<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚óªÔ∏è ‚úùÔ∏è üôÖ Vorhersagen von Mathematikern. Wir analysieren die wichtigsten Methoden zur Erkennung von Anomalien üíÉüèæ üì∞ üì£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Einsatz k√ºnstlicher Intelligenz in der Industrie zur vorausschauenden Wartung verschiedener Systeme gewinnt im Ausland immer mehr an Beliebtheit. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vorhersagen von Mathematikern. Wir analysieren die wichtigsten Methoden zur Erkennung von Anomalien</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/447190/">  Der Einsatz k√ºnstlicher Intelligenz in der Industrie zur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorausschauenden Wartung</a> verschiedener Systeme gewinnt im Ausland immer mehr an Beliebtheit.  Der Zweck dieser Technik besteht darin, Fehlfunktionen im Betrieb des Systems w√§hrend der Betriebsphase zu identifizieren, bevor es f√ºr eine rechtzeitige Reaktion ausf√§llt. <br><br>  Wie relevant ist dieser Ansatz in unserem Land und im Westen?  Die Schlussfolgerung kann beispielsweise zu Artikeln √ºber Habr√© und in Medium gezogen werden.  Es gibt fast keine Artikel √ºber Habr√© zur L√∂sung von Problemen bei der vorausschauenden Wartung.  Auf Medium gibt es einen ganzen Satz.  Hier, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier wird</a> gut beschrieben, was die Ziele und Vorteile dieses Ansatzes sind. <br><br>  Aus diesem Artikel lernen Sie: <br><br><ul><li>  Warum wird diese Technik ben√∂tigt? </li><li>  Welche Ans√§tze des maschinellen Lernens werden h√§ufiger f√ºr die vorausschauende Wartung verwendet? </li><li>  wie ich einen der Tricks mit einem einfachen Beispiel ausprobiert habe. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/845/2a4/888/8452a4888db8d633dd14d426f6b80cbe.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Quelle</i></a> <br><a name="habracut"></a><br>  Welche Funktionen bietet Predictive Service? <br><br><ul><li>  ein kontrollierter Reparaturprozess, der nach Bedarf durchgef√ºhrt wird, wodurch Geld gespart wird und ohne Eile die Qualit√§t dieser Arbeiten verbessert wird; </li><li>  Identifizierung einer bestimmten Fehlfunktion im Betrieb des Ger√§ts (die M√∂glichkeit, ein bestimmtes Teil zum Austausch zu kaufen, wenn das Ger√§t in Betrieb ist, bietet enorme Vorteile); </li><li>  Optimierung des Ger√§tebetriebs, der Lasten usw.; </li><li>  Reduzierung der Kosten f√ºr die regelm√§√üige Abschaltung von Ger√§ten. </li></ul><br>  Der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">n√§chste Artikel √ºber Medium</a> beschreibt gut die Fragen, die beantwortet werden m√ºssen, um zu verstehen, wie man dieses Problem in einem bestimmten Fall angeht. <br><br>  Bei der Datenerfassung oder bei der Auswahl von Daten zum Erstellen eines Modells ist es wichtig, drei Gruppen von Fragen zu beantworten: <br><br><ol><li>  K√∂nnen alle Systemprobleme vorhergesagt werden?  Welche Vorhersage ist besonders wichtig? </li><li>  Was ist ein Fehlerprozess?  Funktioniert das gesamte System nicht mehr oder √§ndert sich nur die Betriebsart?  Ist es ein schneller Prozess, eine sofortige oder allm√§hliche Verschlechterung? </li><li>  Entspricht die Systemleistung angemessen der Leistung?  Beziehen sie sich auf einzelne Teile des Systems oder auf das gesamte System? </li></ol><br>  Es ist auch wichtig, im Voraus zu verstehen, was Sie vorhersagen m√∂chten und was vorhergesagt werden kann und was nicht. <br><br>  Der Artikel auf Medium listet auch Fragen auf, mit denen Sie Ihr spezifisches Ziel bestimmen k√∂nnen: <br><br><ul><li>  Was muss vorhergesagt werden?  Die verbleibende Lebensdauer, abnormales Verhalten oder nicht, die Wahrscheinlichkeit eines Ausfalls in den n√§chsten N Stunden / Tagen / Wochen? </li><li>  Gibt es gen√ºgend historische Daten? </li><li>  Ist bekannt, wann das System anomale Messwerte lieferte und wann nicht?  Ist es m√∂glich, solche Angaben zu markieren? </li><li>  Wie weit sollte das Modell sehen?  Wie unabh√§ngig sind die Messwerte, die den Betrieb des Systems im Intervall von einer Stunde / Tag / Woche widerspiegeln? </li><li>  Was m√ºssen Sie optimieren?  Ob das Modell so viele Verst√∂√üe wie m√∂glich erfassen soll, w√§hrend ein Fehlalarm ausgegeben wird, oder ob es ausreicht, mehrere Ereignisse ohne Fehlalarme zu erfassen. </li></ul><br>  Es ist zu hoffen, dass sich die Situation in Zukunft verbessern wird.  Bisher gibt es Schwierigkeiten im Bereich der vorausschauenden Wartung: Nur wenige Beispiele f√ºr Fehlfunktionen des Systems oder Momente f√ºr Fehlfunktionen des Systems sind ausreichend, aber sie sind nicht gekennzeichnet.  Der Fehlerprozess ist unbekannt. <br><br>  Der Hauptweg, um die Schwierigkeiten bei der vorausschauenden Wartung zu √ºberwinden, ist die Verwendung von <b>Anomaliesuchmethoden</b> .  Solche Algorithmen erfordern kein Markup f√ºr das Training.  Zum Testen und Debuggen von Algorithmen ist ein Markup in der einen oder anderen Form erforderlich.  Solche Methoden sind insofern begrenzt, als sie keinen bestimmten Fehler vorhersagen, sondern nur eine Abnormalit√§t der Indikatoren signalisieren. <br><br>  Das ist aber schon nicht schlecht. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/847/46c/6d7/84746c6d7414722b0a1b7b322000f201.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Quelle</i></a> <br><br><h2>  Methoden </h2><br>  Jetzt m√∂chte ich √ºber einige Merkmale von Anomalieerkennungsans√§tzen sprechen, und dann werden wir gemeinsam die F√§higkeiten einiger einfacher Algorithmen in der Praxis testen. <br><br>  Obwohl in einer bestimmten Situation mehrere Algorithmen getestet werden m√ºssen, um nach Anomalien zu suchen und den besten auszuw√§hlen, k√∂nnen einige Vor- und Nachteile der in diesem Bereich verwendeten Haupttechniken ermittelt werden. <br><br>  Zun√§chst ist es wichtig, im Voraus zu verstehen, wie viel Prozent der Anomalien in den Daten enthalten sind. <br><br>  Wenn es sich um eine Variation des halb√ºberwachten Ansatzes handelt (wir untersuchen nur ‚Äûnormale‚Äú Daten und arbeiten (testen) und dann Daten mit Anomalien), ist <b>die Support-Vektor-Methode mit einer Klasse ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">One-Class SVM</a> )</b> die optimalste Wahl.  Wenn radiale Basisfunktionen als Kernel verwendet werden, erstellt dieser Algorithmus eine nichtlineare Oberfl√§che um den Ursprung.  Je sauberer die Trainingsdaten sind, desto besser funktioniert es. <br><br>  In anderen F√§llen bleibt auch die Notwendigkeit bestehen, das Verh√§ltnis von anomalen und "normalen" Punkten zu kennen - um die Grenzschwelle zu bestimmen. <br><br>  Wenn die Anzahl der Anomalien in den Daten mehr als 5% betr√§gt und sie sich recht gut von der Hauptstichprobe trennen lassen, k√∂nnen Standard-Anomaliesuchmethoden verwendet werden. <br><br>  In diesem Fall ist die <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Isolationswaldmethode</a></b> hinsichtlich der Qualit√§t am stabilsten: <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Isolationswald besteht aus</a></b> randomisierten Daten.  Eine charakteristischere Indikation geht eher tiefer, w√§hrend sich ungew√∂hnliche Indikatoren in den ersten Iterationen vom Rest der Stichprobe trennen. <br><br>  Andere Algorithmen funktionieren besser, wenn sie unter die Besonderheiten der Daten "passen". <br><br>  Wenn die Daten eine Normalverteilung haben, ist die <b>elliptische H√ºllkurvenmethode</b> geeignet, bei der die Daten mit einer mehrdimensionalen Normalverteilung angen√§hert werden.  Je weniger wahrscheinlich es ist, dass der Punkt zur Verteilung geh√∂rt, desto gr√∂√üer ist die Wahrscheinlichkeit, dass er anomal ist. <br><br>  Wenn die Daten so dargestellt werden, dass die relative Position verschiedener Punkte ihre Unterschiede gut widerspiegelt, scheinen metrische Methoden eine gute Wahl zu sein: z. B. <b>k n√§chste Nachbarn, k-te n√§chster Nachbar, ABOD (winkelbasierte Ausrei√üererkennung) oder LOF (lokaler Ausrei√üerfaktor) )</b> <br><br>  Alle diese Methoden legen nahe, dass sich die ‚Äûrichtigen‚Äú Indikatoren auf einen Bereich des mehrdimensionalen Raums konzentrieren.  Wenn unter den k (oder k-ten) n√§chsten Nachbarn alles weit vom Ziel entfernt ist, ist der Punkt eine Anomalie.  F√ºr ABOD ist die Argumentation √§hnlich: Wenn sich alle k n√§chstgelegenen Punkte im Verh√§ltnis zum betrachteten im selben Raumsektor befinden, ist der Punkt eine Anomalie.  F√ºr LOF: Wenn die lokale Dichte (f√ºr jeden Punkt durch k n√§chste Nachbarn vorgegeben) niedriger ist als die von k n√§chsten Nachbarn, ist der Punkt eine Anomalie. <br><br>  Wenn die Daten gut geclustert sind, sind <b>Methoden, die auf der Clusteranalyse</b> basieren, eine gute Wahl.  Wenn der Punkt von den Zentren mehrerer Cluster gleich weit entfernt ist, ist er anomal. <br><br>  Wenn die Richtungen der gr√∂√üten Varianz√§nderung in den Daten gut unterschieden sind, scheint es eine gute Wahl zu sein, <b>auf der Grundlage der Hauptkomponentenmethode nach Anomalien</b> zu <b>suchen</b> .  In diesem Fall werden Abweichungen vom Durchschnittswert f√ºr n1 (die meisten ‚ÄûHauptkomponenten‚Äú) und n2 (die am wenigsten ‚ÄûHauptkomponenten‚Äú) als Anomaliema√ü betrachtet. <br><br>  Beispielsweise wird empfohlen, sich den Datensatz <b>der Prognostics and Health Management Society (PHM Society)</b> anzusehen.  Diese gemeinn√ºtzige Organisation veranstaltet jedes Jahr einen Wettbewerb.  Im Jahr 2018 war es beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erforderlich, Betriebsfehler und die Zeit vor dem Ausfall der Ionenstrahl√§tzanlage vorherzusagen</a> .  Wir werden den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datensatz f√ºr 2015 nehmen</a> .  Es enth√§lt die Messwerte mehrerer Sensoren f√ºr 30 Installationen (Trainingsbeispiel) und muss vorhersagen, wann und welcher Fehler auftreten wird. <br><br>  Ich habe im Netzwerk keine Antworten f√ºr das Testbeispiel gefunden, daher werden wir nur mit dem Training spielen. <br><br>  Im Allgemeinen sind alle Einstellungen √§hnlich, unterscheiden sich jedoch beispielsweise in der Anzahl der Komponenten, in der Anzahl der Anomalien usw.  Daher macht es wenig Sinn, in den ersten 20 zu lernen und in anderen zu testen. <br><br>  Also werden wir eine der Installationen ausw√§hlen, sie laden und uns diese Daten ansehen.  In dem Artikel geht es nicht um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Feature-Engineering</a> , daher werden wir nicht viel miteinander vergleichen. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.covariance <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> EllipticEnvelope <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neighbors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LocalOutlierFactor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IsolationForest <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.svm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> OneClassSVM dfa=pd.read_csv(<span class="hljs-string"><span class="hljs-string">'plant_12a.csv'</span></span>,names=[<span class="hljs-string"><span class="hljs-string">'Component number'</span></span>,<span class="hljs-string"><span class="hljs-string">'Time'</span></span>,<span class="hljs-string"><span class="hljs-string">'S1'</span></span>,<span class="hljs-string"><span class="hljs-string">'S2'</span></span>,<span class="hljs-string"><span class="hljs-string">'S3'</span></span>,<span class="hljs-string"><span class="hljs-string">'S4'</span></span>,<span class="hljs-string"><span class="hljs-string">'S1ref'</span></span>,<span class="hljs-string"><span class="hljs-string">'S2ref'</span></span>,<span class="hljs-string"><span class="hljs-string">'S3ref'</span></span>,<span class="hljs-string"><span class="hljs-string">'S4ref'</span></span>]) dfa.head(<span class="hljs-number"><span class="hljs-number">10</span></span>)</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/301/77e/2bb/30177e2bb970e82495b18008b44d7ea4.jpg"></div><br>  Wie Sie sehen k√∂nnen, gibt es sieben Komponenten, f√ºr die jeweils vier Sensoren abgelesen werden, die alle 15 Minuten gemessen werden.  S1ref-S4ref in der Beschreibung des Wettbewerbs erscheinen als Referenzwerte, aber die Werte unterscheiden sich stark von den Messwerten der Sensoren.  Um keine Zeit damit zu verschwenden, dar√ºber nachzudenken, was sie bedeuten, entfernen wir sie.  Wenn Sie sich die Verteilung der Werte f√ºr jedes Merkmal (S1-S4) ansehen, stellt sich heraus, dass die Verteilungen f√ºr S1, S2 und S4 kontinuierlich und f√ºr S3 diskret sind.  Betrachtet man au√üerdem die gemeinsame Verteilung von S2 und S4, so stellt sich heraus, dass sie umgekehrt proportional sind. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/69b/82b/cde/69b82bcdecdfca69128d88673b0518b4.jpg"></div><br>  Obwohl eine Abweichung von einer direkten Abh√§ngigkeit auf einen Fehler hinweisen kann, werden wir dies nicht √ºberpr√ºfen, sondern einfach S4 entfernen. <br><br>  Wir verarbeiten den Datensatz erneut.  Verlassen Sie S1, S2 und S3.  Wir skalieren S1 und S2 mit StandardScaler (wir subtrahieren den Durchschnitt und dividieren durch die Standardabweichung), √ºbersetzen S3 in OHE (One Hot Encoding).  Wir n√§hen Messwerte von allen Installationskomponenten in einer Zeile.  Insgesamt 89 Funktionen.  2 * 7 = 14 - Messwerte S1 und S2 f√ºr 7 Komponenten und 75 eindeutige Werte von R3.  Nur 56 Tausend solcher Zeilen. <br><br>  Laden Sie die Datei mit Fehlern hoch. <br><br><pre> <code class="python hljs">dfc=pd.read_csv(<span class="hljs-string"><span class="hljs-string">'plant_12c.csv'</span></span>,names=[<span class="hljs-string"><span class="hljs-string">'Start Time'</span></span>, <span class="hljs-string"><span class="hljs-string">'End Time'</span></span>,<span class="hljs-string"><span class="hljs-string">'Type'</span></span>]) dfc.head()</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3ad/419/e50/3ad419e50ac870a71c153b523a22bfed.jpg"></div><br>  Bevor ich diese Algorithmen in unserem Datensatz ausprobiere, werde ich mir einen weiteren kleinen Exkurs erlauben.  Sie m√ºssen getestet werden.  Hierzu wird vorgeschlagen, die Startzeit des Fehlers und die Endzeit zu nehmen.  Alle Indikationen innerhalb dieses Intervalls gelten als abnormal und au√üerhalb als normal.  Dieser Ansatz hat viele Nachteile.  Vor allem aber tritt ein ungew√∂hnliches Verhalten auf, bevor der Fehler behoben wird.  Lassen Sie uns aus Gr√ºnden der Wiedergabetreue das Fenster der Anomalien vor einer halben Stunde verschieben.  Wir werden das F1-Ma√ü, die Pr√§zision und den R√ºckruf bewerten. <br><br>  Der Code zur Unterscheidung von Merkmalen und zur Bestimmung der Qualit√§t des Modells: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_and_preprocess</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(plant_num)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-comment"><span class="hljs-comment">#      ,       dfa=pd.read_csv('plant_{}a.csv'.format(plant_num),names=['Component number','Time','S1','S2','S3','S4','S1ref','S2ref','S3ref','S4ref'])   dfc=pd.read_csv('plant_{}c.csv'.format(plant_num),names=['Start Time','End Time','Type']).drop(0,axis=0)   N_comp=len(dfa['Component number'].unique())   #  15    dfa['Time']=pd.to_datetime(dfa['Time']).dt.round('15min')   #  6    (  ,    )   dfc=dfc[dfc['Type']!=6]   dfc['Start Time']=pd.to_datetime(dfc['Start Time'])   dfc['End Time']=pd.to_datetime(dfc['End Time'])   #      ,       OHE  3-    dfa=pd.concat([dfa.groupby('Time').nth(i)[['S1','S2','S3']].rename(columns={"S1":"S1_{}".format(i),"S2":"S2_{}".format(i),"S3":"S3_{}".format(i)}) for i in range(N_comp)],axis=1).dropna().reset_index()   for k in range(N_comp):       dfa=pd.concat([dfa.drop('S3_'+str(k),axis=1),pd.get_dummies(dfa['S3_'+str(k)],prefix='S3_'+str(k))],axis=1).reset_index(drop=True)   #          df_train,df_test=train_test_split(dfa,test_size=0.25,shuffle=False)   cols_to_scale=df_train.filter(regex='S[1,2]').columns   scaler=preprocessing.StandardScaler().fit(df_train[cols_to_scale])   df_train[cols_to_scale]=scaler.transform(df_train[cols_to_scale])   df_test[cols_to_scale]=scaler.transform(df_test[cols_to_scale])   return df_train,df_test,dfc #       def get_true_labels(measure_times,dfc,shift_delta):   idxSet=set()   dfc['Start Time']-=pd.Timedelta(minutes=shift_delta)   dfc['End Time']-=pd.Timedelta(minutes=shift_delta)   for idx,mes_time in tqdm_notebook(enumerate(measure_times),total=measure_times.shape[0]):       intersect=np.array(dfc['Start Time']&lt;mes_time).astype(int)*np.array(dfc['End Time']&gt;mes_time).astype(int)       idxs=np.where(intersect)[0]       if idxs.shape[0]:           idxSet.add(idx)   dfc['Start Time']+=pd.Timedelta(minutes=shift_delta)   dfc['End Time']+=pd.Timedelta(minutes=shift_delta)   true_labels=pd.Series(index=measure_times.index)   true_labels.iloc[list(idxSet)]=1   true_labels.fillna(0,inplace=True)   return true_labels #          def check_model(model,df_train,df_test,filt='S[123]'):   model.fit(df_train.drop('Time',axis=1).filter(regex=(filt)))   y_preds = pd.Series(model.predict(df_test.drop(['Time','Label'],axis=1).filter(regex=(filt)))).map({-1:1,1:0})   print('F1 score: {:.3f}'.format(f1_score(df_test['Label'],y_preds)))   print('Precision score: {:.3f}'.format(precision_score(df_test['Label'],y_preds)))   print('Recall score: {:.3f}'.format(recall_score(df_test['Label'],y_preds)))   score = model.decision_function(df_test.drop(['Time','Label'],axis=1).filter(regex=(filt)))   sns.distplot(score[df_test['Label']==0])   sns.distplot(score[df_test['Label']==1]) df_train,df_test,anomaly_times=load_and_preprocess(12) df_test['Label']=get_true_labels(df_test['Time'],dfc,30)</span></span></code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/50b/6f2/be9/50b6f2be9c3220853e92461805030e0b.jpg"></div>  <i>Testergebnisse f√ºr einfache Anomaliesuchalgorithmen im PHM 2015 Data Challenge-Datensatz</i> <br><br>  Zur√ºck zu den Algorithmen.  Probieren wir One Class SVM (OCSVM), IsolationForest (IF), EllipticEnvelope (EE) und LocalOutlierFactor (LOF) f√ºr unsere Daten aus.  Zun√§chst werden wir keine Parameter einstellen.  Ich stelle fest, dass LOF in zwei Modi arbeiten kann.  Wenn novelty = False nur im Trainingssatz nach Anomalien suchen kann (es gibt nur fit_predict), wenn True, dann soll nach Anomalien au√üerhalb des Trainingssatzes gesucht werden (kann separat passen und vorhersagen).  IF hat einen Verhaltensmodus von alt und neu.  Wir verwenden neu.  Er gibt bessere Ergebnisse. <br><br>  OCSVM erkennt Anomalien gut, aber es gibt zu viele Fehlalarme.  Bei anderen Methoden ist das Ergebnis noch schlechter. <br><br>  Angenommen, wir kennen den Prozentsatz der Anomalien in den Daten.  In unserem Fall 27%.  OCSVM hat nu - die obere Sch√§tzung f√ºr den Prozentsatz der Fehler und die untere f√ºr den Prozentsatz der Unterst√ºtzungsvektoren.  Andere Kontaminationsmethoden weisen einen Prozentsatz von Datenfehlern auf.  Bei den IF- und LOF-Methoden wird dies automatisch ermittelt, w√§hrend es f√ºr OCSVM und EE standardm√§√üig auf 0,1 eingestellt ist.  Versuchen wir, die Kontamination (nu) auf 0,27 zu setzen.  Jetzt das Top-Ergebnis f√ºr EE. <br><br>  Code zur √úberpr√ºfung von Modellen: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">check_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model,df_train,df_test,filt=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'S[123]'</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span>   model_type,model = model   model.fit(df_train.drop(<span class="hljs-string"><span class="hljs-string">'Time'</span></span>,axis=<span class="hljs-number"><span class="hljs-number">1</span></span>).filter(regex=(filt)))   y_preds = pd.Series(model.predict(df_test.drop([<span class="hljs-string"><span class="hljs-string">'Time'</span></span>,<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],axis=<span class="hljs-number"><span class="hljs-number">1</span></span>).filter(regex=(filt)))).map({<span class="hljs-number"><span class="hljs-number">-1</span></span>:<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>})   print(<span class="hljs-string"><span class="hljs-string">'F1 score for {}: {:.3f}'</span></span>.format(model_type,f1_score(df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],y_preds)))   print(<span class="hljs-string"><span class="hljs-string">'Precision score for {}: {:.3f}'</span></span>.format(model_type,precision_score(df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],y_preds)))   print(<span class="hljs-string"><span class="hljs-string">'Recall score for {}: {:.3f}'</span></span>.format(model_type,recall_score(df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],y_preds)))   score = model.decision_function(df_test.drop([<span class="hljs-string"><span class="hljs-string">'Time'</span></span>,<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],axis=<span class="hljs-number"><span class="hljs-number">1</span></span>).filter(regex=(filt)))   sns.distplot(score[df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>]==<span class="hljs-number"><span class="hljs-number">0</span></span>])   sns.distplot(score[df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>]==<span class="hljs-number"><span class="hljs-number">1</span></span>])   plt.title(<span class="hljs-string"><span class="hljs-string">'Decision score distribution for {}'</span></span>.format(model_type))   plt.show()</code> </pre> <br>  Es ist interessant, die Verteilung der Anomalieindikatoren f√ºr verschiedene Methoden zu untersuchen.  Es ist ersichtlich, dass LOF f√ºr diese Daten nicht gut funktioniert.  EE hat Punkte, die der Algorithmus als extrem abnormal betrachtet.  Dort fallen jedoch normale Punkte.  IsoFor und OCSVM zeigen, dass die Wahl der Grenzschwelle (Kontamination / Nu) wichtig ist, was den Kompromiss zwischen Genauigkeit und Vollst√§ndigkeit ver√§ndert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a9d/0c8/80f/a9d0c880f36fe37f1de6c9290b8cccc7.png"></div><br>  Es ist logisch, dass die Messwerte der Sensoren nahezu normalverteilt sind und nahezu station√§re Werte aufweisen.  Wenn wir wirklich eine gekennzeichnete Testprobe haben, vorzugsweise auch eine validierte, kann der Kontaminationswert get√∂nt werden.  Die n√§chste Frage ist, welche Fehler st√§rker orientiert sind: falsch positiv oder falsch negativ? <br><br>  Das LOF-Ergebnis ist sehr niedrig.  Nicht sehr beeindruckend.  Denken Sie jedoch daran, dass OHE-Variablen zusammen mit den von StandardScaler transformierten Variablen zur Eingabe gehen.  Und die Standardabst√§nde sind euklidisch.  Wenn Sie jedoch nur die Variablen gem√§√ü S1 und S2 z√§hlen, wird die Situation korrigiert und das Ergebnis ist mit anderen Methoden vergleichbar.  Es ist jedoch wichtig zu verstehen, dass einer der Schl√ºsselparameter der aufgelisteten Metrikklassifizierer die Anzahl der Nachbarn ist.  Dies wirkt sich erheblich auf die Qualit√§t aus und muss abgestimmt werden.  Die Entfernungsmetrik selbst w√§re auch sch√∂n zu erfassen. <br><br>  Versuchen Sie nun, die beiden Modelle zu kombinieren.  Zu Beginn entfernen wir die Anomalien aus dem Trainingssatz.  Und dann werden wir OCSVM auf einem ‚Äûsaubereren‚Äú Trainingsset trainieren.  Nach den vorherigen Ergebnissen haben wir die gr√∂√üte Vollst√§ndigkeit in EE beobachtet.  Wir l√∂schen die Trainingsprobe durch EE, trainieren OCSVM darauf und erhalten F1 = 0,50, Genauigkeit = 0,34, Vollst√§ndigkeit = 0,95.  Nicht beeindruckend.  Aber wir haben nur nu = 0,27 gefragt.  Und die Daten, die wir haben, sind mehr oder weniger "sauber".  Wenn wir davon ausgehen, dass die F√ºlle des EE auf dem Trainingsmuster gleich ist, bleiben 5% der Fehler bestehen.  Wir setzen uns eine solche Nu und erhalten F1 = 0,69, Genauigkeit = 0,59, Vollst√§ndigkeit = 0,82.  Gro√üartig.  Es ist wichtig zu beachten, dass bei anderen Methoden eine solche Kombination nicht funktioniert, da sie impliziert, dass die Anzahl der Anomalien im Trainingssatz und die Testnummer gleich sind.  Wenn Sie diese Methoden an einem reinen Trainingsdatensatz trainieren, m√ºssen Sie weniger Kontamination als in realen Daten und nicht nahe Null angeben. Es ist jedoch besser, sie f√ºr die Kreuzvalidierung auszuw√§hlen. <br><br>  Es ist interessant, das Suchergebnis in der Reihenfolge der Indikationen zu betrachten: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a2/0c5/26d/2a20c526d944b55116f3fcd6af064eab.png"></div><br>  Die Abbildung zeigt einen Ausschnitt der Messwerte des ersten und zweiten Sensors f√ºr 7 Komponenten.  In der Legende die Farbe der entsprechenden Fehler (Anfang und Ende werden durch vertikale Linien derselben Farbe angezeigt).  Punkte zeigen die Vorhersagen an: gr√ºn - wahre Vorhersagen, rot - falsch positiv, lila - falsch negativ.  Die Abbildung zeigt, dass es schwierig ist, die Fehlerzeit visuell zu bestimmen, und der Algorithmus diese Aufgabe recht gut bew√§ltigt.  Es ist zwar wichtig zu verstehen, dass die Messwerte des dritten Sensors hier nicht angegeben sind.  Au√üerdem gibt es nach dem Ende des Fehlers falsch positive Messwerte.  Das hei√üt,  Der Algorithmus erkennt, dass es auch fehlerhafte Werte gibt, und wir haben diesen Bereich als fehlerfrei markiert.  Die rechte Seite der Abbildung zeigt den Bereich vor dem Fehler, den wir als fehlerhaft markiert haben (eine halbe Stunde vor dem Fehler), der als fehlerfrei erkannt wurde und zu falsch negativen Modellfehlern f√ºhrt.  In der Mitte der Figur wird ein zusammenh√§ngendes St√ºck erkannt, das als Fehler erkannt wird.  Die Schlussfolgerung kann wie folgt gezogen werden: Wenn Sie das Problem der Suche nach Anomalien l√∂sen, m√ºssen Sie eng mit Ingenieuren zusammenarbeiten, die die Essenz der Systeme verstehen, deren Ausgabe Sie vorhersagen m√ºssen, da die √úberpr√ºfung der verwendeten Algorithmen im Markup die Realit√§t nicht vollst√§ndig widerspiegelt und die Bedingungen, unter denen solche Algorithmen auftreten k√∂nnten, nicht vollst√§ndig widerspiegelt verwendet werden. <br><br>  Code zum Zeichnen des Diagramms: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_time_course</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df_test,dfc,y_preds,start,end,vert_shift=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">4</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span>   plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>))   cols=df_train.filter(regex=(<span class="hljs-string"><span class="hljs-string">'S[12]'</span></span>)).columns   add=<span class="hljs-number"><span class="hljs-number">0</span></span>   preds_idx=y_preds.iloc[start:end][y_preds[<span class="hljs-number"><span class="hljs-number">0</span></span>]==<span class="hljs-number"><span class="hljs-number">1</span></span>].index   true_idx=df_test.iloc[start:end,:][df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>]==<span class="hljs-number"><span class="hljs-number">1</span></span>].index   tp_idx=set(true_idx.values).intersection(set(preds_idx.values))   fn_idx=set(true_idx.values).difference(set(preds_idx.values))   fp_idx=set(preds_idx.values).difference(set(true_idx.values))   xtime=df_test[<span class="hljs-string"><span class="hljs-string">'Time'</span></span>].iloc[start:end]   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> cols:       plt.plot(xtime,df_test[col].iloc[start:end]+add)       plt.scatter(xtime.loc[tp_idx].values,df_test.loc[tp_idx,col]+add,color=<span class="hljs-string"><span class="hljs-string">'green'</span></span>)       plt.scatter(xtime.loc[fn_idx].values,df_test.loc[fn_idx,col]+add,color=<span class="hljs-string"><span class="hljs-string">'violet'</span></span>)       plt.scatter(xtime.loc[fp_idx].values,df_test.loc[fp_idx,col]+add,color=<span class="hljs-string"><span class="hljs-string">'red'</span></span>)       add+=vert_shift   failures=dfc[(dfc[<span class="hljs-string"><span class="hljs-string">'Start Time'</span></span>]&gt;xtime.iloc[<span class="hljs-number"><span class="hljs-number">0</span></span>])&amp;(dfc[<span class="hljs-string"><span class="hljs-string">'Start Time'</span></span>]&lt;xtime.iloc[<span class="hljs-number"><span class="hljs-number">-1</span></span>])]   unique_fails=np.sort(failures[<span class="hljs-string"><span class="hljs-string">'Type'</span></span>].unique())   colors=np.array([np.random.rand(<span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> fail <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> unique_fails])   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> fail_idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> failures.index:       c=colors[np.where(unique_fails==failures.loc[fail_idx,<span class="hljs-string"><span class="hljs-string">'Type'</span></span>])[<span class="hljs-number"><span class="hljs-number">0</span></span>]][<span class="hljs-number"><span class="hljs-number">0</span></span>]       plt.axvline(failures.loc[fail_idx,<span class="hljs-string"><span class="hljs-string">'Start Time'</span></span>],color=c)       plt.axvline(failures.loc[fail_idx,<span class="hljs-string"><span class="hljs-string">'End Time'</span></span>],color=c)   leg=plt.legend(unique_fails)   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(unique_fails)):       leg.legendHandles[i].set_color(colors[i])</code> </pre> <br>  Wenn der Prozentsatz der Anomalien unter 5% liegt und / oder sie schlecht von den ‚Äûnormalen‚Äú Indikatoren getrennt sind, funktionieren die oben genannten Methoden schlecht und es lohnt sich, Algorithmen zu verwenden, die auf neuronalen Netzen basieren.  Im einfachsten Fall w√§ren dies: <br><br><ul><li>  Auto-Encoder (ein hoher Fehler eines trainierten Auto-Encoders signalisiert eine Abnormalit√§t beim Lesen); </li><li>  wiederkehrende Netzwerke (Lernen nach Reihenfolge, um den letzten Messwert vorherzusagen. Wenn der Unterschied gro√ü ist, ist der Punkt abnormal). </li></ul><br>  Unabh√§ngig davon sind die Besonderheiten der Arbeit mit Zeitreihen zu beachten.  Es ist wichtig zu verstehen, dass die meisten der oben genannten Algorithmen (mit Ausnahme von Autoencodern und Isolieren von W√§ldern) h√∂chstwahrscheinlich eine schlechtere Qualit√§t ergeben, wenn Verz√∂gerungsfunktionen hinzugef√ºgt werden (Messwerte von fr√ºheren Zeitpunkten). <br><br>  Versuchen wir in unserem Beispiel, Verz√∂gerungsfunktionen hinzuzuf√ºgen.  Die Beschreibung des Wettbewerbs besagt, dass die Werte 3 Stunden vor dem Fehler in keiner Weise mit dem Fehler verbunden sind.  Dann f√ºgen Sie die Zeichen in 3 Stunden hinzu.  Insgesamt 259 Zeichen. <br><br>  Infolgedessen blieben die Ergebnisse f√ºr OCSVM und IsolationForest nahezu unver√§ndert, w√§hrend die f√ºr Elliptic Envelope und LOF zur√ºckgingen. <br><br>  Um Informationen √ºber die Dynamik des Systems zu verwenden, sollten Auto-Encoder mit wiederkehrenden oder gefalteten neuronalen Netzen verwendet werden.  Oder zum Beispiel eine Kombination aus Auto-Encodern, Komprimieren von Informationen und herk√∂mmlichen Ans√§tzen zum Suchen nach Anomalien basierend auf komprimierten Informationen.  Der umgekehrte Ansatz scheint ebenfalls vielversprechend.  Prim√§res Screening der uncharakteristischsten Punkte durch Standardalgorithmen und anschlie√üendes Trainieren des Auto-Encoders bereits auf saubereren Daten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/340/9e8/dbc/3409e8dbcc5e9bcac2a1acb08bc7d146.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Quelle</i></a> <br><br>  Es gibt eine Reihe von Techniken zum Arbeiten mit eindimensionalen Zeitreihen.  Alle zielen darauf ab, zuk√ºnftige Messwerte vorherzusagen, und Punkte, die von der Vorhersage abweichen, werden als Anomalien betrachtet. <br><br><h2>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Holt-Winters-Modell</a> </h2><br>  Die dreifache exponentielle Gl√§ttung unterteilt die Serie in drei Komponenten: Level, Trend und Saisonalit√§t.  Wenn die Reihe in dieser Form pr√§sentiert wird, funktioniert das Verfahren dementsprechend gut.  Facebook Prophet arbeitet nach einem √§hnlichen Prinzip, bewertet die Komponenten selbst jedoch auf andere Weise.  Weitere Details finden Sie beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br><h2>  S (ARIMA) </h2><br>  Bei dieser Methode basiert das Vorhersagemodell auf Autoregression und gleitendem Durchschnitt.  Wenn wir √ºber die Erweiterung von S (ARIMA) sprechen, k√∂nnen wir die Saisonalit√§t bewerten.  Lesen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> mehr √ºber den Ansatz. <br><br><h2>  Andere pr√§diktive Service-Ans√§tze </h2><br>  Wenn es um Zeitreihen geht und Informationen √ºber den Zeitpunkt des Auftretens von Fehlern vorliegen, k√∂nnen Sie die Lehrmethoden bei einem Lehrer anwenden.  Neben dem Bedarf an markierten Daten ist es in diesem Fall wichtig zu verstehen, dass die Fehlervorhersage von der Art des Fehlers abh√§ngt.  Wenn es viele Fehler unterschiedlicher Art gibt, ist es h√∂chstwahrscheinlich erforderlich, diese einzeln vorherzusagen, was noch mehr gekennzeichnete Daten erfordert, aber die Aussichten sind attraktiver. <br><br>  Es gibt alternative M√∂glichkeiten, maschinelles Lernen f√ºr die vorausschauende Wartung zu verwenden.  Zum Beispiel Vorhersage eines Systemfehlers in den n√§chsten N Tagen (Klassifizierungsaufgabe).  Es ist wichtig zu verstehen, dass ein solcher Ansatz erfordert, dass dem Auftreten eines Fehlers im Betrieb des Systems eine Periode der Verschlechterung vorausgeht (nicht notwendigerweise allm√§hlich).  In diesem Fall scheint der erfolgreichste Ansatz die Verwendung neuronaler Netze mit Faltungsschichten und / oder wiederkehrenden Schichten zu sein.  Unabh√§ngig davon sind Methoden zur Erweiterung von Zeitreihen zu erw√§hnen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zwei Ans√§tze</a> erscheinen mir am interessantesten und zugleich einfachsten: <br><br><ul><li>  Der durchgehende Teil der Reihe wird ausgew√§hlt (z. B. 70%, und der Rest wird entfernt) und auf die urspr√ºngliche Gr√∂√üe gedehnt </li><li>  Ein kontinuierlicher Teil der Reihe (z. B. 20%) wird ausgew√§hlt und gedehnt oder komprimiert.  Danach wird die gesamte Reihe entsprechend komprimiert oder auf ihre urspr√ºngliche Gr√∂√üe gedehnt. </li></ul><br>  Es besteht auch die M√∂glichkeit, die verbleibende Systemlebensdauer vorherzusagen (Regressionsaufgabe).  Hier k√∂nnen wir einen separaten Ansatz unterscheiden: Die Vorhersage bezieht sich nicht auf die Lebensdauer, sondern auf die Weibull-Verteilungsparameter. <br><br>  Sie k√∂nnen hier √ºber die Distribution selbst und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> √ºber ihre Verwendung in Verbindung mit wiederkehrenden Netzen lesen.  Diese Verteilung hat zwei Parameter Œ± und Œ≤.  Œ± gibt an, wann das Ereignis eintreten wird, und Œ≤ gibt an, wie sicher der Algorithmus ist.  Obwohl die Anwendung dieses Ansatzes vielversprechend ist, treten in diesem Fall Schwierigkeiten beim Training des neuronalen Netzwerks auf, da es einfacher ist, zu Beginn des Algorithmus unsicher zu sein, als eine angemessene Lebensdauer vorherzusagen. <br><br>  Unabh√§ngig davon ist die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cox-Regression zu</a> erw√§hnen.  Sie k√∂nnen die Fehlertoleranz des Systems f√ºr jeden Zeitpunkt nach der Diagnose vorhersagen und es als Produkt zweier Funktionen darstellen.  Eine Funktion ist die Verschlechterung des Systems, unabh√§ngig von seinen Parametern, d.h.  solchen Systemen gemeinsam.  Und die zweite ist eine exponentielle Abh√§ngigkeit von den Parametern eines bestimmten Systems.  F√ºr eine Person gibt es also eine gemeinsame Funktion im Zusammenhang mit dem Altern, die f√ºr alle mehr oder weniger gleich ist.  Die Verschlechterung der Gesundheit ist aber auch mit dem Zustand der inneren Organe verbunden, der f√ºr jeden unterschiedlich ist. <br><br>  Ich hoffe, Sie wissen jetzt etwas mehr √ºber vorausschauende Wartung.  Ich bin sicher, Sie werden Fragen zu den Methoden des maschinellen Lernens haben, die f√ºr diese Technologie am h√§ufigsten verwendet werden.  Ich werde gerne jeden von ihnen in den Kommentaren beantworten.  Wenn Sie nicht nur nach dem Geschriebenen fragen m√∂chten, sondern auch etwas √Ñhnliches tun m√∂chten, freut sich unser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CleverDATA-</a> Team immer √ºber talentierte und begeisterte Fachleute. <br><br><div class="spoiler">  <b class="spoiler_title">Gibt es offene Stellen?</b>  <b class="spoiler_title">Nat√ºrlich!</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Java Developer (Big Data)</a> </li></ul></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de447190/">https://habr.com/ru/post/de447190/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de447178/index.html">5 effektive M√∂glichkeiten f√ºr den Einsatz von Process Mining-Technologie</a></li>
<li><a href="../de447180/index.html">√úbersicht und Vergleich von Ingress Controllern f√ºr Kubernetes</a></li>
<li><a href="../de447182/index.html">Betriebssysteme: Drei einfache Teile. Teil 3: Prozess-API (√úbersetzung)</a></li>
<li><a href="../de447184/index.html">Was ist Initial Exchange Offering (IEO) und wie unterscheidet es sich von ICO?</a></li>
<li><a href="../de447186/index.html">So starten Sie einen ML-Prototyp an einem Tag. Bericht Yandex.Taxi</a></li>
<li><a href="../de447192/index.html">Welche Rolle kann Technologie in der alten Kunst des Gew√ºrzmischens spielen?</a></li>
<li><a href="../de447194/index.html">Rendering-Funktionen in Metro: Exodus c Raytracing</a></li>
<li><a href="../de447196/index.html">7. Check Point Erste Schritte R80.20. Zugangskontrolle</a></li>
<li><a href="../de447198/index.html">Mondmission "Bereshit": Landungsunfall-Sturz auf den Mond</a></li>
<li><a href="../de447204/index.html">17. April: Offene Vorlesung "Der Weg des Spieleentwicklers: Von der Idee zum Start" und eine Spielbibliothek an der Higher School of Law</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé¶ üß• üé¥ Neuronale Netzwerkarchitektur zur Implementierung des RL-Algorithmus mit der F√§higkeit, gleichzeitig laufende Aktionen festzulegen üëèüèº üöå üìã</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eines der klassischen neuronalen Netzwerkschemata zum Implementieren des RL-Algorithmus ist wie folgt: 


 Wobei: Eingaben - Eingaben in das neuronale...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neuronale Netzwerkarchitektur zur Implementierung des RL-Algorithmus mit der F√§higkeit, gleichzeitig laufende Aktionen festzulegen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454916/">  Eines der klassischen neuronalen Netzwerkschemata zum Implementieren des RL-Algorithmus ist wie folgt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vx/y-/ez/vxy-ezv8r9wzknk0xrjx4b7cozg.png"></div><br>  Wobei: Eingaben - Eingaben in das neuronale Netzwerk;  FC - (vollst√§ndig verbundene) Hidden-Layer-Architektur oder CNN - FC - Architecture-Hidden-Layer-Architektur (abh√§ngig davon, was den Eing√§ngen zugef√ºhrt wird);  Ausg√§nge - Netzwerkausg√§nge.  Netzwerkausgaben sind h√§ufig eine Softmax-Schicht, die die Wahrscheinlichkeit einer der Aktionen aus der Menge aller m√∂glichen Aktionen angibt. <br><br>  Der Nachteil dieser Architektur besteht darin, dass es schwierig ist, die Auswahl mehrerer gleichzeitig ausgef√ºhrter Aktionen zu implementieren. <br><br>  Um dieses Problem zu l√∂sen, wird eine Architektur mit einer Maskenschicht vorgeschlagen.  Die vorgeschlagene Architektur lautet wie folgt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fk/co/md/fkcomd9t7pidbqcp1ffvw4iobvu.png"></div><br>  Diese Architektur stimmt vollst√§ndig mit der klassischen Architektur √ºberein, enth√§lt jedoch auch eine Aktionsmaskenschicht.  Es gibt nur einen Ausweg aus dieser Architektur - dies ist der Wert des Werts der Aktion (eine Gruppe gleichzeitig ausgef√ºhrter Aktionen).  Die Aktionsmaskenschicht kann gem√§√ü dem folgenden Pseudocode implementiert werden: <br><a name="habracut"></a><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Layer</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, items, item_size, extra_size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span>(items &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span>(item_size &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span>(extra_size &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span>) self.items = items self.item_size = item_size self.extra_size = extra_size <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self._expand_op = np.zeros((self.items, self.items*self.item_size), \ dtype=np.float32) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(self.items): self._expand_op[i,i*self.item_size:(i+<span class="hljs-number"><span class="hljs-number">1</span></span>)*self.item_size] = np.float32(<span class="hljs-number"><span class="hljs-number">1.0</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs, ops)</span></span></span><span class="hljs-function">:</span></span> op_mask_part = inputs[:self.items*self.item_size] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> self.extra_size &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: ext_part = inputs[self.items*self.item_size:] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: ext_part = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-comment"><span class="hljs-comment"># if ops in [-0.5, 0.5] or [-0.5 .. 0.5]: ops1 = np.add(ops, np.float(0.5)) # optional extended_op = np.matmul(ops1, self._expand_op) if self.extra_size &gt; 0: return np.concatenate((np.multiply(op_mask_part, extended_op), ext_part)) else: return np.multiply(op_mask_part,extended_op)</span></span></code> </pre> <br>  Die Verwendung dieses Codes zeigt das folgende Codefragment: <br><br><pre> <code class="python hljs">items = <span class="hljs-number"><span class="hljs-number">5</span></span> item_size = <span class="hljs-number"><span class="hljs-number">10</span></span> extra_size = <span class="hljs-number"><span class="hljs-number">20</span></span> l = Layer(items=items, item_size=item_size, extra_size=extra_size) l.build() inputs = np.random.rand(items*item_size+extra_size) ops = np.random.randint(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, (items,), dtype=<span class="hljs-string"><span class="hljs-string">"int"</span></span>) ops = ops.astype(dtype=np.float32) - np.float32(<span class="hljs-number"><span class="hljs-number">0.5</span></span>) result = l.call(inputs,ops)</code> </pre><br>  Aus dem Schichtcode ist ersichtlich, dass das neuronale Netzwerk f√ºr jede Aktion lernt, eine Darstellung der Aktion in Form einer Reihe von Gewichten zu bilden.  Und diese Darstellungen gehen entweder nach der Maskenschicht ins Netzwerk oder nicht.  Abh√§ngig von der Operation k√∂nnen diese Gewichte mit der Aufgabe einer Operation f√ºr die gesamte Gruppe von Aktionsgewichten erfolgen (nicht nur Multiplikation mit [0,1]).  Somit wird die Aufgabe von Aktionen gebildet, um den Wert der Gruppe von Aktionen zu berechnen, die vom Netzwerk ausgef√ºhrt werden.  (Im klassischen Fall berechnete die Softmax-Schicht den Wert aller Aktionen. In der vorgeschlagenen Architektur berechnet das neuronale Netzwerk den Wert einer Gruppe ausgew√§hlter Aktionen.) <br><br>  (F√ºr eine Definition des Werts einer Aktion siehe beispielsweise R. S. Sutton, E. G. Barto Reinforced Learning.) <br><br><h3>  Beispiele f√ºr die Verwendung der vorgeschlagenen Architektur </h3><br><h4>  Tetris-Spiel </h4><br>  Die Idee, diese Architektur zum Spielen von Tetris zu verwenden, ist wie folgt.  An den Eing√§ngen senden wir das Bild des Glases des Tetris-Spiels (ein Pixel ein Quadrat).  Wir gruppieren einzelne Aktionen in Aktionsgruppen.  Die Bewertung einer Aktion f√ºr ein neuronales Netzwerk ist eine Maske der Endposition einer Figur in einem Glas.  Die Figur wird durch ihre Quadrate in der Aktionsmaske in der Schicht der Aktionsmaske im neuronalen Netzwerk festgelegt.  Um eine Gruppe von Aktionen auszuw√§hlen, w√§hlen wir die maximale Bewertung der Aktion (Beenden) aus der Liste aller Endpositionen der aktuellen Figur aus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hn/ic/xq/hnicxqwntkfn4kfsm5nem3dwxya.png"></div><br>  Zeichnen.  Das Feld (blaue Zellen) und die fallende Form (hellgraue Zellen) werden angezeigt.  Die endg√ºltige Position der Figur sind alle m√∂glichen Positionen, von denen sich die Figur gem√§√ü den Spielregeln (nicht gezeigt) nicht bewegen kann. <br><br><h4>  Agent, der die Bewegung eines Autos simuliert </h4><br>  In diesem Fall wurden jede Beschleunigungsaktion (mehrere Beschleunigungsbeschleunigungen), Bremsen (mehrere m√∂gliche Beschleunigungen beim Bremsen) sowie mehrere Rotationsgrade als Elementaraktionen modelliert.  Es versteht sich, dass gleichzeitig eine Rotation und eine der Beschleunigungen beteiligt sein k√∂nnen oder nur eine Rotationsaktion oder eine Beschleunigungsaktion.  In diesem Fall k√∂nnen Sie in der Architektur mehrere Elementaraktionen gleichzeitig angeben, um eine komplexe Aktion zu bilden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cy/m2/z3/cym2z34jxlthfggjvtlwmteu3lc.png"></div><br>  Zeichnen.  Neben dem Feld zur Durchf√ºhrung von Aktionen des Automodells (auf dem das Parkziel durch rote und gr√ºne Linien angegeben ist) werden auch die Eingaben des neuronalen Netzes (unten) und die Werte der Bewertung von Aktionen f√ºr alle m√∂glichen Aktionen in diesem Zustand des Modells angezeigt. <br><br><h3>  Andere m√∂gliche Anwendungen der Architektur </h3><br>  In √§hnlicher Weise kann bei Verwendung von Tetris in einem Spiel die Architektur f√ºr andere Spiele verwendet werden, bei denen eine Reihe von Figuren und mehrere Aktionen gleichzeitig auf dem Spielfeld festgelegt werden k√∂nnen (z. B. Bewegen auf dem Spielfeld). <br><br>  In der Robotik kann diese Architektur als Metanetzwerk dienen, das einzelne Strukturelemente zu einem gemeinsamen Ensemble koordiniert. <br><br>  Mit dieser Architektur k√∂nnen Sie auch das Transferlernen verwenden, um den CNN-Teil vorab zu trainieren, und umgekehrt zu Beginn, um den RL-Teil des neuronalen Netzwerks zu trainieren und dann den CNN-Teil im bereits trainierten RL-Netzwerk anhand von Modelldaten zu trainieren.  In dem Beispiel wurde beim Programmieren des Tetris-Spiels das Transferlernen mit Training am Anfang des CNN-Teils und des FC-Teils auf die Aktionsmaskenschicht angewendet (was auf das resultierende Netzwerk √ºbertragen wird).  Bei dem Parkproblem plane ich auch, nach dem Erlernen des RL-Teils (dh der ersten Kirsche) ein CNN-Training anzuwenden. <br><br>  ‚Üí Beispiele f√ºr Programmquellcodes finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de454916/">https://habr.com/ru/post/de454916/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de454896/index.html">Warum ich freiberuflich zu einem Remote-Team gewechselt bin</a></li>
<li><a href="../de454898/index.html">Programmierung ist mehr als Codierung</a></li>
<li><a href="../de454900/index.html">So machen Sie Webformulare auf der Website bequem und sicher: Entwicklungstools und Konstruktoren</a></li>
<li><a href="../de454904/index.html">Samsung startet kostenlosen Online-Kurs f√ºr Computer Vision Neural Network</a></li>
<li><a href="../de454912/index.html">Die Zwergenfestung Tarn Adams spricht √ºber die Spieleentwicklung</a></li>
<li><a href="../de454918/index.html">So kombinieren Sie den R√ºcken zweier Einzelh√§ndler in SAP in 12 Stunden</a></li>
<li><a href="../de454920/index.html">Front-End-Leistung: Analysieren wichtiger Metriken</a></li>
<li><a href="../de454922/index.html">Geschichten √ºber ausl√§ndische Kunden und ihre Arbeitsmerkmale in Russland nach dem PD-Gesetz</a></li>
<li><a href="../de454924/index.html">Authentifizierungseinstellungen in Veeam Backup f√ºr Microsoft Office 365 v3</a></li>
<li><a href="../de454926/index.html">Alles, was Sie √ºber word2vec wussten, ist nicht wahr</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
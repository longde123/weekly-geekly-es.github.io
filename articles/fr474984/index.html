<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔦 😎 🤶🏾 RabbitMQ contre Kafka: basculement et haute disponibilité 🅾️ 🎅🏿 ✋🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans un article précédent, nous avons examiné le clustering RabbitMQ pour la tolérance aux pannes et la haute disponibilité. Maintenant, approfondisso...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ contre Kafka: basculement et haute disponibilité</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/474984/"><img src="https://habrastorage.org/webt/rc/zb/n7/rczbn7bwtp8b5day0whi_wace2e.jpeg"><br><br>  Dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article précédent,</a> nous avons examiné le clustering RabbitMQ pour la tolérance aux pannes et la haute disponibilité.  Maintenant, approfondissons Apache Kafka. <br><br>  Ici, l'unité de réplication est une partition.  Chaque sujet comporte une ou plusieurs sections.  Chaque section a un leader avec ou sans abonnés.  Lors de la création d'un sujet, le nombre de partitions et le taux de réplication sont indiqués.  La valeur habituelle est 3, ce qui signifie trois remarques: un leader et deux suiveurs. <br><a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/ly/hd/ml/lyhdmlstwyv-tf_-ts54gife3cw.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Quatre sections sont réparties entre trois courtiers</font></i> <br><br>  Toutes les demandes de lecture et d'écriture sont transmises au responsable.  Les suiveurs envoient périodiquement des demandes au leader pour recevoir les derniers messages.  Les consommateurs ne se tournent jamais vers les followers, ces derniers n'existent que pour la redondance et la tolérance aux pannes. <br><br><img src="https://habrastorage.org/webt/sb/fc/v0/sbfcv0j3mosfzvrb7qktoexl_lg.png"><br><br><h1>  Échec de la section </h1><br>  Lorsqu'un courtier tombe, les dirigeants de plusieurs sections échouent souvent.  Dans chacun d'eux, le suiveur d'un autre nœud devient le leader.  En fait, ce n'est pas toujours le cas, car le facteur de synchronisation affecte également: s'il y a des suiveurs synchronisés, et sinon, la transition vers une réplique non synchronisée est-elle autorisée.  Mais pour l'instant, ne compliquons pas les choses. <br><br>  Le courtier 3 quitte le réseau - et pour la section 2, un nouveau leader sur le courtier 2 est élu. <br><br><img src="https://habrastorage.org/webt/im/ct/r0/imctr0qotjsjg4_jx3g6p5otk9u.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. Le courtier 3 décède et son disciple du courtier 2 est élu nouveau chef de la section 2</font></i> <br><br>  Ensuite, le courtier 1 quitte et la section 1 perd également son chef, dont le rôle revient au courtier 2. <br><br><img src="https://habrastorage.org/webt/rg/fo/zp/rgfozpk7b_t1odoxso1mvihmccu.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">3. Il ne reste qu'un courtier.</font></i>  <i><font color="gray">Tous les dirigeants sont sur le même courtier à redondance zéro.</font></i> <br><br>  Lorsque le courtier 1 revient sur le réseau, il ajoute quatre abonnés, fournissant une certaine redondance à chaque section.  Mais tous les leaders sont restés sur le broker 2. <br><br><img src="https://habrastorage.org/webt/mh/lj/2s/mhlj2sn5r6rcjodqnl22450bjn8.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">4. Les dirigeants restent sur le courtier 2</font></i> <br><br>  Lorsque le courtier 3 monte, nous revenons à trois répliques par section.  Mais tous les leaders sont toujours sur le broker 2. <br><br><img src="https://habrastorage.org/webt/3u/tb/op/3utbopk0awdg8rg62natyoxqg9o.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">5. Placement déséquilibré des dirigeants après la restauration des courtiers 1 et 3</font></i> <br><br>  Kafka a un outil pour mieux rééquilibrer les dirigeants que RabbitMQ.  Là, vous avez dû utiliser un plug-in ou un script tiers qui a modifié les politiques de migration du nœud principal en réduisant la redondance lors de la migration.  De plus, pour les grandes files d'attente, il fallait supporter l'inaccessibilité lors de la synchronisation. <br><br>  Kafka a un concept de «repères préférés» pour le rôle de leadership.  Lorsque les sections de sujet sont créées, Kafka essaie de répartir uniformément les leaders sur les nœuds et marque ces premiers leaders comme préférés.  Au fil du temps, en raison des redémarrages du serveur, des échecs et des échecs de connectivité, les leaders peuvent se retrouver sur d'autres nœuds, comme dans le cas extrême décrit ci-dessus. <br><br>  Pour résoudre ce problème, Kafka propose deux options: <br><br><ul><li>  L'option <i>auto.leader.rebalance.enable = true</i> permet au nœud du contrôleur de réaffecter automatiquement les leaders aux répliques préférées et de restaurer ainsi une distribution uniforme. <br></li><li>  Un administrateur peut exécuter le script <i>kafka-preferred-replica-election.sh</i> pour réaffecter manuellement. </li></ul><br><br><img src="https://habrastorage.org/webt/qt/2l/th/qt2lth99rb1fhzq8g4r93uoxh6k.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">6. Répliques après rééquilibrage</font></i> <br><br>  C'était une version simplifiée de l'échec, mais la réalité est plus complexe, bien qu'il n'y ait rien de trop compliqué ici.  Tout se résume à des répliques synchronisées (répliques In-Sync, ISR). <br><br><h1>  Répliques synchronisées (ISR) </h1><br>  ISR est un ensemble de répliques d'une partition qui est considérée comme «synchronisée» (en synchronisation).  Il y a un leader, mais il peut ne pas y avoir de followers.  Un suiveur est considéré comme synchronisé s'il a fait des copies exactes de tous les messages de leader avant l'expiration de l'intervalle <i>replica.lag.time.max.ms</i> . <br><br>  Le suiveur est supprimé de l'ensemble ISR s'il: <br><br><ul><li>  n'a pas fait de demande d'échantillonnage pour l'intervalle <i>replica.lag.time.max.ms</i> (considéré comme mort) <br></li><li>  n'a pas eu le temps de mettre à jour pour l'intervalle <i>replica.lag.time.max.ms</i> (considéré comme lent) </li></ul><br>  Les suiveurs font des demandes de récupération dans l'intervalle <i>replica.fetch.wait.max.ms</i> , qui par défaut est de 500 ms. <br><br>  Pour expliquer clairement l'objectif de l'ISR, vous devez consulter les confirmations du producteur (producteur) et certains scénarios de défaillance.  Les producteurs peuvent choisir quand un courtier envoie une confirmation: <br><br><ul><li>  acks = 0, la confirmation n'est pas envoyée <br></li><li>  acks = 1, la confirmation est envoyée après que le leader a écrit un message dans son journal local <br></li><li>  acks = all, une confirmation est envoyée après que toutes les répliques du ISR ont écrit un message dans les journaux locaux </li></ul><br>  Dans la terminologie de Kafka, si l'ISR a enregistré le message, il est «engagé».  Acks = all est l'option la plus sûre, mais aussi un délai supplémentaire.  Examinons deux exemples d'échec et comment les différentes options «acks» interagissent avec le concept ISR. <br><br><h3>  Acks = 1 et ISR </h3><br>  Dans cet exemple, nous verrons que si le leader n'attend pas que chaque message de tous les abonnés soit enregistré, alors si le leader échoue, les données peuvent être perdues.  Aller à un abonné non synchronisé peut être activé ou désactivé en définissant <i>unclean.leader.election.enable</i> . <br><br>  Dans cet exemple, le fabricant est défini sur acks = 1.  La section est répartie entre les trois courtiers.  Broker 3 est derrière, il s'est synchronisé avec le leader il y a huit secondes et est maintenant derrière par 7456 messages.  Le courtier 1 n'a qu'une seconde de retard.  Notre producteur envoie un message et reçoit rapidement un accusé de réception, sans frais généraux pour les adeptes lents ou morts auxquels le leader ne s'attend pas. <br><br><img src="https://habrastorage.org/webt/ej/bh/g7/ejbhg7svgcphrhpdtzbwuw--wg4.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">7. ISR avec trois répliques</font></i> <br><br>  Le courtier 2 échoue et le fabricant reçoit une erreur de connexion.  Après la transition du leadership vers le courtier 1, nous perdons 123 messages.  Le suiveur du courtier 1 faisait partie de l'ISR, mais ne s'est pas complètement synchronisé avec le leader lors de sa chute. <br><br><img src="https://habrastorage.org/webt/6y/th/y9/6ythy9olfa5zr2wyqtfqcrq8u5e.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">8. En cas d'échec, les messages sont perdus</font></i> <br><br>  Dans la configuration <i>bootstrap.servers</i> , le fabricant répertorie plusieurs courtiers, et il peut demander à un autre courtier qui est devenu le nouveau leader de la section.  Il établit ensuite une connexion avec le courtier 1 et continue d'envoyer des messages. <br><br><img src="https://habrastorage.org/webt/br/o6/jr/bro6jrn5nt-a0wzvg_yt0csmdgg.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">9. L'envoi de messages reprend après une courte pause</font></i> <br><br>  Le courtier 3 traîne encore plus loin.  Il effectue des requêtes de récupération, mais ne peut pas se synchroniser.  Cela peut être dû à une connexion réseau lente entre les courtiers, un problème de stockage, etc. Il est supprimé de l'ISR.  Désormais, l'ISR se compose d'une seule réplique - le leader!  Le fabricant continue d'envoyer des messages et de recevoir une confirmation. <br><br><img src="https://habrastorage.org/webt/b2/qj/aj/b2qjaj5g_yx2wfb-jdkalxr9074.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">10. Le suiveur du courtier 3 est supprimé de l'ISR</font></i> <br><br>  Le courtier 1 tombe et le rôle du leader revient au courtier 3 avec la perte de 15286 messages!  Le fabricant reçoit un message d'erreur de connexion.  Aller au leader en dehors de l'ISR n'était possible qu'en raison du paramètre <i>unclean.leader.election.enable = true</i> .  S'il est défini sur <i>false</i> , la transition ne se serait pas produite et toutes les demandes de lecture et d'écriture seraient rejetées.  Dans ce cas, nous attendons le retour du courtier 1 avec ses données intactes dans la réplique, qui reprendra la tête. <br><br><img src="https://habrastorage.org/webt/rr/n1/-n/rrn1-nekmhjtro9pxeueciytb50.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">11. Le courtier 1 tombe.</font></i>  <i><font color="gray">En cas d'échec, un grand nombre de messages sont perdus</font></i> <br><br>  Le constructeur établit une connexion avec le dernier courtier et constate qu'il est désormais le leader de la section.  Il commence à envoyer des messages au courtier 3. <br><br><img src="https://habrastorage.org/webt/qj/qq/go/qjqqgoevfafcmcxtidd_bvjw9wi.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">12. Après une courte pause, les messages sont à nouveau envoyés à la section 0</font></i> <br><br>  Nous avons vu qu'en plus de brèves interruptions pour établir de nouvelles connexions et rechercher un nouveau leader, le fabricant envoyait constamment des messages.  Cette configuration assure l'accessibilité grâce à la cohérence (sécurité des données).  Kafka a perdu des milliers de messages, mais a continué d'accepter de nouvelles entrées. <br><br><h3>  Acks = all et ISR </h3><br>  Répétons à nouveau ce scénario, mais avec <i>acks = all</i> .  Retarder le courtier 3 en moyenne quatre secondes.  Le fabricant envoie un message avec <i>acks = all</i> et ne reçoit plus de réponse rapide.  Le leader attend que tous les messages de l'ISR stockent le message. <br><br><img src="https://habrastorage.org/webt/3c/6j/a5/3c6ja5msoncfx1s-xbyjpmujtdo.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">13. ISR avec trois répliques.</font></i>  <i><font color="gray">L'un est lent, entraînant un retard d'enregistrement</font></i> <br><br>  Après quatre secondes de délai supplémentaire, le courtier 2 envoie un accusé de réception.  Toutes les répliques sont désormais entièrement mises à jour. <br><br><img src="https://habrastorage.org/webt/ol/eg/y6/olegy6unibvup0tlza6cbd4gqic.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">14. Toutes les répliques enregistrent les messages et un accusé de réception est envoyé</font></i> <br><br>  Le courtier 3 est maintenant encore plus en retard et est en cours de retrait de l'ISR.  Le délai est considérablement réduit car il n'y a plus de répliques lentes dans l'ISR.  Le courtier 2 n'attend plus que le courtier 1 et il a un décalage moyen de 500 ms. <br><br><img src="https://habrastorage.org/webt/ub/0e/7j/ub0e7jm1siaa9dvcmxyldti1ify.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">15. La réplique sur le courtier 3 est supprimée de l'ISR</font></i> <br><br>  Ensuite, le courtier 2 tombe et le leadership passe au courtier 1 sans perdre de messages. <br><br><img src="https://habrastorage.org/webt/a7/ts/8m/a7ts8mywsvuowiof5jp6f6eszlq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">16. Le courtier 2 tombe</font></i> <br><br>  Le constructeur trouve un nouveau leader et commence à lui envoyer des messages.  Le délai est toujours réduit, car maintenant l'ISR se compose d'une seule réplique!  Par conséquent, l'option <i>acks = all</i> n'ajoute pas de redondance. <br><br><img src="https://habrastorage.org/webt/-z/i_/od/-zi_odb0nc-nf0xe1tsxmzlr-uq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">17. La réplique sur le courtier 1 prend les devants sans perdre les messages</font></i> <br><br>  Ensuite, le courtier 1 tombe et le leadership passe au courtier 3 avec la perte de 14 238 messages! <br><br><img src="https://habrastorage.org/webt/sr/x5/1m/srx51mjemyxnksoewy6n91_lgqy.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">18. Le courtier 1 meurt et la transition du leadership avec une configuration impure entraîne une perte de données importante</font></i> <br><br>  Nous n'avons pas pu définir l'option <i>unclean.leader.election.enable</i> sur <i>true</i> .  Par défaut, c'est <i>faux</i> .  La définition de <i>acks = all</i> avec <i>unclean.leader.election.enable = true</i> offre une accessibilité avec une sécurité supplémentaire des données.  Mais, comme vous pouvez le voir, nous pouvons encore perdre des messages. <br><br>  Mais que faire si nous voulons augmenter la sécurité des données?  Vous pouvez définir <i>unclean.leader.election.enable = false</i> , mais cela ne nous protège pas nécessairement contre la perte de données.  Si le chef est tombé fort et a pris les données avec lui, les messages sont toujours perdus, et l'accessibilité est perdue jusqu'à ce que l'administrateur récupère la situation. <br><br>  Il vaut mieux garantir la redondance de tous les messages, et sinon refuser d'enregistrer.  Ensuite, du moins du point de vue du courtier, la perte de données n'est possible qu'avec deux ou plusieurs défaillances simultanées. <br><br><h3>  Acks = all, min.insync.replicas et ISR </h3><br>  Avec la <i>configuration de</i> rubrique <i>min.insync.replicas,</i> nous <i>augmentons</i> la sécurité des données.  Reprenons la dernière partie du dernier scénario, mais cette fois avec <i>min.insync.replicas = 2</i> . <br><br>  Ainsi, le courtier 2 a une réplique leader et le suiveur du courtier 3 est supprimé de l'ISR. <br><br><img src="https://habrastorage.org/webt/5g/ij/ls/5gijlstkvqxo4ojr6wfxxwn719m.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">19. ISR de deux répliques</font></i> <br><br>  Le courtier 2 tombe et le leadership passe au courtier 1 sans perdre de messages.  Mais maintenant ISR se compose d'une seule réplique.  Cela ne correspond pas au nombre minimum pour recevoir des enregistrements, et par conséquent le courtier répond à la tentative d'enregistrement avec l'erreur <i>NotEnoughReplicas</i> . <br><br><img src="https://habrastorage.org/webt/ng/p5/fj/ngp5fjym6nvykpohj8brnl8bvxc.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">20. Le nombre d'ISR est inférieur de un à celui spécifié dans min.insync.replicas</font></i> <br><br>  Cette configuration sacrifie la disponibilité pour la cohérence.  Avant de confirmer un message, nous garantissons qu'il est enregistré sur au moins deux répliques.  Cela donne au fabricant beaucoup plus de confiance.  Ici, la perte de message n'est possible que si deux répliques échouent simultanément dans un court intervalle, jusqu'à ce que le message soit répliqué sur un suiveur supplémentaire, ce qui est peu probable.  Mais si vous êtes un superparanoïde, vous pouvez définir le taux de réplication à 5, et <i>min.insync.replicas</i> à 3. Ensuite, trois courtiers à la fois doivent tomber en même temps afin de perdre le record!  Bien sûr, pour une telle fiabilité, vous paierez un délai supplémentaire. <br><br><h1>  Lorsque l'accessibilité est nécessaire pour la sécurité des données </h1><br>  Comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">avec RabbitMQ</a> , parfois l'accessibilité est nécessaire pour la sécurité des données.  Vous devez y penser: <br><br><ul><li>  Un éditeur peut-il simplement renvoyer une erreur et un service ou un utilisateur supérieur peut-il réessayer plus tard? <br></li><li>  Un éditeur peut-il enregistrer un message localement ou dans une base de données pour réessayer plus tard? </li></ul><br>  Si la réponse est non, l'optimisation de l'accessibilité améliore la sécurité des données.  Vous perdrez moins de données si vous choisissez la disponibilité au lieu de supprimer l'enregistrement.  Ainsi, tout se résume à trouver un équilibre, et la décision dépend de la situation spécifique. <br><br><h1>  La signification de l'ISR </h1><br>  La suite ISR vous permet de choisir l'équilibre optimal entre la sécurité des données et la latence.  Par exemple, pour garantir que la plupart des répliques sont accessibles en cas de panne, en minimisant l'impact des répliques mortes ou lentes en termes de retard. <br><br>  Nous choisissons nous-mêmes la valeur de <i>replica.lag.time.max.ms</i> en fonction de nos besoins.  En substance, ce paramètre signifie quel retard nous sommes prêts à accepter avec <i>acks = all</i> .  La valeur par défaut est de dix secondes.  Si c'est trop long pour vous, vous pouvez le réduire.  Ensuite, la fréquence des changements dans l'ISR augmentera, car les abonnés seront plus souvent supprimés et ajoutés. <br><br>  RabbitMQ n'est qu'une collection de miroirs qui doivent être répliqués.  Les miroirs lents introduisent un délai supplémentaire, et la réponse des miroirs morts peut être attendue avant l'expiration des paquets qui vérifient la disponibilité de chaque nœud (net tick).  Les ISR sont un moyen intéressant d'éviter ces problèmes avec une latence accrue.  Mais nous risquons de perdre la redondance, car l'ISR ne peut être réduit qu'à un leader.  Pour éviter ce risque, utilisez le paramètre <i>min.insync.replicas</i> . <br><br><h1>  Garantie de connectivité client </h1><br>  Dans les paramètres <i>bootstrap.servers</i> du fabricant et du consommateur, vous pouvez spécifier plusieurs courtiers pour connecter les clients.  L'idée est que lorsque vous déconnectez un nœud, il existe plusieurs nœuds de rechange avec lesquels le client peut ouvrir une connexion.  Ce ne sont pas nécessairement des chefs de section, mais simplement un tremplin pour le bootstrap.  Le client peut leur demander sur quel nœud se trouve le leader de la section lecture / écriture. <br><br>  Dans RabbitMQ, les clients peuvent se connecter à n'importe quel hôte et le routage interne envoie une demande si nécessaire.  Cela signifie que vous pouvez installer un équilibreur de charge devant RabbitMQ.  Kafka exige que les clients se connectent à l'hôte hébergeant le leader de la partition correspondante.  Dans cette situation, l'équilibreur de charge ne livre pas.  La liste <i>bootstrap.servers</i> est critique pour que les clients puissent accéder aux noeuds appropriés et les trouver après un plantage. <br><br><h1>  Architecture de consensus de Kafka </h1><br>  Jusqu'à présent, nous n'avons pas examiné comment le cluster apprend la chute du courtier et comment un nouveau leader est choisi.  Pour comprendre comment Kafka fonctionne avec les partitions réseau, vous devez d'abord comprendre l'architecture de consensus. <br><br>  Chaque cluster Kafka est déployé avec le cluster Zookeeper - c'est un service de consensus distribué qui permet au système de parvenir à un consensus sur un état donné avec la priorité sur la cohérence par rapport à la disponibilité.  L'approbation des opérations de lecture et d'écriture nécessite le consentement de la plupart des nœuds Zookeeper. <br><br>  Zookeeper stocke le statut du cluster: <br><br><ul><li>  Liste des sujets, des sections, de la configuration, des répliques actuelles des leaders, des répliques préférées. <br></li><li>  Membres du cluster.  Chaque courtier envoie un ping dans un cluster Zookeeper.  S'il ne reçoit pas de ping pendant une période donnée, alors Zookeeper écrit le courtier inaccessible. <br></li><li>  Le choix des nœuds primaires et secondaires pour le contrôleur. </li></ul><br>  Le nœud du contrôleur est l'un des courtiers Kafka qui est responsable de l'élection des chefs de réplique.  Zookeeper envoie au contrôleur des notifications d'appartenance à un cluster et de modifications de sujet, et le contrôleur doit agir conformément à ces changements. <br><br>  Par exemple, prenez un nouveau sujet avec dix sections et un coefficient de réplication de 3. Le contrôleur doit sélectionner le leader de chaque section, en essayant de répartir de manière optimale les leaders entre les courtiers. <br><br>  Pour chaque section, le contrôleur: <br><br><ul><li>  met à jour les informations dans Zookeeper sur ISR et le leader; <br></li><li>  envoie une commande LeaderAndISRCommand à chaque courtier qui publie une réplique de cette section, informant les courtiers de l'ISR et du leader. </li></ul><br>  Lorsqu'un courtier avec un chef tombe, Zookeeper envoie une notification au contrôleur, et il sélectionne un nouveau chef.  Encore une fois, le contrôleur met d'abord à jour Zookeeper, puis envoie une commande à chaque courtier, les informant d'un changement de leadership. <br><br>  Chaque leader est responsable du recrutement des ISR.  Le <i>paramètre replica.lag.time.max.ms</i> détermine qui y ira.  Lorsque l'ISR change, le leader transmet les nouvelles informations à Zookeeper. <br><br>  Zookeeper est toujours informé de tout changement, de sorte qu'en cas d'échec, la direction se déplace en douceur vers le nouveau leader. <br><br><img src="https://habrastorage.org/webt/yi/1v/in/yi1vinwmeg4exdiautqohweg8rq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">21. Consensus Kafka</font></i> <br><br><h1>  Protocole de réplication </h1><br>  La compréhension des détails de la réplication vous aide à mieux comprendre les scénarios de perte de données potentiels. <br><br><h3>  Exemples de demandes, décalage de fin de journal (LEO) et Highwater Mark (HW) </h3><br>  Nous avons considéré que les abonnés envoient périodiquement des demandes de récupération au leader.  L'intervalle par défaut est de 500 ms.  Cela diffère de RabbitMQ en ce que dans RabbitMQ, la réplication est lancée non pas par le miroir de file d'attente, mais par l'assistant.  Le maître pousse les modifications aux miroirs. <br><br>  Le leader et tous les suiveurs conservent le label Log End Offset (LEO) et Highwater (HW).  La marque LEO stocke le décalage du dernier message dans la réplique locale et HW stocke le décalage du dernier commit.  N'oubliez pas que pour le statut de validation, le message doit être enregistré dans toutes les répliques ISR.  Cela signifie que LEO est généralement légèrement en avance sur HW. <br><br>  Lorsqu'un leader reçoit un message, il l'enregistre localement.  Le suiveur fait une demande de récupération, passant son LEO.  Le leader envoie ensuite un paquet de messages commençant par ce LEO, et transmet également le matériel actuel.  Lorsque le leader reçoit des informations indiquant que toutes les répliques ont enregistré le message à un décalage donné, il déplace la marque HW.  Seul le leader peut déplacer le matériel, et ainsi tous les suiveurs connaîtront la valeur actuelle dans les réponses à leur demande.  Cela signifie que les suiveurs peuvent être à la traîne du leader en matière de reporting et de connaissance des matériels.  Les consommateurs ne reçoivent des messages que jusqu'au HW actuel. <br><br>  Notez que «persistant» signifie écrit dans la mémoire, pas sur le disque.  Pour des performances, Kafka se synchronise sur le disque à un intervalle spécifié.  RabbitMQ a également un tel intervalle, mais il n'enverra la confirmation à l'éditeur qu'après que le maître et tous les miroirs auront écrit le message sur le disque.  Pour des raisons de performances, les développeurs de Kafka ont décidé d'envoyer un accusé de réception dès que le message est écrit en mémoire.  Kafka s'appuie sur le fait que la redondance compense le risque de stockage à court terme des messages confirmés uniquement en mémoire. <br><br><h1>  Échec du leader </h1><br>  Lorsqu'un chef tombe, Zookeeper avertit le contrôleur et il sélectionne une nouvelle réplique de chef.  Le nouveau leader établit une nouvelle marque HW en ligne avec son LEO.  Ensuite, les abonnés reçoivent des informations sur le nouveau leader.  Selon la version de Kafka, le suiveur choisira l'un des deux scénarios: <br><br><ol><li>  Tronque le journal local au célèbre HW et envoie un message au nouveau leader après cette marque. <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il enverra une demande au chef pour connaître HW au moment de son élection en tant que chef, puis tronquer le journal à ce décalage. </font><font style="vertical-align: inherit;">Ensuite, il commencera à faire des demandes d'échantillonnage périodiques, à partir de ce décalage.</font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Le suiveur peut avoir besoin de couper le journal pour les raisons suivantes: </font></font><br><br><ul><li>    ,     ISR,   Zookeeper,     .    ISR,    «»,          .  ,        . Kafka ,     .  ,   ,         HW      .    ,   <i>acks=all</i>    . <br></li><li>     .      ,        .  ,       ,  ,   ,    ,        . </li></ul><br><h3>  c  </h3><br>        ,     :          HW (  ).  , RabbitMQ       .        .    ,             «    ».            .       . <br><br> Kafka —   ,       ,   RabbitMQ,        .      .  Kafka —      ,        .            .    Kafka      HW  (   )   ,     .    ,    ,       ,     LEO. <br><br>        ISR     .      ,    ,  ,         ISR.          . <br><br><h1>   </h1><br>  Kafka  ,   RabbitMQ,      ,     .  Kafka    ,      . <br><br>      : <br><br><ul><li>  1.    ,     Zookeeper. <br></li><li>  2.      ,     Zookeeper. <br></li><li>  3.   ,    Zookeeper. <br></li><li>  4.   ,    Zookeeper. <br></li><li>  5.        Kafka,   Zookeeper. <br></li><li>  6.        Kafka,   Zookeeper. <br></li><li>  7.   Kafka     Kafka. <br></li><li>  8.  Kafka   Zookeeper. </li></ul><br>      . <br><br><h3>  1.    ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/je/cd/f1/jecdf1kc9y8gc8ej5sfmuelo30a.png"><br> <i><font color="gray">. 22.  1. ISR   </font></i> <br><br>     3   1  2,    Zookeeper.  3       .    <i>replica.lag.time.max.ms</i>    ISR      .    ,         ISR,   . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/ir/tq/ir/irtqir6cr8whigmvfqo1t-bbsso.png"><br> <i><font color="gray">. 23.  1.    ISR,            replica.lag.time.max.ms</font></i> <br><br>     (split-brain)   ,   RabbitMQ.    . <br><br><h3>  2.      ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/ri/fy/q6/rifyq652am8lmbhlgpfvfq-pjnm.png"><br> <i><font color="gray">. 24.  2.    </font></i> <br><br>       ,      Zookeeper.     , ISR ,       ,        .  ,    .        ,    . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/hj/8g/-1/hj8g-1veu8rkisccp7t6c9bxq7k.png"><br> <i><font color="gray">. 25.  2. ISR    </font></i> <br><br><h3>  3.   ,    Zookeeper </h3><br>    Zookeeper,      .           ISR. Zookeeper        ,     ,     . <br><br><img src="https://habrastorage.org/webt/cv/tb/gj/cvtbgjgw7ub1w8dmii46aql3bhc.png"><br> <i><font color="gray">. 26.  3.       </font></i> <br><br><h3>  4.   ,    Zookeeper </h3><br><img src="https://habrastorage.org/webt/zw/k4/8o/zwk48obscffldqgdhpyl0dvvipc.png"><br> <i><font color="gray">. 27.  4.    </font></i> <br><br>    Zookeeper,      . <br><br><img src="https://habrastorage.org/webt/eh/s1/hx/ehs1hxu4sako2udflhmhhbqhtsu.png"><br> <i><font color="gray">. 28.  4.    Zookeeper</font></i> <br><br>    Zookeeper        .      .      ,           <i>acks=1</i> .        ,         ISR   .        Zookeeper,     ,         . <br><br>  <i>acks=all</i>   ,    ISR   ,      .        ISR,          - . <br><br>            .    ,   ,     ,       HW,        ,    .         .     ,    .     ,        ,    . <br><br><img src="https://habrastorage.org/webt/pt/z_/pn/ptz_pnhoyrwvw4v-l9re3ffjzcg.png"><br> <i><font color="gray">. 29.  4.    1     </font></i> <br><br><h3>  5.        Kafka,   Zookeeper </h3><br>        Kafka,   Zookeeper.     ISR,    ,    . <br><br><img src="https://habrastorage.org/webt/ik/aj/a1/ikaja1i4z3fnodbcmam8sp2jbjc.png"><br> <i><font color="gray">. 30.  5.     ISR</font></i> <br><br><h3>  6.        Kafka,   Zookeeper </h3><br><img src="https://habrastorage.org/webt/cz/5h/2m/cz5h2mnqelpalxozp-jv4yv23rc.png"><br> <i><font color="gray">. 31.  6.    </font></i> <br><br>      ,   Zookeeper.          <i>acks=1</i> . <br><br><img src="https://habrastorage.org/webt/pj/pi/vj/pjpivjf1bsnvowntmkjqxdzipfe.png"><br> <i><font color="gray">. 32.  6.      Kafka  Zookeeper</font></i> <br><br>      <i>replica.lag.time.max.ms</i> ,    ISR   ,     ,     Zookeeper,     . <br><br>  , Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/g8/rg/wo/g8rgwol3elzkz8dwxojtclogyns.png"><br> <i><font color="gray">. 33.  6.  </font></i> <br><br>         ,      .    60    .            . <br><br><img src="https://habrastorage.org/webt/zu/zl/dh/zuzldhf62qbynz_voxil-25roxe.png"><br> <i><font color="gray">. 34.  6.     </font></i> <br><br>     ,       .    ,    Zookeeper ,     .      HW           . <br><br><img src="https://habrastorage.org/webt/zj/5e/vd/zj5evdyqhphl9uupogfvbjx7zjk.png"><br> <i><font color="gray">. 35.  6.        </font></i> <br><br>           ,    <i>acks=1</i>  <i>min.insync.replicas</i>  1.        ,    ,     ,     ,         —    ,   .       ,    <i>acks=1</i> . <br><br>     ,       ,    ISR   .    -  .   ,      ,  <i>acks=all</i> ,    ISR    .       .      — <i>min.insync.replicas = 2</i> . <br><br><h3>  7.   Kafka     Kafka </h3><br>  ,      Kafka          .         ,    6.             . <br><br><h3>  8.  Kafka   Zookeeper </h3><br>    Zookeeper         Kafka.       ,       Zookeeper,         .    ,  ,     ,     Kafka. <br><br><h3>    </h3><br>  ,         ,     ,    . , ,     ,      . <br><br>  -      Zookeeper,        <i>acks=1</i> .    Zookeeper       .     <i>acks=all</i> . <br><br>  <i>min.insync.replicas</i>        ,         ,    6. <br><br><h1>     </h1><br>   ,      Kafka: <br><br><ul><li>   ,      <i>acks=1</i> <br></li><li>   (unclean)  ,       ISR,   <i>acks=all</i> <br></li><li>    Zookeeper,      <i>acks=1</i> <br></li><li>   ,     ISR   .    ,  <i>acks=all</i> .      ,  <i>min.insync.replicas=1</i> . <br></li><li>     .     ,       .        . </li></ul><br>     ,   ,      .    —   <i>acks=all</i>  <i>min.insync.replicas</i>  1. <br><br><h1>    RabbitMQ  Kafka </h1><br>              .   RabbitMQ   .        ,   .           RabbitMQ.       ,    .       .    ,         ( )       . <br><br>  Kafka   .          .    .  ,    .    ,     ,           . , -  ,       .     ,      . <br><br> RabbitMQ  Kafka         .    , RabbitMQ              .        : <br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fsync toutes les quelques centaines de millisecondes </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les miroirs ne peuvent être détectés qu'après la durée de vie des paquets qui vérifient la disponibilité de chaque nœud (net tick). </font><font style="vertical-align: inherit;">Si le miroir ralentit ou tombe, cela ajoute un délai.</font></font></li></ul><br>  Kafka s'appuie sur le fait que si le message est stocké sur plusieurs nœuds, vous pouvez confirmer les messages dès qu'ils sont en mémoire.  De ce fait, il y a un risque de perdre des messages de tout type (même <i>acks = all</i> , <i>min.insync.replies = 2</i> ) en cas de panne simultanée. <br><br>  Dans l'ensemble, Kafka présente de meilleures performances et a été initialement conçu pour les clusters.  Le nombre d'adeptes peut être porté à 11, si nécessaire pour des raisons de fiabilité.  Un facteur de réplication de 5 et un nombre minimum de répliques dans un état synchronisé de <i>min.insync.replicas = 3</i> feront de la perte de message un événement très rare.  Si votre infrastructure est capable de fournir un tel taux de réplication et un niveau de redondance, vous pouvez choisir cette option. <br><br>  Le clustering RabbitMQ est bon pour les petites files d'attente.  Mais même les petites files d'attente peuvent augmenter rapidement avec un trafic élevé.  Une fois les files d'attente devenues volumineuses, vous devrez faire un choix difficile entre disponibilité et fiabilité.  Le clustering RabbitMQ est le mieux adapté aux situations non typiques où les avantages de la flexibilité de RabbitMQ l'emportent sur les inconvénients du clustering. <br><br>  L'un des antidotes à la grande vulnérabilité de file d'attente de RabbitMQ est de les décomposer en de nombreux plus petits.  Si vous n'avez pas besoin d'un ordre complet de toute la file d'attente, mais uniquement des messages pertinents (par exemple, les messages d'un client spécifique), ou rien du tout, alors cette option est acceptable: regardez mon projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Rebalanser</a> pour fractionner la file d'attente (le projet est encore à un stade précoce). <br><br>  Enfin, n'oubliez pas un certain nombre de bogues dans les mécanismes de clustering et de réplication de RabbitMQ et de Kafka.  Au fil du temps, les systèmes sont devenus plus matures et stables, mais aucun message ne sera jamais protégé à 100% contre les pertes!  De plus, des accidents à grande échelle se produisent dans les centres de données! <br><br>  Si j'ai raté quelque chose, fait une erreur ou si vous n'êtes d'accord avec aucun des points, n'hésitez pas à écrire un commentaire ou à me contacter. <br><br>  Les gens me demandent souvent: «Que choisir, Kafka ou RabbitMQ?», «Quelle plateforme est la meilleure?».  La vérité est que cela dépend vraiment de votre situation, de votre expérience actuelle, etc. Je n'ose pas exprimer mon opinion, car ce sera trop de simplification de recommander une plate-forme unique pour tous les cas d'utilisation et les limitations possibles.  J'ai écrit cette série d'articles pour que vous puissiez vous faire votre propre opinion. <br><br>  Je tiens à dire que les deux systèmes sont des chefs de file dans ce domaine.  Je suis peut-être un peu biaisé, car à partir de l'expérience de mes projets, je suis plus enclin à apprécier des choses comme la garantie de l'ordre des messages et la fiabilité. <br><br>  Je vois d'autres technologies qui manquent de fiabilité et de commande garantie, puis je regarde RabbitMQ et Kafka - et je comprends la valeur incroyable de ces deux systèmes. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr474984/">https://habr.com/ru/post/fr474984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr474968/index.html">RxDart pour les plus petits ... projets</a></li>
<li><a href="../fr474970/index.html">Comment écrire un contrat intelligent avec Python sur l'ontologie? Partie 5: API native</a></li>
<li><a href="../fr474976/index.html">Boating City: comment Venise existe sans voitures</a></li>
<li><a href="../fr474978/index.html">IBM Watson Visual Recognition: la reconnaissance d'objets désormais disponible dans IBM Cloud</a></li>
<li><a href="../fr474982/index.html">Tutoriel JavaFX: FXML et SceneBuilder</a></li>
<li><a href="../fr474988/index.html">Bienvenue chez Mitap: Carrières chez Data Science pour débutants</a></li>
<li><a href="../fr474990/index.html">Pratique: comment créer un réseau Wi-Fi dans un parc de la ville</a></li>
<li><a href="../fr474992/index.html">Analyse des batteries d'ordinateurs portables défectueuses. Notes de motard électrique</a></li>
<li><a href="../fr474994/index.html">Comment couper un monolithe en services et maintenir les performances des caches en mémoire sans perdre en cohérence</a></li>
<li><a href="../fr474996/index.html">Le résumé des événements informatiques de novembre (deuxième partie)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî¶ üòé ü§∂üèæ RabbitMQ contre Kafka: basculement et haute disponibilit√© üÖæÔ∏è üéÖüèø ‚úãüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans un article pr√©c√©dent, nous avons examin√© le clustering RabbitMQ pour la tol√©rance aux pannes et la haute disponibilit√©. Maintenant, approfondisso...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ contre Kafka: basculement et haute disponibilit√©</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/474984/"><img src="https://habrastorage.org/webt/rc/zb/n7/rczbn7bwtp8b5day0whi_wace2e.jpeg"><br><br>  Dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article pr√©c√©dent,</a> nous avons examin√© le clustering RabbitMQ pour la tol√©rance aux pannes et la haute disponibilit√©.  Maintenant, approfondissons Apache Kafka. <br><br>  Ici, l'unit√© de r√©plication est une partition.  Chaque sujet comporte une ou plusieurs sections.  Chaque section a un leader avec ou sans abonn√©s.  Lors de la cr√©ation d'un sujet, le nombre de partitions et le taux de r√©plication sont indiqu√©s.  La valeur habituelle est 3, ce qui signifie trois remarques: un leader et deux suiveurs. <br><a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/ly/hd/ml/lyhdmlstwyv-tf_-ts54gife3cw.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Quatre sections sont r√©parties entre trois courtiers</font></i> <br><br>  Toutes les demandes de lecture et d'√©criture sont transmises au responsable.  Les suiveurs envoient p√©riodiquement des demandes au leader pour recevoir les derniers messages.  Les consommateurs ne se tournent jamais vers les followers, ces derniers n'existent que pour la redondance et la tol√©rance aux pannes. <br><br><img src="https://habrastorage.org/webt/sb/fc/v0/sbfcv0j3mosfzvrb7qktoexl_lg.png"><br><br><h1>  √âchec de la section </h1><br>  Lorsqu'un courtier tombe, les dirigeants de plusieurs sections √©chouent souvent.  Dans chacun d'eux, le suiveur d'un autre n≈ìud devient le leader.  En fait, ce n'est pas toujours le cas, car le facteur de synchronisation affecte √©galement: s'il y a des suiveurs synchronis√©s, et sinon, la transition vers une r√©plique non synchronis√©e est-elle autoris√©e.  Mais pour l'instant, ne compliquons pas les choses. <br><br>  Le courtier 3 quitte le r√©seau - et pour la section 2, un nouveau leader sur le courtier 2 est √©lu. <br><br><img src="https://habrastorage.org/webt/im/ct/r0/imctr0qotjsjg4_jx3g6p5otk9u.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. Le courtier 3 d√©c√®de et son disciple du courtier 2 est √©lu nouveau chef de la section 2</font></i> <br><br>  Ensuite, le courtier 1 quitte et la section 1 perd √©galement son chef, dont le r√¥le revient au courtier 2. <br><br><img src="https://habrastorage.org/webt/rg/fo/zp/rgfozpk7b_t1odoxso1mvihmccu.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">3. Il ne reste qu'un courtier.</font></i>  <i><font color="gray">Tous les dirigeants sont sur le m√™me courtier √† redondance z√©ro.</font></i> <br><br>  Lorsque le courtier 1 revient sur le r√©seau, il ajoute quatre abonn√©s, fournissant une certaine redondance √† chaque section.  Mais tous les leaders sont rest√©s sur le broker 2. <br><br><img src="https://habrastorage.org/webt/mh/lj/2s/mhlj2sn5r6rcjodqnl22450bjn8.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">4. Les dirigeants restent sur le courtier 2</font></i> <br><br>  Lorsque le courtier 3 monte, nous revenons √† trois r√©pliques par section.  Mais tous les leaders sont toujours sur le broker 2. <br><br><img src="https://habrastorage.org/webt/3u/tb/op/3utbopk0awdg8rg62natyoxqg9o.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">5. Placement d√©s√©quilibr√© des dirigeants apr√®s la restauration des courtiers 1 et 3</font></i> <br><br>  Kafka a un outil pour mieux r√©√©quilibrer les dirigeants que RabbitMQ.  L√†, vous avez d√ª utiliser un plug-in ou un script tiers qui a modifi√© les politiques de migration du n≈ìud principal en r√©duisant la redondance lors de la migration.  De plus, pour les grandes files d'attente, il fallait supporter l'inaccessibilit√© lors de la synchronisation. <br><br>  Kafka a un concept de ¬´rep√®res pr√©f√©r√©s¬ª pour le r√¥le de leadership.  Lorsque les sections de sujet sont cr√©√©es, Kafka essaie de r√©partir uniform√©ment les leaders sur les n≈ìuds et marque ces premiers leaders comme pr√©f√©r√©s.  Au fil du temps, en raison des red√©marrages du serveur, des √©checs et des √©checs de connectivit√©, les leaders peuvent se retrouver sur d'autres n≈ìuds, comme dans le cas extr√™me d√©crit ci-dessus. <br><br>  Pour r√©soudre ce probl√®me, Kafka propose deux options: <br><br><ul><li>  L'option <i>auto.leader.rebalance.enable = true</i> permet au n≈ìud du contr√¥leur de r√©affecter automatiquement les leaders aux r√©pliques pr√©f√©r√©es et de restaurer ainsi une distribution uniforme. <br></li><li>  Un administrateur peut ex√©cuter le script <i>kafka-preferred-replica-election.sh</i> pour r√©affecter manuellement. </li></ul><br><br><img src="https://habrastorage.org/webt/qt/2l/th/qt2lth99rb1fhzq8g4r93uoxh6k.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">6. R√©pliques apr√®s r√©√©quilibrage</font></i> <br><br>  C'√©tait une version simplifi√©e de l'√©chec, mais la r√©alit√© est plus complexe, bien qu'il n'y ait rien de trop compliqu√© ici.  Tout se r√©sume √† des r√©pliques synchronis√©es (r√©pliques In-Sync, ISR). <br><br><h1>  R√©pliques synchronis√©es (ISR) </h1><br>  ISR est un ensemble de r√©pliques d'une partition qui est consid√©r√©e comme ¬´synchronis√©e¬ª (en synchronisation).  Il y a un leader, mais il peut ne pas y avoir de followers.  Un suiveur est consid√©r√© comme synchronis√© s'il a fait des copies exactes de tous les messages de leader avant l'expiration de l'intervalle <i>replica.lag.time.max.ms</i> . <br><br>  Le suiveur est supprim√© de l'ensemble ISR s'il: <br><br><ul><li>  n'a pas fait de demande d'√©chantillonnage pour l'intervalle <i>replica.lag.time.max.ms</i> (consid√©r√© comme mort) <br></li><li>  n'a pas eu le temps de mettre √† jour pour l'intervalle <i>replica.lag.time.max.ms</i> (consid√©r√© comme lent) </li></ul><br>  Les suiveurs font des demandes de r√©cup√©ration dans l'intervalle <i>replica.fetch.wait.max.ms</i> , qui par d√©faut est de 500 ms. <br><br>  Pour expliquer clairement l'objectif de l'ISR, vous devez consulter les confirmations du producteur (producteur) et certains sc√©narios de d√©faillance.  Les producteurs peuvent choisir quand un courtier envoie une confirmation: <br><br><ul><li>  acks = 0, la confirmation n'est pas envoy√©e <br></li><li>  acks = 1, la confirmation est envoy√©e apr√®s que le leader a √©crit un message dans son journal local <br></li><li>  acks = all, une confirmation est envoy√©e apr√®s que toutes les r√©pliques du ISR ont √©crit un message dans les journaux locaux </li></ul><br>  Dans la terminologie de Kafka, si l'ISR a enregistr√© le message, il est ¬´engag√©¬ª.  Acks = all est l'option la plus s√ªre, mais aussi un d√©lai suppl√©mentaire.  Examinons deux exemples d'√©chec et comment les diff√©rentes options ¬´acks¬ª interagissent avec le concept ISR. <br><br><h3>  Acks = 1 et ISR </h3><br>  Dans cet exemple, nous verrons que si le leader n'attend pas que chaque message de tous les abonn√©s soit enregistr√©, alors si le leader √©choue, les donn√©es peuvent √™tre perdues.  Aller √† un abonn√© non synchronis√© peut √™tre activ√© ou d√©sactiv√© en d√©finissant <i>unclean.leader.election.enable</i> . <br><br>  Dans cet exemple, le fabricant est d√©fini sur acks = 1.  La section est r√©partie entre les trois courtiers.  Broker 3 est derri√®re, il s'est synchronis√© avec le leader il y a huit secondes et est maintenant derri√®re par 7456 messages.  Le courtier 1 n'a qu'une seconde de retard.  Notre producteur envoie un message et re√ßoit rapidement un accus√© de r√©ception, sans frais g√©n√©raux pour les adeptes lents ou morts auxquels le leader ne s'attend pas. <br><br><img src="https://habrastorage.org/webt/ej/bh/g7/ejbhg7svgcphrhpdtzbwuw--wg4.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">7. ISR avec trois r√©pliques</font></i> <br><br>  Le courtier 2 √©choue et le fabricant re√ßoit une erreur de connexion.  Apr√®s la transition du leadership vers le courtier 1, nous perdons 123 messages.  Le suiveur du courtier 1 faisait partie de l'ISR, mais ne s'est pas compl√®tement synchronis√© avec le leader lors de sa chute. <br><br><img src="https://habrastorage.org/webt/6y/th/y9/6ythy9olfa5zr2wyqtfqcrq8u5e.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">8. En cas d'√©chec, les messages sont perdus</font></i> <br><br>  Dans la configuration <i>bootstrap.servers</i> , le fabricant r√©pertorie plusieurs courtiers, et il peut demander √† un autre courtier qui est devenu le nouveau leader de la section.  Il √©tablit ensuite une connexion avec le courtier 1 et continue d'envoyer des messages. <br><br><img src="https://habrastorage.org/webt/br/o6/jr/bro6jrn5nt-a0wzvg_yt0csmdgg.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">9. L'envoi de messages reprend apr√®s une courte pause</font></i> <br><br>  Le courtier 3 tra√Æne encore plus loin.  Il effectue des requ√™tes de r√©cup√©ration, mais ne peut pas se synchroniser.  Cela peut √™tre d√ª √† une connexion r√©seau lente entre les courtiers, un probl√®me de stockage, etc. Il est supprim√© de l'ISR.  D√©sormais, l'ISR se compose d'une seule r√©plique - le leader!  Le fabricant continue d'envoyer des messages et de recevoir une confirmation. <br><br><img src="https://habrastorage.org/webt/b2/qj/aj/b2qjaj5g_yx2wfb-jdkalxr9074.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">10. Le suiveur du courtier 3 est supprim√© de l'ISR</font></i> <br><br>  Le courtier 1 tombe et le r√¥le du leader revient au courtier 3 avec la perte de 15286 messages!  Le fabricant re√ßoit un message d'erreur de connexion.  Aller au leader en dehors de l'ISR n'√©tait possible qu'en raison du param√®tre <i>unclean.leader.election.enable = true</i> .  S'il est d√©fini sur <i>false</i> , la transition ne se serait pas produite et toutes les demandes de lecture et d'√©criture seraient rejet√©es.  Dans ce cas, nous attendons le retour du courtier 1 avec ses donn√©es intactes dans la r√©plique, qui reprendra la t√™te. <br><br><img src="https://habrastorage.org/webt/rr/n1/-n/rrn1-nekmhjtro9pxeueciytb50.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">11. Le courtier 1 tombe.</font></i>  <i><font color="gray">En cas d'√©chec, un grand nombre de messages sont perdus</font></i> <br><br>  Le constructeur √©tablit une connexion avec le dernier courtier et constate qu'il est d√©sormais le leader de la section.  Il commence √† envoyer des messages au courtier 3. <br><br><img src="https://habrastorage.org/webt/qj/qq/go/qjqqgoevfafcmcxtidd_bvjw9wi.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">12. Apr√®s une courte pause, les messages sont √† nouveau envoy√©s √† la section 0</font></i> <br><br>  Nous avons vu qu'en plus de br√®ves interruptions pour √©tablir de nouvelles connexions et rechercher un nouveau leader, le fabricant envoyait constamment des messages.  Cette configuration assure l'accessibilit√© gr√¢ce √† la coh√©rence (s√©curit√© des donn√©es).  Kafka a perdu des milliers de messages, mais a continu√© d'accepter de nouvelles entr√©es. <br><br><h3>  Acks = all et ISR </h3><br>  R√©p√©tons √† nouveau ce sc√©nario, mais avec <i>acks = all</i> .  Retarder le courtier 3 en moyenne quatre secondes.  Le fabricant envoie un message avec <i>acks = all</i> et ne re√ßoit plus de r√©ponse rapide.  Le leader attend que tous les messages de l'ISR stockent le message. <br><br><img src="https://habrastorage.org/webt/3c/6j/a5/3c6ja5msoncfx1s-xbyjpmujtdo.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">13. ISR avec trois r√©pliques.</font></i>  <i><font color="gray">L'un est lent, entra√Ænant un retard d'enregistrement</font></i> <br><br>  Apr√®s quatre secondes de d√©lai suppl√©mentaire, le courtier 2 envoie un accus√© de r√©ception.  Toutes les r√©pliques sont d√©sormais enti√®rement mises √† jour. <br><br><img src="https://habrastorage.org/webt/ol/eg/y6/olegy6unibvup0tlza6cbd4gqic.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">14. Toutes les r√©pliques enregistrent les messages et un accus√© de r√©ception est envoy√©</font></i> <br><br>  Le courtier 3 est maintenant encore plus en retard et est en cours de retrait de l'ISR.  Le d√©lai est consid√©rablement r√©duit car il n'y a plus de r√©pliques lentes dans l'ISR.  Le courtier 2 n'attend plus que le courtier 1 et il a un d√©calage moyen de 500 ms. <br><br><img src="https://habrastorage.org/webt/ub/0e/7j/ub0e7jm1siaa9dvcmxyldti1ify.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">15. La r√©plique sur le courtier 3 est supprim√©e de l'ISR</font></i> <br><br>  Ensuite, le courtier 2 tombe et le leadership passe au courtier 1 sans perdre de messages. <br><br><img src="https://habrastorage.org/webt/a7/ts/8m/a7ts8mywsvuowiof5jp6f6eszlq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">16. Le courtier 2 tombe</font></i> <br><br>  Le constructeur trouve un nouveau leader et commence √† lui envoyer des messages.  Le d√©lai est toujours r√©duit, car maintenant l'ISR se compose d'une seule r√©plique!  Par cons√©quent, l'option <i>acks = all</i> n'ajoute pas de redondance. <br><br><img src="https://habrastorage.org/webt/-z/i_/od/-zi_odb0nc-nf0xe1tsxmzlr-uq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">17. La r√©plique sur le courtier 1 prend les devants sans perdre les messages</font></i> <br><br>  Ensuite, le courtier 1 tombe et le leadership passe au courtier 3 avec la perte de 14 238 messages! <br><br><img src="https://habrastorage.org/webt/sr/x5/1m/srx51mjemyxnksoewy6n91_lgqy.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">18. Le courtier 1 meurt et la transition du leadership avec une configuration impure entra√Æne une perte de donn√©es importante</font></i> <br><br>  Nous n'avons pas pu d√©finir l'option <i>unclean.leader.election.enable</i> sur <i>true</i> .  Par d√©faut, c'est <i>faux</i> .  La d√©finition de <i>acks = all</i> avec <i>unclean.leader.election.enable = true</i> offre une accessibilit√© avec une s√©curit√© suppl√©mentaire des donn√©es.  Mais, comme vous pouvez le voir, nous pouvons encore perdre des messages. <br><br>  Mais que faire si nous voulons augmenter la s√©curit√© des donn√©es?  Vous pouvez d√©finir <i>unclean.leader.election.enable = false</i> , mais cela ne nous prot√®ge pas n√©cessairement contre la perte de donn√©es.  Si le chef est tomb√© fort et a pris les donn√©es avec lui, les messages sont toujours perdus, et l'accessibilit√© est perdue jusqu'√† ce que l'administrateur r√©cup√®re la situation. <br><br>  Il vaut mieux garantir la redondance de tous les messages, et sinon refuser d'enregistrer.  Ensuite, du moins du point de vue du courtier, la perte de donn√©es n'est possible qu'avec deux ou plusieurs d√©faillances simultan√©es. <br><br><h3>  Acks = all, min.insync.replicas et ISR </h3><br>  Avec la <i>configuration de</i> rubrique <i>min.insync.replicas,</i> nous <i>augmentons</i> la s√©curit√© des donn√©es.  Reprenons la derni√®re partie du dernier sc√©nario, mais cette fois avec <i>min.insync.replicas = 2</i> . <br><br>  Ainsi, le courtier 2 a une r√©plique leader et le suiveur du courtier 3 est supprim√© de l'ISR. <br><br><img src="https://habrastorage.org/webt/5g/ij/ls/5gijlstkvqxo4ojr6wfxxwn719m.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">19. ISR de deux r√©pliques</font></i> <br><br>  Le courtier 2 tombe et le leadership passe au courtier 1 sans perdre de messages.  Mais maintenant ISR se compose d'une seule r√©plique.  Cela ne correspond pas au nombre minimum pour recevoir des enregistrements, et par cons√©quent le courtier r√©pond √† la tentative d'enregistrement avec l'erreur <i>NotEnoughReplicas</i> . <br><br><img src="https://habrastorage.org/webt/ng/p5/fj/ngp5fjym6nvykpohj8brnl8bvxc.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">20. Le nombre d'ISR est inf√©rieur de un √† celui sp√©cifi√© dans min.insync.replicas</font></i> <br><br>  Cette configuration sacrifie la disponibilit√© pour la coh√©rence.  Avant de confirmer un message, nous garantissons qu'il est enregistr√© sur au moins deux r√©pliques.  Cela donne au fabricant beaucoup plus de confiance.  Ici, la perte de message n'est possible que si deux r√©pliques √©chouent simultan√©ment dans un court intervalle, jusqu'√† ce que le message soit r√©pliqu√© sur un suiveur suppl√©mentaire, ce qui est peu probable.  Mais si vous √™tes un superparano√Øde, vous pouvez d√©finir le taux de r√©plication √† 5, et <i>min.insync.replicas</i> √† 3. Ensuite, trois courtiers √† la fois doivent tomber en m√™me temps afin de perdre le record!  Bien s√ªr, pour une telle fiabilit√©, vous paierez un d√©lai suppl√©mentaire. <br><br><h1>  Lorsque l'accessibilit√© est n√©cessaire pour la s√©curit√© des donn√©es </h1><br>  Comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">avec RabbitMQ</a> , parfois l'accessibilit√© est n√©cessaire pour la s√©curit√© des donn√©es.  Vous devez y penser: <br><br><ul><li>  Un √©diteur peut-il simplement renvoyer une erreur et un service ou un utilisateur sup√©rieur peut-il r√©essayer plus tard? <br></li><li>  Un √©diteur peut-il enregistrer un message localement ou dans une base de donn√©es pour r√©essayer plus tard? </li></ul><br>  Si la r√©ponse est non, l'optimisation de l'accessibilit√© am√©liore la s√©curit√© des donn√©es.  Vous perdrez moins de donn√©es si vous choisissez la disponibilit√© au lieu de supprimer l'enregistrement.  Ainsi, tout se r√©sume √† trouver un √©quilibre, et la d√©cision d√©pend de la situation sp√©cifique. <br><br><h1>  La signification de l'ISR </h1><br>  La suite ISR vous permet de choisir l'√©quilibre optimal entre la s√©curit√© des donn√©es et la latence.  Par exemple, pour garantir que la plupart des r√©pliques sont accessibles en cas de panne, en minimisant l'impact des r√©pliques mortes ou lentes en termes de retard. <br><br>  Nous choisissons nous-m√™mes la valeur de <i>replica.lag.time.max.ms</i> en fonction de nos besoins.  En substance, ce param√®tre signifie quel retard nous sommes pr√™ts √† accepter avec <i>acks = all</i> .  La valeur par d√©faut est de dix secondes.  Si c'est trop long pour vous, vous pouvez le r√©duire.  Ensuite, la fr√©quence des changements dans l'ISR augmentera, car les abonn√©s seront plus souvent supprim√©s et ajout√©s. <br><br>  RabbitMQ n'est qu'une collection de miroirs qui doivent √™tre r√©pliqu√©s.  Les miroirs lents introduisent un d√©lai suppl√©mentaire, et la r√©ponse des miroirs morts peut √™tre attendue avant l'expiration des paquets qui v√©rifient la disponibilit√© de chaque n≈ìud (net tick).  Les ISR sont un moyen int√©ressant d'√©viter ces probl√®mes avec une latence accrue.  Mais nous risquons de perdre la redondance, car l'ISR ne peut √™tre r√©duit qu'√† un leader.  Pour √©viter ce risque, utilisez le param√®tre <i>min.insync.replicas</i> . <br><br><h1>  Garantie de connectivit√© client </h1><br>  Dans les param√®tres <i>bootstrap.servers</i> du fabricant et du consommateur, vous pouvez sp√©cifier plusieurs courtiers pour connecter les clients.  L'id√©e est que lorsque vous d√©connectez un n≈ìud, il existe plusieurs n≈ìuds de rechange avec lesquels le client peut ouvrir une connexion.  Ce ne sont pas n√©cessairement des chefs de section, mais simplement un tremplin pour le bootstrap.  Le client peut leur demander sur quel n≈ìud se trouve le leader de la section lecture / √©criture. <br><br>  Dans RabbitMQ, les clients peuvent se connecter √† n'importe quel h√¥te et le routage interne envoie une demande si n√©cessaire.  Cela signifie que vous pouvez installer un √©quilibreur de charge devant RabbitMQ.  Kafka exige que les clients se connectent √† l'h√¥te h√©bergeant le leader de la partition correspondante.  Dans cette situation, l'√©quilibreur de charge ne livre pas.  La liste <i>bootstrap.servers</i> est critique pour que les clients puissent acc√©der aux noeuds appropri√©s et les trouver apr√®s un plantage. <br><br><h1>  Architecture de consensus de Kafka </h1><br>  Jusqu'√† pr√©sent, nous n'avons pas examin√© comment le cluster apprend la chute du courtier et comment un nouveau leader est choisi.  Pour comprendre comment Kafka fonctionne avec les partitions r√©seau, vous devez d'abord comprendre l'architecture de consensus. <br><br>  Chaque cluster Kafka est d√©ploy√© avec le cluster Zookeeper - c'est un service de consensus distribu√© qui permet au syst√®me de parvenir √† un consensus sur un √©tat donn√© avec la priorit√© sur la coh√©rence par rapport √† la disponibilit√©.  L'approbation des op√©rations de lecture et d'√©criture n√©cessite le consentement de la plupart des n≈ìuds Zookeeper. <br><br>  Zookeeper stocke le statut du cluster: <br><br><ul><li>  Liste des sujets, des sections, de la configuration, des r√©pliques actuelles des leaders, des r√©pliques pr√©f√©r√©es. <br></li><li>  Membres du cluster.  Chaque courtier envoie un ping dans un cluster Zookeeper.  S'il ne re√ßoit pas de ping pendant une p√©riode donn√©e, alors Zookeeper √©crit le courtier inaccessible. <br></li><li>  Le choix des n≈ìuds primaires et secondaires pour le contr√¥leur. </li></ul><br>  Le n≈ìud du contr√¥leur est l'un des courtiers Kafka qui est responsable de l'√©lection des chefs de r√©plique.  Zookeeper envoie au contr√¥leur des notifications d'appartenance √† un cluster et de modifications de sujet, et le contr√¥leur doit agir conform√©ment √† ces changements. <br><br>  Par exemple, prenez un nouveau sujet avec dix sections et un coefficient de r√©plication de 3. Le contr√¥leur doit s√©lectionner le leader de chaque section, en essayant de r√©partir de mani√®re optimale les leaders entre les courtiers. <br><br>  Pour chaque section, le contr√¥leur: <br><br><ul><li>  met √† jour les informations dans Zookeeper sur ISR et le leader; <br></li><li>  envoie une commande LeaderAndISRCommand √† chaque courtier qui publie une r√©plique de cette section, informant les courtiers de l'ISR et du leader. </li></ul><br>  Lorsqu'un courtier avec un chef tombe, Zookeeper envoie une notification au contr√¥leur, et il s√©lectionne un nouveau chef.  Encore une fois, le contr√¥leur met d'abord √† jour Zookeeper, puis envoie une commande √† chaque courtier, les informant d'un changement de leadership. <br><br>  Chaque leader est responsable du recrutement des ISR.  Le <i>param√®tre replica.lag.time.max.ms</i> d√©termine qui y ira.  Lorsque l'ISR change, le leader transmet les nouvelles informations √† Zookeeper. <br><br>  Zookeeper est toujours inform√© de tout changement, de sorte qu'en cas d'√©chec, la direction se d√©place en douceur vers le nouveau leader. <br><br><img src="https://habrastorage.org/webt/yi/1v/in/yi1vinwmeg4exdiautqohweg8rq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">21. Consensus Kafka</font></i> <br><br><h1>  Protocole de r√©plication </h1><br>  La compr√©hension des d√©tails de la r√©plication vous aide √† mieux comprendre les sc√©narios de perte de donn√©es potentiels. <br><br><h3>  Exemples de demandes, d√©calage de fin de journal (LEO) et Highwater Mark (HW) </h3><br>  Nous avons consid√©r√© que les abonn√©s envoient p√©riodiquement des demandes de r√©cup√©ration au leader.  L'intervalle par d√©faut est de 500 ms.  Cela diff√®re de RabbitMQ en ce que dans RabbitMQ, la r√©plication est lanc√©e non pas par le miroir de file d'attente, mais par l'assistant.  Le ma√Ætre pousse les modifications aux miroirs. <br><br>  Le leader et tous les suiveurs conservent le label Log End Offset (LEO) et Highwater (HW).  La marque LEO stocke le d√©calage du dernier message dans la r√©plique locale et HW stocke le d√©calage du dernier commit.  N'oubliez pas que pour le statut de validation, le message doit √™tre enregistr√© dans toutes les r√©pliques ISR.  Cela signifie que LEO est g√©n√©ralement l√©g√®rement en avance sur HW. <br><br>  Lorsqu'un leader re√ßoit un message, il l'enregistre localement.  Le suiveur fait une demande de r√©cup√©ration, passant son LEO.  Le leader envoie ensuite un paquet de messages commen√ßant par ce LEO, et transmet √©galement le mat√©riel actuel.  Lorsque le leader re√ßoit des informations indiquant que toutes les r√©pliques ont enregistr√© le message √† un d√©calage donn√©, il d√©place la marque HW.  Seul le leader peut d√©placer le mat√©riel, et ainsi tous les suiveurs conna√Ætront la valeur actuelle dans les r√©ponses √† leur demande.  Cela signifie que les suiveurs peuvent √™tre √† la tra√Æne du leader en mati√®re de reporting et de connaissance des mat√©riels.  Les consommateurs ne re√ßoivent des messages que jusqu'au HW actuel. <br><br>  Notez que ¬´persistant¬ª signifie √©crit dans la m√©moire, pas sur le disque.  Pour des performances, Kafka se synchronise sur le disque √† un intervalle sp√©cifi√©.  RabbitMQ a √©galement un tel intervalle, mais il n'enverra la confirmation √† l'√©diteur qu'apr√®s que le ma√Ætre et tous les miroirs auront √©crit le message sur le disque.  Pour des raisons de performances, les d√©veloppeurs de Kafka ont d√©cid√© d'envoyer un accus√© de r√©ception d√®s que le message est √©crit en m√©moire.  Kafka s'appuie sur le fait que la redondance compense le risque de stockage √† court terme des messages confirm√©s uniquement en m√©moire. <br><br><h1>  √âchec du leader </h1><br>  Lorsqu'un chef tombe, Zookeeper avertit le contr√¥leur et il s√©lectionne une nouvelle r√©plique de chef.  Le nouveau leader √©tablit une nouvelle marque HW en ligne avec son LEO.  Ensuite, les abonn√©s re√ßoivent des informations sur le nouveau leader.  Selon la version de Kafka, le suiveur choisira l'un des deux sc√©narios: <br><br><ol><li>  Tronque le journal local au c√©l√®bre HW et envoie un message au nouveau leader apr√®s cette marque. <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il enverra une demande au chef pour conna√Ætre HW au moment de son √©lection en tant que chef, puis tronquer le journal √† ce d√©calage. </font><font style="vertical-align: inherit;">Ensuite, il commencera √† faire des demandes d'√©chantillonnage p√©riodiques, √† partir de ce d√©calage.</font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Le suiveur peut avoir besoin de couper le journal pour les raisons suivantes: </font></font><br><br><ul><li>    ,     ISR,   Zookeeper,     .    ISR,    ¬´¬ª,          .  ,        . Kafka ,     .  ,   ,         HW      .    ,   <i>acks=all</i>    . <br></li><li>     .      ,        .  ,       ,  ,   ,    ,        . </li></ul><br><h3>  c  </h3><br>        ,     :          HW (  ).  , RabbitMQ       .        .    ,             ¬´    ¬ª.            .       . <br><br> Kafka ‚Äî   ,       ,   RabbitMQ,        .      .  Kafka ‚Äî      ,        .            .    Kafka      HW  (   )   ,     .    ,    ,       ,     LEO. <br><br>        ISR     .      ,    ,  ,         ISR.          . <br><br><h1>   </h1><br>  Kafka  ,   RabbitMQ,      ,     .  Kafka    ,      . <br><br>      : <br><br><ul><li>  1.    ,     Zookeeper. <br></li><li>  2.      ,     Zookeeper. <br></li><li>  3.   ,    Zookeeper. <br></li><li>  4.   ,    Zookeeper. <br></li><li>  5.        Kafka,   Zookeeper. <br></li><li>  6.        Kafka,   Zookeeper. <br></li><li>  7.   Kafka     Kafka. <br></li><li>  8.  Kafka   Zookeeper. </li></ul><br>      . <br><br><h3>  1.    ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/je/cd/f1/jecdf1kc9y8gc8ej5sfmuelo30a.png"><br> <i><font color="gray">. 22.  1. ISR   </font></i> <br><br>     3   1  2,    Zookeeper.  3       .    <i>replica.lag.time.max.ms</i>    ISR      .    ,         ISR,   . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/ir/tq/ir/irtqir6cr8whigmvfqo1t-bbsso.png"><br> <i><font color="gray">. 23.  1.    ISR,            replica.lag.time.max.ms</font></i> <br><br>     (split-brain)   ,   RabbitMQ.    . <br><br><h3>  2.      ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/ri/fy/q6/rifyq652am8lmbhlgpfvfq-pjnm.png"><br> <i><font color="gray">. 24.  2.    </font></i> <br><br>       ,      Zookeeper.     , ISR ,       ,        .  ,    .        ,    . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/hj/8g/-1/hj8g-1veu8rkisccp7t6c9bxq7k.png"><br> <i><font color="gray">. 25.  2. ISR    </font></i> <br><br><h3>  3.   ,    Zookeeper </h3><br>    Zookeeper,      .           ISR. Zookeeper        ,     ,     . <br><br><img src="https://habrastorage.org/webt/cv/tb/gj/cvtbgjgw7ub1w8dmii46aql3bhc.png"><br> <i><font color="gray">. 26.  3.       </font></i> <br><br><h3>  4.   ,    Zookeeper </h3><br><img src="https://habrastorage.org/webt/zw/k4/8o/zwk48obscffldqgdhpyl0dvvipc.png"><br> <i><font color="gray">. 27.  4.    </font></i> <br><br>    Zookeeper,      . <br><br><img src="https://habrastorage.org/webt/eh/s1/hx/ehs1hxu4sako2udflhmhhbqhtsu.png"><br> <i><font color="gray">. 28.  4.    Zookeeper</font></i> <br><br>    Zookeeper        .      .      ,           <i>acks=1</i> .        ,         ISR   .        Zookeeper,     ,         . <br><br>  <i>acks=all</i>   ,    ISR   ,      .        ISR,          - . <br><br>            .    ,   ,     ,       HW,        ,    .         .     ,    .     ,        ,    . <br><br><img src="https://habrastorage.org/webt/pt/z_/pn/ptz_pnhoyrwvw4v-l9re3ffjzcg.png"><br> <i><font color="gray">. 29.  4.    1     </font></i> <br><br><h3>  5.        Kafka,   Zookeeper </h3><br>        Kafka,   Zookeeper.     ISR,    ,    . <br><br><img src="https://habrastorage.org/webt/ik/aj/a1/ikaja1i4z3fnodbcmam8sp2jbjc.png"><br> <i><font color="gray">. 30.  5.     ISR</font></i> <br><br><h3>  6.        Kafka,   Zookeeper </h3><br><img src="https://habrastorage.org/webt/cz/5h/2m/cz5h2mnqelpalxozp-jv4yv23rc.png"><br> <i><font color="gray">. 31.  6.    </font></i> <br><br>      ,   Zookeeper.          <i>acks=1</i> . <br><br><img src="https://habrastorage.org/webt/pj/pi/vj/pjpivjf1bsnvowntmkjqxdzipfe.png"><br> <i><font color="gray">. 32.  6.      Kafka  Zookeeper</font></i> <br><br>      <i>replica.lag.time.max.ms</i> ,    ISR   ,     ,     Zookeeper,     . <br><br>  , Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/g8/rg/wo/g8rgwol3elzkz8dwxojtclogyns.png"><br> <i><font color="gray">. 33.  6.  </font></i> <br><br>         ,      .    60    .            . <br><br><img src="https://habrastorage.org/webt/zu/zl/dh/zuzldhf62qbynz_voxil-25roxe.png"><br> <i><font color="gray">. 34.  6.     </font></i> <br><br>     ,       .    ,    Zookeeper ,     .      HW           . <br><br><img src="https://habrastorage.org/webt/zj/5e/vd/zj5evdyqhphl9uupogfvbjx7zjk.png"><br> <i><font color="gray">. 35.  6.        </font></i> <br><br>           ,    <i>acks=1</i>  <i>min.insync.replicas</i>  1.        ,    ,     ,     ,         ‚Äî    ,   .       ,    <i>acks=1</i> . <br><br>     ,       ,    ISR   .    -  .   ,      ,  <i>acks=all</i> ,    ISR    .       .      ‚Äî <i>min.insync.replicas = 2</i> . <br><br><h3>  7.   Kafka     Kafka </h3><br>  ,      Kafka          .         ,    6.             . <br><br><h3>  8.  Kafka   Zookeeper </h3><br>    Zookeeper         Kafka.       ,       Zookeeper,         .    ,  ,     ,     Kafka. <br><br><h3>    </h3><br>  ,         ,     ,    . , ,     ,      . <br><br>  -      Zookeeper,        <i>acks=1</i> .    Zookeeper       .     <i>acks=all</i> . <br><br>  <i>min.insync.replicas</i>        ,         ,    6. <br><br><h1>     </h1><br>   ,      Kafka: <br><br><ul><li>   ,      <i>acks=1</i> <br></li><li>   (unclean)  ,       ISR,   <i>acks=all</i> <br></li><li>    Zookeeper,      <i>acks=1</i> <br></li><li>   ,     ISR   .    ,  <i>acks=all</i> .      ,  <i>min.insync.replicas=1</i> . <br></li><li>     .     ,       .        . </li></ul><br>     ,   ,      .    ‚Äî   <i>acks=all</i>  <i>min.insync.replicas</i>  1. <br><br><h1>    RabbitMQ  Kafka </h1><br>              .   RabbitMQ   .        ,   .           RabbitMQ.       ,    .       .    ,         ( )       . <br><br>  Kafka   .          .    .  ,    .    ,     ,           . , -  ,       .     ,      . <br><br> RabbitMQ  Kafka         .    , RabbitMQ              .        : <br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fsync toutes les quelques centaines de millisecondes </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les miroirs ne peuvent √™tre d√©tect√©s qu'apr√®s la dur√©e de vie des paquets qui v√©rifient la disponibilit√© de chaque n≈ìud (net tick). </font><font style="vertical-align: inherit;">Si le miroir ralentit ou tombe, cela ajoute un d√©lai.</font></font></li></ul><br>  Kafka s'appuie sur le fait que si le message est stock√© sur plusieurs n≈ìuds, vous pouvez confirmer les messages d√®s qu'ils sont en m√©moire.  De ce fait, il y a un risque de perdre des messages de tout type (m√™me <i>acks = all</i> , <i>min.insync.replies = 2</i> ) en cas de panne simultan√©e. <br><br>  Dans l'ensemble, Kafka pr√©sente de meilleures performances et a √©t√© initialement con√ßu pour les clusters.  Le nombre d'adeptes peut √™tre port√© √† 11, si n√©cessaire pour des raisons de fiabilit√©.  Un facteur de r√©plication de 5 et un nombre minimum de r√©pliques dans un √©tat synchronis√© de <i>min.insync.replicas = 3</i> feront de la perte de message un √©v√©nement tr√®s rare.  Si votre infrastructure est capable de fournir un tel taux de r√©plication et un niveau de redondance, vous pouvez choisir cette option. <br><br>  Le clustering RabbitMQ est bon pour les petites files d'attente.  Mais m√™me les petites files d'attente peuvent augmenter rapidement avec un trafic √©lev√©.  Une fois les files d'attente devenues volumineuses, vous devrez faire un choix difficile entre disponibilit√© et fiabilit√©.  Le clustering RabbitMQ est le mieux adapt√© aux situations non typiques o√π les avantages de la flexibilit√© de RabbitMQ l'emportent sur les inconv√©nients du clustering. <br><br>  L'un des antidotes √† la grande vuln√©rabilit√© de file d'attente de RabbitMQ est de les d√©composer en de nombreux plus petits.  Si vous n'avez pas besoin d'un ordre complet de toute la file d'attente, mais uniquement des messages pertinents (par exemple, les messages d'un client sp√©cifique), ou rien du tout, alors cette option est acceptable: regardez mon projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Rebalanser</a> pour fractionner la file d'attente (le projet est encore √† un stade pr√©coce). <br><br>  Enfin, n'oubliez pas un certain nombre de bogues dans les m√©canismes de clustering et de r√©plication de RabbitMQ et de Kafka.  Au fil du temps, les syst√®mes sont devenus plus matures et stables, mais aucun message ne sera jamais prot√©g√© √† 100% contre les pertes!  De plus, des accidents √† grande √©chelle se produisent dans les centres de donn√©es! <br><br>  Si j'ai rat√© quelque chose, fait une erreur ou si vous n'√™tes d'accord avec aucun des points, n'h√©sitez pas √† √©crire un commentaire ou √† me contacter. <br><br>  Les gens me demandent souvent: ¬´Que choisir, Kafka ou RabbitMQ?¬ª, ¬´Quelle plateforme est la meilleure?¬ª.  La v√©rit√© est que cela d√©pend vraiment de votre situation, de votre exp√©rience actuelle, etc. Je n'ose pas exprimer mon opinion, car ce sera trop de simplification de recommander une plate-forme unique pour tous les cas d'utilisation et les limitations possibles.  J'ai √©crit cette s√©rie d'articles pour que vous puissiez vous faire votre propre opinion. <br><br>  Je tiens √† dire que les deux syst√®mes sont des chefs de file dans ce domaine.  Je suis peut-√™tre un peu biais√©, car √† partir de l'exp√©rience de mes projets, je suis plus enclin √† appr√©cier des choses comme la garantie de l'ordre des messages et la fiabilit√©. <br><br>  Je vois d'autres technologies qui manquent de fiabilit√© et de commande garantie, puis je regarde RabbitMQ et Kafka - et je comprends la valeur incroyable de ces deux syst√®mes. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr474984/">https://habr.com/ru/post/fr474984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr474968/index.html">RxDart pour les plus petits ... projets</a></li>
<li><a href="../fr474970/index.html">Comment √©crire un contrat intelligent avec Python sur l'ontologie? Partie 5: API native</a></li>
<li><a href="../fr474976/index.html">Boating City: comment Venise existe sans voitures</a></li>
<li><a href="../fr474978/index.html">IBM Watson Visual Recognition: la reconnaissance d'objets d√©sormais disponible dans IBM Cloud</a></li>
<li><a href="../fr474982/index.html">Tutoriel JavaFX: FXML et SceneBuilder</a></li>
<li><a href="../fr474988/index.html">Bienvenue chez Mitap: Carri√®res chez Data Science pour d√©butants</a></li>
<li><a href="../fr474990/index.html">Pratique: comment cr√©er un r√©seau Wi-Fi dans un parc de la ville</a></li>
<li><a href="../fr474992/index.html">Analyse des batteries d'ordinateurs portables d√©fectueuses. Notes de motard √©lectrique</a></li>
<li><a href="../fr474994/index.html">Comment couper un monolithe en services et maintenir les performances des caches en m√©moire sans perdre en coh√©rence</a></li>
<li><a href="../fr474996/index.html">Le r√©sum√© des √©v√©nements informatiques de novembre (deuxi√®me partie)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
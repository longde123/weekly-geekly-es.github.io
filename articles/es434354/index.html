<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëßüèª üßõ üêù Crear un modelo de reconocimiento facial utilizando el aprendizaje profundo en Python ü§òüèæ ‚úãüèæ ‚è±Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La traductora Elena Bornovolokova espec√≠ficamente para Netolog√≠a adapt√≥ un art√≠culo de Fayzan Shaykh sobre c√≥mo crear un modelo de reconocimiento faci...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Crear un modelo de reconocimiento facial utilizando el aprendizaje profundo en Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/netologyru/blog/434354/">  <i>La traductora Elena Bornovolokova espec√≠ficamente para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Netolog√≠a</a> adapt√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo de</a> Fayzan Shaykh sobre c√≥mo crear un modelo de reconocimiento facial y en qu√© √°reas se puede aplicar.</i> <br><br><h2>  Introduccion </h2><br>  En los √∫ltimos a√±os, la visi√≥n por computadora ha ganado popularidad y se destac√≥ en una direcci√≥n separada.  Los desarrolladores est√°n creando nuevas aplicaciones que se utilizan en todo el mundo. <a name="habracut"></a><br>  En esta direcci√≥n, me atrae el concepto de c√≥digo abierto.  Incluso los gigantes de la tecnolog√≠a est√°n listos para compartir nuevos descubrimientos e innovaciones con todos, para que la tecnolog√≠a no siga siendo un privilegio de los ricos. <br><br>  Una de estas tecnolog√≠as es el reconocimiento facial.  Cuando se usa correcta y √©ticamente, esta tecnolog√≠a se puede aplicar en muchas √°reas de la vida. <br><br>  En este art√≠culo, le mostrar√© c√≥mo crear un algoritmo de reconocimiento facial efectivo utilizando herramientas de c√≥digo abierto.  Antes de pasar a esta informaci√≥n, quiero que te prepares e inspires viendo este video: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wr4rx0Spihs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Reconocimiento facial: aplicaciones potenciales </h2><br>  Aqu√≠ hay algunas √°reas potenciales de aplicaci√≥n de la tecnolog√≠a de reconocimiento facial. <br><br>  <b>Reconocimiento facial en redes sociales</b> .  Facebook ha reemplazado el etiquetado manual de im√°genes con sugerencias de etiquetas generadas autom√°ticamente para cada imagen cargada en la plataforma.  Facebook utiliza un algoritmo simple de reconocimiento facial para analizar los p√≠xeles en la imagen y compararlo con sus respectivos usuarios. <br><br>  <b>Reconocimiento facial en seguridad</b> .  Un ejemplo simple del uso de la tecnolog√≠a de reconocimiento facial para proteger los datos personales es desbloquear su tel√©fono inteligente "en la cara".  Esta tecnolog√≠a tambi√©n se puede implementar en el sistema de acceso: una persona mira a la c√°mara y determina si debe ingresarla o no. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/bYrRQQX2PvY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <b>Reconocimiento facial para contar el n√∫mero de personas</b> .  La tecnolog√≠a de reconocimiento facial se puede utilizar para contar la cantidad de personas que asisten a un evento (como una conferencia o un concierto).  En lugar de contar manualmente a los participantes, instalamos una c√°mara que puede capturar im√°genes de las caras de los participantes y proporcionar el n√∫mero total de visitantes.  Esto ayudar√° a automatizar el proceso y a ahorrar tiempo. <br><br><img src="https://habrastorage.org/webt/fn/bc/-k/fnbc-kgpcaeogtd4attryczyjfq.png"><br><br><h2>  Configuraci√≥n del sistema: requisitos de hardware y software </h2><br>  Considere c√≥mo podemos usar la tecnolog√≠a de reconocimiento facial poni√©ndose en contacto con las herramientas de c√≥digo abierto disponibles para nosotros. <br><br>  Utilic√© las siguientes herramientas que te recomiendo: <br><br><ul><li>  C√°mara web (Logitech C920) para construir un modelo de reconocimiento facial en tiempo real en una computadora port√°til Lenovo E470 ThinkPad (Core i5 7th Gen).  Tambi√©n puede usar la c√°mara o videoc√°mara integrada de su computadora port√°til con cualquier sistema adecuado para el an√°lisis de video en tiempo real en lugar de los que us√©. <br></li><li> Es preferible utilizar un procesador de gr√°ficos para un procesamiento de video m√°s r√°pido. <br></li><li>  Utilizamos el sistema operativo Ubuntu 18.04 con todo el software necesario. <br></li></ul><br>  Antes de continuar con la construcci√≥n de nuestro modelo de reconocimiento facial, analizaremos estos puntos con m√°s detalle. <br><br><h3>  Paso 1: configuraci√≥n de hardware </h3><br>  Compruebe si la c√°mara est√° configurada correctamente.  Con Ubuntu, esto es simple: vea si el dispositivo es reconocido por el sistema operativo.  Para hacer esto, siga estos pasos: <br><br><ol><li> Antes de conectar la c√°mara web a la computadora port√°til, verifique todos los dispositivos de video conectados escribiendo <code>ls /dev/video*</code> en el s√≠mbolo del sistema.  Como resultado, aparece una lista de todos los dispositivos de video conectados al sistema. <img src="https://habrastorage.org/webt/za/h8/9m/zah89mjqr1gezzo8xekib9fhmzw.png"></li><li>  Conecte la c√°mara web y vuelva a ejecutar el comando.  Si la c√°mara web est√° conectada correctamente, el nuevo dispositivo se reflejar√° como resultado del comando. <img src="https://habrastorage.org/webt/bs/og/lc/bsoglcdg4tevubdfds6reijtogw.png"></li><li>  Tambi√©n puede usar el software de la c√°mara web para verificar su correcto funcionamiento.  Ubuntu puede usar el programa Cheese para esto. <img src="https://habrastorage.org/webt/jl/9t/f3/jl9tf3b3qke5udd2fu3h1mzbcmo.png"></li></ol><br><h3>  Paso 2: configuraci√≥n del software </h3><br>  <b>Paso 2.1: Instalar Python</b> <br><br>  El c√≥digo en este art√≠culo fue escrito usando Python (versi√≥n 3.5).  Para instalar Python, recomiendo usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Anaconda</a> , una distribuci√≥n popular de Python para procesar y analizar datos. <br><br>  <b>Paso 2.2: Instalar OpenCV</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenCV</a> es una biblioteca de c√≥digo abierto que est√° dise√±ada para crear aplicaciones de visi√≥n por computadora.  La instalaci√≥n de OpenCV se realiza utilizando <code>pip</code> : <br><br><pre> <code class="python hljs">pip3 install opencv-python</code> </pre> <br>  <b>Paso 2.3: Establecer la API de face_recognition</b> <br><br>  Utilizaremos la <code>face_recognition API</code> , que se considera la API de reconocimiento facial Python m√°s f√°cil del mundo.  Para instalar, use: <br><br><pre> <code class="python hljs">pip install dlib pip install face_recognition</code> </pre> <br><h2>  Implementaci√≥n </h2><br>  Despu√©s de configurar el sistema, procedemos a la implementaci√≥n.  Para comenzar, crearemos un programa y luego explicaremos lo que hicimos. <br><br><h3>  Tutorial </h3><br>  Cree un archivo <code>face_detector.py</code> y luego copie el siguiente c√≥digo: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># import libraries import cv2 import face_recognition # Get a reference to webcam video_capture = cv2.VideoCapture("/dev/video1") # Initialize variables face_locations = [] while True: # Grab a single frame of video ret, frame = video_capture.read() # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses) rgb_frame = frame[:, :, ::-1] # Find all the faces in the current frame of video face_locations = face_recognition.face_locations(rgb_frame) # Display the results for top, right, bottom, left in face_locations:  # Draw a box around the face  cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2) # Display the resulting image cv2.imshow('Video', frame) # Hit 'q' on the keyboard to quit! if cv2.waitKey(1) &amp; 0xFF == ord('q'):  break # Release handle to the webcam video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre> <br>  Luego ejecute este archivo de Python escribiendo: <br><br><pre> <code class="python hljs">python face_detector.py</code> </pre> <br>  Si todo funciona correctamente, se abrir√° una nueva ventana con el modo de reconocimiento facial lanzado en tiempo real. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/eh14NomINOs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Para resumir y explicar lo que hizo nuestro c√≥digo: <br><br><ol><li>  Primero, <b>indicamos el hardware</b> en el que se analizar√° el video. <br></li><li>  Luego hicimos una <b>captura de video en</b> tiempo <b>real</b> cuadro por cuadro. <br></li><li>  Luego <b>se proces√≥ cada cuadro</b> y se <b>extrajo</b> la <b>ubicaci√≥n de todas las caras</b> en la imagen. <br></li><li>  Como resultado, <b>estos cuadros se reprodujeron en forma de video</b> junto con una indicaci√≥n de d√≥nde se encuentran las caras. <br></li></ol><br><h3>  Ejemplo de aplicaci√≥n de reconocimiento facial </h3><br>  Esto no es todo lo divertido termina.  Haremos una cosa m√°s genial: crearemos un ejemplo completo de aplicaci√≥n basado en el c√≥digo anterior.  Haremos peque√±os cambios en el c√≥digo y todo estar√° listo. <br><br>  Suponga que desea crear un sistema automatizado utilizando una videoc√°mara para rastrear d√≥nde se encuentra actualmente el altavoz.  Dependiendo de su posici√≥n, el sistema gira la c√°mara para que el altavoz permanezca siempre en el centro del cuadro. <br>  El primer paso es crear un sistema que identifique a la persona o personas en el video y se centre en la ubicaci√≥n del orador. <br><br><img src="https://habrastorage.org/webt/xg/q-/ub/xgq-ubchs7yktjujlxcoakih7d0.png"><br><br>  Vamos a descubrir c√≥mo hacerlo.  Como ejemplo, seleccion√© un video en YouTube con un discurso de los oradores de la conferencia DataHack Summit 2017. <br><br>  Primero, importe las bibliotecas necesarias: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> face_recognition</code> </pre> <br>  Luego leemos el video y establecemos la duraci√≥n: <br><br><pre> <code class="python hljs">input_movie = cv2.VideoCapture(<span class="hljs-string"><span class="hljs-string">"sample_video.mp4"</span></span>) length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))</code> </pre> <br>  Despu√©s de eso, creamos un archivo de salida con la resoluci√≥n necesaria y la velocidad de fotogramas similar a la del archivo de entrada. <br><br>  Cargamos la imagen del altavoz como muestra para reconocerla en el video: <br><br><pre> <code class="python hljs">image = face_recognition.load_image_file(<span class="hljs-string"><span class="hljs-string">"sample_image.jpeg"</span></span>) face_encoding = face_recognition.face_encodings(image)[<span class="hljs-number"><span class="hljs-number">0</span></span>] known_faces = [ face_encoding, ]</code> </pre> <br>  Una vez terminado, comenzamos el ciclo, que ser√°: <br><br><ul><li>  Extraer fotograma del video. <br></li><li>  Encuentra todas las caras e identif√≠calas. <br></li><li>  Cree un nuevo video que combine el marco original con la ubicaci√≥n de la cara del orador con una firma. <br></li></ul><br>  Veamos el c√≥digo que ejecutar√° esto: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Initialize variables face_locations = [] face_encodings = [] face_names = [] frame_number = 0 while True: # Grab a single frame of video ret, frame = input_movie.read() frame_number += 1 # Quit when the input video file ends if not ret:  break # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses) rgb_frame = frame[:, :, ::-1] # Find all the faces and face encodings in the current frame of video face_locations = face_recognition.face_locations(rgb_frame, model="cnn") face_encodings = face_recognition.face_encodings(rgb_frame, face_locations) face_names = [] for face_encoding in face_encodings:  # See if the face is a match for the known face(s)  match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)  name = None  if match[0]:      name = "Phani Srikant"  face_names.append(name) # Label the results for (top, right, bottom, left), name in zip(face_locations, face_names):  if not name:      continue      # Draw a box around the face  cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)  # Draw a label with a name below the face  cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)       font = cv2.FONT_HERSHEY_DUPLEX  cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1) # Write the resulting image to the output video file print("Writing frame {} / {}".format(frame_number, length)) output_movie.write(frame) # All done! input_movie.release() cv2.destroyAllWindows()</span></span></code> </pre> <br>  El c√≥digo te dar√° este resultado: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/uOcN6FhX6gY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  De los editores </h2><br>  Cursos de Netolog√≠a sobre el tema: <br><br><ul><li>  profesi√≥n en l√≠nea " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desarrollador de Python</a> " </li><li>  Profesi√≥n en l√≠nea <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Data Scientist</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es434354/">https://habr.com/ru/post/es434354/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es434340/index.html">C√≥mo auditamos el Wi-Fi en el metro de Delhi y lo que surgi√≥</a></li>
<li><a href="../es434342/index.html">Curso MIT "Seguridad de sistemas inform√°ticos". Lecci√≥n 22: "MIT de seguridad de la informaci√≥n", parte 1</a></li>
<li><a href="../es434344/index.html">Curso MIT "Seguridad de sistemas inform√°ticos". Lecci√≥n 22: "MIT de seguridad de la informaci√≥n", parte 2</a></li>
<li><a href="../es434346/index.html">Curso MIT "Seguridad de sistemas inform√°ticos". Lecci√≥n 22: "MIT de seguridad de la informaci√≥n", parte 3</a></li>
<li><a href="../es434348/index.html">¬øRecuerdas tu contrase√±a en Habr√©?</a></li>
<li><a href="../es434356/index.html">Python Stiller con correo electr√≥nico</a></li>
<li><a href="../es434358/index.html">Sustituci√≥n de importaciones de sistemas operativos. ¬øC√≥mo veo el sistema operativo dom√©stico?</a></li>
<li><a href="../es434360/index.html">Charla explicada sobre programaci√≥n asincr√≥nica en Javascript</a></li>
<li><a href="../es434362/index.html">NO pronosticado para 2019</a></li>
<li><a href="../es434364/index.html">Hangfire Queue Support</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
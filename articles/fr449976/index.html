<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö£üèª üßìüèº üö¶ Conteneurs associatifs multithread en C ++. Rapport Yandex ü§æüèΩ ‚è≤Ô∏è ‚è∫Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√Ä partir du rapport du d√©veloppeur senior Sergey Murylyov, vous pouvez en apprendre davantage sur le conteneur associatif multi-thread pour la bibliot...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Conteneurs associatifs multithread en C ++. Rapport Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/449976/">  √Ä partir du rapport du d√©veloppeur senior Sergey Murylyov, vous pouvez en apprendre davantage sur le conteneur associatif multi-thread pour la biblioth√®que standard, qui est d√©velopp√© dans le cadre du WG21.  Sergey a parl√© des avantages et des inconv√©nients des solutions populaires √† ce probl√®me et de la voie choisie par les d√©veloppeurs. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Y4Zw8a1an7U" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Vous avez probablement d√©j√† devin√© √† partir du titre que le rapport d'aujourd'hui portera sur la fa√ßon dont nous, dans le cadre du groupe de travail 21, avons cr√©√© notre conteneur, similaire √† std :: unordered_map, mais pour un environnement multi-thread. <a name="habracut"></a><br><br>  Dans de nombreux langages de programmation - Java, C #, Python - cela existe d√©j√† et est assez largement utilis√©.  Mais dans notre C ++ bien-aim√©, le plus rapide et le plus productif, cela ne s'est pas produit.  Mais nous avons consult√© et d√©cid√© de faire une telle chose. <br><br><img src="https://habrastorage.org/webt/hh/3p/fu/hh3pfuxkhev-zboni6oerp4yvdg.jpeg"><br><br>  Avant d'ajouter quelque chose √† la norme, vous devez r√©fl√©chir √† la fa√ßon dont les gens l'utiliseront.  Ensuite, pour cr√©er une interface plus correcte, qui sera tr√®s probablement adopt√©e par la commission - de pr√©f√©rence sans aucun amendement.  Et pour qu‚Äôen fin de compte, il n‚Äôy ait pas de telle chose qu‚Äôils aient fait une chose, <br><br>  L'option la plus connue et la plus utilis√©e est la mise en cache de gros calculs lourds.  Il existe un service Memcached assez connu qui met simplement en cache les r√©ponses du serveur Web en m√©moire.  Il est clair que vous pouvez faire √† peu pr√®s la m√™me chose du c√¥t√© de votre candidature, si vous disposez d'un conteneur associatif comp√©titif.  Les deux approches ont leurs avantages et leurs inconv√©nients.  Mais si vous ne disposez pas d'un tel conteneur, vous devrez soit faire votre propre v√©lo ou utiliser une sorte de Memcached. <br><br>  Un autre cas d'utilisation populaire est la d√©duplication des √©v√©nements.  Je pense que beaucoup dans cette salle √©crivent toutes sortes de syst√®mes distribu√©s et savent que les files d'attente distribu√©es sont souvent utilis√©es pour communiquer entre les composants, tels qu'Apache Kafka et Amazon Kinesis.  Ils se distinguent par une telle fonctionnalit√© qu'ils peuvent envoyer plusieurs fois un message √† un consommateur.  Cela s'appelle au moins une fois la livraison, ce qui signifie une garantie de livraison au moins une fois: plus est possible, moins ne l'est pas. <br><br>  Consid√©rez cela en termes de vie r√©elle.  Imaginez que nous ayons un backend d'une salle de chat ou d'un r√©seau social o√π la messagerie a lieu.  Cela peut conduire au fait que quelqu'un a √©crit un message et que quelqu'un a re√ßu plusieurs fois une notification push sur son t√©l√©phone portable.  Il est clair que si les utilisateurs voient cela, ils n'en seront pas contents.  On fait valoir que ce probl√®me peut √™tre r√©solu avec un si merveilleux conteneur multi-thread. <br><br>  Le cas suivant, moins fr√©quemment utilis√©, est celui o√π nous avons juste besoin d'enregistrer quelque chose c√¥t√© serveur, des m√©tadonn√©es pour l'utilisateur.  Par exemple, nous pouvons gagner du temps lors de la derni√®re authentification de l'utilisateur, afin de comprendre quand, la prochaine fois, il lui sera demand√© son nom d'utilisateur et son mot de passe. <br><br>  La derni√®re option sur cette diapositive est les statistiques.  √Ä partir d'applications r√©elles, un exemple d'utilisation dans une machine virtuelle de Facebook peut √™tre donn√©.  Ils ont fait une machine virtuelle enti√®re pour optimiser PHP et dans leur machine virtuelle, ils essaient d'√©crire les arguments avec lesquels ils ont √©t√© appel√©s dans une table de hachage multi-thread pour toutes les fonctions int√©gr√©es.  Et s'ils ont un r√©sultat dans le cache, ils essaient de le donner tout de suite et ne comptent rien. <br><br><img src="https://habrastorage.org/webt/3p/gj/ve/3pgjvel56b7vvkupvwvhpcqouhc.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Ajouter quelque chose de grand et de compliqu√© √† la norme n'est ni facile ni rapide.  En r√®gle g√©n√©rale, si quelque chose de gros est ajout√©, il passe par la sp√©cification technique.  Actuellement, la norme √©volue beaucoup pour √©tendre la prise en charge du multithreading dans la biblioth√®que standard.  Et en particulier, la proposition P0260R3 sur les files d'attente multithreads est en cours actuellement.  Cette proposition concerne une structure de donn√©es tr√®s similaire √† nous, et nos d√©cisions de conception sont tr√®s similaires √† bien des √©gards. <br><br>  En fait, l'un des concepts de base de leur conception est que leur interface est diff√©rente de la file d'attente standard std ::.  √Ä quoi √ßa sert?  Si vous regardez la file d'attente standard, puis pour en extraire un √©l√©ment, vous devez effectuer deux op√©rations.  Vous devez effectuer une op√©ration frontale pour compter et une op√©ration pop pour supprimer.  Si nous travaillons dans des conditions de multithreading, nous pouvons avoir une sorte d'op√©ration sur la file d'attente entre ces deux appels, et il peut arriver que nous consid√©rions un √©l√©ment et en supprimions un autre, ce qui semble conceptuellement incorrect.  Par cons√©quent, ces deux appels y ont √©t√© remplac√©s par un, et quelques autres appels de la cat√©gorie des essais push et try pop ont √©t√© ajout√©s.  Mais l'id√©e g√©n√©rale est qu'un conteneur multi-thread ne sera pas le m√™me qu'une interface normale. <br><br>  Les files d'attente multithread ont √©galement de nombreuses impl√©mentations diff√©rentes qui r√©solvent plusieurs t√¢ches diff√©rentes.  La t√¢che la plus courante est la t√¢che des producteurs et des consommateurs, lorsque nous avons des threads qui produisent certaines t√¢ches et que certains threads prennent des t√¢ches de la file d'attente et les traitent. <br><br>  Le deuxi√®me cas est celui o√π nous avons juste besoin d'une sorte de file d'attente synchronis√©e.  Dans le cas des fabricants et des consommateurs, nous obtenons une file d'attente limit√©e au haut et au bas.  Si nous essayons, relativement parlant, d'extraire d'une file d'attente vide, alors nous entrons dans un √©tat d'attente.  Et la m√™me chose se produit √† peu pr√®s si nous essayons d'ajouter quelque chose qui ne rentre pas dans la file d'attente en taille. <br><br>  Dans cette proposition, il est √©galement d√©crit que nous avons une interface distincte qui nous permet de distinguer la mise en ≈ìuvre que nous avons √† l'int√©rieur de la serrure, ou la serrure libre.  Le fait qu'ici partout dans la proposition est √©crit sans verrou, en fait, il est √©crit dans les livres comme sans attente.  Cela signifie que notre algorithme fonctionne pour un nombre fixe d'op√©rations.  Verrouiller librement signifie un peu diff√©rent, mais ce n'est pas le but. <br><br><img src="https://habrastorage.org/webt/tk/ba/fh/tkbafhushvnkm7pl0iolc81qcru.jpeg"><br><br>  Examinons un diagramme typique de la fa√ßon dont l'impl√©mentation de notre table de hachage pourrait ressembler si elle est bloqu√©e.  Nous l'avons divis√© en plusieurs segments.  Chaque segment, en r√®gle g√©n√©rale, contient une sorte de verrou, tel que Mutex, Spinlock, ou quelque chose d'encore plus d√©licat.  Et en plus de Mutex ou Spinlock, il contient √©galement la table de hachage habituelle, qui est prot√©g√©e par cette activit√©. <br><br>  Dans cette image, nous avons une table de hachage, qui est faite sur les listes.  En fait, dans notre impl√©mentation de r√©f√©rence, nous avons √©crit une table de hachage avec un adressage ouvert pour des raisons de performances.  Les consid√©rations de performances sont fondamentalement les m√™mes que pourquoi std :: vector est plus rapide que std :: list car le vecteur, relativement parlant, est stock√© s√©quentiellement en m√©moire.  Lorsque nous le parcourons, nous avons un acc√®s s√©quentiel, qui est bien mis en cache.  Si nous utilisons une sorte de feuilles, nous aurons toutes sortes de sauts entre les diff√©rentes sections de la m√©moire.  Et le tout, en r√®gle g√©n√©rale, se termine par le fait que nous perdons de la productivit√©. <br><br>  Au tout d√©but, lorsque nous voulons trouver quelque chose dans cette table de hachage, nous prenons le code de hachage de la cl√©.  Vous pouvez le prendre modulo et faire autre chose avec lui pour obtenir le num√©ro de segment, et dans le segment que nous recherchons, comme dans une table de hachage r√©guli√®re, mais en m√™me temps, bien s√ªr, nous prenons le verrou. <br><br><img src="https://habrastorage.org/webt/tq/uv/8t/tquv8tlfrcsr1zttyu_-elp1j1c.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Les principales id√©es de notre conception.  Bien s√ªr, nous avons √©galement cr√©√© une interface qui ne correspond pas √† std :: unordered_map.  La raison en est la suivante.  Par exemple, dans std :: unordered_map ordinaire, nous avons une chose aussi merveilleuse que les it√©rateurs.  Premi√®rement, toutes les impl√©mentations ne peuvent pas les prendre en charge normalement.  Et ceux qui peuvent prendre en charge, en r√®gle g√©n√©rale, sont des impl√©mentations sans verrouillage qui n√©cessitent soit une r√©cup√©ration de place, soit une sorte de pointeurs intelligents qui nettoient la m√©moire derri√®re. <br><br>  En plus de cela, nous avons lanc√© plusieurs autres types d'op√©rations.  En fait, les it√©rateurs, ils sont en de nombreux endroits.  Par exemple, ils sont en Java.  Mais, en r√®gle g√©n√©rale, curieusement, ils ne se synchronisent pas l√†-bas.  Et si vous essayez de faire quelque chose avec eux √† partir de diff√©rents threads, ils peuvent facilement entrer dans un √©tat non valide, et vous pouvez obtenir une exception en Java, et si vous √©crivez ceci sur les avantages, alors ce sera probablement un comportement non d√©fini, ce qui est encore pire .  Et d'ailleurs, sur le sujet des comportements ind√©finis: √† mon avis, les camarades de Facebook dans leur folie de biblioth√®que, qui est publi√©e en open source sur GitHub, l'ont fait.  Je viens de copier l'interface avec Java et d'obtenir de merveilleux it√©rateurs. <br><br>  Nous n'avons pas non plus de probl√®me de m√©moire, c'est-√†-dire que si nous ajoutons quelque chose au conteneur et prenons de la m√©moire pour cela, nous ne le rendrons pas, m√™me si nous supprimons tout.  Une autre condition pr√©alable √† cette d√©cision √©tait que nous ayons une table de hachage avec un adressage ouvert √† l'int√©rieur.  Il fonctionne sur une structure de donn√©es lin√©aire qui, comme le vecteur, ne rend pas de m√©moire. <br><br>  Le prochain moment conceptuel est qu'en aucun cas nous ne donnerons √† quiconque des liens ext√©rieurs et des pointeurs vers des objets internes.  Cela a √©t√© fait pr√©cis√©ment pour √©viter la n√©cessit√© d'une collecte de d√©chets et non pour appliquer des pointeurs intelligents.  Il est clair que si nous stockons des objets suffisamment grands, leur stockage par valeur √† l'int√©rieur ne sera pas rentable.  Mais, dans ce cas, nous pouvons toujours les envelopper dans une sorte de pointeurs intelligents de notre choix.  Et, si nous voulons, par exemple, faire une sorte de synchronisation sur les valeurs, nous pouvons les envelopper dans une sorte de boost :: synchronized_value. <br><br>  Nous avons vu qu'il y a quelque temps, la classe shared_ptr a √©t√© supprim√©e de la m√©thode qui renvoyait le nombre de liens actifs vers cet objet.  Et nous sommes arriv√©s √† la conclusion que nous devons √©galement supprimer plusieurs fonctions, √† savoir, size, count, empty, buckets_count, car d√®s que nous renvoyons cette valeur de la fonction, elle cesse imm√©diatement d'√™tre valide, car quelqu'un peut changer le m√™me moment. <br><br>  Lors d'une de nos pr√©c√©dentes r√©unions, ils nous ont demand√© d'ajouter une sorte de mode afin que nous puissions acc√©der √† notre conteneur en mode monothread, comme un std :: unordered_map classique.  Une telle s√©mantique nous permet de distinguer clairement o√π nous travaillons en mode multithread et o√π non.  Et pour √©viter certaines situations d√©sagr√©ables lorsque les gens prennent un conteneur multi-thread, attendez-vous √† ce que tout se passe bien avec eux, prenez des it√©rateurs, puis soudain, il s'av√®re que tout est mauvais. <br><br><img src="https://habrastorage.org/webt/bm/kg/gc/bmkggc4kiu0yquhztvltr9ygeve.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Lors de cette r√©union √† Hawa√Ø, toute une proposition a √©t√© r√©dig√©e contre nous.  :) On nous a dit que de telles choses n'avaient pas leur place dans la norme, car il existe de nombreuses fa√ßons de cr√©er votre conteneur associatif multi-thread. <br><br>  Chacun a ses avantages et ses inconv√©nients - et on ne sait pas comment utiliser ce que nous r√©ussissons finalement.  En r√®gle g√©n√©rale, il est utilis√© lorsque vous avez besoin d'une sorte de performance extr√™me.  Et il semble que notre solution en bo√Æte ne convient pas, il faut l'optimiser pour chaque cas sp√©cifique. <br><br>  Le deuxi√®me point de cette proposition √©tait que notre interface n'est pas compatible avec le fait que Facebook a post√© sur GitHub depuis sa biblioth√®que standard. <br><br>  En fait, il n'y avait pas de probl√®me particulier l√†-bas.  Il y avait simplement une question de la cat√©gorie "Je n'ai pas lu, mais condamne".  Ils ont juste regard√© - l'interface est diff√©rente, ce qui signifie qu'elle n'est pas compatible. <br><br>  L'id√©e de la proposition √©tait √©galement que des t√¢ches similaires devraient √™tre r√©solues √† l'aide de la conception dite bas√©e sur des politiques, quand il est n√©cessaire de cr√©er un param√®tre de mod√®le suppl√©mentaire dans lequel vous pouvez passer un masque de bits avec quelles fonctionnalit√©s nous voulons activer et lesquelles d√©sactiver.  En effet, cela semble un peu sauvage et conduit au fait que nous obtenons environ 2 ^ n impl√©mentations, o√π n est le nombre de fonctionnalit√©s diff√©rentes. <br><br><img src="https://habrastorage.org/webt/h0/pw/rr/h0pwrrhpdlvzs-5hb-w6awjus88.jpeg"><br><br>  Dans le code, cela ressemble √† ceci.  Nous avons une sorte de param√®tre et un certain nombre de constantes pr√©d√©finies qui peuvent y √™tre pass√©es.  Curieusement, cette proposition a √©t√© rejet√©e. <br><br><img src="https://habrastorage.org/webt/ph/36/jt/ph36jtup-3_xxs0lmmyhoiwuoso.jpeg"><br><br>  Parce que, en fait, le comit√© a d√©j√† adopt√© la position que de telles choses devraient √™tre lorsque la file d'attente multithread passe par SG1.  Il n'y a m√™me pas eu de vote sur cette question.  Mais deux questions ont √©t√© mises aux voix. <br><br>  Le premier.  Beaucoup de gens nous voulaient du c√¥t√© de notre impl√©mentation de r√©f√©rence pour soutenir la lecture sans prendre de verrous.  Pour que nous ayons une lecture compl√®tement non bloquante.  Cela a vraiment du sens: en r√®gle g√©n√©rale, le cas d'utilisation le plus populaire est la mise en cache.  Et c'est tr√®s b√©n√©fique pour nous d'avoir une lecture rapide. <br><br>  Deuxi√®me moment.  Tout le monde a beaucoup entendu parler de l'ami pr√©c√©dent qui a parl√© de la conception bas√©e sur les politiques.  Tout le monde avait une id√©e - mais quoi, laissez-moi parler de mon id√©e aussi!  Et tout le monde a vot√© pour une conception bas√©e sur les politiques.  M√™me si je dois dire que toute cette histoire dure depuis un certain temps, et devant nous, nos coll√®gues d'Intel, d'Arch Robinson et d'Anton Malakhov le faisaient.  Et ils avaient d√©j√† plusieurs propositions √† ce sujet.  Ils ont juste propos√© d'ajouter une impl√©mentation sans verrouillage bas√©e sur l'algorithme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SeepOrderedList</a> .  Et ils avaient √©galement une conception bas√©e sur des politiques avec la plainte de m√©moire. <br><br>  Et cette proposition n'aimait pas le Library Evolution Working Group.  Il a √©t√© conclu avec la raison que nous aurons simplement une augmentation illimit√©e du nombre de mots dans la norme.  Il sera tout simplement impossible de pr√©visualiser ad√©quatement et de simplement impl√©menter dans le code. <br><br>  Nous n'avons aucun commentaire sur les id√©es elles-m√™mes.  Nous avons des commentaires, pour la plupart, sur la mise en ≈ìuvre des r√©f√©rences.  Et bien s√ªr, nous avons quelques id√©es qui peuvent √™tre introduites pour le rendre plus clair.  Mais essentiellement, la prochaine fois, nous irons avec la m√™me proposition.  Nous esp√©rons sinc√®rement que nous n'aurons pas, comme pour les modules, cinq appels avec la m√™me proposition.  Nous croyons sinc√®rement en nous-m√™mes, et nous serons autoris√©s √† passer au prochain appel, et que le groupe de travail sur l'√©volution de la biblioth√®que insistera n√©anmoins sur notre opinion et ne nous permettra pas de faire avancer la conception bas√©e sur les politiques.  Parce que notre adversaire ne s'arr√™te pas.  Il a d√©cid√© de prouver √† tout le monde que c'√©tait n√©cessaire.  Mais comme on dit, le temps nous le dira.  J'ai tout, merci de votre attention. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr449976/">https://habr.com/ru/post/fr449976/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr449966/index.html">Tableaux dans Figma. Conception d'une grille de donn√©es par un composant</a></li>
<li><a href="../fr449968/index.html">Redmadrobot discute d'AppsConf 2019: vid√©o</a></li>
<li><a href="../fr449970/index.html">Publier sous le drapeau noir, ou comme je n'ai pas mis votre cours vid√©o sur le tracker</a></li>
<li><a href="../fr449972/index.html">Comment injecter rapidement des piscines en amont?</a></li>
<li><a href="../fr449974/index.html">Netramesh - solution de maillage de service l√©ger</a></li>
<li><a href="../fr449978/index.html">Igor Antarov de Moscou Tesla Club se d√©bat avec 20 mythes sur Tesla et les voitures √©lectriques</a></li>
<li><a href="../fr449984/index.html">Google Actualit√©s et Leo Tolstoy: visualisation des incorporations de mots Word2Vec √† l'aide de t-SNE</a></li>
<li><a href="../fr449986/index.html">Blockchain: que devons-nous construire un bo√Ætier?</a></li>
<li><a href="../fr449990/index.html">Comment se faire des amis latex, formules et Habr?</a></li>
<li><a href="../fr449992/index.html">Pr√©sentation du mod√®le de pilote simple (SDM) NodeMCU: interface utilisateur dynamique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèΩ‚Äçü§ù‚Äçüßëüèª üë©üèø‚Äçüîß üßùüèΩ C√≥mo las computadoras aprendieron a reconocer im√°genes incre√≠blemente bien üîè üõ©Ô∏è üßñüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Un importante trabajo cient√≠fico de 2012 transform√≥ el campo del software de reconocimiento de im√°genes. 


 Hoy puedo, por ejemplo, abrir Google Phot...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo las computadoras aprendieron a reconocer im√°genes incre√≠blemente bien</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455331/"><h3>  Un importante trabajo cient√≠fico de 2012 transform√≥ el campo del software de reconocimiento de im√°genes. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/0d6/b8d/67e/0d6b8d67e771c94acab7f0ed50a54ba4.jpg"><br><br>  Hoy puedo, por ejemplo, abrir Google Photos, escribir "playa" y ver un mont√≥n de mis fotos de varias playas que visit√© en la √∫ltima d√©cada.  Y nunca firm√© mis fotos: Google reconoce playas en ellas en funci√≥n de su contenido.  Esta caracter√≠stica aparentemente aburrida se basa en una tecnolog√≠a llamada "red neuronal convolucional profunda", que permite a los programas comprender im√°genes utilizando un m√©todo complejo, inaccesible a las tecnolog√≠as de generaciones anteriores. <br><br>  En los √∫ltimos a√±os, los investigadores han descubierto que la precisi√≥n del software mejora a medida que construyen redes neuronales (NS) m√°s profundas y las capacitan en conjuntos de datos cada vez m√°s grandes.  Esto cre√≥ una necesidad insaciable de potencia inform√°tica y enriqueci√≥ a los fabricantes de GPU como Nvidia y AMD.  Hace unos a√±os, Google desarroll√≥ sus propios chips especiales para la Asamblea Nacional, mientras que otras compa√±√≠as est√°n tratando de mantenerse al d√≠a. <br><a name="habracut"></a><br>  En Tesla, por ejemplo, Andrei Karpati, un experto en aprendizaje profundo, ha sido nombrado jefe del proyecto Piloto autom√°tico.  Ahora el fabricante de autom√≥viles est√° desarrollando su propio chip para acelerar el trabajo del NS en futuras versiones del piloto autom√°tico.  O tome Apple: los chips A11 y A12, centrales para los √∫ltimos iPhones, tienen un " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">procesador neuronal</a> " Neural Engine que acelera el NS y permite que las aplicaciones de reconocimiento de imagen y voz funcionen mejor. <br><br>  Los expertos que entrevist√© para este art√≠culo siguen el comienzo del auge del aprendizaje profundo en un trabajo espec√≠fico: AlexNet, que lleva el nombre del autor principal, Alex Krizhevsky.  "Creo que 2012 fue un a√±o hist√≥rico cuando sali√≥ el trabajo de AlexNet", dijo Sean Gerrish, experto en defensa y autor del libro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥mo piensan los autos inteligentes</a> ". <br><br>  Hasta 2012, las redes neuronales profundas (GNS) eran un poco atrasados ‚Äã‚Äãen el mundo de la regi√≥n de Mosc√∫.  Pero luego Krizhevsky y sus colegas de la Universidad de Toronto participaron en la prestigiosa competencia para el reconocimiento de im√°genes, y su programa super√≥ dram√°ticamente en precisi√≥n todo lo que se desarroll√≥ antes.  Casi al instante, STS se convirti√≥ en la tecnolog√≠a l√≠der en reconocimiento de im√°genes.  Otros investigadores que utilizan esta tecnolog√≠a pronto demostraron nuevas mejoras en la precisi√≥n del reconocimiento. <br><br>  En este art√≠culo, profundizaremos en el aprendizaje profundo.  Explicar√© qu√© es NS, c√≥mo est√°n capacitados y por qu√© requieren tales recursos inform√°ticos.  Y luego explicar√© por qu√© cierto tipo de NS (redes de convoluci√≥n profunda) entienden las im√°genes tan bien.  No te preocupes, habr√° muchas fotos. <br><br><h2>  Un ejemplo simple con una neurona </h2><br>  El concepto de una "red neuronal" puede parecerle vago, as√≠ que comencemos con un ejemplo simple.  Suponga que desea que la Asamblea Nacional decida si conducir un autom√≥vil en funci√≥n de las se√±ales de tr√°fico verdes, amarillas y rojas.  NS puede resolver este problema con una sola neurona. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c00/2d0/dda/c002d0dda45d5fef70ab7a156ad8e7cd.png"><br><br>  Una neurona recibe datos de entrada (1 - encendido, 0 - apagado), se multiplica por el peso apropiado y suma todos los valores de los pesos.  Luego, la neurona agrega un desplazamiento que define el valor umbral para la "activaci√≥n" de la neurona.  En este caso, si la salida es positiva, creemos que la neurona se ha activado, y viceversa.  La neurona es equivalente a la desigualdad "verde - rojo - 0.5&gt; 0".  Si resulta ser cierto, es decir, el verde est√° encendido y el rojo no est√° encendido, entonces el autom√≥vil debe irse. <br><br>  En NS real, las neuronas artificiales dan otro paso.  Al sumar una entrada ponderada y agregar un desplazamiento, la neurona usa una funci√≥n de activaci√≥n no lineal.  A menudo se usa una funci√≥n sigmoidea, en forma de S, que siempre produce un valor de 0 a 1. <br><br>  El uso de la funci√≥n de activaci√≥n no cambiar√° el resultado de nuestro modelo simple de sem√°foro (solo necesitamos usar un valor umbral de 0.5, no 0).  Pero la no linealidad de las funciones de activaci√≥n es necesaria para que las NS modelen funciones m√°s complejas.  Sin la funci√≥n de activaci√≥n, cada NS arbitrariamente complejo se reduce a una combinaci√≥n lineal de datos de entrada.  Una funci√≥n lineal no puede simular fen√≥menos complejos en el mundo real.  La funci√≥n de activaci√≥n no lineal permite al NS aproximar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cualquier funci√≥n matem√°tica</a> . <br><br><h2>  Ejemplo de red </h2><br>  Por supuesto, hay muchas formas de aproximar una funci√≥n.  NS destaca por el hecho de que sabemos c√≥mo "entrenarlos" utilizando un poco de √°lgebra, un mont√≥n de datos y un mar de potencia inform√°tica.  En lugar de indicarle al programador que desarrolle el NS para una tarea espec√≠fica, podemos crear un software que comience con un NS bastante general, estudie un mont√≥n de ejemplos marcados y luego cambie el NS para que proporcione la etiqueta correcta para tantos ejemplos como sea posible.  La expectativa es que el NS final resumir√° los datos y producir√° las etiquetas correctas para ejemplos que no estaban previamente en la base de datos. <br><br>  El proceso que condujo a este objetivo comenz√≥ mucho antes que AlexNet.  En 1986, un tr√≠o de investigadores public√≥ un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajo hist√≥rico</a> sobre la propagaci√≥n hacia atr√°s, una tecnolog√≠a que ayud√≥ a hacer realidad el aprendizaje matem√°tico de las NS complejas. <br><br>  Para imaginar c√≥mo funciona la propagaci√≥n hacia atr√°s, veamos un NS simple descrito por Michael Nielsen en su excelente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">libro de texto GO en l√≠nea</a> .  El prop√≥sito de la red es procesar la imagen de un n√∫mero escrito a mano en una resoluci√≥n de 28x28 p√≠xeles y determinar correctamente si se escribe el n√∫mero 0, 1, 2, etc. <br><br>  Cada imagen es 28 * 28 = 784 cantidades de entrada, cada una de las cuales es un n√∫mero real de 0 a 1, que indica cu√°nto es el p√≠xel claro u oscuro.  Nielsen cre√≥ el NA de este tipo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbf/85e/fe1/fbf85efe11ae6dc62ccd0257e2325229.png"><br><br>  Cada c√≠rculo en el centro y en la columna derecha es una neurona similar a la que examinamos en la secci√≥n anterior.  Cada neurona toma un promedio ponderado de la entrada, agrega un desplazamiento y aplica una funci√≥n de activaci√≥n.  Los c√≠rculos de la izquierda no son neuronas; representan los datos de entrada de la red.  Y aunque la imagen muestra solo 8 c√≠rculos de entrada, de hecho hay 784 de ellos, uno para cada p√≠xel. <br><br>  Cada una de las 10 neuronas de la derecha debe "disparar" su propio n√∫mero: la primera debe activarse cuando se ingresa un 0 escrito a mano (y solo en este caso), la segunda cuando la red ve un 1 escrito a mano (y solo √©l), y as√≠ sucesivamente. <br><br>  Cada neurona percibe la entrada de cada neurona de la capa anterior.  Entonces, cada una de las 15 neuronas en el medio recibe 784 valores de entrada.  Cada una de estas 15 neuronas tiene un par√°metro de peso para cada uno de los 784 valores de entrada.  Esto significa que solo esta capa tiene 15 * 784 = 11 760 par√°metros de peso.  De manera similar, la capa de salida contiene 10 neuronas, cada una de las cuales recibe informaci√≥n de las 15 neuronas de la capa intermedia, lo que agrega otros 15 * 10 = 150 par√°metros de peso.  Adem√°s, la red tiene 25 variables de desplazamiento, una para cada una de las 25 neuronas. <br><br><h2>  Entrenamiento de redes neuronales </h2><br>  El objetivo del entrenamiento es ajustar estos 11,935 par√°metros para maximizar la probabilidad de que la neurona de salida deseada, y solo ella, se active cuando las redes dan una imagen de un d√≠gito escrito a mano.  Podemos hacer esto con el conocido conjunto de im√°genes MNIST, donde hay 60,000 im√°genes marcadas con una resoluci√≥n de 28x28 p√≠xeles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/16d/dab/2ee/16ddab2ee3bcd9e22d96f267e473a2f4.png"><br>  <i>160 de 60,000 im√°genes del conjunto MNIST</i> <br><br>  Nielsen demuestra c√≥mo entrenar una red usando 74 l√≠neas de c√≥digo python regular, sin ninguna biblioteca para MO.  El aprendizaje comienza eligiendo valores aleatorios para cada uno de estos 11,935 par√°metros, pesos y compensaciones.  Luego, el programa pasa por ejemplos de im√°genes, pasando por dos etapas con cada una de ellas: <br><ol><li>  El paso de propagaci√≥n directa calcula la salida de la red en funci√≥n de la imagen de entrada y los par√°metros actuales. </li><li>  El paso de retropropagaci√≥n calcula la desviaci√≥n del resultado de los datos de salida correctos y cambia los par√°metros de la red para mejorar ligeramente su eficiencia en esta imagen. </li></ol><br><br>  Un ejemplo  Digamos que la red recibi√≥ la siguiente imagen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e22/129/af7/e22129af76f6376aaa204ae02164a790.png"><br><br>  Si est√° bien calibrado, entonces el pin "7" deber√≠a ir a 1, y las otras nueve conclusiones deber√≠an ir a 0. Pero, digamos que en cambio, la red en la salida "0" da un valor de 0.8.  ¬°Esto es demasiado!  El algoritmo de entrenamiento cambia los pesos de entrada de la neurona responsable de "0" para que se acerque a 0 la pr√≥xima vez que se procese esta imagen. <br><br>  Para esto, el algoritmo de retropropagaci√≥n calcula un gradiente de error para cada peso de entrada.  Esta es una medida de c√≥mo cambiar√° el error de salida para un cambio dado en el peso de entrada.  Luego, el algoritmo usa el gradiente para decidir cu√°nto cambiar cada peso de entrada: cuanto mayor sea el gradiente, m√°s fuerte ser√° el cambio. <br><br>  En otras palabras, el proceso de entrenamiento "entrena" a las neuronas de la capa de salida para prestar menos atenci√≥n a aquellas entradas (neuronas en la capa intermedia) que las empujan a la respuesta incorrecta, y m√°s a las entradas que empujan en la direcci√≥n correcta. <br><br>  El algoritmo repite este paso para todas las dem√°s neuronas de salida.  Reduce los pesos de entrada para las neuronas "1", "2", "3", "4", "5", "6", "8" y "9" (pero no "7") para reducir el valor de estos neuronas de salida.  Cuanto mayor sea el valor de salida, mayor ser√° el gradiente del error de salida con respecto al peso de entrada, y m√°s disminuir√° su peso. <br><br>  Y viceversa, el algoritmo aumenta el peso de los datos de entrada para la salida "7", lo que hace que la neurona produzca un valor m√°s alto la pr√≥xima vez que reciba esta imagen.  Una vez m√°s, las entradas con valores mayores aumentar√°n m√°s los pesos, lo que har√° que la neurona de salida "7" preste m√°s atenci√≥n a estas entradas la pr√≥xima vez. <br><br>  Luego, el algoritmo debe realizar los mismos c√°lculos para la capa intermedia: cambie cada peso de entrada en una direcci√≥n que reducir√° los errores de red, nuevamente, acercando la salida "7" a 1, y el resto a 0. Pero cada neurona media tiene una conexi√≥n con los 10 d√≠as libres, lo que complica las cosas en dos aspectos. <br><br>  En primer lugar, el gradiente de error para cada neurona promedio depende no solo del valor de entrada, sino tambi√©n de los gradientes de error en la siguiente capa.  El algoritmo se denomina retropropagaci√≥n porque los gradientes de error de las capas posteriores de la red se propagan en la direcci√≥n opuesta y se utilizan para calcular los gradientes en las capas anteriores. <br><br>  Adem√°s, cada neurona media es una entrada para los diez d√≠as libres.  Por lo tanto, el algoritmo de entrenamiento tiene que calcular el gradiente de error, que refleja c√≥mo un cambio en un cierto peso de entrada afecta el error promedio para todas las salidas. <br><br>  La retropropagaci√≥n es un algoritmo para subir una colina: cada pasada acerca los valores de salida a los valores correctos para una imagen determinada, pero solo un poco.  Cuantos m√°s ejemplos mire el algoritmo, m√°s alto subir√° la colina hacia el conjunto √≥ptimo de par√°metros que clasifican correctamente la cantidad m√°xima de ejemplos de entrenamiento.  Para lograr una alta precisi√≥n, se requieren miles de ejemplos, y el algoritmo puede necesitar recorrer cada imagen en este conjunto docenas de veces antes de que su efectividad deje de crecer. <br><br>  Nielsen muestra c√≥mo implementar estas 74 l√≠neas en python.  Sorprendentemente, una red capacitada con un programa tan simple puede reconocer m√°s del 95% de los n√∫meros escritos a mano de la base de datos MNIST.  Con mejoras adicionales, una red simple de dos capas puede reconocer m√°s del 98% de los n√∫meros. <br><br><h2>  Avance AlexNet </h2><br>  Se podr√≠a pensar que se supon√≠a que el desarrollo del tema de la propagaci√≥n hacia atr√°s tendr√≠a lugar en la d√©cada de 1980 y dar√≠a lugar a un r√°pido progreso en el MO basado en la Asamblea Nacional, pero esto no sucedi√≥.  En la d√©cada de 1990 y principios de 2000, algunas personas trabajaron en esta tecnolog√≠a, pero el inter√©s en la Asamblea Nacional no gan√≥ impulso hasta principios de 2010. <br><br>  Esto se remonta a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la competencia ImageNet</a> , una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">competencia</a> anual de MO organizada por Stanford Fay Fay Lee, un especialista en TI.  Cada a√±o, los rivales reciben el mismo conjunto de m√°s de un mill√≥n de im√°genes para entrenamiento, cada una de las cuales se etiqueta manualmente en categor√≠as de m√°s de 1000, desde "cami√≥n de bomberos" y "hongo" hasta "guepardo".  El software de los participantes se juzga por la posibilidad de clasificar otras im√°genes que no estaban en el conjunto.  Un programa puede hacer algunas conjeturas, y su trabajo se considera exitoso si al menos una de las primeras cinco conjeturas coincide con la marca de una persona. <br><br>  La competencia comenz√≥ en 2010, y los NS profundos no jugaron un papel importante en ella en los primeros dos a√±os.  Los mejores equipos usaron diferentes t√©cnicas de MO y lograron resultados bastante promedio.  En 2010, el equipo gan√≥ con un porcentaje de errores igual a 28. En 2011, con un error del 25%. <br><br>  Y luego vino el 2012.  Un equipo de la Universidad de Toronto hizo una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">oferta</a> , m√°s tarde apodada AlexNet en honor del autor principal, Alex Krizhevsky, y dej√≥ a los rivales muy por detr√°s.  Usando NS profundo, el equipo logr√≥ una tasa de error del 16%.  Para el competidor m√°s cercano, esta cifra era 26. <br><br>  El NS descrito en el art√≠culo para el reconocimiento de escritura a mano tiene dos capas, 25 neuronas y casi 12,000 par√°metros.  AlexNet era mucho m√°s grande y complejo: ocho capas entrenadas, 650,000 neuronas y 60 millones de par√°metros. <br><br>  Se requiere una potencia de procesamiento enorme para entrenar NS de este tama√±o, y AlexNet fue dise√±ado para aprovechar la paralelizaci√≥n masiva disponible con las GPU modernas.  Los investigadores descubrieron c√≥mo dividir el trabajo de capacitaci√≥n de la red en dos GPU, que duplicaron el poder.  Y a√∫n as√≠, a pesar de la estricta optimizaci√≥n, la capacitaci√≥n de la red tom√≥ de 5 a 6 d√≠as en el hardware que estaba disponible en 2012 (en un par de Nvidia GTX 580 con 3 Gb de memoria). <br><br>  Es √∫til estudiar ejemplos de los resultados de AlexNet para comprender cu√°n serio fue este avance.  Aqu√≠ hay una imagen de un art√≠culo cient√≠fico que muestra ejemplos de im√°genes y las primeras cinco conjeturas de la red seg√∫n su clasificaci√≥n: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d36/1ee/3b6/d361ee3b61cc19de787edda63d6e1e65.png"><br><br>  AlexNet pudo reconocer la marca en la primera imagen, aunque solo hay una peque√±a forma en la esquina.  El software no solo identific√≥ correctamente al leopardo, sino que tambi√©n ofreci√≥ otras opciones cercanas: un jaguar, un guepardo, un leopardo de las nieves y un Mau egipcio.  AlexNet etiquet√≥ la foto de carpe como "ag√°rico".  Simplemente "hongo" fue la segunda versi√≥n de la red. <br><br>  "Errores" AlexNet tambi√©n son impresionantes.  Marc√≥ la foto con un d√°lmata parado detr√°s de un mont√≥n de cerezas como "d√°lmata", aunque la etiqueta oficial era "cereza".  AlexNet reconoci√≥ que hab√≠a alg√∫n tipo de baya en la foto, entre las cinco primeras opciones estaban "uvas" y "sa√∫co", simplemente no reconoci√≥ la cereza.  En una foto de un l√©mur de Madagascar sentado en un √°rbol, AlexNet dio una lista de peque√±os mam√≠feros que viven en los √°rboles.  Creo que muchas personas (incluy√©ndome a m√≠) habr√≠an puesto la firma incorrecta aqu√≠. <br><br>  La calidad del trabajo fue impresionante y demostr√≥ que el software es capaz de reconocer objetos comunes en una amplia gama de sus orientaciones y entornos.  GNS se convirti√≥ r√°pidamente en la t√©cnica m√°s popular para el reconocimiento de im√°genes, y desde entonces el mundo de MO no la ha abandonado. <br><br>  "Tras el √©xito en 2012 del m√©todo basado en GO, la mayor√≠a de los participantes en la competencia de 2013 cambiaron a redes neuronales convolucionales profundas", escribieron los patrocinadores de ImageNet.  En los a√±os siguientes, esta tendencia continu√≥, y posteriormente los ganadores trabajaron sobre la base de tecnolog√≠as b√°sicas, aplicadas por primera vez por el equipo de AlexNet.  Para 2017, los rivales, utilizando NS m√°s profundos, redujeron seriamente la tasa de error a menos de tres.  Dada la complejidad de la tarea, las computadoras han aprendido hasta cierto punto a resolverla mejor que muchas personas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/433/872/5e1/4338725e10f14ecf679878fb267394c9.png"><br>  <i>El porcentaje de errores en la clasificaci√≥n de im√°genes en diferentes a√±os.</i> <br><br><h2>  Redes de convoluci√≥n: un concepto </h2><br>  T√©cnicamente, AlexNet era un NS convolucional.  En esta secci√≥n, explicar√© lo que hace la red neuronal convolucional (SNA) y por qu√© esta tecnolog√≠a se ha vuelto cr√≠ticamente importante para los algoritmos modernos de reconocimiento de patrones. <br><br>  La red simple anteriormente discutida para el reconocimiento de escritura a mano estaba completamente conectada: cada neurona de la primera capa era una entrada para cada neurona de la segunda capa.  Dicha estructura funciona bastante bien en tareas simples con reconocimiento de n√∫meros en im√°genes de 28x28 p√≠xeles.  Pero no escala bien. <br><br>  En la base de datos de d√≠gitos manuscritos MNIST, todos los caracteres est√°n centrados.  Esto simplifica enormemente el aprendizaje, porque, por ejemplo, los siete siempre tendr√°n varios p√≠xeles oscuros en la parte superior y derecha, y la esquina inferior izquierda siempre es blanca.  Zero casi siempre tendr√° una mancha blanca en los p√≠xeles medios y oscuros en los bordes.  Una red simple y totalmente conectada puede reconocer tales patrones con bastante facilidad. <br><br>  Pero supongamos que desea crear un NS capaz de reconocer n√∫meros que puedan ubicarse en cualquier lugar de una imagen m√°s grande.  Una red totalmente conectada no funcionar√° tan bien con esta tarea, ya que no tiene una forma efectiva de reconocer caracter√≠sticas similares en formularios ubicados en diferentes partes de la imagen.  Si en su conjunto de datos de entrenamiento, la mayor√≠a de los sietes se encuentran en la esquina superior izquierda, entonces su red ser√° mejor para reconocer los sietes en la esquina superior izquierda que en cualquier otra parte de la imagen. <br><br>  Te√≥ricamente, este problema puede resolverse asegurando que su conjunto tenga muchos ejemplos de cada d√≠gito en cada una de las posiciones posibles.  Pero en la pr√°ctica esto ser√° un gran desperdicio de recursos.  Con el aumento del tama√±o de la imagen y la profundidad de la red, la cantidad de enlaces, y la cantidad de par√°metros de peso, aumentar√° explosivamente.  Necesitar√° muchas m√°s im√°genes de entrenamiento (y potencia inform√°tica) para lograr una precisi√≥n adecuada. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cuando una red neuronal aprende a reconocer una forma ubicada en un lugar de una imagen, debe poder aplicar este conocimiento para reconocer la misma forma en otras partes de la imagen. SNA proporciona una soluci√≥n elegante a este problema. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Es como si tomaras una plantilla y la adjuntases a todos los lugares de la imagen", dijo el investigador de IA Jai Teng. - ¬øTiene una plantilla con una imagen de un perro y primero la coloca en la esquina superior derecha de la imagen para ver si hay un perro all√≠? Si no, est√°s cambiando un poco la plantilla. Y as√≠ para toda la imagen. No importa d√≥nde est√© la foto del perro. La plantilla coincidir√° con ella. No necesita cada parte de la red para aprender su propia clasificaci√≥n de perros ".</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Imagine que tomamos una imagen grande y la dividimos en cuadrados de 28x28 p√≠xeles. </font><font style="vertical-align: inherit;">Luego podemos alimentar cada cuadrado de una red totalmente conectada que reconoce la escritura a mano que estudiamos antes. </font><font style="vertical-align: inherit;">Si la salida "7" se activa en al menos uno de los cuadrados, esto ser√° un signo de que hay un siete en toda la imagen. </font><font style="vertical-align: inherit;">Esto es exactamente lo que hacen las redes convolucionales.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> C√≥mo funcionaban las redes convolucionales en AlexNet </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En las redes convolucionales, tales "plantillas" se conocen como detectores de caracter√≠sticas, y el √°rea que estudian se conoce como el campo receptivo. Los detectores de caracter√≠sticas reales funcionan con campos mucho m√°s peque√±os que un cuadrado con un lado de 28 p√≠xeles. En AlexNet, los detectores de caracter√≠sticas en la primera capa convolucional trabajaron con un campo receptivo de 11x11 p√≠xeles de tama√±o. En las capas posteriores, los campos receptivos ten√≠an 3-5 unidades de ancho. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Durante el recorrido, el detector de signos de la imagen de entrada produce un mapa de signos: una red bidimensional, en la que se observa la intensidad con la que se activ√≥ el detector en diferentes partes de la imagen. Las capas convolucionales generalmente tienen m√°s de un detector, y cada una de ellas escanea la imagen en busca de diferentes patrones. AlexNet ten√≠a 96 detectores de funciones en la primera capa, entregando 96 tarjetas de funciones.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/94f/1a0/c3d/94f1a0c3deacf7903606f4ecaf040b20.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para comprender mejor esto, considere una representaci√≥n visual de los patrones estudiados por cada uno de los 96 detectores de primera capa AlexNet despu√©s de entrenar la red. Hay detectores que buscan l√≠neas horizontales o verticales, transiciones de claro a oscuro, patrones de ajedrez y muchas otras formas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Una imagen en color generalmente se representa como un mapa de p√≠xeles con tres n√∫meros para cada p√≠xel: el valor de rojo, verde y azul. La primera capa de AlexNet toma esta vista y la convierte en una vista con 96 n√∫meros. Cada "p√≠xel" en esta imagen tiene 96 valores, uno para cada detector de caracter√≠sticas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En este ejemplo, el primero de los 96 valores indica si alg√∫n punto de la imagen coincide con este patr√≥n:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/260/3fa/933/2603fa9332cbf509d9afd9dc1870e53a.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El segundo valor indica si alg√∫n punto de imagen coincide con dicho patr√≥n: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a0b/736/b01/a0b736b01ab683e1dfbd229e29904500.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">el tercer valor indica si alg√∫n punto de imagen coincide con dicho patr√≥n: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/bd9/a72/09c/bd9a7209cb808f24e18d54327974a0e7.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y as√≠ sucesivamente para 93 detectores de caracter√≠sticas en la primera capa AlexNet. La primera capa produce una nueva representaci√≥n de la imagen, donde cada p√≠xel es un vector en 96 dimensiones (explicar√© m√°s adelante que esta representaci√≥n se reduce 4 veces). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esta es la primera capa de AlexNet. Luego hay cuatro capas convolucionales m√°s, cada una de las cuales toma la salida de la anterior como entrada.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como vimos, la primera capa revela patrones b√°sicos, como l√≠neas horizontales y verticales, transiciones de claro a oscuro y curvas. El segundo nivel los usa como un bloque de construcci√≥n para reconocer formas ligeramente m√°s complejas. Por ejemplo, la segunda capa podr√≠a tener un detector de caracter√≠sticas que encuentre c√≠rculos utilizando una combinaci√≥n de las salidas de los detectores de caracter√≠sticas de la primera capa que encuentren curvas. La tercera capa encuentra formas a√∫n m√°s complejas combinando caracter√≠sticas de la segunda capa. El cuarto y quinto encuentran patrones a√∫n m√°s complejos. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los investigadores Matthew Zeiler y Rob Fergus publicaron un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">excelente trabajo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> en 2014 </font><font style="vertical-align: inherit;">, que proporciona formas muy √∫tiles para visualizar patrones reconocidos por una red neuronal de cinco capas similar a ImageNet.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En la siguiente presentaci√≥n de diapositivas tomada de su trabajo, cada imagen, excepto la primera, tiene dos mitades. A la derecha, ver√° ejemplos de miniaturas que han activado fuertemente un detector de caracter√≠sticas en particular. Se recogen en nueve, y cada grupo corresponde a su propio detector. A la izquierda hay un mapa que muestra exactamente qu√© p√≠xeles en esta miniatura son los m√°s responsables de la coincidencia. Esto es especialmente evidente en la quinta capa, ya que hay detectores de caracter√≠sticas que reaccionan fuertemente a los perros, logotipos, ruedas, etc. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2c/beb/74e/a2cbeb74e2f71a9b1b84fbea587294b2.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La primera capa: patrones y formas simples. La </font></font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/701/ebd/501/701ebd5013d881b6892c66c3fb63d77f.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">segunda capa: comienzan a aparecer peque√±as estructuras. Los </font></font></i> <font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;">detectores de </font></i><i><font style="vertical-align: inherit;">caracter√≠sticas </font></i></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/34d/283/91a/34d28391a4bb2d0804e15d12992208ba.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en la tercera capa pueden reconocer formas m√°s complejas, como ruedas de autom√≥viles, panales e incluso siluetas de personas.</font></font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/41a/ee2/cb6/41aee2cb61324edc33313a0b01c874b5.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La cuarta capa es capaz de distinguir formas complejas, como las caras de los perros o las patas de los p√°jaros. </font></font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/04b/96a/baa/04b96abaa00cf8ed2dcb994d56a5af3f.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La quinta capa puede reconocer formas muy complejas.</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Al observar las im√°genes, puede ver c√≥mo cada capa posterior puede reconocer patrones cada vez m√°s complejos. La primera capa reconoce patrones simples que no son como nada. El segundo reconoce texturas y formas simples. En la tercera capa, se hacen visibles formas reconocibles como ruedas y esferas rojo anaranjado (tomates, mariquitas, algo m√°s).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En la primera capa, el lado del campo receptivo es 11, y en las posteriores, de tres a cinco. Pero recuerde, las capas posteriores reconocen mapas de caracter√≠sticas generados por capas anteriores, por lo que cada uno de sus "p√≠xeles" denota varios p√≠xeles de la imagen original. Por lo tanto, el campo receptivo de cada capa incluye una mayor parte de la primera imagen que las capas anteriores. Esto es parte de la raz√≥n por la cual las miniaturas en las capas posteriores se ven m√°s complejas que en las anteriores. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La quinta y √∫ltima capa de la red es capaz de reconocer una impresionante variedad de elementos. Por ejemplo, mira esta imagen que seleccion√© en la esquina superior derecha de la imagen correspondiente a la quinta capa:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e82/3fb/895/e823fb8956c1b12d92b32607c41837ec.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Las nueve im√°genes de la derecha pueden no ser iguales. Pero si observa los nueve mapas de calor de la izquierda, ver√° que este detector de funciones no se enfoca en los objetos en primer plano de las fotos. ¬°En cambio, se concentra en la hierba en el fondo de cada uno de ellos! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obviamente, un detector de hierba es √∫til si una de las categor√≠as que est√° tratando de identificar es "hierba", pero puede ser √∫til para muchas otras categor√≠as. Despu√©s de cinco capas convolucionales, AlexNet tiene tres capas conectadas completamente, como nuestra red para el reconocimiento de escritura a mano. Estas capas examinan cada uno de los mapas de caracter√≠sticas emitidos por cinco capas convolucionales, tratando de clasificar la imagen en una de las 1000 categor√≠as posibles.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entonces, si hay hierba en el fondo, entonces con una alta probabilidad habr√° un animal salvaje en la imagen. </font><font style="vertical-align: inherit;">Por otro lado, si hay hierba en el fondo, es menos probable que sea una imagen de muebles en la casa. </font><font style="vertical-align: inherit;">Estos y otros detectores de caracter√≠sticas de quinta capa proporcionan una tonelada de informaci√≥n sobre el contenido probable de la foto. </font><font style="vertical-align: inherit;">Las √∫ltimas capas de la red sintetizan esta informaci√≥n para proporcionar una suposici√≥n basada en hechos sobre lo que generalmente se representa en la imagen.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Lo que hace que las capas convolucionales sean diferentes: pesos de entrada comunes </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vimos que los detectores de caracter√≠sticas en capas convolucionales muestran un reconocimiento de patrones impresionante, pero hasta ahora no he explicado c√≥mo funcionan realmente las redes convolucionales. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La capa convolucional (SS) consta de neuronas. Ellos, como cualquier neurona, toman un promedio ponderado en la entrada y usan la funci√≥n de activaci√≥n. Los par√°metros se entrenan utilizando t√©cnicas de propagaci√≥n hacia atr√°s. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pero, a diferencia del NS anterior, el SS no est√° completamente conectado. Cada neurona recibe informaci√≥n de una peque√±a fracci√≥n de las neuronas de la capa anterior. Y, lo que es m√°s importante, las neuronas de red convolucionales tienen pesos de entrada comunes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Veamos la primera neurona del primer AlexNet SS con m√°s detalle. El campo receptivo de esta capa tiene un tama√±o de 11x11 p√≠xeles, por lo que la primera neurona estudia un cuadrado de 11x11 p√≠xeles en una esquina de la imagen. Esta neurona recibe informaci√≥n de estos 121 p√≠xeles, y cada p√≠xel tiene tres valores: rojo, verde y azul. Por lo tanto, en general, la neurona tiene 363 par√°metros de entrada. Como cualquier neurona, esta toma un promedio ponderado de 363 par√°metros y les aplica una funci√≥n de activaci√≥n. Y, dado que los par√°metros de entrada son 363, los par√°metros de peso tambi√©n necesitan 363.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La segunda neurona de la primera capa es similar a la primera. Tambi√©n estudia los cuadrados de 11x11 p√≠xeles, pero su campo receptivo se desplaza cuatro p√≠xeles en relaci√≥n con el primero. Los dos campos tienen una superposici√≥n de 7 p√≠xeles, por lo que la red no pierde de vista los patrones interesantes que caen en la uni√≥n de dos cuadrados. La segunda neurona tambi√©n toma 363 par√°metros que describen el cuadrado 11x11, multiplica cada uno de ellos por peso, agrega y aplica la funci√≥n de activaci√≥n. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pero en lugar de usar un conjunto separado de 363 pesos, la segunda neurona usa los mismos pesos que la primera. El p√≠xel superior izquierdo de la primera neurona usa los mismos pesos que el p√≠xel superior izquierdo de la segunda. Por lo tanto, ambas neuronas est√°n buscando el mismo patr√≥n; sus campos receptivos simplemente se desplazan 4 p√≠xeles entre s√≠.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Naturalmente, hay m√°s de dos neuronas: en la red 55x55 hay 3025 neuronas. Cada uno de ellos usa el mismo conjunto de 363 pesos que los dos primeros. Juntas, todas las neuronas forman un detector de caracter√≠sticas que "escanea" la imagen en busca del patr√≥n deseado, que puede ubicarse en cualquier lugar. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recuerde que la primera capa AlexNet tiene 96 detectores de caracter√≠sticas. Las 3025 neuronas que acabo de mencionar forman uno de estos 96 detectores. Cada uno de los 95 restantes es un grupo separado de 3025 neuronas. Cada grupo de 3025 neuronas usa un conjunto com√∫n de 363 pesos; sin embargo, para cada uno de los 95 grupos tiene el suyo.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los HF se entrenan utilizando la misma propagaci√≥n hacia atr√°s que se usa para redes completamente conectadas, pero la estructura convolucional hace que el proceso de aprendizaje sea m√°s eficiente y efectivo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Usar la convoluci√≥n realmente ayuda: los par√°metros se pueden reutilizar", dijo Sean Gerrish, experto en defensa y autorizaci√≥n. </font><font style="vertical-align: inherit;">Esto reduce dr√°sticamente la cantidad de pesos de entrada que la red tiene que aprender, lo que le permite producir mejores resultados con menos ejemplos de capacitaci√≥n. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aprender en una parte de la imagen da como resultado un reconocimiento mejorado del mismo patr√≥n en otras partes de la imagen. </font><font style="vertical-align: inherit;">Esto permite que la red logre un alto rendimiento en una cantidad mucho menor de ejemplos de capacitaci√≥n.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> La gente r√°pidamente se dio cuenta del poder de las redes convolucionales profundas. </font></font></h2><br>  El trabajo de AlexNet se convirti√≥ en una sensaci√≥n en la comunidad acad√©mica de la regi√≥n de Mosc√∫, pero su importancia se entendi√≥ r√°pidamente en la industria de TI.  Google estaba especialmente interesado en ella. <br><br>  En 2013, Google adquiri√≥ una startup fundada por los autores AlexNet.  La compa√±√≠a utiliz√≥ esta tecnolog√≠a para agregar una nueva funci√≥n de b√∫squeda de fotos a Google Photos.  "Tomamos la investigaci√≥n avanzada y la pusimos en funcionamiento poco m√°s de seis meses despu√©s", escribi√≥ Chuck Rosenberg de Google. <br><br>  Mientras tanto, en 2013, se describi√≥ c√≥mo Google usa GSS para reconocer direcciones de fotos de Google Street View.  "Nuestro sistema nos ayud√≥ a extraer casi 100 millones de direcciones f√≠sicas de estas im√°genes", escribieron los autores. <br><br>  Los investigadores descubrieron que la eficacia de NS crece con una profundidad creciente.  "Descubrimos que la eficacia de este enfoque aumenta con la profundidad del SCN, y las arquitecturas m√°s profundas que entrenamos muestran los mejores resultados", escribi√≥ el equipo de Google Street View.  "Nuestros experimentos sugieren que las arquitecturas m√°s profundas pueden producir una mayor precisi√≥n, pero con una desaceleraci√≥n en la eficiencia". <br><br>  Entonces, despu√©s de AlexNet, las redes comenzaron a profundizarse.  El equipo de Google hizo una oferta en la competencia en 2014, solo dos a√±os despu√©s de que AlexNet gan√≥ en 2012. Tambi√©n se bas√≥ en un SNA profundo, pero Goolge utiliz√≥ una red mucho m√°s profunda de 22 capas para lograr una tasa de error de 6,7%: esta fue una mejora importante en comparaci√≥n con el 16% de AlexNet. <br><br>  Pero al mismo tiempo, las redes m√°s profundas funcionaron mejor solo con conjuntos m√°s grandes de datos de entrenamiento.  Por lo tanto, Gerrish dice que el conjunto de datos y la competencia ImageNet jugaron un papel importante en el √©xito del SNA.  Recuerde que en la competencia ImageNet, los participantes reciben un mill√≥n de im√°genes y se les pide que las clasifiquen en 1,000 categor√≠as. <br><br>  "Si tiene un mill√≥n de im√°genes para capacitaci√≥n, cada clase incluye 1,000 im√°genes", dijo Gerrish.  Sin un conjunto de datos tan grande, dijo, "tendr√≠as demasiadas opciones para entrenar la red". <br><br>  En los √∫ltimos a√±os, los expertos se est√°n concentrando cada vez m√°s en recopilar una gran cantidad de datos para capacitar redes m√°s profundas y m√°s precisas.  Es por eso que las compa√±√≠as que desarrollan autom√≥viles rob√≥ticos se concentran en correr en la v√≠a p√∫blica: las im√°genes y videos de estos viajes se env√≠an a la sede y se utilizan para entrenar a las empresas NS. <br><br><h2>  Auge de la computaci√≥n de aprendizaje profundo </h2><br>  El descubrimiento del hecho de que las redes m√°s profundas y los conjuntos de datos m√°s grandes pueden mejorar el rendimiento de NS ha creado una sed insaciable por una potencia inform√°tica cada vez mayor.  Uno de los componentes principales del √©xito de AlexNet fue la idea de que el entrenamiento matricial se usa en el entrenamiento NS, que se puede realizar de manera eficiente en GPU bien paralelizables. <br><br>  "Los NS est√°n bien paralelos", dijo Jai Ten, un investigador de MO.  Las tarjetas gr√°ficas, que proporcionan una enorme potencia de procesamiento en paralelo para videojuegos, han demostrado ser √∫tiles para las NS. <br><br>  "La parte central de la GPU, una multiplicaci√≥n matricial muy r√°pida, result√≥ ser la parte central para el trabajo de la Asamblea Nacional", dijo Ten. <br><br>  Todo esto ha sido exitoso para los principales fabricantes de GPU, Nvidia y AMD.  Ambas compa√±√≠as han desarrollado nuevos chips espec√≠ficamente adaptados a las necesidades de la aplicaci√≥n MO, y ahora las aplicaciones de IA son responsables de una parte importante de las ventas de GPU de estas compa√±√≠as. <br><br>  En 2016, Google anunci√≥ la creaci√≥n de un chip especial, la Unidad de Procesamiento de Tensor (TPU), dise√±ada para operar en la Asamblea Nacional.  "Aunque Google estaba considerando la posibilidad de crear circuitos integrados de prop√≥sito especial (ASIC) en 2006, esta situaci√≥n se volvi√≥ urgente en 2013", <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">escribi√≥</a> un representante de la compa√±√≠a el a√±o pasado.  "Fue entonces cuando nos dimos cuenta de que los requisitos de r√°pido crecimiento de la Asamblea Nacional para la potencia inform√°tica pueden requerir que dupliquemos la cantidad de centros de datos que tenemos". <br><br>  Al principio, solo los propios servicios de Google ten√≠an acceso a TPU, pero luego la compa√±√≠a permiti√≥ que todos usaran esta tecnolog√≠a a trav√©s de una plataforma de computaci√≥n en la nube. <br><br>  Por supuesto, Google no es la √∫nica compa√±√≠a que trabaja en chips de inteligencia artificial.  Solo algunos ejemplos: en las √∫ltimas versiones de los chips de iPhone <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hay un</a> "n√∫cleo neuronal" optimizado para operaciones con el NS.  Intel est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desarrollando</a> su propia l√≠nea de chips optimizados para GO.  Tesla <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">anunci√≥</a> recientemente el rechazo de los chips de Nvidia a favor de sus propios chips NS.  Tambi√©n se rumorea que Amazon est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajando</a> en sus chips de inteligencia artificial. <br><br><h2>  ¬øPor qu√© las redes neuronales profundas son dif√≠ciles de entender? </h2><br>  Le expliqu√© c√≥mo funcionan las redes neuronales, pero no le expliqu√© por qu√© funcionan tan bien.  No est√° claro c√≥mo exactamente la inmensa cantidad de c√°lculos matriciales permite que un sistema inform√°tico distinga un jaguar de un guepardo y el sa√∫co de la grosella. <br><br>  Quiz√°s la cualidad m√°s notable de la Asamblea Nacional es que no lo hacen.  La convoluci√≥n permite que el NS entienda la separaci√≥n sil√°bica: pueden determinar si la imagen de la esquina superior derecha de la imagen es similar a la imagen en la esquina superior izquierda de otra imagen. <br><br>  Pero al mismo tiempo, el SCN no tiene idea de la geometr√≠a.  No pueden reconocer la similitud de las dos im√°genes si se giran 45 grados o se duplican.  SNA no intenta comprender la estructura tridimensional de los objetos y no puede tener en cuenta las diferentes condiciones de iluminaci√≥n. <br><br>  Pero al mismo tiempo, los NS pueden reconocer fotos de perros tomadas tanto de frente como de lado, y no importa si el perro ocupa una peque√±a parte de la imagen o una grande.  Como lo hacen  Resulta que si hay suficientes datos, un enfoque estad√≠stico con enumeraci√≥n directa puede hacer frente a la tarea.  El SNA no est√° dise√±ado para que pueda "imaginar" c√≥mo se ver√≠a una imagen en particular desde un √°ngulo diferente o en diferentes condiciones, pero con un n√∫mero suficiente de ejemplos etiquetados, puede aprender todas las variaciones posibles de la imagen por simple repetici√≥n. <br><br>  Hay evidencia de que el sistema visual de las personas funciona de manera similar.  Mire un par de im√°genes: primero estudie cuidadosamente la primera y luego abra la segunda. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d43/861/b2d/d43861b2ddeebcec572cab31c9ddb81a.png"><br>  <i>Primera foto</i> <br><br><div class="spoiler">  <b class="spoiler_title">Segunda foto</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/529/451/bde/529451bde2016793fd9cfe4ec092b46a.png"><br></div></div><br><br>  El creador de la imagen tom√≥ la fotograf√≠a de alguien y puso los ojos y la boca al rev√©s.  La imagen parece relativamente normal cuando la miras al rev√©s, porque el sistema visual humano est√° acostumbrado a ver los ojos y la boca en esta posici√≥n.  Pero si observa la imagen en la orientaci√≥n correcta, puede ver inmediatamente que la cara est√° extra√±amente distorsionada. <br><br>  Esto sugiere que el sistema visual humano se basa en las mismas t√©cnicas de reconocimiento de patrones crudos que el NS.  Si observamos algo que casi siempre es visible en una orientaci√≥n, el ojo humano, podemos reconocerlo mucho mejor en su orientaci√≥n normal. <br><br>  Los NS reconocen bien las im√°genes utilizando todo el contexto disponible en ellas.  Por ejemplo, los autom√≥viles generalmente circulan por carreteras.  Los vestidos generalmente se usan en el cuerpo de una mujer o se cuelgan en un armario.  Las aeronaves generalmente se disparan contra el cielo o gobiernan en la pista.  Nadie ense√±a espec√≠ficamente al NS estas correlaciones, pero con un n√∫mero suficiente de ejemplos etiquetados, la red misma puede aprenderlos. <br><br>  En 2015, los investigadores de Google intentaron comprender mejor el NS, "ejecut√°ndolos al rev√©s".  En lugar de usar im√°genes para entrenar NS, usaron NS entrenado para cambiar las im√°genes.  Por ejemplo, comenzaron con una imagen que conten√≠a ruido aleatorio, y luego la cambiaron gradualmente para que activara fuertemente una de las neuronas de salida del NS; de hecho, le pidieron al NS que "dibujara" una de las categor√≠as que se le ense√±√≥ a reconocer.  En un caso interesante, forzaron al NS a generar im√°genes que activan el NS, entrenados para reconocer las pesas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ece/817/a18/ece817a18e8c2fc63281cb0a1773ac91.png"><br><br>  "Por supuesto, hay pesas aqu√≠, pero ni una sola imagen de pesas parece completa sin la presencia de un cuerpo muscular muscular que las levante", escribieron los investigadores de Google. <br><br>  A primera vista parece extra√±o, pero en realidad no es tan diferente de lo que hace la gente.  Si vemos un objeto peque√±o o borroso en la imagen, buscamos una pista en su entorno para comprender lo que puede suceder all√≠.  Las personas, obviamente, hablan de las im√°genes de manera diferente, utilizando una comprensi√≥n conceptual compleja del mundo que las rodea.  Pero al final, el STS reconoce bien las im√°genes porque aprovechan al m√°ximo todo el contexto representado en ellas, y esto no es muy diferente de c√≥mo las personas lo hacen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/455331/">https://habr.com/ru/post/455331/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../455318/index.html">¬øCu√°les son las √°reas de aplicaci√≥n de la impresi√≥n 3D?</a></li>
<li><a href="../455319/index.html">Artista 3D de flujo de trabajo. C√≥mo no ahogarse en una tonelada de informaci√≥n. Parte 1</a></li>
<li><a href="../455321/index.html">H√°galo usted mismo dom√≥tica</a></li>
<li><a href="../455325/index.html">Portar aplicaciones de escritorio a .NET Core</a></li>
<li><a href="../455329/index.html">Anuncio de extensi√≥n de herramientas de Azure IoT Edge (versi√≥n preliminar)</a></li>
<li><a href="../455333/index.html">¬øQui√©n puso Python en la actualizaci√≥n de Windows 10 de mayo de 2019?</a></li>
<li><a href="../455335/index.html">Petty Petty Joy # 3: Poes√≠a</a></li>
<li><a href="../455337/index.html">¬øQui√©n agreg√≥ Python a la √∫ltima actualizaci√≥n de Windows?</a></li>
<li><a href="../455339/index.html">Excavando tumbas, SQL Server, a√±os de outsourcing y tu primer proyecto</a></li>
<li><a href="../455341/index.html">Lo que se sabe sobre la certificaci√≥n ITIL 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
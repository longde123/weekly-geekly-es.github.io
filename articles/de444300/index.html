<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò® üñêüèº üë©üèº‚Äçüé® Die Entwicklung der Architektur des Handels- und Clearingsystems der Moskauer B√∂rse. Teil 1 üë∂üèº üëÉüèª üîÑ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! Mein Name ist Sergey Kostanbaev, an der B√∂rse entwickle ich den Kern des Handelssystems. 

 Wenn die New Yorker B√∂rse in Hollywood-F...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Entwicklung der Architektur des Handels- und Clearingsystems der Moskauer B√∂rse. Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/moex/blog/444300/"><img src="https://habrastorage.org/webt/1l/tg/fk/1ltgfktpjwjmzxxty7fnwez8zh0.jpeg"><br><br>  Hallo allerseits!  Mein Name ist Sergey Kostanbaev, an der B√∂rse entwickle ich den Kern des Handelssystems. <br><br>  Wenn die New Yorker B√∂rse in Hollywood-Filmen gezeigt wird, sieht es immer so aus: Menschenmassen schreien etwas, winken Papier, es herrscht v√∂lliges Chaos.  Wir hatten dies nie an der Moskauer B√∂rse, da der Handel fast von Anfang an elektronisch abgewickelt wurde und auf zwei Hauptplattformen basiert - Spectra (Derivatemarkt) und ASTS (W√§hrungs-, Aktien- und Geldm√§rkte).  Und heute m√∂chte ich √ºber die Entwicklung der Architektur des ASTS-Handels- und Clearingsystems sprechen, √ºber verschiedene L√∂sungen und Erkenntnisse.  Die Geschichte wird lang sein, also musste ich sie in zwei Teile teilen. <br><a name="habracut"></a><br>  Wir sind eine der wenigen B√∂rsen der Welt, die mit Verm√∂genswerten aller Klassen handeln und eine umfassende Palette von B√∂rsendiensten anbieten.  Zum Beispiel haben wir im vergangenen Jahr den zweiten Platz in Bezug auf das Handelsvolumen von Anleihen weltweit belegt, den 25. Platz unter allen B√∂rsen und den 13. Platz nach Kapitalisierung unter den √∂ffentlichen B√∂rsen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4cb/cfc/903/4cbcfc90328c075abc687564ad382bd5.png"><br><br>  F√ºr professionelle Bieter sind Parameter wie Reaktionszeit, Stabilit√§t der Zeitverteilung (Jitter) und Zuverl√§ssigkeit des gesamten Komplexes von entscheidender Bedeutung.  Derzeit verarbeiten wir zig Millionen Transaktionen pro Tag.  Die Verarbeitung jeder Transaktion durch den Systemkern dauert mehrere zehn Sekunden.  Nat√ºrlich ist bei Mobilfunkbetreibern zu Neujahr oder bei Suchmaschinen die Auslastung selbst h√∂her als bei uns, aber in Bezug auf die Auslastung, gepaart mit den oben genannten Merkmalen, k√∂nnen nur wenige mit uns vergleichen, wie es mir scheint.  Gleichzeitig ist es f√ºr uns wichtig, dass das System keine Sekunde langsamer wird, absolut stabil arbeitet und alle Benutzer unter gleichen Bedingungen sind. <br><br><h2>  Ein bisschen Geschichte </h2><br>  1994 wurde das australische ASTS-System an der Moskauer Interbank Currency Exchange (MICEX) eingef√ºhrt, und von diesem Moment an k√∂nnen Sie die russische Geschichte des elektronischen Handels z√§hlen.  1998 wurde die Architektur der B√∂rse f√ºr die Einf√ºhrung des Internethandels modernisiert.  Seitdem gewinnt die Geschwindigkeit der Einf√ºhrung neuer L√∂sungen und architektonischer √Ñnderungen in allen Systemen und Subsystemen nur noch an Dynamik. <br><br>  In jenen Jahren arbeitete das Austauschsystem mit Hi-End-Hardware - den hochzuverl√§ssigen HP Superdome 9000-Servern (basierend auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PA-RISC-Architektur</a> ), die absolut alles duplizierten: die E / A-Subsysteme, das Netzwerk, den RAM (tats√§chlich gab es ein RAID-Array aus dem RAM ), Prozessoren (Hot-Swapping unterst√ºtzt).  Es war m√∂glich, eine beliebige Komponente des Servers zu √§ndern, ohne den Computer anzuhalten.  Wir haben uns auf diese Ger√§te verlassen und sie als nahezu st√∂rungsfrei angesehen.  Das Betriebssystem war Unix-√§hnliches HP UX. <br><br>  Aber seit ungef√§hr 2010 ist ein Ph√§nomen wie der Hochfrequenzhandel (HFT) oder der Hochfrequenzhandel, einfach ausgedr√ºckt, Austauschroboter, aufgetreten.  In nur 2,5 Jahren hat sich die Auslastung unserer Server um das 140-fache erh√∂ht. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/251/646/529/25164652921c8d56c1fa5fd9219b7131.png"><br><br>  Es war unm√∂glich, einer solchen Belastung mit der alten Architektur und Ausr√ºstung standzuhalten.  Es war notwendig, sich irgendwie anzupassen. <br><br><h2>  Starten Sie </h2><br>  Anfragen an das Austauschsystem k√∂nnen in zwei Typen unterteilt werden: <br><br><ul><li>  Transaktionen  Wenn Sie Dollar, Aktien oder etwas anderes kaufen m√∂chten, senden Sie eine Transaktion an das Handelssystem und erhalten Sie eine Antwort √ºber den Erfolg. </li><li>  Informationsanfragen.  Wenn Sie den aktuellen Preis erfahren m√∂chten, sehen Sie sich das Auftragsbuch oder die Indizes an und senden Sie dann Informationsanfragen. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/afa/3cb/080/afa3cb0800fc3fd2c4bc83348e00bca2.png"><br><br>  Schematisch kann der Kern des Systems in drei Ebenen unterteilt werden: <br><br><ul><li>  Die Kundenebene, auf der Makler und Kunden arbeiten.  Alle interagieren mit Zugriffsservern. </li><li>  Zugriffsserver (Gateways) sind Caching-Server, die alle Informationsanforderungen lokal verarbeiten.  M√∂chten Sie wissen, zu welchem ‚Äã‚ÄãPreis Sberbank-Aktien jetzt gehandelt werden?  Die Anfrage geht an den Zugriffsserver. </li><li>  Wenn Sie jedoch Aktien kaufen m√∂chten, befindet sich die Anfrage bereits auf dem zentralen Server (Trade Engine).  F√ºr jeden Markttyp gibt es einen solchen Server, sie spielen eine entscheidende Rolle, und wir haben dieses System f√ºr sie entwickelt. </li></ul><br>  Der Kern des Handelssystems ist eine knifflige In-Memory-Datenbank, in der alle Transaktionen B√∂rsentransaktionen sind.  Die Basis wurde in C geschrieben, von den externen Abh√§ngigkeiten gab es nur die libc-Bibliothek und es gab keine dynamische Speicherzuordnung.  Um die Verarbeitungszeit zu verk√ºrzen, beginnt das System mit einem statischen Satz von Arrays und einer statischen Verlagerung von Daten: Zuerst werden alle Daten f√ºr den aktuellen Tag in den Speicher geladen, und dann werden keine Festplattenzugriffe ausgef√ºhrt. Alle Arbeiten werden nur im Speicher ausgef√ºhrt.  Beim Systemstart sind alle Referenzdaten bereits sortiert, sodass die Suche sehr effizient funktioniert und zur Laufzeit wenig Zeit in Anspruch nimmt.  Alle Tabellen werden mit aufdringlichen Listen und B√§umen f√ºr dynamische Datenstrukturen erstellt, sodass zur Laufzeit keine Speicherzuweisung erforderlich ist. <br><br>  Lassen Sie uns kurz auf die Geschichte der Entwicklung unseres Handels- und Clearingsystems eingehen. <br>  Die erste Version der Architektur des Handels- und Clearingsystems basierte auf der sogenannten Unix-Interaktion: Shared Memory, Semaphoren und Warteschlangen wurden verwendet, und jeder Prozess bestand aus einem Thread.  Dieser Ansatz war Anfang der neunziger Jahre weit verbreitet. <br><br>  Die erste Version des Systems enthielt zwei Gateway-Ebenen und einen zentralen Server des Handelssystems.  Das Arbeitsschema war wie folgt: <br><br><ul><li>  Der Client sendet eine Anforderung, die das Gateway erreicht.  Er √ºberpr√ºft die G√ºltigkeit des Formats (aber nicht der Daten selbst) und lehnt die falsche Transaktion ab. </li><li>  Wenn eine Informationsanforderung gesendet wurde, wird sie lokal ausgef√ºhrt.  Wenn es sich um eine Transaktion handelt, wird sie an den zentralen Server umgeleitet. </li><li>  Dann verarbeitet die Handelsmaschine die Transaktion, √§ndert den lokalen Speicher und sendet eine Antwort auf die Transaktion und auf sich selbst - auf die Replikation unter Verwendung eines separaten Replikationsmechanismus. </li><li>  Das Gateway empf√§ngt eine Antwort vom zentralen Knoten und leitet sie an den Client weiter. </li><li>  Nach einer Weile empf√§ngt das Gateway die Transaktion mithilfe des Replikationsmechanismus und f√ºhrt sie diesmal lokal aus. Dabei werden die Datenstrukturen so ge√§ndert, dass in den folgenden Informationsanforderungen die tats√§chlichen Daten angezeigt werden. </li></ul><br>  Tats√§chlich wird hier das Replikationsmodell beschrieben, bei dem Gateway die im Handelssystem ausgef√ºhrten Aktionen vollst√§ndig wiederholte.  Ein separater Replikationskanal stellte dieselbe Transaktionsausf√ºhrungsreihenfolge auf mehreren Zugriffsknoten bereit. <br><br>  Da der Code Single-Threaded war, wurde ein klassisches Schema mit gegabelten Prozessen verwendet, um viele Clients zu bedienen.  Das Erstellen eines Fork f√ºr die gesamte Datenbank war jedoch sehr teuer. Daher wurden einfache Serviceprozesse verwendet, die Pakete aus TCP-Sitzungen sammelten und in eine Warteschlange (SystemV Message Queue) √ºberf√ºhrten.  Gateway und Trade Engine arbeiteten nur mit dieser Warteschlange und nahmen von dort Transaktionen zur Ausf√ºhrung entgegen.  Es war bereits unm√∂glich, eine Antwort darauf zu senden, da nicht klar ist, welcher Serviceprozess sie lesen soll.  Wir haben also auf einen Trick zur√ºckgegriffen: Jeder gegabelte Prozess hat eine Antwortwarteschlange f√ºr sich selbst erstellt, und als eine Anforderung in die eingehende Warteschlange einging, wurde ihr sofort ein Tag f√ºr die Antwortwarteschlange hinzugef√ºgt. <br><br>  Das st√§ndige Kopieren gro√üer Datenmengen aus der Warteschlange in die Warteschlange verursachte Probleme, insbesondere bei Informationsanforderungen.  Daher haben wir einen anderen Trick ausgenutzt: Zus√§tzlich zur Antwortwarteschlange hat jeder Prozess auch einen gemeinsam genutzten Speicher (SystemV Shared Memory) erstellt.  Die Pakete selbst wurden darin abgelegt, und nur das Tag wurde in der Warteschlange gespeichert, sodass Sie das Quellpaket finden k√∂nnen.  Dies half, Daten im Prozessor-Cache zu speichern. <br><br>  SystemV IPC enth√§lt Dienstprogramme zum Anzeigen des Status von Warteschlangen-, Speicher- und Semaphorobjekten.  Wir haben dies aktiv genutzt, um zu verstehen, was zu einem bestimmten Zeitpunkt im System geschieht, wo sich Pakete ansammeln, was blockiert wird usw. <br><br><h2>  Erste Modernisierung </h2><br>  Zun√§chst haben wir das Single-Process-Gateway losgeworden.  Der wesentliche Nachteil bestand darin, dass entweder eine Replikationstransaktion oder eine Informationsanforderung von einem Client verarbeitet werden konnte.  Und mit zunehmender Auslastung verarbeitet das Gateway Anforderungen l√§nger und kann den Replikationsdatenstrom nicht verarbeiten.  Wenn der Client eine Transaktion gesendet hat, m√ºssen Sie au√üerdem nur deren G√ºltigkeit √ºberpr√ºfen und weiterleiten.  Aus diesem Grund haben wir einen Gateway-Prozess durch viele Komponenten ersetzt, die parallel arbeiten k√∂nnen: Multithread-Informationen und Transaktionsprozesse, die unabh√§ngig voneinander mit einem gemeinsamen Speicherbereich mithilfe der RW-Sperre arbeiten.  Gleichzeitig haben wir Planungs- und Replikationsprozesse eingef√ºhrt. <br><br><h2>  Die Auswirkungen des Hochfrequenzhandels </h2><br>  Die obige Version der Architektur dauerte bis 2010.  Inzwischen waren wir mit der Leistung der HP Superdome-Server nicht mehr zufrieden.  Dar√ºber hinaus ist die PA-RISC-Architektur tats√§chlich gestorben, der Anbieter hat keine wesentlichen Aktualisierungen angeboten.  Infolgedessen haben wir begonnen, von HP UX / PA RISC auf Linux / x86 umzusteigen.  Der √úbergang begann mit der Anpassung der Zugangsserver. <br><br>  Warum mussten wir die Architektur erneut √§ndern?  Tatsache ist, dass der Hochfrequenzhandel das Lastprofil des Systemkerns erheblich ver√§ndert hat. <br><br>  Angenommen, wir haben eine kleine Transaktion, die zu einer erheblichen Preis√§nderung gef√ºhrt hat - jemand hat eine halbe Milliarde Dollar gekauft.  Nach einigen Millisekunden bemerken dies alle Marktteilnehmer und beginnen mit einer Korrektur.  Nat√ºrlich stehen Anfragen in einer riesigen Warteschlange, die das System f√ºr lange Zeit harken wird. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d0b/00e/ac6/d0b00eac6f1d2833db744246d58ce66a.png"><br><br>  In diesem Intervall von 50 ms betr√§gt die durchschnittliche Geschwindigkeit etwa 16.000 Transaktionen pro Sekunde.  Wenn Sie das Fenster auf 20 ms reduzieren, erhalten wir eine durchschnittliche Geschwindigkeit von 90.000 Transaktionen pro Sekunde, und in der Spitze gibt es 200.000 Transaktionen.  Mit anderen Worten, die Last ist instabil mit scharfen St√∂√üen.  Und die Anforderungswarteschlange sollte immer schnell verarbeitet werden. <br><br>  Aber warum gibt es √ºberhaupt eine Warteschlange?  In unserem Beispiel haben viele Benutzer eine Preis√§nderung festgestellt und die entsprechenden Transaktionen gesendet.  Diese kommen zu Gateway, er serialisiert sie, legt eine bestimmte Reihenfolge fest und sendet sie an das Netzwerk.  Router mischen Pakete und leiten sie weiter.  Wessen Paket fr√ºher kam, diese Transaktion "gewann".  Infolgedessen stellten B√∂rsenkunden fest, dass die Wahrscheinlichkeit einer schnellen Verarbeitung steigt, wenn dieselbe Transaktion von mehreren Gateways gesendet wurde.  Bald begannen Austauschroboter, Gateway mit Anfragen zu bombardieren, und es kam zu einer Lawine von Transaktionen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/65b/1f9/429/65b1f9429f7806a1e5e8d5e2c67c3184.png"><br><br><h2>  Eine neue Evolutionsrunde </h2><br>  Nach umfangreichen Tests und Recherchen haben wir auf den Echtzeitkern des Betriebssystems umgestellt.  Zu diesem Zweck entschieden sie sich f√ºr RedHat Enterprise MRG Linux, wo MRG f√ºr Messaging Real-Time Grid steht.  Der Vorteil von Echtzeit-Patches besteht darin, dass sie das System f√ºr die schnellstm√∂gliche Ausf√ºhrung optimieren: Alle Prozesse sind in einer FIFO-Warteschlange angeordnet, Sie k√∂nnen Kernel isolieren, keine Drops, alle Transaktionen werden in strikter Reihenfolge verarbeitet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c1/607/6e8/5c16076e8ed1a40c5e1aea471f5f0f70.png"><br>  <i>Rot - Arbeiten Sie mit einer Warteschlange in einem normalen Kernel, Gr√ºn - Arbeiten Sie in einem Echtzeitkernel.</i> <br><br>  Das Erreichen einer geringen Latenz auf normalen Servern ist jedoch nicht so einfach: <br><br><ul><li>  Der SMI-Modus, der in der x86-Architektur im Mittelpunkt der Arbeit mit wichtigen Peripherieger√§ten steht, st√∂rt stark.  Die Verarbeitung verschiedener Hardwareereignisse und die Verwaltung von Komponenten und Ger√§ten erfolgt durch die Firmware im sogenannten transparenten SMI-Modus, in dem das Betriebssystem √ºberhaupt nicht sieht, was die Firmware tut.  In der Regel bieten alle gro√üen Anbieter spezielle Erweiterungen f√ºr Firmware-Server an, mit denen sich die SMI-Verarbeitung reduzieren l√§sst. </li><li>  Es sollte keine dynamische Steuerung der Prozessorfrequenz erfolgen, dies f√ºhrt zu zus√§tzlichen Ausfallzeiten. </li><li>  Wenn das Dateisystemprotokoll zur√ºckgesetzt wird, treten im Kernel bestimmte Prozesse auf, die zu unvorhersehbaren Verz√∂gerungen f√ºhren. </li><li>  Sie m√ºssen auf Dinge wie CPU-Affinit√§t, Interrupt-Affinit√§t, NUMA achten. </li></ul><br>  Ich muss sagen, dass das Thema der Konfiguration der Linux-Hardware und des Kernels f√ºr die Echtzeitverarbeitung einen separaten Artikel verdient.  Wir haben viel Zeit mit Experimenten und Forschung verbracht, bevor wir ein gutes Ergebnis erzielt haben. <br><br>  Beim Wechsel von PA-RISC-Servern zu x86 mussten wir den Systemcode praktisch nicht viel √§ndern, sondern nur anpassen und neu konfigurieren.  Gleichzeitig wurden mehrere Fehler behoben.  Zum Beispiel zeigten sich schnell die Konsequenzen, dass PA RISC ein Big-Endian-System und x86 ein Little-Endian-System war: Beispielsweise wurden Daten nicht korrekt gelesen.  Ein schwierigerer Fehler war, dass PA RISC <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sequentiellen konsistenten</a> Speicherzugriff verwendet, w√§hrend x86 Lesevorg√§nge neu anordnen kann, sodass Code, der auf einer Plattform absolut g√ºltig ist, auf einer anderen Plattform nicht mehr funktioniert. <br><br>  Nach dem Wechsel zu x86 stieg die Produktivit√§t fast dreimal an, die durchschnittliche Transaktionsverarbeitungszeit verringerte sich auf 60 Œºs. <br><br>  Schauen wir uns nun genauer an, welche wichtigen √Ñnderungen an der Systemarchitektur vorgenommen wurden. <br><br><h2>  Hei√ües Standby-Epos </h2><br>  Bei Commodity-Servern war uns bewusst, dass diese weniger zuverl√§ssig sind.  Bei der Erstellung einer neuen Architektur haben wir daher a priori die M√∂glichkeit eines Ausfalls eines oder mehrerer Knoten angenommen.  Daher brauchten wir ein Hot-Standby-System, das sehr schnell auf Backup-Maschinen umschalten kann. <br><br>  Dar√ºber hinaus gab es weitere Anforderungen: <br><br><ul><li>  In keinem Fall sollten Sie verarbeitete Transaktionen verlieren. </li><li>  Das System muss f√ºr unsere Infrastruktur absolut transparent sein. </li><li>  Clients sollten keine Verbindungsunterbrechungen sehen. </li><li>  Die Reservierung sollte keine wesentliche Verz√∂gerung mit sich bringen, da dies ein kritischer Faktor f√ºr den Umtausch ist. </li></ul><br>  Bei der Erstellung eines Hot-Standby-Systems wurden solche Szenarien nicht als doppelte Fehler betrachtet (z. B. funktionierte das Netzwerk auf einem Server nicht mehr und der Hauptserver blieb h√§ngen).  hat die M√∂glichkeit von Fehlern in der Software nicht ber√ºcksichtigt, da diese beim Testen erkannt werden;  und ber√ºcksichtigte nicht die Fehlfunktion von Eisen. <br><br>  Als Ergebnis kamen wir zu folgendem Schema: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad3/4a6/52f/ad34a652fbe11f9023f484e9d64dd19c.png"><br><br><ul><li>  Der Hauptserver interagierte direkt mit Gateway-Servern. </li><li>  Alle auf dem Hauptserver empfangenen Transaktionen wurden sofort √ºber einen separaten Kanal auf den Sicherungsserver repliziert.  Der Schiedsrichter (Gouverneur) koordinierte den Wechsel, wenn Probleme auftraten. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/050/ca8/118/050ca81185b227e767e3de134d8b2f8e.png"></li><li>  Der Hauptserver verarbeitete jede Transaktion und wartete auf die Best√§tigung vom Sicherungsserver.  Um die Verz√∂gerung zu minimieren, haben wir uns geweigert, auf den Abschluss der Transaktion auf dem Sicherungsserver zu warten.  Da die Dauer der Transaktion √ºber das Netzwerk mit der Dauer der Transaktion vergleichbar war, wurde keine zus√§tzliche Verz√∂gerung hinzugef√ºgt. </li><li>  Wir konnten den Verarbeitungsstatus des Haupt- und Sicherungsservers nur f√ºr die vorherige Transaktion √ºberpr√ºfen, und der Verarbeitungsstatus der aktuellen Transaktion war unbekannt.  Da hier immer noch Single-Thread-Prozesse verwendet wurden, w√ºrde das Warten auf eine Antwort von Backup den gesamten Verarbeitungsablauf verlangsamen. Daher haben wir einen vern√ºnftigen Kompromiss eingegangen: Wir haben das Ergebnis der vorherigen Transaktion √ºberpr√ºft. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/e3d/34c/9f0/e3d34c9f079015074fa63cf39016d1cf.png"><br><br>  Das Schema funktionierte wie folgt. <br><br>  Angenommen, der Hauptserver reagiert nicht mehr, aber das Gateway kommuniziert weiter.  Auf dem Sicherungsserver wird ein Timeout ausgel√∂st, es wird an Governor weitergeleitet, und er weist ihm die Rolle des Hauptservers zu, und alle Gateways wechseln zum neuen Hauptserver. <br><br>  Wenn der Hauptserver wieder in Betrieb ist, wird auch ein internes Timeout ausgel√∂st, da seit einiger Zeit keine Anrufe mehr vom Gateway an den Server eingegangen sind.  Dann wendet er sich auch an den Gouverneur und schlie√üt ihn vom Plan aus.  Infolgedessen arbeitet die B√∂rse bis zum Ende des Handelszeitraums mit einem Server.  Da die Wahrscheinlichkeit eines Serverabsturzes eher gering ist, wurde ein solches Schema als durchaus akzeptabel angesehen, enthielt keine komplexe Logik und war leicht zu testen. <br><br>  <i><b>Fortsetzung folgt.</b></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de444300/">https://habr.com/ru/post/de444300/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de444288/index.html">Neue mobile Anwendung LampTest.ru</a></li>
<li><a href="../de444290/index.html">Die Grundlagen der reaktiven Programmierung mit RxJS. Teil 2. Bediener und Rohre</a></li>
<li><a href="../de444294/index.html">Wie die Gesch√§ftsluftfahrt in Russland funktioniert (FBO-Zentren)</a></li>
<li><a href="../de444296/index.html">6 n√ºtzliche Ressourcen und Dienstleistungen f√ºr potenzielle Auswanderer in die USA, nach Deutschland und Kanada</a></li>
<li><a href="../de444298/index.html">Wissenschaftler sagen, dass sie lebende Dinosaurier f√ºr 5 Jahre umgestalten k√∂nnen</a></li>
<li><a href="../de444302/index.html">Die Entwicklung der Architektur des Handels- und Clearingsystems der Moskauer B√∂rse. Teil 2</a></li>
<li><a href="../de444304/index.html">Huawei und Nutanix geben HCI-Partnerschaft bekannt</a></li>
<li><a href="../de444306/index.html">Sex, Liebe und Beziehungen durch das Prisma der Microservice-Architektur</a></li>
<li><a href="../de444308/index.html">Nachrichten aus der Spielebranche (11.-18. M√§rz 2019)</a></li>
<li><a href="../de444312/index.html">Installieren Sie ReactOS von einem USB-Stick</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
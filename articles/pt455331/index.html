<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåÑ üéØ ü§±üèΩ Como os computadores aprenderam a reconhecer imagens incrivelmente bem üçì üëåüèæ ‚õàÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Um trabalho cient√≠fico significativo a partir de 2012 transformou o campo do software de reconhecimento de imagem 


 Hoje eu posso, por exemplo, abri...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como os computadores aprenderam a reconhecer imagens incrivelmente bem</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455331/"><h3>  Um trabalho cient√≠fico significativo a partir de 2012 transformou o campo do software de reconhecimento de imagem </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/0d6/b8d/67e/0d6b8d67e771c94acab7f0ed50a54ba4.jpg"><br><br>  Hoje eu posso, por exemplo, abrir o Google Fotos, escrever ‚Äúpraia‚Äù e ver v√°rias fotos de v√°rias praias que visitei na √∫ltima d√©cada.  E nunca assinei minhas fotos: o Google reconhece as praias com base no conte√∫do.  Esse recurso aparentemente chato √© baseado em uma tecnologia chamada "rede neural convolucional profunda", que permite que os programas compreendam imagens usando um m√©todo complexo, inacess√≠vel √†s tecnologias das gera√ß√µes anteriores. <br><br>  Nos √∫ltimos anos, os pesquisadores descobriram que a precis√£o do software se torna melhor √† medida que constroem redes neurais mais profundas (NS) e as treinam em conjuntos de dados cada vez maiores.  Isso criou uma necessidade insaci√°vel de poder de computa√ß√£o e enriqueceu fabricantes de GPU, como Nvidia e AMD.  H√° alguns anos, o Google desenvolveu seus pr√≥prios chips especiais para a Assembl√©ia Nacional, enquanto outras empresas est√£o tentando acompanh√°-lo. <br><a name="habracut"></a><br>  Na Tesla, por exemplo, Andrei Karpati, especialista em aprendizado profundo, foi nomeado chefe do projeto Piloto Autom√°tico.  Agora, a montadora est√° desenvolvendo seu pr√≥prio chip para acelerar o trabalho do NS em vers√µes futuras do piloto autom√°tico.  Ou ent√£o, pegue a Apple: os chips A11 e A12, centrais para os iPhones mais recentes, t√™m um ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">processador neural</a> ‚Äù do Neural Engine que acelera o NS e permite que aplicativos de reconhecimento de imagem e voz funcionem melhor. <br><br>  Os especialistas que entrevistei para este artigo acompanham o in√≠cio do boom do aprendizado profundo em um trabalho espec√≠fico: AlexNet, em homenagem ao autor principal, Alex Krizhevsky.  "Acredito que 2012 foi um ano marcante quando o trabalho da AlexNet foi lan√ßado", disse Sean Gerrish, especialista em defesa e autor do livro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Como os carros inteligentes pensam</a> ". <br><br>  At√© 2012, as redes neurais profundas (GNS) eram uma esp√©cie de remanso no mundo da regi√£o de Moscou.  Mas ent√£o Krizhevsky e seus colegas da Universidade de Toronto participaram da prestigiada competi√ß√£o pelo reconhecimento de imagens, e seu programa superou dramaticamente em precis√£o tudo o que foi desenvolvido antes dele.  Quase instantaneamente, o STS se tornou a tecnologia l√≠der em reconhecimento de imagem.  Outros pesquisadores que usam essa tecnologia logo demonstraram novas melhorias na precis√£o do reconhecimento. <br><br>  Neste artigo, vamos nos aprofundar no aprendizado profundo.  Vou explicar o que √© o NS, como eles s√£o treinados e por que eles exigem esses recursos de computa√ß√£o.  E ent√£o explicarei por que um certo tipo de NS - redes de convolu√ß√£o profunda - entende as imagens t√£o bem.  N√£o se preocupe, haver√° muitas fotos. <br><br><h2>  Um exemplo simples com um neur√¥nio </h2><br>  O conceito de uma "rede neural" pode parecer vago para voc√™, ent√£o vamos come√ßar com um exemplo simples.  Suponha que voc√™ queira que a Assembl√©ia Nacional decida se deve dirigir um carro com base nos sinais de tr√¢nsito verde, amarelo e vermelho.  O NS pode resolver esse problema com um √∫nico neur√¥nio. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c00/2d0/dda/c002d0dda45d5fef70ab7a156ad8e7cd.png"><br><br>  Um neur√¥nio recebe dados de entrada (1 - ligado, 0 - desligado), multiplica pelo peso apropriado e soma todos os valores dos pesos.  Em seguida, o neur√¥nio adiciona um deslocamento que define o valor limite para a "ativa√ß√£o" do neur√¥nio.  Nesse caso, se o resultado for positivo, acreditamos que o neur√¥nio foi ativado - e vice-versa.  O neur√¥nio √© equivalente √† desigualdade "verde - vermelho - 0,5&gt; 0".  Se for verdade - ou seja, o verde est√° aceso e o vermelho n√£o est√° aceso -, o carro deve partir. <br><br>  Na NS real, os neur√¥nios artificiais d√£o outro passo.  Ao adicionar uma entrada ponderada e adicionar um deslocamento, o neur√¥nio usa uma fun√ß√£o de ativa√ß√£o n√£o linear.  Freq√ºentemente usado √© um sigm√≥ide, uma fun√ß√£o em forma de S, sempre produzindo um valor de 0 a 1. <br><br>  O uso da fun√ß√£o de ativa√ß√£o n√£o altera o resultado do nosso modelo simples de sem√°foro (basta usar um valor limite de 0,5, e n√£o 0).  Mas a n√£o linearidade das fun√ß√µes de ativa√ß√£o √© necess√°ria para que os NSs modelem fun√ß√µes mais complexas.  Sem a fun√ß√£o de ativa√ß√£o, cada NS arbitrariamente complexo √© reduzido a uma combina√ß√£o linear de dados de entrada.  Uma fun√ß√£o linear n√£o pode simular fen√¥menos complexos no mundo real.  A fun√ß√£o de ativa√ß√£o n√£o linear permite ao NS aproximar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">qualquer fun√ß√£o matem√°tica</a> . <br><br><h2>  Exemplo de rede </h2><br>  Obviamente, existem muitas maneiras de aproximar uma fun√ß√£o.  Os NS se destacam pelo fato de sabermos ‚Äútrein√°-los‚Äù usando um pouco de √°lgebra, um monte de dados e um mar de poder computacional.  Em vez de instruir o programador a desenvolver o NS para uma tarefa espec√≠fica, podemos criar um software que comece com um NS bastante geral, estude v√°rios exemplos marcados e depois altere o NS para fornecer o r√≥tulo correto para o maior n√∫mero poss√≠vel de exemplos.  A expectativa √© que o NS final resuma os dados e produza os r√≥tulos corretos para exemplos que n√£o estavam anteriormente no banco de dados. <br><br>  O processo que levou a esse objetivo come√ßou muito antes da AlexNet.  Em 1986, um trio de pesquisadores publicou um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho hist√≥rico</a> sobre retropropaga√ß√£o, uma tecnologia que ajudou a tornar realidade o aprendizado matem√°tico de NSs complexos. <br><br>  Para imaginar como funciona a retropropaga√ß√£o, vejamos um simples NS descrito por Michael Nielsen em seu excelente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">livro online GO</a> .  O objetivo da rede √© processar a imagem de um n√∫mero escrito √† m√£o em uma resolu√ß√£o de 28x28 pixels e determinar corretamente se o n√∫mero 0, 1, 2 etc. √© gravado. <br><br>  Cada imagem tem 28 * 28 = 784 quantidades de entrada, cada uma com um n√∫mero real de 0 a 1, indicando quanto o pixel √© claro ou escuro.  Nielsen criou o NA desse tipo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbf/85e/fe1/fbf85efe11ae6dc62ccd0257e2325229.png"><br><br>  Cada c√≠rculo no centro e na coluna da direita √© um neur√¥nio semelhante ao que examinamos na se√ß√£o anterior.  Cada neur√¥nio obt√©m uma m√©dia ponderada da entrada, adiciona um deslocamento e aplica uma fun√ß√£o de ativa√ß√£o.  Os c√≠rculos √† esquerda n√£o s√£o neur√¥nios, eles representam os dados de entrada da rede.  E embora a imagem mostre apenas 8 c√≠rculos de entrada, na verdade existem 784 deles - um para cada pixel. <br><br>  Cada um dos 10 neur√¥nios √† direita deve "acionar" seu pr√≥prio n√∫mero: o superior deve ativar quando um 0 manuscrito √© inserido (e somente nesse caso), o segundo quando a rede v√™ um 1 manuscrito (e somente ele) e assim por diante. <br><br>  Cada neur√¥nio percebe a entrada de cada neur√¥nio da camada anterior.  Portanto, cada um dos 15 neur√¥nios no meio recebe 784 valores de entrada.  Cada um desses 15 neur√¥nios possui um par√¢metro de peso para cada um dos 784 valores de entrada.  Isso significa que apenas essa camada possui 15 * 784 = 11.760 par√¢metros de peso.  Da mesma forma, a camada de sa√≠da cont√©m 10 neur√¥nios, cada um dos quais recebe entrada de todos os 15 neur√¥nios da camada do meio, o que adiciona outros 15 * 10 = 150 par√¢metros de peso.  Al√©m disso, a rede possui 25 vari√°veis ‚Äã‚Äãde deslocamento - uma para cada um dos 25 neur√¥nios. <br><br><h2>  Treinamento em redes neurais </h2><br>  O objetivo do treinamento √© ajustar esses 11.935 par√¢metros para maximizar a probabilidade de que o neur√¥nio de sa√≠da desejado - e somente ele - seja ativado quando as redes fornecerem uma imagem de um d√≠gito manuscrito.  Podemos fazer isso com o conhecido conjunto de imagens MNIST, onde existem 60.000 imagens marcadas com uma resolu√ß√£o de 28x28 pixels. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/16d/dab/2ee/16ddab2ee3bcd9e22d96f267e473a2f4.png"><br>  <i>160 de 60.000 imagens do conjunto MNIST</i> <br><br>  A Nielsen demonstra como treinar uma rede usando 74 linhas de c√≥digo python comum - sem nenhuma biblioteca para MO.  O aprendizado come√ßa escolhendo valores aleat√≥rios para cada um desses 11.935 par√¢metros, pesos e compensa√ß√µes.  Em seguida, o programa passa por exemplos de imagens, passando por duas etapas com cada uma delas: <br><ol><li>  A etapa de propaga√ß√£o direta calcula a sa√≠da da rede com base na imagem de entrada e nos par√¢metros atuais. </li><li>  A etapa de retropropaga√ß√£o calcula o desvio do resultado dos dados de sa√≠da corretos e altera os par√¢metros da rede para melhorar levemente sua efici√™ncia nesta imagem. </li></ol><br><br>  Um exemplo  Digamos que a rede tenha recebido a seguinte imagem: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e22/129/af7/e22129af76f6376aaa204ae02164a790.png"><br><br>  Se estiver bem calibrado, o pino "7" deve ir para 1 e as outras nove conclus√µes devem ir para 0. Mas, digamos que, em vez disso, a rede na sa√≠da "0" d√™ um valor de 0,8.  Isso √© demais!  O algoritmo de treinamento altera os pesos de entrada do neur√¥nio respons√°vel por "0" para que fique mais pr√≥ximo de 0 na pr√≥xima vez que esta imagem for processada. <br><br>  Para isso, o algoritmo de retropropaga√ß√£o calcula um gradiente de erro para cada peso de entrada.  Esta √© uma medida de como o erro de sa√≠da ser√° alterado para uma determinada altera√ß√£o no peso de entrada.  Em seguida, o algoritmo usa o gradiente para decidir quanto alterar cada peso de entrada - quanto maior o gradiente, mais forte a altera√ß√£o. <br><br>  Em outras palavras, o processo de treinamento "treina" os neur√¥nios da camada de sa√≠da para prestar menos aten√ß√£o √†s entradas (neur√¥nios na camada do meio) que as levam √† resposta errada, e mais √†s entradas que pressionam na dire√ß√£o certa. <br><br>  O algoritmo repete esta etapa para todos os outros neur√¥nios de sa√≠da.  Reduz os pesos de entrada dos neur√¥nios "1", "2", "3", "4", "5", "6", "8" e "9" (mas n√£o "7"), a fim de diminuir o valor desses neur√¥nios de sa√≠da.  Quanto maior o valor de sa√≠da, maior o gradiente do erro de sa√≠da em rela√ß√£o ao peso de entrada - e mais seu peso diminuir√°. <br><br>  E vice-versa, o algoritmo aumenta o peso dos dados de entrada para a sa√≠da "7", o que faz com que o neur√¥nio produza um valor mais alto na pr√≥xima vez que receber essa imagem.  Novamente, entradas com valores maiores aumentar√£o mais os pesos, o que far√° com que o neur√¥nio de sa√≠da ‚Äú7‚Äù preste mais aten√ß√£o a essas entradas na pr√≥xima vez. <br><br>  Ent√£o, o algoritmo deve executar os mesmos c√°lculos para a camada intermedi√°ria: altere cada peso de entrada em uma dire√ß√£o que reduza os erros de rede - novamente, aproximando a sa√≠da "7" de 1 e o restante a 0. Mas cada neur√¥nio m√©dio tem uma conex√£o com todos os 10 dias de folga, o que complica as coisas em dois aspectos. <br><br>  Em primeiro lugar, o gradiente de erro para cada neur√¥nio m√©dio depende n√£o apenas do valor de entrada, mas tamb√©m dos gradientes de erro na pr√≥xima camada.  O algoritmo √© chamado de retropropaga√ß√£o porque os gradientes de erro das camadas posteriores da rede se propagam na dire√ß√£o oposta e s√£o usados ‚Äã‚Äãpara calcular os gradientes nas camadas anteriores. <br><br>  Al√©m disso, cada neur√¥nio do meio √© uma entrada para todos os dez dias de folga.  Portanto, o algoritmo de treinamento deve calcular o gradiente de erro, o que reflete como uma altera√ß√£o em um determinado peso de entrada afeta o erro m√©dio de todas as sa√≠das. <br><br>  A retropropaga√ß√£o √© um algoritmo de escalar uma colina: cada passagem aproxima os valores de sa√≠da dos valores corretos para uma determinada imagem, mas apenas um pouco.  Quanto mais exemplos o algoritmo examina, mais alto ele sobe a colina em dire√ß√£o ao conjunto ideal de par√¢metros que classificam corretamente o n√∫mero m√°ximo de exemplos de treinamento.  Para obter alta precis√£o, milhares de exemplos s√£o necess√°rios e o algoritmo pode precisar percorrer cada imagem neste conjunto dezenas de vezes antes que sua efic√°cia pare de crescer. <br><br>  Nielsen mostra como implementar essas 74 linhas em python.  Surpreendentemente, uma rede treinada com um programa t√£o simples pode reconhecer mais de 95% dos n√∫meros manuscritos do banco de dados MNIST.  Com melhorias adicionais, uma rede simples de duas camadas pode reconhecer mais de 98% dos n√∫meros. <br><br><h2>  Inova√ß√£o AlexNet </h2><br>  Voc√™ pode pensar que o desenvolvimento do tema da retropropaga√ß√£o deveria ocorrer na d√©cada de 1980 e dar origem a um r√°pido progresso no MO baseado na Assembl√©ia Nacional - mas isso n√£o aconteceu.  Nos anos 90 e in√≠cio dos anos 2000, algumas pessoas trabalharam nessa tecnologia, mas o interesse na Assembl√©ia Nacional n√£o ganhou impulso at√© o in√≠cio dos anos 2010. <br><br>  Isso pode ser rastreado at√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a competi√ß√£o ImageNet</a> , uma competi√ß√£o anual de MO organizada por Stanford Fay Fay Lee, especialista em TI.  A cada ano, os rivais recebem o mesmo conjunto de mais de um milh√£o de imagens para treinamento, cada qual rotulado manualmente em categorias de mais de 1000 - de "caminh√£o de bombeiros" e "cogumelo" a "chita".  O software dos participantes √© julgado pela possibilidade de classificar outras imagens que n√£o estavam no conjunto.  Um programa pode dar alguns palpites e seu trabalho √© considerado bem-sucedido se pelo menos um dos cinco primeiros palpites corresponder √† marca estabelecida por uma pessoa. <br><br>  A competi√ß√£o come√ßou em 2010 e os NSs profundos n√£o tiveram um grande papel nos primeiros dois anos.  As melhores equipes usaram diferentes t√©cnicas de MO e alcan√ßaram resultados razoavelmente m√©dios.  Em 2010, a equipe venceu com uma porcentagem de erros igual a 28. Em 2011 - com um erro de 25%. <br><br>  E ent√£o veio 2012.  Uma equipe da Universidade de Toronto fez uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">oferta</a> - mais tarde apelidada de AlexNet em homenagem ao autor principal, Alex Krizhevsky - e deixou os rivais para tr√°s.  Usando o NS profundo, a equipe alcan√ßou uma taxa de erro de 16%.  Para o concorrente mais pr√≥ximo, esse n√∫mero era 26. <br><br>  O NS descrito no artigo para reconhecimento de manuscrito possui duas camadas, 25 neur√¥nios e quase 12.000 par√¢metros.  O AlexNet era muito maior e mais complexo: oito camadas treinadas, 650.000 neur√¥nios e 60 milh√µes de par√¢metros. <br><br>  √â necess√°rio um enorme poder de processamento para treinar NSs desse tamanho, e o AlexNet foi projetado para tirar proveito da paraleliza√ß√£o massiva dispon√≠vel nas GPUs modernas.  Os pesquisadores descobriram como dividir o trabalho de treinar a rede em duas GPUs, o que dobrou o poder.  E, apesar da otimiza√ß√£o rigorosa, o treinamento em rede levou de 5 a 6 dias para o hardware que estava dispon√≠vel em 2012 (em um par de Nvidia GTX 580 com 3 Gb de mem√≥ria). <br><br>  √â √∫til estudar exemplos dos resultados da AlexNet para entender o qu√£o s√©rio esse avan√ßo foi.  Aqui est√° uma foto de um artigo cient√≠fico que mostra exemplos de imagens e os cinco primeiros palpites da rede por sua classifica√ß√£o: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d36/1ee/3b6/d361ee3b61cc19de787edda63d6e1e65.png"><br><br>  A AlexNet conseguiu reconhecer o tique na primeira foto, embora exista apenas um pequeno formul√°rio no canto.  O software n√£o apenas identificou corretamente o leopardo, mas tamb√©m deu outras op√ß√µes pr√≥ximas - um jaguar, chita, leopardo das neves, o Mau eg√≠pcio.  AlexNet adicionou aos itens a foto hornbeam como "agaric".  Apenas "cogumelo" foi a segunda vers√£o da rede. <br><br>  "Erros" AlexNet tamb√©m s√£o impressionantes.  Ela marcou a foto com um d√°lmata em p√© atr√°s de um monte de cerejas como "d√°lmata", embora o r√≥tulo oficial fosse "cereja".  A AlexNet reconheceu que havia algum tipo de fruta na foto - entre as cinco primeiras op√ß√µes eram "uvas" e "sabugueiro" - ela simplesmente n√£o reconheceu a cereja.  Em uma foto de um l√™mure de Madagascar sentado em uma √°rvore, AlexNet deu uma lista de pequenos mam√≠feros que vivem em √°rvores.  Eu acho que muitas pessoas (inclusive eu) teriam colocado a assinatura errada aqui. <br><br>  A qualidade do trabalho foi impressionante e demonstrou que o software √© capaz de reconhecer objetos comuns em uma ampla gama de orienta√ß√µes e ambientes.  O GNS rapidamente se tornou a t√©cnica mais popular para reconhecimento de imagens e, desde ent√£o, o mundo do MO n√£o o abandonou. <br><br>  ‚ÄúAp√≥s o sucesso do m√©todo baseado em GO em 2012, a maioria dos participantes da competi√ß√£o de 2013 mudou para redes neurais convolucionais profundas‚Äù, escreveram os patrocinadores do ImageNet.  Nos anos seguintes, essa tend√™ncia continuou e, posteriormente, os vencedores trabalharam com base em tecnologias b√°sicas, aplicadas pela primeira vez pela equipe AlexNet.  Em 2017, os rivais, usando NSs mais profundos, reduziram seriamente a taxa de erro para menos de tr√™s.  Dada a complexidade da tarefa, os computadores aprenderam at√© certo ponto a resolv√™-la melhor do que muitas pessoas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/433/872/5e1/4338725e10f14ecf679878fb267394c9.png"><br>  <i>A porcentagem de erros na classifica√ß√£o de imagens em diferentes anos</i> <br><br><h2>  Redes de convolu√ß√£o: um conceito </h2><br>  Tecnicamente, AlexNet era um NS convolucional.  Nesta se√ß√£o, explicarei o que a rede neural convolucional (SNA) faz e por que essa tecnologia se tornou criticamente importante para os algoritmos modernos de reconhecimento de padr√µes. <br><br>  A rede simples discutida anteriormente para reconhecimento de manuscrito estava completamente conectada: cada neur√¥nio da primeira camada era uma entrada para cada neur√¥nio da segunda camada.  Essa estrutura funciona muito bem em tarefas simples com reconhecimento de n√∫meros em imagens de 28x28 pixels.  Mas n√£o escala bem. <br><br>  No banco de dados de d√≠gitos manuscritos MNIST, todos os caracteres s√£o centralizados.  Isso simplifica muito o aprendizado, porque, digamos, os sete sempre ter√£o v√°rios pixels escuros na parte superior e direita e o canto inferior esquerdo √© sempre branco.  Zero quase sempre ter√° uma mancha branca nos pixels m√©dios e escuros nas bordas.  Uma rede simples e totalmente conectada pode reconhecer esses padr√µes facilmente. <br><br>  Mas digamos que voc√™ queira criar um NS capaz de reconhecer n√∫meros que podem ser localizados em qualquer lugar em uma imagem maior.  Uma rede totalmente conectada n√£o funcionar√° t√£o bem com essa tarefa, porque n√£o possui uma maneira eficaz de reconhecer recursos semelhantes em formul√°rios localizados em diferentes partes da imagem.  Se no conjunto de dados de treinamento a maioria dos setes estiver localizada no canto superior esquerdo, sua rede ser√° melhor em reconhecer os setes no canto superior esquerdo do que em qualquer outra parte da imagem. <br><br>  Teoricamente, esse problema pode ser resolvido garantindo que o seu conjunto tenha muitos exemplos de cada d√≠gito em cada uma das posi√ß√µes poss√≠veis.  Mas, na pr√°tica, isso ser√° um enorme desperd√≠cio de recursos.  Com o aumento do tamanho da imagem e da profundidade da rede, o n√∫mero de links - e o n√∫mero de par√¢metros de peso - aumentar√° de forma explosiva.  Voc√™ precisar√° de muito mais imagens de treinamento (e poder de computa√ß√£o) para obter uma precis√£o adequada. <br><br>     ,     ,               .      . <br><br> ¬´   ,             , ‚Äî     . ‚Äì       ,          ,   ‚Äì    ?  ,    .     . ,     .    .   ,         ¬ª. <br><br> ,     ,     2828 .         ,   ,     .          ¬´7¬ª,    ,       .      . <br><br><h2>      AlexNet </h2><br>     ¬´¬ª ,   ,     ‚Äì  .        ,      28 .  AlexNet            1111 .         3-5 . <br><br>          :  ,   ,        .        ,          .  AlexNet     96  ,  96  . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/94f/1a0/c3d/94f1a0c3deacf7903606f4ecaf040b20.png"><br><br>    ,    ,    96    AlexNet   .   ,     ,     ,      . <br><br>              :  ,   .   AlexNet        ,  96 .  ¬´¬ª     96 ,      . <br><br>      96  ,   -     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/260/3fa/933/2603fa9332cbf509d9afd9dc1870e53a.png"><br><br>   ,   -     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a0b/736/b01/a0b736b01ab683e1dfbd229e29904500.png"><br><br>   ,   -     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bd9/a72/09c/bd9a7209cb808f24e18d54327974a0e7.png"><br><br>      93      AlexNet.      ,    ‚Äì    96  (  ,      4 ). <br><br>    AlexNet.      ,        . <br><br>   ,     ,     ,       .            .  ,        ,          ,  .       ,     .        . <br><br>         2014  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> ,       ,   ,   ImageNet. <br><br>   ,    ,   ,  ,   .     ,     .     ‚Äì      .  ‚Äì ,            .       ,     ,    , ,    . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2c/beb/74e/a2cbeb74e2f71a9b1b84fbea587294b2.png"><br> <i>  ‚Äì    </i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/701/ebd/501/701ebd5013d881b6892c66c3fb63d77f.png"><br> <i>  ‚Äì    </i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/34d/283/91a/34d28391a4bb2d0804e15d12992208ba.png"><br> <i>         ,   ,     </i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/41a/ee2/cb6/41aee2cb61324edc33313a0b01c874b5.png"><br> <i>     ,      </i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/04b/96a/baa/04b96abaa00cf8ed2dcb994d56a5af3f.png"><br> <i>      </i> <br><br>  ,   ,          .     ,     .      .           -  (,  , - ). <br><br>        11,     ‚Äì    .  ,      ,    ,    ¬´¬ª     .             ,   .    ,        ,   . <br><br> ,         .  ,    ,       ,   : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e82/3fb/895/e823fb8956c1b12d92b32607c41837ec.png"><br><br>          .        ,  ,            .           ! <br><br> ,   ,    ,    ,  ¬´¬ª,          .      AlexNet   ,  ,        .       ,    ,       1000  . <br><br>       ,         .   ,     ,         .              .             ,      . <br><br><h2>    :    </h2><br>  ,          ,      ,     . <br><br>   ()   . ,    ,         .       . <br><br> ,     ,    .            . ,  ,       . <br><br>       AlexNet .       1111 ,      1111     .        121 ,        ‚Äì ,   .      363  .   ,     363 ,      . ,    363,     363. <br><br>       .     1111 ,          .       7 ,         ,     .     363 ,   1111,      ,     . <br><br>   ,      363 ,       ,   .         ,     .         ;       4    . <br><br> ,    :   5555  3025 .           363 ,    .      , ¬´¬ª     ,      . <br><br> ,     AlexNet  96  .     3025      96 .    95- ‚Äì     3025 .    3025      363  ‚Äì ,    95   . <br><br>        ,      ,          . <br><br> ¬´    ‚Äì    ¬ª, ‚Äî         .      ,    ,           . <br><br>                .            . <br><br><h2>         </h2><br>  O trabalho de AlexNet se tornou uma sensa√ß√£o na comunidade acad√™mica da regi√£o de Moscou, mas sua import√¢ncia foi rapidamente entendida no setor de TI.  O Google estava especialmente interessado nela. <br><br>  Em 2013, o Google adquiriu uma startup fundada pelos autores AlexNet.  A empresa usou essa tecnologia para adicionar um novo recurso de pesquisa de fotos ao Google Fotos.  "Pegamos a pesquisa avan√ßada e a colocamos em opera√ß√£o pouco mais de seis meses depois", escreveu Chuck Rosenberg, do Google. <br><br>  Enquanto isso, em 2013, foi descrito como o Google usa o GSS para reconhecer endere√ßos de fotos do Google Street View.  "Nosso sistema nos ajudou a extrair quase 100 milh√µes de endere√ßos f√≠sicos dessas imagens", escreveram os autores. <br><br>  Os pesquisadores descobriram que a efic√°cia do NS cresce com o aumento da profundidade.  "Descobrimos que a efic√°cia dessa abordagem aumenta com a profundidade do SNA, e a arquitetura mais profunda que treinamos mostra os melhores resultados", escreveu a equipe do Google Street View.  "Nossos experimentos sugerem que arquiteturas mais profundas podem produzir maior precis√£o, mas com uma desacelera√ß√£o da efici√™ncia". <br><br>  Ent√£o, depois da AlexNet, as redes come√ßaram a ficar mais profundas.  A equipe do Google fez uma oferta na competi√ß√£o em 2014 - apenas dois anos ap√≥s a vit√≥ria da AlexNet em 2012. Tamb√©m foi baseado em um SNA profundo, mas Goolge usou uma rede muito mais profunda de 22 camadas para obter uma taxa de erro de 6,7% - essa foi uma grande melhoria em compara√ß√£o aos 16% da AlexNet. <br><br>  Mas, ao mesmo tempo, redes mais profundas funcionavam melhor apenas com conjuntos maiores de dados de treinamento.  Portanto, Gerrish diz que o conjunto de dados e a concorr√™ncia do ImageNet tiveram um papel importante no sucesso do SNA.  Lembre-se de que, no concurso ImageNet, os participantes recebem um milh√£o de imagens e s√£o solicitados a classific√°-las em 1.000 categorias. <br><br>  "Se voc√™ tem um milh√£o de imagens para treinamento, cada classe inclui 1.000 imagens", disse Gerrish.  Sem um conjunto de dados t√£o grande, ele disse: "voc√™ teria muitas op√ß√µes para treinar a rede". <br><br>  Nos √∫ltimos anos, os especialistas est√£o se concentrando cada vez mais na coleta de uma enorme quantidade de dados para treinar redes mais profundas e precisas.  √â por isso que as empresas que desenvolvem carros-rob√¥ se concentram em rodar em vias p√∫blicas - imagens e v√≠deos dessas viagens s√£o enviados para a sede e usados ‚Äã‚Äãpara treinar NS corporativos. <br><br><h2>  Crescimento de aprendizado profundo de computa√ß√£o </h2><br>  A descoberta do fato de que redes mais profundas e conjuntos de dados maiores podem melhorar o desempenho do NS criou uma sede insaci√°vel de poder de computa√ß√£o cada vez maior.  Um dos principais componentes do sucesso da AlexNet foi a id√©ia de que o treinamento em matriz √© usado no treinamento NS, que pode ser executado com efici√™ncia em GPUs bem paraleliz√°veis. <br><br>  "Os NSs s√£o bem paralelos", disse Jai Ten, pesquisador do MO.  As placas gr√°ficas - fornecendo uma enorme capacidade de processamento paralelo para videogames - provaram ser √∫teis para os NSs. <br><br>  "A parte central do trabalho da GPU, a multiplica√ß√£o muito r√°pida da matriz, acabou sendo a parte central do trabalho da Assembl√©ia Nacional", disse Ten. <br><br>  Tudo isso foi bem-sucedido para os principais fabricantes de GPU, Nvidia e AMD.  Ambas as empresas desenvolveram novos chips especificamente adaptados √†s necessidades do aplicativo MO, e agora os aplicativos de IA s√£o respons√°veis ‚Äã‚Äãpor uma parte significativa das vendas de GPU dessas empresas. <br><br>  Em 2016, o Google anunciou a cria√ß√£o de um chip especial, a Tensor Processing Unit (TPU), projetada para operar na Assembl√©ia Nacional.  "Embora o Google estivesse considerando a possibilidade de criar circuitos integrados para fins especiais (ASICs) em 2006, essa situa√ß√£o tornou-se urgente em 2013", <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">escreveu</a> um representante da empresa no ano passado.  "Foi ent√£o que percebemos que os requisitos de r√°pido crescimento da Assembl√©ia Nacional para poder de computa√ß√£o podem exigir que dobremos o n√∫mero de data centers que temos". <br><br>  Inicialmente, apenas os servi√ßos do Google tinham acesso a TPUs, mas depois a empresa permitiu que todos usassem essa tecnologia por meio de uma plataforma de computa√ß√£o em nuvem. <br><br>  Obviamente, o Google n√£o √© a √∫nica empresa que trabalha com chips de IA.  Apenas alguns exemplos: nas vers√µes mais recentes dos chips para iPhone, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">existe um</a> "n√∫cleo neural" otimizado para opera√ß√µes com o NS.  A Intel est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">desenvolvendo</a> sua pr√≥pria linha de chips otimizados para GO.  A Tesla <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">anunciou</a> recentemente a rejei√ß√£o de chips da Nvidia em favor de seus pr√≥prios chips NS.  H√° rumores de que a Amazon esteja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalhando</a> em seus chips de IA. <br><br><h2>  Por que redes neurais profundas s√£o dif√≠ceis de entender </h2><br>  Expliquei como as redes neurais funcionam, mas n√£o expliquei por que elas funcionam t√£o bem.  N√£o est√° claro como exatamente a imensa quantidade de c√°lculos matriciais permite que um sistema de computador diferencie uma on√ßa-pintada de um guepardo e sabugueiro de groselha. <br><br>  Talvez a qualidade mais not√°vel da Assembl√©ia Nacional seja que n√£o.  A convolu√ß√£o permite que o NS entenda a hifeniza√ß√£o - eles podem dizer se a imagem no canto superior direito da imagem √© semelhante √† imagem no canto superior esquerdo de outra imagem. <br><br>  Mas, ao mesmo tempo, o SNA n√£o tem id√©ia sobre geometria.  Eles n√£o podem reconhecer a semelhan√ßa das duas imagens se forem giradas 45 graus ou dobradas.  O SNA n√£o tenta entender a estrutura tridimensional dos objetos e n√£o pode levar em considera√ß√£o as diferentes condi√ß√µes de ilumina√ß√£o. <br><br>  Mas, ao mesmo tempo, os NSs podem reconhecer fotos de c√£es tirados de frente e de lado, e n√£o importa se o c√£o ocupa uma pequena parte da imagem ou uma grande.  Como eles fazem isso?  Acontece que, se houver dados suficientes, uma abordagem estat√≠stica com enumera√ß√£o direta pode lidar com a tarefa.  O SNA n√£o foi projetado para "imaginar" como uma imagem em particular ficaria de um √¢ngulo diferente ou em condi√ß√µes diferentes, mas com um n√∫mero suficiente de exemplos rotulados, ela pode aprender todas as varia√ß√µes poss√≠veis da imagem por simples repeti√ß√£o. <br><br>  H√° evid√™ncias de que o sistema visual das pessoas funciona de maneira semelhante.  Veja algumas fotos - primeiro estude cuidadosamente a primeira e depois abra a segunda. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d43/861/b2d/d43861b2ddeebcec572cab31c9ddb81a.png"><br>  <i>Primeira foto</i> <br><br><div class="spoiler">  <b class="spoiler_title">Segunda foto</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/529/451/bde/529451bde2016793fd9cfe4ec092b46a.png"><br></div></div><br><br>  O criador da imagem tirou a fotografia de algu√©m e virou os olhos e a boca de cabe√ßa para baixo.  A imagem parece relativamente normal quando voc√™ a olha de cabe√ßa para baixo, porque o sistema visual humano est√° acostumado a ver olhos e bocas nessa posi√ß√£o.  Mas se voc√™ olhar a foto na orienta√ß√£o correta, poder√° ver imediatamente que o rosto est√° estranhamente distorcido. <br><br>  Isso sugere que o sistema visual humano √© baseado nas mesmas t√©cnicas de reconhecimento de padr√µes brutos que o NS.  Se olharmos para algo que quase sempre √© vis√≠vel em uma orienta√ß√£o - o olho humano -, podemos reconhec√™-lo muito melhor em sua orienta√ß√£o normal. <br><br>  Os NSs reconhecem bem as imagens usando todo o contexto dispon√≠vel nelas.  Por exemplo, carros geralmente dirigem nas estradas.  Os vestidos geralmente s√£o usados ‚Äã‚Äãno corpo de uma mulher ou pendurados em um arm√°rio.  As aeronaves geralmente s√£o atiradas contra o c√©u ou dominam a pista.  Ningu√©m ensina especificamente ao NS essas correla√ß√µes, mas com um n√∫mero suficiente de exemplos rotulados, a pr√≥pria rede pode aprend√™-los. <br><br>  Em 2015, pesquisadores do Google tentaram entender melhor o NS, "executando-os ao contr√°rio".  Em vez de usar imagens para o treinamento de NS, eles usavam NS treinado para alterar as imagens.  Por exemplo, eles come√ßaram com uma imagem contendo ru√≠do aleat√≥rio e, gradualmente, a mudaram para que ativasse fortemente um dos neur√¥nios de sa√≠da do SN - na verdade, pediram ao NS para "desenhar" uma das categorias que foi ensinado a reconhecer.  Em um caso interessante, eles for√ßaram o NS a gerar imagens que ativam o NS, treinadas para reconhecer halteres. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ece/817/a18/ece817a18e8c2fc63281cb0a1773ac91.png"><br><br>  "√â claro que existem halteres aqui, mas nenhuma imagem dos halteres parece completa sem a presen√ßa de um rolo muscular muscular levantando-os", escreveram pesquisadores do Google. <br><br>  √Ä primeira vista, parece estranho, mas, na realidade, n√£o √© t√£o diferente do que as pessoas fazem.  Se vemos um objeto pequeno ou emba√ßado na imagem, procuramos uma pista ao seu redor para entender o que pode acontecer l√°.  As pessoas, obviamente, falam sobre as fotos de maneira diferente, usando uma compreens√£o conceitual complexa do mundo ao seu redor.  Mas, no final, o STS reconhece bem as imagens, porque elas tiram o m√°ximo proveito de todo o contexto descrito nelas, e isso n√£o √© muito diferente de como as pessoas fazem isso. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt455331/">https://habr.com/ru/post/pt455331/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt455318/index.html">Quais s√£o as √°reas de aplica√ß√£o da impress√£o 3D?</a></li>
<li><a href="../pt455319/index.html">Artista 3D de fluxo de trabalho. Como n√£o se afogar em uma tonelada de informa√ß√µes. Parte 1</a></li>
<li><a href="../pt455321/index.html">Dom√≥tica fa√ßa voc√™ mesmo</a></li>
<li><a href="../pt455325/index.html">Portando aplicativos da √°rea de trabalho para o .NET Core</a></li>
<li><a href="../pt455329/index.html">An√∫ncio Extens√£o (Ferramentas de Borda) da IoT do Azure (Visualiza√ß√£o)</a></li>
<li><a href="../pt455333/index.html">Quem colocou o Python na atualiza√ß√£o do Windows 10 de maio de 2019?</a></li>
<li><a href="../pt455335/index.html">Petty Petty Joy # 3: Poesia</a></li>
<li><a href="../pt455337/index.html">Quem adicionou o Python √† atualiza√ß√£o mais recente do Windows?</a></li>
<li><a href="../pt455339/index.html">Cavando t√∫mulos, SQL Server, anos de terceiriza√ß√£o e seu primeiro projeto</a></li>
<li><a href="../pt455341/index.html">O que se sabe sobre a certifica√ß√£o ITIL 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
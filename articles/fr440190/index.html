<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö≠ üëàüèº üó°Ô∏è Connaissance du r√©seau neuronal le plus simple et de sa mise en ≈ìuvre pas √† pas ‚Ü™Ô∏è ü§ò üë¶üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Une fois, je suis tomb√© sur un livre intitul√© "Cr√©ez votre r√©seau neuronal" , √©crit par Tarik Rashid . Contrairement √† de nombreux autres livres sur l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Connaissance du r√©seau neuronal le plus simple et de sa mise en ≈ìuvre pas √† pas</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440190/"> Une fois, je suis tomb√© sur un livre intitul√© <b>"Cr√©ez votre r√©seau neuronal"</b> , √©crit par <b>Tarik Rashid</b> .  Contrairement √† de nombreux autres livres sur les r√©seaux de neurones, tout a √©t√© pr√©sent√© dans un langage simple, avec un nombre suffisant d'exemples et de conseils <br><br>  Inspir√© par ce livre, je veux le parcourir pas √† pas - √† savoir sa partie pratique - en <b>√©crivant le code d'un r√©seau neuronal simple</b> . <br>  Cet article s'adresse √† ceux qui veulent faire des r√©seaux de neurones et de l'apprentissage automatique, mais qui ont jusqu'√† pr√©sent du mal √† comprendre ce domaine scientifique √©tonnant.  Le <b>squelette le</b> plus simple <b>du</b> code d'un r√©seau neuronal sera d√©crit ci-dessous, afin que beaucoup comprennent le principe le plus simple de construction et d'interaction de tout ce que ce r√©seau neuronal consiste. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/055/9ca/080/0559ca080954e91fdfed1b451fcbfebe.jpg" alt="image"><br><a name="habracut"></a><br><br>  Les th√©ories sur l'apprentissage automatique et les r√©seaux de neurones sur l'Habr√© suffisent.  Mais si quelqu'un en a besoin, je laisserai quelques liens √† la fin de l'article.  Et maintenant, nous allons commencer √† √©crire du code directement, et nous allons √©crire en <b>Python</b> , je recommande d'utiliser <u><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Jupyter-Notebook</a></u> lors de l'√©criture de code <br><br><h2>  √âtape 1. Initialisation du r√©seau </h2><br>  Tout d'abord, bien s√ªr, nous devons initialiser tous les composants actifs de notre r√©seau <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># numpy ‚Äî    Python,        import numpy #  scipy.special , -scipy    , ,  ,      ,       ,   - " " import scipy.special #,      import matplotlib.pyplot #     class neuralNetwork: #     def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate): #     ,   ,   ,  ) #     ,  ,   self.inodes = inputnodes self.hnodes = hiddennodes self.onodes = outputnodes #    , wih -       ,    who-       self.wih = numpy.random.rand(self.hnodes, self.inodes) self.who = numpy.random.rand(self.onodes, self.hnodes) #   -  ,  ,  ,    ,     ,     ,  ,  ,   self.lr = learningrate #  -   self.activation_function = lambda x: scipy.special.expit(x)</span></span></code> </pre> <br><h2>  Sigmo√Øde </h2><br>  Cette fonction appartient √† la classe des fonctions continues, prend un <b>nombre r√©el arbitraire (c'est-√†-dire <b>pas n√©cessairement</b> un entier)</b> √† l'entr√©e <b>et donne un nombre r√©el dans la plage de 0 √† 1 √† la sortie</b> . <br><br>  En particulier, les grands <b>nombres</b> (modulo) <b>n√©gatifs se transforment en z√©ro</b> <b>et les grands</b> <b>nombres</b> <b>positifs en</b> <b>deviennent</b> <b>un</b> . <br><br>  Sa sortie est bien interpr√©t√©e <b>comme le niveau d'activation des</b> neurones: de l' <b>absence d'activation</b> (0) √† l' <b>activation</b> compl√®tement <b>satur√©e</b> (1). <br><br>  La sigmo√Øde est exprim√©e par la formule: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eee/fc0/ace/eeefc0acea96c33eedbb8befdaf28fa7.png" alt="image"><br><br>  Le graphique de la fonction sigmo√Øde conform√©ment √† la figure ci-dessous: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/688/227/a86/688227a8673b5e82494c8aa01536c3ef.png" alt="image"><br><br>  La fonction sigmo√Øde est: <br><br><ul><li>  continu </li><li>  en augmentation monotone; </li><li>  diff√©renciable. </li></ul><br>  Dans ce code, le sigmo√Øde est pr√©sent, comme vous pouvez le voir, sous le nom <b>expit (x)</b> <br><br><h2>  Un peu sur l'apparence d'un n≈ìud dans un r√©seau de neurones </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/32e/7ad/4b4/32e7ad4b4fac123e73d88c44a8acb8ca.png" alt="image"><br><br>  L'image montre le plus ce n≈ìud, seulement il est g√©n√©ralement pr√©sent√© sous la forme d'un cercle, pas d'un rectangle.  Comme nous le voyons, √† l'int√©rieur d'un rectangle (enfin, ou d'un cercle) - tout cela est abstrait, il y a 2 fonctions: <br><br>  La 1√®re fonction est engag√©e dans le fait qu'elle re√ßoit toutes les entr√©es, en tenant compte des poids, des donn√©es, et parfois m√™me en tenant compte du neurone de d√©placement (un neurone sp√©cial qui permet simplement aux graphiques de se d√©placer, et non de se m√©langer dans un tas laid, c'est tout) <br><br>  La 2e fonction prend comme param√®tre la m√™me valeur que la premi√®re fonction additionn√©e, et cette deuxi√®me fonction est appel√©e fonction d'activation.  Dans notre cas, un <b>sigmo√Øde</b> <br><br>  <b>Nous continuons</b> : <br><br><h2>  Partie 2. Formation au r√©seau neuronal </h2><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs_list, targets_list)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#       inputs = numpy.array(inputs_list, ndmin=2).T #     input targets = numpy.array(targets_list, ndmin=2).T #  targets #      hidden_inputs = numpy.dot(self.wih, inputs) #  ,       .    ,       hidden_inputs (1 ),        -   (2 ) hidden_outputs = self.activation_function(hidden_inputs) #    ()  final_inputs = numpy.dot(self.who, hidden_outputs) #  ,     final_outputs = self.activation_function(final_inputs) #   ( - ) output_errors = targets - final_outputs #      ,    &lt;b&gt;  &lt;/b&gt;,   &lt;b&gt;       &lt;/b&gt;(      ) hidden_errors = numpy.dot(self.who.T, output_errors) #        ( ,      ) self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs)) #       (       ) self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))</span></span></code> </pre><br>  <b>Et maintenant nous approchons de la fin</b> <br><br><h2>  Partie 3. Interrogation d'un r√©seau de neurones </h2><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  ,      def query(self, inputs_list): #         inputs = numpy.array(inputs_list, ndmin=2).T #      hidden_inputs = numpy.dot(self.wih, inputs) #  ,     hidden_outputs = self.activation_function(hidden_inputs) #      final_inputs = numpy.dot(self.who, hidden_outputs) #     ,     final_outputs = self.activation_function(final_inputs) return final_outputs</span></span></code> </pre> <br><h2>  Nous le menons √† terme </h2><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     ,  ,  (  &lt;b&gt;&lt;/b&gt;-    , ,   input_nodes = 3 hidden_nodes = 3 output_nodes = 3 #    -   , ... 0.3! learning_rate = 0.3 #   (n    neuralNetwork ,      __init__ ,        n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)</span></span></code> </pre> <br><h2>  PS </h2><br>  Ci-dessus a √©t√© pr√©sent√© le mod√®le le plus simple d'un r√©seau de neurones.  Mais aucune application sp√©cifique n'a √©t√© montr√©e. <br><br>  Si vous le souhaitez, vous pouvez aller plus loin en ajoutant la possibilit√© de reconna√Ætre le texte manuscrit dans le code <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MNIST</a> , pour cela vous pouvez comprendre compl√®tement (et juste vous amuser) avec ce <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fichier jupyter</a> , ma t√¢che √©tait de d√©montrer le code et, si possible, de m√¢cher sur le r√©seau et pour quelles r√©ponses <br><br><h2>  PPS </h2><br>  Vous trouverez ci-dessous des liens utiles: <br><br>  1. Lien vers Github Tarik <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">-&gt;</a> <br>  2. Son livre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">-&gt;</a> <br>  3. Th√©orie de l'apprentissage automatique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">-&gt;</a> <br>  4. Th√©orie de l'apprentissage automatique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">-&gt;</a> <br>  5. Th√©orie de l'apprentissage automatique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">-&gt;</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440190/">https://habr.com/ru/post/fr440190/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440178/index.html">Suppression de la r√©cursivit√© en Python</a></li>
<li><a href="../fr440180/index.html">Concours de programmation Q #: Concours de codage Microsoft Q #</a></li>
<li><a href="../fr440182/index.html">IBM Watson Studio - Une plate-forme de d√©veloppement d'applications AI bas√©e sur le cloud</a></li>
<li><a href="../fr440184/index.html">Pourquoi nous utilisons GraphQL dans 8base</a></li>
<li><a href="../fr440188/index.html">Atteindre les √©toiles: ma√Ætriser les op√©rateurs Ansible pour g√©rer les applications dans Kubernetes</a></li>
<li><a href="../fr440192/index.html">Comment cr√©ons-nous la radio d'entreprise pour</a></li>
<li><a href="../fr440196/index.html">Secrets d'esprit et math√©matiques</a></li>
<li><a href="../fr440198/index.html">Nouvelles imprimantes 3D DWS pour les professionnels</a></li>
<li><a href="../fr440200/index.html">Parlons de la journalisation</a></li>
<li><a href="../fr440202/index.html">Contr√¥les proactifs OWASP: Liste des pr√©requis pour les d√©veloppeurs de logiciels</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
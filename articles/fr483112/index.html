<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï∞Ô∏è üéµ üòÅ Utilisation de Clickhouse en remplacement de ELK, Big Query et TimescaleDB ‚úçüèø üöÅ üì¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Clickhouse est un moteur de base de donn√©es de syst√®me de gestion de base de donn√©es analytique (OLAP) open source open source cr√©√© par Yandex. Il est...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Utilisation de Clickhouse en remplacement de ELK, Big Query et TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/483112/">  <a href="https://clickhouse.yandex/">Clickhouse</a> est un moteur de base de donn√©es de syst√®me de gestion de base de donn√©es analytique (OLAP) open source open source cr√©√© par Yandex.  Il est utilis√© par Yandex, CloudFlare, VK.com, Badoo et d'autres services √† travers le monde pour stocker de tr√®s grandes quantit√©s de donn√©es (ins√©rer des milliers de lignes par seconde ou des p√©taoctets de donn√©es stock√©es sur le disque). <br><br>  Dans le SGBD ¬´cha√Æne¬ª habituel, dont MySQL, Postgres, MS SQL Server sont des exemples, les donn√©es sont stock√©es dans cet ordre: <br><br><img src="https://habrastorage.org/webt/op/as/zd/opaszdhxefzryaitjqttg8sk_to.jpeg"><br><br>  Dans ce cas, les valeurs li√©es √† une ligne sont stock√©es physiquement c√¥te √† c√¥te.  Dans un SGBD en colonnes, les valeurs de diff√©rentes colonnes sont stock√©es s√©par√©ment et les donn√©es d'une colonne sont stock√©es ensemble: <br><br><img src="https://habrastorage.org/webt/oj/17/vg/oj17vgwsilwf8mri4-whzqzm31s.jpeg"><a name="habracut"></a><br><br>  Des exemples de SGBD en colonnes sont Vertica, Paraccel (Actian Matrix, Amazon Redshift), Sybase IQ, Exasol, Infobright, InfiniDB, MonetDB (VectorWise, Actian Vector), LucidDB, SAP HANA, Google Dremel, Google PowerDrill, Druid, kdb +. <br><br>  La soci√©t√© de <a href="https://qwintry.com/">transfert de courrier Qwintry a</a> commenc√© √† utiliser Clickhouse en 2018 pour ses rapports et a √©t√© tr√®s impressionn√©e par sa simplicit√©, son √©volutivit√©, sa prise en charge SQL et sa vitesse.  La vitesse de ce SGBD √©tait bord√©e de magie. <br><br><h3>  Simplicit√© </h3><br>  Clickhouse s'installe sur Ubuntu avec une seule commande.  Si vous connaissez SQL, vous pouvez imm√©diatement commencer √† utiliser Clickhouse pour vos besoins.  Cependant, cela ne signifie pas que vous pouvez ex√©cuter "show create table" dans MySQL et copier-coller SQL dans Clickhouse. <br><br>  Par rapport √† MySQL, dans ce SGBD, il existe d'importantes diff√©rences de types de donn√©es dans les d√©finitions des sch√©mas de table, donc pour un travail confortable, vous avez encore besoin de temps pour modifier les d√©finitions du sch√©ma de table et √©tudier les moteurs de table. <br><br>  Clickhouse fonctionne tr√®s bien sans aucun logiciel suppl√©mentaire, mais si vous souhaitez utiliser la r√©plication, vous devrez installer ZooKeeper.  L'analyse des performances des requ√™tes montre d'excellents r√©sultats - les tables syst√®me contiennent toutes les informations et toutes les donn√©es peuvent √™tre obtenues en utilisant l'ancien SQL ennuyeux. <br><br><h3>  Performances </h3><br><br><ul><li> <a href="https://clickhouse.yandex/benchmark.html">Benchmark</a> comparant Clickhouse avec Vertica et MySQL sur un serveur de configuration: deux sockets CPU Intel¬Æ Xeon¬Æ E5-2650 v2 @ 2.60GHz;  128 Go de RAM;  md RAID-5 sur 8 disques durs SATA de 6 To, ext4. </li><li>  <a href="https://www.altinity.com/blog/2017/6/20/clickhouse-vs-redshift">Benchmark</a> comparant Clickhouse avec le stockage de donn√©es cloud Amazon RedShift. </li><li>  Extraits du <a href="https://blog.cloudflare.com/how-cloudflare-analyzes-1m-dns-queries-per-second/">blog sur les performances de Cloudflare Clickhouse</a> : </li></ul><br><img src="https://habrastorage.org/webt/oo/2c/0d/oo2c0dfcidwr9fsilydx_b9jilw.jpeg"><br><br>  La base de donn√©es ClickHouse a une conception tr√®s simple - tous les n≈ìuds du cluster ont les m√™mes fonctionnalit√©s et utilisent uniquement ZooKeeper pour la coordination.  Nous avons construit un petit cluster de plusieurs n≈ìuds et effectu√© des tests, au cours desquels nous avons constat√© que le syst√®me avait des performances assez impressionnantes, ce qui correspond aux avantages d√©clar√©s dans les r√©f√©rences des SGBD analytiques.  Nous avons d√©cid√© d'examiner de plus pr√®s le concept derri√®re ClickHouse.  Le premier obstacle √† la recherche √©tait le manque d'outils et la petite taille de la communaut√© ClickHouse, nous avons donc explor√© la conception de ce syst√®me de gestion de base de donn√©es pour comprendre comment il fonctionne. <br><br>  ClickHouse ne prend pas en charge la r√©ception de donn√©es directement depuis Kafka (pour le moment, il sait d√©j√† comment), car il ne s'agit que d'une base de donn√©es, nous avons donc √©crit notre propre service d'adaptateur dans Go.  Il a lu les messages cod√©s Cap'n Proto de Kafka, les a convertis en TSV et les a ins√©r√©s dans ClickHouse par lots via l'interface HTTP.  Plus tard, nous avons r√©√©crit ce service pour utiliser la biblioth√®que Go en conjonction avec notre propre interface ClickHouse pour am√©liorer les performances.  Lors de l'√©valuation des performances de r√©ception des paquets, nous avons d√©couvert une chose importante - il s'est av√©r√© que chez ClickHouse, ces performances d√©pendent fortement de la taille du paquet, c'est-√†-dire du nombre de lignes ins√©r√©es en m√™me temps.  Pour comprendre pourquoi cela se produit, nous avons examin√© comment ClickHouse stocke les donn√©es. <br><br>  Le moteur principal, ou plut√¥t la famille de moteurs de table utilis√©s par ClickHouse pour stocker des donn√©es, est MergeTree.  Ce moteur est conceptuellement similaire √† l'algorithme LSM utilis√© par Google BigTable ou Apache Cassandra, mais il √©vite de construire une table de m√©moire interm√©diaire et √©crit des donn√©es directement sur le disque.  Cela lui donne un excellent d√©bit d'√©criture, car chaque paquet ins√©r√© n'est tri√© que par la cl√© primaire ¬´cl√© primaire¬ª, est compress√© et √©crit sur le disque pour former un segment. <br><br>  L'absence d'une table m√©moire ou de tout concept de ¬´fra√Æcheur¬ª des donn√©es signifie √©galement qu'elles ne peuvent √™tre ajout√©es que le syst√®me ne prend pas en charge leur modification ou leur suppression.  Aujourd'hui, la seule fa√ßon de supprimer des donn√©es est de les supprimer par mois calendaires, car les segments ne franchissent jamais la limite du mois.  L'√©quipe ClickHouse travaille activement √† rendre cette fonctionnalit√© personnalisable.  D'un autre c√¥t√©, cela rend l'enregistrement et la fusion des segments sans couture, de sorte que la bande passante de r√©ception √©volue lin√©airement avec le nombre d'insertions parall√®les jusqu'√† ce que les E / S ou les c≈ìurs soient satur√©s. <br>  Cependant, ce fait signifie √©galement que le syst√®me n'est pas adapt√© aux petits colis, donc les services et les inserts Kafka sont utilis√©s pour la mise en m√©moire tampon.  De plus, ClickHouse en arri√®re-plan continue de constamment effectuer la fusion de segments, de sorte que de nombreuses petites informations seront combin√©es et enregistr√©es plusieurs fois, augmentant ainsi l'intensit√© d'enregistrement.  Dans ce cas, trop de pi√®ces non li√©es entra√Æneront un √©tranglement agressif des inserts tant que la fusion se poursuivra.  Nous avons constat√© que le meilleur compromis entre la r√©ception de donn√©es en temps r√©el et les performances de r√©ception est de recevoir un nombre limit√© d'insertions par seconde dans la table. <br><br>  La cl√© des performances de lecture de table est l'indexation et le positionnement des donn√©es sur le disque.  Quelle que soit la vitesse du traitement, lorsque le moteur doit analyser des t√©raoctets de donn√©es √† partir du disque et n'en utiliser qu'une partie, cela prendra du temps.  ClickHouse est un magasin de colonnes, donc chaque segment contient un fichier pour chaque colonne (colonne) avec des valeurs tri√©es pour chaque ligne.  Ainsi, des colonnes enti√®res qui ne figurent pas dans la requ√™te peuvent √™tre ignor√©es en premier, puis plusieurs cellules peuvent √™tre trait√©es en parall√®le avec l'ex√©cution vectoris√©e.  Pour √©viter une analyse compl√®te, chaque segment a un petit fichier d'index. <br><br>  √âtant donn√© que toutes les colonnes sont tri√©es par ¬´cl√© primaire¬ª, le fichier d'index ne contient que les √©tiquettes (lignes captur√©es) de chaque Ni√®me ligne afin de pouvoir les stocker en m√©moire m√™me pour les tr√®s grandes tables.  Par exemple, vous pouvez d√©finir les param√®tres par d√©faut "marquer chaque 8192√®me ligne", puis l'indexation "maigre" de la table avec 1 billion.  les lignes, qui s'int√®grent facilement dans la m√©moire, n'occuperont que 122 070 caract√®res. <br><br><h3>  D√©veloppement du syst√®me </h3><br>  Le d√©veloppement et l'am√©lioration de Clickhouse peuvent √™tre retrac√©s jusqu'au <a href="https://github.com/yandex/ClickHouse/pulse">repo Github</a> et s'assurer que le processus de ¬´croissance¬ª se d√©roule √† un rythme impressionnant. <br><br><img src="https://habrastorage.org/webt/zl/iw/iz/zliwizhn6we2o5easwfkystr5g0.jpeg"><br><br><h3>  Popularit√© </h3><br>  Clickhouse semble cro√Ætre de fa√ßon exponentielle, en particulier dans la communaut√© russophone.  La conf√©rence de l'an dernier, High load 2018 (Moscou, du 8 au 9 novembre 2018), a montr√© que des monstres tels que vk.com et Badoo utilisent Clickhouse, avec lequel ils collent des donn√©es (par exemple, des journaux) de dizaines de milliers de serveurs en m√™me temps.  Dans une vid√©o de 40 minutes, <a href="https://www.youtube.com/watch%3Fv%3DpbbcMcrQoXw">Yuri Nasretdinov de l'√©quipe VKontakte explique comment cela se fait</a> .  Bient√¥t, nous publierons la transcription sur Habr pour la commodit√© de travailler avec le mat√©riel. <br><br><h3>  Domaines d'application </h3><br>  Apr√®s avoir pass√© un peu de temps √† rechercher, je pense qu'il y a des domaines dans lesquels ClickHouse peut √™tre utile ou capable de remplacer compl√®tement d'autres solutions plus traditionnelles et populaires, telles que MySQL, PostgreSQL, ELK, Google Big Query, Amazon RedShift, TimescaleDB, Hadoop, MapReduce, Pinot et Druid.  Voici les d√©tails de l'utilisation de ClickHouse pour mettre √† niveau ou remplacer compl√®tement les SGBD ci-dessus. <br><br><h3>  Extension de MySQL et PostgreSQL </h3><br>  Plus r√©cemment, nous avons partiellement remplac√© MySQL par ClickHouse pour la <a href="https://www.mautic.org/">plateforme de newsletter Mautic newsletter</a> .  Le probl√®me √©tait que MySQL, en raison de sa conception mal con√ßue, journalisait chaque e-mail envoy√© et chaque lien dans cet e-mail avec un hachage base64, cr√©ant une √©norme table MySQL (email_stats).  Apr√®s avoir envoy√© seulement 10 millions de lettres aux abonn√©s du service, cette table occupait 150 Go d'espace fichier et MySQL a commenc√© √† "s'√©mousser" sur les requ√™tes simples.  Pour r√©soudre le probl√®me d'espace fichier, nous avons utilis√© avec succ√®s la compression de table InnoDB, qui l'a r√©duite de 4 fois.  Cependant, cela n'a toujours aucun sens de stocker plus de 20 √† 30 millions de courriels dans MySQL juste pour la lecture de l'histoire, car toute simple demande qui, pour une raison quelconque, doit effectuer une analyse compl√®te entra√Æne un √©change et une charge importante sur les E / S, par exemple. √† propos desquels nous recevons r√©guli√®rement des avertissements Zabbix. <br><br><img src="https://habrastorage.org/webt/t6/h9/3d/t6h93dxzyu7l_ddcmb9g-zhctwk.jpeg"><br><br>  Clickhouse utilise deux algorithmes de compression qui r√©duisent la quantit√© de donn√©es d'environ <a href="https://www.altinity.com/blog/2017/11/21/compression-in-clickhouse">3</a> √† <a href="https://www.altinity.com/blog/2017/11/21/compression-in-clickhouse">4 fois</a> , mais dans ce cas particulier, les donn√©es √©taient particuli√®rement ¬´compressibles¬ª. <br><br><img src="https://habrastorage.org/webt/rd/8o/0x/rd8o0xpshmzaqfmbzblzp-cgczm.jpeg"><br><br><h3>  Remplacement ELK </h3><br>  D'apr√®s notre propre exp√©rience, la pile ELK (ElasticSearch, Logstash et Kibana, dans ce cas particulier, ElasticSearch) n√©cessite beaucoup plus de ressources pour s'ex√©cuter que ce qui est n√©cessaire pour stocker les journaux.  ElasticSearch est un excellent moteur si vous avez besoin d'une bonne recherche de journal en texte int√©gral (et je ne pense pas que vous en ayez vraiment besoin), mais je me demande pourquoi, de facto, il est devenu le moteur de journalisation standard.  Ses performances de r√©ception en combinaison avec Logstash ont cr√©√© des probl√®mes pour nous m√™me avec des charges plut√¥t petites et ont n√©cessit√© l'ajout d'une quantit√© croissante de RAM et d'espace disque.  En tant que base de donn√©es, Clickhouse est meilleur qu'ElasticSearch pour les raisons suivantes: <br><br><ul><li>  Prise en charge du dialecte SQL; </li><li>  Le meilleur taux de compression des donn√©es stock√©es; </li><li>  Prise en charge des recherches d'expressions r√©guli√®res regex au lieu de recherches en texte int√©gral; </li><li>  Planification des requ√™tes am√©lior√©e et performances globales sup√©rieures. </li></ul><br>  Actuellement, le plus gros probl√®me qui se pose lors de la comparaison de ClickHouse avec ELK est le manque de solutions pour l'envoi des journaux, ainsi que le manque de documentation et d'aides √† la formation sur ce sujet.  Dans le m√™me temps, chaque utilisateur peut configurer ELK √† l'aide du Digital Ocean Guide, qui est tr√®s important pour la mise en ≈ìuvre rapide de ces technologies.  Il y a un moteur de base de donn√©es ici, mais il n'y a pas encore de Filebeat pour ClickHouse.  Oui, il existe <a href="https://www.fluentd.org/">fluentd</a> et un syst√®me pour travailler avec les journaux de <a href="https://github.com/Altinity/clicktail">loghouse</a> , il existe un outil <a href="https://github.com/Altinity/clicktail">clicktail</a> pour entrer les donn√©es des fichiers journaux dans ClickHouse, mais tout cela prend plus de temps.  Cependant, ClickHouse m√®ne toujours en raison de sa simplicit√©, donc m√™me les d√©butants l'installent de mani√®re √©l√©mentaire et commencent √† l'utiliser pleinement en seulement 10 minutes. <br><br>  Pr√©f√©rant des solutions minimalistes, j'ai essay√© d'utiliser FluentBit, un outil pour envoyer des journaux avec une tr√®s petite quantit√© de m√©moire, avec ClickHouse, tout en essayant d'√©viter d'utiliser Kafka.  Cependant, des incompatibilit√©s mineures, telles que des <a href="https://github.com/fluent/fluent-bit/issues/848">probl√®mes de format de date</a> , doivent √™tre corrig√©es avant de pouvoir le faire sans une couche proxy qui convertit les donn√©es de FluentBit en ClickHouse. <br><br>  Comme alternative √† Kibana, vous pouvez utiliser <a href="https://github.com/Vertamedia/clickhouse-grafana">Grafana</a> comme <a href="https://github.com/Vertamedia/clickhouse-grafana">backend</a> ClickHouse.  Si je comprends bien, cela peut entra√Æner des probl√®mes de performances lors du rendu d'une √©norme quantit√© de points de donn√©es, en particulier avec les anciennes versions de Grafana.  Chez Qwintry, nous n'avons pas encore essay√©, mais des plaintes √† ce sujet apparaissent de temps en temps sur le canal de support ClickHouse dans Telegram. <br><br><h3>  Remplacement de Google Big Query et Amazon RedShift (solution pour les grandes entreprises) </h3><br>  Le cas d'utilisation id√©al pour BigQuery est de t√©l√©charger 1 To de donn√©es JSON et d'effectuer des requ√™tes analytiques sur celles-ci.  Big Query est un excellent produit dont l'√©volutivit√© est difficile √† surestimer.  C'est un logiciel beaucoup plus complexe que ClickHouse, fonctionnant sur un cluster interne, mais du point de vue du client, il a beaucoup en commun avec ClickHouse.  BigQuery peut rapidement augmenter le prix d√®s que vous payez pour chaque SELECT, c'est donc une v√©ritable solution SaaS avec tous ses avantages et ses inconv√©nients. <br><br>  ClickHouse est le meilleur choix lorsque vous effectuez de nombreuses requ√™tes co√ªteuses en calcul.  Plus vous ex√©cutez de requ√™tes SELECT chaque jour, plus il est logique de remplacer Big Query par ClickHouse, car un tel remplacement vous fera √©conomiser des milliers de dollars en termes de t√©raoctets de donn√©es trait√©es.  Cela ne s'applique pas aux donn√©es stock√©es, ce qui est assez bon march√© √† traiter dans Big Query. <br><br>  L'article du cofondateur d'Altinity, Alexander Zaitsev, <a href="https://www.altinity.com/blog/2017/10/23/migration-to-clickhouse">¬´Switching to ClickHouse¬ª,</a> parle des avantages d'une telle migration de SGBD. <br><br><h3>  Remplacement de TimescaleDB </h3><br>  TimescaleDB est une extension PostgreSQL qui optimise le travail avec les s√©ries temporelles de s√©ries chronologiques dans une base de donn√©es r√©guli√®re ( <a href="https://docs.timescale.com/v1.0/introduction">https://docs.timescale.com/v1.0/introduction</a> , <a href="https://habr.com/ru/company/zabbix/blog/458530/">https://habr.com/en/company/zabbix/blog/458530 /</a> ). <br><br>  Bien que ClickHouse ne soit pas un concurrent s√©rieux dans le cr√©neau des s√©ries temporelles, mais la structure des colonnes et l'ex√©cution vectorielle des requ√™tes, dans la plupart des cas de traitement des requ√™tes analytiques, il est beaucoup plus rapide que TimescaleDB.  Dans le m√™me temps, les performances de r√©ception des donn√©es de paquets ClickHouse sont environ 3 fois plus √©lev√©es, en outre, elles utilisent 20 fois moins d'espace disque, ce qui est vraiment important pour le traitement de grandes quantit√©s de donn√©es historiques: <a href="https://www.altinity.com/blog/ClickHouse-for-time-series">https://www.altinity.com/blog/ClickHouse-for -s√©rie temporelle</a> . <br><br>  Contrairement √† ClickHouse, la seule fa√ßon d'√©conomiser de l'espace disque dans TimescaleDB est d'utiliser ZFS ou des syst√®mes de fichiers similaires. <br><br>  Les prochaines mises √† jour de ClickHouse introduiront probablement une compression delta, ce qui la rendra encore plus adapt√©e au traitement et au stockage des donn√©es de s√©ries chronologiques.  TimescaleDB peut √™tre un meilleur choix qu'un ClickHouse nu dans les cas suivants: <br><br><ul><li>  petites installations avec une tr√®s petite quantit√© de RAM (&lt;3 Go); </li><li>  un grand nombre de petits INSERT que vous ne souhaitez pas mettre en tampon dans de grands fragments; </li><li>  meilleure coh√©rence, uniformit√© et exigences ACID; </li><li>  Prise en charge de PostGIS; </li><li>  fusion avec les tables PostgreSQL existantes, car Timescale DB est essentiellement PostgreSQL. </li></ul><br><h3>  Concurrence avec les syst√®mes Hadoop et MapReduce </h3><br>  Hadoop et d'autres produits MapReduce peuvent effectuer de nombreux calculs complexes, mais ils fonctionnent g√©n√©ralement avec des retards √©normes. ClickHouse r√©sout ce probl√®me en traitant des t√©raoctets de donn√©es et en fournissant des r√©sultats presque instantan√©ment.  Ainsi, ClickHouse est beaucoup plus efficace pour effectuer des recherches analytiques rapides et interactives, ce qui devrait √™tre int√©ressant pour les sp√©cialistes du traitement des donn√©es. <br><br><h3>  Comp√©tition avec Pinot et Druide </h3><br>  Les concurrents les plus proches de ClickHouse sont Pinot et Druid, un produit open source lin√©airement √©volutif en colonnes.  Un excellent travail de comparaison de ces syst√®mes a √©t√© publi√© dans un article de <a href="https://medium.com/%40leventov/comparison-of-the-open-source-olap-systems-for-big-data-ClickHouse-druid-and-pinot-8e042a5ed1c7">Roman Leventov</a> dat√© du 1er f√©vrier 2018. <br><br><img src="https://habrastorage.org/webt/4c/26/hb/4c26hbndeb9gj0mq86lyfrmpc0e.jpeg"><br><br>  Cet article n√©cessite une mise √† jour - il indique que ClickHouse ne prend pas en charge les op√©rations UPDATE et DELETE, ce qui n'est pas enti√®rement vrai pour les derni√®res versions. <br><br>  Nous n'avons pas assez d'exp√©rience avec ces SGBD, mais je n'aime pas la complexit√© de l'infrastructure utilis√©e pour ex√©cuter Druid et Pinot - c'est tout un tas de ¬´pi√®ces mobiles¬ª entour√©es de Java de tous les c√¥t√©s. <br><br>  Druid et Pinot sont des projets d'incubateur Apache, dont le d√©veloppement est couvert en d√©tail par Apache dans les pages de ses projets GitHub.  Le pinot est apparu dans l'incubateur en octobre 2018, et le druide est n√© 8 mois plus t√¥t - en f√©vrier. <br><br>  Le manque d'informations sur le fonctionnement d'AFS me pose quelques questions, et peut-√™tre stupides.  Je me demande si les auteurs de Pinot ont remarqu√© que la Fondation Apache est plus dispos√©e envers le druide, et cette attitude envers le concurrent a-t-elle fait envie?  Le d√©veloppement de Druid va-t-il ralentir et Pinot va-t-il s'acc√©l√©rer si des sponsors soutenant les premiers s'int√©ressent soudainement aux seconds? <br><br><h3>  Inconv√©nients de ClickHouse </h3><br>  Immaturit√©: √âvidemment, ce n'est toujours pas une technologie ennuyeuse, mais en tout cas, rien de semblable n'est observ√© dans d'autres SGBD en colonnes. <br><br>  Les petits inserts ne fonctionnent pas bien √† grande vitesse: les inserts doivent √™tre divis√©s en gros morceaux, car les performances des petits inserts diminuent proportionnellement au nombre de colonnes de chaque ligne.  C'est ainsi que ClickHouse stocke les donn√©es sur le disque - chaque colonne signifie 1 fichier ou plus, donc pour ins√©rer 1 ligne contenant 100 colonnes, vous devez ouvrir et √©crire au moins 100 fichiers.  C'est pourquoi un interm√©diaire est n√©cessaire pour mettre en m√©moire tampon les insertions (sauf si le client lui-m√™me fournit la mise en m√©moire tampon) - il s'agit g√©n√©ralement de Kafka ou d'une sorte de syst√®me de gestion de file d'attente.  Vous pouvez √©galement utiliser le moteur de table Buffer pour copier ult√©rieurement de gros morceaux de donn√©es dans des tables MergeTree. <br><br>  Les jointures de table sont limit√©es par la RAM du serveur, mais au moins elles sont l√†!  Par exemple, Druid et Pinot n'ont pas de telles connexions du tout, car ils sont difficiles √† impl√©menter directement dans les syst√®mes distribu√©s qui ne prennent pas en charge le d√©placement de grandes donn√©es entre les n≈ìuds. <br><br><h3>  Conclusions </h3><br>  Dans les ann√©es √† venir, nous pr√©voyons d'utiliser largement ClickHouse dans Qwintry, car ce SGBD offre un excellent √©quilibre de performances, une faible surcharge, une √©volutivit√© et une simplicit√©.  Je suis √† peu pr√®s s√ªr qu'il commencera √† se propager rapidement d√®s que la communaut√© ClickHouse proposera de nouvelles fa√ßons de l'utiliser sur les petites et moyennes installations. <br><br><h3>  Un peu de publicit√© :) </h3><br>  Merci de rester avec nous.  Aimez-vous nos articles?  Vous voulez voir des mat√©riaux plus int√©ressants?  Soutenez-nous en passant une commande ou en recommandant √† vos amis <a href="https://ua-hosting.company/cloudvps/nl">des VPS bas√©s sur le cloud pour les d√©veloppeurs √† partir de 4,99 $</a> , un <b>analogue unique de serveurs d'entr√©e de gamme que nous avons invent√©s pour vous:</b> <a href="https://habr.com/company/ua-hosting/blog/347386/">Toute la v√©rit√© sur les VPS (KVM) E5-2697 v3 (6 c≈ìurs) 10 Go DDR4 480 Go SSD 1 Gbit / s √† partir de 19 $ ou comment diviser le serveur?</a>  (les options sont disponibles avec RAID1 et RAID10, jusqu'√† 24 c≈ìurs et jusqu'√† 40 Go de DDR4). <br><br>  <b>Dell R730xd 2 fois moins cher au centre de donn√©es Equinix Tier IV √† Amsterdam?</b>  Nous avons seulement <b><a href="https://ua-hosting.company/serversnl">2 x Intel TetraDeca-Core Xeon 2x E5-2697v3 2.6GHz 14C 64GB DDR4 4x960GB SSD 1Gbps 100 TV √† partir de 199 $</a> aux Pays-Bas!</b>  <b><b>Dell R420 - 2x E5-2430 2.2Ghz 6C 128GB DDR3 2x960GB SSD 1Gbps 100TB - √† partir de 99 $!</b></b>  Pour en savoir plus sur la <a href="https://habr.com/company/ua-hosting/blog/329618/">cr√©ation d'un b√¢timent d'infrastructure.</a>  <a href="https://habr.com/company/ua-hosting/blog/329618/">classe utilisant des serveurs Dell R730xd E5-2650 v4 co√ªtant 9 000 euros pour un sou?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr483112/">https://habr.com/ru/post/fr483112/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr483082/index.html">La chasse aux vuln√©rabilit√©s est 7% plus efficace</a></li>
<li><a href="../fr483084/index.html">Cam√©ra avec fonction de suivi</a></li>
<li><a href="../fr483086/index.html">R√©sultats de 2019: quels actifs se sont r√©v√©l√©s √™tre les plus rentables pour les investisseurs russes</a></li>
<li><a href="../fr483094/index.html">Comment j'ai r√©alis√© mon r√™ve lorsque j'ai visit√© le bureau russe de Microsoft</a></li>
<li><a href="../fr483110/index.html">Rostov-sur-le-Don: soci√©t√©s informatiques, communaut√©s et √©v√©nements en 2019</a></li>
<li><a href="../fr483114/index.html">Les fen√™tres modales que nous m√©ritons</a></li>
<li><a href="../fr483116/index.html">Fabrication d'un tuyau de t√©lescope √† la maison</a></li>
<li><a href="../fr483118/index.html">Ce qui sera ajout√© √† JavaScript en 2020</a></li>
<li><a href="../fr483120/index.html">Comment connecter des cartes dans une projection ellipso√Øde, si celle-ci n'est pas fournie?</a></li>
<li><a href="../fr483126/index.html">Les effets cryog√©niques peuvent assurer le transport en toute s√©curit√© des batteries de v√©hicules √©lectriques endommag√©es</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
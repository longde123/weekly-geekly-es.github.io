<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíë üßìüèº ‚óÄÔ∏è Pantalla de renderizado de agua ü§´ üßëüèΩ‚Äçü§ù‚ÄçüßëüèΩ üßöüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mi √∫ltima tarea en gr√°ficos t√©cnicos / renderizado fue encontrar una buena soluci√≥n para renderizar agua. En particular, la representaci√≥n de chorros ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pantalla de renderizado de agua</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420495/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/216/ca8/1f5/216ca81f5eb506eab2dbcfc730a904b4.png" alt="imagen"></div><br>  Mi √∫ltima tarea en gr√°ficos t√©cnicos / renderizado fue encontrar una buena soluci√≥n para renderizar agua.  En particular, la representaci√≥n de chorros de agua delgados y de r√°pido movimiento basados ‚Äã‚Äãen part√≠culas.  Durante la semana pasada, pens√© en buenos resultados, as√≠ que escribir√© un art√≠culo sobre esto. <br><br>  Realmente no me gusta el enfoque de cubos voxelizados / de marcha al procesar agua (ver, por ejemplo, renderizar una simulaci√≥n de fluido en Blender).  Cuando el volumen de agua est√° en la misma escala que la cuadr√≠cula utilizada para renderizar, el movimiento es notablemente discreto.  Este problema se puede resolver aumentando la resoluci√≥n de la cuadr√≠cula, pero para chorros delgados a distancias relativamente largas en tiempo real, simplemente no es pr√°ctico porque afecta en gran medida el tiempo de ejecuci√≥n y la memoria ocupada.  (Hay un precedente para usar estructuras de voxel dispersas para mejorar la situaci√≥n. Pero no estoy seguro de qu√© tan bien funciona para sistemas din√°micos. Adem√°s, este no es el nivel de dificultad con el que me gustar√≠a trabajar). <br><br>  La primera alternativa que explor√© fue Screen Space Meshes de M√ºller.  Utilizan la representaci√≥n de part√≠culas de agua en un tamp√≥n de profundidad, alis√°ndolo, reconociendo fragmentos conectados de profundidad similar y construyendo una malla a partir del resultado utilizando cuadrados de marcha.  Hoy, este m√©todo probablemente se ha vuelto <i>m√°s</i> aplicable que en 2007 (ya que ahora podemos crear una malla en el sombreador de c√≥mputo), pero todav√≠a est√° asociado con un mayor nivel de complejidad y costo de lo que quisiera. <br><br>  Al final, encontr√© la presentaci√≥n de Simon Green con GDC 2010, Screen Space Fluid Rendering For Games.  Comienza exactamente de la misma manera que Screen Space Meshes: renderizando part√≠culas en el b√∫fer de profundidad y suaviz√°ndolo.  Pero en lugar de construir la malla, el b√∫fer resultante se usa para sombrear y componer el l√≠quido en la escena principal (al registrar expl√≠citamente la profundidad). Decid√≠ implementar dicho sistema. <br><a name="habracut"></a><br><h3>  Preparaci√≥n </h3><br>  Varios proyectos anteriores de Unity me ense√±aron a no lidiar con las limitaciones de renderizar el motor.  Por lo tanto, los buffers fluidos son procesados ‚Äã‚Äãpor una segunda c√°mara con una profundidad de campo menor para que se muestre frente a la escena principal.  Cada sistema de fluido existe en una capa de representaci√≥n separada;  la c√°mara principal excluye una capa de agua y la segunda c√°mara solo produce agua.  Ambas c√°maras son hijos de un objeto vac√≠o para garantizar su orientaci√≥n relativa. <br><br>  Tal esquema significa que puedo renderizar casi cualquier cosa en la capa l√≠quida, y se ver√° como espero que sea.  En el contexto de mi escena de demostraci√≥n, esto significa que algunos chorros y salpicaduras de subemisores pueden fusionarse.  Adem√°s, esto permitir√° la mezcla de otros sistemas de agua, por ejemplo, vol√∫menes basados ‚Äã‚Äãen campos de altitud, que luego se pueden representar igual.  (No he probado esto todav√≠a). <br><br>  La fuente de agua en mi escena es un sistema de part√≠culas est√°ndar.  De hecho, no se realiza simulaci√≥n de fluidos.  Esto, a su vez, significa que las part√≠culas no se superponen entre s√≠ de una manera completamente f√≠sica, pero el resultado final parece aceptable en la pr√°ctica. <br><br><h3>  Fluid buffer rendering </h3><br>  El primer paso en esta t√©cnica es renderizar el tamp√≥n de fluido base.  Este es un b√∫fer fuera de la pantalla que contiene (en la etapa actual de mi implementaci√≥n) lo siguiente: ancho de fluido, vector de movimiento en el espacio de la pantalla y valor de ruido.  Adem√°s, renderizamos el b√∫fer de profundidad registrando expl√≠citamente la profundidad del sombreador de fragmentos para convertir cada cuadr√°ngulo de una part√≠cula en una "bola" esf√©rica (bueno, en realidad el√≠ptica). <br><br>  Los c√°lculos de profundidad y anchura son bastante simples: <br><br><pre><code class="cpp hljs">frag_out o; float3 N; N.xy = i.uv*<span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> r2 = dot(N.xy, N.xy); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (r2 &gt; <span class="hljs-number"><span class="hljs-number">1.0</span></span>) discard; Nz = <span class="hljs-built_in"><span class="hljs-built_in">sqrt</span></span>(<span class="hljs-number"><span class="hljs-number">1.0</span></span> - r2); float4 pixel_pos = float4(i.view_pos + N * i.size, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); float4 clip_pos = mul(UNITY_MATRIX_P, pixel_pos); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> depth = clip_pos.z / clip_pos.w; o.depth = depth; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> thick = Nz * i.size * <span class="hljs-number"><span class="hljs-number">2</span></span>;</code> </pre> <br>  (Por supuesto, los c√°lculos de profundidad se pueden simplificar; desde la posici√≥n del clip solo necesitamos z y w). <br><br>  Un poco m√°s tarde, volveremos al sombreador de fragmentos para los vectores de movimiento y ruido. <br><br>  La diversi√≥n comienza en el sombreador de v√©rtices, y es aqu√≠ donde me desv√≠o de la t√©cnica verde.  El objetivo de este proyecto es hacer chorros de agua a alta velocidad;  Se puede realizar con la ayuda de part√≠culas esf√©ricas, pero se necesitar√° una gran cantidad de ellas para crear un chorro continuo.  En cambio, estirar√© los cuadr√°ngulos de las part√≠culas en funci√≥n de su velocidad, que a su vez estira las bolas de profundidad, haci√©ndolas no esf√©ricas, sino el√≠pticas.  (Dado que los c√°lculos de profundidad se basan en UV, que no cambian, todo funciona.) <br><br>  Los usuarios experimentados de Unity pueden preguntarse por qu√© simplemente no uso el modo de Cartelera Estirada incorporado disponible en el sistema de part√≠culas Unity.  Stretched Billboard realiza estiramientos incondicionales a lo largo del vector de velocidad en el espacio del mundo.  En el caso general, esto es bastante adecuado, pero conduce a un problema muy notable cuando el vector de velocidad se codirige con el vector de c√°mara orientado hacia adelante (o muy cerca de √©l).  Billboard se estira en la pantalla, lo que hace que su naturaleza bidimensional sea muy notable. <br><br>  En cambio, uso una valla publicitaria dirigida a la c√°mara y proyecto el vector de velocidad en el plano de la part√≠cula, utiliz√°ndolo para estirar el cuadril√°tero.  Si el vector de velocidad es perpendicular al plano (dirigido a la pantalla o lejos de √©l), entonces la part√≠cula permanece sin estirar y esf√©rica, como deber√≠a, y cuando est√° inclinada, la part√≠cula se estira en esta direcci√≥n, que es lo que necesitamos. <br><br>  Dejemos una larga explicaci√≥n, aqu√≠ hay una funci√≥n bastante simple: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ComputeStretchedVertex</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float3 p_world, float3 c_world, float3 vdir_world, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> stretch_amount)</span></span></span><span class="hljs-function"> </span></span>{ float3 center_offset = p_world - c_world; float3 stretch_offset = dot(center_offset, vdir_world) * vdir_world; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> p_world + stretch_offset * lerp(<span class="hljs-number"><span class="hljs-number">0.25f</span></span>, <span class="hljs-number"><span class="hljs-number">3.0f</span></span>, stretch_amount); }</code> </pre> <br>  Para calcular el vector de movimiento del espacio de la pantalla, calculamos dos conjuntos de posiciones de vectores: <br><br><pre> <code class="cpp hljs">float3 vp1 = ComputeStretchedVertex( vertex_wp, center_wp, velocity_dir_w, rand); float3 vp0 = ComputeStretchedVertex( vertex_wp - velocity_w * unity_DeltaTime.x, center_wp - velocity_w * unity_DeltaTime.x, velocity_dir_w, rand); o.motion_0 = mul(_LastVP, float4(vp0, <span class="hljs-number"><span class="hljs-number">1.0</span></span>)); o.motion_1 = mul(_CurrVP, float4(vp1, <span class="hljs-number"><span class="hljs-number">1.0</span></span>));</code> </pre> <br>  Tenga en cuenta que dado que calculamos los vectores de movimiento en el pasaje principal y no en el pasaje de los vectores de velocidad, Unity no nos proporciona una proyecci√≥n de corriente previa o sin distorsi√≥n desde la vista.  Para solucionar esto, agregu√© un script simple a los sistemas de part√≠culas correspondientes: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">ScreenspaceLiquidRenderer</span></span> : <span class="hljs-title"><span class="hljs-title">MonoBehaviour</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> Camera LiquidCamera; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> ParticleSystemRenderer m_ParticleRenderer; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> m_First; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Matrix4x4 m_PreviousVP; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Start</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { m_ParticleRenderer = GetComponent(); m_First = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWillRenderObject</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { Matrix4x4 current_vp = LiquidCamera.nonJitteredProjectionMatrix * LiquidCamera.worldToCameraMatrix; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (m_First) { m_PreviousVP = current_vp; m_First = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } m_ParticleRenderer.material.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_LastVP"</span></span>, GL.GetGPUProjectionMatrix(m_PreviousVP, <span class="hljs-literal"><span class="hljs-literal">true</span></span>)); m_ParticleRenderer.material.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_CurrVP"</span></span>, GL.GetGPUProjectionMatrix(current_vp, <span class="hljs-literal"><span class="hljs-literal">true</span></span>)); m_PreviousVP = current_vp; } }</code> </pre> <br>  Cach√© la matriz anterior manualmente porque Camera.previousViewProjectionMatrix da resultados incorrectos. <br><br>  ¬Ø \ _ („ÉÑ) _ / ¬Ø <br><br>  (Adem√°s, este m√©todo viola el renderizado; puede ser prudente establecer constantes de matriz global en la pr√°ctica en lugar de usarlas para cada material). <br><br>  Volvamos al sombreador de fragmentos: utilizamos las posiciones proyectadas para calcular los vectores de movimiento del espacio de la pantalla: <br><br><pre> <code class="cpp hljs">float3 hp0 = i.motion_0.xyz / i.motion_0.w; float3 hp1 = i.motion_1.xyz / i.motion_1.w; float2 vp0 = (hp0.xy + <span class="hljs-number"><span class="hljs-number">1</span></span>) / <span class="hljs-number"><span class="hljs-number">2</span></span>; float2 vp1 = (hp1.xy + <span class="hljs-number"><span class="hljs-number">1</span></span>) / <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> UNITY_UV_STARTS_AT_TOP vp0.y = 1.0 - vp0.y; vp1.y = 1.0 - vp1.y; #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endif</span></span></span><span class="hljs-meta"> float2 vel = vp1 - vp0;</span></span></code> </pre> <br>  (Los c√°lculos de vectores de movimiento con casi ning√∫n cambio se toman de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">https://github.com/keijiro/ParticleMotionVector/blob/master/Assets/ParticleMotionVector/Shaders/Motion.cginc</a> ) <br><br>  Finalmente, el √∫ltimo valor en el tamp√≥n de fluido es el ruido.  Utilizo un n√∫mero aleatorio estable para cada part√≠cula para seleccionar uno de los cuatro ruidos (empaquetados en una sola textura).  Luego se escala por la velocidad y la unidad menos el tama√±o de part√≠cula (por lo tanto, las part√≠culas r√°pidas y peque√±as son m√°s ruidosas).  Este valor de ruido se utiliza en el paso de sombreado para distorsionar las normales y agregar una capa de espuma.  El trabajo de Green utiliza ruido blanco de tres canales, pero un trabajo m√°s nuevo (Renderizado de fluidos de espacio de pantalla con flujo de curvatura) propone utilizar el ruido de Perlin.  Utilizo ruido Voronoi / ruido celular con diferentes escalas: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/743/9f4/c0b/7439f4c0beebbc16cbfa536c516b2fcf.png"></div><br><h3>  Problemas de mezcla (y soluciones) </h3><br>  Y aqu√≠ aparecen los primeros problemas de mi implementaci√≥n.  Para el correcto c√°lculo del espesor de las part√≠culas se mezclan aditivamente.  Como la mezcla afecta a todas las salidas, esto significa que los vectores de ruido y movimiento tambi√©n se mezclan aditivamente.  El ruido aditivo nos conviene bastante, pero no los vectores aditivos, y si los dejas como est√°n, obtienes un repugnante antisolapamiento (TAA) y un desenfoque de movimiento.  Para resolver este problema, cuando renderizo un b√∫fer fluido, simplemente multiplico los vectores de movimiento por el grosor y divido por el grosor total en el paso de sombreado.  Esto nos da un vector de movimiento promedio ponderado para todas las part√≠culas superpuestas;  no es exactamente lo que necesitamos (se crean artefactos extra√±os cuando se cruzan varios chorros), pero es bastante aceptable. <br><br>  Un problema m√°s complejo es la profundidad;  Para la representaci√≥n adecuada del b√∫fer de profundidad, necesitamos tener activos tanto el registro de profundidad como la verificaci√≥n de profundidad.  Esto puede causar problemas si las part√≠culas no se clasifican (porque la diferencia en el orden de renderizado puede hacer que la salida de part√≠culas superpuestas por otras se recorte).  Por lo tanto, ordenamos al sistema de part√≠culas Unity que clasifique las part√≠culas por profundidad, y luego cruzamos nuestros dedos y esperamos.  que los sistemas tambi√©n rendir√°n en profundidad.  Tendremos * casos * de sistemas superpuestos (por ejemplo, la intersecci√≥n de dos chorros de part√≠culas) que no se procesan correctamente, lo que conducir√° a un grosor menor.  Pero esto no sucede con mucha frecuencia y no afecta en gran medida la apariencia. <br><br>  Lo m√°s probable es que el enfoque correcto sea hacer que los buffers de profundidad y color est√©n completamente separados;  La recompensa por esto ser√° la representaci√≥n de dos pasos.  Vale la pena explorar este problema al configurar el sistema. <br><br><h3>  Suavizado de profundidad </h3><br>  Finalmente, lo m√°s importante en la t√©cnica verde.  Colocamos un mont√≥n de bolas esf√©ricas en el b√∫fer de profundidad, pero en realidad, el agua no consiste en "bolas".  As√≠ que ahora tomamos esta aproximaci√≥n y la difuminamos para que se parezca m√°s a la superficie de un l√≠quido. <br><br>  El enfoque ingenuo es simplemente aplicar profundidades de ruido gaussianas a todo el b√∫fer.  Crea resultados extra√±os: suaviza los puntos distantes m√°s que los cercanos y difumina los bordes de las siluetas.  En cambio, podemos cambiar el radio de desenfoque en profundidad y usar desenfoque de dos lados para guardar los bordes. <br><br>  Aqu√≠ solo surge un problema: tales cambios hacen que el desenfoque sea indistinguible.  El desenfoque compartido se puede realizar en dos pasadas: desenfoque horizontal y luego vertical.  El desenfoque indistinguible se realiza en una sola pasada.  Esta diferencia es importante porque el desenfoque compartido se escala linealmente (O (w) + O (h)), y el desenfoque no compartido se escala directamente (O (w * h)).  El desenfoque no compartido a gran escala se est√° volviendo r√°pidamente inaplicable en la pr√°ctica. <br><br>  Como adultos, desarrolladores responsables, podemos hacer el movimiento obvio: cerrar los ojos, fingir que el ruido bidireccional * es * compartido y a√∫n implementarlo con pasillos horizontales y verticales separados. <br><br>  Green en su presentaci√≥n demostr√≥ que aunque este enfoque <i>crea</i> artefactos en el resultado resultante (especialmente al reconstruir normales), la etapa de sombreado los oculta bien.  Cuando trabajo con las corrientes de agua m√°s estrechas que creo, estos artefactos son a√∫n menos notables y no afectan particularmente el resultado. <br><br><h3>  Sombreado </h3><br>  Finalmente terminamos de trabajar con el tamp√≥n fluido.  Ahora pase a la segunda parte del efecto: sombrear y componer la imagen principal. <br><br>  Aqu√≠ nos encontramos con muchas restricciones de representaci√≥n de Unity.  Decid√≠ iluminar el agua solo con la luz del sol y el skybox;  El soporte de fuentes de iluminaci√≥n adicionales requiere varios pases (¬°esto es un desperdicio!) O construir una estructura de b√∫squeda de iluminaci√≥n en el lado de la GPU (costosa y bastante complicada).  Adem√°s, dado que Unity no proporciona acceso a los mapas de sombras, y las luces direccionales usan sombras en el espacio de la pantalla (basadas en un b√∫fer de profundidad representado por una geometr√≠a opaca), no tenemos acceso a la informaci√≥n de sombras de una fuente de luz solar.  Puede adjuntar un b√∫fer de comando a una fuente de luz solar para crear un mapa de sombra del espacio de la pantalla espec√≠ficamente para el agua, pero hasta ahora no lo he hecho. <br><br>  La √∫ltima etapa de sombreado se controla mediante un script y utiliza el b√∫fer de comandos para enviar llamadas de sorteo.  Esto es <i>necesario</i> porque la textura del vector de movimiento (utilizada para el suavizado temporal (TAA) y el desenfoque de movimiento) no se puede utilizar para la representaci√≥n directa con Graphics.SetRenderTarget ().  En el gui√≥n adjunto a la c√°mara principal, escribimos lo siguiente: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Start</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-comment"><span class="hljs-comment">//... m_QuadMesh = new Mesh(); m_QuadMesh.subMeshCount = 1; m_QuadMesh.vertices = new Vector3[] { new Vector3(0, 0, 0.1f), new Vector3(1, 0, 0.1f), new Vector3(1, 1, 0.1f), new Vector3(0, 1, 0.1f), }; m_QuadMesh.uv = new Vector2[] { new Vector2(0, 0), new Vector2(1, 0), new Vector2(1, 1), new Vector2(0, 1), }; m_QuadMesh.triangles = new int[] { 0, 1, 2, 0, 2, 3, }; m_QuadMesh.UploadMeshData(false); m_CommandBuffer = new CommandBuffer(); m_CommandBuffer.Clear(); m_CommandBuffer.SetProjectionMatrix( GL.GetGPUProjectionMatrix( Matrix4x4.Ortho(0, 1, 0, 1, -1, 100), false)); m_CommandBuffer.SetRenderTarget( BuiltinRenderTextureType.CameraTarget, BuiltinRenderTextureType.CameraTarget); m_CommandBuffer.DrawMesh( m_QuadMesh, Matrix4x4.identity, m_Mat, 0, m_Mat.FindPass("LIQUIDCOMPOSITE")); m_CommandBuffer.SetRenderTarget( BuiltinRenderTextureType.MotionVectors, BuiltinRenderTextureType.Depth); m_CommandBuffer.DrawMesh( m_QuadMesh, Matrix4x4.identity, m_Mat, 0, m_Mat.FindPass("MOTION")); }</span></span></code> </pre> <br>  Los buffers de color y los vectores de movimiento no se pueden representar simult√°neamente con MRT (objetivos de renderizado m√∫ltiple).  No pude encontrar la raz√≥n.  Adem√°s, requieren uni√≥n a diferentes tampones de profundidad.  Afortunadamente, escribimos la profundidad en estos dos buffers de profundidad, por lo que volver a proyectar el suavizado temporal funciona bien (oh, es un placer trabajar con el motor de caja negra). <br><br>  En cada cuadro, arrojamos un render compuesto de OnPostRender (): <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-function">RenderTexture </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GenerateRefractionTexture</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { RenderTexture result = RenderTexture.GetTemporary(m_MainCamera.activeTexture.descriptor); Graphics.Blit(m_MainCamera.activeTexture, result); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnPostRender</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (ScreenspaceLiquidCamera &amp;&amp; ScreenspaceLiquidCamera.IsReady()) { RenderTexture refraction_texture = GenerateRefractionTexture(); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_MainTex"</span></span>, ScreenspaceLiquidCamera.GetColorBuffer()); m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_MainTex_TexelSize"</span></span>, ScreenspaceLiquidCamera.GetTexelSize()); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_LiquidRefractTexture"</span></span>, refraction_texture); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_MainDepth"</span></span>, ScreenspaceLiquidCamera.GetDepthBuffer()); m_Mat.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_DepthViewFromClip"</span></span>, ScreenspaceLiquidCamera.GetProjection().inverse); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (SunLight) { m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_SunDir"</span></span>, transform.InverseTransformVector(-SunLight.transform.forward)); m_Mat.SetColor(<span class="hljs-string"><span class="hljs-string">"_SunColor"</span></span>, SunLight.color * SunLight.intensity); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_SunDir"</span></span>, transform.InverseTransformVector(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Vector3(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>))); m_Mat.SetColor(<span class="hljs-string"><span class="hljs-string">"_SunColor"</span></span>, Color.white); } m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_ReflectionProbe"</span></span>, ReflectionProbe.defaultTexture); m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_ReflectionProbe_HDR"</span></span>, ReflectionProbe.defaultTextureHDRDecodeValues); Graphics.ExecuteCommandBuffer(m_CommandBuffer); RenderTexture.ReleaseTemporary(refraction_texture); } }</code> </pre> <br>  Y aqu√≠ es donde termina la participaci√≥n de la CPU, luego solo van los sombreadores. <br><br>  Comencemos con el paso de los vectores de movimiento.  As√≠ es como se ve todo el sombreador: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"UnityCG.cginc"</span></span></span><span class="hljs-meta"> sampler2D _MainDepth; sampler2D _MainTex; struct appdata { float4 vertex : POSITION; float2 uv : TEXCOORD0; }; struct v2f { float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; }; v2f vert(appdata v) { v2f o; o.vertex = mul(UNITY_MATRIX_P, v.vertex); o.uv = v.uv; return o; } struct frag_out { float4 color : SV_Target; float depth : SV_Depth; }; frag_out frag(v2f i) { frag_out o; float4 fluid = tex2D(_MainTex, i.uv); </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (fluid.a == 0) discard; o.depth = tex2D(_MainDepth, i.uv).r; float2 vel = fluid.gb / fluid.a; o.color = float4(vel, 0, 1); return o; }</span></span></code> </pre> <br>  La velocidad en el espacio de la pantalla se almacena en el canal verde y azul del tamp√≥n de fluido.  Como escalamos la velocidad por el grosor al renderizar el b√∫fer, nuevamente dividimos el grosor total (ubicado en el canal alfa) para obtener una velocidad promedio ponderada. <br><br>  Vale la pena se√±alar que cuando se trabaja con grandes vol√∫menes de agua, puede ser necesario otro m√©todo de procesamiento del buffer de velocidad.  Como renderizamos sin mezclar, los vectores de movimiento para todo lo que se encuentra <i>detr√°s del</i> agua se pierden, destruyendo el TAA y el desenfoque de movimiento de estos objetos.  Cuando se trabaja con corrientes delgadas de agua, esto no es un problema, pero puede interferir cuando se trabaja con una piscina o lago cuando necesitamos TAA o objetos de desenfoque de movimiento para ser claramente visibles a trav√©s de la superficie. <br><br>  M√°s interesante es el pase de sombreado principal.  Nuestra primera prioridad despu√©s de enmascarar con el grosor del l√≠quido es reconstruir la posici√≥n y la normalidad del espacio de visualizaci√≥n (espacio de visualizaci√≥n). <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ViewPosition</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float2 uv)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_z = tex2D(_MainDepth, uv).r; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_x = uv.x * <span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_y = <span class="hljs-number"><span class="hljs-number">1.0</span></span> - uv.y * <span class="hljs-number"><span class="hljs-number">2.0</span></span>; float4 clip_p = float4(clip_x, clip_y, clip_z, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); float4 view_p = mul(_DepthViewFromClip, clip_p); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (view_p.xyz / view_p.w); } <span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ReconstructNormal</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float2 uv, float3 vp11)</span></span></span><span class="hljs-function"> </span></span>{ float3 vp12 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)); float3 vp10 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>)); float3 vp21 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)); float3 vp01 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)); float3 dvpdx0 = vp11 - vp12; float3 dvpdx1 = vp10 - vp11; float3 dvpdy0 = vp11 - vp21; float3 dvpdy1 = vp01 - vp11; <span class="hljs-comment"><span class="hljs-comment">// Pick the closest float3 dvpdx = dot(dvpdx0, dvpdx0) &gt; dot(dvpdx1, dvpdx1) ? dvpdx1 : dvpdx0; float3 dvpdy = dot(dvpdy0, dvpdy0) &gt; dot(dvpdy1, dvpdy1) ? dvpdy1 : dvpdy0; return normalize(cross(dvpdy, dvpdx)); }</span></span></code> </pre> <br>  Esta es una forma costosa de reconstruir la posici√≥n del espacio de visualizaci√≥n: tomamos la posici√≥n en el espacio del clip y realizamos la operaci√≥n inversa de la proyecci√≥n. <br><br>  Despu√©s de encontrar una manera de reconstruir las posiciones, las normales son m√°s simples: calculamos la posici√≥n de los puntos vecinos en el b√∫fer de profundidad y construimos una base tangente a partir de ellos.  Para trabajar con los bordes de las siluetas, tomamos muestras en ambas direcciones y seleccionamos el punto m√°s cercano al espacio de vista para reconstruir lo normal.  Este m√©todo funciona sorprendentemente bien y causa problemas solo en el caso de objetos muy delgados. <br><br>  Esto significa que realizamos cinco operaciones separadas de proyecci√≥n inversa por p√≠xel (para el punto actual y cuatro vecinas).  Hay una forma menos costosa, pero esta publicaci√≥n ya es demasiado larga, as√≠ que la dejar√© para m√°s adelante. <br><br>  Las normales resultantes son: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b2c/0ed/7f6/b2c0ed7f6cfcc66473ff4e5380c46894.png"></div><br>  Distorsiono esta normal calculada usando las derivadas del valor de ruido del buffer de fluido, escaladas por el par√°metro de fuerza y ‚Äã‚Äãnormalizadas dividiendo por el grosor del chorro (por la misma raz√≥n que la velocidad): <br><br><pre> <code class="cpp hljs">N.xy += NoiseDerivatives(i.uv, fluid.r) * (_NoiseStrength / fluid.a); N = normalize(N);</code> </pre> <br>  Finalmente podemos proceder con el sombreado en s√≠.  El sombreado del agua consta de tres partes principales: reflexi√≥n especular, refracci√≥n especular y espuma. <br><br>  Reflection es un GGX est√°ndar tomado completamente del sombreador Unity est√°ndar.  (Con una correcci√≥n, se usa la F0 correcta del 2% para el agua). <br><br>  Con la refracci√≥n, todo es m√°s interesante.  La refracci√≥n correcta requiere trazado de rayos (o marcaje de rayos para un resultado aproximado).  Afortunadamente, la refracci√≥n es menos intuitiva para el ojo que la reflexi√≥n y, por lo tanto, los resultados incorrectos no son tan notables.  Por lo tanto, cambiamos la muestra de UV para la textura refractiva por x e y normales, escaladas por el par√°metro de espesor y fuerza: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> aspect = _MainTex_TexelSize.y * _MainTex_TexelSize.z; float2 refract_uv = (i.grab_pos.xy + N.xy * float2(<span class="hljs-number"><span class="hljs-number">1</span></span>, -aspect) * fluid.a * _RefractionMultiplier) / i.grab_pos.w; float4 refract_color = tex2D(_LiquidRefractTexture, refract_uv);</code> </pre> <br>  (Tenga en cuenta que se utiliza la correcci√≥n de correlaci√≥n; es <i>opcional</i> ; despu√©s de todo, es solo una aproximaci√≥n, pero agregarla es bastante simple). <br><br>  Esta luz refractada pasa a trav√©s del l√≠quido, por lo que parte de ella se absorbe: <br><br><pre> <code class="cpp hljs">float3 water_color = _AbsorptionColor.rgb * _AbsorptionIntensity; refract_color.rgb *= <span class="hljs-built_in"><span class="hljs-built_in">exp</span></span>(-water_color * fluid.a);</code> </pre> <br>  Tenga en cuenta que _AbsorptionColor se determina exactamente en el sentido opuesto al esperado: los valores de cada canal indican la cantidad de luz <i>absorbida en</i> lugar de transmitida.  Por lo tanto, _AbsorptionColor con un valor de (1, 0, 0) no da rojo, sino un color turquesa (verde azulado). <br><br>  La reflexi√≥n y la refracci√≥n se mezclan utilizando coeficientes de Fresnel: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> spec_blend = lerp(<span class="hljs-number"><span class="hljs-number">0.02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(<span class="hljs-number"><span class="hljs-number">1.0</span></span> - ldoth, <span class="hljs-number"><span class="hljs-number">5</span></span>)); float4 clear_color = lerp(refract_color, spec, spec_blend);</code> </pre> <br>  Hasta ese momento, jugamos con las reglas (principalmente) y usamos sombreado f√≠sico. <br><br>  Es bastante bueno, pero tiene un problema con el agua.  Es un poco dif√≠cil de ver: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ff2/4f2/ba2/ff24f2ba2dad5dc6fe7714ad3fd55124.png"></div><br>  Para solucionarlo, agreguemos un poco de espuma. <br><br>  La espuma aparece cuando el agua es turbulenta y el aire se mezcla con el agua para formar burbujas.  Tales burbujas crean todo tipo de variaciones en la reflexi√≥n y la refracci√≥n, lo que le da a toda el agua una sensaci√≥n de iluminaci√≥n difusa.  Modelar√© este comportamiento con luz ambiental envuelta: <br><br><pre> <code class="cpp hljs">float3 foam_color = _SunColor * saturate((dot(N, L)*<span class="hljs-number"><span class="hljs-number">0.25f</span></span> + <span class="hljs-number"><span class="hljs-number">0.25f</span></span>));</code> </pre> <br>  Se agrega al color final usando un factor especial, dependiendo del ruido del fluido y del coeficiente de Fresnel suavizado: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> foam_blend = saturate(fluid.r * _NoiseStrength) * lerp(<span class="hljs-number"><span class="hljs-number">0.05f</span></span>, <span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(<span class="hljs-number"><span class="hljs-number">1.0f</span></span> - ndotv, <span class="hljs-number"><span class="hljs-number">3</span></span>)); clear_color.rgb += foam_color * saturate(foam_blend);</code> </pre> <br>  La iluminaci√≥n ambiental envuelta se normaliza para conservar energ√≠a y poder usarse como una aproximaci√≥n de la difusi√≥n.  La mezcla del color de la espuma es m√°s notable.  Es una violaci√≥n bastante clara de la ley de conservaci√≥n de la energ√≠a. <br><br>  Pero en general, todo se ve bien y hace que la transmisi√≥n sea m√°s notable: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/216/ca8/1f5/216ca81f5eb506eab2dbcfc730a904b4.png"></div><br><h3>  M√°s trabajo y mejoras </h3><br>  En el sistema creado, mucho se puede mejorar. <br><br><ul><li>  Usando m√∫ltiples colores.  Por el momento, la absorci√≥n se calcula solo en la √∫ltima etapa de sombreado y utiliza un color y brillo constantes para todo el l√≠quido en la pantalla.  Es posible el soporte para diferentes colores, pero requiere un segundo tamp√≥n de color y la soluci√≥n de la integral de absorci√≥n para cada part√≠cula en el proceso de renderizaci√≥n del tamp√≥n de fluido base.  Esto podr√≠a ser potencialmente una operaci√≥n costosa. </li><li>  Cobertura total  Al tener acceso a la estructura de b√∫squeda de iluminaci√≥n en el lado de la GPU (ya sea construida a mano o gracias a la uni√≥n a la nueva tuber√≠a de renderizado Unity HD), podemos iluminar adecuadamente el agua con cualquier cantidad de fuentes de luz y crear la iluminaci√≥n ambiental adecuada. </li><li>  Refracci√≥n mejorada.  Con las texturas borrosas de la textura de fondo, podemos simular mejor la refracci√≥n para superficies rugosas.  En la pr√°ctica, esto no es muy √∫til para peque√±as pulverizaciones de l√≠quido, pero puede ser √∫til para grandes vol√∫menes. </li></ul><br>  Si tuviera la oportunidad, mejorar√≠a este sistema a la p√©rdida de un pulso, pero en este momento se puede llamar completo. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es420495/">https://habr.com/ru/post/es420495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es420479/index.html">Inyecci√≥n de dependencias en el servicio Apache Ignite.NET</a></li>
<li><a href="../es420487/index.html">Las empresas solicitan el derecho a los datos personales de los usuarios</a></li>
<li><a href="../es420489/index.html">Los nuevos procesadores ARM pueden competir con Core i5</a></li>
<li><a href="../es420491/index.html">Mi forma de guerrero, o c√≥mo prepar√© una aplicaci√≥n para la vida en Sailfish</a></li>
<li><a href="../es420493/index.html">¬øPuede el servicio de pedidos de comida estadounidense convertirse en Amazon en el mundo de los restaurantes?</a></li>
<li><a href="../es420497/index.html">Singularidad de verduras: Kroger lanza robocouriers para clientes de frutas y verduras en Arizona</a></li>
<li><a href="../es420499/index.html">Anatom√≠a de los sistemas de recomendaci√≥n. Primera parte</a></li>
<li><a href="../es420501/index.html">Linux en RAM: debirf way 2018</a></li>
<li><a href="../es420503/index.html">JS Developer Day, diferentes ciudades y comunidades: un d√≠a festivo</a></li>
<li><a href="../es420505/index.html">OpenAI Five ganar√° el equipo profesional en The International</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
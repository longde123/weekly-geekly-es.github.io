<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëçüèª üëêüèΩ üçû Uma nova abordagem para entender o pensamento de m√°quina üîñ üë©‚Äçüë¶‚Äçüë¶ ü§≤üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As redes neurais s√£o conhecidas por sua incompreensibilidade - o computador pode dar uma boa resposta, mas n√£o pode explicar o que levou a essa conclu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Uma nova abordagem para entender o pensamento de m√°quina</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440426/"><h3>  As redes neurais s√£o conhecidas por sua incompreensibilidade - o computador pode dar uma boa resposta, mas n√£o pode explicar o que levou a essa conclus√£o.  Bin Kim est√° desenvolvendo um "tradutor humano" para que, se a intelig√™ncia artificial quebrar, possamos entend√™-la. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/069/0a0/2c1/0690a02c197e3af97ec6e5cec9754fd6.jpg"><br>  <i>Bean Kim, pesquisadora do Google Brain, est√° desenvolvendo uma maneira de questionar um sistema de aprendizado de m√°quina sobre suas decis√µes.</i> <br><br>  Se o m√©dico lhe disser que voc√™ precisa de cirurgia, voc√™ descobrir√° o porqu√™ - e esperar√° que a explica√ß√£o dele pare√ßa significativa para voc√™, mesmo que voc√™ n√£o tenha sido treinado como m√©dico.  Been Kim, pesquisador do Google Brain, acredita que dever√≠amos esperar o mesmo da intelig√™ncia artificial (IA).  Ela √© especialista em aprendizado de m√°quina ‚Äúinterpretado‚Äù (MO) e deseja criar uma IA que possa explicar suas a√ß√µes a qualquer pessoa. <br><a name="habracut"></a><br>  Desde dez anos atr√°s, a tecnologia das redes neurais por tr√°s da IA ‚Äã‚Äãcome√ßou a se espalhar cada vez mais, foi capaz de transformar todos os processos, desde a classifica√ß√£o de e-mails at√© a descoberta de novos medicamentos, gra√ßas √† sua capacidade de aprender com os dados e procurar padr√µes neles.  Mas essa capacidade tem uma pegada inexplic√°vel: a pr√≥pria complexidade que permite que as redes neurais modernas com treinamento aprofundado aprendam com sucesso como dirigir um carro e reconhe√ßam a fraude com seguros tornam quase imposs√≠vel para os especialistas entender os princ√≠pios de seu trabalho.  Se uma rede neural √© treinada para procurar pacientes com risco de c√¢ncer de f√≠gado ou esquizofrenia - e um sistema chamado "Paciente Profundo" foi lan√ßado no Mount Sinai Hospital em Nova York em 2015 - ent√£o n√£o h√° como entender quais. dados caracterizam a rede neural "presta aten√ß√£o".  Esse "conhecimento" est√° espalhado por muitas camadas de neur√¥nios artificiais, cada uma das quais tem conex√µes com centenas ou milhares de outros neur√¥nios. <br><br>  √Ä medida que mais e mais ind√∫strias tentam automatizar ou melhorar seus processos de tomada de decis√£o usando a IA, esse problema de "caixa preta" parece ser menos uma falha tecnol√≥gica e mais uma falha fundamental.  Um projeto da DARPA chamado XAI (abrevia√ß√£o de ‚ÄúIA Explic√°vel‚Äù, IA eXplainable) est√° explorando ativamente esse problema, e a interpretabilidade est√° saindo das linhas de frente da pesquisa no campo da MO, mais perto de seu centro.  "A IA est√° em um momento cr√≠tico em que n√≥s, a humanidade, estamos tentando descobrir se essa tecnologia √© adequada para n√≥s", diz Kim.  "Se n√£o resolvermos o problema da interpretabilidade, acho que n√£o conseguiremos seguir em frente com essa tecnologia, e talvez simplesmente a recusemos". <br><br>  Kim e colegas do Google Brain recentemente desenvolveram o sistema Teste com vetores de ativa√ß√£o de conceito (TCAV), que ela descreve como tradutora humana que permite ao usu√°rio fazer uma pergunta √† caixa preta da IA ‚Äã‚Äãsobre quanto um certo conceito de alto n√≠vel estava envolvido na tomada de decis√£o.  Por exemplo, se o sistema MO for treinado para encontrar imagens de zebra, uma pessoa poderia pedir ao TCAV para descrever o quanto o conceito de ‚Äúlistras‚Äù faz no processo de tomada de decis√£o. <br><br>  O TCAV foi testado inicialmente em modelos treinados para reconhecer imagens, mas tamb√©m funciona com modelos projetados para processamento de texto ou certas tarefas de visualiza√ß√£o de dados, por exemplo, gr√°ficos de EEG.  "√â generalizado e simples - pode ser conectado a muitos modelos diferentes", diz Kim. <br><br>  Quanta conversou com Kim sobre o que significa interpretabilidade, quem precisa e por que isso importa. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4c8/f00/6c4/4c8f006c4ccacab3d668b366f5cbecee.jpg"><br><br>  <b>Voc√™ em sua carreira se concentrou na ‚Äúinterpretabilidade‚Äù para o MO.</b>  <b>Mas o que exatamente esse termo significa?</b> <br><br>  A interpretabilidade tem dois ramos.  Uma √© a interpretabilidade para a ci√™ncia: se voc√™ considerar a rede neural como um objeto de estudo, poder√° realizar experimentos cient√≠ficos para entender realmente todos os meandros do modelo, as raz√µes de sua rea√ß√£o e assim por diante. <br><br>  O segundo ramo, no qual concentro principalmente meus esfor√ßos, √© a interpretabilidade para criar uma IA capaz de responder perguntas.  Voc√™ n√£o precisa entender todos os pequenos detalhes do modelo.  Mas nosso objetivo √© entender o suficiente para que essa ferramenta possa ser usada com seguran√ßa. <br><br>  <b>Mas como algu√©m pode acreditar em um sistema, se n√£o entende completamente como ele funciona?</b> <br><br>  Vou te dar uma analogia.  Suponha que no meu quintal haja uma √°rvore que eu queira cortar.  Eu tenho uma serra el√©trica para isso.  N√£o entendo exatamente como funciona uma serra el√©trica.  Mas as instru√ß√µes dizem: "Algo a ser tratado com cuidado para n√£o se cortar".  Tendo instru√ß√µes, √© melhor usar uma serra el√©trica em vez de uma serra manual - a √∫ltima √© mais f√°cil de entender, mas eu precisaria v√™-la por cinco horas. <br><br>  <b>Voc√™ entende o que significa "cortar", mesmo que n√£o saiba tudo sobre o mecanismo que torna isso poss√≠vel.</b> <br><br>  Sim  O objetivo do segundo ramo da interpretabilidade √© o seguinte: podemos entender a ferramenta o suficiente para ser segura de usar?  E podemos criar esse entendimento, confirmando que o conhecimento humano √∫til √© refletido no instrumento. <br><br>  <b>Mas como o ‚Äúreflexo do conhecimento humano‚Äù torna a caixa preta da IA ‚Äã‚Äãmais compreens√≠vel?</b> <br><br>  Aqui est√° outro exemplo.  Se o m√©dico usar o modelo MO para fazer um diagn√≥stico de c√¢ncer, ele precisar√° saber que o modelo n√£o seleciona simplesmente alguma correla√ß√£o aleat√≥ria nos dados que n√£o precisamos.  Uma maneira de verificar isso √© confirmar que o modelo MO faz aproximadamente a mesma coisa que o m√©dico faria.  Ou seja, para mostrar que o conhecimento diagn√≥stico do m√©dico se reflete no modelo. <br><br>  Por exemplo, se um m√©dico procurar uma inst√¢ncia celular adequada para o diagn√≥stico de c√¢ncer, ele procurar√° algo chamado "gl√¢ndula mesclada".  Ele tamb√©m levar√° em conta indicadores como a idade do paciente e se ele passou por quimioterapia no passado.  Esses fatores, ou conceitos, ser√£o levados em considera√ß√£o por um m√©dico que tenta diagnosticar o c√¢ncer.  Se pudermos mostrar que o modelo MO tamb√©m chama a aten√ß√£o para eles, ent√£o o modelo ser√° mais compreens√≠vel, pois refletir√° o conhecimento humano dos m√©dicos. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/8Bi-EhFPSLk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  <b>√â com isso que o TCAV lida - mostra quais conceitos de alto n√≠vel o modelo MO usa para a tomada de decis√£o?</b> <br><br>  Sim  Antes disso, os m√©todos de interpretabilidade explicavam apenas o que a rede neural faz em termos de "recursos de entrada".  O que isso significa?  Se voc√™ tiver uma imagem, cada um de seus pixels ser√° um recurso de entrada.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Yang Lekun</a> (pioneiro da aprendizagem profunda, diretor de pesquisa de IA do Facebook), disse que considera esses modelos super interpret√°veis, j√° que √© poss√≠vel olhar para cada n√≥ da rede neural e ver os valores num√©ricos de cada um dos recursos de entrada.  Para computadores, isso pode ser adequado, mas as pessoas pensam de maneira diferente.  N√£o estou dizendo para voc√™ "Veja os pixels de 100 a 200, os valores RGB s√£o 0,2 e 0,3".  Eu digo: "Esta √© uma imagem de um cachorro muito desgrenhado".  As pessoas se comunicam dessa maneira - atrav√©s de conceitos. <br><br>  <b>Como o TCAV se traduz entre recursos e conceitos de entrada?</b> <br><br>  Vamos voltar ao exemplo de um m√©dico usando o modelo MO, que j√° foi treinado para classificar imagens de amostras de c√©lulas de acordo com o c√¢ncer.  Voc√™, como m√©dico, precisa descobrir a import√¢ncia do conceito de "gl√¢ndulas mescladas" para o modelo fazer previs√µes positivas para o c√¢ncer.  Primeiro, voc√™ coleciona, digamos, 20 imagens que mostram exemplos de gl√¢ndulas mescladas.  Em seguida, voc√™ conecta esses exemplos rotulados ao modelo. <br><br>  Ent√£o, o TCAV dentro de si realiza o chamado  "Verifica√ß√£o de sensibilidade".  Quando adicionamos essas imagens rotuladas das gl√¢ndulas mescladas, quanto aumenta a probabilidade de uma previs√£o positiva de c√¢ncer?  A resposta pode ser estimada por um n√∫mero de 0 a 1. E esses ser√£o seus pontos no TCAV.  Se a probabilidade aumentasse, esse conceito era importante para o modelo.  Caso contr√°rio, esse conceito n√£o √© importante. <br><br>  <b>"Conceito" √© um termo vago.</b>  <b>Existem conceitos que n√£o funcionam com o TCAV?</b> <br><br>  Se voc√™ n√£o conseguir descrever um conceito usando um subconjunto do seu conjunto de dados, ele n√£o funcionar√°.  Se o seu modelo de MO √© treinado em imagens, o conceito deve ser expresso visualmente.  Se, por exemplo, quero expressar visualmente o conceito de amor, ser√° bastante dif√≠cil. <br><br>  Tamb√©m verificamos cuidadosamente o conceito.  Temos um procedimento de verifica√ß√£o estat√≠stica que rejeita o vetor conceitual se tiver um efeito equivalente ao aleat√≥rio no modelo.  Se o seu conceito n√£o passar neste teste, o TCAV dir√°: "N√£o sei, esse conceito n√£o parece algo importante para o modelo". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e7d/2e4/bb5/e7d2e4bb5cb0093890c6938abdb5acdc.jpg"><br><br>  <b>O projeto TCAV √© mais focado na constru√ß√£o da confian√ßa na IA do que na generaliza√ß√£o de seu entendimento?</b> <br><br>  N√£o, - e vou explicar o porqu√™, j√° que essa diferen√ßa √© muito sutil. <br><br>  De muitos estudos no campo da ci√™ncia cognitiva e da psicologia, sabemos que as pessoas s√£o muito confiantes.  Isso significa que √© muito f√°cil enganar uma pessoa, for√ßando-a a acreditar em alguma coisa.  O objetivo da interpretabilidade do MO √© o oposto.  Consiste em informar uma pessoa que n√£o √© seguro usar um sistema espec√≠fico.  O objetivo √© descobrir a verdade.  Portanto, "confian√ßa" n√£o √© a palavra certa. <br><br>  <b>Ent√£o, o objetivo da interpretabilidade √© descobrir poss√≠veis falhas no racioc√≠nio da IA?</b> <br><br>  Sim exatamente. <br><br>  <b>Como ela pode revelar as falhas?</b> <br><br>  O TCAV pode ser usado para fazer ao modelo uma pergunta sobre conceitos que n√£o est√£o relacionados ao campo de pesquisa.  Voltando ao exemplo de m√©dicos usando IA para prever a probabilidade de c√¢ncer.  Os m√©dicos podem pensar subitamente: ‚ÄúAparentemente, a m√°quina fornece previs√µes positivas para a presen√ßa de c√¢ncer em muitas imagens nas quais a cor √© levemente alterada para azul.  Acreditamos que esse fator n√£o deve ser levado em considera√ß√£o. ‚Äù  E se eles obtiverem uma pontua√ß√£o alta no TCAV em azul, significa que encontraram um problema em seu modelo MO. <br><br>  <b>O TCAV foi projetado para ser pendurado em sistemas de IA existentes que n√£o podem ser interpretados.</b>  <b>Por que n√£o criar imediatamente sistemas interpretados em vez de caixas pretas?</b> <br><br>  H√° um ramo do estudo da interpretabilidade, focado na cria√ß√£o de modelos inicialmente interpretados que refletem o racioc√≠nio de uma pessoa.  Mas acho que sim: agora j√° estamos cheios de modelos de IA prontos para uso que s√£o usados ‚Äã‚Äãpara resolver problemas importantes e, ao cri√°-los, n√£o pensamos inicialmente em interpretabilidade.  T√£o f√°cil de comer.  Muitos deles trabalham no Google!  Voc√™ pode dizer: "A interpretabilidade √© t√£o √∫til que vamos criar outro modelo para voc√™ substituir o que voc√™ possui".  Bem, boa sorte. <br><br>  E ent√£o o que fazer?  Ainda precisamos passar por esse momento crucial para decidir se essa tecnologia √© √∫til para n√≥s ou n√£o.  Portanto, estou trabalhando nos m√©todos de interpretabilidade p√≥s-treinamento.  Se algu√©m lhe deu um modelo e voc√™ n√£o pode alter√°-lo, como voc√™ aborda a tarefa de gerar explica√ß√µes sobre seu comportamento para poder us√°-lo com seguran√ßa?  √â exatamente isso que o TCAV faz. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05d/9ba/522/05d9ba52265cd534871c8f62f4ce05f7.jpg"><br><br>  <b>O TCAV permite que as pessoas perguntem √† IA sobre a import√¢ncia de certos conceitos.</b>  <b>Mas e se n√£o soubermos o que perguntar - e se quisermos que a IA explique?</b> <br><br>  No momento, estamos trabalhando em um projeto que pode encontrar automaticamente conceitos para voc√™.  Chamamos isso de DTCAV - o TCAV de abertura.  Mas acho que o principal problema da interpretabilidade √© que as pessoas participam desse processo e que permitimos que pessoas e m√°quinas se comuniquem. <br><br>  Em muitos casos, ao trabalhar com aplicativos dos quais depende muito, os especialistas em um campo espec√≠fico j√° possuem uma lista de conceitos que s√£o importantes para eles.  N√≥s do Google Brain somos constantemente confrontados com isso nas aplica√ß√µes m√©dicas da IA.  Eles n√£o precisam de um conjunto de conceitos - eles querem fornecer modelos de conceito que sejam interessantes para eles.  Estamos trabalhando com um m√©dico que trata de retinopatia diab√©tica, doen√ßa ocular e, quando contamos a ela sobre o TCAV, ela ficou muito feliz porque j√° tinha um monte de hip√≥teses sobre o que o modelo pode fazer e agora pode verificar todas as perguntas que surgiram.  Essa √© uma vantagem enorme e uma maneira muito centrada no usu√°rio de implementar o aprendizado de m√°quina colaborativo. <br><br>  <b>Voc√™ acha que, sem interpretabilidade, a humanidade pode simplesmente abandonar a tecnologia de IA.</b>  <b>Considerando as oportunidades que tem, voc√™ realmente avalia essa op√ß√£o como real?</b> <br><br>  Sim  Foi exatamente o que aconteceu com os sistemas especialistas.  Na d√©cada de 1980, determinamos que eles s√£o mais baratos do que as pessoas na solu√ß√£o de alguns problemas.  E quem usa sistemas especialistas hoje?  Ninguem  E depois disso chegou o inverno da IA. <br><br>  At√© agora, isso n√£o parece prov√°vel, tanto hype e dinheiro est√£o sendo investidos em IA.  Mas, a longo prazo, acho que a humanidade pode decidir - talvez por medo, talvez por falta de evid√™ncias - que essa tecnologia n√£o nos conv√©m.  √â poss√≠vel </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt440426/">https://habr.com/ru/post/pt440426/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt440414/index.html">Sobre linter, qualidade de c√≥digo, qualidade em geral e gerenciamento de qualidade</a></li>
<li><a href="../pt440416/index.html">Col√¥nia. Cap√≠tulo 25: Noite Fora</a></li>
<li><a href="../pt440420/index.html">Bem-vindo ao Devleads Meetup 21 de fevereiro</a></li>
<li><a href="../pt440422/index.html">Quando voc√™ √© respons√°vel pela qualidade do presente. A hist√≥ria de um experimento blockchain</a></li>
<li><a href="../pt440424/index.html">Algoritmo de Pensamento e Consci√™ncia</a></li>
<li><a href="../pt440428/index.html">SMAA: Suaviza√ß√£o morfol√≥gica aprimorada de subpixel</a></li>
<li><a href="../pt440430/index.html">De onde veio o slogan "N√£o seja mau"</a></li>
<li><a href="../pt440432/index.html">SciFi de sexta-feira sobre as profiss√µes do futuro: ‚ÄúGarotas de Verdade‚Äù</a></li>
<li><a href="../pt440434/index.html">Ind√∫stria automobil√≠stica russa: o caminho para tecnologias aditivas</a></li>
<li><a href="../pt440436/index.html">Tarefas pr√°ticas Java - para cursos e outras atividades</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
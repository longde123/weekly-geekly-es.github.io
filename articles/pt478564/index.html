<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÜé üò∂ ‚úã Como n√≥s do TsIAN domamos terabytes de logs üï• üë©üèΩ‚Äçü§ù‚Äçüë®üèº üëò</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal, meu nome √© Alexander, trabalho como engenheiro no CIAN e estou envolvido na administra√ß√£o de sistemas e automa√ß√£o de processos de infraes...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como n√≥s do TsIAN domamos terabytes de logs</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/cian/blog/478564/"><img src="https://habrastorage.org/getpro/habr/post_images/f5a/f37/994/f5af37994ecad978b8cd3edd3dc7ae0a.png"><br><br>  Ol√° pessoal, meu nome √© Alexander, trabalho como engenheiro no CIAN e estou envolvido na administra√ß√£o de sistemas e automa√ß√£o de processos de infraestrutura.  Nos coment√°rios de um dos artigos anteriores, fomos solicitados a informar onde obtemos 4 TB de logs por dia e o que fazemos com eles.  Sim, temos muitos logs e um cluster de infraestrutura separado foi criado para process√°-los, o que nos permite resolver rapidamente problemas.  Neste artigo, falarei sobre como a adaptamos ao longo do ano para trabalhar com um fluxo crescente de dados. <br><a name="habracut"></a><br><h3>  Por onde come√ßamos </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/6d2/1eb/3da/6d21eb3da4aa0189ae44b9ca951b15a8.jpg"><br><br>  Nos √∫ltimos anos, a carga no cian.ru cresceu muito rapidamente e, no terceiro trimestre de 2018, o tr√°fego de recursos atingiu 11,2 milh√µes de usu√°rios √∫nicos por m√™s.  Naquele momento, em momentos cr√≠ticos, perdemos at√© 40% dos logs, por causa dos quais n√£o conseguimos lidar rapidamente com os incidentes e gastamos muito tempo e esfor√ßo resolvendo-os.  Muitas vezes, n√£o conseguimos encontrar a causa do problema, e ele voltou ap√≥s algum tempo.  Foi o inferno com o qual voc√™ teve que fazer alguma coisa. <br><br>  Naquele momento, usamos um cluster de 10 n√≥s de dados com o ElasticSearch vers√£o 5.5.2 com configura√ß√µes t√≠picas de √≠ndice para armazenar logs.  Foi introduzida h√° mais de um ano como uma solu√ß√£o popular e acess√≠vel: ent√£o o fluxo de logs n√£o era t√£o grande que n√£o fazia sentido criar configura√ß√µes n√£o-padr√£o. <br><br>  O armazenamento de logs em portas diferentes forneceu o processamento de logs de entrada em cinco coordenadores do ElasticSearch.  Um √≠ndice, independentemente do tamanho, consistia em cinco fragmentos.  Como rota√ß√£o hor√°ria e di√°ria foi organizada, como resultado, cerca de 100 novos fragmentos apareceram no cluster a cada hora.  Embora n√£o houvesse muitos logs, o cluster gerenciava e ningu√©m chamava a aten√ß√£o para suas configura√ß√µes. <br><br><h3>  Problemas de crescimento </h3><br>  O volume dos logs gerados cresceu muito rapidamente, pois dois processos se sobrepuseram.  Por um lado, havia cada vez mais usu√°rios do servi√ßo.  Por outro lado, come√ßamos a mudar ativamente para a arquitetura de microsservi√ßos, vendo nossos antigos mon√≥litos em C # e Python.  V√°rias dezenas de novos microsservi√ßos que substitu√≠ram partes do mon√≥lito geraram significativamente mais logs para o cluster de infraestrutura. <br><br>  Foi o dimensionamento que nos levou ao fato de que o cluster se tornou praticamente incontrol√°vel.  Quando os logs come√ßaram a chegar a uma velocidade de 20 mil mensagens por segundo, a rota√ß√£o in√∫til freq√ºente aumentou o n√∫mero de shards para 6 mil, e um n√≥ foi respons√°vel por mais de 600 shards. <br><br>  Isso causou problemas com a aloca√ß√£o de RAM e, quando um n√≥ caiu, a movimenta√ß√£o simult√¢nea de todos os shards come√ßou, multiplicando o tr√°fego e carregando os n√≥s restantes, o que tornou quase imposs√≠vel gravar dados no cluster.  E durante esse per√≠odo ficamos sem registros.  E com um problema no servidor, perdemos 1/10 do cluster em princ√≠pio.  Um grande n√∫mero de pequenos √≠ndices adicionou complexidade. <br><br>  Sem registros, n√£o entend√≠amos as causas do incidente e, mais cedo ou mais tarde, pod√≠amos pisar no mesmo rake novamente, mas isso era inaceit√°vel na ideologia de nossa equipe, pois todos os mecanismos de trabalho que t√≠nhamos foram aprimorados exatamente do contr√°rio - nunca repetimos os mesmos problemas.  Para fazer isso, precis√°vamos de um volume completo de logs e sua entrega quase em tempo real, pois uma equipe de engenheiros de servi√ßo monitorava alertas n√£o apenas das m√©tricas, mas tamb√©m dos logs.  Para entender a extens√£o do problema - naquele momento, o volume total de logs era de cerca de 2 TB por dia. <br><br>  Estabelecemos uma meta - eliminar completamente a perda de logs e reduzir o tempo de entrega ao cluster ELK para um m√°ximo de 15 minutos durante casos de for√ßa maior (contamos com esse n√∫mero no futuro como um KPI interno). <br><br><h3>  Novo mecanismo de rota√ß√£o e n√≥s quentes e quentes </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/363/96f/05e/36396f05e01c97e805388ff27d134e2a.jpg"><br><br>  Iniciamos a transforma√ß√£o do cluster atualizando a vers√£o do ElasticSearch de 5.5.2 para 6.4.3.  Mais uma vez, um cluster da vers√£o 5 chegou at√© n√≥s e decidimos reembols√°-lo e atualizar completamente - ainda n√£o h√° logs.  Ent√£o fizemos essa transi√ß√£o em apenas algumas horas. <br><br>  A transforma√ß√£o mais ambiciosa nesse est√°gio foi a introdu√ß√£o de tr√™s n√≥s com o coordenador como um buffer intermedi√°rio, Apache Kafka.  O intermedi√°rio de mensagens nos salvou de perder logs durante problemas com o ElasticSearch.  Ao mesmo tempo, adicionamos 2 n√≥s ao cluster e mudamos para uma arquitetura hot-warm com tr√™s n√≥s "hot" dispostos em racks diferentes no data center.  N√≥s redirecionamos logs para eles que n√£o devem ser perdidos em nenhum caso - nginx, bem como logs de erro do aplicativo.  Logs secund√°rios - depura√ß√£o, aviso etc. foram para outros n√≥s e, ap√≥s 24 horas, os logs "importantes" foram movidos dos n√≥s "quentes". <br><br>  Para n√£o aumentar o n√∫mero de pequenos √≠ndices, passamos da rota√ß√£o do tempo para o mecanismo de sobreposi√ß√£o.  Havia muitas informa√ß√µes nos f√≥runs de que a rota√ß√£o por tamanho do √≠ndice n√£o √© confi√°vel, por isso decidimos usar a rota√ß√£o pelo n√∫mero de documentos no √≠ndice.  Analisamos cada √≠ndice e registramos o n√∫mero de documentos ap√≥s os quais a rota√ß√£o deve funcionar.  Assim, atingimos o tamanho ideal do shard - n√£o mais que 50 GB. <br><br><h3>  Otimiza√ß√£o de Cluster </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/cf3/c46/45e/cf3c4645e6b74cf5491f9878dacfa185.jpg"><br><br>  No entanto, n√£o nos livramos completamente dos problemas.  Infelizmente, pequenos √≠ndices pareciam iguais: eles n√£o atingiram o volume definido, n√£o giraram e foram exclu√≠dos pela limpeza global de √≠ndices com mais de tr√™s dias, desde que removemos a rota√ß√£o por data.  Isso levou √† perda de dados devido ao fato de o √≠ndice do cluster desaparecer completamente e uma tentativa de gravar em um √≠ndice inexistente quebrou a l√≥gica do curador que usamos para controle.  O alias para grava√ß√£o foi transformado em um √≠ndice e quebrou a l√≥gica da rolagem, causando um crescimento descontrolado de alguns √≠ndices para 600 GB. <br><br>  Por exemplo, para configurar a rota√ß√£o: <br><br><pre><code class="plaintext hljs">urator-elk-rollover.yaml --- actions:   1:     action: rollover     options:       name: "nginx_write"       conditions:         max_docs: 100000000   2:     action: rollover     options:       name: "python_error_write"       conditions:         max_docs: 10000000</code> </pre> <br><br>  Na aus√™ncia de alias de rollover, ocorreu um erro: <br><br><pre> <code class="plaintext hljs">ERROR   alias "nginx_write" not found. ERROR   Failed to complete action: rollover. &lt;type 'exceptions.ValueError'&gt;: Unable to perform index rollover with alias "nginx_write".</code> </pre><br><br>  Deixamos a solu√ß√£o para esse problema para a pr√≥xima itera√ß√£o e levantamos outra quest√£o: alternamos para puxar a l√≥gica do Logstash, que lida com os logs recebidos (removendo informa√ß√µes desnecess√°rias e enriquecendo).  N√≥s o colocamos na janela de encaixe, que √© lan√ßada atrav√©s do docker-compondo, e no mesmo lugar, colocamos logstash-exportador, que fornece m√©tricas ao Prometheus para monitoramento operacional do fluxo de logs.  Portanto, tivemos a oportunidade de alterar suavemente o n√∫mero de inst√¢ncias de logstash respons√°veis ‚Äã‚Äãpelo processamento de cada tipo de log. <br><br>  Enquanto aprimor√°vamos o cluster, o tr√°fego do cian.ru cresceu para 12,8 milh√µes de usu√°rios √∫nicos por m√™s.  Como resultado, nossas convers√µes n√£o acompanharam um pouco as mudan√ßas na produ√ß√£o, e fomos confrontados com o fato de que os n√≥s "quentes" n√£o podiam lidar com a carga e atrasaram toda a entrega de logs.  Recebemos os dados "quentes" sem falhas, mas tivemos que intervir na entrega do restante e fazer a substitui√ß√£o manual para distribuir uniformemente os √≠ndices. <br><br>  Ao mesmo tempo, o dimensionamento e a altera√ß√£o das configura√ß√µes das inst√¢ncias de logstash no cluster foram complicados pelo fato de ser uma composi√ß√£o de docker local e todas as a√ß√µes foram executadas manualmente (para adicionar novos fins, voc√™ teve que passar por todos os servidores com as m√£os e fazer docker-compose em todos os lugares). <br><br><h3>  Redistribui√ß√£o de log </h3><br>  Em setembro deste ano, continuamos vendo o mon√≥lito, a carga no cluster aumentou e o fluxo de logs estava se aproximando de 30 mil mensagens por segundo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/28c/ff7/c76/28cff7c7661c901102a69fe49beeccd0.png"><br><br>  Iniciamos a pr√≥xima itera√ß√£o com a atualiza√ß√£o do ferro.  Trocamos de cinco coordenadores para tr√™s, substitu√≠mos os n√≥s de dados e vencemos em termos de dinheiro e volume de armazenamento.  Para n√≥s, usamos duas configura√ß√µes: <br><br><ul><li>  Para n√≥s quentes: E3-1270 v6 / 960Gb SSD / 32 Gb x 3 x 2 (3 para Hot1 e 3 para Hot2). <br></li><li>  Para n√≥s quentes: E3-1230 v6 / 4Tb SSD / 32 Gb x 4. <br></li></ul><br>  Nessa itera√ß√£o, removemos o √≠ndice com os logs de acesso ao microsservi√ßo, que ocupam tanto espa√ßo quanto os logs nginx do front-end, no segundo grupo de tr√™s n√≥s ativos.  Agora, armazenamos dados em n√≥s quentes por 20 horas e depois os transferimos para quente para outros logs. <br><br>  Resolvemos o problema do desaparecimento de pequenos √≠ndices reconfigurando sua rota√ß√£o.  Os √≠ndices agora s√£o alternados de qualquer maneira a cada 23 horas, mesmo que haja poucos dados.  Isso aumentou um pouco o n√∫mero de shards (eles se tornaram cerca de 800), mas do ponto de vista do desempenho do cluster isso √© toler√°vel. <br><br>  Como resultado, seis n√≥s "quentes" e apenas quatro n√≥s "quentes" apareceram no cluster.  Isso causa um pequeno atraso nas solicita√ß√µes por longos intervalos de tempo, mas aumentar o n√∫mero de n√≥s no futuro resolver√° esse problema. <br><br>  Nesta itera√ß√£o, o problema da falta de escala semiautom√°tica tamb√©m foi corrigido.  Para isso, implantamos um cluster Nomad de infraestrutura - semelhante ao que j√° implantamos para produ√ß√£o.  Embora o n√∫mero de Logstash n√£o seja alterado automaticamente, dependendo da carga, mas chegaremos a isso. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c5/331/493/5c533149373a09c73e329e3bb43e0d81.png"><br><br><h3>  Planos futuros </h3><br>  A configura√ß√£o implementada √© bem dimensionada e agora armazenamos 13,3 TB de dados - todos os logs em 4 dias, o que √© necess√°rio para a an√°lise emergencial de alertas.  Convertemos parte dos logs em m√©tricas, adicionadas ao Graphite.  Para facilitar o trabalho dos engenheiros, temos m√©tricas para o cluster de infraestrutura e scripts para corrigir problemas t√≠picos semiautom√°ticos.  Depois de aumentar o n√∫mero de n√≥s de dados, planejado para o pr√≥ximo ano, mudaremos para o armazenamento de dados de 4 para 7 dias.  Isso ser√° suficiente para o trabalho operacional, pois sempre tentamos investigar incidentes o mais r√°pido poss√≠vel e os dados de telemetria est√£o dispon√≠veis para investiga√ß√µes de longo prazo. <br><br>  Em outubro de 2019, o tr√°fego do cian.ru aumentou para 15,3 milh√µes de usu√°rios √∫nicos por m√™s.  Este foi um teste s√©rio da solu√ß√£o arquitetural para a entrega de logs. <br><br>  Agora, estamos nos preparando para atualizar o ElasticSearch para a vers√£o 7. No entanto, para isso, precisaremos atualizar o mapeamento de muitos √≠ndices no ElasticSearch, porque eles passaram da vers√£o 5.5 e foram declarados descontinuados na vers√£o 6 (eles simplesmente n√£o existem na vers√£o 7).  E isso significa que, no processo de atualiza√ß√£o, certamente haver√° alguma for√ßa maior que nos deixar√° sem registros por enquanto.  Das 7 vers√µes, estamos ansiosos pelo Kibana com uma interface aprimorada e novos filtros. <br><br>  Atingimos o objetivo principal: paramos de perder logs e reduzimos o tempo de inatividade do cluster de infraestrutura de 2-3 quedas por semana para algumas horas de servi√ßo por m√™s.  Todo esse trabalho de produ√ß√£o √© quase invis√≠vel.  No entanto, agora podemos determinar com precis√£o o que est√° acontecendo com nosso servi√ßo, podemos faz√™-lo rapidamente em modo silencioso e n√£o nos preocupar que os logs sejam perdidos.  Em geral, estamos satisfeitos, felizes e nos preparando para novas explora√ß√µes, sobre as quais falaremos mais adiante. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt478564/">https://habr.com/ru/post/pt478564/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt478544/index.html">Vue Storefront: Importar diret√≥rio do Magento 2</a></li>
<li><a href="../pt478546/index.html">Websockets Alguma experi√™ncia em desenvolvimento e opera√ß√£o. N√≥s modificamos o cliente</a></li>
<li><a href="../pt478550/index.html">Como gerenciar um rel√≥gio? An√°lise da pista front-end do segundo campeonato de programa√ß√£o</a></li>
<li><a href="../pt478552/index.html">Segundo applet, fechando-o e bot√µes transparentes no Processamento 3</a></li>
<li><a href="../pt478554/index.html">Webinar "SRE - hype ou o futuro?" 12 de dezembro √†s 11:00</a></li>
<li><a href="../pt478566/index.html">iOS Rede quando o aplicativo n√£o est√° sendo executado</a></li>
<li><a href="../pt478572/index.html">Bot em redes neurais: como um assistente virtual funciona e aprende</a></li>
<li><a href="../pt478574/index.html">A verdade sobre os freios ferrovi√°rios: Parte 4 - Freios de passageiros</a></li>
<li><a href="../pt478580/index.html">Como o chip gr√°fico da Super Nintendo funcionou: Guia Super PPU</a></li>
<li><a href="../pt478582/index.html">Relat√≥rio Global VPN sobre dispositivos m√≥veis em 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
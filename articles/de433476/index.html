<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•ú üßïüèø üöä 50 Selleriet√∂ne ‚è∫Ô∏è üë®‚Äçüë®‚Äçüëß üÄÑÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sie sind hier, wenn Sie wissen m√∂chten, wie Sie ein Framework z√§hmen k√∂nnen, das in den Kreisen der Python-Entwickler namens Celery weithin bekannt is...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>50 Selleriet√∂ne</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/433476/">  Sie sind hier, wenn Sie wissen m√∂chten, wie Sie ein Framework z√§hmen k√∂nnen, das in den Kreisen der Python-Entwickler namens Celery weithin bekannt ist.  Und selbst wenn Sellerie grundlegende Befehle in Ihrem Projekt sicher ausf√ºhrt, kann die Fintech-Erfahrung Ihnen unbekannte Seiten er√∂ffnen.  Weil Fintech immer Big Data ist und damit Hintergrundaufgaben, Stapelverarbeitung, asynchrone API usw. erforderlich sind. <br><img src="https://habrastorage.org/webt/oc/8a/rn/oc8arnnknqs37365anrx9mvuuru.jpeg"><br><br>  Das Sch√∂ne an Oleg Churkins Geschichte √ºber Sellerie in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Moskau Python Conf ++</a> ist, dass Sie n√ºtzliche Ideen ausleihen k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">,</a> zus√§tzlich zu detaillierten Anweisungen zum Konfigurieren und √úberwachen von Sellerie unter Last. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SxgzHz-zE-c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>√úber den Sprecher und das Projekt:</strong> Oleg <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Churkin</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Bahusss</a> ) entwickelt seit 8 Jahren Python-Projekte unterschiedlicher Komplexit√§t und hat in vielen bekannten Unternehmen gearbeitet: Yandex, Rambler, RBC, Kaspersky Lab.  Jetzt Techlide im Fintech-StatusPoney-Startup. <br><a name="habracut"></a><br>  Das Projekt arbeitet mit einer gro√üen Menge an Finanzdaten von Benutzern (1,5 Terabyte): Konten, Transaktionen, H√§ndler usw.  Es werden t√§glich bis zu eine Million Aufgaben ausgef√ºhrt.  Vielleicht scheint diese Zahl f√ºr jemanden nicht wirklich gro√ü zu sein, aber f√ºr ein kleines Startup mit bescheidenen Kapazit√§ten ist dies eine erhebliche Datenmenge, und die Entwickler mussten sich auf dem Weg zu einem stabilen Prozess verschiedenen Problemen stellen. <br><br>  Oleg sprach √ºber die wichtigsten Punkte der Arbeit: <br><br><ul><li>  Welche Aufgaben wollten Sie mit dem Framework l√∂sen, warum haben Sie sich f√ºr Sellerie entschieden? </li><li>  Wie Sellerie half. </li><li>  So konfigurieren Sie Sellerie unter Last. </li><li>  So √ºberwachen Sie den Selleriestatus. </li></ul><br>  Und er teilte einige Design-Dienstprogramme, die die fehlende Funktionalit√§t in Sellerie implementieren.  Wie sich herausstellte, im Jahr 2018, und das kann sein.  Das Folgende ist eine Textversion des Berichts aus der ersten Person. <br><br><h2>  Problem <br></h2><br>  Es war erforderlich, um die folgenden Aufgaben zu l√∂sen: <br><br><ul><li>  F√ºhren Sie <strong>separate Hintergrundaufgaben aus</strong> . </li><li>  F√ºhren Sie eine <strong>Stapelverarbeitung von Aufgaben durch</strong> , dh f√ºhren Sie viele Aufgaben gleichzeitig aus. </li><li>  Betten Sie den Prozess <strong>Extrahieren, Transformieren, Laden ein</strong> . </li><li>  Implementieren Sie die <strong>asynchrone API</strong> .  Es stellt sich heraus, dass die asynchrone API nicht nur mithilfe asynchroner Frameworks implementiert werden kann, sondern auch vollst√§ndig synchron. </li><li> F√ºhren Sie <strong>regelm√§√üige Aufgaben aus</strong> .  Kein einziges Projekt kann ohne regelm√§√üige Aufgaben auskommen, f√ºr einige kann auf Cron verzichtet werden, aber es gibt auch bequemere Werkzeuge. </li><li>  Erstellen einer <strong>Triggerarchitektur</strong> : Um einen Trigger auszul√∂sen, f√ºhren Sie eine Aufgabe aus, die die Daten aktualisiert.  Dies geschieht, um den Mangel an Laufzeitleistung durch Vorberechnung von Daten im Hintergrund auszugleichen. </li></ul><br>  <strong>Hintergrundaufgaben</strong> umfassen alle Arten von Benachrichtigungen: E-Mail, Push, Desktop - all dies wird in Hintergrundaufgaben durch einen Ausl√∂ser gesendet.  Ebenso wird eine regelm√§√üige Aktualisierung der Finanzdaten gestartet. <br><br>  Im Hintergrund werden verschiedene spezifische √úberpr√ºfungen durchgef√ºhrt, beispielsweise die √úberpr√ºfung eines Benutzers auf Betrug.  Bei Finanz-Startups wird <strong>viel Aufmerksamkeit und Aufmerksamkeit speziell der Datensicherheit gewidmet</strong> , da wir Benutzern erm√∂glichen, ihre Bankkonten zu unserem System hinzuzuf√ºgen, und wir alle ihre Transaktionen sehen k√∂nnen.  Betr√ºger k√∂nnen versuchen, unseren Service f√ºr etwas Schlechtes zu nutzen, um beispielsweise den Kontostand eines gestohlenen Kontos zu √ºberpr√ºfen. <br><br>  Die letzte Kategorie von Hintergrundaufgaben sind <strong>Wartungsaufgaben</strong> : etwas optimieren, sehen, reparieren, √ºberwachen usw. <br><br>  F√ºr Massenbenachrichtigungen wird die <strong>Stapelverarbeitung verwendet</strong> .  Eine gro√üe Menge von Daten, die wir von unseren Benutzern erhalten, muss auf eine bestimmte Weise berechnet und verarbeitet werden, einschlie√ülich  im Batch-Modus. <br><br>  Das gleiche Konzept beinhaltet das klassische <strong>Extrahieren, Transformieren, Laden</strong> : <br><br><ul><li>  Laden von Daten aus externen Quellen (externe API); </li><li>  unverarbeitet halten; </li><li>  F√ºhren Sie Aufgaben aus, die Daten lesen und verarbeiten. </li><li>  Wir speichern die verarbeiteten Daten an der richtigen Stelle im richtigen Format, damit sie sp√§ter beispielsweise bequem in der Benutzeroberfl√§che verwendet werden k√∂nnen. </li></ul><br>  Es ist kein Geheimnis, dass die asynchrone API mit einer einfachen Abfrageanforderung ausgef√ºhrt werden kann: Das Frontend initiiert den Prozess im Backend, das Backend startet eine Aufgabe, die sich regelm√§√üig selbst startet, die Ergebnisse "vergie√üt" und den Status in der Datenbank aktualisiert.  Das Frontend zeigt dem Benutzer, dass sich dieser interaktive Status √§ndert.  Dies erm√∂glicht Ihnen: <br><br><ul><li>  Abrufaufgaben von anderen Aufgaben ausf√ºhren; </li><li>  F√ºhren Sie je nach Bedingungen unterschiedliche Aufgaben aus. </li></ul><br>  In unserem Dienst reicht dies vorerst aus, aber in Zukunft m√ºssen wir wahrscheinlich etwas anderes umschreiben. <br><br><h2>  Werkzeuganforderungen <br></h2><br>  Um diese Aufgaben zu implementieren, hatten wir die folgenden Anforderungen an Werkzeuge: <br><br><ul><li>  Funktionalit√§t, die notwendig ist, um unsere Ambitionen zu verwirklichen. </li><li>  <strong>Skalierbarkeit</strong> ohne Kr√ºcken. </li><li>  <strong>√úberwachung des</strong> Systems, um zu verstehen, wie es funktioniert.  Wir verwenden die Fehlerberichterstattung, damit die Integration mit Sentry nicht fehl am Platz ist, auch nicht mit Django. </li><li>  <strong>Leistung</strong> , weil wir viele Aufgaben haben. </li><li>  Reife, Zuverl√§ssigkeit und aktive Entwicklung sind offensichtliche Dinge.  Wir suchten nach einem Tool, das unterst√ºtzt und entwickelt wird. </li><li>  Angemessenheit der Dokumentation - <strong>keine Dokumentation irgendwo</strong> . </li></ul><br><h2>  Welches Tool soll ich w√§hlen? <br></h2><br>  Welche Optionen gibt es 2018 auf dem Markt, um diese Probleme zu l√∂sen? <br><br>  Es war einmal eine Zeit f√ºr weniger ehrgeizige Aufgaben, als ich eine handliche <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bibliothek</a> schrieb, die noch in einigen Projekten verwendet wird.  Es ist einfach zu bedienen und f√ºhrt Aufgaben im Hintergrund aus.  Gleichzeitig werden jedoch keine Broker ben√∂tigt (weder Sellerie noch andere), <strong>sondern</strong> nur der <strong>uwsgi-</strong> Anwendungsserver, der √ºber einen Spooler verf√ºgt, beginnt als separater Worker.  Dies ist eine sehr einfache L√∂sung - alle Aufgaben werden bedingt in Dateien gespeichert.  F√ºr einfache Projekte ist das genug, aber f√ºr unsere war es nicht genug. <br><br>  Irgendwie haben wir √ºberlegt: <br><br><ul><li>  Sellerie (10K Sterne auf GitHub); </li><li>  RQ (5K Sterne auf GitHub); </li><li>  Huey (2K Sterne auf GitHub); </li><li>  Dramatiq (1K Sterne auf GitHub); </li><li>  Tasktiger (0,5K Sterne auf GitHub); </li><li>  Luftstrom?  Luigi </li></ul><br><h2>  Vielversprechender Kandidat 2018 <br></h2><br>  Jetzt m√∂chte ich Ihre Aufmerksamkeit auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dramatiq</a> lenken.  Dies ist eine Bibliothek des erfahrenen Selleries, der alle Nachteile von Sellerie kannte und beschloss, alles neu zu schreiben, nur sehr sch√∂n.  Vorteile von Dramatiq: <br><br><ul><li>  Eine Reihe aller notwendigen Funktionen. </li><li>  Steigerung der Produktivit√§t. </li><li>  Unterst√ºtzung f√ºr Wachposten und Metriken f√ºr Prometheus sofort </li><li>  Eine kleine und klar geschriebene Codebasis, Code-Autoreload. </li></ul><br>  Vor einiger Zeit hatte Dramatiq Probleme mit Lizenzen: Zuerst gab es AGPL, dann wurde es durch LGPL ersetzt.  Aber jetzt k√∂nnen Sie es versuchen. <br><br>  Aber im Jahr 2016 gab es neben Sellerie nichts Besonderes zu nehmen.  Wir mochten seine reichhaltige Funktionalit√§t und dann passte es ideal zu unseren Aufgaben, denn selbst dann war es ausgereift und funktional: <br><br><ul><li>  hatte regelm√§√üige Aufgaben aus der Box; </li><li>  unterst√ºtzte mehrere Makler; </li><li>  Integriert mit Django und Sentry. </li></ul><br><h2>  Projektfunktionen <br></h2><br>  Ich werde Ihnen von unserem Kontext erz√§hlen, damit die weitere Geschichte klarer wird. <br><br>  Wir verwenden <strong>Redis als Nachrichtenbroker</strong> .  Ich habe viele Geschichten und Ger√ºchte geh√∂rt, dass Redis Nachrichten verliert, dass es nicht als Nachrichtenvermittler geeignet ist.  Aus Produktionsgr√ºnden wird dies nicht best√§tigt, aber wie sich herausstellt, arbeitet Redis jetzt effizienter als RabbitMQ (zumindest bei Celery liegt das Problem anscheinend im Integrationscode mit Brokern).  In Version 4 wurde der Redis-Broker behoben, er hat beim Neustart wirklich aufgeh√∂rt, Aufgaben zu verlieren, und funktioniert recht stabil.  2016 wollte Celery Redis aufgeben und sich auf die Integration mit RabbitMQ konzentrieren, aber dies geschah gl√ºcklicherweise nicht. <br><br>  Wenn wir bei Problemen mit Redis ernsthafte Hochverf√ºgbarkeit ben√∂tigen, wechseln wir zu Amazon SQS oder Amazon MQ, da wir die Leistung von Amazon nutzen. <br><br>  Wir <strong>verwenden das Ergebnis-Backend nicht zum Speichern der Ergebnisse</strong> , da wir es vorziehen, die Ergebnisse selbst dort zu speichern, wo wir m√∂chten, und sie so zu √ºberpr√ºfen, wie wir es m√∂chten.  Wir wollen nicht, dass Sellerie dies f√ºr uns tut. <br><br>  Wir verwenden einen <strong>Pefork-Pool</strong> , <strong>dh</strong> Prozessarbeiter, die separate Prozessgabeln f√ºr zus√§tzliche Parallelit√§t erstellen. <br><br><h2>  Arbeitseinheit <br></h2><br>  Wir werden die Grundelemente diskutieren, um diejenigen auf den neuesten Stand zu bringen, die Sellerie nicht probiert haben, sondern nur werden.  <strong>Arbeitseinheit f√ºr Sellerie ist eine Herausforderung</strong> .  Ich werde ein Beispiel f√ºr eine einfache Aufgabe geben, die eine E-Mail sendet. <br><br>  Einfache Funktion und Dekorateur: <br><br><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@current_app.task def send_email(email: str): print(f'Sending email to email={email}')</span></span></code> </pre> <br>  Das Starten der Aufgabe ist einfach: Entweder rufen wir die Funktion auf und die Aufgabe wird zur Laufzeit (send_email (email = "python@example.com")) oder im Worker ausgef√ºhrt, dh die Auswirkung der Aufgabe im Hintergrund: <br><br><pre> <code class="python hljs">send_email.delay(email=<span class="hljs-string"><span class="hljs-string">"python@example.com"</span></span>) send_email.apply_async( kwargs={email: <span class="hljs-string"><span class="hljs-string">"python@example.com"</span></span>} )</code> </pre><br>  F√ºr zwei Jahre Arbeit mit Sellerie unter hoher Belastung haben wir uns die Regeln f√ºr gute Form ausgedacht.  Es gab viele Rechen, wir haben gelernt, wie man um sie herumkommt, und ich werde erz√§hlen, wie. <br><br><h4>  Code-Design <br></h4><br>  Die Aufgabe kann unterschiedliche Logik enthalten.  Im Allgemeinen hilft Ihnen Sellerie dabei, Aufgaben in Dateien oder Paketen zu speichern oder von irgendwoher zu importieren.  Manchmal erhalten Sie einen Stapel Gesch√§ftslogik in einem Modul.  Unserer Meinung nach besteht der richtige Ansatz unter dem Gesichtspunkt der Modularit√§t der Anwendung darin, ein <strong>Minimum an Logik in der Aufgabe zu halten</strong> .  Wir verwenden R√§tsel nur als "Ausl√∂ser" des Codes.  Das hei√üt, die Aufgabe enth√§lt keine Logik an sich, sondern l√∂st den Start von Code im Hintergrund aus. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@celery_app.task(queue='...') def run_regular_update(provider_account_id, *args, **kwargs): """...""" flow = flows.RegularSyncProviderAccountFlow(provider_account_id) return flow.run(*args, **kwargs)</span></span></code> </pre><br>  Wir setzen den gesamten Code in externe Klassen ein, die einige andere Klassen verwenden.  Alle Aufgaben bestehen im Wesentlichen aus zwei Zeilen. <br><br><h4>  Einfache Objekte in Parametern <br></h4><br>  Im obigen Beispiel wird eine bestimmte ID an die Aufgabe √ºbergeben.  Bei allen Aufgaben, die wir verwenden, √ºbertragen wir <strong>nur kleine skalare Daten</strong> , id.  Wir serialisieren keine Django-Modelle, um sie zu √ºbertragen.  Selbst in ETL speichern wir einen gro√üen Daten-Blob, der von einem externen Dienst stammt, zuerst und f√ºhren dann eine Aufgabe aus, die diesen gesamten Blob anhand seiner ID liest und verarbeitet. <br><br>  Wenn Sie dies nicht tun, haben wir in Redis eine sehr gro√üe Mischung aus verbrauchtem Speicher gesehen.  Die Nachricht nimmt mehr Speicherplatz ein, das Netzwerk ist stark ausgelastet, die Anzahl der verarbeiteten Aufgaben (Leistung) sinkt.  Solange das Objekt fertig ist, sind die Aufgaben irrelevant, das Objekt wurde bereits gel√∂scht.  Die Daten mussten serialisiert werden - in JSON in Python ist nicht alles gut serialisiert.  Wir brauchten die Gelegenheit, bei Wiederholungsaufgaben irgendwie schnell zu entscheiden, was mit diesen Daten geschehen soll, sie erneut abzurufen und einige √úberpr√ºfungen durchzuf√ºhren. <br><br><blockquote>  Wenn Sie Big Data in Parametern √ºbertragen, denken Sie noch einmal dar√ºber nach!  Es ist besser, einen kleinen Skalar mit einer kleinen Menge an Informationen im Problem zu √ºbertragen und aus diesen Informationen in der Aufgabe alles zu erhalten, was Sie ben√∂tigen. <br></blockquote><br><h4>  Idempotente Probleme <br></h4><br>  Sellerieentwickler selbst empfehlen diesen Ansatz.  Wenn der Codeabschnitt wiederholt wird, sollten keine Nebenwirkungen auftreten, das Ergebnis sollte das gleiche sein.  Dies ist nicht immer einfach zu erreichen, insbesondere wenn eine Interaktion mit vielen Diensten oder zweiphasigen Commits besteht. <br><br>  Wenn Sie jedoch alles lokal erledigen, k√∂nnen Sie jederzeit √ºberpr√ºfen, ob die eingehenden Daten vorhanden und relevant sind. Sie k√∂nnen wirklich daran arbeiten und Transaktionen verwenden.  Wenn f√ºr eine Aufgabe viele Abfragen in der Datenbank vorhanden sind und zur Laufzeit m√∂glicherweise ein Fehler auftritt, verwenden Sie Transaktionen, um unn√∂tige √Ñnderungen zur√ºckzusetzen. <br><br><h4>  Abw√§rtskompatibilit√§t <br></h4><br>  Wir hatten einige interessante Nebenwirkungen, als wir die Anwendung bereitstellten.  Unabh√§ngig davon, welche Art von Bereitstellung Sie verwenden (blau + gr√ºn oder fortlaufendes Update), wird es immer eine Situation geben, in der der alte Servicecode Nachrichten f√ºr den neuen Worker-Code erstellt, und umgekehrt empf√§ngt der alte Worker Nachrichten vom neuen Service-Code, da er "zuerst" eingef√ºhrt wurde. und da ging der Verkehr. <br><br>  Wir haben Fehler entdeckt und Aufgaben verloren, bis wir gelernt haben, wie man die <strong>Abw√§rtskompatibilit√§t zwischen Releases</strong> aufrechterh√§lt.  Abw√§rtskompatibilit√§t besteht darin, dass die Aufgaben zwischen den Releases sicher funktionieren sollten, unabh√§ngig davon, welche Parameter in diese Aufgabe eingehen.  Daher machen wir jetzt bei allen Aufgaben eine "Gummi" -Signatur (** kwargs).  Wenn Sie in der n√§chsten Version einen neuen Parameter hinzuf√ºgen m√ºssen, √ºbernehmen Sie ihn von ** kwargs in der neuen Version, aber nicht in der alten - nichts wird kaputt gehen.  Sobald sich die Signatur √§ndert und Sellerie nichts davon wei√ü, st√ºrzt sie ab und gibt den Fehler aus, dass die Aufgabe keinen solchen Parameter enth√§lt. <br><br>  Eine strengere M√∂glichkeit, solche Probleme zu vermeiden, besteht darin, die Task-Warteschlangen zwischen den Releases zu versionieren. Die Implementierung ist jedoch recht schwierig, und wir haben sie vorerst im Backlog belassen. <br><br><h4>  Zeit√ºberschreitungen <br></h4><br>  Probleme k√∂nnen aufgrund unzureichender Anzahl oder falscher Zeit√ºberschreitungen auftreten. <br><br><blockquote>  Es ist b√∂se, keine Zeit√ºberschreitung f√ºr eine Aufgabe festzulegen.  Dies bedeutet, dass Sie nicht verstehen, was in der Aufgabe vor sich geht und wie die Gesch√§ftslogik funktionieren sollte. <br></blockquote><br>  Daher sind alle unsere Aufgaben mit Zeit√ºberschreitungen versehen, einschlie√ülich globaler f√ºr alle Aufgaben, und Zeit√ºberschreitungen werden auch f√ºr jede bestimmte Aufgabe festgelegt. <br><br>  <strong>Muss angebracht werden: soft_limit_timeout</strong> und <strong>l√§uft ab.</strong> <br><br>  L√§uft ab, wie viel eine Aufgabe in einer Linie leben kann.  Bei Problemen m√ºssen sich keine Aufgaben in den Warteschlangen ansammeln.  Wenn wir jetzt beispielsweise dem Benutzer etwas melden m√∂chten, aber etwas passiert ist und die Aufgabe erst morgen ausgef√ºhrt werden kann, ist dies nicht sinnvoll. Morgen ist die Nachricht nicht mehr relevant.  Daher haben wir f√ºr Benachrichtigungen einen relativ kleinen Ablauf. <br><br>  Beachten Sie die Verwendung von <strong>eta (Countdown) + Sichtbarkeit</strong> <strong>_timeout</strong> .  Die FAQ beschreibt ein solches Problem mit Redis - das sogenannte Sichtbarkeits-Timeout des Redis-Brokers.  Standardm√§√üig betr√§gt der Wert eine Stunde: Wenn der Mitarbeiter nach einer Stunde feststellt, dass niemand die Aufgabe ausgef√ºhrt hat, f√ºgt er sie erneut der Warteschlange hinzu.  Wenn der Countdown zwei Stunden betr√§gt, stellt der Broker nach einer Stunde fest, dass diese Aufgabe noch nicht abgeschlossen ist, und erstellt eine weitere Aufgabe derselben.  Und in zwei Stunden sind zwei identische Aufgaben erledigt. <br><br><blockquote>  Wenn die gesch√§tzte Zeit oder der Countdown 1 Stunde √ºberschreitet, f√ºhrt die Verwendung von Redis h√∂chstwahrscheinlich zu doppelten Aufgaben, es sei denn, Sie haben den Wert f√ºr sichtbarkeitszeit√ºberschreitung in den Einstellungen f√ºr die Verbindung zum Broker ge√§ndert. <br></blockquote><br><h4>  Wiederholen Sie die Richtlinie <br></h4><br>  F√ºr Aufgaben, die wiederholt werden k√∂nnen oder fehlschlagen k√∂nnen, verwenden wir die Wiederholungsrichtlinie.  Wir setzen es jedoch sorgf√§ltig ein, um externe Dienste nicht zu √ºberfordern.  Wenn Sie Aufgaben schnell wiederholen, ohne ein exponentielles Backoff anzugeben, kann es sein, dass ein externer oder m√∂glicherweise ein interner Dienst dies einfach nicht aush√§lt. <br><br>  Die Parameter <strong>retry_backoff</strong> , <strong>retry_jitter</strong> und <strong>max_retries lassen sich</strong> gerne explizit angeben, insbesondere max_retries.  retry_jitter - ein Parameter, mit dem Sie ein wenig Chaos verursachen k√∂nnen, damit sich die Aufgaben nicht gleichzeitig wiederholen. <br><br><h4>  Speicherlecks <br></h4><br><blockquote>  Leider sind Speicherlecks sehr einfach und es ist schwierig, sie zu finden und zu beheben. </blockquote><br>  Im Allgemeinen ist die Arbeit mit Speicher in Python sehr kontrovers.  Sie werden viel Zeit und Nerven aufwenden, um zu verstehen, warum das Leck auftritt, und dann stellt sich heraus, dass es nicht einmal in Ihrem Code enthalten ist.  Legen Sie daher beim Starten eines Projekts immer ein <strong>Speicherlimit f√ºr den Worker fest</strong> : worker_max_memory_per_child. <br><br>  Dies stellt sicher, dass OOM Killer nicht eines Tages kommt, nicht alle Arbeiter t√∂tet und Sie nicht alle Aufgaben verlieren.  Sellerie startet die Arbeiter bei Bedarf neu. <br><br><h4>  Priorit√§tsaufgaben <br></h4><br>  Es gibt immer Aufgaben, die vor allen anderen erledigt werden m√ºssen, schneller als alle anderen - sie m√ºssen sofort erledigt werden!  Es gibt Aufgaben, die nicht so wichtig sind - lassen Sie sie tags√ºber erledigen.  Hierzu hat die Aufgabe einen <strong>Priorit√§tsparameter.</strong>  In Redis funktioniert es sehr interessant - eine neue Warteschlange wird mit einem Namen erstellt, in dem Priorit√§t hinzugef√ºgt wird. <br><br>  Wir verwenden einen anderen Ansatz - <strong>getrennte Arbeiter f√ºr Priorit√§ten</strong> , d. H.  Auf altmodische Weise schaffen wir Sellerie-Arbeiter mit unterschiedlicher ‚ÄûBedeutung‚Äú: <br><br><pre> <code class="python hljs">celery multi start high_priority low_priority -c:high_priority <span class="hljs-number"><span class="hljs-number">2</span></span> -c:low_priority <span class="hljs-number"><span class="hljs-number">6</span></span> -Q:high_priority urgent_notifications -Q:low_priority emails,urgent_notifications</code> </pre><br>  Celery Multi Start ist ein Helfer, mit dem Sie die gesamte Selleriekonfiguration auf einem Computer und √ºber dieselbe Befehlszeile ausf√ºhren k√∂nnen.  In diesem Beispiel erstellen wir Knoten (oder Worker): High_priority und Low_priority, 2 und 6 sind Parallelit√§t. <br><br>  Zwei Mitarbeiter mit hoher Priorit√§t verarbeiten st√§ndig die Warteschlange f√ºr dringende Benachrichtigungen.  Niemand sonst nimmt diese Mitarbeiter mit, sie lesen nur wichtige Aufgaben aus der Warteschlange f√ºr dringende Benachrichtigungen. <br><br>  F√ºr unwichtige Aufgaben gibt es eine Warteschlange mit niedriger Priorit√§t.  Es gibt 6 Mitarbeiter, die Nachrichten aus allen anderen Warteschlangen erhalten.  Wir abonnieren auch Mitarbeiter mit niedriger Priorit√§t f√ºr dringende Benachrichtigungen, damit sie helfen k√∂nnen, wenn Mitarbeiter mit hoher Priorit√§t nicht damit umgehen k√∂nnen. <br><br>  Wir verwenden dieses klassische Schema, um Aufgaben zu priorisieren. <br><br><h4>  Extrahieren, transformieren, laden <br></h4><br>  In den meisten F√§llen sieht ETL wie eine Kette von Aufgaben aus, von denen jede Eingabe von der vorherigen Aufgabe erh√§lt. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task def download_account_data(account_id) ‚Ä¶ return account_id @task def process_account_data(account_id, processing_type) ‚Ä¶ return account_data @task def store_account_data(account_data) ‚Ä¶</span></span></code> </pre><br>  Das Beispiel hat drei Aufgaben.  Sellerie hat einen Ansatz f√ºr die verteilte Verarbeitung und mehrere n√ºtzliche Dienstprogramme, einschlie√ülich der <strong>Kettenfunktion</strong> , die eine Pipeline aus drei solchen Aufgaben macht: <br><br><pre> <code class="python hljs">chain( download_account_data.s(account_id), process_account_data.s(processing_type=<span class="hljs-string"><span class="hljs-string">'fast'</span></span>), store_account_data.s() ).delay()</code> </pre><br>  Sellerie zerlegt die Pipeline, f√ºhrt die erste Aufgabe der Reihe nach aus, √ºbertr√§gt dann die empfangenen Daten an die zweite und √ºbertr√§gt die Daten, die die zweite Aufgabe an die dritte zur√ºckgibt.  So implementieren wir einfache ETL-Pipelines. <br><br>  F√ºr komplexere Ketten m√ºssen Sie zus√§tzliche Logik verbinden.  Es ist jedoch wichtig zu beachten, dass die <strong>gesamte Kette auseinander f√§llt</strong> , wenn in einer Aufgabe ein Problem in dieser Kette <strong>auftritt</strong> .  Wenn Sie dieses Verhalten nicht m√∂chten, behandeln Sie die Ausnahme und setzen Sie die Ausf√ºhrung fort, oder stoppen Sie die gesamte Kette ausnahmsweise. <br><br>  Tats√§chlich sieht diese Kette im Inneren wie eine gro√üe Aufgabe aus, die alle Aufgaben mit allen Parametern enth√§lt.  Wenn Sie also die Anzahl der Aufgaben in der Kette missbrauchen, erhalten Sie einen sehr hohen Speicherverbrauch und eine Verlangsamung des Gesamtprozesses.  <strong>Das Erstellen von Ketten mit Tausenden von Aufgaben ist eine schlechte Idee.</strong> <br><br><h2>  Stapelaufgabenverarbeitung <br></h2><br>  Das Interessanteste: Was passiert, wenn Sie eine E-Mail an zwei Millionen Benutzer senden m√ºssen? <br><br>  Sie schreiben eine solche Funktion, um alle Benutzer zu umgehen: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task def send_report_emails_to_users(): for user_id in User.get_active_ids(): send_report_email.delay(user_id=user_id)</span></span></code> </pre><br>  In den meisten F√§llen erh√§lt die Funktion jedoch nicht nur die Benutzer-ID, sondern auch die gesamte Benutzertabelle im Allgemeinen.  Jeder Benutzer hat seine eigene Aufgabe. <br><br>  Bei dieser Aufgabe gibt es mehrere Probleme: <br><br><ul><li>  Aufgaben werden nacheinander gestartet, dh die letzte Aufgabe (zweimillionster Benutzer) wird in 20 Minuten gestartet und funktioniert m√∂glicherweise bereits zu diesem Zeitpunkt. </li><li>  Alle Benutzer-IDs werden zuerst in den Anwendungsspeicher geladen und dann in die Warteschlange - delay () f√ºhrt 2 Millionen Aufgaben aus. </li></ul><br>  Ich habe es Task Flood genannt, das Diagramm sieht ungef√§hr so ‚Äã‚Äãaus. <br><img src="https://habrastorage.org/webt/j_/ya/6r/j_ya6r359licn16439uohbpoaow.png"><br>  Es gibt einen Zustrom von Aufgaben, die die Mitarbeiter langsam zu bearbeiten beginnen.  Folgendes passiert, wenn Aufgaben eine Master-Replik verwenden, das gesamte Projekt zu knacken beginnt und nichts funktioniert.  Nachfolgend finden Sie ein Beispiel aus unserer Praxis, in der die DB-CPU-Auslastung mehrere Stunden lang 100% betrug. Um ehrlich zu sein, haben wir es geschafft, Angst zu bekommen. <br><img src="https://habrastorage.org/webt/ac/wh/jy/acwhjy96edpu3dry_vatxj5z7yw.png"><br>  Das Problem ist, dass das System mit zunehmender Anzahl von Benutzern stark beeintr√§chtigt wird.  Die Aufgabe, die sich mit der Planung befasst: <br><br><ul><li>  erfordert immer mehr Speicher; </li><li>  l√§uft l√§nger und kann durch Timeout "get√∂tet" werden. </li></ul><br>  Aufgaben√ºberflutung tritt auf: Aufgaben sammeln sich in Warteschlangen an und verursachen eine gro√üe Belastung nicht nur f√ºr interne, sondern auch f√ºr externe Dienste. <br><br>  Wir haben versucht <strong>, die Wettbewerbsf√§higkeit der Arbeitnehmer zu verringern.</strong> Dies hilft in gewissem Sinne - die Belastung des Dienstes wird verringert.  Oder Sie k√∂nnen <strong>interne Services skalieren</strong> .  Dies wird jedoch das Problem des Generatorproblems nicht l√∂sen, das immer noch viel in Anspruch nimmt.  Und beeinflusst in keiner Weise die Abh√§ngigkeit von der Leistung externer Dienste. <br><br><h3>  Aufgabengenerierung <br></h3><br>  Wir haben uns f√ºr einen anderen Weg entschieden.  In den meisten F√§llen m√ºssen wir derzeit nicht alle 2 Millionen Aufgaben ausf√ºhren.  Es ist normal, dass das Versenden von Benachrichtigungen an alle Benutzer beispielsweise 4 Stunden dauert, wenn diese Briefe nicht so wichtig sind. <br><br>  Zuerst haben wir versucht, <strong>Celery.chunks zu verwenden</strong> : <br><br><pre> <code class="python hljs">send_report_email.chunks( ({<span class="hljs-string"><span class="hljs-string">'user_id'</span></span>: user.id} <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> user <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> User.objects.active()), n=<span class="hljs-number"><span class="hljs-number">100</span></span> ).apply_async()</code> </pre><br>  Dies hat die Situation nicht ge√§ndert, da trotz des Iterators alle Benutzer-IDs in den Speicher geladen werden.  Und alle Arbeiter bekommen eine Reihe von Aufgaben, und obwohl sich die Arbeiter ein wenig entspannen werden, waren wir am Ende mit dieser Entscheidung nicht zufrieden. <br><br>  Wir haben versucht, <strong>rate_limit</strong> auf Worker <strong>festzulegen</strong> , damit diese nur eine bestimmte Anzahl von Aufgaben pro Sekunde verarbeiten, und wir haben herausgefunden, dass rate_limit, das f√ºr die Aufgabe angegeben wurde, rate_limit f√ºr den Worker ist.  Wenn Sie also rate_limit f√ºr die Aufgabe angeben, bedeutet dies nicht, dass die Aufgabe 70 Mal pro Sekunde ausgef√ºhrt wird.  Dies bedeutet, dass der Arbeiter es 70 Mal pro Sekunde ausf√ºhrt, und abh√§ngig davon, was Sie mit den Arbeitern haben, kann sich diese Grenze dynamisch √§ndern, d. H.  real limit rate_limit * len (Arbeiter). <br><br>  Wenn der Worker startet oder stoppt, √§ndert sich das gesamte rate_limit.  Wenn Ihre Aufgaben langsam sind, wird au√üerdem der gesamte Prefetch in der Warteschlange, die den Worker f√ºllt, mit diesen langsamen Aufgaben verstopft.  Der Arbeiter sieht aus: ‚ÄûOh, ich habe diese Aufgabe in rate_limit, ich kann sie nicht mehr ausf√ºhren.  Und alle folgenden Aufgaben in der Warteschlange sind genau gleich - lassen Sie sie h√§ngen! ‚Äú  - und warten. <br><br><h3>  Chunkificator <br></h3><br>  Am Ende beschlossen wir, unsere eigene zu schreiben, und erstellten eine kleine Bibliothek namens Chunkificator. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task @chunkify_task(sleep_timeout=...l initial_chunk=...) def send_report_emails_to_users(chunk: Chunk): for user_id in User.get_active_ids(chunk=chunk): send_report_email.delay(user_id=user_id)</span></span></code> </pre><br>  Es ben√∂tigt sleep_timeout und initial_chunk und ruft sich selbst mit einem neuen Chunk auf.  Chunk ist eine Abstraktion entweder √ºber Ganzzahllisten oder √ºber Datums- oder Datums- / Uhrzeitlisten.  Wir √ºbergeben den Block an eine Funktion, die nur Benutzer mit diesem Block empf√§ngt und Aufgaben nur f√ºr diesen Block ausf√ºhrt. <br><br>  Somit f√ºhrt der Aufgabengenerator nur die Anzahl der ben√∂tigten Aufgaben aus und verbraucht nicht viel Speicher.  Das Bild ist so geworden. <br><img src="https://habrastorage.org/webt/yh/gg/h_/yhggh__vbzgiexxwskakp1nltrw.png"><br>  Das Highlight ist, dass wir einen sp√§rlichen Block verwenden, dh wir verwenden Instanzen in der Datenbank als Block-ID (einige von ihnen werden m√∂glicherweise √ºbersprungen, sodass m√∂glicherweise weniger Aufgaben vorhanden sind).  Infolgedessen stellte sich heraus, dass die Last gleichm√§√üiger war, der Prozess l√§nger wurde, aber jeder lebt und es geht ihm gut, die Basis ist nicht anstrengend. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Bibliothek ist</a> f√ºr Python 3.6+ implementiert und auf GitHub verf√ºgbar.  Es gibt eine Nuance, die ich beheben m√∂chte, aber f√ºr den Moment ben√∂tigt datetime-chunk einen Pickle-Serializer - viele werden dies nicht k√∂nnen. <br><br>  Ein paar rhetorische Fragen - woher kamen all diese Informationen?  Wie haben wir herausgefunden, dass wir Probleme hatten?  Woher wissen Sie, dass ein Problem bald kritisch wird und Sie bereits mit der L√∂sung beginnen m√ºssen? <br><br>  Die Antwort ist nat√ºrlich √úberwachung. <br><br><h2>  √úberwachung <br></h2><br>  Ich mag es wirklich zu √ºberwachen, ich mag es alles zu √ºberwachen und meinen Finger am Puls der Zeit zu halten.  Wenn Sie Ihren Finger nicht am Puls der Zeit halten, treten Sie st√§ndig auf den Rechen. <br><br>  Standard√ºberwachungsfragen: <br><br><ul><li>  √úbernimmt die aktuelle Worker- / Parallelit√§tskonfiguration die Last? </li><li>  Was ist die Verschlechterung der Ausf√ºhrungszeit von Aufgaben? </li><li>  Wie lange h√§ngen Aufgaben in der Schlange?  Pl√∂tzlich ist die Leitung schon √ºberf√ºllt? </li></ul><br>  Wir haben verschiedene Optionen ausprobiert.  Sellerie hat eine <strong>CLI-</strong> Oberfl√§che, es ist ziemlich reichhaltig und bietet: <br><br><ul><li>  inspizieren - Informationen √ºber das System; </li><li>  Steuerung - Systemeinstellungen verwalten; </li><li>  L√∂schen - L√∂schen von Warteschlangen (h√∂here Gewalt); </li><li>  Ereignisse - Benutzeroberfl√§che der Konsole zum Anzeigen von Informationen zu ausgef√ºhrten Aufgaben. </li></ul><br>  Aber es ist schwer, etwas wirklich zu √ºberwachen.  Es ist besser f√ºr lokale Schnickschnack geeignet oder wenn Sie zur Laufzeit etwas rate_limit √§ndern m√∂chten. <br><br>  <strong>NB: Sie</strong> ben√∂tigen Zugriff auf den Produktionsbroker, um die CLI-Schnittstelle verwenden zu k√∂nnen. <br><br>  <strong>Mit Celery Flower</strong> k√∂nnen Sie dasselbe wie mit der CLI tun, nur √ºber die Weboberfl√§che, und das ist noch nicht alles.  Es werden jedoch einige einfache Diagramme erstellt, und Sie k√∂nnen die Einstellungen im laufenden Betrieb √§ndern. <br><br>  Im Allgemeinen ist Sellerieblume geeignet, um zu sehen, wie alles in kleinen Aufbauten funktioniert.  Dar√ºber hinaus unterst√ºtzt es die HTTP-API, was praktisch ist, wenn Sie Automatisierung schreiben. <br><br>  Aber wir haben uns <strong>f√ºr Prometheus entschieden.</strong>  Sie nahmen den aktuellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Exporteur</a> : feste Speicherlecks darin;  Metriken f√ºr Ausnahmetypen hinzugef√ºgt;  Metriken f√ºr die Anzahl der Nachrichten in den Warteschlangen hinzugef√ºgt;  Integriert in Warnungen in Grafana und freut euch.  Es ist auch auf GitHub ver√∂ffentlicht, Sie k√∂nnen es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier sehen</a> . <br><br><h4>  Beispiele in Grafana <br></h4><br><img src="https://habrastorage.org/webt/wa/i3/yt/wai3ytvm4ewoiumfrlvn2gzq9eg.png"><br>  Oben Statistik f√ºr alle Ausnahmen: Welche Ausnahmen f√ºr welche Aufgaben.  Unten ist die Zeit, um die Aufgaben zu erledigen. <br><img src="https://habrastorage.org/webt/ae/l3/sf/ael3sfmjeve51s5jtui9fh_7ydq.png"><br><h2>  Was fehlt in Sellerie? <br></h2><br>  Dies ist ein gr√ºner Rahmen, er hat viele Dinge, aber wir fehlen!  Es gibt nicht gen√ºgend kleine Funktionen wie: <br><br><ul><li>  <strong>Automatisches Neuladen von Code w√§hrend der Entwicklung</strong> - unterst√ºtzt diesen Sellerie nicht - Neustart. </li><li>  <strong>Metriken f√ºr Prometheus sind sofort einsatzbereit</strong> , Dramatiq jedoch. </li><li>  <strong>Unterst√ºtzung f√ºr die</strong> <strong>Aufgabensperre,</strong> sodass jeweils nur eine Aufgabe ausgef√ºhrt wird.  Sie k√∂nnen es selbst tun, aber Dramatiq und Tasktiger haben einen praktischen Dekorateur, der sicherstellt, dass alle anderen √§hnlichen Aufgaben blockiert werden. </li><li>  <strong>Rate_limit f√ºr eine Aufgabe</strong> - nicht f√ºr den Arbeiter. </li></ul><br><h2>  Schlussfolgerungen <br></h2><br>  Trotz der Tatsache, dass Sellerie ein Framework ist, das viele in der Produktion verwenden, besteht es aus 3 Bibliotheken - Sellerie, Kombu und Billard.  Alle drei Bibliotheken werden von Mitentwicklern entwickelt und k√∂nnen eine Abh√§ngigkeit aufheben und Ihre Assembly unterbrechen. <br><img src="https://habrastorage.org/webt/dv/np/52/dvnp52xxgjcwsbdwr3c15a86-ac.png"><br>  Daher hoffe ich, dass Sie es bereits irgendwie gekl√§rt und Ihre Versammlungen deterministisch gemacht haben. <br><br>  In der Tat sind die Schlussfolgerungen nicht so traurig.  <strong>Sellerie bew√§ltigt seine Aufgaben</strong> in unserem Fintech-Projekt unter unserer Last.  Wir haben Erfahrungen gesammelt, die ich mit Ihnen geteilt habe, und Sie k√∂nnen unsere L√∂sungen anwenden oder verfeinern und auch alle Ihre Schwierigkeiten √ºberwinden. <br><br>  Vergessen Sie nicht, dass die <strong>√úberwachung ein wesentlicher Bestandteil Ihres Projekts sein sollte</strong> .  Nur durch √úberwachung k√∂nnen Sie herausfinden, wo etwas nicht stimmt, was behoben, hinzugef√ºgt, behoben werden muss. <br><br>  <strong>Ansprechpartner Oleg</strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Churkin</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Bahusss</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Facebook</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github</a> . <br><br><blockquote>  Die n√§chste gro√üe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Moscow Python Conf ++</a> findet <b>am 5. April</b> in Moskau <b>statt</b> .  In diesem Jahr werden wir versuchen, alle Vorteile an einem Tag in einem experimentellen Modus zu vereinen.  Es wird nicht weniger Berichte geben, wir werden ausl√§ndischen Entwicklern bekannter Bibliotheken und Produkte einen ganzen Strom zuweisen.  Dar√ºber hinaus ist Freitag ein idealer Tag f√ºr After-Partys, der, wie Sie wissen, ein wesentlicher Bestandteil der Konferenz √ºber Kommunikation ist. <br><br>  Nehmen Sie an unserer professionellen Python-Konferenz teil - reichen Sie Ihren Bericht <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier ein</a> und buchen Sie Ihr Ticket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .  In der Zwischenzeit laufen die Vorbereitungen, Artikel zu Moscow Python Conf ++ 2018 werden hier erscheinen. <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de433476/">https://habr.com/ru/post/de433476/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de433464/index.html">Subkosmische Rasse</a></li>
<li><a href="../de433466/index.html">Seiten vergleichen. Einfaches Plugin f√ºr Atlassian Confluence</a></li>
<li><a href="../de433468/index.html">Fehlerinjektion: Ihr System ist unzuverl√§ssig, wenn Sie nicht versucht haben, es zu besch√§digen</a></li>
<li><a href="../de433472/index.html">Unity 2018.3 ver√∂ffentlicht</a></li>
<li><a href="../de433474/index.html">Pylint von innen nach au√üen. Wie macht er das?</a></li>
<li><a href="../de433478/index.html">Warum Django im Tinkoff Magazine ausgew√§hlt wird</a></li>
<li><a href="../de433480/index.html">Holivarny Geschichte √ºber Linter</a></li>
<li><a href="../de433482/index.html">Django unter dem Mikroskop</a></li>
<li><a href="../de433486/index.html">Was nochmal? Die Wiederbelebung von Nicht-Bank-Debitkarten</a></li>
<li><a href="../de433488/index.html">Christmas Scrum Meetup UPD Broadcast Mitap</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
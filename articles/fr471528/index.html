<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚¨úÔ∏è üìª üò´ D√©ployer des applications √† l'aide de Docker Swarm üå≠ üë©üèª‚Äçüî¨ üìì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le syst√®me de recommandation de contenu vid√©o en ligne sur lequel nous travaillons est un d√©veloppement commercial ferm√© et est techniquement un clust...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>D√©ployer des applications √† l'aide de Docker Swarm</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471528/">  Le syst√®me de recommandation de contenu vid√©o en ligne sur lequel nous travaillons est un d√©veloppement commercial ferm√© et est techniquement un cluster multi-composants de ses propres composants open source.  Le but de cet article est de d√©crire l'introduction d'un syst√®me de clustering Docker Swarm pour une plate-forme interm√©diaire, sans perturber le flux de travail existant de nos processus dans un temps limit√©.  Le r√©cit pr√©sent√© √† votre attention est divis√© en deux parties.  La premi√®re partie d√©crit le CI / CD avant d'utiliser l'essaim de docker et la seconde d√©crit le processus de mise en ≈ìuvre.  Ceux qui ne sont pas int√©ress√©s par la lecture de la premi√®re partie peuvent passer en toute s√©curit√© √† la seconde. <br><a name="habracut"></a><br><h3>  Partie I </h3><br>  Au cours d'une ann√©e lointaine et lointaine, il a fallu configurer le processus CI / CD le plus rapidement possible.  L'une des conditions √©tait de ne pas utiliser Docker <i>pour d√©ployer les</i> composants d√©velopp√©s pour plusieurs raisons: <br><br><ul><li>  pour un fonctionnement plus fiable et stable des composants en Production (c'est-√†-dire, en fait, l'exigence de ne pas utiliser la virtualisation) </li><li>  Les principaux d√©veloppeurs ne voulaient pas travailler avec Docker (√©trange, mais c'√©tait juste √ßa) </li><li>  pour des raisons id√©ologiques gestion R&amp;D </li></ul><br>  L'infrastructure, la pile et les exemples d'exigences initiales pour MVP √©taient les suivants: <br><br><ul><li>  4 serveurs Intel¬Æ X5650 avec Debian (une machine plus puissante compl√®tement pour le d√©veloppement) </li><li>  Le d√©veloppement de composants personnalis√©s s'effectue en C ++, Python3 </li><li>  Les principaux outils tiers: Kafka, Clickhouse, Airflow, Redis, Grafana, Postgresql, Mysql, ... </li><li>  Assemblage des pipelines et test des composants s√©par√©ment pour le d√©bogage et la publication </li></ul><br>  L'un des premiers probl√®mes √† r√©soudre √† l'√©tape initiale est de savoir comment d√©ployer des composants personnalis√©s dans n'importe quel environnement (CI / CD). <br><br>  Les composants tiers ont d√©cid√© de proc√©der √† une installation syst√©mique et de les mettre √† jour de mani√®re syst√©mique.  Les applications personnalis√©es d√©velopp√©es en C ++ ou Python peuvent √™tre d√©ploy√©es de plusieurs mani√®res.  Parmi eux, par exemple: la cr√©ation de packages syst√®me, leur envoi vers le r√©f√©rentiel des images collect√©es et leur installation ult√©rieure sur les serveurs.  Pour une raison inconnue, une autre m√©thode a √©t√© choisie, √† savoir, √† l'aide de CI, les fichiers d'application ex√©cutables sont compil√©s, un environnement de projet virtuel est cr√©√©, des modules py √† partir de requirements.txt sont install√©s et tous ces artefacts sont envoy√©s avec les configurations, les scripts et l'environnement d'application qui l'accompagne aux serveurs.  Ensuite, les applications sont lanc√©es √† partir d'un utilisateur virtuel sans droits d'administrateur. <br><br>  Gitlab-CI a √©t√© choisi comme syst√®me CI / CD.  Le pipeline r√©sultant ressemblait √† ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/460/406/c27/460406c27d873dc28928ac3ba901f903.png" alt="image"><br><div class="spoiler">  <b class="spoiler_title">Structurellement, gitlab-ci.yml ressemblait √† ceci</b> <div class="spoiler_text"><pre><code class="xml hljs">--- variables: #     ,    CMAKE_CPUTYPE: "westmere" DEBIAN: "MYREGISTRY:5000/debian:latest" before_script: - eval $(ssh-agent -s) - ssh-add <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">(echo</span></span></span><span class="hljs-tag"> "$</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">SSH_PRIVATE_KEY</span></span></span><span class="hljs-tag">") </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">mkdir</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-p</span></span></span><span class="hljs-tag"> ~/</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">.ssh</span></span></span><span class="hljs-tag"> &amp;&amp; </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">echo</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-e</span></span></span><span class="hljs-tag"> "</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Host</span></span></span><span class="hljs-tag"> *\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">tStrictHostKeyChecking</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">no</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">" &gt;</span></span> ~/.ssh/config stages: - build - testing - deploy debug.debian: stage: build image: $DEBIAN script: - cd builds/release &amp;&amp; ./build.sh paths: - bin/ - builds/release/bin/ when: always release.debian: stage: build image: $DEBIAN script: - cd builds/release &amp;&amp; ./build.sh paths: - bin/ - builds/release/bin/ when: always ## testing stage tests.codestyle: stage: testing image: $DEBIAN dependencies: - release.debian script: - /bin/bash run_tests.sh -t codestyle -b "${CI_COMMIT_REF_NAME}_codestyle" tests.debug.debian: stage: testing image: $DEBIAN dependencies: - debug.debian script: - /bin/bash run_tests.sh -e codestyle/test_pylint.py -b "${CI_COMMIT_REF_NAME}_debian_debug" artifacts: paths: - run_tests/username/ when: always expire_in: 1 week tests.release.debian: stage: testing image: $DEBIAN dependencies: - release.debian script: - /bin/bash run_tests.sh -e codestyle/test_pylint.py -b "${CI_COMMIT_REF_NAME}_debian_release" artifacts: paths: - run_tests/username/ when: always expire_in: 1 week ## staging stage deploy_staging: stage: deploy environment: staging image: $DEBIAN dependencies: - release.debian script: - cd scripts/deploy/ &amp;&amp; python3 createconfig.py -s $CI_ENVIRONMENT_NAME &amp;&amp; /bin/bash install_venv.sh -d -r ../../requirements.txt &amp;&amp; python3 prepare_init.d.py &amp;&amp; python3 deploy.py -s $CI_ENVIRONMENT_NAME when: manual</code> </pre> <br></div></div><br>  Il convient de noter que l'assemblage et les tests sont effectu√©s sur sa propre image, o√π tous les packages syst√®me n√©cessaires sont d√©j√† install√©s et d'autres param√®tres sont d√©finis. <br><br>  Bien que chacun de ces scripts en cours d'emploi soit int√©ressant √† sa mani√®re, <s>je n'en parlerai certainement pas</s> , mais la description de chacun d'entre eux prendra beaucoup de temps et ce n'est pas le but de l'article.  Je ferai seulement attention au fait que l'√©tape de d√©ploiement consiste en une s√©quence d'appels de script: <br><br><ol><li>  <b>createconfig.py</b> - cr√©e le fichier settings.ini avec les param√®tres des composants dans un environnement diff√©rent pour le d√©ploiement ult√©rieur (pr√©production, production, test, ...) </li><li>  <b>install_venv.sh</b> - cr√©e un environnement virtuel pour les composants py dans un r√©pertoire sp√©cifique et le copie sur des serveurs distants </li><li>  <b>prepare_init.d.py</b> - pr√©pare les scripts de d√©marrage et d'arr√™t des composants sur la base d'un mod√®le </li><li>  <b>deploy.py</b> - <b>d√©compresse</b> et red√©marre de nouveaux composants </li></ol><br>  Le temps a pass√©.  La phase de mise en sc√®ne a √©t√© remplac√©e par la pr√©production et la production.  Le support produit a √©t√© ajout√© sur un autre kit de distribution (CentOS).  5 serveurs physiques plus puissants et une douzaine de serveurs virtuels ont √©t√© ajout√©s.  Et il devenait de plus en plus difficile pour les d√©veloppeurs et les testeurs d'ex√©cuter leurs t√¢ches dans un environnement plus ou moins proche de l'√©tat de fonctionnement.  A cette √©poque, il est devenu clair qu'il est impossible de se passer de lui ... <br><br><h3>  Partie II </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/673/166/f0e67316667fed0c0d673653419e8b8a.png" alt="image"><br><br>  Ainsi, notre cluster est <s>toujours le spectacle d'un</s> syst√®me de quelques dizaines de composants distincts qui ne sont pas d√©crits par Dockerfiles.  Vous pouvez le configurer pour le d√©ploiement dans un environnement sp√©cifique uniquement dans son ensemble.  Notre t√¢che consiste √† d√©ployer le cluster dans un environnement interm√©diaire pour l'ex√©cuter avant les tests pr√©liminaires. <br><br>  Th√©oriquement, il peut y avoir plusieurs clusters fonctionnant simultan√©ment: autant de t√¢ches sont termin√©es ou presque termin√©es.  Les capacit√©s disponibles sur nos serveurs nous permettent d'ex√©cuter plusieurs clusters sur chaque serveur.  Chaque cluster interm√©diaire doit √™tre isol√© (il ne doit pas y avoir d'intersection sur les ports, les r√©pertoires, etc.). <br><br>  La ressource la plus pr√©cieuse est notre temps, et nous n'avions pas grand-chose. <br><br>  Pour un d√©marrage plus rapide, ils ont choisi Docker Swarm en raison de sa simplicit√© et de sa flexibilit√© d'architecture.  La premi√®re chose que nous avons faite a √©t√© de cr√©er sur les serveurs de gestion √† distance et plusieurs n≈ìuds: <br><br><pre> <code class="bash hljs">$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION kilqc94pi2upzvabttikrfr5d nop-test-1 Ready Active 19.03.2 jilwe56pl2zvabupryuosdj78 nop-test-2 Ready Active 19.03.2 j5a4yz1kr2xke6b1ohoqlnbq5 * nop-test-3 Ready Active Leader 19.03.2</code> </pre><br>  Ensuite, nous avons cr√©√© un r√©seau: <br><br><pre> <code class="bash hljs">$ docker network create --driver overlay --subnet 10.10.10.0/24 nw_swarm</code> </pre><br>  Ensuite, nous avons connect√© les n≈ìuds Gitlab-CI et Swarm en termes de gestion √† distance des n≈ìuds CI: installation de certificats, configuration de variables secr√®tes, ainsi que configuration du service Docker sur le serveur de gestion.  Cet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> nous a fait gagner beaucoup de temps. <br><br>  Ensuite, nous avons ajout√© des t√¢ches pour cr√©er et d√©truire la pile dans .gitlab-ci .yml. <br><br><div class="spoiler">  <b class="spoiler_title">Quelques travaux suppl√©mentaires ont √©t√© ajout√©s √† .gitlab-ci .yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">## staging stage deploy_staging: stage: testing before_script: - echo "override global 'before_script'" image: "REGISTRY:5000/docker:latest" environment: staging dependencies: [] variables: DOCKER_CERT_PATH: "/certs" DOCKER_HOST: tcp://10.50.173.107:2376 DOCKER_TLS_VERIFY: 1 CI_BIN_DEPENDENCIES_JOB: "release.centos.7" script: - mkdir -p $DOCKER_CERT_PATH - echo "$TLSCACERT" &gt; $DOCKER_CERT_PATH/ca.pem - echo "$TLSCERT" &gt; $DOCKER_CERT_PATH/cert.pem - echo "$TLSKEY" &gt; $DOCKER_CERT_PATH/key.pem - docker stack deploy -c docker-compose.yml ${CI_ENVIRONMENT_NAME}_${CI_COMMIT_REF_NAME} --with-registry-auth - rm -rf $DOCKER_CERT_PATH when: manual ## stop staging stage stop_staging: stage: testing before_script: - echo "override global 'before_script'" image: "REGISTRY:5000/docker:latest" environment: staging dependencies: [] variables: DOCKER_CERT_PATH: "/certs" DOCKER_HOST: tcp://10.50.173.107:2376 DOCKER_TLS_VERIFY: 1 script: - mkdir -p $DOCKER_CERT_PATH - echo "$TLSCACERT" &gt; $DOCKER_CERT_PATH/ca.pem - echo "$TLSCERT" &gt; $DOCKER_CERT_PATH/cert.pem - echo "$TLSKEY" &gt; $DOCKER_CERT_PATH/key.pem - docker stack rm ${CI_ENVIRONMENT_NAME}_${CI_COMMIT_REF_NAME} # TODO: need check that stopped when: manual</code> </pre><br></div></div><br>  √Ä partir de l'extrait de code ci-dessus, il est clair que deux boutons (deploy_staging, stop_staging) ont √©t√© ajout√©s aux pipelines qui n√©cessitent une intervention manuelle. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2de/e3c/790/2dee3c7907f75f793499665d8a60de8a.png" alt="image"><br>  Le nom de la pile correspond au nom de la branche et cette unicit√© devrait suffire.  Les services de la pile re√ßoivent des adresses IP uniques, des ports, des r√©pertoires, etc.  sera isol√©, mais le m√™me d'une pile √† l'autre (car le fichier de configuration est le m√™me pour toutes les piles) - c'est ce que nous avons r√©alis√©.  Nous d√©ployons <b>la pile</b> (cluster) √† l'aide de <b>docker-compose.yml</b> , qui d√©crit notre cluster. <br><br><div class="spoiler">  <b class="spoiler_title">docker-compose.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">--- version: '3' services: userprop: image: redis:alpine deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: celery_bcd: image: redis:alpine deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: schedulerdb: image: mariadb:latest environment: MYSQL_ALLOW_EMPTY_PASSWORD: 'yes' MYSQL_DATABASE: schedulerdb MYSQL_USER: **** MYSQL_PASSWORD: **** command: ['--character-set-server=utf8mb4', '--collation-server=utf8mb4_unicode_ci', '--explicit_defaults_for_timestamp=1'] deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: celerydb: image: mariadb:latest environment: MYSQL_ALLOW_EMPTY_PASSWORD: 'yes' MYSQL_DATABASE: celerydb MYSQL_USER: **** MYSQL_PASSWORD: **** deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: cluster: image: $CENTOS7 environment: - CENTOS - CI_ENVIRONMENT_NAME - CI_API_V4_URL - CI_REPOSITORY_URL - CI_PROJECT_ID - CI_PROJECT_URL - CI_PROJECT_PATH - CI_PROJECT_NAME - CI_COMMIT_REF_NAME - CI_BIN_DEPENDENCIES_JOB command: &gt; sudo -u myusername -H /bin/bash -c ". /etc/profile &amp;&amp; mkdir -p /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME &amp;&amp; cd /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME &amp;&amp; git clone -b $CI_COMMIT_REF_NAME $CI_REPOSITORY_URL . &amp;&amp; curl $CI_API_V4_URL/projects/$CI_PROJECT_ID/jobs/artifacts/$CI_COMMIT_REF_NAME/download?job=$CI_BIN_DEPENDENCIES_JOB -o artifacts.zip &amp;&amp; unzip artifacts.zip ; cd /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME/scripts/deploy/ &amp;&amp; python3 createconfig.py -s $CI_ENVIRONMENT_NAME &amp;&amp; /bin/bash install_venv.sh -d -r ../../requirements.txt &amp;&amp; python3 prepare_init.d.py &amp;&amp; python3 deploy.py -s $CI_ENVIRONMENT_NAME" deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none tty: true stdin_open: true networks: nw_swarm: networks: nw_swarm: external: true</code> </pre><br></div></div><br>  Ici, vous pouvez voir que les composants sont connect√©s par un r√©seau (nw_swarm) et sont accessibles les uns aux autres. <br><br>  Les composants syst√®me (bas√©s sur redis, mysql) sont s√©par√©s du pool commun de composants personnalis√©s (dans les plans et personnalis√©s sont divis√©s en services).  L'√©tape de d√©ploiement de notre cluster ressemble au transfert CMD vers notre grande image configur√©e et, dans l'ensemble, ne diff√®re pratiquement pas du d√©ploiement d√©crit dans la partie I. Je souligne les diff√©rences: <br><br><ul><li>  <b>git clone ...</b> - nous obtenons les fichiers n√©cessaires pour faire un d√©ploiement (createconfig.py, install_venv.sh, etc.) </li><li>  <b>curl ... &amp;&amp; unzip ...</b> - t√©l√©charger et d√©compresser les artefacts d'assemblage (utilitaires compil√©s) </li></ul><br>  Il n'y a qu'un seul probl√®me qui n'a pas encore √©t√© d√©crit: les composants qui ont une interface Web ne sont pas accessibles depuis les navigateurs des d√©veloppeurs.  Nous r√©solvons ce probl√®me en utilisant un proxy inverse, donc: <br><br>  Dans .gitlab-ci.yml, apr√®s le d√©ploiement de la pile de cluster, ajoutez la ligne de d√©ploiement de l'√©quilibreur (qui, lors de la validation, ne met √† jour que sa configuration (cr√©e de nouveaux fichiers de configuration nginx en utilisant le mod√®le: /etc/nginx/conf.d/${CI_COMMIT_REF_NAME‚ñ∫.conf) - voir le code docker-compose-nginx.yml) <br><br><pre> <code class="xml hljs"> - docker stack deploy -c docker-compose-nginx.yml ${CI_ENVIRONMENT_NAME} --with-registry-auth</code> </pre><br><div class="spoiler">  <b class="spoiler_title">docker-compose-nginx.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">--- version: '3' services: nginx: image: nginx:latest environment: CI_COMMIT_REF_NAME: ${CI_COMMIT_REF_NAME} NGINX_CONFIG: |- server { listen 8080; server_name staging_${CI_COMMIT_REF_NAME}_cluster.dev; location / { proxy_pass http://staging_${CI_COMMIT_REF_NAME}_cluster:8080; } } server { listen 5555; server_name staging_${CI_COMMIT_REF_NAME}_cluster.dev; location / { proxy_pass http://staging_${CI_COMMIT_REF_NAME}_cluster:5555; } } volumes: - /tmp/staging/nginx:/etc/nginx/conf.d command: /bin/bash -c "echo -e \"$$NGINX_CONFIG\" &gt; /etc/nginx/conf.d/${CI_COMMIT_REF_NAME}.conf; nginx -g \"daemon off;\"; /etc/init.d/nginx reload" ports: - 8080:8080 - 5555:5555 - 3000:3000 - 443:443 - 80:80 deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: networks: nw_swarm: external: true</code> </pre><br></div></div><br>  Sur les ordinateurs de d√©veloppement, mettez √† jour / etc / hosts;  enregistrer l'url sur nginx: <br><br> <code>10.50.173.106 staging_BRANCH-1831_cluster.dev <br></code> <br>  Ainsi, le d√©ploiement de clusters de staging isol√©s a √©t√© impl√©ment√© et les d√©veloppeurs peuvent d√©sormais les lancer en quantit√© suffisante pour tester leurs t√¢ches. <br><br>  Plans futurs: <br><br><ul><li>  S√©parez nos composants en tant que services </li><li>  Faites pour chaque Dockerfile </li><li>  D√©tecter automatiquement les n≈ìuds moins charg√©s dans la pile </li><li>  D√©finir les n≈ìuds par mod√®le de nom (plut√¥t que d'utiliser id comme dans l'article) </li><li>  Ajouter v√©rifier que la pile est d√©truite </li><li>  ... </li></ul><br>  Un merci sp√©cial pour l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr471528/">https://habr.com/ru/post/fr471528/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr471516/index.html">Intel 665p - SSD avec NAND QLC √† 96 couches</a></li>
<li><a href="../fr471518/index.html">Apple en 2019 est Linux en 2000</a></li>
<li><a href="../fr471520/index.html">Le livre "T√¢ches classiques en informatique en Python"</a></li>
<li><a href="../fr471522/index.html">Askozia. Fonctionnement de l'autoprovisioning Plug & Play</a></li>
<li><a href="../fr471524/index.html">Traduction compl√®te des instructions pour les √©valuateurs Google</a></li>
<li><a href="../fr471530/index.html">GitLab a parcouru un chemin inhabituel vers CI / CD et Kubernetes</a></li>
<li><a href="../fr471532/index.html">Au revoir PCB; bonjour interconnexion silicium</a></li>
<li><a href="../fr471536/index.html">Google Flood Prediction: An Inside Look</a></li>
<li><a href="../fr471538/index.html">De l'id√©e d'une application mobile au MVP dans lequel les investisseurs investiront</a></li>
<li><a href="../fr471542/index.html">Reconnaissance de texte OCR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
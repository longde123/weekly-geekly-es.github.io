<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚺 🏴󠁧󠁢󠁳󠁣󠁴󠁿 🚵🏿 Instrucciones de la API de detección de objetos TensorFlow ⛅️ 🐠 👍</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Traducción del tutorial de la API de detección de objetos TensorFlow - Capacitación y evaluación del detector de objetos personalizado . 

 Todos sabe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Instrucciones de la API de detección de objetos TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/422353/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e69/109/61a/e6910961a21edc6bc6f3f4b58b92c9cd.png"></div><br>  <i>Traducción del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tutorial de la API de detección de objetos TensorFlow - Capacitación y evaluación del detector de objetos personalizado</a> .</i> <br><br>  Todos sabemos conducir un automóvil, es bastante fácil, ¿verdad?  Pero, ¿qué harás si alguien te pide que subas al avión?  Así es, leerás las instrucciones.  Del mismo modo, el siguiente manual lo ayudará a configurar su API y disfrutar de un vuelo agradable. <br><a name="habracut"></a><br>  En primer lugar, clone el repositorio por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">referencia</a> .  Espero que ya tengas instalado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> . <br><br>  <i>git clone <a href="">github.com/tensorflow/models.git</a></i> <br><br>  En el aprendizaje automático, generalmente entrenamos y probamos un modelo usando un archivo CSV.  Pero en este caso, actuamos de acuerdo con el esquema que se muestra en la figura: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ccb/6f5/7df/ccb6f57dfab5c0f35040019be7f60f87.png"><br><br>  Antes de continuar, detengámonos en la estructura de directorios que usaremos. <br><br><ul><li>  datos / - Esto contendrá registros y archivos CSV. </li><li>  images / - Aquí hay un conjunto de datos para entrenar a nuestro modelo. </li><li>  formación / - Aquí guardamos el modelo entrenado. </li><li>  eval / - Esto almacenará los resultados de la evaluación del modelo. </li></ul><br><h2>  Paso 1: guardar imágenes en CSV </h2><br>  Aquí todo es bastante simple.  No profundizaremos en esta tarea, solo daré algunos enlaces útiles. <br><br>  Nuestra tarea es etiquetar la imagen y crear archivos train.CSV y test.CSV. <br><br><ul><li>  Con la herramienta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">labelImg,</a> marque la imagen.  Cómo hacer esto, mira <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> . </li><li>  Convierta XML a CSV, como se muestra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> . </li></ul><br>  Hay muchas formas de crear archivos CSV, más o menos adecuados para trabajar con cada conjunto de datos específico. <br><br>  Como parte de nuestro proyecto, intentaremos lograr la detección de ganglios pulmonares utilizando el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conjunto de datos LUNA</a> .  Las coordenadas de los nodos ya se conocían y, por lo tanto, la creación de archivos CSV no fue difícil.  Para encontrar los nodos, utilizamos las 6 coordenadas que se muestran a continuación: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a64/edd/019/a64edd0197a38edf75ee699e80e7f319.png"><br><br>  Debe corregir solo el nombre de los <code>nodules</code> clase (nodos), todo lo demás permanecerá sin cambios.  Una vez que los objetos marcados se presentan en forma de números, puede proceder a la creación de TFRecords. <br><br><h2>  Paso 2: crea TFRecords </h2><br>  La API de detección de objetos TensorFlow no acepta entradas para entrenar el modelo en formato CSV, por lo que debe crear TFRecords utilizando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este archivo.</a> <br><br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">""" Usage: # From tensorflow/models/ # Create train data: python generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=train.record # Create test data: python generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=test.record """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> division <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> print_function <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> object_detection.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> dataset_util <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> namedtuple, OrderedDict flags = tf.app.flags flags.DEFINE_string(<span class="hljs-string"><span class="hljs-string">'csv_input'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'Path to the CSV input'</span></span>) flags.DEFINE_string(<span class="hljs-string"><span class="hljs-string">'output_path'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'Path to output TFRecord'</span></span>) FLAGS = flags.FLAGS <span class="hljs-comment"><span class="hljs-comment"># TO-DO replace this with label map def class_text_to_int(row_label): if row_label == 'raccoon': return 1 else: None def split(df, group): data = namedtuple('data', ['filename', 'object']) gb = df.groupby(group) return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)] def create_tf_example(group, path): with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid: encoded_jpg = fid.read() encoded_jpg_io = io.BytesIO(encoded_jpg) image = Image.open(encoded_jpg_io) width, height = image.size filename = group.filename.encode('utf8') image_format = b'jpg' xmins = [] xmaxs = [] ymins = [] ymaxs = [] classes_text = [] classes = [] for index, row in group.object.iterrows(): xmins.append(row['xmin'] / width) xmaxs.append(row['xmax'] / width) ymins.append(row['ymin'] / height) ymaxs.append(row['ymax'] / height) classes_text.append(row['class'].encode('utf8')) classes.append(class_text_to_int(row['class'])) tf_example = tf.train.Example(features=tf.train.Features(feature={ 'image/height': dataset_util.int64_feature(height), 'image/width': dataset_util.int64_feature(width), 'image/filename': dataset_util.bytes_feature(filename), 'image/source_id': dataset_util.bytes_feature(filename), 'image/encoded': dataset_util.bytes_feature(encoded_jpg), 'image/format': dataset_util.bytes_feature(image_format), 'image/object/bbox/xmin': dataset_util.float_list_feature(xmins), 'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs), 'image/object/bbox/ymin': dataset_util.float_list_feature(ymins), 'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs), 'image/object/class/text': dataset_util.bytes_list_feature(classes_text), 'image/object/class/label': dataset_util.int64_list_feature(classes), })) return tf_example def main(_): writer = tf.python_io.TFRecordWriter(FLAGS.output_path) path = os.path.join(os.getcwd(), 'images') examples = pd.read_csv(FLAGS.csv_input) grouped = split(examples, 'filename') for group in grouped: tf_example = create_tf_example(group, path) writer.write(tf_example.SerializeToString()) writer.close() output_path = os.path.join(os.getcwd(), FLAGS.output_path) print('Successfully created the TFRecords: {}'.format(output_path)) if __name__ == '__main__': tf.app.run()</span></span></code> </pre> <br>  Después de descargar el archivo, realice un pequeño cambio: en la línea 31, en lugar de la palabra <code>raccoon</code> ponga su propia marca.  En el ejemplo dado, estos son <code>nodules</code> , nodos.  Si su modelo necesita definir varios tipos de objetos, cree clases adicionales. <br><br>  <i>Nota</i>  <i>La numeración de las etiquetas debe comenzar desde uno, no desde cero.</i>  <i>Por ejemplo, si usa tres tipos de objetos, se les debe asignar los valores 1, 2 y 3, respectivamente.</i> <br><br>  Use el siguiente código para crear el archivo <i>train.record</i> : <br><br><pre> <code class="python hljs">python generate_tfRecord.py --CSV_input=data/train.CSV --output_path=data/train.record</code> </pre> <br>  Use el siguiente código para crear el archivo <i>test.record</i> : <br><br><pre> <code class="python hljs">python generate_tfrecord.py — CSV_input=data/test.CSV — output_path=data/test.record</code> </pre> <br><h2>  Paso 3: entrenamiento modelo </h2><br>  Una vez que se crean los archivos que necesitamos, estamos casi listos para comenzar a aprender. <br><br><ol><li>  <a href="">Seleccione el modelo a</a> enseñar.  Debe encontrar un compromiso entre velocidad y precisión: cuanto mayor sea la velocidad, menor será la precisión de la determinación y viceversa.  Aquí, <code>sd_mobilenet_v1_coco</code> usa como ejemplo. </li><li>  Después de decidir con qué modelo trabajará, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">descargue el archivo de configuración apropiado</a> .  En este ejemplo, esto es <code>ssd_mobilenet_v1_coco.config</code> . </li><li>  Cree un archivo <i>object-detect.pbtxt</i> que tenga este aspecto: <br><br><pre> <code class="python hljs">item { id: <span class="hljs-number"><span class="hljs-number">1</span></span> name: <span class="hljs-string"><span class="hljs-string">'nodule'</span></span> }</code> </pre> <br>  Dale al <code>nodule</code> nombre diferente.  Si hay varias clases, aumente el valor de <code>id</code> e ingrese nuevos nombres. </li></ol><br>  Es hora de configurar el archivo de configuración, haciendo los siguientes ajustes. <br><br>  Cambie el número de clases de acuerdo a sus requerimientos. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#before num_classes: 90 #After num_classes: 1</span></span></code> </pre> <br>  Si la potencia de su GPU es insuficiente, baje el valor del <code>batch_size</code> del <code>batch_size</code> . <br><br><pre> <code class="python hljs">batch_size: <span class="hljs-number"><span class="hljs-number">24</span></span></code> </pre> <br>  Especifique la ruta al modelo <code>ssd_mobilenet_v1_coco</code> que hemos descargado anteriormente. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#before fine_tune_checkpoint: "PATH_TO_BE_CONFIGURED/model.ckpt" #after fine_tune_checkpoint: "ssd_mobilenet_v1_coco/model.ckpt"</span></span></code> </pre> <br>  Especifique la ruta al archivo <i>train.record</i> . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#before train_input_reader: { tf_record_input_reader { input_path: "PATH_TO_BE_CONFIGURED/mscoco_train.record" } label_map_path: "PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt" } #after train_input_reader: { tf_record_input_reader { input_path: "data/train.record" } label_map_path: "data/object-detection.pbtxt" }</span></span></code> </pre> <br>  Especifique la ruta al archivo <i>test.record.</i> <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#before eval_input_reader: { tf_record_input_reader { input_path: "PATH_TO_BE_CONFIGURED/mscoco_val.record" } label_map_path: "PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt" shuffle: false num_readers: 1} #after eval_input_reader: { tf_record_input_reader { input_path: "data/test.record" } label_map_path: "data/object-detection.pbtxt" shuffle: false num_readers: 1}</span></span></code> </pre> <br>  Ahora copie las carpetas de <i>datos /</i> e <i>imágenes / a las</i> carpetas de <i>modelos / investigación / detección de objetos</i> .  Si se le solicita que combine carpetas, acéptelo. <br><br>  Además, necesitaremos el archivo <i>train.py</i> ubicado en el <i>directorio de</i> <i>detección de objetos</i> / <i>.</i> <br><br><pre> <code class="python hljs">cd models/research/object-detection</code> </pre> <br>  Cree la carpeta de <i>entrenamiento /</i> en la carpeta / <i>detección de objetos</i> <i>.</i>  Está en <i>formación /</i> salvaremos nuestro modelo.  Copie <i>ssd_mobilenet_v1_coco.config</i> en el <i>archivo de</i> <i>entrenamiento /</i> configuración.  El entrenamiento se realiza usando el comando: <br><br><pre> <code class="python hljs">python train.py --logtostderr \ --train_dir=training/ \ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config</code> </pre> <br>  Si todo va según el plan, verá cómo cambia la función de pérdida en cada etapa. <br><br><h2>  Paso 4: Evaluación del modelo </h2><br>  Finalmente, evaluamos el modelo almacenado en el directorio <i>training /</i> .  Para hacer esto, ejecute el archivo <i>eval.py</i> e ingrese el siguiente comando: <br><br><pre> <code class="python hljs">python eval.py \ --logtostderr \ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config \ --checkpoint_dir=training/ \ --eval_dir=eval/</code> </pre> <br>  Los resultados de la verificación se reflejarán en la carpeta <i>eval /</i> .  Se pueden visualizar con TensorBoard. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#To visualize the eval results tensorboard --logdir=eval/ #TO visualize the training results tensorboard --logdir=training/</span></span></code> </pre> <br>  Abra el enlace a través de un navegador.  En la pestaña <i>Imágenes</i> , verá los resultados del modelo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d25/107/871/d25107871dfd23defc48ade0e0c61bd5.png"><br><br>  Eso es todo, ha configurado correctamente la API de detección de objetos TensorFlow. <br><br>  Uno de los errores más comunes: <br><br> <code>No module named deployment on object_detection/train.py</code> <br> <br>  Se resuelve usando el comando: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># From tensorflow/models/research/ export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim</span></span></code> </pre> <br>  Puede leer sobre las formas de cambiar los parámetros Faster-RCNN / SSD <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> . <br><br>  Gracias por su atencion! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es422353/">https://habr.com/ru/post/es422353/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es422337/index.html">Yandex lanzó una nube</a></li>
<li><a href="../es422339/index.html">"Creo que JavaScript no es adecuado para la web". 10 preguntas para el programador, 4 lanzamientos (desde Berlín)</a></li>
<li><a href="../es422341/index.html">IoT: promueve mientras otros piensan</a></li>
<li><a href="../es422345/index.html">Servidor en las nubes: resumen del proyecto</a></li>
<li><a href="../es422351/index.html">Ejecución remota de código cargando imágenes en su servidor o computadora local en ghostscript / imagick</a></li>
<li><a href="../es422357/index.html">Aprendizaje profundo para determinar el estilo y el género de las pinturas.</a></li>
<li><a href="../es422359/index.html">Los resultados de la búsqueda por la que pasaste. O no</a></li>
<li><a href="../es422361/index.html">Síndrome corporativo</a></li>
<li><a href="../es422363/index.html">Conferencia PyCon Rusia 2018: video de todos los informes y presentaciones</a></li>
<li><a href="../es422365/index.html">Yandex presentó una queja contra una decisión judicial de eliminar enlaces a contenido pirateado</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
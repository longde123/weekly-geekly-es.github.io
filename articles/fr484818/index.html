<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚Ü©Ô∏è üò£ üôåüèª Le livre "C ++. La pratique de la programmation multithread " üö∑ üßöüèø üë≤üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut, habrozhiteli! Le langage C ++ est choisi lorsque vous devez cr√©er des applications vraiment rapides comme l'√©clair. Et un traitement comp√©titif...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le livre "C ++. La pratique de la programmation multithread "</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/484818/"> <a href="https://habr.com/ru/company/piter/blog/484818/"><img src="https://habrastorage.org/webt/cr/ym/3u/crym3urkeecjcfe-nsvq0nrw59y.jpeg" align="left" alt="image"></a>  Salut, habrozhiteli!  Le langage C ++ est choisi lorsque vous devez cr√©er des applications vraiment rapides comme l'√©clair.  Et un traitement comp√©titif de haute qualit√© les rendra encore plus rapides.  Les nouvelles fonctionnalit√©s de C ++ 17 vous permettent d'utiliser toute la puissance de la programmation multithread pour r√©soudre facilement les probl√®mes de traitement graphique, d'apprentissage automatique, etc. Anthony Williams, un expert en traitement comp√©titif, examine des exemples et d√©crit des t√¢ches pratiques, et partage des secrets qui seront utiles √† tous dans y compris les d√©veloppeurs les plus exp√©riment√©s. <br><br>  Dans le livre ‚Ä¢ Un aper√ßu complet des fonctionnalit√©s de C ++ 17.  ‚Ä¢ Lancement et contr√¥le de flux.  ‚Ä¢ Synchronisation des op√©rations concurrentielles.  ‚Ä¢ D√©veloppement d'un code comp√©titif.  ‚Ä¢ D√©bogage d'applications multithread.  Le livre convient aux d√©veloppeurs de niveau interm√©diaire utilisant C et C ++.  Une exp√©rience en programmation comp√©titive n'est pas requise. <br><a name="habracut"></a><br><h3>  D√©veloppement de code comp√©titif </h3><br><h3>  8.1.  Fa√ßons de r√©partir le travail entre les threads </h3><br>  Imaginez que vous ayez besoin de construire une maison.  Pour ce faire, vous devrez creuser une fosse de fondation, remplir la fondation elle-m√™me, √©riger des murs, poser des tuyaux et du c√¢blage √©lectrique, etc. Th√©oriquement, avec des comp√©tences suffisantes, tout peut √™tre fait ind√©pendamment, mais cela prendra probablement beaucoup de temps et vous devrez passer d'un travail √† un autre.  Mais vous pouvez embaucher des assistants.  Ensuite, il faudra choisir le nombre d'assistants √† embaucher et d√©cider de ce qu'ils devraient √™tre en mesure de faire.  Vous pouvez, par exemple, embaucher deux ouvriers et travailler avec eux.  Ensuite, vous devez toujours passer d'une ≈ìuvre √† une autre, mais maintenant les choses iront plus vite, car il y aura plus d'artistes. <br><br>  Vous pouvez choisir une autre option - embaucher une √©quipe de sp√©cialistes, comme un ma√ßon, un charpentier, un √©lectricien et un plombier.  Chacun travaillera dans sa propre sp√©cialit√©, par cons√©quent, jusqu'√† ce que le plombier ait un front de travail, il restera inactif.  Et pourtant, les choses iront plus vite qu'avant, car il y a plus de travailleurs, et tandis que l'√©lectricien effectuera le c√¢blage dans la cuisine, le plombier peut aller aux toilettes.  Mais lorsqu'il n'y a pas de travail pour un sp√©cialiste sp√©cifique, plus de temps d'arr√™t sont obtenus.  Cependant, on peut noter que m√™me avec les temps d'arr√™t pris en compte, le travail se d√©place plus rapidement lorsque des sp√©cialistes viennent au travail, plut√¥t qu'une √©quipe de travailleurs.  Les sp√©cialistes n'ont pas besoin de changer constamment d'outils et chacun d'entre eux accomplira sa t√¢che plus rapidement que l'ouvrier.  Que ce soit effectivement le cas, cela d√©pend des circonstances sp√©cifiques: tout est appris dans la pratique. <br><br>  M√™me si vous impliquez des sp√©cialistes, vous devez toujours choisir un nombre diff√©rent de travailleurs de diff√©rentes sp√©cialit√©s.  Il est peut-√™tre judicieux d'embaucher, par exemple, plus de ma√ßons que d'√©lectriciens.  De plus, la composition de votre √©quipe et l'efficacit√© globale de son travail peuvent changer si vous devez construire plusieurs maisons √† la fois.  M√™me s'il y a peu de travail pour un plombier dans une seule maison, alors lors de la construction de plusieurs maisons √† la fois, il peut √™tre pris pour toute la journ√©e.  De plus, si vous n'avez pas √† payer de sp√©cialistes pour les temps d'arr√™t, vous pouvez recruter une √©quipe plus importante, m√™me si le nombre de personnes travaillant simultan√©ment ne change pas. <br><br>  Mais arr√™tez de parler de la construction.  Qu'est-ce que tout cela a √† voir avec les threads?  Et vous pouvez leur appliquer des consid√©rations similaires.  Vous devez d√©cider du nombre de threads √† utiliser et des t√¢ches √† effectuer.  Avons-nous besoin de fils universels qui effectuent le travail n√©cessaire √† un moment particulier, ou de fils sp√©cialis√©s bien adapt√©s √† une seule chose?  Ou peut-√™tre vaut-il la peine de combiner les deux?  Ces d√©cisions doivent √™tre prises quelles que soient les raisons de la parall√©lisation du programme, et les performances et la clart√© du code d√©pendent consid√©rablement de leur succ√®s.  Par cons√©quent, il est si important d'imaginer quelles options sont disponibles afin de prendre une d√©cision comp√©tente lors du d√©veloppement de la structure de l'application.  Dans cette section, nous consid√©rerons un certain nombre de m√©thodes de distribution des t√¢ches, en commen√ßant par la distribution des donn√©es entre les threads jusqu'√† ce que tout autre travail soit effectu√©. <br><br><h3>  8.1.1.  R√©partition des donn√©es entre les threads avant traitement </h3><br>  Les plus faciles √† parall√©liser sont des algorithmes simples, tels que std :: for_each, qui effectuent des op√©rations sur chaque √©l√©ment d'un ensemble de donn√©es.  Pour parall√©liser cet algorithme, vous pouvez affecter chaque √©l√©ment √† l'un des threads de traitement.  √Ä l'avenir, lors de l'examen des probl√®mes de performances, il deviendra clair que la meilleure option de distribution pour obtenir des performances optimales d√©pend des caract√©ristiques de la structure des donn√©es. <br><br>  Lors de la distribution de donn√©es, le cas le plus simple est celui o√π les N premiers √©l√©ments sont affect√©s √† un flux, les N √©l√©ments suivants √† un autre, et ainsi de suite (Fig. 8.1), mais d'autres sch√©mas peuvent √™tre utilis√©s.  Quelle que soit la m√©thode de distribution des donn√©es, chaque thread ne traite que les √©l√©ments qui lui sont attribu√©s, sans interagir avec les autres threads jusqu'√† la fin du traitement. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ie/ex/rm/ieexrmf49u6qerfqmuhtcgpbgpe.png" alt="image"></div><br>  La structure doit √™tre famili√®re √† toute personne ayant <a href="http://www.mpi-forum.org/">travaill√©</a> avec la programmation dans les environnements Message Passing Interface (MPI, <a href="http://www.mpi-forum.org/">www.mpi-forum.org</a> ) ou OpenMP (http://www.openmp.org/): la t√¢che est divis√©e en plusieurs t√¢ches ex√©cut√©es en parall√®le, les workflows les ex√©cutent ind√©pendamment les uns des autres et les r√©sultats sont collect√©s au stade final de l'information.  Cette approche a √©t√© utilis√©e dans l'exemple avec la fonction d'accumulation de la section 2.4: les t√¢ches parall√®les et l'√©tape de r√©duction sont une accumulation.  Pour un algorithme for_each simple, l'√©tape finale est manquante, car il n'y a rien √† r√©duire. <br><br>  Le fait qu'un mix soit d√©fini comme l'essence de l'√©tape finale joue un r√¥le tr√®s important: une impl√©mentation √©l√©mentaire similaire √† celle montr√©e dans l'extrait 2.9 effectuera ce mix comme une √©tape s√©quentielle finale.  Mais souvent, cette √©tape est √©galement parall√©lis√©e: l'accumulation est une op√©ration de r√©duction, de sorte que le code du Listing 2.9 peut √™tre modifi√© pour obtenir un appel r√©cursif du m√™me code lorsque, par exemple, le nombre de threads est sup√©rieur au nombre minimal d'√©l√©ments trait√©s par le thread.  Vous pouvez √©galement forcer les workflows √† effectuer des √©tapes de cumul d√®s que chacun d'eux a termin√© sa t√¢che, plut√¥t que de d√©marrer de nouveaux threads √† chaque fois. <br><br>  Malgr√© toute son efficacit√©, cette technique n'est pas polyvalente.  Parfois, les donn√©es ne peuvent pas √™tre divis√©es √† l'avance avec pr√©cision, car la composition de chaque pi√®ce n'est connue qu'au cours du traitement.  En particulier, cela est √©vident lorsque vous utilisez des algorithmes r√©cursifs tels que Quicksort, ils n√©cessitent donc une approche diff√©rente. <br><br><h3>  8.1.2.  Distribution de donn√©es r√©cursive </h3><br>  L'algorithme Quicksort comporte deux √©tapes principales: la division des donn√©es en deux parties - tout ce qui revient √† l'un des √©l√©ments (r√©f√©rence), et tout ce qui se trouve apr√®s dans l'ordre de tri final, et le tri r√©cursif de ces deux moiti√©s.  Il est impossible de le parall√©liser en divisant au pr√©alable les donn√©es, car il est possible de d√©terminer dans quelle ¬´moiti√©¬ª elles tombent uniquement lors du traitement des √©l√©ments.  Si vous avez l'intention de parall√©liser cet algorithme, vous devez utiliser l'essence m√™me de la r√©cursivit√©.  √Ä chaque niveau de r√©cursivit√©, de plus en plus d'appels √† la fonction quick_sort sont effectu√©s, car vous devez trier ceux qui sont plus grands que la r√©f√©rence et ceux qui sont plus petits que lui.  Ces appels r√©cursifs sont ind√©pendants les uns des autres car ils font r√©f√©rence √† des ensembles d'√©l√©ments distincts.  De ce fait, ils sont les premiers candidats √† la comp√©titivit√©.  Cette distribution r√©cursive est repr√©sent√©e sur la Fig.  8.2. <br><br>  Cette impl√©mentation a d√©j√† √©t√© rencontr√©e au chapitre 4. Au lieu de faire deux appels r√©cursifs pour les moiti√©s plus grandes et plus petites, nous avons utilis√© la fonction std :: async (), qui ex√©cute des t√¢ches asynchrones pour la moiti√© la plus petite √† chaque √©tape.  En raison de l'utilisation de std :: async (), la biblioth√®que de threads C ++ a d√ª d√©cider quand d√©marrer la t√¢che dans un nouveau thread et quand - en mode synchrone. <br><br>  Il existe une circonstance importante: lors du tri d'un grand ensemble de donn√©es, le d√©marrage d'un nouveau thread pour chaque r√©cursivit√© entra√Ænera une augmentation rapide du nombre de threads.  Lors de l'examen des probl√®mes de performances, il sera d√©montr√© qu'un trop grand nombre de threads peuvent ralentir l'application.  En outre, avec un grand nombre de flux de donn√©es, cela peut tout simplement ne pas suffire.  L'id√©e m√™me de diviser la t√¢che enti√®re dans un tel mode r√©cursif semble tr√®s r√©ussie, il vous suffit de surveiller attentivement le nombre de threads.  Dans les cas simples, la fonction std :: async () g√®re cela, mais il existe d'autres options. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/ji/l3/rzjil3fye0-nfj2quxo75cvxon4.png" alt="image"></div><br>  L'un d'eux consiste √† utiliser la fonction std :: thread :: hardware_concurrency () pour s√©lectionner le nombre de threads, comme cela a √©t√© fait dans la version parall√®le de la fonction accumulate () du Listing 2.9.  Ensuite, au lieu de d√©marrer un nouveau thread pour chaque appel r√©cursif, vous pouvez placer le fragment √† trier sur une pile adapt√©e aux threads, par exemple, comme indiqu√© dans les chapitres 6 et 7. Si le thread n'a rien √† faire ou s'il a fini de traiter tous ses fragments ou attend que le fragment soit tri√©, il peut prenez un fragment de la pile et triez-le. <br><br>  Le listing 8.1 montre une impl√©mentation simple de cette technologie.  Comme dans la plupart des autres exemples, il ne fait que d√©montrer l'intention et n'est pas un code pr√™t pour une utilisation pratique.  Si vous utilisez le compilateur C ++ 17 et que votre biblioth√®que le prend en charge, vous devez utiliser les algorithmes parall√®les fournis par la biblioth√®que standard conform√©ment aux descriptions donn√©es au chapitre 10. <br><br>  Listing 8.1.  Un algorithme Quicksort parall√®le qui utilise une pile de fragments en attente de tri <br><br><img src="https://habrastorage.org/webt/ko/nb/h6/konbh6b_q40lp0uz-gxyunwws3g.png" alt="image"><br><img src="https://habrastorage.org/webt/5s/md/52/5smd5279wgwzktq4thil54lidqy.png" alt="image"><br><img src="https://habrastorage.org/webt/ro/js/kt/rojsktncuxgmls2wtndzt9ywhqy.png" alt="image"><br><br>  Ici, la fonction parallel_quick_sort <b>(19)</b> place la majeure partie des responsabilit√©s fonctionnelles sur la classe sorter <b>(1)</b> , qui fournit un moyen facile de regrouper la pile de fragments non tri√©s <b>(2)</b> et de plusieurs threads <b>(3)</b> .  Le travail principal est effectu√© dans la fonction du composant do_sort <b>(9)</b> , qui est occup√©e par le partitionnement de donn√©es habituel <b>(10)</b> .  Cette fois, au lieu de d√©marrer un nouveau thread pour chaque fragment, il pousse ce fragment sur la pile (11) et ne d√©marre un nouveau thread que s'il existe une ressource processeur libre (12).  Puisqu'un fragment avec des valeurs inf√©rieures √† celle de la r√©f√©rence peut √™tre trait√© par un autre flux, nous devons attendre sa disponibilit√© <b>(13)</b> .  Afin que le temps ne soit pas perdu (dans le cas o√π nous avons un seul thread ou que tous les autres threads sont d√©j√† occup√©s), une tentative est faite pour traiter les fragments de la pile pendant cette p√©riode d'attente <b>(14)</b> .  La fonction try_sort_chunk r√©cup√®re un fragment de la pile <b>(7)</b> , le trie <b>(8)</b> et enregistre les r√©sultats dans la promesse de promesse afin qu'ils puissent recevoir le flux qui a mis ce fragment sur la pile <b>(15)</b> . <br><br>  Maintenant, les threads qui viennent d'√™tre lanc√©s sont en boucle et essaient de trier les fragments de la pile <b>(17)</b> si l'indicateur end_of_data <b>(16)</b> n'est pas d√©fini.  Entre les v√©rifications, ils abandonnent la ressource informatique √† d'autres threads afin de pouvoir pousser du travail suppl√©mentaire sur la pile.  Le travail du code en termes de mise en ordre de ces threads d√©pend du destructeur de votre classe sorter <b>(4)</b> .  Lorsque toutes les donn√©es sont tri√©es, la fonction do_sort renverra le contr√¥le (m√™me en maintenant l'activit√© des threads de travail), le thread principal reviendra de parallel_quick_sort <b>(20)</b> et d√©truira l'objet trieur.  Il d√©finira l'indicateur end_of_data <b>(5)</b> et attendra que les threads finissent de fonctionner <b>(6). La</b> d√©finition de l'indicateur arr√™tera la boucle dans la fonction des threads (16). <br><br>  Avec cette approche, le probl√®me du nombre illimit√© de threads inh√©rent √† la fonction spawn_task qui a lanc√© le nouveau thread dispara√Ætra et la d√©pendance √† la biblioth√®que de threads C ++, qui s√©lectionnera le nombre de threads pour vous, comme lors de l'utilisation de std :: async (), dispara√Ætra.  Au lieu de cela, pour √©viter un changement de t√¢che trop fr√©quent, le nombre de threads est limit√© par la valeur renvoy√©e par la fonction std :: thread :: hardware_concurrency ().  Mais un autre probl√®me se pose: la gestion de ces flux et l'√©change de donn√©es entre eux compliquent grandement le code.  De plus, malgr√© le fait que les threads traitent des √©l√©ments de donn√©es individuels, tous acc√®dent √† la pile, y ajoutant de nouveaux fragments et prenant des fragments pour traitement.  Une concurrence aussi intense peut r√©duire les performances, m√™me si une pile sans verrouillage (et donc non bloquante) est utilis√©e, et les raisons de cela seront bient√¥t examin√©es. <br><br>  Cette approche est une version sp√©ciale du pool de threads - un ensemble de threads, chacun recevant le travail de la liste des travaux diff√©r√©s, l'ex√©cute, puis se tourne vers la liste pour un nouveau.  Certains probl√®mes potentiels inh√©rents au pool de threads (y compris la concurrence lors de l'acc√®s √† la liste des travaux) et les moyens de les r√©soudre sont abord√©s dans le chapitre 9. Sur la mise √† l'√©chelle de l'application cr√©√©e afin qu'elle s'ex√©cute sur plusieurs processeurs, nous aborderons ce chapitre un peu plus tard (voir sous-section 8.2.1). <br><br>  Lors de la distribution des donn√©es avant le traitement et en mode r√©cursif, il est suppos√© qu'elles sont fix√©es √† l'avance et une recherche est en cours pour leur distribution.  Mais cela ne se produit pas toujours: si les donn√©es sont cr√©√©es en mode dynamique ou proviennent d'une source externe, cette approche ne fonctionne pas.  Dans ce cas, il peut √™tre plus raisonnable de r√©partir le travail en fonction du type de t√¢che et non en fonction des donn√©es elles-m√™mes. <br><br><h3>  8.1.3.  R√©partition du travail par type de t√¢che </h3><br>  La r√©partition du travail entre les threads en attribuant √† chacun d'entre eux (√† l'avance ou de mani√®re r√©cursive pendant le traitement des donn√©es) diff√©rentes donn√©es dans tous les cas est bas√©e sur l'hypoth√®se que les threads vont faire le m√™me travail sur chaque pi√®ce.  Une autre distribution du travail est la sp√©cialisation des flux, o√π chacun effectue une t√¢che distincte, car les plombiers et les √©lectriciens effectuent diff√©rentes t√¢ches dans la construction d'une maison.  Les flux peuvent fonctionner avec des donn√©es diff√©rentes ou identiques, mais dans ce dernier cas, ils le font √† des fins diff√©rentes. <br><br>  Cette division particuli√®re du travail r√©sulte de la s√©paration des t√¢ches √† l'aide de la concurrence: chaque fil a une t√¢che distincte, qu'il effectue ind√©pendamment des autres flux.  Parfois, d'autres threads peuvent fournir des donn√©es au flux ou produire des √©v√©nements auxquels il doit r√©pondre, mais en g√©n√©ral, chaque flux se concentre sur les performances de haute qualit√© d'une seule t√¢che.  C'est une bonne conception de base, o√π chaque morceau de code doit √™tre responsable d'une chose. <br><br><h3>  R√©partition du travail par type de t√¢che afin de partager les responsabilit√©s </h3><br>  Une application monothread doit faire face √† des conflits li√©s au principe de responsabilit√© unique, lorsque plusieurs t√¢ches doivent √™tre ex√©cut√©es en continu pendant un certain temps, ou que l'application doit faire face au traitement des √©v√©nements entrants en temps opportun (par exemple, un utilisateur appuie sur une touche ou des donn√©es arrivent sur le r√©seau) en pr√©sence d'autres t√¢ches inachev√©es.  Dans un environnement informatique √† thread unique, vous devez cr√©er ind√©pendamment du code qui ex√©cute une partie de la t√¢che A, une partie de la t√¢che B, v√©rifie si une touche est enfonc√©e et s'il n'y a pas de paquets r√©seau, puis revient cycliquement √† la partie suivante de la t√¢che A. t√¢ches A en raison de la n√©cessit√© de maintenir son √©tat et de rendre p√©riodiquement le contr√¥le √† la boucle principale.  Si vous ajoutez trop de t√¢ches au cycle, le travail peut ralentir consid√©rablement et l'utilisateur remarquera probablement une r√©action lente aux frappes.  Je suis s√ªr que tout le monde a observ√© les manifestations extr√™mes d'une situation similaire dans certaines applications: vous d√©finissez une t√¢che pour l'application, et l'interface ne r√©agit √† rien tant qu'elle n'est pas termin√©e. <br><br>  Ici, les flux entrent en sc√®ne.  Si vous ex√©cutez chaque t√¢che dans un thread distinct, le syst√®me d'exploitation peut le faire √† votre place.  Dans le code de la t√¢che A, vous pouvez vous concentrer sur l'ach√®vement de la t√¢che sans vous soucier du maintien de l'√©tat et du retour √† la boucle principale, ni du temps qui s'√©coulera avant que cela ne se produise.  Autrement dit, le syst√®me d'exploitation enregistrera automatiquement l'√©tat et passera au bon moment √† la t√¢che B ou C, et si le syst√®me sur lequel le programme sera ex√©cut√© a plusieurs c≈ìurs ou processeurs, il sera possible d'ex√©cuter simultan√©ment les t√¢ches A et B. Le code de traitement des frappes ou des re√ßus les paquets r√©seau peuvent maintenant √™tre ex√©cut√©s en temps opportun, et tout le monde en b√©n√©ficiera: l'utilisateur recevra une r√©ponse ad√©quate du programme et vous, en tant que d√©veloppeur, recevrez un code simplifi√©, car chaque flux peut √™tre dirig√©  effectuer des op√©rations directement li√©es √† ses fonctions, sans les m√©langer avec le flux de contr√¥le et l'interaction avec l'utilisateur. <br><br>  Une image id√©ale se dessine.  Mais tout peut-il se passer de cette fa√ßon?  Comme toujours, tout d√©pend des circonstances sp√©cifiques.  Si l'ind√©pendance totale est respect√©e et que les flux n'ont pas besoin d'√©changer des donn√©es entre eux, c'est exactement ce qui se passera.  Malheureusement, une situation similaire est observ√©e assez rarement.  Souvent, les actions n√©cessaires √† l'utilisateur ont la forme de t√¢ches d'arri√®re-plan pratiques, et elles doivent informer l'utilisateur de la t√¢che, mettant √† jour l'interface utilisateur d'une mani√®re ou d'une autre.  Ou l'utilisateur peut avoir besoin d'arr√™ter la t√¢che, donc l'interface utilisateur devra en quelque sorte envoyer un message √† la t√¢che en arri√®re-plan, ce qui provoquera l'arr√™t de son ex√©cution.  Dans les deux cas, il est n√©cessaire de consid√©rer soigneusement la conception et la synchronisation appropri√©e, mais les t√¢ches effectu√©es resteront fragment√©es.  Le thread d'interface utilisateur contr√¥le toujours cette interface, mais il peut √™tre affect√© √† l'ex√©cution d'une mise √† jour √† la demande d'autres threads.  Un thread qui impl√©mente une t√¢che en arri√®re-plan se concentre toujours sur les op√©rations requises pour la terminer; il arrive √©galement que l'un des threads en arri√®re-plan permette √† la t√¢che d'arr√™ter l'autre thread.  Dans les deux cas, les flux ne se soucient pas de l'origine de la demande, ils se soucient uniquement du fait qu'elle soit con√ßue pour eux et directement li√©e √† leurs responsabilit√©s. <br><br>  Le partage des responsabilit√©s entre plusieurs threads pr√©sente deux dangers graves.  Premi√®rement, il peut s‚Äôav√©rer que des responsabilit√©s inappropri√©es sont r√©parties.  Un signe de cela est trop de donn√©es partag√©es par les flux, ou le fait que diff√©rents flux doivent s‚Äôattendre les uns les autres.          .      .        , , ,    ,             .   ,        ,     ‚Äî   , ,        . <br><br>                .             ,     ,         . <br><br><h3>      </h3><br>                 ,            .      : ,     ,         . <br><br>            ‚Äî        .   ,     ,      .   ,     ,       ,           . <br><br>      ,    8.1.1,   ,           . ,                  . <br><br>     ,        :    ,       . ,        20          ,      3 .      ,         .  ,   ,    ,  ,   12       ,  24  ‚Äî   . .  20     .      .         .       , ,  ,   ,   12 . ,   12       ,        .      ,  :  ,   ,     ,  ,       ,        .      3         12 . <br><br>      ,    9 ,         .            . ,  ,      .          25   ,    ‚Äî  .  ,       ,    : ,   100   ,  ,    1 ,    100 ,    1     100 .     ,  ,        .       ,     ,  , . <br><br>       ,    ,     ,   ,      . <br><br><h3> 8.2. ,      </h3><br>            ,  ,      .        ,  ,     .     ,       16      ,     . <br><br>    ,        ‚Äî   ,    ,    (      ),      .          ,    :      ? <br><br><h3> 8.2.1.     ? </h3><br>  ( )     ,          .   ,    ,        ,          .     ,     .      ,     . ,         ,         (   )       .     ,   ,      ,            . <br><br>     16-       16  :          16 .    ,        16 .   ,    ,         (   ).    ,    16    ,      ,           ,      1.       (oversubscription). <br><br>          ,       ,    C++11 (Standard Thread Library)   std::thread::hardware_concurrency().             . <br><br>   std::thread::hardware_concurrency()    :       -  ,   ,        .   ,        ,  std::thread::hardware_concurrency(),     .  std::async()    ,           .           . <br><br>      ,    ,    ,      .              ‚Äî   ,   ,     . ,     ,   ,       ,          C++.   ,     std::async(),       ,   ,    .       ,     .   ,      ,      std::thread::hardware_concurrency(),     .      ,      ,  ,    . <br><br>       ,                 .          ,     ,      ,    ,        . <br><br>         ,        ‚Äî          . <br><br>  ¬ªPlus d'informations sur le livre sont disponibles sur <a href="https://www.piter.com/collection/new/product/c-praktika-mnogopotochnogo-programmirovaniya%3F_gs_cttl%3D120%255E_%255Eamp%255E_%255Egs_direct_link%3D1%255E_%255Eamp%255E_%255Egsaid%3D82744%255E_%255Eamp%255E_%255Egsmid%3D29789%255E_%255Eamp%255E_%255Egstid%3Dc">le site Web de l'√©diteur</a> <br>  ¬ª <a href="https://storage.piter.com/upload/contents/978544610831/978544610831_X.pdf">Contenu</a> <br>  ¬ª <a href="https://storage.piter.com/upload/contents/978544610831/978544610831_p.pdf">Extrait</a> <br><br>    25%   ‚Äî <b>C++</b> <br><br>  Lors du paiement de la version papier du livre, un livre √©lectronique est envoy√© par e-mail. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr484818/">https://habr.com/ru/post/fr484818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr484804/index.html">Que chiffrer dans un syst√®me d'entreprise? Et pourquoi faire √ßa?</a></li>
<li><a href="../fr484806/index.html">Diff√©rence entre cPanel et Plesk Obsidian</a></li>
<li><a href="../fr484812/index.html">Mon exp√©rience avec Plesk</a></li>
<li><a href="../fr484814/index.html">6. Mise en route de Fortinet v6.0. Filtrage Web et contr√¥le des applications</a></li>
<li><a href="../fr484816/index.html">Utilisation de hooks d'op√©rations pour sauvegarder des fichiers sur macOS √† la vol√©e</a></li>
<li><a href="../fr484820/index.html">FAQ.Net - un programme de prise de notes gratuit pour Windows avec une conception mise √† jour</a></li>
<li><a href="../fr484822/index.html">Blazor: comment emp√™cher un composant de tomber malade ou deux approches pour s√©parer le code du balisage</a></li>
<li><a href="../fr484824/index.html">La guerre pour √©teindre les lumi√®res</a></li>
<li><a href="../fr484826/index.html">L'intelligence artificielle aggrave encore plus la mauvaise m√©decine</a></li>
<li><a href="../fr484834/index.html">Comment construire une strat√©gie d'entreprise pour la formation et le d√©veloppement</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüè≠ ‚ûó üëàüèº API funcional Keras no TensorFlow ‚ô•Ô∏è üíä ü§í</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Keras possui duas APIs para criar rapidamente arquiteturas de rede neural Sequencial e Funcional. Se o primeiro permitir construir apenas arquiteturas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>API funcional Keras no TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483664/"><img src="https://habrastorage.org/webt/w1/zr/n8/w1zrn8ydafoxahso_ig7vx1stfg.png"><br><br>  Keras possui duas APIs para criar rapidamente arquiteturas de rede neural Sequencial e Funcional.  Se o primeiro permitir construir apenas arquiteturas seq√ºenciais de redes neurais, usando a API Funcional, voc√™ poder√° definir uma rede neural na forma de um gr√°fico ac√≠clico direcionado arbitr√°rio, o que oferece muito mais oportunidades para a constru√ß√£o de modelos complexos.  Este artigo √© uma tradu√ß√£o do Functional API Feature Guide do site TensorFlow. <br><a name="habracut"></a><br><h2>  1. Introdu√ß√£o </h2><br>  A API Funcional permite criar modelos de forma mais flex√≠vel que a API Sequencial; ela pode processar modelos com topologia n√£o linear, modelos com camadas comuns e modelos com v√°rias entradas ou sa√≠das. <br><br>  √â baseado no fato de que o modelo de aprendizado profundo √© geralmente um gr√°fico ac√≠clico direcionado (DAG) de camadas <br><br>  API funcional √© um conjunto de ferramentas para <b>plotagem de camadas</b> . <br><br>  Considere o seguinte modelo: <br><br><blockquote>  (entrada: vetor 784-dimensional) <br>  ‚Üß <br>  [Camada densa (64 elementos, ativa√ß√£o de relu)] <br>  ‚Üß <br>  [Camada densa (64 elementos, ativa√ß√£o de relu)] <br>  ‚Üß <br>  [Camada densa (10 elementos, ativa√ß√£o do softmax)] <br>  ‚Üß <br>  (sa√≠da: distribui√ß√£o de probabilidade acima de 10 classes) </blockquote>  Este √© um gr√°fico simples de 3 camadas. <br><br>  Para construir esse modelo usando a API Funcional, voc√™ precisa come√ßar criando um n√≥ de entrada: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,))</code> </pre> <br>  Aqui, simplesmente indicamos a dimens√£o dos nossos dados: vetores 784 dimensionais.  Observe que a quantidade de dados √© sempre omitida; indicamos apenas a dimens√£o de cada elemento.  Para inserir o tamanho pretendido para as imagens `(32, 32, 3)`, usar√≠amos: <br><br><pre> <code class="python hljs">img_inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>))</code> </pre> <br>  Quais <code>inputs</code> retornam cont√©m informa√ß√µes sobre o tamanho e o tipo de dados que voc√™ planeja transferir para o seu modelo: <br><br><pre> <code class="python hljs">inputs.shape</code> </pre> <br><pre> <code class="python hljs">TensorShape([<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>])</code> </pre> <br><pre> <code class="python hljs">inputs.dtype</code> </pre> <br><pre> <code class="python hljs">tf.float32</code> </pre> <br>  Voc√™ cria um novo n√≥ no gr√°fico de camadas chamando a camada neste objeto de <code>inputs</code> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers dense = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) x = dense(inputs)</code> </pre> <br>  "Chamar uma camada" √© semelhante a desenhar uma seta da "entrada" para a camada que criamos.  Passamos a entrada para a camada <code>dense</code> e obtemos <code>x</code> . <br><br>  Vamos adicionar mais algumas camadas ao nosso gr√°fico de camadas: <br><br><pre> <code class="python hljs">x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x)</code> </pre> <br>  Agora podemos criar um <code>Model</code> especificando suas entradas e sa√≠das no gr√°fico de camadas: <br><br><pre> <code class="python hljs">model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br>  Vejamos novamente o processo completo de defini√ß√£o de modelo: <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs=inputs, outputs=outputs, name=<span class="hljs-string"><span class="hljs-string">'mnist_model'</span></span>)</code> </pre> <br>  Vamos ver como √© o resumo do modelo: <br><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><pre> <code class="python hljs">Model: <span class="hljs-string"><span class="hljs-string">"mnist_model"</span></span> _________________________________________________________________ Layer (type) Output Shape Param <span class="hljs-comment"><span class="hljs-comment"># ================================================================= img (InputLayer) [(None, 784)] 0 _________________________________________________________________ dense_3 (Dense) (None, 64) 50240 _________________________________________________________________ dense_4 (Dense) (None, 64) 4160 _________________________________________________________________ dense_5 (Dense) (None, 10) 650 ================================================================= Total params: 55,050 Trainable params: 55,050 Non-trainable params: 0 _________________________________________________________________</span></span></code> </pre> <br>  Tamb√©m podemos desenhar o modelo como um gr√°fico: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model.png'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/oq/4o/vl/oq4ovlxewr3hxczaldchmbeyfua.png" alt="imagem"><br><br>  E, opcionalmente, derivar as dimens√µes da entrada e sa√≠da de cada camada no gr√°fico constru√≠do: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model_with_shape_info.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fn/rm/hc/fnrmhcqknnsjdcgmqp9w6dpong8.png" alt="imagem"><br><br>  Esta imagem e o c√≥digo que escrevemos s√£o id√™nticos.  Na vers√£o do c√≥digo, as setas de liga√ß√£o s√£o simplesmente substitu√≠das por opera√ß√µes de chamada. <br><br>  O "gr√°fico de camadas" √© uma imagem mental muito intuitiva para o modelo de aprendizado profundo, e a API Funcional √© uma maneira de criar modelos que refletem de perto essa imagem mental. <br><br><h2>  Treinamento, avalia√ß√£o e conclus√£o </h2><br>  Aprender, avaliar e derivar trabalhos para modelos criados usando a API Funcional, como nos modelos Sequenciais. <br><br>  Considere uma demonstra√ß√£o r√°pida. <br><br>  Aqui, carregamos o conjunto de dados de imagem MNIST, convertemos em vetores, treinamos o modelo nos dados (enquanto monitoramos a qualidade do trabalho na amostra de teste) e, finalmente, avaliamos nosso modelo nos dados de teste: <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = x_train.reshape(<span class="hljs-number"><span class="hljs-number">60000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> x_test = x_test.reshape(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> model.compile(loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, optimizer=keras.optimizers.RMSprop(), metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) history = model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) test_scores = model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Test loss:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(<span class="hljs-string"><span class="hljs-string">'Test accuracy:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h2>  Salvando e serializando </h2><br>  Salvar e serializar modelos criados com a API Funcional funciona exatamente da mesma forma que nos modelos Sequenciais. <br><br>  A maneira padr√£o de salvar um modelo Funcional √© chamar <code>model.save(</code> ), que permite salvar o modelo inteiro em um arquivo. <br><br>  Posteriormente, voc√™ pode restaurar o mesmo modelo nesse arquivo, mesmo que n√£o tenha mais acesso ao c√≥digo que criou o modelo. <br><br>  Este arquivo inclui: <br><br><ul><li>  Arquitetura de modelo </li><li>  Pesos do modelo (que foram obtidos durante o treinamento) </li><li>  Configura√ß√£o de treinamento do modelo (o que voc√™ passou na <code>compile</code> ) </li><li>  O otimizador e sua condi√ß√£o, se fosse (isso permite que voc√™ retome o treinamento de onde parou) </li></ul><br><pre> <code class="python hljs">model.save(<span class="hljs-string"><span class="hljs-string">'path_to_my_model.h5'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> model <span class="hljs-comment"><span class="hljs-comment"># Recreate the exact same model purely from the file: model = keras.models.load_model('path_to_my_model.h5')</span></span></code> </pre><br><h2>  Usando o mesmo gr√°fico de camada para definir v√°rios modelos </h2><br>  Na API Funcional, os modelos s√£o criados especificando dados de entrada e sa√≠da em um gr√°fico de camadas.  Isso significa que um gr√°fico de camada √∫nica pode ser usado para gerar v√°rios modelos. <br><br>  No exemplo abaixo, usamos a mesma pilha de camadas para criar dois modelos: <br>  um modelo de <code> (encoder)</code> que converte imagens de entrada em vetores de 16 dimens√µes e um modelo de <code> (autoencoder)</code> ponta a <code> (autoencoder)</code> para treinamento. <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(encoder_output) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) autoencoder = keras.Model(encoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre><br>  Observe que tornamos a arquitetura de decodifica√ß√£o estritamente sim√©trica √† arquitetura de codifica√ß√£o, para que a dimens√£o dos dados de sa√≠da seja igual √† dos dados de entrada <code>(28, 28, 1)</code> .  A camada <code>Conv2D</code> √© <code>Conv2D</code> para a camada <code>Conv2D</code> e a camada <code>MaxPooling2D</code> ser√° a volta para a camada <code>MaxPooling2D</code> . <br><br><h2>  Os modelos podem ser chamados como camadas </h2><br>  Voc√™ pode usar qualquer modelo como se fosse uma camada, chamando-o de <code>Input</code> ou de sa√≠da de outra camada. <br><br>  Observe que, ao invocar um modelo, voc√™ n√£o apenas reutiliza sua arquitetura, mas tamb√©m seus pesos.  Vamos v√™-lo em a√ß√£o.  Aqui est√° outra olhada em um exemplo de codificador autom√°tico quando um modelo de codificador, um modelo de decodificador √© criado e eles s√£o conectados em duas chamadas para obter um modelo de codificador autom√°tico: <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'original_img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() decoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">16</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'encoded_img'</span></span>) x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(decoder_input) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder = keras.Model(decoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'decoder'</span></span>) decoder.summary() autoencoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) encoded_img = encoder(autoencoder_input) decoded_img = decoder(encoded_img) autoencoder = keras.Model(autoencoder_input, decoded_img, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre> <br>  Como voc√™ v√™, um modelo pode ser aninhado: um modelo pode conter um submodelo (j√° que o modelo pode ser considerado como uma camada). <br><br>  Um caso de uso comum para aninhar modelos √© o <i>conjunto</i> . <br><br>  Como exemplo, veja como combinar um conjunto de modelos em um modelo que calcula a m√©dia de suas previs√µes: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> keras.Model(inputs, outputs) model1 = get_model() model2 = get_model() model3 = get_model() inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) y1 = model1(inputs) y2 = model2(inputs) y3 = model3(inputs) outputs = layers.average([y1, y2, y3]) ensemble_model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br><br><h2>  Manipulando topologias complexas de gr√°ficos </h2><br><h3>  Modelos com v√°rias entradas e sa√≠das </h3><br>  A API funcional simplifica a manipula√ß√£o de v√°rias entradas e sa√≠das.  Isso n√£o pode ser feito com a API sequencial. <br><br>  Aqui est√° um exemplo simples. <br><br>  Suponha que voc√™ esteja criando um sistema para classificar os aplicativos dos clientes por prioridade e envi√°-los para o departamento certo. <br><br>  Seu modelo ter√° 3 entradas: <br><br><ul><li>  Cabe√ßalho do aplicativo (entrada de texto) </li><li>  Conte√∫do de texto do aplicativo (entrada de texto) </li><li>  Quaisquer tags adicionadas pelo usu√°rio (entrada categ√≥rica) </li></ul><br>  O modelo ter√° 2 sa√≠das: <br><br><ul><li>  Escore de prioridade entre 0 e 1 (sa√≠da sigm√≥ide escalar) </li><li>  O departamento que deve processar o aplicativo (sa√≠da softmax referente a muitos departamentos) </li></ul><br>  Vamos construir um modelo em v√°rias linhas usando a API Funcional. <br><br><pre> <code class="python hljs">num_tags = <span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-comment"><span class="hljs-comment">#     num_words = 10000 #         num_departments = 4 #     title_input = keras.Input(shape=(None,), name='title') #      body_input = keras.Input(shape=(None,), name='body') #      tags_input = keras.Input(shape=(num_tags,), name='tags') #    `num_tags` #      64-  title_features = layers.Embedding(num_words, 64)(title_input) #      64-  body_features = layers.Embedding(num_words, 64)(body_input) #        128-  title_features = layers.LSTM(128)(title_features) #        32-  body_features = layers.LSTM(32)(body_features) #          x = layers.concatenate([title_features, body_features, tags_input]) #         priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x) #       department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x) #   ,     model = keras.Model(inputs=[title_input, body_input, tags_input], outputs=[priority_pred, department_pred])</span></span></code> </pre> <br>  Vamos desenhar um gr√°fico de modelo: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'multi_input_and_output_model.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gc/hk/uw/gchkuwc_zgefnaf4tx0ercck8bc.png"><br><br>  Ao compilar esse modelo, podemos atribuir diferentes fun√ß√µes de perda para cada sa√≠da. <br><br>  Voc√™ pode at√© atribuir pesos diferentes a cada fun√ß√£o de perda para variar sua contribui√ß√£o para a fun√ß√£o geral de perda de aprendizado. <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=[<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>], loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br>  Como demos nomes √†s nossas camadas de sa√≠da, tamb√©m podemos especificar fun√ß√µes de perda: <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss={<span class="hljs-string"><span class="hljs-string">'priority'</span></span>: <span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'department'</span></span>: <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>}, loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br>  Podemos treinar o modelo passando listas de matrizes Numpy de dados e r√≥tulos de entrada: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Dummy input data title_data = np.random.randint(num_words, size=(1280, 10)) body_data = np.random.randint(num_words, size=(1280, 100)) tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32') # Dummy target data priority_targets = np.random.random(size=(1280, 1)) dept_targets = np.random.randint(2, size=(1280, num_departments)) model.fit({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets}, epochs=2, batch_size=32)</span></span></code> </pre><br>  Ao chamar o ajuste com um objeto <code>Dataset</code> , uma tupla de listas como <code>([title_data, body_data, tags_data], [priority_targets, dept_targets])</code> ou uma tupla de dicion√°rios <code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> devem ser retornadas <code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> . <br><br><h3>  Modelo de resnet de treinamento </h3><br>  Al√©m de modelos com v√°rias entradas e sa√≠das, a API Funcional simplifica a manipula√ß√£o de topologias com conectividade n√£o linear, ou seja, modelos nos quais as camadas n√£o est√£o conectadas em s√©rie.  Esses modelos tamb√©m n√£o podem ser implementados usando a API sequencial (como o nome indica). <br><br>  Um caso de uso comum para isso s√£o as conex√µes residuais. <br><br>  Vamos criar um modelo de treinamento ResNet para o CIFAR10 para demonstrar isso. <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) block_1_output = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_1_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_2_output = layers.add([x, block_1_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_2_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_3_output = layers.add([x, block_2_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(block_3_output) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs, outputs, name=<span class="hljs-string"><span class="hljs-string">'toy_resnet'</span></span>) model.summary()</code> </pre> <br>  Vamos desenhar um gr√°fico de modelo: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'mini_resnet.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/qj/vi/bk/qjvibkpx9zrbp09rcfhj_drtlzc.png"><br><br>  E ensine a ela: <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() x_train = x_train.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_test = x_test.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> y_train = keras.utils.to_categorical(y_train, <span class="hljs-number"><span class="hljs-number">10</span></span>) y_test = keras.utils.to_categorical(y_test, <span class="hljs-number"><span class="hljs-number">10</span></span>) model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)</code> </pre> <br><h2>  Compartilhamento de camada </h2><br>  Outro bom uso da API funcional s√£o os modelos que usam camadas comuns.  Camadas comuns s√£o inst√¢ncias de camadas que s√£o reutilizadas no mesmo modelo: elas estudam recursos relacionados a v√°rios caminhos em um gr√°fico de camadas. <br><br>  Camadas comuns s√£o frequentemente usadas para codificar dados de entrada provenientes dos mesmos espa√ßos (digamos, de duas partes diferentes de texto que possuem o mesmo dicion√°rio), pois fornecem a troca de informa√ß√µes entre esses dados diferentes, o que permite que esses modelos sejam treinados com menos dados.  Se uma determinada palavra aparecer em uma das entradas, isso facilitar√° seu processamento em todas as entradas que passam pelo n√≠vel geral. <br><br>  Para compartilhar uma camada na API Funcional, basta chamar a mesma inst√¢ncia da camada v√°rias vezes.  Por exemplo, aqui a camada <code>Embedding</code> √© compartilhada em duas entradas de texto: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   1000    128-  shared_embedding = layers.Embedding(1000, 128) #     text_input_a = keras.Input(shape=(None,), dtype='int32') #     text_input_b = keras.Input(shape=(None,), dtype='int32') #           encoded_input_a = shared_embedding(text_input_a) encoded_input_b = shared_embedding(text_input_b)</span></span></code> </pre> <br><h2>  Recuperando e Reutilizando N√≥s em um Gr√°fico de Camadas </h2><br>  Como o gr√°fico de camada que voc√™ manipula na API Funcional √© uma estrutura de dados est√°tica, √© poss√≠vel acess√°-lo e verific√°-lo.  √â assim que constru√≠mos modelos funcionais, por exemplo, na forma de imagens. <br><br>  Isso tamb√©m significa que podemos acessar as ativa√ß√µes das camadas intermedi√°rias (‚Äún√≥s‚Äù no gr√°fico) e us√°-las em outros lugares.  Isso √© extremamente √∫til para extrair caracter√≠sticas, por exemplo! <br><br>  Vamos ver um exemplo.  Este √© um modelo VGG19 com escalas pr√©-treinadas no ImageNet: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.applications <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> VGG19 vgg19 = VGG19()</code> </pre> <br>  E estas s√£o ativa√ß√µes de modelo intermedi√°rias obtidas consultando a estrutura de dados do gr√°fico: <br><br><pre> <code class="python hljs">features_list = [layer.output <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> layer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> vgg19.layers]</code> </pre> <br>  Podemos usar esses recursos para criar um novo modelo de extra√ß√£o de recursos que retorna valores de ativa√ß√£o de n√≠vel intermedi√°rio - e podemos fazer tudo isso em 3 linhas <br><br><pre> <code class="python hljs">feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list) img = np.random.random((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) extracted_features = feat_extraction_model(img)</code> </pre> <br>  Isso √© conveniente ao implementar a transfer√™ncia de estilo neural, como em outros casos. <br><br><h2>  Estendendo a API escrevendo camadas personalizadas </h2><br>  <code>tf.keras</code> possui uma ampla variedade de camadas embutidas.  Aqui est√£o alguns exemplos: <br><br>  Camadas convolucionais: <code>Conv1D</code> , <code>Conv2D</code> , <code>Conv3D</code> , <code>Conv2DTranspose</code> , etc. <br>  Camadas de <code>MaxPooling1D</code> : <code>MaxPooling1D</code> , <code>MaxPooling2D</code> , <code>MaxPooling3D</code> , <code>MaxPooling3D</code> , etc. <br>  Camadas RNN: <code>GRU</code> , <code>LSTM</code> , <code>ConvLSTM2D</code> , etc. <br>  <code>BatchNormalization</code> , <code>BatchNormalization</code> , <code>Embedding</code> , etc. <br><br>  Se voc√™ n√£o encontrou o que precisa, √© f√°cil estender a API criando sua pr√≥pria camada. <br><br>  Todas as camadas subclassificam a classe <code>Layer</code> e implementam: <br><br>  O m√©todo de <code>call</code> que define os c√°lculos executados pela camada. <br>  O m√©todo de <code>build</code> que cria os pesos da camada (observe que esta √© apenas uma conven√ß√£o de estilo; voc√™ tamb√©m pode criar pesos em <code>__init__</code> ). <br><br>  Aqui est√° uma implementa√ß√£o simples da camada <code>Dense</code> : <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs)</code> </pre> <br>  Se voc√™ deseja que sua camada customizada suporte a serializa√ß√£o, tamb√©m deve definir o m√©todo <code>get_config</code> que retorna os argumentos do construtor da inst√¢ncia da camada: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> {<span class="hljs-string"><span class="hljs-string">'units'</span></span>: self.units} inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs) config = model.get_config() new_model = keras.Model.from_config( config, custom_objects={<span class="hljs-string"><span class="hljs-string">'CustomDense'</span></span>: CustomDense})</code> </pre> <br>  Opcionalmente, voc√™ tamb√©m pode implementar o m√©todo da classe <code>from_config (cls, config)</code> , respons√°vel por recriar a inst√¢ncia da camada, conforme seu dicion√°rio de configura√ß√£o.  A <code>from_config</code> padr√£o <code>from_config</code> √© assim: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">from_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cls, config)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> cls(**config)</code> </pre> <br><h2>  Quando usar a API Funcional </h2><br>  Como determinar quando √© melhor usar a API Funcional para criar um novo modelo ou simplesmente subclassificar <code>Model</code> diretamente? <br><br>  Em geral, a API Funcional √© de alto n√≠vel e f√°cil de usar, possui v√°rias fun√ß√µes que n√£o s√£o suportadas por modelos de subclasse. <br><br>  No entanto, a subclassifica√ß√£o do modelo oferece grande flexibilidade ao criar modelos que n√£o s√£o facilmente descritos como um gr√°fico ac√≠clico direcionado de camadas (por exemplo, voc√™ n√£o pode implementar o Tree-RNN com a API funcional, √© necess√°rio subclassificar o <code>Model</code> diretamente). <br><br><h3>  Pontos fortes da API funcional: </h3><br>  As propriedades listadas abaixo s√£o verdadeiras para modelos seq√ºenciais (que tamb√©m s√£o estruturas de dados), mas s√£o verdadeiras para modelos de subclasse (que s√£o c√≥digo Python, n√£o estruturas de dados). <br><br><h4>  A API funcional produz c√≥digo mais curto. </h4><br>  Sem <code>super(MyClass, self).__init__(...)</code> , sem <code>def call(self, ...):</code> etc. <br><br>  Compare: <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x) mlp = keras.Model(inputs, outputs)</code> </pre> <br>  Com vers√£o subclassificada: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MLP</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(keras.Model)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, **kwargs)</span></span></span><span class="hljs-function">:</span></span> super(MLP, self).__init__(**kwargs) self.dense_1 = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) self.dense_2 = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> x = self.dense_1(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.dense_2(x) <span class="hljs-comment"><span class="hljs-comment">#   . mlp = MLP() #    . #            . _ = mlp(tf.zeros((1, 32)))</span></span></code> </pre> <br><h4>  Seu modelo √© validado conforme est√° escrito. </h4><br>  Na API Funcional, as especifica√ß√µes de entrada (shape e dtype) s√£o criadas antecipadamente (via `Input`) e, cada vez que voc√™ chama a camada, a camada verifica se as especifica√ß√µes passadas correspondem √†s suas suposi√ß√µes; se esse n√£o for o caso, voc√™ receber√° uma mensagem de erro √∫til . <br><br>  Isso garante que qualquer modelo que voc√™ construa com a API Funcional seja iniciado.  Toda a depura√ß√£o (n√£o relacionada √† depura√ß√£o de converg√™ncia) ocorrer√° estaticamente durante a constru√ß√£o do modelo, e n√£o no tempo de execu√ß√£o.  Isso √© semelhante √† verifica√ß√£o de tipo no compilador. <br><br><h4>  Seu modelo funcional pode ser representado graficamente e tamb√©m √© test√°vel. </h4><br>  Voc√™ pode desenhar o modelo na forma de um gr√°fico e pode acessar facilmente os n√≥s intermedi√°rios do gr√°fico, por exemplo, para extrair e reutilizar a ativa√ß√£o das camadas intermedi√°rias, como vimos no exemplo anterior: <br><br><pre> <code class="plaintext hljs">features_list = [layer.output for layer in vgg19.layers] feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)</code> </pre> <br>  Como o modelo Funcional √© mais uma estrutura de dados do que um peda√ßo de c√≥digo, ele pode ser serializado com seguran√ßa e pode ser salvo como um √∫nico arquivo que permite recriar exatamente o mesmo modelo sem acesso ao c√≥digo-fonte. <br><br><h3>  Defici√™ncias funcionais da API </h3><br><h4>  Ele n√£o suporta arquiteturas din√¢micas. </h4><br>  A API Funcional processa modelos como camadas DAG.  Isso √© verdade para a maioria das arquiteturas de aprendizado profundo, mas n√£o para todos: por exemplo, redes recursivas ou RNNs da √Årvore n√£o atendem a essa suposi√ß√£o e n√£o podem ser implementadas na API Funcional. <br><br><h4>  √Äs vezes, voc√™ s√≥ precisa escrever tudo do zero. </h4><br>  Ao escrever arquiteturas avan√ßadas, conv√©m fazer algo que v√° al√©m da ‚Äúdefini√ß√£o de camadas do DAG‚Äù: por exemplo, voc√™ pode usar v√°rios m√©todos personalizados de treinamento e sa√≠da em uma inst√¢ncia do seu modelo.  Isso requer subclassifica√ß√£o. <br><br><h2>  Combinando e combinando v√°rios estilos de API </h2><br>  √â importante observar que escolher entre a API Funcional ou subclassificar o Modelo n√£o √© uma solu√ß√£o bin√°ria que limita voc√™ a uma categoria de modelos.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Todos os modelos na API tf.keras podem interagir entre si, sejam modelos sequenciais, modelos funcionais ou modelos / camadas subclassificados, escritos do zero. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voc√™ sempre pode usar o modelo Funcional ou o modelo Sequencial como parte do modelo / camada subclassificado:</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment"># Define a Functional model inputs = keras.Input((None, units)) x = layers.GlobalAveragePooling1D()(inputs) outputs = layers.Dense(1, activation='sigmoid')(x) model = keras.Model(inputs, outputs) class CustomRNN(layers.Layer): def __init__(self): super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation='tanh') self.projection_2 = layers.Dense(units=units, activation='tanh') # Our previously-defined Functional model self.classifier = model def call(self, inputs): outputs = [] state = tf.zeros(shape=(inputs.shape[0], self.units)) for t in range(inputs.shape[1]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=1) print(features.shape) return self.classifier(features) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, timesteps, input_dim)))</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por outro lado, voc√™ pode usar qualquer Camada ou Modelo subclassificado na API Funcional se implementar um m√©todo </font></font><code>call</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que corresponda a um dos seguintes padr√µes: </font></font><br><br> <code>call(self, inputs, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">onde </font></font><code>inputs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est√° a estrutura do tensor ou do tensor aninhado (por exemplo, lista de tensores) e onde </font></font><code>**kwargs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est√£o os argumentos sem tensor (n√£o entrada) . </font></font><br> <code>call(self, inputs, training=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">onde </font></font><code>training</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√© um valor booleano indicando em qual modo a camada, aprendizado ou sa√≠da deve se comportar. </font></font><br> <code>call(self, inputs, mask=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">onde </font></font><code>mask</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√© o tensor da m√°scara booleana (√∫til para RNN, por exemplo). </font></font><br> <code>call(self, inputs, training=None, mask=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- √© claro que voc√™ pode ter os dois par√¢metros que definem o comportamento da camada ao mesmo tempo.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al√©m disso, se voc√™ implementar o m√©todo `get_config` em sua camada ou modelo personalizado, os modelos funcionais criados com ele ser√£o serializados e clonados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abaixo est√° um pequeno exemplo em que usamos RNN personalizados escritos do zero Modelos funcionais:</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomRNN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.projection_2 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.classifier = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> outputs = [] state = tf.zeros(shape=(inputs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], self.units)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(inputs.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.classifier(features) <span class="hljs-comment"><span class="hljs-comment">#           #  `batch_shape`,     `CustomRNN`  #    (     `state`). inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim)) x = layers.Conv1D(32, 3)(inputs) outputs = CustomRNN()(x) model = keras.Model(inputs, outputs) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, 10, 5)))</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Isso conclui nosso Guia de API funcional! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora voc√™ tem em m√£os um poderoso conjunto de ferramentas para a constru√ß√£o de modelos de aprendizado profundo.</font></font><br><br>  <i>Ap√≥s a verifica√ß√£o, a tradu√ß√£o tamb√©m aparecer√° no Tensorflow.org.</i>  <i>Se voc√™ deseja participar da tradu√ß√£o da documenta√ß√£o do site Tensorflow.org para o russo, entre em contato com um coment√°rio ou pessoal.</i>  <i>Quaisquer corre√ß√µes ou coment√°rios s√£o apreciados.</i> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como ilustra√ß√£o, usamos a imagem do modelo GoogLeNet, que tamb√©m √© um gr√°fico ac√≠clico direcionado.</font></font></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt483664/">https://habr.com/ru/post/pt483664/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt483650/index.html">Cosmodromes mais pr√≥ximos do equador - Wenchang Tropical Cosmodrome</a></li>
<li><a href="../pt483652/index.html">Mentir para mim, se puder: caracter√≠sticas de conduzir um pentest sociot√©cnico</a></li>
<li><a href="../pt483654/index.html">Feedback em com√≠cios, um por um, por que ele pode n√£o funcionar e como tentar corrigi-lo?</a></li>
<li><a href="../pt483660/index.html">Telegram-bot para gerenciamento de infraestrutura</a></li>
<li><a href="../pt483662/index.html">Integra√ß√£o do Cisco Threat Response e Cisco Stealthwatch Enterprise</a></li>
<li><a href="../pt483666/index.html">Sobre Volodya e o ozonizador</a></li>
<li><a href="../pt483668/index.html">O resumo de materiais frescos do mundo do front-end da √∫ltima semana n¬∫ 397 (6 a 12 de janeiro de 2020)</a></li>
<li><a href="../pt483670/index.html">Tudo o que voc√™ queria saber sobre o endere√ßo MAC</a></li>
<li><a href="../pt483674/index.html">Como as redes neurais bin√°rias funcionam e por que elas ser√£o populares em 2020</a></li>
<li><a href="../pt483678/index.html">Desenvolvendo programas Python extremamente r√°pidos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòì üë¥üèæ ‚õ∏Ô∏è O livro "Trabalhar com BigData nas nuvens. Processando e armazenando dados com exemplos do Microsoft Azure ¬ª üë©üèæ‚Äçüíª üå©Ô∏è üë©üèø‚Äçüè´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Aqui est√° o primeiro livro originalmente em russo no qual os segredos do processamento de big data (Big Data) nas nuvens s√£o examinados com exemplos r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O livro "Trabalhar com BigData nas nuvens. Processando e armazenando dados com exemplos do Microsoft Azure ¬ª</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/428375/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/un/xm/vy/unxmvydwj2ybjfabsmi3vbdcnsg.jpeg" align="left" alt="imagem"></a>  Aqui est√° o primeiro livro originalmente em russo no qual os segredos do processamento de big data (Big Data) nas nuvens s√£o examinados com exemplos reais. <br><br>  O foco est√° nas solu√ß√µes Microsoft Azure e AWS.  Todas as etapas do trabalho s√£o consideradas - obten√ß√£o de dados preparados para processamento na nuvem, usando armazenamento em nuvem, ferramentas de an√°lise de dados em nuvem.  √â prestada aten√ß√£o especial aos servi√ßos SAAS; s√£o demonstradas as vantagens das tecnologias em nuvem em compara√ß√£o com as solu√ß√µes implantadas em servidores dedicados ou m√°quinas virtuais. <br><br>  O livro foi projetado para um amplo p√∫blico e servir√° como um excelente recurso para o desenvolvimento do Azure, Docker e outras tecnologias indispens√°veis, sem as quais as empresas modernas s√£o impens√°veis. <br><br>  N√≥s convidamos voc√™ a ler a passagem "Download direto de dados de streaming" <br><a name="habracut"></a><br><h3>  10.1  Arquitetura geral </h3><br>  No cap√≠tulo anterior, examinamos a situa√ß√£o em que muitos aplicativos clientes devem enviar um grande n√∫mero de mensagens que precisam ser processadas dinamicamente, colocadas no reposit√≥rio e processadas novamente nele.  Ao mesmo tempo, voc√™ deve poder alterar a l√≥gica do fluxo de processamento e armazenamento de dados sem recorrer √† altera√ß√£o do c√≥digo do cliente.  E, finalmente, do ponto de vista das raz√µes de seguran√ßa, os clientes devem ter o direito de fazer apenas uma coisa: enviar mensagens ou receb√™-las, mas de maneira alguma ler dados ou excluir bancos de dados, e eles n√£o devem ter direitos diretos para gravar esses dados. <br><br>  Essas tarefas s√£o muito comuns em sistemas que trabalham com dispositivos IoT conectados por meio de uma conex√£o √† Internet, bem como em sistemas de an√°lise de log online.  Al√©m dos requisitos listados acima para o nosso servi√ßo dedicado, h√° mais dois requisitos relacionados √†s especificidades da ‚ÄúInternet das Coisas‚Äù e para garantir o processamento confi√°vel de mensagens.  Antes de tudo, o protocolo de intera√ß√£o entre o cliente e o receptor de servi√ßo deve ser muito simples, para que possa ser implementado em um dispositivo com recursos de computa√ß√£o limitados e mem√≥ria muito limitada (por exemplo, Arduino, Intel Edison, STM32 Discovery e outras plataformas "inadequadas", como como antes de RaspberryPi).  O pr√≥ximo requisito √© a entrega confi√°vel de mensagens, independentemente de poss√≠veis falhas nos servi√ßos de processamento.  Este √© um requisito mais forte do que o requisito de alta confiabilidade.  De fato, para garantir a confiabilidade geral de todo o sistema, √© necess√°rio que a confiabilidade de todos os seus componentes seja alta o suficiente e a adi√ß√£o de um novo componente n√£o leve a um aumento percept√≠vel no n√∫mero de falhas.  Al√©m da falha na infraestrutura da nuvem, pode ocorrer um erro no servi√ßo criado pelo usu√°rio.  E mesmo assim, a mensagem deve ser processada assim que o servi√ßo do usu√°rio for restaurado.  Para fazer isso, o servi√ßo de recebimento de fluxo de mensagens deve armazenar de forma confi√°vel a mensagem at√© que seja processada ou at√© que sua vida √∫til expire (isso √© necess√°rio para evitar o estouro de mem√≥ria durante um fluxo de mensagens cont√≠nuo).  Um servi√ßo com essas propriedades √© chamado de Hub de Eventos.  Para dispositivos IoT, existem hubs especializados (Hub IoT), que possuem v√°rias outras propriedades que s√£o muito importantes para uso em conjunto com os dispositivos Internet das Coisas (por exemplo, comunica√ß√£o bidirecional a partir de um ponto, roteamento de mensagens interno, "dobras digitais" do dispositivo e v√°rias outros).  No entanto, esses servi√ßos ainda s√£o especializados e n√£o os consideraremos em detalhes. <br><br>  Antes de prosseguirmos para o conceito de concentra√ß√£o de mensagens, passemos √†s id√©ias subjacentes a ele. <br><br>  Suponha que tenhamos uma fonte de mensagem (por exemplo, solicita√ß√µes de um cliente) e um servi√ßo que deve lidar com elas.  O processamento de uma √∫nica solicita√ß√£o leva tempo e requer recursos computacionais (CPU, mem√≥ria, IOPS).  Al√©m disso, durante o processamento de uma solicita√ß√£o, as solicita√ß√µes restantes n√£o podem ser processadas.  Para que os aplicativos clientes n√£o congelem enquanto aguardam o lan√ßamento de um servi√ßo, √© necess√°rio separ√°-los com a ajuda de um servi√ßo adicional que ser√° respons√°vel por armazenar mensagens enquanto aguardam o processamento na fila.  Essa separa√ß√£o tamb√©m √© necess√°ria para aumentar a confiabilidade geral do sistema.  De fato, o cliente envia uma mensagem ao sistema, mas o servi√ßo de processamento pode "cair", mas a mensagem n√£o deve ser perdida, deve ser armazenada em um servi√ßo mais confi√°vel que o servi√ßo de processamento.  A vers√£o mais simples desse servi√ßo √© chamada de fila (Fig. 10.1). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ql/8v/vn/ql8vvnkz7cm8mkc0mrgtrdczzae.png" alt="imagem"></div><br>  O servi√ßo de fila funciona da seguinte maneira: o cliente conhece o URL da fila e possui chaves de acesso.  Usando o SDK ou API da fila, o cliente coloca uma mensagem que cont√©m o carimbo de data / hora, o identificador e o corpo da mensagem com uma carga √∫til no formato JSON, XML ou bin√°rio. <br><br>  O c√≥digo do programa do servi√ßo inclui um ciclo que "escuta" a fila, recuperando a pr√≥xima mensagem a cada etapa e, se houver uma mensagem na fila, ela √© extra√≠da e processada.  Se o servi√ßo processar com √™xito a mensagem, ela ser√° removida da fila.  Se ocorrer um erro durante o processamento, ele n√£o ser√° exclu√≠do e poder√° ser processado novamente quando uma nova vers√£o do servi√ßo, com o c√≥digo corrigido, for iniciada.  A fila foi projetada para sincronizar um cliente (ou um grupo de clientes semelhantes) e exatamente um servi√ßo de processamento (embora o √∫ltimo possa estar localizado em um cluster de servidores ou em um farm de servidores).  Os Servi√ßos de Enfileiramento em Nuvem incluem a Fila de Armazenamento do Azure, a Fila do Barramento de Servi√ßo do Azure e o AWS SQS.  Os servi√ßos hospedados em m√°quinas virtuais incluem RabbitMQ, ZeroMQ, MSMQ, IBM MQ, etc. <br><br>  Diferentes servi√ßos de fila garantem diferentes tipos de entrega de mensagens: <br><ul><li>  Entrega de mensagem pelo menos uma vez </li><li>  entrega estritamente √∫nica; </li><li>  entrega de mensagens enquanto mant√©m a ordem; </li><li>  entrega da mensagem sem manter a ordem. </li></ul><br>  A fila fornece entrega confi√°vel de mensagens de uma fonte para um servi√ßo de processamento, ou seja, intera√ß√£o um a um.  Mas e se for necess√°rio fornecer a entrega de mensagens a v√°rios servi√ßos?  Nesse caso, voc√™ precisa usar um servi√ßo chamado "t√≥pico" (t√≥pico) (Fig. 10.2). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wo/mi/6i/womi6if7bwniohwxjvik1r68v_4.png" alt="imagem"></div><br>  Um elemento importante dessa arquitetura √© "assinaturas".  Este √© o caminho registrado na se√ß√£o em que a mensagem √© enviada.  As mensagens s√£o publicadas no t√≥pico pelo cliente e transferidas para uma das assinaturas, da qual s√£o extra√≠das por um dos servi√ßos e processadas por ele.  Os t√≥picos fornecem uma arquitetura de intera√ß√£o um para muitos no atendimento ao cliente.  Exemplos de tais servi√ßos incluem o T√≥pico do Barramento de Servi√ßo do Azure e o AWS SNS. <br><br>  Agora, suponha que haja um grande n√∫mero de clientes heterog√™neos que precisem enviar muitas mensagens para v√°rios servi√ßos, ou seja, precisamos criar um sistema de intera√ß√£o muitos para muitos.  Obviamente, essa arquitetura pode ser constru√≠da usando v√°rias se√ß√µes, mas essa constru√ß√£o n√£o √© escal√°vel e requer esfor√ßo de administra√ß√£o e monitoramento.  No entanto, existem servi√ßos separados - concentradores de mensagens (Fig. 10.3). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5t/na/sg/5tnasgyiet_8zcd0zmtvxj4koeg.png" alt="imagem"></div><br>  O hub aceita mensagens de muitos clientes.  Todos os clientes podem enviar mensagens para um terminal em servi√ßo comum ou conectar-se separadamente a terminais diferentes por meio de chaves especiais.  Essas chaves permitem gerenciar clientes com flexibilidade: desconectar alguns, conectar novos, etc. Dentro do hub, tamb√©m existem parti√ß√µes.  Por√©m, nesse caso, eles podem ser distribu√≠dos entre todos os clientes para aumentar a produtividade (round robin - ‚Äúcom adi√ß√£o c√≠clica‚Äù) ou o cliente pode publicar mensagens em uma das se√ß√µes.  Por outro lado, os servi√ßos de processamento s√£o combinados em grupos de consumidores.  Um ou v√°rios servi√ßos podem ser conectados a um grupo.  Portanto, um concentrador de mensagens √© o servi√ßo mais flex√≠vel que pode ser configurado como uma fila, se√ß√£o ou grupo de filas ou um conjunto de se√ß√µes.  Em geral, um concentrador de mensagens fornece um relacionamento muitos para muitos entre clientes e servi√ßos.  Esses hubs incluem Apache Kafka, Azure Event Hub e AWS Kinesis Stream. <br><br>  Antes de analisar os servi√ßos PaaS baseados na nuvem, prestaremos aten√ß√£o a um servi√ßo muito poderoso e conhecido - Apache Kafka.  Em ambientes em nuvem, ele pode ser acessado como uma distribui√ß√£o implantada diretamente em um cluster de m√°quina virtual ou usando o servi√ßo HDInsight.  Portanto, o Apache Kafka √© um servi√ßo que fornece os seguintes recursos: <br><ul><li>  Postando e assinando um fluxo de mensagens </li><li>  armazenamento confi√°vel de mensagens; </li><li>  Aplica√ß√£o de servi√ßos de processamento de mensagens de streaming de terceiros. </li></ul><br>  Fisicamente, o Kafka √© executado em um cluster de um ou mais servidores.  Kafka fornece uma API para interagir com clientes externos (Fig. 10.4). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gz/50/ug/gz50ugazn-xwectzo--c8pulh4c.png" alt="imagem"></div><br>  Considere essas APIs em ordem. <br><ul><li>  As APIs do fornecedor permitem que os aplicativos clientes publiquem fluxos de mensagens em um ou mais t√≥picos Kafka. </li><li>  As APIs do consumidor oferecem aos aplicativos clientes a capacidade de assinar um ou mais t√≥picos e processar os fluxos de mensagens entregues pelos t√≥picos aos clientes. </li><li>  As APIs do processador de fluxo permitem que os aplicativos interajam com o cluster Kafka como um processador de fluxo.  As fontes para um processador podem ser um ou mais t√≥picos.  Nesse caso, as mensagens processadas tamb√©m s√£o colocadas em um ou mais t√≥picos. </li><li>  As APIs do conector ajudam a conectar fontes de dados externas (por exemplo, RDB) como fontes de mensagens (por exemplo, √© poss√≠vel interceptar eventos de altera√ß√£o de dados no banco de dados) e como receptores. </li></ul><br>  No Kafka, a intera√ß√£o entre clientes e o cluster ocorre via TCP, o que √© facilitado pelos SDKs existentes para v√°rias linguagens de programa√ß√£o, incluindo .Net.  Mas as linguagens b√°sicas do SDK s√£o Java e Scala. <br><br>  Em um cluster, o armazenamento de fluxos de mensagens (na terminologia Kafka tamb√©m chamada de entradas) ocorre logicamente em objetos chamados t√≥picos (Fig. 10.5).  Cada registro consiste em uma chave, um valor e um carimbo de data / hora.  Em ess√™ncia, um t√≥pico √© uma sequ√™ncia de registros (mensagens) que foram publicados pelos clientes.  Os t√≥picos Kafka suportam de 0 a v√°rios assinantes.  Cada t√≥pico √© representado fisicamente como um log particionado.  Cada se√ß√£o √© uma sequ√™ncia ordenada de registros, √† qual novos novos que chegam √† entrada do Kafka s√£o constantemente adicionados. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qn/yi/wu/qnyiwuqtcxijhasj3iz7q8eh4jm.png" alt="imagem"></div><br>  Cada entrada na se√ß√£o corresponde a um n√∫mero na sequ√™ncia, tamb√©m chamado de deslocamento, que identifica exclusivamente essa mensagem na sequ√™ncia.  Diferentemente da fila, o Kafka exclui a mensagem n√£o ap√≥s o processamento do servi√ßo, mas ap√≥s a vida √∫til das mensagens.  Essa √© uma propriedade muito importante, oferecendo a capacidade de ler de um t√≥pico para diferentes consumidores.  Al√©m disso, um vi√©s est√° associado a cada consumidor (Fig. 10.6).  E cada ato de leitura leva apenas a um aumento no valor de cada cliente individualmente e √© determinado precisamente pelo cliente. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mj/1b/mk/mj1bmkl7ooowixrdekhfg3-bix8.png" alt="imagem"></div><br>  No caso normal, esse deslocamento aumenta em um ap√≥s a leitura bem-sucedida de uma mensagem do t√≥pico.  Mas, se necess√°rio, o cliente pode mudar esse deslocamento e repetir a opera√ß√£o de leitura. <br><br>  O uso do conceito de se√ß√µes tem os seguintes objetivos. <br><br>  Primeiramente, as se√ß√µes fornecem a capacidade de escalar t√≥picos quando um t√≥pico n√£o se encaixa no mesmo n√≥.  Ao mesmo tempo, cada se√ß√£o possui um n√≥ inicial (n√£o o confunda com o n√≥ principal de todo o cluster) e zero ou v√°rios n√≥s seguidores.  O n√≥ principal √© respons√°vel pelo processamento das opera√ß√µes de leitura / grava√ß√£o, enquanto os seguidores s√£o suas c√≥pias passivas.  Se o n√≥ principal falhar, um dos n√≥s sucessores se tornar√° automaticamente o n√≥ principal.  Cada n√≥ do cluster √© o principal para algumas se√ß√µes e um seguidor para outras.  Em segundo lugar, essa replica√ß√£o aumenta o desempenho da leitura devido √† possibilidade de opera√ß√µes de leitura paralela. <br><br>  O produtor pode colocar a mensagem em qualquer t√≥pico de sua escolha explicitamente ou no modo round robin implicitamente (ou seja, com preenchimento uniforme).  Os consumidores est√£o unidos nos chamados grupos de consumidores, e cada mensagem publicada no t√≥pico √© entregue a um cliente em cada grupo de consumidores.  Nesse caso, os clientes podem ser hospedados fisicamente em um ou mais servidores / m√°quinas virtuais.  Em mais detalhes, a entrega da mensagem √© a seguinte.  Para todos os clientes pertencentes ao mesmo grupo de consumidores, as mensagens podem ser distribu√≠das entre os clientes para otimizar a carga.  Se os clientes pertencerem a diferentes grupos de consumidores, cada mensagem ser√° enviada para cada grupo.  A separa√ß√£o das mensagens das se√ß√µes por diferentes grupos de consumidores √© mostrada na Fig.  10.7 <br><br>  Agora, descreverei brevemente os principais par√¢metros de entrega e armazenamento de mensagens garantidos pelo Kafka. <br><ul><li>  As mensagens enviadas pelo fabricante para um t√≥pico espec√≠fico ser√£o adicionadas estritamente na ordem em que foram enviadas. </li><li>  O cliente v√™ a ordem das mensagens no t√≥pico que foi recebido quando as mensagens foram salvas.  Como resultado, as mensagens s√£o entregues do produtor ao consumidor estritamente na ordem em que s√£o recebidas. </li><li>  A replica√ß√£o dobrada em N do t√≥pico garante a estabilidade do t√≥pico √† falha de n√≥s N - 1 sem perda de desempenho. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rf/qp/ms/rfqpmsno04krpiqxhs1qv8agwhu.png" alt="imagem"></div><br>  Portanto, o servi√ßo Apache Kafka pode ser usado nos seguintes modos. <br><br><ul><li>  Servi√ßo - intermedi√°rio de mensagens (fila) ou servi√ßo de publica√ß√£o - assinatura de mensagens (t√≥pico).  De fato, o Kafka √© baseado em um grupo de t√≥picos que podem ser convertidos em uma fila com um assinante.  (Deve-se lembrar: em contraste com os servi√ßos habituais de intermedi√°rios de mensagens, criados com base no princ√≠pio das filas, as mensagens Kafka s√£o exclu√≠das somente ap√≥s o t√©rmino de sua vida √∫til, enquanto os intermedi√°rios implementam o princ√≠pio Peek-Delete, ou seja, recupera√ß√£o e exclus√£o ap√≥s o processamento bem-sucedido. ) O princ√≠pio dos grupos de consumidores resume esses dois conceitos, e a capacidade de publicar mensagens em todos os t√≥picos com a distribui√ß√£o de round robin faz do Kafka um intermedi√°rio universal de mensagens multimodo. </li><li>  Servi√ßo para an√°lise de mensagens de streaming.  Isso √© poss√≠vel gra√ßas √† API para processadores de streaming inclu√≠dos no Kafka, que permite criar sistemas complexos, criados com base no Event Driven, com servi√ßos que filtram mensagens ou respondem a elas, al√©m de servi√ßos que agregam mensagens. </li></ul><br>  Todas essas propriedades possibilitam o uso do Kafka como um componente-chave de uma plataforma que trabalha com dados de streaming e possui √≥timos recursos para criar sistemas complexos de processamento de mensagens.  Mas, ao mesmo tempo, o Kafka √© bastante complicado em termos de implanta√ß√£o e configura√ß√£o de um cluster de v√°rios n√≥s, o que requer um esfor√ßo administrativo significativo.  Mas, por outro lado, como as id√©ias subjacentes ao Kafka s√£o muito adequadas para criar sistemas, transmitir mensagens e receber mensagens, os provedores de nuvem fornecem servi√ßos de PaaS que implementam essas id√©ias e ocultam todas as dificuldades de criar e administrar um cluster Kafka.  Por√©m, como esses servi√ßos t√™m v√°rias restri√ß√µes em termos de personaliza√ß√£o e expans√£o al√©m dos limites alocados para os servi√ßos, os provedores de nuvem fornecem servi√ßos especiais de IaaS / PaaS para a implanta√ß√£o f√≠sica do Kafka em um cluster de m√°quina virtual.  Nesse caso, o usu√°rio tem quase total liberdade de configura√ß√£o e expans√£o.  Esses servi√ßos incluem o Azure HDInsight.  J√° foi mencionado acima.  Foi criado para, por um lado, fornecer ao usu√°rio servi√ßos do ecossistema Hadoop por conta pr√≥pria, sem inv√≥lucros externos e, por outro lado, para aliviar as dificuldades decorrentes da instala√ß√£o, administra√ß√£o e configura√ß√£o diretas do IaaS.  A hospedagem no Docker √© um pouco distante.  Como esse √© um t√≥pico extremamente importante, vamos consider√°-lo, mas primeiro familiarize-se com os servi√ßos de PaaS implementados usando os conceitos b√°sicos do Kafka. <br><br><h3>  10.2  Hub de eventos do Azure </h3><br>  Considere o servi√ßo de hub de mensagens do Azure Event Hub.  √â um servi√ßo criado no modelo PaaS.  V√°rios grupos de clientes podem atuar como fontes de mensagens para o Hub de Eventos do Azure (Figura 10.8).  Antes de tudo, esse √© um grupo muito grande de servi√ßos em nuvem cujas sa√≠das ou gatilhos podem ser configurados para enviar mensagens diretamente para o Hub de Eventos.  Estes podem ser Trabalho de Stream Analytics, Grade de Eventos e um grupo significativo de servi√ßos que redirecionam eventos - logs no Hub de Eventos (principalmente, criados usando o AppService: App da API, aplicativo da Web, aplicativo m√≥vel e aplicativo de fun√ß√µes). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/th/wr/-y/thwr-yanwimel2wqzorsolaojxo.png" alt="imagem"></div><br>  As mensagens entregues ao hub podem ser capturadas diretamente e armazenadas no Blob Storage ou no Data Lake Store. <br><br>  O pr√≥ximo grupo de fontes s√£o clientes ou dispositivos externos de software para os quais n√£o h√° SDK do Azure Event Hub e que n√£o podem ser integrados diretamente aos servi√ßos do Azure.  Esses clientes incluem principalmente dispositivos de IoT.  Eles podem enviar mensagens para o Hub de Eventos via HTTPS ou AMQP.  A considera√ß√£o de como conectar esses dispositivos est√° al√©m do escopo de nosso livro. <br><br>  Por fim, os clientes de software que geram mensagens e as enviam para o Hub de Eventos usando o SDK do Hub de Eventos do Azure.  Este grupo inclui o Azure PowerShell e a CLI do Azure. <br>  Como receptores de mensagens (consumidores - ‚Äúconsumidores‚Äù) do Hub de Eventos, o Trabalho do Stream Analytics ou o servi√ßo de integra√ß√£o de Grade de Eventos podem ser usados.  Al√©m disso, √© poss√≠vel receber mensagens de clientes de software usando o Azure Event Hub SDK.  Os consumidores se conectam ao Hub de Eventos usando o protocolo AMQP 1.0. <br><br>  Considere os conceitos b√°sicos do Hub de Eventos do Azure necess√°rios para entender como us√°-lo e configur√°-lo.  Qualquer fonte (tamb√©m chamada de publisher na documenta√ß√£o) que envia uma mensagem ao hub deve usar o protocolo HTTPS ou AMQP 1.0.  A escolha de um protocolo √© determinada pelo tipo de cliente, pela rede de comunica√ß√£o e pelos requisitos da taxa de mensagens.  O AMQP requer uma conex√£o permanente entre dois soquetes TCP bidirecionais.  √â protegido usando o protocolo de criptografia da camada de transporte TLS ou SSL / TLS.   ,  ,       AMQP   ,  HTTPS,          .      HTTPS. <br><br>     ,         SAS (Shared Access Signature) tokens.          SAS-          SAS   .      SAS-,      (  ). <br><br>         256 .  ,                  . <br><br>  ,      Event Hub.      ,        ,      ,     -.   EventHub     (partitions).   EventHub ‚Äî    ,     ¬´  ‚Äî  ¬ª (FIFO) (. 10.9). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/iq/2g/_p/iq2g_p_ldvolfuahy8admgxqhzo.png" alt="imagem"></div><br>   ‚Äî       Event Hub.  Event Hub    2  32 ,          Event Hub.   ,          . <br><br>    (    )    ,      (    ,     ‚Äî . ),       (retention period),   .   .           .       ,  Azure Event Hub    (offset).     ‚Äî    ,      ,  ,  ,      .          . Azure Event Hub SDK    ,     ,     .       -,         . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fe/ab/bc/feabbcymdq52xiddkbp2vcajz-k.png" alt="imagem"></div><br>  ,          ,     ,       ,    .   Azure Event Hub SDK     ,        .  ,     Storage Account.  Azure,     Event Hub,       . <br><br>     Event Hub     (partition key),          .    ‚Äî   . ,         (    )          .        ,       (round robin). <br><br>       .      ,       (consumer group) (. 10.11).             .             (view) (     ) ,  ,     .        ,       .     ‚Äî 20,            ,            . <br><br>          .  ,              .    ,     (throughput unit).         : <br><ul><li>    ‚Äî 1 M    1000    (   ,       ); </li><li>    ‚Äî 2 M  . </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O valor da taxa de transfer√™ncia espec√≠fica √© configurado para cada hub separadamente. </font><font style="vertical-align: inherit;">Se as fontes excederem a taxa de transfer√™ncia permitida, uma exce√ß√£o ser√° lan√ßada nelas. </font><font style="vertical-align: inherit;">Nesse caso, o receptor simplesmente n√£o pode receber mensagens mais rapidamente que um determinado valor. </font><font style="vertical-align: inherit;">As unidades de largura de banda tamb√©m afetam o custo do uso do servi√ßo.</font></font> Cuidado!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Voc√™ deve estar ciente de que existem limites de largura de banda alocados para o espa√ßo para nome e n√£o para inst√¢ncias individuais do servi√ßo Hub de Eventos. </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/i_/l0/jc/i_l0jcqwomkuargf-sygdrfufdc.png" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Os concentradores de mensagens s√£o logicamente agrupados em espa√ßos para nome (espa√ßo para nome) (Fig. 10.12). </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jf/de/h-/jfdeh-khouxn6olnkxcgw6-w1a4.png" alt="imagem"></div><br><br>  ¬ªMais informa√ß√µes sobre o livro podem ser encontradas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site do editor</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Conte√∫do</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Trecho</a> <br><br>  Cupom de 20% de desconto para <b>vendedores ambulantes</b> - <b>BigData</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt428375/">https://habr.com/ru/post/pt428375/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt428365/index.html">A hist√≥ria de como o faturamento do Google mudou ou como evitar custos desnecess√°rios</a></li>
<li><a href="../pt428367/index.html">Fabricamos o menor modem de sonar do mundo</a></li>
<li><a href="../pt428369/index.html">Sair da roda de Sansara, extremismo e um pouco de coisa verde - uma an√°lise de tarefas do livreto GridGain na confer√™ncia Joker 2018</a></li>
<li><a href="../pt428371/index.html">Jogo antigo da IBM</a></li>
<li><a href="../pt428373/index.html">iPhone √© inconveniente de usar</a></li>
<li><a href="../pt428377/index.html">Biomarcadores Epigen√©ticos do Envelhecimento</a></li>
<li><a href="../pt428379/index.html">O processo de design real. Uma hist√≥ria passo a passo sobre como criar um site voltado para neg√≥cios</a></li>
<li><a href="../pt428381/index.html">Investimento de US $ 10 milh√µes e elogios a Wozniak - um longo caminho para criar um designer de computadores para crian√ßas</a></li>
<li><a href="../pt428383/index.html">A Sony publicou uma lista completa de jogos para o PlayStation Classic</a></li>
<li><a href="../pt428385/index.html">Mais caf√©, menos cafe√≠na: Intel 9a gera√ß√£o (parte 1)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧜🏿 🐞 ❔ Bagaimana memahami Tensorflow dan tidak mati, dan bahkan mengajarkan sesuatu tentang mobil 🙏🏼 👨‍👨‍👧‍👦 🧘</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo Pengawal. Posting hari ini adalah tentang bagaimana tidak tersesat di belantara berbagai pilihan untuk menggunakan TensorFlow untuk pembelajaran ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana memahami Tensorflow dan tidak mati, dan bahkan mengajarkan sesuatu tentang mobil</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427449/"><p>  Halo Pengawal.  Posting hari ini adalah tentang bagaimana tidak tersesat di belantara berbagai pilihan untuk menggunakan TensorFlow untuk pembelajaran mesin dan mencapai tujuan Anda.  Artikel ini dirancang agar pembaca mengetahui dasar-dasar prinsip pembelajaran mesin, tetapi belum mencoba melakukannya dengan tangannya sendiri.  Hasilnya, kami mendapatkan demo yang berfungsi di Android, yang mengenali sesuatu dengan akurasi yang cukup tinggi.  Tetapi hal pertama yang pertama. </p><br><p><img src="https://habrastorage.org/webt/rs/7r/_f/rs7r_f7v6dywnklpaok4htwntsq.jpeg"></p><a name="habracut"></a><br><p>  Setelah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">melihat</a> bahan-bahan terbaru, diputuskan untuk melibatkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tensorflow</a> , yang sekarang mendapatkan momentum tinggi, dan artikel-artikel dalam bahasa Inggris dan Rusia tampaknya cukup untuk tidak menggali segala sesuatu dan dapat mengetahui apa itu. </p><br><p>  Menghabiskan dua minggu, mempelajari artikel dan banyak sampel mantan di kantor.  situs, saya menyadari bahwa saya tidak mengerti apa-apa.  Terlalu banyak informasi dan opsi tentang bagaimana Tensorflow dapat digunakan.  Kepalaku sudah bengkak karena betapa mereka menawarkan solusi yang berbeda dan apa yang harus dilakukan dengan mereka, sebagaimana diterapkan pada tugas saya. </p><br><p><img src="https://habrastorage.org/webt/bd/2z/jy/bd2zjyct-gx0xbz9nfbwwya5aw8.png"></p><br><p>  Kemudian saya memutuskan untuk mencoba semuanya mulai dari opsi yang paling sederhana dan paling siap pakai (di mana saya diharuskan mendaftarkan dependensi dalam gradle dan menambahkan beberapa baris kode) ke yang lebih kompleks (di mana saya harus membuat dan melatih model grafik sendiri dan belajar cara menggunakannya di ponsel) aplikasi). </p><br><p>  Pada akhirnya, saya harus menggunakan versi yang rumit, yang akan dibahas lebih detail di bawah ini.  Sementara itu, saya telah menyusun untuk Anda daftar opsi sederhana yang sama-sama efektif, hanya masing-masing sesuai dengan tujuannya. </p><br><h3 id="1--ml-kithttpsfirebasegooglecomdocsml-kit">  1. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ML KIT</a> </h3><br><p><img src="https://habrastorage.org/webt/al/of/8w/alof8wunrnv66f66xwv2rrlbrn0.png"></p><br><p>  Solusi termudah untuk digunakan - beberapa baris kode yang dapat Anda gunakan: </p><br><ul><li>  Pengenalan teks (teks, karakter latin) </li><li>  Deteksi wajah (wajah, emosi) </li><li>  Pemindaian barcode (barcode, kode qr) </li><li>  Pelabelan gambar (sejumlah jenis objek dalam gambar) </li><li>  Pengakuan landmark (atraksi) </li></ul><br><p>  Ini sedikit lebih rumit. Dengan solusi ini, Anda juga dapat menggunakan model TensorFlow Lite Anda sendiri, tetapi mengonversi ke format ini menyebabkan kesulitan, jadi item ini belum pernah dicoba. </p><br><p>  Saat pencipta keturunan ini menulis, sebagian besar tugas dapat diselesaikan menggunakan perkembangan ini.  Tetapi jika ini tidak berlaku untuk tugas Anda, Anda harus menggunakan model khusus. </p><br><h3 id="2--custom-visionhttpswwwcustomvisionai">  2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Visi Kustom</a> </h3><br><p><img src="https://habrastorage.org/webt/p9/c_/2u/p9c_2ujglvyu8mbffhrmoqpzav0.png"></p><br><p>  Alat yang sangat nyaman untuk membuat dan melatih model khusus Anda menggunakan gambar. <br>  Dari Pros - ada versi gratis yang memungkinkan Anda menyimpan satu proyek. <br>  Of the Cons - versi gratis membatasi jumlah gambar "masuk" menjadi 3.000.  Untuk mencoba dan membuat jaringan akurasi yang biasa-biasa saja - itu sudah cukup.  Untuk tugas yang lebih tepat, Anda perlu lebih banyak. <br>  Semua yang diperlukan pengguna adalah menambahkan gambar dengan tanda (misalnya - image1 adalah "racoon", image2 adalah "sun"), melatih dan mengekspor grafik untuk digunakan di masa mendatang. </p><br><p><img src="https://habrastorage.org/webt/co/lk/nw/colknw0ljunbtzcixxdrde6qwtm.png"></p><br><p>  Peduli Microsoft bahkan menawarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sampelnya</a> sendiri, yang dengannya Anda dapat mencoba grafik yang Anda terima. <br>  Bagi mereka yang sudah "dalam subjek" - grafik yang dihasilkan sudah dalam keadaan Beku, mis.  Anda tidak perlu melakukan / mengonversi apa pun dengan itu. <br>  Solusi ini bagus ketika Anda memiliki sampel besar dan (perhatian) BANYAK kelas yang berbeda dalam pelatihan.  Karena  jika tidak, akan ada banyak definisi yang salah dalam praktiknya.  Sebagai contoh, Anda dilatih tentang rakun dan matahari, dan jika ada seseorang di pintu masuk, maka ia dapat dengan probabilitas yang sama ditentukan oleh sistem seperti yang satu atau yang lain.  Meskipun pada kenyataannya - tidak satu atau yang lain. </p><br><h3 id="3--sozdanie-modeli-vruchnuyu">  3. Membuat model secara manual </h3><br><p><img src="https://habrastorage.org/webt/m_/ku/r_/m_kur_ks0vdyiqoiw7h5pvbwoey.jpeg"></p><br><p>  Saat Anda perlu memperbaiki sendiri model untuk pengenalan gambar, manipulasi yang lebih kompleks dengan pemilihan gambar input ikut berperan. <br>  Sebagai contoh, kami tidak ingin memiliki batasan pada volume sampel input (seperti pada paragraf sebelumnya), atau kami ingin melatih model lebih tepat dengan mengatur sendiri jumlah zaman dan parameter pelatihan lainnya. <br>  Dalam pendekatan ini, ada beberapa contoh dari Tensorflow yang menggambarkan prosedur dan hasil akhirnya. <br>  Berikut ini beberapa contoh: </p><br><ul><li>  Codelab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tensorflow</a> keren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">untuk Penyair</a> . <br></li></ul><br><br><p>  Ini memberikan contoh tentang cara membuat pengelompokan jenis warna berdasarkan pada basis data ImageNet yang terbuka - siapkan gambar dan kemudian latih modelnya.  Juga sedikit disebutkan tentang bagaimana Anda dapat bekerja dengan alat yang agak menarik - TensorBoard.  Dari fungsinya yang paling sederhana - ini menunjukkan dengan jelas struktur model yang sudah Anda selesaikan, serta proses pembelajaran dalam banyak cara. </p><br><ul><li><p>  Kodlab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tensorflow untuk Penyair 2</a> - terus bekerja dengan penggolong warna.  Ini menunjukkan bagaimana jika Anda memiliki file grafik dan labelnya (yang diperoleh di codelab sebelumnya), Anda dapat menjalankan aplikasi di android.  Salah satu poin dari codelab adalah konversi dari format grafik "biasa" ".pb" ke format lite Tensorflow (yang melibatkan beberapa optimasi file untuk mengurangi ukuran file grafik terakhir, karena perangkat seluler memerlukan ini). </p><br></li><li><p>  Pengakuan tulisan tangan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MNIST</a> . <br></p><br><img src="https://habrastorage.org/webt/bz/ah/mx/bzahmxc0xozicgssbkzfqbgi1qw.gif"></li></ul><br><br><p>  Lobak berisi model asli (yang telah disiapkan untuk tugas ini), instruksi tentang cara melatihnya, mengubahnya, dan cara menjalankan proyek untuk Android pada akhirnya untuk memeriksa bagaimana semuanya bekerja </p><br><p>  Berdasarkan contoh-contoh ini, Anda dapat mengetahui cara bekerja dengan model khusus di Tensorflow dan mencoba membuat sendiri atau mengambil salah satu model pra-terlatih yang dirakit di github: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Model dari Tensorflow</a> </p><br><p>  Berbicara tentang model "pra-terlatih".  Nuansa menarik saat menggunakan itu: </p><br><ul><li>  Struktur mereka sudah siap untuk tugas tertentu. </li><li>  Mereka sudah terlatih dalam ukuran sampel besar. <br>  Oleh karena itu, jika sampel Anda tidak cukup diisi, Anda dapat mengambil model pra-terlatih yang dekat dengan ruang lingkup tugas Anda.  Dengan menggunakan model ini, menambahkan aturan pelatihan Anda sendiri, Anda akan mendapatkan hasil yang lebih baik daripada mencoba melatih model dari awal. </li></ul><br><h3 id="4--object-detection-api---cozdanie-modeli-vruchnuyu">  4. Object Detection API + pembuatan model manual </h3><br><p>  Namun, semua paragraf sebelumnya tidak memberikan hasil yang diinginkan.  Sejak awal sulit memahami apa yang perlu dilakukan dan dengan pendekatan apa.  Kemudian artikel keren di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Object Detection API</a> ditemukan, yang menceritakan bagaimana menemukan beberapa kategori pada satu gambar, serta beberapa contoh dari kategori yang sama.  Dalam proses pengerjaan sampel ini, artikel sumber dan tutorial video tentang mengenali objek khusus ternyata lebih nyaman (tautan akan ada di akhir). </p><br><p>  Tetapi pekerjaan itu tidak dapat diselesaikan tanpa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel tentang pengakuan Pikachu</a> - karena nuansa yang sangat penting ditunjukkan di sana, yang karena alasan tertentu tidak disebutkan di mana pun dalam satu panduan atau contoh.  Dan tanpa itu, semua pekerjaan yang dilakukan akan sia-sia. </p><br><p>  Jadi, sekarang akhirnya tentang apa yang masih harus dilakukan dan apa yang terjadi di jalan keluar. </p><br><ol><li>  Pertama, tepung dari instalasi Tensorflow.  Siapa yang tidak dapat menginstalnya, atau menggunakan skrip standar untuk membuat, melatih model - hanya bersabar dan google.  Hampir setiap masalah telah ditulis dalam masalah di githib atau di stackoverflow. <br></li></ol><br>  Menurut instruksi untuk pengenalan objek, kita perlu menyiapkan sampel input sebelum melatih model.  Artikel-artikel ini menjelaskan secara rinci bagaimana melakukan ini menggunakan alat yang nyaman - labelImg  Satu-satunya kesulitan di sini adalah melakukan pekerjaan yang sangat panjang dan teliti dalam menyoroti batas-batas objek yang kita butuhkan.  Dalam hal ini, perangko pada gambar dokumen. <br><br><img src="https://habrastorage.org/webt/ge/hh/x_/gehhx_5fqfezu1sbh5tvoofss20.png"><br>  Langkah selanjutnya, menggunakan skrip yang sudah jadi, kami mengekspor data dari langkah 2 pertama ke file csv, kemudian ke TFRecords - format data input Tensorflow.  Tidak ada kesulitan yang muncul di sini. <br>  Pilihan model pra-pelatihan, atas dasar mana kami akan melakukan pra-pelatihan grafik, serta pelatihan itu sendiri.  Di sinilah jumlah kesalahan terbesar yang tidak diketahui dapat terjadi, penyebab paket yang dihapus (atau bengkok diinstal) yang diperlukan untuk bekerja.  Tetapi Anda akan berhasil, jangan putus asa, hasilnya sepadan. <br><br><img src="https://habrastorage.org/webt/9y/qw/1b/9yqw1boyubfcrrf5jcaylkjjtyo.jpeg"><br>  Ekspor file yang diterima setelah pelatihan ke format 'pb'.  Cukup pilih file terakhir 'ckpt' dan ekspor. <br>  Menjalankan contoh pekerjaan di Android. <br>  Mengunduh sampel pengenal objek resmi dari Tensorflow github - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TF Detect</a> .  Masukkan model dan file Anda dengan label di sana.  Tapi  Tidak akan ada yang berhasil. <br><br><img src="https://habrastorage.org/webt/kj/3k/o4/kj3ko4d3ywoap8ff6oknuwova7c.gif"><br><br><p>  Di sinilah lelucon terbesar dalam semua pekerjaan baru saja terjadi, cukup aneh - yah, sampel Tensorflow tidak mau bekerja dengan cara apa pun.  Semuanya telah jatuh.  Hanya Pikachu yang perkasa dengan artikelnya yang berhasil membantu mewujudkan semuanya. <br>  Baris pertama dalam file labels.txt harus berupa tulisan "???", karena  secara default di Object Detection API, jumlah id objek tidak dimulai dengan 0 seperti biasa, tetapi dengan 1. Karena fakta bahwa kelas nol dicadangkan, pertanyaan ajaib harus ditunjukkan.  Yaitu  file tag Anda akan terlihat seperti ini: </p><br><pre><code class="hljs">??? stamp</code> </pre> <br><p>  Dan kemudian - jalankan sampel dan lihat pengakuan objek dan tingkat kepercayaan yang diterima. </p><br><p><img src="https://habrastorage.org/webt/ly/kr/dm/lykrdma-x9h8epuqsuah3gkr3bk.png"><img src="https://habrastorage.org/webt/ne/lm/7v/nelm7v8rpjiuhzhevlptp0dc-fa.png"><img src="https://habrastorage.org/webt/9t/ci/4r/9tci4rxzhixufdjhb5ecpdof0ik.png"></p><br><p>  Dengan demikian, hasilnya adalah aplikasi sederhana yang, ketika Anda mengarahkan kamera, mengenali batas cap pada dokumen dan menunjukkannya bersama dengan akurasi pengenalan. <br>  Dan jika kita mengecualikan waktu yang dihabiskan untuk mencari pendekatan yang tepat dan mencoba meluncurkannya, maka, secara keseluruhan, pekerjaannya ternyata cukup cepat dan benar-benar tidak rumit.  Anda hanya perlu tahu nuansa sebelum mulai bekerja. </p><br><p>  Sudah sebagai bagian tambahan (di sini Anda sudah bisa menutup artikel jika Anda bosan dengan informasinya), saya ingin menulis beberapa hacks kehidupan yang membantu dalam menangani semua ini. </p><br><ul><li><p>  cukup sering skrip tensorflow tidak berfungsi karena dijalankan dari direktori yang salah.  Selain itu, itu berbeda pada PC yang berbeda: seseorang perlu menjalankan dari <code>tensroflowmodels/models/research</code> direktori <code>tensroflowmodels/models/research</code> untuk bekerja, dan seseorang <code>tensroflowmodels/models/research/object-detection</code> level yang lebih dalam dari <code>tensroflowmodels/models/research/object-detection</code> </p><br></li><li><p>  ingat bahwa untuk setiap terminal terbuka Anda perlu mengekspor jalur lagi menggunakan perintah </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">export</span></span> PYTHONPATH=/  /tensroflowmodels/models/research/slim:<span class="hljs-variable"><span class="hljs-variable">$PYTHONPATH</span></span></code> </pre> <br></li><li><p>  jika Anda tidak menggunakan grafik Anda sendiri dan ingin mencari tahu informasi tentangnya (misalnya, " <code>input_node_name</code> ", yang diperlukan nanti), jalankan dua perintah dari folder root: </p><br><pre> <code class="hljs powershell">bazel build tensorflow/tools/graph_transforms:summarize_graph bazel<span class="hljs-literal"><span class="hljs-literal">-bin</span></span>/tensorflow/tools/graph_transforms/summarize_graph -<span class="hljs-literal"><span class="hljs-literal">-in_graph</span></span>=<span class="hljs-string"><span class="hljs-string">"/  /frozen_inference_graph.pb"</span></span></code> </pre> <br><p>  di mana " <code>/  /frozen_inference_graph.pb</code> " adalah jalur ke grafik yang ingin Anda ketahui </p><br></li><li><p>  Untuk melihat informasi tentang grafik, Anda dapat menggunakan Tensorboard. </p><br><pre> <code class="hljs powershell">python import_pb_to_tensorboard.py -<span class="hljs-literal"><span class="hljs-literal">-model_dir</span></span>=output/frozen_inference_graph.pb -<span class="hljs-literal"><span class="hljs-literal">-log_dir</span></span>=training</code> </pre> <br><p>  di mana Anda perlu menentukan jalur ke grafik ( <code>model_dir</code> ) dan jalur ke file yang diterima selama pelatihan ( <code>log_dir</code> ).  Kemudian cukup buka localhost di browser dan lihat minat Anda. </p><br></li></ul><br><p>  Dan bagian terakhir - bekerja dengan skrip python dalam instruksi Object Detection API - lembar contekan kecil di bawah ini dengan perintah dan tips telah disiapkan untuk Anda. </p><br><div class="spoiler">  <b class="spoiler_title">Lembar curang</b> <div class="spoiler_text"><p>  Ekspor dari labelimg ke csv (dari direktori object_detection) </p><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">python</span></span> xml_to_csv.py</code> </pre> <br><p>  Lebih lanjut, semua langkah yang tercantum di bawah ini harus dilakukan dari folder Tensorflow yang sama (" <code>tensroflowmodels/models/research/object-detection</code> " atau satu tingkat lebih tinggi - tergantung pada bagaimana Anda pergi) - itu saja gambar pemilihan input, TFRecords, dan file lain harus disalin di dalam direktori ini sebelum mulai bekerja. </p><br><p>  Ekspor dari csv ke tfrecord </p><br><pre> <code class="hljs powershell">python generate_tfrecord.py -<span class="hljs-literal"><span class="hljs-literal">-csv_input</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/train_labels.csv -<span class="hljs-literal"><span class="hljs-literal">-output_path</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/train.record python generate_tfrecord.py -<span class="hljs-literal"><span class="hljs-literal">-csv_input</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/test_labels.csv -<span class="hljs-literal"><span class="hljs-literal">-output_path</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/test.record</code> </pre> <br><p>  * Jangan lupa untuk mengubah baris 'train' dan 'test' di jalur dalam file itu sendiri (generate_tfrecord.py), serta <br>  nama kelas yang dikenali dalam fungsi <code>class_text_to_int</code> (yang harus diduplikasi dalam file <code>pbtxt</code> yang akan Anda buat sebelum melatih grafik). </p><br><p>  Pelatihan </p><br><pre> <code class="hljs powershell">python legacy/train.py —logtostderr -<span class="hljs-literal"><span class="hljs-literal">-train_dir</span></span>=training/ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/ssd_mobilenet_v1_coco.config</code> </pre> <br><p>  ** Sebelum pelatihan, jangan lupa memeriksa file " <code>training/object-detection.pbtxt</code> " - harus ada semua kelas yang dikenali dan file " <code>training/ssd_mobilenet_v1_coco.config</code> " - di sana Anda perlu mengubah parameter " <code>num_classes</code> " ke jumlah kelas Anda. </p><br><p>  Ekspor model ke pb </p><br><pre> <code class="hljs powershell">python export_inference_graph.py \ -<span class="hljs-literal"><span class="hljs-literal">-input_type</span></span>=image_tensor \ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/pipeline.config \ -<span class="hljs-literal"><span class="hljs-literal">-trained_checkpoint_prefix</span></span>=training/model.ckpt<span class="hljs-literal"><span class="hljs-literal">-110</span></span> \ -<span class="hljs-literal"><span class="hljs-literal">-output_directory</span></span>=output</code> </pre> </div></div><br><p>  Terima kasih atas minat Anda pada topik ini! </p><br><p>  Referensi </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Artikel asli tentang pengenalan objek</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Siklus video ke artikel tentang pengakuan objek dalam bahasa Inggris</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Himpunan skrip yang digunakan dalam artikel asli</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id427449/">https://habr.com/ru/post/id427449/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id427437/index.html">Mengkonfigurasi server tertaut: ms sql server dan teradata</a></li>
<li><a href="../id427439/index.html">Seluruh kebenaran tentang RTOS. Artikel # 16. Sinyal</a></li>
<li><a href="../id427441/index.html">Konvergensi dengan Kubernet</a></li>
<li><a href="../id427443/index.html">Pembedahan kesuksesan</a></li>
<li><a href="../id427447/index.html">PVS-Studio termasuk dukungan untuk GNU Arm Embedded Toolchain</a></li>
<li><a href="../id427451/index.html">Hubungkan tugas phpStorm ke Bitrix24</a></li>
<li><a href="../id427453/index.html">Bagaimana saya melakukan transmisi suara pada Raspberry Pi</a></li>
<li><a href="../id427457/index.html">Gelombang Ketiga AI dan Sistem untuk Keamanan Negara</a></li>
<li><a href="../id427459/index.html">Lampu LED diall dari toko Castorama</a></li>
<li><a href="../id427461/index.html">Keindahan fungsi TIDAK-anonim dalam JavaScript</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
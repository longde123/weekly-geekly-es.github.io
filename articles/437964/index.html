<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚òπÔ∏è üïπÔ∏è ü§æüèø Libro "Machine Learning y TensorFlow" üôèüèº üï¢ üë©üèæ‚Äçü§ù‚Äçüë®üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Conocer el aprendizaje autom√°tico y la biblioteca TensorFlow es similar a las primeras lecciones en una escuela de manejo, cuando sufres de estacionam...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Libro "Machine Learning y TensorFlow"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/437964/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/webt/cy/lg/n3/cylgn38lpjyhq7gveb9cmmt_ml8.jpeg" align="left" alt="imagen"></a>  Conocer el aprendizaje autom√°tico y la biblioteca TensorFlow es similar a las primeras lecciones en una escuela de manejo, cuando sufres de estacionamiento paralelo, trata de cambiar de marcha en el momento adecuado y no mezclar los espejos, recordando fren√©ticamente la secuencia de acciones, mientras tu pie tiembla nerviosamente en los pedales de gas.  Este es un ejercicio dif√≠cil pero necesario.  Entonces, en el aprendizaje autom√°tico: antes de usar sistemas modernos de reconocimiento facial o algoritmos de pron√≥stico en el mercado de valores, tendr√° que lidiar con las herramientas apropiadas y un conjunto de instrucciones para luego crear sus propios sistemas sin problemas. <br><br>  Los principiantes en el aprendizaje autom√°tico apreciar√°n la orientaci√≥n aplicada de este libro, ya que su prop√≥sito es presentar los conceptos b√°sicos y luego resolver r√°pidamente problemas reales.  A partir de una revisi√≥n de los conceptos de aprendizaje autom√°tico y los principios de trabajar con TensorFlow, pasar√° a algoritmos b√°sicos, estudiar√° redes neuronales y podr√° resolver de forma independiente los problemas de clasificaci√≥n, agrupaci√≥n, regresi√≥n y pron√≥stico. <br><a name="habracut"></a><br><h3>  Extracto  Redes neuronales convolucionales </h3><br>  Comprar en tiendas despu√©s de un d√≠a agotador es una tarea muy onerosa.  Mis ojos son atacados por demasiada informaci√≥n.  Ventas, cupones, una variedad de colores, ni√±os peque√±os, luces parpadeantes y pasillos llenos de personas: estos son solo algunos ejemplos de todas las se√±ales que se env√≠an a la corteza visual del cerebro, independientemente de si quiero o no prestarle atenci√≥n.  El sistema visual absorbe una gran cantidad de informaci√≥n. <br><br>  Seguramente conoces la frase "es mejor ver una vez que escuchar cien veces".  Esto puede ser cierto para usted y para m√≠ (es decir, para las personas), pero ¬øpuede la m√°quina encontrar significado en las im√°genes?  Nuestros fotorreceptores visuales seleccionan longitudes de onda de luz, pero esta informaci√≥n, aparentemente, no se extiende a nuestra conciencia.  Al final, no puedo decir exactamente qu√© longitudes de onda de luz estoy observando.  Del mismo modo, la c√°mara recibe p√≠xeles de imagen.  Pero, en cambio, queremos recibir algo de un nivel superior, por ejemplo, nombres o posiciones de objetos.  ¬øC√≥mo obtenemos informaci√≥n percibida a nivel humano a partir de p√≠xeles? <br><br>  Para obtener un cierto significado de los datos de origen, ser√° necesario dise√±ar un modelo de red neuronal.  En cap√≠tulos anteriores, se introdujeron varios tipos de modelos de redes neuronales, como los modelos completamente conectados (cap√≠tulo 8) y los codificadores autom√°ticos (cap√≠tulo 7).  En este cap√≠tulo, presentaremos otro tipo de modelo llamado red neuronal convolucional (CNN).  Este modelo funciona muy bien con im√°genes y otros datos sensoriales como el sonido.  Por ejemplo, el modelo CNN puede clasificar de manera confiable qu√© objeto se muestra en la imagen. <br><br>  El modelo CNN, que se discutir√° en este cap√≠tulo, recibir√° capacitaci√≥n para clasificar las im√°genes en una de las 10 categor√≠as posibles.  En este caso, "una imagen es mejor que una sola palabra", ya que solo tenemos 10 opciones posibles.  Este es un peque√±o paso hacia la percepci√≥n a nivel humano, pero tenemos que comenzar con algo, ¬øverdad? <br><br><h3>  9.1.  Desventajas de las redes neuronales </h3><br>  El aprendizaje autom√°tico es una lucha eterna para el desarrollo de un modelo que tenga suficiente expresividad para presentar datos, pero al mismo tiempo no sea tan universal como para volver a entrenar y memorizar patrones.  Las redes neuronales se ofrecen como una forma de aumentar la expresividad;  aunque, como puede suponer, sufren mucho por las trampas del reciclaje. <br><br><blockquote>  NOTA La reentrenamiento ocurre cuando un modelo entrenado es excepcionalmente preciso en un conjunto de datos de entrenamiento y malo en un conjunto de datos de validaci√≥n.  Este modelo es probablemente demasiado universal para la peque√±a cantidad de datos disponibles, y al final solo recuerda los datos de entrenamiento. </blockquote><br>  Para comparar la versatilidad de los dos modelos de aprendizaje autom√°tico, puede usar un algoritmo heur√≠stico r√°pido y tosco para calcular la cantidad de par√°metros que deben determinarse como resultado del entrenamiento.  Como se muestra en la fig.  9.1, una red neuronal completamente conectada que toma una imagen de 256 √ó 256 y la mapea en una capa de 10 neuronas tendr√° 256 √ó 256 √ó 10 = 655,360 par√°metros.  Comp√°relo con un modelo que contiene solo cinco par√°metros.  Se puede suponer que una red neuronal completamente conectada puede presentar datos m√°s complejos que un modelo de cinco par√°metros. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_c/ey/qe/_ceyqe8jc1s-xzasfzbv4vezhum.png" alt="imagen"></div><br>  La siguiente secci√≥n discute las redes neuronales convolucionales, que son una forma razonable de reducir el n√∫mero de par√°metros.  En lugar de tratar con redes completamente conectadas, CNN reutiliza los mismos par√°metros repetidamente. <br><br><h3>  9.2.  Redes neuronales convolucionales </h3><br>  La idea principal que subyace a las redes neuronales convolucionales es que la comprensi√≥n local de la imagen es suficiente.  La ventaja pr√°ctica de las redes neuronales convolucionales es que, al tener varios par√°metros, es posible reducir significativamente el tiempo de entrenamiento, as√≠ como la cantidad de datos necesarios para entrenar el modelo. <br><br>  En lugar de redes completamente conectadas con pesos de cada p√≠xel, CNN tiene un n√∫mero suficiente de pesos necesarios para ver un peque√±o fragmento de la imagen.  Es como leer un libro con una lupa: al final, lees toda la p√°gina, pero en cualquier momento, solo miras un peque√±o fragmento. <br><br>  Imagine una imagen de 256 √ó 256. En lugar de usar el c√≥digo TensorFlow que procesa toda la imagen a la vez, puede escanear el fragmento de imagen por fragmento, por ejemplo, una ventana de 5 √ó 5. Una ventana de 5 √ó 5 se desliza sobre la imagen (generalmente de izquierda a derecha y de arriba a abajo), como mostrado en la fig.  9.2.  Lo "r√°pido" que se desliza se llama longitud de zancada.  Por ejemplo, una longitud de paso de 2 significa que una ventana deslizante de 5 √ó 5 se mueve 2 p√≠xeles a la vez hasta que haya pasado toda la imagen.  En TensorFlow, como se mostrar√° pronto, puede ajustar la longitud del paso y el tama√±o de la ventana utilizando la biblioteca de funciones incorporada. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tl/lj/br/tlljbr-3r61p02umh30yi-wtmhi.png" alt="imagen"></div><br>  Esta ventana 5 √ó 5 tiene una matriz de peso 5 √ó 5 asociada. <br><br><blockquote>  DEFINICI√ìN Una convoluci√≥n es una suma ponderada de los valores de intensidad de p√≠xeles en una imagen a medida que la ventana pasa a trav√©s de toda la imagen.  Resulta que este proceso de convoluci√≥n de la imagen con la matriz de pesos crea otra imagen (del mismo tama√±o, que depende del plegado).  La coagulaci√≥n es el proceso de aplicaci√≥n de convoluci√≥n. </blockquote><br>  Todas las manipulaciones de la ventana deslizante se producen en la capa convolucional de la red neuronal.  Una red neuronal convolucional t√≠pica tiene varias capas convolucionales.  Cada capa convolucional generalmente crea muchas convoluciones adicionales, por lo tanto, la matriz de ponderaci√≥n es un tensor de 5 √ó 5 √ó n, donde n es el n√∫mero de convoluciones. <br><br>  Como ejemplo, deje que la imagen atraviese una capa convolucional con una matriz de peso de 5 √ó 5 √ó 64 dimensiones. Esto crea 64 circunvoluciones con una ventana deslizante de 5 √ó 5. Por lo tanto, el modelo correspondiente tiene 5 √ó 5 √ó 64 = 1600 par√°metros, que es significativamente menor que el n√∫mero de par√°metros de una red totalmente conectada : 256 √ó 256 = 65.536. <br><br>  El atractivo de las redes neuronales convolucionales (CNN) es que el n√∫mero de par√°metros utilizados por el modelo no depende del tama√±o de la imagen original.  ¬°Puede ejecutar la misma red neuronal convolucional en im√°genes de 300 √ó 300, y el n√∫mero de par√°metros en la capa convolucional no cambiar√°! <br><br><h3>  9.3.  Preparaci√≥n de imagen </h3><br>  Antes de comenzar a usar el modelo CNN con TensorFlow, prepare algunas im√°genes.  Los listados en esta secci√≥n lo ayudar√°n a configurar un conjunto de datos de capacitaci√≥n para el resto del cap√≠tulo. <br><br>  En primer lugar, descargue el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conjunto</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">datos</a> CIFAR-10 de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">www.cs.toronto.edu/~kriz/cifar-10-</a> python.tar.gz.  Este conjunto contiene 60,000 im√°genes distribuidas uniformemente en 10 categor√≠as, que es un recurso bastante grande para tareas de clasificaci√≥n.  Luego, el archivo de imagen debe colocarse en el directorio de trabajo.  En la fig.  La Figura 9.3 muestra ejemplos de im√°genes de este conjunto de datos. <br><br>  Ya usamos el conjunto de datos CIFAR-10 en el cap√≠tulo anterior sobre codificadores autom√°ticos, y ahora mira este c√≥digo nuevamente.  La siguiente lista se toma directamente de la documentaci√≥n de CIFAR-10 ubicada en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">www.cs.toronto.edu/~kriz/cifar.html</a> .  Ponga el c√≥digo en el archivo cifar_tools.py. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xs/rd/6n/xsrd6nmuunpim-aeqepzxwj1acy.png" alt="imagen"></div><br>  Listado 9.1.  Cargando im√°genes de un archivo CIFAR-10 en Python <br><br><pre><code class="plaintext hljs">import pickle def unpickle(file): fo = open(file, 'rb') dict = pickle.load(fo, encoding='latin1') fo.close() return dict</code> </pre> <br>  Las redes neuronales son propensas a la reentrenamiento, por lo que es importante hacer todo lo posible para minimizar este error.  Para hacer esto, no olvides limpiar los datos antes de procesarlos. <br><br>  La limpieza de datos es el proceso principal de la tuber√≠a de aprendizaje autom√°tico.  El c√≥digo en el Listado 9.2 usa los siguientes tres pasos para limpiar un conjunto de im√°genes: <br><br>  1. Si tiene una imagen en color, intente convertirla a tonos de gris para reducir la dimensionalidad de los datos de entrada y, por lo tanto, reducir el n√∫mero de par√°metros. <br><br>  2. Piense en recortar la imagen en el centro, porque los bordes de la imagen no proporcionan ninguna informaci√≥n √∫til. <br><br>  3. Normalice la entrada restando la media y dividiendo por la desviaci√≥n est√°ndar de cada muestra de datos para que los gradientes no cambien demasiado durante la propagaci√≥n hacia atr√°s. <br><br>  La siguiente lista muestra c√≥mo borrar un conjunto de datos utilizando estos m√©todos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ba/nf/al/banfal_9g-9gy2lns0q_qv2qce8.png" alt="imagen"></div><br>  Guarde todas las im√°genes del conjunto de datos CIFAR-10 y ejecute la funci√≥n de limpieza.  La siguiente lista define un m√©todo conveniente para leer, limpiar y estructurar datos para usar en TensorFlow.  All√≠, debe incluir el c√≥digo del archivo cifar_tools.py. <br><br>  Listado 9.3.  Preprocesamiento de todos los archivos CIFAR-10 <br><br><pre> <code class="plaintext hljs">def read_data(directory): names = unpickle('{}/batches.meta'.format(directory))['label_names'] print('names', names) data, labels = [], [] for i in range(1, 6): filename = '{}/data_batch_{}'.format(directory, i) batch_data = unpickle(filename) if len(data) &gt; 0: data = np.vstack((data, batch_data['data'])) labels = np.hstack((labels, batch_data['labels'])) else: data = batch_data['data'] labels = batch_data['labels'] print(np.shape(data), np.shape(labels)) data = clean(data) data = data.astype(np.float32) return names, data, labels</code> </pre> <br>  En el archivo using_cifar.py, puede usar el m√©todo importando cifar_tools para esto.  Los listados 9.4 y 9.5 muestran c√≥mo obtener m√∫ltiples im√°genes de un conjunto de datos y visualizarlas. <br><br>  Listado 9.4.  Usando la funci√≥n auxiliar cifar_tools <br><br><pre> <code class="plaintext hljs">import cifar_tools names, data, labels = \ cifar_tools.read_data('your/location/to/cifar-10-batches-py')</code> </pre> <br>  Puede seleccionar arbitrariamente varias im√°genes y dibujarlas de acuerdo con la etiqueta.  La siguiente lista hace exactamente eso, para que pueda comprender mejor el tipo de datos con los que estar√° tratando. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9s/3c/ls/9s3clsibt-fy4tqxlnmggitpydm.png" alt="imagen"></div><br>  Al ejecutar este c√≥digo, crear√° el archivo cifar_examples.png, que se ver√° como la Fig.  9.3. <br><br>  ¬ªSe puede encontrar m√°s informaci√≥n sobre el libro en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el sitio web del editor</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Contenidos</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Extracto</a> <br><br>  Cup√≥n de 20% de descuento para vendedores ambulantes - <b>Machine Learning</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/437964/">https://habr.com/ru/post/437964/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../437952/index.html">C√≥mo probar en AutoCar: MindMap, an√°lisis de c√≥digo est√°tico y MockServer</a></li>
<li><a href="../437956/index.html">"Implementando Splunk 7" - el primer libro sobre Splunk en ruso</a></li>
<li><a href="../437958/index.html">Autorizaci√≥n en ESIA en un servidor de terminal con firma digital de acuerdo con GOST-2012</a></li>
<li><a href="../437960/index.html">Asesoramiento del director t√©cnico de una empresa de TI para graduados de bootcamp</a></li>
<li><a href="../437962/index.html">PVS-Studio ROI</a></li>
<li><a href="../437968/index.html">PVS-Studio ROI</a></li>
<li><a href="../437972/index.html">PHP para principiantes. La sesi√≥n</a></li>
<li><a href="../437974/index.html">¬øC√≥mo ganar WorldSkills digitales? En un ejemplo pr√°ctico</a></li>
<li><a href="../437976/index.html">"Vkontakte" permiti√≥ ocultar registros individuales de la polic√≠a</a></li>
<li><a href="../437978/index.html">Bienvenido a SphinxSearch-meetup SuperJob</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
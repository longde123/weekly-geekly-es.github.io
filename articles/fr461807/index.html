<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚òîÔ∏è üíö üë• Comment les priorit√©s des pods chez Kubernetes ont caus√© des temps d'arr√™t chez Grafana Labs üôÇ ü•à üêß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Remarque perev. : Nous pr√©sentons √† votre attention des d√©tails techniques sur les raisons de la r√©cente panne du service cloud, servi par les cr√©ateu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment les priorit√©s des pods chez Kubernetes ont caus√© des temps d'arr√™t chez Grafana Labs</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/461807/">  <i><b>Remarque</b></i>  <i><b>perev.</b></i>  <i>: Nous pr√©sentons √† votre attention des d√©tails techniques sur les raisons de la r√©cente panne du service cloud, servi par les cr√©ateurs de Grafana.</i>  <i>Ceci est un exemple classique de la fa√ßon dont une nouvelle fonctionnalit√© apparemment extr√™mement utile con√ßue pour am√©liorer la qualit√© des infrastructures ... peut faire beaucoup de mal si l'on ne pr√©voit pas les nombreuses nuances de son application dans les r√©alit√©s de la production.</i>  <i>C'est merveilleux quand de tels documents apparaissent qui vous permettent non seulement d'apprendre de vos erreurs.</i>  <i>Les d√©tails se trouvent dans la traduction de ce texte du vice-pr√©sident des produits de Grafana Labs.</i> <br><br><img src="https://habrastorage.org/webt/yb/jj/1h/ybjj1hh4m7ro1eym14eiercw7po.jpeg"><br><br>  Vendredi 19 juillet, le service Hosted Prometheus de Grafana Cloud a cess√© de fonctionner pendant environ 30 minutes.  Je m'excuse aupr√®s de tous les clients qui ont souffert de l'√©chec.  Notre t√¢che est de fournir les outils n√©cessaires au suivi, et nous comprenons que leur inaccessibilit√© complique votre vie.  Nous prenons cet incident tr√®s au s√©rieux.  Cette note explique ce qui s'est pass√©, comment nous y avons r√©agi et ce que nous faisons pour que cela ne se reproduise plus. <a name="habracut"></a><br><br><h2>  Contexte </h2><br>  Le service Grafana Cloud Hosted Prometheus est bas√© sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cortex</a> , un projet de la CNCF visant √† cr√©er un service Prometheus √©volutif, hautement accessible et multi-locataire.  L'architecture Cortex est constitu√©e d'un ensemble de microservices distincts, chacun remplissant sa fonction: r√©plication, stockage, requ√™tes, etc.  Cortex se d√©veloppe activement, il a constamment de nouvelles opportunit√©s et am√©liore sa productivit√©.  Nous d√©ployons r√©guli√®rement de nouvelles versions de Cortex sur des clusters afin que les clients puissent profiter de ces opportunit√©s - heureusement, Cortex peut mettre √† jour sans temps d'arr√™t. <br><br>  Pour des mises √† jour fluides, le service Ingester Cortex n√©cessite une r√©plique Ingester suppl√©mentaire pendant le processus de mise √† jour.  <i>( <b>Remarque</b> : <a href="">Ingester</a> est le composant principal de Cortex. Sa t√¢che consiste √† collecter un flux constant d'√©chantillons, √† les regrouper en morceaux de Prometheus et √† les stocker dans une base de donn√©es comme DynamoDB, BigTable ou Cassandra.)</i> Cela permet aux Ingesters plus √¢g√©s. transmettre les donn√©es actuelles aux nouveaux Ing√©nieurs.  Il convient de noter que les ing√©rents exigent des ressources.  Pour leur travail, il est n√©cessaire d'avoir 4 c≈ìurs et 15 Go de m√©moire par pod, soit  25% de la puissance du processeur et de la m√©moire de la machine de base dans le cas de nos clusters Kubernetes.  En g√©n√©ral, nous avons g√©n√©ralement beaucoup plus de ressources inutilis√©es dans un cluster que 4 c≈ìurs et 15 Go de m√©moire, de sorte que nous pouvons facilement ex√©cuter ces ing√©rateurs suppl√©mentaires lors des mises √† jour. <br><br>  Cependant, il arrive souvent qu'en fonctionnement normal aucune de ces machines ne dispose de ces 25% de ressources non r√©clam√©es.  Oui, nous ne nous effor√ßons pas: le CPU et la m√©moire sont toujours utiles pour d'autres processus.  Pour r√©soudre ce probl√®me, nous avons d√©cid√© d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kubernetes Pod Priorities</a> .  L'id√©e est de donner aux Ingesters une priorit√© plus √©lev√©e que les autres microservices (sans √©tat).  Lorsque nous devons ex√©cuter un Ingester suppl√©mentaire (N + 1), nous for√ßons temporairement d'autres pods plus petits.  Ces pods sont transf√©r√©s vers des ressources libres sur d'autres machines, laissant un ¬´trou¬ª suffisamment grand pour lancer un Ingester suppl√©mentaire. <br><br>  Jeudi 18 juillet, nous avons lanc√© quatre nouveaux niveaux de priorit√© dans nos clusters: <b>critique</b> , <b>√©lev√©</b> , <b>moyen</b> et <b>faible</b> .  Ils ont √©t√© test√©s sur un cluster interne sans trafic client pendant environ une semaine.  Par d√©faut, les pods sans priorit√© donn√©e ont re√ßu <b>une</b> priorit√© <b>moyenne</b> ; une classe avec une priorit√© <b>√©lev√©e a</b> √©t√© d√©finie pour les Ing√©nieurs.  <b>Critical</b> √©tait r√©serv√© √† la surveillance (Prometheus, Alertmanager, node-exporter, kube-state-metrics, etc.).  Notre configuration est ouverte, et voir PR <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br><h2>  Accident </h2><br>  Vendredi 19 juillet, l'un des ing√©nieurs a lanc√© un nouveau cluster Cortex d√©di√© pour un gros client.  La configuration de ce cluster n'incluait pas les nouvelles priorit√©s des pods, donc tous les nouveaux pods ont re√ßu la priorit√© par d√©faut - <b>medium</b> . <br><br>  Le cluster Kubernetes ne disposait pas de suffisamment de ressources pour le nouveau cluster Cortex, et le cluster de production Cortex existant n'a pas √©t√© mis √† jour (les utilisateurs ont √©t√© laiss√©s sans priorit√© <b>√©lev√©e</b> ).  √âtant donn√© que les ingesters du nouveau cluster sont pass√©s par d√©faut √† <b>une</b> priorit√© <b>moyenne</b> et que les pods existants en production ont fonctionn√© sans priorit√© du tout, les ingesters du nouveau cluster ont chass√© les ingesters du cluster de production Cortex existant. <br><br>  ReplicaSet pour l'Ingester pr√©empt√© dans le cluster de production a d√©tect√© le module pr√©empt√© et en a cr√©√© un nouveau pour conserver le nombre de copies sp√©cifi√©.  Le nouveau pod a √©t√© d√©fini sur <b>une</b> priorit√© <b>moyenne</b> par d√©faut, et le prochain "ancien" Ing√©nieur en production a perdu des ressources.  Le r√©sultat a √©t√© <b>un processus semblable √† une avalanche</b> qui a conduit √† √©vincer toutes les gousses d'Ingester pour les clusters de production de Cortex. <br><br>  Les ingestion gardent l'√©tat et stockent les donn√©es des 12 derni√®res heures.  Cela nous permet de les compresser plus efficacement avant d'√©crire dans un stockage √† long terme.  Pour ce faire, Cortex r√©partit les donn√©es de la s√©rie √† l'aide d'une table de hachage distribu√©e (DHT) et r√©plique chaque s√©rie sur trois ing√©rateurs √† l'aide de la coh√©rence de quorum de style Dynamo.  Cortex n'√©crit pas de donn√©es sur les Ingesters, qui sont d√©sactiv√©s.  Ainsi, lorsqu'un grand nombre d'Ingesters quittent la DHT, Cortex ne peut pas fournir une r√©plication suffisante des enregistrements et ils ¬´tombent¬ª. <br><br><h2>  D√©tection et √©limination </h2><br>  De nouvelles notifications Prometheus bas√©es sur le " <i>budget</i> bas√© sur l' <i>erreur</i> " (les d√©tails apparaissent dans un futur article) ont commenc√© √† sonner l'alarme 4 minutes apr√®s le d√©but de l'arr√™t.  Au cours des cinq minutes suivantes, nous avons effectu√© des diagnostics et √©tendu le cluster Kubernetes sous-jacent pour prendre en charge les clusters de production nouveaux et existants. <br><br>  Cinq minutes plus tard, les anciens Ingesters ont enregistr√© avec succ√®s leurs donn√©es, et les nouveaux ont d√©marr√©, et les clusters Cortex sont redevenus disponibles. <br><br>  Il a fallu 10 minutes suppl√©mentaires pour diagnostiquer et corriger les erreurs de m√©moire insuffisante (MOO) √† partir des proxys d'authentification inverse situ√©s en face de Cortex.  Les erreurs MOO ont √©t√© caus√©es par une augmentation de dix fois de QPS (comme nous le pensons, en raison de demandes trop agressives de la part des serveurs clients Prometheus). <br><br><h2>  Les cons√©quences </h2><br>  Le temps d'arr√™t total √©tait de 26 minutes.  Aucune donn√©e n'a √©t√© perdue.  Les utilisateurs ont r√©ussi √† t√©l√©charger toutes les donn√©es en m√©moire vers un stockage √† long terme.  Lors d'un arr√™t, les serveurs clients Prometheus ont enregistr√© les entr√©es <i>distantes</i> dans le tampon √† l'aide de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nouvelle API remote_write</a> bas√©e sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">WAL</a> (cr√©√©e par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Callum Styan</a> de Grafana Labs) et ont r√©p√©t√© les entr√©es ayant √©chou√© apr√®s l'√©chec. <br><br><img src="https://habrastorage.org/webt/ub/rv/3p/ubrv3po8fpxvn0r5ifuvwbcdogy.png"><br>  <i>Op√©rations d'√©criture du cluster de production</i> <br><br><h2>  Conclusions </h2><br>  Il est important d'apprendre de cet incident et de prendre les mesures n√©cessaires pour √©viter une r√©cidive. <br><br>  R√©trospectivement, nous devons admettre que nous n'aurions pas d√ª d√©finir la priorit√© par d√©faut √† <b>moyen</b> tant que tous les ingestionnaires en production n'ont pas obtenu une priorit√© <b>√©lev√©e</b> .  De plus, ils auraient d√ª s'occuper √† l'avance de leur priorit√© <b>√©lev√©e</b> .  Maintenant, tout est r√©par√©.  Nous esp√©rons que notre exp√©rience aidera d'autres organisations √† envisager l'utilisation des priorit√©s des pods dans Kubernetes. <br><br>  Nous ajouterons un niveau de contr√¥le suppl√©mentaire sur le d√©ploiement de tout objet suppl√©mentaire dont les configurations sont globales pour le cluster.  D√©sormais, ces changements seront √©valu√©s par plus de personnes.  En outre, la modification qui a conduit √† l'√©chec a √©t√© jug√©e trop insignifiante pour un document de projet distinct - elle n'a √©t√© discut√©e que dans le probl√®me GitHub.  D√©sormais, toutes ces modifications de configuration seront accompagn√©es d'une documentation de projet appropri√©e. <br><br>  Enfin, nous automatisons le redimensionnement du proxy d'authentification inverse pour √©viter les MOO pendant la congestion, ce dont nous avons √©t√© t√©moins, et analysons les param√®tres Prometheus par d√©faut li√©s √† la restauration et √† la mise √† l'√©chelle pour √©viter des probl√®mes similaires √† l'avenir. <br><br>  L'√©chec v√©cu a √©galement eu des cons√©quences positives: apr√®s avoir re√ßu les ressources n√©cessaires, Cortex s'est automatiquement r√©tabli sans aucune intervention suppl√©mentaire.  Nous avons √©galement acquis une exp√©rience pr√©cieuse avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Grafana Loki</a> , notre nouveau syst√®me d'agr√©gation de journaux, qui a contribu√© √† garantir que tous les ingestion se comportaient correctement pendant et apr√®s l'accident. <br><br><h2>  PS du traducteur </h2><br>  Lisez aussi dans notre blog: <br><br><ul><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Auto-scaling et gestion des ressources dans Kubernetes (revue et rapport vid√©o)</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kubernetes-adventure Dailymotion: construire des infrastructures dans les nuages ‚Äã‚Äã+ sur site</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Migration de Tinder vers Kubernetes</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 10: Reddit</a> . " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr461807/">https://habr.com/ru/post/fr461807/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr461793/index.html">Ivan Ponomarev √† propos de l'API Kafka Streams lors de la r√©union jug.msk.ru</a></li>
<li><a href="../fr461797/index.html">Contes de service. Un article frivole sur le travail s√©rieux</a></li>
<li><a href="../fr461801/index.html">DisplayPort-LVDS</a></li>
<li><a href="../fr461803/index.html">DVC (Data Version Control): versionnage des donn√©es et reproductibilit√© de l'exp√©rience</a></li>
<li><a href="../fr461805/index.html">Application d'int√©gration Monte Carlo dans le rendu</a></li>
<li><a href="../fr461813/index.html">Nouvelles du monde d'OpenStreetMap n ¬∞ 470 (07.16.2019 - 07.22.2019)</a></li>
<li><a href="../fr461815/index.html">Une r√©volution dans la conception des alimentations informatiques il y a un demi-si√®cle</a></li>
<li><a href="../fr461817/index.html">CMake et C ++ - fr√®res pour toujours</a></li>
<li><a href="../fr461819/index.html">Pourquoi la conception d'un site Web simple est meilleure scientifiquement</a></li>
<li><a href="../fr461821/index.html">Une nouvelle immunoth√©rapie a √©limin√© toutes les tumeurs chez une femme atteinte d'un cancer du sein m√©tastatique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
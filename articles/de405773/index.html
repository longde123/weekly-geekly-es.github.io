<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶á ü§∫ üìò Wie man einen Computer irref√ºhrt: die heimt√ºckische Wissenschaft, k√ºnstliche Intelligenz zu t√§uschen üê£ ü•¢ ü§∑üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Zu Beginn des 20. Jahrhunderts gab der deutsche Pferdetrainer und Mathematiker Wilhelm von Austin der Welt bekannt, dass er einem Pferd das Z√§hlen bei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie man einen Computer irref√ºhrt: die heimt√ºckische Wissenschaft, k√ºnstliche Intelligenz zu t√§uschen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/405773/"><img src="https://habrastorage.org/web/c38/08f/4a7/c3808f4a70d1426ca51c7b7f9abb7627.jpg"><br><br>  Zu Beginn des 20. Jahrhunderts gab der deutsche Pferdetrainer und Mathematiker Wilhelm von Austin der Welt bekannt, dass er einem Pferd das Z√§hlen beigebracht habe.  Von Austin reiste jahrelang durch Deutschland, um dieses Ph√§nomen zu demonstrieren.  Er bat sein Pferd mit dem Spitznamen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Clever Hans</a> (Rasse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orlov Traber</a> ), die Ergebnisse einfacher Gleichungen zu berechnen.  Antwortete Hans und stampfte mit dem Huf.  Zwei plus zwei?  Vier Treffer. <br><br>  Aber Wissenschaftler glaubten nicht, dass Hans so schlau war, wie von Austin behauptete.  Der Psychologe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Karl Stumpf</a> f√ºhrte eine gr√ºndliche Untersuchung durch, die als "Hans-Komitee" bezeichnet wurde.  Er entdeckte, dass Smart Hans keine Gleichungen l√∂st, sondern auf visuelle Signale reagiert.  Hans tippte auf seinen Huf, bis er die richtige Antwort bekam, woraufhin sein Trainer und eine begeisterte Menge in Schreie ausbrachen.  Und dann h√∂rte er einfach auf.  Als er diese Reaktionen nicht sah, klopfte er weiter. <br><a name="habracut"></a><br>  Die Informatik kann viel von Hans lernen.  Das beschleunigte Entwicklungstempo in diesem Bereich l√§sst darauf schlie√üen, dass der gr√∂√üte Teil der von uns erstellten KI ausreichend trainiert wurde, um die richtigen Antworten zu liefern, die Informationen jedoch nicht wirklich versteht.  Und es ist leicht zu t√§uschen. <br><br>  Algorithmen f√ºr maschinelles Lernen wurden schnell zu allsehenden Hirten der menschlichen Herde.  Die Software verbindet uns mit dem Internet, √ºberwacht Spam und sch√§dliche Inhalte in unseren E-Mails und wird bald unsere Autos fahren.  Ihre T√§uschung verschiebt das tektonische Fundament des Internets und bedroht unsere Sicherheit in der Zukunft. <br><br>  Kleine Forschungsgruppen - von der Pennsylvania State University, von Google, vom US-Milit√§r - entwickeln Pl√§ne zum Schutz vor m√∂glichen Angriffen auf KI.  In der Studie vorgebrachte Theorien besagen, dass ein Angreifer √§ndern kann, was ein Robomobil ‚Äûsieht‚Äú.  Oder aktivieren Sie die Spracherkennung auf dem Telefon und zwingen Sie es, eine sch√§dliche Website mit Sounds zu betreten, die nur f√ºr eine Person L√§rm sind.  Oder lassen Sie den Virus durch die Netzwerk-Firewall lecken. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/0e0/75b/0eb/0e075b0eb595f3aaeafaa8233e4df1b2.jpg" alt="Bild"><br>  <i>Links ist das Bild des Geb√§udes, rechts das modifizierte Bild, das das tiefe neuronale Netzwerk auf Strau√üe bezieht.</i>  <i>In der Mitte werden alle √Ñnderungen angezeigt, die auf das Prim√§rbild angewendet wurden.</i> <br><br>  Anstatt die Kontrolle √ºber ein Robomobil zu √ºbernehmen, zeigt ihm diese Methode so etwas wie eine Halluzination - ein Bild, das es eigentlich nicht gibt. <br><br>  Solche Angriffe verwenden Bilder mit einem Trick [gegnerische Beispiele - es gibt keinen etablierten russischen Begriff, w√∂rtlich stellt sich heraus, dass es sich um ‚ÄûBeispiele mit Kontrast‚Äú oder ‚Äûrivalisierende Beispiele‚Äú handelt - ca.  transl.]: Bilder, T√∂ne, Text, der f√ºr Menschen normal aussieht, aber von einer v√∂llig anderen Maschine wahrgenommen wird.  Die kleinen √Ñnderungen, die von den Angreifern vorgenommen werden, k√∂nnen dazu f√ºhren, dass das tiefe neuronale Netzwerk die falschen Schlussfolgerungen dar√ºber zieht, was es zeigt. <br><br>  "Jedes System, das maschinelles Lernen verwendet, um sicherheitskritische Entscheidungen zu treffen, ist potenziell anf√§llig f√ºr diese Art von Angriff", sagte Alex Kanchelyan, ein Forscher an der Universit√§t von Berkeley, der Angriffe auf maschinelles Lernen mit gef√§lschten Bildern untersucht. <br><br>  Wenn die Forscher diese Nuancen in den fr√ºhen Stadien der KI-Entwicklung kennen, k√∂nnen sie verstehen, wie diese M√§ngel behoben werden k√∂nnen.  Einige haben dies bereits aufgegriffen und sagen, dass ihre Algorithmen dadurch immer effizienter geworden sind. <br><br>  Der gr√∂√üte Teil der KI-Forschung basiert auf tiefen neuronalen Netzen, die wiederum auf einem breiteren Feld des maschinellen Lernens basieren.  MoD-Technologien verwenden Differential- und Integralrechnung und Statistiken, um Software zu erstellen, die von den meisten von uns verwendet wird, z. B. Spam-Filter in der E-Mail oder im Internet.  In den letzten 20 Jahren haben Forscher begonnen, diese Techniken auf eine neue Idee anzuwenden, neuronale Netze - Softwarestrukturen, die die Gehirnfunktion nachahmen.  Die Idee ist, die Berechnungen √ºber Tausende kleiner Gleichungen (‚ÄûNeuronen‚Äú), die Daten empfangen, dezentralisieren, verarbeiten und weiterleiten, auf die n√§chste Schicht von Tausenden kleiner Gleichungen zu dezentralisieren. <br><br>  Diese KI-Algorithmen werden auf die gleiche Weise trainiert wie im Fall von MO, das wiederum den Lernprozess einer Person kopiert.  Ihnen werden Beispiele f√ºr verschiedene Dinge und die zugeh√∂rigen Tags gezeigt.  Zeigen Sie dem Computer (oder Kind) das Bild einer Katze, sagen Sie, dass die Katze so aussieht, und der Algorithmus lernt, Katzen zu erkennen.  Daf√ºr muss der Computer Tausende und Abermillionen Bilder von Katzen und Katzen anzeigen. <br><br>  Forscher haben herausgefunden, dass diese Systeme mit speziell ausgew√§hlten irref√ºhrenden Daten angegriffen werden k√∂nnen, die sie als ‚Äûkontroverse Beispiele‚Äú bezeichnen. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/862/7d4/14c/8627d414c9dbe2c4d35b06ca93e1fe0e.jpg" alt="Bild"><br>  <i>In einem Artikel aus dem Jahr 2015 haben Forscher von Google gezeigt, dass tiefe neuronale Netze gezwungen sein k√∂nnen, dieses Bild eines Pandas Gibbons zuzuschreiben.</i> <br><br>  "Wir zeigen Ihnen ein Foto, das den Schulbus deutlich zeigt und Sie glauben l√§sst, es sei ein Strau√ü", sagte Ian Goodfellow, ein Google-Forscher, der aktiv an solchen Angriffen auf neuronale Netze arbeitet. <br><br>  Die Forscher √§nderten die f√ºr neuronale Netze bereitgestellten Bilder nur um 4% und konnten sie in 97% der F√§lle dazu verleiten, Fehler bei der Klassifizierung zu machen.  Selbst wenn sie nicht genau w√ºssten, wie das neuronale Netzwerk Bilder verarbeitet, k√∂nnten sie es in 85% der F√§lle t√§uschen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die letzte Variante des</a> Betrugs ohne Daten in der Netzwerkarchitektur wird als ‚ÄûBlack-Box-Angriff‚Äú bezeichnet.  Dies ist der erste dokumentierte Fall eines funktionellen Angriffs dieser Art auf ein tiefes neuronales Netzwerk, und seine Bedeutung ist, dass ungef√§hr in diesem Szenario Angriffe in der realen Welt stattfinden k√∂nnen. <br><br>  In der Studie griffen Forscher der Pennsylvania State University, von Google und des US Navy Research Laboratory ein neuronales Netzwerk an, das vom MetaMind-Projekt unterst√ºtzte Bilder klassifiziert und als Online-Tool f√ºr Entwickler dient.  Das Team baute das angegriffene Netzwerk auf und trainierte es, aber sein Angriffsalgorithmus funktionierte unabh√§ngig von der Architektur.  Mit einem solchen Algorithmus konnten sie das neuronale Black-Box-Netzwerk mit einer Genauigkeit von 84,24% austricksen. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/7b1/dc3/1f4/7b1dc31f4d7eb5712d1b230f7fdabf64.jpg" alt="Bild"><br>  <i>Die oberste Reihe von Fotos und Zeichen - korrekte Zeichenerkennung.</i> <i><br></i>  <i>Untere Reihe - Das Netzwerk musste Zeichen v√∂llig falsch erkennen.</i> <br><br>  Das Einspeisen ungenauer Daten in Maschinen ist keine neue Idee, aber Doug Tygar, Professor an der Universit√§t von Berkeley, der im Gegensatz dazu seit 10 Jahren maschinelles Lernen studiert, sagt, diese Angriffstechnologie habe sich von einem einfachen MO zu komplexen tiefen neuronalen Netzen entwickelt.  B√∂swillige Hacker verwenden diese Technik seit Jahren f√ºr Spam-Filter. <br><br>  Tigers Forschung stammt aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">seiner Arbeit</a> von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2006</a> √ºber Angriffe dieser Art in einem Netzwerk mit dem Verteidigungsministerium, die er 2011 mit Hilfe von Forschern von UC Berkeley und Microsoft Research erweiterte.  Das Google-Team, das als erstes tiefe neuronale Netze verwendet, ver√∂ffentlichte 2014 seine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erste Arbeit</a> , zwei Jahre nachdem es die M√∂glichkeit solcher Angriffe entdeckt hatte.  Sie wollten sicherstellen, dass dies keine Anomalie war, sondern eine echte M√∂glichkeit.  2015 ver√∂ffentlichten sie eine weitere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit,</a> in der sie einen Weg zum Schutz von Netzwerken und zur Steigerung ihrer Effizienz beschrieben haben. Ian Goodfellow hat seitdem Ratschl√§ge zu anderen wissenschaftlichen Arbeiten in diesem Bereich gegeben, einschlie√ülich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">des Black-Box-Angriffs</a> . <br><br>  Forscher nennen die allgemeinere Idee unzuverl√§ssiger Informationen ‚Äûbyzantinische Daten‚Äú und sind dank des Fortschritts der Forschung zu tiefem Lernen gekommen.  Der Begriff stammt von der bekannten ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufgabe der byzantinischen Gener√§le</a> ‚Äú, einem Gedankenexperiment auf dem Gebiet der Informatik, bei dem eine Gruppe von Gener√§len ihre Handlungen mit Hilfe von Boten koordinieren muss, ohne das Vertrauen zu haben, dass einer von ihnen ein Verr√§ter ist.  Sie k√∂nnen den Informationen ihrer Kollegen nicht vertrauen. <br><br>  ‚ÄûDiese Algorithmen sind f√ºr zuf√§lliges Rauschen ausgelegt, nicht jedoch f√ºr byzantinische Daten‚Äú, sagt Taigar.  Um zu verstehen, wie solche Angriffe funktionieren, schl√§gt Goodfello vor, sich ein neuronales Netzwerk in Form eines Dispersionsdiagramms vorzustellen. <br><br>  Jeder Punkt im Diagramm repr√§sentiert ein Pixel des vom neuronalen Netzwerk verarbeiteten Bildes.  In der Regel versucht das Netzwerk, eine Linie durch die Daten zu ziehen, die am besten zur Menge aller Punkte passt.  In der Praxis ist dies etwas komplizierter, da unterschiedliche Pixel unterschiedliche Werte f√ºr das Netzwerk haben.  In Wirklichkeit ist dies ein komplexer mehrdimensionaler Graph, der von einem Computer verarbeitet wird. <br><br>  In unserer einfachen Analogie eines Streudiagramms bestimmt die Form der durch die Daten gezogenen Linie, was das Netzwerk zu sehen glaubt.  F√ºr einen erfolgreichen Angriff auf solche Systeme m√ºssen Forscher nur einen kleinen Teil dieser Punkte √§ndern und das Netzwerk eine Entscheidung treffen lassen, die tats√§chlich nicht existiert.  In dem Beispiel eines Busses, der wie ein Strau√ü aussieht, ist das Foto des Schulbusses mit Pixeln gepunktet, die gem√§√ü dem Muster angeordnet sind, das mit den einzigartigen Eigenschaften von Strau√üenfotos verbunden ist, die dem Netzwerk vertraut sind.  Dies ist eine unsichtbare Kontur f√ºr das Auge, aber wenn der Algorithmus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Daten verarbeitet und vereinfacht</a> , scheinen ihm die extremen Datenpunkte f√ºr den Strau√ü eine geeignete Klassifizierungsoption zu sein.  In der Black-Box-Version testeten die Forscher die Arbeit mit verschiedenen Eingabedaten, um festzustellen, wie der Algorithmus bestimmte Objekte sieht. <br><br>  Indem die Forscher dem Objektklassifizierer eine gef√§lschte Eingabe gaben und die von der Maschine getroffenen Entscheidungen untersuchten, konnten sie den Algorithmus wiederherstellen, um das Bilderkennungssystem zu t√§uschen.  M√∂glicherweise kann ein solches System in Robomobilen in diesem Fall das "Nachgeben" -Schild anstelle des Stoppschilds sehen.  Als sie verstanden, wie das Netzwerk funktionierte, konnten sie die Maschine alles sehen lassen. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/d91/d4a/f16/d91d4af16d2c1644444f58a67dd42e8e.jpg" alt="Bild"><br>  <i>Ein Beispiel daf√ºr, wie der Bildklassifizierer abh√§ngig von den verschiedenen Objekten im Bild unterschiedliche Linien zeichnet.</i>  <i>Gef√§lschte Beispiele k√∂nnen als Extremwerte in der Grafik betrachtet werden.</i> <br><br>  Forscher sagen, dass ein solcher Angriff direkt in das Bildverarbeitungssystem eingegeben werden kann, indem die Kamera umgangen wird, oder dass diese Manipulationen mit einem echten Zeichen ausgef√ºhrt werden k√∂nnen. <br><br>  Die Sicherheitsspezialistin der Columbia University, Alison Bishop, sagte jedoch, dass eine solche Prognose unrealistisch sei und von dem im Robomobile verwendeten System abh√§nge.  Wenn die Angreifer bereits Zugriff auf den Datenstrom von der Kamera haben, k√∂nnen sie ihm bereits Eingaben geben. <br><br>  "Wenn sie zum Eingang der Kamera gelangen k√∂nnen, sind solche Schwierigkeiten nicht erforderlich", sagt sie.  "Du kannst ihr nur das Stoppschild zeigen." <br><br>  Andere Angriffsmethoden, neben der Umgehung der Kamera - zum Beispiel das Zeichnen visueller Markierungen auf einem echten Schild - scheinen Bishop unwahrscheinlich.  Sie bezweifelt, dass die bei Robomobilen verwendeten Kameras mit niedriger Aufl√∂sung im Allgemeinen zwischen kleinen √Ñnderungen des Vorzeichens unterscheiden k√∂nnen. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/9ef/d47/a6e/9efd47a6ee9f74748cdb79c976da84bf.jpg" alt="Bild"><br>  <i>Das makellose Bild links ist als Schulbus klassifiziert.</i>  <i>Rechts korrigiert - wie ein Strau√ü.</i>  <i>In der Mitte √§ndert sich das Bild.</i> <br><br>  Zwei Gruppen, eine an der University of Berkeley und eine an der Georgetown University, haben erfolgreich Algorithmen entwickelt, mit denen digitale Assistenten wie Siri und Google Now Sprachbefehle erhalten k√∂nnen, die wie unh√∂rbares Rauschen klingen.  F√ºr eine Person erscheinen solche Befehle wie zuf√§lliges Rauschen, aber gleichzeitig k√∂nnen sie Ger√§ten wie Alexa Befehle erteilen, die von ihrem Besitzer nicht vorgesehen sind. <br><br>  Nicholas Carlini, einer der Forscher f√ºr byzantinische Audioangriffe, sagt, dass sie in ihren Tests Open-Source-Audioerkennungsprogramme, Siri und Google Now, mit einer Genauigkeit von mehr als 90% aktivieren konnten. <br><br>  Das Ger√§usch ist wie eine Art Science-Fiction-Alien-Verhandlung.  Dies ist eine Mischung aus wei√üem Rauschen und einer menschlichen Stimme, aber es ist √ºberhaupt nicht wie ein Sprachbefehl. <br><br>  Laut Carlini kann bei einem solchen Angriff jeder, der ein Telefonger√§usch geh√∂rt hat (es ist erforderlich, Angriffe auf iOS und Android separat zu planen), gezwungen werden, eine Webseite aufzurufen, auf der auch Ger√§usche wiedergegeben werden, wodurch in der N√§he befindliche Telefone infiziert werden.  Oder diese Seite l√§dt leise ein Malware-Programm herunter.  Es ist auch m√∂glich, dass solche Ger√§usche im Radio verloren gehen und im wei√üen Rauschen oder parallel zu anderen Audioinformationen versteckt werden. <br><br>  Solche Angriffe k√∂nnen auftreten, weil die Maschine darauf trainiert ist, sicherzustellen, dass fast alle Daten wichtige Daten enthalten und dass eines h√§ufiger vorkommt als das andere, wie von Goodfello erl√§utert. <br><br>  Das Netzwerk zu t√§uschen und es zu zwingen zu glauben, dass es ein gemeinsames Objekt sieht, ist einfacher, weil es glaubt, dass es solche Objekte h√§ufiger sehen sollte.  Daher konnten Goodfellow und eine andere Gruppe von der University of Wyoming das Netzwerk dazu bringen, Bilder zu klassifizieren, die √ºberhaupt nicht existierten - es identifizierte Objekte in wei√üem Rauschen, zuf√§llig erzeugte Schwarz-Wei√ü-Pixel. <br><br>  In einer Goodfellow-Studie wurde zuf√§lliges wei√ües Rauschen, das durch ein Netzwerk geht, von ihr als Pferd eingestuft.  Zuf√§lligerweise bringt uns dies zur√ºck zur Geschichte von Clever Hans, einem nicht sehr mathematisch begabten Pferd. <br><br>  Goodfellow sagt, dass neuronale Netze wie Smart Hans keine Ideen lernen, sondern nur herausfinden, wann sie die richtige Idee finden.  Der Unterschied ist klein aber wichtig.  Der Mangel an grundlegendem Wissen erleichtert b√∂swillige Versuche, den Anschein zu erwecken, die ‚Äûrichtigen‚Äú Algorithmusergebnisse zu finden, die sich tats√§chlich als falsch herausstellen.  Um zu verstehen, was etwas ist, muss eine Maschine auch verstehen, was es nicht ist. <br><br>  Goodfello, der die Netzwerksortierung von Bildern sowohl auf nat√ºrlichen Bildern als auch auf verarbeiteten (gef√§lschten) Bildern trainiert hatte, stellte fest, dass er nicht nur die Wirksamkeit solcher Angriffe um 90% reduzieren, sondern auch das Netzwerk besser f√ºr die anf√§ngliche Aufgabe einsetzen konnte. <br><br>  ‚ÄûIndem Sie es erm√∂glichen, wirklich ungew√∂hnliche gef√§lschte Bilder zu erkl√§ren, k√∂nnen Sie die zugrunde liegenden Konzepte noch zuverl√§ssiger erkl√§ren‚Äú, sagt Goodfellow. <br><br>  Zwei Gruppen von Audioforschern verwendeten einen √§hnlichen Ansatz wie das Google-Team und sch√ºtzten ihre neuronalen Netze durch √úbertraining vor ihren eigenen Angriffen.  Sie erzielten √§hnliche Erfolge und reduzierten ihre Angriffseffizienz um mehr als 90%. <br><br>  Es ist nicht verwunderlich, dass dieses Forschungsgebiet das US-Milit√§r interessierte.  Das Army Research Laboratory hat sogar zwei der neuesten Arbeiten zu diesem Thema gesponsert, darunter den Black-Box-Angriff.  Und obwohl die Agentur Forschung finanziert, bedeutet dies nicht, dass Technologie im Krieg eingesetzt wird.  Laut dem Vertreter der Abteilung k√∂nnen bis zu 10 Jahre von der Forschung bis zu Technologien vergehen, die f√ºr den Einsatz durch einen Soldaten geeignet sind. <br><br>  Ananthram Swami, ein Forscher am US Army Laboratory, war k√ºrzlich an mehreren Arbeiten zur KI-T√§uschung beteiligt.  Die Armee ist an der Aufdeckung und Beendigung betr√ºgerischer Daten in unserer Welt interessiert, in der nicht alle Informationsquellen sorgf√§ltig gepr√ºft werden k√∂nnen.  Swami verweist auf eine Reihe von Daten, die von √∂ffentlichen Sensoren an Universit√§ten stammen und in Open-Source-Projekten arbeiten. <br><br>  ‚ÄûWir kontrollieren nicht immer alle Daten.  F√ºr unseren Gegner ist es ziemlich einfach, uns auszutricksen ‚Äú, sagt Swami.  "In einigen F√§llen k√∂nnen die Folgen eines solchen Betrugs leichtfertig sein, in einigen F√§llen das Gegenteil." <br><br>  Er sagt auch, dass die Armee an autonomen Robotern, Panzern und anderen Fahrzeugen interessiert ist, so dass das Ziel dieser Forschung offensichtlich ist.  Durch die Untersuchung dieser Themen kann die Armee einen Vorsprung bei der Entwicklung von Systemen gewinnen, die keinen derartigen Angriffen ausgesetzt sind. <br><br>  Jede Gruppe, die ein neuronales Netzwerk verwendet, sollte jedoch Bedenken hinsichtlich der M√∂glichkeit von Angriffen mit KI-Spoofing haben.  Maschinelles Lernen und KI stecken noch in den Kinderschuhen, und Sicherheitsl√ºcken k√∂nnen derzeit schwerwiegende Folgen haben.  Viele Unternehmen vertrauen hochsensiblen Informationen auf KI-Systeme, die den Test der Zeit nicht bestanden haben.  Unsere neuronalen Netze sind noch zu jung, um alles zu wissen, was wir √ºber sie brauchen. <br><br>  Ein √§hnliches Versehen f√ºhrte dazu, dass <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Microsofts Twitter-Bot Tay</a> schnell zu einem Rassisten mit einer Vorliebe f√ºr V√∂lkermord wurde.  Der Fluss b√∂sartiger Daten und die Funktion ‚ÄûNach mir wiederholen‚Äú f√ºhrten dazu, dass Tay stark vom beabsichtigten Pfad abwich.  Der Bot wurde durch minderwertige Eingaben ausgetrickst, und dies ist ein praktisches Beispiel f√ºr eine schlechte Implementierung des maschinellen Lernens. <br><br>  Kanchelyan glaubt nicht, dass die M√∂glichkeiten f√ºr solche Angriffe nach erfolgreicher Recherche durch das Google-Team ausgesch√∂pft sind. <br><br>  "Im Bereich der Computersicherheit sind Angreifer immer vor uns", sagt Kanchelyan.  "Es wird ziemlich gef√§hrlich sein zu behaupten, dass wir alle Probleme mit der T√§uschung neuronaler Netze durch ihr wiederholtes Training gel√∂st haben." </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de405773/">https://habr.com/ru/post/de405773/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de405763/index.html">Kingston Duo 3C - Lebensretter f√ºr microSD-Speicherkarten</a></li>
<li><a href="../de405765/index.html">Maximieren Sie Ihre Einsparungen mit Canon MAXIFY: Kompakte Tintenstrahldrucker f√ºr mittelgro√üe Arbeitsgruppen und Home Offices</a></li>
<li><a href="../de405767/index.html">Bitcoin Cash: Genie aus der Flasche entlassen</a></li>
<li><a href="../de405769/index.html">Auf der Suche nach verlorenem Geld: BTC-E-Administratoren k√ºndigten die R√ºckkehr der Kontrolle √ºber die B√∂rsenbasis an. Das ist aber nicht sicher</a></li>
<li><a href="../de405771/index.html">F√ºnf Jahre auf dem Mars</a></li>
<li><a href="../de405775/index.html">Nur Kaspersky Anti-Virus blockiert das CIA-Dienstprogramm</a></li>
<li><a href="../de405777/index.html">Der Klimawandel k√∂nnte einen Teil S√ºdasiens unbewohnt machen</a></li>
<li><a href="../de405779/index.html">Fortgeschrittene Zivilisationen k√∂nnen das galaktische Internet mithilfe planetarischer Komplettl√∂sungen aufbauen</a></li>
<li><a href="../de405781/index.html">Leben mit einem Stern - Teil 2: Weltraumwetter</a></li>
<li><a href="../de405783/index.html">Die dunkle Zukunft des Internets: Ungleichheit und mangelnde Freiheit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
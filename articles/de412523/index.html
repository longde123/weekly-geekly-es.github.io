<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍🚒 🖐️ 🙌🏼 ConvNets. Prototyp eines Projekts mit Mask R-CNN 😿 🧖🏾 ⛏️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! Schließlich warteten wir auf einen weiteren Teil der Materialreihe des Absolventen unseres Big Data Specialist- und Deep Learning- Program...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ConvNets. Prototyp eines Projekts mit Mask R-CNN</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/newprolab/blog/412523/">  Hallo Habr!  Schließlich warteten wir auf einen weiteren Teil der Materialreihe des Absolventen unseres <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Big Data Specialist-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep Learning-</a> Programms, Cyril Danilyuk, über die Verwendung von Mask R-CNN, den derzeit beliebten neuronalen Netzen, als Teil eines Systems zur Klassifizierung von Bildern, nämlich Beurteilung der Qualität eines zubereiteten Gerichts anhand eines Datensatzes von Sensoren. <br><br>  Nachdem wir den Spielzeugdatensatz untersucht haben, der im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorherigen Artikel</a> aus Bildern von Verkehrszeichen besteht, können wir nun das Problem lösen, mit dem ich im wirklichen Leben konfrontiert war: <b>„Ist es möglich, den Deep-Learning-Algorithmus zu implementieren, mit dem hochwertige Gerichte nacheinander von schlechten Gerichten unterschieden werden können? Fotos? "</b>  .  Kurz gesagt, das Unternehmen wollte Folgendes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fv/_o/vv/fv_ovvsls8uz-qdmfurmijy-qbk.png"></div>  <sub>Was ein Unternehmen darstellt, wenn es über maschinelles Lernen nachdenkt:</sub> <br><a name="habracut"></a><br>  Dies ist ein Beispiel für ein falsch gestelltes Problem: In diesem Fall kann nicht festgestellt werden, ob eine Lösung vorhanden ist, ob sie eindeutig und stabil ist.  Darüber hinaus ist die Erklärung des Problems selbst sehr vage, ganz zu schweigen von der Umsetzung seiner Lösung.  Natürlich ist dieser Artikel nicht der Effektivität der Kommunikation oder des Projektmanagements gewidmet, aber es ist wichtig zu beachten: <b>Nehmen</b> Sie <b>niemals Projekte an, bei denen das Endergebnis nicht definiert und in der Arbeitserklärung festgehalten ist.</b>  Eine der zuverlässigsten Möglichkeiten, mit dieser Unsicherheit umzugehen, besteht darin, zuerst einen Prototyp zu erstellen und dann mit neuem Wissen den Rest der Aufgabe zu strukturieren.  Das haben wir getan. <br><br><h3>  Erklärung des Problems </h3><br>  In meinem Prototyp habe ich mich auf ein Gericht aus dem Menü konzentriert - ein Omelett - und eine skalierbare Pipeline erstellt, die die "Qualität" des Omeletts am Ausgang bestimmt.  Dies kann detaillierter wie folgt beschrieben werden: <br><br><ul><li>  <b>Problemtyp:</b> Mehrklassenklassifizierung mit 6 diskreten Qualitätsklassen: <i>gut</i> (gut), <i>gebrochenes</i> Eigelb (mit Eigelb), <i>überröstet</i> (verkocht), zwei Eier (zwei Eier), vier Eier (vier Eier), <i>verlegte</i> Stücke (mit auf einem Teller verstreuten Stücken) . </li><li> <b>Datensatz:</b> 351 manuell gesammelte Fotos verschiedener Omeletts.  Trainings- / Validierungs- / Testmuster: 139/32/180 gemischte Fotos. </li><li>  <b>Klassenetiketten:</b> Jedes Foto entspricht einem Klassenetikett, das einer subjektiven Beurteilung der Qualität des Omeletts entspricht. </li><li>  <b>Metrik:</b> kategoriale Kreuzentropie. </li><li>  <b>Minimales Domänenwissen: Ein</b> Omelett von „Qualität“ sollte so aussehen: Es besteht aus drei Eiern, einer kleinen Menge Speck, einem Petersilienblatt in der Mitte, hat kein Eigelb und keine verkochten Stücke.  Außerdem sollte die Gesamtzusammensetzung „gut aussehen“, dh die Teile sollten nicht über die gesamte Platte verteilt sein. </li><li>  <b>Abschlusskriterium: Der</b> beste Wert der Kreuzentropie in der Testprobe unter allen möglichen nach zweiwöchiger Entwicklung des Prototyps. </li><li>  <b>Die Methode der endgültigen Visualisierung:</b> t-SNE auf dem Datenraum einer kleineren Dimension. </li></ul><br><img src="https://habrastorage.org/webt/yb/8i/uk/yb8iuk0ics242w3vpztsjefgucg.png"><br>  <sub>Bilder eingeben</sub> <br><br>  Das Hauptziel der Pipeline besteht darin, zu lernen, verschiedene Arten von Signalen zu kombinieren (z. B. Bilder aus verschiedenen Winkeln, eine Heatmap usw.), nachdem eine vorkomprimierte Darstellung von jedem von ihnen erhalten wurde und diese Merkmale für die endgültige Vorhersage durch den neuronalen Netzwerkklassifizierer geleitet werden.  So können wir unseren Prototyp realisieren und für weitere Arbeiten praktisch anwendbar machen.  Im Folgenden sind einige der im Prototyp verwendeten Signale aufgeführt: <br><br><ul><li>  Masken der Hauptbestandteile (Maske R-CNN): <i>Signal Nr. 1</i> . </li><li>  Die Anzahl der Hauptbestandteile auf dem Rahmen., <i>Signal Nummer 2</i> . </li><li>  RGB-Ernte von Platten mit Omelett ohne Hintergrund.  Der Einfachheit halber habe ich beschlossen, sie noch nicht zum Modell hinzuzufügen, obwohl sie das offensichtlichste Signal sind: In Zukunft können Sie das Faltungsnetzwerk für die Klassifizierung mit einer geeigneten <i>Triplettverlustfunktion</i> trainieren, Bildeinbettungen berechnen und den <i>L2-Abstand</i> vom Strom abschneiden Bilder zu perfektionieren.  Leider hatte ich keine Gelegenheit, diese Hypothese zu testen, da die Testprobe nur aus 139 Objekten bestand. </li></ul><br><h3>  Gesamtansicht der Pipeline </h3><br>  Ich stelle fest, dass ich einige wichtige Schritte überspringen muss, z. B. die explorative Datenanalyse, das Erstellen eines grundlegenden Klassifikators und die aktive Kennzeichnung (mein vorgeschlagener Begriff, dh halbautomatische Annotation von Objekten, inspiriert vom <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Polygon-RNN-Demovideo</a> ) für Mask R-CNN (mehr dazu) dies in den nächsten Beiträgen). <br><br>  Schauen Sie sich die gesamte Pipeline im Allgemeinen an: <br><br><img src="https://habrastorage.org/webt/er/bd/m2/erbdm2blw4soc4vjtoabjlwbbrg.png"><br>  <sub>In diesem Artikel interessieren uns die Phasen von Mask R-CNN und die Klassifizierung innerhalb der Pipeline.</sub> <br><br>  Als nächstes betrachten wir drei Stufen: 1) Verwenden der Maske R-CNN zum Erstellen von Masken aus Omelettbestandteilen;  2) ConvNet-Klassifikator basierend auf Keras;  3) Visualisierung der Ergebnisse mit t-SNE. <br><br><h3>  Stufe 1: Maske R-CNN und Gebäudemasken </h3><br>  Die Maske R-CNN (MRCNN) war kürzlich auf dem Höhepunkt ihrer Popularität.  Ausgehend vom ursprünglichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Facebook-Artikel</a> und endend mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Data Science Bowl 2018</a> bei Kaggle hat sich Mask R-CNN als leistungsstarke Architektur für beispielsweise die Segmentierung (d. H. Nicht nur die pixelweise Bildsegmentierung, sondern auch die Trennung mehrerer Objekte derselben Klasse) etabliert )  Darüber hinaus ist es eine Freude, mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung von MRCNN von Matterport</a> in Keras zu arbeiten.  Der Code ist gut strukturiert, gut dokumentiert und funktioniert sofort, wenn auch langsamer als erwartet. <br><br>  In der Praxis ist es insbesondere bei der Entwicklung eines Prototyps wichtig, über ein vorab trainiertes neuronales Faltungsnetzwerk zu verfügen.  In den meisten Fällen ist der mit Tags versehene Datensatz des Datenwissenschaftlers sehr begrenzt oder gar nicht, während ConvNet viele mit Tags versehene Daten benötigt, um Konvergenz zu erreichen (beispielsweise enthält der ImageNet-Datensatz 1,2 Millionen mit Tags versehene Bilder).  Hier hilft das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Transferlernen</a> : Wir können das Gewicht der Faltungsschichten festlegen und nur den Klassifikator neu trainieren.  Das Fixieren von Faltungsschichten ist wichtig für kleine Datensätze, da diese Technik eine Umschulung verhindert. <br><br>  Folgendes habe ich nach der ersten Ära der Umschulung erhalten: <br><br><img src="https://habrastorage.org/webt/ru/g-/cv/rug-cvztg2vpv85obstkuvhl7-4.png"><br>  <sub>Ergebnis der Objektsegmentierung: Alle wichtigen Inhaltsstoffe werden erkannt</sub> <br><br>  In der nächsten Phase der Pipeline ( <i>Process Inferenced Data for Classifier</i> ) müssen Sie den Teil des Bildes ausschneiden, der die Platte enthält, und die zweidimensionale Binärmaske für jeden Bestandteil auf dieser Platte extrahieren: <br><br><img src="https://habrastorage.org/webt/qg/62/5p/qg625pze9oobq1ttlp0ryp6beuk.png"><br>  <sub>Beschnittenes Bild mit Hauptbestandteilen in Form von binären Masken.</sub> <br><br>  Diese binären Masken werden dann zu einem 8-Kanal-Bild kombiniert (da ich 8 Maskenklassen für MRCNN definiert habe), und wir erhalten das <i>Signal Nr. 1</i> : <br><br><img src="https://habrastorage.org/webt/l7/3w/8p/l73w8p1ztuu_udp5mmq7ro9knsk.png"><br>  <sub><i>Signal Nr. 1</i> : 8-Kanal-Bild bestehend aus Binärmasken.</sub>  <sub>In Farbe zur besseren Visualisierung.</sub> <br><br>  Um das <i>Signal Nr. 2 zu erhalten</i> , habe ich gezählt, wie oft jede Zutat auf dem Erntegut der Platte gefunden wurde, und einen Satz von Merkmalsvektoren erhalten, von denen jeder seinem Erntegut entspricht. <br><br><h3>  Stufe 2: ConvNet-Klassifizierer in Keras </h3><br>  Der CNN-Klassifikator wurde mit Keras von Grund auf neu implementiert.  Ich wollte mehrere Signale kombinieren ( <i>Signal Nr. 1</i> und <i>Signal Nr. 2</i> sowie die mögliche Hinzufügung von Daten in der Zukunft) und die neuronalen Netze diese verwenden lassen, um Vorhersagen über die Qualität des Gerichts zu treffen.  Die unten dargestellte Architektur ist erprobt und alles andere als ideal: <br><br><img src="https://habrastorage.org/webt/zb/ow/y4/zbowy4ebvcigyosde3wv3ni-ziq.jpeg"><br><br>  Ein paar Worte zur Architektur des Klassifikators: <br><br><ul><li>  <b>Multiskalen-Faltungsmodul</b> : Ich habe anfangs einen 5x5-Filter für Faltungsschichten gewählt, aber dies führte nur zu einem zufriedenstellenden Ergebnis.  Verbesserungen wurden erzielt, indem <i>AveragePooling2D</i> auf mehrere Ebenen mit unterschiedlichen Filtern <i>angewendet wurde</i> : 3x3, 5x5, 7x7, 11x11.  Vor jeder der Schichten wurde eine zusätzliche 1 × 1-Faltungsschicht hinzugefügt, um die Abmessung zu verringern.  Diese Komponente ähnelt einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Inception-Modul</a> , obwohl ich nicht vorhatte, ein zu tiefes Netzwerk aufzubauen. </li><li>  <b>Größere Filter</b> : Ich habe größere Filter verwendet, da sie dazu beitragen, größere Zeichen leicht aus dem Eingabebild zu extrahieren (das selbst im Wesentlichen eine Aktivierungsschicht mit 8 Filtern ist - die Maske jedes Inhaltsstoffs kann als separater Filter betrachtet werden). </li><li>  <b>Kombinieren von Signalen</b> : In meiner naiven Implementierung wurde nur eine Schicht verwendet, die zwei Sätze von Attributen verband: verarbeitete binäre Masken ( <i>Signal Nr. 1</i> ) und gezählte Zutaten ( <i>Signal Nr. 2</i> ).  Trotz seiner Einfachheit ermöglichte die Hinzufügung des <i>Signals Nr. 2</i> die Reduzierung der Kreuzentropiemetrik von <i>0,8</i> auf <i>[0,7, 0,72]</i> . </li><li>  <b>Logits</b> : In Bezug auf TensorFlow ist Logit eine Ebene, auf der <i>tf.nn.softmax_cross_entropy_with_logits</i> angewendet wird, um den <i>Stapelverlust</i> zu berechnen. </li></ul><br><h3>  Stufe 3: Visualisierung der Ergebnisse mit t-SNE </h3><br>  Um die Ergebnisse des Klassifikators anhand von Testdaten zu visualisieren, habe ich t-SNE verwendet - einen Algorithmus, mit dem Sie die Quelldaten in einen Raum niedrigerer Dimension übertragen können (um das Prinzip des Algorithmus zu verstehen, empfehle ich, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Originalartikel zu</a> lesen, er ist äußerst informativ und gut geschrieben). <br><br>  Vor der Visualisierung habe ich Testbilder aufgenommen, die Logit-Schicht des Klassifikators extrahiert und den t-SNE-Algorithmus auf diesen Datensatz angewendet.  Obwohl ich nicht verschiedene Werte des Ratlosigkeitsparameters ausprobiert habe, sieht das Ergebnis immer noch ziemlich gut aus: <br><br><img src="https://habrastorage.org/webt/er/yk/ic/erykictzlrzdvhchpvli86c8lwi.gif"><br>  <sub>Das Ergebnis von t-SNE auf Testdaten mit Klassifikatorvorhersagen</sub> <br><br>  Natürlich ist dieser Ansatz nicht perfekt, aber er funktioniert.  Es kann einige mögliche Verbesserungen geben: <br><br><ul><li>  <b>Weitere Daten.</b>  Faltungsnetzwerke erfordern viele Daten, und ich hatte nur 139 Bilder für das Training.  Techniken wie die Datenerweiterung funktionieren einwandfrei (ich habe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">D4 oder die symmetrische Diedererweiterung verwendet</a> , was zu mehr als zweitausend Bildern führte), aber es ist immer noch äußerst wichtig, mehr reale Daten zu haben. </li><li>  <b>Besser geeignete Verlustfunktion.</b>  Der Einfachheit halber habe ich kategoriale Kreuzentropie verwendet, was gut ist, weil es sofort funktioniert.  Die beste Option wäre die Verwendung der Verlustfunktion, die Abweichungen innerhalb von Klassen berücksichtigt, z. B. die Triplettverlustfunktion (siehe den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FaceNet-Artikel</a> ). </li><li>  <b>Verbesserung der Klassifikatorarchitektur.</b>  Der aktuelle Klassifikator ist im Wesentlichen ein Prototyp, dessen einziger Zweck darin besteht, binäre Masken zu erstellen und mehrere Merkmalssätze zu einer einzigen Pipeline zu kombinieren. </li><li>  <b>Verbessertes Bildlayout.</b>  Ich war sehr schlampig beim manuellen Markieren von Bildern: Der Klassifikator hat diesen Job bei einem Dutzend Testbildern besser gemacht als ich. </li></ul><br>  <b>Fazit</b>  Es muss endlich erkannt werden, dass das Unternehmen weder Daten noch Erklärungen noch eine klarere Aufgabe hat, die gelöst werden muss.  Und das ist gut (sonst, warum brauchen sie Sie?), Weil Ihre Aufgabe darin besteht, verschiedene Tools, Multi-Core-Prozessoren, vorab geschulte Modelle und eine Mischung aus technischem und geschäftlichem Know-how zu verwenden, um zusätzlichen Wert im Unternehmen zu schaffen. <br><br>  Fangen Sie klein an: Ein funktionierender Prototyp kann aus mehreren Codeblöcken erstellt werden und erhöht die Produktivität weiterer Gespräche mit der Unternehmensleitung erheblich.  Dies ist die Arbeit eines Datenwissenschaftlers - um Unternehmen neue Ansätze und Ideen anzubieten. <br><br><hr><br>  Am 20. September 2018 startet der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">„Big Data Specialist 9.0“</a> , in dem Sie unter anderem lernen, wie Sie Daten visualisieren und die Geschäftslogik hinter dieser oder jener Aufgabe verstehen, um Kollegen und Management die Ergebnisse Ihrer Arbeit effektiver zu präsentieren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de412523/">https://habr.com/ru/post/de412523/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de412513/index.html">Wie werde ich Produktmanager ohne Erfahrung?</a></li>
<li><a href="../de412515/index.html">DJI Ronin-S startet Vertrieb</a></li>
<li><a href="../de412517/index.html">AGPM - Wie Git für Gruppenrichtlinien. Fast</a></li>
<li><a href="../de412519/index.html">Drahtloser batterieloser HD-Camcorder</a></li>
<li><a href="../de412521/index.html">SOC is People: Jedi-Umschulungskurse</a></li>
<li><a href="../de412527/index.html">Crowdfunding für die Astronautik am Beispiel des 435-nm-Projekts</a></li>
<li><a href="../de412529/index.html">Wo zahlen mehr an Programmierer. Vergleichen Sie 22 Länder</a></li>
<li><a href="../de412531/index.html">Battle Space Laser "Skiff"</a></li>
<li><a href="../de412533/index.html">Lokalisierung personenbezogener Daten von Nichtrussen</a></li>
<li><a href="../de412535/index.html">Interview mit "Alice's Chief Brain"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
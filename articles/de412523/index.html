<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüöí üñêÔ∏è üôåüèº ConvNets. Prototyp eines Projekts mit Mask R-CNN üòø üßñüèæ ‚õèÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! Schlie√ülich warteten wir auf einen weiteren Teil der Materialreihe des Absolventen unseres Big Data Specialist- und Deep Learning- Program...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ConvNets. Prototyp eines Projekts mit Mask R-CNN</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/newprolab/blog/412523/">  Hallo Habr!  Schlie√ülich warteten wir auf einen weiteren Teil der Materialreihe des Absolventen unseres <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Big Data Specialist-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep Learning-</a> Programms, Cyril Danilyuk, √ºber die Verwendung von Mask R-CNN, den derzeit beliebten neuronalen Netzen, als Teil eines Systems zur Klassifizierung von Bildern, n√§mlich Beurteilung der Qualit√§t eines zubereiteten Gerichts anhand eines Datensatzes von Sensoren. <br><br>  Nachdem wir den Spielzeugdatensatz untersucht haben, der im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorherigen Artikel</a> aus Bildern von Verkehrszeichen besteht, k√∂nnen wir nun das Problem l√∂sen, mit dem ich im wirklichen Leben konfrontiert war: <b>‚ÄûIst es m√∂glich, den Deep-Learning-Algorithmus zu implementieren, mit dem hochwertige Gerichte nacheinander von schlechten Gerichten unterschieden werden k√∂nnen? Fotos? "</b>  .  Kurz gesagt, das Unternehmen wollte Folgendes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fv/_o/vv/fv_ovvsls8uz-qdmfurmijy-qbk.png"></div>  <sub>Was ein Unternehmen darstellt, wenn es √ºber maschinelles Lernen nachdenkt:</sub> <br><a name="habracut"></a><br>  Dies ist ein Beispiel f√ºr ein falsch gestelltes Problem: In diesem Fall kann nicht festgestellt werden, ob eine L√∂sung vorhanden ist, ob sie eindeutig und stabil ist.  Dar√ºber hinaus ist die Erkl√§rung des Problems selbst sehr vage, ganz zu schweigen von der Umsetzung seiner L√∂sung.  Nat√ºrlich ist dieser Artikel nicht der Effektivit√§t der Kommunikation oder des Projektmanagements gewidmet, aber es ist wichtig zu beachten: <b>Nehmen</b> Sie <b>niemals Projekte an, bei denen das Endergebnis nicht definiert und in der Arbeitserkl√§rung festgehalten ist.</b>  Eine der zuverl√§ssigsten M√∂glichkeiten, mit dieser Unsicherheit umzugehen, besteht darin, zuerst einen Prototyp zu erstellen und dann mit neuem Wissen den Rest der Aufgabe zu strukturieren.  Das haben wir getan. <br><br><h3>  Erkl√§rung des Problems </h3><br>  In meinem Prototyp habe ich mich auf ein Gericht aus dem Men√º konzentriert - ein Omelett - und eine skalierbare Pipeline erstellt, die die "Qualit√§t" des Omeletts am Ausgang bestimmt.  Dies kann detaillierter wie folgt beschrieben werden: <br><br><ul><li>  <b>Problemtyp:</b> Mehrklassenklassifizierung mit 6 diskreten Qualit√§tsklassen: <i>gut</i> (gut), <i>gebrochenes</i> Eigelb (mit Eigelb), <i>√ºberr√∂stet</i> (verkocht), zwei Eier (zwei Eier), vier Eier (vier Eier), <i>verlegte</i> St√ºcke (mit auf einem Teller verstreuten St√ºcken) . </li><li> <b>Datensatz:</b> 351 manuell gesammelte Fotos verschiedener Omeletts.  Trainings- / Validierungs- / Testmuster: 139/32/180 gemischte Fotos. </li><li>  <b>Klassenetiketten:</b> Jedes Foto entspricht einem Klassenetikett, das einer subjektiven Beurteilung der Qualit√§t des Omeletts entspricht. </li><li>  <b>Metrik:</b> kategoriale Kreuzentropie. </li><li>  <b>Minimales Dom√§nenwissen: Ein</b> Omelett von ‚ÄûQualit√§t‚Äú sollte so aussehen: Es besteht aus drei Eiern, einer kleinen Menge Speck, einem Petersilienblatt in der Mitte, hat kein Eigelb und keine verkochten St√ºcke.  Au√üerdem sollte die Gesamtzusammensetzung ‚Äûgut aussehen‚Äú, dh die Teile sollten nicht √ºber die gesamte Platte verteilt sein. </li><li>  <b>Abschlusskriterium: Der</b> beste Wert der Kreuzentropie in der Testprobe unter allen m√∂glichen nach zweiw√∂chiger Entwicklung des Prototyps. </li><li>  <b>Die Methode der endg√ºltigen Visualisierung:</b> t-SNE auf dem Datenraum einer kleineren Dimension. </li></ul><br><img src="https://habrastorage.org/webt/yb/8i/uk/yb8iuk0ics242w3vpztsjefgucg.png"><br>  <sub>Bilder eingeben</sub> <br><br>  Das Hauptziel der Pipeline besteht darin, zu lernen, verschiedene Arten von Signalen zu kombinieren (z. B. Bilder aus verschiedenen Winkeln, eine Heatmap usw.), nachdem eine vorkomprimierte Darstellung von jedem von ihnen erhalten wurde und diese Merkmale f√ºr die endg√ºltige Vorhersage durch den neuronalen Netzwerkklassifizierer geleitet werden.  So k√∂nnen wir unseren Prototyp realisieren und f√ºr weitere Arbeiten praktisch anwendbar machen.  Im Folgenden sind einige der im Prototyp verwendeten Signale aufgef√ºhrt: <br><br><ul><li>  Masken der Hauptbestandteile (Maske R-CNN): <i>Signal Nr. 1</i> . </li><li>  Die Anzahl der Hauptbestandteile auf dem Rahmen., <i>Signal Nummer 2</i> . </li><li>  RGB-Ernte von Platten mit Omelett ohne Hintergrund.  Der Einfachheit halber habe ich beschlossen, sie noch nicht zum Modell hinzuzuf√ºgen, obwohl sie das offensichtlichste Signal sind: In Zukunft k√∂nnen Sie das Faltungsnetzwerk f√ºr die Klassifizierung mit einer geeigneten <i>Triplettverlustfunktion</i> trainieren, Bildeinbettungen berechnen und den <i>L2-Abstand</i> vom Strom abschneiden Bilder zu perfektionieren.  Leider hatte ich keine Gelegenheit, diese Hypothese zu testen, da die Testprobe nur aus 139 Objekten bestand. </li></ul><br><h3>  Gesamtansicht der Pipeline </h3><br>  Ich stelle fest, dass ich einige wichtige Schritte √ºberspringen muss, z. B. die explorative Datenanalyse, das Erstellen eines grundlegenden Klassifikators und die aktive Kennzeichnung (mein vorgeschlagener Begriff, dh halbautomatische Annotation von Objekten, inspiriert vom <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Polygon-RNN-Demovideo</a> ) f√ºr Mask R-CNN (mehr dazu) dies in den n√§chsten Beitr√§gen). <br><br>  Schauen Sie sich die gesamte Pipeline im Allgemeinen an: <br><br><img src="https://habrastorage.org/webt/er/bd/m2/erbdm2blw4soc4vjtoabjlwbbrg.png"><br>  <sub>In diesem Artikel interessieren uns die Phasen von Mask R-CNN und die Klassifizierung innerhalb der Pipeline.</sub> <br><br>  Als n√§chstes betrachten wir drei Stufen: 1) Verwenden der Maske R-CNN zum Erstellen von Masken aus Omelettbestandteilen;  2) ConvNet-Klassifikator basierend auf Keras;  3) Visualisierung der Ergebnisse mit t-SNE. <br><br><h3>  Stufe 1: Maske R-CNN und Geb√§udemasken </h3><br>  Die Maske R-CNN (MRCNN) war k√ºrzlich auf dem H√∂hepunkt ihrer Popularit√§t.  Ausgehend vom urspr√ºnglichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Facebook-Artikel</a> und endend mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Data Science Bowl 2018</a> bei Kaggle hat sich Mask R-CNN als leistungsstarke Architektur f√ºr beispielsweise die Segmentierung (d. H. Nicht nur die pixelweise Bildsegmentierung, sondern auch die Trennung mehrerer Objekte derselben Klasse) etabliert )  Dar√ºber hinaus ist es eine Freude, mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung von MRCNN von Matterport</a> in Keras zu arbeiten.  Der Code ist gut strukturiert, gut dokumentiert und funktioniert sofort, wenn auch langsamer als erwartet. <br><br>  In der Praxis ist es insbesondere bei der Entwicklung eines Prototyps wichtig, √ºber ein vorab trainiertes neuronales Faltungsnetzwerk zu verf√ºgen.  In den meisten F√§llen ist der mit Tags versehene Datensatz des Datenwissenschaftlers sehr begrenzt oder gar nicht, w√§hrend ConvNet viele mit Tags versehene Daten ben√∂tigt, um Konvergenz zu erreichen (beispielsweise enth√§lt der ImageNet-Datensatz 1,2 Millionen mit Tags versehene Bilder).  Hier hilft das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Transferlernen</a> : Wir k√∂nnen das Gewicht der Faltungsschichten festlegen und nur den Klassifikator neu trainieren.  Das Fixieren von Faltungsschichten ist wichtig f√ºr kleine Datens√§tze, da diese Technik eine Umschulung verhindert. <br><br>  Folgendes habe ich nach der ersten √Ñra der Umschulung erhalten: <br><br><img src="https://habrastorage.org/webt/ru/g-/cv/rug-cvztg2vpv85obstkuvhl7-4.png"><br>  <sub>Ergebnis der Objektsegmentierung: Alle wichtigen Inhaltsstoffe werden erkannt</sub> <br><br>  In der n√§chsten Phase der Pipeline ( <i>Process Inferenced Data for Classifier</i> ) m√ºssen Sie den Teil des Bildes ausschneiden, der die Platte enth√§lt, und die zweidimensionale Bin√§rmaske f√ºr jeden Bestandteil auf dieser Platte extrahieren: <br><br><img src="https://habrastorage.org/webt/qg/62/5p/qg625pze9oobq1ttlp0ryp6beuk.png"><br>  <sub>Beschnittenes Bild mit Hauptbestandteilen in Form von bin√§ren Masken.</sub> <br><br>  Diese bin√§ren Masken werden dann zu einem 8-Kanal-Bild kombiniert (da ich 8 Maskenklassen f√ºr MRCNN definiert habe), und wir erhalten das <i>Signal Nr. 1</i> : <br><br><img src="https://habrastorage.org/webt/l7/3w/8p/l73w8p1ztuu_udp5mmq7ro9knsk.png"><br>  <sub><i>Signal Nr. 1</i> : 8-Kanal-Bild bestehend aus Bin√§rmasken.</sub>  <sub>In Farbe zur besseren Visualisierung.</sub> <br><br>  Um das <i>Signal Nr. 2 zu erhalten</i> , habe ich gez√§hlt, wie oft jede Zutat auf dem Erntegut der Platte gefunden wurde, und einen Satz von Merkmalsvektoren erhalten, von denen jeder seinem Erntegut entspricht. <br><br><h3>  Stufe 2: ConvNet-Klassifizierer in Keras </h3><br>  Der CNN-Klassifikator wurde mit Keras von Grund auf neu implementiert.  Ich wollte mehrere Signale kombinieren ( <i>Signal Nr. 1</i> und <i>Signal Nr. 2</i> sowie die m√∂gliche Hinzuf√ºgung von Daten in der Zukunft) und die neuronalen Netze diese verwenden lassen, um Vorhersagen √ºber die Qualit√§t des Gerichts zu treffen.  Die unten dargestellte Architektur ist erprobt und alles andere als ideal: <br><br><img src="https://habrastorage.org/webt/zb/ow/y4/zbowy4ebvcigyosde3wv3ni-ziq.jpeg"><br><br>  Ein paar Worte zur Architektur des Klassifikators: <br><br><ul><li>  <b>Multiskalen-Faltungsmodul</b> : Ich habe anfangs einen 5x5-Filter f√ºr Faltungsschichten gew√§hlt, aber dies f√ºhrte nur zu einem zufriedenstellenden Ergebnis.  Verbesserungen wurden erzielt, indem <i>AveragePooling2D</i> auf mehrere Ebenen mit unterschiedlichen Filtern <i>angewendet wurde</i> : 3x3, 5x5, 7x7, 11x11.  Vor jeder der Schichten wurde eine zus√§tzliche 1 √ó 1-Faltungsschicht hinzugef√ºgt, um die Abmessung zu verringern.  Diese Komponente √§hnelt einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Inception-Modul</a> , obwohl ich nicht vorhatte, ein zu tiefes Netzwerk aufzubauen. </li><li>  <b>Gr√∂√üere Filter</b> : Ich habe gr√∂√üere Filter verwendet, da sie dazu beitragen, gr√∂√üere Zeichen leicht aus dem Eingabebild zu extrahieren (das selbst im Wesentlichen eine Aktivierungsschicht mit 8 Filtern ist - die Maske jedes Inhaltsstoffs kann als separater Filter betrachtet werden). </li><li>  <b>Kombinieren von Signalen</b> : In meiner naiven Implementierung wurde nur eine Schicht verwendet, die zwei S√§tze von Attributen verband: verarbeitete bin√§re Masken ( <i>Signal Nr. 1</i> ) und gez√§hlte Zutaten ( <i>Signal Nr. 2</i> ).  Trotz seiner Einfachheit erm√∂glichte die Hinzuf√ºgung des <i>Signals Nr. 2</i> die Reduzierung der Kreuzentropiemetrik von <i>0,8</i> auf <i>[0,7, 0,72]</i> . </li><li>  <b>Logits</b> : In Bezug auf TensorFlow ist Logit eine Ebene, auf der <i>tf.nn.softmax_cross_entropy_with_logits</i> angewendet wird, um den <i>Stapelverlust</i> zu berechnen. </li></ul><br><h3>  Stufe 3: Visualisierung der Ergebnisse mit t-SNE </h3><br>  Um die Ergebnisse des Klassifikators anhand von Testdaten zu visualisieren, habe ich t-SNE verwendet - einen Algorithmus, mit dem Sie die Quelldaten in einen Raum niedrigerer Dimension √ºbertragen k√∂nnen (um das Prinzip des Algorithmus zu verstehen, empfehle ich, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Originalartikel zu</a> lesen, er ist √§u√üerst informativ und gut geschrieben). <br><br>  Vor der Visualisierung habe ich Testbilder aufgenommen, die Logit-Schicht des Klassifikators extrahiert und den t-SNE-Algorithmus auf diesen Datensatz angewendet.  Obwohl ich nicht verschiedene Werte des Ratlosigkeitsparameters ausprobiert habe, sieht das Ergebnis immer noch ziemlich gut aus: <br><br><img src="https://habrastorage.org/webt/er/yk/ic/erykictzlrzdvhchpvli86c8lwi.gif"><br>  <sub>Das Ergebnis von t-SNE auf Testdaten mit Klassifikatorvorhersagen</sub> <br><br>  Nat√ºrlich ist dieser Ansatz nicht perfekt, aber er funktioniert.  Es kann einige m√∂gliche Verbesserungen geben: <br><br><ul><li>  <b>Weitere Daten.</b>  Faltungsnetzwerke erfordern viele Daten, und ich hatte nur 139 Bilder f√ºr das Training.  Techniken wie die Datenerweiterung funktionieren einwandfrei (ich habe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">D4 oder die symmetrische Diedererweiterung verwendet</a> , was zu mehr als zweitausend Bildern f√ºhrte), aber es ist immer noch √§u√üerst wichtig, mehr reale Daten zu haben. </li><li>  <b>Besser geeignete Verlustfunktion.</b>  Der Einfachheit halber habe ich kategoriale Kreuzentropie verwendet, was gut ist, weil es sofort funktioniert.  Die beste Option w√§re die Verwendung der Verlustfunktion, die Abweichungen innerhalb von Klassen ber√ºcksichtigt, z. B. die Triplettverlustfunktion (siehe den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FaceNet-Artikel</a> ). </li><li>  <b>Verbesserung der Klassifikatorarchitektur.</b>  Der aktuelle Klassifikator ist im Wesentlichen ein Prototyp, dessen einziger Zweck darin besteht, bin√§re Masken zu erstellen und mehrere Merkmalss√§tze zu einer einzigen Pipeline zu kombinieren. </li><li>  <b>Verbessertes Bildlayout.</b>  Ich war sehr schlampig beim manuellen Markieren von Bildern: Der Klassifikator hat diesen Job bei einem Dutzend Testbildern besser gemacht als ich. </li></ul><br>  <b>Fazit</b>  Es muss endlich erkannt werden, dass das Unternehmen weder Daten noch Erkl√§rungen noch eine klarere Aufgabe hat, die gel√∂st werden muss.  Und das ist gut (sonst, warum brauchen sie Sie?), Weil Ihre Aufgabe darin besteht, verschiedene Tools, Multi-Core-Prozessoren, vorab geschulte Modelle und eine Mischung aus technischem und gesch√§ftlichem Know-how zu verwenden, um zus√§tzlichen Wert im Unternehmen zu schaffen. <br><br>  Fangen Sie klein an: Ein funktionierender Prototyp kann aus mehreren Codebl√∂cken erstellt werden und erh√∂ht die Produktivit√§t weiterer Gespr√§che mit der Unternehmensleitung erheblich.  Dies ist die Arbeit eines Datenwissenschaftlers - um Unternehmen neue Ans√§tze und Ideen anzubieten. <br><br><hr><br>  Am 20. September 2018 startet der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûBig Data Specialist 9.0‚Äú</a> , in dem Sie unter anderem lernen, wie Sie Daten visualisieren und die Gesch√§ftslogik hinter dieser oder jener Aufgabe verstehen, um Kollegen und Management die Ergebnisse Ihrer Arbeit effektiver zu pr√§sentieren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de412523/">https://habr.com/ru/post/de412523/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de412513/index.html">Wie werde ich Produktmanager ohne Erfahrung?</a></li>
<li><a href="../de412515/index.html">DJI Ronin-S startet Vertrieb</a></li>
<li><a href="../de412517/index.html">AGPM - Wie Git f√ºr Gruppenrichtlinien. Fast</a></li>
<li><a href="../de412519/index.html">Drahtloser batterieloser HD-Camcorder</a></li>
<li><a href="../de412521/index.html">SOC is People: Jedi-Umschulungskurse</a></li>
<li><a href="../de412527/index.html">Crowdfunding f√ºr die Astronautik am Beispiel des 435-nm-Projekts</a></li>
<li><a href="../de412529/index.html">Wo zahlen mehr an Programmierer. Vergleichen Sie 22 L√§nder</a></li>
<li><a href="../de412531/index.html">Battle Space Laser "Skiff"</a></li>
<li><a href="../de412533/index.html">Lokalisierung personenbezogener Daten von Nichtrussen</a></li>
<li><a href="../de412535/index.html">Interview mit "Alice's Chief Brain"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
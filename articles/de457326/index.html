<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äçüè´ üßü üöØ Failover-Cluster PostgreSQL + Patroni. Implementierungserfahrung üë©üèΩ‚Äç‚öñÔ∏è üçµ ü§ûüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In dem Artikel werde ich Ihnen erz√§hlen, wie wir das Problem der PostgreSQL-Fehlertoleranz angegangen sind, warum dies f√ºr uns wichtig geworden ist un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Failover-Cluster PostgreSQL + Patroni. Implementierungserfahrung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/miro/blog/457326/">  In dem Artikel werde ich Ihnen erz√§hlen, wie wir das Problem der PostgreSQL-Fehlertoleranz angegangen sind, warum dies f√ºr uns wichtig geworden ist und was am Ende passiert ist. <br><br>  Wir haben einen hoch ausgelasteten Service: 2,5 Millionen Benutzer weltweit, mehr als 50.000 aktive Benutzer pro Tag.  Die Server befinden sich in Amazone in einer Region Irlands: Es sind st√§ndig mehr als 100 verschiedene Server in Betrieb, von denen fast 50 √ºber Datenbanken verf√ºgen. <br><br>  Das gesamte Backend ist eine gro√üe monolithische Stateful-Java-Anwendung, die eine konstante Websocket-Verbindung zum Client aufrechterh√§lt.  Bei gleichzeitiger Arbeit mehrerer Benutzer auf einer Karte sehen alle die √Ñnderungen in Echtzeit, da wir jede √Ñnderung in der Datenbank aufzeichnen.  Wir haben ungef√§hr 10.000 Anfragen pro Sekunde an unsere Datenbanken.  Bei Spitzenlast in Redis schreiben wir mit 80-100.000 Abfragen pro Sekunde. <br><img src="https://habrastorage.org/webt/ef/pn/er/efpner_0rhtuim1zt0gwrhff3b8.png"><br><a name="habracut"></a><br><br><h2>  Warum wir von Redis zu PostgreSQL gewechselt sind </h2><br>  Zun√§chst arbeitete unser Service mit Redis zusammen, einem Schl√ºsselwert-Repository, in dem alle Daten im RAM des Servers gespeichert sind. <br><br>  Vorteile von Redis: <br><br><ol><li>  Hohe R√ºcklaufquote, as  alles ist im Speicher gespeichert; </li><li>  Bequeme Sicherung und Replikation. </li></ol><br>  Nachteile Redis f√ºr uns: <br><br><ol><li> Es gibt keine echten Transaktionen.  Wir haben versucht, sie auf der Ebene unserer Anwendung zu simulieren.  Leider funktionierte dies nicht immer gut und erforderte das Schreiben von sehr komplexem Code. </li><li>  Die Datenmenge ist durch die Speichermenge begrenzt.  Mit zunehmender Datenmenge w√§chst der Speicher, und am Ende werden wir auf die Merkmale der ausgew√§hlten Instanz sto√üen, f√ºr die in AWS der Dienst angehalten werden muss, um den Instanztyp zu √§ndern. </li><li>  Es ist notwendig, st√§ndig eine niedrige Latenz aufrechtzuerhalten, da  Wir haben sehr viele Anfragen.  Der optimale Verz√∂gerungspegel f√ºr uns betr√§gt 17-20 ms.  Auf der Ebene von 30-40 ms erhalten wir lange Antworten auf die Anforderungen unserer Anwendung und die Verschlechterung des Dienstes.  Leider geschah dies bei uns im September 2018, als eine der Redis-Instanzen aus irgendeinem Grund eine zweimal h√∂here Latenz als gew√∂hnlich erhielt.  Um das Problem zu l√∂sen, haben wir den Service mitten am Tag wegen au√üerplanm√§√üiger Wartung eingestellt und die problematische Redis-Instanz ersetzt. </li><li>  Es ist leicht, Dateninkonsistenzen zu erhalten, selbst bei geringf√ºgigen Fehlern im Code, und dann viel Zeit damit zu verbringen, Code zu schreiben, um diese Daten zu korrigieren. </li></ol><br>  Wir haben die Nachteile ber√ºcksichtigt und festgestellt, dass wir zu etwas Bequemerem √ºbergehen m√ºssen, mit normalen Transaktionen und weniger Abh√§ngigkeit von der Latenz.  Durchf√ºhrung einer Studie, Analyse vieler Optionen und Auswahl von PostgreSQL. <br><br>  Wir sind seit 1,5 Jahren in eine neue Datenbank umgezogen und haben nur einen kleinen Teil der Daten √ºbertragen. Jetzt arbeiten wir gleichzeitig mit Redis und PostgreSQL.  Weitere Informationen zu den Phasen des Verschiebens und Wechselns von Daten zwischen Datenbanken finden Sie in einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel meines Kollegen</a> . <br><br>  Als wir gerade mit dem Umzug begannen, arbeitete unsere Anwendung direkt mit der Datenbank und wandte sich an den Redis- und PostgreSQL-Assistenten.  Der PostgreSQL-Cluster bestand aus einem Master- und einem asynchronen Replikatreplikat.  So sah das Datenbankoperationsschema aus: <br><img src="https://habrastorage.org/webt/wc/wg/ef/wcwgefzqham9mw7hm-5xc37pfp0.png"><br><br><h2>  PgBouncer-Bereitstellung </h2><br>  W√§hrend wir umzogen, entwickelte sich auch das Produkt: Die Anzahl der Benutzer und die Anzahl der Server, die mit PostgreSQL arbeiteten, nahmen zu, und wir begannen, Verbindungen zu verpassen.  PostgreSQL erstellt f√ºr jede Verbindung einen eigenen Prozess und verbraucht Ressourcen.  Sie k√∂nnen die Anzahl der Verbindungen bis zu einem bestimmten Punkt erh√∂hen, andernfalls besteht die M√∂glichkeit, dass der Datenbankbetrieb nicht optimal ist.  Die ideale Option in dieser Situation w√§re die Wahl eines Verbindungsmanagers, der vor der Basis steht. <br><br>  Wir hatten zwei Optionen f√ºr den Verbindungsmanager: Pgpool und PgBouncer.  Der erste unterst√ºtzt jedoch nicht den Transaktionsmodus f√ºr die Arbeit mit der Datenbank. Daher haben wir uns f√ºr PgBouncer entschieden. <br><br>  Wir haben das folgende Arbeitsschema eingerichtet: Unsere Anwendung greift auf einen PgBouncer zu, gefolgt von Masters PostgreSQL, und hinter jedem Master ein Replikat mit asynchroner Replikation. <br><img src="https://habrastorage.org/webt/ql/uq/vh/qluqvh64yeyzwvow79wc3tt0nm0.png"><br><br>  Gleichzeitig konnten wir nicht die gesamte Datenmenge in PostgreSQL speichern, und die Geschwindigkeit der Arbeit mit der Datenbank war f√ºr uns wichtig. Daher haben wir begonnen, PostgreSQL auf Anwendungsebene zu sharden.  Das oben beschriebene Schema ist hierf√ºr relativ praktisch: Wenn Sie einen neuen PostgreSQL-Shard hinzuf√ºgen, reicht es aus, die PgBouncer-Konfiguration zu aktualisieren, und die Anwendung kann sofort mit dem neuen Shard arbeiten. <br><br><h3>  PgBouncer-Fehlertoleranz </h3><br>  Dieses Schema funktionierte, bis die einzige PgBouncer-Instanz starb.  Wir befinden uns in AWS, wo alle Instanzen auf Hardware ausgef√ºhrt werden, die regelm√§√üig ausf√§llt.  In solchen F√§llen wechselt die Instanz einfach auf die neue Hardware und funktioniert wieder.  Dies geschah mit PgBouncer, war jedoch nicht mehr verf√ºgbar.  Das Ergebnis dieses Herbstes war die Unzug√§nglichkeit unseres Dienstes f√ºr 25 Minuten.  AWS empfiehlt die Verwendung von Redundanz auf der Benutzerseite f√ºr solche Situationen, die zu diesem Zeitpunkt bei uns nicht implementiert wurden. <br><br>  Danach haben wir ernsthaft √ºber die Fehlertoleranz von PgBouncer- und PostgreSQL-Clustern nachgedacht, da eine √§hnliche Situation bei jeder Instanz in unserem AWS-Konto erneut auftreten kann. <br><br>  Wir haben das PgBouncer-Fehlertoleranzschema wie folgt erstellt: Alle Anwendungsserver greifen auf den Network Load Balancer zu, hinter dem sich zwei PgBouncer befinden.  Jeder PgBouncer betrachtet den gleichen Master-PostgreSQL jedes Shards.  Wenn die AWS-Instanz erneut abst√ºrzt, wird der gesamte Datenverkehr √ºber einen anderen PgBouncer umgeleitet.  Fehlertoleranz Network Load Balancer bietet AWS. <br><br>  Mit diesem Schema k√∂nnen Sie problemlos neue PgBouncer-Server hinzuf√ºgen. <br><img src="https://habrastorage.org/webt/05/uc/da/05ucdayudomunfsxjc_gggs5abe.png"><br><br><h2>  Erstellen eines PostgreSQL-Failoverclusters </h2><br>  Bei der L√∂sung dieses Problems haben wir verschiedene Optionen ber√ºcksichtigt: selbst geschriebenes Failover, repmgr, AWS RDS, Patroni. <br><br><h3>  Selbstgeschriebene Skripte </h3><br>  Sie k√∂nnen die Arbeit des Masters √ºberwachen und im Falle eines Sturzes das Replikat zum Master hochstufen und die Konfiguration von PgBouncer aktualisieren. <br><br>  Die Vorteile dieses Ansatzes sind maximale Einfachheit, da Sie selbst Skripte schreiben und genau verstehen, wie sie funktionieren. <br><br>  Nachteile: <br><br><ul><li>  Der Master stirbt m√∂glicherweise nicht, stattdessen kann ein Netzwerkfehler auftreten.  Ohne dies zu wissen, wird das Replikat an den Master weitergeleitet, und der alte Master arbeitet weiter.  Infolgedessen erhalten wir zwei Server als Master und wissen nicht, welcher von ihnen die neuesten tats√§chlichen Daten enth√§lt.  Diese Situation wird auch als Split-Brain bezeichnet. </li><li>  Wir hatten keine Nachbildung.  In unserer Konfiguration werden der Master und ein Replikat nach dem Umschalten des Replikats auf den Master verschoben, und wir haben keine Replikate mehr. Daher m√ºssen wir manuell ein neues Replikat hinzuf√ºgen. </li><li>  Wir ben√∂tigen eine zus√§tzliche √úberwachung des Failover-Vorgangs, w√§hrend wir 12 PostgreSQL-Shards haben, was bedeutet, dass wir 12 Cluster √ºberwachen m√ºssen.  Wenn Sie die Anzahl der Shards erh√∂hen, m√ºssen Sie immer noch daran denken, das Failover zu aktualisieren. </li></ul><br>  Selbst geschriebenes Failover sieht sehr kompliziert aus und erfordert nicht triviale Unterst√ºtzung.  Mit einem einzelnen PostgreSQL-Cluster ist dies die einfachste Option, die jedoch nicht skaliert werden kann und daher f√ºr uns nicht geeignet ist. <br><br><h3>  Repmgr </h3><br>  Replication Manager f√ºr PostgreSQL-Cluster, der den Betrieb eines PostgreSQL-Clusters verwalten kann.  Gleichzeitig gibt es kein automatisches Failover "out of the box", sodass Sie f√ºr die Arbeit Ihren eigenen "Wrapper" auf die fertige L√∂sung schreiben m√ºssen.  Daher kann alles noch komplizierter werden als bei selbst geschriebenen Skripten. Deshalb haben wir Repmgr nicht einmal ausprobiert. <br><br><h3>  AWS RDS </h3><br>  Es unterst√ºtzt alles, was Sie f√ºr uns ben√∂tigen, kann sichern und unterst√ºtzt einen Verbindungspool.  Es verf√ºgt √ºber eine automatische Umschaltung: Beim Tod des Masters wird das Replikat zum neuen Master, und AWS √§ndert den DNS-Datensatz in den neuen Master, w√§hrend sich die Replikate in verschiedenen AZs befinden k√∂nnen. <br><br>  Zu den Nachteilen geh√∂rt das Fehlen subtiler Einstellungen.  Als Beispiel f√ºr die Feinabstimmung: In unseren F√§llen gibt es Einschr√§nkungen f√ºr TCP-Verbindungen, die in RDS leider nicht m√∂glich sind: <br><br><pre><code class="python hljs">net.ipv4.tcp_keepalive_time=<span class="hljs-number"><span class="hljs-number">10</span></span> net.ipv4.tcp_keepalive_intvl=<span class="hljs-number"><span class="hljs-number">1</span></span> net.ipv4.tcp_keepalive_probes=<span class="hljs-number"><span class="hljs-number">5</span></span> net.ipv4.tcp_retries2=<span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br>  Dar√ºber hinaus ist der AWS RDS-Preis fast doppelt so hoch wie der regul√§re Instanzpreis, was der Hauptgrund f√ºr die Ablehnung dieser Entscheidung war. <br><br><h3>  Patroni </h3><br>  Dies ist eine Python-Vorlage zum Verwalten von PostgreSQL mit guter Dokumentation, automatischem Failover und Github-Quellcode. <br><br>  Vorteile von Patroni: <br><br><ul><li>  Jeder Konfigurationsparameter ist gezeichnet, es ist klar, wie es funktioniert; </li><li>  Das automatische Failover funktioniert sofort. </li><li>  Es ist in Python geschrieben, und da wir selbst viel in Python schreiben, wird es f√ºr uns einfacher sein, mit Problemen umzugehen und m√∂glicherweise sogar bei der Entwicklung des Projekts zu helfen. </li><li>  Es steuert PostgreSQL vollst√§ndig, erm√∂glicht es Ihnen, die Konfiguration auf allen Knoten des Clusters gleichzeitig zu √§ndern. Wenn ein Neustart des Clusters erforderlich ist, um die neue Konfiguration anzuwenden, kann dies mithilfe von Patroni erneut durchgef√ºhrt werden. </li></ul><br>  Nachteile: <br><br><ul><li>  Aus der Dokumentation geht nicht hervor, wie mit PgBouncer gearbeitet werden soll.  Obwohl es schwierig ist, es als Minus zu bezeichnen, besteht die Aufgabe von Patroni darin, PostgreSQL zu verwalten, und wie die Verbindungen zu Patroni verlaufen, ist unser Problem. </li><li>  Es gibt nur wenige Beispiele f√ºr die Implementierung von Patroni in gro√üen Mengen, w√§hrend es viele Beispiele f√ºr die Implementierung von Grund auf gibt. </li></ul><br>  Um einen Failover-Cluster zu erstellen, haben wir Patroni ausgew√§hlt. <br><br><h2>  Patroni-Implementierungsprozess </h2><br>  Vor Patroni hatten wir 12 PostgreSQL-Shards in der Konfiguration, einen Master und ein Replikat mit asynchroner Replikation.  Anwendungsserver haben √ºber den Network Load Balancer auf die Datenbanken zugegriffen, hinter dem zwei Instanzen mit PgBouncer standen, und alle PostgreSQL-Server waren dahinter. <br><img src="https://habrastorage.org/webt/05/uc/da/05ucdayudomunfsxjc_gggs5abe.png"><br><br>  Um Patroni zu implementieren, mussten wir ein verteiltes Cluster-Konfigurations-Repository ausw√§hlen.  Patroni arbeitet mit verteilten Konfigurationsspeichersystemen wie etcd, Zookeeper, Consul.  Wir haben nur einen vollwertigen Consul-Cluster auf dem Produkt, der in Verbindung mit Vault funktioniert, und wir verwenden ihn nicht mehr.  Ein guter Grund, Consul f√ºr den vorgesehenen Zweck zu verwenden. <br><br><h3>  Wie Patroni mit dem Konsul zusammenarbeitet </h3><br>  Wir haben einen Consul-Cluster, der aus drei Knoten besteht, und einen Patroni-Cluster, der aus einem Leader und einem Replikat besteht (in Patroni wird ein Master als Cluster-Leader und Slaves als Replicas bezeichnet).  Jede Instanz eines Patroni-Clusters sendet st√§ndig Informationen zum Clusterstatus an Consul.  Daher k√∂nnen Sie vom Konsul aus immer die aktuelle Konfiguration des Patroni-Clusters herausfinden und herausfinden, wer derzeit der Anf√ºhrer ist. <br><br><img src="https://habrastorage.org/webt/jx/j5/is/jxj5ispkzoegn8x80dw-qtynw3q.png"><br><br>  Um Patroni mit Consul zu verbinden, reicht es aus, die offizielle Dokumentation zu lesen, in der angegeben ist, dass Sie den Host im http- oder https-Format angeben m√ºssen, je nachdem, wie wir mit Consul arbeiten, und optional das Verbindungsschema: <br><br><pre> <code class="plaintext hljs">host: the host:port for the Consul endpoint, in format: http(s)://host:port scheme: (optional) http or https, defaults to http</code> </pre> <br>  Es sieht einfach aus, aber hier beginnen Fallstricke.  Mit Consul arbeiten wir an einer sicheren Verbindung √ºber https und unsere Verbindungskonfiguration sieht folgenderma√üen aus: <br><br><pre> <code class="python hljs">consul: host: https://server.production.consul:<span class="hljs-number"><span class="hljs-number">8080</span></span> verify: true cacert: {{ consul_cacert }} cert: {{ consul_cert }} key: {{ consul_key }}</code> </pre> <br>  Das geht aber nicht  Zu Beginn kann Patroni keine Verbindung zu Consul herstellen, da es trotzdem versucht, http zu folgen. <br><br>  Der Quellcode f√ºr Patroni half bei der L√∂sung des Problems.  Gut, dass es in Python geschrieben ist.  Es stellt sich heraus, dass der Host-Parameter √ºberhaupt nicht analysiert wird und das Protokoll im Schema angegeben werden muss.  Hier ist der Arbeitskonfigurationsblock f√ºr die Zusammenarbeit mit Consul: <br><br><pre> <code class="python hljs">consul: host: server.production.consul:<span class="hljs-number"><span class="hljs-number">8080</span></span> scheme: https verify: true cacert: {{ consul_cacert }} cert: {{ consul_cert }} key: {{ consul_key }}</code> </pre> <br><h3>  Konsul-Vorlage </h3><br>  Daher haben wir Speicher f√ºr eine Konfiguration ausgew√§hlt.  Jetzt m√ºssen Sie verstehen, wie PgBouncer seine Konfiguration √§ndert, wenn Sie den Leader im Patroni-Cluster √§ndern.  Die Dokumentation beantwortet diese Frage nicht, weil  Dort wird die Arbeit mit PgBouncer grunds√§tzlich nicht beschrieben. <br><br>  Auf der Suche nach einer L√∂sung haben wir einen Artikel gefunden (ich erinnere mich leider nicht an den Namen), in dem geschrieben wurde, dass die Consul-Vorlage bei der Verbindung von PgBouncer und Patroni sehr hilfreich war.  Dies veranlasste uns, die Arbeit der Konsul-Vorlage zu studieren. <br><br>  Es stellte sich heraus, dass die Consul-Vorlage die Konfiguration des PostgreSQL-Clusters in Consul st√§ndig √ºberwacht.  Wenn sich der Leader √§ndert, aktualisiert er die PgBouncer-Konfiguration und sendet einen Befehl zum Neustart. <br><br><img src="https://habrastorage.org/webt/iv/_f/j-/iv_fj-sjbnqtfabqlnmu986sa0o.png"><br><br>  Das gro√üe Plus der Vorlage ist, dass sie als Code gespeichert wird. Wenn Sie also einen neuen Shard hinzuf√ºgen, reicht es aus, ein neues Commit durchzuf√ºhren und die Vorlage im automatischen Modus zu aktualisieren, wobei das Prinzip der Infrastruktur als Code unterst√ºtzt wird. <br><br><h3>  Neue Architektur mit Patroni </h3><br>  Als Ergebnis haben wir dieses Arbeitsschema erhalten: <br><img src="https://habrastorage.org/webt/7b/-m/-v/7b-m-vyorrbbuognzt2qx2-fymm.png"><br><br>  Alle Anwendungsserver greifen auf den Balancer zu ‚Üí zwei PgBouncer-Instanzen befinden sich dahinter ‚Üí Auf jeder Instanz wird eine ulonsul-Vorlage gestartet, die den Status jedes Patroni-Clusters √ºberwacht und die Relevanz der PgBouncer-Konfiguration √ºberwacht, die Anforderungen an den aktuellen Leiter jedes Clusters sendet. <br><br><h3>  Manuelle Pr√ºfung </h3><br>  Vor dem Start des Programms haben wir diese Schaltung in einer kleinen Testumgebung gestartet und die Funktion der automatischen Umschaltung √ºberpr√ºft.  Sie √∂ffneten das Brett, bewegten den Aufkleber und "t√∂teten" in diesem Moment den Anf√ºhrer des Clusters.  Deaktivieren Sie in AWS die Instanz einfach √ºber die Konsole. <br><br><img src="https://habrastorage.org/webt/ly/yf/aj/lyyfaj6bxodfoaqrsds5j00ycnw.gif"><br><br>  Der Aufkleber kehrte innerhalb von 10 bis 20 Sekunden zur√ºck und begann sich wieder normal zu bewegen.  Dies bedeutet, dass der Patroni-Cluster ordnungsgem√§√ü funktioniert hat: Er hat den Anf√ºhrer ge√§ndert, die Informationen an Consul gesendet, und die Consul-Vorlage hat diese Informationen sofort erfasst, die PgBouncer-Konfiguration ersetzt und den Befehl zum erneuten Laden gesendet. <br><br><h2>  Wie kann man unter hoher Last √ºberleben und minimale Ausfallzeiten einhalten? </h2><br>  Alles funktioniert super!  Es stellen sich aber neue Fragen: Wie funktioniert es unter hoher Last?  Wie kann man schnell und sicher alles in die Produktion rollen? <br><br>  Die Testumgebung, in der wir Lasttests durchf√ºhren, hilft uns bei der Beantwortung der ersten Frage.  Es ist v√∂llig identisch mit der Produktion in der Architektur und hat Testdaten generiert, deren Volumen ungef√§hr dem der Produktion entspricht.  Wir beschlie√üen, nur einen der PostgreSQL-Assistenten w√§hrend des Tests zu "t√∂ten" und zu sehen, was passiert.  Zuvor ist es jedoch wichtig, das automatische Rollen zu √ºberpr√ºfen, da wir in dieser Umgebung mehrere PostgreSQL-Shards haben, sodass wir vor dem Verkauf hervorragende Tests der Konfigurationsskripte erhalten. <br><br>  Beide Aufgaben sehen ehrgeizig aus, aber wir haben PostgreSQL 9.6.  Vielleicht werden wir sofort auf 11.2 upgraden? <br><br>  Wir beschlie√üen, dies in zwei Schritten zu tun: zuerst ein Upgrade auf 11.2, dann Patroni. <br><br><h3>  PostgreSQL-Update </h3><br>  Um die Version von PostgreSQL schnell zu aktualisieren, m√ºssen Sie die Option <b>-k verwenden</b> , mit der ein fester Link auf der Festplatte erstellt wird und Ihre Daten nicht kopiert werden m√ºssen.  Bei einer Basis von 300-400 GB dauert das Update 1 Sekunde. <br><br>  Wir haben viele Shards, daher muss das Update automatisch durchgef√ºhrt werden.  Zu diesem Zweck haben wir ein Ansible-Playbook geschrieben, das den gesamten Aktualisierungsprozess f√ºr uns ausf√ºhrt: <br><br><pre> <code class="plaintext hljs">/usr/lib/postgresql/11/bin/pg_upgrade \ &lt;b&gt;--link \&lt;/b&gt; --old-datadir='' --new-datadir='' \ --old-bindir='' --new-bindir='' \ --old-options=' -c config_file=' \ --new-options=' -c config_file='</code> </pre> <br>  Hierbei ist zu beachten, dass vor dem Starten des Upgrades das <b>Programm</b> mit dem Parameter <b>--check ausgef√ºhrt</b> werden muss, um die M√∂glichkeit eines Upgrades zu <b>gew√§hrleisten</b> .  Unser Skript ersetzt auch das Upgrade durch Konfigurationen.  Das Skript, das wir in 30 Sekunden fertiggestellt haben, ist ein hervorragendes Ergebnis. <br><br><h3>  Starten Sie Patroni </h3><br>  Um das zweite Problem zu l√∂sen, schauen Sie sich einfach die Konfiguration von Patroni an.  Im offiziellen Repository gibt es eine Beispielkonfiguration mit initdb, die f√ºr die Initialisierung einer neuen Datenbank beim ersten Start von Patroni verantwortlich ist.  Da wir jedoch eine vorgefertigte Datenbank haben, haben wir diesen Abschnitt gerade aus der Konfiguration gel√∂scht. <br><br>  Als wir Patroni auf einem vorgefertigten PostgreSQL-Cluster installierten und ausf√ºhrten, hatten wir ein neues Problem: Beide Server wurden als Leader gestartet.  Patroni wei√ü nichts √ºber den fr√ºhen Status des Clusters und versucht, beide Server als zwei separate Cluster mit demselben Namen zu starten.  L√∂schen Sie das Datenverzeichnis auf dem Slave, um dieses Problem zu beheben: <br><br><pre> <code class="plaintext hljs">rm -rf /var/lib/postgresql/</code> </pre> <br>  <b>Dies darf nur am Sklaven erfolgen!</b> <br><br>  Wenn Sie ein sauberes Replikat verbinden, erstellt Patroni einen Basebackup-Leader, stellt das Replikat wieder her und holt den aktuellen Status durch Wal-Logs ein. <br><br>  Eine weitere Schwierigkeit besteht darin, dass alle PostgreSQL-Cluster standardm√§√üig als main bezeichnet werden.  Wenn jeder Cluster nichts √ºber den anderen wei√ü, ist dies normal.  Wenn Sie jedoch Patroni verwenden m√∂chten, m√ºssen alle Cluster einen eindeutigen Namen haben.  Die L√∂sung besteht darin, den Clusternamen in der PostgreSQL-Konfiguration zu √§ndern. <br><br><h3>  Belastungstest </h3><br>  Wir haben einen Test gestartet, der die Arbeit der Benutzer auf den Boards simuliert.  Als die Last unseren durchschnittlichen Tageswert erreichte, wiederholten wir genau denselben Test und schalteten eine Instanz mit dem Leiter PostgreSQL aus.  Das automatische Failover funktionierte wie erwartet: Patroni wechselte den Leader, Consul-template aktualisierte die Konfiguration von PgBouncer und schickte den Befehl zum Neuladen.  Laut unseren Grafiken in Grafana war klar, dass es Verz√∂gerungen von 20 bis 30 Sekunden und eine kleine Anzahl von Fehlern von Servern im Zusammenhang mit der Verbindung zur Datenbank gibt.  Dies ist eine normale Situation. Solche Werte gelten f√ºr unser Failover und sind definitiv besser als die Ausfallzeit des Dienstes. <br><br><h2>  Patronis Produktion </h2><br>  Als Ergebnis haben wir folgenden Plan erhalten: <br><br><ul><li>  Stellen Sie die Consul-Vorlage auf dem PgBouncer-Server bereit und starten Sie sie. </li><li>  PostgreSQL-Updates auf Version 11.2; </li><li>  √Ñnderung des Clusternamens; </li><li>  Starten eines Patroni-Clusters. </li></ul><br>  Gleichzeitig k√∂nnen Sie mit unserem Schema fast jederzeit das erste Element erstellen. Wir k√∂nnen abwechselnd jeden PgBouncer von der Arbeit entfernen und eine Bereitstellung darauf ausf√ºhren und die Konsul-Vorlage starten.  Also haben wir es getan. <br><br>  F√ºr ein schnelles Rollen haben wir Ansible verwendet, da wir bereits das gesamte Playbook in einer Testumgebung √ºberpr√ºft haben und die Ausf√ºhrungszeit des vollst√§ndigen Skripts f√ºr jeden Shard zwischen 1,5 und 2 Minuten betrug.  Wir k√∂nnten alles abwechselnd f√ºr jeden Shard ausrollen, ohne unseren Service zu beenden, aber wir m√ºssten jedes PostgreSQL f√ºr ein paar Minuten ausschalten.  In diesem Fall k√∂nnten Benutzer, deren Daten sich auf diesem Shard befinden, zu diesem Zeitpunkt nicht vollst√§ndig arbeiten, was f√ºr uns nicht akzeptabel ist. <br><br>  Der Ausweg aus dieser Situation war die geplante Wartung, die alle 3 Monate stattfindet.  Dies ist ein Fenster f√ºr geplante Arbeiten, wenn wir unseren Dienst vollst√§ndig deaktivieren und Datenbankinstanzen aktualisieren.  Es blieb noch eine Woche bis zum n√§chsten Fenster, und wir beschlossen, nur zu warten und uns weiter vorzubereiten.  W√§hrend des Wartens haben wir zus√§tzlich sichergestellt: F√ºr jeden PostgreSQL-Shard haben wir im Falle eines Fehlers ein Ersatzreplikat erstellt, um die neuesten Daten zu speichern, und f√ºr jeden Shard eine neue Instanz hinzugef√ºgt, die ein neues Replikat im Patroni-Cluster werden sollte, um keinen Befehl zum L√∂schen von Daten auszuf√ºhren .  All dies trug dazu bei, das Fehlerrisiko zu minimieren. <br><img src="https://habrastorage.org/webt/ps/ge/yh/psgeyhvrazg-zd1nrochwhl1hag.png"><br><br>  Wir haben unseren Dienst neu gestartet, alles hat so funktioniert, wie es sollte, die Benutzer haben weiter gearbeitet, aber in den Diagrammen haben wir eine ungew√∂hnlich hohe Belastung des Consul-Servers festgestellt. <br><img src="https://habrastorage.org/webt/uk/b9/gu/ukb9guaj4wfabq60v262qe098am.png"><br><br>  Warum haben wir es in der Testumgebung nicht gesehen?  Dieses Problem zeigt sehr gut, dass es notwendig ist, das Prinzip der Infrastruktur als Code zu befolgen und die gesamte Infrastruktur zu verfeinern, beginnend mit Testumgebungen und endend mit der Produktion.  Ansonsten ist es sehr einfach, das Problem zu bekommen, das wir haben.  Was ist passiert?  Consul erschien zuerst in der Produktion und dann in Testumgebungen. Infolgedessen war die Version von Consul in Testumgebungen h√∂her als in der Produktion.  Nur in einer der Versionen wurde ein CPU-Leck bei der Arbeit mit consul-template behoben.  Deshalb haben wir gerade Consul aktualisiert und damit das Problem gel√∂st. <br><br><h3>  Starten Sie den Patroni-Cluster neu </h3><br>  Wir haben jedoch ein neues Problem, das uns nicht einmal bewusst war.  Beim Aktualisieren von Consul entfernen wir einfach den Consul-Knoten mit dem Befehl consul verlassen aus dem Cluster. ‚Üí Patroni stellt eine Verbindung zu einem anderen Consul-Server her. ‚Üí Alles funktioniert.  Als wir jedoch die letzte Instanz des Consul-Clusters erreichten und den Consul-Leave-Befehl an ihn sendeten, wurden alle Patroni-Cluster einfach neu gestartet, und in den Protokollen wurde der folgende Fehler angezeigt: <br><br><pre> <code class="plaintext hljs">ERROR: get_cluster Traceback (most recent call last): ... RetryFailedError: 'Exceeded retry deadline' ERROR: Error communicating with DCS &lt;b&gt;LOG: database system is shut down&lt;/b&gt;</code> </pre> <br>  Der Patroni-Cluster konnte keine Informationen zu seinem Cluster abrufen und wurde neu gestartet. <br><br>  Um eine L√∂sung zu finden, haben wir die Autoren von Patroni √ºber ein Problem mit Github kontaktiert.  Sie schlugen Verbesserungen an unseren Konfigurationsdateien vor: <br><br><pre> <code class="python hljs">consul: consul.checks: [] bootstrap: dcs: retry_timeout: <span class="hljs-number"><span class="hljs-number">8</span></span></code> </pre> <br>  Wir konnten das Problem in einer Testumgebung wiederholen und diese Parameter dort testen, aber leider funktionierten sie nicht. <br><br>  Das Problem ist noch ungel√∂st.  Wir planen, die folgenden L√∂sungen auszuprobieren: <br><br><ul><li>  Verwenden Sie Consul-Agent f√ºr jede Instanz des Patroni-Clusters. </li><li>  Beheben Sie das Problem im Code. </li></ul><br>  Wir wissen, wo der Fehler aufgetreten ist: Das Problem verwendet wahrscheinlich das Standardzeitlimit, das nicht durch die Konfigurationsdatei √ºberschrieben wird.  Wenn der letzte Consul-Server aus dem Cluster entfernt wird, friert der gesamte Consul-Cluster l√§nger als eine Sekunde ein. Aus diesem Grund kann Patroni den Status des Clusters nicht abrufen und startet den gesamten Cluster vollst√§ndig neu. <br><br>  Zum Gl√ºck sind keine Fehler mehr aufgetreten. <br><br><h2>  Ergebnisse der Verwendung von Patroni </h2><br>  Nach dem erfolgreichen Start von Patroni haben wir in jedem Cluster ein zus√§tzliches Replikat hinzugef√ºgt.  Jetzt gibt es in jedem Cluster den Anschein eines Quorums: ein Anf√ºhrer und zwei Repliken - um sich beim Wechsel gegen den Fall des Split-Brain zu versichern. <br><img src="https://habrastorage.org/webt/ef/pn/er/efpner_0rhtuim1zt0gwrhff3b8.png"><br><br>  Patroni arbeitet seit mehr als drei Monaten in der Produktion.  In dieser Zeit hat er es bereits geschafft, uns zu helfen.  Vor kurzem starb der Leiter eines der Cluster in AWS, das automatische Failover funktionierte und die Benutzer arbeiteten weiter.  Patroni erledigte seine Hauptaufgabe. <br><br>  <b>Eine kleine Zusammenfassung der Verwendung von Patroni:</b> <br><br><ul><li>  Bequemlichkeit der √Ñnderung einer Konfiguration.  Es reicht aus, die Konfiguration auf einer Instanz zu √§ndern, und sie wird √ºber den gesamten Cluster gezogen.  Wenn ein Neustart erforderlich ist, um die neue Konfiguration anzuwenden, meldet Patroni dies.  Patroni kann den gesamten Cluster mit einem einzigen Befehl neu starten, was ebenfalls sehr praktisch ist. </li><li>  Das automatische Failover funktioniert und hat es bereits geschafft, uns zu helfen. </li><li>  PostgreSQL-Update ohne Ausfallzeiten der Anwendung.  Sie m√ºssen zuerst die Replikate auf die neue Version aktualisieren, dann den Leader im Patroni-Cluster √§ndern und den alten Leader aktualisieren.  In diesem Fall erfolgt das erforderliche Testen des automatischen Failovers. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de457326/">https://habr.com/ru/post/de457326/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457308/index.html">Auf dem Weg von Sergej Pawlowitsch Korolev. Modernes russisches bemanntes Projekt. Teil 2. Rakete</a></li>
<li><a href="../de457310/index.html">Biologie der Informationsabh√§ngigkeit</a></li>
<li><a href="../de457312/index.html">Einf√ºhrung in die Mengenlehre</a></li>
<li><a href="../de457316/index.html">Wie das Rollenspiel in der realen Welt f√ºr G√§ste Armeniens mit Reisen durch die H√§lfte des Landes arrangiert wird</a></li>
<li><a href="../de457324/index.html">Digitale Veranstaltungen in Moskau vom 24. bis 30. Juni</a></li>
<li><a href="../de457328/index.html">Kategorien anstelle von Verzeichnissen oder das semantische Dateisystem f√ºr Linux</a></li>
<li><a href="../de457330/index.html">Wie kann man schnell interessante Warnungen des PVS-Studio-Analysators f√ºr C- und C ++ - Code √ºberpr√ºfen?</a></li>
<li><a href="../de457332/index.html">Wie kann man schnell interessante Warnungen sehen, die vom PVS-Studio Analyzer f√ºr C- und C ++ - Code generiert wurden?</a></li>
<li><a href="../de457334/index.html">TacacsGUI, Konfigurationsmanager</a></li>
<li><a href="../de457336/index.html">Die Folgen einer vorzeitigen Entfernung von Weisheitsz√§hnen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíáüèø üë©üèø‚Äçü§ù‚Äçüë©üèº üå≥ Todo lo que quer√≠a saber sobre el procesamiento de consultas, pero no quer√≠a preguntar üë®üèø‚Äç‚öïÔ∏è üçá üßëüèæ‚Äçü§ù‚ÄçüßëüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬øQu√© es un servicio de red? Este es un programa que acepta solicitudes entrantes a trav√©s de la red y las procesa, posiblemente devolviendo respuestas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Todo lo que quer√≠a saber sobre el procesamiento de consultas, pero no quer√≠a preguntar</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/432630/"><p>  ¬øQu√© es un servicio de red?  Este es un programa que acepta solicitudes entrantes a trav√©s de la red y las procesa, posiblemente devolviendo respuestas. </p><br><p>  Hay muchos aspectos en los que los servicios de red difieren entre s√≠.  En este art√≠culo, me centro en c√≥mo manejar las solicitudes entrantes. </p><br><p>  Elegir un m√©todo de procesamiento de solicitudes tiene consecuencias de largo alcance.  ¬øC√≥mo hacer un servicio de chat con 100.000 conexiones simult√°neas?  ¬øQu√© enfoque tomar para extraer datos de una secuencia de archivos mal estructurados?  La elecci√≥n incorrecta conducir√° a una p√©rdida de tiempo y energ√≠a. </p><br><p>  El art√≠culo analiza enfoques como un conjunto de procesos / subprocesos, procesamiento orientado a eventos, patr√≥n de media sincronizaci√≥n / mitad de sincronizaci√≥n y muchos otros.  Se dan numerosos ejemplos, se consideran los pros y los contras de los enfoques, se consideran sus caracter√≠sticas y aplicaciones. </p><a name="habracut"></a><br><h2 id="vvedenie">  Introduccion </h2><br><p>  El tema de los m√©todos de procesamiento de consultas no es nuevo, vea, por ejemplo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">uno</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dos</a> .  Sin embargo, la mayor√≠a de los art√≠culos lo consideran solo parcialmente.  Este art√≠culo est√° destinado a llenar los vac√≠os y proporcionar una presentaci√≥n coherente del problema. </p><br><p>  Se considerar√°n los siguientes enfoques: </p><br><ul><li>  procesamiento secuencial </li><li>  proceso de solicitud </li><li>  flujo de solicitud </li><li>  proceso / grupo de subprocesos </li><li>  procesamiento orientado a eventos (patr√≥n de reactor) </li><li>  patr√≥n de media sincronizaci√≥n / mitad as√≠ncrono </li><li>  procesamiento de transportador </li></ul><br><p>  Cabe se√±alar que un servicio que procesa solicitudes no es necesariamente un servicio de red.  Este puede ser un servicio que recibe nuevas tareas de la base de datos o la cola de tareas.  En este art√≠culo, se entiende por servicios de red, pero debe comprender que los enfoques considerados tienen un alcance m√°s amplio. </p><br><h3 id="tldr">  TL; DR </h3><br><p>  Al final del art√≠culo hay una lista con una breve descripci√≥n de cada enfoque. </p><br><h2 id="posledovatelnaya-obrabotka">  Procesamiento secuencial </h2><br><p>  Una aplicaci√≥n consta de un solo hilo en un solo proceso.  Todas las solicitudes se procesan solo secuencialmente.  No hay paralelismo.  Si varias solicitudes llegan al servicio al mismo tiempo, una de ellas se procesa, el resto se pone en cola. </p><br><p>  Adem√°s, este enfoque es f√°cil de implementar.  No hay cerraduras y competencia por los recursos.  La desventaja obvia es la incapacidad de escalar con un gran n√∫mero de clientes. </p><br><h2 id="process-na-zapros">  Proceso de solicitud </h2><br><p>  Una aplicaci√≥n consiste en un proceso central que acepta solicitudes entrantes y flujos de trabajo.  Para cada nueva solicitud, el proceso principal crea un flujo de trabajo que procesa la solicitud.  Escalar por el n√∫mero de solicitudes es simple: cada solicitud tiene su propio proceso. </p><br><p>  No hay nada complicado en esta arquitectura, pero tiene <del>  los problemas </del>  <strong>limitaciones</strong> : </p><br><ul><li>  El proceso consume muchos recursos. <br>  Intente crear 10,000 conexiones simult√°neas a PostgreSQL RDBMS y observe el resultado. </li><li>  Los procesos no tienen memoria compartida (predeterminado).  Si necesita acceso a datos compartidos o un cach√© compartido, tendr√° que mapear la memoria compartida (llamando a linux mmap, munmap) o usar almacenamiento externo (memcahed, redis) </li></ul><br><p>  Estos problemas no se detienen de ninguna manera.  A continuaci√≥n se mostrar√° c√≥mo se gestionan en PostgeSQL RDBMS. </p><br><p>  <strong>Pros de</strong> esta arquitectura: </p><br><ul><li>  La ca√≠da de uno de los procesos no afectar√° a los dem√°s.  Por ejemplo, un error de procesamiento de un caso raro no descartar√° toda la aplicaci√≥n, solo la solicitud procesada sufrir√° </li><li>  Diferenciaci√≥n de derechos de acceso a nivel del sistema operativo.  Dado que el proceso es la esencia del sistema operativo, puede utilizar sus mecanismos est√°ndar para delimitar los derechos de acceso a los recursos del sistema operativo </li><li>  Puede cambiar el proceso de ejecuci√≥n sobre la marcha.  Por ejemplo, si se utiliza un script separado para procesar una solicitud, para reemplazar el algoritmo de procesamiento, es suficiente cambiar el script.  Un ejemplo ser√° considerado a continuaci√≥n. </li><li>  M√°quinas multin√∫cleo utilizadas eficientemente </li></ul><br><p>  <strong>Ejemplos:</strong> </p><br><ul><li>  PostgreSQL RDBMS crea un nuevo proceso para cada nueva conexi√≥n.  La memoria compartida se usa para trabajar con datos generales.  PostgreSQL puede manejar el alto consumo de recursos de los procesos de muchas maneras diferentes.  Si hay pocos clientes (un stand dedicado para analistas), entonces no hay tal problema.  Si hay una sola aplicaci√≥n que accede a la base de datos, puede crear un grupo de conexiones de base de datos en el nivel de la aplicaci√≥n.  Si hay muchas aplicaciones, puede usar pgbouncer </li><li>  sshd escucha las solicitudes entrantes en el puerto 22 y la bifurcaci√≥n en cada conexi√≥n.  Cada conexi√≥n ssh es una bifurcaci√≥n del demonio sshd que recibe y ejecuta los comandos del usuario en secuencia.  Gracias a esta arquitectura, los recursos del sistema operativo se utilizan para diferenciar los derechos de acceso. </li><li>  Un ejemplo de nuestra propia pr√°ctica.  Hay una secuencia de archivos no estructurados de los que necesita obtener metadatos.  El proceso de servicio principal distribuye archivos entre los procesos del controlador.  Cada proceso de controlador es un script que toma una ruta de archivo como par√°metro.  El procesamiento de archivos ocurre en un proceso separado, por lo tanto, debido a un error de procesamiento, el servicio completo no se bloquea.  Para actualizar el algoritmo de procesamiento, es suficiente cambiar los scripts de procesamiento sin detener el servicio. </li></ul><br><p>  En general, debo decir que este enfoque tiene sus ventajas, que determinan su alcance, pero la escalabilidad es muy limitada. </p><br><h2 id="potok-na-zapros">  Solicitar flujo </h2><br><p>  Este enfoque es muy parecido al anterior.  La diferencia es que se utilizan hilos en lugar de procesos.  Esto le permite usar la memoria compartida fuera de la caja.  Sin embargo, las otras ventajas del enfoque anterior ya no se pueden usar, mientras que el consumo de recursos tambi√©n ser√° alto. </p><br><p>  <strong>Pros:</strong> </p><br><ul><li>  Memoria compartida lista para usar </li><li>  Facilidad de implementaci√≥n </li><li>  Uso eficiente de CPU multi-core </li></ul><br><p>  <strong>Contras:</strong> </p><br><ul><li>  Una secuencia consume muchos recursos.  En sistemas operativos tipo Unix, un subproceso consume casi tantos recursos como un proceso. </li></ul><br><p>  Un ejemplo de uso es MySQL.  Pero debe tenerse en cuenta que MySQL utiliza un enfoque mixto, por lo que este ejemplo se discutir√° en la siguiente secci√≥n. </p><br><h2 id="pul-processovpotokov">  Proceso / grupo de subprocesos </h2><br><p>  Los flujos (procesos) crean costosos y largos.  Para no desperdiciar recursos, puede usar el mismo hilo repetidamente.  Habiendo limitado adicionalmente el n√∫mero m√°ximo de hilos, obtenemos un grupo de hilos (procesos).  Ahora el hilo principal acepta solicitudes entrantes y las pone en cola.  Los flujos de trabajo toman solicitudes de la cola y las procesan.  Este enfoque se puede tomar como la escala natural del procesamiento secuencial de solicitudes: cada subproceso de trabajo solo puede procesar flujos secuencialmente, agruparlos le permite procesar solicitudes en paralelo.  Si cada transmisi√≥n puede manejar 1000 rps, entonces 5 transmisiones manejar√°n la carga cerca de 5000 rps (sujeto a una competencia m√≠nima por los recursos compartidos). </p><br><p>  La agrupaci√≥n se puede crear de antemano al inicio del servicio o formarse gradualmente.  Usar un grupo de subprocesos es m√°s com√∫n ya que  le permite aplicar memoria compartida. </p><br><p>  El tama√±o del grupo de subprocesos no tiene que ser limitado.  Un servicio puede usar subprocesos libres del grupo y, si no hay ninguno, crear un nuevo subproceso.  Despu√©s de procesar la solicitud, el subproceso se une al grupo y espera la siguiente solicitud.  Esta opci√≥n es una combinaci√≥n de un enfoque de subprocesos bajo solicitud y un grupo de subprocesos.  Un ejemplo se dar√° a continuaci√≥n. </p><br><p>  <strong>Pros:</strong> </p><br><ul><li>  el uso de muchos n√∫cleos de CPU </li><li>  reducci√≥n de costos para crear un hilo / proceso </li></ul><br><p>  <strong>Contras:</strong> </p><br><ul><li>  Escalabilidad limitada en el n√∫mero de clientes concurrentes.  El uso del grupo nos permite reutilizar el mismo subproceso varias veces sin costos de recursos adicionales, sin embargo, no resuelve el problema fundamental de una gran cantidad de recursos consumidos por el subproceso / proceso.  La creaci√≥n de un servicio de chat que pueda soportar 100,000 conexiones simult√°neas utilizando este enfoque fallar√°. </li><li>  La escalabilidad est√° limitada por los recursos compartidos, por ejemplo, si los subprocesos usan memoria compartida ajustando el acceso a ella mediante sem√°foros / mutexes.  Esta es una limitaci√≥n de todos los enfoques que utilizan recursos compartidos. </li></ul><br><p>  <strong>Ejemplos:</strong> </p><br><ol><li>  Aplicaci√≥n Python que se ejecuta con uWSGI y nginx.  El proceso principal de uWSGI recibe solicitudes entrantes de nginx y las distribuye entre los procesos de Python del int√©rprete que procesan las solicitudes.  La aplicaci√≥n se puede escribir en cualquier marco compatible con uWSGI: Django, Flask, etc. </li><li>  MySQL usa un grupo de subprocesos: cada nueva conexi√≥n es procesada por uno de los subprocesos libres del grupo.  Si no hay hilos libres, MySQL crea un nuevo hilo.  El tama√±o del grupo de subprocesos libres y el n√∫mero m√°ximo de subprocesos (conexiones) est√°n limitados por la configuraci√≥n. </li></ol><br><p>  Quiz√°s este sea uno de los enfoques m√°s comunes para construir servicios de red, si no el m√°s com√∫n.  Le permite escalar bien, alcanzando grandes rps.  La principal limitaci√≥n del enfoque es el n√∫mero de conexiones de red procesadas simult√°neamente.  De hecho, este enfoque funciona bien solo si las solicitudes son cortas o pocos clientes. </p><br><h2 id="sobytiyno-orientirovannaya-obrabotka-reactor-pattern">  Procesamiento orientado a eventos (patr√≥n de reactor) </h2><br><p>  Dos paradigmas, sincr√≥nico y asincr√≥nico, son eternos competidores entre s√≠.  Hasta ahora, solo se han discutido enfoques sincr√≥nicos, pero ser√≠a un error ignorar el enfoque asincr√≥nico.  El procesamiento de solicitudes orientado a eventos o reactivo es un enfoque en el que cada operaci√≥n de E / S se realiza de forma as√≠ncrona y, al final de la operaci√≥n, se llama a un controlador.  Como regla general, el procesamiento de cada solicitud consta de muchas llamadas as√≠ncronas seguidas de la ejecuci√≥n de controladores.  En cualquier momento, una aplicaci√≥n de un solo subproceso ejecuta el c√≥digo de un solo controlador, pero la ejecuci√≥n de los controladores de varias solicitudes se alterna entre s√≠, lo que le permite procesar simult√°neamente (pseudo-paralelo) muchas solicitudes paralelas. </p><br><p>  Una discusi√≥n completa de este enfoque est√° m√°s all√° del alcance de este art√≠culo.  Para una mirada m√°s profunda, puede recomendar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reactor (Reactor)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¬øCu√°l es el secreto de la velocidad de NodeJS?</a>  , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dentro de NGINX</a> .  Aqu√≠ nos limitamos a considerar los pros y los contras de este enfoque. </p><br><p>  <strong>Pros:</strong> </p><br><ul><li>  Escalado efectivo por rps y el n√∫mero de conexiones simult√°neas.  Un servicio reactivo puede procesar simult√°neamente una gran cantidad de conexiones (decenas de miles) si la mayor√≠a de las conexiones est√°n esperando que se complete la E / S </li></ul><br><p>  <strong>Contras:</strong> </p><br><ul><li>  La complejidad del desarrollo.  La programaci√≥n en estilo as√≠ncrono es m√°s dif√≠cil que en s√≠ncrono.  La l√≥gica del procesamiento de solicitudes es m√°s compleja, la depuraci√≥n tambi√©n es m√°s dif√≠cil que en el c√≥digo s√≠ncrono. </li><li>  Errores que conducen al bloqueo de todo el servicio.  Si el idioma o el tiempo de ejecuci√≥n no est√°n dise√±ados originalmente para el procesamiento as√≠ncrono, entonces una sola operaci√≥n sincr√≥nica puede bloquear todo el servicio, negando la posibilidad de escalar. </li><li>  Dif√≠cil de escalar a trav√©s de los n√∫cleos de la CPU.  Este enfoque supone un solo subproceso en un solo proceso, por lo que no puede usar m√∫ltiples n√∫cleos de CPU al mismo tiempo.  Cabe se√±alar que hay formas de evitar esta limitaci√≥n. </li><li>  Corolario del p√°rrafo anterior: este enfoque no escala bien para solicitudes que requieren CPU.  El n√∫mero de rps para este enfoque es inversamente proporcional al n√∫mero de operaciones de CPU requeridas para procesar cada solicitud.  Exigir solicitudes de CPU niega las ventajas de este enfoque. </li></ul><br><p>  <strong>Ejemplos:</strong> </p><br><ol><li>  Node.js utiliza el patr√≥n de reactor listo para usar.  Para obtener m√°s detalles, consulte ¬øCu√°l es el secreto de la velocidad de NodeJS? </li><li>  nginx: los procesos de trabajo de nginx utilizan el patr√≥n del reactor para procesar solicitudes en paralelo.  Ver Inside NGINX para m√°s detalles. </li><li>  Programa C / C ++ que usa directamente herramientas del sistema operativo (epoll en Linux, IOCP en Windows, kqueue en FreeBSD), o usa el marco (libev, libevent, libuv, etc.). </li></ol><br><h2 id="half-synchalf-async">  Media sincronizaci√≥n / mitad as√≠ncrona </h2><br><p>  El nombre se toma de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">POSA: Patrones para objetos concurrentes y en red</a> .  En el original, este patr√≥n se interpreta de manera muy amplia, pero para los prop√≥sitos de este art√≠culo, entender√© este patr√≥n de manera algo m√°s estrecha.  Half sync / half async es un enfoque de procesamiento de solicitudes que utiliza un flujo de control ligero (hilo verde) para cada solicitud.  Un programa consta de uno o m√°s subprocesos a nivel del sistema operativo, sin embargo, el sistema de ejecuci√≥n del programa admite subprocesos verdes que el sistema operativo no ve y no puede controlar. </p><br><p>  Algunos <strong>ejemplos</strong> para hacer la consideraci√≥n m√°s espec√≠fica: </p><br><ol><li>  Servicio en idioma Go.  El lenguaje Go admite muchos hilos de ejecuci√≥n livianos: goroutine.  El programa utiliza uno o m√°s subprocesos del sistema operativo, pero el programador opera con goroutines, que se distribuyen de manera transparente entre los subprocesos del sistema operativo para utilizar CPU de m√∫ltiples n√∫cleos. </li><li>  Servicio de Python con biblioteca gevent.  La biblioteca gevent permite al programador usar hilos verdes en el nivel de la biblioteca.  Todo el programa se ejecuta en un solo hilo del sistema operativo. </li></ol><br><p>  En esencia, este enfoque est√° dise√±ado para combinar el alto rendimiento del enfoque asincr√≥nico con la simplicidad de la programaci√≥n de c√≥digo s√≠ncrono. </p><br><p>  Usando este enfoque, a pesar de la ilusi√≥n de sincronismo, el programa funcionar√° de forma as√≠ncrona: el sistema de ejecuci√≥n del programa controlar√° el bucle de eventos y cada operaci√≥n "sincr√≥nica" en realidad ser√° as√≠ncrona.  Cuando se llama a una operaci√≥n de este tipo, el sistema de ejecuci√≥n llamar√° a la operaci√≥n asincr√≥nica utilizando herramientas del sistema operativo y registrar√° un controlador de finalizaci√≥n de la operaci√≥n.  Cuando se completa la operaci√≥n asincr√≥nica, el sistema de ejecuci√≥n llamar√° al controlador registrado previamente, que continuar√° ejecutando el programa en el punto de invocaci√≥n de la operaci√≥n "sincr√≥nica". </p><br><p>  Como resultado, el enfoque de media sincronizaci√≥n / mitad asincr√≥nica contiene algunas ventajas y algunas desventajas del enfoque asincr√≥nico.  El volumen del art√≠culo no nos permite considerar este enfoque en detalle.  Para aquellos interesados, le aconsejo que lea el cap√≠tulo del mismo nombre en el libro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">POSA: Patrones para objetos concurrentes y en red</a> . </p><br><p>  El enfoque de media sincronizaci√≥n / mitad asincr√≥nica en s√≠ introduce una nueva entidad de "flujo verde": un flujo de control ligero a nivel del programa o del sistema de ejecuci√≥n de la biblioteca.  Qu√© hacer con hilos verdes es una elecci√≥n del programador.  Puede usar un grupo de hilos verdes, puede crear un nuevo hilo verde para cada nueva solicitud.  La diferencia en comparaci√≥n con los subprocesos / procesos del sistema operativo es que los subprocesos verdes son mucho m√°s baratos: consumen mucha menos RAM y se crean mucho m√°s r√°pido.  Esto le permite crear una gran cantidad de hilos verdes, por ejemplo, cientos de miles en el idioma Go.  Una cantidad tan grande justifica el uso del enfoque verde de flujo a pedido. </p><br><p>  <strong>Pros:</strong> </p><br><ul><li>  Se escala bien en rps y la cantidad de conexiones simult√°neas </li><li>  El c√≥digo es m√°s f√°cil de escribir y depurar en comparaci√≥n con el enfoque asincr√≥nico </li></ul><br><p>  <strong>Contras:</strong> </p><br><ul><li>  Dado que la ejecuci√≥n de operaciones es realmente as√≠ncrona, los errores de programaci√≥n son posibles cuando una sola operaci√≥n s√≠ncrona bloquea todo el proceso.  Esto se siente especialmente en lenguajes donde este enfoque se implementa mediante una biblioteca, por ejemplo Python. </li><li>  La opacidad del programa.  Cuando se utilizan subprocesos o procesos del sistema operativo, el algoritmo de ejecuci√≥n del programa es claro: cada subproceso / proceso realiza operaciones en la secuencia en la que est√°n escritos en el c√≥digo.  Utilizando el enfoque de media sincronizaci√≥n / mitad asincr√≥nica, las operaciones que se escriben secuencialmente en el c√≥digo pueden alternar de manera impredecible con operaciones que procesan solicitudes concurrentes. </li><li>  No apto para sistemas en tiempo real.  El procesamiento as√≠ncrono de solicitudes complica enormemente la provisi√≥n de garant√≠as para el tiempo de procesamiento de cada solicitud individual.  Esto es una consecuencia del p√°rrafo anterior. </li></ul><br><p>  Dependiendo de la implementaci√≥n, este enfoque escala bien en todos los n√∫cleos de CPU (Golang) o no escala en absoluto (Python). <br>  Este enfoque, adem√°s de as√≠ncrono, le permite manejar una gran cantidad de conexiones simult√°neas.  Pero programar un servicio usando este enfoque es m√°s f√°cil porque  El c√≥digo est√° escrito en un estilo sincr√≥nico. </p><br><h2 id="konveyernaya-obrabotka">  Procesamiento del transportador </h2><br><p>  Como su nombre lo indica, en este enfoque, las solicitudes se procesan por canalizaci√≥n.  El proceso de procesamiento consta de varios subprocesos del sistema operativo dispuestos en una cadena.  Cada hilo es un enlace en la cadena; realiza un cierto subconjunto de las operaciones necesarias para procesar la solicitud.  Cada solicitud pasa secuencialmente a trav√©s de todos los enlaces de la cadena, y diferentes enlaces en cada momento procesan diferentes solicitudes. </p><br><p>  <strong>Pros:</strong> </p><br><ul><li>  Este enfoque escala bien en rps.  Cuantos m√°s enlaces en la cadena, m√°s solicitudes se procesan por segundo. </li><li>  El uso de m√∫ltiples subprocesos le permite escalar bien en los n√∫cleos de la CPU. </li></ul><br><p>  <strong>Contras:</strong> </p><br><ul><li>  No todas las categor√≠as de consulta son adecuadas para este enfoque.  Por ejemplo, organizar encuestas largas utilizando este enfoque ser√° dif√≠cil e inconveniente. </li><li>  La complejidad de la implementaci√≥n y la depuraci√≥n.  Batir el procesamiento secuencial para que la productividad sea alta puede ser dif√≠cil.  La depuraci√≥n de un programa en el que cada solicitud se procesa secuencialmente en varios subprocesos paralelos es m√°s dif√≠cil que el procesamiento secuencial. </li></ul><br><p>  <strong>Ejemplos:</strong> </p><br><ol><li>  Un ejemplo interesante de procesamiento de transportadores se describi√≥ en el informe highload 2018 La <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">evoluci√≥n de la arquitectura del sistema de negociaci√≥n y compensaci√≥n de la Bolsa de Mosc√∫</a> </li></ol><br><p>  La canalizaci√≥n se usa ampliamente, pero la mayor√≠a de las veces los enlaces son componentes individuales en procesos independientes que intercambian mensajes, por ejemplo, a trav√©s de una cola de mensajes o una base de datos. </p><br><h2 id="rezyume">  Resumen </h2><br><p>  Un breve resumen de los enfoques considerados: </p><br><ul><li>  Procesamiento sincr√≥nico. <br>  Un enfoque simple, pero muy limitado en escalabilidad, tanto en rps como en el n√∫mero de conexiones simult√°neas.  No permite el uso de m√∫ltiples n√∫cleos de CPU simult√°neamente. </li><li>  Un nuevo proceso para cada solicitud. <br>     .         ,      .             .       ( ,     ). </li><li>     . <br>   ,     ,      .       ,      . </li><li>  /. <br>            /.        .    rps    .        .      . </li><li> -  (reactor ). <br>    rps    .   -   ,     .      CPU    </li><li> Half sync/half async. <br>    rps    .         CPU (Golang)     (Python).      ,   ()  .        reactor ,      ,    reactor . </li><li>  . <br>    ,     .       (, long polling   ). </li></ul><br><p>     ,        . </p><br><p>   :    ?    ,        ? </p><br><h3 id="ssylki">  Referencias </h3><br><ol><li>  Art√≠culos relacionados: <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">     </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">     : </a> </li></ul></li><li> - : <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reactor ()</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">    NodeJS?</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Inside NGINX</a> </li></ul></li><li>       : <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache vs Nginx:  </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">       Node.js  PHP</a> </li></ul></li><li> Half sync/half async: <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Half-Sync/Half-Async (Java Design Patterns)</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">POSA: Patterns for Concurrent and Networked Objects</a> </li></ul></li><li>  : <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Green threads ()</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Green Vs Native Threads</a> </li></ul></li><li>  : <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">  -   </a> </li></ul></li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es432630/">https://habr.com/ru/post/es432630/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es432620/index.html">Curso MIT "Seguridad de sistemas inform√°ticos". Lecci√≥n 20: Seguridad del tel√©fono m√≥vil, Parte 3</a></li>
<li><a href="../es432622/index.html">Necesita m√°s desenfoques diferentes</a></li>
<li><a href="../es432624/index.html">Aprenda t√°cticas adversas, t√©cnicas y conocimientos comunes (ATT @ CK). T√°cticas empresariales. Parte 5</a></li>
<li><a href="../es432626/index.html">Formas de interactuar con el sistema: desde cintas perforadas hasta neurointerfaces</a></li>
<li><a href="../es432628/index.html">@Pythonetc Noviembre 2018</a></li>
<li><a href="../es432632/index.html">La historia de Lenny, el troll de spam favorito de Internet Troll</a></li>
<li><a href="../es432634/index.html">Descripci√≥n general de cinco bibliotecas de desarrollo web HTTP</a></li>
<li><a href="../es432636/index.html">Tutorial React Parte 1: Descripci√≥n general del curso, React, ReactDOM y JSX Razones de popularidad</a></li>
<li><a href="../es432638/index.html">Novedades de Upsource 2018.2</a></li>
<li><a href="../es432640/index.html">Lanzamiento de Rust 1.31 y Rust 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
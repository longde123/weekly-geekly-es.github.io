<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôçüèª üï≥Ô∏è üë©üèø‚Äçüî¨ Praktische Anwendung von ELK. Konfigurieren Sie den Logstash „äóÔ∏è üö§ üßöüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einf√ºhrung 
 Bereitstellung des n√§chsten Systems, da eine gro√üe Anzahl verschiedener Protokolle verarbeitet werden muss. Als Werkzeug ELK gew√§hlt. In ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Praktische Anwendung von ELK. Konfigurieren Sie den Logstash</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451264/"><h1>  Einf√ºhrung </h1><br>  Bereitstellung des n√§chsten Systems, da eine gro√üe Anzahl verschiedener Protokolle verarbeitet werden muss.  Als Werkzeug ELK gew√§hlt.  In diesem Artikel werden unsere Erfahrungen mit der Optimierung dieses Stapels erl√§utert. <br><br>  Wir setzen uns nicht das Ziel, alle M√∂glichkeiten zu beschreiben, sondern wollen uns genau auf die L√∂sung praktischer Probleme konzentrieren.  Dies ist darauf zur√ºckzuf√ºhren, dass es bei ausreichend gro√üer Dokumentation und vorgefertigten Bildern viele Fallstricke gibt, zumindest haben wir sie gefunden. <br><a name="habracut"></a><br>  Wir haben den Stack √ºber Docker-Compose bereitgestellt.  Au√üerdem hatten wir eine gut geschriebene docker-compose.yml, mit der wir den Stack fast problemlos anheben konnten.  Und es schien uns, dass der Sieg bereits nahe war, jetzt werden wir uns ein bisschen drehen, um unseren Bed√ºrfnissen zu entsprechen, und das war's. <br><br>  Leider war der Versuch, das System so zu optimieren, dass Protokolle von unserer Anwendung empfangen und verarbeitet werden, nicht von Erfolg gekr√∂nt.  Aus diesem Grund haben wir beschlossen, dass es sich lohnt, jede Komponente einzeln zu untersuchen und dann zu ihren Beziehungen zur√ºckzukehren. <br><br>  Also haben wir mit logstash angefangen. <br><br><h1>  Umgebung, Bereitstellung, Starten Sie Logstash im Container </h1><br>  F√ºr die Bereitstellung verwenden wir Docker-Compose. Die hier beschriebenen Experimente wurden unter MacOS und Ubuntu 18.0.4 durchgef√ºhrt. <br><br>  Das Logstash-Image, das bei uns in der urspr√ºnglichen Datei docker-compose.yml registriert wurde, lautet docker.elastic.co/logstash/logstash:6.3.2 <br><br>  Wir werden es f√ºr Experimente verwenden. <br><br>  Um logstash auszuf√ºhren, haben wir eine separate docker-compose.yml geschrieben.  Nat√ºrlich war es m√∂glich, das Image √ºber die Befehlszeile zu starten, aber wir haben ein bestimmtes Problem gel√∂st, bei dem alles von Docker-Compose gestartet wird. <br><br><h2>  Kurz √ºber Konfigurationsdateien </h2><br>  Wie aus der Beschreibung hervorgeht, kann logstash sowohl f√ºr einen Kanal ausgef√ºhrt werden. In diesem Fall muss die Datei * .conf √ºbertragen werden, oder f√ºr mehrere Kan√§le. In diesem Fall muss die Datei pipelines.yml √ºbertragen werden, die wiederum mit den Dateien verkn√ºpft wird .conf f√ºr jeden Kanal. <br>  Wir gingen den zweiten Weg.  Es schien uns universeller und skalierbarer.  Aus diesem Grund haben wir pipelines.yml erstellt und das Pipelines-Verzeichnis erstellt, in das wir die .conf-Dateien f√ºr jeden Kanal ablegen. <br><br>  Im Container befindet sich eine weitere Konfigurationsdatei - logstash.yml.  Wir ber√ºhren es nicht, verwenden es so wie es ist. <br><br>  Also, die Struktur unserer Verzeichnisse: <br><br><img src="https://habrastorage.org/webt/ci/zd/49/cizd49eci9alvlbi1fwk8nyyaky.png"><br><br>  Um die Eingabe zu erhalten, glauben wir vorerst, dass es sich um TCP auf Port 5046 handelt, und f√ºr die Ausgabe verwenden wir stdout. <br><br>  Hier ist eine so einfache Konfiguration f√ºr den ersten Lauf.  Da ist die anf√§ngliche Aufgabe zu starten. <br><br>  Wir haben also diese docker-compose.yml <br><br><pre><code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro</code> </pre> <br>  Was sehen wir hier? <br><br><ol><li>  Netzwerke und Volumes stammen aus der urspr√ºnglichen docker-compose.yml (der, in der der gesamte Stack gestartet wird), und ich denke, dass sie das Gesamtbild hier nicht wesentlich beeinflussen. </li><li>  Wir erstellen einen Logstash-Service aus dem Image docker.elastic.co/logstash/logstash:6.3.2 und geben ihm den Namen logstash_one_channel. </li><li>  Wir leiten Port 5046 innerhalb des Containers an denselben internen Port weiter. </li><li>  Wir ordnen unsere Kanaleinstellungsdatei ./config/pipelines.yml der Datei /usr/share/logstash/config/pipelines.yml im Container zu, in der logstash sie aufnimmt und f√ºr alle F√§lle schreibgesch√ºtzt macht. </li><li>  Wir zeigen das Verzeichnis ./config/pipelines, in dem sich die Kanaleinstellungsdateien befinden, im Verzeichnis / usr / share / logstash / config / pipelines an und machen es auch schreibgesch√ºtzt. </li></ol><br><img src="https://habrastorage.org/webt/5u/s3/dw/5us3dwu8forutzwmtlfnlcjt-ic.png"><br><br>  Pipelines.yml-Datei <br><br><pre> <code class="plaintext hljs">- pipeline.id: HABR pipeline.workers: 1 pipeline.batch.size: 1 path.config: "./config/pipelines/habr_pipeline.conf"</code> </pre><br>  Hier wird ein Kanal mit der HABR-Kennung und dem Pfad zu seiner Konfigurationsdatei beschrieben. <br><br>  Und schlie√ülich die Datei "./config/pipelines/habr_pipeline.conf" <br><br><pre> <code class="plaintext hljs">input { tcp { port =&gt; "5046" } } filter { mutate { add_field =&gt; [ "habra_field", "Hello Habr" ] } } output { stdout { } }</code> </pre><br>  Lassen Sie uns vorerst nicht auf seine Beschreibung eingehen, sondern versuchen zu rennen: <br><br><pre> <code class="bash hljs">docker-compose up</code> </pre><br>  Was sehen wir? <br><br>  Der Container startete.  Wir k√∂nnen seine Funktion √ºberpr√ºfen: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'13123123123123123123123213123213'</span></span> | nc localhost 5046</code> </pre><br>  Und wir sehen die Antwort in der Containerkonsole: <br><br><img src="https://habrastorage.org/webt/uj/oy/tz/ujoytzcsc_mmiagm05savxahnzm.jpeg"><br><br>  Gleichzeitig sehen wir aber auch: <br><br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,790] <font color="¬´CC0000¬ª">[ERROR] [logstash.licensechecker.licensereader] Lizenzinformationen k√∂nnen nicht vom Lizenzserver abgerufen werden {: message =&gt; "Elasticsearch Nicht erreichbar: [http: // elasticsearch: 9200 /]</font> [Manticore :: ResolutionFailure] elasticsearch ", ... <br><br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,894] [INFO] [logstash.pipeline] Die <font color="green">Pipeline wurde erfolgreich gestartet.</font> {: Pipeline_id =&gt; ". Monitoring-logstash",: thread =&gt; "# &lt;Thread: 0x119abb86 run&gt;"} <br><br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,988] [INFO] [logstash.agent] Pipelines werden ausgef√ºhrt {: count =&gt; 2,: running_pipelines =&gt; [: HABR,: ". Monitoring-logstash"],: non_running_pipelines =&gt; [ ]} <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 00,015] <font color="¬´CC0000¬ª">[</font> FEHLER] <font color="¬´CC0000¬ª">[logstash.inputs.metrics] X-Pack ist auf Logstash installiert, jedoch nicht auf Elasticsearch.</font>  <font color="¬´CC0000¬ª">Bitte installieren Sie X-Pack auf Elasticsearch, um die √úberwachungsfunktion zu verwenden.</font>  <font color="¬´CC0000¬ª">Andere Funktionen sind m√∂glicherweise verf√ºgbar.</font> <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 00,526] [INFO] [logstash.agent] Der Logstash-API-Endpunkt {: port =&gt; 9600} wurde erfolgreich gestartet. <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,478] [INFO] [logstash.outputs.elasticsearch] Ausf√ºhren der Integrit√§tspr√ºfung, um festzustellen, ob eine Elasticsearch-Verbindung funktioniert {: healthcheck_url =&gt; http: // elasticsearch: 9200 /,: path =&gt; "/"} <br>  l <font color="¬´#38B9C7¬ª">ogstash_one_channel |</font>  [2019-04-29T11: 29: 04,487] <font color="orange">[WARN] [logstash.outputs.elasticsearch] Es wurde versucht, die Verbindung zur toten ES-Instanz wiederherzustellen, es ist jedoch ein Fehler aufgetreten.</font>  <font color="orange">{: url =&gt; " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">elasticsearch</a> : 9200 /",: error_type =&gt; LogStash :: Outputs :: ElasticSearch :: HttpClient :: Pool :: HostUnreachableError,: error =&gt; "Elasticsearch nicht erreichbar: [http: // elasticsearch: 9200 / ] [Manticore :: ResolutionFailure] elasticsearch ‚Äù}</font> <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,704] [INFO] [logstash.licensechecker.licensereader] Ausf√ºhren der Integrit√§tspr√ºfung, um festzustellen, ob eine Elasticsearch-Verbindung funktioniert {: healthcheck_url =&gt; http: // elasticsearch: 9200 /,: path =&gt; "/"} <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,710] <font color="orange">[WARN] [logstash.licensechecker.licensereader] Es wurde versucht, die Verbindung zur toten ES-Instanz wiederherzustellen, es ist jedoch ein Fehler aufgetreten.</font>  <font color="orange">{: url =&gt; " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">elasticsearch</a> : 9200 /",: error_type =&gt; LogStash :: Outputs :: ElasticSearch :: HttpClient :: Pool :: HostUnreachableError,: error =&gt; "Elasticsearch nicht erreichbar: [http: // elasticsearch: 9200 / ] [Manticore :: ResolutionFailure] elasticsearch ‚Äù}</font> <br><br>  Und unser Baumstamm schleicht sich st√§ndig an. <br><br>  Hier habe ich gr√ºn eine Meldung hervorgehoben, dass die Pipeline erfolgreich gestartet wurde, rot - eine Fehlermeldung und gelb - eine Meldung √ºber einen Versuch, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">elasticsearch</a> zu kontaktieren: 9200. <br>  Dies liegt daran, dass die im Bild enthaltene logstash.conf die Verf√ºgbarkeit von Elasticsearch √ºberpr√ºft.  Schlie√ülich geht logstash davon aus, dass es als Teil des Elk-Stacks funktioniert, und wir haben es getrennt. <br><br>  Sie k√∂nnen arbeiten, aber nicht bequem. <br><br>  Die L√∂sung besteht darin, diese Pr√ºfung √ºber die Umgebungsvariable XPACK_MONITORING_ENABLED zu deaktivieren. <br><br>  Nehmen Sie eine √Ñnderung an docker-compose.yml vor und f√ºhren Sie sie erneut aus: <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro</code> </pre><br>  Jetzt ist alles in Ordnung.  Der Beh√§lter ist zum Experimentieren bereit. <br><br>  Wir k√∂nnen wieder die n√§chste Konsole eingeben: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'13123123123123123123123213123213'</span></span> | nc localhost 5046</code> </pre><br>  Und siehe: <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "message" =&gt; "13123123123123123123123213123213", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T11:43:44.582Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "host" =&gt; "gateway", logstash_one_channel | "port" =&gt; 49418 logstash_one_channel | }</code> </pre><br><h1>  Arbeiten Sie innerhalb eines Kanals </h1><br>  Also fingen wir an.  Jetzt k√∂nnen Sie sich tats√§chlich die Zeit nehmen, Logstash direkt zu konfigurieren.  Wir werden die Datei pipelines.yml vorerst nicht ber√ºhren. Wir werden sehen, was Sie durch die Arbeit mit einem Kanal erreichen k√∂nnen. <br><br>  Ich muss sagen, dass das allgemeine Prinzip der Arbeit mit der Kanalkonfigurationsdatei im offiziellen Handbuch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> gut beschrieben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ist</a> <br>  Wenn Sie auf Russisch lesen m√∂chten, haben wir diesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel hier verwendet</a> (aber die Abfragesyntax ist dort alt, wir m√ºssen dies ber√ºcksichtigen). <br><br>  Gehen wir nacheinander vom Abschnitt Eingabe aus.  Wir haben bereits Arbeiten an TCP gesehen.  Was k√∂nnte hier noch von Interesse sein? <br><br><h2>  Testen Sie Nachrichten mit Heartbeat </h2><br>  Es gibt eine so interessante M√∂glichkeit, automatische Testnachrichten zu generieren. <br>  Dazu m√ºssen Sie das Heartbean-Plugin in den Eingabeabschnitt aufnehmen. <br><br><pre> <code class="plaintext hljs">input { heartbeat { message =&gt; "HeartBeat!" } }</code> </pre><br>  Einschalten, einmal pro Minute starten, um zu empfangen <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "@timestamp" =&gt; 2019-04-29T13:52:04.567Z, logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "HeartBeat!", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "host" =&gt; "a0667e5c57ec" logstash_one_channel | }</code> </pre><br>  Wir wollen √∂fter bekommen, wir m√ºssen den Intervallparameter hinzuf√ºgen. <br>  So erhalten wir alle 10 Sekunden eine Nachricht. <br><br><pre> <code class="plaintext hljs">input { heartbeat { message =&gt; "HeartBeat!" interval =&gt; 10 } }</code> </pre><br><h2>  Daten aus einer Datei abrufen </h2><br>  Wir haben uns auch f√ºr den Dateimodus entschieden.  Wenn es normal mit der Datei funktioniert, ist es m√∂glich, dass zumindest f√ºr die lokale Verwendung kein Agent ben√∂tigt wird. <br><br>  Gem√§√ü der Beschreibung sollte der Betriebsmodus dem Schwanz-f √§hnlich sein, d.h.  Liest neue Zeilen oder liest optional die gesamte Datei. <br><br>  Also, was wir bekommen wollen: <br><br><ol><li>  Wir m√∂chten Zeilen erhalten, die an eine Protokolldatei angeh√§ngt werden. </li><li>  Wir m√∂chten Daten empfangen, die in mehrere Protokolldateien geschrieben wurden, und gleichzeitig die Freigabe der Daten freigeben. </li><li>  Wir m√∂chten √ºberpr√ºfen, ob beim Neustart von logstash diese Daten nicht erneut empfangen werden. </li><li>  Wir m√∂chten √ºberpr√ºfen, ob Logstash deaktiviert ist und die Daten weiterhin in Dateien geschrieben werden. Wenn wir sie ausf√ºhren, erhalten wir diese Daten. </li></ol><br>  F√ºgen Sie zur Durchf√ºhrung des Experiments eine weitere Zeile zu docker-compose.yml hinzu und √∂ffnen Sie das Verzeichnis, in dem wir die Dateien ablegen. <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro - ./logs:/usr/share/logstash/input</code> </pre><br>  Und √§ndern Sie den Eingabeabschnitt in habr_pipeline.conf <br><br><pre> <code class="plaintext hljs">input { file { path =&gt; "/usr/share/logstash/input/*.log" } }</code> </pre><br>  Wir fangen an: <br><br><pre> <code class="bash hljs">docker-compose up</code> </pre><br>  Um Protokolldateien zu erstellen und aufzuzeichnen, verwenden wir den folgenden Befehl: <br><br><pre> <code class="bash hljs"> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'1'</span></span> &gt;&gt; logs/number1.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:28:53.876Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log" logstash_one_channel | }</code> </pre><br>  Ja, es funktioniert! <br><br>  Gleichzeitig sehen wir, dass wir das Pfadfeld automatisch hinzugef√ºgt haben.  In Zukunft k√∂nnen wir also Datens√§tze danach filtern. <br><br>  Versuchen wir es noch einmal: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'2'</span></span> &gt;&gt; logs/number1.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:28:59.906Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "2", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log" logstash_one_channel | }</code> </pre><br><br>  Und jetzt zu einer anderen Datei: <br><br><pre> <code class="bash hljs"> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'1'</span></span> &gt;&gt; logs/number2.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:29:26.061Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number2.log" logstash_one_channel | }</code> </pre><br>  Gro√üartig!  Die Datei wurde abgeholt, der Pfad war korrekt, alles ist in Ordnung. <br><br>  Stoppen Sie den Logstash und starten Sie ihn neu.  Lass uns warten.  Die Stille.  Das hei√üt,  Wir erhalten diese Aufzeichnungen nicht erneut. <br><br>  Und jetzt das gewagteste Experiment. <br><br>  Wir setzen logstash und f√ºhren aus: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'3'</span></span> &gt;&gt; logs/number2.log <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'4'</span></span> &gt;&gt; logs/number1.log</code> </pre><br>  F√ºhren Sie logstash erneut aus und sehen Sie: <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "3", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number2.log", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:48:50.589Z logstash_one_channel | } logstash_one_channel | { logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "4", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:48:50.856Z logstash_one_channel | }</code> </pre><br>  Hurra!  Alles wurde abgeholt. <br><br>  Wir m√ºssen jedoch vor Folgendem warnen.  Wenn der Container mit logstash gel√∂scht wird (Docker stoppen logstash_one_channel &amp;&amp; Docker rm logstash_one_channel), wird nichts abgeholt.  Im Container wurde die Dateiposition gespeichert, an der sie gelesen wurde.  Wenn es von Grund auf neu ausgef√ºhrt wird, werden nur neue Zeilen akzeptiert. <br><br><h3>  Lesen Sie vorhandene Dateien </h3><br>  Angenommen, wir f√ºhren logstash zum ersten Mal aus, haben aber bereits Protokolle und m√∂chten diese verarbeiten. <br>  Wenn wir logstash mit dem oben verwendeten Eingabeabschnitt ausf√ºhren, erhalten wir nichts.  Nur Zeilenumbr√ºche werden von logstash verarbeitet. <br><br>  F√ºgen Sie dem Eingabeabschnitt eine zus√§tzliche Zeile hinzu, um Zeilen aus vorhandenen Dateien abzurufen: <br><br><pre> <code class="plaintext hljs">input { file { start_position =&gt; "beginning" path =&gt; "/usr/share/logstash/input/*.log" } }</code> </pre><br>  Dar√ºber hinaus gibt es eine Nuance, die nur neue Dateien betrifft, die logstash noch nicht gesehen hat.  F√ºr die gleichen Dateien, die bereits in das Sichtfeld von logstash fielen, erinnerte er sich bereits an ihre Gr√∂√üe und nimmt jetzt nur noch neue Eintr√§ge in sie auf. <br><br>  Lassen Sie uns auf das Studium des Eingabeabschnitts eingehen.  Es gibt viel mehr M√∂glichkeiten, aber f√ºr uns reichen weitere Experimente vorerst aus. <br><br><h2>  Routing und Datenkonvertierung </h2><br>  Versuchen wir, das folgende Problem zu l√∂sen. Nehmen wir an, wir haben Nachrichten von einem Kanal, einige davon sind informativ und teilweise eine Fehlermeldung.  Unterschied im Tag.  Einige INFO, andere FEHLER. <br><br>  Wir m√ºssen sie am Ausgang trennen.  Das hei√üt,  Wir schreiben Informationsnachrichten in einen Kanal und Fehlermeldungen in einen anderen. <br><br>  Gehen Sie dazu vom Eingabebereich zum Filtern und Ausgeben. <br><br>  Mithilfe des Filterabschnitts analysieren wir die eingehende Nachricht und erhalten daraus einen Hash (Schl√ºssel-Wert-Paare), mit dem Sie bereits arbeiten k√∂nnen, d. H.  durch Bedingungen zerlegen.  Und im Ausgabebereich w√§hlen wir Nachrichten aus und senden sie jeweils an unseren Kanal. <br><br><h3>  Analysieren einer Nachricht mit grok </h3><br>  Um Textzeichenfolgen zu analysieren und eine Reihe von Feldern daraus abzurufen, gibt es im Filterbereich ein spezielles Plugin - grok. <br><br>  Da ich hier keine detaillierte Beschreibung geben m√∂chte (hierzu verweise ich auf die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offizielle Dokumentation</a> ), werde ich mein einfaches Beispiel geben. <br><br>  Dazu m√ºssen Sie das Format der Eingabezeilen festlegen.  Ich habe sie: <br><br>  1 INFO message1 <br>  2 ERROR message2 <br><br>  Das hei√üt,  Der Bezeichner kommt zuerst, dann INFO / ERROR, dann ein Wort ohne Leerzeichen. <br>  Nicht schwer, aber genug, um zu verstehen, wie es funktioniert. <br><br>  Im Filterbereich des Grok-Plugins m√ºssen wir also ein Muster f√ºr das Parsen unserer Zeilen definieren. <br><br>  Es wird so aussehen: <br><br><pre> <code class="plaintext hljs">filter { grok { match =&gt; { "message" =&gt; ["%{INT:message_id} %{LOGLEVEL:message_type} %{WORD:message_text}"] } } }</code> </pre><br>  Dies ist im Wesentlichen ein regul√§rer Ausdruck.  Es werden vorgefertigte Muster wie INT, LOGLEVEL, WORD verwendet.  Ihre Beschreibung sowie andere Muster finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier.</a> <br><br>  Wenn Sie diesen Filter durchlaufen, wird unsere Zeichenfolge in einen Hash aus drei Feldern umgewandelt: message_id, message_type, message_text. <br><br>  Sie werden im Ausgabebereich angezeigt. <br><br><h3>  Weiterleiten von Nachrichten im Ausgabeabschnitt mit dem Befehl if </h3><br>  Wie wir uns erinnern, wollten wir im Ausgabeabschnitt die Nachrichten in zwei Streams aufteilen.  Einige - welche iNFO werden wir an die Konsole ausgeben, und mit Fehlern werden wir in eine Datei ausgeben. <br><br>  Wie teilen wir diese Beitr√§ge auf?  Der Zustand des Problems fordert bereits zur L√∂sung auf - wir haben bereits das ausgew√§hlte Feld message_type, das nur zwei Werte INFO und ERROR annehmen kann.  F√ºr ihn werden wir mit der if-Anweisung eine Wahl treffen. <br><br><pre> <code class="plaintext hljs">if [message_type] == "ERROR" { #     } else { #    stdout }</code> </pre><br>  Die Beschreibung der Arbeit mit Feldern und Operatoren finden Sie in diesem Abschnitt des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offiziellen Handbuchs</a> . <br><br>  Nun zur eigentlichen Schlussfolgerung. <br><br>  Bei der Ausgabe an die Konsole ist hier alles klar - stdout {} <br><br>  Und hier ist die Ausgabe der Datei - denken Sie daran, dass wir alles aus dem Container ausf√ºhren und damit die Datei, in die wir das Ergebnis schreiben, von au√üen zug√§nglich ist, m√ºssen wir dieses Verzeichnis in docker-compose.yml √∂ffnen. <br><br>  Gesamt: <br><br>  Der Ausgabeabschnitt unserer Datei sieht folgenderma√üen aus: <br><br><pre> <code class="plaintext hljs"> output { if [message_type] == "ERROR" { file { path =&gt; "/usr/share/logstash/output/test.log" codec =&gt; line { format =&gt; "custom format: %{message}"} } } else {stdout { } } }</code> </pre><br>  F√ºgen Sie in docker-compose.yml ein weiteres Volume zur Ausgabe hinzu: <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro - ./logs:/usr/share/logstash/input - ./output:/usr/share/logstash/output</code> </pre><br>  Wir beginnen, wir versuchen, wir sehen eine Aufteilung in zwei Fl√ºsse. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de451264/">https://habr.com/ru/post/de451264/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de451254/index.html">Kategorie: Unboxing Eisen IaaS-Anbieter</a></li>
<li><a href="../de451256/index.html">Was ist ein ideales Berichtssystem? Ist es realistisch zu verstehen, was im Unternehmen passiert?</a></li>
<li><a href="../de451258/index.html">Fang mich, wenn du kannst. Brief des Managers</a></li>
<li><a href="../de451260/index.html">10 thematische Veranstaltungen der ITMO University</a></li>
<li><a href="../de451262/index.html">Wissenschaftler aus Stanford: Ein Ger√§t im Ohr kann die Funktion des Gehirns √ºberwachen</a></li>
<li><a href="../de451266/index.html">Dreidimensionale Modellierung in der modernen Welt</a></li>
<li><a href="../de451268/index.html">Victor Gamov √ºber Kafka Streams IQ auf jug.msk.ru</a></li>
<li><a href="../de451270/index.html">B = Aufmerksamkeit oder wie man Zeit schafft</a></li>
<li><a href="../de451272/index.html">Wenn Sie bereits an die T√ºr geklopft haben: So sch√ºtzen Sie Informationen auf Ger√§ten</a></li>
<li><a href="../de451274/index.html">Perfekte Waffe, Krieg der Perspektiven und ein Mensch, der die Decke erreicht</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
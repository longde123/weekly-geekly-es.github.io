<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÑ ü§öüèΩ üíÜüèæ LLVM para Tensorflow, o compilador de ley de Moore üë®üèæ‚Äçüíº üôáüèΩ ü§Ωüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El ecosistema TensorFlow contiene una serie de compiladores y optimizadores que trabajan en varios niveles de la pila de software y hardware. Para aqu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>LLVM para Tensorflow, o compilador de ley de Moore</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457826/">  El ecosistema TensorFlow contiene una serie de compiladores y optimizadores que trabajan en varios niveles de la pila de software y hardware.  Para aquellos que usan Tensorflow diariamente, esta pila de m√∫ltiples niveles puede generar errores dif√≠ciles de entender, tanto en tiempo de compilaci√≥n como en tiempo de ejecuci√≥n, asociados con el uso de varios tipos de hardware (GPU, TPU, plataformas m√≥viles, etc.) <br><br>  Estos componentes, comenzando con el gr√°fico de Tensorflow, se pueden representar en la forma de dicho diagrama: <br><br><img src="https://habrastorage.org/webt/ly/cf/0y/lycf0y0ld6eld56mnuba9iyhjii.png"><br><br>  <i>En realidad es m√°s dif√≠cil</i> <br><a name="habracut"></a><br>  En este diagrama, podemos ver que los gr√°ficos de Tensorflow se pueden ejecutar de varias maneras diferentes. <br><br><div class="spoiler">  <b class="spoiler_title">una nota</b> <div class="spoiler_text">  En TensorFlow 2.0, los gr√°ficos pueden ser impl√≠citos; la ejecuci√≥n codiciosa puede ejecutar operaciones individualmente, en grupos o en un gr√°fico completo.  Estos gr√°ficos o fragmentos del gr√°fico deben optimizarse y ejecutarse. <br></div></div><br>  Por ejemplo: <br><br><ul><li>  Enviamos los gr√°ficos al ejecutor de Tensorflow, que llama a n√∫cleos especializados escritos a mano. </li><li>  Convi√©rtalos a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">XLA</a> HLO (representaci√≥n del optimizador de alto nivel XLA): una representaci√≥n de alto nivel del optimizador XLA, que, a su vez, puede llamar al compilador <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LLVM</a> para la CPU o GPU, o continuar usando XLA para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TPU</a> , o combinarlos. </li><li>  Los convertimos a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorRT</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nGraph</a> u otro formato para un conjunto de instrucciones especializadas implementado en hardware. </li><li>  Los convertimos al formato <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow Lite</a> , los ejecutamos en el tiempo de ejecuci√≥n TensorFlow Lite o los convertimos a c√≥digo para ejecutarlos en la GPU o DSP a trav√©s de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API de redes neuronales de Android</a> (NNAPI) o similar. </li></ul><br>  Tambi√©n hay m√©todos m√°s complejos, que incluyen muchos pases de optimizaci√≥n en cada capa, como, por ejemplo, en el marco Grappler, que optimiza las operaciones en TensorFlow. <br><br>  Aunque estas diversas implementaciones de compiladores y representaciones intermedias mejoran el rendimiento, su diversidad plantea un problema para los usuarios finales, como mensajes de error confusos al emparejar estos subsistemas.  Adem√°s, los creadores de nuevas pilas de software y hardware deben ajustar los pasos de optimizaci√≥n y conversi√≥n para cada nuevo caso. <br><br>  Y en virtud de todo esto, nos complace anunciar MLIR, una representaci√≥n intermedia de niveles m√∫ltiples.  Este es un formato de vista intermedio y bibliotecas de compilaci√≥n para usar entre una vista de modelo y un compilador de bajo nivel que genera c√≥digo dependiente del hardware.  Al presentar MLIR, queremos dar paso a nuevas investigaciones en el desarrollo de la optimizaci√≥n de compiladores e implementaciones de compiladores basados ‚Äã‚Äãen componentes de calidad industrial. <br><br>  Esperamos que MLIR sea de inter√©s para muchos grupos, incluidos: <br><br><ul><li>  investigadores compiladores, as√≠ como profesionales que desean optimizar el rendimiento y el consumo de memoria de los modelos de aprendizaje autom√°tico; </li><li>  fabricantes de hardware que buscan una forma de combinar su hardware con Tensorflow, como TPU, neuroprocesadores m√≥viles en tel√©fonos inteligentes y otros ASIC personalizados; </li><li>  personas que desean brindar a los lenguajes de programaci√≥n los beneficios proporcionados por la optimizaci√≥n de compiladores y aceleradores de hardware; </li></ul><br><h3>  ¬øQu√© es el MLIR? </h3><br>  MLIR es esencialmente una infraestructura flexible para compiladores de optimizaci√≥n modernos.  Esto significa que consiste en una especificaci√≥n de representaci√≥n intermedia (IR) y un conjunto de herramientas para transformar esta representaci√≥n.  Cuando hablamos de compiladores, pasar de una vista de nivel superior a una vista de nivel inferior se denomina reducci√≥n, y utilizaremos este t√©rmino en el futuro. <br><br>  MLIR est√° construido bajo la influencia de LLVM y presta descaradamente muchas buenas ideas.  Tiene un sistema de tipo flexible y est√° dise√±ado para representar, analizar y transformar gr√°ficos, combinando muchos niveles de abstracci√≥n en un nivel de compilaci√≥n.  Estas abstracciones incluyen operaciones de Tensorflow, regiones de bucles poli√©dricos anidados, instrucciones de LLVM y operaciones y tipos de punto fijo. <br><br><h3>  Dialectos de MLIR </h3><br>  Para separar los diversos objetivos de software y hardware, MLIR tiene "dialectos", que incluyen: <br><br><ul><li>  TensorFlow IR, que incluye todo lo que se puede hacer en los gr√°ficos de TensorFlow </li><li>  XLA HLO IR, dise√±ado para obtener todos los beneficios proporcionados por el compilador XLA, cuyo resultado podemos obtener c√≥digo para TPU, y no solo. </li><li>  Un dialecto de afinidad experimental dise√±ado espec√≠ficamente para representaciones <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">poli√©dricas</a> y optimizaciones. </li><li>  LLVM IR, 1: 1 que coincide con la vista LLVM nativa, lo que permite a MLIR generar c√≥digo para la GPU y la CPU utilizando LLVM. </li><li>  TensorFlow Lite dise√±ado para generar c√≥digo para plataformas m√≥viles </li></ul><br>  Cada dialecto contiene un conjunto de operaciones espec√≠ficas, que utilizan invariantes, tales como: "es un operador binario, y su entrada y salida son del mismo tipo". <br><br><h3>  Extensiones MLIR </h3><br>  MLIR no tiene una lista fija e incorporada de operaciones intr√≠nsecas globales.  Los dialectos pueden definir tipos completamente personalizados, y de esta manera MLIR puede modelar cosas como el sistema de tipo IR LLVM (que tiene agregados de primera clase), abstracciones de lenguaje de dominio, como tipos cuantificados, importantes para los aceleradores optimizados de ML y, en el futuro, incluso un sistema de tipo Swift o Clang. <br><br>  Si desea adjuntar un nuevo compilador de bajo nivel a este sistema, puede crear un nuevo dialecto y descender del dialecto del gr√°fico TensorFlow a su dialecto.  Esto simplifica el camino para desarrolladores de hardware y desarrolladores de compiladores.  Puede orientar el dialecto a diferentes niveles del mismo modelo, los optimizadores de alto nivel ser√°n responsables de partes espec√≠ficas de IR. <br><br>  Para los investigadores de compiladores y desarrolladores de marcos, MLIR le permite crear transformaciones en cada nivel, puede definir sus propias operaciones y abstracciones en IR, lo que le permite modelar mejor las tareas de su aplicaci√≥n.  Por lo tanto, MLIR es m√°s que una infraestructura de compilador pura, que es LLVM. <br><br>  Aunque MLIR funciona como un compilador para ML, ¬°tambi√©n permite el uso de tecnolog√≠as de aprendizaje autom√°tico!  Esto es muy importante para los ingenieros que desarrollan bibliotecas num√©ricas, y no pueden proporcionar soporte para la variedad completa de modelos y hardware de ML.  La flexibilidad de MLIR facilita la exploraci√≥n de estrategias para el descenso de c√≥digo cuando se mueve entre niveles de abstracci√≥n. <br><br><h3>  Que sigue </h3><br>  Hemos abierto un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">repositorio de GitHub</a> e invitamos a todos los interesados ‚Äã‚Äã(¬°consulte nuestra gu√≠a!).  Lanzaremos algo m√°s que esta caja de herramientas: las especificaciones de dialecto TensorFlow y TF Lite, en los pr√≥ximos meses.  Podemos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">darle</a> m√°s informaci√≥n, para obtener m√°s informaci√≥n, vea la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">presentaci√≥n de Chris Luttner</a> y nuestro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">README en Github</a> . <br><br>  Si desea mantenerse al tanto de todo lo relacionado con MLIR, √∫nase a nuestra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nueva lista de correo</a> , que pronto se centrar√° en los anuncios de lanzamientos futuros de nuestro proyecto.  Qu√©date con nosotros! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/457826/">https://habr.com/ru/post/457826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457812/index.html">"¬°Espera! ¬øQui√©n viene? Video vigilancia en el porche</a></li>
<li><a href="../457814/index.html">Pr√≥ximos pasos para ir 2</a></li>
<li><a href="../457816/index.html">Juju de un vistazo</a></li>
<li><a href="../457820/index.html">C√≥mo hacer crecer un evangelista para su empresa</a></li>
<li><a href="../457824/index.html">Estr√©s infeccioso: sincronizaci√≥n interespec√≠fica de los niveles de cortisol en el ejemplo de los perros y sus due√±os.</a></li>
<li><a href="../457830/index.html">¬øC√≥mo reparar una piscina del patio trasero en 7 horas usando el m√©todo de la ruta cr√≠tica?</a></li>
<li><a href="../457836/index.html">Lo que aprend√≠ al crear Dribbble</a></li>
<li><a href="../457838/index.html">La tecnolog√≠a EDR como elemento de la tr√≠ada nuclear SOC</a></li>
<li><a href="../457842/index.html">Sistema de control de movimiento de naves espaciales Soyuz-TM</a></li>
<li><a href="../457844/index.html">Siete h√°bitos b√°sicos para equipos de desarrollo que trabajan remotamente</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
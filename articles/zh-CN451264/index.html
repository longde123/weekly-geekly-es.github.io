<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⚱️ 🤜🏽 🤽🏿 ELK的实际应用。 配置logstash ⏩ 💅🏻 🐵</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="引言 
 部署下一个系统时，需要处理大量的各种日志。 作为工具选择了ELK。 本文将讨论我们在调整此堆栈方面的经验。 

 我们并没有设定一个描述其所有可能性的目标，但我们想专注于解决实际问题。 这是由于以下事实：存在大量的文档和现成的图像，存在很多陷阱，至少我们发现了这些陷阱。 

 我们通过do...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ELK的实际应用。 配置logstash</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451264/"><h1> 引言 </h1><br> 部署下一个系统时，需要处理大量的各种日志。 作为工具选择了ELK。 本文将讨论我们在调整此堆栈方面的经验。 <br><br> 我们并没有设定一个描述其所有可能性的目标，但我们想专注于解决实际问题。 这是由于以下事实：存在大量的文档和现成的图像，存在很多陷阱，至少我们发现了这些陷阱。 <br><a name="habracut"></a><br> 我们通过docker-compose部署了堆栈。 而且，我们有一个写得很好的docker-compose.yml，它使我们几乎没有问题地提升了堆栈。 对我们来说，胜利似乎已经迫在眉睫，现在我们将稍作调整以适应我们的需求，仅此而已。 <br><br> 不幸的是，尝试调整系统以从我们的应用程序接收和处理日志的尝试并未获得成功。 因此，我们认为值得分别研究每个组件，然后返回它们之间的关系。 <br><br> 因此，我们从logstash开始。 <br><br><h1> 环境，部署，在容器中启动Logstash </h1><br> 为了进行部署，我们使用docker-compose，此处描述的实验是在MacOS和Ubuntu 18.0.4上进行的。 <br><br> 在原始docker-compose.yml中向我们注册的logstash映像是docker.elastic.co/logstash/logstash:6.3.2 <br><br> 我们将其用于实验。 <br><br> 为了运行logstash，我们编写了一个单独的docker-compose.yml。 当然，可以从命令行启动映像，但是我们确实解决了一个特定的问题，其中启动了docker-compose中的所有内容。 <br><br><h2> 简要介绍配置文件 </h2><br> 从描述中可以看出，logstash可以在一个通道中运行，在这种情况下，它需要传输* .conf文件，或者在多个通道中运行，在这种情况下，它需要传输pipelines.yml文件，该文件又将链接到文件.conf每个频道。 <br> 我们走了第二条路。 在我们看来，它似乎更具通用性和可扩展性。 因此，我们创建了pipelines.yml，并创建了pipelines目录，我们将在其中放置每个通道的.conf文件。 <br><br> 容器内还有另一个配置文件-logstash.yml。 我们不触摸它，而是按原样使用它。 <br><br> 因此，目录的结构为： <br><br><img src="https://habrastorage.org/webt/ci/zd/49/cizd49eci9alvlbi1fwk8nyyaky.png"><br><br> 为了获得输入，目前，我们认为它是端口5046上的tcp，对于输出，我们将使用stdout。 <br><br> 这是第一次运行时的简单配置。 由于初始任务是启动。 <br><br> 所以，我们有了这个docker-compose.yml <br><br><pre><code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro</code> </pre> <br> 我们在这里看到什么？ <br><br><ol><li> 网络和卷取自原始的docker-compose.yml（启动整个堆栈的那个），我认为它们不会显着影响此处的整体情况。 </li><li> 我们从docker.elastic.co/logstash/logstash:6.3.2映像创建一个logstash服务，并将其命名为logstash_one_channel。 </li><li> 我们将容器内的端口5046转发到相同的内部端口。 </li><li> 我们将通道设置文件./config/pipelines.yml映射到容器内的文件/usr/share/logstash/config/pipelines.yml中，logstash将在其中将其选中并设为只读，以防万一。 </li><li> 在/ usr / share / logstash / config / pipelines目录中，我们显示./config/pipelines目录，其中包含通道设置文件，并且也将其设置为只读。 </li></ol><br><img src="https://habrastorage.org/webt/5u/s3/dw/5us3dwu8forutzwmtlfnlcjt-ic.png"><br><br>  Pipelines.yml文件 <br><br><pre> <code class="plaintext hljs">- pipeline.id: HABR pipeline.workers: 1 pipeline.batch.size: 1 path.config: "./config/pipelines/habr_pipeline.conf"</code> </pre><br> 在此，将描述具有HABR标识符的一个通道及其配置文件的路径。 <br><br> 最后是文件“ ./config/pipelines/habr_pipeline.conf” <br><br><pre> <code class="plaintext hljs">input { tcp { port =&gt; "5046" } } filter { mutate { add_field =&gt; [ "habra_field", "Hello Habr" ] } } output { stdout { } }</code> </pre><br> 现在让我们不进入他的描述，尝试运行： <br><br><pre> <code class="bash hljs">docker-compose up</code> </pre><br> 我们看到了什么？ <br><br> 容器启动。 我们可以检查其操作： <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'13123123123123123123123213123213'</span></span> | nc localhost 5046</code> </pre><br> 我们在容器控制台中看到了答案： <br><br><img src="https://habrastorage.org/webt/uj/oy/tz/ujoytzcsc_mmiagm05savxahnzm.jpeg"><br><br> 但同时，我们还看到： <br><br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11：28：59,790] <font color="«CC0000»">[错误] [logstash.licensechecker.licensereader]无法从许可证服务器获取许可证信息{：message =&gt;“ Elasticsearch Unreachable：[http：// elasticsearch：9200 /]</font> [Manticore :: ResolutionFailure] elasticsearch“，... <br><br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11：28：59,894] [INFO] [logstash.pipeline] <font color="green">管道已成功启动</font> {：pipeline_id =&gt;“。Monitoring-logstash” ,: thread =&gt;“＃&lt;Thread：0x119abb86 run&gt;”} <br><br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11：28：59,988] [INFO] [logstash.agent]正在运行的管道{：count =&gt; 2 ,: running_pipelines =&gt; [：HABR ,:“。Monitoring-logstash”] ,: non_running_pipelines =&gt; [ ]} <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11：29：00,015] <font color="«CC0000»">[错误] [logstash.inputs.metrics] X-Pack已安装在Logstash上，但未安装在Elasticsearch上。</font>  <font color="«CC0000»">请在Elasticsearch上安装X-Pack以使用监视功能。</font>  <font color="«CC0000»">其他功能可能可用。</font> <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11：29：00,526] [INFO] [logstash.agent]已成功启动Logstash API端点{：port =&gt; 9600} <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11：29：04,478] [INFO] [logstash.outputs.elasticsearch]运行状况检查以查看Elasticsearch连接是否正常工作{：healthcheck_url =&gt; http：// elasticsearch：9200 / ,: path =&gt; “ /”} <br>  l <font color="«#38B9C7»">ogstash_one_channel |</font>  [2019-04-29T11：29：04,487] <font color="orange">[WARN] [logstash.outputs.elasticsearch]试图恢复与死掉的ES实例的连接，但出现错误。</font>  <font color="orange">{：url =&gt;“ elasticsearch：9200 /” ,: error_type =&gt; LogStash ::输出:: ElasticSearch :: HttpClient :: Pool :: HostUnreachableError ,: error =&gt;“ Elasticsearch Unreachable：[http：// elasticsearch：9200 / ] [Manticore :: ResolutionFailure] elasticsearch”}</font> <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11：29：04,704] [INFO] [logstash.licensechecker.licensereader]运行状况检查以查看Elasticsearch连接是否正常工作{：healthcheck_url =&gt; http：// elasticsearch：9200 / ,: path =&gt; “ /”} <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11：29：04,710] <font color="orange">[WARN] [logstash.licensechecker.licensereader]试图恢复与死掉的ES实例的连接，但出现错误。</font>  <font color="orange">{：url =&gt;“ elasticsearch：9200 /” ,: error_type =&gt; LogStash ::输出:: ElasticSearch :: HttpClient :: Pool :: HostUnreachableError ,: error =&gt;“ Elasticsearch Unreachable：[http：// elasticsearch：9200 / ] [Manticore :: ResolutionFailure] elasticsearch”}</font> <br><br> 而且我们的日志一直在爬。 <br><br> 在这里，我以绿色突出显示一条消息，表示管道已成功启动，红色（一条错误消息，黄色）一条有关尝试联系<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">elasticsearch</a>的消息：9200。 <br> 发生这种情况是因为图像中包含的logstash.conf会检查Elasticsearch的可用性。 毕竟，logstash假定它是Elk堆栈的一部分，因此我们将其分开。 <br><br> 您可以工作，但不方便。 <br><br> 解决方案是通过XPACK_MONITORING_ENABLED环境变量禁用此检查。 <br><br> 对docker-compose.yml进行更改，然后再次运行： <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro</code> </pre><br> 现在，一切都很好。 容器已准备好进行实验。 <br><br> 我们可以再次输入下一个控制台： <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'13123123123123123123123213123213'</span></span> | nc localhost 5046</code> </pre><br> 并查看： <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "message" =&gt; "13123123123123123123123213123213", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T11:43:44.582Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "host" =&gt; "gateway", logstash_one_channel | "port" =&gt; 49418 logstash_one_channel | }</code> </pre><br><h1> 在一个渠道内工作 </h1><br> 因此，我们开始了。 现在，您实际上可以花时间直接配置logstash。 我们暂时不会触摸pipelines.yml文件，我们将看到使用一个通道可以得到什么。 <br><br> 我必须说，在官方指南中对使用通道配置文件的一般原理进行了很好的说明， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a> <br> 如果您想用俄语阅读，那么我们<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在这里</a>使用了这篇<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">文章</a> （但是查询语法在那里太旧了，我们必须考虑到这一点）。 <br><br> 让我们依次从“输入”部分开始。 我们已经看到了有关tcp的工作。 这里还有什么有趣的？ <br><br><h2> 使用心跳测试消息 </h2><br> 产生自动测试消息的机会非常有趣。 <br> 为此，您需要在输入部分中包含heartbean插件。 <br><br><pre> <code class="plaintext hljs">input { heartbeat { message =&gt; "HeartBeat!" } }</code> </pre><br> 打开，每分钟启动一次即可接收 <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "@timestamp" =&gt; 2019-04-29T13:52:04.567Z, logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "HeartBeat!", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "host" =&gt; "a0667e5c57ec" logstash_one_channel | }</code> </pre><br> 我们希望得到更多的频率，我们需要添加interval参数。 <br> 这是我们每10秒会收到一条消息的方式。 <br><br><pre> <code class="plaintext hljs">input { heartbeat { message =&gt; "HeartBeat!" interval =&gt; 10 } }</code> </pre><br><h2> 从文件中检索数据 </h2><br> 我们还决定查看文件模式。 如果该文件可以正常使用，则可能至少在本地使用时不需要代理。 <br><br> 根据描述，操作模式应类似于tail -f，即。 读取换行符，或者作为一个选择，读取整个文件。 <br><br> 所以我们想要得到： <br><br><ol><li> 我们想要获取附加到一个日志文件的行。 </li><li> 我们希望接收写入多个日志文件的数据，同时能够共享数据来源。 </li><li> 我们要检查的是，重新启动logstash时，它将不会再次收到此数据。 </li><li> 我们要检查是否禁用了logstash，并且数据继续写入文件中，然后在运行它时，我们将获得此数据。 </li></ol><br> 要进行实验，请在docker-compose.yml中添加另一行，以打开用于放置文件的目录。 <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro - ./logs:/usr/share/logstash/input</code> </pre><br> 并在habr_pipeline.conf中更改输入部分 <br><br><pre> <code class="plaintext hljs">input { file { path =&gt; "/usr/share/logstash/input/*.log" } }</code> </pre><br> 我们开始： <br><br><pre> <code class="bash hljs">docker-compose up</code> </pre><br> 要创建和记录日志文件，我们将使用以下命令： <br><br><pre> <code class="bash hljs"> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'1'</span></span> &gt;&gt; logs/number1.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:28:53.876Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log" logstash_one_channel | }</code> </pre><br> 是的，它有效！ <br><br> 同时，我们看到我们自动添加了路径字段。 因此，将来我们可以通过它过滤记录。 <br><br> 让我们再试一次： <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'2'</span></span> &gt;&gt; logs/number1.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:28:59.906Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "2", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log" logstash_one_channel | }</code> </pre><br><br> 现在到另一个文件： <br><br><pre> <code class="bash hljs"> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'1'</span></span> &gt;&gt; logs/number2.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:29:26.061Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number2.log" logstash_one_channel | }</code> </pre><br> 太好了！ 文件被拾取，路径正确，一切都很好。 <br><br> 停止logstash并重新启动。 等一下 沉默。 即 我们不会再收到这些记录。 <br><br> 现在是最大胆的实验。 <br><br> 我们放入logstash并执行： <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'3'</span></span> &gt;&gt; logs/number2.log <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'4'</span></span> &gt;&gt; logs/number1.log</code> </pre><br> 再次运行logstash，请参阅： <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "3", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number2.log", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:48:50.589Z logstash_one_channel | } logstash_one_channel | { logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "4", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:48:50.856Z logstash_one_channel | }</code> </pre><br> 万岁！ 一切都捡了。 <br><br> 但是，我们必须警告以下内容。 如果删除了带有logstash的容器（docker stop logstash_one_channel &amp;&amp; docker rm logstash_one_channel），则将不会进行任何操作。 在容器内部，保存了读取文件的位置。 如果从头开始，它将仅接受换行。 <br><br><h3> 读取现有文件 </h3><br> 假设我们是第一次运行logstash，但是我们已经有了日志，我们想对其进行处理。 <br> 如果我们使用上面使用的输入部分来运行logstash，那么我们将一无所获。 仅换行符将由logstash处理。 <br><br> 为了从现有文件中提取行，请在输入部分添加另一行： <br><br><pre> <code class="plaintext hljs">input { file { start_position =&gt; "beginning" path =&gt; "/usr/share/logstash/input/*.log" } }</code> </pre><br> 而且，有一个细微差别，这只会影响logstash尚未看到的新文件。 对于已经落入logstash视野中的相同文件，他已经记住了它们的大小，现在只在其中添加新条目。 <br><br> 让我们专注于输入部分的研究。 还有更多选择，但是对我们来说，现在进行进一步的实验就足够了。 <br><br><h2> 路由和数据转换 </h2><br> 让我们尝试解决以下问题，假设我们从一个渠道收到消息，其中一些是参考消息，部分是错误消息。 标签不同。 一些信息，其他错误。 <br><br> 我们需要在输出处将它们分开。 即 我们在一个通道中编写参考消息，而在另一通道中编写错误消息。 <br><br> 为此，请从输入部分转到过滤器并输出。 <br><br> 使用过滤器部分，我们将解析传入的消息，从中获取哈希（键值对），您已经可以使用它，即 根据条件拆卸。 在输出部分，我们选择消息并将其发送到我们的频道。 <br><br><h3> 使用grok解析消息 </h3><br> 为了解析文本字符串并从中获取一组字段，过滤器部分中有一个特殊的插件-grok。 <br><br> 我不打算在这里给出详细说明（为此，我参考<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">官方文档</a> ），我将给出一个简单的示例。 <br><br> 为此，您需要确定输入行的格式。 我有它们： <br><br>  1条信息消息1 <br>  2错误消息2 <br><br> 即 标识符首先出现，然后是INFO / ERROR，然后是一些没有空格的单词。 <br> 不难，但足以理解其工作原理。 <br><br> 因此，在过滤器部分的grok插件中，我们需要定义一种模式来解析行。 <br><br> 它看起来像这样： <br><br><pre> <code class="plaintext hljs">filter { grok { match =&gt; { "message" =&gt; ["%{INT:message_id} %{LOGLEVEL:message_type} %{WORD:message_text}"] } } }</code> </pre><br> 这本质上是一个正则表达式。 使用现成的模式，例如INT，LOGLEVEL，WORD。 它们的描述以及其他模式可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这里</a>找到<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">。</a> <br><br> 现在，通过此过滤器，我们的字符串将变成三个字段的哈希：message_id，message_type，message_text。 <br><br> 它们将显示在输出部分。 <br><br><h3> 使用if命令在输出部分中路由消息 </h3><br> 我们记得在输出部分，我们将消息分成两个流。 有些-iNFO，我们将输出到控制台，如果有错误，我们将输出到文件。 <br><br> 我们如何拆分这些职位？ 问题的状况已经提示解决方案-我们已经选择了message_type字段，该字段只能使用两个值INFO和ERROR。 对于他来说，我们将使用if语句进行选择。 <br><br><pre> <code class="plaintext hljs">if [message_type] == "ERROR" { #     } else { #    stdout }</code> </pre><br> 有关使用字段和运算符的说明，可在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">官方手册的</a>此部分中找到。 <br><br> 现在，关于实际结论本身。 <br><br> 输出到控制台，一切都在这里清楚了-stdout {} <br><br> 这是文件的输出-请记住，我们都是从容器运行所有文件，因此可以从外部访问写入结果的文件，我们需要在docker-compose.yml中打开此目录。 <br><br> 总计： <br><br> 文件的输出部分如下所示： <br><br><pre> <code class="plaintext hljs"> output { if [message_type] == "ERROR" { file { path =&gt; "/usr/share/logstash/output/test.log" codec =&gt; line { format =&gt; "custom format: %{message}"} } } else {stdout { } } }</code> </pre><br> 在docker-compose.yml中添加另一个卷以输出： <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro - ./logs:/usr/share/logstash/input - ./output:/usr/share/logstash/output</code> </pre><br> 我们开始，尝试，我们看到分成两个流程。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN451264/">https://habr.com/ru/post/zh-CN451264/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN451252/index.html">Python中的字符串是否应该可迭代？</a></li>
<li><a href="../zh-CN451254/index.html">类别：拆箱铁IaaS提供商</a></li>
<li><a href="../zh-CN451256/index.html">什么是理想的报告系统。 了解公司正在发生的事情是否现实？</a></li>
<li><a href="../zh-CN451258/index.html">如果可以的话，赶上我。 经理来信</a></li>
<li><a href="../zh-CN451260/index.html">ITMO大学的10个主题活动</a></li>
<li><a href="../zh-CN451266/index.html">现代世界中的三维建模</a></li>
<li><a href="../zh-CN451268/index.html">Victor Gamov在jug.msk.ru上介绍Kafka Streams IQ</a></li>
<li><a href="../zh-CN451270/index.html">B =注意，或如何创造时间</a></li>
<li><a href="../zh-CN451272/index.html">如果您已经敲门：如何保护设备上的信息</a></li>
<li><a href="../zh-CN451274/index.html">完美武器，视角之战和人类登上天花板</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
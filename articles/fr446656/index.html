<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüé® üë©üèª‚Äçüé§ üïç Codage de la parole √† 1600 bits / s avec vocodeur neuronal LPCNet üà¥ üíé ‚òÑÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il s'agit d'une continuation du premier article sur LPCNet . Dans la premi√®re d√©mo, nous avons pr√©sent√© une architecture qui combine le traitement du ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Codage de la parole √† 1600 bits / s avec vocodeur neuronal LPCNet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446656/"><img src="https://habrastorage.org/getpro/habr/post_images/6ba/d56/c2e/6bad56c2eecd2e1aad4190ba40d1be74.jpg"><br><br>  Il s'agit d'une continuation du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premier article sur LPCNet</a> .  Dans la premi√®re d√©mo, nous avons pr√©sent√© une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">architecture</a> qui combine le traitement du signal et l'apprentissage en profondeur pour am√©liorer l'efficacit√© de la synth√®se vocale neuronale.  Cette fois, nous transformerons LPCNet en un codec de parole neuronal avec un tr√®s faible d√©bit binaire (voir l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article scientifique</a> ).  Il peut √™tre utilis√© sur les √©quipements actuels et m√™me sur les t√©l√©phones. <br><br>  Pour la premi√®re fois, un vocodeur neuronal fonctionne en temps r√©el sur un c≈ìur de processeur du t√©l√©phone, et non sur un GPU haute vitesse.  Le d√©bit binaire final de 1600 bps est environ dix fois inf√©rieur √† celui des codecs √† large bande ordinaires.  La qualit√© est bien meilleure que les vocoders existants avec un d√©bit binaire tr√®s faible et comparable aux codecs plus traditionnels qui utilisent un d√©bit binaire plus √©lev√©. <br><a name="habracut"></a><br><h3>  Encodeurs et vocodeurs de forme d'onde </h3><br>  Il existe deux grands types de codecs vocaux: les codeurs de forme d'onde et les vocodeurs.  Les encodeurs de forme d'onde incluent Opus, AMR / AMR-WB et tous les codecs pouvant √™tre utilis√©s pour la musique.  Ils essaient de fournir une forme d'onde d√©cod√©e aussi proche que possible de l'original - en tenant g√©n√©ralement compte de certaines caract√©ristiques perceptuelles.  Les Vocoders, en revanche, sont en fait des synth√©tiseurs.  Le codeur extrait des informations sur la hauteur et la forme du chemin de parole, transmet ces informations au d√©codeur et il synth√©tise de nouveau la parole.  C'est presque comme la reconnaissance vocale suivie de la lecture de texte dans un synth√©tiseur vocal, sauf que l'encodeur de texte est beaucoup plus simple / plus rapide que la reconnaissance vocale (et transmet un peu plus d'informations). <br><br>  Les vocodeurs existent depuis les ann√©es 70, mais comme leurs d√©codeurs effectuent la synth√®se vocale, ils ne peuvent pas √™tre bien meilleurs que les syst√®mes de synth√®se vocale conventionnels, qui jusqu'√† r√©cemment semblaient tout simplement horribles.  C'est pourquoi les vocodeurs √©taient g√©n√©ralement utilis√©s √† des vitesses inf√©rieures √† 3 kB / s.  De plus, les encodeurs de signaux fournissent simplement la meilleure qualit√©.  Cela s'est poursuivi jusqu'√† r√©cemment, lorsque des syst√®mes de synth√®se vocale neuronale tels que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">WaveNet sont apparus</a> .  Soudain, la synth√®se a commenc√© √† sonner beaucoup mieux et, bien s√ªr, il y avait des gens qui voulaient <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">faire un vocodeur √† partir de WaveNet</a> . <br><br><h3>  Pr√©sentation de LPCNet </h3><br>  WaveNet produit une parole de tr√®s haute qualit√©, mais n√©cessite des centaines de gigaflops de puissance de calcul.  LPCNet a consid√©rablement r√©duit la complexit√© de calcul.  Le vocodeur est bas√© sur WaveRNN, qui am√©liore WaveNet en utilisant un r√©seau neuronal r√©current (RNN) et des matrices clairsem√©es.  LPCNet am√©liore encore WaveRNN avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la pr√©diction lin√©aire</a> (LPC), qui fonctionnait bien dans les vocodeurs plus anciens.  Il pr√©dit un √©chantillon √† partir d'une combinaison lin√©aire d'√©chantillons pr√©c√©dents et, surtout, le rend beaucoup plus rapide qu'un r√©seau de neurones.  Bien s√ªr, ce n'est pas universel (sinon les vocoders des ann√©es 70 sonneraient bien), mais cela peut s√©rieusement r√©duire la charge sur le r√©seau neuronal.  Cela vous permet d'utiliser un r√©seau plus petit que WaveRNN sans sacrifier la qualit√©. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/652/8fc/7df/6528fc7df88256e797551173b11f5e1d.png"></div><br>  <i><font color="gray">Examinons de plus pr√®s LPCNet.</font></i>  <i><font color="gray">La partie jaune √† gauche est calcul√©e une fois par trame et sa sortie est utilis√©e pour la fr√©quence d'√©chantillonnage du r√©seau √† droite (bleu).</font></i>  <i><font color="gray">L'unit√© de calcul pr√©dit un √©chantillon au temps t sur la base des √©chantillons pr√©c√©dents et des coefficients de pr√©diction lin√©aire</font></i> <br><br><h1>  Caract√©ristiques de compression </h1><br>  LPCNet synth√©tise la parole √† partir de vecteurs de 20 caract√®res par trame pendant 10 ms.  Parmi ceux-ci, 18 signes sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des</a> coefficients <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cepstraux</a> repr√©sentant la forme du spectre.  Les deux autres d√©crivent la hauteur: un param√®tre pour le pas de pitch (p√©riode de pitch), et l'autre pour la <i>force</i> (la corr√©lation du signal avec lui-m√™me, si vous introduisez un retard par le pitch).  Si vous stockez les param√®tres sous forme de valeurs √† virgule flottante, toutes ces informations prennent jusqu'√† 64 kbit / s pendant le stockage ou la transmission.  C'est trop, car m√™me le codec Opus fournit un codage vocal de tr√®s haute qualit√© √† seulement 16 kbit / s (pour 16 kHz mono).  De toute √©vidence, vous devez appliquer une forte compression ici. <br><br><h3>  La hauteur </h3><br>  Tous les codecs d√©pendent fortement de la hauteur tonale, mais contrairement aux encodeurs de forme d'onde, o√π la hauteur juste "aide √† r√©duire la redondance, les vocodeurs n'ont pas de repli.  Si vous choisissez la mauvaise hauteur, ils commenceront √† g√©n√©rer un discours de mauvaise qualit√© (voire illisible).  Sans entrer dans les d√©tails (voir l'article scientifique), l'encodeur LPCNet peine √† ne pas se tromper de hauteur.  La recherche commence par une recherche de <i>corr√©lations</i> temporelles dans un signal vocal.  Voir ci-dessous comment fonctionne une recherche typique. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3e4/024/a6a/3e4024a6aac9fcd8cd1fb8eb750918e6.gif"><br>  <i><font color="gray">Le pitch est la p√©riode pendant laquelle le pitch est r√©p√©t√©.</font></i>  <i><font color="gray">L'animation recherche le pas qui correspond √† la corr√©lation maximale entre le signal x (n) et sa copie x (nT) avec un retard.</font></i>  <i><font color="gray">La valeur T avec une corr√©lation maximale est un pas de hauteur</font></i> <br><br>  Ces informations doivent √™tre cod√©es avec le moins de bits possible sans trop d√©grader le r√©sultat.  Puisque nous percevons la fr√©quence par nature sur une √©chelle logarithmique (par exemple, chaque octave musicale double la fr√©quence pr√©c√©dente), cela a du sens dans le codage logarithmique.  La hauteur du signal de parole chez la plupart des gens (nous n'essayons pas de couvrir la soprano ici) se situe entre 62,5 et 500 Hz.  Avec sept bits (128 valeurs possibles), nous obtenons une r√©solution d'environ un quart de ton (la diff√©rence entre et avant et re est d'un ton). <br><br>  Alors, avec la hauteur finie?  Enfin, pas si vite.  Les gens ne parlent pas comme des robots des films des ann√©es 60.  La hauteur de la voix peut varier m√™me dans un paquet de 40 millisecondes.  Vous devez en tenir compte, en laissant les bits pour le param√®tre de modification de la hauteur: 3 bits pour coder la diff√©rence jusqu'√† 2,5 demi-tons entre le d√©but et la fin du paquet.  Enfin, vous devez coder la corr√©lation des pas de hauteur, en distinguant les voyelles et les consonnes (par exemple, s et f).  Deux bits suffisent pour la corr√©lation. <br><br><h3>  Cepstrum </h3><br>  Alors que la hauteur contient les caract√©ristiques externes de la parole (prosodie, √©motion, accentuation, ...), la caract√©ristique spectrale d√©termine <i>ce qui a</i> √©t√© dit (sauf pour les langues tonales comme le chinois, o√π la hauteur est importante pour le sens).  Les cordes vocales produisent approximativement le m√™me son pour n'importe quelle voyelle, mais la forme du tractus vocal d√©termine le son qui sera prononc√©.  Le chemin vocal agit comme un filtre et la t√¢che du codeur est d'√©valuer ce filtre et de le transmettre au d√©codeur.  Cela peut √™tre fait efficacement si vous convertissez le spectre en un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cepstre</a> (oui, c'est un ¬´spectre¬ª avec un ordre de lettres modifi√©, ce sont nous des gars dr√¥les dans le traitement du signal num√©rique). <br><br>  Pour un signal d'entr√©e √† 16 kHz, le cepstre repr√©sente essentiellement un vecteur de 18 nombres toutes les 10 ms, qui doivent √™tre compress√©s autant que possible.  √âtant donn√© que nous avons quatre de ces vecteurs dans un paquet de 40 ms et qu'ils sont g√©n√©ralement similaires les uns aux autres, nous voulons √©liminer autant que possible la redondance.  Cela peut √™tre fait en utilisant des vecteurs voisins comme pr√©dicteurs et en ne transmettant que la diff√©rence entre la pr√©diction et la valeur r√©elle.  Dans le m√™me temps, nous ne voulons pas trop d√©pendre des packages pr√©c√©dents si l'un d'eux dispara√Æt.  Il semble que le probl√®me soit d√©j√† r√©solu ... <br><br>  <font color="brown"><i>Si vous n'avez qu'un marteau, tout ressemble √† un clou - Abraham Maslow.</i></font> <br><br>  Si vous avez beaucoup <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travaill√©</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">avec les codecs vid√©o</a> , vous √™tes probablement tomb√© sur le concept des images B.  Contrairement aux codecs vid√©o, qui divisent une trame en plusieurs paquets, nous avons au contraire plusieurs trames dans un seul paquet.  Nous commen√ßons par coder l' <i>image cl√©</i> , c'est-√†-dire le vecteur ind√©pendant et la <b>fin du</b> paquet.  Ce vecteur est cod√© sans pr√©diction, occupant 37 bits: 7 pour l'√©nergie totale (premier coefficient cepstral) et 30 bits pour d'autres param√®tres utilisant la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">quantification vectorielle</a> (VQ).  Viennent ensuite les trames B (hi√©rarchiques).  Des deux mots cl√©s (un du package actuel et un du pr√©c√©dent), un cepstre entre eux est pr√©vu.  En tant que pr√©dicteur pour coder la diff√©rence entre la valeur r√©elle et la pr√©diction, vous pouvez choisir entre deux images cl√©s ou leur valeur moyenne.  Nous utilisons √† nouveau VQ et codons ce vecteur en utilisant un total de 13 bits, y compris le choix du pr√©dicteur.  Il ne nous reste plus que deux vecteurs et tr√®s peu de bits.  Utilisez les 3 derniers bits pour s√©lectionner simplement le pr√©dicteur pour les vecteurs restants.  Bien s√ªr, tout cela est beaucoup plus facile √† comprendre dans la figure: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/530/395/c02/530395c02aba2079c8e82e79f98071f4.png"></div><br>  <i><font color="gray">Pr√©diction et quantification Cepstrum pour le package k.</font></i>  <i><font color="gray">Les vecteurs verts sont quantifi√©s ind√©pendamment, les vecteurs bleus sont pr√©dits et les vecteurs rouges utilisent la pr√©diction sans quantification r√©siduelle.</font></i>  <i><font color="gray">La pr√©diction est indiqu√©e par des fl√®ches.</font></i> <br><br><h3>  Tout mettre ensemble </h3><br>  En ajoutant tout cela, nous obtenons 64 bits par paquet de 40 millisecondes ou 1600 bits par seconde.  Si vous voulez calculer le taux de compression, alors la parole √† large bande non compress√©e est de 256 kbps (16 kHz √† 16 bits par √©chantillon), ce qui signifie un taux de compression de 160 fois!  Bien s√ªr, vous pouvez toujours jouer avec des quantificateurs et obtenir un d√©bit binaire inf√©rieur ou sup√©rieur (avec un effet correspondant sur la qualit√©), mais vous devez commencer quelque part.  Voici un tableau avec la disposition o√π vont ces bits. <br><br><table><tbody><tr><td align="center" colspan="2">  <b>Allocation de bits</b> </td></tr><tr><td>  Param√®tre </td><td>  Bit </td></tr><tr><td>  Pitch pitch </td><td>  6 </td></tr><tr><td>  Modulation de hauteur </td><td>  3 </td></tr><tr><td>  Corr√©lation d'altitude </td><td>  2 </td></tr><tr><td>  √ânergie </td><td>  7 </td></tr><tr><td>  Cepstrum VQ ind√©pendant (40 ms) </td><td>  30 </td></tr><tr><td>  Cepstrum VQ pr√©vu (20 ms) </td><td>  13 </td></tr><tr><td>  Interpolation Cepstrum (10 ms) </td><td>  3 </td></tr><tr><td>  Total </td><td>  64 </td></tr></tbody></table><br>  √Ä 64 bits par paquet 40 ms, √† 25 paquets par seconde, 1600 bps sont obtenus. <br><br><h1>  Impl√©mentation </h1><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code source de LPCNet</a> est disponible sous la licence BSD.  Il comprend une biblioth√®que qui simplifie l'utilisation du codec.  Veuillez noter que le d√©veloppement n'est pas termin√©: le format et l'API sont <b>appel√©s √†</b> changer.  Le r√©f√©rentiel dispose √©galement d'une application de d√©monstration <code>lpcnet_demo</code> dans laquelle il est facile de tester le codec √† partir de la ligne de commande.  Consultez le fichier README.md pour des instructions compl√®tes. <br><br>  Qui veut creuser plus profond√©ment, il y a une option pour former de nouveaux mod√®les et / ou utiliser LPCNet comme bloc de construction pour d'autres applications, telles que la synth√®se vocale (LPCNet n'est qu'un composant du synth√©tiseur, il n'effectue pas de synth√®se seul). <br><br><h3>  Performances </h3><br>  La synth√®se de la parole neuronale n√©cessite beaucoup de ressources.  Lors de la conf√©rence ICASSP de l'ann√©e derni√®re, Bastian Klein et ses coll√®gues de Google / DeepMind ont pr√©sent√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un codec de 2400 bps bas√© sur WaveNet</a> , recevant un flux binaire du codec2.  Bien que cela semble incroyable, la complexit√© de calcul de centaines de gigaflops signifie qu'il ne peut pas √™tre lanc√© en temps r√©el sans un GPU co√ªteux et un effort s√©rieux. <br><br>  Au contraire, notre codec 1600 bit / s ne produit que 3 gigaflops et est con√ßu pour fonctionner en temps r√©el sur des √©quipements beaucoup plus abordables.  En fait, il peut √™tre utilis√© aujourd'hui dans des applications r√©elles.  L'optimisation a n√©cessit√© l'√©criture de code pour les jeux d'instructions AVX2 / FMA et Neon (code int√©gr√© uniquement, sans assembleur).  Gr√¢ce √† cela, nous pouvons d√©sormais encoder (et surtout d√©coder) la parole en temps r√©el non seulement sur un PC, mais aussi sur des t√©l√©phones plus ou moins modernes.  Vous trouverez ci-dessous les performances des processeurs x86 et ARM. <br><br><table><tbody><tr><td colspan="4" align="center">  Performances </td></tr><tr><td>  CPU </td><td>  La fr√©quence </td><td>  % d'un noyau </td><td>  En temps r√©el </td></tr><tr><td>  AMD 2990WX (Threadripper) </td><td>  3,0 GHz * </td><td>  14% </td><td>  7.0x </td></tr><tr><td>  Intel Xeon E5-2640 v4 (Broadwell) </td><td>  2,4 GHz * </td><td>  20% </td><td>  5,0x </td></tr><tr><td>  Snapdragon 855 (Cortex-A76 sur <b>Galaxy S10</b> ) </td><td>  2,82 GHz </td><td>  31% </td><td>  3.2x </td></tr><tr><td>  Snapdragon 845 (Cortex-A75 sur <b>Pixel 3</b> ) </td><td>  2,5 GHz </td><td>  68% </td><td>  1,47x </td></tr><tr><td>  AMD A1100 (Cortex-A57) </td><td>  1,7 GHz </td><td>  102% </td><td>  0,98x </td></tr><tr><td>  BCM2837 (Cortex-A53 sur Raspberry Pi 3) </td><td>  1,2 GHz </td><td>  310% </td><td>  0,32x </td></tr><tr><td>  * mode turbo </td><td></td><td></td><td></td></tr></tbody></table><br><br>  Les chiffres sont assez int√©ressants.  Bien que seuls Broadwell et Threadripper soient affich√©s, sur la plate-forme x86, les processeurs Haswell et Skylake ont des performances similaires (en tenant compte de la fr√©quence d'horloge).  Cependant, les processeurs ARM sont sensiblement diff√©rents les uns des autres.  M√™me en tenant compte de la diff√©rence de fr√©quence A76 est cinq √† six fois plus rapide que A53: c'est tr√®s attendu, car A53 est principalement utilis√© pour l'efficacit√© √©nerg√©tique (par exemple, dans les grands syst√®mes PETITS).  N√©anmoins, LPCNet peut tr√®s bien fonctionner en temps r√©el sur un t√©l√©phone moderne, en utilisant un seul c≈ìur.  Bien qu'il serait bien de l'ex√©cuter en temps r√©el sur le Raspberry Pi 3. Maintenant, c'est loin, mais rien n'est impossible. <br><br>  Sur x86, la raison de la limitation des performances est cinq fois le maximum th√©orique.  Comme vous le savez, les op√©rations de multiplication matrice-vecteur sont moins efficaces que les op√©rations matrice-matrice car il y a plus de t√©l√©chargements par op√©ration - en particulier, un t√©l√©chargement de matrice pour chaque op√©ration FMA.  D'une part, les performances sont li√©es au cache L2, qui ne fournit que 16 bits par cycle.  D'un autre c√¥t√©, Intel pr√©tend que L2 peut donner jusqu'√† 32 bits par cycle sur Broadwell et 64 bits par cycle sur Skylake. <br><br><h1>  R√©sultats </h1><br>  Nous avons effectu√© des tests audio de style MUSHRA pour comparer la qualit√© du codage.  Conditions d'essai: <br><br><ul><li>  <b>√âchantillon</b> : original (si vous obtenez un meilleur r√©sultat que l'original, il y a clairement un probl√®me avec votre test) <br></li><li>  <b>LPCNet 1600 bps</b> : notre d√©mo <br></li><li>  <b>LPNet non compress√©</b> : "LPNet avec 122 unit√©s √©quivalentes" du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premier article</a> <br></li><li>  <b>Opus 9000 bps large bande</b> : le d√©bit binaire le plus bas auquel l'Opus 1.3 code pour l'audio √† large bande <br></li><li>  <b>MELP √† 2400 bps</b> : un vocodeur bien connu avec un faible d√©bit binaire (similaire en qualit√© au codec2) <br></li><li>  <b>Speex 4000 bps</b> : ce vocodeur √† large bande ne doit jamais √™tre utilis√©, mais c'est une bonne r√©f√©rence pour le bas </li></ul><br>  Dans le premier test (set 1), nous avons huit fragments de discours de d√©clarations de deux hommes et deux femmes.  Les fichiers du premier ensemble appartiennent √† la m√™me base de donn√©es (c'est-√†-dire aux m√™mes conditions d'enregistrement) qui a √©t√© utilis√©e pour la formation, mais ces personnes sp√©cifiques ont √©t√© exclues de l'ensemble de formation.  Dans le deuxi√®me test (set 2), nous avons utilis√© certains fichiers du test Opus (non compress√©s), enregistrant le son dans diff√©rentes conditions, pour nous assurer que LPCNet passe √† une g√©n√©ralisation.  Dans les deux tests, 100 participants chacun, donc les erreurs sont assez faibles.  Voir les r√©sultats ci-dessous. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dc6/e7d/cc5/dc6e7dcc5b08735cb492ad07bf7894af.svg"></div><br>  <i><font color="gray">Qualit√© subjective (MUSHRA) en deux tests</font></i> <br><br>  En g√©n√©ral, LPCNet √† 1600 bps semble bon - beaucoup mieux que MELP √† 2400 bps, et pas loin derri√®re Opus √† 9000 bps.  Dans le m√™me temps, LPCNet non compress√© est l√©g√®rement meilleure en qualit√© que Opus √† 9000 bps.  Cela signifie qu'il est possible de fournir une meilleure qualit√© que l'Opus √† des d√©bits binaires de l'ordre de 2000 √† 6 000 bps. <br><br><h3>  √âcoutez-vous </h3><br>  Voici des exemples du test audio: <br><br>  Femme (set 1) <br><br><ul><li>  <a href="">√âchantillon</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet non compress√©</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br>  Homme (set 1) <br><br><ul><li>  <a href="">√âchantillon</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet non compress√©</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br>  Mixte (set 2) <br><br><ul><li>  <a href="">√âchantillon</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet non compress√©</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br><br><h1>  O√π cela peut-il √™tre utilis√©? </h1><br>  Nous pensons qu'il s'agit d'une technologie int√©ressante en soi, mais elle a √©galement des applications pratiques.  Voici quelques options. <br><br><h3>  VoIP dans les pays mal connect√©s </h3><br>  Tout le monde n'a pas toujours une connexion haut d√©bit.  Dans certains pays, la communication est tr√®s lente et peu fiable.  Un codec vocal de 1600 bits fonctionne normalement dans de telles conditions, transmettant m√™me plusieurs fois les paquets pour plus de fiabilit√©.  Bien s√ªr, en raison de la surcharge des en-t√™tes de paquets (40 octets pour IP + UDP + RTP), il est pr√©f√©rable de cr√©er des paquets plus gros: 40, 80 ou 120 ms. <br><br><h3>  Radio amateur / HF </h3><br>  Depuis dix ans maintenant, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">David Rowe</a> travaille sur le codage de la parole pour les communications radio.  Il a d√©velopp√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Codec2</a> , qui transmet la voix √† des vitesses de 700 √† 3200 bps.  Au cours de la derni√®re ann√©e, David et moi avons discut√© de la fa√ßon d'am√©liorer Codec2 √† l'aide de la synth√®se neuronale, et maintenant nous le faisons enfin.  Dans son blog, David a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©crit</a> sur sa propre impl√©mentation du codec bas√© sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LPCNet</a> pour l'int√©gration avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FreeDV</a> . <br><br><h3>  Fiabilit√© accrue en cas de perte de paquets </h3><br>  La capacit√© de coder un train de bits de qualit√© d√©cente dans un petit nombre de bits est utile pour fournir une redondance sur un canal peu fiable.  Opus a un m√©canisme de correction d'erreur directe (FEC) appel√© LBRR, qui code une trame pr√©c√©dente avec un d√©bit binaire inf√©rieur et l'envoie dans la trame actuelle.  Cela fonctionne bien, mais ajoute des frais g√©n√©raux importants.  La duplication de flux √† 1600 bit / s est beaucoup plus efficace. <br><br><h1>  Plans </h1><br>  Il existe de nombreuses autres possibilit√©s pour utiliser LPCNet.  Par exemple, l'am√©lioration des codecs existants (le m√™me Opus).  Comme dans d'autres codecs, la qualit√© d'Opus se d√©grade assez rapidement √† des d√©bits tr√®s faibles (inf√©rieurs √† 8000 bps), car le codec de forme d'onde n'a pas suffisamment de bits pour correspondre √† l'original.  Mais les informations de pr√©diction lin√©aire transmises sont suffisantes pour que LPCNet synth√©tise une parole au son correct - mieux qu'Opus ne peut le faire √† ce d√©bit binaire.  De plus, le reste des informations transmises par Opus (pr√©visions r√©siduelles) aide LPCNet √† synth√©tiser un r√©sultat encore meilleur.  Dans un sens, LPCNet peut √™tre utilis√© comme un post-filtre sophistiqu√© pour am√©liorer la qualit√© d'Opus (ou de tout autre codec) sans changer le flux binaire (c'est-√†-dire tout en conservant une compatibilit√© totale). <br><br><h1>  Ressources suppl√©mentaires </h1><br><ol><li>  J.-M. Valin, J. Skoglund, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vocodeur neuronal √† large bande de 1,6 Kbps utilisant LPCNet</a> , <i>envoy√© √† Interspeech 2019</i> , arXiv: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1903.12087</a> . </li><li>  J.-M. Valin, J. Skoglund, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LPCNet: Advanced Neural Speech Synthesis Through Linear Prediction</a> , <i>Proc.</i>  <i>ICASSP, 2019</i> , arXiv: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1810.11846</a> . </li><li>  A. van den Oord, S.Dileman, H. Zen, K.Simonyan, O.Vinyals, A. Graves, N.Kalkhbrenner, E. Senor, K.Kavukuglu, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">WaveNet: mod√®le g√©n√©ratif pour le son non trait√©</a> , 2016. </li><li>  N. Karlhbrenner, E. Elsen, C.Simonyan, S.Nouri, N.Casagrande, E. Lockhart, F.Stimberg, A. van den Oord, S.Dileman, K.Kavukuglu, Synth√®se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">efficace du son neuronal</a> , 2018. </li><li>  V.B.Klein, F.S.K.Lim, A.Lyubs, J.Skoglund, F.Stimberg, K.Wang, T.S.Walters, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Codage de la parole √† faible d√©bit bas√© sur Wavenet</a> , 2018 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code source de</a> LPCNet. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Codec pour FreeDV bas√© sur LPCNet par</a> David Rowe. </li><li>  Rejoignez la discussion sur le d√©veloppement sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">#opus sur irc.freenode.net</a> (‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">interface web</a> ) </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr446656/">https://habr.com/ru/post/fr446656/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr446642/index.html">Liste de contr√¥le pour la cr√©ation et la publication d'applications Web</a></li>
<li><a href="../fr446646/index.html">InterSystems IRIS 2019.1 Release</a></li>
<li><a href="../fr446648/index.html">D√©veloppement d'op√©rateurs Kubernetes avec Operator Framework</a></li>
<li><a href="../fr446650/index.html">Combien co√ªtent les testeurs et de quoi d√©pendent leurs salaires? Construire le portrait d'un sp√©cialiste en AQ performant</a></li>
<li><a href="../fr446652/index.html">MVCC-4. Instantan√©s de donn√©es</a></li>
<li><a href="../fr446658/index.html">Entretien avec Andrei Stankevich sur la programmation sportive</a></li>
<li><a href="../fr446662/index.html">Transactions et m√©canismes de contr√¥le</a></li>
<li><a href="../fr446666/index.html">Tirez le meilleur parti des calculatrices graphiques: jeux sur la TI-83</a></li>
<li><a href="../fr446668/index.html">Python pour le web: ce qu'un junior doit savoir pour travailler et grandir</a></li>
<li><a href="../fr446674/index.html">Nous mod√©lisons l'algorithme MUSIC pour d√©terminer la direction d'arriv√©e d'une onde √©lectromagn√©tique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
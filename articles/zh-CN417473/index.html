<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤰🏻 💇🏽 🐟 使用DRBD9和Proxmox的可信存储（第1部分：NFS） 🍶 🛋️ 🚴🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="也许至少每个人早晚对搜寻高性能软件定义的存储感到困惑的人早就听说过DRBD ，甚至可能对此有所了解。 


 的确，在Ceph和GlusterFS的流行程度达到顶峰的情况下，它们在原理上相当不错，而且最重要的是开箱即​​用，每个人都对它一点儿忘了。 而且，以前的版本不支持复制到两个以上的节点，因此，...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>使用DRBD9和Proxmox的可信存储（第1部分：NFS）</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417473/"><p><img src="https://habrastorage.org/getpro/habr/post_images/f6a/771/043/f6a7710433c8887d6bbbe4792cc178e1.jpg" alt="图片"></p><br><p> 也许至少每个人早晚对搜寻高性能<strong>软件定义的存储</strong>感到困惑<strong>的人早就听</strong>说过<strong>DRBD</strong> ，甚至可能<strong>对此有所</strong>了解。 </p><br><p> 的确，在<strong>Ceph</strong>和<strong>GlusterFS</strong>的流行程度达到顶峰的情况下，它们在原理上相当不错，而且最重要的是开箱即​​用，每个人都对它一点儿忘了。 而且，以前的版本不支持复制到两个以上的节点，因此，经常会遇到<strong>裂脑</strong>问题，这显然并没有增加它的流行性。 </p><br><p> 该解决方案实际上并不是什么新事物，但是很有竞争力。 在相对较低的成本给CPU和<strong>RAM，DRBD</strong>提供在<strong>块设备</strong>真正快速和安全的同步<strong>。</strong> 在这整个过程中，LINBIT-DRBD开发人员不会停滞不前，并不断对其进行完善。 从<strong>DRBD9</strong>版本开始， <strong>它</strong>不再只是网络镜像，而是更多。 </p><br><p> 首先，为多台服务器创建单个<strong>分布式块设备</strong>的想法已逐渐淡出背景，现在LINBIT试图提供用于编排和管理在<strong>LVM</strong>和<strong>ZFS分区</strong>之上创建的群集中的许多drbd设备的工具。 </p><br><p> 例如，DRBD9最多支持32个副本，RDMA，无盘节点，并且新的编排工具使您可以使用快照，在线迁移等。 </p><br><p> 尽管<strong>DRBD9</strong>具有与<strong>Proxmox</strong> ， <strong>Kubernetes</strong> ， <strong>OpenStack</strong>和<strong>OpenNebula</strong>集成的工具，但目前它们处于过渡模式，当新工具尚未在任何地方得到支持时，旧工具将很快被<em>弃用</em> 。 这些是<strong>DRBDmanage</strong>和<strong>Linstor</strong> 。 </p><br><p> 我将利用这一时刻来不深入介绍每个细节，而是更详细地研究<strong>DRBD9</strong>本身的配置和工作原理。 <a name="habracut"></a> 即使仅仅是因为Linstor控制器的容错配置意味着将其安装在这些设备之一上，您仍然必须弄清楚它。 </p><br><p> 在本文中，我想向您介绍<strong>DRBD9</strong>及其在没有第三方插件的情况下在<strong>Proxmox中</strong>使用的可能性。 </p><br><h2 id="drbdmanage-i-linstor">  DRBD管理和Linstor </h2><br><p> 首先，值得一提的是有关<strong>DRBDmanage的内容</strong> ，它在<strong>Proxmox中的</strong>集成非常好。  LINBIT为Proxmox提供了现成的DRBDmanage插件，使您可以直接从<strong>Proxmox</strong>界面使用其所有功能。 </p><br><p> 它看起来确实很棒，但不幸的是有一些缺点。 </p><br><ul><li>首先，标记的卷名称， <strong>LVM组</strong>或<strong>ZFS池</strong>必须命名为<code>drbdpool</code> 。 </li><li> 每个节点不能使用多个池 </li><li> 根据解决方案的具体情况， <strong>控制器卷</strong>只能在常规LVM上，而不能在其他情况下使用 </li><li> 周期性的<strong>dbus</strong>故障， <strong>DRBDmanage</strong>密切使用<strong>它</strong>来与节点进行交互。 </li></ul><br><p> 结果，LINBIT决定用一个简单的应用程序替换所有复杂的DRBDmanage逻辑，该应用程序使用常规的<strong>tcp连接</strong>与节点进行通信，并且在那里工作时没有任何魔术。 于是就有了<strong>林斯托</strong> 。 </p><br><p>  <strong>Linstor</strong>确实工作得很好。 不幸的是，开发人员选择<strong>Java</strong>作为编写Linstor服务器的主要语言，但不要让这吓到您，因为Linstor本身仅处理在节点上<strong>分发</strong> DRBD <strong>配置</strong>和<strong>切片</strong> LVM / ZFS分区。 </p><br><blockquote> 两种解决方案都是免费的，并根据免费的<strong>GPL3</strong>许可进行分发<strong>。</strong> </blockquote><p> 您可以在<strong>Proxmox</strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">官方Wiki</a>上阅读有关它们的每个信息以及有关为<strong>Proxmox</strong>设置上述插件的信息。 </p><br><h2 id="otkazoustoychivyy-nfs-server"> 故障转移NFS服务器 </h2><br><p> 不幸的是，在撰写本文时， <strong>Linstor仅</strong>与<strong>Kubernetes</strong>集成。 但是到了今年年底，预计其他<strong>Proxmox</strong> ， <strong>OpenNebula</strong> ， <strong>OpenStack</strong>系统的驱动程序将被使用。 </p><br><p> 但是到目前为止，还没有现成的解决方案，但是我们不喜欢旧的一种方法。 让我们尝试使用旧的方式DRBD9来组织对共享分区的<strong>NFS访问</strong> 。 </p><br><p> 尽管如此，决定同样不会没有优势，因为NFS-服务器将允许你组织从多台服务器存储文件系统<strong>竞争性接入</strong> ，而不需要与DLM复杂的集群文件系统，如OCFS和GFS2。 </p><br><p> 在这种情况下，只需将容器与Proxmox界面中的NFS服务器一起迁移，就可以切换<strong>主要</strong> / <strong>辅助</strong>节点的角色。 </p><br><p> 您还可以在此文件系统中存储任何文件，以及虚拟磁盘和备份。 </p><br><p> 如果您使用<strong>Kubernetes，</strong>则可以为<strong>PersistentVolumes</strong>安排<strong>ReadWriteMany</strong>访问。 </p><br><h2 id="proxmox-i-lxc-konteynery">  Proxmox和LXC容器 </h2><br><p> 现在的问题是：为什么选择Proxmox？ </p><br><p> 原则上，要构建这样的方案，我们可以使用Kubernetes以及带有集群管理器的常规方案。 但是<strong>Proxmox</strong>提供了现成的，非常多功能的，同时简单直观的界面，几乎可以满足您的所有需求。 它是现成的，具有<strong>集群</strong>功能，并支持基于softdog的<strong>防护</strong>机制。 并且当使用<strong>LXC容器时，</strong>它允许您在切换时实现最小的超时。 <br> 最终的解决方案将不会有单<strong>点故障</strong> 。 </p><br><p> 实际上，我们将主要使用Proxmox作为<strong>集群管理器</strong> ，在这里我们可以将单独的<strong>LXC容器</strong>视为在经典HA集群中运行的服务，只是区别在于<strong>根系统</strong>也随容器一起提供。 也就是说，您不需要在每个服务器上分别安装多个服务实例，而只能在容器内执行一次。 <br> 如果您曾经使用过<strong>群集管理器软件</strong>并为应用程序提供了<strong>HA</strong> ，您将理解我的意思。 </p><br><h2 id="obschaya-shema"> 一般方案 </h2><br><p> 我们的解决方案将类似于数据库的标准复制方案。 </p><br><ul><li> 我们有<strong>三个节点</strong> </li><li> 每个节点都有一个分布式<strong>drbd设备</strong> 。 </li><li> 该设备具有常规文件系统（ <strong>ext4</strong> ） </li><li> 只有一台服务器可以成为<strong>主</strong>服务器 </li><li>  <strong>LXC容器中</strong>的<strong>NFS服务器</strong>在向导上启动。 </li><li> 所有节点都严格通过<strong>NFS</strong>访问设备<strong>。</strong> </li><li> 如果有必要，该向导可以移动到另一个节点，与<strong>NFS-服务器</strong>一起 </li></ul><br><p>  <strong>DRBD9</strong>具有一项非常酷的功能，可大大简化所有操作： <br> 当drbd设备安装在某个节点上时，它会自动变为“ <strong>主要”</strong> 。 如果该设备被标记为<strong>Primary</strong> ，则任何尝试将其安装在另一个节点上都将导致访问错误。 这样可确保阻止并保证防止同时访问设备。 </p><br><p> 为什么所有这些都大大简化了？ 因为当容器启动时， <strong>Proxmox会</strong>自动在该节点上挂载该设备并将其变为主设备；而当容器停止时，相反，它将对其进行卸载，然后该设备再次变为<strong>辅助</strong>设备。 <br> 因此，我们不再需要担心切换<strong>主要</strong> / <strong>次要</strong>设备，Proxmox会<strong>自动进行</strong>切换，万岁！ </p><br><h2 id="nastroyka-drbd">  DRBD设置 </h2><br><p> 好了，我们已经找到了这个主意，现在让我们继续实施。 </p><br><p> 默认情况下<strong>，</strong> <strong>Linux内核</strong>提供<strong>了</strong> <strong>drbd的第八个版本</strong> ，不幸的是它不<strong>适合</strong>我们，我们需要安装模块的第九个版本。 </p><br><p> 连接LINBIT存储库并安装所需的一切： </p><br><pre> <code class="bash hljs">wget -O- https://packages.linbit.com/package-signing-pubkey.asc | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://packages.linbit.com/proxmox/ proxmox-5 drbd-9.0"</span></span> \ &gt; /etc/apt/sources.list.d/linbit.list apt-get update &amp;&amp; apt-get -y install pve-headers drbd-dkms drbd-utils drbdtop</code> </pre> <br><ul><li>  <code>pve-headers</code> -必要的内核头文件的模块组装 </li><li>  <code>drbd-dkms</code> -DKMS格式的内核模块 </li><li>  <code>drbd-utils</code>基本的DRBD管理实用程序 </li><li>  <code>drbdtop</code>是仅用于DRBD的交互式工具，如top </li></ul><br><p> 安装<strong>模块后，我们将</strong>检查是否一切正常： </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># modprobe drbd # cat /proc/drbd version: 9.0.14-1 (api:2/proto:86-113)</span></span></code> </pre> <br><p> 如果在命令的输出中看到<strong>第八个版本</strong> ，则出了点问题，并且<strong>树内</strong>内核模块已加载。 检查<code>dkms status</code>找出原因。 </p><br><p> 我们拥有的每个节点都将在常规分区之上运行相同的<strong>drbd设备</strong> 。 首先，我们需要为每个节点上的drbd准备本节。 </p><br><p> 这样的分区可以是任何<strong>块设备</strong> ，可以是lvm，zvol，磁盘分区或整个磁盘。 在本文中，我将使用单独的nvme磁盘，并在drbd下使用一个分区： <code>/dev/nvme1n1p1</code> </p><br><p> 值得注意的是，设备名称有时会更改，因此最好立即养成对设备使用恒定符号链接的习惯。 </p><br><p> 查找符号链接<code>/dev/nvme1n1p1</code>可以如下： </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># find /dev/disk/ -lname '*/nvme1n1p1' /dev/disk/by-partuuid/847b9713-8c00-48a1-8dff-f84c328b9da2 /dev/disk/by-path/pci-0000:0e:00.0-nvme-1-part1 /dev/disk/by-id/nvme-eui.0000000001000000e4d25c33da9f4d01-part1 /dev/disk/by-id/nvme-INTEL_SSDPEKKA010T7_BTPY703505FB1P0H-part1</span></span></code> </pre> <br><p> 我们在所有三个节点上描述我们的资源： </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cat /etc/drbd.d/nfs1.res resource nfs1 { meta-disk internal; device /dev/drbd100; protocol C; net { after-sb-0pri discard-zero-changes; after-sb-1pri discard-secondary; after-sb-2pri disconnect; } on pve1 { address 192.168.2.11:7000; disk /dev/disk/by-partuuid/95e7eabb-436e-4585-94ea-961ceac936f7; node-id 0; } on pve2 { address 192.168.2.12:7000; disk /dev/disk/by-partuuid/aa7490c0-fe1a-4b1f-ba3f-0ddee07dfee3; node-id 1; } on pve3 { address 192.168.2.13:7000; disk /dev/disk/by-partuuid/847b9713-8c00-48a1-8dff-f84c328b9da2; node-id 2; } connection-mesh { hosts pve1 pve2 pve3; } }</span></span></code> </pre> <br><p> 建议使用<strong>单独的网络</strong>进行drbd同步。 </p><br><p> 现在为drbd创建元数据并运行它： </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm create-md nfs1 initializing activity log initializing bitmap (320 KB) to all zero Writing meta data... New drbd meta data block successfully created. success # drbdadm up nfs1</span></span></code> </pre> <br><p> 在所有三个节点上重复这些步骤，并检查状态： </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm status nfs1 role:Secondary disk:Inconsistent pve2 role:Secondary peer-disk:Inconsistent pve3 role:Secondary peer-disk:Inconsistent</span></span></code> </pre> <br><p> 现在，我们的<strong>不一致</strong>磁盘位于所有三个节点上，这是因为drbd不知道应将哪个磁盘作为原始磁盘。 我们必须将其中一个标记为“ <strong>主要”，</strong>以便其状态与其他节点同步： </p><br><pre> <code class="bash hljs">drbdadm primary --force nfs1 drbdadm secondary nfs1</code> </pre> <br><p> 此后， <strong>同步</strong>将立即开始： </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm status nfs1 role:Secondary disk:UpToDate pve2 role:Secondary replication:SyncSource peer-disk:Inconsistent done:26.66 pve3 role:Secondary replication:SyncSource peer-disk:Inconsistent done:14.20</span></span></code> </pre><br><p> 我们不必等待它完成，我们可以并行执行其他步骤。 它们可以在<strong>任何节点</strong>上执行，而不管其在DRBD中本地磁盘的当前状态如何。 所有请求将自动重定向到状态为<strong>UpToDate</strong>的设备。 </p><br><p> 不要忘记在节点上激活drbd服务的<strong>自动运行</strong> ： </p><br><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span> drbd.service</code> </pre> <br><h2 id="nastroyka-lxc-konteynera"> 配置LXC容器 </h2><br><p> 我们<strong>将</strong>省略由三个节点组成的<strong>Proxmox集群</strong>的配置部分，该部分在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">官方Wiki中</a>有充分描述 </p><br><p> 如前所述，我们的<strong>NFS服务器</strong>将在<strong>LXC容器中工作</strong> 。 我们将继续在设备上的容器<code>/dev/drbd100</code> ，我们刚刚创建的。 </p><br><p> 首先，我们需要在其上创建一个<strong>文件系统</strong> ： </p><br><pre> <code class="hljs powershell">mkfs <span class="hljs-literal"><span class="hljs-literal">-t</span></span> ext4 <span class="hljs-literal"><span class="hljs-literal">-O</span></span> mmp <span class="hljs-literal"><span class="hljs-literal">-E</span></span> mmp_update_interval=<span class="hljs-number"><span class="hljs-number">5</span></span> /dev/drbd100</code> </pre> <br><p> 默认情况下， <strong>Proxmox</strong>在文件系统级别包括<strong>多重安装保护</strong> ，原则上我们可以不用它，因为 默认情况下，DRBD具有其自身的保护，它仅禁止该设备使用第二个<strong>主要</strong>对象，但谨慎并不会伤害我们。 </p><br><p> 现在下载Ubuntu模板： </p><br><pre> <code class="hljs pgsql"># wget http://download.proxmox.com/images/<span class="hljs-keyword"><span class="hljs-keyword">system</span></span>/ubuntu<span class="hljs-number"><span class="hljs-number">-16.04</span></span>-standard_16<span class="hljs-number"><span class="hljs-number">.04</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>_amd64.tar.gz -P /var/lib/vz/<span class="hljs-keyword"><span class="hljs-keyword">template</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/</code> </pre> <br><p> 并从中创建我们的容器： </p><br><pre> <code class="hljs powershell">pct create <span class="hljs-number"><span class="hljs-number">101</span></span> local:vztmpl/ubuntu<span class="hljs-literal"><span class="hljs-literal">-16</span></span>.<span class="hljs-number"><span class="hljs-number">04</span></span><span class="hljs-literal"><span class="hljs-literal">-standard_16</span></span>.<span class="hljs-number"><span class="hljs-number">04</span></span><span class="hljs-literal"><span class="hljs-literal">-1_amd64</span></span>.tar.gz \ -<span class="hljs-literal"><span class="hljs-literal">-hostname</span></span>=nfs1 \ -<span class="hljs-literal"><span class="hljs-literal">-net0</span></span>=name=eth0,bridge=vmbr0,gw=<span class="hljs-number"><span class="hljs-number">192.168</span></span>.<span class="hljs-number"><span class="hljs-number">1.1</span></span>,ip=<span class="hljs-number"><span class="hljs-number">192.168</span></span>.<span class="hljs-number"><span class="hljs-number">1.11</span></span>/<span class="hljs-number"><span class="hljs-number">24</span></span> \ -<span class="hljs-literal"><span class="hljs-literal">-rootfs</span></span>=volume=/dev/drbd100,shared=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p> 在此命令中，我们指示容器的<strong>根系统</strong>将位于设备<code>/dev/drbd100</code>并添加参数<code>shared=1</code>以允许容器在节点之间<strong>迁移</strong> 。 </p><br><p> 如果出现问题，您可以随时通过<strong>Proxmox</strong>界面或在<code>/etc/pve/lxc/101.conf</code>容器<code>/etc/pve/lxc/101.conf</code>中对其进行<code>/etc/pve/lxc/101.conf</code> </p><br><p>  Proxmox将解压缩模板并为我们准备容器<strong>根系统</strong> 。 之后，我们可以启动我们的容器： </p><br><pre> <code class="hljs pgsql">pct <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span></code> </pre> <br><h2 id="nastroyka-nfs-servera"> 配置NFS服务器。 </h2><br><p> 默认情况下，Proxmox <strong>不允许</strong> <strong>NFS服务器</strong>在容器中运行，但是有多种方法可以启用它。 </p><br><p> 其中之一就是添加<code>lxc.apparmor.profile: unconfined</code>到我们容器的<code>/etc/pve/lxc/100.conf</code> 。 </p><br><p> 或者我们可以持续为所有容器<strong>启用NFS</strong> ，为此，我们需要更新所有节点上LXC的标准模板，将以下行添加到<code>/etc/apparmor.d/lxc/lxc-default-cgns</code> ： </p><br><pre> <code class="hljs nginx"> <span class="hljs-attribute"><span class="hljs-attribute">mount</span></span> fstype=nfs, mount fstype=nfs4, mount fstype=nfsd, mount fstype=rpc_pipefs,</code> </pre> <br><p> 更改之后，重新启动容器： </p><br><pre> <code class="hljs pgsql">pct shutdown <span class="hljs-number"><span class="hljs-number">101</span></span> pct <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span></code> </pre> <br><p> 现在让我们登录它： </p><br><pre> <code class="hljs perl">pct <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span> bash</code> </pre> <br><p> 安装更新和<strong>NFS服务器</strong> ： </p><br><pre> <code class="hljs powershell">apt<span class="hljs-literal"><span class="hljs-literal">-get</span></span> update apt<span class="hljs-literal"><span class="hljs-literal">-get</span></span> <span class="hljs-literal"><span class="hljs-literal">-y</span></span> upgrade apt<span class="hljs-literal"><span class="hljs-literal">-get</span></span> <span class="hljs-literal"><span class="hljs-literal">-y</span></span> install nfs<span class="hljs-literal"><span class="hljs-literal">-kernel</span></span><span class="hljs-literal"><span class="hljs-literal">-server</span></span></code> </pre> <br><p> 创建一个<strong>导出</strong> ： </p><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">echo</span></span> '/<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class"> *(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">rw</span></span></span><span class="hljs-class">,</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">no_root_squash</span></span></span><span class="hljs-class">,</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">no_subtree_check</span></span></span><span class="hljs-class">)' &gt;&gt; /etc/exports mkdir /</span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class"> exportfs -a</span></span></code> </pre> <br><h2 id="nastroyka-ha">  HA设置 </h2><br><p> 在撰写本文时，proxmox <strong>HA-manager</strong>有一个<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">错误</a> ，该<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">错误</a>不允许HA容器成功完成其工作，因此，未被完全杀死的<strong>nfs服务器</strong>的<strong>内核空间</strong>进程会阻止drbd设备离开<strong>Secondary</strong> 。 如果您已经遇到这种情况，则不要惊慌，只需在启动容器的节点上执行<code>killall -9 nfsd</code> ，然后drbd设备应“释放”，它将转到<strong>Secondary</strong> 。 </p><br><p> 要修复此错误，请在所有节点上运行以下命令： </p><br><pre> <code class="hljs powershell">sed <span class="hljs-literal"><span class="hljs-literal">-i</span></span> <span class="hljs-string"><span class="hljs-string">'s/forceStop =&gt; 1,/forceStop =&gt; 0,/'</span></span> /usr/share/perl5/PVE/HA/Resources/PVECT.pm systemctl restart pve<span class="hljs-literal"><span class="hljs-literal">-ha</span></span><span class="hljs-literal"><span class="hljs-literal">-lrm</span></span>.service</code> </pre> <br><p> 现在我们可以去<strong>HA-经理</strong> kofiguratsii。 让我们为设备创建一个单独的HA组： </p><br><pre> <code class="hljs powershell">ha<span class="hljs-literal"><span class="hljs-literal">-manager</span></span> groupadd nfs1 -<span class="hljs-literal"><span class="hljs-literal">-nodes</span></span> pve1,pve2,pve3 -<span class="hljs-literal"><span class="hljs-literal">-nofailback</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span> -<span class="hljs-literal"><span class="hljs-literal">-restricted</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p> 我们的<strong>资源</strong>将仅在为此组指定的节点上工作。 将我们的容器添加到该组： </p><br><pre> <code class="hljs powershell">ha<span class="hljs-literal"><span class="hljs-literal">-manager</span></span> add ct:<span class="hljs-number"><span class="hljs-number">101</span></span> -<span class="hljs-literal"><span class="hljs-literal">-group</span></span>=nfs1 -<span class="hljs-literal"><span class="hljs-literal">-max_relocate</span></span>=<span class="hljs-number"><span class="hljs-number">3</span></span> -<span class="hljs-literal"><span class="hljs-literal">-max_restart</span></span>=<span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br><p> 仅此而已。 简单吧？ </p><br><p> 生成的<strong>nfs球</strong>可以立即连接到Proxmox，以存储和运行其他虚拟机和容器。 </p><br><h2 id="rekomendacii-i-tyuning"> 建议和调优 </h2><br><h5 id="drbd"> 广播电视 </h5><br><p> 如上文所述，始终建议使用单独的网络进行复制。 强烈建议使用<strong>10 Gb网络适配器</strong> ，否则会遇到端口速度问题。 <br> 如果复制似乎足够慢，请尝试使用<strong>DRBD的</strong>某些选项。 这是配置，我认为这是我的<strong>10G网络的</strong>最佳配置： </p><br><pre> <code class="hljs swift"># cat /etc/drbd.d/global_common.conf global { usage-<span class="hljs-built_in"><span class="hljs-built_in">count</span></span> yes; udev-always-use-vnr; } common { handlers { } startup { } options { } disk { <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-fill-target 10M; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-<span class="hljs-built_in"><span class="hljs-built_in">max</span></span>-rate 720M; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-plan-ahead <span class="hljs-number"><span class="hljs-number">10</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-<span class="hljs-built_in"><span class="hljs-built_in">min</span></span>-rate 20M; } net { <span class="hljs-built_in"><span class="hljs-built_in">max</span></span>-buffers 36k; sndbuf-size 1024k; rcvbuf-size 2048k; } }</code> </pre> <br><p> 您可以从<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">官方DRBD文档中</a>获取有关每个参数的更多信息<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">。</a> </p><br><h5 id="nfs-server">  NFS服务器 </h5><br><p> 为了加快<strong>NFS服务器</strong>的操作<strong>，</strong>可能有助于增加NFS服务器正在运行的<strong>实例</strong>总数。 默认情况下<strong>-8</strong> ，就我个人而言，它帮助我将此数字增加到<strong>64</strong> 。 </p><br><p> 为此，请在<code>/etc/default/nfs-kernel-server</code>更新<code>RPCNFSDCOUNT=64</code>参数。 <br> 并重新启动守护程序： </p><br><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">restart</span></span> nfs-utils systemctl <span class="hljs-keyword"><span class="hljs-keyword">restart</span></span> nfs-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span></code> </pre> <br><h5 id="nfsv3-vs-nfsv4">  NFSv3和NFSv4 </h5><br><p> 知道<strong>NFSv3</strong>和<strong>NFSv4</strong>之间的区别吗？ </p><br><ul><li>  <strong>NFSv3</strong>是<strong>无状态协议；</strong>通常，它可以更好地容忍故障并恢复得更快。 </li><li>  <strong>NFSv4</strong>是一种<strong>有状态协议</strong> ，它运行速度更快，并且可以绑定到某些tcp端口，但是由于存在状态，因此它对故障更加敏感。 它还具有使用Kerberos和许多其他有趣功能使用身份验证的能力。 </li></ul><br><p> 但是，当您运行<code>showmount -e nfs_server</code> ，将使用NFSv3协议。  Proxmox还使用NFSv3。  NFSv3也通常用于组织网络启动计算机。 </p><br><p> 通常，如果没有特别的理由要使用NFSv4，请尝试使用NFSv3，因为由于缺少状态而使NFSv3对于任何失败的痛苦都较小。 </p><br><p> 您可以通过为<strong>mount</strong>命令指定<code>-o vers=3</code>参数来使用NFSv3来安装球： </p><br><pre> <code class="bash hljs">mount -o vers=3 nfs_server:/share /mnt</code> </pre> <br><p> 如果需要，通常可以为服务器禁用NFSv4，为此，请在<code>--no-nfs-version 4</code>变量中添加<code>--no-nfs-version 4</code>选项，然后重新启动服务器，例如： </p><br><pre> <code class="bash hljs">RPCNFSDCOUNT=<span class="hljs-string"><span class="hljs-string">"64 --no-nfs-version 4"</span></span></code> </pre> <br><h2 id="iscsi-i-lvm">  iSCSI和LVM </h2><br><p> 同样，可以在容器内部配置常规的<strong>tgt守护程序</strong> ，iSCSI将为I / O操作产生更高的性能，并且由于tgt服务器完全在用户空间中工作，因此容器可以更平稳地工作。 </p><br><p> 通常，使用<strong>LVM</strong>将导出的<strong>LUN</strong>切成许多片段。 但是，有几个细微差别需要考虑，例如：如何提供LVM <strong>锁以</strong>在多个主机上共享导出的组。 </p><br><p> 也许我将<strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在下一篇文章中</a></strong>描述这些细微差别。 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN417473/">https://habr.com/ru/post/zh-CN417473/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt486150/index.html">Desenvolvimento da esfera de TI na Eslováquia. Benefícios de trabalho para jovens profissionais</a></li>
<li><a href="../pt486156/index.html">Como eu ensinei, e depois escrevi um manual de treinamento em Python</a></li>
<li><a href="../pt486158/index.html">Visualização da tradução automática neural (modelos seq2seq com mecanismo de atenção)</a></li>
<li><a href="../pt486164/index.html">Coronavírus 2019-nCoV. Perguntas frequentes sobre proteção respiratória e desinfecção</a></li>
<li><a href="../pt486174/index.html">Tenho rotatividade zero</a></li>
<li><a href="../zh-CN417475/index.html">Glusterfs +纠删码：当您需要大量，便宜且可靠时</a></li>
<li><a href="../zh-CN417477/index.html">热桌</a></li>
<li><a href="../zh-CN417479/index.html">在Go中更快地自己动手字符串连接</a></li>
<li><a href="../zh-CN417481/index.html">关于JavaScript ES6中的生成器，以及为什么可以选择研究它们</a></li>
<li><a href="../zh-CN417483/index.html">JS框架比较：React，Vue和Hyperapp</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
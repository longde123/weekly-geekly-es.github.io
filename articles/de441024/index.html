<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§© üì∫ üç™ Wir schreiben einen Crawler f√ºr ein oder zwei 1.0 üí≥ ‚õÑÔ∏è üïµüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ein Webcrawler (oder Webspider) ist ein wichtiger Bestandteil von Suchmaschinen zum Crawlen von Webseiten, um Informationen √ºber sie in Datenbanken ei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir schreiben einen Crawler f√ºr ein oder zwei 1.0</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/semrush/blog/441024/">  Ein <b>Webcrawler</b> (oder Webspider) ist ein wichtiger Bestandteil von Suchmaschinen zum Crawlen von Webseiten, um Informationen √ºber sie in Datenbanken einzugeben, haupts√§chlich f√ºr ihre weitere Indizierung.  Suchmaschinen (Google, Yandex, Bing) sowie SEO-Produkte (SEMrush, MOZ, Ahrefs) haben nicht nur so etwas.  Und diese Sache ist ziemlich interessant: sowohl in Bezug auf Potenziale und Anwendungsf√§lle als auch f√ºr die technische Implementierung. <br><br><img src="https://habrastorage.org/webt/vw/pi/-9/vwpi-9jp8-dypdtmlh58qqa1nm0.jpeg"><br><br>  Mit diesem Artikel werden wir beginnen, Ihr Crawler- <s>Bike</s> <b>iterativ zu</b> erstellen, viele Funktionen zu analysieren und Fallstricke zu l√∂sen.  Von einer einfachen rekursiven Funktion zu einem skalierbaren und erweiterbaren Dienst.  Muss interessant sein! <br><a name="habracut"></a><br><h3>  Intro </h3><br>  Iterativ bedeutet dies, dass am Ende jeder Version eine gebrauchsfertige Version des ‚ÄûProdukts‚Äú mit den vereinbarten Einschr√§nkungen, Funktionen und Schnittstellen erwartet wird. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Node.js</a> und <b>JavaScript wurden</b> als Plattform und Sprache ausgew√§hlt, da es einfach und asynchron ist.  F√ºr die industrielle Entwicklung sollte die Wahl der technologischen Basis nat√ºrlich auf den gesch√§ftlichen Anforderungen, Erwartungen und Ressourcen basieren.  Als Demonstration und Prototyp ist diese Plattform absolut nichts (IMHO). <br><br><blockquote>  Das ist mein Crawler.  Es gibt viele solcher Crawler, aber dieser geh√∂rt mir. <br>  Mein Crawler ist mein bester Freund. <br></blockquote><br>  Die Implementierung des Crawlers ist eine recht beliebte Aufgabe und kann auch bei technischen Interviews gefunden werden.  Es gibt wirklich viele fertige ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Nutch</a> ) und selbst geschriebene L√∂sungen f√ºr verschiedene Bedingungen und in vielen Sprachen.  Kommentare aus pers√∂nlicher Erfahrung in der Entwicklung oder Nutzung sind daher willkommen und interessant. <br><br><h3>  Erkl√§rung des Problems </h3><br>  Die Aufgabe f√ºr die erste (erste) Implementierung unseres <s>Tyap-Blooper-</s> Crawlers lautet wie folgt: <br><br><blockquote>  <b>One-Two Crawler 1.0</b> <br>  Schreiben Sie ein Crawlerskript, das die internen <i>&lt;a href /&gt; -Links</i> einer kleinen Site (bis zu 100 Seiten) umgeht.  Stellen Sie daher eine Liste der URLs von Seiten mit den empfangenen Codes und eine Karte ihrer Verkn√ºpfung bereit.  Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">robots.txt-</a> Regeln und das Attribut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">rel = nofollow</a> link werden ignoriert. </blockquote><br>  <b>Achtung!</b>  Das Ignorieren von <i>robots.txt-</i> Regeln ist aus offensichtlichen Gr√ºnden eine schlechte Idee.  Wir werden diese L√ºcke in Zukunft schlie√üen.  F√ºgen Sie in der Zwischenzeit den Parameter limit hinzu, der die Anzahl der zu crawlenden Seiten begrenzt, damit DoS nicht gestoppt wird, und probieren Sie die experimentelle Site aus (es ist besser, Ihre eigene "Hamster-Site" f√ºr Experimente zu verwenden). <br><br><h3>  Implementierung </h3><br>  F√ºr die Ungeduldigen sind <a href="">hier die Quellen</a> dieser L√∂sung. <br><br><ol><li>  HTTP (S) -Client </li><li>  Antwortoptionen </li><li>  Link-Extraktion </li><li>  Linkvorbereitung und Filterung </li><li>  URL-Normalisierung </li><li>  Hauptfunktionsalgorithmus </li><li>  Ergebnis zur√ºckgeben </li></ol><br><h4>  1. HTTP (S) -Client </h4><br>  Das erste, was wir tun m√ºssen, ist, Anfragen zu senden und Antworten √ºber HTTP und HTTPS zu empfangen.  In node.js gibt es daf√ºr zwei √ºbereinstimmende Clients.  Nat√ºrlich k√∂nnen Sie eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorgefertigte Client-Anfrage entgegennehmen</a> , aber f√ºr unsere Aufgabe ist sie √§u√üerst redundant: Wir m√ºssen nur eine GET-Anfrage senden und eine Antwort mit dem Text und den Headern erhalten. <br><br>  Die API beider Clients, die wir ben√∂tigen, ist identisch. Wir erstellen eine Karte: <br><br><pre><code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> clients = { <span class="hljs-string"><span class="hljs-string">'http:'</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'http'</span></span>), <span class="hljs-string"><span class="hljs-string">'https:'</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'https'</span></span>) };</code> </pre> <br>  Wir deklarieren einen einfachen Funktionsabruf, dessen einziger Parameter die <b>absolute</b> URL der gew√ºnschten Webressourcenzeichenfolge ist.  Mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem URL-Modul</a> analysieren wir die resultierende Zeichenfolge in ein URL-Objekt.  Dieses Objekt hat ein Feld mit dem Protokoll (mit einem Doppelpunkt), anhand dessen wir den entsprechenden Client ausw√§hlen: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> url = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'url'</span></span>); <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fetch</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">dst</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> dstURL = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> URL(dst); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> client = clients[dstURL.protocol]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!client) { <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Error</span></span>(<span class="hljs-string"><span class="hljs-string">'Could not select a client for '</span></span> + dstURL.protocol); } <span class="hljs-comment"><span class="hljs-comment">// ... }</span></span></code> </pre><br>  Verwenden Sie als N√§chstes den ausgew√§hlten Client und verpacken Sie das Ergebnis der <i>Abruffunktion</i> in ein Versprechen: <br><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fetch</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">dst</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Promise</span></span>(<span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">resolve, reject</span></span></span><span class="hljs-function">) =&gt;</span></span> { <span class="hljs-comment"><span class="hljs-comment">// ... let req = client.get(dstURL.href, res =&gt; { // do something with the response }); req.on('error', err =&gt; reject('Failed on the request: ' + err.message)); req.end(); }); }</span></span></code> </pre><br><br>  Jetzt k√∂nnen wir asynchron eine Antwort erhalten, aber im Moment machen wir nichts damit. <br><br><h4>  2. Antwortoptionen </h4><br>  Um die Site zu crawlen, m√ºssen 3 Antwortoptionen verarbeitet werden: <br><br><ol><li>  <b>OK</b> - Ein 2xx-Statuscode wurde empfangen.  Es ist notwendig, den Antworttext als Ergebnis f√ºr die weitere Verarbeitung zu speichern - neue Links zu extrahieren. </li><li>  <b>REDIRECT</b> - Ein 3xx-Statuscode wurde empfangen.  Dies ist eine Weiterleitung zu einer anderen Seite.  In diesem Fall ben√∂tigen wir den <i>Standortantwort-</i> Header, von dem aus wir einen einzelnen "ausgehenden" Link verwenden. </li><li>  <b>NO_DATA</b> - Alle anderen F√§lle: 4xx / 5xx und 3xx ohne den <i>Location-</i> Header.  Es gibt keinen weiteren Weg zu unserem Crawler. </li></ol><br>  Die <i>Abruffunktion</i> l√∂st die verarbeitete Antwort unter Angabe ihres Typs auf: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> ft = { <span class="hljs-string"><span class="hljs-string">'OK'</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-comment"><span class="hljs-comment">// code (2xx), content 'REDIRECT': 2, // code (3xx), location 'NO_DATA': 3 // code };</span></span></code> </pre><br>  Umsetzung der Strategie zur Erzielung des Ergebnisses in den besten Traditionen von <i>if-else</i> : <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> code = res.statusCode; <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> codeGroup = <span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.floor(code / <span class="hljs-number"><span class="hljs-number">100</span></span>); <span class="hljs-comment"><span class="hljs-comment">// OK if (codeGroup === 2) { let body = []; res.setEncoding('utf8'); res.on('data', chunk =&gt; body.push(chunk)); res.on('end', () =&gt; resolve({ code, content: body.join(''), type: ft.OK })); } // REDIRECT else if (codeGroup === 3 &amp;&amp; res.headers.location) { resolve({ code, location: res.headers.location, type: ft.REDIRECT }); } // NO_DATA (others) else { resolve({ code, type: ft.NO_DATA }); }</span></span></code> </pre><br>  Die <i>Abruffunktion</i> ist einsatzbereit: <a href="">der gesamte Funktionscode</a> . <br><br><h4>  3. Extraktion von Links </h4><br>  Abh√§ngig von der Variante der empfangenen Antwort m√ºssen Sie nun in der Lage sein, Links aus den Ergebnisdaten von <i>fetch</i> f√ºr das weitere Crawlen zu extrahieren.  Dazu definieren wir die <i>Extraktionsfunktion</i> , die ein Ergebnisobjekt als Eingabe verwendet und ein Array neuer Links zur√ºckgibt. <br><br>  Wenn der Ergebnistyp REDIRECT ist, gibt die Funktion ein Array mit einer einzelnen Referenz aus dem <i>Standortfeld</i> zur√ºck.  Wenn NO_DATA, dann ein leeres Array.  Wenn OK, m√ºssen wir den Parser f√ºr den pr√§sentierten <i>Textinhalt</i> f√ºr die Suche verbinden. <br><br>  F√ºr die Suchaufgabe <i>&lt;a href /&gt; k√∂nnen</i> Sie auch einen regul√§ren Ausdruck schreiben.  Diese L√∂sung l√§sst sich jedoch √ºberhaupt nicht skalieren, da wir in Zukunft zumindest auf andere Attribute ( <i>rel</i> ) des Links achten werden. Maximal werden wir √ºber <i>img</i> , <i>Link</i> , <i>Skript</i> , <i>Audio / Video</i> ( <i>Quelle</i> ) und andere Ressourcen nachdenken.  Es ist vielversprechender und bequemer, den Text des Dokuments zu analysieren und einen Baum seiner Knoten zu erstellen, um die √ºblichen Selektoren zu umgehen. <br><br>  Wir werden die beliebte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JSDOM-</a> Bibliothek f√ºr die Arbeit mit dem DOM in node.js verwenden: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> { JSDOM } = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'jsdom'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> <span class="hljs-built_in"><span class="hljs-built_in">document</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JSDOM(fetched.content).window.document; <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> elements = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementsByTagName(<span class="hljs-string"><span class="hljs-string">'A'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Array</span></span>.from(elements) .map(<span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">el</span></span></span><span class="hljs-function"> =&gt;</span></span> el.getAttribute(<span class="hljs-string"><span class="hljs-string">'href'</span></span>)) .filter(<span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">href</span></span></span><span class="hljs-function"> =&gt;</span></span> <span class="hljs-keyword"><span class="hljs-keyword">typeof</span></span> href === <span class="hljs-string"><span class="hljs-string">'string'</span></span>) .map(<span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">href</span></span></span><span class="hljs-function"> =&gt;</span></span> href.trim()) .filter(<span class="hljs-built_in"><span class="hljs-built_in">Boolean</span></span>);</code> </pre><br>  Wir erhalten alle <i>A-</i> Elemente aus dem Dokument und dann alle gefilterten Werte des <i>href-</i> Attributs, wenn nicht leere Zeilen. <br><br><h4>  4. Vorbereitung und Filterung von Links </h4><br>  Aufgrund des Extraktors haben wir eine Reihe von Links (URLs) und zwei Probleme: 1) Die URL kann relativ sein und 2) Die URL kann zu einer externen Ressource f√ºhren (wir ben√∂tigen jetzt nur interne). <br><br>  Das erste Problem wird durch die Funktion <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">url.resolve behoben</a> , mit der die URL der Zielseite relativ zur URL der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quellseite aufgel√∂st wird</a> . <br><br>  Um das zweite Problem zu l√∂sen, schreiben wir eine einfache Dienstprogrammfunktion <i>inScope</i> , die den Host der Zielseite mit dem Host der Basis-URL des aktuellen Crawls vergleicht: <br><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getLowerHost</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">dst</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> URL(dst)).hostname.toLowerCase(); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">inScope</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">dst, base</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> dstHost = getLowerHost(dst); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> baseHost = getLowerHost(base); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> i = dstHost.indexOf(baseHost); <span class="hljs-comment"><span class="hljs-comment">// the same domain or has subdomains return i === 0 || dstHost[i - 1] === '.'; }</span></span></code> </pre><br>  Die Funktion sucht nach einem Teilstring ( <i>baseHost</i> ) mit einer √úberpr√ºfung des vorherigen Zeichens, wenn der Teilstring gefunden wurde: da <i>wwwexample.com</i> und <i>example.com</i> unterschiedliche Dom√§nen sind.  Infolgedessen verlassen wir die angegebene Domain nicht, sondern umgehen ihre Subdomains. <br><br>  Wir verfeinern die <i>Extraktionsfunktion</i> , indem wir "Absolutisierung" hinzuf√ºgen und die resultierenden Links filtern: <br><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">extract</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">fetched, src, base</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> extractRaw(fetched) .map(<span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">href</span></span></span><span class="hljs-function"> =&gt;</span></span> url.resolve(src, href)) .filter(<span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">dst</span></span></span><span class="hljs-function"> =&gt;</span></span> /^https?\:\/\<span class="hljs-comment"><span class="hljs-comment">//i.test(dst)) .filter(dst =&gt; inScope(dst, base)); }</span></span></code> </pre><br>  Hier ist <i>abgerufen</i> das Ergebnis der <i>Abruffunktion</i> , <i>src</i> ist die URL der Quellseite, <i>base</i> ist die Basis-URL des Crawls.  Am Ausgang erhalten wir eine Liste bereits absoluter interner Links (URLs) zur weiteren Verarbeitung.  Der gesamte Funktionscode <a href="">ist hier</a> zu <a href="">sehen</a> . <br><br><h4>  5. URL-Normalisierung </h4><br>  Wenn Sie erneut auf eine URL sto√üen, m√ºssen Sie keine weitere Anforderung f√ºr die Ressource senden, da die Daten bereits empfangen wurden (oder eine andere Verbindung noch offen ist und auf eine Antwort wartet).  Es reicht jedoch nicht immer aus, die Zeichenfolgen zweier URLs zu vergleichen, um dies zu verstehen.  Die Normalisierung ist das Verfahren, das erforderlich ist, um die √Ñquivalenz syntaktisch unterschiedlicher URLs zu bestimmen. <br><br>  Der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Normalisierungsprozess</a> besteht aus einer ganzen Reihe von Transformationen, die auf die Quell-URL und ihre Komponenten angewendet werden.  Hier sind nur einige davon: <br><br><ul><li>  Das Schema und der Host unterscheiden nicht zwischen Gro√ü- und Kleinschreibung, daher sollten sie in niedrigere konvertiert werden. </li><li>  Alle Prozents√§tze (wie "% 3A") m√ºssen in Gro√übuchstaben geschrieben werden. </li><li>  Der Standardport (80 f√ºr HTTP) kann entfernt werden. </li><li>  Das Fragment ( <i>#</i> ) ist f√ºr den Server nie sichtbar und kann auch gel√∂scht werden. </li></ul><br>  Sie k√∂nnen jederzeit etwas Fertiges nehmen (z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">URL normalisieren</a> ) oder Ihre eigene einfache Funktion schreiben, die die wichtigsten und h√§ufigsten F√§lle abdeckt: <br><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normalize</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">dst</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> dstUrl = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> URL(dst); <span class="hljs-comment"><span class="hljs-comment">// ignore userinfo (auth property) let origin = dstUrl.protocol + '//' + dstUrl.hostname; // ignore http(s) standart ports if (dstUrl.port &amp;&amp; (!/^https?\:/i.test(dstUrl.protocol) || ![80, 8080, 443].includes(+dstUrl.port))) { origin += ':' + dstUrl.port; } // ignore fragment (hash property) let path = dstUrl.pathname + dstUrl.search; // convert origin to lower case return origin.toLowerCase() // and capitalize letters in escape sequences + path.replace(/%([0-9a-f]{2})/ig, (_, es) =&gt; '%' + es.toUpperCase()); }</span></span></code> </pre><br><div class="spoiler">  <b class="spoiler_title">Nur f√ºr den Fall, das Format des URL-Objekts</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/zs/te/jr/zstejr_mjpparhgrr4aar6ma7nq.png"><br></div></div><br>  Ja, es gibt keine Sortierung von Abfrageparametern, Ignorieren von utm-Tags, Verarbeiten von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">_escaped_fragment_</a> und anderen Dingen, die wir (absolut) √ºberhaupt nicht ben√∂tigen. <br><br>  Als N√§chstes erstellen wir einen lokalen Cache mit normalisierten URLs, die vom Crawl-Framework angefordert werden.  Bevor wir die n√§chste Anfrage senden, normalisieren wir die empfangene URL. Wenn sie sich nicht im Cache befindet, f√ºgen Sie sie hinzu und senden erst dann eine neue Anfrage. <br><br><h4>  6. Der Algorithmus der Hauptfunktion </h4><br>  Die Schl√ºsselkomponenten (Grundelemente) der L√∂sung sind fertig. Es ist Zeit, alles zusammen zu sammeln.  Lassen Sie uns zun√§chst die Signatur der <i>Durchforstungsfunktion</i> bestimmen: an der Eingabe die Start-URL und das Seitenlimit.  Die Funktion gibt ein Versprechen zur√ºck, dessen Aufl√∂sung ein akkumuliertes Ergebnis liefert.  Schreiben Sie es in die <i>Ausgabedatei</i> : <br><br><pre> <code class="javascript hljs">crawl(start, limit).then(<span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">result</span></span></span><span class="hljs-function"> =&gt;</span></span> { fs.writeFile(output, <span class="hljs-built_in"><span class="hljs-built_in">JSON</span></span>.stringify(result), <span class="hljs-string"><span class="hljs-string">'utf8'</span></span>, err =&gt; { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (err) <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> err; }); });</code> </pre><br>  Der einfachste rekursive Workflow der Crawling-Funktion kann in folgenden Schritten beschrieben werden: <br><br><blockquote>  1. Initialisierung des Caches und des Ergebnisobjekts <br>  2. WENN sich die Zielseiten-URL (√ºber <b>Normalisieren</b> ) nicht im Cache befindet, DANN <br>  - 2.1.  WENN das <i>Limit</i> erreicht ist, ENDE (auf Ergebnis warten) <br>  - 2.2.  URL zum Cache hinzuf√ºgen <br>  - 2.3.  Speichern Sie den Link zwischen Quelle und Zielseite im Ergebnis <br>  - 2.4.  Asynchrone Anfrage pro Seite senden ( <b>Abruf</b> ) <br>  - 2.5.  WENN die Anfrage erfolgreich ist, DANN <br>  - - 2.5.1.  Neue Links aus dem Ergebnis <b>extrahieren</b> ( <b>extrahieren</b> ) <br>  - - 2.5.2.  F√ºhren Sie f√ºr jede neue Verbindung den Algorithmus 2-3 aus <br>  - 2.6.  Andernfalls markieren Sie die Seite als Fehler <br>  - 2.7.  Speichern Sie die Seitendaten, um das Ergebnis zu erhalten <br>  - 2.8.  WENN dies die letzte Seite war, bringen Sie das Ergebnis <br>  3. Speichern Sie andernfalls die Verkn√ºpfung zwischen der Quelle und der Zielseite im Ergebnis <br></blockquote><br>  <b>Ja, dieser Algorithmus wird in Zukunft gro√üe √Ñnderungen erfahren.</b>  Jetzt wird bewusst eine rekursive L√∂sung auf der Stirn verwendet, so dass es sp√§ter besser ist, den Unterschied in den Implementierungen zu ‚Äûsp√ºren‚Äú.  Das Werkst√ºck f√ºr die Implementierung der Funktion sieht folgenderma√üen aus: <br><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">crawl</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">start, limit = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">100</span></span></span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// initialize cache &amp; result return new Promise((resolve, reject) =&gt; { function curl(src, dst) { // check dst in the cache &amp; pages limit // save the link (src -&gt; dst) to the result fetch(dst).then(fetched =&gt; { extract(fetched, dst, start).forEach(ln =&gt; curl(dst, ln)); }).finally(() =&gt; { // save the page's data to the result // check completion and resolve the result }); } curl(null, start); }); }</span></span></code> </pre><br>  Das Erreichen des Seitenlimits wird durch einen einfachen Anforderungsz√§hler √ºberpr√ºft.  Der zweite Z√§hler - die Anzahl der aktiven Anforderungen gleichzeitig - dient als Test f√ºr die Bereitschaft, das Ergebnis zu liefern (wenn der Wert auf Null geht).  Wenn die <i>Abruffunktion</i> die n√§chste Seite nicht erhalten konnte, setzen Sie den Statuscode daf√ºr auf null. <br><br>  Sie k√∂nnen sich hier (optional) mit dem Implementierungscode <a href="">vertraut machen</a> , aber vorher sollten Sie das Format des zur√ºckgegebenen Ergebnisses ber√ºcksichtigen. <br><br><h4>  7. Zur√ºckgegebenes Ergebnis </h4><br>  Wir werden eine eindeutige <i>ID-ID</i> mit einem einfachen Inkrement f√ºr die abgefragten Seiten einf√ºhren: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> id = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cache = {}; <span class="hljs-comment"><span class="hljs-comment">// ... let dstNorm = normalize(dst); if (dstNorm in cache === false) { cache[dstNorm] = ++id; // ... }</span></span></code> </pre><br>  F√ºr das Ergebnis erstellen wir ein Array von <i>Seiten,</i> in das wir Objekte mit Daten auf der Seite <i>einf√ºgen</i> : <i>ID</i> {Nummer}, <i>URL</i> {Zeichenfolge} und <i>Code</i> {Nummer | Null} (dies ist jetzt genug).  Wir erstellen auch ein Array von <i>Links</i> f√ºr Links zwischen Seiten in Form eines Objekts: <i>von</i> ( <i>ID der</i> Quellseite) <i>bis</i> ( <i>ID der</i> Zielseite). <br><br>  Zu Informationszwecken sortieren wir vor dem Aufl√∂sen des Ergebnisses die Liste der Seiten in aufsteigender Reihenfolge der <i>ID</i> (schlie√ülich werden die Antworten in beliebiger Reihenfolge angezeigt). Wir erg√§nzen das Ergebnis mit der Anzahl der gescannten Z√§hlseiten und einem Flag beim Erreichen der angegebenen <i>Flossengrenze</i> : <br><br><pre> <code class="javascript hljs">resolve({ <span class="hljs-attr"><span class="hljs-attr">pages</span></span>: pages.sort(<span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">p1, p2</span></span></span><span class="hljs-function">) =&gt;</span></span> p1.id - p2.id), <span class="hljs-attr"><span class="hljs-attr">links</span></span>: links.sort(<span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">l1, l2</span></span></span><span class="hljs-function">) =&gt;</span></span> l1.from - l2.from || l1.to - l2.to), count, <span class="hljs-attr"><span class="hljs-attr">fin</span></span>: count &lt; limit });</code> </pre><br><h3>  Anwendungsbeispiel </h3><br>  Das fertige Crawlerskript enth√§lt die folgende Zusammenfassung: <br><br><pre> <code class="plaintext hljs">node crawl-cli.js --start="&lt;URL&gt;" [--output="&lt;filename&gt;"] [--limit=&lt;int&gt;]</code> </pre><br>  Erg√§nzend zur Protokollierung der wichtigsten Punkte des Prozesses sehen wir beim Start ein solches Bild: <br><br><pre> <code class="plaintext hljs">$ node crawl-cli.js --start="https://google.com" --limit=20 [2019-02-26T19:32:10.087Z] Start crawl "https://google.com" with limit 20 [2019-02-26T19:32:10.089Z] Request (#1) "https://google.com/" [2019-02-26T19:32:10.721Z] Fetched (#1) "https://google.com/" with code 301 [2019-02-26T19:32:10.727Z] Request (#2) "https://www.google.com/" [2019-02-26T19:32:11.583Z] Fetched (#2) "https://www.google.com/" with code 200 [2019-02-26T19:32:11.720Z] Request (#3) "https://play.google.com/?hl=ru&amp;tab=w8" [2019-02-26T19:32:11.721Z] Request (#4) "https://mail.google.com/mail/?tab=wm" [2019-02-26T19:32:11.721Z] Request (#5) "https://drive.google.com/?tab=wo" ... [2019-02-26T19:32:12.929Z] Fetched (#11) "https://www.google.com/advanced_search?hl=ru&amp;authuser=0" with code 200 [2019-02-26T19:32:13.382Z] Fetched (#19) "https://translate.google.com/" with code 200 [2019-02-26T19:32:13.782Z] Fetched (#14) "https://plus.google.com/108954345031389568444" with code 200 [2019-02-26T19:32:14.087Z] Finish crawl "https://google.com" on count 20 [2019-02-26T19:32:14.087Z] Save the result in "result.json"</code> </pre><br>  Und hier ist das Ergebnis im JSON-Format: <br><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"pages"</span></span>: [ { <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"url"</span></span>: <span class="hljs-string"><span class="hljs-string">"https://google.com/"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"code"</span></span>: <span class="hljs-number"><span class="hljs-number">301</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-attr"><span class="hljs-attr">"url"</span></span>: <span class="hljs-string"><span class="hljs-string">"https://www.google.com/"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"code"</span></span>: <span class="hljs-number"><span class="hljs-number">200</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">"url"</span></span>: <span class="hljs-string"><span class="hljs-string">"https://play.google.com/?hl=ru&amp;tab=w8"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"code"</span></span>: <span class="hljs-number"><span class="hljs-number">302</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-attr"><span class="hljs-attr">"url"</span></span>: <span class="hljs-string"><span class="hljs-string">"https://mail.google.com/mail/?tab=wm"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"code"</span></span>: <span class="hljs-number"><span class="hljs-number">302</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-attr"><span class="hljs-attr">"url"</span></span>: <span class="hljs-string"><span class="hljs-string">"https://drive.google.com/?tab=wo"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"code"</span></span>: <span class="hljs-number"><span class="hljs-number">302</span></span> }, // ... { <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">19</span></span>, <span class="hljs-attr"><span class="hljs-attr">"url"</span></span>: <span class="hljs-string"><span class="hljs-string">"https://translate.google.com/"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"code"</span></span>: <span class="hljs-number"><span class="hljs-number">200</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-attr"><span class="hljs-attr">"url"</span></span>: <span class="hljs-string"><span class="hljs-string">"https://calendar.google.com/calendar?tab=wc"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"code"</span></span>: <span class="hljs-number"><span class="hljs-number">302</span></span> } ], <span class="hljs-attr"><span class="hljs-attr">"links"</span></span>: [ { <span class="hljs-attr"><span class="hljs-attr">"from"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"to"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"from"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-attr"><span class="hljs-attr">"to"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"from"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-attr"><span class="hljs-attr">"to"</span></span>: <span class="hljs-number"><span class="hljs-number">4</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"from"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-attr"><span class="hljs-attr">"to"</span></span>: <span class="hljs-number"><span class="hljs-number">5</span></span> }, // ... { <span class="hljs-attr"><span class="hljs-attr">"from"</span></span>: <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-attr"><span class="hljs-attr">"to"</span></span>: <span class="hljs-number"><span class="hljs-number">19</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"from"</span></span>: <span class="hljs-number"><span class="hljs-number">19</span></span>, <span class="hljs-attr"><span class="hljs-attr">"to"</span></span>: <span class="hljs-number"><span class="hljs-number">8</span></span> } ], <span class="hljs-attr"><span class="hljs-attr">"count"</span></span>: <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-attr"><span class="hljs-attr">"fin"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> }</code> </pre><br><br>  Was kann man damit schon machen?  In der Liste der Seiten finden Sie mindestens alle besch√§digten Seiten der Site.  Mit Informationen zur internen Verkn√ºpfung k√∂nnen Sie lange Ketten (und geschlossene Schleifen) von Weiterleitungen erkennen oder die wichtigsten Seiten anhand der Referenzmasse finden. <br><br><h3>  Ank√ºndigung 2.0 </h3><br>  Wir haben eine Version des einfachsten Konsolen-Crawlers, der die Seiten einer Site umgeht.  Der Quellcode <a href="">ist hier</a> .  Es gibt auch ein Beispiel und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unit-Tests</a> f√ºr einige Funktionen. <br><br>  Dies ist ein kurzer Absender von Anfragen, und der n√§chste vern√ºnftige Schritt w√§re, ihm gute Manieren beizubringen.  Es geht um den <i>User-Agent-</i> Header, die <i>robots.txt-</i> Regeln, die <i>Crawl-Delay-</i> Direktive und vieles mehr.  Unter dem Gesichtspunkt der Implementierung bedeutet dies zun√§chst, Nachrichten in die Warteschlange zu stellen und dann eine gr√∂√üere Last zu bedienen.  <i>Wenn dieses Material nat√ºrlich interessant sein wird!</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de441024/">https://habr.com/ru/post/de441024/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de441012/index.html">Interessante Fakten √ºber die Geschichte des chinesischen Mondprogramms und der Weltraummission Chang'e-4</a></li>
<li><a href="../de441014/index.html">Low-Budget-Stereo-Rendering in wenigen Codezeilen (Stereogramm, Anaglyphe, Stereoskop)</a></li>
<li><a href="../de441018/index.html">Tools zur Entwicklung und Spezifikation von NanoCAD Mechanics-Programmen</a></li>
<li><a href="../de441020/index.html">Wie VTB zu einem einzigen Wissen kam</a></li>
<li><a href="../de441022/index.html">H√§ufige Fehler von Fahrg√§sten von Eisenbahnen und Fluggesellschaften</a></li>
<li><a href="../de441026/index.html">VMware NSX f√ºr die Kleinsten. Teil 2. Firewall und NAT konfigurieren</a></li>
<li><a href="../de441028/index.html">Wie Forscher offene MongoDB- und Elasticsearch-Datenbanken entdecken</a></li>
<li><a href="../de441030/index.html">Erkennen von Webangriffen mit einem Seq2Seq Autoencoder</a></li>
<li><a href="../de441032/index.html">KeeBee Erstellen Sie Ihre eigene USB-Tastatur von Grund auf neu</a></li>
<li><a href="../de441034/index.html">6 Punkte Conversion-Wachstum oder wie Sie das Vertrauen mit einem Telefon auf der Website erh√∂hen k√∂nnen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
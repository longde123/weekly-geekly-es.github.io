<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ˜ ğŸš• ğŸŒŒ VKontakte Analisis Produk ClickHouse ğŸ² ğŸ‘ âŒ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mengembangkan produk apa pun, apakah itu layanan video atau rekaman, cerita atau artikel, saya ingin dapat mengukur "kebahagiaan" bersyarat dari pengg...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>VKontakte Analisis Produk ClickHouse</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vk/blog/445284/"><img src="https://habrastorage.org/webt/0f/oi/nf/0foinfaynjgjrh11h6w55fr5510.jpeg"><br><br>  Mengembangkan produk apa pun, apakah itu layanan video atau rekaman, cerita atau artikel, saya ingin dapat mengukur "kebahagiaan" bersyarat dari pengguna.  Untuk memahami apakah kita membuat perubahan kita lebih baik atau lebih buruk, untuk menyesuaikan arah pengembangan produk, berdasarkan bukan pada intuisi dan perasaan kita sendiri, tetapi pada metrik dan angka yang dapat Anda percayai. <br><br>  Dalam artikel ini, saya akan memberi tahu Anda bagaimana kami berhasil meluncurkan statistik produk dan analitik pada layanan dengan audiens 97 juta bulanan, sambil mendapatkan pertanyaan analitis kinerja sangat tinggi.  Kita akan berbicara tentang ClickHouse, mesin yang digunakan, dan fitur kueri.  Saya akan menjelaskan pendekatan agregasi data, yang memungkinkan kami memperoleh metrik kompleks dalam sepersekian detik, dan berbicara tentang konversi dan pengujian data. <br><br>  Sekarang kita memiliki sekitar 6 miliar acara makanan per hari, dalam waktu dekat kita akan mencapai 20â€“25 miliar.  Dan kemudian - dengan kecepatan yang tidak secepat itu, kita akan meningkat menjadi 40-50 miliar pada akhir tahun, ketika kita menggambarkan semua acara makanan yang menarik bagi kita. <br><br>  <b>1 baris diatur.</b>  <b>Berlalu: 0,287 dtk.</b>  <b>Memproses 59,85 miliar baris, 59,85 GB (208,16 miliar baris / dt., 208,16 GB / dt.)</b> <br><br>  Detail di bawah potongan. <br><a name="habracut"></a><br><h1>  Kata Pengantar </h1><br>  Alat analitik adalah VKontakte sebelumnya.  Pengguna unik dipertimbangkan, adalah mungkin untuk membuat jadwal acara dengan irisan dan dengan demikian jatuh ke kedalaman layanan.  Namun, itu adalah pertanyaan irisan tetap di muka, data agregat, HLL untuk yang unik, beberapa kekakuan dan ketidakmampuan untuk dengan cepat menjawab pertanyaan yang sedikit lebih rumit daripada "berapa banyak?" <br><br>  Tentu saja, ada, sedang dan akan hadoop, itu juga ditulis, ditulis dan akan banyak ditulis, banyak log menggunakan layanan.  Sayangnya, HDFS hanya digunakan oleh beberapa tim untuk melaksanakan tugas mereka sendiri.  Yang lebih menyedihkan, hdfs bukan tentang pertanyaan analitik cepat: ada banyak pertanyaan di berbagai bidang, jawaban yang harus ditemukan dalam kode, dan tidak dalam dokumentasi yang dapat diakses oleh semua orang. <br><br>  Kami sampai pada kesimpulan bahwa tidak mungkin lagi hidup seperti ini.  Setiap tim harus memiliki data, pertanyaan atas mereka harus cepat, dan data itu sendiri harus akurat dan kaya akan parameter yang berguna. <br><br>  Karenanya, kami merumuskan persyaratan yang jelas untuk sistem statistik / analisis baru: <br><br><ul><li>  pertanyaan analitik harus cepat; </li><li>  data cukup akurat, idealnya ini adalah peristiwa interaksi pengguna mentah dengan layanan; </li><li>  struktur acara harus dijelaskan, dipahami, dan dapat diakses; </li><li>  penyimpanan data yang andal, jaminan pengiriman satu kali; </li><li>  dimungkinkan untuk menghitung unik, audiens (harian, mingguan, bulanan), metrik retensi, waktu yang dihabiskan oleh pengguna dalam layanan, tindakan terukur pada metrik unik dan lainnya dengan serangkaian irisan; </li><li>  pengujian, konversi data, dan visualisasi sedang berlangsung. </li></ul><br><h1>  Di dapur </h1><br>  Pengalaman menunjukkan bahwa kami membutuhkan dua database: yang lambat, di mana kami akan mengumpulkan dan memperkaya data, dan yang cepat, di mana kami dapat bekerja dengan data ini dan membuat grafik di atasnya.  Ini adalah salah satu pendekatan yang paling umum, di mana dalam basis yang lambat, misalnya, dalam HDFS, proyeksi yang berbeda dibangun - di atas yang unik dan pada jumlah peristiwa dengan irisan untuk jangka waktu tertentu. <br><br>  Pada hari yang hangat di bulan September, ketika berbicara tentang secangkir teh di dapur yang menghadap ke Katedral Kazan, kami mempunyai ide untuk mencoba ClickHouse sebagai basis cepat - pada waktu itu kami telah menggunakannya untuk menyimpan log teknis.  Ada banyak keraguan terkait terutama dengan kecepatan dan keandalan: tes kinerja yang dinyatakan tampak tidak realistis, dan rilis database baru secara berkala merusak fungsi yang ada.  Karena itu, proposal itu sederhana - untuk dicoba. <br><br><h1>  Sampel pertama </h1><br>  Kami mengerahkan sekelompok dua mesin dengan konfigurasi ini: <br>  2xE5-2620 v4 (total 32 core), ram 256G, 28T tempat (raid10 dengan ext4). <br><br>  Awalnya, itu dekat tata letak, tapi kemudian kami beralih ke jauh.  ClickHouse memiliki banyak mesin tabel yang berbeda, tetapi yang utama berasal dari keluarga MergeTree.  Kami memilih ReplicatedReplacingMergeTree dengan kira-kira pengaturan berikut: <br><br><pre><code class="sql hljs">PARTITION BY dt ORDER BY (toStartOfHour(time), cityHash64(user_id), event_microsec, event_id) SAMPLE BY cityHash64(user_id) SETTINGS index_granularity = 8192;</code> </pre> <br>  <b>Digandakan</b> - berarti bahwa tabel direplikasi, dan ini memecahkan salah satu persyaratan keandalan kami. <br><br>  <b>Mengganti</b> - tabel mendukung deduplikasi pada kunci utama: secara default, kunci primer cocok dengan tombol sortir, jadi bagian ORDER BY hanya memberi tahu Anda apa kunci utama itu. <br><br>  <b>SAMPEL OLEH</b> - Saya juga ingin mencoba pengambilan sampel: sampel mengembalikan sampel acak-semu yang seragam. <br><br>  <b>index_granularity = 8192</b> adalah jumlah baris data ajaib antara serif indeks (ya, jarang), yang digunakan secara default.  Kami tidak mengubahnya. <br><br>  Partisi dilakukan berdasarkan hari (meskipun secara default - berdasarkan bulan).  Banyak permintaan data yang seharusnya intraday - misalnya, buat grafik menit penayangan video untuk hari tertentu. <br><br>  Selanjutnya, kami mengambil sepotong log teknis dan mengisi meja dengan sekitar satu miliar baris.  Kompresi luar biasa, pengelompokan berdasarkan tipe kolom Int *, menghitung nilai unik - semuanya bekerja sangat cepat! <br><br>  Berbicara tentang kecepatan, maksud saya tidak ada satu permintaan yang bertahan lebih dari 500 ms, dan kebanyakan dari mereka masuk ke dalam 50-100 ms.  Dan ini pada dua mesin - dan, pada kenyataannya, hanya satu yang terlibat dalam perhitungan. <br><br>  Kami melihat semua ini dan membayangkan bahwa alih-alih kolom UInt8 akan ada id negara, dan kolom Int8 akan diganti oleh data, misalnya, tentang usia pengguna.  Dan mereka menyadari bahwa ClickHouse sepenuhnya cocok untuk kita, jika semuanya dilakukan dengan benar. <br><br><h1>  Pengetikan data yang kuat </h1><br>  Manfaat ClickHouse dimulai tepat ketika skema data yang benar terbentuk.  Contoh: platform String - bad, platform Int8 + dictionary - good, LowCardinality (String) - nyaman dan bagus (saya akan berbicara tentang LowCardinality sedikit kemudian). <br><br>  Kami membuat kelas generator khusus di php, yang, atas permintaan, membuat kelas wrapper atas peristiwa berdasarkan tabel di ClickHouse, dan satu titik masuk tunggal untuk masuk.  Saya akan menjelaskan contoh skema yang ternyata: <br><br><ol><li>  Analis / insinyur data / pengembang menjelaskan dokumentasi: bidang mana, nilai yang mungkin, peristiwa perlu dicatat. </li><li>  Tabel dibuat di ClickHouse sesuai dengan struktur data dari paragraf sebelumnya. </li><li>  Kelas pembungkus untuk acara berdasarkan tabel dihasilkan. </li><li>  Tim produk mengimplementasikan mengisi bidang objek kelas ini, mengirim. </li></ol><br>  Mengubah skema di tingkat php dan jenis data yang dicatat tidak akan berfungsi tanpa terlebih dahulu mengubah tabel di ClickHouse.  Dan ini, pada gilirannya, tidak dapat dilakukan tanpa koordinasi dengan tim, perubahan dalam dokumentasi dan deskripsi peristiwa. <br><br>  Untuk setiap acara, Anda dapat mengatur dua pengaturan yang mengontrol persentase acara yang dikirim ke ClickHouse dan hadoop masing-masing.  Pengaturan diperlukan terutama untuk pengguliran bertahap dengan kemampuan untuk mengurangi penebangan jika terjadi kesalahan.  Sebelum hadoop, data dikirimkan dengan cara standar menggunakan Kafka.  Dan di ClickHouse, mereka terbang melalui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">skema dengan KittenHouse</a> dalam mode persisten, yang menjamin setidaknya satu pengiriman acara tunggal. <br><br>  Acara dikirim ke tabel buffer ke beling yang diinginkan, berdasarkan sisa membagi beberapa hash dari user_id dengan jumlah beling di cluster.  Selanjutnya, tabel buffer menyiram data ke ReplicatedReplacingMergeTree lokal.  Dan di atas tabel lokal, tabel terdistribusi ditarik dengan mesin Terdistribusi, yang memungkinkan Anda untuk mengakses data dari semua pecahan. <br><br><h1>  Denormalisasi </h1><br>  ClickHouse adalah DBMS berbentuk kolom.  Ini bukan tentang bentuk normal, yang berarti lebih baik memiliki semua informasi dengan benar dalam acara tersebut daripada bergabung.  Ada juga yang Gabung, tetapi jika tabel kanan tidak pas di memori, rasa sakit dimulai.  Oleh karena itu, kami membuat keputusan dengan tekad kuat: semua informasi yang kami minati harus disimpan dalam acara itu sendiri.  Misalnya, jenis kelamin, usia pengguna, negara, kota, ulang tahun - semua itu adalah informasi publik yang dapat berguna untuk analitik audiens, serta semua informasi yang berguna tentang objek interaksi.  Jika, misalnya, kita berbicara tentang video, itu video_id, video_owner_id, tanggal unggah video, panjang, kualitas pada saat acara, kualitas maksimal, dan sebagainya. <br><br>  Secara total, di setiap tabel kami memiliki 50 hingga 200 kolom, sementara di semua tabel ada bidang layanan.  Misalnya, log kesalahan adalah error_log - pada kenyataannya, kami menyebut kesalahan di luar jangkauan tipe.  Dalam kasus nilai-nilai aneh melampaui ukuran tipe di bidang dengan usia. <br><br><h2>  Type LowCardinality (T) </h2><br>  ClickHouse memiliki kemampuan untuk menggunakan kamus eksternal.  Mereka disimpan dalam memori, diperbarui secara berkala, dapat secara efektif digunakan dalam berbagai skenario, termasuk sebagai buku referensi klasik.  Misalnya, Anda ingin mencatat sistem operasi dan Anda memiliki dua alternatif: string atau angka + direktori.  Tentu saja, pada sejumlah besar data, dan untuk permintaan analitik kinerja tinggi, adalah logis untuk menulis angka, dan mendapatkan representasi string dari kamus saat Anda membutuhkan: <br><br><pre> <code class="sql hljs">dictGetString('os', 'os_name', toUInt64(os_id))</code> </pre> <br>  Tetapi ada cara yang jauh lebih nyaman - untuk menggunakan tipe LowCardinality (String), yang secara otomatis membuat kamus.  Kinerja dengan LowCardinality dalam kondisi kardinalitas rendah dari himpunan nilai secara radikal lebih tinggi daripada dengan String. <br><br>  Sebagai contoh, kami menggunakan LowCardinality (String) untuk jenis acara 'play', 'pause', 'rewind'.  Atau untuk platform: 'web', 'android', 'iphone': <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> vk_platform, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt = yesterday() <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> vk_platform Elapsed: <span class="hljs-number"><span class="hljs-number">0.145</span></span> sec. Processed <span class="hljs-number"><span class="hljs-number">1.98</span></span> billion <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>, <span class="hljs-number"><span class="hljs-number">5.96</span></span> GB (<span class="hljs-number"><span class="hljs-number">13.65</span></span> billion <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>/s., <span class="hljs-number"><span class="hljs-number">41.04</span></span> GB/s.)</code> </pre> <br>  Fitur ini masih eksperimental, jadi untuk menggunakannya Anda harus melakukan: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> allow_experimental_low_cardinality_type = <span class="hljs-number"><span class="hljs-number">1</span></span>;</code> </pre> <br>  Tetapi ada perasaan bahwa setelah beberapa waktu dia tidak akan lagi berada di bawah pengaturan. <br><br><h1>  VKontakte agregasi data </h1><br>  Karena ada banyak kolom, dan ada banyak acara, keinginan alami adalah untuk memotong partisi "lama", tetapi pertama-tama - untuk merakit unit.  Kadang-kadang, perlu untuk menganalisis peristiwa mentah (sebulan atau setahun yang lalu), jadi kami tidak memotong data dalam HDFS - analis mana pun dapat menghubungi parket yang diinginkan untuk tanggal apa pun. <br><br>  Sebagai aturan, ketika mengumpulkan dalam interval waktu, kami selalu berpijak pada kenyataan bahwa jumlah baris per unit waktu sama dengan produk dari daya potong.  Ini memberlakukan pembatasan: negara-negara mulai mengumpulkan dalam kelompok-kelompok seperti 'Rusia', 'Asia', 'Eropa', 'Sisa dunia', dan usia - dalam interval untuk mengurangi dimensi menjadi satu juta baris bersyarat per tanggal. <br><br><h2>  Agregasi berdasarkan <b>dt, user_id</b> </h2><br>  Tetapi kami memiliki ClickHouse reaktif!  Bisakah kita berakselerasi ke 50-100 juta garis dalam satu kencan? <br>  Tes cepat menunjukkan bahwa kami dapat, dan pada saat itu muncul ide sederhana - untuk meninggalkan pengguna di dalam mesin.  Yaitu, untuk menggabungkan bukan dengan "date, slices" menggunakan alat percikan, tetapi dengan "date, user" berarti oleh ClickHouse, sambil melakukan beberapa "transposisi" data. <br><br>  Dengan pendekatan ini, kami menyimpan pengguna dalam data agregat, yang berarti bahwa kami masih dapat mempertimbangkan indikator audiensi, retensi, dan metrik frekuensi.  Kita dapat menghubungkan unit, menghitung audiens umum dari beberapa layanan hingga seluruh audiens VKontakte.  Semua ini dapat dilakukan oleh setiap irisan yang ada dalam tabel untuk kondisi saat yang sama. <br><br>  Saya akan mengilustrasikan dengan sebuah contoh: <br><br><img src="https://habrastorage.org/webt/1n/zq/23/1nzq23ia7micv91mecw0kqzxgrm.jpeg"><br><br>  Setelah agregasi (lebih banyak kolom di sebelah kanan): <br><br><img src="https://habrastorage.org/webt/nx/ol/xl/nxolxl2vmnnlsxlx6svuaklh9go.jpeg"><br><br>  Dalam hal ini, agregasi terjadi tepat oleh (dt, user_id).  Untuk bidang dengan informasi pengguna, dengan agregasi seperti itu, Anda dapat menggunakan fungsi apa saja, anyHeavy (memilih nilai yang sering dijumpai).  Anda dapat, misalnya, mengumpulkan AnyHeavy (platform) secara agregat untuk mengetahui platform mana yang paling sering digunakan pengguna dari peristiwa video.  Jika diinginkan, Anda dapat menggunakan groupUniqArray (platform) dan menyimpan array semua platform dari mana pengguna mengangkat acara tersebut.  Jika ini tidak cukup, Anda dapat membuat kolom terpisah untuk platform dan menyimpan, misalnya, jumlah video unik yang diputar hingga setengah dari platform tertentu: <br><br><pre> <code class="sql hljs">uniqCombinedIf(cityHash64(video_owner_id, video_id), (platform = 'android') AND (event = '50p')) as uniq_videos_50p_android</code> </pre> <br>  Dengan pendekatan ini, agregat yang agak lebar diperoleh di mana setiap baris adalah pengguna yang unik, dan setiap kolom berisi informasi baik pada pengguna atau tentang interaksinya dengan layanan. <br><br>  Ternyata untuk menghitung DAU suatu layanan, cukup melakukan permintaan seperti itu di atas agregatnya: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> dt, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> DAU <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> dt Elapsed: <span class="hljs-number"><span class="hljs-number">0.078</span></span> sec.</code> </pre> <br>  Atau hitung berapa hari pengguna berada dalam layanan selama seminggu: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">2.922</span></span> sec.</code> </pre> <br>  Kami dapat mempercepat dengan pengambilan sampel, sementara hampir tanpa kehilangan keakuratan: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-number"><span class="hljs-number">10</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.454</span></span> sec.</code> </pre> <br>  Harus segera dicatat bahwa pengambilan sampel tidak berdasarkan persentase peristiwa, tetapi oleh persentase pengguna - dan sebagai hasilnya, ini menjadi alat yang sangat kuat. <br><br>  Atau sama untuk 4 minggu dengan 1/100 sampling - sekitar 1% hasil kurang akurat diperoleh. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-number"><span class="hljs-number">100</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">28</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">28</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.287</span></span> sec.</code> </pre> <br><h2>  Agregasi di sisi lain </h2><br>  Saat digabungkan dengan (dt, user_id), kami tidak kehilangan pengguna, kami tidak ketinggalan informasi tentang interaksinya dengan layanan, tetapi, tentu saja, kami kehilangan metrik tentang objek interaksi tertentu.  Tapi Anda tidak bisa kehilangan ini juga - mari kita membangun unit dengan <br>  (dt, video_owner_id, video_id), mengikuti ide yang sama.  Kami menyimpan informasi tentang video sebanyak mungkin, kami tidak ketinggalan data tentang interaksi video dengan pengguna, dan kami benar-benar kehilangan informasi tentang pengguna tertentu. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> starts <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg3 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (dt = yesterday()) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (video_id = ...) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (video_owner_id = ...) <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.030</span></span> sec</code> </pre> <br>  Atau 10 penayangan video teratas kemarin: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> video_id, video_owner_id, watches <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> video_agg_video_d1 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt = yesterday() <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> watches <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.035</span></span> sec.</code> </pre> <br>  Akibatnya, kami memiliki skema agregat bentuk: <br><br><ul><li>  agregasi berdasarkan "tanggal, pengguna" di dalam produk; </li><li>  agregasi berdasarkan "tanggal, objek interaksi" dalam produk; </li><li>  terkadang proyeksi lain muncul. </li></ul><br><h1>  Azkaban dan TeamCity </h1><br>  Akhirnya, beberapa kata tentang infrastruktur.  Pengumpulan agregat kami dimulai pada malam hari, dimulai dengan MENGOPTIMASI pada setiap tabel dengan data mentah untuk memicu penggabungan data yang luar biasa di ReplicatedReplacingMergeTree.  Operasi dapat bertahan cukup lama, namun, perlu untuk menghapus mengambil, jika terjadi.  Perlu dicatat bahwa sejauh ini saya belum pernah menemukan duplikat, tetapi tidak ada jaminan bahwa mereka tidak akan muncul di masa depan. <br><br>  Langkah selanjutnya adalah pembuatan agregat.  Ini adalah skrip bash tempat terjadi hal-hal berikut: <br><br><ul><li>  pertama kita mendapatkan jumlah pecahan dan beberapa host dari pecahan: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> shard_num, <span class="hljs-keyword"><span class="hljs-keyword">any</span></span>(host_name) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> host <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> system.clusters <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> shard_num</code> </pre> </li><li>  lalu skrip dieksekusi secara berurutan untuk setiap shard (clickhouse-client -h $ host) permintaan formulir (untuk agregat oleh pengguna): <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/$shards_count <span class="hljs-keyword"><span class="hljs-keyword">OFFSET</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/$shard_num</code> </pre> </li></ul><br>  Ini tidak sepenuhnya optimal dan dapat menghasilkan banyak interaksi jaringan antara host.  Namun, ketika menambahkan pecahan baru, semuanya terus bekerja di luar kotak, lokalitas data untuk unit dipertahankan, jadi kami memutuskan untuk tidak terlalu khawatir tentang hal itu. <br><br>  Kami memiliki Azkaban sebagai penjadwal tugas.  Saya tidak akan mengatakan bahwa ini adalah alat yang sangat nyaman, tetapi ini mengatasi tugasnya dengan sempurna, termasuk ketika harus membangun pipa yang sedikit lebih rumit dan ketika satu skrip perlu menunggu beberapa skrip lainnya selesai. <br><br>  Total waktu yang dihabiskan untuk mengubah acara yang sekarang ada menjadi agregat adalah 15 menit. <br><br><h2>  Pengujian </h2><br>  Setiap pagi kami menjalankan tes otomatis yang menjawab pertanyaan tentang data mentah, serta kesiapan dan kualitas agregat: â€œPeriksa bahwa untuk kemarin tidak ada lebih dari setengah persen lebih sedikit data atau data unik pada data mentah atau agregat dibandingkan dengan hari yang sama seminggu yang lalu. " <br><br>  Secara teknologi, ini adalah tes unit biasa menggunakan JUnit dan mengimplementasikan driver jdbc untuk ClickHouse.  Menjalankan semua tes diluncurkan di TeamCity dan membutuhkan waktu sekitar 30 detik dalam 1 utas, dan jika terjadi kegagalan, kami mendapatkan pemberitahuan VKontakte dari bot TeamCity kami yang luar biasa. <br><br><h1>  Kesimpulan </h1><br>  Gunakan hanya versi stabil ClickHouse dan rambut Anda akan lembut dan halus.  Perlu ditambahkan bahwa <b><i>ClickHouse tidak melambat</i></b> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id445284/">https://habr.com/ru/post/id445284/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id445272/index.html">JavaScript adalah bahasa pemrograman terbaik untuk pemula. Jadi atau tidak?</a></li>
<li><a href="../id445274/index.html">Ketika "ZoÃ«"! == "ZoÃ«", atau mengapa Anda perlu menormalkan string Unicode</a></li>
<li><a href="../id445276/index.html">Panduan UseEffect Lengkap</a></li>
<li><a href="../id445278/index.html">Cara membuat game jika Anda tidak pernah seorang artis</a></li>
<li><a href="../id445280/index.html">Profitabilitas situs dan layanan</a></li>
<li><a href="../id445286/index.html">Pijakan kaki untuk otak: Platform Pendaftaran Terdistribusi Hedera Hashgraph</a></li>
<li><a href="../id445288/index.html">Semua pinjaman konsumen dan data pribadi Anda "di satu tempat" ...</a></li>
<li><a href="../id445290/index.html">Bagaimana menerapkan proses terpadu dengan mempertimbangkan semua fitur perusahaan?</a></li>
<li><a href="../id445292/index.html">Apa yang saya tidak pernah diberitahu tentang CSS</a></li>
<li><a href="../id445294/index.html">Dan lagi tentang monitor kedua dari tablet ...</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
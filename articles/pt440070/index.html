<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíû üßíüèø üï∏Ô∏è Julia, descida de gradiente e m√©todo simplex üë©üèø‚Äçüè´ ü§∞üèæ üå©Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Continuamos familiarizados com os m√©todos de otimiza√ß√£o multidimensional. 


 A seguir, prop√µe-se a implementa√ß√£o do m√©todo de descida mais r√°pida com...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Julia, descida de gradiente e m√©todo simplex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440070/"><p><img src="https://habrastorage.org/webt/1d/dr/ms/1ddrmshpanmg5fsnpwbzgy-fi8e.png"></p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Continuamos</a> familiarizados com os m√©todos de otimiza√ß√£o multidimensional. </p><br><p> A seguir, prop√µe-se a implementa√ß√£o do m√©todo de descida mais r√°pida com an√°lise da velocidade de execu√ß√£o, bem como a implementa√ß√£o do m√©todo Nelder-Mead por meio da linguagem Julia e C ++. </p><a name="habracut"></a><br><h2 id="metod-gradientnogo-spuska">  M√©todo de descida de gradiente </h2><br><p>  A busca pelo extremo √© realizada em etapas na dire√ß√£o do gradiente (max) ou anti-gradiente (min).  A cada passo na dire√ß√£o do gradiente (anti-gradiente), o movimento √© realizado at√© que a fun√ß√£o aumente (diminua). </p><br><p>  Para a teoria, siga os links: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Descida de gradiente</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">M√©todo do Gradiente Conjugado</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">M√©todo Nelder-Mead</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vis√£o geral dos m√©todos de gradiente</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SciPy, otimiza√ß√£o</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vis√£o geral dos m√©todos b√°sicos de otimiza√ß√£o matem√°tica para problemas com restri√ß√µes</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">M√©todo de otimiza√ß√£o Nelder-Mead.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Implementa√ß√£o Python</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zaitsev V.V. M√©todos num√©ricos para f√≠sicos.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Equa√ß√µes n√£o lineares e otimiza√ß√£o</a> <br>  Como base foram utilizados exemplos da √∫ltima fonte. </li></ul><br><p>  Com a fun√ß√£o de modelo, selecionamos um parabol√≥ide el√≠ptico e configuramos a fun√ß√£o de renderiza√ß√£o de relevo: </p><br><pre><code class="python hljs">using Plots plotly() <span class="hljs-comment"><span class="hljs-comment">#   function plotter(plot_fun; low, up) Xs = range(low[1], stop = up[1], length = 80) Ys = range(low[2], stop = up[2], length = 80) Zs = [ fun([xy]) for x in Xs, y in Ys ]; plot_fun(Xs, Ys, Zs) xaxis!( (low[1], up[1]), low[1]:(up[1]-low[1])/5:up[1] ) #   yaxis!( (low[2], up[2]), low[2]:(up[2]-low[2])/5:up[2] ) end parabol(x) = sum(u-&gt;u*u, x) #   fun = parabol plotter(surface, low = [-1 -1], up = [1 1])</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/oo/ln/4x/ooln4xwtmg_yie4ikccevpjbpxy.png"></p><br><p>  Definimos uma fun√ß√£o que implementa o m√©todo de descida mais √≠ngreme, que leva a dimens√£o do problema, a precis√£o, o comprimento da etapa, a aproxima√ß√£o inicial e o tamanho do quadro da caixa delimitadora: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># -- ,     -   function ofGradient(; ndimes = 2, Œµ = 1e-4, st = 0.9, fit = [9.9, 9.9], low = [-1 -1], up = [10 10]) k = 0 while st &gt; Œµ g = grad(fit, 0.01) fung = fun(fit) fit -= st*g if fun(fit) &gt;= fung st *= 0.5 fit += st*g end k += 1 #println(k, " ", fit) end #println(fun(fit)) end</span></span></code> </pre> <br><p>  Voc√™ pode se concentrar na fun√ß√£o que calcula a dire√ß√£o do gradiente em termos de otimiza√ß√£o. </p><br><p>  A primeira coisa que vem √† mente s√£o a√ß√µes com matrizes: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># \delta -      #      function grad(fit, Œ¥) ndimes = length(fit) Œî = zeros(ndimes, ndimes) for i = 1:ndimes Œî[i,i] = Œ¥ end fr = [ fun( fit + Œî[:,i] ) for i=1:ndimes] fl = [ fun( fit - Œî[:,i] ) for i=1:ndimes] g = 0.5(fr - fl)/Œ¥ modg = sqrt( sum(x -&gt; x*x, g) ) g /= modg end</span></span></code> </pre> <br><p>  O que √© realmente bom Julia √© que as √°reas problem√°ticas podem ser facilmente testadas: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#]add BenchmarkTools using BenchmarkTools @benchmark ofGradient() BenchmarkTools.Trial: memory estimate: 44.14 KiB allocs estimate: 738 -------------- minimum time: 76.973 Œºs (0.00% GC) median time: 81.315 Œºs (0.00% GC) mean time: 92.828 Œºs (9.14% GC) maximum time: 5.072 ms (94.37% GC) -------------- samples: 10000 evals/sample: 1</span></span></code> </pre> <br><p>  Voc√™ pode se apressar para redigitar tudo no estilo Sishny </p><br><pre> <code class="python hljs">function grad(fit::Array{Float64,<span class="hljs-number"><span class="hljs-number">1</span></span>}, Œ¥::Float64) ndimes::Int8 = <span class="hljs-number"><span class="hljs-number">2</span></span> g = zeros(ndimes) modg::Float64 = <span class="hljs-number"><span class="hljs-number">0.</span></span> Fr::Float64 = <span class="hljs-number"><span class="hljs-number">0.</span></span> Fl::Float64 = <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i = <span class="hljs-number"><span class="hljs-number">1</span></span>:ndimes fit[i] += Œ¥ Fr = fun(fit) fit[i] -= <span class="hljs-number"><span class="hljs-number">2</span></span>Œ¥ Fl = fun(fit) fit[i] += Œ¥ g[i] = <span class="hljs-number"><span class="hljs-number">0.5</span></span>(Fr - Fl)/Œ¥ modg += g[i]*g[i] end modg = sqrt( modg ) g /= modg end @benchmark ofGradient() BenchmarkTools.Trial: memory estimate: <span class="hljs-number"><span class="hljs-number">14.06</span></span> KiB allocs estimate: <span class="hljs-number"><span class="hljs-number">325</span></span> -------------- minimum time: <span class="hljs-number"><span class="hljs-number">29.210</span></span> Œºs (<span class="hljs-number"><span class="hljs-number">0.00</span></span>% GC) median time: <span class="hljs-number"><span class="hljs-number">30.395</span></span> Œºs (<span class="hljs-number"><span class="hljs-number">0.00</span></span>% GC) mean time: <span class="hljs-number"><span class="hljs-number">33.603</span></span> Œºs (<span class="hljs-number"><span class="hljs-number">6.88</span></span>% GC) maximum time: <span class="hljs-number"><span class="hljs-number">4.287</span></span> ms (<span class="hljs-number"><span class="hljs-number">98.88</span></span>% GC) -------------- samples: <span class="hljs-number"><span class="hljs-number">10000</span></span> evals/sample: <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  Mas, como se v√™, ele mesmo e sem n√≥s sabe quais tipos devem ser definidos, ent√£o chegamos a um compromisso: </p><br><pre> <code class="python hljs">function grad(fit, Œ¥) <span class="hljs-comment"><span class="hljs-comment">#    ndimes = length(fit) g = zeros(ndimes) for i = 1:ndimes fit[i] += Œ¥ Fr = fun(fit) fit[i] -= Œ¥ fit[i] -= Œ¥ Fl = fun(fit) fit[i] += Œ¥ g[i] = 0.5(Fr - Fl)/Œ¥ end modg = sqrt( sum(x -&gt; x*x, g) ) g /= modg end @benchmark ofGradient() BenchmarkTools.Trial: memory estimate: 15.38 KiB allocs estimate: 409 -------------- minimum time: 28.026 Œºs (0.00% GC) median time: 30.394 Œºs (0.00% GC) mean time: 33.724 Œºs (6.29% GC) maximum time: 3.736 ms (98.72% GC) -------------- samples: 10000 evals/sample: 1</span></span></code> </pre> <br><p>  Agora deixe ele desenhar: </p><br><pre> <code class="python hljs">function ofGradient(; ndimes = <span class="hljs-number"><span class="hljs-number">2</span></span>, Œµ = <span class="hljs-number"><span class="hljs-number">1e-4</span></span>, st = <span class="hljs-number"><span class="hljs-number">0.9</span></span>, fit = [<span class="hljs-number"><span class="hljs-number">9.9</span></span>, <span class="hljs-number"><span class="hljs-number">9.9</span></span>], low = [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-number"><span class="hljs-number">-1</span></span>], up = [<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span>]) k = <span class="hljs-number"><span class="hljs-number">0</span></span> x = [] y = [] push!(x, fit[<span class="hljs-number"><span class="hljs-number">1</span></span>]) push!(y, fit[<span class="hljs-number"><span class="hljs-number">2</span></span>]) plotter(contour, low = low, up = up) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> st &gt; Œµ g = grad(fit, <span class="hljs-number"><span class="hljs-number">0.01</span></span>) fung = fun(fit) fit -= st*g <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> fun(fit) &gt;= fung st *= <span class="hljs-number"><span class="hljs-number">0.5</span></span> fit += st*g end k += <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">#println(k, " ", fit) push!(x, fit[1]) push!(y, fit[2]) end plot!(x, y, w = 3, legend = false, marker = :rect ) title!("Age = $kf(x,y) = $(fun(fit))") println(fun(fit)) end ofGradient()</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/3g/4e/lo/3g4eloq6pgjwfdw4yoovacooi3i.png"></p><br><p>  Agora vamos tentar as fun√ß√µes de Ackley: </p><br><pre> <code class="python hljs">ekly(x) = <span class="hljs-number"><span class="hljs-number">-20</span></span>exp(<span class="hljs-number"><span class="hljs-number">-0.2</span></span>sqrt(<span class="hljs-number"><span class="hljs-number">0.5</span></span>(x[<span class="hljs-number"><span class="hljs-number">1</span></span>]*x[<span class="hljs-number"><span class="hljs-number">1</span></span>]+x[<span class="hljs-number"><span class="hljs-number">2</span></span>]*x[<span class="hljs-number"><span class="hljs-number">2</span></span>]))) - exp(<span class="hljs-number"><span class="hljs-number">0.5</span></span>(cospi(<span class="hljs-number"><span class="hljs-number">2</span></span>x[<span class="hljs-number"><span class="hljs-number">1</span></span>])+cospi(<span class="hljs-number"><span class="hljs-number">2</span></span>x[<span class="hljs-number"><span class="hljs-number">2</span></span>]))) + <span class="hljs-number"><span class="hljs-number">20</span></span> + ‚ÑØ <span class="hljs-comment"><span class="hljs-comment"># f(0,0) = 0, x_i ‚àà [-5,5] fun = ekly ofGradient(fit = [4.3, 4.9], st = 0.1, low = [3 4.5], up = [4.5 5.4] )</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/in/49/nj/in49njxvjmk1pldjwflc6x5dhzc.png"></p><br><p>  Caiu no m√≠nimo local.  Vamos dar mais passos: </p><br><pre> <code class="python hljs">ofGradient(fit = [<span class="hljs-number"><span class="hljs-number">4.3</span></span>, <span class="hljs-number"><span class="hljs-number">4.9</span></span>], st = <span class="hljs-number"><span class="hljs-number">0.9</span></span>, low = [<span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">4.5</span></span>], up = [<span class="hljs-number"><span class="hljs-number">4.5</span></span> <span class="hljs-number"><span class="hljs-number">5.4</span></span>] )</code> </pre> <br><p><img src="https://habrastorage.org/webt/1u/wu/rn/1uwurnti-yqnz_x75wfk6fxhahs.png"></p><br><pre> <code class="python hljs">ofGradient(fit = [<span class="hljs-number"><span class="hljs-number">4.3</span></span>, <span class="hljs-number"><span class="hljs-number">4.9</span></span>], st = <span class="hljs-number"><span class="hljs-number">1.9</span></span>, low = [<span class="hljs-number"><span class="hljs-number">-5.2</span></span> <span class="hljs-number"><span class="hljs-number">-2.2</span></span>], up = [<span class="hljs-number"><span class="hljs-number">8.1</span></span> <span class="hljs-number"><span class="hljs-number">7.1</span></span>] )</code> </pre> <br><p><img src="https://habrastorage.org/webt/lw/21/fn/lw21fnq0hmobp49moqmytvcdjbe.png"></p><br><p>  ... e um pouco mais: </p><br><pre> <code class="python hljs">ofGradient(fit = [<span class="hljs-number"><span class="hljs-number">4.3</span></span>, <span class="hljs-number"><span class="hljs-number">4.9</span></span>], st = <span class="hljs-number"><span class="hljs-number">8.9</span></span>, low = [<span class="hljs-number"><span class="hljs-number">-5.2</span></span> <span class="hljs-number"><span class="hljs-number">-2.2</span></span>], up = [<span class="hljs-number"><span class="hljs-number">8.1</span></span> <span class="hljs-number"><span class="hljs-number">7.1</span></span>] )</code> </pre> <br><p><img src="https://habrastorage.org/webt/ah/pj/1s/ahpj1swejdx7srnqo5jh7s0af9w.png"><br>  √ìtimo!  E agora algo com uma ravina, como a fun√ß√£o Rosenbrock: </p><br><pre> <code class="python hljs">rosenbrok(x) = <span class="hljs-number"><span class="hljs-number">100</span></span>(x[<span class="hljs-number"><span class="hljs-number">2</span></span>]-x[<span class="hljs-number"><span class="hljs-number">1</span></span>]*x[<span class="hljs-number"><span class="hljs-number">1</span></span>])^<span class="hljs-number"><span class="hljs-number">2</span></span> + (x[<span class="hljs-number"><span class="hljs-number">1</span></span>]<span class="hljs-number"><span class="hljs-number">-1</span></span>)^<span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-comment"><span class="hljs-comment"># f(0,0) = 0, x_i ‚àà [-5,5] fun = rosenbrok plotter(surface, low = [-2 -1.5], up = [2 1.5])</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/rn/mo/wj/rnmowjiuky7rayeoaw410fh1jem.png"></p><br><pre> <code class="python hljs">ofGradient(fit = [<span class="hljs-number"><span class="hljs-number">2.3</span></span>, <span class="hljs-number"><span class="hljs-number">2.2</span></span>], st = <span class="hljs-number"><span class="hljs-number">9.9</span></span>, low = [<span class="hljs-number"><span class="hljs-number">-5.2</span></span> <span class="hljs-number"><span class="hljs-number">-5.2</span></span>], up = [<span class="hljs-number"><span class="hljs-number">8.1</span></span> <span class="hljs-number"><span class="hljs-number">7.1</span></span>] )</code> </pre> <br><p><img src="https://habrastorage.org/webt/hd/fm/d3/hdfmd3vr0zammghj39u5o-3nu-y.png"></p><br><pre> <code class="python hljs">ofGradient(fit = [<span class="hljs-number"><span class="hljs-number">2.3</span></span>, <span class="hljs-number"><span class="hljs-number">2.2</span></span>], st = <span class="hljs-number"><span class="hljs-number">0.9</span></span>, low = [<span class="hljs-number"><span class="hljs-number">-5.2</span></span> <span class="hljs-number"><span class="hljs-number">-5.2</span></span>], up = [<span class="hljs-number"><span class="hljs-number">8.1</span></span> <span class="hljs-number"><span class="hljs-number">7.1</span></span>] )</code> </pre> <br><p><img src="https://habrastorage.org/webt/rp/eu/mf/rpeumfpmjhvxjo-5k0cm1fjtnyq.png"><br>  Moralidade: os gradientes n√£o gostam de copa. </p><br><h2 id="simpleks-metod">  M√©todo simplex </h2><br><p>  O m√©todo Nelder-Mead, tamb√©m conhecido como m√©todo de poliedro deform√°vel e m√©todo simplex, √© um m√©todo de otimiza√ß√£o incondicional de uma fun√ß√£o de v√°rias vari√°veis ‚Äã‚Äãque n√£o usa a derivada (mais precisamente, gradientes) da fun√ß√£o e, portanto, √© facilmente aplic√°vel a fun√ß√µes n√£o suaves e / ou com ru√≠do. </p><br><p>  A ess√™ncia do m√©todo √© o movimento sequencial e a deforma√ß√£o de um simplex em torno de um ponto extremo. </p><br><p>  O m√©todo encontra um extremo local e pode estar preso em um deles.  Se voc√™ ainda precisa encontrar um extremo global, pode tentar escolher um simplex inicial diferente. </p><br><p>  Fun√ß√µes auxiliares: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          function sortcoord(Mx) N = size(Mx,2) f = [fun(Mx[:,i]) for i in 1:N] #     Mx[:, sortperm(f)] #Return a permutation vector I that puts v[I] in sorted order. end #   function normx(Mx) m = size(Mx,2) D = zeros(m-1,m) vecl(x) = sqrt( sum(u -&gt; u*u, x) )#   for i = 1:m, j = i+1:m D[i,j] = vecl(Mx[:,i] - Mx[:,j]) #     end D sqrt(maximum(D)) end function simplexplot(xy, low, up) for i = 1:length(xy) if i%11 == 0 low *= 0.05 up *= 0.05 end Xs = range(low[1], stop = up[1], length = 80) Ys = range(low[2], stop = up[2], length = 80) Zs = [ fun([xy]) for y in Ys, x in Xs ] contour(Xs, Ys, Zs) xaxis!( low[1]:(up[1]-low[1])*0.2:up[1] ) yaxis!( low[2]:(up[2]-low[2])*0.2:up[2] ) plot!(xy[i][1,:], xy[i][2,:], w = 3, legend = false, marker = :circle ) title!("Age = $if(x,y) = $(fun(xy[i][:,1]))") savefig("$fun $i.png") end end</span></span></code> </pre> <br><p>  E o pr√≥prio m√©todo simplex: </p><br><pre> <code class="python hljs">function ofNelderMid(; ndimes = <span class="hljs-number"><span class="hljs-number">2</span></span>, Œµ = <span class="hljs-number"><span class="hljs-number">1e-4</span></span>, fit = [<span class="hljs-number"><span class="hljs-number">.1</span></span>, <span class="hljs-number"><span class="hljs-number">.1</span></span>], low = [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-number"><span class="hljs-number">-1</span></span>], up = [<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>]) vecl(v) = sqrt( sum(x -&gt; x*x, v) ) k = <span class="hljs-number"><span class="hljs-number">0</span></span> N = ndimes Xx = zeros(N, N+<span class="hljs-number"><span class="hljs-number">1</span></span>) coords = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i = <span class="hljs-number"><span class="hljs-number">1</span></span>:N+<span class="hljs-number"><span class="hljs-number">1</span></span> Xx[:,i] = fit end <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i = <span class="hljs-number"><span class="hljs-number">1</span></span>:N Xx[i,i] += <span class="hljs-number"><span class="hljs-number">0.5</span></span>*vecl(fit) + Œµ end p = normx(Xx) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> p &gt; Œµ k += <span class="hljs-number"><span class="hljs-number">1</span></span> Xx = sortcoord(Xx) Xo = [ sum(Xx[i,<span class="hljs-number"><span class="hljs-number">1</span></span>:N])/N <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i = <span class="hljs-number"><span class="hljs-number">1</span></span>:N ] <span class="hljs-comment"><span class="hljs-comment">#  - i-  Ro = 2Xo - Xx[:,N+1] FR = fun(Ro) if FR &gt; fun(Xx[:,N+1]) for i = 2:N+1 Xx[:,i] = 0.5(Xx[:,1] + Xx[:,i]) end else if FR &lt; fun(Xx[:,1]) Eo = Xo + 2(Xo - Xx[:,N+1]) if FR &gt; fun(Eo) Xx[:,N+1] = Eo else Xx[:,N+1] = Ro end else if FR &lt;= fun(Xx[:,N]) Xx[:,N+1] = Ro else Co = Xo + 0.5(Xo - Xx[:,N+1]) if FR &gt; fun(Co) Xx[:,N+1] = Co else Xx[:,N+1] = Ro end end end end #println(k, " ", p, " ", Xx[:,1]) push!(coords, [Xx[:,1:3] Xx[:,1] ]) p = normx(Xx) end #while #simplexplot(coords, low, up) fit = Xx[:,1] end ofNelderMid(fit = [-9, -2], low = [-2 2], up = [-8 8])</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/td/1q/e6/td1qe6h4ykk4snlgxikunbmxrbc.gif"></p><br><p>  E para a sobremesa um pouco de faia ... por exemplo, a fun√ß√£o de Bukin <br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">f</span><span class="MJXp-mo" id="MJXp-Span-3" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">x</span><span class="MJXp-mo" id="MJXp-Span-5" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-6">y</span><span class="MJXp-mo" id="MJXp-Span-7" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-8" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-9">100</span><span class="MJXp-mtext" id="MJXp-Span-10">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12">q</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14">t</span><span class="MJXp-mrow" id="MJXp-Span-15"><span class="MJXp-mrow" id="MJXp-Span-16"><span class="MJXp-mo" id="MJXp-Span-17" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18">y</span><span class="MJXp-mo" id="MJXp-Span-19" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mn" id="MJXp-Span-20">0.01</span><span class="MJXp-msubsup" id="MJXp-Span-21"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22" style="margin-right: 0.05em;">x</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-23" style="vertical-align: 0.5em;">2</span></span><span class="MJXp-mrow" id="MJXp-Span-24"><span class="MJXp-mo" id="MJXp-Span-25" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span></span><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-27">0.01</span><span class="MJXp-mrow" id="MJXp-Span-28"><span class="MJXp-mo" id="MJXp-Span-29" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-30">x</span><span class="MJXp-mo" id="MJXp-Span-31" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-32">10</span><span class="MJXp-mrow" id="MJXp-Span-33"><span class="MJXp-mo" id="MJXp-Span-34" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-1"> f (x, y) = 100 \ sqrt {| y-0.01x ^ 2 |} + 0.01 | x + 10 | </script></p><br><pre> <code class="python hljs">bukin6(x) = <span class="hljs-number"><span class="hljs-number">100</span></span>sqrt(abs(x[<span class="hljs-number"><span class="hljs-number">2</span></span>]<span class="hljs-number"><span class="hljs-number">-0.01</span></span>x[<span class="hljs-number"><span class="hljs-number">1</span></span>]*x[<span class="hljs-number"><span class="hljs-number">1</span></span>])) + <span class="hljs-number"><span class="hljs-number">0.01</span></span>abs(x[<span class="hljs-number"><span class="hljs-number">1</span></span>]+<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-comment"><span class="hljs-comment"># f(-10,1) = 0, x_i ‚àà [-15,-5; -3,3] fun = bukin6 ofNelderMid(fit = [-10, -2], low = [-3 -7], up = [-8 -4.5])</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/i2/fx/hb/i2fxhbbd0mtly2pnw9et4ojecfy.gif"></p><br><p>  M√≠nimo local - bem, nada, a principal coisa √© escolher o simplex inicial certo, ent√£o, para mim, encontrei um favorito. </p><br><p>  B√¥nus  M√©todos de Nelder-Mead, a descida mais r√°pida e a descida coordenada em C ++ </p><br><div class="spoiler">  <b class="spoiler_title">Alarme!</b>  <b class="spoiler_title">550 linhas de c√≥digo!</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">/* * File: main.cpp * Author: User * * Created on 3  2017 ., 21:22 */</span></span> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;math.h&gt; using namespace std; typedef double D; class Model { public: D *fit; D ps; Model(); DI(); }; Model :: Model() { ps = 1; fit = new D[3]; fit[0]=1.3; fit[1]=1.; fit[2]=2.; } D Model :: I() // rosenbrock { return 100*(fit[1]-fit[0]*fit[0]) * (fit[1]-fit[0]*fit[0]) + (1-fit[0])*(1-fit[0]); } class Methods : public Model { public: void ofDescent(); void Newton(int i); void SPI(int i); //sequential parabolic interpolation void Cutters(int i); void Interval(D *ab, D st, int i); void Gold_section(int i); void ofGradient(); void Grad(int N, D *g, D delta); void Srt(D **X, int N); void ofNelder_Mid(); D Nor(D **X, int N); }; void Methods :: ofDescent()//   { int i, j=0; D *z = new D[3]; D sumx, sumz; sumx = sumz = 0; do { sumx = sumz = 0; for(i=0; i&lt;3; i++) z[i] = fit[i]; for(i=0; i&lt;2; i++) { //Cutters(i); //SPI(i); Newton(i); //Gold_section(i); sumx += fit[i]; sumz += z[i]; } j++; //if(j%1000==0) cout &lt;&lt; j &lt;&lt; " " &lt;&lt; fit[0] &lt;&lt; " " &lt;&lt; fit[1] &lt;&lt; " " &lt;&lt; fit[2] &lt;&lt; " " &lt;&lt; fit[3] &lt;&lt; endl; //cout &lt;&lt; sumz &lt;&lt; " " &lt;&lt; sumx &lt;&lt; endl; } while(fabs(sumz - sumx) &gt; 1e-6); delete[]z; } void Methods :: SPI(int i) { int k = 2; D f0, f1, f2; D v0, v1, v2; D s0, s1, s2; D *X = new D[300]; X[0] = fit[i] + 0.01; X[1] = fit[i]; X[2] = fit[i] - 0.01; while(fabs(X[k] - X[k-1]) &gt; 1e-3) { fit[i] = X[k]; f0 = I(); fit[i] = X[k-1]; f1 = I(); fit[i] = X[k-2]; f2 = I(); v0 = X[k-1] - X[k-2]; v1 = X[k ] - X[k-2]; v2 = X[k ] - X[k-1]; s0 = X[k-1]*X[k-1] - X[k-2]*X[k-2]; s1 = X[k ]*X[k ] - X[k-2]*X[k-2]; s2 = X[k ]*X[k ] - X[k-1]*X[k-1]; X[k+1] = 0.5*(f2*s2 - f1*s1 + f0*s0) / (f2*v2 - f1*v1 + f0*v0); k++; cout &lt;&lt; k &lt;&lt; " " &lt;&lt; X[k] &lt;&lt; endl; } fit[i] = X[k]; delete[]X; } void Methods :: Newton(int i) { D dt, T, It; int k=0; while(fabs(T-fit[i]) &gt; 1e-3) { It = I(); T = fit[i]; fit[i] += 0.01; dt = I(); fit[i] -= 0.01; fit[i] -= It*0.001 / (dt - It); cout &lt;&lt; k &lt;&lt; " " &lt;&lt; fit[i] &lt;&lt; endl; k++; } } void Methods :: Cutters(int i) { D Tn, Tnm, Tnp, It, Itm; int j=0; Tn = 0.15; Tnm = 2.65;//otrezok Itm = I(); //cout &lt;&lt; Tnm &lt;&lt; " " &lt;&lt; Tn &lt;&lt; endl; while(fabs(Tn-Tnm) &gt; 1e-6) { fit[i] = Tn; It = I(); Tnp = Tn - It * (Tn-Tnm) / (It-Itm); cout &lt;&lt; j+1 &lt;&lt; " " &lt;&lt; Tnp &lt;&lt; endl; Itm = It; Tnm = Tn; Tn = Tnp; j++; } fit[i] = Tnp; } void Methods :: Interval(D *ab, D st, int i) { D Fa, Fdx, d, c, Fb, fitbox = fit[i]; ab[0] = fit[i]; Fa = I(); fit[i] -= st; Fdx = I(); fit[i] += st; if(Fdx &lt; Fa) st = -st; fit[i] += st; ab[1] = fit[i]; Fb = I(); while(Fb &lt; Fa) { d = ab[0]; ab[0] = ab[1]; Fa = Fb; fit[i] += st; ab[1] = fit[i]; Fb = I(); cout &lt;&lt; Fb &lt;&lt; " " &lt;&lt; Fa &lt;&lt; endl; } if(st&lt;0) { c = ab[1]; ab[1] = d; d = c; } ab[0] = d; fit[i] = fitbox; } void Methods :: Gold_section(int i) { D Fa, Fb, al, be; D *ab = new D[2]; D st = 0.5; D e = 0.5*(sqrt(5) - 1); Interval(ab, st, i); al = e*ab[0] + (1-e)*ab[1]; be = e*ab[1] + (1-e)*ab[0]; fit[i] = al; Fa = I(); fit[i] = be; Fb = I(); while(fabs(ab[1]-ab[0]) &gt; e) { if(Fa &lt; Fb) { ab[1] = be; be = al; Fb = Fa; al = e*ab[0] + (1-e)*ab[1]; fit[i] = al; Fa = I(); } if(Fa &gt; Fb) { ab[0] = al; al = be; Fa = Fb; be = e*ab[1] + (1-e)*ab[0]; fit[i] = be; Fb = I(); } cout &lt;&lt; ab[0] &lt;&lt; " " &lt;&lt; ab[1] &lt;&lt; endl; } fit[i] = 0.5*(ab[0] + ab[1]); cout &lt;&lt; ab[0] &lt;&lt; " " &lt;&lt; ab[1] &lt;&lt; endl; } void Methods :: Grad(int N, D *g, D delta)//   { int n; D Fr, Fl, modG=0; for(n=0; n&lt;N; n++) { fit[n] += delta; Fr = I(); fit[n] -= delta; fit[n] -= delta; Fl = I(); fit[n] += delta; g[n] = (Fr - Fl)*0.5/delta; modG += g[n]*g[n]; } modG = sqrt(modG); for(n=0; n&lt;N; n++) g[n] /= modG; g[N] = I(); } void Methods :: ofGradient() { int n, j=0; D Fun, st, eps; const int N = 2; D *g = new D[N+1]; st = 0.1; eps = 0.000001; while(st &gt; eps) { Grad(N,g,0.0001); for(n=0; n&lt;N; n++) fit[n] -= st*g[n]; Fun = I(); if(Fun &gt;= g[N]) { st /= 2.; for(n=0; n&lt;N; n++) fit[n] += st*g[n]; } j++; cout &lt;&lt; j &lt;&lt; " " &lt;&lt; fit[0]/ps &lt;&lt; " " &lt;&lt; fit[1]/ps &lt;&lt; " " &lt;&lt; fit[2]/ps&lt;&lt; endl; } } void Methods :: ofNelder_Mid() { int i, j, k; D modz = 0., p, eps = 1e-3; D FR, FN, F0, FE, FNm1, FC; const int N = 2; D *Co = new D[N]; D *Eo = new D[N]; D *Ro = new D[N]; D *Xo = new D[N]; D **Xx = new D*[N]; D **dz = new D*[N]; for(i=0;i&lt;N;i++) { dz[i] = new D[N]; Xx[i] = new D[N+1]; } for(i=0;i&lt;N;i++) for(j=0;j&lt;N;j++) if(i^j) dz[i][j] = 0; else dz[i][j] = 1; for(i=0;i&lt;N;i++) Xx[i][N] = fit[i]; for(i=0;i&lt;N;i++) modz += fit[i]*fit[i]; modz = sqrt(modz); for(i=0;i&lt;N;i++) dz[i][i] = 0.5*modz; for(i=0;i&lt;N;i++) for(j=0;j&lt;N;j++) Xx[i][j] = fit[i] + dz[i][j]; k = 0; p = Nor(Xx, N); while(p &gt; eps) { k++; Srt(Xx, N); for(i=0;i&lt;N;i++) Xo[i] = 0.; for(i=0;i&lt;N;i++) for(j=0;j&lt;N;j++) Xo[i] += Xx[i][j]; for(i=0;i&lt;N;i++) Xo[i] /= N; for(i=0;i&lt;N;i++) Ro[i] = Xo[i] + (Xo[i]-Xx[i][N]); for(i=0;i&lt;N;i++) fit[i] = Ro[i]; FR = I(); for(i=0;i&lt;N;i++) fit[i] = Xx[i][N]; FN = I(); if(FR &gt; FN) { for(i=0;i&lt;N;i++) for(j=1;j&lt;=N;j++) Xx[i][j] = 0.5*(Xx[i][0] + Xx[i][j]); } else { for(i=0;i&lt;N;i++) fit[i] = Xx[i][0]; F0 = I(); if(FR &lt; F0) { for(i=0;i&lt;N;i++) Eo[i] = Xo[i] +2*(Xo[i] - Xx[i][N]); for(i=0;i&lt;N;i++) fit[i] = Eo[i]; FE = I(); if(FE &lt; FR) for(i=0;i&lt;N;i++) Xx[i][N] = Eo[i]; else for(i=0;i&lt;N;i++) Xx[i][N] = Ro[i]; } else { for(i=0;i&lt;N;i++) fit[i] = Xx[i][N-1]; FNm1 = I(); if(FR &lt;= FNm1) for(i=0;i&lt;N;i++) Xx[i][N] = Ro[i]; else { for(i=0;i&lt;N;i++) Co[i] = Xo[i] +0.5*(Xo[i] - Xx[i][N]); for(i=0;i&lt;N;i++) fit[i] = Co[i]; FC = I(); if(FC &lt; FR) for(i=0;i&lt;N;i++) Xx[i][N] = Co[i]; else for(i=0;i&lt;N;i++) Xx[i][N] = Ro[i]; } } } for(i=0;i&lt;N;i++) cout &lt;&lt; Xx[i][0] &lt;&lt; " "; cout &lt;&lt; k &lt;&lt; " " &lt;&lt; p &lt;&lt; endl; p = Nor(Xx, N); if(p &lt; eps) break; } for(i=0;i&lt;N;i++) fit[i] = Xx[i][0]; /*for(i=0;i&lt;N;i++) { for(j=0;j&lt;N+1;j++) cout &lt;&lt; Xx[i][j] &lt;&lt; " "; cout &lt;&lt; endl; }*/ delete[]Co; delete[]Xo; delete[]Ro; delete[]Eo; for(i=0;i&lt;N;i++) { delete[]dz[i]; delete[]Xx[i]; } } //   D Methods :: Nor(D **X, int N) { int i, j, k; D norm, xij, pn = 0.; for(i=0;i&lt;N;i++) for(j=i+1;j&lt;=N;j++) { xij = 0.; for(k=0;k&lt;N;k++) xij += ( (X[k][i]-X[k][j])*(X[k][i]-X[k][j]) ); pn = sqrt(xij);//    if(norm &gt; pn) norm = pn;//   } return sqrt(norm); } //    void Methods :: Srt(D **X, int N) { int i, j, k; D temp; D *f = new D[N+1]; D *box = new D[N]; D **y = new D*[N+1]; for(i=0;i&lt;N+1;i++)//  y[i] = new D[N+1]; for(i=0;i&lt;N;i++) box[i] = fit[i];//    for(i=0;i&lt;=N;i++) { for(j=0;j&lt;N;j++) fit[j] = X[j][i]; f[i] = I();//     } for(i=0;i&lt;N;i++) fit[i] = box[i];//    for(i=0;i&lt;N;i++) for(j=0;j&lt;=N;j++) y[i][j] = X[i][j]; for(i=0;i&lt;=N;i++) y[N][i] = f[i];//stack(X, f) //    , //     N    for(i=1;i&lt;=N;i++) for(j=0;j&lt;=Ni;j++) if(y[N][j] &gt;= y[N][j+1]) for(k=0;k&lt;=N;k++) { temp = y[k][j]; y[k][j] = y[k][j+1]; y[k][j+1] = temp; } //submatrix   for(i=0;i&lt;N;i++) for(j=0;j&lt;=N;j++) X[i][j] = y[i][j]; /* for(i=0;i&lt;=N;i++) { for(j=0;j&lt;=N;j++) cout &lt;&lt; y[i][j] &lt;&lt; " "; cout &lt;&lt; endl; } */ for(i=0;i&lt;N+1;i++) delete[]y[i]; delete[]box; delete[]f; } int main() { Methods method; //method.ofDescent(); //method.ofGradient(); method.ofNelder_Mid(); return 0; }</span></span></span></span></code> </pre></div></div><br><p>  O suficiente por hoje.  A pr√≥xima etapa ser√° l√≥gica para tentar algo da otimiza√ß√£o global, digitar mais fun√ß√µes de teste e depois estudar os pacotes com m√©todos internos. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt440070/">https://habr.com/ru/post/pt440070/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt440058/index.html">Relat√≥rio de problemas e disponibilidade da Internet 2018‚Äì2019</a></li>
<li><a href="../pt440060/index.html">TensorFlow no Apache Ignite</a></li>
<li><a href="../pt440062/index.html">Planejando com prazer. Como configuramos processos sem gerentes</a></li>
<li><a href="../pt440064/index.html">Data centers √† sua escolha: Londres, Moscou, Zurique, S√£o Petersburgo</a></li>
<li><a href="../pt440066/index.html">Extens√µes VSCode para facilitar o desenvolvimento de JavaScript e Vue</a></li>
<li><a href="../pt440072/index.html">Demo AresDB: ferramenta de an√°lise em tempo real de fonte aberta baseada em GPU do Uber</a></li>
<li><a href="../pt440074/index.html">Roskomos considera incorreto comparar os motores Raptor Ilona Mask e RD-180</a></li>
<li><a href="../pt440076/index.html">Tradu√ß√£o e interpreta√ß√£o de publicidade do ingl√™s para o russo</a></li>
<li><a href="../pt440078/index.html">Dispositivo compilador r√°pido. Parte 4</a></li>
<li><a href="../pt440084/index.html">10 bilh√µes de exporta√ß√µes de software √© insignificante</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
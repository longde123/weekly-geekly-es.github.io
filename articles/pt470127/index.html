<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíï üé® üöª Compositor com mem√≥ria de longo prazo üí≥ üêÉ üâê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Compor m√∫sicas automaticamente 

 Quase imediatamente depois de aprender a programar, eu queria criar um software capaz de compor m√∫sicas. 

 Por v√°ri...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Compositor com mem√≥ria de longo prazo</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470127/"><h2>  Compor m√∫sicas automaticamente </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e91/f1e/b09/e91f1eb09e53ad458aaaeca5650b59aa.jpg" width="500"></div><br>  Quase imediatamente depois de aprender a programar, eu queria criar um software capaz de compor m√∫sicas. <br><br>  Por v√°rios anos, fiz tentativas primitivas de compor m√∫sicas automaticamente para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Visions of Chaos</a> .  Basicamente, foram utilizadas f√≥rmulas matem√°ticas simples ou muta√ß√µes gen√©ticas de seq√º√™ncias aleat√≥rias de notas.  Tendo alcan√ßado recentemente um sucesso modesto no estudo e aplica√ß√£o do TensorFlow e das redes neurais para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">procurar aut√¥matos celulares</a> , decidi tentar usar redes neurais para criar m√∫sica. <br><br><h2>  Como isso funciona </h2><br>  O compositor ensina uma rede neural com mem√≥ria de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">longo</a> prazo (LSTM).  As redes LSTM s√£o adequadas para prever o que vem a seguir nas sequ√™ncias de dados.  Leia mais sobre LSTM <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">aqui</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0db/ce9/120/0dbce9120efb949af9aff64a8177c02f.png" title="LSTM - Clique para o tamanho original" width="500"></div><br>  Uma rede LSTM recebe v√°rias seq√º√™ncias de notas (nesse caso, s√£o arquivos midi de canal √∫nico).  Ap√≥s treinamento suficiente, ela tem a oportunidade de criar m√∫sicas semelhantes aos materiais de ensino. <br><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3f1/b32/98d/3f1b3298dededa70f51a95d42727aaf0.png" title="LSTM - Clique para o tamanho original" width="500"></div><br>  Os elementos internos do LSTM podem parecer intimidadores, mas o uso do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">TensorFlow</a> e / ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Keras</a> simplifica bastante a cria√ß√£o e a experimenta√ß√£o do LSTM. <br><br><h2>  M√∫sica de origem para treinamento de modelos </h2><br>  Para redes LSTM simples, basta que as composi√ß√µes de origem sejam um √∫nico canal midi.  √ìtimo para isso s√£o arquivos midi do solo ao piano.  Encontrei arquivos midi com solos de piano na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">p√°gina</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">mfiles</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Classical Piano</a> e usei-os para treinar meus modelos. <br><br>  Coloquei a m√∫sica de diferentes compositores em pastas separadas.  Gra√ßas a isso, o usu√°rio pode selecionar Bach, clicar no bot√£o Compor e obter uma m√∫sica que (espero) seja como Bach. <br><br><h2>  Modelo LSTM </h2><br>  O modelo com base no qual escrevi o c√≥digo selecionou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este exemplo do</a> autor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Sigur√∞ur Sk√∫li Sigurgeirsson</a> , sobre quem ele escreve com mais detalhes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">aqui</a> . <br><br>  Executei o script lstm.py e ap√≥s 15 horas ele concluiu o treinamento.  Quando executei o predict.py para gerar os arquivos midi, fiquei desapontado porque eles consistiam em uma nota repetida.  Repetindo o treinamento duas vezes, obtive os mesmos resultados. <br><br>  Modelo de origem <br><br><pre><code class="python hljs">model = Sequential() model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">512</span></span>,input_shape=(network_input.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], network_input.shape[<span class="hljs-number"><span class="hljs-number">2</span></span>]),return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">512</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">512</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(n_vocab)) model.add(Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'rmsprop'</span></span>,metrics=[<span class="hljs-string"><span class="hljs-string">"accuracy"</span></span>])</code> </pre> <br>  Depois de adicionar a sa√≠da do gr√°fico ao script, vi por que meu modelo n√£o funcionou.  A precis√£o n√£o cresceu com o tempo, como deveria.  Veja abaixo no post os bons gr√°ficos que mostram como deve ser o modelo de trabalho. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/28c/2ef/19d/28c2ef19dee58e8235a240b536162ceb.jpg" title="Clique para o tamanho original" width="500"></div><br>  Eu n√£o tinha ideia do por que aconteceu.  mas abandonou esse modelo e come√ßou a ajustar as configura√ß√µes. <br><br><pre> <code class="python hljs">model = Sequential() model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">512</span></span>, input_shape=(network_input.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], network_input.shape[<span class="hljs-number"><span class="hljs-number">2</span></span>]), return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(BatchNormalization()) model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(BatchNormalization()) model.add(Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(BatchNormalization()) model.add(Dense(n_vocab)) model.add(Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>,metrics=[<span class="hljs-string"><span class="hljs-string">"accuracy"</span></span>])</code> </pre> <br>  √â mais compacto e possui menos camadas LSTM.  Tamb√©m adicionei o BatchNormalization, vendo-o no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">v√≠deo sentdex</a> .  Provavelmente, existem modelos melhores, mas este funcionou muito bem em todas as minhas sess√µes de treinamento. <br><br>  Observe que nos dois modelos substitu√≠ LSTM por CuDNNLSTM.  Ent√£o, consegui um treinamento LSTM muito mais r√°pido, gra√ßas ao uso do Cuda.  Se voc√™ n√£o possui uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">GPU com suporte ao Cuda</a> , use o LSTM.  Obrigado ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">sendtex</a> por esta dica.  Aprender novos modelos e compor arquivos midi usando CuDNNLSTM √© cerca de cinco vezes mais r√°pido. <br><br><h2>  Por quanto tempo o modelo deve ser treinado </h2><br>  A semelhan√ßa dos resultados com a m√∫sica original depende da dura√ß√£o do treinamento do modelo (o n√∫mero de √©pocas).  Se houver poucas eras, o resultado resultante ter√° muitas notas repetidas.  Se houver muitas eras, o modelo ser√° treinado novamente e simplesmente copie a m√∫sica original. <br><br>  Mas como voc√™ sabe quantas √©pocas parar? <br><br>  Uma solu√ß√£o simples √© adicionar um retorno de chamada que armazene o modelo e o gr√°fico de precis√£o / perda a cada 50 √©pocas em uma execu√ß√£o de treinamento em 500 √©pocas.  Gra√ßas a isso, ap√≥s concluir o treinamento, voc√™ obter√° modelos e gr√°ficos com um incremento de 50 √©pocas, mostrando como o treinamento ocorre. <br><br>  Aqui est√£o os resultados dos gr√°ficos de uma execu√ß√£o com salvamento a cada 50 √©pocas, combinados em um GIF animado. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e93/357/716/e933577163ece7cc7e679edec71d0b90.gif"></div><br>  Estes s√£o os gr√°ficos que queremos ver.  As perdas devem cair e permanecer baixas.  A precis√£o deve aumentar e permanecer pr√≥xima de 100%. <br><br>  √â necess√°rio usar um modelo com o n√∫mero de √©pocas correspondente ao momento em que os gr√°ficos atingiram seus limites pela primeira vez.  Para o gr√°fico mostrado acima, ser√£o 150 eras.  Se voc√™ usar modelos mais antigos, eles ser√£o treinados novamente e provavelmente levar√£o a uma c√≥pia simples do material de origem. <br><br>  O modelo correspondente a essas colunas foi treinado em arquivos midi da categoria Hinos, extra√≠dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">daqui</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Sa√≠da de dados midi em um modelo com 150 eras. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Sa√≠da Midi em um modelo de 100 √©pocas. <br><br>  Mesmo um modelo com 100 eras pode copiar a fonte com muita precis√£o.  Isso pode ser devido a uma amostra relativamente pequena de arquivos midi para treinamento.  Com mais notas, o aprendizado √© melhor. <br><br><h2>  Quando o aprendizado vai mal </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/166/c17/97c/166c1797ceb0baa6894a982d55ce12ed.jpg" title="Clique para o tamanho original" width="500"></div><br>  A imagem acima mostra um exemplo do que pode e acontece durante o treinamento.  As perdas s√£o reduzidas e a precis√£o √© aumentada, como de costume, mas de repente elas come√ßam a enlouquecer.  Nesta fase, tamb√©m pode valer a pena parar.  O modelo n√£o aprender√° mais (pelo menos na minha experi√™ncia) novamente.  Nesse caso, o modelo salvo com 100 eras ainda √© muito aleat√≥rio e, com 150 eras, o momento de falha do modelo j√° passou.  Agora eu sou salvo a cada 25 √©pocas para encontrar exatamente o momento ideal da modelo com o melhor treinamento, mesmo antes de ela treinar novamente e travar. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/486/65a/eea/48665aeea577e093ad0d944a4b4a3a35.jpg" title="Clique para o tamanho original" width="500"></div><br>  Outro exemplo de erro de aprendizagem.  Este modelo foi treinado em arquivos midi retirados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">daqui</a> .  Nesse caso, ela se manteve bem por pouco mais de 200 √©pocas.  Ao usar um modelo com 200 eras, o resultado a seguir √© obtido no Midi. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Sem a cria√ß√£o de gr√°ficos, nunca saber√≠amos se o modelo tem problemas e quando surgiram, e tamb√©m n√£o conseguir√≠amos um bom modelo sem come√ßar do zero. <br><br><h2>  Outros exemplos </h2><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo com 75 eras, criado com base nas composi√ß√µes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Chopin</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo da era 50 baseado em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">arquivos Midi para composi√ß√µes de Natal</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo de 100 √©pocas baseado em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">arquivos Midi para composi√ß√µes de Natal</a> .  Mas eles s√£o realmente "Natal"? <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo de 300 √©pocas baseado em arquivos Bach Midi, extra√≠dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">daqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">daqui</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo de 200 √©pocas baseado no √∫nico arquivo Midi de Balakirev tirado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">aqui</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Modelo com 200 √©pocas, baseado em composi√ß√µes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Debussy</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo da era 175 baseado nas composi√ß√µes de Mozart. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo com 100 √©pocas baseado em composi√ß√µes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Schubert</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo da era 200 baseado em composi√ß√µes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Schumann</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo da √©poca 200 baseado nas composi√ß√µes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">de Tchaikovsky</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo com 175 √©pocas baseado em can√ß√µes folcl√≥ricas. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Modelo com 100 eras baseado em can√ß√µes de ninar. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo da era 100 baseado na m√∫sica do casamento. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Clique para ouvir midi" width="26"></a> <br><br>  Um modelo de 200 √©pocas baseado em meus pr√≥prios arquivos midi, extra√≠dos das minhas trilhas sonoras de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">v√≠deos do YouTube</a> .  Pode ser um pouco reciclado, porque basicamente gera c√≥pias dos meus arquivos midi curtos de um e dois tempos. <br><br><h2>  Pontua√ß√µes </h2><br>  Depois de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">obter seus</a> arquivos midi, voc√™ pode usar ferramentas on-line como o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">SolMiRe</a> para convert√™-los em pontua√ß√µes.  Abaixo est√° a pontua√ß√£o do arquivo midi Softology 200-epoch apresentado acima. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1e4/7fe/2cc/1e47fe2cc3cada4e27671bfe27397226.jpg" title="Clique para o tamanho original" width="500"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ccd/2ff/dff/ccd2ffdff1344ef7ad97a210dba6b17e.jpg" title="Clique para o tamanho original" width="500"></div><br><h2>  Onde posso testar o compositor </h2><br>  O LSTM Composer agora est√° inclu√≠do no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">Visions of Chaos</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/29c/abd/6ac/29cabd6acecf1baf6fd9f99e531d1f9e.jpg" width="500"></div><br>  Selecione um estilo na lista suspensa e clique em Escrever.  Se voc√™ instalou o m√≠nimo necess√°rio de Python e TensorFlow (consulte as instru√ß√µes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener">aqui</a> ), em alguns segundos (se voc√™ tiver uma GPU r√°pida), voc√™ receber√° um novo arquivo midi composto por m√°quina que poder√° ouvir e usar para qualquer outra finalidade.  Sem direitos autorais, sem royalties.  Se voc√™ n√£o gostar dos resultados, poder√° clicar em Redigir novamente e ap√≥s alguns segundos uma nova composi√ß√£o estar√° pronta. <br><br>  Os resultados ainda n√£o podem ser considerados composi√ß√µes completas, mas eles t√™m pequenas sequ√™ncias interessantes de notas que usarei para criar m√∫sica no futuro.  Nesse sentido, o compositor LSTM pode ser uma boa fonte de inspira√ß√£o para novas composi√ß√µes. <br><br><h2>  Fonte Python </h2><br>  Abaixo est√° o c√≥digo de script Python que usei para treinamento e previs√£o de LSTM.  Para que esses scripts funcionem, n√£o √© necess√°rio instalar o Visions of Chaos, e o aprendizado e a gera√ß√£o do midi funcionar√£o na linha de comando. <br><br>  Aqui est√° o script de treinamento <code>lstm_music_train.py</code> <br><br><div class="spoiler">  <b class="spoiler_title">lstm_music_train.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># based on code from https://github.com/Skuldur/Classical-Piano-Composer # to use this script pass in; # 1. the directory with midi files # 2. the directory you want your models to be saved to # 3. the model filename prefix # 4. how many total epochs you want to train for # eg python -W ignore "C:\\LSTM Composer\\lstm_music_train.py" "C:\\LSTM Composer\\Bach\\" "C:\\LSTM Composer\\" "Bach" 500 import os import tensorflow as tf # ignore all info and warning messages os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) import glob import pickle import numpy import sys import keras import matplotlib.pyplot as plt from music21 import converter, instrument, note, chord from datetime import datetime from keras.models import Sequential from keras.layers.normalization import BatchNormalization from keras.layers import Dense from keras.layers import Dropout from keras.layers import CuDNNLSTM from keras.layers import Activation from keras.utils import np_utils from keras.callbacks import TensorBoard from shutil import copyfile # name of midi file directory, model directory, model file prefix, and epochs mididirectory = str(sys.argv[1]) modeldirectory = str(sys.argv[2]) modelfileprefix = str(sys.argv[3]) modelepochs = int(sys.argv[4]) notesfile = modeldirectory + modelfileprefix + '.notes' # callback to save model and plot stats every 25 epochs class CustomSaver(keras.callbacks.Callback): def __init__(self): self.epoch = 0 # This function is called when the training begins def on_train_begin(self, logs={}): # Initialize the lists for holding the logs, losses and accuracies self.losses = [] self.acc = [] self.logs = [] def on_epoch_end(self, epoch, logs={}): # Append the logs, losses and accuracies to the lists self.logs.append(logs) self.losses.append(logs.get('loss')) self.acc.append(logs.get('acc')*100) # save model and plt every 50 epochs if (epoch+1) % 25 == 0: sys.stdout.write("\nAuto-saving model and plot after {} epochs to ".format(epoch+1)+"\n"+modeldirectory + modelfileprefix + "_" + str(epoch+1).zfill(3) + ".model\n"+modeldirectory + modelfileprefix + "_" + str(epoch+1).zfill(3) + ".png\n\n") sys.stdout.flush() self.model.save(modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.model') copyfile(notesfile,modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.notes'); N = numpy.arange(0, len(self.losses)) # Plot train loss, train acc, val loss and val acc against epochs passed plt.figure() plt.subplots_adjust(hspace=0.7) plt.subplot(2, 1, 1) # plot loss values plt.plot(N, self.losses, label = "train_loss") plt.title("Loss [Epoch {}]".format(epoch+1)) plt.xlabel('Epoch') plt.ylabel('Loss') plt.subplot(2, 1, 2) # plot accuracy values plt.plot(N, self.acc, label = "train_acc") plt.title("Accuracy % [Epoch {}]".format(epoch+1)) plt.xlabel("Epoch") plt.ylabel("Accuracy %") plt.savefig(modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.png') plt.close() # train the neural network def train_network(): sys.stdout.write("Reading midi files...\n\n") sys.stdout.flush() notes = get_notes() # get amount of pitch names n_vocab = len(set(notes)) sys.stdout.write("\nPreparing note sequences...\n") sys.stdout.flush() network_input, network_output = prepare_sequences(notes, n_vocab) sys.stdout.write("\nCreating CuDNNLSTM neural network model...\n") sys.stdout.flush() model = create_network(network_input, n_vocab) sys.stdout.write("\nTraining CuDNNLSTM neural network model...\n\n") sys.stdout.flush() train(model, network_input, network_output) # get all the notes and chords from the midi files def get_notes(): # remove existing data file if it exists if os.path.isfile(notesfile): os.remove(notesfile) notes = [] for file in glob.glob("{}/*.mid".format(mididirectory)): midi = converter.parse(file) sys.stdout.write("Parsing %s ...\n" % file) sys.stdout.flush() notes_to_parse = None try: # file has instrument parts s2 = instrument.partitionByInstrument(midi) notes_to_parse = s2.parts[0].recurse() except: # file has notes in a flat structure notes_to_parse = midi.flat.notes for element in notes_to_parse: if isinstance(element, note.Note): notes.append(str(element.pitch)) elif isinstance(element, chord.Chord): notes.append('.'.join(str(n) for n in element.normalOrder)) with open(notesfile,'wb') as filepath: pickle.dump(notes, filepath) return notes # prepare the sequences used by the neural network def prepare_sequences(notes, n_vocab): sequence_length = 100 # get all pitch names pitchnames = sorted(set(item for item in notes)) # create a dictionary to map pitches to integers note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) network_input = [] network_output = [] # create input sequences and the corresponding outputs for i in range(0, len(notes) - sequence_length, 1): sequence_in = notes[i:i + sequence_length] # needs to take into account if notes in midi file are less than required 100 ( mod ? ) sequence_out = notes[i + sequence_length] # needs to take into account if notes in midi file are less than required 100 ( mod ? ) network_input.append([note_to_int[char] for char in sequence_in]) network_output.append(note_to_int[sequence_out]) n_patterns = len(network_input) # reshape the input into a format compatible with CuDNNLSTM layers network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1)) # normalize input network_input = network_input / float(n_vocab) network_output = np_utils.to_categorical(network_output) return (network_input, network_output) # create the structure of the neural network def create_network(network_input, n_vocab): ''' """ create the structure of the neural network """ model = Sequential() model.add(CuDNNLSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True)) model.add(Dropout(0.3)) model.add(CuDNNLSTM(512, return_sequences=True)) model.add(Dropout(0.3)) model.add(CuDNNLSTM(512)) model.add(Dense(256)) model.add(Dropout(0.3)) model.add(Dense(n_vocab)) model.add(Activation('softmax')) model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=["accuracy"]) ''' model = Sequential() model.add(CuDNNLSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True)) model.add(Dropout(0.2)) model.add(BatchNormalization()) model.add(CuDNNLSTM(256)) model.add(Dropout(0.2)) model.add(BatchNormalization()) model.add(Dense(128, activation="relu")) model.add(Dropout(0.2)) model.add(BatchNormalization()) model.add(Dense(n_vocab)) model.add(Activation('softmax')) model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=["accuracy"]) return model # train the neural network def train(model, network_input, network_output): # saver = CustomSaver() # history = model.fit(network_input, network_output, epochs=modelepochs, batch_size=50, callbacks=[tensorboard]) history = model.fit(network_input, network_output, epochs=modelepochs, batch_size=50, callbacks=[CustomSaver()]) # evaluate the model print("\nModel evaluation at the end of training") train_acc = model.evaluate(network_input, network_output, verbose=0) print(model.metrics_names) print(train_acc) # save trained model model.save(modeldirectory + modelfileprefix + '_' + str(modelepochs) + '.model') # delete temp notes file os.remove(notesfile) if __name__ == '__main__': train_network()</span></span></code> </pre> </div></div><br>  E aqui est√° o script da gera√ß√£o midi <code>lstm_music_predict.py</code> : <br><br><div class="spoiler">  <b class="spoiler_title">lstm_music_predict.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># based on code from https://github.com/Skuldur/Classical-Piano-Composer # to use this script pass in; # 1. path to notes file # 2. path to model # 3. path to midi output # eg python -W ignore "C:\\LSTM Composer\\lstm_music_predict.py" "C:\\LSTM Composer\\Bach.notes" "C:\\LSTM Composer\\Bach.model" "C:\\LSTM Composer\\Bach.mid" # ignore all info and warning messages import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' import tensorflow as tf tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) import pickle import numpy import sys import keras.models from music21 import instrument, note, stream, chord from keras.models import Sequential from keras.layers import Dense from keras.layers import Dropout from keras.layers import Activation # name of weights filename notesfile = str(sys.argv[1]) modelfile = str(sys.argv[2]) midifile = str(sys.argv[3]) # generates a piano midi file def generate(): sys.stdout.write("Loading notes data file...\n\n") sys.stdout.flush() #load the notes used to train the model with open(notesfile, 'rb') as filepath: notes = pickle.load(filepath) sys.stdout.write("Getting pitch names...\n\n") sys.stdout.flush() # Get all pitch names pitchnames = sorted(set(item for item in notes)) # Get all pitch names n_vocab = len(set(notes)) sys.stdout.write("Preparing sequences...\n\n") sys.stdout.flush() network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab) sys.stdout.write("Loading LSTM neural network model...\n\n") sys.stdout.flush() model = create_network(normalized_input, n_vocab) sys.stdout.write("Generating note sequence...\n\n") sys.stdout.flush() prediction_output = generate_notes(model, network_input, pitchnames, n_vocab) sys.stdout.write("\nCreating MIDI file...\n\n") sys.stdout.flush() create_midi(prediction_output) # prepare the sequences used by the neural network def prepare_sequences(notes, pitchnames, n_vocab): # map between notes and integers and back note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) sequence_length = 100 network_input = [] output = [] for i in range(0, len(notes) - sequence_length, 1): sequence_in = notes[i:i + sequence_length] sequence_out = notes[i + sequence_length] network_input.append([note_to_int[char] for char in sequence_in]) output.append(note_to_int[sequence_out]) n_patterns = len(network_input) # reshape the input into a format compatible with LSTM layers normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1)) # normalize input normalized_input = normalized_input / float(n_vocab) return (network_input, normalized_input) # create the structure of the neural network def create_network(network_input, n_vocab): model = keras.models.load_model(modelfile) return model # generate notes from the neural network based on a sequence of notes def generate_notes(model, network_input, pitchnames, n_vocab): # pick a random sequence from the input as a starting point for the prediction start = numpy.random.randint(0, len(network_input)-1) int_to_note = dict((number, note) for number, note in enumerate(pitchnames)) pattern = network_input[start] prediction_output = [] # generate 500 notes for note_index in range(500): prediction_input = numpy.reshape(pattern, (1, len(pattern), 1)) prediction_input = prediction_input / float(n_vocab) prediction = model.predict(prediction_input, verbose=0) index = numpy.argmax(prediction) result = int_to_note[index] prediction_output.append(result) pattern.append(index) pattern = pattern[1:len(pattern)] if (note_index + 1) % 50 == 0: sys.stdout.write("{} out of 500 notes generated\n".format(note_index+1)) sys.stdout.flush() return prediction_output # convert the output from the prediction to notes and create a midi file from the notes def create_midi(prediction_output): offset = 0 output_notes = [] # create note and chord objects based on the values generated by the model for pattern in prediction_output: # pattern is a chord if ('.' in pattern) or pattern.isdigit(): notes_in_chord = pattern.split('.') notes = [] for current_note in notes_in_chord: new_note = note.Note(int(current_note)) new_note.storedInstrument = instrument.Piano() notes.append(new_note) new_chord = chord.Chord(notes) new_chord.offset = offset output_notes.append(new_chord) # pattern is a note else: new_note = note.Note(pattern) new_note.offset = offset new_note.storedInstrument = instrument.Piano() output_notes.append(new_note) # increase offset each iteration so that notes do not stack offset += 0.5 midi_stream = stream.Stream(output_notes) midi_stream.write('midi', fp=midifile) if __name__ == '__main__': generate()</span></span></code> </pre> </div></div><br><h2>  Tamanhos de arquivo de modelo </h2><br>  A desvantagem de incluir redes neurais no Visions of Chaos √© o tamanho dos arquivos.  Se a gera√ß√£o do modelo fosse mais r√°pida, basta adicionar um bot√£o para que o usu√°rio final possa treinar os modelos.  Mas como algumas das sess√µes de treinamento de muitos modelos podem levar v√°rios dias, isso n√£o √© particularmente pr√°tico.  Pareceu-me que √© melhor fazer todo o treinamento e testar voc√™ mesmo e adicionar apenas os melhores modelos de trabalho.  Isso tamb√©m significa que o usu√°rio final s√≥ precisa pressionar um bot√£o, e modelos treinados criar√£o composi√ß√µes musicais. <br><br>  Cada um dos modelos tem um tamanho de 22 megabytes.  Nas condi√ß√µes da Internet moderna, isso n√£o √© muito, mas ao longo dos anos de desenvolvimento, Visions of Chaos vem aumentando de tamanho gradualmente, e apenas recentemente aumentou repentinamente de 70 para 91 MB (devido ao modelo de busca por aut√¥matos celulares).  Portanto, at√© agora, adicionei apenas um modelo ao instalador principal do Visions of Chaos.  Para usu√°rios que desejam mais, publiquei um link para outros 1 GB de modelos.  Eles tamb√©m podem usar o script acima para criar seus pr√≥prios modelos com base em seus arquivos midi. <br><br><h2>  O que vem a seguir? </h2><br>  Nesse est√°gio, o compositor LSTM √© o exemplo mais simples de uso de redes neurais para compor m√∫sica. <br><br>  Eu j√° encontrei outros compositores de m√∫sica em redes neurais com as quais experimentarei no futuro, ent√£o voc√™ pode esperar que em Visions of Chaos existam novas possibilidades para compor m√∫sicas automaticamente. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt470127/">https://habr.com/ru/post/pt470127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt470115/index.html">O seu navegador m√≥vel dificulta a condu√ß√£o</a></li>
<li><a href="../pt470117/index.html">Preparando-se para combinar</a></li>
<li><a href="../pt470121/index.html">Escolas de programa√ß√£o da empresa ou como ingressar em TI</a></li>
<li><a href="../pt470123/index.html">Armadilha financeira Yandex.Money</a></li>
<li><a href="../pt470125/index.html">N√£o julgue estritamente o c√≥digo de outra pessoa</a></li>
<li><a href="../pt470129/index.html">Gerenciamento de mem√≥ria declarativa</a></li>
<li><a href="../pt470133/index.html">Como coletar m√©tricas n√£o distorcidas por refer√™ncia de tempo com o Prometheus</a></li>
<li><a href="../pt470135/index.html">Uma aplica√ß√£o web interativa sem programa√ß√£o? F√°cil! Mavo nos seus bra√ßos</a></li>
<li><a href="../pt470139/index.html">2 hacks de vida: alternativas √† pesquisa cl√°ssica no Microsoft SQL Server</a></li>
<li><a href="../pt470145/index.html">‚ÄúCuidado, FAS!‚Äù: Por que o ingresso militar √© perigoso na publicidade, por que √© importante saber matem√°tica e se a verdade pura √© sempre necess√°ria</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
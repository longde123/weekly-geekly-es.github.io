<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßöüèº üë©üèΩ‚Äçüè´ üë©üèº‚Äçü§ù‚Äçüë®üèø Erstellen einer Android-Anwendung zur Texterkennung in 10 Minuten. Mobile Vision CodeLab üëßüèø üë®‚ÄçüöÄ ‚úäüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Videoversion des Tutorials 
 
 

 Die optische Zeichenerkennung ( OCR ) bietet dem Computer die M√∂glichkeit, Text in einem Bild zu lesen, sodass Anwen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstellen einer Android-Anwendung zur Texterkennung in 10 Minuten. Mobile Vision CodeLab</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/412679/"><h2>  Videoversion des Tutorials </h2><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/mIEfqtn9nts" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<p> <em>Die optische Zeichenerkennung</em> ( <strong>OCR</strong> ) bietet dem Computer die M√∂glichkeit, Text in einem Bild zu lesen, sodass Anwendungen Zeichen, Artikel, Flyer, Textseiten, Men√ºs oder alles in Form von Text verstehen k√∂nnen.  <code>Mobile Vision Text API</code> bietet <code>Android</code> Entwicklern eine leistungsstarke und zuverl√§ssige <code>OCR</code> Funktion, die die meisten <code>Android</code> Ger√§te unterst√ºtzt und die Gr√∂√üe Ihrer Anwendung nicht erh√∂ht. </p><br><p>  In diesem Tutorial erstellen Sie eine Anwendung, in der der gesamte in den Frame fallende Text w√§hrend des Videoaufzeichnungsprozesses erkannt und abgespielt wird. <a name="habracut"></a></p><br><p>  Wir haben auch Artikel zu anderen Mobile Vision-Funktionen ver√∂ffentlicht: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erkennen von Objekten und menschlichen Emotionen</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesichtserkennung</a> ; </li></ul><br><p>  Der Quellcode kann hier heruntergeladen <a href="">werden</a> . </p><br><p>  Oder klonen Sie das <code>GitHub</code> Repository √ºber die Befehlszeile: </p><br><pre> <code class="bash hljs">$ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/googlesamples/android-vision.git</code> </pre> <br><p>  Das <code>visionSamples</code> Repository enth√§lt viele Beispielprojekte im Zusammenhang mit <code>Mobile Vision</code> .  In dieser Lektion werden nur zwei verwendet: </p><br><ul><li> <strong><img src="https://habrastorage.org/getpro/habr/post_images/1e8/d51/ef8/1e8d51ef802bcde6a7d36bf83490b24d.png" width="22" height="22"></strong>  <strong>ocr-codelab / ocr-reader-start</strong> ist der urspr√ºngliche Code, den Sie in dieser Lektion verwenden werden. </li><li> <strong><img src="https://habrastorage.org/getpro/habr/post_images/1e8/d51/ef8/1e8d51ef802bcde6a7d36bf83490b24d.png" width="22" height="22"></strong>  <strong>ocr-codelab / ocr-reader-complete</strong> - der vollst√§ndige Code f√ºr die fertige Anwendung.  Sie k√∂nnen damit Fehler beheben oder direkt zur Arbeitsanwendung wechseln. </li></ul><br><h2>  Google Play Services-Update </h2><br><p>  M√∂glicherweise m√ºssen Sie Ihre installierte Version von <code>Google Repository</code> aktualisieren, um die <code>Mobile Vision Text API</code> . </p><br><p>  √ñffnen Sie <code>Android Studio</code> und √∂ffnen Sie den <code>SDK Manager</code> : </p><br><img src="https://habrastorage.org/getpro/habr/post_images/c09/c24/18f/c09c2418f842d747bb135a7d868c4931.png" width="240" height="117"><br><p><br>  Stellen Sie sicher, dass das <code>Google Repository</code> neuesten Stand ist.  Es muss mindestens Version <code>26</code> . </p><br><img src="https://habrastorage.org/getpro/habr/post_images/55f/a3f/0ee/55fa3f0ee048bc97f5b14b9fff7734ea.png" width="750" height="502"><br><p></p><br><h2>  F√ºgen Sie eine Google Play Services-Abh√§ngigkeit hinzu und erstellen Sie eine Launcher-App </h2><br><p>  Jetzt k√∂nnen Sie das Starterprojekt √∂ffnen: </p><br><ol><li><p>  W√§hlen Sie ein Startverzeichnis <strong><img src="https://habrastorage.org/getpro/habr/post_images/1e8/d51/ef8/1e8d51ef802bcde6a7d36bf83490b24d.png" width="22" height="22"></strong>  <code>ocr-reader</code> aus dem heruntergeladenen Code ( <strong>Datei</strong> &gt; <strong>√ñffnen</strong> &gt; <code>ocr-codelab/ocr-reader-start</code> ). </p><br></li><li><p>  F√ºgen Sie der Anwendung die Abh√§ngigkeit von <code>Google Play Services</code> .  Ohne diese Abh√§ngigkeit ist die <code>Text API</code> nicht verf√ºgbar. </p><br></li></ol><br><p>  Das Projekt zeigt m√∂glicherweise das Fehlen der <strong>Datei integer / google_play_services_version an</strong> und gibt einen Fehler aus.  Dies ist normal, wir werden es im n√§chsten Schritt beheben. </p><br><p>  √ñffnen Sie die Datei <code>build.gradle</code> im <code>app</code> Modul und √§ndern Sie den Abh√§ngigkeitsblock so, dass dort die Abh√§ngigkeit von <code>play-services-vision</code> ist.  Wenn alles fertig ist, sollte die Datei folgenderma√üen aussehen: </p><br><pre> <code class="hljs nginx"><span class="hljs-section"><span class="hljs-section">dependencies</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">implementation</span></span> fileTree(dir: <span class="hljs-string"><span class="hljs-string">'libs'</span></span>, include: [<span class="hljs-string"><span class="hljs-string">'*.jar'</span></span>]) implementation <span class="hljs-string"><span class="hljs-string">'com.android.support:support-v4:26.1.0'</span></span> implementation <span class="hljs-string"><span class="hljs-string">'com.android.support:design:26.1.0'</span></span> implementation <span class="hljs-string"><span class="hljs-string">'com.google.android.gms:play-services-vision:15.0.0'</span></span> }</code> </pre> <br><ol><li><p>  Klicken Sie auf <img src="https://habrastorage.org/getpro/habr/post_images/f7d/f74/7c5/f7df747c534410a9c0391d47de0bb0e3.png" width="21" height="21">  <code>Gradle</code> Synchronisierungstaste. </p><br></li><li><p>  Klicken Sie auf <img src="https://habrastorage.org/getpro/habr/post_images/82f/7df/0d1/82f7df0d1dce3d570e7c35d7d8fb4575.png" width="22" height="23">  Startknopf. </p><br></li></ol><br><p>  Nach einigen Sekunden wird der Bildschirm "Text lesen" angezeigt, dies ist jedoch nur ein schwarzer Bildschirm. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/c41/e98/6dc/c41e986dc883fb67fe0caf0760e99378.png" width="349" height="621"><br><p><br>  Im <code>CameraSource</code> passiert nichts, da <code>CameraSource</code> nicht konfiguriert ist.  Lass es uns tun. </p><br><p>  Wenn Sie keinen Erfolg haben, k√∂nnen Sie ein Projekt √∂ffnen <strong><img src="https://habrastorage.org/getpro/habr/post_images/1e8/d51/ef8/1e8d51ef802bcde6a7d36bf83490b24d.png" width="22" height="22"></strong>  <code>ocr-reader-complete</code> und stellen Sie sicher, dass es richtig funktioniert.  Dieses Projekt ist eine vorgefertigte Version der Lektion. Wenn diese Version nicht funktioniert, sollten Sie √ºberpr√ºfen, ob mit Ihren Ger√§te- und <code>Android Studio</code> Einstellungen alles in Ordnung ist. </p><br><h2>  Konfigurieren Sie TextRecognizer und CameraSource </h2><br><p>  <code>TextRecognizer</code> erstellen wir unseren <code>TextRecognizer</code> .  Dieses Detektorobjekt verarbeitet die Bilder und bestimmt, welcher Text in ihnen erscheint.  Nach der Initialisierung kann <code>TextRecognizer</code> verwendet werden, um Text in allen Bildtypen zu erkennen.  Suchen Sie die Methode <code>createCameraSource</code> und erstellen Sie einen <code>TextRecognizer</code> : </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createCameraSource</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">boolean</span></span></span></span><span class="hljs-function"><span class="hljs-params"> autoFocus, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">boolean</span></span></span></span><span class="hljs-function"><span class="hljs-params"> useFlash)</span></span></span><span class="hljs-function"> </span></span>{ Context context = getApplicationContext(); <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Create the TextRecognizer TextRecognizer textRecognizer = new TextRecognizer.Builder(context).build(); // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Set the TextRecognizer's Processor. // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Check if the TextRecognizer is operational. // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Create the mCameraSource using the TextRecognizer. }</span></span></code> </pre> <br><p>  Jetzt ist <code>TextRecognizer</code> einsatzbereit.  M√∂glicherweise funktioniert es jedoch noch nicht.  Wenn das Ger√§t nicht √ºber gen√ºgend Speicher verf√ºgt oder <code>Google Play Services</code> keine <code>OCR</code> Abh√§ngigkeiten laden kann, funktioniert das <code>TextRecognizer</code> Objekt nicht.  Bevor wir es f√ºr die Texterkennung verwenden, m√ºssen wir √ºberpr√ºfen, ob es bereit ist.  Wir werden diese Pr√ºfung zu <code>createCameraSource</code> hinzuf√ºgen, nachdem wir den <code>createCameraSource</code> initialisiert haben: </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Check if the TextRecognizer is operational. if (!textRecognizer.isOperational()) { Log.w(TAG, "Detector dependencies are not yet available."); // Check for low storage. If there is low storage, the native library will not be // downloaded, so detection will not become operational. IntentFilter lowstorageFilter = new IntentFilter(Intent.ACTION_DEVICE_STORAGE_LOW); boolean hasLowStorage = registerReceiver(null, lowstorageFilter) != null; if (hasLowStorage) { Toast.makeText(this, R.string.low_storage_error, Toast.LENGTH_LONG).show(); Log.w(TAG, getString(R.string.low_storage_error)); } }</span></span></code> </pre> <br><p>  Nachdem wir √ºberpr√ºft haben, dass <code>TextRecognizer</code> einsatzbereit ist, k√∂nnen wir damit einzelne Frames erkennen.  Aber wir wollen etwas Interessanteres tun: Lesen Sie den Text im Videomodus.  Zu diesem <code>CameraSource</code> erstellen wir eine <code>CameraSource</code> , die f√ºr die Steuerung der Kamera <code>CameraSource</code> ist.  Wir m√ºssen eine hohe Aufl√∂sung f√ºr die Aufnahme einstellen und den Autofokus aktivieren, um die Aufgabe der Erkennung von kleinem Text zu bew√§ltigen.  Wenn Sie sicher sind, dass Ihre Benutzer gro√üe Textbl√∂cke, z. B. Zeichen, betrachten, k√∂nnen Sie eine niedrigere Aufl√∂sung verwenden, und die Bildverarbeitung wird schneller: </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Create the cameraSource using the TextRecognizer. cameraSource = new CameraSource.Builder(getApplicationContext(), textRecognizer) .setFacing(CameraSource.CAMERA_FACING_BACK) .setRequestedPreviewSize(1280, 1024) .setRequestedFps(15.0f) .setFlashMode(useFlash ? Camera.Parameters.FLASH_MODE_TORCH : null) .setFocusMode(autoFocus ? Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO : null) .build();</span></span></code> </pre> <br><p>  So sollte die <code>createCameraSource</code> Methode aussehen, wenn Sie fertig sind: </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createCameraSource</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">boolean</span></span></span></span><span class="hljs-function"><span class="hljs-params"> autoFocus, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">boolean</span></span></span></span><span class="hljs-function"><span class="hljs-params"> useFlash)</span></span></span><span class="hljs-function"> </span></span>{ Context context = getApplicationContext(); <span class="hljs-comment"><span class="hljs-comment">// Create the TextRecognizer TextRecognizer textRecognizer = new TextRecognizer.Builder(context).build(); // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Set the TextRecognizer's Processor. // Check if the TextRecognizer is operational. if (!textRecognizer.isOperational()) { Log.w(TAG, "Detector dependencies are not yet available."); // Check for low storage. If there is low storage, the native library will not be // downloaded, so detection will not become operational. IntentFilter lowstorageFilter = new IntentFilter(Intent.ACTION_DEVICE_STORAGE_LOW); boolean hasLowStorage = registerReceiver(null, lowstorageFilter) != null; if (hasLowStorage) { Toast.makeText(this, R.string.low_storage_error, Toast.LENGTH_LONG).show(); Log.w(TAG, getString(R.string.low_storage_error)); } } // Create the cameraSource using the TextRecognizer. cameraSource = new CameraSource.Builder(getApplicationContext(), textRecognizer) .setFacing(CameraSource.CAMERA_FACING_BACK) .setRequestedPreviewSize(1280, 1024) .setRequestedFps(15.0f) .setFlashMode(useFlash ? Camera.Parameters.FLASH_MODE_TORCH : null) .setFocusMode(autoFocus ? Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO : null) .build(); }</span></span></code> </pre> <br><p>  Wenn Sie die Anwendung ausf√ºhren, werden Sie sehen, dass das Video gestartet wurde!  <code>createCameraSource</code> Bilder von der Kamera zu verarbeiten, m√ºssen wir dieses letzte <code>TODO</code> zu <code>createCameraSource</code> : Erstellen Sie einen <code>Processor</code> , um den <code>createCameraSource</code> Text zu verarbeiten. </p><br><h2>  OcrDetectorProcessor erstellen </h2><br><p>  Ihre Anwendung kann jetzt Text in einzelnen Frames mithilfe der Erkennungsmethode in <code>TextRecognizer</code> .  So finden Sie beispielsweise Text auf einem Foto.  Um den Text jedoch direkt w√§hrend der Videoaufnahme lesen zu k√∂nnen, m√ºssen Sie einen <code>Processor</code> implementieren, der den Text verarbeitet, sobald er auf dem Bildschirm angezeigt wird. </p><br><p>  <code>OcrDetectorProcessor</code> Sie zur <code>OcrDetectorProcessor</code> Klasse <code>OcrDetectorProcessor</code> implementieren Sie die <code>Detector.Processor</code> Schnittstelle: </p><br><p>  <em>OcrDetectorProcessor.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">OcrDetectorProcessor</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Detector</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Processor</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TextBlock</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> GraphicOverlay&lt;OcrGraphic&gt; graphicOverlay; OcrDetectorProcessor(GraphicOverlay&lt;OcrGraphic&gt; ocrGraphicOverlay) { graphicOverlay = ocrGraphicOverlay; } }</code> </pre> <br><p>  Um diese Schnittstelle zu implementieren, m√ºssen Sie zwei Methoden √ºberschreiben.  Der erste, <code>receiveDetections</code> , empf√§ngt <code>TextBlocks</code> von <code>receiveDetections</code> , <code>TextBlocks</code> sie erkannt werden.  Die zweite <code>release</code> wird verwendet, um Ressourcen freizugeben, wenn ein <code>TextRecognizer</code> zerst√∂rt wird.  In diesem Fall m√ºssen wir nur die grafische <code>OcrGraphic</code> l√∂schen, wodurch alle <code>OcrGraphic</code> Objekte <code>OcrGraphic</code> werden. </p><br><p>  Wir werden <code>TextBlocks</code> und <code>OcrGraphic</code> Objekte f√ºr jeden vom Prozessor erkannten <code>TextBlocks</code> erstellen.  Wir implementieren die Logik ihrer Zeichnung im n√§chsten Schritt. </p><br><p>  <em>OcrDetectorProcessor.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">receiveDetections</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Detector.Detections&lt;TextBlock&gt; detections)</span></span></span><span class="hljs-function"> </span></span>{ graphicOverlay.clear(); SparseArray&lt;TextBlock&gt; items = detections.getDetectedItems(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; items.size(); ++i) { TextBlock item = items.valueAt(i); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (item != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> &amp;&amp; item.getValue() != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>) { Log.d(<span class="hljs-string"><span class="hljs-string">"Processor"</span></span>, <span class="hljs-string"><span class="hljs-string">"Text detected! "</span></span> + item.getValue()); OcrGraphic graphic = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> OcrGraphic(graphicOverlay, item); graphicOverlay.add(graphic); } } } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">release</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ graphicOverlay.clear(); }</code> </pre> <br><p>  <code>textRecognizer</code> der Prozessor bereit ist, m√ºssen wir <code>textRecognizer</code> f√ºr die Verwendung konfigurieren.  <code>createCameraSource</code> Sie zum letzten verbleibenden <code>TODO</code> in der Methode <code>OcrCaptureActivity</code> in <code>OcrCaptureActivity</code> : </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// Create the TextRecognizer TextRecognizer textRecognizer = new TextRecognizer.Builder(context).build(); // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Set the TextRecognizer's Processor. textRecognizer.setProcessor(new OcrDetectorProcessor(graphicOverlay));</span></span></code> </pre> <br><p>  F√ºhren Sie nun die Anwendung aus.  Wenn Sie zu diesem Zeitpunkt die Kamera √ºber Text bewegen, werden Debug-Meldungen "Text erkannt!" Angezeigt.  in <code>Android Monitor Logcat</code> !  Dies ist jedoch keine sehr visuelle Methode, um zu visualisieren, was <code>TextRecognizer</code> sieht, oder? </p><br><p>  Im n√§chsten Schritt werden wir diesen Text auf dem Bildschirm zeichnen. </p><br><h2>  Zeichnen von Text auf dem Bildschirm </h2><br><p>  Lassen Sie uns die <code>OcrGraphic</code> in <code>OcrGraphic</code> .  Wir m√ºssen verstehen, ob das Bild Text enth√§lt, die Koordinaten seiner R√§nder in Leinwandrahmen konvertieren und dann sowohl die R√§nder als auch den Text zeichnen. </p><br><p>  <em>OcrGraphic.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">draw</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Canvas canvas)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Draw the text onto the canvas. if (text == null) { return; } // Draws the bounding box around the TextBlock. RectF rect = new RectF(text.getBoundingBox()); rect = translateRect(rect); canvas.drawRect(rect, rectPaint); // Render the text at the bottom of the box. canvas.drawText(text.getValue(), rect.left, rect.bottom, textPaint); }</span></span></code> </pre> <br><p>  Starten Sie die Anwendung und testen Sie sie an diesem Beispieltext: </p><br><img src="https://habrastorage.org/getpro/habr/post_images/9f9/62d/41d/9f962d41d7ee963958a8bbc2f88b97ec.png" width="663" height="169"><br><p>  Sie sollten sehen, dass auf dem Bildschirm ein Rahmen mit Text angezeigt wird!  Mit <code>TEXT_COLOR</code> k√∂nnen Sie mit der Farbe des Textes <code>TEXT_COLOR</code> . </p><br><p>  Wie w√§re es damit? </p><br><img src="https://habrastorage.org/getpro/habr/post_images/8f2/09a/d7c/8f209ad7cd7ae77245abaa3250ea91d2.png" width="621" height="441"><br><p>  Der Rahmen um den Text sieht korrekt aus, aber der Text befindet sich am unteren Rand. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/8dc/0ef/ec1/8dc0efec1d11dadff02a2ca7aa83d752.png" width="351" height="622"><br><p><br>  Dies liegt daran, dass die Engine den gesamten Text, den sie im <code>TextBlock</code> als einen einzigen Satz <code>TextBlock</code> , selbst wenn ein Satz in mehrere Zeilen unterteilt ist.  Wenn Sie das gesamte Angebot erhalten m√∂chten, ist dies sehr praktisch.  Aber was ist, wenn Sie wissen m√∂chten, wo sich jede einzelne Textzeile befindet? </p><br><p>  Sie k√∂nnen <code>Lines</code> aus einem <code>TextBlock</code> <code>getComponents</code> , indem <code>getComponents</code> <code>TextBlock</code> aufrufen. <code>getComponents</code> dann jede Zeile sortieren, k√∂nnen Sie leicht die Position und den Text darin <code>getComponents</code> .  Auf diese Weise k√∂nnen Sie Text an der Stelle zeichnen, an der er wirklich angezeigt wird. </p><br><p>  <em>OcrGraphic.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">draw</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Canvas canvas)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Draw the text onto the canvas. if (text == null) { return; } // Draws the bounding box around the TextBlock. RectF rect = new RectF(text.getBoundingBox()); rect = translateRect(rect); canvas.drawRect(rect, rectPaint); // Break the text into multiple lines and draw each one according to its own bounding box. List&lt;? extends Text&gt; textComponents = text.getComponents(); for(Text currentText : textComponents) { float left = translateX(currentText.getBoundingBox().left); float bottom = translateY(currentText.getBoundingBox().bottom); canvas.drawText(currentText.getValue(), left, bottom, textPaint); } }</span></span></code> </pre> <br><p>  Versuchen Sie diesen Text noch einmal: </p><br><img src="https://habrastorage.org/getpro/habr/post_images/8f2/09a/d7c/8f209ad7cd7ae77245abaa3250ea91d2.png" width="655" height="465"><br><p>  Gro√üartig!  Sie k√∂nnen den gefundenen Text je nach Bedarf sogar in noch kleinere Komponenten aufteilen.  Sie k√∂nnen <code>getComponents</code> in jeder Zeile aufrufen und <code>Elements</code> (lateinische W√∂rter) <code>getComponents</code> .  Es ist m√∂glich, <code>textSize</code> so zu konfigurieren, dass der Text so viel Platz einnimmt wie der tats√§chliche Text auf dem Bildschirm. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/102/3e0/2d2/1023e02d2d8659ec0a4d51662241037e.png" width="349" height="620"><br><p></p><br><h2>  Spielen Sie Text ab, wenn Sie darauf klicken </h2><br><p>  Jetzt wird der Text von der Kamera in strukturierte Linien umgewandelt und diese Linien werden auf dem Bildschirm angezeigt.  Lass uns etwas anderes mit ihnen machen. </p><br><p>  Mithilfe der in <code>Android</code> <code>TextToSpeech API</code> und der <code>OcrGraphic</code> Methode in <code>OcrGraphic</code> k√∂nnen wir der Anwendung beibringen, laut zu sprechen, wenn Sie auf den Text klicken. </p><br><p>  Lassen Sie uns zun√§chst die Methode <code>OcrGraphic</code> in <code>OcrGraphic</code> .  Wir m√ºssen nur √ºberpr√ºfen, ob die <code>x</code> und <code>y</code> Koordinaten innerhalb der Grenzen des angezeigten Textes liegen. <br>  <em>OcrGraphic.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">boolean</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">contains</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> y)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Check if this graphic's text contains this point. if (text == null) { return false; } RectF rect = new RectF(text.getBoundingBox()); rect = translateRect(rect); return rect.contans(x, y); }</span></span></code> </pre> <br><p>  M√∂glicherweise stellen Sie fest, dass die <code>Draw</code> Methode viel gemeinsam hat!  In diesem Projekt sollten Sie in der Lage sein, den Code wiederzuverwenden, aber hier lassen wir alles so, wie es nur als Beispiel dient. </p><br><p>  <code>onTap</code> wir nun mit der <code>onTap</code> Methode in <code>OcrCaptureActivity</code> und verarbeiten den Klick auf den Text, falls sich an dieser Stelle einer befindet. </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">boolean</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onTap</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rawX, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rawY)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Speak the text when the user taps on screen. OcrGraphic graphic = graphicOverlay.getGraphicAtLocation(rawX, rawY); TextBlock text = null; if (graphic != null) { text = graphic.getTextBlock(); if (text != null &amp;&amp; text.getValue() != null) { Log.d(TAG, "text data is being spoken! " + text.getValue()); // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Speak the string. } else { Log.d(TAG, "text data is null"); } } else { Log.d(TAG,"no text detected"); } return text != null; }</span></span></code> </pre> <br><p>  Sie k√∂nnen die Anwendung ausf√ºhren und sicherstellen, dass das Klicken auf den Text tats√§chlich √ºber <code>Android Monitor Logcat</code> . </p><br><p>  Lassen Sie uns unsere App zum Reden bringen!  Gehen Sie zum Anfang der <code>Activity</code> und suchen Sie die <code>onCreate</code> Methode.  Beim Starten der Anwendung m√ºssen wir die <code>TextToSpeech</code> Engine f√ºr die zuk√ºnftige Verwendung initialisieren. </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onCreate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Bundle bundle)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// (Portions of this method omitted) // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Set up the Text To Speech engine. TextToSpeech.OnInitListener listener = new TextToSpeech.OnInitListener() { @Override public void onInit(final int status) { if (status == TextToSpeech.SUCCESS) { Log.d("TTS", "Text to speech engine started successfully."); tts.setLanguage(Locale.US); } else { Log.d("TTS", "Error starting the text to speech engine."); } } }; tts = new TextToSpeech(this.getApplicationContext(), listener); }</span></span></code> </pre> <br><p>  Trotz der Tatsache, dass wir <code>TextToSpeech</code> korrekt initialisiert <code>TextToSpeech</code> , m√ºssen Sie in der Regel immer noch allgemeine Fehler behandeln, z. B. wenn die Engine beim ersten Klicken auf den Text noch nicht bereit ist. </p><br><p>  <code>TextToSpeech</code> auch sprachabh√§ngig.  Sie k√∂nnen die Sprache basierend auf der Sprache des erkannten Textes √§ndern.  Die Spracherkennung ist nicht in die <code>Mobile Vision Text API</code> , sie ist jedoch √ºber die <code>Google Translate API</code> verf√ºgbar.  Als Sprache zum Erkennen von Text k√∂nnen Sie die Sprache des Benutzerger√§ts verwenden. </p><br><p>  Alles, was √ºbrig bleibt, ist das Hinzuf√ºgen des <code>onTap</code> in der <code>onTap</code> Methode. </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">boolean</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onTap</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rawX, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rawY)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Speak the text when the user taps on screen. OcrGraphic graphic = graphicOverlay.getGraphicAtLocation(rawX, rawY); TextBlock text = null; if (graphic != null) { text = graphic.getTextBlock(); if (text != null &amp;&amp; text.getValue() != null) { Log.d(TAG, "text data is being spoken! " + text.getValue()); // Speak the string. tts.speak(text.getValue(), TextToSpeech.QUEUE_ADD, null, "DEFAULT"); } else { Log.d(TAG, "text data is null"); } } else { Log.d(TAG,"no text detected"); } return text != null; }</span></span></code> </pre> <br><p>  Wenn Sie nun die Anwendung starten und auf den erkannten Text klicken, wird er von Ihrem Ger√§t abgespielt.  Probieren Sie es aus! </p><br><h2>  Fertigstellung </h2><br><p>  Jetzt haben Sie eine Anwendung, die Text von der Kamera erkennen und laut aussprechen kann! </p><br><p>  Sie k√∂nnen das erworbene Wissen der Texterkennung in Ihren anderen Anwendungen anwenden.  Lesen Sie beispielsweise Adressen und Telefonnummern von Visitenkarten und durchsuchen Sie den Text anhand von Fotos verschiedener Dokumente.  Kurz gesagt, verwenden Sie <code>OCR</code> √ºberall dort, wo Sie Text in einem Bild erkennen m√ºssen. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de412679/">https://habr.com/ru/post/de412679/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de412667/index.html">Cybergroup Turla verwendet Metasploit in der Moskitokampagne</a></li>
<li><a href="../de412669/index.html">Zeitmanagement ist nicht be√§ngstigend: wie man mehr macht</a></li>
<li><a href="../de412671/index.html">BLE-Konsole: Eine v√∂llig neue Art der Interaktion mit BLE-Ger√§ten</a></li>
<li><a href="../de412675/index.html">Multisig-Vertr√§ge und -Adressen in Bitcoin und Ethereum</a></li>
<li><a href="../de412677/index.html">R√ºckverfolgbarkeitsmatrix</a></li>
<li><a href="../de412681/index.html">Bin√§re Berechnungen f√ºr die Dezimalarithmetik</a></li>
<li><a href="../de412683/index.html">Wo und wie lernt man maschinelles Lernen?</a></li>
<li><a href="../de412685/index.html">Unity GPU Path Tracing - Teil 2</a></li>
<li><a href="../de412687/index.html">Implementieren Sie IdM. Verfahren und technische Mittel - von Basic bis IdM</a></li>
<li><a href="../de412689/index.html">Predictive IT Analytics optimieren die verteilte Anwendungs√ºberwachung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
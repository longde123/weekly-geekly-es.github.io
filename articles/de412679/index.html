<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧚🏼 👩🏽‍🏫 👩🏼‍🤝‍👨🏿 Erstellen einer Android-Anwendung zur Texterkennung in 10 Minuten. Mobile Vision CodeLab 👧🏿 👨‍🚀 ✊🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Videoversion des Tutorials 
 
 

 Die optische Zeichenerkennung ( OCR ) bietet dem Computer die Möglichkeit, Text in einem Bild zu lesen, sodass Anwen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstellen einer Android-Anwendung zur Texterkennung in 10 Minuten. Mobile Vision CodeLab</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/412679/"><h2>  Videoversion des Tutorials </h2><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/mIEfqtn9nts" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<p> <em>Die optische Zeichenerkennung</em> ( <strong>OCR</strong> ) bietet dem Computer die Möglichkeit, Text in einem Bild zu lesen, sodass Anwendungen Zeichen, Artikel, Flyer, Textseiten, Menüs oder alles in Form von Text verstehen können.  <code>Mobile Vision Text API</code> bietet <code>Android</code> Entwicklern eine leistungsstarke und zuverlässige <code>OCR</code> Funktion, die die meisten <code>Android</code> Geräte unterstützt und die Größe Ihrer Anwendung nicht erhöht. </p><br><p>  In diesem Tutorial erstellen Sie eine Anwendung, in der der gesamte in den Frame fallende Text während des Videoaufzeichnungsprozesses erkannt und abgespielt wird. <a name="habracut"></a></p><br><p>  Wir haben auch Artikel zu anderen Mobile Vision-Funktionen veröffentlicht: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erkennen von Objekten und menschlichen Emotionen</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesichtserkennung</a> ; </li></ul><br><p>  Der Quellcode kann hier heruntergeladen <a href="">werden</a> . </p><br><p>  Oder klonen Sie das <code>GitHub</code> Repository über die Befehlszeile: </p><br><pre> <code class="bash hljs">$ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/googlesamples/android-vision.git</code> </pre> <br><p>  Das <code>visionSamples</code> Repository enthält viele Beispielprojekte im Zusammenhang mit <code>Mobile Vision</code> .  In dieser Lektion werden nur zwei verwendet: </p><br><ul><li> <strong><img src="https://habrastorage.org/getpro/habr/post_images/1e8/d51/ef8/1e8d51ef802bcde6a7d36bf83490b24d.png" width="22" height="22"></strong>  <strong>ocr-codelab / ocr-reader-start</strong> ist der ursprüngliche Code, den Sie in dieser Lektion verwenden werden. </li><li> <strong><img src="https://habrastorage.org/getpro/habr/post_images/1e8/d51/ef8/1e8d51ef802bcde6a7d36bf83490b24d.png" width="22" height="22"></strong>  <strong>ocr-codelab / ocr-reader-complete</strong> - der vollständige Code für die fertige Anwendung.  Sie können damit Fehler beheben oder direkt zur Arbeitsanwendung wechseln. </li></ul><br><h2>  Google Play Services-Update </h2><br><p>  Möglicherweise müssen Sie Ihre installierte Version von <code>Google Repository</code> aktualisieren, um die <code>Mobile Vision Text API</code> . </p><br><p>  Öffnen Sie <code>Android Studio</code> und öffnen Sie den <code>SDK Manager</code> : </p><br><img src="https://habrastorage.org/getpro/habr/post_images/c09/c24/18f/c09c2418f842d747bb135a7d868c4931.png" width="240" height="117"><br><p><br>  Stellen Sie sicher, dass das <code>Google Repository</code> neuesten Stand ist.  Es muss mindestens Version <code>26</code> . </p><br><img src="https://habrastorage.org/getpro/habr/post_images/55f/a3f/0ee/55fa3f0ee048bc97f5b14b9fff7734ea.png" width="750" height="502"><br><p></p><br><h2>  Fügen Sie eine Google Play Services-Abhängigkeit hinzu und erstellen Sie eine Launcher-App </h2><br><p>  Jetzt können Sie das Starterprojekt öffnen: </p><br><ol><li><p>  Wählen Sie ein Startverzeichnis <strong><img src="https://habrastorage.org/getpro/habr/post_images/1e8/d51/ef8/1e8d51ef802bcde6a7d36bf83490b24d.png" width="22" height="22"></strong>  <code>ocr-reader</code> aus dem heruntergeladenen Code ( <strong>Datei</strong> &gt; <strong>Öffnen</strong> &gt; <code>ocr-codelab/ocr-reader-start</code> ). </p><br></li><li><p>  Fügen Sie der Anwendung die Abhängigkeit von <code>Google Play Services</code> .  Ohne diese Abhängigkeit ist die <code>Text API</code> nicht verfügbar. </p><br></li></ol><br><p>  Das Projekt zeigt möglicherweise das Fehlen der <strong>Datei integer / google_play_services_version an</strong> und gibt einen Fehler aus.  Dies ist normal, wir werden es im nächsten Schritt beheben. </p><br><p>  Öffnen Sie die Datei <code>build.gradle</code> im <code>app</code> Modul und ändern Sie den Abhängigkeitsblock so, dass dort die Abhängigkeit von <code>play-services-vision</code> ist.  Wenn alles fertig ist, sollte die Datei folgendermaßen aussehen: </p><br><pre> <code class="hljs nginx"><span class="hljs-section"><span class="hljs-section">dependencies</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">implementation</span></span> fileTree(dir: <span class="hljs-string"><span class="hljs-string">'libs'</span></span>, include: [<span class="hljs-string"><span class="hljs-string">'*.jar'</span></span>]) implementation <span class="hljs-string"><span class="hljs-string">'com.android.support:support-v4:26.1.0'</span></span> implementation <span class="hljs-string"><span class="hljs-string">'com.android.support:design:26.1.0'</span></span> implementation <span class="hljs-string"><span class="hljs-string">'com.google.android.gms:play-services-vision:15.0.0'</span></span> }</code> </pre> <br><ol><li><p>  Klicken Sie auf <img src="https://habrastorage.org/getpro/habr/post_images/f7d/f74/7c5/f7df747c534410a9c0391d47de0bb0e3.png" width="21" height="21">  <code>Gradle</code> Synchronisierungstaste. </p><br></li><li><p>  Klicken Sie auf <img src="https://habrastorage.org/getpro/habr/post_images/82f/7df/0d1/82f7df0d1dce3d570e7c35d7d8fb4575.png" width="22" height="23">  Startknopf. </p><br></li></ol><br><p>  Nach einigen Sekunden wird der Bildschirm "Text lesen" angezeigt, dies ist jedoch nur ein schwarzer Bildschirm. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/c41/e98/6dc/c41e986dc883fb67fe0caf0760e99378.png" width="349" height="621"><br><p><br>  Im <code>CameraSource</code> passiert nichts, da <code>CameraSource</code> nicht konfiguriert ist.  Lass es uns tun. </p><br><p>  Wenn Sie keinen Erfolg haben, können Sie ein Projekt öffnen <strong><img src="https://habrastorage.org/getpro/habr/post_images/1e8/d51/ef8/1e8d51ef802bcde6a7d36bf83490b24d.png" width="22" height="22"></strong>  <code>ocr-reader-complete</code> und stellen Sie sicher, dass es richtig funktioniert.  Dieses Projekt ist eine vorgefertigte Version der Lektion. Wenn diese Version nicht funktioniert, sollten Sie überprüfen, ob mit Ihren Geräte- und <code>Android Studio</code> Einstellungen alles in Ordnung ist. </p><br><h2>  Konfigurieren Sie TextRecognizer und CameraSource </h2><br><p>  <code>TextRecognizer</code> erstellen wir unseren <code>TextRecognizer</code> .  Dieses Detektorobjekt verarbeitet die Bilder und bestimmt, welcher Text in ihnen erscheint.  Nach der Initialisierung kann <code>TextRecognizer</code> verwendet werden, um Text in allen Bildtypen zu erkennen.  Suchen Sie die Methode <code>createCameraSource</code> und erstellen Sie einen <code>TextRecognizer</code> : </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createCameraSource</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">boolean</span></span></span></span><span class="hljs-function"><span class="hljs-params"> autoFocus, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">boolean</span></span></span></span><span class="hljs-function"><span class="hljs-params"> useFlash)</span></span></span><span class="hljs-function"> </span></span>{ Context context = getApplicationContext(); <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Create the TextRecognizer TextRecognizer textRecognizer = new TextRecognizer.Builder(context).build(); // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Set the TextRecognizer's Processor. // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Check if the TextRecognizer is operational. // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Create the mCameraSource using the TextRecognizer. }</span></span></code> </pre> <br><p>  Jetzt ist <code>TextRecognizer</code> einsatzbereit.  Möglicherweise funktioniert es jedoch noch nicht.  Wenn das Gerät nicht über genügend Speicher verfügt oder <code>Google Play Services</code> keine <code>OCR</code> Abhängigkeiten laden kann, funktioniert das <code>TextRecognizer</code> Objekt nicht.  Bevor wir es für die Texterkennung verwenden, müssen wir überprüfen, ob es bereit ist.  Wir werden diese Prüfung zu <code>createCameraSource</code> hinzufügen, nachdem wir den <code>createCameraSource</code> initialisiert haben: </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Check if the TextRecognizer is operational. if (!textRecognizer.isOperational()) { Log.w(TAG, "Detector dependencies are not yet available."); // Check for low storage. If there is low storage, the native library will not be // downloaded, so detection will not become operational. IntentFilter lowstorageFilter = new IntentFilter(Intent.ACTION_DEVICE_STORAGE_LOW); boolean hasLowStorage = registerReceiver(null, lowstorageFilter) != null; if (hasLowStorage) { Toast.makeText(this, R.string.low_storage_error, Toast.LENGTH_LONG).show(); Log.w(TAG, getString(R.string.low_storage_error)); } }</span></span></code> </pre> <br><p>  Nachdem wir überprüft haben, dass <code>TextRecognizer</code> einsatzbereit ist, können wir damit einzelne Frames erkennen.  Aber wir wollen etwas Interessanteres tun: Lesen Sie den Text im Videomodus.  Zu diesem <code>CameraSource</code> erstellen wir eine <code>CameraSource</code> , die für die Steuerung der Kamera <code>CameraSource</code> ist.  Wir müssen eine hohe Auflösung für die Aufnahme einstellen und den Autofokus aktivieren, um die Aufgabe der Erkennung von kleinem Text zu bewältigen.  Wenn Sie sicher sind, dass Ihre Benutzer große Textblöcke, z. B. Zeichen, betrachten, können Sie eine niedrigere Auflösung verwenden, und die Bildverarbeitung wird schneller: </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Create the cameraSource using the TextRecognizer. cameraSource = new CameraSource.Builder(getApplicationContext(), textRecognizer) .setFacing(CameraSource.CAMERA_FACING_BACK) .setRequestedPreviewSize(1280, 1024) .setRequestedFps(15.0f) .setFlashMode(useFlash ? Camera.Parameters.FLASH_MODE_TORCH : null) .setFocusMode(autoFocus ? Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO : null) .build();</span></span></code> </pre> <br><p>  So sollte die <code>createCameraSource</code> Methode aussehen, wenn Sie fertig sind: </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createCameraSource</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">boolean</span></span></span></span><span class="hljs-function"><span class="hljs-params"> autoFocus, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">boolean</span></span></span></span><span class="hljs-function"><span class="hljs-params"> useFlash)</span></span></span><span class="hljs-function"> </span></span>{ Context context = getApplicationContext(); <span class="hljs-comment"><span class="hljs-comment">// Create the TextRecognizer TextRecognizer textRecognizer = new TextRecognizer.Builder(context).build(); // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Set the TextRecognizer's Processor. // Check if the TextRecognizer is operational. if (!textRecognizer.isOperational()) { Log.w(TAG, "Detector dependencies are not yet available."); // Check for low storage. If there is low storage, the native library will not be // downloaded, so detection will not become operational. IntentFilter lowstorageFilter = new IntentFilter(Intent.ACTION_DEVICE_STORAGE_LOW); boolean hasLowStorage = registerReceiver(null, lowstorageFilter) != null; if (hasLowStorage) { Toast.makeText(this, R.string.low_storage_error, Toast.LENGTH_LONG).show(); Log.w(TAG, getString(R.string.low_storage_error)); } } // Create the cameraSource using the TextRecognizer. cameraSource = new CameraSource.Builder(getApplicationContext(), textRecognizer) .setFacing(CameraSource.CAMERA_FACING_BACK) .setRequestedPreviewSize(1280, 1024) .setRequestedFps(15.0f) .setFlashMode(useFlash ? Camera.Parameters.FLASH_MODE_TORCH : null) .setFocusMode(autoFocus ? Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO : null) .build(); }</span></span></code> </pre> <br><p>  Wenn Sie die Anwendung ausführen, werden Sie sehen, dass das Video gestartet wurde!  <code>createCameraSource</code> Bilder von der Kamera zu verarbeiten, müssen wir dieses letzte <code>TODO</code> zu <code>createCameraSource</code> : Erstellen Sie einen <code>Processor</code> , um den <code>createCameraSource</code> Text zu verarbeiten. </p><br><h2>  OcrDetectorProcessor erstellen </h2><br><p>  Ihre Anwendung kann jetzt Text in einzelnen Frames mithilfe der Erkennungsmethode in <code>TextRecognizer</code> .  So finden Sie beispielsweise Text auf einem Foto.  Um den Text jedoch direkt während der Videoaufnahme lesen zu können, müssen Sie einen <code>Processor</code> implementieren, der den Text verarbeitet, sobald er auf dem Bildschirm angezeigt wird. </p><br><p>  <code>OcrDetectorProcessor</code> Sie zur <code>OcrDetectorProcessor</code> Klasse <code>OcrDetectorProcessor</code> implementieren Sie die <code>Detector.Processor</code> Schnittstelle: </p><br><p>  <em>OcrDetectorProcessor.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">OcrDetectorProcessor</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Detector</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Processor</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TextBlock</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> GraphicOverlay&lt;OcrGraphic&gt; graphicOverlay; OcrDetectorProcessor(GraphicOverlay&lt;OcrGraphic&gt; ocrGraphicOverlay) { graphicOverlay = ocrGraphicOverlay; } }</code> </pre> <br><p>  Um diese Schnittstelle zu implementieren, müssen Sie zwei Methoden überschreiben.  Der erste, <code>receiveDetections</code> , empfängt <code>TextBlocks</code> von <code>receiveDetections</code> , <code>TextBlocks</code> sie erkannt werden.  Die zweite <code>release</code> wird verwendet, um Ressourcen freizugeben, wenn ein <code>TextRecognizer</code> zerstört wird.  In diesem Fall müssen wir nur die grafische <code>OcrGraphic</code> löschen, wodurch alle <code>OcrGraphic</code> Objekte <code>OcrGraphic</code> werden. </p><br><p>  Wir werden <code>TextBlocks</code> und <code>OcrGraphic</code> Objekte für jeden vom Prozessor erkannten <code>TextBlocks</code> erstellen.  Wir implementieren die Logik ihrer Zeichnung im nächsten Schritt. </p><br><p>  <em>OcrDetectorProcessor.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">receiveDetections</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Detector.Detections&lt;TextBlock&gt; detections)</span></span></span><span class="hljs-function"> </span></span>{ graphicOverlay.clear(); SparseArray&lt;TextBlock&gt; items = detections.getDetectedItems(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; items.size(); ++i) { TextBlock item = items.valueAt(i); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (item != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> &amp;&amp; item.getValue() != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>) { Log.d(<span class="hljs-string"><span class="hljs-string">"Processor"</span></span>, <span class="hljs-string"><span class="hljs-string">"Text detected! "</span></span> + item.getValue()); OcrGraphic graphic = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> OcrGraphic(graphicOverlay, item); graphicOverlay.add(graphic); } } } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">release</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ graphicOverlay.clear(); }</code> </pre> <br><p>  <code>textRecognizer</code> der Prozessor bereit ist, müssen wir <code>textRecognizer</code> für die Verwendung konfigurieren.  <code>createCameraSource</code> Sie zum letzten verbleibenden <code>TODO</code> in der Methode <code>OcrCaptureActivity</code> in <code>OcrCaptureActivity</code> : </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// Create the TextRecognizer TextRecognizer textRecognizer = new TextRecognizer.Builder(context).build(); // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Set the TextRecognizer's Processor. textRecognizer.setProcessor(new OcrDetectorProcessor(graphicOverlay));</span></span></code> </pre> <br><p>  Führen Sie nun die Anwendung aus.  Wenn Sie zu diesem Zeitpunkt die Kamera über Text bewegen, werden Debug-Meldungen "Text erkannt!" Angezeigt.  in <code>Android Monitor Logcat</code> !  Dies ist jedoch keine sehr visuelle Methode, um zu visualisieren, was <code>TextRecognizer</code> sieht, oder? </p><br><p>  Im nächsten Schritt werden wir diesen Text auf dem Bildschirm zeichnen. </p><br><h2>  Zeichnen von Text auf dem Bildschirm </h2><br><p>  Lassen Sie uns die <code>OcrGraphic</code> in <code>OcrGraphic</code> .  Wir müssen verstehen, ob das Bild Text enthält, die Koordinaten seiner Ränder in Leinwandrahmen konvertieren und dann sowohl die Ränder als auch den Text zeichnen. </p><br><p>  <em>OcrGraphic.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">draw</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Canvas canvas)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Draw the text onto the canvas. if (text == null) { return; } // Draws the bounding box around the TextBlock. RectF rect = new RectF(text.getBoundingBox()); rect = translateRect(rect); canvas.drawRect(rect, rectPaint); // Render the text at the bottom of the box. canvas.drawText(text.getValue(), rect.left, rect.bottom, textPaint); }</span></span></code> </pre> <br><p>  Starten Sie die Anwendung und testen Sie sie an diesem Beispieltext: </p><br><img src="https://habrastorage.org/getpro/habr/post_images/9f9/62d/41d/9f962d41d7ee963958a8bbc2f88b97ec.png" width="663" height="169"><br><p>  Sie sollten sehen, dass auf dem Bildschirm ein Rahmen mit Text angezeigt wird!  Mit <code>TEXT_COLOR</code> können Sie mit der Farbe des Textes <code>TEXT_COLOR</code> . </p><br><p>  Wie wäre es damit? </p><br><img src="https://habrastorage.org/getpro/habr/post_images/8f2/09a/d7c/8f209ad7cd7ae77245abaa3250ea91d2.png" width="621" height="441"><br><p>  Der Rahmen um den Text sieht korrekt aus, aber der Text befindet sich am unteren Rand. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/8dc/0ef/ec1/8dc0efec1d11dadff02a2ca7aa83d752.png" width="351" height="622"><br><p><br>  Dies liegt daran, dass die Engine den gesamten Text, den sie im <code>TextBlock</code> als einen einzigen Satz <code>TextBlock</code> , selbst wenn ein Satz in mehrere Zeilen unterteilt ist.  Wenn Sie das gesamte Angebot erhalten möchten, ist dies sehr praktisch.  Aber was ist, wenn Sie wissen möchten, wo sich jede einzelne Textzeile befindet? </p><br><p>  Sie können <code>Lines</code> aus einem <code>TextBlock</code> <code>getComponents</code> , indem <code>getComponents</code> <code>TextBlock</code> aufrufen. <code>getComponents</code> dann jede Zeile sortieren, können Sie leicht die Position und den Text darin <code>getComponents</code> .  Auf diese Weise können Sie Text an der Stelle zeichnen, an der er wirklich angezeigt wird. </p><br><p>  <em>OcrGraphic.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">draw</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Canvas canvas)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Draw the text onto the canvas. if (text == null) { return; } // Draws the bounding box around the TextBlock. RectF rect = new RectF(text.getBoundingBox()); rect = translateRect(rect); canvas.drawRect(rect, rectPaint); // Break the text into multiple lines and draw each one according to its own bounding box. List&lt;? extends Text&gt; textComponents = text.getComponents(); for(Text currentText : textComponents) { float left = translateX(currentText.getBoundingBox().left); float bottom = translateY(currentText.getBoundingBox().bottom); canvas.drawText(currentText.getValue(), left, bottom, textPaint); } }</span></span></code> </pre> <br><p>  Versuchen Sie diesen Text noch einmal: </p><br><img src="https://habrastorage.org/getpro/habr/post_images/8f2/09a/d7c/8f209ad7cd7ae77245abaa3250ea91d2.png" width="655" height="465"><br><p>  Großartig!  Sie können den gefundenen Text je nach Bedarf sogar in noch kleinere Komponenten aufteilen.  Sie können <code>getComponents</code> in jeder Zeile aufrufen und <code>Elements</code> (lateinische Wörter) <code>getComponents</code> .  Es ist möglich, <code>textSize</code> so zu konfigurieren, dass der Text so viel Platz einnimmt wie der tatsächliche Text auf dem Bildschirm. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/102/3e0/2d2/1023e02d2d8659ec0a4d51662241037e.png" width="349" height="620"><br><p></p><br><h2>  Spielen Sie Text ab, wenn Sie darauf klicken </h2><br><p>  Jetzt wird der Text von der Kamera in strukturierte Linien umgewandelt und diese Linien werden auf dem Bildschirm angezeigt.  Lass uns etwas anderes mit ihnen machen. </p><br><p>  Mithilfe der in <code>Android</code> <code>TextToSpeech API</code> und der <code>OcrGraphic</code> Methode in <code>OcrGraphic</code> können wir der Anwendung beibringen, laut zu sprechen, wenn Sie auf den Text klicken. </p><br><p>  Lassen Sie uns zunächst die Methode <code>OcrGraphic</code> in <code>OcrGraphic</code> .  Wir müssen nur überprüfen, ob die <code>x</code> und <code>y</code> Koordinaten innerhalb der Grenzen des angezeigten Textes liegen. <br>  <em>OcrGraphic.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">boolean</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">contains</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> y)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Check if this graphic's text contains this point. if (text == null) { return false; } RectF rect = new RectF(text.getBoundingBox()); rect = translateRect(rect); return rect.contans(x, y); }</span></span></code> </pre> <br><p>  Möglicherweise stellen Sie fest, dass die <code>Draw</code> Methode viel gemeinsam hat!  In diesem Projekt sollten Sie in der Lage sein, den Code wiederzuverwenden, aber hier lassen wir alles so, wie es nur als Beispiel dient. </p><br><p>  <code>onTap</code> wir nun mit der <code>onTap</code> Methode in <code>OcrCaptureActivity</code> und verarbeiten den Klick auf den Text, falls sich an dieser Stelle einer befindet. </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">boolean</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onTap</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rawX, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rawY)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Speak the text when the user taps on screen. OcrGraphic graphic = graphicOverlay.getGraphicAtLocation(rawX, rawY); TextBlock text = null; if (graphic != null) { text = graphic.getTextBlock(); if (text != null &amp;&amp; text.getValue() != null) { Log.d(TAG, "text data is being spoken! " + text.getValue()); // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Speak the string. } else { Log.d(TAG, "text data is null"); } } else { Log.d(TAG,"no text detected"); } return text != null; }</span></span></code> </pre> <br><p>  Sie können die Anwendung ausführen und sicherstellen, dass das Klicken auf den Text tatsächlich über <code>Android Monitor Logcat</code> . </p><br><p>  Lassen Sie uns unsere App zum Reden bringen!  Gehen Sie zum Anfang der <code>Activity</code> und suchen Sie die <code>onCreate</code> Methode.  Beim Starten der Anwendung müssen wir die <code>TextToSpeech</code> Engine für die zukünftige Verwendung initialisieren. </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onCreate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Bundle bundle)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// (Portions of this method omitted) // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Set up the Text To Speech engine. TextToSpeech.OnInitListener listener = new TextToSpeech.OnInitListener() { @Override public void onInit(final int status) { if (status == TextToSpeech.SUCCESS) { Log.d("TTS", "Text to speech engine started successfully."); tts.setLanguage(Locale.US); } else { Log.d("TTS", "Error starting the text to speech engine."); } } }; tts = new TextToSpeech(this.getApplicationContext(), listener); }</span></span></code> </pre> <br><p>  Trotz der Tatsache, dass wir <code>TextToSpeech</code> korrekt initialisiert <code>TextToSpeech</code> , müssen Sie in der Regel immer noch allgemeine Fehler behandeln, z. B. wenn die Engine beim ersten Klicken auf den Text noch nicht bereit ist. </p><br><p>  <code>TextToSpeech</code> auch sprachabhängig.  Sie können die Sprache basierend auf der Sprache des erkannten Textes ändern.  Die Spracherkennung ist nicht in die <code>Mobile Vision Text API</code> , sie ist jedoch über die <code>Google Translate API</code> verfügbar.  Als Sprache zum Erkennen von Text können Sie die Sprache des Benutzergeräts verwenden. </p><br><p>  Alles, was übrig bleibt, ist das Hinzufügen des <code>onTap</code> in der <code>onTap</code> Methode. </p><br><p>  <em>OcrCaptureActivity.java</em> </p><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">boolean</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onTap</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rawX, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rawY)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> Speak the text when the user taps on screen. OcrGraphic graphic = graphicOverlay.getGraphicAtLocation(rawX, rawY); TextBlock text = null; if (graphic != null) { text = graphic.getTextBlock(); if (text != null &amp;&amp; text.getValue() != null) { Log.d(TAG, "text data is being spoken! " + text.getValue()); // Speak the string. tts.speak(text.getValue(), TextToSpeech.QUEUE_ADD, null, "DEFAULT"); } else { Log.d(TAG, "text data is null"); } } else { Log.d(TAG,"no text detected"); } return text != null; }</span></span></code> </pre> <br><p>  Wenn Sie nun die Anwendung starten und auf den erkannten Text klicken, wird er von Ihrem Gerät abgespielt.  Probieren Sie es aus! </p><br><h2>  Fertigstellung </h2><br><p>  Jetzt haben Sie eine Anwendung, die Text von der Kamera erkennen und laut aussprechen kann! </p><br><p>  Sie können das erworbene Wissen der Texterkennung in Ihren anderen Anwendungen anwenden.  Lesen Sie beispielsweise Adressen und Telefonnummern von Visitenkarten und durchsuchen Sie den Text anhand von Fotos verschiedener Dokumente.  Kurz gesagt, verwenden Sie <code>OCR</code> überall dort, wo Sie Text in einem Bild erkennen müssen. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de412679/">https://habr.com/ru/post/de412679/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de412667/index.html">Cybergroup Turla verwendet Metasploit in der Moskitokampagne</a></li>
<li><a href="../de412669/index.html">Zeitmanagement ist nicht beängstigend: wie man mehr macht</a></li>
<li><a href="../de412671/index.html">BLE-Konsole: Eine völlig neue Art der Interaktion mit BLE-Geräten</a></li>
<li><a href="../de412675/index.html">Multisig-Verträge und -Adressen in Bitcoin und Ethereum</a></li>
<li><a href="../de412677/index.html">Rückverfolgbarkeitsmatrix</a></li>
<li><a href="../de412681/index.html">Binäre Berechnungen für die Dezimalarithmetik</a></li>
<li><a href="../de412683/index.html">Wo und wie lernt man maschinelles Lernen?</a></li>
<li><a href="../de412685/index.html">Unity GPU Path Tracing - Teil 2</a></li>
<li><a href="../de412687/index.html">Implementieren Sie IdM. Verfahren und technische Mittel - von Basic bis IdM</a></li>
<li><a href="../de412689/index.html">Predictive IT Analytics optimieren die verteilte Anwendungsüberwachung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüíº üîä üë©üèø‚Äçüé® Am√©liorer la qualit√© de la classification des textes en connectant Wikipedia üßí üç± üòù</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous utilisons une grande source structur√©e de textes multilingues - Wikipedia pour am√©liorer la classification des textes. L'approche est bonne avec ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Am√©liorer la qualit√© de la classification des textes en connectant Wikipedia</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446228/"> Nous utilisons une grande source structur√©e de textes multilingues - Wikipedia pour am√©liorer la classification des textes.  L'approche est bonne avec un degr√© √©lev√© d'automatisme et d'ind√©pendance √† partir duquel un probl√®me de classification particulier est r√©solu.  Le plus grand effet, cependant, est attendu sur les t√¢ches de d√©termination du sujet. <br><a name="habracut"></a><br>  L'id√©e principale est d'extraire de Wikipedia uniquement les textes qui nous aident √† r√©soudre notre probl√®me de classification, en ignorant les autres.  Si nous classons des textes sur les chats, il est peu probable que nous ayons besoin de textes sur la physique quantique, bien que des textes sur d'autres types d'animaux puissent √™tre utiles.  La s√©paration automatique de ces textes les uns des autres est l'essence de l'approche d√©crite. <br><br>  Wikip√©dia, comme vous le savez, est une collection d'articles sur de nombreux domaines de connaissances et d'int√©r√™ts.  Dans le m√™me temps, une partie importante des articles contient des liens vers des articles sur un sujet similaire, mais dans d'autres langues.  Ce ne sont pas des traductions, √† savoir des articles d'un sujet g√©n√©ral.  De plus, la plupart des articles entrent dans une ou plusieurs cat√©gories.  Les cat√©gories, √† leur tour, sont pour la plupart organis√©es sous la forme d'un arbre hi√©rarchique.  Autrement dit, la t√¢che de regrouper les articles Wikipedia sur des sujets qui nous int√©ressent peut √™tre r√©solue. <br><br>  Nous utilisons la ressource DBPedia - une version pr√©c√¢bl√©e et structur√©e de Wikipedia.  DBPedia nous donne toutes les informations n√©cessaires - les noms des articles, leurs annotations, les cat√©gories des articles et les cat√©gories sup√©rieures pour les cat√©gories.  Nous commen√ßons par la langue la plus repr√©sent√©e sur Wikip√©dia - l'anglais.  Si votre t√¢che ne contient pas ou peu de textes en anglais, utilisez la langue pour laquelle il existe de nombreux documents. <br><br><h3>  √âtape 1. Regroupement de Wikipedia </h3><br>  Concentrez-vous sur les cat√©gories d'articles.  Pour l'instant, ignorez leur contenu.  Les cat√©gories forment un graphique, principalement en forme d'arbre, mais il existe √©galement des cycles.  Les articles sont les points d'extr√©mit√© du graphique (feuilles) connect√©s √† un ou plusieurs n≈ìuds du graphique.  Nous utilisons l'outil Node2Vec pour obtenir une repr√©sentation vectorielle de chaque cat√©gorie et de chaque article.  Les articles de sujets similaires sont regroup√©s dans l'espace vectoriel. <br><br>  Nous regroupons par n'importe quelle m√©thode pratique de l'article en un nombre assez important (des centaines) de grappes. <br><br><h3>  √âtape 2. Formation sur les classificateurs sur Wikip√©dia </h3><br>  Nous rempla√ßons les noms des articles des grappes r√©sultantes par leurs annotations (r√©sum√© long et r√©sum√© court - environ un paragraphe de texte par article).  Nous avons maintenant des centaines de clusters d√©finis comme des ensembles de textes.  Nous utilisons un mod√®le pratique et construisons un classificateur qui r√©sout le probl√®me de la classification multiclasse: un cluster - une classe.  Nous avons utilis√© FastText. <br>  En sortie, nous obtenons un mod√®le qui prend du texte en entr√©e et en sortie, il donne un vecteur d'estimation du degr√© auquel le texte appartient √† nos centaines de groupes de classes. <br><br>  Si la premi√®re √©tape consiste √† regrouper les articles de Wikip√©dia non pas par leurs cat√©gories, mais par leur contenu, alors, premi√®rement, nous perdrons des informations par cat√©gories, mais c'est important, et deuxi√®mement, nous obtiendrons un syst√®me d√©g√©n√©r√© - qui, par textes, est regroup√© et construit mod√®le de classificateur.  La qualit√© finale sera probablement pire qu'avec une approche s√©par√©e.  Bien que je n'aie pas v√©rifi√©. <br><br><h3>  √âtape 3. Construire un mod√®le par vous-m√™me, combattre, donn√©es </h3><br>  Nous utilisons une s√©lection de nos donn√©es de combat et soumettons chaque document √† l'entr√©e du mod√®le de l'√©tape 2. Le mod√®le renvoie un vecteur d'estimations.  Nous utilisons ce vecteur comme vecteur d'entit√© pour le document en question.  En cons√©quence, apr√®s avoir trait√© tous nos √©chantillons d'entra√Ænement de documents de combat, nous obtenons un tableau sous la forme standard pour l'apprentissage automatique - une √©tiquette de classe, un ensemble de signes num√©riques.  Nous appelons cette table un ensemble de formation. <br><br>  Nous construisons sur l'√©chantillon d'apprentissage un classificateur qui peut √©valuer le contenu informationnel des attributs individuels.  Les arbres de d√©cision et leurs variations al√©atoires en for√™t sont bien adapt√©s.  Les signes les plus informatifs sont les groupes d'articles de Wikip√©dia qui ont non seulement des th√®mes similaires aux th√®mes de nos documents de combat, mais, plus important encore, les sujets de ces articles nous permettent de bien s√©parer nos classes de combat.  Lors des premi√®res it√©rations, l'histogramme de l'informativit√© des signes est g√©n√©ralement assez plat - plusieurs grappes informatives et une longue queue sont presque √©gales en termes d'informativit√© aux centaines de signes restants. <br><br>  Apr√®s avoir √©tudi√© l'histogramme du contenu informationnel des caract√®res, un point d'inflexion a √©t√© d√©termin√© empiriquement √† chaque fois, et environ 10 √† 30% des grappes sont pass√©es √† l'it√©ration suivante.  L'essence de l'it√©ration est que les articles des clusters informatifs s√©lectionn√©s ont √©t√© combin√©s, soumis aux √©tapes 1 √† 3, o√π ils ont √©t√© regroup√©s √† nouveau, deux classificateurs ont √©t√© reconstruits, et tout s'est termin√© par une analyse de l'histogramme du contenu de l'information.  Cela prendra 3-4 it√©rations. <br><br>  Il s'est av√©r√© que sur nos donn√©es, les signes num√©riques, en particulier les nombres des ann√©es, ont un poids tr√®s fort et entra√Ænent l'informatisation de l'ensemble du cluster sur eux-m√™mes.  En cons√©quence logique, les groupes consacr√©s aux √©v√©nements sportifs annuels sont devenus les plus informatifs - une masse de nombres et de dates, un vocabulaire √©troit.  J'ai d√ª supprimer tous les num√©ros dans les textes des annotations d'articles (dans la deuxi√®me √©tape).  C'est devenu sensiblement meilleur, des groupes d'articles ayant vraiment un sujet cibl√© ont commenc√© √† se d√©marquer (comme nous l'avons imagin√©).  Dans le m√™me temps, des clusters inattendus sont apparus qui logiquement tombaient sur notre mission de combat, avaient le bon vocabulaire, mais il √©tait tr√®s difficile de deviner a priori l'utilit√© de tels clusters. <br><br><h3>  √âtape 4. Finalisez le mod√®le </h3><br>  Apr√®s plusieurs it√©rations des √©tapes 1 √† 3, nous avons un nombre raisonnable d'articles s√©lectionn√©s sur Wikipedia, dont les sujets aident √† partager nos documents de combat.  Nous √©largissons la s√©lection avec des articles similaires dans d'autres langues qui nous int√©ressent et construisons des grappes finales, cette fois des dizaines.  Ces clusters peuvent √™tre utilis√©s de deux mani√®res: soit cr√©er un classificateur similaire √† l'√©tape 2, et l'utiliser pour √©tendre le vecteur de fonctionnalit√© num√©rique dans votre mission de combat, ou utiliser ces ensembles de textes comme source de vocabulaire suppl√©mentaire et les int√©grer dans votre classificateur de combat.  Nous avons utilis√© la deuxi√®me voie. <br><br>  Notre classificateur de combat est un ensemble de deux mod√®les - bayes na√Øfs tronqu√©s et xgboost.  Naive Bayes travaille sur des grammes longs, ce sont des grammes avec des longueurs de 1 √† 16 √©l√©ments, et chaque gramme trouv√© incline le total √† l'une des classes, mais Bayes ne prend pas de d√©cision finale - il ne donne que la somme des poids en grammes li√©s √† chaque des cours.  Xgboost accepte la sortie de bayes, d'autres classificateurs et certains attributs num√©riques qui sont construits ind√©pendamment du texte, et xgboost donne d√©j√† le mod√®le final et l'√©valuation finale.  Cette approche facilite la connexion de tous les ensembles de textes au mod√®le gram bayes, y compris les ensembles d'articles Wikip√©dia qui en r√©sultent, et xgboost recherche d√©j√† des mod√®les sous la forme de r√©actions typiques des clusters wikipedia aux textes de combat. <br><br><h3>  R√©sultats et conclusions </h3><br>  Le premier r√©sultat a donn√© une augmentation de la pr√©cision conditionnelle de 60% √† 62%.  Lors du remplacement des annotations des articles Wikipedia √† l'√©tape 4 par les articles d√©gonfl√©s eux-m√™mes, la pr√©cision est pass√©e √† 66%.  Le r√©sultat est naturel, car la taille de l'annotation est de deux ou trois phrases, et la taille de l'article est sup√©rieure de plusieurs ordres de grandeur.  Plus de mat√©riel linguistique - plus d'effet. <br><br>  Nous devrions nous attendre √† ce que, apr√®s avoir termin√© toute la proc√©dure sur les textes des articles, plut√¥t que des annotations, l'augmentation de la qualit√© soit encore plus grande, mais il y a d√©j√† un probl√®me de num√©ro technique - il est difficile de pomper et de traiter l'int√©gralit√© de Wikip√©dia, ou sa partie notable (si vous ne commencez pas d√®s la premi√®re it√©ration).  De plus, si vous utilisez initialement non seulement l'anglais, mais toutes les langues d'int√©r√™t, vous pouvez toujours gagner autre chose.  Dans ce cas, la croissance des volumes trait√©s est multiple, et non par ordre de grandeur, comme dans le premier cas. <br><br><h4>  Vecteur de document s√©mantique </h4><br>  Pour chaque document, un vecteur est construit √† partir de la relation du document aux sujets donn√©s en fonction des cat√©gories Wikip√©dia.  Le vecteur est chiffr√© soit par la m√©thode d√©crite √† l'√©tape 3, soit par nos bayes grammes.  En cons√©quence, les documents de combat peuvent √™tre regroup√©s en fonction de ces vecteurs et obtenir un regroupement des documents de combat par sujet.  Il ne reste plus qu'√† d√©poser les hashtags et chaque nouveau document peut d√©j√† tomber dans la base de donn√©es avec des balises.  Les utilisateurs peuvent alors rechercher.  C'est le cas si vous apposez des balises de mani√®re explicite et visible √† l'utilisateur.  Cela a l'air √† la mode, m√™me si je ne suis pas un partisan. <br><br><h4>  Recherche adaptative </h4><br>  Une m√©thode plus int√©ressante d'utilisation des vecteurs de documents s√©mantiques est la recherche adaptative.  En observant l'activit√© de l'utilisateur, sur quels documents il s'attarde et ceux qu'il ne lit m√™me pas, vous pouvez d√©finir le domaine d'int√©r√™t de l'utilisateur dans le long terme (apr√®s tout, les utilisateurs ont √©galement une r√©partition des responsabilit√©s et tout le monde recherche principalement le sien) et dans le cadre de la session de recherche en cours. <br><br>  Les documents avec des sujets similaires ont des vecteurs s√©mantiques similaires avec une mesure de cosinus √©lev√©e, ce qui vous permet d'√©valuer les documents dans les r√©sultats de la recherche √† la vol√©e en fonction du degr√© de conformit√© attendue avec les int√©r√™ts de l'utilisateur, ce qui vous permet d'augmenter les documents n√©cessaires dans les r√©sultats de la recherche. <br><br>  Par cons√©quent, m√™me avec des requ√™tes de recherche identiques pour chaque utilisateur, les r√©sultats de la recherche peuvent √™tre personnalis√©s pour lui et en fonction du document de l'√©tape pr√©c√©dente qui int√©ressait l'utilisateur, la prochaine √©tape de recherche sera adapt√©e aux besoins de l'utilisateur, m√™me si la requ√™te de recherche elle-m√™me n'a pas chang√©. <br><br>  Nous travaillons actuellement sur le probl√®me de la recherche adaptative. <br><br><h4>  Test d'hypoth√®se d'entreprise </h4><br>  Les affaires viennent p√©riodiquement avec des id√©es brillantes qui sont tr√®s difficiles √† mettre en ≈ìuvre.  Nous devons apprendre √† trouver des documents par leur description, sans avoir soit un √©chantillon balis√© pour la formation, ni la possibilit√© de soumettre aux √©valuateurs un ensemble de documents √† noter.  Cela se produit g√©n√©ralement lorsque les documents cibles sont rarement trouv√©s en ce qui concerne le flux g√©n√©ral de documents, et par cons√©quent, en soumettant un pool de 10 mille documents aux √©valuateurs sans filtrage pr√©alable, vous pouvez obtenir 1-2 sorties n√©cessaires ou m√™me moins. <br><br>  Notre approche est de cr√©er un processus d'apprentissage it√©ratif bas√© sur des vecteurs s√©mantiques.  √Ä la premi√®re √©tape, nous trouvons plusieurs textes qui d√©finissent notre sujet cible - il peut s'agir d'articles de Wikip√©dia ou de textes provenant d'autres sources.  Pour chaque texte, son vecteur s√©mantique est produit.  Si le sujet cible est complexe, l'alg√®bre des ensembles fonctionne - unification, intersection, exclusion de certains sujets des autres.  Par exemple - il y a des articles Wikipedia sur ¬´Recherche et d√©veloppement¬ª et sur ¬´Cosm√©tique¬ª, l'intersection des ensembles donnera ¬´R&amp;D sur les cosm√©tiques¬ª. <br><br>  Tous les documents de la base de donn√©es peuvent √™tre tri√©s selon le degr√© de conformit√© avec les sujets donn√©s, puis l'alg√®bre des ensembles fonctionne sur les documents eux-m√™mes comme suit - un document est consid√©r√© comme pertinent pour le sujet si son vecteur s√©mantique est plus proche du vecteur des articles Wikip√©dia d'un sujet donn√© que la moyenne de la base de donn√©es.  Intersection - si en m√™me temps le vecteur s√©mantique du document est plus proche des deux sujets que la moyenne de la base de donn√©es.  D'autres op√©rations sont similaires. <br><br>  Nous trouvons un ensemble de centaines ou deux documents qui ont la proximit√© la plus proche de tous les sujets positifs et, en m√™me temps, la proximit√© la plus proche de tous les sujets n√©gatifs (si nous ne sommes pas int√©ress√©s par les questions financi√®res dans la recherche que nous recherchons, nous d√©finirons l'article de la cat√©gorie ¬´Finance¬ª comme exemple n√©gatif) )  Nous donnerons ces documents aux √©valuateurs, ils y trouveront plusieurs exemples positifs, sur la base de ces exemples, nous rechercherons d'autres documents avec des vecteurs s√©mantiques proches, les marquerons et, en sortie, nous obtiendrons suffisamment de documents pour que la classe positive puisse construire n'importe quel classificateur pratique.  Cela peut prendre plusieurs it√©rations. <br><br><h4>  R√©sum√© </h4><br>  L'approche d√©crite permet automatiquement, sans analyse manuelle, de s√©lectionner √† partir de Wikipedia ou d'un autre ensemble source de textes qui aident √† r√©soudre le probl√®me de classification.  En connectant simplement les clusters de Wikipedia √† un classificateur de travail, on peut s'attendre √† une augmentation significative de la qualit√©, sans n√©cessiter une adaptation du classificateur lui-m√™me. <br><br>  Eh bien, la recherche adaptative est int√©ressante. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr446228/">https://habr.com/ru/post/fr446228/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr446210/index.html">ADAM-3600 - un contr√¥leur industriel multifonctionnel</a></li>
<li><a href="../fr446212/index.html">Profondeurs SIEM: corr√©lations pr√™tes √† l'emploi. Partie 5. M√©thodologie pour d√©velopper des r√®gles de corr√©lation</a></li>
<li><a href="../fr446214/index.html">OS1: un noyau primitif sur Rust pour x86. Partie 3. Carte m√©moire, exception de d√©faut de page, tas et allocations</a></li>
<li><a href="../fr446218/index.html">Le game designer n'est pas tr√®s diff√©rent d'un psycho. Comment nous avons cr√©√© le jeu CMAN</a></li>
<li><a href="../fr446222/index.html">Utilisation des potentiels thermiques pour l'analyse de territoire</a></li>
<li><a href="../fr446230/index.html">Surveillance et gestion √† distance des p√©riph√©riques bas√©s sur Linux / OpenWrt / Lede via le port 80, suite</a></li>
<li><a href="../fr446234/index.html">Comment des b√©n√©voles du monde entier cr√©ent des √©missions en direct de l'ICPC-2019</a></li>
<li><a href="../fr446236/index.html">Yandex am√©liorera les algorithmes de reconnaissance vocale</a></li>
<li><a href="../fr446238/index.html">Exploiter les chargeurs de d√©marrage sign√©s pour contourner le d√©marrage s√©curis√© UEFI</a></li>
<li><a href="../fr446242/index.html">La procrastination comme outil de voyage dans le temps</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
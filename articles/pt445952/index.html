<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìÜ üë®‚Äçüëß‚Äçüë¶ üßñüèæ Um trilh√£o de pequenos singles üë®üèæ‚Äçüé§ üßòüèº üßóüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fonte da imagem: www.nikonsmallworld.com 


 O anti-pl√°gio √© um mecanismo de pesquisa especializado, que j√° foi escrito anteriormente . E qualquer mec...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Um trilh√£o de pequenos singles</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/antiplagiat/blog/445952/"><p><img src="https://habrastorage.org/webt/hc/qv/ma/hcqvmaxyzdevsbs7cs8lw_fpile.jpeg"></p><br><p>  <sub><em>Fonte da imagem: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.nikonsmallworld.com</a></em></sub> </p><br><p>  O anti-pl√°gio √© um mecanismo de pesquisa especializado, que j√° foi escrito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">anteriormente</a> .  E qualquer mecanismo de pesquisa, o que quer que se diga, para trabalhar rapidamente, precisa de seu pr√≥prio √≠ndice, que leva em considera√ß√£o todos os recursos da √°rea de pesquisa.  No meu primeiro artigo sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Habr,</a> falarei sobre a implementa√ß√£o atual do nosso √≠ndice de pesquisa, o hist√≥rico de seu desenvolvimento e as raz√µes para a escolha de uma ou outra solu√ß√£o.  Algoritmos .NET eficazes n√£o s√£o um mito, mas uma realidade dif√≠cil e produtiva.  Vamos mergulhar no mundo do hash, da compress√£o bit a bit e dos caches de prioridade em v√°rios n√≠veis.  E se voc√™ precisar de uma pesquisa mais r√°pida que <b>O (1)</b> ? </p><br><p>  Se algu√©m n√£o souber onde est√£o as telhas nesta foto, seja bem-vindo ... </p><br><p><a name="habracut"></a></p><br><h1>  Telhas, √≠ndice e por que procur√°-las </h1><br><p>  Uma telha √© um peda√ßo de texto com algumas palavras em tamanho.  As telhas se sobrep√µem, da√≠ o nome (ingl√™s, telhas - escamas, lado a lado).  Seu tamanho espec√≠fico √© um segredo aberto - 4 palavras.  Ou 5?  Bem, isso depende.  No entanto, mesmo esse valor fornece pouco e depende da composi√ß√£o das palavras de parada, do algoritmo para normalizar as palavras e de outros detalhes que n√£o s√£o significativos na estrutura deste artigo.  No final, calculamos o hash de 64 bits com base nessa telha, que chamaremos de telha no futuro. </p><br><p>  De acordo com o texto do documento, voc√™ pode criar muitas telhas, cujo n√∫mero √© compar√°vel ao n√∫mero de palavras no documento: </p><br><p>  <em>texto: string ‚Üí telhas: uint64 []</em> </p><br><p>  Se v√°rias telhas coincidem em dois documentos, assumimos que os documentos se cruzam.  Quanto mais telhas coincidirem, mais texto id√™ntico estar√° nesse par de documentos.  O √≠ndice procura documentos que tenham o maior n√∫mero de interse√ß√µes com o documento que est√° sendo verificado. </p><br><p><img src="https://habrastorage.org/webt/ud/th/z_/udthz_wa_avl6zbaij-cydicgx8.jpeg"></p><br><p>  <sub><em>Fonte da imagem: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wikipedia</a></em></sub> </p><br><p>  O √≠ndice Shingles permite executar duas opera√ß√µes principais: </p><br><ol><li><p>  Indexar as telhas dos documentos com seus identificadores: </p><br><p>  <i>index.Add (docId, telhas)</i> </p></li><li><p>  Pesquise e exiba uma lista classificada de identificadores para documentos sobrepostos: </p><br><p>  <i>index.Search (shingles) ‚Üí (docId, score) []</i> </p></li></ol><br><p>  O algoritmo de classifica√ß√£o, acredito, √© digno de um artigo separado em geral, portanto n√£o escreveremos sobre isso aqui. </p><br><p> O √≠ndice de telhas √© muito diferente dos conhecidos de texto completo, como Sphinx, Elastic ou maior: Google, Yandex, etc. ... Por um lado, n√£o requer PNL e outras alegrias da vida.  Todo o processamento de texto √© retirado e n√£o afeta o processo, bem como a sequ√™ncia de telhas no texto.  Por outro lado, a consulta de pesquisa n√£o √© uma palavra ou frase de v√°rias palavras, mas at√© v√°rias centenas de milhares de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hashes</a> , que s√£o importantes no conjunto, e n√£o separadamente. </p><br><p>  Hipoteticamente, voc√™ pode usar o √≠ndice de texto completo como substituto do √≠ndice de telhas, mas as diferen√ßas s√£o muito grandes.  A maneira mais f√°cil de usar algum armazenamento conhecido de valor-chave, isso ser√° mencionado abaixo.  Estamos vendo nossa implementa√ß√£o de <s>bicicleta</s> , chamada ShingleIndex. </p><br><p>  Por que nos incomodamos?  Mas porque </p><br><ul><li>  <u>Volumes</u> : <br><ol><li>  Existem muitos documentos.  Agora, temos cerca de 650 milh√µes deles, e este ano obviamente haver√° mais; </li><li>  O n√∫mero de telhas √∫nicas est√° crescendo aos trancos e barrancos e j√° est√° chegando a centenas de bilh√µes.  Estamos √† espera de um trilh√£o. </li></ol></li><li>  <u>Velocidade</u> : <br><ol><li>  Durante o dia, durante a sess√£o de ver√£o, mais de 300 mil documentos s√£o verificados atrav√©s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">do sistema anti-pl√°gio</a> .  Isso √© um pouco para os padr√µes dos mecanismos de pesquisa populares, mas mant√©m o tom; </li><li>  Para uma verifica√ß√£o bem-sucedida dos documentos quanto √† exclusividade, o n√∫mero de documentos indexados deve ter ordens de magnitude maiores que os documentos que est√£o sendo verificados.  A vers√£o atual do nosso √≠ndice, em m√©dia, pode ser preenchida a uma velocidade de mais de 4000 documentos m√©dios por segundo. </li></ol></li></ul><br><p>  E est√° tudo em uma m√°quina!  Sim, podemos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">replicar</a> , estamos nos aproximando gradualmente do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sharding</a> din√¢mico em um cluster, mas de 2005 at√© hoje, o √≠ndice em uma m√°quina com cuidado foi capaz de lidar com todas as dificuldades acima. </p><br><h1>  Estranha experi√™ncia </h1><br><p>  No entanto, agora somos t√£o experientes.  Goste ou n√£o, mas n√≥s tamb√©m crescemos e tentamos coisas diferentes no decorrer do crescimento, das quais √© divertido lembrar agora. </p><br><p><img src="https://habrastorage.org/webt/nx/l4/jx/nxl4jxkzhzumxh91qyds84byk70.jpeg"></p><br><p>  <sub><em>Fonte da imagem: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wikipedia</a></em></sub> </p><br><p>  Primeiro de tudo, um leitor inexperiente gostaria de usar um banco de dados SQL.  Voc√™s n√£o s√£o os √∫nicos que pensam assim, a implementa√ß√£o do SQL nos serviu bem por v√°rios anos para implementar cole√ß√µes muito pequenas.  No entanto, o foco foi imediatamente em milh√µes de documentos, ent√£o tive que ir mais longe. </p><br><p>  Como voc√™ sabe, ningu√©m gosta de bicicletas, e o LevelDB ainda n√£o era de dom√≠nio p√∫blico, ent√£o em 2010 nossos olhos se voltaram para o BerkeleyDB.  Tudo √© legal - uma base persistente de valores-chave incorporada com m√©todos adequados de acesso a btree e hash e uma longa hist√≥ria.  Tudo com ela foi maravilhoso, mas: </p><br><ul><li>  No caso de uma implementa√ß√£o de hash, quando atingiu um volume de 2 GB, simplesmente caiu.  Sim, ainda est√°vamos trabalhando no modo de 32 bits; </li><li>  A implementa√ß√£o da √°rvore B + funcionou de maneira est√°vel, mas com volumes de mais de alguns gigabytes, a velocidade da pesquisa come√ßou a cair significativamente. </li></ul><br><p>  Temos que admitir que nunca encontramos uma maneira de ajust√°-lo √† nossa tarefa.  Talvez o problema esteja nas liga√ß√µes .net, que ainda precisavam ser conclu√≠das.  A implementa√ß√£o do BDB acabou sendo usada como um substituto para o SQL como um √≠ndice intermedi√°rio antes de preencher o principal. </p><br><p>  O tempo passou.  Em 2014, eles tentaram o LMDB e o LevelDB, mas n√£o o implementaram.  Os funcion√°rios do Departamento de Pesquisa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Anti-Pl√°gio</a> usaram o RocksDB como √≠ndice.  √Ä primeira vista, foi um achado.  Mas a reposi√ß√£o lenta e a velocidade med√≠ocre de busca, mesmo em pequenos volumes, nada deram em nada. </p><br><p>  Fizemos tudo isso acima, enquanto desenvolv√≠amos nosso pr√≥prio √≠ndice personalizado.  Como resultado, ele se tornou t√£o bom em resolver nossos problemas que abandonamos os ‚Äúplugues‚Äù anteriores e focamos em melhor√°-lo, que agora usamos na produ√ß√£o em qualquer lugar. </p><br><h1>  Camadas de √≠ndice </h1><br><p>  No final, o que temos agora?  De fato, o √≠ndice de telhas consiste em v√°rias camadas (matrizes) com elementos de comprimento constante - de 0 a 128 bits - que depende n√£o apenas da camada e n√£o √© necessariamente um m√∫ltiplo de oito. </p><br><p>  Cada uma das camadas desempenha um papel.  Alguns tornam a pesquisa mais r√°pida, outros economizam espa√ßo e outros nunca s√£o usados, mas s√£o realmente necess√°rios.  Vamos tentar descrev√™-los para aumentar sua efici√™ncia total na pesquisa. </p><br><p><img src="https://habrastorage.org/webt/sd/y9/ze/sdy9zefei-lyrhgpafxq9viz9pc.jpeg"></p><br><p>  <sub><em>Fonte da imagem: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wikipedia</a></em></sub> </p><br><h4>  1. Matriz de √≠ndice </h4><br><p>  Sem perda de generalidade, consideraremos agora que uma √∫nica telha √© atribu√≠da ao documento, </p><br><p>  <i>(docId ‚Üí cascalho)</i> </p><br><p>  Trocaremos os elementos do par (inverter, porque o √≠ndice √© realmente "invertido"!), </p><br><p>  <i>(cascalho ‚Üí docId)</i> </p><br><p>  Classifique pelos valores das telhas e forme uma camada.  Porque  os tamanhos da telha e o identificador do documento s√£o constantes, agora qualquer pessoa que entenda a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pesquisa bin√°ria</a> pode encontrar um par al√©m das leituras <b>O (logn)</b> do arquivo.  Quanta, muita coisa.  Mas isso √© melhor do que apenas <b>O (n)</b> . </p><br><p>  Se o documento tiver v√°rias telhas, haver√° v√°rios pares desse documento.  Se houver v√°rios documentos com a mesma telha, isso tamb√©m n√£o mudar√° muito - haver√° v√°rios pares seguidos com a mesma telha.  Nos dois casos, a pesquisa durar√° um tempo compar√°vel. </p><br><h4>  2. Matriz de grupos </h4><br><p>  Dividimos cuidadosamente os elementos do √≠ndice da etapa anterior em grupos de qualquer maneira conveniente.  Por exemplo, para que eles se ajustem ao <s>setor de cluster, o bloco da</s> unidade de aloca√ß√£o (leitura, 4096 bytes), levando em considera√ß√£o o n√∫mero de bits e outros truques, formar√° um dicion√°rio eficaz.  Temos uma matriz simples de posi√ß√µes de tais grupos: </p><br><p>  <i>group_map (hash (shingle)) -&gt; group_position.</i> </p><br><p>  Ao procurar uma telha, agora vamos primeiro procurar a posi√ß√£o do grupo neste dicion√°rio e, em seguida, descarregar o grupo e pesquisar diretamente na mem√≥ria.  Toda a opera√ß√£o requer duas leituras. </p><br><p>  O dicion√°rio de posi√ß√µes de grupo ocupa v√°rias ordens de magnitude menos espa√ßo do que o pr√≥prio √≠ndice, geralmente pode ser simplesmente descarregado na mem√≥ria.  Assim, n√£o haver√° duas leituras, mas uma.  Total, <b>O (1)</b> . </p><br><h4>  3. Filtro Bloom </h4><br><p>  Nas entrevistas, os candidatos geralmente resolvem problemas emitindo solu√ß√µes √∫nicas com <b>O (n ^ 2)</b> ou mesmo <b>O (2 ^ n)</b> .  Mas n√≥s n√£o fazemos coisas est√∫pidas.  Existe <b>O (0)</b> no mundo, eis a quest√£o?  Vamos tentar sem muita esperan√ßa para um resultado ... </p><br><p>  Vamos voltar para a √°rea de assunto.  Se o aluno for bem-sucedido e escreveu o trabalho, ele pr√≥prio, ou simplesmente n√£o houver texto, mas lixo, uma parte significativa de suas telhas ser√° √∫nica e n√£o ser√° encontrada no √≠ndice.  Uma estrutura de dados como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o filtro Bloom √©</a> bem conhecida no mundo.  Antes de pesquisar, verifique a telha nela.  Se n√£o houver telha no √≠ndice, voc√™ n√£o poder√° procurar mais, caso contr√°rio, v√° mais longe. </p><br><p>  O filtro Bloom em si √© bastante simples, mas n√£o faz sentido usar um vetor hash com nossos volumes.  √â suficiente usar uma: <b>+1 na</b> leitura do filtro Bloom.  Isso fornece leituras <b>-1</b> ou <b>-2</b> dos est√°gios subseq√ºentes, caso a telha seja √∫nica e n√£o haja falso positivo no filtro.  Cuidado com as m√£os! </p><br><p>  A probabilidade de um erro do filtro Bloom √© definida durante a constru√ß√£o; a probabilidade de uma telha desconhecida √© determinada pela honestidade do aluno.  C√°lculos simples podem chegar √† seguinte depend√™ncia: </p><br><ul><li>  Se confiarmos na honestidade das pessoas (ou seja, na verdade, o documento √© original), a velocidade da pesquisa diminuir√°; </li><li>  Se o documento estiver claramente costurado, a velocidade da pesquisa aumentar√°, mas precisamos de muita mem√≥ria. </li></ul><br><p>  Com a confian√ßa nos alunos, temos o princ√≠pio de "confiar, mas verificar", e a pr√°tica mostra que ainda h√° lucro com o filtro Bloom. </p><br><p>  Dado que essa estrutura de dados tamb√©m √© menor que o pr√≥prio √≠ndice e pode ser armazenada em cache, na melhor das hip√≥teses, permite remover a telha sem nenhum acesso ao disco. </p><br><h4>  4. caudas pesadas </h4><br><p>  Existem telhas que s√£o encontradas em quase toda parte.  Sua participa√ß√£o no n√∫mero total √© escassa, mas ao construir o √≠ndice na primeira etapa, na segunda, grupos de dezenas e centenas de MB podem ser obtidos.  N√≥s os lembraremos separadamente e os descartamos imediatamente da consulta de pesquisa. </p><br><p>  Quando essa etapa trivial foi usada pela primeira vez em 2011, o tamanho do √≠ndice caiu pela metade e a pr√≥pria pesquisa foi acelerada. </p><br><h4>  5. Outras caudas </h4><br><p>  Mesmo assim, uma telha pode ter muitos documentos.  E isso √© normal.  Dezenas, centenas, milhares ... Mantendo-os dentro do √≠ndice principal se torna in√∫til, eles tamb√©m n√£o podem se encaixar em um grupo, a partir do qual o volume do dicion√°rio de posi√ß√µes de grupo √© inflado.  Coloque-os em uma sequ√™ncia separada com armazenamento mais eficiente.  Segundo as estat√≠sticas, essa decis√£o √© mais do que justificada.  Al√©m disso, v√°rios pacotes bit a bit podem reduzir o n√∫mero de acessos ao disco e o volume do √≠ndice. </p><br><p>  Como resultado, para facilitar a manuten√ß√£o, imprimimos todas essas camadas em um grande bloco de arquivos.  Existem dez dessas camadas nele.  Mas parte n√£o √© usada na pesquisa, parte √© muito pequena e sempre √© armazenada na mem√≥ria, parte √© ativamente armazenada em cache conforme necess√°rio / poss√≠vel. </p><br><p>  Na batalha, na maioria das vezes a busca por uma telha se resume a uma ou duas leituras aleat√≥rias de arquivos.  Na pior das hip√≥teses, voc√™ tem que fazer tr√™s.  Todas as camadas s√£o efetivamente (√†s vezes bit a bit) matrizes de elementos de comprimento constante.  Tal √© normaliza√ß√£o.  O tempo para descompactar √© insignificante em compara√ß√£o com o pre√ßo do volume total durante o armazenamento e a capacidade de armazenar em cache melhor. </p><br><p>  Na constru√ß√£o, os tamanhos das camadas s√£o calculados principalmente com anteced√™ncia, gravados sequencialmente, portanto esse procedimento √© bastante r√°pido. </p><br><h1>  Como voc√™ chegou l√°, n√£o sabia onde </h1><br><p></p><blockquote><code>     2010         ,                .    ,          .  ,      .</code> </blockquote> <br><p><img src="https://habrastorage.org/webt/2x/f7/-f/2xf7-fs8nt4rmfx7cvmeyyb_ftq.jpeg"></p><br><p>  <sub><em>Fonte da imagem: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wikipedia</a></em></sub> </p><br><p>  Inicialmente, nosso √≠ndice consistia em duas partes - uma constante, descrita acima, e uma tempor√°ria, cuja fun√ß√£o era SQL, ou BDB, ou seu pr√≥prio log de atualiza√ß√£o.  Ocasionalmente, por exemplo, uma vez por m√™s (e algumas vezes por ano), o tempor√°rio √© classificado, filtrado e mesclado com o principal.  O resultado foi unido e os dois antigos foram removidos.  Se o tempor√°rio n√£o couber na RAM, o procedimento passou por uma classifica√ß√£o externa. </p><br><p>  Esse procedimento foi bastante problem√°tico, foi iniciado no modo semi-manual e exigiu a reescrita de todo o arquivo de √≠ndice do zero.  Reescrevendo centenas de gigabytes para alguns milh√µes de documentos - bem, prazer, eu lhe digo ... </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Mem√≥rias do passado ...</b> <div class="spoiler_text"><blockquote> <code>       SSD.        ,  31    SSD          wcf-       .  ,          . ,  .</code> </blockquote> </div></div><br><p>  Para que o SSD n√£o seja particularmente tenso e o √≠ndice seja atualizado com mais frequ√™ncia, em 2012, envolvemos uma cadeia de v√°rias partes, partes de acordo com o seguinte esquema: </p><br><p><img src="https://habrastorage.org/webt/v4/5s/xo/v45sxoctvil0bhwkf2pfp7vamrs.png"></p><br><p>  Aqui, o √≠ndice consiste em uma cadeia do mesmo tipo de peda√ßos, exceto o primeiro.  O primeiro, addon, era um log somente de acr√©scimo com um √≠ndice na RAM.  Os peda√ßos subsequentes aumentaram de tamanho (e idade) at√© o √∫ltimo (zero, principal, raiz, ...). </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Nota para ciclistas ...</b> <div class="spoiler_text">  √Äs vezes, voc√™ n√£o deve escrever um c√≥digo e nem pensar, mas apenas pesquis√°-lo no Google.  At√© a nota√ß√£o, o diagrama √© semelhante ao do artigo de 1996 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">‚ÄúA √°rvore de mesclagem estruturada em log‚Äù</a> : <img src="https://habrastorage.org/webt/1z/r2/yh/1zr2yhxxboh0syuyfozcujnm5hm.png"></div></div><br><p>  Ao adicionar um documento, ele foi primeiro dobrado em um complemento.  Quando estava cheio ou por outros crit√©rios, um peda√ßo permanente foi constru√≠do sobre ele.  Os v√°rios peda√ßos vizinhos, se necess√°rio, se fundiram em um novo e os originais foram exclu√≠dos.  Atualizar um documento ou exclu√≠-lo funcionou da mesma maneira. </p><br><p>  Crit√©rios de mesclagem, comprimento da cadeia, algoritmo de desvio, contabiliza√ß√£o de itens e atualiza√ß√µes exclu√≠dos e outros par√¢metros foram ajustados.  A abordagem em si estava envolvida em v√°rias tarefas semelhantes e tomou forma como uma estrutura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LSM</a> interna separada em um .net limpo.  Na mesma √©poca, o LevelDB se tornou popular. </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Pequena observa√ß√£o sobre a √°rvore LSM</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O LSM-Tree √© um</a> algoritmo bastante interessante, com boa justificativa.  Mas, IMHO, houve alguma confus√£o no significado do termo √Årvore.  No <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> original <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">,</a> tratava-se de uma cadeia de √°rvores com a capacidade de transferir galhos.  Nas implementa√ß√µes modernas, esse nem sempre √© o caso.  Portanto, nossa estrutura acabou sendo nomeada como LsmChain, ou seja, a cadeia de blocos lsm. </div></div><br><p>  O algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LSM</a> no nosso caso possui recursos muito adequados: </p><br><ol><li>  inser√ß√£o / exclus√£o / atualiza√ß√£o instant√¢nea, </li><li>  carga reduzida nos SSDs durante a atualiza√ß√£o, </li><li>  formato de peda√ßos simplificados, </li><li>  pesquisa seletiva apenas em partes antigas / novas, </li><li>  backup trivial </li><li>  o que mais a alma quer. </li><li>  ... </li></ol><br><p>  Em geral, √†s vezes √© √∫til inventar bicicletas para o autodesenvolvimento. </p><br><h1>  Otimiza√ß√£o macro, micro e nano </h1><br><p>  E, finalmente, compartilharemos dicas t√©cnicas sobre como fazemos no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Antiplagiarism</a> essas coisas no .Net (e n√£o apenas nele). </p><br><p>  Observe com anteced√™ncia que muitas vezes tudo depende muito do seu hardware, dados ou modo de uso espec√≠fico.  Tendo torcido em um lugar, voamos para fora do cache da CPU, em outro - nos deparamos com a largura de banda da interface SATA, no terceiro - come√ßamos a travar no GC.  E em algum lugar a inefici√™ncia da implementa√ß√£o de uma chamada de sistema espec√≠fica. </p><br><p><img src="https://habrastorage.org/webt/gl/pq/sp/glpqspyystghvhhemtthxysivp0.jpeg"></p><br><p>  <sub><em>Fonte da imagem: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wikipedia</a></em></sub> </p><br><h1>  Trabalhar com arquivo </h1><br><p>  O problema com o acesso ao arquivo n√£o √© exclusivo para n√≥s.  H√° um arquivo grande de <s>terabyte de exabyte</s> , cujo volume √© muitas vezes maior que a quantidade de RAM.  A tarefa √© ler os milh√µes espalhados ao redor de alguns pequenos valores aleat√≥rios.  E faz√™-lo de forma r√°pida, eficiente e barata.  Temos que apertar, comparar e pensar muito. </p><br><p>  Vamos come√ßar com um simples.  Para ler o byte estimado, voc√™ precisa: </p><br><ol><li>  Abrir arquivo (novo FileStream); </li><li>  Mova para a posi√ß√£o desejada (posi√ß√£o ou busca, sem diferen√ßa); </li><li>  Leia a matriz de bytes desejada (leitura); </li><li>  Feche o arquivo (Dispose). </li></ol><br><p>  E isso √© ruim, porque √© longo e triste.  Por tentativa, erro e repetidas etapas no rake, identificamos o seguinte algoritmo de a√ß√µes: </p><br><ul><li><p>  <b>Leitura √∫nica aberta e m√∫ltipla</b> </p><br><p>  Se essa sequ√™ncia for feita na testa, para todas as solicita√ß√µes no disco, ent√£o nos curvaremos rapidamente.  Cada um desses itens entra em uma solicita√ß√£o ao kernel do SO, o que √© caro. </p><br><p>  Obviamente, voc√™ deve abrir o arquivo uma vez e ler sequencialmente todos os milh√µes de nossos valores, o que fazemos </p></li><li><p>  <b>Nada extra</b> </p><br><p>  Obtendo o tamanho do arquivo, a posi√ß√£o atual nele tamb√©m √© opera√ß√µes bastante dif√≠ceis.  Mesmo que o arquivo n√£o tenha sido alterado. </p><br><p>  Qualquer consulta, como obter o tamanho do arquivo ou a posi√ß√£o atual, deve ser evitada. </p></li><li><p>  <b>Filestreampool</b> </p><br><p>  Pr√≥ximo.  Infelizmente, o FileStream √© essencialmente de thread √∫nico.  Se voc√™ quiser ler um arquivo em paralelo, precisar√° criar / fechar novos fluxos de arquivos. </p><br><p>  At√© criar algo como aiosync, voc√™ deve inventar suas pr√≥prias bicicletas. </p><br><p>  Meu conselho √© criar um pool de fluxos de arquivos por arquivo.  Isso evitar√° perder tempo abrindo / fechando um arquivo.  E se voc√™ combin√°-lo com o ThreadPool e levar em conta que o SSD emite seus megaIOPSs com multithreading forte ... Bem, voc√™ me entende. </p></li><li><p>  <b>Unidade de aloca√ß√£o</b> </p><br><p>  Pr√≥ximo.  Os dispositivos de armazenamento (HDD, SSD, Optane) e o sistema de arquivos operam com arquivos no n√≠vel do bloco (cluster, setor, unidade de aloca√ß√£o).  Eles podem n√£o corresponder, mas agora s√£o quase sempre 4096 bytes.  A leitura de um ou dois bytes na borda de dois desses blocos em um SSD √© cerca de uma vez e meia mais lenta do que dentro do pr√≥prio bloco. </p><br><p>  Voc√™ deve organizar seus dados para que os elementos subtra√≠dos fiquem dentro dos limites do bloco do <s>setor de cluster</s> . </p></li><li><p>  <b>Sem buffer.</b> </p><br><p>  Pr√≥ximo.  O FileStream, por padr√£o, usa um buffer de 4096 bytes.  E a m√° not√≠cia √© que voc√™ n√£o pode deslig√°-lo.  No entanto, se voc√™ estiver lendo mais dados que o tamanho do buffer, o √∫ltimo ser√° ignorado. </p><br><p>  Para leitura aleat√≥ria, voc√™ deve definir o buffer como 1 byte (n√£o funcionar√° menos) e depois considerar que n√£o √© usado. </p></li><li><p>  <b>Use buffer.</b> </p><br><p>  Al√©m de leituras aleat√≥rias, h√° tamb√©m sequenciais.  Aqui, o buffer j√° pode se tornar √∫til se voc√™ n√£o quiser ler tudo de uma vez.  Eu aconselho voc√™ a come√ßar com este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> .  Qual o tamanho do buffer a ser configurado depende se o arquivo est√° no HDD ou no SSD.  No primeiro caso, 1 MB ser√° ideal; no segundo, 4kB padr√£o ser√° suficiente.  Se o tamanho da √°rea de dados a ser lida for compar√°vel a esses valores, √© melhor subtra√≠-lo de uma vez, ignorando o buffer, como no caso de leitura aleat√≥ria.  Buffers grandes n√£o trar√£o lucro em velocidade, mas come√ßar√£o a atingir o GC. </p><br><p>  Ao ler seq√ºencialmente grandes partes do arquivo, voc√™ deve definir o buffer como 1 MB para HDD e 4kB para SSD.  Bem, isso depende. </p></li></ul><br><h1>  MMF vs FileStream </h1><br><p>  Em 2011, uma dica chegou ao MemoryMappedFile, pois esse mecanismo foi implementado desde o .Net Framework v4.0.  Primeiro, eles o usavam ao armazenar em cache o filtro Bloom, que j√° era inconveniente no modo de 32 bits devido √† limita√ß√£o de 4 GB.  Mas ao me mudar para o mundo de 64 bits, eu queria mais.  Os primeiros testes foram impressionantes.  Armazenamento em cache gratuito, velocidade anormal, interface de leitura conveniente da estrutura.  Mas houve problemas: </p><br><ul><li>  Primeiro, curiosamente, velocidade.  Se os dados j√° estiverem armazenados em cache, tudo est√° bem.  Mas, se n√£o, a leitura de um byte do arquivo era acompanhada de uma "eleva√ß√£o" de uma quantidade muito maior de dados do que seria com uma leitura regular. </li><li>  Em segundo lugar, curiosamente, mem√≥ria.  Quando aquecida, a mem√≥ria compartilhada aumenta, funciona - n√£o, o que √© l√≥gico.  Mas ent√£o os processos vizinhos come√ßam a se comportar n√£o muito bem.  Eles podem entrar em uma troca ou acidentalmente cair da OoM.  O volume ocupado pelo MMF na RAM, infelizmente, n√£o pode ser controlado.  E o lucro do cache no caso em que o arquivo leg√≠vel √© um par de ordens de magnitude maior que a mem√≥ria fica sem sentido. </li></ul><br><p>  O segundo problema ainda poderia ser combatido.  Ele desaparece se o √≠ndice funcionar na janela de encaixe ou em uma m√°quina virtual dedicada.  Mas o problema da velocidade foi fatal. </p><br><p>  Como resultado, o FMM foi abandonado um pouco mais do que completamente.  O armazenamento em cache no antipl√°gio come√ßou a ser feito de forma expl√≠cita, se poss√≠vel mantendo na mem√≥ria as camadas mais usadas nas prioridades e limites. </p><br><p><img src="https://habrastorage.org/webt/qr/em/sd/qremsdrzpkqcxqrbam_finb4dyw.jpeg"></p><br><p>  <sub><em>Fonte da imagem: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wikipedia</a></em></sub> </p><br><h1>  Bits / bytes </h1><br><p>  N√£o bytes, o mundo √© um.  √Äs vezes voc√™ precisa descer para o n√≠vel de bit. </p><br><p>  Por exemplo: suponha que voc√™ tenha um trilh√£o de n√∫meros parcialmente pedidos, ansiosos para salvar e ler com freq√º√™ncia.  Como trabalhar com tudo isso? </p><br><ul><li>  BinaryWriter.Write simples?  - r√°pido, mas lento.  Tamanho importa.  A leitura a frio depende principalmente do tamanho do arquivo. </li><li>  Outra varia√ß√£o do VarInt?  - r√°pido, mas lento.  A consist√™ncia √© importante.  O volume come√ßa a depender dos dados, o que requer mem√≥ria adicional para o posicionamento. </li><li>  Bit embalagem?  - r√°pido, mas lento.  Voc√™ precisa controlar suas m√£os com mais cuidado. </li></ul><br><p>  N√£o existe uma solu√ß√£o ideal, mas no caso espec√≠fico, basta comprimir o intervalo de 32 bits ao necess√°rio para armazenar as caudas economizadas 12% mais (dezenas de GB!) Do que o VarInt (economizando apenas a diferen√ßa das vizinhas, √© claro), e isso √© v√°rias vezes op√ß√£o b√°sica. </p><br><p>  Outro exemplo  Voc√™ tem um link em um arquivo para alguma matriz de n√∫meros.  Link de 64 bits, arquivo por terabyte.  Tudo parece bem.  √Äs vezes, existem muitos n√∫meros na matriz, √†s vezes poucos.  Muitas vezes um pouco.  Com muita frequ√™ncia  Em seguida, basta pegar e armazenar toda a matriz no pr√≥prio link.  Lucro  Fa√ßa as malas com cuidado, mas n√£o esque√ßa. </p><br><h1>  Estruturas, inseguras, lotes, microop√ß√µes </h1><br><p>  Bem e outras micro otimiza√ß√µes.  N√£o escreverei aqui sobre o banal "vale a pena salvar o comprimento da matriz em um loop" ou "o que √© mais r√°pido, para ou foreach". </p><br><p>  Existem duas regras simples, e vamos segui-las: 1. "compare tudo", 2. "mais benchmark". </p><br><ul><li><p>  <b>Struct</b> .  Usado em qualquer lugar.  N√£o envie GC.  E, como est√° na moda hoje, tamb√©m temos nossa pr√≥pria ValueList mega-r√°pida. </p></li><li><p>  <b>Inseguro</b> .  Permite mapit (e unmap) estruturas para uma matriz de bytes quando usado.  Portanto, n√£o precisamos de meios separados de serializa√ß√£o.  √â verdade que existem perguntas para fixar e desfragmentar a pilha, mas at√© agora ela n√£o foi mostrada.  Bem, isso depende. </p></li><li><p>  <b>Dosagem</b> .  O trabalho com muitos elementos deve ser feito por pacotes / grupos / blocos.  Arquivo de leitura / grava√ß√£o, transfer√™ncia entre fun√ß√µes.  Um problema separado √© o tamanho desses pacotes.  Geralmente, existe um √≥timo, e seu tamanho geralmente varia de 1kB a 8MB (tamanho do cache da CPU, tamanho do cluster, tamanho da p√°gina, tamanho de outra coisa).  Tente bombear a fun√ß√£o IEnumerable &lt;byte&gt; ou IEnumerable &lt;byte [1024]&gt; e sinta a diferen√ßa. </p></li><li><p>  <b>Pooling</b> .  Toda vez que voc√™ escreve "novo", um gatinho morre em algum lugar.  Uma vez novo byte [ <a href="">85000</a> ] - e o trator montou uma tonelada de gansos.  Se n√£o for poss√≠vel usar o stackalloc, crie um conjunto de objetos e reutilize-o novamente. </p></li><li><p>  <b>Inlining</b> .  Como criar duas fun√ß√µes em vez de uma pode acelerar tudo dez vezes?  Simples.  Quanto menor o tamanho do corpo da fun√ß√£o (m√©todo), maior a probabilidade de ela estar alinhada.  Infelizmente, no mundo das dotnet ainda n√£o h√° como fazer inlining parcial; portanto, se voc√™ tiver uma fun√ß√£o quente que, em 99% dos casos, sai ap√≥s o processamento das primeiras linhas, e as centenas de linhas restantes processam o 1% restante, divida-o com seguran√ßa em dois (ou tr√™s), carregando a cauda pesada em uma fun√ß√£o separada. </p></li></ul><br><h1>  O que mais? </h1><br><ul><li><p>  <b>Span &lt;T&gt;</b> , <b>Memory &lt;T&gt;</b> - prometidamente.  O c√≥digo ser√° mais simples e talvez um pouco mais r√°pido.  Estamos aguardando o lan√ßamento do .Net Core v3.0 e Std v2.1 para mudar para eles, porque  nosso kernel no .Net Std v2.0, que normalmente n√£o suporta extens√µes. </p></li><li><p>  <b>Ass√≠ncrono / aguardar</b> - at√© agora controverso.  Os benchmarks de leitura aleat√≥ria mais simples mostraram que o consumo da CPU est√° realmente caindo, mas a velocidade de leitura tamb√©m est√° diminuindo.  Deve assistir.  Ainda n√£o o estamos usando no √≠ndice. </p></li></ul><br><h1>  Conclus√£o </h1><br><p>  Espero que meu afastamento lhe d√™ prazer em entender a beleza de algumas decis√µes.  N√≥s realmente gostamos do nosso √≠ndice.  √â um c√≥digo eficiente e bonito, funciona muito bem.  Uma solu√ß√£o altamente especializada no n√∫cleo do sistema, o local cr√≠tico de seu trabalho, √© melhor que o geral.  Nosso sistema de controle de vers√£o lembra as inser√ß√µes do assembler no c√≥digo C ++.  Agora, existem quatro vantagens - apenas C # puro, apenas .Net.  Nela, escrevemos at√© os algoritmos de pesquisa mais complexos e n√£o nos arrependemos.  Com o advento do .Net Core, a transi√ß√£o para o Docker, o caminho para um futuro brilhante do DevOps se tornou mais f√°cil e claro.  A frente √© a solu√ß√£o do problema de fragmenta√ß√£o e replica√ß√£o din√¢micas sem reduzir a efic√°cia e a beleza da solu√ß√£o. </p><br><p>  Obrigado a todos que leram at√© o fim.  Para todas as discrep√¢ncias e outras inconsist√™ncias, escreva coment√°rios.  Ficarei feliz em receber qualquer conselho razo√°vel e refut√°-lo nos coment√°rios. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt445952/">https://habr.com/ru/post/pt445952/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt445932/index.html">Seguran√ßa de aplicativos clientes: dicas pr√°ticas para um desenvolvedor front-end</a></li>
<li><a href="../pt445936/index.html">Desenvolvimento de eletr√¥nicos. Sobre microcontroladores nos dedos</a></li>
<li><a href="../pt445940/index.html">AMA com Habr, v 7.0. Lim√£o, Rosquinhas e Not√≠cias</a></li>
<li><a href="../pt445946/index.html">MWC: instru√ß√µes de uso</a></li>
<li><a href="../pt445948/index.html">Heran√ßa em C ++: iniciante, intermedi√°rio, avan√ßado</a></li>
<li><a href="../pt445954/index.html">Acelerador de IA da HSE, MTS e Rostelecom</a></li>
<li><a href="../pt445958/index.html">SPDS GraphiCS - sistema de fachada e cobertura</a></li>
<li><a href="../pt445962/index.html">Est√°gio em TI: vis√£o do gerente</a></li>
<li><a href="../pt445964/index.html">O MEPhI sediar√° uma olimp√≠ada de seguran√ßa da informa√ß√£o do aluno: como participar e o que isso oferece</a></li>
<li><a href="../pt445966/index.html">Nota do arquiteto de front-end n¬∫ 1. Voc√™ n√£o pode simplesmente obter e usar o Redux.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèÄ ü§µüèø üë®üèæ‚Äçüíº √úberwachung und Kubernetes (R√ºckblick und Videobericht) üõµ üé¨ ü§∏üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Am 28. Mai wurde auf der RootConf 2018-Konferenz, die im Rahmen des RIT ++ 2018- Festivals stattfand , im Abschnitt ‚ÄûProtokollierung und √úberwachung‚Äú ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√úberwachung und Kubernetes (R√ºckblick und Videobericht)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/412901/">  Am 28. Mai wurde auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RootConf</a> 2018-Konferenz, die im Rahmen des RIT ++ 2018- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Festivals stattfand</a> , im Abschnitt ‚ÄûProtokollierung und √úberwachung‚Äú ein Bericht ‚Äû√úberwachung und Kubernetes‚Äú ver√∂ffentlicht.  Es handelt von den Erfahrungen mit der √úberwachung des Setups mit Prometheus, die Flant als Ergebnis des Betriebs von Dutzenden von Kubernetes-Projekten in der Produktion erhalten hat. <br><br><img src="https://habrastorage.org/webt/pm/o9/dm/pmo9dmnz9jf7b-yhej9shmir92q.jpeg"><br><br>  Aus Tradition freuen wir uns, ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>Video mit einem Bericht</b></a> (ungef√§hr eine Stunde, <b>viel</b> informativer <b>als der</b> Artikel) und dem Hauptdruck in Textform zu pr√§sentieren.  Lass uns gehen! <a name="habracut"></a><br><br><h2>  Was ist √úberwachung? </h2><br>  Es gibt viele √úberwachungssysteme: <br><br><img src="https://habrastorage.org/webt/pa/07/i0/pa07i0ojuohdqwxbk6lvf86lgls.png"><br><br>  Es scheint, als w√ºrde man einen von ihnen nehmen und installieren - das ist alles, die Frage ist geschlossen.  Die Praxis zeigt jedoch, dass dies nicht der Fall ist.  Und hier ist warum: <br><br><ol><li>  <b>Tachometer zeigt Geschwindigkeit an</b> .  Wenn wir die Geschwindigkeit einmal pro Minute mit dem Tachometer messen, stimmt die Durchschnittsgeschwindigkeit, die wir auf der Grundlage dieser Daten berechnen, nicht mit den Kilometerz√§hlerdaten √ºberein.  Und wenn dies bei einem Auto offensichtlich ist, dann vergessen wir es oft, wenn es um viele, viele Indikatoren f√ºr den Server geht. <br><img src="https://habrastorage.org/webt/s9/13/fv/s913fvrbguhqbp3iuuobwrmazt8.png"><br>  <i>Was wir messen und wie wir tats√§chlich gereist sind</i> </li><li>  <b>Weitere Messungen</b> .  Je mehr <i>verschiedene</i> Indikatoren wir erhalten, desto genauer wird die Diagnose von Problemen sein ... aber nur unter der Bedingung, dass dies wirklich n√ºtzliche Indikatoren sind und nicht nur alles, was Sie gesammelt haben. </li><li>  <b>Warnungen</b> .  Das Senden von Warnungen ist nicht kompliziert.  Zwei typische Probleme: a) Fehlalarme treten so oft auf, dass wir nicht mehr auf Warnungen reagieren. B) Warnungen kommen zu einem Zeitpunkt, an dem es zu sp√§t ist (alles ist bereits explodiert).  Und bei der √úberwachung zu erreichen, dass diese Probleme nicht aufgetreten sind, ist echte Kunst! </li></ol><br>  Die √úberwachung besteht aus drei Ebenen, von denen jede von entscheidender Bedeutung ist: <br><br><ol><li>  Zuallererst ist dies ein System, mit dem Sie <b>Unf√§lle</b> <b>vorbeugen, √ºber Unf√§lle informieren</b> (wenn sie nicht verhindert werden konnten) und eine <b>schnelle Diagnose von</b> Problemen durchf√ºhren k√∂nnen. </li><li>  Was wird daf√ºr ben√∂tigt?  <b>Genaue Daten</b> , <b>n√ºtzliche Diagramme</b> (sehen Sie sie sich an und verstehen Sie, wo das Problem liegt), <b>relevante Warnungen</b> (treffen Sie zum richtigen Zeitpunkt ein und enthalten Sie klare Informationen). </li><li>  Damit dies funktioniert, ist ein <b>√úberwachungssystem</b> erforderlich. </li></ol><br>  Die ordnungsgem√§√üe Einrichtung eines √úberwachungssystems, das wirklich funktioniert, ist keine leichte Aufgabe und erfordert auch ohne Kubernetes einen durchdachten Ansatz f√ºr die Implementierung.  Aber was passiert mit seinem Aussehen? <br><br><h2>  Einzelheiten zur √úberwachung von Kubernetes </h2><br><h3>  Nr. 1.  Gr√∂√üer und schneller </h3><br>  Kubernetes ver√§ndert sich stark, weil die Infrastruktur immer gr√∂√üer und schneller wird.  Wenn fr√ºher bei gew√∂hnlichen Eisenservern ihre Anzahl sehr begrenzt war und der Additionsprozess sehr lang war (Tage oder Wochen dauerte), dann erh√∂hte sich bei virtuellen Maschinen die Anzahl der Entit√§ten erheblich und die Zeit ihrer Einf√ºhrung in den Kampf wurde auf Sekunden reduziert. <br><br>  Mit Kubernetes ist die Anzahl der Entit√§ten um eine Gr√∂√üenordnung gewachsen, ihre Hinzuf√ºgung ist vollst√§ndig automatisiert (Konfigurationsmanagement ist erforderlich, da ohne Beschreibung einfach kein neuer Pod erstellt werden kann), die gesamte Infrastruktur ist sehr dynamisch geworden (z. B. werden Pods jedes Mal gel√∂scht und freigegeben werden erneut erstellt). <br><br><img src="https://habrastorage.org/webt/01/fv/cf/01fvcfbc_i2roepw7nh0q6womsk.png"><br><br>  Was √§ndert sich daran? <br><br><ol><li>  Grunds√§tzlich h√∂ren wir auf, einzelne H√ºlsen oder Beh√§lter zu betrachten - jetzt interessieren wir uns <b>nur noch</b> f√ºr <b>Gruppen von Objekten</b> . </li><li>  <b>Die Serviceerkennung wird unbedingt erforderlich</b> , da die "Geschwindigkeiten" bereits so hoch sind, dass wir neue Entit√§ten im Prinzip nicht wie zuvor beim Kauf neuer Server manuell starten / l√∂schen k√∂nnen. </li><li>  <b>Die Datenmenge w√§chst erheblich</b> .  Wenn fr√ºhere Metriken von Servern oder virtuellen Maschinen erfasst wurden, jetzt von Pods, deren Anzahl viel gr√∂√üer ist. </li><li>  Die interessanteste √Ñnderung, die ich als " <b>Metadatenfluss</b> " bezeichnet habe, und ich werde Ihnen mehr dar√ºber erz√§hlen. </li></ol><br>  Ich werde mit diesem Vergleich beginnen: <br><br><ul><li>  Wenn Sie Ihr Kind in den Kindergarten schicken, erh√§lt es eine pers√∂nliche Box, die ihm f√ºr das n√§chste Jahr (oder l√§nger) zugewiesen wird und auf der sein Name angegeben ist. </li><li>  Wenn Sie zum Pool kommen, ist Ihr Schlie√üfach nicht signiert und wird Ihnen f√ºr eine ‚ÄûSitzung‚Äú ausgestellt. </li></ul><br>  <b>Klassische √úberwachungssysteme denken also, dass sie ein Kindergarten sind</b> , kein Pool: Sie gehen davon aus, dass das √úberwachungsobjekt f√ºr immer oder lange zu ihnen gekommen ist, und geben ihnen entsprechend Schlie√üf√§cher.  Die Realit√§ten in Kubernetes sind jedoch anders: Ein Pod kam in den Pool (d. H. Wurde erstellt), schwamm darin (bis zu einer neuen Bereitstellung) und ging (wurde zerst√∂rt) - all dies geschieht schnell und regelm√§√üig.  Das √úberwachungssystem muss daher verstehen, dass die von ihm √ºberwachten Objekte ein kurzes Leben f√ºhren und es zum richtigen Zeitpunkt vollst√§ndig vergessen k√∂nnen. <br><br><h3>  Nr. 2.  Parallele Realit√§t existiert </h3><br>  Ein weiterer wichtiger Punkt - mit dem Aufkommen von Kubernetes haben wir gleichzeitig zwei ‚ÄûRealit√§ten‚Äú: <br><br><ol><li>  Kubernetes-Welt, in der es Namespaces, Bereitstellungen, Pods und Container gibt.  Dies ist eine komplexe Welt, aber sie ist logisch und strukturiert. </li><li>  Die "physische" Welt, bestehend aus vielen (buchst√§blich - Haufen) Containern auf jedem Knoten. </li></ol><br><img src="https://habrastorage.org/webt/1p/wc/xj/1pwcxjjt1xbgwqufldfm1upua10.png"><br>  <i>Ein und derselbe Container in Kubernetes ‚Äûvirtueller Realit√§t‚Äú (oben) und der physischen Welt der Knoten (unten)</i> <br><br>  Und w√§hrend des √úberwachungsprozesses m√ºssen wir <b>die physische Welt der Container</b> st√§ndig <b>mit der Realit√§t von Kubernetes vergleichen</b> .  Wenn wir uns beispielsweise einen Namespace ansehen, m√∂chten wir wissen, wo sich alle seine Container (oder die Container eines seiner Herde) befinden.  Ohne dies sind Warnungen nicht visuell und bequem zu verwenden, da es f√ºr uns wichtig ist, zu verstehen, welche Objekte sie melden. <br><br><img src="https://habrastorage.org/webt/2p/n7/3t/2pn73tojozunuxdnjiba8yqw7-y.png"><br>  <i>Verschiedene Arten von Warnungen - letztere sind visueller und bequemer bei der Arbeit als die anderen</i> <br><br>  <b>Die Schlussfolgerungen</b> hier sind: <br><br><ol><li>  Das √úberwachungssystem muss die in Kubernetes integrierten Grundelemente verwenden. </li><li>  Es gibt mehr als eine Realit√§t: Oft treten Probleme nicht mit dem Herd auf, sondern mit einem bestimmten Knoten, und wir m√ºssen st√§ndig verstehen, in welcher Art von ‚ÄûRealit√§t‚Äú sie sich befinden. </li><li>  In einem Cluster gibt es in der Regel mehrere Umgebungen (neben der Produktion), was bedeutet, dass dies ber√ºcksichtigt werden muss (z. B. um nachts keine Warnungen √ºber Probleme mit Entwicklern zu erhalten). </li></ol><br>  Wir haben also drei notwendige Bedingungen, damit alles funktioniert: <br><br><ol><li>  Wir verstehen gut, was √úberwachung ist. </li><li>  Wir kennen die Funktionen, die bei Kubernetes angezeigt werden. </li><li>  Wir adoptieren den Prometheus. </li></ol><br>  Und um wirklich zu trainieren, muss man sich nur noch <i>wirklich viel</i> M√ºhe geben!  √úbrigens, warum genau Prometheus? <br><br><h2>  Prometheus </h2><br>  Es gibt zwei M√∂glichkeiten, die Frage nach der Wahl von Prometheus zu beantworten: <br><br><ol><li>  Sehen Sie, wer und was im Allgemeinen zur √úberwachung von Kubernetes verwendet wird. </li><li>  Betrachten Sie die technischen Vorteile. </li></ol><br>  Zum ersten habe ich die Umfragedaten aus The New Stack (aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem</a> E-Book " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">The State of the Kubernetes Ecosystem</a> ") verwendet, wonach Prometheus zumindest beliebter ist als andere L√∂sungen (sowohl Open Source als auch SaaS), und wenn Sie sich das ansehen, hat es einen f√ºnffachen statistischen Vorteil . <br><br>  Lassen Sie uns nun sehen, wie Prometheus funktioniert, parallel dazu, wie sich seine F√§higkeiten mit Kubernetes kombinieren und damit verbundene Herausforderungen l√∂sen. <br><br><h2>  Wie ist Prometheus aufgebaut? </h2><br>  Prometheus ist in Go geschrieben und als einzelne Bin√§rdatei verteilt, in die alles eingebaut ist.  Der grundlegende Algorithmus f√ºr seine Funktionsweise lautet wie folgt: <br><br><img src="https://habrastorage.org/webt/nh/xt/hp/nhxthp-dm3wveymrgbejbanainw.png"><br><br><ul><li>  <b>Der Kollektor</b> liest die <b>Zieltabelle</b> , d.h.  eine Liste der zu √ºberwachenden Objekte und die H√§ufigkeit ihrer Abfrage (standardm√§√üig - 60 Sekunden). </li><li>  Danach sendet der Collector eine HTTP-Anfrage an jeden Pod, den Sie <b>ben√∂tigen,</b> und erh√§lt eine Antwort mit einer Reihe von Metriken - es kann einhundert, eintausend, zehntausend sein ... Jede Metrik hat einen Namen, einen Wert und <b>Beschriftungen</b> . </li><li>  Die empfangene Antwort wird in der <b>TSDB-</b> Datenbank gespeichert, wo der Zeitstempel ihres Empfangs und die Beschriftungen des Objekts, von dem sie entnommen wurde, zu den empfangenen <b>Metrikdaten</b> hinzugef√ºgt werden. <br><br><div class="spoiler">  <b class="spoiler_title">Kurz √ºber TSDB</b> <div class="spoiler_text">  <i>TSDB - Zeitreihendatenbank (DB f√ºr Zeitreihen) on Go, mit der Sie Daten f√ºr eine bestimmte Anzahl von Tagen speichern k√∂nnen und dies sehr effizient (in Gr√∂√üe, Speicher und Eingabe / Ausgabe).</i>  <i>Daten werden nur lokal gespeichert, ohne Clustering und Replikation, was ein Plus (es funktioniert einfach und garantiert) und ein Minus (es gibt keine horizontale Skalierung des Speichers) ist, aber im Fall von Prometheus ist das Sharding gut gemacht, F√∂deration - dazu sp√§ter mehr.</i> <br></div></div></li><li>  <b>Service Discovery</b> ist eine in Prometheus integrierte <b>Service Discovery-</b> Engine, mit der Sie Daten ‚Äûaus der Box‚Äú (√ºber die Kubernetes-API) empfangen k√∂nnen, um eine Zieltabelle zu erstellen. </li></ul><br>  Wie sieht dieser Tisch aus?  F√ºr jeden Eintrag wird die URL gespeichert, die zum Abrufen von Metriken, der H√§ufigkeit von Anrufen und Beschriftungen verwendet wird. <br><br><img src="https://habrastorage.org/webt/xu/9m/c_/xu9mc_ikwk-sdzkrs_fjt6lsfj0.png"><br><br>  Etiketten werden verwendet, um die "Welten" von Kubernetes mit den physischen zu vergleichen.  Um beispielsweise einen Pod mit Redis zu finden, m√ºssen der Werte-Namespace, der Service (der aufgrund der technischen Funktionen f√ºr einen bestimmten Fall anstelle der Bereitstellung verwendet wird) und der tats√§chliche Pod vorhanden sein.  Dementsprechend werden diese 3 Bezeichnungen in Zieltabelleneintr√§gen f√ºr Redis-Metriken gespeichert. <br><br>  Diese Eintr√§ge in der Tabelle werden auf der Grundlage der Prometheus- <code>scrape_configs</code> in der die √úberwachungsobjekte beschrieben werden: <code>scrape_configs</code> Abschnitt <code>scrape_configs</code> werden <code>scrape_configs</code> definiert, die angeben, nach welchen Labels nach zu √ºberwachenden Objekten gesucht werden soll, wie sie gefiltert werden sollen und welche Labels aufgezeichnet werden sollen. <br><br><h2>  Welche Daten sammelt Kubernetes? </h2><br><ul><li>  Erstens ist der <b>Assistent</b> in Kubernetes ziemlich kompliziert - und es ist wichtig, den Status seiner Arbeit zu √ºberwachen (Kube-Apiserver, Kube-Controller-Manager, Kube-Scheduler, Kube-etcd3 ...). Au√üerdem ist er an den Clusterknoten gebunden. </li><li>  Zweitens ist es wichtig zu wissen, was <b>in Kubernetes vor sich geht</b> . Dazu erhalten wir Daten von: <br><ul><li>  <i>kubelet</i> - Diese Kubernetes-Komponente wird auf jedem Knoten des Clusters ausgef√ºhrt (und stellt eine Verbindung zum K8s-Assistenten her).  cAdvisor ist integriert (alle Metriken nach Containern) und speichert auch Informationen zu verbundenen persistenten Volumes. </li><li>  <i>Kube-State-Metriken</i> - Dies ist der Prometheus-Exporter f√ºr die Kubernetes-API (mit dem Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Informationen zu Objekten</a> abrufen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">k√∂nnen</a> , die in Kubernetes gespeichert sind: Pods, Dienste, Bereitstellungen usw.; Beh√§lter- oder Herdstatus); </li><li>  <i>Node-Exporter</i> - bietet Informationen √ºber den Knoten selbst, grundlegende Metriken auf dem Linux-System (CPU, Diskstats, Meminfo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">usw.</a> ). </li></ul></li><li>  Als n√§chstes folgen <b>Kubernetes-Komponenten</b> wie kube-dns, kube-prometheus-operator und kube-prometheus, ingress-nginx-controller usw. </li><li>  Die n√§chste Kategorie von zu √ºberwachenden Objekten ist die in Kubernetes gestartete <b>Software</b> .  Dies sind typische Serverdienste wie nginx, php-fpm, Redis, MongoDB, RabbitMQ ... Wir tun dies selbst, sodass beim Hinzuf√ºgen bestimmter Labels zum Dienst automatisch die erforderlichen Daten erfasst werden, wodurch das aktuelle Dashboard in Grafana erstellt wird. </li><li>  Schlie√ülich ist die Kategorie f√ºr alles andere <b>benutzerdefiniert</b> .  Mit den Prometheus-Tools k√∂nnen Sie die Erfassung beliebiger Metriken (z. B. die Anzahl der Bestellungen) automatisieren, indem Sie der Servicebeschreibung einfach ein <code>prometheus-custom-target</code> Label hinzuf√ºgen. </li></ul><br><img src="https://habrastorage.org/webt/0s/e6/c3/0se6c3ygspys909x3ju6m9aq7uu.gif"><br><h2>  Grafiken </h2><br>  Die empfangenen Daten <i>(oben beschrieben)</i> werden zum Senden von Warnungen und zum Erstellen von Diagrammen verwendet.  Wir zeichnen Graphen mit <b>Grafana</b> .  Ein wichtiges ‚ÄûDetail‚Äú ist hier <b>PromQL</b> , die Prometheus-Abfragesprache, die sich perfekt in Grafana integrieren l√§sst. <br><br><img src="https://habrastorage.org/webt/_a/sl/7w/_asl7wbfscz1eyxstacdij_liio.png"><br><br>  Es ist f√ºr die meisten Aufgaben recht einfach und bequem <i>(aber zum Beispiel ist das Beitreten zu Joins bereits unpraktisch, aber Sie m√ºssen es trotzdem tun)</i> .  Mit PromQL k√∂nnen Sie alle erforderlichen Aufgaben l√∂sen: schnell die erforderlichen Metriken ausw√§hlen, Werte vergleichen, arithmetische Operationen ausf√ºhren, gruppieren, mit Zeitintervallen arbeiten und vieles mehr.  Zum Beispiel: <br><br><img src="https://habrastorage.org/webt/3h/1d/0v/3h1d0vskm__dosoxpx1rzd5jis8.png"><br><br>  Dar√ºber hinaus verf√ºgt Prometheus √ºber einen <b>Evaluator</b> , der mit demselben PromQL mit der angegebenen H√§ufigkeit auf TSDB zugreifen kann.  Warum ist das so?  Beispiel: Beginnen Sie mit dem Senden von Warnungen in F√§llen, in denen gem√§√ü den verf√ºgbaren Metriken in den letzten 5 Minuten ein Fehler von 500 auf dem Webserver aufgetreten ist.  Zus√§tzlich zu den Beschriftungen, die in der Anforderung enthalten waren, f√ºgt Evaluator den Daten f√ºr Warnungen zus√§tzliche (wie von uns konfiguriert) <b>hinzu</b> . <b>Anschlie√üend</b> werden sie im JSON-Format an eine andere Prometheus-Komponente <b>gesendet</b> - <b>Alertmanager</b> . <br><br>  Prometheus sendet regelm√§√üig (alle 30 Sekunden) Warnungen an Alertmanager, die diese deduplizieren (nach Erhalt der ersten Warnung wird diese gesendet und die n√§chsten werden nicht erneut gesendet). <br><br><img src="https://habrastorage.org/webt/ju/0e/lg/ju0elg1u57wtxfjopy6wz38vtfg.png"><br><br>  <i><b>Hinweis</b> : Wir verwenden Alertmanager nicht zu Hause, sondern senden Daten von Prometheus direkt an unser System, mit dem unsere Mitarbeiter arbeiten. Dies spielt jedoch im allgemeinen Schema keine Rolle.</i> <br><br><h2>  Prometheus bei Kubernetes: Das gro√üe Ganze </h2><br>  Lassen Sie uns nun sehen, wie dieses gesamte Prometheus-Bundle in Kubernetes funktioniert: <br><br><img src="https://habrastorage.org/webt/w-/gu/ue/w-guue_2b8q12romg-qv7uw2hpi.png"><br><br><ul><li>  Kubernetes hat einen eigenen Namespace f√ºr Prometheus <i>(wir haben <code>kube-prometheus</code> in der Abbildung)</i> . </li><li>  Dieser Namespace hostet den Pod mit der Prometheus-Installation, die alle 30 Sekunden Metriken von allen Zielen sammelt, die √ºber Service Discovery im Cluster empfangen wurden. </li><li>  Es enth√§lt auch einen Pod mit Alertmanager, der Daten von Prometheus empf√§ngt und Warnungen sendet <i>(an Mail, Slack, PagerDuty, WeChat, Integration von Drittanbietern <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">usw.</a> )</i> . </li><li>  Prometheus steht vor einem Load Balancer - einem regul√§ren Dienst in Kubernetes - und Grafana greift √ºber diesen auf Prometheus zu.  Um <b>Fehlertoleranz</b> zu <b>gew√§hrleisten, verwendet Prometheus</b> mehrere Pods mit Prometheus-Installationen, von denen jeder alle Daten sammelt und in seiner TSDB speichert.  Durch den Balancer trifft Grafana einen von ihnen. </li><li>  Die Anzahl der Pods mit Prometheus wird durch die <i>StatefulSet-</i> Einstellung gesteuert. Normalerweise stellen wir nicht mehr als zwei Pods her, aber Sie k√∂nnen diese Anzahl erh√∂hen.  In √§hnlicher Weise wird √ºber StatefulSet auch ein Alertmanager bereitgestellt, f√ºr dessen Fehlertoleranz mindestens 3 Pods erforderlich sind (da ein Quorum erforderlich ist, um Entscheidungen √ºber das Senden von Alerts zu treffen). <br></li></ul><br>  Was fehlt hier? .. <br><br><h2>  F√∂deration f√ºr Prometheus </h2><br>  Wenn Daten alle 30 (oder 60) Sekunden erfasst werden, endet der Speicherort sehr schnell, und noch schlimmer, es sind viele Rechenressourcen erforderlich (beim Empfangen und Verarbeiten einer so gro√üen Anzahl von Punkten von TSDB).  Wir m√∂chten jedoch Informationen f√ºr <b>gro√üe <i>und</i> e Zeitintervalle</b> speichern und herunterladen k√∂nnen.  Wie erreicht man das? <br><br>  Es reicht aus, dem allgemeinen Schema, in dem Service Discovery deaktiviert ist, <b>eine weitere Installation von Prometheus</b> (wir nennen es <i>langfristig</i> ) hinzuzuf√ºgen, und in der Zieltabelle gibt es den einzigen statischen Datensatz, der zum Haupt-Prometheus ( <i>main</i> ) f√ºhrt.  <b>Dies ist dank des <a href="">Verbunds m√∂glich</a></b> : Mit Prometheus k√∂nnen Sie die neuesten Werte aller Metriken in einer einzigen Abfrage zur√ºckgeben.  Somit funktioniert die erste Installation von Prometheus weiterhin (Zugriff alle 60 oder beispielsweise 30 Sekunden) auf alle Ziele im Kubernetes-Cluster, und die zweite - alle 5 Minuten - empf√§ngt Daten von der ersten und speichert sie, um Daten f√ºr einen langen Zeitraum √ºberwachen zu k√∂nnen ( aber ohne tiefes Detail). <br><br><img src="https://habrastorage.org/webt/zc/uj/k3/zcujk3s5oxler1lhwaaswadmiyy.png"><br>  <i>F√ºr die zweite Prometheus-Installation ist keine Serviceerkennung erforderlich, und die Zieltabelle besteht aus einer Zeile</i> <br><br><img src="https://habrastorage.org/webt/od/zr/ow/odzrowlvdyq3qmhfldvy085naou.png"><br>  <i>Das ganze Bild mit Prometheus-Installationen von zwei Arten: Haupt (oben) und Langzeit</i> <br><br>  Der letzte Schliff besteht darin <b>, Grafana</b> mit beiden Prometheus-Installationen zu verbinden und auf besondere Weise Dashboards zu erstellen, damit Sie zwischen Datenquellen ( <i>Haupt-</i> oder <i>Langzeitdaten</i> ) wechseln k√∂nnen.  Ersetzen Sie dazu mithilfe der Vorlagen-Engine in allen Bedienfeldern die Variable <code>$prometheus</code> anstelle der Datenquelle. <br><br><img src="https://habrastorage.org/webt/ju/v3/9u/juv39un0v2qdtwegrt07qpg-1yi.png"><br><br><h2>  Was ist sonst noch in den Grafiken wichtig? </h2><br>  Zwei wichtige Punkte, die beim Organisieren von Zeitpl√§nen ber√ºcksichtigt werden m√ºssen, sind die Unterst√ºtzung von Kubernetes-Grundelementen und die M√∂glichkeit, schnell vom Gesamtbild (oder einer niedrigeren "Ansicht") zu einem bestimmten Dienst zu gelangen und umgekehrt. <br><br>  Die Unterst√ºtzung f√ºr Grundelemente (Namespaces, Pods usw.) wurde bereits erw√§hnt - dies ist im Prinzip eine notwendige Voraussetzung f√ºr ein komfortables Arbeiten in der Realit√§t von Kubernetes.  Und hier ist ein Beispiel zum Drilldown: <br><br><ul><li>  Wir betrachten die Diagramme des Ressourcenverbrauchs von drei Projekten (d. H. Drei Namespaces) - wir sehen, dass der Hauptteil der CPU (oder des Speichers oder des Netzwerks, ...) auf Projekt A f√§llt. </li><li>  Wir sehen uns die gleichen Grafiken an, aber bereits f√ºr die Dienste von Projekt A: Welche davon verbraucht die meiste CPU? </li><li>  Wir wenden uns den Diagrammen des gew√ºnschten Dienstes zu: Welcher Pod ist ‚Äûschuld‚Äú? </li><li>  Wir wenden uns den Diagrammen des gew√ºnschten Pods zu: Welcher Container ist "schuld"?  Das ist das gew√ºnschte Ziel! </li></ul><br><img src="https://habrastorage.org/webt/fq/vb/ly/fqvblyn0wdnoqqzqgwi0ublftjy.png"><br><h2>  Zusammenfassung </h2><br><ul><li>  Geben Sie genau an, was √úberwachung ist.  <i>(Lassen Sie sich von der ‚Äûdreischichtigen Torte‚Äú daran erinnern ... und daran, dass es auch ohne Kubernetes nicht einfach ist, sie kompetent zu backen!)</i> </li><li>  Denken Sie daran, dass Kubernetes obligatorische Details hinzuf√ºgt: Zielgruppierung, Serviceerkennung, gro√üe Datenmengen, Metadatenfluss.  Dar√ºber hinaus: <br><ul><li>  ja, einige von ihnen werden auf magische Weise ("out of the box") in Prometheus gel√∂st; </li><li>  Es bleibt jedoch noch ein weiterer Teil, der unabh√§ngig und sorgf√§ltig √ºberwacht werden muss. </li></ul></li></ul><br>  Und denken Sie daran, dass <b>Inhalte wichtiger sind als ein System</b> , d. H.  Richtige Diagramme und Warnungen sind prim√§r und nicht Prometheus (oder eine andere √§hnliche Software) als solche. <br><br><img src="https://habrastorage.org/webt/ml/61/ou/ml61oub7wmavnyfdmjepkm7bd-y.png"><br><br><h2>  Videos und Folien </h2><br>  Video von der Auff√ºhrung (ca. eine Stunde): <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/zj6SlzzBRaA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Pr√§sentation des Berichts: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  PS </h2><br>  Weitere Berichte in unserem Blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datenbanken und Kubernetes</a> ";  <i>(Dmitry Stolyarov; 8. November 2018 bei HighLoad ++)</i> ; </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beste CI / CD-Praktiken mit Kubernetes und GitLab</a> ‚Äú;  <i>(Dmitry Stolyarov; 7. November 2017 bei HighLoad ++)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unsere Erfahrung mit Kubernetes in kleinen Projekten</a> ";  <i>(Dmitry Stolyarov; 6. Juni 2017 bei RootConf)</i> ; </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mit dapp sammeln wir Docker-Images f√ºr CI / CD schnell und bequem</a> ‚Äú <i>(Dmitry Stolyarov; 8. November 2016 bei HighLoad ++)</i> ; </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kontinuierliche Lieferpraktiken mit Docker</a> ‚Äú <i>(Dmitry Stolyarov; 31. Mai 2016 bei RootConf)</i> . </li></ul><br>  Sie k√∂nnten auch an folgenden Ver√∂ffentlichungen interessiert sein: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Ger√§t und der Mechanismus des Prometheus-Betreibers in Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberwachung mit Prometheus in Kubernetes in 15 Minuten</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Infrastruktur mit Kubernetes als erschwinglichem Service</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de412901/">https://habr.com/ru/post/de412901/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de412891/index.html">Citrix XenServer 7.0 E / A nicht optimiert Management Agent nicht installiert</a></li>
<li><a href="../de412893/index.html">In vier Jahren einen erfahrenen Programmierer erreichen: die "School 21" -Methode</a></li>
<li><a href="../de412895/index.html">Vesta Matveeva: Der Kampf gegen Cyberkriminalit√§t ist eine moralische Entscheidung</a></li>
<li><a href="../de412897/index.html">√úberwachung von Atlassian-Produkten mit Prometheus</a></li>
<li><a href="../de412899/index.html">Wochenendlesung: 30 Materialien zu Ton, der Geschichte der Audiomarken und der Filmindustrie</a></li>
<li><a href="../de412903/index.html">Wie wir Habr gemalt haben</a></li>
<li><a href="../de412905/index.html">√úber LL-Parsing: Ein Ansatz zum Parsen durch das Konzept des String-Schneidens</a></li>
<li><a href="../de412911/index.html">Entwickler sprechen √ºber Funktionen, die aus Spielen herausgeschnitten wurden</a></li>
<li><a href="../de412913/index.html">"Baikal-T1" wurde f√ºr 3990 Rubel verkauft</a></li>
<li><a href="../de412915/index.html">Bestimmung der Gasdichte aus den Ergebnissen der Druck- und Temperaturmessung mit Arduino-Sensoren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
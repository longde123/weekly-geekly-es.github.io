<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✉️ 🎬 👸🏿 Programação heterogênea e oneAPI Toolkit. Palestra improvisada de especialistas da Intel responde às suas perguntas 🖲️ 💡 ❎</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Como parte da coluna "Faça uma pergunta a um especialista da Intel", solicitamos ao especialista em Intel Konstantin Vladimirov que respondesse pergun...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Programação heterogênea e oneAPI Toolkit. Palestra improvisada de especialistas da Intel responde às suas perguntas</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/479486/"><img src="https://habrastorage.org/webt/tz/b5/gv/tzb5gvt-1m1z3yvd4tjzot84ao4.jpeg"><br><br>  Como parte da coluna "Faça uma pergunta a um especialista da Intel", solicitamos ao especialista em Intel Konstantin Vladimirov que respondesse perguntas relacionadas à programação heterogênea, ao <a href="https//software.intel.com/en-us/oneapi">kit de ferramentas oneAPI</a> e a coisas interessantes relacionadas.  O resultado superou todas as nossas expectativas.  Konstantin não economizou tempo e deu respostas detalhadas e substanciadas, sem medo de ser polêmico.  De fato, recebemos uma pequena palestra sobre programação entre arquiteturas em todas as suas formas: descarregar nuances, otimizações, padrões e assim por diante. <br>  Transferimos o microfone para o especialista.  Bem, os comentários são dados ao público. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Pergunta <a href="https://habr.com/ru/users/soarex16/" class="user_link">Soarex16</a> <br><blockquote>  Quão trabalhosa será a transição do OpenCL para o oneAPI e quais benefícios podem ser obtidos com isso? </blockquote><br>  <b>A resposta</b>  Mudar para o DPC ++ pode ser complicado, mas, na minha opinião, vale a pena.  Existem dois estágios principais. <br><br>  Primeiramente, essa é uma transição da sua linguagem de programação heterogênea (OpenCL, computação Vulkan), que, provavelmente, é baseada na API.  Aqui você tem uma vantagem no fato de que você já conhece a área de assunto e a dificuldade está em mudar o pensamento do controle direto via API para construções de linguagem um pouco mais implícitas. <br>  Em segundo lugar, essa é uma transição do seu idioma host.  Se você descarregou toda a sua vida do C puro, o limite de entrada é igual ao limite para alternar de C para C ++, que é bastante alto. <br><br>  Por que tentar? <br><br>  Em primeiro lugar, o DPC ++ faz um ótimo trabalho para um programador.  Você esquecerá muito rapidamente, como um pesadelo, todas essas chamadas explícitas para clXXXYYY, e o que o sexto argumento significa, e se você esqueceu o código de retorno.  Muitos wrappers orientados a objetos não escondem a rotina, mas geralmente com o custo de alternar da API OpenCL padrão para a API wrapper não tão padrão (eu também vi essas bicicletas).  No caso do DPC ++, você simplesmente escreve o SYCL padrão com extensões Intel (que em breve também se tornará o SYCL padrão). <br><br>  Em segundo lugar, o DPC ++ fornece compilação conjunta, ou seja, você pode ter certeza dos tipos e não terá problemas nas bordas da API com dimensões, preenchimento, alinhamento.  Você escreve o código do kernel e do host em um arquivo e esse é o mesmo código.  Usando o USM, você também pode trabalhar com estruturas de dados complexas com muito mais facilidade. <br><br>  Em terceiro lugar, o DPC ++ é C ++ real, ou seja, permite programação generalizada.  Por exemplo, o kernel mais simples para adicionar dois vetores: <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> kern = [A, B, C](cl::sycl::id&lt;<span class="hljs-number"><span class="hljs-number">1</span></span>&gt; wiID) { C[wiID] = A[wiID] + B[wiID]; <span class="hljs-comment"><span class="hljs-comment">//   A, B  C?  ! };</span></span></code> </pre> <br>  A mesma coisa no OpenCL: <br><br><pre> <code class="cpp hljs">_<span class="hljs-function"><span class="hljs-function">kernel </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vector_add</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(__global </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *A, __global </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *B, __global </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *C)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = get_global_id(<span class="hljs-number"><span class="hljs-number">0</span></span>); C[i] = A[i] + B[i]; }</code> </pre> <br>  Você vê, fui forçado a apontar para um tipo OpenCL int.  Se eu precisar de um float, precisarei escrever outro kernel ou usar um pré-processador ou geração de código externo.  Obter quase todos os recursos do C ++ à sua disposição pode ser um pouco assustador se você não tiver experiência com o C ++.  Mas isso é comum quando se trata de uma grande mudança tecnológica. <br><br>  E todos os benefícios não se limitam a isso.  Mencionarei outra coisa nas respostas a seguir. <br><br>  Então, eu teria baixado o compilador em seu lugar e tentado, pois não é difícil fazer isso com o pacote <a href="https://software.intel.com/en-us/oneapi">OneAPI</a> . <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Question <a href="https://habr.com/ru/users/juster/" class="user_link">Juster</a> <br><blockquote>  O OpenVINO e o oneAPI estarão de alguma forma relacionados? </blockquote><br>  <b>A resposta</b>  A distribuição OpenVINO agora faz parte da distribuição OneAPI.  Aprender e usar redes neurais são tarefas computacionalmente difíceis que se beneficiam muito da programação heterogênea.  Acredito que, mais cedo ou mais tarde, todos os componentes OneAPI tornarão possível o uso de todos os recursos de computação disponíveis: aceleradores gráficos e aceleradores especiais como Nervana e FPGA.  E tudo isso sem sair do paradigma da linguagem e do sistema de tipos do seu programa C ++. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Perguntas do correio <br><blockquote>  Estou tentando entender como o acelerador de hardware de IA ficará em três anos. Por favor, ajude com isso.  Existe uma empresa interessante Graphcore e sua IPU - este dispositivo não é menos eficiente que o FPGA, mas é muito mais fácil programar - Python com suporte para TensorFlow e outras estruturas.  Acontece que, se as promessas da Graphcore forem cumpridas, não haverá necessidade de FPGAs no mercado de aprendizado de máquina.  O Python é muito mais conveniente para os cientistas de dados do que o C ++. <br>  Você concorda que o FPGA não é adequado para o mercado de aprendizado de máquina comparado às soluções programáveis ​​em Python?  Se o mercado de ML é perdido, que outros aplicativos FPGA comuns você vê? <br>  Em quais aplicativos você vê a necessidade inevitável de programação heterogênea, onde você não pode conviver com ferramentas mais convenientes, como Python? </blockquote><br>  <b>A resposta</b>  Olhei brevemente para que tipo de IPU.  Mais um pedaço de ferro no qual todos descarregarão.  Esses caras competem com a GPU e com aceleradores especiais, e não com o FPGA. <br><br>  Nas tarefas para as quais uma peça de hardware especializada é afiada, ela sempre vence o FPGA, por exemplo, a renderização de vídeo é melhor em uma placa de vídeo etc.  Mas no mundo (inclusive no mundo da ML) existem muitas tarefas para as quais nada de especial foi inventado ou lançado, e aqui o FPGA sempre será indispensável.  Por exemplo, porque existe uma questão de preço e, para ser barato, uma peça de hardware especializada deve ser enorme. <br><br>  Suponha agora que a IPU especificada é realmente legal.  Isso não cancelará a programação heterogênea; pelo contrário, a presença de um acelerador tão excelente o estimulará.  E também dará um avanço gigantesco no OneAPI e no DPC ++, porque mais cedo ou mais tarde alguém dirá "Eu quero usar tanto a sua IPU quanto a minha GPU em um programa".  Bem cedo, porque a programação heterogênea é sobre isso.  Seu significado é a transferência de uma tarefa adequada para um dispositivo adequado.  Uma tarefa pode vir de qualquer lugar.  E esse dispositivo pode ser qualquer coisa, pode até ser o mesmo dispositivo em que o programa está sendo executado.  Por exemplo, se você descarregar o kernel escrito no ISPC e utilizar os recursos vetoriais do Xeon ao máximo, poderá descarregá-lo você mesmo e ainda obter um ganho significativo.  O principal critério aqui é desempenho.  Bem, nunca haverá muita produtividade neste mundo.  Mesmo com os melhores aceleradores do mundo. <br><br>  Quanto ao Python e sua conveniência ... Devo admitir imediatamente que não gosto de linguagens dinamicamente digitadas: elas são lentas e, em vez de um erro de compilação normal, você deve esperar duas horas antes de cair no tempo de execução devido ao tipo errado.  Mas não vejo como é ruim fazer as mesmas descargas no Python.  A propósito, o OneAPI já inclui o Intel Distribution for Python, o que é extremamente conveniente para várias revisões. <br><br>  Ou seja, no mundo dos sonhos dos amantes de Python, você escreve um programa e o transfere para todos os aceleradores que pode encontrar usando o OneAPI, e não para um monte de bibliotecas específicas de fornecedores.  Outra coisa é que, com essa abordagem, você perde a digitação de ponta a ponta e retorna ao mundo extremamente precário da programação baseada em API.  Talvez o desenvolvimento do DPC ++ incentive a comunidade a usar mais ativamente ferramentas mais apropriadas, como C ++. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Pergunta do correio <br><blockquote>  Desempenho versus OpenCL.  Deve haver impostos sobre o luxo - ou seja,  custos indiretos.  Existem medidas? </blockquote><br>  <b>A resposta</b>  Na Internet, você pode encontrar muitas medições com diversos resultados, dependendo do compilador, da tarefa e da qualidade da implementação.  Como uma pesquisa pessoal, avaliei tarefas simples (SGEMM, DGEMM) no meu laptop (gráficos integrados do Skylake) e vi que, até agora, há algum problema (em porcentagem).  Mas parece-me que isso é uma conseqüência do fato de que tudo isso é beta até agora. <br><br>  Em teoria, o resultado deve ser aceleração, não desaceleração, ou seja, em princípio, todo esse luxo deve ter um valor negativo.  É tudo sobre o compilador.  Quando seu programa consiste em uma única fonte e é processado como um único programa, o compilador obtém oportunidades fantásticas e incríveis de otimização: definindo código comum, invertendo loops, reorganizando seções de código e tudo o mais que o compilador simplesmente não pode fazer na abordagem baseada em API, mas mais cedo ou mais tarde, ela definitivamente aprenderá com um único modelo de fonte. <br><br>  Além disso, o DPC ++ terá um custo negativo em termos de tempo de desenvolvimento.  Um exemplo simples são os acessadores SYCL, que o compilador já está usando para organizar eventos e gerenciar filas assíncronas. <br><br><pre> <code class="cpp hljs">deviceQueue.submit([&amp;](cl::sycl::handler &amp;cgh) { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> A = bufferA.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_read&gt;(cgh); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> B = bufferB.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_read&gt;(cgh); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> C = bufferC.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_write&gt;(cgh); .... deviceQueue.submit([&amp;](cl::sycl::handler &amp;cgh) { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> A = bufferA.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_read&gt;(cgh); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> B = bufferB.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_read&gt;(cgh); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> D = bufferD.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_write&gt;(cgh);</code> </pre><br>  Aqui, o compilador vê que os dois pacotes apenas lêem A e B e escrevem buffers independentes C e D; como resultado, ele vê a capacidade de enviá-los em paralelo, se houver tamanhos globais suficientes. <br><br>  Obviamente, um programa OpenCL gravado de forma pedestre também pode fazê-lo, mas o tempo de desenvolvimento gasto com um kernel não trivial não será comparável. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Pergunta do correio <br><blockquote>  Todas as maneiras de otimizar aplicativos OpenCL para DPC ++ são relevantes?  O que há de novo a ser adicionado a eles? </blockquote><br>  <b>A resposta</b>  Eu diria que a maior parte da sutil otimização manual que está sendo feita pelos gravadores do kernel pode e deve ser feita pelo compilador.  Da mesma forma, por exemplo, considero uma prática prejudicial instalar manualmente um assembler em linha em programas C ++, porque mesmo que ofereça benefícios táticos, ele interfere nas otimizações e atua como um fator negativo no desenvolvimento e na transferência de um produto.  Bem, o OpenCL agora também é montador. <br><br>  Quanto à resposta mais detalhada, tenho medo do abismo aqui.  Por exemplo, existe um documento Intel bem conhecido "Guia do desenvolvedor OpenCL para gráficos de processador Intel".  E há uma <a href="https://software.intel.com/en-us/iocl-opg-avoiding-needless-synchronization">seção</a> sobre como tentar, para não colocar onde o excesso de sincronização. <br><br>  Portanto, do meu ponto de vista, essa é uma tarefa não humana em princípio.  As pessoas são extremamente pobres em raciocinar sobre a sincronização multithread e tendem a esculpir a sincronização de maneira conservadora ou incorreta, ou ambas ao mesmo tempo - coloquei vírgulas como essa ( <i>mas foi corrigida - nota editorial</i> ). <br><br>  Por outro lado, no DPC ++, em vez de escrever código com barreiras explícitas, assim: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (t = <span class="hljs-number"><span class="hljs-number">0</span></span>; t &lt; numTiles; t++) { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tiledRow = TS * t + row; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tiledCol = TS * t + col; Asub[col][row] = A[globalRow * AY + tiledCol]; Bsub[col][row] = B[tiledRow * BY + globalCol]; <span class="hljs-comment"><span class="hljs-comment">// Synchronise to make sure the tile is loaded barrier(CLK_LOCAL_MEM_FENCE); // .... etc ....</span></span></code> </pre> <br>  Você provavelmente escreverá uma iteração explícita de <i>parallel_for_work_group</i> , dentro da qual <i>group.parallel_for_work_item</i> <br><br><pre> <code class="cpp hljs">cgh.parallel_for_work_group&lt;<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">mxm_kernel</span></span></span><span class="hljs-class">&gt;( </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">cl</span></span></span><span class="hljs-class">:</span></span>:sycl::range&lt;<span class="hljs-number"><span class="hljs-number">2</span></span>&gt;{BIG_AX / TS, BIG_BY / TS}, cl::sycl::range&lt;<span class="hljs-number"><span class="hljs-number">2</span></span>&gt;{TS, TS}, [=](cl::sycl::group&lt;<span class="hljs-number"><span class="hljs-number">2</span></span>&gt; group) { <span class="hljs-comment"><span class="hljs-comment">// .... etc .... for (int t = 0; t &lt; numTiles; t++) { group.parallel_for_work_item([&amp;](cl::sycl::h_item&lt;2&gt; it) { // .... etc .... Asub[col][row] = A[globalRow][tiledCol]; Bsub[col][row] = B[tiledRow][globalCol]; }); //      ,   </span></span></code> </pre> <br>  Como resultado, você não precisa definir a sincronização manualmente, e toda a seção pode ser descartada. <br><br>  E assim você pode andar em todas as seções.  Algo vai sobreviver, algo vai sair.  Prevejo o surgimento de um novo documento "Otimização para DPC ++", mas o tempo deve passar, pois todas as técnicas realmente úteis são desenvolvidas apenas mais tarde e com sangue <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Pergunta do correio <br><blockquote>  Há uma limitação no OpenCL - você não pode usar "dados distantes" no kernel, ou seja, por exemplo, implementar um "filtro amplo" que usa dados de entrada de um grande grupo de pixels maior que o grupo de trabalho OpenCL em um cálculo.  O que o DPC ++ oferece a esse respeito? </blockquote><br>  <b>A resposta</b>  Bem, isso é impossível.  Obviamente, não escrevo kernels em particular ... Mas é absolutamente certo que você pode usar toda a memória global como ela é, basta garantir que trabalhe com operações atômicas (ou sincronize externamente os kernels hierárquicos).  E você também pode conectar o System SVM (bem, ou o USM no DPC ++). <br><br>  Infelizmente, tudo isso é extremamente ineficiente, e eu não gosto de todos esses truques.  Além disso, eles são difíceis de otimizar pelo compilador. <br><br>  E assim, se falamos de soluções diretas e eficazes, é claro que não há mágica no DPC ++.  No final, seu programa ainda está dividido em partes: o código do host e o código do dispositivo, e todas as restrições do dispositivo afetam o código do dispositivo.  O tamanho máximo do grupo de trabalho é o paralelismo real de que seu hardware é capaz.  Tudo o que está em cima disso são apenas maneiras de sair, afetando drasticamente o desempenho.  É por isso que o DPC ++ oferece uma oportunidade para fazer isso: <i>device.get_info &lt;sycl :: info :: device :: max_work_group_size&gt; ()</i> e depois decide como viver com o número resultante. <br><br>  Seria tentador, é claro, criar um modelo no DPC ++, quando o programador trabalha como você gosta com loops de qualquer tamanho, e o compilador examina o que fazer a seguir, mas seria mortalmente errado, porque ocultaria constantes e até assintóticos de complexidade adicional computação aparecendo do nada.  Por outro motivo, Alexandrescu escreveu que "encapsular a complexidade deve ser considerado um crime", e isso também se aplica. <br><br>  Às vezes, revisar o próprio algoritmo ajuda.  Aqui, o DPC ++ facilita as coisas porque é mais fácil refatorar um código mais estruturado.  Mas isso é tão consolador. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Pergunta do correio <br><blockquote>  O DPC ++ é baseado em SYCL.  Mas e se você for mais fundo, quais são as diferenças do OpenCL na implementação do backend, se houver.  Por exemplo, o mecanismo de distribuição entre dispositivos heterogêneos é o mesmo que o OpenCL? </blockquote><br>  <b>A resposta</b>  Se você se esconder, esse é o OpenCL.  Todas as vantagens e vantagens do SYCL são as vantagens e os pontos fortes do idioma, ou seja, o frontend.  Do front-end, vem o bom e velho SPIRV, que vai para o back-end e lá é otimizado (geralmente já em tempo de execução, ou seja, é JIT) já para uma placa de vídeo específica da mesma maneira que o OpenCL seria otimizado para ela. <br><br>  Outra coisa é que o mecanismo de distribuição de trabalho entre dispositivos heterogêneos é apenas mais front-end que back-end, porque é o código do host que decide o que enviar e para onde.  E o código do host é obtido no DPC ++.  Eu já mostrei um exemplo um pouco mais alto de como o compilador pode, com base nos acessadores, tomar uma decisão sobre pacotes paralelos.  E esta é apenas a ponta do iceberg. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Pergunta do correio <br><blockquote>  Bibliotecas  Sim, não estamos falando de CUDA.  Mas sabemos que, para desenvolvedores de CUDA, existem bibliotecas muito úteis que funcionam com alto desempenho na GPU.  O OneAPI também contém algumas bibliotecas, mas, por exemplo, <a href="https://software.intel.com/en-us/ipp">IPP</a> - não há nada útil de arquivamento para trabalhar com imagens no oneAPI / OpenCL.  Haverá algo e como, neste caso, mudar de CUDA para oneAPI? </blockquote><br>  <b>A resposta</b>  A transição da CUDA para um único padrão aberto será difícil, mas inevitável.  Obviamente, a CUDA agora tem uma infraestrutura mais madura.  Mas as características de seu licenciamento são uma desvantagem de bloqueio, porque cada vez mais players aparecem no mercado de sistemas heterogêneos, cartões e aceleradores cada vez mais interessantes de diferentes fabricantes. <br><br>  A diversidade de APIs existentes dificulta o uso desse mundo de possibilidades para programadores com experiência na CPU clássica.  O que leva ao OneAPI ou algo parecido.  Aqui a mágica não está na inovação da Intel nos gráficos, mas no fato de que a Intel abre a porta do DPC ++ para todos.  Nós nem possuímos o padrão SYCL, ele pertence ao grupo Khronos e todas as extensões Intel são extensões no Khronos onde qualquer pessoa pode se comprometer (e há representantes de todos os principais players do país).  E isso significa que (as bibliotecas) e a comunidade aparecerão (já estão aparecendo) e várias vagas nessa direção. <br><br>  E, é claro, o IPP será reescrito para novas realidades.  Não tenho nada a ver com IPP, mas o uso do DPC ++ é senso comum, e pessoas sãs estão sentadas lá. <br><br>  Mas o mais importante é que agora é o momento da história em que você pode escrever sua própria biblioteca, que ultrapassará o IPP e que o mundo inteiro usará.  Porque os padrões abertos sempre vencem. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="imagem">  Pergunta do correio <br><blockquote>  Se compararmos o lançamento de algoritmos de redes neurais de treinamento e inferência no Nervana e FPGA - quais são as diferenças na programação e a eficiência resultante? </blockquote><br>  <b>A resposta</b>  Não sei nada sobre detalhes de programação de FPGA, escrevo compiladores.  Mas eu tenho uma contra-pergunta.  E como vamos comparar?  Em benchmarks padrão, é antidesportivo, Nervana lambeu embaixo deles.  Mas caso você tenha algo interessante, o FPGA desamarra as suas mãos, e colocar isso em Nervana pode ser longo, caro, só isso. <br><br>  Acontece que a pergunta em si é, por assim dizer, da série "quem é mais forte que um elefante ou uma baleia".  Mas essa não é uma pergunta real.  A verdadeira questão é: como aproveitar um elefante e uma baleia em um carrinho?  Bem, ou pelo menos distribua, digamos, um elefante para puxá-lo por terra e uma baleia por mar. <br><br>  No caso do OneAPI, você terá o mesmo programa, em geral, em C ++ padrão.  E você pode escrevê-lo e executá-lo com descarregamento para frente e para trás.  Essa será a mesma tarefa que lhe interessa, na qual você mesmo pode medir e otimizar o desempenho.  Um padrão único e uma interface única para dispositivos heterogêneos serão um passo para comparar maçãs com maçãs em tais assuntos. <br><br>  Por exemplo: “o que é melhor para% da minha tarefa% do ponto de vista da facilidade de programação e eficiência - coloque essa parte no FPGA, deixe essa no Nervana ou divida essa parte em duas e reescreva essa parte para a GPU?” <br><br>  E a história toda com a OneAPI - é apenas para você dizer: "por que pensar nisso por um longo tempo, vou tentar agora rapidamente, é SIMPLES". <br><br>  Ainda não, não é fácil.  Mas haverá. <br><br><hr><br>  <b>Posfácio do especialista</b> <br><br>  Obrigado a todos por suas perguntas.  É possível e até provável que eu estivesse errado, impreciso e cometi erros.  Acontece que, na Internet, constantemente alguém está errado. <br><br>  Espero poder interessar alguém em programação heterogênea e DPC ++.  Quero recomendar a todos o site <a href="https://sycl.tech/">sycl.tech</a> , onde <a href="https://sycl.tech/">existem muitos</a> relatórios, inclusive de especialistas de renome mundial (é necessário inglês) <br><br>  Bom para todos! <br><br>  <i>PS do editor.</i>  <i>Desta vez, por decisão unânime do conselho editorial, foi decidido atribuir o prêmio pela melhor pergunta ... ao autor das respostas.</i>  <i>Eu acho que você concorda que isso é justo.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt479486/">https://habr.com/ru/post/pt479486/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt479468/index.html">Edge of Honesty e John Doe</a></li>
<li><a href="../pt479474/index.html">Por que a auto-organização de equipes é tão importante no Scrum e por que não pode haver gerentes nele</a></li>
<li><a href="../pt479478/index.html">Plug-in Java sem problemas</a></li>
<li><a href="../pt479480/index.html">SARIF SDK e seus erros</a></li>
<li><a href="../pt479482/index.html">SARIF SDK e seus erros</a></li>
<li><a href="../pt479488/index.html">De um laptop - um servidor doméstico com energia redundante ao roteador Mikrotik</a></li>
<li><a href="../pt479492/index.html">Computação sem servidor baseada no OpenWhisk, parte 3</a></li>
<li><a href="../pt479496/index.html">Analisando tarefas WTF em JavaScript</a></li>
<li><a href="../pt479498/index.html">Como o tempo linear se transforma no Windows em O (n²)</a></li>
<li><a href="../pt479502/index.html">Como sobreviver à era glacial mais severa da história da Terra?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游뱣游 游꿂 游뚶 Prueba de resistencia de GPU NVidia en la transcodificaci칩n de transmisi칩n en vivo 游땘 游 游뱠游낗</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A continuaci칩n se muestra una historia detallada sobre c칩mo cargamos la tarjeta de NVidia con las tareas de transcodificar video para su transmisi칩n. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Prueba de resistencia de GPU NVidia en la transcodificaci칩n de transmisi칩n en vivo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/401539/">  <i>A continuaci칩n se muestra una historia detallada sobre c칩mo cargamos la tarjeta de NVidia con las tareas de transcodificar video para su transmisi칩n.</i>  <i>Demostremos que probamos lo que sucedi칩 y la mejor manera de usar tarjetas de video para transmitir en l칤nea.</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/files/7ef/cc6/50b/7efcc650b901459bbb5addc4fe8d6bd3.png"></div><a name="habracut"></a>  Durante varios a침os, nuestro equipo ha estado desarrollando productos para procesar y distribuir contenido multimedia en l칤nea.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Este art칤culo describi칩</a> recientemente por qu칠 los propietarios de contenido podr칤an necesitar tales soluciones en nuestra era de YouTube. <br><br>  Uno de nuestros productos es el servidor de medios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nimble Streamer</a> , que es un software de servidor que lleva las transmisiones en vivo y los archivos a la entrada y los hace accesibles a una gran cantidad de espectadores, mientras que simult치neamente le permite monetizar el contenido.  Esta es una aplicaci칩n nativa escrita en C ++ y portada a todos los sistemas operativos y plataformas populares (Linux, Windows, MacOS) (x64, ARM).  Desde el principio, el bajo consumo de recursos y la alta productividad fueron los requisitos principales, y logramos lograr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">buenos resultados</a> en esto. <br><br>  El a침o pasado, lanzamos el complemento Nimble Streamer: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transcodificador de transmisi칩n en vivo</a> .  Esta aplicaci칩n le permite tomar el flujo de entrada de video y / o audio en diferentes formatos y hacer varias conversiones con ellos en tiempo real.  La funcionalidad incluye decodificaci칩n (software y hardware), conversi칩n de video y audio mediante filtros (cambio de tama침o, superposici칩n, etc.) y codificaci칩n (codificaci칩n), tanto de software como de hardware. <br><br>  El transcodificador se controla a trav칠s del servicio web WMSPanel, los scripts de transcodificaci칩n se crean a trav칠s de la interfaz de arrastrar y soltar, que le permite ver visualmente el proceso.  Se pueden ejecutar varios escenarios juntos: con este enfoque es conveniente ejecutar combinaciones de prueba, cargando el servidor en cualquier variaci칩n. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">En estos videos</a> puede ver ejemplos de c칩mo funciona la interfaz. <br><br>  La decodificaci칩n de cada flujo se realiza solo una vez antes de todas las conversiones adicionales ... Esto le permite ahorrar recursos en una operaci칩n de decodificaci칩n costosa, esto se ver치 claramente a lo largo de las pruebas. <br><br>  Uno de los mecanismos de conversi칩n que se pueden usar en nuestro transcodificador es la decodificaci칩n de hardware y la codificaci칩n de video utilizando la GPU de NVidia.  Las tarjetas gr치ficas de las 칰ltimas generaciones le permiten asumir algunas de las tareas t칤picas, lo que elimina la carga de la CPU.  Nuestro transcodificador puede trabajar con este hardware, que nuestros clientes utilizan activamente. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/460/a36/96e/460a3696ed2e4f1e8d7491ecc4e7c2ca.png"></div><br>  En el curso de la comunicaci칩n con representantes de la oficina rusa de NVidia, se nos pidi칩 que intentemos organizar pruebas de estr칠s conjuntas de nuestro transcodificador y GPU NVidia para comprender cu치l ser치 el efecto econ칩mico de tal t치ndem en comparaci칩n con la transcodificaci칩n exclusiva de software, sin aceleraci칩n de hardware.  Adem치s, quer칤a entender c칩mo usar de manera 칩ptima la GPU y, si es posible, dar buenas recetas. <br><br>  Necesit치bamos obtener r치pidamente el hierro apropiado y acceder a 칠l, para el ciclo de nuestros experimentos.  Planeamos encontrarnos un par de semanas.  Queda por encontrar d칩nde conseguir el equipo.  La mejor opci칩n ser칤a encontrarlos en la nube y obtener acceso remoto.  Despu칠s de buscar las opciones, result칩 que AWS a칰n no tiene una VM con una GPU de generaci칩n Maxwell, y en la nube de Azure, solo est치 previsto comenzar a proporcionarlas pronto. <br><br><h2>  1. Hierro de NVidia en la nube de Softlayer, configurando Nimble Streamer </h2><br>  Con la asistencia de NVidia, IBM nos proporcion칩 acceso a su nube, la plataforma IBM Bluemix Cloud Platform (anteriormente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Softlayer</a> ).  Esta es una gran red de centros de datos modernos (alrededor de 50 en el momento de la publicaci칩n) en todo el mundo, conectados por una red privada com칰n y que proporcionan una gran selecci칩n de servicios de infraestructura en la nube.  Todos los centros de datos est치n unificados y le permiten alquilar de uno a cientos de servidores virtuales o f칤sicos de la configuraci칩n requerida durante varias horas, as칤 como equilibradores, sistemas de almacenamiento, firewalls; en general, todo lo que se requiere para construir una infraestructura de TI confiable para el servicio de TI implementado. <br><br>  La oficina de representaci칩n rusa de IBM nos dio acceso completo al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">portal de autoservicio</a> para administrar los servicios en la nube y a la configuraci칩n del servidor necesaria, donde pudimos trabajar con diferentes flujos de entrada y configuraciones de nuestro transcodificador. <br><br><h3>  Hierro </h3><br>  Primero, nos dieron un servidor f칤sico (metal) con 128 GB de RAM y 2xGPU NVidia Tesla M60 y sistema operativo Ubuntu 14.04 preinstalado.  Todos los par치metros del servidor, contrase침as, versiones de firmware, su conmutaci칩n, IP dedicada, el estado de los componentes de hardware, eran visibles directamente en su cuenta personal, lo que le permite hacer las manipulaciones necesarias con el hardware alquilado, lo que minimiza la necesidad de interacci칩n con el soporte de IBM.  Durante la ejecuci칩n de la prueba, result칩 que no pudimos cargar de manera 칩ptima esta configuraci칩n, debido a una serie de limitaciones en la generaci칩n de contextos. <br><br>  Quer칤amos reducir la configuraci칩n.  Como utilizamos la plataforma en la nube, fue necesario a trav칠s del portal de autoservicio para solicitar cambios de configuraci칩n.  Despu칠s de la aprobaci칩n, esta operaci칩n tard칩 aproximadamente 2 horas en la ventana de servicio aprobada.  Durante este tiempo, el personal t칠cnico del centro de datos de Amsterdam elimin칩 componentes adicionales (ranuras RAM y 1xGPU) del servidor que nos proporcionaron antes y lo devolvi칩 a la operaci칩n.  Debe tenerse en cuenta que para los desarrolladores esta opci칩n es muy conveniente, ya que no es necesario ocuparse de la configuraci칩n del hardware, repararla o incluso pasar tiempo instalando el sistema operativo.  Perm칤tame recordarle que en este caso el hipervisor no se utiliza porque necesitamos exprimir al m치ximo los recursos de hardware. <br><br>  En base a los resultados de nuestra investigaci칩n, nos decidimos por la siguiente configuraci칩n del servidor: <br><blockquote>  Doble Intel Xeon E5-2690 v3 (2.60GHz) <br>  24 n칰cleos <br>  64 GB de RAM <br>  1 TB SATA <br></blockquote><br>  Tenemos 2 procesadores con 12 n칰cleos cada uno, y gracias a Hyper Threading obtenemos el doble, es decir  virtualmente 48 n칰cleos. <br><br>  En escenarios con un acelerador de gr치ficos, se utiliz칩 una tarjeta basada en el chip GM204 - Tesla M60: <br><blockquote>  NVIDIA Tesla M60 <br>  1xGPU: 2 x Maxwell GM204 <br>  Memoria: 16 GB GDDR5 <br>  Velocidad de reloj: 2.5 GHz <br>  N칰cleos NVIDIA CUDA: 2 x 2048 <br>  Ancho de banda de memoria: 2 x 160 GB / seg. </blockquote><br>  Le llamo la atenci칩n sobre el hecho de que no se realiz칩 ninguna afinidad, ajuste de chip, overclocking u otra magia en el hardware reducido, solo CPU y GPU no overclockeadas, y para la GPU solo se utiliz칩 el controlador oficial tomado del sitio web de NVidia.  Si alguien tiene una experiencia similar, comparta en los comentarios. <br><br>  Entonces, tenemos acceso.  Un r치pido conocimiento de la interfaz web del panel de control (todo es simple y claro all칤), luego acceder al servidor a trav칠s de SSH, y aqu칤 estamos en la l칤nea de comandos habitual de Ubuntu, poner Nimble Streamer, registrar una licencia de transcodificador nueva y hacer una peque침a configuraci칩n de configuraci칩n. <br><br><h3>  Transcodificador 치gil streamer </h3><br>  Nimble Streamer se configur칩 para crear previamente el cach칠 de contexto de GPU.  Esto se debe al hecho de que la GPU tiene un l칤mite en el n칰mero m치ximo de contextos de decodificaci칩n y codificaci칩n creados, y adem치s, crear contextos sobre la marcha puede tomar demasiado tiempo. <br>  Se pueden encontrar m치s detalles sobre el problema de crear contextos en la secci칩n correspondiente a continuaci칩n. <br><br>  Configuraci칩n de Nimbl en el ejemplo de la primera serie de pruebas: <br><blockquote>  nvenc_context_cache_enable = true <br>  nvenc_context_create_lock = true <br>  nvenc_context_cache_init = 0: 30: 15.1: 30: 15 <br>  nvenc_context_reuse_enable = true </blockquote><br>  M치s detalles sobre estas configuraciones est치n escritos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en nuestro art칤culo</a> . <br><br>  Antes de comenzar cada serie de pruebas, el cach칠 se configur칩 por separado, teniendo en cuenta los detalles de cada tarea. <br><br><h3>  Crear scripts de transcodificaci칩n </h3><br>  Se sigui칩 trabajando en nuestro servicio WMSPanel, donde se configuran los scripts del transcodificador. <br><br>  Como ya se mencion칩, el trabajo pasa por la interfaz web, todo es extremadamente claro y conveniente.  Creamos una serie de escenarios que combinan diferentes opciones de transcodificaci칩n (CPU / GPU), diferentes opciones de resoluci칩n y diferentes par치metros de codificaci칩n (CPU / GPU, perfil, velocidad de bits, etc.) <br><br>  Se pueden ejecutar conjuntos de escenarios simult치neamente, lo que permite introducir varias combinaciones de pruebas, aumentar la carga en un orden diferente y cambiarla seg칰n la situaci칩n.  Simplemente seleccione los escenarios necesarios y det칠ngalos o rean칰delos. <br><br>  Aqu칤 hay un conjunto de escenarios: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/cd6/197/b77/cd6197b77e6b4c0697f43f8d1cfaaf07.png"></div><br>  Aqu칤 hay un ejemplo de uno de los escenarios: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e47/1ff/924/e471ff9244f240edb2c092f42d5cf721.png"></div><br>  El decodificador de GPU se ve as칤: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/382/0f8/2fd/3820f82fd74e4e0ea106534962e1ba28.png"></div><br>  Aplicamos el filtro de tama침o de imagen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9d3/bd0/eab/9d3bd0eab2ac47d4b3183aca91db0d6f.png"></div><br>  Y aqu칤 est치 el codificador para la variante GPU: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/212/d34/e2e/212d34e2e3cf425a9f94d03194f7c62d.png"></div><br><br>  En general, el funcionamiento de la interfaz del transcodificador se puede <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ver en estos videos</a> . <br><br><h2>  2. Transcodificaci칩n de transmisiones FullHD 1080p </h2><br>  Para empezar, probamos el escenario con las cargas m치s altas para descubrir los l칤mites de las capacidades de hierro.  Por el momento, la "m치s pesada" de las resoluciones utilizadas en la pr치ctica es FullHD 1080p. <br><br>  Para generar las transmisiones en vivo originales, se tom칩 un archivo en <b>FullHD</b> (1920 * 1080) en <b>H.264 de alto perfil</b> .  El contenido en s칤 es un video tour de la ciudad, es decir  Este es un video con una tasa de cambio de imagen promedio.  No hay marcos est치ticos de un solo color que puedan facilitar el trabajo del transcodificador, pero no hay un cambio demasiado r치pido de tipos y colores.  En una palabra: una carga bastante t칤pica. <br><br>  Se alimentaron <b>36 transmisiones id칠nticas</b> a la entrada de Nimble Streamer, que luego se utilizaron en el transcodificador en diferentes escenarios. <br><br>  El escenario de transcodificaci칩n se usa t칤picamente: la transmisi칩n entrante es de perfil alto de <b>1080p</b> , perfil principal de <b>720p, 480p, 360p</b> y luego las secuencias de <b>perfil de l칤nea de base</b> se hacen a partir de ella <b>: 240p, 160p</b> .  En total, hay 1 flujo en la entrada y 5 en la salida. Por lo general, tambi칠n se realiza un paso (transferencia sin cambios) del flujo original para que el espectador pueda seleccionar 1080p mientras visualiza.  No lo agregamos en el script, porque  no utiliza transcodificaci칩n: hay una transferencia directa de datos de entrada a salida.  Este escenario est치 optimizado en Nimble y en condiciones reales aumentar치 el consumo de memoria de forma relativamente leve. <br>  Audio en las secuencias generadas - no.  Agregar audio al script no causar치 cargas significativas de CPU, pero por la pureza del experimento, excluimos el sonido. <br><br><h3>  Prueba de CPU, sin GPU </h3><br>  Para comenzar, lanzamos scripts de transcodificaci칩n sin usar una GPU, especificando el decodificador y codificador de software en los scripts. <br><br>  Como resultado, fue posible procesar solo 16 flujos de entrada con la emisi칩n de 80 flujos de todos los permisos de salida. <br><br>  Carga de CPU: 4600%, es decir  46 n칰cleos estuvieron involucrados.  Consumo de RAM: aproximadamente 15 GB. <br><br><h3>  Prueba de CPU + GPU </h3><br>  La memoria cach칠 de contexto al inicio se configura como 0: 30: 15.1: 30: 15, es decir  30 contextos para codificar, 15 para decodificar, cada GPU. <br><br>  Perm칤tame recordarle que en la GPU tenemos dos n칰cleos, lo que nos permite paralelizar las tareas, esto es 칰til para nosotros. <br><br>  La carga m치xima se obtuvo con la siguiente configuraci칩n de flujo. <br><br>  El decodificador de entrada GPU0 y GPU1 - 15 flujos.  De este modo, obtenemos 30 secuencias decodificadas, listas para su uso posterior.  Cada secuencia se decodifica solo una vez, sin importar cu치ntos escenarios se use en el futuro. <br><br>  Los codificadores GPU0 y GPU1 recibieron 15 transmisiones cada uno para obtener 720p, es decir.  Se produjeron 30 transmisiones de 720p en una salida. <br><br>  Adem치s, los codificadores GPU0 y GPU1 proporcionaron cada uno 15 flujos para 480p, y tambi칠n se emitieron 30 flujos de 480p. <br><br>  Como los contextos del codificador se agotaron, la codificaci칩n de los permisos restantes se estableci칩 en la CPU.  Result칩 lo siguiente: <br><br><ol><li>  30 transmisiones 360p </li><li>  30 transmisiones 240p </li><li>  30 transmisiones 160p </li></ol><br>  La carga result칩 ser 2600% de CPU, 75% de decodificador, 32% de codificador.  Luego, la CPU se carg칩 con 6 transmisiones para decodificar, por cada 5 resoluciones similares configuradas, para un total de 30 hilos por salida. <br><br>  En total, se recibieron <b>36 transmisiones en la entrada, 180 se emitieron en la salida</b> .  La carga final se repara de la siguiente manera: <b>4400% de CPU, 75% de decodificador de tarjeta, 32% de codificador de tarjeta, 30 GB de RAM</b> . <br><br><h3>  Algunos detalles </h3><br>  Decidimos verificar la opci칩n en la que procesamos las tareas m치s dif칤ciles en la GPU: decodificar 1080 y codificar 720 y 480, y dejar que el resto se procese a trav칠s de la CPU. <br><br>  Primero, verificamos el l칤mite del decodificador.  Con 22 hilos, la decodificaci칩n se vio afectada por el problema de los contextos, simplemente no se pudieron crear.  Disminuy칩 a 21: se crearon contextos, pero la carga se volvi칩 100% y los artefactos comenzaron a observarse en la secuencia.  Nos detuvimos en 20 transmisiones, decodificamos 20 transmisiones, codificamos a 160p, todo funciona bien. <br><br>  Adem치s, result칩 emp칤ricamente que esta tarjeta con 16 GB de RAM a bordo puede funcionar con confianza en 47 contextos, y no hay diferencia, estos son los contextos de un codificador o decodificador.  Repito: se trata espec칤ficamente de esta GPU Tesla M60, en otras tarjetas este n칰mero puede ser diferente.  Creemos que si la tarjeta tuviera 24 GB de RAM, el n칰mero de contextos podr칤a ser diferente, pero esto debe ser probado. <br><br>  Como resultado, elegimos la f칩rmula de creaci칩n de cach칠 "15 contextos del decodificador y 30 contextos del codificador", que proporciona 30 secuencias a la entrada y para cada una le permite crear 2 permisos.  Entonces, las resoluciones superiores, 720 y 480, se lanzaron en la GPU, y el resto, 360, 240 y 160, se enviaron a la CPU.  Y como la CPU a칰n estaba libre despu칠s de eso, "terminamos" los n칰cleos libres con nuevos hilos, dejando 4 n칰cleos para tareas utilitarias. <br><br><h2>  3. Transcodificaci칩n de transmisiones HD 720p </h2><br>  Escenario de carga t칤pica  La mayor parte del contenido ahora se crea en HD.  Incluso el reciente SuperBowl LI, el programa mejor calificado en el mercado estadounidense, se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transmiti칩 en HD</a> , dejando FullHD para el futuro. <br><br>  Para generar las secuencias de origen, se tom칩 un archivo en <b>HD</b> (1280 * 720) en un <b>perfil alto</b> .  El contenido es la serie favorita de "The Good Wife" de nuestro ingeniero, es decir  Este es un video con una tasa de cambio de imagen promedio. <br><br>  En la entrada del Nimble Streamer, se alimentaron 70 transmisiones id칠nticas, que luego se utilizaron en el transcodificador en diferentes escenarios. <br><br>  Se utiliza el siguiente escenario de transcodificaci칩n: la transmisi칩n entrante es de <b>720p de</b> perfil alto, <b>480p, perfil principal de 360p</b> y luego se hacen <b>240p, 160p l칤neas de</b> perfil de <b>l칤nea base</b> .  Total, en la entrada 1, en la salida 4. No se realiz칩 el paso de la secuencia original, como en el escenario anterior.  El audio en las secuencias generadas tampoco lo es. <br><br><h3>  Prueba de CPU, sin GPU </h3><br>  Como en la secci칩n anterior, intentamos transcodificar secuencias solo en la CPU.  Como resultado, fue posible procesar solo 22 flujos de entrada con la emisi칩n de 88 flujos de todos los permisos de salida.  Carga de CPU: 4700%, es decir  Participaron 47 n칰cleos.  Consumo de RAM: aproximadamente 20 GB. <br><br><h3>  Prueba de CPU + GPU </h3><br>  La memoria cach칠 de contexto al inicio se configura como 0: 23: 23.1: 23: 23, es decir  23 contextos para codificar, 23 para decodificar para cada GPU. <br><br>  Usando la GPU, se decodificaron 46 secuencias de 720p.  All칤, en la GPU, se codificaron 46 secuencias de 480p.  A continuaci칩n, se realizaron codificaciones de 360p, 240p y 160p en la CPU: 46 transmisiones cada una. <br>  Carga fija de 2100% de CPU, 61% del decodificador, 16% del codificador. <br><br>  Adem치s, se lanz칩 la codificaci칩n y decodificaci칩n de 24 subprocesos a la CPU, por cada 1 subproceso - 4 salidas, como para la GPU. <br><br>  En total, <b>se ingresaron 70 secuencias, se emitieron 280 secuencias</b> . <br>  Carga: <b>4600%, 61% del decodificador, 16% del codificador, 30 GB de RAM</b> . <br><br>  En cuanto a la prueba anterior, quiz치s una GPU RAM m치s grande dar칤a m치s contextos y podr칤amos manejar m치s hilos.  Pero esto es solo en teor칤a, es necesario verificarlo. <br><br><h2>  4. El problema con la creaci칩n de contextos en la GPU NVidia </h2><br>  Algunas palabras sobre el problema que no nos permitieron procesar m치s subprocesos en la GPU. <br><br>  A fines del a침o pasado, realizamos pruebas con el equipo de NVidia, con varias tarjetas.  Al trabajar con m칰ltiples GPU, result칩 que la creaci칩n de contextos ralentiza enormemente el servidor: la creaci칩n de cada nuevo contexto tom칩 m치s y m치s tiempo del mapa.  Si el primer contexto se cre칩 en el orden de 300 ms, cada uno de los siguientes agreg칩 200-300 ms y ya en los terceros diez contextos, crear uno nuevo tom칩 3-4 segundos cada uno.  Cuando un usuario crea un script de transcodificaci칩n, se supone que comienza a trabajar de inmediato y sin demoras, y esta nueva circunstancia neg칩 todas las ventajas en la velocidad de Nimbl y dio demoras en la creaci칩n de contextos que condujeron a demoras en el inicio de la codificaci칩n. <br><br>  Al principio, la sospecha recay칩 en Nimble, pero luego hicimos pruebas usando ffmpeg, que NVidia proporciona a los clientes y el resultado fue exactamente el mismo: la GPU est치 gastando m치s y m치s tiempo creando cada nuevo contexto.  En condiciones en las que el servidor ya est치 transcodificando y necesita iniciar nuevos subprocesos para el procesamiento, esto afecta el rendimiento general y hace que el servidor simplemente sea inutilizable. <br><br>  El problema fue descrito en detalle por el equipo de NVidia, pero hasta ahora no se ha proporcionado una soluci칩n a tiempo completo.  Por lo tanto, hasta ahora hemos implementado un mecanismo de almacenamiento en cach칠 de contexto en nuestro servidor, con la creaci칩n preliminar de contextos al inicio del servidor.  Esto resolvi칩 el problema desde el punto de vista del trabajo del usuario final, pero el inicio del Nimbl puede llevar algo de tiempo.  La configuraci칩n de Nimbl para un trabajo efectivo con contextos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se describe en nuestro blog</a> . <br><br>  Adem치s, los contextos no son f치ciles de crear.  Con una gran cantidad de contextos al incluir cualquier script de transcodificaci칩n, la API de NVENC comienza a arrojar errores: "La llamada a la API fall칩 porque no pudo asignar suficiente memoria para realizar la operaci칩n solicitada". <br><br>  Emp칤ricamente, result칩 que una GPU puede comenzar y trabajar con confianza en 47 contextos, y no hay diferencia, estos son los contextos de un codificador o decodificador.  Se supon칤a que esto se deb칤a a la cantidad de memoria en la GPU.  Ahora hay 16 GB, si coloca una tarjeta con 24 GB, es probable que se puedan hacer m치s contextos.  Pero esto es solo una teor칤a, es necesario verificar, como se mencion칩 anteriormente.  Los datos obtenidos son v치lidos para un modelo de GPU espec칤fico, otras tarjetas deben probarse por separado. <br><br>  Es la restricci칩n en el n칰mero de contextos lo que pone el obst치culo principal cuando se trabaja con grandes cargas. <br><br><h2>  5. Conclusiones </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por lo tanto, el prop칩sito de las pruebas era estudiar la efectividad de la GPU para el rango de tareas indicado y desarrollar recetas para su uso adecuado. </font><font style="vertical-align: inherit;">Cual es el resultado?</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Efecto econ칩mico </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Arriba, vimos c칩mo la cantidad de subprocesos que se pueden procesar en la CPU y en el t치ndem CPU + GPU es diferente. </font><font style="vertical-align: inherit;">Veamos qu칠 significa esto en t칠rminos de dinero. </font><font style="vertical-align: inherit;">Como base tomamos los mismos Softlayer y los precios de alquiler de sus equipos.</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La configuraci칩n sin una GPU costar치 </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 819 por mes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aqu칤 puedes recoger un</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auto.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La configuraci칩n con la GPU costar치 </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 1729 por mes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para el centro de datos en Amsterdam, los precios se pueden </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">encontrar aqu칤</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Cuando se usa una GPU, el precio de alquiler del servidor aumenta ligeramente, ya que se usa el factor de forma de caso 2U m치s grande. </font><font style="vertical-align: inherit;">El efecto econ칩mico probablemente ser치 mayor al comprar equipos (pero esto requiere un an치lisis serio del TCO, teniendo en cuenta la actualizaci칩n constante de la l칤nea de GPU NVidia).</font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ahora veamos los resultados de la prueba: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para FullHD 1080p</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU sin GPU: 16 hilos por entrada + 80 hilos por salida </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU + GPU: 36 hilos por entrada + 180 por salida </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficio de GPU: 2.25x. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficios</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> del uso de la GPU: $ 819 * 2.25 - $ 1729 = </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 113 por mes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> al alquilar 1 servidor con una GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para HD 720p</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU sin GPU: 22 hilos por entrada + 88 hilos por salida </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU + GPU: 70 hilos por entrada + 280 por salida </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficio de GPU: 3.18x. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficio</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de usar la GPU: $ 819 * 3.18 - $ 1729 = </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 875 por mes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> al alquilar 1 servidor con una GPU </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es decir, con la opci칩n de alquiler, los ahorros son bastante notables. </font><font style="vertical-align: inherit;">Esto no tiene en cuenta los descuentos: en la oficina rusa de IBM prometen descuentos en el alquiler de recursos en la nube en comparaci칩n con los precios presentados aqu칤. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No entramos en las opciones con la compra, porque </font><font style="vertical-align: inherit;">aqu칤, el costo total de propiedad depende en gran medida de la elecci칩n del proveedor, el costo del servicio en el centro de datos y otros factores que son familiares para quienes trabajan con metal desnudo. </font><font style="vertical-align: inherit;">Sin embargo, las cifras preliminares tambi칠n hablan a favor de una soluci칩n basada en GPU.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Adem치s, no olvide el tr치fico y el ancho del canal: est치n incluidos en una cierta cantidad en las tarifas presentadas anteriormente, pero deber치 seleccionar las opciones para sus tareas en funci칩n del n칰mero de hilos, el n칰mero esperado de usuarios, etc. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Escalamiento </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La opci칩n con una tarjeta gr치fica por servidor nos parece m치s rentable que la opci칩n con dos o m치s tarjetas. Como podemos ver, el decodificador de GPU siempre carg칩 m치s que el codificador, pero incluso permaneci칩 subcargado debido a problemas con el uso de contextos. Si agrega una segunda tarjeta, el decodificador se usar치 a칰n menos, los codificadores que no podremos cargar a plena capacidad, y todo el trabajo en la codificaci칩n a칰n tendr치 que trasladarse a la CPU, lo que no se justificar치 por el dinero. Tambi칠n probamos la opci칩n con dos GPU gracias al soporte de Softlayer, pero debido al d칠bil efecto econ칩mico, no damos detalles en el art칤culo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En consecuencia, para escalar la carga, es preferible agregar nuevos servidores con una tarjeta gr치fica que agregar tarjetas a las m치quinas existentes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si el n칰mero de transmisiones entrantes y salientes para su proyecto es relativamente peque침o, por ejemplo, una docena de transmisiones HD con una peque침a cantidad de resoluciones de salida, con una cantidad relativamente peque침a de filtrado, ser칤a m치s conveniente utilizar un servidor sin una GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tambi칠n vale la pena se침alar que la cantidad de RAM para la tarea de convertir subprocesos no es tan importante como la potencia de procesamiento. Entonces, en algunos casos, tambi칠n puede ahorrar reduciendo la cantidad de memoria.</font></font><br><br><h3>  Conclusi칩n </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La soluci칩n de hardware presentada, una combinaci칩n de la CPU y GPU Tesla M60, fue perfecta para transcodificar transmisiones en vivo bajo cargas pesadas. </font><font style="vertical-align: inherit;">La GPU se encarga de las operaciones m치s intensivas en recursos: decodifica las secuencias y las codifica en las resoluciones m치s altas, mientras que las resoluciones medias y peque침as se procesan bien en la CPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si uno de los lectores tiene experiencia y est치 optimizando el rendimiento de las tarjetas gr치ficas para la transmisi칩n en vivo, estaremos encantados de conocer su experiencia: escriba los comentarios.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es401539/">https://habr.com/ru/post/es401539/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es401527/index.html">C칩mo se degradan las unidades 칩pticas</a></li>
<li><a href="../es401529/index.html">Preg칰ntele a Ethan: 쯇uede el universo ser considerado vivo?</a></li>
<li><a href="../es401531/index.html">En el marco del proyecto "La ciencia no es harina", se llevar치 a cabo una discusi칩n sobre el tema: "Sexo, drogas, rock and roll: 쯔dicci칩n o vida?"</a></li>
<li><a href="../es401533/index.html">Dificultades para elegir una tarjeta de video econ칩mica en el ejemplo de la RX 460</a></li>
<li><a href="../es401535/index.html">Colonia Cap칤tulo 4: la vieja base militar</a></li>
<li><a href="../es401541/index.html">50 쮐혝햣햫햨쮏 햏햞* 햃햟햟혝햫혦햧 햦햣햪 햗햊햎-햨쮏얧쟴쮏쒫썛쫧쫨혠 혜햦햡햫햟햩쮏 햪햦햨쮏쥃쮏쫨쮏햩햣햟햪햦 Microchip</a></li>
<li><a href="../es401543/index.html">Uso de conjuntos de datos del portal de datos abiertos de Rusia data.gov.ru</a></li>
<li><a href="../es401545/index.html">Chef, te veo. Intel Unite - Herramienta de comunicaci칩n profesional</a></li>
<li><a href="../es401549/index.html">Estados ex칩ticos de la materia, pantallas LCD y el futuro del agua.</a></li>
<li><a href="../es401551/index.html">Valve desarrolla tres juegos de realidad virtual al mismo tiempo y espera desarrollar tecnolog칤a</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤹🏿 🎋 🚜 Prueba de resistencia de GPU NVidia en la transcodificación de transmisión en vivo 😍 😠 🤶🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A continuación se muestra una historia detallada sobre cómo cargamos la tarjeta de NVidia con las tareas de transcodificar video para su transmisión. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Prueba de resistencia de GPU NVidia en la transcodificación de transmisión en vivo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/401539/">  <i>A continuación se muestra una historia detallada sobre cómo cargamos la tarjeta de NVidia con las tareas de transcodificar video para su transmisión.</i>  <i>Demostremos que probamos lo que sucedió y la mejor manera de usar tarjetas de video para transmitir en línea.</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/files/7ef/cc6/50b/7efcc650b901459bbb5addc4fe8d6bd3.png"></div><a name="habracut"></a>  Durante varios años, nuestro equipo ha estado desarrollando productos para procesar y distribuir contenido multimedia en línea.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Este artículo describió</a> recientemente por qué los propietarios de contenido podrían necesitar tales soluciones en nuestra era de YouTube. <br><br>  Uno de nuestros productos es el servidor de medios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nimble Streamer</a> , que es un software de servidor que lleva las transmisiones en vivo y los archivos a la entrada y los hace accesibles a una gran cantidad de espectadores, mientras que simultáneamente le permite monetizar el contenido.  Esta es una aplicación nativa escrita en C ++ y portada a todos los sistemas operativos y plataformas populares (Linux, Windows, MacOS) (x64, ARM).  Desde el principio, el bajo consumo de recursos y la alta productividad fueron los requisitos principales, y logramos lograr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">buenos resultados</a> en esto. <br><br>  El año pasado, lanzamos el complemento Nimble Streamer: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transcodificador de transmisión en vivo</a> .  Esta aplicación le permite tomar el flujo de entrada de video y / o audio en diferentes formatos y hacer varias conversiones con ellos en tiempo real.  La funcionalidad incluye decodificación (software y hardware), conversión de video y audio mediante filtros (cambio de tamaño, superposición, etc.) y codificación (codificación), tanto de software como de hardware. <br><br>  El transcodificador se controla a través del servicio web WMSPanel, los scripts de transcodificación se crean a través de la interfaz de arrastrar y soltar, que le permite ver visualmente el proceso.  Se pueden ejecutar varios escenarios juntos: con este enfoque es conveniente ejecutar combinaciones de prueba, cargando el servidor en cualquier variación. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">En estos videos</a> puede ver ejemplos de cómo funciona la interfaz. <br><br>  La decodificación de cada flujo se realiza solo una vez antes de todas las conversiones adicionales ... Esto le permite ahorrar recursos en una operación de decodificación costosa, esto se verá claramente a lo largo de las pruebas. <br><br>  Uno de los mecanismos de conversión que se pueden usar en nuestro transcodificador es la decodificación de hardware y la codificación de video utilizando la GPU de NVidia.  Las tarjetas gráficas de las últimas generaciones le permiten asumir algunas de las tareas típicas, lo que elimina la carga de la CPU.  Nuestro transcodificador puede trabajar con este hardware, que nuestros clientes utilizan activamente. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/460/a36/96e/460a3696ed2e4f1e8d7491ecc4e7c2ca.png"></div><br>  En el curso de la comunicación con representantes de la oficina rusa de NVidia, se nos pidió que intentemos organizar pruebas de estrés conjuntas de nuestro transcodificador y GPU NVidia para comprender cuál será el efecto económico de tal tándem en comparación con la transcodificación exclusiva de software, sin aceleración de hardware.  Además, quería entender cómo usar de manera óptima la GPU y, si es posible, dar buenas recetas. <br><br>  Necesitábamos obtener rápidamente el hierro apropiado y acceder a él, para el ciclo de nuestros experimentos.  Planeamos encontrarnos un par de semanas.  Queda por encontrar dónde conseguir el equipo.  La mejor opción sería encontrarlos en la nube y obtener acceso remoto.  Después de buscar las opciones, resultó que AWS aún no tiene una VM con una GPU de generación Maxwell, y en la nube de Azure, solo está previsto comenzar a proporcionarlas pronto. <br><br><h2>  1. Hierro de NVidia en la nube de Softlayer, configurando Nimble Streamer </h2><br>  Con la asistencia de NVidia, IBM nos proporcionó acceso a su nube, la plataforma IBM Bluemix Cloud Platform (anteriormente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Softlayer</a> ).  Esta es una gran red de centros de datos modernos (alrededor de 50 en el momento de la publicación) en todo el mundo, conectados por una red privada común y que proporcionan una gran selección de servicios de infraestructura en la nube.  Todos los centros de datos están unificados y le permiten alquilar de uno a cientos de servidores virtuales o físicos de la configuración requerida durante varias horas, así como equilibradores, sistemas de almacenamiento, firewalls; en general, todo lo que se requiere para construir una infraestructura de TI confiable para el servicio de TI implementado. <br><br>  La oficina de representación rusa de IBM nos dio acceso completo al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">portal de autoservicio</a> para administrar los servicios en la nube y a la configuración del servidor necesaria, donde pudimos trabajar con diferentes flujos de entrada y configuraciones de nuestro transcodificador. <br><br><h3>  Hierro </h3><br>  Primero, nos dieron un servidor físico (metal) con 128 GB de RAM y 2xGPU NVidia Tesla M60 y sistema operativo Ubuntu 14.04 preinstalado.  Todos los parámetros del servidor, contraseñas, versiones de firmware, su conmutación, IP dedicada, el estado de los componentes de hardware, eran visibles directamente en su cuenta personal, lo que le permite hacer las manipulaciones necesarias con el hardware alquilado, lo que minimiza la necesidad de interacción con el soporte de IBM.  Durante la ejecución de la prueba, resultó que no pudimos cargar de manera óptima esta configuración, debido a una serie de limitaciones en la generación de contextos. <br><br>  Queríamos reducir la configuración.  Como utilizamos la plataforma en la nube, fue necesario a través del portal de autoservicio para solicitar cambios de configuración.  Después de la aprobación, esta operación tardó aproximadamente 2 horas en la ventana de servicio aprobada.  Durante este tiempo, el personal técnico del centro de datos de Amsterdam eliminó componentes adicionales (ranuras RAM y 1xGPU) del servidor que nos proporcionaron antes y lo devolvió a la operación.  Debe tenerse en cuenta que para los desarrolladores esta opción es muy conveniente, ya que no es necesario ocuparse de la configuración del hardware, repararla o incluso pasar tiempo instalando el sistema operativo.  Permítame recordarle que en este caso el hipervisor no se utiliza porque necesitamos exprimir al máximo los recursos de hardware. <br><br>  En base a los resultados de nuestra investigación, nos decidimos por la siguiente configuración del servidor: <br><blockquote>  Doble Intel Xeon E5-2690 v3 (2.60GHz) <br>  24 núcleos <br>  64 GB de RAM <br>  1 TB SATA <br></blockquote><br>  Tenemos 2 procesadores con 12 núcleos cada uno, y gracias a Hyper Threading obtenemos el doble, es decir  virtualmente 48 núcleos. <br><br>  En escenarios con un acelerador de gráficos, se utilizó una tarjeta basada en el chip GM204 - Tesla M60: <br><blockquote>  NVIDIA Tesla M60 <br>  1xGPU: 2 x Maxwell GM204 <br>  Memoria: 16 GB GDDR5 <br>  Velocidad de reloj: 2.5 GHz <br>  Núcleos NVIDIA CUDA: 2 x 2048 <br>  Ancho de banda de memoria: 2 x 160 GB / seg. </blockquote><br>  Le llamo la atención sobre el hecho de que no se realizó ninguna afinidad, ajuste de chip, overclocking u otra magia en el hardware reducido, solo CPU y GPU no overclockeadas, y para la GPU solo se utilizó el controlador oficial tomado del sitio web de NVidia.  Si alguien tiene una experiencia similar, comparta en los comentarios. <br><br>  Entonces, tenemos acceso.  Un rápido conocimiento de la interfaz web del panel de control (todo es simple y claro allí), luego acceder al servidor a través de SSH, y aquí estamos en la línea de comandos habitual de Ubuntu, poner Nimble Streamer, registrar una licencia de transcodificador nueva y hacer una pequeña configuración de configuración. <br><br><h3>  Transcodificador ágil streamer </h3><br>  Nimble Streamer se configuró para crear previamente el caché de contexto de GPU.  Esto se debe al hecho de que la GPU tiene un límite en el número máximo de contextos de decodificación y codificación creados, y además, crear contextos sobre la marcha puede tomar demasiado tiempo. <br>  Se pueden encontrar más detalles sobre el problema de crear contextos en la sección correspondiente a continuación. <br><br>  Configuración de Nimbl en el ejemplo de la primera serie de pruebas: <br><blockquote>  nvenc_context_cache_enable = true <br>  nvenc_context_create_lock = true <br>  nvenc_context_cache_init = 0: 30: 15.1: 30: 15 <br>  nvenc_context_reuse_enable = true </blockquote><br>  Más detalles sobre estas configuraciones están escritos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en nuestro artículo</a> . <br><br>  Antes de comenzar cada serie de pruebas, el caché se configuró por separado, teniendo en cuenta los detalles de cada tarea. <br><br><h3>  Crear scripts de transcodificación </h3><br>  Se siguió trabajando en nuestro servicio WMSPanel, donde se configuran los scripts del transcodificador. <br><br>  Como ya se mencionó, el trabajo pasa por la interfaz web, todo es extremadamente claro y conveniente.  Creamos una serie de escenarios que combinan diferentes opciones de transcodificación (CPU / GPU), diferentes opciones de resolución y diferentes parámetros de codificación (CPU / GPU, perfil, velocidad de bits, etc.) <br><br>  Se pueden ejecutar conjuntos de escenarios simultáneamente, lo que permite introducir varias combinaciones de pruebas, aumentar la carga en un orden diferente y cambiarla según la situación.  Simplemente seleccione los escenarios necesarios y deténgalos o reanúdelos. <br><br>  Aquí hay un conjunto de escenarios: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/cd6/197/b77/cd6197b77e6b4c0697f43f8d1cfaaf07.png"></div><br>  Aquí hay un ejemplo de uno de los escenarios: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e47/1ff/924/e471ff9244f240edb2c092f42d5cf721.png"></div><br>  El decodificador de GPU se ve así: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/382/0f8/2fd/3820f82fd74e4e0ea106534962e1ba28.png"></div><br>  Aplicamos el filtro de tamaño de imagen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9d3/bd0/eab/9d3bd0eab2ac47d4b3183aca91db0d6f.png"></div><br>  Y aquí está el codificador para la variante GPU: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/212/d34/e2e/212d34e2e3cf425a9f94d03194f7c62d.png"></div><br><br>  En general, el funcionamiento de la interfaz del transcodificador se puede <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ver en estos videos</a> . <br><br><h2>  2. Transcodificación de transmisiones FullHD 1080p </h2><br>  Para empezar, probamos el escenario con las cargas más altas para descubrir los límites de las capacidades de hierro.  Por el momento, la "más pesada" de las resoluciones utilizadas en la práctica es FullHD 1080p. <br><br>  Para generar las transmisiones en vivo originales, se tomó un archivo en <b>FullHD</b> (1920 * 1080) en <b>H.264 de alto perfil</b> .  El contenido en sí es un video tour de la ciudad, es decir  Este es un video con una tasa de cambio de imagen promedio.  No hay marcos estáticos de un solo color que puedan facilitar el trabajo del transcodificador, pero no hay un cambio demasiado rápido de tipos y colores.  En una palabra: una carga bastante típica. <br><br>  Se alimentaron <b>36 transmisiones idénticas</b> a la entrada de Nimble Streamer, que luego se utilizaron en el transcodificador en diferentes escenarios. <br><br>  El escenario de transcodificación se usa típicamente: la transmisión entrante es de perfil alto de <b>1080p</b> , perfil principal de <b>720p, 480p, 360p</b> y luego las secuencias de <b>perfil de línea de base</b> se hacen a partir de ella <b>: 240p, 160p</b> .  En total, hay 1 flujo en la entrada y 5 en la salida. Por lo general, también se realiza un paso (transferencia sin cambios) del flujo original para que el espectador pueda seleccionar 1080p mientras visualiza.  No lo agregamos en el script, porque  no utiliza transcodificación: hay una transferencia directa de datos de entrada a salida.  Este escenario está optimizado en Nimble y en condiciones reales aumentará el consumo de memoria de forma relativamente leve. <br>  Audio en las secuencias generadas - no.  Agregar audio al script no causará cargas significativas de CPU, pero por la pureza del experimento, excluimos el sonido. <br><br><h3>  Prueba de CPU, sin GPU </h3><br>  Para comenzar, lanzamos scripts de transcodificación sin usar una GPU, especificando el decodificador y codificador de software en los scripts. <br><br>  Como resultado, fue posible procesar solo 16 flujos de entrada con la emisión de 80 flujos de todos los permisos de salida. <br><br>  Carga de CPU: 4600%, es decir  46 núcleos estuvieron involucrados.  Consumo de RAM: aproximadamente 15 GB. <br><br><h3>  Prueba de CPU + GPU </h3><br>  La memoria caché de contexto al inicio se configura como 0: 30: 15.1: 30: 15, es decir  30 contextos para codificar, 15 para decodificar, cada GPU. <br><br>  Permítame recordarle que en la GPU tenemos dos núcleos, lo que nos permite paralelizar las tareas, esto es útil para nosotros. <br><br>  La carga máxima se obtuvo con la siguiente configuración de flujo. <br><br>  El decodificador de entrada GPU0 y GPU1 - 15 flujos.  De este modo, obtenemos 30 secuencias decodificadas, listas para su uso posterior.  Cada secuencia se decodifica solo una vez, sin importar cuántos escenarios se use en el futuro. <br><br>  Los codificadores GPU0 y GPU1 recibieron 15 transmisiones cada uno para obtener 720p, es decir.  Se produjeron 30 transmisiones de 720p en una salida. <br><br>  Además, los codificadores GPU0 y GPU1 proporcionaron cada uno 15 flujos para 480p, y también se emitieron 30 flujos de 480p. <br><br>  Como los contextos del codificador se agotaron, la codificación de los permisos restantes se estableció en la CPU.  Resultó lo siguiente: <br><br><ol><li>  30 transmisiones 360p </li><li>  30 transmisiones 240p </li><li>  30 transmisiones 160p </li></ol><br>  La carga resultó ser 2600% de CPU, 75% de decodificador, 32% de codificador.  Luego, la CPU se cargó con 6 transmisiones para decodificar, por cada 5 resoluciones similares configuradas, para un total de 30 hilos por salida. <br><br>  En total, se recibieron <b>36 transmisiones en la entrada, 180 se emitieron en la salida</b> .  La carga final se repara de la siguiente manera: <b>4400% de CPU, 75% de decodificador de tarjeta, 32% de codificador de tarjeta, 30 GB de RAM</b> . <br><br><h3>  Algunos detalles </h3><br>  Decidimos verificar la opción en la que procesamos las tareas más difíciles en la GPU: decodificar 1080 y codificar 720 y 480, y dejar que el resto se procese a través de la CPU. <br><br>  Primero, verificamos el límite del decodificador.  Con 22 hilos, la decodificación se vio afectada por el problema de los contextos, simplemente no se pudieron crear.  Disminuyó a 21: se crearon contextos, pero la carga se volvió 100% y los artefactos comenzaron a observarse en la secuencia.  Nos detuvimos en 20 transmisiones, decodificamos 20 transmisiones, codificamos a 160p, todo funciona bien. <br><br>  Además, resultó empíricamente que esta tarjeta con 16 GB de RAM a bordo puede funcionar con confianza en 47 contextos, y no hay diferencia, estos son los contextos de un codificador o decodificador.  Repito: se trata específicamente de esta GPU Tesla M60, en otras tarjetas este número puede ser diferente.  Creemos que si la tarjeta tuviera 24 GB de RAM, el número de contextos podría ser diferente, pero esto debe ser probado. <br><br>  Como resultado, elegimos la fórmula de creación de caché "15 contextos del decodificador y 30 contextos del codificador", que proporciona 30 secuencias a la entrada y para cada una le permite crear 2 permisos.  Entonces, las resoluciones superiores, 720 y 480, se lanzaron en la GPU, y el resto, 360, 240 y 160, se enviaron a la CPU.  Y como la CPU aún estaba libre después de eso, "terminamos" los núcleos libres con nuevos hilos, dejando 4 núcleos para tareas utilitarias. <br><br><h2>  3. Transcodificación de transmisiones HD 720p </h2><br>  Escenario de carga típica  La mayor parte del contenido ahora se crea en HD.  Incluso el reciente SuperBowl LI, el programa mejor calificado en el mercado estadounidense, se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transmitió en HD</a> , dejando FullHD para el futuro. <br><br>  Para generar las secuencias de origen, se tomó un archivo en <b>HD</b> (1280 * 720) en un <b>perfil alto</b> .  El contenido es la serie favorita de "The Good Wife" de nuestro ingeniero, es decir  Este es un video con una tasa de cambio de imagen promedio. <br><br>  En la entrada del Nimble Streamer, se alimentaron 70 transmisiones idénticas, que luego se utilizaron en el transcodificador en diferentes escenarios. <br><br>  Se utiliza el siguiente escenario de transcodificación: la transmisión entrante es de <b>720p de</b> perfil alto, <b>480p, perfil principal de 360p</b> y luego se hacen <b>240p, 160p líneas de</b> perfil de <b>línea base</b> .  Total, en la entrada 1, en la salida 4. No se realizó el paso de la secuencia original, como en el escenario anterior.  El audio en las secuencias generadas tampoco lo es. <br><br><h3>  Prueba de CPU, sin GPU </h3><br>  Como en la sección anterior, intentamos transcodificar secuencias solo en la CPU.  Como resultado, fue posible procesar solo 22 flujos de entrada con la emisión de 88 flujos de todos los permisos de salida.  Carga de CPU: 4700%, es decir  Participaron 47 núcleos.  Consumo de RAM: aproximadamente 20 GB. <br><br><h3>  Prueba de CPU + GPU </h3><br>  La memoria caché de contexto al inicio se configura como 0: 23: 23.1: 23: 23, es decir  23 contextos para codificar, 23 para decodificar para cada GPU. <br><br>  Usando la GPU, se decodificaron 46 secuencias de 720p.  Allí, en la GPU, se codificaron 46 secuencias de 480p.  A continuación, se realizaron codificaciones de 360p, 240p y 160p en la CPU: 46 transmisiones cada una. <br>  Carga fija de 2100% de CPU, 61% del decodificador, 16% del codificador. <br><br>  Además, se lanzó la codificación y decodificación de 24 subprocesos a la CPU, por cada 1 subproceso - 4 salidas, como para la GPU. <br><br>  En total, <b>se ingresaron 70 secuencias, se emitieron 280 secuencias</b> . <br>  Carga: <b>4600%, 61% del decodificador, 16% del codificador, 30 GB de RAM</b> . <br><br>  En cuanto a la prueba anterior, quizás una GPU RAM más grande daría más contextos y podríamos manejar más hilos.  Pero esto es solo en teoría, es necesario verificarlo. <br><br><h2>  4. El problema con la creación de contextos en la GPU NVidia </h2><br>  Algunas palabras sobre el problema que no nos permitieron procesar más subprocesos en la GPU. <br><br>  A fines del año pasado, realizamos pruebas con el equipo de NVidia, con varias tarjetas.  Al trabajar con múltiples GPU, resultó que la creación de contextos ralentiza enormemente el servidor: la creación de cada nuevo contexto tomó más y más tiempo del mapa.  Si el primer contexto se creó en el orden de 300 ms, cada uno de los siguientes agregó 200-300 ms y ya en los terceros diez contextos, crear uno nuevo tomó 3-4 segundos cada uno.  Cuando un usuario crea un script de transcodificación, se supone que comienza a trabajar de inmediato y sin demoras, y esta nueva circunstancia negó todas las ventajas en la velocidad de Nimbl y dio demoras en la creación de contextos que condujeron a demoras en el inicio de la codificación. <br><br>  Al principio, la sospecha recayó en Nimble, pero luego hicimos pruebas usando ffmpeg, que NVidia proporciona a los clientes y el resultado fue exactamente el mismo: la GPU está gastando más y más tiempo creando cada nuevo contexto.  En condiciones en las que el servidor ya está transcodificando y necesita iniciar nuevos subprocesos para el procesamiento, esto afecta el rendimiento general y hace que el servidor simplemente sea inutilizable. <br><br>  El problema fue descrito en detalle por el equipo de NVidia, pero hasta ahora no se ha proporcionado una solución a tiempo completo.  Por lo tanto, hasta ahora hemos implementado un mecanismo de almacenamiento en caché de contexto en nuestro servidor, con la creación preliminar de contextos al inicio del servidor.  Esto resolvió el problema desde el punto de vista del trabajo del usuario final, pero el inicio del Nimbl puede llevar algo de tiempo.  La configuración de Nimbl para un trabajo efectivo con contextos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se describe en nuestro blog</a> . <br><br>  Además, los contextos no son fáciles de crear.  Con una gran cantidad de contextos al incluir cualquier script de transcodificación, la API de NVENC comienza a arrojar errores: "La llamada a la API falló porque no pudo asignar suficiente memoria para realizar la operación solicitada". <br><br>  Empíricamente, resultó que una GPU puede comenzar y trabajar con confianza en 47 contextos, y no hay diferencia, estos son los contextos de un codificador o decodificador.  Se suponía que esto se debía a la cantidad de memoria en la GPU.  Ahora hay 16 GB, si coloca una tarjeta con 24 GB, es probable que se puedan hacer más contextos.  Pero esto es solo una teoría, es necesario verificar, como se mencionó anteriormente.  Los datos obtenidos son válidos para un modelo de GPU específico, otras tarjetas deben probarse por separado. <br><br>  Es la restricción en el número de contextos lo que pone el obstáculo principal cuando se trabaja con grandes cargas. <br><br><h2>  5. Conclusiones </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por lo tanto, el propósito de las pruebas era estudiar la efectividad de la GPU para el rango de tareas indicado y desarrollar recetas para su uso adecuado. </font><font style="vertical-align: inherit;">Cual es el resultado?</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Efecto económico </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Arriba, vimos cómo la cantidad de subprocesos que se pueden procesar en la CPU y en el tándem CPU + GPU es diferente. </font><font style="vertical-align: inherit;">Veamos qué significa esto en términos de dinero. </font><font style="vertical-align: inherit;">Como base tomamos los mismos Softlayer y los precios de alquiler de sus equipos.</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La configuración sin una GPU costará </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 819 por mes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aquí puedes recoger un</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auto.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La configuración con la GPU costará </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 1729 por mes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para el centro de datos en Amsterdam, los precios se pueden </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">encontrar aquí</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Cuando se usa una GPU, el precio de alquiler del servidor aumenta ligeramente, ya que se usa el factor de forma de caso 2U más grande. </font><font style="vertical-align: inherit;">El efecto económico probablemente será mayor al comprar equipos (pero esto requiere un análisis serio del TCO, teniendo en cuenta la actualización constante de la línea de GPU NVidia).</font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ahora veamos los resultados de la prueba: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para FullHD 1080p</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU sin GPU: 16 hilos por entrada + 80 hilos por salida </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU + GPU: 36 hilos por entrada + 180 por salida </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficio de GPU: 2.25x. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficios</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> del uso de la GPU: $ 819 * 2.25 - $ 1729 = </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 113 por mes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> al alquilar 1 servidor con una GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para HD 720p</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU sin GPU: 22 hilos por entrada + 88 hilos por salida </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU + GPU: 70 hilos por entrada + 280 por salida </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficio de GPU: 3.18x. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficio</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de usar la GPU: $ 819 * 3.18 - $ 1729 = </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 875 por mes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> al alquilar 1 servidor con una GPU </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es decir, con la opción de alquiler, los ahorros son bastante notables. </font><font style="vertical-align: inherit;">Esto no tiene en cuenta los descuentos: en la oficina rusa de IBM prometen descuentos en el alquiler de recursos en la nube en comparación con los precios presentados aquí. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No entramos en las opciones con la compra, porque </font><font style="vertical-align: inherit;">aquí, el costo total de propiedad depende en gran medida de la elección del proveedor, el costo del servicio en el centro de datos y otros factores que son familiares para quienes trabajan con metal desnudo. </font><font style="vertical-align: inherit;">Sin embargo, las cifras preliminares también hablan a favor de una solución basada en GPU.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Además, no olvide el tráfico y el ancho del canal: están incluidos en una cierta cantidad en las tarifas presentadas anteriormente, pero deberá seleccionar las opciones para sus tareas en función del número de hilos, el número esperado de usuarios, etc. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Escalamiento </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La opción con una tarjeta gráfica por servidor nos parece más rentable que la opción con dos o más tarjetas. Como podemos ver, el decodificador de GPU siempre cargó más que el codificador, pero incluso permaneció subcargado debido a problemas con el uso de contextos. Si agrega una segunda tarjeta, el decodificador se usará aún menos, los codificadores que no podremos cargar a plena capacidad, y todo el trabajo en la codificación aún tendrá que trasladarse a la CPU, lo que no se justificará por el dinero. También probamos la opción con dos GPU gracias al soporte de Softlayer, pero debido al débil efecto económico, no damos detalles en el artículo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En consecuencia, para escalar la carga, es preferible agregar nuevos servidores con una tarjeta gráfica que agregar tarjetas a las máquinas existentes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si el número de transmisiones entrantes y salientes para su proyecto es relativamente pequeño, por ejemplo, una docena de transmisiones HD con una pequeña cantidad de resoluciones de salida, con una cantidad relativamente pequeña de filtrado, sería más conveniente utilizar un servidor sin una GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">También vale la pena señalar que la cantidad de RAM para la tarea de convertir subprocesos no es tan importante como la potencia de procesamiento. Entonces, en algunos casos, también puede ahorrar reduciendo la cantidad de memoria.</font></font><br><br><h3>  Conclusión </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La solución de hardware presentada, una combinación de la CPU y GPU Tesla M60, fue perfecta para transcodificar transmisiones en vivo bajo cargas pesadas. </font><font style="vertical-align: inherit;">La GPU se encarga de las operaciones más intensivas en recursos: decodifica las secuencias y las codifica en las resoluciones más altas, mientras que las resoluciones medias y pequeñas se procesan bien en la CPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si uno de los lectores tiene experiencia y está optimizando el rendimiento de las tarjetas gráficas para la transmisión en vivo, estaremos encantados de conocer su experiencia: escriba los comentarios.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es401539/">https://habr.com/ru/post/es401539/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es401527/index.html">Cómo se degradan las unidades ópticas</a></li>
<li><a href="../es401529/index.html">Pregúntele a Ethan: ¿Puede el universo ser considerado vivo?</a></li>
<li><a href="../es401531/index.html">En el marco del proyecto "La ciencia no es harina", se llevará a cabo una discusión sobre el tema: "Sexo, drogas, rock and roll: ¿adicción o vida?"</a></li>
<li><a href="../es401533/index.html">Dificultades para elegir una tarjeta de video económica en el ejemplo de la RX 460</a></li>
<li><a href="../es401535/index.html">Colonia Capítulo 4: la vieja base militar</a></li>
<li><a href="../es401541/index.html">50 оттенков ПНЯ* Аппаратный прием ШИМ-кодированных сигналов микроконтроллерами Microchip</a></li>
<li><a href="../es401543/index.html">Uso de conjuntos de datos del portal de datos abiertos de Rusia data.gov.ru</a></li>
<li><a href="../es401545/index.html">Chef, te veo. Intel Unite - Herramienta de comunicación profesional</a></li>
<li><a href="../es401549/index.html">Estados exóticos de la materia, pantallas LCD y el futuro del agua.</a></li>
<li><a href="../es401551/index.html">Valve desarrolla tres juegos de realidad virtual al mismo tiempo y espera desarrollar tecnología</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
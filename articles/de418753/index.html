<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👈 🤶🏽 👨‍❤️‍👨 vSAN in der VMware Cloud ✖️ 🤸🏾 👧🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Speichern und Zugreifen auf Daten ist für jedes Informationssystem ein Problem. Selbst ein gut konzipiertes Speichersystem (im Folgenden als SHD b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>vSAN in der VMware Cloud</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/418753/"><img src="https://habrastorage.org/webt/pl/tj/to/pltjtoutsishswrt2dgxaktv5ka.png"><br><br>  Das Speichern und Zugreifen auf Daten ist für jedes Informationssystem ein Problem.  Selbst ein gut konzipiertes Speichersystem (im Folgenden als SHD bezeichnet) während des Betriebs zeigt Probleme, die mit einer verringerten Leistung verbunden sind.  Besondere Aufmerksamkeit sollte einer Reihe von Skalierungsproblemen gewidmet werden, wenn sich die Menge der beteiligten Ressourcen den von Speicherentwicklern festgelegten Grenzwerten nähert. <br><br>  Der Hauptgrund für das Auftreten dieser Probleme ist die traditionelle Architektur, die auf einer engen Bindung an die Hardwareeigenschaften der verwendeten Speichergeräte basiert.  Die meisten Kunden wählen nach wie vor die Methode zum Speichern und Zugreifen auf Daten, wobei die Merkmale der physischen Schnittstellen (SAS / SATA / SCSI) und nicht die tatsächlichen Anforderungen der verwendeten Anwendungen berücksichtigt werden. <br><a name="habracut"></a><br>  Vor einem Dutzend Jahren war dies eine logische Entscheidung.  Systemadministratoren wählten sorgfältig Informationsspeichergeräte mit den erforderlichen Spezifikationen aus, z. B. SATA / SAS, und rechneten damit, ein Leistungsniveau zu erreichen, das auf den Hardwarefunktionen von Festplattencontrollern basiert.  Der Kampf ging um das Volumen der RAID-Controller-Caches und um Optionen, die Datenverlust verhindern.  Dieser Ansatz zur Lösung des Problems ist nicht optimal. <br><br>  In der aktuellen Umgebung ist es bei der Auswahl von Speichersystemen sinnvoll, nicht von physischen Schnittstellen auszugehen, sondern von der in IOPS ausgedrückten Leistung (Anzahl der E / A-Vorgänge pro Sekunde).  Durch die Verwendung der Virtualisierung können Sie vorhandene Hardwareressourcen flexibel nutzen und das erforderliche Leistungsniveau gewährleisten.  Wir für unseren Teil sind bereit, Ressourcen mit den Eigenschaften bereitzustellen, die für die Anwendung wirklich notwendig sind. <br><br><h2>  Speichervirtualisierung </h2><br>  Mit der Entwicklung von Virtualisierungssystemen war es notwendig, eine innovative Lösung zum Speichern und Zugreifen auf Daten zu finden und gleichzeitig die Fehlertoleranz sicherzustellen.  Dies war der Ausgangspunkt für die Erstellung von SDS (Software-Defined Storage).  Um den geschäftlichen Anforderungen gerecht zu werden, wurden diese Repositorys mit der Trennung von Software und Hardware entwickelt. <br><br>  Die SDS-Architektur unterscheidet sich grundlegend von der traditionellen.  Die Speicherlogik wurde auf Softwareebene abstrahiert.  Die Organisation des Speichers ist aufgrund der Vereinheitlichung und Virtualisierung jeder der Komponenten eines solchen Systems einfacher geworden. <br><br>  Was ist der Hauptfaktor, der die Implementierung von Sicherheitsdatenblättern überall behindert?  Dieser Faktor ist meistens eine falsche Bewertung der Bedürfnisse der verwendeten Anwendungen und eine falsche Risikobewertung.  Für ein Unternehmen hängt die Wahl der Lösung von den Implementierungskosten ab, basierend auf den aktuell verbrauchten Ressourcen.  Nur wenige Leute denken - was passiert, wenn die Informationsmenge und die erforderliche Leistung die Fähigkeiten der ausgewählten Architektur überschreiten.  Das Denken auf der Grundlage des methodischen Prinzips „man sollte nicht ohne Notwendigkeit existieren“, besser bekannt als „Occams Klinge“, entscheidet über die Wahl traditioneller Lösungen. <br><br>  Nur wenige verstehen, dass die Notwendigkeit der Skalierbarkeit und Zuverlässigkeit der Datenspeicherung wichtiger ist, als es auf den ersten Blick scheint.  Informationen sind eine Ressource, und daher muss das Risiko ihres Verlusts versichert sein.  Was passiert, wenn ein herkömmliches Speichersystem ausfällt?  Sie müssen die Garantie nutzen oder neue Geräte kaufen.  Und wenn das Speichersystem eingestellt wird oder die "Lebensdauer" (das sogenannte EOL - End-of-Life) beendet ist?  Dies kann ein schwarzer Tag für jedes Unternehmen sein, das seine eigenen vertrauten Dienste nicht weiter nutzen kann. <br><br>  Es gibt keine Systeme, die keinen einzigen Fehlerpunkt haben.  Es gibt jedoch Systeme, die den Ausfall einer oder mehrerer Komponenten problemlos überstehen können.  Sowohl virtuelle als auch traditionelle Speichersysteme wurden unter Berücksichtigung der Tatsache erstellt, dass früher oder später ein Fehler auftreten wird.  Dies ist nur die "Festigkeitsgrenze" herkömmlicher Speichersysteme, die in der Hardware festgelegt sind, aber in virtuellen Speichersystemen wird sie in der Softwareschicht festgelegt. <br><br><h2>  Integration </h2><br>  Dramatische Änderungen in der IT-Infrastruktur sind immer ein unerwünschtes Phänomen, das mit Ausfallzeiten und Geldverlusten behaftet ist.  Nur die reibungslose Implementierung neuer Lösungen ermöglicht es, negative Folgen zu vermeiden und die Arbeit der Dienste zu verbessern.  Aus diesem Grund hat Selectel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Cloud basierend auf VMware</a> entwickelt und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eingeführt</a> , einem anerkannten Marktführer im Bereich Virtualisierung.  Mit dem von uns erstellten Service kann jedes Unternehmen alle Infrastrukturaufgaben einschließlich der Datenspeicherung lösen. <br><br>  Wir werden Ihnen genau sagen, wie wir uns für ein Speichersystem entschieden haben und welche Vorteile uns diese Wahl gebracht hat.  Natürlich wurden sowohl traditionelle Speichersysteme als auch Sicherheitsdatenblätter berücksichtigt.  Um alle Aspekte des Betriebs und der Risiken klar zu verstehen, bieten wir einen tieferen Einblick in das Thema. <br><br>  In der Entwurfsphase wurden folgende Anforderungen an Speichersysteme gestellt: <br><br><ul><li>  <strong>Fehlertoleranz;</strong> </li><li>  <strong>Leistung</strong> </li><li>  <strong>Skalierung</strong> </li><li>  <strong>die Fähigkeit, Geschwindigkeit zu garantieren;</strong> </li><li>  <strong>korrekter Betrieb im VMware-Ökosystem.</strong> </li></ul><br>  Die Verwendung herkömmlicher Hardwarelösungen konnte nicht das erforderliche Maß an Skalierbarkeit bieten, da es aufgrund architektonischer Einschränkungen unmöglich ist, das Speichervolumen ständig zu erhöhen.  Die Reservierung auf der Ebene eines gesamten Rechenzentrums war ebenfalls sehr schwierig.  Deshalb haben wir unsere Aufmerksamkeit auf SDS gerichtet. <br><br>  Es gibt verschiedene Softwarelösungen auf dem SDS-Markt, die für den Aufbau einer Cloud auf Basis von VMware vSphere geeignet sind.  Unter diesen Lösungen können festgestellt werden: <br><br><ul><li>  <strong>Dell EMC ScaleIO;</strong> </li><li>  <strong>Hyperkonvergentes virtuelles SAN für Datencore;</strong> </li><li>  <strong>HPE StoreVirtual.</strong> </li></ul><br>  Diese Lösungen sind für die Verwendung mit VMware vSphere geeignet. Sie lassen sich jedoch nicht in den Hypervisor integrieren und werden separat ausgeführt.  Daher wurde die Wahl zugunsten von VMware vSAN getroffen.  Lassen Sie uns im Detail betrachten, wie die virtuelle Architektur einer solchen Lösung aussieht. <br><br><h3>  Architektur </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hb/hu/nr/hbhunruzcic-pa1ggjw_-winfcg.png"></div><br>  <sup><i>Bild aus der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offiziellen Dokumentation</a></i></sup> <br><br>  Im Gegensatz zu herkömmlichen Speichersystemen werden nicht alle Informationen an einem bestimmten Punkt gespeichert.  Die Daten der virtuellen Maschine werden gleichmäßig auf alle Hosts verteilt. Die Skalierung erfolgt durch Hinzufügen von Hosts oder Installieren zusätzlicher Festplattenlaufwerke.  Es werden zwei Konfigurationsoptionen unterstützt: <br><br><ul><li>  <strong>AllFlash-Konfiguration</strong> (nur Solid-State-Laufwerke, sowohl für die Datenspeicherung als auch für den Cache); </li><li>  <strong>Hybridkonfiguration</strong> (magnetischer Speicher und Solid State Cache). </li></ul><br>  Das Verfahren zum Hinzufügen von Speicherplatz erfordert keine zusätzlichen Einstellungen, z. B. das Erstellen einer LUN (Logical Unit Number, Logical Disk Numbers) und das Festlegen des Zugriffs darauf.  Sobald der Host zum Cluster hinzugefügt wird, steht sein Speicherplatz für alle virtuellen Maschinen zur Verfügung.  Dieser Ansatz hat mehrere wesentliche Vorteile: <br><br><ul><li>  <strong>mangelnde Bindung an den Gerätehersteller;</strong> </li><li>  <strong>erhöhte Fehlertoleranz;</strong> </li><li>  <strong>Gewährleistung der Datenintegrität im Falle eines Fehlers;</strong> </li><li>  <strong>einzelnes Kontrollzentrum über die vSphere-Konsole;</strong> </li><li>  <strong>bequeme horizontale und vertikale Skalierung.</strong> </li></ul><br>  Diese Architektur stellt jedoch hohe Anforderungen an die Netzwerkinfrastruktur.  Um einen maximalen Durchsatz zu gewährleisten, basiert das Netzwerk in unserer Cloud auf dem Spine-Leaf-Modell. <br><br><h3>  Netzwerk </h3><br>  Das traditionelle dreistufige Netzwerkmodell (Kern / Aggregation / Zugriff) weist eine Reihe erheblicher Nachteile auf.  Ein bemerkenswertes Beispiel sind die Einschränkungen der Spanning-Tree-Protokolle. <br><br>  Das Spine-Leaf-Modell verwendet nur zwei Ebenen, was die folgenden Vorteile bietet: <br><br><ul><li>  <strong>vorhersehbarer Abstand zwischen Geräten;</strong> </li><li>  <strong>Der Verkehr verläuft auf der besten Route.</strong> </li><li>  <strong>einfache Skalierung;</strong> </li><li>  <strong>Ausschluss von L2-Protokollbeschränkungen.</strong> </li></ul><br>  Ein wesentliches Merkmal einer solchen Architektur ist, dass sie für den Durchgang von "horizontalem" Verkehr optimiert ist.  Datenpakete durchlaufen nur einen Sprung, was eine klare Schätzung der Verzögerungen ermöglicht. <br><br>  Eine physische Verbindung wird über mehrere 10-GbE-Verbindungen pro Server bereitgestellt, deren Bandbreite mithilfe des Aggregationsprotokolls kombiniert wird.  Somit erhält jeder physische Host Hochgeschwindigkeitszugriff auf alle Speicherobjekte. <br><br>  Der Datenaustausch wird mithilfe eines von VMware erstellten proprietären Protokolls implementiert, das einen schnellen und zuverlässigen Betrieb des Speichernetzwerks beim Ethernet-Transport (ab 10 GbE) ermöglicht. <br><br>  Der Übergang zum Objektmodell der Datenspeicherung ermöglichte eine flexible Anpassung der Speichernutzung an die Anforderungen der Kunden.  Alle Daten werden in Form von Objekten gespeichert, die auf bestimmte Weise auf die Cluster-Hosts verteilt werden.  Wir klären die Werte einiger Parameter, die gesteuert werden können. <br><br><h3>  Fehlertoleranz </h3><br><ol><li>  <strong>FTT (Fehler zu tolerieren).</strong>  Gibt die Anzahl der Hostfehler an, die der Cluster verarbeiten kann, ohne den regulären Betrieb zu unterbrechen. </li><li>  <strong>FTM (Fehlertoleranzmethode).</strong>  Die Methode zur Gewährleistung der Fehlertoleranz auf Plattenebene. <br><br>  a.  <strong>Spiegeln</strong> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jb/kv/lw/jbkvlwsmyvua7jrw2f8jj0820am.png"></div><br>  <sup><i>Bild aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VMware-Blog.</a></i></sup> <br><br>  Stellt eine vollständige Vervielfältigung eines Objekts dar, und Replikate befinden sich immer auf verschiedenen physischen Hosts.  Das dieser Methode am nächsten liegende Analogon ist RAID-1.  Durch seine Verwendung kann der Cluster routinemäßig bis zu drei Fehler von Komponenten (Festplatten, Hosts, Netzwerkverlust usw.) verarbeiten.  Dieser Parameter wird durch Einstellen der FTT-Option konfiguriert. <br><br>  Standardmäßig hat diese Option den Wert 1, und für das Objekt wird 1 Replikat erstellt (nur 2 Instanzen auf verschiedenen Hosts).  Mit zunehmendem Wert beträgt die Anzahl der Kopien N + 1.  Bei einem Maximalwert von FTT = 3 befinden sich 4 Instanzen des Objekts auf verschiedenen Hosts. <br><br>  Mit dieser Methode können Sie maximale Leistung auf Kosten der Speicherplatzeffizienz erzielen.  Es kann sowohl in Hybrid- als auch in AllFlash-Konfigurationen verwendet werden. <br><br>  b.  <strong>Löschcodierung</strong> (analog zu RAID 5/6). <br><img src="https://habrastorage.org/webt/72/zq/hh/72zqhhyrlncoqga9qlzg0wdfgco.png"><br><br>  <sup><i>Bild aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem</a> Blog von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cormachogan.com.</a></i></sup> <br><br>  Die Arbeit dieser Methode wird ausschließlich in AllFlash-Konfigurationen unterstützt.  Bei der Aufzeichnung jedes Objekts werden die entsprechenden Paritätsblöcke berechnet, die im Falle eines Fehlers die eindeutige Wiederherstellung von Daten ermöglichen.  Dieser Ansatz spart im Vergleich zur Spiegelung erheblich Speicherplatz. <br><br>  Natürlich erhöht der Betrieb dieses Verfahrens den Overhead, was sich in einer Verringerung der Produktivität äußert.  Angesichts der Leistung der AllFlash-Konfiguration ist dieser Nachteil jedoch ausgeglichen, sodass die Verwendung der Löschcodierung für die meisten Aufgaben eine akzeptable Option ist. <br><br>  Darüber hinaus führt VMware vSAN das Konzept der „Fehlerdomänen“ ein, bei denen es sich um eine logische Gruppierung von Server-Racks oder Festplattenkörben handelt.  Sobald die erforderlichen Elemente gruppiert sind, führt dies zur Verteilung der Daten auf verschiedene Knoten unter Berücksichtigung der Fehlerdomänen.  Auf diese Weise kann der Cluster den Verlust einer gesamten Domäne überleben, da sich alle entsprechenden Replikate der Objekte auf anderen Hosts in einer anderen Fehlerdomäne befinden. <br><br>  Die kleinste Fehlerdomäne ist eine Datenträgergruppe, bei der es sich um ein logisch verbundenes Laufwerk handelt.  Jede Datenträgergruppe enthält zwei Arten von Medien - Cache und Kapazität.  Als Cache-Medium erlaubt das System die Verwendung nur von Solid-State-Disks, und sowohl Magnet- als auch Solid-State-Disks können als Kapazitätsträger fungieren.  Durch das Zwischenspeichern von Medien können Magnetplatten beschleunigt und die Latenz beim Zugriff auf Daten verringert werden. </li></ol><br><h2>  Implementierung </h2><br>  Lassen Sie uns darüber sprechen, welche Einschränkungen in der VMware vSAN-Architektur bestehen und warum sie benötigt werden.  Unabhängig von den verwendeten Hardwareplattformen bietet die Architektur die folgenden Einschränkungen: <br><br><ul><li>  <strong>nicht mehr als 5 Plattengruppen pro Host;</strong> </li><li>  <strong>nicht mehr als 7 Kapazitätsträger in einer Plattengruppe;</strong> </li><li>  <strong>nicht mehr als 1 Cache-Träger in einer Plattengruppe;</strong> </li><li>  <strong>nicht mehr als 35 Kapazitätsträger pro Host;</strong> </li><li>  <strong>nicht mehr als 9000 Komponenten pro Host (einschließlich Zeugenkomponenten);</strong> </li><li>  <strong>nicht mehr als 64 Hosts in einem Cluster;</strong> </li><li>  <strong>Nicht mehr als 1 vSAN-Datenspeicher pro Cluster.</strong> </li></ul><br>  Warum wird das benötigt?  Bis die angegebenen Grenzwerte überschritten werden, arbeitet das System mit der angegebenen Kapazität und hält ein Gleichgewicht zwischen Leistung und Speicherkapazität aufrecht.  Auf diese Weise können Sie den korrekten Betrieb des gesamten virtuellen Speichersystems als Ganzes gewährleisten. <br><br>  Zusätzlich zu diesen Einschränkungen sollte ein wichtiges Merkmal beachtet werden.  Es wird nicht empfohlen, mehr als 70% des gesamten Speichervolumens zu füllen.  Tatsache ist, dass bei Erreichen von 80% der Neuausgleichsmechanismus automatisch gestartet wird und das Speichersystem beginnt, Daten auf alle Cluster-Hosts zu verteilen.  Das Verfahren ist sehr ressourcenintensiv und kann die Leistung des Festplattensubsystems erheblich beeinträchtigen. <br><br>  Um den Anforderungen einer Vielzahl von Kunden gerecht zu werden, haben wir drei Speicherpools implementiert, um die Verwendung in verschiedenen Szenarien zu vereinfachen.  Schauen wir uns jeden von ihnen der Reihe nach an. <br><br><h3>  Schneller Plattenpool </h3><br>  Die Priorität beim Erstellen dieses Pools bestand darin, Speicher zu erhalten, der maximale Leistung für das Hosten hoch ausgelasteter Systeme bietet.  Server aus diesem Pool verwenden ein Paar Intel P4600 als Cache und 10 Intel P3520 als Datenspeicher.  Der Cache in diesem Pool wird verwendet, damit Daten direkt vom Medium gelesen werden und Schreibvorgänge über den Cache ausgeführt werden. <br><br>  Um die Nutzkapazität zu erhöhen und die Fehlertoleranz sicherzustellen, wird ein Datenspeichermodell namens Erasure Coding verwendet.  Dieses Modell ähnelt einem normalen RAID 5/6-Array, jedoch auf der Ebene der Objektspeicherung.  Um die Wahrscheinlichkeit einer Datenbeschädigung auszuschließen, verwendet vSAN einen Prüfsummenberechnungsmechanismus für jeden 4K-Datenblock. <br><br>  Die Validierung wird im Hintergrund während Lese- / Schreibvorgängen sowie für „kalte“ Daten durchgeführt, auf die im Laufe des Jahres kein Zugriff angefordert wurde.  Wenn eine Nichtübereinstimmung der Prüfsumme festgestellt wird und daher eine Datenbeschädigung festgestellt wird, stellt vSAN Dateien automatisch durch Überschreiben wieder her. <br><br><h3>  Hybrid-Laufwerkpool </h3><br>  Bei diesem Pool besteht seine Hauptaufgabe darin, eine große Datenmenge bereitzustellen und gleichzeitig ein gutes Maß an Fehlertoleranz sicherzustellen.  Bei vielen Aufgaben hat die Geschwindigkeit des Datenzugriffs keine Priorität, das Volumen und die Speicherkosten sind viel wichtiger.  Die Verwendung von Solid-State-Laufwerken als solcher Speicher ist mit unangemessen hohen Kosten verbunden. <br><br>  Dieser Faktor war der Grund für die Erstellung des Pools, der eine Mischung aus Solid-State-Laufwerken (wie in anderen Pools Intel P4600) und von HGST entwickelten Festplatten auf Unternehmensebene ist.  Ein hybrider Workflow beschleunigt den Zugriff auf häufig angeforderte Daten durch Zwischenspeichern von Lese- und Schreibvorgängen. <br><br>  Auf der logischen Ebene werden Daten gespiegelt, um Verluste bei einem Hardwarefehler zu vermeiden.  Jedes Objekt ist in identische Komponenten unterteilt und wird vom System an verschiedene Hosts verteilt. <br><br><h3>  Pool mit Notfallwiederherstellung </h3><br><img src="https://habrastorage.org/webt/hz/ne/xi/hznexild-sq7oxyvy6m9yvr-xm4.png"><br><br>  Die Hauptaufgabe des Pools besteht darin, ein Höchstmaß an Fehlertoleranz und Leistung zu erreichen.  Durch die Verwendung der <strong>Stretched vSAN-</strong> Technologie konnten wir den Speicher zwischen den Rechenzentren Tsvetochnaya-2 in St. Petersburg und Dubrovka-3 in der Region Leningrad <strong>verteilen</strong> .  Jeder Server in diesem Pool ist mit zwei leistungsstarken Intel P4600-Laufwerken für den Cache-Betrieb und 6 Intel P3520-Laufwerken für die Datenspeicherung ausgestattet.  Auf der logischen Ebene sind dies 2 Plattengruppen pro Host. <br><br>  Die AllFlash-Konfiguration hat keinen schwerwiegenden Nachteil - einen starken Rückgang der IOPS und eine Zunahme der Warteschlange für Festplattenanforderungen mit einem erhöhten Volumen an wahlfreiem Zugriff auf Daten.  Genau wie in einem Pool mit schnellen Festplatten werden Schreibvorgänge durch den Cache geleitet und das Lesen erfolgt direkt. <br><br>  Nun zum Hauptunterschied zum Rest der Pools.  Die Daten jeder virtuellen Maschine werden in einem Rechenzentrum gespiegelt und gleichzeitig synchron in ein anderes Rechenzentrum repliziert, das uns gehört.  Selbst ein schwerer Unfall, beispielsweise eine vollständige Unterbrechung der Konnektivität zwischen Rechenzentren, ist daher kein Problem.  Selbst ein vollständiger Verlust des Rechenzentrums wirkt sich nicht auf die Daten aus. <br><br>  Ein Unfall mit einem vollständigen Ausfall der Site - die Situation ist ziemlich selten, aber vSAN kann sie mit Ehre überleben, ohne Daten zu verlieren.  Die Gäste unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SelectelTechDay 2018-</a> Veranstaltung konnten sich selbst davon überzeugen, wie im Stretched vSAN-Cluster ein vollständiger Standortfehler aufgetreten ist.  Virtuelle Maschinen wurden nur eine Minute nach dem Ausschalten aller Server an einem der Standorte verfügbar.  Alle Mechanismen funktionierten genau wie geplant, aber die Daten blieben unberührt. <br><br>  Die Aufgabe der bekannten Speicherarchitektur bringt viele Änderungen mit sich.  Eine dieser Änderungen war die Entstehung neuer virtueller „Entitäten“, zu denen auch die Zeugen-Appliance gehört.  Die Bedeutung dieser Lösung besteht darin, den Prozess der Aufzeichnung von Replikaten von Daten zu verfolgen und zu bestimmen, welche relevant sind.  Gleichzeitig werden die Daten selbst nicht in Zeugenkomponenten gespeichert, sondern nur in Metadaten zum Aufzeichnungsprozess. <br><br>  Dieser Mechanismus wird im Falle eines Unfalls wirksam, wenn während des Replikationsprozesses ein Fehler auftritt, der dazu führt, dass die Replikate nicht synchron sind. <br><br>  Um festzustellen, welche relevante Informationen enthalten, wird ein Quorum-Bestimmungsmechanismus verwendet.  Jede Komponente hat ein „Stimmrecht“ und erhält eine bestimmte Anzahl von Stimmen (1 oder mehr).  Das gleiche „Stimmrecht“ hat Zeugenbestandteile, die im Falle einer kontroversen Situation die Rolle von Schiedsrichtern spielen. <br><br>  Ein Quorum wird nur erreicht, wenn für ein Objekt eine vollständige Replik verfügbar ist und die Anzahl der aktuellen „Stimmen“ mehr als 50% beträgt. <br><br><h2>  Fazit </h2><br>  Die Wahl von VMware vSAN als Speichersystem ist für uns zu einer wichtigen Entscheidung geworden.  Diese Option hat Stresstests und Fehlertoleranztests bestanden, bevor sie in unser VMware-basiertes Cloud-Projekt aufgenommen wurde. <br><br>  Den Testergebnissen zufolge wurde deutlich, dass die deklarierte Funktionalität wie erwartet funktioniert und alle Anforderungen unserer Cloud-Infrastruktur erfüllt. <br><br>  Haben Sie aufgrund Ihrer eigenen Erfahrung mit vSAN etwas zu erzählen?  Willkommen zu den Kommentaren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418753/">https://habr.com/ru/post/de418753/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418739/index.html">Additive Technology Center: Industrielle 3D-Drucker 3D-Systeme, Stratasys, SLM, EOS</a></li>
<li><a href="../de418741/index.html">Fügen Sie die Verschlüsselung hinzu und drücken Sie auf reguläres SIP</a></li>
<li><a href="../de418743/index.html">Geschichte des ersten Platzes im ML Boot Camp VI</a></li>
<li><a href="../de418747/index.html">Problemlösung: Wie können Probleme in einem Team effektiv gelöst werden?</a></li>
<li><a href="../de418751/index.html">Dex frecher chinesischer Spion</a></li>
<li><a href="../de418755/index.html">Wie E-Commerce groß angelegte Werbeaktionen überlebt. Vorbereitung auf Spitzenlasten im Web [Teil 1]</a></li>
<li><a href="../de418757/index.html">Ausdünnende Zeitrahmen (Kryptowährungen, Devisen, Börsen)</a></li>
<li><a href="../de418759/index.html">Wie viel kostet es für einen Studenten, einen Chip auszustellen?</a></li>
<li><a href="../de418761/index.html">Das Buch „Pure Python. Die Feinheiten der Programmierung für Profis »</a></li>
<li><a href="../de418763/index.html">Mittel / Senior: Wie kann man aus dem Sumpf ausbrechen?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
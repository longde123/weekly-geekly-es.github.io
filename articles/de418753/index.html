<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëà ü§∂üèΩ üë®‚Äç‚ù§Ô∏è‚Äçüë® vSAN in der VMware Cloud ‚úñÔ∏è ü§∏üèæ üëßüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Speichern und Zugreifen auf Daten ist f√ºr jedes Informationssystem ein Problem. Selbst ein gut konzipiertes Speichersystem (im Folgenden als SHD b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>vSAN in der VMware Cloud</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/418753/"><img src="https://habrastorage.org/webt/pl/tj/to/pltjtoutsishswrt2dgxaktv5ka.png"><br><br>  Das Speichern und Zugreifen auf Daten ist f√ºr jedes Informationssystem ein Problem.  Selbst ein gut konzipiertes Speichersystem (im Folgenden als SHD bezeichnet) w√§hrend des Betriebs zeigt Probleme, die mit einer verringerten Leistung verbunden sind.  Besondere Aufmerksamkeit sollte einer Reihe von Skalierungsproblemen gewidmet werden, wenn sich die Menge der beteiligten Ressourcen den von Speicherentwicklern festgelegten Grenzwerten n√§hert. <br><br>  Der Hauptgrund f√ºr das Auftreten dieser Probleme ist die traditionelle Architektur, die auf einer engen Bindung an die Hardwareeigenschaften der verwendeten Speicherger√§te basiert.  Die meisten Kunden w√§hlen nach wie vor die Methode zum Speichern und Zugreifen auf Daten, wobei die Merkmale der physischen Schnittstellen (SAS / SATA / SCSI) und nicht die tats√§chlichen Anforderungen der verwendeten Anwendungen ber√ºcksichtigt werden. <br><a name="habracut"></a><br>  Vor einem Dutzend Jahren war dies eine logische Entscheidung.  Systemadministratoren w√§hlten sorgf√§ltig Informationsspeicherger√§te mit den erforderlichen Spezifikationen aus, z. B. SATA / SAS, und rechneten damit, ein Leistungsniveau zu erreichen, das auf den Hardwarefunktionen von Festplattencontrollern basiert.  Der Kampf ging um das Volumen der RAID-Controller-Caches und um Optionen, die Datenverlust verhindern.  Dieser Ansatz zur L√∂sung des Problems ist nicht optimal. <br><br>  In der aktuellen Umgebung ist es bei der Auswahl von Speichersystemen sinnvoll, nicht von physischen Schnittstellen auszugehen, sondern von der in IOPS ausgedr√ºckten Leistung (Anzahl der E / A-Vorg√§nge pro Sekunde).  Durch die Verwendung der Virtualisierung k√∂nnen Sie vorhandene Hardwareressourcen flexibel nutzen und das erforderliche Leistungsniveau gew√§hrleisten.  Wir f√ºr unseren Teil sind bereit, Ressourcen mit den Eigenschaften bereitzustellen, die f√ºr die Anwendung wirklich notwendig sind. <br><br><h2>  Speichervirtualisierung </h2><br>  Mit der Entwicklung von Virtualisierungssystemen war es notwendig, eine innovative L√∂sung zum Speichern und Zugreifen auf Daten zu finden und gleichzeitig die Fehlertoleranz sicherzustellen.  Dies war der Ausgangspunkt f√ºr die Erstellung von SDS (Software-Defined Storage).  Um den gesch√§ftlichen Anforderungen gerecht zu werden, wurden diese Repositorys mit der Trennung von Software und Hardware entwickelt. <br><br>  Die SDS-Architektur unterscheidet sich grundlegend von der traditionellen.  Die Speicherlogik wurde auf Softwareebene abstrahiert.  Die Organisation des Speichers ist aufgrund der Vereinheitlichung und Virtualisierung jeder der Komponenten eines solchen Systems einfacher geworden. <br><br>  Was ist der Hauptfaktor, der die Implementierung von Sicherheitsdatenbl√§ttern √ºberall behindert?  Dieser Faktor ist meistens eine falsche Bewertung der Bed√ºrfnisse der verwendeten Anwendungen und eine falsche Risikobewertung.  F√ºr ein Unternehmen h√§ngt die Wahl der L√∂sung von den Implementierungskosten ab, basierend auf den aktuell verbrauchten Ressourcen.  Nur wenige Leute denken - was passiert, wenn die Informationsmenge und die erforderliche Leistung die F√§higkeiten der ausgew√§hlten Architektur √ºberschreiten.  Das Denken auf der Grundlage des methodischen Prinzips ‚Äûman sollte nicht ohne Notwendigkeit existieren‚Äú, besser bekannt als ‚ÄûOccams Klinge‚Äú, entscheidet √ºber die Wahl traditioneller L√∂sungen. <br><br>  Nur wenige verstehen, dass die Notwendigkeit der Skalierbarkeit und Zuverl√§ssigkeit der Datenspeicherung wichtiger ist, als es auf den ersten Blick scheint.  Informationen sind eine Ressource, und daher muss das Risiko ihres Verlusts versichert sein.  Was passiert, wenn ein herk√∂mmliches Speichersystem ausf√§llt?  Sie m√ºssen die Garantie nutzen oder neue Ger√§te kaufen.  Und wenn das Speichersystem eingestellt wird oder die "Lebensdauer" (das sogenannte EOL - End-of-Life) beendet ist?  Dies kann ein schwarzer Tag f√ºr jedes Unternehmen sein, das seine eigenen vertrauten Dienste nicht weiter nutzen kann. <br><br>  Es gibt keine Systeme, die keinen einzigen Fehlerpunkt haben.  Es gibt jedoch Systeme, die den Ausfall einer oder mehrerer Komponenten problemlos √ºberstehen k√∂nnen.  Sowohl virtuelle als auch traditionelle Speichersysteme wurden unter Ber√ºcksichtigung der Tatsache erstellt, dass fr√ºher oder sp√§ter ein Fehler auftreten wird.  Dies ist nur die "Festigkeitsgrenze" herk√∂mmlicher Speichersysteme, die in der Hardware festgelegt sind, aber in virtuellen Speichersystemen wird sie in der Softwareschicht festgelegt. <br><br><h2>  Integration </h2><br>  Dramatische √Ñnderungen in der IT-Infrastruktur sind immer ein unerw√ºnschtes Ph√§nomen, das mit Ausfallzeiten und Geldverlusten behaftet ist.  Nur die reibungslose Implementierung neuer L√∂sungen erm√∂glicht es, negative Folgen zu vermeiden und die Arbeit der Dienste zu verbessern.  Aus diesem Grund hat Selectel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Cloud basierend auf VMware</a> entwickelt und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eingef√ºhrt</a> , einem anerkannten Marktf√ºhrer im Bereich Virtualisierung.  Mit dem von uns erstellten Service kann jedes Unternehmen alle Infrastrukturaufgaben einschlie√ülich der Datenspeicherung l√∂sen. <br><br>  Wir werden Ihnen genau sagen, wie wir uns f√ºr ein Speichersystem entschieden haben und welche Vorteile uns diese Wahl gebracht hat.  Nat√ºrlich wurden sowohl traditionelle Speichersysteme als auch Sicherheitsdatenbl√§tter ber√ºcksichtigt.  Um alle Aspekte des Betriebs und der Risiken klar zu verstehen, bieten wir einen tieferen Einblick in das Thema. <br><br>  In der Entwurfsphase wurden folgende Anforderungen an Speichersysteme gestellt: <br><br><ul><li>  <strong>Fehlertoleranz;</strong> </li><li>  <strong>Leistung</strong> </li><li>  <strong>Skalierung</strong> </li><li>  <strong>die F√§higkeit, Geschwindigkeit zu garantieren;</strong> </li><li>  <strong>korrekter Betrieb im VMware-√ñkosystem.</strong> </li></ul><br>  Die Verwendung herk√∂mmlicher Hardwarel√∂sungen konnte nicht das erforderliche Ma√ü an Skalierbarkeit bieten, da es aufgrund architektonischer Einschr√§nkungen unm√∂glich ist, das Speichervolumen st√§ndig zu erh√∂hen.  Die Reservierung auf der Ebene eines gesamten Rechenzentrums war ebenfalls sehr schwierig.  Deshalb haben wir unsere Aufmerksamkeit auf SDS gerichtet. <br><br>  Es gibt verschiedene Softwarel√∂sungen auf dem SDS-Markt, die f√ºr den Aufbau einer Cloud auf Basis von VMware vSphere geeignet sind.  Unter diesen L√∂sungen k√∂nnen festgestellt werden: <br><br><ul><li>  <strong>Dell EMC ScaleIO;</strong> </li><li>  <strong>Hyperkonvergentes virtuelles SAN f√ºr Datencore;</strong> </li><li>  <strong>HPE StoreVirtual.</strong> </li></ul><br>  Diese L√∂sungen sind f√ºr die Verwendung mit VMware vSphere geeignet. Sie lassen sich jedoch nicht in den Hypervisor integrieren und werden separat ausgef√ºhrt.  Daher wurde die Wahl zugunsten von VMware vSAN getroffen.  Lassen Sie uns im Detail betrachten, wie die virtuelle Architektur einer solchen L√∂sung aussieht. <br><br><h3>  Architektur </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hb/hu/nr/hbhunruzcic-pa1ggjw_-winfcg.png"></div><br>  <sup><i>Bild aus der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offiziellen Dokumentation</a></i></sup> <br><br>  Im Gegensatz zu herk√∂mmlichen Speichersystemen werden nicht alle Informationen an einem bestimmten Punkt gespeichert.  Die Daten der virtuellen Maschine werden gleichm√§√üig auf alle Hosts verteilt. Die Skalierung erfolgt durch Hinzuf√ºgen von Hosts oder Installieren zus√§tzlicher Festplattenlaufwerke.  Es werden zwei Konfigurationsoptionen unterst√ºtzt: <br><br><ul><li>  <strong>AllFlash-Konfiguration</strong> (nur Solid-State-Laufwerke, sowohl f√ºr die Datenspeicherung als auch f√ºr den Cache); </li><li>  <strong>Hybridkonfiguration</strong> (magnetischer Speicher und Solid State Cache). </li></ul><br>  Das Verfahren zum Hinzuf√ºgen von Speicherplatz erfordert keine zus√§tzlichen Einstellungen, z. B. das Erstellen einer LUN (Logical Unit Number, Logical Disk Numbers) und das Festlegen des Zugriffs darauf.  Sobald der Host zum Cluster hinzugef√ºgt wird, steht sein Speicherplatz f√ºr alle virtuellen Maschinen zur Verf√ºgung.  Dieser Ansatz hat mehrere wesentliche Vorteile: <br><br><ul><li>  <strong>mangelnde Bindung an den Ger√§tehersteller;</strong> </li><li>  <strong>erh√∂hte Fehlertoleranz;</strong> </li><li>  <strong>Gew√§hrleistung der Datenintegrit√§t im Falle eines Fehlers;</strong> </li><li>  <strong>einzelnes Kontrollzentrum √ºber die vSphere-Konsole;</strong> </li><li>  <strong>bequeme horizontale und vertikale Skalierung.</strong> </li></ul><br>  Diese Architektur stellt jedoch hohe Anforderungen an die Netzwerkinfrastruktur.  Um einen maximalen Durchsatz zu gew√§hrleisten, basiert das Netzwerk in unserer Cloud auf dem Spine-Leaf-Modell. <br><br><h3>  Netzwerk </h3><br>  Das traditionelle dreistufige Netzwerkmodell (Kern / Aggregation / Zugriff) weist eine Reihe erheblicher Nachteile auf.  Ein bemerkenswertes Beispiel sind die Einschr√§nkungen der Spanning-Tree-Protokolle. <br><br>  Das Spine-Leaf-Modell verwendet nur zwei Ebenen, was die folgenden Vorteile bietet: <br><br><ul><li>  <strong>vorhersehbarer Abstand zwischen Ger√§ten;</strong> </li><li>  <strong>Der Verkehr verl√§uft auf der besten Route.</strong> </li><li>  <strong>einfache Skalierung;</strong> </li><li>  <strong>Ausschluss von L2-Protokollbeschr√§nkungen.</strong> </li></ul><br>  Ein wesentliches Merkmal einer solchen Architektur ist, dass sie f√ºr den Durchgang von "horizontalem" Verkehr optimiert ist.  Datenpakete durchlaufen nur einen Sprung, was eine klare Sch√§tzung der Verz√∂gerungen erm√∂glicht. <br><br>  Eine physische Verbindung wird √ºber mehrere 10-GbE-Verbindungen pro Server bereitgestellt, deren Bandbreite mithilfe des Aggregationsprotokolls kombiniert wird.  Somit erh√§lt jeder physische Host Hochgeschwindigkeitszugriff auf alle Speicherobjekte. <br><br>  Der Datenaustausch wird mithilfe eines von VMware erstellten propriet√§ren Protokolls implementiert, das einen schnellen und zuverl√§ssigen Betrieb des Speichernetzwerks beim Ethernet-Transport (ab 10 GbE) erm√∂glicht. <br><br>  Der √úbergang zum Objektmodell der Datenspeicherung erm√∂glichte eine flexible Anpassung der Speichernutzung an die Anforderungen der Kunden.  Alle Daten werden in Form von Objekten gespeichert, die auf bestimmte Weise auf die Cluster-Hosts verteilt werden.  Wir kl√§ren die Werte einiger Parameter, die gesteuert werden k√∂nnen. <br><br><h3>  Fehlertoleranz </h3><br><ol><li>  <strong>FTT (Fehler zu tolerieren).</strong>  Gibt die Anzahl der Hostfehler an, die der Cluster verarbeiten kann, ohne den regul√§ren Betrieb zu unterbrechen. </li><li>  <strong>FTM (Fehlertoleranzmethode).</strong>  Die Methode zur Gew√§hrleistung der Fehlertoleranz auf Plattenebene. <br><br>  a.  <strong>Spiegeln</strong> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jb/kv/lw/jbkvlwsmyvua7jrw2f8jj0820am.png"></div><br>  <sup><i>Bild aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VMware-Blog.</a></i></sup> <br><br>  Stellt eine vollst√§ndige Vervielf√§ltigung eines Objekts dar, und Replikate befinden sich immer auf verschiedenen physischen Hosts.  Das dieser Methode am n√§chsten liegende Analogon ist RAID-1.  Durch seine Verwendung kann der Cluster routinem√§√üig bis zu drei Fehler von Komponenten (Festplatten, Hosts, Netzwerkverlust usw.) verarbeiten.  Dieser Parameter wird durch Einstellen der FTT-Option konfiguriert. <br><br>  Standardm√§√üig hat diese Option den Wert 1, und f√ºr das Objekt wird 1 Replikat erstellt (nur 2 Instanzen auf verschiedenen Hosts).  Mit zunehmendem Wert betr√§gt die Anzahl der Kopien N + 1.  Bei einem Maximalwert von FTT = 3 befinden sich 4 Instanzen des Objekts auf verschiedenen Hosts. <br><br>  Mit dieser Methode k√∂nnen Sie maximale Leistung auf Kosten der Speicherplatzeffizienz erzielen.  Es kann sowohl in Hybrid- als auch in AllFlash-Konfigurationen verwendet werden. <br><br>  b.  <strong>L√∂schcodierung</strong> (analog zu RAID 5/6). <br><img src="https://habrastorage.org/webt/72/zq/hh/72zqhhyrlncoqga9qlzg0wdfgco.png"><br><br>  <sup><i>Bild aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem</a> Blog von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cormachogan.com.</a></i></sup> <br><br>  Die Arbeit dieser Methode wird ausschlie√ülich in AllFlash-Konfigurationen unterst√ºtzt.  Bei der Aufzeichnung jedes Objekts werden die entsprechenden Parit√§tsbl√∂cke berechnet, die im Falle eines Fehlers die eindeutige Wiederherstellung von Daten erm√∂glichen.  Dieser Ansatz spart im Vergleich zur Spiegelung erheblich Speicherplatz. <br><br>  Nat√ºrlich erh√∂ht der Betrieb dieses Verfahrens den Overhead, was sich in einer Verringerung der Produktivit√§t √§u√üert.  Angesichts der Leistung der AllFlash-Konfiguration ist dieser Nachteil jedoch ausgeglichen, sodass die Verwendung der L√∂schcodierung f√ºr die meisten Aufgaben eine akzeptable Option ist. <br><br>  Dar√ºber hinaus f√ºhrt VMware vSAN das Konzept der ‚ÄûFehlerdom√§nen‚Äú ein, bei denen es sich um eine logische Gruppierung von Server-Racks oder Festplattenk√∂rben handelt.  Sobald die erforderlichen Elemente gruppiert sind, f√ºhrt dies zur Verteilung der Daten auf verschiedene Knoten unter Ber√ºcksichtigung der Fehlerdom√§nen.  Auf diese Weise kann der Cluster den Verlust einer gesamten Dom√§ne √ºberleben, da sich alle entsprechenden Replikate der Objekte auf anderen Hosts in einer anderen Fehlerdom√§ne befinden. <br><br>  Die kleinste Fehlerdom√§ne ist eine Datentr√§gergruppe, bei der es sich um ein logisch verbundenes Laufwerk handelt.  Jede Datentr√§gergruppe enth√§lt zwei Arten von Medien - Cache und Kapazit√§t.  Als Cache-Medium erlaubt das System die Verwendung nur von Solid-State-Disks, und sowohl Magnet- als auch Solid-State-Disks k√∂nnen als Kapazit√§tstr√§ger fungieren.  Durch das Zwischenspeichern von Medien k√∂nnen Magnetplatten beschleunigt und die Latenz beim Zugriff auf Daten verringert werden. </li></ol><br><h2>  Implementierung </h2><br>  Lassen Sie uns dar√ºber sprechen, welche Einschr√§nkungen in der VMware vSAN-Architektur bestehen und warum sie ben√∂tigt werden.  Unabh√§ngig von den verwendeten Hardwareplattformen bietet die Architektur die folgenden Einschr√§nkungen: <br><br><ul><li>  <strong>nicht mehr als 5 Plattengruppen pro Host;</strong> </li><li>  <strong>nicht mehr als 7 Kapazit√§tstr√§ger in einer Plattengruppe;</strong> </li><li>  <strong>nicht mehr als 1 Cache-Tr√§ger in einer Plattengruppe;</strong> </li><li>  <strong>nicht mehr als 35 Kapazit√§tstr√§ger pro Host;</strong> </li><li>  <strong>nicht mehr als 9000 Komponenten pro Host (einschlie√ülich Zeugenkomponenten);</strong> </li><li>  <strong>nicht mehr als 64 Hosts in einem Cluster;</strong> </li><li>  <strong>Nicht mehr als 1 vSAN-Datenspeicher pro Cluster.</strong> </li></ul><br>  Warum wird das ben√∂tigt?  Bis die angegebenen Grenzwerte √ºberschritten werden, arbeitet das System mit der angegebenen Kapazit√§t und h√§lt ein Gleichgewicht zwischen Leistung und Speicherkapazit√§t aufrecht.  Auf diese Weise k√∂nnen Sie den korrekten Betrieb des gesamten virtuellen Speichersystems als Ganzes gew√§hrleisten. <br><br>  Zus√§tzlich zu diesen Einschr√§nkungen sollte ein wichtiges Merkmal beachtet werden.  Es wird nicht empfohlen, mehr als 70% des gesamten Speichervolumens zu f√ºllen.  Tatsache ist, dass bei Erreichen von 80% der Neuausgleichsmechanismus automatisch gestartet wird und das Speichersystem beginnt, Daten auf alle Cluster-Hosts zu verteilen.  Das Verfahren ist sehr ressourcenintensiv und kann die Leistung des Festplattensubsystems erheblich beeintr√§chtigen. <br><br>  Um den Anforderungen einer Vielzahl von Kunden gerecht zu werden, haben wir drei Speicherpools implementiert, um die Verwendung in verschiedenen Szenarien zu vereinfachen.  Schauen wir uns jeden von ihnen der Reihe nach an. <br><br><h3>  Schneller Plattenpool </h3><br>  Die Priorit√§t beim Erstellen dieses Pools bestand darin, Speicher zu erhalten, der maximale Leistung f√ºr das Hosten hoch ausgelasteter Systeme bietet.  Server aus diesem Pool verwenden ein Paar Intel P4600 als Cache und 10 Intel P3520 als Datenspeicher.  Der Cache in diesem Pool wird verwendet, damit Daten direkt vom Medium gelesen werden und Schreibvorg√§nge √ºber den Cache ausgef√ºhrt werden. <br><br>  Um die Nutzkapazit√§t zu erh√∂hen und die Fehlertoleranz sicherzustellen, wird ein Datenspeichermodell namens Erasure Coding verwendet.  Dieses Modell √§hnelt einem normalen RAID 5/6-Array, jedoch auf der Ebene der Objektspeicherung.  Um die Wahrscheinlichkeit einer Datenbesch√§digung auszuschlie√üen, verwendet vSAN einen Pr√ºfsummenberechnungsmechanismus f√ºr jeden 4K-Datenblock. <br><br>  Die Validierung wird im Hintergrund w√§hrend Lese- / Schreibvorg√§ngen sowie f√ºr ‚Äûkalte‚Äú Daten durchgef√ºhrt, auf die im Laufe des Jahres kein Zugriff angefordert wurde.  Wenn eine Nicht√ºbereinstimmung der Pr√ºfsumme festgestellt wird und daher eine Datenbesch√§digung festgestellt wird, stellt vSAN Dateien automatisch durch √úberschreiben wieder her. <br><br><h3>  Hybrid-Laufwerkpool </h3><br>  Bei diesem Pool besteht seine Hauptaufgabe darin, eine gro√üe Datenmenge bereitzustellen und gleichzeitig ein gutes Ma√ü an Fehlertoleranz sicherzustellen.  Bei vielen Aufgaben hat die Geschwindigkeit des Datenzugriffs keine Priorit√§t, das Volumen und die Speicherkosten sind viel wichtiger.  Die Verwendung von Solid-State-Laufwerken als solcher Speicher ist mit unangemessen hohen Kosten verbunden. <br><br>  Dieser Faktor war der Grund f√ºr die Erstellung des Pools, der eine Mischung aus Solid-State-Laufwerken (wie in anderen Pools Intel P4600) und von HGST entwickelten Festplatten auf Unternehmensebene ist.  Ein hybrider Workflow beschleunigt den Zugriff auf h√§ufig angeforderte Daten durch Zwischenspeichern von Lese- und Schreibvorg√§ngen. <br><br>  Auf der logischen Ebene werden Daten gespiegelt, um Verluste bei einem Hardwarefehler zu vermeiden.  Jedes Objekt ist in identische Komponenten unterteilt und wird vom System an verschiedene Hosts verteilt. <br><br><h3>  Pool mit Notfallwiederherstellung </h3><br><img src="https://habrastorage.org/webt/hz/ne/xi/hznexild-sq7oxyvy6m9yvr-xm4.png"><br><br>  Die Hauptaufgabe des Pools besteht darin, ein H√∂chstma√ü an Fehlertoleranz und Leistung zu erreichen.  Durch die Verwendung der <strong>Stretched vSAN-</strong> Technologie konnten wir den Speicher zwischen den Rechenzentren Tsvetochnaya-2 in St. Petersburg und Dubrovka-3 in der Region Leningrad <strong>verteilen</strong> .  Jeder Server in diesem Pool ist mit zwei leistungsstarken Intel P4600-Laufwerken f√ºr den Cache-Betrieb und 6 Intel P3520-Laufwerken f√ºr die Datenspeicherung ausgestattet.  Auf der logischen Ebene sind dies 2 Plattengruppen pro Host. <br><br>  Die AllFlash-Konfiguration hat keinen schwerwiegenden Nachteil - einen starken R√ºckgang der IOPS und eine Zunahme der Warteschlange f√ºr Festplattenanforderungen mit einem erh√∂hten Volumen an wahlfreiem Zugriff auf Daten.  Genau wie in einem Pool mit schnellen Festplatten werden Schreibvorg√§nge durch den Cache geleitet und das Lesen erfolgt direkt. <br><br>  Nun zum Hauptunterschied zum Rest der Pools.  Die Daten jeder virtuellen Maschine werden in einem Rechenzentrum gespiegelt und gleichzeitig synchron in ein anderes Rechenzentrum repliziert, das uns geh√∂rt.  Selbst ein schwerer Unfall, beispielsweise eine vollst√§ndige Unterbrechung der Konnektivit√§t zwischen Rechenzentren, ist daher kein Problem.  Selbst ein vollst√§ndiger Verlust des Rechenzentrums wirkt sich nicht auf die Daten aus. <br><br>  Ein Unfall mit einem vollst√§ndigen Ausfall der Site - die Situation ist ziemlich selten, aber vSAN kann sie mit Ehre √ºberleben, ohne Daten zu verlieren.  Die G√§ste unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SelectelTechDay 2018-</a> Veranstaltung konnten sich selbst davon √ºberzeugen, wie im Stretched vSAN-Cluster ein vollst√§ndiger Standortfehler aufgetreten ist.  Virtuelle Maschinen wurden nur eine Minute nach dem Ausschalten aller Server an einem der Standorte verf√ºgbar.  Alle Mechanismen funktionierten genau wie geplant, aber die Daten blieben unber√ºhrt. <br><br>  Die Aufgabe der bekannten Speicherarchitektur bringt viele √Ñnderungen mit sich.  Eine dieser √Ñnderungen war die Entstehung neuer virtueller ‚ÄûEntit√§ten‚Äú, zu denen auch die Zeugen-Appliance geh√∂rt.  Die Bedeutung dieser L√∂sung besteht darin, den Prozess der Aufzeichnung von Replikaten von Daten zu verfolgen und zu bestimmen, welche relevant sind.  Gleichzeitig werden die Daten selbst nicht in Zeugenkomponenten gespeichert, sondern nur in Metadaten zum Aufzeichnungsprozess. <br><br>  Dieser Mechanismus wird im Falle eines Unfalls wirksam, wenn w√§hrend des Replikationsprozesses ein Fehler auftritt, der dazu f√ºhrt, dass die Replikate nicht synchron sind. <br><br>  Um festzustellen, welche relevante Informationen enthalten, wird ein Quorum-Bestimmungsmechanismus verwendet.  Jede Komponente hat ein ‚ÄûStimmrecht‚Äú und erh√§lt eine bestimmte Anzahl von Stimmen (1 oder mehr).  Das gleiche ‚ÄûStimmrecht‚Äú hat Zeugenbestandteile, die im Falle einer kontroversen Situation die Rolle von Schiedsrichtern spielen. <br><br>  Ein Quorum wird nur erreicht, wenn f√ºr ein Objekt eine vollst√§ndige Replik verf√ºgbar ist und die Anzahl der aktuellen ‚ÄûStimmen‚Äú mehr als 50% betr√§gt. <br><br><h2>  Fazit </h2><br>  Die Wahl von VMware vSAN als Speichersystem ist f√ºr uns zu einer wichtigen Entscheidung geworden.  Diese Option hat Stresstests und Fehlertoleranztests bestanden, bevor sie in unser VMware-basiertes Cloud-Projekt aufgenommen wurde. <br><br>  Den Testergebnissen zufolge wurde deutlich, dass die deklarierte Funktionalit√§t wie erwartet funktioniert und alle Anforderungen unserer Cloud-Infrastruktur erf√ºllt. <br><br>  Haben Sie aufgrund Ihrer eigenen Erfahrung mit vSAN etwas zu erz√§hlen?  Willkommen zu den Kommentaren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418753/">https://habr.com/ru/post/de418753/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418739/index.html">Additive Technology Center: Industrielle 3D-Drucker 3D-Systeme, Stratasys, SLM, EOS</a></li>
<li><a href="../de418741/index.html">F√ºgen Sie die Verschl√ºsselung hinzu und dr√ºcken Sie auf regul√§res SIP</a></li>
<li><a href="../de418743/index.html">Geschichte des ersten Platzes im ML Boot Camp VI</a></li>
<li><a href="../de418747/index.html">Probleml√∂sung: Wie k√∂nnen Probleme in einem Team effektiv gel√∂st werden?</a></li>
<li><a href="../de418751/index.html">Dex frecher chinesischer Spion</a></li>
<li><a href="../de418755/index.html">Wie E-Commerce gro√ü angelegte Werbeaktionen √ºberlebt. Vorbereitung auf Spitzenlasten im Web [Teil 1]</a></li>
<li><a href="../de418757/index.html">Ausd√ºnnende Zeitrahmen (Kryptow√§hrungen, Devisen, B√∂rsen)</a></li>
<li><a href="../de418759/index.html">Wie viel kostet es f√ºr einen Studenten, einen Chip auszustellen?</a></li>
<li><a href="../de418761/index.html">Das Buch ‚ÄûPure Python. Die Feinheiten der Programmierung f√ºr Profis ¬ª</a></li>
<li><a href="../de418763/index.html">Mittel / Senior: Wie kann man aus dem Sumpf ausbrechen?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
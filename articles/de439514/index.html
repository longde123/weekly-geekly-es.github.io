<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôéüèº ü¶Ü üë©üèΩ‚Äç‚úàÔ∏è Tarantool-Replikation: Konfiguration und Verwendung üë®üèæ‚Äçüé§ üöá üìì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich betrete das Tarantool Core Team und beteilige mich an der Entwicklung eines Datenbankmoduls, der internen Kommunikation von Serverkomponenten und ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tarantool-Replikation: Konfiguration und Verwendung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439514/"><img src="https://habrastorage.org/webt/ec/a3/bt/eca3bttl2uu6rg8sz7e9sj3o3us.jpeg"><br><br>  Ich betrete das Tarantool Core Team und beteilige mich an der Entwicklung eines Datenbankmoduls, der internen Kommunikation von Serverkomponenten und der Replikation.  Und heute werde ich Ihnen sagen, wie die Replikation funktioniert. <br><a name="habracut"></a><br><h2>  Informationen zur Replikation </h2><br>  Bei der Replikation werden Kopien von Daten von einem Gesch√§ft in ein anderes erstellt.  Jede Kopie wird als Replikat bezeichnet.  Die Replikation kann verwendet werden, wenn Sie ein Backup erstellen, Hot Standby implementieren oder das System horizontal skalieren m√ºssen.  Und daf√ºr ist es notwendig, die gleichen Daten auf verschiedenen Knoten des Computernetzwerks des Clusters verwenden zu k√∂nnen. <br><br>  Wir klassifizieren die Replikation auf zwei Arten: <br><br><ul><li> <b>Richtung: Master-Master oder Master-Slave</b> .  Die Master-Slave-Replikation ist die einfachste Option.  Sie haben einen Knoten, auf dem Sie Daten √§ndern.  Sie √ºbersetzen diese √Ñnderungen auf die anderen Knoten, auf die sie angewendet werden.  Bei der Master-Master-Replikation werden √Ñnderungen an mehreren Knoten gleichzeitig vorgenommen.  In diesem Fall √§ndert jeder Knoten seine Daten selbst und wendet die an anderen Knoten vorgenommenen √Ñnderungen auf sich selbst an. </li><li>  <b>Betriebsart: asynchron oder synchron</b> .  Die synchrone Replikation bedeutet, dass keine Daten festgeschrieben werden und die Replikation dem Benutzer erst best√§tigt wird, wenn die √Ñnderungen √ºber mindestens die Mindestanzahl von Clusterknoten √ºbertragen werden.  Bei der asynchronen Replikation sind das Festschreiben einer Transaktion (Festschreiben) und die Interaktion mit einem Benutzer zwei unabh√§ngige Prozesse.  Um Daten festzuschreiben, m√ºssen sie nur in das lokale Protokoll fallen, und erst dann werden diese √Ñnderungen auf irgendeine Weise an andere Knoten √ºbertragen.  Offensichtlich hat die asynchrone Replikation aus diesem Grund eine Reihe von Nebenwirkungen. </li></ul><br><h2>  Wie funktioniert die Replikation in Tarantool? </h2><br>  Die Replikation in Tarantool bietet mehrere Funktionen: <br><br><ul><li>  Es besteht aus einfachen Bausteinen, mit denen Sie einen Cluster beliebiger Topologie erstellen k√∂nnen.  Jedes dieser grundlegenden Konfigurationselemente ist unidirektional, dh Sie haben immer Master und Slave.  Der Master f√ºhrt einige Aktionen aus und generiert ein Protokoll der Vorg√§nge, das auf dem Replikat verwendet wird. </li><li>  Die Tarantool-Replikation ist asynchron.  Das hei√üt, das System best√§tigt das Festschreiben an Sie, unabh√§ngig davon, wie viele Replikate diese Transaktion gesehen hat, wie viel sie auf sich selbst angewendet wurde und ob sie √ºberhaupt ausgef√ºhrt wurde. </li><li>  Eine weitere Eigenschaft der Replikation in Tarantool ist, dass sie zeilenbasiert ist.  Tarantool f√ºhrt ein Operationsprotokoll (WAL).  Die Operation gelangt zeilenweise dorthin, dh wenn sich ein Tapla aus dem Leerzeichen √§ndert, wird diese Operation als eine Zeile in das Protokoll geschrieben.  Danach liest der Hintergrundprozess diese Zeile aus dem Protokoll und sendet sie an das Replikat.  Wie viele Replikate der Master hat, so viele Hintergrundprozesse.  Das hei√üt, jeder Replikationsprozess auf verschiedene Knoten des Clusters wird asynchron von anderen ausgef√ºhrt. </li><li>  Jeder Clusterknoten verf√ºgt √ºber eine eigene eindeutige Kennung, die beim Erstellen des Knotens generiert wird.  Dar√ºber hinaus verf√ºgt der Knoten √ºber eine Kennung im Cluster (Mitgliedsnummer).  Dies ist eine numerische Konstante, die einem Replikat zugewiesen wird, wenn eine Verbindung zu einem Cluster besteht, und die w√§hrend ihrer gesamten Lebensdauer im Cluster beim Replikat verbleibt. </li></ul><br>  Aufgrund der Asynchronit√§t werden Daten an verz√∂gerte Replikate geliefert.  Das hei√üt, Sie haben einige √Ñnderungen vorgenommen, das System hat das Festschreiben best√§tigt, die Operation wurde bereits auf den Master angewendet, aber auf Replikaten wird sie mit einer gewissen Verz√∂gerung angewendet, die durch die Geschwindigkeit bestimmt wird, mit der der Hintergrundreplikationsprozess die Operation liest, an die Replik sendet und diese angewendet wird . <br><br>  Aus diesem Grund besteht die M√∂glichkeit, dass Daten nicht synchron sind.  Angenommen, wir haben mehrere Master, die miteinander verbundene Daten √§ndern.  Es kann sich herausstellen, dass die von Ihnen verwendeten Vorg√§nge nicht kommutativ sind und sich auf dieselben Daten beziehen. Dann haben zwei verschiedene Clustermitglieder unterschiedliche Versionen der Daten. <br><br>  <b>Wenn die Replikation in Tarantool ein unidirektionaler Master-Slave ist, wie wird dann Master-Master erstellt?</b>  Ganz einfach: Erstellen Sie einen anderen Replikationskanal, jedoch in die andere Richtung.  Sie m√ºssen verstehen, dass die Master-Master-Replikation in Tarantool nur eine Kombination aus zwei voneinander unabh√§ngigen Datenstr√∂men ist. <br><br>  Nach dem gleichen Prinzip k√∂nnen wir den dritten Master verbinden und als Ergebnis ein vollst√§ndiges Mesh-Netzwerk aufbauen, in dem jedes Replikat ein Master und ein Slave f√ºr alle anderen Replikate ist. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nx/z5/b-/nxz5b-f9rzqtmhi7ga4fhq8pdq8.png" width="500"></div><br>  Beachten Sie, dass nicht nur die Vorg√§nge repliziert werden, die lokal auf diesem Master initiiert werden, sondern auch diejenigen, die er extern √ºber Replikationsprotokolle empfangen hat.  In diesem Fall werden die auf Replikat Nr. 1 erstellten √Ñnderungen zweimal auf Replikat Nr. 3 angewendet: direkt und √ºber Replikat Nr. 2. Mit dieser Eigenschaft k√∂nnen komplexere Topologien ohne Verwendung eines vollst√§ndigen Netzes erstellt werden.  Sagen wir diesen. <br><br><img src="https://habrastorage.org/webt/k3/wy/r4/k3wyr4imeqfncmfar65mohmcj24.png"><br><br>  Allen drei Mastern, die zusammen den vollst√§ndigen Netzkern des Clusters bilden, ist ein individuelles Replikat zugeordnet.  Da das Proxying von Protokollen auf jedem der Master durchgef√ºhrt wird, enthalten alle drei "sauberen" Slaves alle Operationen, die auf einem der Clusterknoten ausgef√ºhrt wurden. <br><br>  Diese Konfiguration kann f√ºr eine Vielzahl von Aufgaben verwendet werden.  Sie k√∂nnen keine redundanten Verbindungen zwischen allen Knoten des Clusters erstellen. Wenn Replikate in der N√§he platziert werden, verf√ºgen sie mit minimaler Verz√∂gerung √ºber eine exakte Kopie des Masters.  All dies geschieht mit dem grundlegenden Master-Slave-Replikationselement. <br><br><h2>  Beschriften von Cluster-Vorg√§ngen </h2><br>  Es stellt sich die Frage: <b>Wenn Vorg√§nge zwischen allen Clustermitgliedern √ºbertragen werden und mehrmals zu jedem Replikat gelangen, wie verstehen wir, welche Vorg√§nge ausgef√ºhrt werden m√ºssen und welche nicht?</b>  Dies erfordert einen Filtermechanismus.  Jeder aus dem Protokoll gelesenen Operation werden zwei Attribute zugewiesen: <br><br><ul><li>  Die Kennung des Servers, auf dem dieser Vorgang initiiert wurde. </li><li>  Die Sequenznummer der Operation auf dem Server, lsn, der sein Initiator ist.  Jeder Server weist bei der Ausf√ºhrung einer Operation jeder empfangenen Protokollzeile eine zunehmende Nummer zu: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ... Wenn wir also wissen, dass f√ºr einen Server mit einer bestimmten Kennung die Operation mit angewendet wurde lsn 10, dann sind Operationen mit lsn 9, 8, 7, 10, die √ºber andere Replikationskan√§le kamen, nicht erforderlich.  Stattdessen wenden wir Folgendes an: 11, 12 usw. </li></ul><br><h2>  Replikatstatus </h2><br>  <b>Und wie speichert Tarantool Informationen zu den bereits angewendeten Vorg√§ngen?</b>  Dazu gibt es eine Vclock-Uhr - dies ist der Vektor des letzten lsn, der auf jeden Knoten im Cluster angewendet wird. <br><br> <code>[lsn <sub>1</sub> , lsn <sub>2</sub> , lsn <sub>n</sub> ]</code> <br> <br>  Dabei ist <code>lsn <sub>i</sub></code> die Nummer der letzten bekannten Operation vom Server mit der Kennung i. <br><br>  Vclock kann auch als bestimmte Momentaufnahme des gesamten Clusterstatus bezeichnet werden, der diesem Replikat bekannt ist.  Wenn wir die Server-ID der Operation kennen, die angekommen ist, isolieren wir die Komponente der lokalen Vclock, die wir ben√∂tigen, vergleichen die erhaltene lsn mit der lsn-Operation und entscheiden, ob diese Operation verwendet werden soll.  Infolgedessen werden von einem bestimmten Master initiierte Vorg√§nge nacheinander gesendet und angewendet.  Gleichzeitig k√∂nnen die auf verschiedenen Mastern erstellten Workflows aufgrund der asynchronen Replikation miteinander gemischt werden. <br><br><h2>  Clustererstellung </h2><br>  Angenommen, wir haben einen Cluster, der aus zwei Elementen besteht, Master und Slave, und wir m√∂chten eine dritte Instanz damit verbinden.  Es hat eine eindeutige UUID, aber es gibt noch keine Cluster-ID.  Wenn Tarantool noch nicht initialisiert ist, m√∂chte es dem Cluster beitreten. Es muss eine JOIN-Operation an einen der Master senden, der sie ausf√ºhren kann, dh es befindet sich im Lese- / Schreibmodus.  Als Antwort auf JOIN sendet der Master seinen lokalen Snapshot an das Verbindungsreplikat.  Das Replikat rollt es zu Hause, solange es noch keine Kennung hat.  Jetzt wird das Replikat mit einer leichten Verz√∂gerung mit dem Cluster synchronisiert.  Danach weist der Master, auf dem JOIN ausgef√ºhrt wurde, diesem Replikat eine Kennung zu, die protokolliert und an das Replikat gesendet wird.  Wenn einem Replikat ein Bezeichner zugewiesen wird, wird er zu einem vollwertigen Knoten und kann danach die Protokollreplikation auf seiner Seite initiieren. <br><br>  Zeilen aus dem Journal werden ab dem Status dieses Replikats zum Zeitpunkt der Anforderung des Replikationsprotokolls vom Master gesendet, dh von der Uhr, die es w√§hrend des JOIN-Prozesses empfangen hat, oder von der Stelle, an der das Replikat zuvor gestoppt wurde.  Wenn das Replikat aus irgendeinem Grund heruntergefallen ist, wird beim n√§chsten Herstellen einer Verbindung zum Cluster kein JOIN mehr ausgef√ºhrt, da bereits ein lokaler Snapshot vorhanden ist.  Sie fragt nur nach allen Operationen, die w√§hrend ihrer Abwesenheit im Cluster stattgefunden haben. <br><br><h2>  Registrieren Sie ein Replikat in einem Cluster </h2><br>  Um den Status √ºber die Struktur des Clusters zu speichern, wird ein spezieller Bereich verwendet - Cluster.  Es enth√§lt die Server-IDs im Cluster, ihre Seriennummern und eindeutigen IDs. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/af/0f/hr/af0fhra2ln0s2xcq-qsmeim2xtc.png" width="500"></div><br><br> <code>[1, 'c35b285c-c5b1-4bbe-83b1-b825eb594aa4'] <br> [2, '37b12cb7-d324-4d75-b428-cde92c18e708'] <br> [3, 'b72b1aa6-42a0-4d73-a611-900e44cdd465']</code> <br> <br>  Bezeichner m√ºssen nicht in der richtigen Reihenfolge ausgef√ºhrt werden, da Knoten gel√∂scht und hinzugef√ºgt werden k√∂nnen. <br><br>  Hier ist die erste Falle.  In der Regel werden Cluster nicht von einem Knoten erfasst: Sie f√ºhren eine bestimmte Anwendung aus und sie stellt den gesamten Cluster auf einmal bereit.  Die Replikation in Tarantool ist jedoch asynchron.  Was ist, wenn zwei Master gleichzeitig neue Knoten verbinden und ihnen identische Kennungen zuweisen?  Es wird einen Konflikt geben. <br><br>  Hier ist ein Beispiel f√ºr einen falschen und korrekten JOIN: <br><br><img src="https://habrastorage.org/webt/o2/9_/bc/o29_bcjs3dhyllneqlgaczljxys.png"><br><br>  Wir haben zwei Master und zwei Repliken, die eine Verbindung herstellen m√∂chten.  Sie machen JOINs auf verschiedenen Meistern.  Angenommen, Replikate erhalten dieselben Bezeichner.  Dann f√§llt die Replikation zwischen den Mastern und denen, die es schaffen, ihre Protokolle zu replizieren, auseinander, der Cluster f√§llt auseinander. <br><br>  Um dies zu verhindern, m√ºssen Sie Replikate jederzeit ausschlie√ülich auf einem Master initiieren.  Zu diesem Zweck f√ºhrte Tarantool ein solches Konzept als Initialisierungsleiter ein und implementierte einen Algorithmus zur Auswahl dieses Leiters.  Ein Replikat, das eine Verbindung zum Cluster herstellen m√∂chte, stellt zun√§chst eine Verbindung zu allen Mastern her, die ihm aus der √ºbertragenen Konfiguration bekannt sind.  Anschlie√üend w√§hlt das Replikat diejenigen aus, die bereits initiiert wurden (bei der Bereitstellung des Clusters k√∂nnen nicht alle Knoten das volle Geld verdienen).  Und aus ihnen werden die Master ausgew√§hlt, die f√ºr die Aufnahme verf√ºgbar sind.  In Tarantool gibt es schreibgesch√ºtzt und schreibgesch√ºtzt. Wir k√∂nnen uns nicht auf dem schreibgesch√ºtzten Knoten registrieren.  Danach w√§hlen wir aus der Liste der gefilterten Knoten den Knoten mit der niedrigsten UUID aus. <br><br>  Wenn wir dieselbe Konfiguration und dieselbe Liste von Servern auf nicht initialisierten Instanzen verwenden, die eine Verbindung zum Cluster herstellen, w√§hlen sie denselben Master aus, was bedeutet, dass JOIN h√∂chstwahrscheinlich erfolgreich sein wird. <br><br>  Von hier leiten wir eine Regel ab: Wenn Replikate parallel mit einem Cluster verbunden werden, m√ºssen alle diese Replikate dieselbe Replikationskonfiguration haben.  Wenn wir irgendwo etwas weglassen, besteht die M√∂glichkeit, dass Instanzen mit einer anderen Konfiguration auf verschiedenen Mastern initiiert werden und der Cluster nicht zusammengesetzt werden kann. <br><br>  Angenommen, wir haben uns geirrt oder der Administrator hat vergessen, die Konfiguration zu reparieren, oder Ansible ist kaputt gegangen, und der Cluster ist immer noch auseinandergefallen.  Was kann das bezeugen?  Erstens k√∂nnen steckbare Replikate ihre lokalen Snapshots nicht erstellen: Replikate werden nicht gestartet und melden Fehler.  Zweitens werden auf den Mastern in den Protokollen Fehler im Zusammenhang mit Konflikten im Space-Cluster angezeigt. <br><br>  Wie l√∂sen wir diese Situation?  Es ist einfach: <br><br><ul><li>  Zun√§chst m√ºssen wir die Konfiguration √ºberpr√ºfen, die wir f√ºr die Verbindungsreplikate festgelegt haben. Wenn wir sie nicht reparieren, ist alles andere nutzlos. </li><li>  Danach beseitigen wir die Konflikte im Cluster und machen ein Bild. </li></ul><br>  Jetzt k√∂nnen Sie versuchen, die Replikate erneut zu initialisieren. <br><br><h2>  Konfliktl√∂sung </h2><br>  Also haben wir einen Cluster erstellt und eine Verbindung hergestellt.  Alle Knoten arbeiten im Abonnementmodus, dh sie erhalten die von verschiedenen Mastern generierten √Ñnderungen.  Da die Replikation asynchron ist, sind Konflikte m√∂glich.  Wenn Sie gleichzeitig Daten auf verschiedenen Mastern √§ndern, erhalten verschiedene Replikate unterschiedliche Kopien der Daten, da die Vorg√§nge in einer anderen Reihenfolge angewendet werden k√∂nnen. <br><br>  Hier ist ein Beispielcluster nach der Ausf√ºhrung von JOIN: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-o/2j/k2/-o2jk2hjv2dqndshyqta_blcmo8.png" width="500"></div><br>  Wir haben drei Master-Slaves, zwischen denen Protokolle √ºbertragen werden, die in verschiedene Richtungen √ºbertragen werden und auf Slaves angewendet werden.  Nicht synchronisierte Daten bedeuten, dass jedes Replikat seinen eigenen Vclock-√Ñnderungsverlauf hat, da Streams von verschiedenen Mastern miteinander gemischt werden k√∂nnen.  Dann kann die Reihenfolge der Operationen f√ºr Instanzen variieren.  Wenn unsere Operationen nicht kommutativ sind, wie z. B. die REPLACE-Operation, sind die Daten, die wir auf diesen Replikaten erhalten, unterschiedlich. <br><br>  Ein kleines Beispiel.  Angenommen, wir haben zwei Master mit vclock = {0,0}.  Und beide f√ºhren zwei Operationen aus, die als op1,1, op1,2, op2,1, op2,2 bezeichnet werden.  Dies ist die zweite Zeitscheibe, in der jeder der Master eine lokale Operation ausf√ºhrte: <br><br><img src="https://habrastorage.org/webt/-y/z7/cy/-yz7cyhaozyxkdltf7pptl37oqa.png"><br><br>  Gr√ºn zeigt eine √Ñnderung der entsprechenden vclock-Komponente an.  Zuerst √§ndern beide Master ihre Uhr, und dann f√ºhrt der zweite Master eine weitere lokale Operation aus und erh√∂ht die Uhr erneut.  Der erste Master empf√§ngt die Replikationsoperation vom zweiten Master. Dies wird durch die rote Nummer 1 in vclock des ersten Clusterknotens angezeigt. <br><br><img src="https://habrastorage.org/webt/if/j8/8f/ifj88f4rat3litvsyedit09shw0.png"><br><br>  Dann empf√§ngt der zweite Master die Operation von der ersten und die erste - die zweite Operation von der zweiten.  Und am Ende f√ºhrt der erste Master seine letzte Operation aus und der zweite Master empf√§ngt sie. <br><br><img src="https://habrastorage.org/webt/gh/3z/jo/gh3zjoicvoxqd772_pt1m92wfem.png"><br><br>  Vclock im Nullzeitquantum haben wir das gleiche - {0,0}.  In der letzten Zeit haben wir auch die gleiche Uhr {2,2}, es scheint, dass die Daten gleich sein sollten.  Die Reihenfolge der Operationen, die an jedem Master ausgef√ºhrt werden, ist jedoch unterschiedlich.  Und wenn dies eine REPLACE-Operation mit unterschiedlichen Werten f√ºr dieselben Schl√ºssel ist?  Dann erhalten wir trotz der gleichen Uhr am Ende unterschiedliche Versionen der Daten auf beiden Replikaten. <br><br>  Wir sind auch in der Lage, diese Situation zu l√∂sen. <br><br><ul><li>  <b>Sharding-Datens√§tze</b> .  Erstens k√∂nnen wir Schreibvorg√§nge nicht f√ºr zuf√§llig ausgew√§hlte Replikate ausf√ºhren, sondern sie irgendwie zerlegen.  Sie haben nur die Schreiboperationen zwischen verschiedenen Mastern unterbrochen und schlie√ülich ein Konsistenzsystem erhalten.  Beispielsweise haben sich die Schl√ºssel auf einem Master von 1 auf 10 und auf einem anderen von 11 auf 20 ge√§ndert. Die Knoten tauschen ihre Protokolle aus und erhalten genau dieselben Daten. <br><br>  Sharding impliziert, dass wir einen bestimmten Router haben.  Es muss √ºberhaupt keine separate Entit√§t sein, der Router kann Teil der Anwendung sein.  Es kann ein Shard sein, der Schreiboperationen auf sich selbst anwendet oder sie auf die eine oder andere Weise an einen anderen Master √ºbertr√§gt.  Es wird jedoch so √ºbergeben, dass die √Ñnderungen der zugeh√∂rigen Werte an einen bestimmten Master gehen: Ein Werteblock ging an einen Master, ein anderer Block an einen anderen Master.  In diesem Fall k√∂nnen Lesevorg√§nge an jeden Knoten im Cluster gesendet werden.  Und vergessen Sie nicht die asynchrone Replikation: Wenn Sie auf demselben Master aufgezeichnet haben, m√ºssen Sie m√∂glicherweise auch daraus lesen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/de/cq/wv/decqwvuzuaz-yn6t7fbyq2o2sv4.png" width="500"></div></li><li>  <b>Logische Reihenfolge der Operationen</b> .  Angenommen, Sie k√∂nnen gem√§√ü den Bedingungen des Problems die Priorit√§t der Operation irgendwie bestimmen.  Geben Sie beispielsweise einen Zeitstempel, eine Version oder ein anderes Etikett ein, mit dem wir verstehen k√∂nnen, welche Operation fr√ºher physisch stattgefunden hat.  Das hei√üt, wir sprechen von einer externen Bestellquelle. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/h8/pt/zl/h8ptzlm1ieiugdnjr66ubi9pxwq.png" width="500"></div><br>  Tarantool verf√ºgt √ºber einen <code>before_replace</code> Trigger, der w√§hrend der Replikation ausgef√ºhrt werden kann.  In diesem Fall sind wir nicht darauf beschr√§nkt, Anfragen weiterzuleiten, sondern k√∂nnen sie senden, wohin wir wollen.  Bei der Replikation am Eingang des Datenstroms haben wir jedoch einen Ausl√∂ser.  Er liest die gesendete Leitung, vergleicht sie mit der bereits gespeicherten Leitung und entscheidet, welche der Leitungen eine h√∂here Priorit√§t hat.  Das hei√üt, der Trigger ignoriert entweder die Replikationsanforderung oder wendet sie m√∂glicherweise mit den erforderlichen √Ñnderungen an.  Wir wenden diesen Ansatz bereits an, obwohl er auch seine Nachteile hat.  Zun√§chst ben√∂tigen Sie eine externe Taktquelle.  Angenommen, ein Betreiber in einem Mobiltelefonsalon nimmt √Ñnderungen an einem Teilnehmer vor.  F√ºr solche Vorg√§nge k√∂nnen Sie die Zeit auf dem Computer des Betreibers verwenden, da es unwahrscheinlich ist, dass mehrere Bediener gleichzeitig √Ñnderungen an einem Teilnehmer vornehmen.  Operationen k√∂nnen auf unterschiedliche Weise erfolgen. Wenn jedoch jeder von ihnen eine bestimmte Version zugewiesen werden kann, bleiben beim Durchlaufen von Triggern nur die relevanten √ºbrig. <br><br>  Der zweite Nachteil der Methode: Da der Trigger auf jedes Delta angewendet wird, das durch Replikation f√ºr jede Anforderung kam, entsteht eine zus√§tzliche Rechenlast.  Aber dann haben wir eine konsistente Kopie der Daten auf einer Cluster-Skala. </li></ul><br><h2>  Synchronisieren </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jr/1n/db/jr1ndb23coit6rz1qeblip_tpy0.png" width="500"></div><br>  Unsere Replikation ist asynchron, dh durch Festschreibungsausf√ºhrung wissen Sie nicht, ob sich diese Daten bereits auf einem anderen Clusterknoten befinden.  Wenn Sie ein Commit f√ºr den Master vorgenommen haben, wurde es Ihnen best√§tigt, und der Master hat aus irgendeinem Grund sofort aufgeh√∂rt zu arbeiten. Dann k√∂nnen Sie nicht sicher sein, dass die Daten an einem anderen Ort gespeichert wurden.  Um dieses Problem zu l√∂sen, verf√ºgt das Tarantool-Replikationsprotokoll √ºber eine ACK.  Jeder Master wei√ü, welche letzte ACK von jedem Slave kam. <br><br>  Was ist ein ACK?  Wenn der Slave das Delta empf√§ngt, das mit dem Master lsn und seiner Kennung markiert ist, sendet er als Antwort ein spezielles ACK-Paket, in das er nach Anwendung dieser Operation seine lokale Uhr packt.  Mal sehen, wie das funktionieren kann. <br><br>  Wir haben einen Meister, der 4 Operationen in sich selbst durchgef√ºhrt hat.  Angenommen, der Slave-Slave hat irgendwann die ersten drei Zeilen empfangen und seine Uhr auf {3.0} erh√∂ht. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oy/iw/y1/oyiwy1eifo7_jfsb9ylvi1wkija.png" width="500"></div><br>  ACK ist noch nicht angekommen.  Nachdem der Slave diese drei Leitungen empfangen hat, sendet er das ACK-Paket, an das er zum Zeitpunkt des Sendens des Pakets seine Uhr angeschlossen hat.  Lassen Sie den Slave-Master eine weitere Leitung im selben Zeitfenster senden, dh die vclock des Slaves hat sich erh√∂ht.  Auf dieser Grundlage wei√ü Master Nr. 1 mit Sicherheit, dass die ersten drei Operationen, die er ausgef√ºhrt hat, bereits auf diesen Slave angewendet wurden.  Diese Zust√§nde werden f√ºr alle Slaves gespeichert, mit denen der Master arbeitet, sie sind v√∂llig unabh√§ngig. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/u1/rx/va/u1rxvazmmssfoizpfecbwf3ceas.png" width="500"></div><br>  Und am Ende antwortet der Slave mit einem vierten ACK-Paket.  Danach wei√ü der Master, dass der Slave mit ihm synchronisiert ist. <br><br>  Dieser Mechanismus kann im Anwendungscode verwendet werden.  Wenn Sie eine Operation festschreiben, best√§tigen Sie den Benutzer nicht sofort, sondern rufen zuerst eine spezielle Funktion auf.  Es wartet darauf, dass der dem Master bekannte lsn-Slave zum Zeitpunkt des Abschlusses des Commits gleich dem lsn Ihres Masters ist.  Sie m√ºssen also nicht auf die vollst√§ndige Synchronisierung warten, sondern nur auf den genannten Moment warten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1-/oe/93/1-oe930isjznmsurqj314c2-gue.png" width="500"></div><br>  Angenommen, unser erster Anruf hat drei Leitungen ge√§ndert, und der zweite Anruf hat eine ge√§ndert.  Nach dem ersten Aufruf m√∂chten Sie sicherstellen, dass die Daten synchronisiert sind.  Der oben gezeigte Zustand bedeutet bereits, dass der erste Anruf auf mindestens einem Slave synchronisiert wurde. <br><br>  Wo genau Sie nach Informationen dazu suchen, werden wir im n√§chsten Abschnitt betrachten. <br><br><h2>  √úberwachung </h2><br>  Wenn die Replikation synchron ist, ist die √úberwachung sehr einfach: Wenn sie auseinanderf√§llt, werden Fehler an Ihre Vorg√§nge ausgegeben.  Und wenn die Replikation asynchron ist, wird die Situation verwirrend.  Der Meister antwortet Ihnen, dass alles in Ordnung ist, es funktioniert, akzeptiert, aufgeschrieben.  Gleichzeitig sind jedoch alle Replikate tot, die Daten sind nicht redundant, und wenn Sie den Master verlieren, verlieren Sie die Daten.  Daher m√∂chte ich den Cluster wirklich √ºberwachen und verstehen, was mit der asynchronen Replikation geschieht, wo sich die Replikate befinden und in welchem ‚Äã‚ÄãZustand sie sich befinden. <br><br>  F√ºr die grundlegende √úberwachung verf√ºgt Tarantool √ºber eine box.info-Entit√§t.  Es lohnt sich, es in der Konsole aufzurufen, da Sie interessante Daten sehen werden. <br><br><pre> <code class="plaintext hljs">id: 1 uuid: c35b285c-c5b1-4bbe-83b1-b825eb594aa4 lsn : 5 vclock : {2: 1, 1: 5} replication : 1: id: 1 uuid : c35b285c -c5b1 -4 bbe -83b1 - b825eb594aa4 lsn : 5 2: id: 2 uuid : 37 b12cb7 -d324 -4 d75 -b428 - cde92c18e708 lsn : 1 upstream : status : follow idle : 0.30358312401222 peer : lag: 3.6001205444336 e -05 downstream : vclock : {2: 1, 1: 5}</code> </pre> <br>  Die wichtigste Metrik ist die ID- <code>id</code> .  In diesem Fall bedeutet 1, dass die lsn dieses Masters an der ersten Position in allen vclock gespeichert wird.  Eine sehr n√ºtzliche Sache.  Wenn Sie einen Konflikt mit JOIN haben, k√∂nnen Sie einen Master nur durch eindeutige Bezeichner von einem anderen unterscheiden.  Lokale Mengen umfassen auch solche Mengen wie lsn.  Dies ist die Nummer der letzten Zeile, die dieser Master ausgef√ºhrt und in sein Protokoll geschrieben hat.  In unserem Beispiel hat der erste Master f√ºnf Operationen ausgef√ºhrt.  Vclock ist der Betriebszustand, von dem er wei√ü, dass er ihn auf sich selbst angewendet hat.  Und schlie√ülich f√ºhrte er f√ºr Master Nummer 2 eine seiner Replikationsoperationen durch. <br><br>  Nach den Anzeigen des lokalen Status k√∂nnen Sie sehen, was diese Instanz √ºber den Status der Clusterreplikation wei√ü. Dazu gibt es einen <code>replication</code> .  Es listet alle der Instanz bekannten Clusterknoten auf, einschlie√ülich sich selbst.  Der erste Knoten hat die Kennung 1, id entspricht der aktuellen Instanz.  Der zweite Knoten hat die Kennung 2, sein lsn 1 entspricht dem lsn, der in vclock geschrieben wird.  In diesem Fall betrachten wir die Master-Master-Replikation, wenn Master Nr. 1 sowohl der Master f√ºr den zweiten Knoten des Clusters als auch dessen Slave ist, dh ihm folgt. <br><br><ul><li>  Die Essenz von <code>upstream</code> .  Das <code>status follow</code> Attribut bedeutet, dass Master 1 auf Master 2 folgt. Leerlauf ist die Zeit, die seit der letzten Interaktion mit diesem Master lokal vergangen ist.  Wir senden keinen Stream kontinuierlich, der Master sendet nur dann ein Delta, wenn √Ñnderungen daran auftreten.  Wenn wir eine Art ACK senden, kommunizieren wir auch.  Wenn der Leerlauf gro√ü wird (Sekunden, Minuten, Stunden), stimmt offensichtlich etwas nicht. </li><li>  <code>lag</code> Attribut.  Wir haben √ºber Lag gesprochen.  Zus√§tzlich zu lsn und der <code>server id</code> jede Operation im Protokoll mit einem Zeitstempel gekennzeichnet - der Ortszeit, w√§hrend der diese Operation in vclock auf dem Master aufgezeichnet wurde, der sie ausgef√ºhrt hat.  Gleichzeitig vergleicht Slave seinen lokalen Zeitstempel mit dem Zeitstempel des Deltas, das er erhalten hat.  Der letzte aktuelle Zeitstempel, der f√ºr die letzte Zeile empfangen wurde, wird vom Slave bei der √úberwachung angezeigt. </li><li>  <code>downstream</code> Attribut.  Es zeigt, was der Meister √ºber seinen bestimmten Sklaven wei√ü.  Dies ist die Best√§tigung, die der Sklave an ihn sendet.  Der oben dargestellte <code>downstream</code> bedeutet, dass sein Sklave, auch bekannt als Master auf Nummer 2, ihm das letzte Mal seine Uhr schickte, die 5.1 war.  Dieser Meister wei√ü, dass alle f√ºnf seiner Linien, die er an seinem Platz vervollst√§ndigte, zu einem anderen Knoten gingen. </li></ul><br><h2>  XLOG-Verlust </h2><br>  Betrachten Sie die Situation mit dem Fall des Meisters. <br><br><pre> <code class="plaintext hljs">lsn : 0 id: 3 replication : 1: &lt;...&gt; upstream : status: disconnected peer : lag: 3.9100646972656 e -05 idle: 1602.836148153 message: connect, called on fd 13, aka [::1]:37960 2: &lt;...&gt; upstream : status : follow idle : 0.65611373598222 peer : lag: 1.9550323486328 e -05 3: &lt;...&gt; vclock : {2: 2, 1: 5}</code> </pre> <br>  Zun√§chst √§ndert sich der Status.  <code>Lag</code> √§ndert sich nicht, da die von uns angewendete Linie dieselbe bleibt und wir keine neuen erhalten haben.  Gleichzeitig w√§chst der <code>idle</code> , in diesem Fall sind es bereits 1602 Sekunden, so viel Zeit war der Meister tot.  Und wir sehen eine Fehlermeldung: Es besteht keine Netzwerkverbindung. <br><br>  Was tun in einer √§hnlichen Situation?  Wir finden heraus, was mit unserem Master passiert ist, ziehen den Administrator an, starten den Server neu und heben den Knoten an.  Die wiederholte Replikation wird durchgef√ºhrt, und wenn der Master das System betritt, stellen wir eine Verbindung her, abonnieren dessen XLOG, holen sie f√ºr uns selbst und der Cluster stabilisiert sich. <br><br>  Aber es gibt ein kleines Problem.  Stellen Sie sich vor, wir h√§tten einen Sklaven, der aus irgendeinem Grund ausgeschaltet war und lange Zeit abwesend war.  W√§hrend dieser Zeit l√∂schte der Meister, der es bediente, das XLOG.  Beispielsweise ist die Festplatte voll, der Garbage Collector hat Protokolle gesammelt.  Wie kann ein zur√ºckkehrender Sklave weitermachen?  Auf keinen Fall.  Weil die Protokolle, die er anwenden muss, um mit dem Cluster synchronisiert zu werden, weg sind und es keinen Ort gibt, an dem sie abgerufen werden k√∂nnen.  In diesem Fall wird ein interessanter Fehler angezeigt: Der Status wird nicht mehr <code>disconnected</code> , sondern <code>stopped</code> .  Und eine bestimmte Nachricht: Es gibt keine Protokolldatei, die mit einer solchen lsn √ºbereinstimmt. <br><br><pre> <code class="plaintext hljs">id: 3 replication : 1: &lt;...&gt; upstream : peer : status: stopped lag : 0.0001683235168457 idle : 9.4331328970147 message: 'Missing .xlog file between LSN 7 1: 5, 2: 2 and 8 1: 6, 2: 2' 2: &lt;...&gt; 3: &lt;...&gt; vclock : {2: 2, 1: 5}</code> </pre> <br>  In der Tat ist die Situation nicht immer t√∂dlich.  Angenommen, wir haben mehr als zwei Master, und auf einigen von ihnen bleiben diese Protokolle erhalten.  Wir sch√ºtten sie allen Meistern gleichzeitig ein und lagern sie nicht nur auf einem.  Dann stellt sich heraus, dass diese Replik, die sich mit allen Mastern verbindet, die sie kennt, auf einigen von ihnen die Protokolle findet, die sie ben√∂tigt.  Sie wird alle diese Operationen zu Hause ausf√ºhren, ihre Uhr wird sich erh√∂hen und sie wird den aktuellen Status des Clusters erreichen.  Danach k√∂nnen Sie versuchen, die Verbindung wiederherzustellen. <br><br>  Wenn √ºberhaupt keine Protokolle vorhanden sind, k√∂nnen wir das Replikat nicht fortsetzen.  Es bleibt nur eine Neuinitialisierung.  Denken Sie an die eindeutige Kennung. Sie k√∂nnen sie auf ein Blatt Papier oder in eine Datei schreiben.  Dann bereinigen wir das Replikat lokal: L√∂schen Sie seine Bilder, Protokolle und so weiter.  Verbinden Sie danach das Replikat erneut mit derselben UUID wie es. <br><br>     UUID   : <code>box.cfg{instance_uuid =  uuid}</code> . <br><br>   ,   .   UUID    space cluster,    .       ,    .    UUID,  master,     JOIN,     ,       UUID,   ,    . <br><br>   ,   UUID ,     space cluster      ,    .       .  ,  ,          . <br><br><h2>  </h2><br> ,  -           .   ,        .    ,   ,      . <br><br>  Tarantool   . <br><br> <code>replication_connect_quorum: 2 <br> replication_connect_timeout: 30 <br> replication_sync_lag: 0.1</code> <br> <br> ,   , ,            ,   ,  ,  master'     0,1 .    30 .     ,   .   0,1 .  ,      . <br><br><h2> Keep alive </h2><br>  ,      ip tables drop.  ,    -  30   30 ,    ,      .     ,   keep alive-. <br><br>  keep alive-  : <code>box.cfg.replication_timeout</code> . <br><br>      master'      ,    keep alive-, ,   .    4  master  slave   keep alive-   ,         .             master'. <br><br><h2>    </h2><br>  ,      .    6 ,      5 .     10 ,    9 .     . <br><br>   ,    ,     .       ,         master',   .  -          .   . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pp/wv/qo/ppwvqoys4enyzstnxbfp0mtkug4.png" width="500"></div><br>     6 ,       3.     ,    .  ,     5 ,      3 . <br><br><h2>     </h2><br>   ,       : <br><br><ul><li>  . </li><li>  ,       space cluster,        .          . </li></ul><br>   ,    Telegram-,  .          ,     GitHub,   . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439514/">https://habr.com/ru/post/de439514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439504/index.html">Ben√∂tigt Ihr Team einen Dateningenieur?</a></li>
<li><a href="../de439506/index.html">9 Alternativen zu einem schlechten Team (Designmuster)</a></li>
<li><a href="../de439508/index.html">Mitap √ºber Open Source-Entwicklung in Moskau</a></li>
<li><a href="../de439510/index.html">Hoch belastetes verteiltes Steuerungssystem eines modernen Kernkraftwerks</a></li>
<li><a href="../de439512/index.html">Das Alter der Dinosaurier oder die gesetzlich gepr√ºfte R√ºckversicherung?</a></li>
<li><a href="../de439516/index.html">00110001 00110100 00101110 00110000 00110010</a></li>
<li><a href="../de439518/index.html">GeekUniversity Aktualisiertes Webentwicklungs-Schulungsprogramm: Weitere Praktiken und F√§lle f√ºr Delivery Clubs</a></li>
<li><a href="../de439520/index.html">Proof-of-Stake: Neues Gesch√§ftsmodell im Jahr 2019?</a></li>
<li><a href="../de439522/index.html">DNS-Rebinding in 2k19 oder wie man wirklich schwitzt, indem man eine Pornoseite besucht</a></li>
<li><a href="../de439524/index.html">Fortnite ist die Zukunft, aber aus eher unerwarteten Gr√ºnden</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
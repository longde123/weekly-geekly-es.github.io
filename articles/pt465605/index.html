<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙅🏻 👩🏻‍🔬 ♣️ O livro “Aprendizado por reforço profundo em Python. Ginásio OpenAI e TensorFlow para profissionais » 👩🏿‍💻 🛑 🚃</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Oi, habrozhiteli! O aprendizado por reforço é a área mais popular e promissora da inteligência artificial. O aprendizado prático de RL em Python ajuda...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O livro “Aprendizado por reforço profundo em Python. Ginásio OpenAI e TensorFlow para profissionais »</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/465605/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/hf/sc/yz/hfscyzhjnopaerkvbdvf89gflfc.jpeg" align="left" alt="imagem"></a>  Oi, habrozhiteli!  O aprendizado por reforço é a área mais popular e promissora da inteligência artificial.  O aprendizado prático de RL em Python ajudará você a dominar não apenas o básico, mas também os algoritmos avançados de aprendizado profundo com reforço.  Este livro é destinado a desenvolvedores de MO e entusiastas de aprendizado profundo que estão interessados ​​em inteligência artificial e desejam aprender o método de aprendizado por reforço.  Leia este livro e torne-se um especialista em aprendizado reforçado, implementando exemplos práticos no trabalho ou fora dele.  O conhecimento de álgebra linear, análise matemática e a linguagem de programação Python ajudará você a entender a lógica da apresentação. <br><a name="habracut"></a><br><h3>  Trecho.  Gerando letras usando o LSTM RNN </h3><br>  Agora vamos ver como usar o LSTM para gerar letras de Zayn Malik.  O conjunto de dados das letras de músicas de Zane pode ser baixado em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/sudharsan13296/Hands-On-Reinforcement-Learning-With-Python/blob/master/07.%20Deep%20Learning%20Fundamentals/data/ZaynLyrics.txt</a> . <br><br>  O trabalho começa importando as bibliotecas necessárias: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br>  Em seguida, o arquivo com a letra é lido: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">"Zayn_Lyrics.txt"</span></span>,<span class="hljs-string"><span class="hljs-string">"r"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data=f.read() data=data.replace(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) data = data.lower()</code> </pre> <br>  Verifique se os dados foram enviados com sucesso: <br><br><pre> <code class="python hljs">data[:<span class="hljs-number"><span class="hljs-number">50</span></span>] <span class="hljs-string"><span class="hljs-string">"now i'm on the edge can't find my way it's inside "</span></span></code> </pre> <br>  Agora todos os caracteres são armazenados na variável all_chars: <br><br><pre> <code class="plaintext hljs">all_chars=list(set(data))</code> </pre> <br>  O número de caracteres exclusivos é armazenado em unique_chars: <br><br><pre> <code class="python hljs">unique_chars = len(all_chars)</code> </pre> <br>  E o número total de caracteres é armazenado na variável total_chars: <br><br><pre> <code class="python hljs">total_chars =len(data)</code> </pre> <br>  Primeiro, atribuímos a cada caractere um índice.  char_to_ix conterá o mapeamento do caractere para o índice e ix_to_char conterá o mapeamento do caractere para o índice: <br><br><pre> <code class="python hljs">char_to_ix = { ch:i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i,ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(all_chars) } ix_to_char = { i:ch <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i,ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(all_chars) }</code> </pre> <br>  Um exemplo: <br><br><pre> <code class="python hljs">char_to_ix[<span class="hljs-string"><span class="hljs-string">'e'</span></span>] <span class="hljs-number"><span class="hljs-number">9</span></span> ix_to_char[<span class="hljs-number"><span class="hljs-number">9</span></span>] e</code> </pre> <br>  Em seguida, é definida a função generate_batch, que gera os valores de entrada e de destino.  Os valores teóricos são iguais ao deslocamento do valor de entrada vezes i. <br><br>  Por exemplo, se input = [12,13,24] com um valor de deslocamento de 1, os valores alvo serão [13,24]: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generate_batch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(seq_length,i)</span></span></span><span class="hljs-function">:</span></span> inputs = [char_to_ix[ch] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[i:i+seq_length]] targets = [char_to_ix[ch] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[i+<span class="hljs-number"><span class="hljs-number">1</span></span>:i+seq_length+<span class="hljs-number"><span class="hljs-number">1</span></span>]] inputs=np.array(inputs).reshape(seq_length,<span class="hljs-number"><span class="hljs-number">1</span></span>) targets=np.array(targets).reshape(seq_length,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> inputs,targets</code> </pre> <br>  Determinaremos a duração da sequência, a velocidade da aprendizagem e o número de nós, que é igual ao número de neurônios: <br><br><pre> <code class="python hljs">seq_length = <span class="hljs-number"><span class="hljs-number">25</span></span> learning_rate = <span class="hljs-number"><span class="hljs-number">0.1</span></span> num_nodes = <span class="hljs-number"><span class="hljs-number">300</span></span></code> </pre> <br>  Crie o LSTM RNN.  O TensorFlow fornece a função BasicLSTMCell () para a construção de células LSTM;  você deve especificar o número de unidades na célula LSTM e o tipo de função de ativação usada. <br><br>  Portanto, criamos a célula LSTM e construímos a rede RNN com essa célula usando a função tf.nn.dynamic_rnn (), que retorna a saída e o valor do estado: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_rnn</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> cell= tf.contrib.rnn.BasicLSTMCell(num_units=num_nodes, activation=tf.nn.relu) outputs, states = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> outputs,states</code> </pre> <br>  Agora crie um substituto para a entrada X e o destino Y: <br><br><pre> <code class="python hljs">X=tf.placeholder(tf.float32,[<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>]) Y=tf.placeholder(tf.float32,[<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Converta X e Y em int: <br><br><pre> <code class="python hljs">X=tf.cast(X,tf.int32) Y=tf.cast(Y,tf.int32)</code> </pre> <br>  Crie também visualizações onehot para X e Y: <br><br><pre> <code class="python hljs">X_onehot=tf.one_hot(X,unique_chars) Y_onehot=tf.one_hot(Y,unique_chars)</code> </pre> <br>  Obtenha as saídas e estados da RNN chamando a função build_rnn: <br><br><pre> <code class="python hljs">outputs,states=build_rnn(X_onehot)</code> </pre> <br>  Transponha a saída: <br><br><pre> <code class="python hljs">outputs=tf.transpose(outputs,perm=[<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>])</code> </pre> <br>  Inicializamos os pesos e compensações: <br><br><pre> <code class="python hljs">W=tf.Variable(tf.random_normal((num_nodes,unique_chars),stddev=<span class="hljs-number"><span class="hljs-number">0.001</span></span>)) B=tf.Variable(tf.zeros((<span class="hljs-number"><span class="hljs-number">1</span></span>,unique_chars)))</code> </pre> <br>  Calculamos a saída multiplicando a saída pelo peso e adicionando o deslocamento: <br><br><pre> <code class="python hljs">Ys=tf.matmul(outputs[<span class="hljs-number"><span class="hljs-number">0</span></span>],W)+B</code> </pre> <br>  Agora vamos executar a ativação do softmax e obter as probabilidades: <br><br><pre> <code class="python hljs">prediction = tf.nn.softmax(Ys)</code> </pre> <br>  A perda de cross_entropy será calculada da seguinte maneira: <br><br><pre> <code class="python hljs">cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels =Y_onehot,logits=Ys))</code> </pre> <br>  Nosso objetivo é minimizar as perdas, para que possamos realizar a propagação de volta para a rede e realizar a descida gradiente: <br><br><pre> <code class="python hljs">optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cro ss_entropy)</code> </pre> <br>  Em seguida, será definida a previsão da função auxiliar, que fornecerá os índices do próximo símbolo previsto, de acordo com o modelo RNN: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(seed,i)</span></span></span><span class="hljs-function">:</span></span> x=np.zeros((<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>)) x[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]= seed indices=[] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(i): p=sess.run(prediction,{X:x}) index = np.random.choice(range(unique_chars), p=p.ravel()) x[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]=index indices.append(index) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> indices</code> </pre> <br>  Em seguida, serão definidos o tamanho do pacote batch_size, o número de pacotes e o número de eras, bem como o valor do turno para gerar o pacote: <br><br><pre> <code class="python hljs">batch_size=<span class="hljs-number"><span class="hljs-number">100</span></span> total_batch=int(total_chars//batch_size) epochs=<span class="hljs-number"><span class="hljs-number">1000</span></span> shift=<span class="hljs-number"><span class="hljs-number">0</span></span></code> </pre> <br>  Por fim, criamos uma sessão TensorFlow e construímos um modelo: <br><br><pre> <code class="python hljs">init=tf.global_variables_initializer() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: sess.run(init) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(epoch): print(<span class="hljs-string"><span class="hljs-string">"Epoch {}:"</span></span>.format(epoch)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> shift + batch_size+<span class="hljs-number"><span class="hljs-number">1</span></span> &gt;= len(data): shift =<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#         # generate_batch,      shift, #    for i in range(total_batch): inputs,targets=generate_batch(batch_size,shift) shift += batch_size # calculate loss if(i%100==0): loss=sess.run(cross_entropy,feed_dict={X:inputs, Y:targets}) #      #    predict index =predict(inputs[0],200) #     ix_to_char #    txt = ''.join(ix_to_char[ix] for ix in index) print('Iteration %i: '%(i)) print ('\n %s \n' % (txt, )) sess.run(optimiser,feed_dict={X:inputs,Y:targets})</span></span></code> </pre> <br>  Como você pode ver nos resultados, na era inicial, a saída consiste em caracteres aleatórios, mas conforme você aprende, os resultados melhoram: <br><br><pre> <code class="python hljs">Epoch <span class="hljs-number"><span class="hljs-number">0</span></span>: Iteration <span class="hljs-number"><span class="hljs-number">0</span></span>: wsadrpud,kpswkypeqawnlfyweudkgt,khdi nmgo<span class="hljs-string"><span class="hljs-string">f' u vnvlmbis . snsblp,podwjqehb,e;g- '</span></span>fyqjsyeg,byjgyotsrdf;;u,ha;ik<span class="hljs-string"><span class="hljs-string">'sfc;dvtauofd.,q.;npsw'</span></span>wjy-quw<span class="hljs-string"><span class="hljs-string">'quspfqw- . . . Epoch 113: Iteration 0: i wanna see you, yes, and she said yes!</span></span></code> </pre> <br><h3>  Sobre o autor </h3><br>  <i>Sudharsan Ravichandiran</i> é especialista em processamento e análise de dados, um fervoroso fã de inteligência artificial e um blogueiro em vídeo.  Ele se formou em ciência da computação pela Universidade de Anne e está envolvido em pesquisas sobre a implementação prática de aprendizado profundo e aprendizado reforçado, incluindo processamento de linguagem natural e visão computacional.  Anteriormente trabalhou como web designer e desenvolvedor freelancer, participou da criação de vários sites premiados.  Atualmente, ele participa de projetos de código aberto e frequentemente responde a perguntas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Stack Overflow</a> . <br><br><h3>  Sobre editores de ciências </h3><br>  <i>Sujit Pal</i> é diretor de pesquisa técnica da Elsevier Labs, a mais recente equipe de desenvolvimento de tecnologia do Reed-Elsevier Group.  Ele está envolvido em pesquisas no campo da pesquisa semântica, processamento de linguagem natural, máquina e aprendizado profundo.  Na Elsevier, ele trabalhou em vários projetos de iniciativa, incluindo avaliar e melhorar a qualidade da pesquisa, classificação de imagens e identificação duplicada, anotando e desenvolvendo antologias de textos médicos e científicos.  Ele escreveu um livro de aprendizado profundo com Antonio Gulli e escreve sobre tecnologia em seu blog <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Salmon Run</a> . <br><br>  <i>Suriyadeepan Ramamoorthy</i> é pesquisador e engenheiro de inteligência artificial do pesquisador e engenheiro de IA em Pondicherry (Índia).  O assunto principal de seu trabalho é entender as línguas naturais e formar o raciocínio.  Ele escreve extensivamente em um blog de aprendizado profundo.  Na SAAMA Technologies, ele usa métodos avançados de aprendizado profundo para analisar textos biomédicos.  Sendo um fervoroso defensor do software livre, ele participa ativamente de projetos para seu desenvolvimento na comunidade da FSFTN.  Ele também está interessado em redes colaborativas, visualização de dados e programação criativa. <br><br>  »Mais informações sobre o livro podem ser encontradas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site do editor</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Conteúdo</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Trecho</a> <br><br>  Cupom de 25% de desconto para vendedores ambulantes - <b>Python</b> <br><br>  Após o pagamento da versão impressa do livro, um livro eletrônico é enviado por e-mail. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt465605/">https://habr.com/ru/post/pt465605/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt465595/index.html">5G chega até nós?</a></li>
<li><a href="../pt465597/index.html">Aprendendo STM8S Slow Start. Parte 0</a></li>
<li><a href="../pt465599/index.html">IPFS sem dor (mas isso não é preciso)</a></li>
<li><a href="../pt465601/index.html">Por que você precisa do DevOps e que são especialistas em DevOps</a></li>
<li><a href="../pt465603/index.html">Cursos vs estágio. Como ensinamos midbells na SimbirSoft</a></li>
<li><a href="../pt465607/index.html">Entendendo Lean e Agile no desenvolvimento de software</a></li>
<li><a href="../pt465609/index.html">Por que o 1C-Bitrix de 1 de dezembro de 2019 pode se transformar em uma abóbora</a></li>
<li><a href="../pt465611/index.html">Música para o programador</a></li>
<li><a href="../pt465613/index.html">Um guia completo para matrizes e fatias de Golang</a></li>
<li><a href="../pt465615/index.html">Bloqueios inteligentes: o que são, como funcionam (e quem instala)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
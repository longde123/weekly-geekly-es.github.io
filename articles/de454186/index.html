<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∑üèΩ üöë ü§∏üèº Erstellen Sie eine Pipeline f√ºr die Streaming-Datenverarbeitung. Teil 1 üß¶ üë®‚Äçüë¶ ü§∂üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo an alle. Freunde, wir teilen Ihnen eine √úbersetzung eines Artikels mit, der speziell f√ºr Studenten des Data Engineer- Kurses erstellt wurde. Las...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstellen Sie eine Pipeline f√ºr die Streaming-Datenverarbeitung. Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/454186/">  Hallo an alle.  Freunde, wir teilen Ihnen eine √úbersetzung eines Artikels mit, der speziell f√ºr Studenten des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Data Engineer-</a> Kurses erstellt wurde.  Lass uns gehen! <br><br><img src="https://habrastorage.org/webt/fv/mo/wz/fvmowz46naiimojhlq03dhxm38w.png"><br><br><h2>  Apache Beam und DataFlow f√ºr Echtzeit-Pipelines </h2><br>  Der heutige Beitrag basiert auf einer Aufgabe, an der ich k√ºrzlich bei der Arbeit gearbeitet habe.  Ich war sehr gl√ºcklich, es zu implementieren und die geleistete Arbeit im Format eines Blogposts zu beschreiben, da es mir die M√∂glichkeit gab, an der Datenentwicklung zu arbeiten und etwas zu tun, das f√ºr mein Team sehr n√ºtzlich w√§re.  Vor nicht allzu langer Zeit habe ich festgestellt, dass unsere Systeme eine relativ gro√üe Anzahl von Benutzerprotokollen speichern, die sich auf eines unserer Produkte f√ºr die Arbeit mit Daten beziehen.  Es stellte sich heraus, dass niemand diese Daten verwendet hatte, und ich interessierte mich sofort f√ºr das, was wir herausfinden konnten, wenn wir anfingen, sie regelm√§√üig zu analysieren.  Es gab jedoch einige Probleme auf dem Weg.  Das erste Problem war, dass die Daten in vielen verschiedenen Textdateien gespeichert wurden, die f√ºr eine sofortige Analyse nicht verf√ºgbar waren.  Das zweite Problem war, dass sie in einem geschlossenen System gespeichert waren, sodass ich keines meiner bevorzugten Datenanalysetools verwenden konnte. <a name="habracut"></a><br><br>  Ich musste entscheiden, wie wir den Zugriff erleichtern und zumindest einen Mehrwert schaffen k√∂nnen, indem wir diese Datenquelle in einige unserer Benutzerinteraktionsl√∂sungen einbetten.  Nachdem ich eine Weile nachgedacht hatte, beschloss ich, eine Pipeline zu erstellen, um diese Daten in die Cloud-Datenbank zu √ºbertragen, damit ich und das Team darauf zugreifen und Schlussfolgerungen ziehen k√∂nnen.  Nachdem ich vor einiger Zeit meine Spezialisierung in Data Engineering bei Coursera abgeschlossen hatte, war ich bestrebt, einige der Kurswerkzeuge im Projekt zu verwenden. <br><br>  Das Einf√ºgen von Daten in eine Cloud-Datenbank schien also eine clevere M√∂glichkeit zu sein, mein erstes Problem zu l√∂sen. Aber was k√∂nnte ich mit Problem Nummer 2 tun?  Gl√ºcklicherweise gab es eine M√∂glichkeit, diese Daten in eine Umgebung zu √ºbertragen, in der ich auf Tools wie Python und die Google Cloud Platform (GCP) zugreifen konnte.  Es war jedoch ein langer Prozess, daher musste ich etwas tun, das es mir erm√∂glichte, die Entwicklung fortzusetzen, w√§hrend ich auf das Ende der Daten√ºbertragung wartete.  Die L√∂sung bestand darin, gef√§lschte Daten mithilfe der <b>Faker-</b> Bibliothek in Python zu erstellen.  Ich hatte diese Bibliothek noch nie benutzt, erkannte aber schnell, wie n√ºtzlich sie war.  Mit diesem Ansatz konnte ich Code schreiben und die Pipeline ohne tats√§chliche Daten testen. <br><br>  Auf der Grundlage des Vorstehenden werde ich Ihnen in diesem Beitrag erl√§utern, wie ich die oben beschriebene Pipeline mit einigen der in GCP verf√ºgbaren Technologien erstellt habe.  Insbesondere werde ich <b>Apache Beam (Version f√ºr Python), Dataflow, Pub / Sub und Big Query verwenden</b> , um Benutzerprotokolle zu sammeln, Daten zu konvertieren und zur weiteren Analyse in eine Datenbank zu √ºbertragen.  In meinem Fall ben√∂tigte ich nur die Batch-Funktionalit√§t von Beam, da meine Daten nicht in Echtzeit eintrafen und Pub / Sub nicht erforderlich war.  Ich werde mich jedoch auf die Streaming-Version konzentrieren, da dies in der Praxis der Fall sein kann. <br><br><h2>  Einf√ºhrung in GCP und Apache Beam </h2><br>  Die Google Cloud Platform bietet eine Reihe wirklich n√ºtzlicher Tools f√ºr die Verarbeitung von Big Data.  Hier sind einige der Tools, die ich verwenden werde: <br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pub / Sub</a> ist ein Messaging-Dienst, der die Publisher-Subscriber-Vorlage verwendet, mit der wir Daten in Echtzeit empfangen k√∂nnen. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DataFlow</a> ist ein Dienst, der die Erstellung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datenpipelines</a> vereinfacht und automatisch Aufgaben wie die Skalierung der Infrastruktur l√∂st. Das bedeutet, dass wir uns nur auf das Schreiben von Code f√ºr unsere Pipeline konzentrieren k√∂nnen. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BigQuery</a> ist ein Cloud-basiertes Data Warehouse.  Wenn Sie mit anderen SQL-Datenbanken vertraut sind, m√ºssen Sie sich nicht lange mit BigQuery besch√§ftigen. </li><li>  Und schlie√ülich werden wir Apache Beam verwenden, n√§mlich uns auf die Python-Version konzentrieren, um unsere Pipeline zu erstellen.  Mit diesem Tool k√∂nnen wir eine Pipeline f√ºr das Streaming oder die Stapelverarbeitung erstellen, die in GCP integriert ist.  Es ist besonders n√ºtzlich f√ºr die Parallelverarbeitung und eignet sich f√ºr Aufgaben wie Extrahieren, Transformieren und Laden (ETL). Wenn wir also Daten mit Transformationen oder Berechnungen von einem Ort an einen anderen verschieben m√ºssen, ist Beam eine gute Wahl. </li></ul><br><br>  In GCP steht eine gro√üe Anzahl von Tools zur Verf√ºgung, so dass es schwierig sein kann, alle Tools einschlie√ülich ihres Zwecks abzudecken. Dennoch finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier eine</a> kurze Zusammenfassung als Referenz. <br><br><h2>  Visualisierung unseres F√∂rderers </h2><br>  Lassen Sie uns die Komponenten unserer Pipeline in <i>Abbildung 1</i> visualisieren.  Auf hoher Ebene m√∂chten wir Benutzerdaten in Echtzeit erfassen, verarbeiten und an BigQuery √ºbertragen.  Protokolle werden erstellt, wenn Benutzer mit dem Produkt interagieren, indem sie Anforderungen an den Server senden, die dann protokolliert werden.  Diese Daten k√∂nnen besonders n√ºtzlich sein, um zu verstehen, wie Benutzer mit unserem Produkt interagieren und ob sie ordnungsgem√§√ü funktionieren.  Im Allgemeinen enth√§lt der F√∂rderer die folgenden Schritte: <br><br><ol><li>  Die Protokolldaten unserer Benutzer werden im Bereich Pub / Sub ver√∂ffentlicht. </li><li>  Wir werden eine Verbindung zu Pub / Sub herstellen und die Daten mit Python und Beam in das entsprechende Format konvertieren (Schritte 3 und 4 in Abbildung 1). </li><li>  Nach der Konvertierung der Daten stellt Beam eine Verbindung zu BigQuery her und f√ºgt sie unserer Tabelle hinzu (Schritte 4 und 5 in Abbildung 1). </li><li>  Zur Analyse k√∂nnen wir mit verschiedenen Tools wie Tableau und Python eine Verbindung zu BigQuery herstellen. </li></ol><br>  Beam macht diesen Vorgang sehr einfach, unabh√§ngig davon, ob wir eine Streaming-Datenquelle oder eine CSV-Datei haben, und wir m√∂chten die Stapelverarbeitung durchf√ºhren.  Sp√§ter werden Sie sehen, dass der Code nur die minimalen √Ñnderungen enth√§lt, die zum Wechseln zwischen ihnen erforderlich sind.  Dies ist einer der Vorteile der Verwendung von Beam. <br><br><img src="https://habrastorage.org/webt/2s/nv/kc/2snvkcz6-jwybsxr2kyz3awipaw.png"><br>  <i>Abbildung 1: Die Hauptdatenpipeline</i> <br><br><h2>  Pseudodaten mit Faker erstellen </h2><br>  Wie bereits erw√§hnt, habe ich mich aufgrund des eingeschr√§nkten Zugriffs auf Daten entschlossen, Pseudodaten im gleichen Format wie die tats√§chlichen zu erstellen.  Dies war eine sehr n√ºtzliche √úbung, da ich Code schreiben und die Pipeline testen konnte, w√§hrend ich Daten erwartete.  Ich schlage vor, einen Blick auf die Faker- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation zu</a> werfen, wenn Sie wissen m√∂chten, was diese Bibliothek sonst noch zu bieten hat.  Unsere Benutzerdaten √§hneln im Allgemeinen dem folgenden Beispiel.  Basierend auf diesem Format k√∂nnen wir zeilenweise Daten generieren, um Echtzeitdaten zu simulieren.  Diese Protokolle geben uns Informationen wie Datum, Art der Anfrage, Antwort vom Server, IP-Adresse usw. <br><br> <code>192.52.197.161 - - [30/Apr/2019:21:11:42] "PUT /tag/category/tag HTTP/1.1" [401] 155 "https://harris-lopez.com/categories/about/" "Mozilla/5.0 (Macintosh; PPC Mac OS X 10_11_2) AppleWebKit/5312 (KHTML, like Gecko) Chrome/34.0.855.0 Safari/5312"</code> <br> <br>  Basierend auf der obigen Zeile m√∂chten wir unsere <b>LINE-</b> Variable mit 7 Variablen in geschweiften Klammern erstellen.  Wir werden sie etwas sp√§ter auch als Variablennamen in unserem Tabellenschema verwenden. <br><br> <code>LINE = """\ <br> {remote_addr} - - [{time_local}] "{request_type} {request_path} HTTP/1.1" [{status}] {body_bytes_sent} "{http_referer}" "{http_user_agent}"\ <br> """</code> <br> <br>  Wenn wir eine Stapelverarbeitung durchf√ºhren w√ºrden, w√§re der Code sehr √§hnlich, obwohl wir in einem bestimmten Zeitraum eine Reihe von Beispielen erstellen m√ºssten.  Um einen F√§lscher zu verwenden, erstellen wir einfach ein Objekt und rufen die Methoden auf, die wir ben√∂tigen.  Insbesondere war Faker n√ºtzlich, um IP-Adressen sowie Websites zu erstellen.  Ich habe die folgenden Methoden angewendet: <br><br> <code>fake.ipv4() <br> fake.uri_path() <br> fake.uri() <br> fake.user_agent() <br></code> <br><br><pre> <code class="php hljs">from faker import Faker import time import random import os import numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np from datetime import datetime, timedelta LINE = <span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"\ {remote_addr} - - [{time_local}] "</span></span>{request_type} {request_path} HTTP/<span class="hljs-number"><span class="hljs-number">1.1</span></span><span class="hljs-string"><span class="hljs-string">" [{status}] {body_bytes_sent} "</span></span>{http_referer}<span class="hljs-string"><span class="hljs-string">" "</span></span>{http_user_agent}<span class="hljs-string"><span class="hljs-string">"\ "</span></span><span class="hljs-string"><span class="hljs-string">""</span></span> def generate_log_line(): fake = Faker() now = datetime.now() remote_addr = fake.ipv4() time_local = now.strftime(<span class="hljs-string"><span class="hljs-string">'%d/%b/%Y:%H:%M:%S'</span></span>) request_type = random.choice([<span class="hljs-string"><span class="hljs-string">"GET"</span></span>, <span class="hljs-string"><span class="hljs-string">"POST"</span></span>, <span class="hljs-string"><span class="hljs-string">"PUT"</span></span>]) request_path = <span class="hljs-string"><span class="hljs-string">"/"</span></span> + fake.uri_path() status = np.random.choice([<span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-number"><span class="hljs-number">401</span></span>, <span class="hljs-number"><span class="hljs-number">404</span></span>], p = [<span class="hljs-number"><span class="hljs-number">0.9</span></span>, <span class="hljs-number"><span class="hljs-number">0.05</span></span>, <span class="hljs-number"><span class="hljs-number">0.05</span></span>]) body_bytes_sent = random.choice(range(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) http_referer = fake.uri() http_user_agent = fake.user_agent() log_line = LINE.format( remote_addr=remote_addr, time_local=time_local, request_type=request_type, request_path=request_path, status=status, body_bytes_sent=body_bytes_sent, http_referer=http_referer, http_user_agent=http_user_agent ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> log_line</code> </pre> <br><br>  Das Ende des ersten Teils. <br><br>  In den kommenden Tagen werden wir die Fortsetzung des Artikels mit Ihnen teilen, aber jetzt warten wir traditionell auf Kommentare ;-). <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zweiter Teil</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de454186/">https://habr.com/ru/post/de454186/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de454176/index.html">Uibook - ein visuelles Testwerkzeug f√ºr React-Komponenten mit Medienabfragen</a></li>
<li><a href="../de454178/index.html">Ein Beispiel f√ºr die Berechnung der Rente eines IT-Mitarbeiters aus Moskau</a></li>
<li><a href="../de454180/index.html">Schr√∂dinger Cloud Backup</a></li>
<li><a href="../de454182/index.html">Ein ausf√ºhrliches Interview mit dem Dekan der Python-Abteilung von GeekBrains - wie und warum Anf√§nger Sprache lernen</a></li>
<li><a href="../de454184/index.html">KubeCon Europe 2019: Wie wir das Kubernetes Main Event zum ersten Mal besuchten</a></li>
<li><a href="../de454188/index.html">Alternative Rekrutierungskan√§le</a></li>
<li><a href="../de454190/index.html">Was Sie nicht tun m√ºssen, wenn Ihr Telefon gestohlen wird</a></li>
<li><a href="../de454196/index.html">3D-Druck von Elektronik am Beispiel einer Drohne: Dr√§hte und Platinen werden nicht mehr ben√∂tigt</a></li>
<li><a href="../de454198/index.html">Erstellen eines Gradle SpringBoot + Angular-Projekts mit mehreren Modulen in IDEA</a></li>
<li><a href="../de454204/index.html">Verhaltens-Crawlen ist kein Allheilmittel?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
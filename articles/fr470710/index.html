<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤙🏼 🤟🏽 🛌🏾 Apprentissage automatique pour votre chasse à plat. 2e partie 🤹🏿 🌵 💇🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A. A. A. A. A. A. A.  
 Avez-vous pensé à l'influence du métro le plus proche sur le prix de votre appartement? A. 
 A. A. Qu'en est-il de plusieurs j...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apprentissage automatique pour votre chasse à plat. 2e partie</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470710/"><p>  A. A. A. A. A. A. A. <span class="notranslate" onmouseover="_tipon(this)" onmouseout="_tipoff()"></span> <br>  Avez-vous pensé à l'influence du métro le plus proche sur le prix de votre appartement?  A. <br>  A. A. Qu'en est-il de plusieurs jardins d'enfants autour de votre appartement?  Êtes-vous prêt à plonger dans le monde des données géospatiales? </p><br><p>  A. <img src="https://habrastorage.org/webt/mk/hb/cd/mkhbcdjqdoilsw7psuegvtv25r0.png" alt="Le monde offre tellement Informati o n ...">  A. <br>  A. A. <br>  A. <a name="habracut"></a></p><br><h2 id="what-is-all-about">  De quoi s'agit-il? </h2><br><p>  A. <br>  Dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partie précédente</a> , nous avions quelques données et avons essayé de trouver une offre suffisamment bonne sur un marché immobilier à Iekaterinbourg. </p><br><p>  Nous étions arrivés à un point où nous avions une précision de validation croisée proche de 73%.  Cependant, chaque pièce a 2 faces.  Et 73% de précision c'est 27% d'erreur.  Comment pourrions-nous réduire cela?  Quelle est la prochaine étape? </p><br><p>  A. </p><br><h2 id="spatial-data-is-coming-to-help">  Les données spatiales viennent en aide </h2><br><p>  Que diriez-vous d'obtenir plus de données de l'environnement?  Nous pouvons utiliser le géo-contexte et certaines données spatiales. <br>  A. <br>  Les gens passent rarement toute leur vie à la maison.  A. Parfois, ils vont aux magasins, prennent les enfants à la garderie.  Leurs enfants grandissent et vont à l'école, à l'université, etc.  A. </p><br><p>  Ou ... parfois, ils ont besoin d'une aide médicale et recherchent un hôpital.  Et une chose très importante est le transport public, le métro au moins. A. En d'autres termes, il y a beaucoup de choses à proximité, qui ont un impact sur les prix. </p><br><p>  Permettez-moi de vous en montrer une liste: </p><br><ul><li>  Arrêts des transports publics </li><li>  Boutiques </li><li>  Jardins d'enfants </li><li>  Hôpitaux / institutions médicales A. A. A. A. A. A.  A. A. A. </li><li>  Établissements d'enseignement A. A. A. A. A. A.  A. A. A. </li><li>  Métro </li></ul><br><h3 id="visualization-for-new-data">  Visualisation des nouvelles données </h3><br><p>  Après avoir obtenu ces informations de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">A. Différentes sources A. A. ,</a> J'ai fait une visualisation. </p><br><p>  A. <br>  A. <img src="https://habrastorage.org/webt/ws/au/w5/wsauw53wky7lkl0ffzklyiyomg4.png">  A. A. A. A. <br>  Il y a quelques points sur la carte du quartier le plus prestigieux (et le plus cher) de Yek aterinburg. A. A. A. A. A. <br>  A. A. </p><br><ul><li>  A. A. A. A. R ed points - appartements </li><li>  <strong>O</strong> ran ge - arrêts </li><li>  Yellow - boutiques </li><li>  <strong>G</strong> reen - jardins d'enfants </li><li>  <strong>B</strong> lue - éducation </li><li>  <strong>I</strong> ndigo - médical </li><li>  <strong>V</strong> iolet - Metro </li></ul><br><p>  Oui, un arc-en-ciel est ici. </p><br><h3 id="overview">  Présentation </h3><br><p>  Nous avons maintenant un ensemble de données qui est délimité par des géodonnées et contient de nouvelles informations </p><br><pre><code class="python hljs">df.head(<span class="hljs-number"><span class="hljs-number">10</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/pn/wp/2g/pnwp2gqzcxbt25nmahbmri2g9fu.png"></p><br><pre> <code class="python hljs">df.describe()</code> </pre><br><p><img src="https://habrastorage.org/webt/r2/vj/cx/r2vjcx5myydbcx8vqo1p4pneea8.png"></p><br><h2 id="a-good-old-model">  Un bon vieux modèle </h2><br><p>  Essayez de la même manière qu'avant </p><br><pre> <code class="python hljs">y = df.cost X = df.drop(columns=[<span class="hljs-string"><span class="hljs-string">'cost'</span></span>]) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>,random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>)</code> </pre> <br><p>  Ensuite, nous entraînons à nouveau notre modèle, croisons les doigts et essayons à nouveau de prédire le prix de l'appartement. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LinearRegression regressor = LinearRegression() model = regressor.fit(X_train, y_train) do_cross_validation(X_test, y_test, model)</code> </pre> <br><p><img src="https://habrastorage.org/webt/e_/af/fl/e_affl53a0ey291a3_rzscwst20.png"></p><br><p>  Hmm ... il semble meilleur que le résultat précédent avec 73% de précision. <br>  Qu'en est-il des essais d'interprétation?  Notre modèle précédent avait une capacité suffisante pour expliquer le prix forfaitaire. </p><br><pre> <code class="python hljs">estimate_model(regressor)</code> </pre> <br><p><img src="https://habrastorage.org/webt/tv/db/vs/tvdbvsugcwrsekxthskddg0uyto.png"></p><br><p>  Oups ... Notre nouveau modèle fonctionne bien avec les anciennes fonctionnalités, mais le comportement avec les nouvelles semble étrange. </p><br><p>  Par exemple, le plus grand nombre d'établissements d'enseignement ou de médecine entraîne une baisse du prix de l'appartement.  En conséquence, le nombre d'arrêts à proximité de l'appartement est une situation identique et il devrait gagner une contribution supplémentaire au prix forfaitaire. <br>  Le nouveau modèle est plus précis, mais il ne correspond pas à la vie réelle. </p><br><h2 id="something-is-broken">  Quelque chose est cassé </h2><br><p>  Voyons ce qui s'est passé. </p><br><p>  Tout d'abord - je veux vous rappeler que la caractéristique clé de notre régression linéaire est ... euh ... la linéarité.  Oui, le capitaine Obvious est ici. </p><br><p>  Si vos données sont compatibles avec une idée "Le plus gros / le bail est X, le plus grand / le bail sera Y" - la régression linéaire sera un bon outil.  Mais les géodonnées sont plus complexes que prévu. </p><br><p>  Par exemple: </p><br><ul><li>  Lorsque près de votre appartement est un arrêt de bus, c'est bien, mais si le nombre d'entre eux est d'environ 5, cela conduit à une rue bruyante et les gens voudraient éviter d'acheter un appartement à proximité. </li><li>  S'il y a une université, elle devrait avoir une bonne influence sur le prix, <br>  en même temps, une foule d'étudiants près de chez vous n'est pas si heureuse si vous n'êtes pas une personne très sociable. </li><li>  Le métro près de chez vous est bien, mais si vous vivez en une heure à pied <br>  du métro le plus proche - cela ne devrait pas avoir de sens. </li></ul><br><p>  Comme vous le voyez, cela dépend de nombreux facteurs et points de vue.  Et la nature de nos géodonnées n'est pas linéaire, nous ne pouvons en extrapoler l'impact. <br>  Dans le même temps, pourquoi le modèle avec des coefficients bizarres fonctionne-t-il mieux que le précédent? </p><br><pre> <code class="python hljs">plot.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) corr = df.corr()*<span class="hljs-number"><span class="hljs-number">100.0</span></span> sns.heatmap(corr[[<span class="hljs-string"><span class="hljs-string">'cost'</span></span>]], cmap= sns.diverging_palette(<span class="hljs-number"><span class="hljs-number">220</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), center=<span class="hljs-number"><span class="hljs-number">0</span></span>, linewidths=<span class="hljs-number"><span class="hljs-number">1</span></span>, cbar_kws={<span class="hljs-string"><span class="hljs-string">"shrink"</span></span>: <span class="hljs-number"><span class="hljs-number">.7</span></span>}, annot=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, fmt=<span class="hljs-string"><span class="hljs-string">".2f"</span></span>)﻿﻿﻿﻿</code> </pre> <br><p><img src="https://habrastorage.org/webt/qu/ja/fg/qujafgl6oqquabiiv_5eyyzhq18.png" alt="La corrélation avec le prix de l'appartement"></p><br><p>  Ça a l'air intéressant.  Nous avons vu l'image similaire dans la partie précédente. <br>  Il existe une corrélation négative entre la distance au métro le plus proche et le prix.  Et ce facteur a un impact sur la précision plus que certains anciens. </p><br><p>  <strong>Pendant ce temps</strong> , notre modèle fonctionne mal et ne voit pas les dépendances entre les données agrégées et la variable cible.  La simplicité de la régression linéaire a ses propres limites.  A. </p><br><h2 id="the-king-is-dead-long-live-the-king">  Le roi est mort, vive le roi! </h2><br><p>  Et si une régression linéaire ne convient pas à notre cas, quoi de mieux?  Si seulement notre modèle pouvait être "plus intelligent" ... </p><br><p>  Heureusement, nous avons une approche qui devrait mieux à cause de cela plus ... flexible et a un mécanisme intégré "faire si ça fait autre chose faire ça". </p><br><p>  <strong>L'arbre de décision</strong> apparaît sur la scène. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.tree <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> DecisionTreeRegressor A decision tree can have a different depth, usually, it works well when depth <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> bigger. And the parameter of max depth has the biggest influence on the result. Let<span class="hljs-string"><span class="hljs-string">'s do some code for checking depth from 3 to 32 data = [] for x in range(3,32): regressor = DecisionTreeRegressor(max_depth=x,random_state=42) model = regressor.fit(X_train, y_train) accuracy = do_cross_validation(X, y, model) data.append({'</span></span>max_depth<span class="hljs-string"><span class="hljs-string">':x,'</span></span>accuracy<span class="hljs-string"><span class="hljs-string">':accuracy}) data = pd.DataFrame(data) ax = sns.lineplot(x="max_depth", y="accuracy", data=data) max_result = data.loc[data['</span></span>accuracy<span class="hljs-string"><span class="hljs-string">'].idxmax()] ax.set_title(f'</span></span>Max accuracy-{max_result.accuracy}\nDepth {max_result.max_depth} <span class="hljs-string"><span class="hljs-string">')</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/iq/q1/vp/iqq1vpflhxb2vgpfdqeum6th_vo.png" alt="&quot;Plus&quot; ne signifie pas &quot;Meilleur&quot;"></p><br><p>  Eh bien ... pour une situation où le m A. Ax_depth d'un arbre est égal à 8 la précision est supérieure à 77. <br>  Et ce serait une bonne réussite si nous ne réfléchissions pas aux limites de cette approche.  Voyons comment cela fonctionnera avec <em>A. A. M ax_depht = 2 A. A.</em> A. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> IPython.core.display <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image, SVG <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.tree <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> export_graphviz <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> graphviz <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Source <span class="hljs-number"><span class="hljs-number">2</span></span>_level_regressor = DecisionTreeRegressor(max_depth=<span class="hljs-number"><span class="hljs-number">2</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>) model = <span class="hljs-number"><span class="hljs-number">2</span></span>_level_regressor.fit(X_train, y_train) graph = Source(export_graphviz(model, out_file=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span> , feature_names=X.columns , filled = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) SVG(graph.pipe(format=<span class="hljs-string"><span class="hljs-string">'svg'</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/tu/aq/nn/tuaqnnpvmhawqb4tmbn9rcix64u.png"></p><br><p>  Sur cette photo, nous pouvons voir qu'il n'y a que 4 variantes de prédiction.  Lorsque vous utilisez <em>DecisionTreeRegressor</em> , cela fonctionne différemment de la <em>régression linéaire</em> .  Tout simplement différemment.  Il n'utilise pas une contribution de facteurs (coefficients), au lieu de cela que <em>DecisionTreeRegressor</em> utilise la "vraisemblance".  Et le prix d'un appartement sera le même que celui le plus similaire prévu. <br>  Nous pouvons le montrer en prédisant notre prix avec cet arbre. </p><br><pre> <code class="python hljs">y = two_level_regressor.predict(X_test) errors = pd.DataFrame(data=y,columns=[<span class="hljs-string"><span class="hljs-string">'errors'</span></span>]) f, ax = plot.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>)) sns.countplot(x=<span class="hljs-string"><span class="hljs-string">"errors"</span></span>, data=errors)</code> </pre> <br><p><img src="https://habrastorage.org/webt/bw/kl/t3/bwklt3nvb65y2mdmfwlkj0_v_le.png"><br>  Et chaque prédiction correspondra à l'une de ces valeurs.  Et lorsque nous utilisons <em>max_depth</em> = 8, nous ne pouvons nous attendre à plus de 256 options différentes pour plus de 2000 appartements.  C'est peut-être bon pour les problèmes de classification, mais ce n'est pas assez flexible pour notre cas. </p><br><h2 id="wisdom-of-crowd">  Sagesse de la foule </h2><br><p>  Si vous essayez de prédire le score lors de la finale de la Coupe du monde - il y a de fortes chances que vous vous trompiez.  Dans le même temps, si vous demandez l'avis de tous les juges du championnat, vous aurez de meilleures chances de deviner.  Si vous demandez à des experts indépendants, des formateurs, des juges, puis faites de la magie avec les réponses - vos chances augmenteront considérablement.  On dirait une élection d'un président. </p><br><p>  Un ensemble de plusieurs arbres «primitifs» peut donner plus que chacun d'eux.  Et <em>rando mForestRegressor est</em> un outil que nous utiliserons </p><br><p>  Tout d'abord, considérons les paramètres de base - <em>max_depth</em> , <em>max_features</em> et un <em>certain nombre d'arbres</em> dans le modèle. <br>  A. </p><br><h3 id="number-of-trees">  Nombre d'arbres </h3><br><p>  Conformément à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">"Combien d'arbres dans une forêt aléatoire?"</a>  le meilleur choix sera de <strong>128 arbres</strong> .  Une augmentation supplémentaire du nombre d'arbres n'entraîne pas une amélioration significative de la précision, mais augmente le temps de formation. </p><br><h3 id="maximal-number-of-features">  Nombre maximal de fonctionnalités </h3><br><p>  En ce moment, notre modèle a 12 fonctionnalités.  La moitié d'entre eux sont des anciens qui sont liés à des fonctionnalités de flat, d'autres liés au géo-contexte.  J'ai donc décidé de donner une chance à chacun d'eux.  Soit <strong>6 fonctionnalités</strong> pour un arbre. </p><br><h3 id="maximal-depth-of-a-tree">  Profondeur maximale d'un arbre </h3><br><p>  Pour ce paramètre, nous pouvons analyser une courbe d'apprentissage. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestRegressor data = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">32</span></span>): regressor = RandomForestRegressor(random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>, max_depth=x, n_estimators=<span class="hljs-number"><span class="hljs-number">128</span></span>,max_features=<span class="hljs-number"><span class="hljs-number">6</span></span>)﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿model = regressor.fit(X_train, y_train)﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿accuracy = do_cross_validation(X, y, model) data.append({<span class="hljs-string"><span class="hljs-string">'max_depth'</span></span>:x,<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>:accuracy}) data = pd.DataFrame(data) f, ax = plot.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) sns.lineplot(x=<span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>, y=<span class="hljs-string"><span class="hljs-string">"accuracy"</span></span>, data=data) max_result = data.loc[data[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>].idxmax()] ax.set_title(<span class="hljs-string"><span class="hljs-string">f'Max accuracy-</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{max_result.accuracy}</span></span></span><span class="hljs-string">\nDepth </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{max_result.max_depth}</span></span></span><span class="hljs-string"> '</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/sl/mw/ca/slmwcayhk5w0tlediopsbku7dde.png" alt="86% de précision est incroyable"></p><br><p>  Whoa ... plus de 86% de précision sur <strong>max_depth = 16</strong> contre 77% sur un arbre de conception.  Cela a l'air incroyable, n'est-ce pas? </p><br><h2 id="conclusion">  Conclusion </h2><br><p>  Eh bien ... maintenant, nous avons un meilleur résultat en prévision que les précédents, 86% est près de la ligne d'arrivée.  La dernière étape pour vérifier - examinons l'importance des fonctionnalités.  Les géodonnées ont-elles profité à notre modèle? </p><br><pre> <code class="python hljs">feat_importances = model.feature_importances_ feat_importances = pd.Series(feat_importances, index=X.columns) feat_importances.nlargest(<span class="hljs-number"><span class="hljs-number">5</span></span>).plot(kind=<span class="hljs-string"><span class="hljs-string">'barh'</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/cn/bm/im/cnbmimno-ma3r0qbqozoq7diwrw.png" alt="Le top 5 des fonctionnalités les plus importantes"></p><br><p>  Certaines anciennes fonctionnalités ont encore affecté le résultat.  En même temps, la distance par rapport au métro et aux jardins d'enfants les plus proches a également été affectée.  Et cela semble logique. </p><br><p>  Sans aucun doute, les géodonnées nous ont aidés à améliorer notre modèle. </p><br><p>  <strong>Merci d'avoir lu!</strong> </p><br><h2 id="ps">  PS </h2><br><p>  Notre voyage n'est pas encore terminé.  Une précision de 86% est un résultat formidable pour des données réelles.  En attendant, voici un petit écart entre 14% et 10% d'erreur moyenne, ce que nous attendons.  Dans le prochain chapitre de notre histoire, nous allons essayer de surmonter cette barrière ou au moins de diminuer cette erreur. A. A. A. A. A. A.  A. A. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Il</a> y a le cahier IPython </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr470710/">https://habr.com/ru/post/fr470710/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr470692/index.html">Comment nous avons créé un nouveau site Web Rosbank et ce qui en est ressorti</a></li>
<li><a href="../fr470694/index.html">Choisir une plate-forme de marketing par e-mail: que faire attention aux entreprises russes</a></li>
<li><a href="../fr470696/index.html">Pourquoi Kaldi est-il bon pour la reconnaissance vocale? (mis à jour le 12.25.2019)</a></li>
<li><a href="../fr470700/index.html">Dessus de table. Métallique Silencieux Le vôtre</a></li>
<li><a href="../fr470706/index.html">Python + Keras + LSTM: faites un traducteur de texte en une demi-heure</a></li>
<li><a href="../fr470714/index.html">Comment je suis allé à la finale de la percée numérique</a></li>
<li><a href="../fr470718/index.html">"Effets algébriques" dans le langage humain</a></li>
<li><a href="../fr470720/index.html">Comment écrire un contrat intelligent avec Python sur l'ontologie? Partie 2: API de stockage</a></li>
<li><a href="../fr470722/index.html">Comment écrire un contrat intelligent avec Python sur l'ontologie? Partie 3: API d'exécution</a></li>
<li><a href="../fr470726/index.html">Comment ne pas se noyer dans la routine, ou notre expérience en comparant les décharges AWR pendant les tests de résistance</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
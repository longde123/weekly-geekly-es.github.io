<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåª ‚ûø üë©üèø‚Äçü§ù‚Äçüë®üèΩ Migrar de Mongo a Postgres: la experiencia del peri√≥dico The Guardian üÜï üõåüèº üë©üèº‚Äç‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The Guardian es uno de los peri√≥dicos brit√°nicos m√°s grandes, fue fundado en 1821. Durante casi 200 a√±os de existencia, el archivo ha acumulado una ca...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Migrar de Mongo a Postgres: la experiencia del peri√≥dico The Guardian</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/436416/"><img src="https://habrastorage.org/webt/4w/zu/h3/4wzuh3ik2zdn_awvt9l2rhd4oia.jpeg" alt="imagen"><br><br>  The Guardian es uno de los peri√≥dicos brit√°nicos m√°s grandes, fue fundado en 1821.  Durante casi 200 a√±os de existencia, el archivo ha acumulado una cantidad justa.  Afortunadamente, no todo est√° almacenado en el sitio, solo en las √∫ltimas d√©cadas.  La base de datos, que los propios brit√°nicos llamaron la "fuente de la verdad" para todo el contenido en l√≠nea, contiene alrededor de 2,3 millones de elementos.  Y en un momento, se dieron cuenta de la necesidad de migrar de Mongo a Postgres SQL: despu√©s de un caluroso d√≠a de julio de 2015, los procedimientos de conmutaci√≥n por error se probaron severamente.  ¬°La migraci√≥n tom√≥ casi 3 a√±os! .. <br><br>  Hemos traducido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo</a> que describe c√≥mo fue el proceso de migraci√≥n y qu√© dificultades enfrentaron los administradores.  El proceso es largo, pero el resumen es simple: llegar a la gran tarea, conciliar que los errores ser√°n necesarios.  Pero al final, 3 a√±os despu√©s, los colegas brit√°nicos lograron celebrar el final de la migraci√≥n.  Y dormir <br><a name="habracut"></a><br><h4>  <b>Primera parte: el comienzo</b> </h4><br>  En Guardian, la mayor parte del contenido, incluidos art√≠culos, blogs, galer√≠as de fotos y videos, se produce dentro de nuestro propio CMS, Composer.  Hasta hace poco, Composer trabajaba con Mongo DB basado en AWS.  Esta base de datos era esencialmente una "fuente de verdad" para todo el contenido en l√≠nea de Guardian: alrededor de 2,3 millones de elementos.  Y acabamos de completar la migraci√≥n de Mongo a Postgres SQL. <br><br>  Composer y sus bases de datos se alojaron originalmente en Guardian Cloud, un centro de datos en el s√≥tano de nuestra oficina cerca de Kings Cross, con conmutaci√≥n por error en otros lugares de Londres.  Un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">caluroso d√≠a de julio de 2015,</a> nuestros procedimientos de conmutaci√≥n por error fueron sometidos a una prueba bastante severa. <br><br><img src="https://habrastorage.org/webt/ij/nu/wx/ijnuwxcxdtlrnupaxikvcqq7ofe.jpeg" alt="imagen"><br>  <i>Calor: bueno para bailar en la fuente, desastroso para el centro de datos.</i>  <i>Foto: Sarah Lee / Guardian</i> <br><br>  Desde entonces, la migraci√≥n de Guardian a AWS se ha convertido en una cuesti√≥n de vida o muerte.  Para migrar a la nube, decidimos comprar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpsManager</a> , el software de administraci√≥n Mongo DB, y firmamos un contrato de soporte t√©cnico de Mongo.  Utilizamos OpsManager para administrar copias de seguridad, orquestar y monitorear nuestro grupo de bases de datos. <br><br>  Debido a los requisitos editoriales, necesit√°bamos iniciar el cl√∫ster de base de datos y OpsManager en nuestra propia infraestructura en AWS, y no usar la soluci√≥n administrada de Mongo.  Tuvimos que sudar, ya que Mongo no proporcion√≥ ninguna herramienta para una configuraci√≥n f√°cil en AWS: dise√±amos manualmente toda la infraestructura y escribimos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cientos de scripts Ruby</a> para instalar agentes de monitoreo / automatizaci√≥n y orquestar nuevas instancias de bases de datos.  Como resultado, tuvimos que organizar un equipo de programas educativos sobre gesti√≥n de bases de datos en el equipo, lo que esper√°bamos que asumiera OpsManager. <br><br>  Desde la transici√≥n a AWS, hemos tenido dos fallas significativas debido a problemas en la base de datos, cada uno de los cuales no permiti√≥ la publicaci√≥n en theguardian.com durante al menos una hora.  En ambos casos, ni el personal de soporte t√©cnico de OpsManager ni Mongo pudieron brindarnos asistencia suficiente, y nosotros mismos resolvimos el problema, en un caso, gracias a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">miembro de nuestro equipo</a> que logr√≥ abordar la situaci√≥n por tel√©fono desde el desierto en las afueras de Abu Dhabi. <br><br>  Cada uno de los problemas problem√°ticos merece una publicaci√≥n separada, pero aqu√≠ est√°n los puntos generales: <br><br><ul><li>  Preste mucha atenci√≥n al tiempo: no bloquee el acceso a su VPC hasta el punto de que NTP deje de funcionar. </li><li>  Crear autom√°ticamente √≠ndices de bases de datos al inicio de la aplicaci√≥n es una mala idea. </li><li>  La administraci√≥n de la base de datos es extremadamente importante y dif√≠cil, y no quisi√©ramos hacerlo nosotros mismos. </li></ul><br>  OpsManager no cumpli√≥ su promesa de una gesti√≥n simple de la base de datos.  Por ejemplo, la administraci√≥n real de OpsManager en s√≠, en particular, la actualizaci√≥n de OpsManager versi√≥n 1 a la versi√≥n 2, requiri√≥ mucho tiempo y conocimiento especial sobre nuestra configuraci√≥n de OpsManager.  Tampoco cumpli√≥ su promesa de "actualizaciones de un clic" debido a cambios en el esquema de autenticaci√≥n entre diferentes versiones de Mongo DB.  Perdimos al menos dos meses de ingenieros por a√±o administrando la base de datos. <br><br>  Todos estos problemas, combinados con la importante tarifa anual que pagamos por el contrato de soporte y OpsManager, nos obligaron a buscar una opci√≥n de base de datos alternativa con las siguientes caracter√≠sticas: <br><br><ul><li>  Esfuerzo m√≠nimo para administrar la base de datos. </li><li>  Cifrado en reposo. </li><li>  Una ruta de migraci√≥n aceptable con Mongo. </li></ul><br>  Dado que todos nuestros otros servicios ejecutan AWS, la opci√≥n obvia es Dynamo, la base de datos NoSQL de Amazon.  Desafortunadamente, en ese momento, Dynamo no admit√≠a el cifrado en reposo.  Despu√©s de esperar unos nueve meses para que se agregue esta caracter√≠stica, terminamos abandonando esta idea al decidir usar Postgres en AWS RDS. <br>  "¬°Pero Postgres no es un repositorio de documentos!"  - est√°s indignado ... Bueno, s√≠, este no es un repositorio de base, pero tiene tablas similares a las columnas JSONB, con soporte para √≠ndices en los campos de la herramienta JSON Blob.  Esper√°bamos que con JSONB pudi√©ramos migrar de Mongo a Postgres con cambios m√≠nimos en nuestro modelo de datos.  Adem√°s, si quisi√©ramos pasar a un modelo m√°s relacional en el futuro, tendr√≠amos esa oportunidad.  Otra gran cosa sobre Postgres es lo bien que funcion√≥: para cada pregunta que ten√≠amos, en la mayor√≠a de los casos, la respuesta ya estaba dada en Stack Overflow. <br><br>  En t√©rminos de rendimiento, est√°bamos seguros de que Postgres podr√≠a hacerlo: Composer es una herramienta exclusiva para grabar contenido (escribe en la base de datos cada vez que un periodista deja de imprimir), y generalmente el n√∫mero de usuarios simult√°neos no excede varios cientos, lo que no requiere el sistema super alta potencia! <br><br><h4>  Segunda parte: la migraci√≥n de contenido de dos d√©cadas pas√≥ sin tiempo de inactividad </h4><br>  <b>Plan</b> <br><br>  La mayor√≠a de las migraciones de bases de datos implican las mismas acciones, y la nuestra no fue la excepci√≥n.  Esto es lo que hicimos: <br><br><ul><li>  Cre√≥ una nueva base de datos. </li><li>  Crearon una forma de escribir en una nueva base de datos (nueva API). </li><li>  Creamos un servidor proxy que env√≠a tr√°fico tanto a la base de datos antigua como a la nueva, utilizando la antigua como la principal. </li><li>  Se movieron los registros de la base de datos anterior a la nueva. </li><li>  Hicieron de la nueva base de datos la principal. </li><li>  Se elimin√≥ la base de datos anterior. </li></ul><br>  Dado que la base de datos a la que migramos proporcion√≥ el funcionamiento de nuestro CMS, fue cr√≠tico que la migraci√≥n causara la menor cantidad de problemas posible para nuestros periodistas.  Al final, la noticia nunca termina. <br><br>  <b>Nueva API</b> <br><br>  El trabajo en la nueva API basada en Postgres comenz√≥ a fines de julio de 2017.  Este fue el comienzo de nuestro viaje.  Pero para entender c√≥mo fue, primero debemos aclarar d√≥nde comenzamos. <br><br>  Nuestra arquitectura CMS simplificada era algo as√≠: una base de datos, una API y varias aplicaciones relacionadas (como una interfaz de usuario).  La pila fue construida y durante 4 a√±os ahora opera sobre la base de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Scala</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Scalatra Framework</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Angular.js</a> . <br><br>  Despu√©s de un an√°lisis, llegamos a la conclusi√≥n de que antes de que podamos migrar el contenido existente, necesitamos una forma de contactar la nueva base de datos PostgreSQL, manteniendo operativa la antigua API.  Despu√©s de todo, Mongo DB es nuestra "fuente de verdad".  Ella nos sirvi√≥ como un salvavidas mientras experimentamos con la nueva API. <br><br>  Esta es una de las razones por las cuales construir sobre la antigua API no era parte de nuestros planes.  La separaci√≥n de funciones en la API original fue m√≠nima, y ‚Äã‚Äãlos m√©todos espec√≠ficos necesarios para trabajar espec√≠ficamente con Mongo DB se pueden encontrar incluso a nivel de controlador.  Como resultado, la tarea de agregar otro tipo de base de datos a una API existente era demasiado arriesgada. <br><br>  Fuimos al otro lado y duplicamos la antigua API.  As√≠ naci√≥ APIV2.  Era una copia m√°s o menos exacta de la antigua API relacionada con Mongo, e inclu√≠a los mismos puntos finales y funcionalidades.  Utilizamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">doobie</a> , la capa de caracter√≠sticas JDBC pura para Scala, agregamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Docker</a> para ejecutar y probar localmente, y mejoramos el registro de operaciones y el intercambio de responsabilidades.  Se supon√≠a que APIV2 era una versi√≥n r√°pida y moderna de la API. <br><br>  A fines de agosto de 2017, implementamos una nueva API que utilizaba PostgreSQL como su base de datos.  Pero eso fue solo el comienzo.  Hay art√≠culos en Mongo DB que se crearon por primera vez hace m√°s de dos d√©cadas, y todos tuvieron que migrar a la base de datos de Postgres. <br><br>  <b>La migracion</b> <br><br>  Deber√≠amos poder editar cualquier art√≠culo en el sitio, independientemente de cu√°ndo se public√≥, por lo tanto, todos los art√≠culos existen en nuestra base de datos como una √∫nica "fuente de verdad". <br><br>  Aunque todos los art√≠culos viven en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API de contenido de Guardian (CAPI)</a> , que sirve a las aplicaciones y al sitio, fue extremadamente importante para nosotros migrar sin ning√∫n problema t√©cnico, ya que nuestra base de datos es nuestra "fuente de verdad".  Si algo le sucediera al cl√∫ster Elasticsearch CAPI, lo volver√≠amos a indexar desde la base de datos de Composer. <br>  Por lo tanto, antes de deshabilitar Mongo, tuvimos que asegurarnos de que la misma solicitud para la API que se ejecuta en Postgres y la API que se ejecuta en Mongo devolver√≠a respuestas id√©nticas. <br>  Para hacer esto, necesit√°bamos copiar todo el contenido en la nueva base de datos de Postgres.  Esto se hizo usando un script que interactuaba directamente con las API antiguas y nuevas.  La ventaja de este m√©todo fue que ambas API ya proporcionaban una interfaz bien probada para leer y escribir art√≠culos dentro y fuera de las bases de datos, en lugar de escribir algo que accediera directamente a las bases de datos respectivas. <br><br>  El orden b√°sico de migraci√≥n fue el siguiente: <br><br><ul><li>  Obt√©n contenido de Mongo. </li><li>  Publica contenido en Postgres. </li><li>  Obt√©n contenido de Postgres. </li><li>  Aseg√∫rese de que las respuestas de ellos sean id√©nticas. </li></ul><br>  La migraci√≥n de la base de datos puede considerarse exitosa solo si los usuarios finales no se han dado cuenta de que esto ha sucedido, y un buen script de migraci√≥n siempre ser√° la clave de dicho √©xito.  Necesit√°bamos un script que pudiera: <br><br><ul><li>  Ejecuta solicitudes HTTP. </li><li>  Aseg√∫rese de que despu√©s de migrar parte del contenido, la respuesta de ambas API sea la misma. </li><li>  Det√©ngase cuando ocurra un error. </li><li>  Cree un registro detallado de operaciones para diagnosticar problemas. </li><li>  Reinicie despu√©s de un error desde el punto correcto. </li></ul><br>  Comenzamos usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">amonita</a> .  Le permite escribir scripts en el lenguaje Scala, que es el n√∫cleo de nuestro equipo.  Fue una buena oportunidad para experimentar con algo que no hab√≠amos usado antes para ver si nos ser√≠a √∫til.  Aunque Ammonite nos permiti√≥ usar un lenguaje familiar, encontramos varias deficiencias al trabajar en √©l.  Intellij actualmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">admite</a> Ammonite, pero no lo hizo durante nuestra migraci√≥n, y perdimos la finalizaci√≥n autom√°tica y la importaci√≥n autom√°tica.  Adem√°s, durante un largo per√≠odo de tiempo, el script Ammonite no se pudo ejecutar. <br>  Finalmente, Ammonite no era la herramienta adecuada para este trabajo, y en su lugar utilizamos el proyecto sbt para hacer la migraci√≥n.  Esto nos permiti√≥ trabajar en un idioma en el que confiamos, as√≠ como realizar varias 'migraciones de prueba' antes de lanzarnos en el entorno de trabajo principal. <br><br>  Inesperado fue lo √∫til que fue para verificar la versi√≥n de la API que se ejecuta en Postgres.  Encontramos varios errores dif√≠ciles de encontrar y casos limitantes que no encontramos antes. <br><br>  Avancemos r√°pidamente hasta enero de 2018, cuando es el momento de probar la migraci√≥n completa en nuestro entorno de CODIGO previo. <br><br>  Como la mayor√≠a de nuestros sistemas, la √∫nica similitud entre CODE y PROD es la versi√≥n de la aplicaci√≥n que se est√° lanzando.  La infraestructura de AWS compatible con CODE fue mucho menos potente que PROD, simplemente porque obtiene mucha menos carga de trabajo. <br><br>  Esperamos que la migraci√≥n de prueba en el entorno CODE nos ayude a: <br><br><ul><li>  Calcule cu√°nto tiempo llevar√° la migraci√≥n en el entorno PROD. </li><li>  Evaluar c√≥mo (si es que la migraci√≥n) afecta la productividad. </li></ul><br>  Para obtener mediciones precisas de estos indicadores, tuvimos que poner los dos entornos en completa correspondencia mutua.  Esto incluy√≥ restaurar una copia de seguridad de Mongo DB de PROD a CODE y actualizar la infraestructura compatible con AWS. <br><br>  La migraci√≥n de poco m√°s de 2 millones de elementos de datos deber√≠a haber llevado mucho m√°s tiempo de lo que permitir√≠a una jornada laboral est√°ndar.  Por lo tanto, ejecutamos el script en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pantalla</a> durante la noche. <br><br>  Para medir el progreso de la migraci√≥n, enviamos consultas estructuradas (usando tokens) a nuestra pila ELK (Elasticsearch, Logstash y Kibana).  A partir de ah√≠, podr√≠amos crear paneles detallados mediante el seguimiento de la cantidad de art√≠culos transferidos con √©xito, la cantidad de bloqueos y el progreso general.  Adem√°s, todos los indicadores se mostraban en la pantalla grande para que todo el equipo pudiera ver los detalles. <br><br><img src="https://habrastorage.org/webt/wk/zh/uj/wkzhujequqzbqpf65ewnt4zcfbg.png" alt="imagen"><br>  <i>Panel de control que muestra el progreso de la migraci√≥n: Herramientas editoriales / Guardian</i> <br><br>  Una vez que se complet√≥ la migraci√≥n, verificamos una coincidencia para cada documento en Postgres y en Mongo. <br><br><h4>  <b>Tercera parte: Proxies y lanzamiento en Prod</b> </h4><br>  <b>Proxies</b> <br><br>  Ahora que se lanz√≥ la nueva API que se ejecuta en Postgres, necesit√°bamos probarla con patrones reales de tr√°fico y acceso a datos para asegurarnos de su confiabilidad y estabilidad.  Hab√≠a dos formas posibles de hacer esto: actualizar cada cliente que accede a la API de Mongo para que acceda a ambas API;  o ejecute un proxy que lo haga por nosotros.  Escribimos proxies en Scala usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Akka Streams</a> . <br><br>  El proxy era bastante simple: <br><br><ul><li>  Reciba el tr√°fico del equilibrador de carga. </li><li>  Redirigir el tr√°fico a la API principal y viceversa. </li><li>  Reenv√≠e el mismo tr√°fico de forma as√≠ncrona a una API adicional. </li><li>  Calcule las discrepancias entre las dos respuestas y reg√≠strelas en un registro. </li></ul><br>  Inicialmente, el proxy registr√≥ muchas discrepancias, incluidas algunas diferencias de comportamiento dif√≠ciles de encontrar pero importantes en las dos API que deb√≠an corregirse. <br><br>  <b>Registro estructurado</b> <br><br>  En Guardian, iniciamos sesi√≥n con la pila <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ELK</a> (Elasticsearch, Logstash y Kibana).  Usar Kibana nos dio la oportunidad de visualizar la revista de la manera m√°s conveniente para nosotros.  Kibana usa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la sintaxis de consulta de Lucene</a> , que es bastante f√°cil de aprender.  Pero pronto nos dimos cuenta de que era imposible filtrar o agrupar las entradas de diario en la configuraci√≥n actual.  Por ejemplo, no pudimos filtrar los que se enviaron como resultado de solicitudes GET. <br><br>  Decidimos enviar datos m√°s estructurados a Kibana, no solo mensajes.  Una entrada de registro contiene varios campos, por ejemplo, la marca de tiempo y el nombre de la pila o aplicaci√≥n que envi√≥ la solicitud.  Agregar nuevos campos es muy f√°cil.  Estos campos estructurados se denominan marcadores y pueden implementarse utilizando la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">biblioteca logstash-logback-encoder</a> .  Para cada solicitud, extrajimos informaci√≥n √∫til (por ejemplo, ruta, m√©todo, c√≥digo de estado) y creamos un mapa con informaci√≥n adicional necesaria para el registro.  Aqu√≠ hay un ejemplo: <br><br><pre><code class="plaintext hljs">import akka.http.scaladsl.model.HttpRequest import ch.qos.logback.classic.{Logger =&gt; LogbackLogger} import net.logstash.logback.marker.Markers import org.slf4j.{LoggerFactory, Logger =&gt; SLFLogger} import scala.collection.JavaConverters._ object Logging { val rootLogger: LogbackLogger = LoggerFactory.getLogger(SLFLogger.ROOT_LOGGER_NAME).asInstanceOf[LogbackLogger] private def setMarkers(request: HttpRequest) = { val markers = Map( "path" -&gt; request.uri.path.toString(), "method" -&gt; request.method.value ) Markers.appendEntries(markers.asJava) } def infoWithMarkers(message: String, akkaRequest: HttpRequest) = rootLogger.info(setMarkers(akkaRequest), message) }</code> </pre> <br>  Los campos adicionales en nuestros registros nos permitieron crear paneles informativos y agregar m√°s contexto a las discrepancias, lo que nos ayud√≥ a identificar algunas inconsistencias menores entre las dos API. <br><br>  <b>Replicaci√≥n de tr√°fico y refactorizaci√≥n de proxy</b> <br><br>  Despu√©s de transferir el contenido a la base de datos CODE, obtuvimos una copia casi exacta de la base de datos PROD.  La principal diferencia era que CODE no ten√≠a tr√°fico.  Para replicar el tr√°fico real al entorno CODE, utilizamos la herramienta de c√≥digo abierto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GoReplay</a> (en lo sucesivo, gor).  Es muy f√°cil de instalar y flexible para personalizar seg√∫n sus requisitos. <br><br>  Dado que todo el tr√°fico que llegaba a nuestras API fue primero a servidores proxy, ten√≠a sentido instalar gor en contenedores proxy.  Vea a continuaci√≥n c√≥mo cargar gor en su contenedor y c√≥mo comenzar a monitorear el tr√°fico en el puerto 80 y enviarlo a otro servidor. <br><br><pre> <code class="plaintext hljs"> wget https://github.com/buger/goreplay/releases/download/v0.16.0.2/gor_0.16.0_x64.tar.gz tar -xzf gor_0.16.0_x64.tar.gz gor sudo gor --input-raw :80 --output-http http://apiv2.code.co.uk</code> </pre><br>  Durante un tiempo, todo funcion√≥ bien, pero muy pronto hubo un mal funcionamiento cuando el proxy no estuvo disponible durante varios minutos.  En el an√°lisis, encontramos que los tres contenedores proxy se colgaban peri√≥dicamente al mismo tiempo.  Al principio pensamos que el proxy estaba fallando porque gor estaba usando demasiados recursos.  Tras un an√°lisis m√°s detallado de la consola de AWS, encontramos que los contenedores proxy se colgaban regularmente, pero no al mismo tiempo. <br><br>  Antes de profundizar m√°s en el problema, tratamos de encontrar una manera de ejecutar gor, pero esta vez sin carga adicional en el proxy.  La soluci√≥n vino de nuestra pila secundaria para Composer.  Esta pila se usa solo en caso de emergencia, y nuestra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">herramienta de monitoreo de trabajo la</a> prueba constantemente.  Esta vez, la reproducci√≥n del tr√°fico de esta pila a CODE a doble velocidad funcion√≥ sin ning√∫n problema. <br><br>  Nuevos hallazgos han planteado muchas preguntas.  El proxy se cre√≥ como una herramienta temporal, por lo que es posible que no se haya dise√±ado con tanto cuidado como otras aplicaciones.  Adem√°s, fue construido usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://doc.akka.io/docs/akka-">Akka Http</a> , con el que ninguno de nuestro equipo estaba familiarizado.  El c√≥digo estaba desordenado y lleno de soluciones r√°pidas.  Decidimos comenzar muchas refactorizaciones para mejorar la legibilidad.  Esta vez utilizamos generadores for en lugar de la creciente l√≥gica anidada que usamos antes.  Y agreg√≥ a√∫n m√°s marcadores de registro. <br><br>  Esper√°bamos poder evitar que los contenedores proxy se congelen si entramos en detalles de lo que estaba sucediendo dentro del sistema y simplificamos la l√≥gica de su funcionamiento.  Pero eso no funcion√≥.  Despu√©s de dos semanas de intentar hacer que el proxy sea m√°s confiable, nos sentimos atrapados.  Era necesario tomar una decisi√≥n.  Decidimos arriesgarnos y dejar el proxy tal como est√°, ya que es mejor dedicar tiempo a la migraci√≥n en s√≠ misma que tratar de arreglar un software que ser√° innecesario en un mes.  Pagamos esta soluci√≥n con dos fallas m√°s, casi dos minutos cada una, pero ten√≠a que hacerse. <br><br>  Avancemos r√°pidamente hasta marzo de 2018, cuando ya completamos la migraci√≥n a CODE sin sacrificar el rendimiento de la API o la experiencia del cliente en CMS.  Ahora podr√≠amos comenzar a pensar en descartar proxies de CODE. <br><br>  El primer paso fue cambiar las prioridades de la API para que el proxy interactuara primero con Postgres.  Como dijimos anteriormente, esto se decidi√≥ por un cambio en la configuraci√≥n.  Sin embargo, hubo una dificultad. <br><br>  Composer env√≠a mensajes a la secuencia de Kinesis despu√©s de actualizar el documento.  Solo se necesita una API para enviar mensajes para evitar la duplicaci√≥n.  Para esto, las API tienen un indicador en la configuraci√≥n: verdadero para la API admitida por Mongo y falso para los Postgres admitidos.  Simplemente cambiar el proxy para interactuar con Postgres primero no fue suficiente, ya que el mensaje no se enviar√≠a a la transmisi√≥n de Kinesis hasta que la solicitud llegara a Mongo.  Ha pasado demasiado tiempo <br><br>  Para resolver este problema, creamos puntos finales HTTP para cambiar instant√°neamente la configuraci√≥n de todas las instancias del equilibrador de carga sobre la marcha.  Esto nos permiti√≥ conectar la API principal muy r√°pidamente sin la necesidad de editar el archivo de configuraci√≥n y volver a implementar.  Adem√°s, esto puede automatizarse, lo que reduce la interacci√≥n humana y la probabilidad de errores. <br><br>  Ahora todas las solicitudes se enviaron primero a Postgres, y API2 interactu√≥ con Kinesis.  Los reemplazos podr√≠an hacerse permanentes con cambios de configuraci√≥n y redistribuci√≥n. <br><br>  El siguiente paso fue eliminar completamente el proxy y obligar a los clientes a acceder exclusivamente a la API de Postgres.  Como tenemos muchos clientes, no fue posible actualizar cada uno de ellos individualmente.  Por lo tanto, elevamos esta tarea al nivel de DNS.  Es decir, creamos un CNAME en DNS que primero apuntaba al proxy ELB y cambiar√≠a para apuntar a la API ELB.  Esto permiti√≥ realizar un solo cambio en lugar de actualizar cada cliente API individual. <br><br>  Es hora de mover el PROD.  Aunque daba un poco de miedo, bueno, porque este es el principal entorno de trabajo.  El proceso fue relativamente simple, ya que todo se decidi√≥ cambiando la configuraci√≥n.  Adem√°s, a medida que se agregaba un marcador de etapa a los registros, era posible volver a perfilar tableros construidos previamente simplemente actualizando el filtro Kibana. <br><br>  <b>Desactivar proxies y Mongo DB</b> <br><br>  Despu√©s de 10 meses y 2.4 millones de art√≠culos migrados, finalmente pudimos desactivar toda la infraestructura relacionada con Mongo.  Pero primero, ten√≠amos que hacer lo que todos est√°bamos esperando: matar el proxy. <br><br><img src="https://habrastorage.org/webt/6q/g5/ck/6qg5cksqesrnoig3gxnu7kfea-i.png" alt="imagen"><br>  <i>Registros que muestran la desactivaci√≥n del Proxy API flexible.</i>  <i>Fotograf√≠a: Editorial Tools / Guardian</i> <br><br>  ¬°Este peque√±o software nos caus√≥ tantos problemas que anhelamos desconectarlo pronto!  Todo lo que ten√≠amos que hacer era actualizar el registro CNAME para apuntar directamente al equilibrador de carga APIV2. <br>  Todo el equipo se reuni√≥ alrededor de una computadora.  Era necesario hacer solo una pulsaci√≥n de tecla.  ¬°Todos contuvieron el aliento!  Silencio completo ... ¬°Haz clic!  El trabajo esta hecho.  ¬°Y nada vol√≥!  Todos exhalamos alegremente. <br><br>  Sin embargo, eliminar la antigua API de Mongo DB estaba lleno de otra prueba.  Desesperados por eliminar el c√≥digo anterior, descubrimos que nuestras pruebas de integraci√≥n nunca se ajustaron para usar la nueva API.  Todo r√°pidamente se puso rojo.  Afortunadamente, la mayor√≠a de los problemas estaban relacionados con la configuraci√≥n y los solucionamos f√°cilmente.  Hubo varios problemas con las consultas PostgreSQL que fueron detectadas por las pruebas.  Pensando en lo que podr√≠a hacerse para evitar este error, aprendimos una lecci√≥n: al comenzar una gran tarea, reconcilie que habr√° errores. <br><br>  Despu√©s de eso, todo funcion√≥ sin problemas.  Desconectamos todas las instancias de Mongo de OpsManager y luego las desconectamos.  Lo √∫nico que quedaba por hacer era celebrar.  Y dormir </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436416/">https://habr.com/ru/post/es436416/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436400/index.html">Configure el entorno de desarrollo para aprender HTML, CSS, PHP en Windows</a></li>
<li><a href="../es436404/index.html">Equilibrio de tr√°fico VoIP tolerante a fallas. Cambio de carga entre centros de datos en la hora pico</a></li>
<li><a href="../es436406/index.html">C√≥mo convertirte en desarrollador de juegos si eres un agente de bienes ra√≠ces</a></li>
<li><a href="../es436408/index.html">Modelado num√©rico: la historia de un proyecto</a></li>
<li><a href="../es436412/index.html">Recorrido fotogr√°fico por la nueva oficina de Facebook de Boston</a></li>
<li><a href="../es436420/index.html">El vertedero m√°s grande de la historia: 2.700 millones de cuentas, de las cuales 773 millones son √∫nicas.</a></li>
<li><a href="../es436422/index.html">La imitaci√≥n no puede ser una estrategia de desarrollo de productos.</a></li>
<li><a href="../es436424/index.html">Peque√±as criaturas, grandes hechos: el papel de los cortadores de hojas en el efecto invernadero de los neotr√≥picos</a></li>
<li><a href="../es436426/index.html">Pausa la aplicaci√≥n si se pierde la conexi√≥n de red</a></li>
<li><a href="../es436428/index.html">¬øPor qu√© animamos a la programaci√≥n deportiva?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
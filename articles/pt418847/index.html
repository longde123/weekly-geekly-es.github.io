<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧑🏿‍🤝‍🧑🏻 🥑 🤢 Rede neural óptica 🧒🏿 🔉 🈳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Máscara de fase multicamada treinada (classificador de caracteres manuscritos). À direita, está um modelo físico de uma rede neural óptica D²NN impres...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Rede neural óptica</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/418847/"><img src="https://habrastorage.org/webt/m2/xq/tj/m2xqtjhmcoi7hwz757dfzhrhb-o.jpeg"><br>  <i><font color="gray">Máscara de fase multicamada treinada (classificador de caracteres manuscritos).</font></i>  <i><font color="gray">À direita, está um modelo físico de uma rede neural óptica D²NN impressa em uma impressora 3D: camadas 8 × 8 cm com uma distância de 3 cm entre si</font></i> <br><br>  Uma equipe de pesquisadores da Universidade da Califórnia em Los Angeles desenvolveu um novo tipo de rede neural que usa luz em vez de eletricidade para funcionar.  A revista Science publicou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo</a> descrevendo uma idéia, um dispositivo funcional, seu desempenho e tipos de aplicativos, que, segundo os autores, são bons para a computação em um novo tipo de rede neural. <br><br>  A Rede Neural Profunda Difrativa Profunda (D²NN), totalmente óptica, formada fisicamente a partir de uma variedade de superfícies refletivas ou transparentes.  Essas superfícies trabalham juntas, desempenhando uma função arbitrária, adquirida como resultado do treinamento.  Enquanto a obtenção do resultado e a previsão na rede física são organizadas de forma totalmente óptica, a parte do treinamento com o design da estrutura das superfícies refletivas é calculada em um computador. <br><a name="habracut"></a><br>  Portanto, no modelo físico, D²NN consiste em várias camadas reflexivas ou transparentes.  Nessas camadas, cada ponto transmite ou reflete uma onda de entrada.  Assim, este ponto é um neurônio artificial que está conectado aos neurônios das próximas camadas por difração óptica.  A estrutura de D²NN é mostrada na ilustração. <br><br><img src="https://habrastorage.org/webt/p8/ui/gd/p8uigdcnfuvebalr6mhjxseucxy.png"><br>  <i><font color="gray">Rede Neural Profunda Difrativa (D²NN).</font></i> <br><br>  Na ilustração A, um diagrama de várias camadas transparentes / reflexivas, em que cada ponto é um neurônio com um coeficiente complexo de transparência ou reflexão.  Esses coeficientes são derivados da aprendizagem profunda.  Após a fase de treinamento, o design do D²NN é fixo - e as placas correspondentes são impressas na impressora 3D, que calcula a função obtida como resultado do treinamento preliminar.  Ao contrário das redes eletrônicas de computadores, aqui os cálculos são realizados <b>à velocidade da luz</b> . <br><br>  Durante os experimentos, os cientistas treinaram e testaram experimentalmente vários tipos de D²NN.  A Figura B mostra o classificador de caracteres manuscritos e a Figura C mostra as lentes de imagem. <br><br>  A parte inferior da ilustração compara a operação da rede neural óptica difrativa (esquerda) e da rede neural eletrônica (direita).  Baseado em ondas coerentes, o D²NN opera com valores de entrada complexos e viés multiplicativo.  Os pesos em D²NN são baseados na difração de espaço livre e determinam a interferência coerente das ondas secundárias, que são a fase e / ou a amplitude modulada pelas camadas anteriores.  O símbolo "o" significa a operação do produto de Hadamard, isto é, multiplicação lógica bit a bit dos membros correspondentes de duas sequências de igual comprimento. <br><br>  Os pesquisadores explicam que a estrutura da rede neural óptica é organizada de acordo <b>com o princípio de Huygens</b> , segundo o qual cada elemento da frente de onda pode ser considerado como o centro da perturbação secundária que gera ondas esféricas secundárias, e o campo de luz resultante em cada ponto do espaço será determinado pela interferência dessas ondas.  Assim, o neurônio artificial em D²NN é conectado a outros neurônios da próxima camada através de uma onda secundária, que é modulada em amplitude e fase pelo padrão de interferência de entrada criado pelas camadas anteriores e pelo coeficiente local de transmissão / reflexão neste momento. <br><br>  Por analogia com as redes neurais profundas padrão, podemos considerar o coeficiente de transmissão / reflexão de cada ponto / neurônio como o termo multiplicativo “viés”, que é corrigido iterativamente durante o treinamento da rede de difração usando o método de erro de propagação traseira.  Após o treinamento numérico, o design do D2NN é fixo e os coeficientes de transmissão / reflexão dos neurônios de todas as camadas são determinados.  Em seguida, você pode fazer as camadas calculadas por qualquer método: impressão 3D, litografia etc. <br><br>  Os cientistas enfatizam que a rede neural óptica desempenha uma função na velocidade da luz e não precisa de energia.  Portanto, é uma maneira rápida e eficaz de implementar tarefas de aprendizado de máquina. <br><br>  Para testar a idéia, os pesquisadores criaram uma rede neural capaz de reconhecer números de zero a nove - e reportar o resultado.  Após o treinamento em 55.000 imagens de números, a rede neural impressa de sete camadas mostrou uma precisão de 93,39%. <br><br><img src="https://habrastorage.org/webt/ci/rf/0t/cirf0t6vh5lgkblbz3-pct4cw4i.png"><br><br>  Ao reconhecer roupas e sapatos da moda, uma rede neural de cinco camadas mostrou uma precisão de 81,13%, uma rede neural de dez camadas - 86,60%. <br><br><img src="https://habrastorage.org/webt/yh/2g/qv/yh2gqvdh5et99u1dype75pgfgvm.png"><br><br>  Segundo os pesquisadores, a rede neural do tipo óptico pode ser usada em dispositivos especializados que exigem alta velocidade, como determinar uma pessoa específica em uma multidão de pessoas em movimento. <br><br>  O artigo científico foi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publicado</a> em 26 de julho de 2018 na revista <i>Science</i> (doi: 10.1126 / science.aat8084, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt418847/">https://habr.com/ru/post/pt418847/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt418837/index.html">Vida na Alemanha através dos olhos de minha esposa</a></li>
<li><a href="../pt418839/index.html">Kivy - # 1 estrutura de desenvolvimento de plataforma cruzada</a></li>
<li><a href="../pt418841/index.html">20 estados estão tentando parar a distribuição de arquivos CAD da Internet para imprimir armas</a></li>
<li><a href="../pt418843/index.html">Produção Hell STALKER: Shadow of Chernobyl</a></li>
<li><a href="../pt418845/index.html">Como Roskomnadzor bloqueia o HideMy.name e o que acontecerá a seguir. Uma palavra para os fundadores do serviço VPN</a></li>
<li><a href="../pt418849/index.html">Resumo de eventos para profissionais de RH na área de TI em agosto de 2018</a></li>
<li><a href="../pt418851/index.html">Como comprar a ilusão de segurança na forma de relógios inteligentes para crianças</a></li>
<li><a href="../pt418853/index.html">Detalhes sobre a atualização de Testemunha Segregada e as consequências de sua adoção no Bitcoin</a></li>
<li><a href="../pt418855/index.html">Seminário on-line aberto “Criando um aplicativo no Webpack + React + Express”</a></li>
<li><a href="../pt418857/index.html">Preparando Certificados SSL para Instalação</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
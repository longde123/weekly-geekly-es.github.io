<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§öüèΩ üê¢ üêî Auf die Frage von TI üèáüèΩ üë¶ üìπ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄûJetzt zeige ich dir ein Portr√§t ... Hmm ... ich warne dich, dass dies ein Portr√§t ist ... Wie auch immer, bitte behandle ihn wie ein Portr√§t ... 

 I...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Auf die Frage von TI</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451918/">  <b>‚ÄûJetzt zeige ich dir ein Portr√§t ... Hmm ... ich warne dich, dass dies ein Portr√§t ist ... Wie auch immer, bitte behandle ihn wie ein Portr√§t ...</b> <br><br>  In diesem Beitrag werden wir √ºber die Entwicklung und das Debuggen von Programmen f√ºr den CC1350 MK in der vom Hersteller empfohlenen CCS-Entwicklungsumgebung sprechen.  Die Vorz√ºge (und sie sind) und die Nachteile (und wie ohne sie) der oben genannten Produkte werden beeinflusst.  Der Text enth√§lt keine Screenshots, die den Speicherort des Kompilierungssymbols in der integrierten Programmierumgebung oder die Auswahl einer Datei in einem Verzeichnis anzeigen (eingekreist).  Ich erkenne die grunds√§tzliche M√∂glichkeit von Artikeln in einem √§hnlichen Stil und werde versuchen, mich auf konzeptionelle Fragen zu konzentrieren, in der Hoffnung, dass mein Leser die Details herausfinden kann. <br><br>  Der Zweck dieses Opus ist neben dem Austausch der gesammelten Erfahrungen der Versuch, bei einheimischen MK-Herstellern, die direkte Konkurrenten von TI sind ("in dem Land, in dem wir gedeihen"), gesunden Neid zu erregen - die Aufgabe ist offen gesagt undankbar, aber sie sagen, dass ein Stein einen Tropfen abnutzt. <br><a name="habracut"></a><br>  Ich werde sofort betonen, dass es sich nur um Windows 7 (au√üerdem nur) Version 7 handeln wird, obwohl die TI-Website eine Option f√ºr Mac und Linux bietet. Ich habe sie nicht ausprobiert. Ich bin ziemlich bereit zu glauben, dass dort nicht alles so cool ist, aber warum sollte ich dar√ºber nachdenken? √ºber das Schlechte (oder umgekehrt, dort ist alles gro√üartig, aber warum dann Neid). <br><br>  Was lehrt uns die TI-Website? Um mit Evaluierungsmodulen arbeiten zu k√∂nnen, m√ºssen Sie drei notwendige Schritte ausf√ºhren: <br><br><ol><li>  Evaluierungsmodule kaufen - fertig. <br><br>  Hinweis zu den R√§ndern (PNP): Sie m√ºssen dies auch tun, da ich pers√∂nlich in der fraglichen Programmierumgebung (leider) nicht die M√∂glichkeit gefunden habe, Hardware f√ºr das Debuggen zu emulieren, zumindest dort, wo ich gesucht habe. </li><li>  Installieren Sie die Entwicklungsumgebung - laden Sie das Installationsprogramm herunter, f√ºhren Sie es aus, alles hat funktioniert.  Wir verbinden das Evaluierungsmodul mit USB - das Brennholz steigt von selbst auf und alles hat wieder geklappt - fertig.  Wenn Sie versuchen, das Ger√§t zu programmieren, erhalten wir eine Meldung √ºber die Notwendigkeit, die Firmware zu aktualisieren. Wir sind uns einig, und es hat sich erneut alles herausgestellt.  Im Allgemeinen gibt es nichts zu schreiben, wenn es immer und √ºberall war ... </li><li>  Gehen Sie und studieren Sie den Kurs TI SimpleLink Academy 3.10.01 f√ºr SimpleLink CC13x0 SDK 3.10 - ein seltsamer Vorschlag, den ich zu lehren scheint - nur um zu verderben, aber so sei es, ich √∂ffne den entsprechenden Link und bin fassungslos - wie viel ist da drin. </li></ol><br>  Hier finden Sie Schulungsunterlagen zur Arbeit mit SYS / BIOS-Hardwaretreibern und zum TI-RTOS-Betriebssystem sowie zur Verwendung des NDK-Netzwerkstapels, einschlie√ülich USB, und zur Verwendung von drahtlosen Protokollen und vielen weiteren Aspekten der Arbeit mit Vertretern verschiedener MK-Familien, die vom Unternehmen hergestellt wurden.  Und all dieser Reichtum wird von gebrauchsfertigen Beispielen begleitet, und wenn wir das Vorhandensein von Benutzerhandb√ºchern und Modulbeschreibungen ber√ºcksichtigen, gibt es vielleicht nichts mehr zu w√ºnschen.  Es gibt aber auch Dienstprogramme, die das Vorbereiten und Konfigurieren von Programmcode, das Flashen und Debuggen auf verschiedene Weise erleichtern, und diese F√ºlle ist auch gut dokumentiert. <br><br>  Pnp: Wenn jemand dazu neigt, dieses Material als Werbung in Bezug auf das Unternehmen, seine Produkte und sein Programmiersystem zu betrachten, dann wird es h√∂chstwahrscheinlich richtig sein und ich bin wirklich sehr beeindruckt von der Menge der erkannten Software.  Seine Qualit√§t wird weiter diskutiert und ich hoffe, mein Verdacht auf Voreingenommenheit wird zerstreut, ich war nicht v√∂llig geblendet von dem Gef√ºhl und ich sehe weiterhin perfekt die Fehler des Beschreibungsobjekts, so dass dies nicht die Liebe zur Jugend ist, sondern ein ernstes Gef√ºhl eines erwachsenen Spezialisten.  Ich habe Angst, mir die H√∂he der Materialkosten vorzustellen, die f√ºr die Erstellung und Wartung eines solchen Volumens an Software und Dokumentation erforderlich sind, aber dies wurde offensichtlich nicht in einem Monat erledigt, und das Unternehmen versteht wahrscheinlich, was es tut. <br><br>  Okay, bis wir das Studium der Materialien f√ºr sp√§ter verschieben, werden wir alles ‚Äûauf dem Weg mit dem Nugget‚Äú verstehen und CCS mutig √∂ffnen.  Es implementiert das Konzept der Arbeitsbereiche, die vom √ºbergeordneten Eclipse empfangen wurden.  Pers√∂nlich ist mir das Projektkonzept n√§her, aber niemand st√∂rt uns, genau ein Projekt im Raum zu halten, also lasst uns weitermachen. <br><br>  Aber dann wird es etwas schlimmer - wir √∂ffnen den Arbeitsbereich (RP) f√ºr unser Debugging-Board und sehen viele Projekte (in der Regel in zwei Versionen - unter RTOS und f√ºr ‚ÄûBare Iron‚Äú).  Wie ich bereits sagte, ist dies kein Verbrechen, aber die Tatsache, dass viele Projekte dieselben Dateien mit identischen Softwaremodulen enthalten, ist √ºberhaupt nicht gro√üartig.  Der Code wird viele Male dupliziert und unterst√ºtzende √Ñnderungen werden zu einer nicht trivialen Aufgabe.  Ja, mit einer solchen L√∂sung ist es viel einfacher, das Projekt durch einfaches Kopieren des Verzeichnisses zu √ºbertragen, aber f√ºr solche Dinge wird das Projekt exportiert und es ist recht gut implementiert.  Links zu Dateien im Projektbaum werden angemessen unterst√ºtzt, sodass die Entscheidung, die Dateien selbst in die bereitgestellten Beispiele aufzunehmen, nicht als zufriedenstellend angesehen werden kann. <br><br>  Wir setzen unsere Forschung fort - wir werden mit einem abgeschlossenen Projekt arbeiten, aber keine LED blinken lassen, obwohl sich zwei davon auf der Debug-Platine befinden, sondern mit einer seriellen Schnittstelle, einem vorgefertigten Uartecho-Beispiel.  Wir erstellen eine neue RP, nehmen das f√ºr uns interessante Projekt auf und ... nichts kommt dabei heraus. Aus der Nachricht geht hervor, dass es notwendig ist, ein verwandtes Projekt in die RP aufzunehmen.  Es ist nicht sehr klar, warum dies getan wird, aber es ist nicht schwierig, die Anforderungen der Umgebung zu erf√ºllen, wonach das Projekt mit der Montage beginnt. <br><br>  Pnp: Auf dem Heimcomputer habe ich den Befehl Projekt importieren verwendet, und alle erforderlichen Einschl√ºsse wurden von selbst vorgenommen.  Wo genau verwandte Projekte angegeben sind, wei√ü ich nicht, lassen wir die Analyse dieses Aspekts f√ºr die Zukunft. <br><br>  Wir kompilieren, flashen und beginnen mit dem Debuggen.  Wir finden ein interessantes Ph√§nomen - die schrittweise Ausf√ºhrung wird nicht angemessen angezeigt, wenn man die Bibliothek f√ºr die Arbeit mit einer seriellen Schnittstelle betrachtet - Optimierungskosten.  Wir deaktivieren die Optimierung in den Compiler-Einstellungen (welche Einstellungen sind nicht vorhanden, gibt es wirklich Leute, die sie alle kennen und dar√ºber hinaus alle verwenden), bauen das Projekt erneut zusammen - und nichts √§ndert sich.  Es stellt sich heraus, dass nur die Dateien enthalten sind, die im Projektbaum enthalten sind, zumindest in Form von Links.  Wir f√ºgen Links zu den Bibliotheksquellen hinzu und nach dem Wiederherstellen wird alles korrekt debuggt (vorausgesetzt, wir haben die Option, Debugging-Informationen zu generieren). <br><br>  Pnp: Ich habe jedoch Optionen gefunden, um die MISRA-C-Konformit√§tspr√ºfung zu aktivieren. <br><br>  Pnp: Eine andere M√∂glichkeit besteht darin, den Befehl "Clean ..." f√ºr die nachfolgende Assembly zu verwenden. Der Befehl "Build All" wirkt sich aus irgendeinem Grund nicht auf das zugeh√∂rige Projekt aus. <br><br>  Dann stellen wir fest, dass nicht immer alles normal debuggt wird. Manchmal befinden wir uns in Bereichen des Maschinencodes, f√ºr die der Compiler die Quelle nicht findet.  Da die Programmierumgebung uns alle f√ºr die Arbeit erforderlichen Dateien zur Verf√ºgung stellt - das Ergebnis des Pr√§prozessors, des Assembler-Codes und der Linkerkarte (Sie m√ºssen nur daran denken, die entsprechenden Optionen zu aktivieren), wenden wir uns letzterem zu.  Wir finden zwei Bereiche des Programmcodes - ab 0x0000.  und ab 0x1000.  (32-Bit-Architekturen sind f√ºr alle gut, aber das Schreiben von Adressen ist nicht ihre St√§rke).  Wir wenden uns der Dokumentation f√ºr die Mikroschaltung zu und stellen fest, dass sich im Inneren ein ROM-Bereich befindet, der speziell auf 0x1000 abgebildet ist. Er enth√§lt den integrierten Teil der Bibliotheken.  Es wird argumentiert, dass die Verwendung von Routinen daraus die Leistung verbessert und den Verbrauch im Vergleich zum 0x000-Adressraum reduziert.  W√§hrend wir MK beherrschen, sind wir nicht so an den letzten Parametern interessiert, aber die Bequemlichkeit des Debuggens ist entscheidend.  Sie k√∂nnen die Verwendung von ROM deaktivieren (jedoch f√ºr unsere Zwecke), indem Sie die Option NO_ROM auf den Compiler setzen, was wir tun und das Projekt neu zusammensetzen. <br><br>  PNP: Der √úbergang zur Subroutine im ROM sieht sehr lustig aus - es gibt keinen langen √úbergang im Befehlssystem, daher erfolgt der √úbergang zun√§chst mit einer R√ºckkehr zum Zwischenpunkt im unteren Adressbereich (0x0000), und dort liegt bereits der PC-Startbefehl, dessen Parameter vom Disassembler nicht erkannt werden.  Etwas, das ich nicht glauben kann, als ob man mit solchen Gemeinkosten an Geschwindigkeit gewinnen kann, obwohl f√ºr lange Routinen - warum nicht. <br><br>  Eine interessante Frage ist √ºbrigens, wie im Allgemeinen garantiert wird, dass der Inhalt des ROM den vom Unternehmen freundlicherweise zur Verf√ºgung gestellten Quellcodes entspricht.  Ich kann sofort einen Mechanismus zum Einbetten zus√§tzlicher (nat√ºrlich Debugging- und Service-) Funktionen in das ROM vorschlagen, der f√ºr den Benutzer - MK-Programmierer - v√∂llig unsichtbar ist.  Und ich pers√∂nlich habe keinen Zweifel daran, dass die Entwickler des Chips auch viele andere Mechanismen kennen, die solche Funktionen implementieren, aber wir werden den Angriff der Paranoia beenden. <br><br>  Andererseits kann ich das Erscheinen eines solchen Analogons des BIOS nur begr√º√üen, da dies auf lange Sicht den Traum der Entwickler von einer echten Portabilit√§t von Code zwischen verschiedenen MK-Familien mit einem Kern Wirklichkeit werden l√§sst.  Wir stellen auch die Besonderheit der Implementierung der Interaktion mit "eingebetteten" Softwaremodulen fest.  Wenn in fr√ºhen Versuchen, einen √§hnlichen Mechanismus zu erstellen, der in TivaC-Modellen implementiert ist, ein Anruf-Supervisor mit der Gruppennummer und der Nummer des Einstiegspunkts in das Unterprogramm aufgerufen wurde, was einen erheblichen Overhead verursachte, liegt die Aufl√∂sung der Kommunikation aufgrund doppelter Namen von Funktionen und auf Linker-Ebene Direkte Weitspr√ºnge zu Unterprogrammen im ROM werden eingef√ºgt.  Dies ist viel schneller in der Ausf√ºhrung, erfordert jedoch eine Neukompilierung des Projekts, wenn das Nutzungsmodell ge√§ndert wird. <br><br>  Nachdem wir uns auf das bequeme Debuggen vorbereitet haben, kehren wir zu unserem Projekt zur√ºck und beginnen, das Programm mit Zugriff auf die Quellcodes der Module leise zu debuggen (nun, das habe ich mir gedacht ...), um uns eine Meinung √ºber die Qualit√§t dieser Texte zu bilden.  Das untersuchte Projekt implementiert einen Spiegel des seriellen Kommunikationskanals und ist f√ºr Schulungszwecke √§u√üerst praktisch.  Nat√ºrlich haben wir die Option mit RTOS gew√§hlt, ich sehe nicht den geringsten Grund, sie in unserer Konfiguration nicht zu verwenden (viel Speicher und Programmspeicher). <br><br>  Wir stellen sofort fest, dass die Quellcodes in C dargestellt werden. Dies ist oft nicht sehr praktisch. Viele Sprachkonstrukte sehen im Vergleich zu ihren Analoga auf den Pluspunkten umst√§ndlich aus, aber die Entwickler waren mehr an der Codekompatibilit√§t als an syntaktischem Zucker interessiert.  Obwohl es m√∂glich w√§re, eine C ++ - Version von Bibliotheken zu erstellen, ist die bedingte Kompilierung seit langem bekannt und wird √ºberall verwendet, was jedoch zus√§tzliche Materialkosten mit sich bringt.  Sicher wei√ü das Management des Unternehmens, was es tut, und meine Kommentare sind eine Art "gerissene Analyse", aber es scheint mir, dass ich auch das Recht auf meine Meinung habe. <br><br>  Ich kenne auch den umgekehrten Ansatz, wenn die Bibliothek mit den neuesten C ++ - Tools erstellt wird und wenn gefragt wird, was f√ºr Entwickler zu tun ist, die Compiler verwenden, die nicht den neuesten Spezifikationen entsprechen, ist die perfekte Antwort, auf neue Versionen zu aktualisieren oder nicht diese Bibliothek (ich empfehle dringend die zweite Option in solchen F√§llen).  Meine pers√∂nliche Meinung ist, dass wenn wir wirklich wollen, dass unser Produkt verwendet wird (und TI es eindeutig will und die Bibliothek nicht nach dem Prinzip "Lass es mich fallen, hier ist eine neue Trommel f√ºr dich" erstellt wird), sein Ansatz sicherlich wahr ist. <br><br>  Der Quellcode des Programms sieht klassisch aus: Initialisieren der Hardware- und Softwareumgebung, Erstellen von Aufgaben und Starten eines Shedulers im Hauptmodul, der Aufgabentext in einem separaten Kompilierungsmodul.  In dem betrachteten Beispiel ist die Aufgabe genau eine - mainThread, der Zweck ist aus dem Namen nicht ganz klar, und auch, was mich etwas verwirrt - der Name der Datei, die den Quelltext enth√§lt, stimmt nicht mit dem Namen der Funktion √ºberein (uartecho.c - obwohl der Name hier spricht) gut ja Die Suche in der Programmierumgebung wird auf standardm√§√üige Weise implementiert (Kontextmen√º oder F3 f√ºr den Entit√§tsnamen), und dies ist kein Problem. <br><br>  Das Festlegen der Aufgabenparameter vor dem Start wird erwartet: <br><br><ol><li>  eine Parameterstruktur erstellen (nat√ºrlich lokal), </li><li>  gib ihm Standardwerte, </li><li>  andere als die Standardparameter einstellen und </li><li>  Verwenden Sie die Struktur beim Erstellen der Aufgabe. </li></ol><br>  Trotz der Art der Nat√ºrlichkeit dieser Operationen ist dies nicht f√ºr alle Bibliotheksautoren offensichtlich, und ich habe verschiedene Implementierungen gesehen, bei denen es zum Beispiel keine Stufe 2 gab, die zu einem lustigen (f√ºr einen externen Beobachter, nicht f√ºr einen Programmierer) Programmverhalten f√ºhrte.  In diesem Fall ist alles in Ordnung. Die einzige Frage, die sich gestellt hat, ist, warum die Standardwerte nicht konstant sind. Wahrscheinlich ist dies ein Erbe der verdammten Vergangenheit. <br><br>  PNP: Im bekannten FREE-RTOS wird ein etwas anderer Ansatz gew√§hlt, wobei die Aufgabenparameter direkt im Hauptteil des Aufrufs der API der Aufgabenerstellungsfunktion angegeben sind.  Die Vor- und Nachteile dieser Ans√§tze sind wie folgt: <br><br><ol><li>  + erm√∂glicht es Ihnen, Parameter, die mit den Standardwerten √ºbereinstimmen, nicht explizit anzugeben, + erfordert nicht, sich die Reihenfolge der Parameter zu merken, - ausf√ºhrlicher, - gr√∂√üere Speicherkosten, - Sie m√ºssen die Standardparameter kennen, - erstellt ein benanntes Zwischenobjekt </li><li>  - erfordert die Angabe aller Parameter, - erfordert das Speichern der Reihenfolge der Parameter, + ist kompakter, + erfordert weniger Speicher, + erfordert keine benannten Zwischenobjekte. <br><br>  Es gibt eine dritte Methode, die vom Autor dieses Beitrags empfohlen wird (im Stil von TURBO) und die √ºber einen eigenen Satz verf√ºgt </li><li>  + erm√∂glicht es Ihnen, Parameter, die dem Standard entsprechen, nicht explizit anzugeben, + erfordert nicht, sich die Reihenfolge der Parameter zu merken, -multi-verbal, -gro√üere Speicherkosten, -Sie m√ºssen die Standardparameter kennen, + arbeitet im Lambda-Stil, + macht Standardfehler schwierig zu implementieren, -sicht etwas seltsam wegen der vielen rechten Klammern. </li></ol><br>  Nun, es gibt eine weitere vierte Option, die keine Nachteile aufweist, aber C ++ von mindestens 14 erfordert - wir lecken uns die Lippen und gehen vorbei. <br><br>  Wir starten das Debuggen, f√ºhren das Programm aus und √∂ffnen eine der beiden seriellen Schnittstellen, die von der Debugging-Karte bereitgestellt werden, im Terminalfenster, das von der Programmierumgebung bereitgestellt wird.  Welcher der beiden Ports (einer debuggt, wahrscheinlich der zweite ist Benutzer, Sie k√∂nnen ihre Nummern im System sehen) ist im Voraus schwer zu erkennen, manchmal der j√ºngste, manchmal der √§ltere, zumindest √§ndert sich nichts, wenn Sie die Karte wieder anschlie√üen, sodass Sie ihn auf die Karte schreiben k√∂nnen.  Noch eine Unannehmlichkeit: Offene Terminals werden nicht mit dem Projekt gespeichert und beim √ñffnen einer Debugging-Sitzung nicht wiederhergestellt, obwohl sie beim Beenden nicht geschlossen werden.  Wir √ºberpr√ºfen die Funktionsweise des Programms und stellen sofort einen weiteren Nachteil fest: Das Terminal kann nicht konfiguriert werden. Beispielsweise funktioniert es im Unix-Stil mit einem Closing / r. Ich habe den Kontakt zu einem solchen Minimalismus verloren, obwohl uns niemand mit der Verwendung eines externen Terminalprogramms st√∂rt. <br><br>  Pnp: Wir stellen eine weitere Funktion des Debuggens fest. Dies gilt f√ºr jede Entwicklungsumgebung. Wenn wir Aufgaben mit einem Sheduler wechseln, verlieren wir den Fokus. Haltepunkte helfen uns, dieses Problem zu l√∂sen. <br><br>  Betrachten Sie zun√§chst den Prozess des Erstellens einer Instanz einer seriellen Schnittstelle - hier scheint alles Standard zu sein, es wird eine Struktur verwendet, deren Feldern die erforderlichen Parameter des Objekts zugewiesen sind.  Beachten Sie, dass wir bei den Profis, die in C v√∂llig abwesend sind, die M√∂glichkeit haben, alle Initialisierungen ‚Äûunter der Haube‚Äú vollst√§ndig zu verbergen, aber ich habe bereits m√∂gliche Argumente f√ºr die zweite L√∂sung vorgebracht.  Es gibt eine Funktion zum Initialisieren der Optimierungsstruktur, und diese ist gut (paradoxerweise klingt diese Funktion f√ºr die Autoren einiger Bibliotheken nicht obligatorisch).  An diesem Punkt der Geschichte enden die Flitterwochen und das gew√∂hnliche <strike>(eheliche)</strike> Leben beginnt. <br><br>  Eine sorgf√§ltige Untersuchung der Quellen zeigt, dass nicht alles so gut ist.  Was ist das Problem - die Initialisierungsfunktion kopiert die Standardwerte von dem Objekt, das im konstanten Bereich liegt, in unsere Kontrollstruktur, und das ist wunderbar, aber aus irgendeinem Grund: <br><br><ol><li>  Das Objekt ist global, obwohl es von der einzigen Funktion zum Initialisieren der Parameter verwendet wird (zu einem Zeitpunkt kostete eine √§hnliche Vorgehensweise Toyota einen angemessenen Betrag). Nun, das Hinzuf√ºgen der statischen Anweisung ist einfach. </li><li>  Das Steuerobjekt hei√üt, in C gibt es keine sch√∂ne L√∂sung f√ºr dieses Problem, oder besser gesagt, es gibt eine L√∂sung mit einer anonymen Kopie, und ich habe es in einem langen Post gegeben, aber viele rechte Klammern erlauben es nicht, diese Option wirklich sch√∂n zu nennen, in Plus gibt es eine L√∂sung von unglaublicher Sch√∂nheit, aber was von einem Wunschtraum tr√§umen; </li><li>  Alle Felder des Objekts sind in der Bittiefe eindeutig redundant, sogar Bitfelder (Aufz√§hlungen von zwei m√∂glichen Werten) werden in 32-Bit-W√∂rtern gespeichert. </li><li>  Aufz√§hlungsmoduskonstanten werden in Form von Definitionen definiert, was eine √úberpr√ºfung in der Kompilierungsphase unm√∂glich und zur Laufzeit erforderlich macht. </li><li>  Wenn Sie einen Abschnitt einer Endlosschleife an verschiedenen Stellen m√∂glicher Fehler wiederholen, ist es viel korrekter, einen (in diesem Fall leeren) Handler zu erstellen. </li><li>  Nun, alle Operationen zum Einrichten und Starten einer Aufgabe k√∂nnen (und sollten) in einer Funktion oder sogar einem Makro versteckt sein. </li></ol><br>  Aber die Initialisierung des Empfangspuffers ist gut gemacht - wir verwenden vorreservierten Speicher, keine Manipulation des Heaps, die Aufrufkette ist etwas kompliziert, aber alles ist lesbar. <br><br>  Pnp: Im Debug-Fenster, vor unseren Augen, dem Call-Stack, wird alles so gemacht, wie es sollte und solide - Respekt und Respekt.  Das einzige, was etwas √ºberraschend ist, ist der Versuch, dieses Fenster auszublenden, der zum Ende der Debugging-Sitzung f√ºhrt. <br><br>  Nun, und noch eine etwas unerwartete Entscheidung: Setzen Sie die m√∂gliche Anzahl von Objekten in der Aufz√§hlung f√ºr serielle Ports und f√ºr diese Debug-Karte im Stil auf 1 <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-keyword"><span class="hljs-keyword">enum</span></span> CC1310_LAUNCHXL_UARTName { CC1310_LAUNCHXL_UART0 = <span class="hljs-number"><span class="hljs-number">0</span></span>, CC1310_LAUNCHXL_UARTCOUNT } CC1310_LAUNCHXL_UARTName;</code> </pre> <br>  Solche L√∂sungen sind Standard f√ºr echte √úbertragungen, aber f√ºr die Beschreibung von Hardwareobjekten - und ich wusste nicht, dass dies m√∂glich ist, obwohl es f√ºr mich selbst funktioniert.  Wir haben die Initialisierung von Eisen abgeschlossen, fahren wir fort. <br><br>  In einer laufenden Aufgabe beobachten wir eine klassische Endlosschleife, in der Daten von einer seriellen Schnittstelle von der Funktion gelesen werden <pre> <code class="cpp hljs">UART_read(uart, &amp;input, <span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre>  und sofort per Funktion zur√ºckgeschickt <pre> <code class="cpp hljs">UART_write(uart, &amp;input, <span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre>  .  Gehen wir zum ersten und sehen uns einen Versuch an, Zeichen aus dem Empfangspuffer zu lesen <pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (handle-&gt;fxnTablePtr-&gt;readPollingFxn(handle, buffer, size))</code> </pre>  (Wie hasse ich solche Dinge, aber in C ist es sonst einfach unm√∂glich), gehen wir tiefer und finden uns in UARTCC26XX_read wieder, und von dort aus gelangen wir zur Implementierung des Ringpuffers - einer Funktion <pre> <code class="cpp hljs">RingBuf_get(&amp;object-&gt;ringBuffer, &amp;readIn)</code> </pre>  .  Hier geht das gew√∂hnliche Leben in eine akute Phase. <br><br>  Ich wollte nicht sagen, dass mir dieses spezielle Modul (ringbuf.c-Datei) nicht gefallen hat, es wurde einfach schrecklich geschrieben und ich pers√∂nlich h√§tte den Platz einer so angesehenen Gruppe von Autoren dieses Teils mit Scham rausgeschmissen (Sie k√∂nnen mich immer noch an ihre Stelle setzen, aber ich f√ºrchte dass das Gehaltsniveau unserer indischen Kollegen nicht zu mir passt), aber ich wei√ü wahrscheinlich nicht was.  Pass auf deine H√§nde auf: <br><br>  1) Das erneute Rollen von Lese- / Schreibzeigern wird durch den Rest der Division implementiert <br><br><pre> <code class="cpp hljs">object-&gt;tail = (object-&gt;tail + <span class="hljs-number"><span class="hljs-number">1</span></span>) % object-&gt;length;</code> </pre> <br>  und es gibt keine Optimierungen des Compilers, wenn diese Operation ausgef√ºhrt wird, wie beispielsweise das √úberlagern einer Bitmaske, da die L√§nge des Puffers keine Konstante ist.  Ja, in diesem MK gibt es eine Hardware-Teilungsoperation und sie ist ziemlich schnell (ich habe dar√ºber geschrieben), aber es dauert immer noch nie 2 Taktzyklen, wie bei der korrekten Implementierung mit ehrlichem Re-Roll (und ich habe auch dar√ºber geschrieben). <br><br>  Pnp: Ich habe k√ºrzlich eine Beschreibung der neuen M7-Architektur in der Implementierung gesehen und kann mich an niemanden erinnern. Aus irgendeinem Grund wurde das Teilen von 32 durch 32 in 2-12 Zyklen statt in 2-7 Zyklen durchgef√ºhrt.  Entweder handelt es sich um einen √úbersetzungsfehler, oder ... ich wei√ü nicht einmal, woran ich denken soll. <br><br>  2) Dar√ºber hinaus wird dieses Codefragment an mehr als einer Stelle wiederholt - Makros und Inlines f√ºr Weicheier, Strg + C und Strg + V-Regel, das DRY-Prinzip geht durch den Wald, <br><br>  3) ein vollst√§ndig redundanter Z√§hler von gef√ºllten Pufferpl√§tzen wurde implementiert, was den folgenden Nachteil mit sich brachte: <br><br>  4) kritische Abschnitte beim Lesen und Schreiben.  Nun, ich kann immer noch glauben, dass die Autoren dieses Moduls meine Beitr√§ge zu Habr√© nicht lesen (obwohl dieses Verhalten f√ºr Fachleute auf dem Gebiet der Firmware nicht akzeptabel ist), aber sie sollten mit dem Mustang-Buch vertraut sein, da dieses Problem im Detail untersucht wird. <br><br>  5) Wie eine Kirsche auf dem Kuchen wurde au√üerdem ein Indikator f√ºr die maximale Puffergr√∂√üe mit einem sehr verschwommenen Namen und einer vollst√§ndig fehlenden Beschreibung eingef√ºhrt (letzteres gilt allgemein f√ºr das gesamte Modul).  Ich schlie√üe nicht aus, dass diese Option f√ºr das Debuggen n√ºtzlich sein kann, aber warum sollte sie in die Version gezogen werden? Haben wir √ºberhaupt Prozessorzyklen mit dem RAM? <br><br>  6) Gleichzeitig fehlt die Puffer√ºberlaufverarbeitung vollst√§ndig (es gibt eine -1-R√ºckmeldung √ºber diese Situation) - selbst in Arduino werden wir die Qualit√§t dieser Verarbeitung au√üer Acht lassen, aber ihre Abwesenheit ist noch schlimmer.  Oder waren die Autoren von der bekannten Tatsache inspiriert, dass Annahmen bez√ºglich einer relativ leeren Menge zutreffen, einschlie√ülich der Tatsache, dass sie nicht leer ist? <br><br>  Im Allgemeinen stimmen meine Kommentare vollst√§ndig mit der ersten Zeile des Demotivators zum Thema Code√ºberpr√ºfung "10 Codezeilen - 10 Kommentare" √ºberein. <br><br>  Das vorletzte der festgestellten M√§ngel l√§sst uns √ºbrigens √ºber globalere Dinge nachdenken - aber wie implementieren wir die Basisklasse √ºberhaupt, um ihre tiefgreifende Modifikation durchf√ºhren zu k√∂nnen.  Alle Felder sicher zu machen, ist eine zweifelhafte Idee (obwohl wahrscheinlich die einzig richtige). Einen Aufruf freundlicher Funktionen in die Erben einzuf√ºgen, ist Kr√ºcken sehr √§hnlich.  Wenn es in diesem speziellen Fall eine einfache Antwort auf die Frage gibt, einen Indikator f√ºr die Pufferf√ºlle einzuf√ºhren - eine generierte Klasse mit √ºberlappendem Schreiben und Lesen und einem zus√§tzlichen Z√§hler -, dann das Lesen zu implementieren, ohne den Puffer vorzur√ºcken (wie in diesem Fall) oder das zuletzt platzierte Zeichen zu ersetzen (ich habe z Ringpuffer-Implementierung) Sie k√∂nnen nicht auf den Zugriff auf die internen Daten der √ºbergeordneten Klasse verzichten. <br><br>  Gleichzeitig gibt es keine Beschwerden √ºber die Implementierung des tats√§chlichen Lesens von der seriellen Schnittstelle - die Eingabe blockiert, wenn nicht gen√ºgend Zeichen im Empfangspuffer vorhanden sind, wird ein Semaphor gespannt und die Steuerung wird an den Sheduler √ºbertragen - alles wird genau und korrekt implementiert.  Pers√∂nlich mag ich es nicht wirklich, die Ausr√ºstung in einem Allzweckverfahren zu steuern, aber dies verringert die Verschachtelung von Verfahren und verringert den Index der zyklomatischen Komplexit√§t, unabh√§ngig davon, was dies bedeutet. <br><br>  Achten wir nun auf die √úbertragung der empfangenen Daten an den seriellen Kanal, da beim Erstellen des Objekts nur ein Ringpuffer vorhanden war - der empfangende.  In der Tat wird der interne Puffer der Hardware zum √úbertragen von Zeichen verwendet, und wenn er gef√ºllt ist, wird das Warten auf die Bereitschaft eingegeben (zumindest im blockierenden Betriebsmodus).  Ich kann mir nicht helfen, um den Stil der entsprechenden Funktionen nicht zu kritisieren: 1) Aus irgendeinem Grund verf√ºgt das Objekt √ºber einen verallgemeinerten Zeiger, der sich innerhalb der Funktion st√§ndig in einen Zeiger auf Zeichen verwandelt <pre> <code class="cpp hljs">*(<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">char</span></span> *)object-&gt;writeBuf);</code> </pre>  2) Die Logik der Arbeit ist v√∂llig undurchsichtig und leicht verwirrt.  Dies alles ist jedoch nicht so wichtig, da es dem Benutzer verborgen bleibt und "die maximale Geschwindigkeit nicht beeinflusst". <br><br>  W√§hrend der Recherche sto√üen wir auf eine weitere Funktion - wir sehen den Quellcode einiger interner Funktionen im Debug-Modus nicht - dies ist auf eine Namens√§nderung f√ºr verschiedene Kompilierungsoptionen (ROM / NO_ROM) zur√ºckzuf√ºhren.  Ersetzen Sie die erforderliche Quelldatei (C: \ Jenkins \ jobs \ FWGroup-DriverLib \ workspace \ modules \ output \ cc13xx_cha_2_0_ext \ driverlib \ bin \ ccs /./../../../ driverlib / uart.c--) Ich habe versagt (aber ich habe es nicht wirklich versucht), obwohl ich die Quelle gefunden habe (nat√ºrlich in der Datei in der Datei uart.c, danke, Captain). Gl√ºcklicherweise ist dieses Fragment einfach und es ist einfach, den Assembler-Code mit dem Quellcode in C zu identifizieren (vor allem, wenn Sie die Funktionen des ITxxx-Teams kennen).  Ich wei√ü nicht, wie ich dieses Problem f√ºr Bibliotheken mit komplexen Funktionen l√∂sen soll. Wir werden √ºberlegen, wann dies erforderlich ist. <br><br>  Und schlie√ülich eine kleine Bemerkung: Ich bin bereit zu glauben, dass die Hardware der seriellen Kanalimplementierung f√ºr MK CC13x0-Modelle dieselbe ist wie die f√ºr CC26x0, und das Duplizieren des Inhalts einer Datei mit dem Namen UARTCC26XX.c --- kann nicht als die richtige L√∂sung bezeichnet werden, sondern das Erstellen einer Zwischendefinitionsdatei mit Einbeziehung Ich w√ºrde die Quelldatei begr√º√üen, die Funktionen und den entsprechenden Kommentar √ºberschreiben, da dies das Programm verst√§ndlicher machen w√ºrde, und dies sollte immer willkommen sein, vout. <br><br>  W√§hrend der Testfall funktioniert, haben wir viel √ºber die interne Struktur von Standardbibliotheken gelernt, ihre St√§rken und nicht so guten Seiten festgestellt. Zum Abschluss der √úberpr√ºfung werden wir versuchen, die Antwort auf die Frage zu finden, die dem Programmierer normalerweise im Dilemma ‚ÄûBetriebssystem oder nicht Betriebssystem‚Äú - Kontextwechselzeit - wichtig ist.  Hier sind zwei M√∂glichkeiten m√∂glich: 1) Die Betrachtung des Quellcodes ist eher eine theoretische Methode, erfordert ein gewisses Ma√ü an Eintauchen in das Thema, das ich nicht demonstrieren m√∂chte, und 2) ein praktisches Experiment.  Nat√ºrlich liefert die zweite Methode im Gegensatz zur ersten keine absolut korrekten Ergebnisse, aber ‚Äûdie Wahrheit ist immer konkret‚Äú und die erhaltenen Daten k√∂nnen als angemessen angesehen werden, wenn die Messungen korrekt organisiert sind. <br><br>  Um die Schaltzeit abzusch√§tzen, m√ºssen wir zun√§chst lernen, wie die Gesamtausf√ºhrungszeit verschiedener Programmfragmente bewertet wird.  In dieser Architektur gibt es ein Debugging-Modul, zu dem auch ein Systemz√§hler geh√∂rt.  Informationen √ºber dieses Modul sind leicht zug√§nglich, aber der Teufel versteckt sich wie immer im Detail.  Versuchen wir zun√§chst, den erforderlichen Modus mit den Handles direkt √ºber den Zugriff auf die Register zu konfigurieren.  Wir finden schnell den Registerblock CPU_DWT und darin finden wir sowohl den CYCCNT-Z√§hler selbst als auch das Steuerregister daf√ºr CTRL mit dem CYCCNTENA-Bit.  Nat√ºrlich, oder wie sie sagen, ist nat√ºrlich nichts passiert und die ARM-Website hat eine Antwort auf die Frage, warum - es ist notwendig, das Debugging-Modul mit dem TRCENA-Bit im DEMCR-Register zu aktivieren.  Aber das letzte Register ist nicht so einfach - im DWT-Block ist es nicht vorhanden, in anderen Bl√∂cken ist die Suche faul - sie sind ziemlich lang, aber ich habe keine Suche nach Namen im Registerfenster gefunden (aber es w√§re sch√∂n, sie zu haben).  Wir gehen in das Speicherfenster, geben die Adresse des Registers ein (sie ist uns seit dem Datum bekannt) (aus irgendeinem Grund ist das hexadezimale Format der Adresse nicht standardm√§√üig, Sie m√ºssen das Pr√§fix 0x mit Stiften hinzuf√ºgen) und pl√∂tzlich sehen wir eine benannte Speicherzelle mit dem Namen CPU_CSC_DEMCR.  Es ist, gelinde gesagt, lustig, warum das Unternehmen die Register im Vergleich zu den vom Lizenzgeber der Architektur vorgeschlagenen Namen umbenannt hat, wahrscheinlich war es notwendig.  Und genau, im Registerblock CPU_CSC finden wir unser Register, setzen das gew√ºnschte Bit darin, kehren zum Z√§hler zur√ºck, aktivieren es und alles hat funktioniert. <br><br>  Pnp: Es gibt immer noch eine Suche nach Namen, sie wird (nat√ºrlich) von der Strg-F-Kombination aufgerufen, sie existiert nur im Kontextmen√º, aber in der √ºblichen wird sie abgebrochen, ich entschuldige mich bei den Entwicklern. <br><br>  Sofort stelle ich einen weiteren Nachteil des Speicherfensters fest - das Drucken des Inhalts wird durch Angabe der benannten Zellen unterbrochen, wodurch die Ausgabe zerrissen und nicht in 16 (8.32.64, ersetzen Sie die erforderlichen) W√∂rter unterteilt wird.  Dar√ºber hinaus √§ndert sich das Ausgabeformat, wenn die Fenstergr√∂√üe ge√§ndert wird.  M√∂glicherweise kann dies alles nach Bedarf des Benutzers konfiguriert werden, aber basierend auf meiner eigenen Erfahrung (und was ich sonst noch tun sollte) erkl√§re ich, dass das Festlegen des Ausgabeformats des Speicheranzeigefensters nicht f√ºr intuitiv offensichtliche L√∂sungen gilt.  Ich bin voll und ganz daf√ºr, eine so praktische Funktion wie das Anzeigen benannter Speicherbereiche im Anzeigefenster zu aktivieren, da sonst viele Benutzer nie davon erfahren w√ºrden, aber auch diejenigen, die es bewusst deaktivieren m√∂chten, m√ºssen vorsichtig sein. <br><br>  √úbrigens w√ºrde ich die M√∂glichkeit, Makros (oder Skripte) f√ºr die Arbeit mit der Umgebung zu erstellen, nicht ganz aufgeben, da ich diese Registereinstellung (um die Zeitmessung zu aktivieren) jedes Mal nach dem Zur√ºcksetzen des MK vornehmen musste, da ich die Codekorrektur durch Einf√ºgen von Registermanipulationen f√ºr Debugging-Zwecke in Betracht ziehe nicht sehr richtig.  Obwohl ich nie Makros gefunden habe, kann die Arbeit mit Registern erheblich vereinfacht werden, da einzelne (notwendige) Register in das Ausdrucksfenster aufgenommen werden k√∂nnen, wodurch die Arbeit mit ihnen erheblich erleichtert und beschleunigt wird. <br><br>  Um zu betonen, dass sich das Gef√ºhl des Ingenieurs f√ºr die MK-Familie nicht abgek√ºhlt hat (ansonsten schimpfe ich mit verschiedenen Aspekten der Entwicklungsumgebung), stelle ich fest, dass der Z√§hler einwandfrei funktioniert - ich konnte in keinem der Debug-Modi zus√§tzliche Zyklen finden, aber bevor dies geschah zumindest in der MK-Serie von LuminaryMicro entwickelt werden. <br><br>  Wir skizzieren also den Versuchsplan zur Bestimmung der Kontextwechselzeit - erstellen Sie eine zweite Aufgabe, die einen bestimmten internen Z√§hler (in einer Endlosschleife) inkrementiert, den MC f√ºr eine bestimmte Zeit startet und die Beziehung zwischen dem Systemz√§hler und dem Aufgabenz√§hler ermittelt.  Starten Sie als N√§chstes den MK f√ºr eine √§hnliche Zeit (nicht unbedingt genau gleich) und geben Sie ungef√§hr einmal pro Sekunde 10 Zeichen in einem Tempo ein.  Es ist zu erwarten, dass dies dazu f√ºhrt, dass 10 zur Echo-Task und 10 zur√ºck zur Z√§hler-Task geschaltet werden.  Ja, diese Kontextwechsel werden nicht gem√§√ü dem Sheduler-Timer, sondern je nach Ereignis ausgef√ºhrt. Dies sollte jedoch keinen Einfluss auf die Gesamtausf√ºhrungszeit der untersuchten Funktion haben. Daher beginnen wir mit der Implementierung des Plans, erstellen die Z√§hleraufgabe und starten sie. <br><br>  Hier finden wir eine Funktion von RTOS, zumindest in der Standardkonfiguration - es verdr√§ngt sich nicht "f√ºr echt": Wenn die Priorit√§tsaufgabe st√§ndig zur Ausf√ºhrung bereit ist (und die Gegenaufgabe ist dies) und dem Sheduler keine Kontrolle gibt (keine Signale erwartet, nicht einschlafen, nicht durch Flags usw. blockiert), dann wird √ºberhaupt keine einzige Aufgabe mit niedrigerer Priorit√§t aus dem Wort ausgef√ºhrt.  Dies ist nicht Linux, bei dem verschiedene Methoden verwendet werden, um sicherzustellen, dass jeder ein Quantum erh√§lt, "damit niemand beleidigt wird".  Dieses Verhalten ist zu erwarten, viele leichte RTOS verhalten sich so, aber das Problem ist tiefer, da das Management keine Aufgaben mit gleicher Priorit√§t wie eine st√§ndig vorbereitete erh√§lt.  Aus diesem Grund habe ich in diesem Beispiel die Echo-Task angehalten, die angehalten ist. Die Priorit√§t ist h√∂her als die st√§ndig bereitgestellte Z√§hler-Task. Andernfalls erfasst diese alle Prozessorressourcen rechtzeitig. <br><br>  Wir beginnen das Experiment, der erste Teil (der nur auf die Ausf√ºhrungszeit wartet) gab die Daten zum Verh√§ltnis der Z√§hler 406181 / 58015 = 7 an - es wird durchaus erwartet.  Der zweite Teil (mit 10 aufeinanderfolgenden Zeichen f√ºr ~ 10 Sekunden) liefert die Ergebnisse 351234k-50167k * 7 = 63k / 20 = 3160 Zyklen, die letzte Ziffer ist die Zeit, die mit der Kontextumschaltprozedur in MK-Zyklen verbunden ist.  Pers√∂nlich scheint mir dieser Wert etwas gr√∂√üer zu sein als erwartet, wir forschen weiter, es scheint, dass es noch einige Aktionen gibt, die die Statistik verderben. <br><br>  PNP: Ein h√§ufiger Fehler eines Experimentators besteht darin, die zuvor erwarteten Ergebnisse nicht zu bewerten und an den empfangenen M√ºll zu glauben (bis zu 737 Entwickler). <br><br>  Es ist offensichtlich (‚Äûja, ganz offensichtlich‚Äú), dass das Ergebnis neben der eigentlichen Kontextumschaltung auch die Zeit enth√§lt, die erforderlich ist, um die Vorg√§nge zum Lesen eines Zeichens aus dem Puffer und zum Ausgeben an die serielle Schnittstelle auszuf√ºhren.  Weniger offensichtlich ist, dass es auch die Zeit hat, einen Interrupt beim Empfang zu verarbeiten und das Zeichen in den Empfangspuffer zu legen.  Wie k√∂nnen wir eine Katze von Fleisch trennen - daf√ºr haben wir einen kniffligen Trick - wir stoppen das Programm, geben 10 Zeichen ein und starten es.  Wir k√∂nnen erwarten (wir sollten uns die Quelle ansehen), dass ein Interrupt beim Empfang nur einmal auftritt und sofort alle Zeichen vom Empfangspuffer an den Ring gesendet werden, was bedeutet, dass wir weniger Overhead sehen.  Es ist auch einfach, den Zeitpunkt der Lieferung an die serielle Schnittstelle zu bestimmen - wir geben jedes zweite Zeichen aus und l√∂sen die resultierenden 2 linearen Gleichungen mit 2 unbekannten.  Und es ist m√∂glich und noch einfacher - nichts abzuleiten, was ich getan habe. <br><br>  Und hier sind die Ergebnisse solcher kniffligen Manipulationen: Wir machen die Eingabe durch das Paket und die fehlenden Ticks werden kleiner - 2282, schalten die Ausgabe aus und die Kosten fallen auf 1222 Ticks - es ist besser, obwohl ich auf 300 Ticks gehofft habe. <br><br>  Mit der Zeit des Lesens kann jedoch nichts dergleichen gefunden werden, da es gleichzeitig mit der gew√ºnschten Kontextumschaltzeit skaliert wird.  Das einzige, was ich anbieten kann, ist, den internen Timer zu Beginn der Eingabe des empfangenen Zeichens auszuschalten und wieder einzuschalten, bevor Sie auf das n√§chste warten.  Dann arbeiten zwei Z√§hler synchron (mit Ausnahme des Umschaltens) und es kann leicht bestimmt werden.  Ein solcher Ansatz erfordert jedoch eine gr√ºndliche Implementierung von Systemprogrammen in den Texten, und dennoch bleibt die Komponente der Interrupt-Behandlung erhalten.  Daher schlage ich vor, mich auf die bereits erhaltenen Daten zu beschr√§nken, die es uns erm√∂glichen, fest zu behaupten, dass die Taskwechselzeit im betrachteten TI-RTOS 1222 Taktzyklen nicht √ºberschreitet, was f√ºr eine gegebene Taktfrequenz 30 Mikrosekunden betr√§gt. <br><br>  PNP: jedenfalls viel - ich habe Zyklen bei 100: 30 gez√§hlt, um den Kontext zu speichern, 40, um die fertige Aufgabe zu bestimmen und 30, um den Kontext wiederherzustellen, aber wir bekommen eine Gr√∂√üenordnung mehr.  Obwohl die Optimierung jetzt deaktiviert wurde, schalten Sie ‚Äìo2 ein und sehen Sie das Ergebnis: Es hat sich nicht viel ge√§ndert - es wurde 2894 statt 3160. <br><br>  Es gibt noch eine andere Idee: Wenn das Betriebssystem das Wechseln von Peer-to-Peer-Aufgaben unterst√ºtzt, k√∂nnen Sie zwei Aufgaben mit Z√§hlern ausf√ºhren, auf magische Weise Daten √ºber die Anzahl der Schalter in einer Weile abrufen und den Verlust des Systemz√§hlers berechnen, jedoch aufgrund der Besonderheiten des Shedulers, √ºber die ich bereits gesagt, wird dieser Ansatz nicht zum Erfolg f√ºhren.  Obwohl eine andere Option m√∂glich ist - Ping-Pong zwischen zwei Peer-to-Peer- (oder sogar Peer-to-Peer-) Aufgaben √ºber ein Semaphor durchzuf√ºhren, ist es einfach, die Anzahl der Kontextwechsel hier zu berechnen - Sie m√ºssen es versuchen, aber es wird morgen sein. <br><br>  Die traditionelle Umfrage am Ende des Beitrags dieses Mal widmet sich nicht der Pr√§sentationsebene (es ist jedem unvoreingenommenen Leser klar, dass er √ºber jedes Lob hinausgeht und alle Erwartungen √ºbertrifft), sondern dem Thema des n√§chsten Beitrags. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de451918/">https://habr.com/ru/post/de451918/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de451904/index.html">Manchmal ist mehr weniger. Wenn eine Abnahme der Last zu einer Zunahme der Verz√∂gerung f√ºhrt</a></li>
<li><a href="../de451906/index.html">Exchange-Sicherheitsanf√§lligkeit: Ermitteln der Erh√∂hung der Berechtigung f√ºr einen Dom√§nenadministrator</a></li>
<li><a href="../de451908/index.html">Die Geschichte der Computer: eine Nacht im Yandex Museum</a></li>
<li><a href="../de451912/index.html">Das tiefe neuronale Netzwerk von MuseNet schreibt Musik</a></li>
<li><a href="../de451916/index.html">Asynchrones PHP und die Geschichte eines Fahrrads</a></li>
<li><a href="../de451920/index.html">Optimieren Sie den E-Mail-Speicher in der Zimbra Collaboration Suite</a></li>
<li><a href="../de451922/index.html">Festkomma-Arithmetik in C ++</a></li>
<li><a href="../de451926/index.html">√úber Live-Code nach 130 Streams</a></li>
<li><a href="../de451928/index.html">So richten Sie Webanalysen auf AMP-Seiten ein</a></li>
<li><a href="../de451930/index.html">Automatisierung der Treppenhausbeleuchtung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👅 🍪 🧤 Python是寻找喜欢旅行的人的廉价航班的助手 🥄 🦐 👄</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="这篇文章的作者（我们今天要翻译的译本）说，她的目标是谈论使用Selenium开发Python网络抓取工具，该工具搜索机票价格。 搜索票证时，使用灵活的日期（相对于指定日期为+-3天）。 Scraper将搜索结果保存在Excel文件中，并向启动它的人发送一封电子邮件，其中包含有关他设法找到的内容的一般...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python是寻找喜欢旅行的人的廉价航班的助手</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/451872/"> 这篇文章的作者（我们今天要翻译的译本）说，她的目标是谈论使用Selenium开发Python网络抓取工具，该工具搜索机票价格。 搜索票证时，使用灵活的日期（相对于指定日期为+-3天）。  Scraper将搜索结果保存在Excel文件中，并向启动它的人发送一封电子邮件，其中包含有关他设法找到的内容的一般信息。 该项目的目的是帮助旅行者找到最优惠的价格。 <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/webt/xl/jo/rr/xljorr2xue-q63wegfrfyt5uxu4.jpeg"></a> <br><br> 如果您在处理材料时感到迷失，请阅读本文。 <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">我们在找什么？</font> </h2><br> 您可以随意使用此处描述的系统。 例如，我用它来搜索周末旅行和我的家乡的门票。 如果您真的想寻找有利可图的门票，可以在服务器上运行脚本（一个简单的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">服务器</a> ，每月130卢布，非常适合此操作），并使其每天运行一次或两次。 搜索结果将通过电子邮件发送给您。 此外，我建议您进行所有配置，以便脚本将搜索结果保存到Excel文件中，并将其保存在Dropbox文件夹中，以便您可以随时随地查看此类文件。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d39/b7b/f3b/d39b7bf3b4f8c11fa9617ae308f01247.png"></div><br>  <i><font color="#999999">我尚未发现错误的关税，但我相信这是可能的</font></i> <br><br> 如前所述，在搜索时使用“灵活日期”，脚本会查找距给定日期三天内的报价。 尽管启动脚本时，它仅在一个方向上搜索商品，但是很容易对其进行优化，以使其可以在多个飞行方向上收集数据。 有了它的帮助，您甚至可以搜索错误的关税，这样的发现可能非常有趣。 <br><br><h2>  <font color="#3AC1EF">为什么需要另一个刮板机？</font> </h2><br> 老实说，当我第一次开始抓取网页时，它并不是特别有趣。 我想在预测建模，财务分析以及可能的文本情感色彩分析领域中进行更多的项目。 但是事实证明，这很有趣-弄清楚如何创建一个程序来收集网站数据。 当我研究这个主题时，我意识到Web抓取是Internet的“引擎”。 <br><br> 您可能会认为这是一个大胆的声明。 但是，请考虑一下Google如何开始使用Larry Page使用Java和Python创建的Web抓取工具。  Googlebot一直在研究和探索互联网，试图为他们的用户提供最佳的答案。  Web抓取具有无限数量的应用程序，即使您在数据科学领域对其他事情感兴趣，那么为了获取数据进行分析，您也将需要一些抓取技能。 <br><br> 我在最近获得的有关网络抓取的精彩<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">书籍中</a>找到了这里使用的一些技巧。 在其中，您可以找到许多关于被研究者的实际应用的简单示例和想法。 此外，还有关于reCaptcha测试旁路的非常有趣的一章。 对我来说，这是个新闻，因为我不知道有解决这些问题的专用工具甚至整个服务。 <br><br><h2>  <font color="#3AC1EF">你喜欢旅行吗？</font> </h2><br> 对于本节标题中的一个简单且无害的问题，人们经常会听到一个肯定的答案，其中提供了几个与被问到的人有关的旅行故事。 我们大多数人都会同意，旅行是深入新的文化环境并扩大视野的绝佳途径。 但是，如果您问某人有关他是否想购买机票的问题，我敢肯定，答案远非如此肯定。 实际上，Python来了。 <br><br> 在创建机票信息搜索系统的过程中，我们需要解决的第一个任务是选择一个合适的平台来获取信息。 对于我来说，解决这个问题并不容易，但是最终我选择了Kayak服务。 我尝试了Momondo，Skyscanner，Expedia等服务，但是针对这些资源上的机器人的保护机制是不可渗透的。 经过多次尝试，在此期间，为了说服我自己是人类，我不得不应对交通信号灯，人行横道和自行车，我决定让皮艇最适合我，即使在这里，如果在短时间内加载太多页面，检查也会开始。 我设法使漫游器每隔4到6个小时就将请求发送到该站点，并且一切正常。 使用Kayak时，有时会遇到困难，但是如果您开始受到检查的困扰，则需要手动处理它们，然后启动漫游器，或者等待几个小时，检查应该停止。 如有必要，您可以很好地将代码改编为另一个平台，如果这样做，则可以在注释中报告它。 <br><br> 如果您只是刚开始进行网页抓取，并且不知道为什么有些网站为此感到挣扎，那么在开始该领域的第一个项目之前，请帮个忙，并在Google中搜索单词“网页抓取礼节”。 如果您不合理地进行网页抓取，则实验可能比您想象的要早结束。 <br><br><h2>  <font color="#3AC1EF">开始使用</font> </h2><br> 以下是有关我们的网络抓取工具代码中发生的情况的一般概述： <br><br><ul><li> 导入所需的库。 </li><li> 打开Goog​​le Chrome浏览器标签。 </li><li> 调用启动机器人的函数，并向其传递城市和日期，这将在搜索票证时使用。 </li><li> 此功能接收按照最有吸引力（最佳）的条件排序的第一个搜索结果，然后按按钮加载其他结果。 </li><li> 另一个函数从整个页面收集数据并返回一个数据帧。 </li><li> 前面的两个步骤是使用按机票价格（便宜）和飞行速度（最快）的分类类型执行的。 </li><li> 将向电子邮件用户发送一封电子邮件，其中包含机票价格的简要摘要（最便宜的机票和平均价格），并且具有按上述三个指标排序的信息的数据框被保存为Excel文件。 </li><li> 所有上述操作在指定的时间段后循环执行。 </li></ul><br> 应当注意，每个Selenium项目都以Web驱动程序开头。 我使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Chromedriver</a> ，可与Google Chrome一起使用，但还有其他选择。  PhantomJS和Firefox也很受欢迎。 加载驱动程序后，需要将其放置在适当的文件夹中，以完成其使用的准备工作。 脚本的第一行打开一个新的Chrome标签。 <br><br> 请记住，在我的故事中，我并没有尝试开辟新的视野来寻找机票的有利可图。 有很多更先进的技术可以找到这样的报价。 我只是想为读者提供一种简单而实用的方法来解决此问题。 <br><br> 这是我们上面讨论的代码。 <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sleep, strftime <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> randint <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> selenium <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> webdriver <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> selenium.webdriver.common.keys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Keys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> smtplib <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> email.mime.multipart <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MIMEMultipart <span class="hljs-comment"><span class="hljs-comment">#      chromedriver! chromedriver_path = 'C:/{YOUR PATH HERE}/chromedriver_win32/chromedriver.exe' driver = webdriver.Chrome(executable_path=chromedriver_path) #     Chrome sleep(2)</span></span></code> </pre> <br> 在代码的开头，您可以看到整个项目中使用的包导入命令。 因此，使用<code>randint</code>以便该机器人在开始新的搜索操作之前会“睡着”几秒钟。 通常没有一个机器人就不能没有它。 如果您运行上述代码，则会打开一个Chrome窗口，该漫游器将使用该窗口来处理网站。 <br><br> 让我们做一个小实验，在单独的窗口中打开kayak.com网站。 选择我们要飞往的城市，要到达的城市以及航班日期。 选择日期时，我们将验证范围为+ -3天。 我在编写代码时考虑到了网站根据此类请求生成的内容。 例如，如果您只需要搜索给定日期的票证，那么很有可能必须修改机器人代码。 在讨论代码时，我会做出适当的解释，但是如果您感到困惑，请告诉我。 <br><br> 现在，单击搜索开始按钮，然后查看地址栏中的链接。 它看起来像我在下面的示例中使用的链接，其中声明了存储URL的<code>kayak</code>变量，并使用了Web驱动程序的<code>get</code>方法。 单击搜索按钮后，结果应显示在页面上。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ae6/ac7/1f7/ae6ac71f71c92c6ff76d5dd6a8fcfa25.png"></div><br> 当我在几分钟内多次使用<code>get</code>命令两次至三次时，要求我通过reCaptcha通过测试。 您可以手动进行此检查，然后继续进行实验，直到系统决定安排新的检查为止。 当我测试脚本时，我觉得第一个搜索会话总是没有问题，因此，如果您要尝试使用该代码，则只需定期手动对其进行检查，并使代码在搜索会话之间使用较长的时间间隔即可执行。 是的，如果您考虑一下，一个人不太可能需要在搜索操作之间间隔10分钟才能获得的机票价格信息。 <br><br><h2>  <font color="#3AC1EF">使用XPath处理页面</font> </h2><br> 因此，我们打开了窗口并加载了网站。 要获取价格和其他信息，我们需要使用XPath技术或CSS选择器。 我决定停留在XPath上，并且不觉得需要使用CSS选择器，但是这样做很有可能。 使用XPath在页面上移动可能是一项艰巨的任务，即使使用本文中介绍的方法（该方法使用了从页面代码中复制相应的标识符），我也意识到，这实际上并不是最佳的访问方式必要的元素。 顺便说一下，在本书中，您可以找到有关使用XPath和CSS选择器处理页面的基础知识的出色说明。 这是相应的Web驱动程序方法的外观。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fa6/5c0/5c0/fa65c05c0385c658a4eee0c08a6274ff.png"></div><br> 因此，我们将继续致力于该机器人。 利用该程序选择最便宜的车票。 在下图中，XPath选择器代码以红色突出显示。 为了查看代码，您需要右键单击感兴趣的页面元素，然后在出现的菜单中选择“检查”命令。 可以针对不同的页面元素调用此命令，其页面代码将在代码查看窗口中显示并突出显示。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2c4/eee/9dc/2c4eee9dc28a8ef0ff540e1c01d3eda5.png"></div><br>  <i><font color="#999999">查看页面代码</font></i> <br><br> 为了确认我对从代码中复制选择器的缺点的推理，请注意以下功能。 <br><br> 这是复制代码时得到的： <br><br><pre> <code class="python hljs">//*[@id=<span class="hljs-string"><span class="hljs-string">"wtKI-price_aTab"</span></span>]/div[<span class="hljs-number"><span class="hljs-number">1</span></span>]/div/div/div[<span class="hljs-number"><span class="hljs-number">1</span></span>]/div/span/span</code> </pre> <br> 为了复制类似内容，您需要右键单击您感兴趣的代码部分，然后从出现的菜单中选择“复制”&gt;“复制XPath”。 <br><br> 这是我用来定义“最便宜”按钮的内容： <br><br><pre> <code class="python hljs">cheap_results = <span class="hljs-string"><span class="hljs-string">'//a[@data-code = "price"]'</span></span></code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9c9/4e3/8a4/9c94e38a436fa588ade8a2f92d97aa2d.png"></div><br>  <i><font color="#999999">复制&gt;复制XPath命令</font></i> <br><br> 很明显，第二种选择看起来简单得多。 使用它时，它将搜索元素a，该元素的<code>data-code</code>属性等于<code>price</code> 。 使用第一个选项，将搜索一个<code>id</code>元素，其为<code>wtKI-price_aTab</code> ，并且该元素的XPath路径类似于<code>/div[1]/div/div/div[1]/div/span/span</code> 。 对页面的类似XPath请求将完成此操作，但仅执行一次。 我现在可以说，下次加载页面时<code>id</code>会更改。 每次加载页面时， <code>wtKI</code>字符<code>wtKI</code>都会动态变化，因此，在下一页重新加载后，使用它的代码将无用。 因此，花一些时间弄清楚XPath。 这些知识将很好地为您服务。 <br><br> 但是，应该注意的是，在使用非常简单的站点时，复制XPath选择器可能会派上用场，如果适合您的话，那没有什么错。 <br><br> 现在，让我们考虑一下如果需要在列表内的多行中获取所有搜索结果该怎么办。 很简单 每个结果都在带有<code>resultWrapper</code>类的对象内。 下载所有结果的过程可以类似于下面所示的循环进行。 <br><br> 应该注意的是，如果您了解上述内容，那么您应该很容易理解我们将解析的大多数代码。 在编写此代码的过程中，我们使用某种机制来指示路径（XPath），以转到所需的内容（实际上，这是包装结果的元素）。 这样做是为了获取元素的文本并将其放置在可以从中读取数据的对象中（首先使用<code>flight_containers</code> ，然后使用<code>flights_list</code> ）。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0b2/3fc/b7f/0b23fcb7f32738fd6012541c40f68b97.png"></div><br> 显示前三行，我们可以清楚地看到我们需要的所有内容。 但是，我们有更多有趣的方式来获取信息。 我们需要分别从每个元素中获取数据。 <br><br><h2>  <font color="#3AC1EF">上班！</font> </h2><br> 编写函数以加载其他结果是最简单的，所以让我们开始吧。 我想最大程度地增加程序接收有关航班的航班数量，同时又不会引起服务中导致验证的怀疑，因此，每次显示该页面时，我都会单击“加载更多结果”按钮。 在这段代码中，您应注意<code>try</code>块，由于有时按钮无法正常加载，我添加了<code>try</code>块。 如果您也遇到这种情况，请在<code>start_kayak</code>函数的代码中<code>start_kayak</code>函数的调用，我们将在下面讨论。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      ,      def load_more():   try:       more_results = '//a[@class = "moreButton"]'       driver.find_element_by_xpath(more_results).click()       #            ,          print('sleeping.....')       sleep(randint(45,60))   except:       pass</span></span></code> </pre> <br> 现在，在对此功能进行了长时间分析之后（有时我可能会被迷住），我们准备声明一个将处理页面抓取的功能。 <br><br> 我已经收集了称为<code>page_scrape</code>的下一个函数中的大部分功能。 有时返回的有关路径各阶段的数据被合并在一起，对于它们的分离，我使用一种简单的方法。 例如，我第一次使用变量<code>section_a_list</code>和<code>section_b_list</code> 。 我们的函数返回数据帧<code>flights_df</code> ，这使我们可以分离使用不同数据排序方法获得的结果，然后将它们组合起来。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">page_scrape</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-string"><span class="hljs-string">"""This function takes care of the scraping part"""</span></span>     xp_sections = <span class="hljs-string"><span class="hljs-string">'//*[@class="section duration"]'</span></span>   sections = driver.find_elements_by_xpath(xp_sections)   sections_list = [value.text <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> value <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sections]   section_a_list = sections_list[::<span class="hljs-number"><span class="hljs-number">2</span></span>] <span class="hljs-comment"><span class="hljs-comment">#          section_b_list = sections_list[1::2]     #     reCaptcha,    - .   #  ,  -   ,     ,       #   if        -   #    ,           #    SystemExit           if section_a_list == []:       raise SystemExit     #     A     B     a_duration = []   a_section_names = []   for n in section_a_list:       #         a_section_names.append(''.join(n.split()[2:5]))       a_duration.append(''.join(n.split()[0:2]))   b_duration = []   b_section_names = []   for n in section_b_list:       #         b_section_names.append(''.join(n.split()[2:5]))       b_duration.append(''.join(n.split()[0:2]))   xp_dates = '//div[@class="section date"]'   dates = driver.find_elements_by_xpath(xp_dates)   dates_list = [value.text for value in dates]   a_date_list = dates_list[::2]   b_date_list = dates_list[1::2]   #      a_day = [value.split()[0] for value in a_date_list]   a_weekday = [value.split()[1] for value in a_date_list]   b_day = [value.split()[0] for value in b_date_list]   b_weekday = [value.split()[1] for value in b_date_list]     #     xp_prices = '//a[@class="booking-link"]/span[@class="price option-text"]'   prices = driver.find_elements_by_xpath(xp_prices)   prices_list = [price.text.replace('$','') for price in prices if price.text != '']   prices_list = list(map(int, prices_list))   # stops -   ,         ,   -     xp_stops = '//div[@class="section stops"]/div[1]'   stops = driver.find_elements_by_xpath(xp_stops)   stops_list = [stop.text[0].replace('n','0') for stop in stops]   a_stop_list = stops_list[::2]   b_stop_list = stops_list[1::2]   xp_stops_cities = '//div[@class="section stops"]/div[2]'   stops_cities = driver.find_elements_by_xpath(xp_stops_cities)   stops_cities_list = [stop.text for stop in stops_cities]   a_stop_name_list = stops_cities_list[::2]   b_stop_name_list = stops_cities_list[1::2]     #   -,          xp_schedule = '//div[@class="section times"]'   schedules = driver.find_elements_by_xpath(xp_schedule)   hours_list = []   carrier_list = []   for schedule in schedules:       hours_list.append(schedule.text.split('\n')[0])       carrier_list.append(schedule.text.split('\n')[1])   #          a  b   a_hours = hours_list[::2]   a_carrier = carrier_list[1::2]   b_hours = hours_list[::2]   b_carrier = carrier_list[1::2]     cols = (['Out Day', 'Out Time', 'Out Weekday', 'Out Airline', 'Out Cities', 'Out Duration', 'Out Stops', 'Out Stop Cities',           'Return Day', 'Return Time', 'Return Weekday', 'Return Airline', 'Return Cities', 'Return Duration', 'Return Stops', 'Return Stop Cities',           'Price'])   flights_df = pd.DataFrame({'Out Day': a_day,                              'Out Weekday': a_weekday,                              'Out Duration': a_duration,                              'Out Cities': a_section_names,                              'Return Day': b_day,                              'Return Weekday': b_weekday,                              'Return Duration': b_duration,                              'Return Cities': b_section_names,                              'Out Stops': a_stop_list,                              'Out Stop Cities': a_stop_name_list,                              'Return Stops': b_stop_list,                              'Return Stop Cities': b_stop_name_list,                              'Out Time': a_hours,                              'Out Airline': a_carrier,                              'Return Time': b_hours,                              'Return Airline': b_carrier,                                                     'Price': prices_list})[cols]     flights_df['timestamp'] = strftime("%Y%m%d-%H%M") #      return flights_df</span></span></code> </pre> <br> 我试图命名变量，以便代码清晰。 请记住，以<code>a</code>开头的变量是路径的第一步，而<code>b</code>是第二步。 转到下一个功能。 <br><br><h2>  <font color="#3AC1EF">辅助机制</font> </h2><br> 现在，我们有了一个功能，可让您加载其他搜索结果，并具有处理这些结果的功能。 本文可以在此完成，因为这两个功能提供了可独立打开的抓取页面所需的一切。 但是我们尚未考虑上面讨论的一些辅助机制。 例如，这是用于发送电子邮件和其他内容的代码。 所有这些都可以在我们现在考虑的<code>start_kayak</code>函数中找到。 <br><br> 要使用此功能，您需要有关城市和日期的信息。 她利用这些信息在<code>kayak</code>变量中形成一个链接，该链接用于转到一个页面，该页面将包含按其最佳匹配排序的搜索结果。 在第一次抓取会话之后，我们将使用页面顶部表中的价格。 即，我们找到最低票价和平均价格。 所有这些以及站点发布的预测将通过电子邮件发送。 在页面上，相应的表格应位于左上角。 顺便说一下，使用此表进行操作可能会在使用确切日期进行搜索时导致错误，因为在这种情况下，该表未显示在页面上。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">start_kayak</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(city_from, city_to, date_start, date_end)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-string"><span class="hljs-string">"""City codes - it's the IATA codes!   Date format -  YYYY-MM-DD"""</span></span>     kayak = (<span class="hljs-string"><span class="hljs-string">'https://www.kayak.com/flights/'</span></span> + city_from + <span class="hljs-string"><span class="hljs-string">'-'</span></span> + city_to +            <span class="hljs-string"><span class="hljs-string">'/'</span></span> + date_start + <span class="hljs-string"><span class="hljs-string">'-flexible/'</span></span> + date_end + <span class="hljs-string"><span class="hljs-string">'-flexible?sort=bestflight_a'</span></span>)   driver.get(kayak)   sleep(randint(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>))     <span class="hljs-comment"><span class="hljs-comment">#    ,           try   try:       xp_popup_close = '//button[contains(@id,"dialog-close") and contains(@class,"Button-No-Standard-Style close ")]'       driver.find_elements_by_xpath(xp_popup_close)[5].click()   except Exception as e:       pass   sleep(randint(60,95))   print('loading more.....')  #     load_more()     print('starting first scrape.....')   df_flights_best = page_scrape()   df_flights_best['sort'] = 'best'   sleep(randint(60,80))     #      ,        matrix = driver.find_elements_by_xpath('//*[contains(@id,"FlexMatrixCell")]')   matrix_prices = [price.text.replace('$','') for price in matrix]   matrix_prices = list(map(int, matrix_prices))   matrix_min = min(matrix_prices)   matrix_avg = sum(matrix_prices)/len(matrix_prices)     print('switching to cheapest results.....')   cheap_results = '//a[@data-code = "price"]'   driver.find_element_by_xpath(cheap_results).click()   sleep(randint(60,90))   print('loading more.....')  #     load_more()     print('starting second scrape.....')   df_flights_cheap = page_scrape()   df_flights_cheap['sort'] = 'cheap'   sleep(randint(60,80))     print('switching to quickest results.....')   quick_results = '//a[@data-code = "duration"]'   driver.find_element_by_xpath(quick_results).click()    sleep(randint(60,90))   print('loading more.....')  #     load_more()     print('starting third scrape.....')   df_flights_fast = page_scrape()   df_flights_fast['sort'] = 'fast'   sleep(randint(60,80))     #     Excel-,         final_df = df_flights_cheap.append(df_flights_best).append(df_flights_fast)   final_df.to_excel('search_backups//{}_flights_{}-{}_from_{}_to_{}.xlsx'.format(strftime("%Y%m%d-%H%M"),                                                                                  city_from, city_to,                                                                                  date_start, date_end), index=False)   print('saved df.....')     #    ,  ,  ,      xp_loading = '//div[contains(@id,"advice")]'   loading = driver.find_element_by_xpath(xp_loading).text   xp_prediction = '//span[@class="info-text"]'   prediction = driver.find_element_by_xpath(xp_prediction).text   print(loading+'\n'+prediction)     #    loading   , , ,        #    -    "Not Sure"   weird = '¯\\_(ツ)_/¯'   if loading == weird:       loading = 'Not sure'     username = 'YOUREMAIL@hotmail.com'   password = 'YOUR PASSWORD'   server = smtplib.SMTP('smtp.outlook.com', 587)   server.ehlo()   server.starttls()   server.login(username, password)   msg = ('Subject: Flight Scraper\n\n\ Cheapest Flight: {}\nAverage Price: {}\n\nRecommendation: {}\n\nEnd of message'.format(matrix_min, matrix_avg, (loading+'\n'+prediction)))   message = MIMEMultipart()   message['From'] = 'YOUREMAIL@hotmail.com'   message['to'] = 'YOUROTHEREMAIL@domain.com'   server.sendmail('YOUREMAIL@hotmail.com', 'YOUROTHEREMAIL@domain.com', msg)   print('sent email.....')</span></span></code> </pre> <br> 我使用Outlook帐户（hotmail.com）测试了此脚本。 我没有检查它是否可以正确运行Gmail帐户，该邮件系统非常流行，但是有很多可能的选择。 如果您使用Hotmail帐户，则为了使所有功能正常工作，您只需要在代码中输入数据即可。 <br><br> 如果您想了解在此函数代码的不同部分中究竟执行了什么操作，则可以复制它们并进行试验。 代码实验是理解它的唯一方法。 <br><br><h2>  <font color="#3AC1EF">准备系统</font> </h2><br> 现在，我们讨论的所有内容都已完成，我们可以创建一个简单的循环，在其中调用我们的函数。 该脚本要求用户提供有关城市和日期的数据。 在不断重启脚本的情况下进行测试时，您不太希望每次都手动输入此数据，因此可以在测试期间通过注释掉下面的严格注释了脚本所需数据的行来注释掉对应的行。 <br><br><pre> <code class="python hljs">city_from = input(<span class="hljs-string"><span class="hljs-string">'From which city? '</span></span>) city_to = input(<span class="hljs-string"><span class="hljs-string">'Where to? '</span></span>) date_start = input(<span class="hljs-string"><span class="hljs-string">'Search around which departure date? Please use YYYY-MM-DD format only '</span></span>) date_end = input(<span class="hljs-string"><span class="hljs-string">'Return when? Please use YYYY-MM-DD format only '</span></span>) <span class="hljs-comment"><span class="hljs-comment"># city_from = 'LIS' # city_to = 'SIN' # date_start = '2019-08-21' # date_end = '2019-09-07' for n in range(0,5):   start_kayak(city_from, city_to, date_start, date_end)   print('iteration {} was complete @ {}'.format(n, strftime("%Y%m%d-%H%M")))     #  4    sleep(60*60*4)   print('sleep finished.....')</span></span></code> </pre> <br> 这是脚本的测试运行。 <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/44c/305/023/44c305023996a98a3dec745493dce7a7.png"></div><br>  <i><font color="#999999">测试运行脚本</font></i> <br><br><h2>  <font color="#3AC1EF">总结</font> </h2><br> 如果您到了这一步，恭喜！ 现在，您已经可以使用网络刮板，尽管我已经发现了许多改进方法。 例如，它可以与Twilio集成在一起，以便发送电子邮件而不是电子邮件。 您可以使用VPN或其他方式同时从多个服务器接收结果。 检查站点用户是否为人也是一个反复出现的问题，但是这个问题也可以解决。 无论如何，现在您有了一个可以扩展的基础。 例如，确保将Excel文件作为电子邮件的附件发送给用户。 <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN451872/">https://habr.com/ru/post/zh-CN451872/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN451860/index.html">数学家发现乘数的完美方法</a></li>
<li><a href="../zh-CN451862/index.html">乔·迪普里姆（Joe Diprim）的《音乐闪电》：自学成才的工程师制作特斯拉线圈进行娱乐和赚钱</a></li>
<li><a href="../zh-CN451864/index.html">在Windows OS中检测到EternalBlue级别的严重RCE漏洞</a></li>
<li><a href="../zh-CN451866/index.html">选择网络中最近的节点</a></li>
<li><a href="../zh-CN451870/index.html">所有程序员都需要了解的现代C ++功能</a></li>
<li><a href="../zh-CN451874/index.html">Google的热门SEO趋势</a></li>
<li><a href="../zh-CN451876/index.html">法兰克福数据中心：Telehouse数据中心</a></li>
<li><a href="../zh-CN451878/index.html">将立体声视频实时流传输到VR眼镜（Oculus Go）</a></li>
<li><a href="../zh-CN451880/index.html">DevPRO'19：从Wrike展位观看</a></li>
<li><a href="../zh-CN451884/index.html">从事开发人员七年：我学到了什么</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
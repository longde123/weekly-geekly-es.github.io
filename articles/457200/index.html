<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòú üë©‚Äçüë©‚Äçüëß‚Äçüëß üöΩ Un robot de dibujo para realizar escenas cotidianas e incluso historias ‚è≠Ô∏è üö± üìå</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Si le pidieran que dibujara a varias personas en ropa de esqu√≠, de pie en la nieve, es probable que comience con un esquema de tres o cuatro personas ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Un robot de dibujo para realizar escenas cotidianas e incluso historias</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/457200/"><p> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/657/93f/e0f/65793fe0f0e42b382c46426806424e36.png" alt="Dibujo bot" width="1024" height="414"></a> </p><br><p>  Si le pidieran que dibujara a varias personas en ropa de esqu√≠, de pie en la nieve, es probable que comience con un esquema de tres o cuatro personas razonablemente ubicadas en el centro del lienzo, luego dibuje en los esqu√≠s debajo de su pies  Aunque no se especific√≥, es posible que decida agregar una mochila a cada uno de los esquiadores para responder a las expectativas de los esquiadores deportivos.  Finalmente, completar√≠a cuidadosamente los detalles, tal vez pintando su ropa de azul, bufandas de color rosa, todo sobre un fondo blanco, haciendo que estas personas sean m√°s realistas y garantizando que su entorno coincida con la descripci√≥n.  Finalmente, para hacer que la escena sea m√°s v√≠vida, incluso puede dibujar en algunas piedras marrones que sobresalen de la nieve para sugerir que estos esquiadores est√°n en las monta√±as. </p><br><p>  Ahora hay un bot que puede hacer todo eso. </p><a name="habracut"></a><br><p>  La nueva tecnolog√≠a de IA que se est√° desarrollando en Microsoft Research AI puede comprender una descripci√≥n en lenguaje natural, esbozar un dise√±o de la imagen, sintetizar la imagen y luego refinar los detalles en funci√≥n del dise√±o y las palabras individuales proporcionadas.  En otras palabras, este bot puede generar im√°genes a partir de descripciones de texto de subt√≠tulos de escenas cotidianas.  Este mecanismo deliberado produjo un impulso significativo en la calidad de imagen generada en comparaci√≥n con la t√©cnica de vanguardia anterior para la generaci√≥n de texto a imagen para escenas cotidianas complicadas, de acuerdo con los resultados de las pruebas est√°ndar de la industria informadas en " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Texto dirigido por objetos- S√≠ntesis de imagen a trav√©s de entrenamiento adversario</a> ‚Äù, que se publicar√° este mes en Long Beach, California, en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conferencia IEEE 2019 sobre Visi√≥n por Computadora y Reconocimiento de Patrones</a> (CVPR 2019).  Este es un proyecto de colaboraci√≥n entre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pengchuan Zhang</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Qiuyuan Huang</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Jianfeng Gao</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Microsoft Research AI</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lei Zhang</a> de Microsoft, Xiaodong He de JD AI Research y Wenbo Li y Siwei Lyu de la Universidad de Albany, SUNY (mientras Wenbo Li trabaj√≥ como un pasante en Microsoft Research AI). </p><br><p>  Hay dos desaf√≠os principales intr√≠nsecos al problema del robot de dibujo basado en la descripci√≥n.  La primera es que pueden aparecer muchos tipos de objetos en las escenas cotidianas y el bot deber√≠a poder comprenderlos y dibujarlos a todos.  Los m√©todos anteriores de generaci√≥n de texto a imagen utilizan pares de subt√≠tulos de imagen que solo proporcionan una se√±al de supervisi√≥n de grano muy grueso para generar objetos individuales, limitando su calidad de generaci√≥n de objetos.  En esta nueva tecnolog√≠a, los investigadores hacen uso del conjunto de datos COCO que contiene etiquetas y mapas de segmentaci√≥n para 1,5 millones de instancias de objetos en 80 clases de objetos comunes, lo que permite al bot aprender tanto el concepto como la apariencia de estos objetos.  Esta se√±al supervisada de grano fino para la generaci√≥n de objetos mejora significativamente la calidad de generaci√≥n para estas clases de objetos comunes. </p><br><p>  El segundo desaf√≠o radica en la comprensi√≥n y generaci√≥n de las relaciones entre m√∫ltiples objetos en una escena.  Se ha logrado un gran √©xito en la generaci√≥n de im√°genes que solo contienen un objeto principal para varios dominios espec√≠ficos, como caras, p√°jaros y objetos comunes.  Sin embargo, generar escenas m√°s complejas que contengan m√∫ltiples objetos con relaciones sem√°nticamente significativas entre esos objetos sigue siendo un desaf√≠o importante en la tecnolog√≠a de generaci√≥n de texto a imagen.  Este nuevo robot de dibujo aprendi√≥ a generar el dise√±o de objetos a partir de patrones de coincidencia en el conjunto de datos COCO para luego generar una imagen condicionada en el dise√±o pregenerado. </p><br><h3>  Generaci√≥n de im√°genes atenta por objetos </h3><br><p>  En el n√∫cleo del robot de dibujo de Microsoft Research AI se encuentra una tecnolog√≠a conocida como Red Adversarial Generativa, o GAN.  La GAN consta de dos modelos de aprendizaje autom√°tico: un generador que genera im√°genes a partir de descripciones de texto y un discriminador que usa descripciones de texto para juzgar la autenticidad de las im√°genes generadas.  El generador intenta obtener im√°genes falsas m√°s all√° del discriminador;  el discriminador por otro lado nunca quiere ser enga√±ado.  Trabajando juntos, el discriminador empuja al generador hacia la perfecci√≥n. </p><br><p>  El robot de dibujo fue entrenado en un conjunto de datos de 100,000 im√°genes, cada una con etiquetas de objetos sobresalientes y mapas de segmentaci√≥n y cinco subt√≠tulos diferentes, permitiendo a los modelos concebir objetos individuales y relaciones sem√°nticas entre objetos.  La GAN, por ejemplo, aprende c√≥mo debe ser un perro al comparar im√°genes con y sin descripciones de perros. </p><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/27e/b5f/e0a/27eb5fe0ab38f35180ba6558f15f0456.png" alt="Figura 1: Una escena compleja con m√∫ltiples objetos y relaciones." width="273" height="272"></a> <br><p>  Figura 1: Una escena compleja con m√∫ltiples objetos y relaciones. </p><br><p>  Las GAN funcionan bien al generar im√°genes que contienen solo un objeto destacado, como un rostro humano, p√°jaros o perros, pero la calidad se estanca con escenas cotidianas m√°s complejas, como una escena descrita como "Una mujer que usa un casco monta un caballo" (ver Figura 1.) Esto se debe a que tales escenas contienen m√∫ltiples objetos (mujer, casco, caballo) y ricas relaciones sem√°nticas entre ellas (mujer con casco, mujer con caballo).  El bot primero debe comprender estos conceptos y colocarlos en la imagen con un dise√±o significativo.  Despu√©s de eso, se requiere una se√±al m√°s supervisada capaz de ense√±ar la generaci√≥n de objetos y la generaci√≥n de dise√±o para cumplir con esta tarea de generaci√≥n de im√°genes y comprensi√≥n del lenguaje. </p><br><p>  A medida que los humanos dibujan estas escenas complicadas, primero decidimos sobre los objetos principales a dibujar y hacemos un dise√±o colocando cuadros delimitadores para estos objetos en el lienzo.  Luego nos enfocamos en cada objeto, verificando repetidamente las palabras correspondientes que describen este objeto.  Para capturar este rasgo humano, los investigadores crearon lo que llamaron una GAN atenta dirigida por objetos, u ObjGAN, para modelar matem√°ticamente el comportamiento humano de la atenci√≥n centrada en objetos.  ObjGAN hace esto dividiendo el texto de entrada en palabras individuales y haciendo coincidir esas palabras con objetos espec√≠ficos en la imagen. </p><br><p>  Los humanos suelen verificar dos aspectos para refinar el dibujo: el realismo de los objetos individuales y la calidad de los parches de imagen.  ObjGAN tambi√©n imita este comportamiento mediante la introducci√≥n de dos discriminadores: un discriminador por objeto y un discriminador por parche.  El discriminador en cuanto al objeto est√° tratando de determinar si el objeto generado es realista o no y si el objeto es consistente con la descripci√≥n de la oraci√≥n.  El discriminador de parche est√° tratando de determinar si este parche es realista o no y si este parche es consistente con la descripci√≥n de la oraci√≥n. </p><br><h3>  Trabajo relacionado: visualizaci√≥n de la historia </h3><br><p>  Los modelos de generaci√≥n de texto a imagen de √∫ltima generaci√≥n pueden generar im√°genes realistas de aves basadas en una descripci√≥n de una sola oraci√≥n.  Sin embargo, la generaci√≥n de texto a imagen puede ir mucho m√°s all√° de la s√≠ntesis de una sola imagen basada en una oraci√≥n.  En " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">StoryGAN: A GAN condicional secuencial para visualizaci√≥n de historias</a> ", <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Jianfeng Gao</a> de Microsoft Research, junto con Zhe Gan, Jingjing Liu y Yu Cheng de Microsoft Dynamics 365 AI Research, Yitong Li, David Carlson y Lawrence Carin de Duke University, Yelong Shen de Tencent AI Research y Yuexin Wu de la Universidad Carnegie Mellon van un paso m√°s all√° y proponen una nueva tarea, llamada Visualizaci√≥n de historias.  Dado un p√°rrafo de varias oraciones, se puede visualizar una historia completa, generando una secuencia de im√°genes, una para cada oraci√≥n.  Esta es una tarea desafiante, ya que el robot de dibujo no solo debe imaginar un escenario que se ajuste a la historia, modelar las interacciones entre los diferentes personajes que aparecen en la historia, sino que tambi√©n debe ser capaz de mantener la consistencia global en escenas y personajes din√°micos.  Este desaf√≠o no ha sido abordado por ning√∫n m√©todo de generaci√≥n de im√°genes o videos. </p><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/04c/5c0/39c/04c5c039ca8dc39e2f47ffabb9437db7.png" alt="Figura 2: Visualizaci√≥n de la historia vs. Generaci√≥n simple de im√°genes." width="1024" height="454"></a> <br><p>  Figura 2: Visualizaci√≥n de la historia vs.  Generaci√≥n simple de im√°genes. </p><br><p>  Los investigadores crearon un nuevo modelo de generaci√≥n de secuencia de historia a imagen, StoryGAN, basado en el marco secuencial condicional GAN.  Este modelo es √∫nico porque consiste en un codificador de contexto profundo que rastrea din√°micamente el flujo de la historia y dos discriminadores en los niveles de la historia y la imagen para mejorar la calidad de la imagen y la consistencia de las secuencias generadas.  StoryGAN tambi√©n puede extenderse naturalmente para la edici√≥n interactiva de im√°genes, donde una imagen de entrada puede editarse secuencialmente seg√∫n las instrucciones del texto.  En este caso, una secuencia de instrucciones para el usuario servir√° como entrada de "historia".  En consecuencia, los investigadores modificaron los conjuntos de datos existentes para crear los conjuntos de datos CLEVR-SV y Pororo-SV, como se muestra en la Figura 2. </p><br><h3>  Aplicaciones pr√°cticas: una historia real </h3><br><p>  La tecnolog√≠a de generaci√≥n de texto a imagen podr√≠a encontrar aplicaciones pr√°cticas que act√∫en como una especie de asistente de boceto para pintores y dise√±adores de interiores, o como una herramienta para la edici√≥n de fotos activada por voz.  Con m√°s potencia inform√°tica, los investigadores imaginan la tecnolog√≠a que genera pel√≠culas animadas basadas en guiones, aumentando el trabajo que hacen los cineastas animados al eliminar parte del trabajo manual involucrado. </p><br><p>  Por ahora, las im√°genes generadas a√∫n est√°n lejos de ser realistas.  Los objetos individuales casi siempre revelan fallas, como caras borrosas o autobuses con formas distorsionadas.  Estos defectos son una clara indicaci√≥n de que una computadora, no un humano, cre√≥ las im√°genes.  Sin embargo, la calidad de las im√°genes ObjGAN es significativamente mejor que las im√°genes GAN mejores de su clase y sirven como un hito en el camino hacia una inteligencia gen√©rica, similar a la humana, que aumenta las capacidades humanas. </p><br><p>  Para que las IA y los humanos compartan el mismo mundo, cada uno debe tener una forma de interactuar con el otro.  El lenguaje y la visi√≥n son las dos modalidades m√°s importantes para que los humanos y las m√°quinas interact√∫en entre s√≠.  La generaci√≥n de texto a imagen es una tarea importante que promueve la investigaci√≥n de inteligencia multimodal con visi√≥n del lenguaje. </p><br><p>  Los investigadores que crearon este emocionante trabajo esperan compartir estos hallazgos con los asistentes a CVPR en Long Beach y escuchar lo que piensas.  Mientras tanto, no dude en consultar su c√≥digo de c√≥digo abierto para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ObjGAN</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">StoryGAN</a> en GitHub </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/457200/">https://habr.com/ru/post/457200/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457190/index.html">Tratamos negocios a trav√©s de la implementaci√≥n de sistemas CRM</a></li>
<li><a href="../457192/index.html">Airbus toma nuevas alturas con la realidad mixta de Microsoft</a></li>
<li><a href="../457194/index.html">Airbus alcanza nuevas alturas con la ayuda de la tecnolog√≠a de realidad mixta de Microsoft</a></li>
<li><a href="../457196/index.html">Petty little joy # 5: Dynaconf - administrando la configuraci√≥n en el proyecto</a></li>
<li><a href="../457198/index.html">La red neuronal ha aprendido a dibujar escenas complejas a partir de una descripci√≥n textual.</a></li>
<li><a href="../457202/index.html">C√≥mo elegimos ideas para el desarrollo de nuestros productos: el proveedor debe poder escuchar ...</a></li>
<li><a href="../457204/index.html">Windows PowerShell y rutas largas</a></li>
<li><a href="../457206/index.html">SQL Index Manager: una larga historia sobre SQL Server, excavaci√≥n de tumbas y mantenimiento de √≠ndices</a></li>
<li><a href="../457208/index.html">Generar din√°micamente robots.txt para sitios ASP.NET Core basados ‚Äã‚Äãen el entorno</a></li>
<li><a href="../457210/index.html">Almacene recursos est√°ticos en su alojamiento</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⏫ 🧖🏾 🌿 第一个模型：时尚MNIST数据集 ▫️ 👞 🐇</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="可以在此链接上找到完整的俄语课程。 
 此链接提供原始英语课程。 

 每2-3天安排一次新的讲座。 

 Udacity首席执行官Sebastian Trun访谈 
 “因此，我们仍然像塞巴斯蒂安一样与您和我们在一起。” 我们只想讨论完全连接的层，即那些相同的密集层。 在此之前，我想问一个问题。 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>第一个模型：时尚MNIST数据集</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454034/"> 可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此链接</a>上找到完整的俄语课程。 <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此链接</a>提供原始英语课程。 <br><img src="https://habrastorage.org/webt/ry/3a/55/ry3a55ljajwq9gp5jwwhztrxyxo.png"><br>  <i>每2-3天安排一次新的讲座。</i> <br><a name="habracut"></a><br><h2>  Udacity首席执行官Sebastian Trun访谈 </h2><br>  “因此，我们仍然像塞巴斯蒂安一样与您和我们在一起。” 我们只想讨论完全连接的层，即那些相同的密集层。 在此之前，我想问一个问题。 深度学习的界限是什么？在接下来的10年中将有哪些最大障碍？ 一切都变的如此之快！ 您认为接下来的“大事”是什么？ <br>  -我要说两件事。 首先是用于多个任务的通用AI。 太好了！ 人们可以解决多个问题，并且永远不要做同样的事情。 第二是将技术推向市场。 对我来说，机器学习的独特之处在于它为计算机提供了观察和发现数据模式的能力，从而帮助人们成为专家级的业内最佳人才！ 机器学习可用于法律，医学，自动驾驶汽车。 开发这样的应用程序是因为它们可以带来很多钱，但是最重要的是，您有机会让世界变得更加美好。 <br>  -我真的很喜欢您将所有内容都表达在深度学习及其应用中的方式-这只是一个可以帮助您解决特定问题的工具。 <br>  -是的！ 难以置信的工具，对不对？ <br>  -是的，我完全同意您的意见！ <br>  “几乎像人的大脑！” <br>  -您在视频课程的第一部分中的第一次采访中提到了医疗应用。 您认为深度学习在哪些应用程序中会带来最大的乐趣和惊喜？ <br>  -好多！ 很好！ 医学是积极使用深度学习的领域的短名单。 几个月前我失去了姐姐，她患了癌症，这非常令人难过。 我认为，许多疾病可以及早发现-在早期阶段，可以治愈或减慢其发展进程。 实际上，其想法是将一些工具转移到房屋（智能家居）中，以便有可能在人们本人看到它们之前就检测出这种健康状况的偏差。 我还要补充一点-重复一切，完成任何办公室工作，在其中您一次又一次地执行相同类型的操作，例如簿记。 甚至我作为首席执行官，也做了很多重复的动作。 使它们自动化甚至与邮件通信一起工作都很棒！ <br>  -我不能不同意你！ 在本课程中，我们将向学生介绍带有称为稠密层的神经网络层的课程。 您能否详细介绍一下您对全连接层的看法？ <br>  -因此，让我们从一个事实开始，即每个网络可以通过不同的方式连接。 它们中的一些可能具有非常紧密的连接性，这使您可以在扩展和与大型网络“竞争”时获得一些好处。 有时您不知道所需的连接数，因此将所有内容都连接起来-这称为完全连接层。 我补充说，这种方法比更有条理的方法具有更大的力量和潜力。 <br>  -我完全同意你的看法！ 感谢您帮助我们了解有关完全连接层的更多信息。 我期待我们终于开始实现它们并编写代码的时刻。 <br>  -玩得开心！ 真的很有趣！ <br><br><h2> 引言 </h2><br>  -欢迎回来！ 在上一课中，您了解了如何使用TensorFlow和Keras构建第一个神经网络，神经网络如何工作以及训练（培训）过程如何工作。 特别是，我们看到了如何训练模型以将摄氏温度转换为华氏温度。 <br><br><img src="https://habrastorage.org/webt/7h/jc/jq/7hjcjqzg5rz1qzpbncjes5ipor8.jpeg"><br><br>  -我们还熟悉了全连接层（密集层）的概念，这是神经网络中最重要的层。 但是在本课中，我们将做很多更酷的事情！ 在本课程中，我们将开发一个可以识别服装元素和图像的神经网络。 正如我们前面提到的，机器学习使用称为“功能”的输入和称为“标签”的输出，模型通过该输入学习并找到转换算法。 因此，首先，我们将需要许多示例来训练神经网络以识别服装的各种元素。 让我提醒您，训练的示例是一对值-输入要素和输出标签，它们被馈送到神经网络的输入。 在我们的新示例中，图像将用作输入，输出标签应为图片中所示服装项目所属的服装类别。 幸运的是，这样的数据集已经存在。 它被称为时尚MNIST。 在下一部分中，我们将仔细研究该数据集。 <br><br><h2> 时尚MNIST数据集 </h2><br> 欢迎来到MNIST数据集的世界！ 因此，我们的图像集由28x28张图像组成，每个像素代表一个灰色阴影。 <br><br><img src="https://habrastorage.org/webt/ua/mr/f6/uamrf6n8gci7qi2c1t_ganxtai8.jpeg"><br><br> 数据集包含T恤，上衣，凉鞋甚至靴子的图像。 这是我们的MNIST数据集包含的完整列表： <br><br><img src="https://habrastorage.org/webt/3i/ce/7n/3ice7nwlkok2g_n-trodker5s7e.jpeg"><br><br> 每个输入图像对应于上述标签之一。  Fashion MNIST数据集包含70,000张图像，因此我们有一个开始和工作的地方。 在这70,000人中，我们将使用60,000人来训练神经网络。 <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br> 我们将使用剩余的10,000个元素来检查我们的神经网络对识别服装元素的了解程度。 稍后，我们将解释为什么将数据集分为训练集和测试集。 <br><br> 这是我们的Fashion MNIST数据集。 <br><br><img src="https://habrastorage.org/webt/mx/lw/dz/mxlwdzjrfhviwmgsliwdcy6tbwq.png"><br><br> 请记住，数据集中的每个图像都是一个灰度级为28x28的图像，这表示每个图像的大小均为784字节。 我们的任务是创建一个神经网络，该神经网络在输入处接收这784个字节，然后在输出处返回在10种可用的衣服类别中，输入处所应用的元素所属。 <br><br><h2> 神经网络 </h2><br> 在本课程中，我们将使用一个深度神经网络，该网络将学习从Fashion MNIST数据集中对图像进行分类。 <br><br><img src="https://habrastorage.org/webt/xg/cr/h_/xgcrh_cowdhfz-owx34wp-kqzi0.png"><br><br> 上图显示了我们的神经网络的外观。 让我们更详细地看一下。 <br><br> 我们神经网络的输入值是一个长度为784的一维数组，由于每个图像都是28x28像素（=图像中总共784像素）的原因，正是该长度的数组，我们将其转换为一维数组。 将2D图像转换为矢量的过程称为展平，并通过展平层（展平层）实现。 <br><br><img src="https://habrastorage.org/webt/7d/wu/d_/7dwud_tt2qctnaigzc8my3pz1j0.png"><br><br> 您可以通过创建适当的图层来进行平滑处理： <br><br><pre><code class="python hljs">tf.keras.layers.Flatten(input_shape=[<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br> 该层将28x28像素的2D图像（每个像素1个字节用于灰度阴影）转换为784个像素的1D数组。 <br><br> 输入值将与我们的第一个<code>dense</code>网络层完全相关，我们选择的大小等于128个神经元。 <br><br><img src="https://habrastorage.org/webt/mk/n_/3w/mkn_3wrocxruhbwhil0fmh5wh_8.png"><br><br> 这是在代码中创建该层的样子： <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu)</code> </pre><br> 别说了 什么是<code>tf.nn.relu</code> ？ 在将摄氏度转换为华氏度时，我们在先前的神经网络示例中未使用此功能！ 最重要的是，当前任务要比用作事实调查示例的任务复杂得多-将摄氏温度转换为华氏温度。 <br><br>  <code>ReLU</code>是一种数学函数，可添加到完全连接的层中，从而为网络提供更多功能。 实际上，这是对我们全连接层的一个小扩展，它使我们的神经网络能够解决更复杂的问题。 我们不会详细介绍，但是可以在下面找到一些更详细的信息。 <br><br> 最后，我们的最后一层，也称为输出层，由10个神经元组成。 它包含10个神经元，因为我们的Fashion MNIST数据集包含10个服装类别。 这10个输出值中的每一个将代表输入图像在此服装类别中的可能性。 换句话说，这些值反映了模型对输出图像中的10种服装类别中的特定类别的预测和相关性的正确性的模型“信心”。 例如，图像显示衣服，运动鞋，鞋子等的可能性是多少？ <br><br><img src="https://habrastorage.org/webt/fo/2b/3v/fo2b3vakws6ubmiwtj9rrctltla.png"><br><br> 例如，如果将衬衫图像输入到我们的神经网络的输入中，则该模型可以为我们提供类似于您在上图中看到的结果-输入图像与输出标签匹配的概率。 <br><br> 如果您注意的话，您会发现最大的可能性-0.85表示标签6，它对应于衬衫。 该模特是85％确保衬衫上的图像。 通常，看起来像衬衫的事物也将具有较高的概率等级，而最不相似的事物将具有较低的概率等级。 <br><br> 由于所有10个输出值都对应于概率，因此在将所有这些值求和时，我们得到1。这10个值也称为概率分布。 <br><br> 现在，我们需要一个输出层来计算每个标签的概率。 <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br> 我们将使用以下命令执行此操作： <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax)</code> </pre><br> 实际上，无论何时创建解决分类问题的神经网络，我们都始终使用完全连接的层作为神经网络的最后一层。 神经网络的最后一层应包含等于类数的神经元，我们确定其<code>softmax</code>并使用softmax激活函数。 <br><br><h3>  <code>ReLU</code>神经元激活功能 </h3><br> 在本课程中，我们将<code>ReLU</code>视为可以扩展神经网络功能并为其提供附加功能的东西。 <br><br>  <code>ReLU</code>是一个数学函数，如下所示： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/691/c04/e7b/691c04e7b270706458daf61c4b38cf22.png" alt="图片"><br><br> 如果输入值为负值，则<code>ReLU</code>函数返回0或为零，在所有其他情况下，该函数将返回原始输入值。 <br><br>  <code>ReLU</code>使解决非线性问题成为可能。 <br><br> 将摄氏度转换为华氏度是一项线性任务，因为表达式<code>f = 1.8*c + 32</code>是线的方程<code>y = m*x + b</code> 。 但是，我们要解决的大多数任务都是非线性的。 在这种情况下，将ReLU激活功能添加到我们的全连接层可以帮助完成此类任务。 <br><br>  <code>ReLU</code>只是激活功能的一种。 有诸如S形，ReLU，ELU，tanh的激活函数，但是， <code>ReLU</code>最常被用作默认激活函数。 要构建和使用包含ReLU的模型，您无需了解它在内部如何工作。 如果您仍然想更好地理解，那么我们建议您阅读<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">本文</a> 。 <br><br> 让我们回顾一下本课中介绍的新术语： <br><br><ul><li>  <b>平滑</b> -将2D图像转换为1D矢量的过程； </li><li>  <b>ReLU</b>是一个激活函数，可以使模型解决非线性问题。 </li><li>  <b>Softmax-</b>计算每种可能的输出类别的概率的函数； </li><li>  <b>分类</b> -一类机器学习任务，用于确定两个或多个类别（类）之间的差异。 </li></ul><br><h2> 培训与测试 </h2><br> 训练模型（机器学习中的任何模型）时，始终有必要将数据集至少分为两个不同的集-用于训练的数据集和用于测试的数据集。 在这一部分中，我们将理解为什么值得这样做。 <br><br> 让我们记住如何分发来自Fashion MNIST的数据集，该数据集由70,000个副本组成。 <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br> 我们建议将70,000分为两部分-在第一部分中，保留60,000进行培训，在第二部分中保留10,000进行测试。 这种方法的必要性是由以下事实引起的：在对模型进行了60,000份训练之后，有必要检查尚未在训练模型的数据集中得到的示例的结果和工作有效性。 <br><br> 就其自身而言，它类似于在学校通过考试。 在通过考试之前，您要努力解决特定班级的问题。 然后，在考试中，您会遇到同一类问题，但输入数据却不同。 提交与培训期间相同的数据是没有意义的，否则，任务将减少为记住决策，而不是找到解决方案模型。 这就是为什么在考试中您会面临课程中以前没有的任务。 只有这样，我们才能验证模型是否已经学习了通用解。 <br><br> 机器学习也会发生同样的事情。 您将显示一些数据，这些数据代表您要学习如何解决的特定类别的任务。 在我们的案例中，使用来自Fashion MNIST的数据集，我们希望神经网络能够确定图像中服装元素所属的类别。 这就是为什么我们在60,000个包含所有类别服装的示例上训练模型的原因。 训练后，我们要检查模型的有效性，因此我们提供模型尚未“看到”的剩余10,000件衣物。 如果我们决定不这样做，而不用10,000个示例进行测试，我们将无法确定地说我们的模型是否经过实际训练来确定服装的类别，或者她是否记住了所有输入和输出值对。 <br><br> 这就是为什么在机器学习中我们总是有一个训练数据集和一个测试数据集的原因。 <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow</a>是现成的培训数据的集合。 <br><br> 数据集通常分为几个块，每个块都用于训练和测试神经网络有效性的某个阶段。 在这一部分中，我们讨论： <br><br><ul><li>  <b>训练数据集</b> ：旨在训练神经网络的数据集； </li><li>  <b>测试数据集</b> ：旨在验证神经网络效率的数据集； </li></ul><br> 考虑另一个数据集，我称之为验证数据集。 此数据集仅<b>在</b>训练<b>期间</b>不用于训练模型。 因此，在我们的模型经过几个训练周期后，我们将其提供给我们的测试数据集并查看结果。 例如，如果在训练过程中损失函数的值减小，并且测试数据集的准确性下降，则意味着我们的模型仅简单地记住成对的输入输出值。 <br><br> 验证数据集将在训练结束时重新使用，以测量模型预测的最终准确性。 <br><br> 有关<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">培训和测试数据集的</a>更多<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">信息，请参阅Google Crash课程</a> 。 <br><br><h2>  CoLab的实践部分 </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">链接到原始的英语CoLab</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">链接到Russian CoLab</a> 。 <br><br><h2> 衣物图像分类 </h2><br> 在本部分课程中，我们将构建和训练一个神经网络，以对服装元素的图像进行分类，例如衣服，运动鞋，衬衫，T恤等。 <br><br> 如果片刻不清楚，没关系。 本课程的目的是向您介绍TensorFlow，同时解释其工作算法，并使用TensorFlow形成对项目的共识，而不是深入研究实现细节。 <br><br> 在本部分中，我们使用<code>tf.keras</code> ，这是一个用于在TensorFlow中构建和训练模型的高级API。 <br><br><h3> 安装和导入依赖项 </h3><br> 我们将需要<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow数据集</a> ，该API可以简化加载和访问由多种服务提供的数据集的过程。 我们还将需要一些辅助库。 <br><br><pre> <code class="python hljs">!pip install -U tensorflow_datasets</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-comment"><span class="hljs-comment">#  TensorFlow    TensorFlow import tensorflow as tf import tensorflow_datasets as tfds tf.logging.set_verbosity(tf.logging.ERROR) #   import math import numpy as np import matplotlib.pyplot as plt #    import tqdm import tqdm.auto tqdm.tqdm = tqdm.auto.tqdm print(tf.__version__) tf.enable_eager_execution()</span></span></code> </pre><br><h3> 导入Fashion MNIST数据集 </h3><br> 此示例使用Fashion MNIST数据集，该数据集包含10个类别的灰度的70,000张服装项目图像。 图像包含低分辨率（28x28像素）的衣物，如下所示： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/2c1/da3/18d2c1da3b5c7dbff14ea81077d9ed24.png" alt="图片"><br><br> 时尚MNIST被用来替代经典MNIST数据集-最常被用作“ Hello，World！” 在机器学习和计算机视觉方面。  MNIST数据集包含手写数字（0、1、2等）的图像，其格式与本例中的服装相同。 <br><br> 在我们的示例中，我们使用Fashion MNIST是因为其种类繁多，并且因为从实现的角度来看，此任务比解决MNIST数据集上的典型问题更为有趣。 这两个数据集都足够小，因此，它们用于检查算法的正确可操作性。 强大的数据集，可用于开始学习机器学习，测试和调试代码。 <br><br> 我们将使用60,000张图像来训练网络，并使用10,000张图像来测试训练和图像分类的准确性。 您可以使用API​​通过TensorFlow直接访问Fashion MNIST数据集： <br><br><pre> <code class="python hljs">dataset, metadata = tfds.load(<span class="hljs-string"><span class="hljs-string">'fashion_mnist'</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_dataset, test_dataset = dataset[<span class="hljs-string"><span class="hljs-string">'train'</span></span>], dataset[<span class="hljs-string"><span class="hljs-string">'test'</span></span>]</code> </pre><br> 通过加载数据集，我们可以获得元数据，训练数据集和测试数据集。 <br><br><ul><li> 在来自“ train_dataset”的数据集上训练模型 </li><li> 在来自test_dataset的数据集上测试了模型 </li></ul><br> 图片是二维<code>2828</code>数组，其中每个单元格中的值可以在<code>[0, 255]</code>区间内。 标签-一个整数数组，其中每个值都在<code>[0, 9]</code>区间内。 这些标签对应于输出图像类，如下所示： <br><br><div class="scrollable-table"><table><tbody><tr><th> 标签 </th><th> 班级 </th></tr><tr><td>  0 </td><td>  T恤/上衣 </td></tr><tr><td>  1个 </td><td> 短裤 </td></tr><tr><td>  2 </td><td> 毛衣 </td></tr><tr><td>  3 </td><td> 着装 </td></tr><tr><td>  4 </td><td> 披风 </td></tr><tr><td>  5 </td><td> 凉鞋 </td></tr><tr><td>  6 </td><td> 上衣 </td></tr><tr><td>  7 </td><td> 运动鞋 </td></tr><tr><td>  8 </td><td> 包袋 </td></tr><tr><td>  9 </td><td> 开机 </td></tr></tbody></table></div><br><br> 每个图像都属于一个标签。 由于类名称不包含在原始数据集中，因此在绘制图像时将其保存以备将来使用： <br><br><pre> <code class="python hljs">class_names = [<span class="hljs-string"><span class="hljs-string">' / '</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>]</code> </pre><br><h4> 我们研究数据 </h4><br> 在训练模型之前，让我们研究训练集中呈现的数据的格式和结构。 以下代码将显示训练数据集中有60,000张图像，测试数据集中有10,000张图像： <br><br><pre> <code class="python hljs">num_train_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'train'</span></span>].num_examples num_test_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'test'</span></span>].num_examples print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_train_examples)) print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_test_examples))</code> </pre><br><h3> 数据预处理 </h3><br> 图像中每个像素的值在<code>[0,255]</code>范围内。 为了使模型正常工作，必须将这些值归一化-减小为<code>[0,1]</code>间隔内的值。 因此，稍稍降低一点，我们声明并实现归一化功能，然后将其应用于训练和测试数据集中的每个图像。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normalize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images, labels)</span></span></span><span class="hljs-function">:</span></span> images = tf.cast(images, tf.float32) images /= <span class="hljs-number"><span class="hljs-number">255</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> images, labels <span class="hljs-comment"><span class="hljs-comment">#  map         #      train_dataset = train_dataset.map(normalize) test_dataset = test_dataset.map(normalize)</span></span></code> </pre><br><h4> 我们研究处理后的数据 </h4><br> 让我们画一个图像来看看它： <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          #   reshape() for image, label in test_dataset.take(1): break; image = image.numpy().reshape((28, 28)) #   plt.figure() plt.imshow(image, cmap=plt.cm.binary) plt.colorbar() plt.grid(False) plt.show()</span></span></code> </pre><br><img src="https://habrastorage.org/webt/ce/se/hw/cesehwjbca_ol0s1dcpxnaxyu2i.png"><br><br> 我们显示训练数据集中的前25个图像，并在每个图像下方指示其所属的类别。 <br><br> 确保数据格式正确，我们准备开始创建和训练网络。 <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) i = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (image, label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">25</span></span>): image = image.numpy().reshape((<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,i+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.xticks([]) plt.yticks([]) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.imshow(image, cmap=plt.cm.binary) plt.xlabel(class_names[label]) i += <span class="hljs-number"><span class="hljs-number">1</span></span> plt.show()</code> </pre><br><img src="https://habrastorage.org/webt/4h/_v/s7/4h_vs7mj97mmqknia5mpnzaqfis.png"><br><br><h4> 建立模型 </h4><br> 建立神经网络需要调整图层，然后组装具有优化和损失函数的模型。 <br><br><h4> 自定义图层 </h4><br> 建立神经网络的基本元素是层。 该层从输入数据中提取视图。 通过多层连接的工作结果，我们得到了解决该问题的观点。 <br><br> 大多数时候，您在进行深度学习时都会在简单层之间创建链接。 例如，大多数图层，例如tf.keras.layers.Dense，都有一组可以在学习过程中“拟合”的参数。 <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br> 网络由三层组成： <br><br><ul><li>  <b>输入</b> <code>tf.keras.layers.Flatten</code>此层将尺寸为28x28像素的图像转换为尺寸为784（28 * 28）的一维数组。 在这一层上，我们没有用于训练的参数，因为该层仅处理输入数据的转换。 </li><li>  <b>隐藏层</b> <code>tf.keras.layers.Dense</code> -128个神经元的紧密连接层。 每个神经元（节点）都将前一层的所有784个值作为输入，在训练过程中根据内部权重和位移来更改输入值，然后将单个值返回到下一层。 </li><li>  <b>输出层</b> <code>ts.keras.layers.Dense</code> - <code>softmax</code>由10个神经元组成，每个神经元代表一类特定的服装元素。 与上一层一样，每个神经元都接收上一层所有128个神经元的输入值。 在训练过程中，该层上每个神经元的权重和位移都会发生变化，因此结果值的范围为<code>[0,1]</code> ，表示图像属于此类的概率。  10个神经元的所有输出值的总和为1。 </li></ul><br><h4> 编译模型 </h4><br> 在我们开始训练模型之前，还需要进行一些设置。 这些设置是在模型组装期间通过调用compile方法进行的： <br><br><ul><li>  <b>损失函数</b> -一种用于测量所需值与预测值之间距离的算法。 </li><li>  <b>优化函数</b> -一种“拟合”模型内部参数（权重和偏移量）以最小化损失函数的算法； </li><li>  <b>指标</b> -用于监视培训过程和测试。 下面的示例使用诸如<code></code> ，已正确分类的图像百分比之类的指标。 </li></ul><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><h3> 我们训练模型 </h3><br> 首先，我们根据训练数据集确定训练过程中的动作顺序： <br><br><ol><li> 使用<code>dataset.repeat()</code>方法将输入数据集重复无数次<code>dataset.repeat()</code>以下描述的<code>epochs</code>参数确定要执行的所有训练迭代的次数） </li><li>  <code>dataset.shuffle(60000)</code>方法混合了所有图像，因此我们模型的训练不受输入数据输入顺序的影响。 </li><li>  <code>model.fit</code> <code>dataset.batch(32)</code>方法告诉<code>model.fit</code>训练<code>model.fit</code>更新模型的内部变量时都使用32个图像的块和标签。 </li></ol><br> 通过调用<code>model.fit</code>方法进行培训： <br><br><ul><li> 将<code>train_dataset</code>发送到模型输入。 </li><li> 该模型学习将输入图像与标签匹配。 </li><li> 参数<code>epochs=5</code>将训练次数限制为对数据集进行5次完整训练迭代，最终使我们可以进行5 * 60,000 = 300,000个示例的训练。 </li></ul><br>  （您可以忽略<code>steps_per_epoch</code>参数，不久该参数将被从方法中排除）。 <br><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE) test_dataset = test_dataset.batch(BATCH_SIZE)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))</code> </pre><br> 这是结论： <br><br> <code>Epoch 1/5 <br> 1875/1875 [==============================] - 26s 14ms/step - loss: 0.4921 - acc: 0.8267 <br> Epoch 2/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3652 - acc: 0.8686 <br> Epoch 3/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3341 - acc: 0.8782 <br> Epoch 4/5 <br> 1875/1875 [==============================] - 19s 10ms/step - loss: 0.3111 - acc: 0.8858 <br> Epoch 5/5 <br> 1875/1875 [==============================] - 16s 8ms/step - loss: 0.2911 - acc: 0.8922 <br></code> <br> 在模型训练期间，将为每次训练迭代显示损失函数的值和准确性度量。 该模型在训练数据上达到约0.88（88％）的精度。 <br><br><h4> 检查准确性 </h4><br> 让我们检查一下模型在测试数据上产生的精度。 我们将使用测试数据集中的所有示例来检查准确性。 <br><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE)) print(<span class="hljs-string"><span class="hljs-string">"    : "</span></span>, test_accuracy)</code> </pre><br> 结论： <br><br> <code>313/313 [==============================] - 1s 5ms/step - loss: 0.3440 - acc: 0.8793 <br>     : 0.8793 <br></code> <br><br> 如您所见，结果证明测试数据集的准确性小于训练数据集的准确性。 这是很正常的，因为模型是在train_dataset数据上训练的。 当模型发现一个从未见过的图像时（来自train_dataset数据集），显然分类效率会降低。 <br><br><h3> 预测和探索 </h3><br> 我们可以使用经过训练的模型来获得一些图像的预测。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> test_images, test_labels <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): test_images = test_images.numpy() test_labels = test_labels.numpy() predictions = model.predict(test_images)</code> </pre><br><pre> <code class="python hljs">predictions.shape</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">结论：</font><font style="vertical-align: inherit;">在上面的示例中，模型为每个测试输入图像预测了标签。</font><font style="vertical-align: inherit;">让我们看一下第一个预测：</font></font><br><br> <code>(32, 10) <br></code> <br><br><font style="vertical-align: inherit;"></font><br><br><pre> <code class="python hljs">predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 结论： </font></font><br><br><pre> <code class="python hljs">array([<span class="hljs-number"><span class="hljs-number">3.1365351e-05</span></span>, <span class="hljs-number"><span class="hljs-number">9.0029374e-08</span></span>, <span class="hljs-number"><span class="hljs-number">5.0016739e-03</span></span>, <span class="hljs-number"><span class="hljs-number">6.3597057e-05</span></span>, <span class="hljs-number"><span class="hljs-number">6.8342477e-02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span>, <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span>, <span class="hljs-number"><span class="hljs-number">1.8982398e-09</span></span>, <span class="hljs-number"><span class="hljs-number">8.4999456e-06</span></span>, <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>], dtype=float32)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回想一下，模型预测是10个值的数组。</font><font style="vertical-align: inherit;">这些值描述了模型对输入图像属于特定类别（服装项目）的“信心”。</font><font style="vertical-align: inherit;">我们可以看到最大值如下：</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 结论： </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">这意味着模型最有信心该图像属于标记为6的类（class_names [6]）。</font><font style="vertical-align: inherit;">我们可以检查并确保结果正确，并且正确无误：</font></font><br><br><pre> <code class="python hljs">test_labels[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 我们可以显示所有输入图像以及10类的相应模型预测： </font></font><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_labels, images)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label, img = predictions_array[i], true_label[i], images[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) plt.imshow(img[...,<span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=plt.cm.binary) predicted_label = np.argmax(predictions_array) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_label == true_label: color = <span class="hljs-string"><span class="hljs-string">'blue'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: color = <span class="hljs-string"><span class="hljs-string">'red'</span></span> plt.xlabel(<span class="hljs-string"><span class="hljs-string">"{} {:2.0f}% ({})"</span></span>.format(class_names[predicted_label], <span class="hljs-number"><span class="hljs-number">100</span></span> * np.max(predictions_array), class_names[true_label]), color=color) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_value_array</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_label)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label = predictions_array[i], true_label[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) thisplot = plt.bar(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), predictions_array, color=<span class="hljs-string"><span class="hljs-string">"#777777"</span></span>) plt.ylim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) predicted_label = np.argmax(predictions_array) thisplot[predicted_label].set_color(<span class="hljs-string"><span class="hljs-string">'red'</span></span>) thisplot[true_label].set_color(<span class="hljs-string"><span class="hljs-string">'blue'</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 让我们看一下第0张图像，模型的预测结果和预测数组。 </font></font><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">0</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/fc/7i/ef/fc7iefucuvtopx4_avluy-rq1ei.png"><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">12</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/n0/2y/tj/n02ytjjdkeubvkqvjdusbkwoemy.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">现在让我们显示一些带有各自预测的图像。</font><font style="vertical-align: inherit;">正确的预测为蓝色，错误的预测为红色。</font><font style="vertical-align: inherit;">图像下方的值反映输入图像对应于此类的置信度百分比。</font><font style="vertical-align: inherit;">请注意，即使“ confidence”值很高，结果也可能不正确。</font></font><br><br><pre> <code class="python hljs">num_rows = <span class="hljs-number"><span class="hljs-number">5</span></span> num_cols = <span class="hljs-number"><span class="hljs-number">3</span></span> num_images = num_rows * num_cols plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_rows)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_images): plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/m1/11/je/m111jevw7ptxblu2ccmlwmtonva.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 使用训练有素的模型来预测单个图像的标签： </font></font><br><br><pre> <code class="python hljs">img = test_images[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 结论： </font></font><br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">中的模型</font></font><code>tf.keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">针对按块（集合）的预测</font><font style="vertical-align: inherit;">进行了</font><font style="vertical-align: inherit;">优化。</font><font style="vertical-align: inherit;">因此，尽管事实是我们只使用一个元素，但仍需要将其添加到列表中：</font></font><br><br><pre> <code class="python hljs">img = np.array([img]) print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">结论：</font></font><br><br> <code>(1, 28, 28, 1)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">现在我们将预测结果：</font></font><br><br><pre> <code class="python hljs">predictions_single = model.predict(img) print(predictions_single)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 结论： </font></font><br><br><pre> <code class="python hljs">[[<span class="hljs-number"><span class="hljs-number">3.1365438e-05</span></span> <span class="hljs-number"><span class="hljs-number">9.0029722e-08</span></span> <span class="hljs-number"><span class="hljs-number">5.0016833e-03</span></span> <span class="hljs-number"><span class="hljs-number">6.3597123e-05</span></span> <span class="hljs-number"><span class="hljs-number">6.8342514e-02</span></span> <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span> <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.8982469e-09</span></span> <span class="hljs-number"><span class="hljs-number">8.4999692e-06</span></span> <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>]]</code> </pre><br><pre> <code class="python hljs">plot_value_array(<span class="hljs-number"><span class="hljs-number">0</span></span>, predictions_single, test_labels) _ = plt.xticks(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), class_names, rotation=<span class="hljs-number"><span class="hljs-number">45</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/eo/vw/sl/eovwslxcn_ldtj2abz870ninw4g.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">model.predict方法返回列表列表（数组的数组），每个列表用于输入块中的图像。</font><font style="vertical-align: inherit;">对于单个输入图像，我们得到唯一的结果：</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions_single[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 结论： </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 如前所述，该模型预测标签6（衬衫）。 </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 练习题 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">尝试不同的模型，看看准确性将如何变化。</font><font style="vertical-align: inherit;">特别是，请尝试更改以下设置：</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 将epochs参数设置为1； </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 例如，将隐藏层中的神经元数量从10的低值更改为512，并查看预测模型的准确性将如何变化； </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 在平坦层（平滑层）和最终的致密层之间添加其他层，并在该层上试验神经元的数量； </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 不要标准化像素值，看看会发生什么。 </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">请记住激活GPU，以便所有计算都更快（</font></font><code>Runtime -&gt; Change runtime type -&gt; Hardware accelertor -&gt; GPU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font><font style="vertical-align: inherit;">另外，如果在操作过程中遇到问题，请尝试重置全局环境设置：</font></font><br><br><ul><li> <code>Edit -&gt; Clear all outputs</code> </li> <li> <code>Runtime -&gt; Reset all runtimes</code> </li> </ul><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 摄氏度VS MNIST </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-在这一阶段，我们已经遇到了两种类型的神经网络。我们的第一个神经网络学习了如何将摄氏温度转换为华氏温度，并返回可以在广泛数值范围内的单个值。</font></font><br><br><img src="https://habrastorage.org/webt/o8/ag/_t/o8ag_trkedahoa0ftg3pstkirt4.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们的第二个神经网络返回10个概率值，这些值反映了网络对输入图像对应于特定类别的信心。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">神经网络可用于解决各种问题。</font></font><br><br><img src="https://habrastorage.org/webt/no/0v/jo/no0vjoulnrva_-bky0uauc3tesi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们通过预测单个值解决的第一类问题称为</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回归</font></font></b> .             .              ,  ,    . <br><br>   ,           ,  <b></b> .        («»   ,      ).       ,      10 ,       ,     —   ,       . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">让我们总结并注意这两类问题之间的区别- </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回归</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分类</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br><br><img src="https://habrastorage.org/webt/_c/wj/qu/_cwjquy9ivk-s3zma34qamyakoq.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">恭喜，您已经研究了两种类型的神经网络！为下一次演讲做准备，在那里我们将学习一种新型的神经网络-卷积神经网络（CNN）。</font></font><br><br><h3> 总结 </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在本课程中，我们训练了神经网络对服装元素进行图像分类。为此，我们使用了Fashion MNIST数据集，其中包含70,000张服装图片。其中60,000个我们用来训练神经网络，其余的10,000个用来测试其工作的有效性。为了将这些图像提交到神经网络的输入，我们需要将它们从28x28 2D格式转换（平滑）为784个元素的1D格式。我们的网络由128个神经元的完全连接层和10个神经元的输出层组成，对应于标签的数量（类别，服装项目类别）。这10个输出值代表每个类别的概率分布。</font><i><font style="vertical-align: inherit;">Softmax</font></i><font style="vertical-align: inherit;">激活</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">功能</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">计算概率分布。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们还了解了</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回归</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分类</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">之间的区别</font><font style="vertical-align: inherit;">。</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回归</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：返回单个值（例如房屋价值）的模型。</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分类</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：返回几个类别之间的概率分布的模型。</font><font style="vertical-align: inherit;">例如，在我们与Fashion MNIST的任务中，输出值为10个概率值，每个概率值都与特定类别（服装项目类别）相关联。</font><font style="vertical-align: inherit;">我提醒您，我们使用</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">激活函数</font><font style="vertical-align: inherit;">只是为了获得最后一层的概率分布。</font></font></li></ul><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">文章的视频版本</font></font></b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 该视频在发布几天后发布，并已添加到文章中。 </font></font><br></div></div><br>  ...和标准号召性用语-注册，加号并分享:) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">YouTube的</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">电报</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN454034/">https://habr.com/ru/post/zh-CN454034/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN454018/index.html">iOS摘要6（5月17日至5月30日）</a></li>
<li><a href="../zh-CN454024/index.html">STM32F334C8T6上的MPPT充电控制器</a></li>
<li><a href="../zh-CN454028/index.html">使用PHP Russia 2019进行草图绘制：简洁的代码，黑暗的魔术</a></li>
<li><a href="../zh-CN454030/index.html">Odigest：本周的设计师感兴趣</a></li>
<li><a href="../zh-CN454032/index.html">路由器和数据传递Clean Swift体系结构</a></li>
<li><a href="../zh-CN454036/index.html">解决现成解决方案并降低一百万或两百万的6种方法</a></li>
<li><a href="../zh-CN454038/index.html">Ilya Zverev：多年来，OpenStreetMap获得了如此严格的基础架构，您可以在不离开家的情况下绘制地图</a></li>
<li><a href="../zh-CN454040/index.html">React Russia 2019会议已经在6月1日</a></li>
<li><a href="../zh-CN454042/index.html">付您想要的钱：这个模特如何在音乐中崭露头角，以及谁试图那样赚钱</a></li>
<li><a href="../zh-CN454044/index.html">iPad和iPhone上的创意</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöê üõåüèæ üñïüèª Der weichste und pelzigste Weg in maschinellem Lernen und tiefen neuronalen Netzen üßï ‚òÉÔ∏è üë®üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Modernes maschinelles Lernen erm√∂glicht es Ihnen, unglaubliche Dinge zu tun. Neuronale Netze arbeiten zum Wohle der Gesellschaft: Sie finden Kriminell...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Der weichste und pelzigste Weg in maschinellem Lernen und tiefen neuronalen Netzen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/470904/">  Modernes maschinelles Lernen erm√∂glicht es Ihnen, unglaubliche Dinge zu tun.  Neuronale Netze arbeiten zum Wohle der Gesellschaft: Sie finden Kriminelle, erkennen Bedrohungen, helfen bei der Diagnose von Krankheiten und treffen schwierige Entscheidungen.  Algorithmen k√∂nnen eine Person in ihrer Kreativit√§t √ºbertreffen: Sie malen Bilder, schreiben Lieder und machen aus gew√∂hnlichen Bildern Meisterwerke.  Und diejenigen, die diese Algorithmen entwickeln, werden oft als karikierte Wissenschaftler dargestellt. <br><br>  Nicht alles ist so be√§ngstigend!  Jeder, der mit Programmierung vertraut ist, kann aus Grundmodellen ein neuronales Netzwerk aufbauen.  Und es ist nicht einmal notwendig, Python zu lernen, alles kann in nativem JavaScript gemacht werden.  Es ist einfach, loszulegen und warum maschinelles Lernen f√ºr Front-End- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Anbieter erforderlich</a> ist, sagte <strong>Aleksey Okhrimenko</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">obenjiro</a> ) von FrontendConf, und wir haben es auf den Text √ºbertragen, sodass Architekturnamen und n√ºtzliche Links zur Hand waren. <br><br><h2>  Spoiler.  Alarm! </h2><br>  Diese Geschichte: <br><br><ul><li> <strong>Nicht f√ºr diejenigen, die bereits</strong> mit maschinellem Lernen arbeiten.  Etwas Interessantes wird sein, aber es ist unwahrscheinlich, dass Sie unter dem Schnitt auf die Er√∂ffnung warten. </li><li>  <strong>Nicht √ºber Transferlernen.</strong>  Wir werden nicht dar√ºber sprechen, wie man ein neuronales Netzwerk in Python schreibt und dann mit JavaScript damit arbeitet.  Keine Cheats - wir werden tiefe neuronale Netze speziell f√ºr JS schreiben. </li><li>  <strong>Nicht alle Details.</strong>  Im Allgemeinen passen nicht alle Konzepte in einen Artikel, aber wir werden nat√ºrlich das Notwendige analysieren. </li></ul><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BX2M8t5BA3s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>√úber den Redner:</strong> Alexei Okhrimenko arbeitet bei Avito in der Abteilung Frontend Architecture und leitet in seiner Freizeit das Angular Moscow Meetup und ver√∂ffentlicht das ‚ÄûFive Minute Angular‚Äú.  Im Laufe seiner langen Karriere hat er das Designmuster MALEVICH entwickelt, den PEG-Grammatik-Parser SimplePEG.  Der CSSComb-Betreuer von Alexey teilt regelm√§√üig sein Wissen √ºber neue Technologien auf Konferenzen und in seinem JS- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Telegrammkanal f√ºr</a> maschinelles Lernen. <br><br><h2>  Maschinelles Lernen ist sehr beliebt. </h2><br>  Sprachassistenten, Siri, Google Assistant, Alice, sind beliebt und h√§ufig in unserem Leben anzutreffen.  Viele Produkte haben von der herk√∂mmlichen algorithmischen Datenverarbeitung auf maschinelles Lernen umgestellt.  Ein markantes Beispiel ist Google Translate. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/cg/uz/z3cguzzlmogpjxmymmqhok5xw50.jpeg"></div><br>  Alle Innovationen und die coolsten Chips in Smartphones basieren auf maschinellem Lernen. <br><br><img src="https://habrastorage.org/webt/qd/2m/1g/qd2m1gmmouw29qcfbytgd5gdcoc.jpeg"><br><br>  Beispielsweise verwendet Google NightSight maschinelles Lernen.  Die coolen Fotos, die wir sehen, wurden nicht mit Objektiven, Sensoren oder Stabilisierung aufgenommen, sondern mit Hilfe des maschinellen Lernens.  Die Maschine hat schlie√ülich die Leute in DOTA2 geschlagen, was bedeutet, dass wir kaum eine Chance haben, k√ºnstliche Intelligenz zu besiegen.  Deshalb m√ºssen wir maschinelles Lernen so schnell wie m√∂glich beherrschen. <br><br><h2>  Beginnen wir mit einem einfachen </h2><br>  Was ist unsere t√§gliche Programmierroutine, wie schreiben wir normalerweise Funktionen? <br><img src="https://habrastorage.org/webt/n1/kn/ss/n1knssbigatyl2zrakkoaazsuai.jpeg"><br>  Wir nehmen die Daten und den Algorithmus, die wir selbst erfunden oder von popul√§ren fertigen √ºbernommen haben, kombinieren, zaubern ein wenig und erhalten eine Funktion, die uns in einer bestimmten Situation die richtige Antwort gibt. <br><br>  Wir sind an diese Reihenfolge gew√∂hnt, aber es w√ºrde eine solche Gelegenheit geben, ohne den Algorithmus zu kennen, aber einfach die Daten und die Antwort zu haben, um den Algorithmus von ihnen zu erhalten. <br><br><img src="https://habrastorage.org/webt/tq/6p/4w/tq6p4wwa4ctyhg_j7a4b_t2dhl0.jpeg"><br><br>  Sie k√∂nnen sagen: "Ich bin Programmierer, ich kann immer einen Algorithmus schreiben." <br><br>  Ok, aber zum Beispiel, welcher Algorithmus wird hier ben√∂tigt? <br><br><img src="https://habrastorage.org/webt/mq/ey/ce/mqeycerayzppkiqobxr_-o13oka.jpeg"><br><br>  Angenommen, die Katze hat scharfe Ohren und die Ohren des Hundes sind stumpf, klein wie ein Mops. <br><br><img src="https://habrastorage.org/webt/nv/dp/-h/nvdp-h5hvyset6n3fz-q6ya03hs.jpeg"><br><br>  Versuchen wir an den Ohren zu verstehen, wer wer ist.  Aber irgendwann stellen wir fest, dass Hunde scharfe Ohren haben k√∂nnen. <br><br><img src="https://habrastorage.org/webt/uk/j2/pr/ukj2prwe9ln0hdjj6x0qa5q9vxw.jpeg"><br><br>  Unsere Hypothese ist nicht gut, wir brauchen andere Eigenschaften.  Im Laufe der Zeit werden wir immer mehr Details erfahren und uns dadurch immer mehr demotivieren, und irgendwann werden wir dieses Gesch√§ft ganz aufgeben wollen. <br><br>  Ich stelle mir ein ideales Bild wie dieses vor: Im Voraus gibt es eine Antwort (wir wissen, um welche Art von Bild es sich handelt), es gibt Daten (wir wissen, dass eine Katze gezeichnet ist), wir m√∂chten einen Algorithmus erhalten, der Daten f√ºttert und Antworten am Ausgang erh√§lt. <br><br>  Es gibt eine L√∂sung - dies ist maschinelles Lernen, n√§mlich einer seiner Teile - tiefe neuronale Netze. <br><br><h2>  Tiefe neuronale Netze </h2><br>  Maschinelles Lernen ist ein riesiger Bereich.  Es bietet eine gigantische Menge an Methoden, und jede ist auf ihre Weise gut. <br><br><img src="https://habrastorage.org/webt/qv/8t/kj/qv8tkjpyrk_qeia-hp4fxkvco7w.jpeg"><br><br>  Eines davon ist Deep Neural Networks.  Deep Learning hat einen unbestreitbaren Vorteil, aufgrund dessen es popul√§r geworden ist. <br><br>  Um diesen Vorteil zu verstehen, betrachten wir das klassische Klassifizierungsproblem am Beispiel von Katzen und Hunden. <br><br>  Es gibt Daten: Bilder oder Fotos.  Das erste, was zu tun ist, ist das Einbetten (Einbetten), dh das Transformieren der Daten, damit die Maschine bequem mit ihnen arbeiten kann.  Es ist unpraktisch, mit Bildern zu arbeiten, das Auto braucht etwas Einfacheres. <br><br>  Richten Sie zuerst die Bilder aus und entfernen Sie die Farbe.  Unabh√§ngig von der Farbe des Hundes oder der Katze ist es wichtig, die Art des Tieres zu bestimmen.  Dann verwandeln wir die Bilder in Arrays, in denen beispielsweise 0 dunkel und 1 hell ist. <br><br><img src="https://habrastorage.org/webt/th/st/aq/thstaqtmxfb1jqo-eacmrtlaxym.jpeg"><br><br>  Mit dieser Darstellung von Daten k√∂nnen neuronale Netze bereits funktionieren. <br><br>  Lassen Sie uns zwei weitere Arrays erstellen und diese zu einer bestimmten ‚ÄûEbene‚Äú zusammenf√ºhren.  Als n√§chstes werden wir jedes der Elemente der Schicht und des Datenarrays unter Verwendung einer einfachen Matrixmultiplikation miteinander multiplizieren und das Ergebnis in zwei Aktivierungsfunktionen umleiten (sp√§ter werden wir analysieren, was diese Funktionen sind).  Wenn die Aktivierungsfunktion eine ausreichende Anzahl von Werten empf√§ngt, wird sie "aktiviert" und f√ºhrt zu folgendem Ergebnis: <br><br><ul><li>  Die erste Funktion gibt 1 zur√ºck, wenn es sich um eine Katze handelt, und 0, wenn es sich nicht um eine Katze handelt. </li><li>  Die zweite Funktion gibt 1 zur√ºck, wenn es sich um einen Hund handelt, und 0, wenn es sich nicht um einen Hund handelt. </li></ul><br>  Dieser Ansatz zum Codieren einer Antwort wird als <strong>One-Hot-Codierung bezeichnet</strong> . <br><br><img src="https://habrastorage.org/webt/bb/-a/x5/bb-ax5li-ngkav87ibjjazse6m4.jpeg"><br><br>  Einige Merkmale tiefer neuronaler Netze sind bereits erkennbar: <br><br><ul><li>  Um mit neuronalen Netzen arbeiten zu k√∂nnen, m√ºssen Sie Daten am Eingang codieren und am Ausgang decodieren. </li><li>  Durch die Codierung k√∂nnen wir von Daten abstrahieren. </li><li>  Durch √Ñndern der Eingabedaten k√∂nnen wir neuronale Netze f√ºr verschiedene Dom√§nendom√§nen generieren.  Auch solche, in denen wir keine Experten sind. </li></ul><br>  Es ist nicht notwendig zu wissen, was eine Katze ist, was ein Hund ist.  Es reicht aus, die erforderlichen Nummern f√ºr eine zus√§tzliche Ebene auszuw√§hlen. <br><br>  Bisher bleibt nur unklar, warum diese Netzwerke als "tief" bezeichnet werden. <br>  Alles ist sehr einfach: Wir k√∂nnen eine weitere Ebene erstellen (Arrays und ihre Aktivierungsfunktionen).  Und √ºbertragen Sie das Ergebnis einer Schicht auf eine andere. <br><br><img src="https://habrastorage.org/webt/9n/8r/qh/9n8rqhrwuewcgwa17oq-beuj7r4.jpeg"><br><br>  Sie k√∂nnen so viele dieser Ebenen und ihre Funktionen zur Aktivierung aufeinander legen.  Durch die Kombination von Schichtarchitektur erhalten wir ein tiefes neuronales Netzwerk.  Seine Tiefe ist eine Vielzahl von Schichten.  Und gemeinsam als <strong>"Modell" bezeichnet.</strong> <br><br>  Nun wollen wir sehen, wie die Werte f√ºr alle diese Ebenen ausgew√§hlt werden.  Es gibt eine coole <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Visualisierung</a> , mit der Sie verstehen k√∂nnen, wie der Lernprozess abl√§uft. <br><br><img src="https://habrastorage.org/webt/aw/ot/at/awotatoajim-4vykkxk5wgldodq.jpeg"><br><br>  Links sind Daten und rechts ist eine der Ebenen.  Es ist ersichtlich, dass das √Ñndern der Werte innerhalb der Ebenenarrays das Koordinatensystem zu √§ndern scheint.  So Anpassung an die Daten und Lernen.  Lernen ist also der Prozess der Auswahl der richtigen Werte f√ºr Layer-Arrays.  Diese Werte werden als Gewichte oder Gewichte bezeichnet. <br><br><h2>  Maschinelles Lernen ist schwer </h2><br>  Ich m√∂chte dich ver√§rgern, maschinelles Lernen ist schwer.  All dies ist eine gro√üe Vereinfachung.  In Zukunft werden Sie eine gro√üe Menge linearer Algebra finden, die ziemlich komplex ist.  Leider gibt es kein Entrinnen davon. <br><br>  Nat√ºrlich gibt es Kurse, aber selbst das schnellste Training dauert mehrere Monate und ist nicht billig.  Au√üerdem m√ºssen Sie es noch selbst herausfinden.  Das Feld des maschinellen Lernens ist so stark gewachsen, dass es fast unm√∂glich ist, alles im Auge zu behalten.  Im Folgenden finden Sie beispielsweise eine Reihe von Modellen zum L√∂sen nur einer Aufgabe (Objekterkennung): <br><br><img src="https://habrastorage.org/webt/tw/bx/rs/twbxrs3-fary0wir6wd-e4x_2_i.jpeg"><br><br>  Pers√∂nlich war ich sehr demotiviert.  Ich konnte mich den neuronalen Netzen nicht n√§hern und mit ihnen arbeiten.  Aber ich habe einen Weg gefunden und m√∂chte ihn mit Ihnen teilen.  Es ist nicht revolution√§r, es gibt nichts Vergleichbares, Sie kennen es bereits. <br><br><h2>  Blackbox - Ein einfacher Ansatz </h2><br>  Es ist nicht erforderlich, alle Aspekte des maschinellen Lernens zu verstehen, um zu lernen, wie Sie neuronale Netze auf Ihre Gesch√§ftsaufgaben anwenden.  Ich werde einige Beispiele zeigen, die Sie hoffentlich inspirieren. <br><br>  F√ºr viele ist ein Auto auch eine Black Box.  Aber selbst wenn Sie nicht wissen, wie es funktioniert, m√ºssen Sie die Regeln lernen.  Beim maschinellen Lernen m√ºssen Sie also noch einige Regeln kennen: <br><br><ul><li>  Lernen Sie TensorFlow JS (Bibliothek f√ºr die Arbeit mit neuronalen Netzen). </li><li>  Lernen Sie, Modelle auszuw√§hlen. </li></ul><br>  Wir konzentrieren uns auf diese Aufgaben und beginnen mit dem Code. <br><br><h2>  Lernen durch Erstellen von Code </h2><br>  Die TensorFlow-Bibliothek wurde f√ºr eine Vielzahl von Sprachen geschrieben: Python, C / C ++, JavaScript, Go, Java, Swift, C #, Haskell, Julia, R, Scala, Rust, OCaml, Crystal.  Aber wir werden definitiv das Beste w√§hlen - JavaScript. <br><br>  TensorFlow kann durch Verbinden eines Skripts mit CDN mit unserer Seite verbunden werden: <br><br><pre><code class="javascript hljs">&lt;script src=<span class="hljs-string"><span class="hljs-string">"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"</span></span>&gt;<span class="xml"><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;/</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">script</span></span></span></span><span class="xml"><span class="hljs-tag">&gt;</span></span></span></span></code> </pre> <br>  Oder benutze npm: <br><br><ul><li>  <code>npm install @tensorflow/tfjs-node</code> - f√ºr den <code>npm install @tensorflow/tfjs-node</code> (Website); </li><li>  <code>npm install @tensorflow/tfjs-node-gpu</code> (Linux CUDA) - f√ºr die GPU, jedoch nur, wenn der Linux-Computer und die Grafikkarte die CUDA-Technologie unterst√ºtzen.  Stellen Sie sicher, dass die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CUDA-Rechenkapazit√§t</a> mit Ihrer Bibliothek √ºbereinstimmt, damit sich nicht herausstellt, dass teure Hardware nicht geeignet ist. </li><li>  <code>npm install @tensorflow/tfjs</code> ( <code>npm install @tensorflow/tfjs</code> / Browser) - f√ºr einen Browser ohne Verwendung von Node.js. </li></ul><br>  Um mit TensorFlow JS zu arbeiten, reicht es aus, eines der oben genannten Module zu importieren.  Sie werden viele Codebeispiele sehen, in die alles importiert wird.  Sie m√ºssen dies nicht tun, w√§hlen Sie nur einen aus und importieren Sie ihn. <br><br><h3>  Tensoren </h3><br>  Wenn die anf√§nglichen Daten fertig sind, m√ºssen Sie zuerst <strong>TensorFlow importieren</strong> .  Wir werden Tensorflow / tfjs-node-gpu verwenden, um die Beschleunigung aufgrund der Leistung der Grafikkarte zu erhalten. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  @tensorflow/tfjs-node-gpu  node.js const tf = require('@tensorflow/tfjs'); const a = [[1,2], [3,4]];</span></span></code> </pre> <br>  Es gibt ein zweidimensionales Datenarray - wir werden damit arbeiten. <br><br>  Als n√§chstes muss <strong>ein Tensor erstellt werden</strong> .  In diesem Fall wird ein Tensor mit Rang 2 erzeugt, dh tats√§chlich ein zweidimensionales Array.  Wir √ºbertragen die Daten und erhalten den 2x2-Tensor. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  rank-2  (/) const b = tf.tensor([[1,2], [3,4]]); console.log('shape:', b.shape); b.print()</span></span></code> </pre> <br>  Beachten Sie, dass die <code>console.log</code> aufgerufen wird und nicht <code>console.log</code> , da <code>b</code> (der von uns erstellte Tensor) kein gew√∂hnliches Objekt ist, n√§mlich der Tensor.  Er hat seine eigenen Methoden und Eigenschaften. <br><br>  Sie k√∂nnen auch einen Tensor aus einem planaren Array erstellen und seine Form im Auge behalten, sagen wir.  Das hei√üt, ein Formular - ein zweidimensionales Array - zu deklarieren, einfach ein flaches Array zu √ºbertragen und das Formular direkt anzugeben.  Das Ergebnis wird das gleiche sein. <br><br>  Aufgrund der Tatsache, dass die Daten und das Formular getrennt gespeichert werden k√∂nnen, ist es m√∂glich, die Form des Tensors zu √§ndern.  Wir k√∂nnen die <code>reshape</code> aufrufen und die Form von 2x2 auf 4x1 √§ndern. <br><br>  Der n√§chste wichtige Schritt besteht darin <strong>, die Daten auszugeben und</strong> in die reale Welt zur√ºckzugeben. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const g = tf.tensor([[1,2], [3,4]]); g.data().then((raw) =&gt; { console.log('async raw value of g:', raw); }); console.log('raw value of g:', g.dataSync()); console.log('raw multidimensional value of g:', g.arraySync());</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Code f√ºr</a> alle drei Schritte.</i> <br><br>  Die Datenmethode gibt Versprechen zur√ºck.  Nachdem es aufgel√∂st wurde, erhalten wir den unmittelbaren Wert des Rohwerts, aber asynchron.  Wenn wir m√∂chten, k√∂nnen wir es synchron abrufen, aber denken Sie daran, dass Sie hier an Leistung verlieren k√∂nnen. Verwenden Sie daher nach M√∂glichkeit asynchrone Methoden. <br><br>  Die <code>dataSync</code> Methode gibt Daten immer in einem Flat-Array-Format zur√ºck.  Und wenn wir die Daten in dem Format zur√ºckgeben m√∂chten, in dem sie im Tensor gespeichert sind, m√ºssen wir <code>arraySync</code> . <br><br><h3>  Betreiber </h3><br>  Alle Operatoren in TensorFlow sind <strong>standardm√§√üig unver√§nderlich</strong> , dh bei jeder Operation wird immer ein neuer Tensor zur√ºckgegeben.  Nehmen Sie oben einfach unser Array und quadrieren Sie alle Elemente. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   Immutable const x = tf.tensor([1,2,3,4]); const y = x.square(); // tf.square(x); y.print();</span></span></code> </pre> <br>  Warum solche Schwierigkeiten f√ºr einfache mathematische Operationen?  Alle Operatoren, die wir brauchen - die Summe, der Median usw. - sind da.  Dies ist erforderlich, da der Tensor und dieser Ansatz es Ihnen tats√§chlich erm√∂glichen, ein Diagramm von Berechnungen zu erstellen und Berechnungen nicht sofort durchzuf√ºhren, sondern in WebGL (im Browser) oder CUDA (Node.js auf dem Computer).  Das hei√üt, die tats√§chliche Verwendung der Hardwarebeschleunigung ist f√ºr uns unsichtbar und f√ºhrt bei Bedarf zu einem Fallback auf der CPU.  Das Tolle ist, dass wir √ºber nichts nachdenken m√ºssen.  Wir m√ºssen nur die tfjs-API lernen. <br><br>  Das Wichtigste ist jetzt das Modell. <br><br><h3>  Modell </h3><br>  Der einfachste Weg, ein Modell zu erstellen, ist Sequential, dh ein sequentielles Modell, wenn Daten von einer Ebene zur n√§chsten Ebene und von dieser zur n√§chsten Ebene √ºbertragen werden.  Die einfachsten Ebenen, die hier verwendet werden, werden verwendet. <blockquote>  Die Schicht selbst ist nur eine Abstraktion von Tensoren und Operatoren.  Grob gesagt sind dies Hilfsfunktionen, die eine gro√üe Menge Mathematik vor Ihnen verbergen. </blockquote><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//    const model = tf.sequential({ layers: [ tf.layers.dense({ inputShape: [784], units: 32, activation: 'relu' }), tf.layers.dense({ units: 10, activation: 'softmax' }) ] });</span></span></code> </pre> <br>  Versuchen wir zu verstehen, wie man mit dem Modell arbeitet, ohne auf die Implementierungsdetails einzugehen. <br><br>  Zun√§chst geben wir die Form der Daten an, die in das neuronale Netzwerk fallen - <code>inputShape</code> ist ein erforderlicher Parameter.  Wir geben <code>units</code> - die Anzahl der mehrdimensionalen Arrays und die Aktivierungsfunktion. <br><br>  Die <code>relu</code> Funktion <code>relu</code> bemerkenswert, als sie zuf√§llig gefunden wurde - sie wurde ausprobiert, sie funktionierte besser und sie suchten sehr lange nach einer mathematischen Erkl√§rung, warum dies geschieht. <br><br>  F√ºr die letzte Ebene, wenn wir eine Kategorie erstellen, wird h√§ufig die Softmax-Funktion verwendet - sie eignet sich sehr gut zum Anzeigen einer Antwort im One-Hot-Encoding-Format.  Rufen Sie nach dem <code>model.summary()</code> des Modells <code>model.summary()</code> auf, um sicherzustellen, dass das Modell richtig zusammengesetzt ist.  In besonders schwierigen Situationen k√∂nnen Sie sich der Erstellung eines Modells mithilfe der funktionalen Programmierung n√§hern. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const input = tf.input({ shape: [784] }); const dense1 = tf.layers.dense({ units: 32, activation: 'relu' }).apply(input); const dense2 = tf.layers.dense({ units: 10, activation: 'softmax' }).apply(dense1); const model = tf.model({ inputs: input, outputs: dense2 });</span></span></code> </pre> <br>  Wenn Sie ein besonders komplexes Modell erstellen m√ºssen, k√∂nnen Sie den funktionalen Ansatz verwenden: Jedes Mal, wenn jede Ebene eine neue Variable ist.  Als Beispiel nehmen wir die n√§chste Ebene manuell und wenden die vorherige Ebene darauf an, damit wir komplexere Architekturen erstellen k√∂nnen.  Ich werde Ihnen sp√§ter zeigen, wo dies n√ºtzlich sein kann. <br><br>  Das n√§chste sehr wichtige Detail ist, dass wir die Eingabe- und Ausgabeschichten in das Modell √ºbergeben, dh die Schichten, die in das neuronale Netzwerk eintreten, und die Schichten, die Schichten f√ºr die Antwort sind. <br><br>  Danach ist ein wichtiger Schritt das <strong>Kompilieren des Modells</strong> .  Versuchen wir zu verstehen, was Kompilierung in Bezug auf tfjs ist. <br><br>  Denken Sie daran, wir haben versucht, die richtigen Werte in unserem neuronalen Netzwerk zu finden.  Es ist nicht notwendig, sie abzuholen.  Sie werden auf eine bestimmte Weise ausgew√§hlt, wie die Optimierungsfunktion sagt. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   (  ) model.compile({ optimizer: 'sgd', loss: 'categoricalCrossentropy', metrics: ['accuracy'] });</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code zur</a> Beschreibung von sequentiellen Ebenen und zur Kompilierung.</i> <br><br>  Ich werde veranschaulichen, was ein Optimierer ist und was eine Verlustfunktion ist. <br><br><img src="https://habrastorage.org/webt/se/lt/1l/selt1lv8ppxvokzopux387dp0os.png"><br><br>  Der Optimierer ist die gesamte Karte.  Es erm√∂glicht Ihnen, nicht nur zuf√§llig herumzulaufen und nach Wert zu suchen, sondern dies nach einem bestimmten Algorithmus mit Bedacht zu tun. <br><br>  Die Verlustfunktion ist die Art und Weise, wie wir nach dem optimalen Wert suchen (kleiner schwarzer Pfeil).  Es hilft zu verstehen, welche Gradientenwerte zum Trainieren unseres neuronalen Netzwerks verwendet werden sollen. <br><br>  Wenn Sie in Zukunft neuronale Netze beherrschen, werden Sie selbst eine Verlustfunktion schreiben.  Ein gro√üer Teil des Erfolgs eines neuronalen Netzwerks h√§ngt davon ab, wie gut diese Funktion geschrieben ist.  Aber das ist eine andere Geschichte.  Fangen wir einfach an. <br><br><h4>  Beispiel f√ºr ein Netzwerklernen </h4><br>  Wir werden zuf√§llige Daten und zuf√§llige Antworten (Labels) generieren.  Wir rufen das <code>fit</code> Modul auf, √ºbergeben die Daten, Antworten und einige wichtige Parameter: <br><br><ul><li>  <code>epochs</code> - 5 Mal, das hei√üt ungef√§hr 5 Mal, werden wir ein vollwertiges Training durchf√ºhren; </li><li>  <code>batchSize</code> , wie viele Gewichte gleichzeitig zum Heben ge√§ndert werden k√∂nnen - wie viele Elemente gleichzeitig verarbeitet werden m√ºssen.  Je besser die Grafikkarte ist, desto mehr Speicher kann √ºber <code>batchSize</code> eingestellt werden. </li></ul><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const data = tf.randomNormal([100, 784]); const labels = tf.randomNormal([100, 10]); //   model.fit(data, labels, { epochs: 5, batchSize: 32 }).then(info =&gt; { console.log('  :', info.history.acc); })</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> aller letzten Schritte.</i> <br><br>  <code>Model.fit</code> asynchrone Methode <code>Model.fit</code> gibt ein Versprechen zur√ºck.  Auf diese Weise k√∂nnen Sie jedoch async / await verwenden und auf die Ausf√ºhrung warten. <br><br>  Als n√§chstes ist die <strong>Verwendung</strong> .  Wir haben unser Modell trainiert, dann nehmen wir die Daten, die wir verarbeiten m√∂chten, und nennen die <code>predict</code> . Wir sagen: "Vorhersagen, was wirklich da ist?", Und dank dessen erhalten wir das Ergebnis. <br><br><h3>  Standardstruktur </h3><br>  Jedes neuronale Netzwerk hat drei Hauptdateien: <br><br><ul><li>  index.js - Datei, in der alle Parameter des neuronalen Netzwerks gespeichert sind; </li><li>  model.js - eine Datei, in der das Modell und seine Architektur direkt gespeichert werden; </li><li>  data.js - eine Datei, in der Daten gesammelt, verarbeitet und in unser System eingebettet werden. </li></ul><br>  Also sprach ich dar√ºber, wie man TensorFlow.js lernt.  Kleinunternehmen bleibt <strong>es, ein Modell zu w√§hlen</strong> . <br><br>  Dies ist leider nicht ganz richtig.  Tats√§chlich m√ºssen Sie jedes Mal, wenn Sie ein Modell ausw√§hlen, bestimmte Schritte wiederholen. <br><br><ul><li>  Bereiten Sie Daten daf√ºr vor, dh machen Sie die Einbettung und passen Sie sie an die Architektur an. </li><li>  Konfigurieren Sie die Hyper-Einstellungen (ich werde Ihnen sp√§ter sagen, was dies bedeutet). </li><li>  Trainiere / trainiere jedes neuronale Netzwerk (jedes Modell kann seine eigenen Nuancen haben). </li><li>  Wenden Sie ein neuronales Modell an, und Sie k√∂nnen es auch auf verschiedene Arten anwenden. </li></ul><br><h2>  W√§hlen Sie ein Modell </h2><br>  Beginnen wir mit den grundlegenden Optionen, auf die Sie h√§ufig sto√üen werden. <br><br><h3>  Tiefer Sinn </h3><br>  Dies ist ein beliebtes Beispiel f√ºr ein tiefes neuronales Netzwerk.  Alles ist ganz einfach gemacht: Es gibt einen √∂ffentlich verf√ºgbaren Datensatz - MNIST-Datensatz. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6g/yu/-4/6gyu-4wjgg4zfvf8w7byjx_z5yw.jpeg" width="600"></div><br>  Dies sind beschriftete Bilder mit Zahlen, auf deren Grundlage es bequem ist, ein neuronales Netzwerk zu trainieren. <br><br>  In √úbereinstimmung mit der Architektur der One-Hot-Codierung codieren wir jede der letzten Schichten.  Ziffern 10 - dementsprechend gibt es am Ende 10 letzte Schichten.  Wir senden einfach Schwarzwei√übilder an den Eingang, all dies ist sehr √§hnlich zu dem, wor√ºber wir am Anfang gesprochen haben. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> model = tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">784</span></span>], <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> }), ] });</code> </pre> <br>  Wir begradigen das Bild zu einem eindimensionalen Array, wir erhalten 784 Elemente.  In einer Schicht 512 Arrays.  Aktivierungsfunktion <code>'relu'</code> . <br><br>  Die n√§chste Schicht von Arrays ist etwas kleiner (256), die Aktivierungsschicht ist ebenfalls <code>'relu'</code> .  Wir haben die Anzahl der Arrays reduziert, um nach allgemeineren Merkmalen zu suchen.  Das neuronale Netzwerk muss aufgefordert werden, zu lernen, und gezwungen sein, eine ernstere, allgemeine Entscheidung zu treffen, weil sie es selbst nicht tun wird. <br><br>  Am Ende erstellen wir 10 Matrizen und verwenden die Softmax-Aktivierung f√ºr die One-Hot-Codierung. Diese Art der Aktivierung funktioniert gut mit dieser Art der Antwortcodierung. <br><br>  In tiefen Netzwerken k√∂nnen Sie 80-90% der Bilder korrekt erkennen - ich m√∂chte mehr.  Eine Person erkennt mit einer Qualit√§t von ca. 96%.  K√∂nnen neuronale Netze eine Person fangen und √ºberholen? <br><br><h3>  CNN (Convolutional Neural Network) </h3><br>  Faltungsnetzwerke funktionieren wahnsinnig einfach.  Am Ende haben sie die gleiche Architektur wie in den vorherigen Beispielen.  Aber am Anfang passiert etwas anderes.  Arrays reduzieren das Bild, anstatt nur einige L√∂sungen anzugeben.  Sie nehmen an dem Bild teil und reduzieren es auf eine Ziffer.  Dann werden sie alle zusammen gesammelt und wieder reduziert. <br><img src="https://habrastorage.org/webt/mi/xc/gk/mixcgkl0kgopjxgams8szm0wr2q.jpeg"><br>  Dadurch wird die Gr√∂√üe des Bildes verringert, gleichzeitig werden Teile des Bildes immer besser erkannt.  Faltungsnetzwerke eignen sich sehr gut f√ºr die Mustererkennung, sogar besser als Menschen. <br><blockquote>  Das Erkennen von Bildern wird einem Auto besser anvertraut als einer Person.  Es gab eine spezielle Studie, und die Person verlor leider. </blockquote>  CNNs funktionieren sehr einfach: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> model = tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }), tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }), tf.layers.maxPooling2d({<span class="hljs-attr"><span class="hljs-attr">poolSize</span></span>: [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>]}), tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }) tf.layers.flatten(tf.layers.maxPooling2d({ <span class="hljs-attr"><span class="hljs-attr">poolSize</span></span>: [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>] })), tf.layers.dense({<span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>}), tf.layers.dense({<span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span>}) ] });</code> </pre> <br>  Wir geben ein bestimmtes mehrdimensionales Array ein: ein Bild mit 28 x 28 Pixel plus eine Dimension f√ºr die Helligkeit. In diesem Fall ist das Bild schwarzwei√ü, die dritte Dimension ist also 1. <br><br>  Als N√§chstes legen wir die Anzahl der <code>filters</code> und <code>kernelSize</code> - wie viele Pixel werden schmaler.  Aktivierungsfunktion √ºberall <code>relu</code> . <br><br>  Es gibt eine weitere Ebene <code>maxPooling2d</code> , die ben√∂tigt wird, um die Gr√∂√üe noch effizienter zu reduzieren.  Faltungsnetzwerke verengen die Gr√∂√üe sehr allm√§hlich, und oft besteht keine Notwendigkeit, sehr tiefe Faltungsnetzwerke herzustellen. <br><br>  Ich werde erkl√§ren, warum es etwas sp√§ter unm√∂glich ist, sehr tiefe Faltungsnetzwerke zu erstellen, aber denken Sie vorerst daran: Manchmal m√ºssen sie etwas schneller aufgerollt werden.  Hierf√ºr gibt es eine separate maxPooling-Ebene. <br><br>  Ganz am Ende befindet sich die gleiche dichte Schicht.  Das hei√üt, wir haben mithilfe von Faltungs-Neuronalen Netzen verschiedene Zeichen aus den Daten herausgezogen. Danach verwenden wir den Standardansatz und kategorisieren unsere Ergebnisse, dank derer wir die Bilder erkennen. <br><br><h3>  U net </h3><br>  Dieses Architekturmodell ist Faltungsnetzwerken zugeordnet.  Mit seiner Hilfe wurden viele Entdeckungen auf dem Gebiet der Krebsbek√§mpfung gemacht, beispielsweise bei der Erkennung von Krebszellen und Glaukom.  Dar√ºber hinaus kann dieses Modell b√∂sartige Zellen nicht schlechter finden als ein Professor auf diesem Gebiet. <br><br>  Ein einfaches Beispiel: Unter den verrauschten Daten m√ºssen Sie Krebszellen (Kreise) finden. <br><br><img src="https://habrastorage.org/webt/hj/9b/yr/hj9byresramxnetrg7t_kenia0a.jpeg"><br><br>  U-Net ist so gut, dass es sie fast perfekt finden kann.  Die Architektur ist sehr einfach: <br><br><img src="https://habrastorage.org/webt/16/5_/vx/165_vxamsqm5eveub2tdhzxprc8.jpeg"><br><br>  Es gibt dieselben Faltungsnetzwerke wie MaxPooling, wodurch die Gr√∂√üe verringert wird.  Der einzige Unterschied: Das Modell verwendet auch <strong>Scan-</strong> Netzwerke - das <strong>Entfaltungsnetzwerk</strong> . <br><br>  Zus√§tzlich zum Faltungsscan wird jede der Ebenen auf hoher Ebene miteinander kombiniert (Start und Ausgang), wodurch eine gro√üe Anzahl von Beziehungen auftritt.  Solche U-Net funktionieren auch bei kleinen Datenmengen gut. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//First part (down climb) const input = buildInput(...IMAGE_INPUT); const conv1 = genConv2D(64).apply(input); const conv2 = genConv2D(64).apply(conv1); const pool1 = geMaxPool2D(2).apply(conv2); const conv3 = genConv2D(128).apply(pool1); const conv4 = genConv2D(128).apply(conv3); const pool2 = geMaxPool2D(2).apply(conv4); const conv5 = genConv2D(256).apply(pool2); const conv6 = genConv2D(256).apply(conv5); const pool3 = geMaxPool2D(2).apply(conv6); const conv7 = genConv2D(512).apply(pool3); const conv8 = genConv2D(512).apply(conv7); const pool4 = geMaxPool2D(2).apply(conv8); const conv9 = genConv2D(1024).apply(pool4); const conv10 = genConv2D(1024).apply(conv9); const up1 = genUp2D().apply(conv10); const merge1 = tf.layers.concatenate({ axis: 3 }).apply([up1, conv8]); //Second part (up climb) const conv11 = genConv2D(512).apply(merge1); const conv12 = genConv2D(512).apply(conv11); const up2 = genUp2D().apply(conv12); const merge2 = tf.layers.concatenate({ axis: 3 }).apply([up2, conv6]); const conv13 = genConv2D(256).apply(merge2); const conv14 = genConv2D(256).apply(conv13); const up3 = genUp2D().apply(conv14); const merge3 = tf.layers.concatenate({ axis: 3 }).apply([up3, conv4]); const conv15 = genConv2D(128).apply(merge3); const conv16 = genConv2D(128).apply(conv15); const up4 = genUp2D().apply(conv16); const merge4 = tf.layers.concatenate({ axis: 3 }).apply([up4, conv2]); const conv17 = genConv2D(64).apply(merge4); const conv18 = genConv2D(64).apply(conv17); const conv19 = tf.layers .conv2d({ kernelSize: [1, 1], activation: "sigmoid", filters: 1, padding: "same" }) .apply(conv18); const model = tf.model({ inputs: input, outputs: conv19 });</span></span></code> </pre> <br>  Dieser Code ist im Editor leichter zu erlernen.  Im Allgemeinen wird hier eine gro√üe Anzahl von Faltungsnetzwerken erstellt. Um sie wieder bereitzustellen, <code>concatenate</code> wir mehrere Ebenen und f√ºhren sie zusammen.  Dies ist nur eine Visualisierung eines Bildes, nur in Codeform.  Alles ist ganz einfach - das Kopieren und Reproduzieren eines solchen Modells ist einfach. <br><br><h2>  LSTM (Long Short-Term Memory) </h2><br>  Beachten Sie, dass alle betrachteten Beispiele eine Funktion haben - das Eingabedatenformat ist festgelegt.  Bei der Eingabe in das Netzwerk m√ºssen die Daten gleich gro√ü sein und miteinander √ºbereinstimmen.  LSTM-Modelle konzentrieren sich darauf, wie sie damit umgehen sollen. <br><br>  Zum Beispiel gibt es einen Dienst Yandex.Referats, der Abstracts generiert. <br><br><img src="https://habrastorage.org/webt/_o/g7/mh/_og7mh4hlaz87r6jpbkzjqsgdbc.png"><br><br>  Er gibt einen vollst√§ndigen Abrakadabra aus, der aber gleichzeitig der Wahrheit ziemlich √§hnlich ist: <br><br><blockquote>  <strong>Zusammenfassung in Mathematik zum Thema: "Newtons Binom als Axiom"</strong> <br><br>  Gem√§√ü dem Vorstehenden erzeugt das Oberfl√§chenintegral ein krummliniges Integral.  Die nach unten konvexe Funktion ist weiterhin gefragt. <br><br>  Daraus folgt nat√ºrlich, dass die Normalit√§t zur Oberfl√§che noch gefragt ist.  Gem√§√ü dem vorherigen spezifiziert das Poisson-Integral im Wesentlichen das trigonometrische Poisson-Integral. </blockquote><br>  Der Dienst basiert auf neuronalen Seq-to-Seq-Netzen.  Ihre Architektur ist komplexer. <br><br><img src="https://habrastorage.org/webt/6r/3s/aw/6r3sawht3bnxadqmorz0vjqwzmw.jpeg"><br><br>  Schichten sind in einem ziemlich komplexen System angeordnet.  Aber seien Sie nicht beunruhigt - Sie m√ºssen nicht alle diese Pfeile selbst ausf√ºhren.  Wenn Sie m√∂chten, k√∂nnen Sie, aber nicht notwendig.  Es gibt einen Helfer, der dies f√ºr Sie erledigt. <br><br>  Die Hauptsache zu verstehen ist, dass jedes dieser St√ºcke mit dem vorherigen kombiniert wird.  Es werden Daten nicht nur aus den Anfangsdaten, sondern auch aus der vorherigen neuronalen Schicht entnommen.  Grob gesagt ist es m√∂glich, eine Art Speicher aufzubauen - eine Sequenz von Daten zu speichern, zu reproduzieren und aufgrund dieser Arbeit ‚ÄûSequenz zu Sequenz‚Äú.  Dar√ºber hinaus k√∂nnen die Sequenzen sowohl am Eingang als auch am Ausgang unterschiedlich gro√ü sein. <br><br>  Im Code sieht alles sch√∂n aus: <br><br><pre> <code class="javascript hljs">tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.lstm({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">returnSequences</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>] }), tf.layers.lstm({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">returnSequences</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> }) ] }) ;</code> </pre> <br>  Es gibt einen speziellen Helfer, der besagt, dass wir 512 Objekte (Arrays) haben.  <code>inputShape: [10000, 64]</code> N√§chstes die Sequenz und das Eingabeformular zur√ºck ( <code>inputShape: [10000, 64]</code> ).  Als n√§chstes f√ºhren wir eine weitere Ebene ein, geben aber die Sequenz nicht zur√ºck ( <code>returnSequences: false</code> ), da wir am Ende sagen, dass wir jetzt die Aktivierungsfunktion f√ºr 64 verschiedene Zeichen (Klein- und Gro√übuchstaben) verwenden m√ºssen.  64 Optionen werden mithilfe der One-Hot-Codierung aktiviert. <br><br><h2>  Am interessantesten </h2><br>  Jetzt fragen Sie sich wahrscheinlich: ‚ÄûDas ist nat√ºrlich alles gut, aber warum brauche ich es?  "Krebs zu bek√§mpfen ist gut, aber warum brauche ich ihn an vorderster Front?" <br><br>  Und T√§nze mit einem Tamburin beginnen: um herauszufinden, wie man beispielsweise neuronale Netze auf das Layout anwendet. <br><blockquote>  Mit Hilfe neuronaler Netze k√∂nnen Probleme gel√∂st werden, die bisher nicht zu l√∂sen waren.  Einige, an die man nicht einmal denken konnte.  Es h√§ngt alles von Ihnen, Ihrer Vorstellungskraft und ein wenig √úbung ab. </blockquote>  Jetzt werde ich live interessante Beispiele f√ºr die Verwendung der von uns untersuchten Modelle zeigen. <br><br><h3>  CNN  Audio-Teams </h3><br>  Mithilfe von Faltungsnetzwerken k√∂nnen Sie nicht nur Bilder, sondern auch Audiobefehle erkennen. Bei einer Erkennungsqualit√§t von 97%, dh auf der Ebene von Google Assistant und Yandex-Alice. <br><br>  Nat√ºrlich ist es allein im Netzwerk nicht m√∂glich, vollwertige Sprache und S√§tze zu erkennen, aber Sie k√∂nnen einen einfachen Sprachassistenten erstellen. <br><br>  Weitere Informationen zu Alice finden Sie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bericht von</a> Nikita Dubko sowie zum Google-Assistenten, zum Umgang mit Sprache und zu Browserstandards. <br><br>  Tatsache ist, dass jedes Wort, jeder Befehl in ein Spektrogramm umgewandelt werden kann. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/au/_v/r8/au_vr8gdnqh3k6gkcgyhz0ybwoq.jpeg" width="500"></div><br>  Sie k√∂nnen beliebige Audioinformationen in ein solches Spektrogramm konvertieren.  Anschlie√üend k√∂nnen Sie das Audio im Bild codieren, CNN auf das Bild anwenden und einfache Sprachbefehle erkennen. <br><br><h3>  U-net.  Screenshot-Test </h3><br>  U-Net eignet sich nicht nur f√ºr eine erfolgreiche Krebsdiagnose, sondern auch zum Testen von Screenshots.  Einzelheiten finden Sie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bericht von</a> Lyudmila Mzhachikh, und ich werde die Basis selbst informieren. <br><br>  Zum Testen mit Screenshots werden zwei Screenshots ben√∂tigt: <br><br><ul><li>  Grund (Referenz), mit dem wir vergleichen; </li><li>  Screenshot zum Testen. </li></ul><br><img src="https://habrastorage.org/webt/kx/2g/ci/kx2gcib0rilb_zzhohk15dmnoi4.jpeg"><br>  Leider gibt es beim Screenshot-Testen oft viele negative St√ºrze (falsch positive).  Dies kann jedoch vermieden werden, indem fortschrittliche Krebsbek√§mpfungstechnologien auf das Front-End angewendet werden. <br><br>  Denken Sie daran, wir haben das Bild in dem Bereich markiert, in dem Krebs vorliegt und nicht.  Das gleiche kann hier gemacht werden. <br><br><img src="https://habrastorage.org/webt/19/kk/uw/19kkuwktd9iv30ffolxasj3_l-k.jpeg"><br><br>  Wenn wir ein Bild mit einem guten Layout sehen, markieren wir es nicht und wir markieren Bilder mit einem schlechten Layout.  So k√∂nnen Sie das Layout mit einem einzigen Bild testen.   ,     ,   ,    . U-Net     . <br><br>       ,    ,    .  ,          U-Net,  .  ,   . <br><br><h3> LSTM. Twitter ‚Äî  2000 </h3><br>   ,    ,     ,    . <br><br>       ,     LSTM  .   40     - , : <em>¬´ ‚Äî     ¬ª</em> . <br><br>   ,  : <br><br><img src="https://habrastorage.org/webt/yu/_6/xk/yu_6xkkdkak9jganrrpvxs6vd9g.jpeg"><br><br> -   , ? <br><br>  ‚Äî .    -   : <br><br><img src="https://habrastorage.org/webt/lk/hz/sf/lkhzsfwyvs42ky2yi-k6m5reu7o.jpeg"><br><br><img src="https://habrastorage.org/webt/ai/a7/jv/aia7jvkjsgw35wpjixbsko4vjwe.jpeg"><br><br>  ,   ¬´¬ª       ,       ,        (,  ). <br><br>  : <em>¬´    ¬ª</em>  <em>¬´   ¬ª</em> . <br><br>       ‚Äî  . <br><blockquote> ¬´   ¬ª. </blockquote><br>      : <br><br><img src="https://habrastorage.org/webt/lv/ud/dp/lvuddp8bnuagbh4kgmsao3j_qvo.jpeg"><br><br><h4> EPOCS 250 </h4><br>    ,     . <br><br>    -   , ,  ,     .   ,      Overfitting ‚Äî . <br><br>   ,    ‚Äî       .  , , .   ,   ,         ,         . <br><br>    ,       ,          . <br><br>  ,       . <br><br><img src="https://habrastorage.org/webt/cv/_j/ft/cv_jftct2bzeb2_ik1apzezgjsg.jpeg"><br><br>   , ,        ,        .      ( ,  ),      .          . <br><blockquote>     ‚Äî    .    . </blockquote>      overfitting.      ,    helper-: Dropout; BatchNormalization. <br><br><h3> LSTM. Prettier </h3><br>  ,     ‚Äî  Prettier   .       ,     . <br><br>  <code>const a = 1</code> .    : <code>[]c co on ns st</code> ,    ,            : <code>[][] []c co on ns st</code> ,      . <br><br>     ,            ,     . <br><br> ,    ,     .      , ,  0 ‚Äî  ,      -  ,  - .   . <br><br>            ,      .         . <br><br><h2>  Anstelle von Schlussfolgerungen </h2><br> , ,     .   . , ,         Deep Neural Network. <br><br>        .         ,      .      .            .     . <br><br>       JS,       ,     .         ,      .  ,   JavaScript,         .     TensorFlow.js. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><em></em></a> <em> ,     .    </em> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><em>telegram-</em></a> <em>    JS.</em> <br><blockquote>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FrontendConf</a>    , 13 .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> 32        . <br><br>    ,    ,           .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>  Saint AppsConf,       .      ,  ,    ,     . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de470904/">https://habr.com/ru/post/de470904/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de470884/index.html">Schreiben und Lesen von Daten in der Bitcoin-Blockchain</a></li>
<li><a href="../de470888/index.html">Russische und internationale Gesetzgebung im Bereich des Schutzes personenbezogener Daten</a></li>
<li><a href="../de470892/index.html">Einfache Implementierung eines kleinen CAM auf einem FPGA</a></li>
<li><a href="../de470894/index.html">Kugel</a></li>
<li><a href="../de470902/index.html">Hohe Leistung und native Partitionierung: Zabbix mit TimescaleDB-Unterst√ºtzung</a></li>
<li><a href="../de470908/index.html">Zum ersten Mal auf der Welt wurde mit Hilfe additiver Technologien eine gro√üformatige Triebwerksbaugruppe f√ºr Flugzeuge erhalten</a></li>
<li><a href="../de470910/index.html">Was kann mit Anmerkungen zu Microservice-Vertr√§gen getan werden?</a></li>
<li><a href="../de470916/index.html">Der ‚Äûbilligste‚Äú elektronische Kontrollpunkt in Russland, der √ºber ein Smartphone gesteuert wird</a></li>
<li><a href="../de470918/index.html">F # 9: Geben Sie Option ein</a></li>
<li><a href="../de470920/index.html">5+ M√∂glichkeiten, eine Verbindung zu einer DataLine-Cloud herzustellen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
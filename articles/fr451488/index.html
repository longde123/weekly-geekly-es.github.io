<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßï üßô üêá Calcul de cannibalisation bas√© sur le test A / B classique et la m√©thode bootstrap üìë üë©üèæ üèùÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cet article d√©crit une m√©thode de calcul de cannibalisation pour une application mobile bas√©e sur le test A / B classique. Dans ce cas, les actions ci...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Calcul de cannibalisation bas√© sur le test A / B classique et la m√©thode bootstrap</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451488/">  Cet article d√©crit une m√©thode de calcul de cannibalisation pour une application mobile bas√©e sur le test A / B classique.  Dans ce cas, les actions cibles sont consid√©r√©es et √©valu√©es dans le cadre du processus de r√©attribution √† partir d'une source publicitaire (Direct, Criteo, AdWords UAC et autres) par rapport aux actions cibles du groupe auquel l'annonce a √©t√© d√©sactiv√©e. <br><br>  L'article donne un aper√ßu des m√©thodes classiques de comparaison d'√©chantillons ind√©pendants avec une br√®ve base th√©orique et une description des biblioth√®ques utilis√©es, y compris  d√©crit bri√®vement l'essence de la m√©thode bootstrap et son impl√©mentation dans la biblioth√®que FaceBook Bootstrapped, ainsi que les probl√®mes qui se posent dans la pratique lors de l'application de ces techniques, et comment les r√©soudre. <br><a name="habracut"></a><br>  Les preuves sont soit obscurcies, soit non fournies afin de maintenir un accord de non-divulgation. <br><br>  √Ä l'avenir, je pr√©vois de compl√©ter et de modifier l√©g√®rement cet article √† mesure que de nouveaux faits apparaissent, afin que cette version puisse √™tre consid√©r√©e comme la premi√®re version.  Je serais reconnaissant pour les commentaires et les critiques. <br><br><h3>  Pr√©sentation </h3> <br>  La cannibalisation est le processus de circulation du trafic, complet et cibl√©, d'un canal √† un autre. <br><br>  Les sp√©cialistes du marketing utilisent g√©n√©ralement cet indicateur comme coefficient K suppl√©mentaire dans le calcul du CPA: le CPA calcul√© est multipli√© par 1 + K.  Dans ce cas, CPA signifie le co√ªt total pour attirer du trafic / le nombre d'actions cibl√©es qui sont mon√©tis√©es directement, c'est-√†-dire qui ont g√©n√©r√© le profit r√©el - par exemple, un appel cibl√© et / ou mon√©tis√© indirectement - par exemple, augmenter le volume de la base de donn√©es publicitaires, augmenter l'audience, etc. <br><br>  Lorsque des canaux gratuits (par exemple, visites de SERP organiques, clics sur des liens sur des sites que nous pouvons utiliser gratuitement) sont cannibalis√©s pour payants (Direct, Adwords au lieu de produits biologiques, publicit√© dans les flux de r√©seaux sociaux au lieu de cliquer sur des annonces, est gratuit plac√©s en groupes, etc.), cela comporte des risques de pertes financi√®res, il est donc important de conna√Ætre le taux de cannibalisation. <br><br>  Dans notre cas, il s'agissait de calculer la cannibalisation des transitions "organiques" √† l'application par des transitions issues du r√©seau publicitaire Criteo.  La surveillance est un appareil ou un utilisateur (GAID / ADVID et IDFA). <br><br><h3>  Pr√©paration √† l'exp√©rience </h3><br>  Vous pouvez pr√©parer l'audience √† l'exp√©rimentation en divisant les utilisateurs du syst√®me analytique AdJust en groupes pour isoler ceux qui verront les annonces d'un certain r√©seau publicitaire (√©chantillon de contr√¥le) et ceux qui ne verront pas les annonces utilisant GAID ou ADVID et IDFA, respectivement (AdJust fournit l'API Audience Builder).  Ensuite, dans l'√©chantillon de contr√¥le, vous pouvez inclure une campagne publicitaire dans le r√©seau publicitaire √©tudi√© dans l'exp√©rience. <br><br>  Je note de moi-m√™me que, comme il semble intuitivement, l'exp√©rience suivante serait plus comp√©tente dans ce cas: s√©lectionner quatre groupes - ceux qui avaient retargeting d√©sactiv√© de tous les canaux (1), comme le groupe exp√©rimental, et ceux qui avaient uniquement le reciblage activ√© avec Criteo (2);  ceux qui n'avaient que le reciblage d√©sactiv√© avec Criteo (3), ceux qui avaient tous le reciblage (4) activ√©.  Il serait alors possible de calculer (1) / (2), ayant re√ßu la valeur r√©elle de la cannibalisation par des campagnes publicitaires du r√©seau Criteo de transitions ¬´organiques¬ª vers l'application, et (3) / (4), ayant re√ßu la cannibalisation de Criteo dans l'environnement ¬´naturel¬ª (apr√®s tout, Criteo, √©videmment peut √©galement cannibaliser d'autres cha√Ænes payantes).  La m√™me exp√©rience doit √™tre r√©p√©t√©e pour les autres r√©seaux publicitaires afin de conna√Ætre l'impact de chacun d'eux;  dans un monde id√©al, il serait int√©ressant d'√©tudier la cannibalisation crois√©e entre toutes les sources payantes cl√©s qui constituent la plus grande part du trafic total, mais cela prendrait beaucoup de temps (√† la fois pour pr√©parer les exp√©riences du point de vue du d√©veloppement et pour √©valuer les r√©sultats), ce qui entra√Ænerait critique pour une minutie d√©raisonnable. <br><br>  En fait, notre exp√©rience a √©t√© r√©alis√©e dans les conditions (3) et (4), les √©chantillons ont √©t√© divis√©s dans un rapport de 10% √† 90%, l'exp√©rience a √©t√© men√©e pendant 2 semaines. <br><br><h3>  Pr√©paration et v√©rification des donn√©es </h3><br>  Avant de commencer une √©tude, une √©tape importante est la pr√©-formation comp√©tente et le nettoyage des donn√©es. <br><br>  Il convient de noter qu'en fait, les dispositifs actifs pour la p√©riode d'exp√©rience √©taient 2 fois moins (respectivement 42,5% et 50% des groupes t√©moins et exp√©rimentaux) que les dispositifs dans les √©chantillons initiaux complets, ce qui s'explique par la nature des donn√©es: <br><br><ol><li>  tout d'abord (et c'est une des principales raisons), la s√©lection pour le reciblage depuis Adjust contient les identifiants de tous les appareils qui ont d√©j√† install√© l'application, c'est-√†-dire les appareils qui ne sont plus utilis√©s et ceux avec lesquels l'application √©tait d√©j√† supprim√© </li><li>  deuxi√®mement, il n'est pas n√©cessaire que tous les appareils se soient connect√©s √† l'application pendant l'exp√©rience. </li></ol><br>  Cependant, nous avons calcul√© la cannibalisation sur la base des donn√©es d'un √©chantillon complet.  Pour moi personnellement, l'exactitude d'un tel calcul est toujours un point discutable - en g√©n√©ral, √† mon avis, il est plus correct de nettoyer tous ceux qui ont d√©sinstall√© l'application et ne l'ont pas install√©e par les balises correspondantes, ainsi que ceux qui ne se sont pas connect√©s √† l'application depuis plus d'un an - cette p√©riode de temps, l'utilisateur peut changer l'appareil;  moins - de cette mani√®re, pour l'exp√©rience, les utilisateurs qui ne sont pas pass√©s √† l'application, mais qui pourraient le faire, pourraient √™tre supprim√©s de la s√©lection si nous leur montrions des annonces sur le r√©seau Criteo.  Je veux noter que dans un bon monde, toutes ces n√©gligences et hypoth√®ses forc√©es doivent √™tre examin√©es et v√©rifi√©es s√©par√©ment, mais nous vivons dans un monde o√π le faire vite et √† poil. <br><br>  Dans notre cas, il est important de v√©rifier les points suivants: <br><br><ol><li>  Nous v√©rifions l'intersection dans nos √©chantillons initiaux - exp√©rimentaux et t√©moins.  Dans une exp√©rience correctement mise en ≈ìuvre, de telles intersections ne devraient pas √™tre, cependant, dans notre cas, il y avait plusieurs doublons de l'√©chantillon exp√©rimental dans le contr√¥le.  Dans notre cas, la part de ces doublons dans le volume total des appareils impliqu√©s dans l'exp√©rience √©tait faible; par cons√©quent, nous avons n√©glig√© cette condition.  S'il y avait&gt; 1% de doublons, l'exp√©rience devrait √™tre consid√©r√©e comme incorrecte et une deuxi√®me exp√©rience devrait √™tre effectu√©e, apr√®s avoir pr√©alablement nettoy√© les doublons. </li><li>  Nous v√©rifions que les donn√©es de l'exp√©rience ont vraiment √©t√© affect√©es - le reciblage aurait d√ª √™tre d√©sactiv√© dans l'√©chantillon exp√©rimental (au moins avec Criteo, dans l'exp√©rience correctement d√©finie - de tous les canaux), il est donc n√©cessaire de v√©rifier l'absence de DeviceID dans l'exp√©rience de reciblage avec Criteo.  Dans notre cas, DeviceID du groupe exp√©rimental est n√©anmoins tomb√© dans le reciblage, mais il y en avait moins de 1%, ce qui est n√©gligeable. </li></ol><br><h3>  √âvaluation directe de l'exp√©rience </h3><br>  Nous consid√©rerons le changement dans les m√©triques cibles suivantes: absolu - le nombre d'appels, et relatif - le nombre d'appels par utilisateur dans les groupes de contr√¥le (vu les publicit√©s sur le r√©seau Criteo) et exp√©rimental (les publicit√©s ont √©t√© d√©sactiv√©es).  Dans le code ci-dessous, les donn√©es variables font r√©f√©rence √† la structure pandas.DataFrame, qui est form√©e √† partir des r√©sultats d'un √©chantillon exp√©rimental ou t√©moin. <br><br>  Il existe des m√©thodes param√©triques et non param√©triques pour √©valuer la signification statistique de la diff√©rence de valeurs dans des √©chantillons non apparent√©s.  Les crit√®res d'√©valuation param√©trique donnent une plus grande pr√©cision, mais ont des limites dans leur application - en particulier, l'une des principales conditions est que les valeurs mesur√©es pour les observations dans l'√©chantillon soient distribu√©es normalement. <br><br><h4>  1. L'√©tude de la distribution des valeurs dans les √©chantillons pour la normalit√© </h4><br>  La premi√®re √©tape consiste √† examiner les √©chantillons existants pour le type de distribution des valeurs et l'√©galit√© des variances des √©chantillons √† l'aide de tests standard - les crit√®res de Kolmogorov-Smirnov et Shapiro-Wilks et le test de Bartlett mis en ≈ìuvre dans la biblioth√®que sklearn.stats, en prenant p-value = 0,05: <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : def norm_test(df, pvalue = 0.05, test_name = 'kstest'): if test_name == 'kstest': st = stats.kstest(df, 'norm') if test_name == 'shapiro': st = stats.shapiro(df) sys.stdout.write('According to {} {} is {}normal\n'.format(test_name, df.name, {True:'NOT ', False:''}[st[1] &lt; pvalue])) #    : def barlett_test(df1, df2, pvalue = 0.05): st = stats.bartlett(df1, df2) sys.stdout.write('Variances of {} and {} is {}equals\n'.format(df1.name, df2.name, {True:'NOT ', False:''}[st[1] &lt; pvalue]))</span></span></code> </pre> <br>  De plus, pour une √©valuation visuelle des r√©sultats, vous pouvez utiliser la fonction d'histogramme. <br><br><pre> <code class="python hljs">data_agg = data.groupby([<span class="hljs-string"><span class="hljs-string">'bucket'</span></span>]).aggregate({<span class="hljs-string"><span class="hljs-string">'device_id'</span></span>: <span class="hljs-string"><span class="hljs-string">'nunique'</span></span>, <span class="hljs-string"><span class="hljs-string">'calls'</span></span>: <span class="hljs-string"><span class="hljs-string">'sum'</span></span>}).fillna(<span class="hljs-number"><span class="hljs-number">0</span></span>) data_conv = data_agg[<span class="hljs-string"><span class="hljs-string">'calls_auto'</span></span>]/data_agg[<span class="hljs-string"><span class="hljs-string">'device_id'</span></span>] data_conv.hist(bins=<span class="hljs-number"><span class="hljs-number">20</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/8m/zc/u4/8mzcu4-emautrimdpvczuttfkf8.png" alt="image"><br><br>  Vous pouvez lire l'histogramme comme ceci: 10 fois dans l'√©chantillon, il y a eu une conversion de 0,08, 1 - 0,14.  Cela ne dit rien sur le nombre d'appareils comme observations pour aucun des indicateurs de conversion. <br><br>  Dans notre cas, la distribution de la valeur du param√®tre √† la fois en valeur absolue et en valeur relative (le nombre d'appels √† l'appareil) dans les √©chantillons n'est pas normale. <br>  Dans ce cas, vous pouvez utiliser soit le test de Wilcoxon non param√©trique impl√©ment√© dans la biblioth√®que sklearn.stats standard, soit essayer de ramener la distribution des valeurs dans les √©chantillons √† la forme normale et appliquer l'un des crit√®res param√©triques - le test t de Student ou le test Shapiro-Wilks de Student. <br><br><h4>  2. M√©thodes de r√©duction de la distribution des valeurs dans les √©chantillons √† la forme normale </h4><br>  <b>2.1.</b>  <b>Sous-godets</b> <br><br>  Une approche pour ramener la distribution √† la normale est la m√©thode du sous-ensemble.  Son essence est simple et la th√®se math√©matique suivante est la base th√©orique: selon le th√©or√®me de la limite centrale classique, la distribution des moyennes tend vers la normale - la somme de n variables al√©atoires ind√©pendantes identiquement distribu√©es a une distribution proche de la normale, et, de mani√®re √©quivalente, la distribution des moyennes d'√©chantillonnage des n premiers n al√©atoires ind√©pendants distribu√©s identiquement les quantit√©s ont tendance √† revenir √† la normale.  Par cons√©quent, nous pouvons diviser les bucket'es existants en sous-bucket'y et, en cons√©quence, en prenant les valeurs moyennes de sub-bucket'y pour chacun des bucket'ov, nous pouvons obtenir une distribution proche de la normale: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   subbucket' data['subbucket'] = data['device_id'].apply(lambda x: randint(0,1000)) # Variant 1 data['subbucket'] = data['device_id'].apply(lambda x: hash(x)%1000) # Variant 2</span></span></code> </pre> <br>  Il peut y avoir de nombreuses options pour le fractionnement, tout d√©pend de l'imagination du d√©veloppeur et des principes moraux - vous pouvez prendre un hasard honn√™te ou utiliser le hachage du seau d'origine, prenant ainsi en compte le m√©canisme pour le publier dans le sch√©ma. <br><br>  Cependant, dans la pratique, √† partir de plusieurs dizaines de lancements de code, nous n'avons re√ßu la distribution normale qu'une seule fois, c'est-√†-dire que cette m√©thode n'est ni garantie ni stable. <br><br>  En outre, le rapport des actions cibles et des utilisateurs au nombre total d'actions et d'utilisateurs dans le sous-ensemble peut ne pas √™tre coh√©rent avec les backets initiaux, vous devez donc d'abord v√©rifier que le ratio est maintenu. <br><br><pre> <code class="python hljs">data[data[<span class="hljs-string"><span class="hljs-string">'calls'</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>].device_id.nunique()/data.device_id.nunique() <span class="hljs-comment"><span class="hljs-comment"># Total buckets = data.groupby(['bucket']).aggregate({'device_id': 'nunique', 'calls': 'sum'}) buckets[buckets['calls'] &gt; 0].device_id.nunique()/buckets.device_id.nunique() # Buckets subbuckets = data.groupby(['subbucket']).aggregate({'device_id': 'nunique', 'calls': 'sum'}) subbuckets[subbuckets['calls'] &gt; 0].device_id.nunique()/subbuckets.device_id.nunique() # Subbuckets</span></span></code> </pre> <br>  Au cours d'une telle v√©rification, nous avons d√©couvert que les taux de conversion des sous-ensembles par rapport √† la s√©lection d'origine ne sont pas conserv√©s.  √âtant donn√© que nous devons en outre garantir la coh√©rence du ratio de la part des appels dans les √©chantillons de sortie et de source, nous utilisons l'√©quilibrage des classes, en ajoutant une pond√©ration afin que les donn√©es soient s√©lectionn√©es s√©par√©ment par sous-groupes: s√©par√©ment des observations avec des actions cibles et s√©par√©ment des observations sans actions cibles dans la bonne proportion.  De plus, dans notre cas, les √©chantillons ont √©t√© r√©partis de mani√®re in√©gale;  intuitivement, il semble que la moyenne ne devrait pas changer, mais comment la non-uniformit√© des √©chantillons affecte la variance n'est pas √©vidente √† partir de la formule de dispersion.  Afin de clarifier si la diff√©rence de taille des √©chantillons affecte le r√©sultat, le crit√®re du carr√© Xi est utilis√© - si une diff√©rence statistiquement significative est d√©tect√©e, une base de donn√©es plus grande avec une taille plus petite sera √©chantillonn√©e: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">class_arrays_balancer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df1, df2, target = </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'calls'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, pvalue=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.05</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> df1_target_size = len(df1[df1[target] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>]) print(df1.columns.to_list()) df2_target_size = len(df2[df2[target] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>]) total_target_size = df1_target_size + df2_target_size chi2_target, pvalue_target, dof_target, expected_target = chi2_contingency([[df1_target_size, total_target_size], [df2_target_size, total_target_size]]) df1_other_size = len(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>]) df2_other_size = len(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>]) total_other_size = df1_other_size + df2_other_size chi2_other, pvalue_other, dof_other, expected_other = chi2_contingency([[df1_other_size, total_other_size], [df2_other_size, total_other_size]]) df1_target, df2_target, df1_other, df2_other = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> pvalue_target &lt; pvalue: sample_size = min([df1_target_size, df2_target_size]) df1_rnd_indx = np.random.choice(df1_target_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df2_rnd_indx = np.random.choice(df2_target_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df1_target = pd.DataFrame((np.asarray(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">1</span></span>])[df1_rnd_indx]).tolist(), columns = df1.columns.tolist()) df2_target = pd.DataFrame((np.asarray(df2[df2[target] == <span class="hljs-number"><span class="hljs-number">1</span></span>])[df2_rnd_indx]).tolist(), columns = df2.columns.tolist()) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p_value_other &lt; pvalue: sample_size = min([df1_other_size, df2_other_size]) df1_rnd_indx = np.random.choice(df1_other_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df2_rnd_indx = np.random.choice(df2_other_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df1_other = pd.DataFrame((np.asarray(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>])[df1_rnd_indx]).tolist(), columns = df1.columns.tolist()) df2_other = pd.DataFrame((np.asarray(df2[df2[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>])[df2_rnd_indx]).tolist(), columns = df2.columns.tolist()) df1 = pd.concat([df1_target, df1_other]) df2 = pd.concat([df2_target, df2_other]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df1, df2 exp_classes, control_classes = class_arrays_balancer(data_exp, data_control)</code> </pre> <br>  En sortie, nous obtenons des donn√©es √©quilibr√©es en taille et coh√©rentes avec les taux de conversion initiaux, les m√©triques √©tudi√©es (calcul√©es pour les valeurs moyennes du sous-bucket) dans lesquelles elles sont d√©j√† r√©parties normalement, ce qui peut √™tre vu √† la fois visuellement et par les r√©sultats de l'application des crit√®res de test d√©j√† connus de nous normalit√© (avec une valeur p&gt; = 0,05).  Par exemple, pour les indicateurs relatifs: <br><br><pre> <code class="python hljs">data_conv = (data[data[<span class="hljs-string"><span class="hljs-string">'calls'</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>].groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.sum()*<span class="hljs-number"><span class="hljs-number">1.0</span></span>/data.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).device_id.nunique()) data_conv.hist(bins = <span class="hljs-number"><span class="hljs-number">50</span></span>)</code> </pre> <br>  Maintenant, le test t peut √™tre appliqu√© √† la moyenne sur les sous-ensembles (donc, ce n'est pas device_id, pas un p√©riph√©rique, mais un sous-ensemble qui agit comme une observation). <br><br>  Apr√®s nous √™tre assur√©s que les changements sont statistiquement significatifs, nous pouvons, en toute conscience, faire ce pour quoi nous avons tout commenc√© - calculer la cannibalisation: <br><br><pre> <code class="python hljs">(data_exp.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg() - data_cntrl.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg() )/ data_exp.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg()</code> </pre> <br>  Le d√©nominateur doit √™tre le trafic sans publicit√©, c'est-√†-dire exp√©rimental. <br><br><h4>  3. M√©thode Bootstrap </h4><br>  La m√©thode bootstrap est une extension de la m√©thode sous-bucket et repr√©sente sa version plus avanc√©e et am√©lior√©e;  une impl√©mentation logicielle de cette m√©thode en Python peut √™tre trouv√©e dans la biblioth√®que Facebook Bootstrapped. <br>  En bref, l'id√©e de bootstrap peut √™tre d√©crite comme suit: une m√©thode n'est rien de plus qu'un constructeur d'√©chantillons g√©n√©r√©s de mani√®re similaire aux m√©thodes de sous-ensemble au hasard, mais avec des r√©p√©titions possibles.  Nous pouvons dire le placement de la population g√©n√©rale (si l'on peut appeler l'√©chantillon d'origine) avec le retour.  En sortie, des moyennes (ou m√©dianes, montants, etc.) sont form√©es √† partir des moyennes pour chacun des sous-√©chantillons g√©n√©r√©s. <br><br>  <i>Les principales m√©thodes de la biblioth√®que FaceBook Bootstrap</i> : <br><pre> <code class="python hljs">bootstrap()</code> </pre>  - met en ≈ìuvre un m√©canisme de formation de sous-√©chantillons;  renvoie la limite inf√©rieure (5 centile) et la limite sup√©rieure (95 centile) par d√©faut;  pour renvoyer une distribution discr√®te dans cette plage, il est n√©cessaire de d√©finir le param√®tre <i>return_distribution = True</i> (il est g√©n√©r√© par la fonction d'assistance <i>generate_distributions ()</i> ). <br><br>  Vous pouvez sp√©cifier le nombre d'it√©rations √† l'aide du param√®tre <i>num_iterations</i> , dans lequel les sous-√©chantillons seront g√©n√©r√©s, et le nombre de sous-√©chantillons <i>iteration_batch_size</i> pour chaque it√©ration.  A la sortie de <i>generate_distributions ()</i> , un √©chantillon sera g√©n√©r√© avec une taille √©gale au nombre d'it√©rations <i>num_iterations</i> , dont les √©l√©ments seront la moyenne des valeurs des √©chantillons <i>iteration_batch_size</i> calcul√©es √† chaque it√©ration.  Avec de grands volumes d'√©chantillons, les donn√©es peuvent ne plus tenir en m√©moire, il est donc conseill√© dans de tels cas de r√©duire la valeur de <i>iteration_batch_size</i> . <br><br>  <i>Exemple</i> : que l'√©chantillon d'origine soit 2 000 000;  <i>num_iterations</i> = 10 000, <i>iteration_batch_size</i> = 300. Ensuite, √† chacune des 10 000 it√©rations, 300 listes de 2 000 000 d'√©l√©ments seront stock√©es en m√©moire. <br><br>  La fonction permet √©galement le calcul parall√®le sur plusieurs c≈ìurs de processeur, sur plusieurs threads, en d√©finissant le nombre requis √† l'aide du param√®tre <i>num_threads</i> . <br><br><pre> <code class="python hljs">bootstrap_ab()</code> </pre> <br>  effectue toutes les m√™mes actions que la fonction <i>bootstrap ()</i> d√©crite ci-dessus, cependant, en outre, l'agr√©gation des valeurs moyennes est √©galement effectu√©e par la m√©thode sp√©cifi√©e dans <i>stat_func</i> - √† partir des valeurs de <i>num_iterations</i> .  Ensuite, la m√©trique sp√©cifi√©e dans le param√®tre compare_func est calcul√©e et la signification statistique est estim√©e. <br><br><pre> <code class="python hljs">compare_functions</code> </pre> <br>  - une classe de fonctions qui fournit des outils pour la formation de param√®tres d'√©valuation: <br><pre> <code class="python hljs">compare_functions.difference() compare_functions.percent_change() compare_functions.ratio() compare_functions.percent_difference() <span class="hljs-comment"><span class="hljs-comment"># difference = (test_stat - ctrl_stat) # percent_change = (test_stat - ctrl_stat) * 100.0 / ctrl_stat # ratio = test_stat / ctrl_stat # percent_difference = (test_stat - ctrl_stat) / ((test_stat + ctrl_stat) / 2.0) * 100.0</span></span></code> </pre> <br><pre> <code class="python hljs">stats_functions</code> </pre>  - une classe de fonctions √† partir de laquelle la m√©thode d'agr√©gation de la m√©trique √©tudi√©e est s√©lectionn√©e: <br><pre> <code class="python hljs">stats_functions.mean stats_functions.sum stats_functions.median stats_functions.std</code> </pre> <br>  En tant que <i>stat_func,</i> vous pouvez √©galement utiliser une fonction personnalis√©e d√©finie par l'utilisateur, par exemple: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(test_stat, ctrl_stat)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (test_stat - ctrl_stat)/test_stat bs.bootstrap_ab(test.values, control.values, stats_functions.mean, test_func, num_iterations=<span class="hljs-number"><span class="hljs-number">5000</span></span>, alpha=<span class="hljs-number"><span class="hljs-number">0.05</span></span>, iteration_batch_size=<span class="hljs-number"><span class="hljs-number">100</span></span>, scale_test_by=<span class="hljs-number"><span class="hljs-number">1</span></span>, num_threads=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br>  En fait, <i>(test_stat - ctrl_stat) / test_stat</i> est la formule pour calculer notre cannibalisation. <br><br>  Alternativement, ou dans le but d'une exp√©rience pratique, vous pouvez initialement obtenir des distributions √† l'aide de <i>bootstrap ()</i> , v√©rifier la signification statistique des diff√©rences dans les m√©triques cibles √† l'aide du test t, puis leur appliquer les manipulations n√©cessaires. <br>  Un exemple de la fa√ßon dont la distribution normale de ¬´qualit√©¬ª peut √™tre obtenue en utilisant cette m√©thode: <br><br><img src="https://habrastorage.org/webt/pc/is/ws/pciswsulv_wuinbcqkn-hgmluwe.png"><br><br>  Une documentation plus d√©taill√©e se trouve sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la page du r√©f√©rentiel</a> . <br><br>  Pour le moment, c'est tout ce dont je voulais (ou j'ai r√©ussi) √† parler.  J'ai essay√© de d√©crire bri√®vement mais clairement les m√©thodes utilis√©es et le processus de leur mise en ≈ìuvre.  Il est possible que les m√©thodologies n√©cessitent un ajustement, donc je serai reconnaissant pour les commentaires et les critiques. <br><br>  Je remercie √©galement mes coll√®gues pour leur aide dans la pr√©paration de ce travail.  Si l'article re√ßoit des commentaires majoritairement positifs, j'indiquerai ici leurs noms ou surnoms (par accord pr√©alable). <br><br>  Meilleurs voeux √† tous!  :) <br><br>  PS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dear Championship Channel</a> , la t√¢che d'√©valuer les r√©sultats des tests A / B est l'une des plus importantes en science des donn√©es, car aucun lancement d'un nouveau mod√®le ML en production n'est complet sans A / B.  Peut-√™tre qu'il est temps d'organiser un concours pour d√©velopper un syst√®me d'√©valuation des r√©sultats des tests A / B?  :) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451488/">https://habr.com/ru/post/fr451488/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451468/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 364 (6-12 mai 2019)</a></li>
<li><a href="../fr451476/index.html">LLVM en termes de Go</a></li>
<li><a href="../fr451478/index.html">Acc√©l√©rer l'exploration des donn√©es √† l'aide de la biblioth√®que de profilage pandas</a></li>
<li><a href="../fr451480/index.html">Pourquoi le minist√®re de l'Industrie et du Commerce interdit-il le stockage de donn√©es sur des √©quipements √©trangers</a></li>
<li><a href="../fr451482/index.html">Comp√©tences d'un programmeur moderne sous un angle diff√©rent</a></li>
<li><a href="../fr451492/index.html">Sept variables Bash inattendues</a></li>
<li><a href="../fr451496/index.html">Mitap Netologii ¬´Carri√®res en science des donn√©es pour les d√©butants¬ª</a></li>
<li><a href="../fr451498/index.html">Food Design Digest, avril 2019</a></li>
<li><a href="../fr451502/index.html">√âv√©nements num√©riques √† Moscou du 13 au 19 mai</a></li>
<li><a href="../fr451504/index.html">Photos sur le web 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìí üë• üëµüèΩ Was kann man sonst noch bei der Suche tun? Yandex-Bericht ü¶â üë£ üò±</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Yandex verf√ºgt √ºber einen Suchkomponenten-Entwicklungsdienst, der eine Suchbasis auf MapReduce aufbaut, Daten f√ºr den Satz zum Rendern bereitstellt, A...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Was kann man sonst noch bei der Suche tun? Yandex-Bericht</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/445152/">  Yandex verf√ºgt √ºber einen Suchkomponenten-Entwicklungsdienst, der eine Suchbasis auf MapReduce aufbaut, Daten f√ºr den Satz zum Rendern bereitstellt, Algorithmen und Datenstrukturen generiert und ML-Probleme des Qualit√§tswachstums l√∂st.  Alexey Shlyunkin, der Leiter einer der Gruppen innerhalb dieses Dienstes, erkl√§rt, woraus die Suchlaufzeit besteht und wie wir sie verwalten. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/8NHDcwOEBDs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><blockquote>  Willst du in ML st√∂bern - st√∂bern?  Sie m√∂chten nur MapReduce - ok.  Willst du Laufzeit - Laufzeit. </blockquote><br>  - Was ist heute eine Suche?  Yandex begann mit einer Suche und entwickelte sie.  20 Jahre sind vergangen.  Wir haben eine Suchbasis f√ºr Hunderte von Milliarden von Dokumenten. <br><br><a name="habracut"></a>  Wir nennen ein Dokument jede Seite im Internet, aber nicht nur sie.  Dennoch - seine Inhalte, verschiedene Statistiken dar√ºber, welche Benutzer gerne darauf zugreifen, wie viele von ihnen.  Plus die Daten, die wir berechnet haben. <br><br>  Es handelt sich auch um Zehntausende von Instanzen, die als Antwort auf jede Anforderung Daten verarbeiten, nach etwas suchen und die Suchantwort bereichern.  Einige Instanzen suchen nach Bildern, andere nach normalen Textdokumenten, andere nach Videos usw. Das hei√üt, Zehntausende von Maschinen werden f√ºr jede Anforderung aktiviert.  Sie alle versuchen, etwas zu finden und das Ergebnis zu verbessern, das Ihnen gezeigt wird.  Dementsprechend bedienen Zehntausende von Maschinen Tausende von Anforderungen pro Sekunde.  Diese Zehntausende von Instanzen werden zu Hunderten von Diensten kombiniert, um ein Problem zu l√∂sen. <br><br><img src="https://habrastorage.org/webt/vv/ge/qi/vvgeqica4ehx9uawes9ylfw098m.jpeg"><br><br>  Es gibt einen Suchkern - einen Websuchdienst.  Und es gibt einen Videosuchdienst usw. Dementsprechend gibt es eine Sache, die die Antworten verschiedener Suchanfragen kombiniert und versucht zu w√§hlen, welche und in welcher Reihenfolge es besser ist, den Benutzer zu zeigen.  Wenn dies eine Art Anfrage zu Musik ist, ist es wahrscheinlich besser, zuerst Yandex.Music und dann zum Beispiel eine Seite √ºber diese Musikgruppe zu zeigen.  Dies wird als Mixer bezeichnet.  Es gibt bereits Hunderte solcher Dienste, und sie tun f√ºr jede Anfrage etwas und versuchen, den Benutzern irgendwie zu helfen.  Und nat√ºrlich nutzt dies alles maschinelles Lernen aller Art, von einfachen Statistiken √ºber lineare Modelle bis hin zu Gradientenverst√§rkungen, neuronalen Netzen und so weiter. <br><br>  Ich werde jetzt √ºber Infrastruktur und ML sprechen. <br><br>  Meine Gruppe wird als neue Laufzeitentwicklungsgruppe bezeichnet und ist Teil des Entwicklungsdienstes f√ºr Suchkomponenten.  Damit Sie eine Idee haben, erz√§hle ich Ihnen ein wenig, was unser Service tut. <br><br><img src="https://habrastorage.org/webt/so/vn/kt/sovnktsoqacdyqxp0l7g_q9sgjm.jpeg"><br><br>  In der Tat an alle.  Wenn Sie eine Suche einreichen, haben wir fast alles in die Hand genommen, angefangen beim Aufbau einer Suchbasis.  Das hei√üt, wir haben MapReduce, wir sammeln dort alle Daten √ºber Dokumente, kochen sie, bauen alle Arten von Datenstrukturen auf, damit wir bei der Abfrage effizient etwas berechnen k√∂nnen.  Dementsprechend arbeiten wir von unten, wenn das Dokument gerade bei uns ankommt, von der ersten Phase an, wenn diese Dokumente etwas erhalten und bewerten, bis ganz oben, wo das Layout bedingtes JSON empf√§ngt und es mit allen Bildern und sch√∂nen Dingen zeichnet.  Von unten nach oben entwickeln wir etwas auf dem gesamten Stapel. <br><br>  Wir schreiben aber nicht nur Code und tun dies dementsprechend auch in der Infrastruktur.  Wir trainieren tats√§chlich neuronale Netze, CatBoost.  Und andere ML-Dinge, die Sie sich vorstellen und verbrennen k√∂nnen, lehren wir auch.  Da wir gro√üe Lasten und gro√üe Datenmengen haben, st√∂bern wir nat√ºrlich in Algorithmen und Datenstrukturen und halten uns niemals davon ab, sie irgendwo einzuf√ºhren.  Zum Beispiel verwenden wir an mehreren Stellen Segmentb√§ume.  Wir haben unsere eigene Komprimierung von Indizes, die Bor bilden, und ber√ºcksichtigen dementsprechend die Dynamik, wie W√∂rterb√ºcher am besten erstellt werden k√∂nnen. <br><br>  Im Allgemeinen waren wir mit einem so gro√üen Koloss wie einer Suche mit so einfachen Aufgaben ges√§ttigt.  Deshalb lieben wir nat√ºrlich etwas Komplexes, Neues, etwas, das uns herausfordert.  Und wir haben nicht wie √ºblich zehn Codezeilen geschrieben.  Wir m√ºssen √ºber einige Experimente nachdenken.  Im Allgemeinen stehen die Aufgaben, die wir uns stellen, oft am Rande der Fiktion.  Manchmal denkst du: Es ist wahrscheinlich nicht m√∂glich.  Aber dann haben Sie vielleicht irgendwie experimentiert - Experimente k√∂nnen ein ganzes Jahr dauern -, aber am Ende stellt sich etwas heraus.  Dann fangen wir an, etwas vorzustellen, neu zu machen. <br><br>  Neben Projekten, F√§higkeiten usw. sind wir im Allgemeinen eines der ehrgeizigsten und am schnellsten wachsenden Teams in Yandex.  Zum Beispiel kam ich vor zwei Jahren, war die neunte Person in unserem Dienst.  Jetzt haben wir einen Service von fast 60 Personen.  Dies ist in der Tat bei den Praktikanten der Fall, aber im Allgemeinen sind wir in zwei Jahren genau viermal gewachsen.  Dies soll Ihnen eine Vorstellung davon geben, was unser Service tut. <br><br>  Jetzt m√∂chte ich Ihnen ein wenig √ºber unsere Aufgaben und die Richtung erz√§hlen, in die wir in naher Zukunft immer relevanter werden.  Dazu m√ºssen Sie jedoch zun√§chst kurz beschreiben, wie die grundlegendste Suchebene funktioniert. <br><br><img src="https://habrastorage.org/webt/by/3e/eu/by3eeuckwlvf33ia2f_hwovampe.jpeg"><br><br>  Generell funktioniert alles sehr einfach.  Wir haben unsere Suchbasis, wir haben alle Dokumente und wir teilen alle diese Dokumente mehr oder weniger gleichm√§√üig in N Teile auf.  Sie werden Scherben genannt.  Und ein Programm namens "Basic Search" wird √ºber den Shard gestartet.  Ihre Aufgabe ist es, entsprechend nach diesem Teil des Internets zu suchen.  Das hei√üt, sie wei√ü, wie man danach sucht und wei√ü nichts mehr √ºber das andere Internet.  Und wir haben so N Scherben.  √úber ihnen werden grundlegende Suchvorg√§nge gestartet, und dementsprechend gibt es dar√ºber eine Metasuche.  Die Anfrage des Benutzers f√§llt hinein und geht dementsprechend einfach an alle Shards, und jeder Shard f√ºhrt eine Suche durch, dann gibt jeder ein Ergebnis zur√ºck, f√ºhrt eine Art Zusammenf√ºhrung durch und gibt eine Antwort. <br><br>  So wurde die Suche f√ºr fast alle 20 Jahre organisiert, und im Allgemeinen dachten sie lange Zeit, dass dies so bleiben w√ºrde und nichts Besseres getan werden k√∂nnte.  Aber alles √§ndert sich, neue Technologien entstehen, und durch maschinelles Lernen k√∂nnen Sie nicht nur die Qualit√§t steigern, sondern auch Infrastrukturprobleme l√∂sen.  In letzter Zeit wurden bei unserer Suche sehr viele Projekte an der Schnittstelle von Infrastruktur und maschinellem Lernen gedreht.  Wenn zwei solcher Mastodons verschmelzen, werden sehr interessante Ergebnisse erhalten. <br><br><img src="https://habrastorage.org/webt/ty/0s/zo/ty0szoxygxc0jvgwxifylxmfqqi.jpeg"><br><br>  Vor kurzem sind neuronale Netze erschienen.  Wir haben den Text der Anfrage, da ist der Text des Dokuments.  Wir m√∂chten einen Zahlenvektor aus der Anforderung abrufen, um einen Zahlenvektor aus dem Dokument abzurufen, damit das Skalarprodukt den gew√ºnschten Wert vorhersagt.  Zum Beispiel m√∂chten wir das Skalarprodukt trainieren, um die Wahrscheinlichkeit vorherzusagen, mit der ein Benutzer auf dieses Dokument klickt.  Ziemlich verst√§ndlich. <br><br><img src="https://habrastorage.org/webt/dr/cx/dl/drcxdlgw4bne__esu_lvrfumefy.jpeg"><br><br>  Es ist ungef√§hr so ‚Äã‚Äãangeordnet.  Wenn sehr, sehr unh√∂flich, dann haben wir einige W√∂rter auf der untersten Ebene, und dann gibt es mehrere Ebenen des Netzwerks.  Tats√§chlich nimmt jede Schicht einen Vektor als Eingabe.  Das hei√üt, die unterste Schicht ist ein so sp√§rlicher Vektor, bei dem jedes Wort eine Anforderung ist.  Multipliziert es mit einer Matrix, erh√§lt eine Art Vektor und wendet dementsprechend eine gewisse Nichtlinearit√§t auf jede Komponente an, und dies mehrmals.  Und die letzte Ebene, dies wird nur der Vektor genannt, den wir gerade aufgenommen haben, hat solche Ebenen angewendet, und hier ist die letzte Ebene genau der Anforderungsvektor. <br><br>  Dementsprechend wurden diese neuronalen Netze in den letzten Jahren aktiv in die Suche eingef√ºhrt, sie brachten viele Vorteile f√ºr die Qualit√§t.  Sie haben jedoch das Problem, dass alle Gr√∂√üen, die wir vorhersagen m√∂chten, gut, aber grob genug sind, denn um ein solches neuronales Netzwerk zu trainieren, ist die unterste Schicht sehr gro√ü - alle W√∂rter stammen aus zig Millionen W√∂rtern, sodass Sie schreiben k√∂nnen m√ºssen Sie gab mehrere Milliarden Daten ein. <br><br>  Zum Beispiel k√∂nnen wir einige Benutzerklicks trainieren und so weiter.  Das wichtigste Signal, das bei unserer Suche als das wichtigste angesehen wird, ist die manuelle Kennzeichnung durch bestimmte Personen.  Sie nehmen die Anfrage entgegen, nehmen das Dokument, lesen es, verstehen, wie gut es ist, und markieren, dh wie sehr dieses Dokument zu dieser Anfrage passt.  Lange Zeit konnten wir eine solche Gr√∂√üenordnung von neuronalen Netzen nicht vorhersagen, da wir immer noch Millionen von Sch√§tzungen haben, weil es sehr teuer ist, den gesamten Planeten einzustellen, um st√§ndig alles zu markieren.  Deshalb haben wir einen Hack gemacht. <br><br><img src="https://habrastorage.org/webt/ao/yb/3m/aoyb3mcdap3a7l4lyett7y9h9bo.jpeg"><br><br>  Neuronales Netz neuronaler Netze.  In den letzten Jahren haben wir eine Menge neuronaler Netze angesammelt, die gute Signale vorhersagen, aber etwas rauer als die Einsch√§tzung spezieller Personen.  Dementsprechend haben wir beschlossen, die vorgefertigten Vektoren dieser Netzwerke an die untere Schicht zu senden, und dann werden wir das neuronale Netzwerk trainieren, um unsere Suchrelevanz f√ºr das kleinere Datennetz vorherzusagen. <br><br>  Das Ergebnis war ein sehr gutes Modell.  Sie bringt die Anforderungen von Dokumenten in einen Vektor und ihr skalares Produkt sagt direkt die tats√§chliche Relevanz voraus, die wir schon lange vorhersagen wollten. <br><br>  Au√üerdem hatten wir eine Idee, wie wir die Suche ein wenig wiederholen k√∂nnen.  Das Projekt wird als KNN-Basis bezeichnet (englische k-n√§chste Nachbarn, k-n√§chste Nachbarn-Methode). <br><br><img src="https://habrastorage.org/webt/ev/il/uw/eviluwyaq_ip-xgtae0jpojo6su.jpeg"><br><br>  Die Grundidee ist dies.  Wir haben einen Abfragevektor und einen Dokumentvektor.  Wir m√ºssen den n√§chsten finden.  Wir haben jedes Dokument durch einen Vektor dargestellt.  Lassen Sie uns N Cluster hervorheben, die den gesamten Dokumentraum charakterisieren.  Grob gesagt.  Stark kleiner als die Anzahl der Dokumente, aber zum Beispiel charakterisieren sie Themen.  In einfachen Worten, es gibt eine Gruppe von Katzen, eine Gruppe von Lebensmitteln, eine Gruppe von Programmen und so weiter. <br><br>  Dementsprechend werden wir Dokumente nicht wie zuvor zuf√§llig in Shards streuen, sondern das Dokument in diesen Shard legen, dh dessen Schwerpunkt dem Dokument am n√§chsten liegt.  Dementsprechend werden wir solche Dokumente nach Themen in Shard gruppiert haben. <br><br>  Und weiter, nur f√ºr eine Anfrage, k√∂nnen wir jetzt nicht zu allen Scherben gehen, sondern nur zu einer kleinen Teilmenge derer, die dieser Anfrage am n√§chsten sind. <br><br><img src="https://habrastorage.org/webt/xq/-x/xz/xq-xxz9zsxwngyiaovqilmdytda.jpeg"><br><br>  Dementsprechend hatten wir ein solches Schema, Metasuche ist in allen Shards enthalten.  Und jetzt muss er zu einer viel kleineren Nummer gehen, und gleichzeitig werden wir immer noch nach den n√§chsten Dokumenten suchen. <br><br>  Was bekommen wir eigentlich von diesem Design?  Dies reduziert den Verbrauch von Computerressourcen erheblich, einfach weil wir weniger Cluster verwenden.  Dies ist, wie ich bereits sagte, einer der H√∂hepunkte unseres Service. Dies ist die Legierung aus Infrastruktur und maschinellem Lernen, die solche Ergebnisse liefert, an die niemand zuvor denken konnte. <br><br><img src="https://habrastorage.org/webt/sq/r3/pd/sqr3pdlcsbgwah4raljs1y8y45k.jpeg"><br><br>  Und am Ende ist es einfach eine ziemlich lustige Sache, denn Sie haben die Modelle hier und dann haben Sie die gesamte Suche √ºberarbeitet, die Petabyte an Daten deaktiviert und die Suche funktioniert f√ºr Sie. Sie verbraucht zehnmal weniger Ressourcen.  Sie haben eine Milliarde Dollar f√ºr das Unternehmen gespart, alle sind gl√ºcklich. <br><br><img src="https://habrastorage.org/webt/zs/wl/ei/zswlei9tbbnwnjad68aa48h8h54.jpeg"><br><br>  Ich habe √ºber eines der Projekte gesprochen, die in unserer Suche erscheinen und die zusammen mit allen Experimenten f√ºr ein suspendiertes Jahr umgesetzt und durchgef√ºhrt werden.  Unsere anderen typischen Aufgaben sind die Verdoppelung der Suchbasis, da das Internet st√§ndig w√§chst und wir es einholen und auf allen Seiten im Internet suchen m√∂chten.  Und dies ist nat√ºrlich die Beschleunigung der Basisschicht, in der es die meisten F√§lle gibt, das meiste Eisen.  Wenn Sie beispielsweise Ihre Basissuche um ein Prozent beschleunigen, sparen Sie etwa eine Million Dollar. <br><br>  Wir sind auch als Startup-Inkubator an der Suche beteiligt.  Ich werde es erkl√§ren.  Die Suche wird seit 20 Jahren durchgef√ºhrt.  Es hat schon viele Dinge getan, oft sind wir auf eine Sackgasse gesto√üen und dachten, dass nichts mehr getan werden k√∂nnte.  Dann gab es eine lange Reihe von Experimenten.  Wir haben diese Sackgasse wieder durchbrochen.  Und in dieser Zeit haben wir viel Fachwissen gesammelt, wie man gro√üe und coole Dinge macht.  Dementsprechend werden die meisten neuen Anweisungen in Yandex jetzt in der Suche ausgef√ºhrt, da die Suchenden bereits wissen, wie dies alles zu tun ist, und es logisch ist, sie zu bitten, zumindest ein neues System zu entwerfen.  Und maximal - mach es selbst. <br><br>  Nun hoffe ich, dass Sie eine kleine Vorstellung von unserer Arbeit haben.  Ich werde schnell den thematischen Teil meiner Geschichte √ºber Praktikanten in unserem Dienst erz√§hlen.  Wir lieben sie sehr.  Wir haben viele davon, letzten Sommer gab es nur in meiner Gruppe 20 Auszubildende, und ich finde das gut.  Wenn Sie ein oder drei Praktikanten nehmen, f√ºhlen sie sich ein wenig einsam, manchmal haben sie Angst, √§ltere Kameraden zu fragen.  Und wenn es viele von ihnen gibt, kommunizieren sie als Kameraden im Ungl√ºck miteinander.  Wenn sie Angst haben, Entwickler etwas zu fragen, werden sie gehen und in die Ecke fl√ºstern.  Eine solche Atmosph√§re hilft, alles effizient zu machen. <br><br>  Wir haben eine Million Aufgaben, das Team ist nicht sehr gro√ü, daher sind unsere Praktikanten voll ausgelastet.  Wir bitten den Auszubildenden nicht, die ganze Zeit am Protokoll zu sitzen, Tests zu schreiben, den Code zu √ºberarbeiten, sondern geben sofort eine komplizierte Produktionsaufgabe: Beschleunigen Sie die Suche, verbessern Sie die Indexkomprimierung.  Nat√ºrlich helfen wir.  Wir wissen, dass sich das alles auszahlt, deshalb teilen wir gerne unser Fachwissen.  Da unser T√§tigkeitsfeld sehr umfangreich ist, wird jeder von uns eine Aufgabe f√ºr sich finden, die ihm gef√§llt.  Willst du in ML st√∂bern - st√∂bern?  Sie m√∂chten nur MapReduce - ok.  Willst du Laufzeit - Laufzeit.  Da ist alles. <br><br>  Was brauchen Sie, um zu uns zu kommen?  Wir machen alles haupts√§chlich in C ++ und Python.  Es ist nicht notwendig, beide zu kennen. Man kann eines wissen.  Wir begr√º√üen die Kenntnis von Algorithmen.  Es bildet einen bestimmten Denkstil und hilft sehr.  Dies ist aber auch nicht notwendig: Auch hier sind wir bereit, alles zu lehren, wir sind bereit, unsere Zeit zu investieren, weil wir wissen, dass es sich auszahlt.  Die wichtigste Anforderung, die wir stellen, unser Motto, ist, vor nichts und vielen Zahlen Angst zu haben.  Haben Sie keine Angst, die Produktion einzustellen, haben Sie keine Angst, etwas Kompliziertes zu tun.  Deshalb brauchen wir Menschen, die auch vor nichts Angst haben und bereit sind, Berge zu verwandeln.  Vielen Dank. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de445152/">https://habr.com/ru/post/de445152/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de445136/index.html">Sei nicht nerv√∂s, beeile dich nicht, unterbreche nicht: die Geschichte einer Trag√∂die</a></li>
<li><a href="../de445138/index.html">IBM Integration Bus und was es isst</a></li>
<li><a href="../de445140/index.html">PHP Digest Nr. 152 (11. - 25. M√§rz 2019)</a></li>
<li><a href="../de445146/index.html">Die Geschichte des Slonik-Elefanten, das PostgreSQL-Logo</a></li>
<li><a href="../de445150/index.html">Upwork ist in der Russischen F√∂deration registriert</a></li>
<li><a href="../de445154/index.html">Digitale Veranstaltungen in Moskau vom 25. bis 31. M√§rz</a></li>
<li><a href="../de445156/index.html">Glenmark Kompaktvernebler: eine n√ºtzliche Sache im Alltag</a></li>
<li><a href="../de445158/index.html">Optimale Teileorientierung und Support-Konfiguration im 3D-Drucker</a></li>
<li><a href="../de445160/index.html">Wir entwickeln eine Pedal-Firmware, um das Balalaika-Spielen zu lernen</a></li>
<li><a href="../de445162/index.html">Terraform Provider Selectel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
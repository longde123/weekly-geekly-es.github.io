<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐽 👨🏻‍🔧 👨🏼‍🔬 .NET, TensorFlow et les moulins à vent de Kaggle - le voyage commence 👩🏼‍🚒 🤰 🧔🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il s'agit d'une série d'articles sur mon voyage en cours dans la forêt sombre des compétitions Kaggle en tant que développeur .NET. 

 Je me concentre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>.NET, TensorFlow et les moulins à vent de Kaggle - le voyage commence</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437174/"><img src="https://habrastorage.org/webt/tc/fj/ml/tcfjml8-rk618mttrw9qhvfan_u.png" align="left">  Il s'agit d'une série d'articles sur mon voyage en cours dans la forêt sombre des compétitions <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" title="Kaggle">Kaggle en</a> tant que développeur .NET. <br><br>  Je me concentrerai sur les réseaux de neurones (presque) purs dans cet article et les suivants.  Cela signifie que la plupart des parties ennuyeuses de la préparation de l'ensemble de données, comme le remplissage des valeurs manquantes, la sélection des fonctionnalités, l'analyse des valeurs aberrantes, etc.  sera intentionnellement ignoré. <br><br>  La pile technologique sera l'API C # + TensorFlow <i>tf.keras</i> .  À ce jour, il faudra également Windows.  Les modèles plus grands dans les futurs articles peuvent avoir besoin d'un GPU approprié pour que leur temps de formation reste sain. <br><a name="habracut"></a><br><h2>  Prédisons les prix de l'immobilier! </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les prix des maisons</a> sont une grande compétition pour les novices.  Son jeu de données est petit, il n'y a pas de règles spéciales, le classement public a de nombreux participants et vous pouvez soumettre jusqu'à 4 entrées par jour. <br><br>  Inscrivez-vous sur Kaggle, si vous ne l'avez pas encore fait, rejoignez ce concours et téléchargez les données.  L'objectif est de prédire le prix de vente (colonne SalePrice) pour les entrées dans <i>test.csv</i> .  L'archive contient <i>train.csv</i> , qui compte environ 1500 entrées avec un prix de vente connu pour s'entraîner.  Nous allons commencer par charger cet ensemble de données et l'explorer un peu avant d'entrer dans les réseaux de neurones. <br><br><h2>  Analyser les données d'entraînement </h2><br>  <i>Ai-je dit que nous allons sauter la préparation de l'ensemble de données?</i>  <i>J'ai menti!</i>  <i>Vous devez jeter un oeil au moins une fois.</i> <br><br>  À ma grande surprise, je n'ai pas trouvé de moyen facile de charger un fichier .csv dans la bibliothèque de classes standard .NET, j'ai donc installé un package NuGet, appelé <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CsvHelper</a> .  Pour simplifier la manipulation des données, j'ai également obtenu mon nouveau package d'extension LINQ préféré <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MoreLinq</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Chargement de données .csv dans DataTable</b> <div class="spoiler_text"><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> DataTable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">LoadData</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> csvFilePath</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> result = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DataTable(); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> reader = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvDataReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamReader(csvFilePath)))) { result.Load(reader); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; }</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">ML.NET</b> <div class="spoiler_text">  L'utilisation de <i>DataTable</i> pour la formation à la manipulation des données est, en fait, une mauvaise idée. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ML.NET</a> est censé avoir le chargement .csv et de nombreuses opérations de peparation et d'exploration de données.  Cependant, il n'était pas encore prêt à cet usage particulier, lorsque je viens de participer au concours des prix des logements. <br></div></div><br><br>  Les données ressemblent à ceci (seulement quelques lignes et colonnes): <br><br><table><tbody><tr><td>  Id </td><td>  MSSubClass </td><td>  Msoning </td><td>  LotFrontage </td><td>  Lotarea </td></tr><tr><td>  1 </td><td>  60 </td><td>  RL </td><td>  65 </td><td>  8450 </td></tr><tr><td>  2 </td><td>  20 </td><td>  RL </td><td>  80 </td><td>  9600 </td></tr><tr><td>  3 </td><td>  60 </td><td>  RL </td><td>  68 </td><td>  11250 </td></tr><tr><td>  4 </td><td>  70 </td><td>  RL </td><td>  60 </td><td>  9550 </td></tr></tbody></table><br><br>  Après le chargement des données, nous devons supprimer la colonne <i>Id</i> , car elle n'est en fait pas liée au prix des maisons: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> trainData = LoadData(<span class="hljs-string"><span class="hljs-string">"train.csv"</span></span>); trainData.Columns.Remove(<span class="hljs-string"><span class="hljs-string">"Id"</span></span>);</code> </pre> <br><h3>  Analyse des types de données de colonne </h3><br>  DataTable n'infère pas automatiquement les types de données des colonnes et suppose qu'il s'agit de toutes les chaînes.  La prochaine étape consiste donc à déterminer ce que nous avons réellement.  Pour chaque colonne, j'ai calculé les statistiques suivantes: nombre de valeurs distinctes, combien d'entre elles sont des nombres entiers et combien d'entre elles sont des nombres à virgule flottante (un code source avec toutes les méthodes d'assistance sera lié à la fin de l'article): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> values = rows.Select(row =&gt; (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column]); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> ints = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> distincts = values.Distinct().Count();</code> </pre> <br><h3>  Colonnes numériques </h3><br>  Il s'avère que la plupart des colonnes sont en fait des entiers, mais comme les réseaux de neurones fonctionnent principalement sur des nombres flottants, nous les convertirons de toute façon en doubles. <br><br><h3>  Colonnes catégorielles </h3><br>  D'autres colonnes décrivent les catégories auxquelles appartenait la propriété en vente.  Aucun d'entre eux n'a trop de valeurs différentes, ce qui est bien.  Pour les utiliser comme entrée pour notre futur réseau de neurones, ils doivent également être convertis pour <i>doubler</i> . <br><br>  Initialement, je leur ai simplement attribué des numéros de 0 à distinctValueCount - 1, mais cela n'a pas beaucoup de sens, car il n'y a en fait aucune progression de "Facade: Blue" à "Facade: Green" en "Facade: White".  Donc, au début, j'ai changé cela en ce qu'on appelle un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">codage à chaud</a> , où chaque valeur unique obtient une colonne d'entrée distincte.  Par exemple, «Facade: Blue» devient [1,0,0] et «Facade: White» devient [0,0,1]. <br><br><h3>  Les réunir tous </h3><br><div class="spoiler">  <b class="spoiler_title">Grande sortie d'exploration de données</b> <div class="spoiler_text">  CentralAir: 2 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Rue: 2 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Utilitaires: 2 valeurs, entiers: 0,00%, flottants: 0,00% <br>  Allée: 3 valeurs, pouces: 0,00%, flottants: 0,00% <br>  BsmtHalfBath: 3 valeurs, entiers: 100,00%, flottants: 100,00% <br>  HalfBath: 3 valeurs, entiers: 100,00%, flottants: 100,00% <br>  LandSlope: 3 valeurs, entiers: 0,00%, flottants: 0,00% <br>  PavedDrive: 3 valeurs, pouces: 0,00%, flottants: 0,00% <br>  BsmtFullBath: 4 valeurs, entiers: 100,00%, flottants: 100,00% <br>  ExterQual: 4 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Cheminées: 4 valeurs, pouces: 100,00%, flotteurs: 100,00% <br>  FullBath: 4 valeurs, entiers: 100,00%, flottants: 100,00% <br>  GarageFinish: 4 valeurs, pouces: 0,00%, flottants: 0,00% <br>  KitchenAbvGr: 4 valeurs, pouces: 100,00%, flottants: 100,00% <br>  KitchenQual: 4 valeurs, pouces: 0,00%, flottants: 0,00% <br>  LandContour: 4 valeurs, entiers: 0,00%, flottants: 0,00% <br>  LotShape: 4 valeurs, entiers: 0,00%, flottants: 0,00% <br>  PoolQC: 4 valeurs, entiers: 0,00%, flottants: 0,00% <br>  BldgType: 5 valeurs, entiers: 0,00%, flottants: 0,00% <br>  BsmtCond: 5 valeurs, entiers: 0,00%, flottants: 0,00% <br>  BsmtExposure: 5 valeurs, entiers: 0,00%, flottants: 0,00% <br>  BsmtQual: 5 valeurs, entiers: 0,00%, flottants: 0,00% <br>  ExterCond: 5 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Clôture: 5 valeurs, pouces: 0,00%, flottants: 0,00% <br>  GarageCars: 5 valeurs, entiers: 100,00%, flottants: 100,00% <br>  Chauffage QC: 5 valeurs, pouces: 0,00%, flottants: 0,00% <br>  LotConfig: 5 valeurs, pouces: 0,00%, flottants: 0,00% <br>  MasVnrType: 5 valeurs, entiers: 0,00%, flottants: 0,00% <br>  MiscFeature: 5 valeurs, entiers: 0,00%, flottants: 0,00% <br>  MSZoning: 5 valeurs, entiers: 0,00%, flottants: 0,00% <br>  YrSold: 5 valeurs, entiers: 100,00%, flottants: 100,00% <br>  Électrique: 6 valeurs, pouces: 0,00%, flottants: 0,00% <br>  FireplaceQu: 6 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Fondation: 6 valeurs, entiers: 0,00%, flottants: 0,00% <br>  GarageCond: 6 valeurs, pouces: 0,00%, flottants: 0,00% <br>  GarageQual: 6 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Chauffage: 6 valeurs, pouces: 0,00%, flottants: 0,00% <br>  RoofStyle: 6 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Condition: 6 valeurs, pouces: 0,00%, flottants: 0,00% <br>  BsmtFinType1: 7 valeurs, entiers: 0,00%, flottants: 0,00% <br>  BsmtFinType2: 7 valeurs, entiers: 0,00%, flottants: 0,00% <br>  Fonctionnel: 7 valeurs, pouces: 0,00%, flottants: 0,00% <br>  GarageType: 7 valeurs, pouces: 0,00%, flottants: 0,00% <br>  BedroomAbvGr: 8 valeurs, pouces: 100,00%, flottants: 100,00% <br>  Condition2: 8 valeurs, pouces: 0,00%, flottants: 0,00% <br>  HouseStyle: 8 valeurs, pouces: 0,00%, flottants: 0,00% <br>  PoolArea: 8 valeurs, entiers: 100,00%, flottants: 100,00% <br>  RoofMatl: 8 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Condition 1: 9 valeurs, pouces: 0,00%, flottants: 0,00% <br>  GlobalCond: 9 valeurs, pouces: 100,00%, flottants: 100,00% <br>  SaleType: 9 valeurs, pouces: 0,00%, flottants: 0,00% <br>  Qualité globale: 10 valeurs, pouces: 100,00%, flottants: 100,00% <br>  MoSold: 12 valeurs, pouces: 100,00%, flottants: 100,00% <br>  TotRmsAbvGrd: 12 valeurs, entiers: 100,00%, flottants: 100,00% <br>  Extérieur 1er: 15 valeurs, pouces: 0,00%, flottants: 0,00% <br>  MSSubClass: 15 valeurs, entiers: 100,00%, flottants: 100,00% <br>  Extérieur2e: 16 valeurs, pouces: 0,00%, flottants: 0,00% <br>  3SsnPorch: 20 valeurs, entiers: 100,00%, flottants: 100,00% <br>  MiscVal: 21 valeurs, entiers: 100,00%, flottants: 100,00% <br>  LowQualFinSF: 24 valeurs, entiers: 100,00%, flottants: 100,00% <br>  Quartier: 25 valeurs, entrées: 0,00%, flottants: 0,00% <br>  YearRemodAdd: 61 valeurs, entiers: 100,00%, flottants: 100,00% <br>  ScreenPorch: 76 valeurs, pouces: 100,00%, flottants: 100,00% <br>  GarageYrBlt: 98 valeurs, pouces: 94,45%, flottants: 94,45% <br>  LotFrontage: 111 valeurs, pouces: 82,26%, flottants: 82,26% <br>  Année de construction: 112 valeurs, pouces: 100,00%, flottants: 100,00% <br>  EnclosedPorch: 120 valeurs, entiers: 100,00%, flottants: 100,00% <br>  BsmtFinSF2: 144 valeurs, entiers: 100,00%, flottants: 100,00% <br>  OpenPorchSF: 202 valeurs, entiers: 100,00%, flottants: 100,00% <br>  WoodDeckSF: 274 valeurs, entiers: 100,00%, flottants: 100,00% <br>  MasVnrArea: 328 valeurs, entrées: 99,45%, flottants: 99,45% <br>  2ndFlrSF: 417 valeurs, entiers: 100,00%, flottants: 100,00% <br>  GarageArea: 441 valeurs, entiers: 100,00%, flottants: 100,00% <br>  BsmtFinSF1: 637 valeurs, entiers: 100,00%, flottants: 100,00% <br>  SalePrix: 663 valeurs, pouces: 100,00%, flottants: 100,00% <br>  TotalBsmtSF: 721 valeurs, entiers: 100,00%, flottants: 100,00% <br>  1stFlrSF: 753 valeurs, entiers: 100,00%, flottants: 100,00% <br>  BsmtUnfSF: 780 valeurs, entiers: 100,00%, flottants: 100,00% <br>  GrLivArea: 861 valeurs, entiers: 100,00%, flottants: 100,00% <br>  LotArea: 1073 valeurs, entiers: 100,00%, flottants: 100,00% <br><br>  De nombreuses colonnes de valeurs: <br>  Extérieur1er: AsbShng, AsphShn, BrkComm, BrkFace, CBlock, CemntBd, HdBoard, ImStucc, MetalSd, Plywood, Stone, Stucco, VinylSd, Wd Sdng, WdShing <br>  Exterior2nd: AsbShng, AsphShn, Brk Cmn, BrkFace, CBlock, CmentBd, HdBoard, ImStucc, MetalSd, Other, Plywood, Stone, Stucco, VinylSd, Wd Sdng, Wd Shng <br>  Quartier: Blmngtn, Blueste, BrDale, BrkSide, ClearCr, CollgCr, Crawfor, Edwards, Gilbert, IDOTRR, MeadowV, Mitchel, NAmes, NoRidge, NPkVill, NridgHt, NWAmes, OldTown, Sawyer, SawyerW, Somerst, Stone, Stoner Veenker <br><br>  flotteurs non analysables <br>  GarageYrBlt: NA <br>  LotFrontage: NA <br>  MasVnrArea: NA <br><br>  gammes de flotteurs: <br>  BsmtHalfBath: 0 ... 2 <br>  HalfBath: 0 ... 2 <br>  BsmtFullBath: 0 ... 3 <br>  Cheminées: 0 ... 3 <br>  FullBath: 0 ... 3 <br>  KitchenAbvGr: 0 ... 3 <br>  GarageCars: 0 ... 4 <br>  Année: 2006 ... 2010 <br>  BedroomAbvGr: 0 ... 8 <br>  PoolArea: 0 ... 738 <br>  GlobalCond: 1 ... 9 <br>  Qualité globale: 1 ... 10 <br>  MoSold: 1 ... 12 <br>  TotRmsAbvGrd: 2 ... 14 <br>  MSSubClass: 20 ... 190 <br>  3SsnPorch: 0 ... 508 <br>  MiscVal: 0 ... 15500 <br>  LowQualFinSF: 0 ... 572 <br>  AnnéeRemodAjouter: 1950 ... 2010 <br>  ScreenPorch: 0 ... 480 <br>  GarageYrBlt: 1900 ... 2010 <br>  LotFrontage: 21 ... 313 <br>  Année de construction: 1872 ... 2010 <br>  EnclosedPorch: 0 ... 552 <br>  BsmtFinSF2: 0 ... 1474 <br>  OpenPorchSF: 0 ... 547 <br>  WoodDeckSF: 0 ... 857 <br>  MasVnrArea: 0 ... 1600 <br>  2ndFlrSF: 0 ... 2065 <br>  GarageArea: 0 ... 1418 <br>  BsmtFinSF1: 0 ... 5644 <br>  Prix: 34,900 ... 755,000 <br>  TotalBsmtSF: 0 ... 6110 <br>  1stFlrSF: 334 ... 4692 <br>  BsmtUnfSF: 0 ... 2336 <br>  GrLivArea: 334 ... 5642 <br>  LotArea: 1300 ... 215245 <br></div></div><br><br>  Dans cet esprit, j'ai construit le <i>ValueNormalizer</i> suivant, qui prend quelques informations sur les valeurs à l'intérieur de la colonne, et renvoie une fonction, qui transforme une valeur (une <i>chaîne</i> ) en un vecteur d' <i>entité</i> numérique pour le réseau de neurones ( <i>double []</i> ): <br><br><div class="spoiler">  <b class="spoiler_title">ValueNormalizer</b> <div class="spoiler_text"><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Func&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[]&gt; ValueNormalizer( <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats, IEnumerable&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>&gt; values) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (floats &gt; <span class="hljs-number"><span class="hljs-number">0.01</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> max = values.AsDouble().Max().Value; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span>[] { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(s, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) ? v / max : <span class="hljs-number"><span class="hljs-number">-1</span></span> }; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>[] domain = values.Distinct().OrderBy(v =&gt; v).ToArray(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[domain.Length+<span class="hljs-number"><span class="hljs-number">1</span></span>] .Set(Array.IndexOf(domain, s)+<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); } }</code> </pre> <br></div></div><br>  Nous avons maintenant les données converties dans un format adapté à un réseau de neurones.  Il est temps d'en construire un. <br><br><h2>  Construisez un réseau de neurones </h2><br>  <i>À partir d'aujourd'hui, vous devrez utiliser une machine Windows pour cela.</i> <br><br>  Si vous avez déjà installé Python et TensorFlow 1.1x, tout ce dont vous avez besoin est <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">PackageReference</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Include</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"Gradient"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Version</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"0.1.10-tech-preview3"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre> <br>  dans votre fichier .csproj moderne.  Sinon, reportez-vous au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">manuel Gradient</a> pour effectuer la configuration initiale. <br><br>  Une fois le package opérationnel, nous pouvons créer notre premier réseau profond peu profond. <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras.layers; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.train; ... <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> model = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Sequential(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Layer[] { <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">16</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dropout(rate: <span class="hljs-number"><span class="hljs-number">0.1</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">10</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">1</span></span>, activation: tf.nn.relu_fn), }); model.compile(optimizer: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AdamOptimizer(), loss: <span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>);</code> </pre> <br>  Cela créera un réseau neuronal non formé avec 3 couches de neurones et une couche de décrochage, ce qui aidera à éviter le surapprentissage. <br><br><div class="spoiler">  <b class="spoiler_title">tf.nn.relu_fn</b> <div class="spoiler_text">  <i>tf.nn.relu_fn</i> est la fonction d'activation de nos neurones.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ReLU</a> est connu pour bien fonctionner dans les réseaux profonds, car il résout le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">problème de gradient qui disparaît</a> : les dérivées des fonctions d'activation non linéaires d'origine avaient tendance à devenir très petites lorsque l'erreur se propageait depuis la couche de sortie dans les réseaux profonds.  Cela signifiait que les couches plus proches de l'entrée ne s'ajusteraient que très légèrement, ce qui ralentissait considérablement la formation des réseaux profonds. <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Abandon</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le décrochage</a> est une couche de fonctions spéciales dans les réseaux de neurones, qui ne contient en fait pas de neurones en tant que tels.  Au lieu de cela, il fonctionne en prenant chaque entrée individuelle et la remplace de manière aléatoire par 0 sur la sortie automatique (sinon elle transmet simplement la valeur d'origine).  Ce faisant, cela permet d'éviter le sur- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ajustement</a> à des entités moins pertinentes dans un petit ensemble de données.  Par exemple, si nous ne supprimions pas la colonne <i>Id</i> , le réseau pourrait potentiellement mémoriser le mappage &lt;Id&gt; -&gt; &lt;SalePrice&gt; exactement, ce qui nous donnerait une précision de 100% sur l'ensemble de formation, mais des chiffres complètement indépendants sur toutes les autres données. <br><br>  Pourquoi avons-nous besoin d'abandon?  Nos données d'entraînement n'ont que ~ 1500 exemples, et ce minuscule réseau de neurones que nous avons construit a&gt; 1800 poids accordables.  S'il s'agissait d'un simple polynôme, il pourrait correspondre à la fonction de prix que nous essayons d'approcher exactement.  Mais alors, il aurait des valeurs énormes sur toutes les entrées en dehors de l'ensemble de formation d'origine. <br></div></div><br><h2>  Nourrir les données </h2><br>  TensorFlow attend ses données soit dans des tableaux NumPy, soit dans des tenseurs existants.  Je convertis DataRows en tableaux NumPy: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> numpy; ... <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> predict = <span class="hljs-string"><span class="hljs-string">"SalePrice"</span></span>; <span class="hljs-function"><span class="hljs-function">ndarray </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetInputs</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">IEnumerable&lt;DataRow&gt; rowSeq</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(rowSeq.Select(row =&gt; np.array( columnTypes .Where(c =&gt; c.column.ColumnName != predict) .SelectMany(column =&gt; column.normalizer( row.Table.Columns.Contains(column.column.ColumnName) ? (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column.column.ColumnName] : <span class="hljs-string"><span class="hljs-string">"-1"</span></span>)) .ToArray())) .ToArray() ); } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> predictColumn = columnTypes.Single(c =&gt; c.column.ColumnName == predict); ndarray trainOutputs = np.array(predictColumn.trainValues .AsDouble() .Select(v =&gt; v ?? <span class="hljs-number"><span class="hljs-number">-1</span></span>) .ToArray()); ndarray trainInputs = GetInputs(trainRows);</code> </pre> <br>  Dans le code ci-dessus, nous convertissons chaque <i>DataRow</i> en <i>ndarray</i> en prenant chaque cellule qu'il <i>contient</i> et en appliquant le <i>ValueNormalizer</i> correspondant à sa colonne.  Ensuite, nous mettons toutes les lignes dans un autre <i>ndarray</i> , obtenant un tableau de tableaux. <br><br>  Aucune transformation de ce type n'est nécessaire pour les sorties, où nous convertissons simplement les valeurs du train en un autre <i>ndarray</i> . <br><br><h2>  Il est temps de descendre le gradient </h2><br>  Avec cette configuration, tout ce que nous devons faire pour former notre réseau est d'appeler la fonction d' <i>ajustement</i> du modèle: <br><br><pre> <code class="cs hljs">model.fit(trainInputs, trainOutputs, epochs: <span class="hljs-number"><span class="hljs-number">2000</span></span>, validation_split: <span class="hljs-number"><span class="hljs-number">0.075</span></span>, verbose: <span class="hljs-number"><span class="hljs-number">2</span></span>);</code> </pre> <br>  Cet appel annulera en fait les 7,5% restants de l'ensemble de formation pour validation, puis répétera les 2000 fois suivantes: <br><br><ol><li>  diviser le reste du <i>train Entrées</i> en lots </li><li>  alimenter ces lots un par un dans le réseau neuronal </li><li>  erreur de calcul en utilisant la fonction de perte que nous avons définie ci-dessus </li><li>  rétropropagation de l'erreur à travers les gradients des connexions neuronales individuelles, en ajustant les poids </li></ol><br>  Pendant la formation, il affichera l'erreur du réseau sur les données qu'il a mises de côté pour validation en tant que <b>val_loss</b> et l'erreur sur les données de formation elles-mêmes comme une simple <b>perte</b> .  Généralement, si <b>val_loss</b> devient beaucoup plus important que la <b>perte</b> , cela signifie que le réseau a commencé à sur-ajuster.  J'aborderai cela plus en détail dans les articles suivants. <br><br>  Si vous avez tout fait correctement, une <u>racine carrée</u> de l'une de vos pertes devrait être de l'ordre de 20000. <br><br><img src="https://habrastorage.org/webt/fu/rn/vg/furnvg6dbs8ocijm91_3xcqdxhm.png"><br><br><h2>  Soumission </h2><br>  Je ne parlerai pas beaucoup de la génération du fichier à soumettre ici.  Le code pour calculer les sorties est simple: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> SubmissionInputFile = <span class="hljs-string"><span class="hljs-string">"test.csv"</span></span>; DataTable submissionData = LoadData(SubmissionInputFile); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> submissionRows = submissionData.Rows.Cast&lt;DataRow&gt;(); ndarray submissionInputs = GetInputs(submissionRows); ndarray sumissionOutputs = model.predict(submissionInputs);</code> </pre> <br>  qui utilise principalement des fonctions, qui ont été définies précédemment. <br><br>  Ensuite, vous devez les écrire dans un fichier .csv, qui est simplement une liste de paires Id, preded_value. <br><br>  Lorsque vous soumettez votre résultat, vous devriez obtenir un score de l'ordre de 0,17, qui se situerait quelque part dans le dernier quart du tableau du classement public.  Mais bon, si c'était aussi simple qu'un réseau à 3 couches avec 27 neurones, ces scientifiques de données embêtants n'obtiendraient pas 300k $ + / an de compensations totales des grandes entreprises américaines <br><br><h2>  Envelopper </h2><br>  Le code source complet de cette entrée (avec tous les assistants et certaines des parties commentées de mes explorations et expériences précédentes) est d'environ 200 lignes sur le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PasteBin</a> . <br><br>  Dans le prochain article, vous verrez mes manigances essayer d'atteindre le top 50% de ce classement public.  Ce sera une aventure de compagnon amateur, un combat avec The Windmill of Overfitting avec le seul outil dont dispose le vagabond - un modèle plus grand (par exemple, NN profond, rappelez-vous, pas d'ingénierie manuelle des fonctionnalités!).  Ce sera moins un tutoriel de codage, et plus une quête de pensée avec des mathématiques vraiment croches et une conclusion étrange.  Restez à l'écoute! <br><br><h2>  Les liens </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Concours des prix des logements sur Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tutoriel de régression TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Page d'accueil de TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Référence de l'API TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dégradé (liaison TensorFlow)</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr437174/">https://habr.com/ru/post/fr437174/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr437160/index.html">Devops</a></li>
<li><a href="../fr437164/index.html"># 10yearschallenge pour les programmeurs</a></li>
<li><a href="../fr437166/index.html">Vol de combat sur Meteor-e</a></li>
<li><a href="../fr437170/index.html">Facebook suggère d'utiliser des lasers spatiaux pour les communications mondiales</a></li>
<li><a href="../fr437172/index.html">IBM MQ et JMeter: premier contact</a></li>
<li><a href="../fr437176/index.html">Application pour iOS et Android sur Kotlin + Flutter UI</a></li>
<li><a href="../fr437180/index.html">JVM de Sibérie dure: grande interview sur Excelsior JET</a></li>
<li><a href="../fr437182/index.html">Interception d'appels système dans le module du noyau Linux</a></li>
<li><a href="../fr437184/index.html">Nikolay Durov a terminé à 90% le développement de la plate-forme Telegram Open Network</a></li>
<li><a href="../fr437186/index.html">Monolith à microservices. Point de vue infrastructure</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
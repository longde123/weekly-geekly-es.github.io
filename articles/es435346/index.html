<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçüî¨ üë©üèø‚Äçüç≥ ‚õ™Ô∏è Suscr√≠base a Kafka a trav√©s de HTTP o c√≥mo simplificar sus enlaces web üß£ üë©üèø‚Äçü§ù‚Äçüë©üèº ‚ò£Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hay muchas formas de procesar mensajes de sistemas Pub-Sub: usando un servicio separado, aislando un proceso aislado, orquestando un grupo de procesos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Suscr√≠base a Kafka a trav√©s de HTTP o c√≥mo simplificar sus enlaces web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/435346/">  Hay muchas formas de procesar mensajes de sistemas Pub-Sub: usando un servicio separado, aislando un proceso aislado, orquestando un grupo de procesos / hilos, IPC complejo, Poll-over-Http y muchos otros.  Hoy quiero hablar sobre c√≥mo usar Pub-Sub a trav√©s de HTTP y sobre mi servicio escrito espec√≠ficamente para esto. <br><br>  El uso de un backend de servicio HTTP ya preparado en algunos casos es una soluci√≥n ideal para procesar una cola de mensajes: <br><br><ol><li>  Balance√°ndose fuera de la caja.  Por lo general, el backend ya est√° detr√°s del equilibrador y tiene una infraestructura lista para cargar, lo que simplifica enormemente el trabajo con mensajes. </li><li>  Usando un controlador REST normal (cualquier recurso HTTP).  El consumo de mensajes HTTP minimiza el costo de implementar compiladores para diferentes idiomas si el backend es mixto. </li><li>  Simplificaci√≥n del uso de enlaces web de otros servicios.  Ahora, casi todos los servicios (Jira, Gitlab, Mattermost, Slack ...) de alguna manera admiten enlaces web para interactuar con el mundo exterior.  Puede facilitarle la vida si le ense√±a a la cola a realizar las funciones de un despachador HTTP. </li></ol><br>  Este enfoque tambi√©n tiene desventajas: <br><br><ol><li>  Puedes olvidarte de la ligereza de la soluci√≥n.  HTTP es un protocolo pesado, y el uso de marcos del lado del consumidor aumentar√° instant√°neamente la latencia y la carga. </li><li>  Perdemos las fortalezas del enfoque de Encuesta, obteniendo las debilidades de Push. </li><li>  El procesamiento de mensajes por las mismas instancias de servicio que procesan clientes pueden afectar la capacidad de respuesta.  Esto no es significativo, ya que se trata con equilibrio y aislamiento. </li></ol><br>  Implement√© la idea como un servicio Queue-Over-Http, que se discutir√° m√°s adelante.  El proyecto est√° escrito en Kotlin usando Spring Boot 2.1.  Como corredor, solo Apache Kafka est√° disponible actualmente. <br><a name="habracut"></a><br>  <i>Adem√°s en el art√≠culo, se supone que el lector est√° familiarizado con Kafka y conoce los commits (commit) y los offsets (offset) de los mensajes, los principios de grupos (grupo) y consumidores (consumidor), y tambi√©n comprende c√≥mo la partici√≥n (partici√≥n) difiere del tema (tema) .</i>  <i>Si hay lagunas, le aconsejo que lea <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esta</a> secci√≥n de la documentaci√≥n de Kafka antes de continuar.</i> <br><br><h1>  Contenido </h1><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Revisar</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Se compromete</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Manejo de errores</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mensajes</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Rendimiento</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Demostraci√≥n</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conclusi√≥n</a> </li></ul><br><a name="overview"></a><h1>  Revisar </h1><br>  Queue-Over-Http es un servicio que act√∫a como intermediario entre un intermediario de mensajes y el consumidor HTTP final (el servicio facilita la implementaci√≥n del soporte para enviar mensajes a los consumidores de cualquier otra forma, por ejemplo, varios * RPC).  Por el momento, solo est√° disponible la suscripci√≥n, la cancelaci√≥n de la suscripci√≥n y la visualizaci√≥n de la lista de consumidores. El env√≠o de mensajes al agente (producto) a trav√©s de HTTP a√∫n no se ha implementado debido a la imposibilidad de garantizar el orden de los mensajes sin el apoyo especial del productor. <br><br>  La figura clave del servicio es un consumidor que puede suscribirse a particiones espec√≠ficas o solo a temas (se admite el patr√≥n de temas).  En el primer caso, el equilibrio autom√°tico de particiones est√° desactivado.  Despu√©s de suscribirse, el recurso HTTP especificado comienza a recibir mensajes de las particiones Kafka asignadas.  Arquitect√≥nicamente, cada suscriptor est√° asociado con un cliente Java Kafka nativo. <br><br><div class="spoiler">  <b class="spoiler_title">entretenida historia sobre KafkaConsumer</b> <div class="spoiler_text">  Kafka tiene un maravilloso cliente Java que puede hacer mucho.  Lo uso en el adaptador de cola para recibir mensajes del intermediario y luego lo env√≠o a las colas de servicio locales.  Vale la pena mencionar que el cliente trabaja exclusivamente en el contexto de un solo hilo. <br><br>  La idea del adaptador es simple.  Comenzamos en un hilo, escribimos el planificador m√°s simple de clientes nativos, centr√°ndonos en reducir la latencia.  Es decir, escribimos algo similar: <br><br><pre><code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (!Thread.interrupted()) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> hasWork = <span class="hljs-literal"><span class="hljs-literal">false</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (consumer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> kafkaConsumers) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> queueGroup = consumers[consumer] ?: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span> invalidateSubscription(consumer, queueGroup) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> records = consumer.poll(Duration.ZERO) <span class="hljs-comment"><span class="hljs-comment">/*      */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!records.isEmpty) { hasWork = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> committed = doCommit() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!hasWork &amp;&amp; committed == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// ,    Thread.sleep(1) } }</span></span></code> </pre> <br>  Parece que todo es maravilloso, la latencia es m√≠nima incluso con docenas de consumidores.  En la pr√°ctica, result√≥ que <code>KafkaConsumer</code> para este modo de operaci√≥n y ofrece una tasa de asignaci√≥n de aproximadamente 1.5 MB / s en tiempo de inactividad.  Con 100 correos, la tasa de asignaci√≥n alcanza los 150 MB / sy hace que GC a menudo piense en la aplicaci√≥n.  Por supuesto, toda esta basura est√° en el √°rea joven, GC es bastante capaz de manejar esto, pero a√∫n as√≠, la soluci√≥n no es perfecta. <br><br>  Obviamente, debe seguir el camino t√≠pico de <code>KafkaConsumer</code> y ahora <code>KafkaConsumer</code> cada suscriptor en mi transmisi√≥n.  Esto proporciona una sobrecarga para la memoria y la programaci√≥n, pero no hay otra manera. <br><br>  Reescribo el c√≥digo de arriba, quitando el bucle interno y cambiando <code>Duration.ZERO</code> a <code>Duration.ofMillis(100)</code> .  Resulta bien, la tasa de asignaci√≥n cae a 80-150 KB / s aceptables por consumidor.  Sin embargo, una encuesta con un tiempo de espera de 100 ms retrasa toda la cola de confirmaciones para estos mismos 100 ms, y esto es inaceptable en gran medida. <br><br>  En el proceso de encontrar soluciones al problema, recuerdo <code>KafkaConsumer::wakeup</code> , que arroja una <code>WakeupException</code> e interrumpe cualquier operaci√≥n de bloqueo en el consumidor.  Con este m√©todo, el camino hacia la baja latencia es simple: cuando llega una nueva solicitud de confirmaci√≥n, la ponemos en la cola y al consumidor nativo llamamos <code>wakeup</code> .  En el ciclo de trabajo, <code>WakeupException</code> y vaya a confirmar lo que se ha acumulado.  Para la transferencia de control con la ayuda de excepciones, debe entregarlo inmediatamente en sus manos, pero como nada m√°s ... <br><br>  Resulta que esta opci√≥n est√° lejos de ser perfecta, ya que cualquier operaci√≥n en el consumidor nativo ahora arroja una <code>WakeupException</code> , incluida la confirmaci√≥n en s√≠.  El procesamiento de esta situaci√≥n desordenar√° el c√≥digo con una bandera que permite que se realice la <code>wakeup</code> . <br><br>  Llegu√© a la conclusi√≥n de que ser√≠a bueno modificar el m√©todo <code>KafkaConsumer::poll</code> para que pueda interrumpirse normalmente, de acuerdo con un indicador adicional.  Como resultado, <a href="https://github.com/viirtus/queue-over-">Frankenstein</a> naci√≥ de la reflexi√≥n, que copia exactamente el m√©todo de encuesta original, agregando una salida del bucle por la bandera.  Este indicador se establece mediante un m√©todo separado de interruptPoll, que, adem√°s, llama a la activaci√≥n en el selector de clientes para liberar el bloqueo del hilo en las operaciones de E / S. <br><br>  Despu√©s de implementar el cliente de esta manera, obtengo la velocidad de reacci√≥n desde el momento en que llega una solicitud de confirmaci√≥n hasta que se procesa hasta 100 microsegundos, y una latencia excelente para recuperar mensajes de un intermediario, lo cual est√° bien. <br></div></div><br>  Cada partici√≥n est√° representada por una cola local separada, donde el adaptador escribe mensajes del intermediario.  El trabajador toma mensajes de √©l y los env√≠a para su ejecuci√≥n, es decir, para enviarlos a trav√©s de HTTP. <br><br>  El servicio admite el procesamiento de mensajes por lotes para aumentar el rendimiento.  Al suscribirse, puede especificar el <code>concurrencyFactor</code> cada tema (se aplica a cada partici√≥n asignada de forma independiente).  Por ejemplo, <code>concurrencyFactor=1000</code> significa que 1000 mensajes en forma de solicitudes HTTP se pueden enviar al consumidor al mismo tiempo.  Tan pronto como todos los mensajes del paquete fueron resueltos inequ√≠vocamente por el consumidor, el servicio decide la pr√≥xima confirmaci√≥n de la compensaci√≥n del √∫ltimo mensaje en Kafka.  Por lo tanto, el segundo valor de <code>concurrencyFactor</code> es el n√∫mero m√°ximo de mensajes procesados ‚Äã‚Äãpor el consumidor en caso de un bloqueo de Kafka o Queue-Over-Http. <br><br>  Para reducir los retrasos, la cola tiene <code>loadFactor = concurrencyFactor * 2</code> , que le permite leer el doble de mensajes del agente que se pueden enviar.  Dado que la confirmaci√≥n autom√°tica est√° deshabilitada en el cliente nativo, dicho esquema no viola las garant√≠as de al menos una vez. <br>  Un alto valor de <code>concurrencyFactor</code> aumenta el rendimiento de la cola al reducir el n√∫mero de confirmaciones que toman hasta 10 ms en el peor de los casos.  Al mismo tiempo, aumenta la carga sobre el consumidor. <br><br>  El orden de env√≠o de mensajes dentro del paquete no est√° garantizado, pero se puede lograr estableciendo <code>concurrencyFactor=1</code> . <br><br><a name="commits"></a><h1>  Se compromete </h1><br>  Los commits son una parte importante del servicio.  Cuando el siguiente paquete de datos est√° listo, el desplazamiento del √∫ltimo mensaje del paquete se confirma inmediatamente a Kafka, y solo despu√©s de una confirmaci√≥n exitosa el siguiente paquete est√° disponible para su procesamiento.  A menudo esto no es suficiente y se requiere una confirmaci√≥n autom√°tica.  Para hacer esto, existe el par√°metro <code>autoCommitPeriodMs</code> , que tiene poco en com√∫n con el per√≠odo cl√°sico de confirmaci√≥n autom√°tica para clientes nativos que confirman el √∫ltimo mensaje le√≠do desde la partici√≥n.  Imagine <code>concurrencyFactor=10</code> .  El servicio ha enviado los 10 mensajes y est√° esperando que cada uno de ellos est√© listo.  El procesamiento del mensaje 3 se completa primero, luego el mensaje 1 y luego el mensaje 10. En este punto, es hora de confirmaci√≥n autom√°tica.  Es importante no violar la sem√°ntica de al menos una vez.  Por lo tanto, solo puede confirmar el primer mensaje, es decir, el desplazamiento 2, ya que solo se proces√≥ con √©xito en ese momento.  Adem√°s, hasta la pr√≥xima confirmaci√≥n autom√°tica, se procesan los mensajes 2, 5, 6, 4 y 8. Ahora solo necesita confirmar la compensaci√≥n 7, y as√≠ sucesivamente.  La confirmaci√≥n autom√°tica casi no tiene efecto en el rendimiento. <br><br><a name="errors"></a><h1>  Manejo de errores </h1><br>  En el modo normal de operaci√≥n, el servicio env√≠a un mensaje al supervisor una vez.  Si por alguna raz√≥n caus√≥ un error 4xx o 5xx, el servicio reenviar√° el mensaje, esperando un procesamiento exitoso.  El tiempo entre intentos se puede configurar como un par√°metro separado. <br><br>  Tambi√©n es posible establecer el n√∫mero de intentos despu√©s de los cuales el mensaje se marcar√° como procesado, lo que detendr√° las retransmisiones independientemente del estado de la respuesta.  No recomiendo usar esto para datos confidenciales, las situaciones de falla de los consumidores siempre deben ajustarse manualmente.  Los mensajes fijos se pueden monitorear mediante registros de servicio y monitoreando el estado de la respuesta del consumidor. <br><br><div class="spoiler">  <b class="spoiler_title">sobre pegarse</b> <div class="spoiler_text">  Por lo general, el servidor HTTP, que le da a 4xx o 5xx el estado de la respuesta, tambi√©n env√≠a la <code>Connection: close</code> encabezado.  Una conexi√≥n TCP que se cierra de esta manera permanece en estado <code>TIME_WAITED</code> hasta que el sistema operativo la borra despu√©s de un tiempo.  El problema es que tales conexiones ocupan un puerto completo que no se puede reutilizar hasta que se libere.  Esto puede resultar en la ausencia de puertos libres en la m√°quina para establecer una conexi√≥n TCP y el servicio se lanzar√° con excepciones en los registros para cada env√≠o.  En la pr√°ctica, en Windows 10, los puertos terminan despu√©s de 10-20 mil enviando mensajes err√≥neos en 1-2 minutos.  En modo est√°ndar, esto no es un problema. <br></div></div><br><a name="messages"></a><h1>  Mensajes </h1><br>  Cada mensaje extra√≠do del intermediario se env√≠a al asesor a trav√©s de HTTP al recurso especificado durante la suscripci√≥n.  Por defecto, un mensaje es enviado por una solicitud POST en el cuerpo.  Este comportamiento se puede cambiar especificando cualquier otro m√©todo.  Si el m√©todo no admite el env√≠o de datos en el cuerpo, puede especificar el nombre del par√°metro de cadena en el que se enviar√° el mensaje.  Adem√°s, al suscribirse, puede especificar encabezados adicionales que se agregar√°n a cada mensaje, lo cual es conveniente para la autorizaci√≥n b√°sica mediante tokens.  Los encabezados se agregan a cada mensaje con el identificador del consumidor, tema y partici√≥n, de donde se ley√≥ el mensaje, n√∫mero de mensaje, clave de partici√≥n, si corresponde, as√≠ como el nombre del intermediario. <br><br><a name="performance"></a><h1>  Rendimiento </h1><br>  Para evaluar el rendimiento, utilic√© una PC (Windows 10, OpenJDK-11 (G1 sin sintonizaci√≥n), i7-6700K, 16GB), que ejecuta el servicio y una computadora port√°til (Windows 10, i5-8250U, 8GB), en la que giraba el productor del mensaje, HTTP Consumer Consumer y Kafka con la configuraci√≥n predeterminada.  La PC est√° conectada al enrutador a trav√©s de una conexi√≥n por cable de 1 Gb / s, la computadora port√°til a trav√©s de 802.11ac.  El productor escribe cada 110 ms cada 100 ms para 110 bytes de mensajes a los temas designados para los que est√°n suscritos los consumidores ( <code>concurrencyFactor=500</code> , la confirmaci√≥n autom√°tica est√° desactivada) de diferentes grupos.  El soporte est√° lejos de ser ideal, pero puede obtener alguna imagen. <br><br>  Un par√°metro clave de medici√≥n es el efecto del servicio en la latencia. <br><br>  Dejar: <br>  - t <sub>q</sub> - marca de tiempo del servicio que recibe mensajes del cliente nativo <br>  - d <sub>t0</sub> es el tiempo entre t <sub>q</sub> y el momento en que se envi√≥ el mensaje desde la cola local al grupo de ejecutivos <br>  - d <sub>t</sub> es el tiempo entre t <sub>q</sub> y el momento en que se envi√≥ la solicitud HTTP.  Esa es la influencia del servicio en la latencia del mensaje. <br><br>  Durante las mediciones, se obtuvieron los siguientes resultados (C - consumidores, T - temas, M - mensajes): <br><br><img src="https://habrastorage.org/webt/p4/r7/pq/p4r7pqavkke1d3glzc7u8o6a5gu.png"><br><br>  En el modo operativo est√°ndar, el servicio en s√≠ casi no afecta la latencia y el consumo de memoria es m√≠nimo.  Los valores m√°ximos de d <sub>t</sub> (aproximadamente 60 ms) no se indican espec√≠ficamente, ya que dependen de la operaci√≥n del GC y no del servicio en s√≠.  El ajuste especial de GC o la sustituci√≥n de G1 con Shenandoah puede ayudar a suavizar la propagaci√≥n de los valores m√°ximos. <br><br>  Todo cambia dram√°ticamente cuando el consumidor no hace frente al flujo de mensajes desde la cola y el servicio activa el modo de aceleraci√≥n.  En este modo, el consumo de memoria aumenta, ya que el tiempo de respuesta a las solicitudes aumenta significativamente, lo que impide la limpieza oportuna de los recursos.  El efecto sobre la latencia aqu√≠ permanece al nivel de los resultados anteriores, y los valores altos de dt son causados ‚Äã‚Äãpor la carga previa de mensajes en la cola local. <br><br>  Desafortunadamente, no es posible realizar pruebas con una carga mayor, ya que la computadora port√°til ya se dobla a 1300 RPS.  Si alguien puede ayudar con la organizaci√≥n de las mediciones a altas cargas, con mucho gusto proporcionar√© un ensamblaje para las pruebas. <br><br><a name="demo"></a><h1>  Demostraci√≥n </h1><br>  Ahora pasemos a la demostraci√≥n.  Para esto necesitamos: <br><br><ul><li>  Agente de Kafka, listo para salir.  Tomar√© la instancia planteada en 192.168.99.100:9092 de Bitnami. </li><li>  Un recurso HTTP que recibir√° mensajes.  Para mayor claridad, tom√© ganchos web de Slack. </li></ul><br>  En primer lugar, debe generar el servicio Queue-Over-Http.  Para hacer esto, cree los siguientes contenidos en un directorio vac√≠o <code>application.yml</code> : <br><br><pre> <code class="plaintext hljs">spring: profiles: default logging: level: com: viirrtus: queueOverHttp: DEBUG app: persistence: file: storageDirectory: "persist" brokers: - name: "Kafka" origin: "kafka" config: bootstrap.servers: "192.168.99.100:9092"</code> </pre><br>  Aqu√≠ le indicamos al servicio los par√°metros de conexi√≥n de un agente espec√≠fico, as√≠ como d√≥nde almacenar los suscriptores para que no se pierdan entre inicios.  En `app.brokers []. Config`, puede especificar cualquier par√°metro de conexi√≥n admitido por el cliente nativo de Kafka; puede encontrar una lista completa <a href="">aqu√≠</a> . <br><br>  Dado que Spring procesa el archivo de configuraci√≥n, puede escribir muchas cosas interesantes all√≠.  Incluyendo, configurar el registro. <br><br>  Ahora ejecute el servicio en s√≠.  Usamos la forma m√°s f√°cil: <code>docker-compose.yml</code> : <br><br><pre> <code class="plaintext hljs">version: "2" services: app: image: viirrtus/queue-over-http:0.1.3 restart: unless-stopped command: --debug ports: - "8080:8080" volumes: - ./application.yml:/application.yml - ./persist:/persist</code> </pre><br>  <i>Si esta opci√≥n no le conviene, puede compilar el servicio desde la fuente.</i>  <i>Instrucciones de montaje en el proyecto L√©ame, un enlace al que se encuentra al final del art√≠culo.</i> <br><br>  El siguiente paso es registrar el primer suscriptor.  Para hacer esto, debe realizar una solicitud HTTP al servicio con una descripci√≥n del consumidor: <br><br><pre> <code class="plaintext hljs">POST localhost:8080/broker/subscription Content-Type: application/json { "id": "my-first-consumer", "group": { "id": "consumers" }, "broker": "Kafka", "topics": [ { "name": "slack.test", "config": { "concurrencyFactor": 10, "autoCommitPeriodMs": 100 } } ], "subscriptionMethod": { "type": "http", "delayOnErrorMs": 1000, "retryBeforeCommit": 10, "uri": "&lt;slack-wh-uri&gt;", "additionalHeaders": { "Content-Type": "application/json" } } }</code> </pre><br>  Si todo sali√≥ bien, la respuesta ser√° casi el mismo contenido enviado. <br><br>  Veamos cada par√°metro: <br><br><ul><li>  <code>Consumer.id</code> - ID de nuestro suscriptor </li><li>  <code>Consumer.group.id</code> - identificador de grupo </li><li>  <code>Consumer.broker</code> : indique a cu√°l de los corredores de servicios debe suscribirse </li><li>  <code>Consumer.topics[0].name</code> : el nombre del tema del que queremos recibir mensajes </li><li> <code>Consumer.topics[0].config. concurrencyFactor</code>  <code>Consumer.topics[0].config. concurrencyFactor</code> : n√∫mero m√°ximo de mensajes enviados simult√°neamente </li><li> <code>Consumer.topics[0].config. autoCommitPeriodMs</code>  <code>Consumer.topics[0].config. autoCommitPeriodMs</code> : per√≠odo de confirmaci√≥n forzada para mensajes listos </li><li>  <code>Consumer.subscriptionMethod.type</code> : tipo de suscripci√≥n.  Solo HTTP est√° disponible actualmente. </li><li>  <code>Consumer.subscriptionMethod.delayOnErrorMs</code> : tiempo antes de reenviar un mensaje que termin√≥ en un error </li><li>  <code>Consumer.subscriptionMethod.retryBeforeCommit</code> : el n√∫mero de intentos de reenviar el mensaje de error.  Si es 0, el mensaje girar√° hasta el procesamiento exitoso.  En nuestro caso, la garant√≠a de entrega completa no es tan importante como la constancia del flujo. </li><li>  <code>Consumer.subscriptionMethod.uri</code> : el recurso al que se enviar√°n los mensajes </li><li>  <code>Consumer.subscriptionMethod.additionalHeader</code> : encabezados adicionales que se enviar√°n con cada mensaje.  Tenga en cuenta que habr√° JSON en el cuerpo de cada mensaje para que Slack pueda interpretar correctamente la solicitud. </li></ul><br>  <i>En esta solicitud, se omite el m√©todo HTTP, ya que el valor predeterminado, POST, Slack est√° bastante bien.</i> <br><br>  Desde este momento, el servicio monitorea las particiones asignadas del tema slack.test para nuevos mensajes. <br><br>  Para escribir mensajes sobre el tema, utilizar√© las utilidades integradas en Kafka que se encuentran en <code>/opt/bitnami/kafka/bin</code> imagen de Kafka lanzada (la ubicaci√≥n de las utilidades en otras instancias de Kafka puede diferir): <br><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list localhost:9092 --topic slack.test &gt; {‚Äútext‚Äù: ‚ÄúHello!‚Äù}</code> </pre><br>  Al mismo tiempo, Slack le notificar√° de un nuevo mensaje: <br><br><img src="https://habrastorage.org/webt/kl/eh/z7/klehz7ev6x1y2eaqpf_ylpnjic4.png"><br><br>  <i>Para cancelar la suscripci√≥n de un consumidor, es suficiente hacer una solicitud POST para 'intermediar / cancelar la suscripci√≥n' con el mismo contenido que estaba durante la suscripci√≥n.</i> <br><br><a name="the-end"></a><h1>  Conclusi√≥n </h1><br>  Por el momento, solo se implementa la funcionalidad b√°sica.  Adem√°s, se planea mejorar el procesamiento por lotes, tratar de implementar la sem√°ntica Exactamente una vez, agregar la capacidad de enviar mensajes al agente a trav√©s de HTTP y, lo m√°s importante, agregar soporte para otros Pub-Sub populares. <br><br>  El servicio Queue-Over-Http se encuentra actualmente en desarrollo activo.  La versi√≥n 0.1.3 es lo suficientemente estable como para probar en dev y soportes de escenario.  El rendimiento ha sido probado en Windows 10, Debian 9 y Ubuntu 18.04.  Puede usar productos bajo su propio riesgo.  Si desea ayudar con el desarrollo o dar su opini√≥n sobre el servicio, bienvenido al proyecto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://github.com/viirtus/queue-over-">Github</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es435346/">https://habr.com/ru/post/es435346/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es435334/index.html">Reacci√≥n a letras fr√≠as</a></li>
<li><a href="../es435336/index.html">Algo encontrado: documentos con la reuni√≥n de Elasticsearch Mosc√∫ en OZON</a></li>
<li><a href="../es435338/index.html">Creamos un sistema de cronometraje electr√≥nico de carreras.</a></li>
<li><a href="../es435340/index.html">Investigador publica un ejemplo de c√≥digo de trabajo de gusanos para Facebook</a></li>
<li><a href="../es435344/index.html">Amazon present√≥ Showroom, o por qu√© pronto compraremos todos los muebles en l√≠nea</a></li>
<li><a href="../es435348/index.html">MCerver simple: un peque√±o shell para el servidor de Minecraft</a></li>
<li><a href="../es435352/index.html">Conferencia DEFCON 18. Espionaje pr√°ctico usando un tel√©fono m√≥vil. Parte 2</a></li>
<li><a href="../es435354/index.html">Conferencia DEFCON 18. Espionaje pr√°ctico usando un tel√©fono m√≥vil. Parte 1</a></li>
<li><a href="../es435358/index.html">Antig√ºedades: minidisco en la era del iPod</a></li>
<li><a href="../es435360/index.html">Snippets vs Clover: supera el cuestionario en tiempo real m√°s popular</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
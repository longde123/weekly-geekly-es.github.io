<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí™üèª üïäÔ∏è üôçüèΩ Segredos da computa√ß√£o imposs√≠vel da GPU üïï üÖ∞Ô∏è üë®üèæ‚Äçüç≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nossa experi√™ncia no uso de um cluster de computa√ß√£o de 480 GPUs AMD RX 480 para resolver problemas matem√°ticos. Como problema, pegamos a prova do teo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Segredos da computa√ß√£o imposs√≠vel da GPU</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/combox/blog/425731/"> Nossa experi√™ncia no uso de um cluster de computa√ß√£o de 480 GPUs AMD RX 480 para resolver problemas matem√°ticos.  Como problema, pegamos a prova do teorema de um artigo do professor A. Chudnov  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Decomposi√ß√µes c√≠clicas de conjuntos que separam d√≠grafos e classes c√≠clicas de jogos com recompensa garantida</a> ".  A tarefa √© encontrar o n√∫mero m√≠nimo de participantes em uma coaliz√£o nos jogos de coaliz√£o do tipo Nim, o que garante a vit√≥ria de uma das partes. <br><br><img src="https://habrastorage.org/webt/jc/gm/wj/jcgmwjouxeywvjyjlxa8vec5s5c.jpeg"><br><a name="habracut"></a><br><h3>  Desenvolvimento de CPU </h3><br>  O primeiro processador que realmente obteve distribui√ß√£o em massa √© o 8086 da Intel, desenvolvido em 1978.  A velocidade do clock de 8086 era de apenas 8 MHz.  Alguns anos depois, os primeiros processadores apareceram dentro dos quais havia 2, 4 e at√© 8 n√∫cleos.  Cada n√∫cleo permitiu que seu c√≥digo fosse executado independentemente dos outros.  Para compara√ß√£o, o moderno processador Intel Core i9-7980XE opera com uma frequ√™ncia de 2,6 GHz e cont√©m 18 n√∫cleos.  Como voc√™ pode ver, o progresso n√£o p√°ra! <br><br><h3>  Desenvolvimento de GPU </h3><br>  Simultaneamente ao desenvolvimento de processadores centrais, tamb√©m foram desenvolvidas placas de v√≠deo.  Basicamente, suas caracter√≠sticas s√£o importantes para jogos de computador, onde as novas tecnologias s√£o especialmente coloridas e a renderiza√ß√£o de imagens em 3D est√° gradualmente se aproximando da qualidade fotogr√°fica.  No in√≠cio do desenvolvimento de jogos de computador, o c√°lculo da imagem foi realizado na CPU, mas logo foi alcan√ßada a inventividade dos desenvolvedores de gr√°ficos 3D, que conseguiram otimizar at√© as coisas √≥bvias ( <i>InvSqrt () √© um</i> bom exemplo).  Portanto, coprocessadores com um conjunto especial de instru√ß√µes para executar c√°lculos 3D come√ßaram a aparecer nas placas de v√≠deo.  Com o tempo, o n√∫mero de equipes cresceu, o que, por um lado, permitiu trabalhar de forma mais flex√≠vel e eficiente com a imagem e, por outro, complicou o processo de desenvolvimento. <br><br>  Desde 1996, os aceleradores gr√°ficos S3 ViRGE, 3dfx Voodoo, Diamond Monster e outros come√ßaram a ser produzidos.  Em 1999, a nVidia lan√ßou o processador GeForce 256, introduzindo o termo GPU - um processador gr√°fico.  J√° √© universal, pode lidar com c√°lculos geom√©tricos, transforma√ß√£o de coordenadas, posicionamento de pontos de ilumina√ß√£o e trabalhar com pol√≠gonos.  A diferen√ßa entre a GPU e outros chips gr√°ficos era que, al√©m de comandos especializados, havia um conjunto de comandos padr√£o com os quais voc√™ podia implementar seu pr√≥prio algoritmo de renderiza√ß√£o.  Isso deu uma vantagem significativa, pois permitiu adicionar efeitos especiais, e n√£o apenas aqueles que j√° est√£o programados na placa de v√≠deo.  Come√ßando com a GeForce 8000/9000, os processadores de stream apareceram na GPU - computadores j√° desenvolvidos.  Seu n√∫mero variou de 16 a 128, dependendo do modelo.Na terminologia moderna, eles s√£o chamados de unidades de sombreamento unificadas ou simplesmente unidades de sombreamento.  As GPUs AMD Vega 64 fabricadas hoje cont√™m 4096 unidades de shader e a frequ√™ncia do rel√≥gio pode chegar a 1536 MHz! <br><br><h3>  O que cont√©m uma GPU? </h3><br><img align="right" src="https://habrastorage.org/webt/my/rm/lc/myrmlcjalz2qiygw-qg-vdp4o18.png">  A arquitetura da GPU difere da CPU em um grande n√∫mero de n√∫cleos e em um conjunto minimalista de instru√ß√µes destinadas principalmente √† computa√ß√£o vetorial.  No n√≠vel da arquitetura, foram resolvidos problemas de opera√ß√£o paralela de um grande n√∫mero de n√∫cleos e acesso simult√¢neo √† mem√≥ria.  As GPUs modernas cont√™m de 2 a 4 mil unidades de shader, que s√£o combinadas em unidades de computa√ß√£o (Compute Unit).  Na computa√ß√£o paralela, o problema do acesso simult√¢neo √† mem√≥ria √© especialmente grave.  Se cada um dos processadores de fluxo tentar gravar na c√©lula de mem√≥ria, esses comandos terminar√£o no bloqueio e precisar√£o ser enfileirados, o que reduzir√° bastante o desempenho.  Portanto, os processadores de fluxo executam instru√ß√µes em pequenos grupos: enquanto um grupo executa os c√°lculos, o outro carrega os registros, etc.  Voc√™ tamb√©m pode combinar os n√∫cleos em grupos de trabalho com mem√≥ria compartilhada e mecanismos internos de sincroniza√ß√£o. <br><br>  Outra caracter√≠stica importante da GPU √© a presen√ßa de registradores de vetores e ALUs de vetores, que podem executar opera√ß√µes simultaneamente para v√°rios componentes do vetor.  Isso √© principalmente necess√°rio para gr√°ficos 3D, mas como nosso mundo √© tridimensional, nada nos impede de us√°-lo para muitos c√°lculos f√≠sicos.  Na presen√ßa de ALUs de vetor livre, elas tamb√©m podem ser usadas para calcular quantidades escalares. <br><br><h3>  Eles s√£o t√£o diferentes, CPU e GPU </h3><br>  Para a opera√ß√£o completa do sistema de computa√ß√£o, os dois tipos de dispositivos s√£o importantes.  Por exemplo, estamos executando um programa passo a passo, um determinado algoritmo seq√ºencial.  N√£o h√° como executar a quinta etapa do algoritmo, portanto os dados para ele s√£o calculados na etapa quatro.  Nesse caso, √© mais eficiente usar uma CPU com um cache grande e alta velocidade de clock.  Mas existem classes inteiras de tarefas que se prestam bem √† paraleliza√ß√£o.  Nesse caso, a efic√°cia da GPU √© √≥bvia.  O exemplo mais comum √© calcular os pixels de uma imagem renderizada.  O procedimento para cada pixel √© quase o mesmo, os dados sobre objetos e texturas 3D est√£o localizados na RAM da placa de v√≠deo e cada processador de fluxo pode calcular independentemente sua pr√≥pria parte da imagem. <br><br>  Aqui est√° um exemplo de uma tarefa moderna - treinar uma rede neural.  Um grande n√∫mero de neur√¥nios id√™nticos precisa ser treinado, ou seja, para alterar os coeficientes de peso de cada neur√¥nio.  Ap√≥s essas altera√ß√µes, √© necess√°rio passar as seq√º√™ncias de teste pela rede neural para treinamento e obter vetores de erro.  Tais c√°lculos s√£o adequados para a GPU.  Cada processador de fluxo pode se comportar como um neur√¥nio e, durante o c√°lculo, n√£o ser√° necess√°rio criar a solu√ß√£o de maneira sequencial, todos os nossos c√°lculos ocorrer√£o simultaneamente.  Outro exemplo √© o c√°lculo dos fluxos aerodin√¢micos.  √â necess√°rio descobrir o poss√≠vel comportamento da ponte projetada sob a influ√™ncia do vento, simular sua estabilidade aerodin√¢mica, encontrar os locais ideais de instala√ß√£o para as carenagens ajustar o fluxo de ar ou calcular a resist√™ncia √† resson√¢ncia do vento.  Lembra-se da famosa "ponte da dan√ßa" em Volgogrado?  Eu acho que ningu√©m iria querer estar naquele momento na ponte ... <br><br>  O comportamento do fluxo de ar em cada ponto pode ser descrito pelas mesmas equa√ß√µes matem√°ticas e resolver essas equa√ß√µes em paralelo em um grande n√∫mero de n√∫cleos. <br><br><h3>  GPU nas m√£os dos programadores </h3><br>  Para realizar c√°lculos na GPU, um idioma e compilador especiais s√£o usados.  Existem v√°rias estruturas para executar a computa√ß√£o geral da GPU: OpenCL, CUDA, C ++ AMP, OpenACC.  Os dois primeiros foram amplamente utilizados, mas o uso do CUDA √© limitado apenas pelas GPUs da nVidia. <br><br>  O OpenCL foi lan√ßado em 2009 pela Apple.  Mais tarde, Intel, IBM, AMD, Google e nVidia ingressaram no Khronos Group e anunciaram seu suporte ao padr√£o comum.  Desde ent√£o, uma nova vers√£o do padr√£o aparece a cada um ano e meio ou dois e cada um traz melhorias cada vez mais s√©rias. <br><br>  At√© o momento, a linguagem OpenCL C ++ vers√£o 2.2 est√° em conformidade com o padr√£o C ++ 14, suporta a execu√ß√£o simult√¢nea de v√°rios programas no dispositivo, a intera√ß√£o entre eles atrav√©s de filas e pipelines internos e permite o gerenciamento flex√≠vel de buffers e mem√≥ria virtual. <br><br><h3>  Tarefas reais </h3><br>  Um problema interessante da teoria dos jogos, em cuja solu√ß√£o participamos, √© a prova do teorema de um artigo do professor A. Chudnov  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Decomposi√ß√µes c√≠clicas de conjuntos que separam d√≠grafos e classes c√≠clicas de jogos com recompensa garantida</a> ".  A tarefa √© encontrar o n√∫mero m√≠nimo de participantes em uma coaliz√£o nos jogos de coaliz√£o do tipo Nim, o que garante a vit√≥ria de uma das partes. <br><br>  Do ponto de vista matem√°tico, √© uma busca por uma sequ√™ncia c√≠clica de suporte.  Se voc√™ representar a sequ√™ncia na forma de uma lista de zeros e uns, a verifica√ß√£o de suporte poder√° ser implementada por opera√ß√µes l√≥gicas bit a bit.  Do ponto de vista da programa√ß√£o, essa sequ√™ncia √© um registro longo, por exemplo, 256 bits.  A maneira mais confi√°vel de resolver esse problema √© classificar todas as op√ß√µes, exceto a imposs√≠vel por raz√µes √≥bvias. <br><br>  Os objetivos da solu√ß√£o do problema s√£o quest√µes de processamento de sinal eficaz (detec√ß√£o, sincroniza√ß√£o, medi√ß√£o de coordenadas, codifica√ß√£o, etc.). <br><br>  A complexidade de resolver esse problema √© resolver um grande n√∫mero de op√ß√µes.  Por exemplo, se estamos procurando uma solu√ß√£o para n = 25, ent√£o s√£o 25 bits e, se n = 100, j√° s√£o 100 bits.  Se tomarmos o n√∫mero de todas as combina√ß√µes poss√≠veis, ent√£o para n = 25 √© 2 ^ 25 = 33 554 432, e para n = 100 j√° √© 2 ^ 100 = 1 267 650 600 228 229 401 496 703 205 376 combina√ß√µes.  O aumento da complexidade √© simplesmente colossal! <br><br>  Essa tarefa √© bem paralela, o que significa que √© ideal para o cluster de GPU. <br><br><h3>  Programmers vs Maths </h3><br>  Inicialmente, os matem√°ticos resolveram esse problema no Visual Basic no Excel, de modo que conseguiram obter solu√ß√µes prim√°rias, mas o baixo desempenho das linguagens de script n√£o nos permitiu avan√ßar muito.  A decis√£o de n = 80 levou um m√™s e meio ... Inclinamos a cabe√ßa na frente dessas pessoas pacientes. <br><br>  Na primeira etapa, implementamos o algoritmo de tarefa em C e o lan√ßamos na CPU.  No processo, descobriu-se que muito pode ser otimizado ao trabalhar com sequ√™ncias de bits. <br>  Em seguida, otimizamos a √°rea de pesquisa e eliminamos a duplica√ß√£o.  Al√©m disso, uma an√°lise do c√≥digo do assembler gerado pelo compilador e a otimiza√ß√£o do c√≥digo para os recursos do compilador deram um bom resultado.  Tudo isso possibilitou um aumento significativo na velocidade dos c√°lculos. <br><br>  O pr√≥ximo est√°gio de otimiza√ß√£o foi o perfil.  A medi√ß√£o do tempo de execu√ß√£o de v√°rias se√ß√µes do c√≥digo mostrou que em algumas ramifica√ß√µes do algoritmo a carga na mem√≥ria aumentou significativamente, assim como a ramifica√ß√£o excessiva do programa foi revelada.  Devido a essa falha "pequena", quase um ter√ßo da energia da CPU n√£o foi usada. <br><br>  Um aspecto muito importante da solu√ß√£o de tais problemas √© a precis√£o da escrita do c√≥digo.  Ningu√©m sabe as respostas corretas para esse problema e, portanto, n√£o h√° vetores de teste.  Existe apenas a primeira parte da gama de solu√ß√µes que os matem√°ticos encontraram.  A confiabilidade de novas solu√ß√µes s√≥ pode ser garantida pela precis√£o da escrita do c√≥digo. <br><br>  Portanto, chegou a etapa de preparar o programa para a solu√ß√£o na GPU e o c√≥digo foi modificado para funcionar em v√°rios segmentos.  O programa de controle agora est√° envolvido no envio de tarefas entre threads.  Em um ambiente multithread, a velocidade de c√°lculo aumentou 5 vezes!  Isso foi alcan√ßado devido √† opera√ß√£o simult√¢nea de 4 threads e √† combina√ß√£o de fun√ß√µes. <br><br>  Nesta fase, a decis√£o fez os c√°lculos corretos at√© n = 80 em 10 minutos, enquanto no Excel, esses c√°lculos levaram um m√™s e meio!  Pouca vit√≥ria! <br><br><h3>  GPU e OpenCL </h3><br>  Foi decidido usar o OpenCL vers√£o 1.2 para garantir a m√°xima compatibilidade entre diferentes plataformas.  A depura√ß√£o inicial foi feita na CPU da Intel e depois na GPU da Intel.  Ent√£o eles mudaram para a GPU da AMD. <br><br>  O padr√£o OpenCL 1.2 suporta vari√°veis ‚Äã‚Äãinteiras de 64 bits.  A dimens√£o de 128 bits √© limitada pela AMD, mas √© compilada em dois n√∫meros de 64 bits.  Por motivos de compatibilidade e para otimizar o desempenho, decidiu-se apresentar um n√∫mero de 256 bits como um grupo de n√∫meros de 32 bits, opera√ß√µes l√≥gicas bit a bit nas quais s√£o executadas na GPU ALU interna o mais r√°pido poss√≠vel. <br>  Um programa OpenCL cont√©m um kernel - uma fun√ß√£o que √© o ponto de entrada de um programa.  Os dados para processamento s√£o baixados da CPU para a RAM da placa de v√≠deo e transferidos para o kernel na forma de buffers - ponteiros para uma matriz de dados de entrada e sa√≠da.  Por que uma matriz?  Executamos computa√ß√£o de alto desempenho, precisamos de muitas tarefas que s√£o executadas simultaneamente.  O kernel √© executado no dispositivo em v√°rias inst√¢ncias.  Cada n√∫cleo conhece seu identificador e recebe sua pr√≥pria parte de um buffer compartilhado.  O caso em que a solu√ß√£o mais simples √© a mais eficaz.  O OpenCL n√£o √© apenas uma linguagem, mas tamb√©m uma estrutura abrangente na qual todos os detalhes da computa√ß√£o cient√≠fica e da computa√ß√£o de jogos s√£o cuidadosamente pensados.  Isso facilita a vida do desenvolvedor.  Por exemplo, voc√™ pode iniciar muitos threads, o gerenciador de tarefas os colocar√° no pr√≥prio dispositivo.  As tarefas que n√£o iniciaram a execu√ß√£o imediata ser√£o colocadas em fila e iniciadas √† medida que as unidades de computa√ß√£o se tornarem livres.  Cada inst√¢ncia do kernel possui seu pr√≥prio espa√ßo no buffer de sa√≠da, onde coloca a resposta ap√≥s a conclus√£o do trabalho. <br><br>  A principal tarefa do gerenciador OpenCL √© garantir a execu√ß√£o paralela de v√°rias inst√¢ncias do kernel.  A experi√™ncia cient√≠fica e pr√°tica acumulada ao longo de d√©cadas √© aplicada aqui.  Enquanto alguns n√∫cleos carregam dados nos registradores, outra parte atualmente trabalha com mem√≥ria ou realiza c√°lculos - como resultado, o n√∫cleo da GPU sempre est√° totalmente carregado. <br>  O compilador OpenCL faz um bom trabalho de otimiza√ß√£o, mas √© mais f√°cil para um desenvolvedor influenciar o desempenho.  A otimiza√ß√£o da GPU segue em duas dire√ß√µes - acelerando a execu√ß√£o do c√≥digo e a possibilidade de paralelizar.  A qualidade do paralelismo do c√≥digo pelo compilador depende de v√°rias coisas: o n√∫mero de registros de rascunho ocupados (localizados na mem√≥ria mais lenta da GPU - global), o tamanho do c√≥digo compilado (√© necess√°rio ajustar em 32 kb de cache), o n√∫mero de registros vetoriais e escalares usados. <br><br><h3>  GPU ComBox A-480 ou um milh√£o de n√∫cleos </h3><br>  Essa √© a parte mais interessante do projeto, quando mudamos do Excel para um cluster de computa√ß√£o que consiste em placas gr√°ficas AMD RX 480 480. Grande, r√°pido e eficiente.  Completamente pronto para cumprir a tarefa e obter os resultados que o mundo nunca viu antes. <br><br>  Gostaria de observar que, em todas as etapas de melhoria e otimiza√ß√£o do c√≥digo, iniciamos a busca por uma solu√ß√£o desde o in√≠cio e comparamos as respostas da nova vers√£o com as anteriores.  Isso nos permitiu ter certeza de que a otimiza√ß√£o e as melhorias do c√≥digo n√£o introduziram erros nas solu√ß√µes.  Aqui voc√™ precisa entender que n√£o h√° respostas corretas no final do livro e ningu√©m no mundo as conhece. <br>  O lan√ßamento no cluster confirmou nossas suposi√ß√µes sobre a velocidade das solu√ß√µes: a busca por seq√º√™ncias para n&gt; 100 levou cerca de uma hora.  Foi incr√≠vel ver como as novas solu√ß√µes estavam no cluster ComBox A-480 em minutos, enquanto no CPU demorava muitas horas. <br><br>  Em apenas duas horas do cluster de computa√ß√£o, obtivemos todas as solu√ß√µes at√© n = 127.  Uma verifica√ß√£o das solu√ß√µes mostrou que as respostas obtidas s√£o confi√°veis ‚Äã‚Äãe correspondem aos teoremas do professor A. Chudnov mencionados no artigo <br><br><h3>  Evolu√ß√£o da velocidade </h3><br>  Se voc√™ observar o ganho de desempenho no curso da solu√ß√£o do problema, os resultados foram aproximadamente os seguintes: <br><br><ul><li>  meses e meio para n = 80 no Excel; </li><li>  uma hora para n = 80 no Core i5 com um programa C ++ otimizado; </li><li>  10 minutos para n = 80 no Core i5 usando multithreading; </li><li>  10 minutos para n = 100 em uma GPU AMD RX 480; </li><li>  120 minutos para n = 127 no ComBox A-480. </li></ul><br><h3>  Perspectivas e futuro </h3><br>  Muitas tarefas na interse√ß√£o entre ci√™ncia e pr√°tica est√£o pendentes para melhorar nossa vida.  O mercado de aluguel de energia para computa√ß√£o est√° apenas emergindo e a necessidade de computa√ß√£o paralela continua a crescer. <br><br>  Poss√≠veis aplica√ß√µes da computa√ß√£o paralela: <br><br><ul><li>  tarefas de controle autom√°tico de ve√≠culos e drones; </li><li>  c√°lculos de caracter√≠sticas aerodin√¢micas e hidrodin√¢micas; </li><li>  reconhecimento de fala e imagens visuais; </li><li>  treinamento em redes neurais; </li><li>  tarefas de astronomia e astron√°utica; </li><li>  an√°lise estat√≠stica e correla√ß√£o de dados; </li><li>  dobrar compostos prote√≠na-prote√≠na; </li><li>  diagn√≥stico precoce de doen√ßas usando IA. </li></ul><br>  Uma dire√ß√£o separada √© a computa√ß√£o em nuvem na GPU.  Por exemplo, gigantes como Amazon, IBM e Google alugam seu poder de computa√ß√£o na GPU.  Hoje, podemos dizer com confian√ßa que o futuro da computa√ß√£o paralela de alto desempenho pertencer√° aos clusters de GPU. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt425731/">https://habr.com/ru/post/pt425731/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt425719/index.html">Aipo em projetos ocupados: um pouco de pr√°tica</a></li>
<li><a href="../pt425723/index.html">O Facebook est√° desenvolvendo ativamente um servi√ßo para encontrar trabalho e contratar funcion√°rios em uma rede social</a></li>
<li><a href="../pt425725/index.html">Caso de Patentes da Nintendo - Game Boy</a></li>
<li><a href="../pt425727/index.html">At√© a pr√≥xima</a></li>
<li><a href="../pt425729/index.html">Bem-vindo ao Hackathon Pro: como foi a primeira caridade SmartMail Hack</a></li>
<li><a href="../pt425737/index.html">Mapas na tabela: como escolher um provedor de mapas para um aplicativo m√≥vel</a></li>
<li><a href="../pt425739/index.html">Microsoft anuncia o Project xCloud - servi√ßo de streaming de jogos de ponta</a></li>
<li><a href="../pt425741/index.html">Docotic.Pdf: Quais problemas o PVS-Studio detecta em um projeto maduro?</a></li>
<li><a href="../pt425743/index.html">Psicoterapia Marte na casa de Saturno e inje√ß√µes intracerebrais de psilocibina homeop√°tica</a></li>
<li><a href="../pt425747/index.html">O que aconteceu com "Timur e sua equipe" ou pensamentos sobre a Parceria de T√©cnicos Militantes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
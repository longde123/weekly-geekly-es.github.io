<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ≥Ô∏è ü•Ä üò¶ O livro "Arquitetos da intelig√™ncia" ‚óºÔ∏è üßîüèø üïµüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A intelig√™ncia artificial (IA) est√° se movendo rapidamente da fic√ß√£o cient√≠fica para a vida cotidiana. Os dispositivos modernos reconhecem a fala huma...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O livro "Arquitetos da intelig√™ncia"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/476466/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/mb/12/np/mb12npah994j7jq-gm2outusizg.jpeg" align="left" alt="imagem"></a>  A intelig√™ncia artificial (IA) est√° se movendo rapidamente da fic√ß√£o cient√≠fica para a vida cotidiana.  Os dispositivos modernos reconhecem a fala humana, s√£o capazes de responder a perguntas e realizar a tradu√ß√£o autom√°tica.  Em v√°rias √°reas, desde a condu√ß√£o de um ve√≠culo n√£o tripulado at√© o diagn√≥stico de c√¢ncer, s√£o utilizados algoritmos de reconhecimento de objetos baseados em IA, cujas capacidades s√£o superiores √†s humanas.  As grandes empresas de m√≠dia usam o jornalismo rob√≥tico para criar artigos semelhantes aos direitos autorais a partir dos dados coletados.  A IA est√° obviamente pronta para se tornar uma tecnologia verdadeiramente universal, como a eletricidade. <br><br>  Quais abordagens e tecnologias s√£o consideradas as mais promissoras?  Que grandes descobertas s√£o poss√≠veis nos pr√≥ximos anos?  √â poss√≠vel criar uma m√°quina verdadeiramente pensante ou IA compar√°vel √† humana, e em quanto tempo?  Quais riscos e amea√ßas est√£o associados √† IA e como evit√°-los?  A IA causar√° caos na economia e no mercado de trabalho?  As m√°quinas superinteligentes sair√£o do controle humano e se tornar√£o uma amea√ßa real? <br><br>  Claro, √© imposs√≠vel prever o futuro.  No entanto, os especialistas sabem mais sobre o estado atual da tecnologia, bem como sobre inova√ß√µes no futuro pr√≥ximo, do que qualquer outra pessoa.  Voc√™ ter√° reuni√µes brilhantes com pessoas reconhecidas como R. Kurzweil, D. Hassabis, J. Hinton, R. Brooks e muitos outros. <br><a name="habracut"></a><br><h3>  Yan Lekun </h3><br>  VICE-PRESIDENTE E FUNDADOR DO LABORAT√ìRIO DE PESQUISA DA AI NO FACEBOOK (FAIR), PROFESSOR DE CI√äNCIA DA COMPUTA√á√ÉO NA UNIVERSIDADE DE NOVA IORQUE <br><br>  <i>Juntamente com Jeffrey Hinton e Joshua Benjio, Ian Lekun faz parte de um grupo de pesquisadores cujos esfor√ßos e perseveran√ßa levaram √† atual revolu√ß√£o em rela√ß√£o √†s redes neurais e aprendizado profundo.</i>  <i>Enquanto trabalhava no Bell Labs, ele inventou redes neurais convolucionais.</i>  <i>Ele recebeu um diploma de engenheiro el√©trico em Paris pela ESIEE e um doutorado em ci√™ncia da computa√ß√£o pela Universidade de Pierre e Marie Curie.</i>  <i>Ap√≥s a p√≥s-gradua√ß√£o, ele trabalhou no Laborat√≥rio Jeffrey Hinton da Universidade de Toronto.</i> <br><br>  <b>Martin Ford:</b> A explos√£o de interesse em aprendizado profundo nos √∫ltimos 10 anos √© uma conseq√º√™ncia da melhoria simult√¢nea das redes neurais, aumentando o poder dos computadores e a quantidade de dados dispon√≠veis? <br><br>  <b>Yang Lekun:</b> Sim, mas o processo foi mais deliberado.  Apareceu em 1986‚Äì87.  o algoritmo de retropropaga√ß√£o tornou poss√≠vel o treinamento de redes neurais multicamadas.  Isso causou uma onda de interesse que durou at√© 1995. Em 2003, Jeffrey Hinton, Joshua Benggio e eu propusemos um plano para renovar o interesse da comunidade por esses m√©todos, porque estavam confiantes em sua vit√≥ria iminente.  Ent√£o, podemos dizer que houve uma conspira√ß√£o deliberada. <br><br>  <b>M.F .:</b> Voc√™ j√° entendeu todas as perspectivas?  IA e aprendizado profundo agora s√£o considerados sin√¥nimos. <br><br>  <b>I. L .:</b> Sim e n√£o.  Sab√≠amos que os m√©todos formariam a base da vis√£o computacional, reconhecimento de fala e, possivelmente, algumas outras coisas, mas ningu√©m esperava que eles se estendessem √† compreens√£o de linguagem natural, rob√≥tica, an√°lise de imagens m√©dicas e at√© contribu√≠ssem para o surgimento de ve√≠culos n√£o tripulados.  No in√≠cio dos anos 90.  Eu pensei que o movimento em dire√ß√£o a essas coisas seria mais suave e elas apareceriam um pouco mais cedo.  Est√°vamos aguardando a revolu√ß√£o que aconteceu por volta de 2013. <br><br>  <b>M.F .:</b> E como surgiu seu interesse em IA e aprendizado de m√°quina? <br><br>  <b>Y. L .:</b> Desde a inf√¢ncia, eu estava interessado em ci√™ncia, tecnologia e quest√µes globais sobre a origem da vida, a intelig√™ncia, a origem da humanidade.  A ideia de IA me encantou.  Mas nos anos 1960-70.  ningu√©m fez isso na Fran√ßa, ent√£o depois da escola eu fui estudar como engenheiro. <br><br>  Em 1980, gostei muito do livro sobre a filosofia da linguagem e da aprendizagem: o debate entre Jean Piaget e Noam Chomsky (‚ÄúLinguagem e aprendizagem: uma discuss√£o entre Jean Piaget e Noam Chomsky‚Äù), no qual o criador da teoria do desenvolvimento cognitivo e do linguista discutiu natureza e educa√ß√£o , bem como o surgimento de linguagem e intelig√™ncia. <br><br>  Do lado de Piaget, o professor do MIT Seymour Peypert falou sobre as origens do aprendizado de m√°quina no final da d√©cada de 1960.  realmente contribuiu para a interrup√ß√£o do trabalho com redes neurais.  E agora, depois de 10 anos, ele exaltou o chamado perceptron - um modelo muito simples de aprendizado de m√°quina que apareceu na d√©cada de 1950.  e no qual ele trabalhou na d√©cada de 1960.  Ent√£o, pela primeira vez, me familiarizei com o conceito de aprendizado de m√°quina e fiquei absolutamente fascinado por ele.  A capacidade de aprender, considerei parte integrante da intelig√™ncia. <br><br>  Como estudante, li tudo o que pude encontrar sobre aprendizado de m√°quina e fiz v√°rios projetos sobre esse t√≥pico.  Descobriu-se que no Ocidente ningu√©m trabalha com redes neurais.  Alguns pesquisadores japoneses trabalharam no que mais tarde ficou conhecido como esse termo.  Em nosso pa√≠s, esse t√≥pico n√£o interessava a ningu√©m, em parte por causa do que apareceu no final da d√©cada de 1960.  livros de Peypert e Minsky. <br><br>  Comecei uma pesquisa independente e, em 1987, defendi minha disserta√ß√£o de doutorado Modeles connexionnistes de l'apprentissage ("Modelos de aprendizado conexionistas").  Meu gerente Maurice Milgram n√£o lidou com esse t√≥pico e me disse diretamente que ele poderia se tornar meu consultor oficialmente, mas ele n√£o poderia me ajudar tecnicamente. <br><br>  No in√≠cio dos anos 80  Descobri uma comunidade de pessoas que trabalhavam em redes neurais e as contatei.  Como resultado, em paralelo com David Rumelhart e Jeffrey Hinton, descobri algo como o m√©todo de propaga√ß√£o reversa do erro. <br><br>  <b>M.F .:</b> Ou seja, no in√≠cio dos anos 80.  No Canad√°, existem numerosos estudos nessa √°rea? <br><br>  <b>Y. L.:</b> N√£o, tudo aconteceu nos EUA.  No Canad√°, esses estudos ainda n√£o foram realizados.  No in√≠cio dos anos 80  Jeffrey Hinton era funcion√°rio da Universidade da Calif√≥rnia, San Diego, onde trabalhou com psic√≥logos cognitivos como David Rumelhart e James McClelland.  Como resultado, apareceu um livro explicando a psicologia com a ajuda de redes neurais simples e modelos de computador.  Jeffrey tornou-se professor assistente na Universidade Carnegie Mellon.  Ele s√≥ se mudou para Toronto em 1987. Ent√£o me mudei para Toronto e trabalhei em seu laborat√≥rio por um ano. <br><br>  M.F .: No in√≠cio dos anos 80.  Eu era estudante de ci√™ncia da computa√ß√£o e n√£o lembro que redes neurais foram usadas em algum lugar.  Agora a situa√ß√£o mudou dramaticamente. <br><br>  <b>Y. L .:</b> As redes neurais n√£o est√£o apenas √† margem da ci√™ncia.  Nos anos 70  e in√≠cio dos anos 80.  eles foram realmente anatematizados.  Os artigos foram rejeitados por uma men√ß√£o √†s redes neurais. <br><br>  O conhecido artigo Optimal Perceptual Inference, publicado em 1983 por Jeffrey Hinton e Terry Seinowski.  Para descrever nele um dos primeiros modelos de aprendizagem profunda e rede neural, eles usaram palavras de c√≥digo, mesmo no nome. <br><br>  <b>M.F .:</b> Voc√™ √© conhecido como o autor de uma rede neural convolucional.  Por favor, explique o que √©? <br><br>  <b>Y. L .:</b> Inicialmente, essa rede neural foi otimizada para o reconhecimento de objetos em imagens.  Por√©m, pode ser aplicado a uma ampla gama de tarefas, como reconhecimento de fala e tradu√ß√£o autom√°tica.  A id√©ia para sua cria√ß√£o foi servida pelas caracter√≠sticas do c√≥rtex visual do c√©rebro de animais e seres humanos, estudadas nas d√©cadas de 1950 e 1960.  David Hubel e Thorsten Wiesel, que mais tarde receberam o Pr√™mio Nobel de Neurobiologia. <br><br>  A rede convolucional √© uma maneira especial de conectar neur√¥nios que n√£o s√£o uma c√≥pia exata dos neur√¥nios biol√≥gicos.  Na primeira camada - a camada de convolu√ß√£o - cada neur√¥nio √© associado a um pequeno n√∫mero de pixels da imagem e calcula a soma ponderada de seus dados de entrada.  Durante o treinamento, os pesos mudam.  Grupos de neur√¥nios veem pequenas √°reas da imagem.  Se um neur√¥nio detectar um recurso espec√≠fico em uma √°rea, outro neur√¥nio detectar√° exatamente o mesmo recurso na √°rea adjacente e todos os outros neur√¥nios nas √°reas restantes da imagem.  A opera√ß√£o matem√°tica que os neur√¥nios realizam juntos √© chamada de convolu√ß√£o discreta.  Da√≠ o nome. <br><br>  Em seguida, vem a camada n√£o linear, na qual cada neur√¥nio √© ativado ou desativado, dependendo se a soma ponderada calculada pela camada de convolu√ß√£o acabou sendo maior ou menor que o limite especificado.  Por fim, a terceira camada executa uma opera√ß√£o de redu√ß√£o de amostragem para garantir que uma leve distor√ß√£o ou deforma√ß√£o da imagem de entrada n√£o mude muito a sa√≠da.  Isso fornece independ√™ncia das deforma√ß√µes da imagem de entrada. <br><br>  De fato, uma rede convolucional √© uma pilha organizada a partir de camadas de convolu√ß√£o, n√£o linearidade e subamostragem.  Quando s√£o dobrados, aparecem neur√¥nios que reconhecem objetos.  Por exemplo, um neur√¥nio que liga quando o cavalo est√° na imagem, outro neur√¥nio para carros, um terceiro para pessoas e assim por diante, para todas as categorias necess√°rias. <br><br>  Al√©m disso, o que a rede neural faz √© determinado pela for√ßa das conex√µes entre os neur√¥nios, ou seja, pesos.  E esses pesos n√£o s√£o programados, mas s√£o o resultado do treinamento. <br><br>  A imagem do cavalo √© mostrada na rede e, se n√£o responder "cavalo", ser√° informado que isso est√° errado e ser√° solicitado a resposta correta.  Depois disso, usando o algoritmo de propaga√ß√£o de erro de retorno, a rede ajusta os pesos de todas as conex√µes para que, na pr√≥xima vez em que a mesma imagem seja exibida, o resultado fique mais pr√≥ximo do desejado.  Ao mesmo tempo, voc√™ tem que mostrar a ela milhares de imagens. <br><br>  <b>M. F. -</b> √â este ensino com um professor?  Pelo que entendi, agora essa √© a abordagem dominante. <br><br>  <b>Y. L .:</b> Exatamente.  Quase todos os aplicativos modernos de aprendizagem profunda usam treinamento de professores.  A m√°gica √© que a rede treinada geralmente fornece as respostas certas, mesmo para imagens que n√£o haviam sido mostradas antes.  Mas precisa de um grande n√∫mero de exemplos. <br><br>  <b>M.F .:</b> E o que se pode esperar no futuro?  Ser√° poss√≠vel ensinar um carro quando crian√ßa, que s√≥ precisa mostrar um gato uma vez e dar um nome a ele? <br><br>  <b>I. L .:</b> Na verdade, voc√™ n√£o est√° certo.  Os primeiros treinamentos convolucionais realmente acontecem em milh√µes de imagens de v√°rias categorias.  E ent√£o, se voc√™ precisar adicionar uma nova categoria, por exemplo, ensinar um computador a reconhecer gatos, algumas amostras ser√£o suficientes.  Afinal, a rede j√° est√° treinada para reconhecer objetos de quase qualquer tipo.  As adi√ß√µes ao treinamento est√£o relacionadas a um par de camadas superiores. <br><br>  <b>MF:</b> J√° se parece com o modo como as crian√ßas estudam. <br><br>  <b>Y. L.:</b> N√£o, infelizmente, n√£o √© nada disso.  As crian√ßas obt√™m a maioria das informa√ß√µes antes que algu√©m lhes diga: "Este √© um gato".  Nos primeiros meses de vida, as crian√ßas aprendem sem ter id√©ia do idioma.  Eles reconhecem a estrutura do mundo simplesmente observando o mundo e interagindo um pouco com ele.  Essa maneira de acumular conhecimento n√£o est√° dispon√≠vel para m√°quinas.  Como cham√°-lo n√£o est√° claro.  Alguns usam o termo provocador "ensino sem professor".  Isso √†s vezes √© chamado de treinamento antecipat√≥rio ou indutivo.  Eu chamo de auto-estudo.  Ao treinar esse tipo, n√£o h√° como se preparar para executar uma tarefa, √© simplesmente observar o mundo e como ele funciona. <br><br>  <b>M.F .:</b> O aprendizado refor√ßado se enquadra nessa categoria? <br><br>  <b>Y. L.:</b> N√£o, esta √© uma categoria completamente diferente.  De fato, existem tr√™s categorias principais: aprendizado refor√ßado, treinamento de professores e auto-aprendizado. <br><br>  O treinamento com refor√ßo ocorre por tentativa e erro e funciona bem em jogos nos quais voc√™ pode fazer quantas tentativas quiser.  O bom desempenho do AlphaGo foi alcan√ßado depois que a m√°quina jogou mais jogos do que toda a humanidade nos √∫ltimos tr√™s mil anos.  Para problemas do mundo real, essa abordagem √© impratic√°vel. <br><br>  Uma pessoa pode aprender a dirigir um carro em 15 horas de treinamento sem colidir com nada.  Se voc√™ usar os m√©todos de treinamento existentes com refor√ßos, o carro, para aprender a andar sem motorista, ter√° que cair de um penhasco 10 mil vezes antes que ela entenda como evitar isso. <br><br>  <b>M.F .:</b> Parece-me que este √© um argumento a favor da modelagem. <br><br>  <b>Y. L .:</b> Pelo contr√°rio, √© uma confirma√ß√£o de que o tipo de treinamento utilizado pelas pessoas √© muito diferente do aprendizado refor√ßado.  Isso √© semelhante ao treinamento de refor√ßo baseado em modelo.  Afinal, uma pessoa, dirigindo pela primeira vez, tem um modelo do mundo e pode prever as consequ√™ncias de suas a√ß√µes.  Como fazer a m√°quina estudar independentemente os modelos progn√≥sticos √© o principal problema n√£o resolvido. <br><br>  <b>M.F .:</b> √â sobre isso que voc√™ trabalha com o Facebook? <br><br>  <b>I. L .:</b> Sim, essa √© uma das coisas em que estamos trabalhando.  Tamb√©m treinamos a m√°quina para observar diferentes fontes de dados.  Estamos construindo um modelo de mundo, esperando nele refletir o senso comum, para que mais tarde possa ser usado como progn√≥stico. <br><br>  <b>M.F .:</b> Algumas pessoas pensam que apenas o aprendizado profundo n√£o √© suficiente, e nas redes deve haver inicialmente uma estrutura respons√°vel pela intelig√™ncia.  E voc√™ parece convencido de que a intelig√™ncia pode emergir organicamente de redes neurais relativamente universais. <br><br>  Y. L.: Voc√™ exagera.  Todo mundo concorda com a necessidade da estrutura, a quest√£o √© como ela deve ser.  E por falar em pessoas que acreditam que deve haver estruturas que forne√ßam pensamento l√≥gico e a capacidade de argumentar, voc√™ provavelmente quer dizer Gary Marcus e, possivelmente, Oren Etzioni.  Discutimos com Gary sobre esse assunto esta manh√£.  Sua opini√£o n√£o √© bem recebida na comunidade, porque, sem dar a menor contribui√ß√£o ao aprendizado profundo, ele escreveu criticamente sobre isso.  Oren trabalhou nesta √°rea por algum tempo e, ao mesmo tempo, fala muito mais suavemente. <br><br>  De fato, a id√©ia de redes convolucionais surgiu como uma tentativa de adicionar estrutura √†s redes neurais.  A quest√£o √©: o que permite √† m√°quina manipular caracteres ou, por exemplo, corresponder aos recursos hier√°rquicos da linguagem? <br><br>  Muitos de meus colegas, incluindo Jeffrey Hinton e Joshua Benggio, concordam que mais cedo ou mais tarde poderemos ficar sem estruturas.  Eles podem ser √∫teis a curto prazo, porque ainda n√£o foi inventada uma maneira de auto-aprendizado.  Esse ponto pode ser contornado, vinculando tudo √† arquitetura.  Mas a microestrutura do c√≥rtex, visual e pr√©-frontal, parece completamente homog√™nea. <br><br>  <b>M.F .:</b> O c√©rebro usa algo semelhante ao m√©todo de propaga√ß√£o de erros? <br><br>  <b>I. L .:</b> Isso √© desconhecido.  Pode acontecer que essa n√£o seja a propaga√ß√£o de retorno na forma como a conhecemos, mas uma forma semelhante de aproxima√ß√£o da estimativa do gradiente.  Joshua Benggio trabalhou em formas biologicamente plaus√≠veis de estimativa de gradiente.  H√° uma chance de o c√©rebro estimar o gradiente de qualquer fun√ß√£o alvo. <br><br>  <b>M.F .:</b> Quais outras coisas importantes est√£o sendo trabalhadas no Facebook? <br><br>  <b>Y. L .:</b> Estamos envolvidos em uma variedade de pesquisas b√°sicas, al√©m de quest√µes de aprendizado de m√°quina; portanto, lidamos principalmente com matem√°tica aplicada e otimiza√ß√£o.  Est√° em andamento o trabalho de aprendizagem refor√ßada e os chamados padr√µes geradores, que s√£o uma forma de autoaprendizagem ou aprendizagem antecipada. <br><br>  <b>MF:</b> O Facebook desenvolve sistemas que podem manter uma conversa? <br><br>  <b>Y. L .:</b> Listei os t√≥picos fundamentais de pesquisa acima, mas tamb√©m existem muitas √°reas de sua aplica√ß√£o.  O Facebook est√° desenvolvendo ativamente desenvolvimentos no campo da vis√£o computacional, e pode-se argumentar que temos o melhor grupo de pesquisa do mundo.  Trabalhamos muito no processamento de texto em um idioma natural.  Isso inclui tradu√ß√£o, generaliza√ß√£o, categoriza√ß√£o (descobrir qual t√≥pico est√° sendo discutido) e sistemas de di√°logo para assistentes virtuais, sistemas de perguntas e respostas, etc. <br><br>  <b>M.F .:</b> Voc√™ acha que um dia haver√° uma IA capaz de passar no teste de Turing? <br><br>  <b>I. L .:</b> Em algum momento, isso acontecer√°, mas n√£o considero o teste de Turing um bom crit√©rio: √© f√°cil de enganar e est√° um pouco desatualizado.  Muitos esquecem ou se recusam a acreditar que a linguagem √© um fen√¥meno secund√°rio em rela√ß√£o √† intelig√™ncia. <br><br>  ¬ªMais informa√ß√µes sobre o livro podem ser encontradas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site do editor</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Conte√∫do</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Trecho</a> <br><br>  Cupom de desconto de 25% para vendedores ambulantes - <b>Intelligence Architects</b> <br><br>  Ap√≥s o pagamento da vers√£o impressa do livro, um livro eletr√¥nico √© enviado por e-mail. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt476466/">https://habr.com/ru/post/pt476466/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt476452/index.html">Armazenamento de valor-chave ou como nossos aplicativos se tornaram mais convenientes</a></li>
<li><a href="../pt476454/index.html">O 5G est√° chegando: quais empresas garantir√£o a introdu√ß√£o de novas tecnologias em 2020</a></li>
<li><a href="../pt476456/index.html">O sistema de cr√©dito social chin√™s n√£o √©, antes de tudo, um sistema de avalia√ß√£o de cidad√£os, mas uma API massiva</a></li>
<li><a href="../pt476460/index.html">O primeiro formato de arquivo de sucesso na Internet n√£o foi o MP3, mas o MIDI</a></li>
<li><a href="../pt476464/index.html">Problemas de log de eventos de seguran√ßa do sistema Windows</a></li>
<li><a href="../pt476468/index.html">Novo curso online gratuito de an√°lise de texto de rede neural da Samsung</a></li>
<li><a href="../pt476474/index.html">Devolvemos o Keenetic no suporte KN-1310 do modem usb</a></li>
<li><a href="../pt476476/index.html">Exibir o Gmail apenas em html</a></li>
<li><a href="../pt476478/index.html">Etapas da introdu√ß√£o de modelos de aprendizado de m√°quina em grandes empresas</a></li>
<li><a href="../pt476480/index.html">Como desenvolver um desenvolvedor em uma cidade pequena e n√£o muito de TI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßöüèΩ üëèüèΩ üï∏Ô∏è Wir machen ein maschinelles Lernprojekt in Python. Teil 2 üíÉüèæ ü•ò üî¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ein vollst√§ndiger Durchgang zum maschinellen Lernen in Python: Teil Zwei 

 Das Zusammenstellen aller Teile eines maschinellen Lernprojekts kann schwi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir machen ein maschinelles Lernprojekt in Python. Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/425907/"><img src="https://habrastorage.org/getpro/habr/post_images/225/910/6f3/2259106f3ccc19ae2b8b1ec9f316c4f2.png"><br><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ein vollst√§ndiger Durchgang zum maschinellen Lernen in Python: Teil Zwei</a></i> <br><br>  Das Zusammenstellen aller Teile eines maschinellen Lernprojekts kann schwierig sein.  In dieser Artikelserie werden wir alle Phasen der Implementierung des maschinellen Lernprozesses anhand realer Daten durchlaufen und herausfinden, wie die verschiedenen Techniken miteinander kombiniert werden. <br><br>  Im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ersten Artikel haben</a> wir die Daten bereinigt und strukturiert, eine explorative Analyse durchgef√ºhrt, eine Reihe von Attributen zur Verwendung im Modell gesammelt und eine Basis f√ºr die Bewertung der Ergebnisse festgelegt.  Mithilfe dieses Artikels lernen wir, wie Sie in Python implementieren und mehrere Modelle f√ºr maschinelles Lernen vergleichen, eine hyperparametrische Optimierung durchf√ºhren, um das beste Modell zu optimieren, und die Leistung des endg√ºltigen Modells anhand eines Testdatensatzes bewerten. <br><br>  Der gesamte Projektcode befindet sich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf GitHub</a> , und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ist das zweite Notizbuch, das sich auf den aktuellen Artikel bezieht.  Sie k√∂nnen den Code beliebig verwenden und √§ndern! <br><a name="habracut"></a><br><h2>  Modellbewertung und -auswahl </h2><br>  Anmerkung: Wir arbeiten an einer kontrollierten Regressionsaufgabe, bei der mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Energieinformationen aus Geb√§uden in New York</a> ein Modell erstellt wird, das vorhersagt, welchen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Energy Star Score ein</a> bestimmtes Geb√§ude erhalten wird.  Wir sind sowohl an der Genauigkeit der Prognose als auch an der Interpretierbarkeit des Modells interessiert. <br><br>  Heute k√∂nnen Sie aus den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vielen verf√ºgbaren Modellen f√ºr maschinelles Lernen</a> ausw√§hlen, und diese F√ºlle kann einsch√ºchternd sein.  Nat√ºrlich gibt es im Netzwerk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vergleichende Bewertungen</a> , die Ihnen bei der Auswahl eines Algorithmus helfen, aber ich ziehe es vor, einige davon auszuprobieren und herauszufinden, welcher besser ist.  Zum gr√∂√üten Teil basiert maschinelles Lernen eher auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">empirischen als auf theoretischen Ergebnissen</a> , und es ist fast <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unm√∂glich, im Voraus zu verstehen, welches Modell genauer ist</a> . <br><br>  Es wird allgemein empfohlen, mit einfachen, interpretierbaren Modellen wie der linearen Regression zu beginnen. Wenn die Ergebnisse nicht zufriedenstellend sind, fahren Sie mit komplexeren, aber normalerweise genaueren Methoden fort.  Diese Grafik (sehr anti-wissenschaftlich) zeigt die Beziehung zwischen der Genauigkeit und Interpretierbarkeit einiger Algorithmen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1a1/602/9a1/1a16029a1b75b5ba4022d477615f352f.png"><br>  <i>Interpretierbarkeit und Genauigkeit ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> ).</i> <br><br>  Wir werden f√ºnf Modelle mit unterschiedlichem Komplexit√§tsgrad bewerten: <br><br><ul><li>  Lineare Regression. </li><li>  Die Methode der k-n√§chsten Nachbarn. </li><li>  "Zuf√§lliger Wald." </li><li>  Gradientenverst√§rkung. </li><li>  Methode der Unterst√ºtzungsvektoren. </li></ul><br>  Wir werden nicht den theoretischen Apparat dieser Modelle betrachten, sondern ihre Implementierung.  Wenn Sie sich f√ºr Theorie interessieren, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lesen Sie</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eine Einf√ºhrung in das statistische Lernen</a> (kostenlos erh√§ltlich) oder das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">praktische maschinelle Lernen mit Scikit-Learn und TensorFlow</a> .  In beiden B√ºchern wird die Theorie perfekt erkl√§rt und die Wirksamkeit der Verwendung der genannten Methoden in den Sprachen R bzw. Python gezeigt. <br><br><h4>  Geben Sie die fehlenden Werte ein </h4><br>  Obwohl wir beim L√∂schen der Daten die Spalten verworfen haben, in denen mehr als die H√§lfte der Werte fehlen, haben wir immer noch viele Werte.  Modelle f√ºr maschinelles Lernen k√∂nnen nicht mit fehlenden Daten arbeiten, daher m√ºssen wir sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ausf√ºllen</a> . <br><br>  Zuerst betrachten wir die Daten und erinnern uns, wie sie aussehen: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Read in data into dataframes train_features = pd.read_csv('data/training_features.csv') test_features = pd.read_csv('data/testing_features.csv') train_labels = pd.read_csv('data/training_labels.csv') test_labels = pd.read_csv('data/testing_labels.csv') Training Feature Size: (6622, 64) Testing Feature Size: (2839, 64) Training Labels Size: (6622, 1) Testing Labels Size: (2839, 1)</span></span></code> </pre> <br>  Jeder <code>NaN</code> Wert ist ein fehlender Datensatz in den Daten.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sie k√∂nnen sie auf verschiedene Arten f√ºllen</a> , und wir verwenden die relativ einfache Median-Imputationsmethode, bei der die fehlenden Daten durch die Durchschnittswerte f√ºr die entsprechenden Spalten ersetzt werden. <br><br>  Im folgenden Code erstellen wir ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scikit-Learn</a> Imputer- <code>Imputer</code> mit einer Medianstrategie.  Dann trainieren wir es mit den Trainingsdaten (mit <code>imputer.fit</code> ) und wenden es an, um die fehlenden Werte in den Trainings- und Tests√§tzen (mit <code>imputer.transform</code> ) <code>imputer.transform</code> .  Das hei√üt, die Datens√§tze, die in den <i>Testdaten</i> fehlen, werden mit dem entsprechenden Medianwert aus den <i>Trainingsdaten</i> gef√ºllt. <br><br>  Wir f√ºhren das F√ºllen durch und trainieren das Modell nicht so, wie es ist, um das Problem des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verlusts von Testdaten</a> zu vermeiden, wenn Informationen aus dem Testdatensatz in das Training einflie√üen. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Create an imputer object with a median filling strategy imputer = Imputer(strategy='median') # Train on the training features imputer.fit(train_features) # Transform both training data and testing data X = imputer.transform(train_features) X_test = imputer.transform(test_features) Missing values in training features: 0 Missing values in testing features: 0</span></span></code> </pre> <br>  Jetzt sind alle Werte gef√ºllt, es gibt keine L√ºcken. <br><br><h4>  Feature-Skalierung </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Skalierung</a> ist der allgemeine Prozess zum √Ñndern des Bereichs eines Merkmals.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dies ist ein notwendiger Schritt</a> , da Vorzeichen in verschiedenen Einheiten gemessen werden, was bedeutet, dass sie unterschiedliche Bereiche abdecken.  Dies verzerrt die Ergebnisse von Algorithmen wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Support-Vektor-</a> Methode und der k-Nearest-Neighbour-Methode, die die Abst√§nde zwischen den Messungen ber√ºcksichtigen, erheblich.  Durch Skalierung k√∂nnen Sie dies vermeiden.  Obwohl Methoden wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lineare Regression und ‚ÄûRandom Forest‚Äú</a> keine Skalierung von Features erfordern, ist es besser, diesen Schritt beim Vergleich mehrerer Algorithmen nicht zu vernachl√§ssigen. <br><br>  Wir skalieren mit jedem Attribut auf einen Bereich von 0 bis 1. Wir nehmen alle Werte des Attributs, w√§hlen das Minimum aus und dividieren es durch die Differenz zwischen Maximum und Minimum (Bereich).  Diese Skalierungsmethode wird oft als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Normalisierung bezeichnet, und der andere Hauptweg ist die Standardisierung</a> . <br><br>  Dieser Prozess ist einfach manuell zu implementieren, daher verwenden wir das <code>MinMaxScaler</code> Objekt von Scikit-Learn.  Der Code f√ºr diese Methode ist identisch mit dem Code zum Ausf√ºllen der fehlenden Werte. Anstelle des Einf√ºgens wird nur die Skalierung verwendet.  Denken Sie daran, dass wir das Modell nur im Trainingssatz lernen und dann alle Daten transformieren. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Create the scaler object with a range of 0-1 scaler = MinMaxScaler(feature_range=(0, 1)) # Fit on the training data scaler.fit(X) # Transform both the training and testing data X = scaler.transform(X) X_test = scaler.transform(X_test)</span></span></code> </pre> <br>  Jetzt hat jedes Attribut einen Mindestwert von 0 und einen H√∂chstwert von 1. Das Ausf√ºllen der fehlenden Werte und die Skalierung der Attribute - diese beiden Stufen werden in fast jedem maschinellen Lernprozess ben√∂tigt. <br><br><h4>  Wir implementieren maschinelle Lernmodelle in Scikit-Learn </h4><br>  Nach all den Vorarbeiten ist das Erstellen, Trainieren und Ausf√ºhren von Modellen relativ einfach.  Wir werden die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scikit-Learn-</a> Bibliothek in Python verwenden, die wundersch√∂n dokumentiert ist und √ºber eine ausgefeilte Syntax zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen von</a> Modellen verf√ºgt.  Indem Sie lernen, wie Sie in Scikit-Learn ein Modell erstellen, k√∂nnen Sie schnell alle Arten von Algorithmen implementieren. <br><br>  Wir werden den Prozess der Erstellung, des Trainings ( <code>.fit</code> ) und des Testens ( <code>.predict</code> ) mithilfe der Gradientenverst√§rkung <code>.predict</code> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GradientBoostingRegressor <span class="hljs-comment"><span class="hljs-comment"># Create the model gradient_boosted = GradientBoostingRegressor() # Fit the model on the training data gradient_boosted.fit(X, y) # Make predictions on the test data predictions = gradient_boosted.predict(X_test) # Evaluate the model mae = np.mean(abs(predictions - y_test)) print('Gradient Boosted Performance on the test set: MAE = %0.4f' % mae) Gradient Boosted Performance on the test set: MAE = 10.0132</span></span></code> </pre> <br>  Nur eine Codezeile zum Erstellen, Trainieren und Testen.  Um andere Modelle zu erstellen, verwenden wir dieselbe Syntax und √§ndern nur den Namen des Algorithmus. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/215/58f/ab4/21558fab42e2669b96132dff6a5b2691.png"><br><br>  Um Modelle objektiv zu bewerten, haben wir den Basispegel anhand des Medianwerts des Ziels berechnet und 24,5 erhalten.  Die Ergebnisse waren viel besser, sodass unser Problem durch maschinelles Lernen gel√∂st werden kann. <br><br>  In unserem Fall erwies sich die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gradientenverst√§rkung</a> (MAE = 10.013) als etwas besser als die "zuf√§llige Gesamtstruktur" (10.014 MAE).  Obwohl diese Ergebnisse nicht als ganz ehrlich angesehen werden k√∂nnen, verwenden wir f√ºr Hyperparameter meistens die Standardwerte.  Die Wirksamkeit der Modelle h√§ngt stark von diesen Einstellungen ab, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">insbesondere bei der Support-Vektor-Methode</a> .  Basierend auf diesen Ergebnissen werden wir jedoch die Gradientenverst√§rkung w√§hlen und beginnen, sie zu optimieren. <br><br><h2>  Hyperparametrische Modelloptimierung </h2><br>  Nachdem Sie ein Modell ausgew√§hlt haben, k√∂nnen Sie es durch Anpassen der Hyperparameter f√ºr die zu l√∂sende Aufgabe optimieren. <br><br>  Aber lassen Sie uns zun√§chst verstehen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">was Hyperparameter sind und wie sie sich von gew√∂hnlichen Parametern unterscheiden</a> . <br><br><ul><li>  Die Hyperparameter des Modells k√∂nnen als Einstellungen des Algorithmus betrachtet werden, die wir vor Beginn des Trainings festgelegt haben.  Beispielsweise ist der Hyperparameter die Anzahl der B√§ume in der "zuf√§lligen Gesamtstruktur" oder die Anzahl der Nachbarn in der Methode der k-n√§chsten Nachbarn. </li><li>  Modellparameter - was sie w√§hrend des Trainings lernt, zum Beispiel Gewichte in linearer Regression. </li></ul><br>  Durch die Steuerung des Hyperparameters beeinflussen wir die Ergebnisse des Modells und ver√§ndern das Gleichgewicht zwischen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Untererziehung und Umschulung</a> .  Unter Lernen versteht man eine Situation, in der das Modell nicht komplex genug ist (es hat zu wenig Freiheitsgrade), um die Entsprechung von Zeichen und Zielen zu untersuchen.  Ein untertrainiertes Modell weist eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hohe</a> Vorspannung auf, die durch Komplikation des Modells korrigiert werden kann. <br><br>  Umschulung ist eine Situation, in der sich das Modell im Wesentlichen an die Trainingsdaten erinnert.  Das umgeschulte Modell weist eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hohe</a> Varianz auf, die angepasst werden kann, indem die Komplexit√§t des Modells durch Regularisierung begrenzt wird.  Sowohl unter- als auch umgeschulte Modelle k√∂nnen die Testdaten nicht gut verallgemeinern. <br><br>  Die Schwierigkeit bei der Auswahl der richtigen Hyperparameter besteht darin, dass f√ºr jede Aufgabe ein eindeutiger optimaler Satz vorhanden ist.  Daher k√∂nnen Sie die besten Einstellungen nur ausw√§hlen, indem Sie verschiedene Kombinationen f√ºr das neue Dataset ausprobieren.  Gl√ºcklicherweise verf√ºgt Scikit-Learn √ºber eine Reihe von Methoden, mit denen Sie Hyperparameter effektiv bewerten k√∂nnen.  Dar√ºber hinaus versuchen Projekte wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TPOT</a> , die Suche nach Hyperparametern mithilfe von Ans√§tzen wie der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">genetischen Programmierung</a> zu optimieren.  In diesem Artikel beschr√§nken wir uns auf die Verwendung von Scikit-Learn. <br><br><h4>  √úberpr√ºfen Sie die zuf√§llige Suche </h4><br>  Lassen Sie uns eine Hyperparameter-Optimierungsmethode implementieren, die als zuf√§llige Kreuzvalidierungssuchen bezeichnet wird: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zufallssuche</a> - eine Technik zur Auswahl von Hyperparametern.  Wir definieren ein Raster und w√§hlen dann zuf√§llig verschiedene Kombinationen daraus aus, im Gegensatz zur Rastersuche, bei der wir jede Kombination nacheinander ausprobieren.  Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zufallssuche funktioniert</a> √ºbrigens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fast genauso gut wie die Rastersuche</a> , ist aber viel schneller. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Durch</a> Gegenpr√ºfung kann die ausgew√§hlte Kombination von Hyperparametern bewertet werden.  Anstatt die Daten in Trainings- und Tests√§tze aufzuteilen, wodurch die f√ºr das Training verf√ºgbare Datenmenge reduziert wird, verwenden wir die K-Block-Kreuzvalidierung (K-Fold Cross Validation).  Dazu teilen wir die Trainingsdaten in k Bl√∂cke auf und f√ºhren dann den iterativen Prozess aus, bei dem wir zuerst das Modell auf k-1 Bl√∂cken trainieren und dann das Ergebnis vergleichen, wenn wir auf dem k-ten Block lernen.  Wir werden den Vorgang k-mal wiederholen und am Ende den durchschnittlichen Fehlerwert f√ºr jede Iteration erhalten.  Dies wird die endg√ºltige Bewertung sein. </li></ul><br>  Hier ist eine grafische Darstellung der Kreuzvalidierung von k-Bl√∂cken bei k = 5: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e17/94b/51e/e1794b51eded0314afd9f594a8e9ee5e.png"><br><br>  Der gesamte zuf√§llige Suchprozess f√ºr die Kreuzvalidierung sieht folgenderma√üen aus: <br><br><ol><li>  Wir setzen ein Gitter von Hyperparametern. </li><li>  W√§hlen Sie zuf√§llig eine Kombination von Hyperparametern aus. </li><li>  Erstellen Sie mit dieser Kombination ein Modell. </li><li>  Wir bewerten das Ergebnis des Modells mithilfe der K-Block-Kreuzvalidierung. </li><li>  Wir entscheiden, welche Hyperparameter das beste Ergebnis liefern. </li></ol><br>  Nat√ºrlich geschieht dies alles nicht manuell, sondern mit <code>RandomizedSearchCV</code> von Scikit-Learn! <br><br><h4>  Kleiner Exkurs: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gradientenverst√§rkungsmethoden</a> </h4><br>  Wir werden ein Gradienten-Boost-basiertes Regressionsmodell verwenden.  Dies ist eine kollektive Methode, dh das Modell besteht aus zahlreichen ‚Äûschwachen Lernenden‚Äú, in diesem Fall aus separaten Entscheidungsb√§umen.  Wenn die Sch√ºler in parallelen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Algorithmen wie ‚ÄûRandom Forest‚Äú</a> lernen und dann das Vorhersageergebnis durch Abstimmung ausgew√§hlt wird, lernen die Sch√ºler in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Boosting-Algorithmen</a> wie Gradient Boosting nacheinander und jeder von ihnen ‚Äûkonzentriert‚Äú sich auf die Fehler seiner Vorg√§nger. <br><br>  In den letzten Jahren sind Boosting-Algorithmen popul√§r geworden und gewinnen h√§ufig bei Wettbewerben f√ºr maschinelles Lernen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gradient Boosting</a> ist eine der Implementierungen, bei denen Gradient Descent verwendet wird, um die Kosten der Funktion zu minimieren.  Die Implementierung der Gradientenverst√§rkung in Scikit-Learn wird als nicht so effektiv angesehen wie in anderen Bibliotheken, beispielsweise in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">XGBoost</a> , funktioniert jedoch gut bei kleinen Datens√§tzen und liefert ziemlich genaue Vorhersagen. <br><br><h4>  Zur√ºck zur hyperparametrischen Einstellung </h4><br>  Bei der Regression mit Gradientenverst√§rkung m√ºssen viele Hyperparameter konfiguriert werden. Einzelheiten finden Sie in der Scikit-Learn-Dokumentation.  Wir werden optimieren: <br><br><ul><li>  <code>loss</code> : Minimierung der Verlustfunktion; </li><li>  <code>n_estimators</code> : Anzahl der verwendeten schwachen Entscheidungsb√§ume (Entscheidungsb√§ume); </li><li>  <code>max_depth</code> : maximale Tiefe jedes Entscheidungsbaums; </li><li>  <code>min_samples_leaf</code> : Die Mindestanzahl von Beispielen, die sich im Blattknoten des Entscheidungsbaums befinden sollten. </li><li>  <code>min_samples_split</code> : Die Mindestanzahl von Beispielen, die zum <code>min_samples_split</code> des Entscheidungsbaumknotens erforderlich sind. </li><li>  <code>max_features</code> : Die maximale Anzahl von Features, die zum Trennen von Knoten verwendet werden. </li></ul><br>  Ich bin mir nicht sicher, ob jemand wirklich versteht, wie das alles funktioniert, und der einzige Weg, die beste Kombination zu finden, besteht darin, verschiedene Optionen auszuprobieren. <br><br>  In diesem Code erstellen wir ein Raster von Hyperparametern, erstellen dann ein <code>RandomizedSearchCV</code> Objekt und suchen mithilfe der 4-Block-Kreuzvalidierung nach 25 verschiedenen Kombinationen von Hyperparametern: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Loss function to be optimized loss = ['ls', 'lad', 'huber'] # Number of trees used in the boosting process n_estimators = [100, 500, 900, 1100, 1500] # Maximum depth of each tree max_depth = [2, 3, 5, 10, 15] # Minimum number of samples per leaf min_samples_leaf = [1, 2, 4, 6, 8] # Minimum number of samples to split a node min_samples_split = [2, 4, 6, 10] # Maximum number of features to consider for making splits max_features = ['auto', 'sqrt', 'log2', None] # Define the grid of hyperparameters to search hyperparameter_grid = {'loss': loss, 'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'min_samples_split': min_samples_split, 'max_features': max_features} # Create the model to use for hyperparameter tuning model = GradientBoostingRegressor(random_state = 42) # Set up the random search with 4-fold cross validation random_cv = RandomizedSearchCV(estimator=model, param_distributions=hyperparameter_grid, cv=4, n_iter=25, scoring = 'neg_mean_absolute_error', n_jobs = -1, verbose = 1, return_train_score = True, random_state=42) # Fit on the training data random_cv.fit(X, y) After performing the search, we can inspect the RandomizedSearchCV object to find the best model: # Find the best combination of settings random_cv.best_estimator_ GradientBoostingRegressor(loss='lad', max_depth=5, max_features=None, min_samples_leaf=6, min_samples_split=6, n_estimators=500)</span></span></code> </pre> <br>  Sie k√∂nnen diese Ergebnisse f√ºr eine Rastersuche verwenden, indem Sie Parameter f√ºr das Raster ausw√§hlen, die nahe an diesen optimalen Werten liegen.  Eine weitere Abstimmung d√ºrfte das Modell jedoch nicht wesentlich verbessern.  Es gibt eine allgemeine Regel: Die kompetente Konstruktion von Merkmalen hat einen viel gr√∂√üeren Einfluss auf die Genauigkeit des Modells als die teuerste Hyperparametereinstellung.  Dies ist das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesetz zur Verringerung der Rentabilit√§t in Bezug auf maschinelles Lernen</a> : Das Entwerfen von Attributen bietet die h√∂chste Rendite, und hyperparametrisches Tuning bringt nur bescheidene Vorteile. <br><br>  Um die Anzahl der Sch√§tzer (Entscheidungsb√§ume) zu √§ndern und gleichzeitig die Werte anderer Hyperparameter beizubehalten, kann ein Experiment durchgef√ºhrt werden, das die Rolle dieser Einstellung demonstriert.  Die Implementierung ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier angegeben</a> , aber hier ist das Ergebnis: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aca/18e/d51/aca18ed519f22d26c6b78af3324b8614.png"><br><br>  Mit zunehmender Anzahl der vom Modell verwendeten B√§ume nimmt die Fehlerquote beim Training und Testen ab.  Lernfehler nehmen jedoch viel schneller ab, und infolgedessen wird das Modell umgeschult: Es zeigt hervorragende Ergebnisse bei Trainingsdaten, funktioniert jedoch schlechter bei Testdaten. <br><br>  Bei Testdaten nimmt die Genauigkeit immer ab (da das Modell die richtigen Antworten f√ºr den Trainingsdatensatz sieht), aber ein signifikanter R√ºckgang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">weist auf eine Umschulung hin</a> .  Dieses Problem kann gel√∂st werden, indem die Menge der Trainingsdaten erh√∂ht oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Komplexit√§t des Modells mithilfe von Hyperparametern verringert wird</a> .  Hier werden wir nicht auf Hyperparameter eingehen, aber ich empfehle Ihnen, immer auf das Problem der Umschulung zu achten. <br><br>  F√ºr unser endg√ºltiges Modell werden 800 Bewerter herangezogen, da dies die niedrigste Fehlerquote bei der Kreuzvalidierung ergibt.  Testen Sie jetzt das Modell! <br><br><h2>  Bewertung anhand von Testdaten </h2><br>  Als Verantwortliche haben wir daf√ºr gesorgt, dass unser Modell w√§hrend des Trainings in keiner Weise Zugang zu Testdaten erhielt.  Daher k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wir die Genauigkeit bei der Arbeit mit Testdaten als</a> Modellqualit√§tsindikator <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verwenden,</a> wenn diese f√ºr reale Aufgaben zugelassen sind. <br><br>  Wir geben die Modelltestdaten ein und berechnen den Fehler.  Hier ist ein Vergleich der Ergebnisse des Standardalgorithmus zur Erh√∂hung des Gradienten und unseres benutzerdefinierten Modells: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Make predictions on the test set using default and final model default_pred = default_model.predict(X_test) final_pred = final_model.predict(X_test) Default model performance on the test set: MAE = 10.0118. Final model performance on the test set: MAE = 9.0446.</span></span></code> </pre> <br>  Durch hyperparametrische Abstimmung konnte die Modellgenauigkeit um etwa 10% verbessert werden.  Je nach Situation kann dies eine erhebliche Verbesserung sein, die jedoch viel Zeit in Anspruch nimmt. <br><br>  Sie k√∂nnen die Trainingszeit f√ºr beide Modelle mit dem <code>%timeit</code> magic <code>%timeit</code> in Jupyter Notebooks vergleichen.  Messen Sie zun√§chst die Standarddauer des Modells: <br><br><pre> <code class="python hljs">%%timeit -n <span class="hljs-number"><span class="hljs-number">1</span></span> -r <span class="hljs-number"><span class="hljs-number">5</span></span> default_model.fit(X, y) <span class="hljs-number"><span class="hljs-number">1.09</span></span> s ¬± <span class="hljs-number"><span class="hljs-number">153</span></span> ms per loop (mean ¬± std. dev. of <span class="hljs-number"><span class="hljs-number">5</span></span> runs, <span class="hljs-number"><span class="hljs-number">1</span></span> loop each)</code> </pre> <br>  Eine Sekunde zum Lernen ist sehr anst√§ndig.  Aber das getunte Modell ist nicht so schnell: <br><br><pre> <code class="python hljs">%%timeit -n <span class="hljs-number"><span class="hljs-number">1</span></span> -r <span class="hljs-number"><span class="hljs-number">5</span></span> final_model.fit(X, y) <span class="hljs-number"><span class="hljs-number">12.1</span></span> s ¬± <span class="hljs-number"><span class="hljs-number">1.33</span></span> s per loop (mean ¬± std. dev. of <span class="hljs-number"><span class="hljs-number">5</span></span> runs, <span class="hljs-number"><span class="hljs-number">1</span></span> loop each)</code> </pre> <br>  Diese Situation verdeutlicht den grundlegenden Aspekt des maschinellen Lernens: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Es geht um Kompromisse</a> .  Es ist st√§ndig notwendig, ein Gleichgewicht zwischen Genauigkeit und Interpretierbarkeit, zwischen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verschiebung und Streuung</a> , zwischen Genauigkeit und Betriebszeit usw. zu w√§hlen.  Die richtige Kombination wird vollst√§ndig von der spezifischen Aufgabe bestimmt.  In unserem Fall ist eine 12-fache Verl√§ngerung der Arbeitsdauer relativ gesehen gro√ü, aber absolut gesehen unbedeutend. <br><br>  Wir haben die endg√ºltigen Prognoseergebnisse erhalten. Analysieren wir sie nun und stellen fest, ob es erkennbare Abweichungen gibt.  Links ist ein Diagramm der Dichte der vorhergesagten und realen Werte, rechts ein Histogramm des Fehlers: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/817/ea7/f23/817ea7f2371b83ff0ae6ae5fa02b5a1e.png" width="350"><img src="https://habrastorage.org/getpro/habr/post_images/f49/f42/5cc/f49f425cc56d717a1e75b9478d1a24d1.png" width="340"><br><br>  Die Vorhersage des Modells wiederholt die Verteilung der realen Werte gut, w√§hrend sich der Dichtepeak in den Trainingsdaten n√§her am Medianwert (66) befindet als am realen Dichtepeak (etwa 100).  Fehler haben eine fast normale Verteilung, obwohl es mehrere gro√üe negative Werte gibt, wenn sich die Modellprognose stark von den realen Daten unterscheidet.  Im n√§chsten Artikel werden wir uns die Interpretation der Ergebnisse genauer ansehen. <br><br><h2>  Fazit </h2><br>  In diesem Artikel haben wir verschiedene Phasen der L√∂sung des Problems des maschinellen Lernens untersucht: <br><br><ul><li>  Fehlende Werte und Skalierungsfunktionen ausf√ºllen. </li><li>  Auswertung und Vergleich der Ergebnisse mehrerer Modelle. </li><li>  Hyperparametrische Abstimmung mit zuf√§lliger Rastersuche und Kreuzvalidierung. </li><li>  Bewertung des besten Modells anhand von Testdaten. </li></ul><br>  Die Ergebnisse zeigen, dass wir maschinelles Lernen verwenden k√∂nnen, um den Energy Star Score basierend auf verf√ºgbaren Statistiken vorherzusagen.  Mit Hilfe der Gradientenverst√§rkung wurde ein Fehler von 9,1 bei den Testdaten erreicht.  Hyperparametrisches Tuning kann die Ergebnisse erheblich verbessern, jedoch auf Kosten einer signifikanten Verlangsamung.  Dies ist einer von vielen Kompromissen, die beim maschinellen Lernen ber√ºcksichtigt werden m√ºssen. <br><br>  Im n√§chsten Artikel werden wir versuchen herauszufinden, wie unser Modell funktioniert.  Wir werden uns auch die Hauptfaktoren ansehen, die den Energy Star Score beeinflussen.  Wenn wir wissen, dass das Modell genau ist, werden wir versuchen zu verstehen, warum es dies vorhersagt und was uns dies √ºber das Problem selbst sagt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de425907/">https://habr.com/ru/post/de425907/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de425897/index.html">Funktionen zur Verwendung der RxJs-Bibliothek in einem Online-Banking-System</a></li>
<li><a href="../de425899/index.html">Ameisenh√ºgel oder Festung? Ich baue ein Haus zum Preis einer Wohnung. 1 Teil</a></li>
<li><a href="../de425901/index.html">Wetterstation auf Arduino von A bis Z. Teil 1</a></li>
<li><a href="../de425903/index.html">Urlaub kommt zu uns: SCRF hat das ISM-Band von 868 MHz verdoppelt</a></li>
<li><a href="../de425905/index.html">So schreiben Sie Assembler-Code mit √ºberlappenden Anweisungen (eine andere Technik zum Verschleiern von Bytecode)</a></li>
<li><a href="../de425911/index.html">√úbertragen Sie Cloud CRM in die Box-Version</a></li>
<li><a href="../de425915/index.html">Wie grenz√ºberschreitende Kommunikation Ampeln ersetzen und den Weg zur Arbeit verk√ºrzen kann</a></li>
<li><a href="../de425917/index.html">Der Justizk√§mpfer verhindert, dass Waymo die Schl√ºssel-Lidar-Technologie patentiert</a></li>
<li><a href="../de425919/index.html">Hexagon-Karten in Unity: Speichern und Laden, Texturen, Entfernungen</a></li>
<li><a href="../de425921/index.html">.NET Community-Meeting auf CLRium # 4 + online</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
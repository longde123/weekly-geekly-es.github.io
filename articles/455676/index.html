<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏾‍⚖️ 📩 🙎🏽 ¿Estalló la burbuja de aprendizaje automático o el comienzo de un nuevo amanecer? 🏼 🔺 👨‍🔬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recientemente, se ha publicado un artículo que muestra una buena tendencia en el aprendizaje automático en los últimos años. En resumen: el número de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¿Estalló la burbuja de aprendizaje automático o el comienzo de un nuevo amanecer?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/455676/">  Recientemente, se ha publicado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un artículo</a> que muestra una buena tendencia en el aprendizaje automático en los últimos años.  En resumen: el número de nuevas empresas en el campo del aprendizaje automático ha disminuido considerablemente en los últimos dos años. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1c6/466/4fc/1c64664fcaf125f2104e67547b533e41.png" alt="imagen"></div><br>  Pues que.  Analicemos "si estalló la burbuja", "cómo vivir" y hablemos de dónde vino ese garabato. <br><a name="habracut"></a><br>  Primero, hablemos sobre cuál fue el refuerzo de esta curva.  ¿De dónde vino ella?  Probablemente todos recordarán la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">victoria del</a> aprendizaje automático en 2012 en el concurso ImageNet.  Después de todo, ¡este es el primer evento mundial!  Pero en realidad esto no es así.  Y el crecimiento de la curva comienza un poco antes.  Lo dividiría en varios puntos. <br><br><ol><li>  2008 es la aparición del término "big data".  Los productos reales comenzaron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">a aparecer</a> en 2010.  Big data está directamente relacionado con el aprendizaje automático.  Sin big data, el funcionamiento estable de los algoritmos que existían en ese momento es imposible.  Y estas no son redes neuronales.  Hasta 2012, las redes neuronales son la minoría marginal.  Pero entonces comenzaron a funcionar algoritmos completamente diferentes, que habían existido durante años, o incluso décadas: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SVM</a> (1963, 1993), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Random Forest</a> (1995), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AdaBoost</a> (2003), ... Las nuevas empresas de esos años se asocian principalmente con el procesamiento automático de datos estructurados. : taquillas, usuarios, publicidad, mucho más. <br><br>  La derivada de esta primera ola es un conjunto de marcos como XGBoost, CatBoost, LightGBM, etc. <br></li><li>  En 2011-2012, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">las redes neuronales convolucionales</a> ganaron una serie de concursos de reconocimiento de imágenes.  Su uso real fue algo retrasado.  Diría que las nuevas empresas y soluciones masivamente significativas comenzaron a aparecer en 2014.  Se necesitaron dos años para digerir que las neuronas aún funcionan, para crear marcos convenientes que se puedan instalar y ejecutar en un período de tiempo razonable, para desarrollar métodos que estabilicen y aceleren el tiempo de convergencia. <br><br>  Las redes convolucionales permitieron resolver problemas de visión artificial: clasificación de imágenes y objetos en una imagen, detección de objetos, reconocimiento de objetos y personas, mejora de imágenes, etc., etc. </li><li>  2015-2017 años.  El auge de los algoritmos y proyectos vinculados a las redes de recurrencia o sus análogos (LSTM, GRU, TransformerNet, etc.).  Han aparecido algoritmos de voz a texto y sistemas de traducción automática que funcionan bien.  En parte, se basan en redes convolucionales para resaltar características básicas.  Parcialmente por el hecho de que aprendieron a recopilar conjuntos de datos realmente grandes y buenos. </li></ol><br><img src="https://habrastorage.org/webt/_c/bj/f2/_cbjf2doqjypuqwfwh1d8_vx92a.png"><br><br>  "¿Ha estallado la burbuja?"  ¿Hype se está sobrecalentando?  ¿Murieron como una cadena de bloques? <br>  Pues bien!  Mañana Siri dejará de funcionar en su teléfono, y pasado mañana Tesla no distinguirá un giro de un canguro. <br><br>  Las redes neuronales ya están funcionando.  Están en docenas de dispositivos.  Realmente te permiten ganar, cambiar el mercado y el mundo que te rodea.  Hype se ve un poco diferente: <br><br><img src="https://habrastorage.org/webt/zl/7m/ph/zl7mphh3m3rzprgxpbaopha3gwy.png"><br><br>  Es solo que las redes neuronales han dejado de ser algo nuevo.  Sí, muchas personas tienen altas expectativas.  Pero una gran cantidad de compañías han aprendido a usar sus neuronas y a fabricar productos basados ​​en ellas.  Las neuronas dan una nueva funcionalidad, pueden reducir trabajos, reducir el precio de los servicios: <br><br><ul><li>  Las empresas manufactureras integran algoritmos para el análisis de rechazos en el transportador. </li><li>  Las granjas ganaderas están comprando sistemas para controlar las vacas. </li><li>  Cosechadoras automáticas. </li><li>  Centros de llamadas automatizados. </li><li>  Filtros en Snapchat.  ( <s>bueno, al menos algo sensato!</s> ) </li></ul><br>  Pero lo principal, y no lo más obvio: "No hay más ideas nuevas, o no traerán capital instantáneo".  Las redes neuronales han resuelto docenas de problemas.  Y ellos decidirán aún más.  Todas las ideas obvias que fueron - generaron muchas nuevas empresas.  Pero todo lo que estaba en la superficie ya ha sido recolectado.  En los últimos dos años, no he encontrado una sola idea nueva para el uso de redes neuronales.  No hay un solo enfoque nuevo (bueno, está bien, hay algunos problemas con las GAN). <br><br>  Y cada próxima puesta en marcha es cada vez más complicada.  Ya no se requieren dos tipos que entrenen a una neurona en datos abiertos.  Requiere programadores, un servidor, un equipo de redactores, soporte complejo, etc. <br><br>  Como resultado, hay menos startups.  Pero la producción es más.  ¿Necesita adjuntar el reconocimiento de matrícula?  Hay cientos de profesionales con experiencia relevante en el mercado.  Puede contratar y en un par de meses su empleado creará un sistema.  O compre uno terminado.  Pero haciendo una nueva startup? .. Locura! <br><br>  Necesitamos crear un sistema para rastrear a los visitantes: ¿por qué pagar por un montón de licencias? Si puede hacer las suyas durante 3-4 meses, agudícelas para su negocio. <br><br>  Ahora las redes neuronales siguen el mismo camino que docenas de otras tecnologías. <br><br>  ¿Recuerdas cómo ha cambiado el concepto de "desarrollador de sitios" desde 1995?  Si bien el mercado no está saturado de especialistas.  Hay muy pocos profesionales.  Pero puedo apostar que en 5-10 años no habrá mucha diferencia entre un programador de Java y un desarrollador de redes neuronales.  Y esos y esos especialistas serán suficientes en el mercado. <br><br>  Simplemente habrá una clase de tareas para las que las neuronas resuelven.  Había una tarea: contratar a un especialista. <br><br>  <b>“¿Y luego qué?</b>  <b>¿Dónde está la inteligencia artificial prometida?</b> <br><br>  Y aquí hay un pequeño pero interesante neponyatchka :) <br><br>  La pila de tecnología que existe hoy, aparentemente, todavía no nos llevará a la inteligencia artificial.  Las ideas, su novedad, se han agotado en gran medida.  Hablemos de lo que mantiene el nivel actual de desarrollo. <br><br><h3>  Limitaciones </h3><br>  Comencemos con los drones automáticos.  Parece entenderse que es posible fabricar automóviles totalmente autónomos con las tecnologías actuales.  Pero después de cuántos años esto sucederá no está claro.  Tesla cree que esto sucederá en un par de años. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Ucp0TTmvqOE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Hay muchos otros <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">especialistas</a> que califican esto como 5-10 años. <br><br>  Lo más probable, en mi opinión, después de 15 años, la infraestructura de las ciudades en sí misma cambiará para que la aparición de automóviles autónomos sea inevitable, será su continuación.  Pero esto no puede considerarse inteligencia.  Modern Tesla es una tubería muy compleja para filtrar datos, buscarlos y volver a capacitarlos.  Estas son reglas, reglas, reglas, recopilación de datos y filtros sobre ellos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> escribí un poco más al respecto, o mire desde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este</a> punto). <br><br><h3>  Primer problema </h3><br>  Y es aquí donde vemos el <b>primer problema fundamental</b> .  Big data  Esto es exactamente lo que generó la ola actual de redes neuronales y aprendizaje automático.  Ahora, para hacer algo complejo y automático, necesita muchos datos.  No solo mucho, sino mucho, mucho.  Necesitamos algoritmos automatizados para su recopilación, marcado, uso.  Queremos hacer que el automóvil vea camiones contra el sol; primero debemos recoger un número suficiente de ellos.  Queremos que el auto no se vuelva loco con una bicicleta atornillada a la cajuela - más muestras. <br><br>  Además, un ejemplo no es suficiente.  Cientos?  Miles? <br><br><img src="https://habrastorage.org/webt/hl/tm/ip/hltmipml3fq_m-md4ansomrxjmk.jpeg"><br><br><h3>  Segundo problema </h3><br>  <b>El segundo problema</b> es la visualización de lo que ha entendido nuestra red neuronal.  Esta es una tarea muy no trivial.  Hasta ahora, pocas personas entienden cómo visualizar esto.  Estos artículos son muy recientes, estos son solo algunos ejemplos, incluso remotos: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Visualización de</a> fijación en texturas.  Muestra bien lo que la neurona tiende a ir en ciclos + lo que ella percibe como información inicial. <br><br><img src="https://habrastorage.org/webt/d7/wb/5f/d7wb5fbpcbugnrcma1qrnn9vyc0.png" alt="imagen"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Visualización de</a> atenuación durante las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">traducciones</a> .  Realmente, la atenuación a menudo se puede usar con precisión para mostrar qué causó tal reacción de red.  Conocí tales cosas para depurar y para soluciones de productos.  Hay muchos artículos sobre este tema.  Pero cuanto más complejos son los datos, más difícil es comprender cómo lograr una visualización sostenible. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/154/93f/988/15493f988978760639233843c9c28c91.png" alt="imagen"><br><br>  Bueno, sí, el viejo conjunto de "mira lo que hay dentro de la rejilla en los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">filtros</a> ".  Estas imágenes eran populares hace unos 3-4 años, pero todos se dieron cuenta rápidamente de que las imágenes son hermosas, pero no tienen mucho sentido. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f68/78c/a4a/f6878ca4a732ef4890e1ad9d8a369896.jpg" alt="imagen"><br><br>  No mencioné docenas de otras lociones, métodos, hacks, estudios sobre cómo mostrar el interior de la red.  ¿Estas herramientas funcionan?  ¿Te ayudan a entender rápidamente cuál es el problema y a depurar la red? ... ¿Sacar el último porcentaje?  Bueno, algo como esto: <br><br><img width="600" src="https://habrastorage.org/webt/eo/p0/i6/eop0i67mupthvfm86dwn139kkha.jpeg"><br><br>  Puedes ver cualquier concurso en Kaggle.  Y una descripción de cómo las personas toman las decisiones finales.  ¡Llegamos al modelo 100-500-800 mulenov y funcionó! <br><br>  Por supuesto, exagero.  Pero estos enfoques no dan respuestas rápidas y directas. <br><br>  Teniendo suficiente experiencia, después de haber elegido diferentes opciones, puede emitir un veredicto sobre por qué su sistema tomó tal decisión.  Pero corregir el comportamiento del sistema será difícil.  Coloque una muleta, mueva el umbral, agregue un conjunto de datos, tome otra red de fondo. <br><br><h3>  Tercer problema </h3><br>  <b>El tercer problema fundamental</b> es que las cuadrículas no enseñan lógica, sino estadística.  Estadísticamente esta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">persona</a> : <br><br><img src="https://habrastorage.org/webt/wa/lg/6h/walg6hlyvy_cvd7i6oojypaa0lc.png" alt="imagen"><br><br>  Lógicamente, no muy similar.  Las redes neuronales no aprenden algo complicado si no son forzadas.  Siempre aprenden los síntomas más simples.  Tiene ojos, nariz, cabeza?  Entonces esta cara!  O dé un ejemplo donde los ojos no signifiquen la cara.  Y de nuevo, millones de ejemplos. <br><br><h3>  Hay mucho espacio en la parte inferior </h3><br>  Diría que son estos tres problemas globales los que hoy limitan el desarrollo de las redes neuronales y el aprendizaje automático.  Y donde estos problemas no se limitaron ya se usa activamente. <br><br>  <b>¿Es este el final?</b>  <b>Las redes neuronales se levantaron?</b> <br><br>  Desconocido  Pero, por supuesto, todos esperan que no. <br><br>  Hay muchos enfoques y direcciones para resolver los problemas fundamentales que he cubierto anteriormente.  Pero hasta ahora, ninguno de estos enfoques nos ha permitido hacer algo fundamentalmente nuevo, resolver algo que aún no se ha resuelto.  Hasta ahora, todos los proyectos fundamentales se realizan sobre la base de enfoques estables (Tesla), o siguen siendo proyectos de prueba de institutos o corporaciones (Google Brain, OpenAI). <br><br>  En términos generales, la dirección principal es la creación de una representación de alto nivel de los datos de entrada.  En cierto sentido, "memoria".  El ejemplo más simple de memoria son las diversas representaciones de "incrustación" de imágenes.  Bueno, por ejemplo, todos los sistemas de reconocimiento facial.  La red aprende a obtener de la cara una cierta idea estable que no depende de la rotación, la iluminación y la resolución.  De hecho, la red minimiza la métrica de "caras diferentes - lejos" e "idéntico - cerca". <br><br><img src="https://habrastorage.org/webt/8z/re/sp/8zrespvq6y2unwlyuaeovq3fj58.png"><br><br>  Tal entrenamiento requiere decenas y cientos de miles de ejemplos.  Pero el resultado trae algunos rudimentos de "Aprendizaje único".  Ahora no necesitamos cientos de caras para recordar a una persona.  Solo una cara, y eso es todo, ¡lo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">descubriremos</a> ! <br>  Solo aquí está el problema ... La cuadrícula solo puede aprender objetos bastante simples.  Cuando se trata de distinguir no caras, sino, por ejemplo, "personas vestidas" (la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tarea de redentificación</a> ), la calidad falla en muchos órdenes de magnitud.  Y la red ya no puede aprender suficientes cambios de ángulo obvios. <br><br>  Y aprender de millones de ejemplos también es de alguna manera un entretenimiento regular. <br><br>  Hay trabajo para reducir significativamente las elecciones.  Por ejemplo, puede recuperar de inmediato uno de los primeros <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajos de Google OneShot</a> <b>Learning</b> : <br><br><img src="https://habrastorage.org/webt/dv/h5/zt/dvh5zte1ggsunwya3tm40zqwiec.png"><br><br>  Hay muchos de estos trabajos, por ejemplo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> . <br><br>  Hay una desventaja: por lo general, el entrenamiento funciona bien en algunos "ejemplos MNIST'ovskie" simples.  Y en la transición a tareas complejas, necesita una base grande, un modelo de objetos o algún tipo de magia. <br>  En general, el trabajo en el entrenamiento One-Shot es un tema muy interesante.  Encuentras muchas ideas.  Pero en su mayor parte, los dos problemas que he enumerado (capacitación previa en un gran conjunto de datos / inestabilidad en datos complejos) están obstaculizando el aprendizaje. <br><br>  Por otro lado, GAN - redes generativamente competitivas - se acerca a la integración.  Probablemente leyó un montón de artículos sobre este tema en Habré.  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> ) <br>  Una característica de la GAN es la formación de un espacio de estado interno (esencialmente la misma incrustación), que le permite dibujar una imagen.  Pueden ser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">personas</a> , puede haber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">acciones</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e25/77f/f6d/e2577ff6d435046c44f861ab5d3ce2b3.jpg" alt="imagen"><br><br>  El problema de GAN es que cuanto más complejo es el objeto generado, más difícil es describirlo en la lógica del "generador-discriminador".  Como resultado, a partir de aplicaciones reales de GAN, que solo se escuchan DeepFake, que, nuevamente, manipula las representaciones de los individuos (para lo cual existe una base enorme). <br><br>  He encontrado muy pocas otras aplicaciones útiles.  Por lo general, una especie de silbato falso con dibujos. <br><br>  Y de nuevo.  Nadie comprende cómo esto nos permitirá avanzar hacia un futuro más brillante.  Representar la lógica / espacio en una red neuronal es bueno.  Pero necesitamos una gran cantidad de ejemplos, no entendemos cómo esta neurona se representa a sí misma, no entendemos cómo hacer que la neurona recuerde alguna idea realmente complicada. <br><br>  <b>El aprendizaje por refuerzo</b> es un enfoque completamente diferente.  Seguramente recuerdas cómo Google venció a todos en Go.  Victorias recientes en Starcraft y Dota.  Pero aquí todo está lejos de ser tan optimista y prometedor.  Lo mejor de RL y su complejidad es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este artículo</a> . <br><br>  Para resumir brevemente lo que escribió el autor: <br><br><ul><li>  Los modelos listos para usar no se ajustan / funcionan mal en la mayoría de los casos </li><li>  Las tareas prácticas son más fáciles de resolver de otras maneras.  Boston Dynamics no usa RL debido a su complejidad / imprevisibilidad / complejidad computacional </li><li>  Para que RL funcione, necesita una función compleja.  A menudo es difícil crear / escribir. </li><li>  Es difícil entrenar modelos.  Tenemos que pasar mucho tiempo para balancearnos y salir de optima local </li><li>  Como resultado, es difícil repetir el modelo, la inestabilidad del modelo al más mínimo cambio. </li><li>  A menudo se sobrellena en algunos patrones izquierdos, hasta el generador de números aleatorios </li></ul><br>  El punto clave es que RL aún no funciona en producción.  Google tiene algún tipo de experimentos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ).  Pero no he visto un solo sistema de abarrotes. <br><br>  <b>Memoria</b>  La desventaja de todo lo que se describe arriba no está estructurada.  Un enfoque para tratar de ordenar todo esto es proporcionar a la red neuronal acceso a una memoria separada.  Para que pueda grabar y reescribir los resultados de sus pasos allí.  Entonces la red neuronal se puede determinar por el estado actual de la memoria.  Esto es muy similar a los procesadores y computadoras clásicos. <br><br>  El artículo más famoso y popular es de DeepMind: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b66/f0d/3a9/b66f0d3a9da550ad89e677eb4453a6bf.png" alt="imagen"><br><br>  Parece que aquí está, ¿la clave para entender la inteligencia?  Pero más bien, no.  El sistema todavía necesita una gran cantidad de datos para la capacitación.  Y funciona principalmente con datos tabulares estructurados.  Al mismo tiempo, cuando Facebook <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">resolvió un</a> problema similar, siguieron el camino "ven la memoria, solo hacen que la neurona sea más complicada, pero más ejemplos, y se aprenderá por sí misma". <br><br>  <b>Desenredamiento</b> .  Otra forma de crear una memoria significativa es tomar las mismas incrustaciones, pero al aprender a introducir criterios adicionales que les permitan resaltar "significados" en ellos.  Por ejemplo, queremos entrenar una red neuronal para distinguir entre el comportamiento de una persona en una tienda.  Si siguiéramos el camino estándar, tendríamos que hacer una docena de redes.  Uno está buscando a una persona, el segundo determina lo que está haciendo, el tercero es su edad, el cuarto es el género.  La lógica separada mira la parte de la tienda donde la hace / aprende.  El tercero determina su trayectoria, etc. <br><br>  O, si hubiera una cantidad infinita de datos, entonces sería posible entrenar una red para todo tipo de resultados (es obvio que tal conjunto de datos no se puede escribir). <br><br>  El enfoque de desinserción nos dice, y capacitemos a la red para que pueda distinguir entre conceptos.  Para que ella pueda integrarse en el video, donde un área determinaría la acción, una, la posición en el piso a tiempo, una, la altura de la persona y otra, su género.  Al mismo tiempo, durante el entrenamiento, me gustaría sugerir casi nunca tales conceptos clave a la red, sino para que identifique y agrupe las áreas.  Hay pocos artículos de este tipo (algunos de ellos son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> ) y en general son bastante teóricos. <br><br>  Pero esta dirección, al menos teóricamente, debería cubrir los problemas enumerados al principio. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/314/bd2/7ab/314bd27abc46e22c8c64430c6b6b9211.gif" alt="imagen"><br><br>  Descomposición de la imagen según los parámetros "color de pared / color de piso / forma de objeto / color de objeto / etc." <br><br><img src="https://habrastorage.org/webt/km/md/fb/kmmdfbtnliixqj3d5szfofcqe7q.jpeg"><br><br>  Descomposición de la cara según los parámetros "tamaño, cejas, orientación, color de piel, etc." <br><br><h3>  Otros </h3><br>  Hay muchas otras direcciones no tan globales que nos permiten reducir de alguna manera la base, trabajar con datos más heterogéneos, etc. <br><br>  <b>Atencion</b>  Probablemente no tenga sentido aislar esto como un método separado.  Solo un enfoque que refuerza a los demás.  Se le han dedicado muchos artículos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> ).  El significado de Atención es fortalecer la respuesta de la red a objetos importantes durante el entrenamiento.  A menudo por alguna designación de destino externo, o una pequeña red externa. <br><br>  <b>Simulación 3D</b>  Si haces un buen motor 3D, a menudo puedes cerrar el 90% de los datos de entrenamiento con él (incluso vi un ejemplo en el que casi el 99% de los datos se cerró con un buen motor).  Hay muchas ideas y trucos sobre cómo hacer que una red entrenada en un motor 3D funcione con datos reales (ajuste fino, transferencia de estilo, etc.).  Pero a menudo, hacer un buen motor es varios órdenes de magnitud más difícil que recopilar datos.  Ejemplos al hacer motores: <br>  Entrenamiento de robots ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">google</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">braingarden</a> ) <br>  Aprendiendo a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">reconocer los</a> productos en una tienda (pero en dos proyectos que hicimos, lo dispensamos con calma). <br>  Entrenamiento en Tesla (nuevamente, el video que estaba arriba). <br><br><h2>  Conclusiones </h2><br>  Todo el artículo es, en cierto sentido, conclusiones.  Probablemente el mensaje principal que quería hacer era "se acabó el obsequio, las neuronas no dan soluciones más simples".  Ahora tenemos que trabajar duro para construir soluciones complejas.  O trabajar duro haciendo informes científicos complejos. <br><br>  En general, el tema es discutible.  ¿Quizás los lectores tienen ejemplos más interesantes? </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/455676/">https://habr.com/ru/post/455676/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../455658/index.html">El legendario Intel Core i7-2600K: prueba de Sandy Bridge en 2019 (parte 3)</a></li>
<li><a href="../455662/index.html">Gran pantalla mecánica con mecanismo de leva como decodificador.</a></li>
<li><a href="../455666/index.html">Creación de ventas salientes en una empresa de servicios de TI</a></li>
<li><a href="../455668/index.html">Escribimos bajo FPGA sin HDL. Comparación de herramientas de desarrollo de alto nivel.</a></li>
<li><a href="../455670/index.html">Cómo las impresoras 3D imprimen huesos, vasos sanguíneos y órganos</a></li>
<li><a href="../455678/index.html">En el camino de Sergey Pavlovich Korolev. Proyecto tripulado ruso moderno. Parte 1. "Federación"</a></li>
<li><a href="../455682/index.html">¿Cuánto gastas en infraestructura? ¿Y cómo ahorrar en esto?</a></li>
<li><a href="../455684/index.html">¿Por qué realizamos un hackathon para probadores?</a></li>
<li><a href="../455686/index.html">¿Cómo elegir la mejor herramienta de gestión de proyectos si eres un milenio?</a></li>
<li><a href="../455692/index.html">ASZP: el restyling o el teatro comienzan con una percha</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
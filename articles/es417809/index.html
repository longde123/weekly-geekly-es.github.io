<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåó üéüÔ∏è üë©üèª‚Äçü§ù‚Äçüë®üèΩ AI, curso pr√°ctico. Arquitecturas modernas de redes neuronales profundas para la clasificaci√≥n de im√°genes üíü üêê üë®üèø‚Äçüè´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En un art√≠culo anterior, Descripci√≥n general de las redes neuronales para la clasificaci√≥n de im√°genes , nos familiarizamos con los conceptos b√°sicos ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso pr√°ctico. Arquitecturas modernas de redes neuronales profundas para la clasificaci√≥n de im√°genes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/417809/"><img src="https://habrastorage.org/webt/sz/-n/ep/sz-neph-gqvvjim1l0dreihnxlu.png"><br><br>  En un art√≠culo anterior, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Descripci√≥n general de las redes neuronales para la clasificaci√≥n de im√°genes</a> , nos familiarizamos con los conceptos b√°sicos de las redes neuronales convolucionales, as√≠ como las ideas subyacentes.  En este art√≠culo, analizaremos algunas arquitecturas de redes neuronales profundas con gran potencia de procesamiento, como AlexNet, ZFNet, VGG, GoogLeNet y ResNet, y resumiremos las principales ventajas de cada una de estas arquitecturas.  La estructura del art√≠culo se basa en una entrada de blog <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conceptos b√°sicos de redes neuronales convolucionales, parte 3</a> . <br><a name="habracut"></a><br>  Actualmente, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ImageNet</a> Challenge es el principal incentivo subyacente al desarrollo de sistemas de reconocimiento de m√°quinas y clasificaci√≥n de im√°genes.  La campa√±a es una competencia para trabajar con datos, en la que los participantes reciben un gran conjunto de datos (m√°s de un mill√≥n de im√°genes).  La tarea de la competencia es desarrollar un algoritmo que le permita clasificar las im√°genes requeridas en objetos en 1000 categor√≠as, como perros, gatos, autom√≥viles y otros, con un n√∫mero m√≠nimo de errores. <br><br>  De acuerdo con las reglas oficiales del concurso, los algoritmos deben proporcionar una lista de no m√°s de cinco categor√≠as de objetos en orden descendente de confianza para cada categor√≠a de im√°genes.  La calidad de marcado de la imagen se eval√∫a en funci√≥n de la etiqueta que mejor coincida con la propiedad de verdad de la imagen.  La idea es permitir que el algoritmo identifique varios objetos en la imagen y no acumule puntos de penalizaci√≥n en el caso de que alguno de los objetos detectados estuviera realmente presente en la imagen pero no se incluyera en la propiedad de verdad fundamental. <br><br>  En el primer a√±o de la competencia, los participantes recibieron atributos de imagen preseleccionados para entrenar el modelo.  Estos podr√≠an ser, por ejemplo, signos del algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SIFT</a> procesados ‚Äã‚Äãusando la cuantificaci√≥n vectorial y adecuados para su uso en el m√©todo de bolsa de palabras o para su presentaci√≥n como una pir√°mide espacial.  Sin embargo, en 2012 hubo un verdadero avance en esta √°rea: un grupo de cient√≠ficos de la Universidad de Toronto demostr√≥ que una red neuronal profunda puede lograr resultados significativamente m√°s altos en comparaci√≥n con los modelos tradicionales de aprendizaje autom√°tico construidos sobre la base de vectores de propiedades de imagen previamente seleccionadas.  En las siguientes secciones, se considerar√° la primera arquitectura innovadora propuesta en 2012, as√≠ como las arquitecturas que son sus seguidores hasta 2015. <br><br><img src="https://habrastorage.org/webt/b1/yc/0j/b1yc0jlxh6r5g9xmpvsfocbxmxo.png"><br>  <i>Diagrama de cambios en el n√∫mero de errores (en porcentaje) en la clasificaci√≥n de im√°genes ImageNet * para las cinco categor√≠as principales.</i>  <i>Imagen tomada de la presentaci√≥n de Kaiming He, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aprendizaje residual profundo para el reconocimiento de im√°genes</a></i> <br><br><h3>  <font color="#0071c5">Alexnet</font> </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La</a> arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AlexNet</a> fue propuesta en 2012 por un grupo de cient√≠ficos (A. Krizhevsky, I. Sutskever y J. Hinton) de la Universidad de Toronto.  Este fue un trabajo innovador en el que los autores utilizaron por primera vez (en ese momento) redes neuronales convolucionales profundas con una profundidad total de ocho capas (cinco capas convolucionales y tres completamente conectadas). <br><br><img src="https://habrastorage.org/webt/fm/wq/lm/fmwqlmznjszot3yzk1zfejfab6w.png"><br>  <i>Arquitectura AlexNet</i> <br><br>  La arquitectura de red consta de las siguientes capas: <br><br><ul><li>  [Capa de convoluci√≥n + selecci√≥n de valor m√°ximo + normalizaci√≥n] x 2 </li><li>  [Capa de convoluci√≥n] x 3 </li><li>  [Elegir el valor m√°ximo] </li><li>  [Capa completa] x 3 </li></ul><br>  Tal esquema puede parecer un poco extra√±o, porque el proceso de aprendizaje se dividi√≥ entre las dos GPU debido a su alta complejidad computacional.  Esta separaci√≥n de trabajo entre las GPU requiere la separaci√≥n manual del modelo en bloques verticales que interact√∫an entre s√≠. <br><br>  La arquitectura de AlexNet ha reducido el n√∫mero de errores para las cinco categor√≠as principales a 16.4 por ciento, ¬°casi la mitad en comparaci√≥n con desarrollos avanzados anteriores!  Tambi√©n en el marco de esta arquitectura se introdujo una funci√≥n de activaci√≥n como una unidad de rectificaci√≥n lineal ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ReLU</a> ), que actualmente es el est√°ndar de la industria.  El siguiente es un breve resumen de otras caracter√≠sticas clave de la arquitectura AlexNet y su proceso de aprendizaje: <br><br><ul><li>  Aumento intensivo de datos </li><li>  M√©todo de exclusi√≥n </li><li>  Optimizaci√≥n mediante momento SGD (consulte la gu√≠a de optimizaci√≥n "Descripci√≥n general de los algoritmos de optimizaci√≥n de descenso de gradiente") </li><li>  Ajuste manual de la velocidad de aprendizaje (reducci√≥n de este coeficiente en 10 con estabilizaci√≥n de precisi√≥n) </li><li>  El modelo final es una colecci√≥n de siete redes neuronales convolucionales. </li><li>  La capacitaci√≥n se realiz√≥ en dos procesadores gr√°ficos NVIDIA * GeForce GTX * 580 con un total de 3 GB de memoria de video en cada uno de ellos. </li></ul><br><h3>  <font color="#0071c5">Zfnet</font> </h3><br>  La arquitectura de red <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ZFNet</a> propuesta por los investigadores M. Zeiler y R. Fergus de la Universidad de Nueva York es casi id√©ntica a la arquitectura AlexNet.  Las √∫nicas diferencias significativas entre ellos son las siguientes: <br><br><ul><li>  Tama√±o del filtro y paso en la primera capa convolucional (en AlexNet, el tama√±o del filtro es 11 √ó 11, y el paso es 4; en ZFNet - 7 √ó 7 y 2, respectivamente) </li><li>  El n√∫mero de filtros en capas convolucionales limpias (3, 4, 5). </li></ul><br><img src="https://habrastorage.org/webt/gj/ji/wz/gjjiwzynwfzcnsrw3_vzgilojoo.png"><br>  <i>Arquitectura ZFNet</i> <br><br>  Gracias a la arquitectura ZFNet, el n√∫mero de errores para las cinco categor√≠as principales cay√≥ al 11.4 por ciento.  Quiz√°s el papel principal en esto es jugado por el ajuste preciso de los hiperpar√°metros (tama√±o y n√∫mero de filtros, tama√±o del paquete, velocidad de aprendizaje, etc.).  Sin embargo, tambi√©n es probable que las ideas de la arquitectura ZFNet se hayan convertido en una contribuci√≥n muy significativa al desarrollo de redes neuronales convolucionales.  Ziller y Fergus propusieron un sistema para visualizar n√∫cleos, pesos y una vista oculta de im√°genes llamada DeconvNet.  Gracias a ella, se hizo posible una mejor comprensi√≥n y un mayor desarrollo de las redes neuronales convolucionales. <br><br><h3>  <font color="#0071c5">VGG Net</font> </h3><br>  En 2014, K. Simonyan y E. Zisserman de la Universidad de Oxford propusieron una arquitectura llamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VGG</a> .  La idea principal y distintiva de esta estructura es <i>mantener los filtros lo m√°s simples posible</i> .  Por lo tanto, todas las operaciones de convoluci√≥n se realizan con un filtro de tama√±o 3 y un paso de tama√±o 1, y todas las operaciones de submuestreo se realizan con un filtro de tama√±o 2 y un paso de tama√±o 2. Sin embargo, esto no es todo.  Junto con la simplicidad de los m√≥dulos convolucionales, la red ha crecido significativamente en profundidad, ¬°ahora tiene 19 capas!  La idea m√°s importante, propuesta por primera vez en este trabajo, es <i>imponer capas convolucionales sin capas de submuestreo</i> .  La idea subyacente es que dicha superposici√≥n a√∫n proporciona un campo receptivo suficientemente grande (por ejemplo, tres capas convolucionales superpuestas de tama√±o 3 √ó 3 en pasos de 1 tienen un campo receptivo similar a una capa convolucional de tama√±o 7 √ó 7), sin embargo, el n√∫mero de par√°metros es significativamente menor que en redes con filtros grandes (sirve como regularizador).  Adem√°s, es posible introducir transformaciones no lineales adicionales. <br><br>  Esencialmente, los autores han demostrado que incluso con bloques de construcci√≥n muy simples, puede lograr resultados de calidad superior en el concurso ImageNet.  El n√∫mero de errores para las cinco categor√≠as principales se redujo a 7.3 por ciento. <br><br><img src="https://habrastorage.org/webt/x7/rk/yj/x7rkyjkvxchmnso5gd56gf83eec.png"><br>  <i>Arquitectura VGG.</i>  <i>Tenga en cuenta que el n√∫mero de filtros es inversamente proporcional al tama√±o espacial de la imagen.</i> <br><br><h3>  <font color="#0071c5">GoogleNet</font> </h3><br>  Anteriormente, todo el desarrollo de la arquitectura consist√≠a en simplificar los filtros y aumentar la profundidad de la red.  En 2014, C. Szegedy, junto con otros participantes, propuso un enfoque completamente diferente y cre√≥ la arquitectura m√°s compleja en ese momento, llamada GoogLeNet. <br><br><img src="https://habrastorage.org/webt/dl/rg/c7/dlrgc7gmujh1atkvisnx5onluim.png"><br>  <i>Arquitectura GoogLeNet.</i>  <i>Utiliza el m√≥dulo Inception, resaltado en verde en la figura;</i>  <i>la construcci√≥n de redes se basa en estos m√≥dulos</i> <br><br>  Uno de los principales logros de este trabajo es el denominado m√≥dulo Inception, que se muestra en la figura a continuaci√≥n.  Las redes de otras arquitecturas procesan los datos de entrada secuencialmente, capa por capa, mientras usan el m√≥dulo Inception, <i>los datos de entrada se procesan en paralelo</i> .  Esto le permite acelerar la salida, as√≠ como minimizar el <i>n√∫mero total de par√°metros</i> . <br><br><img src="https://habrastorage.org/webt/uo/ny/0t/uony0thmws6rtd5jyloaqxs5swe.png"><br>  <i>M√≥dulo de inicio.</i>  <i>Tenga en cuenta que el m√≥dulo usa varias ramas paralelas, que calculan diferentes propiedades en funci√≥n de los mismos datos de entrada, y luego combinan los resultados</i> <br><br>  Otro truco interesante utilizado en el m√≥dulo Inception es usar capas convolucionales de tama√±o 1 √ó 1. Esto puede parecer in√∫til hasta que recordemos el hecho de que el filtro cubre toda la dimensi√≥n de profundidad.  Por lo tanto, una convoluci√≥n 1 √ó 1 es una forma simple de reducir la dimensi√≥n de un mapa de propiedades.  Este tipo de capas convolucionales fue introducido por primera vez en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">red por</a> M. Lin et al., Una explicaci√≥n comprensible y comprensible tambi√©n se puede encontrar en la publicaci√≥n del blog <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Convoluci√≥n [1 √ó 1] - utilidad contraria a la intuici√≥n</a> por A. Prakash. <br><br>  Finalmente, esta arquitectura redujo el n√∫mero de errores para las cinco categor√≠as principales en otro medio por ciento, a un valor de 6.7 por ciento. <br><br><h3>  <font color="#0071c5">Resnet</font> </h3><br>  En 2015, un grupo de investigadores (Cuming Hee y otros) de Microsoft Research Asia tuvo una idea que actualmente la mayor√≠a de la comunidad considera una de las etapas m√°s importantes en el desarrollo del aprendizaje profundo. <br><br>  Uno de los principales problemas de las redes neuronales profundas es el problema de un gradiente de fuga.  En pocas palabras, este es un problema t√©cnico que surge cuando se utiliza el m√©todo de propagaci√≥n de error de retroceso para el algoritmo de c√°lculo de gradiente.  Cuando se trabaja con propagaci√≥n hacia atr√°s de errores, se utiliza una regla de cadena.  Adem√°s, si el gradiente tiene un valor peque√±o al final de la red, entonces puede tomar un valor infinitamente peque√±o para cuando llegue al comienzo de la red.  Esto puede conducir a problemas de una naturaleza completamente diferente, incluida la imposibilidad de aprender la red en principio (para obtener m√°s informaci√≥n, consulte la entrada del blog de R. Kapur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El problema de un gradiente de desvanecimiento</a> ). <br><br>  Para resolver este problema, Caiming Hee y su grupo propusieron la siguiente idea: permitir que la red estudie el mapeo residual (un elemento que debe agregarse a la entrada) en lugar de la pantalla en s√≠.  T√©cnicamente, esto se hace utilizando la conexi√≥n de derivaci√≥n que se muestra en la figura. <br><br><img src="https://habrastorage.org/webt/0r/tc/qs/0rtcqsfuosnmqzprsvgdiho2i_o.png"><br>  <i>Diagrama esquem√°tico del bloque residual: los datos de entrada se transmiten a trav√©s de una conexi√≥n acortada sin pasar por las capas de conversi√≥n y se agregan al resultado.</i>  <i>Tenga en cuenta que una conexi√≥n "id√©ntica" no agrega par√°metros adicionales a la red, por lo tanto, su estructura no es complicada</i> <br><br>  Esta idea es extremadamente simple, pero al mismo tiempo extremadamente efectiva.  Resuelve el problema del gradiente que desaparece, permiti√©ndole moverse sin ning√∫n cambio desde las capas superiores a las inferiores a trav√©s de conexiones "id√©nticas".  Gracias a esta idea, puedes entrenar redes muy profundas y extremadamente profundas. <br><br>  La red que gan√≥ el ImageNet Challenge en 2015 conten√≠a 152 capas (los autores pudieron entrenar la red que conten√≠a 1001 capas, pero produjo aproximadamente el mismo resultado, por lo que dejaron de trabajar con ella).  Adem√°s, esta idea hizo posible reducir literalmente a la mitad la cantidad de errores para las cinco categor√≠as principales, a un valor de 3.6 por ciento.  Seg√∫n un estudio de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lo que aprend√≠ al competir con una red neuronal convolucional en el concurso ImageNet de</a> A. Karpathy, el rendimiento humano para esta tarea es aproximadamente del 5 por ciento.  Esto significa que la arquitectura ResNet es capaz de superar los resultados humanos, al menos en esta tarea de clasificaci√≥n de im√°genes. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417809/">https://habr.com/ru/post/es417809/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417791/index.html">C√≥mo fuimos a la Semana de Desarrolladores de Nueva York</a></li>
<li><a href="../es417795/index.html">Mi obsesi√≥n con los videojuegos en mi adolescencia no es un "trastorno del juego".</a></li>
<li><a href="../es417797/index.html">4 razones por las que los proyectos de la NASA est√°n incumpliendo los plazos e inflando el presupuesto</a></li>
<li><a href="../es417801/index.html">C√≥mo me mud√© a Israel despu√©s de bloquear Telegram</a></li>
<li><a href="../es417803/index.html">Procesamiento de fotos por lotes en Blender</a></li>
<li><a href="../es417813/index.html">Zabbix: monitoreo de vecinos de OSPF utilizando TRAMP SNMPv3, dolor y desesperaci√≥n</a></li>
<li><a href="../es417821/index.html">Network Digest: 20 materiales expertos sobre protocolos, est√°ndares y seguridad de la informaci√≥n</a></li>
<li><a href="../es417823/index.html">Nueva generaci√≥n: se lanza la primera red comercial 5G del mundo</a></li>
<li><a href="../es417825/index.html">"Extendiendo los l√≠mites": el rango de 6 GHz se dar√° a las necesidades de Wi-Fi</a></li>
<li><a href="../es417827/index.html">Wi-Fi gratuito: el tribunal alem√°n suprime las sanciones para las cafeter√≠as por violaciones de los derechos de autor de los clientes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
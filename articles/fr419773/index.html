<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéç üëÄ üë®üèø‚Äçü§ù‚Äçüë®üèæ De z√©ro √† h√©ros "Actions sur Google": commencer üë∂üèª üë©üèª‚Äç‚öïÔ∏è ‚Ü©Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hackathon Google, et tout ce dont vous avez besoin pour commencer √† d√©velopper vos applications pour un assistant. 


 Google a organis√© un hackathon ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>De z√©ro √† h√©ros "Actions sur Google": commencer</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redmadrobot/blog/419773/"><img src="https://habrastorage.org/webt/ek/p5/kq/ekp5kqbvvl0p4mdidicbmgfw5b0.png" alt="image"><br><p>  Hackathon Google, et tout ce dont vous avez besoin pour commencer √† d√©velopper vos applications pour un assistant. </p><br><p>  Google a organis√© un hackathon d√©di√© √† la technologie Actions On Google.  C'est une bonne occasion d'acqu√©rir de l'exp√©rience et de r√©fl√©chir √† la fa√ßon de commencer √† cr√©er une interface utilisateur de conversation (CUI) pour nos applications.  Par cons√©quent, nous avons r√©uni une √©quipe de deux d√©veloppeurs Android: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">shipa_o</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">raenardev</a> et designer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">camaradeguest,</a> et nous <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">sommes</a> all√©s participer. </p><a name="habracut"></a><br><h2>  Qu'est-ce que les actions sur Google? </h2><br><p>  Actions sur Google (AoG) est un moyen d'ajouter votre action √† l'assistant. <br>  Vous pouvez le faire en utilisant 4 outils: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Actions de contenu</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tranches</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Actions de l'application</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comp√©tence pour Google Assistant</a> . </li></ul><br><p>  Lors du hackathon, nous avons cr√©√© une comp√©tence - une application qui √©tend les capacit√©s d'un assistant, nous allons donc nous arr√™ter l√†. </p><br><p> Apr√®s l'appel, "Ok Google.  Je veux parler avec <code>${_}</code> ¬ª, l'assistant ouvre la comp√©tence avec laquelle l'utilisateur m√®ne un dialogue: </p><br><img src="https://habrastorage.org/webt/l2/vw/es/l2vwesoe1sywaswq0_8bmgjhhga.jpeg" alt="image" width="50%"><br><h3>  Comment √©crire une comp√©tence? <br></h3><br><p>  Vous aurez besoin de deux comp√©tences: <br>  - compr√©hension de l'interface utilisateur conversationnelle (CUI), la capacit√© de les concevoir; <br>  - Capacit√© √† travailler avec Natural Language Processing (NLP), par exemple, Dialogflow. </p><br><h4>  √âtape 1: Conception </h4><br><p>  Pour que votre comp√©tence ait un interlocuteur prot√©ique, il vaut mieux penser √† l'avenir maintenant.  La demande sera celle qui tiendra compte du contexte d'utilisation.  Les interfaces de dialogue seront utilis√©es lorsqu'il sera possible de parler √† haute voix et d'interagir avec des appareils avec la voix plus facilement et plus rapidement qu'avec les mains, les yeux et d'autres parties du corps. </p><br><p>  L'interface vocale est s√©rie.  S'il est possible de montrer la forme enti√®re de la commande sur un graphique et que la personne choisira elle-m√™me ce qu'il faut regarder en premier et ensuite quoi, alors vous ne pourrez poser des questions que l'une apr√®s l'autre √† voix haute.  Pour trouver une application populaire et pratique, trouvez l'intersection entre les besoins de l'utilisateur et la possibilit√© d'utiliser l'interface vocale (ou l'impossibilit√© d'utiliser les autres). </p><br><p>  La premi√®re chose qui me vient √† l'esprit est un assistant vocal pour les aveugles, qui aide √† r√©soudre les probl√®mes quotidiens.  Par exemple, passez une commande dans un magasin, appelez un taxi, appelez des proches.  Le second est un livre de recettes parlant pour les femmes au foyer avec les mains dans la farine.  Troisi√®mement, les jeux dans lesquels vous devez expliquer quelque chose. </p><br><p>  Nous avons d√©cid√© de commencer par un simple et avons d√©velopp√© un robot qui conseille les gens sur les bons films.  Nous avons battu l'imperfection des synth√©tiseurs vocaux: notre assistant ne pr√©tend m√™me pas √™tre un homme et met l'accent sur sa personnalit√© √©lectronique vivante dans tous les sens. </p><br><p>  Google a r√©dig√© d'excellentes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lignes directrices</a> sur la fa√ßon de d√©velopper des interfaces interactives.  Et nous parlerons de la fa√ßon dont nous avons con√ßu notre premier-n√© parlant. </p><br><p>  <b>1. Invocation</b> </p><br><p>  Tout d'abord, vous devez appeler un assistant.  L'appel peut √™tre explicite (invocation explicite) et indirect (invocation implicite).  Les gens utiliseront un traitement explicite lorsqu'ils connaissent d√©j√† l'application.  Indirectement, l'Assistant Google peut recommander une application appropri√©e dans une situation sp√©cifique.  Les options choisies correctement pour l'attrait indirect - comme les bons mots cl√©s dans la publicit√© contextuelle, ne sont que plus ¬´humaines¬ª. </p><br><div class="scrollable-table"><table><tbody><tr><td>  Type d'appel </td><td><p>  La description </p><br></td><td>  Exemple </td></tr><tr><td>  Invocation explicite </td><td>  Avec le nom de l'assistant </td><td><p><br>  Ok Google, je veux parler au robot Red Passionate Movie. <br>  Appelez-moi un robot de cin√©ma. <br>  O√π est rouge et passionn√© l√†-bas? </p><br></td></tr><tr><td><br>  Invocation implicite </td><td><br>  Dans le contexte o√π vous avez besoin d'un assistant </td><td><br>  Ok Google, conseille-moi un film. <br>  Je veux voir une dr√¥le de com√©die. <br>  Quel genre de film regarder avec une fille? </td></tr></tbody></table></div><br><p>  Il est important que les appels indirects ne soient pas trop g√©n√©raux.  Comme les mots-cl√©s g√©n√©raux dans la publicit√© contextuelle, ils ne vous emp√™chent que de trouver la bonne application et abaissent la note de l'application lors de l'√©mission de l'Assistant. </p><br><p>  Les appels peuvent contenir un lien profond vers les fonctionnalit√©s individuelles de l'assistant vocal.  Par exemple, g√©n√©ralement notre robot-film commence √† communiquer avec le fait qu'il propose √† une personne de choisir un genre.  Mais s'il est appel√© sur un appel indirect, "Je veux voir une com√©die dr√¥le", il est logique d'entamer un dialogue avec l'offre d'un bon film garanti du genre mentionn√©. </p><br><p>  <b>2. Premier message d'accueil</b> </p><br><p>  Le premier message d'accueil est ce que l'application indique √† la personne imm√©diatement apr√®s l'appel. <br>  Vous devez d'abord informer l'utilisateur que l'assistant est d√©j√† l√†: </p><br><blockquote>  Salut, une forme de vie prot√©ique.  Je suis un robot-cin√©aste passionn√© de Red.  Le but de mon existence est de conseiller les films biologiques sur les bons films. </blockquote><p>  Et puis - sugg√©rez quoi faire ensuite.  Notre robot recherche des films par genre, nous proposons donc √† quelle demande une personne peut aller plus loin: <br>  Que voulez-vous voir: peut-√™tre de la com√©die, de l'action ou de l'horreur? </p><br><p>  Les utilisateurs nouveaux et exp√©riment√©s peuvent √™tre accueillis de plusieurs fa√ßons.  Si une personne parle avec votre assistant pour la premi√®re fois, vous pouvez parler un peu de vous.  Si ce n'est pas le premier - une longue salutation l'ennuiera.  Par cons√©quent, vous pouvez imm√©diatement passer aux choses s√©rieuses: </p><br><div class="scrollable-table"><table><tbody><tr><td>  Premi√®re fois </td><td><p>  √Ä plusieurs reprises </p><br></td></tr><tr><td>  Salut, une forme de vie prot√©ique.  Je suis un robot-cin√©aste passionn√© de Red.  Le but de mon existence est de conseiller les films biologiques sur les bons films.  Que voulez-vous voir: peut-√™tre de la com√©die, de l'action ou de l'horreur? </td><td><br>  Salutations, mec!  Quel genre vous int√©resse? </td></tr></tbody></table></div><br><p>  <b>3. Conversation humaine</b> </p><br><p>  Apprenez √† votre assistant √† comprendre la parole naturelle et √† poursuivre la conversation.  La fa√ßon la plus simple de le faire est de communiquer avec des personnes du public cible avant m√™me le d√©but du d√©veloppement.  De plus, il est souhaitable verbalement, et non par √©crit, car le discours familier √©crit est plus rare qu'oral.  Jouez le r√¥le du robot et demandez √† l'interlocuteur d'imaginer qu'il utilise votre future application.  Enregistrez toutes les bo√Ætes de dialogue sur l'enregistreur, puis d√©chiffrez.  Cela vous aidera √† concevoir un diagramme de conversation typique et √† trouver o√π les branches peuvent appara√Ætre. </p><br><h4>  √âtape 2: D√©veloppement </h4><br><p>  Il existe plusieurs fa√ßons de d√©velopper votre action pour un assistant: </p><br><ul><li>  Avec Dialogflow. </li><li>  Avec Actions sur le SDK Google. </li><li>  Le texte peut √™tre trait√© ind√©pendamment - par exemple, si vous avez votre propre solution pour le traitement du langage naturel (NLP - Natural Language Processing). </li></ul><br><p>  Ce qui suit est l'interaction d'un assistant avec votre comp√©tence. <br>  La bo√Æte de dialogue ressemble √† ceci: </p><br><ol><li><p>  L'assistant traduit le discours en texte et l'envoie √† votre action. </p><br></li><li><p>  Le texte est trait√© de l'une des mani√®res ci-dessus.  Dans ce diagramme, via Dialogflow. </p><br></li><li><p>  Dialogflow d√©finit l'intention (l'intention sp√©cifique de l'utilisateur) et re√ßoit <br>  √† partir de lui des entit√©s (param√®tres). </p><br></li><li><p>  (Facultatif) Dialogflow peut appeler le webhook correspondant, traiter les donn√©es sur le backend et obtenir une r√©ponse. </p><br></li><li><p>  Dialogflow constitue la r√©ponse. </p><br></li><li><p>  L'assistant exprime la r√©ponse, allume le microphone et √©coute ce que l'utilisateur dira. </p><br></li></ol><br><img src="https://habrastorage.org/webt/ib/us/uf/ibusuffx_dlpg1eewj7ev4xcpzc.png" alt="image"><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Diagramme d'action de l'assistant</a> </p><br><h4>  Dialogflow </h4><br><p>  Nous ne d√©taillerons pas les bases de Dialogflow - Google a publi√© de bonnes vid√©os de tutoriel. </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Intentions</a> - sur la reconnaissance de l'intention, comment Dialogflow comprend exactement ce que l'utilisateur demande ou quelle action il veut effectuer. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Entit√©s</a> - sur la reconnaissance des param√®tres √† l'int√©rieur d'une phrase.  Par exemple, dans le cas de la recommandation de films, il s'agit d'un genre sp√©cifique. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dialog Control</a> - sur le m√©canisme de contexte (√† ce sujet ci-dessous) et la satisfaction: sur la fa√ßon de traiter la demande de l'utilisateur lui-m√™me en acc√©dant √† votre backend, et comment renvoyer quelque chose de plus int√©ressant qu'une r√©ponse textuelle. </li></ol><br><p>  Nous supposons que vous avez d√©j√† regard√© la vid√©o et compris la console Dialogflow.  Examinons les probl√®mes qui se sont pos√©s dans chacune des parties du processus de mise en ≈ìuvre, et ce qui est int√©ressant peut √™tre not√©. </p><br><p>  Rappelez-vous √©galement les r√®gles pour construire un bon dialogue lorsque vous passez √† la mise en ≈ìuvre - cela affectera le groupe d'intentions, l'ensemble d'entit√©s et leur utilisation dans les r√©ponses, l'utilisation des contextes et tout le reste. </p><br><h4>  Intentions </h4><br><p>  Il y a des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">recommandations</a> - pour faire un message d'accueil plus d√©taill√© pour le nouvel utilisateur, et pour le reste pour le rendre plus concis.  Comment mettre cela en ≈ìuvre? </p><br><p>  Dans la console Dialogflow, cette logique ne peut pas √™tre d√©termin√©e.  Cela peut √™tre fait dans l'accomplissement d'une intention bienvenue.  En d'autres termes, vous devrez le faire avec vos mains. </p><br><p>  Cela s'applique √©galement √† la gestion des erreurs.  Par exemple, pour la premi√®re fois, vous pouvez simplement demander √† nouveau, et la deuxi√®me fois, vous pouvez dire quel type de r√©ponse vous attendez de l'utilisateur. </p><br><p>  Vous ne le ferez pas par le biais des r√©ponses - une r√©ponse al√©atoire sera s√©lectionn√©e.  Vous pouvez le faire par l'accomplissement ou un peu plus compliqu√© en le liant au contexte (plus de d√©tails ci-dessous). </p><br><h4>  Entit√©s </h4><br><p>  <b>"Autoriser l'expansion automatis√©e" et sys.Any</b> </p><br><p>  Si la phrase est de structure similaire, lorsque "Autoriser l'expansion automatis√©e" est activ√© en tant qu'entit√© reconnue, quelque chose peut y entrer qui ne peut toujours pas √™tre trait√© avec profit. </p><br><p>  Par exemple, votre application reconna√Æt la phrase "Sugg√©rez-moi quelque chose de &lt;genre&gt;" pour obtenir des conseils sur les films.  Si vous dites ¬´Conseillez-moi quelque chose de la nourriture¬ª, alors en tant que param√®tre ¬´genre¬ª, vous n'obtiendrez pas ce que vous attendez.  Cela a du sens si l'ensemble des genres vous est constamment mis √† jour dynamiquement sur le backend, et que la r√©ponse de l'utilisateur y est trait√©e, mais vous n'avez pas le temps de mettre √† jour l'entit√©. </p><br><p>  Une autre solution consiste √† utiliser sys.Any.  Dans ce cas, il transmettra tout ce qui √©tait apr√®s la conception attendue, ce qui peut √™tre l'ensemble de la proposition.  Cela donne plus d'opportunit√©s que l'expansion automatis√©e, mais il y a aussi plus d'inconv√©nients. </p><br><p>  <b>Singulier et pluriel, cas, sexe</b> </p><br><p>  Voyons un exemple simple.  Nous parlerons de vos fruits pr√©f√©r√©s et l'application r√©pondra √† quel point ils sont cool.  Dans les exemples ci-dessous, P est l'utilisateur, A est notre action. </p><br><blockquote>  P: Les ananas sont les plus savoureux. <br>  R: Oui, les ananas sont les fruits les plus cool! <br></blockquote><p>  Dans cet exemple, nous avons l'entit√©: Ananas <br>  Mais que se passe-t-il si l'utilisateur dit "Ananas"?  Nous pouvons ajouter un synonyme. </p><br><blockquote>  P: J'ai aim√© l'ananas. <br>  R: Oui, les ananas sont les fruits les plus cool! </blockquote><p>  La valeur par d√©faut est le formulaire de r√©f√©rence - c'est-√†-dire  c'est la forme originale, pas ses synonymes.  C'est pourquoi l'application ne dit pas "Oui, l'ananas est le fruit le plus cool!" </p><br><p>  Il convient √©galement d'en tenir compte lors de la r√©daction des r√©ponses.  Si nous avions la r√©ponse ¬´Oui, $ fruit est le plus cool!¬ª, Alors nous obtiendrions ce qui suit: </p><br><blockquote>  P: J'ai aim√© l'ananas. <br>  R: Oui, les ananas sont les plus cool! </blockquote><p>  Et n'oubliez pas les cas: </p><br><blockquote>  P: Je veux du drame <br>  R: Voici un drame cool ... <br></blockquote><p>  Par cons√©quent, vous devez √©crire √† la fois les valeurs initiales de l'entit√© et les r√©ponses sous une forme coh√©rente.  Par exemple, nous pouvons faire toutes les formes d'entit√© originales pour les fruits au pluriel et les synonymes dans n'importe quel. </p><br><p>  Nous ferons des genres en russe dans le cas nominatif, mais en nombre (drames, horreurs). </p><br><p>  Quand nous arriverons aux r√©ponses, nous n'√©crirons pas "Oui, $ fruit est le fruit le plus cool!"  et "Oui, $ fruit est le plus cool!"  - les fruits sont toujours au pluriel. </p><br><p>  Dans le cas de la langue russe, il vaut la peine d'aller encore plus loin et de r√©fl√©chir √† la mani√®re de r√©diger une r√©ponse convenue - nous avons non seulement des cas (drame / drame), mais aussi le genre (drame / western). </p><br><blockquote>  P: Je veux un western <br>  R: Voici un western cool ... <br></blockquote><br><blockquote>  P: Je veux un western <br>  A: Western?  Ok, voici un film sympa ... </blockquote><p>  Mais comment retourner exactement le formulaire d'entit√© que l'utilisateur a dit? </p><br><p>  Dans le cas des genres, le synonyme de ¬´science-fiction¬ª pourrait √™tre ¬´extraterrestres¬ª.  Ensuite, si l'utilisateur disait ¬´extraterrestres¬ª, la ¬´science-fiction¬ª reviendrait comme param√®tre. <br>  Si nous voulons obtenir l'entit√© sous la forme dans laquelle l'utilisateur l'a dit, alors il vaut la peine de choisir la valeur de $ entity.original </p><br><img src="https://habrastorage.org/webt/vf/eq/9f/vfeq9fm3m3dbgzmmyik5qxvvd0q.png" alt="image"><br><p>  Mais alors il peut y avoir des probl√®mes avec l'incoh√©rence du nombre et (surtout) l'incoh√©rence des cas.  Est-ce vraiment n√©cessaire?  Si tel est le cas, cr√©ez une entit√© pour le singulier, le pluriel et la casse.  Les r√©ponses doivent √©galement √™tre coh√©rentes avec le formulaire d'entit√© qu'elles utilisent. </p><br><h4>  Contextes </h4><br><p>  Peut-√™tre avec cela le plus de probl√®mes. </p><br><p>  <b>Contexte d'entr√©e</b> </p><br><p>  C'est le contexte auquel une intention particuli√®re est li√©e.  Plusieurs intentions peuvent r√©pondre √† la m√™me phrase, et celle avec le contexte d'entr√©e actif fonctionnera tr√®s probablement. <br>  Ainsi, par exemple, vous pouvez joindre une r√©ponse oui / non √† une question sp√©cifique, ce qui se fait en utilisant l'intention de suivi dans Dialogflow </p><br><p>  <b>Contexte de sortie</b> </p><br><p>  C'est le contexte qui est activ√© lorsque l'intention est d√©clench√©e.  C'est ainsi que les contextes sont activ√©s dans la console Dialogflow (cela peut √©galement √™tre fait en cours d'ex√©cution).  Nous indiquons le nombre de tours du dialogue pendant lequel il sera actif, et apr√®s la remise √† z√©ro du compteur ou apr√®s 20 minutes il est d√©sactiv√©.  Cela signifie que les donn√©es dans ce contexte ne seront plus disponibles et les intentions pour lesquelles elles sont entr√©es ne fonctionneront pas. </p><br><p>  Une autre astuce est li√©e au m√™me: vous pouvez activer un contexte avec une intention et le d√©sactiver manuellement avec une autre, en le pla√ßant simplement comme contexte de sortie pour la deuxi√®me intention avec le nombre de r√©ponses 0. </p><br><p>  Si vous ne voulez pas √©crire de code en ex√©cution, vous pouvez ainsi impl√©menter une logique int√©ressante, par exemple, en utilisant le contexte comme compteur, impl√©menter la gestion des erreurs lorsque l'assistant ne comprend pas l'utilisateur. </p><br><h4>  Conseils de dialogue </h4><br><ul><li><p>  Il n'est pas n√©cessaire de red√©marrer la page avec l'aper√ßu de l'assistant - lorsque vous avez apport√© des modifications √† l'agent dialogflow, vous pouvez attendre la fin de sa formation et r√©p√©ter imm√©diatement la phrase non reconnue dans le simulateur.  Dialogflow peut √™tre consid√©r√© comme un backend auquel se r√©f√®re un assistant. </p><br></li><li><p>  Utilisez des agents pr√©d√©finis - vous pouvez voir ici comment impl√©menter un sc√©nario typique. </p><br></li><li><p>  Soyez prudent avec la section Small talk.  Son utilisation ne d√©sactive pas le microphone √† la fin de la conversation, et ces r√©ponses ne contiennent g√©n√©ralement pas d'appel √† l'action.  Vous ne dirigez pas l'utilisateur vers le prochain cycle de dialogue, et il ne sait pas tout √† fait ce qu'il convient de dire plus loin.  Avec une forte probabilit√©, √† cause de cela, vous ne pouvez pas passer l'examen.  Il est pr√©f√©rable de cr√©er des intentions distinctes pour cela si vous pouvez les saisir dans la bo√Æte de dialogue. </p><br></li><li><p>  Ne modifiez pas la m√™me intention en m√™me temps.  Maintenant, le travail simultan√© de plusieurs personnes n'est pas pris en charge - on ne sait pas dont les modifications seront √©cras√©es. </p><br></li><li><p>  S'il est n√©cessaire de parall√©liser le travail avec intention, il peut √™tre effectu√© dans des projets s√©par√©s, puis il suffit de s√©lectionner ceux qui sont n√©cessaires et de les transf√©rer.  Importez et exportez √©galement des entit√©s dans json / xml et importez / exportez √† dessein. </p><br></li><li><p>  Imm√©diatement, il convient de consid√©rer que vous √©crivez une action pour une langue particuli√®re.  √âcrire des r√©ponses en russe a des nuances suppl√©mentaires.  La localisation de l'action semble donc plus difficile qu'avec l'interface graphique de l'application mobile. </p><br></li><li><p>  Tenez compte des r√®gles de conception des interfaces vocales - elles affectent non seulement l'ensemble des r√©pliques, mais √©galement la structure dans son ensemble.  Vous construisez un dialogue, donc chaque r√©ponse doit laisser un appel √† l'action pour que l'utilisateur comprenne quoi dire. </p><br></li><li><p>  Une fois que tout est pr√™t et que vous commencez √† tester, n'ayez pas peur d'abandonner des branches individuelles du dialogue ou des formulaires de questions.  Peut-√™tre qu'au stade des tests, vous comprendrez comment connecter les intentions et ce qui manque pour en faciliter l'utilisation. </p><br></li></ul><br><h4>  Connexion au serveur </h4><br><p>  Pour connecter le serveur, vous devez utiliser l'accomplissement.  Il y a deux options pour cela: </p><br><ul><li>  <strong>Client Webhook</strong> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Plusieurs</a> langues prises en charge. </li><li>  <strong>√âditeur en ligne</strong> sur les fonctions cloud pour Firebase (node.js). </li></ul><br><p>  Prenons le plus simple: l'√©diteur en ligne. </p><br><p>  Nous ne pr√©tendons pas √™tre un expert en node.js; corriger les erreurs dans les commentaires est le bienvenu. </p><br><p>  Il est important de faire attention √† la version de l'API Dialogflow. <br>  Derni√®re version v2.  Tout ce qui est √©crit pour la version v1 ne fonctionne pas avec. <br>  En savoir plus sur la migration <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </p><br><p>  Liens utiles: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Documentation et code source de la biblioth√®que pour travailler avec dialogflow-</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Premiers pas avec l'ex√©cution de Dialogflow</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Des exemples</a> </li><li>  Les journaux peuvent √™tre consult√©s ici: <a href="">Acc√©dez √† la console Firebase √† c√¥t√© du bouton D√©ployer</a> </li></ul><br><h4>  Analyser le mod√®le standard </h4><br><div class="spoiler">  <b class="spoiler_title">Lorsque vous ouvrez la section Ex√©cution, le code suivant s'affiche dans le fichier / onglet `index.js`:</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">'use strict'; const functions = require('firebase-functions'); const {WebhookClient} = require('dialogflow-fulfillment'); const {Card, Suggestion} = require('dialogflow-fulfillment'); process.env.DEBUG = 'dialogflow:debug'; // enables lib debugging statements exports.dialogflowFirebaseFulfillment = functions.https.onRequest((request, response) =&gt; { const agent = new WebhookClient({ request, response }); console.log('Dialogflow Request headers: ' + JSON.stringify(request.headers)); console.log('Dialogflow Request body: ' + JSON.stringify(request.body)); function welcome(agent) { agent.add(`Welcome to my agent!`); } function fallback(agent) { agent.add(`I didn't understand`); agent.add(`I'm sorry, can you try again?`); } // // Uncomment and edit to make your own intent handler // // uncomment `intentMap.set('your intent name here', yourFunctionHandler);` // // below to get this function to be run when a Dialogflow intent is matched // function yourFunctionHandler(agent) { // agent.add(`This message is from Dialogflow's Cloud Functions for Firebase editor!`); // agent.add(new Card({ // title: `Title: this is a card title`, // imageUrl: 'https://developers.google.com/actions/images/badges/XPM_BADGING_GoogleAssistant_VER.png', // text: `This is the body text of a card. You can even use line\n breaks and emoji! `, // buttonText: 'This is a button', // buttonUrl: 'https://assistant.google.com/' // }) // ); // agent.add(new Suggestion(`Quick Reply`)); // agent.add(new Suggestion(`Suggestion`)); // agent.setContext({ name: 'weather', lifespan: 2, parameters: { city: 'Rome' }}); // } // // Uncomment and edit to make your own Google Assistant intent handler // // uncomment `intentMap.set('your intent name here', googleAssistantHandler);` // // below to get this function to be run when a Dialogflow intent is matched // function googleAssistantHandler(agent) { // let conv = agent.conv(); // Get Actions on Google library conv instance // conv.ask('Hello from the Actions on Google client library!') // Use Actions on Google library // agent.add(conv); // Add Actions on Google library responses to your agent's response // } // // See https://github.com/dialogflow/dialogflow-fulfillment-nodejs/tree/master/samples/actions-on-google // // for a complete Dialogflow fulfillment library Actions on Google client library v2 integration sample // Run the proper function handler based on the matched Dialogflow intent name let intentMap = new Map(); intentMap.set('Default Welcome Intent', welcome); intentMap.set('Default Fallback Intent', fallback); // intentMap.set('your intent name here', yourFunctionHandler); // intentMap.set('your intent name here', googleAssistantHandler); agent.handleRequest(intentMap); });</code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">Et ces d√©pendances dans le fichier / onglet `package.json`:</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">{ "name": "dialogflowFirebaseFulfillment", "description": "This is the default fulfillment for a Dialogflow agents using Cloud Functions for Firebase", "version": "0.0.1", "private": true, "license": "Apache Version 2.0", "author": "Google Inc.", "engines": { "node": "~6.0" }, "scripts": { "start": "firebase serve --only functions:dialogflowFirebaseFulfillment", "deploy": "firebase deploy --only functions:dialogflowFirebaseFulfillment" }, "dependencies": { "actions-on-google": "2.0.0-alpha.4", "firebase-admin": "^4.2.1", "firebase-functions": "^0.5.7", "dialogflow": "^0.1.0", "dialogflow-fulfillment": "0.3.0-beta.3" } }</code> </pre> </div></div><br><p>  Tout d'abord, mettez √† jour les d√©pendances alpha et b√™ta vers les derni√®res stables. </p><br><div class="spoiler">  <b class="spoiler_title">Voici les derni√®res versions en ce moment.</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">{ "dependencies": { "actions-on-google": "^2.2.0", "firebase-admin": "^5.2.1", "firebase-functions": "^0.6.2", "dialogflow": "^0.6.0", "dialogflow-fulfillment": "^0.5.0" } }</code> </pre> </div></div><br><p>  Et maintenant, regardons de plus pr√®s le code. </p><br><div class="spoiler">  <b class="spoiler_title">Ci-dessus se fait l'importation des d√©pendances</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">// Cloud Functions  Firebase library const functions = require('firebase-functions'); //       const {WebhookClient} = require('dialogflow-fulfillment'); //       const {Card, Suggestion} = require('dialogflow-fulfillment');</code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">Tout le point de r√©alisation est de remplacer le rappel-un `dialogflowFirebaseFulfillment`</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">exports.dialogflowFirebaseFulfillment = functions.https.onRequest((request, response) =&gt; { console.log('Dialogflow Request headers: ' + JSON.stringify(request.headers)); console.log('Dialogflow Request body: ' + JSON.stringify(request.body)); //   . const agent = new WebhookClient({ request, response }); //   let result = request.body.queryResult; //  action  entities https://dialogflow.com/docs/actions-and-parameters let action = result.action; let parameters = result.parameters; //    https://dialogflow.com/docs/contexts let outputContexts = result.outputContexts; //       let intentRequest = request.body.originalDetectIntentRequest; });</code> </pre> </div></div><br><p>  Ce rappel sera appel√© pour les intentions pour lesquelles vous activez le fullfilment. </p><br><div class="spoiler">  <b class="spoiler_title">Red√©finissez maintenant la r√©ponse √† l'intention</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">exports.dialogflowFirebaseFulfillment = functions.https.onRequest((request, response) =&gt; { const agent = new WebhookClient({ request, response }); function welcome(agent) { //   agent.add(`Welcome to my agent!`); } function fallback(agent) { agent.add(`I didn't understand`); agent.add(`I'm sorry, can you try again?`); } //   ,  : // key -   intent-. // value -   ,   . let intentMap = new Map(); intentMap.set('Default Welcome Intent', welcome); intentMap.set('Default Fallback Intent', fallback); agent.handleRequest(intentMap); });</code> </pre> </div></div><br><p>  Dans le m√™me temps, le code remplace compl√®tement la r√©ponse d'intention de la section R√©ponses. <br>  Les r√©ponses ne seront appel√©es qu'en cas d'√©chec du rappel, vous pouvez donc y traiter les erreurs. </p><br><p>  Nous supprimons les fonctions de traitement intentionnel du rappel. <br>  Les fonctions d'accueil et de secours sont dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fermeture</a> . </p><br><div class="spoiler">  <b class="spoiler_title">Pour les supprimer du rappel, vous devrez ajouter le transfert du contexte de la fonction et des param√®tres via `bind`</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">exports.dialogflowFirebaseFulfillment = functions.https.onRequest((request, response) =&gt; { const agent = new WebhookClient({ request, response }); let intentMap = new Map(); //  set  Map.      intentMap .set('Default Welcome Intent', welcome.bind(this, agent)) .set('Default Fallback Intent', fallback.bind(this, agent)); agent.handleRequest(intentMap); }); function welcome(agent) { agent.add(`Welcome to my agent!`); } function fallback(agent) { //   2   add    agent.add([ `I didn't understand`, `I'm sorry, can you try again?` ]); }</code> </pre> </div></div><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Donc, vous √™tes maintenant pr√™t √† √©crire votre premi√®re comp√©tence pour Google Assistant. </font><font style="vertical-align: inherit;">Il y a une base, mais passons au hardcore dans la partie suivante.</font></font></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr419773/">https://habr.com/ru/post/fr419773/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr419763/index.html">Exemples de calcul du "facteur de disponibilit√©" pour des ensembles d'√©quipements de r√©seau</a></li>
<li><a href="../fr419765/index.html">Le cours "Langages de programmation Web" (bas√© sur Ruby) de MSTU. N.E. Bauman sur la cha√Æne Technostream</a></li>
<li><a href="../fr419767/index.html">Le cr√©ateur de Wikip√©dia r√©pond aux questions: programmation, sommeil, livres, conseils pour la vie</a></li>
<li><a href="../fr419769/index.html">WireGuard "viendra" au noyau Linux - pourquoi?</a></li>
<li><a href="../fr419771/index.html">Recueil Fintech: la Banque centrale acc√©l√®re la collecte de donn√©es biom√©triques clients, les crypto-monnaies sont en baisse et le march√© de l'Internet des objets se d√©veloppe</a></li>
<li><a href="../fr419777/index.html">Comment vendre des serveurs NNN aux Pays-Bas et ne pas se laisser enthousiasmer: les secrets de vente</a></li>
<li><a href="../fr419779/index.html">Les poumons cultiv√©s ont √©t√© transplant√©s avec succ√®s chez un porc; apr√®s 5 ans, des essais sur l'homme sont possibles</a></li>
<li><a href="../fr419781/index.html">SpaceX a organis√© le premier atelier sur Mars</a></li>
<li><a href="../fr419783/index.html">L'homme contre la machine: une nouvelle √©thique pour la cybers√©curit√©</a></li>
<li><a href="../fr419785/index.html">Comment fonctionne MSTP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎎 ⏪ 🧑🏽‍🤝‍🧑🏻 Intuitive Anwendung von Monte-Carlo-Methoden mit Markov-Ketten 👶🏼 🏞️ ☝🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ist es einfach Ich habe es versucht 
 Alexey Kuzmin, Direktor für Datenentwicklung und Arbeit bei DomKlik, Dozent für Datenwissenschaft in Netologie, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Intuitive Anwendung von Monte-Carlo-Methoden mit Markov-Ketten</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/netologyru/blog/460497/"><h4>  Ist es einfach  Ich habe es versucht </h4><br>  <i>Alexey Kuzmin, Direktor für Datenentwicklung und Arbeit bei DomKlik, Dozent für Datenwissenschaft in Netologie, hat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Artikel von</a> Rahul Agarwal übersetzt, wie Monte-Carlo-Methoden mit Markov-Ketten funktionieren, um Probleme mit einem großen Zustandsraum zu lösen.</i> <br><a name="habracut"></a><br>  Jeder, der mit Data Science in Verbindung steht, hat jemals von Monte-Carlo-Methoden mit Markov-Ketten (MCMCs) gehört.  Manchmal wird das Thema beim Studium der Bayes'schen Statistik angesprochen, manchmal bei der Arbeit mit Werkzeugen wie dem Propheten. <br><br>  Aber MCMC ist schwer zu verstehen.  Wann immer ich über diese Methoden las, bemerkte ich, dass die Essenz von MCMC in den tiefen Schichten des mathematischen Rauschens verborgen ist und es schwierig ist, hinter diesem Rauschen zu erkennen.  Ich musste viele Stunden damit verbringen, dieses Konzept zu verstehen. <br><br>  In diesem Artikel wird versucht, Monte-Carlo-Methoden mit Markov-Ketten zu erklären, damit klar wird, wofür sie verwendet werden.  Ich werde mich in meinem nächsten Beitrag auf einige weitere Möglichkeiten konzentrieren, diese Methoden anzuwenden. <br><br>  Also fangen wir an.  MCMC besteht aus zwei Begriffen: Monte-Carlo- und Markov-Ketten.  Sprechen wir über jeden von ihnen. <br><br><h2>  Monte Carlo </h2><br><img src="https://habrastorage.org/webt/i8/wx/2n/i8wx2nylvemkcfvwp7rxvznjfa0.jpeg"><br><br>  Im einfachsten Sinne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">können Monte-Carlo-Methoden</a> als einfache Simulationen definiert werden. <br><br>  Monte Carlo Methods erhielt ihren Namen vom Monte Carlo Casino in Monaco.  In vielen Kartenspielen müssen Sie die Wahrscheinlichkeit kennen, den Dealer zu gewinnen.  Manchmal kann die Berechnung dieser Wahrscheinlichkeit mathematisch kompliziert oder unlösbar sein.  Wir können jedoch jederzeit eine Computersimulation ausführen, um das gesamte Spiel viele Male zu spielen, und die Wahrscheinlichkeit als die Anzahl der Siege geteilt durch die Anzahl der gespielten Spiele betrachten. <br>  Dies ist alles, was Sie über Monte-Carlo-Methoden wissen müssen.  Ja, es ist nur eine einfache Modellierungstechnik mit einem ausgefallenen Namen. <br><br><h2>  Markov-Ketten </h2><br><img src="https://habrastorage.org/webt/7r/my/np/7rmynpvle1yn4xk5tuwqdvkd7mo.jpeg"><br><br>  Da der Begriff MCMC aus zwei Teilen besteht, müssen Sie noch verstehen, was <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Markov-Ketten sind</a> .  Bevor wir jedoch zu den Markov-Ketten übergehen, lassen Sie uns ein wenig über die Markov-Eigenschaften sprechen. <br><br>  Angenommen, es gibt ein System von M-möglichen Zuständen, und Sie wechseln von einem Zustand in einen anderen.  Lass dich noch nicht verwirren.  Ein spezielles Beispiel für ein solches System ist das Wetter, das von heiß über kalt bis mäßig wechselt.  Ein weiteres Beispiel ist der Aktienmarkt, der von einem bärischen zu einem bullischen und stagnierenden Staat springt. <br><br>  <i>Die Markov-Eigenschaft</i> legt nahe, dass für einen gegebenen Prozess, der sich zu einem bestimmten Zeitpunkt im Zustand X <sub>n befindet</sub> , die Wahrscheinlichkeit X <sub>n + 1</sub> = k (wobei k einer der M-Zustände ist, in die der Prozess gehen kann) nur von abhängt Was ist dieser Zustand im Moment.  Und nicht darüber, wie es seinen aktuellen Zustand erreicht hat. <br>  In mathematischen Begriffen können wir dies in Form der folgenden Formel schreiben: <br><img src="https://habrastorage.org/webt/tw/kq/se/twkqseq2tra2alhiqdyfuyswnla.png"><br>  Aus Gründen der Klarheit ist es Ihnen egal, in welcher Reihenfolge der Markt bullisch wurde.  Die Wahrscheinlichkeit, dass der nächste Staat „bärisch“ sein wird, wird nur durch die Tatsache bestimmt, dass sich der Markt derzeit in einem „bullischen“ Zustand befindet.  Das macht auch in der Praxis Sinn. <br><br>  Ein Prozess mit einer Markov-Eigenschaft wird als Markov-Prozess bezeichnet.  Warum ist die Markov-Kette wichtig?  Aufgrund seiner stationären Verteilung. <br><br><h3>  Was ist stationäre Verteilung? </h3><br>  Ich werde versuchen, die stationäre Verteilung zu erklären, indem ich sie für das folgende Beispiel berechne.  Angenommen, Sie haben einen Markov-Prozess für die Börse, wie unten gezeigt. <br><img src="https://habrastorage.org/webt/1k/o-/bb/1ko-bbb9hzmv8j9o_an1ocvyurs.png"><br>  Sie haben eine Übergangswahrscheinlichkeitsmatrix, die die Wahrscheinlichkeit eines Übergangs vom Zustand X <sub>i</sub> zum X <sub>j bestimmt</sub> . <br><img src="https://habrastorage.org/webt/or/u7/jp/oru7jpnpioj12jbrcw7t4o6sk94.png"><br>  Übergangswahrscheinlichkeitsmatrix, Q. <br><br>  In der transienten Wahrscheinlichkeitsmatrix Q ist die Wahrscheinlichkeit, dass der nächste Zustand "bull" ist, gegeben, wenn der aktuelle Zustand "bull" = 0,9 ist;  Die Wahrscheinlichkeit, dass der nächste Zustand "bärisch" ist, wenn der aktuelle Zustand "bull" ist = 0,075.  Usw. <br><br>  Beginnen wir mit einem bestimmten Zustand.  Unser Zustand wird durch den Vektor [Stier, Bär, Stagnation] bestimmt.  Wenn wir mit einem „bärischen“ Zustand beginnen, sieht der Vektor folgendermaßen aus: [0,1,0].  Wir können die Wahrscheinlichkeitsverteilung für den nächsten Zustand berechnen, indem wir den aktuellen Zustandsvektor mit der Übergangswahrscheinlichkeitsmatrix multiplizieren. <br><img src="https://habrastorage.org/webt/or/jy/85/orjy85onzacwcu2wlgftmugzygk.png"><br>  <b>Beachten Sie, dass sich die Wahrscheinlichkeiten zu 1 addieren.</b> <br><br>  Die folgende Zustandsverteilung ergibt sich aus der Formel: <br><img src="https://habrastorage.org/webt/ge/wk/fu/gewkfuf7xziuajc2ox7tn9blfcm.png"><br><br>  Usw.  Am Ende erreichen Sie einen stationären Zustand, in dem sich der Zustand stabilisiert: <br><img src="https://habrastorage.org/webt/iy/5y/65/iy5y65fxgxo4foqpe3fpq2hs-dq.png"><br><br>  Für die oben beschriebene Übergangswahrscheinlichkeitsmatrix Q ist die stationäre Verteilung s <br><img src="https://habrastorage.org/webt/ae/ut/_8/aeut_8m8wsypenpgkig3onnzwdc.png"><br>  Sie können eine stationäre Verteilung mit dem folgenden Code erhalten: <br><br><pre><code class="python hljs">Q = np.matrix([[<span class="hljs-number"><span class="hljs-number">0.9</span></span>,<span class="hljs-number"><span class="hljs-number">0.075</span></span>,<span class="hljs-number"><span class="hljs-number">0.025</span></span>],[<span class="hljs-number"><span class="hljs-number">0.15</span></span>,<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.05</span></span>],[<span class="hljs-number"><span class="hljs-number">0.25</span></span>,<span class="hljs-number"><span class="hljs-number">0.25</span></span>,<span class="hljs-number"><span class="hljs-number">0.5</span></span>]]) init_s = np.matrix([[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> , <span class="hljs-number"><span class="hljs-number">0</span></span>]]) epsilon =<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> epsilon&gt;<span class="hljs-number"><span class="hljs-number">10e-9</span></span>:    next_s = np.dot(init_s,Q)    epsilon = np.sqrt(np.sum(np.square(next_s - init_s)))    init_s = next_s print(init_s) ------------------------------------------------------------------ matrix([[<span class="hljs-number"><span class="hljs-number">0.62499998</span></span>, <span class="hljs-number"><span class="hljs-number">0.31250002</span></span>, <span class="hljs-number"><span class="hljs-number">0.0625</span></span>  ]])</code> </pre> <br>  Sie können auch von jedem anderen Zustand aus starten - erzielen Sie die gleiche stationäre Verteilung.  Ändern Sie den Ausgangszustand im Code, wenn Sie dies sicherstellen möchten. <br><br>  Jetzt können wir die Frage beantworten, warum die stationäre Verteilung so wichtig ist. <br><br>  Die stationäre Verteilung ist wichtig, da damit die Wahrscheinlichkeit bestimmt werden kann, dass sich ein System zufällig in einem bestimmten Zustand befindet. <br><br>  In unserem Beispiel können wir sagen, dass sich der Markt in 62,5% der Fälle in einem „bullischen“ Zustand befindet, 31,25% in einem „bärischen“ Zustand und 6,25% in einer Stagnation. <br><br>  Intuitiv kann man dies als zufälliges Wandern um die Kette sehen. <br><br><img src="https://habrastorage.org/webt/i3/e6/xt/i3e6xtqko2iip-janj6dvfbnv4q.png"><br>  Zufälliger Spaziergang <br><br>  Sie befinden sich an einem bestimmten Punkt und wählen den nächsten Zustand aus, wobei Sie die Wahrscheinlichkeitsverteilung des nächsten Zustands unter Berücksichtigung des aktuellen Zustands beobachten.  Wir können einige Knoten häufiger als andere besuchen, basierend auf den Wahrscheinlichkeiten dieser Knoten. <br><br>  So löste Google das Suchproblem zu Beginn des Internets.  Das Problem bestand darin, die Seiten nach ihrer Wichtigkeit zu sortieren.  Google hat das Problem mithilfe des Pagerank-Algorithmus gelöst.  Der Google Pagerank-Algorithmus sollte den Status als Seite und die Wahrscheinlichkeit einer Seite in einer stationären Verteilung als ihre relative Bedeutung betrachten. <br><br>  Nun wenden wir uns direkt der Betrachtung von MCMC-Methoden zu. <br><br><h2>  Was sind Monte-Carlo-Methoden mit Markov-Ketten (MCMC) </h2><br>  Lassen Sie mich eine Frage stellen, bevor ich beantworte, was MCMC ist.  Wir kennen die Beta-Distribution.  Wir kennen seine Wahrscheinlichkeitsdichtefunktion.  Aber können wir aus dieser Verteilung eine Stichprobe ziehen?  Können Sie einen Weg finden, dies zu tun? <br><br><img src="https://habrastorage.org/webt/ks/ai/wd/ksaiwdv7lomes7g55ihqbhxushs.png"><br>  Denken Sie ... <br><br>  Mit MCMC können Sie aus einer beliebigen Wahrscheinlichkeitsverteilung auswählen.  Dies ist besonders wichtig, wenn Sie eine Auswahl aus der posterioren Verteilung treffen müssen. <br><img src="https://habrastorage.org/webt/12/kn/-5/12kn-58z9ub6t2ft1lctptwix28.png"><br>  Die Abbildung zeigt den Bayes-Satz. <br><br>  Beispielsweise müssen Sie eine Probe aus einer posterioren Verteilung erstellen.  Aber ist es einfach, die hintere Komponente zusammen mit der Normalisierungskonstante (Evidenz) zu berechnen?  In den meisten Fällen finden Sie sie in Form eines Produkts aus Wahrscheinlichkeit und a priori Wahrscheinlichkeit.  Die Berechnung der Normalisierungskonstante (p (D)) funktioniert jedoch nicht.  Warum?  Schauen wir uns das genauer an. <br><br>  Angenommen, H nimmt nur 3 Werte an: <br><br>  p (D) = p (H = H1) .p (D | H = H1) + p (H = H2) .p (D | H = H2) + p (H = H3) .p (D | H = H3) <br><br>  In diesem Fall ist p (D) leicht zu berechnen.  Was aber, wenn der Wert von H stetig ist?  Wäre es möglich, dies so einfach zu berechnen, insbesondere wenn H unendliche Werte annehmen würde?  Dazu müsste ein komplexes Integral gelöst werden. <br><br>  Wir wollen eine zufällige Auswahl aus der posterioren Verteilung treffen, aber auch p (D) als Konstante betrachten. <br><br>  Wikipedia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schreibt</a> : <br><br>  Monte-Carlo-Methoden mit Markov-Ketten sind eine Klasse von Algorithmen zur Abtastung aus einer Wahrscheinlichkeitsverteilung, die auf dem Aufbau einer Markov-Kette basiert, die als stationäre Verteilung die gewünschte Form hat.  Der Kettenzustand nach einer Reihe von Schritten wird dann als Auswahl aus der gewünschten Verteilung verwendet.  Die Probenqualität verbessert sich mit zunehmender Anzahl von Schritten. <br><br>  Schauen wir uns ein Beispiel an.  Angenommen, Sie benötigen ein Beispiel aus der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beta-Distribution</a> .  Seine Dichte: <br><img src="https://habrastorage.org/webt/ag/xh/wj/agxhwjqglfhcz2bl88eu3ov84ja.png"><br><br>  wobei C die Normalisierungskonstante ist.  Eigentlich ist dies eine Funktion von α und β, aber ich möchte zeigen, dass es für eine Stichprobe aus der Beta-Verteilung nicht benötigt wird, also nehmen wir es als Konstante. <br><br>  Das Beta-Verteilungsproblem ist wirklich schwierig, wenn nicht praktisch unlösbar.  In der Realität müssen Sie möglicherweise mit komplexeren Verteilungsfunktionen arbeiten, und manchmal kennen Sie die Normalisierungskonstanten nicht. <br><br>  MCMC-Methoden erleichtern das Leben, indem sie Algorithmen bereitstellen, mit denen eine Markov-Kette mit einer Beta-Verteilung als stationäre Verteilung erstellt werden kann, da wir aus einer gleichmäßigen Verteilung wählen können (was relativ einfach ist). <br><br>  Wenn wir mit einem zufälligen Zustand beginnen und auf der Grundlage eines Algorithmus mehrmals zum nächsten Zustand übergehen, werden wir schließlich eine Markov-Kette mit einer Beta-Verteilung als stationäre Verteilung erstellen.  Und die Zustände, in denen wir uns seit langer Zeit befinden, können als Beispiel aus der Beta-Distribution verwendet werden. <br><br>  Einer dieser MCMC-Algorithmen ist der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Metropolis-Hastings-Algorithmus.</a> <br><br><h2>  Metropolis-Hastings-Algorithmus </h2><br><img src="https://habrastorage.org/webt/qq/oj/89/qqoj89il8-rsyd3xo-sqawnrug0.jpeg"><br><br><h3>  Intuition: </h3><br>  Was ist der Zweck? <br><br>  <i>Intuitiv möchten wir ein Stück Oberfläche (unsere Markov-Kette) so entlang gehen, dass die Zeit, die wir an jedem Ort verbringen, proportional zur Höhe der Oberfläche an diesem Ort ist (die gewünschte Wahrscheinlichkeitsdichte, aus der wir eine Auswahl treffen möchten).</i> <i><br><br></i>  <i>So möchten wir beispielsweise doppelt so viel Zeit auf einem 100 Meter hohen Hügel verbringen wie auf einem benachbarten 50 Meter hohen Hügel.</i>  <i>Es ist gut, dass wir dies auch dann tun können, wenn wir die absoluten Höhen der Punkte auf der Oberfläche nicht kennen: Alles, was Sie wissen müssen, sind die relativen Höhen.</i>  <i>Wenn beispielsweise die Spitze des Hügels A zweimal höher ist als die Spitze des Hügels B, möchten wir in A doppelt so viel Zeit verbringen wie auf B.</i> <i><br><br></i>  <i>Es gibt komplexere Schemata, um neue Orte und Regeln für ihre Annahme vorzuschlagen, aber die Hauptidee lautet wie folgt:</i> <i><br><br></i> <ol><li>  <i>Wählen Sie einen neuen "vorgeschlagenen" Ort.</i> </li><li>  <i>Finden Sie heraus, wie hoch oder niedriger dieser Ort im Vergleich zum aktuellen ist.</i> </li><li>  <i>An Ort und Stelle bleiben oder an einen neuen Ort ziehen, mit einer Wahrscheinlichkeit proportional zur Höhe der Orte.</i> </li></ol> <i><br></i>  <i>Der Zweck des MCMC besteht darin, aus einer Wahrscheinlichkeitsverteilung auszuwählen, ohne an irgendeinem Punkt seine genaue Höhe kennen zu müssen (C muss nicht bekannt sein).</i> <i><br></i>  <i>Wenn der Wanderprozess korrekt eingerichtet ist, können Sie sicherstellen, dass diese Proportionalität (zwischen der aufgewendeten Zeit und der Verteilungshöhe) erreicht wird</i> . <br><br><h3>  Algorithmus: </h3><br>  Lassen Sie uns nun die Aufgabe formeller definieren und beschreiben.  Sei s = (s1, s2, ..., sM) die gewünschte stationäre Verteilung.  Wir wollen eine Markov-Kette mit einer solchen stationären Verteilung erstellen.  Wir beginnen mit einer beliebigen Markov-Kette mit M-Zuständen mit der Übergangsmatrix P, so dass pij die Wahrscheinlichkeit des Übergangs vom Zustand i nach j darstellt. <br><br>  Intuitiv wissen wir, wie man die Markov-Kette durchstreift, aber die Markov-Kette hat nicht die erforderliche stationäre Verteilung.  Diese Kette hat eine stationäre Verteilung (die wir nicht brauchen).  Unser Ziel ist es, die Art und Weise, wie wir um die Markov-Kette herumwandern, so zu ändern, dass die Kette die gewünschte stationäre Verteilung hat. <br><br>  Um dies zu tun: <br><br><ol><li>  Beginnen Sie mit einem zufälligen Ausgangszustand i. </li><li>  Wählen Sie zufällig einen neuen angenommenen Zustand aus, indem Sie die Übergangswahrscheinlichkeiten in der i-ten Zeile der Übergangsmatrix P betrachten. </li><li>  Berechnen Sie ein Maß namens Entscheidungswahrscheinlichkeit, das definiert ist als: aij = min (sj.pji / si.pij, 1). </li><li>  Wirf nun eine Münze, die mit der Wahrscheinlichkeit aij auf der Oberfläche des Adlers landet.  Wenn ein Adler fällt, nehmen Sie das Angebot an, gehen Sie zum nächsten Zustand über, andernfalls lehnen Sie das Angebot ab, dh bleiben Sie im aktuellen Zustand. <br></li><li>  Wiederholen Sie viele Male. <br></li></ol><br>  Nach einer großen Anzahl von Tests konvergiert diese Kette und hat eine stationäre Verteilung s.  Dann können wir Kettenzustände als Stichprobe aus jeder Verteilung verwenden. <br><br>  Wenn Sie dies tun, um die Beta-Verteilung abzutasten, müssen Sie nur die Wahrscheinlichkeitsdichte verwenden, um nach der Wahrscheinlichkeit zu suchen, eine Entscheidung zu treffen.  Teilen Sie dazu sj durch si (dh die Normalisierungskonstante C wird aufgehoben). <br><br><h3>  Beta-Auswahl </h3><br><img src="https://habrastorage.org/webt/h9/ac/zw/h9aczwarm4hfwm0pya3hai-rg2e.jpeg"><br><br>  Nun wenden wir uns dem Problem der Stichprobe aus der Beta-Distribution zu. <br><br>  Eine Beta-Verteilung ist eine kontinuierliche Verteilung auf [0,1] und kann auf [0,1] unendliche Werte haben.  Angenommen, eine beliebige Markov-Kette P mit unendlichen Zuständen auf [0,1] hat eine Übergangsmatrix P, so dass pij = pji = alle Elemente in der Matrix. <br><br>  Wir brauchen keine Matrix P, wie wir später sehen werden, aber ich möchte, dass die Beschreibung des Problems dem von uns vorgeschlagenen Algorithmus so nahe wie möglich kommt. <br><br><ul><li>  Beginnen Sie mit einem zufälligen Anfangszustand i, der aus einer Gleichverteilung auf (0,1) erhalten wird. </li><li>  Wählen Sie zufällig einen neuen angenommenen Zustand aus, indem Sie die Übergangswahrscheinlichkeiten in der i-ten Zeile der Übergangsmatrix P betrachten. Angenommen, wir wählen einen anderen Zustand Unif (0,1) als den angenommenen Zustand j. </li><li>  Berechnen Sie das Maß, das als Entscheidungswahrscheinlichkeit bezeichnet wird: </li></ul><br><img src="https://habrastorage.org/webt/lp/jo/-0/lpjo-0phzn3o8zl83oniptticmu.png"><br>  Was vereinfacht zu: <br><img src="https://habrastorage.org/webt/4c/he/pi/4chepi6_1om84fk52t8jquzpmku.png"><br>  Da pji = pij und wo <br><img src="https://habrastorage.org/webt/pm/qc/y2/pmqcy2hanok1y-mnhbxk49dqbve.png"><br><ul><li>  Wirf jetzt eine Münze.  Mit der Wahrscheinlichkeit aij wird ein Adler fallen.  Wenn ein Adler fällt, sollten Sie das Angebot annehmen, dh in den nächsten Zustand wechseln.  Andernfalls lohnt es sich, das Angebot abzulehnen, dh im selben Zustand zu bleiben. </li><li>  Wiederholen Sie den Test viele Male. </li></ul><br><h3>  Code: </h3><br>  Es ist Zeit, von der Theorie zur Praxis überzugehen.  Wir werden unser Beta-Beispiel in Python schreiben. <br><br><pre> <code class="python hljs">impo rt rand om <span class="hljs-comment"><span class="hljs-comment"># Lets define our Beta Function to generate s for any particular state. We don't care for the normalizing constant here. def beta_s(w,a,b): return w**(a-1)*(1-w)**(b-1) # This Function returns True if the coin with probability P of heads comes heads when flipped. def random_coin(p): unif = random.uniform(0,1) if unif&gt;=p: return False else: return True # This Function runs the MCMC chain for Beta Distribution. def beta_mcmc(N_hops,a,b): states = [] cur = random.uniform(0,1) for i in range(0,N_hops): states.append(cur) next = random.uniform(0,1) ap = min(beta_s(next,a,b)/beta_s(cur,a,b),1) # Calculate the acceptance probability if random_coin(ap): cur = next return states[-1000:] # Returns the last 100 states of the chain</span></span></code> </pre><br>  Vergleichen Sie die Ergebnisse mit der tatsächlichen Beta-Verteilung. <br><br><pre> <code class="python hljs">impo rt num py <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pylab <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pl <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scipy.special <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ss %matplotlib inline pl.rcParams[<span class="hljs-string"><span class="hljs-string">'figure.figsize'</span></span>] = (<span class="hljs-number"><span class="hljs-number">17.0</span></span>, <span class="hljs-number"><span class="hljs-number">4.0</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Actual Beta PDF. def beta(a, b, i): e1 = ss.gamma(a + b) e2 = ss.gamma(a) e3 = ss.gamma(b) e4 = i ** (a - 1) e5 = (1 - i) ** (b - 1) return (e1/(e2*e3)) * e4 * e5 # Create a function to plot Actual Beta PDF with the Beta Sampled from MCMC Chain. def plot_beta(a, b): Ly = [] Lx = [] i_list = np.mgrid[0:1:100j] for i in i_list: Lx.append(i) Ly.append(beta(a, b, i)) pl.plot(Lx, Ly, label="Real Distribution: a="+str(a)+", b="+str(b)) pl.hist(beta_mcmc(100000,a,b),normed=True,bins =25, histtype='step',label="Simulated_MCMC: a="+str(a)+", b="+str(b)) pl.legend() pl.show() plot_beta(0.1, 0.1) plot_beta(1, 1) plot_beta(2, 3)</span></span></code> </pre><br><br><img src="https://habrastorage.org/webt/6z/b_/zb/6zb_zbywfexkiagddl4lpusmcko.png"><br><br>  Wie Sie sehen können, sind die Werte der Beta-Distribution sehr ähnlich.  Somit hat das MCMC-Netzwerk einen stationären Zustand erreicht <br><br>  Im obigen Code haben wir einen Beta-Sampler erstellt, aber das gleiche Konzept gilt für jede andere Distribution, aus der wir eine Auswahl treffen möchten. <br><br><h2>  Schlussfolgerungen </h2><br><img src="https://habrastorage.org/webt/5f/oh/h5/5fohh5w_hsavzw3yvbryxewnnkw.png"><br><br>  Es war ein großartiger Beitrag.  Herzlichen Glückwunsch, wenn Sie es bis zum Ende gelesen haben. <br><br>  MCMC-Methoden können im Wesentlichen komplex sein, bieten uns jedoch große Flexibilität.  Sie können aus einer beliebigen Verteilungsfunktion auswählen, indem Sie die Auswahl über die MCMC vornehmen.  Typischerweise werden diese Methoden verwendet, um Proben aus posterioren Verteilungen zu entnehmen. <br><br>  Sie können MCMC auch verwenden, um Probleme mit einem großen Zustandsraum zu lösen.  Zum Beispiel bei einem Rucksackproblem oder zur Entschlüsselung.  Ich werde versuchen, Ihnen im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nächsten</a> Beitrag weitere interessante Beispiele zu liefern.  Bleib dran. <br><br><h2>  Von den Redakteuren </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Python-</a> Kurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zum Arbeiten mit Daten</a> </li><li>  Online-Kurs für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">maschinelles Lernen</a> </li><li>  Online-Kurs " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GROSSE DATEN von Grund auf neu</a> " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460497/">https://habr.com/ru/post/de460497/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460485/index.html">Wie ein Online-Turnier das "Ziel nächste Woche" entmutigen kann</a></li>
<li><a href="../de460489/index.html">TOP 11 Fehler bei der Entwicklung von BCP</a></li>
<li><a href="../de460491/index.html">Arduino Temperatur- und Feuchtigkeitssensor mit Senden und Plotten (Teil 1)</a></li>
<li><a href="../de460493/index.html">"Killer Apps" für PC aus den 80ern: VisiCalc und WordStar</a></li>
<li><a href="../de460495/index.html">Container-to-Pipeline: CRI-O ist jetzt die Standardeinstellung in OpenShift Container Platform 4</a></li>
<li><a href="../de460499/index.html">Drei Gewinner des Dijkstra-Preises: Wie verliefen Hydra 2019 und SPTDC 2019?</a></li>
<li><a href="../de460501/index.html">Beispiel für die Implementierung einer kontinuierlichen Integration mit BuildBot</a></li>
<li><a href="../de460503/index.html">Drahtlose Konfiguration des Raspberry PI 3 B +</a></li>
<li><a href="../de460505/index.html">Verführen Sie drei Kreuze oder warum Projekte so schwer pünktlich zu beenden sind</a></li>
<li><a href="../de460507/index.html">XEN und die Zukunft der Automobilindustrie: Wie ein Open-Source-Hypervisor zu einem Konkurrenten für kommerzielle Automobillösungen wird</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
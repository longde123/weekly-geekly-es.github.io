<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏹 🚗 👨🏿‍🎓 Comment je n'ai PAS analysé Internet biélorusse 🤦 😁 👨🏾‍🤝‍👨🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Préface 
 Cet article n'est pas très similaire à ceux qui ont été publiés plus tôt sur l'analyse d'Internet dans certains pays, car je n'ai pas poursu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment je n'ai PAS analysé Internet biélorusse</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446022/"><h2>  Préface </h2><br>  Cet article n'est pas très similaire à ceux qui ont été publiés plus tôt sur l'analyse d'Internet dans certains pays, car je n'ai pas poursuivi les objectifs de l'analyse en masse d'un segment spécifique d'Internet à la recherche de ports ouverts et de la présence des vulnérabilités les plus populaires car il est contraire à la loi. <br><br>  J'avais plutôt un intérêt légèrement différent - essayer d'identifier tous les sites pertinents dans la zone de domaine BY en utilisant différentes méthodes, déterminer la pile de technologies utilisées, à travers des services comme Shodan, VirusTotal, etc. pour effectuer une reconnaissance passive sur IP et des ports ouverts et, dans l'appendice, collecter un peu d'autres utiles des informations pour la formation de quelques statistiques générales sur le niveau de sécurité des sites et des utilisateurs. <br><a name="habracut"></a><br><h2>  Introduction et notre boîte à outils </h2><br>  Le plan au tout début était simple - contactez votre registraire local pour une liste des domaines enregistrés actuels, puis vérifiez tout pour la disponibilité et commencez à explorer les sites qui fonctionnent.  En réalité, tout s'est avéré beaucoup plus compliqué - ce type d'informations était naturel, personne ne voulait le fournir, à l'exception de la page de statistiques officielles des noms de domaine enregistrés dans la zone BY (environ 130 mille domaines).  S'il n'y a pas de telles informations, vous devez les collecter vous-même. <br><br><img src="https://habrastorage.org/webt/yh/pz/4w/yhpz4wvpvleq-f25o5fp5wwt_2u.png"><br><br>  En termes d'outils, en fait, tout est assez simple - nous regardons vers l'open source, vous pouvez toujours ajouter quelque chose, terminer quelques béquilles minimales.  Parmi les plus populaires, les outils suivants ont été utilisés: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Whatweb</a> </li><li>  boucler </li><li>  creuser </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wafw00f</a> </li><li>  API tierces ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VirusTotal</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google SafeBrwosing</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Shodan</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vulners</a> ) </li></ul><br><br><h2>  Début des activités: point de départ </h2><br>  Comme introduction, comme je l'ai déjà dit, idéalement, les noms de domaine étaient appropriés, mais où puis-je les obtenir?  Nous devons partir de quelque chose de plus simple, dans ce cas, les adresses IP nous conviennent, mais encore une fois - avec les recherches inversées, il n'est pas toujours possible d'attraper tous les domaines, et lors de la collecte des noms d'hôtes - ce n'est pas toujours le bon domaine.  À ce stade, j'ai commencé à réfléchir à des scénarios possibles pour collecter ce type d'informations, encore une fois - le fait que notre budget était de 5 $ pour la location de VPS a été pris en compte, tout le reste devrait être gratuit. <br><br><h3>  Nos sources potentielles d'information: </h3><br><ul><li>  Adresses IP (site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ip2location</a> ) </li><li>  Recherchez les domaines par la deuxième partie de l'adresse e-mail (mais où les obtenir? </li><li>  Certains bureaux d'enregistrement / hébergeurs peuvent nous fournir ces informations sous forme de sous-domaines </li><li>  Sous-domaines et leur inversion subséquente (Sublist3r et Aquatone peuvent aider ici) </li><li>  Bruteforce et entrée manuelle (longue, morne, mais possible, même si je n'ai pas utilisé cette option) </li></ul><br>  Je vais prendre un peu d'avance et dire qu'avec cette approche, j'ai réussi à collecter environ 50 000 domaines et sites uniques, respectivement (je n'ai pas réussi à tout traiter).  S'il continuait à collecter activement des informations, alors en moins d'un mois de travail, mon convoyeur aurait certainement maîtrisé l'intégralité de la base de données, ou la majeure partie. <br><br><h3>  Passons aux choses sérieuses </h3><br>  Dans les articles précédents, les informations sur les adresses IP ont été extraites du site IP2LOCATION, pour des raisons évidentes, je n'ai pas rencontré ces articles (car toutes les actions ont eu lieu beaucoup plus tôt), mais je suis également venu vers cette ressource.  Certes, dans mon cas, l'approche était différente - j'ai décidé de ne pas prendre la base de données localement pour moi et de ne pas extraire les informations du CSV, mais j'ai décidé de surveiller les modifications directement sur le site, sur une base continue et comme base principale d'où tous les scripts suivants prendront des objectifs - fait un tableau avec Adresses IP dans différents formats: CIDR, liste «de» et «à», marque de pays (juste au cas où), numéro AS, description AS. <br><br><img src="https://habrastorage.org/webt/mx/s4/wj/mxs4wjpxueytkcd15srf7alswf8.png"><br><br>  Le format n'est pas le plus optimal, mais j'étais assez satisfait de la démo et de la promotion ponctuelle, et afin de ne pas opter pour des informations auxiliaires comme l'ASN sur une base continue, j'ai décidé de le connecter également à la maison.  Pour obtenir ces informations, je me suis tourné vers le service <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IpToASN</a> , ils ont une API pratique (avec restrictions), que vous avez en fait juste besoin d'intégrer en vous. <br><br><div class="spoiler">  <b class="spoiler_title">Code d'analyse IP</b> <div class="spoiler_text"><pre><code class="php hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ipList</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, <span class="hljs-string"><span class="hljs-string">"https://lite.ip2location.com/belarus-ip-address-ranges"</span></span>); curl_setopt($ch, CURLOPT_HEADER, <span class="hljs-number"><span class="hljs-number">0</span></span>); curl_setopt($ch, CURLOPT_USERAGENT,<span class="hljs-string"><span class="hljs-string">'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.13) Gecko/20080311 Firefox/2.0.0.13'</span></span>); curl_setopt($ch, CURLOPT_RETURNTRANSFER, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); $ipList = curl_exec($ch); curl_close ($ch); preg_match_all(<span class="hljs-string"><span class="hljs-string">"/(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\&lt;\/td\&gt;\s+\&lt;td\&gt;\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})/"</span></span>, $ipList, $matches); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> $matches[<span class="hljs-number"><span class="hljs-number">0</span></span>]; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">iprange2cidr</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">($ipStart, $ipEnd)</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (is_string($ipStart) || is_string($ipEnd)){ $start = ip2long($ipStart); $end = ip2long($ipEnd); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>{ $start = $ipStart; $end = $ipEnd; } $result = <span class="hljs-keyword"><span class="hljs-keyword">array</span></span>(); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>($end &gt;= $start){ $maxSize = <span class="hljs-number"><span class="hljs-number">32</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ($maxSize &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>){ $mask = hexdec(iMask($maxSize - <span class="hljs-number"><span class="hljs-number">1</span></span>)); $maskBase = $start &amp; $mask; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>($maskBase != $start) <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; $maxSize--; } $x = log($end - $start + <span class="hljs-number"><span class="hljs-number">1</span></span>)/log(<span class="hljs-number"><span class="hljs-number">2</span></span>); $maxDiff = floor(<span class="hljs-number"><span class="hljs-number">32</span></span> - floor($x)); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>($maxSize &lt; $maxDiff){ $maxSize = $maxDiff; } $ip = long2ip($start); array_push($result, <span class="hljs-string"><span class="hljs-string">"$ip/$maxSize"</span></span>); $start += pow(<span class="hljs-number"><span class="hljs-number">2</span></span>, (<span class="hljs-number"><span class="hljs-number">32</span></span>-$maxSize)); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> $result; } $getIpList = ipList(); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span>($getIpList <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> $item) { $cidr = iprange2cidr($ip[<span class="hljs-number"><span class="hljs-number">0</span></span>], $ip[<span class="hljs-number"><span class="hljs-number">1</span></span>]); }</code> </pre> <br></div></div><br>  Après avoir découvert l'IP, nous devons, hélas, exécuter toute notre base de données via les services de recherche inversée - c'est impossible, sauf pour l'argent. <br><br>  Parmi les services qui sont excellents pour cela et pratiques à utiliser, je veux en mentionner deux: <br><br><ol><li>  VirusTotal - limite sur la fréquence des appels à partir d'une seule clé API </li><li>  Hackertarget.com (leur API) - limite sur le nombre de hits d'une IP </li></ol><br>  En contournant les limites, les options suivantes ont été obtenues: <br><br><ul><li>  Dans le premier cas, l'un des scénarios consiste à supporter des délais d'attente de 15 secondes, au total, nous aurons 4 appels par minute, ce qui peut considérablement affecter notre vitesse et dans cette situation, il sera utile d'utiliser 2-3 de ces touches, et je recommanderais de recourir à la même pour proxy et changer d'agent utilisateur. </li><li>  Dans le deuxième cas, j'ai écrit un script pour l'analyse automatique de la base de données proxy basée sur des informations accessibles au public, leur validation et leur utilisation ultérieure (mais plus tard, j'ai laissé cette option parce que VirusTotal était également suffisant en substance) </li></ul><br>  Nous allons plus loin et nous nous dirigeons en douceur vers les adresses e-mail.  Ils peuvent également être une source d'informations utiles, mais où les collecter?  Il n'a pas fallu longtemps pour trouver une solution, car  les utilisateurs détiennent peu dans notre segment de sites personnels, et la plupart d'entre eux sont des organisations - les sites Web de profil comme les répertoires de magasins en ligne, les forums et les marchés conditionnels nous conviendront. <br><br>  Par exemple, une inspection rapide de l'un de ces sites a montré que de nombreux utilisateurs ajoutent leur e-mail directement à leur profil public et, par conséquent, cette entreprise peut être soigneusement analysée pour une utilisation future. <br><br><div class="spoiler">  <b class="spoiler_title">Un des analyseurs</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/env python3 import sys, threading, time, os, urllib, re, requests, pymysql from html.parser import HTMLParser from urllib import request from bs4 import BeautifulSoup # HEADERS CONFIG headers = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11.9; rv:42.0) Gecko/20200202 Firefox/41.0' } file = open('dat.html', 'w') def parseMails(uid): page = 'https://profile.onliner.by/user/'+str(uid)+'' cookie = {'onl_session': 'YOUR_SESSION_COOOKIE_HERE'} r = requests.get(page, headers = headers, cookies = cookie) data = BeautifulSoup(r.text) userinfo = data.find_all('dl', {'class': 'uprofile-info'}) find_email = [] for item in userinfo: find_email += str(item.find('a')) get_mail = ''.join(find_email) detect_email = re.compile(".+?&gt;(.+@.+?)&lt;/a&gt;").search(get_mail) file.write("&lt;li&gt;('"+detect_email.group(1)+"'),&lt;/li&gt;") for uid in range(1, 10000): t = threading.Thread(target=parseMails, args=(uid,)) t.start() time.sleep(0.3)</span></span></code> </pre><br></div></div><br>  Je n'entrerai pas dans les détails de l'analyse de chaque site, il est plus pratique de deviner l'ID utilisateur par force brute, il est plus facile d'analyser un plan de site, d'obtenir des informations sur les pages de l'entreprise à partir de celui-ci, puis de collecter des adresses auprès d'eux.  Après avoir collecté les adresses, il nous reste à effectuer plusieurs opérations simples en les triant immédiatement par zone de domaine, en conservant les «queues» et en les exécutant pour exclure les doublons de la base de données existante. <br><br>  À ce stade, je crois qu'avec la formation de la portée, nous pouvons terminer et passer à l'intelligence.  L'intelligence, comme nous le savons déjà, peut être de deux types - active et passive, dans notre cas - l'approche passive sera la plus pertinente.  Mais là encore, le simple accès au site sur le port 80 ou 443 sans charge malveillante et l'exploitation des vulnérabilités est une action tout à fait légitime.  Notre intérêt est les réponses du serveur à une seule demande, dans certains cas, il peut y avoir deux demandes (redirection de http vers https), dans des cas plus rares, jusqu'à trois (lorsque www est utilisé). <br><br><h2>  Intelligence </h2><br>  En utilisant ces informations comme domaine, nous pouvons collecter les données suivantes: <br><br><ul><li>  Enregistrements DNS (NS, MX, TXT) </li><li>  En-têtes de réponse </li><li>  Identifier la pile technologique utilisée </li><li>  Comprenez par quel protocole le site fonctionne. </li><li>  Essayez d'identifier les ports ouverts (basés sur la base de données Shodan / Censys) sans analyse directe </li><li>  Essayez d'identifier les vulnérabilités sur la base de la corrélation des informations de Shodan / Censys avec la base de données Vulners </li><li>  Est-ce dans la base de données malveillantes de la navigation sécurisée Google </li><li>  Collectez les adresses e-mail par domaine, ainsi que les correspondances déjà trouvées et vérifiez par Have I Been Pwned, en plus - lien vers les réseaux sociaux </li><li>  Un domaine est dans certains cas non seulement le visage de l'entreprise, mais aussi le produit de ses activités, des adresses e-mail pour l'inscription sur les services, etc., respectivement - vous pouvez rechercher des informations qui leur sont associées sur des ressources comme GitHub, Pastebin, Google Dorks (Google CSE ) </li></ul><br>  Vous pouvez toujours aller de l'avant et profiter de l'option masscan ou nmap, zmap, en les configurant d'abord via Tor avec un lancement dans un temps aléatoire ou même à partir de plusieurs instances, mais nous avons d'autres objectifs et le nom implique que je n'ai pas fait de scans directs. <br><br>  Nous collectons les enregistrements DNS, vérifions la possibilité d'amplification des requêtes et des erreurs de configuration comme AXFR: <br><br><div class="spoiler">  <b class="spoiler_title">Un exemple de collecte d'enregistrements de serveur NS</b> <div class="spoiler_text"><pre> <code class="bash hljs">dig ns +short <span class="hljs-variable"><span class="hljs-variable">$domain</span></span> | sed <span class="hljs-string"><span class="hljs-string">'s/\.$//g'</span></span> | awk <span class="hljs-string"><span class="hljs-string">'{print $1}'</span></span></code> </pre> <br></div></div><br>  Exemple de collecte d'enregistrements MX (voir NS, remplacez simplement 'ns' par 'mx' <br><br><div class="spoiler">  <b class="spoiler_title">Vérifiez AXFR (il existe de nombreuses solutions ici, voici une autre béquille, mais pas de sécurité, utilisée pour visualiser les sorties)</b> <div class="spoiler_text"><pre> <code class="php hljs"> $digNs = trim(shell_exec(<span class="hljs-string"><span class="hljs-string">"dig ns +short $domain | sed 's/\.$//g' | awk '{print $1}'"</span></span>)); $ns = explode(<span class="hljs-string"><span class="hljs-string">"\n"</span></span>, $digNs); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span>($ns <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> $target) { $axfr = trim(shell_exec(<span class="hljs-string"><span class="hljs-string">"dig -t axfr $domain @$target | awk '{print $1}' | sed 's/\.$//g'"</span></span>)); $axfr = preg_replace(<span class="hljs-string"><span class="hljs-string">"/\;/"</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, $axfr); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(!<span class="hljs-keyword"><span class="hljs-keyword">empty</span></span>(trim($axfr))) { $axfr = preg_replace(<span class="hljs-string"><span class="hljs-string">"/\;/"</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, $axfr); $res = json_encode(explode(<span class="hljs-string"><span class="hljs-string">"\n"</span></span>, trim($axfr)));</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Vérifiez l'amplification DNS</b> <div class="spoiler_text"><pre> <code class="bash hljs">dig +short test.openresolver.com TXT @<span class="hljs-variable"><span class="hljs-variable">$dns</span></span></code> </pre> <br>  Dans mon cas, les serveurs NS ont été pris dans la base de données, donc à la fin de la variable, vous pouvez remplacer n'importe quel serveur en fait.  En ce qui concerne l'exactitude des résultats de ce service, je ne peux pas être sûr que tout fonctionne bien là-bas et les résultats sont toujours valides, mais j'espère que la plupart des résultats sont réels. <br></div></div><br>  Si pour quelque raison que ce soit, nous devons conserver une URL finale à part entière vers le site, j'ai utilisé cURL pour cela: <br><br><pre> <code class="bash hljs">curl -I -L <span class="hljs-variable"><span class="hljs-variable">$target</span></span> | awk <span class="hljs-string"><span class="hljs-string">'/Location/{print $2}'</span></span></code> </pre> <br>  Il parcourra lui-même l'intégralité de la redirection et affichera la dernière, c'est-à-dire  URL actuelle du site.  Dans mon cas, cela a été extrêmement utile pour l'utilisation ultérieure d'outils tels que WhatWeb. <br><br>  Pourquoi devrions-nous l'utiliser?  Afin de déterminer le système d'exploitation, le serveur Web, le site CMS utilisé, certains en-têtes, des modules supplémentaires tels que les bibliothèques / frameworks JS / HTML, ainsi que le titre du site par lequel vous pouvez ensuite essayer de filtrer par le même domaine d'activité. <br><br>  Dans ce cas, une option très pratique consiste à exporter les résultats du fonctionnement de l'outil au format XML pour une analyse ultérieure et à les importer dans la base de données s'il est prévu de les traiter tous plus tard. <br><br><pre> <code class="bash hljs">whatweb --no-errors https://www.mywebsite.com --<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>-xml=results.xml</code> </pre> <br>  Pour ma part, j'ai créé JSON à la suite de la sortie et l'ai déjà mis dans la base de données. <br><br>  En parlant d'en-têtes, vous pouvez faire presque la même chose avec cURL ordinaire en exécutant une requête du formulaire: <br><br><pre> <code class="bash hljs">curl -I https://www.mywebsite.com</code> </pre> <br>  Dans les en-têtes, récupérez des informations sur le CMS et les serveurs Web à l'aide d'expressions régulières, par exemple. <br><br>  En plus de l'utile, nous pouvons également mettre en évidence la possibilité de collecter des informations sur les ports ouverts en utilisant Shodan puis en utilisant les données déjà obtenues, effectuer une vérification de la base de données Vulners à l'aide de leur API (les liens vers les services sont donnés dans l'en-tête).  Bien sûr, il peut y avoir des problèmes de précision dans ce scénario, mais ce n'est pas une analyse directe avec validation manuelle, mais un "jonglage" banal de données provenant de sources tierces, mais au moins c'est mieux que rien du tout. <br><br><div class="spoiler">  <b class="spoiler_title">Fonction PHP pour Shodan</b> <div class="spoiler_text"><pre> <code class="php hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">shodanHost</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">($host)</span></span></span><span class="hljs-function"> </span></span>{ $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, <span class="hljs-string"><span class="hljs-string">"https://api.shodan.io/shodan/host/"</span></span>.$host.<span class="hljs-string"><span class="hljs-string">"?key=&lt;YOUR_API_KEY&gt;"</span></span>); curl_setopt($ch, CURLOPT_HEADER, <span class="hljs-number"><span class="hljs-number">0</span></span>); curl_setopt($ch, CURLOPT_USERAGENT,<span class="hljs-string"><span class="hljs-string">'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.13) Gecko/20080311 Firefox/2.0.0.13'</span></span>); curl_setopt($ch, CURLOPT_RETURNTRANSFER, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); $shodanResponse = curl_exec($ch); curl_close ($ch); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> json_decode($shodanResponse); }</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Un exemple d'une telle analyse comparative # 1</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/ha/fv/7q/hafv7qlzupcsueqn_qwe_0qyo7y.png"><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Exemple # 2</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/9x/0c/jx/9x0cjxkltuscladnh9rd4nshsga.png"><br></div></div><br>  Oui, depuis qu'ils ont commencé à parler de l'API, alors les Vulner ont des limites et la solution la plus optimale serait d'utiliser leur script Python, tout fonctionnera bien sans torsion-torsions, dans le cas de PHP, j'ai rencontré quelques petites difficultés (encore une fois, ajoutez. les délais d'attente ont sauvé la situation). <br><br>  L'un des derniers tests - nous étudierons les informations sur le pare-feu utilisé avec un script tel que "wafw00f".  En testant ce merveilleux outil, j'ai remarqué une chose intéressante: ce n'était pas toujours la première fois qu'il était possible de déterminer le type de pare-feu utilisé. <br><br>  Pour voir quels types de pare-feu wafw00f peut potentiellement détecter, vous pouvez entrer la commande suivante: <br><br><pre> <code class="bash hljs">wafw00f -l</code> </pre> <br>  Pour déterminer le type de pare-feu - wafw00f analyse les en-têtes de réponse du serveur après l'envoi d'une demande standard au site, si cette tentative n'est pas suffisante, elle génère bien une demande de test simple supplémentaire, et si cela ne suffit pas à nouveau - la troisième méthode opère sur les données après les deux premières tentatives . <br><br>  Parce que  pour les statistiques, en fait, nous n'avons pas besoin de toute la réponse, nous coupons tous les excès avec une expression régulière et ne laissons que le nom pare-feu: <br><br><pre> <code class="php hljs">/is\sbehind\sa\s(.+?)\n/</code> </pre> <br>  Eh bien, comme je l'ai écrit plus tôt - en plus des informations sur le domaine et le site, les informations sur les adresses e-mail et les réseaux sociaux ont également été mises à jour en mode passif: <br><br><div class="spoiler">  <b class="spoiler_title">Statistiques par e-mail définies en fonction du domaine</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/f-/lq/fj/f-lqfjqylimkrb3l8ham2yxo8f4.png"><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Un exemple de détermination de la liaison des réseaux sociaux à l'adresse e-mail</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/an/pw/dq/anpwdqniobeopkdhnyq5pd5ejgk.png"><br></div></div><br>  Le moyen le plus simple était de gérer la validation des adresses sur Twitter (2 voies), avec Facebook (1 voie) à cet égard, il s'est avéré être un peu plus compliqué en raison d'un système légèrement plus complexe pour générer une véritable session utilisateur. <br><br><h2>  Passons aux statistiques sèches. </h2><br><h4>  Statistiques DNS </h4><br><img src="https://habrastorage.org/webt/uk/md/m1/ukmdm1eoizu6sjvxaf7nld8kdgi.png"><br><br>  <b>Fournisseur - combien de sites</b> <br>  ns1.tutby.com: 10899 <br>  ns2.tutby.com: 10899 <br>  ns1.neolocation.com: 4877 <br>  ns2.neolocation.com: 4873 <br>  ns3.neolocation.com: 4572 <br>  ns1.activeby.net: 4231 <br>  ns2.activeby.net: 4229 <br>  u1.hoster.by: 3382 <br>  u2.hoster.by: 3378 <br><br>  DNS unique trouvé: 2462 <br>  Serveurs MX (mail) uniques: 9175 (en plus des services populaires, il y a un nombre suffisant d'administrateurs qui utilisent leurs propres services de messagerie) <br>  Affecté par le transfert de zone DNS: 1011 <br>  Affecté par l'amplification DNS: 531 <br>  Peu de fans CloudFlare: 375 (sur la base des enregistrements NS utilisés) <br><br><h4>  Statistiques CMS </h4><br><img src="https://habrastorage.org/webt/oz/zp/0k/ozzp0kkl6kof-gomjiesmgoju_y.png"><br><br>  <b>CMS - Quantité</b> <br>  WordPress: 5118 <br>  Joomla: 2722 <br>  Bitrix: 1757 <br>  Drupal: 898 <br>  OpenCart: 235 <br>  DataLife: 133 <br>  Magento: 32 <br><br><ul><li>  Installations WordPress potentiellement vulnérables: 2977 </li><li>  Installations potentiellement vulnérables de Joomla: 212 </li><li>  En utilisant le service Google SafeBrowsing, il a été possible d'identifier des sites potentiellement dangereux ou infectés: environ 10 000 (à des moments différents, quelqu'un a réparé, quelqu'un a apparemment cassé, les statistiques ne sont pas entièrement objectives) </li><li>  À propos de HTTP et HTTPS - moins de la moitié des sites du volume trouvé utilisent ce dernier, mais compte tenu du fait que ma base de données n'est pas complète, mais seulement 40% du nombre total, il est fort possible que la plupart de la seconde moitié des sites puissent et communiquent via HTTPS . </li></ul><br><h4>  Statistiques du pare-feu: </h4><br><img src="https://habrastorage.org/webt/1o/pf/qc/1opfqck9bluf4aa2xvjt2aivaks.png"><br><br>  <b>Pare-feu - Numéro</b> <br>  ModSecurity: 4354 <br>  IBM Web App Security: 126 <br>  Meilleure sécurité WP: 110 <br>  CloudFlare: 104 <br>  Imperva SecureSphere: 45 <br>  Juniper WebApp Secure: 45 <br><br><h4>  Statistiques du serveur Web </h4><br><img src="https://habrastorage.org/webt/k1/ru/ut/k1ruutqumvvmoism9bafmdp8oko.png"><br><br>  <b>Serveur Web - Numéro</b> <br>  Nginx: 31752 <br>  Apache: 4042 <br>  IIS: 959 <br><br>  Installations obsolètes et potentiellement vulnérables de Nginx: 20966 <br>  Installations obsolètes et potentiellement vulnérables d'Apache: 995 <br><br>  Malgré le fait que hoster.by soit le leader dans les domaines et l'hébergement, par exemple, en général, Open Contact s'est également distingué, mais la vérité est dans le nombre de sites sur une IP: <br><br><img src="https://habrastorage.org/webt/mq/gu/wj/mqguwjm8_1ggvfo_o5vam20tjto.png"><br><br>  <b>IP - Sites</b> <br>  93.84.119.243: 556 <br>  93.125.99.83: 399 <br>  193.232.92.25: 386 <br><br><img src="https://habrastorage.org/webt/h0/us/nk/h0usnka_tsv0yqqa5jb8vd5wy_k.png"><br><br>  Par e-mail, les statistiques détaillées ont vraiment décidé de ne pas être extraites, non triées par zone de domaine, mais plutôt, il était intéressant de voir l'emplacement des utilisateurs par rapport à des fournisseurs spécifiques: <br><br><ul><li>  Sur le service TUT.BY: 38282 </li><li>  Sur le service Yandex (par | ru): 28127 </li><li>  Sur le service Gmail: 33452 </li><li>  Lié à Facebook: 866 </li><li>  Lié à Twitter: 652 </li><li>  En vedette dans les fuites selon HIBP: 7844 </li><li>  L'intelligence passive a permis d'identifier plus de 13 000 adresses e-mail </li></ul><br>  Comme vous pouvez le voir, l'image globale est assez positive, en particulier l'utilisation active de nginx de la part des hébergeurs.  Cela est peut-être en grande partie dû au type d'hébergement partagé populaire parmi les utilisateurs ordinaires. <br><br>  Du fait que je n'aimais pas vraiment ça - il y a un nombre suffisant de fournisseurs d'hébergement de la main du milieu qui ont remarqué des erreurs comme AXFR, utilisé des versions obsolètes de SSH et Apache et quelques autres problèmes mineurs.  Ici, bien sûr, plus de lumière sur la situation pourrait être apportée par la phase active, mais pour le moment, en vertu de notre législation, il me semble que c'est impossible, et je ne voudrais pas vraiment m'engager dans les rangs des ravageurs pour de telles questions. <br><br>  L'image de l'e-mail est généralement plutôt rose, si vous pouvez l'appeler ainsi.  Oh oui, où le fournisseur TUT.BY est indiqué - cela signifiait utiliser le domaine, car  Ce service fonctionne sur la base de Yandex. <br><br><h2>  Conclusion </h2><br>  En conclusion, je peux dire une chose - même avec les résultats disponibles, vous pouvez rapidement comprendre qu'il y a beaucoup de travail pour les spécialistes impliqués dans le nettoyage des sites contre les virus, la configuration du WAF et la configuration / l'ajout de différents CMS. <br><br>  Eh bien, sérieusement, comme dans les deux articles précédents, nous voyons que les problèmes existent à des niveaux absolument différents dans absolument tous les segments de l'Internet et des pays, et certains d'entre eux proposent même une étude à distance de la question, sans utiliser de méthodes offensantes, etc. e.  utiliser des informations accessibles au public pour collecter les compétences spéciales qui ne sont pas requises. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr446022/">https://habr.com/ru/post/fr446022/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr445992/index.html">Nauchpop au minimum: illusions d'optique</a></li>
<li><a href="../fr445998/index.html">Comment se faire des amis Progress OpenEdge et Oracle DBMS</a></li>
<li><a href="../fr446000/index.html">Quel est le problème avec Yandex.Music? Analyse UX / UI</a></li>
<li><a href="../fr446006/index.html">Intel - un son nouveau</a></li>
<li><a href="../fr446008/index.html">Outil open source pour la validation de la qualité de la recherche basée sur l'intention</a></li>
<li><a href="../fr446024/index.html">Installer et configurer un nœud Ripple</a></li>
<li><a href="../fr446026/index.html">Pourquoi SvelteJS est sans doute le meilleur framework pour les nouveaux développeurs web</a></li>
<li><a href="../fr446028/index.html">Blocs de construction d'applications distribuées. Zéro approximation</a></li>
<li><a href="../fr446030/index.html">Startups dans le domaine de la biotechnologie anti-âge, qui seront pertinentes en 2019</a></li>
<li><a href="../fr446032/index.html">Zoomez des vidéos 1080P en 4K, ou comment j'ai appris à ne pas m'inquiéter et à aimer le haut de gamme en utilisant les réseaux de neurones</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
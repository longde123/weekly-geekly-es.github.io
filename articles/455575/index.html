<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíô ‚ôëÔ∏è üíÉ Neural Matching: c√≥mo adaptar el contenido a las realidades de Google üë©üèø‚Äçü§ù‚Äçüë®üèΩ üíÜüèæ üé±</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los motores de b√∫squeda no tienen mucha l√≥gica, esto es un hecho. Pero lo est√°n intentando. Y los especialistas en SEO intentan responder: intentan al...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neural Matching: c√≥mo adaptar el contenido a las realidades de Google</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/promopult/blog/455575/"><img src="https://habrastorage.org/webt/lk/ma/zj/lkmazjjzfmqxe_oudbr040wnxaa.png"><br><br><p>  Los motores de b√∫squeda no tienen mucha l√≥gica, esto es un hecho.  Pero lo est√°n intentando.  Y los especialistas en SEO intentan responder: intentan alcanzar la m√°xima relevancia de las p√°ginas, bas√°ndose en conjeturas y experimentaci√≥n. </p><br><p>  Google recientemente se complaci√≥ con un nuevo factor de clasificaci√≥n: Neural Matching.  Le√≠mos que los expertos escriben sobre esto y recopilamos algunos trucos que lo ayudar√°n a escribir textos m√°s relevantes para las solicitudes. </p><br><p>  Y, por cierto, NM no es LSI para ti, es un poco m√°s complicado. </p><a name="habracut"></a><br><p>  En septiembre de 2018, Danny Sullivan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tuite√≥</a> que en los √∫ltimos meses, Google ha estado utilizando el m√©todo AI Neural Matching para asociar mejor las palabras con los conceptos.  Este algoritmo influy√≥ en los resultados del 30% de las solicitudes en todo el mundo. </p><br><img src="https://habrastorage.org/webt/yy/-v/rm/yy-vrmtdddxadr5lr2ga9ve_bpc.png"><br><br><p>  No ten√≠amos prisa por escribir sobre el nuevo algoritmo, est√°bamos esperando las aclaraciones de Google y la investigaci√≥n en esta √°rea.  Pero las cosas siguen ah√≠: la mayor√≠a de los comentaristas muestran las mismas capturas de pantalla y hablan sobre la transici√≥n de buscar por palabras a buscar por intenci√≥n.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tambi√©n</a> se refieren al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Modelo de coincidencia de relevancia profunda (DRMM)</a> . </p><br><p>  Intentemos averiguar qu√© tipo de animal es este Neural Matching y c√≥mo adaptar el contenido en el sitio. </p><br><h2>  Ejemplos de emparejamiento neuronal </h2><br><p>  Danny Sullivan describe qu√© es Neural Matching.  Dio un ejemplo de emitir la pregunta "por qu√© mi televisor se ve extra√±o".  El usuario ingresa dicha consulta cuando a√∫n no sabe cu√°l es el efecto de telenovela.  Pero Google, gracias al nuevo algoritmo, sabe exactamente lo que necesita: </p><br><img src="https://habrastorage.org/webt/29/e8/db/29e8db4mufa5fo6__hfkgx5cqwi.jpeg"><br><br><p>  En ruso, una historia similar: </p><br><img src="https://habrastorage.org/webt/gh/2p/io/gh2pioe4hfrdgbhvtnqf9x0cfim.jpeg"><br><br><p>  Otro ejemplo.  Conociste un insecto "hermoso" en el apartamento y no tienes idea de c√≥mo se llama: </p><br><img src="https://habrastorage.org/webt/vw/pb/uy/vwpbuy5onwfkytpq1pc0zgl366i.jpeg"><br><br><p> Vamos a Google, ingresamos un conjunto de caracter√≠sticas y en la primera posici√≥n obtenemos la respuesta relevante: </p><br><img src="https://habrastorage.org/webt/e6/cs/k5/e6csk5pof2yvfsuy1e8fx8jrwcc.jpeg"><br><br><p>  La implementaci√≥n de Neural Matching se debe al hecho de que los usuarios no siempre saben lo que est√°n buscando y no siempre formulan correctamente las solicitudes.  Danny Sullivan mostr√≥ varias consultas "incorrectas": </p><br><img src="https://habrastorage.org/webt/mr/yu/-e/mryu-exwhyt5ms9hk8fae5elxei.jpeg"><br><br><p>  La tarea de Neural Matching es determinar la verdadera <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">intenci√≥n de</a> b√∫squeda (intenci√≥n) y producir los resultados correctos. </p><br><img src="https://habrastorage.org/webt/xl/dg/ks/xldgks3lrvdsq__mpesljf8kuze.jpeg"><br><br><p>  Para determinar la intenci√≥n, no se usan palabras separadas, sino esencias y relaciones entre ellas.  Vea c√≥mo funciona: en el ejemplo de las consultas "se emborrach√≥ qu√© hacer" y "se emborrach√≥ en la noche". </p><br><p>  Cada solicitud contiene la misma entidad: "se emborrach√≥".  Pero combinarlo con la esencia de "durante la noche" le indica al motor de b√∫squeda que el usuario quiere decir comer en exceso.  Y la esencia de "qu√© hacer" probablemente se asocia con la intoxicaci√≥n. </p><br><img src="https://habrastorage.org/webt/5n/oh/dd/5nohddwwhblfa7jv31wsjd4qemk.jpeg"><br><br><p>  ¬øC√≥mo define Google la intenci√≥n? ¬øLa sem√°ntica es similar?  El motor de b√∫squeda compara con qu√© frecuencia las entidades combinadas en la solicitud se encuentran lado a lado en las p√°ginas.  Adem√°s, las estad√≠sticas sobre las solicitudes se tienen en cuenta (los usuarios al ingresar la solicitud "se emborracharon por la noche" con mayor frecuencia hacen clic en art√≠culos espec√≠ficos sobre comer en exceso). </p><br><p>  <strong>Otro ejemplo.</strong>  El usuario ingresa la frase "poner ventanas".  Esta es solo la solicitud "incorrecta" de la que habla Danny Sullivan.  Google entiende que una persona por "poner" significa algo m√°s que una simple instalaci√≥n de ventanas, y muestra en la PARTE SUPERIOR los resultados correctos desde su punto de vista: </p><br><img src="https://habrastorage.org/webt/ph/ss/tg/phsstgnyk01bjxf-mud-ojw0xm4.jpeg"><br><br><p>  En este caso, solo una p√°gina del TOP-6 contiene la palabra "entregar" (en el sentido de "proveedor de ventanas", y no "instalar ventanas usted mismo").  En las p√°ginas restantes del TOP-6 no hay una palabra "put", ni siquiera palabras ra√≠z.  Aunque los resultados como "C√≥mo instalar Windows usted mismo", etc., ya se mezclan a continuaci√≥n. </p><br><p>  Esto lleva a una conclusi√≥n aparentemente parad√≥jica: para ocupar posiciones altas en muchas palabras, no es necesario saturar los textos con una sem√°ntica similar a una consulta de b√∫squeda.  La relevancia del contenido es evaluada por un conjunto de entidades (frases marcadoras), que tienen muchas probabilidades de satisfacer la intenci√≥n de b√∫squeda. </p><br><p>  <strong>Esto cambia el enfoque para escribir textos de SEO: antes las claves eran el punto de referencia, ahora las necesidades de la audiencia.</strong> </p><br><h2>  Clasificaci√≥n de relevancia de documentos y coincidencia neuronal: ¬øc√≥mo afectar√° esto al SEO? </h2><br><p>  Roger Montti sugiri√≥ en un art√≠culo para Search Engine Journal que el algoritmo de Neural Matching podr√≠a funcionar seg√∫n el m√©todo de Clasificaci√≥n de Relevancia de Documentos (DRR).  El m√©todo se describe en el art√≠culo " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Clasificaci√≥n de relevancia profunda utilizando interacciones mejoradas de consulta de documentos</a> " publicado en Google AI. </p><br><p>  La esencia del m√©todo DRR es que al determinar la relevancia de un documento, su texto se usa exclusivamente.  Otros factores (enlaces, anclas, menciones, SEO en la p√°gina) no importan. </p><br><p>  ¬øQu√©, los enlaces ya no son necesarios?  Realmente no es as√≠.  La clasificaci√≥n seg√∫n el m√©todo DRR descrito es parte del algoritmo de clasificaci√≥n general.  En la primera etapa, la emisi√≥n se forma teniendo en cuenta todos los factores de clasificaci√≥n (enlaces, claves, "movilidad", geolocalizaci√≥n, etc.).  Por lo tanto, el motor de b√∫squeda elimina el contenido base e identifica sitios de buena reputaci√≥n.  En la segunda etapa, la RRD ingresa al trabajo; entre los mejores resultados, selecciona los m√°s relevantes (pero solo tiene en cuenta el texto). </p><br><p>  En la pr√°ctica, puede verse as√≠.  Hay dos sitios: uno muy respetable y joven.  El sitio joven contiene s√∫per contenido que no tiene an√°logos en el nicho, lleno de detalles y detalles.  Pero dado que hay m√°s enlaces a un sitio autorizado, su p√°gina ocupa el primer lugar y la p√°gina de un sitio joven ocupa el d√©cimo.  Y aqu√≠ entra en funcionamiento la RRD: el motor de b√∫squeda escanea los textos y se da cuenta de que el contenido del sitio joven es m√°s significativo que el de un sitio autorizado.  La consecuencia es el movimiento del sitio joven a una posici√≥n m√°s alta. </p><br><h2>  C√≥mo hacer contenido en Neural Matching </h2><br><p>  Si Neural Matching funciona en funci√≥n de la RRD o no, no es tan importante.  Es importante que la intenci√≥n de b√∫squeda "conduzca" aqu√≠.  No largos "pa√±os", ni la densidad de palabras clave, ni sin√≥nimos. </p><br><img src="https://habrastorage.org/webt/dt/ii/wn/dtiiwnnqwbx9vjsxwepwf7mqu8g.jpeg"><br><br><p>  Antes de crear contenido, decida: </p><br><ul><li>  para qui√©n es √©l (lo mejor es realizar una investigaci√≥n, hacer retratos de los usuarios y escribir para ellos); </li><li>  por qu√© es necesario (qu√© tarea cierra); </li><li>  qu√© contiene lo que los competidores no tienen (qu√© valor aporta). </li></ul><br><p>  Para aumentar la relevancia de los textos, adem√°s de las consultas b√°sicas, utilice entidades estrechamente relacionadas.  Si el texto est√° escrito por un experto, entonces esas entidades probablemente estar√°n en el texto.  Otra cuesti√≥n es cuando el redactor recibe TK; en este caso, es necesario determinar las entidades e indicarlas en la tarea. </p><br><p>  Consideremos los m√©todos de recopilaci√≥n de entidades utilizando el ejemplo de una categor√≠a de la tienda en l√≠nea "Generadores de gasolina". </p><br><h3>  1. Buscar preguntas / respuestas </h3><br><p>  Puede identificar las necesidades de los usuarios mediante foros, comentarios en art√≠culos de blogs y debates en redes sociales.  Todo funciona  Pero es m√°s f√°cil ir a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Answers@Mail.ru</a> (o la contraparte occidental: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Quora</a> ), ingresar una consulta de b√∫squeda, revisar las preguntas y resaltar las entidades asociadas con las teclas principales. </p><br><p>  A pedido de "generadores de gasolina" mail.ru emite 1624 preguntas.  Revisamos la lista y seleccionamos las entidades que caracterizan las necesidades del p√∫blico objetivo. </p><br><img src="https://habrastorage.org/webt/bb/rp/gx/bbrpgxdk8i4hlbdoqywhvthybns.jpeg"><br><br><img src="https://habrastorage.org/webt/_u/qz/x-/_uqzx-_imraetz4jcbwgdzd1t7i.jpeg"><br><br><p>  Despu√©s de seleccionar las entidades, pensamos qu√© contenido es adecuado para ellas.  Por ejemplo, el consumo de gasolina por 1 hora y los m√©todos de uso del generador (para soldar, para una caldera, para la iluminaci√≥n, etc.) deben indicarse en la descripci√≥n de productos espec√≠ficos.  En la descripci√≥n de la r√∫brica ‚ÄúGeneradores de gasolina‚Äù, puede describir brevemente en qu√© se diferencian los generadores de gasolina del gas, el inversor, etc. En el art√≠culo del blog se describe un problema con el funcionamiento de los generadores. </p><br><p>  El procesamiento de preguntas en los servicios de control de calidad es minucioso, pero le permite resaltar las necesidades reales de la audiencia, de lo que es posible que no haya adivinado. </p><br><p>  Puede intentar simplificar el trabajo utilizando el servicio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Responder al p√∫blico</a> .  Recopila preguntas, comparaciones y diversas formulaciones que ocurren en la red con la aparici√≥n de una frase dada. </p><br><img src="https://habrastorage.org/webt/9o/ab/7y/9oab7ytgb171vqysbqcfdz5lako.jpeg"><br><br><p>  El √∫nico inconveniente es el servicio en ingl√©s.  La traducci√≥n de la frase deseada resuelve parcialmente el problema.  Pero en el segmento comercial, vale la pena recordar las peculiaridades de los mercados (lo que preocupa a los indios puede ser in√∫til para los rusos). </p><br><h3>  2. Analizar frases de asociaci√≥n </h3><br><p>  Debajo de los resultados de b√∫squeda, se muestra el bloque "Junto con ... a menudo buscado": aqu√≠ se recopilan las frases que el propio motor de b√∫squeda asocia con la frase original ("generadores de gasolina"). </p><br><img src="https://habrastorage.org/webt/x7/7j/ec/x77jec90jb_u-uekbe3woungduw.jpeg"><br><br><p>  El an√°lisis de frases de asociaci√≥n le permite identificar entidades relacionadas: 5 kW, 3 kW, 10 kW, inversor, 1 kW. </p><br><p>  Queda por pensar c√≥mo incluirlos en el contenido.  Por ejemplo, en la descripci√≥n de la columna de "generadores impulsados ‚Äã‚Äãpor gasolina", vale la pena decir para qu√© fines son adecuados los generadores de diferente potencia (1, 3, 5, 10 kW) y tipo (inversor, convencional, etc.). </p><br><p>  Si tiene muchas solicitudes iniciales, recopile manualmente las asociaciones durante mucho tiempo; use el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">analizador</a> . </p><br><h3>  3. Analizando sugerencias de b√∫squeda </h3><br><p>  Las sugerencias son otra fuente para hacer coincidir entidades relacionadas. </p><br><img src="https://habrastorage.org/webt/oj/h4/nw/ojh4nwxgw_kkzlt3reyjy1xcyxq.jpeg"><br><br><p>  Reponemos la lista de entidades recopiladas de las asociaciones: con ejecuci√≥n autom√°tica, diesel, 380 voltios, silencioso.  Estas son palabras que caracterizan bien los problemas del usuario. </p><br><p>  Tambi√©n hay un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">analizador</a> para recopilar pistas. </p><br><p>  En principio, los m√©todos discutidos son suficientes para tener una idea de las necesidades de la audiencia.  Pero si desea resolver la sem√°ntica a√∫n m√°s profundamente, aqu√≠ hay dos formas opcionales. </p><br><h3>  4. Selecci√≥n de cuasi-sin√≥nimos </h3><br><p>  Los cuasin√≥nimos (asociaciones sem√°nticas) son palabras que tienen un significado cercano, pero no intercambiables en diferentes contextos.  Por ejemplo, las palabras "generador" y "generador autom√°tico" son sin√≥nimos en el texto sobre repuestos de autom√≥viles, pero no lo ser√°n en el texto sobre tipos de generadores. </p><br><p>  Los cuasin√≥nimos se determinan en funci√≥n de la frecuencia de su aparici√≥n en los textos.  Para resolver este problema, hay un servicio de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RusVect≈çr</a> (secci√≥n "Palabras similares").  Ingrese la palabra de inter√©s, marque todos los modelos y partes del discurso disponibles, y comience la b√∫squeda. </p><br><img src="https://habrastorage.org/webt/b_/ai/7o/b_ai7ocf_ou2w4bdnb9udf5ryr4.png"><br><br><p>  Como resultado, obtendr√° los 10 asociados m√°s importantes para cada modelo de b√∫squeda.  Usarlos a ciegas en la formaci√≥n de TK no vale la pena: aqu√≠ habr√° mucha "basura" (a√∫n es preferible analizar asociaciones basadas en datos de motores de b√∫squeda).  Sin embargo, puedes identificar palabras interesantes.  Por ejemplo, vemos que las palabras "generador de gas", "inversor", "generador de gas", "contactor", etc. est√°n asociadas con la palabra "generador". </p><br><h3>  5. An√°lisis de textos de la competencia </h3><br><p>  Para identificar las necesidades de la audiencia, este m√©todo no es el mejor.  En primer lugar, no se sabe cu√°ndo se cre√≥ el contenido en los sitios web de los competidores (durante este tiempo, las preferencias de b√∫squeda podr√≠an cambiar).  En segundo lugar, no hay garant√≠a de que los competidores hayan analizado cuidadosamente los problemas de la audiencia y hayan creado textos basados ‚Äã‚Äãen ellos. </p><br><p>  Por otro lado, si usa este m√©todo como auxiliar, existe la posibilidad de identificar entidades que podr√≠a perderse. </p><br><p>  Entonces, ingresamos la consulta principal "generadores de gasolina" en la b√∫squeda, copiamos los textos relevantes de los sitios al TOP-10 y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">seleccionamos la</a> sem√°ntica usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Advego</a> : </p><br><img src="https://habrastorage.org/webt/cg/lq/wi/cglqwipgfx17du32ihhr0zb7j_y.jpeg"><br><br><p>  Complementamos la lista de entidades relevantes: 4 tiempos, emergencia, aut√≥noma, ininterrumpida, para casa de verano, para la naturaleza, etc. </p><br><p>  Poniendo todo junto y obteniendo un TK optimizado para Neural Matching. </p><br><h2>  TK para letras: haz Neural Matching, no LSI </h2><br><p>  Despu√©s de recopilar las entidades relevantes, debe escribir el texto.  Pero no basta con especificar las claves y una lista de sin√≥nimos y palabras relacionadas en los TOR, como suele hacerse al ordenar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">textos LSI</a> . </p><br><img src="https://habrastorage.org/webt/w1/xs/jo/w1xsjohqyrbq40nwr7updfkyeoi.png"><br><br><p>  <em>Ejemplo de TK para texto LSI</em> </p><br><p>  Sobre la base de tales conocimientos tradicionales, simplemente con una lista de palabras, a veces se obtienen textos bastante extra√±os. </p><br><p>  Una pr√°ctica com√∫n entre los redactores es escribir un texto, y solo luego ingresar las palabras dadas en √©l.  Esto es m√°s f√°cil, ya que no necesita interrumpir la selecci√≥n e inserci√≥n de palabras en el proceso de redacci√≥n del texto.  Pero tales inserciones retroactivamente pueden romper, y a menudo romper, la l√≥gica y el estilo del texto. </p><br><p>  El texto debajo de Neural Matching trata sobre los usuarios y sus necesidades, no sobre las claves y las palabras m√°s.  Por lo tanto, las caracter√≠sticas puramente de marketing aparecen en TK: descripciones de los consumidores y sus motivos.  Las teclas y las palabras m√°s se desvanecen en el fondo: se usan como marcadores y no como elementos obligatorios.  Su lugar est√° ocupado por las necesidades de informaci√≥n de la audiencia. </p><br><img src="https://habrastorage.org/webt/mi/na/fe/minafe6tad3qlamzsal5e0kxf2m.png"><br><br><p>  <em>Ejemplo TK bajo Neural Matching</em> </p><br><p>  Tal TK le permite al autor entender claramente para qui√©n es el texto, por qu√© y bajo qu√© circunstancias ser√° le√≠do.  Tal TK no solo deletrea las palabras que se usar√°n, sino que da instrucciones sobre qu√© escribir para usar estas palabras. </p><br><p>  Neural Matching, al optimizar las p√°ginas para la b√∫squeda, cambia el √©nfasis de la mec√°nica puramente SEO al marketing.  De hecho, esta tendencia se ha observado durante varios a√±os.  Neural Matching es solo un paso m√°s hacia la optimizaci√≥n de motores de b√∫squeda con rostro humano. </p><br><p>  Optimizar el contenido para Neural Matching requiere tiempo y trabajo de cabeza.  Es mucho m√°s f√°cil soltar las claves del AX en el TK, analizar m√°s palabras y decirle al redactor: "Escribir para la gente".  Pero con el desarrollo de la b√∫squeda de IA, este enfoque ser√° cada vez menos efectivo. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/455575/">https://habr.com/ru/post/455575/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../455559/index.html">¬øC√≥mo puede una computadora cu√°ntica entrar en los sistemas modernos de encriptaci√≥n y reducir el costo de producci√≥n de amon√≠aco?</a></li>
<li><a href="../455563/index.html">Peque√±as empresas: ¬øAutomatizar o no?</a></li>
<li><a href="../455565/index.html">¬øPuede la mente fingir el universo?</a></li>
<li><a href="../455569/index.html">Te invitamos a la Conferencia de Tarantool el 17 de junio.</a></li>
<li><a href="../455571/index.html">Cursores DB en Doctrine</a></li>
<li><a href="../455577/index.html">SDL 2 Lecciones: Lecci√≥n 3 - Eventos</a></li>
<li><a href="../455579/index.html">Tupperware: ¬øel asesino de Facebook Kubernetes?</a></li>
<li><a href="../455580/index.html">Impresiones de aplicaciones m√≥viles imprescindibles</a></li>
<li><a href="../455582/index.html">Navegaci√≥n en la tienda: a trav√©s de la realidad aumentada hasta el estante deseado</a></li>
<li><a href="../455584/index.html">Entrevistas personalizadas con las fuerzas internas de la empresa: desde errores hasta descubrimientos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
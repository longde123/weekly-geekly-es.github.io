<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüë®‚Äçüë¶‚Äçüë¶ üò© üÜí C√≥mo generar sonido binaural en una pista de audio monocanal: el video ayudar√° üë©üèø‚Äçüé® üë©üèº üå≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los especialistas de la Universidad de Texas en Austin (UT Austin) han desarrollado una red neuronal que procesa grabaciones de audio monocanal en vid...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo generar sonido binaural en una pista de audio monocanal: el video ayudar√°</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/audiomania/blog/436696/">  Los especialistas de la Universidad de Texas en Austin (UT Austin) han <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desarrollado una</a> red neuronal que procesa grabaciones de audio monocanal en video y recrea su sonido "envolvente". <br><br>  Te contamos c√≥mo funciona. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/webt/xu/ry/o3/xuryo3tf8x35qjyqidooxlh-aao.jpeg"></a> <a name="habracut"></a><br>  <font color="#A9A9A9"><i>Foto de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">marneejill</a> / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CC BY-SA</a></i></font> <br><br><h2>  Nuevo m√©todo de creaci√≥n de sonido 3D </h2><br>  El sonido envolvente a menudo se encuentra en juegos o pel√≠culas, pero el sonido 3D es raro en videos condicionales en la red.  La grabaci√≥n requiere un equipo costoso que no siempre est√° disponible para los creadores del video; a menudo solo se usan tel√©fonos inteligentes para disparar. <br><br>  Una pista de audio grabada de esta manera limita nuestra percepci√≥n del video: no puede transmitir c√≥mo se ubican las fuentes de sonido en el espacio y c√≥mo se mueven.  Debido a esto, el sonido del video puede sentirse "plano". <br><br>  UT Austin fue abordado por una profesora universitaria, Kristen Grauman, y un estudiante, Ruohan Gao.  Crearon un sistema basado en algoritmos de aprendizaje autom√°tico que hace posible convertir la grabaci√≥n de audio monocanal en grabaci√≥n de video "envolvente".  La tecnolog√≠a se llama "2.5D Visual Sound". <br><br>  Este no es un sonido espacial completo, sino "modelado".  Sin embargo, seg√∫n los desarrolladores, para el oyente promedio, la diferencia ser√° casi imperceptible. <br><br><h2>  ¬øC√≥mo funciona la tecnolog√≠a? </h2><br>  El sistema desarrollado en UT Austin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">usa</a> dos redes neuronales. <br><br>  La primera red neuronal se cre√≥ sobre la base de la arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ResNet</a> , que fue presentada por investigadores de Microsoft en 2015.  Reconoce objetos en el video y recopila informaci√≥n sobre su movimiento en el cuadro.  En la salida, la red genera una matriz llamada mapa de caracter√≠sticas, con las coordenadas de los objetos en cada cuadro del video. <br><br>  Esta informaci√≥n se transmite a la segunda red neuronal: Mono2Binaural.  Fue desarrollado en la Universidad de Texas.  La red tambi√©n recibe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">espectrogramas de</a> grabaciones <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de</a> audio obtenidas usando la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transformaci√≥n de Fourier de ventana</a> usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la funci√≥n Hann</a> . <br><br>  Mono2Binaural consta de diez capas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">convolucionales</a> .  Despu√©s de cada una de estas capas en la red, hay un bloque de normalizaci√≥n por lotes, que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aumenta la</a> precisi√≥n del pron√≥stico del algoritmo, y un bloque de rectificaci√≥n lineal con la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">funci√≥n de activaci√≥n</a> ReLU. <br><br>  Las capas convolucionales de la red neuronal analizan los cambios de frecuencia en el espectrograma y componen una matriz que contiene informaci√≥n sobre qu√© parte del espectrograma debe pertenecer al canal de audio izquierdo y cu√°l a la derecha.  Luego, usando la ventana inversa Transformada de Fourier, se genera una nueva grabaci√≥n de audio. <br><br>  Al mismo tiempo, Mono2Binaural puede reproducir sonido espacial para cada uno de los objetos en el video por separado.  Por ejemplo, una red neuronal puede reconocer dos instrumentos en un video, un tambor y una tuber√≠a, y crear una pista de sonido separada para cada uno de ellos. <br><br><h2>  Opiniones sobre "Sonido Visual 2.5D" </h2><br>  Seg√∫n los propios desarrolladores, lograron crear una tecnolog√≠a que recrea una "sensaci√≥n espacial realista".  Mono2Binaural mostr√≥ un buen resultado durante las pruebas y, por lo tanto, los autores est√°n seguros de que su proyecto tiene un gran potencial. <br><br>  Para demostrar la efectividad de su tecnolog√≠a, los expertos realizaron una serie de experimentos.  Invitaron a un grupo de personas que compararon el sonido de dos pistas: una fue creada usando Mono2Binaural y la segunda usando el m√©todo Ambisonics. <br><br>  Este √∫ltimo fue desarrollado en la Universidad de California en San Diego.  Este m√©todo tambi√©n crea audio "envolvente" desde monosound, pero, a diferencia de la nueva tecnolog√≠a, solo funciona con videos de 360 ‚Äã‚Äãgrados. <br><br><blockquote>  La mayor√≠a de los oyentes eligieron el audio Mono2Binaural como el m√°s cercano al sonido real.  Las pruebas tambi√©n mostraron que en el 60% de los casos, los usuarios identificaron con precisi√≥n la ubicaci√≥n de la fuente de sonido de o√≠do. </blockquote><br>  El algoritmo todav√≠a tiene algunas desventajas.  Por ejemplo, una red neuronal no distingue entre los sonidos de una gran cantidad de objetos.  Adem√°s, obviamente, no podr√° determinar la posici√≥n de la fuente de sonido, que no est√° en el video.  Sin embargo, los desarrolladores planean resolver estos problemas. <br><br><h2>  Anal√≥gicos tecnol√≥gicos </h2><br>  En el campo del reconocimiento de sonido de video, hay varios proyectos similares.  Escribimos sobre uno de ellos antes.  Este es un " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">micr√≥fono visual</a> " de expertos del MIT.  Su algoritmo reconoce las vibraciones microsc√≥picas de los objetos bajo la influencia de las ondas ac√∫sticas en un video silencioso y restaura el sonido que se escuch√≥ en la sala en funci√≥n de estos datos.  Los cient√≠ficos pudieron "leer" la melod√≠a de la canci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mary Had a Little Lamb</a> de un paquete de papas fritas, plantas caseras e incluso ladrillos. <br><br><img src="https://habrastorage.org/webt/k_/8l/vs/k_8lvsrouc7mc8czmgv_kytfp1y.jpeg"><br>  <font color="#A9A9A9"><i>Foto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Quinn Dombrowski</a> / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CC BY-SA</a></i></font> <br><br>  Otros proyectos est√°n desarrollando tecnolog√≠as para grabar sonido en videos de 360 ‚Äã‚Äãgrados.  Uno de ellos es Ambisonics, que mencionamos anteriormente.  El principio del algoritmo es similar a Mono2Binaural: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">analiza el</a> movimiento de los objetos en el marco y los correlaciona con los cambios en el sonido.  Sin embargo, la tecnolog√≠a Ambisonics tiene varias limitaciones: la red neuronal solo funciona con videos de 360 ‚Äã‚Äãgrados y no emite bien el sonido si hay un eco en la grabaci√≥n. <br><br>  Otro proyecto en esta √°rea es Sol VR360 de G-Audio.  A diferencia de otros desarrollos, la tecnolog√≠a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ya se ha implementado</a> en el servicio de usuario para el procesamiento de sonido de Sol.  Crea audio espacial para videos de 360 ‚Äã‚Äãgrados de conciertos o deportes.  La desventaja del servicio es que los clips generados se reproducen solo en aplicaciones Sol. <br><br><h2>  Conclusiones </h2><br>  Los desarrolladores de sistemas para crear sonido espacial ven el campo principal de aplicaci√≥n de la tecnolog√≠a en aplicaciones VR y AR para la m√°xima inmersi√≥n de una persona en la atm√≥sfera de un juego o pel√≠cula.  Si es posible superar una serie de dificultades que enfrentan, la tecnolog√≠a tambi√©n se puede utilizar para ayudar a las personas con discapacidad visual.  Con la ayuda de dichos sistemas, podr√°n comprender con m√°s detalle lo que sucede en el marco de los videos. <br><br><hr><br>  <i>M√°s sobre tecnolog√≠a de audio en nuestro canal de Telegram:</i> <i><br><br></i>  <i>A.</i> <i><img src="https://habrastorage.org/webt/xq/5o/_r/xq5o_rmc8w8juvbckkxdgn5adaw.png"></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">InSight grab√≥ por primera vez los sonidos del viento marciano</a></i> <i><br><img src="https://habrastorage.org/webt/xq/5o/_r/xq5o_rmc8w8juvbckkxdgn5adaw.png"></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ocho tecnolog√≠as de audio que ingresar√°n al Sal√≥n de la Fama de TECnology en 2019</a></i> <i><br><img src="https://habrastorage.org/webt/xq/5o/_r/xq5o_rmc8w8juvbckkxdgn5adaw.png"></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Las ventanas activas con cancelaci√≥n de ruido ahogan los sonidos de la metr√≥poli</a></i> <br><br><hr></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436696/">https://habr.com/ru/post/es436696/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436686/index.html">JPEG del mundo 3D. ¬øQu√© es glTF?</a></li>
<li><a href="../es436688/index.html">El gigante de TI abandona el mercado de chips para centros de datos: cu√©ntenos qu√© significa para la industria</a></li>
<li><a href="../es436690/index.html">[Preguntar - responder] sobre propiedad intelectual y protecci√≥n de datos</a></li>
<li><a href="../es436692/index.html">(in) Guerra finita</a></li>
<li><a href="../es436694/index.html">Mi compilador Pascal y arte contempor√°neo polaco</a></li>
<li><a href="../es436698/index.html">¬øDe cu√°ntas maneras puedo escribir factorial en Scheme?</a></li>
<li><a href="../es436700/index.html">Anti-spoofing: ¬øc√≥mo resisten los sistemas de reconocimiento facial a los estafadores?</a></li>
<li><a href="../es436704/index.html">La historia de c√≥mo elegimos escalas para la automatizaci√≥n de cajas registradoras</a></li>
<li><a href="../es436708/index.html">En qu√© consiste IoT</a></li>
<li><a href="../es436710/index.html">Las tendencias del mercado de gamedev del a√±o 2019 en mi humilde opini√≥n. Descentralizaci√≥n?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
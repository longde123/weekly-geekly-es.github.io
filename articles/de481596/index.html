<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçüíª üèÄ üêÇ Analysieren der ELK 7.5-Einstellungen f√ºr die Mikrotik-Protokollanalyse üë®üèæ üíáüèº üë®üèø‚ÄçüöÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es war lange eine Idee zu sehen, was Sie mit ELK und improvisierten Quellen f√ºr Protokolle und Statistiken tun k√∂nnen. Auf den Seiten des Habr m√∂chte ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analysieren der ELK 7.5-Einstellungen f√ºr die Mikrotik-Protokollanalyse</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/481596/">  Es war lange eine Idee zu sehen, was Sie mit ELK und improvisierten Quellen f√ºr Protokolle und Statistiken tun k√∂nnen.  Auf den Seiten des Habr m√∂chte ich ein praktisches Beispiel zeigen, wie Sie mit einem Heim-Mini-Server beispielsweise einen Honeypot mit einem Protokollanalysesystem auf der Basis des ELK-Stacks erstellen k√∂nnen.  In diesem Artikel werde ich Ihnen das einfachste Beispiel f√ºr die Analyse von Firewall-Protokollen mit dem ELK-Stack erl√§utern.  In Zukunft m√∂chte ich die Umgebungseinstellungen f√ºr die Analyse von Netflow-Verkehr und PCAP-Dumps von Zeek beschreiben. <br><br><img src="https://habrastorage.org/webt/ze/cb/qx/zecbqxrubn4v0mutaoewxzsp1zm.png"><br><br>  Wenn Sie eine √∂ffentliche IP-Adresse und ein mehr oder weniger intelligentes Ger√§t als Gateway / Firewall haben, k√∂nnen Sie einen passiven Honeypot organisieren, indem Sie die Protokollierung eingehender Anforderungen an "k√∂stlichen" TCP- und UDP-Ports konfigurieren.  Es gibt ein Beispiel f√ºr die Konfiguration eines Mikrotik-Routers unter dem Cutter. Wenn Sie jedoch einen Router eines anderen Herstellers (oder ein anderes Sicherheitssystem) zur Hand haben, m√ºssen Sie nur einige Datenformate und herstellerspezifische Einstellungen herausfinden, und Sie erhalten das gleiche Ergebnis. <br><br><h3>  Haftungsausschluss </h3><br>  Der Artikel gibt nicht vor, originell zu sein. Er befasst sich nicht mit Fragen der Fehlertoleranz von Diensten, der Sicherheit, bew√§hrten Methoden usw.  Es ist notwendig, dieses Material als akademisch zu betrachten. Es ist geeignet, um mit der Grundfunktionalit√§t des ELK-Stacks und dem Protokollanalysemechanismus des Netzwerkger√§ts vertraut zu werden.  Es k√∂nnte jedoch auch f√ºr Anf√§nger interessant sein. <br><br>  Das Projekt wird √ºber die Docker-Compose-Datei gestartet. Die Bereitstellung einer √§hnlichen Umgebung ist sehr einfach. Auch wenn Sie einen Router eines anderen Anbieters zur Hand haben, m√ºssen Sie nur ein wenig √ºber Datenformate und herstellerspezifische Einstellungen wissen.  Im √úbrigen habe ich versucht, alle mit der Konfiguration von Logstash-Pipelines und Elasticsearch-Zuordnungen in der aktuellen Version von ELK verbundenen Nuancen so detailliert wie m√∂glich zu beschreiben.  Alle Komponenten dieses Systems werden auf <a href="https://github.com/mekhanme/elk-mikrot" rel="nofollow">github</a> gehostet, einschlie√ülich Dienstkonfigurationen.  Am Ende des Artikels werde ich den Abschnitt Fehlerbehebung ausf√ºhren, in dem die Schritte zur Diagnose der g√§ngigen Probleme beschrieben werden, mit denen Neulinge in diesem Gesch√§ft konfrontiert sind. <br><a name="habracut"></a><br><h3>  Einleitung </h3><br>  Auf dem Server selbst habe ich das Proxmox-Virtualisierungssystem installiert, auf dem auf dem KVM-Rechner Docker-Container gestartet werden.  Es wird davon ausgegangen, dass Sie wissen, wie Docker und Docker-Compose funktionieren, da es gen√ºgend Konfigurationsbeispiele zur Internetnutzung gibt.  Ich werde nicht auf die Probleme bei der Installation von Docker eingehen, sondern ein wenig √ºber Docker-Compose schreiben. <br><br>  Die Idee, Honeypot auf den Markt zu bringen, entstand w√§hrend des Studiums von Elasticsearch, Logstash und Kibana.  In meiner beruflichen Laufbahn war ich noch nie mit der Verwaltung und allgemeinen Verwendung dieses Stacks befasst, aber ich habe Hobbyprojekte durchgef√ºhrt, die mich sehr daran interessiert haben, die M√∂glichkeiten der Elasticsearch- und Kibana-Suchmaschine zu erkunden, mit denen Daten analysiert und visualisiert werden k√∂nnen. <br><br>  Mein nicht der neueste Mini-NUC-Server mit 8 GB RAM reicht gerade aus, um den ELK-Stack mit einem Elastic-Knoten zu starten.  In Produktionsumgebungen ist dies nat√ºrlich nicht zu empfehlen, aber genau richtig f√ºr das Training.  Zum Thema Sicherheit steht am Ende des Artikels eine Bemerkung. <br><br>  Das Internet enth√§lt <a href="https://habr.com/ru/post/324760/">zahlreiche</a> Anweisungen zum Installieren und Konfigurieren des ELK-Stacks f√ºr √§hnliche Aufgaben (z. B. <a href="https://habr.com/ru/post/324760/">Analysieren von Brute-Force-Angriffen auf ssh mit Logstash Version 2</a> , <a href="https://habr.com/ru/post/431600/">Analysieren von Suricata-Protokollen mit Filebeat Version 6</a> ). In den meisten F√§llen wird jedoch nicht auf Details geachtet 90 Prozent des Materials werden f√ºr die Versionen 1 bis 6 sein (zum Zeitpunkt des Schreibens ist die aktuelle Version von ELK 7.5.0).  Dies ist wichtig, da Elasticsearch ab Version 6 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html" rel="nofollow">beschlossen hat, die</a> Entit√§t "Zuordnungstyp" <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html" rel="nofollow">zu entfernen</a> , wodurch die Abfragesyntax und die Zuordnungsstruktur ge√§ndert wurden.  Das Zuordnen von Vorlagen in Elastic ist im Allgemeinen ein sehr wichtiges Objekt, und damit sp√§ter keine Probleme mit der Datenerfassung und -visualisierung auftreten, rate ich Ihnen, sich nicht auf das Kopieren und Einf√ºgen einzulassen und zu versuchen, zu verstehen, was Sie tun.  Weiterhin werde ich versuchen klar zu erkl√§ren, was die beschriebenen Operationen und Konfigurationen bedeuten. <br><br><h2>  Router einrichten </h2><br>  F√ºr das Heimnetzwerk verwende ich Mikrotik als Router, also wird ein Beispiel f√ºr ihn sein.  Fast jedes System kann so konfiguriert werden, dass Syslog an einen Remote-Server gesendet wird, sei es ein Router, ein Server oder ein anderes Sicherheitssystem, das Protokolle erstellt. <br><br><h3>  Senden von Syslog-Nachrichten an einen Remote-Server </h3><br>  Um in Mikrotik die Protokollierung auf einem Remote-Server √ºber die CLI zu konfigurieren, geben Sie einfach ein paar Befehle ein: <br><br><pre><code class="plaintext hljs">/system logging action add remote=192.168.88.130 remote-port=5145 src-address=192.168.88.1 name=logstash target=remote /system logging add action=logstash topics=info</code> </pre> <br><h3>  Konfigurieren von Firewallregeln mit der Protokollierung </h3><br>  Wir interessieren uns nur f√ºr bestimmte Daten (Hostname, IP-Adresse, Benutzername, URL usw.), aus denen Sie eine sch√∂ne Visualisierung oder Auswahl erhalten k√∂nnen.  Um Informationen zu Port-Scans und Zugriffsversuchen zu erhalten, m√ºssen Sie im einfachsten Fall die Firewall-Komponente so konfigurieren, dass sie Regel-Trigger protokolliert.  Ich habe die Regeln in der NAT-Tabelle in Mikrotik und nicht in Filter konfiguriert, da ich in Zukunft Chanipots einrichten werde, die die Arbeit von Diensten emulieren. Auf diese Weise kann ich mehr Informationen √ºber das Verhalten von Botnetzen erhalten, dies ist jedoch ein fortgeschritteneres Szenario und nicht zu diesem Zeitpunkt. <br><br>  Achtung!  In der folgenden Konfiguration wird der Standard-TCP-Port des SSH-Dienstes (22) in das lokale Netzwerk eingeschleift.  Wenn Sie mit SSH von au√üen auf den Router zugreifen und die Einstellungen √ºber Port 22 verf√ºgen ( <i>IP-Dienst</i> in der CLI <i>drucken</i> und <i>IP&gt; -Dienste</i> in Winbox), sollten Sie den Port f√ºr Management-SSH neu zuweisen oder die letzte Regel nicht in die Tabelle eingeben. <br>  Abh√§ngig vom Namen der WAN-Schnittstelle (wenn die WAN-Bridge nicht verwendet wird) m√ºssen Sie auch den Parameter f√ºr die <i>Schnittstelle</i> in den entsprechenden √§ndern. <br><br><pre> <code class="plaintext hljs">/ip firewall nat add action=netmap chain=dstnat comment="HONEYPOT RDP" dst-port=3389 in-interface=bridge-wan log=yes log-prefix=honeypot_rdp protocol=tcp to-addresses=192.168.88.201 to-ports=3389 add action=netmap chain=dstnat comment="HONEYPOT ELASTIC" dst-port=9200 in-interface=bridge-wan log=yes log-prefix=honeypot_elastic protocol=tcp to-addresses=192.168.88.201 to-ports=9211 add action=netmap chain=dstnat comment=" HONEYPOT TELNET" dst-port=23 in-interface=bridge-wan log=yes log-prefix=honeypot_telnet protocol=tcp to-addresses=192.168.88.201 to-ports=2325 add action=netmap chain=dstnat comment="HONEYPOT DNS" dst-port=53 in-interface=bridge-wan log=yes log-prefix=honeypot_dns protocol=udp to-addresses=192.168.88.201 to-ports=9953 add action=netmap chain=dstnat comment="HONEYPOT FTP" dst-port=21 in-interface=bridge-wan log=yes log-prefix=honeypot_ftp protocol=tcp to-addresses=192.168.88.201 to-ports=9921 add action=netmap chain=dstnat comment="HONEYPOT SMTP" dst-port=25 in-interface=bridge-wan log=yes log-prefix=honeypot_smtp protocol=tcp to-addresses=192.168.88.201 to-ports=9925 add action=netmap chain=dstnat comment="HONEYPOT SMB" dst-port=445 in-interface=bridge-wan log=yes log-prefix=honeypot_smb protocol=tcp to-addresses=192.168.88.201 to-ports=9445 add action=netmap chain=dstnat comment="HONEYPOT MQTT" dst-port=1883 in-interface=bridge-wan log=yes log-prefix=honeypot_mqtt protocol=tcp to-addresses=192.168.88.201 to-ports=9883 add action=netmap chain=dstnat comment="HONEYPOT SIP" dst-port=5060 in-interface=bridge-wan log=yes log-prefix=honeypot_sip protocol=tcp to-addresses=192.168.88.201 to-ports=9060 add action=dst-nat chain=dstnat comment="HONEYPOT SSH" dst-port=22 in-interface=bridge-wan log=yes log-prefix=honeypot_ssh protocol=tcp to-addresses=192.168.88.201 to-ports=9922</code> </pre> <br><img src="https://habrastorage.org/webt/of/dm/jo/ofdmjo5n3f8fi54udyvbixhaifm.png"><br><br>  In Winbox wird dasselbe auf der <i>Registerkarte IP&gt; Firewall&gt; NAT</i> konfiguriert. <br><br>  Der Router leitet nun die empfangenen Pakete an die lokale Adresse 192.168.88.201 und den benutzerdefinierten Port weiter.  Momentan h√∂rt niemand auf diese Ports, sodass die Verbindungen unterbrochen werden.  In Zukunft k√∂nnen Sie in Docker Honeypot ausf√ºhren, von denen es f√ºr jeden Dienst viele gibt.  Wenn dies nicht geplant ist, sollten Sie anstelle von NAT-Regeln eine Regel mit der Drop-Aktion in die Filterkette schreiben. <br><br><h3>  Starten von ELK mit Docker-Compose </h3><br>  Als N√§chstes k√∂nnen Sie die Komponente konfigurieren, die die Protokolle verarbeitet.  Ich rate Ihnen, das Repository sofort zu √ºben und zu klonen, um die Konfigurationsdateien vollst√§ndig anzuzeigen.  Alle beschriebenen Configs sind dort zu sehen, im Text des Artikels werde ich nur einen Teil der Configs kopieren. <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ git clone https://github.com/mekhanme/elk-mikrot.git</code> </pre> <br><img src="https://habrastorage.org/webt/95/_b/9g/95_b9gu4scfg99nwtyfph-0pf7o.png"><br><br>  In einer Test- oder Entwicklungsumgebung ist es am bequemsten, Docker-Container mit docker-compose auszuf√ºhren.  In diesem Projekt verwende ich zur Zeit die Docker-Compose-Datei der neuesten <a href="https://docs.docker.com/compose/compose-file/" rel="nofollow">Version 3.7</a> . Sie erfordert die Docker-Engine-Version 18.06.0+. Es lohnt sich daher, den <a href="https://docs.docker.com/install/linux/docker-ce/centos/" rel="nofollow">Docker</a> zu aktualisieren und <a href="https://docs.docker.com/compose/install/" rel="nofollow">Docker-Compose zu verwenden</a> . <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl -L "https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose ‚ùØ‚ùØ chmod +x /usr/local/bin/docker-compose</code> </pre> <br>  Da in den letzten Versionen von Docker-Compose der Parameter mem_limit entfernt und Deploy hinzugef√ºgt wurde, der nur im Schwarmmodus ausgef√ºhrt wird ( <i>Docker-Stack-Deploy</i> ), f√ºhrt das Starten der <i>Docker-Compose-Up-</i> Konfiguration mit Einschr√§nkungen zu einem Fehler.  Da ich keinen Schwarm verwende und Ressourcenlimits haben m√∂chte, muss ich ihn mit der Option <i>--compatibility</i> starten, mit der die Limits von Docker-Compose-Versionen in Nicht-Schwei√ü-√Ñquivalente konvertiert werden. <br><br>  Testlauf aller Container (im Hintergrund -d): <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker-compose --compatibility up -d</code> </pre> <br>  Sie m√ºssen warten, bis alle Bilder heruntergeladen wurden, und nachdem der Start abgeschlossen ist, k√∂nnen Sie den Status der Container mit dem folgenden Befehl √ºberpr√ºfen: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker-compose --compatibility ps</code> </pre> <br>  Aufgrund der Tatsache, dass sich alle Container im selben Netzwerk befinden (wenn Sie das Netzwerk nicht explizit angeben, wird eine neue Br√ºcke erstellt, die f√ºr dieses Szenario geeignet ist) und docker-compose.yml den Parameter container_name f√ºr alle <i>Container enth√§lt</i> , verf√ºgen die Container bereits √ºber eine Verbindung √ºber das integrierte DNS Hafenarbeiter.  Infolgedessen ist es nicht erforderlich, IP-Adressen in Container-Konfigurationen zu registrieren.  In der Logstash-Konfiguration ist das Subnetz 192.168.88.0/24 als lokal registriert, weiter unten in der Konfiguration finden Sie n√§here Erl√§uterungen, nach denen Sie das Beispiel der Konfiguration vor dem Start ablenken k√∂nnen. <br><br><h2>  Konfigurieren Sie ELK Services </h2><br>  Des Weiteren werden Erkl√§rungen zur Konfiguration der Funktionen der ELK-Komponenten sowie einige weitere Aktionen gegeben, die in Elasticsearch ausgef√ºhrt werden m√ºssen. <br><br>  Um die geografischen Koordinaten anhand der IP-Adresse zu ermitteln, m√ºssen Sie die kostenlose <a href="https://dev.maxmind.com/geoip/geoip2/geolite2/" rel="nofollow">GeoLite2-</a> Datenbank von MaxMind herunterladen: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ cd elk-mikrot &amp;&amp; mkdir logstash/geoip_db ‚ùØ‚ùØ curl -O https://geolite.maxmind.com/download/geoip/database/GeoLite2-City-CSV.zip &amp;&amp; unzip GeoLite2-City-CSV.zip -d logstash/geoip_db &amp;&amp; rm -f GeoLite2-City-CSV.zip ‚ùØ‚ùØ curl -O https://geolite.maxmind.com/download/geoip/database/GeoLite2-ASN-CSV.zip &amp;&amp; unzip GeoLite2-ASN-CSV.zip -d logstash/geoip_db &amp;&amp; rm -f GeoLite2-ASN-CSV.zip</code> </pre> <br><h3>  Logstash-Setup </h3><br>  Die Hauptkonfigurationsdatei ist <i>logstash.yml</i> , in der ich die Option zum automatischen <i>erneuten</i> Laden der Konfiguration registriert habe. Die restlichen Einstellungen f√ºr die Testumgebung sind nicht von Bedeutung.  Die Konfiguration der Datenverarbeitung (Protokolle) in Logstash wird in separaten <i>conf-</i> Dateien beschrieben, die normalerweise im <i>Pipeline-</i> Verzeichnis gespeichert sind.  Wenn in dem Schema <a href="https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html" rel="nofollow">mehrere Pipelines</a> verwendet werden, beschreibt die Datei <a href="https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html" rel="nofollow">pipelines.yml</a> die aktivierten <i>Pipelines</i> .  Eine Pipeline ist eine Aktionskette f√ºr unstrukturierte Daten, um am Ausgang Daten mit einer bestimmten Struktur zu erhalten.  Ein Schema mit separat konfigurierter <i>pipelines.yml</i> ist optional. Sie k√∂nnen darauf verzichten, indem Sie alle configs aus dem bereitgestellten <i>Pipeline-</i> Verzeichnis herunterladen. Mit einer bestimmten <i>pipelines.yml-</i> Datei ist die Konfiguration jedoch flexibler, da Sie die <i>conf-</i> Dateien aus dem <i>Pipeline-</i> Verzeichnis <i>ein-</i> und ausschalten k√∂nnen notwendige configs.  Dar√ºber hinaus funktioniert das Neuladen von Konfigurationen nur im Schema mit mehreren Pipelines. <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ cat logstash/config/pipelines.yml - pipeline.id: logstash-mikrot path.config: "pipeline/logstash-mikrot.conf"</code> </pre> <br>  Als n√§chstes kommt der wichtigste Teil der Logstash-Konfiguration.  Die Pipeline-Beschreibung besteht aus mehreren Abschnitten - zu Beginn werden die Plugins im Abschnitt <i>Input</i> angezeigt, mit deren Hilfe Logstash Daten empf√§ngt.  Der einfachste Weg, Syslog von einem Netzwerkger√§t zu sammeln, ist die Verwendung der <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-tcp.html" rel="nofollow">tcp</a> / <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-udp.html" rel="nofollow">udp-</a> Eingabe-Plugins.  Der einzige erforderliche Parameter f√ºr diese Plugins ist <i>port</i> . Er muss wie in den Router-Einstellungen angegeben werden. <br><br>  Der zweite Abschnitt ist <i>Filter</i> , der weitere Aktionen mit Daten vorschreibt, die noch nicht strukturiert wurden.  In meinem Beispiel werden unn√∂tige Syslog-Nachrichten von einem Router mit bestimmtem Text gel√∂scht.  Dies geschieht mit der Bedingung und der Standard- <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-drop.html" rel="nofollow"><i>Drop-</i></a> Aktion, die die gesamte Nachricht verwirft, wenn die Bedingung erf√ºllt ist.  In der <a href="https://www.elastic.co/guide/en/logstash/7.5/event-dependent-configuration.html" rel="nofollow">Bedingung</a> wird das <i>Nachrichtenfeld</i> auf das Vorhandensein von bestimmtem Text √ºberpr√ºft. <br><br><img src="https://habrastorage.org/webt/iq/j0/ut/iqj0utufb6itcsrwspxi9qw4e2c.png"><br><br>  Wenn die Nachricht nicht abf√§llt, geht sie weiter die Kette hinunter und tritt in den <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-grok.html" rel="nofollow"><i>Grok-</i></a> Filter ein.  Wie die Dokumentation sagt, ist <i>grok eine gro√üartige M√∂glichkeit, unstrukturierte Protokolldaten in strukturierte und abfragbare Daten zu zerlegen</i> .  Dieser Filter wird verwendet, um Protokolle verschiedener Systeme (Linux-Syslog, Webserver, Datenbank, Netzwerkger√§te usw.) zu verarbeiten.  Basierend auf <a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns" rel="nofollow">vorgefertigten Mustern k√∂nnen</a> Sie ohne gro√üen Zeitaufwand einen Parser f√ºr mehr oder weniger sich wiederholende Sequenzen erstellen.  Es ist praktisch, einen <a href="http://grokdebug.herokuapp.com/" rel="nofollow">Online-Parser</a> zur Validierung zu verwenden (in der neuesten Version von Kibana finden Sie √§hnliche Funktionen im Abschnitt <i>Entwicklungstools</i> ). <br><br><img src="https://habrastorage.org/webt/_g/9q/ky/_g9qkyst3-na7a2i8mhxwf8avw0.gif"><br><br>  Der <i>Datentr√§ger "./logstash/patterns:/usr/share/logstash/patterns" ist</i> in der Datei <i>docker-compose.yml</i> registriert. Im <i>Verzeichnis</i> <i>patterns</i> befindet sich eine Datei mit Standard-Community-Mustern (nur aus <i>Gr√ºnden</i> der <i>Benutzerfreundlichkeit</i> <i>,</i> falls ich das vergessen habe) sowie eine Datei mit Analog zu den Mustern verschiedener Arten von Mikrotik-Nachrichten ( <i>Firewall-</i> und <i>Auth-</i> Module <i>)</i> k√∂nnen Sie Ihre eigenen Vorlagen f√ºr Nachrichten mit einer anderen Struktur hinzuf√ºgen. <br><br>  Die Standardoptionen <i>add_field</i> und <i>remove_field</i> erm√∂glichen das Hinzuf√ºgen oder Entfernen von Feldern zu der Nachricht, die in einem beliebigen Filter verarbeitet wird.  In diesem Fall wird das <i>Hostfeld</i> gel√∂scht, das den Hostnamen enth√§lt, von dem die Nachricht empfangen wurde.  In meinem Beispiel gibt es nur einen Host, sodass dieses Feld keinen Sinn macht. <br><br>  Au√üerdem habe ich im <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-cidr.html" rel="nofollow"><i>selben</i></a> Filterabschnitt den <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-cidr.html" rel="nofollow"><i>cidr-</i></a> Filter registriert, der das Feld mit der IP-Adresse auf √úbereinstimmung mit der Eintragsbedingung im angegebenen Subnetz √ºberpr√ºft und das Tag <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-cidr.html" rel="nofollow"><i>einf√ºgt</i></a> .  Basierend auf dem Tag in der weiteren Kette werden Aktionen ausgef√ºhrt oder nicht ausgef√ºhrt (falls dies ausdr√ºcklich der Fall ist, um in Zukunft keine Geoip-Suche nach lokalen Adressen durchzuf√ºhren). <br><br>  Es kann eine beliebige Anzahl von <i>Filterabschnitten geben</i> , sodass innerhalb eines Abschnitts weniger Bedingungen vorliegen. In dem neuen Abschnitt, den ich f√ºr Nachrichten ohne das <i>src_local-</i> Tag definiert habe, werden Firewall-Ereignisse verarbeitet, an denen wir an der Quelladresse interessiert sind. <br><br>  Jetzt m√ºssen wir etwas mehr dar√ºber sprechen, woher Logstash GeoIP-Informationen bezieht.  Logstash unterst√ºtzt GeoLite2-Datenbanken.  Es gibt mehrere Datenbankoptionen. Ich verwende zwei Datenbanken: GeoLite2 City (mit Informationen zu Land, Stadt, Zeitzone) und GeoLite2 ASN (Informationen zu dem autonomen System, zu dem die IP-Adresse geh√∂rt). <br><br><img src="https://habrastorage.org/webt/gf/ps/a1/gfpsa18cwgwa-7bcadoca7qyhtk.png"><br><br>  Das <a href="https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-geoip.html" rel="nofollow"><i>GeoIP-</i></a> Plugin ist auch am Hinzuf√ºgen von GeoIP-Informationen zur Nachricht beteiligt.  In den Parametern m√ºssen Sie das Feld angeben, das die IP-Adresse, die verwendete Basis und den Namen des neuen Felds enth√§lt, in das die Informationen geschrieben werden.  In meinem Beispiel wird dasselbe f√ºr Ziel-IP-Adressen gemacht, aber in diesem einfachen Szenario sind diese Informationen bisher nicht interessant, da die Zieladresse immer die Adresse des Routers ist.  In Zukunft wird es jedoch m√∂glich sein, dieser Pipeline Protokolle nicht nur von der Firewall aus hinzuzuf√ºgen, sondern auch von anderen Systemen, auf denen es wichtig ist, beide Adressen zu √ºberpr√ºfen. <br><br>  Mit dem <a href="https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-mutate.html" rel="nofollow"><i>Mutate-</i></a> Filter k√∂nnen Sie die Nachrichtenfelder √§ndern und den Text in den Feldern selbst √§ndern. In der Dokumentation werden viele Beispiele f√ºr m√∂gliche Aktionen ausf√ºhrlich beschrieben.  In diesem Fall wird es verwendet, um ein Tag hinzuzuf√ºgen, Felder umzubenennen (f√ºr die weitere Visualisierung von Protokollen in Kibana ist ein bestimmtes Format des <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.3/geo-point.html" rel="nofollow"><i>Geopunktobjekts</i></a> erforderlich, ich werde dieses Thema weiter ber√ºhren) und unn√∂tige Felder zu l√∂schen. <br><br><img src="https://habrastorage.org/webt/kn/9l/qf/kn9lqfj3uwaqh0fhh-tir-f7zr4.png"><br><br>  Dies beendet den Datenverarbeitungsabschnitt und kann nur angeben, wohin eine strukturierte Nachricht gesendet werden soll.  In diesem Fall sammelt Elasticsearch Daten. Sie m√ºssen nur die IP-Adresse, den Port und den Indexnamen eingeben.  Es wird empfohlen, den Index mit einem variablen Datumsfeld einzugeben, damit jeden Tag ein neuer Index erstellt wird. <br><br><img src="https://habrastorage.org/webt/ve/sk/ec/veskecc3kqsidcymnbkafoa3spo.png"><br><br><h3>  Elasticsearch einrichten </h3><br>  Zur√ºck zur Elasticsuche.  Zuerst m√ºssen Sie sicherstellen, dass der Server betriebsbereit ist.  Mit Elastic wird am effizientesten √ºber die Rest-API in der CLI interagiert.  Mit curl k√∂nnen Sie den Status des Knotens anzeigen (ersetzen Sie localhost durch die IP-Adresse des Host-Dockers): <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl localhost:9200</code> </pre> <br>  Dann k√∂nnen Sie versuchen, Kibana bei zu √∂ffnen <a href="http://localhost:5601/" rel="nofollow"></a>  <a href="http://localhost/" rel="nofollow"><i>localhost</i></a> : 5601.  In der Kibana-Weboberfl√§che muss nichts konfiguriert werden (es sei denn, Sie √§ndern das Thema auf dunkel).  Wir sind interessiert, ob ein Index erstellt wurde. √ñffnen Sie dazu den Bereich <i>Verwaltung</i> und w√§hlen Sie <i>Elasticsearch-Indexverwaltung</i> oben links aus.  Hier k√∂nnen Sie sehen, wie viele Dokumente indiziert sind, wie viel Speicherplatz ben√∂tigt wird, und Informationen zur Indexzuordnung aus n√ºtzlichen Informationen abrufen. <br><br><img src="https://habrastorage.org/webt/kl/yp/vv/klypvvi1aa2zlueq98960wdut90.png"><br><br>  In diesem Fall m√ºssen Sie die richtige Zuordnungsvorlage registrieren.  Diese Informationen werden f√ºr Elastic ben√∂tigt, damit er versteht, welche Datentypen zu welchen Feldern geh√∂ren.  Um beispielsweise eine spezielle Auswahl basierend auf IP-Adressen f√ºr das Feld " <i>src_ip" zu treffen</i> , m√ºssen <i>Sie</i> den <i>IP-</i> Datentyp explizit angeben. <i>Um</i> den geografischen Standort zu bestimmen, m√ºssen Sie das Feld " <i>geoip.location"</i> in einem bestimmten Format definieren und den Typ " <i>geo_point"</i> registrieren.  Es m√ºssen nicht alle m√∂glichen Felder beschrieben werden, da bei neuen Feldern der Datentyp automatisch anhand dynamischer Muster ermittelt wird ( <i>Long</i> f√ºr Zahlen und <i>Keyword</i> f√ºr Strings). <br><br>  Sie k√∂nnen eine neue Vorlage entweder mit dem Einrollen oder direkt √ºber die Kibana-Konsole schreiben (Abschnitt <i>Entwicklungstools</i> ). <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl -X POST -H "Content-Type: application/json" -d @elasticsearch/logstash_mikrot-template.json http://192.168.88.130:9200/_template/logstash-mikrot</code> </pre> <br>  Nach dem √Ñndern des Mappings m√ºssen Sie den Index l√∂schen: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl -X DELETE http://192.168.88.130:9200/logstash-mikrot-2019.12.16</code> </pre> <br>  Wenn mindestens eine Nachricht im Index eintrifft, √ºberpr√ºfen Sie die Zuordnung: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl http://192.168.88.130:9200/logstash-mikrot-2019.12.16/_mapping</code> </pre> <br>  F√ºr die weitere Verwendung von Daten in Kibana m√ºssen Sie unter <i>Verwaltung&gt; Kibana-Indexmuster</i> ein <i>Muster</i> erstellen.  Geben Sie den <i>Indexnamen</i> mit dem Symbol * ( <i>logstash-mikrot *) ein,</i> damit alle Indizes √ºbereinstimmen. <i>W√§hlen</i> Sie das <i>Zeitstempelfeld</i> als Feld mit Datum und Uhrzeit aus.  In das Feld <i>Benutzerdefinierte Indexmuster-</i> <i>ID</i> k√∂nnen Sie die Muster-ID eingeben (z. B. <i>logstash-mikrot</i> ). Dies kann in Zukunft den Zugriff auf das Objekt vereinfachen. <br><br><h2>  Datenanalyse und Visualisierung in Kibana </h2><br>  Nachdem Sie das Indexmuster erstellt haben, k√∂nnen Sie mit der interessantesten Teiledatenanalyse und -visualisierung fortfahren.  Kibana hat viele Funktionen und Abschnitte, aber bisher werden wir uns nur f√ºr zwei interessieren. <br><br><h3>  Entdecken </h3><br>  Hier k√∂nnen Sie Dokumente in Indizes anzeigen, empfangene Informationen filtern, suchen und anzeigen.  Es ist wichtig, die Zeitachse nicht zu vergessen, die den Zeitrahmen in den Suchbedingungen festlegt. <br><br><img src="https://habrastorage.org/webt/vk/wn/ta/vkwntasygmykelzligkpf3flsxu.gif"><br><br><h3>  Visualisieren </h3><br>  In diesem Abschnitt k√∂nnen Sie eine Visualisierung basierend auf den gesammelten Daten erstellen.  Am einfachsten ist es, die Quellen f√ºr das Scannen von Botnetzen auf einer geografischen Karte (gepunktet oder in Form einer Heatmap) anzuzeigen.  Es gibt auch viele M√∂glichkeiten, Diagramme zu erstellen, Auswahlen zu treffen usw. <br><br><img src="https://habrastorage.org/webt/f_/rx/p2/f_rxp2xbq4necn0dcsyw2mxkfuy.gif"><br><br>  In Zukunft m√∂chte ich etwas mehr √ºber die Datenverarbeitung, m√∂glicherweise die Visualisierung und m√∂glicherweise etwas anderes Interessantes erz√§hlen.  W√§hrend des Studiums werde ich versuchen, das Tutorial zu erg√§nzen. <br><br><h2>  Fehlerbehebung </h2><br>  Wenn der Index nicht in Elasticsearch angezeigt wird, sollten Sie sich zuerst die Logstash-Protokolle ansehen: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker logs logstash --tail 100 -f</code> </pre> <br>  Logstash funktioniert nicht, wenn keine Verbindung mit Elasticsearch besteht oder ein Fehler in der Pipelinekonfiguration der Hauptgrund ist. Dies wird nach einer sorgf√§ltigen Untersuchung der Protokolle deutlich, die standardm√§√üig in json docker geschrieben werden. <br><br>  Wenn das Protokoll keine Fehler enth√§lt, m√ºssen Sie sicherstellen, dass Logstash Nachrichten auf dem konfigurierten Socket abf√§ngt.  F√ºr Debug-Zwecke k√∂nnen Sie <i>stdout</i> als <i>Ausgabe verwenden</i> : <br><br><pre> <code class="plaintext hljs">stdout { codec =&gt; rubydebug }</code> </pre> <br>  Danach schreibt Logstash Debag-Informationen, wenn die Nachricht direkt im Protokoll eingeht. <br><br>  Das Pr√ºfen von Elasticsearch ist sehr einfach. Lassen Sie einfach eine GET-Anforderung f√ºr die IP-Adresse und den Port des Servers oder f√ºr einen bestimmten API-Endpunkt einrollen.  Sehen Sie sich beispielsweise den Status von Indizes in einer f√ºr Menschen lesbaren Tabelle an: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl -s 'http://192.168.88.130:9200/_cat/indices?v'</code> </pre> <br><img src="https://habrastorage.org/webt/of/ke/v_/ofkev_rfp6uo9x5rf4tcey0egbm.gif"><br><br>  Kibana startet auch dann nicht, wenn keine Verbindung zu Elasticsearch besteht. Dies ist anhand der Protokolle leicht zu erkennen. <br><br>  Wenn sich das Webinterface nicht √∂ffnen l√§sst, sollten Sie sicherstellen, dass die Firewall unter Linux richtig konfiguriert oder deaktiviert ist (in Centos gab es Probleme mit <i>iptables</i> und <i>docker</i> , die auf den Rat des <a href="https://stackoverflow.com/questions/31667160/running-docker-container-iptables-no-chain-target-match-by-that-name" rel="nofollow">Themas hin</a> behoben wurden).  Es ist auch zu ber√ºcksichtigen, dass bei nicht sehr produktiven Ger√§ten alle Komponenten mehrere Minuten lang geladen werden k√∂nnen.  Bei Speichermangel werden die Dienste m√∂glicherweise √ºberhaupt nicht geladen.  Anzeigen der Nutzung von Containerressourcen: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker stats</code> </pre> <br>  Wenn pl√∂tzlich jemand nicht mehr wei√ü, wie er die Konfiguration von Containern in der <i>Datei docker-compose.yml</i> richtig √§ndern und die Container neu starten kann, m√ºssen Sie <i>docker-compose.yml bearbeiten</i> und denselben Befehl mit denselben Parametern erneut starten: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker-compose --compatibility up -d</code> </pre> <br>  Gleichzeitig werden in den ge√§nderten Abschnitten alte Objekte (Container, Netzwerke, Volumes) gel√∂scht und neue entsprechend der Konfiguration neu erstellt.  Die Daten von Diensten gehen nicht gleichzeitig verloren, da <i>benannte Volumes verwendet werden</i> , die nicht mit dem Container gel√∂scht werden und die Konfigurationsdateien vom Hostsystem eingeh√§ngt werden. Logstash kann sogar die Konfigurationsdateien √ºberwachen und die Pipeline-Konfiguration neu starten, wenn die Datei ge√§ndert wird. <br><br>  Sie k√∂nnen den Dienst separat mit dem <i>Befehl</i> <i>docker restart</i> <i>neu starten</i> (es ist nicht erforderlich, dass Sie sich mit <i>docker-compose.yml</i> im Verzeichnis <i>befinden)</i> : <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker restart logstash</code> </pre> <br>  Sie k√∂nnen die <i>Docker-</i> Objektkonfiguration mit dem <i>Befehl</i> <i><a href="https://stedolan.github.io/jq/tutorial/" rel="nofollow">docker inspect anzeigen</a></i> . Es ist praktischer, sie mit <i><a href="https://stedolan.github.io/jq/tutorial/" rel="nofollow">jq zu verwenden</a></i> . <br><br><img src="https://habrastorage.org/webt/vw/l0/-v/vwl0-vgzu8snbp16vgzet9lsa64.gif"><br><br><h2>  Fazit </h2><br>  Ich m√∂chte darauf hinweisen, dass die Sicherheit in diesem Projekt nicht gemeldet wurde, da es sich um eine Testumgebung handelt und keine Ver√∂ffentlichung au√üerhalb des Routers geplant ist.  Wenn Sie es f√ºr eine ernstere Verwendung bereitstellen, m√ºssen Sie die bew√§hrten Methoden befolgen, Zertifikate f√ºr HTTPS installieren, Sicherungen erstellen und die normale √úberwachung (die nicht neben dem Hauptsystem startet) ausf√ºhren.  √úbrigens l√§uft Traefik in meinem Docker auf meinem Server, der f√ºr einige Dienste ein Reverse-Proxy ist, und beendet TLS auf sich selbst und f√ºhrt die Authentifizierung durch.  Das hei√üt, dank des konfigurierten DNS und des Reverse-Proxys ist es m√∂glich, √ºber das Internet mit nicht konfiguriertem HTTPS und einem Kennwort auf das Kibana-Webinterface zuzugreifen (in der Community-Version unterst√ºtzt Kibana nach meinem Verst√§ndnis keinen Kennwortschutz f√ºr das Webinterface).  Ich plane, meine Erfahrungen mit der Einrichtung von Traefik f√ºr die Verwendung in einem Heimnetzwerk mit Docker weiter zu beschreiben. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de481596/">https://habr.com/ru/post/de481596/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de481584/index.html">Wenn Sie ein Team leiten, brechen Sie alle Regeln</a></li>
<li><a href="../de481586/index.html">E-Commerce-Tech-Trends 2020: Zeitalter der immersiven Technologien</a></li>
<li><a href="../de481588/index.html">Die √úbungen zur Isolierung von Runet begannen. √úberwachen wir?</a></li>
<li><a href="../de481592/index.html">Sechs Neujahrs-Geschenkoptionen f√ºr einen Autofahrer mit einem guten Rabatt</a></li>
<li><a href="../de481594/index.html">Entwicklung eines ‚Äûeinfachen Spannungsgenerators‚Äú nach GOST R IEC 61508 (IEC 61508)</a></li>
<li><a href="../de481598/index.html">Ein kleiner Beitrag zum Kampf gegen die Avalonia UI-Zoo-Plattformen</a></li>
<li><a href="../de481600/index.html">Bonsai Family Wiki Engine: 2019 Ergebnisse</a></li>
<li><a href="../de481604/index.html">Wie hart Tscheljabinsk Entwickler Spiele f√ºr Google Play und soziale Netzwerke machen</a></li>
<li><a href="../de481606/index.html">Statisches Abonnement unter Verwendung der Observer-Vorlage unter Verwendung von C ++ und des Cortex M4-Mikrocontrollers</a></li>
<li><a href="../de481610/index.html">PostgreSQL Antipatterns: Aktualisierung einer gro√üen Tabelle unter Last</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
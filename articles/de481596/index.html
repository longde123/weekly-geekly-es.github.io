<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏻‍💻 🏀 🐂 Analysieren der ELK 7.5-Einstellungen für die Mikrotik-Protokollanalyse 👨🏾 💇🏼 👨🏿‍🚀</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es war lange eine Idee zu sehen, was Sie mit ELK und improvisierten Quellen für Protokolle und Statistiken tun können. Auf den Seiten des Habr möchte ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analysieren der ELK 7.5-Einstellungen für die Mikrotik-Protokollanalyse</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/481596/">  Es war lange eine Idee zu sehen, was Sie mit ELK und improvisierten Quellen für Protokolle und Statistiken tun können.  Auf den Seiten des Habr möchte ich ein praktisches Beispiel zeigen, wie Sie mit einem Heim-Mini-Server beispielsweise einen Honeypot mit einem Protokollanalysesystem auf der Basis des ELK-Stacks erstellen können.  In diesem Artikel werde ich Ihnen das einfachste Beispiel für die Analyse von Firewall-Protokollen mit dem ELK-Stack erläutern.  In Zukunft möchte ich die Umgebungseinstellungen für die Analyse von Netflow-Verkehr und PCAP-Dumps von Zeek beschreiben. <br><br><img src="https://habrastorage.org/webt/ze/cb/qx/zecbqxrubn4v0mutaoewxzsp1zm.png"><br><br>  Wenn Sie eine öffentliche IP-Adresse und ein mehr oder weniger intelligentes Gerät als Gateway / Firewall haben, können Sie einen passiven Honeypot organisieren, indem Sie die Protokollierung eingehender Anforderungen an "köstlichen" TCP- und UDP-Ports konfigurieren.  Es gibt ein Beispiel für die Konfiguration eines Mikrotik-Routers unter dem Cutter. Wenn Sie jedoch einen Router eines anderen Herstellers (oder ein anderes Sicherheitssystem) zur Hand haben, müssen Sie nur einige Datenformate und herstellerspezifische Einstellungen herausfinden, und Sie erhalten das gleiche Ergebnis. <br><br><h3>  Haftungsausschluss </h3><br>  Der Artikel gibt nicht vor, originell zu sein. Er befasst sich nicht mit Fragen der Fehlertoleranz von Diensten, der Sicherheit, bewährten Methoden usw.  Es ist notwendig, dieses Material als akademisch zu betrachten. Es ist geeignet, um mit der Grundfunktionalität des ELK-Stacks und dem Protokollanalysemechanismus des Netzwerkgeräts vertraut zu werden.  Es könnte jedoch auch für Anfänger interessant sein. <br><br>  Das Projekt wird über die Docker-Compose-Datei gestartet. Die Bereitstellung einer ähnlichen Umgebung ist sehr einfach. Auch wenn Sie einen Router eines anderen Anbieters zur Hand haben, müssen Sie nur ein wenig über Datenformate und herstellerspezifische Einstellungen wissen.  Im Übrigen habe ich versucht, alle mit der Konfiguration von Logstash-Pipelines und Elasticsearch-Zuordnungen in der aktuellen Version von ELK verbundenen Nuancen so detailliert wie möglich zu beschreiben.  Alle Komponenten dieses Systems werden auf <a href="https://github.com/mekhanme/elk-mikrot" rel="nofollow">github</a> gehostet, einschließlich Dienstkonfigurationen.  Am Ende des Artikels werde ich den Abschnitt Fehlerbehebung ausführen, in dem die Schritte zur Diagnose der gängigen Probleme beschrieben werden, mit denen Neulinge in diesem Geschäft konfrontiert sind. <br><a name="habracut"></a><br><h3>  Einleitung </h3><br>  Auf dem Server selbst habe ich das Proxmox-Virtualisierungssystem installiert, auf dem auf dem KVM-Rechner Docker-Container gestartet werden.  Es wird davon ausgegangen, dass Sie wissen, wie Docker und Docker-Compose funktionieren, da es genügend Konfigurationsbeispiele zur Internetnutzung gibt.  Ich werde nicht auf die Probleme bei der Installation von Docker eingehen, sondern ein wenig über Docker-Compose schreiben. <br><br>  Die Idee, Honeypot auf den Markt zu bringen, entstand während des Studiums von Elasticsearch, Logstash und Kibana.  In meiner beruflichen Laufbahn war ich noch nie mit der Verwaltung und allgemeinen Verwendung dieses Stacks befasst, aber ich habe Hobbyprojekte durchgeführt, die mich sehr daran interessiert haben, die Möglichkeiten der Elasticsearch- und Kibana-Suchmaschine zu erkunden, mit denen Daten analysiert und visualisiert werden können. <br><br>  Mein nicht der neueste Mini-NUC-Server mit 8 GB RAM reicht gerade aus, um den ELK-Stack mit einem Elastic-Knoten zu starten.  In Produktionsumgebungen ist dies natürlich nicht zu empfehlen, aber genau richtig für das Training.  Zum Thema Sicherheit steht am Ende des Artikels eine Bemerkung. <br><br>  Das Internet enthält <a href="https://habr.com/ru/post/324760/">zahlreiche</a> Anweisungen zum Installieren und Konfigurieren des ELK-Stacks für ähnliche Aufgaben (z. B. <a href="https://habr.com/ru/post/324760/">Analysieren von Brute-Force-Angriffen auf ssh mit Logstash Version 2</a> , <a href="https://habr.com/ru/post/431600/">Analysieren von Suricata-Protokollen mit Filebeat Version 6</a> ). In den meisten Fällen wird jedoch nicht auf Details geachtet 90 Prozent des Materials werden für die Versionen 1 bis 6 sein (zum Zeitpunkt des Schreibens ist die aktuelle Version von ELK 7.5.0).  Dies ist wichtig, da Elasticsearch ab Version 6 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html" rel="nofollow">beschlossen hat, die</a> Entität "Zuordnungstyp" <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html" rel="nofollow">zu entfernen</a> , wodurch die Abfragesyntax und die Zuordnungsstruktur geändert wurden.  Das Zuordnen von Vorlagen in Elastic ist im Allgemeinen ein sehr wichtiges Objekt, und damit später keine Probleme mit der Datenerfassung und -visualisierung auftreten, rate ich Ihnen, sich nicht auf das Kopieren und Einfügen einzulassen und zu versuchen, zu verstehen, was Sie tun.  Weiterhin werde ich versuchen klar zu erklären, was die beschriebenen Operationen und Konfigurationen bedeuten. <br><br><h2>  Router einrichten </h2><br>  Für das Heimnetzwerk verwende ich Mikrotik als Router, also wird ein Beispiel für ihn sein.  Fast jedes System kann so konfiguriert werden, dass Syslog an einen Remote-Server gesendet wird, sei es ein Router, ein Server oder ein anderes Sicherheitssystem, das Protokolle erstellt. <br><br><h3>  Senden von Syslog-Nachrichten an einen Remote-Server </h3><br>  Um in Mikrotik die Protokollierung auf einem Remote-Server über die CLI zu konfigurieren, geben Sie einfach ein paar Befehle ein: <br><br><pre><code class="plaintext hljs">/system logging action add remote=192.168.88.130 remote-port=5145 src-address=192.168.88.1 name=logstash target=remote /system logging add action=logstash topics=info</code> </pre> <br><h3>  Konfigurieren von Firewallregeln mit der Protokollierung </h3><br>  Wir interessieren uns nur für bestimmte Daten (Hostname, IP-Adresse, Benutzername, URL usw.), aus denen Sie eine schöne Visualisierung oder Auswahl erhalten können.  Um Informationen zu Port-Scans und Zugriffsversuchen zu erhalten, müssen Sie im einfachsten Fall die Firewall-Komponente so konfigurieren, dass sie Regel-Trigger protokolliert.  Ich habe die Regeln in der NAT-Tabelle in Mikrotik und nicht in Filter konfiguriert, da ich in Zukunft Chanipots einrichten werde, die die Arbeit von Diensten emulieren. Auf diese Weise kann ich mehr Informationen über das Verhalten von Botnetzen erhalten, dies ist jedoch ein fortgeschritteneres Szenario und nicht zu diesem Zeitpunkt. <br><br>  Achtung!  In der folgenden Konfiguration wird der Standard-TCP-Port des SSH-Dienstes (22) in das lokale Netzwerk eingeschleift.  Wenn Sie mit SSH von außen auf den Router zugreifen und die Einstellungen über Port 22 verfügen ( <i>IP-Dienst</i> in der CLI <i>drucken</i> und <i>IP&gt; -Dienste</i> in Winbox), sollten Sie den Port für Management-SSH neu zuweisen oder die letzte Regel nicht in die Tabelle eingeben. <br>  Abhängig vom Namen der WAN-Schnittstelle (wenn die WAN-Bridge nicht verwendet wird) müssen Sie auch den Parameter für die <i>Schnittstelle</i> in den entsprechenden ändern. <br><br><pre> <code class="plaintext hljs">/ip firewall nat add action=netmap chain=dstnat comment="HONEYPOT RDP" dst-port=3389 in-interface=bridge-wan log=yes log-prefix=honeypot_rdp protocol=tcp to-addresses=192.168.88.201 to-ports=3389 add action=netmap chain=dstnat comment="HONEYPOT ELASTIC" dst-port=9200 in-interface=bridge-wan log=yes log-prefix=honeypot_elastic protocol=tcp to-addresses=192.168.88.201 to-ports=9211 add action=netmap chain=dstnat comment=" HONEYPOT TELNET" dst-port=23 in-interface=bridge-wan log=yes log-prefix=honeypot_telnet protocol=tcp to-addresses=192.168.88.201 to-ports=2325 add action=netmap chain=dstnat comment="HONEYPOT DNS" dst-port=53 in-interface=bridge-wan log=yes log-prefix=honeypot_dns protocol=udp to-addresses=192.168.88.201 to-ports=9953 add action=netmap chain=dstnat comment="HONEYPOT FTP" dst-port=21 in-interface=bridge-wan log=yes log-prefix=honeypot_ftp protocol=tcp to-addresses=192.168.88.201 to-ports=9921 add action=netmap chain=dstnat comment="HONEYPOT SMTP" dst-port=25 in-interface=bridge-wan log=yes log-prefix=honeypot_smtp protocol=tcp to-addresses=192.168.88.201 to-ports=9925 add action=netmap chain=dstnat comment="HONEYPOT SMB" dst-port=445 in-interface=bridge-wan log=yes log-prefix=honeypot_smb protocol=tcp to-addresses=192.168.88.201 to-ports=9445 add action=netmap chain=dstnat comment="HONEYPOT MQTT" dst-port=1883 in-interface=bridge-wan log=yes log-prefix=honeypot_mqtt protocol=tcp to-addresses=192.168.88.201 to-ports=9883 add action=netmap chain=dstnat comment="HONEYPOT SIP" dst-port=5060 in-interface=bridge-wan log=yes log-prefix=honeypot_sip protocol=tcp to-addresses=192.168.88.201 to-ports=9060 add action=dst-nat chain=dstnat comment="HONEYPOT SSH" dst-port=22 in-interface=bridge-wan log=yes log-prefix=honeypot_ssh protocol=tcp to-addresses=192.168.88.201 to-ports=9922</code> </pre> <br><img src="https://habrastorage.org/webt/of/dm/jo/ofdmjo5n3f8fi54udyvbixhaifm.png"><br><br>  In Winbox wird dasselbe auf der <i>Registerkarte IP&gt; Firewall&gt; NAT</i> konfiguriert. <br><br>  Der Router leitet nun die empfangenen Pakete an die lokale Adresse 192.168.88.201 und den benutzerdefinierten Port weiter.  Momentan hört niemand auf diese Ports, sodass die Verbindungen unterbrochen werden.  In Zukunft können Sie in Docker Honeypot ausführen, von denen es für jeden Dienst viele gibt.  Wenn dies nicht geplant ist, sollten Sie anstelle von NAT-Regeln eine Regel mit der Drop-Aktion in die Filterkette schreiben. <br><br><h3>  Starten von ELK mit Docker-Compose </h3><br>  Als Nächstes können Sie die Komponente konfigurieren, die die Protokolle verarbeitet.  Ich rate Ihnen, das Repository sofort zu üben und zu klonen, um die Konfigurationsdateien vollständig anzuzeigen.  Alle beschriebenen Configs sind dort zu sehen, im Text des Artikels werde ich nur einen Teil der Configs kopieren. <br><br><pre> <code class="plaintext hljs">❯❯ git clone https://github.com/mekhanme/elk-mikrot.git</code> </pre> <br><img src="https://habrastorage.org/webt/95/_b/9g/95_b9gu4scfg99nwtyfph-0pf7o.png"><br><br>  In einer Test- oder Entwicklungsumgebung ist es am bequemsten, Docker-Container mit docker-compose auszuführen.  In diesem Projekt verwende ich zur Zeit die Docker-Compose-Datei der neuesten <a href="https://docs.docker.com/compose/compose-file/" rel="nofollow">Version 3.7</a> . Sie erfordert die Docker-Engine-Version 18.06.0+. Es lohnt sich daher, den <a href="https://docs.docker.com/install/linux/docker-ce/centos/" rel="nofollow">Docker</a> zu aktualisieren und <a href="https://docs.docker.com/compose/install/" rel="nofollow">Docker-Compose zu verwenden</a> . <br><br><pre> <code class="plaintext hljs">❯❯ curl -L "https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose ❯❯ chmod +x /usr/local/bin/docker-compose</code> </pre> <br>  Da in den letzten Versionen von Docker-Compose der Parameter mem_limit entfernt und Deploy hinzugefügt wurde, der nur im Schwarmmodus ausgeführt wird ( <i>Docker-Stack-Deploy</i> ), führt das Starten der <i>Docker-Compose-Up-</i> Konfiguration mit Einschränkungen zu einem Fehler.  Da ich keinen Schwarm verwende und Ressourcenlimits haben möchte, muss ich ihn mit der Option <i>--compatibility</i> starten, mit der die Limits von Docker-Compose-Versionen in Nicht-Schweiß-Äquivalente konvertiert werden. <br><br>  Testlauf aller Container (im Hintergrund -d): <br><br><pre> <code class="plaintext hljs">❯❯ docker-compose --compatibility up -d</code> </pre> <br>  Sie müssen warten, bis alle Bilder heruntergeladen wurden, und nachdem der Start abgeschlossen ist, können Sie den Status der Container mit dem folgenden Befehl überprüfen: <br><br><pre> <code class="plaintext hljs">❯❯ docker-compose --compatibility ps</code> </pre> <br>  Aufgrund der Tatsache, dass sich alle Container im selben Netzwerk befinden (wenn Sie das Netzwerk nicht explizit angeben, wird eine neue Brücke erstellt, die für dieses Szenario geeignet ist) und docker-compose.yml den Parameter container_name für alle <i>Container enthält</i> , verfügen die Container bereits über eine Verbindung über das integrierte DNS Hafenarbeiter.  Infolgedessen ist es nicht erforderlich, IP-Adressen in Container-Konfigurationen zu registrieren.  In der Logstash-Konfiguration ist das Subnetz 192.168.88.0/24 als lokal registriert, weiter unten in der Konfiguration finden Sie nähere Erläuterungen, nach denen Sie das Beispiel der Konfiguration vor dem Start ablenken können. <br><br><h2>  Konfigurieren Sie ELK Services </h2><br>  Des Weiteren werden Erklärungen zur Konfiguration der Funktionen der ELK-Komponenten sowie einige weitere Aktionen gegeben, die in Elasticsearch ausgeführt werden müssen. <br><br>  Um die geografischen Koordinaten anhand der IP-Adresse zu ermitteln, müssen Sie die kostenlose <a href="https://dev.maxmind.com/geoip/geoip2/geolite2/" rel="nofollow">GeoLite2-</a> Datenbank von MaxMind herunterladen: <br><br><pre> <code class="plaintext hljs">❯❯ cd elk-mikrot &amp;&amp; mkdir logstash/geoip_db ❯❯ curl -O https://geolite.maxmind.com/download/geoip/database/GeoLite2-City-CSV.zip &amp;&amp; unzip GeoLite2-City-CSV.zip -d logstash/geoip_db &amp;&amp; rm -f GeoLite2-City-CSV.zip ❯❯ curl -O https://geolite.maxmind.com/download/geoip/database/GeoLite2-ASN-CSV.zip &amp;&amp; unzip GeoLite2-ASN-CSV.zip -d logstash/geoip_db &amp;&amp; rm -f GeoLite2-ASN-CSV.zip</code> </pre> <br><h3>  Logstash-Setup </h3><br>  Die Hauptkonfigurationsdatei ist <i>logstash.yml</i> , in der ich die Option zum automatischen <i>erneuten</i> Laden der Konfiguration registriert habe. Die restlichen Einstellungen für die Testumgebung sind nicht von Bedeutung.  Die Konfiguration der Datenverarbeitung (Protokolle) in Logstash wird in separaten <i>conf-</i> Dateien beschrieben, die normalerweise im <i>Pipeline-</i> Verzeichnis gespeichert sind.  Wenn in dem Schema <a href="https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html" rel="nofollow">mehrere Pipelines</a> verwendet werden, beschreibt die Datei <a href="https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html" rel="nofollow">pipelines.yml</a> die aktivierten <i>Pipelines</i> .  Eine Pipeline ist eine Aktionskette für unstrukturierte Daten, um am Ausgang Daten mit einer bestimmten Struktur zu erhalten.  Ein Schema mit separat konfigurierter <i>pipelines.yml</i> ist optional. Sie können darauf verzichten, indem Sie alle configs aus dem bereitgestellten <i>Pipeline-</i> Verzeichnis herunterladen. Mit einer bestimmten <i>pipelines.yml-</i> Datei ist die Konfiguration jedoch flexibler, da Sie die <i>conf-</i> Dateien aus dem <i>Pipeline-</i> Verzeichnis <i>ein-</i> und ausschalten können notwendige configs.  Darüber hinaus funktioniert das Neuladen von Konfigurationen nur im Schema mit mehreren Pipelines. <br><br><pre> <code class="plaintext hljs">❯❯ cat logstash/config/pipelines.yml - pipeline.id: logstash-mikrot path.config: "pipeline/logstash-mikrot.conf"</code> </pre> <br>  Als nächstes kommt der wichtigste Teil der Logstash-Konfiguration.  Die Pipeline-Beschreibung besteht aus mehreren Abschnitten - zu Beginn werden die Plugins im Abschnitt <i>Input</i> angezeigt, mit deren Hilfe Logstash Daten empfängt.  Der einfachste Weg, Syslog von einem Netzwerkgerät zu sammeln, ist die Verwendung der <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-tcp.html" rel="nofollow">tcp</a> / <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-udp.html" rel="nofollow">udp-</a> Eingabe-Plugins.  Der einzige erforderliche Parameter für diese Plugins ist <i>port</i> . Er muss wie in den Router-Einstellungen angegeben werden. <br><br>  Der zweite Abschnitt ist <i>Filter</i> , der weitere Aktionen mit Daten vorschreibt, die noch nicht strukturiert wurden.  In meinem Beispiel werden unnötige Syslog-Nachrichten von einem Router mit bestimmtem Text gelöscht.  Dies geschieht mit der Bedingung und der Standard- <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-drop.html" rel="nofollow"><i>Drop-</i></a> Aktion, die die gesamte Nachricht verwirft, wenn die Bedingung erfüllt ist.  In der <a href="https://www.elastic.co/guide/en/logstash/7.5/event-dependent-configuration.html" rel="nofollow">Bedingung</a> wird das <i>Nachrichtenfeld</i> auf das Vorhandensein von bestimmtem Text überprüft. <br><br><img src="https://habrastorage.org/webt/iq/j0/ut/iqj0utufb6itcsrwspxi9qw4e2c.png"><br><br>  Wenn die Nachricht nicht abfällt, geht sie weiter die Kette hinunter und tritt in den <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-grok.html" rel="nofollow"><i>Grok-</i></a> Filter ein.  Wie die Dokumentation sagt, ist <i>grok eine großartige Möglichkeit, unstrukturierte Protokolldaten in strukturierte und abfragbare Daten zu zerlegen</i> .  Dieser Filter wird verwendet, um Protokolle verschiedener Systeme (Linux-Syslog, Webserver, Datenbank, Netzwerkgeräte usw.) zu verarbeiten.  Basierend auf <a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns" rel="nofollow">vorgefertigten Mustern können</a> Sie ohne großen Zeitaufwand einen Parser für mehr oder weniger sich wiederholende Sequenzen erstellen.  Es ist praktisch, einen <a href="http://grokdebug.herokuapp.com/" rel="nofollow">Online-Parser</a> zur Validierung zu verwenden (in der neuesten Version von Kibana finden Sie ähnliche Funktionen im Abschnitt <i>Entwicklungstools</i> ). <br><br><img src="https://habrastorage.org/webt/_g/9q/ky/_g9qkyst3-na7a2i8mhxwf8avw0.gif"><br><br>  Der <i>Datenträger "./logstash/patterns:/usr/share/logstash/patterns" ist</i> in der Datei <i>docker-compose.yml</i> registriert. Im <i>Verzeichnis</i> <i>patterns</i> befindet sich eine Datei mit Standard-Community-Mustern (nur aus <i>Gründen</i> der <i>Benutzerfreundlichkeit</i> <i>,</i> falls ich das vergessen habe) sowie eine Datei mit Analog zu den Mustern verschiedener Arten von Mikrotik-Nachrichten ( <i>Firewall-</i> und <i>Auth-</i> Module <i>)</i> können Sie Ihre eigenen Vorlagen für Nachrichten mit einer anderen Struktur hinzufügen. <br><br>  Die Standardoptionen <i>add_field</i> und <i>remove_field</i> ermöglichen das Hinzufügen oder Entfernen von Feldern zu der Nachricht, die in einem beliebigen Filter verarbeitet wird.  In diesem Fall wird das <i>Hostfeld</i> gelöscht, das den Hostnamen enthält, von dem die Nachricht empfangen wurde.  In meinem Beispiel gibt es nur einen Host, sodass dieses Feld keinen Sinn macht. <br><br>  Außerdem habe ich im <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-cidr.html" rel="nofollow"><i>selben</i></a> Filterabschnitt den <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-cidr.html" rel="nofollow"><i>cidr-</i></a> Filter registriert, der das Feld mit der IP-Adresse auf Übereinstimmung mit der Eintragsbedingung im angegebenen Subnetz überprüft und das Tag <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-cidr.html" rel="nofollow"><i>einfügt</i></a> .  Basierend auf dem Tag in der weiteren Kette werden Aktionen ausgeführt oder nicht ausgeführt (falls dies ausdrücklich der Fall ist, um in Zukunft keine Geoip-Suche nach lokalen Adressen durchzuführen). <br><br>  Es kann eine beliebige Anzahl von <i>Filterabschnitten geben</i> , sodass innerhalb eines Abschnitts weniger Bedingungen vorliegen. In dem neuen Abschnitt, den ich für Nachrichten ohne das <i>src_local-</i> Tag definiert habe, werden Firewall-Ereignisse verarbeitet, an denen wir an der Quelladresse interessiert sind. <br><br>  Jetzt müssen wir etwas mehr darüber sprechen, woher Logstash GeoIP-Informationen bezieht.  Logstash unterstützt GeoLite2-Datenbanken.  Es gibt mehrere Datenbankoptionen. Ich verwende zwei Datenbanken: GeoLite2 City (mit Informationen zu Land, Stadt, Zeitzone) und GeoLite2 ASN (Informationen zu dem autonomen System, zu dem die IP-Adresse gehört). <br><br><img src="https://habrastorage.org/webt/gf/ps/a1/gfpsa18cwgwa-7bcadoca7qyhtk.png"><br><br>  Das <a href="https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-geoip.html" rel="nofollow"><i>GeoIP-</i></a> Plugin ist auch am Hinzufügen von GeoIP-Informationen zur Nachricht beteiligt.  In den Parametern müssen Sie das Feld angeben, das die IP-Adresse, die verwendete Basis und den Namen des neuen Felds enthält, in das die Informationen geschrieben werden.  In meinem Beispiel wird dasselbe für Ziel-IP-Adressen gemacht, aber in diesem einfachen Szenario sind diese Informationen bisher nicht interessant, da die Zieladresse immer die Adresse des Routers ist.  In Zukunft wird es jedoch möglich sein, dieser Pipeline Protokolle nicht nur von der Firewall aus hinzuzufügen, sondern auch von anderen Systemen, auf denen es wichtig ist, beide Adressen zu überprüfen. <br><br>  Mit dem <a href="https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-mutate.html" rel="nofollow"><i>Mutate-</i></a> Filter können Sie die Nachrichtenfelder ändern und den Text in den Feldern selbst ändern. In der Dokumentation werden viele Beispiele für mögliche Aktionen ausführlich beschrieben.  In diesem Fall wird es verwendet, um ein Tag hinzuzufügen, Felder umzubenennen (für die weitere Visualisierung von Protokollen in Kibana ist ein bestimmtes Format des <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.3/geo-point.html" rel="nofollow"><i>Geopunktobjekts</i></a> erforderlich, ich werde dieses Thema weiter berühren) und unnötige Felder zu löschen. <br><br><img src="https://habrastorage.org/webt/kn/9l/qf/kn9lqfj3uwaqh0fhh-tir-f7zr4.png"><br><br>  Dies beendet den Datenverarbeitungsabschnitt und kann nur angeben, wohin eine strukturierte Nachricht gesendet werden soll.  In diesem Fall sammelt Elasticsearch Daten. Sie müssen nur die IP-Adresse, den Port und den Indexnamen eingeben.  Es wird empfohlen, den Index mit einem variablen Datumsfeld einzugeben, damit jeden Tag ein neuer Index erstellt wird. <br><br><img src="https://habrastorage.org/webt/ve/sk/ec/veskecc3kqsidcymnbkafoa3spo.png"><br><br><h3>  Elasticsearch einrichten </h3><br>  Zurück zur Elasticsuche.  Zuerst müssen Sie sicherstellen, dass der Server betriebsbereit ist.  Mit Elastic wird am effizientesten über die Rest-API in der CLI interagiert.  Mit curl können Sie den Status des Knotens anzeigen (ersetzen Sie localhost durch die IP-Adresse des Host-Dockers): <br><br><pre> <code class="plaintext hljs">❯❯ curl localhost:9200</code> </pre> <br>  Dann können Sie versuchen, Kibana bei zu öffnen <a href="http://localhost:5601/" rel="nofollow"></a>  <a href="http://localhost/" rel="nofollow"><i>localhost</i></a> : 5601.  In der Kibana-Weboberfläche muss nichts konfiguriert werden (es sei denn, Sie ändern das Thema auf dunkel).  Wir sind interessiert, ob ein Index erstellt wurde. Öffnen Sie dazu den Bereich <i>Verwaltung</i> und wählen Sie <i>Elasticsearch-Indexverwaltung</i> oben links aus.  Hier können Sie sehen, wie viele Dokumente indiziert sind, wie viel Speicherplatz benötigt wird, und Informationen zur Indexzuordnung aus nützlichen Informationen abrufen. <br><br><img src="https://habrastorage.org/webt/kl/yp/vv/klypvvi1aa2zlueq98960wdut90.png"><br><br>  In diesem Fall müssen Sie die richtige Zuordnungsvorlage registrieren.  Diese Informationen werden für Elastic benötigt, damit er versteht, welche Datentypen zu welchen Feldern gehören.  Um beispielsweise eine spezielle Auswahl basierend auf IP-Adressen für das Feld " <i>src_ip" zu treffen</i> , müssen <i>Sie</i> den <i>IP-</i> Datentyp explizit angeben. <i>Um</i> den geografischen Standort zu bestimmen, müssen Sie das Feld " <i>geoip.location"</i> in einem bestimmten Format definieren und den Typ " <i>geo_point"</i> registrieren.  Es müssen nicht alle möglichen Felder beschrieben werden, da bei neuen Feldern der Datentyp automatisch anhand dynamischer Muster ermittelt wird ( <i>Long</i> für Zahlen und <i>Keyword</i> für Strings). <br><br>  Sie können eine neue Vorlage entweder mit dem Einrollen oder direkt über die Kibana-Konsole schreiben (Abschnitt <i>Entwicklungstools</i> ). <br><br><pre> <code class="plaintext hljs">❯❯ curl -X POST -H "Content-Type: application/json" -d @elasticsearch/logstash_mikrot-template.json http://192.168.88.130:9200/_template/logstash-mikrot</code> </pre> <br>  Nach dem Ändern des Mappings müssen Sie den Index löschen: <br><br><pre> <code class="plaintext hljs">❯❯ curl -X DELETE http://192.168.88.130:9200/logstash-mikrot-2019.12.16</code> </pre> <br>  Wenn mindestens eine Nachricht im Index eintrifft, überprüfen Sie die Zuordnung: <br><br><pre> <code class="plaintext hljs">❯❯ curl http://192.168.88.130:9200/logstash-mikrot-2019.12.16/_mapping</code> </pre> <br>  Für die weitere Verwendung von Daten in Kibana müssen Sie unter <i>Verwaltung&gt; Kibana-Indexmuster</i> ein <i>Muster</i> erstellen.  Geben Sie den <i>Indexnamen</i> mit dem Symbol * ( <i>logstash-mikrot *) ein,</i> damit alle Indizes übereinstimmen. <i>Wählen</i> Sie das <i>Zeitstempelfeld</i> als Feld mit Datum und Uhrzeit aus.  In das Feld <i>Benutzerdefinierte Indexmuster-</i> <i>ID</i> können Sie die Muster-ID eingeben (z. B. <i>logstash-mikrot</i> ). Dies kann in Zukunft den Zugriff auf das Objekt vereinfachen. <br><br><h2>  Datenanalyse und Visualisierung in Kibana </h2><br>  Nachdem Sie das Indexmuster erstellt haben, können Sie mit der interessantesten Teiledatenanalyse und -visualisierung fortfahren.  Kibana hat viele Funktionen und Abschnitte, aber bisher werden wir uns nur für zwei interessieren. <br><br><h3>  Entdecken </h3><br>  Hier können Sie Dokumente in Indizes anzeigen, empfangene Informationen filtern, suchen und anzeigen.  Es ist wichtig, die Zeitachse nicht zu vergessen, die den Zeitrahmen in den Suchbedingungen festlegt. <br><br><img src="https://habrastorage.org/webt/vk/wn/ta/vkwntasygmykelzligkpf3flsxu.gif"><br><br><h3>  Visualisieren </h3><br>  In diesem Abschnitt können Sie eine Visualisierung basierend auf den gesammelten Daten erstellen.  Am einfachsten ist es, die Quellen für das Scannen von Botnetzen auf einer geografischen Karte (gepunktet oder in Form einer Heatmap) anzuzeigen.  Es gibt auch viele Möglichkeiten, Diagramme zu erstellen, Auswahlen zu treffen usw. <br><br><img src="https://habrastorage.org/webt/f_/rx/p2/f_rxp2xbq4necn0dcsyw2mxkfuy.gif"><br><br>  In Zukunft möchte ich etwas mehr über die Datenverarbeitung, möglicherweise die Visualisierung und möglicherweise etwas anderes Interessantes erzählen.  Während des Studiums werde ich versuchen, das Tutorial zu ergänzen. <br><br><h2>  Fehlerbehebung </h2><br>  Wenn der Index nicht in Elasticsearch angezeigt wird, sollten Sie sich zuerst die Logstash-Protokolle ansehen: <br><br><pre> <code class="plaintext hljs">❯❯ docker logs logstash --tail 100 -f</code> </pre> <br>  Logstash funktioniert nicht, wenn keine Verbindung mit Elasticsearch besteht oder ein Fehler in der Pipelinekonfiguration der Hauptgrund ist. Dies wird nach einer sorgfältigen Untersuchung der Protokolle deutlich, die standardmäßig in json docker geschrieben werden. <br><br>  Wenn das Protokoll keine Fehler enthält, müssen Sie sicherstellen, dass Logstash Nachrichten auf dem konfigurierten Socket abfängt.  Für Debug-Zwecke können Sie <i>stdout</i> als <i>Ausgabe verwenden</i> : <br><br><pre> <code class="plaintext hljs">stdout { codec =&gt; rubydebug }</code> </pre> <br>  Danach schreibt Logstash Debag-Informationen, wenn die Nachricht direkt im Protokoll eingeht. <br><br>  Das Prüfen von Elasticsearch ist sehr einfach. Lassen Sie einfach eine GET-Anforderung für die IP-Adresse und den Port des Servers oder für einen bestimmten API-Endpunkt einrollen.  Sehen Sie sich beispielsweise den Status von Indizes in einer für Menschen lesbaren Tabelle an: <br><br><pre> <code class="plaintext hljs">❯❯ curl -s 'http://192.168.88.130:9200/_cat/indices?v'</code> </pre> <br><img src="https://habrastorage.org/webt/of/ke/v_/ofkev_rfp6uo9x5rf4tcey0egbm.gif"><br><br>  Kibana startet auch dann nicht, wenn keine Verbindung zu Elasticsearch besteht. Dies ist anhand der Protokolle leicht zu erkennen. <br><br>  Wenn sich das Webinterface nicht öffnen lässt, sollten Sie sicherstellen, dass die Firewall unter Linux richtig konfiguriert oder deaktiviert ist (in Centos gab es Probleme mit <i>iptables</i> und <i>docker</i> , die auf den Rat des <a href="https://stackoverflow.com/questions/31667160/running-docker-container-iptables-no-chain-target-match-by-that-name" rel="nofollow">Themas hin</a> behoben wurden).  Es ist auch zu berücksichtigen, dass bei nicht sehr produktiven Geräten alle Komponenten mehrere Minuten lang geladen werden können.  Bei Speichermangel werden die Dienste möglicherweise überhaupt nicht geladen.  Anzeigen der Nutzung von Containerressourcen: <br><br><pre> <code class="plaintext hljs">❯❯ docker stats</code> </pre> <br>  Wenn plötzlich jemand nicht mehr weiß, wie er die Konfiguration von Containern in der <i>Datei docker-compose.yml</i> richtig ändern und die Container neu starten kann, müssen Sie <i>docker-compose.yml bearbeiten</i> und denselben Befehl mit denselben Parametern erneut starten: <br><br><pre> <code class="plaintext hljs">❯❯ docker-compose --compatibility up -d</code> </pre> <br>  Gleichzeitig werden in den geänderten Abschnitten alte Objekte (Container, Netzwerke, Volumes) gelöscht und neue entsprechend der Konfiguration neu erstellt.  Die Daten von Diensten gehen nicht gleichzeitig verloren, da <i>benannte Volumes verwendet werden</i> , die nicht mit dem Container gelöscht werden und die Konfigurationsdateien vom Hostsystem eingehängt werden. Logstash kann sogar die Konfigurationsdateien überwachen und die Pipeline-Konfiguration neu starten, wenn die Datei geändert wird. <br><br>  Sie können den Dienst separat mit dem <i>Befehl</i> <i>docker restart</i> <i>neu starten</i> (es ist nicht erforderlich, dass Sie sich mit <i>docker-compose.yml</i> im Verzeichnis <i>befinden)</i> : <br><br><pre> <code class="plaintext hljs">❯❯ docker restart logstash</code> </pre> <br>  Sie können die <i>Docker-</i> Objektkonfiguration mit dem <i>Befehl</i> <i><a href="https://stedolan.github.io/jq/tutorial/" rel="nofollow">docker inspect anzeigen</a></i> . Es ist praktischer, sie mit <i><a href="https://stedolan.github.io/jq/tutorial/" rel="nofollow">jq zu verwenden</a></i> . <br><br><img src="https://habrastorage.org/webt/vw/l0/-v/vwl0-vgzu8snbp16vgzet9lsa64.gif"><br><br><h2>  Fazit </h2><br>  Ich möchte darauf hinweisen, dass die Sicherheit in diesem Projekt nicht gemeldet wurde, da es sich um eine Testumgebung handelt und keine Veröffentlichung außerhalb des Routers geplant ist.  Wenn Sie es für eine ernstere Verwendung bereitstellen, müssen Sie die bewährten Methoden befolgen, Zertifikate für HTTPS installieren, Sicherungen erstellen und die normale Überwachung (die nicht neben dem Hauptsystem startet) ausführen.  Übrigens läuft Traefik in meinem Docker auf meinem Server, der für einige Dienste ein Reverse-Proxy ist, und beendet TLS auf sich selbst und führt die Authentifizierung durch.  Das heißt, dank des konfigurierten DNS und des Reverse-Proxys ist es möglich, über das Internet mit nicht konfiguriertem HTTPS und einem Kennwort auf das Kibana-Webinterface zuzugreifen (in der Community-Version unterstützt Kibana nach meinem Verständnis keinen Kennwortschutz für das Webinterface).  Ich plane, meine Erfahrungen mit der Einrichtung von Traefik für die Verwendung in einem Heimnetzwerk mit Docker weiter zu beschreiben. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de481596/">https://habr.com/ru/post/de481596/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de481584/index.html">Wenn Sie ein Team leiten, brechen Sie alle Regeln</a></li>
<li><a href="../de481586/index.html">E-Commerce-Tech-Trends 2020: Zeitalter der immersiven Technologien</a></li>
<li><a href="../de481588/index.html">Die Übungen zur Isolierung von Runet begannen. Überwachen wir?</a></li>
<li><a href="../de481592/index.html">Sechs Neujahrs-Geschenkoptionen für einen Autofahrer mit einem guten Rabatt</a></li>
<li><a href="../de481594/index.html">Entwicklung eines „einfachen Spannungsgenerators“ nach GOST R IEC 61508 (IEC 61508)</a></li>
<li><a href="../de481598/index.html">Ein kleiner Beitrag zum Kampf gegen die Avalonia UI-Zoo-Plattformen</a></li>
<li><a href="../de481600/index.html">Bonsai Family Wiki Engine: 2019 Ergebnisse</a></li>
<li><a href="../de481604/index.html">Wie hart Tscheljabinsk Entwickler Spiele für Google Play und soziale Netzwerke machen</a></li>
<li><a href="../de481606/index.html">Statisches Abonnement unter Verwendung der Observer-Vorlage unter Verwendung von C ++ und des Cortex M4-Mikrocontrollers</a></li>
<li><a href="../de481610/index.html">PostgreSQL Antipatterns: Aktualisierung einer großen Tabelle unter Last</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
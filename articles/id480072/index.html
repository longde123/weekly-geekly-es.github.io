<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧘🏼 😟 👩🏼‍✈️ Kubernetes: mengapa begitu penting untuk mengatur manajemen sumber daya sistem? 👳 ✖️ 🈯️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sebagai aturan, selalu ada kebutuhan untuk menyediakan kumpulan sumber daya khusus untuk aplikasi apa pun untuk operasi yang benar dan stabil. Tetapi ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes: mengapa begitu penting untuk mengatur manajemen sumber daya sistem?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nixys/blog/480072/"><p>  Sebagai aturan, selalu ada kebutuhan untuk menyediakan kumpulan sumber daya khusus untuk aplikasi apa pun untuk operasi yang benar dan stabil.  Tetapi bagaimana jika beberapa aplikasi bekerja pada kapasitas yang sama sekaligus?  Bagaimana menyediakan sumber daya minimum yang diperlukan untuk masing-masing sumber daya tersebut?  Bagaimana saya bisa membatasi konsumsi sumber daya?  Bagaimana cara mendistribusikan beban antar node dengan benar?  Bagaimana memastikan mekanisme penskalaan horizontal jika terjadi peningkatan beban pada aplikasi? </p><br><p><img src="https://habrastorage.org/webt/-f/yj/hw/-fyjhwhkhcibnshgzndgd4w4e_c.png"></p><a name="habracut"></a><br><p>  Anda harus mulai dengan jenis sumber daya dasar apa yang ada dalam sistem - tentu saja, waktu prosesor dan RAM.  Dalam manifes k8, jenis sumber daya ini diukur dalam unit berikut: </p><br><ul><li>  CPU - di dalam inti </li><li>  RAM - dalam byte </li></ul><br><p>  Selain itu, untuk setiap sumber daya ada peluang untuk menetapkan dua jenis persyaratan - <strong>permintaan</strong> dan <strong>batasan</strong> .  Permintaan - menguraikan persyaratan minimum untuk sumber daya bebas simpul untuk menjalankan wadah (dan perapian secara keseluruhan), sementara batas menetapkan batas ketat pada sumber daya yang tersedia untuk wadah. </p><br><p>  Penting untuk dipahami bahwa dalam manifes tidak perlu mendefinisikan kedua jenis secara eksplisit, dan perilaku tersebut adalah sebagai berikut: </p><br><ul><li>  Jika hanya batas sumber daya yang ditetapkan secara eksplisit, maka permintaan untuk sumber daya ini secara otomatis mengambil nilai yang sama dengan batas (ini dapat diverifikasi dengan memanggil entitas yang dijelaskan).  Yaitu  pada kenyataannya, pengoperasian wadah akan dibatasi oleh jumlah sumber daya yang sama yang diperlukan untuk menjalankannya. </li><li>  Jika hanya permintaan yang ditetapkan secara eksplisit untuk sumber daya, maka tidak ada batasan yang ditetapkan di atas sumber daya ini - yaitu.  wadah hanya dibatasi oleh sumber daya dari simpul itu sendiri. </li></ul><br><p>  Dimungkinkan juga untuk mengkonfigurasi manajemen sumber daya tidak hanya pada level wadah tertentu, tetapi juga pada tingkat namespace menggunakan entitas berikut: </p><br><ul><li>  <strong>LimitRange</strong> - menguraikan kebijakan pembatasan di tingkat wadah / perapian di ns dan diperlukan untuk menjelaskan batasan default pada wadah / perapian, serta untuk mencegah penciptaan wadah / perapian yang jelas-jelas gemuk (atau sebaliknya), batasi jumlah mereka dan tentukan perbedaan yang mungkin dalam nilai dalam batas-batas dan permintaan </li><li>  <strong>ResourceQuotas</strong> - menggambarkan kebijakan pembatasan secara umum untuk semua kontainer di ns dan digunakan, sebagai aturan, untuk membedakan sumber daya antara lingkungan (berguna ketika lingkungan tidak dibatasi secara kaku pada tingkat node) </li></ul><br><p>  Berikut ini adalah contoh manifes di mana batas sumber daya ditetapkan: </p><br><ul><li><p>  Di tingkat wadah khusus: </p><br><pre><code class="plaintext hljs">containers: - name: app-nginx image: nginx resources: requests: memory: 1Gi limits: cpu: 200m</code> </pre> <br><p>  Yaitu  dalam hal ini, untuk memulai sebuah wadah dengan nginx, Anda akan memerlukan setidaknya ketersediaan 1G OP dan 0,2 CPU pada node, sedangkan wadah maksimum dapat memakan 0,2 CPU dan semua OP yang tersedia pada node. </p><br></li><li><p>  Pada tingkat integer ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: ResourceQuota metadata: name: nxs-test spec: hard: requests.cpu: 300m requests.memory: 1Gi limits.cpu: 700m limits.memory: 2Gi</code> </pre> <br><p>  Yaitu  jumlah semua kontainer permintaan dalam ns default tidak dapat melebihi 300m untuk CPU dan 1G untuk OP, dan jumlah semua batas adalah 700m untuk CPU dan 2G untuk OP. </p><br></li><li><p>  Pembatasan default untuk wadah di ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-per-container spec: limits: - type: Container defaultRequest: cpu: 100m memory: 1Gi default: cpu: 1 memory: 2Gi min: cpu: 50m memory: 500Mi max: cpu: 2 memory: 4Gi</code> </pre> <br><p>  Yaitu  di namespace default untuk semua kontainer, secara default, permintaan akan diatur ke 100m untuk CPU dan 1G untuk OP, batas - 1 CPU dan 2G.  Pada saat yang sama, pembatasan juga ditetapkan pada nilai yang mungkin dalam permintaan / batas untuk CPU (50m &lt;x &lt;2) dan RAM (500M &lt;x &lt;4G). </p><br></li><li><p>  Keterbatasan pada tingkat perapian ns </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-pod spec: limits: - type: Pod max: cpu: 4 memory: 1Gi</code> </pre> <br><p>  Yaitu  untuk setiap perapian di ns default, batas 4 vCPU dan 1G akan ditetapkan. </p><br></li></ul><br><p>  Sekarang saya ingin memberi tahu Anda apa keuntungan yang dapat diberikan pemasangan pembatasan ini kepada kami. </p><br><h2 id="mehanizm-balansirovki-nagruzki-mezhdu-nodami">  Mekanisme load balancing antar node </h2><br><p>  Seperti yang Anda ketahui, komponen k8s seperti <strong>scheduler</strong> , yang bekerja sesuai dengan algoritma tertentu, bertanggung jawab untuk distribusi perapian di atas node.  Algoritma ini dalam proses memilih node optimal untuk dijalankan melalui dua tahap: </p><br><ol><li>  Penyaringan </li><li>  Peringkat </li></ol><br><p>  Yaitu  sesuai dengan kebijakan yang dijelaskan, node pada awalnya dipilih di mana perapian dapat diluncurkan berdasarkan seperangkat <strong>predikat</strong> (termasuk apakah node memiliki sumber daya yang cukup untuk menjalankan perapian - PodFitsResources), dan kemudian poin diberikan untuk masing-masing node, sesuai dengan <strong>prioritas</strong> (termasuk, semakin banyak sumber daya gratis yang dimiliki node - semakin banyak poin yang ditetapkan - LeastResourceAllocation / LeastRequestedPriority / BalancedResourceAllocation) dan dijalankan pada node dengan poin terbanyak (jika beberapa node memenuhi kondisi ini sekaligus, maka yang acak dipilih). </p><br><p>  Pada saat yang sama, Anda perlu memahami bahwa penjadwal, ketika mengevaluasi sumber daya yang tersedia dari node, berfokus pada data yang disimpan dalam etcd - yaitu.  dengan jumlah sumber daya yang diminta / dibatasi dari setiap pod yang berjalan pada node ini, tetapi tidak oleh konsumsi sumber daya yang sebenarnya.  Informasi ini dapat diperoleh dalam output dari <code>kubectl describe node $NODE</code> perintah, misalnya: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># kubectl describe nodes nxs-k8s-s1 .. Non-terminated Pods: (9 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits AGE --------- ---- ------------ ---------- --------------- ------------- --- ingress-nginx nginx-ingress-controller-754b85bf44-qkt2t 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-flannel-26bl4 150m (0%) 300m (1%) 64M (0%) 500M (1%) 233d kube-system kube-proxy-exporter-cb629 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-proxy-x9fsc 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system nginx-proxy-k8s-worker-s1 25m (0%) 300m (1%) 32M (0%) 512M (1%) 233d nxs-monitoring alertmanager-main-1 100m (0%) 100m (0%) 425Mi (1%) 25Mi (0%) 233d nxs-logging filebeat-lmsmp 100m (0%) 0 (0%) 100Mi (0%) 200Mi (0%) 233d nxs-monitoring node-exporter-v4gdq 112m (0%) 122m (0%) 200Mi (0%) 220Mi (0%) 233d Allocated resources: (Total limits may be over 100 percent, ie, overcommitted.) Resource Requests Limits -------- -------- ------ cpu 487m (3%) 822m (5%) memory 15856217600 (2%) 749976320 (3%) ephemeral-storage 0 (0%) 0 (0%)</span></span></code> </pre> <br><p>  Di sini kita melihat semua pod berjalan pada node tertentu, serta sumber daya yang diminta masing-masing pod.  Dan inilah tampilan log scheduler ketika memulai cronjob-cron-events-1573793820-xt6q9 pod (informasi ini muncul di log scheduler ketika mengatur level 10 logging dalam argumen pada perintah start --v = 10): </p><br><div class="spoiler">  <b class="spoiler_title">camar yang luas</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">I1115 07:57:21.637791 1 scheduling_queue.go:908] About to try and schedule pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.637804 1 scheduler.go:453] Attempting to schedule pod: nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.638285 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s5 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638300 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s6 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s3 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s4 is allowed, Node is running only 17 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638365 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s12 is allowed, Node is running only 9 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s11 is allowed, Node is running only 11 out of 110 Pods. I1115 07:57:21.638385 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s1 is allowed, Node is running only 19 out of 110 Pods. I1115 07:57:21.638402 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s2 is allowed, Node is running only 21 out of 110 Pods. I1115 07:57:21.638383 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638335 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, Node is running only 18 out of 110 Pods. I1115 07:57:21.638408 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s13 is allowed, Node is running only 8 out of 110 Pods. I1115 07:57:21.638478 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638505 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638577 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638583 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s7 is allowed, Node is running only 25 out of 110 Pods. I1115 07:57:21.638932 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 9 I1115 07:57:21.638946 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 8 I1115 07:57:21.638961 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: BalancedResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 9 I1115 07:57:21.638971 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.638975 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: LeastResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 8 I1115 07:57:21.638990 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.639022 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: TaintTolerationPriority, Score: (10) I1115 07:57:21.639030 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: TaintTolerationPriority, Score: (10) I1115 07:57:21.639034 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: TaintTolerationPriority, Score: (10) I1115 07:57:21.639041 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: NodeAffinityPriority, Score: (0) I1115 07:57:21.639053 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: NodeAffinityPriority, Score: (0) I1115 07:57:21.639059 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: NodeAffinityPriority, Score: (0) I1115 07:57:21.639061 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639063 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639073 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639077 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639085 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639088 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639103 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639109 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639114 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639127 1 generic_scheduler.go:781] Host nxs-k8s-s10 =&gt; Score 100037 I1115 07:57:21.639150 1 generic_scheduler.go:781] Host nxs-k8s-s8 =&gt; Score 100034 I1115 07:57:21.639154 1 generic_scheduler.go:781] Host nxs-k8s-s9 =&gt; Score 100037 I1115 07:57:21.639267 1 scheduler_binder.go:269] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10" I1115 07:57:21.639286 1 scheduler_binder.go:279] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10": all PVCs bound and nothing to do I1115 07:57:21.639333 1 factory.go:733] Attempting to bind cronjob-cron-events-1573793820-xt6q9 to nxs-k8s-s10</code> </pre> </div></div><br><p>  Di sini kita melihat bahwa pada awalnya penjadwal melakukan penyaringan dan membentuk daftar 3 simpul yang memungkinkan untuk dijalankan (nxs-k8s-s8, nxs-k8s-s9, nxs-k8s-s10).  Ini kemudian menghitung poin sesuai dengan beberapa parameter (termasuk BalancedResourceAllocation, LeastResourceAllocation) untuk masing-masing node ini untuk menentukan simpul yang paling cocok.  Pada akhirnya, ini direncanakan di bawah simpul dengan poin terbanyak (di sini, dua node sekaligus memiliki jumlah poin yang sama 100037, jadi yang dipilih secara acak - nxs-k8s-s10). </p><br><p>  <strong>Kesimpulan</strong> : jika pod bekerja pada node yang tidak ada batasan, maka untuk k8 (dari sudut pandang konsumsi sumber daya) ini akan sama dengan jika pod tersebut benar-benar tidak ada pada node ini.  Oleh karena itu, jika Anda memiliki pod dengan proses yang rakus (misalnya, wowza) dan tidak ada batasan untuk itu, maka sebuah situasi dapat muncul ketika sebenarnya yang diberikan telah memakan semua sumber daya dari node, tetapi untuk k8s node ini dianggap diturunkan dan itu akan diberikan jumlah poin yang sama ketika peringkat (yaitu, dalam poin dengan penilaian sumber daya yang tersedia), serta simpul yang tidak memiliki lapangan kerja, yang pada akhirnya dapat menyebabkan distribusi beban yang tidak merata antara node. </p><br><h2 id="vyselenie-poda">  Penggusuran perapian </h2><br><p>  Seperti yang Anda ketahui, masing-masing pod diberikan salah satu dari 3 kelas QoS: </p><br><ol><li>  <strong>dijamin</strong> - ditugaskan ketika permintaan dan batas ditetapkan untuk setiap wadah di perapian untuk memori dan cpu, dan nilai-nilai ini harus cocok </li><li>  <strong>burstable</strong> - setidaknya satu kontainer di perapian memiliki permintaan dan batas, sementara permintaan &lt;batas </li><li>  <strong>upaya terbaik</strong> - ketika tidak ada wadah di perapian yang terbatas sumber dayanya </li></ol><br><p>  Pada saat yang sama, ketika ada kekurangan sumber daya (disk, memori) pada node, kubelet mulai membuat peringkat dan mengusir pod menurut algoritma tertentu yang memperhitungkan prioritas pod dan kelas QoS-nya.  Sebagai contoh, jika kita berbicara tentang RAM, maka berdasarkan poin kelas QoS diberikan sesuai dengan prinsip berikut: </p><br><ul><li>  <strong>Dijamin</strong> : -998 </li><li>  <strong>Usaha Terbaik</strong> : 1000 </li><li>  <strong>Burstable</strong> : min (maks (2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999) </li></ul><br><p>  Yaitu  dengan prioritas yang sama, kubelet pertama-tama akan mengeluarkan pod dengan upaya QoS class terbaik dari node. </p><br><p>  <strong>Kesimpulan</strong> : jika Anda ingin mengurangi kemungkinan penggusuran pod yang diperlukan dari node jika sumber daya tidak mencukupi, maka bersama dengan prioritas, Anda juga harus berhati-hati dalam mengatur permintaan / batas untuk itu. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-podov-prilozheniya-hpa">  Mekanisme auto-scaling horizontal hearth aplikasi (HPA) </h2><br><p>  Ketika tugas adalah untuk secara otomatis menambah dan mengurangi jumlah pod tergantung pada penggunaan sumber daya (sistem - CPU / RAM atau pengguna - rps), k8s seperti <strong>HPA</strong> (Horizontal Pod Autoscaler) dapat membantu dalam solusinya.  Algoritanya adalah sebagai berikut: </p><br><ol><li>  Pembacaan saat ini dari sumber daya yang diamati (currentMetricValue) ditentukan </li><li>  Nilai yang diinginkan untuk sumber daya (NilaiMetri yang diinginkan) ditentukan, yang ditetapkan untuk sumber daya sistem menggunakan permintaan </li><li>  Jumlah replika saat ini ditentukan (currentReplicas) </li><li>  Rumus berikut menghitung jumlah replika yang diinginkan (Replika yang diinginkan) <br>  diinginkanReplicas = [currentReplicas * (currentMetricValue / diinginkanMetricValue)] </li></ol><br><p>  Namun, penskalaan tidak akan terjadi ketika koefisien (currentMetricValue / diinginkanMetricValue) mendekati 1 (kita dapat mengatur sendiri kesalahan yang diijinkan, secara default adalah 0,1). </p><br><p>  Pertimbangkan hpa menggunakan aplikasi uji aplikasi (dijelaskan sebagai Penempatan), di mana perlu untuk mengubah jumlah replika, tergantung pada konsumsi CPU: </p><br><ul><li><p>  Manifes aplikasi </p><br><pre> <code class="plaintext hljs">kind: Deployment apiVersion: apps/v1beta2 metadata: name: app-test spec: selector: matchLabels: app: app-test replicas: 2 template: metadata: labels: app: app-test spec: containers: - name: nginx image: registry.nixys.ru/generic-images/nginx imagePullPolicy: Always resources: requests: cpu: 60m ports: - name: http containerPort: 80 - name: nginx-exporter image: nginx/nginx-prometheus-exporter resources: requests: cpu: 30m ports: - name: nginx-exporter containerPort: 9113 args: - -nginx.scrape-uri - http://127.0.0.1:80/nginx-status</code> </pre> <br><p>  Yaitu  kita melihat bahwa di bawah dengan aplikasi itu awalnya diluncurkan dalam dua contoh, yang masing-masing berisi dua kontainer nginx dan nginx-eksportir, untuk masing-masing <strong>permintaan</strong> CPU diberikan. </p><br></li><li><p>  Manifes HPA </p><br><pre> <code class="plaintext hljs">apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: app-test-hpa spec: maxReplicas: 10 minReplicas: 2 scaleTargetRef: apiVersion: extensions/v1beta1 kind: Deployment name: app-test metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 30</code> </pre> <br><p>  Yaitu  kami menciptakan hpa yang akan memantau uji aplikasi Penempatan dan menyesuaikan jumlah perapian dengan aplikasi berdasarkan indikator cpu (kami berharap bahwa perapian harus mengkonsumsi 30% persen dari CPU yang diminta olehnya), sementara jumlah replika berada dalam kisaran 2-10. </p><br><p>  Sekarang, kami akan mempertimbangkan mekanisme operasi hpa jika kami menerapkan beban ke salah satu perapian: </p><br><pre> <code class="bash hljs"> <span class="hljs-comment"><span class="hljs-comment"># kubectl top pod NAME CPU(cores) MEMORY(bytes) app-test-78559f8f44-pgs58 101m 243Mi app-test-78559f8f44-cj4jz 4m 240Mi</span></span></code> </pre> <br></li></ul><br><p>  Total kami memiliki yang berikut: </p><br><ul><li>  Nilai yang diinginkan (diinginkanMetricValue) - sesuai dengan pengaturan hpa, kami memiliki 30% </li><li>  Nilai saat ini (currentMetricValue) - untuk perhitungan, pengontrol-manajer menghitung nilai rata-rata konsumsi sumber daya dalam%, mis.  kondisional melakukan hal berikut: <br><ol><li>  Mendapat nilai absolut metrik perapian dari server metrik, mis.  101 m dan 4 m </li><li>  Menghitung nilai absolut rata-rata, mis.  (101m + 4m) / 2 = 53m </li><li>  Mendapat nilai absolut untuk konsumsi sumber daya yang diinginkan (untuk ini, permintaan semua kontainer dijumlahkan) 60m + 30m = 90m </li><li>  Menghitung persentase rata-rata konsumsi CPU relatif terhadap perapian permintaan, mis.  53m / 90m * 100% = 59% </li></ol></li></ul><br><p>  Sekarang kita memiliki semua yang diperlukan untuk menentukan apakah perlu mengubah jumlah replika, untuk ini kita menghitung koefisien: </p><br><p> <code>ratio = 59% / 30% = 1.96</code> </p> <br><p>  Yaitu  jumlah replika harus ditambah ~ 2 kali dan make up [2 * 1.96] = 4. </p><br><p>  <strong>Kesimpulan:</strong> Seperti yang Anda lihat, agar mekanisme ini berfungsi, prasyarat termasuk ketersediaan permintaan untuk semua kontainer di perapian yang diamati. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-nod-cluster-autoscaler">  Mekanisme penskalaan otomatis antar node (Cluster Autoscaler) </h2><br><p>  Untuk menetralkan dampak negatif pada sistem selama semburan beban, keberadaan hpa yang disetel tidak cukup.  Misalnya, menurut pengaturan di manajer pengontrol hpa memutuskan bahwa jumlah replika perlu ditingkatkan 2 kali, namun, tidak ada sumber daya gratis pada node untuk menjalankan sejumlah pod (mis. Node tidak dapat menyediakan sumber daya yang diminta untuk permintaan pod) dan pod ini masukkan status Tertunda. </p><br><p>  Dalam hal ini, jika penyedia memiliki IaaS / PaaS yang sesuai (misalnya, GKE / GCE, AKS, EKS, dll.), Alat seperti <strong>Node Autoscaler</strong> dapat membantu kami.  Ini memungkinkan Anda untuk mengatur jumlah node maksimum dan minimum dalam cluster dan secara otomatis menyesuaikan jumlah node saat ini (dengan mengakses API penyedia cloud untuk memesan / menghapus node) ketika ada kekurangan sumber daya dalam cluster dan pod tidak dapat dijadwalkan (dalam kondisi Pending). </p><br><p>  <strong>Kesimpulan:</strong> untuk dapat secara otomatis skala node, perlu untuk menentukan permintaan dalam wadah perapian sehingga k8s dapat dengan benar mengevaluasi beban node dan karenanya melaporkan bahwa tidak ada sumber daya dalam cluster untuk memulai perapian berikutnya. </p><br><hr><br><h2 id="zaklyuchenie">  Kesimpulan </h2><br><p>  Perlu dicatat bahwa pengaturan batas sumber daya untuk wadah bukanlah prasyarat untuk keberhasilan peluncuran aplikasi, tetapi masih lebih baik untuk melakukan ini karena alasan berikut: </p><br><ol><li>  Untuk operasi penjadwal yang lebih akurat dalam hal load balancing antara node k8s </li><li>  Untuk mengurangi kemungkinan terjadinya peristiwa penggusuran jantung </li><li>  Untuk perapian aplikasi penskalaan horizontal (HPA) </li><li>  Untuk penskalaan otomatis antar titik (Cluster Autoscaling) untuk penyedia cloud </li></ol><br><h2 id="takzhe-chitayte-drugie-stati-v-nashem-bloge">  Baca juga artikel lain di blog kami: </h2><br><ul><li>  <a href="https://habr.com/ru/company/nixys/blog/481992/">Tekton Pipeline - jaringan pipa asli Kubernetes</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/473578/">Membangun Modul Dinamis untuk Nginx</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/468779/">Apa hasil migrasi dari ClickHouse tanpa otorisasi ke ClickHouse dengan otorisasi</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/461723/">Memahami paket Konteks di Golang</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/437372/">Tiga trik sederhana untuk mengurangi gambar buruh pelabuhan</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/424717/">Mencadangkan sejumlah besar proyek web heterogen</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id480072/">https://habr.com/ru/post/id480072/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id480060/index.html">Klasifikasi P300 sederhana pada data terbuka</a></li>
<li><a href="../id480062/index.html">10 sistem kontrol. Di mana lebih nyaman untuk berkomunikasi tentang tugas dan berbagi file?</a></li>
<li><a href="../id480064/index.html">Belajar kata-kata dikelompokkan secara tematis</a></li>
<li><a href="../id480068/index.html">[Perbarui] Orang-orang kami dipukuli, dan kami akan diam?</a></li>
<li><a href="../id480070/index.html">Bereaksi manfaat: Sebuah berkah untuk Bisnis?</a></li>
<li><a href="../id480076/index.html">Proses ganda dan rekonsiliasi data dari berbagai sumber</a></li>
<li><a href="../id480078/index.html">Perpustakaan front-end baru di React peripherals</a></li>
<li><a href="../id480080/index.html">Apa yang Anda butuhkan dalam mencatat aplikasi?</a></li>
<li><a href="../id480082/index.html">Menggunakan partisi di MySQL untuk Zabbix dengan sejumlah besar objek pemantauan</a></li>
<li><a href="../id480086/index.html">Cara mematuhi persyaratan 152-FZ, melindungi data pribadi pelanggan kami dan tidak menginjak kami</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
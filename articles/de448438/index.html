<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õèÔ∏è üë®üèΩ‚Äçüéì üåü Begrenzen der Geschwindigkeit der Verarbeitung von Anforderungen oder wie Sie keinen DDoS-Angriff auf Ihren Client arrangieren üçÖ ü§∂üèø üåµ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bei der Entwicklung eines Hochlastprodukts tritt manchmal die Situation auf, dass nicht so viele Anforderungen wie m√∂glich verarbeitet werden m√ºssen, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Begrenzen der Geschwindigkeit der Verarbeitung von Anforderungen oder wie Sie keinen DDoS-Angriff auf Ihren Client arrangieren</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448438/"><p> Bei der Entwicklung eines Hochlastprodukts tritt manchmal die Situation auf, dass nicht so viele Anforderungen wie m√∂glich verarbeitet werden m√ºssen, sondern die Anzahl der Anforderungen pro Zeiteinheit begrenzt werden muss.  In unserem Fall ist dies die Anzahl der Push-Benachrichtigungen, die an Endbenutzer gesendet werden.  Lesen Sie mehr √ºber Ratenbegrenzungsalgorithmen, ihre Vor- und Nachteile - unter dem Strich. </p><br><a name="habracut"></a><br><p>  Zun√§chst ein wenig √ºber uns.  Pushwoosh ist ein B2B-Dienst f√ºr die Kommunikation zwischen unseren Kunden und ihren Benutzern.  Wir bieten Unternehmen umfassende L√∂sungen f√ºr die Kommunikation mit Benutzern √ºber Push-Benachrichtigungen, E-Mail und andere Kommunikationskan√§le.  Neben dem eigentlichen Senden von Nachrichten bieten wir Tools zum Segmentieren der Zielgruppe, Sammeln und Verarbeiten von Statistiken und vieles mehr.  Zu diesem Zweck haben wir von Grund auf ein Hochlastprodukt an der Schnittstelle vieler Technologien entwickelt, von denen nur ein kleiner Teil PHP, Golang, PostgreSQL, MongoDB und Apache Kafka sind.  Viele unserer L√∂sungen sind einzigartig, beispielsweise Hochgeschwindigkeitsbenachrichtigungen.  Wir verarbeiten mehr als 2 Milliarden API-Anfragen pro Tag, wir haben mehr als 3 Milliarden Ger√§te in unserer Datenbank und √ºber die gesamte Zeit haben wir mehr als 500 Milliarden Benachrichtigungen an diese Ger√§te gesendet. </p><br><p>  Und hier kommen wir zu einer Situation, in der Benachrichtigungen nicht so schnell wie m√∂glich (wie bei der bereits erw√§hnten Hochgeschwindigkeit) an Millionen von Ger√§ten gesendet werden m√ºssen, sondern die Geschwindigkeit k√ºnstlich begrenzen, damit die Server unserer Clients, zu denen Benutzer gehen, wenn sie die Benachrichtigung √∂ffnen, nicht unter dieselbe Zeit fallen laden. <br></p><br><p>  Hier helfen uns verschiedene Algorithmen zur Ratenbegrenzung, mit denen wir die Anzahl der Anforderungen pro Zeiteinheit begrenzen k√∂nnen.  In der Regel wird dies beispielsweise beim Entwerfen einer API verwendet, da wir auf diese Weise das System vor versehentlichem oder b√∂swilligem √úberma√ü an Anforderungen sch√ºtzen k√∂nnen, wodurch eine Verz√∂gerung oder ein Denial-of-Service f√ºr andere Clients auftritt.  Wenn eine Ratenbegrenzung implementiert ist, sind alle Clients auf eine feste Anzahl von Anforderungen pro Zeiteinheit beschr√§nkt.  Dar√ºber hinaus kann die Ratenbegrenzung verwendet werden, wenn auf Teile des Systems zugegriffen wird, die vertraulichen Daten zugeordnet sind.  Wenn ein Angreifer Zugriff auf sie erh√§lt, kann er nicht schnell auf alle Daten zugreifen. <br></p><br><p>  Es gibt viele verschiedene M√∂glichkeiten, eine Ratenbegrenzung zu implementieren.  In diesem Artikel werden die Vor- und Nachteile verschiedener Algorithmen sowie die Probleme betrachtet, die bei der Skalierung dieser L√∂sungen auftreten k√∂nnen. <br></p><br><h2>  Algorithmen zur Geschwindigkeitsbegrenzung f√ºr die Anforderungsverarbeitung </h2><br><h3>  Undichter Eimer (undichter Eimer) </h3><br><p>  <i>Leaky Bucket</i> ist ein Algorithmus, der den einfachsten und intuitivsten Ansatz zur Begrenzung der Verarbeitungsgeschwindigkeit mithilfe einer Warteschlange bietet, die als "Bucket" mit Anforderungen dargestellt werden kann.  Wenn eine Anfrage empfangen wird, wird sie am Ende der Warteschlange hinzugef√ºgt.  In regelm√§√üigen Abst√§nden wird das erste Element in der Warteschlange verarbeitet.  Dies wird auch als <abbr title="First In - First Out">FIFO-</abbr> Warteschlange bezeichnet.  Wenn die Warteschlange voll ist, werden zus√§tzliche Anforderungen verworfen (oder "Leck"). <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fo/jw/hy/fojwhyst1w3e6fij2eh6lsb04y8.gif" alt="Token Bucket rendern"></div><br><p>  Der Vorteil dieses Algorithmus besteht darin, dass er Ausbr√ºche gl√§ttet und Anforderungen mit ungef√§hr derselben Geschwindigkeit verarbeitet. Er ist einfach auf einem einzelnen Server oder Load Balancer zu implementieren und effizient im Speicher zu verwenden, da die Warteschlangengr√∂√üe f√ºr jeden Benutzer begrenzt ist. <br>  Bei einem starken Anstieg des Datenverkehrs kann die Warteschlange jedoch mit alten Anforderungen gef√ºllt sein und dem System die M√∂glichkeit nehmen, neuere Anforderungen zu verarbeiten.  Er garantiert auch nicht, dass Anfragen zu einem festgelegten Zeitpunkt bearbeitet werden.  Wenn Sie Balancer laden, um Fehlertoleranz bereitzustellen oder den Durchsatz zu erh√∂hen, m√ºssen Sie au√üerdem eine Koordinierungsrichtlinie implementieren und eine globale Einschr√§nkung zwischen ihnen sicherstellen. <br></p><br><p>  Es gibt eine Variation dieses Algorithmus - <i>Token Bucket</i> ("Bucket with Token" oder "Marker Basket Algorithmus"). <br></p><br><p>  In einer solchen Implementierung werden Token mit einer konstanten Geschwindigkeit zum "Bucket" hinzugef√ºgt, und bei der Verarbeitung der Anforderung wird das Token aus dem "Bucket" gel√∂scht.  Wenn nicht gen√ºgend Token vorhanden sind, wird die Anforderung verworfen.  Sie k√∂nnen den Zeitstempel einfach als Token verwenden. <br></p><br><p>  Es gibt Variationen, bei denen mehrere "Eimer" verwendet werden, w√§hrend sowohl die Gr√∂√üe als auch die Empfangsrate der darin enthaltenen Token f√ºr einzelne "Eimer" unterschiedlich sein k√∂nnen.  Wenn im ersten "Bucket" nicht gen√ºgend Token vorhanden sind, um die Anforderung zu verarbeiten, wird deren Vorhandensein im zweiten usw. √ºberpr√ºft, aber die Priorit√§t der Anforderungsverarbeitung wird verringert (dies wird in der Regel beim Entwurf von Netzwerkschnittstellen verwendet, wenn Sie beispielsweise den Feldwert √§ndern k√∂nnen <abbr title="Codepunkt f√ºr differenzierte Dienste">DSCP-</abbr> verarbeitetes Paket). <br></p><br><p>  Der Hauptunterschied zur Implementierung von <i>Leaky Bucket</i> besteht darin, dass sich Token ansammeln k√∂nnen, wenn das System inaktiv ist, und Bursts sp√§ter auftreten k√∂nnen, w√§hrend die Anforderungen verarbeitet werden (da gen√ºgend Token vorhanden sind), w√§hrend <i>Leaky Bucket</i> die Last garantiert gl√§ttet auch bei Ausfallzeiten. <br></p><br><h3>  Festes Fenster </h3><br><p>  Dieser Algorithmus verwendet ein Fenster von n Sekunden, um Anforderungen zu verfolgen.  In der Regel werden Werte wie 60 Sekunden (Minute) oder 3600 Sekunden (Stunde) verwendet.  Jede eingehende Anfrage erh√∂ht den Z√§hler f√ºr dieses Fenster.  Wenn der Z√§hler einen bestimmten Schwellenwert √ºberschreitet, wird die Anforderung verworfen.  In der Regel wird das Fenster durch die untere Grenze des aktuellen Zeitintervalls bestimmt. Wenn das Fenster also 60 Sekunden breit ist, wird die um 12:00:03 Uhr eintreffende Anforderung an das Fenster 12:00:00 Uhr gesendet. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w3/lz/di/w3lzdijb2gk80a6rltf7rs2ejz8.gif" alt="Festes Rendern"></div><br><p>  Der Vorteil dieses Algorithmus besteht darin, dass er die Verarbeitung neuerer Anforderungen erm√∂glicht, ohne von der Verarbeitung alter Anforderungen abh√§ngig zu sein.  Ein einzelner Verkehrssto√ü in der N√§he des Fensterrahmens kann jedoch die Anzahl der verarbeiteten Anforderungen verdoppeln, da Anforderungen f√ºr das aktuelle und das n√§chste Fenster f√ºr einen kurzen Zeitraum zul√§ssig sind.  Wenn viele Benutzer beispielsweise am Ende der Stunde auf das Zur√ºcksetzen des Fensterz√§hlers warten, k√∂nnen sie zu diesem Zeitpunkt eine Erh√∂hung der Last provozieren, da sie gleichzeitig auf die API zugreifen. <br></p><br><h3>  Schiebeprotokoll </h3><br><p>  Dieser Algorithmus beinhaltet das Verfolgen von Zeitstempeln jeder Benutzeranforderung.  Diese Datens√§tze werden beispielsweise in einem Hash-Set oder einer Hash-Tabelle gespeichert und nach Zeit sortiert.  Datens√§tze au√üerhalb des √ºberwachten Intervalls werden verworfen.  Wenn eine neue Anfrage eingeht, berechnen wir die Anzahl der Datens√§tze, um die H√§ufigkeit der Anfragen zu bestimmen.  Wenn die Anforderung au√üerhalb der zul√§ssigen Menge liegt, wird sie verworfen. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nv/8a/9z/nv8a9zz0_ycg7sm4htfair2fk44.gif" alt="Visualization Sliding Log"></div><br><p>  Der Vorteil dieses Algorithmus besteht darin, dass er keinen Problemen unterliegt, die an den R√§ndern des <i>festen Fensters auftreten</i> , <i>dh</i> die Geschwindigkeitsbegrenzung wird strikt eingehalten.  Da die Anforderungen jedes Clients einzeln √ºberwacht werden, gibt es au√üerdem an bestimmten Punkten kein Spitzenlastwachstum, was ein weiteres Problem des vorherigen Algorithmus darstellt. <br></p><br><p>  Das Speichern von Informationen zu jeder Anforderung kann jedoch teuer sein. Dar√ºber hinaus muss f√ºr jede Anforderung die Anzahl der vorherigen Anforderungen berechnet werden, m√∂glicherweise f√ºr den gesamten Cluster. Infolgedessen l√§sst sich dieser Ansatz nicht gut skalieren, um gro√üe Verkehrsst√∂√üe und Denial-of-Service-Angriffe zu bew√§ltigen. <br></p><br><h3>  Schiebefenster </h3><br><p>  Dies ist ein hybrider Ansatz, der die geringen Kosten f√ºr die Verarbeitung eines <i>festen Fensters</i> und die erweiterte Behandlung von Grenzsituationen kombiniert.  Wie im einfachen <i>festen Fenster</i> verfolgen wir den Z√§hler f√ºr jedes Fenster und ber√ºcksichtigen dann den gewichteten Wert der Anforderungsh√§ufigkeit des vorherigen Fensters basierend auf dem aktuellen Zeitstempel, um Verkehrsst√∂√üe auszugleichen.  Wenn beispielsweise 25% der Zeit des aktuellen Fensters vergangen sind, ber√ºcksichtigen wir 75% der Anforderungen des vorherigen Fensters.  Die relativ geringe Datenmenge, die f√ºr die Verfolgung der einzelnen Schl√ºssel ben√∂tigt wird, erm√∂glicht es uns, in einem gro√üen Cluster zu skalieren und zu arbeiten. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jx/yz/ps/jxyzpszmkozfruckcg2s5lhsmd0.gif" alt="Visualisierungs-Schiebefenster"></div><br><p>  Mit diesem Algorithmus k√∂nnen Sie die Ratenbegrenzung skalieren und gleichzeitig eine gute Leistung erzielen.  Dar√ºber hinaus ist dies eine verst√§ndliche M√∂glichkeit, Kunden Informationen zur Begrenzung der Anzahl von Anforderungen zu √ºbermitteln und die Probleme zu vermeiden, die bei der Implementierung anderer Algorithmen zur Ratenbegrenzung auftreten. <br></p><br><h2>  Ratenbegrenzung in verteilten Systemen </h2><br><h3>  Richtlinien synchronisieren </h3><br><p>  Wenn Sie beim Zugriff auf einen Cluster, der aus mehreren Knoten besteht, die globale Ratenbegrenzung festlegen m√∂chten, m√ºssen Sie eine Einschr√§nkungsrichtlinie implementieren.  Wenn jeder Knoten nur seine eigene Einschr√§nkung verfolgt, kann der Benutzer diese umgehen, indem er einfach Anforderungen an verschiedene Knoten sendet.  Je gr√∂√üer die Anzahl der Knoten ist, desto gr√∂√üer ist die Wahrscheinlichkeit, dass der Benutzer das globale Limit √ºberschreiten kann. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nb/iq/30/nbiq30phqg_b0zibtuoagajyl50.gif" alt="Visualisierung der fehlenden Synchronisation"></div><br><p>  Der einfachste Weg, Limits festzulegen, besteht darin, eine ‚ÄûSticky-Sitzung‚Äú auf dem Balancer so zu konfigurieren, dass der Benutzer zum selben Knoten geleitet wird.  Die Nachteile dieser Methode sind das Fehlen von Fehlertoleranz und Skalierungsproblemen, wenn Clusterknoten √ºberlastet sind. <br></p><br><p>  Die beste L√∂sung, die flexiblere Regeln f√ºr den Lastausgleich erm√∂glicht, ist die Verwendung eines zentralen Data Warehouse (Ihrer Wahl).  Es kann Z√§hler f√ºr die Anzahl der Anforderungen f√ºr jedes Fenster und jeden Benutzer speichern.  Die Hauptprobleme dieses Ansatzes sind die Verl√§ngerung der Antwortzeit aufgrund von Speicheranforderungen und Rennbedingungen. <br></p><br><h3>  Rennbedingungen </h3><br><p>  Eines der gr√∂√üten Probleme bei einem zentralen Data Warehouse ist die M√∂glichkeit von Rennbedingungen im Wettbewerb.  Dies geschieht, wenn Sie den nat√ºrlichen Get-Then-Set-Ansatz verwenden, bei dem Sie den aktuellen Z√§hler extrahieren, inkrementieren und dann den resultierenden Wert an den Speicher zur√ºcksenden.  Das Problem bei diesem Modell besteht darin, dass w√§hrend der Zeit, die erforderlich ist, um den vollst√§ndigen Zyklus dieser Operationen abzuschlie√üen (dh Lesen, Inkrementieren und Schreiben), andere Anforderungen eingehen k√∂nnen, bei denen der Z√§hler jeweils mit einem ung√ºltigen (niedrigeren) Wert gespeichert wird.  Auf diese Weise kann der Benutzer mehr Anforderungen senden, als der Algorithmus zur Ratenbegrenzung bereitstellt. <br></p><br><p>  Eine M√∂glichkeit, dieses Problem zu vermeiden, besteht darin, eine Sperre um den betreffenden Schl√ºssel zu setzen, um den Zugriff auf das Lesen oder Schreiben anderer Prozesse auf den Z√§hler zu verhindern.  Dies kann jedoch schnell zu einem Leistungsengpass werden und l√§sst sich nicht gut skalieren, insbesondere wenn Remote-Server wie Redis als zus√§tzlicher Datenspeicher verwendet werden. <br></p><br><p>  Ein viel besserer Ansatz ist set-then-get, der sich auf atomare Operatoren st√ºtzt, mit denen Sie den Z√§hler schnell inkrementieren und √ºberpr√ºfen k√∂nnen, ohne die atomaren Operationen zu beeintr√§chtigen. <br></p><br><h3>  Leistungsoptimierung </h3><br><p>  Ein weiterer Nachteil der Verwendung eines zentralen Data Warehouse ist die <i>Verl√§ngerung der</i> Antwortzeit aufgrund der Verz√∂gerung bei der √úberpr√ºfung der Z√§hler, die zur Implementierung der Ratenbegrenzung verwendet werden ( <i>Umlaufzeit</i> oder ‚ÄûUmlaufverz√∂gerung‚Äú).  Leider f√ºhrt selbst die √úberpr√ºfung auf schnellen Speicher wie Redis zu zus√§tzlichen Verz√∂gerungen von einigen Millisekunden pro Anforderung. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vn/y_/oc/vny_ocyqyqddljb5lbqnd5wlrgw.gif" alt="Visualisierungs-Roundtrip-Zeit"></div><br><p>  Um die Definition einer Einschr√§nkung mit einer minimalen Verz√∂gerung vorzunehmen, m√ºssen √úberpr√ºfungen im lokalen Speicher durchgef√ºhrt werden.  Dies kann erreicht werden, indem die Bedingungen f√ºr die √úberpr√ºfung der Geschwindigkeit gelockert und schlie√ülich ein konsistentes Modell verwendet wird. <br></p><br><p>  Beispielsweise kann jeder Knoten einen Datensynchronisationszyklus erstellen, in dem er mit dem Repository synchronisiert wird.  Jeder Knoten √ºbertr√§gt regelm√§√üig den Z√§hlerwert f√ºr jeden Benutzer und das betroffene Fenster an den Speicher, der die Werte atomar aktualisiert.  Dann kann der Knoten neue Werte empfangen und Daten im lokalen Speicher aktualisieren.  Dieser Zyklus erm√∂glicht es schlie√ülich, dass alle Knoten im Cluster auf dem neuesten Stand sind. <br></p><br><p>  Der Zeitraum, in dem die Knoten synchronisiert werden, muss anpassbar sein.  K√ºrzere Synchronisationsintervalle f√ºhren zu einer geringeren Datenabweichung, wenn die Last gleichm√§√üig auf mehrere Knoten des Clusters verteilt ist (z. B. wenn der Balancer die Knoten nach dem Round-Robin-Prinzip ermittelt), w√§hrend l√§ngere Intervalle weniger Lese- / Schreiblast f√ºr den Speicher verursachen und reduzieren Sie die Kosten an jedem Knoten, um synchronisierte Daten zu empfangen. <br></p><br><h2>  Vergleich von Ratenbegrenzungsalgorithmen </h2><br><p>  Insbesondere sollten wir in unserem Fall keine Clientanforderungen f√ºr die API ablehnen, sondern sie auf der Grundlage von Daten nicht erstellen.  Wir haben jedoch kein Recht, Anfragen zu "verlieren".  Zu diesem Zweck verwenden wir beim Senden einer Benachrichtigung den Parameter send_rate, der die maximale Anzahl von Benachrichtigungen angibt, die beim Senden pro Sekunde gesendet werden. <br></p><br><p>  Wir haben also einen bestimmten Worker, der die Arbeit in der zugewiesenen Zeit ausf√ºhrt (in meinem Beispiel das Lesen aus einer Datei), der die RateLimitingInterface-Schnittstelle als Eingabe empf√§ngt und angibt, ob eine Anforderung zu einem bestimmten Zeitpunkt ausgef√ºhrt werden kann und wie lange sie ausgef√ºhrt wird. <br></p><br><pre><code class="php hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RateLimitingInterface</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> int $rate Expected send rate */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__construct</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(int $rate)</span></span></span></span>; <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> float $currentTime Current timestamp in microseconds * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> bool */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">canDoWork</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float $currentTime)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bool</span></span></span></span>; }</code> </pre> <br><p>  Alle Codebeispiele finden Sie hier auf GitHub. <br></p><br><p>  Ich werde sofort erkl√§ren, warum Sie eine Zeitscheibe an Worker √ºbertragen m√ºssen.  Tatsache ist, dass es zu teuer ist, einen separaten Daemon auszuf√ºhren, um das Senden einer Nachricht mit einer Geschwindigkeitsbegrenzung zu verarbeiten. Daher wird send_rate tats√§chlich als Parameter ‚ÄûAnzahl der Benachrichtigungen pro Zeiteinheit‚Äú verwendet, der je nach Auslastung zwischen 0,01 und 1 Sekunde liegt. <br></p><br><p>  Tats√§chlich verarbeiten wir bis zu 100 verschiedene Anforderungen mit send_rate pro Sekunde und weisen 1 / N Sekunden f√ºr jedes Zeitquantum zu, wobei N die Anzahl der von diesem D√§mon verarbeiteten Pushs ist.  Der Parameter, an dem wir w√§hrend der Verarbeitung am meisten interessiert sind, ist, ob send_rate eingehalten wird (kleine Fehler sind in die eine oder andere Richtung zul√§ssig) und die Belastung unserer Hardware (minimale Anzahl von Zugriffen auf Speicher, CPU und Speicherverbrauch). <br></p><br><p>  Lassen Sie uns zun√§chst herausfinden, zu welchen Zeitpunkten Worker wirklich funktioniert.  In diesem Beispiel wurde der Einfachheit halber eine Datei mit 10.000 Zeilen mit send_rate = 1000 verarbeitet (dh wir lesen 1000 Zeilen pro Sekunde aus der Datei). <br></p><br>  In den Screenshots markieren Markierungen die Momente und die Anzahl der Fgets-Aufrufe f√ºr alle Algorithmen.  In der Realit√§t kann dies ein Aufruf an eine Datenbank, eine Ressource eines Drittanbieters oder andere Abfragen sein, deren Anzahl wir pro Zeiteinheit begrenzen m√∂chten. <br><br><p>  Auf der X-Skala - die Zeit vom Beginn der Verarbeitung an, von 0 bis 10 Sekunden, wird jede Sekunde in Zehntel unterteilt, sodass der Zeitplan von 0 bis 100 reicht). <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tb/vk/9u/tbvk9usi0mai17koyki16flm6im.png" alt="Token-Bucket-Betrieb"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/77/t0/av/77t0avq7kqwhkm_4tqlcurek4qc.png" alt="Feste Fensteralgorithmus-Operation"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w9/xo/yi/w9xoyihrbuezu0exbewj8mru9mm.png" alt="Die Funktionsweise des Sliding Log-Algorithmus"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ye/u0/etyeu0hvzzd4hygu8outelbr2ru.png" alt="Bedienung des Schiebefenster-Algorithmus"></div><br><p>  Wir sehen, dass trotz der Tatsache, dass alle Algorithmen die Einhaltung von send_rate bew√§ltigen (daf√ºr sind sie vorgesehen), das <i>feste Fenster</i> und das Schiebeprotokoll die gesamte Last fast gleichzeitig "ausgeben", was f√ºr uns nicht sehr geeignet ist, w√§hrend <i>Token Bucket</i> und <i>Sliding Windows</i> verteilt es gleichm√§√üig pro Zeiteinheit (mit Ausnahme der Spitzenlast zum Zeitpunkt des Starts, da zu fr√ºheren Zeitpunkten keine Daten √ºber die Last vorliegen). <br></p><br><p>  Aufgrund der Tatsache, dass der Code in der Realit√§t normalerweise nicht mit dem lokalen Dateisystem funktioniert, aber bei einem Speicher eines Drittanbieters die Antwort verz√∂gert sein kann, Netzwerkprobleme und viele andere Probleme auftreten k√∂nnen, werden wir versuchen zu √ºberpr√ºfen, wie sich dieser oder jener Algorithmus verh√§lt, wenn Anforderungen einige Zeit dauern war nicht.  Zum Beispiel nach 4 und 6 Sekunden. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fj/lj/gg/fjljggb06hkp7yannsyvtt3b_rw.png" alt="Token Bucket-Betrieb verz√∂gern"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qq/jp/nw/qqjpnw6rtcp7wmgmnsu3omlqkrw.png" alt="Fensterbetrieb mit Verz√∂gerung behoben"></div><br><p>  Hier scheint es, dass das <i>feste Fenster</i> nicht richtig funktioniert und 2-mal mehr als die erwarteten Anforderungen in der ersten und von 7 bis 8 Sekunden verarbeitet hat. Dies ist jedoch nicht der Fall, da die Zeit ab dem Zeitpunkt des Starts im Diagramm gez√§hlt wird und der Algorithmus den aktuellen Unix-Zeitstempel verwendet . <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yh/0k/-k/yh0k-ko8ragfy0mb1n4vcjj8c2o.png" alt="Verz√∂gerter Protokollierungsvorgang"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wh/jx/ww/whjxwwdpzkgxx1hikrb2ogpag-o.png" alt="Schiebefensterbetrieb mit Verz√∂gerung"></div><br><p>  Im Allgemeinen hat sich nichts grundlegend ge√§ndert, aber wir sehen, dass der <i>Token Bucket</i> die Last reibungsloser gl√§ttet und niemals das angegebene Ratenlimit √ºberschreitet, aber das <i>Gleitprotokoll</i> im Falle von Ausfallzeiten den zul√§ssigen Wert √ºberschreiten kann. <br></p><br><h2>  Fazit </h2><br><p>  Wir haben alle grundlegenden Algorithmen zur Implementierung der Ratenbegrenzung untersucht, von denen jeder seine Vor- und Nachteile hat und f√ºr verschiedene Aufgaben geeignet ist.  Wir hoffen, dass Sie nach dem Lesen dieses Artikels den am besten geeigneten Algorithmus zur L√∂sung Ihres Problems ausw√§hlen. <br></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de448438/">https://habr.com/ru/post/de448438/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de448424/index.html">55 Jahre sp√§ter: Kult-IBM System / 360-Mainframe-Kultkonsolen</a></li>
<li><a href="../de448430/index.html">Pro Content 2019: drei harte Berichte und ein Liedchen</a></li>
<li><a href="../de448432/index.html">Klebstrahlung: induzierte Radioaktivit√§t, radioaktive Kontamination, Dekontamination ...</a></li>
<li><a href="../de448434/index.html">Top-Unternehmen f√ºr die Entwicklung mobiler Apps</a></li>
<li><a href="../de448436/index.html">Faltungsschicht: Techniken zur Optimierung der Matrixmultiplikation</a></li>
<li><a href="../de448440/index.html">Hunderttausende von Zahlungen von B√ºrgern an die STSI und die FSSP waren gemeinfrei</a></li>
<li><a href="../de448442/index.html">SSD GIGABYTE Aorus RGB M.2: kleine, gleichm√§√üige Fernbedienung f√ºr RGB-LEDs (1 Teil)</a></li>
<li><a href="../de448444/index.html">Die Angst vor der ersten Besch√§ftigung loswerden</a></li>
<li><a href="../de448448/index.html">SWIFT-Bericht: Das Volumen von Geldern, die von Hackern von Banken gestohlen wurden, hat sich drei Jahre nach dem Hack um 100 Millionen US-Dollar verzehnfacht</a></li>
<li><a href="../de448450/index.html">Webanalyse-Tools f√ºr Anf√§nger, Produktvermarkter und Analytiker</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
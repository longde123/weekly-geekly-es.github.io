<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😁 🚲 👻 L'utilisation des réseaux de neurones siamois dans la recherche 💩 🦓 🚑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour à tous! Dans cet article, je vous dirai quelles approches nous utilisons dans Mail.ru Search pour comparer les textes. À quoi ça sert? Dès que...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>L'utilisation des réseaux de neurones siamois dans la recherche</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/468075/"><img src="https://habrastorage.org/webt/vz/r1/ch/vzr1ch09luydotrwrqc26ccyn-u.jpeg"><br><br>  Bonjour à tous!  Dans cet article, je vous dirai quelles approches nous utilisons dans Mail.ru Search pour comparer les textes.  À quoi ça sert?  Dès que nous apprendrons à bien comparer différents textes, le moteur de recherche pourra mieux comprendre les demandes des utilisateurs. <br><br>  De quoi avons-nous besoin pour cela?  Pour commencer, définissez strictement la tâche.  Vous devez déterminer par vous-même les textes que nous considérons similaires et ceux que nous ne considérons pas, puis formuler une stratégie pour déterminer automatiquement la similitude.  Dans notre cas, les textes des requêtes des utilisateurs seront comparés aux textes des documents. <br><a name="habracut"></a><br>  La tâche de déterminer la pertinence du texte comprend trois étapes.  Tout d'abord, le plus simple: recherchez les mots correspondants dans deux textes et tirez des conclusions sur la similitude en fonction des résultats.  La tâche suivante, plus difficile, consiste à rechercher la connexion entre différents mots, à comprendre les synonymes.  Et enfin, la troisième étape: l'analyse de l'ensemble de la phrase / du texte, l'isolement du sens et la comparaison des phrases / textes par les significations. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/74a/d7d/70e/74ad7d70ea842ca2f2750b954b193c64.png"><br><br>  Une façon de résoudre ce problème consiste à trouver un mappage de l'espace de texte à un autre plus simple.  Par exemple, vous pouvez traduire des textes dans un espace vectoriel et comparer des vecteurs. <br><br>  Revenons au début et considérons l'approche la plus simple: trouver des mots correspondants dans les requêtes et les documents.  Une telle tâche en elle-même est déjà assez compliquée: pour bien le faire, nous devons apprendre à obtenir la forme normale des mots, ce qui en soi n'est pas trivial. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Demande <br></th><th>  Titre du document <br></th></tr><tr><td>  <font color="#018bc7">Héros de</font> <font color="#fa7566">conte de fées</font> <br></td><td>  Alphabet de <font color="#018bc7">héros</font> de <font color="#fa7566">contes</font> de <font color="#fa7566">fées</font> <br></td></tr><tr><td>  Héros de conte de fées <br></td><td>  Littérature pour l'âge préscolaire <br></td></tr></tbody></table></div><br>  Le modèle de cartographie directe peut être considérablement amélioré.  Une solution consiste à faire correspondre les synonymes conditionnels.  Par exemple, vous pouvez saisir des hypothèses probabilistes sur la distribution des mots dans les textes.  Vous pouvez travailler avec des représentations vectorielles et isoler implicitement les connexions entre les mots incompatibles, et le faire automatiquement. <br><br>  Puisque nous sommes engagés dans la recherche, nous avons beaucoup de données sur le comportement des utilisateurs lors de la réception de certains documents en réponse à certaines requêtes.  Sur la base de ces données, nous pouvons tirer des conclusions sur la relation entre différents mots. <br><br>  Prenons deux phrases: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a80/f60/c56/a80f60c569a9a4fb72afc20774a7e787.png"><br><br>  Attribuez à chaque paire de mots de la requête et du titre un certain poids, ce qui signifie combien le premier mot est associé au second.  Nous prédirons le clic comme une transformation sigmoïdale de la somme de ces poids.  Autrement dit, nous définissons la tâche de régression logistique, dans laquelle les attributs sont représentés par un ensemble de paires de la forme (mot de la requête, mot du titre / texte du document).  Si nous pouvons former un tel modèle, alors nous comprendrons quels mots sont des synonymes, plus précisément, peuvent être connectés et lesquels ne le sont probablement pas. <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1"><span class="MJXp-mtext" id="MJXp-Span-2">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-5">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-6">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-7">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8">f</span><span class="MJXp-mrow" id="MJXp-Span-9"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-10">C</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14">k</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-20">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-21">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-23">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">t</span><span class="MJXp-mrow" id="MJXp-Span-25"><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;">é</span></span></span><span class="MJXp-mo" id="MJXp-Span-27" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-28">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-29">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-30">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-32">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-33">a</span><span class="MJXp-mtext" id="MJXp-Span-34">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38">t</span><span class="MJXp-mo" id="MJXp-Span-39" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-40">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-42">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-43">m</span><span class="MJXp-mtext" id="MJXp-Span-44">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-46">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-47">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-49">h</span><span class="MJXp-msubsup" id="MJXp-Span-50"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-51" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-52" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-53">i</span></span></span><span class="MJXp-mtext" id="MJXp-Span-54">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-57">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-58">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-59">t</span><span class="MJXp-mo" id="MJXp-Span-60" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mtext" id="MJXp-Span-61">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-63">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-64">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-66">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-67">f</span><span class="MJXp-mrow" id="MJXp-Span-68"><span class="MJXp-mo" id="MJXp-Span-69" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70">o</span><span class="MJXp-mrow" id="MJXp-Span-71"><span class="MJXp-mo" id="MJXp-Span-72" style="margin-left: 0em; margin-right: 0em;">ù</span></span></span><span class="MJXp-mtext" id="MJXp-Span-73">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-74">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-75">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-76">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-78">h</span><span class="MJXp-msubsup" id="MJXp-Span-79"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-81" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-82">i</span></span></span><span class="MJXp-mtext" id="MJXp-Span-83">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-84">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-85">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-86">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-89">f</span><span class="MJXp-mrow" id="MJXp-Span-90"><span class="MJXp-mo" id="MJXp-Span-91" style="margin-left: 0em; margin-right: 0.111em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-92">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-93">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-94">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-95">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-96">s</span><span class="MJXp-msup" id="MJXp-Span-97"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-98" style="margin-right: 0.05em;">d</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-99" style="vertical-align: 0.5em;">′</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-100">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-101">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-102">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-103">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-104">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-105">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-106">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-107">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-108">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-109">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-110">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-111">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-112">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113">s</span><span class="MJXp-mo" id="MJXp-Span-114" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-115">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-116">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-118">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-119">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-120">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-122">q</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-123">u</span><span class="MJXp-mrow" id="MJXp-Span-124"><span class="MJXp-mo" id="MJXp-Span-125" style="margin-left: 0em; margin-right: 0em;">ê</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-126">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127">e</span><span class="MJXp-mo" id="MJXp-Span-128" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-129">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-130">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-131">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-132">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-133">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-136">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-137">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-138">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-139">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-140">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-141">t</span><span class="MJXp-mo" id="MJXp-Span-142" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> \ textbf {Click probabilité} = \ sigma \ left (\ sum \ varphi _ {i} \ right) \ textbf {, où} \ varphi _ {i} \ textbf {- poids d'un couple de mots (mot de requête, mot de document) } </script></p><br>  Vous devez maintenant créer un bon ensemble de données.  Il s'avère qu'il suffit de prendre l'historique des clics des utilisateurs, d'ajouter des exemples négatifs.  Comment mélanger dans des exemples négatifs?  Il est préférable de les ajouter à l'ensemble de données dans un rapport 1: 1.  De plus, les exemples eux-mêmes au premier stade de la formation peuvent être effectués de manière aléatoire: pour une paire requête-document, nous trouvons un autre document aléatoire, et nous considérons une telle paire comme négative.  Aux stades ultérieurs de la formation, il est avantageux de donner des exemples plus complexes: ceux qui ont des intersections, ainsi que des exemples aléatoires que le modèle considère comme similaires (minage dur négatif). <br><br>  Exemple: Synonymes du mot "triangle". <br><br><div class="scrollable-table"><table><tbody><tr><th>  Mot d'origine <br></th><th>  Synonyme <br></th><th>  Le poids <br></th></tr><tr><td>  TRIANGLE <br></td><td>  GÉOMÉTRIE <br></td><td>  0,55878 <br></td></tr><tr><td>  TRIANGLE <br></td><td>  RÉSOUDRE <br></td><td>  0,66079 <br></td></tr><tr><td>  TRIANGLE <br></td><td>  Equilatéral <br></td><td>  0,37966 <br></td></tr><tr><td>  TRIANGLE <br></td><td>  OGE <br></td><td>  0,51284 <br></td></tr><tr><td>  TRIANGLE <br></td><td>  BERMUDES <br></td><td>  0,52195 <br></td></tr></tbody></table></div><br>  À ce stade, nous pouvons déjà distinguer une bonne fonction qui correspond aux mots, mais ce n'est pas ce que nous recherchons. Cette fonction nous permet de faire une correspondance indirecte des mots, et nous voulons comparer des phrases entières. <br><br>  Ici, les réseaux de neurones nous aideront.  Faisons un encodeur qui accepte du texte (une requête ou un document) et produit une représentation vectorielle telle que des textes similaires ont des vecteurs proches et distants.  Par exemple, vous pouvez utiliser la distance cosinus comme mesure de similitude. <br><br>  Ici, nous utiliserons l'appareil des réseaux siamois, car ils sont beaucoup plus faciles à former.  Le réseau siamois se compose d'un codeur, qui est appliqué pour échantillonner les données de deux familles ou plus et d'une opération de comparaison (par exemple, la distance cosinus).  Lors de l'application de l'encodeur à des éléments de différentes familles, les mêmes poids sont utilisés;  cela en soi donne une bonne régularisation et réduit considérablement le nombre de facteurs nécessaires à la formation. <br><br>  L'encodeur produit des représentations vectorielles à partir de textes et apprend de sorte que le cosinus entre les représentations de textes similaires est maximum et entre les représentations de textes différents est minimal. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/164/235/672/164235672d1048f21bf0ca522703999a.png" width="400"></div><br>  Un réseau de complexité sémantique profonde DSSM convient à notre tâche.  Nous l'utilisons avec des modifications mineures, dont je parlerai ci-dessous. <br><br>  Fonctionnement du DSSM classique: les requêtes et les documents sont présentés sous la forme d'un sac de trigrammes, à partir duquel une représentation vectorielle standard est obtenue.  Il passe à travers plusieurs couches entièrement connectées et le réseau est formé de manière à maximiser la probabilité conditionnelle du document sur demande, ce qui équivaut à maximiser la distance cosinusoïdale entre les représentations vectorielles obtenues par un passage complet à travers le réseau. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2a/f6b/71f/b2af6b71f72649de1282e54456bfd695.png"><br>  <i>Po-Sen Huang Xiaodong He <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Jianfeng Gao</a> Li Deng Alex Acero Larry Heck.</i>  <i>2013 Apprentissage de modèles sémantiques structurés en profondeur pour la recherche sur le Web à l'aide de données de clics</i> <br><br>  Nous avons fait presque le même chemin.  A savoir, chaque mot de la requête est représenté comme un vecteur de trigrammes et le texte comme un vecteur de mots, laissant ainsi des informations sur le mot où il se trouvait.  Ensuite, nous utilisons des convolutions unidimensionnelles à l'intérieur des mots, lissant la représentation de ceux-ci, et l'opération de traction maximale globale pour agréger des informations sur la phrase dans une représentation vectorielle simple. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed0/e1f/fd9/ed0e1ffd98e077ba51c91004485f4d2f.jpg"><br><br>  L'ensemble de données que nous avons utilisé pour la formation coïncide presque complètement avec celui utilisé pour le modèle linéaire. <br><br>  Nous ne nous sommes pas arrêtés là.  Tout d'abord, ils ont proposé un mode de pré-formation.  Nous prenons une liste de requêtes pour le document, saisissons quels utilisateurs interagissent avec ce document et formons le réseau de neurones pour intégrer de telles paires.  Comme ces paires appartiennent à la même famille, un tel réseau est plus facile à apprendre.  De plus, il est plus facile de le recycler sur des exemples de combat lorsque nous comparons des demandes et des documents. <br><br>  <i>Exemple: les utilisateurs se rendent sur e.mail.ru/login avec des demandes: e-mail, saisie e-mail, adresse e-mail, ...</i> <br><br><div class="scrollable-table"><table><tbody><tr><th>  Demande <br></th><th>  Le document <br></th><th>  BM25 <br></th><th>  Neurorank <br></th></tr><tr><td>  Astana Toyota <br></td><td>  Site officiel de Toyota au Kazakhstan <br></td><td>  0 <br></td><td>  0,839 <br></td></tr><tr><td>  poésie <br></td><td>  Poetry.ru <br></td><td>  0 <br></td><td>  0,823 <br></td></tr><tr><td>  World Dream Pattaya <br></td><td>  Bangkok Dream World <br></td><td>  0 <br></td><td>  0,818 <br></td></tr><tr><td>  pomme de terre spb <br></td><td>  Acheter des pommes de terre à Saint-Pétersbourg <br></td><td>  0 <br></td><td>  0,811 <br></td></tr></tbody></table></div><br>  Enfin, la dernière partie difficile, avec laquelle nous avons encore du mal et dans laquelle nous avons presque réussi, est de comparer la demande avec un long document.  Pourquoi cette tâche est-elle plus difficile?  Ici, la machinerie des réseaux siamois est déjà plus mal adaptée, car la demande et le long document appartiennent à différentes familles d'objets.  Néanmoins, nous pouvons nous permettre de changer à peine l'architecture.  Il suffit d'ajouter des convolutions également par des mots, ce qui permettra d'économiser plus d'informations sur le contexte de chaque mot pour la représentation vectorielle finale du texte. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/845/b2d/bba/845b2dbbac3e32158f085c06af1dc686.png"><br><br>  À l'heure actuelle, nous continuons d'améliorer la qualité de nos modèles en modifiant les architectures et en expérimentant les sources de données et les mécanismes d'échantillonnage. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr468075/">https://habr.com/ru/post/fr468075/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr468061/index.html">Cron sur Linux: historique, utilisation et appareil</a></li>
<li><a href="../fr468063/index.html">Angulareact</a></li>
<li><a href="../fr468067/index.html">Fonctionnement de la composition alpha</a></li>
<li><a href="../fr468071/index.html">Eduard Medvedev, CTO chez Tungsten Labs: «Nous avons grandi au point où la technologie peut causer des dommages considérables»</a></li>
<li><a href="../fr468073/index.html">Andrei Terekhov: "Vous pouvez dire autant que vous le souhaitez que l'Américain est meilleur, mais notre voiture ne tombe jamais en panne"</a></li>
<li><a href="../fr468077/index.html">Posit les tests de façon adulte. Analyse spectrale</a></li>
<li><a href="../fr468079/index.html">Dimensions personnalisées dans Google Analytics qui nous ont fait économiser plus d'une fois</a></li>
<li><a href="../fr468081/index.html">«Données anonymes» ou ce qui est prévu dans 152-FZ</a></li>
<li><a href="../fr468083/index.html">API Android Camera2 depuis la bouilloire</a></li>
<li><a href="../fr468085/index.html">Le livre "Safe DevOps. Fonctionnement efficace du système</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
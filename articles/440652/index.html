<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßóüèº üéæ üöµ Video computarizado en 755 megap√≠xeles: ple√≥pticos ayer, hoy y ma√±ana ü§∞üèæ üë∏üèΩ ‚ùî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hace alg√∫n tiempo, el autor tuvo la oportunidad de dar una conferencia en VGIK, y hab√≠a mucha gente de la c√°mara en la audiencia. Se le pregunt√≥ a la ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Video computarizado en 755 megap√≠xeles: ple√≥pticos ayer, hoy y ma√±ana</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440652/"><img src="https://habrastorage.org/getpro/habr/post_images/edf/637/bcd/edf637bcd51db4e6b8b3e8c13c3491f0.png"><br><br>  Hace alg√∫n tiempo, el autor tuvo la oportunidad de dar una conferencia en VGIK, y hab√≠a mucha gente de la c√°mara en la audiencia.  Se le pregunt√≥ a la audiencia: "¬øCon qu√© resoluci√≥n m√°xima dispar√≥?", Y result√≥ que alrededor de un tercer disparo 4K u 8 megap√≠xeles, el resto, no m√°s de 2K o 2 megap√≠xeles.  Fue un reto!  Ten√≠a que contar sobre la c√°mara con una resoluci√≥n de 755 megap√≠xeles (resoluci√≥n bruta, para ser precisos, ya que tiene un 4K final) y qu√© posibilidades encantadoras ofrece esto para el disparo profesional. <br><br>  La c√°mara en s√≠ se ve as√≠ (una especie de peque√±o elefante): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/824/93c/286/82493c2865db1d6519d69121b0ba8d9c.png"><br><br>  Adem√°s, abrir√© un terrible secreto, para tomar esta foto busc√°bamos un mejor √°ngulo y una persona m√°s grande.  Por casualidad sent√≠ esta c√°mara en vivo, dir√© que se ve <b>mucho</b> m√°s grande.  La imagen a continuaci√≥n con Yon Karafin, con quienes tenemos aproximadamente la misma altura, refleja con mayor precisi√≥n la escala del desastre: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb5/954/8b6/eb59548b69bc178ace2a379120ca6b33.png"><br><br>  A qui√©n le importa en principio las capacidades del video calculado sobre el que rara vez escriben: ¬°toda la verdad est√° por debajo!  ) <br><a name="habracut"></a><br>  Las discusiones sobre las posibilidades de los ple√≥pticos me recuerdan las discusiones sobre el primer avi√≥n: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d04/b2f/00f/d04b2f00fc8d68a6b3d830665fdfb433.png"><br><br><hr><br>  Lo que dijo la gente: <br>  - <i>Es muy caro ...</i> <br>  - <i>SI!</i> <br>  - <i>Es completamente poco pr√°ctico y ahora no da resultado ...</i> <br>  - <i>SI!</i> <br>  - <i>Es peligroso usar ...</i> <br>  - <i>Maldita sea, ¬°S√ç!</i> <br>  - ¬° <i>Se ve miserable!</i> <br>  - <i>Maldita sea, s√≠, pero <b>vuela, ya ves, LE-TA-ET!</b></i> <br><hr><br>  Despu√©s de 50 a√±os, estos experimentos dieron lugar a una forma fundamentalmente nueva, conveniente y bastante segura de moverse a trav√©s de los oc√©anos (y no solo). <br><br>  La situaci√≥n es la misma aqu√≠.  Absolutamente lo mismo!  Ahora requiere costos irrazonables, es muy inconveniente de usar y parece miserable, ¬°pero realmente VUELA!  Y para estar al tanto de los principios y las perspectivas emergentes, ¬°es simplemente m√°s que inspirador (al menos su humilde servidor)! <br><br>  El monstruo de la foto de arriba recuerda a las primeras c√°maras, que tambi√©n eran grandes, con una lente enorme y giraban en un marco especial: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/feb/153/d5e/feb153d5ebe10e4c0a529270d7244fcc.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">rodaje televisivo de los Juegos Ol√≠mpicos en 1936</a> en los albores de la televisi√≥n.</i> <br><br>  Aqu√≠ se ve mucho, tambi√©n una lente enorme (porque tampoco hay suficiente luz), una c√°mara pesada con una suspensi√≥n especial, tama√±os enormes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b38/770/bbe/b38770bbefae6795d4fb673436906e6f.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lytro a punto de cambiar para siempre el cine</a></i> <br><br>  De lo interesante: la "maleta" a continuaci√≥n es un sistema de refrigeraci√≥n l√≠quida, en caso de falla de la cual la c√°mara no puede tomar m√°s fotos. <br><br>  El gran rect√°ngulo debajo de la lente (claramente visible en la primera foto de arriba) no es la luz de fondo, sino el lidar, un buscador l√°ser que proporciona una escena tridimensional frente a la c√°mara. <br><br>  Un torniquete negro grueso en la parte inferior izquierda en el fondo es un paquete de cables de fibra √≥ptica de aproximadamente 4 cent√≠metros de di√°metro, a trav√©s del cual la c√°mara env√≠a un flujo monstruoso de informaci√≥n a un almacenamiento especial. <br><br>  Aquellos en el tema ya han reconocido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lytro Cinema</a> , de los cuales se crearon 3 piezas.  El primero, que generalmente aparece en todas las im√°genes, es f√°cil de reconocer con un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lidar</a> debajo de la lente.  Despu√©s de 1,5 a√±os, se cre√≥ una segunda c√°mara con problemas estructurales corregidos del primero y los dos lidares (y, por desgracia, casi nadie escribe al respecto).  Adem√°s, el progreso en el desarrollo, por ejemplo, de los lidares en 1.5 a√±os fue tan grande que dos lidares de la segunda c√°mara dieron 10 veces m√°s puntos que un lidar de la primera.  Se supon√≠a que la tercera c√°mara ten√≠a aproximadamente las mismas caracter√≠sticas de resoluci√≥n (para satisfacer los requisitos de los cineastas), pero ten√≠a la mitad del tama√±o (lo cual es cr√≠tico para el uso pr√°ctico).  Pero ... pero m√°s sobre eso m√°s tarde. <br><br>  En cualquier caso, reconociendo en todos los sentidos el papel sobresaliente que jug√≥ Lytro en la popularizaci√≥n de la tecnolog√≠a de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">disparo ple√≥ptico</a> , me gustar√≠a se√±alar que la luz no convergi√≥ en √©l.  En el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Instituto Fraunhofer</a> se fabric√≥ una c√°mara similar, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Raytrix</a> , un productor de c√°maras ple√≥pticas, existe de manera segura, y nuevamente no se me permiti√≥ fotografiar Lytro Cinema, porque ten√≠a mucho miedo de varias compa√±√≠as chinas que trabajaban activamente en esta direcci√≥n (no pude encontrar informaci√≥n fresca sobre ellas). <br><br>  Por lo tanto, anotemos los puntos de todas las ventajas que los ple√≥pticos brindan, y sobre los cuales casi no escriben.  Pero precisamente por eso est√° garantizado para tener √©xito. <br><br><h1>  En lugar de presentar </h1><br>  Solo en Habr√© y solo Lytro se menciona <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en aproximadamente 300 p√°ginas</a> , por lo tanto, seremos cortos. <br><br>  El concepto clave para el disparo pleno√≥ptico es el campo de luz, es decir, no fijamos el color del p√≠xel en cada punto, sino una matriz bidimensional de p√≠xeles, que convierte un cuadro bidimensional miserable en un cuadro normal de cuatro dimensiones (generalmente con muy poca resoluci√≥n en t y s hasta ahora): <br><br><img src="https://habrastorage.org/webt/kr/tg/ex/krtgexrapzcv70xbte74_cepamo.png"><br><br>  En la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wikipedia en ingl√©s</a> , y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">luego en el ruso</a> en art√≠culos sobre el campo de luz, se dice que "la frase" campo de luz "fue utilizada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">por A. Gershun</a> en ... 1936".  Para ser justos, notamos que esto no fue por <s>casualidad una</s> "frase usada", sino el nombre de un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">peque√±o libro de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">178 p√°ginas</a> , que se llam√≥ "Campo de luz": <br><br><img width="300" src="https://habrastorage.org/webt/ba/lw/q_/balwq_fptbhjelv24etahctr5-8.png"><br><br>  E incluso en ese momento, estas obras se aplicaron bastante en la naturaleza y el autor 6 a√±os despu√©s, en el apogeo de la guerra en 1942, recibi√≥ el Premio Stalin de segundo grado por el m√©todo de apag√≥n. <br><br>  En la pr√°ctica, disparar un cuadro de cuatro dimensiones del campo de luz proporciona una gran variedad de microlentes ubicadas frente al sensor de la c√°mara: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/90f/203/fb4/90f203fb49d7e464638a4f164e96fb26.gif"></a> <br>  <i>Fuente: <a href="">plenoptic.inf¬Æ (puede hacer clic y ver en resoluci√≥n completa)</a></i> <br><br>  En realidad, es precisamente porque tenemos un conjunto de microlentes con una peque√±a distancia entre ellos lo que permiti√≥ crear Lytro Cinema, cuyo sensor se ensambl√≥ a partir de un conjunto de sensores cuyos l√≠mites caen en el borde de las lentes.  Se requiri√≥ enfriamiento l√≠quido para enfriar un macizo muy caliente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f2c/bc4/c3a/f2cbc4c3ad04cfa63d0fd1976fda10a8.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Uso de c√°maras plenopticas enfocadas para capturar im√°genes ricas</a></i> <br><br>  Como resultado, tenemos la posibilidad m√°s famosa de c√°maras ple√≥pticas, de las cuales solo los perezosos no escribieron, para cambiar la distancia de enfoque despu√©s de la toma (estas lindas aves no esperar√≠an para enfocar): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb2/49a/815/eb249a815ede8955910d24aadc495a66.gif"><br>  <i>Fuente: Lytro</i> <br><br>  Y poco se ha escrito sobre c√≥mo se ven los ple√≥pticos en una resoluci√≥n adecuada para una pel√≠cula (se abre por clic): <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/0bf/247/057/0bf2470573938428dae4ae4f2c8ca217.png"></a> <br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mira Lytro Change Cinematography Forever</a></i> <br><br>  Abro otro secreto: el foco calculado es la punta del iceberg de los ple√≥pticos.  Y el 90% de las oportunidades que quedan por debajo del nivel de inter√©s de los periodistas en mi opini√≥n son a√∫n m√°s interesantes.  Muchos de ellos son dignos de art√≠culos separados, pero al menos corrijamos la injusticia y al menos los llamemos.  Vamos! <br><br><h1>  Forma de apertura calculada </h1><br>  Como estamos hablando de desenfoque, vale la pena mencionar el llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">efecto bokeh</a> , en el que el resplandor no es necesariamente redondo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4b6/f15/b53/4b6f15b5341de52d29714f789d5f5a52.png"><br><br>  Para los fot√≥grafos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se lanza el</a> llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kit Bokeh</a> , que le permite obtener reflejos de varias formas: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8a8/f3d/c8c/8a8f3dc8cc02ff1ccd7e00272aec9a9f.png"><br><br>  Esto le permite obtener im√°genes bonitas, y la foto a continuaci√≥n muestra claramente que los destellos en forma de corazones incluso tienen piedras en primer plano, solo los corazones son m√°s peque√±os.  Y est√° claro que tratar de desenfocar naturalmente de manera similar en Photoshop es extremadamente dif√≠cil, al menos es recomendable usar un mapa de profundidad: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c14/ca9/61f/c14ca961fa1bce2cb067c228dba7f342.png"><br><br>  Al mismo tiempo, para los ple√≥pticos "calcular" una apertura diferente es una tarea relativamente f√°cil: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1df/6b2/b1c/1df6b2b1cf75edf87faaa0e1c9e689e1.png"><br><br>  Entonces!  Calculamos la distancia de enfoque, calculamos la forma de la apertura, fuimos m√°s all√°, ¬°es m√°s interesante all√≠! <br><br><h1>  Est√©reo Computado </h1><br>  Una caracter√≠stica muy √∫til del sensor ple√≥ptico, sobre la que casi nadie menciona, pero que ya le da una segunda vida, es la capacidad de calcular una imagen desde diferentes puntos.  La ubicaci√≥n del punto est√° realmente determinada por el tama√±o de la lente.  Si la lente es peque√±a, el marco puede moverse ligeramente hacia la izquierda y hacia la derecha, como en este ejemplo (que esta foto est√©reo es visible si mira el cofre del p√°jaro m√°s cercano): <br><br><img width="750" src="https://habrastorage.org/getpro/habr/post_images/2bc/0ef/292/2bc0ef292a64c5ba65b626d374f8f0a8.gif"><br>  <i>Fuente: Lytro</i> <br><br>  Si la lente es grande, como, por ejemplo, Lytro Cinema, el punto de disparo se puede desplazar 10 cent√≠metros.  Perm√≠teme recordarte que entre nuestros ojos tenemos unos 6.5 cent√≠metros, es decir, con una distancia m√°xima de 10 cm, puedes disparar tanto el plano general (y ser√° "tridimensional" como si lo miras con los ojos) y de cerca (con cualquier paralaje sin molestias).  De hecho, esto significa que podemos grabar video est√©reo completo con una lente.  Adem√°s, no solo ser√° est√©reo, sino est√©reo con una calidad perfecta y eso suena fant√°stico hoy en d√≠a, con una distancia variable entre los ejes √≥pticos de las c√°maras virtuales DESPU√âS del disparo.  Tanto eso como otro: oportunidades absolutamente impensables que pueden cambiar radicalmente una situaci√≥n con la grabaci√≥n est√©reo en el futuro. <br><br>  Dado que el futuro est√° de alguna manera en los disparos tridimensionales, deteng√°monos en estos dos puntos con m√°s detalle.  No es ning√∫n secreto que hoy en d√≠a la mayor√≠a de las pel√≠culas en 3D, especialmente los √©xitos de taquilla, no se eliminan, sino que se convierten a 3D.  Esto se hace porque al disparar, surge una larga lista de problemas (a continuaci√≥n se incluye parte de la lista): <br><br><ul><li>  Los fotogramas se pueden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">rotar, desplazar verticalmente o agrandar uno en relaci√≥n con el otro</a> (no digas que esto se arregla f√°cilmente, mira con qu√© frecuencia esos fotogramas entran en los estrenos de pel√≠culas; esto es un horror silencioso ... y un dolor de cabeza).  Entonces, el est√©reo pleno√≥ptico est√° PERFECTAMENTE alineado, incluso si el operador decidi√≥ hacer un acercamiento (debido a la mec√°nica de las dos c√°maras, es extremadamente dif√≠cil hacer que la aproximaci√≥n sea estrictamente sincr√≥nica). <br></li><li>  Los marcos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pueden variar en color</a> , especialmente si el disparo requiere una peque√±a distancia entre los ejes √≥pticos de las c√°maras y tiene que usar un divisor de haz (hab√≠a una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaci√≥n detallada</a> sobre esto).  Resulta que, en una situaci√≥n en la que al disparar cualquier objeto de bengala (el autom√≥vil en el fondo en un d√≠a soleado), estamos condenados al entretenimiento en la postproducci√≥n con la gran mayor√≠a de las c√°maras, con el ple√≥ptico tendremos una imagen PERFECTA con cualquier resplandor.  Esta es una fiesta! <br></li><li>  Los marcos pueden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">variar en nitidez</a> ; de nuevo, un problema notable en los divisores de haz, que est√° completamente ausente en los ple√≥pticos.  Con qu√© nitidez se necesita, con esto calcularemos, absolutamente PERFECTO desde los √°ngulos. <br></li><li>  Los marcos pueden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">flotar en el tiempo</a> .  Los colegas que trabajaron con el material de Stalingrado hablaron sobre la discrepancia entre las marcas de tiempo de las pistas en 4 cuadros, raz√≥n por la cual el cracker sigue siendo relevante.  Encontramos m√°s de 500 escenas con diferencias de tiempo en 105 pel√≠culas.  La diferencia horaria, desafortunadamente, es dif√≠cil de detectar, especialmente en escenas con c√°mara lenta, y al mismo tiempo es el artefacto m√°s doloroso seg√∫n nuestras mediciones.  En el caso de los ple√≥pticos, tendremos una sincronizaci√≥n de tiempo PERFECTA. <br></li><li>  Otro dolor de cabeza al disparar en 3D son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">los paralaje demasiado grandes que causan molestias al ver</a> en una pantalla grande, cuando los ojos pueden divergir hacia los lados para buscar objetos "m√°s all√° del infinito" o converger demasiado para algunos objetos en primer plano.  El c√°lculo correcto de paralaje es un tema dif√≠cil por separado que los operadores deben tener un buen dominio, y un objeto que accidentalmente entra en el marco puede arruinar la toma, haci√©ndolo inc√≥modo.  Con los ple√≥pticos, nosotros mismos elegimos el paralaje DESPU√âS del disparo, por lo que cualquier escena se puede calcular con paralaje PERFECTO, adem√°s, la misma escena ya filmada se puede calcular f√°cilmente para pantallas grandes y pantallas peque√±as.  Este es el llamado cambio de paralaje, que generalmente es extremadamente dif√≠cil y costoso sin p√©rdida de calidad, especialmente si ten√≠a objetos transl√∫cidos o bordes en primer plano. <br></li></ul><br>  En general, la capacidad de CALCULAR el est√©reo perfecto es la base real de la pr√≥xima ola de popularidad en 3D, ya que en los √∫ltimos 100 a√±os se han distinguido 5 ondas de este tipo.  Y, a juzgar por el progreso en la proyecci√≥n l√°ser y el ple√≥ptico, un m√°ximo de 10 a√±os (cuando caducan las patentes principales de Lytro o un poco antes en China) nos esperan un nuevo hierro y un nuevo nivel de pel√≠culas 3D de calidad. <br><br>  Entonces!  Obtuvieron el est√©reo calculado perfecto de una lente (algo imposible para la mayor√≠a, por cierto).  Y no solo lo entendieron, sino que tambi√©n contaron la paralaje despu√©s del hecho, incluso si el objeto est√° desenfocado en primer plano.  ¬°Vamos m√°s profundo! <br><br><h1>  Punto de disparo calculado </h1><br>  Cambiar el punto de disparo tiene una aplicaci√≥n en video 2D ordinario. <br><br>  Si estaba en el set o al menos vio fotograf√≠as, probablemente prest√≥ atenci√≥n a los rieles en los que viaja la c√°mara.  A menudo, para una escena, debe colocarlos en varias direcciones, lo que lleva un tiempo notable.  Los rieles aseguran el buen funcionamiento de la c√°mara.  S√≠, por supuesto, hay una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">c√°mara estable</a> , pero en muchos casos los rieles, por desgracia, no tienen alternativa. <br><br>  La capacidad de cambiar el punto de disparo en Lytro se utiliz√≥ para demostrar que hay suficientes ruedas.  De hecho, cuando la c√°mara se mueve, formamos un "tubo" virtual con un di√°metro de 10 cm en el espacio, dentro del cual podemos cambiar el punto de disparo.  Y esta tuber√≠a le permite compensar peque√±as fluctuaciones.  Esto se muestra bien en este video: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/4qXE4sA-hLQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Adem√°s, a veces necesita resolver el problema inverso, es decir, agregar oscilaciones durante el movimiento.  Por ejemplo, no hubo suficiente din√°mica y el director decidi√≥ hacer una explosi√≥n.  No es largo aplicar un sonido, pero es aconsejable sacudir la c√°mara sincr√≥nicamente, y es mejor no solo mover la imagen plana, ser√° visible, sino sacudirla "honestamente".  Con los ple√≥pticos, el punto de disparo se puede sacudir completamente "honestamente", con un cambio en el punto de disparo, √°ngulo, desenfoque de movimiento, etc.  Habr√° una completa ilusi√≥n de que la c√°mara se sacudi√≥ violentamente, que suavemente y con seguridad mont√≥ sobre ruedas.  De acuerdo, ¬°una oportunidad incre√≠ble!  La pr√≥xima generaci√≥n de steadicam mostrar√° milagros. <br><br>  Por supuesto, para que esto se convierta en realidad, debe esperar hasta que el tama√±o de la c√°mara ple√≥ptica se reduzca a uno razonable.  Pero considerando cu√°nto dinero se est√° invirtiendo en miniaturizaci√≥n y aumentando la resoluci√≥n de los sensores para tel√©fonos inteligentes y tabletas, parece que la espera no es tan larga.  ¬°Y ser√° posible crear una nueva c√°mara ple√≥ptica!  Cada a√±o se hace m√°s y m√°s f√°cil. <br><br>  Entonces!  Se calcul√≥ el punto de disparo y, si es necesario, se movi√≥, estabilizando o desestabilizando la c√°mara.  ¬°Vamos m√°s all√°! <br><br><h1>  Iluminaci√≥n computarizada </h1><br>  Como estamos hablando de una explosi√≥n cerca ... <br><br>  A veces se hace necesario cambiar la iluminaci√≥n del sujeto, por ejemplo, agregar un flash de manera realista.  Los estudios de posproducci√≥n saben bien qu√© problema tan dif√≠cil es este, incluso si la ropa de nuestro personaje es relativamente simple. <br><br>  Aqu√≠ hay un ejemplo de un video con una superposici√≥n de flash, teniendo en cuenta la ropa, sus sombras, etc. (se abre por clic): <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/9f9/5d9/71b/9f95d971be215c71291ab04052bf4c24.png"></a> <br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Entrevista con Yon Karafin</a></i> <br><br>  Debajo del cap√≥, parece un complemento para Nuke, que funciona con un modelo tridimensional completo del actor y le da una nueva luz, teniendo en cuenta el mapa normal, los materiales, el desenfoque de movimiento, etc. <br><br><img width="650" src="https://habrastorage.org/getpro/habr/post_images/657/214/4b7/6572144b7afc8bc6638984b17ce45d88.png"><br><br><img width="650" src="https://habrastorage.org/getpro/habr/post_images/631/766/a83/631766a838c01a2759931f89b44dd2c7.png"><br>  <i>Fuente: Lytro Materials</i> <br><br>  Entonces!  Se calcul√≥ la nueva iluminaci√≥n del objeto ya capturado.  ¬°Vamos m√°s all√°! <br><br><h1>  Resoluci√≥n calculada </h1><br>  Aquellos que experimentaron con el primer Lytro a menudo notaron: s√≠, el juguete es genial, pero la resoluci√≥n es completamente insuficiente para la fotograf√≠a normal. <br><br>  En <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nuestro √∫ltimo art√≠culo</a> sobre Habr, se describi√≥ c√≥mo peque√±os cambios en el punto de disparo pueden ayudar a aumentar significativamente la resoluci√≥n.  Pregunta: ¬øSon estos algoritmos aplicables a los ple√≥pticos?  Respuesta: s√≠!  Adem√°s, los algoritmos de Super Resoluci√≥n son m√°s f√°ciles de trabajar en im√°genes ple√≥pticas, ya que hay un mapa de profundidad, todos los p√≠xeles se toman al mismo tiempo y los cambios se conocen con bastante precisi√≥n.  Es decir, la situaci√≥n de los ple√≥pticos es simplemente m√°gica en comparaci√≥n con las condiciones bajo las cuales los algoritmos de Super Resoluci√≥n funcionan en 2D ordinario.  El resultado es correspondiente: <br><br><img width="650" src="https://habrastorage.org/getpro/habr/post_images/bc9/6cd/e55/bc96cde55e276f4420757de5359467b1.gif"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Restauraci√≥n de cuadros ple√≥pticos ingenuos, inteligentes y de s√∫per resoluci√≥n</a> del Informe t√©cnico de Adobe "Superresoluci√≥n con c√°mara plenoptic 2.0"</i> <br><br>  El √∫nico problema importante (¬°realmente grande!) Es la cantidad de datos y la cantidad de c√°lculo que se requiere.  Sin embargo, hoy en d√≠a es completamente realista cargar una granja de c√≥mputo por la noche y obtener el doble de resoluci√≥n ma√±ana donde sea necesario. <br><br>  Entonces, descubr√≠ la resoluci√≥n calculada.  ¬°Vamos m√°s all√°! <br><br><h1>  Ambiente Computado </h1><br>  Una tarea separada que surge en la etapa de postproducci√≥n, especialmente si se trata de alg√∫n tipo de proyecto fant√°stico o de fantas√≠a, es pegar cuidadosamente los objetos capturados en una escena tridimensional.  A nivel mundial no hay un gran problema.  Hoy en d√≠a, la norma es el escaneo tridimensional del √°rea de tiro y todo lo que queda es combinar cuidadosamente el modelo de disparo y la escena tridimensional para que no haya cl√°sicos del g√©nero cuando las piernas de los actores a veces caen un poco en el piso desigual pintado (esta jamba no es muy visible en la pantalla peque√±a, pero se puede ver claramente en el cine, especialmente en alg√∫n lugar de IMAX). <br><br>  No sin humor, para un ejemplo del funcionamiento de la c√°mara, se utiliz√≥ la escena del disparo del alunizaje (las "sombras tridimensionales" son claramente visibles en lugares que la c√°mara no ve): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/094/809/2b9/0948092b96926ae88866cd222e67f0fe.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Luna |</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lytro |</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VR Playhouse |</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Postproducci√≥n Lightfield</a></i> <br><br>  Dado que, por definici√≥n, un video de m√∫ltiples √°ngulos se graba en una c√°mara ple√≥ptica, construir un mapa de profundidad no es un gran problema.  Y si la c√°mara se combina con el LIDAR, filmamos inmediatamente una escena tridimensional, lo que simplifica categ√≥ricamente la combinaci√≥n de disparos reales y gr√°ficos en la siguiente etapa. <br><br>  Entonces, contamos la escena tridimensional alrededor (combinando datos LIDAR y datos de ple√≥pticos).  Ahora, lo has adivinado, ¬°la representaci√≥n del reconocimiento lunar ser√° a√∫n mejor!  Adelante <br><br><h1>  Clave de croma calculada </h1><br>  ¬°Pero eso no es todo! <br><br>  La tecnolog√≠a habitual de un set de filmaci√≥n moderno son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">las pantallas verdes</a> , cuando en lugares donde se supone que el fondo de una computadora se coloca sobre escudos de madera contrachapada verde o se tiran pancartas verdes.  Esto se hace para que no haya problemas en los bordes transl√∫cidos cuando cambia el fondo.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y dado que en 4K al mover objetos, la mayor√≠a de nuestros bordes se vuelven transl√∫cidos: la relevancia de las pantallas verdes (o azules, dependiendo del color de la ropa de los actores) es extremadamente alta. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esto es extremadamente inusual para los cineastas, pero como nosotros mismos podemos cambiar la nitidez de los objetos, tenemos la oportunidad de procesar cuadros con diferentes profundidades de campo y, como resultado, leer el mapa de translucidez de los bordes y el color exacto del objeto capturado. Esto le permite disparar sin el uso de pantallas verdes, incluida una imagen bastante compleja, y luego restaurar el mapa de transparencia: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/719/321/028/719321028fe5117bbd95f2a5eb53eef4.gif"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fuente: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entrevista con Yon Karafin</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Lytro grab√≥ especialmente un video en el que se usan escaleras en el fondo (ya que </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">debe</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">algo no encaja en el marco: ¬°esta es la ley inquebrantable de la filmaci√≥n!), y el confeti borroso cae en primer plano (lo que convierte inmediatamente la limpieza de los hombres con escaleras en un desaf√≠o para los ni√±os), pero en el marco estos objetos distantes se recortan de manera relativamente f√°cil y todav√≠a tenemos ordenado primer plano, incluso con un mapa de bordes transl√∫cidos (se selecciona un fondo contra el cual es f√°cil evaluar la calidad del confeti que no lo enmascara): un </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e3c/ca5/ecd/e3cca5ecdfa044f5a126210adee71c5f.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lector competente preguntar√°, ¬øqu√© pasa con el movimiento o el mismo cabello? Y tendr√° toda la raz√≥n. Sus dificultades, por supuesto, a√∫n permanecen (y muchas). Otra cosa es que conociendo el fondo con precisi√≥n y teniendo la capacidad de mover ligeramente el objeto delante del fondo, tenemos oportunidades completamente nuevas para construir autom√°ticamente y mejor </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un mapa de transparencia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En realidad, en virtud de los √∫ltimos tres puntos, es posible predecir el √©xito futuro de las c√°maras ple√≥pticas en series de disparos como "Juegos del Trono", cuando se puede poner en marcha una gran cantidad de efectos especiales. </font><font style="vertical-align: inherit;">Lo que significa una reducci√≥n significativa en su costo. </font><font style="vertical-align: inherit;">Ah√≠ no es tan simple, pero las posibilidades de calcular mapas de transparencia debido al reenfoque y la capacidad de cambiar el punto de disparo son un orden de magnitud mayor que las de las c√°maras 2D convencionales. </font><font style="vertical-align: inherit;">Y las herramientas se apretar√°n. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entonces, descubrimos el mapa de transparencia calculado sin pantallas verdes y seguimos adelante.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exposici√≥n calculada </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un tema importante separado es la exposici√≥n calculada o el obturador calculado. Este tema no est√° directamente relacionado con los ple√≥pticos, pero en condiciones modernas, cuando la diagonal, el contraste y la resoluci√≥n de la pantalla crecen juntos y r√°pidamente, se vuelve cada vez m√°s relevante. El problema es el efecto estrobosc√≥pico, que es t√≠pico del movimiento r√°pido de objetos en el cuadro durante el disparo "normal". </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para reducir dr√°sticamente este efecto al hacer que el movimiento sea "suave" y calcular el obturador "ideal", puede grabar un video con una velocidad de cuadro m√°s alta y luego contarlo a una frecuencia m√°s baja usando varias funciones de conversi√≥n, que incluyen no solo sumar cuadros, sino tambi√©n restar (Lytro Cinema ten√≠a 300 fps para dejar en claro c√≥mo interpretar estos gr√°ficos):</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/77a/c8f/887/77ac8f887c64f3d1032dff17ed4a8ade.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esto hace posible "grabar" un video con un obturador que es f√≠sicamente extremadamente dif√≠cil, si no imposible de crear, pero que proporciona extrema "suavidad" y "placer" de los objetos en movimiento en la escena sin el efecto estrobosc√≥pico de las ramas, las ruedas y otros objetos que se mueven r√°pidamente ( especialmente preste atenci√≥n a los discos de las ruedas, y cu√°nto se ha vuelto m√°s visible el autom√≥vil detr√°s de los obst√°culos): </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb7/cd2/51a/eb7cd251a31f2c79d3f8184af7126321.gif"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fuente: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://vimeo.com/114743605</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O aqu√≠ hay dos disparos m√°s, el movimiento de la c√°mara en el que ser√° mucho m√°s agradable de percibir a simple vista, especialmente en la pantalla grande: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/52c/e3a/ebc/52ce3aebcee45ffc1d48baca9ea3033b.gif"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fuente: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https: / </font><font style="vertical-align: inherit;">/vimeo.com/114743605 Uf</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , calculamos la exposici√≥n. </font><font style="vertical-align: inherit;">¬°Sigamos adelante!</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> C√°mara Plenoptic en tel√©fono inteligente hoy </font></font></h1><br>  Por lo general, cuando se trata de los ple√≥pticos hoy en d√≠a, hay conversaciones t√≠picas en el estilo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"El jefe se ha ido: se retira el yeso, ¬°el cliente se va!"</a>  Lytro compr√≥ Google a bajo precio el a√±o pasado, los experimentos de Pelican Imaging no entraron en producci√≥n en masa y, en general, todo sigui√≥ siendo una teor√≠a hermosa ... <br><br><img width="300" src="https://habrastorage.org/getpro/habr/post_images/db1/c6c/d34/db1c6cd34bdfed6d5b6775a934a20e57.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pelican Imaging: M√≥dulos de c√°mara plenoptica para tel√©fonos inteligentes por 20 d√≥lares</a></i> <br><br>  ¬°Ah√≠ tienes!  Los rumores sobre la muerte de los ple√≥pticos son muy exagerados.  Muy fuerte! <br><br>  Por el contrario, en este momento los sensores ple√≥pticos se producen y utilizan en una escala que <b>nunca</b> antes hab√≠a estado en la historia. <br><br>  La notoria compa√±√≠a de Google sin mucha fanfarria lanz√≥ Google Pixel 2 y Google Pixel 3 con sensores ple√≥pticos.  Si miras el tel√©fono, puedes ver claramente que la c√°mara tiene una c√°mara: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/683/8ba/197/6838ba19764118b6b5a264770ce5f8dc.png"><br><br>  Sin embargo, al mismo tiempo, el tel√©fono difumina muy bien el fondo, en general, no es peor que sus colegas de "dos ojos", "tres ojos" y "cuatro ojos" (de acuerdo, la siguiente foto se beneficia especialmente de este efecto): <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/78d/e6e/e8a/78de6ee8a7b0a719ae7c3cc108ac305f.png"></a> <br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AI Google Blog (puede hacer clic y ver un tama√±o m√°s grande, principalmente en los bordes del objeto en primer plano)</a></i> <br><br>  ¬øC√≥mo hacen eso? <br><br>  Se est√° utilizando una fuente de milagros m√°gicos, ineludibles en los √∫ltimos tiempos: ¬ømagia infantil de redes neuronales? <br><br>  Las redes neuronales, especialmente en Pixel 3, tambi√©n se usan activamente en esta tarea, pero m√°s sobre eso m√°s adelante.  Y el secreto de la calidad del efecto es que el sensor del tel√©fono inteligente es pleno√©ptico, aunque la lente cubre solo dos p√≠xeles, como se muestra en la imagen: <br><br><img width="400" src="https://habrastorage.org/getpro/habr/post_images/852/c36/209/852c36209a7528f576e20dc37e0ef1f3.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AI Google Blog</a></i> <br><br>  Como resultado, obtenemos una imagen micro-est√©reo, aqu√≠ se ve un cambio muy leve en el movimiento (la imagen derecha est√° animada y se mueve hacia arriba y hacia abajo, porque el tel√©fono se mantuvo as√≠ cuando se disparaba): <br><br><img src="https://habrastorage.org/webt/pq/bw/ip/pqbwipy4ne_96amqgpvbinmnehy.gif"><br><br>  Pero incluso este cambio extremadamente peque√±o es suficiente para construir un mapa de profundidad para la foto que se est√° tomando (sobre el uso de cambios de subp√≠xeles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en un art√≠culo anterior</a> ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/066/2be/93e/0662be93e0e02b6f87f7c3fa8b1f8e7c.png"><br><br>  Al mismo tiempo, con el uso del aprendizaje autom√°tico, los resultados se pueden mejorar significativamente y esto ya est√° implementado en Pixel 3. En el siguiente ejemplo, Aprendido significa Est√©reo + Aprendido, m√°s sobre esto, con suerte, habr√° una publicaci√≥n separada: <br><br><img width="230" src="https://habrastorage.org/getpro/habr/post_images/566/8e0/05b/5668e005b8efd21ce9f216ed9d16edf1.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/988/e31/9d2/988e319d2619f39a50d19cde8904d891.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/638/a17/966/638a1796697b9f2a675c509ff870465f.png"><br><br><img width="230" src="https://habrastorage.org/getpro/habr/post_images/110/4df/a5e/1104dfa5e50f1d476bc1ee7024520834.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/1ed/beb/daa/1edbebdaa7934c6525005fd8118fbd83.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/77e/ef2/942/77eef2942f1e6b6af44ccc720ae2c3a5.png"><br><br><img width="230" src="https://habrastorage.org/getpro/habr/post_images/429/442/99e/42944299e72b7eb720f3babc5a757b79.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/da3/fe1/3ea/da3fe13eacb3cd5b0a558db1d843b686.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/c6f/a27/c4b/c6fa27c4bac8b9c5cb122e0c69ab814d.png"><br><br>  Para aquellos a quienes les gusta mirar la profundidad en resoluci√≥n completa, hay m√°s ejemplos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en una galer√≠a especial</a> . <br><br>  Se ve claramente que no todo es perfecto, y tenemos artefactos t√≠picos que son t√≠picos para construir un mapa de profundidad desde est√©reo (que, por cierto, tambi√©n est√°n disponibles en los colegas de dos ojos de Pixel), y un poco de paralaje afecta.  Pero ya est√° claro que la calidad de la profundidad es suficiente para segmentar con confianza la imagen por profundidad e imponer a√∫n m√°s efectos diferentes, agregar objetos con m√°s confianza a la escena, etc.  Los resultados de la profundidad MEDIDA son un orden de magnitud mejor que los resultados basados ‚Äã‚Äãen varios supuestos (redes neuronales arbitrarias). <br><br>  ¬°Felicitaciones a todos los que han le√≠do hasta este momento!  ¬°Vives durante el lanzamiento de c√°maras ple√≥pticas en un producto exitoso del mercado masivo, incluso si ni siquiera lo sabes! <br><br>  La historia no termina ah√≠, por supuesto: <br><br><ul><li>  En primer lugar, es interesante que los ple√≥pticos fueran "casi gratis", ya que en las c√°maras de tel√©fonos inteligentes modernas con una miniaturizaci√≥n del sensor y un aumento de la resoluci√≥n, hay una falta catastr√≥fica de flujo luminoso, por lo que cada p√≠xel est√° cubierto con una microlente.  Es decir, dicho sensor no cuesta m√°s (¬°esto es muy importante!), Aunque estamos sacrificando algo una resoluci√≥n que acabamos de aumentar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">debido a otra tecnolog√≠a</a> .  Como resultado de la aplicaci√≥n de dos tecnolog√≠as, el resultado se vuelve mejor en 2D (menos ruido, mayor resoluci√≥n, HDR) y al mismo tiempo se complementa con la profundidad medida, es decir, se convierte en 3D.  El precio de la emisi√≥n es un aumento dram√°tico en el n√∫mero de c√°lculos por fotograma.  Pero para las fotos esto ya es posible hoy y ya funciona en tel√©fonos inteligentes reales. <br></li><li>  En segundo lugar, en una conferencia, un empleado de Google dijo que estaban pensando en cubrir 4 p√≠xeles con una lente, despu√©s de lo cual la calidad del mapa de profundidad ser√° dram√°ticamente m√°s alta, ya que habr√° 2 pares est√©reo con una base est√©reo 1.4 veces m√°s grande (dos diagonales), esto mejorar√° dram√°ticamente la calidad del mapa de profundidad, incluyendo muchos artefactos est√©reo en las fronteras.  Los competidores pueden lograr esta calidad solo colocando al menos 3 c√°maras seguidas.  Tal aumento en la calidad es importante para AR. <br></li><li>  En tercer lugar, Google ya no est√° solo, aqu√≠ hay un ejemplo de una descripci√≥n de una tecnolog√≠a similar en el Vivo V11 Pro, ya ves, acabas de ver una imagen similar: <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/096/4b1/ff8/0964b1ff86f0970e6e7c1ef3611ec11d.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¬øQu√© es la tecnolog√≠a Dual Pixel?</a></i> <br><br><ul><li>  Finalmente, en los √∫ltimos a√±os, el n√∫mero de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaciones sobre la interpolaci√≥n de datos de campo claro</a> ha crecido simplemente como una avalancha.  Y esto es maravilloso, porque para reducir dr√°sticamente la complejidad computacional, se necesitar√°n matem√°ticas no infantiles. </li></ul><br>  Plenoptics tambi√©n se utiliza en el enfoque autom√°tico de c√°maras profesionales, por ejemplo, con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Canon</a> (google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DPAF</a> - Dual Pixel Auto Focus).  ¬øQui√©n hubiera pensado que una broma te√≥rica de hace 30 a√±os, la capacidad de disparar est√©reo con una lente, ser√≠a la primera aplicaci√≥n masiva de los ple√≥pticos ... <br><br>  En general, ¬°el tema fue para los productos! <br><br>  Ella ya est√° volando!  Ya ves, <b>LE-TA-ET!</b> <br><br><hr><br><h1>  Para resumir </h1><br><h2>  Filmoptica en el cine </h2><br>  Arriba, examinamos dos casos de uso de ple√≥pticos: en la producci√≥n de pel√≠culas y en los tel√©fonos inteligentes.  Esta no es una lista completa, por ejemplo, los ple√≥pticos son muy relevantes en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">microscop√≠a</a> : puede hacer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">micrograf√≠as est√©reo calculadas</a> con una gran profundidad de campo "honesta";  los ple√≥pticos son relevantes para las c√°maras industriales, especialmente si necesita tomar fotos de objetos multinivel transl√∫cidos, etc.  Pero al respecto de alguna otra manera. <br><br><hr><br>  Recordemos que para su uso en la producci√≥n de pel√≠culas son relevantes: <br><br><ol><li>  Distancia de enfoque calculada <br></li><li>  Bokeh calculado <br></li><li>  Resoluci√≥n calculada <br></li><li>  Est√©reo perfecto calculado <br></li><li>  Punto de disparo calculado <br></li><li>  Iluminaci√≥n computarizada <br></li><li>  Ambiente Computado <br></li><li>  Pantalla verde calculada <br></li><li>  Obturador calculado <br></li></ol><hr><br>  En los pr√≥ximos a√±os, con la miniaturizaci√≥n y una mayor resoluci√≥n de los sensores, se puede desarrollar tecnolog√≠a para crear una c√°mara de cine pr√°ctica y fundamentalmente nueva que le permite eliminar material para aplicar efectos especiales m√°s r√°pido (sin una pantalla verde) y con menos tomas (m√°s puntos son m√°s f√°ciles de arreglar).  Las nuevas caracter√≠sticas son tan interesantes que, para cuando el sensor pleno√≥ptico con una resoluci√≥n de pel√≠cula adecuada se puede compactar, estas c√°maras est√°n condenadas al √©xito. <br><br>  <b>¬øCu√°ndo puede aparecer una c√°mara as√≠?</b> <br><br>  Una respuesta cautelosa es en los pr√≥ximos 10 a√±os. <br><br>  <b>¬øDe qu√© depende el t√©rmino?</b> <br><br>  De muchos factores.  Buena pregunta: ¬øcu√°l ser√° la situaci√≥n con la capacidad de licenciar las patentes de Lytro que ahora posee Google?  Esto puede ser cr√≠tico.  Afortunadamente, las claves expirar√°n en 10 a√±os (aqu√≠ no recordamos cort√©smente a los colegas chinos de Lytro que pueden acelerar el proceso).  Adem√°s, el trabajo con cantidades colosales de datos generados por la c√°mara ple√≥ptica debe simplificarse: con las nubes modernas, esto es cada vez m√°s f√°cil.  De las buenas noticias: en un momento gracias a Lytro, en un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">programa de composici√≥n muy popular</a> , que se utiliza en una gran cantidad de estudios para el procesamiento est√©reo, se admiti√≥ el formato de datos ple√≥pticos.  Como dicen, Lytro muri√≥, pero la oportunidad de escribir complementos para Nuke con soporte para video plenoptic permaneci√≥ con nosotros.  Esto simplifica la "entrada" en este mercado con un producto profesional, ya que es importante que los estudios puedan trabajar inmediatamente con el formato de las nuevas c√°maras de inmediato sin necesidad de capacitar al personal y en los mismos programas. <br><br><h2>  Plenoptika en tel√©fonos inteligentes </h2><br>  Si hablamos de tel√©fonos inteligentes, entonces todo se ve a√∫n mejor.  Lo m√°s relevante para esta industria es la capacidad de la c√°mara ple√≥ptica para medir la profundidad con un solo sensor (potencialmente r√°pido) y esta caracter√≠stica pronto ser√° de gran demanda. <br><br>  <b>¬øCu√°ndo puede aparecer una c√°mara as√≠?</b> <br><br>  Ya existe  Y ma√±ana, la tecnolog√≠a ser√° repetida por otros fabricantes.  Adem√°s, el factor clave de la pr√≥xima etapa ser√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la realidad aumentada</a> en tel√©fonos inteligentes y tabletas, que hoy carece de precisi√≥n y la capacidad de "ver" una escena tridimensional. <br><br>  <b>¬øDe qu√© depende el t√©rmino?</b> <br><br>  Es probable que la capacidad de medir la distancia con el sensor principal en tiempo real aparezca pronto con Google Pixel, ya que Google se ha estado desarrollando en esta direcci√≥n durante mucho tiempo (consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Proyecto Tango</a> , que est√° cerrado, pero cuyo negocio sigue vivo).  Y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ARCore se</a> ve muy prometedor, as√≠ como el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ARKit de</a> la competencia.  Y el avance, como ahora supones, no tiene que esperar mucho, ya que el valor del p√≠xel del sensor cae exponencialmente, llaman a la velocidad promedio 10 veces en 10 a√±os, y necesitamos una ca√≠da de 2 veces.  Entonces cuenta por ti mismo.  No ma√±ana, pero no por mucho tiempo. <br><br><h1>  En lugar de una conclusi√≥n </h1><br>  ¬øRecuerdas que al principio est√°bamos hablando de una conferencia en VGIK?  Debo decir que no esperaba la reacci√≥n que se produjo al final.  Para decirlo en una palabra, estaba de luto.  Si en dos palabras, entonces luto universal.  Y al principio no entend√≠ cu√°l era el problema.  El operador que apareci√≥ despu√©s de la conferencia me explic√≥ muy bien la situaci√≥n.  Ni siquiera era que el arte de la c√°mara estaba disminuyendo.  Aunque hubo un gran ejemplo: un fragmento de pel√≠cula durante unos 6 segundos, cuando una persona se acerca a la puerta del departamento, golpea, otra persona abre la puerta, saluda y se mueve un poco hacia adelante, mientras la c√°mara enfoca el pasillo, luego el marco de la puerta, luego enfoca instant√°neamente en la persona que lo descubri√≥, y luego en la habitaci√≥n.  Y el operador necesita dominar la c√°mara a la perfecci√≥n, de modo que con una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">profundidad de campo poco profunda como la del cine,</a> opere el zoom de manera magistral, recordando la luz de fondo, la composici√≥n del marco, el mareo al disparar con las manos y otras 1000 peque√±as cosas importantes.  Entonces aqu√≠.  Ni siquiera es que esto sea cada vez m√°s f√°cil.  Esto es incluso bueno.  Menos tomas se echar√°n a perder debido al hecho de que el operador en alg√∫n lugar no tuvo tiempo o se perdi√≥.  Cont√≥ c√≥mo recientemente film√≥ una serie en 4K para el canal.  Y el stock de resoluci√≥n result√≥ ser grande.  Como resultado, el director cort√≥ los cuadros en la posproducci√≥n, y en algunos lugares solo se usaron fragmentos del cuadro para las interrupciones.  Como resultado, la composici√≥n fue simplemente horrible y este operador quer√≠a eliminar su nombre de los cr√©ditos. <br><br>  Las caracter√≠sticas descritas anteriormente de las c√°maras para cineastas significan la transferencia de muchos efectos desde la etapa de filmaci√≥n hasta la etapa de postproducci√≥n.  Y habr√° una gran tristeza si quienes procesan las escenas tomadas son analfabetos en materia de composici√≥n, control de distancia de enfoque, etc.  Si saben leer y escribir, estas son nuevas oportunidades fant√°sticas. <br><br>  <b>Por lo tanto, nos deseamos a todos m√°s competencia, ¬°lo cual no siempre es f√°cil en este mundo que cambia r√°pidamente!</b> <br><br>  <b>Y <s>Cartago ... ¬°</s> todo el video ser√° tridimensional para fines de siglo!</b> <br><br><h1>  Agradecimientos </h1><br>  Me gustar√≠a agradecerle cordialmente: <br><br><ul><li>  Laboratorio de Computaci√≥n Gr√°fica VMK Universidad Estatal de Mosc√∫  MV Lomonosov por su contribuci√≥n al desarrollo de gr√°ficos por computadora en Rusia y no solo <br></li><li>  Nuestros colegas del grupo de videos, gracias a los cuales vieron este art√≠culo, <br></li><li>  personalmente Konstantin Kozhemyakov, quien hizo mucho para hacer este art√≠culo mejor y m√°s visual, <br></li><li>  Jon Karafin cuando era jefe de video de campo de luz en Lytro, gracias a lo cual casi comenzamos a trabajar para mejorar su producto (y no comenzamos por razones ajenas a nuestro control o de nosotros), <br></li><li>  Lytro por su contribuci√≥n a la popularizaci√≥n de los campos de luz y sus capacidades, Google, que atrap√≥ la bandera que cae, y otras compa√±√≠as que fabrican productos basados ‚Äã‚Äãen esta interesante tecnolog√≠a, <br></li><li>  y finalmente, muchas gracias a Sergey Lavrushkin, Roman Kazantsev, Ivan Molodetsky, Evgeny Kuptsov, Yegor Sklyarov, Evgeny Lyapustin y Denis Kondranin por una gran cantidad de comentarios y correcciones sensatas que hicieron que este texto fuera mucho mejor. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440652/">https://habr.com/ru/post/440652/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440642/index.html">Noche de JetBrains en Mosc√∫, 13 de abril</a></li>
<li><a href="../440644/index.html">El resumen de materiales frescos del mundo de la interfaz para la √∫ltima semana No. 352 (11-17 de febrero de 2019)</a></li>
<li><a href="../440646/index.html">Frontend Weekly Digest (11-17 de febrero de 2019)</a></li>
<li><a href="../440648/index.html">Descripci√≥n general de la legislaci√≥n rusa en el campo de la accesibilidad web</a></li>
<li><a href="../440650/index.html">C√≥mo funciona la conciencia: conclusiones del libro de Alexander Nevzorov</a></li>
<li><a href="../440654/index.html">Python de aprendizaje: m√≥dulo argparse</a></li>
<li><a href="../440656/index.html">Contenedor profesional de aplicaciones Node.js usando Docker</a></li>
<li><a href="../440658/index.html">Explorando Docker, Parte 4: Reduciendo el tama√±o de las im√°genes y acelerando su ensamblaje</a></li>
<li><a href="../440660/index.html">Aprendizaje Docker, Parte 5: Comandos</a></li>
<li><a href="../440662/index.html">Tutorial React Parte 18: La sexta fase de trabajar en una aplicaci√≥n TODO</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
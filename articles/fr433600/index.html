<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª üññüèº üî¥ Pixel 3 apprend √† d√©terminer la profondeur des photos üèáüèæ üé∂ üîù</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le mode portrait sur les smartphones Pixel vous permet de prendre des photos d'aspect professionnel qui attirent l'attention sur le sujet en floutant ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pixel 3 apprend √† d√©terminer la profondeur des photos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433600/"> Le mode portrait sur les smartphones Pixel vous permet de prendre des photos d'aspect professionnel qui attirent l'attention sur le sujet en floutant l'arri√®re-plan.  L'ann√©e derni√®re, nous avons d√©crit comment nous calculons la profondeur √† l'aide d'une seule cam√©ra et d'un autofocus √† d√©tection de phase (Autofocus √† d√©tection de phase, PDAF), √©galement connu sous le nom d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">autofocus √† deux pixels</a> .  Ce processus a utilis√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">algorithme st√©r√©o traditionnel</a> sans formation.  Cette ann√©e, au Pixel 3, nous avons adopt√© l'apprentissage automatique afin d'am√©liorer l'√©valuation de la profondeur et de produire des r√©sultats encore meilleurs en mode portrait. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/505/531/899/505531899e63adc78fbd74d94f1c3a3a.gif"><br>  <i>Gauche: l'image originale captur√©e en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HDR +</a> .</i>  <i>√Ä droite, une comparaison des r√©sultats de la prise de vue en mode portrait utilisant la profondeur de la st√©r√©o traditionnelle et de l'apprentissage automatique.</i>  <i>Les r√©sultats d'apprentissage produisent moins d'erreurs.</i>  <i>Dans le r√©sultat st√©r√©o traditionnel, la profondeur de nombreuses lignes horizontales derri√®re l'homme est incorrectement estim√©e √©gale √† la profondeur de l'homme lui-m√™me, ce qui fait qu'elles restent nettes.</i> <br><a name="habracut"></a><br><h2>  Une br√®ve excursion dans le mat√©riel pr√©c√©dent </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'ann√©e derni√®re,</a> nous avons d√©crit que le mode portrait utilise un r√©seau de neurones pour s√©parer les pixels appartenant aux images des personnes et aux images d'arri√®re-plan, et compl√®te ce masque √† deux niveaux avec des informations de profondeur d√©riv√©es des pixels PDAF.  Tout cela a √©t√© fait pour obtenir un flou, en fonction de la profondeur, proche de ce que peut donner un appareil photo professionnel. <br><br>  Pour fonctionner, le PDAF prend deux plans l√©g√®rement diff√©rents de la sc√®ne.  En basculant entre les images, vous pouvez voir que la personne ne bouge pas et que l'arri√®re-plan se d√©place horizontalement - cet effet est appel√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">parallaxe</a> .  Puisque la parallaxe est fonction de la distance d'un point √† la cam√©ra et de la distance entre deux points de vue, nous pouvons d√©terminer la profondeur en comparant chaque point d'une image avec son point correspondant dans une autre. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e15/41c/044/e1541c044baa5454ddee71ef45c9a96c.gif"><br>  <i>Les images PDAF √† gauche et au milieu semblent similaires, mais la parallaxe peut √™tre vue dans le fragment agrandi √† droite.</i>  <i>Il est plus facile √† remarquer par la structure ronde au centre de l'agrandissement.</i> <br><br>  Cependant, trouver de telles correspondances dans les images PDAF (cette m√©thode est appel√©e profondeur st√©r√©o) est une t√¢che extr√™mement difficile, car les points entre les photos se d√©placent tr√®s faiblement.  De plus, toutes les technologies st√©r√©o souffrent de probl√®mes d'ouverture.  Si vous regardez la sc√®ne √† travers une petite ouverture, il ne sera pas possible de trouver la correspondance des points pour les lignes parall√®les √† la ligne de base st√©r√©o, c'est-√†-dire la ligne reliant les deux cam√©ras.  En d'autres termes, lorsque vous √©tudiez les lignes horizontales dans la photo pr√©sent√©e (ou les lignes verticales dans les images avec une orientation portrait), tous les d√©calages d'une image par rapport √† une autre sont approximativement les m√™mes.  Dans le mode portrait de l'ann√©e derni√®re, tous ces facteurs pouvaient conduire √† des erreurs dans la d√©termination de la profondeur et de l'apparence d'artefacts d√©sagr√©ables. <br><br><h2>  Am√©lioration de l'√©valuation de la profondeur </h2><br>  Avec le mode portrait Pixel 3, nous corrigeons ces erreurs en utilisant le fait que la parallaxe des photos st√©r√©o n'est qu'un des nombreux indices dans les images.  Par exemple, les points √©loign√©s du plan de mise au point semblent moins nets, et ce sera un indice de la profondeur de la mise au point.  De plus, m√™me lorsque vous regardez une image sur un √©cran plat, nous pouvons facilement estimer la distance aux objets, car nous connaissons la taille approximative des objets du quotidien (c'est-√†-dire que vous pouvez utiliser le nombre de pixels repr√©sentant le visage d'une personne pour √©valuer sa distance).  Ce sera un indice s√©mantique. <br><br>  D√©velopper manuellement un algorithme qui combine ces conseils est extr√™mement difficile, mais en utilisant MO, nous pouvons le faire tout en am√©liorant les performances des conseils de parallaxe PDAF.  Plus pr√©cis√©ment, nous formons un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©seau de neurones convolutifs</a> √©crit en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorFlow</a> , recevant des pixels PDAF en entr√©e et apprenant √† pr√©dire la profondeur.  Cette nouvelle m√©thode am√©lior√©e d'estimation de la profondeur bas√©e sur MO est utilis√©e en mode portrait Pixel 3. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7db/0ff/5e3/7db0ff5e3063425f703aaf2b3f30fd77.png"><br>  <i>Notre r√©seau de neurones convolutionnels re√ßoit des images PDAF et fournit une carte de profondeur.</i>  <i>Le r√©seau utilise une architecture de type codeur-d√©codeur avec des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">connexions de saut</a> suppl√©mentaires et des blocs r√©siduels.</i> <br><br><h2>  Formation au r√©seau de neurones </h2><br>  Pour former le r√©seau, nous avons besoin de beaucoup d'images PDAF et de cartes de profondeur correspondantes de haute qualit√©.  Et comme nous avons besoin de pr√©visions de profondeur pour √™tre utiles en mode portrait, nous avons besoin que les donn√©es de formation soient similaires aux photos prises par les utilisateurs avec les smartphones. <br><br>  Pour ce faire, nous avons con√ßu un appareil Frankenfon sp√©cial, dans lequel nous avons combin√© cinq t√©l√©phones Pixel 3 et √©tabli une connexion WiFi entre eux, ce qui nous a permis de prendre simultan√©ment des photos de tous les t√©l√©phones (avec une diff√©rence ne d√©passant pas 2 ms).  Avec cet appareil, nous avons calcul√© des cartes de profondeur de haute qualit√© bas√©es sur des photographies, en utilisant √† la fois le mouvement et la st√©r√©o sous plusieurs angles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/995/827/05b/99582705b2c447fa6faf95c5c114d20f.gif"><br>  <i>√Ä gauche: un appareil pour collecter les donn√©es d'entra√Ænement.</i>  <i>Au milieu: un exemple de basculement entre cinq photographies.</i>  <i>La synchronisation de la cam√©ra garantit la capacit√© de calculer la profondeur dans les sc√®nes dynamiques.</i>  <i>Droite: profondeur totale.</i>  <i>Les points avec une faible confiance, o√π la comparaison des pixels dans diff√©rentes photos √©tait incertaine en raison de la faiblesse des textures, sont peints en noir et ne sont pas utilis√©s dans la formation.</i> <br><br>  Les donn√©es obtenues √† l'aide de cet appareil √©taient id√©ales pour former le r√©seau pour les raisons suivantes: <br><br><ul><li>  Cinq points de vue garantissent la pr√©sence de parallaxe dans plusieurs directions, ce qui nous √©vite le probl√®me de l'ouverture. </li><li>  L'emplacement des cam√©ras garantit que tout point de l'image est r√©p√©t√© dans au moins deux photographies, ce qui r√©duit le nombre de points qui ne peuvent pas √™tre mis en correspondance. </li><li>  La ligne de base, c'est-√†-dire la distance entre les cam√©ras, est sup√©rieure √† celle du PDAF, ce qui garantit une estimation plus pr√©cise de la profondeur. </li><li>  La synchronisation de la cam√©ra garantit la capacit√© de calculer la profondeur dans les sc√®nes dynamiques. </li><li>  La portabilit√© de l'appareil garantit la possibilit√© de prendre des photos dans la nature, simulant des photos que les utilisateurs prennent √† l'aide de smartphones. </li></ul><br>  Cependant, malgr√© l'id√©alit√© des donn√©es obtenues √† l'aide de cet appareil, il est toujours extr√™mement difficile de pr√©dire la profondeur absolue des objets de la sc√®ne - une paire PDAF donn√©e peut correspondre √† diff√©rentes cartes de profondeur (tout d√©pend des caract√©ristiques des objectifs, de la distance focale, etc.).  Pour tenir compte de tout cela, nous estimons la profondeur relative des objets de la sc√®ne, ce qui est suffisant pour obtenir des r√©sultats satisfaisants en mode portrait. <br><br><h2>  Nous combinons tout cela </h2><br>  L'estimation de la profondeur √† l'aide de MO sur le Pixel 3 devrait fonctionner rapidement afin que les utilisateurs n'aient pas √† attendre trop longtemps pour obtenir des r√©sultats de portrait.  Cependant, pour obtenir de bonnes estimations de profondeur en utilisant une petite d√©focalisation et une parallaxe, vous devez alimenter les r√©seaux de neurones de la photo en pleine r√©solution.  Pour garantir des r√©sultats rapides, nous utilisons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorFlow Lite</a> , une solution multiplateforme pour le lancement de mod√®les MO sur des appareils mobiles et embarqu√©s, ainsi qu'un puissant GPU Pixel 3, qui vous permet de calculer rapidement la profondeur sur des donn√©es d'entr√©e inhabituellement volumineuses.  Ensuite, nous combinons les estimations de profondeur obtenues avec des masques de notre r√©seau de neurones, qui distingue les personnes, pour obtenir les plus beaux r√©sultats de prise de vue en mode portrait. <br><br><h2>  Essayez-le vous-m√™me </h2><br>  Dans Google Camera App version 6.1 et sup√©rieure, nos cartes de profondeur sont int√©gr√©es dans des images en mode portrait.  Cela signifie que nous pouvons utiliser l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©diteur de profondeur de Google Photos</a> pour modifier le degr√© de flou et le point AF apr√®s avoir pris une photo.  Vous pouvez √©galement utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des</a> programmes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tiers</a> pour extraire des cartes de profondeur √† partir de jpeg et les √©tudier vous-m√™me.  Vous pouvez √©galement prendre un album √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partir du lien</a> , montrant des cartes de profondeur relative et des images correspondantes en mode portrait, pour comparer l'approche st√©r√©o et MO traditionnelle. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr433600/">https://habr.com/ru/post/fr433600/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr433586/index.html">Comment nous n'avons pas gagn√© le hackathon</a></li>
<li><a href="../fr433588/index.html">Performances incroyables des algorithmes parall√®les C ++ 17. Mythe ou r√©alit√©?</a></li>
<li><a href="../fr433592/index.html">Informations: Yandex.Phone</a></li>
<li><a href="../fr433596/index.html">L'erreur de Magellan: d√©passement de tampon ou exp√©dition autour du monde avec SQLite FTS</a></li>
<li><a href="../fr433598/index.html">Comment LLVM optimise la fonction</a></li>
<li><a href="../fr433602/index.html">La simplicit√© math√©matique peut √™tre √† l'origine de la vitesse d'√©volution.</a></li>
<li><a href="../fr433604/index.html">Travail confortable avec Android Studio</a></li>
<li><a href="../fr433606/index.html">Profondeurs SIEM: corr√©lations pr√™tes √† l'emploi. Partie 3.2. M√©thodologie de normalisation des √©v√©nements</a></li>
<li><a href="../fr433608/index.html">La voiture du futur. √âcrans au lieu de vitres automobiles?</a></li>
<li><a href="../fr433610/index.html">Notes d'un phytochimiste. Kaki</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üê´ üôçüèæ ‚ò£Ô∏è KI, praktischer Kurs. Tiefes Lernen, um Musik zu generieren üè™ üç¶ üñïüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dies ist der letzte Artikel in einer Reihe von Schulungsartikeln f√ºr Entwickler auf dem Gebiet der k√ºnstlichen Intelligenz. Es werden die Schritte zum...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>KI, praktischer Kurs. Tiefes Lernen, um Musik zu generieren</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/423727/"><img src="https://habrastorage.org/webt/zy/do/u4/zydou4yx-zh_x9qzbumtrbdhwy4.jpeg"><br><br>  Dies ist der letzte Artikel in einer Reihe von Schulungsartikeln f√ºr Entwickler auf dem Gebiet der k√ºnstlichen Intelligenz.  Es werden die Schritte zum Erstellen eines Deep-Learning-Modells f√ºr die Musikgenerierung, zur Auswahl des richtigen Modells und zur Datenvorverarbeitung sowie die Verfahren zum Einstellen, Trainieren, Testen und √Ñndern von BachBot erl√§utert. <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Musikgenerierung - √úber eine Aufgabe nachdenken</font> </h2><br>  Der erste Schritt bei der L√∂sung vieler Probleme mithilfe k√ºnstlicher Intelligenz (KI) besteht darin, das Problem auf ein Grundproblem zu reduzieren, das mithilfe von KI gel√∂st wird.  Ein solches Problem ist die Sequenzvorhersage, die in √úbersetzungs- und Verarbeitungsanwendungen in nat√ºrlicher Sprache verwendet wird.  Unsere Aufgabe, Musik zu erzeugen, kann auf das Problem der Vorhersage einer Sequenz reduziert werden, und die Vorhersage wird f√ºr eine Sequenz von Noten durchgef√ºhrt. <br><br><h2>  <font color="#0071c5">Modellauswahl</font> </h2><br>  Es gibt verschiedene Arten von neuronalen Netzen, die als Modelle betrachtet werden k√∂nnen: direkt verteilte neuronale Netze, wiederkehrende neuronale Netze und neuronale Netze mit Langzeitged√§chtnis. <br><br>  Neuronen sind die grundlegenden abstrakten Elemente, die sich zu neuronalen Netzen verbinden.  Im Wesentlichen ist ein Neuron eine Funktion, die Daten am Eingang empf√§ngt und das Ergebnis ausgibt. <br><br><img src="https://habrastorage.org/webt/56/pq/hs/56pqhseblx5mqec0apoegck7vd4.png"><br>  <i>Neuron</i> <br><br>  Schichten von Neuronen, die am Eingang dieselben Daten empfangen und verbundene Ausg√§nge haben, k√∂nnen kombiniert werden, um ein <i>neuronales Netzwerk mit direkter Ausbreitung</i> aufzubauen.  Solche neuronalen Netze zeigen hohe Ergebnisse aufgrund der Zusammensetzung nichtlinearer Aktivierungsfunktionen, wenn Daten durch mehrere Schichten geleitet werden (das sogenannte Deep Learning). <br><br><img src="https://habrastorage.org/webt/e8/ps/1v/e8ps1vchys7uap5mjucmyip5ob8.png"><br>  <i>Neuronales Netzwerk mit direkter Verteilung</i> <br><br>  Ein direkt verteiltes neuronales Netzwerk zeigt gute Ergebnisse in einer Vielzahl von Anwendungen.  Ein solches neuronales Netzwerk hat jedoch einen Nachteil, der seine Verwendung in einer Aufgabe im Zusammenhang mit der Musikkomposition (Sequenzvorhersage) nicht zul√§sst: Es hat eine feste Dimension von Eingabedaten, und Musikkompositionen k√∂nnen unterschiedliche L√§ngen haben.  Dar√ºber hinaus <i>ber√ºcksichtigen neuronale Netze mit direkter Verteilung keine Eingaben aus fr√ºheren Zeitschritten, was sie f√ºr die L√∂sung des Sequenzvorhersageproblems nicht sehr n√ºtzlich macht!</i>  Ein Modell, das als <i>wiederkehrendes neuronales Netzwerk bezeichnet wird, ist</i> f√ºr diese Aufgabe besser geeignet. <br><br>  Rekursive neuronale Netze l√∂sen diese beiden Probleme, indem sie Verbindungen zwischen versteckten Knoten einf√ºhren: In diesem Fall k√∂nnen Knoten im n√§chsten Zeitschritt Informationen √ºber die Daten im vorherigen Zeitschritt empfangen. <br><br><img src="https://habrastorage.org/webt/xc/jv/dr/xcjvdrzlx66olpyziwbtfywxukq.png"><br>  <i>Detaillierte Darstellung eines wiederkehrenden neuronalen Netzwerks</i> <br><br>  Wie Sie in der Abbildung sehen k√∂nnen, erh√§lt jedes Neuron jetzt Eingaben sowohl von der vorherigen neuronalen Schicht als auch von der vorherigen Zeit. <br><br>  Rekursive neuronale Netze, die sich mit gro√üen Eingabesequenzen befassen, sto√üen auf das sogenannte <i>Problem des verschwindenden Gradienten</i> : Dies bedeutet, dass der Einfluss fr√ºherer Zeitschritte schnell verschwindet.  Dieses Problem ist charakteristisch f√ºr die Aufgabe der Musikkomposition, da es wichtige langfristige Abh√§ngigkeiten in Musikwerken gibt, die ber√ºcksichtigt werden m√ºssen. <br><br>  Um das Problem eines verschwindenden Gradienten zu l√∂sen, kann eine Modifikation des wiederkehrenden Netzwerks verwendet werden, das als <i>neuronales Netzwerk mit langem Kurzzeitged√§chtnis (oder LSTM-neuronales Netzwerk) bezeichnet wird</i> .  Dieses Problem wird durch die Einf√ºhrung von Speicherzellen gel√∂st, die von drei Arten von "Gates" sorgf√§ltig √ºberwacht werden.  Klicken Sie auf den folgenden Link, um weitere Informationen zu erhalten: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Allgemeine Informationen zu neuronalen LSTM-Netzen</a> . <br><br>  Daher verwendet BachBot ein Modell, das auf dem neuronalen LSTM-Netzwerk basiert. <br><br><h2>  <font color="#0071c5">Vorbehandlung</font> </h2><br>  Musik ist eine sehr komplexe Kunstform und umfasst verschiedene Dimensionen: Tonh√∂he, Rhythmus, Tempo, dynamische Farbt√∂ne, Artikulation und mehr.  Um die Musik f√ºr die Zwecke dieses Projekts zu vereinfachen <i>, werden nur die Tonh√∂he und die Dauer der Kl√§nge ber√ºcksichtigt</i> .  Dar√ºber hinaus wurden alle Ch√∂re in C-Dur oder A-Moll <i>transponiert</i> , und die Notenzeiten wurden <i>zeitlich</i> (gerundet) auf das n√§chste Vielfache der Sechzehntelnote <i>quantisiert</i> .  Diese Ma√ünahmen wurden ergriffen, um die Komplexit√§t der Kompositionen zu verringern und die Netzwerkleistung zu erh√∂hen, w√§hrend der grundlegende Inhalt der Musik unver√§ndert blieb.  Operationen zur Normalisierung der Tonalit√§ten und Dauer von Noten wurden unter Verwendung der music21-Bibliothek durchgef√ºhrt. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">standardize_key</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Converts into the key of C major or A minor. Adapted from https://gist.github.com/aldous-rey/68c6c43450517aa47474 """</span></span> <span class="hljs-comment"><span class="hljs-comment"># conversion tables: eg Ab -&gt; C is up 4 semitones, D -&gt; A is down 5 semitones majors = dict([("A-", 4),("A", 3),("B-", 2),("B", 1),("C", 0),("C#",-1), ("D-", -1),("D", -2),("E-", -3),("E", -4),("F", -5),("F#",6), ("G-", 6), ("G", 5)]) minors = dict([("A-", 1),("A", 0),("B-", -1),("B", -2),("C", -3),("C#",-4), ("D-", -4),("D", -5),("E-", 6),("E", 5),("F", 4),("F#",3), ("G-",3),("G", 2)]) # transpose score key = score.analyze('key') if key.mode == "major": halfSteps = majors[key.tonic.name] elif key.mode == "minor": halfSteps = minors[key.tonic.name] tScore = score.transpose(halfSteps) # transpose key signature for ks in tScore.flat.getKeySignatures(): ks.transpose(halfSteps, inPlace=True) return tScore</span></span></code> </pre> <br>  <i>Der Code zur Standardisierung der Schl√ºsselzeichen in den gesammelten Werken, die Tasten in C-Dur oder A-Moll werden in der Ausgabe verwendet</i> <br><br>  Die Zeitquantisierung auf das n√§chste Vielfache der Sechzehntelnote wurde unter Verwendung der <i>Stream.quantize ()</i> -Funktion der <i>music21-</i> Bibliothek durchgef√ºhrt.  Das Folgende ist ein Vergleich von Statistiken, die einem Datensatz vor und nach seiner vorl√§ufigen Verarbeitung zugeordnet sind: <br><br><img src="https://habrastorage.org/webt/kr/wh/5n/krwh5n0d1dubkwn0urbjmp7ovzs.png"><br>  <i>Verwendung jeder Notenklasse vor (links) und nach der Vorverarbeitung (rechts).</i>  <i>Eine Notenklasse ist eine Note unabh√§ngig von ihrer Oktave.</i> <br><br><img src="https://habrastorage.org/webt/mz/rq/i0/mzrqi0fynco56dhr9kdk-nsfjrs.png"><br>  <i>Position der Notizen vor (links) und nach der Vorverarbeitung (rechts)</i> <br><br>  Wie Sie in der obigen Abbildung sehen k√∂nnen, hat die Transposition der urspr√ºnglichen Tonart der Ch√∂re in die Tonart C-Dur oder c-Moll (a-Moll) die in den gesammelten Werken verwendete Notenklasse erheblich beeinflusst.  Insbesondere die Anzahl der Vorkommen f√ºr Noten in Tonarten in Dur-Tonarten (C-Dur) und a-Moll (a-Moll) (C, D, E, F, G, A, B) nahm zu.  Sie k√∂nnen auch kleine Peaks f√ºr die Noten F # und G # beobachten, da sie in der aufsteigenden Folge von melodischem a-Moll (A, B, C, D, E, F # und G #) vorhanden sind.  <i>Andererseits hatte die Zeitquantisierung einen viel geringeren Effekt.</i>  Dies kann durch die hohe Aufl√∂sung der Quantisierung erkl√§rt werden (√§hnlich wie beim Runden auf viele signifikante Stellen). <br><br><h2>  <font color="#0071c5">Codierung</font> </h2><br>  Nachdem die Daten vorverarbeitet wurden, m√ºssen die Ch√∂re in ein Format codiert werden, das mithilfe eines wiederkehrenden neuronalen Netzwerks leicht verarbeitet werden kann.  Das erforderliche Format ist eine <i>Folge von Token</i> .  F√ºr das BachBot-Projekt wurde die Codierung auf der Ebene der Noten (jedes Token repr√§sentiert eine Note) anstelle der Ebene der Akkorde (jedes Token repr√§sentiert einen Akkord) ausgew√§hlt.  Diese L√∂sung reduzierte die Gr√∂√üe des W√∂rterbuchs von 128 <sup>4</sup> m√∂glichen Akkorden auf 128 m√∂gliche Noten, wodurch die Arbeitseffizienz gesteigert werden konnte. <br><br>  F√ºr das BachBot-Projekt wurde ein urspr√ºngliches Kodierungsschema f√ºr Musikkompositionen erstellt.  Der Choral ist in Zeitschritte unterteilt, die Sechzehntelnoten entsprechen.  Diese Schritte werden als Frames bezeichnet.  Jeder Frame enth√§lt eine Folge von Tupeln, die den Wert der Tonh√∂he einer Note im Format einer digitalen Musikinstrument-Schnittstelle (MIDI) und ein Zeichen f√ºr die Bindung dieser Note an eine vorherige Note derselben H√∂he (Note, Zeichen f√ºr Bindung) darstellen.  Die Noten innerhalb des Rahmens sind in absteigender Reihenfolge der H√∂he nummeriert (Sopran ‚Üí Alt ‚Üí Tenor ‚Üí Bass).  Jeder Rahmen kann auch einen Rahmen haben, der das Ende einer Phrase markiert;  Fermaten werden durch ein Punktsymbol (.) √úber der Note dargestellt.  Die Symbole <i>START</i> und <i>END</i> werden am Anfang und am Ende jedes Chors hinzugef√ºgt.  Diese Symbole bewirken eine Initialisierung des Modells und erm√∂glichen es dem Benutzer, zu bestimmen, wann die Komposition endet. <br><br> <code>START <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (.) <br> (57, False) <br> (52, False) <br> (48, False) <br> (45, False) <br> ||| <br> (.) <br> (57, True) <br> (52, True) <br> (48, True) <br> (45, True) <br> ||| <br> END</code> <br>  <i>Ein Beispiel f√ºr die Codierung von zwei Akkorden.</i>  <i>Jeder Akkord dauert einen achten Taktschlag, der zweite Akkord wird von einer Farm begleitet.</i>  <i>Die Sequenz "|||"</i>  <i>markiert das Ende des Rahmens</i> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">encode_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score, keep_fermatas=True, parts_to_mask=[])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Encodes a music21 score into a List of chords, where each chord is represented with a (Fermata :: Bool, List[(Note :: Integer, Tie :: Bool)]). If `keep_fermatas` is True, all `has_fermata`s will be False. All tokens from parts in `parts_to_mask` will have output tokens `BLANK_MASK_TXT`. Time is discretized such that each crotchet occupies `FRAMES_PER_CROTCHET` frames. """</span></span> encoded_score = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chord <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (score .quantize((FRAMES_PER_CROTCHET,)) .chordify(addPartIdAsGroup=bool(parts_to_mask)) .flat .notesAndRests): <span class="hljs-comment"><span class="hljs-comment"># aggregate parts, remove markup # expand chord/rest st constant timestep between frames if chord.isRest: encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET)) * [[]]) else: has_fermata = (keep_fermatas) and any(map(lambda e: e.isClassOrSubclass(('Fermata',)), chord.expressions)) encoded_chord = [] # </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> sorts Soprano, Bass, Alto, Tenor without breaking ties # c = chord.sortAscending() # sorted_notes = [c[-1], c[0]] + c[1:-1] # for note in sorted_notes: for note in chord: if parts_to_mask and note.pitch.groups[0] in parts_to_mask: encoded_chord.append(BLANK_MASK_TXT) else: has_tie = note.tie is not None and note.tie.type != 'start' encoded_chord.append((note.pitch.midi, has_tie)) encoded_score.append((has_fermata, encoded_chord)) # repeat pitches to expand chord into multiple frames # all repeated frames when expanding a chord should be tied encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET) - 1) * [ (has_fermata, map(lambda note: BLANK_MASK_TXT if note == BLANK_MASK_TXT else (note[0], True), encoded_chord)) ]) return encoded_score</span></span></code> </pre> <br>  <i>Code, der zum Codieren der music21-Tonalit√§t mithilfe eines speziellen Codierungsschemas verwendet wird</i> <br><br><h2>  <font color="#0071c5">Modellaufgabe</font> </h2><br>  Im vorherigen Teil wurde eine Erkl√§rung gegeben, die zeigt, dass die Aufgabe der automatischen Komposition auf die Aufgabe der Vorhersage einer Sequenz reduziert werden kann.  Insbesondere kann ein Modell die wahrscheinlichste n√§chste Note basierend auf vorherigen Noten vorhersagen.  Um diese Art von Problem zu l√∂sen, ist ein neuronales Netzwerk mit langem Kurzzeitged√§chtnis (LSTM) am besten geeignet.  Formal sollte das Modell P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), die Wahrscheinlichkeitsverteilung f√ºr die n√§chstm√∂glichen Noten (x <sub>t + 1</sub> ) basierend auf dem aktuellen Token (x <sub>t</sub> ) und dem vorherigen verborgenen Zustand (h <sub>t-1</sub> ) vorhersagen. .  Interessanterweise wird dieselbe Operation von Sprachmodellen ausgef√ºhrt, die auf wiederkehrenden neuronalen Netzen basieren. <br><br>  Im Kompositionsmodus wird das Modell mit dem <i>START-</i> Token initialisiert. Anschlie√üend wird das <i>n√§chstwahrscheinlichste</i> Token ausgew√§hlt, dem Sie folgen m√∂chten.  Danach w√§hlt das Modell weiterhin das n√§chstwahrscheinlichste Token unter Verwendung der vorherigen Notiz und des vorherigen ausgeblendeten Status aus, bis ein END-Token generiert wird.  Das System enth√§lt Temperaturelemente, die ein gewisses Ma√ü an Zuf√§lligkeit hinzuf√ºgen, um zu verhindern, dass BachBot immer wieder dasselbe St√ºck komponiert. <br><br><h3>  <font color="#0071c5">Verlustfunktion</font> </h3><br>  Beim Training eines Vorhersagemodells muss normalerweise eine Funktion minimiert werden (sogenannte Verlustfunktion).  Diese Funktion beschreibt den Unterschied zwischen der Modellvorhersage und der Grundwahrheitseigenschaft.  BachBot minimiert den Verlust der Kreuzentropie zwischen der vorhergesagten Verteilung (x <sub>t + 1</sub> ) und der tats√§chlichen Verteilung der Zielfunktion.  Die Verwendung der Kreuzentropie als Verlustfunktion ist ein guter Ausgangspunkt f√ºr eine Vielzahl von Aufgaben. In einigen F√§llen k√∂nnen Sie jedoch auch Ihre eigene Verlustfunktion verwenden.  Ein weiterer akzeptabler Ansatz besteht darin, verschiedene Verlustfunktionen zu verwenden und ein Modell anzuwenden, das den tats√§chlichen Verlust w√§hrend der √úberpr√ºfung minimiert. <br><br><h3>  <font color="#0071c5">Schulung / Pr√ºfung</font> </h3><br>  Beim Training eines rekursiven neuronalen Netzwerks verwendete BachBot eine Token-Korrektur mit dem Wert x <sub>t + 1,</sub> anstatt eine Modellvorhersage anzuwenden.  Dieser als obligatorisches Lernen bezeichnete Prozess wird verwendet, um die Konvergenz sicherzustellen, da Modellvorhersagen zu Beginn des Trainings nat√ºrlich zu schlechten Ergebnissen f√ºhren.  Im Gegensatz dazu sollte w√§hrend der Validierung und Zusammensetzung die Vorhersage des Modells x <sub>t + 1</sub> als Eingabe f√ºr die n√§chste Vorhersage wiederverwendet werden. <br><br><h3>  <font color="#0071c5">Andere √úberlegungen</font> </h3><br>  Um die Effizienz in diesem Modell zu erh√∂hen, wurden die folgenden praktischen Methoden verwendet, die f√ºr neuronale LSTM-Netze √ºblich sind: normalisierte Gradientenabschneidung, Eliminierungsmethode, Paketnormalisierung und BPTT-Methode (Truncated Time Error Back Propagation). <br><br>  <i>Das normalisierte Gradientenk√ºrzungsverfahren</i> beseitigt das Problem des unkontrollierten Wachstums des Gradientenwerts (die Umkehrung des Problems des verschwindenden Gradienten, das unter Verwendung der Architektur von LSTM-Speicherzellen gel√∂st wurde).  Mit dieser Technik werden Gradientenwerte, die einen bestimmten Schwellenwert √ºberschreiten, abgeschnitten oder skaliert. <br><br>  <i>Die Ausschlussmethode</i> ist eine Technik, bei der einige <i>zuf√§llig ausgew√§hlte</i> Neuronen w√§hrend des Netzwerktrainings getrennt (ausgeschlossen) werden.  Dies vermeidet eine √úberanpassung und verbessert die Qualit√§t der Generalisierung.  Das Problem der √úberanpassung tritt auf, wenn das Modell f√ºr den Trainingsdatensatz optimiert wird und in geringerem Ma√üe f√ºr Proben au√üerhalb dieses Satzes anwendbar ist.  Die Ausschlussmethode verschlechtert h√§ufig den Verlust w√§hrend des Trainings, verbessert ihn jedoch in der √úberpr√ºfungsphase (mehr dazu weiter unten). <br><br>  Die Berechnung des Gradienten in einem wiederkehrenden neuronalen Netzwerk f√ºr eine Folge von 1000 Elementen entspricht in ihren Kosten den Vorw√§rts- und R√ºckw√§rtspassagen im neuronalen Netzwerk mit direkter Verteilung von 1000 Schichten.  <i>Die</i> BPTT-Methode ( <i>Truncated Error Back Propagation</i> ) √ºber die Zeit wird verwendet, um die Kosten f√ºr die Aktualisierung von Parametern w√§hrend des Trainings zu senken.  Dies bedeutet, dass Fehler nur w√§hrend einer festen Anzahl von Zeitschritten weitergegeben werden, die vom aktuellen Moment zur√ºckgez√§hlt werden.  Bitte beachten Sie, dass mit der BPTT-Methode weiterhin langfristige Lernabh√§ngigkeiten m√∂glich sind, da latente Zust√§nde bereits in vielen fr√ºheren Zeitschritten aufgedeckt wurden. <br><br><h3>  <font color="#0071c5">Parameter</font> </h3><br>  Das Folgende ist eine Liste relevanter Parameter f√ºr Modelle wiederkehrender neuronaler Netze / neuronaler Netze mit langem Kurzzeitged√§chtnis: <br><ul><li>  <i>Die Anzahl der Schichten</i> .  Das Erh√∂hen dieses Parameters kann die Effizienz des Modells erh√∂hen, das Trainieren dauert jedoch l√§nger.  Au√üerdem k√∂nnen zu viele Schichten zu einer √úberanpassung f√ºhren. </li><li>  <i>Die Dimension des latenten Zustands</i> .  Das Erh√∂hen dieses Parameters kann die Komplexit√§t des Modells erh√∂hen, dies kann jedoch zu einer √úberanpassung f√ºhren. </li><li>  <i>Dimension von Vektorvergleichen</i> </li><li>  <i>Die Sequenzl√§nge</i> / Anzahl der Frames vor dem Abschneiden der R√ºckausbreitung des Fehlers √ºber die Zeit. </li><li>  <i>Wahrscheinlichkeit des Ausschlusses von Neuronen</i> .  Die Wahrscheinlichkeit, mit der ein Neuron w√§hrend jedes Aktualisierungszyklus aus dem Netzwerk ausgeschlossen wird. </li></ul><br>  Die Methode zur Auswahl des optimalen Parametersatzes wird sp√§ter in diesem Artikel erl√§utert. <br><br><h2>  <font color="#0071c5">Implementierung, Schulung und Test</font> </h2><br><h3>  <font color="#0071c5">Plattformauswahl</font> </h3><br>  Derzeit gibt es viele Plattformen, auf denen Sie Modelle f√ºr maschinelles Lernen in verschiedenen Programmiersprachen (einschlie√ülich JavaScript!) Implementieren k√∂nnen.  Beliebte Plattformen sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scikit-Learn</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Torch</a> . <br><br>  Die Torch-Bibliothek wurde als Plattform f√ºr das BachBot-Projekt ausgew√§hlt.  Zun√§chst wurde die TensorFlow-Bibliothek ausprobiert, zu diesem Zeitpunkt wurden jedoch umfangreiche wiederkehrende neuronale Netze verwendet, was zu einem √úberlauf des Arbeitsspeichers der GPU f√ºhrte.  Torch ist eine wissenschaftliche Computerplattform, die auf der schnellen Programmiersprache LuaJIT * basiert.  Die Torch-Plattform enth√§lt hervorragende Bibliotheken f√ºr die Arbeit mit neuronalen Netzen und die Optimierung. <br><br><h3>  <font color="#0071c5">Modellimplementierung und Schulung</font> </h3><br>  Die Implementierung h√§ngt nat√ºrlich von der Sprache und Plattform ab, f√ºr die Sie sich entscheiden.  Um zu erfahren, wie BachBot mithilfe von Torch neuronale Netze mit langem Kurzzeitged√§chtnis implementiert, lesen Sie die Skripte, mit denen BachBot-Parameter trainiert und eingestellt werden.  Diese Skripte sind auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Feynman Lyang GitHub-</a> Website verf√ºgbar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">.</a> <br><br>  Ein guter Ausgangspunkt f√ºr die Navigation im Repository ist das <a href="">Skript 1-train.zsh</a> .  Damit finden Sie den Pfad zur Datei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bachbot.py</a> . <br><br>  Genauer gesagt ist das Hauptskript zum Festlegen von Modellparametern die Datei <a href="">LSTM.lua</a> .  Das Skript zum Trainieren des Modells ist die Datei <a href="">train.lua</a> . <br><br><h3>  <font color="#0071c5">Hyperparameter-Optimierung</font> </h3><br>  Um nach den optimalen Werten der Hyperparameter zu suchen, wurde die Rastersuchmethode unter Verwendung des folgenden Parameterrasters verwendet. <br><br><img src="https://habrastorage.org/webt/91/7p/_3/917p_3g7mtewimqlykgaskxn8y0.png"><br>  <i>Raster der von BachBot bei der Rastersuche verwendeten Parameter</i> <br><br>  Eine Rastersuche ist eine vollst√§ndige Suche aller m√∂glichen Kombinationen von Parametern.  Andere vorgeschlagene Methoden zur Optimierung von Hyperparametern sind die Zufallssuche und die Bayes'sche Optimierung. <br><br>  Der optimale Satz von Hyperparametern, der als Ergebnis einer Rastersuche erkannt wird, ist wie folgt: Anzahl der Schichten = 3, Dimension des verborgenen Zustands = 256, Dimension der Vektorvergleiche = 32, Sequenzl√§nge = 128, Wahrscheinlichkeit der Eliminierung von Neuronen = 0,3. <br><br>  Dieses Modell erreichte w√§hrend des Trainings einen Kreuzentropieverlust von 0,324 und in der Verifizierungsphase von 0,477.  Das Diagramm der Lernkurve zeigt, dass der Lernprozess nach 30 Iterationen konvergiert (~ 28,5 Minuten bei Verwendung einer einzelnen GPU). <br><br>  Verlustdiagramme w√§hrend des Trainings und w√§hrend der Verifizierungsphase k√∂nnen auch die Wirkung jedes Hyperparameters veranschaulichen.  Von besonderem Interesse f√ºr uns ist die Wahrscheinlichkeit, Neuronen zu eliminieren: <br><br><img src="https://habrastorage.org/webt/ad/zd/_s/adzd_s3hxek23oyz8dqg_d1pkys.png"><br>  <i>Lernkurven f√ºr verschiedene Einstellungen der Ausschlussmethode</i> <br><br>  In der Figur ist zu sehen, dass das Eliminierungsverfahren das Auftreten einer √úberanpassung wirklich vermeidet.  Obwohl mit einer Ausschlusswahrscheinlichkeit von 0,0 der Verlust w√§hrend des Trainings minimal ist, ist der Verlust in der √úberpr√ºfungsphase maximal.  Gro√üe Wahrscheinlichkeitswerte f√ºhren zu einer Zunahme der Verluste w√§hrend des Trainings und zu einer Abnahme der Verluste in der Verifizierungsphase.  Der Mindestwert des Verlusts w√§hrend der Verifizierungsphase bei der Arbeit mit BachBot wurde mit einer Ausnahmewahrscheinlichkeit von 0,3 festgelegt. <br><br><h3>  <font color="#0071c5">Alternative Bewertungsmethoden (optional)</font> </h3><br>  Bei einigen Modellen - insbesondere bei kreativen Anwendungen wie dem Komponieren von Musik - ist der Verlust m√∂glicherweise kein geeignetes Ma√ü f√ºr den Erfolg des Systems.  Stattdessen kann die subjektive menschliche Wahrnehmung das beste Kriterium sein. <br><br>  Ziel des BachBot-Projekts ist es, automatisch Musik zu komponieren, die nicht von Bachs eigenen Kompositionen zu unterscheiden ist.  Um den Erfolg der Ergebnisse zu bewerten, wurde eine Umfrage unter Benutzern im Internet durchgef√ºhrt.  Die Umfrage erhielt die Form eines Wettbewerbs, bei dem die Benutzer gefragt wurden, welche Werke zum BachBot-Projekt und welche zu Bach geh√∂ren. <br><br>  Die Umfrageergebnisse zeigten, dass die Umfrageteilnehmer (759 Personen mit unterschiedlichem Ausbildungsniveau) in nur 59 Prozent der F√§lle zwischen zwei Stichproben genau unterscheiden konnten.  Dies ist nur 9 Prozent h√∂her als das Ergebnis zuf√§lliger Vermutungen!  Probieren Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BachBot-Umfrage</a> selbst aus! <br><br><h2>  <font color="#0071c5">Anpassung des Modells an die Harmonisierung</font> </h2><br>  Jetzt kann BachBot P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ) berechnen, die Wahrscheinlichkeitsverteilung f√ºr die n√§chstm√∂glichen Noten basierend auf der aktuellen Note und dem vorherigen versteckten Zustand.  Dieses sequentielle Vorhersagemodell kann anschlie√üend angepasst werden, um die Melodie zu harmonisieren.  Ein solches angepasstes Modell ist erforderlich, um die mit Hilfe von Emotionen modulierte Melodie im Rahmen eines Musikprojekts mit einer Diashow zu harmonisieren. <br><br>  Wenn Sie mit der Modellharmonisierung arbeiten, wird eine vorgegebene Melodie bereitgestellt (normalerweise ist dies ein Sopranpart), und danach sollte das Modell Musik f√ºr die verbleibenden Teile komponieren.  Um diese Aufgabe zu erf√ºllen, wird eine gierige "Best-First" -Suche mit der Einschr√§nkung verwendet, dass die Melodienoten festgelegt sind.  Gierige Algorithmen beinhalten Entscheidungen, die aus lokaler Sicht optimal sind.  Im Folgenden finden Sie eine einfache Strategie zur Harmonisierung: <br><blockquote>  Angenommen, x <sub>t</sub> sind Token in der vorgeschlagenen Harmonisierung.  Wenn zum Zeitpunkt t die Note der Melodie entspricht, ist x <sub>t</sub> gleich der gegebenen Note.  Andernfalls ist x <sub>t</sub> gem√§√ü den Vorhersagen des Modells gleich der <i>wahrscheinlichsten</i> n√§chsten Note.  Den Code f√ºr diese Modellanpassung finden Sie auf der Feynman Lyang GitHub-Website: <a href="">HarmModel.lua</a> , <a href="">harmonize.lua</a> . </blockquote><br>  Das Folgende ist ein Beispiel f√ºr die Harmonisierung des Schlaflieds Twinkle, Twinkle, Little Star mit BachBot unter Verwendung der obigen Strategie. <br><br><img src="https://habrastorage.org/webt/wl/mu/kf/wlmukfjpuyeswxwfr15lmkgfvrw.jpeg"><br>  <i>Harmonisierung des Schlaflieds von Twinkle, Twinkle, Little Star mit BachBot (im Sopranpart).</i>  <i>Teile von Bratsche, Tenor und Bass wurden ebenfalls mit BachBot gef√ºllt</i> <br><br>  In diesem Beispiel wird die Melodie des Wiegenlieds Twinkle, Twinkle, Little Star im Sopranpart gegeben.  Danach wurden die Teile Viola, Tenor und Bass mit BachBot nach einer Harmonisierungsstrategie gef√ºllt.  Und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">so klingt es</a> . <br><br>  Trotz der Tatsache, dass BachBot bei der Ausf√ºhrung dieser Aufgabe gute Leistungen erbracht hat, sind mit diesem Modell bestimmte Einschr√§nkungen verbunden.  Genauer gesagt, der Algorithmus <i>blickt nicht</i> in die Melodie hinein und verwendet nur die aktuelle Note der Melodie und den vergangenen Kontext, um nachfolgende Noten zu erzeugen.  Wenn Menschen eine Melodie harmonisieren, k√∂nnen sie die gesamte Melodie abdecken, was die Ableitung geeigneter Harmonisierungen vereinfacht.  Die Tatsache, dass dieses Modell dazu nicht in der Lage ist, kann zu <i>√úberraschungen</i> f√ºhren, da die Verwendung nachfolgender Informationen, die Fehler verursachen, eingeschr√§nkt ist.  Um dieses Problem zu l√∂sen, kann die sogenannte <i>Strahlensuche</i> verwendet werden. <br><br>  Bei Verwendung der Strahlensuche werden verschiedene Bewegungslinien √ºberpr√ºft.  Anstatt nur eine, die wahrscheinlichste Note, die derzeit ausgef√ºhrt wird, zu verwenden, k√∂nnen beispielsweise vier oder f√ºnf wahrscheinlichste Noten ber√ºcksichtigt werden, wonach der Algorithmus seine Arbeit mit jeder dieser Noten fortsetzt.  Durch Untersuchen der verschiedenen Optionen kann das Modell <i>Fehler beheben</i> .  Die Strahlensuche wird h√§ufig in Anwendungen zur Verarbeitung nat√ºrlicher Sprache verwendet, um S√§tze zu erstellen. <br><br>  Mit Hilfe von Emotionen modulierte Melodien k√∂nnen nun durch ein solches Harmonisierungsmodell geleitet werden, um sie zu vervollst√§ndigen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de423727/">https://habr.com/ru/post/de423727/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de423713/index.html">"Made in Russia" - WBASIC-Programmiersprache f√ºr die Entwicklung serverseitiger Webanwendungen</a></li>
<li><a href="../de423719/index.html">Von Erlang / Elixir nach Java und umgekehrt. Abenteuer f√ºr 20 Minuten</a></li>
<li><a href="../de423721/index.html">"Du bist ein h√§sslicher Schwachkopf": Algorithmen und Problemumgehungen zur Erkennung feindlicher Sprachen</a></li>
<li><a href="../de423723/index.html">(Nicht) kommerzielles Projekt: Redis √§ndern Lizenzen, bleiben aber Open Source</a></li>
<li><a href="../de423725/index.html">Entwurfsprozesse im ISP-System. Wie man eine Ideologie einf√ºhrt, eine Abteilung aufbaut und am Leben bleibt</a></li>
<li><a href="../de423729/index.html">5 Millionen Konten in ProtonMail-Krypto-Mail registriert</a></li>
<li><a href="../de423731/index.html">Character Computing mit Python. Teil 1. Die Grundlagen</a></li>
<li><a href="../de423733/index.html">Die Auswirkungen der DSGVO auf russische Betreiber personenbezogener Daten</a></li>
<li><a href="../de423735/index.html">Auf der Internet of Things-Konferenz findet die Battle of Startups statt. Wir laden Teilnehmer ein</a></li>
<li><a href="../de423737/index.html">Strikte Optimierung der Arbeit mit Marktdaten f√ºr den Austausch von Kryptow√§hrungen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍🎨 🕳️ 💯 Renderização estéreo de baixo orçamento em poucas linhas de código (estereograma, anaglyph, estereoscópio) 👨🏼‍🎤 👨🏼‍🎨 ◀️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chegou outro fim de semana, o que significa que estou escrevendo mais algumas dezenas de linhas de código e fazendo uma ilustração ou duas. Nos artigo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Renderização estéreo de baixo orçamento em poucas linhas de código (estereograma, anaglyph, estereoscópio)</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441014/">  Chegou outro fim de semana, o que significa que estou escrevendo mais algumas dezenas de linhas de código e fazendo uma ilustração ou duas.  Nos artigos anteriores, expliquei como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fazer o traçado de raios</a> e até <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">explodir coisas</a> .  Isso pode surpreendê-lo, mas a computação gráfica é bastante fácil: mesmo algumas centenas de linhas de C ++ simples podem produzir imagens muito interessantes. <br><br>  O tópico de hoje é a visão binocular, e nem vamos quebrar a barreira das 100 linhas.  Como podemos desenhar cenas em 3D, seria tolice ignorar pares estéreo, então hoje faremos algo assim: <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br><br>  A pura insanidade dos criadores do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Magic Carpet</a> ainda me surpreende.  Para quem não sabe, este jogo permitiu que você fizesse uma renderização em 3D no modo anaglifo e estereograma <b>no menu principal de configurações</b> !  Isso foi selvagem para mim. <br><br><h1>  Parallax </h1><br>  Então, vamos começar.  Para começar, o que faz com que o nosso aparelho de visão perceba profundidade nos objetos?  Existe um termo inteligente "paralaxe".  Vamos nos concentrar na tela.  Tudo o que está dentro do plano da tela é registrado pelo nosso cérebro como sendo um objeto.  Mas se uma mosca voa entre nossos olhos e a tela, o cérebro a percebe como dois objetos.  A aranha atrás da tela também será dobrada. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br>  Nosso cérebro é muito eficiente na análise de imagens ligeiramente diferentes.  Ele usa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">disparidade binocular</a> para obter informações sobre a profundidade de imagens 2D provenientes da retina usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estereopsia</a> .  Bem, estrague as grandes palavras e vamos desenhar imagens! <br><br>  Vamos imaginar que nosso monitor é uma janela para o mundo virtual :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br>  Nossa tarefa é desenhar duas imagens do que vemos através dessa “janela”, uma para cada olho.  Na foto acima, o “sanduíche” vermelho-azul.  Por enquanto, vamos esquecer como entregar essas imagens ao nosso cérebro. Nesse estágio, precisamos salvar apenas dois arquivos separados.  Em particular, quero saber como obter essas imagens usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">meu minúsculo traçador de raios</a> . <br><br>  Vamos assumir que o ângulo não muda e é o vetor (0,0, -1).  Vamos supor que podemos mover a câmera para a área entre os olhos, mas e daí?  Um pequeno detalhe: a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vista da</a> janela através da nossa “janela” é assimétrica.  Mas nosso traçador de raios só pode render um frustum simétrico: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br>  E o que fazemos agora?  Cheat :) <br><br>  Podemos renderizar imagens um pouco mais amplas do que precisamos e depois cortar as partes extras: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1>  Anaglyph </h1><br>  Acho que cobrimos o mecanismo básico de renderização e agora abordamos a questão de entregar a imagem ao nosso cérebro.  A maneira mais simples é esse tipo de óculos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br>  Fazemos duas renderizações em escala de cinza e atribuímos imagens esquerda e direita aos canais vermelho e azul, respectivamente.  Isto é o que obtemos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br>  O vidro vermelho corta um canal, enquanto o vidro azul corta o outro.  Combinados, os olhos têm uma imagem diferente e a percebemos em 3D.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui estão as modificações</a> no commit principal do tinyraytracer.  As alterações incluem o posicionamento da câmera para montagem de olhos e canais. <br><br>  O Anaglyph é uma das formas mais antigas de assistir imagens estéreo (geradas por computador).  Tem muitas desvantagens, por exemplo, transmissão de cores ruins.  Mas, por outro lado, é muito fácil criar em casa. <br><br>  Se você não possui um compilador no seu computador, não há problema.  Se você possui uma conta no guithub, pode visualizar, editar e executar o código (sic!) Em um clique no seu navegador. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://gitpod.io/&amp;usg=ALkJrhinC0x58w74Qwk2jDecCU7aAsAExg#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Abrir no gitpod"></a> <br><br>  Quando você abre esse link, o gitpod cria uma máquina virtual para você, inicia o VS Code e abre um terminal na máquina remota.  No histórico de comandos (clique no console e pressione a tecla para cima), existe um conjunto completo de comandos que permite compilar o código, iniciá-lo e abrir a imagem resultante. <br><br><h1>  Stereoscope </h1><br>  Com os smartphones se tornando populares, lembramos da invenção do século 19 chamada estereoscópio.  Há alguns anos, o Google sugeriu o uso de duas lentes (que, infelizmente, são difíceis de criar em casa, você precisa comprá-lo), um pouco de papelão (disponível em qualquer lugar) e um smartphone (no seu bolso) para criar credibilidade Óculos VR. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br>  Eles são abundantes no AliExpress e custam US $ 3 por par.  Comparado à renderização de anáglifo, não temos muito o que fazer: basta tirar duas fotos e colocá-las lado a lado.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui está o commit</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br>  Estritamente falando, dependendo da lente, talvez seja necessário <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">corrigir a distorção da lente</a> , mas não me incomodei com isso, pois ela parecia bem, independentemente.  Mas se realmente precisamos aplicar a pré-distorção do barril que compensa a distorção natural da lente, é assim que fica para o meu smartphone e meus óculos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br>  Aqui está o link gitpod: <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://gitpod.io/&amp;usg=ALkJrhinC0x58w74Qwk2jDecCU7aAsAExg#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Abrir no gitpod"></a> <br><br><h1>  Autostereograms </h1><br>  E o que fazemos se não quisermos usar nenhum equipamento extra?  Depois, há apenas uma opção - apertar os olhos.  A imagem anterior, honestamente, é suficiente para a visualização estéreo, basta apertar os olhos (cruzando os olhos ou colocando-os na parede).  Aqui está um esquema que nos diz como assistir a ilustração anterior.  Duas linhas vermelhas mostram as imagens obtidas pela retina esquerda, duas azuis - a retina direita. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br>  Se focarmos na tela, quatro imagens serão combinadas em duas.  Se cruzarmos os olhos ou focarmos em um objeto distante, é possível alimentar "três" imagens do cérebro.  As imagens centrais se sobrepõem, o que cria o efeito estéreo. <br><br>  Pessoas diferentes usam métodos diferentes: por exemplo, não consigo cruzar os olhos, mas os muro facilmente.  É importante que o autostereograma criado para um determinado método seja visto apenas com esse método, ou então obtemos um mapa de profundidade invertido (lembra-se de paralaxe positivo e negativo?).  O problema é que é difícil cruzar os olhos muito, por isso só funciona em imagens pequenas.  Mas e se quisermos os maiores?  Vamos sacrificar totalmente as cores e focar apenas na parte da percepção de profundidade.  Aqui está a imagem que esperamos obter até o final do artigo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br>  Este é um autostereograma de olhos nas paredes.  Para aqueles que preferem o outro método, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui está uma imagem para isso</a> .  Se você não está acostumado a autostereogramas, tente diferentes condições: tela cheia, imagem menor, brilho, escuridão.  Nosso objetivo é cobrir os olhos para que as duas faixas verticais próximas se sobreponham.  O mais fácil é focar na parte superior esquerda da imagem, pois é simples.  Pessoalmente, abro a imagem em tela cheia.  Não se esqueça de remover o cursor do mouse também! <br><br>  Não pare com um efeito 3D incompleto.  Se você vê vagamente formas arredondadas e o efeito 3D é fraco, a ilusão é incompleta.  As esferas devem “pular” para fora da tela em direção ao espectador, o efeito deve ser estável e sustentável.  A estereopsia tem uma gistese: uma vez que você obtém uma imagem estável, fica mais detalhada quanto mais tempo a observa.  Quanto mais os olhos estão da tela, maior o efeito de percepção de profundidade. <br><br>  Este estereograma foi desenhado usando um método sugerido há 25 anos neste artigo: " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Exibindo imagens 3D: algoritmos para estereogramas de pontos aleatórios de imagem única</a> ". <br><br><h3>  Vamos começar </h3><br>  O ponto de partida para renderizar autostereogramas é o mapa de profundidade (já que abandonamos as cores).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Esta confirmação</a> desenha a seguinte imagem: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br>  Os planos mais próximos e futuros definem nossa profundidade: o ponto mais distante do meu mapa tem a profundidade de 0, enquanto o ponto mais próximo tem a profundidade de 1. <br><br><h3>  Os princípios fundamentais </h3><br>  Digamos que nossos olhos estejam a uma distância d da tela.  Colocamos nosso plano distante (imaginário) (z = 0) na mesma distância "atrás" da tela.  Escolhemos a variável µ, que determina a localização do plano próximo (z = 1), que estará à distância µd do plano distante.  Para o meu código, escolhi μ = ⅓.  No geral, todo o nosso "mundo" vive à distância de d-μd em d atrás da tela.  Digamos que sabemos a distância entre os olhos (em pixels, eu escolhi 400 pixels): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br>  Se observarmos o ponto vermelho, dois pixels marcados em verde devem ter a mesma cor no estereograma.  Como calcular a distância entre eles?  Fácil  Se o ponto projetado atual tiver a profundidade de z, a paralaxe dividida pela distância entre os olhos será igual à fração entre as profundidades correspondentes: p / e = (d-dμz) / (2d-dμz).  A propósito, observe que d é simplificado e não aparece em nenhum outro lugar!  Então p / e = (1-μz) / (2-μz), significando que a paralaxe é igual a p = e * (1-μz) / (2-μz) pixels. <br><br>  A principal idéia por trás do autostereograma é: percorremos todo o mapa de profundidade, para cada valor de profundidade, determinamos quais pixels terão a mesma cor e o colocamos em nosso sistema de restrições.  Começamos a partir da imagem aleatória e tentamos satisfazer todas as restrições que definimos anteriormente. <br><br><h3>  Preparando a imagem de origem </h3><br>  Aqui preparamos a imagem que mais tarde será restringida por restrições de paralaxe.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui está o commit</a> , e ele desenha o seguinte: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br>  Observe que as cores são na maioria aleatórias, além do canal vermelho onde eu coloquei rand () * sin para criar um padrão periódico.  As faixas estão separadas por 200 pixels, que é (dado μ = 1/3 e e = 400) o valor máximo de paralaxe em nosso mundo (o plano distante).  O padrão não é tecnicamente necessário, mas ajudará a focar os olhos. <br><br><h3>  Renderização automática </h3><br>  Na verdade, o código completo que desenha o autostereograma se parece com isso: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui está o commit</a> , a função int paralaxe (const float z) nos fornece distância entre pixels da mesma cor para o valor atual da profundidade.  Renderizamos o estereograma linha por linha, uma vez que as linhas são independentes uma da outra (não temos paralaxe vertical).  O loop principal simplesmente itera através de cada linha;  cada vez que começa com um conjunto ilimitado de pixels e, para cada pixel, adiciona uma restrição de igualdade.  No final, ele nos fornece um certo número de agrupamentos de pixels da mesma cor.  Por exemplo, pixels com índices esquerdo e direito devem acabar idênticos. <br><br>  Como armazenar esse conjunto de restrições?  A maneira mais simples é a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estrutura de dados de localização de união</a> .  Não vou entrar em detalhes, basta ir à Wikipedia, são literalmente três linhas de código.  O ponto principal é que, para cada cluster, existe um determinado pixel "raiz" responsável pelo cluster.  O pixel raiz mantém sua cor inicial e todos os outros pixels do cluster devem ser atualizados: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://gitpod.io/&amp;usg=ALkJrhinC0x58w74Qwk2jDecCU7aAsAExg#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Abrir no gitpod"></a> <br><br><h1>  Conclusão </h1><br>  É isso mesmo.  Vinte linhas de código e nosso autostereograma está pronto para você quebrar os olhos.  A propósito, se nos esforçarmos o suficiente, é possível transmitir informações sobre cores. <br><br>  Não cobri outros sistemas estereoscópicos, como os sistemas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3D polarizados</a> , pois são muito mais caros de fabricar.  Se eu perdi alguma coisa, fique à vontade para me corrigir! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt441014/">https://habr.com/ru/post/pt441014/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt441004/index.html">Splunk deixa a Rússia (completamente)</a></li>
<li><a href="../pt441006/index.html">Uma visão geral dos métodos de segmentação de imagens na biblioteca scikit-image</a></li>
<li><a href="../pt441008/index.html">MQ de coelho no sistema de processamento de residentes</a></li>
<li><a href="../pt441010/index.html">Desça na terra mortal ...</a></li>
<li><a href="../pt441012/index.html">Fatos interessantes sobre a história do programa lunar chinês e a missão espacial Chang'e-4</a></li>
<li><a href="../pt441018/index.html">Ferramentas de desenvolvimento e especificação do programa NanoCAD Mechanics</a></li>
<li><a href="../pt441020/index.html">Como o VTB chegou a um único conhecimento</a></li>
<li><a href="../pt441022/index.html">Erros comuns de passageiros de ferrovias e companhias aéreas</a></li>
<li><a href="../pt441024/index.html">Escrevemos um rastreador para um ou dois 1.0</a></li>
<li><a href="../pt441026/index.html">VMware NSX para o menor. Parte 2. Configurando Firewall e NAT</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüé® üï≥Ô∏è üíØ Renderiza√ß√£o est√©reo de baixo or√ßamento em poucas linhas de c√≥digo (estereograma, anaglyph, estereosc√≥pio) üë®üèº‚Äçüé§ üë®üèº‚Äçüé® ‚óÄÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chegou outro fim de semana, o que significa que estou escrevendo mais algumas dezenas de linhas de c√≥digo e fazendo uma ilustra√ß√£o ou duas. Nos artigo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Renderiza√ß√£o est√©reo de baixo or√ßamento em poucas linhas de c√≥digo (estereograma, anaglyph, estereosc√≥pio)</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441014/">  Chegou outro fim de semana, o que significa que estou escrevendo mais algumas dezenas de linhas de c√≥digo e fazendo uma ilustra√ß√£o ou duas.  Nos artigos anteriores, expliquei como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fazer o tra√ßado de raios</a> e at√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">explodir coisas</a> .  Isso pode surpreend√™-lo, mas a computa√ß√£o gr√°fica √© bastante f√°cil: mesmo algumas centenas de linhas de C ++ simples podem produzir imagens muito interessantes. <br><br>  O t√≥pico de hoje √© a vis√£o binocular, e nem vamos quebrar a barreira das 100 linhas.  Como podemos desenhar cenas em 3D, seria tolice ignorar pares est√©reo, ent√£o hoje faremos algo assim: <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br><br>  A pura insanidade dos criadores do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Magic Carpet</a> ainda me surpreende.  Para quem n√£o sabe, este jogo permitiu que voc√™ fizesse uma renderiza√ß√£o em 3D no modo anaglifo e estereograma <b>no menu principal de configura√ß√µes</b> !  Isso foi selvagem para mim. <br><br><h1>  Parallax </h1><br>  Ent√£o, vamos come√ßar.  Para come√ßar, o que faz com que o nosso aparelho de vis√£o perceba profundidade nos objetos?  Existe um termo inteligente "paralaxe".  Vamos nos concentrar na tela.  Tudo o que est√° dentro do plano da tela √© registrado pelo nosso c√©rebro como sendo um objeto.  Mas se uma mosca voa entre nossos olhos e a tela, o c√©rebro a percebe como dois objetos.  A aranha atr√°s da tela tamb√©m ser√° dobrada. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br>  Nosso c√©rebro √© muito eficiente na an√°lise de imagens ligeiramente diferentes.  Ele usa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">disparidade binocular</a> para obter informa√ß√µes sobre a profundidade de imagens 2D provenientes da retina usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estereopsia</a> .  Bem, estrague as grandes palavras e vamos desenhar imagens! <br><br>  Vamos imaginar que nosso monitor √© uma janela para o mundo virtual :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br>  Nossa tarefa √© desenhar duas imagens do que vemos atrav√©s dessa ‚Äújanela‚Äù, uma para cada olho.  Na foto acima, o ‚Äúsandu√≠che‚Äù vermelho-azul.  Por enquanto, vamos esquecer como entregar essas imagens ao nosso c√©rebro. Nesse est√°gio, precisamos salvar apenas dois arquivos separados.  Em particular, quero saber como obter essas imagens usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">meu min√∫sculo tra√ßador de raios</a> . <br><br>  Vamos assumir que o √¢ngulo n√£o muda e √© o vetor (0,0, -1).  Vamos supor que podemos mover a c√¢mera para a √°rea entre os olhos, mas e da√≠?  Um pequeno detalhe: a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vista da</a> janela atrav√©s da nossa ‚Äújanela‚Äù √© assim√©trica.  Mas nosso tra√ßador de raios s√≥ pode render um frustum sim√©trico: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br>  E o que fazemos agora?  Cheat :) <br><br>  Podemos renderizar imagens um pouco mais amplas do que precisamos e depois cortar as partes extras: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1>  Anaglyph </h1><br>  Acho que cobrimos o mecanismo b√°sico de renderiza√ß√£o e agora abordamos a quest√£o de entregar a imagem ao nosso c√©rebro.  A maneira mais simples √© esse tipo de √≥culos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br>  Fazemos duas renderiza√ß√µes em escala de cinza e atribu√≠mos imagens esquerda e direita aos canais vermelho e azul, respectivamente.  Isto √© o que obtemos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br>  O vidro vermelho corta um canal, enquanto o vidro azul corta o outro.  Combinados, os olhos t√™m uma imagem diferente e a percebemos em 3D.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui est√£o as modifica√ß√µes</a> no commit principal do tinyraytracer.  As altera√ß√µes incluem o posicionamento da c√¢mera para montagem de olhos e canais. <br><br>  O Anaglyph √© uma das formas mais antigas de assistir imagens est√©reo (geradas por computador).  Tem muitas desvantagens, por exemplo, transmiss√£o de cores ruins.  Mas, por outro lado, √© muito f√°cil criar em casa. <br><br>  Se voc√™ n√£o possui um compilador no seu computador, n√£o h√° problema.  Se voc√™ possui uma conta no guithub, pode visualizar, editar e executar o c√≥digo (sic!) Em um clique no seu navegador. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://gitpod.io/&amp;usg=ALkJrhinC0x58w74Qwk2jDecCU7aAsAExg#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Abrir no gitpod"></a> <br><br>  Quando voc√™ abre esse link, o gitpod cria uma m√°quina virtual para voc√™, inicia o VS Code e abre um terminal na m√°quina remota.  No hist√≥rico de comandos (clique no console e pressione a tecla para cima), existe um conjunto completo de comandos que permite compilar o c√≥digo, inici√°-lo e abrir a imagem resultante. <br><br><h1>  Stereoscope </h1><br>  Com os smartphones se tornando populares, lembramos da inven√ß√£o do s√©culo 19 chamada estereosc√≥pio.  H√° alguns anos, o Google sugeriu o uso de duas lentes (que, infelizmente, s√£o dif√≠ceis de criar em casa, voc√™ precisa compr√°-lo), um pouco de papel√£o (dispon√≠vel em qualquer lugar) e um smartphone (no seu bolso) para criar credibilidade √ìculos VR. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br>  Eles s√£o abundantes no AliExpress e custam US $ 3 por par.  Comparado √† renderiza√ß√£o de an√°glifo, n√£o temos muito o que fazer: basta tirar duas fotos e coloc√°-las lado a lado.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui est√° o commit</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br>  Estritamente falando, dependendo da lente, talvez seja necess√°rio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">corrigir a distor√ß√£o da lente</a> , mas n√£o me incomodei com isso, pois ela parecia bem, independentemente.  Mas se realmente precisamos aplicar a pr√©-distor√ß√£o do barril que compensa a distor√ß√£o natural da lente, √© assim que fica para o meu smartphone e meus √≥culos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br>  Aqui est√° o link gitpod: <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://gitpod.io/&amp;usg=ALkJrhinC0x58w74Qwk2jDecCU7aAsAExg#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Abrir no gitpod"></a> <br><br><h1>  Autostereograms </h1><br>  E o que fazemos se n√£o quisermos usar nenhum equipamento extra?  Depois, h√° apenas uma op√ß√£o - apertar os olhos.  A imagem anterior, honestamente, √© suficiente para a visualiza√ß√£o est√©reo, basta apertar os olhos (cruzando os olhos ou colocando-os na parede).  Aqui est√° um esquema que nos diz como assistir a ilustra√ß√£o anterior.  Duas linhas vermelhas mostram as imagens obtidas pela retina esquerda, duas azuis - a retina direita. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br>  Se focarmos na tela, quatro imagens ser√£o combinadas em duas.  Se cruzarmos os olhos ou focarmos em um objeto distante, √© poss√≠vel alimentar "tr√™s" imagens do c√©rebro.  As imagens centrais se sobrep√µem, o que cria o efeito est√©reo. <br><br>  Pessoas diferentes usam m√©todos diferentes: por exemplo, n√£o consigo cruzar os olhos, mas os muro facilmente.  √â importante que o autostereograma criado para um determinado m√©todo seja visto apenas com esse m√©todo, ou ent√£o obtemos um mapa de profundidade invertido (lembra-se de paralaxe positivo e negativo?).  O problema √© que √© dif√≠cil cruzar os olhos muito, por isso s√≥ funciona em imagens pequenas.  Mas e se quisermos os maiores?  Vamos sacrificar totalmente as cores e focar apenas na parte da percep√ß√£o de profundidade.  Aqui est√° a imagem que esperamos obter at√© o final do artigo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br>  Este √© um autostereograma de olhos nas paredes.  Para aqueles que preferem o outro m√©todo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui est√° uma imagem para isso</a> .  Se voc√™ n√£o est√° acostumado a autostereogramas, tente diferentes condi√ß√µes: tela cheia, imagem menor, brilho, escurid√£o.  Nosso objetivo √© cobrir os olhos para que as duas faixas verticais pr√≥ximas se sobreponham.  O mais f√°cil √© focar na parte superior esquerda da imagem, pois √© simples.  Pessoalmente, abro a imagem em tela cheia.  N√£o se esque√ßa de remover o cursor do mouse tamb√©m! <br><br>  N√£o pare com um efeito 3D incompleto.  Se voc√™ v√™ vagamente formas arredondadas e o efeito 3D √© fraco, a ilus√£o √© incompleta.  As esferas devem ‚Äúpular‚Äù para fora da tela em dire√ß√£o ao espectador, o efeito deve ser est√°vel e sustent√°vel.  A estereopsia tem uma gistese: uma vez que voc√™ obt√©m uma imagem est√°vel, fica mais detalhada quanto mais tempo a observa.  Quanto mais os olhos est√£o da tela, maior o efeito de percep√ß√£o de profundidade. <br><br>  Este estereograma foi desenhado usando um m√©todo sugerido h√° 25 anos neste artigo: " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Exibindo imagens 3D: algoritmos para estereogramas de pontos aleat√≥rios de imagem √∫nica</a> ". <br><br><h3>  Vamos come√ßar </h3><br>  O ponto de partida para renderizar autostereogramas √© o mapa de profundidade (j√° que abandonamos as cores).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Esta confirma√ß√£o</a> desenha a seguinte imagem: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br>  Os planos mais pr√≥ximos e futuros definem nossa profundidade: o ponto mais distante do meu mapa tem a profundidade de 0, enquanto o ponto mais pr√≥ximo tem a profundidade de 1. <br><br><h3>  Os princ√≠pios fundamentais </h3><br>  Digamos que nossos olhos estejam a uma dist√¢ncia d da tela.  Colocamos nosso plano distante (imagin√°rio) (z = 0) na mesma dist√¢ncia "atr√°s" da tela.  Escolhemos a vari√°vel ¬µ, que determina a localiza√ß√£o do plano pr√≥ximo (z = 1), que estar√° √† dist√¢ncia ¬µd do plano distante.  Para o meu c√≥digo, escolhi Œº = ‚Öì.  No geral, todo o nosso "mundo" vive √† dist√¢ncia de d-Œºd em d atr√°s da tela.  Digamos que sabemos a dist√¢ncia entre os olhos (em pixels, eu escolhi 400 pixels): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br>  Se observarmos o ponto vermelho, dois pixels marcados em verde devem ter a mesma cor no estereograma.  Como calcular a dist√¢ncia entre eles?  F√°cil  Se o ponto projetado atual tiver a profundidade de z, a paralaxe dividida pela dist√¢ncia entre os olhos ser√° igual √† fra√ß√£o entre as profundidades correspondentes: p / e = (d-dŒºz) / (2d-dŒºz).  A prop√≥sito, observe que d √© simplificado e n√£o aparece em nenhum outro lugar!  Ent√£o p / e = (1-Œºz) / (2-Œºz), significando que a paralaxe √© igual a p = e * (1-Œºz) / (2-Œºz) pixels. <br><br>  A principal id√©ia por tr√°s do autostereograma √©: percorremos todo o mapa de profundidade, para cada valor de profundidade, determinamos quais pixels ter√£o a mesma cor e o colocamos em nosso sistema de restri√ß√µes.  Come√ßamos a partir da imagem aleat√≥ria e tentamos satisfazer todas as restri√ß√µes que definimos anteriormente. <br><br><h3>  Preparando a imagem de origem </h3><br>  Aqui preparamos a imagem que mais tarde ser√° restringida por restri√ß√µes de paralaxe.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui est√° o commit</a> , e ele desenha o seguinte: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br>  Observe que as cores s√£o na maioria aleat√≥rias, al√©m do canal vermelho onde eu coloquei rand () * sin para criar um padr√£o peri√≥dico.  As faixas est√£o separadas por 200 pixels, que √© (dado Œº = 1/3 e e = 400) o valor m√°ximo de paralaxe em nosso mundo (o plano distante).  O padr√£o n√£o √© tecnicamente necess√°rio, mas ajudar√° a focar os olhos. <br><br><h3>  Renderiza√ß√£o autom√°tica </h3><br>  Na verdade, o c√≥digo completo que desenha o autostereograma se parece com isso: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui est√° o commit</a> , a fun√ß√£o int paralaxe (const float z) nos fornece dist√¢ncia entre pixels da mesma cor para o valor atual da profundidade.  Renderizamos o estereograma linha por linha, uma vez que as linhas s√£o independentes uma da outra (n√£o temos paralaxe vertical).  O loop principal simplesmente itera atrav√©s de cada linha;  cada vez que come√ßa com um conjunto ilimitado de pixels e, para cada pixel, adiciona uma restri√ß√£o de igualdade.  No final, ele nos fornece um certo n√∫mero de agrupamentos de pixels da mesma cor.  Por exemplo, pixels com √≠ndices esquerdo e direito devem acabar id√™nticos. <br><br>  Como armazenar esse conjunto de restri√ß√µes?  A maneira mais simples √© a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estrutura de dados de localiza√ß√£o de uni√£o</a> .  N√£o vou entrar em detalhes, basta ir √† Wikipedia, s√£o literalmente tr√™s linhas de c√≥digo.  O ponto principal √© que, para cada cluster, existe um determinado pixel "raiz" respons√°vel pelo cluster.  O pixel raiz mant√©m sua cor inicial e todos os outros pixels do cluster devem ser atualizados: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://gitpod.io/&amp;usg=ALkJrhinC0x58w74Qwk2jDecCU7aAsAExg#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Abrir no gitpod"></a> <br><br><h1>  Conclus√£o </h1><br>  √â isso mesmo.  Vinte linhas de c√≥digo e nosso autostereograma est√° pronto para voc√™ quebrar os olhos.  A prop√≥sito, se nos esfor√ßarmos o suficiente, √© poss√≠vel transmitir informa√ß√µes sobre cores. <br><br>  N√£o cobri outros sistemas estereosc√≥picos, como os sistemas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3D polarizados</a> , pois s√£o muito mais caros de fabricar.  Se eu perdi alguma coisa, fique √† vontade para me corrigir! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt441014/">https://habr.com/ru/post/pt441014/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt441004/index.html">Splunk deixa a R√∫ssia (completamente)</a></li>
<li><a href="../pt441006/index.html">Uma vis√£o geral dos m√©todos de segmenta√ß√£o de imagens na biblioteca scikit-image</a></li>
<li><a href="../pt441008/index.html">MQ de coelho no sistema de processamento de residentes</a></li>
<li><a href="../pt441010/index.html">Des√ßa na terra mortal ...</a></li>
<li><a href="../pt441012/index.html">Fatos interessantes sobre a hist√≥ria do programa lunar chin√™s e a miss√£o espacial Chang'e-4</a></li>
<li><a href="../pt441018/index.html">Ferramentas de desenvolvimento e especifica√ß√£o do programa NanoCAD Mechanics</a></li>
<li><a href="../pt441020/index.html">Como o VTB chegou a um √∫nico conhecimento</a></li>
<li><a href="../pt441022/index.html">Erros comuns de passageiros de ferrovias e companhias a√©reas</a></li>
<li><a href="../pt441024/index.html">Escrevemos um rastreador para um ou dois 1.0</a></li>
<li><a href="../pt441026/index.html">VMware NSX para o menor. Parte 2. Configurando Firewall e NAT</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
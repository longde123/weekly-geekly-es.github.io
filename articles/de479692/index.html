<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕒 😦 🚜 Indizierung von Milliarden von Textvektoren 👂 🕴️ ✌🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Beim Extrahieren von Informationen stellt sich häufig die Aufgabe, solche Textfragmente zu finden. Im Rahmen einer Suche kann eine Abfrage vom Benutze...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Indizierung von Milliarden von Textvektoren</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/479692/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/id/dd/fg/idddfg6zku7xq-zv9f0m8xemyiy.jpeg"></div><br>  Beim Extrahieren von Informationen stellt sich häufig die Aufgabe, <i>solche</i> Textfragmente zu finden.  Im Rahmen einer Suche kann eine Abfrage vom Benutzer (z. B. dem Text, den der Benutzer in die Suchmaschine eingibt) oder vom System selbst generiert werden.  Oft müssen wir eine eingehende Abfrage mit bereits indizierten Abfragen abgleichen.  In diesem Artikel wird untersucht, wie Sie ein System erstellen können, das dieses Problem in Bezug auf Milliarden von Anforderungen löst, ohne ein Vermögen für die Serverinfrastruktur auszugeben. <br><a name="habracut"></a><br>  Zunächst definieren wir das Problem formell: <br><br><blockquote>  Angesichts eines festen Satzes von Abfragen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">Q</span></span></span><script type="math/tex" id="MathJax-Element-1"> Q </script>  eingehende Anfrage <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">q</span></span></span><script type="math/tex" id="MathJax-Element-2"> q </script>  und eine ganze Zahl <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-5"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-6">k</span></span></span><script type="math/tex" id="MathJax-Element-3"> k </script>  .  Müssen eine solche Untermenge von Abfragen finden <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-7"><span class="noError" id="MJXp-Span-8" style="display: inline-block;">R&nbsp;=&nbsp;\&nbsp;left&nbsp;\&nbsp;{q0,&nbsp;q1,&nbsp;...,&nbsp;qk&nbsp;\&nbsp;right&nbsp;\}&nbsp;\&nbsp;subset&nbsp;Q</span></span></span><script type="math/tex" id="MathJax-Element-4"> R = \ left \ {q0, q1, ..., qk \ right \} \ subset Q </script>  zu jeder Anfrage <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-9"><span class="MJXp-msubsup" id="MJXp-Span-10"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11" style="margin-right: 0.05em;">q</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-12" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13">i</span></span></span><span class="MJXp-mtext" id="MJXp-Span-14">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17">R</span></span></span><script type="math/tex" id="MathJax-Element-5"> q_ {i} \ in R </script>  war eher wie <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-18"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19">q</span></span></span><script type="math/tex" id="MathJax-Element-6"> q </script>  als jede andere Anfrage in <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-20"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-21">Q</span><span class="MJXp-mo" id="MJXp-Span-22" style="margin-left: 0.267em; margin-right: 0.267em;">∖</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-23">R</span></span></span><script type="math/tex" id="MathJax-Element-7"> Q ∖ R </script>  . </blockquote><br>  Zum Beispiel mit diesem Satz von Abfragen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-24"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25">Q</span></span></span><script type="math/tex" id="MathJax-Element-8"> Q </script>  : <br><br><pre><code class="plaintext hljs">{tesla cybertruck, beginner bicycle gear, eggplant dishes, tesla new car, how expensive is cybertruck, vegetarian food, shimano 105 vs ultegra, building a carbon bike, zucchini recipes}</code> </pre> <br>  und <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-26"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">k</span><span class="MJXp-mo" id="MJXp-Span-28" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-29">3</span></span></span><script type="math/tex" id="MathJax-Element-9"> k = 3 </script>  Sie können folgendes Ergebnis erwarten: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Eingabeaufforderung <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-30"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31">q</span></span></span><script type="math/tex" id="MathJax-Element-10"> q </script><br></th><th>  Ähnliche Abfragen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-32"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-33">R</span></span></span><script type="math/tex" id="MathJax-Element-11"> R </script><br></th></tr><tr><td>  Tesla Pickup <br></td><td>  {Tesla Cybertruck, Tesla New Car, wie teuer ist Cybertruck} <br></td></tr><tr><td>  bestes Fahrrad 2019 <br></td><td>  {Shimano 105 vs Ultegra, sind Carbon-Bikes besser, Fahrradausrüstung} <br></td></tr><tr><td>  kochen mit gemüse <br></td><td>  {Auberginengerichte, Zucchini-Rezepte, vegetarisches Essen} <br></td></tr></tbody></table></div><br>  Bitte beachten Sie, dass wir noch kein <i>Ähnlichkeitskriterium</i> definiert haben.  In diesem Zusammenhang kann dies fast alles bedeuten, aber es kommt normalerweise auf eine Art von Ähnlichkeit an, die auf Schlüsselwörtern oder Vektoren basiert.  Mithilfe der keyword-basierten Ähnlichkeit können wir zwei ähnliche Abfragen finden, wenn sie genügend gemeinsame Wörter enthalten.  Zum Beispiel sind die Abfragen „Ein Restaurant in München eröffnen“ und „Bestes Restaurant in München“ ähnlich, weil sie die Wörter „Restaurant“ und „München“ enthalten.  Und die Fragen „bestes restaurant münchens“ und „wo man in münchen isst“ sind schon weniger ähnlich, weil sie nur ein gemeinsames wort haben.  Wer in München ein Restaurant sucht, ist jedoch besser aufgehoben, wenn sich das zweite Anforderungspaar als ähnlich herausstellt.  Und dabei helfen wir dem Vergleich anhand von Vektoren. <br><br><h1>  Vektordarstellung von Wörtern </h1><br>  Die Vektordarstellung von Wörtern ist eine maschinelle Lerntechnik, die bei der Verarbeitung natürlicher Sprachen verwendet wird, um Text oder Wörter in Vektoren umzuwandeln.  Wenn wir die Aufgabe in den Vektorraum verschieben, können wir mathematische Operationen mit Vektoren verwenden - Summieren und Berechnen von Entfernungen.  Um Verknüpfungen zwischen ähnlichen Wörtern herzustellen, können Sie herkömmliche Methoden der Vektorclusterung verwenden.  <i>Die Bedeutung</i> dieser Operationen im ursprünglichen Wortraum mag nicht offensichtlich sein, aber der Vorteil ist, dass wir jetzt Zugriff auf eine breite Palette von mathematischen Werkzeugen haben.  Wenn Sie an Details zu <a href="https://arxiv.org/pdf/1301.3781.pdf">Wortvektoren</a> und deren Anwendung interessiert sind, lesen Sie mehr über <a href="https://arxiv.org/pdf/1301.3781.pdf">word2vec</a> und <a href="https://nlp.stanford.edu/pubs/glove.pdf">GloVe</a> . <br><br>  Wir haben eine Möglichkeit, Vektoren aus Wörtern zu generieren. Jetzt sammeln wir sie in Textvektoren (Vektoren von Dokumenten oder Ausdrücken).  Der einfachste Weg, dies zu tun, ist das Hinzufügen (oder Mitteln) der Vektoren aller Wörter im Text. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/692/bc5/b0c/692bc5b0ccbbe7a89392528365645708.png"><br>  <i><sup>Abbildung 1: Abfragevektoren</sup></i> <br><br>  Jetzt können Sie die Ähnlichkeit zweier Textteile (oder Abfragen) ermitteln, indem Sie sie im Vektorraum darstellen und den Abstand zwischen den Vektoren berechnen.  Typischerweise wird hierfür ein Winkelabstand verwendet. <br><br>  Infolgedessen ermöglicht die Vektordarstellung von Wörtern einen Textabgleich eines anderen Typs, der den schlüsselwortbasierten Abgleich ergänzt.  Sie können die semantische Ähnlichkeit von Anfragen (zum Beispiel "bestes Restaurant in München" und "wo man in München essen kann") untersuchen, wie wir es vorher nicht konnten. <br><br><h1>  Ungefähre Suche nach nächstem Nachbarn </h1><br>  Jetzt können wir unser ursprüngliches Abfragezuordnungsproblem verfeinern: <br><br><blockquote>  Gegeben eine feste Menge von Abfragevektoren <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-34"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">Q</span></span></span><script type="math/tex" id="MathJax-Element-12"> Q </script>  eingehender Vektor <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-36"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37">q</span></span></span><script type="math/tex" id="MathJax-Element-13"> q </script>  und eine ganze Zahl <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-38"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-39">k</span></span></span><script type="math/tex" id="MathJax-Element-14"> k </script>  .  Sie müssen eine solche Untergruppe von Vektoren finden <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-40"><span class="noError" id="MJXp-Span-41" style="display: inline-block;">R&nbsp;=&nbsp;\&nbsp;left&nbsp;\&nbsp;{q0,&nbsp;q1,&nbsp;...,&nbsp;qk&nbsp;\&nbsp;right&nbsp;\}&nbsp;\&nbsp;subset&nbsp;Q</span></span></span><script type="math/tex" id="MathJax-Element-15"> R = \ left \ {q0, q1, ..., qk \ right \} \ subset Q </script>  so dass der Winkelabstand von <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-42"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-43">q</span></span></span><script type="math/tex" id="MathJax-Element-16"> q </script>  zu jedem Vektor <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-44"><span class="MJXp-msubsup" id="MJXp-Span-45"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-46" style="margin-right: 0.05em;">q</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-47" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">i</span></span></span><span class="MJXp-mtext" id="MJXp-Span-49">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-50">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-51">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-52">R</span></span></span><script type="math/tex" id="MathJax-Element-17"> q_ {i} \ in R </script>  war kürzer als der Abstand zu einem anderen Vektor in <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-53"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">Q</span><span class="MJXp-mo" id="MJXp-Span-55" style="margin-left: 0.267em; margin-right: 0.267em;">∖</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56">R</span></span></span><script type="math/tex" id="MathJax-Element-18"> Q ∖ R </script>  . </blockquote><br>  Dies nennt man die Aufgabe, den nächsten Nachbarn zu finden.  Es gibt eine <a href="https://ru.wikipedia.org/wiki/%25D0%2597%25D0%25B0%25D0%25B4%25D0%25B0%25D1%2587%25D0%25B0_%25D0%25BF%25D0%25BE%25D0%25B8%25D1%2581%25D0%25BA%25D0%25B0_%25D0%25B1%25D0%25BB%25D0%25B8%25D0%25B6%25D0%25B0%25D0%25B9%25D1%2588%25D0%25B5%25D0%25B3%25D0%25BE_%25D1%2581%25D0%25BE%25D1%2581%25D0%25B5%25D0%25B4%25D0%25B0">Reihe von Algorithmen</a> für die schnelle Lösung in niedrigdimensionalen Räumen.  Wenn wir jedoch mit Vektordarstellungen von Wörtern arbeiten, arbeiten wir normalerweise mit hochdimensionalen Vektoren (100-1000 Dimensionen).  Und hier funktionieren die genannten Methoden nicht mehr. <br><br>  Es gibt keine geeignete Möglichkeit, die nächsten Nachbarn in hochdimensionalen Räumen schnell zu ermitteln.  Daher vereinfachen wir das Problem, indem wir die Verwendung von Näherungsergebnissen zulassen: Anstatt immer <i>die</i> nächsten Vektoren zurückzugeben, begnügen wir uns nur mit einigen der nächsten oder <i>zu einem gewissen Grad</i> nahen Nachbarn.  Dies wird als ungefähre Suche nach dem nächsten Nachbarn bezeichnet und ist ein Bereich aktiver Forschung. <br><br><h3>  Hierarchische kleine Welt </h3><br>  Der Hierarchical Navigable Small-World Graph ( <a href="https://arxiv.org/abs/1603.09320">HNSW</a> ) ist einer der schnellsten Algorithmen für die ungefähre Suche nach nächsten Nachbarn.  Der Suchindex in HNSW ist eine mehrstufige Struktur, bei der jede Stufe ein Proximity-Diagramm ist.  Jeder Graphknoten entspricht einem der Abfragevektoren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/42e/55e/4b7/42e55e4b72cd088b45e5aff56159f7fb.png"><br>  <sup><i>Abbildung 2: Mehrstufiges Proximity-Diagramm.</i></sup> <br>  Die Suche nach nächstgelegenen Nachbarn in HNSW verwendet die Zoom-In-Methode.  Es startet im Eingangsknoten der höchsten Ebene und führt auf jeder Ebene rekursiv eine gierige Grafikdurchquerung durch, bis es unten ein lokales Minimum erreicht. <br><br>  Details zum Algorithmus und zur Suchtechnik sind in der wissenschaftlichen Arbeit gut beschrieben.  Es ist wichtig, sich daran zu erinnern, dass jeder Suchzyklus nach den nächsten Nachbarn darin besteht, die Knoten der Graphen zu durchlaufen und die Abstände zwischen den Vektoren zu berechnen.  In den folgenden Schritten wird anhand dieser Methode ein umfangreicher Index erstellt. <br><br><h1>  Die Schwierigkeit, Milliarden von Abfragen zu indizieren </h1><br>  Angenommen, wir müssen 4 Milliarden 200-dimensionale Abfragevektoren indizieren, wobei jede Dimension durch eine 4-Byte-Gleitkommazahl dargestellt wird (4 Milliarden reichen aus, um die Aufgabe interessant zu machen, aber Sie können die Knoten-IDs weiterhin in regulären 4-Byte-Zahlen speichern). .  Eine grobe Berechnung sagt uns, dass die Größe der Vektoren alleine etwa 3 TB beträgt.  Da die meisten vorhandenen Bibliotheken eine RAM-Kapazität für die ungefähre Suche nach den nächsten Nachbarn verwenden, benötigen wir einen sehr großen Server, um mindestens Vektoren in den RAM zu übertragen.  Bitte beachten Sie, dass hierbei der zusätzliche Suchindex nicht berücksichtigt wird, der für die meisten Methoden erforderlich ist. <br><br>  In der gesamten Entwicklungsgeschichte unserer Suchmaschine haben wir dieses Problem auf verschiedene Weise gelöst.  Betrachten wir einige davon. <br><br><h3>  Teilmenge von Daten </h3><br>  Der erste und einfachste Ansatz, mit dem wir das Problem nicht vollständig lösen konnten, bestand darin, die Anzahl der Vektoren im Index zu begrenzen.  Aus einem Zehntel der Daten haben wir einen Index erstellt, der - überraschend - 10% des Speichers benötigt.  Die Qualität der Suche hat sich jedoch verschlechtert, da wir jetzt mit weniger Abfragen gearbeitet haben. <br><br><h3>  Quantisierung </h3><br>  Hier verwendeten wir alle Daten, reduzierten sie jedoch mithilfe der <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B2%25D0%25B0%25D0%25BD%25D1%2582%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5">Quantisierung</a> (wir verwendeten verschiedene Quantisierungstechniken, z. B. die Produktquantisierung, konnten jedoch mit dieser Datenmenge nicht die gewünschte Arbeitsqualität erzielen).  Durch Abrunden einiger Fehler konnten wir alle Vier-Byte-Zahlen in den ursprünglichen Vektoren durch quantisierte Einzel-Byte-Versionen ersetzen.  Die RAM-Größe für Vektoren verringerte sich um 75%.  Wir benötigten jedoch immer noch 750 GB Arbeitsspeicher (ohne die Größe des Index selbst), und dies ist immer noch ein sehr großer Server. <br><br><h1>  Speicherprobleme mit Granne lösen </h1><br>  Die beschriebenen Ansätze hatten ihre Vorteile, erforderten jedoch viel Ressourcen und ergaben eine schlechte Suchqualität.  Obwohl <a href="http://ann-benchmarks.com/">es Bibliotheken gibt</a> , die in weniger als 1 ms antworten, können wir die Geschwindigkeit gegen geringere Hardwareanforderungen eintauschen. <br><br>  <a href="https://github.com/granne/granne">Granne</a> (graphenbasierte ungefähre nächste Nachbarn) ist eine HNSW-Bibliothek, die von Cliqz für die Suche nach solchen Abfragen entwickelt und verwendet wird.  Es hat Open Source Code, aber die Bibliothek befindet sich noch in der aktiven Entwicklung.  Eine verbesserte Version wird 2020 auf <a href="https://crates.io/">crates.io</a> veröffentlicht.  Es ist in Rust mit Python-Inserts geschrieben, die so konzipiert sind, dass Milliarden von Vektoren wettbewerbsfähig sind.  Aus Sicht der Abfragevektoren ist es interessant, dass Granne über einen speziellen Modus verfügt, der im Vergleich zu anderen Bibliotheken viel weniger Speicher benötigt. <br><br><h3>  Kompakte Darstellung von Abfragevektoren </h3><br>  Das Reduzieren der Größe von Abfragevektoren bringt uns viele Vorteile.  Lassen Sie uns dazu zurückgehen und überlegen, Vektoren zu erstellen.  Da Abfragen aus Wörtern bestehen und Abfragevektoren Summen von Wortvektoren sind, können wir ausdrücklich ablehnen, Abfragevektoren zu speichern und sie nach Bedarf zu berechnen. <br><br>  Sie können Abfragen in Form von Wortmengen speichern und anhand der Nachschlagetabelle die entsprechenden Vektoren finden.  Wir vermeiden jedoch eine Umleitung, indem wir jede Abfrage als Liste von Ganzzahl-IDs speichern, die den Wortvektoren in der Abfrage entsprechen.  Speichern Sie beispielsweise die Abfrage „bestes Restaurant Münchens“ als <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-57"><span class="MJXp-mo" id="MJXp-Span-58" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mrow" id="MJXp-Span-59"><span class="MJXp-msubsup" id="MJXp-Span-60"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-61" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-62" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-63">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-64">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-66">t</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-67" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-68"><span class="MJXp-msubsup" id="MJXp-Span-69"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-71" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-72">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-73">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-74">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-75">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-76">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-78">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-81">t</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-82" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-83"><span class="MJXp-msubsup" id="MJXp-Span-84"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-85" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-86" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88">f</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-89" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-90"><span class="MJXp-msubsup" id="MJXp-Span-91"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-92" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-93" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-94">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-95">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-96">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-97">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-98">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-99">h</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-100" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><script type="math/tex" id="MathJax-Element-19"> [{i_ {best}}, {i_ {restaurant}}, {i_ {of}}, {i_ {munich}}] </script>  wo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-101"><span class="MJXp-mrow" id="MJXp-Span-102"><span class="MJXp-msubsup" id="MJXp-Span-103"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-104" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-105" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-106">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-107">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-108">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-109">t</span></span></span></span></span></span><script type="math/tex" id="MathJax-Element-20"> {i_ {best}} </script>  - Dies ist die Vektor-ID des Wortes "best" usw. Angenommen, wir haben weniger als 16 Millionen Wortvektoren (mehr als 1 Byte pro Wort), dann können Sie 3 Byte verwenden, um alle Wort-IDs darzustellen.  Das heißt, anstatt 800 Bytes (oder 200 Bytes bei quantisierten Vektoren) zu speichern, werden für diese Anforderung nur 12 Bytes gespeichert (Dies ist nicht ganz richtig. Da die Anforderungen aus einer anderen Anzahl von Wörtern bestehen, müssen wir auch den Listenoffset im Wortindex speichern. Für Dies erfordert 5 Bytes pro Anforderung. <br><br>  Die Wortvektoren brauchen wir alle.  Die Anzahl der Wörter ist jedoch viel kleiner als die Anzahl der Abfragen, die durch Kombinieren dieser Wörter erstellt werden können.  Und das bedeutet, dass die Größe der Wörter nicht so wichtig ist.  Wenn Sie Wortvektoren als 4-Byte-Gleitkommaversionen in einem einfachen Array speichern <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-110"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-111">v</span></span></span><script type="math/tex" id="MathJax-Element-21"> v </script>  Dann brauchen wir weniger als 1 GB für jede Million Wörter.  Dieses Volume passt problemlos in den Arbeitsspeicher.  Nun sieht der Abfragevektor so aus: <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-112"><span class="noError" id="MJXp-Span-113" style="display: inline-block;">{v&nbsp;_&nbsp;{{i_&nbsp;{best}}}&nbsp;+&nbsp;{v&nbsp;_&nbsp;{{i_&nbsp;{restaurant}}&nbsp;+&nbsp;{v&nbsp;_&nbsp;{{i_&nbsp;{of}}&nbsp;+&nbsp;{v&nbsp;_&nbsp;{{i_&nbsp;{münchen}}}</span></span></span><script type="math/tex" id="MathJax-Element-22"> {v _ {{i_ {best}}} + {v _ {{i_ {restaurant}} + {v _ {{i_ {of}} + {v _ {{i_ {münchen}}} </script>  . <br><br>  Die endgültige Größe der Abfrageübermittlung hängt von der Gesamtzahl der Wörter in der Abfrage ab.  Für 4 Milliarden Abfragen sind dies etwa 80 GB (einschließlich Wortvektoren).  Mit anderen Worten, verglichen mit den ursprünglichen Wortvektoren verringerte sich die Größe um 97% und verglichen mit quantisierten Vektoren um 90%. <br><br>  Und noch eine Sache.  Für eine Suche müssen ungefähr 200-300 Knoten des Graphen besucht werden.  Jeder Knoten hat 20-30 Nachbarn.  Wir müssen also den Abstand vom Eingabeabfragevektor zu 4000-9000 Vektoren im Index berechnen.  Außerdem müssen Vektoren generiert werden.  Wie lange dauert es, um Abfragevektoren im laufenden Betrieb zu erstellen? <br><br>  Es stellt sich heraus, dass dieses Problem mit einem relativ neuen Prozessor in wenigen Millisekunden gelöst werden kann.  Eine Anforderung, die früher in 1 ms ausgeführt wurde, dauert jetzt ungefähr 5 ms.  Dann haben wir den Speicher für Vektoren um 90% reduziert.  Einen solchen Kompromiss haben wir gerne angenommen. <br><br><h3>  Anzeige im Speicher von Vektoren und Index </h3><br>  Oben haben wir das Problem der Reduzierung des Speichers für Vektoren gelöst.  Nachdem wir dieses Problem gelöst hatten, wurde die Indexstruktur selbst zu einem einschränkenden Faktor.  Jetzt müssen Sie die Größe reduzieren. <br><br>  In Granne wird die Graphenstruktur kompakt in Form einer Adjazenzliste mit einer variablen Anzahl von Nachbarn für jeden Knoten gespeichert.  Das heißt, Speicherplatz wird kaum für Metadaten verschwendet.  Die Größe der Indexstruktur hängt stark von den Entwurfsparametern und den Diagrammeigenschaften ab.  Um eine Vorstellung von der Größe des Index zu bekommen, reicht es jedoch zu sagen, dass wir einen Index für 4 Milliarden Vektoren mit einer Gesamtgröße von ca. 240 GB erstellen können.  Dies ist möglicherweise für die Verwendung im Arbeitsspeicher auf einem großen Server akzeptabel, kann jedoch besser durchgeführt werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e73/daa/0de/e73daa0dea90e3e84afe9aaec7bd6a8e.jpg"><br>  <sup><i>Abbildung 3: Zwei verschiedene Layouts in RAM und SSD.</i></sup> <br><br>  Eine wichtige Eigenschaft von Granne ist die Fähigkeit, <a href="https://ru.wikipedia.org/wiki/Mmap">die</a> Index- und Abfragevektoren <a href="https://ru.wikipedia.org/wiki/Mmap">im Speicher anzuzeigen</a> .  Dies ermöglicht es uns, den Index träge zu laden und den Speicher mit mehreren Prozessen gemeinsam zu nutzen.  Die Index- und Abfragedateien sind in separate Anzeigedateien im Speicher unterteilt und können in verschiedenen Layouts im RAM und auf der SSD verwendet werden.  Wenn die Anforderungen für die Verzögerung etwas geringer sind, stellen Sie den Index auf die SSD und fordern Sie RAM an. Wir behalten eine akzeptable Geschwindigkeit bei, ohne übermäßigen Speicherverbrauch.  Am Ende des Artikels werden wir sehen, wie dieser Kompromiss aussieht. <br><br><h3>  Verbesserung der Datenlokalität </h3><br>  In unserer aktuellen Konfiguration erfordert jede Anforderung, wenn sich der Index auf einer SSD befindet, bis zu 200-300 Lesevorgänge von der Festplatte.  Sie können versuchen, die Lokalität der Daten zu erhöhen, indem Sie die Elemente anordnen, deren Vektoren so nahe beieinander liegen, dass sich ihre HNSW-Knoten ebenfalls nicht weit voneinander entfernt im Index befinden.  Die Datenlokalität verbessert die Leistung, da ein einzelner Lesevorgang (normalerweise aus 4 KB extrahiert) mit größerer Wahrscheinlichkeit andere Knoten enthält, die zum Durchlaufen des Diagramms erforderlich sind.  Dies wiederum reduziert die Anzahl der Datenabrufe pro Suche. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1f8/1d2/2f4/1f81d22f418256c704bb12b7514e68a1.jpg"><br>  <sup><i>Abbildung 4: Datenlokalität reduziert das Abrufen von Informationen.</i></sup> <br><br>  Es sollte beachtet werden, dass das Umordnen von Elementen keine Auswirkungen auf die Suchergebnisse hat. Dies ist eine Möglichkeit, die Suche zu beschleunigen.  Das heißt, die Reihenfolge kann beliebig sein, aber nicht jede Option beschleunigt die Suche.  Es ist sehr schwierig, die optimale Reihenfolge zu finden.  Die Heuristik, die wir erfolgreich angewendet haben, besteht jedoch darin, die Abfragen nach dem <i>wichtigsten</i> Wort in jeder Abfrage zu sortieren. <br><br><h1>  Fazit </h1><br>  Wir verwenden Granne zum Erstellen und Verwalten von milliardenschweren Indizes mit Abfragevektoren, um nach ähnlichen Abfragen mit relativ geringem Speicherverbrauch zu suchen.  Die folgende Tabelle zeigt die Anforderungen für verschiedene Methoden.  Seien Sie skeptisch in Bezug auf die absoluten Werte von Verzögerungen während der Suche, da diese stark von der als akzeptabel geltenden Antwort abhängen.  Diese Informationen beschreiben jedoch die relative Leistung der Methoden. <br><br><div class="scrollable-table"><table><tbody><tr><th></th><th>  Anfangswert <br></th><th>  Quantisierung <br></th><th>  Granne (nur RAM) <br></th><th>  Granne (RAM + SSD) <br></th></tr><tr><td>  <b>Die Erinnerung</b> <br></td><td>  3000 + 240 GB <br></td><td>  750 + 240 GB <br></td><td>  80 + 240 GB <br></td><td>  80-150 GB * <br></td></tr><tr><td>  <b>SSD</b> <br></td><td>  - </td><td>  - </td><td>  - </td><td>  240 GB <br></td></tr><tr><td>  <b>Verzögerung</b> <br></td><td>  1 ms <br></td><td>  1 ms <br></td><td>  5 ms <br></td><td>  10-50 ms <br></td></tr></tbody></table></div><br>  <i>* Das Zuweisen eines Speicherindexes, der größer als die erforderliche Menge ist, führte zum Zwischenspeichern einiger (häufig besuchter) Knoten, wodurch die Verzögerung bei der Suche verringert wurde.</i>  <i>Hierfür wurde kein interner Cache verwendet, sondern nur interne OS-Tools (Linux-Kernel).</i> <br><br>  Es ist zu beachten, dass einige der im Artikel erwähnten Optimierungen nicht zur Lösung des allgemeinen Problems der Suche nach nächsten Nachbarn mit nicht zusammensetzbaren Vektoren anwendbar sind.  Sie sind jedoch in allen Situationen anwendbar, in denen Elemente aus weniger Teilen generiert werden können (wie dies bei Wörtern und Abfragen der Fall ist).  Ansonsten können Sie Granne immer noch mit den Quellvektoren verwenden, es wird nur mehr Speicher benötigt, als bei anderen Bibliotheken. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479692/">https://habr.com/ru/post/de479692/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479682/index.html">Sysdig Container Usage Report 2019: Neue Kubernetes und Sicherheitsdetails</a></li>
<li><a href="../de479684/index.html">Wie man Niederfrequenzschlüssel für SEO sammelt: 4 nicht-triviale Wege</a></li>
<li><a href="../de479686/index.html">Wichtige Trends im IT-Outsourcing nach 2020</a></li>
<li><a href="../de479688/index.html">In welchen Ländern und Städten verdienen Entwickler unter Berücksichtigung von Steuern und Lebenshaltungskosten mehr?</a></li>
<li><a href="../de479690/index.html">Zork und Z-Machine: Wie Entwickler das Spiel von Großrechnern auf 8-Bit-Heimcomputer übertragen</a></li>
<li><a href="../de479696/index.html">Ein paar Worte zu Alter Table oder wie man es nicht macht</a></li>
<li><a href="../de479700/index.html">CIMON-2: (un) Doomsday oder wie IBM Watson über den Wolken kletterte</a></li>
<li><a href="../de479702/index.html">Toaster, My Circle und Freelansim werden Teil von Habr</a></li>
<li><a href="../de479704/index.html">Eskalation von Berechtigungen im EA Origin Windows-Client (CVE-2019-19247 und CVE-2019-19248)</a></li>
<li><a href="../de479708/index.html">Inoffizieller Beitrag zum Rebranding von Habr + Competition</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
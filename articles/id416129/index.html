<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤽🏼 🌗 👷 Bagaimana AI belajar menghasilkan gambar kucing 👩🏾‍🚀 🔑 🎶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bagaimana terjemahan AI dapat belajar menghasilkan gambar kucing . 

 Penelitian Generative Adversarial Nets (GAN) yang diterbitkan pada tahun 2014 ad...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana AI belajar menghasilkan gambar kucing</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/416129/"><img src="https://habrastorage.org/webt/_h/iv/p2/_hivp2o-k9yn82z0cmffh1y__yu.jpeg"><br><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagaimana</a> terjemahan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AI dapat belajar menghasilkan gambar kucing</a></i> . <br><br>  Penelitian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Generative Adversarial Nets</a> (GAN) yang diterbitkan pada tahun 2014 adalah terobosan di bidang model generatif.  Peneliti utama Yann Lekun menyebut jaring permusuhan "ide terbaik dalam pembelajaran mesin selama dua puluh tahun terakhir."  Hari ini, berkat arsitektur ini, kita dapat membuat AI yang menghasilkan gambar realistis kucing.  Keren! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3a9/2c3/4bd/3a92c34bdd409aead0b270fa21a59d86.gif"><br>  <i>DCGAN selama pelatihan</i> <br><a name="habracut"></a><br>  Semua kode yang berfungsi ada di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">repositori Github</a> .  Ini akan berguna bagi Anda jika Anda memiliki pengalaman dalam pemrograman Python, pembelajaran mendalam, bekerja dengan Tensorflow dan jaringan saraf convolutional. <br><br>  Dan jika Anda baru belajar mendalam, saya sarankan Anda membiasakan diri dengan serangkaian artikel yang sangat baik <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Machine Learning is Fun!</a> <br><br><h3>  Apa itu DCGAN? </h3><br>  Deep Convolutional Generative Adverserial Networks (DCGAN) adalah arsitektur pembelajaran mendalam yang menghasilkan data yang mirip dengan data dari set pelatihan. <br><br>  Model ini menggantikan dengan lapisan konvolusional lapisan yang sepenuhnya terhubung dari jaringan permusuhan generatif.  Untuk memahami cara kerja DCGAN, kami menggunakan metafora konfrontasi antara seorang kritikus ahli seni dan pemalsu. <br><br>  Pemalsu ("generator") sedang mencoba membuat gambar Van Gogh palsu dan mengirimkannya sebagai gambar asli. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/814/e92/796/814e927961f7a7ac8541ae2104d0b9c0.png"><br><br>  Seorang kritikus seni ("diskriminator") sedang mencoba untuk menghukum pemalsuan, menggunakan pengetahuannya tentang kanvas nyata Van Gogh. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ae1/81d/424/ae181d42436f5ac37219ac75b9371c35.png"><br><br>  Seiring waktu, kritikus seni semakin mendefinisikan kepalsuan, dan pemalsuan membuat semuanya lebih sempurna. <br><br><img src="https://habrastorage.org/webt/vq/lk/gt/vqlkgtau1xlmqscetwib8uuixbk.png"><br>  <i>Seperti yang Anda lihat, DCGAN terdiri dari dua jaringan saraf pembelajaran dalam yang terpisah yang saling bersaing.</i> <br><br><ul><li>  Generator sedang mencoba untuk membuat data yang dapat dipercaya.  Dia tidak tahu apa data sebenarnya, tetapi dia belajar dari respons jaringan saraf musuh, mengubah hasil karyanya dengan setiap iterasi. </li><li> Diskriminator mencoba untuk menentukan data palsu (membandingkan dengan yang asli), menghindari sejauh mungkin yang salah dalam kaitannya dengan data nyata.  Hasil dari model ini adalah umpan balik untuk generator. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/b49/a43/c45/b49a43c45d9a54e577e6729ccbdeba33.png"><br>  <i>Skema DCGAN.</i> <br><br><ul><li>  Generator mengambil vektor noise acak dan menghasilkan gambar. </li><li>  Gambar diberikan kepada diskriminator, ia membandingkannya dengan sampel pelatihan. </li><li>  Diskriminator mengembalikan angka - 0 (palsu) atau 1 (gambar asli). </li></ul><br><h3>  Mari kita buat DCGAN! </h3><br>  Sekarang kita siap untuk membuat AI kita sendiri. <br><br>  Pada bagian ini, kita akan fokus pada komponen utama model kita.  Jika Anda ingin melihat seluruh kode, buka di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> . <br><br><h4>  Masukkan data </h4><br>  Buat bertopik untuk input: <code>inputs_real</code> untuk pembeda dan <code>inputs_z</code> untuk generator.  Harap dicatat bahwa kami akan memiliki dua tingkat pembelajaran, secara terpisah untuk generator dan pembeda. <br><br>  DCGAN sangat sensitif terhadap hiperparameter, sehingga sangat penting untuk menyempurnakannya. <br> <code>def model_inputs(real_dim, z_dim):</code> <br> <br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">""" Create the model inputs :param real_dim: tuple containing width, height and channels :param z_dim: The dimension of Z :return: Tuple of (tensor of real input images, tensor of z data, learning rate G, learning rate D) """</span></span> <span class="hljs-comment"><span class="hljs-comment"># inputs_real for Discriminator inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='inputs_real') # inputs_z for Generator inputs_z = tf.placeholder(tf.float32, (None, z_dim), name="input_z") # Two different learning rate : one for the generator, one for the discriminator learning_rate_G = tf.placeholder(tf.float32, name="learning_rate_G") learning_rate_D = tf.placeholder(tf.float32, name="learning_rate_D") return inputs_real, inputs_z, learning_rate_G, learning_rate_D</span></span></code> </pre> <br><h4>  Diskriminator dan generator </h4><br>  Kami menggunakan <code>tf.variable_scope</code> karena dua alasan. <br><br>  Pertama, untuk memastikan semua nama variabel dimulai dengan generator / diskriminator.  Nantinya ini akan membantu kita dalam melatih dua jaringan saraf. <br>  Kedua, kami akan menggunakan kembali jaringan ini dengan data input yang berbeda: <br><br><ul><li>  Kami akan melatih generator, dan kemudian mengambil sampel gambar yang dihasilkannya. </li><li>  Dalam diskriminator, kami akan membagikan variabel untuk gambar input palsu dan nyata. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/b62/c51/df9/b62c51df96feab5b9b1e482d9b0b0133.png"><br><br>  Mari kita buat diskriminator.  Ingat bahwa sebagai input, dibutuhkan gambar nyata atau palsu dan mengembalikan 0 atau 1 sebagai respons. <br><br>  Beberapa catatan: <br><br><ul><li>  Kita perlu menggandakan ukuran filter di setiap lapisan konvolusional. </li><li>  Menggunakan downsampling tidak disarankan.  Sebaliknya, hanya lapisan convolutional yang dilucuti yang berlaku. </li><li>  Di setiap lapisan, kami menggunakan normalisasi batch (dengan pengecualian lapisan input), karena ini mengurangi pergeseran kovarians.  Baca lebih lanjut di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel luar biasa ini</a> . </li><li>  Kami akan menggunakan Leaky ReLU sebagai fungsi aktivasi, ini akan membantu untuk menghindari efek dari gradien "menghilang". </li></ul><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">discriminator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, is_reuse=False, alpha = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Build the discriminator network. Arguments --------- x : Input tensor for the discriminator n_units: Number of units in hidden layer reuse : Reuse the variables with tf.variable_scope alpha : leak parameter for leaky ReLU Returns ------- out, logits: '''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.variable_scope(<span class="hljs-string"><span class="hljs-string">"discriminator"</span></span>, reuse = is_reuse): <span class="hljs-comment"><span class="hljs-comment"># Input layer 128*128*3 --&gt; 64x64x64 # Conv --&gt; BatchNorm --&gt; LeakyReLU conv1 = tf.layers.conv2d(inputs = x, filters = 64, kernel_size = [5,5], strides = [2,2], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name='conv1') batch_norm1 = tf.layers.batch_normalization(conv1, training = True, epsilon = 1e-5, name = 'batch_norm1') conv1_out = tf.nn.leaky_relu(batch_norm1, alpha=alpha, name="conv1_out") # 64x64x64--&gt; 32x32x128 # Conv --&gt; BatchNorm --&gt; LeakyReLU conv2 = tf.layers.conv2d(inputs = conv1_out, filters = 128, kernel_size = [5, 5], strides = [2, 2], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name='conv2') batch_norm2 = tf.layers.batch_normalization(conv2, training = True, epsilon = 1e-5, name = 'batch_norm2') conv2_out = tf.nn.leaky_relu(batch_norm2, alpha=alpha, name="conv2_out") # 32x32x128 --&gt; 16x16x256 # Conv --&gt; BatchNorm --&gt; LeakyReLU conv3 = tf.layers.conv2d(inputs = conv2_out, filters = 256, kernel_size = [5, 5], strides = [2, 2], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name='conv3') batch_norm3 = tf.layers.batch_normalization(conv3, training = True, epsilon = 1e-5, name = 'batch_norm3') conv3_out = tf.nn.leaky_relu(batch_norm3, alpha=alpha, name="conv3_out") # 16x16x256 --&gt; 16x16x512 # Conv --&gt; BatchNorm --&gt; LeakyReLU conv4 = tf.layers.conv2d(inputs = conv3_out, filters = 512, kernel_size = [5, 5], strides = [1, 1], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name='conv4') batch_norm4 = tf.layers.batch_normalization(conv4, training = True, epsilon = 1e-5, name = 'batch_norm4') conv4_out = tf.nn.leaky_relu(batch_norm4, alpha=alpha, name="conv4_out") # 16x16x512 --&gt; 8x8x1024 # Conv --&gt; BatchNorm --&gt; LeakyReLU conv5 = tf.layers.conv2d(inputs = conv4_out, filters = 1024, kernel_size = [5, 5], strides = [2, 2], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name='conv5') batch_norm5 = tf.layers.batch_normalization(conv5, training = True, epsilon = 1e-5, name = 'batch_norm5') conv5_out = tf.nn.leaky_relu(batch_norm5, alpha=alpha, name="conv5_out") # Flatten it flatten = tf.reshape(conv5_out, (-1, 8*8*1024)) # Logits logits = tf.layers.dense(inputs = flatten, units = 1, activation = None) out = tf.sigmoid(logits) return out, logits</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/c2a/438/e2e/c2a438e2e1bb8160f30c6e62297153f4.png"><br><br>  Kami telah membuat generator.  Ingatlah bahwa dibutuhkan vektor noise (z) sebagai input dan, berkat lapisan konvolusi yang ditransformasikan, menciptakan gambar palsu. <br><br>  Pada setiap lapisan, kami membagi dua ukuran filter, dan juga menggandakan ukuran gambar. <br><br>  Generator bekerja paling baik saat menggunakan <code>tanh</code> sebagai fungsi aktivasi output. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(z, output_channel_dim, is_train=True)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Build the generator network. Arguments --------- z : Input tensor for the generator output_channel_dim : Shape of the generator output n_units : Number of units in hidden layer reuse : Reuse the variables with tf.variable_scope alpha : leak parameter for leaky ReLU Returns ------- out: '''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.variable_scope(<span class="hljs-string"><span class="hljs-string">"generator"</span></span>, reuse= <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> is_train): <span class="hljs-comment"><span class="hljs-comment"># First FC layer --&gt; 8x8x1024 fc1 = tf.layers.dense(z, 8*8*1024) # Reshape it fc1 = tf.reshape(fc1, (-1, 8, 8, 1024)) # Leaky ReLU fc1 = tf.nn.leaky_relu(fc1, alpha=alpha) # Transposed conv 1 --&gt; BatchNorm --&gt; LeakyReLU # 8x8x1024 --&gt; 16x16x512 trans_conv1 = tf.layers.conv2d_transpose(inputs = fc1, filters = 512, kernel_size = [5,5], strides = [2,2], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name="trans_conv1") batch_trans_conv1 = tf.layers.batch_normalization(inputs = trans_conv1, training=is_train, epsilon=1e-5, name="batch_trans_conv1") trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1, alpha=alpha, name="trans_conv1_out") # Transposed conv 2 --&gt; BatchNorm --&gt; LeakyReLU # 16x16x512 --&gt; 32x32x256 trans_conv2 = tf.layers.conv2d_transpose(inputs = trans_conv1_out, filters = 256, kernel_size = [5,5], strides = [2,2], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name="trans_conv2") batch_trans_conv2 = tf.layers.batch_normalization(inputs = trans_conv2, training=is_train, epsilon=1e-5, name="batch_trans_conv2") trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2, alpha=alpha, name="trans_conv2_out") # Transposed conv 3 --&gt; BatchNorm --&gt; LeakyReLU # 32x32x256 --&gt; 64x64x128 trans_conv3 = tf.layers.conv2d_transpose(inputs = trans_conv2_out, filters = 128, kernel_size = [5,5], strides = [2,2], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name="trans_conv3") batch_trans_conv3 = tf.layers.batch_normalization(inputs = trans_conv3, training=is_train, epsilon=1e-5, name="batch_trans_conv3") trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3, alpha=alpha, name="trans_conv3_out") # Transposed conv 4 --&gt; BatchNorm --&gt; LeakyReLU # 64x64x128 --&gt; 128x128x64 trans_conv4 = tf.layers.conv2d_transpose(inputs = trans_conv3_out, filters = 64, kernel_size = [5,5], strides = [2,2], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name="trans_conv4") batch_trans_conv4 = tf.layers.batch_normalization(inputs = trans_conv4, training=is_train, epsilon=1e-5, name="batch_trans_conv4") trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4, alpha=alpha, name="trans_conv4_out") # Transposed conv 5 --&gt; tanh # 128x128x64 --&gt; 128x128x3 logits = tf.layers.conv2d_transpose(inputs = trans_conv4_out, filters = 3, kernel_size = [5,5], strides = [1,1], padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name="logits") out = tf.tanh(logits, name="out") return out</span></span></code> </pre> <br><h4>  Kerugian dalam diskriminator dan generator </h4><br>  Karena kita melatih generator dan diskriminator, kita perlu menghitung kerugian untuk kedua jaringan saraf.  Diskriminator harus memberi 1 ketika "menganggap" gambar itu nyata, dan 0 jika gambar itu palsu.  Sesuai dengan ini dan Anda perlu mengkonfigurasi kerugian.  Kerugian diskriminator dihitung sebagai jumlah kerugian untuk citra asli dan palsu: <br><br> <code>d_loss = d_loss_real + d_loss_fake</code> <br> <br>  di mana <code>d_loss_real</code> adalah kerugian ketika diskriminator menganggap gambar itu salah, tetapi sebenarnya itu nyata.  Itu dihitung sebagai berikut: <br><br><ul><li>  Kami menggunakan <code>d_logits_real</code> , semua label sama dengan 1 (karena semua data adalah nyata). </li><li>  <code>labels = tf.ones_like(tensor) * (1 - smooth)</code> .  Mari kita gunakan label smoothing: turunkan nilai label dari 1,0 ke 0,9 untuk membantu pembeda menggeneralisasi lebih baik. </li></ul><br>  <code>d_loss_fake</code> adalah kerugian ketika diskriminator menganggap gambar itu nyata, tetapi sebenarnya itu palsu. <br><br><ul><li>  Kami menggunakan <code>d_logits_fake</code> , semua label adalah 0. </li></ul><br>  Untuk kehilangan generator, <code>d_logits_fake</code> dari diskriminator digunakan.  Kali ini, semua label adalah 1, karena generator ingin mengelabui pembeda. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_real, input_z, output_channel_dim, alpha)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Get the loss for the discriminator and generator :param input_real: Images from the real dataset :param input_z: Z input :param out_channel_dim: The number of channels in the output image :return: A tuple of (discriminator loss, generator loss) """</span></span> <span class="hljs-comment"><span class="hljs-comment"># Generator network here g_model = generator(input_z, output_channel_dim) # g_model is the generator output # Discriminator network here d_model_real, d_logits_real = discriminator(input_real, alpha=alpha) d_model_fake, d_logits_fake = discriminator(g_model,is_reuse=True, alpha=alpha) # Calculate losses d_loss_real = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_model_real))) d_loss_fake = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_model_fake))) d_loss = d_loss_real + d_loss_fake g_loss = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake))) return d_loss, g_loss</span></span></code> </pre> <br><h4>  Pengoptimal </h4><br>  Setelah menghitung kerugian, generator dan pembeda harus diperbarui secara individual.  Untuk melakukan ini, gunakan <code>tf.trainable_variables()</code> membuat daftar semua variabel yang didefinisikan dalam grafik kami. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model_optimizers</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(d_loss, g_loss, lr_D, lr_G, beta1)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Get optimization operations :param d_loss: Discriminator loss Tensor :param g_loss: Generator loss Tensor :param learning_rate: Learning Rate Placeholder :param beta1: The exponential decay rate for the 1st moment in the optimizer :return: A tuple of (discriminator training operation, generator training operation) """</span></span> <span class="hljs-comment"><span class="hljs-comment"># Get the trainable_variables, split into G and D parts t_vars = tf.trainable_variables() g_vars = [var for var in t_vars if var.name.startswith("generator")] d_vars = [var for var in t_vars if var.name.startswith("discriminator")] update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # Generator update gen_updates = [op for op in update_ops if op.name.startswith('generator')] # Optimizers with tf.control_dependencies(gen_updates): d_train_opt = tf.train.AdamOptimizer(learning_rate=lr_D, beta1=beta1).minimize(d_loss, var_list=d_vars) g_train_opt = tf.train.AdamOptimizer(learning_rate=lr_G, beta1=beta1).minimize(g_loss, var_list=g_vars) return d_train_opt, g_train_opt</span></span></code> </pre> <br><h4>  Pelatihan </h4><br>  Sekarang kami menerapkan fungsi pelatihan.  Idenya cukup sederhana: <br><br><ul><li>  Kami menyimpan model kami setiap lima periode (zaman). </li><li>  Kami menyimpan gambar dalam folder dengan gambar setiap 10 batch terlatih. </li><li>  Setiap 15 periode kami menampilkan <code>g_loss</code> , <code>d_loss</code> dan gambar yang dihasilkan.  Ini karena notebook Jupyter mungkin macet ketika menampilkan terlalu banyak gambar. </li><li>  Atau kita dapat langsung menghasilkan gambar nyata dengan memuat model yang disimpan (ini akan menghemat 20 jam pelatihan). </li></ul><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(epoch_count, batch_size, z_dim, learning_rate_D, learning_rate_G, beta1, get_batches, data_shape, data_image_mode, alpha)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Train the GAN :param epoch_count: Number of epochs :param batch_size: Batch Size :param z_dim: Z dimension :param learning_rate: Learning Rate :param beta1: The exponential decay rate for the 1st moment in the optimizer :param get_batches: Function to get batches :param data_shape: Shape of the data :param data_image_mode: The image mode to use for images ("RGB" or "L") """</span></span> <span class="hljs-comment"><span class="hljs-comment"># Create our input placeholders input_images, input_z, lr_G, lr_D = model_inputs(data_shape[1:], z_dim) # Losses d_loss, g_loss = model_loss(input_images, input_z, data_shape[3], alpha) # Optimizers d_opt, g_opt = model_optimizers(d_loss, g_loss, lr_D, lr_G, beta1) i = 0 version = "firstTrain" with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # Saver saver = tf.train.Saver() num_epoch = 0 if from_checkpoint == True: saver.restore(sess, "./models/model.ckpt") show_generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, True, False) else: for epoch_i in range(epoch_count): num_epoch += 1 if num_epoch % 5 == 0: # Save model every 5 epochs #if not os.path.exists("models/" + version): # os.makedirs("models/" + version) save_path = saver.save(sess, "./models/model.ckpt") print("Model saved") for batch_images in get_batches(batch_size): # Random noise batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim)) i += 1 # Run optimizers _ = sess.run(d_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_D: learning_rate_D}) _ = sess.run(g_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_G: learning_rate_G}) if i % 10 == 0: train_loss_d = d_loss.eval({input_z: batch_z, input_images: batch_images}) train_loss_g = g_loss.eval({input_z: batch_z}) # Save it image_name = str(i) + ".jpg" image_path = "./images/" + image_name show_generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, True, False) # Print every 5 epochs (for stability overwize the jupyter notebook will bug) if i % 1500 == 0: image_name = str(i) + ".jpg" image_path = "./images/" + image_name print("Epoch {}/{}...".format(epoch_i+1, epochs), "Discriminator Loss: {:.4f}...".format(train_loss_d), "Generator Loss: {:.4f}".format(train_loss_g)) show_generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, False, True) return losses, samples</span></span></code> </pre> <br><h4>  Bagaimana cara menjalankannya </h4><br>  Semua ini dapat berjalan langsung di komputer Anda jika Anda siap menunggu 10 tahun, jadi lebih baik menggunakan layanan GPU berbasis cloud seperti AWS atau FloydHub.  Secara pribadi, saya melatih DCGAN ini selama 20 jam di Microsoft Azure dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Deep Virtual Machine mereka</a> .  Saya tidak memiliki hubungan bisnis dengan Azure, saya hanya menyukai layanan pelanggan mereka. <br><br>  Jika Anda mengalami kesulitan menjalankan di mesin virtual, lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel yang</a> bagus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ini</a> . <br><br>  Jika Anda meningkatkan model, jangan ragu untuk melakukan permintaan penarikan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/02d/bf7/78d/02dbf778db1b4d64066fed444f385724.gif"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id416129/">https://habr.com/ru/post/id416129/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id416119/index.html">Posting Jumat pada hari Rabu: atas paket NPM yang paling "esensial"</a></li>
<li><a href="../id416121/index.html">Fujitsu Artificial Intelligence menghitung geometri bahan magnetik</a></li>
<li><a href="../id416123/index.html">Pengakuan barang di rak menggunakan jaringan saraf menggunakan teknologi Keras dan Tensorflow Object Detection API</a></li>
<li><a href="../id416125/index.html">Instalasi, pengaturan sistem dan kontrol untuk kamera</a></li>
<li><a href="../id416127/index.html">CUDA dan Remote GPU</a></li>
<li><a href="../id416131/index.html">Bagaimana menangani PD di Federasi Rusia dan tidak melanggar hukum</a></li>
<li><a href="../id416133/index.html">Pusat Data di Luar Negeri: Equinix LD8</a></li>
<li><a href="../id416135/index.html">Aplikasi GUI lebih kecil dari 1 kb</a></li>
<li><a href="../id416137/index.html">Zabbix sebagai pemindai keamanan</a></li>
<li><a href="../id416139/index.html">Otentikasi kuat sebagai bagian dari strategi GDPR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ùå üë©üèø‚Äçü§ù‚Äçüë©üèº üïí Mudar o Tinder para Kubernetes üë©üèø‚Äçüöí ü§Ω üÉè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nota perev. : Os funcion√°rios do Tinder recentemente compartilharam alguns dos detalhes t√©cnicos da migra√ß√£o de sua infraestrutura para o Kubernetes. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mudar o Tinder para Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/440278/">  <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: Os funcion√°rios do Tinder recentemente compartilharam alguns dos detalhes t√©cnicos da migra√ß√£o de sua infraestrutura para o Kubernetes.</i>  <i>O processo levou quase dois anos e resultou no lan√ßamento nos K8s de uma plataforma de grande escala, composta por 200 servi√ßos hospedados em 48 mil cont√™ineres.</i>  <i>Que dificuldades interessantes os engenheiros do Tinder enfrentaram e que resultados chegaram - leia esta tradu√ß√£o.</i> <br><br><img src="https://habrastorage.org/webt/uq/og/xd/uqogxdavfghsshnu8hvlszhubpe.png"><a name="habracut"></a><br><br><h2>  Porque </h2><br>  H√° quase dois anos, o Tinder decidiu mudar sua plataforma para o Kubernetes.  O Kubernetes permitiria √† equipe do Tinder cont√™iner e mudar para a opera√ß√£o com o m√≠nimo de esfor√ßo por meio de uma <i>implanta√ß√£o imut√°vel</i> .  Nesse caso, o conjunto de aplicativos, sua implanta√ß√£o e a pr√≥pria infraestrutura seriam determinados exclusivamente pelo c√≥digo. <br><br>  Tamb√©m procuramos uma solu√ß√£o para o problema de escalabilidade e estabilidade.  Quando o dimensionamento se tornou cr√≠tico, muitas vezes tivemos que esperar v√°rios minutos para iniciar novas inst√¢ncias do EC2.  Portanto, a ideia de lan√ßar cont√™ineres e come√ßar a servir o tr√°fego em segundos, em vez de minutos, se tornou muito atraente para n√≥s. <br><br>  O processo n√£o foi f√°cil.  Durante a migra√ß√£o, no in√≠cio de 2019, o cluster Kubernetes atingiu uma massa cr√≠tica e come√ßamos a enfrentar v√°rios problemas devido √† quantidade de tr√°fego, tamanho do cluster e DNS.  Nesta jornada, resolvemos muitos problemas interessantes relacionados √† transfer√™ncia de 200 servi√ßos e manuten√ß√£o do cluster Kubernetes, que consiste em 1000 n√≥s, 15.000 pods e 48.000 cont√™ineres em funcionamento. <br><br><h2>  Como </h2><br>  Desde janeiro de 2018, passamos por v√°rios est√°gios de migra√ß√£o.  Come√ßamos contendo todos os nossos servi√ßos e implantando-os nos ambientes de teste do Kubernetes.  Em outubro, iniciou o processo de transfer√™ncia met√≥dica de todos os servi√ßos existentes para o Kubernetes.  Em mar√ßo do ano seguinte, a "realoca√ß√£o" foi conclu√≠da e agora a plataforma Tinder roda exclusivamente no Kubernetes. <br><br><h3>  Crie imagens para o Kubernetes </h3><br>  Temos mais de 30 reposit√≥rios de c√≥digo-fonte para microsservi√ßos em execu√ß√£o em um cluster Kubernetes.  O c√≥digo nesses reposit√≥rios √© escrito em diferentes idiomas (por exemplo, Node.js, Java, Scala, Go) com muitos ambientes de tempo de execu√ß√£o para o mesmo idioma. <br><br>  O sistema de compila√ß√£o foi projetado para fornecer um "contexto de compila√ß√£o" totalmente personaliz√°vel para cada microsservi√ßo.  Geralmente consiste em um Dockerfile e uma lista de comandos do shell.  Seu conte√∫do √© totalmente personaliz√°vel e, ao mesmo tempo, todos esses contextos de compila√ß√£o s√£o gravados de acordo com um formato padronizado.  A padroniza√ß√£o de contextos de constru√ß√£o permite que um √∫nico sistema de constru√ß√£o lide com todos os microsservi√ßos. <br><br><img src="https://habrastorage.org/webt/qg/he/8h/qghe8hvhjmsnpwuivvebqk1ne04.png"><br>  <i>Figura 1-1.</i>  <i>Processo de constru√ß√£o padronizado por meio do construtor de cont√™iner (Construtor)</i> <br><br>  Para obter a m√°xima consist√™ncia entre os tempos de execu√ß√£o, o mesmo processo de constru√ß√£o √© usado durante o desenvolvimento e o teste.  Enfrentamos um problema muito interessante: tivemos que desenvolver uma maneira de garantir a consist√™ncia do ambiente de montagem em toda a plataforma.  Para fazer isso, todos os processos de montagem s√£o realizados dentro de um cont√™iner <i>Builder</i> especial. <br><br>  Sua implementa√ß√£o exigiu t√©cnicas avan√ßadas para trabalhar com o Docker.  O Builder herda o ID do usu√°rio local e os segredos (como a chave SSH, credenciais da AWS, etc.) necess√°rios para acessar os reposit√≥rios privados do Tinder.  Ele monta diret√≥rios locais que cont√™m a fonte para armazenar naturalmente artefatos de montagem.  Essa abordagem aprimora o desempenho, eliminando a necessidade de copiar artefatos de montagem entre o cont√™iner do Builder e o host.  Os artefatos de montagem armazenados podem ser reutilizados sem configura√ß√£o adicional. <br><br>  Para alguns servi√ßos, tivemos que criar outro cont√™iner para combinar o ambiente de compila√ß√£o com o tempo de execu√ß√£o (por exemplo, durante o processo de instala√ß√£o, a biblioteca bode do Node.js. gera artefatos bin√°rios espec√≠ficos da plataforma).  Durante a compila√ß√£o, os requisitos podem variar para diferentes servi√ßos, e o Dockerfile final √© compilado em tempo real. <br><br><h3>  Arquitetura e migra√ß√£o de cluster Kubernetes </h3><br><h4>  Gerenciamento de tamanho de cluster </h4><br>  Decidimos usar o <b>kube-aws</b> para implantar automaticamente o cluster nas inst√¢ncias do Amazon EC2.  No in√≠cio, tudo funcionava em um conjunto comum de n√≥s.  Rapidamente percebemos a necessidade de separar as cargas de trabalho por tamanho e tipo de inst√¢ncias para um uso mais eficiente dos recursos.  A l√≥gica era que o lan√ßamento de v√°rios pods multiencadeados carregados se mostrou mais previs√≠vel no desempenho do que sua coexist√™ncia com um grande n√∫mero de pods de encadeamento √∫nico. <br><br>  Como resultado, decidimos: <br><br><ul><li>  <i>m5.4xlarge</i> - para monitoramento (Prometheus); </li><li>  <i>c5.4xlarge</i> - para carga de trabalho do <i>Node.js.</i> (carga de trabalho de thread √∫nico); </li><li>  <i>c5.2xlarge</i> - para Java e Go (carga de trabalho multiencadeada); </li><li>  <i>c5.4xlarge</i> - para o painel de controle (3 n√≥s). </li></ul><br><h4>  A migra√ß√£o </h4><br>  Uma das etapas preparat√≥rias para migrar da infraestrutura antiga para o Kubernetes foi redirecionar a intera√ß√£o direta existente entre os servi√ßos para os novos balanceadores de carga (ELB, Elastic Load Balancers).  Eles foram criados em uma sub-rede espec√≠fica da nuvem privada virtual (VPC).  Essa sub-rede foi conectada ao Kubernetes VPC.  Isso nos permitiu migrar os m√≥dulos gradualmente, sem levar em conta a ordem espec√≠fica das depend√™ncias de servi√ßo. <br><br>  Esses pontos de extremidade foram criados usando conjuntos ponderados de registros DNS com CNAMEs apontando para cada novo ELB.  Para alternar, adicionamos um novo registro apontando para um novo ELB de servi√ßo Kubernetes com um peso de 0. Em seguida, definimos o Time To Live (TTL) do conjunto de registros como 0. Depois disso, os pesos novos e antigos foram ajustados lentamente e, eventualmente, 100% da carga foi perdida. para o novo servidor.  Ap√≥s a conclus√£o da troca, o valor TTL retornou a um n√≠vel mais adequado. <br><br>  Nossos m√≥dulos Java existentes lidavam com DNS TTL baixo, mas os aplicativos Node n√£o.  Um dos engenheiros reescreveu parte do c√≥digo do conjunto de conex√µes, agrupando-o em um gerente que atualizava os conjuntos a cada 60 segundos.  A abordagem escolhida funcionou muito bem e sem uma redu√ß√£o percept√≠vel no desempenho. <br><br><h2>  As li√ß√µes </h2><br><h3>  Restri√ß√µes de dispositivo de rede </h3><br>  Nas primeiras horas da manh√£ de 8 de janeiro de 2019, a plataforma Tinder caiu de repente.  Em resposta a um aumento n√£o relacionado na lat√™ncia da plataforma no in√≠cio da manh√£, o n√∫mero de pods e n√≥s no cluster aumentou.  Isso levou √† exaust√£o do cache ARP em todos os nossos n√≥s. <br><br>  Existem tr√™s op√ß√µes do Linux associadas ao cache do ARP: <br><br><img src="https://habrastorage.org/webt/fq/bp/av/fqbpavle6xhk1ryeup0nd-lrqm0.png"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fonte</a> ) <br><br>  <b>gc_thresh3</b> √© um limite r√≠gido.  A apar√™ncia no log de entradas do formul√°rio ‚Äúestouro de tabela vizinho‚Äù significava que, mesmo ap√≥s a coleta de lixo s√≠ncrona (GC) no cache do ARP, n√£o havia espa√ßo suficiente para armazenar o registro vizinho.  Nesse caso, o kernel simplesmente eliminou completamente o pacote. <br><br>  Usamos a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Flanela</a> como uma <i>malha de rede</i> no Kubernetes.  Pacotes s√£o transmitidos por VXLAN.  VXLAN √© um t√∫nel L2, erguido sobre uma rede L3.  A tecnologia usa o encapsulamento MAC-in-UDP (Protocolo de datagrama de endere√ßo MAC no usu√°rio) e permite expandir os segmentos de rede do 2¬∫ n√≠vel.  O protocolo de transporte na rede f√≠sica do data center √© IP mais UDP. <br><br> <a href=""><img src="https://habrastorage.org/webt/ad/vn/pl/advnplfowrh7mi-6otctfhzm2xs.png"></a> <br>  <i>Figura 2-1.</i>  <i>Gr√°fico de flanela ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">origem</a> )</i> <br><br><img src="https://habrastorage.org/webt/nz/ti/xz/nztixz_5aer3xofz2drri5uafb8.jpeg"><br>  <i>Figura 2‚Äì2.</i>  <i>Pacote VXLAN ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">origem</a> )</i> <br><br>  Cada n√≥ de trabalho do Kubernetes aloca um espa√ßo de endere√ßo virtual com mask / 24 do bloco maior / 9.  Para cada n√≥, isso <a href="">significa</a> uma entrada na tabela de roteamento, uma entrada na tabela ARP (na interface <i>flannel.1</i> ) e uma entrada na tabela de comuta√ß√£o (FDB).  Eles s√£o adicionados quando o n√≥ de trabalho √© iniciado pela primeira vez ou quando cada novo n√≥ √© detectado. <br><br>  Al√©m disso, a conex√£o n√≥-pod (ou pod-pod) passa pela interface <b>eth0</b> (como mostrado no diagrama de flanela acima).  Isso resulta em uma entrada adicional na tabela ARP para cada origem e destino correspondente do n√≥. <br><br>  Em nosso ambiente, esse tipo de comunica√ß√£o √© muito comum.  Para objetos do tipo de servi√ßo no Kubernetes, um ELB √© criado e o Kubernetes registra cada n√≥ no ELB.  O ELB n√£o sabe nada sobre os pods e o n√≥ selecionado pode n√£o ser o destino final do pacote.  O fato √© que, quando um n√≥ recebe um pacote do ELB, ele leva em considera√ß√£o as regras do <b>iptables</b> para um servi√ßo espec√≠fico e seleciona aleatoriamente o pod em outro n√≥. <br><br>  No momento da falha, o cluster tinha 605 n√≥s.  Pelas raz√µes <b>expostas</b> acima, isso foi suficiente para superar o valor <b>padr√£o de gc_thresh3</b> .  Quando isso acontece, n√£o apenas os pacotes come√ßam a ser descartados, mas todo o espa√ßo de endere√ßo virtual da Flanela com a m√°scara / 24 desaparece da tabela ARP.  As comunica√ß√µes de pod de n√≥ e as consultas DNS s√£o interrompidas (o DNS est√° hospedado em um cluster; consulte o restante deste artigo para obter detalhes). <br><br>  Para resolver esse problema, aumente os valores de <b>gc_thresh1</b> , <b>gc_thresh2</b> e <b>gc_thresh3</b> e reinicie o Flannel para registrar novamente as redes ausentes. <br><br><h4>  Escala de DNS inesperada </h4><br>  Durante o processo de migra√ß√£o, usamos o DNS ativamente para gerenciar o tr√°fego e gradualmente transferir servi√ßos da infraestrutura antiga para o Kubernetes.  Definimos valores TTL relativamente baixos para RecordSets relacionados no Route53.  Quando a infraestrutura antiga estava sendo executada em inst√¢ncias do EC2, nossa configura√ß√£o de resolvedor apontou para o DNS da Amazon.  Tomamos isso como garantido e o impacto do baixo TTL em nossos servi√ßos da Amazon (como o DynamoDB) passou quase despercebido. <br><br>  Como os servi√ßos foram migrados para o Kubernetes, descobrimos que o DNS lida com 250.000 consultas por segundo.  Como resultado, os aplicativos come√ßaram a experimentar tempos limites constantes e s√©rios para consultas de DNS.  Isso aconteceu apesar dos esfor√ßos incr√≠veis para otimizar e alternar o provedor de DNS para o CoreDNS (que atingiu 1.000 pods rodando em 120 n√∫cleos em pico de carga). <br><br>  Explorando outras causas e solu√ß√µes poss√≠veis, encontramos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo</a> descrevendo as condi√ß√µes de corrida que afetam a estrutura de filtragem de pacotes <b>netfilter</b> no Linux.  Os tempos limite observados, juntamente com o crescente contador <b>insert_failed</b> na interface Flannel, corresponderam √†s conclus√µes do artigo. <br><br>  O problema surge no est√°gio de convers√£o de endere√ßo de rede de origem e destino (SNAT e DNAT) e entrada subseq√ºente na tabela <b>conntrack</b> .  Uma das solu√ß√µes alternativas discutidas na empresa e propostas pela comunidade foi a transfer√™ncia do DNS para o pr√≥prio n√≥ de trabalho.  Nesse caso: <br><br><ul><li>  O SNAT n√£o √© necess√°rio porque o tr√°fego permanece dentro do n√≥.  Ele n√£o precisa ser roteado atrav√©s da interface <b>eth0</b> . </li><li>  O DNAT n√£o √© necess√°rio, porque o IP de destino √© local para o host e n√£o um pod selecionado aleatoriamente de acordo com as regras do <b>iptables</b> . </li></ul><br>  Decidimos seguir essa abordagem.  O CoreDNS foi implantado como DaemonSet no Kubernetes e implementamos um servidor DNS local no <b>resolv.conf de</b> cada pod, configurando o <b>sinalizador --cluster-dns</b> do comando <b>kubelet</b> .  Esta solu√ß√£o provou ser eficaz para tempos limite de DNS. <br><br>  No entanto, ainda observamos a perda de pacotes e um aumento no contador <b>insert_failed</b> na interface Flannel.  Essa situa√ß√£o continuou ap√≥s a introdu√ß√£o da solu√ß√£o alternativa, pois conseguimos excluir o SNAT e / ou DNAT apenas para o tr√°fego DNS.  As condi√ß√µes de corrida persistiram para outros tipos de tr√°fego.  Felizmente, a maioria dos nossos pacotes √© TCP e, quando ocorre um problema, eles s√£o simplesmente retransmitidos.  Ainda estamos tentando encontrar uma solu√ß√£o adequada para todos os tipos de tr√°fego. <br><br><h4>  Usando o enviado para um melhor equil√≠brio de carga </h4><br>  Ao migrar os servi√ßos de back-end para o Kubernetes, come√ßamos a sofrer uma carga desequilibrada entre os pods.  Descobrimos que, devido ao HTTP Keepalive, as conex√µes ELB permaneciam nos primeiros pods prontos para cada implanta√ß√£o de lan√ßamento.  Assim, a maior parte do tr√°fego passou por uma pequena porcentagem dos pods dispon√≠veis.  A primeira solu√ß√£o que testamos foi definir o par√¢metro MaxSurge para 100% em novas implanta√ß√µes para os piores casos.  O efeito foi insignificante e pouco promissor em termos de implanta√ß√µes maiores. <br><br>  Outra solu√ß√£o que usamos foi aumentar artificialmente as solicita√ß√µes de recursos para servi√ßos de miss√£o cr√≠tica.  Nesse caso, os pods adjacentes teriam mais espa√ßo de manobra do que outros pods pesados.  A longo prazo, tamb√©m n√£o funcionaria devido ao desperd√≠cio de recursos.  Al√©m disso, nossos aplicativos Node eram de thread √∫nico e, portanto, podiam usar apenas um n√∫cleo.  A √∫nica solu√ß√£o real era usar um melhor balanceamento de carga. <br><br>  H√° muito que desejamos apreciar plenamente o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">enviado</a> .  A situa√ß√£o atual nos permitiu implant√°-lo de uma maneira muito limitada e obter resultados imediatos.  O Envoy √© um proxy de s√©timo n√≠vel de c√≥digo aberto e alto desempenho, projetado para aplicativos SOA grandes.  Ele √© capaz de aplicar t√©cnicas avan√ßadas de balanceamento de carga, incluindo novas tentativas autom√°ticas, disjuntores e limites globais de velocidade.  <i>( <b>Nota</b> : <b>tradu√ß√£o</b> : para obter mais detalhes, consulte o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo recente</a> sobre o Istio - a malha de servi√ßo, baseada no Envoy.)</i> <br><br>  Criamos a seguinte configura√ß√£o: envie o side-car Envoy para cada pod e uma √∫nica rota e o cluster - conecte-se ao cont√™iner localmente por porta.  Para minimizar o potencial de cascata e manter um pequeno raio de "dano", usamos o pod park de proxy frontal da Envoy, um para cada Zona de Disponibilidade (AZ) para cada servi√ßo.  Eles se voltaram para um mecanismo simples de descoberta de servi√ßo escrito por um de nossos engenheiros, que simplesmente retornava uma lista de pods em cada AZ para um determinado servi√ßo. <br><br>  Em seguida, os representantes da frente de servi√ßo usaram esse mecanismo de descoberta de servi√ßo com um cluster e rota upstream.  Definimos tempos limites adequados, aumentamos todas as configura√ß√µes do disjuntor e adicionamos uma configura√ß√£o m√≠nima de repeti√ß√£o para ajudar com falhas √∫nicas e garantir implanta√ß√µes perfeitas.  Antes de cada um desses servi√ßos, enviamos um TCP ELB.  Mesmo que o keepalive de nossa camada principal de proxy permanecesse em alguns pods do Envoy, eles ainda poderiam lidar com a carga muito melhor e estavam prontos para equilibrar atrav√©s de pelo menos_request no backend. <br><br>  Para a implanta√ß√£o, usamos o gancho preStop nos pods de aplicativos e nos side-cars.  O gancho iniciou um erro ao verificar o status do terminal administrativo localizado no cont√™iner lateral e "dormiu" por um tempo para permitir a conclus√£o de conex√µes ativas. <br><br>  Um dos motivos pelos quais conseguimos avan√ßar t√£o rapidamente na solu√ß√£o de problemas est√° relacionado a m√©tricas detalhadas que conseguimos integrar facilmente em uma instala√ß√£o padr√£o do Prometheus.  Com eles, foi poss√≠vel ver exatamente o que estava acontecendo enquanto selecionamos os par√¢metros de configura√ß√£o e redistribu√≠mos o tr√°fego. <br><br>  Os resultados foram imediatos e √≥bvios.  Come√ßamos com os servi√ßos mais desequilibrados e, no momento, ele j√° funciona antes dos 12 servi√ßos mais importantes do cluster.  Este ano, planejamos mudar para uma malha de servi√ßo completa com descoberta de servi√ßo mais avan√ßada, quebra de circuito, detec√ß√£o de outlier, limita√ß√£o de velocidade e rastreamento. <br><br> <a href=""><img src="https://habrastorage.org/webt/gy/yg/6s/gyyg6s_l8nlpbktislqy9jp9fma.png" alt="imagem"></a> <br>  <i>Figura 3-1.</i>  <i>Converg√™ncia da CPU de um servi√ßo durante a transi√ß√£o para o Envoy</i> <br><br><img src="https://habrastorage.org/webt/lf/iw/pn/lfiwpneg1uvaruk85ghgcbhoghy.png"><br><br><img src="https://habrastorage.org/webt/ud/ug/8m/udug8mekxc36ql2vohzl-snp3vu.png"><br><br><h2>  Resultado final </h2><br>  Gra√ßas √† nossa experi√™ncia e pesquisas adicionais, constru√≠mos uma equipe de infraestrutura forte, com boas habilidades em projetar, implantar e operar grandes clusters Kubernetes.  Agora, todos os engenheiros do Tinder t√™m o conhecimento e a experi√™ncia em como empacotar cont√™ineres e implantar aplicativos no Kubernetes. <br><br>  Quando surgiu a necessidade de capacidades adicionais na infraestrutura antiga, tivemos que esperar alguns minutos para lan√ßar novas inst√¢ncias do EC2.  Agora, os cont√™ineres iniciam e come√ßam a processar o tr√°fego por v√°rios segundos, em vez de minutos.  Planejar v√°rios cont√™ineres em uma √∫nica inst√¢ncia do EC2 tamb√©m fornece uma concentra√ß√£o horizontal aprimorada.  Como resultado, em 2019, prevemos uma redu√ß√£o significativa nos custos de EC2 em compara√ß√£o com o ano passado. <br><br>  Demorou quase dois anos para migrar, mas a conclu√≠mos em mar√ßo de 2019.  Atualmente, a plataforma Tinder √© executada exclusivamente no cluster Kubernetes, que consiste em 200 servi√ßos, 1000 n√≥s, 15.000 pods e 48.000 cont√™ineres em execu√ß√£o.  A infraestrutura n√£o √© mais da exclusiva responsabilidade das equipes operacionais.  Todos os nossos engenheiros compartilham essa responsabilidade e controlam o processo de cria√ß√£o e implanta√ß√£o de seus aplicativos usando apenas c√≥digo. <br><br><h2>  PS do tradutor </h2><br>  Leia tamb√©m nossa s√©rie de artigos em nosso blog: <br><br><ul><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 1: <b>4.200 lares e TessMaster no eBay</b></a> . ‚Äù </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 2: <b>Concur e SAP</b></a> . " </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 3: <b>GitHub</b></a> . " </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 4: <b>SoundCloud (autores Prometheus)</b></a> . " </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 5: <b>Monzo Digital Bank.</b></a> ‚Äù </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 6: <b>BlaBlaCar</b></a> . " </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 7: <b>BlackRock</b></a> . " </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 8: <b>Huawei</b></a> ". </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 9: <b>Clusters CERN e 210 K8s.</b></a> ‚Äù </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hist√≥rias de sucesso da Kubernetes em produ√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 10: <b>Reddit</b></a> . " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt440278/">https://habr.com/ru/post/pt440278/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt440268/index.html">Desvio sonoro: mecanismo para gerar cliques ultrass√¥nicos em tra√ßas noturnas como prote√ß√£o contra morcegos</a></li>
<li><a href="../pt440270/index.html">Consideramos um cronograma de turnos na mente</a></li>
<li><a href="../pt440272/index.html">O Mobile Opera possui uma VPN gratuita</a></li>
<li><a href="../pt440274/index.html">Criando um servi√ßo de moeda privada usando o Exonum</a></li>
<li><a href="../pt440276/index.html">Depura√ß√£o de front-end e back-end</a></li>
<li><a href="../pt440280/index.html">An√°lise do Software Livre Android</a></li>
<li><a href="../pt440282/index.html">Estruturas da Web Python mais r√°pidas em 2019</a></li>
<li><a href="../pt440284/index.html">Uma nova vis√£o da exibi√ß√£o de di√°logos no Android</a></li>
<li><a href="../pt440286/index.html">Ru√≠do Perlin, gera√ß√£o de conte√∫do processual e espa√ßo interessante</a></li>
<li><a href="../pt440288/index.html">Seguran√ßa da Internet das coisas. Edi√ß√£o 1. Rel√≥gios inteligentes, rastreadores de fitness e balan√ßas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
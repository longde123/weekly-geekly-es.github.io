<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö† üëÇüèø üò£ Avalia√ß√£o de Keras para TensorFlow üë®üèº‚Äçüöí üèéÔ∏è üé°</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Tradu√ß√£o do guia de vis√£o geral do Tensorflow.org. Este guia fornecer√° o b√°sico para come√ßar a usar o Keras. A leitura leva 10 minutos. 

 Importar tf...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Avalia√ß√£o de Keras para TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482126/"><img src="https://habrastorage.org/webt/wz/o5/gm/wzo5gmjyybfdr1ea_lwtrhsjzvw.jpeg"><br><br>  Tradu√ß√£o do guia de vis√£o geral do Tensorflow.org.  Este guia fornecer√° o b√°sico para come√ßar a usar o Keras.  A leitura leva 10 minutos. <br><a name="habracut"></a><br><h2>  Importar tf.keras </h2><br>  <code>tf.keras</code> √© uma implementa√ß√£o da especifica√ß√£o da API TensorFlow Keras.  Essa √© uma API de alto n√≠vel para modelos de constru√ß√£o e treinamento que inclui suporte de primeira classe para funcionalidades espec√≠ficas do TensorFlow, como <i>execu√ß√£o</i> <code>tf.data</code> , pipelines <code>tf.data</code> e <i>Estimadores</i> .  <code>tf.keras</code> facilita o uso do TensorFlow sem sacrificar a flexibilidade e o desempenho. <br><br>  Para come√ßar, importe <code>tf.keras</code> como parte da sua configura√ß√£o do TensorFlow: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras</code> </pre> <br>  <code>tf.keras</code> pode executar qualquer c√≥digo compat√≠vel com Keras, mas lembre-se: <br><br><ul><li>  A vers√£o do <code>tf.keras</code> na vers√£o mais recente do TensorFlow pode ser diferente da vers√£o mais recente do <code>keras</code> no PyPI.  Confira <code>tf.keras.__version__</code> . </li><li>  Quando voc√™ salva pesos de modelo, <code>tf.keras</code> faz isso por padr√£o no formato de ponto de verifica√ß√£o.  Passe o <code>save_format='h5'</code> para usar o HDF5 (ou adicione a extens√£o <code>.h5</code> ao <code>.h5</code> do arquivo). </li></ul><br><h2>  Construa um modelo simples </h2><br><h3>  Modelo sequencial </h3><br>  No Keras, voc√™ coleta <i>camadas</i> para criar <i>modelos</i> .  Um modelo √© (geralmente) um gr√°fico de camada.  O tipo mais comum de modelo √© a pilha de camadas: <code>tf.keras.Sequential</code> model. <br><br>  Constru√≠mos uma rede simples e totalmente conectada (ou seja, um perceptron multicamada): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers model = tf.keras.Sequential() <span class="hljs-comment"><span class="hljs-comment">#       64 : model.add(layers.Dense(64, activation='relu')) #   : model.add(layers.Dense(64, activation='relu')) #   softmax  10 : model.add(layers.Dense(10, activation='softmax'))</span></span></code> </pre> <br><h3>  Personalizar camadas </h3><br>  Muitas variedades de camadas <code>tf.keras.layers</code> est√£o <code>tf.keras.layers</code> .  A maioria deles usa um construtor de argumento comum: <br><br><ul><li>  <code>activation</code> : define a fun√ß√£o de ativa√ß√£o para a camada.  Este par√¢metro especifica o nome da fun√ß√£o interna ou do objeto chamado.  O par√¢metro n√£o possui valor padr√£o. </li><li>  <code>kernel_initializer</code> e <code>bias_initializer</code> : esquemas de inicializa√ß√£o que criam pesos de camada (core e shift).  Este par√¢metro pode ser o nome ou o objeto chamado.  O inicializador padr√£o √© <code>"Glorot uniform"</code> . </li><li>  <code>kernel_regularizer</code> e <code>bias_regularizer</code> : esquemas de regulariza√ß√£o adicionados aos pesos da camada (n√∫cleo e deslocamento), como regulariza√ß√£o L1 ou L2.  Por padr√£o, a regulariza√ß√£o n√£o est√° definida. </li></ul><br>  Os seguintes exemplos de inst√¢ncias das camadas `tf.keras.layers.Dense` usam argumentos construtores: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : layers.Dense(64, activation='sigmoid') # : layers.Dense(64, activation=tf.keras.activations.sigmoid) #     L1   0.01    : layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01)) #     L2   0.01    : layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01)) #        : layers.Dense(64, kernel_initializer='orthogonal') #        2.0: layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))</span></span></code> </pre> <br><h2>  Treinamento e avalia√ß√£o </h2><br><h3>  Configura√ß√£o de treinamento </h3><br>  Ap√≥s a constru√ß√£o do modelo, configure o processo de aprendizado chamando o m√©todo <code>compile</code> : <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ <span class="hljs-comment"><span class="hljs-comment">#     64   : layers.Dense(64, activation='relu', input_shape=(32,)), #  : layers.Dense(64, activation='relu'), #   softmax  10 : layers.Dense(10, activation='softmax')]) model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])</span></span></code> </pre> <br>  <code>tf.keras.Model.compile</code> aceita tr√™s argumentos importantes: <br><br><ul><li>  <code>optimizer</code> : este objeto define o procedimento de treinamento.  Passe inst√¢ncias do otimizador do m√≥dulo <code>tf.keras.optimizers</code> , como <code>tf.keras.optimizers.Adam</code> ou <code>tf.keras.optimizers.SGD</code> .  Se voc√™ quiser apenas usar as op√ß√µes padr√£o, tamb√©m poder√° especificar otimizadores com palavras-chave como <code>'adam'</code> ou <code>'sgd'</code> . </li><li>  <code>loss</code> : √© uma fun√ß√£o minimizada no processo de aprendizagem.  Entre as varia√ß√µes comuns est√£o o erro padr√£o ( <code>mse</code> ), <code>categorical_crossentropy</code> , <code>binary_crossentropy</code> .  As fun√ß√µes de perda s√£o especificadas pelo nome ou passando o objeto chamado do m√≥dulo <code>tf.keras.losses</code> . </li><li>  <code>metrics</code> : usadas para monitorar o treinamento.  Estes s√£o nomes de sequ√™ncia ou objetos chamados do m√≥dulo <code>tf.keras.metrics</code> . </li><li>  Al√©m disso, para garantir que o modelo seja treinado e avaliado com avidez, verifique se voc√™ passa o par√¢metro <code>run_eagerly=True</code> para o compilador </li></ul><br>  A seguir, veremos alguns exemplos de configura√ß√£o de modelo para treinamento: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       . model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='mse', # mean squared error metrics=['mae']) # mean absolute error #     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])</span></span></code> </pre> <br><h3>  Aprendendo com os dados do NumPy </h3><br>  Para conjuntos de dados menores, use as matrizes de mem√≥ria do NumPy para treinar e avaliar o modelo.  O modelo √© "treinado" em dados de treinamento usando o m√©todo `fit`: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np data = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) labels = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) model.fit(data, labels, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>)</code> </pre> <br>  <code>tf.keras.Model.fit</code> usa tr√™s argumentos importantes: <br><br><ul><li>  <code>epochs</code> : o aprendizado √© dividido em * √©pocas *.  A era √© uma itera√ß√£o em todos os dados de entrada (isso √© feito em pequenos lotes). </li><li>  <code>batch_size</code> : ao transmitir dados do NumPy, o modelo divide os dados em blocos menores (lotes) e itera sobre esses blocos durante o treinamento.  Este n√∫mero indica o tamanho de cada bloco de dados.  Lembre-se de que o √∫ltimo bloco pode ser menor se o n√∫mero total de registros n√£o for dividido pelo tamanho do lote. </li><li>  <code>validation_data</code> : ao prototipar um modelo, voc√™ deseja acompanhar facilmente seu desempenho nos dados de valida√ß√£o.  Passar uma tupla de dados e r√≥tulos de entrada com esse argumento permite que o modelo exiba os valores da fun√ß√£o de perda e as m√©tricas no modo de sa√≠da para os dados transmitidos no final de cada era. </li></ul><br>  Aqui est√° um exemplo usando <code>validation_data</code> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np data = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) labels = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) val_data = np.random.random((<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) val_labels = np.random.random((<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) model.fit(data, labels, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, validation_data=(val_data, val_labels))</code> </pre> <br><h3>  Treinamento usando conjuntos de dados tf.data </h3><br>  Use a API de conjuntos de dados para dimensionar grandes bancos de dados ou treinamento em v√°rios dispositivos.  Passe a inst√¢ncia de `tf.data.Dataset` para o m√©todo <code>fit</code> : <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(32) model.fit(dataset, epochs=10)</span></span></code> </pre> <br>  Como o <code>Dataset</code> fornece dados em lotes, esse trecho de c√≥digo n√£o requer o argumento <code>batch_size</code> . <br><br>  Os conjuntos de dados tamb√©m podem ser usados ‚Äã‚Äãpara validar: <br><br><pre> <code class="python hljs">dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels)) val_dataset = val_dataset.batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) model.fit(dataset, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, validation_data=val_dataset)</code> </pre> <br><h3>  Avalia√ß√£o e previs√£o </h3><br>  Os <code>tf.keras.Model.predict</code> e <code>tf.keras.Model.predict</code> podem usar os <code>tf.data.Dataset</code> NumPy e <code>tf.data.Dataset</code> . <br><br>  √â assim que voc√™ pode <i>estimar as</i> perdas no modo de sa√≠da e nas m√©tricas para os dados fornecidos: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   Numpy data = np.random.random((1000, 32)) labels = np.random.random((1000, 10)) model.evaluate(data, labels, batch_size=32) #   dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(32) model.evaluate(dataset)</span></span></code> </pre> <br>  E aqui est√° como <i>prever a</i> sa√≠da do √∫ltimo n√≠vel no modo de sa√≠da para os dados fornecidos como uma matriz NumPy: <br><br><h2>  Construindo modelos complexos </h2><br><h3>  A API Funcional </h3><br>  O modelo <code>tf.keras.Sequential</code> √© uma pilha de camadas simples com a qual voc√™ n√£o pode imaginar um modelo arbitr√°rio.  Use a API funcional Keras para criar topologias de modelo complexas, como: <br><br><ul><li>  V√°rios modelos de entrada </li><li>  Modelos com v√°rias sa√≠das, </li><li>  Modelos com camadas comuns (a mesma camada √© chamada v√°rias vezes), </li><li>  Modelos com fluxos de dados inconsistentes (por exemplo, rela√ß√µes residuais). </li></ul><br>  A constru√ß√£o de um modelo com uma API funcional funciona da seguinte maneira: <br><br><ol><li>  A inst√¢ncia da camada √© pass√≠vel de chamada e retorna um tensor. </li><li>  Os tensores de entrada e sa√≠da s√£o usados ‚Äã‚Äãpara determinar a inst√¢ncia de <code>tf.keras.Model</code> </li><li>  Este modelo √© treinado exatamente como o modelo `Sequencial`. </li></ol><br>  O exemplo a seguir usa a API funcional para criar uma rede simples e totalmente conectada: <br><br><pre> <code class="python hljs">inputs = tf.keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)) <span class="hljs-comment"><span class="hljs-comment">#    #        . x = layers.Dense(64, activation='relu')(inputs) x = layers.Dense(64, activation='relu')(x) predictions = layers.Dense(10, activation='softmax')(x)</span></span></code> </pre> <br>  Crie uma inst√¢ncia do modelo com essas entradas e sa√≠das. <br><br><pre> <code class="python hljs">model = tf.keras.Model(inputs=inputs, outputs=predictions) <span class="hljs-comment"><span class="hljs-comment">#     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5  model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h3>  Modelos de subclassifica√ß√£o </h3><br>  Crie um modelo totalmente personaliz√°vel usando a subclasse <code>tf.keras.Model</code> e definindo sua pr√≥pria distribui√ß√£o direta.  Crie camadas no m√©todo <code>__init__</code> e defina-as como atributos da inst√¢ncia da classe.  Defina a propaga√ß√£o direta no m√©todo de <code>call</code> . <br><br>  A subclassifica√ß√£o de um modelo √© especialmente √∫til quando a execu√ß√£o r√°pida √© ativada, pois permite escrever imperativamente a distribui√ß√£o direta. <br><br>  Nota: se voc√™ deseja que seu modelo <i>sempre seja</i> executado imperativamente, √© poss√≠vel definir <code>dynamic=True</code> quando chamar o <code>super</code> construtor. <br><blockquote>  Ponto principal: use a API correta para funcionar.  Embora a subclasse de um modelo forne√ßa flexibilidade, √© necess√°rio pagar por ele com maior complexidade e maior potencial para erros personalizados.  Se poss√≠vel, escolha a API funcional. </blockquote>  O exemplo a seguir mostra um modelo tf.keras.Model subclassificado usando distribui√ß√£o direta customizada, que n√£o precisa ser imperativa: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModel</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(tf.keras.Model)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, num_classes=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(MyModel, self).__init__(name=<span class="hljs-string"><span class="hljs-string">'my_model'</span></span>) self.num_classes = num_classes <span class="hljs-comment"><span class="hljs-comment">#    . self.dense_1 = layers.Dense(32, activation='relu') self.dense_2 = layers.Dense(num_classes, activation='sigmoid') def call(self, inputs): #     , #      ( `__init__`). x = self.dense_1(inputs) return self.dense_2(x)</span></span></code> </pre> <br>  Crie uma inst√¢ncia da nova classe de modelo: <br><br><pre> <code class="python hljs">model = MyModel(num_classes=<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-comment"><span class="hljs-comment">#     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5 . model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h3>  Camadas personalizadas </h3><br>  Crie uma camada personalizada subclassificando <code>tf.keras.layers.Layer</code> e implementando os seguintes m√©todos: <br><br><ul><li>  <code>__init__</code> : especifique opcionalmente as subcamadas a serem usadas nesta camada. </li><li>  * <code>build</code> : Crie pesos da camada.  Adicione pesos usando o m√©todo <code>add_weight</code> </li><li>  <code>call</code> : Defina distribui√ß√£o direta. </li><li>  Opcionalmente, a camada pode ser serializada implementando o m√©todo <code>get_config</code> e o <code>from_config</code> classe <code>from_config</code> . </li></ul><br>  Abaixo est√° um exemplo de uma camada de usu√°rio que multiplica a matriz ( <code>matmul</code> ) alimentada na entrada pela matriz do kernel: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyLayer</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output_dim, **kwargs)</span></span></span><span class="hljs-function">:</span></span> self.output_dim = output_dim super(MyLayer, self).__init__(**kwargs) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#       . self.kernel = self.add_weight(name='kernel', shape=(input_shape[1], self.output_dim), initializer='uniform', trainable=True) def call(self, inputs): return tf.matmul(inputs, self.kernel) def get_config(self): base_config = super(MyLayer, self).get_config() base_config['output_dim'] = self.output_dim return base_config @classmethod def from_config(cls, config): return cls(**config)</span></span></code> </pre><br>  Crie um modelo usando sua camada personalizada: <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ MyLayer(<span class="hljs-number"><span class="hljs-number">10</span></span>), layers.Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)]) <span class="hljs-comment"><span class="hljs-comment">#      model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5 . model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h2>  Kolbeki </h2><br>  Kolbek √© um objeto transferido para o modelo para personalizar e expandir seu comportamento durante o treinamento.  Voc√™ pode gravar seu pr√≥prio retorno de chamada personalizado ou usar os <code>tf.keras.callbacks</code> que incluem: <br><br>  <code>tf.keras.callbacks.ModelCheckpoint</code> : Salvando pontos de interrup√ß√£o do modelo em intervalos regulares. <br>  <code>tf.keras.callbacks.LearningRateScheduler</code> : altere dinamicamente a etapa de aprendizado. <br>  <code>tf.keras.callbacks.EarlyStopping</code> : Parando o treinamento quando o resultado da valida√ß√£o para de melhorar. <br>  <code>tf.keras.callbacks.TensorBoard:</code> Monitorar o comportamento do modelo usando <br>  Tensorboard <br><br>  Para usar <code>tf.keras.callbacks.Callback</code> , passe-o para o m√©todo de modelo de <code>fit</code> : <br><br><pre> <code class="python hljs">callbacks = [ <span class="hljs-comment"><span class="hljs-comment">#    `val_loss`     2  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'), #   TensorBoard   `./logs` directory tf.keras.callbacks.TensorBoard(log_dir='./logs') ] model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks, validation_data=(val_data, val_labels))</span></span></code> </pre> <br><h2>  Salvando e restaurando </h2><br><h3>  Salvando apenas valores de peso </h3><br>  Salve e carregue pesos do modelo usando <code>tf.keras.Model.save_weights</code> : <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)), layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)]) model.compile(optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.001</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     TensorFlow Checkpoint model.save_weights('./weights/my_model') #    #        . model.load_weights('./weights/my_model')</span></span></code> </pre> <br>  Por padr√£o, os pesos do modelo s√£o salvos no formato de ponto de verifica√ß√£o TensorFlow.  Os pesos tamb√©m podem ser salvos no formato Keras HDF5 (valor padr√£o para a implementa√ß√£o universal do Keras): <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     HDF5 model.save_weights('my_model.h5', save_format='h5') #    model.load_weights('my_model.h5')</span></span></code> </pre> <br><h3>  Salvando apenas a configura√ß√£o do modelo </h3><br>  A configura√ß√£o do modelo pode ser salva - isso serializa a arquitetura do modelo sem nenhum peso.  Uma configura√ß√£o salva pode restaurar e inicializar o mesmo modelo, mesmo sem o c√≥digo definindo o modelo original.  O Keras suporta os formatos de serializa√ß√£o JSON e YAML: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     JSON json_string = model.to_json() json_string</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pprint pprint.pprint(json.loads(json_string))</code> </pre> <br>  Restaurando um modelo (reinicializado) do JSON: <br><br><pre> <code class="python hljs">fresh_model = tf.keras.models.model_from_json(json_string)</code> </pre><br>  Serializar o modelo para YAML requer a instala√ß√£o de `pyyaml` <i>antes de importar o TensorFlow</i> : <br><br><pre> <code class="python hljs">yaml_string = model.to_yaml() print(yaml_string)</code> </pre> <br>  Restaurando um modelo do YAML: <br><br><pre> <code class="python hljs">fresh_model = tf.keras.models.model_from_yaml(yaml_string)</code> </pre> <br><blockquote>  Nota: modelos em subclasses n√£o s√£o serializ√°veis, porque sua arquitetura √© definida pelo c√≥digo Python no corpo do m√©todo `call`. </blockquote><br><h3>  Salvando o modelo inteiro em um arquivo </h3><br>  O modelo inteiro pode ser salvo em um arquivo que cont√©m os valores dos pesos, a configura√ß√£o do modelo e at√© a configura√ß√£o do otimizador.  Isso permitir√° que voc√™ defina um ponto de interrup√ß√£o do modelo e continue treinando posteriormente exatamente da mesma posi√ß√£o, mesmo sem acesso ao c√≥digo-fonte. <br><br><pre> <code class="plaintext hljs">#    model = tf.keras.Sequential([ layers.Dense(10, activation='softmax', input_shape=(32,)), layers.Dense(10, activation='softmax') ]) model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) model.fit(data, labels, batch_size=32, epochs=5) #      HDF5 model.save('my_model.h5') #         . model = tf.keras.models.load_model('my_model.h5')</code> </pre> <br><h2>  Execu√ß√£o ansiosa </h2><br>  A execu√ß√£o ansiosa √© um ambiente de programa√ß√£o imperativo que executa opera√ß√µes imediatamente.  Isso n√£o √© necess√°rio para o Keras, mas √© suportado pelo <code>tf.keras</code> e √© √∫til para verificar seu programa e depurar. <br><br>  Todos os modelos de constru√ß√£o da API `tf.keras` s√£o compat√≠veis com uma execu√ß√£o r√°pida.  Embora as APIs sequenciais e funcionais possam ser usadas, a execu√ß√£o r√°pida √© especialmente √∫til ao <i>subclassificar um modelo</i> e criar <i>camadas personalizadas</i> - essas APIs exigem que voc√™ escreva a distribui√ß√£o direta na forma de c√≥digo (em vez das APIs que criam modelos montando as camadas existentes). <br><br><h2>  Distribui√ß√£o </h2><br><h3>  GPUs m√∫ltiplas </h3><br>  <code>tf.keras</code> modelos <code>tf.keras</code> podem ser executados em v√°rias GPUs usando <code>tf.distribute.Strategy</code> .  Essa API fornece aprendizado distribu√≠do em v√°rias GPUs com pouca ou nenhuma altera√ß√£o no c√≥digo existente. <br><br>  Atualmente, <code>tf.distribute.MirroredStrategy</code> √∫nica estrat√©gia de distribui√ß√£o suportada.  <code>MirroredStrategy</code> replica gr√°ficos com <br>  aprendizado s√≠ncrono usando redu√ß√£o total em uma m√°quina.  Para usar ` <code>distribute.Strategy</code> , aninhe a instala√ß√£o, o design e a compila√ß√£o do otimizador <code>.scope()</code> <code>Strategy</code> <code>.scope()</code> `e, em seguida, treine o modelo. <br><br>  O exemplo a seguir distribui <code>tf.keras.Model</code> entre v√°rias GPUs na mesma m√°quina. <br><br>  Primeiro, definimos um modelo dentro da √°rea de uma estrat√©gia distribu√≠da: <br><br><pre> <code class="python hljs">strategy = tf.distribute.MirroredStrategy() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> strategy.scope(): model = tf.keras.Sequential() model.add(layers.Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">10</span></span>,))) model.add(layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)) optimizer = tf.keras.optimizers.SGD(<span class="hljs-number"><span class="hljs-number">0.2</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, optimizer=optimizer) model.summary()</code> </pre> <br>  Em seguida, treinamos o modelo nos dados, como de costume: <br><br><pre> <code class="python hljs">x = np.random.random((<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) y = np.random.randint(<span class="hljs-number"><span class="hljs-number">2</span></span>, size=(<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) x = tf.cast(x, tf.float32) dataset = tf.data.Dataset.from_tensor_slices((x, y)) dataset = dataset.shuffle(buffer_size=<span class="hljs-number"><span class="hljs-number">1024</span></span>).batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) model.fit(dataset, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  <i>Ap√≥s a verifica√ß√£o, a tradu√ß√£o tamb√©m aparecer√° no Tensorflow.org.</i>  <i>Se voc√™ deseja participar da tradu√ß√£o da documenta√ß√£o do site Tensorflow.org para o russo, entre em contato com um coment√°rio ou pessoal.</i>  <i>Quaisquer corre√ß√µes ou coment√°rios s√£o apreciados.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt482126/">https://habr.com/ru/post/pt482126/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt482104/index.html">Como lidar com os h√°bitos das pessoas programadas</a></li>
<li><a href="../pt482106/index.html">Habr Freelance 2019: resultados do ano</a></li>
<li><a href="../pt482108/index.html">Intelig√™ncia silenciosa. M√©todo para identificar poss√≠veis vulnerabilidades da WEB</a></li>
<li><a href="../pt482110/index.html">O Linux √© executado no meu cart√£o de visita</a></li>
<li><a href="../pt482114/index.html">Envie e-mails usando asyncio e aiohttp de um aplicativo Django</a></li>
<li><a href="../pt482128/index.html">gReebok detectado. O pr√≥prio dermatologista</a></li>
<li><a href="../pt482130/index.html">Cess√£o em larga escala de direitos para usu√°rios do dom√≠nio de diferentes florestas</a></li>
<li><a href="../pt482132/index.html">A c√≥pia do Tesla Cybertruck foi vista em Moscou. Este √© um ... LADA russo Samara</a></li>
<li><a href="../pt482134/index.html">Compara√ß√£o de h√≠bridos ou o que espera os propriet√°rios dos fones de ouvido Meze romenos por 84 990 e 239 990 rublos</a></li>
<li><a href="../pt482136/index.html">Como um projeto de monomarca entra no TOP derrotando agregadores e servi√ßos internos dos mecanismos de busca?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
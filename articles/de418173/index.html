<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👧🏿 👨‍💻 👨🏻‍🎨 Roundtrip für neuronale Netze oder eine Überprüfung der Verwendung von Auto-Encodern in der Textanalyse 🐏 🤾🏽 🤙🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir haben bereits im ersten Artikel unseres Unternehmensblogs darüber geschrieben, wie der Algorithmus zur Erkennung übertragbarer Kredite funktionier...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Roundtrip für neuronale Netze oder eine Überprüfung der Verwendung von Auto-Encodern in der Textanalyse</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/antiplagiat/blog/418173/"> Wir haben bereits im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ersten Artikel unseres Unternehmensblogs</a> darüber geschrieben, wie der Algorithmus zur Erkennung übertragbarer Kredite funktioniert.  Nur ein paar Absätze in diesem Artikel widmen sich dem Thema des Vergleichens von Texten, obwohl die Idee eine viel detailliertere Beschreibung verdient.  Wie Sie wissen, kann man jedoch nicht sofort über alles erzählen, obwohl man es wirklich will.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Oleg_Bakhteev</a> und ich haben diese Rezension geschrieben, um diesem Thema und der Architektur des Netzwerks namens " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Auto-Encoder</a> ", dem wir sehr herzliche Gefühle entgegenbringen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Tribut zu zollen</a> . <br><br><img src="https://habrastorage.org/webt/fs/ka/ec/fskaecgqanvbmtzhf4hdqdd0bhw.png"><br>  Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep Learning für NLP (ohne Magie)</a> <br><br>  Wie wir in diesem Artikel erwähnt haben, war der Vergleich von Texten „semantisch“ - wir haben nicht die Textfragmente selbst verglichen, sondern die ihnen entsprechenden Vektoren.  Solche Vektoren wurden als Ergebnis des Trainings eines neuronalen Netzwerks erhalten, das ein Textfragment beliebiger Länge in einen Vektor einer großen, aber festen Dimension zeigte.  Wie man eine solche Zuordnung erhält und wie man dem Netzwerk beibringt, die gewünschten Ergebnisse zu erzielen, ist ein separates Thema, das weiter unten erörtert wird. <br><a name="habracut"></a><br><h1>  Was ist ein Auto-Encoder? </h1><br>  Formal wird ein neuronales Netzwerk als Auto-Encoder (oder Auto-Encoder) bezeichnet, der trainiert, um am Netzwerkeingang empfangene Objekte wiederherzustellen. <br><img src="https://habrastorage.org/webt/jy/jw/ip/jyjwipnzwzlyidenzeovey3jba4.png"><br>  Der Auto-Encoder besteht aus zwei Teilen: einem Encoder <b>f</b> , der die Probe <b>X</b> in seine interne Darstellung <b>H</b> codiert, und einem Decoder <b>g</b> , der die ursprüngliche Probe wiederherstellt.  Daher versucht der Autocoder, die wiederhergestellte Version jedes Beispielobjekts mit dem ursprünglichen Objekt zu kombinieren. <br><br>  Beim Training eines Auto-Encoders wird die folgende Funktion minimiert: <br><img src="https://habrastorage.org/webt/9f/ay/cm/9faycmmbldgcxvehefjrurcusyq.png"><br><br>  Wobei <b>r</b> für die wiederhergestellte Version des Originalobjekts steht: <br><img src="https://habrastorage.org/webt/zf/oe/oi/zfoeoiwfxnrscvv0n5cv4keku5k.png"><br><br>  Betrachten Sie das Beispiel in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blog.keras.io</a> : <br><img src="https://habrastorage.org/webt/lw/wp/i_/lwwpi_kn0wyrduexhkqyrg9jttk.png"><br>  Das Netzwerk empfängt ein Objekt <b>x</b> als Eingabe (in unserem Fall die Nummer 2). <br><br>  Unser Netzwerk verschlüsselt dieses Objekt in einen verborgenen Zustand.  Dann wird gemäß dem latenten Zustand die Rekonstruktion des Objekts <b>r</b> wiederhergestellt, die x ähnlich sein sollte.  Wie wir sehen, ist das wiederhergestellte Bild (rechts) verschwommener geworden.  Dies erklärt sich aus der Tatsache, dass wir versuchen, nur die wichtigsten Zeichen des Objekts in einer verborgenen Ansicht zu halten, sodass das Objekt mit Verlusten wiederhergestellt wird. <br><br>  Das Autocoder-Modell ist nach dem Prinzip eines beschädigten Telefons trainiert, bei dem eine Person (Encoder) Informationen <b>(x</b> ) an die zweite Person (Decoder) überträgt und diese wiederum an die dritte Person <b>(r (x)) weiterleitet</b> . <br><br>  Einer der Hauptzwecke solcher Auto-Encoder besteht darin, die Dimension des Quellraums zu verringern.  Wenn es sich um Auto-Encoder handelt, merkt sich das Auto-Encoder durch das Trainingsverfahren für neuronale Netze selbst die Hauptmerkmale von Objekten, von denen es einfacher ist, die ursprünglichen Beispielobjekte wiederherzustellen. <br><br>  Hier können wir eine Analogie zur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Methode der Hauptkomponenten ziehen</a> : Dies ist eine Methode zur Reduzierung der Dimension, deren Ergebnis die Projektion der Probe auf einen Unterraum ist, in dem die Varianz dieser Probe maximal ist. <br><br>  In der Tat ist der Auto-Encoder eine Verallgemeinerung der Hauptkomponentenmethode: Wenn wir uns auf die Betrachtung linearer Modelle beschränken, geben der Auto-Encoder und die Hauptkomponentenmethode die gleichen Vektordarstellungen.  Der Unterschied ergibt sich, wenn wir komplexere Modelle, beispielsweise mehrschichtige, vollständig verbundene neuronale Netze, als Codierer und Decodierer betrachten. <br><br>  Ein Beispiel für einen Vergleich der Hauptkomponentenmethode und des Auto-Encoders finden Sie im Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reduzieren der Dimensionalität von Daten mit neuronalen Netzen</a> : <br><img src="https://habrastorage.org/webt/bj/ap/hq/bjaphq8tpjla39pbn2djsrm84y4.png"><br><br>  Hier werden die Ergebnisse des Trainings des Auto-Encoders und der Hauptkomponentenmethode zum Abtasten von Bildern menschlicher Gesichter demonstriert.  Die erste Zeile zeigt die Gesichter von Personen aus der Kontrollprobe, d.h.  aus einem speziell zurückgestellten Teil der Stichprobe, der von den Algorithmen im Lernprozess nicht verwendet wurde.  In der zweiten und dritten Zeile befinden sich die wiederhergestellten Bilder aus den verborgenen Zuständen des Auto-Encoders bzw. der Hauptkomponentenmethode derselben Dimension.  Hier können Sie deutlich sehen, wie viel besser der Auto-Encoder funktioniert hat. <br><br>  Im selben Artikel ein weiteres anschauliches Beispiel: Vergleich der Ergebnisse des Auto-Encoders und der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LSA-</a> Methode für die Aufgabe des Informationsabrufs.  Die LSA-Methode ist wie die Hauptkomponentenmethode eine klassische Methode des maschinellen Lernens und wird häufig bei Aufgaben im Zusammenhang mit der Verarbeitung natürlicher Sprache verwendet. <br><img src="https://habrastorage.org/webt/di/h5/j3/dih5j3wsflfohomgzzrjo9e6n7k.png"><br>  Die Abbildung zeigt eine 2D-Projektion mehrerer Dokumente, die mit dem Auto-Encoder und der LSA-Methode erstellt wurden.  Farben geben das Thema des Dokuments an.  Es ist ersichtlich, dass die Projektion vom Auto-Encoder Dokumente gut nach Themen aufschlüsselt, während der LSA ein viel lauteres Ergebnis erzeugt. <br><br>  Eine weitere wichtige Anwendung von Auto- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Encodern ist das Netzwerk-Pre-Training</a> .  Das Netzwerk-Pre-Training wird verwendet, wenn das optimierte Netzwerk tief genug ist.  In diesem Fall kann es ziemlich schwierig sein, das Netzwerk „von Grund auf neu“ zu trainieren. Daher wird zunächst das gesamte Netzwerk als eine Kette von Encodern dargestellt. <br><br>  Der Pre-Training-Algorithmus ist recht einfach: Für jede Schicht trainieren wir unseren eigenen Auto-Encoder und stellen dann ein, dass der Ausgang des nächsten Encoders gleichzeitig der Eingang für die nächste Netzwerkschicht ist.  Das resultierende Modell besteht aus einer Kette von Encodern, die darauf trainiert sind, die wichtigsten Merkmale von Objekten eifrig auf ihrer eigenen Ebene zu erhalten.  Das Vorschulungsprogramm wird im Folgenden vorgestellt: <br><img src="https://habrastorage.org/webt/yy/mc/ui/yymcuigpqgegoa_7gwndzfxulia.png"><br>  Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">psyyz10.github.io</a> <br><br>  Diese Struktur wird als gestapelter Autoencoder bezeichnet und häufig als „Übertaktung“ verwendet, um das vollständige Deep-Network-Modell weiter zu trainieren.  Die Motivation für ein solches Training eines neuronalen Netzwerks besteht darin, dass ein tiefes neuronales Netzwerk eine nicht konvexe Funktion ist: Während des Trainings eines Netzwerks kann die Optimierung von Parametern in einem lokalen Minimum „stecken bleiben“.  Durch das gierige Vortraining von Netzwerkparametern können Sie einen guten Ausgangspunkt für das endgültige Training finden und versuchen, solche lokalen Minima zu vermeiden. <br><br>  Natürlich haben wir nicht alle möglichen Strukturen berücksichtigt, da es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sparse Autoencoder</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Denoising Autoencoder</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Contractive Autoencoder</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reconstruction Contractive Autoencoder gibt</a> .  Sie unterscheiden sich untereinander durch die Verwendung verschiedener Fehlerfunktionen und Strafbegriffe.  Alle diese Architekturen verdienen unserer Meinung nach eine gesonderte Prüfung.  In unserem Artikel zeigen wir zunächst das allgemeine Konzept von Auto-Encodern und die spezifischen Aufgaben der Textanalyse, die damit gelöst werden. <br><br><h2>  Wie funktioniert es in Texten? </h2><br>  Wir wenden uns nun spezifischen Beispielen für die Verwendung von Autocodern für Textanalyse-Aufgaben zu.  Wir interessieren uns für beide Seiten der Anwendung - beide Modelle zum Erhalten interner Darstellungen und die Verwendung dieser internen Darstellungen als Attribute, zum Beispiel für das weitere Klassifizierungsproblem.  In Artikeln zu diesem Thema werden häufig Aufgaben wie die Stimmungsanalyse oder die Erkennung von Umformulierungen behandelt. Es gibt jedoch auch Arbeiten, die die Verwendung von Auto-Encodern zum Vergleichen von Texten in verschiedenen Sprachen oder zur maschinellen Übersetzung beschreiben. <br><br>  Bei den Aufgaben der Textanalyse ist das Objekt meistens der Satz, d.h.  geordnete Folge von Wörtern.  Somit empfängt der Auto-Encoder genau diese Folge von Wörtern oder vielmehr Vektordarstellungen dieser Wörter, die aus einem zuvor trainierten Modell stammen.  Was sind Vektordarstellungen von Wörtern, wurde Habré beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> hinreichend detailliert betrachtet.  Daher muss der Auto-Encoder, der eine Folge von Wörtern als Eingabe verwendet, eine interne Darstellung des gesamten Satzes trainieren, die den für uns wichtigen Merkmalen entspricht, basierend auf der Aufgabe.  Bei Problemen der Textanalyse müssen wir Sätze Vektoren so zuordnen, dass sie im Sinne einer Distanzfunktion nahe sind, meistens ein Kosinusmaß: <br><br><img src="https://habrastorage.org/webt/fs/ka/ec/fskaecgqanvbmtzhf4hdqdd0bhw.png"><br>  Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep Learning für NLP (ohne Magie)</a> <br><br>  Einer der ersten Autoren, der den erfolgreichen Einsatz von Auto-Encodern in der Textanalyse zeigte, war <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Richard Socher</a> . <br><br>  In seinem Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dynamisches Pooling und Entfalten rekursiver Autoencoder für die Paraphrase-Erkennung</a> beschreibt er eine neue Autocodierungsstruktur - Entfalten rekursiver Autoencoder (Unfolding RAE) (siehe Abbildung unten). <br><img src="https://habrastorage.org/webt/zn/va/o9/znvao90juxs6ywwmm5ywwe6nrdm.png"><br>  RAE entfalten <br><br>  Es wird angenommen, dass die Satzstruktur von einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">syntaktischen Parser</a> definiert wird.  Die einfachste Struktur wird betrachtet - die Struktur eines Binärbaums.  Ein solcher Baum besteht aus Blättern - Wörtern eines Fragments, internen Knoten (Verzweigungsknoten) - Phrasen und einem Endscheitelpunkt.  Unter Verwendung der Folge von Wörtern (x <sub>1</sub> , x <sub>2</sub> , x <sub>3</sub> ) als Eingabe (drei Vektordarstellungen von Wörtern in diesem Beispiel) codiert der Autocoder in diesem Fall sequentiell von rechts nach links Vektordarstellungen von Satzwörtern in Vektordarstellungen von Phrasen und dann in Vektoren Präsentation des gesamten Angebots.  Insbesondere verketten wir in diesem Beispiel zuerst die Vektoren x <sub>2</sub> und x <sub>3</sub> und multiplizieren sie dann mit der Matrix <i>W <sub>e</sub></i> mit der <i>verborgenen</i> Dimension <i>× 2</i> , wobei <i>versteckt</i> die Größe der verborgenen internen Darstellung ist, <i>sichtbar</i> ist die Dimension des <i>Wortvektors</i> .  Daher reduzieren wir die Dimension und fügen dann mithilfe der tanh-Funktion Nichtlinearität hinzu.  Im ersten Schritt erhalten wir eine versteckte Vektordarstellung für die Phrase zwei Wörter <i>x <sub>2</sub></i> und <i>x <sub>3</sub></i> : <i>h <sub>1</sub></i> = <i>tanh⁡ (W <sub>e</sub> [x <sub>2</sub> , x <sub>3</sub> ] + b <sub>e</sub> )</i> .  Im zweiten kombinieren wir es und das verbleibende Wort <i>h <sub>2</sub></i> = <i>tanh⁡ (W <sub>e</sub> [h <sub>1</sub> , x <sub>1</sub> ] + b <sub>e</sub> )</i> und erhalten eine Vektordarstellung für den gesamten Satz - <i>h <sub>2</sub></i> .  Wie oben erwähnt, müssen wir bei der Definition eines Auto-Encoders den Fehler zwischen Objekten und ihren wiederhergestellten Versionen minimieren.  In unserem Fall sind dies Wörter.  Nachdem wir die endgültige Vektordarstellung des gesamten Satzes <i>h <sub>2 erhalten haben</sub></i> , werden wir seine wiederhergestellten Versionen (x <sub>1</sub> ', x <sub>2</sub> ', x <sub>3</sub> ') dekodieren.  Der Decoder arbeitet hier nach dem gleichen Prinzip wie der Encoder, nur die Parametermatrix und der Verschiebungsvektor unterscheiden sich hier: <i>W <sub>d</sub></i> und <i>b <sub>d</sub></i> . <br><br>  Mit der Struktur eines Binärbaums können Sie Sätze beliebiger Länge in einen Vektor fester Dimension codieren. Wir kombinieren immer ein Vektorpaar derselben Dimension mit derselben Parametermatrix <i>W <sub>e</sub></i> .  Im Fall eines nicht-binären Baums müssen Sie die Matrizen nur im Voraus initialisieren, wenn Sie mehr als zwei Wörter kombinieren möchten - 3, 4, ... n. In diesem Fall hat die Matrix nur die <i>verborgene</i> Dimension <i>× unsichtbar</i> . <br><br>  Es ist bemerkenswert, dass in diesem Artikel trainierte Vektordarstellungen von Phrasen nicht nur zur Lösung des Klassifizierungsproblems verwendet werden - einige Sätze werden umformuliert oder nicht.  Die Daten eines Experiments zur Suche nach den nächsten Nachbarn werden ebenfalls dargestellt - nur basierend auf dem empfangenen Angebotsvektor werden die nächsten Vektoren in der Stichprobe gesucht, deren Bedeutung nahe beieinander liegt: <br><br><img src="https://habrastorage.org/webt/d6/pv/ae/d6pvaevnd18k2ouizgs3t9k0xbk.png"><br><br>  Niemand stört uns jedoch, andere Netzwerkarchitekturen zum Codieren und Decodieren zu verwenden, um Wörter nacheinander zu Sätzen zu kombinieren. <br><br>  Hier ist ein Beispiel aus einem NIPS 2017-Artikel - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deconvolutional Paragraph Representation Learning</a> : <br><img src="https://habrastorage.org/webt/g9/u7/0m/g9u70mec8rpyrbnxuqtnflyxcfo.png"><br><br>  Wir sehen, dass die Codierung der Probe <b>X</b> in die verborgene Darstellung <b>h unter</b> Verwendung eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Faltungs-Neuronalen Netzwerks</a> erfolgt und der Decodierer nach dem gleichen Prinzip arbeitet. <br><br>  Oder hier ist ein Beispiel für die Verwendung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GRU-GRU</a> im Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Überspringen von Gedankenvektoren</a> . <br><br>  Ein interessantes Merkmal hierbei ist, dass das Modell mit dreifachen Sätzen arbeitet: ( <i>s <sub>i-1</sub> , s <sub>i</sub> , s <sub>i + 1</sub></i> ).  Der Satz <i>s <sub>i</sub></i> wird unter Verwendung von Standard-GRU-Formeln codiert, und der Decodierer versucht unter Verwendung der internen Darstellungsinformationen <i>s <sub>i</sub></i> , <i>s <sub>i-1</sub></i> und <i>s <sub>i + 1</sub></i> ebenfalls unter Verwendung von GRU zu decodieren. <br><br><img src="https://habrastorage.org/webt/ed/od/-r/edod-radj66y43mbsgu31zxo7nu.png"><br><br>  Das Funktionsprinzip ähnelt in diesem Fall dem Standardmodell der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">maschinellen Übersetzung neuronaler Netze</a> , das nach dem Encoder-Decoder-Schema arbeitet.  Da wir hier jedoch keine zwei Sprachen haben, senden wir eine Phrase in einer Sprache an die Eingabe unserer Codiereinheit und versuchen, sie wiederherzustellen.  Während des Lernprozesses werden einige interne Qualitätsfunktionen minimiert (dies ist nicht immer ein Rekonstruktionsfehler). Bei Bedarf werden vorab trainierte Vektoren als Merkmale in einem anderen Problem verwendet. <br><br>  In einem weiteren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zweisprachige rekursive Autoencoder für die statistische maschinelle Übersetzung</a> , wird eine Architektur vorgestellt, die einen neuen Blick auf die maschinelle Übersetzung wirft.  Zunächst werden rekursive Autocoder für zwei Sprachen separat trainiert (gemäß dem oben beschriebenen Prinzip - wo Unfolding RAE eingeführt wurde).  Dann wird zwischen ihnen ein dritter Auto-Encoder trainiert - eine Zuordnung zwischen zwei Sprachen.  Eine solche Architektur hat einen klaren Vorteil: Wenn Sie Texte in verschiedenen Sprachen in einem gemeinsamen verborgenen Raum anzeigen, können Sie sie vergleichen, ohne die maschinelle Übersetzung als Zwischenschritt zu verwenden. <br><br><img src="https://habrastorage.org/webt/tj/rq/un/tjrqunxjtnbgsivzz7iohnm8ibs.png"><br><br>  Das Training von Auto-Encodern für Textfragmente findet sich häufig in Artikeln zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ranking-Training</a> .  Auch hier ist die Tatsache wichtig, dass wir die endgültige Funktion der Qualität des Rankings trainieren. Wir trainieren zuerst den Auto-Encoder, um die Vektoren der an die Netzwerkeingabe gesendeten Anforderungen und Antworten besser zu initialisieren. <br><br><img src="https://habrastorage.org/webt/5t/a1/qn/5ta1qnx9gqzl9dypb0t4nhgcjtg.jpeg"><br><br>  Und natürlich können wir <a href="">Variational Autoencoder</a> oder <a href="">VAEs nur</a> als generative Modelle erwähnen.  Am besten sehen Sie sich natürlich nur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesen Vortragseintrag von Yandex an</a> .  Es reicht aus, Folgendes zu sagen: Wenn wir Objekte aus dem verborgenen Raum eines herkömmlichen Auto-Encoders <i>erzeugen</i> möchten, ist die Qualität einer solchen Erzeugung gering, da wir nichts über die Verteilung der verborgenen Variablen wissen.  Sie können den Auto-Encoder jedoch sofort auf die Generierung trainieren und eine Verteilungsannahme einführen. <br><br>  Und dann können Sie mit VAE Texte aus diesem verborgenen Raum generieren, wie es beispielsweise die Autoren des Artikels <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Generieren von Sätzen aus einem kontinuierlichen Raum</a> oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einem hybriden Faltungsvariations-Autoencoder für die Texterzeugung tun</a> . <br><br>  Die generativen Eigenschaften von VAE eignen sich auch gut für Aufgaben, bei denen Texte in verschiedenen Sprachen verglichen werden. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ein Ansatz zur variablen automatischen Codierung zur Induzierung mehrsprachiger Worteinbettungen ist</a> ein hervorragendes Beispiel dafür. <br><br>  Abschließend möchten wir eine kleine Prognose abgeben.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repräsentationslernen</a> - Das Training in internen Repräsentationen mit genau VAE, insbesondere in Verbindung mit den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Generative Adversarial Networks</a> , ist einer der am weitesten entwickelten Ansätze der letzten Jahre. Dies lässt sich anhand der häufigsten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikelthemen</a> der neuesten Top- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ICLR 2018-Konferenzen zum</a> maschinellen Lernen beurteilen und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ICML 2018</a> .  Dies ist ziemlich logisch, da seine Verwendung dazu beigetragen hat, die Qualität bei einer Reihe von Aufgaben zu verbessern, und nicht nur bei Texten.  Aber das ist das Thema einer ganz anderen Rezension ... </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418173/">https://habr.com/ru/post/de418173/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418163/index.html">Produktionstests: Netflix Chaos Automation Platform</a></li>
<li><a href="../de418165/index.html">Quasar, Sobaken und Ungeziefer: Enthüllung von Details der laufenden Cyberspionagekampagne</a></li>
<li><a href="../de418167/index.html">ScadaPy: Fügen Sie das IEC 60870-5-104-Protokoll hinzu</a></li>
<li><a href="../de418169/index.html">Was ist neu in Veeam Availability Console 2.0 Update 1?</a></li>
<li><a href="../de418171/index.html">Auf welche Metriken sollten Sie sich verlassen, wenn Benutzer nur wenige Conversions auf der Website durchführen?</a></li>
<li><a href="../de418177/index.html">Bearbeiten von .heic-Bildern ohne Farbverlust</a></li>
<li><a href="../de418183/index.html">Anwendung der Sprachanalyse in der Wirtschaft</a></li>
<li><a href="../de418185/index.html">Eine Autopsie-Geschichte: Wie wir Hancitor rückgängig gemacht haben</a></li>
<li><a href="../de418187/index.html">In Amerika wurde vorgeschlagen, alle Bibliotheken durch Amazon-Hubs zu ersetzen. Die Öffentlichkeit ist empört</a></li>
<li><a href="../de418189/index.html">Erbe des Zeus: Warum der IcedID-Trojaner für Bankkunden gefährlich ist</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
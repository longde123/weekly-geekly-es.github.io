<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëáüèΩ üëÄ ü•ê Sicherheit beim maschinellen Lernen: Effektive Verteidigungstechniken oder neue Bedrohungen? üç¨ üîä üêê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine der beliebtesten und am meisten diskutierten Nachrichten der letzten Jahre ist, wer k√ºnstliche Intelligenz hinzugef√ºgt hat, wo und welche Hacker ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sicherheit beim maschinellen Lernen: Effektive Verteidigungstechniken oder neue Bedrohungen?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pt/blog/416691/"><p>  Eine der beliebtesten und am meisten diskutierten Nachrichten der letzten Jahre ist, wer k√ºnstliche Intelligenz hinzugef√ºgt hat, wo und welche Hacker was und wo gebrochen haben.  Durch die Kombination dieser Themen erscheinen sehr interessante Studien, und es gab bereits mehrere Artikel auf dem Hub, die Modelle f√ºr maschinelles Lernen t√§uschen konnten, zum Beispiel: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Artikel √ºber die Grenzen des tiefen Lernens</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dar√ºber, wie man neuronale Netze anlockt</a> .  Des Weiteren m√∂chte ich dieses Thema unter dem Gesichtspunkt der Computersicherheit genauer betrachten: </p><br><p><img src="https://habrastorage.org/webt/xg/nc/ev/xgncevhjj0f8_lijnifrzr5x9zm.jpeg" alt="Bild"></p><a name="habracut"></a><br><p>  <strong>Ber√ºcksichtigen Sie die folgenden Punkte:</strong> </p><br><ul><li>  Wichtige Begriffe. </li><li>  Was ist maschinelles Lernen, wenn Sie es pl√∂tzlich noch nicht wussten? </li><li>  Was hat Computersicherheit damit zu tun ?! </li><li>  Ist es m√∂glich, das Modell des maschinellen Lernens zu manipulieren, um einen gezielten Angriff durchzuf√ºhren? </li><li> Kann die Systemleistung beeintr√§chtigt werden? </li><li>  Kann ich die Einschr√§nkungen von Modellen f√ºr maschinelles Lernen nutzen? </li><li>  Kategorisierung von Angriffen. </li><li>  Schutzm√∂glichkeiten. </li><li>  M√∂gliche Folgen. </li></ul><br><h3 id="1-pervoe-s-chego-hotelos-by-nachat--s-terminologii-a-nametermsa">  1. Das erste, mit dem ich beginnen m√∂chte, ist die Terminologie. </h3><br><p>  Diese m√∂gliche Aussage kann aufgrund der bereits in russischer Sprache verfassten Artikel zu einem gro√üen Holivar sowohl in der Wissenschaft als auch in der Fachwelt f√ºhren. Ich m√∂chte jedoch darauf hinweisen, dass der Begriff ‚Äûgegnerische Intelligenz‚Äú als ‚Äûfeindliche Intelligenz‚Äú √ºbersetzt wird.  Und das Wort "Widersacher" selbst sollte nicht mit dem juristischen Begriff "Widersacher" √ºbersetzt werden, sondern mit einem geeigneteren Begriff aus dem Sicherheitsbereich "b√∂sartig" (es gibt keine Beschwerden √ºber die √úbersetzung des Namens der Architektur des neuronalen Netzwerks).  Dann haben alle verwandten Begriffe auf Russisch eine viel hellere Bedeutung, wie z. B. ‚Äûgegnerisches Beispiel‚Äú - eine b√∂swillige Dateninstanz, ‚Äûwiderspr√ºchliche Einstellungen‚Äú - eine b√∂swillige Umgebung.  Und genau der Bereich, den wir als ‚Äûkontroverses maschinelles Lernen‚Äú betrachten werden, ist b√∂swilliges maschinelles Lernen. </p><br><p>  Zumindest im Rahmen dieses Artikels werden solche Begriffe in russischer Sprache verwendet.  Ich hoffe, dass gezeigt werden kann, dass es in diesem Thema viel mehr um Sicherheit geht, um Begriffe aus diesem Bereich fair zu verwenden, als um das erste Beispiel eines √úbersetzers. </p><br><p>  Nun, da wir bereit sind, dieselbe Sprache zu sprechen, k√∂nnen wir im Wesentlichen anfangen :) </p><br><h3 id="2-chto-takoe-mashinnoe-obuchenie-esli-vdrug-vy-vse-esche-ne-znali-a-idmachine_learninga">  2. Was ist maschinelles Lernen, wenn Sie es pl√∂tzlich noch nicht wussten? </h3><br><div class="spoiler">  <b class="spoiler_title">Na ja, noch im Wissen</b> <div class="spoiler_text"><p>  Mit Methoden des maschinellen Lernens meinen wir normalerweise Methoden zum Konstruieren von Algorithmen, die lernen und handeln k√∂nnen, ohne ihr Verhalten explizit auf vorgew√§hlten Daten zu programmieren.  Mit Daten k√∂nnen wir alles meinen, wenn wir es mit einigen Zeichen beschreiben oder messen k√∂nnen.  Wenn es ein Zeichen gibt, das f√ºr einige Daten unbekannt ist, das wir aber wirklich ben√∂tigen, verwenden wir Methoden des maschinellen Lernens, um dieses Zeichen basierend auf bereits bekannten Daten wiederherzustellen oder vorherzusagen. </p><br><p><img src="https://habrastorage.org/webt/xf/1o/tz/xf1otzv3z0siwvtbccazyjzj8lu.jpeg" alt="01"></p><br><p>  Es gibt verschiedene Arten von Problemen, die mit Hilfe des maschinellen Lernens gel√∂st werden k√∂nnen, aber wir werden haupts√§chlich √ºber das Klassifizierungsproblem sprechen. </p><br><p>  Klassischerweise besteht der Zweck der Trainingsphase des Klassifikatormodells darin, eine Beziehung (Funktion) auszuw√§hlen, die die Entsprechung zwischen den Merkmalen eines bestimmten Objekts und einer der bekannten Klassen zeigt.  In einem komplexeren Fall ist eine Vorhersage der Wahrscheinlichkeit einer Zugeh√∂rigkeit zu einer bestimmten Kategorie erforderlich. </p><br><p>  Das hei√üt, die Klassifizierungsaufgabe besteht darin, eine solche Hyperebene zu erstellen, die den Raum teilt, wobei seine Dimension in der Regel die Gr√∂√üe des Merkmalsvektors ist, so dass Objekte verschiedener Klassen auf gegen√ºberliegenden Seiten dieser Hyperebene liegen. </p><br><p>  F√ºr einen zweidimensionalen Raum ist eine solche Hyperebene eine Linie.  Betrachten Sie ein einfaches Beispiel: </p><br><p><img src="https://habrastorage.org/webt/kb/9d/ug/kb9dugamfx-vq6zltlxju85phze.jpeg" alt="02"></p><br><p>  Auf dem Bild sehen Sie zwei Klassen, Quadrate und Dreiecke.  Es ist unm√∂glich, die Abh√§ngigkeit zu finden und sie am genauesten durch eine lineare Funktion zu teilen.  Daher kann mit Hilfe des maschinellen Lernens eine nichtlineare Funktion ausgew√§hlt werden, die am besten zwischen diesen beiden S√§tzen unterscheidet. </p><br><p>  Die Klassifizierungsaufgabe ist eine ziemlich typische Unterrichtsaufgabe mit einem Lehrer.  Um das Modell zu trainieren, ist ein solcher Datensatz erforderlich, damit die Merkmale des Objekts und seiner Klasse unterschieden werden k√∂nnen. </p></div></div><br><h3 id="3-pri-chem-tut-kompyuternaya-bezopasnosta-namecomputer-securitya">  3. Was hat Computersicherheit damit zu tun ?! </h3><br><p>  In der Computersicherheit werden seit langem verschiedene Methoden des maschinellen Lernens bei der Spam-Filterung, der Verkehrsanalyse und der Erkennung von Betrug oder Malware verwendet. </p><br><p>  <strong>In gewisser Weise ist dies ein Spiel, bei dem Sie nach einem Zug erwarten, dass der Feind reagiert.</strong>  <strong>Daher m√ºssen Sie bei diesem Spiel die Modelle st√§ndig anpassen, neue Daten lehren oder sie vollst√§ndig √§ndern, um die neuesten wissenschaftlichen Erkenntnisse zu ber√ºcksichtigen.</strong> </p><br><p>  W√§hrend Antivirenprogramme beispielsweise Signaturanalysen, manuelle Heuristiken und Regeln verwenden, die nur schwer zu warten und zu erweitern sind, streitet die Sicherheitsbranche immer noch √ºber die tats√§chlichen Vorteile von Antivirenprogrammen, und viele betrachten Antivirenprogramme als totes Produkt.  Angreifer umgehen all diese Regeln beispielsweise mit Hilfe von Verschleierung und Polymorphismus.  Aus diesem Grund werden Tools bevorzugt, die intelligentere Techniken verwenden, z. B. Methoden des maschinellen Lernens, mit denen Funktionen automatisch ausgew√§hlt werden (auch solche, die nicht vom Menschen interpretiert werden), gro√üe Informationsmengen schnell verarbeiten, verallgemeinern und schnell Entscheidungen treffen k√∂nnen. </p><br><p>  <strong>Das hei√üt, einerseits wird maschinelles Lernen als Schutzinstrument eingesetzt.</strong>  <strong>Andererseits wird dieses Tool auch f√ºr intelligentere Angriffe verwendet.</strong> </p><br><h3 id="posmotrim-mozhet-li-etot-instrument-byt-uyazvimym">  Mal sehen, ob dieses Tool anf√§llig sein kann? </h3><br><p>  F√ºr jeden Algorithmus ist nicht nur die Auswahl der Parameter sehr wichtig, sondern auch die Daten, auf denen der Algorithmus trainiert wird.  In einer idealen Situation ist es nat√ºrlich notwendig, dass gen√ºgend Daten f√ºr das Training vorhanden sind, die Klassen ausgewogen sind und die Zeit f√ºr das Training unbemerkt bleibt, was im wirklichen Leben praktisch unm√∂glich ist. </p><br><p>  Unter der Qualit√§t eines trainierten Modells wird normalerweise die Genauigkeit der Klassifizierung von Daten verstanden, die das Modell im allgemeinen Fall noch nicht ‚Äûgesehen‚Äú hat, als ein bestimmtes Verh√§ltnis korrekt klassifizierter Datenkopien zur Gesamtmenge der Daten, die wir an das Modell √ºbertragen haben. </p><br><p>  Im Allgemeinen stehen alle Qualit√§tsbewertungen in direktem Zusammenhang mit Annahmen √ºber die erwartete Verteilung der Eingabedaten des Systems und ber√ºcksichtigen nicht die sch√§dlichen Umgebungsbedingungen ( <em>widerspr√ºchliche Einstellungen</em> ), die h√§ufig √ºber die erwartete Verteilung der Eingabedaten hinausgehen.  Unter einer b√∂swilligen Umgebung wird eine Umgebung verstanden, in der es m√∂glich ist, mit dem System zu konfrontieren oder mit ihm zu interagieren.  Typische Beispiele f√ºr solche Umgebungen sind Spamfilter, Betrugserkennungsalgorithmen und Malware-Analysesysteme. </p><br><p>  Somit kann die Genauigkeit als Ma√ü f√ºr die durchschnittliche Systemleistung bei durchschnittlicher Nutzung angesehen werden, w√§hrend die Sicherheitsbewertung an der schlechtesten Implementierung interessiert ist. </p><br><p>  <strong>Das hei√üt, normalerweise werden Modelle f√ºr maschinelles Lernen in einer ziemlich statischen Umgebung getestet, in der die Genauigkeit von der Datenmenge f√ºr jede bestimmte Klasse abh√§ngt, in Wirklichkeit jedoch nicht die gleiche Verteilung garantiert werden kann.</strong>  <strong>Und wir sind daran interessiert, das Modell falsch zu machen.</strong>  <strong>Dementsprechend ist es unsere Aufgabe, so viele Vektoren wie m√∂glich zu finden, die das falsche Ergebnis liefern.</strong> </p><br><p>  Wenn sie √ºber die Sicherheit eines Systems oder Dienstes sprechen, bedeutet dies normalerweise, dass es unm√∂glich ist, eine Sicherheitsrichtlinie innerhalb eines bestimmten Bedrohungsmodells in Hardware oder Software zu verletzen, indem versucht wird, das System sowohl in der Entwicklungsphase als auch in der Testphase zu √ºberpr√ºfen.  <strong>Heutzutage arbeiten jedoch eine Vielzahl von Diensten auf der Grundlage von Datenanalysealgorithmen. Die Risiken liegen daher nicht nur in der anf√§lligen Funktionalit√§t, sondern auch in den Daten selbst, auf deren Grundlage das System Entscheidungen treffen kann.</strong> </p><br><p>  Niemand steht still und Hacker beherrschen auch etwas Neues.  Und die Methoden, die helfen, Algorithmen f√ºr maschinelles Lernen auf die M√∂glichkeit eines Kompromisses durch einen Angreifer zu untersuchen, der Kenntnisse √ºber die Funktionsweise des Modells nutzen kann, werden als <em>kontroverses maschinelles Lernen bezeichnet</em> , oder auf Russisch handelt es sich immer noch um <em>b√∂swilliges maschinelles Lernen</em> . </p><br><p>  Wenn wir √ºber die Sicherheit von Modellen des maschinellen Lernens unter dem Gesichtspunkt der Informationssicherheit sprechen, m√∂chte ich konzeptionell mehrere Aspekte ber√ºcksichtigen. </p><br><h3 id="4-mozhno-li-manipulirovat-modelyu-mashinnogo-obucheniya-chtoby-provesti-celevuyu-atakua-namemanipultiona">  4. Ist es m√∂glich, das Modell des maschinellen Lernens zu manipulieren, um einen gezielten Angriff durchzuf√ºhren? </h3><br><p>  Hier ist ein gutes Beispiel f√ºr die Suchmaschinenoptimierung.  Die Leute untersuchen, wie intelligente Suchmaschinenalgorithmen funktionieren, und manipulieren die Daten auf ihren Websites, um im Suchranking h√∂her zu sein.  Die Frage nach der Sicherheit eines solchen Systems ist in diesem Fall erst dann so akut, wenn einige Daten kompromittiert oder schwerwiegende Sch√§den verursacht wurden. </p><br><p>  Als Beispiel f√ºr ein solches System k√∂nnen Dienste angef√ºhrt werden, die im Wesentlichen Online-Modelltraining verwenden, dh Training, bei dem das Modell Daten in einer sequentiellen Reihenfolge empf√§ngt, um die aktuellen Parameter zu aktualisieren.  Wenn Sie wissen, wie das System trainiert ist, k√∂nnen Sie den Angriff planen und das System mit vorbereiteten Daten versorgen. </p><br><p>  Auf diese Weise werden beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">biometrische Systeme</a> get√§uscht <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, die ihre Parameter schrittweise aktualisieren, wenn kleine √Ñnderungen im Aussehen einer Person</a> auftreten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, beispielsweise mit einer nat√ºrlichen √Ñnderung des Alters</a> , was in diesem Fall eine absolut nat√ºrliche und notwendige Funktionalit√§t des Dienstes ist.  Mit dieser Eigenschaft des Systems k√∂nnen Sie die Daten vorbereiten und an das biometrische System senden. Dabei wird das Modell aktualisiert, bis die Parameter an eine andere Person aktualisiert werden.  Auf diese Weise trainiert der Angreifer das Modell neu und kann sich anstelle des Opfers identifizieren. </p><br><p><img src="https://habrastorage.org/webt/wl/zn/ib/wlznibtbprrotpkl7mp5gbrbf-c.jpeg" alt="03"></p><br><h3 id="5-mozhet-li-zloumyshlennik-podbirat-takie-validnye-dannye-kotorye-vsegda-budut-srabatyvat-nepravilno-chto-privedet-k-uhudsheniyu-proizvoditelnosti-sistemy-v-toy-stepeni-chto-ee-pridetsya-otklyuchita-nameperformancea">  5. Kann ein Angreifer solche g√ºltigen Daten ausw√§hlen, die immer korrekt fehlschlagen, was zu einer Verschlechterung der Systemleistung f√ºhrt, sofern sie deaktiviert werden m√ºssen? </h3><br><p>  Dieses Problem ergibt sich ganz nat√ºrlich aus der Tatsache, dass das Modell des maschinellen Lernens h√§ufig in einer eher statischen Umgebung getestet wird und seine Qualit√§t durch die Verteilung der Daten bewertet wird, auf denen das Modell trainiert wurde.  Gleichzeitig werden sehr oft sehr spezifische Fragen an Datenanalysespezialisten gestellt, die das Modell beantworten muss: </p><br><ul><li>  Ist die Datei b√∂sartig? </li><li>  Geh√∂rt diese Transaktion zum Betrug? </li><li>  Ist der aktuelle Verkehr legitim? </li></ul><br><p>  Und es wird erwartet, dass der Algorithmus nicht 100% genau sein kann, sondern nur mit einer gewissen Wahrscheinlichkeit das Objekt einer Klasse zuordnen kann. Daher m√ºssen wir bei Fehlern der ersten und zweiten Art nach Kompromissen suchen, wenn unser Algorithmus nicht ganz sicher sein kann in seiner Wahl und immer noch falsch. </p><br><p>  Nehmen Sie ein System, das sehr oft Fehler der ersten und zweiten Art erzeugt.  Beispielsweise hat das Antivirenprogramm Ihre Datei blockiert, weil es als b√∂sartig eingestuft wurde (obwohl dies nicht der Fall ist), oder das Antivirenprogramm hat eine b√∂swillige Datei √ºbersprungen.  In diesem Fall h√§lt der Benutzer des Systems es f√ºr ineffektiv und schaltet es meistens einfach aus, obwohl es wahrscheinlich ist, dass ein Satz solcher Daten gerade abgefangen wurde. </p><br><p>  <strong>Und der Datensatz, auf dem das Modell das schlechteste Ergebnis zeigt, existiert immer.</strong>  Die Aufgabe des Angreifers besteht darin, nach solchen Daten zu suchen, um das System auszuschalten.  Solche Situationen sind eher unangenehm, und das Modell sollte sie nat√ºrlich vermeiden.  Und Sie k√∂nnen sich das Ausma√ü der Folgen der Untersuchung aller falschen Vorf√§lle vorstellen! </p><br><p>  Fehler der ersten Art werden als Zeitverschwendung wahrgenommen, w√§hrend Fehler der zweiten Art als verpasste Gelegenheit wahrgenommen werden.  Obwohl in der Tat die Kosten f√ºr diese Arten von Fehlern f√ºr jedes spezifische System unterschiedlich sein k√∂nnen.  Wenn ein Antivirenprogramm billiger sein kann, kann es ein Fehler der ersten Art sein, da es besser ist, auf Nummer sicher zu gehen und zu sagen, dass die Datei b√∂sartig ist. Wenn der Client das System herunterf√§hrt und sich herausstellt, dass die Datei wirklich b√∂swillig ist, bleibt das Antivirenprogramm ‚Äûwie gewarnt‚Äú und die Verantwortung beim Benutzer.  Wenn wir zum Beispiel ein System f√ºr die medizinische Diagnostik verwenden, sind beide Fehler ziemlich teuer, da der Patient in jedem Fall dem Risiko einer falschen Behandlung und eines Gesundheitsrisikos ausgesetzt ist. </p><br><h3 id="6-mozhet-li-zloumyshlennik-ispolzovat-svoystva-metoda-mashinnogo-obucheniya-chtoby-narushit-rabotu-sistemy-to-est-ne-vmeshivayas-v-process-obucheniya-nayti-takie-ogranicheniya-modeli-kotorye-zavedomo-dayut-nevernye-predskazaniyaa-nameconstraintsa">  6. Kann ein Angreifer die Eigenschaften einer maschinellen Lernmethode verwenden, um das System zu st√∂ren?  Das hei√üt, ohne den Lernprozess zu st√∂ren, finden Sie solche Modellbeschr√§nkungen, die offensichtlich falsche Vorhersagen liefern. </h3><br><p>  Es scheint, dass Deep-Learning-Systeme praktisch vor menschlichen Eingriffen in die Auswahl von Zeichen gesch√ºtzt sind, so dass man sagen kann, dass es keinen menschlichen Faktor gibt, wenn Entscheidungen durch das Modell getroffen werden.  Der ganze Reiz des tiefen Lernens besteht darin, dass es ausreicht, die Eingabe des Modells fast als ‚ÄûRohdaten‚Äú zu betrachten, und das Modell selbst hebt durch mehrere lineare Transformationen die Merkmale hervor, die es als am wichtigsten erachtet und eine Entscheidung trifft.  Aber ist es wirklich so gut? </p><br><p>  Es gibt Arbeiten, die die Methoden zur Vorbereitung solcher b√∂swilligen Beispiele im Deep-Learning-Modell beschreiben, das das System falsch klassifiziert.  Eines der wenigen, aber beliebten Beispiele ist ein Artikel √ºber effektive physische Angriffe auf Deep-Learning-Modelle. </p><br><p>  Die Autoren f√ºhrten Experimente durch und schlugen Methoden zur Umgehung von Modellen vor, die auf der Einschr√§nkung des tiefen Lernens basieren und das "Vision" -System am Beispiel der Erkennung von Verkehrszeichen t√§uschen.  F√ºr ein positives Ergebnis reicht es f√ºr die Angreifer aus, solche Bereiche auf dem Objekt zu finden, die den Klassifikator am st√§rksten niederschlagen, und es ist falsch.  Die Experimente wurden an der Marke ‚ÄûSTOP‚Äú durchgef√ºhrt, die aufgrund von √Ñnderungen bei den Forschern das Modell als Marke ‚ÄûSPEED LIMIT 45‚Äú qualifizierte.  Sie testeten ihren Ansatz an anderen Zeichen und erzielten ein positives Ergebnis. </p><br><p><img src="https://habrastorage.org/webt/b7/3n/zp/b73nzp60lmontpvo7g0phqwy4cu.jpeg" alt="04"></p><br><p>  Infolgedessen schlugen die Autoren zwei M√∂glichkeiten vor, mit denen das maschinelle Lernsystem ausgetrickst werden kann: Poster-Druck-Angriff, der eine Reihe kleiner √Ñnderungen am gesamten Umfang der Marke impliziert, Tarnung genannt, und Aufkleber-Angriffe, wenn einige Aufkleber in bestimmten Bereichen auf die Marke geschichtet wurden. </p><br><p>  Aber das sind ganz Lebenssituationen - wenn sich das Schild im Schmutz von Stra√üenstaub befindet oder wenn junge Talente ihre Arbeit daran aufgeben.  Es ist wahrscheinlich, dass k√ºnstliche Intelligenz und Kunst keinen Platz in einer Welt haben. </p><br><p><img src="https://habrastorage.org/webt/qm/qq/gv/qmqqgvkbpraxsstagj1mmsp_o_0.jpeg" alt="Shutterstock"></p><br><p>  Oder neuere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Forschungen zu gezielten Angriffen auf automatische Spracherkennungssysteme</a> .  Sprachnachrichten sind bei der Kommunikation in sozialen Netzwerken zu einem Trend geworden, aber das Abh√∂ren ist nicht immer bequem.  Daher gibt es Dienste, mit denen Sie eine Audioaufnahme in Text √ºbertragen k√∂nnen.  Die Autoren der Arbeit lernten, das Original-Audio zu analysieren, das Tonsignal zu ber√ºcksichtigen und dann ein weiteres Tonsignal zu erzeugen, das dem Original zu 99% √§hnlich ist, indem sie eine kleine √Ñnderung hinzuf√ºgten.  Infolgedessen entschl√ºsselt der Klassifizierer den Datensatz wie vom Angreifer gew√ºnscht. </p><br><p><img src="https://habrastorage.org/webt/o-/6v/8t/o-6v8tgin46wuycj45o67waiaho.png" alt="06"></p><br><h3 id="7-v-svyazi-s-etim-mozhno-bylo-by-kategorizirovat-suschestvuyuschie-ataki-neskolkimi-sposobamigooglv2kgp9a-nameattacksa">  7. In dieser Hinsicht w√§re es m√∂glich, bestehende Angriffe auf verschiedene <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arten</a> zu kategorisieren: </h3><br><p>  <strong>Nach der Expositionsmethode (Einfluss):</strong> </p><br><ul><li>  Verursachende Angriffe wirken sich auf das Modelltraining durch Interferenzen im Trainingssatz aus. </li><li>  Explorative Angriffe verwenden Klassifikatorfehler, ohne den Trainingssatz zu beeinflussen. </li></ul><br><p>  <strong>Sicherheitsverletzung:</strong> </p><br><ul><li>  Integrit√§tsangriffe gef√§hrden das System durch Fehler der zweiten Art. </li><li>  Verf√ºgbarkeitsangriffe f√ºhren zu einem Herunterfahren des Systems, normalerweise basierend auf Fehlern der ersten Art. </li></ul><br><p>  <strong>Spezifit√§t:</strong> </p><br><ul><li>  Gezielter Angriff (gezielter Angriff) zielt darauf ab, die Vorhersage des Klassifikators auf eine bestimmte Klasse zu √§ndern. </li><li>  Massenangriff (wahlloser Angriff) zielt darauf ab, die Reaktion des Klassifikators auf eine andere Klasse als die richtige zu √§ndern. </li></ul><br><p>  <strong>Der Zweck der Sicherheit</strong> besteht darin, Ressourcen vor einem Angreifer zu sch√ºtzen und Anforderungen einzuhalten, deren Verst√∂√üe zu einer teilweisen oder vollst√§ndigen Gef√§hrdung einer Ressource f√ºhren. </p><br><p>  Aus Sicherheitsgr√ºnden werden verschiedene Modelle f√ºr maschinelles Lernen verwendet.  Virenerkennungssysteme zielen beispielsweise darauf ab, die Anf√§lligkeit f√ºr Viren zu verringern, indem sie erkannt werden, bevor das System infiziert wird, oder ein vorhandenes Virus zum Entfernen zu erkennen.  Ein weiteres Beispiel ist das Intrusion Detection System (IDS), das erkennt, dass ein System durch Erkennen von b√∂swilligem Datenverkehr oder verd√§chtigem Verhalten im System kompromittiert wurde.  Eine weitere enge Aufgabe ist das Intrusion Prevention System (IPS), das Intrusionsversuche erkennt und das Eindringen in das System verhindert. </p><br><p>  Im Zusammenhang mit Sicherheitsproblemen besteht das Ziel von Modellen f√ºr maschinelles Lernen im Allgemeinen darin, b√∂swillige Ereignisse zu trennen und zu verhindern, dass sie das System st√∂ren. </p><br><p>  Im Allgemeinen kann das Ziel in zwei Teile geteilt werden: <br>  <em>Integrit√§t</em> : Verhindert, dass ein Angreifer auf Systemressourcen zugreift <br>  <em>Zug√§nglichkeit</em> : Verhindern Sie, dass ein Angreifer den normalen Betrieb st√∂rt. </p><br><p>  Es besteht ein eindeutiger Zusammenhang zwischen Fehlern des zweiten Typs und Integrit√§tsverletzungen: B√∂swillige Instanzen, die in das System √ºbertragen werden, k√∂nnen sch√§dlich sein.  Genau wie Fehler der ersten Art normalerweise die Zug√§nglichkeit verletzen, weil das System selbst zuverl√§ssige Kopien der Daten ablehnt. </p><br><h3 id="8-kakie-suschestvuyut-sposoby-zaschity-ot-zloumyshlennikov-manipuliruyuschih-modelyami-mashinnogo-obucheniyaa-namedefencea">  8. Wie kann man sich vor Cyberkriminellen sch√ºtzen, die Modelle des maschinellen Lernens manipulieren? </h3><br><p>  Derzeit ist es schwieriger, ein Modell f√ºr maschinelles Lernen vor b√∂swilligen Angriffen zu sch√ºtzen, als es anzugreifen.  Nur weil das Modell unabh√§ngig davon, wie viel wir trainieren, immer einen Datensatz enth√§lt, f√ºr den es am schlechtesten funktioniert. <br>  Und heute gibt es keine ausreichend effektiven M√∂glichkeiten, um das Modell mit 100% iger Genauigkeit arbeiten zu lassen.  Es gibt jedoch einige Tipps, die das Modell widerstandsf√§higer gegen b√∂swillige Beispiele machen k√∂nnen. </p><br><p>  Hier ist das Wichtigste: Wenn es m√∂glich ist, maschinelle Lernmodelle in einer b√∂swilligen Umgebung nicht zu verwenden, ist es besser, sie nicht zu verwenden.  Es macht keinen Sinn, maschinelles Lernen abzulehnen, wenn Sie vor der Aufgabe stehen, Bilder zu klassifizieren oder Memes zu generieren.  Es ist kaum m√∂glich, einen signifikanten Schaden zuzuf√ºgen, der im Falle eines vors√§tzlichen Angriffs zu sozial oder wirtschaftlich bedeutenden Konsequenzen f√ºhren w√ºrde.         ,    ,         , , ,        . </p><br><p>        ,      ,      ,     .      . </p><br><p>   ,     ,         .   ,      ,  ,  ,       ,      ,    ,      .  ,   ,     ,   ,       ,     ,      . </p><br><p><img src="https://habrastorage.org/webt/ir/gw/8j/irgw8jzmvbta0vlbqtogwcqbrze.jpeg" alt="Bild"><br> 1 ‚Äî , 2 ‚Äî , 3 ‚Äî   </p><br><p>     , , :      .     .          ,     . </p><br><p>       .         ,      .           ,         .         100%-       - ,            . </p><br><p>    -  ,          ‚Äî   .          ,     ‚Äî    ,    .              ,        . </p><br><p> <strong>     ,       ,       .</strong> </p><br><h3 id="9-kakovy-potencialnye-posledstviya-ispolzovaniya-mashinnogo-obucheniya-s-tochki-zreniya-bezopasnostia-nameconsequencesa"> 9.          ? </h3><br><p>               .                : ,   ,     ,   ,     . </p><br><p>    ,         .         .          ,    .      ,    ,      ,      ¬´¬ª. </p><br><p>   ,   - ,            .    ,       ,    .     -  Twitter,  Microsoft,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> . </p><br><p>       ?    ,  ,     ‚Äî  ,    ,     .   ,     ,  ,            ‚Äî  ,       ,    . </p><br><blockquote>  ,   , ,  ¬´  ‚Äî    ,      ¬ª? </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416691/">https://habr.com/ru/post/de416691/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416681/index.html">Wie viel von PostgreSQL und ClickHouse in Python viel, schnell und sofort in numpy</a></li>
<li><a href="../de416683/index.html">Was weiter? Oder wie man Funktionen f√ºr die Entwicklung ausw√§hlt</a></li>
<li><a href="../de416685/index.html">Epson ColorWorks Follow-up: Ihre Fragen, unsere Antworten</a></li>
<li><a href="../de416687/index.html">QSAN-Speicher als Konkurrent von Tier-1-Marken</a></li>
<li><a href="../de416689/index.html">√úber die Funktionen der Android-Architektur aus der Sicht eines Nicht-Android-Entwicklers</a></li>
<li><a href="../de416693/index.html">D-Link- und Changing Information Technologies-Zertifikate zum Signieren von Malware</a></li>
<li><a href="../de416695/index.html">Unterst√ºtzung f√ºr vSphere 6.7 und andere Funktionen des neuesten Veeam Backup & Replication 9.5-Updates 3a</a></li>
<li><a href="../de416697/index.html">Zusammenschluss der Telekommunikationsbetreiber im Jahr 2018</a></li>
<li><a href="../de416699/index.html">Geek Sniper oder wie man ein "scharfes Auge" macht</a></li>
<li><a href="../de416703/index.html">Erstellen von Tracks im Schnee in Unreal Engine 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
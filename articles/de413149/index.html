<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👾 👩‍💼 👨🏼‍🤝‍👨🏻 Verteiltes Data Warehouse im Data Lake-Konzept: Wo soll ich anfangen? 🏣 🌺 🏪</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In der Unternehmenswelt gab es eine Sättigung mit Front-End-Systemen, Datenbussen und anderen klassischen Systemen, die in den letzten 10 bis 15 Jahre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verteiltes Data Warehouse im Data Lake-Konzept: Wo soll ich anfangen?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neoflex/blog/413149/">  In der Unternehmenswelt gab es eine Sättigung mit Front-End-Systemen, Datenbussen und anderen klassischen Systemen, die in den letzten 10 bis 15 Jahren von allen implementiert wurden.  Aber es gibt ein Segment, das bis vor kurzem den Status "Jeder will, aber niemand weiß, was es ist" hatte.  Und das ist Big Data.  Klingt wunderbar, gefördert von westlichen Top-Unternehmen - wie kann man kein Leckerbissen werden? <br><br><img src="https://habrastorage.org/webt/im/vq/jd/imvqjd41airg83tkthvkawlnlgw.png"><br><br>  Während die meisten nur zuschauen und fragen, haben einige Unternehmen begonnen, Lösungen, die auf diesem Technologie-Stack basieren, aktiv in ihre IT-Landschaft zu implementieren.  Eine wichtige Rolle dabei spielte das Aufkommen kommerzieller Apache Hadoop-Distributionen, deren Entwickler ihren Kunden technischen Support bieten.  Als einer unserer Kunden die Notwendigkeit einer solchen Lösung erkannte, entschied er sich, ein verteiltes Data Warehouse im Data Lake-Konzept auf der Basis von Apache Hadoop zu organisieren. <br><a name="habracut"></a><br><h2>  Projektziele </h2><br><p>  Optimieren Sie zunächst die Arbeit der Risikomanagementabteilung.  Vor Arbeitsbeginn war eine ganze Abteilung mit der Berechnung der Kreditrisikofaktoren (FCR) beschäftigt, und alle Berechnungen wurden manuell durchgeführt.  Die Neuberechnung dauerte jedes Mal ungefähr einen Monat, und die Daten, auf denen sie basierten, hatten Zeit, veraltet zu werden.  Zu den Aufgaben der Lösung gehörten daher das tägliche Laden des Datendeltas in das Repository, die Neuberechnung der FCD und das Erstellen von Data Marts im BI-Tool (die SpagoBI-Funktionalität reichte für diese Aufgabe aus), um sie zu visualisieren. </p><br><p>  Zweitens, um leistungsstarke Data Mining-Tools für Bankmitarbeiter bereitzustellen, die an Data Science beteiligt sind.  Diese Tools wie Jupyter und Apache Zeppelin können lokal installiert und auch zum Erkunden von Daten und Erstellen von Modellen verwendet werden.  Durch die Integration in den Cloudera-Cluster können jedoch die Hardwareressourcen der produktivsten Systemknoten für Berechnungen verwendet werden, was die Aufgaben der Datenanalyse um das Zehn- oder sogar Hundertfache beschleunigt. </p><br><p>  Das Oracle Big Data Appliance-Rack wurde als Zielhardwarelösung ausgewählt, sodass die Clachede-Distribution von Apache Hadoop als Grundlage diente.  Das Rack war einige Zeit unterwegs, und um den Prozess zu beschleunigen, wurden Server in der privaten Cloud des Kunden für dieses Projekt zugewiesen.  Die Lösung ist vernünftig, aber es gab eine Reihe von Problemen, die ich unten diskutieren werde. </p><br><p>  Im Rahmen des Projekts wurden folgende Aufgaben geplant: <br><br></p><ol><li>  Stellen Sie Clouderas CDH (Clouderas Distribution einschließlich Apache Hadoop) und zusätzliche Dienste bereit, die für die Arbeit erforderlich sind. </li><li>  Konfigurieren Sie die installierte Software. </li><li>  Richten Sie eine kontinuierliche Integration ein, um den Entwicklungsprozess zu beschleunigen (wird in einem separaten Artikel behandelt). </li><li>  Installieren Sie BI-Tools zum Erstellen von Berichts- und Datenermittlungstools, um die Arbeit des Rechenzentrums sicherzustellen (wird in einem separaten Beitrag behandelt). </li><li>  Entwicklung von Anwendungen zum Herunterladen der erforderlichen Daten von Endsystemen sowie deren regelmäßige Aktualisierung. </li><li>  Entwickeln Sie Berichtsformulare zur Visualisierung von Daten in einem BI-Tool. </li></ol><br><p> Es ist nicht das erste Jahr, in dem Neoflex Apache Hadoop-basierte Systeme entwickelt und implementiert und sogar ein eigenes Produkt für die visuelle Entwicklung von ETL-Prozessen hat - Neoflex Datagram.  Ich wollte lange an einem der Projekte dieser Klasse teilnehmen und war glücklich, dieses System zu verwalten.  Die Erfahrung erwies sich als sehr wertvoll und motivierend, das Thema weiter zu studieren, und ich beeile mich, es mit Ihnen zu teilen.  Hoffe es wird interessant. </p><br><h2>  Ressourcen </h2><br><p>  Es wird empfohlen, vor Beginn der Installation alles vorzubereiten, was Sie dafür benötigen. <br>  Die Menge und Leistung von Eisen hängt direkt davon ab, wie viele und welche Medien eingesetzt werden müssen.  Zu Entwicklungszwecken können Sie alle Komponenten auf mindestens einer gebrechlichen virtuellen Maschine installieren. Dieser Ansatz ist jedoch nicht erwünscht. </p><br><p>  In der Pilotphase des Projekts und der aktiven Entwicklung, als die Anzahl der Benutzer des Systems minimal war, reichte eine Hauptumgebung aus - dies konnte beschleunigt werden, indem die Zeit zum Laden von Daten aus den Endsystemen verkürzt wurde (das häufigste und langwierigste Verfahren zum Entwickeln von Data Warehouses).  Nachdem sich das System stabilisiert hat, sind wir zu einer Konfiguration mit drei Umgebungen gekommen - test, preprod und prod (main). </p><br><p>  In einer privaten Cloud wurden Server für die Organisation von zwei Umgebungen zugewiesen - der Hauptumgebung und der Testumgebung.  Die Medienspezifikationen sind in der folgenden Tabelle aufgeführt: <br></p><table><tbody><tr><th>  Termin </th><th>  Menge </th><th>  vCPU </th><th>  vRAM, Gb </th><th>  Scheiben, Gb </th></tr><tr><td>  Hauptumgebung, Dienstleistungen Cloudera </td><td>  3 </td><td>  8 </td><td>  64 </td><td>  2.200 </td></tr><tr><td>  Primäre Umgebung, HDFS </td><td>  3 </td><td>  22 </td><td>  288 </td><td>  5000 </td></tr><tr><td>  Kernumgebung, Datenermittlungstools </td><td>  1 </td><td>  16 </td><td>  128 </td><td>  2200 </td></tr><tr><td>  Testumgebung, Cloudera-Dienste </td><td>  1 </td><td>  8 </td><td>  64 </td><td>  2200 </td></tr><tr><td>  Testumgebung, HDFS </td><td>  2 </td><td>  22 </td><td>  256 </td><td>  4000 </td></tr><tr><td>  Kernumgebung, Datenermittlungstools </td><td>  1 </td><td>  16 </td><td>  128 </td><td>  2200 </td></tr><tr><td>  Ci </td><td>  2 </td><td>  6 </td><td>  48 </td><td>  1000 </td></tr></tbody></table><br><p>  Später wurde die Hauptumgebung auf Oracle BDA migriert, und die Server wurden zum Organisieren der Preprod-Umgebung verwendet. </p><br><p>  Die Entscheidung zur Migration war gerechtfertigt - die für HDFS-Server zugewiesenen Ressourcen fehlten objektiv.  Die Engpässe waren winzige Festplatten (was sind 5 TB für Big Data?) Und unzureichend leistungsfähige Prozessoren, die während der regulären Arbeit mit Datenladeaufgaben zu 95% stabil ausgelastet waren.  Bei anderen Servern ist die Situation umgekehrt - fast immer sind sie im Leerlauf und ihre Ressourcen könnten für andere Projekte von großem Vorteil sein. </p><br><p>  Mit Software war es nicht einfach - da die Entwicklung in einer privaten Cloud ohne Internetzugang durchgeführt wurde, mussten alle Dateien über den Sicherheitsdienst und nur nach Vereinbarung übertragen werden.  In dieser Hinsicht musste ich alle erforderlichen Distributionen, Pakete und Abhängigkeiten vorladen. </p><br><p>  Das Festlegen von keepcache = 1 in der Datei /etc/yum.conf (RHEL 7.3 wurde als Betriebssystem verwendet) hat bei dieser schwierigen Aufgabe sehr geholfen. Die Installation der erforderlichen Software auf einem Computer mit Netzwerkzugriff ist viel einfacher als das manuelle Herunterladen aus den Repositorys zusammen mit den Abhängigkeiten. <br><br>  Was Sie bereitstellen müssen: <br><br></p><ol><li>  Oracle JDK (nirgendwo Java). </li><li>  Eine Datenbank zum Speichern von Informationen, die von CDH-Diensten erstellt und verwendet werden (z. B. Hive Metastore).  In unserem Fall wurde PostgreSQL Version 9.2.18 installiert, es können jedoch alle unterstützten Cloudera-Dienste verwendet werden (die Liste ist für verschiedene Versionen der Distribution unterschiedlich, siehe Abschnitt Anforderungen und unterstützte Versionen auf der offiziellen Website).  Hierbei ist zu beachten, dass die Auswahl der Datenbank nicht ganz erfolgreich war - Oracle BDA wird mit der MySQL-Datenbank geliefert (eines ihrer Produkte, das mit dem Kauf von Sun an sie übergeben wurde), und es wäre logischer, eine ähnliche Datenbank für andere Umgebungen zu verwenden, was den Migrationsprozess vereinfachen würde.  Es wird empfohlen, eine Distribution basierend auf der Zielhardwarelösung auszuwählen. </li><li>  Chrony-Daemon für die Zeitsynchronisation auf Servern. </li><li>  Cloudera Manager Server. </li><li>  Dämonen Cloudera Manager. </li></ol><br><h2>  Vorbereitung für die Installation </h2><br><p>  Vor Beginn der Installation von CDH sollten einige vorbereitende Arbeiten durchgeführt werden.  Ein Teil ist während der Installation nützlich, der andere vereinfacht die Bedienung. </p><br><h2>  Installation und Einrichtung des Betriebssystems </h2><br><p>  Zunächst lohnt es sich, die virtuellen (und realen) Maschinen vorzubereiten, auf denen das System gehostet wird: Installieren Sie die unterstützte Version auf jeder von ihnen (die Liste unterscheidet sich für verschiedene Versionen der Distribution, siehe Abschnitt "Anforderungen und unterstützte Versionen" auf der offiziellen Website), weisen Sie sie zu Hostnamen sind verständliche Namen (z. B. &lt;Systemname&gt; Master1,2,3 ..., &lt;Systemname&gt; Slave1,2,3 ...) sowie Markierungsdatenträger für die Dateispeicherung und temporäre Dateien, die während des Systembetriebs erstellt wurden. </p><br><p>  Die Markup-Empfehlungen lauten wie folgt: <br><br></p><ul><li>  Erstellen Sie auf Servern mit HDFS ein Volume von mindestens 500 GB für Dateien, die YARN im Verlauf von Aufgaben erstellt, und legen Sie es im Verzeichnis / yarn ab (wo dieses Volume nach der Installation von CDH bereitgestellt werden muss).  Für das Betriebssystem, die Cloudera-Dienste, Protokolle und andere Einrichtungen sollte ein kleines Volumen (ca. 100 GB) zugewiesen werden.  Der gesamte freie Speicherplatz, der nach diesen Manipulationen verbleibt, sollte zu einem großen Volume zusammengefasst und in das Verzeichnis / dfs eingehängt werden, bevor Daten in den Speicher geladen werden.  HDFS speichert Daten in Form von eher kleinen Blöcken, und es ist besser, sich nicht noch einmal auf deren Übertragung einzulassen.  Um später Discs hinzufügen zu können, wird die Verwendung von LVM empfohlen. Es ist einfacher, den Speicher zu erweitern (insbesondere, wenn er wirklich GROSS wird). </li><li>  Auf Servern mit Cloudera-Diensten können Sie den gesamten verfügbaren Speicherplatz im Stammverzeichnis bereitstellen. Bei großen Dateivolumina sollten keine Probleme auftreten, insbesondere wenn Sie die Protokolle regelmäßig bereinigen.  Die einzige Ausnahme ist der Server mit der Datenbank, die Cloudera-Dienste für ihre Anforderungen verwenden. Auf diesem Server ist es sinnvoll, ein separates Volume unter dem Verzeichnis zu markieren, in dem die Dateien dieser Datenbank gespeichert sind (dies hängt von der ausgewählten Distribution ab).  Services schreiben ziemlich moderat und 500 GB sollten mehr als genug sein.  Aus Sicherheitsgründen können Sie auch LVM verwenden. </li></ul><br><h2>  Einrichten des http-Servers und der Offline-Installation von yum- und CDH-Paketen </h2><br><p>  Da die Software ohne Internetzugang installiert wird, wird empfohlen, den HTTP-Server zu erhöhen und ein lokales Repository zu erstellen, auf das über das Netzwerk zugegriffen werden kann, um die Installation von Paketen zu vereinfachen.  Sie können die gesamte Software lokal installieren, z. B. mit U / min. Bei einer großen Anzahl von Servern und dem Erscheinungsbild mehrerer Umgebungen ist es jedoch praktisch, über ein einziges Repository zu verfügen, von dem Sie Pakete installieren können, ohne sie manuell von Computer zu Computer übertragen zu müssen. </p><br><p>  Die Installation wurde unter dem Betriebssystem Red Hat 7.3 durchgeführt. Daher enthält der Artikel spezifische Befehle für dieses Betriebssystem und andere CentOS-basierte Betriebssysteme.  Bei der Installation auf anderen Betriebssystemen ist die Reihenfolge ähnlich, nur die Paketmanager unterscheiden sich. <br>  Um nicht überall sudo zu schreiben, gehen wir davon aus, dass die Installation vom Root stammt. </p><br><p>  <b>Folgendes müssen Sie tun:</b> <br>  <b>1. Der</b> Computer, auf dem sich der HTTP-Server und die Distributionen befinden, wird ausgewählt. <br>  <b>2.</b> Setzen Sie auf einem Computer mit einem ähnlichen Betriebssystem, der jedoch mit dem Internet verbunden ist, das Flag keepcache = 1 in der Datei /etc/yum.conf, und httpd mit allen Abhängigkeiten wird installiert: <br><br></p><pre><code class="hljs sql">yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> httpd</code> </pre> <br>  Wenn dieser Befehl nicht funktioniert, müssen Sie der Liste der yum-Repositorys ein Repository hinzufügen, das diese Pakete enthält. Beispiel: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">centos.excellmedia.net/7/os/x86_64</a> : <br><br><pre> <code class="hljs tex">echo -e "<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">n</span></span></span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">[centos.excellmedia.net]</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">nname</span></span></span><span class="hljs-tag">=</span></span>excellmedia<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">nbaseurl</span></span></span><span class="hljs-tag">=</span></span>http://centos.excellmedia.net/7/os/x86_64/<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">nenabled</span></span></span><span class="hljs-tag">=</span><span class="hljs-number"><span class="hljs-tag"><span class="hljs-number">1</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ngpgcheck</span></span></span><span class="hljs-tag">=</span><span class="hljs-number"><span class="hljs-tag"><span class="hljs-number">0</span></span></span></span>" &gt; /etc/yum.repos.d/excell.repo</code> </pre> <br>  Danach überprüfen <b>wir mit dem</b> Befehl <b>yum repolist</b> , ob das Repository <b>aufgerufen</b> wurde. Ein hinzugefügtes Repository sollte in der Liste der Repositorys angezeigt werden (repo id - centos.excellmedia.net; repo name - excellmedia). <br>  Überprüfen Sie nun, ob Sie die benötigten Pakete gesehen haben: <br><br><pre> <code class="hljs perl">yum list | <span class="hljs-keyword"><span class="hljs-keyword">grep</span></span> httpd</code> </pre> <br>  Wenn die Ausgabe die erforderlichen Pakete enthält, können Sie sie mit dem obigen Befehl installieren. <br><br>  <b>3.</b> Um das yum-Repository zu erstellen, benötigen wir das createrepo-Paket.  Es befindet sich auch im obigen Repository und ist ähnlich eingestellt: <br><br><pre> <code class="hljs sql">yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> createrepo</code> </pre> <br>  <b>4.</b> Wie ich bereits sagte, benötigen CDH-Dienste eine Datenbank, um zu funktionieren.  Installieren Sie PostgreSQL für folgende Zwecke: <br><br><pre> <code class="hljs sql">yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> postgresql-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span></code> </pre> <br>  <b>5.</b> Eine der Voraussetzungen für den korrekten Betrieb von CDH ist die Zeitsynchronisation auf allen im Cluster enthaltenen Servern.  Für diese Zwecke wird das <b>chronyd-</b> Paket <b>verwendet</b> (auf den Betriebssystemen, auf denen ich CDH bereitstellen musste, wurde es standardmäßig installiert).  Überprüfen Sie die Verfügbarkeit: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">chronyd</span></span> -v</code> </pre> <br>  Wenn es nicht installiert ist, installieren Sie: <br><br><pre> <code class="hljs sql">yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> chrony</code> </pre> <br>  Wenn installiert, dann einfach herunterladen: <br><br><pre> <code class="hljs javascript">yumdownloader --destdir=<span class="hljs-regexp"><span class="hljs-regexp">/var/</span></span>cache/yum/x86_64/<span class="hljs-number"><span class="hljs-number">7</span></span>Server/<span class="xml"><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">repo</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">id</span></span></span></span><span class="xml"><span class="hljs-tag">&gt;</span></span></span><span class="xml">/packages chrony</span></span></code> </pre> <br>  <b>6.</b> Laden Sie gleichzeitig sofort die für die Installation von CDH erforderlichen Pakete herunter.  Sie sind unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">archive.cloudera.com</a> verfügbar - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">archive.cloudera.com/cm</a> &lt;Hauptversion von CDH&gt; / &lt;Name Ihres Betriebssystems&gt; / &lt;Version Ihres Betriebssystems&gt; / x86_64 / cm / &lt;Vollversion von CDH&gt; / RPMS / x86_64 /.  Sie können Pakete manuell herunterladen (Cloudera-Manager-Server und Cloudera-Manager-Daemons) oder analog ein Repository hinzufügen und installieren: <br><br><pre> <code class="hljs powershell">yum install cloudera<span class="hljs-literal"><span class="hljs-literal">-manager</span></span><span class="hljs-literal"><span class="hljs-literal">-daemons</span></span> cloudera<span class="hljs-literal"><span class="hljs-literal">-manager</span></span><span class="hljs-literal"><span class="hljs-literal">-server</span></span></code> </pre> <br>  <b>7.</b> Nach der Installation werden Pakete und ihre Abhängigkeiten im Ordner / var / cache / yum / x86_64 / 7Server / \ &lt;Repo-ID \&gt; / packages zwischengespeichert.  Wir übertragen sie auf den Computer, der für den HTTP-Server und die Distributionen ausgewählt wurde, und installieren: <br><br><pre> <code class="hljs xml">rpm -ivh <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"></span></span></span><span class="hljs-tag"> &gt;</span></span></code> </pre> <br>  <b>8.</b> Führen Sie httpd aus, machen Sie es auf anderen Hosts in unserem Cluster sichtbar und fügen Sie es der Liste der Dienste hinzu, die nach dem Laden automatisch gestartet werden: <br><br><pre> <code class="hljs sql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> httpd systemctl <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span> httpd systemctl <span class="hljs-keyword"><span class="hljs-keyword">stop</span></span> firewalld <span class="hljs-comment"><span class="hljs-comment">#       systemctl disable firewalld #       setenforce 0</span></span></code> </pre> <br>  <b>9.</b> Jetzt haben wir einen funktionierenden HTTP-Server.  Das Arbeitsverzeichnis lautet <b>/ var / www / html</b> .  Erstellen Sie zwei Ordner darin - einen für das Yum-Repository, den anderen für die Cloudera-Parser (dazu später mehr): <br><br><pre> <code class="hljs dos"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /var/www/html <span class="hljs-built_in"><span class="hljs-built_in">mkdir</span></span> yum_repo parcels</code> </pre> <br>  <b>10.</b> Für die Dienste von Cloudera benötigen wir <b>Java</b> .  Auf allen Computern muss dieselbe Version des JDK installiert sein. Cloudera empfiehlt den Hot Spot von Oracle.  Laden Sie das Distributionspaket von der offiziellen Website (http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) herunter und übertragen Sie es in den Ordner <b>yum_repo</b> . <br><br>  <b>11.</b> Erstellen Sie das yum-Repository im Ordner yum_repo mit dem Dienstprogramm createrepo, damit das JDK-Paket für die Installation auf den Cluster-Computern verfügbar ist: <br><br><pre> <code class="hljs swift">createrepo -v /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/www/html/yum_repo/</code> </pre> <br>  <b>12.</b> Nachdem Sie unser lokales Repository auf jedem der Hosts erstellt haben, müssen Sie dessen Beschreibung hinzufügen, ähnlich wie in Absatz 2: <br><br><pre> <code class="hljs tex">echo -e "<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">n</span></span></span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">[yum.local.repo]</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">nname</span></span></span><span class="hljs-tag">=</span></span>yum_repo<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">nbaseurl</span></span></span><span class="hljs-tag">=</span></span>http://&lt;   httpd&gt;/yum_repo/<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">nenabled</span></span></span><span class="hljs-tag">=</span><span class="hljs-number"><span class="hljs-tag"><span class="hljs-number">1</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ngpgcheck</span></span></span><span class="hljs-tag">=</span><span class="hljs-number"><span class="hljs-tag"><span class="hljs-number">0</span></span></span></span>" &gt; /etc/yum.repos.d/yum_repo.repo</code> </pre> <br>  Sie können auch Prüfungen ähnlich wie in Absatz 2 durchführen. <br><br>  <b>13.</b> JDK ist verfügbar, installieren Sie: <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">yum</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">install</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">jdk1</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.8</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.0_161</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.x86_64</span></span></code> </pre> <br>  Um Java verwenden zu können, müssen Sie die Variable JAVA_HOME festlegen.  Ich empfehle, dass Sie es sofort nach der Installation exportieren und in die <b>Dateien</b> <b>/ etc / environment</b> und <b>/ etc / default / bigtop-utils</b> schreiben, damit es nach dem Neustart der Server automatisch exportiert wird und sein Speicherort den CDH-Diensten zur Verfügung gestellt wird: <br><br><pre> <code class="hljs javascript"><span class="hljs-keyword"><span class="hljs-keyword">export</span></span> JAVA_HOME=<span class="hljs-regexp"><span class="hljs-regexp">/usr/</span></span>java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_161 echo <span class="hljs-string"><span class="hljs-string">"JAVA_HOME=/usr/java/jdk1.8.0_161"</span></span> &gt;&gt; <span class="hljs-regexp"><span class="hljs-regexp">/etc/</span></span>environment <span class="hljs-keyword"><span class="hljs-keyword">export</span></span> JAVA_HOME=<span class="hljs-regexp"><span class="hljs-regexp">/usr/</span></span>java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_144 &gt;&gt; <span class="hljs-regexp"><span class="hljs-regexp">/etc/</span></span><span class="hljs-keyword"><span class="hljs-keyword">default</span></span>/bigtop-utils</code> </pre> <br>  <b>14.</b> Installieren Sie chronyd auf die gleiche Weise auf allen Computern im Cluster (es sei denn, es fehlt natürlich): <br><br><pre> <code class="hljs sql">yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> chrony</code> </pre> <br>  <b>15.</b> Wählen Sie den Host aus, auf dem PostgreSQL arbeiten soll, und installieren Sie ihn: <br><br><pre> <code class="hljs sql">yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> postgresql-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span></code> </pre> <br>  <b>16.</b> Wählen Sie auf ähnliche Weise den Host aus, auf dem Cloudera Manager ausgeführt werden soll, und installieren Sie ihn: <br><br><pre> <code class="hljs powershell">yum install cloudera<span class="hljs-literal"><span class="hljs-literal">-manager</span></span><span class="hljs-literal"><span class="hljs-literal">-daemons</span></span> cloudera<span class="hljs-literal"><span class="hljs-literal">-manager</span></span><span class="hljs-literal"><span class="hljs-literal">-server</span></span></code> </pre> <br>  <b>17. Wenn die</b> Pakete installiert sind, können Sie vor der Installation mit der Konfiguration der Software beginnen. <br><br><h3>  Ergänzung: </h3><br><p>  Während der Entwicklung und des Betriebs des Systems müssen Sie dem yum-Repository Pakete hinzufügen, um sie auf den Cluster-Hosts zu installieren (z. B. Anaconda-Distribution).  Dazu müssen Sie zusätzlich zum Übertragen der Dateien in den Ordner yum_repo die folgenden Aktionen ausführen: <br><br></p><ul><li>  Führen Sie auf dem Computer mit httpd den Befehl yum repository update aus: <br><br><pre> <code class="hljs powershell">createrepo <span class="hljs-literal"><span class="hljs-literal">-v</span></span> -<span class="hljs-literal"><span class="hljs-literal">-update</span></span> /var/www/html/yum_repo/</code> </pre> </li><li>  Führen Sie auf allen Computern, auf denen Sie Pakete installieren möchten, eine Leerung der Yum-Caches durch: </li><li><pre> <code class="hljs pgsql">yum clean <span class="hljs-keyword"><span class="hljs-keyword">all</span></span></code> </pre> </li><li><pre> <code class="hljs swift">rm -rf /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/cache/yum</code> </pre> </li></ul><br><h2>  Hilfssoftware konfigurieren </h2><br><p>  Es ist Zeit, PostgreSQL zu konfigurieren und Datenbanken für unsere zukünftigen Dienste zu erstellen.  Diese Einstellungen sind für CDH Version 5.12.1 relevant. Wenn Sie andere Versionen der Distribution installieren, wird empfohlen, den Abschnitt "Cloudera Manager und Managed Service Datastores" auf der offiziellen Website zu lesen. </p><br><p>  Initialisieren wir zunächst die Datenbank: </p><br><pre> <code class="hljs powershell">postgresql<span class="hljs-literal"><span class="hljs-literal">-setup</span></span> initdb</code> </pre> <br>  Jetzt richten wir die Netzwerkinteraktion mit der Datenbank ein.  <b>Ändern Sie</b> in der Datei <b>/var/lib/pgsql/data/pg_hba.conf</b> im Abschnitt IPv4-Lokalverbindungen die Methode für die Adresse 127.0.0.1/32 in die Methode md5, fügen Sie die Vertrauensmethode hinzu und fügen Sie das Clustersubnetz mit der Vertrauensmethode hinzu :: <br><br><pre> <code class="hljs pgsql">vi /var/lib/pgsql/data/pg_hba.conf pg_hba.conf: <span class="hljs-comment"><span class="hljs-comment">----------------------------------------------------------------------- # TYPE DATABASE USER ADDRESS METHOD # "local" is for Unix domain socket connections only local all all peer # IPv4 local connections: host all all 127.0.0.1/32 md5 host all all 127.0.0.1/32 trust host all all &lt;cluster_subnet&gt; trust -----------------------------------------------------------------------</span></span></code> </pre> <br><p>  Dann werden wir einige Anpassungen an der Datei <b>/var/lib/pgsql/data/postgres.conf vornehmen</b> (ich werde nur die Zeilen <b>angeben</b> , die geändert oder auf Konformität überprüft werden müssen: <br><br></p><pre> <code class="hljs cs">vi /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/pgsql/data/postgres.conf postgres.conf: ----------------------------------------------------------------------- listen_addresses = <span class="hljs-string"><span class="hljs-string">'*'</span></span> max_connections = <span class="hljs-number"><span class="hljs-number">100</span></span> shared_buffers = <span class="hljs-number"><span class="hljs-number">256</span></span>MB checkpoint_segments = <span class="hljs-number"><span class="hljs-number">16</span></span> checkpoint_completion_target = <span class="hljs-number"><span class="hljs-number">0.9</span></span> logging_collector = <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> log_filename = <span class="hljs-string"><span class="hljs-string">'postgresql-%a.log'</span></span> log_truncate_on_rotation = <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> log_rotation_age = <span class="hljs-number"><span class="hljs-number">1</span></span>d log_rotation_size = <span class="hljs-number"><span class="hljs-number">0</span></span> log_timezone = <span class="hljs-string"><span class="hljs-string">'W-SU'</span></span> datestyle = <span class="hljs-string"><span class="hljs-string">'iso, mdy'</span></span> timezone = <span class="hljs-string"><span class="hljs-string">'W-SU'</span></span> lc_messages = <span class="hljs-string"><span class="hljs-string">'en_US.UTF-8'</span></span> lc_monetary = <span class="hljs-string"><span class="hljs-string">'en_US.UTF-8'</span></span> lc_numeric = <span class="hljs-string"><span class="hljs-string">'en_US.UTF-8'</span></span> lc_time = <span class="hljs-string"><span class="hljs-string">'en_US.UTF-8'</span></span> default_text_search_config = <span class="hljs-string"><span class="hljs-string">'pg_catalog.english'</span></span> -----------------------------------------------------------------------</code> </pre> <br><p>  Nach Abschluss der Konfiguration müssen Sie Datenbanken (für diejenigen, die näher an der Oracle-Terminologie sind - Schemata) für die Dienste erstellen, die wir installieren werden.  In unserem Fall wurden die folgenden Dienste installiert: Cloudera Management Service, HDFS, Hive, Hue, Impala, Oozie, Yarn und ZooKeeper.  Von diesen benötigen Hive, Hue und Oozie Datenbanken, und zwei Basen werden für die Anforderungen von Cloudera-Diensten benötigt - eine für den Cloudera Manager-Server, die andere für den Berichts-Manager, der Teil des Cloudera Management Service ist.  Starten Sie PostgreSQL und fügen Sie es dem Autoload hinzu: <br><br></p><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> postgresql systemctl <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span> postgresql</code> </pre> <br><p>  Jetzt können wir die erforderlichen Datenbanken verbinden und erstellen: <br><br></p><pre> <code class="hljs pgsql">sudo -u postgres psql &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ROLE</span></span> scm <span class="hljs-keyword"><span class="hljs-keyword">LOGIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">PASSWORD</span></span> <span class="hljs-string"><span class="hljs-string">'&lt;password&gt;'</span></span>; &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DATABASE</span></span> scm <span class="hljs-keyword"><span class="hljs-keyword">OWNER</span></span> scm <span class="hljs-keyword"><span class="hljs-keyword">ENCODING</span></span> <span class="hljs-string"><span class="hljs-string">'UTF8'</span></span>; #    Cloudera Manager &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ROLE</span></span> rman <span class="hljs-keyword"><span class="hljs-keyword">LOGIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">PASSWORD</span></span> <span class="hljs-string"><span class="hljs-string">'&lt;password&gt;'</span></span>; &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DATABASE</span></span> rman <span class="hljs-keyword"><span class="hljs-keyword">OWNER</span></span> rman <span class="hljs-keyword"><span class="hljs-keyword">ENCODING</span></span> <span class="hljs-string"><span class="hljs-string">'UTF8'</span></span>; #      &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ROLE</span></span> hive <span class="hljs-keyword"><span class="hljs-keyword">LOGIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">PASSWORD</span></span> <span class="hljs-string"><span class="hljs-string">'&lt;password&gt;'</span></span>; &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DATABASE</span></span> metastore <span class="hljs-keyword"><span class="hljs-keyword">OWNER</span></span> hive <span class="hljs-keyword"><span class="hljs-keyword">ENCODING</span></span> <span class="hljs-string"><span class="hljs-string">'UTF8'</span></span>; #    Hive Metastore &gt; <span class="hljs-keyword"><span class="hljs-keyword">ALTER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DATABASE</span></span> metastore <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> standard_conforming_strings = <span class="hljs-keyword"><span class="hljs-keyword">off</span></span>; #   PostgreSQL   <span class="hljs-number"><span class="hljs-number">8.2</span></span><span class="hljs-number"><span class="hljs-number">.23</span></span> &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ROLE</span></span> hue_u <span class="hljs-keyword"><span class="hljs-keyword">LOGIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">PASSWORD</span></span> <span class="hljs-string"><span class="hljs-string">'&lt;password&gt;'</span></span>; &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DATABASE</span></span> hue_d <span class="hljs-keyword"><span class="hljs-keyword">OWNER</span></span> hue_u <span class="hljs-keyword"><span class="hljs-keyword">ENCODING</span></span> <span class="hljs-string"><span class="hljs-string">'UTF8'</span></span>; #    Hue &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ROLE</span></span> oozie <span class="hljs-keyword"><span class="hljs-keyword">LOGIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ENCRYPTED</span></span> <span class="hljs-keyword"><span class="hljs-keyword">PASSWORD</span></span> <span class="hljs-string"><span class="hljs-string">'&lt;password&gt;'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOSUPERUSER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INHERIT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">CREATEDB</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOCREATEROLE</span></span>; &gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DATABASE</span></span> "oozie" <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> OWNER = oozie ENCODING = <span class="hljs-string"><span class="hljs-string">'UTF8'</span></span> TABLESPACE = pg_default LC_COLLATE = <span class="hljs-string"><span class="hljs-string">'en_US.UTF-8'</span></span> LC_CTYPE = <span class="hljs-string"><span class="hljs-string">'en_US.UTF-8'</span></span> CONNECTION LIMIT = <span class="hljs-number"><span class="hljs-number">-1</span></span>; #    Oozie    : &gt; \q</code> </pre> <br><p>  Für andere Dienste werden Datenbanken auf die gleiche Weise erstellt. </p><br><p>  Vergessen Sie nicht, das Skript auszuführen, um die Cloudera Manager-Serverdatenbank vorzubereiten, und übergeben Sie ihm die Eingabedaten, um eine Verbindung zu der dafür erstellten Datenbank herzustellen: <br><br></p><pre> <code class="hljs pgsql">. /usr/<span class="hljs-keyword"><span class="hljs-keyword">share</span></span>/cmf/<span class="hljs-keyword"><span class="hljs-keyword">schema</span></span>/scm_prepare_database.sh postgresql scm scm &lt;<span class="hljs-keyword"><span class="hljs-keyword">password</span></span>&gt;</code> </pre> <br><h2>  Erstellen eines Repositorys mit CDH-Dateien </h2><br><p>  Cloudera bietet zwei Möglichkeiten zur Installation von CDH - mithilfe von Paketen und Paketen.  Die erste Option umfasst das Herunterladen einer Reihe von Paketen mit Diensten der erforderlichen Versionen und deren anschließende Installation.  Diese Methode bietet große Flexibilität bei der Clusterkonfiguration, Cloudera garantiert jedoch nicht deren Kompatibilität.  Daher ist die zweite Version der Installation mit Parsels beliebter - vorgeformte Sätze von Paketen kompatibler Versionen.  Die neuesten Versionen finden Sie unter folgendem Link: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">archive.cloudera.com/cdh5/parcels/latest</a> .  Früher kann ein höheres Level gefunden werden.  Zusätzlich zur Parsel von CDH müssen Sie manifest.json aus demselben Repository-Verzeichnis herunterladen. </p><br><p>  Um die entwickelte Funktionalität nutzen zu können, benötigten wir außerdem Spark 2.2, das nicht im CDH-Paket enthalten ist (die erste Version dieses Dienstes ist dort verfügbar).  Um es zu installieren, müssen Sie ein separates Paket mit diesem Dienst und der entsprechenden manifest.json herunterladen, die auch im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cloudera-Archiv</a> verfügbar ist. </p><br><p>  Nachdem Sie die Parsels und die Datei manifest.json geladen haben, müssen Sie sie in die entsprechenden Ordner in unserem Repository übertragen.  Erstellen Sie separate Ordner für CDH- und Spark-Dateien: <br><br></p><pre> <code class="hljs dos"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /var/www/html/parcels <span class="hljs-built_in"><span class="hljs-built_in">mkdir</span></span> cdh spark</code> </pre> <br><p>  Übertragen Sie die Dateien parsels und manifest.json in die erstellten Ordner.  Um sie für die Installation über das Netzwerk verfügbar zu machen, geben wir den entsprechenden Ordner für Zugriffsberechtigungen mit Parsels aus: <br><br></p><pre> <code class="hljs swift">chmod -<span class="hljs-type"><span class="hljs-type">R</span></span> ugo+rX /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/www/html/parcels</code> </pre> <br><p>  Sie können mit der Installation von CDH beginnen, die ich im nächsten Beitrag erläutern werde. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de413149/">https://habr.com/ru/post/de413149/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de413139/index.html">Elektroautos: Die Revolution kommt</a></li>
<li><a href="../de413141/index.html">Klassifizieren Sie große Datenmengen in Apache Spark mithilfe beliebiger Modelle für maschinelles Lernen</a></li>
<li><a href="../de413143/index.html">Bobby Urban Lite: Der neue Urban Backpack von XD Design</a></li>
<li><a href="../de413145/index.html">Analyst hilft Unternehmen, Geld zu verdienen</a></li>
<li><a href="../de413147/index.html">Ist es möglich, Tibero anstelle von Oracle zu verwenden? Und ist es notwendig</a></li>
<li><a href="../de413151/index.html">Die NSA schlug einen Verschlüsselungsstandard für IoT-Geräte vor, der von ISO jedoch abgelehnt wurde</a></li>
<li><a href="../de413155/index.html">Googles Shell Style Guide (auf Russisch)</a></li>
<li><a href="../de413157/index.html">Informationen zum Speichern von Passwörtern in der Datenbank</a></li>
<li><a href="../de413159/index.html">Dunkle oder helle Benutzeroberfläche? Tipps zur Auswahl eines Farbschemas für Ihre Benutzeroberfläche</a></li>
<li><a href="../de413161/index.html">Git Gedicht</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
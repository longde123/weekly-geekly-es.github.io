<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👃🏻 🚬 🥚 Ceph. Katastrophenanatomie 👩🏽‍🚀 👨🏾‍🔬 🚒</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ceph ist ein Objektspeicher, mit dem ein Failovercluster erstellt werden kann. Trotzdem passieren Fehler. Jeder, der mit Ceph arbeitet, kennt die Lege...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ceph. Katastrophenanatomie</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/431536/">  Ceph ist ein Objektspeicher, mit dem ein Failovercluster erstellt werden kann.  Trotzdem passieren Fehler.  Jeder, der mit Ceph arbeitet, kennt die Legende über CloudMouse oder Rosreestr.  Leider ist es nicht üblich, negative Erfahrungen mit uns zu teilen, die Ursachen von Fehlern werden meistens vertuscht und erlauben zukünftigen Generationen nicht, aus den Fehlern anderer zu lernen. <br><br>  Nun, lassen Sie uns einen Testcluster einrichten, der jedoch dem realen nahe kommt, und die Katastrophe anhand von Knochen analysieren.  Wir werden alle Leistungseinbußen messen, Speicherlecks finden und den Service-Wiederherstellungsprozess analysieren.  Und all dies unter der Führung von Artemy Kapitula, der fast ein Jahr lang Fallstricke studierte, führte dazu, dass die Clusterleistung bei Null versagte und die Latenz nicht auf unanständige Werte sprang.  Und ich habe eine rote Grafik, die viel besser ist. <br><img src="https://habrastorage.org/webt/c8/nr/1a/c8nr1akew1kjleodu5trq_ow3oy.png"><br><br>  Als nächstes finden Sie eine Video- und Textversion eines der besten Berichte von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DevOpsConf Russia</a> 2018. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/_fWYUl2QsoI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><a name="habracut"></a><br>  <strong>Über den Sprecher:</strong> Artemy Kapitula Systemarchitekt RCNTEC.  Das Unternehmen bietet IP-Telefonielösungen an (Zusammenarbeit, Organisation eines Remote-Büros, softwaredefinierte Speichersysteme und Energieverwaltungs- / Verteilungssysteme).  Das Unternehmen ist hauptsächlich im Unternehmensbereich tätig und daher auf dem DevOps-Markt nicht sehr bekannt.  Dennoch wurden einige Erfahrungen mit Ceph gesammelt, das in vielen Projekten als Grundelement der Speicherinfrastruktur verwendet wird. <br><br>  <strong>Ceph ist ein softwaredefiniertes Repository mit vielen Softwarekomponenten.</strong> <br><img src="https://habrastorage.org/webt/dw/ow/hm/dwowhmqvjfugd0u-ljhhz3fy2ji.png"><br><br>  Im Diagramm: <br><br><ul><li>  Die obere Ebene ist das interne Clusternetzwerk, über das der Cluster selbst kommuniziert. </li><li>  Die untere Ebene - eigentlich Ceph - ist eine Reihe von internen Ceph-Dämonen (MON, MDS und OSD), die Daten speichern. </li></ul><br>  In der Regel werden alle Daten repliziert. Im Diagramm habe ich absichtlich drei Gruppen mit jeweils drei OSDs ausgewählt, und jede dieser Gruppen enthält normalerweise eine Datenreplik.  Infolgedessen werden Daten in drei Kopien gespeichert. <br><br>  Ein übergeordnetes Clusternetzwerk ist das Netzwerk, über das Ceph-Clients auf Daten zugreifen.  Über sie kommunizieren Clients mit dem Monitor, mit MDS (wer benötigt es) und mit OSD.  Jeder Client arbeitet mit jedem OSD und mit jedem Monitor unabhängig.  Daher weist das <strong>System keinen einzigen Fehlerpunkt auf</strong> , was sehr erfreulich ist. <br><br><h2>  Kunden <br></h2><br>  ● S3-Kunden <br><br>  S3 ist eine API für HTTP.  S3-Clients arbeiten über HTTP und stellen eine Verbindung zu RGW-Komponenten (Ceph Rados Gateway) her.  Sie kommunizieren fast immer mit einer Komponente über ein dediziertes Netzwerk.  Dieses Netzwerk (ich habe es S3-Netzwerk genannt) verwendet nur HTTP, Ausnahmen sind selten. <br><br>  ● Hypervisor mit virtuellen Maschinen <br><br>  Diese Kundengruppe wird häufig verwendet.  Sie arbeiten mit Monitoren und mit OSD, von denen sie allgemeine Informationen über den Clusterstatus und die Datenverteilung erhalten.  Für Daten gehen diese Clients über das öffentliche Cluster-Netzwerk direkt zu OSD-Daemons. <br><br>  ● RBD-Clients <br><br>  Es gibt auch physische BR-Metall-Hosts, bei denen es sich normalerweise um Linux handelt.  Sie sind RBD-Clients und erhalten Zugriff auf Images, die in einem Ceph-Cluster gespeichert sind (Images der virtuellen Maschine). <br><br>  ● CephFS-Clients <br><br>  Die vierte Gruppe von Clients, die noch nicht viele haben, aber von wachsendem Interesse sind, sind CephFS-Cluster-Dateisystem-Clients.  Das CephFS-Clustersystem kann gleichzeitig von vielen Knoten bereitgestellt werden, und alle Knoten erhalten Zugriff auf dieselben Daten, wobei sie mit jedem OSD arbeiten.  Das heißt, es gibt keine Gateways als solche (Samba, NFS und andere).  Das Problem ist, dass ein solcher Client nur Linux und eine ziemlich moderne Version sein kann. <br><img src="https://habrastorage.org/webt/fw/nm/xc/fwnmxcaiig0yy6tkofrljqri3ck.png"><br><br>  Unser Unternehmen arbeitet auf dem Unternehmensmarkt, und dort wird der Ball von ESXi, HyperV und anderen regiert.  Dementsprechend muss der Ceph-Cluster, der irgendwie im Unternehmenssektor verwendet wird, die entsprechenden Techniken unterstützen.  Dies war uns bei Ceph nicht genug, daher mussten wir den Ceph-Cluster mit unseren Komponenten verfeinern und erweitern und tatsächlich etwas mehr als Ceph aufbauen, unsere eigene Plattform zum Speichern von Daten. <br><br>  Darüber hinaus arbeiten Kunden im Unternehmenssektor nicht unter Linux, aber die meisten von ihnen, Windows, gelegentlich Mac OS, können nicht selbst zum Ceph-Cluster wechseln.  Sie müssen durch eine Art Gateway laufen, die in diesem Fall zu Engpässen werden. <br><br>  Wir mussten alle diese Komponenten hinzufügen und erhielten einen etwas breiteren Cluster. <br><img src="https://habrastorage.org/webt/p2/tg/j2/p2tgj2qtpzrzsnst5bophkclywi.png"><br><br>  Wir haben zwei zentrale Komponenten: die <strong>SCSI-Gateways-Gruppe</strong> , die über FibreChannel oder iSCSI den Zugriff auf Daten in einem Ceph-Cluster ermöglicht.  Diese Komponenten werden verwendet, um HyperV und ESXi mit einem Ceph-Cluster zu verbinden.  PROXMOX-Kunden arbeiten immer noch auf ihre eigene Art und Weise - über RBD. <br><br>  Wir lassen Dateiclients nicht direkt in das Clusternetzwerk, da ihnen mehrere fehlertolerante Gateways zugewiesen sind.  Jedes Gateway bietet Zugriff auf das Dateiclustersystem über NFS, AFP oder SMB.  Dementsprechend erhält fast jeder Client, sei es Linux, FreeBSD oder nicht nur ein Client, Server (OS X, Windows), Zugriff auf CephFS. <br><br>  Um all dies zu bewältigen, mussten wir tatsächlich unser eigenes Ceph-Orchester und alle unsere Komponenten entwickeln, die dort zahlreich sind.  Aber jetzt darüber zu sprechen macht keinen Sinn, da dies unsere Entwicklung ist.  Die meisten werden sich wahrscheinlich für den "nackten" Ceph selbst interessieren. <br><br>  Ceph wird häufig verwendet, und gelegentlich treten Fehler auf.  Sicher kennt jeder, der mit Ceph arbeitet, die Legende über CloudMouse.  Dies ist eine schreckliche urbane Legende, aber dort ist nicht alles so schlimm, wie es scheint.  Es gibt ein neues Märchen über Rosreestr.  Ceph drehte sich überall und überall versagte es.  Irgendwo endete es tödlich, irgendwo gelang es, die Konsequenzen schnell zu beseitigen. <br><br>  Leider ist es für uns nicht üblich, negative Erfahrungen auszutauschen, jeder versucht, die relevanten Informationen zu verbergen.  Ausländische Unternehmen sind etwas offener, insbesondere DigitalOcean (ein bekannter Anbieter, der virtuelle Maschinen vertreibt) erlitt fast einen Tag lang einen Ceph-Ausfall. Es war der 1. April - ein wunderbarer Tag!  Sie haben einige der Berichte veröffentlicht, ein kurzes Protokoll unten. <br><img src="https://habrastorage.org/webt/qo/sb/ds/qosbdsczlkvzh-zqsfvid86er5u.png"><br><br>  Die Probleme begannen um 7 Uhr morgens, um 11 Uhr verstanden sie, was geschah, und begannen, den Fehler zu beseitigen.  Zu diesem Zweck haben sie zwei Befehle zugewiesen: Einer lief aus irgendeinem Grund um die Server herum und installierte dort Speicher, und der zweite startete aus irgendeinem Grund manuell einen Server nach dem anderen und überwachte sorgfältig alle Server.  Warum?  Wir sind alle daran gewöhnt, alles mit einem Klick einzuschalten. <br><br>  <em>Was passiert grundsätzlich in einem verteilten System, wenn es effektiv aufgebaut ist und fast an der Grenze seiner Fähigkeiten arbeitet?</em> <br><br>  Um diese Frage zu beantworten, müssen wir uns ansehen, wie der Ceph-Cluster funktioniert und wie der Fehler auftritt. <br><img src="https://habrastorage.org/webt/ln/ks/rd/lnksrda1mb-lmfbymyacym1f8aw.png"><br><br><h2>  Ceph-Fehlerszenario <br></h2><br>  Zuerst funktioniert der Cluster gut, alles läuft gut.  Dann passiert etwas, wonach die OSD-Dämonen, in denen die Daten gespeichert sind, den Kontakt zu den zentralen Komponenten des Clusters (Monitore) verlieren.  Zu diesem Zeitpunkt tritt eine Zeitüberschreitung auf und der gesamte Cluster erhält einen Einsatz.  Der Cluster bleibt eine Weile stehen, bis er erkennt, dass etwas mit ihm nicht stimmt, und korrigiert danach sein internes Wissen.  Danach wird der Kundenservice bis zu einem gewissen Grad wiederhergestellt, und der Cluster arbeitet wieder in einem herabgesetzten Modus.  Und das Lustige ist, dass es schneller funktioniert als im normalen Modus - das ist eine erstaunliche Tatsache. <br><br>  Dann beseitigen wir den Fehler.  Angenommen, wir haben den Strom verloren, das Rack wurde komplett abgeschnitten.  Elektriker kamen angerannt, sie alle restauriert, sie versorgten die Server mit Strom, die Server wurden eingeschaltet und dann <strong>beginnt der Spaß</strong> . <br><br><blockquote>  Jeder ist daran gewöhnt, dass bei einem Serverausfall alles schlecht wird und beim Einschalten des Servers alles gut wird.  Hier ist alles völlig falsch. <br></blockquote><br>  Der Cluster stoppt praktisch, führt die primäre Synchronisation durch und beginnt dann eine reibungslose, langsame Wiederherstellung, wobei er allmählich in den normalen Modus zurückkehrt. <br><img src="https://habrastorage.org/webt/ml/r_/i3/mlr_i3llw-lsdaybp4vbedxeuhi.png"><br><br>  Oben sehen Sie eine grafische Darstellung der Ceph-Clusterleistung, wenn sich ein Fehler entwickelt.  Bitte beachten Sie, dass hier genau die Intervalle, über die wir gesprochen haben, sehr deutlich nachvollzogen werden: <br><br><ul><li>  Normalbetrieb bis ca. 70 Sekunden; </li><li>  Ausfall für eine Minute bis ca. 130 Sekunden; </li><li>  Ein Plateau, das merklich höher als der normale Betrieb ist, ist die Arbeit von degradierten Clustern; </li><li>  Dann schalten wir den fehlenden Knoten ein - dies ist ein Trainingscluster, es gibt nur 3 Server und 15 SSDs.  Wir starten den Server irgendwo um 260 Sekunden. </li><li>  Der Server wurde eingeschaltet und trat in den Cluster ein - IOPS'y fiel. </li></ul><br>  Versuchen wir herauszufinden, was dort wirklich passiert ist.  Das erste, was uns interessiert, ist ein Eintauchen ganz am Anfang des Diagramms. <br><br><h3>  OSD-Fehler <br></h3><br>  Stellen Sie sich ein Beispiel für einen Cluster mit drei Racks mit jeweils mehreren Knoten vor.  Wenn das linke Rack ausfällt, pingen sich alle OSD-Daemons (keine Hosts!) In einem bestimmten Intervall mit Ceph-Nachrichten.  Wenn mehrere Nachrichten verloren gehen, wird eine Nachricht an den Monitor gesendet: "Ich, OSD so und so, kann OSD so und so nicht erreichen." <br><img src="https://habrastorage.org/webt/zh/1s/ge/zh1sge1ljlclxjmgfygxpyyyc8i.png"><br><br>  In diesem Fall werden Nachrichten normalerweise nach Hosts gruppiert. Wenn also zwei Nachrichten von verschiedenen OSDs auf demselben Host eintreffen, werden sie zu einer Nachricht zusammengefasst.  Wenn OSD 11 und OSD 12 melden, dass sie OSD 1 nicht erreichen können, wird dies als Host 11 interpretiert, der über OSD 1 beschwert ist. Wenn OSD 21 und OSD 22 gemeldet wurden, wird dies als Host 21 interpretiert, der mit OSD 1 unzufrieden ist Danach berücksichtigt der Monitor, dass sich OSD 1 im Status "Down" befindet, und benachrichtigt alle Mitglieder des Clusters (durch Ändern der OSD-Zuordnung). Die Arbeit wird im herabgesetzten Modus fortgesetzt. <br><img src="https://habrastorage.org/webt/uu/-c/1w/uu-c1wnwflbqk6ueyumhohtlvjy.png"><br><br>  Hier ist also unser Cluster und das ausgefallene Rack (Host 5 und Host 6).  Wir schalten Host 5 und Host 6 ein, als die Stromversorgung erschien, und ... <br><br><h3>  Cephs inneres Verhalten <br></h3><br>  Und jetzt ist der interessanteste Teil, dass wir mit der <strong>anfänglichen Datensynchronisation beginnen</strong> .  Da es viele Replikate gibt, müssen diese synchron sein und dieselbe Version haben.  Beim Starten des OSD-Starts: <br><br><ul><li>  OSD liest die verfügbaren Versionen und den verfügbaren Verlauf (pg_log - um die aktuellen Versionen von Objekten zu ermitteln). </li><li>  Danach wird festgelegt, auf welchem ​​OSD die neuesten Versionen von herabgesetzten Objekten (missing_loc) aktiviert sind und welche sich dahinter befinden. </li><li>  Wenn die Rückwärtsversionen gespeichert sind, ist eine Synchronisierung erforderlich, und neue Versionen können als Referenz zum Lesen und Schreiben von Daten verwendet werden. </li></ul><br>  Es wird eine Geschichte verwendet, die von allen OSDs gesammelt wird, und diese Geschichte kann ziemlich viel sein;  Der tatsächliche Standort der Gruppe von Objekten im Cluster, in dem sich die entsprechenden Versionen befinden, wird bestimmt.  Wie viele Objekte sich im Cluster befinden, wie viele Datensätze erhalten werden, wenn der Cluster lange Zeit im herabgesetzten Modus gestanden hat, ist die Geschichte lang. <br><br>  <strong>Zum Vergleich: Die</strong> typische Größe eines Objekts bei der Arbeit mit einem RBD-Bild beträgt 4 MB.  Wenn wir in Löschcode arbeiten - 1 MB.  Wenn wir eine 10-TB-Festplatte haben, erhalten wir eine Million Megabyte-Objekte auf der Festplatte.  Wenn wir 10 Festplatten auf dem Server haben, gibt es bereits 10 Millionen Objekte. Wenn 32 Festplatten vorhanden sind (wir bauen einen effizienten Cluster auf, wir haben eine enge Zuordnung), müssen 32 Millionen Objekte im Speicher gehalten werden.  Darüber hinaus werden Informationen zu jedem Objekt in mehreren Kopien gespeichert, da jede Kopie angibt, dass sie an dieser Stelle in dieser Version und in dieser - in dieser - liegt. <br><br>  Es stellt sich heraus, dass sich eine große Datenmenge im RAM befindet: <br><br><ul><li>  Je mehr Objekte vorhanden sind, desto größer ist die Historie von missing_loc. </li><li>  je mehr PG - desto mehr pg_log und OSD-Map; </li></ul><br>  Außerdem: <br><br><ul><li>  je größer die Festplattengröße ist; </li><li>  je höher die Dichte (die Anzahl der Festplatten in jedem Server); </li><li>  Je höher die Belastung des Clusters und desto schneller Ihr Cluster. </li><li>  je länger das OSD inaktiv ist (im Offline-Status); </li></ul><br>  Mit anderen Worten, je <strong>steiler der von uns erstellte Cluster ist und je länger der Teil des Clusters nicht reagiert, desto mehr RAM wird beim Start benötigt</strong> . <br><br><h2>  Extreme Optimierungen sind die Wurzel allen Übels <br></h2><br><blockquote>  <em>"... und der schwarze OOM kommt nachts zu den bösen Jungs und Mädchen und tötet alle Prozesse links und rechts ab."</em> <br><br>  Stadt Sysadmin Legende <br></blockquote><br>  RAM benötigt also viel, der Speicherverbrauch steigt (wir haben sofort mit einem Drittel des Clusters begonnen), und das System kann theoretisch in SWAP integriert werden, wenn Sie es natürlich erstellt haben.  Ich denke, es gibt viele Leute, die SWAP für schlecht halten und es nicht schaffen: „Warum?  Wir haben viel Gedächtnis! “  Dies ist jedoch der falsche Ansatz. <br><br>  Wenn die SWAP-Datei nicht im Voraus erstellt wurde, da entschieden wurde, dass Linux effizienter arbeitet, wird es früher oder später zu einem Speicherkiller (OOM-Killer) kommen. Und nicht zu der Tatsache, dass derjenige getötet wird, der den gesamten Speicher verschlungen hat, nicht derjenige, der zuerst Pech hatte.  Wir wissen, was ein optimistischer Ort ist - wir bitten um eine Erinnerung, sie versprechen es uns, wir sagen: "Jetzt gib uns eine", als Antwort: "Aber nein!"  - und aus dem Gedächtnis Killer. <br><br>  Dies ist ein regulärer Linux-Job, sofern er nicht im Bereich des virtuellen Speichers konfiguriert ist. <br><br>  Der Prozess wird aus dem Gedächtnis Killer und fällt schnell und rücksichtslos aus.  Darüber hinaus wissen keine anderen Prozesse, die er starb, nicht.  Er hatte keine Zeit, irgendjemanden über irgendetwas zu informieren, sie kündigten ihn einfach. <br><br>  Dann wird der Prozess natürlich neu gestartet - wir haben systemd, es startet bei Bedarf auch OSDs, die gefallen sind.  Gefallene OSDs beginnen und ... eine Kettenreaktion beginnt. <br><img src="https://habrastorage.org/webt/9p/s8/4z/9ps84zkjtmuamxyllkcgffsgxkq.png"><br><br>  In unserem Fall haben wir OSD 8 und OSD 9 gestartet, sie haben angefangen, alles zu zerstören, aber kein Glück, OSD 0 und OSD 5. Ein Killer ohne Speicher flog zu ihnen und beendete sie.  Sie starteten neu - sie lasen ihre Daten, begannen den Rest zu synchronisieren und zu zerstören.  Drei weitere Pechvögel (OSD 9, OSD 4 und OSD 7).  Diese drei starteten neu, übten Druck auf den gesamten Cluster aus, die nächste Packung hatte Pech. <br><br>  <strong>Der Cluster beginnt buchstäblich vor unseren Augen auseinanderzufallen</strong> .  Der Abbau erfolgt sehr schnell, und dieses "sehr schnelle" wird normalerweise in Minuten ausgedrückt, maximal zehn Minuten.  Wenn Sie 30 Knoten (10 Knoten pro Rack) haben und das Rack aufgrund eines Stromausfalls herunterfahren, liegt nach 6 Minuten die Hälfte des Clusters. <br><br>  Wir bekommen also so etwas wie das Folgende. <br><img src="https://habrastorage.org/webt/1b/hq/bu/1bhqburpjt74vwnpbgqn5ehdhh0.png"><br><br>  Auf fast jedem Server ist ein OSD ausgefallen.  Und wenn dies auf jedem Server der Fall ist, dh in jeder Fehlerdomäne, <strong>die</strong> wir für das ausgefallene OSD haben, sind die <strong>meisten unserer Daten nicht zugänglich</strong> .  Jede Anfrage ist blockiert - zum Schreiben, zum Lesen - es macht keinen Unterschied.  Das ist alles!  Wir sind aufgestanden. <br><br>  Was tun in einer solchen Situation?  Genauer gesagt, <strong>was musste getan werden</strong> ? <br><br>  <strong>Antwort:</strong> Starten Sie den Cluster nicht sofort, dh das gesamte Rack, sondern heben Sie vorsichtig jeweils einen Dämon auf. <br><br>  Das wussten wir aber nicht.  Wir haben sofort angefangen und bekommen, was wir haben.  In diesem Fall haben wir einen der vier Daemons (8, 9, 10, 11) gestartet. Der Speicherverbrauch wird um ca. 20% steigen.  In der Regel stehen wir vor einem solchen Sprung.  Dann beginnt der Speicherverbrauch zu sinken, da einige der Strukturen, die zum Speichern von Informationen darüber verwendet wurden, wie sich der Cluster verschlechtert hat, verlassen werden.  Das heißt, ein Teil der Platzierungsgruppen ist in seinen normalen Zustand zurückgekehrt, und alles, was zur Aufrechterhaltung des verschlechterten Zustands erforderlich ist, wird freigegeben - <strong>theoretisch wird es freigegeben</strong> . <br><br>  Sehen wir uns ein Beispiel an.  Der C-Code links und rechts ist fast identisch, der Unterschied besteht nur in Konstanten. <br><img src="https://habrastorage.org/webt/sy/1j/u0/sy1ju0rfqjg507jxvk_4wax9_o4.png"><br><br>  Diese beiden Beispiele fordern vom System eine unterschiedliche Speichermenge an: <br><br><ul><li>  links - 2048 Stück à 1 MB; </li><li>  rechts - 2097152 Stück von 1 KByte. </li></ul><br>  Dann warten beide Beispiele darauf, dass wir sie oben fotografieren.  Und nach dem Drücken der EINGABETASTE wird Speicher freigegeben - alles außer dem letzten Stück.  Das ist sehr wichtig - das letzte Stück bleibt.  Und wieder warten sie darauf, dass wir sie fotografieren. <br><br>  Unten ist, was tatsächlich passiert ist. <br><img src="https://habrastorage.org/webt/zx/ah/ug/zxahugrdasantcktho7dbu-tnes.png"><br><br><ul><li>  Zuerst haben beide Prozesse gestartet und den Speicher aufgefressen.  Klingt nach der Wahrheit - 2 GB RSS. </li><li>  Drücken Sie ENTER und lassen Sie sich überraschen.  Das erste Programm, das in großen Stücken auffiel, gab Speicher zurück.  Das zweite Programm kehrte jedoch nicht zurück. </li></ul><br>  Die Antwort darauf liegt im Linux-Malloc. <br><br>  Wenn wir Speicher in großen Blöcken anfordern, wird er unter Verwendung des anonymen mmap-Mechanismus ausgegeben, der dem Adressraum des Prozessors zugewiesen wird, von wo aus der Speicher zu uns geschnitten wird.  Wenn wir free () ausführen, wird Speicher freigegeben und Seiten werden in den Seitencache (System) zurückgegeben. <br><br>  Wenn wir Speicher in kleinen Stücken zuweisen, machen wir sbrk ().  sbrk () verschiebt den Zeiger auf das Ende des Heaps. Theoretisch kann das verschobene Ende zurückgegeben werden, indem Speicherseiten an das System zurückgegeben werden, wenn kein Speicher verwendet wird. <br><br>  Schauen Sie sich nun die Abbildung an.  Wir hatten viele Aufzeichnungen in der Geschichte des Standorts degradierter Objekte, und dann kam die Benutzersitzung - ein langlebiges Objekt.  Wir haben synchronisiert und alle zusätzlichen Strukturen sind verschwunden, aber das langlebige Objekt ist geblieben, und wir können sbrk () nicht zurückbewegen. <br><img src="https://habrastorage.org/webt/06/wf/eg/06wfegwyvu0ibae8xjlwizrwteo.png"><br><br>  Wir haben immer noch viel ungenutzten Speicherplatz, der mit SWAP frei werden könnte.  Aber wir sind schlau - wir haben SWAP deaktiviert. <br><br>  Natürlich wird dann ein Teil des Speichers vom Anfang des Heaps verwendet, aber dies ist nur ein Teil, und ein sehr bedeutender Rest wird belegt bleiben. <br><br>  Was tun in einer solchen Situation?  Die Antwort ist unten. <br><br><h3>  Kontrollierter Start <br></h3><br><ul><li>  Wir starten einen OSD-Daemon. </li><li>  Wir warten, während es synchronisiert ist, wir überprüfen die Speicherbudgets. </li><li>  Wenn wir verstehen, dass wir den Start des nächsten Dämons überleben werden, starten wir den nächsten. </li><li>  Wenn nicht, starten Sie schnell den Daemon neu, der den meisten Speicherplatz beansprucht hat.  Er konnte für kurze Zeit ausfallen, er hat nicht viel Geschichte, fehlende Locs und andere Dinge, also wird er weniger Speicher essen, das Speicherbudget wird sich leicht erhöhen. </li><li>  Wir laufen um den Cluster herum, kontrollieren ihn und erhöhen schrittweise alles. </li><li>  Wir prüfen, ob es möglich ist, mit dem nächsten OSD fortzufahren. </li></ul><br>  DigitalOcean hat dies tatsächlich erreicht: <br>  <em>"Unser Datacenter-Team führt Speichererweiterungen durch, während ein anderes Team langsam weiterhin Knoten aufruft, während das Speicherbudget jedes Hosts manuell verwaltet wird."</em> <br><img src="https://habrastorage.org/webt/nr/yg/a1/nryga17av_ez5yj0mt3lm5grkk0.png"><br><br>  Kehren wir zu unserer Konfiguration und aktuellen Situation zurück.  Jetzt haben wir einen zusammengebrochenen Cluster nach einer Kettenreaktion von Out-of-Memory-Killer.  Wir verbieten den automatischen Neustart von OSD in der roten Domäne und starten nacheinander Knoten aus den blauen Domänen.  Weil <strong>unsere erste Aufgabe immer darin besteht, den Dienst wiederherzustellen</strong> , ohne zu verstehen, warum dies passiert ist.  Wir werden später verstehen, wenn wir den Dienst wiederherstellen.  Im Betrieb ist dies immer der Fall. <br><br>  Wir bringen den Cluster in den Zielzustand, um den Dienst wiederherzustellen, und beginnen dann, ein OSD nach unserer Methodik nach dem anderen auszuführen.  Wir schauen uns den ersten an, starten Sie bei Bedarf die anderen neu, um das Speicherbudget anzupassen, den nächsten - 9, 10, 11 - und der Cluster scheint synchronisiert und bereit zu sein, mit der Wartung zu beginnen. <br><br>  Das Problem ist, wie die <strong>Schreibwartung in Ceph durchgeführt wird</strong> . <br><img src="https://habrastorage.org/webt/hl/rp/ek/hlrpekm0rvjgrjwl11zgdklwecc.png"><br><br>  Wir haben 3 Replikate: ein Master-OSD und zwei Slaves dafür.  Wir werden klarstellen, dass der Master / Slave in jeder Platzierungsgruppe einen eigenen hat, aber jeder einen Master und zwei Slaves hat. <br><br>  Die Schreib- oder Leseoperation fällt auf den Master.  Wenn der Master beim Lesen die richtige Version hat, gibt er sie dem Kunden.  Die Aufnahme ist etwas komplizierter, die Aufnahme muss auf allen Replikaten wiederholt werden.  Wenn der Client 64 KB in OSD 0 schreibt, gehen dementsprechend die gleichen 64 KB in unserem Beispiel an OSD 5 und OSD 8. <br><br>  Tatsache ist jedoch, dass unser OSD 8 stark beeinträchtigt ist, da wir viele Prozesse neu gestartet haben. <br><img src="https://habrastorage.org/webt/es/_z/fr/es_zfrsvdaq8a7f_rgn7hcakpi4.png"><br><br>  Da in Ceph jede Änderung ein Übergang von Version zu Version ist, haben wir unter OSD 0 und OSD 5 eine neue Version, unter OSD 8 - die alte.  ,   ,    ( 64 )    OSD 8   —   4  ( ).     4   OSD 0,   OSD 8,  ,    .       ,      64 . <br><br>    —  . <br><img src="https://habrastorage.org/webt/ch/uc/l_/chucl_b0vhoi-jvuhl3xokm26qg.png"><br><br>   : <br><br><ul><li>    4   1 ,  1000 /  1 . </li><li>   4  ( )  22 ,  45 /. </li></ul><br> ,      ,       ,        ,         . <br><br>      —     . <br><img src="https://habrastorage.org/webt/it/0p/34/it0p34kbqfs3u9hvyhmextflvqc.png"><br><br>    4   22 ,  22 ,   1    4   .   45          SSD,       1  — <strong>   45 </strong> . <br><br>       ,    . <br><br><h2>    <br></h2><br><br><ul><li>   <strong> </strong> ,    — (45+1) / 2 = <strong>23 .</strong> </li><li>   <strong>75% </strong> ,  (45 * 3 + 1) / 4 = <strong>34 </strong> . </li><li>  90% —(45 * 9 + 1) / 10 = 41  —  40  ,   . </li></ul><br>     Ceph,      .                 ,     ,    ,     . <br><br>      Ceph       . <br><img src="https://habrastorage.org/webt/ng/jj/od/ngjjodzmfd4n6kes71g4n6pg7os.png"><br><br><ol><li>     —   :  , ,  ,  ,    . <br></li><li>  — latency.   latency  ,   .      100%    (    ,          ). Latency  60     ,       . <br></li></ol><br><img src="https://habrastorage.org/webt/z3/pb/ob/z3pbobkev0bfszscnwgprpop3xe.png"><br><br>       ,       .  10 ,   1 200 /,    300      ,    ,   .  10 SSD —   300   ,   — ,  - 300   . <br><br><blockquote>    ,     . <br></blockquote><br>  ,     .       900 / (  SSD).     2 500   128    ( , ESXi  HyperV     128 ).      degraded,   225   .     file store,   object store,         ( ),    110   ,     - . <br><br> SSD  110    — ! <br><br> <strong>   ?</strong> <br><br> <strong> 1:</strong>     — <b>   </b> . <br><img src="https://habrastorage.org/webt/ls/ib/rh/lsibrhcfnucjiox9f8gzxbk1cc8.png"><br><br>    :   ;   PG; <br>       . <br><br>    : <br><br><ul><li>    ,  45  —   . </li><li>     (     . ),   14 . </li><li>    ,  8  (  10% PG). </li></ul><br>   <strong>  ,  </strong> ,       , ,  ,     . <br><br> <strong> 2:</strong>   — <b>  </b> (order, objectsize)  . <br><br>     , , ,   4   2  1 .      ,     ,   .  : <br><br><ul><li>     ; </li><li>     (latency)     . </li></ul><br>     : <br><br><ul><li>    ; </li><li>     ; </li><li>   —        .     4 ,   . </li></ul><br>        (32  ) —      ! <br><br> <strong> 3:</strong>    —  <b> Ceph</b> . <br><br>     ,   -,  <strong> Ceph</strong> .                  ,      ,      .     . <br><img src="https://habrastorage.org/webt/c8/nr/1a/c8nr1akew1kjleodu5trq_ow3oy.png"><br><br>     ,   — Latency.  —  ,  — . Latency      30% ,       ,      . <br><br>  Community     ,     preproduction .     ,     .      ,   . <br><br><h1>  Fazit <br></h1><br>      -  ,     .        ,   Ceph    - ,  ,    . <br><br> ● <strong>   -  </strong> . <br>     ,     .  ,  <strong>     </strong> .       .  ,         ,    production.  ,       ,     ,    DigitalOcean  ,   .   ,  ,    ,  . <br><br>   ,        ,        .    ,  : «    !  ?!»     ,  ,     .   ,      : ,   ,    down time. <br><br> ● <strong>    (OSD).</strong> <br>  ,       ,     —     , ,  -      ,   . <strong>     OSD —    —   </strong> .    ,     . <br><br> ● <strong>  .</strong> <br>        OSD       . <strong>   ,   </strong> .  ,     ,     ,   . <br><br> ● <strong>  RAM   OSD.</strong> <br><br> ● <strong>  SWAP.</strong> <br>   SWAP    Ceph' ,    Linux' .         . <br><br> ● <strong>    .</strong> <br>         100%,    10%. ,    ,      ,   . <br><br> ● <strong>        RBD      Rados Getway.</strong> <br>  ,         . <strong>   SWAP —    .</strong> ,    SWAP  —    , ,  ,    ,     . <br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieser Artikel ist eine Abschrift eines der besten Berichte von DevOpsConf Russia. </font><font style="vertical-align: inherit;">In Kürze werden wir das Video öffnen und in einer Textversion veröffentlichen, wie interessant Themen sind. </font><font style="vertical-align: inherit;">Abonnieren Sie hier auf </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Youtube</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder im </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Newsletter,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wenn Sie solche nützlichen Materialien nicht verpassen und über die Neuigkeiten von DevOps informiert werden möchten.</font></font><br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431536/">https://habr.com/ru/post/de431536/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431526/index.html">Korrupter Einfluss: Wie die Stasi Ostdeutschland vor Videospielen verteidigte</a></li>
<li><a href="../de431528/index.html">Das mysteriöse mathematische Genie und der Schriftsteller fördern die Lösung des Permutationsproblems</a></li>
<li><a href="../de431530/index.html">Offene Lektion "Android Material Design: Update-Übersicht"</a></li>
<li><a href="../de431532/index.html">Memristoren bestehend aus 2 nm dicken Teilen</a></li>
<li><a href="../de431534/index.html">Problemidentitäten unter Entwicklern</a></li>
<li><a href="../de431538/index.html">Fallrate & Waren und Mobio: schrittweise Erhöhung aller Indikatoren</a></li>
<li><a href="../de431540/index.html">Pakete und Paketmanager für k8s</a></li>
<li><a href="../de431542/index.html">Effektive Entwicklung und Pflege von Ansible-Rollen</a></li>
<li><a href="../de431544/index.html">Tragen Sie DevOps zu den Massen</a></li>
<li><a href="../de431546/index.html">Warum sagen wir OK?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
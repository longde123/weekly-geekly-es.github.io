<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ùé üë∏üèª üë®üèæ‚Äçüé® ‚ÄûTiefes Verst√§rkungstraining. AlphaGo und andere Technologien ": die Ank√ºndigung des Buches üïê ü§úüèæ ü§±üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! 

 Wir haben eines der besten B√ºcher zum Thema Verst√§rkungstraining zur Vorbestellung, das urspr√ºnglich von Maxim Lapan als " Deep R...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>‚ÄûTiefes Verst√§rkungstraining. AlphaGo und andere Technologien ": die Ank√ºndigung des Buches</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/474276/">  Hallo allerseits! <br><br>  Wir haben eines der besten B√ºcher zum Thema Verst√§rkungstraining zur Vorbestellung, das urspr√ºnglich von Maxim Lapan als " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep Reinforcement Learning Hands-on</a> " bezeichnet wurde.  Hier ist das Cover der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">russischen √úbersetzung</a> : <br><br><img src="https://habrastorage.org/webt/av/ig/n-/avign-oqnxjpgpptv7irkkwsope.jpeg"><br><br>  Damit Sie die Zusammenfassung des Buches sch√§tzen k√∂nnen, bieten wir Ihnen eine √úbersetzung der vom Autor verfassten Rezension zur Ver√∂ffentlichung des Originals an. <br><a name="habracut"></a><br><br>  Hallo! <br><br>  Ich bin ein autodidaktischer Enthusiast, der tiefes Lernen liebt.  Als Vertreter des Packt-Verlags mich kontaktierten und mir vorschlugen, ein praktisches Buch √ºber den aktuellen Stand des tiefen Lernens mit Verst√§rkung zu schreiben, hatte ich ein wenig Angst, aber nach einigem Z√∂gern stimmte ich zu und ging optimistisch davon aus: ‚ÄûOh, es wird eine interessante Erfahrung geben.‚Äú <br>  Ich werde nicht sagen, dass mir diese Arbeit als einfacher Spaziergang gegeben wurde, nat√ºrlich nicht.  Sie haben keine freien Tage, keine Freizeit, st√§ndige Angst vor "eiskalter Dummheit" und die Einhaltung von Fristen f√ºr jedes Kapitel (zwei Wochen pro Kapitel und Beispielcode).  Im Allgemeinen verlief jedoch alles positiv und sehr interessant. <br><br>  Bevor wir den Inhalt jedes Kapitels kurz beschreiben, wollen wir die <i>Idee des gesamten Buches beschreiben</i> . <br>  Als ich vor mehr als vier Jahren anfing, in RL zu experimentieren, verf√ºgte ich √ºber folgende Informationsquellen: <br><br><ul><li>  Sutton und Barto Book of <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reinforcement Learning: Eine Einf√ºhrung</a> </li><li>  Wissenschaftliche Artikel auf <a href="">arxiv.org</a> </li><li>  Der Kurs von David Silver. </li></ul><br><br>  Vielleicht gab es noch etwas anderes, aber dies waren die wichtigsten Informationsquellen.  Alle von ihnen sind sehr weit von der Praxis entfernt: <br><br><ul><li>  Das Buch von Sutton und Barto, auch bekannt als "The RL Book", liefert nur die theoretischen Grundlagen dieser Disziplin. </li><li>  RL-bezogene Artikel werden fast t√§glich ver√∂ffentlicht, enthalten jedoch nur selten Links zu bestimmten Codes.  Nur Formeln und Algorithmen.  Wenn Sie Gl√ºck haben, werden Hyperparameter angezeigt. </li><li>  Der David Silver Kurs wurde 2015 am University College London (UCL) unterrichtet.  Es gibt einen sehr guten √úberblick √ºber die damals existierenden Methoden, so dass sie intuitiv beherrscht werden k√∂nnen. Hier hat die Theorie jedoch wieder Vorrang vor der Praxis. </li></ul><br><br>  Gleichzeitig war ich tief begeistert von dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel DeepMind</a> (‚ÄûEin neuronales Netzwerk kann lernen, Atari-Spiele in Pixeln zu spielen! WOW!‚Äú) Und ich hatte das Gef√ºhl, dass diese trockene Theorie einen gro√üen praktischen Wert verbirgt.  Also habe ich viel Zeit damit verbracht, die Theorie zu studieren, verschiedene Methoden zu implementieren und sie zu debuggen.  Wie Sie wahrscheinlich vermutet haben, war es nicht einfach: Sie k√∂nnen ein paar Wochen damit verbringen, die Methode zu verfeinern und dann feststellen, dass Ihre Implementierung falsch ist (oder, noch schlimmer, Sie haben die Formel falsch verstanden).  Ich halte ein solches Training nicht f√ºr Zeitverschwendung - im Gegenteil, ich denke, dass dies der richtigste Weg ist, etwas zu lernen.  Dies nimmt jedoch viel Zeit in Anspruch. <br><br>  Zwei Jahre sp√§ter, als ich anfing, an dem Text zu arbeiten, war mein Hauptziel Folgendes: einem Leser, der diese faszinierende Disziplin nur kennt - wie ich es einmal tat - gr√ºndliche praktische Informationen √ºber RL-Methoden zu geben. <br><br>  Nun ein wenig zum Buch.  Es konzentriert sich haupts√§chlich auf die Praxis, und ich habe versucht, das Volumen an Theorie und Formeln zu minimieren.  Es enth√§lt Schl√ºsselformeln, aber es werden keine Beweise gegeben.  Grunds√§tzlich versuche ich, ein intuitives Verst√§ndnis f√ºr das Geschehen zu vermitteln, ohne die maximale Genauigkeit der Pr√§sentation anzustreben. <br><br>  Gleichzeitig wird davon ausgegangen, dass der Leser √ºber Grundkenntnisse in Deep Learning und Statistik verf√ºgt.  Das Buch enth√§lt ein Kapitel mit einem √úberblick √ºber die PyTorch-Bibliothek (da alle Beispiele mit PyTorch angegeben werden). Dieses Kapitel kann jedoch nicht als autarke Informationsquelle f√ºr neuronale Netze angesehen werden.  Wenn Sie noch nie von den Verlust- und Aktivierungsfunktionen geh√∂rt haben, schauen Sie sich zun√§chst andere B√ºcher an. Heute gibt es viele.  (Hinweis: Zum Beispiel das Buch " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep Learning</a> "). <br><br>  In meinem Buch finden Sie viele Beispiele unterschiedlicher Komplexit√§t, beginnend mit den einfachsten (die <code>CrossEntropy</code> Methode in der <code>CartPole</code> Umgebung enth√§lt ~ 100 Zeilen in Python), die mit ziemlich gro√üen Projekten enden, z. B. dem Erlernen von AlphGo Zero oder einem RL-Agenten f√ºr den Handel an der B√∂rse.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Beispielcode ist vollst√§ndig auf GitHub hochgeladen.</a> In Python gibt es mehr als 14.000 Codezeilen. <br><br>  Das Buch besteht aus 18 Kapiteln, die die wichtigsten Aspekte des modernen Deep Learning mit Verst√§rkung behandeln: <br><br><ul><li>  <b>Kapitel 1</b> : enth√§lt einf√ºhrende Informationen zum verst√§rkten Lernparadigma und zeigt, wie es sich vom Lernen mit und ohne Lehrer unterscheidet.  Hier betrachten wir das zentrale mathematische Modell im Zusammenhang mit dem Lernen von Verst√§rkung: Markov-Entscheidungsprozesse: (MPPR).  Die Bekanntschaft mit MPNR wurde Schritt f√ºr Schritt gemacht: Ich spreche von Markov-Ketten, die in Markov-Verst√§rkungsprozesse (unter Hinzuf√ºgung einer Verst√§rkungskomponente) und schlie√ülich in vollwertige Markov-Entscheidungsprozesse umgewandelt werden, bei denen die Aktionen des Agenten auch im Gesamtbild ber√ºcksichtigt werden. </li><li>  <b>Kapitel 2</b> : Vortr√§ge √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenAI Gym</a> , eine verallgemeinerte API f√ºr RL, die f√ºr die Arbeit in einer Vielzahl von Umgebungen entwickelt wurde, einschlie√ülich Atari, zur L√∂sung klassischer Probleme wie CartPole, kontinuierliche Lernaufgaben usw. </li><li>  <b>Kapitel 3</b> : gibt einen ausdr√ºcklichen √úberblick √ºber die PyTorch-API.  Dieses Kapitel war nicht als vollst√§ndiger Leitfaden f√ºr DL gedacht, bildet jedoch die Grundlage f√ºr das Verst√§ndnis weiterer Kapitel.  Wenn Sie andere Tools zum L√∂sen von Deep-Learning-Problemen verwenden, sollte dies eine gute Einf√ºhrung in das sch√∂ne PyTorch-Modell sein, damit Sie die Beispiele aus den folgenden Kapiteln leichter verstehen k√∂nnen.  Am Ende dieses Kapitels werden wir ein einfaches GAN unterrichten, das Atari-Screenshots von verschiedenen Spielen generiert und unterscheidet. </li><li>  <b>Kapitel 4</b> : Untersucht eine der einfachsten und leistungsf√§higsten Methoden: CrossEntropy.  In diesem Kapitel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lernen</a> Sie das erste Netzwerk kennen, das Probleme in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CartPole-Umgebung</a> l√∂sen kann. </li><li>  <b>Kapitel 5</b> : Dieses Kapitel beginnt mit dem <b>zweiten Teil des Buches</b> √ºber den Iterationsalgorithmus f√ºr Werte.  In Kapitel 5 wird eine einfache Methode zum Trainieren von Tabellenkalkulationen unter Verwendung der Bellman-Gleichung zur L√∂sung von Problemen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in der FrozenLake-Umgebung erl√§utert</a> . </li><li>  <b>Kapitel 6</b> : Dieses Kapitel f√ºhrt Sie in die DQNs ein, die das Atari-Spiel spielen.  Die Architektur des Agenten ist genau die gleiche wie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ber√ºhmten Artikel DeepMind</a> . </li><li>  <b>Kapitel 7</b> : Einf√ºhrung mehrerer moderner DQN-Erweiterungen zur Verbesserung der Stabilit√§t und Leistung des zugrunde liegenden DQN.  In diesem Kapitel werden die Methoden aus dem Artikel ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Regenbogen: Kombinieren von Verbesserungen in Deep RL</a> ‚Äú beschrieben.  Alle diese Methoden werden in diesem Kapitel implementiert, und ich erkl√§re die ihnen zugrunde liegenden Ideen.  Diese Methoden sind: N-Schritt-DQN, Dual-DQN, verrauschte Netzwerke, Priorit√§tswiedergabepuffer, Duell-Netzwerke und Kategorienetzwerke.  Am Ende des Kapitels werden alle Methoden zu einem gemeinsamen Codebeispiel zusammengefasst, genau wie im ‚ÄûRegenbogenartikel‚Äú. </li><li>  <b>Kapitel 8</b> : beschreibt das erste mittelgro√üe Projekt und veranschaulicht die praktische Seite von RL bei der L√∂sung realer Probleme.  In diesem Kapitel wird ein Agent mithilfe des DQN geschult, um Vorg√§nge an der Vermittlungsstelle auszuf√ºhren. </li><li>  <b>Kapitel 9</b> : Dieses Kapitel beginnt mit dem <b>dritten Teil des</b> Buches √ºber Techniken mit politischem Gradienten.  Darin lernen wir solche Methoden, ihre St√§rken und Schw√§chen im Vergleich zu den Methoden der Aufz√§hlung durch bereits oben betrachtete Werte kennen.  Die erste Methode in dieser Familie hei√üt REINFORCE. </li><li>  <b>Kapitel 10</b> : Beschreibt den Umgang mit einem der schwerwiegendsten Probleme von RL: der Variabilit√§t des Richtliniengradienten.  Nachdem Sie mit grundlegenden PG-Levels experimentiert haben, werden Sie mit der Schauspieler-Kritiker-Methode vertraut. </li><li>  <b>Kapitel 11</b> : Erl√§utert, wie die Schauspieler-Kritiker-Methode auf moderner Hardware parallelisiert werden kann. </li><li>  <b>Kapitel 12</b> : Ein zweites praktisches Beispiel, das beschreibt, wie Probleme im Zusammenhang mit der Verarbeitung nat√ºrlicher Sprache gel√∂st werden k√∂nnen.  In diesem Kapitel lernen wir einen einfachen Chatbot, wie man RL-Methoden f√ºr das Material des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cornell-Kinodialogfelds verwendet</a> . </li><li>  <b>Kapitel 13</b> : Ein weiteres praktisches Beispiel zur Webautomatisierung: Als Plattform wird MiniWoB verwendet.  Leider hat OpenAI die Verwendung von MiniWoB abgelehnt, sodass es schwierig ist, Informationen dar√ºber zu finden ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> einige K√∂rner).  Die Idee von MiniWoB ist jedoch brillant. In diesem Kapitel zeige ich, wie der Agent konfiguriert und geschult wird, um einige der damit verbundenen Probleme zu l√∂sen. </li><li>  <b>Kapitel 14</b> : Der letzte, <b>vierte Teil des</b> Buches, der fortgeschritteneren Methoden und Techniken gewidmet ist, beginnt damit.  Kapitel 14 konzentriert sich auf kontinuierliche Verwaltungsaufgaben und beschreibt die A3C-, DDPG- und D4PG-Methoden zur L√∂sung von Problemen in einigen PyBullet-Umgebungen. </li><li>  <b>Kapitel 15</b> : Erl√§utert weitere Informationen zu kontinuierlichen Verwaltungsproblemen und f√ºhrt Sie anhand von TRPO, PPO und ACKTR in das Ph√§nomen der Vertrauensregion ein. </li><li>  <b>Kapitel 16</b> : Lehrmethoden mit Verst√§rkung ohne Farbverl√§ufe (nach dem Prinzip der ‚ÄûBlack Box‚Äú);  Sie sind als skalierbarere Alternativen f√ºr die DQN- und PG-Methoden positioniert.  Hier werden evolution√§re Strategien und genetische Algorithmen angewendet, um verschiedene Probleme der kontinuierlichen Kontrolle zu l√∂sen. </li><li>  <b>Kapitel 17</b> : Untersucht modellbasierte RL-Ans√§tze und beschreibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Versuch von DeepMind</a> , die L√ºcke zwischen modellbasierten und nicht modellbasierten Methoden zu schlie√üen.  In diesem Kapitel wird der I2A-Agent f√ºr Breakout implementiert. </li><li>  <b>Kapitel 18</b> : Das letzte Kapitel des Buches beschreibt die AlphaGo Zero-Methode, die beim Spielen von Connect4 verwendet wird.  Anschlie√üend wird der fertige Agent als Teil des Telegramm-Bots verwendet, um die Ergebnisse zu √ºberpr√ºfen. </li></ul><br><br><br>  Das ist alles!  Ich hoffe dir gef√§llt das Buch. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de474276/">https://habr.com/ru/post/de474276/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de474252/index.html">Realistische Animation von Charakteren in Spielen mit KI</a></li>
<li><a href="../de474254/index.html">Erstellen eines coolen Sticky-Effekts f√ºr einen Schieberegler bei React</a></li>
<li><a href="../de474256/index.html">Die Idee, Menschen im Wald zu finden</a></li>
<li><a href="../de474268/index.html">Erkennung digitaler Schaltungen. Asynchroner Z√§hlausl√∂ser</a></li>
<li><a href="../de474274/index.html">Wissensgraph. Pluralit√§t, Zeitlichkeit, Aktivit√§tsansatz</a></li>
<li><a href="../de474278/index.html">Python v3.x: So erh√∂hen Sie die Geschwindigkeit von Dekorateuren ohne Registrierung und SMS</a></li>
<li><a href="../de474280/index.html">M√∂chten Sie ein DBMS aus erster Hand? Ein offenes Treffen in Nischni Nowgorod - zu sein</a></li>
<li><a href="../de474282/index.html">Datacenter TCP erkl√§rt</a></li>
<li><a href="../de474284/index.html">Nicht nur Futures und Optionen: Welche anderen sekund√§ren Finanzinstrumente gibt es an B√∂rsen und nicht nur</a></li>
<li><a href="../de474286/index.html">Detaillierte Analyse der Simplex-Methode</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
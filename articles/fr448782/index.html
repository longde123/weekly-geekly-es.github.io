<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😷 📶 💒 Test Python avec pytest. Premiers pas avec pytest, Chapitre 1 👩🏿‍💼 📷 👨🏿‍🤝‍👨🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Retour Suivant 


 J'ai trouvé que le test Python avec pytest est un guide d'introduction extrêmement utile à l'environnement de test pytest. Cela me ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Test Python avec pytest. Premiers pas avec pytest, Chapitre 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448782/"><p><img src="https://habrastorage.org/webt/jl/jn/bb/jljnbbjr-ejh473xy_eccsmknpk.png">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Retour</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Suivant</a> <img src="https://habrastorage.org/webt/rw/dy/-g/rwdy-grsvbpcetjttrmecdkxtlk.png"></p><br><p> <em>J'ai trouvé que le test Python avec pytest est un guide d'introduction extrêmement utile à l'environnement de test pytest.</em>  <em>Cela me rapporte déjà des dividendes dans mon entreprise.</em> <em><br></em> <br>  Rasoir Chris <br>  Vice-président Produit, Uprising Technology </p><br><p><img src="https://habrastorage.org/webt/hd/--/9w/hd--9w134j0rxhmxftrflbbdopy.png"></p><a name="habracut"></a><br><p>  Les exemples de ce livre sont écrits en utilisant Python 3.6 et pytest 3.2.  pytest 3.2 prend en charge Python 2.6, 2.7 et Python 3.3+. </p><br><blockquote>  Le code source du projet Tâches, ainsi que pour tous les tests présentés dans ce livre, est disponible sur le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" title="https://pragprog.com/titles/bopytest/source_code">lien</a> sur la page Web du livre à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" title="https://pragprog.com/titles/bopytest">pragprog.com</a> .  Vous n'avez pas besoin de télécharger le code source pour comprendre le code de test;  le code de test est présenté sous une forme pratique dans les exemples.  Mais pour suivre les tâches du projet ou adapter des exemples de test pour tester votre propre projet (vos mains ne sont pas liées!), Vous devez vous rendre sur la page Web du livre et télécharger le travail.  Là, sur la page Web du livre, il y a un lien pour les messages d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" title="https://pragprog.com/titles/bopytest/errata">erreur</a> et un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" title="https://forums.pragprog.com/forums/438">forum de discussion</a> . </blockquote><p>  Sous le spoiler se trouve une liste d'articles de cette série. </p><br><div class="spoiler">  <b class="spoiler_title">Table des matières</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Présentation</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Chapitre 1: Premiers pas avec pytest</strong></a> (cet article) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Chapitre 2: Écriture des fonctions de test</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Chapitre 3: Appareils Pytest</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Chapitre 4: Luminaires intégrés</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Chapitre 5: Plugins</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Chapitre 6: Configuration</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Chapitre 7: Utilisation de pytest avec d'autres outils</strong></a> </li></ul></div></div><br><h2 id="poehali">  On y va </h2><br><p>  Voici le test: </p><br><blockquote>  <strong>ch1 / test_one.py</strong> </blockquote><br><pre><code class="plaintext hljs">def test_passing(): assert (1, 2, 3) == (1, 2, 3)</code> </pre> <br><p>  Voici à quoi cela ressemble au démarrage: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest test_one.py ===================== test session starts ====================== collected 1 items test_one.py . =================== 1 passed in 0.01 seconds ===================</code> </pre> <br><p><img src="https://habrastorage.org/webt/v0/ak/lu/v0aklucdm0i8nrqtk1v1dwb2oeg.png"></p><br><p>  Le point après <em>test_one.py</em> signifie qu'un test a été exécuté et qu'il a réussi.  Si vous avez besoin de plus d'informations, vous pouvez utiliser <code>-v</code> ou <code>--verbose</code> : </p><br><pre> <code class="plaintext hljs">$ pytest -v test_one.py ===================== test session starts ====================== collected 1 items test_one.py::test_passing PASSED =================== 1 passed in 0.01 seconds ===================</code> </pre> <br><p><img src="https://habrastorage.org/webt/ss/rb/7i/ssrb7i7io-h6ikadzulg5yncvyw.png"></p><br><p>  Si vous avez un terminal couleur, PASSÉ et la ligne du bas sont vertes.  Super! </p><br><p>  Il s'agit d'un test qui a échoué: </p><br><blockquote>  <strong>ch1 / test_two.py</strong> </blockquote><br><pre> <code class="plaintext hljs">def test_failing(): assert (1, 2, 3) == (3, 2, 1)</code> </pre> <br><p>  La façon dont pytest montre les échecs de test est l'une des nombreuses raisons pour lesquelles les développeurs aiment pytest.  Voyons ce qui en résulte: </p><br><pre> <code class="plaintext hljs">$ pytest test_two.py ===================== test session starts ====================== collected 1 items test_two.py F =========================== FAILURES =========================== _________________________ test_failing _________________________ def test_failing(): &gt; assert (1, 2, 3) == (3, 2, 1) E assert (1, 2, 3) == (3, 2, 1) E At index 0 diff: 1 != 3 E Use -v to get the full diff test_two.py:2: AssertionError =================== 1 failed in 0.04 seconds ===================</code> </pre> <br><p><img src="https://habrastorage.org/webt/dr/sh/wu/drshwua2ie5btbcena-4xlewiz4.png"></p><br><p>  Super!  Le test test <em>test_failing</em> obtient sa section pour nous montrer pourquoi il a échoué. </p><br><p>  Et pytest signale avec précision que le premier crash: l'index 0 est un décalage. </p><br><p>  Une grande partie de ce message est rouge, ce qui le fait vraiment ressortir (si vous avez un terminal couleur). </p><br><p>  C'est déjà beaucoup d'informations, mais il y a une ligne avec un indice qui dit Utilisez <code>-v</code> pour obtenir encore plus de descriptions des différences. </p><br><p>  <code>-v</code> celui <code>-v</code> : </p><br><pre> <code class="plaintext hljs">$ pytest -v test_two.py ===================== test session starts ====================== collected 1 items test_two.py::test_failing FAILED =========================== FAILURES =========================== _________________________ test_failing _________________________ def test_failing(): &gt; assert (1, 2, 3) == (3, 2, 1) E assert (1, 2, 3) == (3, 2, 1) E At index 0 diff: 1 != 3 E Full diff: E - (1, 2, 3) E ? ^ ^ E + (3, 2, 1) E ? ^ ^ test_two.py:2: AssertionError =================== 1 failed in 0.04 seconds ===================</code> </pre> <br><p><img src="https://habrastorage.org/webt/u9/8l/dn/u98ldncvvmy1ha0ygy6krwekhvm.png"></p><br><p>  Ouah! <br>  pytest ajoute le caractère caret (^) pour nous montrer exactement quelle est la différence. <br>  Si vous êtes déjà impressionné par la facilité d'écriture, de lecture et d'exécution des tests avec pytest et par la facilité de lecture de la sortie pour voir où la panne s'est produite, eh bien ... vous n'avez encore rien vu.  D'où cela vient, il y a beaucoup plus de miracles.  Restez et laissez-moi vous montrer pourquoi je pense que pytest est absolument la meilleure plate-forme de test. </p><br><p>  Dans la suite de ce chapitre, vous allez installer pytest, regarder les différentes façons de l'exécuter et suivre certaines des options de ligne de commande les plus utilisées.  Dans les prochains chapitres, vous apprendrez comment écrire des fonctions de test qui maximisent la puissance de pytest, comment obtenir le code d'installation dans les sections de configuration et de démontage appelées fixtures, et comment utiliser des fixtures et des plugins pour surcharger vraiment les tests de logiciels. </p><br><p>  Mais je dois d'abord m'excuser.  Désolé de tester <code>assert (1, 2, 3) == (3, 2, 1)</code> , c'est tellement ennuyeux.  J'entends des ronflements?!  Personne n'écrirait un tel test dans la vraie vie.  Les tests logiciels consistent en du code qui vérifie d'autres logiciels qui, hélas, ne fonctionneront pas toujours de manière positive.  Et <code>(1, 2, 3) == (1, 2, 3)</code> fonctionnera toujours.  C'est pourquoi nous n'utiliserons pas de tests trop stupides comme celui-ci dans le reste du livre.  Nous envisagerons des tests pour un vrai projet logiciel.  Nous utiliserons un exemple de projet Tâches qui nécessite un code de test.  J'espère que c'est assez simple pour être facilement compris, mais pas assez simple pour être ennuyeux. </p><br><p>  Une autre application utile des tests de logiciels consiste à tester vos hypothèses sur le fonctionnement du logiciel testé, ce qui peut inclure le test de votre compréhension des modules et packages tiers, et même la création de structures de données Python. </p><br><p>  Le projet Tâches utilise la structure Tâche, basée sur la méthode d'usine namedtuple, qui fait partie de la bibliothèque standard.  La structure de tâches est utilisée comme structure de données pour transférer des informations entre l'interface utilisateur et l'API. </p><br><p>  Dans le reste de ce chapitre, j'utiliserai Task pour montrer comment démarrer pytest et utiliser certaines options de ligne de commande couramment utilisées. </p><br><p>  Voici la tâche: </p><br><pre> <code class="plaintext hljs">from collections import namedtuple Task = namedtuple('Task', ['summary', 'owner', 'done', 'id'])</code> </pre> <br><p>  Avant de passer aux exemples, prenons un peu de recul et parlons de la façon d'obtenir Pytest et de l'installer. </p><br><p>  La fonction factory <em>namedtuple ()</em> existe depuis Python 2.6, mais je trouve toujours que de nombreux développeurs Python ne savent pas à quel point c'est cool.  Au moins, l'utilisation de la tâche pour les cas de test sera plus intéressante que <code>(1, 2, 3) == (1, 2, 3)</code> ou <code>(1, 2)==3</code> . </p><br><p>  Avant de passer aux exemples, prenons un peu de recul et parlons où trouver pytest et comment l'installer. </p><br><h2 id="dobyvaem-pytest">  Pytest minier </h2><br><p>  Siège social de Pytest <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://docs.pytest.org</a> .  Ceci est la documentation officielle.  Mais il se propage via PyPI (l'index du package Python) à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://pypi.python.org/pypi/pytest</a> . </p><br><p>  Comme les autres packages Python distribués via PyPI, utilisez <strong>pip</strong> pour installer pytest dans l'environnement virtuel utilisé pour les tests: </p><br><pre> <code class="plaintext hljs">$ pip3 install -U virtualenv $ python3 -m virtualenv venv $ source venv/bin/activate $ pip install pytest</code> </pre> <br><p>  Si vous n'êtes pas familier avec virtualenv ou pip, je vais vous présenter.  Voir Annexe 1, «Environnements virtuels», page 155 et Annexe 2, page 159. </p><br><p>  <strong>Qu'en est-il de Windows, Python 2 et Venv?</strong> </p><br><p>  L'exemple virtualenv et pip devrait fonctionner sur de nombreux systèmes POSIX, tels que Linux et macOS, ainsi que sur de nombreuses versions de Python, y compris Python 2.7.9 et versions ultérieures. </p><br><p>  La <em>source venv / bin / activate</em> dans la ligne ne fonctionnera pas pour Windows, utilisez <em>plutôt venv \ Scripts \ activate.bat</em> . <br>  Faites ceci: </p><br><pre> <code class="plaintext hljs">C:\&gt; pip3 install -U virtualenv C:\&gt; python3 -m virtualenv venv C:\&gt; venv\Scripts\activate.bat (venv) C:\&gt; pip install pytest</code> </pre> <br><p>  Pour Python 3.6 et supérieur, vous pouvez vous débrouiller avec venv au lieu de virtualenv, et vous n'avez pas à vous soucier de l'installer en premier.  Il est inclus dans Python 3.6 et versions ultérieures.  Cependant, j'ai entendu dire que certaines plates-formes se comportent toujours mieux avec virtualenv. </p><br><h2 id="zapuskaem-pytest">  Exécuter pytest </h2><br><pre> <code class="plaintext hljs">$ pytest --help usage: pytest [options] [file_or_dir] [file_or_dir] [...] ...</code> </pre> <br><p>  En l'absence d'arguments, pytest examinera votre répertoire actuel et tous les sous-répertoires des fichiers de test et exécutera le code de test qu'il trouve.  Si vous donnez à pytest un nom de fichier, un nom de répertoire ou une liste d'entre eux, ils y seront trouvés à la place du répertoire actuel.  Chaque répertoire spécifié sur la ligne de commande est récursivement examiné pour trouver le code de test. </p><br><p>  Par exemple, créons un sous-répertoire appelé tâches et commençons par ce fichier de test: </p><br><blockquote>  <strong>ch1 / tasks / test_three.py</strong> </blockquote><br><pre> <code class="plaintext hljs">"""   Task.""" from collections import namedtuple Task = namedtuple('Task', ['summary', 'owner', 'done', 'id']) Task.__new__.__defaults__ = (None, None, False, None) def test_defaults(): """  ,      .""" t1 = Task() t2 = Task(None, None, False, None) assert t1 == t2 def test_member_access(): """  .field () namedtuple.""" t = Task('buy milk', 'brian') assert t.summary == 'buy milk' assert t.owner == 'brian' assert (t.done, t.id) == (False, None)</code> </pre> <br><p>  Le test test_member_access () consiste à montrer comment accéder aux membres par leur nom et non par leur index, ce qui est l'une des principales raisons d'utiliser des nommés. </p><br><p>  Mettons quelques tests supplémentaires dans un deuxième fichier pour montrer les fonctionnalités _asdict () et _replace () </p><br><p>  Vous pouvez utiliser <em><code>__new __.__ defaults__</code></em> pour créer des objets Task sans spécifier tous les champs.  Le test <em>test_defaults ()</em> est destiné à démontrer et à tester le fonctionnement des valeurs par défaut. </p><br><p>  Le test <em><code>test_member_access()</code></em> doit montrer comment accéder aux membres nommés nd et non par index, ce qui est l'une des principales raisons d'utiliser des nommés. <br>  Ajoutons quelques tests supplémentaires au deuxième fichier pour illustrer les fonctions <em><code>_asdict()</code></em> et <em><code>_replace()</code></em> </p><br><blockquote>  <strong>ch1 / tasks / test_four.py</strong> </blockquote><br><pre> <code class="plaintext hljs">"""   Task.""" from collections import namedtuple Task = namedtuple('Task', ['summary', 'owner', 'done', 'id']) Task.__new__.__defaults__ = (None, None, False, None) def test_asdict(): """_asdict()   .""" t_task = Task('do something', 'okken', True, 21) t_dict = t_task._asdict() expected = {'summary': 'do something', 'owner': 'okken', 'done': True, 'id': 21} assert t_dict == expected def test_replace(): """    fields.""" t_before = Task('finish book', 'brian', False) t_after = t_before._replace(id=10, done=True) t_expected = Task('finish book', 'brian', True, 10) assert t_after == t_expected</code> </pre> <br><p>  Pour exécuter pytest, vous avez la possibilité de spécifier des fichiers et des répertoires.  Si vous ne spécifiez aucun fichier ou répertoire, pytest recherchera les tests dans le répertoire de travail et les sous-répertoires actuels.  Il recherche les fichiers commençant par test_ ou se terminant par _test.  Si vous exécutez pytest à partir du répertoire ch1, sans commandes, vous exécuterez des tests pour quatre fichiers: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest ===================== test session starts ====================== collected 6 items test_one.py . test_two.py F tasks/test_four.py .. tasks/test_three.py .. =========================== FAILURES =========================== _________________________ test_failing _________________________ def test_failing(): &gt; assert (1, 2, 3) == (3, 2, 1) E assert (1, 2, 3) == (3, 2, 1) E At index 0 diff: 1 != 3 E Use -v to get the full diff test_two.py:2: AssertionError ============== 1 failed, 5 passed in 0.08 seconds ==============</code> </pre> <br><p><img src="https://habrastorage.org/webt/ut/2o/kw/ut2okwbdqprgbriqvfswsjd-7ti.png"></p><br><p>  Pour exécuter uniquement nos nouveaux tests de tâches, vous pouvez fournir à pytest tous les noms de fichiers que vous souhaitez exécuter, ou un répertoire, ou appeler pytest à partir du répertoire où se trouvent nos tests: </p><br><pre> <code class="plaintext hljs">$ pytest tasks/test_three.py tasks/test_four.py ===================== test session starts ====================== collected 4 items tasks/test_three.py .. tasks/test_four.py .. =================== 4 passed in 0.02 seconds =================== $ pytest tasks ===================== test session starts ====================== collected 4 items tasks/test_four.py .. tasks/test_three.py .. =================== 4 passed in 0.03 seconds =================== $ cd /path/to/code/ch1/tasks $ pytest ===================== test session starts ====================== collected 4 items test_four.py .. test_three.py .. =================== 4 passed in 0.02 seconds ===================</code> </pre> <br><p><img src="https://habrastorage.org/webt/or/77/t4/or77t4go_qqok-v8qnenx5rxcjy.png"></p><br><p>  La partie d'exécution de pytest, où pytest réussit et trouve les tests à exécuter, est appelée découverte de test.  pytest a pu trouver tous les tests que nous voulions exécuter car nous les avons nommés selon les conventions de dénomination de pytest. </p><br><p>  Voici un bref aperçu des conventions de dénomination afin que votre code de test puisse être détecté à l'aide de pytest: </p><br><ul><li>  Les fichiers de test doivent être nommés <code>test_&lt;something&gt;.py</code> ou <code>&lt;something&gt;_test.py</code> . </li><li>  Les méthodes et fonctions de test doivent être appelées <code>test_&lt;something&gt;</code> . </li><li>  Les classes de test doivent être appelées <code>Test&lt;Something&gt;</code> . </li></ul><br><p>  Puisque nos fichiers et fonctions de test commencent par <code>test_</code> , tout va bien pour nous.  Il existe des moyens de modifier ces règles de découverte si vous disposez de plusieurs tests avec des noms différents. <br>  Je couvrirai cela au chapitre 6, «Configuration», page 113. </p><br><p>  Examinons de plus près le résultat de l'exécution d'un seul fichier: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1/tasks $ pytest test_three.py ================= test session starts ================== platform darwin -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 rootdir: /path/to/code/ch1/tasks, inifile: collected 2 items test_three.py .. =============== 2 passed in 0.01 seconds ===============</code> </pre> <br><p>  Le résultat nous en dit long. </p><br><blockquote>  ===== la session de test démarre ==== </blockquote><p>  . </p><br><p>  pytest fournit un séparateur élégant pour démarrer une session de test.  Une session est un appel pytest unique, comprenant tous les tests exécutés dans plusieurs répertoires.  Cette définition de session devient importante lorsque je parle de la zone de session par rapport aux appareils Pytest dans la définition de la région de l'appareil, à la page 56. </p><br><p>  Plateforme Darwin - sur mon Mac.  Sur un ordinateur Windows, la plateforme est différente.  Les versions suivantes sont des versions de Python et pytest, ainsi que des dépendances sur les packages pytest.  Py et pluggy sont des packages développés par l'équipe pytest pour aider à la mise en œuvre de pytest. </p><br><blockquote>  <strong>rootdir: / chemin / vers / code / ch1 / tâches, inifile:</strong> </blockquote><p>  <code>rootdir</code> est le répertoire partagé le plus haut pour tous les répertoires dans lesquels le code de test est recherché.  Le <code>inifile</code> (vide ici) répertorie les fichiers de configuration utilisés.  Les fichiers de configuration peuvent être <code>pytest.ini</code> , <code>tox.ini</code> ou <code>setup.cfg</code> .  Pour plus d'informations sur les fichiers de configuration, reportez-vous au chapitre 6, «Configuration», page 113. </p><br><blockquote>  <strong>collecté 2 articles</strong> </blockquote><p>  Ce sont deux fonctions de test dans un fichier. </p><br><blockquote>  <strong>test_three.py ..</strong> </blockquote><p>  <code>test_three.py</code> montre le fichier de test.  Il y a une ligne pour chaque fichier de test.  Deux points signifient que les tests sont réussis - un point pour chaque fonction ou méthode de test.  Les points sont destinés uniquement à la réussite des tests.  Les échecs, les erreurs, les sauts, les xfails et les xpasses sont notés respectivement F, E, s, x et X.  Si vous voulez voir plus de points pour réussir les tests, utilisez l'option <code>-v</code> ou <code>--verbose</code> . </p><br><blockquote>  == 2 passés en 0,01 secondes == </blockquote><p>  Cette ligne fait référence au nombre de tests réussis et au temps passé sur toute la session de test.  S'il y a des tests réussis, le numéro de chaque catégorie sera également affiché ici. </p><br><p>  Un résultat de test est le principal moyen par lequel un utilisateur effectuant un test ou affichant les résultats peut comprendre ce qui s'est passé pendant le test.  Dans pytest, les fonctions de test peuvent avoir plusieurs résultats différents, pas seulement réussir ou échouer.  Voici les résultats possibles de la fonction de test: </p><br><ul><li>  RÉUSSI (.): Le test s'est terminé avec succès. </li><li>  FAILED (F): Le test a échoué (ou XPASS + strict). </li><li>  SKIPPED (s): Le test a été ignoré.  Vous pouvez forcer pytest à ignorer le test à l'aide des <code>@pytest.mark.skip()</code> ou <code>pytest.mark.skipif()</code> , décrits dans la section sur les tests à sauter, à la page 34. </li><li>  xfail (x): Le test n'aurait pas dû réussir, il a été lancé et a échoué.  Vous pouvez forcer pytest à indiquer que le test doit échouer à l'aide du <code>@pytest.mark.xfail()</code> , décrit dans les marquages ​​des tests comme prévoyant un échec, à la page 37. </li><li>  XPASS (X): Le test n'aurait pas dû passer, il a été lancé et réussi! .. </li><li>  ERREUR (E): Une exception s'est produite en dehors de la fonction de test, soit dans le luminaire, abordé au chapitre 3, Appareils pytest, à la page 49, ou dans la fonction de crochet, discuté au chapitre 5, Plugins, à la page 95. </li></ul><br><h2 id="vypolnenie-tolko-odnogo-testa">  Exécution d'un seul test </h2><br><p>  Peut-être que la première chose à faire après avoir commencé à écrire des tests est d'en exécuter un seul.  Spécifiez le fichier directement et ajoutez le nom <code>::test_name</code> : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest -v tasks/test_four.py::test_asdict =================== test session starts =================== collected 3 items tasks/test_four.py::test_asdict PASSED ================ 1 passed in 0.01 seconds =================</code> </pre> <br><p>  Voyons maintenant quelques options. </p><br><h2 id="ispolzovanie-opciy">  Utilisation des options </h2><br><p>  Nous avons utilisé l'option verbose, <code>-v</code> ou <code>--verbose</code> plusieurs fois, mais il existe de nombreuses autres options qui méritent d'être connues.  Nous n'allons pas tous les utiliser dans ce livre, seulement quelques-uns.  Vous pouvez afficher la liste complète à l'aide de l'option pytest <code>--help</code> . </p><br><p>  Vous trouverez ci-dessous quelques options très utiles lorsque vous travaillez avec pytest.  Ce n'est pas une liste complète, mais ces options sont suffisantes pour commencer. </p><br><pre> <code class="plaintext hljs">$ pytest --help usage: pytest [options] [file_or_dir] [file_or_dir] [...] ... subset of the list ... positional arguments: file_or_dir general: -k EXPRESSION only run tests which match the given substring expression. An expression is a python evaluatable expression where all names are substring-matched against test names and their parent classes. Example: -k 'test_method or test_other' matches all test functions and classes whose name contains 'test_method' or 'test_other', while -k 'not test_method' matches those that don't contain 'test_method' in their names. Additionally keywords are matched to classes and functions containing extra names in their 'extra_keyword_matches' set, as well as functions which have names assigned directly to them. -m MARKEXPR only run tests matching given mark expression. example: -m 'mark1 and not mark2'. --markers show markers (builtin, plugin and per-project ones). -x, --exitfirst exit instantly on first error or failed test. --maxfail=num exit after first num failures or errors. ... --capture=method per-test capturing method: one of fd|sys|no. -s shortcut for --capture=no. ... --lf, --last-failed rerun only the tests that failed at the last run (or all if none failed) --ff, --failed-first run all tests but run the last failures first. This may re-order tests and thus lead to repeated fixture setup/teardown ... reporting: -v, --verbose increase verbosity. -q, --quiet decrease verbosity. --verbosity=VERBOSE set verbosity ... -l, --showlocals show locals in tracebacks (disabled by default). --tb=style traceback print mode (auto/long/short/line/native/no). ... --durations=N show N slowest setup/test durations (N=0 for all). ... collection: --collect-only only collect tests, don't execute them. ... test session debugging and configuration: --basetemp=dir base temporary directory for this test run.(warning: this directory is removed if it exists) --version display pytest lib version and import information. -h, --help show help message and configuration info</code> </pre><br><h3 id="--collect-only">  --collect seulement </h3><br><p>  L' <code>--collect-only</code> indique quels tests seront effectués avec les paramètres et la configuration donnés.  Il est pratique d'afficher ce paramètre en premier, afin que la sortie puisse être utilisée comme référence pour d'autres exemples.  Si vous démarrez dans le répertoire ch1, vous devriez voir toutes les fonctions de test que vous avez examinées jusqu'à présent dans ce chapitre: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest --collect-only =================== test session starts =================== collected 6 items &lt;Module 'test_one.py'&gt; &lt;Function 'test_passing'&gt; &lt;Module 'test_two.py'&gt; &lt;Function 'test_failing'&gt; &lt;Module 'tasks/test_four.py'&gt; &lt;Function 'test_asdict'&gt; &lt;Function 'test_replace'&gt; &lt;Module 'tasks/test_three.py'&gt; &lt;Function 'test_defaults'&gt; &lt;Function 'test_member_access'&gt; ============== no tests ran in 0.03 seconds ===============</code> </pre> <br><p>  L' <code>--collect-only</code> est utile pour vérifier que les autres options qui sélectionnent les tests avant d'exécuter les tests sont sélectionnées correctement.  Nous l'utiliserons à nouveau avec <code>-k</code> pour montrer comment cela fonctionne. </p><br><h3 id="-k-expression">  -k EXPRESSION </h3><br><p>  L' <code>-k</code> vous permet d'utiliser une expression pour définir des fonctions de test. </p><br><p>  Une option très puissante!  Il peut être utilisé comme raccourci pour exécuter un test distinct, si le nom est unique, ou exécuter un ensemble de tests qui ont un préfixe ou un suffixe commun dans leurs noms.  Supposons que vous souhaitiez exécuter les tests <code>test_asdict()</code> et <code>test_defaults()</code> .  Vous pouvez vérifier le filtre avec: <code>--collect-only</code> : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest -k "asdict or defaults" --collect-only =================== test session starts =================== collected 6 items &lt;Module 'tasks/test_four.py'&gt; &lt;Function 'test_asdict'&gt; &lt;Module 'tasks/test_three.py'&gt; &lt;Function 'test_defaults'&gt; =================== 4 tests deselected ==================== ============== 4 deselected in 0.03 seconds ===============</code> </pre> <br><p>  Ouais!  C'est semblable à ce dont nous avons besoin.  Vous pouvez maintenant les exécuter en supprimant <code>--collect-only</code> : </p><br><pre> <code class="plaintext hljs">$ pytest -k "asdict or defaults" =================== test session starts =================== collected 6 items tasks/test_four.py . tasks/test_three.py . =================== 4 tests deselected ==================== ========= 2 passed, 4 deselected in 0.03 seconds ==========</code> </pre> <br><p>  Oups!  Juste des points.  Alors, ils sont passés.  Mais étaient-ce les bons tests?  Une façon de le savoir est d'utiliser <code>-v</code> ou <code>--verbose</code> : </p><br><pre> <code class="plaintext hljs">$ pytest -v -k "asdict or defaults" =================== test session starts =================== collected 6 items tasks/test_four.py::test_asdict PASSED tasks/test_three.py::test_defaults PASSED =================== 4 tests deselected ==================== ========= 2 passed, 4 deselected in 0.02 seconds ==========</code> </pre> <br><p>  Ouais!  Ce sont les bons tests. </p><br><h3 id="-m-markexpr">  -m MARKEXPR </h3><br><p>  Les marqueurs sont l'un des meilleurs moyens de baliser un sous-ensemble de fonctionnalités de test à exécuter ensemble.  Par exemple, une façon d'exécuter <code>test_replace()</code> et <code>test_member_access()</code> , même s'ils sont dans des fichiers séparés, est de les marquer.  Tout nom de marqueur peut être utilisé.  <code>run_these_please</code> que vous souhaitez utiliser <code>run_these_please</code> .  Notez les tests utilisant le décorateur <code>@pytest.mark.run_these_please</code> , comme ceci: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pytest ... @pytest.mark.run_these_please <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test_member_access</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre> <br><p>  Maintenant la même chose pour <code>test_replace()</code> .  Ensuite, vous pouvez exécuter tous les tests avec le même marqueur avec <code>pytest -m run_these_please</code> : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1/tasks $ pytest -v -m run_these_please ================== test session starts =================== collected 4 items test_four.py::test_replace PASSED test_three.py::test_member_access PASSED =================== 2 tests deselected =================== ========= 2 passed, 2 deselected in 0.02 seconds =========</code> </pre> <br><p>  L'expression du marqueur ne doit pas nécessairement être un marqueur unique.  Vous pouvez utiliser des options telles que <code>-m "mark1 and mark2"</code> pour les tests avec les deux marqueurs, <code>-m "mark1 and not mark2"</code> pour les tests qui ont le label 1 mais pas le label 2, <code>-m "mark1 or mark2"</code> pour les tests avec l'un des, etc., j'examinerai plus en détail les marqueurs dans les méthodes de vérification du marquage, à la page 31. </p><br><h3 id="-x---exitfirst">  -x, --exitfirst </h3><br><p>  Le comportement normal de <em>pytest</em> est d'exécuter tous les tests qu'il trouve.  Si la fonction de test détecte un échec d' <em>assertion</em> ou d' <em>exception</em> , ce test s'arrête et le test échoue.  Et puis <em>pytest</em> exécute le prochain test.  Pour la plupart, c'est ce dont vous avez besoin.  Cependant, en particulier lors du débogage d'un problème, il interfère immédiatement avec la session de test entière lorsque le test n'est pas correct.  C'est ce que fait l'option <code>-x</code> .  Essayons ceci sur les six tests que nous avons en ce moment: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest -x ====================== test session starts ==================== collected 6 items test_one.py . test_two.py F ============================ FAILURES ========================= __________________________ test_failing _______________________ def test_failing(): &gt; assert (1, 2, 3) == (3, 2, 1) E assert (1, 2, 3) == (3, 2, 1) E At index 0 diff: 1 != 3 E Use -v to get the full diff test_two.py:2: AssertionError =============== 1 failed, 1 passed in 0.38 seconds ============</code> </pre><br><p>  En haut de la sortie, vous voyez que les six tests (ou «éléments») ont été collectés, et sur la ligne du bas, vous voyez qu'un test a échoué et un réussi, et <em>pytest a</em> affiché la ligne «Interrompu» pour nous faire savoir qu'il est arrêté.  Sans <code>-x</code> les six tests s'exécuteraient.  Répétons encore sans <code>-x</code> .  Nous utilisons également <code>--tb=no</code> pour désactiver le traçage de pile, car vous l'avez déjà vu et vous n'avez pas besoin de le revoir: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest --tb=no =================== test session starts =================== collected 6 items test_one.py . test_two.py F tasks/test_four.py .. tasks/test_three.py .. =========== 1 failed, 5 passed in 0.09 seconds ============</code> </pre> <br><p>   ,   <code>-x</code> , pytest    <em>test_two.py</em>    . </p><br><h3 id="--maxfailnum"> --maxfail=num </h3><br><p>  <code>-x</code>       .   ,      ,    ,   <code>--maxfail</code> ,  ,    .            ,      .     ,    <code>--maxfail = 2</code> ,    ,  <code>--maxfail = 1</code>    ,  <code>-x</code> : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest --maxfail=2 --tb=no =================== test session starts =================== collected 6 items test_one.py . test_two.py F tasks/test_four.py .. tasks/test_three.py .. =========== 1 failed, 5 passed in 0.08 seconds ============ $ pytest --maxfail=1 --tb=no =================== test session starts =================== collected 6 items test_one.py . test_two.py F !!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!! =========== 1 failed, 1 passed in 0.19 seconds ============</code> </pre> <br><p> E    <code>--tb=no</code> ,   . </p><br><h3 id="-s-and---capturemethod"> -s and --capture=method </h3><br><p>  <code>-s</code>    —    ,     <em>stdout</em> ,           .     <code>--capture=no</code> .   ,        .      ,      ,     ,      .  <code>-s</code>  <code>--capture=no</code>    .         <code>print()</code> ,       . </p><br><p>  ,           , <code>-l/--showlocals</code> ,      ,    . </p><br><p>     <code>--capture=fd</code>  <code>--capture=sys</code> . —  <code>--capture=sys</code>  <code>sys.stdout/stderr</code>  mem-.  <code>--capture=fd</code>    1  2   . </p><br><p>    <code>sys</code>  <code>fd</code>  . ,  ,        .    <code>-s</code> .    ,   <code>-s</code> ,      . </p><br><p>          ;    .   ,       ,      . </p><br><h3 id="-lf---last-failed"> -lf, --last-failed </h3><br><p>              .   <code>--lf</code>     : </p><br><p>  ,     <code>--tb</code> ,    ,         . </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest --lf =================== test session starts =================== run-last-failure: rerun last 1 failures collected 6 items test_two.py F ======================== FAILURES ========================= ______________________ test_failing _______________________ def test_failing(): &gt; assert (1, 2, 3) == (3, 2, 1) E assert (1, 2, 3) == (3, 2, 1) E At index 0 diff: 1 != 3 E Use -v to get the full diff test_two.py:2: AssertionError =================== 5 tests deselected ==================== ========= 1 failed, 5 deselected in 0.08 seconds ==========</code> </pre> <br><h3 id="ff---failed-first"> –ff, --failed-first </h3><br><p>  <code>--ff/--failed-first</code>     ,   <code>--last-failed</code> ,     ,    : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest --ff --tb=no =================== test session starts =================== run-last-failure: rerun last 1 failures first collected 6 items test_two.py F test_one.py . tasks/test_four.py .. tasks/test_three.py .. =========== 1 failed, 5 passed in 0.09 seconds ============</code> </pre> <br><p>  <code>test_failing()</code>  <code>test\_two.py</code>   <code>test\_one.py</code> . ,  <code>test_failing()</code>     , <code>--ff</code>       </p><br><h3 id="-v---verbose"> -v, --verbose </h3><br><p>  <code>-v/--verbose</code>      .     ,       ,        . </p><br><p>      ,           <code>--ff</code>  <code>--tb=no</code> : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest -v --ff --tb=no =================== test session starts =================== run-last-failure: rerun last 1 failures first collected 6 items test_two.py::test_failing FAILED test_one.py::test_passing PASSED tasks/test_four.py::test_asdict PASSED tasks/test_four.py::test_replace PASSED tasks/test_three.py::test_defaults PASSED tasks/test_three.py::test_member_access PASSED =========== 1 failed, 5 passed in 0.07 seconds ============</code> </pre> <br><p><img src="https://habrastorage.org/webt/bw/7f/_4/bw7f_4irv2astplpl5tobqp_xqs.png"></p><br><p>           FAILED   PASSED. </p><br><h3 id="-q---quiet"> -q, --quiet </h3><br><p>  <code>-q/--quiet</code>  <code>-v/--verbose</code> ;      .        <code>--tb=line</code> ,          . </p><br><p>  - <code>q</code> : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest -q .F.... ======================== FAILURES ========================= ______________________ test_failing _______________________ def test_failing(): &gt; assert (1, 2, 3) == (3, 2, 1) E assert (1, 2, 3) == (3, 2, 1) E At index 0 diff: 1 != 3 E Full diff: E - (1, 2, 3) E ? ^ ^ E + (3, 2, 1) E ? ^ ^ test_two.py:2: AssertionError 1 failed, 5 passed in 0.08 seconds</code> </pre> <br><p>  <code>-q</code>    ,    .      <code>-q</code>     (  <code>--tb=no</code> ),    ,        . </p><br><h3 id="-l---showlocals"> -l, --showlocals </h3><br><p>    <code>-l/--showlocals</code>         <code>tracebacks</code>   . </p><br><p>            .     <code>test_replace()</code>   </p><br><pre> <code class="plaintext hljs">t_expected = Task('finish book', 'brian', True, 10)</code> </pre> <br><p>  sur </p><br><pre> <code class="plaintext hljs">t_expected = Task('finish book', 'brian', True, 11)</code> </pre> <br><p> 10  11   .       .         <code>--l/--showlocals</code> : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest -l tasks =================== test session starts =================== collected 4 items tasks/test_four.py .F tasks/test_three.py .. ======================== FAILURES ========================= ______________________ test_replace _______________________ @pytest.mark.run_these_please def test_replace(): """replace() should change passed in fields.""" t_before = Task('finish book', 'brian', False) t_after = t_before._replace(id=10, done=True) t_expected = Task('finish book', 'brian', True, 11) &gt; assert t_after == t_expected E AssertionError: assert Task(summary=...e=True, id=10) == Task(summary='...e=True, id=11) E At index 3 diff: 10 != 11 E Use -v to get the full diff t_after = Task(summary='finish book', owner='brian', done=True, id=10) t_before = Task(summary='finish book', owner='brian', done=False, id=None) t_expected = Task(summary='finish book', owner='brian', done=True, id=11) tasks\test_four.py:28: AssertionError =========== 1 failed, 3 passed in 0.08 seconds ============</code> </pre> <br><p><img src="https://habrastorage.org/webt/c1/f_/vk/c1f_vkcnpoeplpn9arlb-fgj85a.png"></p><br><p>   <code>t_after</code> , <code>t_before</code>  <code>t_expected</code>      ,       assert-. </p><br><h3 id="--tbstyle"> --tb=style </h3><br><p>  <code>--tb=style</code>       .    pytest        ,    ,    .  <em>tracebacks</em>    ,  ,   .    <code>--tb=style</code> . ,    ,  short, line  no. <code>short</code>    <em>assert</em>   <strong>E</strong>  ; <code>line</code>     ; <em>no</em>   . </p><br><p>     <code>test_replace()</code> ,    ,       . <code>--tb=no</code>    </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest --tb=no tasks =================== test session starts =================== collected 4 items tasks/test_four.py .F tasks/test_three.py .. =========== 1 failed, 3 passed in 0.04 seconds ============</code> </pre> <br><blockquote> --tb=line in many cases is enough to tell what's wrong. If you have a ton of failing tests, this option can help to show a pattern in the failures: </blockquote><p> <code>--tb=line</code>    ,  ,   .      ,        : </p><br><pre> <code class="plaintext hljs">$ pytest --tb=line tasks =================== test session starts =================== collected 4 items tasks/test_four.py .F tasks/test_three.py .. ======================== FAILURES ========================= /path/to/code/ch1/tasks/test_four.py:20: AssertionError: assert Task(summary=...e=True, id=10) == Task( summary='...e=True, id=11) =========== 1 failed, 3 passed in 0.05 seconds ============</code> </pre> <br><p>    verbose tracebacks <code>--tb=short</code> : </p><br><pre> <code class="plaintext hljs">$ pytest --tb=short tasks =================== test session starts =================== collected 4 items tasks/test_four.py .F tasks/test_three.py .. ======================== FAILURES ========================= ______________________ test_replace _______________________ tasks/test_four.py:20: in test_replace assert t_after == t_expected E AssertionError: assert Task(summary=...e=True, id=10) == Task( summary='...e=True, id=11) E At index 3 diff: 10 != 11 E Use -v to get the full diff =========== 1 failed, 3 passed in 0.04 seconds ============</code> </pre> <br><p>   ,   ,  . </p><br><p>     ,     . </p><br><p> pytest <code>--tb=long</code>       traceback. pytest <code>--tb=auto</code>         <em>tracebacks</em> ,      .    . pytest <code>--tb=native</code>     <em>traceback</em>   . </p><br><h3 id="--durationsn"> --durations=N </h3><br><p>  <code>--durations=N</code>  ,       .     ;    N  tests/setups/teardowns   .    <code>--durations=0</code> ,            . </p><br><p>      ,   <code>time.sleep(0.1)</code>    . , : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch1 $ pytest --durations=3 tasks ================= test session starts ================= collected 4 items tasks/test_four.py .. tasks/test_three.py .. ============== slowest 3 test durations =============== 0.10s call tasks/test_four.py::test_replace 0.00s setup tasks/test_three.py::test_defaults 0.00s teardown tasks/test_three.py::test_member_access ============== 4 passed in 0.13 seconds</code> </pre> <br><p>     <em>sleep</em>      ,      .        : call(), (setup)  (teardown).      ,                    ,  ,  ,  .       3, pytest Fixtures,  . 49. </p><br><h3 id="--version"> --version </h3><br><p>  <code>--version</code>   pytest  ,    : </p><br><pre> <code class="plaintext hljs">$ pytest --version This is pytest version 3.0.7, imported from /path/to/venv/lib/python3.5/site-packages/pytest.py</code> </pre> <br><p>    pytest   , pytest     site-packages   . </p><br><h3 id="-h---help"> -h, --help </h3><br><p>  <code>-h/--help</code>  ,   ,     pytest.     ,   stock- pytest,       ,      ,  . </p><br><p>  <code>-h</code> : </p><br><ul><li> : pytest [] [file_or_dir] [file_or_dir] [...] </li><li>      ,      </li><li>  ,   ini   ,        6, ,  . 113 </li><li>   ,      pytest (    6, ,  . 113) </li><li>   ,  pytest <code>--markers</code>      ,    2,   ,  . 23 </li><li>   ,  pytest <code>--fixtures</code>       ,    3,  pytest,  . 49 </li></ul><br><p>        : </p><br><pre> <code class="plaintext hljs">(shown according to specified file_or_dir or current dir if not specified)</code> </pre> <br><p>   ,  ,            .   ,         pytest    conftest.py,    - (hook functions),   ,     . </p><br><p>    pytest   conftest.py               .     conftest.py  ini,   pytest.ini   6 «»,   113. </p><br><h2 id="uprazhneniya">  Exercices </h2><br><ol><li><p>    ,  <code>python -m virtualenv</code>  <code>python -m venv</code> .    ,        ,    ,       ,   ,      .      ,      .   1,  ,  . 155,     . </p><br></li><li><p>        . </p><br><pre> <code class="plaintext hljs">- $ source venv/bin/activate - $ deactivate On Windows: - C:\Users\okken\sandbox&gt;venv\scripts\activate.bat - C:\Users\okken\sandbox&gt;deactivate</code> </pre> <br></li><li><p>  pytest    . .  2, pip,   159,     .    ,      pytest,       ,     . </p><br></li><li><p>    .    ,          .  pytest   . </p><br></li><li><p>   assert.    assert something == something_else;   , : </p><br><ul><li> assert 1 in [2, 3, 4] </li><li> assert a &lt; b </li><li> assert 'fizz' not in 'fizzbuzz' </li></ul><br></li></ol><br><h2 id="chto-dalshe">  Et ensuite </h2><br><p>     ,   pytest     .    ,     .        ,   ,      ,     ,   . </p><br><p><img src="https://habrastorage.org/webt/jl/jn/bb/jljnbbjr-ejh473xy_eccsmknpk.png">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Retour</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Suivant</a> <img src="https://habrastorage.org/webt/rw/dy/-g/rwdy-grsvbpcetjttrmecdkxtlk.png"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr448782/">https://habr.com/ru/post/fr448782/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr448770/index.html">Mise à jour de la prise en charge de Razor dans Visual Studio Code. Maintenant avec blazor</a></li>
<li><a href="../fr448774/index.html">SQL vers CSV à l'aide de DBMS_SQL</a></li>
<li><a href="../fr448776/index.html">RxVMS - Une architecture pratique pour les applications Flutter</a></li>
<li><a href="../fr448778/index.html">Présentation du débogage de voyage dans le temps pour Visual Studio Enterprise 2019</a></li>
<li><a href="../fr448780/index.html">Ce qui donne des logiciels pour recruter en argent</a></li>
<li><a href="../fr448784/index.html">Nouvelles fonctionnalités pour les auteurs d'extensions dans Visual Studio 2019 version 16.1</a></li>
<li><a href="../fr448786/index.html">Test Python avec pytest. CHAPITRE 3 Appareils pytest</a></li>
<li><a href="../fr448790/index.html">SpaceVIL - Framework GUI multiplateforme pour le développement sur .Net Core, .Net Standard et JVM</a></li>
<li><a href="../fr448792/index.html">Test Python avec pytest. Luminaires intégrés, Chapitre 4</a></li>
<li><a href="../fr448794/index.html">Test Python avec pytest. Plugins CHAPITRE 5</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
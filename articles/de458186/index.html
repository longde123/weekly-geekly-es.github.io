<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏻‍🔧 👩🏿‍🤝‍👩🏽 👩🏽‍💻 WAL in PostgreSQL: 1. Puffercache 😦 🦀 🐋</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die vorherige Serie war der Isolation und Multi-Version von PostgreSQL gewidmet, und heute starten wir eine neue - über den Write-Ahead-Protokollierun...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>WAL in PostgreSQL: 1. Puffercache</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/postgrespro/blog/458186/">  Die vorherige Serie war der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Isolation und Multi-Version von</a> PostgreSQL gewidmet, und heute starten wir eine neue - <strong>über den</strong> Write-Ahead-Protokollierungsmechanismus.  Ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">möchte</a> Sie daran erinnern, dass das Material auf administrativen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schulungen</a> basiert, die Pavel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">pluzanov</a> und ich absolvieren, aber nicht wörtlich wiederholen und für nachdenkliches Lesen und unabhängiges Experimentieren gedacht sind. <br><br>  Dieser Zyklus besteht aus vier Teilen: <br><br><ul><li>  Puffercache (dieser Artikel); </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Voraufzeichnungsjournal</a> - wie es angeordnet ist und wie es während der Wiederherstellung verwendet wird; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Checkpoint-</a> und Hintergrundaufzeichnung - warum werden sie benötigt und wie werden sie konfiguriert? </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Protokolloptimierung</a> - zu lösende Ebenen und Aufgaben, Zuverlässigkeit und Leistung. </li></ul><br><h1>  Warum ist Journaling notwendig? </h1><br>  Dabei wird ein Teil der Daten, mit denen sich das DBMS befasst, im RAM gespeichert und auf verzögerte Weise auf die Festplatte (oder ein anderes nichtflüchtiges Medium) geschrieben.  Je seltener dies geschieht, desto weniger Input-Output und desto schneller arbeitet das System. <br><br>  Aber was passiert im Falle eines Fehlers, zum Beispiel beim Ausschalten der Stromversorgung oder wenn ein Fehler im DBMS-Code oder im Betriebssystem auftritt?  Der gesamte Inhalt des Arbeitsspeichers geht verloren und nur die auf die Festplatte geschriebenen Daten bleiben erhalten (bei einigen Arten von Fehlern kann auch die Festplatte betroffen sein, in diesem Fall hilft jedoch nur eine Sicherungskopie).  Grundsätzlich kann die E / A so organisiert werden, dass die Daten auf der Festplatte immer in einem konsistenten Zustand gehalten werden. Dies ist jedoch schwierig und nicht zu effizient (soweit ich weiß, ist nur Firebird diesen Weg gegangen). <br><br>  In der Regel, einschließlich PostgreSQL, sind die auf die Festplatte geschriebenen Daten inkonsistent. Bei der Wiederherstellung nach einem Fehler sind spezielle Aktionen erforderlich, um die Konsistenz wiederherzustellen.  Journaling ist genau der Mechanismus, der dies ermöglicht. <br><a name="habracut"></a><br><h1>  Puffer-Cache </h1><br>  Seltsamerweise werden wir über das Journaling mit einem Puffer-Cache sprechen.  Der Puffercache ist nicht die einzige Struktur, die im RAM gespeichert ist, sondern eine der wichtigsten und komplexesten.  Das Verständnis des Funktionsprinzips ist an sich wichtig. In diesem Beispiel lernen wir außerdem, wie Daten zwischen RAM und Festplatte ausgetauscht werden. <br><br>  Caching wird in modernen Computersystemen überall verwendet, ein Prozessor allein kann drei oder vier Cache-Ebenen zählen.  Im Allgemeinen wird jeder Cache benötigt, um den Leistungsunterschied zwischen den beiden Speichertypen auszugleichen, von denen einer relativ schnell ist, aber nicht für alle ausreicht und der andere relativ langsam, aber reichlich vorhanden ist.  Der Puffer-Cache glättet also die Differenz zwischen der Zugriffszeit auf RAM (Nanosekunden) und auf Festplatte (Millisekunden). <br><br>  Beachten Sie, dass das Betriebssystem auch über einen Festplatten-Cache verfügt, der das gleiche Problem löst.  Daher versucht DBMS normalerweise, doppeltes Caching zu vermeiden, indem es direkt auf die Festplatte zugreift und den Betriebssystem-Cache umgeht.  Bei PostgreSQL ist dies jedoch nicht der Fall: Alle Daten werden mit normalen Dateioperationen gelesen und geschrieben. <br><br>  Darüber hinaus verfügen Festplatten-Arrays und sogar die Festplatten selbst über einen eigenen Cache.  Diese Tatsache ist für uns immer noch nützlich, wenn wir zum Thema Zuverlässigkeit kommen. <br><br>  Aber zurück zum DBMS-Puffercache. <br><br>  Es wird so genannt, weil es ein Array von <em>Puffern ist</em> .  Jeder Puffer ist ein Platz für eine Datenseite (Block) plus einen Header.  Der Titel enthält unter anderem: <br><br><ul><li>  Position auf der Festplatte der Seite im Puffer (Datei- und Blocknummer darin); </li><li>  ein Zeichen dafür, dass sich die Daten auf der Seite geändert haben und früher oder später auf die Festplatte geschrieben werden sollten (ein solcher Puffer wird als <em>verschmutzt bezeichnet</em> ); </li><li>  Anzahl der Aufrufe des Puffers (Nutzungsanzahl); </li><li>  Flag zum Fixieren des Puffers (Pinanzahl). </li></ul><br>  Der Puffercache befindet sich im gemeinsam genutzten Speicher des Servers und ist für alle Prozesse zugänglich.  Um mit Daten zu arbeiten - lesen oder ändern - verarbeiten Sie gelesene Seiten im Cache.  Während sich die Seite im Cache befindet, arbeiten wir im RAM damit und sparen Festplattenzugriffe. <br><br><img src="https://habrastorage.org/webt/1u/-j/fd/1u-jfdnjvzjwvrddgb7tbvohhge.png"><br><br>  Zu Beginn enthält der Cache leere Puffer, die alle mit der Liste der freien Puffer verknüpft sind.  Die Bedeutung des Zeigers auf das „nächste Opfer“ wird etwas später klar.  Um die gewünschte Seite schnell im Cache zu finden, wird eine Hash-Tabelle verwendet. <br><br><h1>  Suchseite im Cache </h1><br>  Wenn ein Prozess eine Seite lesen muss, versucht er zunächst, sie mithilfe einer Hash-Tabelle im Puffercache zu finden.  Der Hash-Schlüssel ist die Dateinummer und die Seitenzahl in der Datei.  Im entsprechenden Warenkorb der Hash-Tabelle findet der Prozess die Puffernummer und prüft, ob sie wirklich die gewünschte Seite enthält.  Wie bei jeder Hash-Tabelle sind hier Kollisionen möglich;  In diesem Fall muss der Prozess mehrere Seiten überprüfen. <br><br><blockquote>  Die Verwendung einer Hash-Tabelle wurde lange kritisiert.  Diese Struktur ermöglicht es Ihnen, den Puffer auf der Seite schnell zu finden, ist jedoch völlig nutzlos, wenn Sie beispielsweise alle Puffer finden müssen, die von einer bestimmten Tabelle belegt sind.  Aber noch hat niemand einen guten Ersatz vorgeschlagen. <br></blockquote><br>  Wenn die gewünschte Seite im Cache gefunden wird, sollte der Prozess den Puffer durch Erhöhen der Pin-Anzahl "einfrieren" (mehrere Prozesse können dies gleichzeitig tun).  Solange der Puffer fest ist (der Zählerwert ist größer als Null), wird davon ausgegangen, dass der Puffer verwendet wird und sein Inhalt nicht "radikal" geändert werden sollte.  Beispielsweise wird möglicherweise eine neue Version der Zeile auf der Seite angezeigt. Dies stört niemanden aufgrund von Regeln für Mehrfachversionen und Sichtbarkeit.  Eine andere Seite kann jedoch nicht in den angehefteten Puffer eingelesen werden. <br><br><h1>  Verdrängen </h1><br>  Es kann vorkommen, dass die erforderliche Seite nicht im Cache gefunden wird.  In diesem Fall muss es von der Festplatte in einen Puffer gelesen werden. <br><br>  Befinden sich noch freie Puffer im Cache, wird der erste freie ausgewählt.  Früher oder später werden sie jedoch beendet (normalerweise ist die Größe der Datenbank größer als der für den Cache zugewiesene Speicher), und dann müssen Sie einen der belegten Puffer auswählen, die Seite dort erzwingen und eine neue auf dem freien Platz lesen. <br><br>  Der Preemption-Mechanismus basiert auf der Tatsache, dass die Prozesse bei jedem Zugriff auf den Puffer die Verwendungsanzahl im Header des Puffers erhöhen.  Daher haben die Puffer, die seltener als andere verwendet werden, einen niedrigeren Zählerwert und sind gute Kandidaten für eine Verdrängung. <br><br>  Der Clock-Sweep-Algorithmus durchläuft alle Puffer (unter Verwendung des Zeigers auf das "nächste Opfer") und verringert deren Zugriffsanzahl um eins.  Zum Verdrängen wird der erste Puffer ausgewählt, der: <br><br><ol><li>  hat einen Null-Treffer-Zähler (Nutzungsanzahl), </li><li>  und nicht fest (Null-Pin-Anzahl). </li></ol><br>  Sie können sehen, dass, wenn alle Puffer einen Trefferzähler ungleich Null haben, der Algorithmus mehr als einen Kreis ausführen muss, um die Zähler zurückzusetzen, bis einer von ihnen schließlich auf Null geht.  Um "Wicklungskreise" zu vermeiden, ist der Maximalwert des Trefferzählers auf 5 begrenzt. Bei einer großen Puffer-Cache-Größe kann dieser Algorithmus jedoch einen erheblichen Overhead verursachen. <br><br>  Nachdem der Puffer gefunden wurde, geschieht Folgendes. <br><br>  Der Puffer wird angeheftet, um andere Prozesse anzuzeigen, die verwendet werden.  Neben der Korrektur werden auch andere Blockierungsmethoden verwendet, auf die wir jedoch separat näher eingehen werden. <br><br>  Wenn sich herausstellt, dass der Puffer verschmutzt ist, dh geänderte Daten enthält, kann die Seite nicht einfach verworfen werden - zuerst muss sie auf der Festplatte gespeichert werden.  Dies ist keine gute Situation, da der Prozess, der die Seite lesen soll, auf die Aufzeichnung "fremder" Daten warten muss. Dieser Effekt wird jedoch durch die Checkpoint- und Hintergrundaufzeichnungsprozesse geglättet, die später erläutert werden. <br><br>  Als nächstes wird eine neue Seite von der Festplatte in den ausgewählten Puffer gelesen.  Der Zähler für die Anzahl der Anrufe wird auf eins gesetzt.  Außerdem muss der Link zur geladenen Seite in der Hash-Tabelle registriert sein, damit er in Zukunft gefunden werden kann. <br><br>  Jetzt zeigt der Link zum „nächsten Opfer“ auf den nächsten Puffer, und der gerade geladene hat Zeit, den Trefferzähler zu erhöhen, bis der Zeiger den gesamten Puffercache umrundet und wieder zurückkehrt. <br><br><h1>  Mit meinen eigenen Augen </h1><br>  Wie in PostgreSQL üblich, gibt es eine Erweiterung, mit der Sie in den Puffercache schauen können. <br><br><pre><code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXTENSION</span></span> pg_buffercache;</code> </pre> <br>  Erstellen Sie eine Tabelle und fügen Sie eine Zeile ein. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> cacheme( id <span class="hljs-type"><span class="hljs-type">integer</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> (autovacuum_enabled = <span class="hljs-keyword"><span class="hljs-keyword">off</span></span>); =&gt; <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> cacheme <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre><br>  Was wird im Puffer-Cache sein?  Es sollte mindestens eine Seite mit einer einzelnen Zeile angezeigt werden.  Wir werden dies mit der folgenden Abfrage überprüfen, in der wir nur die zu unserer Tabelle gehörenden Puffer auswählen (anhand der Dateinummer relfilenode) und die Layernummer (relforknumber) dekodieren: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> bufferid, <span class="hljs-keyword"><span class="hljs-keyword">CASE</span></span> relforknumber <span class="hljs-keyword"><span class="hljs-keyword">WHEN</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-string"><span class="hljs-string">'main'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHEN</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-string"><span class="hljs-string">'fsm'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHEN</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-string"><span class="hljs-string">'vm'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">END</span></span> relfork, relblocknumber, isdirty, usagecount, pinning_backends <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> relfilenode = pg_relation_filenode(<span class="hljs-string"><span class="hljs-string">'cacheme'</span></span>::<span class="hljs-type"><span class="hljs-type">regclass</span></span>);</code> </pre><pre> <code class="plaintext hljs"> bufferid | relfork | relblocknumber | isdirty | usagecount | pinning_backends ----------+---------+----------------+---------+------------+------------------ 15735 | main | 0 | t | 1 | 0 (1 row)</code> </pre><br>  So ist es - es gibt eine Seite im Puffer.  Es ist schmutzig (isdirty), der Trefferzähler ist gleich eins (Nutzungsanzahl) und es wird von keinem Prozess behoben (pinning_backends). <br><br>  Fügen Sie nun eine weitere Zeile hinzu und wiederholen Sie die Abfrage.  Um Buchstaben zu speichern, fügen wir eine Zeile in eine andere Sitzung ein und wiederholen die lange Anforderung mit dem Befehl <code>\g</code> . <br><br><pre> <code class="pgsql hljs">| =&gt; <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> cacheme <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">2</span></span>);</code> </pre><br><pre> <code class="pgsql hljs">=&gt; \g</code> </pre><pre> <code class="plaintext hljs"> bufferid | relfork | relblocknumber | isdirty | usagecount | pinning_backends ----------+---------+----------------+---------+------------+------------------ 15735 | main | 0 | t | 2 | 0 (1 row)</code> </pre><br>  Es wurden keine neuen Puffer hinzugefügt - die zweite Zeile passt auf dieselbe Seite.  Bitte beachten Sie, dass sich der Nutzungszähler erhöht hat. <br><br><pre> <code class="pgsql hljs">| =&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> cacheme;</code> </pre><pre> <code class="plaintext hljs">| id | ---- | 1 | 2 | (2 rows)</code> </pre><br><pre> <code class="pgsql hljs">=&gt; \g</code> </pre><pre> <code class="plaintext hljs"> bufferid | relfork | relblocknumber | isdirty | usagecount | pinning_backends ----------+---------+----------------+---------+------------+------------------ 15735 | main | 0 | t | 3 | 0 (1 row)</code> </pre><br>  Und nach dem Zugriff auf die Seite zum Lesen erhöht sich auch der Zähler. <br><br>  Und wenn Sie putzen? <br><br><pre> <code class="pgsql hljs">| =&gt; <span class="hljs-keyword"><span class="hljs-keyword">VACUUM</span></span> cacheme;</code> </pre><br><pre> <code class="pgsql hljs">=&gt; \g</code> </pre><pre> <code class="plaintext hljs"> bufferid | relfork | relblocknumber | isdirty | usagecount | pinning_backends ----------+---------+----------------+---------+------------+------------------ 15731 | fsm | 1 | t | 1 | 0 15732 | fsm | 0 | t | 1 | 0 15733 | fsm | 2 | t | 2 | 0 15734 | vm | 0 | t | 2 | 0 15735 | main | 0 | t | 3 | 0 (5 rows)</code> </pre><br>  Bei der Reinigung wurden eine Sichtbarkeitskarte (eine Seite) und eine Freiraumkarte (drei Seiten - die Mindestgröße dieser Karte) erstellt. <br><br>  Gut und so weiter. <br><br><h1>  Größeneinstellung </h1><br>  Die Cache-Größe wird durch den Parameter <em>shared_buffers festgelegt</em> .  Der Standardwert ist lächerlich 128 MB.  Dies ist einer der Parameter, deren Erhöhung unmittelbar nach der Installation von PostgreSQL sinnvoll ist. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> setting, unit <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_settings <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-type"><span class="hljs-type">name</span></span> = <span class="hljs-string"><span class="hljs-string">'shared_buffers'</span></span>;</code> </pre><pre> <code class="plaintext hljs"> setting | unit ---------+------ 16384 | 8kB (1 row)</code> </pre><br>  Beachten Sie, dass das Ändern eines Parameters einen Neustart des Servers erfordert, da der gesamte erforderliche Cache-Speicher beim Serverstart zugewiesen wird. <br><br>  Aus welchen Gründen wählen Sie den geeigneten Wert? <br><br>  Selbst die größte Datenbank verfügt über einen begrenzten Satz „heißer“ Daten, mit denen zu jedem Zeitpunkt aktiv gearbeitet wird.  Idealerweise sollte dieser Satz im Puffercache abgelegt werden (plus etwas Platz für "einmalige" Daten).  Wenn die Cache-Größe kleiner ist, werden sich aktiv verwendete Seiten ständig gegenseitig quetschen, was zu einer übermäßigen Eingabe / Ausgabe führt.  Es ist aber auch falsch, den Cache gedankenlos zu vergrößern.  Bei einer großen Größe steigen die Overhead-Kosten für die Wartung, und außerdem wird RAM auch für andere Anforderungen benötigt. <br><br>  Daher ist die optimale Puffer-Cache-Größe in verschiedenen Systemen unterschiedlich: Sie hängt von den Daten, der Anwendung und der Last ab.  Leider gibt es keine solche magische Bedeutung, die für alle gleich gut geeignet ist. <br><br>  Die Standardempfehlung lautet, 1/4 des Arbeitsspeichers als erste Annäherung zu verwenden (für Windows vor PostgreSQL 10 wurde empfohlen, eine kleinere Größe zu wählen). <br><br>  Und dann müssen Sie sich die Situation ansehen.  Am besten führen Sie ein Experiment durch: Erhöhen oder verringern Sie die Cache-Größe und vergleichen Sie die Systemleistung.  Dazu ist es natürlich notwendig, einen Prüfstand zu haben und die typische Last reproduzieren zu können - in der Produktionsumgebung sehen solche Experimente nach zweifelhaftem Vergnügen aus. <br><br><blockquote>  Lesen Sie unbedingt den Bericht von Nikolay Samokhvalov auf der PgConf-2019: "Ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">industrieller Ansatz für das PostgreSQL-</a> Tuning <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">: Datenbankexperimente</a> " <br></blockquote><br>  Einige Informationen darüber, was gerade passiert, können jedoch direkt auf einem Live-System mit derselben pg_buffercache-Erweiterung abgerufen werden. Achten Sie vor allem auf den richtigen Winkel. <br><br>  Sie können beispielsweise die Verteilung von Puffern nach ihrem Verwendungsgrad untersuchen: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> usagecount, count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> usagecount <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> usagecount;</code> </pre><pre> <code class="plaintext hljs"> usagecount | count ------------+------- 1 | 221 2 | 869 3 | 29 4 | 12 5 | 564 | 14689 (6 rows)</code> </pre><br>  In diesem Fall sind viele leere Zählerwerte freie Puffer.  Kein Wunder für ein System, in dem nichts passiert. <br><br>  Sie können sehen, wie viele Tabellen in unserer Datenbank zwischengespeichert sind und wie aktiv diese Daten verwendet werden (mit aktiver Verwendung in dieser Abfrage meinen wir Puffer mit einem Verwendungszähler von mehr als 3): <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> c.relname, count(*) blocks, round( <span class="hljs-number"><span class="hljs-number">100.0</span></span> * <span class="hljs-number"><span class="hljs-number">8192</span></span> * count(*) / pg_table_size(c.oid) ) "% of rel", round( <span class="hljs-number"><span class="hljs-number">100.0</span></span> * <span class="hljs-number"><span class="hljs-number">8192</span></span> * count(*) <span class="hljs-keyword"><span class="hljs-keyword">FILTER</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> b.usagecount &gt; <span class="hljs-number"><span class="hljs-number">3</span></span>) / pg_table_size(c.oid) ) "% hot" <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache b <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> pg_class c <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> pg_relation_filenode(c.oid) = b.relfilenode <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> b.reldatabase <span class="hljs-keyword"><span class="hljs-keyword">IN</span></span> ( <span class="hljs-number"><span class="hljs-number">0</span></span>, (<span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-type"><span class="hljs-type">oid</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_database <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> datname = current_database()) ) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> b.usagecount <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> c.relname, c.oid <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span>;</code> </pre><pre> <code class="plaintext hljs"> relname | blocks | % of rel | % hot ---------------------------+--------+----------+------- vac | 833 | 100 | 0 pg_proc | 71 | 85 | 37 pg_depend | 57 | 98 | 19 pg_attribute | 55 | 100 | 64 vac_s | 32 | 4 | 0 pg_statistic | 27 | 71 | 63 autovac | 22 | 100 | 95 pg_depend_reference_index | 19 | 48 | 35 pg_rewrite | 17 | 23 | 8 pg_class | 16 | 100 | 100 (10 rows)</code> </pre><br>  Hier ist zum Beispiel zu sehen, dass der Vac-Tisch den meisten Platz einnimmt (wir haben ihn in einem der vorherigen Themen verwendet), aber niemand hat sich lange damit befasst und er wurde noch nicht herausgedrückt, nur weil die freien Puffer noch nicht leer sind. <br><br>  Sie können sich andere Abschnitte einfallen lassen, die nützliche Informationen zum Nachdenken enthalten.  Es ist nur zu berücksichtigen, dass solche Anfragen: <br><br><ul><li>  muss mehrmals wiederholt werden: Die Zahlen variieren innerhalb bestimmter Grenzen; </li><li>  Es ist nicht erforderlich, es ständig (als Teil der Überwachung) durchzuführen, da die Erweiterung den Betrieb mit dem Puffercache für kurze Zeit blockiert. </li></ul><br>  Und noch etwas.  Wir sollten nicht vergessen, dass PostgreSQL durch regelmäßige Aufrufe des Betriebssystems mit Dateien arbeitet und daher doppeltes Caching stattfindet: Seiten fallen sowohl in den DBMS-Puffercache als auch in den Betriebssystemcache.  Daher führt der "Fehler" im Puffercache nicht immer dazu, dass echte E / A erforderlich sind.  Die Strategie, das Betriebssystem zu verdrängen, unterscheidet sich jedoch von der DBMS-Strategie: Das Betriebssystem weiß nichts über die Bedeutung der gelesenen Daten. <br><br><h1>  Massenverschiebung </h1><br>  Bei Vorgängen, bei denen Daten in großen Mengen gelesen oder geschrieben werden, besteht die Gefahr, dass nützliche Seiten schnell aus dem Puffercache mit "einmaligen" Daten verschoben werden. <br><br>  Um dies zu verhindern, werden für solche Operationen die sogenannten <em>Pufferringe</em> verwendet - ein kleiner Teil des Puffercaches wird für jede Operation zugewiesen.  Die Extrusion erfolgt nur innerhalb des Rings, sodass der Rest der Puffer-Cache-Daten nicht darunter leidet. <br><br>  Zum sequentiellen Lesen großer Tabellen (deren Größe ein Viertel des Puffercaches überschreitet) werden 32 Seiten zugewiesen.  Wenn ein anderer Prozess diese Daten auch beim Lesen einer Tabelle benötigt, beginnt er nicht zuerst mit dem Lesen der Tabelle, sondern stellt eine Verbindung zu einem vorhandenen Pufferring her.  Nach dem Scannen liest er den "verpassten" Anfang der Tabelle. <br><br>  Lass es uns überprüfen.  Erstellen Sie dazu eine Tabelle, sodass eine Zeile eine ganze Seite einnimmt - das Zählen ist bequemer.  Die Standardgröße des Puffercaches beträgt 128 MB = 16384 Seiten mit 8 KB.  Sie müssen also mehr als 4096 Seitenzeilen in die Tabelle einfügen. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> big( id <span class="hljs-type"><span class="hljs-type">integer</span></span> <span class="hljs-keyword"><span class="hljs-keyword">PRIMARY KEY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GENERATED</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ALWAYS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">IDENTITY</span></span>, s <span class="hljs-type"><span class="hljs-type">char</span></span>(<span class="hljs-number"><span class="hljs-number">1000</span></span>) ) <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> (fillfactor=<span class="hljs-number"><span class="hljs-number">10</span></span>); =&gt; <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> big(s) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-string"><span class="hljs-string">'FOO'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">4096</span></span>+<span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre><br>  Lassen Sie uns die Tabelle analysieren. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">ANALYZE</span></span> big; =&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> relpages <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_class <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-type"><span class="hljs-type">oid</span></span> = <span class="hljs-string"><span class="hljs-string">'big'</span></span>::<span class="hljs-type"><span class="hljs-type">regclass</span></span>;</code> </pre><pre> <code class="plaintext hljs"> relpages ---------- 4097 (1 row)</code> </pre><br>  Jetzt müssen wir den Server neu starten, um den Cache der von der Analyse gelesenen Tabellendaten zu löschen. <br><br><pre> <code class="plaintext hljs">student$ sudo pg_ctlcluster 11 main restart</code> </pre><br>  Lesen Sie nach dem Neustart die gesamte Tabelle: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">ANALYZE</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">COSTS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">OFF</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> big;</code> </pre><pre> <code class="plaintext hljs"> QUERY PLAN --------------------------------------------------------------------- Aggregate (actual time=14.472..14.473 rows=1 loops=1) -&gt; Seq Scan on big (actual time=0.031..13.022 rows=4097 loops=1) Planning Time: 0.528 ms Execution Time: 14.590 ms (4 rows)</code> </pre><br>  Stellen Sie sicher, dass nur 32 Puffer von Tabellenseiten im Puffercache belegt sind: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> relfilenode = pg_relation_filenode(<span class="hljs-string"><span class="hljs-string">'big'</span></span>::<span class="hljs-type"><span class="hljs-type">regclass</span></span>);</code> </pre><pre> <code class="plaintext hljs"> count ------- 32 (1 row)</code> </pre><br>  Wenn sequentielles Scannen verboten ist, wird die Tabelle nach Index gelesen: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> enable_seqscan = <span class="hljs-keyword"><span class="hljs-keyword">off</span></span>; =&gt; <span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">ANALYZE</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">COSTS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">OFF</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> big;</code> </pre><pre> <code class="plaintext hljs"> QUERY PLAN ------------------------------------------------------------------------------------------- Aggregate (actual time=50.300..50.301 rows=1 loops=1) -&gt; Index Only Scan using big_pkey on big (actual time=0.098..48.547 rows=4097 loops=1) Heap Fetches: 4097 Planning Time: 0.067 ms Execution Time: 50.340 ms (5 rows)</code> </pre><br>  In diesem Fall wird der Pufferring nicht verwendet und die gesamte Tabelle wird im Puffercache angezeigt (und fast auch der gesamte Index): <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> relfilenode = pg_relation_filenode(<span class="hljs-string"><span class="hljs-string">'big'</span></span>::<span class="hljs-type"><span class="hljs-type">regclass</span></span>);</code> </pre><pre> <code class="plaintext hljs"> count ------- 4097 (1 row)</code> </pre><br>  In ähnlicher Weise werden Pufferringe für den Reinigungsprozess (ebenfalls 32 Seiten) und für Massenschreibvorgänge COPY IN und CREATE TABLE AS SELECT verwendet (normalerweise 2048 Seiten, jedoch nicht mehr als 1/8 des gesamten Puffercaches). <br><br><h1>  Temporäre Tische </h1><br>  Eine Ausnahme von der allgemeinen Regel sind temporäre Tabellen.  Da temporäre Daten nur für einen Prozess sichtbar sind, haben sie im gemeinsam genutzten Puffercache nichts zu tun.  Darüber hinaus sind temporäre Daten nur innerhalb einer einzelnen Sitzung vorhanden, sodass sie nicht vor Fehlern geschützt werden müssen. <br><br>  Für temporäre Daten wird ein Cache im lokalen Speicher des Prozesses verwendet, dem die Tabelle gehört.  Da solche Daten nur einem Prozess zur Verfügung stehen, müssen sie nicht mit Sperren geschützt werden.  Der lokale Cache verwendet den üblichen präemptiven Algorithmus. <br><br>  Im Gegensatz zum allgemeinen Puffercache wird der Speicher für den lokalen Cache nach Bedarf zugewiesen, da temporäre Tabellen nicht in allen Sitzungen verwendet werden.  Die maximale Speichermenge für temporäre Tabellen in einer Sitzung wird durch den Parameter <em>temp_buffers</em> begrenzt. <br><br><h1>  Den Cache aufwärmen </h1><br>  Nach dem Neustart des Servers sollte einige Zeit vergehen, bis sich der Cache „erwärmt“ - und tatsächlich aktiv verwendete Daten sammelt.  Manchmal kann es nützlich sein, die Daten bestimmter Tabellen sofort in den Cache zu lesen, und dafür wurde eine spezielle Erweiterung entwickelt: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXTENSION</span></span> pg_prewarm;</code> </pre><br>  Bisher konnte eine Erweiterung nur bestimmte Tabellen im Puffercache (oder nur im Betriebssystemcache) lesen.  In PostgreSQL 11 konnte der aktuelle Cache-Status jedoch auf der Festplatte gespeichert und nach einem Neustart des Servers wiederhergestellt werden.  Um dies zu nutzen, müssen Sie die Bibliothek zu <em>shared_preload_libraries</em> hinzufügen und den Server neu starten. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">ALTER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SYSTEM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> shared_preload_libraries = <span class="hljs-string"><span class="hljs-string">'pg_prewarm'</span></span>;</code> </pre><br><pre> <code class="plaintext hljs">student$ sudo pg_ctlcluster 11 main restart</code> </pre><br>  Wenn sich im <em>Neustartfeld der</em> Parameter <em>pg_prewarm.autoprewarm</em> nicht geändert hat, wird automatisch der Hintergrundprozess des Autoprewarm-Masters gestartet, der in <em>pg_prewarm.autoprewarm_interval</em> die Liste der Seiten im Cache auf die Festplatte speichert (vergessen Sie nicht, den neuen Prozess beim Festlegen von <em>max_parallel_processes</em> zu berücksichtigen). <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-type"><span class="hljs-type">name</span></span>, setting, unit <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_settings <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-type"><span class="hljs-type">name</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIKE</span></span> <span class="hljs-string"><span class="hljs-string">'pg_prewarm%'</span></span>;</code> </pre><pre> <code class="plaintext hljs"> name | setting | unit ---------------------------------+---------+------ pg_prewarm.autoprewarm | on | pg_prewarm.autoprewarm_interval | 300 | s (2 rows)</code> </pre><br><pre> <code class="plaintext hljs">postgres$ ps -o pid,command --ppid `head -n 1 /var/lib/postgresql/11/main/postmaster.pid` | grep prewarm</code> </pre><pre> <code class="plaintext hljs">10436 postgres: 11/main: autoprewarm master</code> </pre><br>  Jetzt gibt es keine große Tabelle im Cache: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> relfilenode = pg_relation_filenode(<span class="hljs-string"><span class="hljs-string">'big'</span></span>::<span class="hljs-type"><span class="hljs-type">regclass</span></span>);</code> </pre><pre> <code class="plaintext hljs"> count ------- 0 (1 row)</code> </pre><br>  Wenn wir davon ausgehen, dass alle Inhalte sehr wichtig sind, können wir sie durch Aufrufen der folgenden Funktion in den Puffercache einlesen: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> pg_prewarm(<span class="hljs-string"><span class="hljs-string">'big'</span></span>);</code> </pre><pre> <code class="plaintext hljs"> pg_prewarm ------------ 4097 (1 row)</code> </pre><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> relfilenode = pg_relation_filenode(<span class="hljs-string"><span class="hljs-string">'big'</span></span>::<span class="hljs-type"><span class="hljs-type">regclass</span></span>);</code> </pre><pre> <code class="plaintext hljs"> count ------- 4097 (1 row)</code> </pre><br>  Die Liste der Seiten wird in der Datei autoprewarm.blocks gespeichert.  Um es zu sehen, können Sie einfach warten, bis der Autoprewarm-Master-Prozess zum ersten Mal ausgeführt wird. Wir initiieren dies jedoch manuell: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> autoprewarm_dump_now();</code> </pre><pre> <code class="plaintext hljs"> autoprewarm_dump_now ---------------------- 4340 (1 row)</code> </pre><br>  Die Anzahl der verworfenen Seiten beträgt mehr als 4097 - dies schließt die Seiten von Systemkatalogobjekten ein, die bereits vom Server gelesen wurden.  Und hier ist die Datei: <br><br><pre> <code class="plaintext hljs">postgres$ ls -l /var/lib/postgresql/11/main/autoprewarm.blocks</code> </pre><pre> <code class="plaintext hljs">-rw------- 1 postgres postgres 102078  29 15:51 /var/lib/postgresql/11/main/autoprewarm.blocks</code> </pre><br>  Starten Sie nun den Server erneut. <br><br><pre> <code class="plaintext hljs">student$ sudo pg_ctlcluster 11 main restart</code> </pre><br>  Und unmittelbar nach dem Start wird unsere Tabelle erneut im Cache angezeigt. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> relfilenode = pg_relation_filenode(<span class="hljs-string"><span class="hljs-string">'big'</span></span>::<span class="hljs-type"><span class="hljs-type">regclass</span></span>);</code> </pre><pre> <code class="plaintext hljs"> count ------- 4097 (1 row)</code> </pre><br>  Dies bietet den gleichen Autoprewarm-Master-Prozess: Es liest die Datei, teilt die Seiten in Datenbanken auf, sortiert sie (damit das Lesen von der Festplatte so konsistent wie möglich ist) und übergibt den Autoprewarm-Worker zur Verarbeitung an den einzelnen Workflow. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fortsetzung folgt</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458186/">https://habr.com/ru/post/de458186/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458172/index.html">Methoden zum Koppeln elektrischer Verbindungen beim Verfolgen von Differentialpaaren auf Leiterplatten</a></li>
<li><a href="../de458176/index.html">Die Exaflop-Barriere wird 2021 überwunden</a></li>
<li><a href="../de458180/index.html">Kea-basierter Failover-DHCP-Server</a></li>
<li><a href="../de458182/index.html">Wir lesen VKontakte über RSS</a></li>
<li><a href="../de458184/index.html">Haxe und PHP: statische Eingabe, Pfeilfunktionen, Metaprogrammierung und vieles mehr</a></li>
<li><a href="../de458190/index.html">Ich sehe, es bedeutet, dass ich existiere: Deep Learning Review in Computer Vision (Teil 2)</a></li>
<li><a href="../de458202/index.html">Schauen Sie sich einfach SObjectizer an, wenn Sie Actors oder CSP in Ihrem C ++ - Projekt verwenden möchten</a></li>
<li><a href="../de458204/index.html">So bewerten Sie die Speicherleistung unter Linux: Benchmarking mit offenen Tools</a></li>
<li><a href="../de458206/index.html">Erhabener Text 3 für das Site-Layout. Passen Sie das Erscheinungsbild an und installieren Sie Plugins. Anfängerleitfaden</a></li>
<li><a href="../de458208/index.html">Digitale Veranstaltungen in Moskau vom 01. bis 07. Juli</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêá üë©üèø‚Äçüíº üöé Aide-m√©moire pour l'intelligence artificielle - jetez l'exc√©dent, enseignez l'essentiel. Technique de traitement des s√©quences de formation üë®üèæ‚Äçüé® ‚è±Ô∏è ü§µüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il s'agit du deuxi√®me article sur l'analyse et l'√©tude des mat√©riaux de la comp√©tition pour la recherche de navires en mer. Mais maintenant, nous allo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aide-m√©moire pour l'intelligence artificielle - jetez l'exc√©dent, enseignez l'essentiel. Technique de traitement des s√©quences de formation</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433946/">  Il s'agit du deuxi√®me article sur l'analyse et l'√©tude des mat√©riaux de la comp√©tition pour la recherche de navires en mer.  Mais maintenant, nous allons √©tudier les propri√©t√©s des s√©quences d'entra√Ænement.  Essayons de trouver les informations suppl√©mentaires, la redondance dans les donn√©es source et supprimons-les. <br><br><img src="https://habrastorage.org/webt/b4/yk/pz/b4ykpzewv86nxd0szou25c_egzg.jpeg"><br><br>  Cet article est aussi simplement le r√©sultat de la curiosit√© et d'un int√©r√™t oiseux, rien de cela ne se rencontre dans la pratique, et pour les t√¢ches pratiques, il n'y a presque rien pour le copier-coller.  Ceci est une petite √©tude des propri√©t√©s de la s√©quence de formation - le raisonnement et le code de l'auteur sont pr√©sent√©s, vous pouvez tout v√©rifier / compl√©ter / changer vous-m√™me. <br><br>  Le concours de recherche marine de kaggle a r√©cemment pris fin.  Airbus a propos√© d'analyser les images satellites de la mer avec et sans navires.  Un total de 192555 images 768x768x3 - soit 340 720 680 960 octets si uint8 et ceci est une √©norme quantit√© d'informations et il y avait un vague soup√ßon que toutes les images ne sont pas n√©cessaires pour former le r√©seau et dans cette quantit√© d'informations, la r√©p√©tition et la redondance sont √©videntes.  Lors de la formation d'un r√©seau, il est habituel de s√©parer certaines donn√©es et de ne pas les utiliser dans la formation, mais de les utiliser pour v√©rifier la qualit√© de la formation.  Et si une seule et m√™me √©tendue de la mer est tomb√©e dans deux images diff√©rentes et en m√™me temps une image est tomb√©e dans la s√©quence d'entra√Ænement et l'autre dans la s√©quence de v√©rification, alors la v√©rification perdra son sens et le r√©seau sera recycl√©, nous ne v√©rifierons pas la capacit√© du r√©seau √† g√©n√©raliser les informations, car les donn√©es sont les m√™mes.  La lutte contre ce ph√©nom√®ne a pris beaucoup de temps et d'efforts au GPU des participants.  Comme d'habitude, les gagnants et les laur√©ats ne sont pas press√©s de montrer √† leurs fans les secrets de la ma√Ætrise et de d√©finir le code, et il n'y a aucun moyen de l'√©tudier et de l'apprendre, nous allons donc reprendre la th√©orie. <br><a name="habracut"></a><br>  Une simple v√©rification visuelle a montr√© qu'il y a vraiment trop de donn√©es, la m√™me √©tendue de mer est tomb√©e en images diff√©rentes, regardez les exemples <br><br><img src="https://habrastorage.org/webt/b8/wn/tb/b8wntbyikiqqjafizkmc6okundc.png"><br><br><img src="https://habrastorage.org/webt/ph/xh/g1/phxhg1aaqljhnqiaq28h17fktvo.png"><br><br><img src="https://habrastorage.org/webt/7z/pz/ua/7zpzuaapp2rhjfsxqbqe2jip5jk.png"><br><br><img src="https://habrastorage.org/webt/ed/yx/7c/edyx7cyftluhepdskpo7thftvlm.png"><br><br>  C'est pour cette raison que nous ne sommes pas int√©ress√©s par les donn√©es r√©elles, il y a beaucoup de d√©pendances parasites, des connexions inutiles avec nous, un mauvais balisage et d'autres d√©fauts. <br><br>  Dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premier article,</a> nous avons regard√© des images avec des ellipses et du bruit, et nous continuerons √† les √©tudier.  L'avantage de cette approche est que si vous trouvez une caract√©ristique attrayante d'un r√©seau form√© sur un ensemble arbitraire d'images, il n'est pas clair s'il s'agit d'une propri√©t√© de r√©seau ou d'une propri√©t√© d'un ensemble de formation.  Les param√®tres statistiques des s√©quences tir√©es du monde r√©el sont inconnus.  R√©cemment, le grand ma√Ætre Pleskov Pavel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">paske57</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">a</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">expliqu√©</a> qu'il est parfois facile de gagner une classification de segmentation / classification des images s'il est bon de se plonger dans les donn√©es vous-m√™me, par exemple, voir les m√©tadonn√©es des photos.  Et il n'y a aucune garantie que dans les donn√©es r√©elles il n'y a pas de telles d√©pendances, involontairement laiss√©es.  Par cons√©quent, pour √©tudier les propri√©t√©s du r√©seau, nous prenons des photos avec des ellipses et des rectangles, et d√©terminons l'emplacement et la couleur et d'autres param√®tres √† l'aide d'un g√©n√©rateur de nombres al√©atoires d'un ordinateur (qui a un g√©n√©rateur pseudo-al√©atoire, qui a un g√©n√©rateur bas√© sur d'autres algorithmes non num√©riques et les propri√©t√©s physiques de la substance, Mais nous n'en discuterons pas dans cet article). <br><br>  Alors, prenez la mer <i>np.random.sample () * 0,75</i> , nous n'avons pas besoin de vagues, de vent, de c√¥tes et d'autres motifs et faces cach√©s.  Les navires / ellipses seront √©galement peints de la m√™me couleur, et pour distinguer la mer du bateau et des interf√©rences, ajoutez 0,25 √† la mer ou au bateau / brouilleur, et ils auront tous la m√™me forme - des ellipses de tailles et d'orientations diff√©rentes.  L'interf√©rence ne sera √©galement que des rectangles de la m√™me couleur que l'ellipse - c'est important, les informations et les interf√©rences de la m√™me couleur sur le fond du bruit.  Nous <i>n'apporterons</i> qu'une petite modification √† la coloration et nous ex√©cuterons <i>np.random.sample ()</i> pour chaque image et pour chaque ellipse / rectangle, c'est-√†-dire  Ni l'arri√®re-plan ni la couleur de l'ellipse / du rectangle ne sont r√©p√©t√©s.  Plus loin dans le texte, il y a un code du programme pour cr√©er des images / masques et un exemple de dix paires s√©lectionn√©es au hasard. <br><br>  Prenez une version tr√®s courante du r√©seau (vous pouvez prendre votre r√©seau pr√©f√©r√©) et essayez d'identifier et de montrer la redondance d'une grande s√©quence de formation, pour obtenir au moins une sorte de caract√©ristiques qualitatives et quantitatives de la redondance.  C'est-√†-dire  l'auteur pense que de nombreux gigaoctets de s√©quences d'entra√Ænement sont substantiellement redondants, il y a beaucoup d'images inutiles, il n'est pas n√©cessaire de charger des dizaines de GPU et de faire des calculs inutiles.  La redondance des donn√©es se manifeste non seulement et non pas tant dans le fait que les m√™mes parties sont affich√©es dans des images diff√©rentes, mais aussi dans la redondance des informations dans ces donn√©es.  Les donn√©es peuvent √™tre redondantes m√™me si elles ne sont pas r√©p√©t√©es exactement.  Veuillez noter qu'il ne s'agit pas d'une d√©finition stricte des informations et de leur suffisance ou redondance.  Nous voulons simplement savoir combien vous pouvez r√©duire le train, quelles images vous pouvez jeter de la s√©quence de formation et combien de photos suffisent pour une formation acceptable (nous d√©finirons nous-m√™mes la pr√©cision dans le programme).  Il s'agit d'un programme sp√©cifique, d'un ensemble de donn√©es sp√©cifique, et il est possible que sur les ellipses avec des triangles, comme obstacle, rien ne fonctionne aussi bien que sur les ellipses avec des rectangles (mon hypoth√®se est que tout sera le m√™me et le m√™me. Mais nous ne le v√©rifions pas maintenant , nous n'effectuons pas d'analyse et ne prouvons pas de th√©or√®mes). <br><br>  Donc, √©tant donn√©: <br><br><ul><li>  s√©quence d'apprentissage de paires image / masque.  Nous pouvons g√©n√©rer un nombre illimit√© de paires d'images / masques.  Je r√©pondrai imm√©diatement √† la question - pourquoi la couleur et l'arri√®re-plan sont-ils al√©atoires?  Je r√©pondrai simplement, bri√®vement, clairement et compl√®tement que je l'aime tellement, une entit√© suppl√©mentaire sous la forme d'une fronti√®re n'est pas n√©cessaire; </li><li>  le r√©seau est ordinaire, U-net ordinaire, l√©g√®rement modifi√© et largement utilis√© pour la segmentation. </li></ul><br>  Id√©e √† tester: <br><br><ul><li>  dans la s√©quence construite, comme dans les t√¢ches r√©elles, des gigaoctets de donn√©es sont utilis√©s.  L'auteur estime que la taille de la s√©quence de formation n'est pas si critique et qu'il ne devrait pas y avoir beaucoup de donn√©es, mais qu'elles devraient contenir ¬´beaucoup¬ª d'informations.  Une telle quantit√©, dix mille paires d'images / masques, n'est pas n√©cessaire et le r√©seau apprendra √† partir d'une quantit√© de donn√©es beaucoup plus petite. </li></ul><br>  Commen√ßons, s√©lectionnons 10 000 paires et consid√©rons-les attentivement.  Nous allons extraire toute l'eau, tous les morceaux inutiles de cette s√©quence d'entra√Ænement et utiliser et mettre en pratique tous les r√©sidus secs. <br><br>  Vous pouvez maintenant tester votre intuition et supposer combien de paires sur 10 000 suffisent pour former et pr√©dire une autre, mais √©galement cr√©er une s√©quence de 10 000 paires avec une pr√©cision de plus de 0,98.  √âcrivez sur un morceau de papier, apr√®s comparaison. <br><br>  Pour une utilisation pratique, veuillez prendre en compte que la mer et les navires avec interf√©rence sont s√©lectionn√©s artificiellement, c'est <i>np.random.sample ()</i> . <br><br><div class="spoiler">  <b class="spoiler_title">Nous chargeons des biblioth√®ques, nous d√©terminons les tailles d'un tableau d'images</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.draw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ellipse, polygon <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization,Activation,Add,Dropout <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.losses <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> binary_crossentropy <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> keras w_size = <span class="hljs-number"><span class="hljs-number">128</span></span> train_num = <span class="hljs-number"><span class="hljs-number">10000</span></span> radius_min = <span class="hljs-number"><span class="hljs-number">10</span></span> radius_max = <span class="hljs-number"><span class="hljs-number">20</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">d√©terminer les fonctions de perte et de pr√©cision</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br>  Nous utiliserons la m√©trique du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premier article</a> .  Permettez-moi de rappeler aux lecteurs que nous allons pr√©dire le masque du pixel - c'est la ¬´mer¬ª ou le ¬´navire¬ª et √©valuer la v√©rit√© ou la fausset√© de la pr√©diction.  C'est-√†-dire  Les quatre options suivantes sont possibles - nous avons correctement pr√©dit qu'un pixel est une ¬´mer¬ª, correctement pr√©dit qu'un pixel est un ¬´navire¬ª ou fait une erreur en pr√©disant une ¬´mer¬ª ou un ¬´navire¬ª.  Et donc, pour toutes les images et tous les pixels, nous estimons le nombre des quatre options et calculons le r√©sultat - ce sera le r√©sultat du r√©seau.  Et moins les pr√©visions sont erron√©es et vraies, plus le r√©sultat est pr√©cis et meilleur est le r√©seau. <br><br>  Et pour la recherche, prenons l'option du U-net bien √©tudi√©, qui est un excellent r√©seau pour la segmentation d'images.  La version pas si classique d'U-net a √©t√© choisie, mais l'id√©e est la m√™me, le r√©seau effectue une op√©ration tr√®s simple avec les images - il r√©duit la taille de l'image avec quelques transformations √©tape par √©tape, puis essaie de r√©cup√©rer le masque de l'image compress√©e.  C'est-√†-dire  la dimension de l'image dans notre cas est port√©e √† 16x16 puis nous essayons de restaurer le masque en utilisant les donn√©es de toutes les couches de compression pr√©c√©dentes. <br><br>  Nous examinons le r√©seau comme une ¬´bo√Æte noire¬ª, nous ne regarderons pas ce qui se passe avec le r√©seau √† l'int√©rieur, comment les poids changent et comment les gradients sont choisis - c'est le sujet d'une autre √©tude. <br><br><div class="spoiler">  <b class="spoiler_title">U-net avec blocs</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convolution_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, filters, size, strides=</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">,</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">)</span></span></span></span><span class="hljs-function"><span class="hljs-params">, padding=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'same'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, activation=True)</span></span></span><span class="hljs-function">:</span></span> x = Conv2D(filters, size, strides=strides, padding=padding)(x) x = BatchNormalization()(x) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> activation == <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">residual_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(blockInput, num_filters=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">16</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(blockInput) x = BatchNormalization()(x) x = convolution_block(x, num_filters, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>) ) x = convolution_block(x, num_filters, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) x = Add()([x, blockInput]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-comment"><span class="hljs-comment"># Build model def build_model(input_layer, start_neurons, DropoutRatio = 0.5): conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding="same" )(input_layer) conv1 = residual_block(conv1,start_neurons * 1) conv1 = residual_block(conv1,start_neurons * 1) conv1 = Activation('relu')(conv1) pool1 = MaxPooling2D((2, 2))(conv1) pool1 = Dropout(DropoutRatio/2)(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding="same" )(pool1) conv2 = residual_block(conv2,start_neurons * 2) conv2 = residual_block(conv2,start_neurons * 2) conv2 = Activation('relu')(conv2) pool2 = MaxPooling2D((2, 2))(conv2) pool2 = Dropout(DropoutRatio)(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding="same")(pool2) conv3 = residual_block(conv3,start_neurons * 4) conv3 = residual_block(conv3,start_neurons * 4) conv3 = Activation('relu')(conv3) pool3 = MaxPooling2D((2, 2))(conv3) pool3 = Dropout(DropoutRatio)(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding="same")(pool3) conv4 = residual_block(conv4,start_neurons * 8) conv4 = residual_block(conv4,start_neurons * 8) conv4 = Activation('relu')(conv4) pool4 = MaxPooling2D((2, 2))(conv4) pool4 = Dropout(DropoutRatio)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding="same")(pool4) convm = residual_block(convm,start_neurons * 16) convm = residual_block(convm,start_neurons * 16) convm = Activation('relu')(convm) deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) uconv4 = Dropout(DropoutRatio)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding="same")(uconv4) uconv4 = residual_block(uconv4,start_neurons * 8) uconv4 = residual_block(uconv4,start_neurons * 8) uconv4 = Activation('relu')(uconv4) deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) uconv3 = Dropout(DropoutRatio)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding="same")(uconv3) uconv3 = residual_block(uconv3,start_neurons * 4) uconv3 = residual_block(uconv3,start_neurons * 4) uconv3 = Activation('relu')(uconv3) deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) uconv2 = Dropout(DropoutRatio)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding="same")(uconv2) uconv2 = residual_block(uconv2,start_neurons * 2) uconv2 = residual_block(uconv2,start_neurons * 2) uconv2 = Activation('relu')(uconv2) deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) uconv1 = Dropout(DropoutRatio)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding="same")(uconv1) uconv1 = residual_block(uconv1,start_neurons * 1) uconv1 = residual_block(uconv1,start_neurons * 1) uconv1 = Activation('relu')(uconv1) uconv1 = Dropout(DropoutRatio/2)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer # model input_layer = Input((w_size, w_size, 3)) output_layer = build_model(input_layer, 16) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer="adam", metrics=[my_iou_metric]) model.summary()</span></span></code> </pre> <br></div></div><br>  La fonction de g√©n√©ration de paires image / masque.  Sur une image couleur 128x128 remplie de bruit al√©atoire avec une s√©lection al√©atoire de deux plages, soit 0,0 ... 0,75 ou 0,25..1,0.  Placez au hasard une ellipse orient√©e au hasard dans l'image et placez un rectangle au m√™me endroit.  Nous v√©rifions qu'elles ne se coupent pas et, si n√©cessaire, d√©calons le rectangle sur le c√¥t√©.  Chaque fois que nous recalculons les valeurs de la coloration de la mer / bateau.  Pour plus de simplicit√©, nous allons mettre le masque avec l'image dans un tableau, comme quatri√®me couleur, c'est-√†-dire  Red.Green.Blue.Mask, c'est plus facile. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> img_l = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img_h = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span> + <span class="hljs-number"><span class="hljs-number">0.25</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">4</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max c = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p1 = np.rint(np.random.sample()* (w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max) p2 = np.rint(np.random.sample()* (w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max) p3 = np.rint(np.random.sample()* (<span class="hljs-number"><span class="hljs-number">2</span></span>*radius_max - radius_min) + radius_min) p4 = np.rint(np.random.sample()* (<span class="hljs-number"><span class="hljs-number">2</span></span>*radius_max - radius_min) + radius_min) poly = np.array(( (p1, p2), (p1, p2+p4), (p1+p3, p2+p4), (p1+p3, p2), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) in_sc_rr = list(set(rr) &amp; set(rr_p)) in_sc_cc = list(set(cc) &amp; set(cc_p)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_rr) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> len(in_sc_cc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_rr) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: _delta_rr = np.max(in_sc_rr) - np.min(in_sc_rr) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(rr_p) &gt; np.mean(in_sc_rr): poly[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] += _delta_rr <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] -= _delta_rr <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_cc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: _delta_cc = np.max(in_sc_cc) - np.min(in_sc_cc) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(cc_p) &gt; np.mean(in_sc_cc): poly[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] += _delta_cc <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] -= _delta_cc rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr, cc,<span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br>  Cr√©ons une s√©quence d'entra√Ænement de paires, voir au hasard 10 <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] f_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">3</span></span>) f_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) <span class="hljs-comment"><span class="hljs-comment">#    10   fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk]) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze())</span></span></code> </pre><br><img src="https://habrastorage.org/webt/42/7w/x6/427wx65rkih5858776eoahbgbhw.png"><br><br><h3>  Premi√®re √©tape.  Essayons de nous entra√Æner sur un ensemble minimal </h3><br>  La premi√®re √©tape de notre exp√©rience est simple, nous essayons de former le r√©seau pour ne pr√©dire que 11 premi√®res images. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br> <code>accuracy 0.8636 loss 0.0666 : : 47it [00:29, 5.82it/s]</code> <br> <br>  Nous avons s√©lectionn√© les 11 premiers dans la s√©quence initiale et form√© le r√©seau sur eux.  Peu importe que le r√©seau m√©morise ces images sp√©cifiquement ou les r√©sume, l'essentiel est qu'il puisse reconna√Ætre ces 11 images de la mani√®re dont nous avons besoin.  En fonction de l'ensemble de donn√©es s√©lectionn√© et de sa pr√©cision, la formation r√©seau peut durer tr√®s, tr√®s longtemps.  Mais nous n'avons que quelques it√©rations.  Je r√©p√®te qu‚Äôil n‚Äôest plus important pour nous maintenant de savoir comment et ce que le r√©seau a appris ou appris, l‚Äôessentiel est qu‚Äôil ait atteint la pr√©cision de pr√©diction √©tablie. <br><br><h3>  Commencez maintenant l'exp√©rience principale </h3><br>  Nous prendrons de nouvelles paires image / masque de la s√©quence construite et essaierons de les pr√©dire par le r√©seau form√© sur la s√©quence d√©j√† s√©lectionn√©e.  Au d√©but, il ne s'agit que de 11 paires d'image / masque et le r√©seau est entra√Æn√©, peut-√™tre pas tr√®s correctement.  Si dans une nouvelle paire le masque de l'image est pr√©dit avec une pr√©cision acceptable, alors nous rejetons cette paire, elle n'a pas de nouvelles informations pour le r√©seau, elle sait d√©j√† et peut calculer le masque √† partir de cette image.  Si la pr√©cision de la pr√©diction est insuffisante, nous ajoutons cette image avec un masque √† notre s√©quence et commen√ßons √† entra√Æner le r√©seau jusqu'√† ce qu'un r√©sultat de pr√©cision acceptable soit atteint sur la s√©quence s√©lectionn√©e.  C'est-√†-dire  Cette image contient de nouvelles informations et nous les ajoutons √† notre s√©quence de formation et extrayons les informations qu'elle contient par formation. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f_imgs[m0_select&gt;0], f_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9830 loss 0.0287 selected img 271 tested img 9949 : : 1563it [14:16, 1.01it/s]</code> </pre> <br>  Ici, la pr√©cision est utilis√©e dans le sens de ¬´pr√©cision¬ª, et non comme une m√©trique standard de k√©ros, et le sous-programme ¬´my_iou_metric¬ª est utilis√© pour calculer la pr√©cision.  Il est tr√®s int√©ressant d'observer la pr√©cision et le nombre d'images √©tudi√©es et ajout√©es.  Au d√©but, presque toutes les paires image / masque sont ajout√©es par le r√©seau, et quelque part autour de 70, il commence √† se jeter.  Plus pr√®s de 8000 jette presque toutes les paires. <br><br>  V√©rifiez les paires visuellement al√©atoires s√©lectionn√©es par le r√©seau: <br><br><pre> <code class="python hljs">fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) t_imgs = f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>] t_msks = f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): kk = np.random.randint(t_msks.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(t_imgs[kk]) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(t_msks[kk].squeeze())</code> </pre><br>  Rien de sp√©cial ou de surnaturel: <br><br><img src="https://habrastorage.org/webt/dq/rr/7r/dqrr7rze9sbmmoepvvjuma-tjxu.png"><br><br>  Ce sont des paires s√©lectionn√©es par le r√©seau √† diff√©rentes √©tapes de la formation.  Lorsque le r√©seau a re√ßu une paire d'entr√©e de cette s√©quence, il n'a pas pu calculer le masque avec la pr√©cision sp√©cifi√©e et cette paire a √©t√© incluse dans la s√©quence d'apprentissage.  Mais rien de sp√©cial, de photos ordinaires. <br><br><h3>  V√©rification du r√©sultat et de la pr√©cision </h3><br>  V√©rifions la qualit√© du programme de formation du r√©seau, assurez-vous que la qualit√© ne d√©pend pas de mani√®re significative de l'ordre de la s√©quence initiale, pour laquelle nous m√©langeons la s√©quence initiale des paires image / masque, prenons les 11 autres en premier et de la m√™me mani√®re, entra√Ænons le r√©seau et coupons l'exc√©dent. <br><br><pre> <code class="python hljs">sh = np.arange(train_num) np.random.shuffle(sh) f0_imgs = f_imgs[sh] f0_msks = f_msks[sh] model.compile(loss=bce_dice_loss, optimizer=<span class="hljs-string"><span class="hljs-string">"adam"</span></span>, metrics=[my_iou_metric]) model.summary()</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Code d'entra√Ænement</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f0_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f0_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br><pre> <code class="bash hljs">accuracy 0.8636 loss 0.0710 : : 249it [01:03, 5.90it/s]</code> </pre> <br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f0_imgs[m0_select&gt;0], f0_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9890 loss 0.0224 selected img 408 tested img 9456 : : 1061it [21:13, 2.16s/it]</code> </pre> <br></div></div><br>  Le r√©sultat ne d√©pend pas de mani√®re significative de l'ordre des paires de la s√©quence d'origine.  Dans le cas pr√©c√©dent, le r√©seau a choisi 271, maintenant 408, si vous le m√©langez, le r√©seau peut choisir une quantit√© diff√©rente.  Nous ne v√©rifierons pas, l'auteur estime qu'il y en aura toujours sensiblement moins de 10 000. <br><br>  V√©rifier la pr√©cision de la pr√©diction du r√©seau sur une nouvelle s√©quence ind√©pendante <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] test_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">3</span></span>) test_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) test_pred_0 = model.predict(test_imgs) t_val_0 = get_iou_vector(test_msks,test_pred_0) t_val_0</code> </pre> <br><pre> <code class="bash hljs">0.9927799999999938</code> </pre> <br><br><h3>  R√©sum√© et conclusions </h3><br>  Nous avons donc pu extraire de moins de trois √† quatre cents s√©lectionn√©s parmi 10000 paires, la pr√©cision de la pr√©diction est de 0,99278, nous avons pris toutes les paires qui contiennent au moins des informations utiles et jet√© le reste.  Nous n'avons pas align√© les param√®tres statistiques de la s√©quence d'apprentissage, ajout√© la r√©p√©tabilit√© des informations, etc.  et n'a pas du tout utilis√© de m√©thodes statistiques.  Nous prenons une photo qui contient des informations encore inconnues du r√©seau et nous en extrayons tout dans le poids du r√©seau.  Si le r√©seau rencontre au moins une image ¬´myst√©rieuse¬ª, il utilisera tout cela dans les affaires. <br><br>  Un total de 271 paires image / masque contiennent des informations pour pr√©dire 10000 paires avec une pr√©cision d'au moins 0,8075 sur chaque paire, c'est-√†-dire que la pr√©cision totale sur toute la s√©quence est plus √©lev√©e, mais dans chaque image elle n'est pas inf√©rieure √† 0,8075, nous n'avons pas d'images que nous n'avons pas nous pouvons pr√©dire et nous connaissons la limite inf√©rieure de cette pr√©diction.  (ici, bien s√ªr, l'auteur s'est vant√©, comment sans cela, l'article ne v√©rifie pas cette d√©claration, environ 0,8075, ou les preuves, mais tr√®s probablement, cela est vrai) <br><br>  Pour former le r√©seau, il n'est pas n√©cessaire de charger le GPU avec tout ce qui vient √† port√©e de main, vous pouvez retirer le c≈ìur du train et y former le r√©seau au d√©but de la formation.  Au fur et √† mesure que vous obtenez de nouvelles images, vous pouvez manuellement marquer celles que le r√©seau n'a pas pu pr√©dire et les ajouter au c≈ìur du train, en recyclant √† nouveau le r√©seau pour extraire toutes les informations des nouvelles images.  Et il n'est pas n√©cessaire de distinguer une s√©quence de validation; nous pouvons supposer que tout le reste, sauf celui s√©lectionn√©, est une s√©quence de validation. <br><br>  Encore une remarque math√©matique non stricte, mais tr√®s importante.  Il est s√ªr de dire que chaque paire image / masque contient ¬´beaucoup¬ª d'informations.  Chaque paire contient ¬´beaucoup¬ª d'informations, bien que dans la plupart des paires image / masque, les informations se croisent ou se r√©p√®tent.  Chacune des 271 paires image / masque contient des informations essentielles pour la pr√©diction, et cette paire ne peut pas simplement √™tre jet√©e. <br><br>  Eh bien, une petite remarque sur les plis, de nombreux experts et kagglers divisent la s√©quence d'entra√Ænement en plis et les forment s√©par√©ment, combinant les r√©sultats obtenus de mani√®re plus d√©licate.  Dans notre cas, vous pouvez √©galement le diviser en plis, si vous supprimez 271 paires de 10 000, vous pouvez cr√©er une nouvelle s√©quence racine dans les autres, ce qui fournira √©videmment un r√©sultat diff√©rent mais comparable.  Vous pouvez simplement m√©langer et prendre les 11 autres initiaux, comme indiqu√© ci-dessus. <br><br>  L'article fournit un code et montre comment former U-net pour la segmentation d'images.  C'est un exemple concret, et dans l'article intentionnellement il n'y a pas de g√©n√©ralisations √† d'autres r√©seaux, √† d'autres s√©quences, il n'y a pas de math√©matiques rigoureuses, tout est racont√© et montr√© ¬´sur les doigts¬ª.  Juste un exemple de la fa√ßon dont vous pouvez apprendre le r√©seau tout en atteignant une pr√©cision acceptable. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr433946/">https://habr.com/ru/post/fr433946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr433934/index.html">SAFe ou Scaled Agile Framework</a></li>
<li><a href="../fr433936/index.html">Vous cherchez un cadeau high-tech pour un enfant? Pensez √† un terrain de jeu, pas √† un parc</a></li>
<li><a href="../fr433938/index.html">Comment Yandex et Google r√©sument l'ann√©e</a></li>
<li><a href="../fr433940/index.html">Combien co√ªte Review dans l'AppStore</a></li>
<li><a href="../fr433944/index.html">Des exceptions d√©vastatrices</a></li>
<li><a href="../fr433948/index.html">Comment rendre le paiement plus pratique: l'exp√©rience d'un fournisseur IaaS</a></li>
<li><a href="../fr433952/index.html">10 raisons de choisir une solution pour SAP HANA de HPE. 2e partie</a></li>
<li><a href="../fr433954/index.html">Huit technologies audio et gadgets audio qui entreront au Temple de la renomm√©e de TECnology en 2019</a></li>
<li><a href="../fr433956/index.html">Les modders ont utilis√© l'IA pour am√©liorer la texture dans les jeux</a></li>
<li><a href="../fr433958/index.html">Applications TDD sur Spring Boot: travailler avec une base de donn√©es</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
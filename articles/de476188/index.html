<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëãüèΩ ‚ô•Ô∏è üîÑ Ein neuronales Netzwerk zur Definition von Hassern - "Nein, nun, es ist ein Verbot" üë©üèº‚Äç‚öïÔ∏è üôåüèΩ ‚è∫Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo! 

 Sehen Sie oft giftige Kommentare in sozialen Netzwerken? Dies h√§ngt wahrscheinlich von den Inhalten ab, die Sie gerade ansehen. Ich schlage ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ein neuronales Netzwerk zur Definition von Hassern - "Nein, nun, es ist ein Verbot"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/476188/">  Hallo! <br><br>  Sehen Sie oft giftige Kommentare in sozialen Netzwerken?  Dies h√§ngt wahrscheinlich von den Inhalten ab, die Sie gerade ansehen.  Ich schlage vor, ein wenig mit diesem Thema zu experimentieren und das neuronale Netzwerk zu unterrichten, um die Kommentare der Hasser zu bestimmen. <br><br>  Unser globales Ziel ist es, festzustellen, ob ein Kommentar aggressiv ist, dh, es handelt sich um eine bin√§re Klassifikation.  Wir werden ein einfaches neuronales Netzwerk schreiben, es auf einen Datensatz von Kommentaren aus verschiedenen sozialen Netzwerken trainieren und dann eine einfache Analyse mit Visualisierung durchf√ºhren. <br><br>  F√ºr die Arbeit werde ich Google Colab verwenden.  Mit diesem Dienst k√∂nnen Sie Jupyter Notebooks ausf√ºhren und haben kostenlosen Zugriff auf die GPU (NVidia Tesla K80), wodurch das Lernen beschleunigt wird.  Ich ben√∂tige das Backend TensorFlow, die Standardversion in Colab 1.15.0, also aktualisiere einfach auf 2.0.0. <br><br>  Wir importieren das Modul und aktualisieren. <br><a name="habracut"></a><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf !tf_upgrade_v2 -h</code> </pre> <br>  Sie k√∂nnen die aktuelle Version so sehen. <br><br><pre> <code class="python hljs">print(tf.__version__)</code> </pre> <br>  Vorbereitende Arbeiten erledigt, wir importieren alle notwendigen Module. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># For DataFrame object import pandas as pd # Neural Network from keras.models import Sequential from keras.layers import Dense, Dropout from keras.optimizers import RMSprop # Text Vectorizing from keras.preprocessing.text import Tokenizer # Train-test-split from sklearn.model_selection import train_test_split # History visualization %matplotlib inline import matplotlib.pyplot as plt # Normalize from sklearn.preprocessing import normalize</span></span></code> </pre><br><h2>  Beschreibung der verwendeten Bibliotheken </h2><br><ul><li>  os - f√ºr die Arbeit mit dem Dateisystem </li></ul><br><ul><li>  numpy - f√ºr die Arbeit mit Arrays </li></ul><br><ul><li>  pandas - eine Bibliothek zur Analyse von Tabellendaten </li></ul><br><ul><li>  Keras - um ein Modell zu bauen </li></ul><br><ul><li>  keras.preprocessing.Text - zur Textverarbeitung, um es in numerischer Form zum Trainieren eines neuronalen Netzwerks einzureichen </li></ul><br><ul><li>  sklearn.train_test_split - um Testdaten vom Training zu trennen </li></ul><br><ul><li>  matplotlib - um den Lernprozess zu visualisieren </li></ul><br><ul><li>  sklearn.normalize - um Test- und Trainingsdaten zu normalisieren </li></ul><br><h2>  Analysieren von Daten mit Kaggle </h2><br>  Ich lade Daten direkt in den Colab-Laptop.  Au√üerdem extrahiere ich sie bereits ohne Probleme. <br><br><pre> <code class="python hljs">path = <span class="hljs-string"><span class="hljs-string">'labeled.csv'</span></span> df = pd.read_csv(path) df.head()</code> </pre> <br><img src="https://habrastorage.org/webt/7e/is/vk/7eisvkltuwv5hhe0ir5oopolmx4.png"><br><br>  Und das ist die √úberschrift unseres Datensatzes ... Ich f√ºhle mich auch irgendwie unwohl von "Seite aktualisieren, Idiot". <br>  Da unsere Daten in der Tabelle enthalten sind, werden wir sie in zwei Teile unterteilen: Daten f√ºr das Training und f√ºr das Testmodell.  Aber das ist alles Text, etwas muss getan werden. <br><br><h2>  Datenverarbeitung </h2><br>  Entfernen Sie die Zeilenumbr√ºche aus dem Text. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">delete_new_line_symbols</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text)</span></span></span><span class="hljs-function">:</span></span> text = text.replace(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text</code> </pre> <br><pre> <code class="python hljs">df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>].apply(delete_new_line_symbols) df.head()</code> </pre> <br>  Kommentare haben einen echten Datentyp, wir m√ºssen sie in eine ganze Zahl √ºbersetzen.  Speichern Sie es anschlie√üend in einer separaten Variablen. <br><br><pre> <code class="python hljs">target = np.array(df[<span class="hljs-string"><span class="hljs-string">'toxic'</span></span>].astype(<span class="hljs-string"><span class="hljs-string">'uint8'</span></span>)) target[:<span class="hljs-number"><span class="hljs-number">5</span></span>]</code> </pre> <br>  Jetzt werden wir den Text mit der Tokenizer-Klasse leicht verarbeiten.  Lassen Sie uns eine Kopie davon schreiben. <br><br><pre> <code class="python hljs">tokenizer = Tokenizer(num_words=<span class="hljs-number"><span class="hljs-number">30000</span></span>, filters=<span class="hljs-string"><span class="hljs-string">'!"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n'</span></span>, lower=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, split=<span class="hljs-string"><span class="hljs-string">' '</span></span>, char_level=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  <b>Schnell √ºber die Parameter</b> <br><br><ul><li>  num_words - Anzahl fester W√∂rter (am h√§ufigsten) </li></ul><br><ul><li>  Filter - eine Folge von Zeichen, die gel√∂scht werden sollen </li></ul><br><ul><li>  lower - ein boolescher Parameter, der steuert, ob der Text in Kleinbuchstaben geschrieben wird </li></ul><br><ul><li>  split - das Hauptsymbol zum Teilen eines Satzes </li></ul><br><ul><li>  char_level - Gibt an, ob ein einzelnes Zeichen als Wort betrachtet wird </li></ul><br>  Und jetzt werden wir den Text mit der Klasse verarbeiten. <br><br><pre> <code class="python hljs">tokenizer.fit_on_texts(df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>]) matrix = tokenizer.texts_to_matrix(df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>], mode=<span class="hljs-string"><span class="hljs-string">'count'</span></span>) matrix.shape</code> </pre> <br>  Wir haben 14.000 Beispielzeilen und 30.000 Feature-Spalten. <br><br><img src="https://habrastorage.org/webt/4z/iz/ji/4zizjiclkgiyu__wmblolopw3ri.png"><br><br>  Ich baue ein Modell aus zwei Schichten: Dicht und Ausfallend. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() model.add(Dense(<span class="hljs-number"><span class="hljs-number">32</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)) model.compile(optimizer=RMSprop(lr=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Wir normalisieren die Matrix und teilen die Daten wie vereinbart in zwei Teile auf (Training und Test). <br><br><pre> <code class="python hljs">X = normalize(matrix) y = target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) X_train.shape, y_train.shape</code> </pre> <br><h2>  Model Training </h2><br><pre> <code class="python hljs">model = get_model() history = model.fit(X_train, y_train, epochs=<span class="hljs-number"><span class="hljs-number">150</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">500</span></span>, validation_data=(X_test, y_test)) history</code> </pre> <br>  Ich werde den Lernprozess bei den letzten Iterationen zeigen. <br><br><img src="https://habrastorage.org/webt/n5/p8/ko/n5p8ko8tp68sz-tb3bgtrtmyhx4.png"><br><br><h2>  Visualisierung des Lernprozesses </h2><br><pre> <code class="python hljs">history = history.history fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) ax1 = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">221</span></span>) ax2 = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">223</span></span>) x = range(<span class="hljs-number"><span class="hljs-number">150</span></span>) ax1.plot(x, history[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>], <span class="hljs-string"><span class="hljs-string">'b-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Accuracy'</span></span>) ax1.plot(x, history[<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>], <span class="hljs-string"><span class="hljs-string">'r-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Validation accuracy'</span></span>) ax1.legend(loc=<span class="hljs-string"><span class="hljs-string">'lower right'</span></span>) ax2.plot(x, history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>], <span class="hljs-string"><span class="hljs-string">'b-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Losses'</span></span>) ax2.plot(x, history[<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>], <span class="hljs-string"><span class="hljs-string">'r-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Validation losses'</span></span>) ax2.legend(loc=<span class="hljs-string"><span class="hljs-string">'upper right'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/tg/1p/bn/tg1pbntyktgpmnckeeiqbizub9k.png"><br><br><img src="https://habrastorage.org/webt/j0/gh/lb/j0ghlbxyvtctsrvtrwrweuw0vwa.png"><br><br><h2>  Fazit </h2><br>  Das Modell kam um die 75. √Ñra heraus, und dann verh√§lt es sich schlecht.  Die Genauigkeit von 0,85 st√∂rt nicht.  Sie k√∂nnen Spa√ü mit der Anzahl der Ebenen und Hyperparameter haben und versuchen, das Ergebnis zu verbessern.  Es ist immer interessant und geh√∂rt zum Job.  Schreiben Sie √ºber Ihre Gedanken in Kommentare, wir werden sehen, wie viele H√ºte dieser Artikel gewinnen wird. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de476188/">https://habr.com/ru/post/de476188/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de476174/index.html">Die Zusammenstellung interessanter Materialien f√ºr den mobilen Entwickler # 322 (11. - 17. November)</a></li>
<li><a href="../de476178/index.html">Pers√∂nliche Erfahrung des Nichtbrennens bei der Fernarbeit</a></li>
<li><a href="../de476182/index.html">In Japan haben sie einen vierbeinigen Roboter entwickelt, der vertikale Treppen steigen kann</a></li>
<li><a href="../de476184/index.html">Analyse: Wie Forex tats√§chlich funktioniert und was Sie √ºber den Devisenhandel an der B√∂rse wissen m√ºssen, um Risiken zu minimieren</a></li>
<li><a href="../de476186/index.html">Hilfe f√ºr PKI Implementation Devs</a></li>
<li><a href="../de476192/index.html">Ein wichtiger Tweet zur Verl√§ngerung des Lebens</a></li>
<li><a href="../de476194/index.html">Habr Weekly # 27 / Chromebooks vs Macbooks, wie man coole Lebensl√§ufe schreibt, welches Gehalt man verlangen muss, AR-Punkte f√ºr $ 3500</a></li>
<li><a href="../de476198/index.html">Wie ich meine erste Website erstellt habe und was daraus wurde</a></li>
<li><a href="../de476206/index.html">Postgresql inkrementelle Backups mit pgbackrest - ein junger Kampfkurs vom Entwickler</a></li>
<li><a href="../de476208/index.html">Web Almanac 2019: Verf√ºgbarkeit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
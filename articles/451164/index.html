<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüè≠ üßúüèæ üôÄ Buscando espacio de estacionamiento gratuito con Python ‚ôÇÔ∏è ü§∞üèæ üëï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Yo vivo en una buena ciudad Pero, como en muchos otros, la b√∫squeda de un espacio de estacionamiento siempre se convierte en una prueba. Los espacios ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Buscando espacio de estacionamiento gratuito con Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451164/"><img src="https://habrastorage.org/webt/vz/x5/od/vzx5odyqel0ow-z2qolfdo1htd4.gif" alt="imagen"><br><br>  Yo vivo en una buena ciudad  Pero, como en muchos otros, la b√∫squeda de un espacio de estacionamiento siempre se convierte en una prueba.  Los espacios libres ocupan r√°pidamente, e incluso si tiene el suyo propio, ser√° dif√≠cil para los amigos llamarlo, ya que no tendr√°n d√≥nde estacionar. <br><br>  As√≠ que decid√≠ apuntar la c√°mara por la ventana y usar el aprendizaje profundo para que mi computadora me diga cu√°ndo hay espacio disponible: <br><br><img src="https://habrastorage.org/webt/lx/md/gy/lxmdgyxkvnwtwc5nsqccy83mp34.gif" alt="imagen"><br><br>  Puede sonar complicado, pero en realidad escribir un prototipo funcional con aprendizaje profundo es r√°pido y f√°cil.  Todos los componentes necesarios ya est√°n all√≠, solo necesita saber d√≥nde encontrarlos y c√≥mo armarlos. <br><br>  As√≠ que divirt√°monos y escribamos un sistema preciso de notificaci√≥n de estacionamiento gratuito usando Python y aprendizaje profundo <a name="habracut"></a><br><br><h3>  Descomponiendo la tarea </h3><br>  Cuando tenemos una tarea dif√≠cil que queremos resolver utilizando el aprendizaje autom√°tico, el primer paso es dividirla en una secuencia de tareas simples.  Entonces podemos usar varias herramientas para resolver cada una de ellas.  Al combinar varias soluciones simples juntas, obtenemos un sistema que es capaz de hacer algo complejo. <br><br>  As√≠ es como romp√≠ mi tarea: <br><br><img src="https://habrastorage.org/webt/q7/gi/hi/q7gihifth7-k9mad7fhgbj4itcc.jpeg" alt="imagen"><br><br>  La transmisi√≥n de video de la c√°mara web dirigida a la ventana ingresa a la entrada del transportador: <br><br><img src="https://habrastorage.org/webt/aa/wk/ig/aawkigsexhbk5s4slqmvksvofcm.gif" alt="imagen"><br><br>  A trav√©s de la tuber√≠a, transmitiremos cada cuadro del video, uno a la vez. <br><br>  El primer paso es reconocer todos los espacios de estacionamiento posibles en el marco.  Obviamente, antes de que podamos buscar lugares desocupados, necesitamos entender en qu√© partes de la imagen hay estacionamiento. <br><br>  Luego, en cada cuadro necesitas encontrar todos los autos.  Esto nos permitir√° rastrear el movimiento de cada m√°quina de cuadro a cuadro. <br><br>  El tercer paso es determinar qu√© lugares est√°n ocupados por m√°quinas y cu√°les no.  Para hacer esto, combine los resultados de los primeros dos pasos. <br><br>  Finalmente, el programa debe enviar una alerta cuando el espacio de estacionamiento se vuelva libre.  Esto estar√° determinado por los cambios en la ubicaci√≥n de las m√°quinas entre los cuadros del video. <br><br>  Cada uno de estos pasos se puede completar de diferentes maneras utilizando diferentes tecnolog√≠as.  No existe una √∫nica forma correcta o incorrecta de componer este transportador; los diferentes enfoques tendr√°n sus ventajas y desventajas.  Tratemos cada paso con m√°s detalle. <br><br><h3>  Reconocemos espacios de estacionamiento </h3><br>  Esto es lo que ve nuestra c√°mara: <br><br><img src="https://habrastorage.org/webt/2u/zl/xt/2uzlxtgxbn6jvfkhfy0e523ow88.png" alt="imagen"><br><br>  Necesitamos escanear de alguna manera esta imagen y obtener una lista de lugares para estacionar: <br><br><img src="https://habrastorage.org/webt/m-/bq/xb/m-bqxb9ybcjc44blvsuzhnw6xyk.png" alt="imagen"><br><br>  La soluci√≥n "en la frente" ser√≠a simplemente codificar las ubicaciones de todos los espacios de estacionamiento manualmente en lugar de reconocerlos autom√°ticamente.  Pero en este caso, si movemos la c√°mara o queremos buscar espacios de estacionamiento en otra calle, tendremos que hacer todo el procedimiento nuevamente.  Suena m√°s o menos, as√≠ que busquemos una forma autom√°tica de reconocer los espacios de estacionamiento. <br><br>  Alternativamente, puede buscar parqu√≠metros en la imagen y asumir que hay un espacio de estacionamiento al lado de cada uno de ellos: <br><br><img src="https://habrastorage.org/webt/qi/g8/cj/qig8cjwmp7dmduejcddjk6tnoiw.png" alt="imagen"><br><br>  Sin embargo, con este enfoque, no todo es tan sencillo.  En primer lugar, no todos los espacios de estacionamiento tienen un parqu√≠metro, y de hecho, estamos m√°s interesados ‚Äã‚Äãen encontrar espacios de estacionamiento por los que no tenga que pagar.  En segundo lugar, la ubicaci√≥n del parqu√≠metro no nos dice nada sobre d√≥nde est√° el espacio de estacionamiento, sino que solo nos permite hacer una suposici√≥n. <br><br>  Otra idea es crear un modelo de reconocimiento de objetos que busque marcas de espacio de estacionamiento dibujadas en la carretera: <br><br><img src="https://habrastorage.org/webt/bo/vv/nu/bovvnu6rsl-zimlr1gtpp1a_egm.png" alt="imagen"><br><br>  Pero este enfoque es regular.  En primer lugar, en mi ciudad, todas esas marcas son muy peque√±as y dif√≠ciles de ver a distancia, por lo que ser√° dif√≠cil detectarlas usando una computadora.  En segundo lugar, la calle est√° llena de todo tipo de otras l√≠neas y marcas.  Ser√° dif√≠cil separar las marcas de estacionamiento de los divisores de carriles y los cruces peatonales. <br><br>  Cuando encuentre un problema que a primera vista parece dif√≠cil, t√≥mese unos minutos para encontrar otro enfoque para resolver el problema, lo que ayudar√° a sortear algunos problemas t√©cnicos.  ¬øQu√© hay un espacio de estacionamiento?  Este es solo un lugar donde un autom√≥vil est√° estacionado durante mucho tiempo.  Quiz√°s no necesitamos reconocer espacios de estacionamiento en absoluto.  ¬øPor qu√© no solo reconocemos los autos que permanecen quietos durante mucho tiempo y no asumimos que est√°n parados en el estacionamiento? <br><br>  En otras palabras, los espacios de estacionamiento se encuentran donde los autom√≥viles permanecen de pie durante mucho tiempo: <br><br><img src="https://habrastorage.org/webt/b8/tb/ua/b8tbuafyf4uci3jy61jnjlwanqa.png" alt="imagen"><br><br>  Por lo tanto, si podemos reconocer los autos y descubrir cu√°les de ellos no se mueven entre cuadros, podemos adivinar d√≥nde est√°n los espacios de estacionamiento.  Tan simple como eso: ¬°vaya al reconocimiento de m√°quina! <br><br><h3>  Reconocer autos </h3><br>  Reconocer autos en un cuadro de video es una tarea cl√°sica de reconocimiento de objetos.  Hay muchos enfoques de aprendizaje autom√°tico que podr√≠amos utilizar para el reconocimiento.  Estos son algunos de ellos en orden de la "vieja escuela" a la "nueva escuela": <br><br><ul><li>  Puede entrenar el detector basado en HOG (histograma de gradientes orientados, histogramas de gradientes direccionales) y recorrerlo a trav√©s de la imagen completa para encontrar todos los autos.  Este viejo enfoque, que no utiliza el aprendizaje profundo, funciona relativamente r√°pido, pero no se adapta muy bien a las m√°quinas ubicadas de diferentes maneras. </li><li>  Puede entrenar el detector basado en CNN (Red neuronal convolucional, una red neuronal convolucional) y recorrer toda la imagen hasta encontrar todos los autom√≥viles.  Este enfoque funciona exactamente, pero no tan eficientemente, ya que necesitamos escanear la imagen varias veces usando CNN para encontrar todas las m√°quinas.  Y aunque podemos encontrar m√°quinas ubicadas de diferentes maneras, necesitamos muchos m√°s datos de entrenamiento que para un detector HOG. </li><li>  Puede utilizar un nuevo enfoque con aprendizaje profundo como Mask R-CNN, Faster R-CNN o YOLO, que combina la precisi√≥n de CNN y un conjunto de trucos t√©cnicos que aumentan enormemente la velocidad de reconocimiento.  Dichos modelos funcionar√°n relativamente r√°pido (en la GPU) si tenemos muchos datos para entrenar el modelo. </li></ul><br>  En el caso general, necesitamos la soluci√≥n m√°s simple, que funcionar√° como deber√≠a y requerir√° la menor cantidad de datos de entrenamiento.  No es necesario que sea el algoritmo m√°s nuevo y r√°pido.  Sin embargo, espec√≠ficamente en nuestro caso, Mask R-CNN es una opci√≥n razonable, a pesar del hecho de que es bastante nuevo y r√°pido. <br><br>  La arquitectura de la m√°scara R-CNN est√° dise√±ada de tal manera que reconoce objetos en toda la imagen, gasta recursos de manera efectiva y no utiliza el enfoque de ventana deslizante.  En otras palabras, funciona bastante r√°pido.  Con una GPU moderna, podremos reconocer objetos en video en alta resoluci√≥n a una velocidad de varios cuadros por segundo.  Para nuestro proyecto esto deber√≠a ser suficiente. <br><br>  Adem√°s, la m√°scara R-CNN proporciona mucha informaci√≥n sobre cada objeto reconocido.  La mayor√≠a de los algoritmos de reconocimiento devuelven solo un cuadro delimitador para cada objeto.  Sin embargo, la m√°scara R-CNN no solo nos dar√° la ubicaci√≥n de cada objeto, sino tambi√©n su contorno (m√°scara): <br><br><img src="https://habrastorage.org/webt/n2/b0/hp/n2b0hpwgwpkn6ahfhqetvbhq1rg.png" alt="imagen"><br><br>  Para entrenar a la m√°scara R-CNN, necesitamos muchas im√°genes de objetos que queremos reconocer.  Podr√≠amos salir, tomar fotograf√≠as de autom√≥viles y marcarlas en fotograf√≠as, lo que requerir√≠a varios d√≠as de trabajo.  Afortunadamente, los autom√≥viles son uno de esos objetos que las personas a menudo quieren reconocer, por lo que ya existen varios conjuntos de datos p√∫blicos con im√°genes de autom√≥viles. <br><br>  Uno de ellos es el popular <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conjunto de datos</a> SOCO (abreviatura de Common Objects In Context), que tiene im√°genes anotadas con m√°scaras de objetos.  Este conjunto de datos contiene m√°s de 12,000 im√°genes con m√°quinas ya etiquetadas.  Aqu√≠ hay una imagen de ejemplo del conjunto de datos: <br><br><img src="https://habrastorage.org/webt/dv/lz/7l/dvlz7ltgwmudog9-b2f6i7tlmhe.jpeg" alt="imagen"><br><br>  Dichos datos son excelentes para entrenar un modelo basado en la m√°scara R-CNN. <br><br>  Pero aguanta los caballos, ¬°hay noticias a√∫n mejores!  No somos los primeros que quisimos entrenar su modelo utilizando el conjunto de datos COCO; muchas personas ya lo han hecho antes que nosotros y han compartido sus resultados.  Por lo tanto, en lugar de entrenar a nuestro modelo, podemos tomar uno listo que ya reconozca los autos.  Para nuestro proyecto, utilizaremos el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelo de c√≥digo abierto de Matterport.</a> <br><br>  Si le damos una imagen de la c√°mara a la entrada de este modelo, esto es lo que ya tenemos "listo para usar": <br><br><img src="https://habrastorage.org/webt/vy/kq/50/vykq50pcxhyt_vkmfzmxk_fgl5g.png" alt="imagen"><br><br>  El modelo reconoci√≥ no solo autom√≥viles, sino tambi√©n objetos como sem√°foros y personas.  Es curioso que ella reconociera el √°rbol como una planta de interior. <br><br>  Para cada objeto reconocido, el modelo Mask R-CNN devuelve 4 cosas: <br><br><ul><li>  Tipo de objeto detectado (entero).  El modelo COCO pre-entrenado puede reconocer 80 objetos comunes diferentes como autom√≥viles y camiones.  Una lista completa de ellos se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠.</a> </li><li>  El grado de confianza en los resultados del reconocimiento.  Cuanto mayor sea el n√∫mero, m√°s fuerte ser√° el modelo conf√≠a en el reconocimiento del objeto. </li><li>  Un cuadro delimitador para un objeto en forma de coordenadas XY de p√≠xeles en la imagen. </li><li>  Una "m√°scara" que muestra qu√© p√≠xeles dentro del cuadro delimitador forman parte del objeto.  Usando los datos de la m√°scara, puede encontrar el contorno del objeto. </li></ul><br>  A continuaci√≥n se muestra el c√≥digo de Python para detectar el cuadro delimitador para m√°quinas que utilizan los modelos pre-entrenados Mask R-CNN y OpenCV: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-comment"><span class="hljs-comment"># ,     Mask-RCNN. class MaskRCNNConfig(mrcnn.config.Config): NAME = "coco_pretrained_model_config" IMAGES_PER_GPU = 1 GPU_COUNT = 1 NUM_CLASSES = 1 + 80 #   COCO  80  + 1  . DETECTION_MIN_CONFIDENCE = 0.6 #    ,    . def get_car_boxes(boxes, class_ids): car_boxes = [] for i, box in enumerate(boxes): #     ,   . if class_ids[i] in [3, 8, 6]: car_boxes.append(box) return np.array(car_boxes) #   . ROOT_DIR = Path(".") #       . MODEL_DIR = ROOT_DIR / "logs" #       . COCO_MODEL_PATH = ROOT_DIR / "mask_rcnn_coco.h5" #   COCO  . if not COCO_MODEL_PATH.exists(): mrcnn.utils.download_trained_weights(COCO_MODEL_PATH) #     . IMAGE_DIR = ROOT_DIR / "images" #      ‚Äî   0,    ,   . VIDEO_SOURCE = "test_images/parking.mp4" #   Mask-RCNN   . model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig()) #   . model.load_weights(COCO_MODEL_PATH, by_name=True) #   . parked_car_boxes = None #  ,     . video_capture = cv2.VideoCapture(VIDEO_SOURCE) #      . while video_capture.isOpened(): success, frame = video_capture.read() if not success: break #      BGR ( OpenCV)  RGB. rgb_image = frame[:, :, ::-1] #    Mask R-CNN   . results = model.detect([rgb_image], verbose=0) # Mask R-CNN ,       . #     ,     . r = results[0] #  r    : # - r['rois'] ‚Äî      ; # - r['class_ids'] ‚Äî  () ; # - r['scores'] ‚Äî  ; # - r['masks'] ‚Äî   (    ). #      . car_boxes = get_car_boxes(r['rois'], r['class_ids']) print("Cars found in frame of video:") #     . for box in car_boxes: print("Car:", box) y1, x1, y2, x2 = box #  . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1) #    . cv2.imshow('Video', frame) #  'q',  . if cv2.waitKey(1) &amp; 0xFF == ord('q'): break #    . video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre> <br>  Despu√©s de ejecutar este script, aparecer√° una imagen con un marco alrededor de cada m√°quina detectada en la pantalla: <br><br><img src="https://habrastorage.org/webt/_p/il/0r/_pil0reoz3gj7dtqboav_rgerl8.jpeg" alt="imagen"><br><br>  Adem√°s, las coordenadas de cada m√°quina se mostrar√°n en la consola: <br><br><pre> <code class="python hljs">Cars found <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> frame of video: Car: [<span class="hljs-number"><span class="hljs-number">492</span></span> <span class="hljs-number"><span class="hljs-number">871</span></span> <span class="hljs-number"><span class="hljs-number">551</span></span> <span class="hljs-number"><span class="hljs-number">961</span></span>] Car: [<span class="hljs-number"><span class="hljs-number">450</span></span> <span class="hljs-number"><span class="hljs-number">819</span></span> <span class="hljs-number"><span class="hljs-number">509</span></span> <span class="hljs-number"><span class="hljs-number">913</span></span>] Car: [<span class="hljs-number"><span class="hljs-number">411</span></span> <span class="hljs-number"><span class="hljs-number">774</span></span> <span class="hljs-number"><span class="hljs-number">470</span></span> <span class="hljs-number"><span class="hljs-number">856</span></span>]</code> </pre><br>  Entonces aprendimos a reconocer los autos en la imagen. <br><br><h3>  Reconocemos espacios de estacionamiento vac√≠os </h3><br>  Conocemos las coordenadas de p√≠xeles de cada m√°quina.  Mirando a trav√©s de varios cuadros consecutivos, podemos determinar f√°cilmente cu√°les de los autos no se movieron, y asumir que hay espacios de estacionamiento.  Pero, ¬øc√≥mo entender que el auto sali√≥ del estacionamiento? <br><br>  El problema es que los marcos de las m√°quinas se superponen parcialmente entre s√≠: <br><br><img src="https://habrastorage.org/webt/7t/vi/4q/7tvi4q1rgvkfkaljrsp8sjathr0.jpeg" alt="imagen"><br><br>  Por lo tanto, si imagina que cada marco representa un espacio de estacionamiento, puede resultar que est√© parcialmente ocupado por la m√°quina, cuando en realidad est√° vac√≠o.  Necesitamos encontrar una manera de medir el grado de intersecci√≥n de dos objetos para buscar solo los cuadros "m√°s vac√≠os". <br><br>  Usaremos una medida llamada Intersection Over Union (relaci√≥n del √°rea de intersecci√≥n con el √°rea total) o IoU.  IoU se puede encontrar calculando el n√∫mero de p√≠xeles donde se cruzan dos objetos y dividi√©ndolos por el n√∫mero de p√≠xeles ocupados por estos objetos: <br><br><img src="https://habrastorage.org/webt/zs/c0/sz/zsc0szsct8xjwkx5eo-6ieynfuc.png" alt="imagen"><br><br>  Entonces podemos entender c√≥mo el marco muy delimitado del autom√≥vil se cruza con el marco del espacio de estacionamiento.  Esto facilitar√° determinar si el estacionamiento es gratuito.  Si el valor de IoU es bajo, como 0.15, entonces el autom√≥vil ocupa una peque√±a parte del espacio de estacionamiento.  Y si es alto, como 0.6, entonces esto significa que el autom√≥vil ocupa la mayor parte del espacio y no se puede estacionar all√≠. <br><br>  Dado que IoU se usa con bastante frecuencia en la visi√≥n por computadora, es muy probable que las bibliotecas correspondientes implementen esta medida.  En nuestra biblioteca Mask R-CNN, se implementa como una funci√≥n mrcnn.utils.compute_overlaps (). <br><br>  Si tenemos una lista de cuadros delimitadores para espacios de estacionamiento, puede agregar un cheque por la presencia de autom√≥viles en este marco agregando una l√≠nea completa o dos de c√≥digo: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#      . car_boxes = get_car_boxes(r['rois'], r['class_ids']) # ,        . overlaps = mrcnn.utils.compute_overlaps(car_boxes, parking_areas) print(overlaps)</span></span></code> </pre><br>  El resultado deber√≠a verse as√≠: <br><br><pre> <code class="python hljs">[ [<span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-number"><span class="hljs-number">0.07040032</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] [<span class="hljs-number"><span class="hljs-number">0.07040032</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-number"><span class="hljs-number">0.07673165</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] [<span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.02332112</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] ]</code> </pre><br>  En esta matriz bidimensional, cada fila refleja un cuadro del espacio de estacionamiento.  Y cada columna indica qu√© tan fuertemente cada uno de los lugares se cruza con una de las m√°quinas detectadas.  Un resultado de 1.0 significa que todo el lugar est√° completamente ocupado por el autom√≥vil, y un valor bajo como 0.02 indica que el autom√≥vil se ha subido un poco al lugar, pero a√∫n puede estacionarse en √©l. <br><br>  Para encontrar lugares desocupados, solo necesita verificar cada fila en esta matriz.  Si todos los n√∫meros est√°n cerca de cero, ¬°lo m√°s probable es que el lugar sea libre! <br><br>  Sin embargo, tenga en cuenta que el reconocimiento de objetos no siempre funciona perfectamente con video en tiempo real.  Aunque el modelo basado en la m√°scara R-CNN es bastante preciso, de vez en cuando puede perder un autom√≥vil o dos en un cuadro del video.  Por lo tanto, antes de afirmar que el lugar es gratuito, debe asegurarse de que permanezca as√≠ durante los pr√≥ximos 5 a 10 cuadros siguientes del video.  De esta manera, podemos evitar situaciones en las que el sistema marca err√≥neamente un lugar vac√≠o debido a una falla en un cuadro del video.  ¬°Tan pronto como nos aseguremos de que el lugar permanezca libre durante varios fotogramas, puede enviar un mensaje! <br><br><h3>  Enviar SMS </h3><br>  La √∫ltima parte de nuestro transportador es enviar notificaciones por SMS cuando aparece un espacio de estacionamiento gratuito. <br><br>  Enviar un mensaje desde Python es muy f√°cil si usa Twilio.  Twilio es una API popular que le permite enviar SMS desde casi cualquier lenguaje de programaci√≥n con solo unas pocas l√≠neas de c√≥digo.  Por supuesto, si prefiere un servicio diferente, puede usarlo.  No tengo nada que ver con Twilio, es lo primero que me viene a la mente. <br><br>  Para usar Twilio, reg√≠strese para obtener una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cuenta de prueba</a> , cree un n√∫mero de tel√©fono de Twilio y obtenga la informaci√≥n de autenticaci√≥n de su cuenta.  Luego instale la biblioteca del cliente: <br><br><pre> <code class="python hljs">$ pip3 install twilio</code> </pre><br>  Despu√©s de eso, use el siguiente c√≥digo para enviar el mensaje: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> twilio.rest <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Client <span class="hljs-comment"><span class="hljs-comment">#   Twilio. twilio_account_sid = ' Twilio SID' twilio_auth_token = '   Twilio' twilio_source_phone_number = '   Twilio' #    Twilio. client = Client(twilio_account_sid, twilio_auth_token) #  SMS. message = client.messages.create( body=" ", from_=twilio_source_phone_number, to=" ,   " )</span></span></code> </pre><br>  Para agregar la capacidad de enviar mensajes a nuestro script, simplemente copie este c√≥digo all√≠.  Sin embargo, debe asegurarse de que el mensaje no se env√≠e en cada cuadro, donde el espacio libre es visible.  Por lo tanto, tendremos una bandera que en el estado instalado no permitir√° enviar mensajes por alg√∫n tiempo o hasta que se desocupe otro lugar. <br><br><h3>  Poniendo todo junto </h3><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> twilio.rest <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Client <span class="hljs-comment"><span class="hljs-comment"># ,     Mask-RCNN. class MaskRCNNConfig(mrcnn.config.Config): NAME = "coco_pretrained_model_config" IMAGES_PER_GPU = 1 GPU_COUNT = 1 NUM_CLASSES = 1 + 80 #   COCO  80  + 1  . DETECTION_MIN_CONFIDENCE = 0.6 #    ,    . def get_car_boxes(boxes, class_ids): car_boxes = [] for i, box in enumerate(boxes): #     ,   . if class_ids[i] in [3, 8, 6]: car_boxes.append(box) return np.array(car_boxes) #  Twilio. twilio_account_sid = ' Twilio SID' twilio_auth_token = '   Twilio' twilio_phone_number = '   Twilio' destination_phone_number = ',   ' client = Client(twilio_account_sid, twilio_auth_token) #   . ROOT_DIR = Path(".") #       . MODEL_DIR = ROOT_DIR / "logs" #       . COCO_MODEL_PATH = ROOT_DIR / "mask_rcnn_coco.h5" #   COCO  . if not COCO_MODEL_PATH.exists(): mrcnn.utils.download_trained_weights(COCO_MODEL_PATH) #     . IMAGE_DIR = ROOT_DIR / "images" #      ‚Äî   0,   ,   . VIDEO_SOURCE = "test_images/parking.mp4" #   Mask-RCNN   . model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig()) #   . model.load_weights(COCO_MODEL_PATH, by_name=True) #   . parked_car_boxes = None #  ,     . video_capture = cv2.VideoCapture(VIDEO_SOURCE) #         . free_space_frames = 0 #    SMS? sms_sent = False #      . while video_capture.isOpened(): success, frame = video_capture.read() if not success: break #      BGR  RGB. rgb_image = frame[:, :, ::-1] #    Mask R-CNN   . results = model.detect([rgb_image], verbose=0) # Mask R-CNN ,       . #     ,     . r = results[0] #  r    : # - r['rois'] ‚Äî      ; # - r['class_ids'] ‚Äî  () ; # - r['scores'] ‚Äî  ; # - r['masks'] ‚Äî   (    ). if parked_car_boxes is None: #     ‚Äî ,       . #            . parked_car_boxes = get_car_boxes(r['rois'], r['class_ids']) else: #   ,  . ,   . #     . car_boxes = get_car_boxes(r['rois'], r['class_ids']) # ,         . overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes) # ,    ,      . free_space = False #        . for parking_area, overlap_areas in zip(parked_car_boxes, overlaps): #        #    (, ). max_IoU_overlap = np.max(overlap_areas) #         . y1, x1, y2, x2 = parking_area # ,   ,   IoU. if max_IoU_overlap &lt; 0.15: #  !     . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3) # ,        . free_space = True else: #     ‚Äî   . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1) #   IoU  . font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, f"{max_IoU_overlap:0.2}", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255)) #       ,   . #   ,  ,     #      . if free_space: free_space_frames += 1 else: #   ,  . free_space_frames = 0 #       ,  ,   . if free_space_frames &gt; 10: #   SPACE AVAILABLE!!  . font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, f"SPACE AVAILABLE!", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED) #  ,     . if not sms_sent: print("SENDING SMS!!!") message = client.messages.create( body="Parking space open - go go go!", from_=twilio_phone_number, to=destination_phone_number ) sms_sent = True #    . cv2.imshow('Video', frame) #  'q',  . if cv2.waitKey(1) &amp; 0xFF == ord('q'): break #  'q',  . video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre><br>  Para ejecutar ese c√≥digo, primero debe instalar Python 3.6+, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Matterport Mask R-CNN</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenCV</a> . <br><br>  Espec√≠ficamente escrib√≠ el c√≥digo lo m√°s simple posible.  Por ejemplo, si ve un autom√≥vil en el primer cuadro, concluye que todos est√°n estacionados.  Intente experimentar con √©l y vea si puede mejorar su confiabilidad. <br><br>  Simplemente cambiando los identificadores de los objetos que est√° buscando el modelo, puede convertir el c√≥digo en algo completamente diferente.  Por ejemplo, imagine que est√° trabajando en una estaci√≥n de esqu√≠.  Despu√©s de hacer un par de cambios, puede convertir este script en un sistema que reconoce autom√°ticamente a los snowboarders que saltan desde una rampa y graba videos con saltos geniales.  O, si trabaja en una reserva natural, puede crear un sistema que cuente las cebras.  Est√°s limitado solo por tu imaginaci√≥n. <br><br>  Se pueden leer m√°s art√≠culos de este tipo en el canal de telegramas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Neuron</a> (@neurondata) <br><br>  Enlace de traducci√≥n alternativa: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tproger.ru/translations/parking-searching/</a> <br><br>  Todo conocimiento  Experimento! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/451164/">https://habr.com/ru/post/451164/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../451152/index.html">La resistencia en el circuito de la puerta o c√≥mo hacerlo bien</a></li>
<li><a href="../451154/index.html">Sistema local de adquisici√≥n de datos aut√≥nomos (continuaci√≥n)</a></li>
<li><a href="../451158/index.html">Circuitos electricos. Tipos de circuito</a></li>
<li><a href="../451160/index.html">Apache Kafka y Streaming con Spark Streaming</a></li>
<li><a href="../451162/index.html">Correcci√≥n de errores: constantes f√≠sicas en las versiones actuales y nuevas del sistema internacional de unidades (SI)</a></li>
<li><a href="../451166/index.html">¬øQu√© ofrecer√°n los nuevos repositorios para sistemas AI y MO?</a></li>
<li><a href="../451170/index.html">Jeff Bezos anunci√≥ planes para conquistar la luna</a></li>
<li><a href="../451172/index.html">Julia: funciones y estructuras como funciones</a></li>
<li><a href="../451174/index.html">Adaptaci√≥n de programas para ZX Spectrum a TR-DOS por medios modernos. Parte 1</a></li>
<li><a href="../451176/index.html">Noticias del mundo de OpenStreetMap No. 458 (23/04/2019 - 09/04/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
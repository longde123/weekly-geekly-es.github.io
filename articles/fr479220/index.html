<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐧 🏴 🐀 Nano-neurone - 7 fonctions JavaScript simples montrant comment la machine peut "apprendre" 🤾 🦌 📉</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Un nano-neurone est une version simplifiée d'un neurone du concept d'un réseau neuronal. Le nano-neurone effectue la tâche la plus simple et est formé...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nano-neurone - 7 fonctions JavaScript simples montrant comment la machine peut "apprendre"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479220/"><p>  <a href="https://github.com/trekhleb/nano-neuron" rel="nofollow"><strong>Un nano-neurone</strong></a> est une version <em>simplifiée</em> d'un neurone du concept d'un réseau neuronal.  Le nano-neurone effectue la tâche la plus simple et est formé pour convertir la température de degrés Celsius en degrés Fahrenheit. </p><br><p>  Le code <a href="" rel="nofollow"><strong>NanoNeuron.js se</strong></a> compose de 7 fonctions JavaScript simples impliquant l'apprentissage, la formation, la prévision et la propagation directe et en arrière du signal du modèle.  Le but de l'écriture de ces fonctions était de donner au lecteur une explication minimale (intuition) de la façon dont, après tout, une machine peut «apprendre».  Le code n'utilise pas de bibliothèques tierces.  Comme le dit le proverbe, seules les fonctions JavaScript "vanille" simples. </p><br><p>  Ces fonctions ne sont en <strong>aucun cas</strong> un guide exhaustif de l'apprentissage automatique.  De nombreux concepts d'apprentissage automatique sont manquants ou simplifiés!  Cette simplification est autorisée dans le seul but - donner au lecteur la compréhension et l'intuition les plus <strong>élémentaires de</strong> la façon dont une machine peut, en principe, "apprendre", de sorte que, par conséquent, "MAGIE de l'apprentissage automatique" sonne de plus en plus pour le lecteur comme "MATHÉMATIQUES de l'apprentissage automatique". </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/98d/6c4/69e/98d6c469e1facbf97154fe29f698cd12.png" alt="Nanoneuron"></p><a name="habracut"></a><br><h2 id="chto-vyuchit-nash-nano-neyron">  Ce que notre nano-neurone «apprendra» </h2><br><p>  Vous avez peut-être entendu parler des neurones dans le contexte des <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D1%2581%25D0%25BA%25D1%2583%25D1%2581%25D1%2581%25D1%2582%25D0%25B2%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C" rel="nofollow">réseaux</a> de <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D1%2581%25D0%25BA%25D1%2583%25D1%2581%25D1%2581%25D1%2582%25D0%25B2%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C" rel="nofollow">neurones</a> .  Un nano-neurone est une version simplifiée de ce même neurone.  Dans cet exemple, nous allons écrire son implémentation à partir de zéro.  Par souci de simplicité, nous ne construirons pas de réseau de nano-neurones.  Nous allons nous concentrer sur la création d'un seul nano-neurone et essayer de lui apprendre à convertir la température de degrés Celsius en degrés Fahrenheit.  En d'autres termes, nous lui apprendrons à <strong>prédire la</strong> température en degrés Fahrenheit en fonction de la température en degrés Celsius. </p><br><p>  À propos, la formule de conversion des degrés Celsius en degrés Fahrenheit est la suivante: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/9fa/2e8/8b5/9fa2e88b5a7324c8b9fc359b274ba091.png" alt="Celsius à fahrenheit"></p><br><p>  Mais pour le moment, notre nano-neurone ne sait rien de cette formule ... </p><br><h3 id="model-nano-neyrona">  Modèle de nano-neurone </h3><br><p> Commençons par créer une fonction qui décrit le modèle de notre nano-neurone.  Ce modèle est une simple relation linéaire entre <code>x</code> et <code>y</code> , qui ressemble à ceci: <code>y = w * x + b</code> .  Autrement dit, notre nano-neurone est un enfant qui peut tracer une ligne droite dans le système de coordonnées <code>XY</code> . </p><br><p>  Les variables <code>w</code> et <code>b</code> sont des <strong>paramètres de</strong> modèle.  Un nano-neurone ne connaît que ces deux paramètres d'une fonction linéaire.  Ces paramètres sont précisément ce que notre nano-neurone apprendra au cours du processus d'entraînement. </p><br><p>  La seule chose qu'un nano-neurone peut faire à ce stade est de simuler des relations linéaires.  Il le fait dans la méthode <code>predict()</code> , qui prend une variable <code>x</code> à l'entrée et prédit la variable <code>y</code> à la sortie.  Pas de magie. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">NanoNeuron</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">w, b</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.w = w; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.b = b; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.predict = <span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">x</span></span></span><span class="hljs-function">) =&gt;</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x * <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.w + <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.b; } }</code> </pre> <br><p>  _ (... attendez ... <a href="https://en.wikipedia.org/wiki/Linear_regression" rel="nofollow">la régression linéaire</a> c'est vous, ou quoi?) _ </p><br><h3 id="konvertaciya-gradusov-celsiya-v-gradusy-farengeyta">  Conversion degrés Celsius en degrés Fahrenheit </h3><br><p>  La température en degrés Celsius peut être convertie en degrés Fahrenheit selon la formule: <code>f = 1.8 * c + 32</code> , où <code>c</code> est la température en degrés Celsius et <code>f</code> est la température en degrés Fahrenheit. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">celsiusToFahrenheit</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">c</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> w = <span class="hljs-number"><span class="hljs-number">1.8</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> b = <span class="hljs-number"><span class="hljs-number">32</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> f = c * w + b; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> f; };</code> </pre> <br><p>  En conséquence, nous voulons que notre nano-neurone puisse simuler cette fonction particulière.  Il devra deviner (apprendre) que le paramètre <code>w = 1.8</code> et <code>b = 32</code> sans le savoir à l'avance. </p><br><p>  Voici à quoi ressemble la fonction de conversion sur le graphique.  C'est ce que notre «bébé» nano-neuronal doit apprendre à «dessiner»: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/68b/0d6/8bc/68b0d68bcc7be00ec9526867b2fcecf3.png" alt="Conversion de Celsius en Fahrenheit"></p><br><h3 id="generirovanie-dannyh">  Génération de données </h3><br><p>  En programmation classique, nous connaissons les données d'entrée ( <code>x</code> ) et l'algorithme de conversion de ces données (paramètres <code>w</code> et <code>b</code> ), mais les données de sortie ( <code>y</code> ) sont inconnues.  La sortie est calculée sur la base de l'entrée en utilisant un algorithme connu.  En apprentissage automatique, au contraire, seules les données d'entrée et de sortie ( <code>x</code> et <code>y</code> ) sont connues, mais l'algorithme de passage de <code>x</code> à <code>y</code> inconnu (paramètres <code>w</code> et <code>b</code> ). </p><br><p>  C'est la génération d'entrées et de sorties que nous allons maintenant faire.  Nous devons générer des données pour la <strong>formation de</strong> notre modèle et des données pour <strong>tester le</strong> modèle.  La fonction d'assistance <code>celsiusToFahrenheit()</code> nous y aidera.  Chacun des ensembles de données d'apprentissage et de test est un ensemble de paires <code>x</code> et <code>y</code> .  Par exemple, si <code>x = 2</code> , alors <code>y = 35,6</code> et ainsi de suite. </p><br><blockquote>  Dans le monde réel, la plupart des données sont susceptibles d'être <em>collectées</em> et non <em>générées</em> .  Par exemple, ces données collectées peuvent être un ensemble de paires de «photos de visage» -&gt; «nom de la personne». </blockquote><p>  Nous utiliserons l'ensemble de données TRAINING pour entraîner notre nano-neurone.  Avant qu'il ne grandisse et soit capable de prendre des décisions par lui-même, nous devons lui apprendre ce qui est «vrai» et ce qui est «faux» en utilisant des données «correctes» d'un ensemble d'entraînement. </p><br><blockquote>  Soit dit en passant, le principe de vie «ordures à l'entrée - ordures à la sortie» est clairement tracé.  Si un nano-neurone jette un "mensonge" dans le kit de formation que 5 ° C est converti en 1000 ° F, puis après de nombreuses itérations de formation, il le croira et convertira correctement toutes les valeurs de température <strong>sauf</strong> 5 ° C.  Nous devons être très prudents avec les données d'entraînement que nous chargeons quotidiennement dans notre réseau neuronal cérébral. </blockquote><p>  Distrait.  Continuons. </p><br><p>  Nous utiliserons l'ensemble de données TEST pour évaluer dans quelle mesure notre nano-neurone s'est entraîné et peut faire des prédictions correctes sur de nouvelles données qu'il n'a pas vues pendant sa formation. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generateDataSets</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// xTrain -&gt; [0, 1, 2, ...], // yTrain -&gt; [32, 33.8, 35.6, ...] const xTrain = []; const yTrain = []; for (let x = 0; x &lt; 100; x += 1) { const y = celsiusToFahrenheit(x); xTrain.push(x); yTrain.push(y); } // xTest -&gt; [0.5, 1.5, 2.5, ...] // yTest -&gt; [32.9, 34.7, 36.5, ...] const xTest = []; const yTest = []; //   0.5    1,       //   ,       . for (let x = 0.5; x &lt; 100; x += 1) { const y = celsiusToFahrenheit(x); xTest.push(x); yTest.push(y); } return [xTrain, yTrain, xTest, yTest]; }</span></span></code> </pre> <br><h3 id="ocenka-pogreshnosti-predskazaniy">  Estimation d'erreur de prédiction </h3><br><p>  Nous avons besoin d'une certaine métrique (mesure, nombre, évaluation) qui montrera à quel point la prédiction d'un nano-neurone est vraie.  En d'autres termes, ce nombre / métrique / fonction devrait montrer à quel point le nano neurone est correct ou non.  C'est comme à l'école, un élève peut obtenir une note de <code>5</code> ou <code>2</code> pour son contrôle. </p><br><p>  Dans le cas d'un nano-neurone, son erreur (erreur) entre la vraie valeur de <code>y</code> et la valeur prédite de <code>prediction</code> sera produite par la formule: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8d8/e50/ac1/8d8e50ac12d03614e65975f7b5d36931.png" alt="Coût de prédiction"></p><br><p>  Comme le montre la formule, nous considérerons l'erreur comme une simple différence entre les deux valeurs.  Plus les valeurs sont proches les unes des autres, plus la différence est faible.  Nous utilisons ici la quadrature pour se débarrasser du signe, de sorte qu'à la fin <code>(1 - 2) ^ 2</code> équivalent à <code>(2 - 1) ^ 2</code> .  La division par <code>2</code> se produit uniquement dans le but de simplifier la signification de la dérivée de cette fonction dans la formule de rétro-propagation d'un signal (voir ci-dessous). </p><br><p>  La fonction d'erreur dans ce cas ressemblera à ceci: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predictionCost</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">y, prediction</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (y - prediction) ** <span class="hljs-number"><span class="hljs-number">2</span></span> / <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 235.6 }</span></span></code> </pre> <br><h3 id="pryamoe-rasprostranenie-signala">  Propagation directe du signal </h3><br><p>  La propagation directe du signal à travers notre modèle signifie faire des prédictions pour toutes les paires à partir du jeu de données d'apprentissage <code>xTrain</code> et <code>yTrain</code> et calculer l'erreur moyenne (erreur) de ces prédictions. </p><br><p>  Nous laissons simplement notre nano-neurone «s'exprimer», lui permettant de faire des prédictions (convertir la température).  En même temps, un nano-neurone à ce stade peut être très mauvais.  La valeur moyenne de l'erreur de prédiction nous montrera à quel point notre modèle est / est proche de la vérité en ce moment.  La valeur d'erreur est ici très importante, car en modifiant à nouveau les paramètres <code>w</code> et <code>b</code> et en propageant à nouveau la propagation directe du signal, nous pouvons évaluer si notre nano-neurone est devenu «plus intelligent» avec de nouveaux paramètres ou non. </p><br><p>  L'erreur de prédiction moyenne d'un nano-neurone sera effectuée en utilisant la formule suivante: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/575/db3/e0a/575db3e0a0c872b29582147e41231344.png" alt="Coût moyen"></p><br><p>  Où <code>m</code> est le nombre de copies d'apprentissage (dans notre cas, nous avons <code>100</code> paires de données). </p><br><p>  Voici comment nous pouvons implémenter cela dans le code: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forwardPropagation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">model, xTrain, yTrain</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> m = xTrain.length; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> predictions = []; <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cost = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">let</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; m; i += <span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> prediction = nanoNeuron.predict(xTrain[i]); cost += predictionCost(yTrain[i], prediction); predictions.push(prediction); } <span class="hljs-comment"><span class="hljs-comment">//     . cost /= m; return [predictions, cost]; }</span></span></code> </pre> <br><h3 id="obratnoe-rasprostranenie-signala">  Propagation inverse du signal </h3><br><p>  Maintenant que nous savons comment notre nano-neurone a raison ou tort dans ses prédictions (basées sur la valeur moyenne de l'erreur), comment pouvons-nous rendre les prédictions plus précises? </p><br><p>  La propagation inverse du signal nous y aidera.  La propagation du signal de retour est le processus d'évaluation de l'erreur d'un nano-neurone, puis d'ajustement de ses paramètres <code>w</code> et <code>b</code> afin que les prochaines prédictions du nano-neurone pour l'ensemble des données d'apprentissage deviennent un peu plus précises. </p><br><p>  C'est là que l'apprentissage automatique devient comme de la magie.  Le concept clé ici est un <strong>dérivé de la fonction</strong> , qui montre quel pas de taille et quelle voie nous devons prendre afin d'approcher le minimum de la fonction (dans notre cas, le minimum de la fonction d'erreur). </p><br><p>  Le but ultime de la formation d'un nano-neurone est de trouver le minimum de la fonction d'erreur (voir fonction ci-dessus).  Si nous pouvons trouver de telles valeurs de <code>w</code> et <code>b</code> pour lesquelles la valeur moyenne de la fonction d'erreur est petite, cela signifiera que notre nano-neurone s'adapte bien aux prévisions de température en degrés Fahrenheit. </p><br><p>  Les dérivés sont un sujet important et distinct que nous ne traiterons pas dans cet article.  <a href="https://www.mathsisfun.com/calculus/derivatives-introduction.html" rel="nofollow">MathIsFun</a> est une excellente ressource qui peut fournir une compréhension de base des dérivés. </p><br><p>  Une chose que nous devons apprendre de l'essence de la dérivée et qui nous aidera à comprendre comment fonctionne la rétropropagation du signal est que la dérivée d'une fonction à un point spécifique <code>x</code> et <code>y</code> , par définition, est une tangente à la courbe de cette fonction à <code>x</code> et <code>y</code> et <em>nous indique la direction au minimum de la fonction</em> . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/66d/bfd/49a/66dbfd49aaf1ced48d7f6b5917fddb12.svg" alt="Pente dérivée"></p><br><p>  <em>Image prise à partir de <a href="https://www.mathsisfun.com/calculus/derivatives-introduction.html" rel="nofollow">MathIsFun</a></em> </p><br><p>  Par exemple, dans le graphique ci-dessus, vous voyez qu'au point <code>(x=2, y=4)</code> pente de la tangente nous montre que nous devons nous déplacer vers la <code></code> et <code></code> pour atteindre le minimum de la fonction.  Notez également que plus la pente de la tangente est grande, plus nous devons nous déplacer rapidement vers le point minimum. </p><br><p>  Les dérivées de notre fonction d'erreur moyenne <code>averageCost</code> par <code>averageCost</code> aux paramètres <code>w</code> et <code>b</code> ressembleront à ceci: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/4cc/bda/ba1/4ccbdaba120c399c1528e2bc38cf0efd.png" alt="dW"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/e02/0cb/125/e020cb125449849009a9f565a32ff46f.png" alt="dB"></p><br><p>  Où <code>m</code> est le nombre de copies d'apprentissage (dans notre cas, nous avons <code>100</code> paires de données). </p><br><p>  <em>Vous pouvez lire plus en détail sur la façon de prendre la dérivée de fonctions complexes <a href="https://www.mathsisfun.com/calculus/derivatives-rules.html" rel="nofollow">ici</a> .</em> </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">backwardPropagation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">predictions, xTrain, yTrain</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> m = xTrain.length; <span class="hljs-comment"><span class="hljs-comment">//           'w'  'b'. //      0. let dW = 0; let dB = 0; for (let i = 0; i &lt; m; i += 1) { dW += (yTrain[i] - predictions[i]) * xTrain[i]; dB += yTrain[i] - predictions[i]; } //    . dW /= m; dB /= m; return [dW, dB]; }</span></span></code> </pre> <br><h3 id="trenirovka-modeli">  Formation modèle </h3><br><p>  Nous savons maintenant comment estimer l'erreur / erreur des prédictions de notre modèle de nano-neurone pour toutes les données d'entraînement (propagation directe du signal).  Nous savons également ajuster les paramètres <code>w</code> et <code>b</code> modèle des nano-neurones (rétropropagation du signal) afin d'améliorer la précision des prédictions.  Le problème est que si nous effectuons une propagation avant et arrière du signal une seule fois, cela ne suffira pas pour que notre modèle identifie et apprenne les dépendances et les lois dans les données d'apprentissage.  Vous pouvez comparer cela à la visite d'une journée d'un élève à l'école.  Il / elle doit aller à l'école régulièrement, jour après jour, année après année, afin d'apprendre tout le matériel. </p><br><p>  Il faut donc <em>répéter</em> plusieurs fois la propagation avant et arrière du signal.  C'est <code>trainModel()</code> .  Elle est comme une «enseignante» pour le modèle de notre nano-neurone: </p><br><ul><li>  elle passera un certain temps ( <code>epochs</code> ) avec notre nano-neurone encore idiot, essayant de le former, </li><li>  elle utilisera des livres spéciaux (jeux de données <code>xTrain</code> et <code>yTrain</code> ) pour la formation, </li><li>  il encourage notre «étudiant» à étudier plus diligemment (plus rapidement) en utilisant le paramètre <code>alpha</code> , qui contrôle essentiellement la vitesse d'apprentissage. </li></ul><br><p>  Quelques mots sur le paramètre <code>alpha</code> .  Il s'agit simplement d'un coefficient (multiplicateur) pour les valeurs des variables <code>dW</code> et <code>dB</code> , que nous calculons lors de la <code>dW</code> du signal.  Ainsi, la dérivée nous a montré la direction vers le minimum de la fonction d'erreur (les signes des valeurs de <code>dW</code> et <code>dB</code> nous le disent).  La dérivée nous a également montré à quelle vitesse nous devons nous déplacer vers le minimum de la fonction (les valeurs absolues de <code>dW</code> et <code>dB</code> nous le disent).  Maintenant, nous devons multiplier la taille du pas par <code>alpha</code> afin d'ajuster la vitesse de notre approche au minimum (la taille totale du pas).  Parfois, si nous utilisons de grandes valeurs pour <code>alpha</code> , nous pouvons aller dans des étapes si grandes que nous pouvons simplement <em>dépasser le</em> minimum de la fonction, la sautant ainsi. </p><br><p>  Par analogie avec le «professeur», plus elle forcerait notre «nano-étudiant» à apprendre, plus vite il apprendrait, MAIS, si vous le forcez et exercez une pression très forte sur lui, alors notre «nano-étudiant» peut subir une dépression nerveuse et apathie complète et il n’apprendra rien du tout. </p><br><p>  Nous mettrons à jour les paramètres de notre modèle <code>w</code> et <code>b</code> comme suit: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c7b/db8/84f/c7bdb884f2a940d62332246cdbcb44bc.png" alt="w"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b57/622/0ab/b576220ab6515d44255ef56699077bab.png" alt="b"></p><br><p>  Et voici à quoi ressemble la formation elle-même: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trainModel</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">{model, epochs, alpha, xTrain, yTrain}</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//     -.  . const costHistory = []; //    ()  for (let epoch = 0; epoch &lt; epochs; epoch += 1) { //   . const [predictions, cost] = forwardPropagation(model, xTrain, yTrain); costHistory.push(cost); //   . const [dW, dB] = backwardPropagation(predictions, xTrain, yTrain); //    -,    . nanoNeuron.w += alpha * dW; nanoNeuron.b += alpha * dB; } return costHistory; }</span></span></code> </pre> <br><h3 id="soberem-vse-funkcii-vmeste">  Assembler toutes les fonctionnalités </h3><br><p>  Il est temps d'utiliser ensemble toutes les fonctions précédemment créées. </p><br><p>  Créez une instance du modèle de nano-neurone.  Pour le moment, le nano-neurone ne sait rien des paramètres <code>w</code> et <code>b</code> .  Définissons donc <code>w</code> et <code>b</code> au hasard. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> w = <span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.random(); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 0.9492 const b = Math.random(); // ie -&gt; 0.4570 const nanoNeuron = new NanoNeuron(w, b);</span></span></code> </pre> <br><p>  Nous générons des ensembles de données de formation et de test. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> [xTrain, yTrain, xTest, yTest] = generateDataSets();</code> </pre> <br><p>  Essayons maintenant de former notre modèle en utilisant de petites étapes ( <code>0.0005</code> ) pour <code>70000</code> époques.  Vous pouvez expérimenter ces paramètres, ils sont déterminés empiriquement. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> epochs = <span class="hljs-number"><span class="hljs-number">70000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> alpha = <span class="hljs-number"><span class="hljs-number">0.0005</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> trainingCostHistory = trainModel({<span class="hljs-attr"><span class="hljs-attr">model</span></span>: nanoNeuron, epochs, alpha, xTrain, yTrain});</code> </pre> <br><p>  Vérifions comment la valeur d'erreur de notre modèle a changé pendant la formation.  Nous nous attendons à ce que la valeur d'erreur après la formation soit nettement inférieure à celle avant la formation.  Cela signifierait que notre nano-neurone serait plus sage.  L'option inverse est également possible, lorsque après l'entraînement, l'erreur des prédictions n'a fait qu'augmenter (par exemple, les grandes valeurs de l'étape d'apprentissage <code>alpha</code> ). </p><br><pre> <code class="javascript hljs"><span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'  :'</span></span>, trainingCostHistory[<span class="hljs-number"><span class="hljs-number">0</span></span>]); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 4694.3335043 console.log('  :', trainingCostHistory[epochs - 1]); // ie -&gt; 0.0000024</span></span></code> </pre> <br><p>  Et voici comment la valeur de l'erreur de modèle a changé pendant la formation.  Sur l'axe des <code>x</code> trouvent les époques (en milliers).  Nous prévoyons que le graphique diminuera. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/191/860/d6f/191860d6f0cd8cf7d24127f04f779462.png" alt="Processus de formation"></p><br><p>  Voyons quels paramètres notre nano-neurone a «appris».  Nous nous attendons à ce que les paramètres <code>w</code> et <code>b</code> soient similaires aux paramètres du même nom de la fonction <code>celsiusToFahrenheit()</code> ( <code>w = 1.8</code> et <code>b = 32</code> ), car c'est son nano-neurone que j'ai essayé de simuler. </p><br><pre> <code class="javascript hljs"><span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">' -:'</span></span>, {<span class="hljs-attr"><span class="hljs-attr">w</span></span>: nanoNeuron.w, <span class="hljs-attr"><span class="hljs-attr">b</span></span>: nanoNeuron.b}); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; {w: 1.8, b: 31.99}</span></span></code> </pre> <br><p>  Comme vous pouvez le voir, le nano-neurone est très proche de la fonction <code>celsiusToFahrenheit()</code> . </p><br><p>  Voyons maintenant à quel point les prédictions de notre nano-neurone sont précises pour les données de test qu'il n'a pas vues pendant l'entraînement.  L'erreur de prédiction pour les données de test doit être proche de l'erreur de prédiction pour les données d'apprentissage.  Cela signifiera que le nano-neurone a appris les dépendances correctes et peut correctement extraire son expérience de données inconnues auparavant (c'est toute la valeur du modèle). </p><br><pre> <code class="javascript hljs">[testPredictions, testCost] = forwardPropagation(nanoNeuron, xTest, yTest); <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'   :'</span></span>, testCost); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 0.0000023</span></span></code> </pre> <br><p>  Maintenant, puisque notre «nano-bébé» était bien formé à «l'école» et sait maintenant convertir avec précision des degrés Celsius en degrés Fahrenheit même pour des données qu'il n'a pas vues, nous pouvons l'appeler assez «intelligent».  Maintenant, nous pouvons même lui demander des conseils sur la conversion de température, et c'était le but de toute la formation. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> tempInCelsius = <span class="hljs-number"><span class="hljs-number">70</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> customPrediction = nanoNeuron.predict(tempInCelsius); <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">`- "",  </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${tempInCelsius}</span></span></span><span class="hljs-string">°C   :`</span></span>, customPrediction); <span class="hljs-comment"><span class="hljs-comment">// -&gt; 158.0002 console.log('  :', celsiusToFahrenheit(tempInCelsius)); // -&gt; 158</span></span></code> </pre> <br><p>  Très proche!  Comme les gens, notre nano-neurone est bon, mais pas parfait :) </p><br><p>  Codage réussi! </p><br><h2 id="kak-zapustit-i-protestirovat-nano-neyron">  Comment exécuter et tester un nano-neurone </h2><br><p>  Vous pouvez cloner le référentiel et exécuter le nano neurone localement: </p><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/trekhleb/nano-neuron.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> nano-neuron</code> </pre> <br><pre> <code class="bash hljs">node ./NanoNeuron.js</code> </pre> <br><h2 id="upuschennye-koncepcii">  Concepts manqués </h2><br><p>  Les concepts d'apprentissage automatique suivants ont été omis ou simplifiés pour faciliter l'explication. </p><br><p>  <strong>Séparation des ensembles de données de formation et de test</strong> </p><br><p>  Habituellement, vous avez un ensemble de données volumineuses.  Selon le nombre d'exemplaires de cet ensemble, sa division en ensembles d'apprentissage et de test peut être effectuée dans la proportion de 70/30.  Les données de l'ensemble doivent être mélangées au hasard avant d'être divisées.  Si la quantité de données est importante (par exemple, des millions), la division en ensembles de test et de formation peut être effectuée dans des proportions proches de 90/10 ou 95/5. </p><br><p>  <strong>Puissance en ligne</strong> </p><br><p>  Habituellement, vous ne trouverez pas de cas où un seul neurone est utilisé.  La force réside dans le <a href="https://en.wikipedia.org/wiki/Neural_network" rel="nofollow">réseau de</a> ces neurones.  Un réseau de neurones peut apprendre des dépendances beaucoup plus complexes. </p><br><p>  Toujours dans l'exemple ci-dessus, notre nano-neurone peut ressembler davantage à une simple <a href="https://en.wikipedia.org/wiki/Linear_regression" rel="nofollow">régression linéaire</a> qu'à un réseau neuronal. </p><br><p>  <strong>Normalisation d'entrée</strong> </p><br><p>  Avant l'entraînement, il est d'usage de <a href="https://www.jeremyjordan.me/batch-normalization/" rel="nofollow">normaliser les données d'entrée</a> . </p><br><p>  <strong>Implémentation vectorielle</strong> </p><br><p>  Pour les réseaux de neurones, les calculs vectoriels (matriciels) sont beaucoup plus rapides que les calculs <code>for</code> boucles.  Habituellement, la propagation directe et inverse du signal est effectuée à l'aide d'opérations matricielles utilisant, par exemple, la <a href="https://numpy.org/" rel="nofollow">bibliothèque</a> Python <a href="https://numpy.org/" rel="nofollow">Numpy</a> . </p><br><p>  <strong>Fonction d'erreur minimale</strong> </p><br><p>  La fonction d'erreur que nous avons utilisée pour le nano neurone est très simplifiée.  Il doit contenir des <a href="https://stackoverflow.com/questions/32986123/why-the-cost-function-of-logistic-regression-has-a-logarithmic-expression/32998675" rel="nofollow">composants logarithmiques</a> .  Un changement dans la formule de la fonction d'erreur entraînera également un changement dans les formules de propagation avant et arrière du signal. </p><br><p>  <strong>Fonction d'activation</strong> </p><br><p>  Habituellement, la valeur de sortie du neurone passe par la fonction d'activation.  Pour l'activation, des fonctions telles que <a href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="nofollow">Sigmoid</a> , <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="nofollow">ReLU</a> et autres peuvent être utilisées. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr479220/">https://habr.com/ru/post/fr479220/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr479202/index.html">C ++ et méthodes numériques: intégration approximative de Newton-Cotes</a></li>
<li><a href="../fr479210/index.html">Qu'adviendra-t-il des achats dans les magasins en ligne étrangers à partir du 1er janvier 2020</a></li>
<li><a href="../fr479214/index.html">Une sélection d'événements gratuits à venir pour les développeurs à Moscou # 2</a></li>
<li><a href="../fr479216/index.html">Pandora DXL 3000 Second Wind ou comment j'ai vissé ma propre télémétrie</a></li>
<li><a href="../fr479218/index.html">Comment faire un bot qui transforme une photo en bande dessinée: instructions étape par étape pour les nuls</a></li>
<li><a href="../fr479222/index.html">Le condensé de matériaux intéressants pour le développeur mobile # 325 (du 2 au 8 décembre)</a></li>
<li><a href="../fr479226/index.html">Habr-analysis: ce que les utilisateurs commandent en cadeau à Habr</a></li>
<li><a href="../fr479230/index.html">Documentez votre API express avec des annotations fanfaronnades</a></li>
<li><a href="../fr479232/index.html">Développement d'applications MQ JMS sur Spring Boot</a></li>
<li><a href="../fr479234/index.html">Nouvelles du monde d'OpenStreetMap n ° 488 (19/11/2019 - 25/11/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
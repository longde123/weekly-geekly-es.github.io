<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíµ üóùÔ∏è ü•® Dicas e truques do Kubernetes: acelerando a inicializa√ß√£o de grandes bancos de dados üè¶ ü§¶üèæ üö¥üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Com este artigo, abrimos uma s√©rie de publica√ß√µes com instru√ß√µes pr√°ticas sobre como facilitar a vida para n√≥s (a opera√ß√£o) e desenvolvedores em v√°ria...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Dicas e truques do Kubernetes: acelerando a inicializa√ß√£o de grandes bancos de dados</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/417509/">  Com este artigo, abrimos uma s√©rie de publica√ß√µes com instru√ß√µes pr√°ticas sobre como facilitar a vida para n√≥s (a opera√ß√£o) e desenvolvedores em v√°rias situa√ß√µes que acontecem literalmente todos os dias.  Todos eles s√£o coletados da experi√™ncia real na solu√ß√£o de problemas dos clientes e melhoraram com o tempo, mas ainda n√£o reivindicam o ideal - considere-os mais como id√©ias e espa√ßos em branco. <br><br>  Come√ßarei com um "truque" na prepara√ß√£o de grandes despejos de banco de dados como MySQL e PostgreSQL para sua r√°pida implementa√ß√£o para diversas necessidades - antes de tudo, nas plataformas para desenvolvedores.  O contexto das opera√ß√µes descritas abaixo √© o nosso ambiente t√≠pico, que inclui um cluster Kubernetes em funcionamento e o uso do GitLab (e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dapp</a> ) para CI / CD.  Vamos l√°! <br><br><img src="https://habrastorage.org/webt/6j/2l/4z/6j2l4z7lqghreoy3nykvws5x2u0.jpeg"><a name="habracut"></a><br><br>  O principal problema do Kubernetes ao usar a ramifica√ß√£o de recursos s√£o os bancos de dados grandes, quando os desenvolvedores desejam testar / demonstrar suas altera√ß√µes em um banco de dados completo (ou quase completo) da produ√ß√£o.  Por exemplo: <br><br><ul><li>  H√° um aplicativo com um banco de dados no MySQL para 1 TB e 10 desenvolvedores que desenvolvem seus pr√≥prios recursos. </li><li>  Os desenvolvedores desejam loops de teste individuais e mais alguns loops espec√≠ficos para testes e / ou demos. </li><li>  Al√©m disso, √© necess√°rio restaurar o despejo noturno da base de produ√ß√£o em seu circuito de teste por um tempo sensato - para reproduzir o problema com o cliente ou bug. </li><li>  Por fim, √© poss√≠vel diminuir o tamanho do banco de dados em pelo menos 150 GB - n√£o muito, mas ainda economizando espa√ßo.  I.e.  ainda precisamos de alguma forma preparar o despejo. </li></ul><br>  <i><b>Nota</b> : Geralmente, fazemos backup dos bancos de dados MySQL usando o innobackupex da Percona, o que nos permite salvar todos os bancos de dados e usu√°rios ... - em resumo, tudo o que for necess√°rio.</i>  <i>Esse exemplo √© considerado mais adiante no artigo, embora, no caso geral, n√£o importe exatamente como voc√™ faz os backups.</i> <br><br>  Ent√£o, digamos que temos um backup do banco de dados.  O que fazer depois? <br><br><h2>  Etapa 1: preparando um novo banco de dados a partir do dump </h2><br>  Primeiro, criaremos no Kubernetes <i>Deployment</i> , que consistir√° em dois cont√™ineres init <i>(ou seja, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cont√™ineres especiais</a> que s√£o executados antes dos fornos de aplicativos e permitem executar a pr√©-configura√ß√£o)</i> e um recuperador. <br><br>  Mas onde coloc√°-lo?  Temos um banco de dados grande (1 TB) e queremos aumentar dez de suas inst√¢ncias - precisamos de um servidor com um disco grande (10+ TB).  Pedimos separadamente para esta tarefa e marcamos o n√≥ com este servidor com um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">r√≥tulo</a> especial <code>dedicated: non-prod-db</code> .  Ao mesmo tempo, usaremos a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><i>mancha</i></a> hom√¥nima, que o Kubernetes dir√° que apenas aplicativos que s√£o resistentes (com <i>toler√¢ncias</i> ) a ele podem rolar para esse n√≥, ou seja, traduzindo o Kubernetes para o idioma, <code>dedicated Equal non-prod-db</code> . <br><br>  Usando <code>nodeSelector</code> e <code>tolerations</code> selecione o n√≥ desejado (localizado em um servidor com um disco grande): <br><br><pre> <code class="plaintext hljs"> nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute"</code> </pre> <br>  ... e pegue a descri√ß√£o do conte√∫do deste n√≥. <br><br><h3>  Recipientes de inicializa√ß√£o: get-bindump </h3><br>  O primeiro cont√™iner init que chamaremos de <code>get-bindump</code> .  Ele monta <code>emptyDir</code> (em <code>/var/lib/mysql</code> ), onde o dump do banco de dados recebido do servidor de backup ser√° adicionado.  Para fazer isso, o cont√™iner possui tudo o que voc√™ precisa: chaves SSH, endere√ßos de servidor de backup.  Esta etapa no nosso caso leva cerca de 2 horas. <br><br>  A descri√ß√£o desse cont√™iner no <i>Deployment √© a</i> seguinte: <br><br><pre> <code class="plaintext hljs"> - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh</code> </pre> <br>  O script <code>get_bindump.sh</code> usado no cont√™iner: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/version.txt ]; then echo "Dump file already exists." exit 0 fi rm -rf /var/lib/mysql/* borg extract --stdout user@your.server.net:somedb-mysql::${lastdump} stdin | xbstream -x -C /var/lib/mysql/ echo $lastdump &gt; /dump/version.txt</span></span></code> </pre> <br><h3>  Containers de inicializa√ß√£o: prepare-bindump </h3><br>  Ap√≥s o download do backup, o segundo cont√™iner de inicializa√ß√£o √© iniciado - <code>prepare-bindump</code> .  Ele executa <code>innobackupex --apply-log</code> (j√° que os arquivos j√° est√£o dispon√≠veis em <code>/var/lib/mysql</code> - gra√ßas ao <code>emptyDir</code> de <code>get-bindump</code> ) e o servidor MySQL √© iniciado. <br><br>  √â nesse cont√™iner init que fazemos todas as convers√µes necess√°rias no banco de dados, preparando-o para o aplicativo selecionado: limpamos as tabelas para as quais √© permitido, alteramos acessos dentro do banco de dados etc.  Em seguida, desligamos o servidor MySQL e simplesmente arquivamos o arquivo <code>/var/lib/mysql</code> inteiro em um arquivo tar.gz.  Como resultado, o dump se encaixa em um arquivo de 100 GB, que j√° √© uma ordem de magnitude menor que o 1 TB original.  Esta etapa leva cerca de 5 horas. <br><br>  Descri√ß√£o do segundo cont√™iner init no <i>Deployment</i> : <br><br><pre> <code class="plaintext hljs"> - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf</code> </pre> <br>  O script <code>prepare_bindump.sh</code> usado nele se parece com isso: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/healthz ]; then echo "Dump file already exists." exit 0 fi innobackupex --apply-log /var/lib/mysql/ chown -R mysql:mysql /var/lib/mysql chown -R mysql:mysql /var/log/mysql echo "`date`: Starting mysql" /usr/sbin/mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --innodb-data-file-path=ibdata1:200M:autoextend --user=root --skip-grant-tables &amp; sleep 200 echo "`date`: Creating mysql root user" echo "update mysql.user set Password=PASSWORD('password') WHERE user='root';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where USER like '';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where user = 'root' and host NOT IN ('127.0.0.1', 'localhost');" | mysql -uroot -h 127.0.0.1 echo "FLUSH PRIVILEGES;" | mysql -uroot -h 127.0.0.1 echo "truncate somedb.somedb_table_one;" | mysql -uroot -h 127.0.0.1 -ppassword somedb /usr/bin/mysqladmin shutdown -uroot -ppassword cd /var/lib/mysql/ tar -czf /dump/mysql_bindump.tar.gz ./* touch /dump/healthz rm -rf /var/lib/mysql/*</span></span></code> </pre> <br><h3>  Sob </h3><br>  O acorde final √© o lan√ßamento da lareira principal, que ocorre ap√≥s a execu√ß√£o dos cont√™ineres init.  No pod, temos um nginx simples e, por meio do <code>emtpyDir</code> dump compactado e cortado de 100 GB √© <code>emtpyDir</code> .  A fun√ß√£o desse nginx √© fornecer esse despejo. <br><br>  Configura√ß√£o da lareira: <br><br><pre> <code class="plaintext hljs"> - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {}</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">√â assim que o Deployment se parece com seus initContainers ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- apiVersion: apps/v1beta1 kind: Deployment metadata: name: db-dumps spec: strategy: rollingUpdate: maxUnavailable: 0 revisionHistoryLimit: 2 template: metadata: labels: app: db-dumps spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: log mountPath: /var/log/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf containers: - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {} - name: log emptyDir: {} - name: id-rsa secret: defaultMode: 0600 secretName: somedb-id-rsa - name: nginx-config configMap: name: somedb-nginx-config - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: somedb-db-dump spec: clusterIP: None selector: app: db-dumps ports: - name: http port: 80</code> </pre> </div></div><br>  Notas adicionais: <br><br><ol><li>  No nosso caso, preparamos um novo despejo <b>toda noite</b> usando o trabalho agendado no GitLab.  I.e.  todas as noites, essa <i>implanta√ß√£o</i> √© <i>lan√ßada</i> automaticamente, o que gera um novo despejo e o prepara para distribui√ß√£o em todos os ambientes de desenvolvedor de teste. </li><li>  Por que tamb√©m estamos lan√ßando volume <code>/dump</code> nos cont√™ineres init (e no script h√° uma verifica√ß√£o da exist√™ncia de <code>/dump/version.txt</code> )?  Isso √© feito caso o servidor em que ele √© executado seja reiniciado.  Os cont√™ineres ser√£o reiniciados e, sem essa verifica√ß√£o, o dump come√ßar√° a baixar novamente.  Se j√° preparamos um dump uma vez, na pr√≥xima inicializa√ß√£o (no caso de uma reinicializa√ß√£o do servidor), o <code>/dump/version.txt</code> sinalizador <code>/dump/version.txt</code> informar√° sobre isso. </li><li>  Qual √© a imagem <code>db-dumps</code> ?  N√≥s o coletamos com o dapp e seu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><code>Dappfile</code></a> fica assim: <br><br><pre> <code class="plaintext hljs">dimg: "db-dumps" from: "ubuntu:16.04" docker: ENV: TERM: xterm ansible: beforeInstall: - name: "Install percona repositories" apt: deb: https://repo.percona.com/apt/percona-release_0.1-4.xenial_all.deb - name: "Add repository for borgbackup" apt_repository: repo="ppa:costamagnagianfranco/borgbackup" codename="xenial" update_cache=yes - name: "Add repository for mysql 5.6" apt_repository: repo: deb http://archive.ubuntu.com/ubuntu trusty universe state: present update_cache: yes - name: "Install packages" apt: name: "{{`{{ item }}`}}" state: present with_items: - openssh-client - mysql-server-5.6 - mysql-client-5.6 - borgbackup - percona-xtrabackup-24 setup: - name: "Add get_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/get_bindump.sh" | indent 8 }} dest: /get_bindump.sh mode: 0755 - name: "Add prepare_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/prepare_bindump.sh" | indent 8 }} dest: /prepare_bindump.sh mode: 0755</code> </pre> </li></ol><br><h2>  Etapa 2: iniciando o banco de dados em um ambiente de desenvolvedor </h2><br>  Ao lan√ßar o banco de dados MySQL no ambiente de teste do desenvolvedor, ele possui um bot√£o no GitLab que inicia a reimplanta√ß√£o <i>da Implanta√ß√£o no</i> MySQL com a estrat√©gia <code>RollingUpdate.maxUnavailable: 0</code> : <br><br><img src="https://habrastorage.org/webt/up/bv/j8/upbvj8ouflxbxyemaok3llra03a.png"><br><br><div class="spoiler">  <b class="spoiler_title">Como isso √© implementado?</b> <div class="spoiler_text">  No GitLab, quando voc√™ clica em <i>recarregar db</i> , a <i>implanta√ß√£o</i> com a seguinte especifica√ß√£o √© implantada: <br><br><pre> <code class="plaintext hljs">spec: strategy: rollingUpdate: maxUnavailable: 0</code> </pre> <br>  I.e.  pedimos ao Kubernetes para atualizar o <i>Deployment</i> (criar um novo abaixo) e garantir que pelo menos um abaixo esteja ativo.  Como ao criar uma nova lareira, ela possui cont√™ineres init enquanto eles est√£o trabalhando, a nova <b>n√£o</b> entra no status Em <i>execu√ß√£o</i> , o que significa que a antiga continua a funcionar.  E somente no momento em que o pr√≥prio MySQL foi iniciado (e a sonda de prontid√£o funcionou), o tr√°fego muda para ele e o antigo (com o banco de dados antigo) √© exclu√≠do. <br><br>  Detalhes sobre esse esquema podem ser encontrados nos seguintes materiais: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Executando uma atualiza√ß√£o sem</a> <i>interrup√ß√£o (documenta√ß√£o do Kubernetes)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Atualiza√ß√µes cont√≠nuas com implanta√ß√µes do Kubernetes</a> <i>(Ta-Ching Chen)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Estrat√©gias de implanta√ß√£o do Kubernetes</a> <i>(Container Solutions)</i> . </li></ul></div></div><br>  A abordagem escolhida nos permite esperar at√© que um novo dump seja baixado, descompactado e iniciado, e somente depois disso o antigo ser√° exclu√≠do do MySQL.  Assim, enquanto preparamos um novo dep√≥sito, estamos trabalhando silenciosamente com a base antiga. <br><br>  O cont√™iner init desta <i>implanta√ß√£o</i> usa o seguinte comando: <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$DUMP_URL</span></span></span><span class="hljs-string">"</span></span> | tar -C /var/lib/mysql/ -xvz</code> </pre> <br>  I.e.  baixamos o dump do banco de dados compactado que foi preparado na etapa 1, descompacte-o em <code>/var/lib/mysql</code> e, em seguida, inicia-se em <i>Deployment</i> , no qual o MySQL √© iniciado com os dados j√° preparados.  Tudo isso leva cerca de 2 horas. <br><br><div class="spoiler">  <b class="spoiler_title">E a implanta√ß√£o √© a seguinte ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">apiVersion: apps/v1beta1 kind: Deployment metadata: name: mysql spec: strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: service: mysql spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: getdump image: mysql-with-getdump command: ["/usr/local/bin/getdump.sh"] resources: limits: memory: "6000Mi" cpu: "1.5" requests: memory: "6000Mi" cpu: "1.5" volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: DUMP_URL value: "http://somedb-db-dump.infra-db.svc.cluster.local/mysql_bindump.tar.gz" containers: - name: mysql image: mysql:5.6 resources: limits: memory: "1024Mi" cpu: "1" requests: memory: "1024Mi" cpu: "1" lifecycle: preStop: exec: command: ["/etc/init.d/mysql", "stop"] ports: - containerPort: 3306 name: mysql protocol: TCP volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: MYSQL_ROOT_PASSWORD value: "password" volumes: - name: datadir emptyDir: {} - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: mysql spec: clusterIP: None selector: service: mysql ports: - name: mysql port: 3306 protocol: TCP --- apiVersion: v1 kind: ConfigMap metadata: name: somedb-debian-cnf data: debian.cnf: | [client] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock</code> </pre> </div></div><br><h2>  Sum√°rio </h2><br>  Acontece que sempre temos o <i>Deployment</i> , que √© lan√ßado todas as noites e faz o seguinte: <br><br><ul><li>  Obt√©m um novo despejo de banco de dados </li><li>  de alguma forma, ele o prepara para a opera√ß√£o correta em um ambiente de teste (por exemplo, trankeytit algumas tabelas, substitui dados reais do usu√°rio, torna os usu√°rios necess√°rios, etc.); </li><li>  fornece a cada desenvolvedor a oportunidade de lan√ßar um banco de dados preparado para seu namespace no <i>Deployment</i> pressionando um bot√£o no CI - gra√ßas ao <i>Servi√ßo</i> dispon√≠vel nele, o banco de dados estar√° dispon√≠vel no <code>mysql</code> (por exemplo, pode ser o nome do servi√ßo no namespace). </li></ul><br>  Para o exemplo que examinamos, a cria√ß√£o de um despejo a partir de uma r√©plica real leva cerca de 6 horas, a prepara√ß√£o de uma "imagem base" leva 7 horas e a atualiza√ß√£o do banco de dados no ambiente do desenvolvedor leva 2 horas.  Como as duas primeiras a√ß√µes s√£o executadas ‚Äúem segundo plano‚Äù e s√£o invis√≠veis para os desenvolvedores, na verdade, eles podem implantar uma vers√£o de produ√ß√£o do banco de dados (com um tamanho de 1 TB) <b>pelas mesmas 2 horas</b> . <br><br>  Perguntas, cr√≠ticas e corre√ß√µes ao esquema proposto e seus componentes s√£o bem-vindas nos coment√°rios! <br><br>  PS Obviamente, entendemos que, no caso do VMware e de algumas outras ferramentas, seria poss√≠vel criar um instant√¢neo de uma m√°quina virtual e lan√ßar um novo virusalka a partir de um instant√¢neo (que √© ainda mais r√°pido), mas essa op√ß√£o n√£o inclui a prepara√ß√£o da base, levando em considera√ß√£o o que ser√° o mesmo tempo ... Sem mencionar o fato de que nem todos t√™m a oportunidade ou o desejo de usar produtos comerciais. <br><br><h2>  PPS </h2><br>  Outro do ciclo de dicas e truques do K8s: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">P√°ginas de erro personalizadas no NGINX Ingress</a> "; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Transfer√™ncia de recursos trabalhando em um cluster para gerenciamento do Helm 2</a> ‚Äù; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sobre a aloca√ß√£o de n√≥s e a carga na aplica√ß√£o web</a> ‚Äù; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acesso a sites de desenvolvimento</a> ." </li></ul><br>  Leia tamb√©m em nosso blog: <br><br><ul><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Construa e instale aplicativos no Kubernetes usando dapp e GitLab CI</a> ‚Äù; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pratique com dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 1: Criando aplicativos simples</a> "; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pratique com dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 2. Implanta√ß√£o de imagens do Docker no Kubernetes usando Helm</a> "; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Orquestra√ß√£o de DBMS do CockroachDB no Kubernetes</a> ‚Äù; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nossa experi√™ncia com o Kubernetes em pequenos projetos</a> ‚Äù <i>(reportagem em v√≠deo, que inclui uma introdu√ß√£o ao dispositivo t√©cnico do Kubernetes);</i> </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Utilit√°rios √∫teis ao trabalhar com o Kubernetes</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt417509/">https://habr.com/ru/post/pt417509/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt417497/index.html">4 anos em Ci√™ncia de Dados no Schibsted Media Group</a></li>
<li><a href="../pt417501/index.html">Lifehacks fabricando placas de duas camadas (LUT)</a></li>
<li><a href="../pt417503/index.html">O que um desenvolvedor web deve se lembrar de fazer SEO-Feng Shui</a></li>
<li><a href="../pt417505/index.html">Intel lan√ßa patches para novas vulnerabilidades de firmware ME</a></li>
<li><a href="../pt417507/index.html">Truques para vincular e baixar arquivos Mach-O</a></li>
<li><a href="../pt417511/index.html">Intel adquire eASIC - desenvolvedor estrutural de ASIC</a></li>
<li><a href="../pt417513/index.html">An√°logos em Python e JavaScript. Parte dois</a></li>
<li><a href="../pt417515/index.html">O que aprendi criando 100 jogos em 5 anos</a></li>
<li><a href="../pt417517/index.html">P√°ginas da hist√≥ria da Intel. Photo Chronicle and Quiz</a></li>
<li><a href="../pt417521/index.html">Revise certificados SSL para revoga√ß√£o</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëã üëåüèø üóæ C√≥mo pasar de ESXi a KVM / LXD y no perder la cabeza ‚ôêÔ∏è üè∞ ü§õüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Durante mucho tiempo, la compa√±√≠a Maxnet Systems us√≥ la versi√≥n gratuita de VMware - ESXi, comenzando con la versi√≥n 5.0, como hipervisor. La versi√≥n ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo pasar de ESXi a KVM / LXD y no perder la cabeza</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/458922/">  Durante mucho tiempo, la compa√±√≠a Maxnet Systems us√≥ la versi√≥n gratuita de VMware - ESXi, comenzando con la versi√≥n 5.0, como hipervisor.  La versi√≥n paga de vSphere ahuyentaba el modelo de licencia, mientras que la versi√≥n gratuita ten√≠a una serie de inconvenientes que no estaban disponibles en la versi√≥n paga, pero pod√≠a soportarlos.  Pero cuando en las nuevas versiones de ESXi la nueva interfaz web se neg√≥ a funcionar con la anterior, y el monitoreo de los conjuntos RAID dej√≥ de mostrar signos de vida, la compa√±√≠a decidi√≥ buscar una soluci√≥n m√°s universal y abierta.  La compa√±√≠a ya ten√≠a una buena experiencia y una buena impresi√≥n de LXC - Contenedores Linux.  Por lo tanto, se hizo evidente que el hipervisor so√±ado ser√° h√≠brido y combinar√° KVM y LXD para diferentes cargas, una continuaci√≥n evolutiva de LXC.  Al buscar informaci√≥n sobre KVM, la empresa se enfrent√≥ a conceptos err√≥neos, rastrillos y pr√°cticas nocivas, pero las pruebas y el tiempo pusieron todo en su lugar. <br><br><img src="https://habrastorage.org/webt/s-/vc/6s/s-vc6shq5cfia5bjjcuhixbgukq.jpeg"><br><br>  Sobre c√≥mo lidiar con el cambio de ESXi a KVM y no conducir una rueda en un rastrillo, le dir√° a <strong>Lev Nikolaev</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">maniaco</a> ), administrador y desarrollador de sistemas altamente cargados, entrenador de tecnolog√≠a de la informaci√≥n.  Hablemos de la red, repositorios, contenedores, KVM, LXD, LXC, aprovisionamiento y m√°quinas virtuales convenientes. <br><a name="habracut"></a><br><h2>  Prologo </h2><br>  Identificaremos inmediatamente los pensamientos clave, y luego los analizaremos con m√°s detalle. <br><br>  <strong>Red.</strong>  Si bien las velocidades de sus interfaces no superan los 1 Gb / s, el puente es suficiente para usted.  Tan pronto como quieras exprimir m√°s, te limitar√°. <br><br>  <strong>Repositorio.</strong>  Crea un almacenamiento de red compartido.  Incluso si no est√° listo para usar 10 Gbit / s dentro de la red, incluso 1 Gbit / s le dar√° 125 MB / s de almacenamiento.  Para una serie de cargas, esto ser√° suficiente con un margen, y la migraci√≥n de m√°quinas virtuales ser√° una cuesti√≥n elemental. <br><br>  <strong>Contenedor o KVM?</strong>  Pros, contras, trampas.  ¬øQu√© tipos de cargas se colocan mejor en un contenedor y cu√°les se dejan mejor en un KVM? <br><br>  <strong>LXD o LXC</strong> .  Es LXD LXC?  U otra versi√≥n?  O un complemento?  ¬øDe qu√© se trata todo esto?  Disipemos los mitos y comprendamos las diferencias entre LXD y LXC. <br><br>  <strong>Aprovisionamiento conveniente</strong> .  ¬øQu√© es m√°s conveniente: tomar la misma imagen o instalar el sistema desde cero siempre?  ¬øC√≥mo hacerlo de forma r√°pida y precisa cada vez? <br><br>  <strong>Conveniente m√°quina virtual.</strong>  Habr√° historias de miedo sobre cargadores de arranque, particiones, LVM. <br><br>  <strong>Varios</strong>  Muchas preguntas peque√±as: ¬øc√≥mo arrastrar r√°pidamente una m√°quina virtual de ESXi a KVM, c√≥mo migrar bien, c√≥mo virtualizar discos correctamente? <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/HqsxBkxGxqg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  Motivo de la reubicaci√≥n </h2><br>  ¬øDe d√≥nde surgi√≥ la loca idea de pasar de ESXi a KVM / LXD?  ESXi es popular entre las peque√±as y medianas empresas.  Este es un hipervisor bueno y barato.  Pero hay matices. <br><br>  Comenzamos con la versi√≥n 5.0, convenientemente, ¬°todo funciona!  La pr√≥xima versi√≥n 5.5 es la misma. <br><br>  Desde la versi√≥n 6.0 ya es m√°s dif√≠cil.  En ESXi, la interfaz web no qued√≥ inmediatamente libre, solo a partir de la versi√≥n 6.5, antes de que se requiriera una utilidad para Windows.  Soportamos esto.  Quien ejecuta OS X compra Parallels e instala esta utilidad.  Este es un dolor bien conocido. <br><br>  Monitoreo peri√≥dicamente flasheado.  Era necesario reiniciar los servicios de administraci√≥n en la consola del servidor, luego CIM Heartbeat apareci√≥ nuevamente.  Soportamos, ya que no siempre se cay√≥. <br><br>  Versi√≥n ESXi 6.5: basura, desperdicios y atrocidades.  Horrible hipervisor.  Y aqu√≠ est√° el por qu√©. <br><br><ul><li>  <strong>Angular se cae con una excepci√≥n en la entrada a la interfaz web.</strong>  Tan pronto como ingrese su nombre de usuario y contrase√±a, ¬°inmediatamente una excepci√≥n! </li><li>  <strong>La capacidad de controlar de forma remota el estado de la matriz RAID no funciona,</strong> ya que es conveniente para nosotros.  Sol√≠a ‚Äã‚Äãser conveniente, pero en la versi√≥n 6.5, todo est√° mal. </li><li>  <strong>Soporte d√©bil para las tarjetas de red modernas de Intel</strong> .  Las tarjetas de red de Intel y ESXi causan dolor.  Hay un hilo de agon√≠a en el foro de soporte de ESXi sobre esto.  VMware e Intel no son amigos y las relaciones no mejorar√°n en el futuro cercano.  Lo triste es que incluso los clientes de soluciones pagas experimentan problemas. </li><li>  <strong>No hay migraci√≥n dentro de ESXi</strong> .  A menos que la migraci√≥n se considere una pausa, copie y comience el procedimiento.  Ponemos el auto en pausa, lo copiamos r√°pidamente y lo arrancamos en otro lugar.  Pero es imposible llamarlo migraci√≥n, todav√≠a hay uno simple. </li></ul><br>  Despu√©s de ver todo esto, se nos ocurri√≥ la loca idea de movernos con ESXi 6.5. <br><br><h2>  Lista de deseos </h2><br>  Para empezar, escribimos una lista de deseos para un futuro ideal al que vamos. <br><br>  <strong>Gesti√≥n desde debajo de SSH</strong> , y web y m√°s opcional.  La interfaz web es excelente, pero en un viaje de negocios desde un iPhone, entrar en la interfaz web de ESXi y hacer algo all√≠ es inconveniente y dif√≠cil.  Por lo tanto, la √∫nica forma de administrar todo es SSH, no habr√° otra. <br><br>  <strong>Virtualizaci√≥n de Windows.</strong>  A veces los clientes piden cosas extra√±as, y nuestra misi√≥n es ayudarlos. <br><br>  <strong>Siempre controladores nuevos y la capacidad de configurar una tarjeta de red</strong> .  Deseo adecuado, pero no realizado bajo ESXi puro. <br><br>  <strong>Migraci√≥n en vivo, no agrupamiento</strong> .  Queremos la capacidad de arrastrar m√°quinas de un hipervisor a otro sin sentir ning√∫n retraso, tiempo de inactividad o inconvenientes. <br><br>  La lista de deseos est√° lista, luego ha comenzado una b√∫squeda dif√≠cil. <br><br><h2>  Harina de elecci√≥n </h2><br>  El mercado gira en torno a KVM o LXC con diferentes salsas.  A veces parece que Kubernetes est√° en alg√∫n lugar arriba, donde todo est√° bien, el sol y el para√≠so, y en el nivel inferior hay Morlocks: KVM, Xen o algo as√≠ ... <br><br>  Por ejemplo, Proxmox VE es Debian, que fue extra√≠do por el n√∫cleo de Ubuntu.  Se ve raro, pero ¬ølo trae a producci√≥n? <br><br>  Nuestros vecinos abajo son Alt Linux.  Se les ocurri√≥ una soluci√≥n hermosa: crearon Proxmox VE como un paquete.  Simplemente ponen el paquete en un comando.  Esto es conveniente, pero no incluimos Alt Linux en producci√≥n, por lo que no nos conven√≠a. <br><br><h3>  Tomar KVM </h3><br>  Al final, elegimos KVM.  No lo tomaron, Xen, por ejemplo, debido a la comunidad: KVM tiene mucho m√°s.  Parec√≠a que siempre encontrar√≠amos la respuesta a nuestra pregunta.  M√°s tarde descubrimos que el tama√±o de una comunidad no afecta su calidad. <br><br>  Inicialmente, calculamos que tomar√≠amos una m√°quina Bare Metal, agregar√≠amos el Ubuntu con el que estamos trabajando y rodar√≠amos KVM / LXD desde arriba.  Contamos con la capacidad de ejecutar contenedores.  Ubuntu es un sistema bien conocido y no hay sorpresas en t√©rminos de resolver problemas de arranque / recuperaci√≥n para nosotros.  Sabemos d√≥nde patear si el hipervisor no se inicia.  Todo es claro y conveniente para nosotros. <br><br><h2>  Curso intensivo de KVM </h2><br>  Si eres del mundo de ESXi, encontrar√°s muchas cosas interesantes.  Aprende tres palabras: QEMU, KVM y libvirt. <br><br>  <strong>QEMU</strong> traduce los deseos de un SO virtualizado en los desaf√≠os de un proceso regular.  Funciona muy bien en casi todas partes, pero lentamente.  QEMU es un producto independiente que virtualiza muchos otros dispositivos. <br><br>  M√°s adelante en la escena viene un mont√≥n de <strong>QEMU-KVM</strong> .  Este es el m√≥dulo del kernel de Linux para QEMU.  La virtualizaci√≥n de todas las instrucciones es costosa, por lo que tenemos un m√≥dulo de kernel KVM que <strong>traduce solo unas pocas instrucciones</strong> .  Como resultado, esto es significativamente m√°s r√°pido, ya que solo se procesa un peque√±o porcentaje de las instrucciones del conjunto general.  Estos son todos los costos de virtualizaci√≥n. <br><br>  Si solo tiene QEMU, el inicio de la m√°quina virtual sin enlace se ve as√≠: <br><br><pre><code class="plaintext hljs">$ qemu &lt; &gt;</code> </pre> <br>  En los par√°metros que describe la red, bloquee los dispositivos.  Todo es maravilloso, pero inconveniente.  Por lo tanto hay libvirt. <br><br>  <strong>El objetivo de libvirt es ser una herramienta √∫nica para todos los hipervisores</strong> .  Puede funcionar con cualquier cosa: con KVM, con LXD.  Parece que solo queda aprender la sintaxis de libvirt, pero en realidad funciona peor que en teor√≠a. <br><br>  Estas tres palabras son todo lo que se necesita para generar la primera m√°quina virtual en KVM.  Pero de nuevo, hay matices ... <br><br>  Libvirt tiene una configuraci√≥n donde se almacenan m√°quinas virtuales y otras configuraciones.  Almacena la configuraci√≥n en archivos xml: elegantes, modernos y directamente de los a√±os 90.  Si lo desea, se pueden editar a mano, pero por qu√©, si hay comandos convenientes.  Tambi√©n es conveniente que los cambios en los archivos xml est√©n maravillosamente versionados.  Usamos <strong>etckeeper</strong> - versi√≥n del directorio, etc.  Ya es posible usar etckeeper y ya es hora. <br><br><h2>  Curso intensivo de LXC </h2><br>  Hay muchos conceptos err√≥neos sobre LXC y LXD. <br><br><blockquote>  LXC es la capacidad del n√∫cleo moderno de usar espacios de nombres, para pretender que no es en absoluto el n√∫cleo original. </blockquote><br>  Puede crear estos espacios de nombres tantos como desee para cada contenedor.  Formalmente, el n√∫cleo es uno, pero se comporta como muchos n√∫cleos id√©nticos.  LXC le permite ejecutar contenedores, pero solo proporciona herramientas b√°sicas. <br><br>  Canonical, que est√° detr√°s de Ubuntu y avanza agresivamente los contenedores, ha lanzado <strong>LXD, un an√°logo de libvirt</strong> .  Este es un enlace que facilita la ejecuci√≥n de contenedores, pero en su interior sigue siendo LXC. <br><br><blockquote>  LXD es un hipervisor de contenedor basado en LXC. </blockquote><br>  Enterprise reina en LXD.  LXD almacena la configuraci√≥n en su base de datos, en el directorio <code>/var/lib/lxd</code> .  All√≠, LXD lleva su configuraci√≥n a la configuraci√≥n en SQlite.  Copiarlo no tiene sentido, pero puede escribir los comandos que utiliz√≥ para crear la configuraci√≥n del contenedor. <br><br>  No hay descarga como tal, pero la mayor√≠a de los cambios son automatizados por equipos.  Este es un an√°logo del archivo Docker, solo con control manual. <br><br><h2>  Producci√≥n </h2><br>  A lo que nos enfrentamos cuando todos navegamos en funcionamiento. <br><br><h3>  Red </h3><br>  ¬°Cu√°nta basura y alboroto infernales en Internet sobre la red en KVM!  El 90% de los materiales dicen usar puente. <br><br><blockquote>  ¬°Deja de usar el puente! </blockquote><br>  ¬øQu√© le pasa a √©l?  √öltimamente, tengo la sensaci√≥n de que la locura est√° sucediendo con los contenedores: coloque Docker encima de Docker para que pueda ejecutar Docker en Docker mientras mira Docker.  La mayor√≠a no entiende lo que est√° haciendo el puente. <br><br>  Pone su controlador de red en <strong>modo promiscuo</strong> y recibe todo el tr√°fico porque no sabe cu√°l y cu√°l no.  Como resultado, todo el tr√°fico del puente pasa a trav√©s de una maravillosa y r√°pida pila Linux de red, y hay muchas copias.  Al final, todo es lento y malo.  Por lo tanto, no use bridge en producci√≥n. <br><br><h3>  SR-IOV </h3><br>  <strong>SR-IOV es la capacidad de virtualizar dentro de una tarjeta de red</strong> .  La tarjeta de red en s√≠ misma puede asignar parte de s√≠ misma para m√°quinas virtuales, lo que requiere cierto soporte de hardware.  Esto es lo que evitar√° la migraci√≥n.  Migrar una m√°quina virtual donde falta SR-IOV es doloroso. <br><br>  SR-IOV debe usarse donde todos los hipervisores lo admitan como parte de la migraci√≥n.  Si no, entonces macvtap es para ti. <br><br><h3>  macvtap </h3><br>  Esto es para aquellos cuya tarjeta de red no es compatible con SR-IOV.  Esta es la versi√≥n ligera del puente: se cuelgan diferentes direcciones MAC en una tarjeta de red, y <strong>se utiliza el filtrado de unidifusi√≥n</strong> : la tarjeta de red no acepta todo, pero estrictamente de acuerdo con la lista de direcciones MAC. <br><br>  Se pueden encontrar m√°s detalles sangrientos en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la</a> gran charla de Toshiaki Makita <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">, Virtual Switching Technologies y Linux Bridge</a> .  Est√° lleno de dolor y sufrimiento. <br><br><blockquote>  El 90% de los materiales sobre c√≥mo construir una red en KVM son in√∫tiles. </blockquote><br>  Si alguien dice que el puente es incre√≠ble, no hables m√°s con esa persona. <br><br>  Con macvtap, la <strong>CPU ahorra alrededor del 30%</strong> debido a menos copias.  Pero el modo promiscuo tiene sus propios matices.  No puede conectarse a la interfaz de red de la m√°quina invitada desde el propio hipervisor, desde el host.  Un informe de Toshiaki detalla esto.  Pero en resumen, no funcionar√°. <br><br>  Desde el propio hipervisor rara vez se pasa a SSH.  Es m√°s conveniente iniciar una consola all√≠, por ejemplo, una consola Win.  Es posible "ver" el tr√°fico en la interfaz: no puede conectarse a trav√©s de TCP, pero el tr√°fico en el hipervisor es visible. <br><br><blockquote>  Si sus velocidades son superiores a 1 Gigabit, elija macvtap. </blockquote><br>  A velocidades de interfaz de hasta 1 Gigabit por segundo, el puente tambi√©n se puede utilizar.  Pero si tiene una tarjeta de red de 10 Gb y desea deshacerse de ella de alguna manera, solo queda macvtap.  No hay otras opciones.  Excepto SR-IOV. <br><br><h3>  systemd-networkd </h3><br>  <strong>Esta es una excelente manera de almacenar la configuraci√≥n de red en el propio hipervisor</strong> .  En nuestro caso, esto es Ubuntu, pero para otros sistemas, systemd funciona. <br><br>  Sol√≠amos tener un archivo <code>/etc/network/interfaces</code> en el que todos guardamos.  Un archivo es inc√≥modo de editar cada vez: systemd-networkd le permite dividir la configuraci√≥n en una dispersi√≥n de archivos peque√±os.  Esto es conveniente porque funciona con cualquier sistema de versiones: se envi√≥ a Git y ver√° cu√°ndo y qu√© cambio sucedi√≥. <br><br>  Hay una falla que descubrieron nuestros networkers.  Cuando necesita agregar una nueva VLAN en el hipervisor, voy y configuro.  Luego digo: "systemctl restart systemd-networkd".  En este momento, todo est√° bien conmigo, pero si las sesiones de BGP de esta m√°quina se generan, se rompen.  Nuestros networkers no aprueban esto. <br><br>  Para el hipervisor, no pasa nada malo.  Systemd-networkd no es adecuado para usuarios fronterizos, servidores con BGP elevado y para hipervisores: excelente. <br><br>  Systemd-networkd est√° lejos de ser final y nunca se completar√°.  Pero esto es m√°s conveniente que editar un archivo enorme.  Una alternativa a systemd-networkd en Ubuntu 18.04 es Netplan.  Esta es una forma "genial" de configurar la red y pisar el rastrillo. <br><br><h3>  Dispositivo de red </h3><br>  Despu√©s de instalar KVM y LXD en el hipervisor, lo primero que ver√° son dos puentes.  Uno hizo KVM para s√≠ mismo, y el segundo, LXD. <br><br><blockquote>  LXD y KVM est√°n intentando desplegar su red. </blockquote><br>  Si todav√≠a necesita un puente, para m√°quinas de prueba o para jugar, elimine el puente, que est√° activado de forma predeterminada y cree el suyo, el que desee.  KVM o LXD lo hacen terriblemente: desliza dnsmasq y comienza el horror. <br><br><h3>  Almacenamiento </h3><br><blockquote>  No importa qu√© implementaciones te gusten: usa el almacenamiento compartido. </blockquote><br>  Por ejemplo, iSCSI para m√°quinas virtuales.  No podr√° deshacerse del "punto de falla", pero puede <strong>consolidar el almacenamiento en un punto</strong> .  Esto abre nuevas oportunidades interesantes. <br><br>  Para hacer esto, debe tener al menos 10 Gb / s de interfaces dentro del centro de datos.  Pero incluso si solo tiene 1 Gbit / s, no se preocupe.  Esto es aproximadamente 125 MB / s, bastante bueno para los hipervisores que no requieren una gran carga de disco. <br><br>  KVM puede migrar y arrastrar el almacenamiento.  Pero, por ejemplo, en el modo de carga de trabajo, transferir una m√°quina virtual a un par de terabytes es una molestia.  Para la migraci√≥n con un almacenamiento com√∫n, solo RAM es suficiente, que es elemental.  Esto <strong>reduce el tiempo de migraci√≥n</strong> . <br><br><h3>  Al final, ¬øLXD o KVM? </h3><br>  Inicialmente, asumimos que para todas las m√°quinas virtuales donde el n√∫cleo coincide con el sistema host, tomaremos LXD.  Y donde necesitamos tomar otro n√∫cleo: tomar KVM. <br><br>  En realidad, los planes no despegaron.  Para entender por qu√©, eche un vistazo m√°s de cerca a LXD. <br><br><h3>  Lxd </h3><br>  La ventaja principal es ahorrar memoria en el n√∫cleo.  El n√∫cleo es el mismo y cuando lanzamos nuevos contenedores el n√∫cleo es el mismo.  En esto, los pros terminaron y comenzaron los contras. <br><br>  <strong>El dispositivo de bloque con rootfs debe estar montado.</strong>  Es m√°s dif√≠cil de lo que parece. <br><br>  <strong>Realmente no hay migraci√≥n</strong> .  Lo es, y se basa en el maravilloso instrumento sombr√≠o que vieron nuestros compatriotas.  Estoy orgulloso de ellos, pero en casos simples criu no funciona. <br><br>  <strong>zabbix-agent se comporta de forma extra√±a en un contenedor</strong> .  Si lo ejecuta dentro del contenedor, ver√° una serie de datos del sistema host y no del contenedor.  Hasta ahora no se puede hacer nada. <br><br>  <strong>Al mirar la lista de procesos en el hipervisor, es imposible entender r√°pidamente de qu√© contenedor est√° creciendo un proceso en particular</strong> .  Lleva tiempo descubrir qu√© espacio de nombres hay, qu√© y d√≥nde.  Si la carga en alg√∫n lugar salt√≥ m√°s de lo habitual, r√°pidamente no lo entiendo.  Este es el principal problema: la limitaci√≥n en las capacidades de respuesta.  Se realiza una mini investigaci√≥n para cada caso. <br><br><blockquote>  La √∫nica ventaja de LXD es ahorrar memoria central y reducir la sobrecarga. </blockquote><br>  Pero Kernel Shared Memory en KVM ya ahorra memoria. <br><br>  Hasta ahora no veo ninguna raz√≥n para presentar una producci√≥n seria y LXD.  A pesar de los mejores esfuerzos de Canonical en esta √°rea, la producci√≥n de LXD trae m√°s problemas que soluciones.  En un futuro cercano, la situaci√≥n no cambiar√°. <br><br>  Pero, no se puede decir que LXD es malo.  Es bueno, pero en casos limitados, de lo que hablar√© m√°s adelante. <br><br><h3>  Criu </h3><br>  Criu es una utilidad sombr√≠a. <br><br>  Cree un contenedor vac√≠o, llegar√° con un cliente DHCP y le dir√°: "¬°Suspenda!"  Obtenga el error porque hay un cliente DHCP: ‚Äú¬°Horror, horror!  Abre el z√≥calo con el letrero "crudo", ¬°qu√© pesadilla! "  Peor en ninguna parte. <br><br><blockquote>  Impresiones de contenedores: sin migraci√≥n, Criu funciona en cualquier otro momento. </blockquote><br>  Me gusta la recomendaci√≥n del equipo de LXD sobre qu√© hacer con Criu para que no haya problemas: <br><br>  - ¬° <em>Toma una versi√≥n m√°s fresca del repositorio!</em> <br><br>  ¬øY de alguna manera puedo ponerlo desde el paquete para que no se ejecute en el repositorio? <br><br><h3>  Conclusiones </h3><br>  <strong>LXD es maravilloso si desea crear una infraestructura de CI / CD.</strong>  Tomamos LVM - Logical Volume Manager, tomamos una instant√°nea de √©l e iniciamos el contenedor en √©l.  ¬°Todo funciona muy bien!  En un segundo, se crea un nuevo contenedor limpio, que est√° configurado para probar y hacer rodar al chef; lo usamos activamente. <br><br>  <strong>LXD es d√©bil para una producci√≥n seria</strong> .  No podemos saber qu√© hacer con LXD en producci√≥n si no funciona bien. <br><br>  <strong>¬°Elija KVM y solo KVM!</strong> <br><br><h3>  La migracion </h3><br>  Dir√© esto brevemente.  Para nosotros, la migraci√≥n result√≥ ser un maravilloso mundo nuevo que nos gusta.  All√≠ todo es simple: hay un equipo para la migraci√≥n y dos opciones importantes: <br><br><pre> <code class="plaintext hljs">virsh migrate &lt;vm&gt; qemu+ssh://&lt;hypervisor&gt;/system --undefinesource -persistent</code> </pre> <br>  Si escribe "Migraci√≥n KVM" en Google y abre el primer material, ver√° un comando para la migraci√≥n, pero sin las dos √∫ltimas teclas.  No ver√° una menci√≥n de que son importantes: "¬°Simplemente ejecute este comando!"  Ejecute el comando, y realmente migra, pero ¬øc√≥mo? <br><br>  Importantes opciones de migraci√≥n. <br><br>  <strong>undefinesource: elimina la m√°quina virtual del hipervisor desde el que estamos migrando.</strong>  Si reinicia despu√©s de dicha migraci√≥n, el hipervisor que dej√≥ reiniciar√° esta m√°quina.  Te sorprender√°s, pero esto es normal. <br><br>  <strong>Sin el segundo par√°metro, persistente, el hipervisor al que se mud√≥ no considera en absoluto que se trate de una migraci√≥n permanente.</strong>  Despu√©s de reiniciar, el hipervisor no recordar√° nada. <br><br><pre> <code class="plaintext hljs">- virsh dominfo &lt;vm&gt; | grep persistent</code> </pre> <br>  Sin este par√°metro, la m√°quina virtual es c√≠rculos en el agua.  Si el primer par√°metro se especifica sin el segundo, adivine qu√© suceder√°. <br><br>  Hay muchos de esos momentos con KVM. <br><br><ul><li>  Red: siempre te hablan sobre bridge, ¬°es una pesadilla!  Usted lee y piensa: ¬øc√≥mo es eso? </li><li>  Migraci√≥n: tampoco dir√°n nada inteligible, hasta que te golpees la cabeza contra esta pared. </li></ul><br><h2>  Por donde empezar </h2><br>  Para empezar tarde, estoy hablando de otra cosa. <br><br><h3>  Aprovisionamiento: c√≥mo implementarlo </h3><br><blockquote>  Si est√° satisfecho con las opciones de instalaci√≥n est√°ndar, el mecanismo predeterminado es excelente. </blockquote><br>  Bajo ESXi, usamos virt-install.  Esta es una forma habitual de implementar una m√°quina virtual.  Es conveniente que cree un archivo preestablecido en el que describa la imagen de su Debian / Ubuntu.  Inicie una nueva m√°quina aliment√°ndola con un kit de distribuci√≥n ISO y un archivo preestablecido.  Entonces el auto rueda solo.  Te conectas a trav√©s de SSH, lo conectas a un chef, enrollas galletas, ¬°eso es todo, ap√∫rate a la producci√≥n! <br><br>  Pero si tienes suficiente virt-install, tengo malas noticias.  Esto significa que no ha llegado a la etapa en que desea hacer otra cosa.  Lo superamos y nos dimos cuenta de que virt-install no es suficiente.  Llegamos a una "imagen dorada", que clonamos y luego lanzamos m√°quinas virtuales. <br><br><h3>  ¬øY c√≥mo organizar una m√°quina virtual? </h3><br>  ¬øPor qu√© llegamos a esta imagen y por qu√© es importante el aprovisionamiento?  Debido a que todav√≠a hay una comprensi√≥n d√©bil en la comunidad de que hay grandes diferencias entre una m√°quina virtual y una m√°quina normal. <br><br>  <strong>Una m√°quina virtual no necesita un proceso de arranque complicado y un cargador de arranque inteligente</strong> .  Es mucho m√°s f√°cil conectar los discos de una m√°quina virtual a una m√°quina que tiene un conjunto completo de herramientas que en modo de recuperaci√≥n tratando de salir a alguna parte. <br><br>  <strong>Una m√°quina virtual necesita la simplicidad de un dispositivo</strong> .  ¬øPor qu√© necesito particiones en un disco virtual?  ¬øPor qu√© la gente toma un disco virtual y coloca particiones all√≠, no LVM? <br><br>  <strong>Una m√°quina virtual necesita la m√°xima extensibilidad</strong> .  Por lo general, las m√°quinas virtuales crecen.  Este es un proceso "genial": aumentar la partici√≥n en el MBR.  Lo borra, en ese momento se limpia el sudor de la frente y piensa: "¬°Simplemente no escriba ahora, simplemente no escriba!"  - Y recrear con los nuevos par√°metros. <br><br><h3>  LVM @ lilo </h3><br>  Como resultado, llegamos a LVM @ lilo.  Este es un gestor de arranque que le permite configurar desde un solo archivo.  Si para editar la configuraci√≥n de GRUB est√° editando un archivo especial que controla el motor de plantillas y crea el monstruoso boot.cfg, luego con Lilo, un archivo y nada m√°s. <br><br>  Partitionless LVM hace que el sistema sea perfecto y f√°cil.  El problema es que GRUB no puede vivir sin MBR o GPT y se est√° congelando.  Le decimos: "GRUB establecete aqu√≠", pero no puede, porque no hay particiones. <br><br>  LVM le permite expandirse r√°pidamente y hacer copias de seguridad.  Di√°logo est√°ndar: <br><br>  <em>- Chicos, ¬øc√≥mo hacen copias de seguridad virtuales?</em> <br><br>  <em>- ... tomamos un dispositivo de bloque y copiamos.</em> <br><br>  <em>- ¬øHas intentado desplegar de nuevo?</em> <br><br>  <em>- Bueno, no, ¬°todo funciona para nosotros!</em> <br><br>  Puede lamer un dispositivo de bloque en una m√°quina virtual en cualquier momento, pero si hay un sistema de archivos, cualquier registro requiere tres movimientos; este procedimiento no es at√≥mico. <br><br>  Si est√° haciendo una instant√°nea de la m√°quina virtual desde el interior, puede comunicarse con el sistema de archivos para que llegue al estado coherente deseado.  Pero esto no es adecuado para todo. <br><br><h2>  ¬øC√≥mo construir un contenedor? </h2><br>  Para comenzar y crear un contenedor, hay herramientas regulares de las plantillas.  LXD ofrece la plantilla Ubuntu 16.04 o 18.04.  Pero si eres un luchador avanzado y no quieres una plantilla regular, pero tus rootfs personalizados, que puedes personalizar para ti, surge la pregunta: ¬øc√≥mo crear un contenedor desde cero en LXD? <br><br><h3>  Contenedor desde cero </h3><br>  <strong>Preparando rootfs</strong> .  Debootstrap ayudar√° con esto: explicamos qu√© paquetes son necesarios, cu√°les no y los instalamos. <br><br>  <strong>Explique a LXD que queremos crear un contenedor a partir de rootfs espec√≠ficos</strong> .  Pero primero, cree un contenedor vac√≠o con un comando breve: <br><br><pre> <code class="plaintext hljs">curl --unix-socket /var/lib/lxd/unix.socket -X POST -d '{"name": "my-container", "source": {"type": "none"}}' lxd/1.0/containers</code> </pre> <br>  Incluso puede ser automatizado. <br><br>  Un lector atento dir√°: ¬ød√≥nde est√° rootfs my-container?  ¬øD√≥nde se indica en qu√© lugar?  ¬°Pero no dije que eso es todo! <br><br>  <strong>Montamos rootfs del contenedor</strong> donde vivir√°.  Luego indicamos que el contenedor rootfs vivir√° aqu√≠: <br><br><pre> <code class="plaintext hljs">lxc config set my-container raw.lxc "lxc.rootfs=/containers/my-container/rootfs"</code> </pre> <br>  De nuevo, esto est√° automatizado. <br><br><h3>  Vida del contenedor </h3><br>  <strong>El contenedor no tiene su propio n√∫cleo</strong> , por lo que cargarlo es m√°s f√°cil <strong>:</strong> systemd, init, y vol√≥. <br><br>  Si no utiliza herramientas regulares para trabajar con LVM, entonces, en la mayor√≠a de los casos, para iniciar el contenedor, deber√° montar el rootfs del contenedor en el hipervisor. <br><br>  A veces encuentro art√≠culos que aconsejan autofs.  No lo hagas.  Systemd tiene unidades de montaje autom√°tico que funcionan, pero autofs no.  Por lo tanto, las unidades systemd automount pueden y deben usarse, pero autofs no vale la pena. <br><br><h2>  Conclusiones </h2><br>  <strong>Nos gusta KVM con migraci√≥n</strong> .  Con LXD, todav√≠a no es el camino, aunque para probar y construir la infraestructura la usamos donde no hay carga de producci√≥n. <br><br>  <strong>Nos encanta el rendimiento de KVM</strong> .  Es m√°s familiar mirar hacia arriba, ver all√≠ un proceso que sea relevante para esta m√°quina virtual y comprender qui√©n y qu√© estamos haciendo.  Esto es mejor que usar un conjunto de utilidades extra√±as con contenedores para descubrir qu√© tipo de golpes bajo el agua hay. <br><br>  <strong>Estamos encantados con la migraci√≥n.</strong>  Esto se debe en gran parte al almacenamiento compartido.  Si migramos arrastrando discos, no ser√≠amos tan felices. <br><br><blockquote>  Si usted, como Leo, est√° listo para hablar sobre la superaci√≥n de las dificultades de operaci√≥n, integraci√≥n o soporte, entonces es el momento <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de enviar un informe</a> a la conferencia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DevOpsConf de</a> oto√±o.  Y nosotros en el comit√© del programa ayudaremos a preparar la misma presentaci√≥n inspiradora y √∫til que esta. <br><br>  No estamos esperando la fecha l√≠mite para la convocatoria de ponencias y ya hemos aceptado varios informes para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el programa de la</a> conferencia.  Suscr√≠base al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bolet√≠n</a> y al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">canal de telegramas</a> y mant√©ngase actualizado sobre las noticias sobre los preparativos para DevOpsConf 2019 y no se pierda nuevos art√≠culos y videos. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458922/">https://habr.com/ru/post/458922/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458912/index.html">Migrar a Zimbra con imapsync</a></li>
<li><a href="../458914/index.html">Qu√© (no) necesitas saber para crear juegos en Unity</a></li>
<li><a href="../458916/index.html">Debajo del cap√≥ de React. Escribimos nuestra implementaci√≥n desde cero</a></li>
<li><a href="../458918/index.html">Lo que puedes aprender del dise√±o de juegos hiper-casuales</a></li>
<li><a href="../458920/index.html">Conferencia para fan√°ticos de DevOps</a></li>
<li><a href="../458924/index.html">Los accidentes te ayudan a aprender</a></li>
<li><a href="../458926/index.html">La tragedia no viene sola</a></li>
<li><a href="../458928/index.html">XLNet vs BERT</a></li>
<li><a href="../458930/index.html">C√≥mo los estudiantes de Perm llegaron a la final del campeonato internacional de an√°lisis de datos de Data Mining Cup 2019</a></li>
<li><a href="../458932/index.html">Yota, o c√≥mo puedes averiguarlo todo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
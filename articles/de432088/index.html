<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤾🏿 👩🏽‍🔬 🎅 MySQL-Hochverfügbarkeit auf GitHub 🖕 😶 👩🏽‍💼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="GitHub verwendet MySQL als primäres Data Warehouse für alles, was nicht mit git tun hat. git ist die Verfügbarkeit von MySQL der Schlüssel zum normale...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>MySQL-Hochverfügbarkeit auf GitHub</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/432088/"><p> GitHub verwendet MySQL als primäres Data Warehouse für alles, was nicht mit <code>git</code> tun hat. <code>git</code> ist die Verfügbarkeit von MySQL der Schlüssel zum normalen Betrieb von GitHub.  Die Site selbst, die GitHub-API, das Authentifizierungssystem und viele andere Funktionen erfordern Zugriff auf Datenbanken.  Wir verwenden mehrere MySQL-Cluster, um verschiedene Dienste und Aufgaben zu erledigen.  Sie werden nach dem klassischen Schema konfiguriert, wobei ein Hauptknoten für die Aufzeichnung und seine Replikate verfügbar ist.  <em>Replikate</em> (andere Clusterknoten) reproduzieren asynchron Änderungen am Hauptknoten und bieten Lesezugriff. </p><br><p>  Die Verfügbarkeit von Host-Sites ist entscheidend.  Ohne den Hauptknoten unterstützt der Cluster keine Aufzeichnung, sodass Sie die erforderlichen Änderungen nicht speichern können.  Das Beheben von Transaktionen, das Registrieren von Problemen, das Erstellen neuer Benutzer, Repositorys, Überprüfungen und vieles mehr ist einfach unmöglich. </p><br><p>  Zur Unterstützung der Aufzeichnung ist ein entsprechender zugänglicher Knoten erforderlich - der Hauptknoten im Cluster.  Die Fähigkeit, einen solchen Knoten zu identifizieren oder zu <em>erkennen</em> , ist jedoch ebenso wichtig. </p><br><p>  Bei einem Ausfall des aktuellen Hauptknotens ist es wichtig, dass ein neuer Server sofort angezeigt wird, um ihn zu ersetzen, und dass alle Dienste schnell über diese Änderung informiert werden können.  Die gesamte Ausfallzeit besteht aus der Zeit, die benötigt wird, um einen Fehler zu erkennen, ein Failover durchzuführen und über einen neuen Hauptknoten zu benachrichtigen. </p><br><p><img src="https://habrastorage.org/webt/m8/ah/po/m8ahpo0jhrucgwj3kb5u7hn9edo.jpeg"></p><a name="habracut"></a><br><p>  Diese Veröffentlichung beschreibt eine Lösung zur Sicherstellung einer hohen Verfügbarkeit von MySQL in GitHub und zur Ermittlung des Hauptdienstes, mit der wir zuverlässig Vorgänge in mehreren Rechenzentren ausführen, die Funktionsfähigkeit aufrechterhalten können, wenn einige dieser Zentren nicht verfügbar sind, und im Ausfallfall minimale Ausfallzeiten gewährleisten können. </p><br><h3 id="celi-obespecheniya-vysokoy-dostupnosti">  Hochverfügbarkeitsziele </h3><br><p>  Die in diesem Artikel beschriebene Lösung ist eine neue, verbesserte Version früherer Hochverfügbarkeitslösungen (HA), die auf GitHub implementiert wurden.  Während wir wachsen, müssen wir die MySQL HA-Strategie anpassen, um sie zu ändern.  Wir bemühen uns, ähnliche Ansätze für MySQL und andere Dienste auf GitHub zu verfolgen. </p><br><p>  Um die richtige Lösung für Hochverfügbarkeit und Serviceerkennung zu finden, sollten Sie zunächst einige spezifische Fragen beantworten.  Hier ist eine Beispielliste von ihnen: </p><br><ul><li>  Welche maximale Ausfallzeit ist für Sie unkritisch? </li><li>  Wie zuverlässig sind Fehlererkennungswerkzeuge?  Sind Fehlalarme (vorzeitige Fehlerverarbeitung) für Sie kritisch? </li><li>  Wie zuverlässig ist das Failover-System?  Wo kann ein Fehler auftreten? </li><li>  Wie effektiv ist die Lösung in mehreren Rechenzentren?  Wie effektiv ist die Lösung in Netzwerken mit niedriger und hoher Latenz? </li><li>  Funktioniert die Lösung auch bei einem vollständigen Ausfall des Rechenzentrums (DPC) oder einer Netzwerkisolation weiter? </li><li>  Welcher Mechanismus (falls vorhanden) verhindert oder mildert die Folgen der Entstehung von zwei Hauptservern im Cluster, die unabhängig voneinander aufzeichnen? </li><li>  Ist Datenverlust für Sie kritisch?  Wenn ja, in welchem ​​Umfang? </li></ul><br><p>  Um dies zu demonstrieren, betrachten wir zunächst die vorherige Lösung und diskutieren, warum wir beschlossen haben, sie aufzugeben. </p><br><h3 id="otkaz-ot-ispolzovaniya-vip-i-dns-dlya-obnaruzheniya">  Verweigerung der Verwendung von VIP und DNS zur Ermittlung </h3><br><p>  Als Teil der vorherigen Lösung haben wir verwendet: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orchestrator</a> zur Fehlererkennung und zum Failover; </li><li>  VIP und DNS für die Hosterkennung. </li></ul><br><p>  In diesem Fall haben Clients einen Aufzeichnungsknoten anhand seines Namens entdeckt, z. B. <code>mysql-writer-1.github.net</code> .  Der Name wurde verwendet, um die virtuelle IP-Adresse (VIP) des Hauptknotens zu bestimmen. </p><br><p>  In einer normalen Situation mussten Kunden lediglich den Namen auflösen und eine Verbindung zur empfangenen IP-Adresse herstellen, auf die der Hauptknoten bereits gewartet hatte. </p><br><p>  Betrachten Sie die folgende Replikationstopologie, die drei verschiedene Rechenzentren umfasst: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8fa/e2e/4f3/8fae2e4f382f3060b5a14ed9d80a5f67.png" alt="Bild"></p><br><p>  Bei einem Ausfall des Hauptknotens muss seinem Platz ein neuer Server zugewiesen werden (einer der Replikate). </p><br><p>  <code>orchestrator</code> erkennt einen Fehler, wählt einen neuen Masterknoten aus und weist dann den Namen / VIP zu.  Clients kennen die Identität des Hauptknotens nicht, sondern nur den Namen, der jetzt auf den neuen Knoten verweisen soll.  Beachten Sie dies jedoch. </p><br><p>  VIP-Adressen werden gemeinsam genutzt, Datenbankserver selbst fordern sie an und besitzen sie.  Um einen VIP zu empfangen oder freizugeben, muss der Server eine ARP-Anfrage senden.  Der Server, dem der VIP gehört, muss ihn zuerst freigeben, bevor der neue Master auf diese Adresse zugreifen kann.  Dieser Ansatz führt zu einigen unerwünschten Konsequenzen: </p><br><ul><li>  Im normalen Modus kontaktiert das Failover-System zuerst den ausgefallenen Hauptknoten und fordert ihn auf, den VIP freizugeben, und wendet sich dann mit einer Anforderung zur VIP-Zuweisung an den neuen Hauptserver.  Was tun, wenn der erste Hauptknoten nicht verfügbar ist oder eine Anforderung zur Freigabe der VIP-Adresse ablehnt?  Angesichts der Tatsache, dass sich der Server derzeit in einem Ausfallzustand befindet, ist es unwahrscheinlich, dass er rechtzeitig oder überhaupt auf eine Anfrage antworten kann. <br><ol><li>  Infolgedessen kann es vorkommen, dass zwei Hosts ihre Rechte an demselben VIP geltend machen.  Abhängig vom kürzesten Netzwerkpfad können verschiedene Clients eine Verbindung zu jedem dieser Server herstellen. </li><li>  Der korrekte Betrieb in dieser Situation hängt von der Interaktion zweier unabhängiger Server ab, und eine solche Konfiguration ist unzuverlässig. </li></ol></li><li>  Selbst wenn der erste Hauptknoten auf Anfragen reagiert, verschwenden wir wertvolle Zeit: Der Wechsel zum neuen Hauptserver erfolgt nicht, während wir den alten kontaktieren. </li><li>  Darüber hinaus gibt es auch bei einer Neuzuweisung von VIPs keine Garantie dafür, dass vorhandene Clientverbindungen auf dem alten Server getrennt werden.  Auch hier laufen wir Gefahr, in einer Situation mit zwei unabhängigen Hauptknoten zu sein. </li></ul><br><p>  Hier und da in unserer Umgebung sind VIP-Adressen einem physischen Standort zugeordnet.  Sie sind einem Switch oder Router zugeordnet.  Daher können wir eine VIP-Adresse nur einem Server zuweisen, der sich in derselben Umgebung wie der ursprüngliche Host befindet.  Insbesondere können wir in einigen Fällen keinen VIP-Server in einem anderen Rechenzentrum zuweisen und müssen Änderungen am DNS vornehmen. </p><br><ul><li>  Das Verteilen von Änderungen an den DNS dauert länger.  Clients speichern DNS-Namen für einen vordefinierten Zeitraum.  Ein Failover mit mehreren Rechenzentren führt zu längeren Ausfallzeiten, da es länger dauert, bis alle Kunden Informationen über den neuen Hauptknoten erhalten. </li></ul><br><p>  Diese Einschränkungen reichten aus, um uns zu zwingen, nach einer neuen Lösung zu suchen, aber wir mussten auch Folgendes berücksichtigen: </p><br><ul><li>  Die Hauptknoten sendeten unabhängig Impulspakete über den <code>pt-heartbeat</code> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">um die Verzögerung und die Lastregelung</a> zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">messen</a> .  Der Dienst musste auf den neu ernannten Hauptknoten übertragen werden.  Wenn möglich, sollte es auf dem alten Server deaktiviert sein. </li><li>  In ähnlicher Weise steuerten die Hauptknoten unabhängig den Betrieb der <a href="">Pseudo-GTID</a> .  Es war notwendig, diesen Prozess auf dem neuen Hauptknoten zu starten und vorzugsweise auf dem alten zu stoppen. </li><li>  Der neue Masterknoten wurde beschreibbar.  Der alte Knoten (falls möglich) sollte <code>read_only</code> (schreibgeschützt) haben. </li></ul><br><p>  Diese zusätzlichen Schritte führten zu einer Erhöhung der Gesamtausfallzeit und fügten ihre eigenen Fehlerquellen hinzu. </p><br><p>  Die Lösung funktionierte und GitHub behandelte erfolgreich MySQL-Fehler im Hintergrund, aber wir wollten unseren Ansatz für HA wie folgt verbessern: </p><br><ul><li>  Gewährleistung der Unabhängigkeit von bestimmten Rechenzentren; </li><li>  Gewährleistung der Funktionsfähigkeit bei Ausfällen von Rechenzentren; </li><li>  Geben Sie unzuverlässige kollaborative Workflows auf </li><li>  Reduzierung der gesamten Ausfallzeiten; </li><li>  Führen Sie das Failover so weit wie möglich ohne Verlust durch. </li></ul><br><h3 id="ha-reshenie-github-orchestrator-consul-glb">  GitHub HA-Lösung: Orchestrator, Consul, GLB </h3><br><p>  Unsere neue Strategie beseitigt zusammen mit den damit verbundenen Verbesserungen die meisten der oben genannten Probleme oder mildert deren Folgen.  Unser derzeitiges HA-System besteht aus folgenden Elementen: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orchestrator</a> zur Fehlererkennung und zum Failover.  Wir verwenden das <a href="">Orchestrator / Raft-</a> Schema mit mehreren Rechenzentren, wie in der folgenden Abbildung gezeigt. </li><li>  Hashicorp- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Konsul</a> für Service Discovery; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GLB / HAProxy</a> als Proxy-Schicht zwischen Clients und Aufzeichnungsknoten.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Quellcode</a> für den GLB Director ist geöffnet. </li><li>  <code>anycast</code> Technologie für das Netzwerk-Routing. </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/762/fb4/7a0/762fb47a0de253cce045889faa945228.png" alt="Bild"></p><br><p>  Mit dem neuen Schema konnten Änderungen an VIP und DNS vollständig aufgegeben werden.  Wenn wir jetzt neue Komponenten einführen, können wir sie trennen und die Aufgabe vereinfachen.  Darüber hinaus hatten wir die Möglichkeit, zuverlässige und stabile Lösungen zu verwenden.  Eine detaillierte Analyse der neuen Lösung ist unten angegeben. </p><br><h3 id="normalnyy-potok">  Normaler Durchfluss </h3><br><p>  In einer normalen Situation stellen Anwendungen über GLB / HAProxy eine Verbindung zu Aufzeichnungsknoten her. </p><br><p>  Anwendungen erhalten nicht die Identität des Hauptservers.  Nach wie vor verwenden sie nur den Namen.  Der Hauptknoten für <code>cluster1</code> wäre beispielsweise <code>mysql-writer-1.github.net</code> .  In unserer aktuellen Konfiguration wird dieser Name jedoch in die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anycast-</a> IP-Adresse aufgelöst. </p><br><p>  Dank der <code>anycast</code> Technologie wird der Name überall in dieselbe IP-Adresse aufgelöst, der Datenverkehr wird jedoch je nach Standort des Clients unterschiedlich geleitet.  Insbesondere werden in jedem unserer Rechenzentren mehrere Instanzen von GLB, unserem hochverfügbaren Load Balancer, bereitgestellt.  Der <code>mysql-writer-1.github.net</code> auf <code>mysql-writer-1.github.net</code> immer an den GLB-Cluster des lokalen Rechenzentrums weitergeleitet.  Aus diesem Grund werden alle Clients von lokalen Proxys bedient. </p><br><p>  Wir führen GLB auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HAProxy aus</a> .  Unser HAProxy-Server bietet <em>Schreibpools</em> : einen für jeden MySQL-Cluster.  Außerdem hat jeder Pool nur einen Server (den Hauptknoten des Clusters).  Alle GLB / HAProxy-Instanzen in allen Rechenzentren haben dieselben Pools und alle verweisen auf dieselben Server in diesen Pools.  Wenn die Anwendung Daten auf <code>mysql-writer-1.github.net</code> in die Datenbank schreiben <code>mysql-writer-1.github.net</code> , spielt es keine Rolle, mit welchem ​​GLB-Server sie eine Verbindung herstellt.  In beiden Fällen wird eine Umleitung zum eigentlichen <code>cluster1</code> durchgeführt. </p><br><p>  Bei Anwendungen endet die Erkennung mit GLB, und eine erneute Erkennung ist nicht erforderlich.  Dieser GLB leitet den Verkehr an den richtigen Ort um. </p><br><p>  Woher erhält der GLB Informationen darüber, welche Server aufgelistet werden sollen?  Wie nehmen wir Änderungen am GLB vor? </p><br><h3 id="obnaruzhenie-cherez-consul">  Entdeckung durch Konsul </h3><br><p>  Der Consul-Dienst ist allgemein als Service Discovery-Lösung bekannt und übernimmt auch DNS-Funktionen.  In unserem Fall verwenden wir es jedoch als leicht zugängliche Speicherung von Schlüsselwerten (KV). </p><br><p>  Im KV-Repository in Consul zeichnen wir die Identität der Hauptclusterknoten auf.  Für jeden Cluster gibt es eine Reihe von KV-Datensätzen, die auf die Daten des entsprechenden Hauptknotens <code>fqdn</code> : seine <code>fqdn</code> , port, ipv4 und ipv6. </p><br><p>  Jeder GLB / HAProxy-Knoten startet eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Konsul-Vorlage</a> , einen Dienst, der Änderungen an den Konsul-Daten verfolgt (in unserem Fall Änderungen an den Daten der Hauptknoten).  Der <code>consul-template</code> erstellt eine Konfigurationsdatei und kann HAProxy beim Ändern von Einstellungen neu laden. </p><br><p>  Aus diesem Grund stehen jeder GLB / HAProxy-Instanz Informationen zum Ändern der Identität des Hauptknotens in Consul zur Verfügung.  Basierend auf diesen Informationen wird die Konfiguration der Instanzen durchgeführt. Die neuen Hauptknoten werden als einzige Entität im Cluster-Server-Pool angegeben.  Danach werden die Instanzen neu geladen, damit die Änderungen wirksam werden. </p><br><p>  Wir haben Consul-Instanzen in jedem Rechenzentrum bereitgestellt, und jede Instanz bietet hohe Verfügbarkeit.  Diese Instanzen sind jedoch unabhängig voneinander.  Sie replizieren nicht und tauschen keine Daten aus. </p><br><p>  Woher erhält Consul Informationen über Änderungen und wie werden diese zwischen Rechenzentren verteilt? </p><br><h3 id="orchestratorraft">  Orchestrator / Floß </h3><br><p>  Wir verwenden das <code>orchestrator/raft</code> Schema: <code>orchestrator</code> Knoten kommunizieren über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raft-</a> Konsens miteinander.  In jedem Rechenzentrum haben wir einen oder zwei <code>orchestrator</code> . </p><br><p>  <code>orchestrator</code> ist für die Erkennung von Fehlern, das MySQL-Failover und die Übertragung der geänderten Masterknotendaten an Consul verantwortlich.  Das Failover wird von einem einzelnen <code>orchestrator/raft</code> Host verwaltet, aber <em>Änderungen</em> , die besagen, dass der Cluster jetzt ein neuer Master ist, werden mithilfe des <code>raft</code> Mechanismus an alle <code>orchestrator</code> Knoten weitergegeben. </p><br><p>  Wenn die <code>orchestrator</code> Nachrichten über eine Änderung der Daten des Hauptknotens erhalten, kontaktiert jeder von ihnen seine eigene lokale Instanz von Consul und initiiert eine KV-Aufzeichnung.  Rechenzentren mit mehreren Instanzen von <code>orchestrator</code> erhalten mehrere (identische) Datensätze in Consul. </p><br><h3 id="obobschennoe-predstavlenie-vsego-potoka">  Verallgemeinerte Ansicht des gesamten Streams </h3><br><p>  Wenn der Masterknoten ausfällt: </p><br><ul><li>  <code>orchestrator</code> erkennen Fehler; </li><li>  <code>orchestrator/raft</code> Master initiiert die Wiederherstellung.  Ein neuer Masterknoten wird zugewiesen. </li><li>  Das <code>orchestrator/raft</code> Schema überträgt die Daten zum Wechsel des Hauptknotens an alle Knoten des <code>raft</code> Clusters. </li><li>  Jede Instanz von <code>orchestrator/raft</code> erhält eine Benachrichtigung über einen Knotenwechsel und schreibt die Identität des neuen Masterknotens in den lokalen KV-Speicher in Consul. </li><li>  Auf jeder GLB / HAProxy-Instanz wird der <code>consul-template</code> Dienst gestartet, der Änderungen im KV-Repository in Consul überwacht, HAProxy neu konfiguriert und neu startet. </li><li>  Der Clientverkehr wird auf den neuen Masterknoten umgeleitet. </li></ul><br><p>  Für jede Komponente sind die Verantwortlichkeiten klar verteilt und die gesamte Struktur ist diversifiziert und vereinfacht.  <code>orchestrator</code> interagiert nicht mit Load Balancern.  Der Konsul benötigt keine Informationen über die Herkunft der Informationen.  Proxyserver funktionieren nur mit Consul.  Clients arbeiten nur mit Proxyservern. </p><br><p>  Außerdem: </p><br><ul><li>  Es ist nicht erforderlich, Änderungen am DNS vorzunehmen und Informationen darüber zu verbreiten. </li><li>  TTL wird nicht verwendet; </li><li>  Der Thread wartet nicht auf Antworten vom Host in einem Fehlerzustand.  Im Allgemeinen wird es ignoriert. </li></ul><br><h3 id="dopolnitelnaya-informaciya">  Weitere Informationen </h3><br><p>  Um den Fluss zu stabilisieren, wenden wir auch die folgenden Methoden an: </p><br><ul><li>  Der HAProxy- <code>hard-stop-after</code> Parameter ist auf einen sehr kleinen Wert eingestellt.  Wenn HAProxy mit dem neuen Server im Schreibpool neu gestartet wird, beendet der Server automatisch alle vorhandenen Verbindungen zum alten Masterknoten. <br><ol><li>  Durch Festlegen des <code>hard-stop-after</code> Parameters können Sie nicht auf Aktionen von Clients warten. Außerdem werden die negativen Folgen des möglichen Auftretens von zwei Hauptknoten im Cluster minimiert.  Es ist wichtig zu verstehen, dass es hier keine Magie gibt, und auf jeden Fall vergeht <em>einige Zeit,</em> bis die alten Bindungen gebrochen sind.  Aber es gibt einen Zeitpunkt, nach dem wir aufhören können, auf unangenehme Überraschungen zu warten. </li></ol></li><li>  Wir benötigen keine ständige Verfügbarkeit des Konsulendienstes.  Tatsächlich muss es nur während des Failovers verfügbar sein.  Wenn der Konsulendienst nicht reagiert, arbeitet GLB weiterhin mit den neuesten bekannten Werten und ergreift keine drastischen Maßnahmen. </li><li>  Der GLB ist so konfiguriert, dass die Identität des neu zugewiesenen Masterknotens überprüft wird.  Wie bei unseren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kontextsensitiven MySQL-Pools</a> wird eine Überprüfung durchgeführt, um zu bestätigen, dass der Server tatsächlich beschreibbar ist.  Wenn wir versehentlich die Identität des Hauptknotens in Consul löschen, gibt es keine Probleme, ein leerer Datensatz wird ignoriert.  Wenn wir versehentlich den Namen eines anderen Servers (nicht des Hauptservers) an Consul schreiben, ist dies in diesem Fall in Ordnung: GLB aktualisiert ihn nicht und arbeitet weiterhin mit dem letzten gültigen Status. </li></ul><br><p>  In den folgenden Abschnitten werden Probleme untersucht und die Ziele der Hochverfügbarkeit analysiert. </p><br><h3 id="obnaruzhenie-sboev-s-pomoschyu-orchestratorraft">  Absturzerkennung mit Orchestrator / Floß </h3><br><p>  <code>orchestrator</code> einen <a href="">umfassenden Ansatz</a> zur Fehlererkennung, der eine hohe Zuverlässigkeit des Tools gewährleistet.  Es treten keine falsch positiven Ergebnisse auf, es werden keine vorzeitigen Fehler ausgeführt, sodass unnötige Ausfallzeiten ausgeschlossen sind. </p><br><p>  Die <code>orchestrator/raft</code> Schaltung bewältigt auch Situationen einer vollständigen Netzwerkisolation des Rechenzentrums (Data Center Fencing).  Die Netzwerkisolation des Rechenzentrums kann zu Verwirrung führen: Die Server im Rechenzentrum können miteinander kommunizieren.  Wie kann man verstehen, wer wirklich isoliert ist - Server <em>in einem bestimmten</em> Rechenzentrum oder in allen <em>anderen</em> Rechenzentren? </p><br><p>  Im <code>orchestrator/raft</code> Schema ist der <code>orchestrator/raft</code> Master ein Failover.  Der Knoten wird zum Leiter, der die Unterstützung der Mehrheit in der Gruppe erhält (Quorum).  Wir haben den <code>orchestrator</code> Knoten so bereitgestellt, dass kein einzelnes Rechenzentrum die Mehrheit bereitstellen kann, während jedes <code>n-1</code> Rechenzentrum dies bereitstellen kann. </p><br><p>  Bei vollständiger Netzwerkisolation des Rechenzentrums werden die <code>orchestrator</code> in diesem Zentrum von ähnlichen Knoten in anderen Rechenzentren getrennt.  Infolgedessen können die <code>orchestrator</code> in einem isolierten Rechenzentrum nicht in einem <code>raft</code> führend werden.  Wenn ein solcher Knoten der Master war, verliert er diesen Status.  Einem neuen Host wird einer der Knoten der anderen Rechenzentren zugewiesen.  Dieser Leiter wird von allen anderen Rechenzentren unterstützt, die miteinander interagieren können. </p><br><p>  Auf diese Weise befindet sich der <code>orchestrator</code> Master immer außerhalb des netzwerkisolierten Rechenzentrums.  Wenn sich der Masterknoten im isolierten Rechenzentrum befand, initiiert der <code>orchestrator</code> ein Failover, um ihn durch den Server eines der verfügbaren Rechenzentren zu ersetzen.  Wir verringern die Auswirkungen der Isolation von Rechenzentren, indem wir Entscheidungen an das Quorum der verfügbaren Rechenzentren delegieren. </p><br><h3 id="uskorennoe-opoveschenie">  Schnellere Benachrichtigung </h3><br><p>  Die Gesamtausfallzeit kann weiter reduziert werden, indem die Benachrichtigung über eine Änderung im Hauptknoten beschleunigt wird.  Wie erreicht man das? </p><br><p>  Wenn der <code>orchestrator</code> Failover startet, berücksichtigt er eine Gruppe von Servern, von denen einer als Hauptserver zugewiesen werden kann.  Aufgrund der Replikationsregeln, -empfehlungen und -einschränkungen kann er eine fundierte Entscheidung über die beste Vorgehensweise treffen. </p><br><p>  Anhand der folgenden Anzeichen kann er auch verstehen, dass ein zugänglicher Server <em>ein idealer Kandidat</em> für die Ernennung zum Hauptserver ist: </p><br><ul><li>  Nichts verhindert, dass der Server erhöht wird (und der Benutzer empfiehlt diesen Server möglicherweise). </li><li>  Es wird erwartet, dass der Server alle anderen Server als Replikate verwenden kann. </li></ul><br><p>  In diesem Fall konfiguriert <code>orchestrator</code> den Server zunächst als beschreibbar und kündigt sofort eine Erhöhung seines Status an (in unserem Fall schreibt er den Datensatz in das KV-Repository in Consul).   orchestrator     ,     . </p><br><p>  ,    ,    GLB   ,     ,     .   :    ! </p><br><h3 id="polusinhronnaya-replikaciya">   </h3><br><p>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> MySQL         ,           .       :  ,    ,   ,        . </p><br><p>     ,      .        ,    ,   .  ,    ,           ,    . </p><br><p>       : <code>500 </code> .                    .          (    ),          . </p><br><p>                   (   )    .           ,      . </p><br><p>       ,        <em> </em>     .            <em></em> ,      ,  <em></em>    .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ,       <em> </em> , ,       . </p><br><h3 id="peredacha-paketov-pulsa">    </h3><br><p>  ,   /  <code>pt-heartbeat</code>  /  ,       .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ,   <code>pt-heartbeat</code>     ,       <code>read_only</code> ,    . </p><br><p>      <code>pt-heartbeat</code>     ,     .       .               .     ,  <code>pt-heartbeat</code>              . </p><br><h3 id="delegirovanie-zadach-orchestrator">   orchestrator </h3><br><p>    orchestrator  : </p><br><ul><li>  Pseudo-GTID; </li><li>       ,    ; </li><li>         ( <code>read_only</code> ),   . </li></ul><br><p>    ,     . ,      ,      ,      .     <code>orchestrator</code>         . </p><br><h3 id="ogranicheniya-i-nedostatki">    </h3><br><p>  -   ,        ,         .     ,   -,         . </p><br><p>     ,       . </p><br><p> ,      ,     ,     -      .         .               <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">STONITH</a>    .    ,  <em> </em> ,       ,    «» -   .  ,       ,  . </p><br><p>    :  Consul    ,     . .  , ,      ,    ,      . </p><br><h3 id="rezultaty">  Ergebnisse </h3><br><p>   orchestrator/GLB/Consul   : </p><br><ul><li>   ; </li><li>      ; </li><li>       ; </li><li>    ; </li><li>  ,      (    ); </li><li>    ; </li><li>    <code>10-13 </code>   . <br><ol><li>        <code>20 </code> ,      — <code>25 </code> . </li></ol></li></ul><br><h3 id="zaklyuchenie">  Fazit </h3><br><p>  «// »         ,   ,   .       .     ,    . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de432088/">https://habr.com/ru/post/de432088/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de432078/index.html">Verkehr am Ende des Tunnels oder DNS im Pentest</a></li>
<li><a href="../de432080/index.html">Missverständnisse der Spieler bei der Bewertung von Risiken. Steuerung des Zufallszahlengenerators in Entwicklung</a></li>
<li><a href="../de432082/index.html">Microsoft AI Chatbot startet China Clothing Collection</a></li>
<li><a href="../de432084/index.html">Wie wir einen Schichtwettbewerb zwischen Produktionsarbeitern arrangiert haben (wie in der UdSSR)</a></li>
<li><a href="../de432086/index.html">3D-Druck an der nach M.V. Lomonosov benannten internationalen Schule</a></li>
<li><a href="../de432090/index.html">Magento Meetup Kharkiv No. 4 - Videoberichte</a></li>
<li><a href="../de432092/index.html">Unangenehme Fehler beim Schreiben von Unit-Tests</a></li>
<li><a href="../de432094/index.html">Gemeinsamer Online-Hackathon von OpenGift und Credits Blockchain Platform</a></li>
<li><a href="../de432096/index.html">Komplette CMake-Anleitung. Teil Zwei: Build System</a></li>
<li><a href="../de432098/index.html">Autopiloten im Straßenverkehr, wie man mit Specials umgeht. mit dem Transport?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
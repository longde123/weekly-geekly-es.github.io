<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§æüèø üë©üèΩ‚Äçüî¨ üéÖ MySQL-Hochverf√ºgbarkeit auf GitHub üñï üò∂ üë©üèΩ‚Äçüíº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="GitHub verwendet MySQL als prim√§res Data Warehouse f√ºr alles, was nicht mit git tun hat. git ist die Verf√ºgbarkeit von MySQL der Schl√ºssel zum normale...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>MySQL-Hochverf√ºgbarkeit auf GitHub</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/432088/"><p> GitHub verwendet MySQL als prim√§res Data Warehouse f√ºr alles, was nicht mit <code>git</code> tun hat. <code>git</code> ist die Verf√ºgbarkeit von MySQL der Schl√ºssel zum normalen Betrieb von GitHub.  Die Site selbst, die GitHub-API, das Authentifizierungssystem und viele andere Funktionen erfordern Zugriff auf Datenbanken.  Wir verwenden mehrere MySQL-Cluster, um verschiedene Dienste und Aufgaben zu erledigen.  Sie werden nach dem klassischen Schema konfiguriert, wobei ein Hauptknoten f√ºr die Aufzeichnung und seine Replikate verf√ºgbar ist.  <em>Replikate</em> (andere Clusterknoten) reproduzieren asynchron √Ñnderungen am Hauptknoten und bieten Lesezugriff. </p><br><p>  Die Verf√ºgbarkeit von Host-Sites ist entscheidend.  Ohne den Hauptknoten unterst√ºtzt der Cluster keine Aufzeichnung, sodass Sie die erforderlichen √Ñnderungen nicht speichern k√∂nnen.  Das Beheben von Transaktionen, das Registrieren von Problemen, das Erstellen neuer Benutzer, Repositorys, √úberpr√ºfungen und vieles mehr ist einfach unm√∂glich. </p><br><p>  Zur Unterst√ºtzung der Aufzeichnung ist ein entsprechender zug√§nglicher Knoten erforderlich - der Hauptknoten im Cluster.  Die F√§higkeit, einen solchen Knoten zu identifizieren oder zu <em>erkennen</em> , ist jedoch ebenso wichtig. </p><br><p>  Bei einem Ausfall des aktuellen Hauptknotens ist es wichtig, dass ein neuer Server sofort angezeigt wird, um ihn zu ersetzen, und dass alle Dienste schnell √ºber diese √Ñnderung informiert werden k√∂nnen.  Die gesamte Ausfallzeit besteht aus der Zeit, die ben√∂tigt wird, um einen Fehler zu erkennen, ein Failover durchzuf√ºhren und √ºber einen neuen Hauptknoten zu benachrichtigen. </p><br><p><img src="https://habrastorage.org/webt/m8/ah/po/m8ahpo0jhrucgwj3kb5u7hn9edo.jpeg"></p><a name="habracut"></a><br><p>  Diese Ver√∂ffentlichung beschreibt eine L√∂sung zur Sicherstellung einer hohen Verf√ºgbarkeit von MySQL in GitHub und zur Ermittlung des Hauptdienstes, mit der wir zuverl√§ssig Vorg√§nge in mehreren Rechenzentren ausf√ºhren, die Funktionsf√§higkeit aufrechterhalten k√∂nnen, wenn einige dieser Zentren nicht verf√ºgbar sind, und im Ausfallfall minimale Ausfallzeiten gew√§hrleisten k√∂nnen. </p><br><h3 id="celi-obespecheniya-vysokoy-dostupnosti">  Hochverf√ºgbarkeitsziele </h3><br><p>  Die in diesem Artikel beschriebene L√∂sung ist eine neue, verbesserte Version fr√ºherer Hochverf√ºgbarkeitsl√∂sungen (HA), die auf GitHub implementiert wurden.  W√§hrend wir wachsen, m√ºssen wir die MySQL HA-Strategie anpassen, um sie zu √§ndern.  Wir bem√ºhen uns, √§hnliche Ans√§tze f√ºr MySQL und andere Dienste auf GitHub zu verfolgen. </p><br><p>  Um die richtige L√∂sung f√ºr Hochverf√ºgbarkeit und Serviceerkennung zu finden, sollten Sie zun√§chst einige spezifische Fragen beantworten.  Hier ist eine Beispielliste von ihnen: </p><br><ul><li>  Welche maximale Ausfallzeit ist f√ºr Sie unkritisch? </li><li>  Wie zuverl√§ssig sind Fehlererkennungswerkzeuge?  Sind Fehlalarme (vorzeitige Fehlerverarbeitung) f√ºr Sie kritisch? </li><li>  Wie zuverl√§ssig ist das Failover-System?  Wo kann ein Fehler auftreten? </li><li>  Wie effektiv ist die L√∂sung in mehreren Rechenzentren?  Wie effektiv ist die L√∂sung in Netzwerken mit niedriger und hoher Latenz? </li><li>  Funktioniert die L√∂sung auch bei einem vollst√§ndigen Ausfall des Rechenzentrums (DPC) oder einer Netzwerkisolation weiter? </li><li>  Welcher Mechanismus (falls vorhanden) verhindert oder mildert die Folgen der Entstehung von zwei Hauptservern im Cluster, die unabh√§ngig voneinander aufzeichnen? </li><li>  Ist Datenverlust f√ºr Sie kritisch?  Wenn ja, in welchem ‚Äã‚ÄãUmfang? </li></ul><br><p>  Um dies zu demonstrieren, betrachten wir zun√§chst die vorherige L√∂sung und diskutieren, warum wir beschlossen haben, sie aufzugeben. </p><br><h3 id="otkaz-ot-ispolzovaniya-vip-i-dns-dlya-obnaruzheniya">  Verweigerung der Verwendung von VIP und DNS zur Ermittlung </h3><br><p>  Als Teil der vorherigen L√∂sung haben wir verwendet: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orchestrator</a> zur Fehlererkennung und zum Failover; </li><li>  VIP und DNS f√ºr die Hosterkennung. </li></ul><br><p>  In diesem Fall haben Clients einen Aufzeichnungsknoten anhand seines Namens entdeckt, z. B. <code>mysql-writer-1.github.net</code> .  Der Name wurde verwendet, um die virtuelle IP-Adresse (VIP) des Hauptknotens zu bestimmen. </p><br><p>  In einer normalen Situation mussten Kunden lediglich den Namen aufl√∂sen und eine Verbindung zur empfangenen IP-Adresse herstellen, auf die der Hauptknoten bereits gewartet hatte. </p><br><p>  Betrachten Sie die folgende Replikationstopologie, die drei verschiedene Rechenzentren umfasst: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8fa/e2e/4f3/8fae2e4f382f3060b5a14ed9d80a5f67.png" alt="Bild"></p><br><p>  Bei einem Ausfall des Hauptknotens muss seinem Platz ein neuer Server zugewiesen werden (einer der Replikate). </p><br><p>  <code>orchestrator</code> erkennt einen Fehler, w√§hlt einen neuen Masterknoten aus und weist dann den Namen / VIP zu.  Clients kennen die Identit√§t des Hauptknotens nicht, sondern nur den Namen, der jetzt auf den neuen Knoten verweisen soll.  Beachten Sie dies jedoch. </p><br><p>  VIP-Adressen werden gemeinsam genutzt, Datenbankserver selbst fordern sie an und besitzen sie.  Um einen VIP zu empfangen oder freizugeben, muss der Server eine ARP-Anfrage senden.  Der Server, dem der VIP geh√∂rt, muss ihn zuerst freigeben, bevor der neue Master auf diese Adresse zugreifen kann.  Dieser Ansatz f√ºhrt zu einigen unerw√ºnschten Konsequenzen: </p><br><ul><li>  Im normalen Modus kontaktiert das Failover-System zuerst den ausgefallenen Hauptknoten und fordert ihn auf, den VIP freizugeben, und wendet sich dann mit einer Anforderung zur VIP-Zuweisung an den neuen Hauptserver.  Was tun, wenn der erste Hauptknoten nicht verf√ºgbar ist oder eine Anforderung zur Freigabe der VIP-Adresse ablehnt?  Angesichts der Tatsache, dass sich der Server derzeit in einem Ausfallzustand befindet, ist es unwahrscheinlich, dass er rechtzeitig oder √ºberhaupt auf eine Anfrage antworten kann. <br><ol><li>  Infolgedessen kann es vorkommen, dass zwei Hosts ihre Rechte an demselben VIP geltend machen.  Abh√§ngig vom k√ºrzesten Netzwerkpfad k√∂nnen verschiedene Clients eine Verbindung zu jedem dieser Server herstellen. </li><li>  Der korrekte Betrieb in dieser Situation h√§ngt von der Interaktion zweier unabh√§ngiger Server ab, und eine solche Konfiguration ist unzuverl√§ssig. </li></ol></li><li>  Selbst wenn der erste Hauptknoten auf Anfragen reagiert, verschwenden wir wertvolle Zeit: Der Wechsel zum neuen Hauptserver erfolgt nicht, w√§hrend wir den alten kontaktieren. </li><li>  Dar√ºber hinaus gibt es auch bei einer Neuzuweisung von VIPs keine Garantie daf√ºr, dass vorhandene Clientverbindungen auf dem alten Server getrennt werden.  Auch hier laufen wir Gefahr, in einer Situation mit zwei unabh√§ngigen Hauptknoten zu sein. </li></ul><br><p>  Hier und da in unserer Umgebung sind VIP-Adressen einem physischen Standort zugeordnet.  Sie sind einem Switch oder Router zugeordnet.  Daher k√∂nnen wir eine VIP-Adresse nur einem Server zuweisen, der sich in derselben Umgebung wie der urspr√ºngliche Host befindet.  Insbesondere k√∂nnen wir in einigen F√§llen keinen VIP-Server in einem anderen Rechenzentrum zuweisen und m√ºssen √Ñnderungen am DNS vornehmen. </p><br><ul><li>  Das Verteilen von √Ñnderungen an den DNS dauert l√§nger.  Clients speichern DNS-Namen f√ºr einen vordefinierten Zeitraum.  Ein Failover mit mehreren Rechenzentren f√ºhrt zu l√§ngeren Ausfallzeiten, da es l√§nger dauert, bis alle Kunden Informationen √ºber den neuen Hauptknoten erhalten. </li></ul><br><p>  Diese Einschr√§nkungen reichten aus, um uns zu zwingen, nach einer neuen L√∂sung zu suchen, aber wir mussten auch Folgendes ber√ºcksichtigen: </p><br><ul><li>  Die Hauptknoten sendeten unabh√§ngig Impulspakete √ºber den <code>pt-heartbeat</code> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">um die Verz√∂gerung und die Lastregelung</a> zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">messen</a> .  Der Dienst musste auf den neu ernannten Hauptknoten √ºbertragen werden.  Wenn m√∂glich, sollte es auf dem alten Server deaktiviert sein. </li><li>  In √§hnlicher Weise steuerten die Hauptknoten unabh√§ngig den Betrieb der <a href="">Pseudo-GTID</a> .  Es war notwendig, diesen Prozess auf dem neuen Hauptknoten zu starten und vorzugsweise auf dem alten zu stoppen. </li><li>  Der neue Masterknoten wurde beschreibbar.  Der alte Knoten (falls m√∂glich) sollte <code>read_only</code> (schreibgesch√ºtzt) haben. </li></ul><br><p>  Diese zus√§tzlichen Schritte f√ºhrten zu einer Erh√∂hung der Gesamtausfallzeit und f√ºgten ihre eigenen Fehlerquellen hinzu. </p><br><p>  Die L√∂sung funktionierte und GitHub behandelte erfolgreich MySQL-Fehler im Hintergrund, aber wir wollten unseren Ansatz f√ºr HA wie folgt verbessern: </p><br><ul><li>  Gew√§hrleistung der Unabh√§ngigkeit von bestimmten Rechenzentren; </li><li>  Gew√§hrleistung der Funktionsf√§higkeit bei Ausf√§llen von Rechenzentren; </li><li>  Geben Sie unzuverl√§ssige kollaborative Workflows auf </li><li>  Reduzierung der gesamten Ausfallzeiten; </li><li>  F√ºhren Sie das Failover so weit wie m√∂glich ohne Verlust durch. </li></ul><br><h3 id="ha-reshenie-github-orchestrator-consul-glb">  GitHub HA-L√∂sung: Orchestrator, Consul, GLB </h3><br><p>  Unsere neue Strategie beseitigt zusammen mit den damit verbundenen Verbesserungen die meisten der oben genannten Probleme oder mildert deren Folgen.  Unser derzeitiges HA-System besteht aus folgenden Elementen: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orchestrator</a> zur Fehlererkennung und zum Failover.  Wir verwenden das <a href="">Orchestrator / Raft-</a> Schema mit mehreren Rechenzentren, wie in der folgenden Abbildung gezeigt. </li><li>  Hashicorp- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Konsul</a> f√ºr Service Discovery; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GLB / HAProxy</a> als Proxy-Schicht zwischen Clients und Aufzeichnungsknoten.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Quellcode</a> f√ºr den GLB Director ist ge√∂ffnet. </li><li>  <code>anycast</code> Technologie f√ºr das Netzwerk-Routing. </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/762/fb4/7a0/762fb47a0de253cce045889faa945228.png" alt="Bild"></p><br><p>  Mit dem neuen Schema konnten √Ñnderungen an VIP und DNS vollst√§ndig aufgegeben werden.  Wenn wir jetzt neue Komponenten einf√ºhren, k√∂nnen wir sie trennen und die Aufgabe vereinfachen.  Dar√ºber hinaus hatten wir die M√∂glichkeit, zuverl√§ssige und stabile L√∂sungen zu verwenden.  Eine detaillierte Analyse der neuen L√∂sung ist unten angegeben. </p><br><h3 id="normalnyy-potok">  Normaler Durchfluss </h3><br><p>  In einer normalen Situation stellen Anwendungen √ºber GLB / HAProxy eine Verbindung zu Aufzeichnungsknoten her. </p><br><p>  Anwendungen erhalten nicht die Identit√§t des Hauptservers.  Nach wie vor verwenden sie nur den Namen.  Der Hauptknoten f√ºr <code>cluster1</code> w√§re beispielsweise <code>mysql-writer-1.github.net</code> .  In unserer aktuellen Konfiguration wird dieser Name jedoch in die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anycast-</a> IP-Adresse aufgel√∂st. </p><br><p>  Dank der <code>anycast</code> Technologie wird der Name √ºberall in dieselbe IP-Adresse aufgel√∂st, der Datenverkehr wird jedoch je nach Standort des Clients unterschiedlich geleitet.  Insbesondere werden in jedem unserer Rechenzentren mehrere Instanzen von GLB, unserem hochverf√ºgbaren Load Balancer, bereitgestellt.  Der <code>mysql-writer-1.github.net</code> auf <code>mysql-writer-1.github.net</code> immer an den GLB-Cluster des lokalen Rechenzentrums weitergeleitet.  Aus diesem Grund werden alle Clients von lokalen Proxys bedient. </p><br><p>  Wir f√ºhren GLB auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HAProxy aus</a> .  Unser HAProxy-Server bietet <em>Schreibpools</em> : einen f√ºr jeden MySQL-Cluster.  Au√üerdem hat jeder Pool nur einen Server (den Hauptknoten des Clusters).  Alle GLB / HAProxy-Instanzen in allen Rechenzentren haben dieselben Pools und alle verweisen auf dieselben Server in diesen Pools.  Wenn die Anwendung Daten auf <code>mysql-writer-1.github.net</code> in die Datenbank schreiben <code>mysql-writer-1.github.net</code> , spielt es keine Rolle, mit welchem ‚Äã‚ÄãGLB-Server sie eine Verbindung herstellt.  In beiden F√§llen wird eine Umleitung zum eigentlichen <code>cluster1</code> durchgef√ºhrt. </p><br><p>  Bei Anwendungen endet die Erkennung mit GLB, und eine erneute Erkennung ist nicht erforderlich.  Dieser GLB leitet den Verkehr an den richtigen Ort um. </p><br><p>  Woher erh√§lt der GLB Informationen dar√ºber, welche Server aufgelistet werden sollen?  Wie nehmen wir √Ñnderungen am GLB vor? </p><br><h3 id="obnaruzhenie-cherez-consul">  Entdeckung durch Konsul </h3><br><p>  Der Consul-Dienst ist allgemein als Service Discovery-L√∂sung bekannt und √ºbernimmt auch DNS-Funktionen.  In unserem Fall verwenden wir es jedoch als leicht zug√§ngliche Speicherung von Schl√ºsselwerten (KV). </p><br><p>  Im KV-Repository in Consul zeichnen wir die Identit√§t der Hauptclusterknoten auf.  F√ºr jeden Cluster gibt es eine Reihe von KV-Datens√§tzen, die auf die Daten des entsprechenden Hauptknotens <code>fqdn</code> : seine <code>fqdn</code> , port, ipv4 und ipv6. </p><br><p>  Jeder GLB / HAProxy-Knoten startet eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Konsul-Vorlage</a> , einen Dienst, der √Ñnderungen an den Konsul-Daten verfolgt (in unserem Fall √Ñnderungen an den Daten der Hauptknoten).  Der <code>consul-template</code> erstellt eine Konfigurationsdatei und kann HAProxy beim √Ñndern von Einstellungen neu laden. </p><br><p>  Aus diesem Grund stehen jeder GLB / HAProxy-Instanz Informationen zum √Ñndern der Identit√§t des Hauptknotens in Consul zur Verf√ºgung.  Basierend auf diesen Informationen wird die Konfiguration der Instanzen durchgef√ºhrt. Die neuen Hauptknoten werden als einzige Entit√§t im Cluster-Server-Pool angegeben.  Danach werden die Instanzen neu geladen, damit die √Ñnderungen wirksam werden. </p><br><p>  Wir haben Consul-Instanzen in jedem Rechenzentrum bereitgestellt, und jede Instanz bietet hohe Verf√ºgbarkeit.  Diese Instanzen sind jedoch unabh√§ngig voneinander.  Sie replizieren nicht und tauschen keine Daten aus. </p><br><p>  Woher erh√§lt Consul Informationen √ºber √Ñnderungen und wie werden diese zwischen Rechenzentren verteilt? </p><br><h3 id="orchestratorraft">  Orchestrator / Flo√ü </h3><br><p>  Wir verwenden das <code>orchestrator/raft</code> Schema: <code>orchestrator</code> Knoten kommunizieren √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raft-</a> Konsens miteinander.  In jedem Rechenzentrum haben wir einen oder zwei <code>orchestrator</code> . </p><br><p>  <code>orchestrator</code> ist f√ºr die Erkennung von Fehlern, das MySQL-Failover und die √úbertragung der ge√§nderten Masterknotendaten an Consul verantwortlich.  Das Failover wird von einem einzelnen <code>orchestrator/raft</code> Host verwaltet, aber <em>√Ñnderungen</em> , die besagen, dass der Cluster jetzt ein neuer Master ist, werden mithilfe des <code>raft</code> Mechanismus an alle <code>orchestrator</code> Knoten weitergegeben. </p><br><p>  Wenn die <code>orchestrator</code> Nachrichten √ºber eine √Ñnderung der Daten des Hauptknotens erhalten, kontaktiert jeder von ihnen seine eigene lokale Instanz von Consul und initiiert eine KV-Aufzeichnung.  Rechenzentren mit mehreren Instanzen von <code>orchestrator</code> erhalten mehrere (identische) Datens√§tze in Consul. </p><br><h3 id="obobschennoe-predstavlenie-vsego-potoka">  Verallgemeinerte Ansicht des gesamten Streams </h3><br><p>  Wenn der Masterknoten ausf√§llt: </p><br><ul><li>  <code>orchestrator</code> erkennen Fehler; </li><li>  <code>orchestrator/raft</code> Master initiiert die Wiederherstellung.  Ein neuer Masterknoten wird zugewiesen. </li><li>  Das <code>orchestrator/raft</code> Schema √ºbertr√§gt die Daten zum Wechsel des Hauptknotens an alle Knoten des <code>raft</code> Clusters. </li><li>  Jede Instanz von <code>orchestrator/raft</code> erh√§lt eine Benachrichtigung √ºber einen Knotenwechsel und schreibt die Identit√§t des neuen Masterknotens in den lokalen KV-Speicher in Consul. </li><li>  Auf jeder GLB / HAProxy-Instanz wird der <code>consul-template</code> Dienst gestartet, der √Ñnderungen im KV-Repository in Consul √ºberwacht, HAProxy neu konfiguriert und neu startet. </li><li>  Der Clientverkehr wird auf den neuen Masterknoten umgeleitet. </li></ul><br><p>  F√ºr jede Komponente sind die Verantwortlichkeiten klar verteilt und die gesamte Struktur ist diversifiziert und vereinfacht.  <code>orchestrator</code> interagiert nicht mit Load Balancern.  Der Konsul ben√∂tigt keine Informationen √ºber die Herkunft der Informationen.  Proxyserver funktionieren nur mit Consul.  Clients arbeiten nur mit Proxyservern. </p><br><p>  Au√üerdem: </p><br><ul><li>  Es ist nicht erforderlich, √Ñnderungen am DNS vorzunehmen und Informationen dar√ºber zu verbreiten. </li><li>  TTL wird nicht verwendet; </li><li>  Der Thread wartet nicht auf Antworten vom Host in einem Fehlerzustand.  Im Allgemeinen wird es ignoriert. </li></ul><br><h3 id="dopolnitelnaya-informaciya">  Weitere Informationen </h3><br><p>  Um den Fluss zu stabilisieren, wenden wir auch die folgenden Methoden an: </p><br><ul><li>  Der HAProxy- <code>hard-stop-after</code> Parameter ist auf einen sehr kleinen Wert eingestellt.  Wenn HAProxy mit dem neuen Server im Schreibpool neu gestartet wird, beendet der Server automatisch alle vorhandenen Verbindungen zum alten Masterknoten. <br><ol><li>  Durch Festlegen des <code>hard-stop-after</code> Parameters k√∂nnen Sie nicht auf Aktionen von Clients warten. Au√üerdem werden die negativen Folgen des m√∂glichen Auftretens von zwei Hauptknoten im Cluster minimiert.  Es ist wichtig zu verstehen, dass es hier keine Magie gibt, und auf jeden Fall vergeht <em>einige Zeit,</em> bis die alten Bindungen gebrochen sind.  Aber es gibt einen Zeitpunkt, nach dem wir aufh√∂ren k√∂nnen, auf unangenehme √úberraschungen zu warten. </li></ol></li><li>  Wir ben√∂tigen keine st√§ndige Verf√ºgbarkeit des Konsulendienstes.  Tats√§chlich muss es nur w√§hrend des Failovers verf√ºgbar sein.  Wenn der Konsulendienst nicht reagiert, arbeitet GLB weiterhin mit den neuesten bekannten Werten und ergreift keine drastischen Ma√ünahmen. </li><li>  Der GLB ist so konfiguriert, dass die Identit√§t des neu zugewiesenen Masterknotens √ºberpr√ºft wird.  Wie bei unseren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kontextsensitiven MySQL-Pools</a> wird eine √úberpr√ºfung durchgef√ºhrt, um zu best√§tigen, dass der Server tats√§chlich beschreibbar ist.  Wenn wir versehentlich die Identit√§t des Hauptknotens in Consul l√∂schen, gibt es keine Probleme, ein leerer Datensatz wird ignoriert.  Wenn wir versehentlich den Namen eines anderen Servers (nicht des Hauptservers) an Consul schreiben, ist dies in diesem Fall in Ordnung: GLB aktualisiert ihn nicht und arbeitet weiterhin mit dem letzten g√ºltigen Status. </li></ul><br><p>  In den folgenden Abschnitten werden Probleme untersucht und die Ziele der Hochverf√ºgbarkeit analysiert. </p><br><h3 id="obnaruzhenie-sboev-s-pomoschyu-orchestratorraft">  Absturzerkennung mit Orchestrator / Flo√ü </h3><br><p>  <code>orchestrator</code> einen <a href="">umfassenden Ansatz</a> zur Fehlererkennung, der eine hohe Zuverl√§ssigkeit des Tools gew√§hrleistet.  Es treten keine falsch positiven Ergebnisse auf, es werden keine vorzeitigen Fehler ausgef√ºhrt, sodass unn√∂tige Ausfallzeiten ausgeschlossen sind. </p><br><p>  Die <code>orchestrator/raft</code> Schaltung bew√§ltigt auch Situationen einer vollst√§ndigen Netzwerkisolation des Rechenzentrums (Data Center Fencing).  Die Netzwerkisolation des Rechenzentrums kann zu Verwirrung f√ºhren: Die Server im Rechenzentrum k√∂nnen miteinander kommunizieren.  Wie kann man verstehen, wer wirklich isoliert ist - Server <em>in einem bestimmten</em> Rechenzentrum oder in allen <em>anderen</em> Rechenzentren? </p><br><p>  Im <code>orchestrator/raft</code> Schema ist der <code>orchestrator/raft</code> Master ein Failover.  Der Knoten wird zum Leiter, der die Unterst√ºtzung der Mehrheit in der Gruppe erh√§lt (Quorum).  Wir haben den <code>orchestrator</code> Knoten so bereitgestellt, dass kein einzelnes Rechenzentrum die Mehrheit bereitstellen kann, w√§hrend jedes <code>n-1</code> Rechenzentrum dies bereitstellen kann. </p><br><p>  Bei vollst√§ndiger Netzwerkisolation des Rechenzentrums werden die <code>orchestrator</code> in diesem Zentrum von √§hnlichen Knoten in anderen Rechenzentren getrennt.  Infolgedessen k√∂nnen die <code>orchestrator</code> in einem isolierten Rechenzentrum nicht in einem <code>raft</code> f√ºhrend werden.  Wenn ein solcher Knoten der Master war, verliert er diesen Status.  Einem neuen Host wird einer der Knoten der anderen Rechenzentren zugewiesen.  Dieser Leiter wird von allen anderen Rechenzentren unterst√ºtzt, die miteinander interagieren k√∂nnen. </p><br><p>  Auf diese Weise befindet sich der <code>orchestrator</code> Master immer au√üerhalb des netzwerkisolierten Rechenzentrums.  Wenn sich der Masterknoten im isolierten Rechenzentrum befand, initiiert der <code>orchestrator</code> ein Failover, um ihn durch den Server eines der verf√ºgbaren Rechenzentren zu ersetzen.  Wir verringern die Auswirkungen der Isolation von Rechenzentren, indem wir Entscheidungen an das Quorum der verf√ºgbaren Rechenzentren delegieren. </p><br><h3 id="uskorennoe-opoveschenie">  Schnellere Benachrichtigung </h3><br><p>  Die Gesamtausfallzeit kann weiter reduziert werden, indem die Benachrichtigung √ºber eine √Ñnderung im Hauptknoten beschleunigt wird.  Wie erreicht man das? </p><br><p>  Wenn der <code>orchestrator</code> Failover startet, ber√ºcksichtigt er eine Gruppe von Servern, von denen einer als Hauptserver zugewiesen werden kann.  Aufgrund der Replikationsregeln, -empfehlungen und -einschr√§nkungen kann er eine fundierte Entscheidung √ºber die beste Vorgehensweise treffen. </p><br><p>  Anhand der folgenden Anzeichen kann er auch verstehen, dass ein zug√§nglicher Server <em>ein idealer Kandidat</em> f√ºr die Ernennung zum Hauptserver ist: </p><br><ul><li>  Nichts verhindert, dass der Server erh√∂ht wird (und der Benutzer empfiehlt diesen Server m√∂glicherweise). </li><li>  Es wird erwartet, dass der Server alle anderen Server als Replikate verwenden kann. </li></ul><br><p>  In diesem Fall konfiguriert <code>orchestrator</code> den Server zun√§chst als beschreibbar und k√ºndigt sofort eine Erh√∂hung seines Status an (in unserem Fall schreibt er den Datensatz in das KV-Repository in Consul).   orchestrator     ,     . </p><br><p>  ,    ,    GLB   ,     ,     .   :    ! </p><br><h3 id="polusinhronnaya-replikaciya">   </h3><br><p>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> MySQL         ,           .       :  ,    ,   ,        . </p><br><p>     ,      .        ,    ,   .  ,    ,           ,    . </p><br><p>       : <code>500 </code> .                    .          (    ),          . </p><br><p>                   (   )    .           ,      . </p><br><p>       ,        <em> </em>     .            <em></em> ,      ,  <em></em>    .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ,       <em> </em> , ,       . </p><br><h3 id="peredacha-paketov-pulsa">    </h3><br><p>  ,   /  <code>pt-heartbeat</code>  /  ,       .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ,   <code>pt-heartbeat</code>     ,       <code>read_only</code> ,    . </p><br><p>      <code>pt-heartbeat</code>     ,     .       .               .     ,  <code>pt-heartbeat</code>              . </p><br><h3 id="delegirovanie-zadach-orchestrator">   orchestrator </h3><br><p>    orchestrator  : </p><br><ul><li>  Pseudo-GTID; </li><li>       ,    ; </li><li>         ( <code>read_only</code> ),   . </li></ul><br><p>    ,     . ,      ,      ,      .     <code>orchestrator</code>         . </p><br><h3 id="ogranicheniya-i-nedostatki">    </h3><br><p>  -   ,        ,         .     ,   -,         . </p><br><p>     ,       . </p><br><p> ,      ,     ,     -      .         .               <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">STONITH</a>    .    ,  <em> </em> ,       ,    ¬´¬ª -   .  ,       ,  . </p><br><p>    :  Consul    ,     . .  , ,      ,    ,      . </p><br><h3 id="rezultaty">  Ergebnisse </h3><br><p>   orchestrator/GLB/Consul   : </p><br><ul><li>   ; </li><li>      ; </li><li>       ; </li><li>    ; </li><li>  ,      (    ); </li><li>    ; </li><li>    <code>10-13 </code>   . <br><ol><li>        <code>20 </code> ,      ‚Äî <code>25 </code> . </li></ol></li></ul><br><h3 id="zaklyuchenie">  Fazit </h3><br><p>  ¬´// ¬ª         ,   ,   .       .     ,    . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de432088/">https://habr.com/ru/post/de432088/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de432078/index.html">Verkehr am Ende des Tunnels oder DNS im Pentest</a></li>
<li><a href="../de432080/index.html">Missverst√§ndnisse der Spieler bei der Bewertung von Risiken. Steuerung des Zufallszahlengenerators in Entwicklung</a></li>
<li><a href="../de432082/index.html">Microsoft AI Chatbot startet China Clothing Collection</a></li>
<li><a href="../de432084/index.html">Wie wir einen Schichtwettbewerb zwischen Produktionsarbeitern arrangiert haben (wie in der UdSSR)</a></li>
<li><a href="../de432086/index.html">3D-Druck an der nach M.V. Lomonosov benannten internationalen Schule</a></li>
<li><a href="../de432090/index.html">Magento Meetup Kharkiv No. 4 - Videoberichte</a></li>
<li><a href="../de432092/index.html">Unangenehme Fehler beim Schreiben von Unit-Tests</a></li>
<li><a href="../de432094/index.html">Gemeinsamer Online-Hackathon von OpenGift und Credits Blockchain Platform</a></li>
<li><a href="../de432096/index.html">Komplette CMake-Anleitung. Teil Zwei: Build System</a></li>
<li><a href="../de432098/index.html">Autopiloten im Stra√üenverkehr, wie man mit Specials umgeht. mit dem Transport?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
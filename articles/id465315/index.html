<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ¿â€ğŸ¤â€ğŸ‘¨ğŸ¼ âœŒğŸ¿ ğŸ”œ Kafka dan microservices: tinjauan umum ğŸŒ¼ ğŸ‘¨â€ğŸ« ğŸ‘©ğŸ»â€ğŸ’¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya. Dalam artikel ini saya akan memberi tahu Anda mengapa kami memilih Kafka sembilan bulan lalu di Avito, dan apa itu. Saya akan membagika...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kafka dan microservices: tinjauan umum</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/465315/"><p><img src="https://habrastorage.org/webt/ds/35/lj/ds35ljzkot_2jqkr7tnjuf8ynwg.png"></p><br><p>  Halo semuanya.  Dalam artikel ini saya akan memberi tahu Anda mengapa kami memilih Kafka sembilan bulan lalu di Avito, dan apa itu.  Saya akan membagikan salah satu kasus penggunaan - broker pesan.  Dan akhirnya, mari kita bicara tentang keuntungan apa yang kita dapatkan dari menerapkan Kafka sebagai pendekatan Layanan. </p><a name="habracut"></a><br><h1 id="problema">  Masalah </h1><br><p><img src="https://habrastorage.org/webt/xd/gl/fu/xdglfupecap80heoegvpab_iy74.png"></p><br><p>  Pertama, sedikit konteks.  Beberapa waktu yang lalu, kami mulai menjauh dari arsitektur monolitik, dan sekarang di Avito sudah ada beberapa ratus layanan berbeda.  Mereka memiliki repositori mereka sendiri, tumpukan teknologi mereka sendiri dan bertanggung jawab atas bagian mereka dari logika bisnis. </p><br><p>  Salah satu masalah dengan sejumlah besar layanan adalah komunikasi.  Layanan A sering ingin mengetahui informasi yang dimiliki layanan B. Dalam hal ini, layanan A mengakses layanan B melalui API yang sinkron.  Layanan B ingin tahu apa yang terjadi dengan layanan G dan D, dan mereka, pada gilirannya, tertarik pada layanan A dan B. Ketika ada banyak layanan "penasaran" seperti itu, koneksi di antara mereka berubah menjadi bola kusut. </p><br><p>  Selain itu, kapan saja, layanan A mungkin tidak tersedia.  Dan apa yang harus dilakukan dalam hal ini, layanan B dan semua layanan lain yang terkait dengannya?  Dan jika Anda perlu membuat rantai panggilan sinkron berurutan untuk menyelesaikan operasi bisnis, probabilitas kegagalan seluruh operasi menjadi lebih tinggi (dan semakin tinggi, semakin lama rantai ini). </p><br><h1 id="vybor-tehnologii">  Pemilihan teknologi </h1><br><p><img src="https://habrastorage.org/webt/pr/t4/xo/prt4xoqz2xianmupqbdqk1unc8i.png" width="300" alt="gambar" align="left"></p><br><p>  OK, masalahnya sudah jelas.  Anda dapat menghilangkannya dengan membuat sistem pesan terpusat antar layanan.  Sekarang, masing-masing layanan sudah cukup untuk mengetahui hanya tentang sistem pesan ini.  Selain itu, sistem itu sendiri harus toleran terhadap kesalahan dan dapat diskalakan secara horizontal, serta dalam hal kecelakaan, mengakumulasi buffer panggilan untuk pemrosesan selanjutnya. </p><br><p>  Sekarang mari kita memilih teknologi di mana pengiriman pesan akan dilaksanakan.  Untuk melakukan ini, pahami dulu apa yang kami harapkan darinya: </p><br><ul><li>  Pesan antar layanan tidak boleh hilang; </li><li>  Pesan dapat diduplikasi </li><li>  pesan dapat disimpan dan dibaca hingga beberapa hari (buffer persisten); </li><li>  layanan dapat berlangganan data yang menarik bagi mereka; </li><li>  beberapa layanan dapat membaca data yang sama; </li><li>  Pesan dapat berisi rincian, muatan curah (transfer yang dilakukan oleh negara); </li><li>  terkadang Anda membutuhkan jaminan pesanan pesan. </li></ul><br><p>  Penting juga bagi kami untuk memilih sistem yang paling skalabel dan andal dengan throughput tinggi (setidaknya 100rb pesan dengan beberapa kilobyte per detik). </p><br><p> Pada tahap ini, kami mengucapkan selamat tinggal pada RabbitMQ (sulit untuk tetap stabil di rps tinggi), PGT dari SkyTools (tidak cukup cepat dan kurang skalabel) dan NSQ (tidak persisten).  Semua teknologi ini digunakan di perusahaan kami, tetapi mereka tidak sesuai dengan tugas yang ada. </p><br><p>  Kemudian kami mulai mencari teknologi baru untuk kami - Apache Kafka, Apache Pulsar dan NATS Streaming. </p><br><p>  Yang pertama menjatuhkan Pulsar.  Kami memutuskan bahwa Kafka dan Pulsar adalah solusi yang cukup mirip.  Dan terlepas dari kenyataan bahwa Pulsar diuji oleh perusahaan besar, itu lebih baru dan menawarkan latensi yang lebih rendah (secara teori), kami memutuskan untuk meninggalkan Kafka dari keduanya, sebagai standar de facto untuk tugas-tugas tersebut.  Kami mungkin akan kembali ke Apache Pulsar di masa mendatang. </p><br><p>  Dan ada dua kandidat yang tersisa: NATS Streaming dan Apache Kafka.  Kami mempelajari kedua solusi secara terperinci, dan keduanya sampai pada tugas itu.  Tetapi pada akhirnya, kami takut akan generasi relatif dari Streaming NATS (dan fakta bahwa salah satu pengembang utama, Tyler Treat, memutuskan untuk meninggalkan proyek dan memulai proyeknya sendiri - Liftbridge).  Pada saat yang sama, mode Clustering Streaming NATS tidak memungkinkan untuk penskalaan horizontal yang kuat (ini mungkin tidak lagi menjadi masalah setelah menambahkan mode partisi pada 2017). </p><br><p>  Namun, NATS Streaming adalah teknologi keren yang ditulis dalam Go dan didukung oleh Cloud Native Computing Foundation.  Tidak seperti Apache Kafka, Zookeeper tidak perlu bekerja ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mungkin bisa mengatakan hal yang sama tentang Kafka segera</a> ), karena di dalamnya mengimplementasikan RAFT.  Pada saat yang sama, Streaming NATS lebih mudah untuk dikelola.  Kami tidak mengecualikan bahwa di masa depan kami akan kembali ke teknologi ini. </p><br><p>  Namun demikian, Apache Kafka telah menjadi pemenang kami hari ini.  Dalam pengujian kami, terbukti cukup cepat (lebih dari satu juta pesan per detik untuk membaca dan menulis dengan volume pesan 1 kilobyte), cukup andal, dapat diukur dengan baik dan pengalaman yang terbukti dalam penjualan oleh perusahaan besar.  Selain itu, Kafka mendukung setidaknya beberapa perusahaan komersial besar (misalnya, kami menggunakan versi Confluent), dan Kafka memiliki ekosistem yang dikembangkan. <br><br clear="left"></p><br><h1 id="obzor-kafka">  Tinjau Kafka </h1><br><p>  Sebelum memulai, saya langsung merekomendasikan buku yang bagus - <em>â€œKafka: The Definitive Guideâ€</em> (juga dalam terjemahan Rusia, tetapi istilah-istilahnya sedikit mematahkan otak).  Di dalamnya Anda dapat menemukan informasi yang diperlukan untuk pemahaman dasar tentang Kafka dan bahkan sedikit lagi.  Dokumentasi Apache sendiri dan blog Confluent juga ditulis dengan baik dan mudah dibaca. </p><br><p>  Jadi, mari kita lihat bagaimana Kafka adalah pandangan mata burung.  Topologi dasar Kafka terdiri dari produsen, konsumen, broker, dan penjaga kebun binatang. </p><br><h3 id="broker">  Pialang </h3><br><p><img src="https://habrastorage.org/webt/ng/o6/l2/ngo6l2ngibz7krlckw0mpdy2x88.png"></p><br><p>  Pialang bertanggung jawab untuk menyimpan data Anda.  Semua data disimpan dalam bentuk biner, dan broker tidak tahu banyak tentang apa mereka dan apa struktur mereka. </p><br><p>  Setiap jenis peristiwa logis biasanya terletak di topik yang terpisah (topik).  Misalnya, acara pembuatan iklan dapat jatuh ke dalam topik item.created, dan acara perubahannya dapat jatuh ke item.changed.  Topik dapat dianggap sebagai pengklasifikasi acara.  Di tingkat topik, Anda dapat mengatur parameter konfigurasi seperti: </p><br><ul><li>  volume data yang disimpan dan / atau usianya (retention.bytes, retention.ms); </li><li>  faktor redundansi data (faktor replikasi); </li><li>  ukuran maksimum satu pesan (max.message.bytes); </li><li>  jumlah minimum dari replika konsisten di mana data dapat ditulis ke topik (min.insync.replicas); </li><li>  kemampuan untuk failover ke replika lagging non-sinkron dengan kehilangan data potensial (haram.leader.election.enable); </li><li>  dan banyak lagi ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://kafka.apache.org/documentation/#topicconfigs</a> ). </li></ul><br><p>  Pada gilirannya, setiap topik dibagi menjadi satu atau lebih partisi (partisi).  Di partisi itulah peristiwa akhirnya jatuh.  Jika ada lebih dari satu broker di cluster, maka partisi akan didistribusikan secara merata di antara semua broker (sejauh mungkin), yang akan memungkinkan Anda untuk skala beban penulisan dan membaca dalam satu topik ke beberapa broker sekaligus. </p><br><p>  Pada disk, data untuk setiap partisi disimpan sebagai file segmen, secara default sama dengan satu gigabyte (dikontrol melalui log.segment.bytes).  Fitur penting adalah bahwa data dihapus dari partisi (ketika retensi dipicu) hanya oleh segmen (Anda tidak dapat menghapus satu peristiwa dari partisi, Anda dapat menghapus hanya seluruh segmen, dan hanya tidak aktif). </p><br><h3 id="zookeeper">  Penjaga kebun binatang </h3><br><p> Zookeeper bertindak sebagai repositori dan koordinator metadata.  Dialah yang mampu mengatakan apakah broker hidup (Anda dapat melihatnya melalui mata penjaga kebun binatang melalui perintah zookeeper-shell <code>ls /brokers/ids</code> ), yang mana dari broker adalah pengontrol ( <code>get /controller</code> ), apakah partisi tersebut dalam keadaan sinkron dengan replika mereka ( <code>get /brokers/topics/topic_name/partitions/partition_number/state</code> ).  Juga, produsen dan konsumen akan pergi ke penjaga kebun binatang terlebih dahulu untuk mencari tahu di broker mana topik dan partisi disimpan.  Dalam kasus ketika faktor replikasi lebih besar dari 1 ditentukan untuk topik, penjaga kebun binatang akan menunjukkan partisi mana yang menjadi pemimpin (mereka akan ditulis dan dibaca dari).  Dalam hal terjadi kecelakaan broker, di penjaga kebun itulah informasi tentang partisi pemimpin baru akan direkam (pada versi 1.1.0 secara tidak sinkron, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dan ini penting</a> ). </p><br><p>  Dalam versi Kafka yang lebih lama, zookeeper juga bertanggung jawab untuk menyimpan offset, tetapi sekarang mereka disimpan dalam topik khusus <code>__consumer_offsets</code> pada broker (walaupun Anda masih bisa menggunakan zookeeper untuk keperluan ini). </p><br><p>  Cara termudah untuk mengubah data Anda menjadi labu hanyalah hilangnya informasi dengan penjaga kebun binatang.  Dalam skenario seperti itu, akan sangat sulit untuk memahami apa dan dari mana membaca. </p><br><h3 id="producer">  Produser </h3><br><p>  Produser adalah layanan yang paling sering menulis data langsung ke Apache Kafka.  Produser memilih topik, di mana pesan tematiknya akan disimpan, dan mulai menulis informasi kepadanya.  Misalnya, seorang produser bisa menjadi layanan iklan.  Dalam hal ini, ia akan mengirim acara seperti "iklan dibuat", "iklan diperbarui", "iklan dihapus", dll. Ke topik tematik.  Setiap acara adalah pasangan nilai kunci. </p><br><p>  Secara default, semua acara didistribusikan oleh partisi partisi dengan round-robin jika kunci tidak diatur (kehilangan urutan), dan melalui MurmurHash (kunci) jika kunci ada (memesan dalam partisi yang sama). </p><br><p>  Perlu segera dicatat di sini bahwa Kafka menjamin urutan acara hanya dalam satu partisi.  Namun pada kenyataannya, seringkali ini bukan masalah.  Misalnya, Anda dapat dengan yakin menambahkan semua perubahan pengumuman yang sama ke satu partisi (dengan demikian menjaga urutan perubahan ini dalam pengumuman).  Anda juga dapat memasukkan nomor urut di salah satu bidang acara. </p><br><h3 id="consumer">  Konsumen </h3><br><p><img src="https://habrastorage.org/webt/z_/ab/oo/z_abooprhxbjgwpaqmjcdplsalc.png"></p><br><p>  Konsumen bertanggung jawab untuk mengambil data dari Apache Kafka.  Jika Anda kembali ke contoh di atas, konsumen dapat menjadi layanan moderasi.  Layanan ini akan berlangganan ke topik layanan pengumuman, dan ketika iklan baru muncul, ia akan menerimanya dan menganalisisnya untuk kepatuhan dengan beberapa kebijakan tertentu. </p><br><p>  Apache Kafka mengingat kejadian terkini apa yang diterima konsumen (topik layanan <code>__consumer__offsets</code> digunakan untuk ini), dengan demikian memastikan bahwa setelah membaca dengan sukses, konsumen tidak akan menerima pesan yang sama dua kali.  Namun demikian, jika Anda menggunakan opsi enable.auto.commit = benar dan sepenuhnya memberikan pekerjaan melacak posisi konsumen dalam topik ke Kafka, Anda dapat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kehilangan data</a> .  Dalam kode produksi, posisi konsumen paling sering dikontrol secara manual (pengembang mengontrol momen ketika komit dari peristiwa baca harus terjadi). </p><br><p>  Dalam kasus di mana satu konsumen tidak cukup (misalnya, aliran acara baru sangat besar), Anda dapat menambah beberapa konsumen dengan menghubungkan mereka bersama-sama dalam kelompok konsumen.  Kelompok konsumen secara logis adalah konsumen yang persis sama, tetapi dengan distribusi data di antara anggota kelompok.  Ini memungkinkan masing-masing peserta untuk mengambil bagian dari pesan mereka, sehingga meningkatkan kecepatan membaca. </p><br><h1 id="rezultaty-testirovaniya">  Hasil tes </h1><br><p><img src="https://habrastorage.org/webt/9w/fg/vy/9wfgvyrgh5ms1uhd8iutqqvu11k.png" width="300" alt="gambar" align="left"></p><br><p>  Di sini saya tidak akan menulis banyak teks penjelasan, cukup bagikan hasilnya.  Pengujian dilakukan pada 3 mesin fisik (12 CPU, 384GB RAM, 15k SAS DISK, 10GBit / s Net), broker dan penjaga kebun dikerahkan di lxc. </p><br><p>  <strong>Pengujian kinerja</strong> </p><br><p>  Selama pengujian, hasil berikut diperoleh. </p><br><ul><li>  Kecepatan merekam pesan dalam ukuran 1KB secara bersamaan oleh 9 produsen - 1.300.000 peristiwa per detik. </li><li>  Kecepatan membaca pesan 1KB pada saat yang sama oleh 9 konsumen - 1.500.000 acara per detik. </li></ul><br><p>  <strong>Pengujian toleransi kesalahan</strong> </p><br><p>  Selama pengujian, hasil berikut diperoleh (3 broker, 3 penjaga kebun). </p><br><ul><li>  Pengakhiran abnormal salah satu broker tidak mengarah pada penangguhan atau tidak dapat diaksesnya kluster.  Pekerjaan berlanjut seperti biasa, tetapi broker lainnya memiliki beban besar. </li><li>  Pemutusan abnormal dua broker dalam kasus cluster tiga broker dan min.isr = 2 mengarah pada tidak dapat diaksesnya cluster untuk menulis, tetapi untuk keterbacaan.  Dalam kasus min.isr = 1, kluster terus tersedia untuk membaca dan menulis.  Namun, mode ini bertentangan dengan persyaratan untuk keamanan data yang tinggi. </li><li>  Penghentian yang tidak normal dari salah satu server Zookeeper tidak mengarah ke shutdown cluster atau tidak dapat diaksesnya.  Pekerjaan berlanjut seperti biasa. </li><li>  Pengakhiran yang tidak normal dari dua server Zookeeper menyebabkan cluster tidak dapat diakses hingga setidaknya satu dari server Zookeeper dipulihkan.  Pernyataan ini berlaku untuk sekelompok server 3 Zookeeper.  Akibatnya, setelah penelitian, diputuskan untuk meningkatkan cluster Zookeeper menjadi 5 server untuk meningkatkan toleransi kesalahan. <br clear="left"></li></ul><br><h1 id="kafka-as-a-service">  Kafka sebagai layanan </h1><br><p><img src="https://habrastorage.org/webt/cc/hg/y_/cchgy_e8d7-cztjd5ltu97kfs2o.jpeg" width="300" alt="gambar" align="left"></p><br><p>  Kami memastikan bahwa Kafka adalah teknologi luar biasa yang memungkinkan kami untuk menyelesaikan set tugas untuk kami (mengimplementasikan broker pesan).  Namun demikian, kami memutuskan untuk melarang layanan mengakses langsung Kafka dan menutupnya dengan layanan data-bus.  Kenapa kita melakukan ini?  Sebenarnya ada beberapa alasan. </p><br><ul><li><p>  Data-bus mengambil alih semua tugas yang terkait dengan integrasi dengan Kafka (implementasi dan konfigurasi konsumen dan produsen, pemantauan, peringatan, pencatatan, penskalaan, dll.).  Dengan demikian, integrasi dengan broker pesan sesederhana mungkin. </p><br></li><li><p>  Data-bus diizinkan untuk abstrak dari bahasa atau perpustakaan tertentu untuk bekerja dengan Kafka. </p><br></li><li><p>  Bus data memungkinkan layanan lain untuk abstrak dari lapisan penyimpanan.  Mungkin pada titik tertentu kita akan mengubah Kafka menjadi Pulsar, dan tidak ada yang akan melihat apa-apa (semua layanan hanya tahu tentang API data-bus). </p><br></li><li><p>  Bus data mengambil alih validasi skema acara. </p><br></li><li><p>  Menggunakan otentikasi data-bus diimplementasikan. </p><br></li><li><p>  Di bawah sampul data-bus, kita dapat, tanpa downtime, secara diam-diam memperbarui versi Kafka, melakukan konfigurasi terpusat dari produsen, konsumen, broker, dll. </p><br></li><li><p>  Data-bus memungkinkan kami untuk menambahkan fitur yang kami butuhkan yang tidak ada di Kafka (seperti audit topik, memantau anomali di cluster, membuat DLQ, dll.). </p><br></li><li><p>  Data-bus memungkinkan failover diimplementasikan secara terpusat untuk semua layanan. </p><br></li></ul><br><p>  Saat ini, untuk mulai mengirim acara ke broker pesan, cukup sambungkan perpustakaan kecil ke kode layanan Anda.  Itu saja.  Anda memiliki kesempatan untuk menulis, membaca, dan skala dengan satu baris kode.  Seluruh implementasi tersembunyi dari Anda, hanya beberapa batang seperti ukuran bets menonjol.  Di bawah tenda, layanan data-bus meningkatkan jumlah instans produsen dan konsumen yang diperlukan di Kubernetes dan menambahkan konfigurasi yang diperlukan untuk mereka, tetapi semua ini transparan untuk layanan Anda. </p><br><p>  Tentu saja, tidak ada peluru perak, dan pendekatan ini memiliki keterbatasan. </p><br><ul><li>  Data-bus perlu didukung sendiri, tidak seperti perpustakaan pihak ketiga. </li><li>  Data-bus meningkatkan jumlah interaksi antara layanan dan broker pesan, yang mengarah pada kinerja yang lebih rendah dibandingkan dengan Kafka telanjang. </li><li>  Tidak semuanya bisa begitu saja disembunyikan dari layanan, kami tidak ingin menduplikasi fungsi KSQL atau Kafka Streaming di bus data, jadi terkadang Anda harus mengizinkan layanan untuk langsung pergi. </li></ul><br><p>  Dalam kasus kami, pro lebih besar daripada kontra, dan keputusan untuk meliput broker pesan dengan layanan terpisah dibenarkan.  Selama tahun operasi, kami tidak mengalami kecelakaan dan masalah serius. </p><br><p>  PS Terima kasih kepada pacar saya, Ekaterina Oblyalyaeva, untuk gambar-gambar keren untuk artikel ini.  Jika Anda menyukainya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ada</a> lebih banyak ilustrasi. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id465315/">https://habr.com/ru/post/id465315/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id465299/index.html">Apache NIFI - Tinjauan Singkat Fitur dalam Praktek</a></li>
<li><a href="../id465301/index.html">Cara membangun proses tata letak e-commerce untuk mendapatkan semua data yang Anda butuhkan</a></li>
<li><a href="../id465303/index.html">Moskow melatih (dan tidak hanya): apa yang telah berubah dan terima kasih kepada mereka yang telah membantu</a></li>
<li><a href="../id465309/index.html">Saya pelit terbesar dalam pengembangan game indie</a></li>
<li><a href="../id465311/index.html">Sistem pemantauan kendaraan DIY</a></li>
<li><a href="../id465319/index.html">Kesalahpahaman masa lalu</a></li>
<li><a href="../id465321/index.html">Di masa depan, para ilmuwan mungkin belajar untuk memprediksi dengan tepat apa yang akan Anda ingat.</a></li>
<li><a href="../id465323/index.html">Apa yang akan menjadi kriptografi pasca-kuantum?</a></li>
<li><a href="../id465325/index.html">Benda spesial yang sulit untuk direbut robot</a></li>
<li><a href="../id465329/index.html">Model pembelajaran mesin yang diinterpretasikan. Bagian 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
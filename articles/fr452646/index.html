<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍❤️‍💋‍👨 👨🏿‍🔧 ⬜️ Ce que le réseau neuronal a vu dans la première photographie d'un trou noir ♻️ 🐌 🙇🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mes amis, beaucoup se souviennent probablement des images du trou noir qui ont choqué tout le monde en avril de cette année. Nous avons trouvé un maté...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ce que le réseau neuronal a vu dans la première photographie d'un trou noir</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/452646/"> Mes amis, beaucoup se souviennent probablement des images du trou noir qui ont choqué tout le monde en avril de cette année.  Nous avons trouvé un matériau très intéressant dans lequel nous parlerons de ce que les algorithmes d'intelligence artificielle «pensent» de l'image d'un trou noir.  En traduisant ce matériel, nous continuons une série de publications dédiées au lancement du cours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Python Neural Networks</a> .  Nous vous avertissons que le matériel s'est avéré plus divertissant qu'informatif, mais ces images valent vraiment la peine d'être vues.  Allons-y. <br><br><img src="https://habrastorage.org/webt/8j/sh/jj/8jshjjmsaffjfpythqwm4zj8wpe.png"><br><br>  Le 11 avril, des scientifiques et des ingénieurs de l'équipe du télescope Event Horizon ont fait une véritable percée dans la compréhension des processus qui se produisent dans l'espace.  Ils ont présenté la première image (photographie) d'un trou noir.  Cela a encore renforcé la théorie générale de la relativité d'Einstein, à savoir l'hypothèse selon laquelle «les objets massifs provoquent une distorsion dans l'espace-temps, qui se reflète sous la forme de changements gravitationnels». <a name="habracut"></a><br><br>  Eh bien, je ne suis ni physicien ni astronome pour comprendre ou expliquer comment cela fonctionne, mais moi, comme des millions de personnes travaillant dans divers domaines, je suis fasciné par l'espace et surtout par le phénomène du trou noir.  La première image d'un trou noir a provoqué une vague de délices dans le monde entier.  Je suis un spécialiste de l'apprentissage profond, qui travaille principalement avec les réseaux de neurones convolutionnels, et il est devenu intéressant pour moi que les algorithmes d'intelligence artificielle «réfléchissent» à l'image d'un trou noir.  C'est ce dont nous parlerons dans l'article. <br><br>  Cet extrait de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Epoch Times</a> décrit le trou noir comme suit: «Les trous noirs sont constitués de« beaucoup de matière emballée dans un très petit espace », principalement formée de« les restes d'une grande étoile décédée lors d'une explosion de supernova ».  Les trous noirs ont un champ gravitationnel si puissant que même la lumière ne peut y échapper.  L'image résultante du trou noir M87 est présentée ci-dessous.  Ce phénomène est bien expliqué dans l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">«Comment donner un sens à l'image du trou noir, selon 2 astrophysiciens»</a> . <br><br><img src="https://habrastorage.org/webt/gs/nb/0p/gsnb0phqngbnxbjlcvq8luifema.png"><br>  <i>Black Hole - M87 - Télescope Event Horizon</i> <br><br><img src="https://habrastorage.org/webt/w1/x_/av/w1x_aviwkbyf5p7qtlvy847ques.png"><br><br>  <i>Différentes zones d'un trou noir.</i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Capture d'écran de la vidéo vox - Pourquoi cette photo du trou noir est si importante</a></i> <br><br>  <b>1. Ce que CCN voit dans l'image d'un trou noir</b> <br><br>  CCN (Convolution Neural Network) - réseaux de neurones à convolution - une classe d'algorithmes d'apprentissage en profondeur qui est extrêmement efficace pour reconnaître des objets du monde réel.  Les CCN sont les meilleurs réseaux de neurones pour interpréter et reconnaître les images.  Ces réseaux de neurones sont formés sur un million d'images et formés pour reconnaître environ 1000 objets différents du monde environnant.  J'ai pensé à montrer l'image d'un trou noir à deux réseaux de neurones convolutionnels formés et voir comment ils le reconnaissent, quel objet du monde qui l'entoure ressemble à un trou noir.  Ce n'est pas une idée sage, car l'image d'un trou noir a été générée en combinant divers signaux reçus de l'espace à l'aide d'un équipement spécial, mais je voulais juste savoir comment l'image serait interprétée sans aucune information supplémentaire sur les signaux. <br><br><img src="https://habrastorage.org/webt/f4/h1/nq/f4h1nqbo52-rnqhn6b2pikkkl5w.png"><br>  <i>VGG-16 Neural Network Forecast - Correspondance</i> <br><br><img src="https://habrastorage.org/webt/es/bu/dg/esbudgztfeyyhlgviplxi1tvz7c.png"><br>  <i>VGG-19 Neural Network Forecast - Correspondance</i> <br><br><img src="https://habrastorage.org/webt/ob/gt/nk/obgtnkongvpjq7tmmevhxwntw7q.png"><br>  <i>Réseau de neurones Forecast ResNet-50 - Bougie</i> <br><br>  Comme nous le voyons dans les images ci-dessus, les VGG-16 et VGG-19 entraînés voient un trou noir comme une correspondance, et ResNet-50 pense que c'est une bougie.  Si nous établissons une analogie avec ces objets, nous comprendrons que cela a un certain sens, car l'allumette allumée et la bougie ont un centre sombre entouré d'une dense lumière jaune vif. <br><br>  <b>2. Quels sont les signes CCN extraits de l'image d'un trou noir</b> <br><br>  J'ai fait encore une chose, j'ai visualisé ce que génèrent les couches intermédiaires VGG-16.  Les réseaux d'apprentissage en profondeur sont appelés profonds, car ils ont un certain nombre de couches, et chacun d'eux traite la représentation et les caractéristiques de l'image à l'entrée.  Voyons ce que les différentes couches du réseau apprennent de l'image entrante.  Le résultat était plutôt beau. <br><br><img src="https://habrastorage.org/webt/zw/i8/eb/zwi8ebtigrz5mbqeqqjgr78esn8.png"><br>  <i>64 cartes caractéristiques de la première couche convolutionnelle VGG-16</i> <br><br>  Si vous regardez de plus près, vous verrez qu'une petite zone lumineuse est un signe fort et qu'elle est absorbée après avoir traversé la plupart des filtres.  Certaines sorties de filtre intéressantes sont présentées ci-dessous, et elles ressemblent déjà vraiment à une sorte d'objet céleste. <br><br><img src="https://habrastorage.org/webt/x9/rb/qq/x9rbqqgbkerobilpnnj_6n5y3ii.png"><br>  <i>4 des 64 cartes fonctionnelles de la première couche convolutionnelle</i> <br><br><img src="https://habrastorage.org/webt/1r/oq/em/1roqemadoo5sc4yfdzapffcxs8g.png"><br>  <i>64 cartes caractéristiques de la deuxième couche convolutionnelle VGG-16</i> <br><br>  Zoomez sur des cartes intéressantes de la deuxième couche du réseau neuronal. <br><br><img src="https://habrastorage.org/webt/mx/c8/t6/mxc8t6bhobqs2hfgdfx9qotzhsm.png"><br>  <i>6 des 64 cartes caractéristiques de la deuxième couche convolutionnelle</i> <br><br>  Nous allons maintenant aller encore plus loin et regarder la troisième couche convolutionnelle. <br><br><img src="https://habrastorage.org/webt/qb/5g/ir/qb5girdp83lu2x1hukhmytcjkoe.png"><br>  <i>128 cartes fonctionnelles de la troisième couche convolutionnelle VGG-16</i> <br><br>  Après avoir approché, nous trouvons un modèle familier. <br><br><img src="https://habrastorage.org/webt/zp/03/2h/zp032hluvfctmjnne9q0xr0ezoa.png"><br>  <i>8 des cartes d'entités présentées ci-dessus sur la troisième couche</i> <br><br>  En approfondissant, nous obtenons quelque chose comme ça. <br><br><img src="https://habrastorage.org/webt/tq/hx/bf/tqhxbfgfrm4ngcn4lbleyzk9aqs.png"><br>  <i>6 cartes sur 128 avec 4 couches convolutives VGG-16</i> <br><br>  En approfondissant, nous obtenons des informations abstraites de plus haut niveau, et lorsque nous visualisons les 7e, 8e et 10e couches de la convolution, nous ne verrons que des informations de haut niveau. <br><br><img src="https://habrastorage.org/webt/67/w2/nq/67w2nq6c77rswgp7pirabi3ygv8.png"><br>  <i>Carte des caractéristiques de la 7e couche convolutionnelle</i> <br><br>  Comme nous pouvons le voir, de nombreuses cartes de fonctionnalités sont sombres et n'apprennent que les fonctionnalités de haut niveau spécifiques nécessaires pour reconnaître cette classe.  Dans les couches plus profondes, ils deviennent plus visibles.  Maintenant, nous zoomons et jetons un œil à certains filtres. <br><br><img src="https://habrastorage.org/webt/te/70/-j/te70-ju3qtx7ha4ubdlebknprty.png"><br>  <i>6 cartes fonctionnelles</i> <br><br>  Considérons maintenant 512 cartes de caractéristiques de la 10e couche convolutionnelle. <br><br><img src="https://habrastorage.org/webt/lp/p5/ez/lpp5ezrj0nagikmxjmhea9fdj_c.png"><br>  <i>Cartes fonctionnelles 10 couche convolutionnelle.</i> <br><br>  Vous voyez maintenant que dans la plupart des cartes d'entités reçues, seule la zone d'image est acceptée comme entité.  Ce sont des signes de haut niveau visibles par les neurones.  Examinons de plus près certaines des cartes de fonctionnalités ci-dessus. <br><br><img src="https://habrastorage.org/webt/d8/zb/wh/d8zbwh1jq3tctobr83xquyafnxm.png"><br>  <i>Certaines des cartes fonctionnelles ont 10 niveaux convolutifs, augmentés en taille</i> <br><br>  Maintenant que nous avons vu que CCN essaye de s'isoler d'une image de trou noir, essayons de passer cette image à d'autres algorithmes de réseau neuronal populaires, tels que Neural Style Transfer et DeepDream. <br><br>  <b>3. Nous essayons Neural Style Transfer et Deep Dream sur l'image d'un trou noir</b> <br><br>  <i>Le transfert de style neuronal</i> est un réseau neuronal intelligent qui donne le «style» d'une image à une autre image source et crée finalement une image artistique.  Si vous ne comprenez toujours pas, les images ci-dessous expliqueront le concept.  J'ai utilisé le site <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deepdreamgenerator.com</a></i> pour créer diverses images artistiques à partir de l'image originale du trou noir.  Les photos se sont avérées assez intéressantes. <br><br><img src="https://habrastorage.org/webt/ti/li/xc/tilixcoaches3m1oeft0_feuxh4.png"><br>  <i>Style de transmission.</i>  <i>Images générées à l'aide de deepdreamgenerator.com</i> <br><br>  <i>DeepDream</i> est un programme de vision par ordinateur créé par l'ingénieur Google Alexander Mordvintsev qui utilise un réseau neuronal convolutif pour rechercher et améliorer les modèles dans les images à l'aide d'une para-idole algorithmique, créant ainsi une image hallucinogène à partir d'images traitées intentionnellement. <br><br><img src="https://habrastorage.org/webt/1a/mu/hs/1amuhs5f5ixbxq1emqtj8o5jpe4.png"><br>  <i>Rêve profond</i>  <i>Images générées à l'aide de deepdreamgenerator.com</i> <br><br>  Dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ces vidéos</a> sur Deep Dream, vous verrez comment des images hallucinantes peuvent être créées. <br><br>  C'est tout!  J'ai été extrêmement choqué quand j'ai vu la première photo d'un trou noir et j'ai immédiatement écrit ce petit article.  Les informations qu'il contient peuvent ne pas être si utiles, mais les images créées lors de son écriture et illustrées ci-dessus en valent la peine.  Profitez des photos! <br><br>  Écrivez dans les commentaires comment vous obtenez le matériel.  Nous attendons tout <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le</a> monde à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la porte ouverte</a> du cours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">"Réseaux de neurones en Python"</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr452646/">https://habr.com/ru/post/fr452646/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr452628/index.html">Feuille inférieure personnalisée: comment cela devrait fonctionner</a></li>
<li><a href="../fr452630/index.html">Sauvegarde, Partie 2: Présentation et test des outils de sauvegarde basés sur rsync</a></li>
<li><a href="../fr452638/index.html">Comment nous avons lancé 2GIS sous CarPlay et nous démêlons toujours</a></li>
<li><a href="../fr452642/index.html">La force de la foule. Comment Chicago a développé un robot poubelle - un nettoyeur de rivière</a></li>
<li><a href="../fr452644/index.html">Conférence des développeurs Web DevConf X - 21 juin</a></li>
<li><a href="../fr452648/index.html">PHP: Comment analyser un fichier XML complexe et ne pas se noyer dans le code natif</a></li>
<li><a href="../fr452652/index.html">Security Week 21: un trou dans Whatsapp, une nouvelle vulnérabilité dans les processeurs Intel, Zero-Day dans Windows</a></li>
<li><a href="../fr452656/index.html">Développement du «firmware» le plus simple pour les FPGA installés dans Redd, et débogage en utilisant le test de mémoire comme exemple</a></li>
<li><a href="../fr452662/index.html">Serveurs HPE à Selectel</a></li>
<li><a href="../fr452664/index.html">J'ai facturé 18 000 $ pour une page Web statique ... et je m'en suis sorti</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
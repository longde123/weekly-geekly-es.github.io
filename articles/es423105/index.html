<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⚜️ 📘 🍠 System.IO.Pipelines: IO de alto rendimiento en .NET 🔓 🎷 🐻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="System.IO.Pipelines es una nueva biblioteca que simplifica la organización del código en .NET. Es difícil garantizar un alto rendimiento y precisión s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>System.IO.Pipelines: IO de alto rendimiento en .NET</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/423105/">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">System.IO.Pipelines</a> es una nueva biblioteca que simplifica la organización del código en .NET.  Es difícil garantizar un alto rendimiento y precisión si tiene que lidiar con un código complejo.  La tarea de System.IO.Pipelines es simplificar el código.  Más detalles debajo del corte! <br><br><img src="https://habrastorage.org/webt/nq/me/p-/nqmep-tqvyyv5nlkpcxjnmlw8z4.jpeg"><a name="habracut"></a><br><br>  La biblioteca surgió como resultado de los esfuerzos del equipo de desarrollo de .NET Core para hacer de Kestrel uno de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">los servidores web más rápidos de la industria</a> .  Originalmente fue concebido como parte de la implementación de Kestrel, pero se ha convertido en una API reutilizable, disponible en la versión 2.1 como una API BCL de primera clase (System.IO.Pipelines). <br><br><h2>  ¿Qué problemas resuelve ella? </h2><br>  Para analizar adecuadamente los datos de una secuencia o socket, debe escribir una gran cantidad de código estándar.  Al mismo tiempo, hay muchas trampas que complican el código en sí y su soporte. <br><br><h2>  ¿Qué dificultades surgen hoy? </h2><br>  Comencemos con una tarea simple.  Necesitamos escribir un servidor TCP que reciba mensajes delimitados por línea (\ n) del cliente. <br><br><h2>  Servidor TCP con NetworkStream </h2><br>  DESVIACIÓN: como en cualquier tarea que requiera un alto rendimiento, cada caso específico debe considerarse en función de las características de su aplicación.  Puede que no tenga sentido gastar recursos en el uso de varios enfoques, que se discutirán más adelante, si la escala de la aplicación de red no es muy grande. <br><br>  El código .NET normal antes de usar tuberías se parece a esto: <br><br><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> buffer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">1024</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> stream.ReadAsync(buffer, <span class="hljs-number"><span class="hljs-number">0</span></span>, buffer.Length); <span class="hljs-comment"><span class="hljs-comment">// Process a single line from the buffer ProcessLine(buffer); }</span></span></code> </pre> <br>  ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sample1.cs</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a> <br><br>  Este código probablemente funcionará con pruebas locales, pero tiene varios errores: <br><br><ul><li>  Quizás después de una sola llamada a ReadAsync, no se reciba el mensaje completo (hasta el final de la línea). </li><li>  Ignora el resultado del método stream.ReadAsync (): la cantidad de datos realmente transferidos al búfer. </li><li>  El código no maneja la recepción de varias líneas en una sola llamada ReadAsync. </li></ul><br>  Estos son los errores de lectura de datos de transmisión más comunes.  Para evitarlos, debe realizar una serie de cambios: <br><br><ul><li>  Necesita almacenar en búfer los datos entrantes hasta que se encuentre una nueva línea. </li><li>  Es necesario analizar todas las líneas devueltas al búfer. </li></ul><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> buffer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">1024</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesBuffered = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesRead = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> stream.ReadAsync(buffer, bytesBuffered, buffer.Length - bytesBuffered); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (bytesRead == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// EOF break; } // Keep track of the amount of buffered bytes bytesBuffered += bytesRead; var linePosition = -1; do { // Look for a EOL in the buffered data linePosition = Array.IndexOf(buffer, (byte)'\n', bytesConsumed, bytesBuffered - bytesConsumed); if (linePosition &gt;= 0) { // Calculate the length of the line based on the offset var lineLength = linePosition - bytesConsumed; // Process the line ProcessLine(buffer, bytesConsumed, lineLength); // Move the bytesConsumed to skip past the line we consumed (including \n) bytesConsumed += lineLength + 1; } } while (linePosition &gt;= 0); } }</span></span></code> </pre> <br>  ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sample2.cs</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a> <br><br>  Repito: esto podría funcionar con pruebas locales, pero a veces hay cadenas de más de 1 Kb (1024 bytes).  Es necesario aumentar el tamaño del búfer de entrada hasta que se encuentre una nueva línea. <br><br>  Además, recopilamos buffers en una matriz cuando procesamos cadenas largas.  Podemos mejorar este proceso con ArrayPool, que evita la reasignación de buffers durante el análisis de largas colas desde el cliente. <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] buffer = ArrayPool&lt;<span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>&gt;.Shared.Rent(<span class="hljs-number"><span class="hljs-number">1024</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesBuffered = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Calculate the amount of bytes remaining in the buffer var bytesRemaining = buffer.Length - bytesBuffered; if (bytesRemaining == 0) { // Double the buffer size and copy the previously buffered data into the new buffer var newBuffer = ArrayPool&lt;byte&gt;.Shared.Rent(buffer.Length * 2); Buffer.BlockCopy(buffer, 0, newBuffer, 0, buffer.Length); // Return the old buffer to the pool ArrayPool&lt;byte&gt;.Shared.Return(buffer); buffer = newBuffer; bytesRemaining = buffer.Length - bytesBuffered; } var bytesRead = await stream.ReadAsync(buffer, bytesBuffered, bytesRemaining); if (bytesRead == 0) { // EOF break; } // Keep track of the amount of buffered bytes bytesBuffered += bytesRead; do { // Look for a EOL in the buffered data linePosition = Array.IndexOf(buffer, (byte)'\n', bytesConsumed, bytesBuffered - bytesConsumed); if (linePosition &gt;= 0) { // Calculate the length of the line based on the offset var lineLength = linePosition - bytesConsumed; // Process the line ProcessLine(buffer, bytesConsumed, lineLength); // Move the bytesConsumed to skip past the line we consumed (including \n) bytesConsumed += lineLength + 1; } } while (linePosition &gt;= 0); } }</span></span></code> </pre> <br>  <i>ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sample3.cs</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a></i> <br><br>  El código funciona, pero ahora el tamaño del búfer ha cambiado, como resultado, aparecen muchas copias.  También se usa más memoria, ya que la lógica no reduce el búfer después de procesar las líneas.  Para evitar esto, puede guardar la lista de búferes, en lugar de cambiar el tamaño del búfer cada vez que una cadena llega a más de 1 Kb. <br><br>  Además, no aumentamos el tamaño del búfer de 1 KB, hasta que esté completamente vacío.  Esto significa que transferiremos memorias intermedias cada vez más pequeñas a ReadAsync, como resultado, aumentará la cantidad de llamadas al sistema operativo. <br><br>  Intentaremos eliminar esto y asignaremos un nuevo buffer tan pronto como el tamaño del existente sea menor a 512 bytes: <br><br><pre> <code class="cs hljs"> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">BufferSegment</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] Buffer { <span class="hljs-keyword"><span class="hljs-keyword">get</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> Count { <span class="hljs-keyword"><span class="hljs-keyword">get</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> Remaining =&gt; Buffer.Length - Count; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> minimumBufferSize = <span class="hljs-number"><span class="hljs-number">512</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segments = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> List&lt;BufferSegment&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumedBufferIndex = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segment = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> BufferSegment { Buffer = ArrayPool&lt;<span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>&gt;.Shared.Rent(<span class="hljs-number"><span class="hljs-number">1024</span></span>) }; segments.Add(segment); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Calculate the amount of bytes remaining in the buffer if (segment.Remaining &lt; minimumBufferSize) { // Allocate a new segment segment = new BufferSegment { Buffer = ArrayPool&lt;byte&gt;.Shared.Rent(1024) }; segments.Add(segment); } var bytesRead = await stream.ReadAsync(segment.Buffer, segment.Count, segment.Remaining); if (bytesRead == 0) { break; } // Keep track of the amount of buffered bytes segment.Count += bytesRead; while (true) { // Look for a EOL in the list of segments var (segmentIndex, segmentOffset) = IndexOf(segments, (byte)'\n', bytesConsumedBufferIndex, bytesConsumed); if (segmentIndex &gt;= 0) { // Process the line ProcessLine(segments, segmentIndex, segmentOffset); bytesConsumedBufferIndex = segmentOffset; bytesConsumed = segmentOffset + 1; } else { break; } } // Drop fully consumed segments from the list so we don't look at them again for (var i = bytesConsumedBufferIndex; i &gt;= 0; --i) { var consumedSegment = segments[i]; // Return all segments unless this is the current segment if (consumedSegment != segment) { ArrayPool&lt;byte&gt;.Shared.Return(consumedSegment.Buffer); segments.RemoveAt(i); } } } } (int segmentIndex, int segmentOffest) IndexOf(List&lt;BufferSegment&gt; segments, byte value, int startBufferIndex, int startSegmentOffset) { var first = true; for (var i = startBufferIndex; i &lt; segments.Count; ++i) { var segment = segments[i]; // Start from the correct offset var offset = first ? startSegmentOffset : 0; var index = Array.IndexOf(segment.Buffer, value, offset, segment.Count - offset); if (index &gt;= 0) { // Return the buffer index and the index within that segment where EOL was found return (i, index); } first = false; } return (-1, -1); }</span></span></code> </pre> <br>  <i>ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sample4.cs</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a></i> <br><br>  Como resultado, el código es significativamente complicado.  Durante la búsqueda del delimitador, rastreamos los buffers llenos.  Para hacer esto, use una Lista, que muestra datos almacenados en el búfer cuando busca un nuevo separador de línea.  Como resultado, ProcessLine e IndexOf aceptarán List en lugar de byte [], offset y count.  La lógica de análisis comenzará a procesar un segmento del búfer o varios. <br><br>  Y ahora el servidor procesará mensajes parciales y usará la memoria compartida para reducir el consumo general de memoria.  Sin embargo, se deben realizar varios cambios: <br><br><ol><li>  Desde ArrayPoolbyte utilizamos solo Byte []: matrices administradas de manera estándar.  En otras palabras, cuando se ejecutan las funciones ReadAsync o WriteAsync, el período de validez de los buffers está vinculado al tiempo de la operación asincrónica (para interactuar con las API de E / S propias del sistema operativo).  Dado que la memoria anclada no se puede mover, esto afecta el rendimiento del recolector de basura y puede causar la fragmentación de la matriz.  Es posible que deba cambiar la implementación del grupo, dependiendo de cuánto tiempo esperarán las operaciones asincrónicas para su ejecución. </li><li>  El rendimiento puede mejorarse rompiendo el vínculo entre la lectura y la lógica del proceso.  Obtenemos el efecto del procesamiento por lotes, y ahora la lógica de análisis podrá leer grandes cantidades de datos, procesando grandes bloques de memorias intermedias, en lugar de analizar líneas individuales.  Como resultado, el código se vuelve aún más complicado: <br><br><ul><li>  Es necesario crear dos ciclos que funcionen independientemente uno del otro.  El primero leerá los datos del socket y el segundo analizará los buffers. </li><li>  Lo que se necesita es una forma de decirle a la lógica de análisis que los datos están disponibles. </li><li>  También es necesario determinar qué sucede si el ciclo lee los datos del socket demasiado rápido.  Necesitamos una forma de ajustar el ciclo de lectura si la lógica de análisis no lo mantiene.  Esto se conoce comúnmente como "control de flujo" o "resistencia de flujo". </li><li>  Debemos asegurarnos de que los datos se transmitan de forma segura.  Ahora, tanto el ciclo de lectura como el ciclo de análisis utilizan el conjunto de buffers; funcionan de forma independiente entre sí en diferentes subprocesos. </li><li>  La lógica de administración de memoria también está involucrada en dos partes diferentes de código: tomar prestados datos del grupo de búferes, que lee los datos del socket, y regresar del grupo de búferes, que es la lógica de análisis. </li><li>  Hay que tener mucho cuidado al devolver los buffers después de ejecutar la lógica de análisis.  De lo contrario, existe la posibilidad de que devolvamos el búfer en el que todavía se está escribiendo la lógica de lectura del socket. </li></ul></li></ol><br>  La complejidad comienza a ir por las nubes (¡y esto está lejos de todos los casos!).  Para crear una red de alto rendimiento, debe escribir código muy complejo. <br><br>  El propósito de System.IO.Pipelines es simplificar este procedimiento. <br><br><h4>  Servidor TCP y System.IO.Pipelines </h4><br>  Veamos cómo funciona System.IO.Pipelines: <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Socket socket</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> pipe = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Pipe(); Task writing = FillPipeAsync(socket, pipe.Writer); Task reading = ReadPipeAsync(pipe.Reader); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Task.WhenAll(reading, writing); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">FillPipeAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Socket socket, PipeWriter writer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> minimumBufferSize = <span class="hljs-number"><span class="hljs-number">512</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Allocate at least 512 bytes from the PipeWriter Memory&lt;byte&gt; memory = writer.GetMemory(minimumBufferSize); try { int bytesRead = await socket.ReceiveAsync(memory, SocketFlags.None); if (bytesRead == 0) { break; } // Tell the PipeWriter how much was read from the Socket writer.Advance(bytesRead); } catch (Exception ex) { LogError(ex); break; } // Make the data available to the PipeReader FlushResult result = await writer.FlushAsync(); if (result.IsCompleted) { break; } } // Tell the PipeReader that there's no more data coming writer.Complete(); } async Task ReadPipeAsync(PipeReader reader) { while (true) { ReadResult result = await reader.ReadAsync(); ReadOnlySequence&lt;byte&gt; buffer = result.Buffer; SequencePosition? position = null; do { // Look for a EOL in the buffer position = buffer.PositionOf((byte)'\n'); if (position != null) { // Process the line ProcessLine(buffer.Slice(0, position.Value)); // Skip the line + the \n character (basically position) buffer = buffer.Slice(buffer.GetPosition(1, position.Value)); } } while (position != null); // Tell the PipeReader how much of the buffer we have consumed reader.AdvanceTo(buffer.Start, buffer.End); // Stop reading if there's no more data coming if (result.IsCompleted) { break; } } // Mark the PipeReader as complete reader.Complete(); }</span></span></code> </pre> <br>  <i>ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sample5.cs</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a></i> <br><br>  La versión canalizada de nuestro lector de línea tiene dos bucles: <br><br><ul><li>  FillPipeAsync lee del socket y escribe en PipeWriter. </li><li>  ReadPipeAsync lee de PipeReader y analiza las líneas entrantes. </li></ul><br>  A diferencia de los primeros ejemplos, no hay memorias intermedias asignadas especialmente.  Esta es una de las principales funciones de System.IO.Pipelines.  Todas las tareas de administración de búfer se transfieren a las implementaciones de PipeReader / PipeWriter. <br><br>  El procedimiento se simplifica: utilizamos el código solo para la lógica empresarial, en lugar de implementar una gestión compleja del búfer. <br><br>  En el primer bucle, se llama a PipeWriter.GetMemory (int) para obtener una cierta cantidad de memoria del escritor principal.  Luego se llama PipeWriter.Advance (int), que le dice a PipeWriter cuántos datos se escriben realmente en el búfer.  Esto es seguido por una llamada a PipeWriter.FlushAsync () para que PipeReader pueda acceder a los datos. <br><br>  El segundo bucle consume los buffers que fueron escritos por PipeWriter pero originalmente recibidos del socket.  Cuando se devuelve la solicitud a PipeReader.ReadAsync (), obtenemos un ReadResult que contiene dos mensajes importantes: datos leídos en el formulario ReadOnlySequence, así como el tipo de datos lógico IsCompleted, que le indica al lector si el escritor ha terminado de trabajar (EOF).  Cuando se encuentra el terminador de línea (EOL) y se analiza la cadena, dividiremos el búfer en partes para omitir el fragmento que ya se ha procesado.  Después de eso, se llama a PipeReader.AdvanceTo y le dice a PipeReader cuántos datos se han consumido. <br><br>  Al final de cada ciclo, se completan tanto el lector como el escritor.  Como resultado, el canal principal libera toda la memoria asignada. <br><br><h2>  System.io.pipelines </h2><br><h4>  Lectura parcial </h4><br>  Además de administrar la memoria, System.IO.Pipelines realiza otra función importante: escanea los datos en el canal, pero no los consume. <br><br>  PipeReader tiene dos API principales: ReadAsync y AdvanceTo.  ReadAsync recibe datos del canal, AdvanceTo le dice a PipeReader que el lector ya no necesita estos búferes, por lo que puede deshacerse de ellos (por ejemplo, devolverlos al grupo de búferes principal). <br><br>  El siguiente es un ejemplo de un analizador HTTP que lee datos de buffers de datos de canales parciales hasta que recibe una línea de inicio adecuada. <br><br><img src="https://habrastorage.org/webt/9c/lp/d8/9clpd8h1r6b1m1jrwultkuggw6i.png"><br><br><h2>  ReadOnlySequenceT </h2><br>  La implementación del canal almacena una lista de buffers relacionados pasados ​​entre PipeWriter y PipeReader.  PipeReader.ReadAsync expone ReadOnlySequence, que es un nuevo tipo de BCL y consta de uno o más segmentos ReadOnlyMemory &lt;T&gt;.  Es similar a Span o Memory, lo que nos da la oportunidad de ver matrices y cadenas. <br><br><img src="https://habrastorage.org/webt/79/y0/kw/79y0kwylohggq941soblji6qd2o.png"><br><br>  Dentro del canal hay punteros que muestran dónde se encuentran el lector y el escritor en el conjunto general de datos resaltados, y también los actualizan a medida que los datos se escriben y leen.  SequencePosition es un punto único en una lista vinculada de buffers y se utiliza para separar de manera eficiente ReadOnlySequence &lt;T&gt;. <br><br>  Dado que ReadOnlySequence &lt;T&gt; admite uno o más segmentos, la operación estándar de la lógica de alto rendimiento es separar rutas rápidas y lentas en función del número de segmentos. <br><br>  Como ejemplo, aquí hay una función que convierte ASCII ReadOnlySequence en una cadena: <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">string</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetAsciiString</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">ReadOnlySequence&lt;</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">&gt; buffer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (buffer.IsSingleSegment) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Encoding.ASCII.GetString(buffer.First.Span); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>.Create((<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)buffer.Length, buffer, (span, sequence) =&gt; { <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segment <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sequence) { Encoding.ASCII.GetChars(segment.Span, span); span = span.Slice(segment.Length); } }); }</code> </pre> <br>  ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sample6.cs</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a> <br><br><h4>  Resistencia al flujo y control de flujo </h4><br>  Idealmente, la lectura y el análisis funcionan juntos: el flujo de lectura consume datos de la red y los coloca en buffers, mientras que el flujo de análisis crea estructuras de datos adecuadas.  El análisis generalmente lleva más tiempo que simplemente copiar bloques de datos de la red.  Como resultado, el flujo de lectura puede sobrecargar fácilmente el flujo de análisis.  Por lo tanto, el flujo de lectura se verá obligado a reducir la velocidad o consumir más memoria para guardar datos para el flujo de análisis.  Para garantizar un rendimiento óptimo, se requiere un equilibrio entre la frecuencia de pausa y la asignación de una gran cantidad de memoria. <br><br>  Para resolver este problema, la tubería tiene dos funciones de control de flujo de datos: PauseWriterThreshold y ResumeWriterThreshold.  PauseWriterThreshold determina cuántos datos deben almacenarse antes de que PipeWriter.FlushAsync se detenga.  ResumeWriterThreshold determina cuánta memoria puede consumir el lector antes de que la grabadora reanude la operación. <br><br><img src="https://habrastorage.org/webt/qf/yj/5u/qfyj5u6aahkadlp8nk1gtc9bqr4.png"><br><br>  PipeWriter.FlushAsync "se bloquea" cuando la cantidad de datos en la secuencia canalizada excede el límite establecido en PauseWriterThreshold y se "desbloquea" cuando cae por debajo del límite establecido en ResumeWriterThreshold.  Para evitar exceder el límite de consumo, solo se utilizan dos valores. <br><br><h4>  Programación de E / S </h4><br>  Cuando se usa async / await, las operaciones posteriores generalmente se llaman en los subprocesos del grupo o en el SynchronizationContext actual. <br><br>  Al realizar E / S, es muy importante monitorear cuidadosamente dónde se ejecuta para hacer un mejor uso de la memoria caché del procesador.  Esto es crítico para aplicaciones de alto rendimiento como servidores web.  System.IO.Pipelines utiliza PipeScheduler para determinar dónde ejecutar devoluciones de llamada asincrónicas.  Esto le permite controlar con mucha precisión qué secuencias utilizar para E / S. <br><br>  Un ejemplo de una aplicación práctica es el transporte Kestrel Libuv, en el que las devoluciones de llamadas de E / S se realizan en canales dedicados del bucle de eventos. <br><br><h2>  Hay otros beneficios para la plantilla PipeReader. </h2><br><ul><li>  Algunos sistemas base admiten "esperar sin almacenamiento en búfer": no es necesario asignar un búfer hasta que los datos disponibles aparezcan en el sistema base.  Entonces, en Linux con epoll, no puede proporcionar un búfer de lectura hasta que los datos estén listos.  Esto evita la situación cuando hay muchos subprocesos esperando datos, y necesita reservar inmediatamente una gran cantidad de memoria. </li><li>  La canalización predeterminada facilita la escritura de pruebas unitarias de código de red: la lógica de análisis es independiente del código de red, y las pruebas unitarias solo ejecutan esta lógica en memorias intermedias en la memoria, en lugar de consumirla directamente desde la red.  También facilita la prueba de patrones complejos mediante el envío de datos parciales.  ASP.NET Core lo usa para probar varios aspectos de las herramientas de análisis http de Kestrel. </li><li>  Los sistemas que permiten que el código de usuario use los principales buffers del sistema operativo (por ejemplo, API de E / S de Windows registradas) son inicialmente adecuados para usar tuberías porque la implementación de PipeReader siempre proporciona buffers. </li></ul><br><h4>  Otros tipos relacionados </h4><br>  También agregamos una serie de nuevos tipos de BCL simples a System.IO.Pipelines: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MemoryPoolT</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">IMemoryOwnerT</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MemoryManagerT</a> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ArrayPoolT</a> se agregó en .NET Core 1.0, y en .NET Core 2.1 ahora hay una representación abstracta más general para un grupo que funciona con cualquier MemoryT.  Obtenemos un punto de extensibilidad que nos permite implementar estrategias de distribución más avanzadas, así como controlar la gestión del búfer (por ejemplo, usar búferes predefinidos en lugar de matrices administradas exclusivamente). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">IBufferWriterT</a> es un receptor para grabar datos almacenados temporalmente sincronizados (implementado por PipeWriter). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">IValueTaskSource</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ValueTaskT ha</a> existido desde el lanzamiento de .NET Core 1.1, pero en .NET Core 2.1 ha adquirido herramientas extremadamente efectivas que proporcionan operaciones asincrónicas ininterrumpidas sin distribución.  Ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí para</a> más información. </li></ul><br><h2>  ¿Cómo usar transportadores? </h2><br>  Las API están en el paquete nuget <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">System.IO.Pipelines</a> . <br><br>  Para ver un ejemplo de la aplicación de servidor .NET Server 2.1 que utiliza canalizaciones para procesar mensajes en minúscula (del ejemplo anterior), consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> .  Se puede iniciar usando dotnet run (o Visual Studio).  En el ejemplo, se espera que los datos se transmitan desde el socket en el puerto 8087, luego los mensajes recibidos se escriben en la consola.  Puede usar un cliente, como netcat o putty, para conectarse al puerto 8087.  Envíe un mensaje en minúscula y vea cómo funciona. <br><br>  Actualmente, la tubería se ejecuta en Kestrel y SignalR, y esperamos que encuentre una aplicación más amplia en muchas bibliotecas de red y componentes de la comunidad .NET en el futuro. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es423105/">https://habr.com/ru/post/es423105/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es423093/index.html">Aumentamos la aleatoriedad del hecho de que [probablemente] [casi] por accidente</a></li>
<li><a href="../es423095/index.html">Novedades en la presentación de Apple</a></li>
<li><a href="../es423097/index.html">Tareas y soluciones para el luchador PostgreSQL</a></li>
<li><a href="../es423101/index.html">Implementación de almacenamiento LINSTOR para Proxmox</a></li>
<li><a href="../es423103/index.html">Podcasts de Python: eso es todo lo que hemos encontrado</a></li>
<li><a href="../es423107/index.html">Te invitamos a la reunión Go in Production</a></li>
<li><a href="../es423109/index.html">Qué presentó Apple y qué piensan los desarrolladores de iOS al respecto</a></li>
<li><a href="../es423115/index.html">Efectos mejorados con el modo de fusión de capa de fondo CSS</a></li>
<li><a href="../es423117/index.html">Vive más tiempo o envejece más lento: un enfoque tecnológico para la vejez</a></li>
<li><a href="../es423119/index.html">DIY TTL arcade machine ... en 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüî¨ üîò üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë© C√≥mo cortar un monolito en servicios y mantener el rendimiento de los cach√©s en memoria sin perder consistencia üé± üåì ü§Æ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos Mi nombre es Alexander, soy desarrollador de Java en el grupo de empresas Tinkoff. 

 En este art√≠culo quiero compartir mi experiencia en...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo cortar un monolito en servicios y mantener el rendimiento de los cach√©s en memoria sin perder consistencia</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/tinkoff/blog/474994/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/io/g8/yg/iog8ygcpquu5zvi7xmlsecbbwmu.png"></div><br>  Hola a todos  Mi nombre es Alexander, soy desarrollador de Java en el grupo de empresas Tinkoff. <br><br>  En este art√≠culo quiero compartir mi experiencia en la resoluci√≥n de problemas asociados con la sincronizaci√≥n del estado de las memorias cach√© en sistemas distribuidos.  Nos encontramos con ellos, dividiendo nuestra aplicaci√≥n monol√≠tica en <s>micro</s> servicios.  Obviamente, hablaremos sobre el almacenamiento en cach√© de datos en el nivel JVM, porque con los cach√©s externos, los problemas de sincronizaci√≥n se resuelven fuera del contexto de la aplicaci√≥n. <br><br>  En este art√≠culo, hablar√© sobre nuestra experiencia de cambiar a una arquitectura orientada a servicios, acompa√±ada de un cambio a Kubernetes, y sobre la resoluci√≥n de problemas relacionados.  Consideraremos el enfoque para organizar el sistema de almacenamiento en cach√© distribuido de la cuadr√≠cula de datos en memoria (IMDG), sus ventajas y desventajas, por lo que decidimos escribir nuestra propia soluci√≥n. <br><br>  Este art√≠culo analiza un proyecto cuyo backend est√° escrito en Java.  Por lo tanto, tambi√©n hablaremos sobre est√°ndares en el campo del almacenamiento en cach√© temporal en memoria.  Discutimos la especificaci√≥n JSR-107, la especificaci√≥n JSR-347 fallida y las caracter√≠sticas de almacenamiento en cach√© en Spring.  ¬°Bienvenido a cat! <br><a name="habracut"></a><br><br><h1>  Y cortemos la aplicaci√≥n en servicios ... </h1><br>  Pasaremos a la arquitectura orientada a servicios y nos trasladaremos a Kubernetes, eso es lo que decidimos hace poco m√°s de 6 meses.  Durante mucho tiempo, nuestro proyecto fue un monolito, muchos problemas relacionados con la deuda t√©cnica acumulada, y escribimos nuevos m√≥dulos de aplicaciones como servicios separados.  Como resultado, la transici√≥n a una arquitectura orientada a servicios y un corte monol√≠tico fue inevitable. <br><br>  Nuestra aplicaci√≥n est√° cargada, en promedio 500 rps llega a los servicios web (en pico alcanza los 900 rps).  Para recopilar el modelo de datos completo en respuesta a cada solicitud, debe ir a los diversos cach√©s varios cientos de veces. <br><br>  Intentamos ir a la memoria cach√© remota no m√°s de tres veces por solicitud, seg√∫n el conjunto de datos requerido, y en las memorias cach√© JVM internas, la carga alcanza 90,000 rps por memoria cach√©.  Tenemos alrededor de 30 cach√©s de este tipo para una variedad de entidades y DTO-shki.  En algunos cach√©s cargados, ni siquiera podemos permitirnos eliminar el valor, ya que esto puede conducir a un aumento en el tiempo de respuesta de los servicios web y a un bloqueo en la aplicaci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mn/db/2v/mndb2vp6ot9byy_fqysaooom6j0.png"></div><br>  As√≠ es como se ve el monitoreo de carga, eliminado de las cach√©s internas en cada nodo durante el d√≠a.  Seg√∫n el perfil de carga, es f√°cil ver que la mayor√≠a de las solicitudes son datos le√≠dos.  Una carga de escritura uniforme se debe a la actualizaci√≥n de valores en cach√©s a una frecuencia dada. <br><br>  El tiempo de inactividad no es v√°lido para nuestra aplicaci√≥n.  Por lo tanto, con el prop√≥sito de una implementaci√≥n sin interrupciones, siempre equilibramos todo el tr√°fico entrante a dos nodos e implementamos la aplicaci√≥n utilizando el m√©todo de actualizaci√≥n continua.  Kubernetes se convirti√≥ en nuestra soluci√≥n de infraestructura ideal al cambiar a los servicios.  Por lo tanto, resolvimos varios problemas a la vez. <br><br>
<h3>  El problema de ordenar y establecer constantemente infraestructura para nuevos servicios </h3><br>  Se nos dio un espacio de nombres en el cl√∫ster para cada circuito, que tenemos tres: dev - para desarrolladores, qa - para probadores, prod - para clientes. <br><br>  Con el espacio de nombres resaltado, agregar un nuevo servicio o aplicaci√≥n se reduce a escribir cuatro manifiestos: Implementaci√≥n, Servicio, Ingress y ConfigMap. <br><br><h3>  Alta tolerancia de carga </h3><br>  El negocio se expande y crece constantemente: hace un a√±o, la carga promedio era dos veces menor que la actual. <br><br>  El escalado horizontal en Kubernetes le permite nivelar las econom√≠as de escala al aumentar la carga de trabajo del proyecto desarrollado. <br><br><h3>  Mantenimiento, recopilaci√≥n de registros y monitoreo. </h3><br>  La vida se vuelve mucho m√°s f√°cil cuando no hay necesidad de agregar registros al sistema de registro al agregar cada nodo, configurar la valla de m√©tricas (a menos que tenga un sistema de monitoreo de inserci√≥n), realizar configuraciones de red y simplemente instalar el software necesario para la operaci√≥n. <br><br>  Por supuesto, todo esto se puede automatizar usando Ansible o Terraform, pero al final, escribir manifiestos m√∫ltiples para cada servicio es mucho m√°s f√°cil. <br><br><h3>  Alta fiabilidad </h3><br>  El mecanismo incorporado k8s de Liveness- and Readiness-samples le permite no preocuparse de que la aplicaci√≥n comenz√≥ a ralentizarse o dej√≥ de responder por completo. <br><br>  Kubernetes ahora controla el ciclo de vida de los m√≥dulos de hogar que contienen contenedores de aplicaciones y el tr√°fico que se dirige a ellos. <br><br>  Junto con las comodidades descritas, necesit√°bamos resolver una serie de problemas para que los servicios sean adecuados para el escalado horizontal y el uso de un modelo de datos com√∫n para muchos servicios.  Era necesario resolver dos problemas: <br><br><ol><li>  <b>El estado de la aplicaci√≥n.</b>  Cuando el proyecto se implementa en el cl√∫ster k8s, comienzan a crearse vainas con contenedores de la nueva versi√≥n de la aplicaci√≥n que no est√°n relacionadas con el estado de las vainas de la versi√≥n anterior.  Se pueden generar nuevos pods de aplicaci√≥n en servidores de cl√∫ster arbitrarios que satisfagan las restricciones especificadas.  Adem√°s, ahora todos los contenedores de aplicaciones que se ejecutan dentro del pod Kubernetes pueden destruirse en cualquier momento si la sonda Liveness dice que debe reiniciarse. </li><li>  <b>Consistencia de datos.</b>  Es necesario mantener la coherencia y la integridad de los datos entre s√≠ en todos los nodos.  Esto es especialmente cierto si varios nodos funcionan dentro de un solo modelo de datos.  Es inaceptable que cuando las solicitudes a diferentes nodos de la aplicaci√≥n en la respuesta, los datos inconsistentes lleguen al cliente. </li></ol><br>  En el desarrollo moderno de sistemas escalables, la arquitectura sin estado es la soluci√≥n a los problemas anteriores.  Eliminamos el primer problema moviendo todas las estad√≠sticas al almacenamiento en la nube S3. <br><br>  Sin embargo, debido a la necesidad de agregar un modelo de datos complejo y ahorrar tiempo de respuesta de nuestros servicios web, no podr√≠amos negarnos a almacenar datos en cach√©s en memoria.  Para resolver el segundo problema, escribieron una biblioteca para sincronizar el estado de los cach√©s internos de los nodos individuales. <br><br><h1>  Sincronizamos cach√©s en nodos separados </h1><br>  Como datos iniciales tenemos un sistema distribuido que consta de N nodos.  Cada nodo tiene aproximadamente 20 memorias cach√© en memoria, cuyos datos se actualizan varias veces por hora. <br><br>  La mayor√≠a de los cach√©s tienen una pol√≠tica de actualizaci√≥n de datos TTL (tiempo de vida), algunos datos se actualizan con una operaci√≥n CRON cada 20 minutos debido a la alta carga.  La carga de trabajo en cach√©s var√≠a de varios miles de rps por la noche a varias decenas de miles durante el d√≠a.  La carga m√°xima, como regla, no excede 100,000 rps.  El n√∫mero de registros en el almacenamiento temporal no excede varios cientos de miles y se coloca en el mont√≥n de un nodo. <br><br>  Nuestra tarea es lograr la consistencia de datos entre la misma cach√© en diferentes nodos, as√≠ como el menor tiempo de respuesta posible.  Considere lo que generalmente hay formas de resolver este problema. <br><br>  La primera y m√°s simple soluci√≥n que viene a la mente es poner toda la informaci√≥n en un cach√© remoto.  En este caso, puede deshacerse por completo del estado de la aplicaci√≥n, no pensar en los problemas de lograr la coherencia y tener un √∫nico punto de acceso a un almac√©n de datos temporal. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ez/zm/bg/ezzmbg3cuvhczrwpwmh5hg5a0-o.png"></div><br>  Este m√©todo de almacenamiento temporal de datos es bastante simple, y lo usamos.  Guardamos en cach√© parte de los datos en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Redis</a> , que es un almacenamiento de datos NoSQL en RAM.  En Redis, generalmente registramos un marco de respuesta de servicio web, y para cada solicitud necesitamos enriquecer estos datos con informaci√≥n relevante, para lo cual tenemos que enviar varios cientos de solicitudes al cach√© local. <br><br>  Obviamente, no podemos extraer los datos de las cach√©s internas para el almacenamiento remoto, ya que el costo de transmitir ese volumen de tr√°fico a trav√©s de la red no nos permitir√° cumplir con el tiempo de respuesta requerido. <br><br>  La segunda opci√≥n es usar una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cuadr√≠cula de datos en memoria</a> (IMDG), que es un cach√© distribuido en memoria.  El esquema de tal soluci√≥n es el siguiente: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/l7/ku/k9/l7kuk9uaiuydck1hs1boeykflys.png"></div><br>  La arquitectura IMDG se basa en el principio de Particionamiento de datos de cach√©s internos de nodos individuales.  De hecho, esto se puede llamar una tabla hash distribuida en un grupo de nodos.  IMDG se considera una de las implementaciones m√°s r√°pidas de almacenamiento distribuido temporal. <br><br>  Hay muchas implementaciones de IMDG, la m√°s popular es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Hazelcast</a> .  El cach√© distribuido le permite almacenar datos en RAM en varios nodos de aplicaci√≥n con un nivel aceptable de confiabilidad y preservaci√≥n de la consistencia, que se logra mediante la replicaci√≥n de datos. <br><br>  La tarea de construir una memoria cach√© distribuida de este tipo no es f√°cil, pero usar una soluci√≥n IMDG ya preparada para nosotros podr√≠a convertirse en un buen reemplazo para las memorias cach√© JVM y eliminar los problemas de replicaci√≥n, consistencia y distribuci√≥n de datos entre todos los nodos de la aplicaci√≥n. <br><br>  La mayor√≠a de los proveedores de IMDG para aplicaciones Java implementan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">JSR-107</a> , la API Java est√°ndar para trabajar con cach√©s internos.  En general, este est√°ndar tiene una historia bastante grande, que analizar√© con m√°s detalle a continuaci√≥n. <br><br>  Hab√≠a una vez ideas para implementar su interfaz para interactuar con IMDG - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">JSR 347</a> .  Pero la implementaci√≥n de tal API no recibi√≥ suficiente soporte de la comunidad Java, y ahora tenemos una √∫nica interfaz para interactuar con cach√©s en memoria, independientemente de la arquitectura de nuestra aplicaci√≥n.  Buena o mala es otra cuesti√≥n, pero nos permite ignorar por completo todas las dificultades de implementar un cach√© distribuido en memoria y trabajar con √©l como cach√© de una aplicaci√≥n monol√≠tica. <br><br>  A pesar de las ventajas obvias de usar IMDG, esta soluci√≥n es a√∫n m√°s lenta que la cach√© JVM est√°ndar, debido a la sobrecarga de garantizar la replicaci√≥n continua de los datos distribuidos entre varios nodos JVM, as√≠ como a la copia de seguridad de estos datos.  En nuestro caso, la cantidad de datos para el almacenamiento temporal no era tan grande, los datos con un margen cab√≠an en la memoria de una aplicaci√≥n, por lo que su asignaci√≥n a varias JVM parec√≠a una soluci√≥n innecesaria.  Y el tr√°fico de red adicional entre nodos de aplicaciones bajo cargas pesadas puede afectar en gran medida el rendimiento y aumentar el tiempo de respuesta de los servicios web.  Al final, decidimos escribir nuestra propia soluci√≥n para este problema. <br><br>  Dejamos cach√©s en memoria como almacenamiento temporal de datos y, para mantener la coherencia, utilizamos el gestor de colas RabbitMQ.  Adoptamos el patr√≥n de dise√±o de comportamiento <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Editor - Suscriptor"</a> y mantuvimos la relevancia de los datos al eliminar el registro modificado de la memoria cach√© de cada nodo.  El esquema de soluci√≥n es el siguiente: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/05/y9/di/05y9dihavtlltrsgxxnkvuj5bhs.png"></div><br>  El diagrama muestra un grupo de N nodos, cada uno de los cuales tiene un cach√© est√°ndar en memoria.  Todos los nodos usan un modelo de datos com√∫n y deben ser consistentes.  En el primer acceso al cach√© por una clave arbitraria, el valor en el cach√© est√° ausente y colocamos el valor real de la base de datos en √©l.  Con cualquier cambio, elimine el registro. <br><br>  Aqu√≠ se proporciona informaci√≥n real en la respuesta de cach√© sincronizando la eliminaci√≥n de una entrada cuando se cambia en cualquiera de los nodos.  Cada nodo en el sistema tiene una cola en el gestor de colas RabbitMQ.  La grabaci√≥n en todas las colas se realiza a trav√©s de un punto de acceso de tipo Tema com√∫n.  Esto significa que los mensajes enviados al tema se incluyen en todas las colas asociadas a √©l.  Entonces, al cambiar el valor en cualquier nodo del sistema, este valor se eliminar√° del almacenamiento temporal de cada nodo, y el acceso posterior iniciar√° la escritura del valor actual en la memoria cach√© desde la base de datos. <br><br>  Por cierto, existe un mecanismo similar de PUB / SUB en Redis.  Pero, en mi opini√≥n, a√∫n es mejor usar el gestor de colas para trabajar con colas, y RabbitMQ fue perfecto para nuestra tarea. <br><br><h1>  JSR 107 est√°ndar y su implementaci√≥n </h1><br>  La API de cach√© Java est√°ndar para el almacenamiento temporal de datos en memoria (especificaci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">JSR-107</a> ) tiene una historia bastante larga; se ha desarrollado durante 12 a√±os. <br><br>  Durante tanto tiempo, los enfoques para el desarrollo de software han cambiado, los monolitos han sido reemplazados por la arquitectura de microservicios.  Debido a una falta tan larga de especificaciones para la API de cach√©, incluso ha habido solicitudes para desarrollar cach√©s de API para sistemas distribuidos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">JSR-347</a> (Cuadr√≠culas de datos para la plataforma Java).  Pero despu√©s del tan esperado lanzamiento de JSR-107 y el lanzamiento de JCache, se retir√≥ la solicitud de crear una especificaci√≥n separada para sistemas distribuidos. <br><br>  Durante los largos 12 a√±os en el mercado, el lugar para el almacenamiento temporal de datos ha cambiado de HashMap a ConcurrentHashMap con el lanzamiento de Java 1.5, y m√°s tarde aparecieron muchas implementaciones de c√≥digo abierto preparadas de almacenamiento en cach√© en memoria. <br><br>  Despu√©s del lanzamiento de JSR-107, las soluciones de los proveedores comenzaron a implementar gradualmente la nueva especificaci√≥n.  Para JCache, incluso hay proveedores especializados en almacenamiento en cach√© distribuido: las mismas cuadr√≠culas de datos, cuya especificaci√≥n nunca se ha implementado. <br><br>  Considere en qu√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">consiste el</a> paquete <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">javax.cache</a> y c√≥mo obtener una instancia de cach√© para nuestra aplicaci√≥n: <br><pre><code class="java hljs">CachingProvider provider = Caching.getCachingProvider(<span class="hljs-string"><span class="hljs-string">"org.cache2k.jcache.provider.JCacheProvider"</span></span>); CacheManager cacheManager = provider.getCacheManager(); CacheConfiguration&lt;Integer, String&gt; config = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MutableConfiguration&lt;Integer, String&gt;() .setTypes(Integer.class, String.class) .setReadThrough(<span class="hljs-keyword"><span class="hljs-keyword">true</span></span>) . . .; Cache&lt;Integer, String&gt; cache = cacheManager.createCache(cacheName, config);</code> </pre> <br>  Aqu√≠ el almacenamiento en cach√© es un cargador de arranque para CachingProvider. <br><br>  En nuestro caso, JCacheProvider, que es la implementaci√≥n de cache2k del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SPI del</a> proveedor JSR-107, se cargar√° desde ClassLoader.  Para el cargador, es posible que no tenga que especificar la implementaci√≥n del proveedor, pero luego intentar√° cargar la implementaci√≥n que se encuentra en <br><blockquote>  META-INF / services / javax.cache.spi.CachingProvider </blockquote><br>  En cualquier caso, en ClassLoader deber√≠a haber una implementaci√≥n √∫nica de CachingProvider. <br><br>  Si utiliza la biblioteca javax.cache sin ninguna implementaci√≥n, se generar√° una excepci√≥n cuando intente crear JCache.  El prop√≥sito del proveedor es crear y administrar el ciclo de vida de CacheManager, que, a su vez, es responsable de administrar y configurar los cach√©s.  Por lo tanto, para crear un cach√©, debe ir de la siguiente manera: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fx/lp/fs/fxlpfsdfmlifqegpwtaynhiakt8.png"></div><br>  Los cach√©s est√°ndar creados con CacheManager deben tener una configuraci√≥n compatible con la implementaci√≥n.  La configuraci√≥n de cach√© parametrizada est√°ndar proporcionada por javax.cache se puede extender a una implementaci√≥n espec√≠fica de CacheProvider. <br><br>  Hoy en d√≠a, hay docenas de implementaciones diferentes de la especificaci√≥n JSR-107: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ehcache</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Guava</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cafe√≠na</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cache2k</a> .  Muchas implementaciones son Grid de datos en memoria en sistemas distribuidos: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Hazelcast</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Oracle Coherence</a> . <br><br>  Tambi√©n hay muchas implementaciones de almacenamiento temporal que no son compatibles con la API est√°ndar.  Durante mucho tiempo en nuestro proyecto, utilizamos Ehcache 2, que no es compatible con JCache (la implementaci√≥n de la especificaci√≥n apareci√≥ con Ehcache 3).  La necesidad de una transici√≥n a una implementaci√≥n compatible con JCache apareci√≥ con la necesidad de monitorear el estado de las memorias cach√© en memoria.  Usando el MetricRegistry est√°ndar, fue posible ajustar el monitoreo solo con la ayuda de la implementaci√≥n JCacheGaugeSet, que recopila m√©tricas de JCache est√°ndar. <br><br>  ¬øC√≥mo elegir la implementaci√≥n de cach√© en memoria adecuada para su proyecto?  Quiz√°s deber√≠as prestar atenci√≥n a lo siguiente: <br><br><ol><li>  ¬øNecesita soporte para la especificaci√≥n JSR-107? </li><li>  Tambi√©n vale la pena prestar atenci√≥n a la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">velocidad de la</a> implementaci√≥n seleccionada.  Bajo cargas pesadas, el rendimiento de las memorias cach√© internas puede tener un impacto significativo en el tiempo de respuesta de su sistema. </li><li>  Apoyo en primavera.  Si usa el marco conocido en su proyecto, vale la pena considerar el hecho de que no todas las implementaciones de cach√© JVM tienen un CacheManager compatible en Spring. </li></ol><br>  Si usted, como nosotros, utiliza activamente Spring en su proyecto, entonces para el almacenamiento en cach√© de datos, probablemente se adhiera al enfoque orientado a aspectos (AOP) y use la anotaci√≥n @Cacheable.  Spring utiliza su propio SPI de CacheManager para que los aspectos funcionen.  Se necesita el siguiente bean para que funcionen los cach√©s de primavera: <br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> org.springframework.cache.<span class="hljs-function"><span class="hljs-function">CacheManager </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cacheManager</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ CachingProvider provider = Caching.getCachingProvider(); CacheManager cacheManager = provider.getCacheManager(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JCacheCacheManager(cacheManager); }</code> </pre><br>  Para trabajar con cach√©s en el paradigma AOP, tambi√©n deben considerarse las consideraciones transaccionales.  El cach√© de primavera debe necesariamente admitir la gesti√≥n de transacciones.  Con este fin, Spring CacheManager hereda las propiedades AbstractTransactionSupportingCacheManager, que se pueden usar para sincronizar operaciones de poner / desalojar realizadas dentro de una transacci√≥n y solo ejecutarlas despu√©s de que se haya confirmado una transacci√≥n exitosa. <br><br>  El ejemplo anterior muestra el uso del contenedor JCacheCacheManager para el administrador de especificaciones de cach√©.  Esto significa que cualquier implementaci√≥n de JSR-107 tambi√©n tiene compatibilidad con Spring CacheManager.  Esta es otra raz√≥n para elegir un cach√© en memoria con soporte para la especificaci√≥n JSR para su proyecto.  Pero si todav√≠a no se necesita este soporte, pero realmente quiero usar @Cacheable, entonces tiene soporte para dos soluciones de cach√© internas m√°s: EhCacheCacheManager y CaffeineCacheManager. <br><br>  Al elegir la implementaci√≥n del cach√© en memoria, no tomamos en cuenta el soporte de IMDG para sistemas distribuidos, como se mencion√≥ anteriormente.  Para mantener el rendimiento de los cach√©s JVM en nuestro sistema, escribimos nuestra propia soluci√≥n. <br><br><h1>  Borrar cach√©s en un sistema distribuido </h1><br>  Los IMDG modernos utilizados en proyectos con arquitectura de microservicio le permiten distribuir datos en la memoria entre todos los nodos de trabajo del sistema utilizando particiones de datos escalables con el nivel requerido de redundancia. <br><br>  En este caso, existen muchos problemas asociados con la sincronizaci√≥n, la consistencia de los datos, etc., sin mencionar el aumento en el tiempo de acceso al almacenamiento temporal.  Tal esquema es redundante si la cantidad de datos utilizados se ajusta en la RAM de un nodo, y para mantener la consistencia de los datos, es suficiente eliminar esta entrada en todos los nodos para cualquier cambio en el valor de cach√©. <br><br>  Al implementar una soluci√≥n de este tipo, la primera idea que viene a la mente es usar EventListener, en JCache hay un CacheEntryRemovedListener para el evento de eliminar una entrada del cach√©.  Parece que es suficiente agregar su propia implementaci√≥n de escucha, que enviar√° mensajes al tema cuando se elimine el registro, y la cach√© eut√©ctica en todos los nodos est√© lista, siempre que cada nodo escuche los eventos de la cola asociada con el tema general, como se muestra en el diagrama arriba <br><br>  Cuando se utiliza dicha soluci√≥n, los datos en diferentes nodos ser√°n inconsistentes debido al hecho de que EventLists en cualquier proceso de implementaci√≥n de JCache despu√©s de que ocurra el evento.  Es decir, si no hay un registro en la memoria cach√© local para la clave dada, pero hay un registro para la misma clave en cualquier otro nodo, el evento no se enviar√° al tema. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_a/ev/5c/_aev5cw333ni_cnstj5elxbowhw.png"></div><br>  Considere qu√© otras formas hay para detectar el evento de un valor que se elimina de la memoria cach√© local. <br><br>  En el paquete javax.cache.event, junto a EventListeners, tambi√©n hay un CacheEntryEventFilter, que, de acuerdo con JavaDoc, se usa para verificar cualquier evento CacheEntryEvent antes de enviar este evento a CacheEntryListener, ya sea un registro, eliminaci√≥n, actualizaci√≥n o un evento relacionado con la caducidad del registro en cach√©  Al usar el filtro, nuestro problema permanecer√°, porque la l√≥gica se ejecutar√° despu√©s de que el evento CacheEntryEvent se registre y despu√©s de que la operaci√≥n CRUD se realice en la memoria cach√©. <br><br>  Sin embargo, es posible detectar el inicio de un evento para eliminar un registro de la memoria cach√©.  Para hacer esto, use la herramienta incorporada en JCache que le permite usar especificaciones de API para escribir y cargar datos desde una fuente externa, si no est√°n en la cach√©.  Hay dos interfaces para esto en el paquete javax.cache.integration: <br><br><ul><li>  CacheLoader: para cargar los datos solicitados por la clave, si no hay entradas en el cach√©. </li><li>  CacheWriter: para utilizar la escritura, eliminaci√≥n y actualizaci√≥n de datos en un recurso externo al invocar las operaciones de cach√© correspondientes. </li></ul><br>  Para garantizar la coherencia, los m√©todos CacheWriter son at√≥micos con respecto a la operaci√≥n de cach√© correspondiente.  Parece que hemos encontrado una soluci√≥n a nuestro problema. <br><br>  Ahora podemos mantener la coherencia de la respuesta de las memorias cach√© en memoria en los nodos cuando utilizamos nuestra implementaci√≥n de CacheWriter, que env√≠a eventos al tema RabbitMQ cada vez que hay alg√∫n cambio en el registro en la memoria cach√© local. <br><br><h1>  Conclusi√≥n </h1><br>  En el desarrollo de cualquier proyecto, cuando se busca una soluci√≥n adecuada para problemas emergentes, es necesario tener en cuenta su especificidad.  En nuestro caso, las caracter√≠sticas del modelo de datos del proyecto, el c√≥digo heredado heredado y la naturaleza de la carga no permitieron usar ninguna de las soluciones existentes para el problema de almacenamiento en cach√© distribuido. <br><br>  Es muy dif√≠cil hacer que una implementaci√≥n universal sea aplicable a cualquier sistema desarrollado.  Para cada implementaci√≥n de este tipo, existen condiciones √≥ptimas para su uso.  En nuestro caso, los detalles del proyecto llevaron a la soluci√≥n descrita en este art√≠culo.  Si alguien tiene un problema similar, estaremos encantados de compartir nuestra soluci√≥n y publicarla en GitHub. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/474994/">https://habr.com/ru/post/474994/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../474982/index.html">Tutorial JavaFX: FXML y SceneBuilder</a></li>
<li><a href="../474984/index.html">RabbitMQ vs. Kafka: conmutaci√≥n por error y alta disponibilidad</a></li>
<li><a href="../474988/index.html">Bienvenido a Mitap: carreras en Data Science para principiantes</a></li>
<li><a href="../474990/index.html">Pr√°ctica dif√≠cil: c√≥mo hacer una red Wi-Fi en un parque de la ciudad</a></li>
<li><a href="../474992/index.html">An√°lisis de bater√≠as de computadoras port√°tiles defectuosas. Notas de motorista el√©ctrico</a></li>
<li><a href="../474996/index.html">El resumen de los eventos de TI en noviembre (segunda parte)</a></li>
<li><a href="../475000/index.html">Prueba p√∫blica de las soluciones de Ethereum Cloud y Cloud Privacy and Scalability</a></li>
<li><a href="../475002/index.html">El trabajo no es un lobo, parte 2. Pasa al jefe y sobrevive en libertad condicional</a></li>
<li><a href="../475004/index.html">¬øCu√°nto ganaron los desarrolladores de diferentes calificaciones en la primera mitad de 2019?</a></li>
<li><a href="../475006/index.html">C√≥mo crear un prototipo de servicio de comparaci√≥n de documentos en 28 horas y ganar un hackathon</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
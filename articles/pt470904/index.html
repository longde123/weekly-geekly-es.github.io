<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêá ü§¶üèø üëçüèæ O caminho mais suave e peludo do aprendizado de m√°quina e das redes neurais profundas üôãüèº üíá üï†</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O aprendizado de m√°quina moderno permite que voc√™ fa√ßa coisas incr√≠veis. As redes neurais trabalham em benef√≠cio da sociedade: encontram criminosos, r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O caminho mais suave e peludo do aprendizado de m√°quina e das redes neurais profundas</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/470904/">  O aprendizado de m√°quina moderno permite que voc√™ fa√ßa coisas incr√≠veis.  As redes neurais trabalham em benef√≠cio da sociedade: encontram criminosos, reconhecem amea√ßas, ajudam a diagnosticar doen√ßas e tomam decis√µes dif√≠ceis.  Os algoritmos podem superar uma pessoa em criatividade: eles pintam quadros, escrevem m√∫sicas e fazem obras-primas a partir de quadros comuns.  E aqueles que desenvolvem esses algoritmos s√£o frequentemente apresentados como cientistas caricaturados. <br><br>  Nem tudo √© t√£o assustador!  Qualquer pessoa familiarizada com a programa√ß√£o pode construir uma rede neural a partir de modelos b√°sicos.  E nem √© necess√°rio aprender Python, tudo pode ser feito em JavaScript nativo.  √â f√°cil come√ßar e por que o aprendizado de m√°quina √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">necess√°rio</a> para os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">fornecedores</a> front-end, disse <strong>Aleksey Okhrimenko</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">obenjiro</a> ) no FrontendConf, e o transferimos para o texto para que nomes de arquitetura e links √∫teis estivessem √† m√£o. <br><br><h2>  Spoiler.  Alerta! </h2><br>  Esta hist√≥ria: <br><br><ul><li> <strong>N√£o √© para quem j√°</strong> trabalha com Machine Learning.  Algo interessante ser√°, mas √© improv√°vel que voc√™ esteja esperando pela abertura. </li><li>  <strong>N√£o √© sobre transfer√™ncia de aprendizado.</strong>  N√£o falaremos sobre como escrever uma rede neural em Python e depois trabalhar com ela a partir do JavaScript.  Sem truques - escreveremos redes neurais profundas especificamente em JS. </li><li>  <strong>Nem todos os detalhes.</strong>  Em geral, todos os conceitos n√£o se encaixam em um artigo, mas √© claro que analisaremos o necess√°rio. </li></ul><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BX2M8t5BA3s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>Sobre o palestrante:</strong> Alexei Okhrimenko trabalha na Avito, no departamento de Arquitetura Frontend, e em seu tempo livre realiza o Angular Moscow Meetup e lan√ßa o ‚ÄúFive Minute Angular‚Äù.  Durante uma longa carreira, ele desenvolveu o padr√£o de design MALEVICH, o analisador de gram√°tica PEG SimplePEG.  O mantenedor de Alexey CSSComb compartilha regularmente conhecimentos sobre novas tecnologias em confer√™ncias e em seu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">canal de telegrama de</a> aprendizado de m√°quina JS. <br><br><h2>  O aprendizado de m√°quina √© muito popular. </h2><br>  Assistentes de voz, Siri, Assistente do Google, Alice, s√£o populares e frequentemente encontrados em nossas vidas.  Muitos produtos passaram do processamento de dados algor√≠tmico convencional para o aprendizado de m√°quina.  Um exemplo impressionante √© o Google Translate. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/cg/uz/z3cguzzlmogpjxmymmqhok5xw50.jpeg"></div><br>  Todas as inova√ß√µes e os chips mais legais em smartphones s√£o baseados em aprendizado de m√°quina. <br><br><img src="https://habrastorage.org/webt/qd/2m/1g/qd2m1gmmouw29qcfbytgd5gdcoc.jpeg"><br><br>  Por exemplo, o Google NightSight usa aprendizado de m√°quina.  As fotos legais que vemos n√£o foram obtidas com lentes, sensores ou estabiliza√ß√£o, mas com a ajuda do aprendizado de m√°quina.  A m√°quina finalmente venceu as pessoas no DOTA2, o que significa que temos poucas chances de derrotar a intelig√™ncia artificial.  Portanto, devemos dominar o aprendizado de m√°quina o mais r√°pido poss√≠vel. <br><br><h2>  Vamos come√ßar com um simples </h2><br>  Qual √© a nossa rotina di√°ria de programa√ß√£o, como geralmente escrevemos fun√ß√µes? <br><img src="https://habrastorage.org/webt/n1/kn/ss/n1knssbigatyl2zrakkoaazsuai.jpeg"><br>  Pegamos os dados e o algoritmo que n√≥s mesmos inventamos ou tiramos dos j√° prontos, combinamos, fazemos um pouco de m√°gica e obtemos uma fun√ß√£o que nos d√° a resposta certa em uma determinada situa√ß√£o. <br><br>  Estamos acostumados a essa ordem de coisas, mas haveria essa oportunidade, sem conhecer o algoritmo, mas simplesmente tendo os dados e a resposta, obt√©m o algoritmo deles. <br><br><img src="https://habrastorage.org/webt/tq/6p/4w/tq6p4wwa4ctyhg_j7a4b_t2dhl0.jpeg"><br><br>  Voc√™ pode dizer: "Sou programador, sempre posso escrever um algoritmo". <br><br>  Ok, mas por exemplo, que algoritmo √© necess√°rio aqui? <br><br><img src="https://habrastorage.org/webt/mq/ey/ce/mqeycerayzppkiqobxr_-o13oka.jpeg"><br><br>  Suponha que o gato tenha orelhas afiadas e as orelhas do cachorro sejam lentas, pequenas, como um pug. <br><br><img src="https://habrastorage.org/webt/nv/dp/-h/nvdp-h5hvyset6n3fz-q6ya03hs.jpeg"><br><br>  Vamos tentar entender quem √© quem pelos ouvidos.  Mas, em algum momento, descobrimos que os c√£es podem ter orelhas afiadas. <br><br><img src="https://habrastorage.org/webt/uk/j2/pr/ukj2prwe9ln0hdjj6x0qa5q9vxw.jpeg"><br><br>  Nossa hip√≥tese n√£o √© boa, precisamos de outras caracter√≠sticas.  Com o tempo, aprenderemos mais e mais detalhes, desmotivando-nos cada vez mais e, em algum momento, desejaremos encerrar completamente esse neg√≥cio. <br><br>  Eu imagino uma imagem ideal como esta: com anteced√™ncia, h√° uma resposta (sabemos que tipo de imagem √©), h√° dados (sabemos que um gato √© desenhado), queremos obter um algoritmo que possa alimentar dados e obter respostas na sa√≠da. <br><br>  Existe uma solu√ß√£o - isso √© aprendizado de m√°quina, ou seja, uma de suas partes - redes neurais profundas. <br><br><h2>  Redes neurais profundas </h2><br>  O aprendizado de m√°quina √© uma √°rea enorme.  Ele oferece uma quantidade gigantesca de m√©todos, e cada um √© bom √† sua maneira. <br><br><img src="https://habrastorage.org/webt/qv/8t/kj/qv8tkjpyrk_qeia-hp4fxkvco7w.jpeg"><br><br>  Uma delas √© a Deep Neural Networks.  A aprendizagem profunda tem uma vantagem ineg√°vel devido √† qual se tornou popular. <br><br>  Para entender essa vantagem, vejamos o problema cl√°ssico de classifica√ß√£o usando c√£es e gatos como exemplo. <br><br>  Existem dados: fotos ou fotos.  A primeira coisa a fazer √© incorporar (incorporar), ou seja, transformar os dados para que a m√°quina fique confort√°vel trabalhando com eles.  √â inconveniente trabalhar com fotos, o carro precisa de algo mais simples. <br><br>  Primeiro, alinhe as fotos e remova a cor.  Independentemente da cor do c√£o ou gato, √© importante determinar o tipo de animal.  Depois, transformamos as imagens em matrizes, onde, por exemplo, 0 √© escuro, 1 √© claro. <br><br><img src="https://habrastorage.org/webt/th/st/aq/thstaqtmxfb1jqo-eacmrtlaxym.jpeg"><br><br>  Com esta apresenta√ß√£o de dados, as redes neurais j√° podem funcionar. <br><br>  Vamos criar mais duas matrizes e fundi-las em uma determinada "camada".  Em seguida, multiplicaremos cada um dos elementos da camada e da matriz de dados usando uma simples multiplica√ß√£o de matrizes e direcionaremos o resultado para duas fun√ß√µes de ativa√ß√£o (posteriormente analisaremos quais s√£o essas fun√ß√µes).  Se a fun√ß√£o de ativa√ß√£o receber um n√∫mero suficiente de valores, ela ser√° "ativada" e produzir√° o resultado: <br><br><ul><li>  a primeira fun√ß√£o retornar√° 1 se for um gato e 0 se n√£o for um gato. </li><li>  a segunda fun√ß√£o retornar√° 1 se for um cachorro e 0 se n√£o for um cachorro. </li></ul><br>  Essa abordagem para codificar uma resposta √© chamada <strong>One-Hot Encoding</strong> . <br><br><img src="https://habrastorage.org/webt/bb/-a/x5/bb-ax5li-ngkav87ibjjazse6m4.jpeg"><br><br>  J√° s√£o vis√≠veis v√°rios recursos de redes neurais profundas: <br><br><ul><li>  Para trabalhar com redes neurais, voc√™ precisa codificar dados na entrada e decodificar na sa√≠da. </li><li>  A codifica√ß√£o nos permite abstrair dos dados. </li><li>  Alterando os dados de entrada, podemos gerar redes neurais para diferentes dom√≠nios de dom√≠nio.  Mesmo aqueles em que n√£o somos especialistas. </li></ul><br>  N√£o √© necess√°rio saber o que √© um gato, o que √© um cachorro.  Basta selecionar os n√∫meros necess√°rios para uma camada adicional. <br><br>  At√© agora, a √∫nica coisa que permanece incerta √© por que essas redes s√£o chamadas de "profundas". <br>  Tudo √© muito simples: podemos criar outra camada (matrizes e suas fun√ß√µes de ativa√ß√£o).  E transfira o resultado de uma camada para outra. <br><br><img src="https://habrastorage.org/webt/9n/8r/qh/9n8rqhrwuewcgwa17oq-beuj7r4.jpeg"><br><br>  Voc√™ pode colocar um sobre o outro quantas dessas camadas e suas fun√ß√µes para ativa√ß√£o.  Combinando arquitetura em camadas, obtemos uma rede neural profunda.  Sua profundidade √© uma infinidade de camadas.  E coletivamente chamado de <strong>"modelo"</strong> . <br><br>  Agora vamos ver como os valores s√£o selecionados para todas essas camadas.  Existe uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">visualiza√ß√£o</a> interessante que permite entender como ocorre o processo de aprendizado. <br><br><img src="https://habrastorage.org/webt/aw/ot/at/awotatoajim-4vykkxk5wgldodq.jpeg"><br><br>  √Ä esquerda, h√° dados e, √† direita, uma das camadas.  Pode-se observar que, alterando os valores dentro das matrizes da camada, parece que alteramos o sistema de coordenadas.  Assim, adaptando-se aos dados e aprendendo.  Assim, o aprendizado √© o processo de sele√ß√£o dos valores corretos para matrizes de camadas.  Esses valores s√£o chamados pesos ou pesos. <br><br><h2>  O aprendizado de m√°quina √© dif√≠cil </h2><br>  Eu quero incomod√°-lo, o aprendizado de m√°quina √© dif√≠cil.  Todas as op√ß√µes acima s√£o uma grande simplifica√ß√£o.  No futuro, voc√™ encontrar√° uma enorme quantidade de √°lgebra linear e bastante complexa.  Infelizmente, n√£o h√° como escapar disso. <br><br>  Claro, existem cursos, mas mesmo o treinamento mais r√°pido dura v√°rios meses e n√£o √© barato.  Al√©m disso, voc√™ ainda precisa descobrir por si mesmo.  O campo do aprendizado de m√°quina cresceu tanto que acompanhar tudo √© quase imposs√≠vel.  Por exemplo, abaixo est√° um conjunto de modelos para resolver apenas uma tarefa (detec√ß√£o de objeto): <br><br><img src="https://habrastorage.org/webt/tw/bx/rs/twbxrs3-fary0wir6wd-e4x_2_i.jpeg"><br><br>  Pessoalmente, eu estava muito desmotivado.  N√£o consegui abordar as redes neurais e come√ßar a trabalhar com elas.  Mas eu encontrei um caminho e quero compartilh√°-lo com voc√™.  N√£o √© revolucion√°rio, n√£o h√° nada disso, voc√™ j√° est√° familiarizado com isso. <br><br><h2>  Blackbox - Uma abordagem simples </h2><br>  N√£o √© necess√°rio entender absolutamente todos os aspectos do aprendizado de m√°quina para aprender como aplicar redes neurais √†s suas tarefas de neg√≥cios.  Vou mostrar alguns exemplos que esperamos inspir√°-lo. <br><br>  Para muitos, um carro tamb√©m √© uma caixa preta.  Mas mesmo se voc√™ n√£o sabe como isso funciona, voc√™ precisa aprender as regras.  Portanto, com o aprendizado de m√°quina - voc√™ ainda precisa conhecer algumas regras: <br><br><ul><li>  Aprenda o TensorFlow JS (biblioteca para trabalhar com redes neurais). </li><li>  Aprenda a escolher modelos. </li></ul><br>  N√≥s nos concentramos nessas tarefas e come√ßamos com o c√≥digo. <br><br><h2>  Aprendendo criando c√≥digo </h2><br>  A biblioteca TensorFlow √© escrita para um grande n√∫mero de idiomas: Python, C / C ++, JavaScript, Go, Java, Swift, C #, Haskell, Julia, R, Scala, Rust, OCaml, Crystal.  Mas definitivamente escolheremos o melhor - JavaScript. <br><br>  O TensorFlow pode ser conectado √† nossa p√°gina conectando um script √† CDN: <br><br><pre><code class="javascript hljs">&lt;script src=<span class="hljs-string"><span class="hljs-string">"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"</span></span>&gt;<span class="xml"><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;/</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">script</span></span></span></span><span class="xml"><span class="hljs-tag">&gt;</span></span></span></span></code> </pre> <br>  Ou use o npm: <br><br><ul><li>  <code>npm install @tensorflow/tfjs-node</code> - para o processo do n√≥ (site); </li><li>  <code>npm install @tensorflow/tfjs-node-gpu</code> (Linux CUDA) - para a GPU, mas apenas se a m√°quina Linux e a placa de v√≠deo suportarem a tecnologia CUDA.  Certifique-se de que o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CUDA Compute Capability</a> corresponda √† sua biblioteca para que n√£o aconte√ßa que hardware caro n√£o seja adequado. </li><li>  <code>npm install @tensorflow/tfjs</code> ( <code>npm install @tensorflow/tfjs</code> / Browser) - para um navegador sem usar o Node.js. </li></ul><br>  Para trabalhar com o TensorFlow JS, basta importar um dos m√≥dulos acima.  Voc√™ ver√° muitos exemplos de c√≥digo em que tudo √© importado.  N√£o √© necess√°rio fazer isso, selecione e importe apenas um. <br><br><h3>  Tensores </h3><br>  Quando os dados iniciais estiverem prontos, a primeira coisa a fazer √© <strong>importar o TensorFlow</strong> .  Usaremos tensorflow / tfjs-node-gpu para obter acelera√ß√£o devido ao poder da placa de v√≠deo. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  @tensorflow/tfjs-node-gpu  node.js const tf = require('@tensorflow/tfjs'); const a = [[1,2], [3,4]];</span></span></code> </pre> <br>  Existe uma matriz de dados bidimensional - trabalharemos com ela. <br><br>  A pr√≥xima coisa importante a fazer √© <strong>criar um tensor</strong> .  Nesse caso, √© criado um tensor de classifica√ß√£o 2, ou seja, de fato uma matriz bidimensional.  Transferimos os dados e obtemos o tensor 2x2. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  rank-2  (/) const b = tf.tensor([[1,2], [3,4]]); console.log('shape:', b.shape); b.print()</span></span></code> </pre> <br>  Observe que o m√©todo <code>print</code> √© chamado, n√£o <code>console.log</code> , porque <code>b</code> (o tensor que criamos) n√£o √© um objeto comum, ou seja, o tensor.  Ele tem seus pr√≥prios m√©todos e propriedades. <br><br>  Voc√™ tamb√©m pode criar um tensor a partir de uma matriz plana e manter sua forma em mente, digamos.  Ou seja, declarar um formul√°rio - uma matriz bidimensional - para transmitir simplesmente uma matriz plana e indicar diretamente a forma.  O resultado ser√° o mesmo. <br><br>  Devido ao fato de que os dados e o formul√°rio podem ser armazenados separadamente, √© poss√≠vel alterar a forma do tensor.  Podemos chamar o m√©todo de <code>reshape</code> e alterar a forma de 2x2 para 4x1. <br><br>  O pr√≥ximo passo importante √© <strong>produzir os dados</strong> , devolv√™-los ao mundo real. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const g = tf.tensor([[1,2], [3,4]]); g.data().then((raw) =&gt; { console.log('async raw value of g:', raw); }); console.log('raw value of g:', g.dataSync()); console.log('raw multidimensional value of g:', g.arraySync());</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O c√≥digo para</a> todas as tr√™s etapas.</i> <br><br>  O m√©todo de <code>data</code> retorna promessa.  Ap√≥s a resolu√ß√£o, obtemos o valor imediato do valor bruto, mas obtemos de forma ass√≠ncrona.  Se quisermos, podemos obt√™-lo de forma s√≠ncrona, mas lembre-se de que aqui voc√™ pode perder desempenho; portanto, use m√©todos ass√≠ncronos sempre que poss√≠vel. <br><br>  O m√©todo <code>dataSync</code> sempre retorna dados em um formato de matriz plana.  E se queremos retornar os dados no formato em que eles est√£o armazenados no tensor, precisamos chamar <code>arraySync</code> . <br><br><h3>  Operadores </h3><br>  Todos os operadores no TensorFlow s√£o <strong>imut√°veis ‚Äã‚Äãpor padr√£o</strong> , ou seja, em cada opera√ß√£o sempre √© retornado um novo tensor.  Acima, basta pegar nossa matriz e agrupar todos os seus elementos. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   Immutable const x = tf.tensor([1,2,3,4]); const y = x.square(); // tf.square(x); y.print();</span></span></code> </pre> <br>  Por que essas dificuldades para opera√ß√µes matem√°ticas simples?  Todos os operadores de que precisamos - a soma, a mediana etc. - est√£o l√°.  Isso √© necess√°rio porque, de fato, o tensor e essa abordagem permitem criar um gr√°fico de c√°lculos e executar c√°lculos n√£o imediatamente, mas no WebGL (no navegador) ou CUDA (Node.js na m√°quina).  Ou seja, na verdade, usar a Acelera√ß√£o de Hardware √© invis√≠vel para n√≥s e, se necess√°rio, fazer fallback na CPU.  O melhor √© que n√£o precisamos pensar em nada sobre isso.  N√≥s apenas precisamos aprender a API tfjs. <br><br>  Agora, o mais importante √© o modelo. <br><br><h3>  Modelo </h3><br>  A maneira mais f√°cil de criar um modelo √© Sequencial, ou seja, um modelo seq√ºencial, quando os dados de uma camada s√£o transferidos para a pr√≥xima camada e dele para a pr√≥xima camada.  As camadas mais simples usadas aqui s√£o usadas. <blockquote>  A pr√≥pria camada √© apenas uma abstra√ß√£o de tensores e operadores.  Grosso modo, essas s√£o fun√ß√µes auxiliares que escondem uma grande quantidade de matem√°tica de voc√™. </blockquote><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//    const model = tf.sequential({ layers: [ tf.layers.dense({ inputShape: [784], units: 32, activation: 'relu' }), tf.layers.dense({ units: 10, activation: 'softmax' }) ] });</span></span></code> </pre> <br>  Vamos tentar entender como trabalhar com o modelo sem entrar nos detalhes da implementa√ß√£o. <br><br>  Primeiro, indicamos a forma de dados que cai na rede neural - <code>inputShape</code> √© um par√¢metro necess√°rio.  Indicamos <code>units</code> - o n√∫mero de matrizes multidimensionais e a fun√ß√£o de ativa√ß√£o. <br><br>  A fun√ß√£o <code>relu</code> not√°vel por ter sido encontrada por acaso - foi tentada, funcionou melhor e, durante muito tempo, eles procuraram uma explica√ß√£o matem√°tica do por que isso acontece. <br><br>  Para a √∫ltima camada, quando criamos uma categoria, a fun√ß√£o softmax √© frequentemente usada - √© muito adequada para exibir uma resposta no formato de codifica√ß√£o One-Hot.  Ap√≥s a cria√ß√£o do modelo, chame <code>model.summary()</code> para garantir que o modelo seja montado da maneira correta.  Em situa√ß√µes particularmente dif√≠ceis, voc√™ pode abordar a cria√ß√£o de um modelo usando programa√ß√£o funcional. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const input = tf.input({ shape: [784] }); const dense1 = tf.layers.dense({ units: 32, activation: 'relu' }).apply(input); const dense2 = tf.layers.dense({ units: 10, activation: 'softmax' }).apply(dense1); const model = tf.model({ inputs: input, outputs: dense2 });</span></span></code> </pre> <br>  Se voc√™ precisar criar um modelo particularmente complexo, poder√° usar a abordagem funcional: sempre que cada camada for uma nova vari√°vel.  Como exemplo, pegamos manualmente a pr√≥xima camada e aplicamos a camada anterior para que possamos construir arquiteturas mais complexas.  Mais tarde, mostrarei a voc√™ onde isso pode ser √∫til. <br><br>  O pr√≥ximo detalhe muito importante √© que passamos as camadas de entrada e sa√≠da para o modelo, ou seja, as camadas que entram na rede neural e as camadas que s√£o camadas para a resposta. <br><br>  Depois disso, uma etapa importante √© <strong>compilar o modelo</strong> .  Vamos tentar entender o que √© compila√ß√£o em termos de tfjs. <br><br>  Lembre-se, tentamos encontrar os valores certos em nossa rede neural.  N√£o √© necess√°rio busc√°-los.  Eles s√£o selecionados de uma certa maneira, como diz a fun√ß√£o do otimizador. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   (  ) model.compile({ optimizer: 'sgd', loss: 'categoricalCrossentropy', metrics: ['accuracy'] });</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo para a</a> descri√ß√£o de camadas sequenciais e compila√ß√£o.</i> <br><br>  Ilustrarei o que √© um otimizador e o que √© uma fun√ß√£o de perda. <br><br><img src="https://habrastorage.org/webt/se/lt/1l/selt1lv8ppxvokzopux387dp0os.png"><br><br>  O otimizador √© o mapa inteiro.  Ele permite que voc√™ n√£o apenas busque por valor aleatoriamente, mas fa√ßa isso com sabedoria, de acordo com um determinado algoritmo. <br><br>  A fun√ß√£o de perda √© a maneira pela qual procuramos o valor ideal (pequena seta preta).  Ajuda a entender quais valores de gradiente usar para treinar nossa rede neural. <br><br>  No futuro, quando voc√™ dominar redes neurais, voc√™ mesmo escrever√° uma fun√ß√£o de perda.  Grande parte do sucesso de uma rede neural depende de qu√£o bem est√° escrita essa fun√ß√£o.  Mas isso √© outra hist√≥ria.  Vamos come√ßar simples. <br><br><h4>  Exemplo de aprendizado de rede </h4><br>  Geraremos dados aleat√≥rios e respostas aleat√≥rias (etiquetas).  Chamamos o m√≥dulo de <code>fit</code> , passamos os dados, respostas e v√°rios par√¢metros importantes: <br><br><ul><li>  <code>epochs</code> - 5 vezes, ou seja, 5 vezes, conduziremos um treinamento completo; </li><li>  <code>batchSize</code> , que <code>batchSize</code> quantos pesos podem ser alterados ao mesmo tempo para levantar - quantos elementos processar ao mesmo tempo.  Quanto melhor a placa de v√≠deo, mais mem√≥ria ela possui, mais <code>batchSize</code> pode ser definido. </li></ul><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const data = tf.randomNormal([100, 784]); const labels = tf.randomNormal([100, 10]); //   model.fit(data, labels, { epochs: 5, batchSize: 32 }).then(info =&gt; { console.log('  :', info.history.acc); })</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo de</a> todas as √∫ltimas etapas.</i> <br><br>  <code>Model.fit</code> ass√≠ncrono <code>Model.fit</code> , retorna promessa.  Mas voc√™ pode usar async / waitit e aguardar a execu√ß√£o dessa maneira. <br><br>  Em seguida √© o <strong>uso</strong> .  N√≥s treinamos nosso modelo, depois pegamos os dados que queremos processar e chamamos o m√©todo de <code>predict</code> , dizemos: ‚ÄúPreveja o que realmente est√° l√°?‚Äù. E, gra√ßas a isso, obtemos o resultado. <br><br><h3>  Estrutura padr√£o </h3><br>  Cada rede neural possui tr√™s arquivos principais: <br><br><ul><li>  index.js - arquivo no qual todos os par√¢metros da rede neural s√£o armazenados; </li><li>  model.js - um arquivo no qual o modelo e sua arquitetura s√£o armazenados diretamente; </li><li>  data.js - um arquivo em que os dados s√£o coletados, processados ‚Äã‚Äãe incorporados ao nosso sistema. </li></ul><br>  Ent√£o, eu falei sobre como aprender o TensorFlow.js.  Pequenas empresas, resta <strong>escolher um modelo</strong> . <br><br>  Infelizmente, isso n√£o √© inteiramente verdade.  De fato, toda vez que voc√™ escolhe um modelo, precisa repetir algumas etapas. <br><br><ul><li>  Prepare os dados para isso, fa√ßa a incorpora√ß√£o, ajuste-os √† arquitetura. </li><li>  Defina as configura√ß√µes do Hyper (depois, informarei o que isso significa). </li><li>  Treine / treine cada rede neural (cada modelo pode ter suas pr√≥prias nuances). </li><li>  Aplique um modelo neural e, novamente, voc√™ pode aplicar de diferentes maneiras. </li></ul><br><h2>  Escolha um modelo </h2><br>  Vamos come√ßar com as op√ß√µes b√°sicas que voc√™ encontrar√° com frequ√™ncia. <br><br><h3>  Sentido profundo </h3><br>  Este √© um exemplo popular de uma rede neural profunda.  Tudo √© feito de maneira simples: existe um conjunto de dados dispon√≠vel ao p√∫blico - conjunto de dados MNIST. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6g/yu/-4/6gyu-4wjgg4zfvf8w7byjx_z5yw.jpeg" width="600"></div><br>  S√£o imagens rotuladas com n√∫meros, com base nas quais √© conveniente treinar uma rede neural. <br><br>  De acordo com a arquitetura da codifica√ß√£o One-Hot, codificamos cada uma das √∫ltimas camadas.  D√≠gitos 10 - em conformidade, haver√° 10 √∫ltimas camadas no final.  Simplesmente enviamos fotos em preto e branco para a entrada, tudo isso √© muito parecido com o que falamos no come√ßo. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> model = tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">784</span></span>], <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> }), ] });</code> </pre> <br>  Endireitamos a imagem em uma matriz unidimensional, obtemos 784 elementos.  Em uma camada 512 matrizes.  Fun√ß√£o de ativa√ß√£o <code>'relu'</code> . <br><br>  A pr√≥xima camada de matrizes √© um pouco menor (256), a camada de ativa√ß√£o tamb√©m √© <code>'relu'</code> .  Reduzimos o n√∫mero de matrizes para procurar caracter√≠sticas mais gerais.  A rede neural deve ser solicitada a aprender e for√ßada a tomar uma decis√£o geral mais s√©ria, porque ela mesma n√£o far√° isso. <br><br>  No final, criamos 10 matrizes e usamos a ativa√ß√£o softmax para a codifica√ß√£o One-Hot - esse tipo de ativa√ß√£o funciona bem com esse tipo de codifica√ß√£o de resposta. <br><br>  Redes profundas permitem que voc√™ reconhe√ßa corretamente de 80 a 90% das fotos - quero mais.  Uma pessoa reconhece com uma qualidade de aproximadamente 96%.  As redes neurais podem capturar e ultrapassar uma pessoa? <br><br><h3>  CNN (Rede Neural Convolucional) </h3><br>  As redes convolucionais funcionam incrivelmente simples.  No final, eles t√™m a mesma arquitetura dos exemplos anteriores.  Mas no come√ßo, algo mais acontece.  As matrizes, em vez de apenas fornecer algumas solu√ß√µes, reduzem a imagem.  Eles participam da imagem e a reduzem, diminuem, para um d√≠gito.  Ent√£o eles s√£o coletados todos juntos e novamente reduzidos. <br><img src="https://habrastorage.org/webt/mi/xc/gk/mixcgkl0kgopjxgams8szm0wr2q.jpeg"><br>  Assim, o tamanho da imagem √© reduzido, mas ao mesmo tempo partes da imagem s√£o reconhecidas cada vez melhor.  As redes de convolu√ß√£o funcionam muito bem para reconhecimento de padr√µes, ainda melhor que os humanos. <br><blockquote>  O reconhecimento de imagens √© melhor confiado a um carro do que a uma pessoa.  Houve um estudo especial, e a pessoa, infelizmente, perdeu. </blockquote>  As CNNs funcionam de maneira muito simples: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> model = tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }), tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }), tf.layers.maxPooling2d({<span class="hljs-attr"><span class="hljs-attr">poolSize</span></span>: [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>]}), tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }) tf.layers.flatten(tf.layers.maxPooling2d({ <span class="hljs-attr"><span class="hljs-attr">poolSize</span></span>: [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>] })), tf.layers.dense({<span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>}), tf.layers.dense({<span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span>}) ] });</code> </pre> <br>  Introduzimos uma matriz multidimensional espec√≠fica: uma imagem de 28x28 pixels, mais uma dimens√£o para brilho; nesse caso, a imagem √© em preto e branco; portanto, a terceira dimens√£o √© 1. <br><br>  Em seguida, definimos o n√∫mero de <code>filters</code> e <code>kernelSize</code> - quantos pixels diminuir√£o.  Fun√ß√£o de ativa√ß√£o em todos os lugares <code>relu</code> . <br><br>  Existe outra camada <code>maxPooling2d</code> , necess√°ria para reduzir o tamanho ainda mais eficientemente.  As redes convolucionais diminuem gradualmente o tamanho e, muitas vezes, n√£o h√° necessidade de criar redes convolucionais muito profundas. <br><br>  Vou explicar por que √© imposs√≠vel criar redes de convolu√ß√£o muito profundas um pouco mais tarde, mas por enquanto, lembre-se: √†s vezes elas precisam ser enroladas um pouco mais r√°pido.  Existe uma camada maxPooling separada para isso. <br><br>  No final, h√° a mesma camada densa.  Ou seja, usando redes neurais convolucionais, extra√≠mos v√°rios sinais dos dados, ap√≥s o que usamos a abordagem padr√£o e categorizamos nossos resultados, gra√ßas aos quais reconhecemos as imagens. <br><br><h3>  U net </h3><br>  Esse modelo de arquitetura est√° associado a redes de convolu√ß√£o.  Com sua ajuda, muitas descobertas foram feitas no campo do controle do c√¢ncer, por exemplo, no reconhecimento de c√©lulas cancer√≠genas e glaucoma.  Al√©m disso, este modelo pode encontrar c√©lulas malignas n√£o piores do que um professor nessa √°rea. <br><br>  Um exemplo simples: entre os dados barulhentos, voc√™ precisa encontrar c√©lulas cancer√≠genas (c√≠rculos). <br><br><img src="https://habrastorage.org/webt/hj/9b/yr/hj9byresramxnetrg7t_kenia0a.jpeg"><br><br>  O U-Net √© t√£o bom que pode encontr√°-los quase perfeitamente.  A arquitetura √© muito simples: <br><br><img src="https://habrastorage.org/webt/16/5_/vx/165_vxamsqm5eveub2tdhzxprc8.jpeg"><br><br>  Existem as mesmas redes de convolu√ß√£o, assim como o MaxPooling, que reduz o tamanho.  A √∫nica diferen√ßa: o modelo tamb√©m usa redes de <strong>varredura</strong> - a <strong>rede deconvolucional</strong> . <br><br>  Al√©m da varredura de convolu√ß√£o, cada uma das camadas de alto n√≠vel √© combinada (in√≠cio e sa√≠da), devido √† qual um grande n√∫mero de relacionamentos aparece.  Essa rede U-Net funciona bem mesmo em pequenas quantidades de dados. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//First part (down climb) const input = buildInput(...IMAGE_INPUT); const conv1 = genConv2D(64).apply(input); const conv2 = genConv2D(64).apply(conv1); const pool1 = geMaxPool2D(2).apply(conv2); const conv3 = genConv2D(128).apply(pool1); const conv4 = genConv2D(128).apply(conv3); const pool2 = geMaxPool2D(2).apply(conv4); const conv5 = genConv2D(256).apply(pool2); const conv6 = genConv2D(256).apply(conv5); const pool3 = geMaxPool2D(2).apply(conv6); const conv7 = genConv2D(512).apply(pool3); const conv8 = genConv2D(512).apply(conv7); const pool4 = geMaxPool2D(2).apply(conv8); const conv9 = genConv2D(1024).apply(pool4); const conv10 = genConv2D(1024).apply(conv9); const up1 = genUp2D().apply(conv10); const merge1 = tf.layers.concatenate({ axis: 3 }).apply([up1, conv8]); //Second part (up climb) const conv11 = genConv2D(512).apply(merge1); const conv12 = genConv2D(512).apply(conv11); const up2 = genUp2D().apply(conv12); const merge2 = tf.layers.concatenate({ axis: 3 }).apply([up2, conv6]); const conv13 = genConv2D(256).apply(merge2); const conv14 = genConv2D(256).apply(conv13); const up3 = genUp2D().apply(conv14); const merge3 = tf.layers.concatenate({ axis: 3 }).apply([up3, conv4]); const conv15 = genConv2D(128).apply(merge3); const conv16 = genConv2D(128).apply(conv15); const up4 = genUp2D().apply(conv16); const merge4 = tf.layers.concatenate({ axis: 3 }).apply([up4, conv2]); const conv17 = genConv2D(64).apply(merge4); const conv18 = genConv2D(64).apply(conv17); const conv19 = tf.layers .conv2d({ kernelSize: [1, 1], activation: "sigmoid", filters: 1, padding: "same" }) .apply(conv18); const model = tf.model({ inputs: input, outputs: conv19 });</span></span></code> </pre> <br>  Este c√≥digo √© mais f√°cil de aprender no editor.  Em geral, um grande n√∫mero de redes de convolu√ß√£o √© criado aqui e, para implant√°-las novamente, <code>concatenate</code> e mesclamos v√°rias camadas.  Isso √© apenas uma visualiza√ß√£o de uma imagem, apenas na forma de c√≥digo.  Tudo √© bem simples - copiar e reproduzir esse modelo √© f√°cil. <br><br><h2>  LSTM (Mem√≥ria de Longo Prazo) </h2><br>  Observe que todos os exemplos considerados t√™m um recurso - o formato dos dados de entrada √© fixo.  A entrada para a rede, os dados devem ser do mesmo tamanho e coincidir.  Os modelos LSTM est√£o focados em como lidar com isso. <br><br>  Por exemplo, existe um servi√ßo Yandex.Referats, que gera resumos. <br><br><img src="https://habrastorage.org/webt/_o/g7/mh/_og7mh4hlaz87r6jpbkzjqsgdbc.png"><br><br>  Ele d√° um abracadabra completo, mas ao mesmo tempo bastante semelhante √† verdade: <br><br><blockquote>  <strong>Resumo em matem√°tica sobre o tema: "O bin√¥mio de Newton como axioma"</strong> <br><br>  De acordo com o anterior, a integral de superf√≠cie produz uma integral curvil√≠nea.  A fun√ß√£o convexa para o fundo ainda est√° em demanda. <br><br>  Naturalmente, segue-se que o normal para a superf√≠cie ainda est√° em demanda.  De acordo com o anterior, a integral de Poisson especifica essencialmente a integral de Poisson trigonom√©trica. </blockquote><br>  O servi√ßo √© baseado em redes neurais Seq a Seq.  Sua arquitetura √© mais complexa. <br><br><img src="https://habrastorage.org/webt/6r/3s/aw/6r3sawht3bnxadqmorz0vjqwzmw.jpeg"><br><br>  As camadas s√£o organizadas em um sistema bastante complexo.  Mas n√£o se assuste - voc√™ n√£o precisa conduzir todas essas flechas sozinho.  Se voc√™ quiser, pode, mas n√£o √© necess√°rio.  Existe um ajudante que far√° isso por voc√™. <br><br>  O principal a entender √© que cada uma dessas pe√ßas √© combinada com a anterior.  Ele pega os dados n√£o apenas dos dados iniciais, mas tamb√©m da camada neural anterior.  Grosso modo, √© poss√≠vel construir algum tipo de mem√≥ria - para memorizar uma sequ√™ncia de dados, reproduzi-la e, devido a esse trabalho, ‚Äúsequ√™ncia para sequ√™ncia‚Äù.  Al√©m disso, as seq√º√™ncias podem ter tamanhos diferentes, tanto na entrada quanto na sa√≠da. <br><br>  Tudo parece bonito no c√≥digo: <br><br><pre> <code class="javascript hljs">tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.lstm({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">returnSequences</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>] }), tf.layers.lstm({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">returnSequences</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> }) ] }) ;</code> </pre> <br>  H√° um auxiliar especial que diz que temos 512 objetos (matrizes).  Em seguida, retorne a sequ√™ncia e o formul√°rio de entrada ( <code>inputShape: [10000, 64]</code> ).  A seguir, apresentamos outra camada, mas n√£o retornamos a sequ√™ncia ( <code>returnSequences: false</code> ), porque no final dizemos que agora precisamos usar a fun√ß√£o de ativa√ß√£o para 64 caracteres diferentes (letras min√∫sculas e mai√∫sculas).  64 op√ß√µes s√£o ativadas usando a codifica√ß√£o One-Hot. <br><br><h2>  Mais interessante </h2><br>  Agora, voc√™ provavelmente est√° se perguntando: ‚ÄúIsso √© tudo, √© claro, bom, mas por que eu preciso disso?  "Combater o c√¢ncer √© bom, mas por que eu preciso disso na linha de frente?" <br><br>  E as dan√ßas com um pandeiro come√ßam: para descobrir como aplicar redes neurais ao layout, por exemplo. <br><blockquote>  Com a ajuda de redes neurais, √© poss√≠vel resolver problemas que antes eram imposs√≠veis de resolver.  Alguns que voc√™ nem conseguia pensar.  Tudo depende de voc√™, sua imagina√ß√£o e um pouco de pr√°tica. </blockquote>  Agora vou mostrar ao vivo exemplos interessantes do uso dos modelos que examinamos. <br><br><h3>  CNN  Equipes de √°udio </h3><br>  Usando redes de convolu√ß√£o, voc√™ pode reconhecer n√£o apenas imagens, mas tamb√©m comandos de √°udio e com 97% de qualidade de reconhecimento, ou seja, no n√≠vel do Google Assistant e Yandex-Alice. <br><br>  Somente na rede, √© claro, n√£o √© poss√≠vel reconhecer frases e frases completas, mas voc√™ pode criar um assistente de voz simples. <br><br>  Mais informa√ß√µes sobre Alice podem ser encontradas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">relat√≥rio de</a> Nikita Dubko e sobre o assistente do Google, como trabalhar com voz e os padr√µes do navegador <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  O fato √© que qualquer palavra, qualquer comando pode ser transformado em um espectrograma. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/au/_v/r8/au_vr8gdnqh3k6gkcgyhz0ybwoq.jpeg" width="500"></div><br>  Voc√™ pode converter qualquer informa√ß√£o de √°udio em um espectrograma.  E ent√£o voc√™ pode codificar o √°udio na imagem e aplicar CNN √† imagem e reconhecer comandos de voz simples. <br><br><h3>  U-net.  Teste de captura de tela </h3><br>  O U-Net √© √∫til n√£o apenas para o diagn√≥stico bem-sucedido do c√¢ncer, mas tamb√©m, por exemplo, para testar capturas de tela.  Para detalhes, veja o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">relat√≥rio de</a> Lyudmila Mzhachikh, e eu direi a pr√≥pria base. <br><br>  Para testar com capturas de tela, s√£o necess√°rias duas capturas de tela: <br><br><ul><li>  b√°sico (refer√™ncia) com o qual estamos comparando; </li><li>  captura de tela para teste. </li></ul><br><img src="https://habrastorage.org/webt/kx/2g/ci/kx2gcib0rilb_zzhohk15dmnoi4.jpeg"><br>  Infelizmente, nos testes de captura de tela, muitas vezes h√° muitas quedas negativas (falsos positivos).  Mas isso pode ser evitado aplicando tecnologias avan√ßadas de controle de c√¢ncer no front-end. <br><br>  Lembre-se, marcamos a imagem na √°rea onde h√° c√¢ncer e n√£o.  O mesmo pode ser feito aqui. <br><br><img src="https://habrastorage.org/webt/19/kk/uw/19kkuwktd9iv30ffolxasj3_l-k.jpeg"><br><br>  Se virmos uma foto com um bom layout, n√£o a marcamos e as fotos com um layout ruim.  Assim, voc√™ pode testar o layout com uma √∫nica imagem.   ,     ,   ,    . U-Net     . <br><br>       ,    ,    .  ,          U-Net,  .  ,   . <br><br><h3> LSTM. Twitter ‚Äî  2000 </h3><br>   ,    ,     ,    . <br><br>       ,     LSTM  .   40     - , : <em>¬´ ‚Äî     ¬ª</em> . <br><br>   ,  : <br><br><img src="https://habrastorage.org/webt/yu/_6/xk/yu_6xkkdkak9jganrrpvxs6vd9g.jpeg"><br><br> -   , ? <br><br>  ‚Äî .    -   : <br><br><img src="https://habrastorage.org/webt/lk/hz/sf/lkhzsfwyvs42ky2yi-k6m5reu7o.jpeg"><br><br><img src="https://habrastorage.org/webt/ai/a7/jv/aia7jvkjsgw35wpjixbsko4vjwe.jpeg"><br><br>  ,   ¬´¬ª       ,       ,        (,  ). <br><br>  : <em>¬´    ¬ª</em>  <em>¬´   ¬ª</em> . <br><br>       ‚Äî  . <br><blockquote> ¬´   ¬ª. </blockquote><br>      : <br><br><img src="https://habrastorage.org/webt/lv/ud/dp/lvuddp8bnuagbh4kgmsao3j_qvo.jpeg"><br><br><h4> EPOCS 250 </h4><br>    ,     . <br><br>    -   , ,  ,     .   ,      Overfitting ‚Äî . <br><br>   ,    ‚Äî       .  , , .   ,   ,         ,         . <br><br>    ,       ,          . <br><br>  ,       . <br><br><img src="https://habrastorage.org/webt/cv/_j/ft/cv_jftct2bzeb2_ik1apzezgjsg.jpeg"><br><br>   , ,        ,        .      ( ,  ),      .          . <br><blockquote>     ‚Äî    .    . </blockquote>      overfitting.      ,    helper-: Dropout; BatchNormalization. <br><br><h3> LSTM. Prettier </h3><br>  ,     ‚Äî  Prettier   .       ,     . <br><br>  <code>const a = 1</code> .    : <code>[]c co on ns st</code> ,    ,            : <code>[][] []c co on ns st</code> ,      . <br><br>     ,            ,     . <br><br> ,    ,     .      , ,  0 ‚Äî  ,      -  ,  - .   . <br><br>            ,      .         . <br><br><h2>  Em vez de conclus√µes </h2><br> , ,     .   . , ,         Deep Neural Network. <br><br>        .         ,      .      .            .     . <br><br>       JS,       ,     .         ,      .  ,   JavaScript,         .     TensorFlow.js. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><em></em></a> <em> ,     .    </em> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><em>telegram-</em></a> <em>    JS.</em> <br><blockquote>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">FrontendConf</a>    , 13 .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> 32        . <br><br>    ,    ,           .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>  Saint AppsConf,       .      ,  ,    ,     . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt470904/">https://habr.com/ru/post/pt470904/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt470884/index.html">Escrevendo e lendo dados no blockchain Bitcoin</a></li>
<li><a href="../pt470888/index.html">Legisla√ß√£o russa e internacional no campo da prote√ß√£o de dados pessoais</a></li>
<li><a href="../pt470892/index.html">Implementa√ß√£o simples de pequenas CAM no FPGA</a></li>
<li><a href="../pt470894/index.html">Bullet</a></li>
<li><a href="../pt470902/index.html">Alto desempenho e particionamento nativo: Zabbix com suporte ao TimescaleDB</a></li>
<li><a href="../pt470908/index.html">Pela primeira vez no mundo, com a ajuda de tecnologias aditivas, foi obtido um conjunto de motores de aeronaves de grande porte</a></li>
<li><a href="../pt470910/index.html">O que pode ser feito com anota√ß√µes de contratos de microsservi√ßo?</a></li>
<li><a href="../pt470916/index.html">O ponto de verifica√ß√£o eletr√¥nico "mais barato" na R√∫ssia controlado a partir de um smartphone</a></li>
<li><a href="../pt470918/index.html">F # 9: Op√ß√£o de tipo</a></li>
<li><a href="../pt470920/index.html">Mais de 5 maneiras de conectar-se a uma nuvem DataLine</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
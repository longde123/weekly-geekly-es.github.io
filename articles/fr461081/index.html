<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò∏ ü•ò ‚õ™Ô∏è Le jour o√π Dodo IS s'est arr√™t√©. Script asynchrone ü•É üéä üëàüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! Chaque SRE de notre √©quipe r√™vait de dormir paisiblement la nuit. Les r√™ves deviennent r√©alit√©. Dans cet article, je parlerai de cela e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le jour o√π Dodo IS s'est arr√™t√©. Script asynchrone</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dodopizzadev/blog/461081/">  Bonjour, Habr!  Chaque SRE de notre √©quipe r√™vait de dormir paisiblement la nuit.  Les r√™ves deviennent r√©alit√©.  Dans cet article, je parlerai de cela et de la fa√ßon dont nous atteignons les performances et la stabilit√© de notre syst√®me Dodo IS. <br><br><img src="https://habrastorage.org/webt/wk/2o/t6/wk2ot6razkmzgly1s69fdwz5quq.png"><a name="habracut"></a><br><blockquote>  <b>Une s√©rie d'articles sur l'effondrement du syst√®me Dodo IS *</b> : <br><br>  1. Le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jour o√π Dodo IS s'est arr√™t√©.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Script synchrone.</a> <br>  2. Le jour o√π Dodo IS s'est arr√™t√©.  Script asynchrone. <br><br>  * Les <i>mat√©riaux ont √©t√© √©crits sur la base de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ma performance √† DotNext 2018 √† Moscou</a></i> . </blockquote>  Dans un article pr√©c√©dent, nous avons examin√© les probl√®mes de blocage de code dans le paradigme du multit√¢che pr√©emptif.  Il √©tait suppos√© qu'il √©tait n√©cessaire de r√©√©crire le code de blocage sur async / wait.  Nous l'avons donc fait.  Parlons maintenant des probl√®mes survenus lorsque nous avons fait cela. <br><br><h2>  Nous introduisons le terme Concurrence </h2><br>  Avant d'arriver √† async, vous devez saisir le terme acc√®s simultan√©. <br><blockquote>  Dans la th√©orie des files d'attente, la <b>concurrence</b> est le nombre de clients qui sont actuellement √† l'int√©rieur du syst√®me.  La concurrence est parfois confondue avec le parall√©lisme, mais en r√©alit√©, ce sont deux choses diff√©rentes. </blockquote>  Pour ceux qui d√©couvrent Concurrency pour la premi√®re fois, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">je recommande la vid√©o de Rob Pike</a> .  La simultan√©it√©, c'est quand nous traitons beaucoup de choses en m√™me temps, et le parall√©lisme, c'est quand nous faisons beaucoup de choses en m√™me temps. <br><br>  Dans les ordinateurs, peu de choses se produisent en parall√®le.  Une telle chose est le calcul sur plusieurs processeurs.  Le degr√© de parall√©lisme est limit√© par le nombre de threads CPU. <br><br>  En fait, Threads fait partie du concept de multit√¢che pr√©emptif, l'une des fa√ßons de mod√©liser la concurrence dans un programme lorsque nous nous appuyons sur le syst√®me d'exploitation dans la question Concurrence.  Ce mod√®le reste utile tant que nous comprenons que nous traitons sp√©cifiquement du mod√®le de concurrence, et non de la concurrence. <br><br>  Async / Wait est un sucre syntaxique pour State Machine, un autre mod√®le de concurrence utile qui peut s'ex√©cuter dans un environnement √† thread unique.  Il s'agit essentiellement du multit√¢che coop√©ratif - le mod√®le lui-m√™me ne prend pas du tout en compte le parall√©lisme.  En combinaison avec le multithreading, nous obtenons un mod√®le au-dessus d'un autre et la vie est tr√®s compliqu√©e. <br><br><h2>  Comparaison des deux mod√®les </h2><br><h4>  Comment cela a fonctionn√© dans le mod√®le multit√¢che pr√©emptif </h4><br>  Disons que nous avons 20 threads et 20 requ√™tes en traitement par seconde.  L'image montre un pic - 200 demandes dans le syst√®me en m√™me temps.  Comment cela pourrait-il arriver: <br><br><ul><li>  les demandes pourraient √™tre regroup√©es si 200 clients cliquaient sur un bouton en m√™me temps; </li><li>  le ramasse-miettes pourrait arr√™ter les demandes pendant plusieurs dizaines de millisecondes; </li><li>  les demandes peuvent √™tre retard√©es dans n'importe quelle file d'attente si le proxy prend en charge la file d'attente. </li></ul><br>  Il existe de nombreuses raisons pour lesquelles les demandes pour une courte p√©riode se sont accumul√©es et sont regroup√©es en un seul ensemble.  En tout cas, rien de terrible ne s'est produit, ils se tenaient dans la file d'attente Thread Pool et se sont lentement termin√©s.  Il n'y a plus de pics, tout se passe comme si de rien n'√©tait. <br><br>  Supposons que l'algorithme de pool de threads intelligent (et il y a des √©l√©ments d'apprentissage automatique l√†-bas) ait d√©cid√© qu'il n'y a jusqu'√† pr√©sent aucune raison d'augmenter le nombre de threads.  Le pool de connexions dans MySql est √©galement de 20 car Threads = 20.  En cons√©quence, nous n'avons besoin que de 20 connexions √† SQL. <br><br><img src="https://habrastorage.org/webt/gm/ch/pz/gmchpzxpvegoyljdauranwzgn7k.png"><br><br>  Dans ce cas, le niveau d'acc√®s concurrentiel du serveur du point de vue du syst√®me externe = 200. Le serveur a d√©j√† re√ßu ces demandes, mais ne les a pas encore termin√©es.  Cependant, pour une application s'ex√©cutant dans le paradigme Multithreading, le nombre de demandes simultan√©es est limit√© par la taille actuelle de Thread Pool = 20. Nous avons donc affaire au degr√© de concurrence = 20. <br><br><h4>  Comment tout fonctionne maintenant dans le mod√®le asynchrone </h4><br><img width="33%" height="33%" src="https://habrastorage.org/webt/dg/yz/pz/dgyzpzj-nl9rawn5ctxdfr3gxgm.png"><br><br>  Voyons ce qui se passe dans une application ex√©cutant async / wait avec la m√™me charge et distribution des requ√™tes.  Il n'y a pas de file d'attente avant de cr√©er une t√¢che et la demande est imm√©diatement trait√©e.  Bien s√ªr, Thread de ThreadPool est utilis√© pendant une courte p√©riode et la premi√®re partie de la demande, avant de contacter la base de donn√©es, est ex√©cut√©e imm√©diatement.  Parce que Thread retourne rapidement √† Thread Pool, nous n'avons pas besoin de beaucoup de Threads pour les traiter.  Dans ce diagramme, nous n'affichons pas du tout le groupe de threads, il est transparent. <br><br><img src="https://habrastorage.org/webt/bm/6h/to/bm6hto7o6gxnrlg9ruzhfsxfet0.png"><br><br>  Qu'est-ce que cela signifie pour notre application?  L'image ext√©rieure est la m√™me - le niveau de concurrence = 200. En m√™me temps, la situation √† l'int√©rieur a chang√©.  Auparavant, les demandes √©taient "encombr√©es" dans la file d'attente ThreadPool, maintenant le degr√© d'acc√®s concurrentiel de l'application est √©galement de 200, car nous n'avons aucune restriction de la part de TaskScheduler.  Hourra!  Nous avons atteint l'objectif asynchrone - l'application "faire face" √† presque tous les degr√©s de concurrence! <br><br><h4>  Cons√©quences: d√©gradation non lin√©aire du syst√®me </h4><br>  L'application est devenue transparente du point de vue de la concurrence, donc maintenant la concurrence est projet√©e sur la base de donn√©es.  Nous avons maintenant besoin d'un pool de connexions de la m√™me taille = 200. La base de donn√©es est le CPU, la m√©moire, le r√©seau, le stockage.  C'est le m√™me service avec ses probl√®mes, comme n'importe quel autre.  Plus nous essayons d'ex√©cuter de requ√™tes en m√™me temps, plus elles s'ex√©cutent lentement. <br><br>  √Ä pleine charge sur la base de donn√©es, au mieux, le temps de r√©ponse se d√©grade lin√©airement: vous avez donn√© deux fois plus de requ√™tes, il a commenc√© √† fonctionner deux fois plus lentement.  Dans la pratique, en raison de la concurrence entre les requ√™tes, une surcharge se produira n√©cessairement et il se peut que le syst√®me se d√©grade de fa√ßon non lin√©aire. <br><br><h4>  Pourquoi cela se produit-il? </h4><br>  Raisons de la deuxi√®me commande: <br><br><ul><li>  La base de donn√©es doit maintenant √™tre conserv√©e simultan√©ment dans la m√©moire de la structure de donn√©es pour r√©pondre √† davantage de demandes; </li><li>  D√©sormais, la base de donn√©es doit servir de plus grandes collections (ce qui est algorithmiquement d√©savantageux). </li></ul><br>  Raison du premier ordre: <br><br><ul><li>  argumentation, qui a √©t√© discut√© un peu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans l'article pr√©c√©dent</a> . </li></ul><br>  Au final, async se bat contre des ressources limit√©es et ... gagne!  La base de donn√©es √©choue et commence √† ralentir.  √Ä partir de cela, le serveur augmente encore la concurrence, et le syst√®me ne peut plus sortir de cette situation avec honneur. <br><br><h2>  Syndrome de mort subite du serveur </h2><br>  Parfois, une situation int√©ressante se produit.  Nous avons un serveur.  Il travaille pour lui comme √ßa, tout est en ordre.  Il y a suffisamment de ressources, m√™me avec une marge.  Ensuite, nous recevons soudainement un message des clients que le serveur ralentit.  Nous regardons le graphique et voyons qu'il y a eu une certaine augmentation de l'activit√© des clients, mais maintenant tout est normal.  Penser √† une attaque DOS ou √† une co√Øncidence.  Maintenant, tout semble aller bien.  Seulement maintenant, le serveur continue d'√™tre stupide, et tout est plus difficile jusqu'√† ce que les d√©lais d'attente commencent √† affluer.  Apr√®s un certain temps, un autre serveur qui utilise la m√™me base de donn√©es commence √©galement √† se plier.  Une situation famili√®re? <br><br><h4>  Pourquoi le syst√®me est-il mort? </h4><br>  Vous pouvez essayer d'expliquer cela par le fait qu'√† un moment donn√©, le serveur a re√ßu un nombre maximal de demandes et s'est ¬´cass√©¬ª.  Mais nous savons que la charge a √©t√© r√©duite, et le serveur ne s'est pas am√©lior√© pendant tr√®s longtemps, jusqu'√† ce que la charge disparaisse compl√®tement. <br><br>  La question rh√©torique: le serveur √©tait-il cens√© tomber en panne en raison d'une charge excessive?  Le font-ils? <br><br><h4>  Nous simulons une situation de plantage du serveur </h4><br>  Ici, nous n'analyserons pas les graphiques d'un vrai syst√®me de production.  Au moment de la panne du serveur, nous ne pouvons souvent pas obtenir un tel calendrier.  Le serveur manque de ressources CPU et, par cons√©quent, il ne peut pas √©crire de journaux ni fournir de mesures.  Sur les diagrammes au moment de la catastrophe, une rupture dans tous les graphiques est souvent observ√©e. <br><br>  Les SRE devraient √™tre capables de produire des syst√®mes de surveillance moins sujets √† cet effet.  Les syst√®mes qui, dans n'importe quelle situation, fournissent au moins certaines informations, et en m√™me temps, sont capables d'analyser des syst√®mes post mortem en utilisant des informations fragmentaires.  √Ä des fins √©ducatives, nous utilisons une approche l√©g√®rement diff√©rente dans cet article. <br><br>  Essayons de cr√©er un mod√®le qui fonctionne math√©matiquement comme un serveur sous charge.  Ensuite, nous √©tudierons les caract√©ristiques du serveur.  Nous ignorons la non-lin√©arit√© des serveurs r√©els et simulons une situation o√π une d√©c√©l√©ration lin√©aire se produit lorsque la charge d√©passe le nominal.  Deux fois plus de demandes que n√©cessaire - nous servons deux fois plus lentement. <br><br>  Cette approche permettra: <br><br><ul><li>  r√©fl√©chissez √† ce qui se passera au mieux; </li><li>  prendre des mesures pr√©cises. </li></ul><br>  Navigation planifi√©e: <br><br><ul><li>  bleu - le nombre de demandes au serveur; </li><li>  vert - r√©ponses du serveur; </li><li>  jaune - d√©lais d'attente; </li><li>  gris fonc√© - demandes qui ont √©t√© supprim√©es sur les ressources du serveur car le client n'a pas attendu de r√©ponse de d√©lai d'attente.  Parfois, un client peut signaler cela au serveur en se d√©connectant, mais en g√©n√©ral, un tel luxe peut √™tre techniquement impossible, par exemple, si le serveur effectue un travail li√© au processeur, sans coop√©ration avec le client. </li></ul><br><br><img src="https://habrastorage.org/webt/8d/r8/lr/8dr8lr7gizm-ovozc0laylwadaa.png"><br><br>  Pourquoi le graphique de demande du client (bleu dans le diagramme) s‚Äôest-il r√©v√©l√© √™tre le cas?  En r√®gle g√©n√©rale, le calendrier des commandes dans nos pizzerias cro√Æt en douceur le matin et diminue le soir.  Mais nous observons trois pics sur le fond de la courbe uniforme habituelle.  Cette forme du graphique n'a pas √©t√© choisie par hasard pour le mod√®le, mais plut√¥t.  Le mod√®le est n√© lors de l'enqu√™te sur un incident r√©el avec le serveur du centre de contact de la pizzeria en Russie lors de la Coupe du monde. <br><br><h2>  Cas "Coupe du monde" </h2><br>  Nous nous sommes assis et avons attendu plus de commandes.  Pr√©par√©s pour le championnat, les serveurs pourront d√©sormais passer un test de r√©sistance. <br><br>  Premier pic - les fans de football vont regarder le championnat, ils ont faim et ach√®tent de la pizza.  Au cours du premier semestre, ils sont occup√©s et ne peuvent pas commander.  Mais les gens qui sont indiff√©rents au football le peuvent, donc sur la carte tout se passe comme d'habitude. <br><br>  Et puis la premi√®re moiti√© se termine, et le deuxi√®me pic arrive.  Les fans sont devenus nerveux, affam√©s et ont pass√© trois fois plus de commandes qu'au premier pic.  La pizza s'ach√®te √† un prix terrible.  Ensuite, la deuxi√®me moiti√© commence, et encore pas √† la pizza. <br><br>  Pendant ce temps, le serveur du centre de contact commence √† se plier lentement et √† servir les demandes de plus en plus lentement.  Le composant syst√®me, dans ce cas, le serveur Web du centre d'appels, est d√©stabilis√©. <br><br>  Le troisi√®me pic arrivera √† la fin du match.  Les fans et le syst√®me attendent une p√©nalit√©. <br><br><h4>  Nous analysons les raisons de la panne du serveur </h4><br>  Qu'est-il arriv√©?  Le serveur peut contenir 100 requ√™tes conditionnelles.  Nous comprenons qu'il est con√ßu pour cette puissance et ne le supportera plus.  Un pic arrive, qui en soi n'est pas si grand.  Mais la zone grise de la concurrence est beaucoup plus √©lev√©e. <br><br>  Le mod√®le est con√ßu de mani√®re √† ce que la concurrence soit num√©riquement √©gale au nombre de commandes par seconde, donc visuellement sur le graphique, elle devrait √™tre de la m√™me √©chelle.  Cependant, il est beaucoup plus √©lev√© car il s'accumule. <br><br>  Nous voyons ici une ombre du graphique - ce sont des demandes qui ont commenc√© √† retourner au client, ex√©cut√©es (indiqu√©es par la premi√®re fl√®che rouge).  L'√©chelle de temps est conditionnelle pour voir le d√©calage temporel.  Le deuxi√®me pic a d√©j√† assomm√© notre serveur.  Il s'est √©cras√© et a commenc√© √† traiter quatre fois moins de demandes que d'habitude. <br><br><img src="https://habrastorage.org/webt/n1/92/qw/n192qwxtwdrfatt_a-lb8y8eire.png"><br><br>  Dans la seconde moiti√© du graphique, il est clair que certaines demandes √©taient toujours ex√©cut√©es au d√©but, mais des taches jaunes sont ensuite apparues - les demandes ont compl√®tement cess√©. <br><br><img src="https://habrastorage.org/webt/pi/la/nv/pilanvzebdl_vl3k3hno9vwezga.png"><br><br>  Encore une fois tout le programme.  On peut voir que la concurrence se d√©cha√Æne.  Une √©norme montagne appara√Æt. <br><br><img src="https://habrastorage.org/webt/ci/l6/kb/cil6kblebzhjokmuvzkwolmngvo.png"><br><br>  Habituellement, nous avons analys√© des mesures compl√®tement diff√©rentes: la vitesse √† laquelle la demande a √©t√© trait√©e, le nombre de demandes par seconde.  Nous ne regardons m√™me pas la concurrence, nous n'avons m√™me pas pens√© √† cette m√©trique.  Mais en vain, car c'est pr√©cis√©ment cette quantit√© qui montre le mieux le moment de d√©faillance du serveur. <br><br>  Mais d'o√π venait une montagne si √©norme?  Le plus gros pic de charge est pass√© depuis longtemps! <br><br><h2>  Little Law </h2><br>  La loi de Little r√©git la concurrence. <br><br>  <i>L (nombre de clients dans le syst√®me) = Œª (vitesse de leur s√©jour) ‚àó W (temps qu'ils passent √† l'int√©rieur du syst√®me)</i> <br><br>  C'est une moyenne.  Cependant, notre situation √©volue dramatiquement, la moyenne ne nous convient pas.  Nous diff√©rencierons cette √©quation, puis int√©grerons.  Pour ce faire, regardez le livre de John Little, qui a invent√© cette formule, et voyez l'int√©grale l√†. <br><br><img src="https://habrastorage.org/webt/sx/f5/dz/sxf5dzgwc9l7low8fild5cpsrf0.png"><br><br>  Nous avons le nombre d'entr√©es dans le syst√®me et le nombre de ceux qui quittent le syst√®me.  La demande arrive et part lorsque tout est termin√©.  Vous trouverez ci-dessous une r√©gion de croissance du graphique correspondant √† la croissance lin√©aire de la concurrence. <br><br><img src="https://habrastorage.org/webt/ax/rv/du/axrvdu3vyx1iw9afieohv5pe-cs.png"><br><br>  Il y a peu de demandes vertes.  Ce sont ceux qui sont r√©ellement mis en ≈ìuvre.  Les bleus sont ceux qui viennent.  Entre temps, nous avons le nombre habituel de demandes, la situation est stable.  Mais la concurrence continue de cro√Ætre.  Le serveur ne fera plus face √† cette situation.  Cela signifie qu'il va bient√¥t tomber. <br><br>  Mais pourquoi la concurrence augmente-t-elle?  Nous regardons l'int√©grale de la constante.  Rien ne change dans notre syst√®me, mais l'int√©grale ressemble √† une fonction lin√©aire qui ne fait que cro√Ætre. <br><br><h2>  Allons-nous jouer? </h2><br>  L'explication avec les int√©grales est compliqu√©e si vous ne vous souvenez pas des math√©matiques.  Ici, je propose de me r√©chauffer et de jouer au jeu. <br><br><h4>  Num√©ro de jeu 1 </h4><br>  <b>Pr√©requis</b> : le serveur re√ßoit des requ√™tes, chacune n√©cessite trois p√©riodes de traitement sur la CPU.  La ressource CPU est r√©partie √©galement entre toutes les t√¢ches.  Ceci est similaire √† la fa√ßon dont les ressources CPU sont consomm√©es pendant le multit√¢che pr√©emptif.  Le nombre dans la cellule signifie la quantit√© de travail restant apr√®s cette mesure.  Pour chaque √©tape conditionnelle, une nouvelle demande arrive. <br><br>  Imaginez que vous ayez re√ßu une demande.  Il ne reste que 3 unit√©s de travail, √† la fin de la premi√®re p√©riode de traitement, il reste 2 unit√©s. <br><br>  Dans la deuxi√®me p√©riode, une autre demande est en couches, maintenant les deux CPU sont occup√©s.  Ils ont effectu√© une unit√© de travail pour les deux premi√®res requ√™tes.  Il reste √† compl√©ter respectivement 1 et 2 unit√©s pour la premi√®re et la deuxi√®me demande. <br><br>  Maintenant, la troisi√®me demande est arriv√©e et le plaisir commence.  Il semblerait que la premi√®re demande aurait d√ª √™tre termin√©e, mais pendant cette p√©riode, trois demandes partagent d√©j√† la ressource CPU, de sorte que le degr√© d'ach√®vement pour les trois demandes est d√©sormais fractionn√© √† la fin de la troisi√®me p√©riode de traitement: <br><br><img src="https://habrastorage.org/webt/k-/tq/mv/k-tqmvjsqabbv0zgwt_vmkfkhy4.png"><br><br>  Encore plus int√©ressant!  La quatri√®me demande est ajout√©e, et maintenant le degr√© de concurrence est d√©j√† de 4, car les quatre demandes n√©cessitaient une ressource au cours de cette p√©riode.  Pendant ce temps, la premi√®re demande √† la fin de la quatri√®me p√©riode est d√©j√† termin√©e, elle ne passe pas √† la p√©riode suivante et il reste 0 t√¢ches pour le CPU. <br><br>  La premi√®re demande √©tant d√©j√† termin√©e, r√©sumons pour lui: elle a dur√© un tiers de plus que pr√©vu.  On a suppos√© que la longueur de chaque t√¢che horizontalement id√©alement = 3, selon la quantit√© de travail.  Nous le marquons en orange, signe que nous ne sommes pas enti√®rement satisfaits du r√©sultat. <br><br><img src="https://habrastorage.org/webt/ap/9n/uy/ap9nuyfqun_gd1ggeidqdlomxuy.png"><br><br>  La cinqui√®me demande arrive.  Le degr√© de concurrence est toujours de 4, mais nous voyons que dans la cinqui√®me colonne, le travail restant est plus global.  En effet, il reste plus de travail dans la quatri√®me colonne que dans la troisi√®me. <br><br>  Nous continuons encore trois p√©riodes.  En attente de r√©ponses. <br>  - Serveur, bonjour! <br>  - ... <br><br><img src="https://habrastorage.org/webt/tv/2m/8r/tv2m8r8selzumgub75zkvs78deu.png"><br><br>  "Votre appel est tr√®s important pour nous ..." <br><br><img src="https://habrastorage.org/webt/ud/k9/rk/udk9rk7ynqduovmhyymp7shqe0q.png"><br><br>  Eh bien, est finalement venue la r√©ponse √† la deuxi√®me demande.  Les temps de r√©ponse sont deux fois plus longs que pr√©vu. <br><br><img src="https://habrastorage.org/webt/tt/7m/iv/tt7mivq-stfincjhlwxm7wqznsq.png"><br><br>  Le degr√© de concurrence a d√©j√† tripl√©, et rien ne pr√©sage que la situation va s'am√©liorer.  Je n'ai pas dessin√© plus loin, car le temps de r√©ponse √† la troisi√®me requ√™te ne rentrera plus dans l'image. <br><br><blockquote>  Notre serveur est entr√© dans un √©tat ind√©sirable, dont il ne sortira jamais seul.  <b>Game over</b> </blockquote><br><h2>  Qu'est-ce qui caract√©rise l'√©tat GameOver du serveur? </h2><br>  Les demandes sont accumul√©es ind√©finiment en m√©moire.  T√¥t ou tard, la m√©moire cessera tout simplement.  De plus, avec une augmentation d'√©chelle, la surcharge du processeur pour l'entretien de diverses structures de donn√©es augmente.  Par exemple, le pool de connexions doit d√©sormais suivre les d√©lais d'expiration pour plus de connexions, le garbage collector doit maintenant rev√©rifier plus d'objets sur le tas, etc. <br><br>  Explorer toutes les cons√©quences possibles de l'accumulation d'objets actifs n'est pas le but de cet article, mais m√™me une simple accumulation de donn√©es en RAM suffit d√©j√† pour remplir le serveur.  De plus, nous avons d√©j√† vu que le serveur client projette ses probl√®mes d'acc√®s concurrentiel sur le serveur de base de donn√©es et sur d'autres serveurs qu'il utilise en tant que client. <br><br>  La chose la plus int√©ressante: maintenant, m√™me si vous soumettez une charge inf√©rieure au serveur, il ne r√©cup√©rera toujours pas.  Toutes les demandes se termineront par un d√©lai d'expiration et le serveur consommera toutes les ressources disponibles. <br><br>  Et √† quoi nous attendions-nous r√©ellement?!  Apr√®s tout, nous avons sciemment donn√© au serveur une quantit√© de travail qu'il ne pouvait pas g√©rer. <br><br>  Lorsque vous traitez avec une architecture de syst√®me distribu√©, il est utile de r√©fl√©chir √† la fa√ßon dont les gens ordinaires r√©solvent ces probl√®mes.  Prenez, par exemple, une bo√Æte de nuit.  Il cessera de fonctionner si trop de personnes y entrent.  Le videur r√©sout le probl√®me simplement: il regarde combien de personnes sont √† l'int√©rieur.  Un √† gauche - en lance un autre.  Un nouvel invit√© viendra appr√©cier la taille de la file d'attente.  Si la file d'attente est longue, il rentrera chez lui.  Et si vous appliquez cet algorithme au serveur? <br><br><img src="https://habrastorage.org/webt/wg/tn/p3/wgtnp3n6qq57dqzfi-ac9s0rj1u.png"><br><br>  Jouons √† nouveau. <br><br><h4>  Num√©ro de jeu 2 </h4><br>  <b>Pr√©requis</b> : Encore une fois, nous avons deux processeurs, les m√™mes t√¢ches de 3 unit√©s, arrivant √† chaque p√©riode, mais maintenant nous allons d√©finir le videur, et les t√¢ches seront intelligentes - s'ils voient que la longueur de la file d'attente est de 2, ils rentrent imm√©diatement √† la maison. <br><br><img src="https://habrastorage.org/webt/b4/cs/gt/b4csgtkcmi3hw1qog4fko6aus2o.png"><br><br><img src="https://habrastorage.org/webt/uw/gi/-v/uwgi-vopihzere8fs_c5f5yctfo.png"><br><br>  La troisi√®me demande est venue.  Dans cette p√©riode, il fait la queue.  Il a le num√©ro 3 √† la fin de la p√©riode.  Il n'y a pas de nombres fractionnaires dans les r√©sidus, car deux CPU effectuent deux t√¢ches, une pour une p√©riode. <br><br>  Bien que nous ayons trois demandes en couches, le degr√© de concurrence √† l'int√©rieur du syst√®me = 2. La troisi√®me est dans la file d'attente et ne compte pas. <br><br><img src="https://habrastorage.org/webt/nm/x4/yw/nmx4ywd6xdqyte5b6vkwgco3hdq.png"><br><br>  Le quatri√®me est venu - la m√™me image, bien que plus de travail ait d√©j√† √©t√© accumul√©. <br><br><img src="https://habrastorage.org/webt/uq/jb/_5/uqjb_5b8whjwjzzetwqwrzjusfy.png"><br>  ... <br>  ... <br><br>  Dans la sixi√®me p√©riode, la troisi√®me demande a √©t√© trait√©e avec un troisi√®me d√©calage, et le degr√© de concurrence est d√©j√† = 4. <br><br><img src="https://habrastorage.org/webt/xs/i1/sf/xsi1sf60jniqqbamvlko-bmd_xa.png"><br><br>  Le degr√© de concurrence a doubl√©.  Elle ne peut plus grandir, car nous avons clairement interdit cela.  Avec une vitesse maximale, seules les deux premi√®res demandes ont √©t√© trait√©es - celles qui sont venues en premier au club, alors qu'il y avait suffisamment d'espace pour tout le monde. <br><br>  Les demandes jaunes √©taient dans le syst√®me plus longtemps, mais elles √©taient en ligne et n'ont pas retard√© la ressource CPU.  Par cons√©quent, ceux qui √©taient √† l'int√©rieur s'amusaient.  Cela pourrait continuer jusqu'√† ce qu'un homme vienne et dise qu'il ne ferait pas la queue, mais plut√¥t qu'il rentrerait chez lui.  Il s'agit d'une demande ayant √©chou√©: <br><br><img src="https://habrastorage.org/webt/tf/qf/qr/tfqfqrsfqvhxphy3wzrdqf_cpvk.png"><br><br>  La situation peut √™tre r√©p√©t√©e √† l'infini, tandis que le temps d'ex√©cution de la requ√™te reste au m√™me niveau - exactement deux fois plus longtemps que nous le souhaiterions. <br><br><img src="https://habrastorage.org/webt/xh/l2/8-/xhl28-uoe_jao9hjppy5zc30in8.png"><br><br>  Nous voyons qu'une simple restriction sur le niveau de concurrence √©limine le probl√®me de viabilit√© du serveur. <br><br><h4>  Comment augmenter la viabilit√© du serveur via la limite de niveau d'acc√®s concurrentiel </h4><br>  Vous pouvez √©crire vous-m√™me le ¬´videur¬ª le plus simple.  Ci-dessous, le code utilisant le s√©maphore.  Il n'y a pas de limite √† la longueur de la ligne ext√©rieure.  Le code est uniquement √† des fins d'illustration, pas besoin de le copier. <br><br><pre><code class="swift hljs">const int <span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span> = <span class="hljs-number"><span class="hljs-number">100</span></span>; <span class="hljs-type"><span class="hljs-type">SemaphoreSlim</span></span> bulkhead = new <span class="hljs-type"><span class="hljs-type">SemaphoreSlim</span></span>(<span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span>, <span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> async <span class="hljs-type"><span class="hljs-type">Task</span></span> <span class="hljs-type"><span class="hljs-type">ProcessRequest</span></span>() { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!await bulkhead.<span class="hljs-type"><span class="hljs-type">WaitAsync</span></span>()) { <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> new <span class="hljs-type"><span class="hljs-type">OperationCanceledException</span></span>(); } <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { await <span class="hljs-type"><span class="hljs-type">ProcessRequestInternal</span></span>(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } finally { bulkhead.<span class="hljs-type"><span class="hljs-type">Release</span></span>(); } }</code> </pre> <br>  Pour cr√©er une file d'attente limit√©e, vous avez besoin de deux s√©maphores.  Pour cela, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la biblioth√®que Polly</a> , que Microsoft recommande, convient.  Faites attention au motif de cloison.  Traduit litt√©ralement par ¬´cloison¬ª - un √©l√©ment structurel qui permet au navire de ne pas couler.  Pour √™tre honn√™te, je pense que le terme videur est mieux adapt√©.  L'important est que ce mod√®le permette au serveur de survivre dans des situations d√©sesp√©r√©es. <br><br>  Tout d'abord, nous extrayons tout ce qui est possible sur le banc de charge du serveur jusqu'√† ce que nous d√©terminions le nombre de demandes qu'il peut contenir.  Par exemple, nous avons d√©termin√© qu'il est de 100. Nous avons mis une cloison. <br><br>  De plus, le serveur ne sautera que le nombre requis de demandes, le reste sera mis en file d'attente.  Il serait sage de choisir un nombre l√©g√®rement plus petit pour qu'il y ait une marge.  Je n'ai pas de recommandation toute faite √† ce sujet, car il y a une forte d√©pendance au contexte et √† la situation sp√©cifique. <br><br><ol><li>  Si le comportement du serveur d√©pend de mani√®re stable de la charge en termes de ressources, alors ce nombre peut approcher la limite. </li><li>  Si le support est soumis √† des fluctuations de charge, un nombre plus prudent doit √™tre choisi, en tenant compte de la taille de ces fluctuations.  De telles fluctuations peuvent se produire pour diverses raisons, par exemple, l'environnement de performance avec GC est caract√©ris√© par de petits pics de charge sur le CPU. </li><li>  Si le serveur effectue des t√¢ches p√©riodiques selon un calendrier, cela doit √©galement √™tre pris en compte.  Vous pouvez m√™me d√©velopper une cloison adaptative qui calculera le nombre de requ√™tes pouvant √™tre envoy√©es simultan√©ment sans d√©gradation du serveur (mais cela d√©passe d√©j√† le cadre de cette √©tude). </li></ol><br><h2>  Exp√©riences de requ√™te </h2><br>  Jetez un ≈ìil √† ce post-mortem en dernier, nous ne le verrons plus. <br><img src="https://habrastorage.org/webt/n1/qn/1i/n1qn1irfrgm-fezifzonark7j94.png"><br>  Tout ce tas gris est sans √©quivoque en corr√©lation avec le crash du serveur.  Gray est la mort du serveur.  Disons simplement le couper et voir ce qui se passe.  Il semble qu'un certain nombre de demandes rentreront chez elles, ne seront tout simplement pas satisfaites.  Mais combien? <br><br><h4>  100 √† l'int√©rieur, 100 √† l'ext√©rieur </h4><br><img src="https://habrastorage.org/webt/u0/6c/m5/u06cm5odrt-dxltnomhwatmhwze.png"><br>  Il s'est av√©r√© que notre serveur a commenc√© √† vivre tr√®s bien et amusant.  Il laboure constamment √† puissance maximale.  Bien s√ªr, lorsqu'un pic survient, cela le met √† la porte, mais pas pour longtemps. <br><br>  Inspir√© par le succ√®s, nous allons essayer de nous assurer qu'il ne rebondit pas du tout.  Essayons d'augmenter la longueur de la file d'attente. <br><br><h4>  100 √† l'int√©rieur, 500 √† l'ext√©rieur </h4><br><img src="https://habrastorage.org/webt/sk/5i/gi/sk5igi9cfgyjajp8lujawwunace.png"><br><br>  √áa s'est am√©lior√©, mais la queue a grandi.  Ce sont les demandes qui sont ex√©cut√©es longtemps apr√®s. <br><br><h4>  100 √† l'int√©rieur, 1000 √† l'ext√©rieur </h4><br>  Puisque quelque chose s'est am√©lior√©, essayons de l'amener au point d'absurdit√©.  R√©solvons la longueur de la file d'attente 10 fois plus que ce que nous pouvons servir simultan√©ment: <br><br><img src="https://habrastorage.org/webt/2g/qd/s6/2gqds68piszleawyid_yk_rtdhg.png"><br><br>  Si nous parlons de la m√©taphore du club et des videurs, cette situation n'est gu√®re possible - personne ne veut attendre plus longtemps √† l'entr√©e que passer du temps dans le club.  Nous ne pr√©tendrons pas non plus qu'il s'agit d'une situation normale pour notre syst√®me. <br><br>  Il vaut mieux ne pas servir le client du tout que le tourmenter sur le site ou dans l'application mobile en chargeant chaque √©cran pendant 30 secondes et en g√¢chant la r√©putation de l'entreprise.  Il vaut mieux dire imm√©diatement et honn√™tement √† une petite partie des clients que nous ne pouvons plus les servir.  Sinon, nous servirons tous les clients plusieurs fois plus lentement, car le graphique montre que la situation persiste pendant un certain temps. <br><br>  Il existe un risque suppl√©mentaire: d'autres composants syst√®me peuvent ne pas √™tre con√ßus pour un tel comportement de serveur et, comme nous le savons d√©j√†, la concurrence est projet√©e sur les clients. <br><br>  Par cons√©quent, nous revenons √† la premi√®re option ¬´100 pour 100¬ª et r√©fl√©chissons √† la mani√®re de dimensionner nos capacit√©s. <br><br><h4>  Gagnant - 100 √† l'int√©rieur, 100 √† l'ext√©rieur </h4><br><img src="https://habrastorage.org/webt/z5/cg/pv/z5cgpvn4qs9abj5ifewfelapa6g.png"><br><br>  ¬Ø \ _ („ÉÑ) _ / ¬Ø <br><br>  Avec ces param√®tres, la plus grande d√©gradation de l'ex√©cution est exactement 2 fois la ¬´valeur nominale¬ª.  Dans le m√™me temps, c'est une d√©gradation de 100% du temps d'ex√©cution des requ√™tes. <br><br>  Si votre client est sensible au temps d'ex√©cution (et cela est g√©n√©ralement vrai √† la fois avec les clients humains et les clients serveur), vous pouvez alors envisager de r√©duire davantage la longueur de la file d'attente.  Dans ce cas, nous pouvons prendre un certain pourcentage de la concurrence interne, et nous saurons avec certitude que le service ne se d√©grade pas dans le temps de r√©ponse de plus de ce pourcentage en moyenne. <br><br>  En fait, nous n'essayons pas de cr√©er une file d'attente, nous essayons de nous prot√©ger des fluctuations de charge.  Ici, tout comme dans le cas de la d√©termination du premier param√®tre de la cloison (quantit√© √† l'int√©rieur), il est utile de d√©terminer quelles fluctuations de la charge le client peut provoquer.  Nous saurons donc dans quels cas, grosso modo, nous manquerons le profit d'un service potentiel. <br><br>  Il est encore plus important de d√©terminer quelles fluctuations de latence peuvent supporter d'autres composants du syst√®me interagissant avec le serveur.  Nous saurons donc que nous tirons vraiment le maximum du syst√®me existant sans risquer de perdre compl√®tement le service. <br><br><h2>  Diagnostic et traitement </h2><br>  Nous traitons la concurrence non contr√¥l√©e avec l'isolement de cloison. <br>  Cette m√©thode, comme les autres discut√©es dans cette s√©rie d'articles, est commod√©ment impl√©ment√©e par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la biblioth√®que Polly</a> . <br><br>  L'avantage de la m√©thode est qu'il sera extr√™mement difficile de d√©stabiliser un composant individuel du syst√®me en tant que tel.  Le syst√®me acquiert un comportement tr√®s pr√©visible en termes de temps pour les demandes r√©ussies et des chances beaucoup plus √©lev√©es pour les demandes compl√®tes r√©ussies. <br><br>  Cependant, nous ne r√©solvons pas tous les probl√®mes.  Par exemple, le probl√®me d'une alimentation insuffisante du serveur.  Dans cette situation, vous devez √©videmment d√©cider de ¬´larguer le ballast¬ª en cas de saut de charge, que nous avons jug√© excessif. <br><br>  D'autres mesures que notre √©tude ne traite pas peuvent inclure, par exemple, la mise √† l'√©chelle dynamique. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr461081/">https://habr.com/ru/post/fr461081/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr461071/index.html">Optimisation des requ√™tes de base de donn√©es sur l'exemple de service B2B pour les constructeurs</a></li>
<li><a href="../fr461073/index.html">Nous connectons des cartes en ligne au navigateur sur le smartphone. Partie 3 - OverpassTurbo</a></li>
<li><a href="../fr461075/index.html">Intelligence d'affaires. Objets informatiques, composants, outils</a></li>
<li><a href="../fr461077/index.html">Comment les pentesters sont-ils cuits? Test d'entr√©e pour les stagiaires en s√©curit√© num√©rique</a></li>
<li><a href="../fr461079/index.html">Ville sans embouteillage</a></li>
<li><a href="../fr461083/index.html">Logiciel d'√©criture avec la fonctionnalit√© des utilitaires client-serveur Windows, partie 02</a></li>
<li><a href="../fr461085/index.html">Changer de langue dans l'application Android</a></li>
<li><a href="../fr461087/index.html">G√©n√©rer des donjons et des grottes pour mon jeu</a></li>
<li><a href="../fr461091/index.html">Lampes LED Camelion</a></li>
<li><a href="../fr461093/index.html">Nouvelles du monde d'OpenStreetMap n ¬∞ 469 (07/09/2019 - 07/07/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
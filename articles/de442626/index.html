<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤷🏻 🤶🏽 🥓 Habraiting: Aufbau einer Wolke russischsprachiger Wörter am Beispiel von Habra-Headern ⚾️ 👮 👢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr. 

 Im letzten Teil von Habraiting wurde eine Methode zum Erstellen einer Wortwolke für englische Begriffe veröffentlicht. Natürlich ist di...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Habraiting: Aufbau einer Wolke russischsprachiger Wörter am Beispiel von Habra-Headern</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/442626/">  Hallo Habr. <br><br>  Im letzten Teil von Habraiting wurde eine Methode zum Erstellen einer Wortwolke für englische Begriffe veröffentlicht.  Natürlich ist die Aufgabe, russische Wörter zu analysieren, viel komplizierter, aber wie in den Kommentaren vorgeschlagen, gibt es dafür vorgefertigte Bibliotheken. <br><br>  Lassen Sie uns herausfinden, wie man ein solches Bild erstellt: <br><br><img src="https://habrastorage.org/webt/8c/ct/a6/8ccta6jikwu2sfopuhf7fdpetgu.png"><br><br>  Außerdem werden wir eine Wolke von Artikeln von Habr für alle Jahre sehen. <br><br>  Wen interessiert es, was passiert ist, bitte unter der Katze. <br><a name="habracut"></a><br><h2>  Parsen </h2><br>  Der ursprüngliche Datensatz ist wie im vorherigen Fall csv mit den Überschriften der Artikel von Habr von 2006 bis 2019.  Wenn jemand daran interessiert ist, es selbst zu versuchen, können Sie es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> herunterladen. <br><br>  Laden Sie zunächst die Daten in den Pandas-Datenrahmen und wählen Sie die Header für das gewünschte Jahr aus. <br><br><pre><code class="python hljs">df = pd.read_csv(log_path, sep=<span class="hljs-string"><span class="hljs-string">','</span></span>, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>, error_bad_lines=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, quotechar=<span class="hljs-string"><span class="hljs-string">'"'</span></span>, comment=<span class="hljs-string"><span class="hljs-string">'#'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> year != <span class="hljs-number"><span class="hljs-number">0</span></span>: dates = pd.to_datetime(df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>], format=<span class="hljs-string"><span class="hljs-string">'%Y-%m-%dT%H:%MZ'</span></span>) df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] = dates df = df[(df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] &gt;= pd.Timestamp(datetime.date(year, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))) &amp; ( df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] &lt; pd.Timestamp(datetime.date(year + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)))] <span class="hljs-comment"><span class="hljs-comment"># Remove some unicode symbols def unicode2str(s): try: return s.replace(u'\u2014', u'-').replace(u'\u2013', u'-').replace(u'\u2026', u'...').replace(u'\xab', u"'").replace(u'\xbb', u"'") except: return s titles = df["title"].map(unicode2str, na_action=None)</span></span></code> </pre> <br>  Die Funktion unicode2str wird benötigt, um verschiedene knifflige Unicode-Zeichen aus der Konsolenausgabe zu entfernen, z. B. nicht standardmäßige Anführungszeichen. Unter OSX funktionierte dies ebenfalls. Bei der Ausgabe an Windows Powershell wurde der Fehler "UnicodeEncodeError: 'charmap'-Codec kann Zeichen nicht codieren" ausgegeben.  Es war zu faul, mit Powershell-Einstellungen umzugehen, daher erwies sich diese Methode als die einfachste. <br><br>  Der nächste Schritt besteht darin, russischsprachige Wörter von allen anderen zu trennen.  Es ist ganz einfach - wir übersetzen die Zeichen in ASCII-Codierung und sehen, was noch übrig ist.  Wenn mehr als 2 Zeichen übrig sind, betrachten wir das Wort "voll" (die einzige Ausnahme, die mir in den Sinn kommt, ist die Go-Sprache, aber diejenigen, die dies wünschen, können sie selbst hinzufügen). <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_ascii</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: s = s.replace(<span class="hljs-string"><span class="hljs-string">"'"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>).replace(<span class="hljs-string"><span class="hljs-string">"-"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>).replace(<span class="hljs-string"><span class="hljs-string">"|"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s.decode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>).encode(<span class="hljs-string"><span class="hljs-string">"ascii"</span></span>, errors=<span class="hljs-string"><span class="hljs-string">"ignore"</span></span>).decode() <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">is_asciiword</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> ascii_word = to_ascii(s) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> len(ascii_word) &gt; <span class="hljs-number"><span class="hljs-number">2</span></span></code> </pre><br>  Die nächste Aufgabe besteht darin, das Wort zu normalisieren. Um eine Wortwolke abzuleiten, muss jedes Wort in einem Fall und in einer Deklination angezeigt werden.  Für Englisch entfernen wir einfach die "'s" am Ende und auch andere unlesbare Zeichen wie Klammern.  Ich bin mir nicht sicher, ob diese Methode wissenschaftlich korrekt ist (und ich bin kein Linguist), aber für diese Aufgabe ist sie völlig ausreichend. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normal_eng</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> sym <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (<span class="hljs-string"><span class="hljs-string">"'s"</span></span>, <span class="hljs-string"><span class="hljs-string">'{'</span></span>, <span class="hljs-string"><span class="hljs-string">'}'</span></span>, <span class="hljs-string"><span class="hljs-string">"'"</span></span>, <span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">'}'</span></span>, <span class="hljs-string"><span class="hljs-string">';'</span></span>, <span class="hljs-string"><span class="hljs-string">'.'</span></span>, <span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">'['</span></span>, <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'('</span></span>, <span class="hljs-string"><span class="hljs-string">')'</span></span>, <span class="hljs-string"><span class="hljs-string">'-'</span></span>, <span class="hljs-string"><span class="hljs-string">'/'</span></span>, <span class="hljs-string"><span class="hljs-string">'\\'</span></span>): s = s.replace(sym, <span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s.lower().strip()</code> </pre><br>  Das Wichtigste, für das eigentlich alles begonnen hat, ist das Parsen russischer Wörter.  Wie in den Kommentaren zum vorherigen Teil empfohlen, kann dies für Python mithilfe der pymorphy2-Bibliothek erfolgen.  Mal sehen, wie es funktioniert. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pymorphy2 morph = pymorphy2.MorphAnalyzer() res = morph.parse(<span class="hljs-string"><span class="hljs-string">u""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> r.normal_form, r.tag.case</code> </pre> <br>  Für dieses Beispiel haben wir die folgenden Ergebnisse: <br><br><pre> <code class="python hljs"> NOUN,inan,masc sing,datv datv  NOUN,inan,masc sing,loc2 loc2  NOUN,inan,neut sing,datv datv  NOUN,inan,masc sing,gen2 gen2</code> </pre><br>  Für das Wort "Welt" definierte MorphAnalyzer "Normalform" als das Substantiv "Welt" (oder "Welt", ich weiß jedoch nicht, was es ist), Singular und mögliche Fälle als Dativ, Genitiv oder Lokativ. <br><br>  Die Verwendung der MorphAnalyzer-Analyse ist recht einfach. Stellen Sie sicher, dass das Wort ein Substantiv ist, und leiten Sie seine normale Form ab. <br><br><pre> <code class="python hljs">morph = pymorphy2.MorphAnalyzer() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normal_rus</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(w)</span></span></span><span class="hljs-function">:</span></span> res = morph.parse(w) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">'NOUN'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> r.tag: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> r.normal_form <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span></code> </pre><br>  Es bleibt alles zusammen zu sammeln und zu sehen, was passiert ist.  Der Code sieht ungefähr so ​​aus (irrelevante Fragmente entfernt): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Counter c_dict = Counter() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> titles.values: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> s.split(): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> is_asciiword(w): <span class="hljs-comment"><span class="hljs-comment"># English word or digit n = normal_eng(w) c_dict[n] += 1 else: # Russian word n = normal_rus(w) if n is not None: c_dict[n] += 1</span></span></code> </pre><br>  Am Ausgang haben wir ein Wörterbuch mit Wörtern und deren Anzahl.  Wir leiten die ersten 100 ab und bilden daraus eine Wolke der Beliebtheit von Wörtern: <br><br><pre> <code class="python hljs">common = c_dict.most_common(<span class="hljs-number"><span class="hljs-number">100</span></span>) wc = WordCloud(width=<span class="hljs-number"><span class="hljs-number">2600</span></span>, height=<span class="hljs-number"><span class="hljs-number">2200</span></span>, background_color=<span class="hljs-string"><span class="hljs-string">"white"</span></span>, relative_scaling=<span class="hljs-number"><span class="hljs-number">1.0</span></span>, collocations=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, min_font_size=<span class="hljs-number"><span class="hljs-number">10</span></span>).generate_from_frequencies(dict(common)) plt.axis(<span class="hljs-string"><span class="hljs-string">"off"</span></span>) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>)) plt.imshow(wc, interpolation=<span class="hljs-string"><span class="hljs-string">"bilinear"</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"%d"</span></span> % year) plt.xticks([]) plt.yticks([]) plt.tight_layout() file_name = <span class="hljs-string"><span class="hljs-string">'habr-words-%d.png'</span></span> % year plt.show()</code> </pre><br>  Das Ergebnis erwies sich jedoch als sehr seltsam: <br><br><img src="https://habrastorage.org/webt/eo/3e/is/eo3eisf-_suvjfhpempv5m4juhk.png"><br><br>  In Textform sah es so aus: <br><br><pre> <code class="python hljs">  <span class="hljs-number"><span class="hljs-number">3958</span></span>  <span class="hljs-number"><span class="hljs-number">3619</span></span>  <span class="hljs-number"><span class="hljs-number">1828</span></span>  <span class="hljs-number"><span class="hljs-number">840</span></span> <span class="hljs-number"><span class="hljs-number">2018</span></span> <span class="hljs-number"><span class="hljs-number">496</span></span>  <span class="hljs-number"><span class="hljs-number">389</span></span>  <span class="hljs-number"><span class="hljs-number">375</span></span>  <span class="hljs-number"><span class="hljs-number">375</span></span></code> </pre><br>  Die Wörter "Performing", "Second" und "Century" waren mit großem Abstand führend.  Und obwohl es im Prinzip möglich ist (Sie können sich vorstellen, dass eine Überschrift wie „Das Durchsuchen von Passwörtern mit einer Geschwindigkeit von 1000 Mal pro Sekunde dauert ein Jahrhundert“), war es verdächtig, dass es so viele dieser Wörter gab.  Und nicht umsonst - wie das Debuggen zeigte, definierte MorphAnalyzer das Wort "c" als "Sekunde" und das Wort "c" als "Jahrhundert".  Das heißt,  In der Überschrift "Verwenden von Technologie ..." hat MorphAnalyzer drei Wörter hervorgehoben - "Sekunde", "Hilfe", "Technologie", was offensichtlich falsch ist.  Die nächsten obskuren Wörter waren "wann" ("bei Verwendung ...") und "bereits", die als das Substantiv "direkt" bzw. "bereits" definiert wurden.  Die Lösung war einfach: Berücksichtigen Sie beim Parsen nur Wörter, die länger als 2 Zeichen sind, und geben Sie eine Liste der Ausnahmewörter in russischer Sprache ein, die von der Analyse ausgeschlossen werden.  Auch dies ist vielleicht nicht ganz wissenschaftlich (zum Beispiel wäre ein Artikel über das „Beobachten eines Farbwechsels durch bereits“ aus der Analyse herausgefallen), aber für diese Aufgabe ist bereits :) ausreichend. <br><br>  Das Endergebnis ist mehr oder weniger der Wahrheit ähnlich (mit Ausnahme von Go und möglichen Artikeln über Schlangen).  Es bleibt noch alles in einem GIF zu speichern (der GIF-Generierungscode befindet sich im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorherigen Teil</a> ), und wir erhalten ein animiertes Ergebnis in Form der Beliebtheit von Schlüsselwörtern in den Überschriften von Habr von 2006 bis 2019. <br><br><img src="https://habrastorage.org/webt/gw/pq/ef/gwpqeflpg6h6wd8f30xiwr_irnk.gif"><br><br><h2>  Fazit </h2><br>  Wie Sie sehen, erwies sich die Analyse des russischen Textes mit Hilfe von vorgefertigten Bibliotheken als recht einfach.  Natürlich ist die gesprochene Sprache mit einigen Vorbehalten ein flexibles System mit vielen Ausnahmen und dem Vorhandensein eines Kontextgefühls je nach Kontext, und es ist wahrscheinlich unmöglich, hier überhaupt 100% ige Sicherheit zu erhalten.  Für die jeweilige Aufgabe reicht jedoch der obige Code aus. <br><br>  Die Arbeit mit kyrillischen Texten in Python selbst ist übrigens alles andere als perfekt - kleinere Probleme mit der Ausgabe von Zeichen auf der Konsole, fehlerhafte Ausgabe von Arrays per Druck, die Notwendigkeit, u "" in Zeilen für Python 2.7 anzuhängen usw. Es ist sogar seltsam, dass im 21. Jahrhundert, wenn Es scheint, dass alle Atavismen wie KOI8-R oder CP-1252 ausgestorben sind. Die Probleme bei der Zeichenfolgencodierung bleiben weiterhin relevant. <br><br>  Schließlich ist es interessant festzustellen, dass das Hinzufügen russischer Wörter zur Textwolke den Informationsgehalt des Bildes im Vergleich zur <a href="">englischen Version</a> praktisch nicht erhöht hat - fast alle IT-Begriffe sprechen Englisch, sodass sich die Liste der russischen Wörter in den letzten 10 Jahren wesentlich weniger geändert hat.  Um die Änderungen in der russischen Sprache zu sehen, müssen Sie wahrscheinlich 50 bis 100 Jahre warten - nach der angegebenen Zeit wird es eine Gelegenheit geben, den Artikel erneut zu aktualisieren;) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de442626/">https://habr.com/ru/post/de442626/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de442616/index.html">Wir beschleunigen die Ereignisverarbeitung auf 1,6 Millionen pro Sekunde</a></li>
<li><a href="../de442618/index.html">Nicht für Selfies: Digitaler Enzymimmunosorbens-Assay mit einem neuen Chip, der in ein Smartphone eingebettet ist</a></li>
<li><a href="../de442620/index.html">Maschinelles Lernen in der IT-Überwachung</a></li>
<li><a href="../de442622/index.html">Wie man Coroutinen in Unity etwas bequemer macht</a></li>
<li><a href="../de442624/index.html">Das Buch „Perfekter Algorithmus. Die Grundlagen</a></li>
<li><a href="../de442630/index.html">Haltbarkeit der LED-Lampe und reduzierte Lichtleistung</a></li>
<li><a href="../de442632/index.html">Geothermie: Wie die Wärme der Erde in eine effiziente Energiequelle umgewandelt wurde</a></li>
<li><a href="../de442636/index.html">Bringen Sie dem Management schlechte Nachrichten?</a></li>
<li><a href="../de442638/index.html">Kubernetes Anwendungsskalierung basierend auf Metriken von Prometheus</a></li>
<li><a href="../de442640/index.html">Perfekter Fehler: Verwenden von Typverwirrung in Flash. Teil 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
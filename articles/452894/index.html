<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üè© üó≥Ô∏è üî§ Face Anti-Spoofing o tecnol√≥gicamente reconoce a un tramposo de mil por cara ‚öìÔ∏è üë©üèø‚Äçü§ù‚Äçüë®üèΩ ‚ùî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La identificaci√≥n biom√©trica de una persona es una de las ideas m√°s antiguas para reconocer a las personas, que generalmente intentaron implementar t√©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Face Anti-Spoofing o tecnol√≥gicamente reconoce a un tramposo de mil por cara</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/452894/"><p>  La identificaci√≥n biom√©trica de una persona es una de las ideas m√°s antiguas para reconocer a las personas, que generalmente intentaron implementar t√©cnicamente.  Las contrase√±as se pueden robar, espiar, olvidar, las claves se pueden falsificar.  Pero las caracter√≠sticas √∫nicas de la persona misma son mucho m√°s dif√≠ciles de fingir y perder.  Esto puede ser huellas digitales, voz, dibujo de los vasos de la retina, marcha y m√°s. </p><br><p><img src="https://habrastorage.org/webt/h4/wd/zr/h4wdzrqvlnvfy8da0k3cn5589hg.jpeg"></p><br><p>  ¬°Por supuesto, los sistemas biom√©tricos est√°n tratando de enga√±ar!  De eso es de lo que hablaremos hoy.  C√≥mo los atacantes intentan eludir los sistemas de reconocimiento facial personificando a otra persona y c√≥mo se puede detectar esto. </p><a name="habracut"></a><br><p>  Puede ver una versi√≥n en video de esta historia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> , y aquellos que prefieren leer a ver, los invito a continuar </p><br><p>  Seg√∫n las ideas de los directores de Hollywood y los escritores de ciencia ficci√≥n, es bastante f√°cil enga√±ar a la identificaci√≥n biom√©trica.  Solo es necesario presentar al sistema las "partes requeridas" del usuario real, ya sea individualmente o tom√°ndolo como reh√©n.  O puede "ponerse la m√°scara" de otra persona sobre usted mismo, por ejemplo, usando una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°scara de trasplante f√≠sico</a> o, en general, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">presentando signos gen√©ticos falsos</a> </p><br><p>  En la vida real, los atacantes tambi√©n intentan presentarse como alguien m√°s.  Por ejemplo, robe un banco usando la m√°scara de un hombre negro, como en la imagen a continuaci√≥n. </p><br><p><img src="https://habrastorage.org/webt/pl/vz/67/plvz67jfgazkigzqsdhkko62ego.png"></p><br><p>  El reconocimiento facial parece un √°rea muy prometedora para su uso en el sector m√≥vil.  Si todos han estado acostumbrados a usar huellas digitales y la tecnolog√≠a de la voz se est√° desarrollando de manera gradual y bastante predecible, entonces, al identificarse personalmente, la situaci√≥n se ha desarrollado de manera bastante inusual y digna de una peque√±a digresi√≥n en la historia del problema. </p><br><h2 id="kak-vse-nachinalos-ili-iz-fantastiki-v-realnost">  C√≥mo comenz√≥ todo o de la ficci√≥n a la realidad </h2><br><p>  Los sistemas de reconocimiento de hoy demuestran una precisi√≥n tremenda.  Con la llegada de grandes conjuntos de datos y arquitecturas complejas, fue posible lograr una precisi√≥n de reconocimiento facial de hasta 0.000001 (¬°un error por mill√≥n!) Y ahora son adecuados para transferir a plataformas m√≥viles.  El cuello de botella era su vulnerabilidad. </p><br><p>  Para hacerse pasar por otra persona en nuestra realidad t√©cnica, y no en la pel√≠cula, las m√°scaras se usan con mayor frecuencia.  Tambi√©n intentan enga√±ar al sistema inform√°tico presentando a otra persona en lugar de su cara.  Las m√°scaras pueden ser de una calidad completamente diferente, desde la foto de otra persona impresa frente a la cara impresa en la impresora hasta m√°scaras tridimensionales muy complejas con calentamiento.  Las m√°scaras se pueden presentar por separado en forma de s√°bana o pantalla, o se pueden usar en la cabeza. </p><br><p>  Se prest√≥ mucha atenci√≥n al tema por un intento exitoso de enga√±ar al sistema Face ID en el iPhone X con una m√°scara bastante compleja de polvo de piedra con inserciones especiales alrededor de los ojos que imitan el calor de una cara viva usando radiaci√≥n infrarroja. </p><br><p><img src="https://habrastorage.org/webt/xl/kq/pr/xlkqprysss0ce2arbqm0sw_xbpo.png"></p><br><p>  Se alega que al usar una m√°scara de este tipo fue posible enga√±ar a Face ID en el iPhone X. Puede encontrar un video y algo de texto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> </p><br><p>  La presencia de tales vulnerabilidades es muy peligrosa para los sistemas bancarios o estatales para autenticar a un usuario en persona, donde la penetraci√≥n de un atacante conlleva p√©rdidas significativas. </p><br><h2 id="terminologiya">  Terminolog√≠a </h2><br><p>  El campo de investigaci√≥n del anti-spoofing facial es bastante nuevo y a√∫n no puede presumir incluso de la terminolog√≠a prevaleciente. </p><br><p>  Aceptemos llamar a un intento de enga√±ar al sistema de identificaci√≥n present√°ndolo con un falso par√°metro biom√©trico (en este caso, una persona) <strong>ataque de suplantaci√≥n de identidad</strong> . </p><br><p>  En consecuencia, un conjunto de medidas de protecci√≥n para contrarrestar tal enga√±o se llamar√° <strong>anti-spoofing</strong> .  Se puede implementar en forma de una variedad de tecnolog√≠as y algoritmos integrados en el transportador de un sistema de identificaci√≥n. </p><br><p>  El <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ISO</a> ofrece un conjunto de terminolog√≠a ligeramente expandido, con t√©rminos como <strong>ataque de presentaci√≥n</strong> : intentos de forzar al sistema a identificar incorrectamente al usuario o permitirle evitar la identificaci√≥n al mostrar una imagen, un video grabado, etc.  <strong>Normal (Bona Fide)</strong> : corresponde al algoritmo habitual del sistema, es decir, todo lo que NO es un ataque.  <strong>El instrumento de ataque de presentaci√≥n</strong> significa un medio de ataque, por ejemplo, una parte artificial del cuerpo.  Y, por √∫ltimo, la <strong>detecci√≥n de ataques de presentaci√≥n</strong> : medios automatizados para detectar tales ataques.  Sin embargo, los est√°ndares mismos todav√≠a est√°n en desarrollo, por lo que es imposible hablar sobre conceptos establecidos.  La terminolog√≠a en ruso est√° casi completamente ausente. </p><br><p>  Para determinar la calidad del trabajo, los sistemas a menudo usan la m√©trica <strong>HTER</strong> (Tasa de error medio total - mitad del error total), que se calcula como la suma de los coeficientes de identificaciones err√≥neamente permitidas (FAR - Tasa de aceptaci√≥n falsa) e identificaciones err√≥neamente prohibidas (FRR - Tasa de rechazo falso), dividido a la mitad <br>  HTER = (FAR + FRR) / 2 </p><br><p>  Vale la pena decir que en los sistemas biom√©tricos, FAR suele recibir la mayor atenci√≥n, a fin de hacer todo lo posible para evitar que un atacante ingrese al sistema.  Y est√°n haciendo un buen progreso en esto (¬ørecuerdan la millon√©sima parte del comienzo del art√≠culo?). La otra cara es el inevitable aumento en FRR: el n√∫mero de usuarios comunes clasificados err√≥neamente como intrusos.  Si esto se puede sacrificar por el estado, la defensa y otros sistemas similares, entonces las tecnolog√≠as m√≥viles que funcionan con su enorme escala, una variedad de dispositivos de suscriptor y, en general, orientados a la perspectiva del usuario, son muy sensibles a cualquier factor que pueda hacer que los usuarios rechacen los servicios.  Si desea reducir la cantidad de tel√©fonos que se estrellaron contra la pared despu√©s de la d√©cima negaci√≥n consecutiva de identificaci√≥n, ¬°debe prestar atenci√≥n a FRR! </p><br><h2 id="vidy-atak-obmanyvaem-sistemu">  Tipos de ataques.  Sistema de trampa </h2><br><p><img src="https://habrastorage.org/webt/dt/jx/lp/dtjxlptnxcphiicevd6lbhlzzpa.png"></p><br><p>  Finalmente, descubramos exactamente c√≥mo los atacantes enga√±an al sistema de reconocimiento, y c√≥mo se puede oponer esto. </p><br><p>  Los medios m√°s populares de hacer trampa son las m√°scaras.  No hay nada m√°s obvio que ponerse la m√°scara de otra persona y presentar su rostro a un sistema de identificaci√≥n (a menudo denominado ataque de m√°scara). </p><br><p><img src="https://habrastorage.org/webt/q2/tr/nl/q2trnl3zhhuftbggl3vx-sfqoyw.png"></p><br><p>  Tambi√©n puede imprimir una foto suya o de otra persona en una hoja de papel y llevarla a la c√°mara (llamemos a este tipo de ataque Ataque impreso). </p><br><p><img src="https://habrastorage.org/webt/f9/g7/ds/f9g7dsc81eiffu9srctasf2udcm.png"></p><br><p>  Un poco m√°s complicado es el ataque Replay, cuando el sistema se presenta con la pantalla de otro dispositivo en el que se reproduce un video previamente grabado con otra persona.  La complejidad de la ejecuci√≥n se compensa con la alta eficiencia de dicho ataque, ya que los sistemas de control a menudo usan signos basados ‚Äã‚Äãen el an√°lisis de secuencias de tiempo, por ejemplo, seguimiento de parpadeo, micro movimientos de la cabeza, presencia de expresiones faciales, respiraci√≥n, etc.  Todo esto se puede reproducir f√°cilmente en video. </p><br><p><img src="https://habrastorage.org/webt/de/dd/vj/deddvj6xvnwbv6dpbryxphjwaa8.png"></p><br><p>  Ambos tipos de ataques tienen una serie de caracter√≠sticas que permiten detectarlos y, por lo tanto, distinguen una pantalla de tableta o una hoja de papel de una persona real. </p><br><p>  Resumimos las caracter√≠sticas que nos permiten identificar estos dos tipos de ataques en una tabla: </p><br><div class="scrollable-table"><table><thead><tr><th>  <strong>Ataque impreso</strong> </th><th>  <strong>Repetir ataque</strong> </th></tr></thead><tbody><tr><td>  Disminuci√≥n de la calidad de la textura de la imagen al imprimir </td><td>  Muar√© </td></tr><tr><td>  Artefactos de transmisi√≥n de medios tonos al imprimir en una impresora </td><td>  Reflexiones (destacados) </td></tr><tr><td>  Artefactos de impresi√≥n mec√°nica (l√≠neas horizontales) </td><td>  Imagen plana (falta de profundidad) </td></tr><tr><td>  Falta de movimientos locales (por ejemplo, parpadeo) </td><td>  Los bordes de la imagen pueden ser visibles. </td></tr><tr><td>  Los bordes de la imagen pueden ser visibles. </td><td></td></tr></tbody></table></div><br><h2 id="algoritmy-obnaruzheniya-atak-staraya-dobraya-klassika">  Algoritmos de detecci√≥n de ataques.  Buen viejo cl√°sico </h2><br><p><img src="https://habrastorage.org/webt/1r/n8/-e/1rn8-elrfhm1q0ud9q4jbaukidq.png"></p><br><p>  Uno de los enfoques m√°s antiguos (2007, 2008) se basa en la detecci√≥n de parpadeos humanos mediante el an√°lisis de la imagen con una m√°scara.  El punto es construir alg√∫n tipo de clasificador binario que le permita seleccionar im√°genes con los ojos abiertos y cerrados en una secuencia de cuadros.  Esto puede ser un an√°lisis de la transmisi√≥n de video utilizando la identificaci√≥n de partes de la cara (detecci√≥n de puntos de referencia) o el uso de alguna red neuronal simple.  Y hoy este m√©todo se usa con mayor frecuencia;  Se le pide al usuario que realice una secuencia de acciones: girar la cabeza, gui√±ar un ojo, sonre√≠r y m√°s.  Si la secuencia es aleatoria, no es f√°cil para un atacante prepararse con anticipaci√≥n.  Desafortunadamente, para un usuario honesto, esta b√∫squeda tampoco siempre es superable, y el compromiso cae bruscamente. </p><br><p><img src="https://habrastorage.org/webt/4s/fb/vv/4sfbvvforopuonls_ochr8dpzjg.png"></p><br><p>  Tambi√©n puede usar las caracter√≠sticas de deterioro de la calidad de la imagen al imprimir o reproducir en la pantalla.  Lo m√°s probable es que incluso algunos patrones locales, incluso elusivos a la vista, se detecten en la imagen.  Esto se puede hacer, por ejemplo, contando patrones binarios locales (LBP, patr√≥n binario local) para diferentes √°reas de la cara despu√©s de seleccionarlo desde el marco ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PDF</a> ).  El sistema descrito puede considerarse el fundador de toda la direcci√≥n de los algoritmos faciales anti-spoofing basados ‚Äã‚Äãen el an√°lisis de im√°genes.  En pocas palabras, al calcular el LBP, cada p√≠xel de la imagen, ocho de sus vecinos se toman secuencialmente y se compara su intensidad.  Si la intensidad es mayor que en el p√≠xel central, se asigna uno, si es menor, cero.  Por lo tanto, para cada p√≠xel se obtiene una secuencia de 8 bits.  En base a las secuencias obtenidas, se construye un histograma por p√≠xel, que se alimenta a la entrada del clasificador SVM. </p><br><p><img src="https://habrastorage.org/webt/qu/x_/vv/qux_vvmfk7ikww7ojknhq_mpbhu.png"></p><br><p>  Patrones binarios locales, histograma y SVM.  Puedes unirte a los cl√°sicos atemporales <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> </p><br><p>  El indicador de eficiencia HTER es "tanto como" 15%, y significa que una parte significativa de los atacantes supera la protecci√≥n sin mucho esfuerzo, aunque debe reconocerse que se elimina mucho.  El algoritmo se prob√≥ en el conjunto de datos IDIAP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Replay-Attack</a> , que se compone de 1200 videos cortos de 50 encuestados y tres tipos de ataques: ataque impreso, ataque m√≥vil, ataque de alta definici√≥n. </p><br><p>  Se han continuado las ideas para analizar la textura de la imagen.  En 2015, Bukinafit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desarroll√≥ un</a> algoritmo para dividir alternativamente la imagen en canales, adem√°s del RGB tradicional, para cuyos resultados se calcularon nuevamente los patrones binarios locales, que, como en el m√©todo anterior, se introdujeron en la entrada del clasificador SVN.  La precisi√≥n HTER, calculada en los conjuntos de datos CASIA y Replay-Attack, fue impresionante en ese momento 3%. </p><br><p><img src="https://habrastorage.org/webt/7j/vy/i7/7jvyi7inhsl5g2ulp05v4luido8.png"></p><br><p>  Al mismo tiempo, apareci√≥ trabajo en la detecci√≥n de muar√©.  Patel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">public√≥</a> un art√≠culo donde sugiri√≥ buscar artefactos de im√°genes en forma de un patr√≥n peri√≥dico causado por la superposici√≥n de dos escaneos.  El enfoque result√≥ ser viable, mostrando HTER alrededor del 6% en los conjuntos de datos IDIAP, CASIA y RAFS.  Tambi√©n fue el primer intento de comparar el rendimiento de un algoritmo en diferentes conjuntos de datos. </p><br><p><img src="https://habrastorage.org/webt/98/m2/ls/98m2ls-svv7gxfaagripfrhzymo.png"></p><br><p>  Patr√≥n peri√≥dico en la imagen causado por barridos superpuestos </p><br><p>  Para detectar intentos de presentar fotos, la soluci√≥n l√≥gica era tratar de analizar no una imagen, sino su secuencia tomada de la transmisi√≥n de video.  Por ejemplo, Anjos y sus colegas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sugirieron</a> aislar caracter√≠sticas de la corriente √≥ptica en pares adyacentes de cuadros, alimentar el clasificador binario a la entrada y promediar los resultados.  El enfoque result√≥ ser bastante efectivo, demostrando un HTER de 1.52% en su propio conjunto de datos. </p><br><p><img src="https://habrastorage.org/webt/ih/9e/vo/ih9evob9a5hmtjekxhx1iwsgxm8.png"></p><br><p>  Un m√©todo interesante para rastrear movimientos, que es algo distante de los enfoques convencionales.  Dado que en 2013 el principio "aplicar una imagen en bruto a la entrada de la red convolucional y ajustar las capas de la cuadr√≠cula para obtener el resultado" no era habitual en los proyectos modernos de aprendizaje profundo, Bharadzha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aplic√≥</a> consistentemente transformaciones preliminares m√°s complejas.  En particular, utiliz√≥ el algoritmo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aumento de video Eulerian</a> conocido por el trabajo de los cient√≠ficos del MIT, que se utiliz√≥ con √©xito para analizar los cambios de color en la piel seg√∫n el pulso.  Reemplac√© LBP con HOOF (histogramas de direcciones de flujo √≥ptico), habiendo notado correctamente que dado que queremos rastrear movimientos, necesitamos los signos apropiados, y no solo el an√°lisis de textura.  Todos los mismos SVM, tradicionales en ese momento, se utilizaron como clasificador.  El algoritmo mostr√≥ resultados extremadamente impresionantes en los conjuntos de datos Print Attack (0%) y Replay Attack (1.25%). </p><br><p><img src="https://habrastorage.org/webt/-i/1w/w2/-i1ww2rsu0kqmxglhh-on8lnr5g.png"></p><br><h2 id="davayte-uzhe-uchit-setki">  ¬°Aprendamos ya la grilla! </h2><br><p><img src="https://habrastorage.org/webt/7p/t-/yk/7pt-ykbzzuyb7bzpnd9qpjodfog.png"></p><br><p>  Desde alg√∫n punto se hizo evidente que la transici√≥n al aprendizaje profundo hab√≠a madurado.  La notoria "revoluci√≥n del aprendizaje profundo" se enfrent√≥ a la lucha contra la suplantaci√≥n de identidad. </p><br><p>  El "primer trago" puede considerarse el m√©todo de an√°lisis de mapas de profundidad en secciones individuales ("parches") de la imagen.  Obviamente, un mapa de profundidad es una muy buena se√±al para determinar el plano en el que se encuentra la imagen.  Aunque solo sea porque la imagen en la hoja de papel no tiene "profundidad" por definici√≥n.  En <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el</a> trabajo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de Ataum en</a> 2017, se extrajeron muchas secciones peque√±as separadas de la imagen; se calcularon mapas de profundidad para ellas, que luego se fusionaron con el mapa de profundidad de la imagen principal.  Se se√±al√≥ que diez parches de im√°genes de caras aleatorias son suficientes para identificar de manera confiable el ataque impreso.  Adem√°s, los autores reunieron los resultados de dos redes neuronales convolucionales, la primera de las cuales calcul√≥ mapas de profundidad para parches, y la segunda para la imagen en su conjunto.  Al entrenar en conjuntos de datos, la clase de Ataque Impreso se asoci√≥ con un mapa de profundidad de cero, y una serie de secciones seleccionadas al azar se asoci√≥ con un modelo de cara tridimensional.  En general, el mapa de profundidad en s√≠ mismo no era tan importante, solo se utiliz√≥ una determinada funci√≥n de indicador, que caracteriza la "profundidad de la secci√≥n".  El algoritmo mostr√≥ un valor HTER de 3.78%.  Se utilizaron tres conjuntos de datos p√∫blicos para la capacitaci√≥n: CASIA-MFSD, MSU-USSA y Replay-Attack. </p><br><p><img src="https://habrastorage.org/webt/a7/bl/df/a7bldfybkgzeeptdtomphvq1kwk.png"></p><br><p>  Desafortunadamente, la disponibilidad de una gran cantidad de marcos excelentes para el aprendizaje profundo ha llevado a la aparici√≥n de una gran cantidad de desarrolladores que est√°n tratando de resolver el problema de la suplantaci√≥n de la cara de una manera conocida de ensamblar redes neuronales.  Por lo general, parece una pila de mapas de caracter√≠sticas en las salidas de varias redes pre-entrenadas en un conjunto de datos generalizado que se alimenta a un clasificador binario. </p><br><p><img src="https://habrastorage.org/webt/ek/8b/rc/ek8brc52akg2y3zfy6ejmbr-taq.png"></p><br><p>  En general, vale la pena concluir que hasta la fecha, se han publicado bastantes trabajos, que generalmente muestran buenos resultados, y que une solo un peque√±o "pero".  ¬°Todos estos resultados se demuestran en un conjunto de datos espec√≠fico!  La situaci√≥n se ve agravada por la disponibilidad limitada de conjuntos de datos y, por ejemplo, en el famoso Replay-Attack, no es sorprendente HTER 0%.  Todo esto lleva a la aparici√≥n de arquitecturas muy complejas, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estas</a> , que utilizan varias funciones ingeniosas, algoritmos auxiliares ensamblados en la pila, con varios clasificadores, cuyos resultados son promediados, y as√≠ sucesivamente ... ¬°Los autores obtienen HTER = 0.04% en la salida! </p><br><p><img src="https://habrastorage.org/webt/aw/_k/s_/aw_ks_6-xp40fyjz97ue9mwzp8q.png"></p><br><p>  Esto sugiere que el problema de la suplantaci√≥n de la cara se ha resuelto dentro de un conjunto de datos espec√≠fico.  Traigamos a la mesa varios m√©todos modernos basados ‚Äã‚Äãen redes neuronales.  Es f√°cil ver que los "resultados de referencia" se lograron mediante m√©todos muy diversos que solo surgieron en las mentes inquisitivas de los desarrolladores. </p><br><p><img src="https://habrastorage.org/webt/bb/7v/73/bb7v73awyzwhxeyyvtejgm3skh4.png"></p><br><p>  Resultados comparativos de varios algoritmos.  La tabla est√° tomada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desde aqu√≠</a> . </p><br><p>  Desafortunadamente, el mismo factor "peque√±o" viola la buena imagen de la lucha por d√©cimas de porcentaje.  Si intenta entrenar la red neuronal en un conjunto de datos y aplicarlo en otro, los resultados ser√°n ... no tan optimistas.  Peor a√∫n, los intentos de aplicar clasificadores en la vida real no dejan ninguna esperanza. <br>  Como ejemplo, tomamos los datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de</a> 2015, donde se utiliz√≥ una m√©trica de su calidad para determinar la autenticidad de la imagen presentada.  Echa un vistazo por ti mismo: </p><br><p><img src="https://habrastorage.org/webt/jw/b5/-n/jwb5-naohhjhek2tkmakbssjyik.png"></p><br><p>  En otras palabras, un algoritmo entrenado en datos de Idiap, pero aplicado en MSU, dar√° una tasa de detecci√≥n verdaderamente positiva del 90.5%, y si hace lo contrario (entrene en MSU y pruebe en Idiap), entonces solo 47.2 puede determinarse correctamente % (!) Para otras combinaciones, la situaci√≥n empeora a√∫n m√°s y, por ejemplo, si entrena el algoritmo en MSU y lo comprueba en CASIA, ¬°entonces el TPR ser√° del 10.8%!  Esto significa que una gran cantidad de usuarios honestos fueron asignados por error a los atacantes, lo que no puede dejar de ser deprimente.  Incluso la capacitaci√≥n en bases de datos cruzadas no podr√≠a revertir la situaci√≥n, que parece ser una salida perfectamente razonable. </p><br><p>  A ver m√°s.  Los resultados presentados en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo de</a> Patel 2016 muestran que incluso con tuber√≠as de procesamiento bastante complejas y la selecci√≥n de caracter√≠sticas confiables como el parpadeo y la textura, los resultados en conjuntos de datos desconocidos no pueden considerarse satisfactorios.  Entonces, en alg√∫n momento se hizo bastante obvio que los m√©todos propuestos desesperadamente no eran suficientes para resumir los resultados. </p><br><p><img src="https://habrastorage.org/webt/vf/lz/ol/vflzoljiplnkj_vgm-zth9a0sdc.png"></p><br><h2 id="a-esli-ustroit-sorevnovanie">  Y si organizas una competencia ... </h2><br><p>  Por supuesto, en el campo de la lucha contra la falsificaci√≥n de rostros no estuvo exento de competencia.  En 2017, se realiz√≥ una competencia en la Universidad de Oulu en Finlandia en su propio conjunto de datos con protocolos bastante interesantes, orientados espec√≠ficamente para su uso en el campo de las aplicaciones m√≥viles. </p><br><p>  - Protocolo 1: hay una diferencia en la iluminaci√≥n y el fondo.  Los conjuntos de datos se registran en varios lugares y difieren en el fondo y la iluminaci√≥n. </p><br><p>  -Protocolo 2: se utilizaron varios modelos de impresoras y pantallas para los ataques.  Entonces, en el conjunto de datos de verificaci√≥n, se utiliza una t√©cnica que no se encuentra en el conjunto de entrenamiento </p><br><p>  Protocolo 3: intercambiabilidad de sensores.  Los videos y ataques de usuarios reales se graban en cinco tel√©fonos inteligentes diferentes y se usan en un conjunto de datos de entrenamiento.         ,      . </p><br><p> - 4:    . </p><br><p>    .     ,      ,            ,      -      .      ,   ,  10%.        : </p><br><ol><li><p> GRADIENT </p><br><ul><li>      (   HSV  YCbCr),   . </li><li>                . </li><li>           HSV  YCbCr,     .    ROI (region-of-interest)            160√ó160 .. </li><li>  ROI   3√ó3  5√ó5  ,     LBP  ,        6018. </li><li>      (Recursive Feature Elimination)    6018  1000. </li><li>         SVM   .| </li></ul><br></li><li><p> SZCVI </p><br><ul><li>      ,    </li><li>    216√ó384 </li><li>  VGG-  </li><li>       </li></ul><br></li><li><p> Recod </p><br><ul><li> SqueezeNet   Imagenet </li><li> Transfer learning    : CASIA  UVAD </li><li>       224√ó224 pixels.      , ,   ,     CNN. </li><li>        . </li><li>            </li></ul><br></li><li><p> CPqD </p><br><ul><li>  Inception-v3,   ImageNet </li><li> C   </li><li>         ,  ,      224√ó224 RGB | </li></ul><br></li></ol><br><p>  ,       .    LBP,  ,    ,     .. GRADIANT        ,     ,      ,   .     . </p><br><p>      .   ,        . -,        ( 15   NUAA  1140  MSU-USSA)  ,   ,  ,   ,     .       ,  ,  ,    ,         . -,                 . ,   CASIA        ,     . ,     ,    ,    ,      ‚Ä¶  ,       ,   ,           . </p><br><p><img src="https://habrastorage.org/webt/ur/yf/t8/uryft8082ylvw-1kbyvcxucjcem.png"></p><br><p>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>        30 .   ,        ,            .  ,          . </p><br><p> ,  ,   ¬´ ¬ª.          . ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>     (rPPG ‚Äì remote photoplethysmography),       .    ,           , -,   ‚Äì     .            .  ,        , ,  . ,        ,     .            ,     ,                 ,        . </p><br><p><img src="https://habrastorage.org/webt/db/le/44/dble44fc8acyqdhzead3ndbkg3a.png"></p><br><p><img src="https://habrastorage.org/webt/sy/u7/vu/syu7vucfvb5inhajqoilb6rqxu8.png"></p><br><p> El trabajo mostr√≥ un valor HTER de aproximadamente el 10%, confirmando la aplicabilidad principal del m√©todo.  Hay varios trabajos que confirman las perspectivas de este enfoque. <br>  (CVPR 2018) JH-Ortega et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">An√°lisis de tiempo de Anti-Spoofing facial basado en pulsos en visible y NIR</a> <br>  (2016) X. Li.  et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Anti-spoofing facial generalizado mediante la detecci√≥n de pulso de videos faciales</a> <br>  (2016) J. Chen y col.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Realsense = frecuencia card√≠aca real: estimaci√≥n de la frecuencia card√≠aca invariante de iluminaci√≥n a partir de videos</a> <br>  (2014) HE Tasli et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Medici√≥n remota de signos vitales basada en PPG utilizando regiones faciales adaptativas</a> </p><br><p>  En 2018, Liu y sus colegas de la Universidad de Michigan propusieron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">abandonar la clasificaci√≥n binaria</a> a favor del enfoque que llamaron "supervisi√≥n binaria", es decir, usar una estimaci√≥n m√°s compleja basada en un mapa de profundidad y una fotopletismograf√≠a remota.  Para cada una de estas im√°genes faciales, se reconstruy√≥ un modelo tridimensional utilizando una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">red neuronal</a> y se le dio un mapa de profundidad.  A las im√°genes falsas se les asign√≥ un mapa de profundidad que consta de ceros, ¬°al final es solo un trozo de papel o la pantalla de un dispositivo!  Estas caracter√≠sticas fueron tomadas como "verdad", las redes neuronales fueron entrenadas en su propio conjunto de datos SiW.  Luego, se superpuso una m√°scara facial tridimensional en la imagen de entrada, se calcul√≥ un mapa de profundidad y un pulso, y todo esto se uni√≥ en un transportador bastante complicado.  Como resultado, el m√©todo mostr√≥ una precisi√≥n de aproximadamente el 10 por ciento en el conjunto de datos competitivos de OULU.  Curiosamente, el ganador de la competencia organizada por la Universidad de Oulu construy√≥ el algoritmo sobre patrones de clasificaci√≥n binarios, seguimiento intermitente y otros signos "dise√±ados a mano", y su soluci√≥n tambi√©n tuvo una precisi√≥n de aproximadamente el 10%.  ¬°La ganancia fue solo del medio por ciento!  La nueva tecnolog√≠a combinada est√° respaldada por el hecho de que el algoritmo fue entrenado en su propio conjunto de datos y probado en OULU, mejorando el resultado del ganador.  Esto indica una cierta portabilidad de los resultados del conjunto de datos al conjunto de datos, y lo que no es broma, es posible para la vida real.  Sin embargo, al intentar realizar capacitaci√≥n en otros conjuntos de datos: CASIA y ReplayAttack, el resultado nuevamente fue de alrededor del 28%.  Por supuesto, esto excede el rendimiento de otros algoritmos cuando se entrena en varios conjuntos de datos, pero con tales valores de precisi√≥n, ¬°no se puede hablar de ning√∫n uso industrial! </p><br><p><img src="https://habrastorage.org/webt/qd/bu/fn/qdbufnt8yc9pghj4egkxqaku_3g.png"></p><br><p>  Wang y sus colegas propusieron un enfoque diferente en un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajo</a> reciente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de</a> 2019.  Se observ√≥ que en el an√°lisis de micromovimiento de la cara, las rotaciones y los desplazamientos de la cabeza son notables, lo que lleva a un cambio caracter√≠stico en los √°ngulos y las distancias relativas entre los signos en la cara.  Entonces, cuando la cara se desplaza horizontalmente, el √°ngulo entre la nariz y la oreja aumenta.  Pero, si cambia una hoja de papel con una imagen de la misma manera, ¬°el √°ngulo disminuir√°!  Por ejemplo, vale la pena citar un dibujo de la obra. </p><br><p><img src="https://habrastorage.org/webt/x9/lq/kz/x9lqkzuzmgz7gz5ejx1rsiom7wq.png"></p><br><p>  Sobre este principio, los autores construyeron una unidad de aprendizaje completa para transferir datos entre capas de una red neuronal.  Tom√≥ en cuenta las "compensaciones incorrectas" para cada cuadro en una secuencia de dos cuadros, y esto permiti√≥ que los resultados se usaran en el siguiente bloque de an√°lisis de dependencia a largo plazo basado en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Unidad Recurrente Cerrada</a> GRU.  Luego, todos los signos se concatenaron, se calcul√≥ la funci√≥n de p√©rdida y se realiz√≥ la clasificaci√≥n final.  Esto nos permiti√≥ mejorar ligeramente el resultado en el conjunto de datos OULU, pero el problema de la dependencia de los datos de entrenamiento persisti√≥, ya que para el par CASIA-MFSD y Replay-Attack, los indicadores fueron 17.5 y 24 por ciento, respectivamente. </p><br><p>  Hacia el final, vale la pena se√±alar el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajo de los</a> expertos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de</a> Tencent, quienes propusieron cambiar la forma en que se recibe la imagen de video fuente.  En lugar de observar pasivamente la escena, sugirieron iluminar din√°micamente la cara y leer los reflejos.  El principio de irradiaci√≥n activa de un objeto se ha aplicado durante mucho tiempo en sistemas de localizaci√≥n de varios tipos, por lo tanto, su uso para estudiar la cara parece muy l√≥gico.  Obviamente, para una identificaci√≥n confiable en la imagen en s√≠ no hay suficientes signos, y puede ser de gran ayuda iluminar la pantalla del tel√©fono o tableta con una secuencia de s√≠mbolos de luz (CAPTCHA de luz seg√∫n la terminolog√≠a de los autores).  A continuaci√≥n, se determina la diferencia en la dispersi√≥n y la reflexi√≥n sobre un par de cuadros, y los resultados se env√≠an a una red neuronal multitarea para su posterior procesamiento en el mapa de profundidad y el c√°lculo de diversas funciones de p√©rdida.  Al final, se realiza una regresi√≥n de los marcos de luz normalizados.  Los autores no analizaron la capacidad de generalizaci√≥n de su algoritmo en otros conjuntos de datos y lo entrenaron en su propio conjunto de datos privado.  El resultado es aproximadamente el 1% y se informa que el modelo ya se ha implementado para uso real. </p><br><p><img src="https://habrastorage.org/webt/c-/ts/w8/c-tsw8vywrvsv3l58ow-axifkay.png"></p><br><p>  Hasta 2017, el √°rea de anti-spoofing facial no estaba muy activa.  Pero 2019 ya ha presentado una serie completa de trabajos, que se asocia con la promoci√≥n agresiva de las tecnolog√≠as m√≥viles de identificaci√≥n facial, principalmente por parte de Apple.  Adem√°s, los bancos est√°n interesados ‚Äã‚Äãen las tecnolog√≠as de reconocimiento facial.  Muchas personas nuevas han venido a la industria, lo que nos permite esperar un progreso r√°pido.  Pero hasta ahora, a pesar de los hermosos t√≠tulos de las publicaciones, la capacidad de generalizaci√≥n de los algoritmos sigue siendo muy d√©bil y no nos permite hablar sobre la idoneidad para el uso pr√°ctico. </p><br><h2 id="zaklyuchenie-a-naposledok-ya-skazhu-chto">  Conclusi√≥n  Y finalmente, dir√© que ... </h2><br><ul><li>  Los patrones binarios locales, el seguimiento del parpadeo, la respiraci√≥n, los movimientos y otros signos dise√±ados manualmente no han perdido su importancia en absoluto.  Esto se debe principalmente al hecho de que el entrenamiento profundo en el campo de la suplantaci√≥n de la cara sigue siendo muy ingenuo. </li><li>  Est√° claro que en la "misma" soluci√≥n, se combinar√°n varios m√©todos.  An√°lisis de reflexi√≥n, dispersi√≥n, mapas de profundidad deben usarse juntos.  Lo m√°s probable es que la adici√≥n de un canal de datos adicional ayude, por ejemplo, la grabaci√≥n de voz y alg√∫n tipo de enfoque del sistema que le permitir√° recopilar varias tecnolog√≠as en un solo sistema </li><li>  Casi todas las tecnolog√≠as utilizadas para el reconocimiento facial encuentran aplicaci√≥n en el anti-spoofing facial (¬°cap!) Todo lo que se desarroll√≥ para el reconocimiento facial, de una forma u otra, ha encontrado aplicaci√≥n para el an√°lisis de ataque </li><li>  Los conjuntos de datos existentes han alcanzado la saturaci√≥n.  De diez conjuntos de datos b√°sicos en cinco, se logr√≥ un error cero.  Esto ya habla, por ejemplo, de la eficiencia de los m√©todos basados ‚Äã‚Äãen mapas de profundidad, pero no permite mejorar la capacidad de generalizaci√≥n.  Necesitamos nuevos datos y nuevos experimentos sobre ellos. </li><li>  Existe un claro desequilibrio entre el grado de desarrollo del reconocimiento facial y el anti-spoofing facial.  Las tecnolog√≠as de reconocimiento est√°n significativamente por delante de los sistemas de protecci√≥n.  Adem√°s, es la falta de sistemas de protecci√≥n confiables lo que inhibe el uso pr√°ctico de los sistemas de reconocimiento facial.  Sucedi√≥ que la atenci√≥n principal se prest√≥ espec√≠ficamente al reconocimiento facial, y los sistemas de detecci√≥n de ataques se mantuvieron algo distantes </li><li>  Existe una gran necesidad de un enfoque sistem√°tico en el campo de la suplantaci√≥n de la cara.  La competencia anterior de la Universidad de Oulu mostr√≥ que cuando se usa un conjunto de datos no representativo, es muy posible derrotarlo con un simple ajuste competente de las soluciones establecidas, sin desarrollar nuevas.  Quiz√°s una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nueva competencia</a> puede cambiar el rumbo </li><li>  Con un creciente inter√©s en el tema y la introducci√≥n de tecnolog√≠as de reconocimiento facial por parte de grandes jugadores, aparecieron "ventanas de oportunidad" para los nuevos equipos ambiciosos, ya que existe una gran necesidad de una nueva soluci√≥n a nivel arquitect√≥nico. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/452894/">https://habr.com/ru/post/452894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../452884/index.html">An√°lisis del rendimiento de la m√°quina virtual en VMware vSphere. Parte 1: CPU</a></li>
<li><a href="../452886/index.html">Proyectos de Wiki y nombre de Noosphere en HACKNOWLEGE</a></li>
<li><a href="../452888/index.html">Cerca de M√∫nich comenz√≥ a probar el tiltrotor de cinco asientos de tama√±o completo Lilium Jet</a></li>
<li><a href="../452890/index.html">23 de mayo, 18:30 - transmisi√≥n en vivo de QIWI Kitchen</a></li>
<li><a href="../452892/index.html">¬øC√≥mo puede un no programador mudarse a los Estados Unidos? Instrucciones paso a paso.</a></li>
<li><a href="../452900/index.html">√çndices en PostgreSQL - 9 (BRIN)</a></li>
<li><a href="../452902/index.html">Terminando 4 a√±os de entrenamiento como programador, entiendo que estoy lejos de ser un programador</a></li>
<li><a href="../452904/index.html">C√≥mo se comunican las m√°quinas: protocolo MQTT</a></li>
<li><a href="../452906/index.html">Motores JavaScript: ¬øc√≥mo funcionan? Desde la pila de llamadas hasta las promesas, (casi) todo lo que necesita saber</a></li>
<li><a href="../452908/index.html">Selenium WebDriver: m√©trica de prueba en tiempo real con Grafana e InfluxDB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
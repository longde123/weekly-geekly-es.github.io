<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§öüèª üë©üèø‚Äç‚öñÔ∏è üßóüèº Trabaje con un cl√∫ster Proxmox: instalaci√≥n, configuraci√≥n de red, ZFS, soluci√≥n de problemas comunes ‚óºÔ∏è üõ≥Ô∏è üë©üèæ‚Äçüîß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En los √∫ltimos a√±os, he estado trabajando muy de cerca con los cl√∫steres de Proxmox: muchos clientes requieren su propia infraestructura para poder de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Trabaje con un cl√∫ster Proxmox: instalaci√≥n, configuraci√≥n de red, ZFS, soluci√≥n de problemas comunes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457894/"> En los √∫ltimos a√±os, he estado trabajando muy de cerca con los cl√∫steres de Proxmox: muchos clientes requieren su propia infraestructura para poder desarrollar su proyecto.  Es por eso que puedo hablar sobre los errores y problemas m√°s comunes que tambi√©n puede encontrar.  Adem√°s de esto, por supuesto configuraremos un grupo de tres nodos desde cero. <br><img src="https://habrastorage.org/webt/jz/j-/lq/jzj-lqgwozo7rze1o8ij7bvzday.png"><br><a name="habracut"></a><br>  Un cl√∫ster Proxmox puede constar de dos o m√°s servidores.  El n√∫mero m√°ximo de nodos en un cl√∫ster es de 32 piezas.  Nuestro propio cl√∫ster consistir√° en tres nodos en una multidifusi√≥n (en el art√≠culo tambi√©n describir√© c√≥mo elevar un cl√∫ster a la unicidad; esto es importante si basa su infraestructura de cl√∫ster en Hetzner u OVH, por ejemplo).  En resumen, la multidifusi√≥n permite la transferencia de datos a varios nodos simult√°neamente.  Con una multidifusi√≥n, no podemos pensar en el n√∫mero de nodos en el cl√∫ster (centr√°ndonos en las limitaciones anteriores). <br><br>  El cl√∫ster en s√≠ est√° construido en una red interna (es importante que las direcciones IP est√©n en la misma subred), el mismo Hetzner y OVH tienen la capacidad de agrupar nodos en diferentes centros de datos utilizando la tecnolog√≠a Virtual Switch (Hetzner) y vRack (OVH) - sobre Virtual Switch Tambi√©n hablaremos en el art√≠culo.  Si su proveedor de alojamiento no tiene tecnolog√≠as similares en funcionamiento, puede usar OVS (Open Virtual Switch), que es compatible de forma nativa con Proxmox, o usar una VPN.  Sin embargo, en este caso, recomiendo usar Unicast con un peque√±o n√∫mero de nodos; a menudo surgen situaciones en las que el cl√∫ster simplemente "se desmorona" en funci√≥n de dicha infraestructura de red y tiene que restaurarse.  Por lo tanto, trato de usar OVH y Hetzner en mi trabajo: he visto menos incidentes de este tipo, pero antes que nada, estudie el proveedor de alojamiento que se alojar√°: ¬øtiene tecnolog√≠a alternativa, qu√© soluciones ofrece, admite multidifusi√≥n, etc.? . <br><br><h3>  Instalar Proxmox </h3><br>  Proxmox se puede instalar de dos maneras: instalador ISO e instalaci√≥n a trav√©s de shell.  Elegimos el segundo m√©todo, as√≠ que instale Debian en el servidor. <br><br>  Procedemos directamente a la instalaci√≥n de Proxmox en cada servidor.  La instalaci√≥n es extremadamente simple y se describe en la documentaci√≥n oficial aqu√≠. <br><br>  Agregue el repositorio de Proxmox y la clave de este repositorio: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://download.proxmox.com/debian/pve stretch pve-no-subscription"</span></span> &gt; /etc/apt/sources.list.d/pve-install-repo.list wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg chmod +r /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg <span class="hljs-comment"><span class="hljs-comment"># optional, if you have a changed default umask</span></span></code> </pre> <br>  Actualizaci√≥n de repositorios y el sistema en s√≠: <br><br><pre> <code class="bash hljs">apt update &amp;&amp; apt dist-upgrade</code> </pre> <br>  Despu√©s de una actualizaci√≥n exitosa, instale los paquetes Proxmox necesarios: <br><br><pre> <code class="bash hljs">apt install proxmox-ve postfix open-iscsi</code> </pre> <br>  <b>Nota</b> : Postfix y grub se configurar√°n durante la instalaci√≥n; uno de ellos puede fallar.  Quiz√°s esto se deba al hecho de que el nombre de host no se resuelve por nombre.  Edite las entradas de los hosts y realice apt-get update <br><br>  A partir de ahora, podemos iniciar sesi√≥n en la interfaz web de Proxmox en https: // &lt;external-ip-address&gt;: 8006 (encontrar√° un certificado no confiable durante la conexi√≥n). <br><br><img src="https://habrastorage.org/webt/e_/cg/mv/e_cgmvs9rrh3qwq0su222v2j0iw.png"><br>  <b>Imagen 1.</b> Interfaz web del nodo Proxmox <br><br><h3>  Instale Nginx y Let's Encrypt Certificate </h3><br>  Realmente no me gusta la situaci√≥n con el certificado y la direcci√≥n IP, por lo que sugiero instalar Nginx y configurar el certificado Let's Encrypt.  No describir√© la instalaci√≥n de Nginx, dejar√© solo los archivos importantes para que funcione el certificado Let's Encriptar: <br><br><div class="spoiler">  <b class="spoiler_title">/etc/nginx/snippets/letsencrypt.conf</b> <div class="spoiler_text"><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">location</span></span><span class="hljs-regexp"><span class="hljs-regexp"> ^~</span></span> /.well-known/acme-challenge/ { <span class="hljs-attribute"><span class="hljs-attribute">allow</span></span> all; <span class="hljs-attribute"><span class="hljs-attribute">root</span></span> /var/lib/letsencrypt/; <span class="hljs-attribute"><span class="hljs-attribute">default_type</span></span> <span class="hljs-string"><span class="hljs-string">"text/plain"</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">try_files</span></span> <span class="hljs-variable"><span class="hljs-variable">$uri</span></span> =<span class="hljs-number"><span class="hljs-number">404</span></span>; }</code> </pre><br><br></div></div><br>  Comando para emitir certificado SSL: <br><br><pre> <code class="bash hljs">certbot certonly --agree-tos --email sos@livelinux.info --webroot -w /var/lib/letsencrypt/ -d proxmox1.domain.name</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Configuraci√≥n del sitio en NGINX</b> <div class="spoiler_text"><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">upstream</span></span> proxmox1.domain.name { <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1:8006</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">80</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> snippets/letsencrypt.conf; <span class="hljs-attribute"><span class="hljs-attribute">return</span></span> <span class="hljs-number"><span class="hljs-number">301</span></span> https://<span class="hljs-variable"><span class="hljs-variable">$host</span></span><span class="hljs-variable"><span class="hljs-variable">$request_uri</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">443</span></span> ssl; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">access_log</span></span> /var/log/nginx/proxmox1.domain.name.access.log; <span class="hljs-attribute"><span class="hljs-attribute">error_log</span></span> /var/log/nginx/proxmox1.domain.name.<span class="hljs-literal"><span class="hljs-literal">error</span></span>.log; <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> snippets/letsencrypt.conf; <span class="hljs-attribute"><span class="hljs-attribute">ssl_certificate</span></span> /etc/letsencrypt/live/proxmox1.domain.name/fullchain.pem; <span class="hljs-attribute"><span class="hljs-attribute">ssl_certificate_key</span></span> /etc/letsencrypt/live/proxmox1.domain.name/privkey.pem; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> https://proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">proxy_next_upstream</span></span> <span class="hljs-literal"><span class="hljs-literal">error</span></span> timeout invalid_header http_500 http_502 http_503 http_504; <span class="hljs-attribute"><span class="hljs-attribute">proxy_redirect</span></span> <span class="hljs-literal"><span class="hljs-literal">off</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_buffering</span></span> <span class="hljs-literal"><span class="hljs-literal">off</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> Host <span class="hljs-variable"><span class="hljs-variable">$host</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> X-Real-IP <span class="hljs-variable"><span class="hljs-variable">$remote_addr</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> X-Forwarded-For <span class="hljs-variable"><span class="hljs-variable">$proxy_add_x_forwarded_for</span></span>; }</code> </pre> <br></div></div><br>  Despu√©s de instalar el certificado SSL, no olvide configurarlo para que se renueve autom√°ticamente a trav√©s de cron: <br><br><pre> <code class="bash hljs">0 */12 * * * /usr/bin/certbot -a \! -d /run/systemd/system &amp;&amp; perl -e <span class="hljs-string"><span class="hljs-string">'sleep int(rand(3600))'</span></span> &amp;&amp; certbot -q renew --renew-hook <span class="hljs-string"><span class="hljs-string">"systemctl reload nginx"</span></span></code> </pre> <br>  Genial  Ahora podemos acceder a nuestro dominio a trav√©s de HTTPS. <br><br>  <b>Nota</b> : para deshabilitar la ventana de informaci√≥n de suscripci√≥n, ejecute este comando: <br><br><pre> <code class="bash hljs">sed -i.bak <span class="hljs-string"><span class="hljs-string">"s/data.status !== 'Active'/false/g"</span></span> /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js &amp;&amp; systemctl restart pveproxy.service</code> </pre> <br>  <b>Configuraciones de red</b> <br><br>  Antes de conectarse al cl√∫ster, configure las interfaces de red en el hipervisor.  Vale la pena se√±alar que la configuraci√≥n de los nodos restantes no es diferente, a excepci√≥n de las direcciones IP y los nombres de los servidores, por lo que no duplicar√© su configuraci√≥n. <br><br>  Crearemos un puente de red para la red interna para que nuestras m√°quinas virtuales (en mi versi√≥n habr√° un contenedor LXC por conveniencia), en primer lugar, est√°n conectadas a la red interna del hipervisor y pueden interactuar entre s√≠.  En segundo lugar, un poco m√°s tarde agregaremos un puente para la red externa para que las m√°quinas virtuales tengan su propia direcci√≥n IP externa.  En consecuencia, los contenedores estar√°n en este momento detr√°s de NAT'om con nosotros. <br><br>  Hay dos formas de trabajar con la configuraci√≥n de red de Proxmox: a trav√©s de la interfaz web o mediante el archivo de configuraci√≥n / etc / network / interfaces.  En la primera opci√≥n, deber√° reiniciar el servidor (o simplemente puede cambiar el nombre del archivo interfaces.new a interfaces y reiniciar el servicio de red a trav√©s de systemd).  Si reci√©n est√° comenzando a configurar y a√∫n no hay m√°quinas virtuales o contenedores LXC, es recomendable reiniciar el hipervisor despu√©s de los cambios. <br><br>  Ahora cree un puente de red llamado vmbr1 en la pesta√±a de red en el panel web de Proxmox. <br><br><img src="https://habrastorage.org/webt/i3/6k/wp/i36kwpe0ky3khngufngwifulwcs.png"><br>  <b>Figura 2.</b> Interfaces de red del nodo proxmox1 <br><br><img src="https://habrastorage.org/webt/ro/k6/tg/rok6tgyuqyvte_dswvl-0xgvbxe.png"><br>  <b>Figura 3.</b> Crear un puente de red <br><br><img src="https://habrastorage.org/webt/kx/xu/kg/kxxukgzgym97cjezlvrczgtji8g.png"><br>  <b>Figura 4.</b> Configuraci√≥n de la configuraci√≥n de red vmbr1 <br><br>  La configuraci√≥n es extremadamente simple: necesitamos vmbr1 para que las instancias tengan acceso a Internet. <br><br>  Ahora reinicie nuestro hipervisor y verifique si se ha creado la interfaz: <br><br><img src="https://habrastorage.org/webt/cx/b9/ga/cxb9ga2zhwn0fefphugyihuj6fg.png"><br>  <b>Figura 5.</b> Interfaz de red vmbr1 en ip una salida de comando <br><br>  Nota: Ya tengo la interfaz ens19: esta es la interfaz con la red interna, en funci√≥n de la cual se crear√° un cl√∫ster. <br><br>  Repita estos pasos en los otros dos hipervisores y luego contin√∫e con el siguiente paso: preparar el cl√∫ster. <br><br>  Adem√°s, una etapa importante ahora es habilitar el reenv√≠o de paquetes; sin √©l, las instancias no obtendr√°n acceso a la red externa.  Abra el archivo sysctl.conf y cambie el valor del par√°metro net.ipv4.ip_forward a 1, despu√©s de lo cual ingresaremos el siguiente comando: <br><br><pre> <code class="bash hljs">sysctl -p</code> </pre> <br>  En la salida, deber√≠a ver la directiva net.ipv4.ip_forward (si no la ha cambiado antes) <br><br>  <b>Configurar un cl√∫ster Proxmox</b> <br><br>  Ahora vamos directamente al cl√∫ster.  Cada nodo debe resolverse a s√≠ mismo y a otros nodos en la red interna, para esto es necesario cambiar los valores en los registros de los hosts de la siguiente manera (cada nodo debe tener un registro sobre los dem√°s): <br><br><pre> <code class="bash hljs">172.30.0.15 proxmox1.livelinux.info proxmox1 172.30.0.16 proxmox2.livelinux.info proxmox2 172.30.0.17 proxmox3.livelinux.info proxmox3</code> </pre><br>  Tambi√©n es necesario agregar las claves p√∫blicas de cada nodo a los dem√°s; esto es necesario para crear un cl√∫ster. <br><br>  Cree un cl√∫ster a trav√©s del panel web: <br><br><img src="https://habrastorage.org/webt/vl/rm/rh/vlrmrhkpwn5dle9gcnomfueoega.png"><br>  <b>Figura 6.</b> Crear un cl√∫ster a trav√©s de la interfaz web <br><br>  Despu√©s de crear el cl√∫ster, necesitamos obtener informaci√≥n al respecto.  Vaya a la misma pesta√±a del cl√∫ster y haga clic en el bot√≥n "Unir informaci√≥n": <br><br><img src="https://habrastorage.org/webt/gj/ur/t2/gjurt2tqr_pgtlfsxv7l3hrz398.png"><br>  <b>Imagen 7.</b> Informaci√≥n sobre el cl√∫ster creado <br><br>  Esta informaci√≥n es √∫til para nosotros al unir el segundo y tercer nodos en el cl√∫ster.  Estamos conectados al segundo nodo y en la pesta√±a Cl√∫ster haga clic en el bot√≥n "Unirse al cl√∫ster": <br><br><img src="https://habrastorage.org/webt/fo/8u/zh/fo8uzhx-lzxfyqkapqdqsfuoalq.png"><br>  <b>Figura 8.</b> Conexi√≥n a un cl√∫ster de nodos <br><br>  Analicemos los par√°metros para la conexi√≥n con m√°s detalle: <br><br><ol><li>  <b>Direcci√≥n de igual:</b> direcci√≥n IP del primer servidor (al que nos estamos conectando) </li><li>  <b>Contrase√±a:</b> contrase√±a del primer servidor </li><li>  <b>Huella digital:</b> obtenemos este valor de la informaci√≥n del cl√∫ster </li></ol><br><img src="https://habrastorage.org/webt/l4/zp/eo/l4zpeodynxiuqubl1fjc4b9iona.png"><br>  <b>Figura 9.</b> Estado del cl√∫ster despu√©s de conectar el segundo nodo <br><br>  ¬°El segundo nodo se ha conectado correctamente!  Sin embargo, esto no siempre sucede.  Si sigue los pasos incorrectamente o surgen problemas de red, la uni√≥n al cl√∫ster fallar√° y el cl√∫ster mismo se "dividir√°".  La mejor soluci√≥n es desconectar el nodo del cl√∫ster, eliminar toda la informaci√≥n sobre el cl√∫ster en √©l, luego reiniciar el servidor y verificar los pasos anteriores.  ¬øC√≥mo desconectar de forma segura un nodo de un cl√∫ster?  Primero, elim√≠nelo del cl√∫ster en el primer servidor: <br><br><pre> <code class="bash hljs">pvecm del proxmox2</code> </pre> <br>  Despu√©s de lo cual el nodo se desconectar√° del cl√∫ster.  Ahora ve al nodo roto y deshabilita los siguientes servicios en √©l: <br><br><pre> <code class="bash hljs">systemctl stop pvestatd.service systemctl stop pvedaemon.service systemctl stop pve-cluster.service systemctl stop corosync systemctl stop pve-cluster</code> </pre><br>  El cl√∫ster Proxmox almacena informaci√≥n sobre s√≠ mismo en la base de datos sqlite, tambi√©n debe borrarse: <br><br><pre> <code class="bash hljs">sqlite3 /var/lib/pve-cluster/config.db delete from tree <span class="hljs-built_in"><span class="hljs-built_in">where</span></span> name = <span class="hljs-string"><span class="hljs-string">'corosync.conf'</span></span>; .quit</code> </pre><br>  Los datos sobre la corteza se eliminan correctamente.  Elimine los archivos restantes, para esto debe iniciar el sistema de archivos del cl√∫ster en modo independiente: <br><br><pre> <code class="bash hljs">pmxcfs -l rm /etc/pve/corosync.conf rm /etc/corosync/* rm /var/lib/corosync/* rm -rf /etc/pve/nodes/*</code> </pre><br>  Reiniciamos el servidor (esto no es necesario, pero estamos seguros: todos los servicios deber√≠an estar funcionando correctamente al final. Para no perder nada, reiniciaremos).  Despu√©s de encender, obtendremos un nodo vac√≠o sin ninguna informaci√≥n sobre el cl√∫ster anterior y podremos iniciar la conexi√≥n nuevamente. <br><br><h3>  Instalar y configurar ZFS </h3><br>  ZFS es un sistema de archivos que se puede usar con Proxmox.  Con √©l, puede permitirse replicar datos a otro hipervisor, migrar la m√°quina virtual / contenedor LXC, acceder al contenedor LXC desde el sistema host, etc.  Instalarlo es bastante simple, procedamos al an√°lisis.  Hay tres SSD disponibles en mis servidores, que combinaremos en una matriz RAID. <br><br>  A√±adir repositorios: <br><br><pre> <code class="bash hljs">nano /etc/apt/sources.list.d/stretch-backports.list deb http://deb.debian.org/debian stretch-backports main contrib deb-src http://deb.debian.org/debian stretch-backports main contrib nano /etc/apt/preferences.d/90_zfs Package: libnvpair1linux libuutil1linux libzfs2linux libzpool2linux spl-dkms zfs-dkms zfs-test zfsutils-linux zfsutils-linux-dev zfs-zed Pin: release n=stretch-backports Pin-Priority: 990</code> </pre><br>  Actualizaci√≥n de la lista de paquetes: <br><br><pre> <code class="bash hljs">apt update</code> </pre> <br>  Establezca las dependencias requeridas: <br><br><pre> <code class="bash hljs"> apt install --yes dpkg-dev linux-headers-$(uname -r) linux-image-amd64</code> </pre> <br>  Instalar ZFS en s√≠ mismo: <br><br><pre> <code class="bash hljs">apt-get install zfs-dkms zfsutils-linux</code> </pre> <br>  Si en el futuro obtiene un error fusermount: no se encuentra el dispositivo de fusible, intente primero 'modprobe fuse', luego ejecute el siguiente comando: <br><br><pre> <code class="bash hljs">modprobe fuse</code> </pre> <br>  Ahora procedamos directamente a la configuraci√≥n.  Primero necesitamos formatear los SSD y configurarlos a trav√©s de parted: <br><br><div class="spoiler">  <b class="spoiler_title">Configurar / dev / sda</b> <div class="spoiler_text"><pre> <code class="bash hljs">parted /dev/sda (parted) <span class="hljs-built_in"><span class="hljs-built_in">print</span></span> Model: ATA SAMSUNG MZ7LM480 (scsi) Disk /dev/sda: 480GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 4296MB 4295MB primary raid 2 4296MB 4833MB 537MB primary raid 3 4833MB 37,0GB 32,2GB primary raid (parted) mkpart Partition <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>? primary/extended? primary File system <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>? [ext2]? zfs Start? 33GB End? 480GB Warning: You requested a partition from 33,0GB to 480GB (sectors 64453125..937500000). The closest location we can manage is 37,0GB to 480GB (sectors 72353792..937703087). Is this still acceptable to you? Yes/No? yes</code> </pre><br></div></div><br>  Se deben realizar acciones similares para otras unidades.  Despu√©s de que todos los discos est√©n preparados, contin√∫e con el siguiente paso: <br><br>  zpool create -f -o ashift = 12 rpool / dev / sda4 / dev / sdb4 / dev / sdc4 <br><br>  Elegimos ashift = 12 por razones de rendimiento: esta es la recomendaci√≥n de zfsonlinux en s√≠, se puede encontrar m√°s sobre esto en su wiki: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github.com/zfsonlinux/zfs/wiki/faq#performance-considerations</a> <br><br>  Aplique algunas configuraciones para ZFS: <br><br><pre> <code class="bash hljs">zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> atime=off rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> compression=lz4 rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> dedup=off rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> snapdir=visible rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> primarycache=all rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> aclinherit=passthrough rpool zfs inherit acltype rpool zfs get -r acltype rpool zfs get all rpool | grep compressratio</code> </pre><br>  Ahora necesitamos calcular algunas variables para calcular zfs_arc_max, hago esto de la siguiente manera: <br><br><pre> <code class="bash hljs">mem =`free --giga | grep Mem | awk <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span>` partofmem=$((<span class="hljs-variable"><span class="hljs-variable">$mem</span></span>/10)) <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> &gt; /sys/module/zfs/parameters/zfs_arc_max grep c_max /proc/spl/kstat/zfs/arcstats zfs create rpool/data cat &gt; /etc/modprobe.d/zfs.conf &lt;&lt; EOL options zfs zfs_arc_max=<span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> EOL <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> &gt; /sys/module/zfs/parameters/zfs_arc_max grep c_max /proc/spl/kstat/zfs/arcstats</code> </pre> <br>  Por el momento, el grupo se ha creado con √©xito, tambi√©n creamos un subgrupo de datos.  Puede verificar el estado de su grupo con el comando de estado zpool.  Esta acci√≥n debe realizarse en todos los hipervisores y luego continuar con el siguiente paso. <br><br>  Ahora agregue ZFS a Proxmox.  Vamos a la configuraci√≥n del centro de datos (es decir, y no a un nodo separado) en la secci√≥n "Almacenamiento", hacemos clic en el bot√≥n "Agregar" y seleccionamos la opci√≥n "ZFS", despu√©s de lo cual veremos los siguientes par√°metros: <br><br>  ID: Nombre de los cien.  Le di el nombre local-zfs <br>  Grupo ZFS: Creamos rpool / data, y lo agregamos aqu√≠. <br>  Nodos: especifique todos los nodos disponibles <br><br>  Este comando crea un nuevo grupo con las unidades que seleccionamos.  En cada hipervisor, debe aparecer un nuevo almacenamiento llamado local-zfs, despu√©s de lo cual puede migrar sus m√°quinas virtuales desde el almacenamiento local a ZFS. <br><br><h3>  Replicar instancias en un hipervisor vecino </h3><br>  El cl√∫ster Proxmox tiene la capacidad de replicar datos de un hipervisor a otro: esta opci√≥n le permite cambiar la instancia de un servidor a otro.  Los datos ser√°n relevantes en el momento de la √∫ltima sincronizaci√≥n: su tiempo se puede configurar al crear la replicaci√≥n (15 minutos se configura como est√°ndar).  Hay dos formas de migrar una instancia a otro nodo Proxmox: manual y autom√°tica.  Veamos primero la opci√≥n manual, y al final le dar√© un script de Python que le permitir√° crear una m√°quina virtual en un hipervisor accesible cuando uno de los hipervisores no est√© disponible. <br><br>  Para crear la replicaci√≥n, vaya al panel web de Proxmox y cree una m√°quina virtual o un contenedor LXC.  En los p√°rrafos anteriores, configuramos el puente vmbr1 con NAT, lo que nos permitir√° ir a la red externa.  Crear√© un contenedor LXC con MySQL, Nginx y PHP-FPM con un sitio de prueba para probar la replicaci√≥n.  A continuaci√≥n hay una instrucci√≥n paso a paso. <br><br>  Cargamos la plantilla adecuada (vaya a almacenamiento -&gt; Contenido -&gt; Plantillas), un ejemplo en la captura de pantalla: <br><br><img src="https://habrastorage.org/webt/sd/bd/57/sdbd579lmmzxefsigiivaftvpce.png"><br>  <b>Imagen 10.</b> Almacenamiento local con plantillas e im√°genes de VM <br><br>  Haga clic en el bot√≥n "Plantillas" y cargue la plantilla de contenedor LXC que necesitamos: <br><br><img src="https://habrastorage.org/webt/qx/ug/he/qxughewqdsfniccmaamka9idie0.png"><br>  <b>Imagen 11.</b> Seleccionar y cargar una plantilla <br><br>  Ahora podemos usarlo al crear nuevos contenedores LXC.  Seleccione el primer hipervisor y haga clic en el bot√≥n "Crear CT" en la esquina superior derecha: veremos el panel para crear una nueva instancia.  Los pasos de instalaci√≥n son bastante simples y solo dar√© el archivo de configuraci√≥n para este contenedor LXC: <br><br><pre> <code class="bash hljs">arch: amd64 cores: 3 memory: 2048 nameserver: 8.8.8.8 net0: name=eth0,bridge=vmbr1,firewall=1,gw=172.16.0.1,hwaddr=D6:60:C5:39:98:A0,ip=172.16.0.2/24,<span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=veth ostype: centos rootfs: <span class="hljs-built_in"><span class="hljs-built_in">local</span></span>:100/vm-100-disk-1.raw,size=10G swap: 512 unprivileged:</code> </pre><br>  El contenedor se cre√≥ con √©xito.  Puede conectarse a contenedores LXC a trav√©s del comando pct enter, tambi√©n agregu√© la clave del hipervisor SSH antes de la instalaci√≥n para conectarse directamente a trav√©s de SSH (hay algunos problemas menores con la visualizaci√≥n del terminal en PCT).  Prepar√© el servidor e instal√© todas las aplicaciones de servidor necesarias all√≠, ahora puede proceder a crear la replicaci√≥n. <br><br>  Hacemos clic en el contenedor LXC y vamos a la pesta√±a "Replicaci√≥n", donde creamos el par√°metro de replicaci√≥n usando el bot√≥n "Agregar": <br><br><img src="https://habrastorage.org/webt/ub/ac/si/ubacsivqghyu5w9np8dlnjdqe3g.png"><br>  <b>Figura 12.</b> Creaci√≥n de replicaci√≥n en la interfaz Proxmox <br><br><img src="https://habrastorage.org/webt/ea/mb/48/eamb489i0yqndxdcknvr2f1vefi.png"><br>  <b>Imagen 13.</b> Ventana de creaci√≥n de trabajo de replicaci√≥n <br><br>  Cre√© la tarea de replicar el contenedor en el segundo nodo, como puede ver en la siguiente captura de pantalla, la replicaci√≥n fue exitosa: preste atenci√≥n al campo "Estado", notifica sobre el estado de la replicaci√≥n, tambi√©n debe prestar atenci√≥n al campo "Duraci√≥n" para saber cu√°nto dura la replicaci√≥n de datos. <br><br><img src="https://habrastorage.org/webt/wr/hd/t7/wrhdt7uk4szufdqrvboovxwr6t0.png"><br>  <b>Imagen 14.</b> Lista de sincronizaci√≥n de VM <br><br>  Ahora intente migrar la m√°quina al segundo nodo con el bot√≥n "Migrar" <br><br>  Comenzar√° la migraci√≥n del contenedor, el registro se puede ver en la lista de tareas: habr√° nuestra migraci√≥n.  Despu√©s de eso, el contenedor se mover√° al segundo nodo. <br><br>  <b>Error de "Error de verificaci√≥n de clave de host"</b> <br><br>  A veces, al configurar un cl√∫ster, puede surgir un problema similar: evita que las m√°quinas migren y creen replicaci√≥n, lo que elimina las ventajas de las soluciones de cl√∫ster.  Para corregir este error, elimine el archivo known_hosts y con√©ctese a trav√©s de SSH al nodo en conflicto: <br><br><pre> <code class="bash hljs">/usr/bin/ssh -o <span class="hljs-string"><span class="hljs-string">'HostKeyAlias=proxmox2'</span></span> root@172.30.0.16</code> </pre><br>  Acepte Hostkey e intente ingresar este comando, deber√≠a conectarlo al servidor: <br><br><pre> <code class="bash hljs">/usr/bin/ssh -o <span class="hljs-string"><span class="hljs-string">'BatchMode=yes'</span></span> -o <span class="hljs-string"><span class="hljs-string">'HostKeyAlias=proxmox2'</span></span> root@172.30.0.16</code> </pre><br><h3>  Caracter√≠sticas de la configuraci√≥n de red en Hetzner </h3><br>  Vaya al panel Robot y haga clic en el bot√≥n "Interruptores virtuales".  En la p√°gina siguiente ver√° un panel para crear y administrar interfaces de conmutador virtual: primero debe crearlo y luego "conectarle" servidores dedicados.  En la b√∫squeda, agregue los servidores necesarios para conectarse: no es necesario reiniciarlos, solo tiene que esperar hasta 10-15 minutos cuando la conexi√≥n al conmutador virtual estar√° activa. <br><br>  Despu√©s de agregar los servidores a Virtual Switch a trav√©s del panel web, nos conectamos a los servidores y abrimos los archivos de configuraci√≥n de las interfaces de red, donde creamos una nueva interfaz de red: <br><br><pre> <code class="bash hljs">auto enp4s0.4000 iface enp4s0.4000 inet static address 10.1.0.11/24 mtu 1400 vlan-raw-device enp4s0</code> </pre> <br>  Echemos un vistazo m√°s de cerca a lo que es.  En esencia, es una VLAN que se conecta a una √∫nica interfaz f√≠sica llamada enp4s0 (puede variar para usted), con un n√∫mero de VLAN: este es el n√∫mero del conmutador virtual que cre√≥ en el panel web del robot Hetzner.  Puede especificar cualquier direcci√≥n, siempre que sea local. <br><br>  Observo que debe configurar enp4s0 como de costumbre, de hecho, debe contener una direcci√≥n IP externa que se emiti√≥ a su servidor f√≠sico.  Repita estos pasos en otros hipervisores, luego reinicie el servicio de red en ellos, haga ping a un nodo vecino utilizando la direcci√≥n IP del conmutador virtual.  Si el ping fue exitoso, entonces ha establecido exitosamente una conexi√≥n entre los servidores usando Virtual Switch. <br><br>  Tambi√©n adjuntar√© el archivo de configuraci√≥n sysctl.conf, ser√° necesario si tiene problemas con el paquete de reenv√≠o y otros par√°metros de red: <br><br><pre> <code class="bash hljs">net.ipv6.conf.all.disable_ipv6=0 net.ipv6.conf.default.disable_ipv6 = 0 net.ipv6.conf.all.forwarding=1 net.ipv4.conf.all.rp_filter=1 net.ipv4.tcp_syncookies=1 net.ipv4.ip_forward=1 net.ipv4.conf.all.send_redirects=0</code> </pre><br>  <b>Agregar subredes IPv4 a Hetzner</b> <br><br>  Antes de comenzar a trabajar, debe solicitar una subred en Hetzner, puede hacerlo a trav√©s del panel Robot. <br><br>  Cree un puente de red con la direcci√≥n que ser√° de esta subred.  Ejemplo de configuraci√≥n: <br><br><pre> <code class="bash hljs">auto vmbr2 iface vmbr2 inet static address ip-address netmask 29 bridge-ports none bridge-stp off bridge-fd 0</code> </pre> <br>  Ahora vaya a la configuraci√≥n de la m√°quina virtual en Proxmox y cree una nueva interfaz de red que se conectar√° al puente vmbr2.  Utilizo el contenedor LXC, su configuraci√≥n se puede cambiar inmediatamente en Proxmox.  Configuraci√≥n final para Debian: <br><br><pre> <code class="bash hljs">auto eth0 iface eth0 inet static address ip-address netmask 26 gateway bridge-address</code> </pre> <br>  Tenga en cuenta: especifiqu√© 26 m√°scaras, no 29; esto es necesario para que la red funcione en la m√°quina virtual. <br><br>  <b>Agregar direcciones IPv4 a Hetzner</b> <br><br>  La situaci√≥n con una sola direcci√≥n IP es diferente, generalmente Hetzner nos da una direcci√≥n adicional desde la subred del servidor.  Esto significa que en lugar de vmbr2 necesitamos usar vmbr0, pero por el momento no lo tenemos.  La conclusi√≥n es que vmbr0 debe contener la direcci√≥n IP del servidor iron (es decir, usar la direcci√≥n que us√≥ la interfaz de red f√≠sica enp2s0).  La direcci√≥n se debe mover a vmbr0, la siguiente configuraci√≥n es adecuada para esto (le aconsejo que solicite KVM, en cuyo caso reanudar√° el funcionamiento de la red): <br><br><pre> <code class="bash hljs">auto enp2s0 iface enp2s0 inet manual auto vmbr0 iface vmbr0 inet static address ip-address netmask 255.255.255.192 gateway ip-gateway bridge-ports enp2s0 bridge-stp off bridge-fd 0</code> </pre><br>  Reinicie el servidor, si es posible (si no, reinicie el servicio de red), y luego verifique las interfaces de red a trav√©s de ip a: <br><br><pre> <code class="bash hljs">2: enp2s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master vmbr0 state UP group default qlen 1000 link/ether 44:8a:5b:2c:30:c2 brd ff:ff:ff:ff:ff:ff</code> </pre><br>  Como puede ver aqu√≠, enp2s0 est√° conectado a vmbr0 y no tiene una direcci√≥n IP, ya que fue reasignado a vmbr0. <br><br>  Ahora en la configuraci√≥n de la m√°quina virtual, agregue la interfaz de red que se conectar√° a vmbr0.  Para la puerta de enlace, especifique la direcci√≥n adjunta a vmbr0. <br><br><h3>  Al final </h3><br>  Espero que este art√≠culo sea √∫til cuando configure el cl√∫ster Proxmox en Hetzner.  Si el tiempo lo permite, expandir√© el art√≠culo y agregar√© instrucciones para OVH; all√≠ tambi√©n, no todo es obvio, como parece a primera vista.  El material result√≥ ser bastante voluminoso, si encuentra errores, escriba los comentarios, los corregir√©.  Gracias a todos por su atenci√≥n. <br><br>  <i>Publicado por Ilya Andreev, editado por Alexei Zhadan y Live Linux Team</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/457894/">https://habr.com/ru/post/457894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457876/index.html">Traducci√≥n: IEEE 802.15.4z Standard. ¬øQu√© nos espera en el futuro?</a></li>
<li><a href="../457884/index.html">Internet soberano: √≥rdenes aclaratorias</a></li>
<li><a href="../457886/index.html">Autenticaci√≥n de dos factores en el sitio utilizando un token USB. Ahora para Linux</a></li>
<li><a href="../457888/index.html">Prueba de mutaci√≥n: pruebas de prueba</a></li>
<li><a href="../457892/index.html">Profesor de ruleta</a></li>
<li><a href="../457896/index.html">Zimbra y protecci√≥n de sobrecarga del servidor</a></li>
<li><a href="../457900/index.html">Comisi√≥n Federal de Comunicaciones de EE. UU. Contra meteor√≥logos</a></li>
<li><a href="../457902/index.html">Mitap para ciencia de datos</a></li>
<li><a href="../457904/index.html">Radio at√≥mica: la primera emisi√≥n musical</a></li>
<li><a href="../457906/index.html">Los m√©dicos creen que en el futuro cercano, los dispositivos de fabricaci√≥n de vacunas aparecer√°n en hogares y farmacias.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç≠ üé® üëãüèæ LLVM pour Tensorflow, ou Law End Compiler de Moore üë®üèº‚Äç‚öïÔ∏è üë®üèø‚Äçüöí ‚¨ÖÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'√©cosyst√®me TensorFlow contient un certain nombre de compilateurs et d'optimiseurs travaillant √† diff√©rents niveaux de la pile logicielle et mat√©riel...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>LLVM pour Tensorflow, ou Law End Compiler de Moore</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457826/">  L'√©cosyst√®me TensorFlow contient un certain nombre de compilateurs et d'optimiseurs travaillant √† diff√©rents niveaux de la pile logicielle et mat√©rielle.  Pour ceux qui utilisent Tensorflow quotidiennement, cette pile multi-niveaux peut g√©n√©rer des erreurs difficiles √† comprendre, √† la fois au moment de la compilation et √† l'ex√©cution, associ√©es √† l'utilisation de diff√©rents types de mat√©riel (GPU, TPU, plateformes mobiles, etc.) <br><br>  Ces composants, √† commencer par le graphique Tensorflow, peuvent √™tre repr√©sent√©s sous la forme d'un tel diagramme: <br><br><img src="https://habrastorage.org/webt/ly/cf/0y/lycf0y0ld6eld56mnuba9iyhjii.png"><br><br>  <i>C'est en fait plus difficile</i> <br><a name="habracut"></a><br>  Dans ce diagramme, nous pouvons voir que les graphiques Tensorflow peuvent √™tre ex√©cut√©s de plusieurs mani√®res diff√©rentes. <br><br><div class="spoiler">  <b class="spoiler_title">une note</b> <div class="spoiler_text">  Dans TensorFlow 2.0, les graphiques peuvent √™tre implicites; l'ex√©cution gourmande peut ex√©cuter des op√©rations individuellement, en groupes ou sur un graphique complet.  Ces graphiques ou fragments de graphique doivent √™tre optimis√©s et ex√©cut√©s. <br></div></div><br>  Par exemple: <br><br><ul><li>  Nous envoyons les graphiques √† l'ex√©cuteur Tensorflow, qui appelle des noyaux manuscrits sp√©cialis√©s </li><li>  Convertissez-les en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">XLA</a> HLO (repr√©sentation XLA High-Level Optimizer) - une repr√©sentation de haut niveau de l'optimiseur XLA, qui, √† son tour, peut appeler le compilateur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LLVM</a> pour le CPU ou le GPU, ou continuer √† utiliser XLA pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TPU</a> , ou les combiner. </li><li>  Nous les convertissons en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorRT</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nGraph</a> ou un autre format pour un jeu d'instructions sp√©cialis√© impl√©ment√© dans le mat√©riel. </li><li>  Nous les convertissons au format <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorFlow Lite</a> , ex√©cut√©s dans le runtime TensorFlow Lite, ou convertis en code pour les ex√©cuter sur le GPU ou le DSP via l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">API Android Neural Networks</a> (NNAPI) ou similaire. </li></ul><br>  Il existe √©galement des m√©thodes plus complexes, notamment de nombreuses passes d'optimisation sur chaque couche, comme, par exemple, dans le cadre Grappler, qui optimise les op√©rations dans TensorFlow. <br><br>  Bien que ces diverses impl√©mentations de compilateurs et de repr√©sentations interm√©diaires am√©liorent les performances, leur diversit√© pose un probl√®me aux utilisateurs finaux, comme la confusion des messages d'erreur lors du couplage de ces sous-syst√®mes.  De plus, les cr√©ateurs de nouvelles piles logicielles et mat√©rielles doivent ajuster les passages d'optimisation et de conversion pour chaque nouveau cas. <br><br>  Et en vertu de tout cela, nous sommes heureux d'annoncer MLIR, une repr√©sentation interm√©diaire √† plusieurs niveaux.  Il s'agit d'un format de vue interm√©diaire et de biblioth√®ques de compilation √† utiliser entre une vue de mod√®le et un compilateur de bas niveau qui g√©n√®re du code d√©pendant du mat√©riel.  En introduisant MLIR, nous voulons c√©der la place √† de nouvelles recherches dans le d√©veloppement d'optimisation de compilateurs et la mise en ≈ìuvre de compilateurs bas√©s sur des composants de qualit√© industrielle. <br><br>  Nous pr√©voyons que le MLIR int√©ressera de nombreux groupes, notamment: <br><br><ul><li>  les chercheurs de compilateurs, ainsi que les praticiens qui souhaitent optimiser les performances et la consommation de m√©moire des mod√®les d'apprentissage automatique; </li><li>  les fabricants de mat√©riel √† la recherche d'un moyen de combiner leur mat√©riel avec Tensorflow, comme les TPU, les neuroprocesseurs mobiles dans les smartphones et d'autres ASIC personnalis√©s; </li><li>  les personnes qui souhaitent donner aux langages de programmation les avantages procur√©s par l'optimisation des compilateurs et des acc√©l√©rateurs mat√©riels; </li></ul><br><h3>  Qu'est-ce que le MLIR? </h3><br>  MLIR est essentiellement une infrastructure flexible pour les compilateurs d'optimisation modernes.  Cela signifie qu'il se compose d'une sp√©cification de repr√©sentation interm√©diaire (IR) et d'un ensemble d'outils pour transformer cette repr√©sentation.  Lorsque nous parlons de compilateurs, le passage d'une vue de niveau sup√©rieur √† une vue de niveau inf√©rieur est appel√© abaissement, et nous utiliserons ce terme √† l'avenir. <br><br>  MLIR est construit sous l'influence du LLVM et lui emprunte sans vergogne de nombreuses bonnes id√©es.  Il a un syst√®me de type flexible et est con√ßu pour repr√©senter, analyser et transformer des graphiques, combinant de nombreux niveaux d'abstraction en un seul niveau de compilation.  Ces abstractions incluent les op√©rations Tensorflow, les r√©gions de boucles poly√©driques imbriqu√©es, les instructions LLVM et les op√©rations et types √† point fixe. <br><br><h3>  Dialectes de MLIR </h3><br>  Afin de s√©parer les diff√©rentes cibles logicielles et mat√©rielles, MLIR dispose de ¬´dialectes¬ª, notamment: <br><br><ul><li>  TensorFlow IR, qui inclut tout ce qui peut √™tre fait dans les graphiques TensorFlow </li><li>  XLA HLO IR, con√ßu pour obtenir tous les avantages fournis par le compilateur XLA, dont la sortie nous permet d'obtenir du code pour TPU, et pas seulement. </li><li>  Un dialecte d'affinit√© exp√©rimental con√ßu sp√©cifiquement pour les repr√©sentations et optimisations <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">poly√©driques</a> </li><li>  LLVM IR, 1: 1 correspondant √† la vue LLVM native, permettant √† MLIR de g√©n√©rer du code pour le GPU et le CPU √† l'aide de LLVM. </li><li>  TensorFlow Lite con√ßu pour g√©n√©rer du code pour les plates-formes mobiles </li></ul><br>  Chaque dialecte contient un ensemble d'op√©rations sp√©cifiques, utilisant des invariants, tels que: "c'est un op√©rateur binaire, et ses entr√©es et sorties sont du m√™me type". <br><br><h3>  Extensions MLIR </h3><br>  MLIR n'a pas de liste fixe et int√©gr√©e d'op√©rations intrins√®ques mondiales.  Les dialectes peuvent d√©finir des types compl√®tement personnalis√©s, et de cette fa√ßon MLIR peut mod√©liser des choses comme le syst√®me de type IR LLVM (ayant des agr√©gats de premi√®re classe), des abstractions de langage de domaine, telles que des types quantifi√©s, importantes pour les acc√©l√©rateurs optimis√©s ML, et, √† l'avenir, m√™me un syst√®me de type Swift ou Clang. <br><br>  Si vous souhaitez associer un nouveau compilateur de bas niveau √† ce syst√®me, vous pouvez cr√©er un nouveau dialecte et descendre du dialecte du graphique TensorFlow vers votre dialecte.  Cela simplifie le chemin d'acc√®s pour les d√©veloppeurs de mat√©riel et les d√©veloppeurs de compilateurs.  Vous pouvez cibler le dialecte √† diff√©rents niveaux du m√™me mod√®le, des optimiseurs de haut niveau seront responsables de parties sp√©cifiques de l'IR. <br><br>  Pour les chercheurs de compilateurs et les d√©veloppeurs de frameworks, MLIR vous permet de cr√©er des transformations √† tous les niveaux, vous pouvez d√©finir vos propres op√©rations et abstractions en IR, vous permettant de mieux mod√©liser vos t√¢ches d'application.  Ainsi, MLIR est plus qu'une pure infrastructure de compilateur, ce que LLVM est. <br><br>  Bien que MLIR fonctionne comme un compilateur pour ML, il permet √©galement l'utilisation de technologies d'apprentissage automatique!  Ceci est tr√®s important pour les ing√©nieurs qui d√©veloppent des biblioth√®ques num√©riques et ne peut pas prendre en charge la grande vari√©t√© de mod√®les et de mat√©riel ML.  La flexibilit√© de MLIR facilite l'exploration de strat√©gies de descente de code lors du d√©placement entre les niveaux d'abstraction. <br><br><h3>  Et ensuite </h3><br>  Nous avons ouvert un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©f√©rentiel GitHub</a> et invitons toutes les personnes int√©ress√©es (consultez notre guide!).  Nous publierons quelque chose de plus que cette bo√Æte √† outils - les sp√©cifications de dialecte TensorFlow et TF Lite, dans les prochains mois.  Nous pouvons vous en dire plus, pour en savoir plus, voir la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pr√©sentation de Chris Luttner</a> et notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">README sur Github</a> . <br><br>  Si vous voulez vous tenir au courant de tout ce qui touche au MLIR, rejoignez notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nouvelle liste de diffusion</a> , qui se concentrera bient√¥t sur les annonces de futures versions de notre projet.  Reste avec nous! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr457826/">https://habr.com/ru/post/fr457826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr457812/index.html">¬´Attends! Qui vient? " Surveillance vid√©o sur le porche</a></li>
<li><a href="../fr457814/index.html">Prochaines √©tapes √† suivre 2</a></li>
<li><a href="../fr457816/index.html">Juju en un coup d'≈ìil</a></li>
<li><a href="../fr457820/index.html">Comment faire grandir un √©vang√©liste pour votre entreprise</a></li>
<li><a href="../fr457824/index.html">Stress infectieux: synchronisation intersp√©cifique des niveaux de cortisol sur l'exemple des chiens et de leurs propri√©taires</a></li>
<li><a href="../fr457830/index.html">Comment r√©parer une piscine d'arri√®re-cour en 7 heures en utilisant la m√©thode du chemin critique?</a></li>
<li><a href="../fr457836/index.html">Ce que j'ai appris en cr√©ant Dribbble</a></li>
<li><a href="../fr457838/index.html">La technologie EDR en tant qu'√©l√©ment de la triade nucl√©aire SOC</a></li>
<li><a href="../fr457842/index.html">Syst√®me de contr√¥le de mouvement de vaisseau spatial Soyouz-TM</a></li>
<li><a href="../fr457844/index.html">Sept habitudes de base pour les √©quipes de d√©veloppement travaillant √† distance</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
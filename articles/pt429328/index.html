<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ÜóÔ∏è ‚ö´Ô∏è üî∞ M√≥dulo de software para digitaliza√ß√£o de documentos danificados üë∞ üôÖüèø üëÜüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O reconhecimento √≥ptico de caracteres (OCR) √© o processo de obten√ß√£o de textos impressos em formato digitalizado. Se voc√™ leu um romance cl√°ssico em u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>M√≥dulo de software para digitaliza√ß√£o de documentos danificados</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429328/"><p> O reconhecimento √≥ptico de caracteres (OCR) √© o processo de obten√ß√£o de textos impressos em formato digitalizado.  Se voc√™ leu um romance cl√°ssico em um dispositivo digital ou pediu a um m√©dico para buscar registros m√©dicos antigos atrav√©s do sistema de computador do hospital, provavelmente usou o OCR. </p><br><p>  O OCR torna o conte√∫do anteriormente est√°tico edit√°vel, pesquis√°vel e compartilh√°vel.  Mas muitos documentos que precisam ser digitalizados cont√™m manchas de caf√©, p√°ginas com cantos enrolados e muitas rugas que mant√™m alguns documentos impressos n√£o digitalizados. </p><br><p>  Todo mundo sabe que h√° milh√µes de livros antigos armazenados em armazenamento.  √â proibido o uso desses livros devido √† sua dilapida√ß√£o e decrepitude e, portanto, a digitaliza√ß√£o desses livros √© muito importante. </p><br><p>  O artigo considera a tarefa de limpar o texto do ru√≠do, reconhecendo o texto em uma imagem e convertendo-o para o formato de texto. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b0/14c/324/3b014c324c6ac91f8d8a761ca4e0bbc1.jpg" alt="imagem"></p><br><p>  Para o treinamento, 144 fotos foram usadas.  O tamanho pode ser diferente, mas de prefer√™ncia deve estar dentro da raz√£o.  As imagens devem estar no formato PNG.  Depois de ler a imagem, a binariza√ß√£o √© usada - o processo de convers√£o de uma imagem colorida em preto e branco, ou seja, cada pixel √© normalizado para um intervalo de 0 a 255, onde 0 √© preto e 255 √© branco. </p><br><p>  Para treinar uma rede convolucional, voc√™ precisa de mais imagens do que existem.  Foi decidido dividir as imagens em partes.  Como a amostra de treinamento consiste em imagens de tamanhos diferentes, cada imagem foi compactada para 448x448 pixels.  O resultado foi 144 imagens em uma resolu√ß√£o de 448x448 pixels.  Todos eles foram cortados em janelas sem sobreposi√ß√£o, com 112 x 112 pixels de tamanho. </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/getpro/habr/post_images/07a/c1d/271/07ac1d2716da451215a597dbb8241a9d.jpg" alt="imagem"></p><br><p>  Assim, das 144 imagens iniciais, foram obtidas cerca de 2304 imagens no conjunto de treinamento.  Mas isso n√£o foi suficiente.  √â necess√°rio mais treinamento para um bom treinamento em rede convolucional.  Como resultado disso, a melhor op√ß√£o era girar as imagens 90 graus, depois 180 e 270 graus.  Como resultado, uma matriz com o tamanho [16.112.112,1] √© fornecida √† entrada da rede.  Onde 16 √© o n√∫mero de imagens, 112 √© a largura e a altura de cada imagem, 1 s√£o os canais de cores.  Foram 9216 exemplos de treinamento.  Isso √© suficiente para treinar uma rede convolucional. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f7d/320/415/f7d320415a5cba904cf715646dddbe2a.png" alt="imagem"></p><br><p>  Cada imagem tem um tamanho de 112x112 pixels.  Se o tamanho for muito grande, a complexidade computacional aumentar√°, respectivamente, as restri√ß√µes √† velocidade de resposta ser√£o violadas, a determina√ß√£o do tamanho neste problema ser√° resolvida pelo m√©todo de sele√ß√£o.  Se voc√™ selecionar um tamanho muito pequeno, a rede n√£o poder√° identificar os principais sinais.  Cada imagem tem um formato preto e branco, portanto, √© dividida em 1 canal.  As imagens coloridas s√£o divididas em 3 canais: vermelho, azul, verde.  Como temos imagens em preto e branco, o tamanho de cada imagem √© 112x122x1 pixels. </p><br><p>  Antes de tudo, √© necess√°rio treinar uma rede neural convolucional em imagens processadas e preparadas.  Para esta tarefa, a arquitetura U-Net foi selecionada. </p><br><p>  Uma vers√£o reduzida da arquitetura foi selecionada, consistindo em apenas dois blocos (a vers√£o original de quatro).  Uma considera√ß√£o importante foi o fato de que uma grande classe de algoritmos de binariza√ß√£o conhecidos √© expressa explicitamente em uma arquitetura ou arquitetura semelhante (como exemplo, podemos modificar o algoritmo Niblack substituindo o desvio padr√£o pelo desvio m√©dio, caso em que a rede √© constru√≠da de maneira especialmente simples). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/43a/928/f6d/43a928f6d29028779c1fa25df30f794c.jpg" alt="imagem"></p><br><p>  A vantagem dessa arquitetura √© que, para treinar a rede, voc√™ pode criar uma quantidade suficiente de dados de treinamento a partir de um pequeno n√∫mero de imagens de origem.  Al√©m disso, a rede possui um n√∫mero relativamente pequeno de pesos devido √† sua arquitetura convolucional.  Mas existem algumas nuances.  Em particular, a rede neural artificial usada, estritamente falando, n√£o resolve o problema de binariza√ß√£o: para cada pixel da imagem de origem, associa um n√∫mero de 0 a 1, que caracteriza o grau em que esse pixel pertence a uma das classes (preenchimento significativo ou plano de fundo) e que √© necess√°rio ainda converter para a resposta bin√°ria final.  [1] </p><br><p>  O U-Net consiste em um caminho de compacta√ß√£o e descompacta√ß√£o e "encaminha" entre eles.  O caminho da compacta√ß√£o, nessa arquitetura, consiste em dois blocos (na vers√£o original de quatro).  Cada bloco possui duas convolu√ß√µes com um filtro 3x3 (usando a fun√ß√£o de ativa√ß√£o Tanh ap√≥s a convolu√ß√£o) e um pool com um tamanho de filtro 2x2 nas etapas de 2. O n√∫mero de canais em cada etapa para baixo dobra. </p><br><p>  O caminho do aperto tamb√©m consiste em dois blocos.  Cada um deles consiste em uma "varredura" com um tamanho de filtro de 2x2, reduzindo pela metade o n√∫mero de canais, concatena√ß√£o com um mapa de recurso cortado correspondente do caminho de compress√£o ("encaminhamento") e duas convolu√ß√µes com um filtro 3x3 (usando a fun√ß√£o de ativa√ß√£o Tanh ap√≥s a convolu√ß√£o).  Em seguida, na √∫ltima camada, uma convolu√ß√£o 1x1 (usando a fun√ß√£o de ativa√ß√£o Sigmoid) para obter uma imagem plana e de sa√≠da.  Observe que o corte do mapa de recursos durante a concatena√ß√£o √© essencial devido √† perda de pixels de limite para cada convolu√ß√£o.  Adam foi escolhido como o m√©todo de otimiza√ß√£o estoc√°stica. </p><br><p>  Em geral, a arquitetura √© uma sequ√™ncia de convolu√ß√£o + camadas de pool que reduzem a resolu√ß√£o espacial da imagem e aumentam combinando-a com os dados da imagem com anteced√™ncia e passando pelas outras camadas da convolu√ß√£o.  Assim, a rede atua como uma esp√©cie de filtro.  [2] </p><br><p>  A amostra de teste consistiu em imagens semelhantes, as diferen√ßas foram apenas na textura do ru√≠do e no texto.  Os testes de rede ocorreram nesta imagem. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/595/79b/89b/59579b89b072f197c925623e11e712c5.jpg" alt="imagem"></p><br><p>  Na sa√≠da da rede neural convolucional, √© obtida uma matriz de n√∫meros com um tamanho de [16.112.112,1].  Cada n√∫mero √© um pixel separado processado pela rede.  As imagens t√™m um formato de 112x112 pixels, como antes, foram cortadas em peda√ßos.  Ela precisa trair a apar√™ncia original.  Combinamos as imagens obtidas em uma parte, como resultado, a imagem tem um formato de 448x448.  Em seguida, multiplicamos cada n√∫mero na matriz por 255 para obter um intervalo de 0 a 255, onde 0 √© preto e 255 √© branco.  Retornamos a imagem ao seu tamanho original, como antes, ela foi compactada.  O resultado √© a figura abaixo na figura. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a05/a85/636/a05a856361fdc5cefe5c84e81df33992.jpg" alt="imagem"></p><br><p>  Neste exemplo, observa-se que a rede convolucional lidou com a maior parte do ru√≠do e mostrou-se eficiente.  Mas √© claramente vis√≠vel que a imagem ficou mais nublada e os ru√≠dos perdidos s√£o vis√≠veis.  No futuro, isso pode afetar a precis√£o do reconhecimento de texto. </p><br><p>  Com base nesse fato, decidiu-se usar outra rede neural - um perceptron multicamada.  No resultado esperado, a rede deve tornar o texto na imagem mais n√≠tido e remover o ru√≠do que est√° faltando na rede neural convolucional. </p><br><p>  Uma imagem j√° processada pela rede de convolu√ß√£o √© enviada para a entrada do perceptron de m√∫ltiplas camadas.  Nesse caso, a amostra de treinamento para esta rede ser√° diferente da amostra da rede convolucional, uma vez que as redes processam a imagem de maneira diferente.  A rede convolucional √© considerada a rede principal e remove a maior parte do ru√≠do na imagem, enquanto o perceptron multicamada processa o que o convolucional n√£o conseguiu. <br>  Aqui est√£o alguns exemplos do conjunto de treinamento para um perceptron de v√°rias camadas. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/505/62f/877/50562f87767ceb31fae90cb98f86dacf.jpg" alt="imagem"></p><br><p>  Os dados da imagem foram obtidos atrav√©s do processamento da amostra de treinamento para a rede convolucional com um perceptron multicamada.  Ao mesmo tempo, o perceptron foi treinado na mesma amostra, mas em um pequeno n√∫mero de exemplos e um pequeno n√∫mero de √©pocas. </p><br><p>  Para o treinamento de perceptron, 36 imagens foram processadas.  A rede √© treinada pixel por pixel, ou seja, um pixel da imagem √© enviado para a entrada da rede.  Na sa√≠da da rede, tamb√©m temos um neur√¥nio de sa√≠da - um pixel, ou seja, a resposta da rede.  Para aumentar a precis√£o do processamento, foram feitos 29 neur√¥nios de entrada.  E na imagem obtida ap√≥s o processamento pela rede de convolu√ß√£o, 28 filtros s√£o sobrepostos.  O resultado s√£o 29 imagens com filtros diferentes.  Enviamos um pixel de cada imagem 29 para a entrada da rede e apenas um pixel √© recebido na sa√≠da da rede, ou seja, a resposta da rede. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d00/628/790/d00628790fa450774472e3293bba3965.jpg" alt="imagem"></p><br><p>  Isso foi feito para melhor treinamento e networking.  Depois disso, a rede come√ßou a aumentar a precis√£o e o contraste da imagem.  Ele tamb√©m limpa pequenos erros que n√£o conseguiam limpar a rede convolucional. </p><br><p>  Como resultado, a rede neural possui 29 neur√¥nios de entrada, um pixel de cada imagem.  Ap√≥s os experimentos, verificou-se que era necess√°ria apenas uma camada oculta, na qual 500 neur√¥nios.  Existe apenas uma sa√≠da da rede.  Como o treinamento ocorreu pixel por pixel, a rede foi acessada n * m vezes, onde n √© a largura da imagem e m √© a altura, respectivamente. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a1a/1b4/2d9/a1a1b42d91fd9ec4ea767e9a72850f11.jpg" alt="imagem"></p><br><p>  Depois de processar a imagem sequencialmente por duas redes neurais, a principal coisa que resta √© reconhecer o texto.  Para isso, foi utilizada uma solu√ß√£o pronta, a biblioteca Python Pytesseract.  O Pytesseract n√£o fornece liga√ß√µes Python verdadeiras.  Em vez disso, √© um inv√≥lucro simples para o bin√°rio tesseract.  Nesse caso, o tesseract √© instalado separadamente no computador.  O Pytesseract salva a imagem em um arquivo tempor√°rio no disco e, em seguida, chama o arquivo bin√°rio do tesseract e grava o resultado em um arquivo. </p><br><p>  Este wrapper foi desenvolvido pelo Google e √© gratuito e gratuito.  Pode ser usado tanto para fins pessoais quanto comerciais.  A biblioteca funciona sem conex√£o √† Internet, suporta v√°rios idiomas para reconhecimento e impressiona com sua velocidade.  Sua aplica√ß√£o pode ser encontrada em v√°rias aplica√ß√µes populares. </p><br><p>  O √∫ltimo item que resta √© gravar o texto reconhecido em um arquivo em um formato adequado para process√°-lo.  Utilizamos para isso um notebook comum, que √© aberto ap√≥s o t√©rmino do programa.  Al√©m disso, o texto √© exibido na interface de teste.  Um bom exemplo de uma interface. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b7/bb0/a49/3b7bb0a49f54d81ecd638b0e074ab24e.jpg" alt="imagem"></p><br><p>  <strong>Refer√™ncias:</strong> </p><br><ol><li>  A hist√≥ria da vit√≥ria no concurso internacional de reconhecimento de documentos da equipe SmartEngines [Recurso eletr√¥nico].  Modo de acesso: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://habr.com/company/smartengines/blog/344550/</a> </li><li>  Segmenta√ß√£o de imagens usando uma rede neural: U-Net [Recurso eletr√¥nico].  Modo de acesso: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://robocraft.ru/blog/machinelearning/3671.html</a> </li></ol><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">&gt; <strong>Reposit√≥rio do Github</strong></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt429328/">https://habr.com/ru/post/pt429328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt429318/index.html">IPhone SMT Solver</a></li>
<li><a href="../pt429320/index.html">Sberbank Data Science Day transmiss√£o ao vivo 10 de novembro</a></li>
<li><a href="../pt429322/index.html">nanoCAD Mechanics 9.0: o b√°sico do design moderno</a></li>
<li><a href="../pt429324/index.html">Lan√ßamento do Unreal Engine 4.21</a></li>
<li><a href="../pt429326/index.html">A App Store n√£o liga. Ou como eu fiz meu aplicativo, mas ele n√£o alcan√ßar√° os usu√°rios</a></li>
<li><a href="../pt429330/index.html">Mitos e lendas do Agile - dos fara√≥s at√© os dias atuais</a></li>
<li><a href="../pt429336/index.html">Comunica√ß√£o entre driver e dispositivo pelo m√©todo _HID ACPI usando o GPIO do controlador Lynxpoint como exemplo</a></li>
<li><a href="../pt429338/index.html">Armazenamento Android: Interno, Externo, Remov√≠vel. Parte 1/3</a></li>
<li><a href="../pt429340/index.html">Pense duas vezes antes de usar o Helm.</a></li>
<li><a href="../pt429342/index.html">Angular 6+ √© um guia completo de inje√ß√£o de depend√™ncia. fornecida em vs provedores: []</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï∫üèΩ üç† üë®üèº‚ÄçüöÄ Wir segmentieren t√§glich 600 Millionen Benutzer in Echtzeit üíÜüèø ‚§¥Ô∏è üë®üèΩ‚Äç‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jeden Tag f√ºhren Benutzer Millionen von Online-Aktivit√§ten durch. Das FACETz DMP-Projekt muss diese Daten strukturieren und segmentieren, um Benutzerp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir segmentieren t√§glich 600 Millionen Benutzer in Echtzeit</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jugru/blog/421125/">  Jeden Tag f√ºhren Benutzer Millionen von Online-Aktivit√§ten durch.  Das FACETz DMP-Projekt muss diese Daten strukturieren und segmentieren, um Benutzerpr√§ferenzen zu identifizieren.  In dem Artikel werden wir dar√ºber sprechen, wie das Team ein Publikum von 600 Millionen Menschen segmentierte, t√§glich 5 Milliarden Ereignisse verarbeitete und mit Statistiken unter Verwendung von Kafka und HBase arbeitete. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/5Ybt_k53CIE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Das Material basiert auf einer Abschrift eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Berichts von Artyom Marinov</a> , einem Big-Data-Spezialisten bei Directual, von der SmartData 2017-Konferenz. <br><a name="habracut"></a><br>  Mein Name ist Artyom Marinov. Ich m√∂chte dar√ºber sprechen, wie wir die Architektur des FACETz DMP-Projekts neu gestaltet haben, als ich bei Data Centric Alliance gearbeitet habe.  Warum wir es getan haben, wozu es gef√ºhrt hat, welchen Weg wir gegangen sind und auf welche Probleme wir gesto√üen sind. <br><br>  DMP (Data Management Platform) ist eine Plattform zum Sammeln, Verarbeiten und Aggregieren von Benutzerdaten.  Daten sind viele verschiedene Dinge.  Die Plattform hat ungef√§hr 600 Millionen Benutzer.  Dies sind Millionen von Cookies, die ins Internet gehen und verschiedene Ereignisse ausl√∂sen.  Im Allgemeinen sieht ein Tag im Durchschnitt ungef√§hr so ‚Äã‚Äãaus: Wir sehen ungef√§hr 5,5 Milliarden Ereignisse pro Tag, sie sind irgendwie nach Tag verteilt und erreichen auf dem H√∂hepunkt ungef√§hr 100.000 Ereignisse pro Sekunde. <img src="https://habrastorage.org/getpro/habr/post_images/f66/f4d/915/f66f4d9154b1ddad3c3bb8af7e5ba860.png">  Ereignisse sind verschiedene Benutzersignale.  Zum Beispiel ein Besuch auf einer Site: Wir sehen, von welchem ‚Äã‚ÄãBrowser der Benutzer geht, von welchem ‚Äã‚ÄãUseragent und von allem, was wir extrahieren k√∂nnen.  Manchmal sehen wir, wie und f√ºr welche Suchanfragen er auf die Website kam.  Es k√∂nnen auch verschiedene Daten aus der Offline-Welt sein, zum Beispiel was es mit Rabattgutscheinen bezahlt und so weiter. <br><br>  Wir m√ºssen diese Daten speichern und den Benutzer in die sogenannten Gruppen von Zielgruppensegmenten einordnen.  Zum Beispiel k√∂nnen die Segmente eine "Frau" sein, die "Katzen liebt" und nach "Autoservice" sucht, sie "hat ein Auto, das √§lter als drei Jahre ist". <br><br>  Warum einen Benutzer segmentieren?  Hierf√ºr gibt es viele Anwendungen, zum Beispiel Werbung.  Verschiedene Werbenetzwerke k√∂nnen Algorithmen f√ºr die Anzeigenschaltung optimieren.  Wenn Sie f√ºr Ihren Autoservice werben, k√∂nnen Sie eine Kampagne so einrichten, dass nur Personen mit einem alten Auto Informationen anzeigen, ausgenommen Besitzer neuer.  Sie k√∂nnen den Inhalt der Website dynamisch √§ndern, Sie k√∂nnen die Daten f√ºr die Bewertung verwenden - es gibt viele Anwendungen. <br><br>  Daten werden von vielen v√∂llig unterschiedlichen Orten erhalten.  Dies k√∂nnen direkte Pixeleinstellungen sein. Wenn der Kunde sein Publikum analysieren m√∂chte, platziert er das Pixel auf der Website, ein unsichtbares Bild, das von unserem Server heruntergeladen wird.  Unter dem Strich sehen wir den Besuch des Benutzers auf dieser Website: Sie k√∂nnen ihn speichern, mit der Analyse und dem Verst√§ndnis des Portr√§ts des Benutzers beginnen. Alle diese Informationen stehen unserem Kunden zur Verf√ºgung. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad9/ebf/849/ad9ebf84913e17fb9e84a947b256a810.png"><br>  Daten k√∂nnen von verschiedenen Partnern abgerufen werden, die viele Daten sehen und diese auf verschiedene Weise monetarisieren m√∂chten.  Partner k√∂nnen Daten sowohl in Echtzeit bereitstellen als auch regelm√§√üig in Form von Dateien hochladen. <br><br>  Hauptanforderungen: <br><br><ul><li>  Horizontale Skalierbarkeit; </li><li>  Einsch√§tzung des Publikumsvolumens; </li><li>  Bequemlichkeit der √úberwachung und Entwicklung; </li><li>  Gute Reaktionsgeschwindigkeit auf Ereignisse. </li></ul><br>  Eine der Hauptanforderungen des Systems ist die horizontale Skalierbarkeit.  Es gibt einen solchen Moment, in dem Sie bei der Entwicklung eines Portals oder Online-Shops die Anzahl Ihrer Benutzer sch√§tzen k√∂nnen (wie es wachsen wird, wie es sich √§ndern wird) und ungef√§hr verstehen k√∂nnen, wie viel Ressourcen ben√∂tigt werden und wie das Gesch√§ft im Laufe der Zeit leben und sich entwickeln wird. <br><br>  Wenn Sie eine Plattform entwickeln, die DMP √§hnlich ist, m√ºssen Sie darauf vorbereitet sein, dass jede gro√üe Site - die bedingte Amazon - Ihre Pixel darin platzieren kann, und Sie m√ºssen mit dem Verkehr dieser gesamten Site arbeiten, w√§hrend Sie nicht fallen sollten, und den Indikatoren Systeme sollten sich davon irgendwie nicht √§ndern. <br><br>  Es ist auch sehr wichtig, das Volumen eines bestimmten Publikums zu verstehen, damit ein potenzieller Werbetreibender oder eine andere Person einen Medienplan ausarbeiten kann.  Zum Beispiel kommt eine Person zu Ihnen und fragt Sie, wie viele schwangere Frauen aus Nowosibirsk nach einer Hypothek suchen, um zu beurteilen, ob es sinnvoll ist, sie gezielt anzusprechen oder nicht. <br><br>  Unter dem Gesichtspunkt der Entwicklung m√ºssen Sie in der Lage sein, alles, was in Ihrem System geschieht, k√ºhl zu √ºberwachen, einen Teil des tats√§chlichen Datenverkehrs zu debuggen und so weiter. <br><br>  Eine der wichtigsten Systemanforderungen ist eine gute Reaktionsgeschwindigkeit auf Ereignisse.  Je schneller die Systeme auf Ereignisse reagieren, desto besser ist dies offensichtlich.  Wenn Sie nach Theaterkarten suchen, dann sehen Sie nach einem Tag, zwei Tagen oder sogar einer Stunde ein Rabattangebot - dies kann irrelevant sein, da Sie bereits Tickets kaufen oder zu einer Auff√ºhrung gehen k√∂nnten.  Wenn Sie nach einem Bohrer suchen - Sie suchen danach, finden, kaufen, h√§ngen ein Regal auf und nach ein paar Tagen beginnt das Bombardement: ‚ÄûKaufen Sie einen Bohrer!‚Äú. <br><br><h3>  Wie zuvor </h3><br>  Der gesamte Artikel befasst sich mit dem Recycling von Architektur.  Ich m√∂chte Ihnen sagen, was unser Ausgangspunkt war, wie alles vor den √Ñnderungen funktioniert hat. <br><br>  Alle Daten, die wir hatten, ob es sich um einen direkten Datenstrom oder um Protokolle handelte, wurden in einem HDFS-verteilten Dateispeicher gespeichert.  Dann gab es einen bestimmten Prozess, der regelm√§√üig gestartet wurde, alle unverarbeiteten Dateien aus HDFS nahm und sie in Datenanreicherungsanforderungen in HBase konvertierte (‚ÄûPUT-Anforderungen‚Äú). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c6/902/3eb/3c69023eb0fc851d8acc327a7b57fb22.png"><br><br><h3>  Wie speichern wir Daten in HBase? </h3><br>  Dies ist eine spaltenweise Zeitreihendatenbank.  Sie hat das Konzept eines Zeilenschl√ºssels - dies ist der Schl√ºssel, unter dem Sie Ihre Daten speichern.  Wir verwenden die Benutzer-ID als Schl√ºssel, die Benutzer-ID, die wir generieren, wenn wir den Benutzer zum ersten Mal sehen.  In jedem Schl√ºssel sind die Daten in Spaltenfamilien unterteilt - Entit√§ten, auf deren Ebene Sie die Metainformationen Ihrer Daten verwalten k√∂nnen.  Sie k√∂nnen beispielsweise tausend Versionen von Datens√§tzen f√ºr ‚ÄûDaten‚Äú der Spaltenfamilie speichern und diese zwei Monate lang speichern, und f√ºr die ‚ÄûRohdaten‚Äú der Spaltenfamilie - optional ein Jahr. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/89f/fb5/46e/89ffb546efcad40cd08d140df54ac6a4.png"><br>  Innerhalb der Spaltenfamilie gibt es viele Spaltenqualifizierer (im Folgenden Spalte).  Wir verwenden verschiedene Benutzerattribute als Spalte.  Es k√∂nnte die URL sein, zu der er gegangen ist, IP-Adresse, Suchanfrage.  Und am wichtigsten ist, dass in jeder Spalte viele Informationen gespeichert sind.  Innerhalb der Spalten-URL kann angegeben werden, dass der Benutzer zu smartdataconf.ru und dann zu einigen anderen Websites gegangen ist.  Als Version wird der Zeitstempel verwendet. Sie sehen einen geordneten Verlauf der Benutzerbesuche.  In unserem Fall k√∂nnen wir feststellen, dass der Benutzer mit dem Schl√ºsselwort "Konferenz" auf die smartdataconf-Website gelangt ist, da er denselben Zeitstempel hat. <br><br><h3>  Arbeite mit HBase </h3><br>  Es gibt verschiedene M√∂glichkeiten, mit HBase zu arbeiten.  Dies k√∂nnen PUT-Anforderungen (Anforderung zur Daten√§nderung), GET-Anforderung ("Geben Sie mir alle Daten zum Benutzer Vasya" usw.) sein.  Sie k√∂nnen SCAN-Anforderungen ausf√ºhren - sequentielles Multithread-Scannen aller Daten in HBase.  Wir haben dies fr√ºher zum Markieren in Zielgruppensegmenten verwendet. <br><br>  Es gab eine Aufgabe namens Analytics Engine, die einmal am Tag ausgef√ºhrt und HBase in mehreren Threads gescannt wurde.  F√ºr jeden Benutzer hat sie die gesamte Geschichte aus HBase entfernt und eine Reihe von Analyseskripten durchlaufen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fba/b4c/674/fbab4c674fabf2f07e0dc8553e8b6cfc.png"><br>  Was ist ein Analyseskript?  Dies ist eine Art Black Box (Java-Klasse), die alle Benutzerdaten als Eingabe empf√§ngt und eine Reihe von Segmenten angibt, die sie als Ausgabe als geeignet erachtet.  Wir geben alles an das Skript, das wir sehen - IP, Besuche, UserAgent usw., und in der Ausgabe geben die Skripte Folgendes aus: ‚ÄûDies ist eine Frau, liebt Katzen, mag keine Hunde‚Äú. <br><br>  Diese Daten wurden an Partner weitergegeben, Statistiken wurden ber√ºcksichtigt.  F√ºr uns war es wichtig zu verstehen, wie viele Frauen im Allgemeinen sind, wie viele M√§nner, wie viele Menschen Katzen lieben, wie viele ein Auto haben oder nicht und so weiter. <br><br>  Wir haben Statistiken in MongoDB gespeichert und geschrieben, indem wir f√ºr jeden Tag einen bestimmten Segmentz√§hler erh√∂ht haben.  Wir hatten eine grafische Darstellung des Volumens jedes Segments f√ºr jeden Tag. <br><br>  Dieses System war gut f√ºr seine Zeit.  Es erlaubte, horizontal zu skalieren, zu wachsen, das Volumen des Publikums zu sch√§tzen, aber es hatte eine Reihe von Nachteilen. <br><br>  Es war nicht immer m√∂glich zu verstehen, was im System vor sich ging, um die Protokolle zu betrachten.  W√§hrend wir beim vorherigen Hoster waren, fiel die Aufgabe aus verschiedenen Gr√ºnden ziemlich oft.  Es gab einen Hadoop-Cluster mit mehr als 20 Servern, einmal am Tag st√ºrzte einer der Server stabil ab.  Dies f√ºhrte dazu, dass die Aufgabe teilweise fallen konnte und die Daten nicht berechnet wurden.  Es war notwendig, Zeit zu haben, um es neu zu starten, und da es mehrere Stunden funktionierte, gab es eine Reihe bestimmter Nuancen. <br><br>  Das Grundlegendste, was die vorhandene Architektur nicht erf√ºllte, war, dass die Reaktionszeit auf das Ereignis zu lang war.  Es gibt sogar eine Geschichte zu diesem Thema.  Es gab ein Unternehmen, das der Bev√∂lkerung in den Regionen Mikrokredite gew√§hrte, und wir haben mit ihnen zusammengearbeitet.  Ihr Kunde kommt auf die Website, f√ºllt einen Antrag auf Mikrokredit aus, das Unternehmen muss innerhalb von 15 Minuten eine Antwort geben: Sind sie bereit, einen Kredit zu vergeben oder nicht?  Wenn Sie bereit sind, haben sie sofort Geld auf die Karte √ºberwiesen. <br><br>  Alles hat irgendwie gut funktioniert.  Der Kunde entschied sich zu √ºberpr√ºfen, wie es im Allgemeinen passiert: Er nahm einen separaten Laptop, installierte ein sauberes System, besuchte viele Seiten im Internet und ging zu seiner Website.  Sie sehen, dass es eine Anfrage gibt, und als Antwort sagen wir, dass es noch keine Daten gibt.  Der Kunde fragt: "Warum gibt es keine Daten?" <br><br>  Wir erkl√§ren: Es gibt eine gewisse Verz√∂gerung, bevor der Benutzer eine Aktion ausf√ºhrt.  Daten werden an HBase gesendet, verarbeitet und erst dann erh√§lt der Client das Ergebnis.  Es scheint, dass nichts Schlimmes passieren wird, wenn der Benutzer die Werbung nicht gesehen hat - alles ist in Ordnung.  In dieser Situation erh√§lt der Benutzer aufgrund der Verz√∂gerung m√∂glicherweise kein Darlehen. <br><br>  Dies ist kein Einzelfall, und es musste auf ein Echtzeitsystem umgestellt werden.  Was wollen wir von ihr? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad8/103/d08/ad8103d08bb70410bcc51c8fdd99b3f5.png"><br>  Wir m√∂chten Daten in HBase schreiben, sobald wir sie sehen.  Wir haben einen Besuch gesehen, alles, was wir wissen, bereichert und an Storage gesendet.  Sobald sich die Daten im Speicher ge√§ndert haben, m√ºssen Sie sofort alle vorhandenen Analyseskripts ausf√ºhren.  Wir m√∂chten die Bequemlichkeit der √úberwachung und Entwicklung, die F√§higkeit, neue Skripte zu schreiben und sie in Teile des realen Datenverkehrs zu debuggen.  Wir m√∂chten verstehen, was das System gerade besch√§ftigt. <br><br>  Das erste, mit dem wir begonnen haben, ist die L√∂sung des zweiten Problems: Segmentieren Sie den Benutzer unmittelbar nach dem √Ñndern der Daten √ºber ihn in HBase.  Anf√§nglich hatten wir Worker-Knoten (auf denen Kartenreduzierungsaufgaben gestartet wurden) am selben Ort wie HBase.  In einigen F√§llen war es sehr gut - die Berechnungen werden neben den Daten durchgef√ºhrt, Aufgaben funktionieren recht schnell, wenig Verkehr geht durch das Netzwerk.  Es ist klar, dass die Aufgabe einige Ressourcen verbraucht, da sie komplexe Analyseskripte ausf√ºhrt. <br><br>  Wenn wir in Echtzeit zur Arbeit gehen, √§ndert sich die Art der Belastung von HBase.  Wir gehen zu zuf√§lligen statt zu sequentiellen Messwerten √ºber.  Es ist wichtig, dass die Belastung von HBase erwartet wird. Wir k√∂nnen nicht zulassen, dass jemand die Aufgabe auf dem Hadoop-Cluster ausf√ºhrt und die HBase-Leistung beeintr√§chtigt. <br><br>  Als erstes haben wir HBase auf separate Server verschoben.  Au√üerdem wurden BlockCache und BloomFilter optimiert.  Dann haben wir gute Arbeit geleistet, um Daten in HBase zu speichern.  Sie haben das System, √ºber das ich am Anfang gesprochen habe, ziemlich √ºberarbeitet und die Daten selbst geerntet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/191/f68/3c9/191f683c9cddf8d90f43cafc5c1163a3.png"><br>  Aus dem Offensichtlichen: Wir haben IP als Zeichenfolge gespeichert und sind in Zahlen lang geworden.  Einige Daten wurden klassifiziert, Vokabeln ausgef√ºhrt und so weiter.  Unter dem Strich konnten wir HBase deshalb etwa zweimal sch√ºtteln - von 10 TB auf 5 TB.  HBase hat einen √§hnlichen Mechanismus wie Trigger in einer regul√§ren Datenbank.  Dies ist ein Coprozessormechanismus.  Wir haben einen Coprozessor geschrieben, der beim Wechsel eines Benutzers zu HBase die Benutzer-ID an Kafka sendet. <br><br>  Die Benutzer-ID befindet sich in Kafka.  Weiterhin gibt es einen bestimmten Service "Segmentator".  Es liest den Strom von Benutzerkennungen und f√ºhrt auf ihnen dieselben Skripte wie zuvor aus und fordert Daten von HBase an.  Der Prozess wurde bei 10% des Datenverkehrs gestartet. Wir haben uns angesehen, wie er funktioniert.  Alles war ziemlich gut. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c1/589/928/8c15899287c8a623bb63df3f85ba84e6.png"><br>  Als n√§chstes begannen wir, die Last zu erh√∂hen und sahen eine Reihe von Problemen.  Das erste, was wir sahen, war, dass der Service funktioniert, segmentiert und dann von Kafka abf√§llt, eine Verbindung herstellt und wieder funktioniert.  Mehrere Dienste - sie helfen sich gegenseitig.  Dann f√§llt der n√§chste ab, ein anderer und so weiter im Kreis.  Gleichzeitig wird die Aufstellung der Benutzer f√ºr die Segmentierung fast nicht geharkt. <br><br>  Dies lag an der Besonderheit des Herzschlagmechanismus in Kafka, damals war es noch Version 0.8.  Herzschlag ist, wenn die Verbraucher dem Broker mitteilen, ob sie am Leben sind oder nicht, in unserem Fall berichtet der Segmentierer.  Folgendes ist passiert: Wir haben ein ziemlich gro√ües Datenpaket erhalten und zur Verarbeitung gesendet.  F√ºr eine Weile funktionierte es, w√§hrend es funktionierte - es wurde kein Herzschlag gesendet.  Makler glaubten, dass der Verbraucher tot war, und schalteten ihn aus. <br><br>  Der Verbraucher arbeitete bis zum Ende, verschwendete wertvolle CPUs und versuchte zu sagen, dass das Datenpaket ausgearbeitet wurde und das n√§chste genommen werden konnte, aber er wurde abgelehnt, weil der andere wegnahm, womit er arbeitete.  Wir haben es behoben, indem wir unseren Hintergrund-Heatbeat gemacht haben. Dann kam die Wahrheit zu einer neueren Version von Kafka, bei der wir dieses Problem behoben haben. <br><br>  Dann stellte sich die Frage: Auf welcher Hardware sollten unsere Segmentatoren installiert werden?  Die Segmentierung ist ein ressourcenintensiver Prozess (CPU-gebunden).  Es ist wichtig, dass der Dienst nicht nur viel CPU verbraucht, sondern auch das Netzwerk l√§dt.  Jetzt erreicht der Verkehr 5 Gbit / s.  Die Frage war: Wo sollen die Dienste auf vielen kleinen oder kleinen Servern abgelegt werden? <br><br>  Zu diesem Zeitpunkt sind wir bereits auf Bare Metal zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">servers.com gewechselt</a> .  Wir haben mit den Jungs von den Servern gesprochen, sie haben uns geholfen und es erm√∂glicht, die Arbeit unserer L√∂sung sowohl auf einer kleinen Anzahl teurer Server als auch auf vielen kosteng√ºnstigen Servern mit leistungsstarken CPUs zu testen.  Wir haben die entsprechende Option ausgew√§hlt und die St√ºckkosten f√ºr die Verarbeitung eines Ereignisses pro Sekunde berechnet.  √úbrigens fiel die Wahl auf ausreichend leistungsf√§higes und gleichzeitig √§u√üerst erschwingliches Dell R230, sie haben es auf den Markt gebracht - alles hat funktioniert. <br><br>  Es ist wichtig, dass, nachdem der Segmentierer den Benutzer in Segmente markiert hat, das Ergebnis seiner Analyse in einem bestimmten Thema Segmentierungsergebnis auf Kafka zur√ºckgreift. <br><br>  Dar√ºber hinaus k√∂nnen wir unabh√§ngig voneinander verschiedene Verbraucher mit diesen Daten verbinden, die sich nicht gegenseitig st√∂ren.  Auf diese Weise k√∂nnen wir jedem Partner unabh√§ngig Daten geben, sei es einigen externen Partnern, internen DSP, Google oder Statistiken. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1e7/051/526/1e705152621996ed538a6a3910e8db47.png"><br>  Bei Statistiken gibt es auch einen interessanten Punkt: Fr√ºher konnten wir den Wert von Z√§hlern in MongoDB erh√∂hen, wie viele Benutzer sich an einem bestimmten Tag in einem bestimmten Segment befanden.  Dies ist jetzt nicht m√∂glich, da wir jetzt jeden Benutzer analysieren, nachdem er ein Ereignis abgeschlossen hat, d. H.  mehrmals am Tag. <br><br>  Daher mussten wir das Problem l√∂sen, die eindeutige Anzahl von Benutzern im Stream zu z√§hlen.  Zu diesem Zweck haben wir die HyperLogLog-Datenstruktur und ihre Implementierung in Redis verwendet.  Die Datenstruktur ist probabilistisch.  Dies bedeutet, dass Sie dort Benutzerkennungen hinzuf√ºgen k√∂nnen. Die Kennungen selbst werden nicht gespeichert, sodass Sie Millionen von eindeutigen Kennungen in HyperLogLog √§u√üerst kompakt speichern k√∂nnen. Dies dauert bis zu 12 Kilobyte pro Schl√ºssel. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2a6/572/614/2a6572614da5ccffd52271292e646e9d.png"><br><br>  Sie k√∂nnen die Bezeichner nicht selbst erhalten, aber Sie k√∂nnen die Gr√∂√üe dieses Satzes herausfinden.  Da die Datenstruktur probabilistisch ist, liegt ein Fehler vor.  Wenn Sie beispielsweise ein Segment haben, das Katzen mag und f√ºr einen bestimmten Tag eine Anfrage nach der Gr√∂√üe dieses Segments stellt, erhalten Sie 99,2 Millionen und dies bedeutet etwa ‚Äûvon 99 Millionen auf 100 Millionen‚Äú. <br><br>  Auch in HyperLogLog k√∂nnen Sie die Gr√∂√üe der Vereinigung mehrerer S√§tze ermitteln.  Angenommen, Sie haben zwei Segmente: "liebt Robben" und "liebt Hunde".  Sagen wir die ersten 100 Millionen, die zweiten 1 Million. Man kann fragen: "Wie viele Tiere m√∂gen sie?"  und erhalten Sie die Antwort "ungef√§hr 101 Millionen" mit einem Fehler von 1%.  Es w√§re interessant zu berechnen, wie sehr Katzen und Hunde gleichzeitig geliebt werden, aber dies zu tun ist ziemlich schwierig. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/380/74d/500/38074d5004513c86015c8d2770047f56.png"><br>  Einerseits k√∂nnen Sie die Gr√∂√üe jedes Satzes ermitteln, die Gr√∂√üe der Vereinigung ermitteln, addieren, voneinander subtrahieren und den Schnittpunkt ermitteln.  Aufgrund der Tatsache, dass die Gr√∂√üe des Fehlers gr√∂√üer sein kann als die Gr√∂√üe des endg√ºltigen Schnittpunkts, kann das Endergebnis die Form "von -50 bis 50.000" haben. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/08d/3ba/520/08d3ba520f5c91efd84822d63f299c83.png"><br>  Wir haben viel daran gearbeitet, die Leistung beim Schreiben von Daten in Redis zu steigern.  Anfangs erreichten wir 200.000 Operationen pro Sekunde.  Wenn jedoch jeder Benutzer mehr als 50 Segmente hat - Informationen √ºber jeden Benutzer aufzeichnen - 50 Vorg√§nge.  Es stellt sich heraus, dass wir nur eine begrenzte Bandbreite haben und in diesem Beispiel keine Informationen √ºber mehr als 4.000 Benutzer pro Sekunde schreiben k√∂nnen. Dies ist um ein Vielfaches weniger als erforderlich. <br><br>  Wir haben √ºber Lua eine separate ‚Äûgespeicherte Prozedur‚Äú in Redis erstellt, dort geladen und eine Zeichenfolge mit der gesamten Liste der Segmente eines Benutzers √ºbergeben.  Die darin enthaltene Prozedur schneidet die √ºbergebene Zeichenfolge in die erforderlichen HyperLogLog-Updates und speichert die Daten, sodass wir ungef√§hr 1 Million Updates pro Sekunde erreicht haben. <br><br>  Ein bisschen Hardcore: Redis ist Single-Threaded, Sie k√∂nnen es an einen Prozessorkern und eine Netzwerkkarte an einen anderen anheften und eine weitere Leistung von 15% erzielen, wodurch Kontextwechsel eingespart werden.  Dar√ºber hinaus ist der wichtige Punkt, dass Sie die Datenstruktur nicht einfach gruppieren k√∂nnen, da die Operationen zum Erhalten der Leistung der Gruppenvereinigungen nicht gruppiert werden <br><br><h3>  Kafka ist ein gro√üartiges Werkzeug </h3><br>  Sie sehen, dass Kafka unser Haupttransportinstrument im System ist. <br>  Es hat die Essenz von "Thema".  Hier schreiben Sie die Daten, aber im Wesentlichen die Warteschlange.  In unserem Fall gibt es mehrere Warteschlangen.  Eine davon sind Kennungen von Benutzern, die segmentiert werden m√ºssen.  Das zweite sind Segmentierungsergebnisse. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f35/eb3/8c2/f35eb38c205fec791ea2f42d41a8c875.png"><br>  Ein Thema ist eine Reihe von Partitionen.  Es ist in einige Teile unterteilt.  Jede Partition ist eine Datei auf der Festplatte.  Wenn Ihre Produzenten Daten schreiben, schreiben sie Textst√ºcke an das Ende der Partition.  Wenn Ihre Kunden die Daten lesen, lesen sie einfach von diesen Partitionen. <br><br>  Wichtig ist, dass Sie mehrere Verbrauchergruppen unabh√§ngig voneinander verbinden k√∂nnen. Diese verbrauchen Daten, ohne sich gegenseitig zu st√∂ren.  Dies wird durch den Namen der Verbrauchergruppe bestimmt und wie folgt erreicht. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/157/5f7/23d/1575f723d77042fd058b9c30bc050247.png"><br>  Es gibt so etwas wie einen Versatz, die Position, an der sich die Verbrauchergruppe jetzt auf jeder Partition befindet.  Beispielsweise verwendet Gruppe A die siebte Nachricht von Partition1 und die f√ºnfte von Partition2.  Gruppe B, unabh√§ngig von A, hat einen anderen Versatz. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f8a/10f/1a0/f8a10f1a04b8614f6b9a437142b0db7b.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie k√∂nnen Ihre Verbrauchergruppe horizontal skalieren, einen weiteren Prozess oder Server hinzuf√ºgen. Dies geschieht durch eine Neuzuweisung von Partitionen (Kafka Broker weist jedem Verbraucher eine Liste von Partitionen f√ºr den Verbrauch zu). Dies bedeutet, dass die erste Verbrauchergruppe nur Partition 1 und die zweite nur Partition 2 verbraucht. Wenn einige der Verbraucher sterben (z. B. kommt kein Hearthbeat), erfolgt eine neue Neuzuweisung Jeder Verbraucher erh√§lt eine aktuelle Partitionsliste zur Verarbeitung.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/56b/40b/bde/56b40bbde5b1890d35f67a481c4a6462.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist sehr praktisch. Zun√§chst k√∂nnen Sie den Offset f√ºr jede Verbrauchergruppe bearbeiten. Stellen Sie sich vor, es gibt einen Partner, an den Sie Daten aus diesem Thema mit den Ergebnissen der Segmentierung √ºbertragen. Er schreibt, dass er versehentlich den letzten Tag der Daten infolge eines Fehlers verloren hat. Und Sie, f√ºr die Verbrauchergruppe dieses Kunden, rollen einfach einen Tag zur√ºck und gie√üen den gesamten Datentag darauf. Wir k√∂nnen auch eine eigene Verbrauchergruppe haben, eine Verbindung zum Produktionsverkehr herstellen, beobachten, was passiert, und reale Daten debuggen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben also erreicht, dass wir begonnen haben, Benutzer beim Wechsel zu segmentieren, neue Verbraucher unabh√§ngig voneinander zu verbinden, Statistiken zu schreiben und sie zu beobachten. Jetzt m√ºssen Sie die Daten sofort nach Eingang bei uns in HBase schreiben lassen.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c4e/eec/d6c/c4eeecd6ce987e902fee723a089ab780.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie wir es gemacht haben. Fr√ºher wurden Batch-Daten geladen. Es gab einen Batch Loader, der Benutzeraktivit√§tsprotokolldateien verarbeitete: Wenn ein Benutzer 10 Besuche machte, kam der Batch f√ºr 10 Ereignisse und wurde in einem Vorgang in HBase aufgezeichnet. Es gab nur ein Ereignis pro Segmentierung. Jetzt wollen wir jedes einzelne Ereignis in den Speicher schreiben. Wir werden den Schreib- und den Lesestream stark erh√∂hen. Die Anzahl der Ereignisse pro Segmentierung wird ebenfalls erh√∂ht.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/79a/849/910/79a8499101ac2cb58ccf272abb668f6f.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Als erstes haben wir HBase auf die SSD portiert. Standardm√§√üig wird dies nicht besonders durchgef√ºhrt. Dies wurde mit HDFS durchgef√ºhrt. Sie k√∂nnen sagen, dass sich ein bestimmtes Verzeichnis in HDFS auf einer solchen Gruppe von Festplatten befinden muss. Es gab ein cooles Problem mit der Tatsache, dass, als wir HBase zur SSD brachten und sie stoppten, alle Schnappsch√ºsse dort ankamen und unsere SSDs ziemlich schnell endeten. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies ist auch gel√∂st. Wir haben begonnen, regelm√§√üig Snapshots in eine Datei zu exportieren, in ein anderes HDFS-Verzeichnis zu schreiben und alle Metainformationen zu Snapshots zu l√∂schen. Wenn Sie wiederherstellen m√ºssen - nehmen Sie die gespeicherte Datei, importieren und wiederherstellen. Diese Operation ist zum Gl√ºck sehr selten.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auch auf der SSD haben sie Write Ahead Log, Twisted MemStore, herausgenommen und den Cache-Block beim Schreiben aktiviert. Sie k√∂nnen sie beim Aufzeichnen von Daten sofort in den Blockcache stellen. Das ist sehr praktisch, weil In unserem Fall ist es sehr wahrscheinlich, dass die Daten sofort gelesen werden, wenn wir sie aufgezeichnet haben. Dies gab auch einige Vorteile. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Als n√§chstes haben wir alle unsere Datenquellen auf das Schreiben von Daten in Kafka umgestellt. Bereits von Kafka aus haben wir Daten in HDFS aufgezeichnet, um die Abw√§rtskompatibilit√§t aufrechtzuerhalten, einschlie√ülich der M√∂glichkeit, dass unsere Analysten mit Daten arbeiten, MapReduce-Aufgaben ausf√ºhren und deren Ergebnisse analysieren k√∂nnen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben eine separate Verbrauchergruppe verbunden, die Daten in HBase schreibt. Dies ist in der Tat ein Wrapper, der aus Kafka liest und die PUTs in HBase bildet.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d53/267/0b3/d532670b344a70dadf97c5c4674b1596.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben zwei Schaltkreise parallel gestartet, um die Abw√§rtskompatibilit√§t nicht zu beeintr√§chtigen und die Systemleistung nicht zu beeintr√§chtigen. Ein neues System wurde nur bei einem bestimmten Prozentsatz des Verkehrs eingef√ºhrt. Mit 10% war alles ziemlich cool. Bei gr√∂√üerer Belastung konnten die Segmentierer den Segmentierungsfluss jedoch nicht bew√§ltigen. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d20/3fa/78c/d203fa78c3d0b80ee7c7a5dce34f558b.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir sammeln die Metrik "Wie viele Nachrichten lagen in Kafka, bevor sie von dort gelesen wurden?". Dies ist eine gute Metrik. Anfangs haben wir die Metrik "Wie viele Rohnachrichten sind jetzt" gesammelt, aber sie sagt nichts Besonderes aus. Sie sehen aus: "Ich habe eine Million Rohnachrichten", na und? Um diese Million zu interpretieren, m√ºssen Sie wissen, wie schnell der Segmentator (Verbraucher) arbeitet, was nicht immer klar ist.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit dieser Metrik sehen Sie sofort, dass die Daten in die Warteschlange geschrieben und daraus entnommen werden, und Sie sehen, wie viel sie voraussichtlich verarbeiten werden. </font><font style="vertical-align: inherit;">Wir haben festgestellt, dass wir keine Zeit zum Segmentieren hatten und die Nachricht einige Stunden vor dem Lesen in der Warteschlange stand. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie k√∂nnten einfach Kapazit√§t hinzuf√ºgen, aber es w√§re einfach zu </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">teuer</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Deshalb haben wir versucht zu optimieren.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Selbstskalierung </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben HBase. Der Benutzer √§ndert sich, seine Kennung fliegt in Kafka. Das Thema ist in Partitionen unterteilt, die Zielpartition wird anhand der Benutzer-ID ausgew√§hlt. Dies bedeutet, dass wenn Sie den Benutzer "Vasya" sehen - er geht zu Partition 1. Wenn Sie "Petya" sehen - zu Partition 2. Dies ist praktisch - Sie k√∂nnen erreichen, dass Sie einen Verbraucher auf einer Instanz Ihres Dienstes sehen, und den zweiten - auf der anderen Seite. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/299/573/aef/299573aefcae8b909623e246d4a2cf80.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir begannen zu beobachten, was los war. Ein typisches Benutzerverhalten im Internet besteht darin, auf eine Website zu gehen und mehrere Hintergrundregisterkarten zu √∂ffnen. Die zweite M√∂glichkeit besteht darin, zur Website zu gehen und mit wenigen Klicks zur Zielseite zu gelangen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir sehen uns die Segmentierungswarteschlange an und sehen Folgendes: Benutzer A hat die Seite besucht. 5 weitere Ereignisse kommen von diesem Benutzer - jedes bedeutet ein √ñffnen der Seite. Wir verarbeiten jedes Ereignis vom Benutzer. Tats√§chlich enthalten die Daten in HBase jedoch alle 5 Besuche. Wir verarbeiten alle 5 Besuche zum ersten Mal, zum zweiten Mal usw. - wir verschwenden CPU-Ressourcen. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6df/eba/fbf/6dfebafbf435cfb43e5b71cc7d2016fd.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aus diesem Grund haben wir begonnen, auf jedem Segmentierer einen bestimmten lokalen Cache mit dem Datum zu speichern, an dem wir diesen Benutzer zuletzt analysiert haben. Das hei√üt, wir haben es verarbeitet, seine Benutzer-ID und seinen Zeitstempel in den Cache geschrieben. Jede Kafka-Nachricht hat auch einen Zeitstempel - wir vergleichen ihn einfach: Wenn der Zeitstempel in der Warteschlange kleiner als das Datum der letzten Segmentierung ist - haben wir den Benutzer bereits auf diese Daten analysiert, und Sie k√∂nnen dieses Ereignis einfach √ºberspringen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Benutzerereignisse (rotes A) k√∂nnen unterschiedlich sein und sind nicht in Ordnung. Der Benutzer kann mehrere Hintergrundregisterkarten √∂ffnen, mehrere Links hintereinander √∂ffnen. M√∂glicherweise hat die Site mehrere unserer Partner gleichzeitig, von denen jeder diese Daten sendet. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unser Pixel kann den Besuch des Benutzers und dann eine andere Aktion sehen - wir werden seinen Helm an uns selbst senden. Wenn f√ºnf Ereignisse eintreffen, verarbeiten wir das erste rote A. Wenn das Ereignis eingetroffen ist, befindet es sich bereits in HBase. Wir sehen Ereignisse, durchlaufen eine Reihe von Skripten. Wir sehen das folgende Ereignis und dort alle die gleichen Ereignisse, weil sie bereits aufgezeichnet sind. Wir f√ºhren es erneut aus, speichern den Cache mit dem Datum und vergleichen ihn mit dem Zeitstempel des Ereignisses.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f5/a41/48b/3f5a4148b5b8f14067816cda7b7bfade.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dank dessen erhielt das System die Eigenschaft der Selbstskalierbarkeit. Die y-Achse ist der Prozentsatz dessen, was wir mit Benutzer-IDs tun, wenn sie zu uns kommen. Gr√ºn - die Arbeit, die wir ausgef√ºhrt haben, hat das Segmentierungsskript gestartet. Gelb - das haben wir nicht gemacht, weil Bereits genau diese Daten segmentiert. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/902/e54/03d/902e5403d2dc07b5f2a4ceaf57ea3e47.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist ersichtlich, dass nachts Ressourcen vorhanden sind, weniger Daten flie√üen und Sie jedes zweite Ereignis segmentieren k√∂nnen. Ein kleinerer Ressourcentag, und wir segmentieren nur 20% der Ereignisse. Ein Sprung am Ende des Tages - der Partner hat Datendateien hochgeladen, die wir zuvor noch nicht gesehen hatten, und sie mussten ‚Äûehrlich‚Äú segmentiert werden.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das System selbst passt sich dem Lastwachstum an. Wenn wir einen sehr gro√üen Partner haben, verarbeiten wir dieselben Daten, jedoch etwas seltener. In diesem Fall verschlechtern sich die Eigenschaften des Systems am Abend, die Segmentierung wird nicht um 2-3 Sekunden, sondern um eine Minute verz√∂gert. F√ºgen Sie am Morgen die Server hinzu und kehren Sie zu den gew√ºnschten Ergebnissen zur√ºck. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So haben wir ca. 5 mal auf den Servern gespart. Jetzt arbeiten wir auf 10 Servern, und so w√ºrde es 50-60 dauern.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das kleine blaue Ding oben sind die Bots. Dies ist der schwierigste Teil der Segmentierung. Sie haben eine gro√üe Anzahl von Besuchen, sie erzeugen eine sehr gro√üe Last auf dem Eisen. Wir sehen jeden Bot auf einem separaten Server. Wir k√∂nnen darauf einen lokalen Cache mit einer schwarzen Liste von Bots sammeln. Einf√ºhrung eines einfachen Betrugs: Wenn ein Benutzer f√ºr eine bestimmte Zeit zu viele Besuche macht, stimmt etwas nicht mit ihm, wir f√ºgen ihn f√ºr eine Weile der schwarzen Liste hinzu. Dies ist ein kleiner blauer Streifen, ungef√§hr 5%. Sie gaben uns weitere 30% Einsparungen bei der CPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Damit haben wir in jeder Phase das erreicht, was wir f√ºr die gesamte Pipeline der Datenverarbeitung sehen. Wir sehen Metriken, wie viel die Nachricht in Kafka war. Abends tr√ºbte sich irgendwo etwas, die Bearbeitungszeit erh√∂hte sich auf eine Minute, dann wurde es freigegeben und wieder normalisiert.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/58e/fed/411/58efed411c7c5a4348b9280b3c963c16.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir k√∂nnen √ºberwachen, wie sich unsere Aktionen mit dem System auf den Durchsatz auswirken. Wir k√∂nnen sehen, wie viel das Skript ausgef√ºhrt wird, wo es optimiert werden muss und wie viel gespeichert werden kann. </font><font style="vertical-align: inherit;">Wir k√∂nnen die Gr√∂√üe der Segmente sehen, die Dynamik der Gr√∂√üe der Segmente, ihre Assoziation und Schnittmenge bewerten. </font><font style="vertical-align: inherit;">Dies kann f√ºr mehr oder weniger gleiche Segmentgr√∂√üen erfolgen.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Was m√∂chten Sie verfeinern? </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben einen Hadoop-Cluster mit einigen Computerressourcen. Er ist besch√§ftigt - Analysten arbeiten tags√ºber daran, aber nachts ist er praktisch frei. Im Allgemeinen k√∂nnen wir den Segmentierer als separaten Prozess in unserem Cluster containerisieren und ausf√ºhren. Wir m√∂chten Statistiken genauer speichern, um das Volumen der Kreuzung genauer berechnen zu k√∂nnen. Wir brauchen auch eine Optimierung der CPU. Dies wirkt sich direkt auf die Kosten der Entscheidung aus. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zusammenfassend: Kafka ist gut, aber wie bei jeder anderen Technologie m√ºssen Sie verstehen, wie es im Inneren funktioniert und was damit passiert. Beispielsweise funktioniert die Garantie f√ºr die Nachrichtenpriorit√§t nur innerhalb der Partition. Wenn Sie eine Nachricht senden, die an verschiedene Partitionen gesendet wird, ist nicht klar, in welcher Reihenfolge diese verarbeitet werden.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reale Daten sind sehr wichtig. </font><font style="vertical-align: inherit;">Wenn wir nicht auf echten Datenverkehr getestet h√§tten, h√§tten wir h√∂chstwahrscheinlich keine Probleme mit Bots und Benutzersitzungen gesehen. </font><font style="vertical-align: inherit;">W√ºrde etwas im luftleeren Raum entwickeln, rennen und sich hinlegen. </font><font style="vertical-align: inherit;">Es ist wichtig zu √ºberwachen, was Sie f√ºr notwendig halten, um zu √ºberwachen, und nicht zu √ºberwachen, was Sie nicht denken.</font></font><br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minute der Werbung. </font><font style="vertical-align: inherit;">Wenn Ihnen dieser Bericht von der SmartData-Konferenz gefallen hat, beachten Sie bitte, dass </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SmartData 2018</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> am 15. Oktober in St. Petersburg stattfindet, einer </font><font style="vertical-align: inherit;">Konferenz f√ºr diejenigen, die in die Welt des maschinellen Lernens, der Analyse und der Datenverarbeitung eintauchen. </font><font style="vertical-align: inherit;">Das Programm wird viele interessante Dinge enthalten, die Seite hat bereits ihre ersten Redner und Berichte.</font></font></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421125/">https://habr.com/ru/post/de421125/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421113/index.html">Einf√ºhrung in DJI Mavic 2 Pro / Zoom</a></li>
<li><a href="../de421115/index.html">Kontext in einer Android-Anwendung</a></li>
<li><a href="../de421119/index.html">SmartTV-Entwicklung f√ºr Unterwasserschwader</a></li>
<li><a href="../de421121/index.html">Video-Streaming √ºber einen Browser mit extrem geringer Latenz (und WebRTC!)</a></li>
<li><a href="../de421123/index.html">Zusammenfassung der IT-Veranstaltungen f√ºr September</a></li>
<li><a href="../de421127/index.html">Skillbox Friday Webinare: Design & Entwickler</a></li>
<li><a href="../de421129/index.html">So reduzieren Sie die Code√ºberpr√ºfung von zwei Wochen auf mehrere Stunden. Die Erfahrung des Yandex.Market-Teams</a></li>
<li><a href="../de421131/index.html">Kritische Sicherheitsanf√§lligkeit von 1Cloud-Servern</a></li>
<li><a href="../de421133/index.html">LINKa. Papiertastatur. Extra gro√üe Kn√∂pfe</a></li>
<li><a href="../de421135/index.html">Au / Ni / MgO: W√§rme√ºbertragung im Nanoma√üstab</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöí üë®üèº‚Äçüé§ üéóÔ∏è Le Deep Learning est d√©sormais en Java üïµÔ∏è üíº üí†</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vous n'aimez pas Java? Oui, vous ne savez pas comment le faire cuire! Mani Sarkar nous invite √† faire connaissance avec l'outil Valohai, qui vous perm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le Deep Learning est d√©sormais en Java</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/469405/">  Vous n'aimez pas Java?  Oui, vous ne savez pas comment le faire cuire!  Mani Sarkar nous invite √† faire connaissance avec l'outil Valohai, qui vous permet de mener des recherches de mod√®les en Java. <br><br><img src="https://habrastorage.org/webt/et/p-/se/etp-sezekre2qlznmvgdzlgds0a.png"><br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Avis de non-responsabilit√© du traducteur</b> <div class="spoiler_text">  J'esp√®re que ce n'est pas une publication publicitaire.  Je ne suis pas affili√© √† Valohai.  Je viens de traduire l'article auquel je renvoie le lien.  Si maladroitement traduit - coup de pied PM.  Si n√©cessaire, je peux supprimer des liens et mentionner d'autres ressources externes.  Merci pour votre compr√©hension. <br></div></div><br><h3>  Pr√©sentation </h3><br>  Il y a quelque temps, je suis tomb√© sur un service cloud appel√© Valohai, et j'√©tais satisfait de son interface utilisateur et de la simplicit√© de conception et de mise en page.  J'ai demand√© le service d'un des membres de Valohai et j'ai re√ßu une version de d√©monstration.  Avant cela, j'ai √©crit un simple pipeline utilisant GNU Parallel, JavaScript, Python et Bash - et un autre qui utilise uniquement GNU Parallel et Bash. <br><br>  J'ai √©galement pens√© √† utiliser des outils de gestion des t√¢ches / flux de travail pr√™ts √† l'emploi comme Jenkins X, Jenkins Pipeline, Concourse ou Airflow, mais pour diverses raisons, j'ai d√©cid√© de ne pas le faire. <br><br>  J'ai remarqu√© que de nombreux exemples et documentation Valohai sont bas√©s sur Python et R et leurs cadres et biblioth√®ques respectifs.  J'ai d√©cid√© de ne pas rater l'occasion et je veux corriger le manque d'exemples et de documentation. <br><br>  Valohai m'a pouss√© √† impl√©menter quelque chose en utilisant la c√©l√®bre biblioth√®que Java appel√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DL4J - Deep Learning for Java</a> . <br><br>  Ma premi√®re exp√©rience avec Valohai m'a fait bonne impression apr√®s avoir ressenti sa conception, sa mise en page et son flux de travail.  Les cr√©ateurs ont d√©j√† pris en compte divers aspects des workflows du d√©veloppeur et de l'infrastructure.  Dans notre monde, le processus de d√©veloppement des infrastructures est principalement contr√¥l√© par les √©quipes DevOps ou SysOps, et nous connaissons les nuances et les points douloureux qui y sont associ√©s. <br><br><h3>  De quoi avons-nous besoin et comment? </h3><br>  Dans tout projet d'apprentissage automatique, il y a deux composants importants (d'un point de vue de haut niveau) - un code qui fonctionnera avec le mod√®le et un code qui fonctionnera avec l'infrastructure, dans lequel tout le cycle de vie du projet sera ex√©cut√©. <br><br>  Bien s√ªr, il y aura des √©tapes et des composants n√©cessaires avant, pendant et apr√®s, mais pour simplifier, disons, nous avons besoin de code et d'infrastructure. <br><br><h4>  Code </h4><br>  Pour le code, j'ai choisi un exemple complexe utilisant DL4J, il s'agit d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet MNist</a> avec un ensemble de formation de 60 000 images et un ensemble de test de 10 000 images de chiffres manuscrits.  Cet ensemble de donn√©es est disponible via la biblioth√®que DL4J (tout comme Keras). <br><br>  Avant de commencer, il est recommand√© de consulter le code source que nous utiliserons.  La classe Java principale s'appelle <a href="">org.deeplearning4j.feedforward.mnist.MLPMnistSingleLayerRunner</a> . <br><br><h4>  L'infrastructure </h4><br>  Nous avons d√©cid√© d'essayer l'exemple Java en utilisant Valohai comme infrastructure pour mener des exp√©riences (formation et √©valuation de mod√®les).  Valohai reconna√Æt les r√©f√©rentiels git et s'y connecte directement, ce qui nous permet d'ex√©cuter notre code ind√©pendamment de la plate-forme ou du langage - nous verrons donc comment cela fonctionne.  Cela signifie √©galement que si vous utilisez GitOps ou Infrastructure-As-Code, tout fonctionnera √©galement pour vous. <br><br>  Pour ce faire, nous avons juste besoin d'un compte chez Valohai.  Apr√®s avoir cr√©√© un compte gratuit, nous avons acc√®s √† plusieurs instances de diff√©rentes configurations.  Pour ce que nous aimerions faire, Free-Tier est plus que suffisant. <br><br><h4>  Deep Learning pour Java et Valohai </h4><br>  Nous fournirons toutes les d√©pendances √† l'image Docker et l'utiliserons pour compiler notre application Java, former le mod√®le et l'√©valuer sur la plateforme Valohai √† l'aide d'un simple fichier <a href="">valohai.yaml</a> situ√© dans le dossier racine du r√©f√©rentiel du projet. <br><br><h4>  Deep Learning pour Java: DL4J </h4><br>  La partie la plus simple.  Nous n'avons pas √† faire grand-chose, il suffit de collecter le bocal et de charger l'ensemble de donn√©es dans le conteneur Docker.  Nous avons une image Docker pr√©-cr√©√©e qui contient toutes les d√©pendances n√©cessaires pour cr√©er une application Java.  Nous avons mis cette image dans le Docker Hub, et vous pouvez la trouver en recherchant dl4j-mnist-single-layer (nous utiliserons une balise sp√©ciale telle que d√©finie dans le fichier YAML).  Nous avons d√©cid√© d'utiliser GraalVM 19.1.1 comme environnement Java de g√©n√©ration et d'ex√©cution pour ce projet, et il est int√©gr√© √† l'image Docker. <br><br>  Lorsque le uber jar est appel√© √† partir de la ligne de commande, nous cr√©ons la classe MLPMnistSingleLayerRunner, qui nous indique l'action pr√©vue, en fonction des param√®tres pass√©s √†: <br><br><pre><code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ MLPMnistSingleLayerRunner mlpMnistRunner = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MLPMnistSingleLayerRunner(); JCommander.newBuilder() .addObject(mlpMnistRunner) .build() .parse(args); mlpMnistRunner.execute(); }</code> </pre> <br>  Les param√®tres pass√©s √† uber jar sont accept√©s par cette classe et trait√©s par la m√©thode execute (). <br><br>  Nous pouvons cr√©er un mod√®le √† l'aide du param√®tre --action train et √©valuer le mod√®le cr√©√© √† l'aide du param√®tre --action assess transmis √† l'application Java. <br><br>  Les principales parties de l'application Java qui effectue ce travail se trouvent dans les deux classes Java mentionn√©es dans les sections ci-dessous. <br><br><h3>  Formation mod√®le </h3><br>  Appeler <br><br><pre> <code class="plaintext hljs">./runMLPMnist.sh --action train --output-dir ${VH_OUTPUTS_DIR} or java -Djava.library.path="" \ -jar target/MLPMnist-1.0.0-bin.jar \ --action train --output-dir ${VH_OUTPUTS_DIR}</code> </pre><br>  Cette commande cr√©e un mod√®le nomm√© mlpmnist-single-layer.pb dans le dossier sp√©cifi√© par le param√®tre --output-dir pass√© au d√©but de l'ex√©cution.  Du point de vue de Valohai, il devrait √™tre plac√© dans $ {VH_OUTPUTS_DIR}, ce que nous faisons (voir le fichier <a href="">valohai.yaml</a> ). <br><br>  Pour le code source, consultez la classe <a href="">MLPMNistSingleLayerTrain.java</a> . <br><br><h3>  √âvaluation du mod√®le </h3><br>  Appeler <br><br><pre> <code class="plaintext hljs">./runMLPMnist.sh --action evaluate --input-dir ${VH_INPUTS_DIR}/model or java -Djava.library.path="" \ -jar target/MLPMnist-1.0.0-bin.jar \ --action evaluate --input-dir ${VH_INPUTS_DIR}/model</code> </pre><br>  Il est suppos√© que le mod√®le (cr√©√© pendant la phase de formation) avec le nom mlpmnist-single-layer.pb sera pr√©sent dans le dossier sp√©cifi√© dans le param√®tre --input-dir transmis lors de l'appel de l'application. <br><br>  Pour le code source, consultez la classe <a href="">MLPMNistSingleLayerEvaluate.java</a> . <br><br>  J'esp√®re que cette courte illustration clarifie le fonctionnement d'une application Java qui enseigne et √©value un mod√®le. <br><br>  C'est tout ce qui nous est demand√©, mais n'h√©sitez pas √† jouer avec le reste des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sources</a> (avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">README.md</a> et les scripts bash) et √† satisfaire votre curiosit√© et votre compr√©hension de la fa√ßon dont cela se fait! <br><br><h3>  Valohai </h3><br>  Valohai nous permet de lier librement notre runtime, notre code et notre jeu de donn√©es, comme vous pouvez le voir dans la structure de fichier YAML ci-dessous.  Ainsi, divers composants peuvent se d√©velopper ind√©pendamment les uns des autres.  Par cons√©quent, seuls les composants d'assemblage et d'ex√©cution sont emball√©s dans notre conteneur Docker. <br><br>  Au moment de l'ex√©cution, nous collectons le JAR Uber dans un conteneur Docker, le chargeons dans un stockage interne ou externe, puis utilisons l'autre √©tape d'ex√©cution pour charger le JAR Uber et le jeu de donn√©es √† partir du stockage (ou d'un autre endroit) pour commencer la formation.  Ainsi, les deux √©tapes d'ex√©cution sont d√©connect√©es;  par exemple, nous pouvons compiler un pot une fois et effectuer des centaines d'√©tapes de formation sur un seul pot.  √âtant donn√© que les environnements d'assemblage et d'ex√©cution n'ont pas √† changer si souvent, nous pouvons les mettre en cache et le code, les ensembles de donn√©es et les mod√®les peuvent √™tre accessibles dynamiquement lors de l'ex√©cution. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">valohai.yaml</a> <br>  L'int√©gration de notre projet Java √† l'infrastructure Valohai consiste principalement √† d√©terminer l'ordre des √©tapes d'ex√©cution dans le fichier valohai.yaml situ√© √† la racine de votre dossier de projet.  Notre valohai.yaml ressemble √† ceci: <br><br><pre> <code class="xml hljs">--- - step: name: Build-dl4j-mnist-single-layer-java-app image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - cd ${VH_REPOSITORY_DIR} - ./buildUberJar.sh - echo "~~~ Copying the build jar file into ${VH_OUTPUTS_DIR}" - cp target/MLPMnist-1.0.0-bin.jar ${VH_OUTPUTS_DIR}/MLPMnist-1.0.0.jar - ls -lash ${VH_OUTPUTS_DIR} environment: aws-eu-west-1-g2-2xlarge - step: name: Run-dl4j-mnist-single-layer-train-model image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - echo "~~~ Unpack the MNist dataset into ${HOME} folder" - tar xvzf ${VH_INPUTS_DIR}/dataset/mlp-mnist-dataset.tgz -C ${HOME} - cd ${VH_REPOSITORY_DIR} - echo "~~~ Copying the build jar file from ${VH_INPUTS_DIR} to current location" - cp ${VH_INPUTS_DIR}/dl4j-java-app/MLPMnist-1.0.0.jar . - echo "~~~ Run the DL4J app to train model based on the the MNist dataset" - ./runMLPMnist.sh {parameters} inputs: - name: dl4j-java-app description: DL4J Java app file (jar) generated in the previous step 'Build-dl4j-mnist-single-layer-java-app' - name: dataset default: https://github.com/neomatrix369/awesome-ai-ml-dl/releases/download/mnist-dataset-v0.1/mlp-mnist-dataset.tgz description: MNist dataset needed to train the model parameters: - name: --action pass-as: '--action {v}' type: string default: train description: Action to perform ie train or evaluate - name: --output-dir pass-as: '--output-dir {v}' type: string default: /valohai/outputs/ description: Output directory where the model will be created, best to pick the Valohai output directory environment: aws-eu-west-1-g2-2xlarge - step: name: Run-dl4j-mnist-single-layer-evaluate-model image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - cd ${VH_REPOSITORY_DIR} - echo "~~~ Copying the build jar file from ${VH_INPUTS_DIR} to current location" - cp ${VH_INPUTS_DIR}/dl4j-java-app/MLPMnist-1.0.0.jar . - echo "~~~ Run the DL4J app to evaluate the trained MNist model" - ./runMLPMnist.sh {parameters} inputs: - name: dl4j-java-app description: DL4J Java app file (jar) generated in the previous step 'Build-dl4j-mnist-single-layer-java-app' - name: model description: Model file generated in the previous step 'Run-dl4j-mnist-single-layer-train-model' parameters: - name: --action pass-as: '--action {v}' type: string default: evaluate description: Action to perform ie train or evaluate - name: --input-dir pass-as: '--input-dir {v}' type: string default: /valohai/inputs/model description: Input directory where the model created by the previous step can be found created environment: aws-eu-west-1-g2-2xlarge</code> </pre><br><h4>  Fonctionnement de Build-dl4j-mnist-single-layer-java-app </h4><br>  √Ä partir du fichier YAML, nous voyons que nous d√©finissons cette √©tape, en utilisant d'abord l'image Docker, puis en ex√©cutant le script pour construire le JAR Uber.  Notre image Docker a la personnalisation des d√©pendances de l'environnement de construction (par exemple GraalVM JDK, Maven, etc.) pour cr√©er une application Java.  Nous ne fournissons aucune entr√©e ou param√®tre, car il s'agit de la phase d'assemblage.  Une fois la construction r√©ussie, nous copions le pot uber nomm√© MLPMnist-1.0.0-bin.jar (nom d'origine) dans le dossier / valohai / sorties (repr√©sent√© par $ {VH_OUTPUTS_DIR}).  Tout dans ce dossier est automatiquement enregistr√© dans le stockage de votre projet, par exemple, dans la corbeille AWS S3.  Enfin, nous d√©finissons notre travail pour AWS. <br><br><div class="spoiler">  <b class="spoiler_title">Remarque</b> <div class="spoiler_text">  Le compte gratuit Valohai n'a pas acc√®s au r√©seau depuis le conteneur Docker (ceci est d√©sactiv√© par d√©faut), veuillez contacter le support pour activer cette option (j'ai d√ª faire de m√™me), sinon nous ne pourrons pas t√©l√©charger notre Maven et d'autres d√©pendances pendant l'assemblage. <br></div></div><br><h4>  Fonctionnement de Run-dl4j-mnist-single-layer-train-model </h4><br>  La s√©mantique de la d√©finition est similaire √† l'√©tape pr√©c√©dente, sauf que nous sp√©cifions deux entr√©es: une pour le pot uber (MLPMnist-1.0.0.jar) et l'autre pour l'ensemble de donn√©es (d√©compress√© dans le dossier $ {HOME} /. Deeplearning4j).  Nous passerons deux param√®tres - --action train et --output-dir / valohai / sorties.  Le mod√®le cr√©√© √† cette √©tape est int√©gr√© dans / valohai / outputs / model (repr√©sent√© par $ {VH_OUTPUTS_DIR} / model). <br><br><div class="spoiler">  <b class="spoiler_title">Remarque</b> <div class="spoiler_text">  Dans les champs de saisie de l'onglet Ex√©cution de l'interface Web de Valohai, nous pouvons s√©lectionner la sortie des ex√©cutions pr√©c√©dentes en utilisant le num√©ro d'ex√©cution, c'est-√†-dire # 1 ou # 2, en plus d'utiliser les donn√©es: // ou http: / URL /, la saisie de quelques lettres du nom du fichier permet √©galement de rechercher dans la liste enti√®re. <br></div></div><br><h4>  Fonctionnement de Run-dl4j-mnist-single-layer -valu-model </h4><br>  Encore une fois, cette √©tape est similaire √† l'√©tape pr√©c√©dente, sauf que nous passerons deux param√®tres --action evaluation et --input-dir / valohai / inputs / model.  De plus, nous avons √† nouveau indiqu√© dans l'entr√©e: les sections d√©finies dans le fichier YAML avec le nom dl4j-java-app et le mod√®le sans la valeur par d√©faut pour les deux.  Cela nous permettra de s√©lectionner le pot uber et le mod√®le que nous voulons √©valuer - qui a √©t√© cr√©√© √† l'aide de l'√©tape Run-dl4j-mnist-single-layer-train-model en utilisant l'interface Web. <br><br>  J'esp√®re que cela explique les √©tapes du fichier de d√©finition ci-dessus, mais si vous avez besoin d'aide, n'h√©sitez pas √† consulter la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> et les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">didacticiels</a> . <br><br><h3>  Interface Web Valohai </h3><br>  Apr√®s avoir re√ßu le compte, nous pouvons nous connecter et continuer √† cr√©er le projet avec le nom mlpmnist-single-layer et associer git repo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github.com/valohai/mlpmnist-dl4j-example</a> au projet et enregistrer le projet. <br><br>  Vous pouvez maintenant terminer l'√©tape et voir comment cela se passe! <br><br><h4>  Cr√©er une application Java DL4J </h4><br>  Acc√©dez √† l'onglet ¬´Ex√©cution¬ª dans l'interface Web et copiez l'ex√©cution existante ou cr√©ez-en une √† l'aide du bouton [Cr√©er ex√©cution].  Tous les param√®tres par d√©faut n√©cessaires seront remplis.  S√©lectionnez √âtape Build-dl4j-mnist-single-layer-java-app. <br><br>  Pour l' <i>environnement,</i> j'ai s√©lectionn√© AWS eu-west-1 g2.2xlarge et cliqu√© sur le bouton [Cr√©er l'ex√©cution] en bas de la page pour voir le d√©but de l'ex√©cution. <br><br><img src="https://habrastorage.org/webt/le/18/zo/le18zo_udbscmekflaux7kqfjcw.png"><br><br><h3>  Formation mod√®le </h3><br>  Acc√©dez √† l'onglet ¬´Ex√©cution¬ª dans l'interface Web et proc√©dez de la m√™me mani√®re qu'√† l'√©tape pr√©c√©dente, puis s√©lectionnez Run-dl4j-mnist-single-layer-train-model.  Vous devrez s√©lectionner l'application Java (entrez simplement le pot dans le champ) cr√©√©e √† l'√©tape pr√©c√©dente.  L'ensemble de donn√©es a d√©j√† √©t√© pr√©rempli √† l'aide du fichier valohai.yaml: <br><br><img src="https://habrastorage.org/webt/md/ls/ov/mdlsovhg3vw9zjnpoeqhxwzgk7w.png"><br><br>  Cliquez sur [Cr√©er ex√©cution] pour d√©marrer. <br><br><img src="https://habrastorage.org/webt/6n/mr/wm/6nmrwmveck6cgdughud1xgx7qdg.png"><br><br>  Vous verrez le r√©sultat dans la console: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:05 ======================================================================= 11:17:05 LayerName (LayerType) nIn,nOut TotalParams ParamsShape 11:17:05 ======================================================================= 11:17:05 layer0 (DenseLayer) 784,1000 785000 W:{784,1000}, b:{1,1000} 11:17:05 layer1 (OutputLayer) 1000,10 10010 W:{1000,10}, b:{1,10} 11:17:05 ----------------------------------------------------------------------- 11:17:05 Total Parameters: 795010 11:17:05 Trainable Parameters: 795010 11:17:05 Frozen Parameters: 0 11:17:05 ======================================================================= [&lt;--- snipped ---&gt;]</code> </pre><br>  Les mod√®les cr√©√©s peuvent √™tre trouv√©s sur l'onglet ¬´Sorties¬ª de l'onglet principal ¬´Ex√©cution¬ª pendant et apr√®s l'ex√©cution: <br><br><img src="https://habrastorage.org/webt/pg/g2/-k/pgg2-kmsr85x87fedfoy24lreye.png"><br><br>  Vous pouvez remarquer plusieurs artefacts dans le sous-onglet Sorties.  En effet, nous maintenons des points de contr√¥le √† la fin de chaque √®re.  Regardons cela dans les journaux: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:14 odolCheckpointListener - Model checkpoint saved: epoch 0, iteration 469, path: /valohai/outputs/checkpoint_0_MultiLayerNetwork.zip [&lt;--- snipped ---&gt;]</code> </pre><br>  Le point de contr√¥le contient l'√©tat du mod√®le dans trois fichiers: <br><br><pre> <code class="plaintext hljs">configuration.json coefficients.bin updaterState.bin</code> </pre><br><h3>  Formation de mod√®le.  M√©tadonn√©es </h3><br>  Vous avez peut-√™tre remarqu√© ces entr√©es dans les journaux d'ex√©cution: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:05 {"epoch": 0, "iteration": 0, "score (loss function)": 2.410047} 11:17:07 {"epoch": 0, "iteration": 100, "score (loss function)": 0.613774} 11:17:09 {"epoch": 0, "iteration": 200, "score (loss function)": 0.528494} 11:17:11 {"epoch": 0, "iteration": 300, "score (loss function)": 0.400291} 11:17:13 {"epoch": 0, "iteration": 400, "score (loss function)": 0.357800} 11:17:14 odolCheckpointListener - Model checkpoint saved: epoch 0, iteration 469, path: /valohai/outputs/checkpoint_0_MultiLayerNetwork.zip [&lt;--- snipped ---&gt;]</code> </pre><br>  Ces donn√©es permettent √† Valohai d'obtenir ces valeurs (au format JSON) qui seront utilis√©es pour construire les m√©triques qui peuvent √™tre vues pendant et apr√®s l'ex√©cution sur l'onglet M√©tadonn√©es suppl√©mentaire de l'onglet principal Ex√©cutions: <br><br><img src="https://habrastorage.org/webt/et/p-/se/etp-sezekre2qlznmvgdzlgds0a.png"><br><br>  Nous avons pu le faire en connectant la classe ValohaiMetadataCreator au mod√®le, de sorte que Valohai se r√©f√®re √† cette classe pendant la formation.  Dans le cas de cette classe, on d√©rive plusieurs √©poques, le nombre d'it√©rations et le Score (valeur de la fonction de perte).  Voici un extrait de code de la classe: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">iterationDone</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Model model, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> iteration, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> epoch)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (printIterations &lt;= <span class="hljs-number"><span class="hljs-number">0</span></span>) printIterations = <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (iteration % printIterations == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> score = model.score(); System.out.println(String.format( <span class="hljs-string"><span class="hljs-string">"{\"epoch\": %d, \"iteration\": %d, \"score (loss function)\": %f}"</span></span>, epoch, iteration, score) ); } }</code> </pre><br><h3>  √âvaluation du mod√®le </h3><br>  Une fois le mod√®le cr√©√© avec succ√®s √† l'√©tape pr√©c√©dente, il doit √™tre √©valu√©.  Nous cr√©ons une nouvelle ex√©cution de la m√™me mani√®re que pr√©c√©demment, mais cette fois, s√©lectionnez l'√©tape Run-dl4j-mnist-single-layer -valu-model.  Nous devrons s√©lectionner √† nouveau l'application Java (MLPMnist-1.0.0.jar) et le mod√®le cr√©√© (mlpmnist-single-layer.pb) avant de d√©marrer l'ex√©cution (comme illustr√© ci-dessous): <br><br><img src="https://habrastorage.org/webt/e9/_b/am/e9_bamnlhownoo40utziaqazg8e.png"><br><br>  Apr√®s avoir s√©lectionn√© le mod√®le souhait√© en entr√©e, cliquez sur le bouton [Cr√©er ex√©cution].  Il s'ex√©cutera plus rapidement que le pr√©c√©dent, et nous verrons le r√©sultat suivant: <br><br><img src="https://habrastorage.org/webt/gp/0i/co/gp0icomuurv7a0gt-niye5hyri4.png"><br><br>  Nous voyons que notre "bonjour" a conduit √† un mod√®le dont la pr√©cision est d'environ 97% sur la base d'un ensemble de donn√©es de test.  La matrice de confusion aide √† trouver les cas o√π un chiffre a √©t√© incorrectement pr√©dit comme un autre chiffre. <br><br>  La question demeure (et au-del√† de la port√©e de cet article) - quelle est la qualit√© du mod√®le face √† des donn√©es r√©elles? <br><br>  Pour cloner un r√©f√©rentiel git, voici ce que vous devez faire: <br><br><pre> <code class="plaintext hljs"> $ git clone https://github.com/valohai/mlpmnist-dl4j-example</code> </pre><br>  Ensuite, nous devons lier notre projet Valohai, cr√©√© via l'interface Web dans la section ci-dessus, avec le projet stock√© sur notre machine locale (celle que nous venons de cloner).  Ex√©cutez les commandes suivantes pour ce faire: <br><br><pre> <code class="plaintext hljs">$ cd mlpmnist-dl4j-example $ vh project --help ### to see all the project-specific options we have for Valohai $ vh project link</code> </pre><br>  On vous montrera quelque chose comme ceci: <br><br><pre> <code class="plaintext hljs">[ 1] mlpmnist-single-layer ... Which project would you like to link with /path/to/mlpmnist-dl4j-example? Enter [n] to create a new project.:</code> </pre><br>  S√©lectionnez 1 (ou celui qui vous convient) et vous devriez voir ce message: <br><br><pre> <code class="plaintext hljs">Success! Linked /path/to/mlpmnist-dl4j-example to mlpmnist-single-layer.</code> </pre><br>  Avant de continuer, assurez-vous que votre projet Valohai est synchronis√© avec le dernier projet git en proc√©dant comme suit: <br><br><pre> <code class="plaintext hljs"> $ vh project fetch</code> </pre><br><img src="https://habrastorage.org/webt/h0/l4/vb/h0l4vbe1eqis5kb9sd7gfslbozk.png"><br><br>  Maintenant, nous pouvons terminer les √©tapes de la CLI avec: <br><br><pre> <code class="plaintext hljs"> $ vh exec run Build-dl4j-mnist-single-layer-java-app</code> </pre><br>  Une fois l'ex√©cution termin√©e, nous pouvons le v√©rifier avec: <br><br><pre> <code class="plaintext hljs">$ vh exec info $ vh exec logs $ vh exec watch</code> </pre><br><h3>  Conclusion </h3><br>  Comme nous l'avons vu, il est tr√®s pratique de travailler ensemble avec DL4J et Valohai.  De plus, nous pouvons d√©velopper divers composants qui composent nos exp√©riences (recherche), c'est-√†-dire l'environnement de construction / d'ex√©cution, le code et l'ensemble de donn√©es, et les int√©grer dans notre projet. <br><br>  Les exemples de mod√®les utilis√©s dans cet article sont un bon moyen de commencer √† cr√©er des projets plus complexes.  Et vous pouvez utiliser l'interface Web ou la ligne de commande pour faire votre travail avec Valohai.  Avec la CLI, vous pouvez √©galement l'int√©grer √† vos installations et scripts (ou m√™me aux travaux CRON ou CI / CD). <br><br>  De plus, il est clair que si je travaille sur un projet li√© √† l'IA / ML / DL, je n'ai pas √† me soucier de cr√©er et de maintenir un pipeline de bout en bout (ce que beaucoup d'autres ont d√ª faire par le pass√©). <br><br><h5>  Les r√©f√©rences </h5><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le projet mlpmnist-dl4j-examples sur GitHub</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ressources AI / ML / DL impressionnantes</a> </li><li>  <a href="">Ressources Java AI / ML / DL</a> </li><li>  <a href="">Deep Learning et ressources DL4J</a> </li></ol><br>  Merci de votre attention! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr469405/">https://habr.com/ru/post/fr469405/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr469393/index.html">R√©daction sur Flare-On 2019</a></li>
<li><a href="../fr469395/index.html">O√π et comment utiliser les multicolonnes (colonnes CSS)</a></li>
<li><a href="../fr469399/index.html">Wi-Fi au mus√©e-domaine Arkhangelskoye</a></li>
<li><a href="../fr469401/index.html">Mise √† jour du service WebMeeting 3CX, Elastix Online Converter et nouveaux didacticiels vid√©o</a></li>
<li><a href="../fr469403/index.html">Nous interviewons un candidat pour le poste de d√©veloppeur de logiciels senior</a></li>
<li><a href="../fr469407/index.html">ARIES PLC110 [M02] -MS4, HMI, OPC et SCADA, ou combien une personne a besoin de th√© √† la camomille. Partie 1</a></li>
<li><a href="../fr469409/index.html">Profilage Linux avec Analyseur de performances</a></li>
<li><a href="../fr469411/index.html">RE: Douleur et larmes dans Svelte 3</a></li>
<li><a href="../fr469413/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 382 (22-29 septembre 2019)</a></li>
<li><a href="../fr469415/index.html">Niveaux d'isolement transactionnel pour les plus petits</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
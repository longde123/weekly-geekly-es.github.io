<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêÜ üçæ üèä Protokolle in Kubernetes (und nicht nur) heute: Erwartungen und Realit√§t ü§öüèº üçø üëâüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es war 2019, und wir haben immer noch keine Standardl√∂sung f√ºr die Protokollaggregation in Kubernetes. In diesem Artikel m√∂chten wir anhand von Beispi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Protokolle in Kubernetes (und nicht nur) heute: Erwartungen und Realit√§t</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/480946/"><img src="https://habrastorage.org/webt/b1/zh/it/b1zhitohqlji21qhzypqn8k_n2s.png"><br><br>  Es war 2019, und wir haben immer noch keine Standardl√∂sung f√ºr die Protokollaggregation in Kubernetes.  In diesem Artikel m√∂chten wir anhand von Beispielen aus der Praxis unsere Suche, die aufgetretenen Probleme und deren L√∂sungen mitteilen. <br><br>  Zun√§chst mache ich jedoch eine Reservierung, bei der verschiedene Kunden sehr unterschiedliche Dinge verstehen, indem sie Protokolle sammeln: <br><br><ul><li>  jemand m√∂chte Sicherheits- und √úberwachungsprotokolle sehen; </li><li>  jemand - zentralisierte Protokollierung der gesamten Infrastruktur; </li><li>  und f√ºr jemanden ist es ausreichend, nur die Anwendungsprotokolle zu sammeln, beispielsweise mit Ausnahme von Balancern. </li></ul><br>  Wie wir verschiedene "Wishlist" implementiert haben und auf welche Schwierigkeiten wir bei der K√ºrzung gesto√üen sind. <a name="habracut"></a><br><br><h2>  Theorie: √úber Protokollierungswerkzeuge </h2><br><h3>  Hintergrundinformationen zu den Komponenten des Protokollierungssystems </h3><br>  Die Protokollierung hat einen langen Weg zur√ºckgelegt, weshalb wir Methoden zum Sammeln und Analysieren von Protokollen entwickelt haben, die wir heute verwenden.  In den 1950er Jahren f√ºhrte Fortran ein Analogon von Standard-I / O-Streams ein, das dem Programmierer beim Debuggen seines Programms half.  Dies waren die ersten Computerprotokolle, die den Programmierern dieser Zeit das Leben leichter machten.  Heute sehen wir in ihnen die erste Komponente des Protokollierungssystems - die <b>Quelle oder der ‚ÄûProduzent‚Äú der Protokolle</b> . <br><br>  Die Informatik stand nicht still: Computernetzwerke erschienen, die ersten Cluster ... Komplexe Systeme, die aus mehreren Computern bestanden, begannen zu funktionieren.  Jetzt mussten Systemadministratoren Protokolle von mehreren Computern sammeln und in besonderen F√§llen Betriebssystemkernel-Meldungen hinzuf√ºgen, falls ein Systemfehler untersucht werden musste.  <a href="https://tools.ietf.org/html/rfc3164">RFC 3164</a> wurde in den fr√ºhen 2000er Jahren herausgegeben und standardisierte remote_syslog, um zentralisierte Protokollsammlungssysteme zu beschreiben.  So erschien eine weitere wichtige Komponente: der <b>Sammler (Collector) von Protokollen</b> und deren Speicherung. <br><br>  Mit der Zunahme des Protokollvolumens und der weit verbreiteten Einf√ºhrung von Webtechnologien stellte sich die Frage, welche Protokolle den Benutzern bequem angezeigt werden sollten.  Einfache Konsolen-Tools (awk / sed / grep) wurden durch erweiterte <b>Protokoll-Viewer ersetzt</b> - die dritte Komponente. <br><br>  Im Zusammenhang mit der Zunahme des Protokollvolumens wurde eines klar: Es werden Protokolle ben√∂tigt, aber nicht alle.  Unterschiedliche Protokolle erfordern unterschiedliche Sicherheitsstufen: Einige gehen jeden zweiten Tag verloren, andere m√ºssen f√ºnf Jahre lang aufbewahrt werden.  Daher wurde dem Protokollierungssystem eine Filter- und Routing-Komponente f√ºr Datenstr√∂me hinzugef√ºgt - nennen wir es einen <b>Filter</b> . <br><br>  Repositorys machten ebenfalls einen gro√üen Sprung: Sie wechselten von regul√§ren Dateien zu relationalen Datenbanken und dann zu dokumentenorientierten Repositorys (z. B. Elasticsearch).  So wurde der Speicher vom Kollektor getrennt. <br><br>  Am Ende hat sich das Konzept des Protokolls zu einem abstrakten Strom von Ereignissen erweitert, den wir f√ºr die Geschichte aufbewahren m√∂chten.  Genauer gesagt, wenn eine Untersuchung durchgef√ºhrt oder ein Analysebericht erstellt werden muss ... <br><br>  Infolgedessen hat sich die Sammlung von Protokollen in relativ kurzer Zeit zu einem wichtigen Subsystem entwickelt, das zu Recht als einer der Unterabschnitte von Big Data bezeichnet werden kann. <br><br><img src="https://habrastorage.org/webt/ld/ax/r6/ldaxr6rvel45_k3jyu3d1eddcgw.png"><br>  <i>Wenn einmal normale Ausdrucke f√ºr ein ‚ÄûProtokollierungssystem‚Äú ausreichen k√∂nnten, hat sich die Situation jetzt sehr ver√§ndert.</i> <br><br><h3>  Kubernetes und Logs </h3><br>  Als Kubernetes in die Infrastruktur kam, ging das bestehende Problem des Sammelns von Protokollen nicht an ihm vorbei.  In gewisser Hinsicht ist es noch schmerzhafter geworden: Die Verwaltung der Infrastrukturplattform wurde nicht nur vereinfacht, sondern auch kompliziert.  Viele alte Dienste begannen, auf Microservice-Tracks zu migrieren.  Im Zusammenhang mit Protokollen f√ºhrte dies zu einer wachsenden Anzahl von Protokollquellen, ihrem speziellen Lebenszyklus und der Notwendigkeit, die Verbindungen aller Systemkomponenten durch die Protokolle zu verfolgen ... <br><br>  Mit Blick auf die Zukunft kann ich sagen, dass es derzeit leider keine standardisierte Protokollierungsoption f√ºr Kubernetes gibt, die sich positiv von allen anderen unterscheiden w√ºrde.  Die beliebtesten Programme in der Community sind: <br><br><ul><li>  Jemand stellt einen <b>EFK-</b> Stack bereit (Elasticsearch, Fluentd, Kibana). </li><li>  Jemand versucht es mit dem k√ºrzlich ver√∂ffentlichten <a href="https://grafana.com/oss/loki/"><b>Loki</b></a> oder verwendet den <a href="https://banzaicloud.com/products/logging-operator/"><b>Protokollierungsoperator</b></a> . </li><li>  wir <i>(und vielleicht nicht nur wir? ..)</i> sind mit unserer eigenen entwicklung weitgehend zufrieden - <a href="https://github.com/flant/loghouse"><b>loghouse</b></a> ... </li></ul><br>  In der Regel verwenden wir solche Bundles in K8-Clustern (f√ºr selbst gehostete L√∂sungen): <br><br><ul><li>  <a href="https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch">Fluentd + Elasticsearch + Kibana</a> ; </li><li>  <a href="https://github.com/flant/loghouse">Fluentd + ClickHouse + Blockhaus</a> . </li></ul><br>  Ich werde mich jedoch nicht mit den Anweisungen f√ºr deren Installation und Konfiguration befassen.  Stattdessen werde ich mich auf ihre M√§ngel und allgemeineren Schlussfolgerungen zur Situation mit Protokollen im Allgemeinen konzentrieren. <br><br><h2>  √úbe mit Logs in K8s </h2><br><img src="https://habrastorage.org/webt/zv/p8/lj/zvp8ljnjmqen_8c0svhhh2kezyc.jpeg" align="left"><br><h3>  "Alltagsprotokolle", wie viele von Ihnen? .. </h3><br>  Die zentrale Erfassung von Protokollen mit einer ausreichend gro√üen Infrastruktur erfordert erhebliche Ressourcen f√ºr die Erfassung, Speicherung und Verarbeitung von Protokollen.  W√§hrend des Betriebs verschiedener Projekte waren wir mit unterschiedlichen Anforderungen und den daraus resultierenden betrieblichen Problemen konfrontiert. <br><br><h4>  Versuchen wir es mit ClickHouse </h4><br>  Schauen wir uns ein zentrales Repository f√ºr ein Projekt mit einer Anwendung an, die eine ganze Reihe von Protokollen generiert: mehr als 5000 Zeilen pro Sekunde.  Beginnen wir mit seinen Protokollen und f√ºgen sie zu ClickHouse hinzu. <br><br>  Sobald die maximale Echtzeit erforderlich ist, ist der 4-Kern-ClickHouse-Server auf dem Festplattensubsystem bereits √ºberlastet: <br><br><img src="https://habrastorage.org/webt/i4/zy/i6/i4zyi6fxq4175ljs3slazm9rgxc.png"><br><br>  Diese Art des Downloads ist darauf zur√ºckzuf√ºhren, dass wir versuchen, so schnell wie m√∂glich an ClickHouse zu schreiben.  Darauf reagiert die Datenbank mit einer erh√∂hten Festplattenlast, die folgende Fehler verursachen kann: <br><br> <code>DB::Exception: Too many parts (300). Merges are processing significantly slower than inserts</code> <br> <br>  Tatsache ist, dass <a href="https://clickhouse.yandex/docs/en/operations/table_engines/mergetree/">MergeTree-Tabellen</a> in ClickHouse (sie enthalten Protokolldaten) ihre eigenen Schwierigkeiten beim Schreiben haben.  Die darin eingef√ºgten Daten erzeugen eine tempor√§re Partition, die dann mit der Haupttabelle zusammengef√ºhrt wird.  Infolgedessen ist die Aufzeichnung auf der Festplatte sehr anspruchsvoll, und es gilt die Einschr√§nkung, deren Benachrichtigung wir oben erhalten haben: In einer Sekunde k√∂nnen nicht mehr als 300 Unterpartitionen zusammengef√ºhrt werden (das sind 300 Einf√ºgungen pro Sekunde). <br><br>  Um dieses Verhalten zu vermeiden, <a href="https://github.com/ClickHouse/ClickHouse/issues/3174">sollten</a> Sie <a href="https://github.com/ClickHouse/ClickHouse/issues/3174">in ClickHouse in</a> m√∂glichst gro√üen <a href="https://github.com/ClickHouse/ClickHouse/issues/3174">Bl√∂cken</a> und nicht √∂fter als einmal in 2 Sekunden <a href="https://github.com/ClickHouse/ClickHouse/issues/3174">schreiben</a> .  Wenn Sie jedoch in gro√üen Stapeln schreiben, sollten Sie weniger h√§ufig in ClickHouse schreiben.  Dies kann wiederum zu Puffer√ºberl√§ufen und zum Verlust von Protokollen f√ºhren.  Die L√∂sung besteht darin, den Fluentd-Puffer zu vergr√∂√üern, aber dann steigt der Speicherverbrauch. <br><br>  <i><b>Hinweis</b> : Eine weitere problematische Seite unserer ClickHouse-L√∂sung war, dass die Partitionierung in unserem Fall (Loghouse) √ºber externe Tabellen implementiert wurde, die durch eine <a href="https://clickhouse.yandex/docs/ru/operations/table_engines/merge/">Merge-Tabelle</a> verkn√ºpft sind.</i>  <i>Dies f√ºhrt dazu, dass beim Abtasten gro√üer Zeitintervalle √ºberm√§√üiger RAM-Speicher erforderlich ist, da der Metatable alle Partitionen durchl√§uft - auch diejenigen, die offensichtlich nicht die erforderlichen Daten enthalten.</i>  <i>Jetzt kann dieser Ansatz jedoch f√ºr aktuelle Versionen von ClickHouse (seit <a href="">18.16</a> ) sicher f√ºr veraltet erkl√§rt werden.</i> <br><br>  Infolgedessen wird deutlich, dass ClickHouse nicht √ºber gen√ºgend Ressourcen f√ºr jedes Projekt verf√ºgt, um Protokolle in Echtzeit zu erfassen (genauer gesagt, ihre Verteilung ist nicht sinnvoll).  Au√üerdem ben√∂tigen Sie einen <b>Akku</b> , zu dem wir zur√ºckkehren.  Der oben beschriebene Fall ist real.  Und zu diesem Zeitpunkt konnten wir keine zuverl√§ssige und stabile L√∂sung anbieten, die den Kunden zufrieden stellt und es erm√∂glicht, Protokolle mit einer minimalen Verz√∂gerung zu sammeln ... <br><br><h4>  Was ist mit Elasticsearch? </h4><br>  Elasticsearch ist daf√ºr bekannt, schwere Lasten zu bew√§ltigen.  Versuchen wir es im selben Projekt.  Jetzt ist die Ladung wie folgt: <br><br><img src="https://habrastorage.org/webt/jh/we/7o/jhwe7ok8_l0alrlv5j72p5lgha0.png"><br><br>  Elasticsearch war in der Lage, den Datenstrom zu verarbeiten. Das Schreiben derartiger Volumes nutzt jedoch die CPU in hohem Ma√üe.  Dies wird von der Organisation des Clusters entschieden.  Rein technisch ist dies kein Problem, aber es stellt sich heraus, dass wir nur f√ºr den Betrieb des Log-Collection-Systems bereits ca. 8 Kerne verwenden und eine zus√§tzliche hoch belastete Komponente im System haben ... <br><br>  Fazit: Diese Option kann gerechtfertigt sein, aber nur, wenn das Projekt umfangreich ist und die Verwaltung bereit ist, erhebliche Ressourcen f√ºr ein zentrales Protokollierungssystem aufzuwenden. <br><br>  Dann stellt sich eine logische Frage: <br><br><h3>  Welche Protokolle werden wirklich ben√∂tigt? </h3><br><img src="https://habrastorage.org/webt/hl/3h/ei/hl3heiig0t7nluwc_bvorqrrndk.jpeg" align="left">  Versuchen wir, den Ansatz selbst zu √§ndern: Die Protokolle sollten gleichzeitig informativ sein und nicht <i>jedes</i> Ereignis im System abdecken. <br><br>  Nehmen wir an, wir haben einen florierenden Online-Shop.  Welche Protokolle sind wichtig?  Es ist eine gute Idee, so viele Informationen wie m√∂glich von einem Zahlungsgateway aus zu sammeln.  Vom Image-Slicing-Service im Produktkatalog sind jedoch nicht alle Protokolle f√ºr uns kritisch: Nur Fehler und erweiterte √úberwachung sind ausreichend (z. B. der Prozentsatz von 500 Fehlern, die diese Komponente generiert). <br><br>  So kamen wir zu dem <b>Schluss,</b> dass eine <b>zentrale Protokollierung keineswegs immer gerechtfertigt ist</b> .  Sehr oft m√∂chte der Client alle Protokolle an einem Ort sammeln, obwohl tats√§chlich nur 5% der gesch√§ftskritischen Nachrichten aus dem gesamten Protokoll ben√∂tigt werden: <br><br><ul><li>  Manchmal reicht es beispielsweise aus, nur die Gr√∂√üe des Containerprotokolls und des Fehlersammlers (z. B. Sentry) zu konfigurieren. </li><li>  Zur Untersuchung von Vorf√§llen reichen h√§ufig Fehlermeldungen und ein umfangreiches lokales Protokoll aus. </li><li>  Wir hatten Projekte, die nur Funktionstests und Fehlersammelsysteme kosteten.  Der Entwickler brauchte die Protokolle nicht als solche - sie sahen alles auf Fehlerspuren. </li></ul><br><h4>  Leben Illustration </h4><br>  Ein gutes Beispiel ist eine andere Geschichte.  Wir erhielten eine Anfrage des Sicherheitsteams eines Kunden, der bereits eine kommerzielle L√∂sung hatte, die lange vor der Implementierung von Kubernetes entwickelt wurde. <br><br>  Es dauerte, bis sich ein zentrales Protokollsammelsystem mit einem Unternehmenssensor zur Erkennung von Problemen - QRadar - ‚Äûangefreundet‚Äú hatte.  Dieses System ist in der Lage, Protokolle √ºber das Syslog-Protokoll zu empfangen, um sie √ºber FTP abzurufen.  Die Integration in das remote_syslog-Plugin f√ºr fluentd funktionierte jedoch nicht sofort <i>(wie sich herausstellte, sind <a href="https://developer.ibm.com/answers/questions/429729/using-fluentd-to-streamfilter-data-to-qradar/">wir nicht die einzigen</a> )</i> .  Probleme bei der Konfiguration von QRadar hatte das Sicherheitsteam des Kunden. <br><br>  Infolgedessen wurde ein Teil der gesch√§ftskritischen Protokolle auf FTP QRadar hochgeladen, und der andere Teil wurde √ºber Remote-Syslog direkt von den Knoten umgeleitet.  Dazu haben wir sogar ein <a href="https://github.com/flant/examples/tree/master/2019/10-remote-syslog">einfaches Diagramm geschrieben</a> - vielleicht hilft es jemandem, ein √§hnliches Problem zu l√∂sen ... Dank des resultierenden Schemas hat der Kunde selbst kritische Protokolle empfangen und analysiert (unter Verwendung seiner bevorzugten Tools), und wir konnten die Kosten f√ºr das Protokollierungssystem senken und nur die letzten aufbewahren Monat. <br><br>  Ein anderes Beispiel zeigt, wie man es nicht macht.  Einer unserer Kunden, der <i>jedes</i> vom Benutzer ausgehende Ereignis handhabte, gab die Informationen mehrzeilig und <i>unstrukturiert</i> in das Protokoll aus.  Wie Sie vielleicht erraten haben, war das Lesen und Speichern solcher Protokolle √§u√üerst unpraktisch. <br><br><h3>  Kriterien f√ºr Protokolle </h3><br>  Solche Beispiele f√ºhren zu der Schlussfolgerung, dass Sie nicht nur ein System zum Sammeln von Protokollen ausw√§hlen, sondern auch <i>die Protokolle selbst entwerfen m√ºssen</i> !  Was sind die Anforderungen hier? <br><br><ul><li>  Protokolle m√ºssen in einem maschinenlesbaren Format vorliegen (z. B. JSON). </li><li>  Protokolle sollten kompakt sein und den Protokollierungsgrad √§ndern k√∂nnen, um m√∂gliche Probleme zu beheben.  Gleichzeitig sollten Sie in Produktionsumgebungen Systeme mit einer Protokollierungsstufe wie <i>Warnung</i> oder <i>Fehler</i> ausf√ºhren. </li><li>  Protokolle m√ºssen normalisiert sein, dh im Protokollobjekt m√ºssen alle Zeilen den gleichen Feldtyp haben. </li></ul><br>  Unstrukturierte Protokolle k√∂nnen zu Problemen beim Laden von Protokollen in das Repository und beim vollst√§ndigen Stoppen ihrer Verarbeitung f√ºhren.  Zur Veranschaulichung hier ein Beispiel mit einem 400-Fehler, auf den sicherlich viele in flie√üenden Protokollen gesto√üen sind: <br><br> <code>2019-10-29 13:10:43 +0000 [warn]: dump an error event: error_class=Fluent::Plugin::ElasticsearchErrorHandler::ElasticsearchError error="400 - Rejected by Elasticsearch"</code> <br> <br>  Ein Fehler bedeutet, dass Sie ein Feld, dessen Typ instabil ist, mit einer fertigen Zuordnung an den Index senden.  Das einfachste Beispiel ist ein Feld im Nginx-Protokoll mit der Variablen <code>$upstream_status</code> .  Es kann entweder eine Zahl oder eine Zeichenfolge sein.  Zum Beispiel: <br><br> <code>{ "ip": "1.2.3.4", "http_user": "-", "request_id": "17ee8a579e833b5ab9843a0aca10b941", "time": "29/Oct/2019:16:18:57 +0300", "method": "GET", "uri": "/staffs/265.png", "protocol": "HTTP/1.1", "status": "200", "body_size": "906", "referrer": "https://example.com/staff", "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36", "request_time": "0.001", "cache_status": "-", "upstream_response_time": "0.001, 0.007", "upstream_addr": "127.0.0.1:9000", "upstream_status": "200", "upstream_response_length": "906", "location": "staff"} <br> { "ip": "1.2.3.4", "http_user": "-", "request_id": "47fe42807f2a7d8d5467511d7d553a1b", "time": "29/Oct/2019:16:18:57 +0300", "method": "GET", "uri": "/staff", "protocol": "HTTP/1.1", "status": "200", "body_size": "2984", "referrer": "-", "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36", "request_time": "0.010", "cache_status": "-", "upstream_response_time": "0.001, 0.007", "upstream_addr": "10.100.0.10:9000, 10.100.0.11:9000", "upstream_status": "404, 200", "upstream_response_length": "0, 2984", "location": "staff"}</code> <br> <br>  Die Protokolle zeigen, dass der Server 10.100.0.10 mit dem Fehler 404 geantwortet hat und die Anforderung an einen anderen Content Store gesendet wurde.  In den Protokollen hat sich die Bedeutung folgenderma√üen ge√§ndert: <br><br> <code>"upstream_response_time": "0.001, 0.007"</code> <br> <br>  Diese Situation ist so weit verbreitet, dass sie <a href="https://github.com/uken/fluent-plugin-elasticsearch">in der Dokumentation</a> sogar gesondert <a href="https://github.com/uken/fluent-plugin-elasticsearch">erw√§hnt wurde</a> . <br><br><h4>  Und was ist mit Zuverl√§ssigkeit? </h4><br>  Es gibt Zeiten, in denen alle Protokolle ausnahmslos wichtig sind.  Und damit haben die oben vorgeschlagenen / diskutierten typischen Protokollsammlungsschemata f√ºr K8 Probleme. <br><br>  Beispielsweise kann fluentd keine Protokolle aus kurzlebigen Containern sammeln.  In einem unserer Projekte hat der Container mit der Datenbankmigration weniger als 4 Sekunden gelebt und wurde dann gel√∂scht - entsprechend der entsprechenden Anmerkung: <br><br> <code>"helm.sh/hook-delete-policy": hook-succeeded</code> <br> <br>  Aus diesem Grund wurde das Migrationsprotokoll nicht in das Repository √ºbernommen.  In diesem Fall kann die <code>before-hook-creation</code> Abhilfe schaffen. <br><br>  Ein weiteres Beispiel ist die Rotation von Docker-Protokollen.  Angenommen, es gibt eine Anwendung, die aktiv in die Protokolle schreibt.  Unter normalen Umst√§nden k√∂nnen wir alle Protokolle verarbeiten. Sobald jedoch ein Problem auftritt, beispielsweise wie oben beschrieben mit dem falschen Format, wird die Verarbeitung gestoppt und Docker dreht die Datei.  Fazit: Gesch√§ftskritische Protokolle k√∂nnen verloren gehen. <br><br>  Aus diesem Grund ist <b>es wichtig, den Protokollfluss zu trennen</b> und das Senden des Wertvollsten direkt in die Anwendung einzubetten, um deren Sicherheit zu gew√§hrleisten.  Dar√ºber hinaus ist es nicht √ºberfl√ºssig, eine Art <b>‚ÄûAkkumulator‚Äú von Protokollen</b> zu erstellen, die die kurze Nichtverf√ºgbarkeit des Speichers √ºberstehen und gleichzeitig wichtige Nachrichten verwalten k√∂nnen. <br><br>  Vergessen <b>Sie</b> nicht, dass <b>es wichtig ist, jedes Subsystem auf eine qualitative Weise zu √ºberwachen</b> .  Andernfalls kann es leicht vorkommen, dass sich fluentd im <code>CrashLoopBackOff</code> Status befindet und nichts sendet, was den Verlust wichtiger Informationen verspricht. <br><br><h2>  Schlussfolgerungen </h2><br>  In diesem Artikel werden SaaS-L√∂sungen wie Datadog nicht ber√ºcksichtigt.  Viele der hier beschriebenen Probleme wurden bereits auf die eine oder andere Weise von kommerziellen Unternehmen gel√∂st, die auf das Sammeln von Protokollen spezialisiert sind, aber nicht jeder kann SaaS aus verschiedenen Gr√ºnden verwenden <i>(die wichtigsten sind die Kosten und die Einhaltung von 152-)</i> . <br><br>  Die zentralisierte Sammlung von Protokollen sieht zun√§chst nach einer einfachen Aufgabe aus, ist es aber √ºberhaupt nicht.  Es ist wichtig sich daran zu erinnern, dass: <br><br><ul><li>  Die detaillierte Anmeldung ist nur eine wichtige Komponente. F√ºr andere Systeme k√∂nnen Sie die √úberwachung und die Fehlererfassung konfigurieren. </li><li>  Protokolle in der Produktion sollten minimiert werden, um eine zus√§tzliche Belastung zu vermeiden. </li><li>  Protokolle m√ºssen maschinenlesbar, normalisiert und in einem strengen Format vorliegen. </li><li>  Wirklich kritische Protokolle sollten in einem separaten Stream gesendet werden, der von den Hauptprotokollen getrennt werden sollte. </li><li>  Es lohnt sich, eine Protokollbatterie in Betracht zu ziehen, die hohe Belastungsspitzen abf√§ngt und die Belastung des Speichers vergleichm√§√üigt. </li></ul><br><img src="https://habrastorage.org/webt/ss/hd/9f/sshd9fqiav2abndbb_uqo0mdjke.jpeg" align="left"><br>  Diese einfachen Regeln w√ºrden, wenn sie √ºberall angewendet w√ºrden, die oben beschriebenen Schaltkreise funktionieren lassen - obwohl ihnen wichtige Komponenten (Batterie) fehlen.  Wenn Sie sich nicht an diese Grunds√§tze halten, f√ºhrt die Aufgabe Sie und die Infrastruktur leicht zu einer anderen hoch belasteten (und gleichzeitig ineffektiven) Komponente des Systems. <br><br><h2>  PS </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  ‚Äû <a href="https://habr.com/ru/company/flant/blog/341386/">Einf√ºhrung von Loghouse - ein Open-Source-System f√ºr die Arbeit mit Protokollen in Kubernetes</a> ‚Äú; </li><li>  " <a href="https://m.habr.com/ru/news/t/476966/">Releases f√ºr das Kubernetes-√ñkosystem mit KubeCon'19: JFrog Container Registry, Kui von IBM, Loki 1.0.0 ...</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/412901/">Monitoring und Kubernetes (Review und Videobericht)</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de480946/">https://habr.com/ru/post/de480946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de480930/index.html">Gib alles ein</a></li>
<li><a href="../de480936/index.html">Schnelle Konvertierung von UPPER_CASE nach camelCase</a></li>
<li><a href="../de480938/index.html">Kryptow√§hrung aus Sicht russischer Richter</a></li>
<li><a href="../de480940/index.html">F√ºhren Sie einen browser√ºbergreifenden UI-Test mit Cucumber und Selenoid in Gitlab CI mit Allure-Bericht aus</a></li>
<li><a href="../de480944/index.html">Top 5 Trends im E-Mail-Marketing im Jahr 2020</a></li>
<li><a href="../de480948/index.html">Mitap Marketing und PR in Ivanovo</a></li>
<li><a href="../de480950/index.html">Analyse des Android-Quiz vom Stand hh.ru auf der Mobius 2019 in Moskau</a></li>
<li><a href="../de480954/index.html">Aufgabennummer 1. Finden Sie Geschlecht und Verwandtschaftsgrad heraus</a></li>
<li><a href="../de480956/index.html">Wie ich einen Weg gefunden habe, alle Citimobil-Fahrer zu verfolgen</a></li>
<li><a href="../de480958/index.html">Satellitenverbindung. √úbersicht der Betreiberfirmen und ein bisschen √ºber das Rating</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
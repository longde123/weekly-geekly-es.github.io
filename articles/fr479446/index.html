<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>â— ğŸ‘©ğŸ¾â€ğŸ¤ ğŸ› Les voitures ont dÃ©jÃ  une longueur d'avance sur les tests de lecture; mais comprennent-ils ce qu'ils lisent? ğŸ‘©ğŸ¼â€ğŸ”¬ ğŸŒ ğŸ¤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Un outil appelÃ© BERT est capable de dÃ©passer les gens dans les tests de lecture et de comprÃ©hension. Cependant, cela montre Ã©galement dans quelle dire...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Les voitures ont dÃ©jÃ  une longueur d'avance sur les tests de lecture; mais comprennent-ils ce qu'ils lisent?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479446/"><h3>  Un outil appelÃ© BERT est capable de dÃ©passer les gens dans les tests de lecture et de comprÃ©hension.  Cependant, cela montre Ã©galement dans quelle direction l'IA doit encore aller. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/1e6/359/58b/1e635958bf5af44bcc9b6256e1a0101f.jpg"><br><br>  Ã€ l'automne 2017, <a href="http://www.nyu.edu/projects/bowman/">Sam Bowman</a> , linguiste en informatique de l'UniversitÃ© de New York, a dÃ©cidÃ© que les ordinateurs ne comprenaient toujours pas trÃ¨s bien le texte.  Bien sÃ»r, ils ont assez bien appris pour simuler cette comprÃ©hension dans certains domaines Ã©troits, tels que les traductions automatiques ou l'analyse des sentiments (par exemple, pour dÃ©terminer si une phrase est "grossiÃ¨re ou douce", comme il l'a dit).  Cependant, Bowman voulait un tÃ©moignage mesurable: une vÃ©ritable comprÃ©hension de ce qui Ã©tait Ã©crit, dÃ©crit en langage humain.  Et il est venu avec un test. <br><a name="habracut"></a><br>  Dans un article d'avril 2018 rÃ©digÃ© en collaboration avec des collÃ¨gues de l'UniversitÃ© de Washington et de DeepMind, une entreprise appartenant Ã  Google engagÃ©e dans l'intelligence artificielle, Bowman a prÃ©sentÃ© un ensemble de neuf tÃ¢ches de comprÃ©hension en lecture pour les ordinateurs appelÃ©es collectivement GLUE (General Language Understanding Evaluation) [comprÃ©hension de l'Ã©valuation langage gÃ©nÃ©ralisÃ©].  Le test a Ã©tÃ© conÃ§u comme Â«un exemple assez indicatif de ce que la communautÃ© des chercheurs considÃ¨re comme des tÃ¢ches intÃ©ressantesÂ», a dÃ©clarÃ© Bowman, mais d'une maniÃ¨re Â«facile pour les gensÂ».  Par exemple, dans une tÃ¢che, la question est posÃ©e sur la vÃ©ritÃ© d'une phrase, qui doit Ãªtre estimÃ©e sur la base des informations d'une phrase prÃ©cÃ©dente.  Si vous pouvez dire que le message Â«Le prÃ©sident Trump a atterri en Irak, Ã  commencer sa visite de sept joursÂ» implique que Â«le prÃ©sident Trump est en visite Ã  l'Ã©trangerÂ», vous passez le test. <br><br>  Les voitures l'ont manquÃ©.  MÃªme les rÃ©seaux de neurones avancÃ©s n'ont pas obtenu plus de 69 points sur 100 au total pour tous les tests - les trois premiers avec un moins.  Bowman et ses collÃ¨gues n'ont pas Ã©tÃ© surpris.  Les rÃ©seaux de neurones - constructions multicouches avec des connexions de calcul qui ressemblent Ã  peu prÃ¨s au travail des neurones dans le cerveau des mammifÃ¨res - montrent de bons rÃ©sultats dans le domaine du Â«traitement du langage naturelÂ», mais les chercheurs n'Ã©taient pas sÃ»rs que ces systÃ¨mes apprenaient quelque chose de sÃ©rieux la langue.  Et GLUE le prouve.  Â«Les premiers rÃ©sultats montrent que la rÃ©ussite des tests GLUE va au-delÃ  des capacitÃ©s des modÃ¨les et mÃ©thodes existantsÂ», Bowman et al. <br><br>  Mais leur Ã©valuation n'a pas durÃ© longtemps.  En octobre 2018, Google a prÃ©sentÃ© une nouvelle mÃ©thode, BERT (Bidirectional Encoder Representations from Transformers) [prÃ©sentations d'encodeur bidirectionnel pour transformateurs].  Il a reÃ§u un score de 80,5 en COLLE.  En seulement six mois, les voitures sont passÃ©es de trois avec un moins Ã  quatre avec un moins dans ce nouveau test, qui mesure la vÃ©ritable comprÃ©hension du langage naturel par les machines. <br><br>  Â«C'Ã©tait commeÂ« bon sang Â»Â», se souvient Bowman, en utilisant un mot plus colorÃ©.  - Ce message a Ã©tÃ© reÃ§u avec mÃ©fiance par la communautÃ©.  Le BERT a reÃ§u dans de nombreux tests des notes proches de ce que nous considÃ©rions comme le maximum possible. Â»  En effet, avant l'apparition de BERT dans le test GLUE, il n'y avait mÃªme pas d'Ã©valuation des rÃ©alisations humaines Ã  comparer.  Lorsque Bowman et l'un de ses Ã©tudiants diplÃ´mÃ©s les ont ajoutÃ©s Ã  GLUE en fÃ©vrier 2019, ils n'ont durÃ© que quelques mois, puis le modÃ¨le BERT de Microsoft les a Ã©galement <a href="https://blogs.msdn.microsoft.com/stevengu/2019/06/20/microsoft-achieves-human-performance-estimate-on-glue-benchmark/">battus</a> . <br><br>  Au moment d'Ã©crire ces lignes, presque toutes les <a href="https://gluebenchmark.com/leaderboard/">premiÃ¨res places</a> dans les tests GLUE sont occupÃ©es par des systÃ¨mes qui incluent, Ã©tendent ou optimisent le modÃ¨le BERT.  Cinq d'entre eux sont supÃ©rieurs en capacitÃ©s humaines. <br><br>  Mais cela signifie-t-il que l'IA commence Ã  comprendre notre langage, ou apprend-elle simplement Ã  battre nos systÃ¨mes?  AprÃ¨s que les rÃ©seaux de neurones basÃ©s sur le BERT aient pris d'assaut les tests de type GLUE, de nouvelles mÃ©thodes d'Ã©valuation sont apparues qui considÃ©raient ces systÃ¨mes PNL comme des versions informatiques de Â« <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BC%25D0%25BD%25D1%258B%25D0%25B9_%25D0%2593%25D0%25B0%25D0%25BD%25D1%2581">Hans intelligent</a> Â», un cheval qui vivait au dÃ©but du 20e siÃ¨cle et qui Ã©tait censÃ© Ãªtre suffisamment intelligent pour pour faire des calculs arithmÃ©tiques dans l'esprit, mais en fait lire les signes inconscients qui lui sont donnÃ©s par son propriÃ©taire. <br><br>  "Nous savons que nous sommes quelque part dans la zone grise entre la comprÃ©hension de la langue dans un sens trÃ¨s ennuyeux et Ã©troit, et la crÃ©ation de l'IA", a dÃ©clarÃ© Bowman.  - En gÃ©nÃ©ral, la rÃ©action des spÃ©cialistes pourrait Ãªtre dÃ©crite comme suit: Comment cela s'est-il produit?  Qu'est-ce que cela signifie?  Que ferons-nous maintenant? " <br><br><h2>  Ã‰crire vos propres rÃ¨gles </h2><br>  Dans la cÃ©lÃ¨bre expÃ©rience de pensÃ©e Â« <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B8%25D1%2582%25D0%25B0%25D0%25B9%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25BA%25D0%25BE%25D0%25BC%25D0%25BD%25D0%25B0%25D1%2582%25D0%25B0">Salle chinoise</a> Â», une personne qui ne connaÃ®t pas la langue chinoise est assise dans une piÃ¨ce remplie de nombreux livres avec des rÃ¨gles.  Dans les livres, vous pouvez trouver les instructions exactes sur la faÃ§on d'accepter la sÃ©quence de caractÃ¨res chinois entrant dans la piÃ¨ce et de donner une rÃ©ponse appropriÃ©e.  Une personne Ã  l'extÃ©rieur paume des questions Ã©crites en chinois sous la porte de la salle.  La personne Ã  l'intÃ©rieur se tourne vers les livres avec les rÃ¨gles et formule des rÃ©ponses parfaitement raisonnables en chinois. <br><br>  Cette expÃ©rience a Ã©tÃ© utilisÃ©e pour prouver qu'en dÃ©pit de l'impression extÃ©rieure, on ne peut pas dire que la personne dans la piÃ¨ce ait une quelconque comprÃ©hension du chinois.  Cependant, mÃªme une simulation de la comprÃ©hension Ã©tait un objectif acceptable du PNL. <br><br>  Le seul problÃ¨me est le manque de livres parfaits avec des rÃ¨gles, car le langage naturel est trop complexe et peu systÃ©matique pour Ãªtre rÃ©duit Ã  un ensemble solide de spÃ©cifications.  Prenons, par exemple, la syntaxe: rÃ¨gles (y compris empiriques) qui dÃ©terminent le regroupement des mots en phrases significatives.  La phrase Â« <a href="https://books.google.com/books%3Fid%3D55YaAAAAIAAJ%26dq%3Dcolorless%2Bgreen%2Bideas%2Bsleep%2Bfuriously">dormant violemment des idÃ©es vertes incolores</a> Â» a la syntaxe, mais toute personne qui connaÃ®t la langue comprend son absence de sens.  Quel livre de rÃ¨gles spÃ©cialement conÃ§u pourrait inclure ce fait non Ã©crit liÃ© au langage naturel - sans parler d'innombrables autres faits? <br><br>  Les chercheurs de la PNL ont essayÃ© de trouver cette <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B2%25D0%25B0%25D0%25B4%25D1%2580%25D0%25B0%25D1%2582%25D1%2583%25D1%2580%25D0%25B0_%25D0%25BA%25D1%2580%25D1%2583%25D0%25B3%25D0%25B0">quadrature du cercle</a> , forÃ§ant les rÃ©seaux de neurones Ã  Ã©crire leurs propres livres de rÃ¨gles artisanales dans le processus de ce qu'on appelle  "PrÃ©-formation" ou prÃ©-formation. <br><br>  Jusqu'en 2018, l'un des principaux outils de formation Ã©tait quelque chose comme un dictionnaire.  Ce dictionnaire a utilisÃ© une <a href="https://ru.wikipedia.org/wiki/%25D0%2592%25D0%25B5%25D0%25BA%25D1%2582%25D0%25BE%25D1%2580%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25B4%25D1%2581%25D1%2582%25D0%25B0%25D0%25B2%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D1%2581%25D0%25BB%25D0%25BE%25D0%25B2">reprÃ©sentation vectorielle des mots</a> [intÃ©gration de mots], dÃ©crivant les connexions entre les mots sous forme de nombres afin que les rÃ©seaux de neurones puissent percevoir ces informations comme des entrÃ©es - quelque chose comme un glossaire approximatif pour une personne dans une piÃ¨ce chinoise.  Cependant, le prÃ©-formÃ© sur le rÃ©seau de neurones du dictionnaire vectoriel est toujours restÃ© aveugle Ã  la signification des mots au niveau de la phrase.  Â«De son point de vue, les phrasesÂ« l'homme a mordu le chien Â»etÂ« le chien a mordu l'homme Â»sont identiquesÂ», a dÃ©clarÃ© <a href="http://tallinzen.net/">Tel Linsen</a> , linguiste en informatique Ã  l'UniversitÃ© Johns Hopkins. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55a/245/f48/55a245f4866cf5ffcf2689d2161f8536.jpg" width="50%"><br>  <i>Tel Linsen, linguiste en informatique Ã  l'UniversitÃ© Johns Hopkins.</i> <br><br>  La mÃ©thode amÃ©liorÃ©e utilise la prÃ©-formation pour fournir au rÃ©seau neuronal des livres de rÃ¨gles plus riches - non seulement un dictionnaire, mais aussi une syntaxe avec un contexte - avant de lui apprendre Ã  effectuer une tÃ¢che PNL spÃ©cifique.  DÃ©but 2018, des chercheurs d'OpenAI, de l'UniversitÃ© de San Francisco, de l'Institut Allen pour l'intelligence artificielle et de l'UniversitÃ© de Washington ont en mÃªme temps trouvÃ© un moyen dÃ©licat de se rapprocher de cela.  Au lieu d'en former une seule, la premiÃ¨re couche du rÃ©seau utilisant la reprÃ©sentation vectorielle des mots, les chercheurs ont commencÃ© Ã  former l'ensemble du rÃ©seau pour une tÃ¢che plus gÃ©nÃ©rale appelÃ©e modÃ©lisation du langage. <br><br>  Â«La faÃ§on la plus simple de modÃ©liser une langue est la suivante: je vais lire un tas de mots et essayer de prÃ©dire ce qui suitÂ», a expliquÃ© <a href="https://research.fb.com/people/ott-myle/">Mile Ott</a> , un chercheur de Facebook.  "Si je dis, 'George W. Bush est nÃ© en', alors les modÃ¨les doivent prÃ©dire le mot suivant dans cette phrase." <br><br>  De tels modÃ¨les de langage avec une formation approfondie peuvent Ãªtre crÃ©Ã©s assez efficacement.  Les chercheurs alimentent simplement d'Ã©normes quantitÃ©s de texte Ã©crit Ã  partir de ressources gratuites comme Wikipedia vers leurs rÃ©seaux de neurones - des milliards de mots disposÃ©s en phrases grammaticalement correctes - et permettent au rÃ©seau de prÃ©dire le mot suivant par lui-mÃªme.  En fait, cela Ã©quivaut au fait que nous inviterons une personne dans une salle chinoise Ã  crÃ©er son propre ensemble de rÃ¨gles, en utilisant les messages chinois entrants comme rÃ©fÃ©rence. <br><br>  "La beautÃ© de cette approche est que le modÃ¨le acquiert une tonne de connaissances syntaxiques", a dÃ©clarÃ© Ott. <br><br>  De plus, ces rÃ©seaux neuronaux prÃ©-entraÃ®nÃ©s peuvent appliquer leurs reprÃ©sentations du langage pour enseigner une tÃ¢che plus Ã©troite, non liÃ©e Ã  la prÃ©diction de mots, au processus de rÃ©glage fin. <br><br>  "Vous pouvez prendre le modÃ¨le de la phase de prÃ©-formation et l'adapter Ã  n'importe quelle tÃ¢che rÃ©elle dont vous avez besoin", a expliquÃ© Ott.  Â«Et aprÃ¨s cela, vous obtenez de bien meilleurs rÃ©sultats que si vous essayiez de rÃ©soudre votre problÃ¨me directement depuis le tout dÃ©but.Â» <br><br>  En juin 2018, quand OpenAI a prÃ©sentÃ© son <a href="https://openai.com/blog/language-unsupervised/">rÃ©seau neuronal GPT</a> , avec un modÃ¨le de langage inclus, qui a passÃ© un mois Ã  s'entraÃ®ner pour un milliard de mots (tirÃ© de 11038 livres numÃ©riques), son rÃ©sultat dans le test GLUE, 72,8 points, est immÃ©diatement devenu le plus le meilleur.  NÃ©anmoins, Sam Bowman a suggÃ©rÃ© que cette zone se dÃ©veloppera pendant trÃ¨s longtemps avant qu'un systÃ¨me ne puisse au moins se rapprocher du niveau de l'homme. <br><br>  Et puis BERT est apparu. <br><br><h2>  Recette prometteuse </h2><br>  Alors qu'est-ce que le BERT? <br><br>  PremiÃ¨rement, il ne s'agit pas d'un rÃ©seau neuronal entiÃ¨rement formÃ©, capable de fournir immÃ©diatement des rÃ©sultats au niveau humain.  Bowman dit que c'est "une recette trÃ¨s prÃ©cise pour former le rÃ©seau neuronal."  Comme un boulanger peut, en suivant la recette, garantir de donner de dÃ©licieux gÃ¢teaux Ã  gÃ¢teaux - qui peuvent ensuite Ãªtre utilisÃ©s pour diffÃ©rents gÃ¢teaux, de la myrtille Ã  la quiche aux Ã©pinards - et les chercheurs de Google ont crÃ©Ã© une recette BERT qui peut servir de base idÃ©ale pour la "cuisson" des rÃ©seaux de neurones (c'est-Ã -dire , leur affinement), afin de bien gÃ©rer les diffÃ©rentes tÃ¢ches de traitement du langage naturel.  Google a ouvert le code BERT, ce qui signifie que d'autres chercheurs n'ont plus besoin de rÃ©pÃ©ter cette recette Ã  partir de zÃ©ro - ils peuvent simplement le tÃ©lÃ©charger;  c'est un peu comme acheter un gÃ¢teau prÃ©cuit pour un gÃ¢teau dans le magasin. <br><br>  Si BERT est une recette, alors quelle est sa liste d'ingrÃ©dients?  "C'est le rÃ©sultat de trois choses diffÃ©rentes connectÃ©es ensemble pour que le systÃ¨me commence Ã  fonctionner", a dÃ©clarÃ© <a href="https://levyomer.wordpress.com/">Omer Levy</a> , un chercheur de Facebook qui a <a href="https://arxiv.org/abs/1906.04341">analysÃ©</a> le dispositif BERT. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1ee/f23/473/1eef234733ede2389825e047170009e0.jpg" width="50%"><br>  <i>Omer Levy, chercheur Facebook</i> <br><br>  Le premier est le modÃ¨le de langue prÃ©-formÃ©, c'est-Ã -dire ces mÃªmes rÃ©pertoires de la salle chinoise.  La seconde est l'occasion de dÃ©cider quelles caractÃ©ristiques de la proposition sont les plus importantes. <br><br>  En 2017, <a href="http://jakob.uszkoreit.net/">Jacob Uzkoreit</a> , ingÃ©nieur chez Google Brain, a travaillÃ© sur les moyens d'accÃ©lÃ©rer les tentatives de l'entreprise pour comprendre la langue.  Il a notÃ© que tous les rÃ©seaux neuronaux avancÃ©s souffrent de leurs limites inhÃ©rentes: ils Ã©tudient la phrase par des mots.  Une telle Â«sÃ©quenceÂ» semble coÃ¯ncider avec l'idÃ©e de la faÃ§on dont les gens lisent le texte.  Cependant, Uzkoreit est devenu intÃ©ressÃ©, "pourrait-il ne pas Ãªtre que la comprÃ©hension de la langue dans un mode linÃ©aire et sÃ©quentiel ne soit pas la plus optimale." <br><br>  Le taux Ã©troit avec des collÃ¨gues a dÃ©veloppÃ© une nouvelle architecture de rÃ©seaux de neurones, se concentrant sur Â«l'attentionÂ», un mÃ©canisme qui permet Ã  chaque couche d'un rÃ©seau de neurones d'attribuer des poids importants Ã  certaines caractÃ©ristiques des donnÃ©es d'entrÃ©e par rapport Ã  d'autres.  Cette nouvelle architecture avec attention, un transformateur, peut prendre une phrase comme Â«un chien mord l'hommeÂ» en entrÃ©e et encoder chaque mot en parallÃ¨le de diffÃ©rentes maniÃ¨res.  Par exemple, un transformateur peut lier Â«morsuresÂ» et Â«personneÂ» en tant que verbe et sujet-objet, ignorant l'article Â«aÂ»;  en mÃªme temps, elle peut associer Â«morsureÂ» et Â«chienÂ» en tant que verbe et sujet-sujet, ignorant l'article Â«leÂ». <br><br>  La nature incohÃ©rente du transformateur prÃ©sente des phrases de maniÃ¨re plus expressive ou, comme le dit Uzkoreit, semblable Ã  un arbre.  Chaque couche du rÃ©seau neuronal Ã©tablit de nombreuses connexions parallÃ¨les entre certains mots, ignorant le reste - Ã  peu prÃ¨s comment un Ã©lÃ¨ve du primaire dÃ©sassemble une phrase en plusieurs parties.  Ces connexions sont souvent Ã©tablies entre des mots qui peuvent ne pas Ãªtre proches.  "De telles structures ressemblent Ã  une superposition de plusieurs arbres", a expliquÃ© Uzkoreit. <br><br>  De telles reprÃ©sentations arborescentes de phrases donnent aux transformateurs l'occasion de modÃ©liser des significations contextuelles, ainsi que d'Ã©tudier efficacement les liens entre des mots trÃ¨s Ã©loignÃ©s dans des phrases complexes.  "C'est quelque peu contre-intuitif", a dÃ©clarÃ© Uzkoreit, "mais vient de la linguistique, qui a longtemps Ã©tÃ© impliquÃ©e dans les modÃ¨les de langage arborescent." <br><br><img src="https://habrastorage.org/getpro/habr/post_images/21e/0a1/fe2/21e0a1fe2331c110f5cb2a966b2b173d.jpg" width="50%"><br>  <i>Jacob Uzkoreit, chef de l'Ã©quipe berlinoise Google AI Brain</i> <br><br>  Enfin, le troisiÃ¨me ingrÃ©dient de la recette BERT Ã©tend encore plus la lecture non linÃ©aire. <br><br>  Contrairement aux autres modÃ¨les de langage prÃ©-formÃ©s crÃ©Ã©s par le traitement de tÃ©raoctets de texte de gauche Ã  droite par les rÃ©seaux de neurones, le modÃ¨le BERT lit de droite Ã  gauche et simultanÃ©ment de gauche Ã  droite, et apprend Ã  prÃ©dire quels mots ont Ã©tÃ© exclus au hasard des phrases.  Par exemple, le BERT peut accepter une phrase de la forme Â«George W. Bush [...] dans le Connecticut en 1946Â» et prÃ©dire quel mot est cachÃ© au milieu de la phrase (dans ce cas, Â«nÃ©Â»), aprÃ¨s avoir traitÃ© le texte dans les deux sens.  "Cette bi-directionalitÃ© oblige le rÃ©seau de neurones Ã  extraire autant d'informations que possible de n'importe quel sous-ensemble de mots", a dÃ©clarÃ© Uzkoreit. <br><br>  La simulation basÃ©e sur BERT utilisÃ©e comme un jeu de mots - modÃ©lisation du langage avec masquage - n'est pas une chose nouvelle.  Il est utilisÃ© depuis des dÃ©cennies pour mesurer la comprÃ©hension de la langue par les gens.  Pour Google, il a fourni un moyen pratique d'utiliser la bi-directionalitÃ© dans les rÃ©seaux de neurones au lieu des mÃ©thodes de prÃ©-formation Ã  sens unique qui avaient dominÃ© ce domaine auparavant.  "Avant BERT, la modÃ©lisation unidirectionnelle du langage Ã©tait la norme, bien qu'il s'agisse d'une limitation facultative", a dÃ©clarÃ© <a href="https://kentonl.com/">Kenton Lee</a> , chercheur chez Google. <br><br>  Chacun de ces trois ingrÃ©dients - un modÃ¨le de langage profond avec prÃ©-formation, attention et bidirectionnalitÃ© - existait avant BERT sÃ©parÃ©ment.  Mais jusqu'Ã  ce que Google publie sa recette fin 2018, personne ne les a combinÃ©s avec autant de succÃ¨s. <br><br><h2>  Affiner la recette </h2><br>  Comme toute bonne recette, le BRET a rapidement Ã©tÃ© adaptÃ© par diffÃ©rents chefs Ã  leurs goÃ»ts.  Au printemps 2019, il y a eu une pÃ©riode Â«oÃ¹ Microsoft et Alibaba se sont succÃ©dÃ©, changeant de place chaque semaine dans le classement, ajustant leur modÃ¨leÂ», se souvient Bowman.  Lorsque la version amÃ©liorÃ©e de BERT a Ã©tÃ© publiÃ©e pour la premiÃ¨re fois en aoÃ»t sous le nom de RoBERTa, le chercheur <a href="http://ruder.io/">Sebastian Ruder</a> de DeepMind a sÃ¨chement remarquÃ© dans son populaire <a href="http://newsletter.ruder.io/issues/nlp-in-industry-leaderboard-madness-fast-ai-nlp-transfer-learning-tools-186245">bulletin NLP</a> : "Nouveau mois, et un nouveau modÃ¨le de langage avancÃ© avec prÃ©-formation." <br><br>  Comme le gÃ¢teau, BERT a plusieurs dÃ©cisions de conception qui affectent la qualitÃ© de son travail.  Cela inclut la taille du rÃ©seau neuronal cuit, la quantitÃ© de donnÃ©es utilisÃ©es pour la prÃ©-formation, la mÃ©thode de masquage des mots et la durÃ©e pendant laquelle le rÃ©seau neuronal a travaillÃ© avec ces donnÃ©es.  Et dans les recettes suivantes, comme RoBERTa, les chercheurs modifient ces dÃ©cisions - comme un chef spÃ©cifiant une recette. <br><br>  Dans le cas de RoBERTa, des chercheurs de Facebook et de l'UniversitÃ© de Washington ont augmentÃ© le nombre de certains ingrÃ©dients (donnÃ©es de prÃ©-formation, longueur des sÃ©quences entrantes, temps de formation), un ingrÃ©dient a Ã©tÃ© supprimÃ© (la tÃ¢che de Â«prÃ©dire la phrase suivanteÂ», qui Ã©tait Ã  l'origine dans le BERT et a affectÃ© nÃ©gativement les rÃ©sultats ), et l'autre a Ã©tÃ© modifiÃ© (compliquÃ© la tÃ¢che de masquer des mots individuels).  En consÃ©quence, ils ont briÃ¨vement pris la premiÃ¨re place du classement GLUE.  Six semaines plus tard, des chercheurs de Microsoft et de l'UniversitÃ© du Maryland ont <a href="https://arxiv.org/abs/1909.11764">ajoutÃ©</a> leurs amÃ©liorations Ã  RoBERTa et ont remportÃ© la prochaine victoire.  Ã€ l'heure actuelle, un autre modÃ¨le a pris la premiÃ¨re place dans GLUE, ALBERT (une abrÃ©viation de Â«lite BERTÂ», c'est-Ã -dire Â«lite BERTÂ»), qui a lÃ©gÃ¨rement modifiÃ© la structure de base de BERT. <br><br>  Â«Nous essayons toujours de dÃ©terminer quelles recettes fonctionnent, lesquelles ne fonctionnent pasÂ», a dÃ©clarÃ© Ott de Facebook, qui a travaillÃ© sur RoBERTa. <br><br>  Mais, comme l'amÃ©lioration de la technique de prÃ©-cuisson des gÃ¢teaux ne vous apprend pas les bases de la chimie, l'amÃ©lioration progressive du BERT ne vous apportera pas particuliÃ¨rement de connaissances thÃ©oriques sur le dÃ©veloppement de la PNL.  Â«Je serai extrÃªmement honnÃªte avec vous - je ne suis pas ces travaux, car pour moi, ils sont extrÃªmement ennuyeuxÂ», a dÃ©clarÃ© Linsen, linguiste en informatique Ã  l'UniversitÃ© Johns Hopkins.  Â«Il y a un certain mystÃ¨re scientifiqueÂ», admet-il, mais pas comment rendre le BERT et tous ses descendants plus intelligents, et mÃªme pas pour comprendre pourquoi ils sont si intelligents.  Au lieu de cela, Â«nous essayons de comprendre dans quelle mesure ces modÃ¨les comprennent vraiment le langageÂ», a-t-il dit, Â«plutÃ´t que d'apprendre des trucs Ã©tranges qui fonctionnent d'une maniÃ¨re ou d'une autre sur les ensembles de donnÃ©es sur lesquels nous Ã©valuons habituellement ces modÃ¨lesÂ». <br><br>  En d'autres termes, le BERT fait quelque chose de bien.  Mais que faire s'il le fait pour la mauvaise raison? <br><br><h2>  DÃ©licat mais pas intelligent </h2><br>  En juillet 2019, deux chercheurs de l'UniversitÃ© d'Ã‰tat de TaÃ¯wan, Cheng Kun, ont utilisÃ© le BERT avec des rÃ©sultats impressionnants sur un test de performance relativement peu connu appelÃ© Â«tÃ¢che de comprÃ©hension des argumentsÂ».  Pour terminer la tÃ¢che, il est nÃ©cessaire de choisir une condition initiale implicite (Â«fondationÂ») qui supporte l'argument en faveur de toute dÃ©claration.  Par exemple, pour prouver que Â«le tabagisme cause le cancerÂ» (dÃ©claration) puisque Â«les Ã©tudes scientifiques ont montrÃ© un lien entre le tabagisme et le cancerÂ» (argumentation), vous devez choisir l'argument Â«la recherche scientifique peut faire confianceÂ» (Â«fondationÂ»), et pas une autre option: Â«La recherche scientifique coÃ»te cherÂ» (mÃªme si cela n'est cependant pas pertinent dans ce contexte).  Tout est-il clair? <br><br>  Sinon, ne vous inquiÃ©tez pas.  MÃªme les gens ne sont pas trÃ¨s bons dans cette tÃ¢che sans pratique.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La valeur de rÃ©fÃ©rence moyenne pour une personne qui ne fait pas d'exercice est de 80 sur 100. Le BERT a atteint 77, ce qui, selon les auteurs, Ã©tait Â«inattenduÂ».</font></font><br><br>   ,  ,  BERT        ,  ,      : BERT      .  ,    ,       .. Â« Â».  ,     ,   Â«Â»,       61% .      ,  ,   BERT   77  53 â€“     .       The Gradient     , <a href="https://thegradient.pub/nlps-clever-hans-moment-has-arrived/"></a> BERT  Â« Â», ,    . <br><br>   , " <a href="https://www.aclweb.org/anthology/P19-1334">   </a> ",      ,    BERT    GLUE           .       ,  ,   BERT    .     (Heuristic Analysis for Natural-Language-Inference Systems, HANS) [  ,      ]. <br><br>   , BERT    ,    â€“   ?      ,     GLUE  .    ,    ,          BERT. Â« -  ,        GLUE,     â€ â€œ,    , â€”  , â€”     Â».    ,    BERT   . Â« , -,  ,  -    , â€”  . â€“           Â». <br><br>    ,         ,           â€“       BERT,       ,    ,        Â« Â».       Â« Â»,        NLP   ,          .     Â« BERT   Â»,  ,  Â«     Â». <br><br>      NLP ,                   .    , BERT        .     Â«   NLP,        Â», â€”  <a href="https://www.cs.uml.edu/~arogers/"> </a> ,         . ,     ,          ,            ,     ,   . <br><br>  ,    ,      ,      .         .    ,    . Â«    ,       ,       ,           Â», â€”  . <br><br>         <a href="https://super.gluebenchmark.com/leaderboard">SuperGLUE</a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">spÃ©cialement conÃ§u pour Ãªtre complexe pour les systÃ¨mes basÃ©s sur BERT. Jusqu'Ã  prÃ©sent, aucun rÃ©seau n'a pu doubler une personne. Mais mÃªme si (ou quand) cela se produit, cela signifie-t-il que les machines peuvent apprendre Ã  mieux comprendre le langage qu'auparavant? Ou est-ce juste que la science deviendra meilleure pour enseigner aux machines comment rÃ©ussir ce test?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Bonne analogie", a dÃ©clarÃ© Bowman. </font><font style="vertical-align: inherit;">Â«Nous avons compris comment rÃ©ussir les tests LSAT et MCAT, mais nous n'avons peut-Ãªtre pas les qualifications nÃ©cessaires pour devenir mÃ©decins ou avocats.Â» </font><font style="vertical-align: inherit;">Et pourtant, Ã  en juger par tout, c'est exactement ainsi que la recherche dans le domaine de l'IA Ã©volue. </font><font style="vertical-align: inherit;">"Les Ã©checs semblaient Ãªtre un sÃ©rieux test d'intelligence jusqu'Ã  ce que nous trouvions comment Ã©crire un programme pour le jeu", a-t-il dÃ©clarÃ©. </font><font style="vertical-align: inherit;">Â«Nous sommes dÃ©finitivement entrÃ©s dans une Ã¨re oÃ¹ l'objectif Ã©tait d'inventer des tÃ¢ches de plus en plus complexes qui reprÃ©sentent une comprÃ©hension de la langue et de trouver des moyens de les rÃ©soudre.Â»</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr479446/">https://habr.com/ru/post/fr479446/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr479428/index.html">Ã‰vÃ©nements numÃ©riques Ã  Moscou du 9 au 15 dÃ©cembre</a></li>
<li><a href="../fr479430/index.html">Ã‰vÃ©nements numÃ©riques Ã  Saint-PÃ©tersbourg du 9 au 15 dÃ©cembre</a></li>
<li><a href="../fr479432/index.html">Yandex.Maps: Je suis allÃ© au contrÃ´leur de carte - j'ai immÃ©diatement obtenu la position de l'utilisateur (d'accord, maintenant sÃ©rieusement)</a></li>
<li><a href="../fr479438/index.html">Postgres-Tuesday # 5: Â«PostgreSQL et Kubernetes. CI / CD. Automatisation des tests Â»</a></li>
<li><a href="../fr479442/index.html">Alexey Savvateev: ModÃ¨le de schisme social de la thÃ©orie des jeux (+ enquÃªte nginx)</a></li>
<li><a href="../fr479450/index.html">AppCode 2019.3: fonctionne plus rapidement, comprend mieux Swift, connaÃ®t Mac Catalyst et affiche facilement les messages d'assemblage</a></li>
<li><a href="../fr479452/index.html">Comment le systÃ¨me de noms de domaine s'est dÃ©veloppÃ©: l'Ã¨re ARPANET</a></li>
<li><a href="../fr479458/index.html">BeautÃ© ou praticitÃ© dans la salle des serveurs</a></li>
<li><a href="../fr479460/index.html">Un guide pour les voitures volantes</a></li>
<li><a href="../fr479462/index.html">SÃ©rialisation en C ++</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
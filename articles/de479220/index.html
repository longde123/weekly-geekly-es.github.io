<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐩 💣 🙌 Nano-Neuron - 7 einfache JavaScript-Funktionen, die zeigen, wie die Maschine "lernen" kann 🤛🏽 🙂 🦇</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ein Nano-Neuron ist eine vereinfachte Version eines Neurons aus dem Konzept eines neuronalen Netzwerks. Nano-Neuron erfüllt die einfachste Aufgabe und...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nano-Neuron - 7 einfache JavaScript-Funktionen, die zeigen, wie die Maschine "lernen" kann</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479220/"><p>  <a href="https://github.com/trekhleb/nano-neuron" rel="nofollow"><strong>Ein Nano-Neuron</strong></a> ist eine <em>vereinfachte</em> Version eines Neurons aus dem Konzept eines neuronalen Netzwerks.  Nano-Neuron erfüllt die einfachste Aufgabe und ist darauf trainiert, Temperaturen von Grad Celsius in Grad Fahrenheit umzuwandeln. </p><br><p>  Der Code von <a href="" rel="nofollow"><strong>NanoNeuron.js</strong></a> besteht aus 7 einfachen JavaScript-Funktionen, die das Lernen, Trainieren, Vorhersagen sowie die direkte und Rückwärtsausbreitung des Modellsignals umfassen.  Der Zweck des Schreibens dieser Funktionen bestand darin, dem Leser eine minimale, grundlegende Erklärung (Intuition) zu geben, wie eine Maschine schließlich "lernen" kann.  Der Code verwendet keine Bibliotheken von Drittanbietern.  Wie das Sprichwort sagt, funktioniert nur einfaches "Vanille" JavaScript. </p><br><p>  Diese Funktionen sind <strong>keine</strong> vollständige Anleitung zum maschinellen Lernen.  Viele maschinelle Lernkonzepte fehlen oder sind vereinfacht!  Diese Vereinfachung dient einzig und allein dem Zweck, dem Leser das <strong>grundlegendste</strong> Verständnis und die Intuition dafür zu vermitteln, wie eine Maschine im Prinzip "lernen" kann, so dass sich "MAGIE des maschinellen Lernens" für den Leser immer mehr als "MATHEMATIK des maschinellen Lernens" anhört. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/98d/6c4/69e/98d6c469e1facbf97154fe29f698cd12.png" alt="Nanoneuron"></p><a name="habracut"></a><br><h2 id="chto-vyuchit-nash-nano-neyron">  Was unser Nano-Neuron "lernen" wird </h2><br><p>  Möglicherweise haben Sie im Zusammenhang mit <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D1%2581%25D0%25BA%25D1%2583%25D1%2581%25D1%2581%25D1%2582%25D0%25B2%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C" rel="nofollow">neuronalen Netzen</a> von Neuronen gehört.  Ein Nano-Neuron ist eine vereinfachte Version desselben Neurons.  In diesem Beispiel schreiben wir die Implementierung von Grund auf neu.  Der Einfachheit halber werden wir kein Netzwerk von Nano-Neuronen aufbauen.  Wir werden uns darauf konzentrieren, ein einziges Nano-Neuron zu erzeugen und ihm beizubringen, wie man die Temperatur von Grad Celsius in Grad Fahrenheit umwandelt.  Mit anderen Worten, wir werden ihm beibringen <strong>, die</strong> Temperatur in Grad Fahrenheit basierend auf der Temperatur in Grad Celsius <strong>vorherzusagen</strong> . </p><br><p>  Übrigens lautet die Formel zum Umrechnen von Grad Celsius in Grad Fahrenheit wie folgt: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/9fa/2e8/8b5/9fa2e88b5a7324c8b9fc359b274ba091.png" alt="Celsius in Fahrenheit"></p><br><p>  Aber im Moment weiß unser Nano-Neuron nichts über diese Formel ... </p><br><h3 id="model-nano-neyrona">  Nano-Neuronen-Modell </h3><br><p> Beginnen wir mit der Erstellung einer Funktion, die das Modell unseres Nano-Neurons beschreibt.  Dieses Modell ist eine einfache lineare Beziehung zwischen <code>x</code> und <code>y</code> , die so aussieht: <code>y = w * x + b</code> .  Einfach ausgedrückt, unser Nano-Neuron ist ein Kind, das im <code>XY</code> Koordinatensystem eine gerade Linie zeichnen kann. </p><br><p>  Die Variablen <code>w</code> und <code>b</code> sind Modellparameter.  Ein Nano-Neuron kennt nur diese beiden Parameter einer linearen Funktion.  Genau diese Parameter lernt unser Nano-Neuron während des Trainingsprozesses. </p><br><p>  Das einzige, was ein Nano-Neuron in dieser Phase tun kann, ist die Simulation linearer Beziehungen.  Er tut dies in der <code>predict()</code> -Methode, die eine Variable <code>x</code> am Eingang und die Variable <code>y</code> am Ausgang voraussagt.  Keine Magie. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">NanoNeuron</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">w, b</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.w = w; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.b = b; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.predict = <span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">x</span></span></span><span class="hljs-function">) =&gt;</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x * <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.w + <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.b; } }</code> </pre> <br><p>  _ (... warte ... <a href="https://en.wikipedia.org/wiki/Linear_regression" rel="nofollow">lineare Regression</a> bist du, oder was?) _ </p><br><h3 id="konvertaciya-gradusov-celsiya-v-gradusy-farengeyta">  Berechne Grad Celsius in Grad Fahrenheit </h3><br><p>  Die Temperatur in Grad Celsius kann nach der Formel in Grad Fahrenheit umgerechnet werden: <code>f = 1.8 * c + 32</code> , wobei <code>c</code> die Temperatur in Grad Celsius und <code>f</code> die Temperatur in Grad Fahrenheit ist. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">celsiusToFahrenheit</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">c</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> w = <span class="hljs-number"><span class="hljs-number">1.8</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> b = <span class="hljs-number"><span class="hljs-number">32</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> f = c * w + b; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> f; };</code> </pre> <br><p>  Daher möchten wir, dass unser Nano-Neuron diese spezielle Funktion simuliert.  Er muss erraten (lernen), dass der Parameter <code>w = 1.8</code> und <code>b = 32</code> ohne es vorher zu wissen. </p><br><p>  So sieht die Konvertierungsfunktion im Diagramm aus.  Das ist es, was unser nano-neuronales "Baby" lernen muss, zu "zeichnen": </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/68b/0d6/8bc/68b0d68bcc7be00ec9526867b2fcecf3.png" alt="Celsius in Fahrenheit umwandeln"></p><br><h3 id="generirovanie-dannyh">  Datengenerierung </h3><br><p>  In der klassischen Programmierung kennen wir die Eingabedaten ( <code>x</code> ) und den Algorithmus zur Konvertierung dieser Daten (Parameter <code>w</code> und <code>b</code> ), aber die Ausgabedaten ( <code>y</code> ) sind unbekannt.  Die Ausgabe wird basierend auf der Eingabe unter Verwendung eines bekannten Algorithmus berechnet.  Im Gegensatz dazu sind beim maschinellen Lernen nur die Eingabe- und Ausgabedaten ( <code>x</code> und <code>y</code> ) bekannt, der Algorithmus zum Umschalten von <code>x</code> auf <code>y</code> unbekannt (Parameter <code>w</code> und <code>b</code> ). </p><br><p>  Es ist die Erzeugung von Input und Output, die wir jetzt tun werden.  Wir müssen Daten zum <strong>Trainieren</strong> unseres Modells und Daten zum <strong>Testen des</strong> Modells generieren.  Die <code>celsiusToFahrenheit()</code> hilft uns dabei.  Jeder der Trainings- und Testdatensätze ist ein Satz von Paaren <code>x</code> und <code>y</code> .  Wenn beispielsweise <code>x = 2</code> , dann ist <code>y = 35,6</code> und so weiter. </p><br><blockquote>  In der realen Welt werden die meisten Daten wahrscheinlich <em>gesammelt</em> und nicht <em>generiert</em> .  Bei solchen gesammelten Daten kann es sich beispielsweise um ein Paar von "Gesichtsfotos" -&gt; "Name der Person" handeln. </blockquote><p>  Wir werden den TRAINING-Datensatz verwenden, um unser Nano-Neuron zu trainieren.  Bevor er erwachsen wird und in der Lage ist, selbst Entscheidungen zu treffen, müssen wir ihm beibringen, was „wahr“ und was „falsch“ ist, indem wir „korrekte“ Daten aus einem Trainingssatz verwenden. </p><br><blockquote>  Übrigens wird hier das Lebensprinzip „Müll am Eingang - Müll am Ausgang“ deutlich nachvollzogen.  Wenn ein Nano-Neuron eine „Lüge“ in das Trainingskit wirft, dass 5 ° C in 1000 ° F umgewandelt werden, dann wird er dies nach vielen Trainingsiterationen glauben und alle Temperaturwerte mit <strong>Ausnahme von</strong> 5 ° C korrekt konvertieren.  Wir müssen mit den Trainingsdaten, die wir täglich in unser neuronales Gehirnnetzwerk laden, sehr vorsichtig sein. </blockquote><p>  Abgelenkt.  Lass uns weitermachen. </p><br><p>  Wir werden den TEST-Datensatz verwenden, um zu bewerten, wie gut unser Nano-Neuron trainiert hat, und können korrekte Vorhersagen für neue Daten treffen, die er während seines Trainings nicht gesehen hat. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generateDataSets</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// xTrain -&gt; [0, 1, 2, ...], // yTrain -&gt; [32, 33.8, 35.6, ...] const xTrain = []; const yTrain = []; for (let x = 0; x &lt; 100; x += 1) { const y = celsiusToFahrenheit(x); xTrain.push(x); yTrain.push(y); } // xTest -&gt; [0.5, 1.5, 2.5, ...] // yTest -&gt; [32.9, 34.7, 36.5, ...] const xTest = []; const yTest = []; //   0.5    1,       //   ,       . for (let x = 0.5; x &lt; 100; x += 1) { const y = celsiusToFahrenheit(x); xTest.push(x); yTest.push(y); } return [xTrain, yTrain, xTest, yTest]; }</span></span></code> </pre> <br><h3 id="ocenka-pogreshnosti-predskazaniy">  Vorhersagefehlerschätzung </h3><br><p>  Wir brauchen eine bestimmte Metrik (Messung, Anzahl, Bewertung), die zeigt, wie nahe die Vorhersage eines Nano-Neurons an der Wahrheit liegt.  Mit anderen Worten, diese Zahl / Metrik / Funktion sollte zeigen, wie richtig oder falsch das Nano-Neuron ist.  Es ist wie in der Schule, ein Schüler kann eine Note von <code>5</code> oder <code>2</code> für seine Kontrolle bekommen. </p><br><p>  Im Fall eines Nano-Neurons wird sein Fehler (Fehler) zwischen dem wahren Wert von <code>y</code> und dem vorhergesagten Wert der <code>prediction</code> durch die Formel erzeugt: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8d8/e50/ac1/8d8e50ac12d03614e65975f7b5d36931.png" alt="Vorhersagekosten"></p><br><p>  Wie aus der Formel hervorgeht, betrachten wir den Fehler als einen einfachen Unterschied zwischen den beiden Werten.  Je näher die Werte beieinander liegen, desto geringer ist der Unterschied.  Wir verwenden hier die Quadratur, um das Zeichen zu entfernen, sodass <code>(1 - 2) ^ 2</code> am Ende <code>(2 - 1) ^ 2</code> .  Die Division durch <code>2</code> erfolgt nur, um die Bedeutung der Ableitung dieser Funktion in der Formel für die Rückausbreitung eines Signals zu vereinfachen (mehr dazu weiter unten). </p><br><p>  Die Fehlerfunktion sieht in diesem Fall folgendermaßen aus: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predictionCost</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">y, prediction</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (y - prediction) ** <span class="hljs-number"><span class="hljs-number">2</span></span> / <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 235.6 }</span></span></code> </pre> <br><h3 id="pryamoe-rasprostranenie-signala">  Direkte Signalausbreitung </h3><br><p>  Direkte Signalausbreitung durch unser Modell bedeutet, Vorhersagen für alle Paare aus dem <code>xTrain</code> und <code>yTrain</code> Trainingsdatensatz zu <code>yTrain</code> und den durchschnittlichen Fehler (Fehler) dieser Vorhersagen zu berechnen. </p><br><p>  Wir lassen unser Nano-Neuron einfach „sprechen“, damit es Vorhersagen treffen kann (Temperatur umwandeln).  Gleichzeitig kann ein Nano-Neuron in diesem Stadium sehr falsch sein.  Der Durchschnittswert des Vorhersagefehlers zeigt uns, wie weit unser Modell derzeit der Wahrheit entspricht.  Der Wert des Fehlers ist hier sehr wichtig, da wir durch Ändern der Parameter <code>w</code> und <code>b</code> und direktes Weiterleiten des Signals auswerten können, ob unser Nano-Neuron mit neuen Parametern „intelligenter“ geworden ist oder nicht. </p><br><p>  Der durchschnittliche Vorhersagefehler eines Nano-Neurons wird mit der folgenden Formel berechnet: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/575/db3/e0a/575db3e0a0c872b29582147e41231344.png" alt="Durchschnittskosten"></p><br><p>  Wobei <code>m</code> die Anzahl der Trainingskopien ist (in unserem Fall haben wir <code>100</code> Datenpaare). </p><br><p>  So können wir dies in Code implementieren: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forwardPropagation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">model, xTrain, yTrain</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> m = xTrain.length; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> predictions = []; <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cost = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">let</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; m; i += <span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> prediction = nanoNeuron.predict(xTrain[i]); cost += predictionCost(yTrain[i], prediction); predictions.push(prediction); } <span class="hljs-comment"><span class="hljs-comment">//     . cost /= m; return [predictions, cost]; }</span></span></code> </pre> <br><h3 id="obratnoe-rasprostranenie-signala">  Signalumkehrung </h3><br><p>  Nun, da wir wissen, wie richtig oder falsch unsere Nano-Neuronen in ihren Vorhersagen sind (basierend auf dem Durchschnittswert des Fehlers), wie können wir die Vorhersagen genauer machen? </p><br><p>  Die umgekehrte Signalausbreitung hilft uns dabei.  Bei der Signalrückübertragung wird der Fehler eines Nano-Neurons bewertet und anschließend dessen Parameter <code>w</code> und <code>b</code> so <code>b</code> , dass die nächsten Vorhersagen des Nano-Neurons für den gesamten Satz von Trainingsdaten etwas genauer werden. </p><br><p>  Hier wird maschinelles Lernen zur Magie.  Das Schlüsselkonzept ist hier eine <strong>Ableitung der Funktion</strong> , die zeigt, welchen Größenschritt und welchen Weg wir gehen müssen, um uns dem Minimum der Funktion (in unserem Fall dem Minimum der Fehlerfunktion) zu nähern. </p><br><p>  Das ultimative Ziel beim Training eines Nano-Neurons ist es, das Minimum der Fehlerfunktion zu finden (siehe Funktion oben).  Wenn wir solche Werte von <code>w</code> und <code>b</code> bei denen der Durchschnittswert der Fehlerfunktion klein ist, bedeutet dies, dass unser Nano-Neuron mit Temperaturvorhersagen in Grad Fahrenheit gut zurechtkommt. </p><br><p>  Derivate sind ein großes und eigenständiges Thema, das wir in diesem Artikel nicht behandeln werden.  <a href="https://www.mathsisfun.com/calculus/derivatives-introduction.html" rel="nofollow">MathIsFun</a> ist eine großartige Ressource, die ein grundlegendes Verständnis von Derivaten vermitteln kann. </p><br><p>  Eine Sache, die wir aus dem Wesen einer Ableitung lernen müssen und die uns helfen wird zu verstehen, wie die Rückausbreitung eines Signals funktioniert, ist, dass die Ableitung einer Funktion an einem bestimmten Punkt <code>x</code> und <code>y</code> per Definition eine Tangente an die Kurve dieser Funktion bei <code>x</code> und ist <code>y</code> und <em>zeigt uns die Richtung zum Minimum der Funktion an</em> . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/66d/bfd/49a/66dbfd49aaf1ced48d7f6b5917fddb12.svg" alt="Ableitung Steigung"></p><br><p>  <em>Bild aus <a href="https://www.mathsisfun.com/calculus/derivatives-introduction.html" rel="nofollow">MathIsFun genommen</a></em> </p><br><p>  In der obigen Grafik sehen Sie beispielsweise, dass am Punkt <code>(x=2, y=4)</code> Neigung der Tangente uns anzeigt, dass wir uns nach <code></code> und <code></code> bewegen <code></code> , um zum Minimum der Funktion zu gelangen.  Beachten Sie auch, dass wir uns umso schneller zum kleinsten Punkt bewegen müssen, je größer die Neigung der Tangente ist. </p><br><p>  Die Ableitungen unserer durchschnittlichen Fehlerfunktion <code>averageCost</code> in <code>averageCost</code> auf die Parameter <code>w</code> und <code>b</code> sehen folgendermaßen aus: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/4cc/bda/ba1/4ccbdaba120c399c1528e2bc38cf0efd.png" alt="dW"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/e02/0cb/125/e020cb125449849009a9f565a32ff46f.png" alt="dB"></p><br><p>  Wobei <code>m</code> die Anzahl der Trainingskopien ist (in unserem Fall haben wir <code>100</code> Datenpaare). </p><br><p>  <em>Hier erfahren Sie ausführlicher, wie Sie die Ableitung komplexer Funktionen übernehmen.</em> </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">backwardPropagation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">predictions, xTrain, yTrain</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> m = xTrain.length; <span class="hljs-comment"><span class="hljs-comment">//           'w'  'b'. //      0. let dW = 0; let dB = 0; for (let i = 0; i &lt; m; i += 1) { dW += (yTrain[i] - predictions[i]) * xTrain[i]; dB += yTrain[i] - predictions[i]; } //    . dW /= m; dB /= m; return [dW, dB]; }</span></span></code> </pre> <br><h3 id="trenirovka-modeli">  Model Training </h3><br><p>  Jetzt wissen wir, wie wir den Fehler der Vorhersagen unseres Nano-Neuron-Modells für alle Trainingsdaten abschätzen können (direkte Signalausbreitung).  Wir wissen auch, wie man die Parameter <code>w</code> und <code>b</code> Nano-Neuronen-Modells (Rückausbreitung des Signals) anpasst, um die Genauigkeit der Vorhersagen zu verbessern.  Das Problem ist, dass wenn wir das Signal nur einmal vorwärts und rückwärts ausbreiten, dies nicht ausreicht, damit unser Modell die Abhängigkeiten und Gesetze in den Trainingsdaten erkennt und lernt.  Sie können dies mit dem eintägigen Schulbesuch eines Schülers vergleichen.  Er / sie muss regelmäßig, Tag für Tag, Jahr für Jahr zur Schule gehen, um das gesamte Material zu lernen. </p><br><p>  Wir müssen also <em>die</em> Vorwärts- und Rückwärtsausbreitung des Signals viele Male <em>wiederholen</em> .  <code>trainModel()</code> Funktion.  Sie ist wie eine "Lehrerin" für das Modell unseres Nano-Neurons: </p><br><ul><li>  Sie wird einige Zeit ( <code>epochs</code> ) mit unserem immer noch albernen Nano-Neuron verbringen und versuchen, ihn zu trainieren. </li><li>  Sie wird spezielle Bücher ( <code>xTrain</code> und <code>yTrain</code> Datensätze) für das Training verwenden. </li><li>  es ermutigt unseren „Schüler“, fleißiger (schneller) mit dem <code>alpha</code> Parameter zu lernen, der im Wesentlichen die Lerngeschwindigkeit steuert. </li></ul><br><p>  Ein paar Worte zum <code>alpha</code> Parameter.  Dies ist nur ein Koeffizient (Multiplikator) für die Werte der Variablen <code>dW</code> und <code>dB</code> , die wir während der <code>dW</code> des Signals berechnen.  Die Ableitung zeigte uns also die Richtung zum Minimum der Fehlerfunktion (die Vorzeichen der Werte von <code>dW</code> und <code>dB</code> sagen dies aus).  Die Ableitung zeigte uns auch, wie schnell wir uns dem Minimum der Funktion <code>dW</code> müssen (die absoluten Werte von <code>dW</code> und <code>dB</code> sagen dies aus).  Jetzt müssen wir die Schrittgröße mit <code>alpha</code> multiplizieren, um die Geschwindigkeit unserer Annäherung auf ein Minimum (die Gesamtschrittgröße) einzustellen.  Wenn wir für <code>alpha</code> große Werte verwenden, können wir manchmal so große Schritte ausführen, dass wir einfach <em>über das</em> Minimum der Funktion springen und diese überspringen können. </p><br><p>  In Analogie zur „Lehrerin“, je stärker sie unsere „Nano-Schülerin“ zum Lernen zwingen würde, desto schneller würde er lernen, ABER wenn Sie ihn sehr stark zwingen und unter Druck setzen, könnte unsere „Nano-Schülerin“ einen Nervenzusammenbruch erleben und völlige Apathie und er wird überhaupt nichts lernen. </p><br><p>  Wir werden die Parameter unseres Modells <code>w</code> und <code>b</code> wie folgt aktualisieren: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c7b/db8/84f/c7bdb884f2a940d62332246cdbcb44bc.png" alt="w"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b57/622/0ab/b576220ab6515d44255ef56699077bab.png" alt="b"></p><br><p>  Und so sieht das Training selbst aus: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trainModel</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">{model, epochs, alpha, xTrain, yTrain}</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//     -.  . const costHistory = []; //    ()  for (let epoch = 0; epoch &lt; epochs; epoch += 1) { //   . const [predictions, cost] = forwardPropagation(model, xTrain, yTrain); costHistory.push(cost); //   . const [dW, dB] = backwardPropagation(predictions, xTrain, yTrain); //    -,    . nanoNeuron.w += alpha * dW; nanoNeuron.b += alpha * dB; } return costHistory; }</span></span></code> </pre> <br><h3 id="soberem-vse-funkcii-vmeste">  Alle Funktionen zusammenfassen </h3><br><p>  Es ist Zeit, alle zuvor erstellten Funktionen zusammen zu verwenden. </p><br><p>  Erstellen Sie eine Instanz des Nano-Neuron-Modells.  Derzeit weiß das Nano-Neuron nichts über die Parameter <code>w</code> und <code>b</code> .  Setzen wir also <code>w</code> und <code>b</code> zufällig. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> w = <span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.random(); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 0.9492 const b = Math.random(); // ie -&gt; 0.4570 const nanoNeuron = new NanoNeuron(w, b);</span></span></code> </pre> <br><p>  Wir generieren Trainings- und Testdatensätze. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> [xTrain, yTrain, xTest, yTest] = generateDataSets();</code> </pre> <br><p>  Versuchen wir nun, unser Modell in kleinen Schritten ( <code>0.0005</code> ) für <code>70000</code> Epochen zu trainieren.  Sie können mit diesen Parametern experimentieren, sie werden empirisch ermittelt. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> epochs = <span class="hljs-number"><span class="hljs-number">70000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> alpha = <span class="hljs-number"><span class="hljs-number">0.0005</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> trainingCostHistory = trainModel({<span class="hljs-attr"><span class="hljs-attr">model</span></span>: nanoNeuron, epochs, alpha, xTrain, yTrain});</code> </pre> <br><p>  Lassen Sie uns überprüfen, wie sich der Fehlerwert unseres Modells während des Trainings geändert hat.  Wir erwarten, dass der Fehlerwert nach dem Training deutlich geringer sein sollte als vor dem Training.  Dies würde bedeuten, dass unser Nano-Neuron klüger ist.  Die umgekehrte Option ist auch möglich, wenn nach dem Training der Fehler der Vorhersagen nur zunimmt (zum Beispiel große Werte des Lernschritts <code>alpha</code> ). </p><br><pre> <code class="javascript hljs"><span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'  :'</span></span>, trainingCostHistory[<span class="hljs-number"><span class="hljs-number">0</span></span>]); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 4694.3335043 console.log('  :', trainingCostHistory[epochs - 1]); // ie -&gt; 0.0000024</span></span></code> </pre> <br><p>  Und so hat sich der Wert des Modellfehlers während des Trainings geändert.  Auf der <code>x</code> Achse befinden sich Epochen (in Tausendern).  Wir gehen davon aus, dass das Chart abnehmen wird. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/191/860/d6f/191860d6f0cd8cf7d24127f04f779462.png" alt="Trainingsprozess"></p><br><p>  Schauen wir uns an, welche Parameter unser Nano-Neuron „gelernt“ hat.  Wir erwarten, dass die Parameter <code>w</code> und <code>b</code> den gleichnamigen Parametern der Funktion <code>celsiusToFahrenheit()</code> ( <code>w = 1.8</code> und <code>b = 32</code> ) ähnlich sind, da ich versucht habe, ihr Nano-Neuron zu simulieren. </p><br><pre> <code class="javascript hljs"><span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">' -:'</span></span>, {<span class="hljs-attr"><span class="hljs-attr">w</span></span>: nanoNeuron.w, <span class="hljs-attr"><span class="hljs-attr">b</span></span>: nanoNeuron.b}); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; {w: 1.8, b: 31.99}</span></span></code> </pre> <br><p>  Wie Sie sehen, ist das Nano-Neuron der Funktion <code>celsiusToFahrenheit()</code> sehr <code>celsiusToFahrenheit()</code> . </p><br><p>  Nun wollen wir sehen, wie genau die Vorhersagen unseres Nano-Neurons für Testdaten sind, die er während des Trainings nicht gesehen hat.  Der Vorhersagefehler für die Testdaten sollte in der Nähe des Vorhersagefehlers für die Trainingsdaten liegen.  Dies bedeutet, dass das Nano-Neuron die richtigen Abhängigkeiten gelernt hat und seine Erfahrung korrekt aus zuvor unbekannten Daten abstrahieren kann (dies ist der gesamte Wert des Modells). </p><br><pre> <code class="javascript hljs">[testPredictions, testCost] = forwardPropagation(nanoNeuron, xTest, yTest); <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'   :'</span></span>, testCost); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 0.0000023</span></span></code> </pre> <br><p>  Jetzt, da unser "Nano-Baby" in der "Schule" gut ausgebildet war und jetzt weiß, wie man Grad Celsius in Grad Fahrenheit genau umrechnet, selbst für Daten, die er nicht gesehen hat, können wir ihn als einigermaßen schlau bezeichnen.  Jetzt können wir ihn sogar um Rat zur Temperaturumrechnung bitten, und das war der Zweck des gesamten Trainings. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> tempInCelsius = <span class="hljs-number"><span class="hljs-number">70</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> customPrediction = nanoNeuron.predict(tempInCelsius); <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">`- "",  </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${tempInCelsius}</span></span></span><span class="hljs-string">°C   :`</span></span>, customPrediction); <span class="hljs-comment"><span class="hljs-comment">// -&gt; 158.0002 console.log('  :', celsiusToFahrenheit(tempInCelsius)); // -&gt; 158</span></span></code> </pre> <br><p>  Ganz in der Nähe!  Wie die Menschen ist unser Nano-Neuron gut, aber nicht perfekt :) </p><br><p>  Erfolgreich codieren! </p><br><h2 id="kak-zapustit-i-protestirovat-nano-neyron">  Wie man ein Nano-Neuron laufen lässt und testet </h2><br><p>  Sie können das Repository klonen und das Nano-Neuron lokal ausführen: </p><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/trekhleb/nano-neuron.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> nano-neuron</code> </pre> <br><pre> <code class="bash hljs">node ./NanoNeuron.js</code> </pre> <br><h2 id="upuschennye-koncepcii">  Verpasste Konzepte </h2><br><p>  Die folgenden Konzepte für maschinelles Lernen wurden zur Vereinfachung der Erläuterung weggelassen oder vereinfacht. </p><br><p>  <strong>Trennung von Trainings- und Testdatensätzen</strong> </p><br><p>  Normalerweise haben Sie einen großen Datensatz.  Abhängig von der Anzahl der Exemplare in diesem Satz kann die Aufteilung in Trainings- und Testsätze im Verhältnis 70/30 erfolgen.  Die Daten im Set müssen vor dem Teilen zufällig gemischt werden.  Wenn die Datenmenge groß ist (z. B. Millionen), kann die Aufteilung in Test- und Trainingssätze in Anteilen nahe 90/10 oder 95/5 durchgeführt werden. </p><br><p>  <strong>Online macht</strong> </p><br><p>  Normalerweise werden Sie keine Fälle finden, in denen nur ein Neuron verwendet wird.  Stärke liegt im <a href="https://en.wikipedia.org/wiki/Neural_network" rel="nofollow">Netzwerk</a> solcher Neuronen.  Ein neuronales Netzwerk kann viel komplexere Abhängigkeiten lernen. </p><br><p>  Im obigen Beispiel ähnelt unser Nano-Neuron möglicherweise eher einer einfachen <a href="https://en.wikipedia.org/wiki/Linear_regression" rel="nofollow">linearen Regression</a> als einem neuronalen Netzwerk. </p><br><p>  <strong>Eingangsnormalisierung</strong> </p><br><p>  Vor dem Training ist es üblich, <a href="https://www.jeremyjordan.me/batch-normalization/" rel="nofollow">die Eingabedaten</a> zu <a href="https://www.jeremyjordan.me/batch-normalization/" rel="nofollow">normalisieren</a> . </p><br><p>  <strong>Vektorimplementierung</strong> </p><br><p>  Bei neuronalen Netzen sind Vektor- (Matrix-) Berechnungen viel schneller als Berechnungen in <code>for</code> Schleifen.  Normalerweise wird die direkte und umgekehrte Signalausbreitung unter Verwendung von Matrixoperationen ausgeführt, die beispielsweise die Python <a href="https://numpy.org/" rel="nofollow">Numpy-</a> Bibliothek verwenden. </p><br><p>  <strong>Minimale Fehlerfunktion</strong> </p><br><p>  Die Fehlerfunktion, die wir für das Nano-Neuron verwendet haben, ist sehr vereinfacht.  Es sollte <a href="https://stackoverflow.com/questions/32986123/why-the-cost-function-of-logistic-regression-has-a-logarithmic-expression/32998675" rel="nofollow">logarithmische Komponenten</a> enthalten.  Eine Änderung der Formel für die Fehlerfunktion hat auch eine Änderung der Formeln für die Vorwärts- und Rückwärtsausbreitung des Signals zur Folge. </p><br><p>  <strong>Aktivierungsfunktion</strong> </p><br><p>  Normalerweise passiert der Ausgabewert des Neurons die Aktivierungsfunktion.  Zur Aktivierung können Funktionen wie <a href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="nofollow">Sigmoid</a> , <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="nofollow">ReLU</a> und andere verwendet werden. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479220/">https://habr.com/ru/post/de479220/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479202/index.html">C ++ und numerische Methoden: Ungefähre Newton-Cotes-Integration</a></li>
<li><a href="../de479210/index.html">Was passiert mit Einkäufen in ausländischen Online-Shops ab dem 1. Januar 2020?</a></li>
<li><a href="../de479214/index.html">Eine Auswahl an bevorstehenden kostenlosen Events für Entwickler in Moskau # 2</a></li>
<li><a href="../de479216/index.html">Zweiter Wind Pandora DXL 3000 oder wie ich meine eigene Telemetrie verschraubt habe</a></li>
<li><a href="../de479218/index.html">So machen Sie einen Bot, der aus einem Foto ein Comic-Buch macht: Schritt-für-Schritt-Anleitung für Dummies</a></li>
<li><a href="../de479222/index.html">Die Zusammenstellung interessanter Materialien für den mobilen Entwickler # 325 (vom 2. bis 8. Dezember)</a></li>
<li><a href="../de479226/index.html">Habr-Analyse: Was Anwender bei Habr als Geschenk bestellen</a></li>
<li><a href="../de479230/index.html">Dokumentieren Sie Ihre Express-API mit Swagger-Annotationen</a></li>
<li><a href="../de479232/index.html">MQ JMS-Anwendungsentwicklung auf Spring Boot</a></li>
<li><a href="../de479234/index.html">Neuigkeiten aus der Welt von OpenStreetMap Nr. 488 (19.11.19 - 25.11.19)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
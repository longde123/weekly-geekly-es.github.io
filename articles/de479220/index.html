<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üê© üí£ üôå Nano-Neuron - 7 einfache JavaScript-Funktionen, die zeigen, wie die Maschine "lernen" kann ü§õüèΩ üôÇ ü¶á</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ein Nano-Neuron ist eine vereinfachte Version eines Neurons aus dem Konzept eines neuronalen Netzwerks. Nano-Neuron erf√ºllt die einfachste Aufgabe und...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nano-Neuron - 7 einfache JavaScript-Funktionen, die zeigen, wie die Maschine "lernen" kann</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479220/"><p>  <a href="https://github.com/trekhleb/nano-neuron" rel="nofollow"><strong>Ein Nano-Neuron</strong></a> ist eine <em>vereinfachte</em> Version eines Neurons aus dem Konzept eines neuronalen Netzwerks.  Nano-Neuron erf√ºllt die einfachste Aufgabe und ist darauf trainiert, Temperaturen von Grad Celsius in Grad Fahrenheit umzuwandeln. </p><br><p>  Der Code von <a href="" rel="nofollow"><strong>NanoNeuron.js</strong></a> besteht aus 7 einfachen JavaScript-Funktionen, die das Lernen, Trainieren, Vorhersagen sowie die direkte und R√ºckw√§rtsausbreitung des Modellsignals umfassen.  Der Zweck des Schreibens dieser Funktionen bestand darin, dem Leser eine minimale, grundlegende Erkl√§rung (Intuition) zu geben, wie eine Maschine schlie√ülich "lernen" kann.  Der Code verwendet keine Bibliotheken von Drittanbietern.  Wie das Sprichwort sagt, funktioniert nur einfaches "Vanille" JavaScript. </p><br><p>  Diese Funktionen sind <strong>keine</strong> vollst√§ndige Anleitung zum maschinellen Lernen.  Viele maschinelle Lernkonzepte fehlen oder sind vereinfacht!  Diese Vereinfachung dient einzig und allein dem Zweck, dem Leser das <strong>grundlegendste</strong> Verst√§ndnis und die Intuition daf√ºr zu vermitteln, wie eine Maschine im Prinzip "lernen" kann, so dass sich "MAGIE des maschinellen Lernens" f√ºr den Leser immer mehr als "MATHEMATIK des maschinellen Lernens" anh√∂rt. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/98d/6c4/69e/98d6c469e1facbf97154fe29f698cd12.png" alt="Nanoneuron"></p><a name="habracut"></a><br><h2 id="chto-vyuchit-nash-nano-neyron">  Was unser Nano-Neuron "lernen" wird </h2><br><p>  M√∂glicherweise haben Sie im Zusammenhang mit <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D1%2581%25D0%25BA%25D1%2583%25D1%2581%25D1%2581%25D1%2582%25D0%25B2%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C" rel="nofollow">neuronalen Netzen</a> von Neuronen geh√∂rt.  Ein Nano-Neuron ist eine vereinfachte Version desselben Neurons.  In diesem Beispiel schreiben wir die Implementierung von Grund auf neu.  Der Einfachheit halber werden wir kein Netzwerk von Nano-Neuronen aufbauen.  Wir werden uns darauf konzentrieren, ein einziges Nano-Neuron zu erzeugen und ihm beizubringen, wie man die Temperatur von Grad Celsius in Grad Fahrenheit umwandelt.  Mit anderen Worten, wir werden ihm beibringen <strong>, die</strong> Temperatur in Grad Fahrenheit basierend auf der Temperatur in Grad Celsius <strong>vorherzusagen</strong> . </p><br><p>  √úbrigens lautet die Formel zum Umrechnen von Grad Celsius in Grad Fahrenheit wie folgt: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/9fa/2e8/8b5/9fa2e88b5a7324c8b9fc359b274ba091.png" alt="Celsius in Fahrenheit"></p><br><p>  Aber im Moment wei√ü unser Nano-Neuron nichts √ºber diese Formel ... </p><br><h3 id="model-nano-neyrona">  Nano-Neuronen-Modell </h3><br><p> Beginnen wir mit der Erstellung einer Funktion, die das Modell unseres Nano-Neurons beschreibt.  Dieses Modell ist eine einfache lineare Beziehung zwischen <code>x</code> und <code>y</code> , die so aussieht: <code>y = w * x + b</code> .  Einfach ausgedr√ºckt, unser Nano-Neuron ist ein Kind, das im <code>XY</code> Koordinatensystem eine gerade Linie zeichnen kann. </p><br><p>  Die Variablen <code>w</code> und <code>b</code> sind Modellparameter.  Ein Nano-Neuron kennt nur diese beiden Parameter einer linearen Funktion.  Genau diese Parameter lernt unser Nano-Neuron w√§hrend des Trainingsprozesses. </p><br><p>  Das einzige, was ein Nano-Neuron in dieser Phase tun kann, ist die Simulation linearer Beziehungen.  Er tut dies in der <code>predict()</code> -Methode, die eine Variable <code>x</code> am Eingang und die Variable <code>y</code> am Ausgang voraussagt.  Keine Magie. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">NanoNeuron</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">w, b</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.w = w; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.b = b; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.predict = <span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">x</span></span></span><span class="hljs-function">) =&gt;</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x * <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.w + <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.b; } }</code> </pre> <br><p>  _ (... warte ... <a href="https://en.wikipedia.org/wiki/Linear_regression" rel="nofollow">lineare Regression</a> bist du, oder was?) _ </p><br><h3 id="konvertaciya-gradusov-celsiya-v-gradusy-farengeyta">  Berechne Grad Celsius in Grad Fahrenheit </h3><br><p>  Die Temperatur in Grad Celsius kann nach der Formel in Grad Fahrenheit umgerechnet werden: <code>f = 1.8 * c + 32</code> , wobei <code>c</code> die Temperatur in Grad Celsius und <code>f</code> die Temperatur in Grad Fahrenheit ist. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">celsiusToFahrenheit</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">c</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> w = <span class="hljs-number"><span class="hljs-number">1.8</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> b = <span class="hljs-number"><span class="hljs-number">32</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> f = c * w + b; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> f; };</code> </pre> <br><p>  Daher m√∂chten wir, dass unser Nano-Neuron diese spezielle Funktion simuliert.  Er muss erraten (lernen), dass der Parameter <code>w = 1.8</code> und <code>b = 32</code> ohne es vorher zu wissen. </p><br><p>  So sieht die Konvertierungsfunktion im Diagramm aus.  Das ist es, was unser nano-neuronales "Baby" lernen muss, zu "zeichnen": </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/68b/0d6/8bc/68b0d68bcc7be00ec9526867b2fcecf3.png" alt="Celsius in Fahrenheit umwandeln"></p><br><h3 id="generirovanie-dannyh">  Datengenerierung </h3><br><p>  In der klassischen Programmierung kennen wir die Eingabedaten ( <code>x</code> ) und den Algorithmus zur Konvertierung dieser Daten (Parameter <code>w</code> und <code>b</code> ), aber die Ausgabedaten ( <code>y</code> ) sind unbekannt.  Die Ausgabe wird basierend auf der Eingabe unter Verwendung eines bekannten Algorithmus berechnet.  Im Gegensatz dazu sind beim maschinellen Lernen nur die Eingabe- und Ausgabedaten ( <code>x</code> und <code>y</code> ) bekannt, der Algorithmus zum Umschalten von <code>x</code> auf <code>y</code> unbekannt (Parameter <code>w</code> und <code>b</code> ). </p><br><p>  Es ist die Erzeugung von Input und Output, die wir jetzt tun werden.  Wir m√ºssen Daten zum <strong>Trainieren</strong> unseres Modells und Daten zum <strong>Testen des</strong> Modells generieren.  Die <code>celsiusToFahrenheit()</code> hilft uns dabei.  Jeder der Trainings- und Testdatens√§tze ist ein Satz von Paaren <code>x</code> und <code>y</code> .  Wenn beispielsweise <code>x = 2</code> , dann ist <code>y = 35,6</code> und so weiter. </p><br><blockquote>  In der realen Welt werden die meisten Daten wahrscheinlich <em>gesammelt</em> und nicht <em>generiert</em> .  Bei solchen gesammelten Daten kann es sich beispielsweise um ein Paar von "Gesichtsfotos" -&gt; "Name der Person" handeln. </blockquote><p>  Wir werden den TRAINING-Datensatz verwenden, um unser Nano-Neuron zu trainieren.  Bevor er erwachsen wird und in der Lage ist, selbst Entscheidungen zu treffen, m√ºssen wir ihm beibringen, was ‚Äûwahr‚Äú und was ‚Äûfalsch‚Äú ist, indem wir ‚Äûkorrekte‚Äú Daten aus einem Trainingssatz verwenden. </p><br><blockquote>  √úbrigens wird hier das Lebensprinzip ‚ÄûM√ºll am Eingang - M√ºll am Ausgang‚Äú deutlich nachvollzogen.  Wenn ein Nano-Neuron eine ‚ÄûL√ºge‚Äú in das Trainingskit wirft, dass 5 ¬∞ C in 1000 ¬∞ F umgewandelt werden, dann wird er dies nach vielen Trainingsiterationen glauben und alle Temperaturwerte mit <strong>Ausnahme von</strong> 5 ¬∞ C korrekt konvertieren.  Wir m√ºssen mit den Trainingsdaten, die wir t√§glich in unser neuronales Gehirnnetzwerk laden, sehr vorsichtig sein. </blockquote><p>  Abgelenkt.  Lass uns weitermachen. </p><br><p>  Wir werden den TEST-Datensatz verwenden, um zu bewerten, wie gut unser Nano-Neuron trainiert hat, und k√∂nnen korrekte Vorhersagen f√ºr neue Daten treffen, die er w√§hrend seines Trainings nicht gesehen hat. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generateDataSets</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// xTrain -&gt; [0, 1, 2, ...], // yTrain -&gt; [32, 33.8, 35.6, ...] const xTrain = []; const yTrain = []; for (let x = 0; x &lt; 100; x += 1) { const y = celsiusToFahrenheit(x); xTrain.push(x); yTrain.push(y); } // xTest -&gt; [0.5, 1.5, 2.5, ...] // yTest -&gt; [32.9, 34.7, 36.5, ...] const xTest = []; const yTest = []; //   0.5    1,       //   ,       . for (let x = 0.5; x &lt; 100; x += 1) { const y = celsiusToFahrenheit(x); xTest.push(x); yTest.push(y); } return [xTrain, yTrain, xTest, yTest]; }</span></span></code> </pre> <br><h3 id="ocenka-pogreshnosti-predskazaniy">  Vorhersagefehlersch√§tzung </h3><br><p>  Wir brauchen eine bestimmte Metrik (Messung, Anzahl, Bewertung), die zeigt, wie nahe die Vorhersage eines Nano-Neurons an der Wahrheit liegt.  Mit anderen Worten, diese Zahl / Metrik / Funktion sollte zeigen, wie richtig oder falsch das Nano-Neuron ist.  Es ist wie in der Schule, ein Sch√ºler kann eine Note von <code>5</code> oder <code>2</code> f√ºr seine Kontrolle bekommen. </p><br><p>  Im Fall eines Nano-Neurons wird sein Fehler (Fehler) zwischen dem wahren Wert von <code>y</code> und dem vorhergesagten Wert der <code>prediction</code> durch die Formel erzeugt: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8d8/e50/ac1/8d8e50ac12d03614e65975f7b5d36931.png" alt="Vorhersagekosten"></p><br><p>  Wie aus der Formel hervorgeht, betrachten wir den Fehler als einen einfachen Unterschied zwischen den beiden Werten.  Je n√§her die Werte beieinander liegen, desto geringer ist der Unterschied.  Wir verwenden hier die Quadratur, um das Zeichen zu entfernen, sodass <code>(1 - 2) ^ 2</code> am Ende <code>(2 - 1) ^ 2</code> .  Die Division durch <code>2</code> erfolgt nur, um die Bedeutung der Ableitung dieser Funktion in der Formel f√ºr die R√ºckausbreitung eines Signals zu vereinfachen (mehr dazu weiter unten). </p><br><p>  Die Fehlerfunktion sieht in diesem Fall folgenderma√üen aus: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predictionCost</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">y, prediction</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (y - prediction) ** <span class="hljs-number"><span class="hljs-number">2</span></span> / <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 235.6 }</span></span></code> </pre> <br><h3 id="pryamoe-rasprostranenie-signala">  Direkte Signalausbreitung </h3><br><p>  Direkte Signalausbreitung durch unser Modell bedeutet, Vorhersagen f√ºr alle Paare aus dem <code>xTrain</code> und <code>yTrain</code> Trainingsdatensatz zu <code>yTrain</code> und den durchschnittlichen Fehler (Fehler) dieser Vorhersagen zu berechnen. </p><br><p>  Wir lassen unser Nano-Neuron einfach ‚Äûsprechen‚Äú, damit es Vorhersagen treffen kann (Temperatur umwandeln).  Gleichzeitig kann ein Nano-Neuron in diesem Stadium sehr falsch sein.  Der Durchschnittswert des Vorhersagefehlers zeigt uns, wie weit unser Modell derzeit der Wahrheit entspricht.  Der Wert des Fehlers ist hier sehr wichtig, da wir durch √Ñndern der Parameter <code>w</code> und <code>b</code> und direktes Weiterleiten des Signals auswerten k√∂nnen, ob unser Nano-Neuron mit neuen Parametern ‚Äûintelligenter‚Äú geworden ist oder nicht. </p><br><p>  Der durchschnittliche Vorhersagefehler eines Nano-Neurons wird mit der folgenden Formel berechnet: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/575/db3/e0a/575db3e0a0c872b29582147e41231344.png" alt="Durchschnittskosten"></p><br><p>  Wobei <code>m</code> die Anzahl der Trainingskopien ist (in unserem Fall haben wir <code>100</code> Datenpaare). </p><br><p>  So k√∂nnen wir dies in Code implementieren: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forwardPropagation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">model, xTrain, yTrain</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> m = xTrain.length; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> predictions = []; <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cost = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">let</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; m; i += <span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> prediction = nanoNeuron.predict(xTrain[i]); cost += predictionCost(yTrain[i], prediction); predictions.push(prediction); } <span class="hljs-comment"><span class="hljs-comment">//     . cost /= m; return [predictions, cost]; }</span></span></code> </pre> <br><h3 id="obratnoe-rasprostranenie-signala">  Signalumkehrung </h3><br><p>  Nun, da wir wissen, wie richtig oder falsch unsere Nano-Neuronen in ihren Vorhersagen sind (basierend auf dem Durchschnittswert des Fehlers), wie k√∂nnen wir die Vorhersagen genauer machen? </p><br><p>  Die umgekehrte Signalausbreitung hilft uns dabei.  Bei der Signalr√ºck√ºbertragung wird der Fehler eines Nano-Neurons bewertet und anschlie√üend dessen Parameter <code>w</code> und <code>b</code> so <code>b</code> , dass die n√§chsten Vorhersagen des Nano-Neurons f√ºr den gesamten Satz von Trainingsdaten etwas genauer werden. </p><br><p>  Hier wird maschinelles Lernen zur Magie.  Das Schl√ºsselkonzept ist hier eine <strong>Ableitung der Funktion</strong> , die zeigt, welchen Gr√∂√üenschritt und welchen Weg wir gehen m√ºssen, um uns dem Minimum der Funktion (in unserem Fall dem Minimum der Fehlerfunktion) zu n√§hern. </p><br><p>  Das ultimative Ziel beim Training eines Nano-Neurons ist es, das Minimum der Fehlerfunktion zu finden (siehe Funktion oben).  Wenn wir solche Werte von <code>w</code> und <code>b</code> bei denen der Durchschnittswert der Fehlerfunktion klein ist, bedeutet dies, dass unser Nano-Neuron mit Temperaturvorhersagen in Grad Fahrenheit gut zurechtkommt. </p><br><p>  Derivate sind ein gro√ües und eigenst√§ndiges Thema, das wir in diesem Artikel nicht behandeln werden.  <a href="https://www.mathsisfun.com/calculus/derivatives-introduction.html" rel="nofollow">MathIsFun</a> ist eine gro√üartige Ressource, die ein grundlegendes Verst√§ndnis von Derivaten vermitteln kann. </p><br><p>  Eine Sache, die wir aus dem Wesen einer Ableitung lernen m√ºssen und die uns helfen wird zu verstehen, wie die R√ºckausbreitung eines Signals funktioniert, ist, dass die Ableitung einer Funktion an einem bestimmten Punkt <code>x</code> und <code>y</code> per Definition eine Tangente an die Kurve dieser Funktion bei <code>x</code> und ist <code>y</code> und <em>zeigt uns die Richtung zum Minimum der Funktion an</em> . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/66d/bfd/49a/66dbfd49aaf1ced48d7f6b5917fddb12.svg" alt="Ableitung Steigung"></p><br><p>  <em>Bild aus <a href="https://www.mathsisfun.com/calculus/derivatives-introduction.html" rel="nofollow">MathIsFun genommen</a></em> </p><br><p>  In der obigen Grafik sehen Sie beispielsweise, dass am Punkt <code>(x=2, y=4)</code> Neigung der Tangente uns anzeigt, dass wir uns nach <code></code> und <code></code> bewegen <code></code> , um zum Minimum der Funktion zu gelangen.  Beachten Sie auch, dass wir uns umso schneller zum kleinsten Punkt bewegen m√ºssen, je gr√∂√üer die Neigung der Tangente ist. </p><br><p>  Die Ableitungen unserer durchschnittlichen Fehlerfunktion <code>averageCost</code> in <code>averageCost</code> auf die Parameter <code>w</code> und <code>b</code> sehen folgenderma√üen aus: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/4cc/bda/ba1/4ccbdaba120c399c1528e2bc38cf0efd.png" alt="dW"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/e02/0cb/125/e020cb125449849009a9f565a32ff46f.png" alt="dB"></p><br><p>  Wobei <code>m</code> die Anzahl der Trainingskopien ist (in unserem Fall haben wir <code>100</code> Datenpaare). </p><br><p>  <em>Hier erfahren Sie ausf√ºhrlicher, wie Sie die Ableitung komplexer Funktionen √ºbernehmen.</em> </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">backwardPropagation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">predictions, xTrain, yTrain</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> m = xTrain.length; <span class="hljs-comment"><span class="hljs-comment">//           'w'  'b'. //      0. let dW = 0; let dB = 0; for (let i = 0; i &lt; m; i += 1) { dW += (yTrain[i] - predictions[i]) * xTrain[i]; dB += yTrain[i] - predictions[i]; } //    . dW /= m; dB /= m; return [dW, dB]; }</span></span></code> </pre> <br><h3 id="trenirovka-modeli">  Model Training </h3><br><p>  Jetzt wissen wir, wie wir den Fehler der Vorhersagen unseres Nano-Neuron-Modells f√ºr alle Trainingsdaten absch√§tzen k√∂nnen (direkte Signalausbreitung).  Wir wissen auch, wie man die Parameter <code>w</code> und <code>b</code> Nano-Neuronen-Modells (R√ºckausbreitung des Signals) anpasst, um die Genauigkeit der Vorhersagen zu verbessern.  Das Problem ist, dass wenn wir das Signal nur einmal vorw√§rts und r√ºckw√§rts ausbreiten, dies nicht ausreicht, damit unser Modell die Abh√§ngigkeiten und Gesetze in den Trainingsdaten erkennt und lernt.  Sie k√∂nnen dies mit dem eint√§gigen Schulbesuch eines Sch√ºlers vergleichen.  Er / sie muss regelm√§√üig, Tag f√ºr Tag, Jahr f√ºr Jahr zur Schule gehen, um das gesamte Material zu lernen. </p><br><p>  Wir m√ºssen also <em>die</em> Vorw√§rts- und R√ºckw√§rtsausbreitung des Signals viele Male <em>wiederholen</em> .  <code>trainModel()</code> Funktion.  Sie ist wie eine "Lehrerin" f√ºr das Modell unseres Nano-Neurons: </p><br><ul><li>  Sie wird einige Zeit ( <code>epochs</code> ) mit unserem immer noch albernen Nano-Neuron verbringen und versuchen, ihn zu trainieren. </li><li>  Sie wird spezielle B√ºcher ( <code>xTrain</code> und <code>yTrain</code> Datens√§tze) f√ºr das Training verwenden. </li><li>  es ermutigt unseren ‚ÄûSch√ºler‚Äú, flei√üiger (schneller) mit dem <code>alpha</code> Parameter zu lernen, der im Wesentlichen die Lerngeschwindigkeit steuert. </li></ul><br><p>  Ein paar Worte zum <code>alpha</code> Parameter.  Dies ist nur ein Koeffizient (Multiplikator) f√ºr die Werte der Variablen <code>dW</code> und <code>dB</code> , die wir w√§hrend der <code>dW</code> des Signals berechnen.  Die Ableitung zeigte uns also die Richtung zum Minimum der Fehlerfunktion (die Vorzeichen der Werte von <code>dW</code> und <code>dB</code> sagen dies aus).  Die Ableitung zeigte uns auch, wie schnell wir uns dem Minimum der Funktion <code>dW</code> m√ºssen (die absoluten Werte von <code>dW</code> und <code>dB</code> sagen dies aus).  Jetzt m√ºssen wir die Schrittgr√∂√üe mit <code>alpha</code> multiplizieren, um die Geschwindigkeit unserer Ann√§herung auf ein Minimum (die Gesamtschrittgr√∂√üe) einzustellen.  Wenn wir f√ºr <code>alpha</code> gro√üe Werte verwenden, k√∂nnen wir manchmal so gro√üe Schritte ausf√ºhren, dass wir einfach <em>√ºber das</em> Minimum der Funktion springen und diese √ºberspringen k√∂nnen. </p><br><p>  In Analogie zur ‚ÄûLehrerin‚Äú, je st√§rker sie unsere ‚ÄûNano-Sch√ºlerin‚Äú zum Lernen zwingen w√ºrde, desto schneller w√ºrde er lernen, ABER wenn Sie ihn sehr stark zwingen und unter Druck setzen, k√∂nnte unsere ‚ÄûNano-Sch√ºlerin‚Äú einen Nervenzusammenbruch erleben und v√∂llige Apathie und er wird √ºberhaupt nichts lernen. </p><br><p>  Wir werden die Parameter unseres Modells <code>w</code> und <code>b</code> wie folgt aktualisieren: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c7b/db8/84f/c7bdb884f2a940d62332246cdbcb44bc.png" alt="w"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b57/622/0ab/b576220ab6515d44255ef56699077bab.png" alt="b"></p><br><p>  Und so sieht das Training selbst aus: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trainModel</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">{model, epochs, alpha, xTrain, yTrain}</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//     -.  . const costHistory = []; //    ()  for (let epoch = 0; epoch &lt; epochs; epoch += 1) { //   . const [predictions, cost] = forwardPropagation(model, xTrain, yTrain); costHistory.push(cost); //   . const [dW, dB] = backwardPropagation(predictions, xTrain, yTrain); //    -,    . nanoNeuron.w += alpha * dW; nanoNeuron.b += alpha * dB; } return costHistory; }</span></span></code> </pre> <br><h3 id="soberem-vse-funkcii-vmeste">  Alle Funktionen zusammenfassen </h3><br><p>  Es ist Zeit, alle zuvor erstellten Funktionen zusammen zu verwenden. </p><br><p>  Erstellen Sie eine Instanz des Nano-Neuron-Modells.  Derzeit wei√ü das Nano-Neuron nichts √ºber die Parameter <code>w</code> und <code>b</code> .  Setzen wir also <code>w</code> und <code>b</code> zuf√§llig. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> w = <span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.random(); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 0.9492 const b = Math.random(); // ie -&gt; 0.4570 const nanoNeuron = new NanoNeuron(w, b);</span></span></code> </pre> <br><p>  Wir generieren Trainings- und Testdatens√§tze. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> [xTrain, yTrain, xTest, yTest] = generateDataSets();</code> </pre> <br><p>  Versuchen wir nun, unser Modell in kleinen Schritten ( <code>0.0005</code> ) f√ºr <code>70000</code> Epochen zu trainieren.  Sie k√∂nnen mit diesen Parametern experimentieren, sie werden empirisch ermittelt. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> epochs = <span class="hljs-number"><span class="hljs-number">70000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> alpha = <span class="hljs-number"><span class="hljs-number">0.0005</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> trainingCostHistory = trainModel({<span class="hljs-attr"><span class="hljs-attr">model</span></span>: nanoNeuron, epochs, alpha, xTrain, yTrain});</code> </pre> <br><p>  Lassen Sie uns √ºberpr√ºfen, wie sich der Fehlerwert unseres Modells w√§hrend des Trainings ge√§ndert hat.  Wir erwarten, dass der Fehlerwert nach dem Training deutlich geringer sein sollte als vor dem Training.  Dies w√ºrde bedeuten, dass unser Nano-Neuron kl√ºger ist.  Die umgekehrte Option ist auch m√∂glich, wenn nach dem Training der Fehler der Vorhersagen nur zunimmt (zum Beispiel gro√üe Werte des Lernschritts <code>alpha</code> ). </p><br><pre> <code class="javascript hljs"><span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'  :'</span></span>, trainingCostHistory[<span class="hljs-number"><span class="hljs-number">0</span></span>]); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 4694.3335043 console.log('  :', trainingCostHistory[epochs - 1]); // ie -&gt; 0.0000024</span></span></code> </pre> <br><p>  Und so hat sich der Wert des Modellfehlers w√§hrend des Trainings ge√§ndert.  Auf der <code>x</code> Achse befinden sich Epochen (in Tausendern).  Wir gehen davon aus, dass das Chart abnehmen wird. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/191/860/d6f/191860d6f0cd8cf7d24127f04f779462.png" alt="Trainingsprozess"></p><br><p>  Schauen wir uns an, welche Parameter unser Nano-Neuron ‚Äûgelernt‚Äú hat.  Wir erwarten, dass die Parameter <code>w</code> und <code>b</code> den gleichnamigen Parametern der Funktion <code>celsiusToFahrenheit()</code> ( <code>w = 1.8</code> und <code>b = 32</code> ) √§hnlich sind, da ich versucht habe, ihr Nano-Neuron zu simulieren. </p><br><pre> <code class="javascript hljs"><span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">' -:'</span></span>, {<span class="hljs-attr"><span class="hljs-attr">w</span></span>: nanoNeuron.w, <span class="hljs-attr"><span class="hljs-attr">b</span></span>: nanoNeuron.b}); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; {w: 1.8, b: 31.99}</span></span></code> </pre> <br><p>  Wie Sie sehen, ist das Nano-Neuron der Funktion <code>celsiusToFahrenheit()</code> sehr <code>celsiusToFahrenheit()</code> . </p><br><p>  Nun wollen wir sehen, wie genau die Vorhersagen unseres Nano-Neurons f√ºr Testdaten sind, die er w√§hrend des Trainings nicht gesehen hat.  Der Vorhersagefehler f√ºr die Testdaten sollte in der N√§he des Vorhersagefehlers f√ºr die Trainingsdaten liegen.  Dies bedeutet, dass das Nano-Neuron die richtigen Abh√§ngigkeiten gelernt hat und seine Erfahrung korrekt aus zuvor unbekannten Daten abstrahieren kann (dies ist der gesamte Wert des Modells). </p><br><pre> <code class="javascript hljs">[testPredictions, testCost] = forwardPropagation(nanoNeuron, xTest, yTest); <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'   :'</span></span>, testCost); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 0.0000023</span></span></code> </pre> <br><p>  Jetzt, da unser "Nano-Baby" in der "Schule" gut ausgebildet war und jetzt wei√ü, wie man Grad Celsius in Grad Fahrenheit genau umrechnet, selbst f√ºr Daten, die er nicht gesehen hat, k√∂nnen wir ihn als einigerma√üen schlau bezeichnen.  Jetzt k√∂nnen wir ihn sogar um Rat zur Temperaturumrechnung bitten, und das war der Zweck des gesamten Trainings. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> tempInCelsius = <span class="hljs-number"><span class="hljs-number">70</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> customPrediction = nanoNeuron.predict(tempInCelsius); <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">`- "",  </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${tempInCelsius}</span></span></span><span class="hljs-string">¬∞C   :`</span></span>, customPrediction); <span class="hljs-comment"><span class="hljs-comment">// -&gt; 158.0002 console.log('  :', celsiusToFahrenheit(tempInCelsius)); // -&gt; 158</span></span></code> </pre> <br><p>  Ganz in der N√§he!  Wie die Menschen ist unser Nano-Neuron gut, aber nicht perfekt :) </p><br><p>  Erfolgreich codieren! </p><br><h2 id="kak-zapustit-i-protestirovat-nano-neyron">  Wie man ein Nano-Neuron laufen l√§sst und testet </h2><br><p>  Sie k√∂nnen das Repository klonen und das Nano-Neuron lokal ausf√ºhren: </p><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/trekhleb/nano-neuron.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> nano-neuron</code> </pre> <br><pre> <code class="bash hljs">node ./NanoNeuron.js</code> </pre> <br><h2 id="upuschennye-koncepcii">  Verpasste Konzepte </h2><br><p>  Die folgenden Konzepte f√ºr maschinelles Lernen wurden zur Vereinfachung der Erl√§uterung weggelassen oder vereinfacht. </p><br><p>  <strong>Trennung von Trainings- und Testdatens√§tzen</strong> </p><br><p>  Normalerweise haben Sie einen gro√üen Datensatz.  Abh√§ngig von der Anzahl der Exemplare in diesem Satz kann die Aufteilung in Trainings- und Tests√§tze im Verh√§ltnis 70/30 erfolgen.  Die Daten im Set m√ºssen vor dem Teilen zuf√§llig gemischt werden.  Wenn die Datenmenge gro√ü ist (z. B. Millionen), kann die Aufteilung in Test- und Trainingss√§tze in Anteilen nahe 90/10 oder 95/5 durchgef√ºhrt werden. </p><br><p>  <strong>Online macht</strong> </p><br><p>  Normalerweise werden Sie keine F√§lle finden, in denen nur ein Neuron verwendet wird.  St√§rke liegt im <a href="https://en.wikipedia.org/wiki/Neural_network" rel="nofollow">Netzwerk</a> solcher Neuronen.  Ein neuronales Netzwerk kann viel komplexere Abh√§ngigkeiten lernen. </p><br><p>  Im obigen Beispiel √§hnelt unser Nano-Neuron m√∂glicherweise eher einer einfachen <a href="https://en.wikipedia.org/wiki/Linear_regression" rel="nofollow">linearen Regression</a> als einem neuronalen Netzwerk. </p><br><p>  <strong>Eingangsnormalisierung</strong> </p><br><p>  Vor dem Training ist es √ºblich, <a href="https://www.jeremyjordan.me/batch-normalization/" rel="nofollow">die Eingabedaten</a> zu <a href="https://www.jeremyjordan.me/batch-normalization/" rel="nofollow">normalisieren</a> . </p><br><p>  <strong>Vektorimplementierung</strong> </p><br><p>  Bei neuronalen Netzen sind Vektor- (Matrix-) Berechnungen viel schneller als Berechnungen in <code>for</code> Schleifen.  Normalerweise wird die direkte und umgekehrte Signalausbreitung unter Verwendung von Matrixoperationen ausgef√ºhrt, die beispielsweise die Python <a href="https://numpy.org/" rel="nofollow">Numpy-</a> Bibliothek verwenden. </p><br><p>  <strong>Minimale Fehlerfunktion</strong> </p><br><p>  Die Fehlerfunktion, die wir f√ºr das Nano-Neuron verwendet haben, ist sehr vereinfacht.  Es sollte <a href="https://stackoverflow.com/questions/32986123/why-the-cost-function-of-logistic-regression-has-a-logarithmic-expression/32998675" rel="nofollow">logarithmische Komponenten</a> enthalten.  Eine √Ñnderung der Formel f√ºr die Fehlerfunktion hat auch eine √Ñnderung der Formeln f√ºr die Vorw√§rts- und R√ºckw√§rtsausbreitung des Signals zur Folge. </p><br><p>  <strong>Aktivierungsfunktion</strong> </p><br><p>  Normalerweise passiert der Ausgabewert des Neurons die Aktivierungsfunktion.  Zur Aktivierung k√∂nnen Funktionen wie <a href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="nofollow">Sigmoid</a> , <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="nofollow">ReLU</a> und andere verwendet werden. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479220/">https://habr.com/ru/post/de479220/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479202/index.html">C ++ und numerische Methoden: Ungef√§hre Newton-Cotes-Integration</a></li>
<li><a href="../de479210/index.html">Was passiert mit Eink√§ufen in ausl√§ndischen Online-Shops ab dem 1. Januar 2020?</a></li>
<li><a href="../de479214/index.html">Eine Auswahl an bevorstehenden kostenlosen Events f√ºr Entwickler in Moskau # 2</a></li>
<li><a href="../de479216/index.html">Zweiter Wind Pandora DXL 3000 oder wie ich meine eigene Telemetrie verschraubt habe</a></li>
<li><a href="../de479218/index.html">So machen Sie einen Bot, der aus einem Foto ein Comic-Buch macht: Schritt-f√ºr-Schritt-Anleitung f√ºr Dummies</a></li>
<li><a href="../de479222/index.html">Die Zusammenstellung interessanter Materialien f√ºr den mobilen Entwickler # 325 (vom 2. bis 8. Dezember)</a></li>
<li><a href="../de479226/index.html">Habr-Analyse: Was Anwender bei Habr als Geschenk bestellen</a></li>
<li><a href="../de479230/index.html">Dokumentieren Sie Ihre Express-API mit Swagger-Annotationen</a></li>
<li><a href="../de479232/index.html">MQ JMS-Anwendungsentwicklung auf Spring Boot</a></li>
<li><a href="../de479234/index.html">Neuigkeiten aus der Welt von OpenStreetMap Nr. 488 (19.11.19 - 25.11.19)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
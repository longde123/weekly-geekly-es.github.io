<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ЁЯХКя╕П ЁЯд│ ЁЯТЖЁЯП╗ рд╕рд░рд▓ BERT рдЖрд╕рд╡рди рдЧрд╛рдЗрдб ЁЯЦКя╕П ЁЯОЕ ЁЯЖЪ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="рдпрджрд┐ рдЖрдк рдорд╢реАрди рд╕реАрдЦрдиреЗ рдореЗрдВ рд░реБрдЪрд┐ рд░рдЦрддреЗ рд╣реИрдВ, рддреЛ рдЖрдкрдиреЗ рд╢рд╛рдпрдж BERT рдФрд░ рдЯреНрд░рд╛рдВрд╕рдлрд╛рд░реНрдорд░ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рд╕реБрдирд╛ рд╣реЛрдЧрд╛ред 


 BERT Google рдХрд╛ рдПрдХ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рд╣реИ, рдЬреЛ рдХрдИ рдХрд╛рд░реНрдпреЛрдВ рдкрд░ рдПрдХ ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>рд╕рд░рд▓ BERT рдЖрд╕рд╡рди рдЧрд╛рдЗрдб</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/485290/"><p>  рдпрджрд┐ рдЖрдк рдорд╢реАрди рд╕реАрдЦрдиреЗ рдореЗрдВ рд░реБрдЪрд┐ рд░рдЦрддреЗ рд╣реИрдВ, рддреЛ рдЖрдкрдиреЗ рд╢рд╛рдпрдж BERT рдФрд░ рдЯреНрд░рд╛рдВрд╕рдлрд╛рд░реНрдорд░ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рд╕реБрдирд╛ рд╣реЛрдЧрд╛ред </p><br><p>  BERT Google рдХрд╛ рдПрдХ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рд╣реИ, рдЬреЛ рдХрдИ рдХрд╛рд░реНрдпреЛрдВ рдкрд░ рдПрдХ рд╡реНрдпрд╛рдкрдХ рдорд╛рд░реНрдЬрд┐рди рджреНрд╡рд╛рд░рд╛ рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдкрд░рд┐рдгрд╛рдо рджрд┐рдЦрд╛рддрд╛ рд╣реИред  рдмреАрдИрдЖрд░рдЯреА, рдФрд░ рдЖрдорддреМрд░ рдкрд░ рдЯреНрд░рд╛рдВрд╕рдлрд╛рд░реНрдорд░, рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдПрд▓реНрдЧреЛрд░рд┐рджрдо (рдПрдирдПрд▓рдкреА) рдХреЗ рд╡рд┐рдХрд╛рд╕ рдореЗрдВ рдПрдХ рдкреВрд░реА рддрд░рд╣ рд╕реЗ рдирдпрд╛ рдХрджрдо рдмрди рдЧрдП рд╣реИрдВред  рдЙрдирдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рд▓реЗрдЦ рдФрд░ рд╡рд┐рднрд┐рдиреНрди рдмреЗрдВрдЪрдорд╛рд░реНрдХ рдХреЗ рд▓рд┐рдП "рд╕реНрдЯреИрдВрдбрд┐рдВрдЧ" <a href="https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional">рдХреЛ Papers With Code рд╡реЗрдмрд╕рд╛рдЗрдЯ рдкрд░</a> рдкрд╛рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред </p><br><p>  рдмреАрдИрдЖрд░рдЯреА рдХреЗ рд╕рд╛рде рдПрдХ рд╕рдорд╕реНрдпрд╛ рд╣реИ: рдпрд╣ рдФрджреНрдпреЛрдЧрд┐рдХ рдкреНрд░рдгрд╛рд▓рд┐рдпреЛрдВ рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдорд╕реНрдпрд╛рдЧреНрд░рд╕реНрдд рд╣реИред  рдмреАрдИрдЖрд░рдЯреА-рдмреЗрд╕ рдореЗрдВ 110 рдПрдо рдкреИрд░рд╛рдореАрдЯрд░, рдмреАрдИрдЖрд░рдЯреА-рдмрдбрд╝реЗ - 340 рдПрдо рд╢рд╛рдорд┐рд▓ рд╣реИрдВред  рдЗрддрдиреА рдмрдбрд╝реА рд╕рдВрдЦреНрдпрд╛ рдореЗрдВ рдорд╛рдкрджрдВрдбреЛрдВ рдХреЗ рдХрд╛рд░рдг, рдЗрд╕ рдореЙрдбрд▓ рдХреЛ рд╕реАрдорд┐рдд рд╕рдВрд╕рд╛рдзрдиреЛрдВ рд╡рд╛рд▓реЗ рдЙрдкрдХрд░рдгреЛрдВ рдЬреИрд╕реЗ рдореЛрдмрд╛рдЗрд▓ рдлреЛрди рдкрд░ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░рдирд╛ рдореБрд╢реНрдХрд┐рд▓ рд╣реИред  рдЗрд╕рдХреЗ рдЕрд▓рд╛рд╡рд╛, рд▓рдВрдмреЗ рд╕рдордп рддрдХ рдкреНрд░рд╡реЗрд╢ рдЗрд╕ рдореЙрдбрд▓ рдХреЛ рдЕрдиреБрдкрдпреБрдХреНрдд рдмрдирд╛рддрд╛ рд╣реИ рдЬрд╣рд╛рдВ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдХреА рдЧрддрд┐ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реЛрддреА рд╣реИред  рдЗрд╕рд▓рд┐рдП, BERT рдХреЛ рддреЗрдЬ рдХрд░рдиреЗ рдХреЗ рддрд░реАрдХреЗ рдЦреЛрдЬрдирд╛ рдПрдХ рдмрд╣реБрдд рд╣реА рдЧрд░реНрдо рд╡рд┐рд╖рдп рд╣реИред </p><br><p>  рд╣рдо Avito рдореЗрдВ рдЕрдХреНрд╕рд░ рдкрд╛рда рд╡рд░реНрдЧреАрдХрд░рдг рд╕рдорд╕реНрдпрд╛рдУрдВ рдХреЛ рд╣рд▓ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╣реИред  рдпрд╣ рдПрдХ рд╕рд╛рдорд╛рдиреНрдп рд░реВрдк рд╕реЗ рд▓рд╛рдЧреВ рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдХрд╛рд░реНрдп рд╣реИ рдЬрд┐рд╕рдХрд╛ рдЕрдЪреНрдЫреА рддрд░рд╣ рд╕реЗ рдЕрдзреНрдпрдпрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред  рд▓реЗрдХрд┐рди рд╣рдореЗрд╢рд╛ рдХреБрдЫ рдирдпрд╛ рдХрд░рдиреЗ рдХреА рдХреЛрд╢рд┐рд╢ рдХрд░рдиреЗ рдХрд╛ рдкреНрд░рд▓реЛрднрди рд╣реЛрддрд╛ рд╣реИред  рдпрд╣ рд▓реЗрдЦ рд░реЛрдЬрдорд░реНрд░рд╛ рдХреА рдорд╢реАрди рд╕реАрдЦрдиреЗ рдХреЗ рдХрд╛рд░реНрдпреЛрдВ рдореЗрдВ BERT рдХреЛ рд▓рд╛рдЧреВ рдХрд░рдиреЗ рдХреЗ рдкреНрд░рдпрд╛рд╕ рд╕реЗ рдкреИрджрд╛ рд╣реБрдЖ рдерд╛ред  рдЗрд╕рдореЗрдВ, рдореИрдВ рджрд┐рдЦрд╛рдКрдВрдЧрд╛ рдХрд┐ рдХреИрд╕реЗ рдЖрдк рдирдП рдбреЗрдЯрд╛ рдХреЛ рдЬреЛрдбрд╝рдиреЗ рдФрд░ рдореЙрдбрд▓ рдХреЛ рдЬрдЯрд┐рд▓ рдХрд┐рдП рдмрд┐рдирд╛ BERT рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдореМрдЬреВрджрд╛ рдореЙрдбрд▓ рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдореЗрдВ рдХрд╛рдлреА рд╕реБрдзрд╛рд░ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред </p><br><p><img src="https://habrastorage.org/webt/c_/po/z2/c_poz2e3dkggx7ekt3gn_9wva3g.png"></p><a name="habracut"></a><br><h2 id="knowledge-distillation-kak-metod-uskoreniya-neyronnyh-setey">  рддрдВрддреНрд░рд┐рдХрд╛ рдиреЗрдЯрд╡рд░реНрдХ рдХреЛ рддреЗрдЬ рдХрд░рдиреЗ рдХреА рдПрдХ рд╡рд┐рдзрд┐ рдХреЗ рд░реВрдк рдореЗрдВ рдЬреНрдЮрд╛рди рдЖрд╕рд╡рди </h2><br><p>  рддрдВрддреНрд░рд┐рдХрд╛ рдиреЗрдЯрд╡рд░реНрдХ рдХреЛ рддреЗрдЬ / рд╣рд▓реНрдХрд╛ рдХрд░рдиреЗ рдХреЗ рдХрдИ рддрд░реАрдХреЗ рд╣реИрдВред  рд╕рдмрд╕реЗ рд╡рд┐рд╕реНрддреГрдд рд╕рдореАрдХреНрд╖рд╛ рдЬреЛ рдореБрдЭреЗ рдорд┐рд▓реА рд╣реИ <a href="https://blog.inten.to/speeding-up-bert-5528e18bb4ea">рд╡рд╣ рдордзреНрдпрдо рдкрд░ рдЗрдВрдЯреЗрдВрдЯреЛ рдмреНрд▓реЙрдЧ рдкрд░</a> рдкреНрд░рдХрд╛рд╢рд┐рдд рд╣реБрдИ рд╣реИред </p><br><p>  рддрд░реАрдХреЛрдВ рдХреЛ рдореЛрдЯреЗ рддреМрд░ рдкрд░ рддреАрди рд╕рдореВрд╣реЛрдВ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ: </p><br><ol><li>  рдиреЗрдЯрд╡рд░реНрдХ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдмрджрд▓ рдЬрд╛рддрд╛ рд╣реИред </li><li>  рдореЙрдбрд▓ рд╕рдВрдкреАрдбрд╝рди (рдорд╛рддреНрд░рд╛ рдХрд╛ рдард╣рд░рд╛рд╡, рдЫрдВрдЯрд╛рдИ)ред </li><li>  рдЬреНрдЮрд╛рди рдЖрд╕рд╡рдиред </li></ol><br><p>  рдпрджрд┐ рдкрд╣рд▓реЗ рджреЛ рддрд░реАрдХреЗ рдЕрдкреЗрдХреНрд╖рд╛рдХреГрдд рдкреНрд░рд╕рд┐рджреНрдз рдФрд░ рд╕рдордЭрдиреЗ рдпреЛрдЧреНрдп рд╣реИрдВ, рддреЛ рддреАрд╕рд░рд╛ рдХрдо рдЖрдо рд╣реИред  рдкрд╣рд▓реА рдмрд╛рд░, рдЖрд╕рд╡рди рдХрд╛ рд╡рд┐рдЪрд╛рд░ рд░рд┐рдЪ рдХрд╛рд░реБрдЖрдирд╛ рджреНрд╡рд╛рд░рд╛ <a href="https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf">"рдореЙрдбрд▓ рд╕рдВрдкреАрдбрд╝рди" рд▓реЗрдЦ рдореЗрдВ</a> рдкреНрд░рд╕реНрддрд╛рд╡рд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред  рдЗрд╕рдХрд╛ рд╕рд╛рд░ рд╕рд░рд▓ рд╣реИ: рдЖрдк рдПрдХ рд╣рд▓реНрдХреЗ рдореЙрдбрд▓ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдЬреЛ рдПрдХ рд╢рд┐рдХреНрд╖рдХ рдореЙрдбрд▓ рдХреЗ рд╡реНрдпрд╡рд╣рд╛рд░ рдпрд╛ рдпрд╣рд╛рдВ рддрдХ тАЛтАЛрдХрд┐ рдореЙрдбрд▓ рдХреА рдПрдХ рдЯреБрдХрдбрд╝реА рдХреА рдирдХрд▓ рдХрд░реЗрдЧрд╛ред  рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ, рд╢рд┐рдХреНрд╖рдХ рдмреАрдИрдЖрд░рдЯреА рд╣реЛрдЧрд╛, рдФрд░ рдЫрд╛рддреНрд░ рдХреЛрдИ рднреА рдкреНрд░рдХрд╛рд╢ рдореЙрдбрд▓ рд╣реЛрдЧрд╛ред </p><br><h2 id="zadacha">  рдХрд╛рд░реНрдп </h2><br><p>  рдЖрдЗрдП рдПрдХ рдЙрджрд╛рд╣рд░рдг рдХреЗ рд░реВрдк рдореЗрдВ рджреНрд╡рд┐рдЖрдзрд╛рд░реА рд╡рд░реНрдЧреАрдХрд░рдг рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЖрд╕рд╡рди рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░реЗрдВред  рдПрдирдПрд▓рдкреА рдХреЗ рд▓рд┐рдП рдореЙрдбрд▓ рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рдорд╛рдирдХ рд╕реЗрдЯ рд╕реЗ рдУрдкрди рдПрд╕рдПрд╕рдЯреА -2 рдбреЗрдЯрд╛рд╕реЗрдЯ рд▓реЗрдВред </p><br><p>  рдпрд╣ рдбреЗрдЯрд╛рд╕реЗрдЯ рднрд╛рд╡рдирд╛рддреНрдордХ рд░рдВрдЧ - рд╕рдХрд╛рд░рд╛рддреНрдордХ рдпрд╛ рдирдХрд╛рд░рд╛рддреНрдордХ рджреНрд╡рд╛рд░рд╛ рдЯреВрдЯреА рд╣реБрдИ IMDb рдХреЗ рд╕рд╛рде рдлрд┐рд▓реНрдореЛрдВ рдХреА рд╕рдореАрдХреНрд╖рд╛рдУрдВ рдХрд╛ рдПрдХ рд╕рдВрдЧреНрд░рд╣ рд╣реИред  рдЗрд╕ рдбреЗрдЯрд╛рд╕реЗрдЯ рдкрд░ рдореАрдЯреНрд░рд┐рдХ рд╕рдЯреАрдХрддрд╛ рд╣реИред </p><br><h2 id="obuchenie-bert-based-modeli-ili-uchitelya">  рдкреНрд░рд╢рд┐рдХреНрд╖рдг BERT- рдЖрдзрд╛рд░рд┐рдд рдореЙрдбрд▓ рдпрд╛ "рд╢рд┐рдХреНрд╖рдХ" </h2><br><p>  рд╕рдмрд╕реЗ рдкрд╣рд▓реЗ, рдЖрдкрдХреЛ "рдмрдбрд╝реЗ" BERT- рдЖрдзрд╛рд░рд┐рдд рдореЙрдбрд▓ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИ, рдЬреЛ рдПрдХ рд╢рд┐рдХреНрд╖рдХ рдмрди рдЬрд╛рдПрдЧрд╛ред  рдРрд╕рд╛ рдХрд░рдиреЗ рдХрд╛ рд╕рдмрд╕реЗ рдЖрд╕рд╛рди рддрд░реАрдХрд╛ рд╣реИ рдХрд┐ BERT рд╕реЗ рдПрдореНрдмреЗрдбрд┐рдВрдЧ рд▓реЗрдирд╛ рдФрд░ рдЙрдирдХреЗ рдКрдкрд░ рдХреНрд▓рд╛рд╕рд┐рдлрд╛рдпрд░ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдирд╛, рдПрдХ рдкрд░рдд рдХреЛ рдиреЗрдЯрд╡рд░реНрдХ рдореЗрдВ рдЬреЛрдбрд╝рдирд╛ред </p><br><p> <a href="https://github.com/huggingface/transformers">рдЯреНрд░рд╛рдВрд╕рдлреЙрд░реНрдорд░ рд▓рд╛рдЗрдмреНрд░реЗрд░реА</a> рдХреЗ рд▓рд┐рдП рдзрдиреНрдпрд╡рд╛рдж <a href="https://github.com/huggingface/transformers">,</a> рдпрд╣ рдХрд░рдирд╛ рдмрд╣реБрдд рдЖрд╕рд╛рди рд╣реИ, рдХреНрдпреЛрдВрдХрд┐ рдмрд░реНрдЯрдлреЙрд░рд╕реЗрдВрд╕реЗрдВрд╕ рдХреНрд▓реИрд╕рд┐рдлрд┐рдХреЗрд╢рди рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП рдПрдХ рддреИрдпрд╛рд░ рд╡рд░реНрдЧ рд╣реИред  рдореЗрд░реА рд░рд╛рдп рдореЗрдВ, рдЗрд╕ рдореЙрдбрд▓ рдХреЛ рдкрдврд╝рд╛рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдмрд╕реЗ рд╡рд┐рд╕реНрддреГрдд рдФрд░ рд╕рдордЭрдиреЗ рдпреЛрдЧреНрдп рдЯреНрдпреВрдЯреЛрд░рд┐рдпрд▓ <a href="https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca">рдЯреБрд╡рд░реНрдбреНрд╕ рдбреЗрдЯрд╛ рд╕рд╛рдЗрдВрд╕ рджреНрд╡рд╛рд░рд╛ рдкреНрд░рдХрд╛рд╢рд┐рдд рдХрд┐рдпрд╛</a> рдЧрдпрд╛ рдерд╛ред </p><br><p>  рдЖрдЗрдП рдХрд▓реНрдкрдирд╛ рдХрд░реЗрдВ рдХрд┐ рд╣рдореЗрдВ рдПрдХ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд BertForSequenceClassification рдореЙрдбрд▓ рдорд┐рд▓рд╛ред  рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ, num_labels = 2, рдХреНрдпреЛрдВрдХрд┐ рд╣рдорд╛рд░реЗ рдкрд╛рд╕ рдПрдХ рджреНрд╡рд┐рдЖрдзрд╛рд░реА рд╡рд░реНрдЧреАрдХрд░рдг рд╣реИред  рд╣рдо рдЗрд╕ рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ "рд╢рд┐рдХреНрд╖рдХ" рдХреЗ рд░реВрдк рдореЗрдВ рдХрд░реЗрдВрдЧреЗред </p><br><h2 id="obuchenie-uchenika">  "рдЫрд╛рддреНрд░" рд╕реАрдЦрдирд╛ </h2><br><p>  рдЖрдк рдПрдХ рдЫрд╛рддреНрд░ рдХреЗ рд░реВрдк рдореЗрдВ рдХрд┐рд╕реА рднреА рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рдХреЛ рд▓реЗ рд╕рдХрддреЗ рд╣реИрдВ: рдПрдХ рддрдВрддреНрд░рд┐рдХрд╛ рдиреЗрдЯрд╡рд░реНрдХ, рдПрдХ рд░реИрдЦрд┐рдХ рдореЙрдбрд▓, рдПрдХ рдирд┐рд░реНрдгрдп рд╡реГрдХреНрд╖ред  рдЖрдЗрдП рдмреЗрд╣рддрд░ рджреГрд╢реНрдп рдХреЗ рд▓рд┐рдП BiLSTM рдХреЛ рд╕рд┐рдЦрд╛рдиреЗ рдХрд╛ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред  рд╢реБрд░реВ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдо рдмрд┐рдирд╛ BERT рдХреЗ BiLSTM рд╕рд┐рдЦрд╛рдПрдВрдЧреЗред </p><br><p>  рдПрдХ рддрдВрддреНрд░рд┐рдХрд╛ рдиреЗрдЯрд╡рд░реНрдХ рдХреЗ рдЗрдирдкреБрдЯ рдХреЛ рдкрд╛рда рдкреНрд░рд╕реНрддреБрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рдЖрдкрдХреЛ рдЗрд╕реЗ рд╡реЗрдХреНрдЯрд░ рдХреЗ рд░реВрдк рдореЗрдВ рдкреНрд░рд╕реНрддреБрдд рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИред  рд╕рдмрд╕реЗ рдЖрд╕рд╛рди рддрд░реАрдХреЛрдВ рдореЗрдВ рд╕реЗ рдПрдХ рд╢рдмреНрджрдХреЛрд╢ рдореЗрдВ рдкреНрд░рддреНрдпреЗрдХ рд╢рдмреНрдж рдХреЛ рдЙрд╕рдХреЗ рд╕реВрдЪрдХрд╛рдВрдХ рдореЗрдВ рдореИрдк рдХрд░рдирд╛ рд╣реИред  рд╢рдмреНрджрдХреЛрд╢ рдореЗрдВ рд╣рдорд╛рд░реЗ рдбрд╛рдЯрд╛рд╕реЗрдЯ рдкреНрд▓рд╕ рджреЛ рд╕реЗрд╡рд╛ рд╢рдмреНрджреЛрдВ рдореЗрдВ рд╢реАрд░реНрд╖-рдПрди рд╕рдмрд╕реЗ рд▓реЛрдХрдкреНрд░рд┐рдп рд╢рдмреНрдж рд╢рд╛рдорд┐рд▓ рд╣реЛрдВрдЧреЗ: "рдкреИрдб" - "рдбрдореА рд╢рдмреНрдж" рддрд╛рдХрд┐ рд╕рднреА рдЕрдиреБрдХреНрд░рдо рдПрдХ рд╣реА рд▓рдВрдмрд╛рдИ рдХреЗ рд╣реЛрдВ, рдФрд░ рд╢рдмреНрджрдХреЛрд╢ рдХреЗ рдмрд╛рд╣рд░ рдХреЗ рд╢рдмреНрджреЛрдВ рдХреЗ рд▓рд┐рдП "рдЕрдирдХ"ред  рд╣рдо рдорд╢рд╛рд▓ рдХреЗ рдЙрдкрдХрд░рдг рдХреЗ рдорд╛рдирдХ рд╕реЗрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╢рдмреНрджрдХреЛрд╢ рдХрд╛ рдирд┐рд░реНрдорд╛рдг рдХрд░реЗрдВрдЧреЗред  рд╕рд╛рджрдЧреА рдХреЗ рд▓рд┐рдП, рдореИрдВрдиреЗ рдкреВрд░реНрд╡-рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рд╢рдмреНрдж рдПрдореНрдмреЗрдбрд┐рдВрдЧ рдХрд╛ рдЙрдкрдпреЛрдЧ рдирд╣реАрдВ рдХрд┐рдпрд╛ред <br></p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchtext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> data <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_vocab</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(X)</span></span></span><span class="hljs-function">:</span></span> X_split = [t.split() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> X] text_field = data.Field() text_field.build_vocab(X_split, max_size=<span class="hljs-number"><span class="hljs-number">10000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text_field <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pad</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(seq, max_len)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(seq) &lt; max_len: seq = seq + [<span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>] * (max_len - len(seq)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> seq[<span class="hljs-number"><span class="hljs-number">0</span></span>:max_len] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_indexes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vocab, words)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [vocab.stoi[w] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> words] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_dataset</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, y_real)</span></span></span><span class="hljs-function">:</span></span> torch_x = torch.tensor(x, dtype=torch.long) torch_y = torch.tensor(y, dtype=torch.float) torch_real_y = torch.tensor(y_real, dtype=torch.long) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> TensorDataset(torch_x, torch_y, torch_real_y)</code> </pre> <br><h3 id="model-bilstm">  рдореЙрдбрд▓ BiLSTM </h3><br><p>  рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП рдХреЛрдб рдЗрд╕ рддрд░рд╣ рджрд┐рдЦреЗрдЧрд╛: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.autograd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Variable <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SimpleLSTM</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, batch_size, device=None)</span></span></span><span class="hljs-function">:</span></span> super(SimpleLSTM, self).__init__() self.batch_size = batch_size self.hidden_dim = hidden_dim self.n_layers = n_layers self.embedding = nn.Embedding(input_dim, embedding_dim) self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout) self.fc = nn.Linear(hidden_dim * <span class="hljs-number"><span class="hljs-number">2</span></span>, output_dim) self.dropout = nn.Dropout(dropout) self.device = self.init_device(device) self.hidden = self.init_hidden() @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_device</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(device)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> device <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> torch.device(<span class="hljs-string"><span class="hljs-string">'cuda'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> device <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_hidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (Variable(torch.zeros(<span class="hljs-number"><span class="hljs-number">2</span></span> * self.n_layers, self.batch_size, self.hidden_dim).to(self.device)), Variable(torch.zeros(<span class="hljs-number"><span class="hljs-number">2</span></span> * self.n_layers, self.batch_size, self.hidden_dim).to(self.device))) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, text, text_lengths=None)</span></span></span><span class="hljs-function">:</span></span> self.hidden = self.init_hidden() x = self.embedding(text) x, self.hidden = self.rnn(x, self.hidden) hidden, cell = self.hidden hidden = self.dropout(torch.cat((hidden[<span class="hljs-number"><span class="hljs-number">-2</span></span>, :, :], hidden[<span class="hljs-number"><span class="hljs-number">-1</span></span>, :, :]), dim=<span class="hljs-number"><span class="hljs-number">1</span></span>)) x = self.fc(hidden) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x</code> </pre> <br><h3 id="obuchenie">  рдЯреНрд░реЗрдирд┐рдВрдЧ </h3><br><p>  рдЗрд╕ рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП, рдЖрдЙрдЯрдкреБрдЯ рд╡реЗрдХреНрдЯрд░ рдХрд╛ рдЖрдпрд╛рдо (batch_size, output_dim) рд╣реЛрдЧрд╛ред  рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдореЗрдВ, рд╣рдо рд╕рд╛рдорд╛рдиреНрдп рд▓реЙрдЧрд▓реЙрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗред  PyTorch рдореЗрдВ BCEWithLogitsLoss рдХреНрд▓рд╛рд╕ рд╣реИ рдЬреЛ рд╕рд┐рдЧреНрдореЙрдЗрдб рдФрд░ рдХреНрд░реЙрд╕ рдПрдиреНрдЯреНрд░реЙрдкреА рдХреЛ рдЬреЛрдбрд╝рддреА рд╣реИред  рдЖрдкрдХреЛ рдХреНрдпрд╛ рдЪрд╛рд╣рд┐рдП </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> criterion = torch.nn.BCEWithLogitsLoss() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> criterion(output, real_label.float())</code> </pre> <br><p>  рд╕реАрдЦрдиреЗ рдХреЗ рдПрдХ рдпреБрдЧ рдХреЗ рд▓рд┐рдП рдХреЛрдб: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_optimizer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model)</span></span></span><span class="hljs-function">:</span></span> optimizer = torch.optim.Adam(model.parameters()) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, <span class="hljs-number"><span class="hljs-number">2</span></span>, gamma=<span class="hljs-number"><span class="hljs-number">0.9</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> optimizer, scheduler <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">epoch_train_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, dataset, loss_func, batch_size)</span></span></span><span class="hljs-function">:</span></span> train_loss = <span class="hljs-number"><span class="hljs-number">0</span></span> train_sampler = RandomSampler(dataset) data_loader = DataLoader(dataset, sampler=train_sampler, batch_size=batch_size, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) model.train() optimizer, scheduler = get_optimizer(model) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, (text, bert_prob, real_label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(tqdm(data_loader, desc=<span class="hljs-string"><span class="hljs-string">'Train'</span></span>)): text, bert_prob, real_label = to_device(text, bert_prob, real_label) model.zero_grad() output = model(text.t(), <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>).squeeze(<span class="hljs-number"><span class="hljs-number">1</span></span>) loss = loss_func(output, bert_prob, real_label) loss.backward() optimizer.step() train_loss += loss.item() scheduler.step() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> train_loss / len(data_loader)</code> </pre> <br><p>  рдпреБрдЧ рдХреЗ рдмрд╛рдж рд╕рддреНрдпрд╛рдкрди рдХреЗ рд▓рд┐рдП рдХреЛрдб: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">epoch_evaluate_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, eval_dataset, loss_func, batch_size)</span></span></span><span class="hljs-function">:</span></span> eval_sampler = SequentialSampler(eval_dataset) data_loader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=batch_size, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) eval_loss = <span class="hljs-number"><span class="hljs-number">0.0</span></span> model.eval() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, (text, bert_prob, real_label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(tqdm(data_loader, desc=<span class="hljs-string"><span class="hljs-string">'Val'</span></span>)): text, bert_prob, real_label = to_device(text, bert_prob, real_label) output = model(text.t(), <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>).squeeze(<span class="hljs-number"><span class="hljs-number">1</span></span>) loss = loss_func(output, bert_prob, real_label) eval_loss += loss.item() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> eval_loss / len(data_loader)</code> </pre> <br><p>  рдпрджрд┐ рдпрд╣ рд╕рдм рдПрдХ рд╕рд╛рде рд░рдЦрд╛ рдЬрд╛рддрд╛ рд╣реИ, рддреЛ рд╣рдореЗрдВ рдореЙрдбрд▓ рдХреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдХреЛрдб рдорд┐рд▓рддреЗ рд╣реИрдВ: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> (TensorDataset, random_split, RandomSampler, DataLoader, SequentialSampler) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchtext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> data <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">device</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> torch.device(<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> torch.cuda.is_available() <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-string"><span class="hljs-string">"cpu"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_device</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> text = text.to(device()) bert_prob = bert_prob.to(device()) real_label = real_label.to(device()) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text, bert_prob, real_label <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LSTMBaseline</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(object)</span></span></span><span class="hljs-class">:</span></span> vocab_name = <span class="hljs-string"><span class="hljs-string">'text_vocab.pt'</span></span> weights_name = <span class="hljs-string"><span class="hljs-string">'simple_lstm.pt'</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, settings)</span></span></span><span class="hljs-function">:</span></span> self.settings = settings self.criterion = torch.nn.BCEWithLogitsLoss().to(device()) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.criterion(output, real_label.float()) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, text_field)</span></span></span><span class="hljs-function">:</span></span> model = SimpleLSTM( input_dim=len(text_field.vocab), embedding_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_dim=<span class="hljs-number"><span class="hljs-number">128</span></span>, output_dim=<span class="hljs-number"><span class="hljs-number">1</span></span>, n_layers=<span class="hljs-number"><span class="hljs-number">1</span></span>, bidirectional=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, batch_size=self.settings[<span class="hljs-string"><span class="hljs-string">'train_batch_size'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, X, y, y_real, output_dir)</span></span></span><span class="hljs-function">:</span></span> max_len = self.settings[<span class="hljs-string"><span class="hljs-string">'max_seq_length'</span></span>] text_field = get_vocab(X) X_split = [t.split() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> X] X_pad = [pad(s, max_len) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(X_split, desc=<span class="hljs-string"><span class="hljs-string">'pad'</span></span>)] X_index = [to_indexes(text_field.vocab, s) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(X_pad, desc=<span class="hljs-string"><span class="hljs-string">'to index'</span></span>)] dataset = to_dataset(X_index, y, y_real) val_len = int(len(dataset) * <span class="hljs-number"><span class="hljs-number">0.1</span></span>) train_dataset, val_dataset = random_split(dataset, (len(dataset) - val_len, val_len)) model = self.model(text_field) model.to(device()) self.full_train(model, train_dataset, val_dataset, output_dir) torch.save(text_field, os.path.join(output_dir, self.vocab_name)) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">full_train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, model, train_dataset, val_dataset, output_dir)</span></span></span><span class="hljs-function">:</span></span> train_settings = self.settings num_train_epochs = train_settings[<span class="hljs-string"><span class="hljs-string">'num_train_epochs'</span></span>] best_eval_loss = <span class="hljs-number"><span class="hljs-number">100000</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_train_epochs): train_loss = epoch_train_func(model, train_dataset, self.loss, self.settings[<span class="hljs-string"><span class="hljs-string">'train_batch_size'</span></span>]) eval_loss = epoch_evaluate_func(model, val_dataset, self.loss, self.settings[<span class="hljs-string"><span class="hljs-string">'eval_batch_size'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> eval_loss &lt; best_eval_loss: best_eval_loss = eval_loss torch.save(model.state_dict(), os.path.join(output_dir, self.weights_name))</code> </pre> <br><h3 id="distillyaciya">  рдЖрд╕рд╡рди </h3><br><p>  рдЗрд╕ рдЖрд╕рд╡рди рд╡рд┐рдзрд┐ рдХрд╛ рд╡рд┐рдЪрд╛рд░ <a href="https://arxiv.org/abs/1903.12136">рд╡рд╛рдЯрд░рд▓реВ рд╡рд┐рд╢реНрд╡рд╡рд┐рджреНрдпрд╛рд▓рдп рдХреЗ рд╢реЛрдзрдХрд░реНрддрд╛рдУрдВ рджреНрд╡рд╛рд░рд╛ рдПрдХ рд▓реЗрдЦ рд╕реЗ</a> рд▓рд┐рдпрд╛ <a href="https://arxiv.org/abs/1903.12136">рдЧрдпрд╛ рд╣реИ</a> ред  рдЬреИрд╕рд╛ рдХрд┐ рдореИрдВрдиреЗ рдКрдкрд░ рдХрд╣рд╛, "рдЫрд╛рддреНрд░" рдХреЛ "рд╢рд┐рдХреНрд╖рдХ" рдХреЗ рд╡реНрдпрд╡рд╣рд╛рд░ рдХреА рдирдХрд▓ рдХрд░рдирд╛ рд╕реАрдЦрдирд╛ рдЪрд╛рд╣рд┐рдПред  рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рд╡реНрдпрд╡рд╣рд╛рд░ рдХреНрдпрд╛ рд╣реИ?  рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ, рдпреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╕реЗрдЯ рдкрд░ рд╢рд┐рдХреНрд╖рдХ рдореЙрдбрд▓ рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгрд┐рдпрд╛рдВ рд╣реИрдВред  рдФрд░ рдореБрдЦреНрдп рд╡рд┐рдЪрд╛рд░ рд╕рдХреНрд░рд┐рдпрдг рдлрд╝рдВрдХреНрд╢рди рдХреЛ рд▓рд╛рдЧреВ рдХрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рдиреЗрдЯрд╡рд░реНрдХ рдЖрдЙрдЯрдкреБрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдирд╛ рд╣реИред  рдпрд╣ рдорд╛рдирд╛ рдЬрд╛рддрд╛ рд╣реИ рдХрд┐ рдЗрд╕ рддрд░рд╣ рд╕реЗ рдореЙрдбрд▓ рдЕрдВрддрд┐рдо рд╕рдВрднрд╛рд╡рдирд╛рдУрдВ рдХреЗ рдорд╛рдорд▓реЗ рдореЗрдВ рдЖрдВрддрд░рд┐рдХ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдХреЛ рдмреЗрд╣рддрд░ рдврдВрдЧ рд╕реЗ рд╕реАрдЦ рд╕рдХреЗрдЧрд╛ред </p><br><p>  рдореВрд▓ рд▓реЗрдЦ рдореЗрдВ рд╣рд╛рдирд┐ рдлрд╝рдВрдХреНрд╢рди рдХреЗ рд▓рд┐рдП рдПрдХ рд╢рдмреНрдж рдЬреЛрдбрд╝рдиреЗ рдХрд╛ рдкреНрд░рд╕реНрддрд╛рд╡ рд╣реИ, рдЬреЛ "рд▓реЙрдЧ" рддреНрд░реБрдЯрд┐ рдХреЗ рд▓рд┐рдП рдЬрд┐рдореНрдореЗрджрд╛рд░ рд╣реЛрдЧрд╛ - рдореЙрдбрд▓ рд▓реЙрдЧ рдХреЗ рдмреАрдЪ рдПрдордПрд╕рдИред </p><br><p><img src="https://habrastorage.org/webt/hx/_d/w9/hx_dw9ypkcwc_fhgui_jcappoo4.png"></p><br><p>  рдЗрди рдЙрджреНрджреЗрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП, рд╣рдо рджреЛ рдЫреЛрдЯреЗ рдмрджрд▓рд╛рд╡ рдХрд░рддреЗ рд╣реИрдВ: 1 рд╕реЗ 2 рддрдХ рдиреЗрдЯрд╡рд░реНрдХ рдЖрдЙрдЯрдкреБрдЯ рдХреА рд╕рдВрдЦреНрдпрд╛ рдХреЛ рдмрджрд▓реЗрдВ рдФрд░ рдиреБрдХрд╕рд╛рди рдлрд╝рдВрдХреНрд╢рди рдХреЛ рдареАрдХ рдХрд░реЗрдВред </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> a = <span class="hljs-number"><span class="hljs-number">0.5</span></span> criterion_mse = torch.nn.MSELoss() criterion_ce = torch.nn.CrossEntropyLoss() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> a*criterion_ce(output, real_label) + (<span class="hljs-number"><span class="hljs-number">1</span></span>-a)*criterion_mse(output, bert_prob)</code> </pre> <br><p>  рдЖрдк рдХреЗрд╡рд▓ рдореЙрдбрд▓ рдФрд░ рд╣рд╛рдирд┐ рдХреЛ рдлрд┐рд░ рд╕реЗ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рдХреЗ рд▓рд┐рдЦреЗ рдЧрдП рд╕рднреА рдХреЛрдб рдХрд╛ рдкреБрди: рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LSTMDistilled</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(LSTMBaseline)</span></span></span><span class="hljs-class">:</span></span> vocab_name = <span class="hljs-string"><span class="hljs-string">'distil_text_vocab.pt'</span></span> weights_name = <span class="hljs-string"><span class="hljs-string">'distil_lstm.pt'</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, settings)</span></span></span><span class="hljs-function">:</span></span> super(LSTMDistilled, self).__init__(settings) self.criterion_mse = torch.nn.MSELoss() self.criterion_ce = torch.nn.CrossEntropyLoss() self.a = <span class="hljs-number"><span class="hljs-number">0.5</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.a * self.criterion_ce(output, real_label) + (<span class="hljs-number"><span class="hljs-number">1</span></span> - self.a) * self.criterion_mse(output, bert_prob) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, text_field)</span></span></span><span class="hljs-function">:</span></span> model = SimpleLSTM( input_dim=len(text_field.vocab), embedding_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_dim=<span class="hljs-number"><span class="hljs-number">128</span></span>, output_dim=<span class="hljs-number"><span class="hljs-number">2</span></span>, n_layers=<span class="hljs-number"><span class="hljs-number">1</span></span>, bidirectional=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, batch_size=self.settings[<span class="hljs-string"><span class="hljs-string">'train_batch_size'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br><p>  рдмрд╕ рдЗрддрдирд╛ рд╣реА, рдЕрдм рд╣рдорд╛рд░рд╛ рдореЙрдбрд▓ "рдирдХрд▓" рдХрд░рдирд╛ рд╕реАрдЦ рд░рд╣рд╛ рд╣реИред </p><br><h3 id="sravnenie-modeley">  рдореЙрдбрд▓ рддреБрд▓рдирд╛ </h3><br><p>  рдореВрд▓ рд▓реЗрдЦ рдореЗрдВ, SST-2 рдХреЗ рд▓рд┐рдП рд╕рд░реНрд╡рд╢реНрд░реЗрд╖реНрда рд╡рд░реНрдЧреАрдХрд░рдг рдкрд░рд┐рдгрд╛рдо = 0 рдкрд░ рдкреНрд░рд╛рдкреНрдд рдХрд┐рдП рдЬрд╛рддреЗ рд╣реИрдВ, рдЬрдм рдореЙрдбрд▓ рдХреЗрд╡рд▓ рдирдХрд▓ рдХрд░рдирд╛ рд╕реАрдЦрддрд╛ рд╣реИ, рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд▓реЗрдмрд▓ рдХреЛ рдзреНрдпрд╛рди рдореЗрдВ рдирд╣реАрдВ рд░рдЦрддрд╛ рд╣реИред  рд╕рдЯреАрдХрддрд╛ рдЕрднреА рднреА BERT рд╕реЗ рдХрдо рд╣реИ, рд▓реЗрдХрд┐рди рдирд┐рдпрдорд┐рдд BiLSTM рд╕реЗ рдХрд╛рдлреА рдмреЗрд╣рддрд░ рд╣реИред </p><br><p><img src="https://habrastorage.org/webt/0m/y6/g7/0my6g7eahypj6eq3o52arxxldxq.png"></p><br><p>  рдореИрдВрдиреЗ рд▓реЗрдЦ рд╕реЗ рдкрд░рд┐рдгрд╛рдо рджреЛрд╣рд░рд╛рдиреЗ рдХреА рдХреЛрд╢рд┐рд╢ рдХреА, рд▓реЗрдХрд┐рди рдореЗрд░реЗ рдкреНрд░рдпреЛрдЧреЛрдВ рдореЗрдВ рд╕рд░реНрд╡реЛрддреНрддрдо рдкрд░рд┐рдгрд╛рдо = 0.5 рдкрд░ рдкреНрд░рд╛рдкреНрдд рд╣реБрдЖред </p><br><p>  рд╕рд╛рдорд╛рдиреНрдп рддрд░реАрдХреЗ рд╕реЗ LSTM рд╕реАрдЦрддреЗ рд╕рдордп рдпрд╣ рд╣рд╛рдирд┐ рдФрд░ рд╕рдЯреАрдХрддрд╛ рд░реЗрдЦрд╛рдВрдХрди рджрд┐рдЦрддрд╛ рд╣реИред  рдиреБрдХрд╕рд╛рди рдХреЗ рд╡реНрдпрд╡рд╣рд╛рд░ рдХреЛ рджреЗрдЦрддреЗ рд╣реБрдП, рдореЙрдбрд▓ рдиреЗ рддреЗрдЬреА рд╕реЗ рд╕реАрдЦрд╛, рдФрд░ рдХрд╣реАрдВ рди рдХрд╣реАрдВ рдЫрдареЗ рдпреБрдЧ рдХреЗ рдмрд╛рдж, рдлрд┐рд░ рд╕реЗ рджреЗрдЦрдирд╛ рд╢реБрд░реВ рд╣реБрдЖред </p><br><p><img src="https://habrastorage.org/webt/lk/bg/rn/lkbgrnank6obtu7pewsoalba9yk.png"></p><br><p>  рдЖрд╕рд╡рди рд░реЗрдЦрд╛рдВрдХрди: </p><br><p><img src="https://habrastorage.org/webt/gl/u5/7g/glu57giappdlhkc31wlpdulsdkc.png"></p><br><p>  рдбрд┐рд╕реНрдЯрд┐рд▓реНрдб BiLSTM рд╕рд╛рдорд╛рдиреНрдп рд╕реЗ рд▓рдЧрд╛рддрд╛рд░ рдмреЗрд╣рддрд░ рд╣реИред  рдпрд╣ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ рдХрд┐ рд╡реЗ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рдореЗрдВ рдмрд┐рд▓реНрдХреБрд▓ рд╕рдорд╛рди рд╣реИрдВ, рдПрдХрдорд╛рддреНрд░ рдЕрдВрддрд░ рд╢рд┐рдХреНрд╖рдг рдХреЗ рддрд░реАрдХреЗ рдореЗрдВ рд╣реИред  <a href="https://github.com/pvgladkov/knowledge-distillation/tree/master/experiments/sst2">рдореИрдВрдиреЗ GitHub рдкрд░</a> рдкреВрд░реНрдг рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЛрдб <a href="https://github.com/pvgladkov/knowledge-distillation/tree/master/experiments/sst2">рдкреЛрд╕реНрдЯ рдХрд┐рдпрд╛</a> ред </p><br><h2 id="zaklyuchenie">  рдирд┐рд╖реНрдХрд░реНрд╖ </h2><br><p>  рдЗрд╕ рдЧрд╛рдЗрдб рдореЗрдВ, рдореИрдВрдиреЗ рдЖрд╕рд╡рди рджреГрд╖реНрдЯрд┐рдХреЛрдг рдХреЗ рдореВрд▓ рд╡рд┐рдЪрд╛рд░ рдХреЛ рд╕рдордЭрд╛рдиреЗ рдХреА рдХреЛрд╢рд┐рд╢ рдХреАред  рдЫрд╛рддреНрд░ рдХреА рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рд╣рд╛рде рдореЗрдВ рдХрд╛рдо рдкрд░ рдирд┐рд░реНрднрд░ рдХрд░реЗрдЧреАред  рд▓реЗрдХрд┐рди рд╕рд╛рдорд╛рдиреНрдп рддреМрд░ рдкрд░, рдпрд╣ рджреГрд╖реНрдЯрд┐рдХреЛрдг рдХрд┐рд╕реА рднреА рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдХрд╛рд░реНрдп рдореЗрдВ рд▓рд╛рдЧреВ рд╣реЛрддрд╛ рд╣реИред  рдореЙрдбрд▓ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рдЪрд░рдг рдореЗрдВ рдЬрдЯрд┐рд▓рддрд╛ рдХреЗ рдХрд╛рд░рдг, рдЖрдк рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рдХреА рдореВрд▓ рд╕рд╛рджрдЧреА рдХреЛ рдмрдирд╛рдП рд░рдЦрддреЗ рд╣реБрдП, рдЗрд╕рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдореЗрдВ рдЙрд▓реНрд▓реЗрдЦрдиреАрдп рд╡реГрджреНрдзрд┐ рдкреНрд░рд╛рдкреНрдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/hi485290/">https://habr.com/ru/post/hi485290/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../hi485278/index.html">рднрдЧрд╡рд╛рди рдХрд╛ рд╣рд╛рдеред рдХреВрдкрди рдорджрдж</a></li>
<li><a href="../hi485280/index.html">рдЬрд╛рдУред FakeDbред рдкрд░реАрдХреНрд╖рдгреЛрдВ рдореЗрдВ рдбреЗрдЯрд╛рдмреЗрд╕ рдЙрддреНрд╕рд░реНрдЬрди</a></li>
<li><a href="../hi485284/index.html">рд╕реНрдкрд┐рдХ тДв рдкреНрд░рд╛рдЗрдо рд▓реЗрдЧреЛ┬о рдПрдЬреБрдХреЗрд╢рди рдХреА рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдВ</a></li>
<li><a href="../hi485286/index.html">рд╣рдо рд╕рд╛рдорд╛рдиреЛрдВ рдХрд╛ рд╡рдЬрди рдХреИрд╕реЗ рдХрд░рддреЗ рд╣реИрдВ рдпрд╛ рдПрдХ рдЫреЛрдЯрд╛ рд╕реНрд╡рдЪрд╛рд▓рди ode</a></li>
<li><a href="../hi485288/index.html">рдкреНрдпрд╛рд░ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЗрдВрдбреА gamedev'a рдирдлрд░рдд</a></li>
<li><a href="../hi485294/index.html">2020 рдореЗрдВ Node.js рдкрд░ рдЖрдзреБрдирд┐рдХ рдкрд╛рдареНрдпрдХреНрд░рдо</a></li>
<li><a href="../hi485298/index.html">рд░рд╣рд╕реНрдпрдордп LyX рдХрд╛рд░реНрдпрдХреНрд░рдоред рднрд╛рдЧ рек</a></li>
<li><a href="../hi485300/index.html">рдПрдХреНрд╕рдкреНрд▓рд┐рдЯ рд░реЗрдбрд┐рд╕ рдЖрд░рд╕реАрдИ рдХреА рдЦреЛрдЬ рдореЗрдВ H2Miner рдХреГрдорд┐ рдХрд╛ рдирдпрд╛ рдкреНрд░рдХреЛрдк</a></li>
<li><a href="../hi485304/index.html">рдЖрдЗрдлреНрд░реЗрдо рддрддреНрд╡ рдХреА рдПрдХ рдЬреЛрдбрд╝реА</a></li>
<li><a href="../hi485312/index.html">рдореЛрдмрд╛рдЗрд▓ рдРрдкреНрд╕ рдХреЗ рд▓рд┐рдП DevOps</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
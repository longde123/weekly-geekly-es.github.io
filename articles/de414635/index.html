<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïô ‚úùÔ∏è üëâüèø KI, praktischer Kurs. Bildvorverarbeitung und -addition ‚åõÔ∏è ‚óΩÔ∏è ‚õ∑Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vorverarbeitung ist ein allgemeiner Begriff f√ºr alle Manipulationen, die mit Daten vor der √úbertragung ihres Modells durchgef√ºhrt werden, einschlie√üli...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>KI, praktischer Kurs. Bildvorverarbeitung und -addition</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/414635/">  Vorverarbeitung ist ein allgemeiner Begriff f√ºr alle Manipulationen, die mit Daten vor der √úbertragung ihres Modells durchgef√ºhrt werden, einschlie√ülich Zentrieren, Normalisieren, Verschieben, Drehen, Zuschneiden usw. In der Regel ist in zwei F√§llen eine Vorverarbeitung erforderlich. <br><br><ul><li>  <b>Datenbereinigung</b> .  Angenommen, einige Artefakte sind in den Bildern vorhanden.  Um das Modelltraining zu erleichtern, m√ºssen Artefakte in der Vorverarbeitungsphase entfernt werden. </li><li>  <b>Hinzuf√ºgung von Daten</b> .  Manchmal reichen kleine Datenmengen nicht f√ºr ein qualitativ hochwertiges Deep-Model-Training aus.  Ein Datenerg√§nzungsansatz ist sehr hilfreich bei der L√∂sung dieses Problems.  Dies ist der Prozess, bei dem jede Datenprobe auf verschiedene Weise transformiert und solche modifizierten Proben zum Datensatz hinzugef√ºgt werden.  Auf diese Weise kann die effektive Gr√∂√üe des Datensatzes erh√∂ht werden. </li></ul><br>  Betrachten wir einige m√∂gliche Transformationsmethoden w√§hrend der Vorverarbeitung und deren Implementierung durch Keras. <br><br><img src="https://habrastorage.org/webt/l-/qv/i5/l-qvi5bbsdqfjdcfheqqzjhrpzu.jpeg"><a name="habracut"></a><br><h2>  <font color="#0071c5">Daten</font> </h2><br>  In diesem und den folgenden Artikeln wird ein Datensatz verwendet, um die emotionale F√§rbung von Bildern zu analysieren.  Es enth√§lt 1.500 Beispiele von Bildern, die in zwei Klassen unterteilt sind - positiv und negativ.  Schauen wir uns einige Beispiele an. <br><br><img src="https://habrastorage.org/webt/mu/rf/_g/murf_geogu_lj6a9q4xoa4pn3si.jpeg"><br>  <i>Negative Beispiele</i> <br><br><img src="https://habrastorage.org/webt/nn/1_/vt/nn1_vtdtnxjci9mlhxxh25f4c5a.jpeg"><br>  <i>Positive Beispiele</i> <br><br><h2>  <font color="#0071c5">Transformationen reinigen</font> </h2><br>  Betrachten Sie nun eine Reihe m√∂glicher Transformationen, die h√§ufig zum Bereinigen von Daten verwendet werden, sowie deren Implementierung und Auswirkungen auf Bilder. <br><br>  Alle Codefragmente finden Sie im Buch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Preprocessing.ipynb</a> . <br><br><h3>  <font color="#0071c5">Neuskalierung</font> </h3><br>  Bilder werden normalerweise im RGB-Format (Rot, Gr√ºn, Blau) gespeichert.  In diesem Format wird das Bild durch ein dreidimensionales (oder dreikanaliges) Array dargestellt. <br><br><img src="https://habrastorage.org/webt/gk/bw/4w/gkbw4wlsomht08_atrneom6ugru.jpeg"><br>  <i>RGB-Zerlegung des Bildes.</i>  <i>Karte aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikiwand</a></i> <br><br>  Eine Dimension wird f√ºr Kan√§le verwendet (rot, gr√ºn und blau), die anderen beiden repr√§sentieren den Standort.  Somit wird jedes Pixel mit drei Zahlen codiert.  Jede Zahl wird normalerweise als vorzeichenloser 8-Bit-Integer-Typ (0 bis 255) gespeichert. <br><br>  <b>Eine Neuskalierung</b> ist eine Operation, bei der der numerische Datenbereich <b>ge√§ndert</b> wird, indem er einfach durch eine vorgegebene Konstante geteilt wird.  In tiefen neuronalen Netzen kann es aufgrund m√∂glicher √úberl√§ufe, Optimierungsprobleme, Stabilit√§t usw. erforderlich sein, die Eingabedaten auf einen Bereich von 0 bis 1 zu beschr√§nken. <br><br>  Zum Beispiel skalieren wir unsere Daten aus dem Bereich [0;  255] auf den Bereich [0;  1].  Im Folgenden verwenden wir die Keras <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>ImageDataGenerator-</i></a> Klasse, mit der Sie alle Transformationen im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>laufenden Betrieb</i></a> durchf√ºhren k√∂nnen. <br><br>  Erstellen wir zwei Instanzen dieser Klasse: eine f√ºr die transformierten Daten, die andere f√ºr die Quelle: <br><br><img src="https://habrastorage.org/webt/pf/0_/hv/pf0_hvqdqdqsqtwwaqw5nznhrhc.png"><br>  (oder f√ºr Standarddaten).  Es muss nur die Skalierungskonstante angegeben werden.  Dar√ºber hinaus k√∂nnen Sie mit der <i>ImageDataGenerator-</i> Klasse Daten direkt aus einem Ordner auf Ihrer Festplatte mithilfe der <i>flow_from_directory-</i> Methode <i>streamen</i> . <br><br>  Alle Parameter finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> , aber die Hauptparameter sind: der Pfad zum Stream und die Zielbildgr√∂√üe (wenn das Bild nicht mit der Zielgr√∂√üe √ºbereinstimmt, schneidet oder erstellt der Generator es einfach).  Schlie√ülich erhalten wir eine Probe vom Generator und betrachten die Ergebnisse. <br><br>  Optisch sind beide Bilder identisch, der Grund daf√ºr ist jedoch, dass Python * -Tools die Gr√∂√üe von Bildern automatisch √§ndern <br><br><img src="https://habrastorage.org/webt/5s/o6/9o/5so69otm8hi5utmf09himqmoigm.jpeg"><br><br>  auf den Standardbereich, damit sie auf dem Bildschirm angezeigt werden k√∂nnen.  Betrachten Sie Rohdaten (Arrays).  Wie Sie sehen k√∂nnen, unterscheiden sich die Rohmassive genau 255-mal. <br><br><h3>  <font color="#0071c5">Graustufen</font> </h3><br>  Eine andere Art der Transformation, die n√ºtzlich sein kann, ist <i>Graustufen</i> , die ein Farb-RGB-Bild in ein Bild konvertiert, in dem alle Farben in Graustufen dargestellt werden.  Bei der herk√∂mmlichen Bildverarbeitung kann eine Graustufen√ºbersetzung in Kombination mit einem nachfolgenden Schwellenwert verwendet werden.  Dieses Transformationspaar kann verrauschte Pixel zur√ºckweisen und Formen im Bild definieren.  Heutzutage werden alle diese Operationen vom Convolutional Neural Network (CNN) ausgef√ºhrt, aber die Graustufenkonvertierung als Vorverarbeitungsschritt kann immer noch n√ºtzlich sein.  F√ºhren Sie diesen Schritt in Keras mit derselben Generatorklasse aus. <br><br><img src="https://habrastorage.org/webt/uh/ay/li/uhaylivvkd5aznb1k-l9hzeeabw.jpeg"><br><br>  Hier erstellen wir nur eine Instanz der Klasse und nehmen zwei verschiedene Generatoren daraus.  Der zweite Generator setzt den Parameter <i>color_mode</i> auf "Graustufen" (der Standardwert ist "RGB"). <br><br><h3>  <font color="#0071c5">Proben zentrieren</font> </h3><br>  Wir haben bereits gesehen, dass die Werte von Rohdaten im Bereich von 0 bis 255 liegen. Somit ist eine Stichprobe eine dreidimensionale Anordnung von Zahlen von 0 bis 255. Angesichts der Prinzipien der Stabilit√§tsstabilit√§t (Beseitigung des Problems des Verschwindens oder S√§ttigens von Werten) <i>kann es erforderlich sein, den Datensatz zu normalisieren so dass der Durchschnitt jeder Datenprobe 0 ist</i> . <br><br><img src="https://habrastorage.org/webt/eh/6s/jg/eh6sjgccinzuviy9vrzklcbzqas.jpeg"><br><br>  Dazu ist es notwendig, den Durchschnittswert √ºber die gesamte Stichprobe zu berechnen und von jeder Zahl in der gegebenen Stichprobe abzuziehen. <br>  In Keras erfolgt dies mit dem Parameter <i>samplewise_center</i> . <br><br><h3>  <font color="#0071c5">Normalisierung der Standardabweichung der Proben</font> </h3><br>  Diese Vorverarbeitungsstufe basiert auf der gleichen Idee wie die Zentrierung der Proben, aber anstatt den Durchschnitt auf 0 von zu setzen, setzt sie die Standardabweichung auf 1. <br><br><img src="https://habrastorage.org/webt/_e/aq/4k/_eaq4kpjy1ox6l70homarb0tlxe.png"><br><br>  Die Normalisierung der <i>Standardabweichung</i> wird durch den Parameter <i>samplewise_std_normalization gesteuert</i> .  Es ist zu beachten, dass diese beiden Methoden zur Normalisierung von Proben h√§ufig zusammen angewendet werden. <br><br>  Diese Transformation kann in Deep-Learning-Modellen verwendet werden, um die Optimierungsstabilit√§t zu verbessern, indem die Auswirkungen explodierender Gradienten verringert werden. <br><br><h3>  <font color="#0071c5">Feature-Zentrierung</font> </h3><br>  In den beiden vorherigen Abschnitten wurde eine Normalisierungstechnik verwendet, bei der jede einzelne Datenprobe untersucht wurde.  Es gibt einen alternativen Ansatz zum Normalisierungsverfahren.  Betrachten Sie jede Zahl im Bildarray als Zeichen.  Dann ist <i>jedes Bild ein Merkmalsvektor</i> .  Der Datensatz enth√§lt viele solcher Vektoren.  Daher k√∂nnen wir sie als eine unbekannte <i>Verteilung betrachten</i> .  Diese Verteilung besteht aus mehreren Parametern und ihre Dimension entspricht der Anzahl der Features, dh Breite √ó H√∂he √ó 3. Obwohl die tats√§chliche Verteilung der Daten unbekannt ist, k√∂nnen Sie versuchen, sie durch Subtrahieren des durchschnittlichen Verteilungswerts zu normalisieren.  Es ist zu beachten, dass der Durchschnittswert ein Vektor derselben Dimension ist, dh es ist auch ein Bild.  Mit anderen Worten, wir mitteln √ºber den gesamten Datensatz und nicht √ºber eine Stichprobe. <br><br>  Es gibt einen speziellen Keras-Parameter namens <i>featurewise_centering</i> , aber leider gab es ab August 2017 einen Fehler bei der Implementierung.  Deshalb setzen wir es selbst um.  Zun√§chst betrachten wir den gesamten Datensatz im Speicher (wir k√∂nnen es uns leisten, da es sich um einen kleinen Datensatz handelt).  Dazu haben wir die Paketgr√∂√üe auf die Gr√∂√üe des Datensatzes eingestellt.  Dann berechnen wir das Durchschnittsbild √ºber den gesamten Datensatz und subtrahieren es schlie√ülich vom Testbild. <br><br><img src="https://habrastorage.org/webt/sm/wn/of/smwnofa7izsr-kyhn2r8mwab-dw.jpeg"><br><br><h3>  <font color="#0071c5">Normalisierung der Standardabweichung der Symptome</font> </h3><br>  Die Idee, die Standardabweichung zu normalisieren, entspricht genau der Idee der Zentrierung.  Der einzige Unterschied besteht darin, dass wir nicht den Durchschnitt subtrahieren, sondern durch die Standardabweichung dividieren.  Optisch ist das Ergebnis nicht viel anders.  Das gleiche passierte <br><br><img src="https://habrastorage.org/webt/im/j-/ge/imj-gegeoxxc_1dsd6km4vshs9e.png"><br>  W√§hrend der Neuskalierung wird die Konstante manuell angegeben, da die Normalisierung der Standardabweichung nichts anderes ist als eine Neuskalierung mit einer auf bestimmte Weise berechneten Konstante und mit einer einfachen Neuskalierung.  Beachten Sie, dass eine √§hnliche Idee zur Normalisierung von Datenpaketen das Herzst√ºck einer modernen Deep-Learning-Technik namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BatchNormalization ist</a> . <br><br><img src="https://habrastorage.org/webt/lf/lc/rg/lflcrgjs6a42y7u1vvtna5nz8jy.jpeg"><br><br><h2>  <font color="#0071c5">Transformation mit dem Zusatz</font> </h2><br>  In diesem Abschnitt werden einige datenabh√§ngige Transformationen betrachtet, die explizit die grafische Natur der Daten verwenden.  Diese Arten von Transformationen werden h√§ufig in Datenadditionsverfahren verwendet. <br><br><h3>  <font color="#0071c5">Drehung</font> </h3><br>  Diese Art der Transformation dreht das Bild in eine bestimmte Richtung (im oder gegen den Uhrzeigersinn). <br><br>  Der Parameter, der die Drehung erm√∂glicht, hei√üt <i>rotationsbereich</i> .  Es gibt den Bereich in Grad an, aus dem der Drehwinkel zuf√§llig mit einer gleichm√§√üigen Verteilung ausgew√§hlt wird.  Es ist zu beachten, dass sich die Bildgr√∂√üe w√§hrend der Drehung nicht √§ndert.  So k√∂nnen einige Teile des Bildes beschnitten und einige gef√ºllt werden. <br><br><img src="https://habrastorage.org/webt/vh/d8/s-/vhd8s-j4ojpyqrcat9rc3jzegm4.png"><br><br>  Der <i>F√ºllmodus</i> wird mit dem Parameter <i>fill_mode eingestellt</i> .  Es werden verschiedene F√ºllmethoden unterst√ºtzt, aber hier verwenden wir die <i>Konstantenmethode</i> als Beispiel. <br><br><img src="https://habrastorage.org/webt/t3/bo/4f/t3bo4fjn4tm96ergzw_ucahbouq.jpeg"><br><br><h3>  <font color="#0071c5">Horizontale Verschiebung</font> </h3><br>  Diese Art der Transformation verschiebt das Bild in eine bestimmte Richtung entlang der horizontalen Achse (links oder rechts). <br><br><img src="https://habrastorage.org/webt/gw/j9/bh/gwj9bh9j8viw1eif_x1vpkpbh_s.png"><br><br>  Die Gr√∂√üe der Verschiebung kann mit dem Parameter <i>width_shift_range</i> bestimmt und als Teil der Gesamtbildbreite gemessen werden. <br><br><h3>  <font color="#0071c5">Vertikale Verschiebung</font> </h3><br><img src="https://habrastorage.org/webt/re/pe/65/repe65wt5ekksezxikypdtglpyc.jpeg"><br><br>  Verschiebt das Bild entlang der vertikalen Achse (nach oben oder unten).  Der Parameter, der den Verschiebungsbereich steuert, wird als <i>height_shift-</i> Generator bezeichnet und auch als Teil der Gesamth√∂he des Bildes gemessen. <br><br><h3>  <font color="#0071c5">Beschneiden</font> </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Eine Zuschneidekonvertierung</a> oder ein Zuschneiden verschiebt jeden Punkt in vertikaler Richtung um einen Betrag, der proportional zum Abstand von diesem Punkt zum Bildrand ist.  Beachten Sie, dass im allgemeinen Fall die Richtung nicht vertikal sein muss und beliebig ist. <br><br><img src="https://habrastorage.org/webt/mc/9w/0-/mc9w0-6flw4ewwlqyrs9gczpzlg.jpeg"><br><br>  Der Parameter, der die Verschiebung <i>steuert,</i> hei√üt <i>Scherbereich</i> und entspricht dem Abweichungswinkel (im Bogenma√ü) zwischen der horizontalen Linie im Originalbild und dem Bild (im mathematischen Sinne) dieser Linie im transformierten Bild. <br><br><h3>  <font color="#0071c5">Vergr√∂√üern / Verkleinern</font> </h3><br><img src="https://habrastorage.org/webt/bd/ut/i6/bduti6xglamlgqkaiv2ck2ef5he.png"><br>  Diese Art der Transformation n√§hert sich dem Originalbild an oder entfernt es.  Der Parameter <i>zoom_range</i> steuert den Zoomfaktor. <br><br><img src="https://habrastorage.org/webt/ij/nj/4l/ijnj4ln-l8raqleq-lbmwkumewc.jpeg"><br><br>  Wenn <i>zoom_range</i> beispielsweise 0,5 ist, wird der Zoomfaktor aus dem Bereich [0,5, 1,5] ausgew√§hlt. <br><br><img src="https://habrastorage.org/webt/wn/vd/zo/wnvdzog-l-clsbupmziwcszoh9o.jpeg"><br><br><h3>  <font color="#0071c5">Horizontaler Flip</font> </h3><br><img src="https://habrastorage.org/webt/qj/xr/r9/qjxrr9l5ktaubq2t_9cagdp7es0.png"><br><br>  Kippt das Bild relativ zur vertikalen Achse.  Sie kann mit dem Parameter <i>horizontal_flip</i> ein- oder ausgeschaltet werden. <br><br><h3>  <font color="#0071c5">Vertikaler Flip</font> </h3><br><img src="https://habrastorage.org/webt/fb/im/g1/fbimg1quzp5t83brbi8ztfv42jk.jpeg"><br><br>  Dreht das Bild um die horizontale Achse.  Der Parameter <i>vertical_flip</i> (vom Typ Boolean) steuert das Vorhandensein oder Fehlen dieser Transformation. <br><br><h2>  <font color="#0071c5">Kombination</font> </h2><br>  Wir wenden alle beschriebenen Arten von Transformationen des Komplements gleichzeitig an und sehen, was passiert.  Denken Sie daran, dass die Parameter f√ºr alle Transformationen zuf√§llig aus einem bestimmten Bereich ausgew√§hlt werden.  Daher m√ºssen wir eine Reihe von Stichproben mit einem signifikanten Grad an Diversit√§t erhalten. <br><br>  Wir initiieren <i>ImageDataGenerator</i> mit allen verf√ºgbaren Parametern und √ºberpr√ºfen den roten Hydranten auf dem Bild. <br><br><img src="https://habrastorage.org/webt/05/tg/el/05tgelnzqacfl5gkwkpgzrrr8qe.jpeg"><br><br>  Beachten Sie, dass der <i>konstante</i> F√ºllmodus nur zur besseren Visualisierung verwendet wurde.  Jetzt werden wir einen erweiterten Auff√ºllmodus verwenden, der als <i>n√§chster bezeichnet wird</i> .  In diesem Modus wird dem leeren Pixel die Farbe des n√§chsten vorhandenen Pixels zugewiesen. <br><br><img src="https://habrastorage.org/webt/l-/qv/i5/l-qvi5bbsdqfjdcfheqqzjhrpzu.jpeg"><br><h2>  <font color="#0071c5">Fazit</font> </h2><br>  Dieser Artikel bietet einen √úberblick √ºber die grundlegenden Techniken f√ºr die Bildvorverarbeitung, z. B. Skalieren, Normalisieren, Drehen, Verschieben und Zuschneiden.  Sie demonstrierten auch die Implementierung dieser Transformationstechniken unter Verwendung von Keras und ihre Einf√ºhrung in den Deep-Learning-Prozess sowohl technisch ( <i>ImageDataGenerator-</i> Klasse) als auch ideologisch ( <i>Datenerg√§nzung</i> ). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414635/">https://habr.com/ru/post/de414635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414625/index.html">Data Center World: Lohnt sich die Fahrt?</a></li>
<li><a href="../de414627/index.html">Sichere Entwicklung an PHDays 8: Ergebnisse des PDUG Community Meetings</a></li>
<li><a href="../de414629/index.html">Die Weltgesundheitsorganisation erkennt offiziell die Existenz von Spielsucht an</a></li>
<li><a href="../de414631/index.html">Zusammenfassung des Buches Praktischer Leitfaden zum Testen in DevOps, Katrina Clokie</a></li>
<li><a href="../de414633/index.html">Es gibt S.L.O.N.a in Teilen. ITAM einf√ºhren und nicht ersticken (Teil 2)</a></li>
<li><a href="../de414637/index.html">IPhone √ºbertr√§gt automatisch Koordinaten, wenn 911 angerufen wird</a></li>
<li><a href="../de414639/index.html">Hacker-Dienste im dunklen Internet</a></li>
<li><a href="../de414641/index.html">XBRL z√§hmen: Analystenhinweise</a></li>
<li><a href="../de414643/index.html">Shop-Codierung: Gewinner des M.SMART-Hackathons</a></li>
<li><a href="../de414645/index.html">ONETRAK - intelligente Armb√§nder und mehr</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
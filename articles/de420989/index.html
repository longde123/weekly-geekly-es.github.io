<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìÇ ‚öõÔ∏è üñ±Ô∏è Warum sollten Sie Radeon nicht wegwerfen, wenn Sie gerne maschinell lernen? üíá üñïüèº üëÇüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich konnte als Student meinen Arbeitsplatz abholen. Logischerweise habe ich AMD-Computerl√∂sungen bevorzugt. weil es  billig  profitabel in Bezug auf P...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Warum sollten Sie Radeon nicht wegwerfen, wenn Sie gerne maschinell lernen?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420989/"><p><img src="https://habrastorage.org/webt/qk/l2/et/qkl2etw2okgtjnaiuwzytjudazy.jpeg" alt="Bild"></p><br><p>  Ich konnte als Student meinen Arbeitsplatz abholen.  Logischerweise habe ich AMD-Computerl√∂sungen bevorzugt.  weil es <del>  billig </del>  profitabel in Bezug auf Preis / Qualit√§t.  Ich habe die Komponenten f√ºr eine lange Zeit aufgenommen, am Ende bin ich mit 40k mit einem Satz FX-8320 und RX-460 2GB eingestiegen.  Anfangs schien dieses Kit perfekt zu sein!  Mein Mitbewohner und ich haben Monero leicht abgebaut und mein Set zeigte 650 h / s gegen√ºber 550 h / s auf einem Set von i5-85xx und Nvidia 1050Ti.  Von meinem Set im Raum war es zwar nachts etwas hei√ü, aber dies wurde entschieden, als ich einen Turmk√ºhler f√ºr die CPU kaufte. </p><a name="habracut"></a><br><h3 id="skazka-konchilas">  Die Geschichte ist vorbei </h3><br><p>  Alles war genau wie in einem M√§rchen, bis ich mich f√ºr maschinelles Lernen im Bereich Computer Vision interessierte.  Noch genauer - bis ich mit Eingabebildern mit einer Aufl√∂sung von mehr als 100x100px arbeiten musste (bis zu diesem Punkt kam mein 8-Core-FX z√ºgig zurecht).  Die erste Schwierigkeit war die Aufgabe, Emotionen zu bestimmen.  4 ResNet-Ebenen, geben Sie Bilder 100x100 und 3000 Bilder in das Trainingsset ein.  Und jetzt - 9 Stunden Training 150 Epochen auf der CPU. <br>  Aufgrund dieser Verz√∂gerung leidet nat√ºrlich der iterative Entwicklungsprozess.  Bei der Arbeit hatten wir Nvidia 1060 6 GB und trainierten f√ºr eine √§hnliche Struktur (obwohl dort die Regression trainiert wurde, um Objekte zu lokalisieren). Sie flog in 15 bis 20 Minuten - 8 Sekunden f√ºr eine √Ñra von 3,5.000 Bildern.  Wenn Sie einen solchen Kontrast unter der Nase haben, wird das Atmen noch schwieriger. </p><br><p>  Ratet mal, mein erster Schritt nach all dem?  Ja, ich habe mit meinem Nachbarn 1050Ti verhandelt.  Mit Argumenten √ºber die Nutzlosigkeit von CUDA f√ºr ihn, mit einem Angebot, meine Karte gegen Aufpreis umzutauschen.  Aber alles umsonst.  Und jetzt poste ich meinen RX 460 auf Avito und √ºberpr√ºfe den gesch√§tzten 1050Ti auf den Websites von Citylink und TechnoPoint.  Selbst im Falle eines erfolgreichen Verkaufs der Karte m√ºsste ich weitere 10.000 finden (ich bin ein Student, wenn auch ein funktionierender). </p><br><h3 id="guglyu">  Google </h3><br><p>  Okay  Ich werde googeln, wie man Radeon unter Tensorflow benutzt.  Da ich wusste, dass dies eine exotische Aufgabe war, hoffte ich nicht besonders, etwas Vern√ºnftiges zu finden.  Sammeln Sie unter Ubuntu, ob es startet oder nicht, und holen Sie sich einen Ziegelstein - S√§tze aus den Foren. </p><br><p>  Und so bin ich in die andere Richtung gegangen - ich habe nicht Tensorflow AMD Radeon, sondern Keras AMD Radeon googelt.  Es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bringt</a> mich sofort auf die Seite von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PlaidML</a> .  Ich starte <a href="">es</a> in 15 Minuten (obwohl ich Keras auf 2.0.5 downgraden musste) und stelle das Netzwerk so ein, dass es lernt.  Die erste Beobachtung - die √Ñra ist 35 Sekunden statt 200. </p><br><h3 id="lezu-issledovat">  Klettern, um zu erkunden </h3><br><p>  Die Autoren von PlaidML sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vertex.ai</a> , das Teil der Intel-Projektgruppe (!) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ist</a> .  Das Entwicklungsziel ist maximale plattform√ºbergreifende.  Dies erh√∂ht nat√ºrlich das Vertrauen in das Produkt.  In ihrem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> hei√üt es, dass PlaidML aufgrund "gr√ºndlicher Optimierung" mit Tensorflow 1.3 + cuDNN 6 konkurrenzf√§hig ist. </p><br><p>  Wir fahren jedoch fort.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der folgende Artikel</a> zeigt uns zum Teil die interne Struktur der Bibliothek.  Der Hauptunterschied zu allen anderen Frameworks besteht in der automatischen Generierung von Berechnungskernen (in der Tensorflow-Notation ist der ‚ÄûKern‚Äú der vollst√§ndige Prozess der Ausf√ºhrung einer bestimmten Operation in einem Diagramm).  F√ºr die automatische Kernelgenerierung in PlaidML sind die genauen Abmessungen aller Tensoren, Konstanten, Schritte, Faltungsgr√∂√üen und Grenzwerte, mit denen Sie sp√§ter arbeiten m√ºssen, sehr wichtig.  Beispielsweise wird argumentiert, dass die weitere Erstellung effektiver Kernel f√ºr 1 und 32 Stapelgr√∂√üen oder f√ºr Windungen der Gr√∂√üen 3x3 und 7x7 unterschiedlich ist.  Mit diesen Daten generiert das Framework selbst die effizienteste Methode zum Parallelisieren und Ausf√ºhren aller Vorg√§nge f√ºr ein bestimmtes Ger√§t mit bestimmten Merkmalen.  Wenn Sie sich Tensorflow ansehen, m√ºssen wir beim Erstellen neuer Operationen auch den Kernel f√ºr diese implementieren - und die Implementierungen sind f√ºr Single-Threaded-, Multi-Threaded- oder CUDA-kompatible Kernel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sehr unterschiedlich</a> .  Das hei√üt,  PlaidML ist deutlich flexibler. </p><br><p>  Wir gehen weiter.  Die Implementierung ist in der selbstgeschriebenen Sprache <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tile geschrieben</a> .  Diese Sprache hat die folgenden Hauptvorteile - die N√§he der Syntax zu mathematischen Notationen (aber verr√ºckt werden!): </p><br><p><img src="https://habrastorage.org/webt/5w/j-/t_/5wj-t_9lnzzlcln4enex-mltn9q.png" alt="Bild"></p><br><p>  Und automatische Differenzierung aller deklarierten Operationen.  In TensorFlow wird beispielsweise beim Erstellen einer neuen benutzerdefinierten Operation dringend empfohlen, eine Funktion zum Berechnen der Verl√§ufe zu schreiben.  Wenn wir also unsere eigenen Operationen in der Tile-Sprache erstellen, m√ºssen wir nur sagen, <strong>WAS</strong> wir berechnen m√∂chten, ohne dar√ºber nachzudenken, wie dies in Bezug auf Hardwareger√§te zu ber√ºcksichtigen ist. </p><br><p>  Zus√§tzlich wird eine Optimierung der Arbeit mit DRAM und einem Analogon des L1-Cache in der GPU durchgef√ºhrt.  Rufen Sie das schematische Ger√§t auf: </p><br><p><img src="https://habrastorage.org/webt/sx/kf/hn/sxkfhnnaru91nkmrvbwqesxnsxs.png" alt="Bild"></p><br><p>  Zur Optimierung werden alle verf√ºgbaren Daten √ºber das Ger√§t verwendet - Cache-Gr√∂√üe, Cache-Zeilenbreite, DRAM-Bandbreite usw.  Die Hauptmethoden bestehen darin, das gleichzeitige Lesen von ausreichend gro√üen Bl√∂cken aus dem DRAM sicherzustellen (ein Versuch, eine Adressierung an verschiedene Bereiche zu vermeiden) und zu erreichen, dass die in den Cache geladenen Daten mehrmals verwendet werden (ein Versuch, zu vermeiden, dass dieselben Daten mehrmals neu geladen werden). </p><br><p>  Alle Optimierungen finden in der ersten √Ñra des Trainings statt und verl√§ngern gleichzeitig die Zeit des ersten Laufs erheblich: </p><br><p><img src="https://habrastorage.org/webt/3e/0v/of/3e0vofsvwm0y5urlztncxdxmurc.jpeg" alt="Bild"></p><br><p>  Dar√ºber hinaus ist anzumerken, dass dieses Framework an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenCL</a> gebunden ist.  Der Hauptvorteil von OpenCL ist, dass es ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Standard f√ºr heterogene Systeme ist und nichts Sie daran hindert, den Kernel auf der CPU auszuf√ºhren</a> .  Ja, hier liegt eines der Hauptgeheimnisse des plattform√ºbergreifenden PlaidML. </p><br><h3 id="zaklyuchenie">  Fazit </h3><br><p>  Nat√ºrlich ist das Training auf dem RX 460 immer noch 5-6 mal langsamer als auf dem 1060, aber Sie k√∂nnen die Preiskategorien von Grafikkarten vergleichen!  Dann bekam ich einen RX 580 8 GB (sie liehen mir!) Und die Zeit, die f√ºr die Ausf√ºhrung der √Ñra ben√∂tigt wurde, wurde auf 20 Sekunden reduziert, was fast vergleichbar ist. </p><br><p>  Der vertex.ai-Blog enth√§lt ehrliche Grafiken (mehr ist besser): </p><br><p><img src="https://habrastorage.org/webt/no/bm/pz/nobmpzbv8-b_6coixtftrmwumrq.png" alt="Bild"></p><br><p>  Es ist ersichtlich, dass PlaidML mit Tensorflow + CUDA konkurrenzf√§hig ist, f√ºr aktuelle Versionen jedoch sicherlich nicht schneller.  Aber PlaidML-Entwickler planen wahrscheinlich nicht, in einen so offenen Kampf einzutreten.  Ihr Ziel ist Universalit√§t, plattform√ºbergreifend. </p><br><p>  Ich werde hier eine nicht ganz vergleichende Tabelle mit meinen Leistungsmessungen hinterlassen: </p><br><table><thead><tr><th>  Computerger√§t </th><th>  Laufzeit der √Ñra (Batch - 16), s </th></tr></thead><tbody><tr><td>  AMD FX-8320 tf </td><td>  200 </td></tr><tr><td>  RX 460 2 GB Plaid </td><td>  35 </td></tr><tr><td>  RX 580 8 GB Plaid </td><td>  20 </td></tr><tr><td>  1060 6 GB TF </td><td>  8 </td></tr><tr><td>  1060 6 GB Plaid </td><td>  10 </td></tr><tr><td>  Intel i7-2600 tf </td><td>  185 </td></tr><tr><td>  Intel i7-2600 Plaid </td><td>  240 </td></tr><tr><td>  GT 640 Plaid </td><td>  46 </td></tr></tbody></table><br><p>  Der neueste vertex.ai-Blogbeitrag und die neuesten √Ñnderungen am Repository sind vom Mai 2018.  Es scheint, dass wenn die Entwickler dieses Tools nicht aufh√∂ren, neue Versionen zu ver√∂ffentlichen, und immer mehr Leute, die von Nvidia beleidigt sind, mit PlaidML vertraut sind, sie viel h√§ufiger √ºber vertex.ai sprechen werden. </p><br><p>  Entdecken Sie Ihre Radeons! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420989/">https://habr.com/ru/post/de420989/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420975/index.html">Mach es nicht in der Produktion</a></li>
<li><a href="../de420977/index.html">QComboBox + QTreeView Tricks</a></li>
<li><a href="../de420979/index.html">Redux Basics (Lehrbuch, 2. Auflage)</a></li>
<li><a href="../de420981/index.html">"Ich kann Ihnen von den allgemeinen Schmerzen aller iOS-Entwickler erz√§hlen" - 10 Fragen an den Programmierer, Ausgabe 2</a></li>
<li><a href="../de420983/index.html">Forscher sagen, es sei fast unm√∂glich, sich vor Google-Spionage zu verstecken</a></li>
<li><a href="../de420991/index.html">Verfolgung</a></li>
<li><a href="../de420993/index.html">5 einfache Schritte zum Erstellen eines Servers zum Testen von Android-REST-Anforderungen</a></li>
<li><a href="../de420995/index.html">Wir w√§hlen das Passwort f√ºr die indische TIN in zwei Sekunden oder warum Brute-Force-Mathematik</a></li>
<li><a href="../de420997/index.html">KDD 2018, vierter Tag, Nobelpreistr√§ger tritt auf</a></li>
<li><a href="../de420999/index.html">Kivy. Xamarin Native reagieren. Drei Frameworks - ein Experiment (Teil 2)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
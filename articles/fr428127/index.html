<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ’‡ğŸ½ ğŸ˜‘ ğŸ”½ Cache Nginx: tout nouveau - vieux bien oubliÃ© ğŸ‘¨ğŸ¾â€ğŸ”¬ ğŸ†’ ğŸ‘®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans la vie de chaque projet, le moment vient oÃ¹ le serveur cesse de rÃ©pondre aux exigences SLA et commence littÃ©ralement Ã  s'Ã©touffer sur la quantitÃ©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cache Nginx: tout nouveau - vieux bien oubliÃ©</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428127/">  Dans la vie de chaque projet, le moment vient oÃ¹ le serveur cesse de rÃ©pondre aux exigences SLA et commence littÃ©ralement Ã  s'Ã©touffer sur la quantitÃ© de trafic entrant.  AprÃ¨s cela, le long processus de recherche de goulots d'Ã©tranglement, de requÃªtes lourdes, d'index mal crÃ©Ã©s, de donnÃ©es non mises en cache ou vice versa, de donnÃ©es trop souvent mises Ã  jour dans le cache et d'autres cÃ´tÃ©s sombres du projet, commence. <br><br>  Mais que faire lorsque votre code est Â«parfaitÂ», toutes les demandes lourdes sont placÃ©es en arriÃ¨re-plan, tout ce qui Ã©tait possible a Ã©tÃ© mis en cache et le serveur n'atteint toujours pas les indicateurs SLA dont nous avons besoin?  Si possible, vous pouvez bien sÃ»r acheter de nouvelles voitures, rÃ©partir une partie du trafic et oublier le problÃ¨me pendant un certain temps. <br><br>  Mais si vous avez le sentiment que votre serveur est capable de plus, ou s'il existe un paramÃ¨tre magique qui accÃ©lÃ¨re le site de 100 fois, vous pouvez rappeler la fonction nginx intÃ©grÃ©e qui vous permet de mettre en cache les rÃ©ponses du backend.  Voyons ce que c'est et comment cela peut aider Ã  augmenter le nombre de demandes traitÃ©es par le serveur. <a name="habracut"></a><br><br><h3>  Qu'est-ce que le cache Nginx et comment fonctionne-t-il? </h3><br>  Le cache Nginx peut rÃ©duire considÃ©rablement le nombre de demandes pour le backend.  Ceci est rÃ©alisÃ© en enregistrant la rÃ©ponse HTTP pendant un certain temps et en accÃ©dant Ã  nouveau Ã  la ressource, en la renvoyant du cache sans mandataire de la demande pour le backend.  La mise en cache, mÃªme pour une courte pÃ©riode, augmentera considÃ©rablement le nombre de requÃªtes traitÃ©es par le serveur. <br><br>  Avant de procÃ©der Ã  la configuration de nginx, vous devez vous assurer qu'il est construit avec le module Â«ngx_http_proxy_moduleÂ», car nous allons le configurer Ã  l'aide de ce module. <br><br>  Pour plus de commoditÃ©, vous pouvez placer la configuration dans un fichier sÃ©parÃ©, par exemple, Â«/etc/nginx/conf.d/cache.confÂ».  Examinons la directive proxy_cache_path, qui vous permet de configurer les paramÃ¨tres de stockage du cache. <br><br><pre><code class="hljs swift">proxy_cache_path /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/nginx/proxy_cache levels=<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">2</span></span> keys_zone=proxy_cache:15m max_size=1G;</code> </pre> <br>  Â«/ Var / lib / nginx / proxy_cacheÂ» spÃ©cifie le chemin de stockage du cache sur le serveur.  C'est dans ce rÃ©pertoire que nginx enregistrera les fichiers mÃªmes avec la rÃ©ponse du backend.  En mÃªme temps, nginx ne crÃ©era pas indÃ©pendamment un rÃ©pertoire pour le cache, vous devez vous en occuper vous-mÃªme. <br><br>  "Niveaux = 1: 2" - dÃ©finit le niveau d'imbrication des rÃ©pertoires avec un cache.  Les niveaux d'imbrication sont indiquÃ©s par Â«:Â», dans ce cas 2 rÃ©pertoires seront crÃ©Ã©s, au total 3 niveaux d'imbrication sont autorisÃ©s.  Pour chaque niveau d'imbrication, des valeurs de 1 Ã  2 sont disponibles, indiquant comment crÃ©er le nom du rÃ©pertoire. <br><br>  Le point important est que le nom du rÃ©pertoire n'est pas choisi au hasard, mais est crÃ©Ã© en fonction du nom du fichier.  Le nom du fichier, Ã  son tour, est le rÃ©sultat de la fonction md5 de la clÃ© de cache; nous examinerons la clÃ© de cache un peu plus tard. <br><br>  Voyons en pratique comment le chemin d'accÃ¨s au fichier cache est construit: <br><br><pre> <code class="hljs swift">/<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/nginx/proxy_cache/<span class="hljs-number"><span class="hljs-number">2</span></span>/<span class="hljs-number"><span class="hljs-number">49</span></span>/07edcfe6974569ab4da6634ad4e5d492</code> </pre> <br>  Le paramÃ¨tre "Keys_zone = proxy_cache: 15m" dÃ©finit le nom de la zone dans la mÃ©moire partagÃ©e, oÃ¹ toutes les clÃ©s actives et les informations les concernant sont stockÃ©es.  GrÃ¢ce Ã  Â«:Â» indique la taille de la mÃ©moire allouÃ©e en Mo.  Selon nginx, 1 Mo suffit pour stocker 8 000 clÃ©s. <br><br>  "Max_size = 1G" dÃ©finit la taille maximale du cache pour toutes les pages au-dessus desquelles nginx se chargera de supprimer les donnÃ©es moins nÃ©cessaires. <br><br>  Il est Ã©galement possible de contrÃ´ler la durÃ©e de vie des donnÃ©es dans le cache, pour cela il suffit de dÃ©finir le paramÃ¨tre Â«inactifÂ» de la directive Â«proxy_cache_pathÂ» qui est de 10 minutes par dÃ©faut.  Si pendant le temps spÃ©cifiÃ© dans le paramÃ¨tre Â«inactifÂ» il n'y a pas eu d'appel aux donnÃ©es de cache, alors ces donnÃ©es sont supprimÃ©es mÃªme si le cache n'est pas encore Â«aigreÂ». <br><br>  Ã€ quoi ressemble ce cache?  Il s'agit en fait d'un fichier normal sur le serveur, dont le contenu est Ã©crit: <br><br>  â€¢ clÃ© de cache; <br>  â€¢ en-tÃªtes de cache; <br>  â€¢ rÃ©ponse du contenu du backend. <br><br>  Si tout est clair avec les en-tÃªtes et la rÃ©ponse du backend, alors il y a un certain nombre de questions sur la Â«clÃ© de cacheÂ».  Comment est-il construit et comment peut-il Ãªtre gÃ©rÃ©? <br><br>  Pour dÃ©crire le modÃ¨le de construction d'une clÃ© de cache dans nginx, il existe une directive proxy_cache_key, dans laquelle une chaÃ®ne est spÃ©cifiÃ©e comme paramÃ¨tre.  Une chaÃ®ne peut Ãªtre constituÃ©e de toutes les variables disponibles dans nginx. <br><br>  Par exemple: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_key</span></span> <span class="hljs-variable"><span class="hljs-variable">$request_method</span></span><span class="hljs-variable"><span class="hljs-variable">$host</span></span><span class="hljs-variable"><span class="hljs-variable">$orig_uri</span></span>:<span class="hljs-variable"><span class="hljs-variable">$cookie_some_cookie</span></span>:<span class="hljs-variable"><span class="hljs-variable">$arg_some_arg</span></span>;</code> </pre> <br>  Le symbole Â«:Â» entre le paramÃ¨tre cookie et le paramÃ¨tre get est utilisÃ© pour Ã©viter les collisions entre les clÃ©s de cache, vous pouvez choisir n'importe quel autre symbole de votre choix.  Par dÃ©faut, nginx utilise la ligne suivante pour gÃ©nÃ©rer la clÃ©: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_key</span></span> <span class="hljs-variable"><span class="hljs-variable">$scheme</span></span><span class="hljs-variable"><span class="hljs-variable">$proxy_host</span></span><span class="hljs-variable"><span class="hljs-variable">$request_uri</span></span>;</code> </pre> <br>  Il convient de noter les directives suivantes qui vous aideront Ã  gÃ©rer votre mise en cache de maniÃ¨re plus flexible: <br><br>  <i>proxy_cache_valid</i> - SpÃ©cifie le temps de mise en cache des rÃ©ponses.  Il est possible d'indiquer le statut spÃ©cifique de la rÃ©ponse, par exemple 200, 302, 404, etc., ou de tout spÃ©cifier Ã  la fois en utilisant la construction Â«anyÂ».  Si seul le temps de mise en cache est spÃ©cifiÃ©, nginx mettra par dÃ©faut en cache uniquement les statuts 200, 301 et 302. <br><br>  Un exemple: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_valid</span></span> <span class="hljs-number"><span class="hljs-number">15m</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_valid</span></span> <span class="hljs-number"><span class="hljs-number">404</span></span> <span class="hljs-number"><span class="hljs-number">15s</span></span>;</code> </pre><br>  Dans cet exemple, nous avons dÃ©fini la durÃ©e de vie du cache sur 15 minutes pour les Ã©tats 200, 301, 302 (nginx les utilise par dÃ©faut, car nous n'avons pas spÃ©cifiÃ© d'Ã©tat spÃ©cifique).  La ligne suivante dÃ©finit le temps de mise en cache sur 15 secondes, uniquement pour les rÃ©ponses avec un Ã©tat de 404. <br><br>  <i>proxy_cache_lock</i> - Cette directive aidera Ã  Ã©viter plusieurs passes vers le backend immÃ©diatement aprÃ¨s un ensemble de cache, il suffit de dÃ©finir la valeur en position Â«onÂ».  Toutes les autres demandes attendront une rÃ©ponse dans le cache ou un dÃ©lai d'expiration pour bloquer la demande sur la page.  Par consÃ©quent, tous les dÃ©lais d'attente peuvent Ãªtre configurÃ©s. <br><br>  <i>proxy_cache_lock_age</i> - Vous permet de dÃ©finir un dÃ©lai d'expiration pour une rÃ©ponse du serveur, aprÃ¨s quoi la prochaine requÃªte lui sera envoyÃ©e une fois le cache dÃ©fini.  La valeur par dÃ©faut est 5 secondes. <br><br>  <i>proxy_cache_lock_timeout</i> - DÃ©finit le temps d'attente pour le verrouillage, aprÃ¨s quoi la demande sera envoyÃ©e au backend, mais la rÃ©ponse ne sera pas mise en cache.  La valeur par dÃ©faut est 5 secondes. <br><br>  <i>proxy_cache_use_stale</i> - Une autre directive utile qui vous permet de configurer quand il est possible d'utiliser un cache obsolÃ¨te. <br><br>  Un exemple: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_use_stale</span></span> <span class="hljs-literal"><span class="hljs-literal">error</span></span> timeout updating;</code> </pre> <br>  Dans ce cas, il utilisera un cache obsolÃ¨te en cas d'erreur de connexion, d'envoi d'une demande, de lecture d'une rÃ©ponse du serveur, de dÃ©passement de la limite d'attente pour l'envoi d'une demande, de lecture d'une rÃ©ponse du serveur, ou si les donnÃ©es du cache sont mises Ã  jour au moment de la demande. <br><br>  <i>proxy_cache_bypass</i> - SpÃ©cifie les conditions dans lesquelles nginx ne prendra pas de rÃ©ponse du cache, mais redirigera immÃ©diatement la demande vers le backend.  Si au moins un des paramÃ¨tres n'est pas vide et n'est pas Ã©gal Ã  Â«0Â».  Un exemple: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_bypass</span></span> <span class="hljs-variable"><span class="hljs-variable">$cookie_nocache</span></span> <span class="hljs-variable"><span class="hljs-variable">$arg_nocache</span></span>;</code> </pre> <br>  <i>proxy_no_cache</i> - DÃ©finit la condition dans laquelle nginx n'enregistrera pas la rÃ©ponse du backend dans le cache.  Le principe de fonctionnement est le mÃªme que celui de la directive proxy_cache_bypass. <br><br><h3>  ProblÃ¨mes possibles avec la mise en cache des pages </h3><br>  Comme mentionnÃ© ci-dessus, avec la mise en cache d'une rÃ©ponse HTTP, nginx enregistre les en-tÃªtes reÃ§us du backend.  Si votre site utilise une session, le cookie de session sera Ã©galement mis en cache.  Tous les utilisateurs qui visitent la page que vous avez eu la chance de mettre en cache recevront vos donnÃ©es personnelles stockÃ©es dans la session. <br><br>  Le prochain dÃ©fi auquel vous serez confrontÃ© est la gestion de la mise en cache.  Bien sÃ»r, vous pouvez dÃ©finir un temps de cache insignifiant de 2 Ã  5 minutes et cela suffira dans la plupart des cas.  Mais cela n'est pas applicable dans toutes les situations, nous allons donc rÃ©inventer notre vÃ©lo.  Maintenant, tout d'abord. <br><br>  <b>Gestion de la conservation des cookies</b> <br><br>  La mise en cache du cÃ´tÃ© nginx impose certaines restrictions de conception.  Par exemple, nous ne pouvons pas utiliser de sessions sur les pages mises en cache, puisque l'utilisateur n'atteint pas le backend, une autre limitation est la livraison de cookies par le backend.  Ã‰tant donnÃ© que nginx met en cache tous les en-tÃªtes, afin d'Ã©viter de stocker la session de quelqu'un d'autre dans le cache, nous devons interdire la livraison de cookies pour les pages mises en cache.  La directive proxy_ignore_headers nous y aidera.  L'argument rÃ©pertorie les en-tÃªtes qui doivent Ãªtre ignorÃ©s du backend. <br><br>  Un exemple: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_ignore_headers</span></span> <span class="hljs-string"><span class="hljs-string">"Set-Cookie"</span></span>;</code> </pre> <br>  Avec cette ligne, nous ignorons l'installation de cookies Ã  partir du serveur mandatÃ©, c'est-Ã -dire que l'utilisateur recevra une rÃ©ponse sans l'en-tÃªte "Set-Cookies".  En consÃ©quence, tout ce que le backend a tentÃ© d'Ã©crire dans le cookie sera ignorÃ© cÃ´tÃ© client, car il ne saura mÃªme pas que quelque chose lui Ã©tait destinÃ©.  Cette restriction de cookie doit Ãªtre prise en compte lors du dÃ©veloppement d'une application.  Par exemple, pour demander une autorisation, vous pouvez dÃ©sactiver l'allumage de l'en-tÃªte afin que l'utilisateur reÃ§oive un cookie de session. <br><br>  Vous devez Ã©galement prendre en compte la durÃ©e de vie de la session, elle peut Ãªtre consultÃ©e dans le paramÃ¨tre Â« <i>session.gc_maxlifetime</i> Â» de la configuration php.ini.  Imaginez que l'utilisateur se connecte au site et commence Ã  consulter le fil d'actualitÃ©s, toutes les donnÃ©es sont dÃ©jÃ  dans le cache nginx.  AprÃ¨s un certain temps, l'utilisateur remarque que son autorisation a disparu et il doit Ã  nouveau passer par le processus d'autorisation, bien qu'il soit restÃ© tout le temps sur le site pour regarder les informations.  Cela s'est produit parce que sur toutes ses demandes, nginx a renvoyÃ© le rÃ©sultat du cache sans envoyer de demande au backend.  Par consÃ©quent, le backend a dÃ©cidÃ© que l'utilisateur Ã©tait inactif et aprÃ¨s une heure spÃ©cifiÃ©e dans Â« <i>session.gc_maxlifetime</i> Â» a supprimÃ© le fichier de session. <br><br>  Pour Ã©viter que cela ne se produise, nous pouvons Ã©muler des demandes d'arriÃ¨re-plan.  Par exemple, via ajax, envoyez une demande qui sera transmise au backend.  Pour passer le cache nginx au backend, il suffit d'envoyer une requÃªte POST, vous pouvez Ã©galement utiliser la rÃ¨gle de la directive Â«proxy_cache_bypassÂ», ou tout simplement dÃ©sactiver le cache de cette page.  La demande n'a pas Ã  rendre quelque chose, il peut s'agir d'un fichier avec une seule ligne commenÃ§ant la session.  Le but d'une telle demande est de prolonger la durÃ©e de vie de la session pendant que l'utilisateur est sur le site, et nginx donne consciencieusement les donnÃ©es mises en cache Ã  toutes ses demandes. <br><br>  <b>Gestion du vidage du cache</b> <br><br>  Vous devez d'abord dÃ©terminer les exigences, le but que nous essayons d'atteindre.  Disons que notre site a une section avec une diffusion de texte des Ã©vÃ©nements sportifs populaires.  Lorsque le chargement de la page est donnÃ© depuis le cache, tous les nouveaux messages arrivent sur les sockets.  Pour que l'utilisateur puisse voir les messages actuels Ã  l'heure actuelle au premier dÃ©marrage, plutÃ´t qu'il y a 15 minutes, nous devons Ãªtre en mesure d'effacer indÃ©pendamment le cache nginx Ã  tout moment.  En mÃªme temps, nginx peut ne pas se trouver sur la mÃªme machine que l'application.  En outre, l'une des exigences pour une rÃ©initialisation sera la possibilitÃ© de supprimer le cache, sur plusieurs pages Ã  la fois. <br><br>  Avant de commencer Ã  rÃ©diger votre solution, voyons ce que nginx propose immÃ©diatement.  Pour rÃ©initialiser le cache, nginx a une directive spÃ©ciale appelÃ©e "proxy_cache_purge", qui enregistre la condition de rÃ©initialisation du cache.  La condition est en fait une ligne normale qui, si elle n'est pas vide et non Â«0Â», supprimera le cache par la clÃ© passÃ©e.  Prenons un petit exemple. <br><br><pre> <code class="hljs perl">proxy_cache_path /data/nginx/cache keys_zone=cache_zone:<span class="hljs-number"><span class="hljs-number">10</span></span><span class="hljs-keyword"><span class="hljs-keyword">m</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">map</span></span> $request_method $purge_method { PURGE <span class="hljs-number"><span class="hljs-number">1</span></span>; default <span class="hljs-number"><span class="hljs-number">0</span></span>; } server { ... location / { proxy_pass http:<span class="hljs-regexp"><span class="hljs-regexp">//backend</span></span>; proxy_cache cache_zone; proxy_cache_key $uri; proxy_cache_purge $purge_method; } }</code> </pre><br>  <i>Un exemple est tirÃ© du site officiel de nginx.</i> <br><br>  La variable $ purge_method est responsable du vidage du cache, qui est une condition pour la directive proxy_cache_purge et est dÃ©finie sur 0 par dÃ©faut.  Cela signifie que nginx fonctionne en mode Â«normalÂ» (il enregistre les rÃ©ponses du backend).  Mais si vous changez la mÃ©thode de demande en Â«PURGEÂ», puis au lieu de mandater la demande pour le backend avec l'enregistrement de la rÃ©ponse, l'entrÃ©e de cache sera supprimÃ©e Ã  l'aide de la clÃ© de mise en cache correspondante.  Il est Ã©galement possible de spÃ©cifier un masque de suppression en spÃ©cifiant un Â«*Â» Ã  la fin de la clÃ© de cache.  Ainsi, nous n'avons pas besoin de connaÃ®tre l'emplacement du cache sur le disque et le principe de formation des clÃ©s, nginx assume ces responsabilitÃ©s.  Mais cette approche prÃ©sente Ã©galement des inconvÃ©nients. <br><br><ul><li>  La directive proxy_cache_purge est disponible dans le cadre d'un abonnement commercial. </li><li>  Il est uniquement possible de supprimer le cache point par point, ou en utilisant le masque de la forme {clÃ© de cache} "*" </li></ul><br>  Ã‰tant donnÃ© que les adresses des pages mises en cache peuvent Ãªtre complÃ¨tement diffÃ©rentes, sans parties communes, l'approche avec le masque Â«*Â» et la directive Â«proxy_cache_purgeÂ» ne nous convient pas.  Reste Ã  rappeler un peu de thÃ©orie et Ã  dÃ©couvrir votre idÃ©e prÃ©fÃ©rÃ©e. <br><br>  Nous savons que le cache nginx est un fichier normal sur le serveur.  Nous avons spÃ©cifiÃ© indÃ©pendamment le rÃ©pertoire de stockage des fichiers de cache dans la directive "proxy_cache_path", nous avons mÃªme spÃ©cifiÃ© la logique de formation du chemin d'accÃ¨s au fichier Ã  partir de ce rÃ©pertoire en utilisant des "niveaux".  La seule chose qui nous manque est la formation correcte de la clÃ© de mise en cache.  Mais nous pouvons Ã©galement le voir dans la directive "proxy_cache_key".  Il ne nous reste plus qu'Ã : <br><br><ul><li>  forment le chemin d'accÃ¨s complet Ã  la page, exactement comme spÃ©cifiÃ© dans la directive proxy_cache_key; </li><li>  coder la chaÃ®ne rÃ©sultante dans md5; </li><li>  crÃ©er des rÃ©pertoires imbriquÃ©s en utilisant la rÃ¨gle du paramÃ¨tre Â«niveauxÂ». </li><li>  Et maintenant, nous avons dÃ©jÃ  le chemin d'accÃ¨s complet au fichier cache sur le serveur.  Il ne nous reste plus qu'Ã  supprimer ce fichier.  De la partie introductive, nous savons que nginx peut ne pas Ãªtre situÃ© sur la machine d'application, vous devez donc permettre de supprimer plusieurs adresses Ã  la fois.  Encore une fois, nous dÃ©crivons l'algorithme: </li><li>  Les chemins gÃ©nÃ©rÃ©s vers les fichiers de cache que nous Ã©crirons dans le fichier; </li><li>  Ã‰crivons un simple script bash que nous mettons sur la machine avec l'application.  Sa tÃ¢che sera de se connecter via ssh au serveur oÃ¹ nous avons mis en cache nginx et de supprimer tous les fichiers de cache spÃ©cifiÃ©s dans le fichier gÃ©nÃ©rÃ© Ã  l'Ã©tape 1; </li></ul><br>  Nous passons de la thÃ©orie Ã  la pratique, nous Ã©crirons un petit exemple illustrant notre algorithme de travail. <br><br>  Ã‰tape 1. GÃ©nÃ©ration d'un fichier avec des chemins d'accÃ¨s au cache. <br><br><pre> <code class="hljs powershell"><span class="hljs-variable"><span class="hljs-variable">$urls</span></span> = [ <span class="hljs-string"><span class="hljs-string">'httpGETdomain.ru/news/111/1:2'</span></span>, <span class="hljs-string"><span class="hljs-string">'httpGETdomain.ru/news/112/3:4'</span></span>, ]; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_nginx_cache_path</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url)</span></span></span></span> { <span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span> = md5(<span class="hljs-variable"><span class="hljs-variable">$url</span></span>); <span class="hljs-variable"><span class="hljs-variable">$firstDir</span></span> = substr(<span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span>, <span class="hljs-literal"><span class="hljs-literal">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-variable"><span class="hljs-variable">$secondDir</span></span> = substr(<span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span>, <span class="hljs-literal"><span class="hljs-literal">-3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"/var/lib/nginx/proxy_cache/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$firstDir</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$secondDir</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$nginxHash</span></span></span><span class="hljs-string">"</span></span>; } //        tmp <span class="hljs-variable"><span class="hljs-variable">$filePath</span></span> = tempnam(<span class="hljs-string"><span class="hljs-string">'tmp'</span></span>, <span class="hljs-string"><span class="hljs-string">'nginx_cache_'</span></span>); //      <span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span> = fopen(<span class="hljs-variable"><span class="hljs-variable">$filePath</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-variable"><span class="hljs-variable">$urls</span></span> as <span class="hljs-variable"><span class="hljs-variable">$url</span></span>) { //      <span class="hljs-variable"><span class="hljs-variable">$cachePath</span></span> = to_nginx_cache_path(<span class="hljs-variable"><span class="hljs-variable">$url</span></span>); //       fwrite(<span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span>, <span class="hljs-variable"><span class="hljs-variable">$cachePath</span></span> . PHP_EOL); } //     fclose(<span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span>); //  bash       exec(<span class="hljs-string"><span class="hljs-string">"/usr/local/bin/cache_remover </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$filePath</span></span></span><span class="hljs-string">"</span></span>);</code> </pre><br>  Veuillez noter que la variable $ urls contient l'url des pages mises en cache, dÃ©jÃ  au format proxy_cache_key spÃ©cifiÃ© dans la configuration nginx.  L'URL agit comme une balise pour les entitÃ©s affichÃ©es sur la page.  Par exemple, vous pouvez crÃ©er une table rÃ©guliÃ¨re dans la base de donnÃ©es, oÃ¹ chaque entitÃ© sera mappÃ©e sur une page spÃ©cifique sur laquelle elle est affichÃ©e.  Ensuite, lorsque vous modifiez des donnÃ©es, nous pouvons faire une sÃ©lection sur la table et supprimer le cache de toutes les pages dont nous avons besoin. <br><br>  Ã‰tape 2. Connectez-vous au serveur de cache et supprimez les fichiers de cache. <br><br><pre> <code class="hljs smalltalk">#      ,      <span class="hljs-type"><span class="hljs-type">FILE_LIST</span></span>=`cat <span class="hljs-string"><span class="hljs-string">$1</span></span> | tr <span class="hljs-comment"><span class="hljs-comment">"\n"</span></span> <span class="hljs-comment"><span class="hljs-comment">" "</span></span>` #   ssh  <span class="hljs-type"><span class="hljs-type">SSH</span></span>=`which ssh` <span class="hljs-type"><span class="hljs-type">USER</span></span>=<span class="hljs-comment"><span class="hljs-comment">"root"</span></span> #         nginx <span class="hljs-type"><span class="hljs-type">HOST</span></span>=<span class="hljs-comment"><span class="hljs-comment">"10.10.1.0"</span></span> #   <span class="hljs-type"><span class="hljs-type">KEY</span></span>=<span class="hljs-comment"><span class="hljs-comment">"/var/keys/id_rsa"</span></span> # <span class="hljs-type"><span class="hljs-type">SSH</span></span> ,          <span class="hljs-string"><span class="hljs-string">$S</span></span>SH -i <span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">KEY</span></span>} <span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">USER</span></span>}@<span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">HOST</span></span>} <span class="hljs-comment"><span class="hljs-comment">"rm -f ${FILE_LIST}"</span></span> #       rm -rf rm -f <span class="hljs-string"><span class="hljs-string">$1</span></span> #  </code> </pre><br>  Les exemples ci-dessus sont fournis Ã  titre indicatif uniquement, ne les utilisez pas en production.  Dans les exemples, les vÃ©rifications des paramÃ¨tres d'entrÃ©e et des restrictions de commande sont omises.  L'un des problÃ¨mes que vous pouvez rencontrer est de limiter la longueur de l'argument Ã  la commande rm.  Lorsque vous testez dans un environnement de dÃ©veloppement sur de petits volumes, cela peut facilement Ãªtre manquÃ©, et en production, vous obtenez l'erreur Â«rm: Liste d'arguments trop longueÂ». <br><br><h3>  Mise en cache de blocs personnalisÃ©e </h3><br>  RÃ©sumons ce que nous avons rÃ©ussi Ã  faire: <br><br><ul><li>  rÃ©duit la charge sur le backend; </li><li>  DÃ©couvrez comment gÃ©rer la mise en cache </li><li>  appris Ã  vider le cache Ã  tout moment. </li></ul><br>  Mais tout n'est pas aussi bon que cela puisse paraÃ®tre Ã  premiÃ¨re vue.  Maintenant, probablement, sinon tous les premiers, alors prÃ©cisÃ©ment chaque deuxiÃ¨me site a une fonctionnalitÃ© d'enregistrement / autorisation, aprÃ¨s avoir traversÃ©, nous voudrons afficher le nom d'utilisateur quelque part dans l'en-tÃªte.  Le bloc avec le nom est unique et devrait afficher le nom d'utilisateur sous lequel nous sommes autorisÃ©s.  Puisque nginx enregistre la rÃ©ponse du backend, et dans le cas de la page, c'est le contenu html de la page, le bloc avec les donnÃ©es personnelles sera Ã©galement mis en cache.  Tous les visiteurs du site verront le nom du premier utilisateur qui est passÃ© au backend pour un ensemble de cache. <br>  Par consÃ©quent, le backend ne doit pas donner de blocs dans lesquels se trouvent des informations personnelles afin que ces informations ne tombent pas dans le cache nginx. <br><br>  Il est nÃ©cessaire d'envisager un chargement alternatif de ces parties de la page.  Comme toujours, cela peut se faire de plusieurs maniÃ¨res, par exemple, aprÃ¨s avoir chargÃ© la page, envoyÃ© une demande ajax et affichÃ© le chargeur Ã  la place du contenu personnel.  Une autre faÃ§on que nous considÃ©rerons aujourd'hui est d'utiliser des balises ssi.  Voyons d'abord ce qu'est SSI, puis comment l'utiliser en conjonction avec le cache nginx. <br><br><h3>  Qu'est-ce que SSI et comment Ã§a marche </h3><br>  SSI (Server-Side includes, server-side inclusions) est un ensemble de commandes intÃ©grÃ©es dans une page html qui indique au serveur quoi faire. <br><br>  Voici une liste de ces commandes (directives): <br><br>  â€¢ if / elif / else / endif - L'opÃ©rateur de branchement; <br>  â€¢ echo - Affiche les valeurs des variables; <br>  â€¢ inclure - Vous permet d'insÃ©rer le contenu d'un autre fichier dans le document. <br>  Seule la derniÃ¨re directive sera discutÃ©e.  La directive include a deux paramÃ¨tres: <br>  â€¢ fichier - SpÃ©cifie le chemin d'accÃ¨s au fichier sur le serveur.  Concernant le rÃ©pertoire courant; <br>  â€¢ virtuel - Indique le chemin d'accÃ¨s virtuel au document sur le serveur. <br><br>  Nous nous intÃ©ressons au paramÃ¨tre Â«virtuelÂ», car spÃ©cifier le chemin complet du fichier sur le serveur n'est pas toujours pratique, ou dans le cas d'une architecture distribuÃ©e, le fichier sur le serveur n'est tout simplement pas lÃ .  Exemple de directive: <br><br><pre> <code class="hljs xml"><span class="hljs-comment"><span class="hljs-comment">&lt;!--#include virtual="/user/personal_news/"--&gt;</span></span></code> </pre> <br>  Pour que nginx dÃ©marre le traitement des insertions ssi, vous devez modifier l'emplacement comme suit: <br><br><pre> <code class="hljs cs">location / { ssi <span class="hljs-keyword"><span class="hljs-keyword">on</span></span>; ... }</code> </pre><br>  DÃ©sormais, toutes les demandes traitÃ©es par l'emplacement Â«/Â» pourront effectuer des insertions ssi. <br><br>  Comment notre demande passera-t-elle par tout ce schÃ©ma? <br><br><ul><li>  le client demande la page; </li><li>  Nginx proxy la demande pour le backend; </li><li>  le backend donne la page avec des insertions ssi; </li><li>  le rÃ©sultat est stockÃ© dans le cache; </li><li>  Nginx Â«interrogeÂ» les blocs manquants; </li><li>  La page rÃ©sultante est envoyÃ©e au client. </li></ul><br>  Comme vous pouvez le voir dans les Ã©tapes, les constructions ssi entreront dans le cache nginx, ce qui permettra de ne pas mettre en cache les blocs personnels, et une page html prÃªte Ã  l'emploi avec toutes les insertions sera envoyÃ©e au client.  Ici, notre chargement fonctionne, nginx demande indÃ©pendamment les blocs de page manquants.  Mais comme toute autre solution, cette approche a ses avantages et ses inconvÃ©nients.  Imaginez qu'il y ait plusieurs blocs sur la page qui devraient Ãªtre affichÃ©s diffÃ©remment selon l'utilisateur, puis chacun de ces blocs sera remplacÃ© par un insert ssi.  Nginx, comme prÃ©vu, demandera chacun de ces blocs au backend, c'est-Ã -dire qu'une requÃªte de l'utilisateur gÃ©nÃ©rera immÃ©diatement plusieurs requÃªtes pour le backend, ce que je ne voudrais pas du tout. <br><br><h3>  Se dÃ©barrasser des requÃªtes backend persistantes via ssi </h3><br>  Pour rÃ©soudre ce problÃ¨me, le module nginx Â«ngx_http_memcached_moduleÂ» nous aidera.  Le module permet de recevoir des valeurs du serveur memcached.  L'Ã©criture dans le module ne fonctionnera pas, le serveur d'applications devrait s'en occuper.  Prenons un petit exemple de configuration de nginx en conjonction avec un module: <br><br><pre> <code class="hljs nginx"><span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> /page { <span class="hljs-attribute"><span class="hljs-attribute">set</span></span> <span class="hljs-variable"><span class="hljs-variable">$memcached_key</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$uri</span></span></span><span class="hljs-string">"</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1:11211</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">error_page</span></span> <span class="hljs-number"><span class="hljs-number">404</span></span> <span class="hljs-number"><span class="hljs-number">502</span></span> <span class="hljs-number"><span class="hljs-number">504</span></span> = <span class="hljs-variable"><span class="hljs-variable">@fallback</span></span>; } <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> <span class="hljs-variable"><span class="hljs-variable">@fallback</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> http://backend; } }</code> </pre><br>  Dans la variable $ memcache_key, nous avons spÃ©cifiÃ© la clÃ© par laquelle nginx tentera d'obtenir les donnÃ©es de memcache.  Les paramÃ¨tres de connexion au serveur memcache sont dÃ©finis dans la directive memcached_pass.  La connexion peut Ãªtre spÃ©cifiÃ©e de plusieurs maniÃ¨res: <br><br>  â€¢ nom de domaine; <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">memcached_pass</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">cache</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.domain</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.ru</span></span>;</code> </pre> <br>  â€¢ adresse IP et port; <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> localhost:<span class="hljs-number"><span class="hljs-number">11211</span></span>;</code> </pre> <br>  â€¢ prise unix; <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> unix:/tmp/memcached.socket;</code> </pre> <br>  â€¢ directive amont. <br><br><pre> <code class="hljs axapta">upstream cachestream { hash $request_uri consistent; <span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">10.10</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>:<span class="hljs-number"><span class="hljs-number">11211</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">10.10</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span>:<span class="hljs-number"><span class="hljs-number">11211</span></span>; } location / { ... memcached_pass cachestream; ... }</code> </pre><br>  Si nginx a rÃ©ussi Ã  obtenir une rÃ©ponse du serveur de cache, il la donne au client.  S'il n'y a pas de donnÃ©es dans le cache, la demande sera envoyÃ©e au backend via Â«@fallbackÂ».  Cette petite configuration du module memcached sous nginx nous aidera Ã  rÃ©duire le nombre de demandes de passage pour le backend des insertions ssi. <br><br>  Nous espÃ©rons que cet article a Ã©tÃ© utile et que nous avons pu montrer l'une des faÃ§ons d'optimiser la charge sur le serveur, de considÃ©rer les principes de base de la configuration de la mise en cache nginx et de rÃ©soudre les problÃ¨mes qui se posent lors de son utilisation. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428127/">https://habr.com/ru/post/fr428127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428117/index.html">Processeurs tensoriels gratuits de Google dans le cloud collaboratif</a></li>
<li><a href="../fr428119/index.html">Â«Class-fields-propositionÂ» ou Â«Qu'est-ce qui s'est mal passÃ© dans tc39 commitÂ»</a></li>
<li><a href="../fr428121/index.html">Stan Drapkin. PiÃ¨ges de cryptographie de haut niveau dans .NET</a></li>
<li><a href="../fr428123/index.html">Semaine de la sÃ©curitÃ© 41: Bonne nouvelle</a></li>
<li><a href="../fr428125/index.html">Qui sont les analyses de produits et pourquoi sont-elles nÃ©cessaires dans une Ã©quipe?</a></li>
<li><a href="../fr428129/index.html">Une logique floue simple collÃ©e Â«de ce qui Ã©taitÂ» pour un moteur Ã  turbine Ã  gaz</a></li>
<li><a href="../fr428131/index.html">Toute la vÃ©ritÃ© sur RTOS. Article # 17. Groupes de drapeaux d'Ã©vÃ©nements: introduction et services de base</a></li>
<li><a href="../fr428133/index.html">Hasura. Architecture GraphQL Ã  SQL Server haute performance</a></li>
<li><a href="../fr428135/index.html">Comment configurer ou dÃ©sactiver les peluches dans l'Ã©diteur de code intÃ©grÃ©</a></li>
<li><a href="../fr428137/index.html">Olympiade, concours d'idÃ©es, confÃ©rences sur la gestion de projets informatiques et projections de films: 10 Ã©vÃ©nements Ã  venir Ã  l'UniversitÃ© ITMO</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
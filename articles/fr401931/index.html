<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘¨ ğŸ“‹ âœŠğŸ¼ De plus en plus intelligents, les voitures commencent Ã  apprendre presque autant que nous ğŸ•¶ï¸ ğŸ‘©ğŸ½â€ğŸ³ ğŸ©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Des Ã©tudes montrent que les modÃ¨les informatiques, appelÃ©s rÃ©seaux de neurones utilisÃ©s dans un nombre croissant d'applications, peuvent apprendre Ã  r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>De plus en plus intelligents, les voitures commencent Ã  apprendre presque autant que nous</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/401931/"><h3>  Des Ã©tudes montrent que les modÃ¨les informatiques, appelÃ©s rÃ©seaux de neurones utilisÃ©s dans un nombre croissant d'applications, peuvent apprendre Ã  reconnaÃ®tre des sÃ©quences dans des donnÃ©es en utilisant les mÃªmes algorithmes que le cerveau humain. </h3><br><img src="https://habrastorage.org/getpro/geektimes/post_images/c2c/1bf/8e1/c2c1bf8e1a76f607108a26cfb43a4858.jpg" alt="image"><br><br>  Le cerveau rÃ©sout son problÃ¨me canonique - l'entraÃ®nement - en ajustant bon nombre de ses composÃ©s selon un ensemble de rÃ¨gles inconnu.  Pour rÃ©vÃ©ler ces rÃ¨gles, les scientifiques ont commencÃ© Ã  dÃ©velopper des modÃ¨les informatiques il y a 30 ans en essayant de reproduire le processus d'apprentissage.  Aujourd'hui, dans un nombre croissant d'expÃ©riences, il devient clair que ces modÃ¨les se comportent de maniÃ¨re trÃ¨s similaire au cerveau rÃ©el dans certaines tÃ¢ches.  Les chercheurs disent que cette similitude suggÃ¨re un ajustement de base entre le cerveau et les algorithmes d'apprentissage informatique. <br><br>  L'algorithme utilisÃ© par le modÃ¨le informatique est appelÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la machine de Boltzmann</a> .  Il a Ã©tÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">inventÃ© par</a> Jeffrey Hinton et Terry Seinowski en 1983 [en fait, en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1985</a> - env.  trad.].  Il semble trÃ¨s prometteur comme une explication thÃ©orique simple de plusieurs processus se produisant dans le cerveau - dÃ©veloppement, formation de la mÃ©moire, reconnaissance des objets et des sons, cycles de sommeil et de rÃ©veil. <br><a name="habracut"></a><br>  Â«C'est la meilleure opportunitÃ© que nous ayons aujourd'hui pour comprendre le cerveauÂ», explique Sue Becker, professeur de psychologie, de neurobiologie et de comportement Ã  l'UniversitÃ©.  McMaster Ã  Hamilton, Ontario.  "Je ne connais pas de modÃ¨le dÃ©crivant un plus large Ã©ventail de phÃ©nomÃ¨nes liÃ©s Ã  l'apprentissage et Ã  la structure cÃ©rÃ©brale." <br><br>  Hinton, un pionnier dans le domaine de l'IA, a toujours voulu comprendre les rÃ¨gles par lesquelles le cerveau amÃ©liore ou affaiblit la communication - c'est-Ã -dire l'algorithme d'apprentissage.  Â«J'ai dÃ©cidÃ© que pour comprendre quelque chose, il fallait le construireÂ», dit-il.  Suivant l'approche rÃ©ductionniste des physiciens, il prÃ©voit de crÃ©er des modÃ¨les informatiques simples du cerveau en utilisant diffÃ©rents algorithmes d'apprentissage et de voir Â«lesquels fonctionnerontÂ», explique Hinton, en partie professeur d'informatique Ã  l'UniversitÃ© de Toronto et en partie Ã  Google. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/e09/ca7/de6/e09ca7de64952922dee2dc5c0e51d154.png" alt="image"><br>  <i>Les rÃ©seaux de neurones multicouches sont constituÃ©s de couches de neurones artificiels avec des connexions pondÃ©rÃ©es entre eux.</i>  <i>J'envoie aux donnÃ©es entrantes une cascade de signaux en couches, et l'algorithme dÃ©termine la variation des poids de chaque connexion.</i> <br><br>  Dans les annÃ©es 1980 et 1990, Hinton, l'arriÃ¨re-arriÃ¨re-petit-fils de la logique du XIXe siÃ¨cle, George Boole, dont les travaux ont constituÃ© la base de l'informatique moderne, a inventÃ© plusieurs algorithmes d'apprentissage automatique.  Les algorithmes qui contrÃ´lent la faÃ§on dont un ordinateur apprend des donnÃ©es sont utilisÃ©s dans des modÃ¨les informatiques appelÃ©s Â«rÃ©seaux de neurones artificielsÂ» - des rÃ©seaux de neurones virtuels interconnectÃ©s qui transmettent des signaux Ã  leurs voisins, sâ€™allument ou sâ€™Ã©teignent ou se Â«dÃ©clenchentÂ».  Lorsque des donnÃ©es sont envoyÃ©es au rÃ©seau, cela conduit Ã  une cascade de rÃ©ponses, et l'algorithme, basÃ© sur l'image de ces rÃ©ponses, choisit d'augmenter ou de diminuer le poids des connexions, ou synapses, entre chaque paire de neurones. <br><br>  Depuis des dÃ©cennies, de nombreux modÃ¨les informatiques Hinton vÃ©gÃ¨tent.  Mais grÃ¢ce aux progrÃ¨s de la puissance du processeur, aux progrÃ¨s dans la comprÃ©hension du cerveau et des algorithmes, les rÃ©seaux de neurones jouent un rÃ´le de plus en plus important en neurobiologie.  Sejnowski [Sejnowski], chef du laboratoire informatique de neurobiologie de l'Institut de recherche biologique.  Salka Ã  La Jolla, en Californie, dÃ©clare: Â«Il y a trente ans, nous avions des idÃ©es trÃ¨s approximatives;  maintenant, nous commenÃ§ons Ã  en tester certains. Â» <br><br><h2>  Machines Ã  cerveau </h2><br>  Les premiÃ¨res tentatives de Hinton pour reproduire le cerveau Ã©taient limitÃ©es.  Les ordinateurs pouvaient exÃ©cuter ses algorithmes d'apprentissage sur de petits rÃ©seaux de neurones, mais les modÃ¨les de mise Ã  l'Ã©chelle surchargeaient trÃ¨s rapidement les processeurs.  En 2005, Hinton a dÃ©couvert que si vous divisez les rÃ©seaux de neurones en couches et exÃ©cutez les algorithmes sÃ©parÃ©ment sur chaque couche, rÃ©pÃ©tant approximativement la structure et le dÃ©veloppement du cerveau, le processus devient plus efficace. <br><br>  Bien que Hinton ait publiÃ© sa dÃ©couverte dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deux</a> <a href="">magazines bien connus</a> , les rÃ©seaux de neurones n'Ã©taient plus Ã  la mode Ã  ce moment-lÃ , et il Â«avait du mal Ã  intÃ©resser les gensÂ», a dÃ©clarÃ© Lee Deng, chercheur principal chez Microsoft Research.  Cependant, Deng connaissait Hinton et a dÃ©cidÃ© de tester sa mÃ©thode Â«d'apprentissage en profondeurÂ» en 2009, reconnaissant rapidement son potentiel.  Au cours des annÃ©es suivantes, les algorithmes d'apprentissage sont utilisÃ©s dans la pratique dans un nombre croissant d'applications, comme l'assistant personnel de Google Now ou la fonction de recherche vocale sur les tÃ©lÃ©phones Microsoft Windows. <br><br>  L'un des algorithmes les plus prometteurs, la machine Boltzmann, tire son nom du physicien autrichien du 19e siÃ¨cle, Ludwig Boltzmann, qui a dÃ©veloppÃ© une branche de la physique traitant un grand nombre de particules, connue sous le nom de mÃ©canique statistique.  Boltzmann a dÃ©couvert une Ã©quation qui donne la probabilitÃ© qu'un gaz molÃ©culaire ait une certaine Ã©nergie lorsqu'il atteint l'Ã©quilibre.  Si vous remplacez les molÃ©cules par des neurones, le rÃ©sultat tendra vers la mÃªme Ã©quation. <br><br>  Les synapses du rÃ©seau commencent par une distribution alÃ©atoire des poids, et les poids sont progressivement ajustÃ©s selon une procÃ©dure assez simple: le circuit de rÃ©ponse gÃ©nÃ©rÃ© en cours de rÃ©ception de donnÃ©es par la machine (comme les images ou les sons) est comparÃ© au circuit de rÃ©ponse alÃ©atoire de la machine qui se produit lorsque les donnÃ©es ne sont pas entrÃ©es. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/68c/dfb/775/68cdfb7753fc04e80a2940469564726e.jpg" alt="image"><br>  <i>Joffrey Hinton pense que la meilleure approche pour comprendre les processus d'apprentissage dans le cerveau est de construire des ordinateurs qui apprennent de la mÃªme maniÃ¨re.</i> <br><br>  Chaque synapse virtuelle suit les deux ensembles statistiques.  Si les neurones qui y sont connectÃ©s sont plus souvent dÃ©clenchÃ©s dans une sÃ©quence rapprochÃ©e lors de la rÃ©ception de donnÃ©es que lors d'une opÃ©ration alÃ©atoire, alors le poids de la synapse augmente d'une valeur proportionnelle Ã  la diffÃ©rence.  Mais si deux neurones sont plus souvent dÃ©clenchÃ©s ensemble au cours d'une opÃ©ration alÃ©atoire, la synapse les reliant est alors considÃ©rÃ©e comme trop forte et affaiblie. <br><br>  La version la plus utilisÃ©e de la machine Boltzmann fonctionne mieux aprÃ¨s la Â«formationÂ», aprÃ¨s avoir traitÃ© des milliers d'Ã©chantillons de donnÃ©es sÃ©quentiellement sur chaque couche.  PremiÃ¨rement, la couche infÃ©rieure du rÃ©seau reÃ§oit des donnÃ©es brutes sous forme d'images ou de sons et, Ã  la maniÃ¨re des cellules rÃ©tiniennes, les neurones sont dÃ©clenchÃ©s s'ils dÃ©tectent des contrastes dans leur zone de donnÃ©es, comme le passage de la lumiÃ¨re Ã  l'obscuritÃ©.  Leur dÃ©clenchement peut dÃ©clencher le dÃ©clenchement des neurones qui leur sont associÃ©s, selon le poids de la synapse qui les relie.  Comme le dÃ©clenchement de paires de neurones virtuels est constamment comparÃ© aux statistiques de fond, des connexions significatives entre les neurones apparaissent et s'intensifient progressivement.  Les poids des synapses sont spÃ©cifiÃ©s et des catÃ©gories de sons et d'images sont intÃ©grÃ©es aux connexions.  Chaque couche suivante est entraÃ®nÃ©e de maniÃ¨re similaire, en utilisant les donnÃ©es de la couche situÃ©e en dessous. <br><br>  Si vous transmettez une image d'une voiture Ã  un rÃ©seau de neurones formÃ© pour dÃ©tecter certains objets dans les images, la couche infÃ©rieure fonctionnera si elle dÃ©tecte un contraste qui indique un visage ou un point final.  Ces signaux iront aux neurones de niveau supÃ©rieur qui dÃ©terminent les angles, les parties des roues, etc.  Au niveau supÃ©rieur, les neurones ne sont dÃ©clenchÃ©s qu'en rÃ©agissant Ã  l'image de la voiture. <br><br>  Â«La magie de ce qui se passe sur le Web est qu'elle peut rÃ©sumerÂ», explique Yann LeCun, directeur du Data Science Center de l'UniversitÃ© de New York.  "Si vous lui montrez une voiture qu'elle n'a jamais vue auparavant, et si la voiture aura des formes et des caractÃ©ristiques communes avec les machines qui lui sont montrÃ©es pendant l'entraÃ®nement, elle peut dÃ©terminer qu'il s'agit d'une voiture." <br><br>  Les rÃ©seaux de neurones ont rÃ©cemment accÃ©lÃ©rÃ© leur dÃ©veloppement grÃ¢ce au mode multicouche Hinton, Ã  l'utilisation de puces informatiques Ã  haute vitesse pour le traitement des graphiques et Ã  la croissance explosive du nombre d'images et d'enregistrements vocaux disponibles pour la formation.  Les rÃ©seaux sont capables de reconnaÃ®tre correctement 88% des mots en anglais, tandis que la personne moyenne en reconnaÃ®t 96%.  Ils peuvent dÃ©tecter des voitures et des milliers d'autres objets dans des images avec une prÃ©cision similaire, et au cours des derniÃ¨res annÃ©es, ils ont pris une position dominante dans les compÃ©titions d'apprentissage automatique. <br><br><h2>  Construire un cerveau </h2><br>  Personne ne sait comment dÃ©terminer directement les rÃ¨gles selon lesquelles le cerveau est entraÃ®nÃ©, mais il existe de nombreuses coÃ¯ncidences indirectes entre le comportement du cerveau et la machine de Boltzmann. <br><br>  Les deux sont formÃ©s sans supervision, en utilisant uniquement les modÃ¨les existants dans les donnÃ©es.  Â«Votre mÃ¨re ne vous dit pas un million de fois ce qui est montrÃ© sur l'imageÂ», dit Hinton.  - Vous devez apprendre Ã  reconnaÃ®tre les choses sans l'avis des autres.  AprÃ¨s avoir Ã©tudiÃ© les catÃ©gories, ils vous indiquent les noms de ces catÃ©gories.  Les enfants apprennent donc les chiens et les chats, puis ils apprennent que les chiens sont appelÃ©s Â«chiensÂ» et que les chats sont appelÃ©s Â«chatsÂ». <br><br>  Le cerveau adulte n'est pas aussi flexible que le jeune, tout comme la machine Boltzmann, aprÃ¨s s'Ãªtre entraÃ®nÃ© pour 100 000 images de voitures, il ne changera pas beaucoup aprÃ¨s en avoir vu une autre.  Ses synapses ont dÃ©jÃ  les bons poids pour catÃ©goriser les voitures.  Mais la formation ne s'arrÃªte pas.  De nouvelles informations peuvent Ãªtre intÃ©grÃ©es dans la structure du cerveau et des machines Boltzmann. <br><br>  Au cours des deux derniÃ¨res dÃ©cennies, une Ã©tude de l'activitÃ© cÃ©rÃ©brale dans un rÃªve a fourni la premiÃ¨re preuve que le cerveau utilise un algorithme similaire Ã  l'algorithme de Boltzmann pour incorporer de nouvelles informations et mÃ©moires dans sa structure.  Les neuroscientifiques savent depuis longtemps que le sommeil joue un rÃ´le important dans la consolidation de la mÃ©moire et aide Ã  intÃ©grer de nouvelles informations.  En 1995, Hinton et ses collÃ¨gues ont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">suggÃ©rÃ©</a> que le sommeil joue le rÃ´le d'un niveau de base dans l'algorithme, dÃ©notant l'activitÃ© des neurones en l'absence de donnÃ©es d'entrÃ©e. <br><br>  "Pendant le sommeil, vous venez de dÃ©terminer la frÃ©quence de base des neurones", explique Hinton.  - Vous dÃ©couvrez la corrÃ©lation de leur travail dans le cas oÃ¹ le systÃ¨me fonctionne seul.  Et puis, si les neurones sont plus en corrÃ©lation, augmentez simplement les poids entre eux.  Et si moins, rÃ©duisez le poids. " <br><br>  Au niveau de la synapse, "cet algorithme peut Ãªtre fourni de plusieurs maniÃ¨res", explique Sezhnowski, conseiller de l'administration prÃ©sidentielle dans le cadre de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'initiative BRAIN</a> , une Ã©tude dotÃ©e d'une subvention de 100 millions de dollars destinÃ©e Ã  dÃ©velopper de nouvelles techniques d'Ã©tude du cerveau. <br><br>  Il dit qu'il est plus facile pour le cerveau de travailler avec l'algorithme de Boltzmann, en passant de la construction de synapses le jour Ã  la diminution la nuit.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Giulio Tononi</a> , directeur du Center for Sleep and Consciousness Studies de l'UniversitÃ© du Wisconsin-Madison, a constatÃ© que l'expression des gÃ¨nes dans les synapses les modifie selon cette hypothÃ¨se: les gÃ¨nes impliquÃ©s dans la croissance des synapses sont plus actifs pendant la journÃ©e et les gÃ¨nes impliquÃ©s dans la contraction synapses - la nuit. <br><br>  Dans une autre option, Â«la ligne de base peut Ãªtre calculÃ©e dans un rÃªve, puis des modifications par rapport Ã  celle-ci peuvent Ãªtre apportÃ©es pendant la journÃ©eÂ», explique Sezhnowski.  Dans son laboratoire, des modÃ¨les informatiques dÃ©taillÃ©s des synapses et des rÃ©seaux qu'ils prennent en charge sont construits pour dÃ©terminer comment ils collectent des statistiques sur les modes d'Ã©veil et de sommeil, et quand la force des synapses change pour afficher cette diffÃ©rence. <br><br><h2>  DifficultÃ©s avec le cerveau </h2><br><img src="https://habrastorage.org/getpro/geektimes/post_images/784/a3b/721/784a3b7213087f712c156f1ad62a346d.jpg" alt="image"><br>  <i>Image de la rÃ©tine dans laquelle diffÃ©rents types de cellules sont indiquÃ©s par diffÃ©rentes couleurs.</i>  <i>La couleur (violet) se connecte Ã  l'horizontale (orange), qui se connecte au bipolaire (vert) et Ã  celles - aux cellules de la rÃ©tine et du ganglion (violet).</i> <br><br>  L'algorithme de Boltzmann peut Ãªtre l'un des nombreux utilisÃ©s par le cerveau pour affiner les synapses.  Dans les annÃ©es 1990, plusieurs groupes indÃ©pendants ont dÃ©veloppÃ© un modÃ¨le thÃ©orique de la faÃ§on dont le systÃ¨me visuel code efficacement le flux d'informations vers la rÃ©tine.  La thÃ©orie postulait que dans les couches infÃ©rieures du cortex visuel, il existe un processus de Â«codage dispersÃ©Â», similaire Ã  la compression d'image, Ã  la suite de quoi les derniers stades du systÃ¨me visuel fonctionnent plus efficacement. <br><br>  Les prÃ©dictions du modÃ¨le passent progressivement des tests de plus en plus rigoureux.  Dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> publiÃ© dans PLOS Computational Biology, des neuroscientifiques computationnels de Grande-Bretagne et d'Australie ont dÃ©couvert que lorsque les rÃ©seaux de neurones utilisant l'algorithme de codage dispersÃ© Products of Experts inventÃ© par Hinton en 2002 traitent les mÃªmes donnÃ©es visuelles inhabituelles que les chats vivants reÃ§oivent (par exemple, les chats et les rÃ©seaux de neurones Ã©tudient les images rayÃ©es), leurs neurones produisent des connexions inhabituelles presque identiques. <br><br>  "Au moment oÃ¹ l'information atteint le cortex visuel, le cerveau, nous pensons, la prÃ©sente comme un code dispersÃ©", a dÃ©clarÃ© Bruno Olshausen, neuroscientifique informatique et directeur du Redwood Center for Theoretical Neurobiology de l'UniversitÃ© de Californie Ã  Berkeley, qui a aidÃ© Ã  dÃ©velopper thÃ©orie du codage dispersÃ©.  "Comme si une machine Boltzmann Ã©tait assise dans votre tÃªte et essayait de comprendre les connexions qui existent entre les Ã©lÃ©ments du code dispersÃ©." <br><br>  Olshausen et l'Ã©quipe ont utilisÃ© des modÃ¨les de rÃ©seaux neuronaux des couches supÃ©rieures du cortex visuel pour montrer comment le cerveau est capable de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">maintenir une perception stable de l'apport visuel</a> malgrÃ© le mouvement des images.  Dans une autre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ã©tude,</a> ils ont dÃ©couvert que l'activitÃ© des neurones dans le cortex visuel des chats regardant un film en noir et blanc est trÃ¨s bien dÃ©crite par la machine Boltzmann. <br><br>  L'une des applications possibles de ce travail est la crÃ©ation de neuroprothÃ¨ses, par exemple une rÃ©tine artificielle.  Si vous regardez comment Â«l'information est formatÃ©e dans le cerveau, vous pouvez comprendre comment stimuler le cerveau pour lui faire croire qu'il voit une imageÂ», explique Olshausen. <br><br>  Sezhnowski dit que la comprÃ©hension des algorithmes de croissance et de rÃ©duction des synapses permettra aux chercheurs de les changer et d'apprendre comment le fonctionnement du rÃ©seau neuronal est perturbÃ©.  Â«Ensuite, ils peuvent Ãªtre comparÃ©s aux problÃ¨mes bien connus des gensÂ», dit-il.  - Presque tous les troubles mentaux peuvent s'expliquer par des problÃ¨mes de synapses.  Si nous pouvons mieux comprendre les synapses, nous pouvons comprendre comment le cerveau fonctionne normalement, comment il traite les informations, comment il apprend et ce qui ne va pas si, par exemple, vous dÃ©veloppez la schizophrÃ©nie. Â» <br><br>  L'approche de l'Ã©tude du cerveau Ã  l'aide de rÃ©seaux de neurones contraste fortement avec l'approche du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Human Brain Project</a> .  Il s'agit du plan annoncÃ© par le neuroscientifique suisse Henry Marcram pour crÃ©er une simulation prÃ©cise du cerveau humain Ã  l'aide d'un superordinateur.  Contrairement Ã  l'approche de Hinton, qui commence par un modÃ¨le grandement simplifiÃ© et suit le chemin de la complication progressive, Markram souhaite inclure immÃ©diatement la plus grande quantitÃ© possible de donnÃ©es, jusqu'aux molÃ©cules individuelles, et espÃ¨re qu'en consÃ©quence, il aura une fonctionnalitÃ© et une conscience complÃ¨tes. <br><br>  Le projet a reÃ§u un financement de 1,3 milliard de dollars de la Commission europÃ©enne, mais Hinton pense que cette mÃ©ga-simulation Ã©chouera, coincÃ©e dans trop de piÃ¨ces mobiles que personne ne comprend encore. <br><br>  De plus, Hinton ne croit pas que le cerveau ne peut Ãªtre compris que par ses images.  Ces donnÃ©es devraient Ãªtre utilisÃ©es pour crÃ©er et affiner des algorithmes.  Â«Une rÃ©flexion thÃ©orique et des recherches sur lâ€™espace des algorithmes dâ€™apprentissage sont nÃ©cessaires pour crÃ©er une thÃ©orie comme celle-ciÂ», dit la machine de Boltzmann.  La prochaine Ã©tape pour Hinton est le dÃ©veloppement d'algorithmes pour former encore plus de rÃ©seaux neuronaux cÃ©rÃ©braux, tels que les synapses connectent les neurones au sein d'une couche, et pas seulement entre diffÃ©rentes couches.  Â«L'objectif principal est de comprendre les avantages qui peuvent Ãªtre obtenus en compliquant les calculs Ã  chaque Ã©tapeÂ», dit-il. <br><br>  L'hypothÃ¨se est que plus de connexions conduiront Ã  des boucles dorsales plus fortes, ce qui, selon Olshausen, aidera trÃ¨s probablement le cerveau Ã  Â«remplir les dÃ©tails manquantsÂ».  Les couches supÃ©rieures interfÃ¨rent avec le travail des neurones des couches infÃ©rieures traitant des informations partielles.  Â«Tout cela est Ã©troitement liÃ© Ã  la conscienceÂ», dit-il. <br><br>  Le cerveau humain est encore beaucoup plus complexe que n'importe quel modÃ¨le.  Il est plus grand, plus dense, plus efficace, il a plus d'interconnexions et de neurones complexes - et il fonctionne simultanÃ©ment avec plusieurs algorithmes.  Olshausen suggÃ¨re que nous comprenons environ 15% de l'activitÃ© du cortex visuel.  Bien que les modÃ¨les avancent, les neurosciences sont toujours "similaires Ã  la physique avant Newton", dit-il.  NÃ©anmoins, il est convaincu que le processus de travail sur la base de ces algorithmes sera un jour capable d'expliquer l'Ã©nigme principale du cerveau - comment les donnÃ©es des organes sensoriels sont transformÃ©es en un sens subjectif de la rÃ©alitÃ©.  La conscience, dit Olshausen, "est quelque chose qui Ã©merge de la rÃ©alitÃ©, une machine Boltzmann trÃ¨s complexe." </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr401931/">https://habr.com/ru/post/fr401931/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr401919/index.html">Imprimante ONO 3D. StÃ©rÃ©olithographie - aux masses</a></li>
<li><a href="../fr401923/index.html">5 mythes sur les projecteurs. Mythe n Â° 2 - Â«LuminositÃ© des couleursÂ» - la caractÃ©ristique d'un projecteur d'un projecteur inventÃ© par les spÃ©cialistes du marketing</a></li>
<li><a href="../fr401925/index.html">PrÃ©sentÃ© par Pi Zero W</a></li>
<li><a href="../fr401927/index.html">Rocket Fuel Saga - l'envers de la mÃ©daille</a></li>
<li><a href="../fr401929/index.html">SpaceX: l'annÃ©e prochaine, nous enverrons deux touristes spatiaux sur la lune</a></li>
<li><a href="../fr401935/index.html">Mozilla acquiert le service de lecture paresseuse de poche</a></li>
<li><a href="../fr401937/index.html">Yandex ignore la vÃ©rification 3D Secure lors du paiement d'annonces dans Yandex.Direct Ã  l'aide de cartes bancaires</a></li>
<li><a href="../fr401939/index.html">Menuisier pour enfants PLAYMAT: le travail du bois Ã  faire soi-mÃªme est intÃ©ressant</a></li>
<li><a href="../fr401941/index.html">PrÃ©sentation de la nouvelle camÃ©ra de surveillance Oco2</a></li>
<li><a href="../fr401943/index.html">Une brÃ¨ve biographie de la famille Intel Atom</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
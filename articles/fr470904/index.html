<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèπ ‚úãüèº üëÜüèæ Le chemin le plus doux et le plus velu de l'apprentissage automatique et des r√©seaux de neurones profonds üçã üë©üèΩ‚Äçüé§ üî¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'apprentissage automatique moderne vous permet de faire des choses incroyables. Les r√©seaux de neurones fonctionnent au b√©n√©fice de la soci√©t√©: ils t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le chemin le plus doux et le plus velu de l'apprentissage automatique et des r√©seaux de neurones profonds</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/470904/">  L'apprentissage automatique moderne vous permet de faire des choses incroyables.  Les r√©seaux de neurones fonctionnent au b√©n√©fice de la soci√©t√©: ils trouvent des criminels, reconnaissent les menaces, aident √† diagnostiquer les maladies et prennent des d√©cisions difficiles.  Les algorithmes peuvent d√©passer une personne en cr√©ativit√©: ils peignent des images, √©crivent des chansons et font des chefs-d'≈ìuvre √† partir d'images ordinaires.  Et ceux qui d√©veloppent ces algorithmes sont souvent pr√©sent√©s comme des scientifiques caricaturaux. <br><br>  Tout n'est pas si effrayant!  Quiconque est un peu familier avec la programmation peut construire un r√©seau neuronal √† partir de mod√®les de base.  Et il n'est m√™me pas n√©cessaire d'apprendre Python, tout peut √™tre fait en JavaScript natif.  Il est facile de commencer et pourquoi l'apprentissage automatique est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">n√©cessaire</a> pour les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">fournisseurs</a> <strong>frontaux</strong> , a d√©clar√© <strong>Aleksey Okhrimenko</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">obenjiro</a> ) √† FrontendConf, et nous l'avons transf√©r√© dans le texte afin que les noms d'architecture et les liens utiles soient √† port√©e de main. <br><br><h2>  Spoiler.  Alerte! </h2><br>  Cette histoire: <br><br><ul><li> <strong>Pas pour ceux qui</strong> travaillent <strong>d√©j√†</strong> avec Machine Learning.  Quelque chose d'int√©ressant sera, mais il est peu probable que sous la coupe vous attendiez l'ouverture. </li><li>  <strong>Pas sur l'apprentissage par transfert.</strong>  Nous ne parlerons pas de la fa√ßon d'√©crire un r√©seau de neurones en Python, puis de travailler avec lui √† partir de JavaScript.  Pas de triche - nous √©crirons des r√©seaux de neurones profonds sp√©cifiquement sur JS. </li><li>  <strong>Pas tous les d√©tails.</strong>  En g√©n√©ral, tous les concepts ne rentreront pas dans un seul article, mais bien s√ªr nous analyserons le n√©cessaire. </li></ul><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BX2M8t5BA3s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>√Ä propos du conf√©rencier:</strong> Alexei Okhrimenko travaille chez Avito dans le d√©partement d'architecture frontale, et pendant son temps libre dirige le Meetup Angular Moscow et publie le ¬´Five Minute Angular¬ª.  Au cours d'une longue carri√®re, il a d√©velopp√© le mod√®le de conception MALEVICH, l'analyseur de grammaire PEG SimplePEG.  Le mainteneur d'Alexey CSSComb partage r√©guli√®rement ses connaissances sur les nouvelles technologies lors de conf√©rences et dans son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">canal de t√©l√©gramme d'</a> apprentissage automatique JS. <br><br><h2>  L'apprentissage automatique est tr√®s populaire. </h2><br>  Les assistants vocaux, Siri, Google Assistant, Alice, sont populaires et se retrouvent souvent dans nos vies.  De nombreux produits sont pass√©s du traitement algorithmique classique des donn√©es √† l'apprentissage automatique.  Un exemple frappant est Google Translate. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/cg/uz/z3cguzzlmogpjxmymmqhok5xw50.jpeg"></div><br>  Toutes les innovations et les puces les plus cool des smartphones sont bas√©es sur l'apprentissage automatique. <br><br><img src="https://habrastorage.org/webt/qd/2m/1g/qd2m1gmmouw29qcfbytgd5gdcoc.jpeg"><br><br>  Par exemple, Google NightSight utilise l'apprentissage automatique.  Les photos sympas que nous voyons n'ont pas √©t√© obtenues avec des objectifs, des capteurs ou une stabilisation, mais avec l'aide du machine learning.  La machine a finalement battu des gens dans DOTA2, ce qui signifie que nous avons peu de chances de vaincre l'intelligence artificielle.  Par cons√©quent, nous devons ma√Ætriser le machine learning le plus rapidement possible. <br><br><h2>  Commen√ßons par un simple </h2><br>  Quelle est notre routine de programmation quotidienne, comment √©crivons-nous habituellement les fonctions? <br><img src="https://habrastorage.org/webt/n1/kn/ss/n1knssbigatyl2zrakkoaazsuai.jpeg"><br>  Nous prenons les donn√©es et l'algorithme que nous avons nous-m√™mes invent√©s ou pris √† partir de pr√™ts √† l'emploi populaires, combinons, faisons un peu de magie et obtenons une fonction qui nous donne la bonne r√©ponse dans une situation donn√©e. <br><br>  Nous sommes habitu√©s √† cet ordre de choses, mais il y aurait une telle opportunit√©, sans conna√Ætre l'algorithme, mais simplement en ayant les donn√©es et la r√©ponse, obtenir l'algorithme d'eux. <br><br><img src="https://habrastorage.org/webt/tq/6p/4w/tq6p4wwa4ctyhg_j7a4b_t2dhl0.jpeg"><br><br>  Vous pouvez dire: "Je suis programmeur, je peux toujours √©crire un algorithme." <br><br>  D'accord, mais par exemple, quel algorithme est n√©cessaire ici? <br><br><img src="https://habrastorage.org/webt/mq/ey/ce/mqeycerayzppkiqobxr_-o13oka.jpeg"><br><br>  Supposons que le chat ait des oreilles pointues et que les oreilles du chien soient ternes, petites, comme un carlin. <br><br><img src="https://habrastorage.org/webt/nv/dp/-h/nvdp-h5hvyset6n3fz-q6ya03hs.jpeg"><br><br>  Essayons de comprendre qui est qui par les oreilles.  Mais √† un moment donn√©, nous d√©couvrons que les chiens peuvent avoir des oreilles pointues. <br><br><img src="https://habrastorage.org/webt/uk/j2/pr/ukj2prwe9ln0hdjj6x0qa5q9vxw.jpeg"><br><br>  Notre hypoth√®se n'est pas bonne, nous avons besoin d'autres caract√©ristiques.  Au fil du temps, nous apprendrons de plus en plus de d√©tails, nous d√©motivant ainsi de plus en plus, et √† un moment donn√©, nous voudrons quitter compl√®tement cette entreprise. <br><br>  J'imagine une image id√©ale comme celle-ci: √† l'avance, il y a une r√©ponse (nous savons de quel type d'image il s'agit), il y a des donn√©es (nous savons qu'un chat est dessin√©), nous voulons obtenir un algorithme qui pourrait alimenter les donn√©es et obtenir des r√©ponses √† la sortie. <br><br>  Il existe une solution - c'est l'apprentissage automatique, √† savoir l'une de ses parties - les r√©seaux de neurones profonds. <br><br><h2>  R√©seaux de neurones profonds </h2><br>  L'apprentissage automatique est un domaine immense.  Il offre une quantit√© gigantesque de m√©thodes, et chacune est bonne √† sa mani√®re. <br><br><img src="https://habrastorage.org/webt/qv/8t/kj/qv8tkjpyrk_qeia-hp4fxkvco7w.jpeg"><br><br>  L'un d'eux est Deep Neural Networks.  Le deep learning a un avantage ind√©niable gr√¢ce auquel il est devenu populaire. <br><br>  Pour comprendre cet avantage, examinons le probl√®me de classification classique en utilisant les chats et les chiens comme exemple. <br><br>  Il y a des donn√©es: des photos ou des photos.  La premi√®re chose √† faire est l'int√©gration (int√©gration), c'est-√†-dire la transformation des donn√©es afin que la machine soit √† l'aise de travailler avec elles.  Il n'est pas pratique de travailler avec des images, la voiture a besoin de quelque chose de plus simple. <br><br>  Tout d'abord, alignez les images et supprimez la couleur.  Quelle que soit la couleur du chien ou du chat, il est important de d√©terminer le type d'animal.  Ensuite, nous transformons les images en tableaux, o√π, par exemple, 0 est sombre, 1 est clair. <br><br><img src="https://habrastorage.org/webt/th/st/aq/thstaqtmxfb1jqo-eacmrtlaxym.jpeg"><br><br>  Avec cette pr√©sentation des donn√©es, les r√©seaux de neurones peuvent d√©j√† fonctionner. <br><br>  Cr√©ons deux autres tableaux et fusionnons-les en un certain ¬´calque¬ª.  Ensuite, nous multiplions chacun des √©l√©ments de la couche et du tableau de donn√©es entre eux √† l'aide d'une simple multiplication matricielle, et nous dirigeons le r√©sultat vers deux fonctions d'activation (nous analyserons plus tard quelles sont ces fonctions).  Si la fonction d'activation re√ßoit un nombre suffisant de valeurs, elle est alors "activ√©e" et produira le r√©sultat: <br><br><ul><li>  la premi√®re fonction renverra 1 s'il s'agit d'un chat et 0 s'il ne s'agit pas d'un chat. </li><li>  la deuxi√®me fonction renverra 1 s'il s'agit d'un chien et 0 s'il ne s'agit pas d'un chien. </li></ul><br>  Cette approche de codage d'une r√©ponse est appel√©e <strong>One-Hot Encoding</strong> . <br><br><img src="https://habrastorage.org/webt/bb/-a/x5/bb-ax5li-ngkav87ibjjazse6m4.jpeg"><br><br>  D√©j√†, plusieurs caract√©ristiques des r√©seaux de neurones profonds sont perceptibles: <br><br><ul><li>  Pour travailler avec des r√©seaux de neurones, vous devez coder les donn√©es √† l'entr√©e et d√©coder √† la sortie. </li><li>  L'encodage nous permet d'abstraire des donn√©es. </li><li>  En modifiant les donn√©es d'entr√©e, nous pouvons g√©n√©rer des r√©seaux de neurones pour diff√©rents domaines.  M√™me ceux dont nous ne sommes pas des experts. </li></ul><br>  Il n'est pas n√©cessaire de savoir ce qu'est un chat, ce qu'est un chien.  Il suffit de s√©lectionner les num√©ros n√©cessaires pour une couche suppl√©mentaire. <br><br>  Jusqu'√† pr√©sent, la seule chose qui reste floue est pourquoi ces r√©seaux sont appel√©s ¬´profonds¬ª. <br>  Tout est tr√®s simple: on peut cr√©er une autre couche (tableaux et leurs fonctions d'activation).  Et transf√©rez le r√©sultat d'une couche √† une autre. <br><br><img src="https://habrastorage.org/webt/9n/8r/qh/9n8rqhrwuewcgwa17oq-beuj7r4.jpeg"><br><br>  Vous pouvez vous superposer autant de ces couches et de leurs fonctions d'activation.  En combinant une architecture en couches, nous obtenons un r√©seau neuronal profond.  Sa profondeur est une multitude de couches.  Et collectivement appel√© le <strong>¬´mod√®le¬ª</strong> . <br><br>  Voyons maintenant comment les valeurs sont s√©lectionn√©es pour tous ces calques.  Il y a une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">visualisation</a> sympa qui vous permet de comprendre comment se d√©roule le processus d'apprentissage. <br><br><img src="https://habrastorage.org/webt/aw/ot/at/awotatoajim-4vykkxk5wgldodq.jpeg"><br><br>  √Ä gauche, les donn√©es et √† droite, l'une des couches.  On peut voir qu'en changeant les valeurs √† l'int√©rieur des tableaux de couches, nous semblons changer le syst√®me de coordonn√©es.  S'adaptant ainsi aux donn√©es et √† l'apprentissage.  Ainsi, l'apprentissage est le processus de s√©lection des bonnes valeurs pour les tableaux de couches.  Ces valeurs sont appel√©es poids ou poids. <br><br><h2>  L'apprentissage automatique est difficile </h2><br>  Je veux vous d√©ranger, l'apprentissage automatique est difficile.  Tout ce qui pr√©c√®de est une grande simplification.  √Ä l'avenir, vous trouverez une √©norme quantit√© d'alg√®bre lin√©aire et assez complexe.  H√©las, il n'y a pas d'√©chappatoire √† cela. <br><br>  Bien s√ªr, il y a des cours, mais m√™me la formation la plus rapide dure plusieurs mois et n'est pas bon march√©.  De plus, vous devez toujours le d√©couvrir vous-m√™me.  Le domaine de l'apprentissage automatique s'est tellement d√©velopp√© qu'il est presque impossible de tout suivre.  Par exemple, voici un ensemble de mod√®les pour r√©soudre une seule t√¢che (d√©tection d'objet): <br><br><img src="https://habrastorage.org/webt/tw/bx/rs/twbxrs3-fary0wir6wd-e4x_2_i.jpeg"><br><br>  Personnellement, j'√©tais tr√®s d√©motiv√©.  Je n'ai pas pu approcher les r√©seaux de neurones et commencer √† travailler avec eux.  Mais j'ai trouv√© un moyen et je veux le partager avec vous.  Ce n'est pas r√©volutionnaire, il n'y a rien de tel, vous le connaissez d√©j√†. <br><br><h2>  Blackbox - Une approche simple </h2><br>  Il n'est pas n√©cessaire de comprendre absolument tous les aspects de l'apprentissage automatique pour apprendre √† appliquer des r√©seaux de neurones √† vos t√¢ches professionnelles.  Je vais vous montrer quelques exemples qui, je l'esp√®re, vous inspireront. <br><br>  Pour beaucoup, une voiture est aussi une bo√Æte noire.  Mais m√™me si vous ne savez pas comment cela fonctionne, vous devez apprendre les r√®gles.  Donc, avec l'apprentissage automatique - vous devez toujours conna√Ætre quelques r√®gles: <br><br><ul><li>  Apprenez TensorFlow JS (biblioth√®que pour travailler avec les r√©seaux de neurones). </li><li>  Apprenez √† choisir des mod√®les. </li></ul><br>  Nous nous concentrons sur ces t√¢ches et commen√ßons par le code. <br><br><h2>  Apprendre en cr√©ant du code </h2><br>  La biblioth√®que TensorFlow est √©crite pour un grand nombre de langages: Python, C / C ++, JavaScript, Go, Java, Swift, C #, Haskell, Julia, R, Scala, Rust, OCaml, Crystal.  Mais nous choisirons certainement le meilleur - JavaScript. <br><br>  TensorFlow peut √™tre connect√© √† notre page en connectant un script avec CDN: <br><br><pre><code class="javascript hljs">&lt;script src=<span class="hljs-string"><span class="hljs-string">"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"</span></span>&gt;<span class="xml"><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;/</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">script</span></span></span></span><span class="xml"><span class="hljs-tag">&gt;</span></span></span></span></code> </pre> <br>  Ou utilisez npm: <br><br><ul><li>  <code>npm install @tensorflow/tfjs-node</code> - pour le processus de n≈ìud (site Web); </li><li>  <code>npm install @tensorflow/tfjs-node-gpu</code> (Linux CUDA) - pour le GPU, mais uniquement si la machine Linux et la carte vid√©o prennent en charge la technologie CUDA.  Assurez-vous que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">capacit√© de calcul CUDA</a> correspond √† votre biblioth√®que afin qu'il ne s'av√®re pas qu'un mat√©riel co√ªteux ne convient pas. </li><li>  <code>npm install @tensorflow/tfjs</code> (Slowest / Browser) - pour un navigateur sans utiliser Node.js. </li></ul><br>  Pour travailler avec TensorFlow JS, il suffit d'importer l'un des modules ci-dessus.  Vous verrez de nombreux exemples de code o√π tout est import√©.  Pas besoin de le faire, s√©lectionnez et importez un seul. <br><br><h3>  Tenseurs </h3><br>  Lorsque les donn√©es initiales sont pr√™tes, la premi√®re chose √† faire est d' <strong>importer TensorFlow</strong> .  Nous utiliserons tensorflow / tfjs-node-gpu pour obtenir l'acc√©l√©ration due √† la puissance de la carte vid√©o. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  @tensorflow/tfjs-node-gpu  node.js const tf = require('@tensorflow/tfjs'); const a = [[1,2], [3,4]];</span></span></code> </pre> <br>  Il existe un tableau de donn√©es √† deux dimensions - nous allons travailler avec lui. <br><br>  La prochaine chose importante √† faire est de <strong>cr√©er un tenseur</strong> .  Dans ce cas, un tenseur est cr√©√© de rang 2, c'est-√†-dire en fait un tableau √† deux dimensions.  Nous transf√©rons les donn√©es et obtenons le tenseur 2x2. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  rank-2  (/) const b = tf.tensor([[1,2], [3,4]]); console.log('shape:', b.shape); b.print()</span></span></code> </pre> <br>  Notez que la m√©thode d' <code>print</code> est appel√©e, pas <code>console.log</code> , car <code>b</code> (le tenseur que nous avons cr√©√©) n'est pas un objet ordinaire, √† savoir le tenseur.  Il a ses propres m√©thodes et propri√©t√©s. <br><br>  Vous pouvez √©galement cr√©er un tenseur √† partir d'un r√©seau planaire et garder sa forme √† l'esprit, disons.  C'est-√†-dire d√©clarer un formulaire - un tableau √† deux dimensions - pour transmettre simplement un tableau plat et indiquer directement le formulaire.  Le r√©sultat sera le m√™me. <br><br>  Du fait que les donn√©es et le formulaire peuvent √™tre stock√©s s√©par√©ment, il est possible de modifier la forme du tenseur.  Nous pouvons appeler la m√©thode de <code>reshape</code> et changer la forme de 2x2 √† 4x1. <br><br>  La prochaine √©tape importante consiste <strong>√† sortir les donn√©es</strong> , √† les renvoyer dans le monde r√©el. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const g = tf.tensor([[1,2], [3,4]]); g.data().then((raw) =&gt; { console.log('async raw value of g:', raw); }); console.log('raw value of g:', g.dataSync()); console.log('raw multidimensional value of g:', g.arraySync());</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code pour</a> les trois √©tapes.</i> <br><br>  La m√©thode de <code>data</code> renvoie la promesse.  Apr√®s sa r√©solution, nous obtenons la valeur imm√©diate de la valeur brute, mais l'obtenons de mani√®re asynchrone.  Si nous le voulons, nous pouvons l'obtenir de mani√®re synchrone, mais rappelez-vous qu'ici vous pouvez perdre des performances, utilisez donc des m√©thodes asynchrones chaque fois que possible. <br><br>  La m√©thode <code>dataSync</code> renvoie toujours les donn√©es dans un format de tableau plat.  Et si nous voulons renvoyer les donn√©es dans le format dans lequel elles sont stock√©es dans le tenseur, nous devons appeler <code>arraySync</code> . <br><br><h3>  Les op√©rateurs </h3><br>  Tous les op√©rateurs de TensorFlow sont <strong>immuables par d√©faut</strong> , c'est-√†-dire qu'√† chaque op√©ration un nouveau tenseur est toujours renvoy√©.  Ci-dessus, prenez simplement notre tableau et mettez en carr√© tous ses √©l√©ments. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   Immutable const x = tf.tensor([1,2,3,4]); const y = x.square(); // tf.square(x); y.print();</span></span></code> </pre> <br>  Pourquoi de telles difficult√©s pour des op√©rations math√©matiques simples?  Tous les op√©rateurs dont nous avons besoin - la somme, la m√©diane, etc. - sont l√†.  Cela est n√©cessaire car, en fait, le tenseur et cette approche vous permettent de cr√©er un graphique de calculs et d'effectuer des calculs non pas imm√©diatement, mais sur WebGL (dans le navigateur) ou CUDA (Node.js sur la machine).  Autrement dit, l'utilisation de l'acc√©l√©ration mat√©rielle est invisible pour nous et, si n√©cessaire, le repli sur le processeur.  La grande chose est que nous n'avons pas besoin d'y penser.  Nous avons juste besoin d'apprendre l'API tfjs. <br><br>  Maintenant, la chose la plus importante est le mod√®le. <br><br><h3>  Mod√®le </h3><br>  La fa√ßon la plus simple de cr√©er un mod√®le est s√©quentielle, c'est-√†-dire un mod√®le s√©quentiel, lorsque les donn√©es d'une couche sont transf√©r√©es vers la couche suivante et de celle-ci vers la couche suivante.  Les couches les plus simples utilis√©es ici sont utilis√©es. <blockquote>  La couche elle-m√™me n'est qu'une abstraction de tenseurs et d'op√©rateurs.  En gros, ce sont des fonctions d'aide qui vous cachent une √©norme quantit√© de math√©matiques. </blockquote><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//    const model = tf.sequential({ layers: [ tf.layers.dense({ inputShape: [784], units: 32, activation: 'relu' }), tf.layers.dense({ units: 10, activation: 'softmax' }) ] });</span></span></code> </pre> <br>  Essayons de comprendre comment travailler avec le mod√®le sans entrer dans les d√©tails d'impl√©mentation. <br><br>  Tout d'abord, nous indiquons la forme des donn√©es qui tombent dans le r√©seau neuronal - <code>inputShape</code> est un param√®tre requis.  Nous indiquons les <code>units</code> - le nombre de tableaux multidimensionnels et la fonction d'activation. <br><br>  La fonction <code>relu</code> remarquable en ce qu'elle a √©t√© trouv√©e par hasard - elle a √©t√© essay√©e, elle a mieux fonctionn√©, et pendant tr√®s longtemps, ils ont cherch√© une explication math√©matique pour expliquer pourquoi cela se produit. <br><br>  Pour la derni√®re couche, lorsque nous cr√©ons une cat√©gorie, la fonction softmax est souvent utilis√©e - elle est tr√®s bien adapt√©e pour afficher une r√©ponse au format One-Hot Encoding.  Une fois le mod√®le cr√©√©, appelez <code>model.summary()</code> pour vous assurer que le mod√®le est assembl√© correctement.  Dans des situations particuli√®rement difficiles, vous pouvez aborder la cr√©ation d'un mod√®le √† l'aide d'une programmation fonctionnelle. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const input = tf.input({ shape: [784] }); const dense1 = tf.layers.dense({ units: 32, activation: 'relu' }).apply(input); const dense2 = tf.layers.dense({ units: 10, activation: 'softmax' }).apply(dense1); const model = tf.model({ inputs: input, outputs: dense2 });</span></span></code> </pre> <br>  Si vous avez besoin de cr√©er un mod√®le particuli√®rement complexe, vous pouvez utiliser l'approche fonctionnelle: chaque fois que chaque couche est une nouvelle variable.  Par exemple, nous prenons manuellement la couche suivante et lui appliquons la couche pr√©c√©dente, afin de pouvoir construire des architectures plus complexes.  Je vous montrerai plus tard o√π cela peut √™tre utile. <br><br>  Le prochain d√©tail tr√®s important est que nous passons les couches d'entr√©e et de sortie dans le mod√®le, c'est-√†-dire les couches qui entrent dans le r√©seau neuronal et les couches qui sont des couches pour la r√©ponse. <br><br>  Apr√®s cela, une √©tape importante consiste √† <strong>compiler le mod√®le</strong> .  Essayons de comprendre ce qu'est la compilation en termes de tfjs. <br><br>  Rappelez-vous, nous avons essay√© de trouver les bonnes valeurs dans notre r√©seau de neurones.  Il n'est pas n√©cessaire de les r√©cup√©rer.  Ils sont s√©lectionn√©s d'une certaine mani√®re, comme le dit la fonction d'optimisation. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   (  ) model.compile({ optimizer: 'sgd', loss: 'categoricalCrossentropy', metrics: ['accuracy'] });</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Code pour la</a> description des couches s√©quentielles et la compilation.</i> <br><br>  Je vais illustrer ce qu'est un optimiseur et ce qu'est une fonction de perte. <br><br><img src="https://habrastorage.org/webt/se/lt/1l/selt1lv8ppxvokzopux387dp0os.png"><br><br>  L'optimiseur est l'ensemble de la carte.  Il vous permet non seulement de courir au hasard et de chercher de la valeur, mais de le faire judicieusement, selon un certain algorithme. <br><br>  La fonction de perte est la fa√ßon dont nous recherchons la valeur optimale (petite fl√®che noire).  Il aide √† comprendre les valeurs de gradient √† utiliser pour former notre r√©seau neuronal. <br><br>  √Ä l'avenir, lorsque vous ma√Ætriserez les r√©seaux de neurones, vous √©crirez vous-m√™me une fonction de perte.  Une grande partie du succ√®s d'un r√©seau de neurones d√©pend de la qualit√© de l'√©criture de cette fonction.  Mais c'est une autre histoire.  Commen√ßons simple. <br><br><h4>  Exemple d'apprentissage en r√©seau </h4><br>  Nous g√©n√©rerons des donn√©es al√©atoires et des r√©ponses al√©atoires (√©tiquettes).  Nous appelons le module d' <code>fit</code> , passons les donn√©es, les r√©ponses et plusieurs param√®tres importants: <br><br><ul><li>  <code>epochs</code> - 5 fois, c'est-√†-dire, grosso modo, 5 fois nous effectuerons une formation √† part enti√®re; </li><li>  <code>batchSize</code> , qui indique combien de poids peuvent √™tre modifi√©s en m√™me temps pour √™tre lev√©s - combien d'√©l√©ments √† traiter en m√™me temps.  Plus la carte vid√©o est bonne, plus elle a de m√©moire, plus la <code>batchSize</code> peut √™tre d√©finie. </li></ul><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const data = tf.randomNormal([100, 784]); const labels = tf.randomNormal([100, 10]); //   model.fit(data, labels, { epochs: 5, batchSize: 32 }).then(info =&gt; { console.log('  :', info.history.acc); })</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Code de</a> toutes les derni√®res √©tapes.</i> <br><br>  <code>Model.fit</code> asynchrone <code>Model.fit</code> , retourne promesse.  Mais vous pouvez utiliser async / wait et attendre l'ex√©cution de cette fa√ßon. <br><br>  Ensuite, <strong>utilisez</strong> .  Nous avons form√© notre mod√®le, puis nous prenons les donn√©es que nous voulons traiter, et nous appelons la m√©thode de <code>predict</code> , nous disons: "Pr√©dire ce qui est vraiment l√†?", Et gr√¢ce √† cela, nous obtenons le r√©sultat. <br><br><h3>  Structure standard </h3><br>  Chaque r√©seau de neurones a trois fichiers principaux: <br><br><ul><li>  index.js - fichier dans lequel tous les param√®tres du r√©seau neuronal sont stock√©s; </li><li>  model.js - un fichier dans lequel le mod√®le et son architecture sont stock√©s directement; </li><li>  data.js - un fichier o√π les donn√©es sont collect√©es, trait√©es et int√©gr√©es dans notre syst√®me. </li></ul><br>  Alors, j'ai parl√© de la fa√ßon d'apprendre TensorFlow.js.  Petite entreprise, il reste <strong>√† choisir un mod√®le</strong> . <br><br>  Malheureusement, ce n'est pas enti√®rement vrai.  En fait, chaque fois que vous choisissez un mod√®le, vous devez r√©p√©ter certaines √©tapes. <br><br><ul><li>  Pr√©parez-y des donn√©es, c'est-√†-dire effectuez l'incorporation, ajustez-les √† l'architecture. </li><li>  Configurez les param√®tres Hyper (je vous dirai plus tard ce que cela signifie). </li><li>  Former / former chaque r√©seau neuronal (chaque mod√®le peut avoir ses propres nuances). </li><li>  Appliquez un mod√®le neuronal, et encore une fois, vous pouvez appliquer de diff√©rentes mani√®res. </li></ul><br><h2>  Choisissez un mod√®le </h2><br>  Commen√ßons par les options de base que vous rencontrerez souvent. <br><br><h3>  Sens profond </h3><br>  Ceci est un exemple populaire d'un r√©seau neuronal profond.  Tout se fait tout simplement: il existe un ensemble de donn√©es accessible au public - MNIST. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6g/yu/-4/6gyu-4wjgg4zfvf8w7byjx_z5yw.jpeg" width="600"></div><br>  Ce sont des images √©tiquet√©es avec des nombres, sur la base desquelles il est pratique de former un r√©seau neuronal. <br><br>  Conform√©ment √† l'architecture de One-Hot Encoding, nous encodons chacune des derni√®res couches.  Chiffres 10 - en cons√©quence, il y aura 10 derni√®res couches √† la fin.  Nous soumettons simplement des photos en noir et blanc √† l'entr√©e, tout cela est tr√®s similaire √† ce dont nous avons parl√© au d√©but. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> model = tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">784</span></span>], <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> }), ] });</code> </pre> <br>  On redresse l'image en un tableau unidimensionnel, on obtient 784 √©l√©ments.  Dans une couche 512 tableaux.  Fonction d'activation <code>'relu'</code> . <br><br>  La couche de tableaux suivante est l√©g√®rement plus petite (256), la couche d'activation est √©galement <code>'relu'</code> .  Nous avons r√©duit le nombre de tableaux pour rechercher des caract√©ristiques plus g√©n√©rales.  Le r√©seau neuronal doit √™tre incit√© √† apprendre et forc√© de prendre une d√©cision g√©n√©rale plus s√©rieuse, car elle-m√™me ne le fera pas. <br><br>  √Ä la fin, nous fabriquons 10 matrices et utilisons l'activation softmax pour le codage √† chaud - ce type d'activation fonctionne bien avec ce type de codage de r√©ponse. <br><br>  Les r√©seaux profonds vous permettent de reconna√Ætre correctement 80 √† 90% des images - j'en veux plus.  Une personne reconna√Æt avec une qualit√© d'environ 96%.  Les r√©seaux de neurones peuvent-ils attraper et d√©passer une personne? <br><br><h3>  CNN (r√©seau neuronal convolutif) </h3><br>  Les r√©seaux convolutifs fonctionnent de mani√®re incroyablement simple.  Au final, ils ont la m√™me architecture que dans les exemples pr√©c√©dents.  Mais au d√©but, quelque chose d'autre se produit.  Les tableaux, au lieu de simplement donner des solutions, r√©duisent l'image.  Ils prennent une partie de l'image et la r√©duisent, l'effondrent √† un chiffre.  Ensuite, ils sont collect√©s tous ensemble et √† nouveau r√©duits. <br><img src="https://habrastorage.org/webt/mi/xc/gk/mixcgkl0kgopjxgams8szm0wr2q.jpeg"><br>  Ainsi, la taille de l'image est r√©duite, mais en m√™me temps des parties de l'image sont de mieux en mieux reconnues.  Les r√©seaux de convolution fonctionnent tr√®s bien pour la reconnaissance de formes, encore mieux que les humains. <br><blockquote>  La reconnaissance des images est mieux confi√©e √† une voiture qu'√† une personne.  Il y a eu une √©tude sp√©ciale et la personne a malheureusement perdu. </blockquote>  Les CNN fonctionnent tr√®s simplement: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> model = tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }), tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }), tf.layers.maxPooling2d({<span class="hljs-attr"><span class="hljs-attr">poolSize</span></span>: [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>]}), tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }) tf.layers.flatten(tf.layers.maxPooling2d({ <span class="hljs-attr"><span class="hljs-attr">poolSize</span></span>: [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>] })), tf.layers.dense({<span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>}), tf.layers.dense({<span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span>}) ] });</code> </pre> <br>  Nous entrons un tableau multidimensionnel sp√©cifique: une image de 28x28 pixels, plus une dimension pour la luminosit√©, dans ce cas, l'image est en noir et blanc, donc la troisi√®me dimension est 1. <br><br>  Ensuite, nous d√©finissons le nombre de <code>filters</code> et de <code>kernelSize</code> - combien de pixels se r√©tr√©ciront.  Fonction d'activation partout <code>relu</code> . <br><br>  Il existe une autre couche <code>maxPooling2d</code> , qui est n√©cessaire pour r√©duire la taille encore plus efficacement.  Les r√©seaux convolutifs r√©duisent la taille tr√®s progressivement, et il n'est souvent pas n√©cessaire de cr√©er des r√©seaux convolutionnels tr√®s profonds. <br><br>  J'expliquerai pourquoi il est impossible de faire des r√©seaux de convolution tr√®s profonds un peu plus tard, mais pour l'instant, rappelez-vous: il faut parfois les enrouler un peu plus vite.  Il existe une couche maxPooling distincte pour cela. <br><br>  √Ä la toute fin, il y a la m√™me couche dense.  Autrement dit, en utilisant des r√©seaux de neurones convolutifs, nous avons retir√© divers signes des donn√©es, apr√®s quoi nous utilisons l'approche standard et classons nos r√©sultats, gr√¢ce auxquels nous reconnaissons les images. <br><br><h3>  U net </h3><br>  Ce mod√®le d'architecture est associ√© aux r√©seaux de convolution.  Avec son aide, de nombreuses d√©couvertes ont √©t√© faites dans le domaine de la lutte contre le cancer, par exemple dans la reconnaissance des cellules canc√©reuses et du glaucome.  De plus, ce mod√®le ne peut pas trouver de cellules malignes pire qu'un professeur dans ce domaine. <br><br>  Un exemple simple: parmi les donn√©es bruyantes dont vous avez besoin pour trouver des cellules canc√©reuses (cercles). <br><br><img src="https://habrastorage.org/webt/hj/9b/yr/hj9byresramxnetrg7t_kenia0a.jpeg"><br><br>  U-Net est si bon qu'il peut les trouver presque parfaitement.  L'architecture est tr√®s simple: <br><br><img src="https://habrastorage.org/webt/16/5_/vx/165_vxamsqm5eveub2tdhzxprc8.jpeg"><br><br>  Il existe les m√™mes r√©seaux de convolution, tout comme il y a MaxPooling, ce qui r√©duit la taille.  La seule diff√©rence: le mod√®le utilise √©galement des r√©seaux de <strong>num√©risation</strong> - le <strong>r√©seau d√©convolutionnel</strong> . <br><br>  En plus de la convolution-scan, chacune des couches de haut niveau est combin√©e les unes avec les autres (d√©but et sortie), en raison de laquelle un grand nombre de relations apparaissent.  Ces U-Net fonctionnent bien m√™me sur de petites quantit√©s de donn√©es. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//First part (down climb) const input = buildInput(...IMAGE_INPUT); const conv1 = genConv2D(64).apply(input); const conv2 = genConv2D(64).apply(conv1); const pool1 = geMaxPool2D(2).apply(conv2); const conv3 = genConv2D(128).apply(pool1); const conv4 = genConv2D(128).apply(conv3); const pool2 = geMaxPool2D(2).apply(conv4); const conv5 = genConv2D(256).apply(pool2); const conv6 = genConv2D(256).apply(conv5); const pool3 = geMaxPool2D(2).apply(conv6); const conv7 = genConv2D(512).apply(pool3); const conv8 = genConv2D(512).apply(conv7); const pool4 = geMaxPool2D(2).apply(conv8); const conv9 = genConv2D(1024).apply(pool4); const conv10 = genConv2D(1024).apply(conv9); const up1 = genUp2D().apply(conv10); const merge1 = tf.layers.concatenate({ axis: 3 }).apply([up1, conv8]); //Second part (up climb) const conv11 = genConv2D(512).apply(merge1); const conv12 = genConv2D(512).apply(conv11); const up2 = genUp2D().apply(conv12); const merge2 = tf.layers.concatenate({ axis: 3 }).apply([up2, conv6]); const conv13 = genConv2D(256).apply(merge2); const conv14 = genConv2D(256).apply(conv13); const up3 = genUp2D().apply(conv14); const merge3 = tf.layers.concatenate({ axis: 3 }).apply([up3, conv4]); const conv15 = genConv2D(128).apply(merge3); const conv16 = genConv2D(128).apply(conv15); const up4 = genUp2D().apply(conv16); const merge4 = tf.layers.concatenate({ axis: 3 }).apply([up4, conv2]); const conv17 = genConv2D(64).apply(merge4); const conv18 = genConv2D(64).apply(conv17); const conv19 = tf.layers .conv2d({ kernelSize: [1, 1], activation: "sigmoid", filters: 1, padding: "same" }) .apply(conv18); const model = tf.model({ inputs: input, outputs: conv19 });</span></span></code> </pre> <br>  Ce code est plus facile √† apprendre dans l'√©diteur.  En g√©n√©ral, un grand nombre de r√©seaux de convolution sont cr√©√©s ici, puis, pour les red√©ployer, nous <code>concatenate</code> et fusionnons plusieurs couches.  Ceci est juste une visualisation d'une image, uniquement sous forme de code.  Tout est assez simple - copier et reproduire un tel mod√®le est facile. <br><br><h2>  LSTM (longue m√©moire √† court terme) </h2><br>  Notez que tous les exemples consid√©r√©s ont une caract√©ristique - le format des donn√©es d'entr√©e est fixe.  L'entr√©e sur le r√©seau, les donn√©es doivent √™tre de la m√™me taille et correspondre les unes aux autres.  Les mod√®les LSTM se concentrent sur la fa√ßon de g√©rer cela. <br><br>  Par exemple, il existe un service Yandex.Referats, qui g√©n√®re des r√©sum√©s. <br><br><img src="https://habrastorage.org/webt/_o/g7/mh/_og7mh4hlaz87r6jpbkzjqsgdbc.png"><br><br>  Il donne un abracadabra complet, mais en m√™me temps assez similaire √† la v√©rit√©: <br><br><blockquote>  <strong>R√©sum√© en math√©matiques sur le th√®me: ¬´Le bin√¥me de Newton comme axiome¬ª</strong> <br><br>  Selon ce qui pr√©c√®de, l'int√©grale de surface produit une int√©grale curviligne.  La fonction convexe vers le bas est toujours en demande. <br><br>  Il en d√©coule naturellement que la normale √† la surface est toujours demand√©e.  Selon la pr√©c√©dente, l'int√©grale de Poisson sp√©cifie essentiellement l'int√©grale trigonom√©trique de Poisson. </blockquote><br>  Le service est bas√© sur des r√©seaux de neurones Seq √† Seq.  Leur architecture est plus complexe. <br><br><img src="https://habrastorage.org/webt/6r/3s/aw/6r3sawht3bnxadqmorz0vjqwzmw.jpeg"><br><br>  Les couches sont dispos√©es dans un syst√®me assez complexe.  Mais ne vous inqui√©tez pas - vous n'avez pas √† ex√©cuter toutes ces fl√®ches vous-m√™me.  Si vous le souhaitez, vous pouvez, mais ce n'est pas n√©cessaire.  Il y a un assistant qui fera cela pour vous. <br><br>  La principale chose √† comprendre est que chacune de ces pi√®ces est combin√©e avec la pr√©c√©dente.  Il prend des donn√©es non seulement des donn√©es initiales, mais aussi de la couche neuronale pr√©c√©dente.  En gros, il est possible de cr√©er une sorte de m√©moire - de m√©moriser une s√©quence de donn√©es, de la reproduire et, gr√¢ce √† ce travail, ¬´s√©quence en s√©quence¬ª.  De plus, les s√©quences peuvent √™tre de tailles diff√©rentes √† la fois en entr√©e et en sortie. <br><br>  Tout est beau dans le code: <br><br><pre> <code class="javascript hljs">tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.lstm({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">returnSequences</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>] }), tf.layers.lstm({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">returnSequences</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> }) ] }) ;</code> </pre> <br>  Il y a un assistant sp√©cial qui dit que nous avons 512 objets (tableaux).  Ensuite, renvoyez la s√©quence et le formulaire d'entr√©e ( <code>inputShape: [10000, 64]</code> ).  Ensuite, nous introduisons une autre couche, mais nous ne retournons pas la s√©quence ( <code>returnSequences: false</code> ), car √† la fin, nous disons que nous devons maintenant utiliser la fonction d'activation pour 64 caract√®res diff√©rents (lettres minuscules et majuscules).  64 options sont activ√©es √† l'aide de l'encodage √† chaud. <br><br><h2>  Le plus int√©ressant </h2><br>  Maintenant, vous vous demandez probablement: ¬´C'est tout, bien s√ªr, bien, mais pourquoi en ai-je besoin?  "Lutter contre le cancer est bien, mais pourquoi en ai-je besoin en premi√®re ligne?" <br><br>  Et les danses avec un tambourin commencent: pour comprendre comment appliquer des r√©seaux de neurones √† la disposition, par exemple. <br><blockquote>  √Ä l'aide de r√©seaux de neurones, il est possible de r√©soudre des probl√®mes qui √©taient auparavant impossibles √† r√©soudre.  Certains auxquels vous ne pouviez m√™me pas penser.  Tout d√©pend de vous, de votre imagination et d'un peu de pratique. </blockquote>  Je vais maintenant montrer en direct des exemples int√©ressants de l'utilisation des mod√®les que nous avons examin√©s. <br><br><h3>  CNN  √âquipes audio </h3><br>  En utilisant des r√©seaux de convolution, vous pouvez reconna√Ætre non seulement des images, mais √©galement des commandes audio, et avec une qualit√© de reconnaissance de 97%, c'est-√†-dire au niveau de Google Assistant et de Yandex-Alice. <br><br>  Sur le seul r√©seau, bien s√ªr, on ne peut pas reconna√Ætre la parole √† part enti√®re, les phrases, mais vous pouvez cr√©er un simple assistant vocal. <br><br>  Plus d'informations sur Alice peuvent √™tre trouv√©es dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport de</a> Nikita Dubko, et sur l'assistant Google, comment travailler avec la voix dedans, et sur les standards du navigateur, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Le fait est que tout mot, toute commande peut √™tre transform√© en spectrogramme. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/au/_v/r8/au_vr8gdnqh3k6gkcgyhz0ybwoq.jpeg" width="500"></div><br>  Vous pouvez convertir n'importe quelle information audio en un tel spectrogramme.  Et puis vous pouvez encoder l'audio dans l'image, appliquer CNN √† l'image et reconna√Ætre les commandes vocales simples. <br><br><h3>  U-net.  Test de capture d'√©cran </h3><br>  U-Net est utile non seulement pour un diagnostic de cancer r√©ussi, mais aussi, par exemple, pour tester des captures d'√©cran.  Pour plus de d√©tails, voir le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport de</a> Lyudmila Mzhachikh, et je dirai √† la base elle-m√™me. <br><br>  Pour tester avec des captures d'√©cran, deux captures d'√©cran sont n√©cessaires: <br><br><ul><li>  base (r√©f√©rence) avec laquelle nous comparons; </li><li>  capture d'√©cran pour les tests. </li></ul><br><img src="https://habrastorage.org/webt/kx/2g/ci/kx2gcib0rilb_zzhohk15dmnoi4.jpeg"><br>  Malheureusement, dans les tests de capture d'√©cran, il y a souvent beaucoup de chutes n√©gatives (faux positifs).  Mais cela peut √™tre √©vit√© en appliquant des technologies avanc√©es de lutte contre le cancer au front-end. <br><br>  Rappelez-vous, nous avons marqu√© l'image sur la zone o√π il y a un cancer et non.  La m√™me chose peut √™tre faite ici. <br><br><img src="https://habrastorage.org/webt/19/kk/uw/19kkuwktd9iv30ffolxasj3_l-k.jpeg"><br><br>  Si nous voyons une image avec une bonne mise en page, nous ne la marquons pas et nous marquons les images avec une mauvaise mise en page.  Ainsi, vous pouvez tester la mise en page avec une seule image.   ,     ,   ,    . U-Net     . <br><br>       ,    ,    .  ,          U-Net,  .  ,   . <br><br><h3> LSTM. Twitter ‚Äî  2000 </h3><br>   ,    ,     ,    . <br><br>       ,     LSTM  .   40     - , : <em>¬´ ‚Äî     ¬ª</em> . <br><br>   ,  : <br><br><img src="https://habrastorage.org/webt/yu/_6/xk/yu_6xkkdkak9jganrrpvxs6vd9g.jpeg"><br><br> -   , ? <br><br>  ‚Äî .    -   : <br><br><img src="https://habrastorage.org/webt/lk/hz/sf/lkhzsfwyvs42ky2yi-k6m5reu7o.jpeg"><br><br><img src="https://habrastorage.org/webt/ai/a7/jv/aia7jvkjsgw35wpjixbsko4vjwe.jpeg"><br><br>  ,   ¬´¬ª       ,       ,        (,  ). <br><br>  : <em>¬´    ¬ª</em>  <em>¬´   ¬ª</em> . <br><br>       ‚Äî  . <br><blockquote> ¬´   ¬ª. </blockquote><br>      : <br><br><img src="https://habrastorage.org/webt/lv/ud/dp/lvuddp8bnuagbh4kgmsao3j_qvo.jpeg"><br><br><h4> EPOCS 250 </h4><br>    ,     . <br><br>    -   , ,  ,     .   ,      Overfitting ‚Äî . <br><br>   ,    ‚Äî       .  , , .   ,   ,         ,         . <br><br>    ,       ,          . <br><br>  ,       . <br><br><img src="https://habrastorage.org/webt/cv/_j/ft/cv_jftct2bzeb2_ik1apzezgjsg.jpeg"><br><br>   , ,        ,        .      ( ,  ),      .          . <br><blockquote>     ‚Äî    .    . </blockquote>      overfitting.      ,    helper-: Dropout; BatchNormalization. <br><br><h3> LSTM. Prettier </h3><br>  ,     ‚Äî  Prettier   .       ,     . <br><br>  <code>const a = 1</code> .    : <code>[]c co on ns st</code> ,    ,            : <code>[][] []c co on ns st</code> ,      . <br><br>     ,            ,     . <br><br> ,    ,     .      , ,  0 ‚Äî  ,      -  ,  - .   . <br><br>            ,      .         . <br><br><h2>  Au lieu de conclusions </h2><br> , ,     .   . , ,         Deep Neural Network. <br><br>        .         ,      .      .            .     . <br><br>       JS,       ,     .         ,      .  ,   JavaScript,         .     TensorFlow.js. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><em></em></a> <em> ,     .    </em> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><em>telegram-</em></a> <em>    JS.</em> <br><blockquote>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FrontendConf</a>    , 13 .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> 32        . <br><br>    ,    ,           .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>  Saint AppsConf,       .      ,  ,    ,     . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr470904/">https://habr.com/ru/post/fr470904/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr470884/index.html">√âcriture et lecture de donn√©es dans la blockchain Bitcoin</a></li>
<li><a href="../fr470888/index.html">L√©gislation russe et internationale dans le domaine de la protection des donn√©es personnelles</a></li>
<li><a href="../fr470892/index.html">Impl√©mentation simple d'un petit CAM sur FPGA</a></li>
<li><a href="../fr470894/index.html">Balle</a></li>
<li><a href="../fr470902/index.html">Hautes performances et partitionnement natif: Zabbix avec prise en charge de TimescaleDB</a></li>
<li><a href="../fr470908/index.html">Pour la premi√®re fois au monde √† l'aide de technologies additives, un assemblage de moteur d'avion de grande taille a √©t√© obtenu</a></li>
<li><a href="../fr470910/index.html">Que peut-on faire avec les annotations des contrats de microservices?</a></li>
<li><a href="../fr470916/index.html">Le point de contr√¥le √©lectronique ¬´le moins cher¬ª en Russie contr√¥l√© depuis un smartphone</a></li>
<li><a href="../fr470918/index.html">F # 9: Option de type</a></li>
<li><a href="../fr470920/index.html">5+ fa√ßons de se connecter √† un cloud DataLine</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
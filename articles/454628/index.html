<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ‚Äçüé§ üë®üèª‚Äç‚öñÔ∏è ‚Ü™Ô∏è Construyendo un sistema autom√°tico de moderaci√≥n de mensajes üôÜ üßôüèª üíÆ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los sistemas de moderaci√≥n autom√°tica se implementan en servicios web y aplicaciones donde es necesario procesar una gran cantidad de mensajes de usua...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Construyendo un sistema autom√°tico de moderaci√≥n de mensajes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454628/"><img src="https://habrastorage.org/webt/xu/yp/u9/xuypu9acrj8o6qbkrhu53ue4kni.png" alt="imagen"><br>  Los sistemas de moderaci√≥n autom√°tica se implementan en servicios web y aplicaciones donde es necesario procesar una gran cantidad de mensajes de usuario.  Dichos sistemas pueden reducir los costos de la moderaci√≥n manual, acelerarla y procesar todos los mensajes de los usuarios en tiempo real.  En el art√≠culo, hablaremos sobre la construcci√≥n de un sistema de moderaci√≥n autom√°tica para procesar ingl√©s usando algoritmos de aprendizaje autom√°tico.  Discutiremos todo el trabajo de la tuber√≠a desde las tareas de investigaci√≥n y la elecci√≥n de los algoritmos de ML hasta la implementaci√≥n.  Veamos d√≥nde buscar conjuntos de datos listos para usar y c√≥mo recopilar datos para la tarea usted mismo. <br><a name="habracut"></a><br><br>  <i>Preparado con Ira Stepanyuk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">id_step</a> ), cient√≠fico de datos en Poteha Labs</i> <br><br><h2>  Descripci√≥n de la tarea </h2><br>  Trabajamos con chats activos multiusuario, donde pueden aparecer mensajes cortos de docenas de usuarios en un chat cada minuto.  La tarea es resaltar mensajes t√≥xicos y mensajes con comentarios obscenos en los di√°logos de dichos chats.  Desde el punto de vista del aprendizaje autom√°tico, esta es una tarea de clasificaci√≥n binaria, donde cada mensaje debe asignarse a una de las clases. <br><br>  Para resolver este problema, antes que nada, era necesario comprender qu√© son los mensajes t√≥xicos y qu√© los hace t√≥xicos.  Para hacer esto, observamos una gran cantidad de mensajes de usuario t√≠picos en Internet.  Aqu√≠ hay algunos ejemplos que ya hemos dividido en mensajes t√≥xicos y normales. <br><br><div class="scrollable-table"><table><tbody><tr><th>  T√≥xico </th><th>  Normal </th></tr><tr><td>  Eres un maldito maric√≥n </td><td>  este libro es tan tonto </td></tr><tr><td>  tu hijo es tan feo (1) </td><td>  Los ganadores ganan, los perdedores ponen excusas </td></tr><tr><td>  Los blancos son due√±os de negros (2) </td><td>  negro como mi alma (2) </td></tr></tbody></table></div><br>  Se puede ver que los mensajes t√≥xicos a menudo contienen palabras obscenas, pero a√∫n as√≠ esto no es un requisito previo.  El mensaje puede no contener palabras inapropiadas, pero puede ser ofensivo para alguien (ejemplo (1)).  Adem√°s, a veces los mensajes t√≥xicos y normales contienen las mismas palabras que se usan en diferentes contextos, ofensivos o no (ejemplo (2)).  Tales mensajes tambi√©n deben ser capaces de distinguir. <br>  Habiendo estudiado varios mensajes, para nuestro sistema de moderaci√≥n llamamos <b><i>t√≥xico a</i></b> aquellos mensajes que contienen declaraciones con expresiones obscenas, insultantes u odio hacia alguien. <br><br><h2>  Datos </h2><br><h4>  Datos abiertos </h4><br>  Uno de los conjuntos de datos de moderaci√≥n m√°s famosos es el conjunto de datos del Kaggle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Toxic Comment Classification Challenge</a> .  Parte del marcado en el conjunto de datos es incorrecto: por ejemplo, los mensajes con palabras obscenas se pueden marcar como normales.  Debido a esto, no puedes simplemente competir en Kernel y obtener un algoritmo de clasificaci√≥n que funcione bien.  Debe trabajar m√°s con los datos, ver qu√© ejemplos no son suficientes y agregar datos adicionales con dichos ejemplos. <br><br>  Adem√°s de los concursos, hay varias publicaciones cient√≠ficas con enlaces a conjuntos de datos adecuados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ejemplo</a> ), pero no todos pueden usarse en proyectos comerciales.  La mayor√≠a de estos conjuntos de datos contienen mensajes de la red social Twitter, donde puedes encontrar muchos tweets t√≥xicos.  Adem√°s, los datos se recopilan de Twitter, ya que ciertos hashtags se pueden usar para buscar y marcar mensajes de usuario t√≥xicos. <br><br><h4>  Datos manuales </h4><br>  Despu√©s de recopilar el conjunto de datos de fuentes abiertas y entrenarlo en el modelo b√°sico, qued√≥ claro que los datos abiertos no son suficientes: la calidad del modelo no es satisfactoria.  Adem√°s de los datos abiertos para resolver el problema, ten√≠amos a nuestra disposici√≥n una selecci√≥n no asignada de mensajes de un mensajero del juego con una gran cantidad de mensajes t√≥xicos. <br><br><img src="https://habrastorage.org/webt/eh/sp/5o/ehsp5oivhvjnfgxrnjqc7wszf9u.gif" alt="imagen"><br><br>  Para usar estos datos para su tarea, tuvieron que ser etiquetados de alguna manera.  En ese momento, ya hab√≠a un clasificador de l√≠nea base entrenado, que decidimos usar para el marcado semiautom√°tico.  Despu√©s de ejecutar todos los mensajes a trav√©s del modelo, obtuvimos las probabilidades de toxicidad de cada mensaje y los ordenamos en orden descendente.  Al comienzo de esta lista se recopilaron mensajes con palabras obscenas y ofensivas.  Al final, por el contrario, hay mensajes de usuario normales.  Por lo tanto, la mayor√≠a de los datos (con valores de probabilidad muy grandes y muy peque√±os) no se pudieron marcar, sino que se asignaron inmediatamente a una determinada clase.  Queda por marcar los mensajes que se ubicaron en el medio de la lista, lo que se hizo manualmente. <br><br><h4>  Aumento de datos </h4><br>  A menudo, en los conjuntos de datos puede ver mensajes cambiados en los que el clasificador est√° equivocado, y la persona entiende correctamente su significado. <br>  Esto se debe a que los usuarios se ajustan y aprenden a enga√±ar a los sistemas de moderaci√≥n para que los algoritmos cometan errores en los mensajes t√≥xicos, y el significado permanece claro para la persona.  Lo que los usuarios est√°n haciendo ahora: <br><br><ul><li>  errores tipogr√°ficos generan: <i>eres un est√∫pido imb√©cil, f√≥llate</i> , </li><li>  reemplace los caracteres alfab√©ticos con n√∫meros similares en la descripci√≥n: <i>n1gga, b0ll0cks</i> , </li><li>  inserte espacios adicionales: <i>idiota</i> , </li><li>  eliminar espacios entre palabras: <i>dieyoustupid</i> . </li></ul><br><br>  Para entrenar un clasificador que sea resistente a tales sustituciones, debe hacer lo que hacen los usuarios: generar los mismos cambios en los mensajes y agregarlos al conjunto de entrenamiento a los datos principales. <br>  En general, esta lucha es inevitable: los usuarios siempre tratar√°n de encontrar vulnerabilidades y ataques, y los moderadores implementar√°n nuevos algoritmos. <br><br><h3>  Descripci√≥n de subtareas </h3><br>  Nos enfrentamos a subtareas para analizar mensajes en dos modos diferentes: <br><br><ul><li>  modo en l√≠nea: an√°lisis de mensajes en tiempo real, con m√°xima velocidad de respuesta; </li><li>  modo fuera de l√≠nea: an√°lisis de registros de mensajes y asignaci√≥n de di√°logos t√≥xicos. </li></ul><br>  En el modo en l√≠nea, procesamos cada mensaje de usuario y lo ejecutamos a trav√©s del modelo.  Si el mensaje es t√≥xico, oc√∫ltelo en la interfaz de chat y, si es normal, mu√©strelo.  En este modo, todos los mensajes deben procesarse muy r√°pidamente: el modelo debe dar una respuesta tan r√°pida como para no interrumpir la estructura del di√°logo entre usuarios. <br>  En el modo fuera de l√≠nea, no hay l√≠mites de tiempo para el trabajo y, por lo tanto, quer√≠a implementar el modelo con la m√°s alta calidad. <br><br><h3>  Modo en l√≠nea.  B√∫squeda de diccionario </h3><br>  Independientemente del modelo que se elija a continuaci√≥n, debemos buscar y filtrar mensajes con palabras obscenas.  Para resolver este subproblema, es m√°s f√°cil compilar un diccionario de palabras y expresiones no v√°lidas que no se pueden omitir, y buscar esas palabras en cada mensaje.  La b√∫squeda debe ser r√°pida, por lo que el algoritmo de b√∫squeda de subcadenas ingenuo para ese tiempo no encaja.  Un algoritmo adecuado para encontrar un conjunto de palabras en una cadena es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el algoritmo Aho-Korasik</a> .  Debido a este enfoque, es posible identificar r√°pidamente algunos ejemplos t√≥xicos y bloquear mensajes antes de que se transmitan al algoritmo principal.  El uso del algoritmo ML le permitir√° "comprender el significado" de los mensajes y mejorar la calidad de la clasificaci√≥n. <br><br><h3>  Modo en l√≠nea.  Modelo b√°sico de aprendizaje autom√°tico </h3><br>  Para el modelo base, decidimos utilizar un enfoque est√°ndar para la clasificaci√≥n de texto: TF-IDF + algoritmo de clasificaci√≥n cl√°sico.  De nuevo por razones de velocidad y rendimiento. <br><br>  TF-IDF es una medida estad√≠stica que le permite determinar las palabras m√°s importantes para el texto en el cuerpo utilizando dos par√°metros: la frecuencia de las palabras en cada documento y el n√∫mero de documentos que contienen una palabra espec√≠fica (en m√°s detalle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ).  Habiendo calculado para cada palabra en el mensaje TF-IDF, obtenemos una representaci√≥n vectorial de este mensaje. <br>  TF-IDF se puede calcular para palabras en el texto, as√≠ como para palabras y caracteres de n-gramas.  Dicha extensi√≥n funcionar√° mejor, ya que podr√° manejar frases y palabras frecuentes que no estaban en la muestra de capacitaci√≥n (fuera del vocabulario). <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_extraction.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TfidfVectorizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sparse vect_word = TfidfVectorizer(max_features=<span class="hljs-number"><span class="hljs-number">10000</span></span>, lowercase=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, analyzer=<span class="hljs-string"><span class="hljs-string">'word'</span></span>, min_df=<span class="hljs-number"><span class="hljs-number">8</span></span>, stop_words=stop_words, ngram_range=(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) vect_char = TfidfVectorizer(max_features=<span class="hljs-number"><span class="hljs-number">30000</span></span>, lowercase=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, analyzer=<span class="hljs-string"><span class="hljs-string">'char'</span></span>, min_df=<span class="hljs-number"><span class="hljs-number">8</span></span>, ngram_range=(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) x_vec_word = vect_word.fit_transform(x_train) x_vec_char = vect_char.fit_transform(x_train) x_vec = sparse.hstack([x_vec_word, x_vec_char])</code> </pre>  <i>Ejemplo de uso de TF-IDF en n-gramos de palabras y caracteres</i> <br><br>  Despu√©s de convertir los mensajes en vectores, puede usar cualquier m√©todo cl√°sico para la clasificaci√≥n: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">regresi√≥n log√≠stica, SVM</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bosque aleatorio, impulso</a> . <br><br>  Decidimos utilizar la regresi√≥n log√≠stica en nuestra tarea, ya que este modelo aumenta la velocidad en comparaci√≥n con otros clasificadores cl√°sicos de ML y predice las probabilidades de clase, lo que le permite seleccionar de manera flexible un umbral de clasificaci√≥n en la producci√≥n. <br><br>  El algoritmo obtenido usando TF-IDF y la regresi√≥n log√≠stica funciona r√°pidamente y define bien los mensajes con palabras y expresiones obscenas, pero no siempre comprende el significado.  Por ejemplo, a menudo los mensajes con las palabras ' <i>negro</i> ' y ' <i>feminismo</i> ' cayeron en la clase t√≥xica.  Quer√≠a solucionar este problema y aprender a comprender mejor el significado de los mensajes utilizando la pr√≥xima versi√≥n del clasificador. <br><br><h3>  Modo fuera de l√≠nea </h3><br>  Para comprender mejor el significado de los mensajes, puede usar algoritmos de redes neuronales: <br><br><ul><li>  Incrustaciones (Word2Vec, FastText) </li><li>  Redes neuronales (CNN, RNN, LSTM) </li><li>  Nuevos modelos pre-entrenados (ELMo, ULMFiT, BERT) </li></ul><br>  Analizaremos algunos de estos algoritmos y c√≥mo se pueden usar con m√°s detalle. <br><br><h4>  Word2Vec y FastText </h4><br>  Los modelos de incrustaci√≥n le permiten obtener representaciones vectoriales de palabras de textos.  Hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dos tipos de Word2Vec</a> : Skip-gram y CBOW (Continuous Bag of Words).  En Skip-gram, el contexto es predicho por la palabra, pero en CBOW, viceversa: el contexto predice la palabra. <br><img src="https://habrastorage.org/webt/rc/kb/iv/rckbivfc1dvmna3bvccy6xoai_g.png" alt="imagen"><br>  Dichos modelos est√°n entrenados en grandes cuerpos de textos y le permiten obtener representaciones vectoriales de palabras de una capa oculta de una red neuronal entrenada.  La desventaja de esta arquitectura es que el modelo aprende de un conjunto limitado de palabras contenidas en el corpus.  Esto significa que para todas las palabras que no estaban en el cuerpo de textos en la etapa de entrenamiento, no habr√° incrustaciones.  Y esta situaci√≥n a menudo ocurre cuando se usan modelos pre-entrenados para sus tareas: para algunas de las palabras no habr√° incrustaciones, en consecuencia se perder√° una gran cantidad de informaci√≥n √∫til. <br><br>  Para resolver el problema con palabras que no est√°n en el diccionario (OOV, fuera del vocabulario) hay un modelo de incrustaci√≥n mejorado: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FastText</a> .  En lugar de usar palabras simples para entrenar la red neuronal, FastText divide las palabras en n-gramas (subpalabras) y aprende de ellas.  Para obtener una representaci√≥n vectorial de una palabra, debe obtener representaciones vectoriales del n-gramo de esta palabra y agregarlas. <br><br>  Por lo tanto, los modelos Word2Vec y FastText pre-entrenados se pueden usar para obtener vectores de caracter√≠sticas de los mensajes.  Las caracter√≠sticas obtenidas se pueden clasificar utilizando clasificadores cl√°sicos de ML o una red neuronal completamente conectada. <br><br><img src="https://habrastorage.org/webt/jb/bp/ma/jbbpma-miqfsht7roadxuk2bap4.png" alt="imagen"><br>  <i>Un ejemplo de la salida de las palabras "m√°s cercano" en significado usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FastText</a> pre- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">entrenado</a></i> <br><br><h4>  Clasificador CNN </h4><br>  Para el procesamiento y clasificaci√≥n de textos de algoritmos de redes neuronales, las redes recurrentes (LSTM, GRU) se usan con mayor frecuencia, ya que funcionan bien con secuencias.  Las redes convolucionales (CNN) se usan con mayor frecuencia para el procesamiento de im√°genes, pero tambi√©n se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pueden usar</a> en la tarea de clasificaci√≥n de texto.  Considere c√≥mo se puede hacer esto. <br>  Cada mensaje es una matriz en la que en cada l√≠nea del token (palabra) se escribe su representaci√≥n vectorial.  La convoluci√≥n se aplica a dicha matriz de cierta manera: el filtro de convoluci√≥n "se desliza" sobre filas enteras de la matriz (vectores de palabras), pero captura varias palabras a la vez (generalmente 2-5 palabras), procesando as√≠ las palabras en el contexto de palabras vecinas.  Los detalles de c√≥mo sucede esto se pueden ver en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">imagen</a> . <br><img src="https://habrastorage.org/webt/hx/yd/vf/hxydvfho2bzzmgyjedkkt9lz9gc.png" alt="imagen"><br>  ¬øPor qu√© usar redes convolucionales para el procesamiento de textos cuando puede usar recurrentes?  El hecho es que las convoluciones funcionan mucho m√°s r√°pido.  Utiliz√°ndolos para la clasificaci√≥n de mensajes, puede ahorrar mucho tiempo en la capacitaci√≥n. <br><br><h4>  ELMo </h4><br>  ELMo (incrustaciones de modelos de lenguaje) es un modelo de incrustaci√≥n basado en un modelo de idioma que se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">introdujo recientemente</a> .  El nuevo modelo de incrustaci√≥n es diferente de los modelos Word2Vec y FastText.  Los vectores de palabras ELMo tienen ciertas ventajas: <br><br><ul><li>  La presentaci√≥n de cada palabra depende del contexto completo en el que se usa. </li><li>  La representaci√≥n se basa en s√≠mbolos, lo que permite la formaci√≥n de representaciones confiables para palabras OOV (fuera del vocabulario). </li></ul><br><br>  ELMo se puede utilizar para diversas tareas en PNL.  Por ejemplo, para nuestra tarea, los vectores de mensajes recibidos usando ELMo se pueden enviar al clasificador cl√°sico de ML o usar una red convolucional o totalmente conectada. <br>  Las incrustaciones pre-entrenadas ELMo son bastante simples de usar para su tarea, un ejemplo de uso se puede encontrar <a href="">aqu√≠</a> . <br><br><h3>  Caracter√≠sticas de implementaci√≥n </h3><br><h4>  API de matraz </h4><br>  El prototipo de API fue escrito en Flask, ya que es f√°cil de usar. <br><br><h4>  Dos im√°genes de Docker </h4><br>  Para la implementaci√≥n, utilizamos dos im√°genes de acoplador: la base, donde se instalaron todas las dependencias, y la principal para iniciar la aplicaci√≥n.  Esto ahorra mucho tiempo de montaje, ya que la primera imagen rara vez se reconstruye, y esto ahorra tiempo durante la implementaci√≥n.  Se dedica mucho tiempo a construir y descargar bibliotecas de aprendizaje autom√°tico, lo que no es necesario con cada confirmaci√≥n. <br><br><h4>  Prueba </h4><br>  La peculiaridad de la implementaci√≥n de un n√∫mero bastante grande de algoritmos de aprendizaje autom√°tico es que incluso con altas m√©tricas en el conjunto de datos de validaci√≥n, la calidad real del algoritmo en producci√≥n puede ser baja.  Por lo tanto, para probar el funcionamiento del algoritmo, todo el equipo us√≥ el bot en Slack.  Esto es muy conveniente, porque cualquier miembro del equipo puede verificar qu√© respuesta dan los algoritmos para un mensaje en particular.  Este m√©todo de prueba le permite ver de inmediato c√≥mo funcionar√°n los algoritmos en los datos en vivo. <br>  Una buena alternativa es lanzar la soluci√≥n en sitios p√∫blicos como Yandex Toloka y AWS Mechanical Turk. <br><br><h3>  Conclusi√≥n </h3><br>  Examinamos varios enfoques para resolver el problema de la moderaci√≥n autom√°tica de mensajes y describimos las caracter√≠sticas de nuestra implementaci√≥n. <br>  Las principales observaciones obtenidas durante el trabajo: <br><br><ul><li>  La b√∫squeda de diccionario y el algoritmo de aprendizaje autom√°tico basados ‚Äã‚Äãen TF-IDF y la regresi√≥n log√≠stica permitieron clasificar los mensajes r√°pidamente, pero no siempre correctamente. </li><li>  Los algoritmos de red neuronal y los modelos de incrustaciones pre-entrenados hacen frente mejor a esta tarea y pueden determinar la toxicidad dentro del significado del mensaje. </li></ul><br><br>  Por supuesto, publicamos la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">demostraci√≥n</a> abierta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Poteha Toxic Comment Detection</a> en el bot de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Facebook</a> .  ¬°Ay√∫danos a mejorar el bot! <br><br>  Estar√© encantado de responder preguntas en los comentarios. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/454628/">https://habr.com/ru/post/454628/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../454616/index.html">El uso de IA para aumentar la eficiencia de los trabajadores mentales</a></li>
<li><a href="../454618/index.html">Foso de productividad: c√≥mo da√±a Slack nuestro flujo de trabajo</a></li>
<li><a href="../454620/index.html">#NoDeployFriday: ¬øayuda o perjudica?</a></li>
<li><a href="../454622/index.html">Kreisel EVEX 910e: modelo hist√≥rico - nueva vida</a></li>
<li><a href="../454626/index.html">DevOops ayer y hoy</a></li>
<li><a href="../454630/index.html">Situaciones excepcionales: parte 1 de 4</a></li>
<li><a href="../454634/index.html">Semana de la seguridad 23: vulnerabilidad del Bloc de notas, un mill√≥n de sistemas con RDP sin parches</a></li>
<li><a href="../454640/index.html">Depuraci√≥n remota de microservicios a trav√©s de SSH bajo VPN en 4 turnos</a></li>
<li><a href="../454642/index.html">‚Äú‚Äú Hacer una aplicaci√≥n para personas ‚Äù: esto no debe garabatearse en la rodilla‚Äù: sobre el desarrollo m√≥vil en CFT</a></li>
<li><a href="../454644/index.html">Entrenamiento Cisco 200-125 CCNA v3.0. D√≠a 8. Configuraci√≥n del interruptor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👏🏼 🔹 🎋 Teori Tempat Pembuangan Akhir Besar: Kami mencari dokumen ilmiah di Internet 🚴 🍷 👩🏼‍🍳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sistem Anti-Plagiarisme adalah mesin pencari khusus. Seperti layaknya mesin pencari, dengan mesin sendiri dan indeks pencarian. Indeks terbesar kami d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Teori Tempat Pembuangan Akhir Besar: Kami mencari dokumen ilmiah di Internet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/antiplagiat/blog/413361/"> Sistem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Anti-Plagiarisme</a> adalah mesin pencari khusus.  Seperti layaknya mesin pencari, dengan mesin sendiri dan indeks pencarian.  Indeks terbesar kami dalam hal jumlah sumber, tentu saja, di Internet berbahasa Rusia.  Sudah lama sekali, kami memutuskan bahwa kami akan memasukkan ke dalam indeks ini semua yang berupa teks (dan bukan gambar, musik atau video), ditulis dalam bahasa Rusia, memiliki ukuran lebih besar dari 1 kb dan bukan "hampir duplikat" dari sesuatu yang sudah ada dalam indeks. <br><br>  Pendekatan ini baik karena tidak memerlukan pra-pemrosesan yang rumit dan meminimalkan risiko “percikan air anak” - melewatkan dokumen yang berpotensi dipinjam teks.  Di sisi lain, sebagai hasilnya, kita hanya tahu sedikit dokumen mana yang akhirnya ada dalam indeks. <br><br>  Ketika indeks Internet tumbuh - dan sekarang, untuk sesaat, ini sudah lebih dari 300 juta dokumen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hanya dalam bahasa Rusia</a> - muncul pertanyaan yang sangat alami: apakah benar-benar ada banyak dokumen berguna dalam dump ini. <br><br>  Dan karena kita ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">yury_chekhovich</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">Andrey_Khazov</a> ) mengambil refleksi ini, lalu mengapa kita tidak sekaligus menjawab beberapa pertanyaan lagi.  Berapa banyak dokumen ilmiah yang diindeks, dan berapa banyak yang tidak ilmiah?  Apa bagian dari artikel ilmiah di antara diploma, artikel, abstrak?  Apa distribusi dokumen berdasarkan subjek? <br><br><img src="https://habrastorage.org/webt/og/m9/ef/ogm9efltmzqiefr26gpoxiugv98.jpeg"><br><br>  Karena kita berbicara tentang ratusan juta dokumen, maka perlu menggunakan sarana analisis data otomatis, khususnya, teknologi pembelajaran mesin.  Tentu saja, dalam kebanyakan kasus, kualitas evaluasi ahli lebih unggul daripada metode mesin, tetapi akan terlalu mahal untuk menarik sumber daya manusia untuk menyelesaikan tugas yang begitu luas. <br><a name="habracut"></a><cut text=" "></cut><br>  Jadi, kita perlu menyelesaikan dua masalah: <br><br><ol><li>  Buat filter "ilmiah", yang, di satu sisi, memungkinkan Anda untuk secara otomatis membuang dokumen yang tidak ada dalam struktur dan konten, dan di sisi lain menentukan jenis dokumen ilmiah.  Segera buat reservasi yang di bawah "ilmiah" sama sekali tidak mengacu pada signifikansi ilmiah atau keandalan hasil.  Tugas filter adalah memisahkan dokumen yang berbentuk artikel ilmiah, disertasi, diploma, dll.  dari jenis teks lain, yaitu fiksi, artikel jurnalistik, artikel berita, dll. </li><li>  Menerapkan suatu alat untuk menggulung dokumen ilmiah yang menghubungkan dokumen dengan salah satu spesialisasi ilmiah (misalnya, <i>Fisika dan Matematika</i> , <i>Ekonomi</i> , <i>Arsitektur</i> , <i>Studi Budaya</i> , dll.). </li></ol><br>  Pada saat yang sama, kita perlu menyelesaikan masalah ini dengan bekerja secara eksklusif dengan dukungan tekstual dokumen, tidak menggunakan metadata mereka, informasi tentang lokasi blok teks dan gambar di dalam dokumen. <br><br>  Mari kita ilustrasikan dengan sebuah contoh.  Pandangan sekilas saja sudah cukup untuk membedakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel ilmiah</a> <br><br><img src="https://habrastorage.org/webt/li/wp/hd/liwphdvcupd3taujfkjmnjupbvc.png"><br><br>  dari, misalnya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dongeng anak-anak</a> . <br><br><img src="https://habrastorage.org/webt/ul/gl/px/ulglpxn_8qvajxqn769_mzyshik.png"><br><br>  Tetapi jika hanya ada lapisan teks (untuk contoh yang sama), Anda harus membaca kontennya. <br><br><h2>  Filter ilmiah dan penyortiran berdasarkan jenis </h2><br>  Kami menyelesaikan tugas secara berurutan: <br><br><ol><li>  Pada tahap pertama, kami memfilter dokumen non-ilmiah; </li><li>  Pada tahap kedua, semua dokumen yang telah diidentifikasi sebagai ilmiah, diklasifikasikan berdasarkan jenis: artikel, disertasi kandidat, abstrak doktoral, diploma, dll. <br></li></ol><br>  Itu terlihat seperti ini: <br><br><img src="https://habrastorage.org/webt/3p/tq/vn/3ptqvnuhjai6nsvi8sgcjqmzdle.jpeg"><br><br>  Jenis khusus (tidak terdefinisi) ditugaskan untuk dokumen yang tidak dapat secara andal dikaitkan dengan salah satu jenis (ini terutama dokumen pendek - halaman situs ilmiah, abstrak abstrak).  Misalnya, publikasi ini akan dikaitkan dengan jenis ini, yang memiliki beberapa tanda keilmuan, tetapi tidak mirip dengan yang di atas. <br><br>  Ada keadaan lain yang harus diperhitungkan.  Ini adalah algoritma dengan kecepatan tinggi dan kebutuhan sumber daya yang rendah - namun, tugas kami adalah tambahan.  Oleh karena itu, kami menggunakan deskripsi indikatif dokumen yang sangat kecil: <br><br><ul><li>  panjang rata-rata kalimat dalam sebuah teks; </li><li>  bagian dari kata-kata penghentian dalam kaitannya dengan semua kata dalam teks; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">indeks keterbacaan</a> ; </li><li>  persentase tanda baca dalam kaitannya dengan semua karakter teks; </li><li>  jumlah kata dari daftar ("abstrak", "disertasi", "diploma", "sertifikasi", "spesialisasi", "monograf", dll.) di bagian awal teks (atribut bertanggung jawab untuk halaman judul); </li><li>  jumlah kata dari daftar ("daftar", "literatur", "bibliografi", dll.) di bagian terakhir teks (atribut bertanggung jawab atas daftar literatur); </li><li>  proporsi huruf dalam teks; </li><li>  panjang kata rata-rata; </li><li>  jumlah kata unik dalam teks. </li></ul><br>  Semua tanda-tanda ini baik karena mereka cepat dihitung.  Sebagai pengklasifikasi, kami menggunakan algoritma hutan acak ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Random forest</a> ), metode klasifikasi populer dalam pembelajaran mesin. <br><br>  Dengan penilaian kualitas tanpa adanya sampel yang ditandai oleh para ahli, sulit, oleh karena itu kami membiarkan penggolong ke dalam koleksi artikel oleh perpustakaan elektronik ilmiah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Elibrary.ru</a> .  Kami berasumsi bahwa semua artikel akan diidentifikasi sebagai ilmiah. <br><br>  Hasil 100%?  Tidak ada yang sejenis - hanya 70%.  Mungkin kami membuat algoritma yang buruk?  Kami melihat-lihat artikel yang difilter.  Ternyata banyak teks tidak ilmiah diterbitkan dalam jurnal ilmiah: editorial, selamat atas peringatan, obituari, resep, dan bahkan horoskop.  Melihat secara selektif artikel-artikel yang dianggap sebagai klasifikasi ilmiah tidak mengungkapkan kesalahan, oleh karena itu, kami mengakui klasifikasi tersebut sesuai. <br><br>  Sekarang kita mengambil tugas kedua.  Di sini Anda tidak dapat melakukannya tanpa materi berkualitas untuk pelatihan.  Kami meminta penilai untuk menyiapkan sampel.  Kami mendapatkan sedikit lebih dari 3,5 ribu dokumen dengan distribusi berikut: <br><br><table><tbody><tr><th>  Jenis dokumen </th><th>  Jumlah dokumen dalam sampel </th></tr><tr><td>  Artikel </td><td>  679 </td></tr><tr><td>  Tesis PhD </td><td>  250 </td></tr><tr><td>  Abstrak tesis PhD </td><td>  714 </td></tr><tr><td>  Koleksi konferensi ilmiah </td><td>  75 </td></tr><tr><td>  Disertasi doktoral </td><td>  159 </td></tr><tr><td>  Abstrak disertasi doktoral </td><td>  189 </td></tr><tr><td>  Monograf </td><td>  107 </td></tr><tr><td>  Panduan belajar </td><td>  403 </td></tr><tr><td>  Tesis </td><td>  664 </td></tr><tr><td>  Jenis tidak terdefinisi </td><td>  514 </td></tr></tbody></table><br>  Untuk mengatasi masalah klasifikasi multi-kelas, kami menggunakan hutan Acak yang sama dan fitur yang sama agar tidak menghitung sesuatu yang istimewa. <br><br>  Kami mendapatkan kualitas klasifikasi berikut: <br><table><tbody><tr><th>  Akurasi </th><th>  Kelengkapan </th><th>  F-ukur </th></tr><tr><td>  81% </td><td>  76% </td><td>  79% </td></tr></tbody></table><br>  Hasil penerapan algoritma terlatih untuk data yang diindeks terlihat dalam diagram di bawah ini.  Gambar 1 menunjukkan bahwa lebih dari setengah koleksi terdiri dari dokumen ilmiah, dan di antaranya, lebih dari separuh dokumen adalah artikel. <br><img src="https://habrastorage.org/webt/tn/my/36/tnmy36llcqdqzkwno_ahauofyfu.png"><br>  <i>Fig.</i>  <i>1. Distribusi dokumen oleh "ilmiah"</i> <br><br>  Gambar 2 menunjukkan distribusi dokumen ilmiah berdasarkan tipe, kecuali tipe “artikel”.  Dapat dilihat bahwa jenis dokumen ilmiah kedua yang paling populer adalah buku teks, dan jenis yang paling langka adalah disertasi doktoral. <br><img src="https://habrastorage.org/webt/l4/bn/_x/l4bn_xekvubmhdcoucuc7rk1mrc.png"><br>  <i>Fig.</i>  <i>2. Distribusi dokumen ilmiah lainnya berdasarkan jenis</i> <br><br>  Secara umum, hasilnya sesuai dengan harapan.  Dari classifier "kasar" cepat kita tidak lagi membutuhkan. <br><br><h2>  Menentukan subjek suatu dokumen </h2><br>  Kebetulan bahwa pengelompokan karya ilmiah terpadu yang diakui secara universal belum dibuat.  Yang paling populer saat ini adalah judul <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VAK</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GRNTI</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">UDC</a> .  Untuk jaga-jaga, kami memutuskan untuk mengelompokkan dokumen secara tematis di bawah masing-masing kategori ini. <br><br>  Untuk membangun classifier tematik, kami menggunakan pendekatan berdasarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pemodelan topik</a> , cara statistik membangun model untuk kumpulan dokumen teks, di mana untuk setiap dokumen probabilitas milik topik tertentu ditentukan.  Sebagai alat untuk membangun model tematik, kami menggunakan perpustakaan terbuka <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">BigARTM</a> .  Kami telah menggunakan perpustakaan ini sebelumnya dan kami tahu itu sangat bagus untuk pemodelan tematik koleksi besar dokumen teks. <br><br>  Namun, ada satu kesulitan.  Dalam pemodelan tematik, menentukan komposisi dan struktur topik adalah hasil dari penyelesaian masalah pengoptimalan dalam kaitannya dengan kumpulan dokumen tertentu.  Kami tidak dapat memengaruhi mereka secara langsung.  Tentu saja, tema yang dihasilkan dari penyetelan ke koleksi kami tidak akan sesuai dengan salah satu pengklasifikasi target. <br><br>  Oleh karena itu, untuk mendapatkan nilai akhir yang tidak diketahui dari rubrik dokumen permintaan tertentu, kita perlu melakukan satu konversi lagi.  Untuk melakukan ini, di ruang topik BigARTM, menggunakan algoritma tetangga terdekat ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">k-NN</a> ), kami mencari beberapa dokumen yang paling mirip dengan kueri dengan rubrik yang dikenal, dan, berdasarkan ini, kami menetapkan kelas yang paling relevan untuk dokumen kueri. <br><br>  Dalam bentuk yang disederhanakan, algoritme ditunjukkan pada gambar: <br><br><img src="https://habrastorage.org/webt/3l/0c/45/3l0c453xctb7qh6ebu9fcxauuuo.jpeg"><br><br>  Untuk melatih model, kami menggunakan dokumen dari sumber terbuka, serta data yang disediakan oleh Elibrary.ru dengan spesialisasi terkenal dari Komisi Pengesahan Tinggi, SRSTI, UDC.  Kami menghapus dari dokumen koleksi yang terkait dengan posisi rubrik yang sangat umum, misalnya, <i>Masalah umum dan kompleks dari ilmu alam dan eksakta</i> , karena dokumen tersebut akan sangat mengganggu klasifikasi akhir. <br><br>  Koleksi terakhir berisi sekitar 280 ribu dokumen untuk pelatihan dan 6 ribu dokumen untuk pengujian untuk masing-masing rubrik. <br><br>  Untuk keperluan kita, cukup bagi kita untuk memprediksi nilai-nilai dari pos tingkat pertama.  Misalnya, untuk teks dengan nilai <i>GRNTI 27.27.24: Fungsi harmonik dan generalisasi mereka,</i> prediksi bagian <i>27: Matematika</i> benar. <br><br>  Untuk meningkatkan kualitas dari algoritma yang dikembangkan, kami menambahkan beberapa pendekatan berdasarkan classifier <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Naif Bayes</a> tua yang baik.  Sebagai tanda, ia menggunakan frekuensi kata-kata yang paling khas untuk setiap dokumen dengan nilai spesifik dari judul HAC. <br><br>  Kenapa begitu sulit?  Sebagai hasilnya, kami mengambil prediksi dari kedua algoritma, menimbangnya dan menghasilkan prediksi rata-rata untuk setiap permintaan.  Teknik ini dalam pembelajaran mesin disebut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ensembling</a> .  Pendekatan semacam itu memberi kita peningkatan kualitas yang nyata.  Misalnya, untuk spesifikasi SRSTI, akurasi algoritma asli adalah 73%, akurasi classifier naif Bayes adalah 65%, dan asosiasi mereka adalah 77%. <br><br>  Hasilnya, kami mendapatkan skema klasifikasi seperti itu: <br><br><img src="https://habrastorage.org/webt/33/t0/jc/33t0jc1fn4ldyizi6ea4lrbxfrg.jpeg"><br><br>  Kami mencatat dua faktor yang mempengaruhi hasil pengklasifikasi.  Pertama, dokumen apa pun dapat diberikan lebih dari satu nilai rubrik sekaligus.  Misalnya, nilai-nilai dari judul Komisi Pengesahan Tinggi 25.00.24 dan 08.00.14 ( <i>Ekonomi</i> , <i>sosial dan politik geografi</i> dan <i>ekonomi Dunia</i> ).  Dan itu tidak akan menjadi kesalahan. <br><br>  Kedua, dalam praktiknya, nilai-nilai rubrik ditempatkan secara ahli, yaitu secara subjektif.  Contoh yang mencolok adalah topik yang tampaknya berbeda seperti <i>Teknik Mesin</i> dan <i>Pertanian dan Kehutanan</i> .  Algoritme kami mengklasifikasikan artikel dengan judul <i>"Mesin untuk menipiskan hutan"</i> dan <i>"Prasyarat untuk pengembangan serangkaian traktor berukuran standar untuk kondisi zona barat laut"</i> untuk teknik mesin, dan sesuai dengan tata letak aslinya, mereka merujuk tepatnya ke pertanian. <br><br>  Oleh karena itu, kami memutuskan untuk menampilkan 3 nilai teratas yang paling mungkin dari masing-masing kategori.  Misalnya, untuk artikel <i>"Toleransi guru profesional (pada contoh aktivitas seorang guru Rusia di sekolah multietnis)",</i> probabilitas nilai-nilai dari judul Komisi Pengesahan Tinggi didistribusikan sebagai berikut: <br><table><tbody><tr><th>  Nilai rubrikator </th><th>  Kemungkinan </th></tr><tr><td>  Ilmu pedagogis </td><td>  47% </td></tr><tr><td>  Ilmu-ilmu psikologi </td><td>  33% </td></tr><tr><td>  Ilmu budaya </td><td>  20% </td></tr></tbody></table><br>  Keakuratan algoritma yang dihasilkan adalah: <br><table><tbody><tr><th>  Rubrikator </th><th>  3 akurasi teratas </th></tr><tr><td>  SRSTI </td><td>  93% </td></tr><tr><td>  VAK </td><td>  92% </td></tr><tr><td>  UDC </td><td>  94% </td></tr></tbody></table><br>  Diagram menunjukkan hasil studi tentang distribusi topik dokumen dalam indeks Internet berbahasa Rusia untuk semua (Gambar 3) dan hanya untuk dokumen ilmiah (Gambar 4).  Dapat dilihat bahwa sebagian besar dokumen berkaitan dengan humaniora: spesifikasi yang paling sering adalah ekonomi, hukum dan pedagogi.  Selain itu, di antara hanya dokumen ilmiah, bagiannya bahkan lebih besar. <br><img src="https://habrastorage.org/webt/fc/xl/l0/fcxll06ddsd3yp2pcchsjh6pu5u.png"><br>  <i>Fig.</i>  <i>3. Distribusi topik di seluruh modul pencarian</i> <br><img src="https://habrastorage.org/webt/s5/-j/rj/s5-jrj9xrnomex9beptlulpvzcc.png"><br>  <i>Fig.</i>  <i>4. Distribusi topik dokumen ilmiah.</i> <br><br>  Sebagai hasilnya, kami benar-benar dari materi yang ada tidak hanya mempelajari struktur tematik dari Internet yang diindeks, tetapi juga membuat fungsionalitas tambahan yang dengannya Anda dapat "mengklasifikasikan" sebuah artikel atau dokumen ilmiah lainnya ke dalam tiga kategori tematis sekaligus. <br><br><img src="https://habrastorage.org/webt/yp/nq/ym/ypnqymmhrajkxuu-jqrbk1tpjq0.png"><br><br>  Fungsi yang dijelaskan di atas sekarang sedang aktif diimplementasikan dalam sistem Anti-Plagiarisme dan akan segera tersedia untuk pengguna. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id413361/">https://habr.com/ru/post/id413361/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id413349/index.html">Metrik Google Analytics apa yang memicu keputusan buruk</a></li>
<li><a href="../id413351/index.html">Tentang orang, monster - dan pemodelan tematik</a></li>
<li><a href="../id413353/index.html">Rocker - driver rockdb untuk Erlang</a></li>
<li><a href="../id413357/index.html">Pertama-tama lihat smartphone gaming ASUS ROG Phone</a></li>
<li><a href="../id413359/index.html">Windows 10 IoT Enterprise - Rahasia Konfigurasi untuk Skrip Tertanam</a></li>
<li><a href="../id413363/index.html">Pengrajin memasang telefoto Canon EF 70-200 mm ke kamera Game Boy</a></li>
<li><a href="../id413367/index.html">Apa itu gelembung hidrokarbon global? Hasil simulasi pasar energi hingga 2050 g</a></li>
<li><a href="../id413371/index.html">Mobil listrik</a></li>
<li><a href="../id413375/index.html">Apakah mungkin untuk berteman Gitlab CI + Docker + Systemd</a></li>
<li><a href="../id413377/index.html">Angstrom-T: kronologi proyek dan mega-order</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßôüèΩ üë∞üèª üë®üèø‚Äçüíª Impala vs Hive vs Spark SQL: Escolhendo o mecanismo SQL certo para funcionar corretamente no Cloudera Data Warehouse üèáüèª üïµüèΩ üåì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sempre nos faltam dados. E n√£o queremos apenas mais dados ... queremos novos tipos de dados que nos permitam entender melhor nossos produtos, clientes...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Impala vs Hive vs Spark SQL: Escolhendo o mecanismo SQL certo para funcionar corretamente no Cloudera Data Warehouse</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/486124/"><img src="https://habrastorage.org/webt/bu/1w/sb/bu1wsbowqiicmki0x1nqsraewjw.jpeg"><br><br>  Sempre nos faltam dados.  E n√£o queremos apenas mais dados ... queremos novos tipos de dados que nos permitam entender melhor nossos produtos, clientes e mercados.  Estamos sempre em busca de novos dados, dados de todas as formas e tamanhos, estruturados e n√£o muito.  Queremos abrir nossas portas para uma nova gera√ß√£o de profissionais de neg√≥cios e especialistas t√©cnicos que abrir√£o entusiasticamente novos bancos de dados e tecnologias conosco, que posteriormente mudar√£o a natureza de como interagimos com os dados e o impacto que eles t√™m em nossas vidas. <br><a name="habracut"></a><br>  Vou dar um exemplo de vida para que voc√™ entenda melhor o que quero dizer.  Cerca de dois anos atr√°s, os dados salvaram a vida da filha de meu amigo.  Quando ela nasceu, ela foi diagnosticada com sete defeitos card√≠acos.  Gra√ßas a novas tecnologias, como gr√°ficos 3D interativos, modelagem virtual, an√°lises ECG mais inteligentes, solu√ß√µes modernas para monitorar pacientes em repouso no leito e gra√ßas a outros procedimentos m√©dicos avan√ßados baseados em dados, ela conseguiu sobreviver a duas cirurgias card√≠acas abertas e agora vive uma vida saud√°vel .  Os dados salvaram sua vida.  √â isso que me impulsiona todos os dias a procurar novas solu√ß√µes inovadoras e maneiras de transferir dados mais rapidamente para aqueles que precisam mais do que outros. <br><br>  Tenho orgulho de fazer parte da equipe do Cloudera Data Warehouse (CDW), desenvolvida pela Cloudera Data Platform (CDP).  O CDP foi criado do zero como uma nuvem de dados corporativos ou Enterprise Data Cloud (EDC).  O EDC √© uma ferramenta multifuncional para implementar muitas tarefas em uma plataforma.  Gra√ßas ao uso de sistemas h√≠bridos e com v√°rias nuvens, o CDP pode funcionar em qualquer lugar - em uma plataforma sem sistema operacional e em uma nuvem p√∫blica e privada.  √Ä medida que mais solu√ß√µes em nuvem s√£o introduzidas como parte de nosso plano de desenvolvimento digital, vemos solu√ß√µes h√≠bridas e com v√°rias nuvens se tornando a nova norma.  No entanto, essas solu√ß√µes combinadas criam problemas para gerenci√°-las, o que, por sua vez, cria novos riscos de seguran√ßa, a probabilidade de vigil√¢ncia do usu√°rio e, posteriormente, uma viola√ß√£o da lei.  Para resolver esses problemas, o CDP possui recursos avan√ßados de seguran√ßa e controle que abrir√£o o acesso aos dados sem arriscar violar a pol√≠tica de seguran√ßa de ningu√©m ou mesmo a lei. <br><br>  O CDW no CDP √© um novo servi√ßo que permite criar um data warehouse de autoatendimento para equipes de an√°lise de BI.  Voc√™ pode criar rapidamente novos data warehouses e us√°-los voc√™ mesmo, ou dar acesso a um grupo de pessoas e usar um √∫nico banco de dados com eles.  Voc√™ se lembra dos momentos em que podia gerenciar seu armaz√©m de dados por conta pr√≥pria?  Gerenciar sem a participa√ß√£o de plataformas e a infraestrutura necess√°ria para sua opera√ß√£o?  Isso nunca aconteceu antes.  O CDW tornou isso poss√≠vel. <br><br>  Gra√ßas ao CDW, v√°rios mecanismos SQL foram disponibilizados, mas a confus√£o vem com √≥timas op√ß√µes.  Vamos examinar os mecanismos SQL dispon√≠veis no CDW no CDP e discutir qual op√ß√£o SQL √© mais adequada para uma tarefa espec√≠fica. <br><br>  Uma √≥tima escolha!  Impala?  Colmeia LLAP?  Spark?  O que usar e quando?  Vamos descobrir. <br><br><h2>  Impala sql engine </h2><br>  O Impala √© um popular mecanismo MPP de c√≥digo aberto com uma ampla variedade de recursos no Cloudera Distribution Hadoop (CDH) e CDP.  A Impala ganhou confian√ßa no mercado com suas consultas SQL altamente interativas e de baixa lat√™ncia.  Os recursos do Impala s√£o muito amplos, o Impala n√£o apenas suporta o Sistema de Arquivos Distribu√≠dos Hadoop (HDFS - Sistema de Arquivos Distribu√≠dos Hadoop) com Parquet, Colunas de Linhas Otimizadas (ORC - N√≥ de Armazenamento Otimizado), Nota√ß√£o de Objetos JavaScript (JSON), Avro e formatos de texto, mas tamb√©m possui suporte interno para Kudu, ADLS (Data Lake Storage) do Microsoft Azure e Amazon Simple Storage Service (S3).  O Impala tem um alto n√≠vel de seguran√ßa usando sentinela ou guarda florestal e, como voc√™ sabe, pode oferecer suporte a milhares de usu√°rios com clusters de centenas de n√≥s em conjuntos de dados com v√°rios petabytes.  Vejamos a arquitetura geral do Impala. <br><br><img src="https://habrastorage.org/webt/on/f3/uk/onf3ukvs8cr_4lorbm6tkholx9c.png"><br><br>  A Impala usa o StateStore para verificar a integridade do cluster.  Se, por algum motivo, o n√≥ Impala ficar offline, o StateStore enviar√° uma mensagem sobre isso para todos os n√≥s e pular√° o n√≥ inacess√≠vel.  O Impala Directory Service gerencia metadados para todas as instru√ß√µes SQL de todos os n√≥s no cluster.  O StateStore e o servi√ßo de diret√≥rio trocam dados com o Hive MetaStore para armazenar blocos e arquivos e depois transferir os metadados para os n√≥s de trabalho.  Quando uma solicita√ß√£o chega, ela √© passada para um dos muitos programas correspondentes em que a compila√ß√£o √© executada e o planejamento iniciado.  Fragmentos do plano s√£o devolvidos e o programa de coordena√ß√£o organiza sua implementa√ß√£o.  Os resultados intermedi√°rios s√£o passados ‚Äã‚Äãentre os servi√ßos Impala e retornados. <br><br>  Essa arquitetura √© ideal para casos em que precisamos de data marts para business intelligence para receber respostas para consultas com baixa lat√™ncia, como geralmente ocorre nos tipos ad-hoc, de autoatendimento e de descoberta.  Nesse cen√°rio, temos clientes nos dizendo respostas para consultas complexas de menos de um segundo a cinco segundos. <br><br>  Para dados da Internet das Coisas (IoT) e cen√°rios relacionados, a Impala, juntamente com solu√ß√µes de streaming como NiFi, Kafka ou Spark Streaming e data warehouses relacionados como Kudu, pode fornecer pipelining cont√≠nuo com um tempo de atraso de menos de dez segundos .  Com recursos de leitura / grava√ß√£o integrados no S3, ADLS, HDFS, Hive, HBase e mais, o Impala √© um excelente mecanismo SQL a ser usado ao iniciar um cluster de at√© 1000 n√≥s e mais de 100 trilh√µes de linhas em tabelas ou conjuntos de dados de 50BP ou mais. <br><br><h2>  Hive LLAP </h2><br>  O Live Long And Process, ou Long Delay Analytics Processing, tamb√©m conhecido como LLAP, √© um mecanismo de execu√ß√£o baseado em Hive que suporta processos de longa execu√ß√£o usando os mesmos recursos de armazenamento em cache e processamento.  Esse mecanismo de processamento nos fornece uma resposta do SQL com uma lat√™ncia muito baixa, pois n√£o temos tempo para iniciar os recursos solicitados. <br><br><img src="https://habrastorage.org/webt/pq/uw/fc/pquwfcyzx5gn55c8d8k1otqvica.png"><br><br>  Al√©m disso, o LLAP fornece e estabelece controle sobre a execu√ß√£o das pol√≠ticas de seguran√ßa, para que todo o trabalho do LLAP seja transparente, o que ajuda a Hive a competir em termos de desempenho da carga de trabalho, mesmo com a m√≠dia de armazenamento mais popular e tradicionalmente usada atualmente. <br><br>  O Hive LLAP oferece o mecanismo SQL mais avan√ßado no ecossistema de big data.  O Hive LLAP foi criado para uma enorme quantidade de dados, fornecendo aos usu√°rios os amplos recursos do Enterprise Data Warehouse (EDW), que suporta a convers√£o de grandes volumes de dados, a execu√ß√£o de consultas longas ou consultas SQL pesadas com centenas de jun√ß√µes.  O Hive suporta visualiza√ß√µes materializadas, chaves substitutas e v√°rias restri√ß√µes semelhantes aos sistemas tradicionais de gerenciamento de banco de dados relacional, incluindo cache interno para consulta de resultados e consulta de dados.  O Hive LLAP pode reduzir a carga de solicita√ß√µes repetidas, reduzindo o tempo de resposta para uma fra√ß√£o de segundo.  O Hive LLAP pode suportar solicita√ß√µes federadas para HDFS (Hadoop Distributed File System) e armazenamentos de objetos, bem como streaming em tempo real, trabalhando com Kafka e Druid. <br><br>  Assim, o Hive LLAP √© ideal como uma solu√ß√£o Enterprise Data Warehouse (EDW), na qual enfrentaremos um grande n√∫mero de consultas longas que exigem grandes transforma√ß√µes ou jun√ß√µes m√∫ltiplas entre tabelas e grandes conjuntos de dados.  Gra√ßas √† tecnologia de cache inclu√≠da no Hive LLAP, agora temos clientes que podem ingressar em 330 bilh√µes de registros com 92 bilh√µes de outros registros com ou sem chave de parti√ß√£o e obter resultados em segundos. <br><br><h2>  Spark sq </h2><br><br>  O Spark √© um mecanismo de processamento de dados de alto desempenho e uso geral que suporta o processamento e a distribui√ß√£o de dados e possui uma ampla variedade de aplicativos.  Existem muitas bibliotecas de dados Spark para especialistas em ci√™ncia de dados e aprendizado de m√°quina que suportam o modelo de programa√ß√£o de n√≠vel superior para desenvolvimento r√°pido.  Parentemente acima do Spark est√£o o Spark SQL, o MLlib, o Spark Streaming e o GrapX. <br><br><img src="https://habrastorage.org/webt/u2/2n/gh/u22nghp80uvyrlof4kwul2pzmgu.png"><br><br>  O Spark SQL √© um m√≥dulo para processamento de dados estruturado, compat√≠vel com v√°rias fontes de dados, com suporte para Hive, Avro, Parquet, ORC, JSON e JDBC.  O Spark SQL √© eficiente em conjuntos de dados semiestruturados e integra-se aos reposit√≥rios Hive MetaStore e NoSQL, como o HBase.  O Spark √© frequentemente usado com v√°rias APIs de software em nossas linguagens de programa√ß√£o favoritas, como Java, Python, R e Scala. <br><br>  O Spark pode ser muito √∫til se voc√™ precisar incorporar consultas SQL aos programas Spark, se funcionar com grandes quantidades de dados e alta carga.  O Spark ajuda muitos de nossos usu√°rios que trabalham nas empresas da Global 100 a reduzir o processamento de dados de streaming.  Combinando isso com o MLlib, vemos quantos de nossos clientes respondem positivamente ao Spark como um excelente sistema de aprendizado de m√°quina ao trabalhar com aplicativos de data warehouse.  Com alto desempenho, baixa lat√™ncia e excelente integra√ß√£o de ferramentas de terceiros, o Spark SQL fornece as melhores condi√ß√µes para alternar entre programa√ß√£o e SQL. <br><br><h3>  Ent√£o, qual mecanismo SQL usar? </h3><br><br>  Como voc√™ pode combinar os mesmos dados no CDW para CDP, voc√™ pode escolher o mecanismo certo para cada tipo de carga de trabalho, como engenharia de dados, EDW tradicional, an√°lise ad hoc, pain√©is de BI, Online Analytical Processing (OLAP) ou Online Processamento de transa√ß√µes (OLTP).  O diagrama abaixo mostra alguns princ√≠pios que visam simplificar a sele√ß√£o, segundo os quais os mecanismos e seus mecanismos s√£o adequados para cada uma das metas estabelecidas. <br><br><img src="https://habrastorage.org/webt/xw/st/ff/xwstffkvxlp9ubso_swhiinvdda.png"><br><br><h2>  Conclus√£o </h2><br>  Se voc√™ usa EDW com suporte a pain√©is de BI, o Hive LLAP fornecer√° os melhores resultados.  Quando precisar de armazenamento de dados ad-hoc, de autoatendimento e de pesquisa, volte os olhos para os benef√≠cios do Impala.  Se voc√™ observar a Engenharia de dados com consultas de longa execu√ß√£o e sem alta simultaneidade, o Spark SQL √© uma √≥tima op√ß√£o.  Se voc√™ precisar de suporte de alta simultaneidade, consulte o Hive on Tez.  Procure suporte OLAP com dados de s√©ries temporais, adicione Druid e, se voc√™ estiver procurando por OLTP com baixa lat√™ncia e alta simultaneidade, talvez seja necess√°rio adicionar o Phoenix. <br><br>  Total - existem muitos mecanismos SQL no CDW para CDP, e isso √© feito de prop√≥sito.  Fazer escolhas antes de tomar uma decis√£o √© a melhor maneira de otimizar processos para aplicativos de alto desempenho com processamento multiencadeado em grandes data warehouses.  O CDW no CDP fornece compartilhamento e compartilhamento de dados em um √∫nico sistema de seguran√ßa, gerenciamento, rastreamento de dados e metadados, o que permite combinar componentes SQL em reposit√≥rios otimizados.  Assim, isso d√° ao usu√°rio a liberdade de escolher o melhor mecanismo SQL, dependendo de suas cargas de trabalho. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt486124/">https://habr.com/ru/post/pt486124/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt486106/index.html">Luz de fundo adapt√°vel para TV Raspberry Pi - Ambilight Analog</a></li>
<li><a href="../pt486114/index.html">Os principais cientistas do campo da neuroci√™ncia se reunir√£o no congresso anual do sindicato da ind√∫stria de neuronets</a></li>
<li><a href="../pt486116/index.html">Testes de simplicidade de Fermat e Miller-Rabin</a></li>
<li><a href="../pt486120/index.html">Normaliza√ß√£o do desvio. Como pr√°ticas erradas est√£o se tornando a norma em nossa ind√∫stria</a></li>
<li><a href="../pt486122/index.html">Child ReactJS com 135 linhas de c√≥digo</a></li>
<li><a href="../pt486128/index.html">Arquiteto de solu√ß√µes de teste: quem √© e quando √© necess√°rio</a></li>
<li><a href="../pt486144/index.html">Por que altcoins morrem e o que pode acontecer com a criptomoeda em um futuro pr√≥ximo?</a></li>
<li><a href="../pt486150/index.html">Desenvolvimento da esfera de TI na Eslov√°quia. Benef√≠cios de trabalho para jovens profissionais</a></li>
<li><a href="../pt486156/index.html">Como eu ensinei, e depois escrevi um manual de treinamento em Python</a></li>
<li><a href="../pt486158/index.html">Visualiza√ß√£o da tradu√ß√£o autom√°tica neural (modelos seq2seq com mecanismo de aten√ß√£o)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
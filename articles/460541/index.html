<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî° üë®‚Äçüëß ü§±üèª Busque contornos faciales en un milisegundo usando un conjunto de √°rboles de regresi√≥n üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø üë¥üèø üôå</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Se prepar√≥ la traducci√≥n del art√≠culo para los estudiantes del curso "Matem√°ticas para la ciencia de datos" 

 Anotaci√≥n 


 Este art√≠culo analiza la ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Busque contornos faciales en un milisegundo usando un conjunto de √°rboles de regresi√≥n</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/460541/"><p><img src="https://habrastorage.org/webt/eb/rn/3a/ebrn3a_ugfcxc9tuhkdmwgnrut8.png"></p><br><p>  <em>Se prepar√≥ la traducci√≥n del art√≠culo para los estudiantes del curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Matem√°ticas para la ciencia de datos"</a></em> </p><br><hr><br><h1 id="annotaciya">  Anotaci√≥n </h1><br><p>  <em>Este art√≠culo analiza la tarea de encontrar contornos faciales para una sola imagen.</em>  <em>Mostramos c√≥mo se puede usar el conjunto de √°rboles de regresi√≥n para predecir la posici√≥n de los contornos faciales directamente desde un subconjunto disperso de intensidades de p√≠xeles, logrando un superrendimiento en tiempo real con predicciones de alta calidad.</em>  <em>Presentamos una estructura general basada en el aumento de gradiente para estudiar un conjunto de √°rboles de regresi√≥n que optimiza la suma de las p√©rdidas cuadr√°ticas y, naturalmente, procesa datos faltantes o parcialmente etiquetados.</em>  <em>Mostraremos c√≥mo el uso de distribuciones apropiadas que tienen en cuenta la estructura de los datos de la imagen ayuda en la selecci√≥n eficiente de contornos.</em>  <em>Tambi√©n se est√°n investigando diversas estrategias de regularizaci√≥n y su importancia en la lucha contra el reciclaje.</em>  <em>Adem√°s, analizamos el efecto de la cantidad de datos de entrenamiento sobre la precisi√≥n de los pron√≥sticos y examinamos el efecto de aumentar los datos utilizando datos sintetizados.</em> <a name="habracut"></a></p><br><h1 id="1-vvedenie">  1. Introducci√≥n </h1><br><p>  En este art√≠culo, presentamos un nuevo algoritmo que busca contornos faciales en milisegundos y logra una precisi√≥n superior o comparable a los m√©todos modernos en conjuntos de datos est√°ndar.  El aumento de la velocidad en comparaci√≥n con los m√©todos anteriores es una consecuencia de la identificaci√≥n de los componentes principales de los algoritmos anteriores para la b√∫squeda de contornos faciales y su posterior inclusi√≥n en una forma optimizada en la cascada de modelos de regresi√≥n con gran ancho de banda, ajustados mediante el aumento de gradiente. </p><br><p>  Demostramos, como ya lo hicimos antes [8, 2], que la b√∫squeda de contornos faciales se puede llevar a cabo utilizando una cascada de modelos de regresi√≥n.  En nuestro caso, cada modelo de regresi√≥n en la cascada predice efectivamente la forma de la cara seg√∫n el pron√≥stico inicial y la intensidad del escaso conjunto de p√≠xeles indexados en relaci√≥n con este pron√≥stico inicial.  Nuestro trabajo se basa en una gran cantidad de estudios realizados durante la √∫ltima d√©cada, que han llevado a un progreso significativo en la tarea de encontrar contornos faciales [9, 4, 13, 7, 15, 1, 16, 18, 3, 6, 19].  En particular, hemos incluido en nuestros modelos de regresi√≥n ajustados dos elementos clave que est√°n presentes en varios de los algoritmos exitosos a continuaci√≥n, y ahora detallamos estos elementos. </p><br><p><img src="https://habrastorage.org/webt/xe/fn/ux/xefnuxzvuozcmpu5xjzvwwm3kq4.png"></p><br><p>  <em>Figura 1. Resultados seleccionados en el conjunto de datos HELEN.</em>  <em>Para detectar 194 puntos clave (puntos de referencia) en la cara en una imagen en un milisegundo, se utiliza un conjunto de √°rboles de regresi√≥n aleatoria.</em> </p><br><p>  El primero gira en torno a la indexaci√≥n de la intensidad de p√≠xeles en relaci√≥n con el pron√≥stico actual de la forma de la cara.  Las caracter√≠sticas distinguidas en la representaci√≥n vectorial de la imagen de la cara pueden variar mucho debido a la deformaci√≥n de la forma y debido a factores interferentes como los cambios en las condiciones de iluminaci√≥n.  Esto hace que sea dif√≠cil predecir con precisi√≥n la forma usando estas funciones.  El dilema es que necesitamos signos confiables para predecir con precisi√≥n la forma y, por otro lado, necesitamos un pron√≥stico preciso de la forma para extraer signos confiables.  En el trabajo anterior [4, 9, 5, 8], as√≠ como en este trabajo, se utiliza un enfoque iterativo (cascada) para resolver este problema.  En lugar de retroceder los par√°metros de forma en funci√≥n de las caracter√≠sticas extra√≠das en el sistema de coordenadas de imagen global, la imagen se convierte en un sistema de coordenadas normalizado en funci√≥n del pron√≥stico de forma actual, y luego se extraen signos para predecir el vector de actualizaci√≥n para los par√°metros de forma.  Este proceso generalmente se repite varias veces hasta la convergencia. </p><br><p>  El segundo examina c√≥mo lidiar con la complejidad del problema de explicaci√≥n / predicci√≥n.  Durante las pruebas, el algoritmo de b√∫squeda de contornos debe predecir la forma de la cara, un vector de alta dimensi√≥n que est√° en el mejor acuerdo con los datos de imagen y nuestro modelo de forma.  El problema no es convexo con muchos √≥ptimos locales.  Los algoritmos exitosos [4, 9] resuelven este problema, suponiendo que la forma predicha debe estar en un subespacio lineal que puede detectarse, por ejemplo, al encontrar los componentes principales de las formas de entrenamiento.  Esta suposici√≥n reduce significativamente el n√∫mero de formas potenciales consideradas durante la explicaci√≥n y puede ayudar a evitar los √≥ptimos locales. </p><br><p>  Un trabajo reciente [8, 11, 2] explota el hecho de que una cierta clase de regresores est√° garantizada para crear predicciones que se encuentran en el subespacio lineal definido por las formas de aprendizaje, y no hay necesidad de restricciones adicionales.  Es importante que nuestros modelos de regresi√≥n tengan estos dos elementos. <br>  Estos dos factores est√°n asociados con nuestro entrenamiento efectivo en el modelo de regresi√≥n.  Optimizamos la funci√≥n de p√©rdida correspondiente y realizamos la selecci√≥n de caracter√≠sticas en funci√≥n de los datos.  En particular, entrenamos a cada regresor usando el aumento de gradiente [10] usando la funci√≥n de p√©rdida cuadr√°tica, la misma funci√≥n de p√©rdida que queremos minimizar durante la prueba.  El conjunto de p√≠xeles dispersos utilizados como entrada para el regresor se selecciona usando una combinaci√≥n del algoritmo de aumento de gradiente y la probabilidad a priori de las distancias entre pares de p√≠xeles de entrada.  La distribuci√≥n a priori permite que el algoritmo de refuerzo investigue eficientemente una gran cantidad de caracter√≠sticas relevantes.  El resultado es una cascada de regresores que pueden localizar puntos de referencia faciales cuando se inicializan desde el frente. </p><br><p>  Las principales contribuciones de este art√≠culo son: </p><br><ol><li>  Un nuevo m√©todo para encontrar contornos faciales, basado en un conjunto de √°rboles de regresi√≥n (√°rboles de decisi√≥n), que realiza la selecci√≥n de caracter√≠sticas invariantes de la forma, mientras minimiza la misma funci√≥n de p√©rdida durante el entrenamiento que queremos minimizar durante las pruebas. </li><li>  Presentamos una extensi√≥n natural de nuestro m√©todo que procesa etiquetas faltantes o indefinidas. </li><li>  Se presentan resultados cuantitativos y cualitativos, que confirman que nuestro m√©todo ofrece pron√≥sticos de alta calidad, siendo mucho m√°s efectivo que el mejor m√©todo anterior (Figura 1). </li><li>  Se analiza la influencia de la cantidad de datos de entrenamiento, el uso de datos parcialmente etiquetados y datos generalizados sobre la calidad de los pron√≥sticos. </li></ol><br><h1 id="2-metod">  2. M√©todo </h1><br><p>  Este art√≠culo presenta un algoritmo para evaluar con precisi√≥n la posici√≥n de los puntos de referencia faciales (puntos clave) en t√©rminos de eficiencia computacional.  Como en trabajos anteriores [8, 2], la cascada de regresores se utiliza en nuestro m√©todo.  En el resto de esta secci√≥n, describimos los detalles de la forma de los componentes individuales de la cascada y c√≥mo llevamos a cabo el entrenamiento. </p><br><h4 id="21-kaskad-regressorov">  2.1.  Cascada de regresi√≥n </h4><br><p>  Primero presentamos alguna notaci√≥n.  Dejar <img src="https://habrastorage.org/getpro/habr/post_images/96b/8a8/cd3/96b8a8cd39c5f39cf67191c499d17a36.svg">  , coordenadas y del hito n√∫mero i de la cara en la imagen I. Luego el vector <img src="https://habrastorage.org/getpro/habr/post_images/bd9/f10/315/bd9f10315460922e284cfe03581f1e91.svg">  denota las coordenadas de todas las caras p en I. A menudo en este art√≠culo llamamos al vector S una forma.  Nosotros usamos <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  para indicar nuestra calificaci√≥n actual S. Cada regresor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  (¬∑, ¬∑) En la cascada predice el vector de actualizaci√≥n de la imagen y <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  que se agrega a la evaluaci√≥n del formulario actual <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  Para mejorar la calificaci√≥n: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/813/e90/80c/813e9080c1daa94987bfd323fcf05d75.svg">  ) <em>(1)</em> </p><br><p>  El punto clave de la cascada es que el regresor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  hace sus pron√≥sticos basados ‚Äã‚Äãen atributos tales como intensidades de p√≠xeles calculados por I e indexados en relaci√≥n con la estimaci√≥n de forma actual <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  .  Esto introduce alg√∫n tipo de invariancia geom√©trica en el proceso, y a medida que avanza por la cascada, puede estar m√°s seguro de que la ubicaci√≥n sem√°ntica exacta en la cara est√° indexada.  M√°s adelante describiremos c√≥mo se realiza esta indexaci√≥n. </p><br><p>  Tenga en cuenta que el rango de salida extendido por el conjunto est√° garantizado en el subespacio lineal de los datos de entrenamiento si la estimaci√≥n inicial <img src="https://habrastorage.org/getpro/habr/post_images/f0d/6ae/457/f0d6ae4573955eb6abc901db0a68bc4a.svg">  Pertenece a este espacio.  Por lo tanto, no necesitamos introducir restricciones adicionales en las predicciones, lo que simplifica enormemente nuestro m√©todo.  La forma inicial se puede seleccionar simplemente como la forma intermedia de datos de entrenamiento, centrada y escalada de acuerdo con la salida del cuadro delimitador del detector de cara general. </p><br><p>  Educar a todos <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  Utilizamos el algoritmo de aumento de gradiente para √°rboles con la suma de p√©rdidas cuadr√°ticas, como se describe en [10].  Ahora daremos detalles detallados de este proceso. </p><br><h4 id="22-obuchenie-kazhdogo-regressora-v-kaskade">  2.2.  Entrenando a cada regresor en una cascada </h4><br><p>  Supongamos que tenemos datos de entrenamiento <img src="https://habrastorage.org/getpro/habr/post_images/a81/786/c9b/a81786c9b9d6dc27492f55b19afb5055.svg">  donde todos <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  es una imagen de la cara, y <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  Su vector de forma.  Para descubrir la primera funci√≥n de regresi√≥n <img src="https://habrastorage.org/getpro/habr/post_images/0ac/302/657/0ac302657b1d8e45efa7f7b9b2557268.svg">  en la cascada, creamos a partir de nuestros tripletes de datos de entrenamiento de la imagen de la cara, el pron√≥stico de forma inicial y el paso de actualizaci√≥n del objetivo, es decir <img src="https://habrastorage.org/getpro/habr/post_images/6a1/450/b9e/6a1450b9ea40a582ec2794d9df7afd31.svg">  ) donde </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f29/a62/581/f29a625813ba6c6cd00aea30a8cfe019.svg">  <em>(2)</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/6c3/a0d/468/6c3a0d468f609ada0672c0f473c589ec.svg">  <em>(3)</em> y </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/691/50d/5cf/69150d5cfe48125a51002916c28453e8.svg">  <em>(4)</em> </p><br><p>  para i = 1, ..., N. </p><br><p>  Establecemos el n√∫mero total de estos tripletes en N = nR, donde R es el n√∫mero de inicializaciones utilizadas en la imagen Ii.  Cada pron√≥stico de forma inicial para la imagen se selecciona uniformemente de <img src="https://habrastorage.org/getpro/habr/post_images/d1c/fb5/092/d1cfb5092f0e598893288582f2114b37.svg">  Sin reemplazo. </p><br><p>  Sobre estos datos entrenamos la funci√≥n de regresi√≥n <img src="https://habrastorage.org/getpro/habr/post_images/bcb/830/694/bcb83069438bb8a2d3e1e51f76a276f4.svg">  (ver Algoritmo 1) usando el aumento gradual de los √°rboles con la suma de las p√©rdidas cuadr√°ticas.  El conjunto de triplete de entrenamiento se actualiza para proporcionar datos de entrenamiento. <img src="https://habrastorage.org/getpro/habr/post_images/f56/e5c/4a8/f56e5c4a803f2c95ebe20dae215895cf.svg">  % 20) para el siguiente regresor <img src="https://habrastorage.org/getpro/habr/post_images/dc5/512/a85/dc5512a85c881619a2c05faa3c2a2806.svg">  en la cascada configurando (con t = 0). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/146/29d/692/14629d6922ca89d70fed70bbeb3287bd.svg">  % 20) <em>(5)</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/17d/8a5/44a/17d8a544a843aa72dc68d79ab9c2236d.svg">  <em>(6)</em> </p><br><p>  Este proceso se repite hasta que se entrena una cascada de regresores T. <img src="https://habrastorage.org/getpro/habr/post_images/ee6/6a5/503/ee66a5503085c7bbaa7a616585c4ae2e.svg">  que en combinaci√≥n proporcionan un nivel suficiente de precisi√≥n. </p><br><p>  Como se indica, cada regresor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  aprende usando el algoritmo de impulso del √°rbol de gradiente.  Debe recordarse que se utiliza la funci√≥n de p√©rdida cuadr√°tica, y los residuos calculados en el bucle interno corresponden al gradiente de esta funci√≥n de p√©rdida estimado en cada muestra de entrenamiento.  La formulaci√≥n del algoritmo incluye el par√°metro de velocidad de aprendizaje 0 &lt;ŒΩ ‚â§ 1, tambi√©n conocido como coeficiente de regularizaci√≥n.  Establecer ŒΩ &lt;1 ayuda a combatir la reconfiguraci√≥n y generalmente conduce a regresores que generalizan mucho mejor que aquellos entrenados con ŒΩ = 1 [10]. </p><br><hr><br><p>  <strong>Algoritmo de aprendizaje 1</strong> <strong><img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg"></strong>  <strong>en cascada</strong> </p><br><p>  Tenemos datos de entrenamiento <img src="https://habrastorage.org/getpro/habr/post_images/2d4/805/43a/2d480543a349544ead268291984b1e6a.svg">  y tasa de aprendizaje (coeficiente de regularizaci√≥n) 0 &lt;ŒΩ &lt;1 </p><br><ol><li>  Inicializar <br><img src="https://habrastorage.org/getpro/habr/post_images/e54/d75/bae/e54d75bae7a82091f8d5c1f04a92cc22.svg"></li><li>  para k = 1, ..., K: <br>  a) establecemos para i = 1, ..., <br><img src="https://habrastorage.org/getpro/habr/post_images/759/573/b03/759573b032b3bb95986dfe5d42d8e5d8.svg"><br>  b) Ajustamos el √°rbol de regresi√≥n al objetivo <img src="https://habrastorage.org/getpro/habr/post_images/683/2f3/54e/6832f354e8f4ecad8283cc1be6a6899a.svg">  con funci√≥n de regresi√≥n d√©bil <img src="https://habrastorage.org/getpro/habr/post_images/425/db2/33f/425db233f09794bfe60e62a49da89a98.svg">  . <br>  c) Actualizaci√≥n <img src="https://habrastorage.org/getpro/habr/post_images/376/5d0/ac3/3765d0ac3de75d838ad520821c141c21.svg"></li><li>  Conclusi√≥n <br><img src="https://habrastorage.org/getpro/habr/post_images/7c0/9c4/2b9/7c09c42b9cc35b3225f89435a9d4ce22.svg"></li></ol><br><hr><br><h4 id="23-drevovidnyy-regressor">  2.3.  √Årbol regresor </h4><br><p>  En el n√∫cleo de cada funci√≥n de regresi√≥n rt hay regresores en forma de √°rbol adecuados para objetivos residuales durante el algoritmo de aumento de gradiente.  Ahora veremos los detalles de implementaci√≥n m√°s importantes para entrenar cada √°rbol de regresi√≥n. </p><br><h4 id="231-invariantnye-split-testy-formy">  2.3.1 Pruebas de forma dividida invariable </h4><br><p>  En cada nodo de separaci√≥n en el √°rbol de regresi√≥n, tomamos una decisi√≥n basada en el valor umbral de la diferencia entre las intensidades de dos p√≠xeles.  Los p√≠xeles utilizados en la prueba est√°n en las posiciones u y v cuando se definen en el sistema de coordenadas de forma intermedia.  Para una imagen de una cara con una forma arbitraria, nos gustar√≠a indexar puntos que tienen la misma posici√≥n con respecto a su forma que u y v, para la forma promedio.  Para hacer esto, antes de extraer los elementos, la imagen se puede deformar a la forma media en funci√≥n de la estimaci√≥n de forma actual.  Dado que usamos solo una representaci√≥n muy escasa de la imagen, es mucho m√°s eficiente deformar la disposici√≥n de los puntos que toda la imagen.  Adem√°s, se puede hacer una aproximaci√≥n aproximada de la deformaci√≥n utilizando solo la transformaci√≥n de similitud global adem√°s de los desplazamientos locales, como se propone en [2]. </p><br><p>  Los detalles exactos son los siguientes.  Dejar <img src="https://habrastorage.org/getpro/habr/post_images/482/2f7/60f/4822f760fdf061f414f323d30d0c14cd.svg">  Es el √≠ndice del punto de referencia en la cara en la forma media m√°s cercano a usted, y define su desplazamiento desde u como <img src="https://habrastorage.org/getpro/habr/post_images/0fa/bbb/f81/0fabbbf8125f80b9f31e3b5ce093bc3c.svg">  . </p><br><p>  Luego para la forma Si definida en la imagen <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  posici√≥n en <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  , que es cualitativamente similar a u en la imagen de una forma mediana, se define como <br><img src="https://habrastorage.org/getpro/habr/post_images/e2d/e8d/0d4/e2de8d0d461e2ef6e76642d39a803b27.svg">  <em>(7)</em> </p><br><p>  donde <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  y <img src="https://habrastorage.org/getpro/habr/post_images/8f6/b4a/913/8f6b4a913e518f22483a28148144b54e.svg">  - matriz de escala y rotaci√≥n de la transformaci√≥n de similitud que transforma <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  en <img src="https://habrastorage.org/getpro/habr/post_images/919/800/718/919800718f235e7487c36b01db6739e1.svg">  , forma media </p><br><p>  Escala y rotaci√≥n minimizan </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/cf0/581/e89/cf0581e890e027fcaf3327e3be6f194c.svg">  <em>(8)</em> </p><br><p>  la suma de los cuadrados entre los puntos de referencia de la forma media, <img src="https://habrastorage.org/getpro/habr/post_images/c73/942/e7f/c73942e7f47a9adb6091e024085fc1bb.svg">  y punto de urdimbre. <img src="https://habrastorage.org/getpro/habr/post_images/b2d/a25/52e/b2da2552e44457f6bcbf5d1aab251267.svg">  definido de manera similar. </p><br><p>  Formalmente, cada divisi√≥n es una soluci√≥n que incluye 3 par√°metros Œ∏ = (œÑ, u, v), y se aplica a cada ejemplo de entrenamiento y prueba como </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/bfe/6ee/9c7/bfe6ee9c7e9da21fb2b81caca3d8abad.svg">  <em>(9)</em> </p><br><p>  donde <img src="https://habrastorage.org/getpro/habr/post_images/ff8/c77/429/ff8c77429402ff15260663452a693e8d.svg">  y <img src="https://habrastorage.org/getpro/habr/post_images/b2d/a25/52e/b2da2552e44457f6bcbf5d1aab251267.svg">  se determinan utilizando la matriz de escala y rotaci√≥n que mejor se deforma <img src="https://habrastorage.org/getpro/habr/post_images/5ac/ad7/803/5acad7803f7a79cc10fa8c714205eeab.svg">  en <img src="https://habrastorage.org/getpro/habr/post_images/919/800/718/919800718f235e7487c36b01db6739e1.svg">  de acuerdo con la ecuaci√≥n (7).  En la pr√°ctica, las tareas y los desplazamientos locales se determinan en la etapa de capacitaci√≥n.  El c√°lculo de la transformaci√≥n de similitud, durante la prueba de la parte m√°s cara de este proceso, se realiza solo una vez en cada nivel de la cascada. </p><br><h4 id="232-vybor-uzlovyh-razbieniy">  2.3.2 Selecci√≥n de particiones nodales </h4><br><p>  Para cada √°rbol de regresi√≥n, aproximamos la funci√≥n b√°sica por una funci√≥n lineal por partes, donde un vector constante es adecuado para cada nodo finito.  Para entrenar el √°rbol de regresi√≥n, generamos aleatoriamente un conjunto de particiones adecuadas, es decir, Œ∏, en cada nodo.  Luego seleccionamos ansiosamente Œ∏ * de estos candidatos, lo que minimiza la suma del error cuadr√°tico.  Si Q es un conjunto de √≠ndices de ejemplos de entrenamiento en un nodo, esto corresponde a la minimizaci√≥n </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8b2/8f1/e02/8b28f1e02ab50c802525c5ded6aaeeaf.svg">  <em>(10)</em> </p><br><p>  donde <img src="https://habrastorage.org/getpro/habr/post_images/fd5/fa1/737/fd5fa1737973ecd7a303b2862a32f8ec.svg">  - √≠ndices de ejemplos que se env√≠an al nodo izquierdo debido a la decisi√≥n Œ∏, <img src="https://habrastorage.org/getpro/habr/post_images/ab1/ee0/4fb/ab1ee04fb1210c9352cc942823f6dcd1.svg">  Es el vector de todos los residuos calculados para la imagen <em>i</em> en el algoritmo de aumento de gradiente, y </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c7f/e61/cc7/c7fe61cc7d441d07443317d12fc860c4.svg">  para <img src="https://habrastorage.org/getpro/habr/post_images/e17/6e7/ece/e176e7ece99e70aeee6c4ffe2949bb2f.svg">  <em>(11)</em> </p><br><p>  La partici√≥n √≥ptima se puede encontrar de manera muy eficiente, porque si transformamos la ecuaci√≥n (10) y omitimos factores independientes de Œ∏, podemos ver que </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/517/57c/a5c/51757ca5c227156f25de32c995a6c1eb.svg"></p><br><p>  Aqu√≠ solo necesitamos calcular <img src="https://habrastorage.org/getpro/habr/post_images/88d/4eb/4bb/88d4eb4bb69acbcbbbf4ad0e10098a80.svg">  al evaluar varios Œ∏, ya que <img src="https://habrastorage.org/getpro/habr/post_images/ba2/1c8/eeb/ba21c8eeb00ef767cf6f5bd5297f986e.svg">  se puede calcular a partir de los objetivos promedio en el nodo principal ¬µ y <img src="https://habrastorage.org/getpro/habr/post_images/88d/4eb/4bb/88d4eb4bb69acbcbbbf4ad0e10098a80.svg">  como sigue: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b0a/e76/10a/b0ae7610afe1aa13d10de797871193c6.svg"></p><br><h4 id="233-vybor-priznakov">  2.3.3 Selecci√≥n de caracter√≠sticas </h4><br><p>  La soluci√≥n en cada nodo se basa en un valor umbral de la diferencia en los valores de intensidad en un par de p√≠xeles.  Esta es una prueba bastante simple, pero es mucho m√°s efectiva que un valor umbral con una sola intensidad, debido a su relativa insensibilidad a los cambios en la iluminaci√≥n global.  Desafortunadamente, la desventaja de usar diferencias de p√≠xeles es que el n√∫mero de candidatos potenciales de separaci√≥n (caracter√≠stica) es cuadr√°tico con respecto al n√∫mero de p√≠xeles en la imagen promedio.  Esto hace que sea dif√≠cil encontrar buenos Œ∏ sin buscar una gran cantidad de ellos.  Sin embargo, este factor limitante puede debilitarse un poco, teniendo en cuenta la estructura de los datos de la imagen. </p><br><p>  Introducimos la distribuci√≥n exponencial </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f30/6b8/6c4/f306b86c47bfa440c1d1c716e3c9d6b8.svg">  <em>(12)</em> </p><br><p>  por la distancia entre los p√≠xeles utilizados en la divisi√≥n para fomentar la selecci√≥n de pares de p√≠xeles m√°s cercanos. </p><br><p>  Hemos descubierto que el uso de esta distribuci√≥n simple reduce el error de predicci√≥n para varios conjuntos de datos faciales.  La Figura 4 compara las caracter√≠sticas seleccionadas con y sin ella, donde el tama√±o del grupo de objetos en ambos casos se establece en 20. </p><br><h1 id="24-obrabotka-propuschennyh-metok">  2.4.  Manejo de etiquetas faltantes </h1><br><p>  El problema de la ecuaci√≥n (10) puede extenderse f√°cilmente para manejar el caso cuando algunos puntos de referencia no est√°n marcados en algunas im√°genes de entrenamiento (o tenemos una medida de incertidumbre para cada punto de referencia).  Introducir variable <img src="https://habrastorage.org/getpro/habr/post_images/7e0/805/7ed/7e08057ed464a0c8c2af586f05a009aa.svg">  [0, 1] para cada imagen de entrenamiento <em>i</em> y cada punto de referencia <em>j</em> .  Instalaci√≥n <img src="https://habrastorage.org/getpro/habr/post_images/260/ce8/a6b/260ce8a6b696864e07aaa5de561923e6.svg">  un valor de 0 indica que el hito <em>j</em> no <em>est√°</em> marcado en la <em>i-</em> √©sima imagen, y un ajuste de 1 indica que est√° marcado.  Entonces la ecuaci√≥n (10) se puede representar de la siguiente manera </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/7e5/183/d89/7e5183d8955912640ff62a62fd8913de.svg"></p><br><p>  donde <img src="https://habrastorage.org/getpro/habr/post_images/07f/821/26e/07f82126e42fc56123ae1a571fcaac7b.svg">  - matriz diagonal con vector <img src="https://habrastorage.org/getpro/habr/post_images/a77/988/515/a779885154cabacbcccfb17d823fd818.svg">  en su diagonal y </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/7a7/975/451/7a79754517a719b74cff33c43743171f.svg">  para <img src="https://habrastorage.org/getpro/habr/post_images/e17/6e7/ece/e176e7ece99e70aeee6c4ffe2949bb2f.svg">  <em>(13)</em> </p><br><p>  El algoritmo de aumento de gradiente tambi√©n debe modificarse para tener en cuenta estos pesos.  Esto se puede hacer simplemente inicializando el modelo de conjunto con el valor promedio ponderado de los objetivos y ajustando los √°rboles de regresi√≥n a los residuos ponderados en el algoritmo 1 de la siguiente manera </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/396/468/7a9/3964687a9c8c905316ef8d6b69d73888.svg">  <em>(14)</em> </p><br><h1 id="3-eksperimenty">  3. Experimentos </h1><br><p>  <strong>Bases:</strong> para evaluar con precisi√≥n el rendimiento de nuestro m√©todo propuesto, conjunto de √°rboles de regresi√≥n (ERT), creamos dos bases m√°s.  El primero se basa en helechos aleatorios (helechos aleatorios) con una selecci√≥n aleatoria de rasgos (EF), y el otro es una versi√≥n m√°s avanzada de este enfoque con la selecci√≥n de rasgos basados ‚Äã‚Äãen la correlaci√≥n (EF + CB), que es nuestra nueva implementaci√≥n [2].  Todos los par√°metros son fijos para los tres enfoques. </p><br><p>  EF utiliza la implementaci√≥n directa de helechos aleatorios como regresores d√©biles en el conjunto y es el m√°s r√°pido para el entrenamiento.  Utilizamos el mismo m√©todo de regularizaci√≥n que se sugiere en [2] para la regularizaci√≥n de helechos. </p><br><p>  EF + CB utiliza un m√©todo de selecci√≥n de objetos basado en correlaci√≥n que proyecta valores de salida, <img src="https://habrastorage.org/getpro/habr/post_images/ab1/ee0/4fb/ab1ee04fb1210c9352cc942823f6dcd1.svg">  's, en una direcci√≥n aleatoria w y selecciona pares de signos (u, v) para los cuales <img src="https://habrastorage.org/getpro/habr/post_images/dcf/e8f/3cc/dcfe8f3ccb1ca1095fc35db5b623abc0.svg">  tiene la mayor correlaci√≥n de muestra para los datos de entrenamiento con objetivos predichos <img src="https://habrastorage.org/getpro/habr/post_images/b63/418/2d8/b634182d884088b10405bc691e479fd8.svg">  . </p><br><p>  <strong>Par√°metros</strong> <br>  A menos que se especifique lo contrario, todos los experimentos se realizan con las siguientes configuraciones de par√°metros fijos.  El n√∫mero de regresores fuertes rt en la cascada es T = 10, y cada uno <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  consiste en K = 500 regresores d√©biles <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg">  .  Profundidad de los √°rboles (o helechos) utilizados para representar <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg">  , establecido igual a F = 5. En cada nivel de la cascada, P = 400 p√≠xeles se seleccionan de la imagen.  Para entrenar regresores d√©biles, seleccionamos aleatoriamente un par de estos p√≠xeles P de acuerdo con nuestra distribuci√≥n y seleccionamos un umbral aleatorio para crear una separaci√≥n potencial, como se describe en la ecuaci√≥n (9).  La mejor separaci√≥n se logra repitiendo este proceso S = 20 veces y eligiendo el que optimice nuestro objetivo.        ,   R = 20      . </p><br><p><img src="https://habrastorage.org/webt/7j/we/fs/7jwefsr7puidwxuehw6owexel8k.png"></p><br><p> <em> 2.       ,             Viola &amp; Jones [17].        .</em> </p><br><p> <strong></strong> <br>          O (TKF).          O (NDTKF S),  N ‚Äî   ,  D ‚Äî  .                HELEN [12],           . </p><br><p> <strong> </strong> <br>   ,   ,      HELEN [12], ,   ,      .    2330 ,     194 .      2000    ,    . </p><br><p>           LFPW [1],    1432 .  ,     778    216   ,         ,      . </p><br><p>  <strong>Comparaci√≥n</strong> <br>  1         .                  (Active Shape Models) ‚Äî STASM [14]  CompASM [12]. </p><br><p><img src="https://habrastorage.org/webt/89/fk/kc/89fkkczbo119vyy4oo7hhu7cmno.png"></p><br><p> <em> 1.        HELEN.  ‚Äî          .       .      ,        .    ,       .              .</em> </p><br><p>   ,    ,        .   3       ,  ,  ERT     ,   .  ,        EF + CB     .  ,      EF + CB       ,     . </p><br><p>          LFPW [1] ( 2).    EF + CB     ,   [2]. (     ,        .)              ,      ,     . </p><br><p><img src="https://habrastorage.org/webt/ef/uu/nz/efuunznz_ljfv_sr1v1vi5fujoy.png"></p><br><p> <em> 2.        LFPW.       1.</em> </p><br><p> <strong> </strong> <br>  4     (12)       ,   ,      .  Œª               0,1   .            <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">         .  4          . </p><br><p><img src="https://habrastorage.org/webt/do/pm/v4/dopmv4u-mj6pa5tcaioawlcvegs.png"></p><br><p> <em> 3.           .         ,  , .  (12).</em> </p><br><p> <strong></strong> <br>        ,   .     ,     .    ‚Äî .        ŒΩ      1 (   ŒΩ = 0.1).           .  , <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg">   ,    ,    ŒΩ = 1.                   (10   )   . (      .) </p><br><p><img src="https://habrastorage.org/webt/lp/hv/hv/lphvhvclakdn02mzwrfe5rtt28w.png"></p><br><p> <em> 3.       HELEN (a)  LFPW (b). EF ‚Äî    ,  EF + CB ‚Äî      ,   .          (5  10),    [2].  ,      (ERT),     ,     ,             .</em> </p><br><p><img src="https://habrastorage.org/webt/xm/3y/pp/xm3yppxdejbgcglidfb-ecofaza.png"></p><br><p> <em> 4.   ,    .       ,      .</em> </p><br><p>             ,   .         ,    . </p><br><p><img src="https://habrastorage.org/webt/0r/hv/l0/0rhvl0mowqozwdscxpkc-lp-w7e.png"></p><br><p> <em> 4.      HELEN     .                .</em> </p><br><p>    ,          .   ,        ,    ,        ,       . </p><br><p> <strong></strong> <br>                 .              .  5          .    ,    ,      [8, 2] (           10 √ó 400 .) </p><br><p><img src="https://habrastorage.org/webt/rt/sa/n3/rtsan3fkhl6houggpnk8zyiwqie.png"></p><br><p> <em> 5.             .</em> </p><br><p> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Datos de entrenamiento</font></font></strong> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Para probar la efectividad de nuestro m√©todo en t√©rminos del n√∫mero de im√°genes de entrenamiento, entrenamos varios modelos de diferentes subconjuntos de datos de entrenamiento. </font><font style="vertical-align: inherit;">La Tabla 6 resume los resultados finales, y la Figura 5 muestra un gr√°fico de errores en cada nivel de la cascada. </font><font style="vertical-align: inherit;">Usar muchos niveles de regresores es m√°s √∫til cuando tenemos una gran cantidad de ejemplos de entrenamiento.</font></font></p><br><p> Repetimos los mismos experimentos con un n√∫mero total fijo de ejemplos extendidos, pero cambiamos la combinaci√≥n de las formas iniciales usadas para crear el ejemplo de entrenamiento a partir de un ejemplo marcado de la cara y una cantidad de im√°genes anotadas usadas para estudiar la cascada (Tabla 7). </p><br><p><img src="https://habrastorage.org/webt/8p/-8/bb/8p-8bbob2qvordp1hhebxruts38.png"></p><br><p>  <em>Tabla 6. La tasa de error final para el n√∫mero de ejemplos de entrenamiento.</em>  <em>Al crear datos de entrenamiento para estudiar regresores en cascada, cada imagen de rostro etiquetada generaba 20 ejemplos de entrenamiento, utilizando 20 caras etiquetadas diferentes como una suposici√≥n inicial sobre la forma del rostro.</em> </p><br><p><img src="https://habrastorage.org/webt/0o/ft/7s/0oft7ss-mbxhjnln3wje3hqzxau.png"></p><br><p>  <em>Figura 5. El error promedio en cada nivel de la cascada se presenta dependiendo del n√∫mero de ejemplos de entrenamiento utilizados.</em>  <em>El uso de muchos niveles de regresores es m√°s √∫til cuando el n√∫mero de ejemplos de entrenamiento es grande.</em> </p><br><p><img src="https://habrastorage.org/webt/am/mj/aq/ammjaqyvpgnzjynmk0ychb7lnw8.png"></p><br><p>  <em>Tabla 7. Aqu√≠ el n√∫mero efectivo de ejemplos de entrenamiento es fijo, pero usamos varias combinaciones del n√∫mero de im√°genes de entrenamiento y el n√∫mero de formas iniciales usadas para cada imagen de rostro marcada.</em> </p><br><p>  El aumento de los datos de entrenamiento usando una variedad de formas iniciales expande el conjunto de datos en t√©rminos de forma.  Nuestros resultados muestran que este tipo de suplemento no compensa completamente la ausencia de im√°genes de entrenamiento anotadas.  Aunque la tasa de mejora obtenida al aumentar el n√∫mero de im√°genes de entrenamiento est√° disminuyendo r√°pidamente despu√©s de los primeros cientos de im√°genes. </p><br><p>  <strong>Anotaciones parciales</strong> <br>  La Tabla 8 muestra los resultados del uso de datos parcialmente anotados.  200 estudios de casos est√°n anotados completamente, y el resto solo parcialmente. </p><br><p><img src="https://habrastorage.org/webt/iu/j9/7q/iuj97qa3-awn35lf8z3yibbuzhw.png"></p><br><p>  <em>Tabla 8. Resultados usando datos parcialmente etiquetados.</em>  <em>200 ejemplos siempre est√°n completamente anotados.</em>  <em>Los valores entre par√©ntesis indican el porcentaje de puntos de referencia observados.</em> </p><br><p>  Los resultados muestran que podemos lograr una mejora significativa utilizando datos parcialmente etiquetados.  Sin embargo, la mejora mostrada puede no estar saturada, porque sabemos que el tama√±o base de los par√°metros de forma es mucho m√°s bajo que el tama√±o de los puntos de referencia (194 √ó 2).  En consecuencia, existe la posibilidad de una mejora m√°s significativa con las marcas parciales, si utiliza expl√≠citamente la correlaci√≥n entre la posici√≥n de los puntos de referencia.  Tenga en cuenta que el procedimiento de aumento de gradiente descrito en este art√≠culo no utiliza correlaci√≥n entre puntos de referencia.  Este problema puede resolverse en futuros trabajos. </p><br><h1 id="4-vyvod">  4. Conclusi√≥n </h1><br><p>  Describimos c√≥mo se puede usar un conjunto de √°rboles de regresi√≥n para hacer retroceder la ubicaci√≥n de puntos de referencia faciales a partir de un subconjunto disperso de valores de intensidad extra√≠dos de la imagen de entrada.  La estructura presentada reduce el error m√°s r√°pido que el trabajo anterior y tambi√©n puede procesar marcas parciales o indefinidas.  Si bien los componentes principales de nuestro algoritmo consideran diversas mediciones objetivo como variables independientes, la continuaci√≥n natural de este trabajo ser√° el uso de la correlaci√≥n de los par√°metros de forma para un entrenamiento m√°s efectivo y un mejor uso de etiquetas parciales. </p><br><p><img src="https://habrastorage.org/webt/am/cu/xs/amcuxsbdkp6du3rohxpnoey0r2q.png"></p><br><p>  <em>Figura 6. Resultados finales en la base de datos HELEN.</em> </p><br><p>  <strong>Agradecimientos</strong> <br>  Este trabajo fue financiado por la Fundaci√≥n Sueca de Investigaci√≥n Estrat√©gica como parte del proyecto VINST. </p><br><h1 id="ispolzovannaya-literatura">  Literatura usada </h1><br><p>  [1] PN Belhumeur, DW Jacobs, DJ Kriegman y N. Kumar.  Localizaci√≥n de partes de rostros utilizando un consenso de ejemplares.  En CVPR, p√°ginas 545‚Äì552, 2011. 1, 5 <br>  [2] X. Cao, Y. Wei, F. Wen y J. Sun.  Alineaci√≥n de caras por regresi√≥n expl√≠cita de formas.  En CVPR, p√°ginas 2887‚Äì2894, 2012. 1, 2, 3, 4, 5, 6 <br>  [3] TF Cootes, M. Ionita, C. Lindner y P. Sauer.  Ajuste de modelo de forma robusto y preciso mediante votaci√≥n de regresi√≥n forestal aleatoria.  En ECCV, 2012.1 <br>  [4] TF Cootes, CJ Taylor, DH Cooper y J. Graham.  Modelos de forma activa: su entrenamiento y aplicaci√≥n.  Visi√≥n por computadora y comprensi√≥n de im√°genes, 61 (1): 38‚Äì59, 1995.1, 2 <br>  [5] D. Cristinacce y TF Cootes.  Regresi√≥n activada modelos de forma activa.  En BMVC, p√°ginas 79.1‚Äì79.10, 2007.1 <br>  [6] M. Dantone, J. Gall, G. Fanelli y LV Gool.  Detecci√≥n de caracter√≠sticas faciales en tiempo real utilizando bosques de regresi√≥n condicional.  En CVPR, 2012.1 <br>  [7] L. Ding y AM Mart√≠nez.  Detecci√≥n detallada precisa de rostros y rasgos faciales.  En CVPR, 2008.1 <br>  [8] P. Dollar, P. Welinder y P. Perona.  Regresi√≥n de pose en cascada.  En CVPR, p√°ginas 1078‚Äì1085, 2010. 1, 2, 6 <br>  [9] GJ Edwards, TF Cootes y CJ Taylor.  Avances en modelos de apariencia activa.  En ICCV, p√°ginas 137‚Äì142, 1999. 1, 2 <br>  [10] T. Hastie, R. Tibshirani y JH Friedman.  Los elementos del aprendizaje estad√≠stico: miner√≠a de datos, inferencia y predicci√≥n.  Nueva York: Springer-Verlag, 2001,2,3 <br>  [11] V. Kazemi y J. Sullivan.  Alineaci√≥n de caras con modelado basado en piezas.  En BMVC, p√°ginas 27.1‚Äì27.10, 2011.2 <br>  [12] V. Le, J. Brandt, Z. Lin, LD Bourdev y TS Huang.  Localizaci√≥n interactiva de rasgos faciales.  En [13] L. Liang, R. Xiao, F. Wen y J. Sun.  Alineaci√≥n de caras a trav√©s de b√∫squeda discriminativa basada en componentes.  En ECCV, p√°ginas 72‚Äì85, 2008. 1ECCV, p√°ginas 679‚Äì 692, 2012.5 <br>  [14] S. Milborrow y F. Nicolls.  Localizaci√≥n de rasgos faciales con un modelo de forma activa extendida.  En ECCV, p√°ginas 504‚Äì513, 2008.5 <br>  [15] J. Saragih, S. Lucey y J. Cohn.  Ajuste del modelo deformable por medio de cambios medios regulares.  Internation Journal of Computer Vision, 91: 200‚Äì215, 2010.1 <br>  [16] BM Smith y L. Zhang.  Alineaci√≥n de la cara conjunta con modelos de forma no param√©trica.  En ECCV, p√°ginas 43‚Äì56, 2012.1 <br>  [17] PA Viola y MJ Jones.  Robusta detecci√≥n de rostros en tiempo real.  En ICCV, p√°gina 747, 2001.5 <br>  [18] X. Zhao, X. Chai y S. Shan.  Alineaci√≥n de la cara conjunta: Rescate las alineaciones malas con las buenas mediante un reajuste regular.  En ECCV, 2012.1 <br>  [19] X. Zhu y D. Ramanan.  Detecci√≥n de rostros, estimaci√≥n de posturas y localizaci√≥n de hitos en la naturaleza.  En CVPR, p√°ginas 2879‚Äì2886, 2012.1 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/460541/">https://habr.com/ru/post/460541/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../460525/index.html">Bienvenido a DINS IT TARDE en julio: QA y JS</a></li>
<li><a href="../460527/index.html">Resoluci√≥n de problemas con pwnable.kr 06 - aleatorio y 09 - error</a></li>
<li><a href="../460533/index.html">Se te ocurri√≥ la idea de un producto de TI, ¬øqu√© sigue?</a></li>
<li><a href="../460537/index.html">ZuriHac: practicando programaci√≥n funcional</a></li>
<li><a href="../460539/index.html">Manejo de errores en Vue</a></li>
<li><a href="../460543/index.html">Nuevas certificaciones para desarrolladores de Cisco. Descripci√≥n general de la certificaci√≥n de la industria</a></li>
<li><a href="../460547/index.html">Antig√ºedades: Psion 5MX y Retired Life</a></li>
<li><a href="../460551/index.html">Portugal Las mejores playas y mil startups al a√±o.</a></li>
<li><a href="../460553/index.html">Tecnolog√≠a, outsourcing y mentalidad: c√≥mo implementamos Microsoft Dynamics 365 en la oficina alemana de Lamoda</a></li>
<li><a href="../460555/index.html">Informe de la reuni√≥n de PyDaCon en Mail.ru Group, 22 de junio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
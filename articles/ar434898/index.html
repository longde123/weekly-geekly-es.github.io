<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⚔️ ☠️ 👳 Grasp2Vec: تعلم تمثيل الكائنات من خلال التقاط التعلم الذاتي 🙎🏼 👩🏼‍🚀 ✌🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="الناس في سن مبكرة بشكل مفاجئ قادرون بالفعل على التعرف على الأشياء المفضلة لديهم والتقاطها ، على الرغم من أنهم لم يتعلموا هذا على وجه التحديد. وفقًا لد...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Grasp2Vec: تعلم تمثيل الكائنات من خلال التقاط التعلم الذاتي</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/434898/" style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/220/c80/5fb/220c805fb8ffb53d2b33413fa2e9eeda.png"><br><br>  الناس في سن مبكرة بشكل مفاجئ قادرون بالفعل على التعرف على الأشياء المفضلة لديهم والتقاطها ، على الرغم من أنهم لم يتعلموا هذا على وجه التحديد.  وفقًا <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">لدراسات</a> تطوير القدرات المعرفية ، تلعب إمكانية التفاعل مع كائنات العالم من حولنا دورًا حاسمًا في تطوير قدرات مثل الاستشعار عن الأشياء ومعالجتها - على سبيل المثال ، الالتقاط المستهدف.  بالتفاعل مع العالم الخارجي ، يمكن للناس أن يتعلموا بتصحيح أخطائهم: نعرف ما فعلناه ونتعلم من النتائج.  في علم الروبوتات ، تتم دراسة هذا النوع من التدريب مع التصحيح الذاتي للأخطاء بفعالية ، لأنه يسمح للأنظمة الآلية بالتعلم دون قدر كبير من بيانات التدريب أو الضبط اليدوي. <br><br>  نحن في Google ، مستوحى من <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">مفهوم ثبات الأجسام</a> ، نقدم نظام <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">Grasp2Vec</a> - خوارزمية بسيطة ولكنها فعالة لبناء تمثيل الكائنات.  يعتمد Grasp2Vec على فهم حدسي مفاده أن محاولة رفع أي كائن ستمنحنا بعض المعلومات - إذا كان الروبوت يلتقط الكائن ويلتقطه ، فيجب أن يكون الكائن في هذا المكان قبل التقاطه.  بالإضافة إلى ذلك ، يعرف الروبوت أنه إذا كان الكائن الملتقط قيد الالتقاط ، فهذا يعني أن الكائن لم يعد في المكان الذي كان فيه.  باستخدام هذا النوع من التعلم الذاتي ، يمكن أن يتعلم الروبوت التعرف على كائن ما بسبب التغيير المرئي في المشهد بعد التقاطه. <br><a name="habracut"></a><br>  استنادًا إلى تعاوننا <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">مع X Robotics</a> ، حيث تم تدريب العديد من الروبوتات في وقت واحد على التقاط الأشياء المنزلية باستخدام كاميرا واحدة فقط كمصدر لبيانات المدخلات ، فإننا نستخدم الالتقاط الآلي لأشياء الالتقاط "عن غير قصد" ، وهذه التجربة تتيح لنا الحصول على فكرة غنية عن الكائن.  يمكن بالفعل استخدام هذه الفكرة لاكتساب قدرة "الالتقاط المتعمد" ، عندما يستطيع ذراع الروبوت رفع الأشياء عند الطلب. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/QzlI_ny4l8s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2 style=";text-align:right;direction:rtl">  خلق وظيفة مكافأة الإدراك الحسي </h2><br>  على منصة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">تعلم التعزيز ،</a> يتم قياس نجاح المهمة من خلال وظيفة المكافأة.  من خلال تعظيم المكافآت ، تتعلم الروبوتات مهارات الالتقاط المختلفة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">من الصفر</a> .  من السهل إنشاء وظيفة مكافأة عندما يمكن قياس النجاح من خلال قراءات أجهزة الاستشعار البسيطة.  مثال بسيط هو زر ينقل المكافأة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">مباشرةً إلى مدخلات الروبوت</a> بالنقر عليه. <br><br>  ومع ذلك ، فإن إنشاء وظيفة المكافأة يكون أكثر تعقيدًا عندما يعتمد معيار النجاح على الفهم الإدراكي للمهمة.  ضع في اعتبارك مشكلة الالتقاط في مثال حيث يتم إعطاء الروبوت صورة للكائن المطلوب الموجود في الالتقاط.  بعد محاولة الروبوت التقاط الكائن ، يفحص محتويات الالتقاط.  تعتمد وظيفة المكافأة لهذه المهمة على إجابة سؤال التعرف على الأنماط: هل تتزامن الكائنات؟ <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f23/a41/c24/f23a41c24b4cc60b062d055bbb5b9347.png"><br>  <i>على اليسار ، تمسك الفرشاة بالفرشاة ، وتظهر العديد من الأشياء في الخلفية (كوب أصفر ، كتلة بلاستيكية زرقاء).</i>  <i>على اليمين ، تمسك القبضة بالكأس ، وتكون الفرشاة في الخلفية.</i>  <i>إذا كانت الصورة اليسرى تمثل النتيجة المرغوبة ، فإن وظيفة المكافأة الجيدة تتمثل في "فهم" أن هاتين الصورتين تتوافقان مع كائنين مختلفين.</i> <br><br>  لحل مشكلة التعرُّف ، نحتاج إلى نظام إدراكي يستخلص مفاهيم ذات معنى من الكائنات من صور غير منظمة (لا يوقعها الأشخاص) ، ويتعلم تصوُّر الأشياء بدون معلم.  تعمل خوارزميات التعلم بدون معلم أساسًا من خلال إنشاء افتراضات هيكلية حول البيانات.  غالبًا ما يُفترض أنه يمكن <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">ضغط</a> الصور <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">إلى مساحة ذات أبعاد أقل</a> ، ويمكن <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">التنبؤ</a> بإطارات الفيديو <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">من تلك السابقة</a> .  ومع ذلك ، دون افتراضات إضافية حول محتويات البيانات ، فإن هذا لا يكفي عادة للتعلم من تمثيلات غير مرتبطة بالكائنات. <br><br>  ماذا لو استخدمنا الروبوت لفصل الأشياء فعليًا أثناء جمع البيانات؟  يوفر Robotics فرصة ممتازة لتعلم كيفية تمثيل الكائنات ، حيث يمكن للروبوتات معالجتها ، مما سيعطي عوامل الاختلاف اللازمة.  تعتمد طريقة عملنا على فكرة أن التقاط كائن يزيله من المشهد.  والنتيجة هي 1) صورة للمشهد قبل الالتقاط ، 2) صورة للمشهد بعد الالتقاط ، و 3) رؤية منفصلة للكائن الملتقط. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8da/43f/0d7/8da43f0d74077b6c65a80026ce7041f0.png"><br>  <i>اليسار - كائنات لالتقاط.</i>  <i>في الوسط - بعد القبض.</i>  <i>على اليمين هو الكائن الذي تم التقاطه.</i> <br><br>  إذا أخذنا في الاعتبار وظيفة مضمّنة تستخرج "مجموعة من الكائنات" من الصور ، فيجب أن تحافظ على علاقة الطرح التالية: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1c8/aa9/723/1c8aa97238f20d832c90f02335c0367c.png"><br>  <i>كائنات قبل الالتقاط - كائنات بعد الالتقاط = كائن تم التقاطه</i> <br><br>  نحقق هذه المساواة مع الهندسة المعمارية التلافيفية وخوارزمية التعلم متري بسيطة.  أثناء التدريب ، تضم البنية الموضحة أدناه الصور قبل الالتقاط وبعده في <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">خريطة</a> كثيفة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">للخواص المكانية</a> .  تتحول هذه الخرائط إلى متجهات من خلال اتحاد متوسط ​​، ويمثل الفرق بين متجهات "قبل الالتقاط" و "بعد الالتقاط" مجموعة من الكائنات.  تتم مقارنة هذا المتجه والتمثيل المقابل لمتجه هذا الكائن المدروس من خلال وظيفة أزواج N. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/32f/e51/c0d/32fe51c0d4915374be646fc0bb2ba76c.png"><br><br>  بعد التدريب ، يتميز نموذجنا بطبيعة الحال بخاصيتين مفيدتين. <br><br><h2 style=";text-align:right;direction:rtl">  1. تشابه الأشياء </h2><br>  يسمح لنا <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">معامل جيب التمام</a> بالمسافة بين زخارف المتجهات بمقارنة الأشياء وتحديد ما إذا كانت متطابقة أم لا.  يمكن استخدام هذا لتنفيذ وظيفة المكافأة للتعلم المعزز ، ويسمح للروبوتات بتعلم كيفية التقاطها بأمثلة دون ترميز البيانات من قبل البشر. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c47/fb7/dd4/c47fb7dd4c79a4e16564f9d6ab669f5e.png"><br><br><h2 style=";text-align:right;direction:rtl">  2. العثور على الأهداف </h2><br>  يمكننا الجمع بين الخرائط المكانية للمشهد ودمج الكائنات لتوطين "الكائن المرغوب" في مساحة الصورة.  عند تنفيذ عمليات الضرب على أساس العناصر لخرائط الميزات المكانية ومراسلات المتجهات الخاصة بالكائن المرغوب فيه ، يمكننا العثور على جميع وحدات البكسل في الخريطة المكانية التي تتوافق مع الكائن الهدف. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c42/271/47b/c4227147baeb69c052549544b9065961.png"><br>  <i>استخدام تطعيمات Grasp2Vec لتوطين الكائنات في المشهد.</i>  <i>أعلى اليسار كائنات في السلة.</i>  <i>أسفل اليسار - الكائن المطلوب التقاطه.</i>  <i>يمنحنا المنتج العددي الخاص بموجه الكائن الهدف والميزات المكانية للصورة "خريطة تنشيط" لكل بكسل (أعلى اليمين) لتشابه قسم معين من الصورة مع الهدف.</i>  <i>يمكن استخدام هذه الخريطة للاقتراب من الهدف.</i> <br><br>  تعمل طريقة عملنا أيضًا عندما تتوافق عدة كائنات مع الهدف ، أو حتى عندما يتألف الهدف من عدة كائنات (متوسط ​​متجهين).  على سبيل المثال ، في هذا السيناريو ، يحدد الروبوت عدة كتل برتقالية في المشهد. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4f3/f9e/b15/4f3f9eb159738345f5a8da4c1dfb83fc.png"><br>  <i>يمكن استخدام "خريطة الحرارة" الناتجة للتخطيط لنهج الروبوت إلى الكائن (الكائنات) الهدف.</i>  <i>نحن نجمع بين الترجمة من Grasp2Vec والتعرف على الأنماط وسياسة "التقاط أي شيء" الخاصة بنا وتحقيق النجاح في 80 ٪ من الحالات أثناء جمع البيانات وفي 59 ٪ مع كائنات جديدة لم يصادفها الروبوت سابقًا.</i> <br><br><h2 style=";text-align:right;direction:rtl">  الخاتمة </h2><br>  في عملنا <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">،</a> أظهرنا كيف يمكن لمهارات القابض الآلي إنشاء بيانات تستخدم لتعليم تمثيل الكائنات.  ثم يمكننا استخدام التدريب على العرض التقديمي لاكتساب مهارات أكثر تعقيدًا بسرعة ، مثل الالتقاط وفقًا لمثال ، مع الحفاظ على جميع خصائص التدريس بدون معلم في نظام الالتقاط المستقل. <br><br>  بالإضافة إلى عملنا ، درست أيضًا العديد من الأعمال الحديثة الأخرى كيف يمكن استخدام التفاعل دون وجود معلم للحصول على تمثيلات للكائنات ، من خلال <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">الالتقاط</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">والدفع</a> وأنواع أخرى من <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">التفاعلات</a> مع الكائنات في البيئة.  إننا نتوقع بسعادة ليس فقط ما يمكن أن يقدمه التعلم الآلي من الروبوتات من حيث تحسين الإدراك والسيطرة ، ولكن أيضًا ما يمكن أن يقدمه الروبوتات من خلال التعلم الآلي من خلال نماذج جديدة للتعلم الذاتي. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar434898/">https://habr.com/ru/post/ar434898/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar434884/index.html">ترجمة كتاب الظربان الأشغال. مذكرات شخصية عن عملي في شركة لوكهيد</a></li>
<li><a href="../ar434888/index.html">هدية رأس السنة الجديدة من الحي الثنائي</a></li>
<li><a href="../ar434892/index.html">رسم رمز في سويفت ، PaintCode</a></li>
<li><a href="../ar434894/index.html">فن الشامانية أو البرامج الثابتة المخصصة ل Olinuxino. الجزء 1</a></li>
<li><a href="../ar434896/index.html">قاعة مشاهير إلكترونيات المستهلك: قصص أفضل الأدوات خلال الخمسين عامًا الماضية ، الجزء الأول</a></li>
<li><a href="../ar434902/index.html">إنشاء مولد استعلامات مخصص في بيانات الربيع Neo4j (الجزء 1)</a></li>
<li><a href="../ar434906/index.html">اختبارات في C ++ دون وحدات الماكرو والذاكرة الحيوية</a></li>
<li><a href="../ar434908/index.html">مبرمج التعليم - ماذا؟ اين؟ متى؟</a></li>
<li><a href="../ar434912/index.html">إن الأسهم السنوية لبورش تايكان محفوظة بالفعل ، بشكل رئيسي من قبل مالكي تسلا</a></li>
<li><a href="../ar434924/index.html">ما الذي يجب قراءته حول تنظيم أماكن العمل ، والعمل الجماعي وتصميم المساحات للعمل عن بُعد</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
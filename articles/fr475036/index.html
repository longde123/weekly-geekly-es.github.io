<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤒 👩🏿‍⚖️ 🥄 Migration de Cassandra vers Kubernetes: fonctionnalités et solutions 👨‍👧‍👦 ♻️ 👏🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous rencontrons régulièrement la base de données Apache Cassandra et la nécessité de l'exploiter dans le cadre de l'infrastructure basée sur Kubernet...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Migration de Cassandra vers Kubernetes: fonctionnalités et solutions</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/475036/"><img src="https://habrastorage.org/webt/5a/mf/ts/5amftsu06d04r-vmvx9to725ss0.png"><br><br>  Nous rencontrons régulièrement la base de données Apache Cassandra et la nécessité de l'exploiter dans le cadre de l'infrastructure basée sur Kubernetes.  Dans cet article, nous partagerons notre vision des étapes nécessaires, des critères et des solutions existantes (y compris un aperçu des opérateurs) pour la migration de Cassandra vers les K8. <a name="habracut"></a><br><br><h2>  «Qui peut contrôler une femme fera face à l'État» </h2><br>  Qui est Cassandra?  Il s'agit d'un système de stockage distribué conçu pour gérer de grandes quantités de données tout en offrant une haute disponibilité sans un seul point de défaillance.  Le projet n'a guère besoin d'une longue introduction, donc je ne donnerai que les principales caractéristiques de Cassandra, qui seront pertinentes dans le contexte d'un article spécifique: <br><br><ul><li>  Cassandra est écrite en Java. </li><li>  La topologie Cassandra comprend plusieurs niveaux: <ul><li>  Node - une instance déployée de Cassandra; </li><li>  Rack - un groupe d'instances Cassandra, unies par n'importe quel attribut, situées dans un centre de données; </li><li>  Datacenter - la totalité de tous les groupes d'instances Cassandra situés dans un centre de données; </li><li>  Cluster - une collection de tous les centres de données. </li></ul></li><li>  Cassandra utilise une adresse IP pour identifier l'hôte. </li><li>  Pour la vitesse des opérations de lecture et d'écriture, Cassandra stocke une partie des données dans la RAM. </li></ul><br>  Maintenant, pour le déplacement potentiel réel vers Kubernetes. <br><br><h2>  Liste de contrôle pour la migration </h2><br>  En parlant de la migration de Cassandra vers Kubernetes, nous espérons qu'il deviendra plus pratique de la gérer avec le déménagement.  Qu'est-ce qui sera nécessaire pour cela, qu'est-ce qui vous aidera? <br><br><h3>  1. Stockage des données </h3><br>  Comme déjà spécifié, une partie des données que Cassanda stocke dans la RAM - dans <i>Memtable</i> .  Mais il existe un autre élément de données qui est enregistré sur le disque - sous la forme de <i>SSTable</i> .  À ces données s'ajoute le <i>journal de</i> l'entité - les enregistrements de toutes les transactions qui sont également enregistrées sur le disque. <br><br><img src="https://habrastorage.org/webt/2g/2e/ck/2g2eck2szmozuahdx4oinucww9o.png"><br>  <i>Schéma de transaction d'écriture Cassandra</i> <br><br>  Dans Kubernetes, nous pouvons utiliser PersistentVolume pour stocker des données.  Grâce à des mécanismes bien développés, l'utilisation des données dans Kubernetes devient plus facile chaque année. <br><br><img src="https://habrastorage.org/webt/3f/_6/eh/3f_6eh1n50l6dofpd9pds9s4ewg.png"><br>  <i>Pour chaque pod avec Cassandra, nous allouerons notre volume persistant</i> <br><br>  Il est important de noter que Cassandra elle-même implique la réplication des données, offrant des mécanismes intégrés pour cela.  Par conséquent, si vous créez un cluster Cassandra à partir d'un grand nombre de nœuds, il n'est pas nécessaire d'utiliser des systèmes distribués tels que Ceph ou GlusterFS pour stocker des données.  Dans ce cas, il sera logique de stocker des données sur le disque hôte en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des disques persistants locaux</a> ou en montant <code>hostPath</code> . <br><br>  Une autre question est de savoir si vous souhaitez créer un environnement de développement distinct pour chaque branche de fonctionnalité.  Dans ce cas, l'approche correcte serait de soulever un nœud Cassandra et de stocker les données dans un stockage distribué, c'est-à-dire  Ceph et GlusterFS mentionnés seront votre option.  Le développeur sera alors sûr de ne pas perdre de données de test même si l'un des nœuds du cluster Kuberntes est perdu. <br><br><h3>  2. Suivi </h3><br>  Prometheus est un choix pratiquement non alternatif pour la surveillance dans Kubernetes <i>(nous en avons parlé en détail dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport correspondant</a> )</i> .  Comment Cassandra s'en sort-elle avec les exportateurs de métriques pour Prometheus?  Et qu'est-ce qui est encore plus important en quelque sorte, avec des tableaux de bord qui leur conviennent pour Grafana? <br><br><img src="https://habrastorage.org/webt/g0/vq/et/g0vqetugsowufigbskokdr74_2q.png"><br>  <i>Un exemple de l'apparition de graphiques dans Grafana pour Cassandra</i> <br><br>  Il n'y a que deux exportateurs: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jmx_exporter</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cassandra_exporter</a> . <br><br>  Nous avons choisi le premier pour nous, car: <br><br><ol><li>  JMX Exporter se développe et se développe, tandis que Cassandra Exporter n'a pas pu obtenir le soutien approprié de la communauté.  Cassandra Exporter ne prend toujours pas en charge la plupart des versions de Cassandra. </li><li>  Vous pouvez l'exécuter en tant que javaagent en ajoutant l'indicateur <code>-javaagent:&lt;plugin-dir-name&gt;/cassandra-exporter.jar=--listen=:9180</code> . </li><li>  Pour lui, il existe un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tableau de bord adéquat</a> qui est incompatible avec Cassandra Exporter. </li></ol><br><h3>  3. Sélection des primitives Kubernetes </h3><br>  Selon la structure ci-dessus du cluster Cassandra, nous essaierons de traduire tout ce qui y est décrit dans la terminologie Kubernetes: <br><br><ul><li>  Noeud Cassandra → Pod </li><li>  Cassandra Rack → StatefulSet </li><li>  Cassandra Datacenter → pool de StatefulSets </li><li>  Cluster Cassandra → ??? </li></ul><br>  Il s'avère qu'il manque une entité supplémentaire pour gérer l'ensemble du cluster Cassandra à la fois.  Mais si quelque chose n'est pas là, nous pouvons le créer!  Kubernetes dispose d'un moteur de définition de ressources dédié appelé <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Définitions de ressources personnalisées</a> . <br><br><img src="https://habrastorage.org/webt/pt/ob/st/ptobst6r86hra1aakwvpcypws8e.png"><br>  <i>Annonce de ressources supplémentaires pour les journaux et les alertes</i> <br><br>  Mais Custom Resource seul ne veut rien dire: vous avez besoin d'un <b>contrôleur</b> pour cela.  Vous devrez peut-être recourir à l'aide d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">opérateur Kubernetes</a> ... <br><br><h3>  4. Identification des gousses </h3><br>  Le point ci-dessus, nous avons convenu qu'un nœud Cassandra équivaudrait à un pod dans Kubernetes.  Mais les adresses IP du pod seront différentes à chaque fois.  Et l'identification du nœud dans Cassandra se produit précisément sur la base de l'adresse IP ... Il s'avère qu'après chaque retrait du pod, le cluster Cassandra ajoutera un nouveau nœud. <br><br>  Il existe une issue, pas même une: <br><br><ol><li>  Nous pouvons conserver des enregistrements par des identifiants d'hôte (UUID qui identifient de manière unique les instances de Cassandra) ou par des adresses IP et enregistrer tout cela dans certaines structures / tableaux.  La méthode présente deux inconvénients principaux: <br><br><ul><li>  Le risque d'une condition de concurrence lorsque deux nœuds tombent à la fois.  Après la mise à niveau, les nœuds Cassandra iront simultanément demander une adresse IP pour eux-mêmes à partir de la table et rivaliser pour la même ressource. </li><li>  Si le nœud Cassandra a perdu ses données, nous ne pourrons plus l'identifier. </li></ul></li><li>  La deuxième solution semble être un petit hack, mais néanmoins: nous pouvons créer un service avec ClusterIP pour chaque nœud Cassandra.  Problèmes avec cette implémentation: <br><br><ul><li>  S'il y a beaucoup de nœuds dans un cluster Cassandra, nous devrons créer beaucoup de services. </li><li>  La fonctionnalité ClusterIP est implémentée via iptables.  Cela peut être un problème si le cluster Cassandra a plusieurs (1000 ... ou même 100?) Nœuds.  Bien que l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">équilibrage basé sur IPVS</a> puisse résoudre ce problème. </li></ul></li><li>  La troisième solution consiste à utiliser un réseau de nœuds pour les nœuds Cassandra au lieu d'un réseau de pod dédié en activant le <code>hostNetwork: true</code> .  Cette méthode impose certaines restrictions: <br><br><ul><li>  Pour remplacer les nœuds.  Il est nécessaire que le nouvel hôte doit avoir la même adresse IP que le précédent (dans les nuages ​​comme AWS, GCP, c'est presque impossible à faire); </li><li>  En utilisant le réseau de nœuds de cluster, nous commençons à rivaliser pour les ressources réseau.  Par conséquent, mettre sur un nœud de cluster plus d'un pod avec Cassandra sera problématique. </li></ul></li></ol><br><h3>  5. Sauvegardes </h3><br>  Nous voulons garder la version complète des données pour un nœud Cassandra sur un calendrier.  Kubernetes offre une opportunité pratique en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CronJob</a> , mais ici Cassandra insère les bâtons dans les roues. <br><br>  Permettez-moi de vous rappeler qu'une partie des données que Cassandra stocke en mémoire.  Pour effectuer une sauvegarde complète, vous devez transférer les données de la mémoire ( <i>Memtables</i> ) vers le disque ( <i>SSTables</i> ).  À ce stade, le nœud Cassandra cesse d'accepter les connexions, s'arrêtant complètement à partir du cluster. <br><br>  Après cela, une sauvegarde ( <i>instantané</i> ) est supprimée et le schéma ( <i>espace de clés</i> ) est <i>enregistré</i> .  Et puis il s'avère que juste une sauvegarde ne nous donne rien: vous devez enregistrer les identifiants de données dont le nœud Cassandra était responsable - ce sont des jetons spéciaux. <br><br><img src="https://habrastorage.org/webt/ve/el/00/veel00wgdubtmtyhjn2gh9kx4rw.png"><br>  <i>Distribution de jetons pour identifier les données responsables des nœuds Cassandra</i> <br><br>  Un exemple de script pour supprimer Cassandra de Google dans Kubernetes peut être trouvé sur <a href="">ce lien</a> .  Le seul point que le script ne prend pas en compte est le vidage des données sur le nœud avant de supprimer l'instantané.  Autrement dit, la sauvegarde n'est pas effectuée pour l'état actuel, mais pour l'état un peu plus tôt.  Mais cela aide à ne pas mettre le nœud hors de travail, ce qui semble très logique. <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">set</span></span> -eu <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> [[ -z <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> ]]; <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> info <span class="hljs-string"><span class="hljs-string">"Please provide a keyspace"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span> 1 <span class="hljs-keyword"><span class="hljs-keyword">fi</span></span> KEYSPACE=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> result=$(nodetool snapshot <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${KEYSPACE}</span></span></span><span class="hljs-string">"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> [[ $? -ne 0 ]]; <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"Error while making snapshot"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span> 1 <span class="hljs-keyword"><span class="hljs-keyword">fi</span></span> timestamp=$(<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$result</span></span></span><span class="hljs-string">"</span></span> | awk <span class="hljs-string"><span class="hljs-string">'/Snapshot directory: / { print $3 }'</span></span>) mkdir -p /tmp/backup <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> path <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> $(find <span class="hljs-string"><span class="hljs-string">"/var/lib/cassandra/data/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${KEYSPACE}</span></span></span><span class="hljs-string">"</span></span> -name <span class="hljs-variable"><span class="hljs-variable">$timestamp</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> table=$(<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${path}</span></span></span><span class="hljs-string">"</span></span> | awk -F <span class="hljs-string"><span class="hljs-string">"[/-]"</span></span> <span class="hljs-string"><span class="hljs-string">'{print $7}'</span></span>) mkdir /tmp/backup/<span class="hljs-variable"><span class="hljs-variable">$table</span></span> mv <span class="hljs-variable"><span class="hljs-variable">$path</span></span> /tmp/backup/<span class="hljs-variable"><span class="hljs-variable">$table</span></span> <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> tar -zcf /tmp/backup.tar.gz -C /tmp/backup . nodetool clearsnapshot <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${KEYSPACE}</span></span></span><span class="hljs-string">"</span></span></code> </pre> <br>  <i>Exemple de script bash pour supprimer la sauvegarde d'un seul nœud Cassandra</i> <br><br><h2>  Solutions prêtes à l'emploi pour Cassandra à Kubernetes </h2><br>  Que utilisent-ils actuellement pour déployer Cassandra dans Kubernetes, et lequel est le plus adapté aux exigences données? <br><br><h3>  1. Solutions StatefulSet ou Helm Chart </h3><br>  L'utilisation des StatefulSets de base pour démarrer un cluster Cassandra est une bonne option.  En utilisant le modèle Helm chart et Go, vous pouvez fournir à l'utilisateur une interface flexible pour déployer Cassandra. <br><br>  Habituellement, cela fonctionne bien ... jusqu'à ce que quelque chose d'inattendu se produise - par exemple, un nœud tombe en panne.  Les outils Kubernetes standard ne peuvent tout simplement pas prendre en compte toutes les fonctionnalités ci-dessus.  De plus, cette approche est très limitée dans la façon dont elle peut être étendue pour une utilisation plus complexe: remplacement de nœud, sauvegarde, restauration, surveillance, etc. <br><br>  Représentants: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Graphique du référentiel Helm principal</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Graphique de bitnami</a> . </li></ul><br>  Les deux graphiques sont également bons, mais sont sujets aux problèmes décrits ci-dessus. <br><br><h3>  2. Solutions basées sur Kubernetes Operator </h3><br>  Ces options sont plus intéressantes car elles offrent des capacités de gestion de cluster étendues.  Pour concevoir une instruction Cassandra, comme toute autre base de données, un bon modèle ressemble à Sidecar &lt;-&gt; Controller &lt;-&gt; CRD: <br><br><img src="https://habrastorage.org/webt/4y/3b/ac/4y3bacrtm3apdyirfanehdzf82w.png"><br>  <i>Diagramme de gestion des nœuds dans une instruction Cassandra correctement conçue</i> <br><br>  Considérez les opérateurs existants. <br><br><h4>  1. Cassandra-operator par instaclustr </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github</a> </li><li>  Volonté: Alpha </li><li>  Licence: Apache 2.0 </li><li>  Implémenté en: Java </li></ul><br>  Il s'agit en effet d'un projet très prometteur et en développement rapide d'une entreprise qui propose des déploiements gérés par Cassandra.  Il, comme décrit ci-dessus, utilise un conteneur sidecar qui accepte les commandes via HTTP.  Il est écrit en Java, donc il lui manque parfois la fonctionnalité de bibliothèque client-go plus avancée.  En outre, l'opérateur ne prend pas en charge différents racks pour un centre de données. <br><br>  Mais l'opérateur a des avantages tels que la prise en charge de la surveillance, la gestion de cluster de haut niveau à l'aide de CRD et même la documentation sur la suppression des sauvegardes. <br><br><h4>  2. Navigator par Jetstack </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github</a> </li><li>  Volonté: Alpha </li><li>  Licence: Apache 2.0 </li><li>  Mis en œuvre en: Golang </li></ul><br>  Une déclaration pour le déploiement de DB-as-a-Service.  Prend actuellement en charge deux bases de données: Elasticsearch et Cassandra.  Il a des solutions intéressantes comme le contrôle d'accès à la base de données via RBAC (pour cela, son propre navigateur-apiserver distinct est levé).  Un projet intéressant, qui mériterait un examen plus approfondi, mais le dernier engagement a été pris il y a un an et demi, ce qui réduit clairement son potentiel. <br><br><h4>  3. Cassandra-opérateur de vgkowski </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github</a> </li><li>  Volonté: Alpha </li><li>  Licence: Apache 2.0 </li><li>  Mis en œuvre en: Golang </li></ul><br>  Ils ne l'ont pas considéré «sérieusement», car le dernier commit sur le référentiel remonte à plus d'un an.  Le développement des opérateurs est abandonné: la dernière version de Kubernetes, déclarée prise en charge, est la 1.9. <br><br><h4>  4. Cassandra-opérateur de Rook </h4><br><ul><li>  <a href="">Github</a> </li><li>  Volonté: Alpha </li><li>  Licence: Apache 2.0 </li><li>  Mis en œuvre en: Golang </li></ul><br>  Un opérateur dont le développement ne va pas aussi vite que nous le souhaiterions.  Il a une structure CRD bien pensée pour gérer le cluster, résout le problème de l'identification des nœuds en utilisant Service avec ClusterIP (le même "hack") ... mais pour l'instant c'est tout.  Il n'y a pas de surveillance et de sauvegardes prêtes à l'emploi pour l'instant (au fait, nous avons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">commencé à nous</a> surveiller).  Un point intéressant est qu'en utilisant cet opérateur, vous pouvez également déployer ScyllaDB. <br><br>  <i>NB: Nous avons utilisé cet opérateur avec des modifications mineures dans l'un de nos projets.</i>  <i>Il n'y a eu aucun problème dans le travail de l'opérateur pendant toute l'opération (~ 4 mois de fonctionnement).</i> <br><br><h4>  5. CassKop par Orange </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github</a> </li><li>  Volonté: Alpha </li><li>  Licence: Apache 2.0 </li><li>  Mis en œuvre en: Golang </li></ul><br>  Le plus jeune opérateur de la liste: le premier commit a été effectué le 23 mai 2019.  Déjà, il a dans son arsenal un grand nombre de fonctionnalités de notre liste, dont plus de détails peuvent être trouvés dans le référentiel du projet.  L'opérateur est basé sur le populaire operator-sdk.  Prend en charge la surveillance prête à l'emploi.  La principale différence avec les autres opérateurs est l'utilisation du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plugin CassKop</a> , implémenté en Python et utilisé pour la communication entre les nœuds Cassandra. <br><br><h2>  Conclusions </h2><br>  Le nombre d'approches et d'options possibles pour porter Cassandra vers Kubernetes parle de lui-même: le sujet est en demande. <br><br>  À ce stade, vous pouvez essayer l'une des solutions ci-dessus à vos risques et périls: aucun des développeurs ne garantit le travail à 100% de leur solution dans l'environnement de production.  Mais maintenant, de nombreux produits semblent prometteurs d'essayer de les utiliser dans les stands de développement. <br><br>  Je pense qu'à l'avenir, cette femme sur le navire devra partir! <br><br><h2>  PS </h2><br>  Lisez aussi dans notre blog: <br><br><ul><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Migration sans entrave de MongoDB vers Kubernetes</a> »; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Migration sans obstacle de RabbitMQ vers Kubernetes</a> »; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bases de données et Kubernetes (revue et reportage vidéo)</a> »; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">K8s trucs et astuces: Accélérer le bootstrap de grandes bases de données.</a> " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr475036/">https://habr.com/ru/post/fr475036/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr475024/index.html">La course à pied est un sport idéal pour un travailleur à distance. Partie 1: le chemin vers la première course d'une centaine de kilomètres</a></li>
<li><a href="../fr475026/index.html">3 histoires de crash de Kubernetes en production: anti-affinité, arrêt gracieux, webhook</a></li>
<li><a href="../fr475028/index.html">Observations sur l'application du ML en affaires sur les actions ŽijemeIT</a></li>
<li><a href="../fr475032/index.html">Gartner Hype Cycle 2019: débriefing</a></li>
<li><a href="../fr475034/index.html">Graphique dans le navigateur pour Arduino et STM32</a></li>
<li><a href="../fr475038/index.html">La première série de "Mathématiques appliquées et informatique" au HSE de Saint-Pétersbourg: qui sont-ils et comment travailler avec eux?</a></li>
<li><a href="../fr475044/index.html">Construire votre propre serveur sans serveur basé sur Fn</a></li>
<li><a href="../fr475046/index.html">La fin justifie-t-elle les moyens? (!) SEO noir et gris</a></li>
<li><a href="../fr475048/index.html">Explication intuitive du test d'hypothèse et valeur de p</a></li>
<li><a href="../fr475050/index.html">ESports - jouer, s'engager</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç¨ üë©üèº‚ÄçüöÄ üë©üèΩ‚Äç‚öïÔ∏è Exp√©rience de mod√©lisation de l'√©quipe Computer Vision Mail.ru üëÉüèº ü§ó üê¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Je m'appelle Eduard Tyantov, je dirige l'√©quipe de vision par ordinateur du groupe Mail.ru. Au cours de plusieurs ann√©es de notre existence, notre √©qu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Exp√©rience de mod√©lisation de l'√©quipe Computer Vision Mail.ru</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/460307/"><img src="https://habrastorage.org/webt/zz/gc/py/zzgcpycxxdaz-0a657wzkvjlvos.jpeg"><br><br>  Je m'appelle Eduard Tyantov, je dirige l'√©quipe de vision par ordinateur du groupe Mail.ru.  Au cours de plusieurs ann√©es de notre existence, notre √©quipe a r√©solu des dizaines de probl√®mes de vision par ordinateur, et aujourd'hui je vais vous parler des m√©thodes que nous utilisons pour cr√©er avec succ√®s des mod√®les d'apprentissage automatique qui fonctionnent sur un large √©ventail de t√¢ches.  Je partagerai des astuces qui peuvent acc√©l√©rer le mod√®le √† toutes les √©tapes: d√©finition d'une t√¢che, pr√©paration des donn√©es, formation et d√©ploiement en production. <br><a name="habracut"></a><br><h2>  Vision par ordinateur √† Mail.ru </h2><br>  Pour commencer, qu'est-ce que la vision par ordinateur dans Mail.ru et quels projets nous faisons.  Nous proposons des solutions dans nos produits, telles que Mail, Mail.ru Cloud (une application pour stocker des photos et des vid√©os), Vision (solutions B2B bas√©es sur la vision par ordinateur) et autres.  Je vais donner quelques exemples. <br><br>  Le Cloud (c'est notre premier et principal client) contient 60 milliards de photos.  Nous d√©veloppons diverses fonctionnalit√©s bas√©es sur l'apprentissage automatique pour leur traitement intelligent, par exemple, la reconnaissance faciale et les visites touristiques ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">il y a un article s√©par√© √† ce sujet</a> ).  Toutes les photos des utilisateurs sont ex√©cut√©es via des mod√®les de reconnaissance, ce qui vous permet d'organiser une recherche et un regroupement par personnes, tags, villes et pays visit√©s, etc. <br><br><img src="https://habrastorage.org/webt/dc/ls/ug/dclsugao8xumevprode0ift5dxq.jpeg"><img src="https://habrastorage.org/webt/zr/bo/rd/zrbordgq4zygrzpzvmsg5x0nt6i.jpeg"><br><br>  Pour Mail, nous avons fait l'OCR - reconnaissance du texte d'une image.  Aujourd'hui, je vais vous en dire un peu plus sur lui. <br><br>  Pour les produits B2B, nous reconnaissons et comptons les personnes dans les files d'attente.  Par exemple, il y a une file d'attente pour les remont√©es m√©caniques et vous devez calculer le nombre de personnes qui s'y trouvent.  Pour commencer, afin de tester la technologie et le jeu, nous avons d√©ploy√© un prototype dans la salle √† manger du bureau.  Il y a plusieurs caisses et, par cons√©quent, plusieurs files d'attente, et nous, en utilisant plusieurs cam√©ras (une pour chacune des files d'attente), en utilisant le mod√®le, nous calculons combien de personnes sont dans les files d'attente et combien de minutes approximatives il reste dans chacune d'elles.  De cette fa√ßon, nous pouvons mieux √©quilibrer les lignes dans la salle √† manger. <br><br><img src="https://habrastorage.org/webt/yr/yq/hb/yryqhbu5zqhxm_fozg-4ygkz6i4.jpeg"><br><br><h2>  √ânonc√© du probl√®me </h2><br>  Commen√ßons par la partie critique de toute t√¢che - sa formulation.  Presque n'importe quel d√©veloppement ML prend au moins un mois (c'est au mieux quand vous savez quoi faire), et dans la plupart des cas plusieurs mois.  Si la t√¢che est incorrecte ou inexacte, il y a une grande chance √† la fin du travail d'entendre le chef de produit quelque chose dans l'esprit: ¬´Tout va mal.  Ce n'est pas bon.  Je voulais autre chose. "  Pour √©viter que cela ne se produise, vous devez prendre certaines mesures.  Quelle est la particularit√© des produits √† base de ML?  Contrairement √† la t√¢che de d√©velopper un site, la t√¢che d'apprentissage automatique ne peut pas √™tre formalis√©e avec du texte seul.  De plus, en r√®gle g√©n√©rale, il semble √† une personne non pr√©par√©e que tout est d√©j√† √©vident, et il est simplement n√©cessaire de tout faire "magnifiquement".  Mais quels sont les petits d√©tails, le gestionnaire de t√¢ches ne le sait peut-√™tre m√™me pas, n'y a jamais pens√© et ne r√©fl√©chira pas avant d'avoir vu le produit final et de dire: ¬´Qu'avez-vous fait?¬ª <br><br><h2>  Les probl√®mes </h2><br>  Comprenons par exemple quels probl√®mes peuvent √™tre.  Supposons que vous ayez une t√¢che de reconnaissance faciale.  Vous le recevez, r√©jouissez-vous et appelez votre m√®re: "Hourra, une t√¢che int√©ressante!"  Mais est-il possible de se d√©composer directement et de commencer √† le faire?  Si vous faites cela, alors √† la fin, vous pouvez vous attendre √† des surprises: <br><br><ul><li>  Il existe diff√©rentes nationalit√©s.  Par exemple, il n'y avait ni Asiatiques ni personne dans le jeu de donn√©es.  Votre mod√®le ne sait donc pas du tout les reconna√Ætre et le produit en a besoin.  Ou vice versa, vous avez pass√© trois mois suppl√©mentaires sur la r√©vision, et le produit n'aura que des Caucasiens, et ce n'√©tait pas n√©cessaire. <br></li><li>  Il y a des enfants.  Pour les p√®res sans enfant comme moi, tous les enfants sont sur un m√™me visage.  Je suis tout √† fait d'accord avec le mod√®le, quand elle envoie tous les enfants dans un cluster - on ne sait vraiment pas en quoi la majorit√© des enfants diff√®rent!  ;) Mais les gens qui ont des enfants ont une opinion compl√®tement diff√©rente.  Habituellement, ce sont aussi vos dirigeants.  Ou il y a encore des erreurs de reconnaissance amusantes lorsque la t√™te de l'enfant est compar√©e avec succ√®s au coude ou √† la t√™te d'un homme chauve (histoire vraie). <br></li><li>  Que faire des personnages peints n'est g√©n√©ralement pas clair.  Dois-je les reconna√Ætre ou non? <br></li></ul><br>  Ces aspects de la t√¢che sont tr√®s importants √† identifier au d√©but.  Par cons√©quent, vous devez travailler et communiquer avec le gestionnaire d√®s le d√©but ¬´sur les donn√©es¬ª.  Les explications orales ne peuvent √™tre accept√©es.  Il est n√©cessaire de regarder les donn√©es.  Il est souhaitable de la m√™me distribution sur laquelle le mod√®le fonctionnera. <br><br>  Id√©alement, au cours de cette discussion, un ensemble de donn√©es de test sera obtenu sur lequel vous pourrez enfin ex√©cuter le mod√®le et v√©rifier s'il fonctionne comme le gestionnaire le souhaitait.  Il est conseill√© de donner une partie de l'ensemble de donn√©es de test au gestionnaire lui-m√™me, afin que vous n'y ayez aucun acc√®s.  Parce que vous pouvez facilement vous recycler sur cet ensemble de test, vous √™tes un d√©veloppeur ML! <br><br>  D√©finir une t√¢che en ML est un travail constant entre un chef de produit et un sp√©cialiste du ML.  M√™me si au d√©but vous d√©finissez bien la t√¢che, alors que le mod√®le se d√©veloppe, de plus en plus de nouveaux probl√®mes appara√Ætront, de nouvelles fonctionnalit√©s que vous apprendrez sur vos donn√©es.  Tout cela doit √™tre constamment discut√© avec le manager.  Les bons managers diffusent toujours √† leurs √©quipes ML qu'ils doivent prendre leurs responsabilit√©s et aider le manager √† d√©finir les t√¢ches. <br><br>  Pourquoi  L'apprentissage automatique est un domaine assez nouveau.  Les gestionnaires n'ont pas (ou ont peu) d'exp√©rience dans la gestion de telles t√¢ches.  √Ä quelle fr√©quence les gens apprennent-ils √† r√©soudre de nouveaux probl√®mes?  Sur les erreurs.  Si vous ne voulez pas que votre projet pr√©f√©r√© devienne une erreur, vous devez vous impliquer et prendre vos responsabilit√©s, apprendre au chef de produit √† d√©finir correctement la t√¢che, d√©velopper des listes de contr√¥le et des politiques;  tout cela aide beaucoup.  Chaque fois que je me retire (ou que quelqu'un de mes coll√®gues me tire) quand une nouvelle t√¢che int√©ressante arrive, et nous courons pour le faire.  Tout ce que je viens de vous dire, je l'oublie moi-m√™me.  Par cons√©quent, il est important d'avoir une sorte de liste de contr√¥le pour vous v√©rifier. <br><br><h2>  Les donn√©es </h2><br>  Les donn√©es sont super importantes en ML.  Pour un apprentissage en profondeur, plus vous alimentez de mod√®les, mieux c'est.  Le graphique bleu montre que les mod√®les d'apprentissage en profondeur s'am√©liorent g√©n√©ralement consid√©rablement lorsque des donn√©es sont ajout√©es. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1x/wf/bb/1xwfbbc7-os0p9wjc8y_2iiyn10.jpeg"></div><br>  Et les ¬´anciens¬ª algorithmes (classiques) d'un certain point ne peuvent plus s'am√©liorer. <br><br>  Les jeux de donn√©es ML sont g√©n√©ralement sales.  Ils ont √©t√© marqu√©s par des gens qui mentent toujours.  Les √©valuateurs sont souvent inattentifs et font beaucoup d'erreurs.  Nous utilisons cette technique: nous prenons les donn√©es que nous avons, formons le mod√®le sur elles, puis √† l'aide de ce mod√®le, nous effa√ßons les donn√©es et r√©p√©tons le cycle. <br><br>  Examinons de plus pr√®s l'exemple de la m√™me reconnaissance de visage.  Disons que nous avons t√©l√©charg√© les avatars des utilisateurs de VKontakte.  Par exemple, nous avons un profil utilisateur avec 4 avatars.  Nous d√©tectons les visages qui se trouvent sur les 4 images et parcourons le mod√®le de reconnaissance des visages.  Nous obtenons donc des int√©grations de personnes, √† l'aide desquelles elles peuvent ¬´coller¬ª des personnes similaires en groupes (cluster).  Ensuite, nous s√©lectionnons le plus grand cluster, en supposant que les avatars de l'utilisateur contiennent principalement son visage.  En cons√©quence, nous pouvons nettoyer toutes les autres faces (qui sont du bruit) de cette fa√ßon.  Apr√®s cela, nous pouvons r√©p√©ter le cycle √† nouveau: sur les donn√©es nettoy√©es, former le mod√®le et l'utiliser pour nettoyer les donn√©es.  Vous pouvez r√©p√©ter plusieurs fois. <br><br>  Presque toujours pour un tel regroupement, nous utilisons des algorithmes CLink.  Il s'agit d'un algorithme de regroupement hi√©rarchique dans lequel il est tr√®s pratique de d√©finir une valeur de seuil pour ¬´coller¬ª des objets similaires (c'est exactement ce qui est requis pour le nettoyage).  CLink g√©n√®re des grappes sph√©riques.  Ceci est important, car nous apprenons souvent l'espace m√©trique de ces int√©grations.  L'algorithme a une complexit√© de O (n <sup>2</sup> ), qui, en principe, est d'env. <br><br>  Parfois, les donn√©es sont si difficiles √† obtenir ou √† baliser qu'il n'y a plus rien √† faire d√®s que vous commencez √† les g√©n√©rer.  L'approche g√©n√©rative vous permet de produire une √©norme quantit√© de donn√©es.  Mais pour cela, vous devez programmer quelque chose.  L'exemple le plus simple est l'OCR, la reconnaissance de texte sur les images.  Le balisage du texte pour cette t√¢che est extr√™mement co√ªteux et bruyant: vous devez mettre en surbrillance chaque ligne et chaque mot, signer le texte, etc.  Les √©valuateurs (personnes de balisage) occuperont une centaine de pages de texte pendant tr√®s longtemps, et beaucoup plus est n√©cessaire pour la formation.  √âvidemment, vous pouvez d'une mani√®re ou d'une autre g√©n√©rer le texte et le ¬´d√©placer¬ª d'une mani√®re ou d'une autre pour que le mod√®le en tire des le√ßons. <br><br>  Nous avons constat√© par nous-m√™mes que la bo√Æte √† outils la meilleure et la plus pratique pour cette t√¢che est une combinaison de PIL, OpenCV et Numpy.  Ils ont tout pour travailler avec du texte.  Vous pouvez compliquer l'image avec du texte de toute fa√ßon afin que le r√©seau ne se reconstitue pas pour des exemples simples. <br><br><img src="https://habrastorage.org/webt/cv/zd/ib/cvzdibgjrtt_qnyro4u8-zcgdgw.png"><br><br>  Parfois, nous avons besoin d'objets du monde r√©el.  Par exemple, des marchandises sur les √©tag√®res des magasins.  L'une de ces images est g√©n√©r√©e automatiquement.  Pensez-vous √† gauche ou √† droite? <br><br><img src="https://habrastorage.org/webt/os/py/gi/ospygi-cu95vtgblk8ekol86qak.jpeg"><br><br>  En fait, les deux sont g√©n√©r√©s.  Si vous ne regardez pas les petits d√©tails, vous ne remarquerez pas de diff√©rences par rapport √† la r√©alit√©.  Nous le faisons en utilisant Blender (analogique de 3dmax). <br><br><img src="https://habrastorage.org/webt/wq/7i/hd/wq7ihd3zrqp0fevkbdylp96hm0m.jpeg"><br><br>  Le principal avantage important est qu'il est open source.  Il poss√®de une excellente API Python, qui vous permet de placer directement des objets dans le code, de configurer et de randomiser le processus et enfin d'obtenir un ensemble de donn√©es diversifi√©. <br><br>  Pour le rendu, le lancer de rayons est utilis√©.  C'est une proc√©dure assez co√ªteuse, mais elle produit un r√©sultat d'excellente qualit√©.  La question la plus importante: o√π trouver des mod√®les d'objets?  En r√®gle g√©n√©rale, ils doivent √™tre achet√©s.  Mais si vous √™tes un pauvre √©tudiant et que vous voulez exp√©rimenter quelque chose, il y a toujours des torrents.  Il est clair que pour la production, vous devez acheter ou commander des mod√®les rendus √† quelqu'un. <br><br>  C'est tout sur les donn√©es.  Passons √† l'apprentissage. <br><br><h2>  Apprentissage m√©trique </h2><br>  L'objectif de l'apprentissage m√©trique est de former le r√©seau afin qu'il traduise des objets similaires dans des r√©gions similaires dans l'espace m√©trique d'int√©gration.  Je vais √† nouveau donner un exemple avec les vues, ce qui est inhabituel car il s'agit essentiellement d'une t√¢che de classification, mais pour des dizaines de milliers de classes.  Il semblerait, pourquoi ici l'apprentissage m√©trique, qui, en r√®gle g√©n√©rale, est appropri√© dans des t√¢ches telles que la reconnaissance faciale?  Essayons de le comprendre. <br><br>  Si vous utilisez des pertes standard lors de la formation d'un probl√®me de classification, par exemple, Softmax, alors les classes dans l'espace m√©trique sont bien s√©par√©es, mais dans l'espace d'int√©gration, les points des diff√©rentes classes peuvent √™tre proches les uns des autres ... <br><br><img src="https://habrastorage.org/webt/od/fl/aq/odflaq4hgygf8vvrnftdrdeinh8.jpeg"><br><br>  Cela cr√©e des erreurs potentielles lors de la g√©n√©ralisation, comme  une l√©g√®re diff√©rence dans les donn√©es source peut modifier le r√©sultat de la classification.  Nous aimerions vraiment que les points soient plus compacts.  Pour cela, diff√©rentes techniques d'apprentissage m√©trique sont utilis√©es.  Par exemple, Center loss, dont l'id√©e est extr√™mement simple: on rassemble simplement des points vers le centre d'apprentissage de chaque classe, qui finit par devenir plus compact. <br><br><img src="https://habrastorage.org/webt/am/pf/nw/ampfnwjhkn4idpxob_tjpvg3sey.jpeg"><br><br>  La perte de centre est programm√©e litt√©ralement sur 10 lignes en Python, elle fonctionne tr√®s rapidement, et surtout, elle am√©liore la qualit√© de la classification, car  la compacit√© conduit √† une meilleure capacit√© de g√©n√©ralisation. <br><br><h2>  Softmax angulaire </h2><br>  Nous avons essay√© de nombreuses m√©thodes d'apprentissage m√©triques diff√©rentes et sommes parvenus √† la conclusion qu'Angular Softmax produit les meilleurs r√©sultats.  Dans la communaut√© des chercheurs, il est √©galement consid√©r√© comme √©tant √† la pointe de la technologie. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ks/gx/ap/ksgxapfkweb9invhas0g2dz2w2s.jpeg"></div><br>  Regardons un exemple de reconnaissance faciale.  Ici, nous avons deux personnes.  Si vous utilisez le Softmax standard, un plan de division sera dessin√© entre eux - bas√© sur deux vecteurs de poids.  Si nous faisons la norme d'int√©gration 1, alors les points se situeront sur le cercle, c'est-√†-dire  sur la sph√®re dans le cas √† n dimensions (image √† droite). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/by/zf/a9/byzfa9okk0cry7vcx6vg4n3dsd8.jpeg"></div><br>  Ensuite, vous pouvez voir que l'angle entre elles est d√©j√† responsable de la s√©paration des classes, et il peut √™tre optimis√©.  Mais cela ne suffit pas.  Si nous continuons √† optimiser l'angle, la t√¢che ne changera pas en fait, car  nous l'avons simplement reformul√© en d'autres termes.  Je me souviens que notre objectif est de rendre les grappes plus compactes. <br><br>  Il est en quelque sorte n√©cessaire d'exiger un angle plus grand entre les classes - pour compliquer la t√¢che du r√©seau neuronal.  Par exemple, de telle mani√®re qu'elle pense que l'angle entre les points d'une classe est plus grand qu'en r√©alit√©, de sorte qu'elle essaie de les comprimer de plus en plus.  Ceci est r√©alis√© en introduisant le param√®tre m, qui contr√¥le la diff√©rence dans les cosinus des angles. <br><br><img src="https://habrastorage.org/webt/lx/fk/xc/lxfkxcrdodlg-wpoasqxcws3gao.jpeg"><br><br>  Il existe plusieurs options pour Angular Softmax.  Ils jouent tous avec le fait que multipliez par m cet angle ou ajoutez, ou multipliez et ajoutez.  √âtat de l'art - ArcFace. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/_i/zw/ye_izwbkvqmr0-fxpxahc2uty6e.gif"></div><br>  En fait, celui-ci est assez facile √† int√©grer dans la classification des pipelines. <br><br><img src="https://habrastorage.org/webt/05/gi/vt/05givtsihtduioo9co9f0jzj5hk.jpeg"><br><br>  Prenons l'exemple de Jack Nicholson.  Nous ex√©cutons sa photo √† travers la grille dans le processus d'apprentissage.  Nous obtenons l'int√©gration, nous parcourons la couche lin√©aire pour la classification et nous obtenons des scores √† la sortie, qui refl√®tent le degr√© d'appartenance √† la classe.  Dans ce cas, la photographie de Nicholson a une vitesse de 20, la plus grande.  De plus, selon la formule d'ArcFace, nous r√©duisons la vitesse de 20 √† 13 (fait uniquement pour la classe de v√©rit√© terrain), compliquant la t√¢che pour le r√©seau neuronal.  Ensuite, nous faisons tout comme d'habitude: Softmax + Cross Entropy. <br><br>  Au total, la couche lin√©aire habituelle est remplac√©e par la couche ArcFace, qui n'est pas √©crite en 10, mais en 20 lignes, mais donne d'excellents r√©sultats et un minimum de surcharge pour la mise en ≈ìuvre.  Par cons√©quent, ArcFace est meilleur que la plupart des autres m√©thodes pour la plupart des t√¢ches.  Il s'int√®gre parfaitement aux t√¢ches de classification et am√©liore la qualit√©. <br><br><h2>  Transfert d'apprentissage </h2><br>  La deuxi√®me chose dont je voulais parler est l'apprentissage par transfert - en utilisant un r√©seau pr√©-form√© sur une t√¢che similaire pour se recycler sur une nouvelle t√¢che.  Ainsi, les connaissances sont transf√©r√©es d'une t√¢che √† l'autre. <br><br>  Nous avons fait notre recherche d'images.  L'essence de la t√¢che est de produire des s√©mantiquement similaires √† partir de la base de donn√©es dans l'image (requ√™te). <br><br><img src="https://habrastorage.org/webt/hp/m-/x2/hpm-x27etg2zdagi9wupvgjdqtm.jpeg"><br><br>  Il est logique de prendre un r√©seau qui a d√©j√† √©tudi√© un grand nombre d'images - sur des ensembles de donn√©es ImageNet ou OpenImages, dans lesquels il y a des millions d'images, et de s'entra√Æner sur nos donn√©es. <br><br><img src="https://habrastorage.org/webt/fn/hq/c-/fnhqc-efmzfkuqmwocx_zy4wp1a.jpeg"><br><br>  Nous avons collect√© des donn√©es pour cette t√¢che sur la base de la similitude des images et des clics des utilisateurs et obtenu 200 000 cours.  Apr√®s une formation avec ArFace, nous avons obtenu le r√©sultat suivant. <br><br><img src="https://habrastorage.org/webt/da/gu/dd/daguddqmsfbsvj9rdrix-slta4u.jpeg"><br><br>  Dans l'image ci-dessus, nous voyons que pour le p√©lican demand√©, les moineaux sont √©galement entr√©s dans le probl√®me.  C'est-√†-dire  l'int√©gration s'est av√©r√©e s√©mantiquement vraie - c'est un oiseau, mais racialement infid√®le.  Le plus ennuyeux est que le mod√®le original avec lequel nous nous sommes recycl√©s connaissait ces classes et les distinguait parfaitement.  Nous voyons ici l'effet commun √† tous les r√©seaux de neurones, appel√© l'oubli catastrophique.  C'est-√†-dire que pendant le recyclage, le r√©seau oublie la t√¢che pr√©c√©dente, parfois m√™me compl√®tement.  C'est exactement ce qui emp√™che dans cette t√¢che d'obtenir une meilleure qualit√©. <br><br><h2>  Distillation des connaissances </h2><br>  Ceci est trait√© en utilisant une technique appel√©e distillation des connaissances, lorsqu'un r√©seau en enseigne un autre et ¬´lui transf√®re ses connaissances¬ª.  A quoi cela ressemble (pipeline de formation complet dans l'image ci-dessous). <br><br><img src="https://habrastorage.org/webt/-j/bx/kc/-jbxkco1joxnxva7ec8luts-hii.jpeg"><br><br>  Nous avons d√©j√† un pipeline de classification familier avec Arcface.  Rappelons que nous avons un r√©seau avec lequel nous sommes pr√©tendus.  Nous l'avons gel√© et calculons simplement ses plong√©es dans toutes les photos dans lesquelles nous apprenons notre r√©seau, et obtenons les classes des classes OpenImages: p√©licans, moineaux, voitures, personnes, etc. ... Nous bougeons du r√©seau neuronal form√© d'origine et apprenons une autre int√©gration pour les classes OpenImages, qui produit des scores similaires.  Avec BCE, nous faisons en sorte que le r√©seau produise une distribution similaire de ces scores.  Ainsi, d'une part, nous apprenons une nouvelle t√¢che (en haut de l'image), mais nous faisons aussi en sorte que le r√©seau n'oublie pas ses racines (en bas) - rappelez-vous les classes qu'il connaissait.  Si vous √©quilibrez correctement les gradients dans une proportion conditionnelle de 50/50, cela laissera tous les p√©licans en haut et jettera tous les moineaux √† partir de l√†. <br><br><img src="https://habrastorage.org/webt/vx/kf/ha/vxkfhatx6n6heozx_xpbhgg_zuq.jpeg"><br><br>  Lorsque nous l'avons appliqu√©, nous avons obtenu un pourcentage complet dans le mAP.  C'est beaucoup. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Mod√®le </th><th>  mAP </th></tr><tr><td>  Arcface </td><td>  92,8 </td></tr><tr><td>  + Distillation de connaissances </td><td>  93,8 (+ 1%) </td></tr></tbody></table></div><br>  Donc, si votre r√©seau oublie la t√¢che pr√©c√©dente, traitez en utilisant la distillation des connaissances - cela fonctionne tr√®s bien. <br><br><h2>  T√™tes suppl√©mentaires </h2><br>  L'id√©e de base est tr√®s simple.  Encore une fois sur l'exemple de la reconnaissance faciale.  Nous avons un ensemble de personnes dans l'ensemble de donn√©es.  Mais souvent, dans les jeux de donn√©es, il existe d'autres caract√©ristiques du visage.  Par exemple, quel √¢ge, quelle couleur des yeux, etc.  Tout cela peut √™tre ajout√© comme un ajout suppl√©mentaire.  signal: apprenez √† chaque t√™te √† pr√©dire ces donn√©es.  Ainsi, notre r√©seau re√ßoit un signal plus diversifi√© et, par cons√©quent, il peut √™tre pr√©f√©rable d'apprendre la t√¢che principale. <br><br><img src="https://habrastorage.org/webt/43/to/rp/43torpgdsj-cce3akz2pfe3me9a.jpeg"><br><br>  Un autre exemple: la d√©tection de file d'attente. <br><br><img src="https://habrastorage.org/webt/im/cj/tk/imcjtk4jdpqwcphgrzjldnckfgq.jpeg"><br><br>  Souvent, dans les ensembles de donn√©es avec des personnes, en plus du corps, il y a un marquage s√©par√© de la position de la t√™te, qui, √©videmment, peut √™tre utilis√©.  Par cons√©quent, nous avons ajout√© au r√©seau la pr√©diction de la zone de d√©limitation de la personne et la pr√©diction de la zone de d√©limitation de la t√™te, et nous avons obtenu une augmentation de 0,5% de la pr√©cision (mAP), ce qui est d√©cent.  Et surtout - gratuit en termes de performances, car  en production, la t√™te suppl√©mentaire est ¬´d√©connect√©e¬ª. <br><br><img src="https://habrastorage.org/webt/gl/4y/5l/gl4y5lhjiikvdewhfntr7bdhkwu.jpeg"><br><br><h2>  OCR </h2><br>  Un cas plus complexe et int√©ressant est l'OCR, d√©j√† mentionn√© ci-dessus.  Le pipeline standard est comme √ßa. <br><br><img src="https://habrastorage.org/webt/i8/nj/dd/i8njddzf7z3ux8wcawjqmjvkyri.jpeg"><br><br>  Qu'il y ait une affiche avec un pingouin, le texte est √©crit dessus.  En utilisant le mod√®le de d√©tection, nous mettons en √©vidence ce texte.  De plus, nous alimentons ce texte √† l'entr√©e du mod√®le de reconnaissance, qui produit le texte reconnu.  Disons que notre r√©seau est erron√© et au lieu de ¬´i¬ª dans le mot pingouins pr√©dit ¬´l¬ª.  Il s'agit en fait d'un probl√®me tr√®s courant dans l'OCR lorsque le r√©seau confond des caract√®res similaires.  La question est de savoir comment √©viter cela - traduire les pingouins en pingouins?  Lorsqu'une personne regarde cet exemple, il est √©vident pour lui que c'est une erreur, car  il a une connaissance de la structure de la langue.  Par cons√©quent, les connaissances sur la distribution des caract√®res et des mots dans la langue doivent √™tre int√©gr√©es dans le mod√®le. <br><br>  Nous avons utilis√© pour cela une chose appel√©e BPE (codage par paire d'octets).  Il s'agit d'un algorithme de compression qui a √©t√© g√©n√©ralement invent√© dans les ann√©es 90 non pas pour l'apprentissage automatique, mais maintenant il est tr√®s populaire et est utilis√© dans l'apprentissage en profondeur.  La signification de l'algorithme est que les sous-s√©quences fr√©quentes dans le texte sont remplac√©es par de nouveaux caract√®res.  Supposons que nous ayons la cha√Æne "aaabdaaabac" et que nous voulons obtenir un BPE pour cela.  Nous constatons que la paire de caract√®res ¬´aa¬ª est la plus fr√©quente dans notre mot.  Nous le rempla√ßons par un nouveau caract√®re ¬´Z¬ª, nous obtenons la cha√Æne ¬´ZabdZabac¬ª.  Nous r√©p√©tons l'it√©ration: nous voyons que ab est la sous-s√©quence la plus fr√©quente, remplacez-la par "Y", nous obtenons la cha√Æne "ZYdZYac".  Maintenant, ¬´ZY¬ª est la sous-s√©quence la plus fr√©quente, nous la rempla√ßons par ¬´X¬ª, nous obtenons ¬´XdXac¬ª.  Ainsi, nous codons certaines d√©pendances statistiques dans la distribution du texte.  Si nous rencontrons un mot dans lequel il y a des sous-s√©quences tr√®s ¬´√©tranges¬ª (rares pour le corps enseignant), alors ce mot est suspect. <br><br> <code>aaabdaaabac <br> ZabdZabac Z=aa <br> <font color="#fa7566">ZY</font> d <font color="#fa7566">ZY</font> ac Y=ab <br> <font color="#fa7566">X</font> d <font color="#fa7566">X</font> ac X=ZY</code> <br> <br>  Comment tout cela s'inscrit dans la reconnaissance. <br><br><img src="https://habrastorage.org/webt/zq/fm/1v/zqfm1vzn2szxicl-txouuvguwj0.jpeg"><br><br>  Nous avons mis en √©vidence le mot ¬´pingouin¬ª, l'avons envoy√© au r√©seau neuronal convolutif, qui a produit une int√©gration spatiale (un vecteur de longueur fixe, par exemple 512).  Ce vecteur code les informations de symboles spatiaux.  Ensuite, nous utilisons un r√©seau de r√©currence (UPD: en fait, nous utilisons d√©j√† le mod√®le Transformer), il donne des √©tats cach√©s (barres vertes), dans chacun desquels la distribution de probabilit√© est cousue - qui, selon le mod√®le, le symbole est repr√©sent√© √† une position sp√©cifique.  Ensuite, en utilisant CTC-Loss, nous d√©roulons ces √©tats et obtenons notre pr√©diction pour le mot entier, mais avec une erreur: L √† la place de i. <br><br><img src="https://habrastorage.org/webt/jc/p4/6k/jcp46k4rb7hz_b18kbbsbgm_aac.jpeg"><br><br>  Int√©gration de BPE dans le pipeline.  Nous voulons √©viter de pr√©dire des caract√®res individuels √† des mots, nous nous √©loignons donc des √©tats dans lesquels les informations sur les caract√®res sont cousues et d√©finissons un autre r√©seau r√©cursif sur eux;  elle pr√©dit BPE.  Dans le cas de l'erreur d√©crite ci-dessus, 3 BPE sont obtenus: "peng", "ul", "ns".  Cela diff√®re consid√©rablement de la s√©quence correcte pour le mot pingouins, c'est-√†-dire stylo, gu, ins.  Si vous regardez cela du point de vue de la formation des mod√®les, alors, dans une pr√©diction caract√®re par mot, le r√©seau a fait une erreur dans une seule lettre sur huit (erreur de 12,5%);  et en termes d'EBP, elle s'est tromp√©e √† 100% en pr√©disant les 3 EPI de mani√®re incorrecte.  C'est un signal beaucoup plus important pour le r√©seau que quelque chose s'est mal pass√© et que vous devez corriger votre comportement.  Lorsque nous avons impl√©ment√© cela, nous avons pu corriger des erreurs de ce type et r√©duire le taux d'erreur sur les mots de 0,25% - c'est beaucoup.  Cette t√™te suppl√©mentaire est supprim√©e lors de l'inf√©rence, remplissant son r√¥le dans la formation. <br><br><h2>  FP16 </h2><br>  La derni√®re chose que je voulais dire sur la formation √©tait FP16.  Il est arriv√© historiquement que les r√©seaux soient form√©s sur le GPU en pr√©cision d'unit√©, c'est-√†-dire FP32.  Mais cela est redondant, en particulier pour l'inf√©rence, o√π la demi-pr√©cision (FP16) est suffisante sans perte de qualit√©.  Cependant, ce n'est pas le cas avec la formation. <br><br><img src="https://habrastorage.org/webt/ax/wj/ts/axwjtss6t1hmatnqwhd34s6uztq.jpeg"><br><br>  Si nous regardons la distribution des gradients, des informations qui mettent √† jour nos poids lors de la propagation des erreurs, nous verrons qu'il y a un √©norme pic √† z√©ro.  Et en g√©n√©ral, beaucoup de valeurs sont proches de z√©ro.  Si nous transf√©rons simplement tous les poids sur FP16, il s'av√®re que nous avons coup√© le c√¥t√© gauche dans la r√©gion de z√©ro (√† partir de la ligne rouge). <br><br><img src="https://habrastorage.org/webt/sv/th/2_/svth2_7cdnkfckg5qvvebpv-bwo.jpeg"><br><br>  Autrement dit, nous allons r√©initialiser un tr√®s grand nombre de gradients.  Et la bonne partie, dans la plage de travail FP16, n'est pas du tout utilis√©e.  Par cons√©quent, si vous vous entra√Ænez le front sur FP16, le processus est susceptible de se disperser (le graphique gris dans l'image ci-dessous). <br><br><img src="https://habrastorage.org/webt/nq/n_/20/nqn_20y7f_4auaqespf7pxakuoo.jpeg"><br><br>  Si vous vous entra√Ænez en utilisant la technique de pr√©cision mixte, le r√©sultat est presque identique √† FP32.  La pr√©cision mixte met en ≈ìuvre deux astuces. <br><br>  Premi√®rement: nous multiplions simplement la perte par une constante, par exemple 128. Ainsi, nous mettons √† l'√©chelle tous les gradients et d√©pla√ßons leurs valeurs de z√©ro √† la plage de travail FP16.  Deuxi√®mement: nous stockons la version principale de la balance FP32, qui est utilis√©e uniquement pour la mise √† jour, et dans les op√©rations de calcul des r√©seaux de passes avant et arri√®re, seule la FP16 est utilis√©e. <br><br>  Nous utilisons Pytorch pour former des r√©seaux.  NVIDIA a fait un assemblage sp√©cial pour cela avec le soi-disant APEX, qui met en ≈ìuvre la logique d√©crite ci-dessus.  Il a deux modes.  La premi√®re est la pr√©cision mixte automatique.  Consultez le code ci-dessous pour voir √† quel point il est facile √† utiliser. <br><br><img src="https://habrastorage.org/webt/fu/nb/8o/funb8omqcc4yrglue2tlsn9bx14.jpeg"><br><br>  Litt√©ralement, deux lignes sont ajout√©es au code de formation pour envelopper la perte et la proc√©dure d'initialisation du mod√®le et des optimiseurs.  Que fait AMP?  Il singe patch'it toutes les fonctions.  Que se passe-t-il exactement?  Par exemple, il voit qu'il y a une fonction de convolution, et elle re√ßoit un profit du FP16.  Il le remplace ensuite par le sien, qui est d'abord converti en FP16, puis effectue une op√©ration de convolution.  AMP fait donc pour toutes les fonctions qui peuvent √™tre utilis√©es sur le r√©seau.  Pour certains, ce n'est pas le cas.  il n'y aura pas d'acc√©l√©ration.  Pour la plupart des t√¢ches, cette m√©thode convient. <br><br>  Deuxi√®me option: optimiseur FP16 pour les fans de contr√¥le complet.  Convient si vous souhaitez vous-m√™me sp√©cifier quels calques seront dans FP16 et lesquels dans FP32.  Mais il a un certain nombre de limites et de difficult√©s.  √áa ne commence pas par un demi-coup de pied (au moins on a d√ª transpirer pour le d√©marrer).  FP_optimizer ne fonctionne √©galement qu'avec Adam, et m√™me alors uniquement avec cet Adam, qui est dans APEX (oui, ils ont leur propre Adam dans le r√©f√©rentiel, qui a une interface compl√®tement diff√©rente de Paytorch). <br><br>  Nous avons fait une comparaison lors de l'apprentissage sur les cartes Tesla T4. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rq/go/6c/rqgo6cvrixdwnueh4rczvoooj3m.jpeg"></div><br><br>  Chez Inference, nous avons deux fois l'acc√©l√©ration attendue.  En formation, nous voyons que le framework Apex fournit une acc√©l√©ration de 20% avec un FP16 relativement simple.  En cons√©quence, nous obtenons un entra√Ænement qui est deux fois plus rapide et consomme 2 fois moins de m√©moire, et la qualit√© de l'entra√Ænement ne souffre en aucune fa√ßon.  Freebie. <br><br><h2>  Inf√©rence </h2><br>  Parce que  Puisque nous utilisons PyTorch, la question est de savoir de toute urgence comment le d√©ployer en production. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/6u/vr/qj6uvrpjh44wmvkktkvdoxpfwow.jpeg"></div><br>  Il y a 3 options pour le faire (et nous les avons toutes utilis√©es). <br><br><ul><li>  ONNX -&gt; Caffe2 </li><li>  ONNX -&gt; TensorRT </li><li>  Et plus r√©cemment Pytorch C ++ </li></ul><br>  Regardons chacun d'eux. <br><br><h2>  ONNX et Caffe2 </h2><br>  ONNX est apparu il y a 1,5 ans.  Il s'agit d'un cadre sp√©cial pour convertir des mod√®les entre diff√©rents cadres.  Et Caffe2 est un framework adjacent √† Pytorch, tous deux en cours de d√©veloppement sur Facebook.  Historiquement, Pytorch se d√©veloppe beaucoup plus rapidement que Caffe2.  Caffe2 est en retard sur Pytorch en termes de fonctionnalit√©s, donc tous les mod√®les que vous avez form√©s √† Pytorch ne peuvent pas √™tre convertis en Caffe2.  Souvent, vous devez r√©apprendre avec d'autres couches.  Par exemple, dans Caffe2, il n'y a pas d'op√©ration standard telle que le sur√©chantillonnage avec l'interpolation du plus proche voisin.  En cons√©quence, nous sommes arriv√©s √† la conclusion que pour chaque mod√®le, nous avons obtenu une image de docker sp√©ciale, dans laquelle nous clouons les versions du cadre avec des clous pour √©viter les √©carts lors de leurs futures mises √† jour, de sorte que lorsque l'une des versions est √† nouveau mise √† jour, nous ne perdons pas de temps sur leur compatibilit√© .  Tout cela n'est pas tr√®s pratique et allonge le processus de d√©ploiement. <br><br><h2>  Tensor rt </h2><br>  Il existe √©galement Tensor RT, un framework NVIDIA qui optimise l'architecture r√©seau pour acc√©l√©rer l'inf√©rence.  Nous avons fait nos mesures (sur la carte Tesla T4). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ls/fn/q0/lsfnq0otllhgjqy1gh2lhwufbom.jpeg"></div><br>  Si vous regardez les graphiques, vous pouvez voir que la transition de FP32 √† FP16 donne une acc√©l√©ration 2x sur Pytorch, tandis que TensorRT en m√™me temps donne autant 4x.  Une diff√©rence tr√®s significative.  Nous l'avons test√© sur Tesla T4, qui a des noyaux de tenseurs qui utilisent tr√®s bien les calculs FP16, ce qui est √©videmment excellent dans TensorRT.  Par cons√©quent, s'il existe un mod√®le tr√®s charg√© fonctionnant sur des dizaines de cartes graphiques, il existe tous les facteurs de motivation pour essayer Tensor RT. <br><br>  Cependant, lorsque vous travaillez avec TensorRT, il y a encore plus de douleur que dans Caffe2: les couches y sont encore moins prises en charge.  Malheureusement, chaque fois que nous utilisons ce framework, nous devons souffrir un peu pour convertir le mod√®le.  Mais pour les mod√®les lourdement charg√©s, vous devez le faire.  ;) Je note que sur les cartes sans noyaux tensoriels une telle augmentation massive n'est pas observ√©e. <br><br><h2>  Pytorch C ++ </h2><br>  Et le dernier est Pytorch C ++.  Il y a six mois, les d√©veloppeurs de Pytorch ont r√©alis√© la douleur des personnes qui utilisent leur framework et ont publi√© le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tutoriel TorchScript</a> , qui vous permet de suivre et de s√©rialiser le mod√®le Python dans un graphique statique sans gestes inutiles (JIT).  Il a √©t√© publi√© en d√©cembre 2018, nous avons imm√©diatement commenc√© √† l'utiliser, avons imm√©diatement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©tect√©</a> quelques bugs de performance et attendu plusieurs mois la fixation de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chintala</a> .  Mais maintenant, c'est une technologie assez stable, et nous l'utilisons activement pour tous les mod√®les.  La seule chose est le manque de documentation, qui est activement compl√©t√©e.  Bien s√ªr, vous pouvez toujours consulter les fichiers * .h, mais pour les personnes qui ne connaissent pas les avantages, c'est difficile.  Mais alors, le travail est vraiment identique avec Python.  En C ++, le j-code est ex√©cut√© sur un interpr√©teur Python minimal, qui garantit pratiquement l'identit√© de C ++ avec Python. <br><br><h2>  Conclusions </h2><br><ul><li>  L'√©nonc√© du probl√®me est super important.  Vous devez communiquer avec les chefs de produit sur les donn√©es.  Avant de commencer √† effectuer la t√¢che, il est conseill√© d'avoir un ensemble de tests pr√™t √† l'emploi sur lequel nous mesurons les m√©triques finales avant l'√©tape de mise en ≈ìuvre. <br></li><li>  Nous nettoyons les donn√©es nous-m√™mes √† l'aide du clustering.  Nous obtenons le mod√®le sur les donn√©es source, nettoyons les donn√©es √† l'aide du clustering CLink et r√©p√©tons le processus jusqu'√† la convergence. <br></li><li>  Apprentissage m√©trique: m√™me la classification aide.  √âtat de l'art - ArcFace, qui est facile √† int√©grer dans le processus d'apprentissage. <br></li><li>  Si vous transf√©rez l'apprentissage √† partir d'un r√©seau pr√©-form√©, afin que le r√©seau n'oublie pas l'ancienne t√¢che, utilisez la distillation des connaissances. <br></li><li>  Il est √©galement utile d'utiliser plusieurs t√™tes de r√©seau qui utiliseront diff√©rents signaux des donn√©es pour am√©liorer la t√¢che principale. <br></li><li>  Pour FP16, vous devez utiliser les assemblys Apex de NVIDIA, Pytorch. <br></li><li>  Et par d√©duction, il est pratique d'utiliser Pytorch C ++. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr460307/">https://habr.com/ru/post/fr460307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr460291/index.html">Probl√®mes de traitement par lots des demandes et leurs solutions (partie 1)</a></li>
<li><a href="../fr460295/index.html">Que signifie dangereux √† Rust?</a></li>
<li><a href="../fr460297/index.html">WeakRef - proposition d'ajout √† la norme ECMAScript</a></li>
<li><a href="../fr460301/index.html">Lampes LED haute puissance nouvelle g√©n√©ration</a></li>
<li><a href="../fr460305/index.html">Moteur AERODISK: Catastrophique. Partie 2. Metrocluster</a></li>
<li><a href="../fr460311/index.html">Il est temps pour une nouvelle th√©orie de l'argent</a></li>
<li><a href="../fr460313/index.html">Les diff√©rentes chansons √† succ√®s ont-elles quelque chose en commun?</a></li>
<li><a href="../fr460319/index.html">√Ä la recherche d'inspecteurs spatiaux</a></li>
<li><a href="../fr460321/index.html">Galerie des meilleurs carnets ML et Data Science</a></li>
<li><a href="../fr460329/index.html">Pas le FEDOR, mais le Skybot F-850 volera vers l'ISS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
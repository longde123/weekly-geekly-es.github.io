<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌿 🏄 🦖 Rastreamento de afinação ou determinação da frequência de afinação na fala, usando Praat, YAAPT e YIN como exemplos 🏎️ 👩‍👧‍👦 👩🏿‍✈️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="No campo do reconhecimento emocional, a voz é a segunda fonte mais importante de dados emocionais após o rosto. A voz pode ser caracterizada por vário...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Rastreamento de afinação ou determinação da frequência de afinação na fala, usando Praat, YAAPT e YIN como exemplos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neurodatalab/blog/416441/"><img src="https://habrastorage.org/getpro/habr/post_images/37d/3f1/975/37d3f19758eb7d646ccff079d37772f8.png" alt="imagem"><br><br>  No campo do reconhecimento emocional, a voz é a segunda fonte mais importante de dados emocionais após o rosto.  A voz pode ser caracterizada por vários parâmetros.  O tom da voz é uma das principais características, no entanto, no campo da tecnologia acústica, é mais correto chamar esse parâmetro de frequência fundamental. <br><br>  A frequência do tom fundamental está diretamente relacionada ao que chamamos de entonação.  E a entonação, por exemplo, está associada às características emocionalmente expressivas da voz. <br><br>  Não obstante, determinar a frequência do tom fundamental não é uma tarefa completamente trivial, com nuances interessantes.  Neste artigo, discutiremos os recursos dos algoritmos para sua determinação e comparamos as soluções existentes com exemplos de gravações de áudio específicas. <br><a name="habracut"></a><br>  <b>1. Introdução</b> <br><br>  Para começar, lembremos qual é, em essência, a frequência do tom fundamental e em quais tarefas ele pode ser necessário.  <i>A frequência fundamental</i> , também chamada de CHOT, Frequência fundamental ou F0, é a frequência das cordas vocais quando elas pronunciam sons sonoros.  Ao pronunciar sons sem tom (não sonoros), por exemplo, falando em um sussurro ou emitindo assobios e assobios, os ligamentos não hesitam, o que significa que essa característica não é relevante para eles. <br><br>  * Observe que a divisão em sons tonais e não tonais não é equivalente à divisão em vogais e consoantes. <br><br>  A variação de frequência do tom fundamental é bastante grande e pode variar bastante não apenas entre as pessoas (para vozes masculinas médias mais baixas, a frequência é de 70 a 200 Hz e, para vozes femininas, pode chegar a 400 Hz), mas também para uma pessoa, especialmente na fala emocional. . <br><br>  A determinação da frequência do tom fundamental é usada para resolver uma ampla gama de problemas: <br><br><ul><li>  Reconhecimento de emoções, como dissemos acima; </li><li>  Determinação de sexo; </li><li>  Ao resolver o problema de segmentar áudio com várias vozes ou dividir o discurso em frases; </li><li>  Na medicina, para determinar as características patológicas da voz (por exemplo, usando os parâmetros acústicos Jitter e Shimmer).  Por exemplo, a identificação de sinais da doença de Parkinson [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> ].  Jitter e Shimmer também podem ser usados ​​para reconhecer emoções [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> ]. </li></ul><br>  No entanto, existem várias dificuldades na determinação de F0.  Por exemplo, muitas vezes é possível confundir F0 com harmônicos, o que pode levar aos chamados efeitos de duplicação de pitch / metade do pitch [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3</a> ].  E em gravações de áudio de baixa qualidade, F0 é bastante difícil de calcular, pois o pico desejado em baixas frequências quase desaparece. <br><br>  A propósito, lembra-se da história de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Laurel e Yanny</a> ?  As diferenças nas palavras que as pessoas ouvem ao ouvir a mesma gravação de áudio surgiram precisamente devido à diferença na percepção F0, que é influenciada por muitos fatores: idade do ouvinte, grau de fadiga e dispositivo de reprodução.  Portanto, ao ouvir gravações em alto-falantes com reprodução de alta qualidade de baixas frequências, você ouvirá Laurel e em sistemas de áudio onde as baixas frequências são mal reproduzidas, Yanny.  O efeito de transição pode ser visto em um dispositivo, por exemplo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  E neste <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> , a rede neural atua como um ouvinte.  Em outro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo,</a> você pode ler como o fenômeno Yanny / Laurel é explicado em termos de formação da fala. <br><br>  Como uma análise detalhada de todos os métodos para determinar F0 seria muito volumosa, o artigo é de natureza geral e pode ajudar a navegar no tópico. <br><br>  <b>Métodos para determinar F0</b> <br><br>  Os métodos para determinar F0 podem ser divididos em três categorias: com base na dinâmica do tempo do sinal ou no domínio do tempo;  com base na estrutura de frequência ou no domínio da frequência, bem como em métodos combinados.  Sugerimos que você se familiarize com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo de</a> revisão sobre o tópico, onde os métodos indicados para extrair F0 são analisados ​​em detalhes. <br><br>  Observe que qualquer um dos algoritmos discutidos consiste em 3 etapas principais: <br><br>  Pré-processamento (filtrando o sinal, dividindo-o em quadros) <br>  Procure por possíveis valores de F0 (candidatos) <br>  O rastreamento é a escolha da trajetória mais provável F0 (já que para cada momento em que temos vários candidatos concorrentes, precisamos encontrar o caminho mais provável entre eles) <br><br>  <b>Domínio do tempo</b> <br><br>  Delineamos alguns pontos gerais.  Antes de aplicar os métodos no domínio do tempo, o sinal é pré-filtrado, deixando apenas frequências baixas.  Os limites são definidos - as frequências mínima e máxima, por exemplo, de 75 a 500 Hz.  A determinação de F0 é feita apenas para áreas com fala harmônica, pois para pausas ou sons de ruído isso não é apenas sem sentido, mas também pode introduzir erros em quadros adjacentes quando a interpolação e / ou suavização é aplicada.  O comprimento do quadro é selecionado para conter pelo menos três períodos. <br><br>  O método principal, com base no qual toda uma família de algoritmos apareceu posteriormente, é a autocorrelação.  A abordagem é bastante simples - é necessário calcular a função de autocorrelação e obter o seu primeiro máximo.  Ele exibirá o componente de frequência mais pronunciado no sinal.  Qual poderia ser a dificuldade no uso de autocorrelação e por que nem sempre o primeiro máximo corresponde à frequência desejada?  Mesmo em condições próximas às ideais em gravações de alta qualidade, o método pode estar errado devido à estrutura complexa do sinal.  Em condições próximas do real, onde, entre outras coisas, podemos encontrar o desaparecimento do pico desejado em gravações ruidosas ou gravações de baixa qualidade inicialmente, o número de erros aumenta acentuadamente. <br><br>  Apesar dos erros, o método de autocorrelação é bastante conveniente e atraente devido à sua simplicidade e lógica básicas, razão pela qual é tomado como base em muitos algoritmos, incluindo o YIN.  Até o nome do algoritmo nos remete a um equilíbrio entre a conveniência e a imprecisão do método de autocorrelação: “O nome YIN de '' yin '' e '' yang '' da filosofia oriental alude à interação entre autocorrelação e cancelamento que envolve.”  [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">4</a> ] <br><br>  Os criadores do YIN tentaram corrigir os pontos fracos da abordagem de autocorrelação.  A primeira mudança é o uso da função Diferença Normalizada Média Cumulativa, que deve reduzir a sensibilidade às modulações de amplitude, tornando os picos mais pronunciados: <br><br>  \ begin {equation} <br>  d'_t (\ tau) = <br>  \ begin {cases} <br>  1, &amp; \ tau = 0 \\ <br>  d_t (\ tau) \ bigg / \ bigg [\ frac {1} {\ tau} \ sum \ limits_ {j = 1} ^ {\ tau} d_t (j) \ bigg] e \ text {caso contrário} <br>  \ end {cases} <br>  \ end {equação} <br>  O YIN também tenta evitar erros que ocorrem nos casos em que o comprimento da função da janela não é completamente dividido pelo período de oscilação.  Para isso, é utilizada interpolação mínima parabólica.  Na última etapa do processamento do sinal de áudio, a função Melhor estimativa local é executada para evitar saltos acentuados nos valores (bons ou ruins - este é um ponto discutível). <br><br>  <b>Domínio de frequência</b> <br><br>  Se falamos sobre o domínio da frequência, a estrutura harmônica do sinal vem à tona, ou seja, a presença de picos espectrais em frequências que são múltiplos de F0.  Você pode "colapsar" esse padrão periódico em um pico claro usando a análise cepstral.  Cepstrum - transformada de Fourier do logaritmo do espectro de potência;  o pico cepstral corresponde ao componente mais periódico do espectro (pode-se ler <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ). <br><br>  <b>Métodos híbridos para determinar F0</b> <br><br>  O próximo algoritmo, que vale a pena explorar com mais detalhes, tem o nome falante YAAPT - mais um algoritmo de rastreamento de afinação - e, na verdade, é híbrido, porque usa informações de frequência e tempo.  Uma descrição completa está no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> , aqui descrevemos apenas os estágios principais. <br><br><img src="https://habrastorage.org/webt/r2/mu/uj/r2muujzlcxgdgp5a0bqem3t_iuu.png"><br>  <i>Figura 1. Diagrama do algoritmo YAAPTalgo ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">link</a> )</i> . <br><br>  O YAAPT consiste em várias etapas principais, a primeira das quais é o pré-processamento.  Nesse estágio, os valores do sinal original são elevados ao quadrado e uma segunda versão do sinal é obtida.  Esta etapa persegue o mesmo objetivo que a Função de Diferença Normalizada Média Acumulada no YIN - amplificação e restauração de picos "congestionados" de autocorrelação.  Ambas as versões do sinal são filtradas - geralmente elas variam de 50 a 1500 Hz, às vezes de 50 a 900 Hz. <br><br>  Então, a trajetória de base F0 é calculada a partir do espectro do sinal convertido.  Os candidatos a F0 são determinados usando o recurso Correlação de Harmônicas Espectrais (SHC). <br><br>  \ begin {equation} <br>  SHC (t, f) = \ sum \ limits_ {f '= - WL / 2} ^ {WL / 2} \ prod \ limits_ {r = 1} ^ {NH + 1} S (t, rf + f') <br>  \ end {equação} <br>  onde S (t, f) é o espectro de magnitude para o quadro te a frequência f, WL é o comprimento da janela em Hz, NH é o número de harmônicos (os autores recomendam o uso dos três primeiros harmônicos).  A potência espectral também é usada para determinar os quadros sonoros e não sonoros, após os quais a trajetória mais ideal é pesquisada e a possibilidade de duplicação / metade do tom é levada em consideração [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3</a> , Seção II, C]. <br><br>  Além disso, os candidatos a F0 são determinados para o sinal inicial e o convertido e, em vez da função de autocorrelação, a Correlação Cruzada Normalizada (NCCF) é usada aqui. <br><br>  \ begin {equation} <br>  NCCF (m) = \ frac {\ sum \ limits_ {n = 0} ^ {Nm-1} x (n) * x (n + m)} {\ sqrt {\ sum \ limits_ {n = 0} ^ { Nm-1} x ^ 2 (n) * \ sum \ limits_ {n = 0} ^ {Nm-1} x ^ 2 (n + m)}} \ text {,} \ espaço {0,3cm} 0 &lt;m &lt;M_ {0} <br>  \ end {equação} <br>  O próximo passo é avaliar todos os possíveis candidatos e calcular sua significância ou peso (mérito).  O peso dos candidatos obtidos a partir do sinal de áudio depende não apenas da amplitude do pico da NCCF, mas também da proximidade da trajetória F0 determinada a partir do espectro.  Ou seja, o domínio da frequência é considerado grosseiro em termos de precisão, mas estável [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3</a> , Seção II, D]. <br><br>  Então, para todos os pares de candidatos restantes, é calculada a matriz de Custo de Transição - o preço de transição, no qual eles finalmente encontram a trajetória ideal [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3</a> , Seção II, E]. <br><br>  <b>Exemplos</b> <br><br>  Agora, aplicamos todos os algoritmos acima a gravações de áudio específicas.  Como ponto de partida, usaremos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Praat</a> , uma ferramenta fundamental para muitos estudiosos da fala.  E então, em Python, examinaremos a implementação do YIN e YAAPT e compararemos os resultados recebidos. <br><br>  Como material de áudio, você pode usar qualquer áudio disponível.  Tiramos vários trechos de nosso banco de dados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RAMAS</a> - um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados</a> multimodal criado com a participação de atores do VGIK.  Você também pode usar material de outros bancos de dados abertos, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LibriSpeech</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RAVDESS</a> . <br><br>  Para um exemplo ilustrativo, extraímos trechos de várias gravações com vozes masculinas e femininas, tanto neutras quanto emocionalmente coloridas, e para maior clareza, as combinamos em uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">gravação</a> .  Vejamos nosso sinal, seu espectrograma, intensidade (cor laranja) e F0 (cor azul).  No Praat, isso pode ser feito usando Ctrl + O (Abrir - Ler do arquivo) e, em seguida, o botão Exibir e Editar. <br><br><img src="https://habrastorage.org/webt/ir/ay/kh/iraykhpzwfetpahhiymdic6pdwi.png"><br>  <i>Figura 2. Espectrograma, intensidade (cor laranja), F0 (cor azul) em Praat.</i> <br><br>  O áudio mostra claramente que, na fala emocional, o tom aumenta em homens e mulheres.  Ao mesmo tempo, F0 para a fala emocional do homem pode muito bem ser comparado com o F0 de uma voz feminina. <br><br>  <b>Rastreamento</b> <br><br>  Selecione a guia Analisar periodicidade - para Inclinar (ac) no menu Praat, ou seja, a definição de F0 usando a correlação automática.  Aparecerá uma janela para definir parâmetros, na qual é possível definir 3 parâmetros para determinar candidatos para F0 e mais 6 parâmetros para o algoritmo de busca de caminhos, que cria o caminho F0 mais provável entre todos os candidatos. <br><br><div class="spoiler">  <b class="spoiler_title">Muitos parâmetros (no Praat, sua descrição também está no botão Ajuda)</b> <div class="spoiler_text"><ul><li>  Limiar de silêncio - o limiar da amplitude relativa do sinal para determinar o silêncio, o valor padrão é 0,03. </li><li>  Limiar de sonoridade - o peso do candidato não sonoro, o valor máximo é 1. Quanto maior esse parâmetro, mais quadros serão definidos como sonoros, ou seja, sem sons de tom.  Nesses quadros, F0 não será determinado.  O valor deste parâmetro é o limite para picos da função de autocorrelação.  O valor padrão é 0,45. </li><li>  Custo de oitava - determina quanto mais peso os candidatos de alta frequência têm em relação aos de baixa frequência.  Quanto maior o valor, mais preferência é dada ao candidato de alta frequência.  O valor padrão é 0,01 por oitava. </li><li>  Custo de salto de oitava - com um aumento nesse coeficiente, o número de transições nítidas de salto entre valores sucessivos de F0 diminui.  O valor padrão é 0,35. </li><li>  Custo expresso / não expresso - aumentar esse coeficiente diminui o número de transições sonoras / não expressas.  O valor padrão é 0,14. </li><li>  Teto de inclinação (Hz) - candidatos acima dessa frequência não são considerados.  O valor padrão é 600 Hz. </li></ul><br></div></div><br>  Uma descrição detalhada do algoritmo pode ser encontrada em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo de</a> 1993. <br><br>  A aparência do resultado do rastreador (localizador de caminho) pode ser vista clicando em OK e depois visualizando (Exibir e editar) o arquivo Pitch resultante.  Pode-se observar que, além da trajetória selecionada, ainda havia candidatos bastante significativos com frequência mais baixa. <br><br><img src="https://habrastorage.org/webt/wq/rq/vf/wqrqvf_cbnbn8orcajij6sfrasu.png"><br>  <i>Figura 3. PitchPath pelos primeiros 1,3 segundos de gravação de áudio.</i> <br><br>  <b>Mas e o Python?</b> <br><br>  Vamos pegar duas bibliotecas que oferecem rastreamento de pitch - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aubio</a> , no qual o algoritmo padrão é YIN, e a biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AMFM_decompsition</a> , que possui uma implementação do algoritmo YAAPT.  No arquivo separado (arquivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PraatPitch.txt</a> ), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">insira os</a> valores F0 do Praat (isso pode ser feito manualmente: selecione o arquivo de som, clique em Exibir e editar, selecione o arquivo inteiro e selecione a listagem de afinação no menu superior). <br><br>  Agora compare os resultados para todos os três algoritmos (YIN, YAAPT, Praat). <br><br><div class="spoiler">  <b class="spoiler_title">Muito código</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> amfm_decompy.basic_tools <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> basic <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> amfm_decompy.pYAAPT <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pYAAPT <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> aubio <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> source, pitch <span class="hljs-comment"><span class="hljs-comment"># load audio signal = basic.SignalObj('/home/eva/Documents/papers/habr/media/audio.wav') filename = '/home/eva/Documents/papers/habr/media/audio.wav' # YAAPT pitches pitchY = pYAAPT.yaapt(signal, frame_length=40, tda_frame_length=40, f0_min=75, f0_max=600) # YIN pitches downsample = 1 samplerate = 0 win_s = 1764 // downsample # fft size hop_s = 441 // downsample # hop size s = source(filename, samplerate, hop_s) samplerate = s.samplerate tolerance = 0.8 pitch_o = pitch("yin", win_s, hop_s, samplerate) pitch_o.set_unit("midi") pitch_o.set_tolerance(tolerance) pitchesYIN = [] confidences = [] total_frames = 0 while True: samples, read = s() pitch = pitch_o(samples)[0] pitch = int(round(pitch)) confidence = pitch_o.get_confidence() pitchesYIN += [pitch] confidences += [confidence] total_frames += read if read &lt; hop_s: break # load PRAAT pitches praat = np.genfromtxt('/home/eva/Documents/papers/habr/PraatPitch.txt', filling_values=0) praat = praat[:,1] # plot fig, (ax1,ax2,ax3) = plt.subplots(3, 1, sharex=True, sharey=True, figsize=(12, 8)) ax1.plot(np.asarray(pitchesYIN), label='YIN', color='green') ax1.legend(loc="upper right") ax2.plot(pitchY.samp_values, label='YAAPT', color='blue') ax2.legend(loc="upper right") ax3.plot(praat, label='Praat', color='red') ax3.legend(loc="upper right") plt.show()</span></span></code> </pre> <br></div></div><br><br><img src="https://habrastorage.org/webt/tv/k7/uq/tvk7uqi50ctcnd3j3rjq0sjzl8s.png"><br>  <i>Figura 4. Comparação da operação dos algoritmos YIN, YAAPT e Praat.</i> <br><br>  Vemos que, com os parâmetros padrão, o YIN é bastante nocauteado, obtendo uma trajetória bastante plana com valores inferiores a Praat e perdendo completamente as transições entre as vozes masculina e feminina, bem como entre a fala emocional e não emocional. <br><br>  YAAPT cortou um tom muito alto no discurso emocional feminino, mas no geral conseguiu claramente melhor.  Devido às suas características específicas, o YAAPT funciona melhor - é impossível responder imediatamente, é claro, mas pode-se supor que o papel seja desempenhado pela obtenção de candidatos de três fontes e um cálculo mais meticuloso do seu peso do que no YIN. <br><br>  <b>Conclusão</b> <br><br>  Como a questão de determinar a frequência do tom fundamental (F0), de uma forma ou de outra, surge antes de quase todo mundo que trabalha com som, há muitas maneiras de resolvê-lo.  A questão da precisão e dos recursos necessários do material de áudio em cada caso determina com que cuidado é necessário selecionar parâmetros ou, em outro caso, você pode restringir-se a uma solução básica como o YAAPT.  Tomando o Praat como o padrão do algoritmo para processamento de fala (no entanto, um grande número de pesquisadores o utiliza), podemos concluir que o YAAPT é, para uma primeira aproximação, mais confiável e preciso que o YIN, embora nosso exemplo tenha sido complicado para ele. <br><br>  Postado por <b>Eva</b> Kazimirova, pesquisadora do Laboratório Neurodata, especialista em processamento de fala. <br><br>  <font color="green"><b>Offtop</b></font> : Você gostou do artigo?  De fato, temos várias tarefas interessantes em ML, matemática e programação e precisamos de cérebros.  Você está curioso?  Venha para nós!  E-mail: hr@neurodatalab.com <br><br><div class="spoiler">  <b class="spoiler_title">Referências</b> <div class="spoiler_text"><ol><li>  Rusz, J., Cmejla, R., Ruzickova, H., Ruzicka, E. Medidas acústicas quantitativas para caracterização de distúrbios da fala e da voz na doença de Parkinson não tratada precoce.  O Jornal da Sociedade Acústica da América, vol.  129, edição 1 (2011), pp.  350-367.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acesso</a> </li><li>  Farrús, M., Hernando, J., Ejarque, P. Jitter e Shimmer Measurement para reconhecimento de alto-falante.  Anais da Conferência Anual da International Speech Communication Association, INTERSPEECH, vol.  2 (2007), pp.  1153-1156.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acesso</a> </li><li>  Zahorian, S., Hu, HA.  Método espectral / temporal para rastreamento de frequência fundamental robusto.  O Jornal da Sociedade Acústica da América, vol.  123, edição 6 (2008), pp.  4559-4571.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acesso</a> </li><li>  De Cheveigné, A., Kawahara, H. YIN, um estimador de frequência fundamental para fala e música.  O Jornal da Sociedade Acústica da América, vol.  111, edição 4 (2002), pp.  1917-1930.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acesso</a> </li></ol></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt416441/">https://habr.com/ru/post/pt416441/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt416431/index.html">Os melhores projetos de blockchain. OIC julho 2018 (votação)</a></li>
<li><a href="../pt416433/index.html">Pergunte a Ethan: As perdas de radiação estelar podem explicar a energia escura?</a></li>
<li><a href="../pt416435/index.html">Por que o cérebro humano é tão eficaz?</a></li>
<li><a href="../pt416437/index.html">Existem produtos químicos suficientes nos mundos gelados para sustentar a vida lá?</a></li>
<li><a href="../pt416439/index.html">iOS 12: agrupamento de notificações</a></li>
<li><a href="../pt416443/index.html">9 segredos do núcleo do ASP.NET</a></li>
<li><a href="../pt416445/index.html">Webinars do Skillbox: os mais interessantes - de graça</a></li>
<li><a href="../pt416449/index.html">.NET Core + Docker no Raspberry Pi. Isso é legal?</a></li>
<li><a href="../pt416451/index.html">Bancos de dados de pesquisa da Microsoft agora disponíveis para todos</a></li>
<li><a href="../pt416453/index.html">Esquemas de roubo em sistemas RBS e cinco níveis de contra-ação para eles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
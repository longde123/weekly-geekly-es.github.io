<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ• ğŸ‘š â£ï¸ Bagaimana Kami Meningkatkan Nginx dan Menyelamatkan Dunia, 54 Tahun Menunggu Setiap Hari ğŸ˜™ ğŸ¤²ğŸ» ğŸ‘¶ğŸ¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="â€œTim @Cloudflare baru saja membuat perubahan yang secara signifikan meningkatkan kinerja jaringan kami, terutama untuk permintaan yang paling lambat. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana Kami Meningkatkan Nginx dan Menyelamatkan Dunia, 54 Tahun Menunggu Setiap Hari</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/419023/"> <i>â€œTim @Cloudflare baru saja membuat perubahan yang secara signifikan meningkatkan kinerja jaringan kami, terutama untuk permintaan yang paling lambat.</i>  <i>Seberapa cepat?</i>  <i>Kami memperkirakan bahwa kami menghemat Internet sekitar 54 tahun <b>per hari</b> yang seharusnya dihabiskan menunggu situs dimuat</i> . <i>â€</i>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tweet</a> Matthew Prince, 28 Juni 2018 <br><br>  10 juta situs, aplikasi, dan API menggunakan Cloudflare untuk mempercepat unduhan konten untuk pengguna.  Pada puncaknya, kami memproses lebih dari 10 juta permintaan per detik di 151 pusat data.  Selama bertahun-tahun, kami telah membuat banyak perubahan pada versi Nginx kami untuk mengatasi pertumbuhan.  Artikel ini adalah tentang salah satu dari perubahan ini. <br><a name="habracut"></a><br><h1>  Cara Kerja Nginx </h1><br>  Nginx adalah salah satu program yang menggunakan loop pemrosesan acara untuk menyelesaikan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">masalah C10K</a> .  Setiap kali acara jaringan tiba (koneksi baru, permintaan atau pemberitahuan untuk mengirim data dalam jumlah lebih besar, dll.), Nginx bangun, memproses acara, dan kemudian kembali ke pekerjaan lain (ini mungkin memproses acara lain).  Ketika suatu peristiwa tiba, data untuknya sudah siap, yang memungkinkan Anda untuk memproses banyak permintaan secara simultan tanpa downtime. <br><br><pre><code class="hljs pgsql">num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/</code> </pre> <br>  Misalnya, inilah yang tampak seperti sepotong kode untuk membaca data dari deskriptor file: <br><br><pre> <code class="hljs pgsql">// we got a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> fd <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (buf_len &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { ssize_t n = <span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (n &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EWOULDBLOCK || errno == EAGAIN) { // try later <span class="hljs-keyword"><span class="hljs-keyword">when</span></span> we <span class="hljs-keyword"><span class="hljs-keyword">get</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event again } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EINTR) { <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> total; } buf_len -= n; buf += n; total += n; }</code> </pre> <br>  Jika fd adalah soket jaringan, maka byte yang sudah diterima akan dikembalikan.  Panggilan terakhir akan mengembalikan <code>EWOULDBLOCK</code> .  Ini berarti bahwa buffer baca lokal telah berakhir dan Anda seharusnya tidak lagi membaca dari soket ini sampai data muncul. <br><br><h1>  Disk I / O berbeda dari jaringan </h1><br>  Jika fd adalah file biasa di Linux, maka <code>EWOULDBLOCK</code> dan <code>EAGAIN</code> tidak pernah muncul, dan operasi baca selalu menunggu untuk membaca seluruh buffer, bahkan jika file dibuka menggunakan <code>O_NONBLOCK</code> .  Seperti yang tertulis dalam manual <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">terbuka (2)</a> : <br><br><blockquote>  Harap perhatikan bahwa tanda ini tidak valid untuk file biasa dan blokir perangkat. </blockquote><br>  Dengan kata lain, kode di atas pada dasarnya dikurangi menjadi ini: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> buf_len; }</code> </pre> <br>  Jika pawang perlu membaca dari disk, maka ia memblokir loop acara hingga pembacaan selesai, dan penangan event berikutnya menunggu. <br><br>  Ini normal untuk sebagian besar tugas, karena membaca dari disk biasanya cukup cepat dan jauh lebih mudah diprediksi daripada menunggu paket dari jaringan.  Apalagi sekarang semua orang memiliki SSD, dan semua cache kami ada di SSD.  Dalam SSD modern, penundaan sangat kecil, biasanya dalam puluhan mikrodetik.  Selain itu, Anda bisa menjalankan Nginx dengan beberapa alur kerja sehingga pengendali acara yang lambat tidak memblokir permintaan dalam proses lain.  Sebagian besar waktu Anda dapat mengandalkan Nginx untuk memproses permintaan dengan cepat dan efisien. <br><br><h1>  Kinerja SSD: tidak selalu seperti yang dijanjikan </h1><br>  Seperti yang bisa Anda tebak, asumsi-asumsi indah ini tidak selalu benar.  Jika setiap pembacaan selalu membutuhkan 50 Î¼s, maka membaca 0,19 MB dalam blok 4 KB (dan kita membaca dalam blok yang lebih besar) hanya akan memakan waktu 2 ms.  Tetapi tes menunjukkan bahwa waktu ke byte pertama kadang-kadang jauh lebih buruk, terutama di persentil ke-99 dan ke-999.  Dengan kata lain, pembacaan paling lambat dari setiap 100 (atau 1000) bacaan seringkali membutuhkan waktu lebih lama. <br><br>  Solid state drive sangat cepat, tetapi dikenal dengan kompleksitasnya.  Mereka memiliki komputer di dalam antrian itu dan menyusun ulang I / O, dan juga melakukan berbagai tugas latar belakang, seperti pengumpulan sampah dan defragmentasi.  Dari waktu ke waktu, permintaan melambat secara nyata.  Kolega saya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Ivan Bobrov,</a> meluncurkan beberapa tolok ukur I / O dan mencatat penundaan baca hingga 1 detik.  Selain itu, beberapa SSD kami memiliki lebih banyak lonjakan kinerja seperti itu daripada yang lain.  Di masa depan kita akan mempertimbangkan indikator ini saat membeli SSD, tetapi sekarang kita perlu mengembangkan solusi untuk peralatan yang ada. <br><br><h1>  Distribusi muatan yang seragam dengan <code>SO_REUSEPORT</code> </h1><br>  Sulit untuk menghindari satu respons lambat per 1000 permintaan, tetapi yang sebenarnya tidak kita inginkan adalah memblokir 1000 permintaan yang tersisa untuk satu detik penuh.  Secara konseptual, Nginx dapat memproses banyak permintaan secara paralel, tetapi hanya memulai 1 pengendali event secara bersamaan.  Jadi saya menambahkan metrik khusus: <br><br><pre> <code class="hljs pgsql">gettimeofday(&amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ gettimeofday(&amp;event_start_handle, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/ timersub(&amp;event_start_handle, &amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, &amp;event_loop_blocked);</code> </pre> <br>  Persentil ke-99 (p99) <code>event_loop_blocked</code> melebihi 50% dari TTFB kami.  Dengan kata lain, separuh waktu ketika melayani permintaan adalah hasil dari memblokir siklus pemrosesan acara oleh permintaan lain.  <code>event_loop_blocked</code> hanya mengukur setengah kunci (karena panggilan yang ditangguhkan ke <code>epoll_wait()</code> tidak diukur), sehingga rasio aktual dari waktu yang diblokir jauh lebih tinggi. <br><br>  Setiap mesin kami menjalankan Nginx dengan 15 alur kerja, mis. Satu I / O lambat akan memblokir tidak lebih dari 6% dari permintaan.  Tetapi acara tidak merata: pekerja utama menerima 11% dari permintaan. <br><br>  <code>SO_REUSEPORT</code> dapat menyelesaikan masalah distribusi yang tidak merata.  Marek Maikovsky menulis sebelumnya tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kelemahan dari</a> pendekatan ini dalam konteks contoh Nginx lainnya, tetapi di sini Anda terutama dapat mengabaikannya: koneksi upstream dalam cache tahan lama, sehingga Anda dapat mengabaikan sedikit peningkatan keterlambatan saat membuka koneksi.  Konfigurasi ini berubah sendiri dengan aktivasi <code>SO_REUSEPORT</code> meningkatkan puncak p99 sebesar 33%. <br><br><h1>  Memindahkan read () ke kumpulan utas: bukan peluru perak </h1><br>  Solusinya adalah membuat read () non-blocking.  Sebenarnya fungsi ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">diimplementasikan dalam Nginx normal</a> !  Menggunakan konfigurasi berikut, baca () dan tulis () dijalankan di kumpulan utas dan jangan halangi loop peristiwa: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">aio</span></span> threads; <span class="hljs-attribute"><span class="hljs-attribute">aio_write</span></span> <span class="hljs-literal"><span class="hljs-literal">on</span></span>;</code> </pre> <br>  Tetapi kami menguji konfigurasi ini dan alih-alih meningkatkan waktu respons sebanyak 33 kali, kami hanya melihat sedikit perubahan pada p99, perbedaannya ada dalam margin of error.  Hasilnya sangat mengecewakan, jadi kami menunda sementara opsi ini. <br><br>  Ada beberapa alasan mengapa kami tidak memiliki peningkatan yang signifikan, seperti pengembang Nginx.  Dalam pengujian mereka menggunakan 200 koneksi simultan untuk meminta file 4 MB ke HDD.  Winchesters memiliki latensi I / O yang lebih banyak, sehingga pengoptimalan memiliki efek yang lebih besar. <br><br>  Selain itu, kami terutama prihatin dengan kinerja p99 (dan p999).  Mengoptimalkan penundaan rata-rata tidak serta merta memecahkan masalah emisi puncak. <br><br>  Terakhir, di lingkungan kita, ukuran file tipikal jauh lebih kecil.  90% dari hit cache kami kurang dari 60KB.  Semakin kecil file, semakin sedikit kasus pemblokiran (biasanya kita membaca seluruh file dalam dua kali dibaca). <br><br>  Mari kita lihat disk I / O ketika menekan cache: <br><br><pre> <code class="hljs ruby">/<span class="hljs-regexp"><span class="hljs-regexp">/     https:/</span></span><span class="hljs-regexp"><span class="hljs-regexp">/example.com    0xCAFEBEEF fd = open("/cache</span></span><span class="hljs-regexp"><span class="hljs-regexp">/prefix/dir</span></span><span class="hljs-regexp"><span class="hljs-regexp">/EF/</span></span>BE/CAFEBEEF<span class="hljs-string"><span class="hljs-string">", O_RDONLY); //    32    //    ,  "</span></span>aio threads<span class="hljs-string"><span class="hljs-string">"  read(fd, buf, 32*1024);</span></span></code> </pre> <br>  32K tidak selalu dibaca.  Jika tajuknya kecil, maka Anda hanya perlu membaca 4 KB (kami tidak menggunakan I / O secara langsung, sehingga kernel membulatkan ke 4 KB).  <code>open()</code> tampaknya tidak berbahaya, tetapi sebenarnya membutuhkan sumber daya.  Minimal, kernel harus memeriksa apakah file itu ada dan apakah proses panggilan memiliki izin untuk membukanya.  Dia perlu menemukan inode untuk <code>/cache/prefix/dir/EF/BE/CAFEBEEF</code> , dan untuk ini dia harus mencari <code>CAFEBEEF</code> di <code>/cache/prefix/dir/EF/BE/</code> .  Singkatnya, dalam kasus terburuk, kernel melakukan pencarian ini: <br><br><pre> <code class="hljs pgsql">/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE/CAFEBEEF</code> </pre> <br>  Ini adalah 6 bacaan terpisah yang <code>open()</code> menghasilkan, dibandingkan dengan 1 <code>read()</code> !  Untungnya, dalam kebanyakan kasus pencarian jatuh ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">cache dentry</a> dan tidak mencapai SSD.  Tetapi jelas bahwa pemrosesan <code>read()</code> dalam kumpulan thread hanya setengah dari gambar. <br><br><h1>  Final chord: non-blocking open () di kumpulan thread </h1><br>  Oleh karena itu, kami membuat perubahan ke Nginx sehingga <code>open()</code> sebagian besar dieksekusi di dalam kumpulan thread dan tidak memblokir loop acara.  Dan ini adalah hasil dari open-blocking non-blocking () dan read () pada saat yang sama: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d70/b1a/84b/d70b1a84b46934921ffd5a1fd7e7182a.png"><br><br>  Pada tanggal 26 Juni, kami meluncurkan perubahan ke 5 pusat data tersibuk, dan hari berikutnya - ke semua 146 pusat data lainnya di seluruh dunia.  Total puncak p99 TTFB menurun sebanyak 6 kali.  Bahkan, jika kami merangkum sepanjang waktu dari pemrosesan 8 juta permintaan per detik, kami menghemat waktu tunggu Internet 54 tahun setiap hari. <br><br>  Serangkaian acara kami belum sepenuhnya menghilangkan kunci.  Secara khusus, pemblokiran masih terjadi saat file pertama kali di-cache (keduanya <code>open(O_CREAT)</code> dan <code>rename()</code> ) atau ketika memperbarui validasi ulang.  Tetapi kasus seperti itu jarang dibandingkan dengan akses cache.  Di masa depan, kami akan mempertimbangkan kemungkinan untuk memindahkan elemen-elemen ini di luar loop pemrosesan acara untuk lebih meningkatkan faktor penundaan p99. <br><br><h1>  Kesimpulan </h1><br>  Nginx adalah platform yang tangguh, tetapi meningkatkan beban I / O Linux sangat tinggi bisa menjadi tugas yang menakutkan.  Nginx standar membongkar bacaan di utas terpisah, tetapi pada skala kami, kami sering perlu melangkah lebih jauh. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id419023/">https://habr.com/ru/post/id419023/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id419011/index.html">Jinja2 di dunia C ++, bagian dua. Rendering</a></li>
<li><a href="../id419013/index.html">Atribusi berbasis corong untuk bisnis SaaS B2B - karena kami mempertimbangkan nilai semua upaya pemasaran</a></li>
<li><a href="../id419017/index.html">Apa yang Baru di ConstraintLayout 1.1</a></li>
<li><a href="../id419019/index.html">AlterEgo: perangkat yang dapat membaca (beberapa) pikiran</a></li>
<li><a href="../id419021/index.html">Jenis-jenis utama pencetakan dan fitur-fiturnya</a></li>
<li><a href="../id419025/index.html">@Pythonetc kompilasi, Juli 2018</a></li>
<li><a href="../id419027/index.html">Keamanan informasi pembayaran tanpa uang tunai bank. Bagian 6 - Analisis Kejahatan Perbankan</a></li>
<li><a href="../id419029/index.html">Fortnite telah menjadi fenomena sosial. Orang tua semakin merekrut pelatih untuk anak-anak mereka dan bermain bersama mereka</a></li>
<li><a href="../id419033/index.html">Sebuah catatan kecil tentang topik menjalankan vue.js di cluster kubernetes</a></li>
<li><a href="../id419035/index.html">Buku â€œHead First Agile. Manajemen proyek yang fleksibel â€</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
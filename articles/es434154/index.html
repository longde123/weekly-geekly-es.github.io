<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧖🏽 🈁 🤞🏾 Conjunto de datos de Año Nuevo 2018: semántica abierta del idioma ruso 👋🏽 🎂 👧🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La semántica abierta del idioma ruso, sobre cuya historia puedes leer aquí y aquí , recibió una gran actualización. Hemos recopilado suficientes datos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Conjunto de datos de Año Nuevo 2018: semántica abierta del idioma ruso</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/434154/">  La semántica abierta del idioma ruso, sobre cuya historia puedes leer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> , recibió una gran actualización.  Hemos recopilado suficientes datos para aplicar el aprendizaje automático sobre el marcado recopilado y construir un modelo de lenguaje semántico.  Lo que salió de él, ver debajo del corte. <br><br><img src="https://habrastorage.org/webt/o-/zn/pr/o-znprf5c6sv6xso7v8r4dmrlwo.png"><br><a name="habracut"></a><br><h2>  Que hacemos </h2><br>  Toma dos grupos de palabras: <br><br><ul><li>  correr, disparar, trazar, caminar, caminar; </li><li>  corredor, fotógrafo, ingeniero, turista, deportista. </li></ul><br>  No es difícil para una persona determinar que el primer grupo contiene sustantivos que nombran <i>acciones o eventos</i> ;  en el segundo - llamando a la <i>gente</i> .  Nuestro objetivo es enseñarle a una máquina a resolver tales problemas. <br><br>  Para hacer esto, debes: <br><br><ol><li>  Descubre qué clases naturales existen en el idioma. </li><li>  Marque un número suficiente de palabras sobre el tema de pertenecer a las clases en el <i>párrafo 1</i> . </li><li>  Cree un algoritmo que aprenda sobre el marcado del <i>elemento 2</i> y reproduzca la clasificación en palabras desconocidas. </li></ol><br><div class="spoiler">  <b class="spoiler_title">¿Es posible resolver este problema con la ayuda de la semántica de distribución?</b> <div class="spoiler_text">  <i>word2vec</i> es una herramienta excelente, pero aún así prefiere la proximidad temática de las palabras, en lugar de la similitud de sus clases semánticas.  Para demostrar este hecho, ejecute el algoritmo en palabras del ejemplo: <br><br><pre><code class="plaintext hljs">w1 | w2 | cosine_sim | | | |  |  | 1.0000 |  |  | 0.6618 |  |  | 0.5410 |  |  | 0.3389 |  |  | 0.1531 |  |  | 0.1342 |  |  | 0.1067 |  |  | 0.0681 |  |  | 0.0458 |  |  | 0.0373 | | | |  |  | 1.0000 |  |  | 0.5782 |  |  | 0.2525 |  |  | 0.2116 |  |  | 0.1644 |  |  | 0.1579 |  |  | 0.1342 |  |  | 0.1275 |  |  | 0.1100 |  |  | 0.0975 | | | |  |  | 1.0000 |  |  | 0.3575 |  |  | 0.2116 |  |  | 0.1587 |  |  | 0.1207 |  |  | 0.1067 |  |  | 0.0889 |  |  | 0.0794 |  |  | 0.0705 |  |  | 0.0430 | | | |  |  | 1.0000 |  |  | 0.1896 |  |  | 0.1753 |  |  | 0.1644 |  |  | 0.1548 |  |  | 0.1531 |  |  | 0.0889 |  |  | 0.0794 |  |  | 0.0568 |  |  | -0.0013 | | | |  |  | 1.0000 |  |  | 0.5410 |  |  | 0.3442 |  |  | 0.2469 |  |  | 0.1753 |  |  | 0.1650 |  |  | 0.1207 |  |  | 0.1100 |  |  | 0.0673 |  |  | 0.0642 | | | |  |  | 1.0000 |  |  | 0.6618 |  |  | 0.4909 |  |  | 0.3442 |  |  | 0.1548 |  |  | 0.1427 |  |  | 0.1422 |  |  | 0.1275 |  |  | 0.1209 |  |  | 0.0705 | | | |  |  | 1.0000 |  |  | 0.5782 |  |  | 0.3687 |  |  | 0.2334 |  |  | 0.1911 |  |  | 0.1587 |  |  | 0.1209 |  |  | 0.0642 |  |  | 0.0373 |  |  | -0.0013 | | | |  |  | 1.0000 |  |  | 0.3575 |  |  | 0.2334 |  |  | 0.1579 |  |  | 0.1503 |  |  | 0.1447 |  |  | 0.1422 |  |  | 0.0673 |  |  | 0.0568 |  |  | 0.0458 | | | |  |  | 1.0000 |  |  | 0.3687 |  |  | 0.2525 |  |  | 0.1896 |  |  | 0.1650 |  |  | 0.1503 |  |  | 0.1495 |  |  | 0.1427 |  |  | 0.0681 |  |  | 0.0430 | | | |  |  | 1.0000 |  |  | 0.4909 |  |  | 0.3389 |  |  | 0.2469 |  |  | 0.1911 |  |  | 0.1495 |  |  | 0.1447 |  |  | 0.0975 |  |  | 0.0889 |  |  | 0.0889 |</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Cómo la semántica abierta resuelve este problema</b> <div class="spoiler_text">  Una búsqueda en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">diccionario semántico</a> da el siguiente resultado: <br><br><pre> <code class="plaintext hljs">  |   | | |  | ABSTRACT:ACTION |  | ABSTRACT:ACTION |  | ABSTRACT:ACTION |  | ABSTRACT:ACTION |  | ABSTRACT:ACTION |  | HUMAN |  | HUMAN |  | HUMAN |  | HUMAN |  | HUMAN |</code> </pre> <br></div></div><br><h2>  Qué se ha hecho y dónde descargar </h2><br>  El resultado del trabajo, publicado en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el repositorio de GC</a> y disponible para descargar, es una descripción de la jerarquía de clases y el marcado (manual y automático) de los sustantivos para estas clases. <br><br>  Para familiarizarse con el conjunto de datos, puede usar el navegador interactivo (enlace en el repositorio).  También hay una versión simplificada del conjunto en el que eliminamos toda la jerarquía y asignamos una sola etiqueta semántica grande a cada palabra: "personas", "animales", "lugares", "cosas", "acciones", etc. <br><br>  <i>Enlace a Github:</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">semántica abierta del idioma ruso (conjunto de datos)</a> . <br><br><h2>  Sobre clases de palabras </h2><br>  En los problemas de clasificación, las clases mismas a menudo están dictadas por el problema que se resuelve, y el trabajo del ingeniero de datos se reduce a encontrar un conjunto exitoso de atributos sobre el cual se puede construir un modelo de trabajo. <br><br>  En nuestro problema, las clases de palabras, estrictamente hablando, no se conocen de antemano.  Aquí un gran estrato de investigación semántica realizado por lingüistas nacionales y extranjeros, la familiaridad con los diccionarios semánticos existentes y WordNet'es viene al rescate. <br><br>  Esta es una buena ayuda, pero la decisión final ya se formó dentro de nuestra propia investigación.  Aquí está la cosa.  Muchos recursos semánticos comenzaron a crearse en la era previa a la computadora (al menos en la comprensión moderna de la computadora) y la elección de las clases fue dictada en gran medida por la intuición del lenguaje de sus creadores.  A fines del siglo anterior, WordNet se utilizó activamente en las tareas de análisis automático de texto, y muchos recursos recién creados se agudizaron para aplicaciones prácticas específicas. <br><br>  El resultado fue que estos recursos lingüísticos contienen simultáneamente información enciclopédica, tanto lingüística como extralingüística, sobre las unidades de la lengua.  Es lógico suponer que es imposible construir un modelo que verifique la información extralingüística, basándose únicamente en el análisis estadístico de textos, porque la fuente de datos simplemente no contiene la información necesaria. <br><br>  En base a esta suposición, buscamos solo clases naturales que puedan detectarse y verificarse automáticamente en base a un modelo puramente lingüístico.  Al mismo tiempo, la arquitectura del sistema permite agregar una cantidad arbitrariamente grande de capas adicionales de información sobre unidades lingüísticas, que pueden ser útiles en aplicaciones prácticas. <br><br>  Vamos a demostrar lo anterior con un ejemplo específico, analizando la palabra "refrigerador".  A partir del modelo lingüístico, podemos descubrir que un "refrigerador" es un objeto material, un diseño, es un contenedor del tipo "caja o bolsa", es decir  no destinado al almacenamiento de líquidos o sólidos sin un recipiente adicional.  Además, de este modelo no está claro que el "refrigerador" sea un producto básico, además, un producto duradero, y tampoco está claro que se trate de un artefacto, es decir,  Objeto hecho por el hombre.  Esta es información no lingüística, que debe suministrarse por separado. <br><br><div class="spoiler">  <b class="spoiler_title">El resultado del modelo para la palabra "refrigerador"</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/fk/jc/eh/fkjcehbnahnisns7mtsl18z3khg.png"><br></div></div><br><h2>  ¿Por qué se necesita todo esto? </h2><br>  Sea como fuere, una persona en el proceso de aprendizaje y cognición de la realidad colgó información adicional sobre los objetos y fenómenos que lo rodean en un marco natural, adquirido por él en la infancia.  Sin embargo, algunos conceptos son universales, independientes del área temática y pueden reutilizarse con éxito. <br><br>  Decir "vendedor" es una <i>persona</i> + un <i>rol funcional</i> .  En algunos casos, el vendedor puede ser un grupo de personas o una organización, pero la subjetividad siempre se conserva: de lo contrario, la acción objetivo no será posible.  Las palabras "intercambio" o "capacitación" se refieren a acciones, es decir,  tienen participantes, duración y resultado.  El contenido exacto de estas acciones puede variar significativamente según la situación y el área temática, pero ciertos aspectos serán invariables.  Este es el marco de lenguaje en el que se superpone el conocimiento extralingüístico variable. <br><br>  Nuestro objetivo es encontrar y explorar la máxima información intralingüística disponible y construir sobre una base un modelo explicativo del lenguaje.  Esto mejorará los algoritmos existentes para el procesamiento automático de texto, incluidos  tan complejas como la resolución de la ambigüedad léxica, la resolución de la anáfora, los casos complicados de marcado morfológico.  En el proceso, necesariamente descansaremos en algún lugar en contra de la necesidad de atraer conocimiento extralingüístico, pero al menos sabremos hacia dónde va la frontera cuando el conocimiento interno del idioma ya no sea suficiente. <br><br><h2>  Clasificación y entrenamiento, conjunto de atributos. </h2><br>  Por el momento, solo trabajamos con sustantivos, por lo tanto, a continuación, cuando decimos "palabra", nos referiremos a signos que se relacionan solo con esta parte del discurso.  Como decidimos usar solo información intralingüística, trabajaremos con textos equipados con marcado morfológico. <br><br>  Como signos, tomamos todos los microcontextos posibles en los que aparece esta palabra.  Para los sustantivos, estos serán: <br><br><ul><li>  APP + X <i>(hermosa X: ojos)</i> </li><li>  GLAG + X <i>(vdite X: hilo)</i> </li><li>  VL + PRED + X <i>(ingrese X: puerta)</i> </li><li>  X + SUSCH_ROD <i>(X: borde de la tabla)</i> </li><li>  SUSHCH + X_ROD <i>(manejar X: sables)</i> </li><li>  X_ SUBJECT + GL <i>(X: la trama se está desarrollando)</i> </li></ul><br>  Hay más tipos de microcontextos, pero los anteriores son los más frecuentes y ya dan un buen resultado al aprender. <br><br>  Todos los microcontextos se reducen a la forma básica y componimos un conjunto de características a partir de ellos.  A continuación, para cada palabra, componimos un vector cuya coordenada <i>i-ésima</i> se correlacionará con la aparición de una palabra dada en el microcontexto <i>i-ésimo</i> . <br><br><div class="spoiler">  <b class="spoiler_title">Tabla de microcontexto para la palabra "mochila"</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">  |  |  |  | | | | |   | VBP_ | 3043 | 1.0000 |  | ADJ | 2426 | 0.9717 |  | NX_NG | 1438 | 0.9065 |   | VBP_ | 1415 | 0.9045 |   | VBP__ | 1300 | 0.8940 |  | NX_NG | 1292 | 0.8932 |  | NX_NG | 1259 | 0.8900 |  | ADJ | 1230 | 0.8871 |  | ADJ | 1116 | 0.8749 |  | ADJ | 903 | 0.8485 |  | ADJ | 849 | 0.8408 |  | NX_NG | 814 | 0.8356 |  | ADJ | 795 | 0.8326 |  | ADJ | 794 | 0.8325 |   | VBP_ | 728 | 0.8217 |  | ADJ | 587 | 0.7948 |  | ADJ | 587 | 0.7948 |   | VBP__ | 567 | 0.7905 |   | VBP_ | 549 | 0.7865 |   | VBP__ | 538 | 0.7840 |   | VBP_ | 495 | 0.7736 |   | VBP_ | 484 | 0.7708 |  | NX_NG | 476 | 0.7687 |  | ADJ | 463 | 0.7652 |  | NX_NG | 459 | 0.7642 |</code> </pre> <br></div></div><br><h2>  Valor objetivo, jerarquía de corte semántico </h2><br>  El lenguaje tiene mecanismos naturales para la reutilización de palabras, lo que provoca la aparición de un fenómeno como la polisemia.  Además, a veces no solo se reutilizan palabras individuales, sino que se realiza una transferencia metafórica de conceptos completos.  Esto es especialmente notable en la transición de conceptos materiales a conceptos abstractos. <br><br>  Este hecho dicta la necesidad de una clasificación jerárquica, en la que las secciones semánticas se organizan en una estructura de árbol y la partición se produce en cada nodo interno.  Esto le permite lidiar con la ambigüedad en los microcontextos de manera mucho más efectiva. <br><br><div class="spoiler">  <b class="spoiler_title">Ejemplos de transferencia de conceptos metafóricos.</b> <div class="spoiler_text">  Además de resolver problemas prácticos apremiantes de la lingüística informática, nuestro trabajo tiene como objetivo estudiar la palabra y varios fenómenos lingüísticos.  La transferencia metafórica de conceptos del plano real al abstracto es un fenómeno bien conocido por los lingüistas cognitivos.  Entonces, por ejemplo, uno de los conceptos más brillantes en el mundo material es el "contenedor" de clase (en la literatura en idioma ruso a menudo se lo denomina "contenedor"). <br><br><blockquote>  Otra metáfora ontológica omnipresente es la metáfora del contenedor, o contenedor, que implica trazar límites en el continuo de nuestra experiencia y comprenderla a través de categorías espaciales.  Según los autores, la forma en que una persona percibe el mundo que la rodea está determinada por su experiencia de tratar con objetos materiales discretos y, en particular, su percepción de sí mismo, su cuerpo.  El hombre es una criatura delimitada del resto del mundo por la piel.  Es un contenedor y, por lo tanto, es común que perciba otras entidades como contenedores con una parte interna y una superficie externa. <br><br>  <i>Skrebtsova T. G. Lingüística cognitiva: teorías clásicas, nuevo</i> <i><br></i>  <i>enfoques</i> </blockquote><br>  El modelo que construimos opera en un solo espacio de atributos y nos permite aprender de ejemplos reales y hacer predicciones en el campo de lo abstracto.  Esto le permite hacer la transferencia descrita anteriormente.  Entonces, por ejemplo, las siguientes palabras son contenedores abstractos, lo cual es consistente con la idea intuitiva: <br><br><img src="https://habrastorage.org/webt/pl/cg/pm/plcgpmsr_v-ehtfgijakgx1mfz4.png"><br><br>  Otro ejemplo interesante es la transferencia del concepto de "líquido" a la esfera de lo intangible: <br><br><img src="https://habrastorage.org/webt/4q/vg/zg/4qvgzgx0lnlcoifaz-avsokq9us.png"><br></div></div><br><h2>  Selección de algoritmo </h2><br>  Como algoritmo, utilizamos la regresión logística.  Esto se debe a varios factores: <br><br><ol><li>  De una forma u otra, el marcado inicial contiene una cierta cantidad de errores y ruido. </li><li>  Los signos pueden estar desequilibrados y también contienen errores: polisemia y uso metafórico (figurado) de la palabra. </li><li>  El análisis preliminar sugiere que una interfaz adecuadamente seleccionada debe repararse con un algoritmo bastante simple. </li><li>  La buena interpretabilidad del algoritmo es importante. </li></ol><br>  El algoritmo mostró bastante buena precisión: <br><br><div class="spoiler">  <b class="spoiler_title">Registros del algoritmo de marcado</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">== ENTITY == slice | label | count | correctCount | accuracy | | | | | | ENTITY | PHYSICAL | 12249 | 11777 | 0.9615 | ENTITY | ABSTRACT | 9854 | 9298 | 0.9436 | | | | | | | | | | 0.9535 | == PHYSICAL:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:ROLE | ORGANIC | 7001 | 6525 | 0.9320 | PHYSICAL:ROLE | INORGANIC | 3805 | 3496 | 0.9188 | | | | | | | | | | 0.9274 | == PHYSICAL:ORGANIC:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:ORGANIC:ROLE | HUMAN | 4879 | 4759 | 0.9754 | PHYSICAL:ORGANIC:ROLE | ANIMAL | 675 | 629 | 0.9319 | PHYSICAL:ORGANIC:ROLE | FOOD | 488 | 411 | 0.8422 | PHYSICAL:ORGANIC:ROLE | ANATOMY | 190 | 154 | 0.8105 | PHYSICAL:ORGANIC:ROLE | PLANT | 285 | 221 | 0.7754 | | | | | | | | | | 0.9474 | == PHYSICAL:INORGANIC:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:INORGANIC:ROLE | CONSTRUCTION | 1045 | 933 | 0.8928 | PHYSICAL:INORGANIC:ROLE | THING | 2385 | 2123 | 0.8901 | PHYSICAL:INORGANIC:ROLE | SUBSTANCE | 399 | 336 | 0.8421 | | | | | | | | | | 0.8859 | == PHYSICAL:CONSTRUCTION:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:CONSTRUCTION:ROLE | TRANSPORT | 188 | 178 | 0.9468 | PHYSICAL:CONSTRUCTION:ROLE | APARTMENT | 270 | 241 | 0.8926 | PHYSICAL:CONSTRUCTION:ROLE | TERRAIN | 285 | 253 | 0.8877 | | | | | | | | | | 0.9044 | == PHYSICAL:THING:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:THING:ROLE | WEARABLE | 386 | 357 | 0.9249 | PHYSICAL:THING:ROLE | TOOLS | 792 | 701 | 0.8851 | PHYSICAL:THING:ROLE | DISHES | 199 | 174 | 0.8744 | PHYSICAL:THING:ROLE | MUSIC_INSTRUMENTS | 63 | 51 | 0.8095 | PHYSICAL:THING:ROLE | WEAPONS | 107 | 69 | 0.6449 | | | | | | | | | | 0.8739 | == PHYSICAL:TOOLS:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:TOOLS:ROLE | PHY_INTERACTION | 213 | 190 | 0.8920 | PHYSICAL:TOOLS:ROLE | INFORMATION | 101 | 71 | 0.7030 | PHYSICAL:TOOLS:ROLE | EM_ENERGY | 72 | 49 | 0.6806 | | | | | | | | | | 0.8031 | == ATTR:INORGANIC:WEARABLE == slice | label | count | correctCount | accuracy | | | | | | ATTR:INORGANIC:WEARABLE | NON_WEARABLE | 538 | 526 | 0.9777 | ATTR:INORGANIC:WEARABLE | WEARABLE | 282 | 269 | 0.9539 | | | | | | | | | | 0.9695 | == ATTR:PHYSICAL:CONTAINER == slice | label | count | correctCount | accuracy | | | | | | ATTR:PHYSICAL:CONTAINER | CONTAINER | 636 | 627 | 0.9858 | ATTR:PHYSICAL:CONTAINER | NOT_A_CONTAINER | 1225 | 1116 | 0.9110 | | | | | | | | | | 0.9366 | == ATTR:PHYSICAL:CONTAINER:TYPE == slice | label | count | correctCount | accuracy | | | | | | ATTR:PHYSICAL:CONTAINER:TYPE | CONFINED_SPACE | 291 | 287 | 0.9863 | ATTR:PHYSICAL:CONTAINER:TYPE | CONTAINER | 140 | 131 | 0.9357 | ATTR:PHYSICAL:CONTAINER:TYPE | OPEN_AIR | 72 | 64 | 0.8889 | ATTR:PHYSICAL:CONTAINER:TYPE | BAG_OR_BOX | 43 | 31 | 0.7209 | ATTR:PHYSICAL:CONTAINER:TYPE | CAVITY | 30 | 20 | 0.6667 | | | | | | | | | | 0.9253 | == ATTR:PHYSICAL:PHY_STATE == slice | label | count | correctCount | accuracy | | | | | | ATTR:PHYSICAL:PHY_STATE | SOLID | 308 | 274 | 0.8896 | ATTR:PHYSICAL:PHY_STATE | FLUID | 250 | 213 | 0.8520 | ATTR:PHYSICAL:PHY_STATE | FABRIC | 72 | 51 | 0.7083 | ATTR:PHYSICAL:PHY_STATE | PLASTIC | 78 | 42 | 0.5385 | ATTR:PHYSICAL:PHY_STATE | SAND | 70 | 31 | 0.4429 | | | | | | | | | | 0.7853 | == ATTR:PHYSICAL:PLACE == slice | label | count | correctCount | accuracy | | | | | | ATTR:PHYSICAL:PLACE | NOT_A_PLACE | 855 | 821 | 0.9602 | ATTR:PHYSICAL:PLACE | PLACE | 954 | 914 | 0.9581 | | | | | | | | | | 0.9591 | == ABSTRACT:ROLE == slice | label | count | correctCount | accuracy | | | | | | ABSTRACT:ROLE | ACTION | 1497 | 1330 | 0.8884 | ABSTRACT:ROLE | HUMAN | 473 | 327 | 0.6913 | ABSTRACT:ROLE | PHYSICS | 257 | 171 | 0.6654 | ABSTRACT:ROLE | INFORMATION | 222 | 146 | 0.6577 | ABSTRACT:ROLE | ABSTRACT | 70 | 15 | 0.2143 | | | | | | | | | | 0.7896 |</code> </pre> <br></div></div><br><h2>  Análisis de errores </h2><br>  Los errores que surgen de la clasificación automática son causados ​​por tres factores principales: <br><br><ol><li>  Homonimia y polisemia: las palabras que tienen el mismo tipo pueden tener diferentes significados (atormentar <b>a</b> y m <b>u</b> ka, detenerse <i>como un proceso</i> y detenerse <i>como una ubicación</i> ).  Esto también incluye el uso metafórico de palabras y metonimia (por ejemplo, una puerta se clasificará como un espacio cerrado; esta es una característica esperada del lenguaje). </li><li>  Desequilibrio en el contexto del uso de la palabra.  Algunos usos orgánicos pueden no estar disponibles en el paquete original, lo que lleva a errores de clasificación. </li><li>  Límite de clase no válido.  Puede trazar límites que no sean computables a partir de contextos y que requieran la participación de conocimiento extralingüístico.  Aquí el algoritmo será impotente. </li></ol><br>  En esta etapa, solo prestamos atención a los errores del tercer tipo y ajustamos el límite seleccionado entre las clases.  Los errores de los dos primeros tipos en una configuración dada del sistema no pueden eliminarse, pero con una cantidad suficiente de datos etiquetados, no representan un gran problema; esto puede verse en la precisión del marcado de las proyecciones superiores. <br><br><h2>  Que sigue </h2><br>  Por el momento, el conjunto de datos cubre la mayoría de los sustantivos existentes en el idioma ruso y representados en el corpus en una variedad suficiente de contextos.  El foco principal estaba en los objetos materiales, como los más comprensibles y elaborados en trabajos científicos.  Las tareas permanecen para refinar el marcado existente, teniendo en cuenta los datos recibidos del algoritmo, y trabajar con clases en los niveles inferiores, donde se observa una disminución en la precisión de la predicción, debido al desenfoque de los límites entre las categorías. <br><br>  Pero este es un tipo de trabajo de rutina, que siempre está ahí.  Una capa de investigación cualitativamente nueva se referirá a la posibilidad de clasificar una palabra en particular en un contexto u oración específica, lo que permitirá tener en cuenta los fenómenos de homonimia y polisemia, incluida la metáfora (significados figurativos). <br><br>  Además, actualmente estamos trabajando en varios proyectos relacionados: <br><br><ul><li>  <b>diccionario de reconocibilidad de las palabras RY: una</b> variación del diccionario de frecuencia, donde la comprensión y familiaridad de la palabra se evalúa como resultado del marcado de crowdsourcing, y no se calcula de acuerdo con el cuerpo de los textos. </li><li>  <b>corpus abierto para resolver la ambigüedad léxica: en</b> base a la competencia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RUSSE 2018 WSI &amp; D Shared Task</a> celebrada como parte de la conferencia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dialogue 2018</a> , la utilidad del corpus con la ambigüedad léxica eliminada para probar algoritmos automáticos para desambiguación y agrupación de significados de palabras se hizo evidente.  También necesitaremos este cuerpo para pasar a la etapa de trabajo sobre semántica abierta descrita en el párrafo anterior. </li></ul><br><h2>  Diccionario tonal de la lengua rusa </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El diccionario tonal</a> son las palabras y expresiones del DO, marcadas por la tonalidad y la fuerza de la gravedad de la carga de evaluación emocional.  En pocas palabras, cuánto una palabra en particular es "mala" o "buena". <br><br>  Por el momento, 67.392 caracteres están marcados (de los cuales 55.532 palabras y 11.860 expresiones). <br><br><h2>  Comentarios y distribución </h2><br>  Agradecemos cualquier comentario en los comentarios, desde críticas al trabajo y nuestros enfoques hasta enlaces a estudios interesantes y artículos relacionados. <br><br>  Si tiene conocidos o colegas que pueden estar interesados ​​en un conjunto de datos publicado, envíeles un enlace a un artículo o repositorio para ayudar a difundir los datos abiertos. <br><br><h2>  Enlace de descarga y licencia </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conjunto de datos: semántica abierta del idioma ruso</a> <br><br>  El conjunto de datos está licenciado bajo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CC BY-NC-SA 4.0</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es434154/">https://habr.com/ru/post/es434154/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es434138/index.html">Escribimos nuestra propia máquina virtual</a></li>
<li><a href="../es434140/index.html">Una breve historia de las características asincrónicas de Javascript</a></li>
<li><a href="../es434142/index.html">El equipo de QRL estableció una fecha límite ajustada para la migración de tokens</a></li>
<li><a href="../es434146/index.html">Las 10 mejores películas de TI</a></li>
<li><a href="../es434150/index.html">Características de la búsqueda de empleo en Europa</a></li>
<li><a href="../es434156/index.html">Fractal de Gerasimov. Encontrado un patrón. Mesa negra</a></li>
<li><a href="../es434158/index.html">OZON Inside: se siente como una startup</a></li>
<li><a href="../es434160/index.html">Presentación de la biblioteca kubedog para el seguimiento de recursos de Kubernetes</a></li>
<li><a href="../es434162/index.html">Face Recognition Ivideon: el sistema de reconocimiento facial más asequible para empresas</a></li>
<li><a href="../es434164/index.html">Migración de IBM Notes / Domino a Zimbra Collaboration Suite</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✝️ 👨🏿‍🤝‍👨🏼 🧓🏾 RabbitMQ与Kafka：故障转移和高可用性 🐧 🎲 👰</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="在上一篇文章中，我们检查了RabbitMQ集群的容错能力和高可用性。 现在让我们深入研究Apache Kafka。 

 在这里，复制单元是一个分区。 每个主题都有一个或多个部分。 每个部分都有带或不带跟随者的领导者。 创建主题时，将指示分区数和复制率。 通常的值为3，表示三句话：一位领导者和两位跟...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ与Kafka：故障转移和高可用性</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/474984/"><img src="https://habrastorage.org/webt/rc/zb/n7/rczbn7bwtp8b5day0whi_wace2e.jpeg"><br><br> 在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">上一篇文章中，</a>我们检查了RabbitMQ集群的容错能力和高可用性。 现在让我们深入研究Apache Kafka。 <br><br> 在这里，复制单元是一个分区。 每个主题都有一个或多个部分。 每个部分都有带或不带跟随者的领导者。 创建主题时，将指示分区数和复制率。 通常的值为3，表示三句话：一位领导者和两位跟随者。 <br><a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/ly/hd/ml/lyhdmlstwyv-tf_-ts54gife3cw.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">1.在三个经纪人中分配四个部分</font></i> <br><br> 所有的读写请求都发送给领导者。 关注者会定期向领导发送请求，以接收最新消息。 消费者从不求助于追随者，追随者仅出于冗余和容错的目的而存在。 <br><br><img src="https://habrastorage.org/webt/sb/fc/v0/sbfcv0j3mosfzvrb7qktoexl_lg.png"><br><br><h1> 部分失败 </h1><br> 当经纪人崩溃时，几个部门的领导者常常会失败。 在每个节点中，来自另一个节点的跟随者都将成为领导者。 实际上，情况并非总是如此，因为同步因素也会影响：是否有同步的跟随者，如果没有，则允许过渡到非同步副本。 但是现在，我们不要使其复杂化。 <br><br> 经纪人3离开网络-对于第2部分，选举了经纪人2的新领导者。 <br><br><img src="https://habrastorage.org/webt/im/ct/r0/imctr0qotjsjg4_jx3g6p5otk9u.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">2.经纪人3去世，其经纪人2的跟随者当选为第2节的新负责人</font></i> <br><br> 然后经纪人1离开，第1部分也失去了其领导者，而其领导者则由经纪人2承担。 <br><br><img src="https://habrastorage.org/webt/rg/fo/zp/rgfozpk7b_t1odoxso1mvihmccu.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">3.仅剩一个经纪人。</font></i>  <i><font color="gray">所有领导者都在同一个零冗余代理人上。</font></i> <br><br> 当代理1返回到网络时，他添加了四个关注者，从而为每个部分提供了一些冗余。 但是所有领导者仍然留在经纪人2上。 <br><br><img src="https://habrastorage.org/webt/mh/lj/2s/mhlj2sn5r6rcjodqnl22450bjn8.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">4.领导人留在经纪人2上</font></i> <br><br> 当代理3上升时，我们将每个部分返回三个副本。 但所有领导人仍在经纪人2上。 <br><br><img src="https://habrastorage.org/webt/3u/tb/op/3utbopk0awdg8rg62natyoxqg9o.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">5.恢复经纪人1和3后领导者的不平衡分配</font></i> <br><br> 与RabbitMQ相比，Kafka具有更好地平衡领导者的工具。 在那里，您必须使用第三方插件或脚本，这些插件或脚本通过减少迁移过程中的冗余来更改用于迁移主节点的策略。 另外，对于大队列，必须在同步期间忍受不可访问性。 <br><br> 卡夫卡在领导角色上拥有“首选线索”的概念。 创建主题部分后，Kafka会尝试将领导者均匀地分布在节点上，并将这些第一个领导者标记为首选。 随着时间的流逝，由于服务器重新引导，故障和连接故障，领导者可能最终会出现在其他节点上，如上文所述的极端情况。 <br><br> 为了解决这个问题，Kafka提供了两种选择： <br><br><ul><li>  <i>auto.leader.rebalance.enable = true</i>选项允许控制器节点自动将领导者重新分配回首选副本，从而恢复统一分发。 <br></li><li> 管理员可以运行<i>kafka-preferred-replica-election.sh</i>脚本来手动重新分配。 </li></ul><br><br><img src="https://habrastorage.org/webt/qt/2l/th/qt2lth99rb1fhzq8g4r93uoxh6k.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">6.重新平衡后的副本</font></i> <br><br> 这是故障的简化版本，但实际情况更为复杂，尽管这里没有什么太复杂的。 全部归结为同步副本（同步副本，ISR）。 <br><br><h1> 同步副本（ISR） </h1><br>  ISR是被视为“同步”（同步）的分区的一组副本。 有领导者，但可能没有跟随者。 如果追随者在复制副本<i>.lag.time.max.ms</i>间隔到期之前对所有领导者消息进行了精确复制，则认为该追随者已同步。 <br><br> 如果满足以下条件，则从ISR集中删除该关注者： <br><br><ul><li> 没有请求间隔<i>replica.lag.time.max.ms的</i>采样请求（考虑为<i>无效</i> ） <br></li><li> 没有时间更新时间间隔的<i>副本copy.lag.time.max.ms</i> （被认为很慢） </li></ul><br> 追随者会在interval.fetch.wait.max.ms间隔（默认为500毫秒）中进行获取请求。 <br><br> 为了清楚地说明ISR的目的，您需要查看生产者（生产者）的确认和一些失败情况。 生产者可以选择经纪人发送确认的时间： <br><br><ul><li>  acks = 0，不发送确认 <br></li><li>  acks = 1，在领导者将消息写入其本地日志后发送确认 <br></li><li>  acks =全部，ISR中的所有副本均已将消息写入本地日志后发送确认 </li></ul><br> 用Kafka术语，如果ISR已保存该消息，则该消息“已提交”。  Acks = all是最安全的选择，但也会带来额外的延迟。 让我们看一下两个故障示例，以及不同的“ acks”选项如何与ISR概念相互作用。 <br><br><h3>  Acks = 1和ISR </h3><br> 在此示例中，我们将看到，如果领导者不等待保存所有关注者的每条消息，那么如果领导者失败，则数据可能会丢失。 通过设置<i>unclean.leader.election.enable</i>可以启用或禁用转到不同步的跟随器。 <br><br> 在此示例中，制造商设置为acks = 1。 该部分分布在所有三个代理中。 经纪人3落后了，它在八秒钟前与领导者同步，现在落后了7456条消息。 经纪人1仅落后一秒钟。 我们的生产者发送消息并迅速收到确认，而对于领导者所不希望的缓慢或死忠的追随者却没有开销。 <br><br><img src="https://habrastorage.org/webt/ej/bh/g7/ejbhg7svgcphrhpdtzbwuw--wg4.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">7.具有三个副本的ISR</font></i> <br><br> 代理2失败，并且制造商收到连接错误。 从领导层过渡到经纪人1后，我们丢失了123条消息。 经纪人1的追随者是ISR的一部分，但在领导者跌倒时并未与他完全同步。 <br><br><img src="https://habrastorage.org/webt/6y/th/y9/6ythy9olfa5zr2wyqtfqcrq8u5e.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">8.失败后，消息将丢失</font></i> <br><br> 在<i>bootstrap.servers</i>配置中，制造商列出了几个经纪人，他可以询问另一个经纪人，谁成为了该部分的新负责人。 然后，他与代理1建立连接并继续发送消息。 <br><br><img src="https://habrastorage.org/webt/br/o6/jr/bro6jrn5nt-a0wzvg_yt0csmdgg.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">9.短暂休息后恢复发送消息</font></i> <br><br> 经纪人3进一步落后。 它发出获取请求，但无法同步。 这可能是由于代理之间的网络连接速度慢，存储问题等。已将其从ISR中删除。 现在，ISR包含一个副本-领导者！ 制造商继续发送消息并收到确认。 <br><br><img src="https://habrastorage.org/webt/b2/qj/aj/b2qjaj5g_yx2wfb-jdkalxr9074.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">10.经纪人3的关注者已从ISR中删除</font></i> <br><br> 代理1倒下，领导者的角色转给代理3，丢失15286条消息！ 制造商收到连接错误消息。 仅由于设置<i>unclean.leader.election.enable = true</i> ，才有可能在ISR之外进入领导者。 如果将其设置为<i>false</i> ，那么将不会发生转换，并且所有读取和写入请求都将被拒绝。 在这种情况下，我们正在等待代理1的返回，其中代理1的原始数据在副本中，它将再次带头。 <br><br><img src="https://habrastorage.org/webt/rr/n1/-n/rrn1-nekmhjtro9pxeueciytb50.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">11.经纪人1滴。</font></i>  <i><font color="gray">如果发生故障，则会丢失大量消息</font></i> <br><br> 制造商与最后一个经纪人建立了联系，并确定他现在是该部门的负责人。 他开始向经纪人3发送消息。 <br><br><img src="https://habrastorage.org/webt/qj/qq/go/qjqqgoevfafcmcxtidd_bvjw9wi.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">12.短暂休息后，消息再次发送到第0部分</font></i> <br><br> 我们看到，除了短暂的中断以建立新的连接并寻找新的领导者之外，制造商还不断发送消息。 此配置通过一致性（数据安全性）提供可访问性。 卡夫卡丢失了数千封邮件，但继续接受新邮件。 <br><br><h3>  Acks =全部和ISR </h3><br> 让我们再次重复这种情况，但是用<i>acks = all</i> 。 将代理3延迟平均四秒钟。 制造商发送的消息带有<i>acks = all</i> ，现在没有收到快速响应。 领导者等待，直到ISR中的所有消息都存储了该消息。 <br><br><img src="https://habrastorage.org/webt/3c/6j/a5/3c6ja5msoncfx1s-xbyjpmujtdo.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">13.具有三个副本的ISR。</font></i>  <i><font color="gray">一个很慢，导致录制延迟</font></i> <br><br> 在四秒钟的额外延迟之后，代理2发送ack。 现在，所有副本均已完全更新。 <br><br><img src="https://habrastorage.org/webt/ol/eg/y6/olegy6unibvup0tlza6cbd4gqic.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">14.所有副本均保存消息并发送确认</font></i> <br><br> 经纪人3现在更加落后，并已从ISR中删除。 由于ISR中没有慢速副本，因此可以大大减少延迟。 代理2现在仅等待代理1，他的平均延迟为500毫秒。 <br><br><img src="https://habrastorage.org/webt/ub/0e/7j/ub0e7jm1siaa9dvcmxyldti1ify.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">15.代理3上的副本已从ISR中删除</font></i> <br><br> 然后经纪人2倒下，领导权传递给经纪人1而不会丢失任何消息。 <br><br><img src="https://habrastorage.org/webt/a7/ts/8m/a7ts8mywsvuowiof5jp6f6eszlq.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">16.经纪人2下跌</font></i> <br><br> 制造商找到新的领导者并开始向他发送消息。 由于现在ISR由一个副本组成，因此延迟仍然减少了！ 因此， <i>acks = all</i>选项不会增加冗余。 <br><br><img src="https://habrastorage.org/webt/-z/i_/od/-zi_odb0nc-nf0xe1tsxmzlr-uq.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">17.代理1上的副本处于领先地位，而不会丢失消息</font></i> <br><br> 然后经纪人1倒下，领导权传递给经纪人3，损失了14,238条消息！ <br><br><img src="https://habrastorage.org/webt/sr/x5/1m/srx51mjemyxnksoewy6n91_lgqy.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">18. Broker 1死了，设置不整洁的领导层过渡导致大量数据丢失</font></i> <br><br> 我们无法将<i>unclean.leader.election.enable</i>选项设置为<i>true</i> 。 默认情况下，它为<i>false</i> 。 设置<i>acks =全部</i>为<i>unclean.leader.election.enable = true</i>可提供可访问性以及一些其他数据安全性。 但是，正如您所看到的，我们仍然会丢失消息。 <br><br> 但是，如果我们想提高数据安全性怎么办？ 您可以设置<i>unclean.leader.election.enable = false</i> ，但这并不一定能防止数据丢失。 如果领导者摔倒并随身携带了数据，那么消息仍然会丢失，并且可访问性也会丢失，直到管理员恢复情况为止。 <br><br> 最好保证所有消息的冗余，否则拒绝记录。 然后，至少从代理的角度来看，只有同时发生两个或多个故障，才有可能发生数据丢失。 <br><br><h3>  Acks =全部，最小不同步副本和ISR </h3><br> 使用<i>min.insync.replicas</i>主题<i>配置，</i>我们可以提高数据安全性。 让我们再次遍历最后一个场景的最后一部分，但是这次是<i>min.insync.replicas = 2</i> 。 <br><br> 因此，代理2具有副本领导者，并且代理3的跟随者已从ISR中删除。 <br><br><img src="https://habrastorage.org/webt/5g/ij/ls/5gijlstkvqxo4ojr6wfxxwn719m.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">19.两个副本的ISR</font></i> <br><br> 经纪人2倒下，领导权传递给经纪人1而不会丢失任何消息。 但是现在，ISR仅包含一个副本。 这与接收记录的最小数量不对应，因此代理对记录尝试进行响应，并显示<i>NotEnoughReplicas</i>错误。 <br><br><img src="https://habrastorage.org/webt/ng/p5/fj/ngp5fjym6nvykpohj8brnl8bvxc.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">20. ISR的数量比min.insync.replicas中指定的数量少一</font></i> <br><br> 此配置会牺牲可用性以保持一致性。 在确认消息之前，我们保证将其记录在至少两个副本上。 这使制造商更有信心。 在此，只有两个副本在短时间内同时失败，消息丢失才有可能，直到将消息复制到其他跟随者为止，这是不可能的。 但是，如果您是超级<i>偏执狂</i> ，则可以将复制比率设置为5，将<i>min.insync.replicas设置</i>为3。然后，必须同时跌倒三个代理才能丢失记录！ 当然，为了获得这种可靠性，您将付出额外的延迟。 <br><br><h1> 需要数据安全性的可访问性时 </h1><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">与RabbitMQ一样</a> ，有时为了数据安全性，必须<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">具有</a>可访问性。 您需要考虑一下： <br><br><ul><li> 发布者可以返回错误，而更高的服务或用户以后再试吗？ <br></li><li> 发布者可以在本地或数据库中保存邮件以供稍后重试吗？ </li></ul><br> 如果答案是否定的，那么优化可访问性将提高数据安全性。 如果选择可用性而不是放弃录制，则丢失的数据将更少。 因此，一切都取决于找到平衡，而决定取决于具体情况。 <br><br><h1>  ISR的含义 </h1><br>  ISR套件使您可以在数据安全性和延迟之间选择最佳的平衡。 例如，要确保在发生故障时可以访问大多数副本，就延迟而言，将死副本或慢副本的影响降到最低。 <br><br> 我们根据自己的需要选择<i>copy.lag.time.max.ms</i>的值。 本质上，此参数表示我们准备接受<i>acks = all的</i>延迟时间。 默认值为十秒。 如果这对您来说太长了，您可以减少它。 然后，ISR中更改的频率将增加，因为追随者将被更频繁地删除和添加。 <br><br>  RabbitMQ只是需要复制的一组镜像。 慢速镜像会带来额外的延迟，并且在检查每个节点的可用性的数据包到期之前（网络滴答声），可以预期死镜像的响应。  ISR是一种避免延迟增加的问题的有趣方法。 但是我们有失去冗余的风险，因为ISR只能简化为领导者。 为避免这种风险，请使用<i>min.insync.replicas</i>设置。 <br><br><h1> 客户连接保证 </h1><br> 在制造商和消费者的<i>bootstrap.servers</i>设置中，可以指定几个代理来连接客户端。 这个想法是，当您断开一个节点的连接时，客户端可以使用几个备用节点来打开连接。 这些不一定是部门负责人，而仅仅是引导的跳板。 客户端可以询问他们读/写部分的负责人位于哪个节点上。 <br><br> 在RabbitMQ中，客户端可以连接到任何主机，并且内部路由会在必要时发送请求。 这意味着您可以在RabbitMQ的前面安装负载均衡器。  Kafka要求客户端连接到托管相应分区负责人的主机。 在这种情况下，负载均衡器将无法交付。  <i>bootstrap.servers</i>列表至关重要，因此客户端可以访问正确的节点并在崩溃后找到它们。 <br><br><h1> 卡夫卡共识架构 </h1><br> 到目前为止，我们还没有考虑集群如何发现经纪人的倒台以及如何选择新的领导者。 要了解Kafka如何与网络分区一起使用，您首先需要了解共识架构。 <br><br> 每个Kafka群集都与Zookeeper群集一起部署-这是一种分布式共识服务，它允许系统在某些给定状态下以一致性优先于可用性来达成共识。 批准读写操作需要大多数Zookeeper节点的同意。 <br><br>  Zookeeper存储集群状态： <br><br><ul><li> 主题，部分，配置，当前领导者副本，首选副本的列表。 <br></li><li> 集群成员。 每个代理将ping到Zookeeper群集中。 如果他在给定的时间内没有收到ping命令，则Zookeeper将使该代理无法访问。 <br></li><li> 控制器的主节点和辅助节点的选择。 </li></ul><br> 控制器节点是负责选举副本领导者的Kafka经纪人之一。  Zookeeper向控制器发送集群成员资格和主题更改的通知，并且控制器必须根据这些更改采取行动。 <br><br> 例如，以一个具有十个部分且复制系数为3的新主题为例。控制器必须选择每个部分的领导者，以尝试在代理之间最佳地分布领导者。 <br><br> 对于每个部分，控制器： <br><br><ul><li> 更新Zookeeper中有关ISR和领导者的信息； <br></li><li> 向发布此部分副本的每个经纪人发送一个LeaderAndISRCommand命令，以通知经纪人有关ISR和领导者的信息。 </li></ul><br> 当具有领导者的经纪人跌倒时，Zookeeper将通知发送给控制者，然后他选择新的领导者。 再次，控制器首先更新Zookeeper，然后向每个代理发送命令，以通知他们领导层的变化。 <br><br> 每个负责人负责招募情监侦。  <i>copy.lag.time.max.ms设置</i>确定谁将去那里。 当ISR发生变化时，领导者会将新信息传递给Zookeeper。 <br><br>  Zookeeper始终会收到有关任何更改的通知，以便在发生故障时，管理层可以平稳地转移到新的主管。 <br><br><img src="https://habrastorage.org/webt/yi/1v/in/yi1vinwmeg4exdiautqohweg8rq.png"><br>  <i><font color="gray">图</font></i>  <i><font color="gray">21.卡夫卡共识</font></i> <br><br><h1> 复制协议 </h1><br> 了解复制详细信息有助于您更好地了解潜在的数据丢失情况。 <br><br><h3> 样品要求，原木末端偏移量（LEO）和高水位线（HW） </h3><br> 我们认为追随者会定期将获取请求发送给领导者。 默认间隔为500毫秒。 这与RabbitMQ的不同之处在于，在RabbitMQ中，复制不是由队列镜像启动，而是由向导启动。 主机将更改推送到镜像。 <br><br> 领导者和所有跟随者保留对数末端偏移（LEO）和高水位（HW）标签。  LEO标记将最后一条消息的偏移量存储在本地副本中，而硬件将最后一次提交的偏移量存储在本地副本中。 请记住，对于提交状态，该消息必须保存在所有ISR副本中。 这意味着LEO通常比HW稍微领先。 <br><br> 领导者收到消息后，将其保存在本地。 跟随者发出获取请求，并传递他的LEO。 然后，领导者发送一个从此LEO开始的消息包，并发送当前的硬件。 领导者收到有关所有副本已按给定偏移量保存邮件的信息时，他将移动HW标记。 只有领导者才能移动硬件，因此所有关注者都将在对其请求的响应中知道当前值。 这意味着追随者在硬件的报告和知识方面都可能落后于领导者。 消费者仅收到当前硬件之前的消息。 <br><br> 请注意，“持久”是指写入内存，而不是磁盘。 为了提高性能，Kafka以指定的时间间隔同步到磁盘。  RabbitMQ也有这样的间隔，但是只有在主服务器和所有镜像将消息写入磁盘后，它才会向发布者发送确认。 由于性能原因，Kafka开发人员决定在消息写入内存后立即发送ack。  Kafka依靠这样的事实，即冗余可弥补仅在内存中短期存储已确认消息的风险。 <br><br><h1> 领导失败 </h1><br> 当领导者跌倒时，Zookeeper会通知控制器，然后他选择一个新的领导者副本。 新领导人根据他的LEO设置了新的硬件标记。 然后关注者会收到有关新领导者的信息。 根据Kafka的版本，关注者将选择以下两种情况之一： <br><br><ol><li> 将本地日志截断到著名的硬件，并在此标记之后向新领导发送消息。 <br></li><li>   ,   HW     ,       .       ,    . </li></ol><br>        : <br><br><ul><li>    ,     ISR,   Zookeeper,     .    ISR,    «»,          .  ,        . Kafka ,     .  ,   ,         HW      .    ,   <i>acks=all</i>    . <br></li><li>     .      ,        .  ,       ,  ,   ,    ,        . </li></ul><br><h3>  c  </h3><br>        ,     :          HW (  ).  , RabbitMQ       .        .    ,             «    ».            .       . <br><br> Kafka —   ,       ,   RabbitMQ,        .      .  Kafka —      ,        .            .    Kafka      HW  (   )   ,     .    ,    ,       ,     LEO. <br><br>        ISR     .      ,    ,  ,         ISR.          . <br><br><h1>   </h1><br>  Kafka  ,   RabbitMQ,      ,     .  Kafka    ,      . <br><br>      : <br><br><ul><li>  1.    ,     Zookeeper. <br></li><li>  2.      ,     Zookeeper. <br></li><li>  3.   ,    Zookeeper. <br></li><li>  4.   ,    Zookeeper. <br></li><li>  5.        Kafka,   Zookeeper. <br></li><li>  6.        Kafka,   Zookeeper. <br></li><li>  7.   Kafka     Kafka. <br></li><li>  8.  Kafka   Zookeeper. </li></ul><br>      . <br><br><h3>  1.    ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/je/cd/f1/jecdf1kc9y8gc8ej5sfmuelo30a.png"><br> <i><font color="gray">. 22.  1. ISR   </font></i> <br><br>     3   1  2,    Zookeeper.  3       .    <i>replica.lag.time.max.ms</i>    ISR      .    ,         ISR,   . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/ir/tq/ir/irtqir6cr8whigmvfqo1t-bbsso.png"><br> <i><font color="gray">. 23.  1.    ISR,            replica.lag.time.max.ms</font></i> <br><br>     (split-brain)   ,   RabbitMQ.    . <br><br><h3>  2.      ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/ri/fy/q6/rifyq652am8lmbhlgpfvfq-pjnm.png"><br> <i><font color="gray">. 24.  2.    </font></i> <br><br>       ,      Zookeeper.     , ISR ,       ,        .  ,    .        ,    . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/hj/8g/-1/hj8g-1veu8rkisccp7t6c9bxq7k.png"><br> <i><font color="gray">. 25.  2. ISR    </font></i> <br><br><h3>  3.   ,    Zookeeper </h3><br>    Zookeeper,      .           ISR. Zookeeper        ,     ,     . <br><br><img src="https://habrastorage.org/webt/cv/tb/gj/cvtbgjgw7ub1w8dmii46aql3bhc.png"><br> <i><font color="gray">. 26.  3.       </font></i> <br><br><h3>  4.   ,    Zookeeper </h3><br><img src="https://habrastorage.org/webt/zw/k4/8o/zwk48obscffldqgdhpyl0dvvipc.png"><br> <i><font color="gray">. 27.  4.    </font></i> <br><br>    Zookeeper,      . <br><br><img src="https://habrastorage.org/webt/eh/s1/hx/ehs1hxu4sako2udflhmhhbqhtsu.png"><br> <i><font color="gray">. 28.  4.    Zookeeper</font></i> <br><br>    Zookeeper        .      .      ,           <i>acks=1</i> .        ,         ISR   .        Zookeeper,     ,         . <br><br>  <i>acks=all</i>   ,    ISR   ,      .        ISR,          - . <br><br>            .    ,   ,     ,       HW,        ,    .         .     ,    .     ,        ,    . <br><br><img src="https://habrastorage.org/webt/pt/z_/pn/ptz_pnhoyrwvw4v-l9re3ffjzcg.png"><br> <i><font color="gray">. 29.  4.    1     </font></i> <br><br><h3>  5.        Kafka,   Zookeeper </h3><br>        Kafka,   Zookeeper.     ISR,    ,    . <br><br><img src="https://habrastorage.org/webt/ik/aj/a1/ikaja1i4z3fnodbcmam8sp2jbjc.png"><br> <i><font color="gray">. 30.  5.     ISR</font></i> <br><br><h3>  6.        Kafka,   Zookeeper </h3><br><img src="https://habrastorage.org/webt/cz/5h/2m/cz5h2mnqelpalxozp-jv4yv23rc.png"><br> <i><font color="gray">. 31.  6.    </font></i> <br><br>      ,   Zookeeper.          <i>acks=1</i> . <br><br><img src="https://habrastorage.org/webt/pj/pi/vj/pjpivjf1bsnvowntmkjqxdzipfe.png"><br> <i><font color="gray">. 32.  6.      Kafka  Zookeeper</font></i> <br><br>      <i>replica.lag.time.max.ms</i> ,    ISR   ,     ,     Zookeeper,     . <br><br>  , Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/g8/rg/wo/g8rgwol3elzkz8dwxojtclogyns.png"><br> <i><font color="gray">. 33.  6.  </font></i> <br><br>         ,      .    60    .            . <br><br><img src="https://habrastorage.org/webt/zu/zl/dh/zuzldhf62qbynz_voxil-25roxe.png"><br> <i><font color="gray">. 34.  6.     </font></i> <br><br>     ,       .    ,    Zookeeper ,     .      HW           . <br><br><img src="https://habrastorage.org/webt/zj/5e/vd/zj5evdyqhphl9uupogfvbjx7zjk.png"><br> <i><font color="gray">. 35.  6.        </font></i> <br><br>           ,    <i>acks=1</i>  <i>min.insync.replicas</i>  1.        ,    ,     ,     ,         —    ,   .       ,    <i>acks=1</i> . <br><br>     ,       ,    ISR   .    -  .   ,      ,  <i>acks=all</i> ,    ISR    .       .      — <i>min.insync.replicas = 2</i> . <br><br><h3>  7.   Kafka     Kafka </h3><br>  ,      Kafka          .         ,    6.             . <br><br><h3>  8.  Kafka   Zookeeper </h3><br>    Zookeeper         Kafka.       ,       Zookeeper,         .    ,  ,     ,     Kafka. <br><br><h3>    </h3><br>  ,         ,     ,    . , ,     ,      . <br><br>  -      Zookeeper,        <i>acks=1</i> .    Zookeeper       .     <i>acks=all</i> . <br><br>  <i>min.insync.replicas</i>        ,         ,    6. <br><br><h1>     </h1><br>   ,      Kafka: <br><br><ul><li>   ,      <i>acks=1</i> <br></li><li>   (unclean)  ,       ISR,   <i>acks=all</i> <br></li><li>    Zookeeper,      <i>acks=1</i> <br></li><li>   ,     ISR   .    ,  <i>acks=all</i> .      ,  <i>min.insync.replicas=1</i> . <br></li><li>     .     ,       .        . </li></ul><br>     ,   ,      .    —   <i>acks=all</i>  <i>min.insync.replicas</i>  1. <br><br><h1>    RabbitMQ  Kafka </h1><br>              .   RabbitMQ   .        ,   .           RabbitMQ.       ,    .       .    ,         ( )       . <br><br>  Kafka   .          .    .  ,    .    ,     ,           . , -  ,       .     ,      . <br><br> RabbitMQ  Kafka         .    , RabbitMQ              .        : <br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 每几百毫秒执行一次fsync </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">只有在检查每个节点的可用性的数据包的生存期（网络滴答）之后，才能检测到镜像。</font><font style="vertical-align: inherit;">如果镜子减速或倒下，则会增加延迟。</font></font></li></ul><br>  Kafka依赖以下事实：如果消息存储在多个节点上，则可以在消息进入内存后立即对其进行确认。 因此，在同时发生故障的情况下，可能会丢失任何类型的消息（偶数<i>acks = all</i> ， <i>min.insync.replies = 2</i> ）。 <br><br> 总体而言，Kafka表现出更好的性能，最初是为集群设计的。 如果需要，为了提高可靠性，可以将跟随者的数量增加到11个。 复制因子5和处于<i>min.insync.replicas = 3</i>的同步状态下的最小副本数将使消息丢失成为非常罕见的事件。 如果您的基础结构能够提供这样的复制速率和一定程度的冗余，则可以选择此选项。 <br><br>  RabbitMQ集群适用于小型队列。 但是即使是很小的队列也可以随着高流量而快速增长。 一旦队列变大，您将不得不在可用性和可靠性之间做出艰难的选择。  RabbitMQ集群最适合非典型情况，在这种情况下，RabbitMQ灵活性的优势胜过集群的任何劣势。 <br><br>  RabbitMQ的大队列漏洞的对策之一就是将它们分解为许多较小的对策。 如果您不需要整个队列的全部顺序，而只需要相关消息（例如，特定客户的消息），或者根本不需要所有消息，那么此选项是可以接受的：请查看我的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Rebalanser</a>项目以拆分队列（该项目仍处于早期阶段）。 <br><br> 最后，不要忘记RabbitMQ和Kafka的集群和复制机制中的许多错误。 随着时间的流逝，系统变得越来越成熟和稳定，但是没有一条消息能够100％受到保护，不会丢失！ 此外，数据中心还会发生大规模事故！ <br><br> 如果我错过任何事情，犯了一个错误或者您不同意任何观点，请随时发表评论或与我联系。 <br><br> 人们经常问我：“选择什么，Kafka还是RabbitMQ？”，“哪个平台更好？”。 事实是，这实际上取决于您的情况，当前的经验等。我不敢发表自己的意见，因为对于所有用例和可能的限制推荐任何一种平台都太简单了。 我写了这一系列文章，以便您形成自己的见解。 <br><br> 我想说两个系统都是该领域的领导者。 也许我有些偏颇，因为从我的项目经验中，我更倾向于欣赏诸如保证消息顺序和可靠性之类的东西。 <br><br> 我看到其他缺乏这种可靠性和无法保证订购的技术，然后看了RabbitMQ和Kafka-我了解这两种系统的不可思议的价值。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN474984/">https://habr.com/ru/post/zh-CN474984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN474968/index.html">RxDart适用于最小的项目</a></li>
<li><a href="../zh-CN474970/index.html">如何使用Python on Ontology编写智能合约？ 第5部分：本机API</a></li>
<li><a href="../zh-CN474976/index.html">划船城市：威尼斯如何没有汽车而存在</a></li>
<li><a href="../zh-CN474978/index.html">IBM Watson视觉识别：IBM Cloud中现已提供对象识别</a></li>
<li><a href="../zh-CN474982/index.html">JavaFX教程：FXML和SceneBuilder</a></li>
<li><a href="../zh-CN474988/index.html">欢迎来到Mitap：面向初学者的数据科学职业</a></li>
<li><a href="../zh-CN474990/index.html">艰苦实践：如何在城市公园中建立Wi-Fi网络</a></li>
<li><a href="../zh-CN474992/index.html">分析笔记本电脑电池故障。 电动摩托笔记</a></li>
<li><a href="../zh-CN474994/index.html">如何在不损失一致性的情况下将整体切入服务并保持内存中缓存的性能</a></li>
<li><a href="../zh-CN474996/index.html">11月的IT事件摘要（第二部分）</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
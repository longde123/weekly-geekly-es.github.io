<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå≥ üêπ üßòüèø Jedi Convolution Network Reduction-Technik - Beschneiden üöú ‚úíÔ∏è ‚úãüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor Ihnen liegt wieder die Aufgabe, Objekte zu erkennen. Priorit√§t - Geschwindigkeit mit akzeptabler Genauigkeit. Sie nehmen die Architektur von YOLOv...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Jedi Convolution Network Reduction-Technik - Beschneiden</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482050/"><p><img src="https://habrastorage.org/webt/tf/oa/br/tfoabr16w_dawnzb9hnjndyv_bg.png" alt="Bild"></p><br><p>  Vor Ihnen liegt wieder die Aufgabe, Objekte zu erkennen.  Priorit√§t - Geschwindigkeit mit akzeptabler Genauigkeit.  Sie nehmen die Architektur von YOLOv3 und trainieren sie.  Die Genauigkeit (mAp75) ist gr√∂√üer als 0,95.  Aber die Laufgeschwindigkeit ist immer noch niedrig.  H√∂lle </p><br><p>  Heute werden wir die Quantisierung umgehen.  Betrachten Sie unter dem Schnitt <strong>Model Pruning</strong> - Schneiden Sie redundante Netzwerkteile, um die Inferenz zu beschleunigen, ohne an Genauigkeit zu verlieren.  Optisch - wo, wie viel und wie schneiden.  Lassen Sie uns herausfinden, wie dies manuell erfolgt und wo Sie automatisieren k√∂nnen.  Am Ende befindet sich ein Repository f√ºr Keras. </p><a name="habracut"></a><br><h3 id="vvedenie">  Einleitung </h3><br><p>  Am letzten Arbeitsplatz, Perm Macroscop, hatte ich die Angewohnheit, immer die Ausf√ºhrungszeit der Algorithmen zu √ºberwachen.  Die Netzwerklaufzeit sollte immer √ºber den Angemessenheitsfilter √ºberpr√ºft werden.  Normalerweise besteht der Stand der Technik in der Produktion diesen Filter nicht, was mich zu Pruning f√ºhrte. </p><br><p>  Beschneiden ist ein altes Thema, <a href="https://www.youtube.com/watch%3Fv%3DeZdOkDtYMoo" rel="nofollow">√ºber das</a> in den <a href="https://www.youtube.com/watch%3Fv%3DeZdOkDtYMoo" rel="nofollow">Stanford-Vorlesungen</a> 2017 gesprochen wurde.  Die Hauptidee besteht darin, die Gr√∂√üe des trainierten Netzwerks zu reduzieren, ohne an Genauigkeit zu verlieren, indem verschiedene Knoten entfernt werden.  Klingt cool, aber ich h√∂re selten von seiner Verwendung.  Wahrscheinlich gibt es nicht genug Implementierungen, es gibt keine russischsprachigen Artikel oder einfach jeder denkt dar√ºber nach, das Know-how zu beschneiden und zu schweigen. <br>  Aber geh auseinander nehmen </p><br><h3 id="vzglyad-v-biologiyu">  Ein Blick in die Biologie </h3><br><p>  Ich liebe es, wenn in Deep Learning Ideen aus der Biologie kommen.  Man kann ihnen wie der Evolution vertrauen (wussten Sie, dass ReLU der <a href="http://www.gatsby.ucl.ac.uk/~lmate/biblio/dayanabbott.pdf" rel="nofollow">Funktion der Aktivierung von Neuronen im Gehirn</a> sehr √§hnlich ist?) </p><br><p>  Der Model-Pruning-Prozess ist auch der Biologie nahe.  Die Netzwerkantwort kann hier mit der Plastizit√§t des Gehirns verglichen werden.  Ein paar interessante Beispiele sind in <a href="https://www.litres.ru/norman-doydzh/plastichnost-mozga/%3Futm_medium%3Dcpc%26utm_source%3Dgoogle%26utm_campaign%3DDSA%257C149839530%26utm_term%3D%26utm_content%3Dk50id%257Caud-499675211712%253Adsa-179513627318%257Ccid%257C149839530%257Caid%257C248455294996%257Cgid%257C6837176850%257Cpos%257C1t1%257Csrc%257Cg_%257Cdvc%257Cc%257Creg%257C1011993%257Crin%257C%257C%26k50id%3D6837176850%257Caud-499675211712%253Adsa-179513627318%26gclid%3DCj0KCQiA0ZHwBRCRARIsAK0Tr-oKPqkmL7_Oxg62JZO8Jlk9zO-9nYKIRFxHi_lgoCvsQQadvUGxUzkaApgpEALw_wcB" rel="nofollow">Norman Dodges</a> Buch: </p><br><ol><li>  Das Gehirn einer Frau, die von Geburt an nur eine H√§lfte hatte, programmierte sich neu, um die Funktionen der fehlenden H√§lfte zu erf√ºllen </li><li>  Der Typ hat sich den Teil des Gehirns erschossen, der f√ºr das Sehen verantwortlich ist.  Im Laufe der Zeit √ºbernahmen andere Teile des Gehirns diese Funktionen.  (nicht noch einmal versuchen) </li></ol><br><p>  So k√∂nnen Sie aus Ihrem Modell einige der schwachen B√ºndel herausschneiden.  In extremen F√§llen k√∂nnen die verbleibenden B√ºndel die abgeschnittenen ersetzen. </p><br><h3 id="lyubish-transfer-learning-ili-uchish-s-nulya">  M√∂gen Sie Transfer Learning oder lernen Sie von Grund auf neu? </h3><br><p>  <strong>Option Nummer eins.</strong>  Sie verwenden Transfer Learning f√ºr Yolov3.  Netzhaut, Maske-RCNN oder U-Netz.  Meistens m√ºssen wir jedoch nicht 80 Klassen von Objekten erkennen, wie dies bei COCO der Fall ist.  In meiner Praxis ist alles auf 1-2 Stunden begrenzt.  Es ist davon auszugehen, dass die Architektur f√ºr 80 Klassen hier redundant ist.  Es ist der Gedanke, dass die Architektur reduziert werden muss.  Dar√ºber hinaus m√∂chte ich dies tun, ohne die vorhandenen vortrainierten Gewichte zu verlieren. </p><br><p>  <strong>Option Nummer zwei.</strong>  M√∂glicherweise verf√ºgen Sie √ºber viele Daten- und Computerressourcen, oder Sie ben√∂tigen nur eine benutzerdefinierte Architektur.  Nicht wichtig.  Aber Sie lernen das Netzwerk von Grund auf.  Die √ºbliche Reihenfolge besteht darin, die Datenstruktur zu untersuchen, eine leistungsreduzierte Architektur auszuw√§hlen und die Schulungsabbrecher von der Umschulung abzuhalten.  Ich habe Aussetzer 0.6 gesehen, Carl. </p><br><p>  In beiden F√§llen kann das Netzwerk reduziert werden.  Gef√∂rdert.  Nun wollen wir herausfinden, welche Art von <del>  Beschneidung </del>  beschneiden </p><br><h3 id="obschiy-algoritm">  Allgemeiner Algorithmus </h3><br><p>  Wir beschlossen, die Faltung zu beseitigen.  Es sieht sehr einfach aus: </p><br><p><img src="https://habrastorage.org/webt/ey/yt/-g/eyyt-g-b6pfzjrbnim_ssosyqqk.png"></p><br><p>  Das Entfernen von Faltungen ist eine Belastung f√ºr das Netzwerk, die normalerweise zu einer gewissen Zunahme der Fehler f√ºhrt.  Einerseits ist dieses Fehlerwachstum ein Indikator daf√ºr, wie richtig wir die Faltung entfernen (z. B. zeigt ein gro√ües Wachstum an, dass wir etwas falsch machen).  Ein geringes Wachstum ist jedoch durchaus akzeptabel und wird h√§ufig durch anschlie√üendes leichtes Weiterbilden mit einem kleinen LR eliminiert.  Wir f√ºgen einen Schritt der Umschulung hinzu: </p><br><p><img src="https://habrastorage.org/webt/kb/ui/5d/kbui5dm1k8sgflm5xzu0wggbbhs.png"></p><br><p>  Jetzt m√ºssen wir verstehen, wann wir unseren Lernzyklus &lt;-&gt; Beschneiden beenden m√∂chten.  Es kann exotische Optionen geben, wenn wir das Netzwerk auf eine bestimmte Gr√∂√üe und Geschwindigkeit reduzieren m√ºssen (z. B. f√ºr mobile Ger√§te).  Die h√§ufigste Option ist jedoch, den Zyklus fortzusetzen, bis der Fehler h√∂her als der zul√§ssige ist.  Bedingung hinzuf√ºgen: </p><br><p><img src="https://habrastorage.org/webt/1i/pi/52/1ipi52uqhkciw2ne-1zt2rbdmje.png"></p><br><p>  So wird der Algorithmus klar.  Es bleibt zu zerlegen, wie die gel√∂schten Windungen zu bestimmen sind. </p><br><h3 id="poisk-udalyaemyh-svertok">  Suche nach Faltung, die gel√∂scht werden soll </h3><br><p>  Wir m√ºssen einige Windungen entfernen.  Es ist eine schlechte Idee, vorauszurennen und irgendetwas abzuschie√üen, obwohl es funktionieren wird.  Aber wenn Sie einen Kopf haben, k√∂nnen Sie denken und versuchen, "schwache" Windungen zum Entfernen auszuw√§hlen.  Es gibt verschiedene M√∂glichkeiten: </p><br><ol><li>  <a href="https://openreview.net/pdf%3Fid%3DrJqFGTslg" rel="nofollow">Das kleinste L1-Ma√ü oder Low_magnitude_pruning</a> .  Die Idee, dass Windungen mit kleinen Gewichten einen kleinen Beitrag zur endg√ºltigen Entscheidung leisten </li><li>  Das kleinste L1-Ma√ü unter Ber√ºcksichtigung von Mittelwert und Standardabweichung.  Wir erg√§nzen die Bewertung der Art der Verteilung. </li><li>  <a href="https://arxiv.org/abs/1512.08571" rel="nofollow">Maskieren von Windungen und Eliminieren der geringsten Beeintr√§chtigung der resultierenden Genauigkeit</a> .  Eine genauere Definition von unbedeutenden Windungen, aber sehr zeitaufwendig und ressourcenintensiv. </li><li>  Andere </li></ol><br><p>  Jede der Optionen hat das Recht auf Leben und ihre eigenen Implementierungsmerkmale.  Hier betrachten wir die Variante mit dem kleinsten L1-Ma√ü </p><br><h3 id="ruchnoy-process-dlya-yolov3">  Manueller Prozess f√ºr YOLOv3 </h3><br><p>  Die urspr√ºngliche Architektur enth√§lt Restbl√∂cke.  Aber egal wie cool sie f√ºr tiefe Netzwerke sind, sie werden uns etwas behindern.  Die Schwierigkeit besteht darin, dass Sie in diesen Layern keine Abstimmungen mit verschiedenen Indizes l√∂schen k√∂nnen: </p><br><p><img src="https://habrastorage.org/webt/mh/p-/-k/mhp--ksk3ifgurz5jx6exgcrm5c.png"></p><br><p>  Daher w√§hlen wir die Ebenen aus, aus denen wir Abstimmungen frei entfernen k√∂nnen: </p><br><p><img src="https://habrastorage.org/webt/qy/ek/zo/qyekzofcur-q0auqurg3egxnato.png"></p><br><p>  Bauen wir nun einen Arbeitszyklus auf: </p><br><ol><li>  Aktivierung entladen </li><li>  Wir fragen uns, wie viel zu schneiden ist </li><li>  Ausschneiden </li><li>  Lernen Sie 10 Epochen mit LR = 1e-4 </li><li>  Testen </li></ol><br><p>  Das Entladen von Windungen ist n√ºtzlich, um zu bewerten, welchen Teil wir in einem bestimmten Schritt entfernen k√∂nnen.  Beispiele f√ºr das Entladen: </p><br><p><img src="https://habrastorage.org/webt/rp/jo/pk/rpjopk6dzfrl6psoucr8tgj0log.png"></p><br><p>  Wir sehen, dass fast √ºberall 5% der Windungen eine sehr niedrige L1-Norm haben und wir sie entfernen k√∂nnen.  Bei jedem Schritt wurde ein solches Entladen wiederholt, und es wurde bewertet, welche Schichten und wie viel geschnitten werden konnten. </p><br><p>  Der gesamte Vorgang wurde in 4 Schritten abgeschlossen (hier und √ºberall die Nummern f√ºr den RTX 2060 Super): </p><br><div class="scrollable-table"><table><thead><tr><th>  Schritt </th><th>  mAp75 </th><th>  Die Anzahl der Parameter in Millionen </th><th>  Netzwerkgr√∂√üe, mb </th><th>  Vom Original% </th><th>  Laufzeit, ms </th><th>  Beschneidungszustand </th></tr></thead><tbody><tr><td>  0 </td><td>  0,9656 </td><td>  60 </td><td>  241 </td><td>  100 </td><td>  180 </td><td>  - </td></tr><tr><td>  1 </td><td>  0.9622 </td><td>  55 </td><td>  218 </td><td>  91 </td><td>  175 </td><td>  5% von allen </td></tr><tr><td>  2 </td><td>  0.9625 </td><td>  50 </td><td>  197 </td><td>  83 </td><td>  168 </td><td>  5% von allen </td></tr><tr><td>  3 </td><td>  0.9633 </td><td>  39 </td><td>  155 </td><td>  64 </td><td>  155 </td><td>  15% f√ºr Schichten mit einer Faltung von 400+ </td></tr><tr><td><del>  4 </del></td><td><del>  0,9555 </del></td><td><del>  31 </del></td><td><del>  124 </del></td><td><del>  51 </del></td><td><del>  146 </del></td><td><del>  10% f√ºr Schichten mit 100+ Faltung </del></td></tr></tbody></table></div><br><p>  Zu Schritt 2 wurde ein positiver Effekt hinzugef√ºgt - die Patchgr√∂√üe 4 wurde gespeichert, was den Umschulungsprozess erheblich beschleunigte. <br>  In Schritt 4 wurde der Prozess gestoppt, weil  Selbst eine l√§ngere Weiterbildung hat den mAp75 nicht auf alte Werte angehoben. <br>  Infolgedessen ist es uns gelungen, die Inferenz um <strong>15%</strong> zu beschleunigen, die Gr√∂√üe um <strong>35% zu</strong> reduzieren und nicht an Genauigkeit zu verlieren. </p><br><h3 id="avtomatizaciya-dlya-bolee-prostyh-arhitektur">  Automatisierung f√ºr einfachere Architekturen </h3><br><p>  F√ºr einfachere Netzwerkarchitekturen (ohne bedingte Additions-, Concaternate- und Restbl√∂cke) ist es durchaus m√∂glich, sich auf die Verarbeitung aller Faltungsschichten zu konzentrieren und den Prozess des Schneidens von Faltungen zu automatisieren. </p><br><p>  Ich habe <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">diese</a> Option <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">hier</a> implementiert. <br>  Es ist ganz einfach: Sie haben nur eine Verlustfunktion, einen Optimierer und Batch-Generatoren: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pruning <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequence train_batch_generator = BatchGenerator... score_batch_generator = BatchGenerator... opt = Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>) pruner = pruning.Pruner(<span class="hljs-string"><span class="hljs-string">"config.json"</span></span>, <span class="hljs-string"><span class="hljs-string">"categorical_crossentropy"</span></span>, opt) pruner.prune(train_batch, valid_batch)</code> </pre> <br><p>  Bei Bedarf k√∂nnen Sie die Konfigurationsparameter √§ndern: </p><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"input_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"output_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model_pruned.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"finetuning_epochs"</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, # the number of epochs for train between pruning steps <span class="hljs-attr"><span class="hljs-attr">"stop_loss"</span></span>: <span class="hljs-number"><span class="hljs-number">0.1</span></span>, # loss for stopping process <span class="hljs-attr"><span class="hljs-attr">"pruning_percent_step"</span></span>: <span class="hljs-number"><span class="hljs-number">0.05</span></span>, # part of convs for delete on every pruning step <span class="hljs-attr"><span class="hljs-attr">"pruning_standart_deviation_part"</span></span>: <span class="hljs-number"><span class="hljs-number">0.2</span></span> # shift for limit pruning part }</code> </pre> <br><p>  Zus√§tzlich ist eine Einschr√§nkung auf Basis der Standardabweichung implementiert.  Das Ziel ist es, einen Teil der gel√∂schten zu begrenzen, ausgenommen Windungen mit bereits "ausreichenden" L1-Ma√üen: </p><br><p><img src="https://habrastorage.org/webt/bh/_9/nq/bh_9nqasnp91xifixn7ilhco0mw.png"></p><br><p>  Daher k√∂nnen wir nur schwache Windungen aus Verteilungen entfernen, die der rechten √§hnlich sind, und wir k√∂nnen die Entfernung aus Verteilungen wie der linken nicht beeinflussen: </p><br><p><img src="https://habrastorage.org/webt/pr/r5/zp/prr5zpjrdvh1wow6slejnn6axya.png"></p><br><p>  Wenn sich die Verteilung normalisiert, kann der Koeffizient pruning_standart_deviation_part ausgew√§hlt werden aus: </p><br><p><img src="https://habrastorage.org/webt/dl/yl/7d/dlyl7dub216jsr67dcbnhez5fl8.png"><br>  Ich empfehle eine 2-Sigma-Annahme.  Oder Sie k√∂nnen sich nicht auf diese Funktion konzentrieren und den Wert &lt;1,0 belassen. </p><br><p>  Die Ausgabe ist ein Diagramm der Netzwerkgr√∂√üe, des Netzwerkverlusts und der Netzwerklaufzeit f√ºr den gesamten Test, normalisiert auf 1,0.  Zum Beispiel wurde hier die Netzwerkgr√∂√üe ohne Qualit√§tsverlust um fast das 2-fache reduziert (ein kleines Faltungsnetzwerk f√ºr 100k-Gewichte): </p><br><p><img src="https://habrastorage.org/webt/ig/hu/x_/ighux_gyoaptm71iu2hk_txga_g.png"></p><br><p>  Die Laufgeschwindigkeit unterliegt normalen Schwankungen und hat sich nicht wesentlich ge√§ndert.  Daf√ºr gibt es eine Erkl√§rung: </p><br><ol><li>  Die Anzahl der Windungen √§ndert sich von bequem (32, 64, 128) zu nicht bequem f√ºr Grafikkarten - 27, 51 usw.  Hier kann ich mich irren, aber h√∂chstwahrscheinlich wirkt es sich aus. </li><li>  Die Architektur ist nicht breit, aber konsistent.  Wenn wir die Breite reduzieren, ber√ºhren wir die Tiefe nicht.  So reduzieren wir die Last, √§ndern aber nicht die Geschwindigkeit. </li></ol><br><p>  Daher √§u√üerte sich die Verbesserung in einer Verringerung der CUDA-Belastung w√§hrend des Laufs um 20 bis 30%, jedoch nicht in einer Verringerung der Laufzeit </p><br><h3 id="itogi">  Zusammenfassung </h3><br><p>  Nachdenken.  Wir haben zwei Optionen f√ºr das Bereinigen in Betracht gezogen - f√ºr YOLOv3 (wenn Sie mit Ihren H√§nden arbeiten m√ºssen) und f√ºr Netzwerke mit einfacheren Architekturen.  Es ist zu erkennen, dass in beiden F√§llen eine Reduzierung der Netzwerkgr√∂√üe und -beschleunigung ohne Genauigkeitsverlust erreicht werden kann.  Ergebnisse: </p><br><ul><li>  Downsizing </li><li>  Beschleunigung ausf√ºhren </li><li>  CUDA-Lastreduzierung </li><li>  Infolgedessen Umweltfreundlichkeit (Wir optimieren den zuk√ºnftigen Einsatz von Computerressourcen. Irgendwo freut sich <a href="https://meduza.io/feature/2019/12/12/kto-takaya-greta-tunberg-i-pochemu-ona-stala-chelovekom-goda-zhurnal-time" rel="nofollow">Greta Tunberg</a> alleine) </li></ul><br><h3 id="appendix">  Anhang </h3><br><ul><li>  Nach dem Bereinigungsschritt k√∂nnen Sie die Quantisierung auch verdrehen (z. B. mit TensorRT). </li><li>  Tensorflow bietet Funktionen f√ºr <a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras" rel="nofollow">Low_Magnitude_Pruning</a> .  Es funktioniert </li><li>  Ich m√∂chte das <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">Repository weiterentwickeln</a> und stehe Ihnen gerne zur Verf√ºgung </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de482050/">https://habr.com/ru/post/de482050/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de482034/index.html">Yandex: Es gibt alles ... √ºber Benutzer</a></li>
<li><a href="../de482038/index.html">Wir fassen die Ergebnisse von 2019 bei Haber Career zusammen</a></li>
<li><a href="../de482040/index.html">Enth√§lt Profiling-Programme in C ++</a></li>
<li><a href="../de482042/index.html">Arbeiten mit der Newtonsoft.Json-Bibliothek anhand eines realen Beispiels. Teil 2</a></li>
<li><a href="../de482044/index.html">10 Best Practices zum Sichern von Docker-Images. Teil 2</a></li>
<li><a href="../de482052/index.html">Neujahrs-Datensatz 2019: offenes Tonw√∂rterbuch der russischen Sprache</a></li>
<li><a href="../de482054/index.html">3. Elastic Stack: Sicherheitsprotokollanalyse. Dashboards</a></li>
<li><a href="../de482058/index.html">Raubtier oder Beute? Wer sch√ºtzt die Zertifizierungsstellen?</a></li>
<li><a href="../de482060/index.html">Access Control Mandate Model (MAC): √úbersicht und Anwendungsapplikationen</a></li>
<li><a href="../de482064/index.html">Einfache Entwicklung mehrsprachiger Websites auf CMS Umbraco 8</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõï üßíüèº üë©üèø‚Äçü§ù‚Äçüë®üèæ Propre v√©lo pour synchroniser MariaDB et Sphinx üëæ üßîüèª ü§õüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le 28 f√©vrier, j'ai fait une pr√©sentation lors de la rencontre SphinxSearch , qui s'est tenue dans nos bureaux. Il a expliqu√© comment nous venions de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Propre v√©lo pour synchroniser MariaDB et Sphinx</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/superjob/blog/447526/"><p><img src="https://habrastorage.org/webt/t0/1g/vk/t01gvkcn0zx47xuioqcvfz5bqoc.png"></p><br><p>  Le 28 f√©vrier, j'ai fait une pr√©sentation lors de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rencontre SphinxSearch</a> , qui s'est tenue dans nos bureaux.  Il a expliqu√© comment nous venions de la reconstruction r√©guli√®re des index pour la recherche en texte int√©gral et l'envoi de mises √† jour dans le code ¬´en place¬ª aux index horaires ferroviaires et la synchronisation automatique de l'√©tat de l'index et de la base de donn√©es MariaDB.  Un enregistrement vid√©o de mon reportage est disponible via le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> , et pour ceux qui pr√©f√®rent lire plut√¥t que regarder la vid√©o, j'ai √©crit cet article. </p><a name="habracut"></a><br><p>  Je vais commencer par la fa√ßon dont notre recherche a √©t√© organis√©e et pourquoi nous avons commenc√© tout cela. </p><br><p>  Notre recherche a √©t√© organis√©e selon un sch√©ma tout √† fait standard. </p><br><p>  Depuis le front-end, les demandes des utilisateurs arrivent sur le serveur d'applications √©crites en PHP, et lui, √† son tour, communique avec la base de donn√©es (nous avons MariaDB).  Si nous devons effectuer une recherche, le serveur d'applications se tourne vers l'√©quilibreur (nous avons un haproxy), qui le connecte √† l'un des serveurs sur lesquels searchd s'ex√©cute, et ce serveur effectue d√©j√† une recherche et renvoie le r√©sultat. </p><br><p>  Les donn√©es de la base de donn√©es entrent dans l'index d'une mani√®re assez traditionnelle: selon le calendrier, nous reconstruisons l'index toutes les quelques minutes avec les documents qui ont √©t√© mis √† jour relativement r√©cemment, et reconstruisons l'index avec les documents dits ¬´archiv√©s¬ª (c'est-√†-dire ceux avec lesquels Pendant longtemps, rien ne s'est pass√©).  Il y a quelques machines allou√©es pour l'indexation, un script y est ex√©cut√© selon un calendrier, qui construit d'abord l'index, puis renomme les fichiers d'index d'une mani√®re sp√©ciale, puis le place dans un dossier s√©par√©.  Et sur chacun des serveurs avec searchd, rsync est d√©marr√© une fois par minute, qui √† partir de ce dossier copie les fichiers dans le dossier index searchd, puis, si quelque chose a √©t√© copi√©, il ex√©cute la requ√™te RELOAD INDEX. </p><br><p>  Cependant, pour certains changements dans les curriculum vitae et les postes vacants, il √©tait n√©cessaire qu'ils ¬´atteignent¬ª l'indice le plus t√¥t possible.  Par exemple, si un poste vacant qui a √©t√© publi√© dans le domaine public est supprim√© de la publication, il est raisonnable de s'attendre du point de vue de l'utilisateur qu'il dispara√Ætra du probl√®me en quelques secondes, pas plus.  Par cons√©quent, ces types de modifications sont envoy√©s directement via searchd √† l'aide de requ√™tes UPDATE.  Et pour que ces modifications soient appliqu√©es √† toutes les copies d'index sur tous nos serveurs, un index distribu√© est configur√© sur chaque searchd, qui envoie des mises √† jour d'attributs √† toutes les instances de searchd.  Le serveur d'applications se connecte toujours √† l'√©quilibreur et envoie une demande de mise √† jour de l'index distribu√©;  ainsi, il n'a pas besoin de conna√Ætre √† l'avance ni la liste des serveurs avec searchd, ni de savoir exactement √† quel serveur avec searchd. </p><br><p>  Tout cela a plut√¥t bien fonctionn√©, mais il y a eu des probl√®mes. </p><br><ol><li>  Le d√©lai moyen entre la cr√©ation du document (nous avons ce curriculum vitae ou vacance) et son entr√©e dans l'index √©tait directement proportionnel √† leur nombre dans notre base de donn√©es. </li><li> Puisque nous avons utilis√© l'index distribu√© pour distribuer les mises √† jour d'attributs, nous n'avions aucune garantie que ces mises √† jour √©taient appliqu√©es √† toutes les copies de l'index. </li><li> Les modifications ¬´urgentes¬ª qui se sont produites lors de la reconstruction de l'index ont √©t√© perdues lorsque la commande <code>RELOAD INDEX</code> √©t√© ex√©cut√©e (simplement parce qu'elles n'√©taient pas encore dans l'index nouvellement construit) et ne sont entr√©es dans l'index qu'apr√®s la prochaine r√©indexation. <img src="https://habrastorage.org/webt/rz/t6/v3/rzt6v3lfrnyayc3-texs56vlh48.png"></li><li>  Les scripts de mise √† jour des index sur les serveurs avec searchd ont √©t√© ex√©cut√©s ind√©pendamment les uns des autres, il n'y avait pas de synchronisation entre eux.  De ce fait, le d√©lai entre la mise √† jour de l'index sur diff√©rents serveurs peut atteindre plusieurs minutes. </li><li>  S'il √©tait n√©cessaire de tester quelque chose li√© √† la recherche, il √©tait n√©cessaire de reconstruire l'index apr√®s chaque modification. </li></ol><br><p>  Chacun de ces probl√®mes s√©par√©ment ne valait pas une retouche cardinale de l'infrastructure de recherche, mais pris ensemble, ils ont g√¢ch√© la vie de mani√®re assez tangible. </p><br><p>  Nous avons d√©cid√© de traiter les probl√®mes ci-dessus en utilisant des index en temps r√©el Sphinx.  De plus, le passage aux indices RT ne nous a pas suffi.  Afin de se d√©barrasser enfin de toute course aux donn√©es, il fallait s'assurer que toutes les mises √† jour de l'application vers l'index passaient par le m√™me canal.  De plus, il √©tait n√©cessaire de sauvegarder quelque part les modifications apport√©es √† la base de donn√©es pendant la reconstruction de l'index (car apr√®s tout, il est parfois n√©cessaire de le reconstruire, mais la proc√©dure n'est pas instantan√©e). </p><br><p>  Nous avons d√©cid√© d'√©tablir la connexion en utilisant le protocole de r√©plication MySQL comme un canal de transfert de donn√©es, et le binlog MySQL est l'endroit id√©al pour enregistrer les modifications lors de la reconstruction de l'index.  Cette solution nous a permis de nous d√©barrasser de l'√©criture sur Sphinx √† partir du code d'application.  Et puisque nous avions d√©j√† utilis√© la r√©plication bas√©e sur les lignes avec un identifiant de transaction global √† ce moment-l√†, le basculement entre les r√©pliques de base de donn√©es pouvait se faire tout simplement. </p><br><p>  L'id√©e de se connecter directement √† la base de donn√©es afin d'en obtenir des modifications pour les envoyer √† l'index n'est bien s√ªr pas nouvelle: en 2016, des coll√®gues d'Avito ont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fait une pr√©sentation</a> o√π ils ont d√©crit en d√©tail comment ils ont r√©solu le probl√®me de la synchronisation des donn√©es dans Sphinx avec la base de donn√©es principale.  Nous avons d√©cid√© d'utiliser leur exp√©rience et de cr√©er un syst√®me similaire pour nous-m√™mes, √† la diff√©rence que nous n'avons pas PostgreSQL, mais MariaDB et l'ancienne branche Sphinx (√† savoir, la version 2.3.2). </p><br><p>  Nous avons fait un service qui s'abonne aux changements dans MariaDB et met √† jour l'index dans Sphinx.  Ses responsabilit√©s sont les suivantes: </p><br><ul><li>  connexion au serveur MariaDB via le protocole de r√©plication et r√©ception d'√©v√©nements du binlog; </li><li>  suivre la position actuelle du journal des transactions et le num√©ro de la derni√®re transaction termin√©e; </li><li>  filtrage des √©v√©nements binlog; </li><li>  trouver quels documents doivent √™tre ajout√©s, supprim√©s ou mis √† jour dans l'index, et pour les documents mis √† jour - quels champs doivent √™tre mis √† jour; </li><li>  demande de donn√©es manquantes √† MariaDB; </li><li>  g√©n√©ration et ex√©cution de demandes de mise √† jour d'index; </li><li>  reconstruire l'index si n√©cessaire. </li></ul><br><p>  Nous avons √©tabli une connexion en utilisant le protocole de r√©plication en utilisant la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">go-mysql</a> .  Elle est charg√©e d'√©tablir une connexion avec MariaDB, de lire les √©v√©nements de r√©plication et de les transmettre √† un gestionnaire.  Ce gestionnaire d√©marre dans goroutine, qui est contr√¥l√© par la biblioth√®que, mais nous √©crivons nous-m√™mes le code du gestionnaire.  Dans le code du gestionnaire, les √©v√©nements sont v√©rifi√©s avec une liste de tables qui nous int√©ressent et les modifications apport√©es √† ces tables sont envoy√©es pour traitement.  Notre gestionnaire stocke √©galement l'√©tat des transactions.  En effet, les √©v√©nements du protocole de r√©plication sont en ordre: GTID (d√©but de transaction) -&gt; ROW (changement de donn√©es) -&gt; XID (fin de transaction), et seul le premier d'entre eux contient des informations sur le num√©ro de transaction.  Il est plus pratique pour nous de transf√©rer le num√©ro de transaction avec son ach√®vement afin d'enregistrer des informations sur la position dans le binlog o√π les modifications ont √©t√© appliqu√©es, et pour cela, nous devons nous souvenir du num√©ro de la transaction en cours entre son d√©but et son ach√®vement. </p><br><pre> <code class="plaintext hljs">MySQL [(none)]&gt; describe sync_state; +-----------------+--------+ | Field | Type | +-----------------+--------+ | id | bigint | | dummy_field | field | | binlog_position | uint | | binlog_name | string | | gtid | string | | flavor | string | +-----------------+--------+</code> </pre> <br><p>  Nous enregistrons le num√©ro de la derni√®re transaction termin√©e dans un index sp√©cial √† partir d'un document sur chaque serveur avec searchd.  Au d√©but du service, nous v√©rifions que les index sont initialis√©s et ont la structure attendue, ainsi que la position enregistr√©e sur tous les serveurs est pr√©sente et la m√™me sur tous les serveurs.  Ensuite, si ces v√©rifications ont r√©ussi et que nous avons pu commencer √† lire le binlog √† partir de la position enregistr√©e, nous commen√ßons la proc√©dure de synchronisation.  Si les v√©rifications √©chouent, ou s'il n'a pas √©t√© possible de commencer la lecture du binlog √† partir de la position enregistr√©e, nous r√©initialisons la position enregistr√©e √† la position actuelle du serveur MariaDB et reconstruisons l'index. </p><br><p>  Le traitement des √©v√©nements de r√©plication commence par d√©terminer quels documents sont affect√©s par un changement particulier dans la base de donn√©es.  Pour ce faire, dans la configuration de notre service, nous avons fait quelque chose comme le routage des √©v√©nements de changement de ligne dans les tables qui nous int√©ressent, c'est-√†-dire un ensemble de r√®gles pour d√©terminer comment les changements dans la base de donn√©es doivent √™tre index√©s. </p><br><pre> <code class="plaintext hljs">[[ingest]] table = "vacancy" id_field = "id" index = "vacancy" [ingest.column_map] user_id = ["user_id"] edited_at = ["date_edited"] profession = ["profession"] latitude = ["latitude_deg", "latitude_rad"] longitude = ["longitude_deg", "longitude_rad"] [[ingest]] table = "vacancy_language" id_field = "vacancy_id" index = "vacancy" [ingest.column_map] language_id = ["languages"] level = ["languages"] [[ingest]] table = "vacancy_metro_station" id_field = "vacancy_id" index = "vacancy" [ingest.column_map] metro_station_id = ["metro"]</code> </pre> <br><p>  Par exemple, avec cet ensemble de r√®gles, les modifications apport√©es aux <code>vacancy_metro_station</code> <code>vacancy</code> , <code>vacancy_language</code> et <code>vacancy_metro_station</code> doivent figurer dans l'index de <code>vacancy</code> .  Le num√©ro de document peut √™tre pris dans le champ <code>id</code> pour la table des <code>vacancy</code> et dans le champ <code>vacancy_id</code> pour les deux autres tables.  Le champ <code>column_map</code> est une table de la d√©pendance des champs d'index sur les champs de diff√©rentes tables de base de donn√©es. </p><br><p>  De plus, lorsque nous avons re√ßu la liste des documents concern√©s par les modifications, nous devons les mettre √† jour dans l'index, mais pas imm√©diatement.  Tout d'abord, nous accumulons les modifications pour chaque document et envoyons les modifications √† l'index d√®s qu'un court laps de temps (nous avons 100 millisecondes) √† partir de la derni√®re modification de ce document. </p><br><p>  Nous avons d√©cid√© de le faire afin d'√©viter de nombreuses mises √† jour d'index inutiles, car dans de nombreux cas, une seule modification logique d'un document se produit √† l'aide de plusieurs requ√™tes SQL qui affectent diff√©rentes tables et sont parfois ex√©cut√©es dans des transactions compl√®tement diff√©rentes. </p><br><p>  Je vais donner un exemple simple.  Supposons qu'un utilisateur ait modifi√© un poste vacant.  Le code responsable de l'enregistrement des modifications est souvent √©crit pour plus de simplicit√© de cette fa√ßon: </p><br><pre> <code class="plaintext hljs">BEGIN; UPDATE vacancy SET edited_at = NOW() WHERE id = 123; DELETE FROM vacancy_language WHERE vacancy_id = 123; INSERT INTO vacancy_language (vacancy_id, language_id, level) VALUES (123, 1, "fluent"), (123, 2, "technical"); DELETE FROM vacancy_metro_station WHERE vacancy_id = 123; INSERT INTO vacancy_metro_station (vacancy_id, metro_station_id) VALUES (123, 55); ... COMMIT;</code> </pre> <br><p>  En d'autres termes, tous les anciens enregistrements sont d'abord supprim√©s des tables li√©es, puis de nouveaux sont ins√©r√©s.  Dans le m√™me temps, il y aura toujours des entr√©es dans le binlog au sujet de ces suppressions et insertions, m√™me si rien n'a chang√© dans le document. </p><br><p>  Afin de ne mettre √† jour que ce qui est n√©cessaire, nous avons fait ce qui suit: trier les lignes modifi√©es afin que pour chaque paire index-document, toutes les modifications puissent √™tre r√©cup√©r√©es dans l'ordre chronologique.  Ensuite, nous pouvons les appliquer √† leur tour pour d√©terminer quels champs dans lesquels les tables ont finalement chang√© et lesquels ne le sont pas, apr√®s quoi nous pouvons utiliser la table <code>column_map</code> obtenir une liste des champs et des attributs d'index qui doivent √™tre mis √† jour pour chaque document affect√©.  De plus, les √©v√©nements li√©s √† un document peuvent ne pas arriver l'un apr√®s l'autre, mais comme ¬´diff√©remment¬ª s'ils sont ex√©cut√©s dans des transactions diff√©rentes.  Mais, sur notre capacit√© √† d√©terminer quels documents ont chang√©, cela n'affectera pas. </p><br><p>  Dans le m√™me temps, cette approche nous a permis de mettre √† jour uniquement les attributs de l'index, s'il n'y avait pas de modifications dans les champs de texte, ainsi que de combiner l'envoi de modifications √† Sphinx. </p><br><p>  Ainsi, nous pouvons maintenant d√©couvrir quels documents doivent √™tre mis √† jour dans l'index. </p><br><p>  Dans de nombreux cas, les donn√©es du binlog ne sont pas suffisantes pour g√©n√©rer une demande de mise √† jour de l'index, nous obtenons donc les donn√©es manquantes du m√™me serveur d'o√π nous lisons le binlog.  Pour cela, il existe un mod√®le de demande de r√©ception de donn√©es dans la configuration de notre service. </p><br><pre> <code class="plaintext hljs">[data_source.vacancy] #               #   -      id     parts = 4 query = """ SELECT vacancy.id AS `:id`, vacancy.profession AS `profession_text:field`, GROUP_CONCAT(DISTINCT vacancy_language.language_id) AS `languages:attr_multi`, GROUP_CONCAT(DISTINCT vacancy_metro_station.metro_station_id) AS `metro:attr_multi` FROM vacancy LEFT JOIN vacancy_language ON vacancy_language.vacancy_id = vacancy.id LEFT JOIN vacancy_metro_station ON vacancy_metro_station.vacancy_id = vacancy.id GROUP BY vacancy.id """</code> </pre> <br><p>  Dans ce mod√®le, tous les champs sont marqu√©s avec des alias sp√©ciaux: <code>[___]:___</code> . <br>  Il est utilis√© √† la fois dans la formation d'une demande de r√©ception des donn√©es manquantes et dans la construction de l'index (plus de d√©tails plus loin). </p><br><p>  Nous formons une demande de ce type: </p><br><pre> <code class="plaintext hljs">SELECT vacancy.id AS `id`, vacancy.profession AS `profession_text`, GROUP_CONCAT(DISTINCT vacancy_language.language_id) AS `languages`, GROUP_CONCAT(DISTINCT vacancy_metro_station.metro_station_id) AS `metro` FROM vacancy LEFT JOIN vacancy_language ON vacancy_language.vacancy_id = vacancy.id LEFT JOIN vacancy_metro_station ON vacancy_metro_station.vacancy_id = vacancy.id WHERE vacancy.id IN (&lt; id ,   &gt;) GROUP BY vacancy.id</code> </pre> <br><p>  Ensuite, pour chaque document, nous v√©rifions si c'est √† la suite de cette demande.  Sinon, cela signifie qu'il a √©t√© supprim√© de la table principale et qu'il peut donc √©galement √™tre supprim√© de l'index (nous ex√©cutons la requ√™te <code>DELETE</code> pour ce document).  Si c'est le cas, voyez si nous devons mettre √† jour les champs de texte pour ce document.  Si les champs de texte n'ont pas besoin d'√™tre mis √† jour, nous effectuons une requ√™te <code>UPDATE</code> pour ce document, sinon <code>REPLACE</code> . </p><br><p>  Il convient de noter ici que la logique de maintien de la position √† partir de laquelle vous pouvez commencer √† lire le binlog en cas de d√©faillance devait √™tre compliqu√©e, car maintenant une situation est possible lorsque nous n'appliquons pas toutes les modifications lues dans le binlog. </p><br><p>  Pour que la reprise de la lecture du binlog fonctionne correctement, nous avons fait ce qui suit: pour chaque √©v√©nement de changement de ligne dans la base de donn√©es, souvenez-vous de l'id de la derni√®re transaction termin√©e au moment o√π cet √©v√©nement s'est produit.  Apr√®s avoir envoy√© les modifications √† Sphinx, nous mettons √† jour le num√©ro de transaction √† partir duquel vous pouvez commencer √† lire en toute s√©curit√©, comme suit.  Si nous n'avons pas trait√© toutes les modifications accumul√©es (car certains documents n'ont pas √©t√© ¬´suivis¬ª dans la file d'attente), nous prenons le num√©ro de la transaction la plus ancienne parmi ceux li√©s aux modifications que nous n'avons pas encore r√©ussi √† appliquer.  Et s'il arrivait que nous appliquions toutes les modifications accumul√©es, nous prenons simplement le num√©ro de la derni√®re transaction termin√©e. </p><br><p>  Ce qui s'est pass√© en cons√©quence nous convenait, mais il y avait un autre point assez important: pour que les performances de l'index en temps r√©el restent √† un niveau acceptable dans le temps, il √©tait n√©cessaire que la taille et le nombre de ¬´morceaux¬ª de cet index restent faibles.  Pour ce faire, Sphinx a une demande <code>FLUSH RAMCHUNK</code> , qui cr√©e un nouveau bloc de disque, et une demande <code>OPTIMIZE INDEX</code> , qui fusionne tous les blocs de disque en un seul.  Au d√©part, nous pensions que nous le ferions p√©riodiquement et c'est tout.  Mais, malheureusement, il s'est av√©r√© que dans la version 2.3.2 <code>OPTIMIZE INDEX</code> ne fonctionne pas (√† savoir, avec une probabilit√© assez √©lev√©e conduit √† une baisse de la recherche).  Par cons√©quent, nous avons d√©cid√© une seule fois par jour de reconstruire compl√®tement l'index, d'autant plus que de temps en temps nous devons encore le faire (par exemple, si le sch√©ma d'index ou les param√®tres du tokenizer changent). </p><br><p>  La proc√©dure de reconstruction de l'index se d√©roule en plusieurs √©tapes. </p><br><ol><li><p>  Nous g√©n√©rons une configuration pour l'indexeur </p><br><p>  Comme mentionn√© ci-dessus, il existe un mod√®le de requ√™te SQL dans la configuration du service.  Il est √©galement utilis√© pour former la configuration de l'indexeur. <br>  Dans la configuration, il existe √©galement d'autres param√®tres n√©cessaires √† la construction de l'index (param√®tres du tokenizer, dictionnaires, diverses restrictions sur la consommation des ressources). </p><br></li><li><p>  Enregistrer la position actuelle de MariaDB </p><br><p>  √Ä partir de cette position, nous commencerons la lecture du binlog, une fois que le nouvel index sera disponible sur tous les serveurs avec searchd. </p><br></li><li><p>  Nous commen√ßons l'indexeur </p><br><p>  <code>indexer --config tmp.vacancy.indexer.0.conf --all</code> commandes du formulaire <code>indexer --config tmp.vacancy.indexer.0.conf --all</code> et attendons <code>indexer --config tmp.vacancy.indexer.0.conf --all</code> termin√©es.  De plus, si l'indice est divis√© en parties, alors nous commen√ßons la construction de toutes les parties en parall√®le. </p><br></li><li><p>  Nous chargeons les fichiers d'index sur les serveurs </p><br><p>  Le t√©l√©chargement sur chaque serveur se produit √©galement en parall√®le, mais nous attendons naturellement que tous les fichiers soient t√©l√©charg√©s sur tous les serveurs.  Pour t√©l√©charger des fichiers dans la configuration du service, il y a une section avec un mod√®le de commande pour t√©l√©charger des fichiers. </p><br><pre> <code class="plaintext hljs">[index_uploader] executable = "rsync" arguments = [ "--files-from=-", "--log-file=&lt;&lt;.DataDir&gt;&gt;/rsync.&lt;&lt;.Host&gt;&gt;.log", "--no-relative", "--times", "--delay-updates", ".", "rsync://&lt;&lt;.Host&gt;&gt;/index/vacancy/", ]</code> </pre> <br><p>  Pour chaque serveur, nous substituons simplement son nom dans la variable Host et ex√©cutons la commande r√©sultante.  Nous utilisons rsync pour le t√©l√©chargement, mais en principe tout programme ou script qui accepte une liste de fichiers dans stdin et t√©l√©charge ces fichiers dans le dossier o√π searchd s'attend √† voir les fichiers d'index fera l'affaire. </p><br></li><li><p>  Nous arr√™tons la synchronisation </p><br><p>  On arr√™te de lire le binlog, on arr√™te le goroutine responsable de l'accumulation des changements. </p><br></li><li><p>  Remplacez l'ancien index par un nouveau </p><br><p>  Pour chaque serveur avec searchd, nous effectuons des requ√™tes s√©quentielles <code>RELOAD INDEX vacancy_plain</code> , <code>TRUNCATE INDEX vacancy_plain</code> , <code>ATTACH INDEX vacancy_plain TO vacancy</code> .  Si l'index est divis√© en parties, nous ex√©cutons ces requ√™tes de mani√®re s√©quentielle pour chaque partie.  En m√™me temps, si nous sommes dans un environnement de production, puis avant d'ex√©cuter ces requ√™tes sur n'importe quel serveur, nous en supprimons la charge via l'√©quilibreur (afin que personne ne fasse de requ√™tes SELECT vers les index entre <code>TRUNCATE</code> et <code>ATTACH</code> ), et d√®s que la derni√®re requ√™te <code>ATTACH</code> est termin√©e, nous renvoyons la charge √† ce serveur. </p><br></li><li><p>  Reprise de la synchronisation √† partir d'une position enregistr√©e </p><br><p>  D√®s que nous rempla√ßons tous les index en temps r√©el par des index nouvellement construits, nous reprenons la lecture du binlog et synchronisons les √©v√©nements du binlog, √† partir de la position que nous avons enregistr√©e avant le d√©but de l'indexation. </p><br></li></ol><br><p>  Voici un exemple de graphique du d√©calage de l'index du serveur MariaDB. </p><br><p><img src="https://habrastorage.org/webt/xs/pq/56/xspq56osyygn1fxx6h5x_oczgpy.png" alt="Arri√©r√© apr√®s r√©indexation"></p><br><p>  Ici, vous pouvez voir que bien que l'√©tat de l'index apr√®s la reconstruction revienne dans le temps, cela se produit tr√®s bri√®vement. </p><br><p>  Maintenant que tout est plus ou moins pr√™t, il est temps de sortir.  Nous l'avons fait progressivement.  Tout d'abord, nous avons vers√© un index en temps r√©el sur quelques serveurs, et le reste √† l'√©poque fonctionnait de la m√™me mani√®re.  Dans le m√™me temps, la structure des index sur les ¬´nouveaux¬ª serveurs ne diff√®re pas des anciens, donc notre application PHP peut toujours se connecter √† l'√©quilibreur sans se soucier de savoir si la requ√™te sera trait√©e sur un index en temps r√©el ou sur un index simple. </p><br><p><img src="https://habrastorage.org/webt/sy/xz/lx/syxzlx_tfmg0-mze5vr1ngt3_tg.png" alt="Sch√©ma de distribution des mises √† jour de transition"></p><br><p>  Les mises √† jour d'attributs, dont j'ai parl√© plus t√¥t, ont √©galement √©t√© envoy√©es selon l'ancien sch√©ma, √† la diff√©rence que l'index distribu√© sur tous les serveurs a √©t√© configur√© pour envoyer des requ√™tes UPDATE uniquement aux serveurs avec des index simples.  De plus, si la demande UPDATE de l'application atteint le serveur avec des index en temps r√©el, elle ne remplit pas cette demande √† la maison, mais l'envoie aux serveurs configur√©s √† l'ancienne. </p><br><p>  Apr√®s la publication, comme nous l'esp√©rions, il s'est av√©r√© r√©duire consid√©rablement le d√©lai entre la fa√ßon dont un curriculum vitae ou un poste vacant change dans la base de donn√©es et la fa√ßon dont les changements correspondants entrent dans l'index. </p><br><p>  Apr√®s le passage √† un index en temps r√©el, il n'√©tait pas n√©cessaire de reconstruire l'index apr√®s chaque modification sur les serveurs de test.  Ainsi, il est devenu possible d'√©crire des autotests de bout en bout avec la participation de la recherche √† peu de frais.  Cependant, comme nous traitons les modifications du binlog de mani√®re asynchrone (du point de vue des clients qui √©crivent dans la base de donn√©es), nous avons d√ª permettre d'attendre que les modifications concernant le document participant √† l'autotest soient trait√©es par notre service et envoy√©es √† searchd . </p><br><p>  Pour ce faire, nous avons cr√©√© un point de terminaison dans notre service, qui ne fait que cela, c'est-√†-dire qu'il attend que toutes les modifications soient appliqu√©es au num√©ro de transaction sp√©cifi√©.  Pour ce faire, imm√©diatement apr√®s avoir apport√© les modifications n√©cessaires √† la base de donn√©es, nous demandons √† MariaDB <code>@@gtid_current_pos</code> et la transf√©rons au point final de notre service.  Si nous avons d√©j√† appliqu√© toutes les transactions √† ce poste √† ce moment, le service r√©pond imm√©diatement que nous pouvons continuer.  Sinon, dans le goroutine responsable de l'application des modifications, nous cr√©ons un abonnement √† ce GTID, et d√®s qu'il (ou celui qui le suit) est appliqu√©, nous permettons √©galement au client de continuer l'autotest. </p><br><p>  En code PHP, cela ressemble √† ceci: </p><br><pre> <code class="plaintext hljs">&lt;?php declare(strict_types=1); use GuzzleHttp\ClientInterface; use GuzzleHttp\RequestOptions; use PDO; class RiverClient { private const REQUEST_METHOD = 'post'; /** * @var ClientInterface */ private $httpClient; public function __construct(ClientInterface $httpClient) { $this-&gt;httpClient = $httpClient; } public function waitForSync(PDO $mysqlConnection, PDO $sphinxConnection, string $riverAddr): void { $masterGTID = $mysqlConnection-&gt;query('SELECT @@gtid_current_pos')-&gt;fetchColumn(); $this-&gt;httpClient-&gt;request( self::REQUEST_METHOD, "http://{$riverAddr}/wait", [RequestOptions::FORM_PARAMS =&gt; ['gtid' =&gt; $masterGTID]] ); } }</code> </pre> <br><h2 id="rezultaty">  R√©sultats </h2><br><p>  En cons√©quence, nous avons pu r√©duire consid√©rablement le d√©lai entre la mise √† jour de MariaDB et de Sphinx. </p><br><p><img src="https://habrastorage.org/webt/lc/rs/rl/lcrsrlzpcw8bzhuptg5s42p6wou.png" alt="D√©calage d'index clair de la base de donn√©es"></p><br><p><img src="https://habrastorage.org/webt/7h/ik/ic/7hikichzuaqyszagbenen-9drhk.png" alt="Retard de l'index Rt de la base de donn√©es"></p><br><p>  Nous sommes √©galement devenus beaucoup plus confiants que toutes les mises √† jour atteignent tous nos serveurs Sphinx √† temps. </p><br><p>  De plus, les tests de recherche (manuels et automatiques) sont devenus beaucoup plus agr√©ables. </p><br><p>  Malheureusement, cela ne nous a pas √©t√© donn√© gratuitement: les performances de l'indice en temps r√©el par rapport √† l'indice ordinaire se sont r√©v√©l√©es l√©g√®rement moins bonnes. </p><br><p>  La r√©partition du temps de traitement des requ√™tes de recherche en fonction du temps pour un index simple est indiqu√©e ci-dessous. </p><br><p><img src="https://habrastorage.org/webt/op/ro/gm/oprogmvvdykt244nlbmzeldufhu.png" alt="Chronologie d'ex√©cution des requ√™tes - plain"></p><br><p>  Et voici le m√™me graphique pour l'index en temps r√©el. </p><br><p><img src="https://habrastorage.org/webt/07/ii/ce/07iicewkxbb0qvsrrob6dbwoa2i.png" alt="Chronologie d'ex√©cution des requ√™tes - en temps r√©el"></p><br><p>  Vous pouvez voir que la part des demandes ¬´rapides¬ª a l√©g√®rement diminu√©, tandis que la part des demandes ¬´lentes¬ª a augment√©. </p><br><h2 id="vmesto-zaklyucheniya">  Au lieu d'une conclusion </h2><br><p>  Reste √† dire que le code du service d√©crit dans cet article, nous l'avons post√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans le domaine public</a> .  Malheureusement, il n'y a pas encore de documentation d√©taill√©e, mais si vous le souhaitez, vous pouvez ex√©cuter un exemple d'utilisation de ce service via <code>docker-compose</code> . </p><br><h2 id="ssylki">  Les r√©f√©rences </h2><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Diapositives vid√©o</a> et rapport </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reportage vid√©o d'Andrey Smirnov et Vyacheslav Kryukov sur Highload ++</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Biblioth√®que Go-mysql</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Code de service avec exemple d'utilisation</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr447526/">https://habr.com/ru/post/fr447526/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr447512/index.html">Et qui a fait √ßa? Automatisez l'audit de la s√©curit√© des informations</a></li>
<li><a href="../fr447514/index.html">7 startups int√©ressantes dans l'IoT</a></li>
<li><a href="../fr447516/index.html">Comment nous avons overclock√© CAD COMPASS-3D ‚Üí Partie 2</a></li>
<li><a href="../fr447520/index.html">Fonctionnalit√©s de hi√©rarchisation automatique dans le stockage Qsan XCubeSAN</a></li>
<li><a href="../fr447522/index.html">Quelles choses utiles peuvent √™tre extraites des journaux d'un poste de travail Windows</a></li>
<li><a href="../fr447528/index.html">Qui est responsable de la qualit√©?</a></li>
<li><a href="../fr447530/index.html">OceanLotus: mise √† jour Malvari pour macOS</a></li>
<li><a href="../fr447532/index.html">Splunk Universal Forwarder dans le Docker en tant que rassembleur de journaux syst√®me</a></li>
<li><a href="../fr447534/index.html">Le cosmonaute Aleksandr Laveykin sur le meilleur film spatial, la force G de 20g et l'atterrissage en douceur</a></li>
<li><a href="../fr447536/index.html">Impl√©mentez IdM. Pr√©paration √† la mise en ≈ìuvre par le client</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
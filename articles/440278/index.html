<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé© ‚úåüèø üôáüèΩ Cambiar Yesca a Kubernetes üë©üèΩ‚Äç‚úàÔ∏è ü§∫ üîö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nota perev. : Los empleados de Tinder recientemente compartieron algunos de los detalles t√©cnicos de la migraci√≥n de su infraestructura a Kubernetes. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cambiar Yesca a Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/440278/">  <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: Los empleados de Tinder recientemente compartieron algunos de los detalles t√©cnicos de la migraci√≥n de su infraestructura a Kubernetes.</i>  <i>El proceso tom√≥ casi dos a√±os y result√≥ en el lanzamiento en K8 de una plataforma a gran escala que consta de 200 servicios alojados en 48 mil contenedores.</i>  <i>¬øQu√© dificultades interesantes enfrentaron los ingenieros de Tinder y qu√© resultados obtuvieron? Lea esta traducci√≥n.</i> <br><br><img src="https://habrastorage.org/webt/uq/og/xd/uqogxdavfghsshnu8hvlszhubpe.png"><a name="habracut"></a><br><br><h2>  Por qu√© </h2><br>  Hace casi dos a√±os, Tinder decidi√≥ cambiar su plataforma a Kubernetes.  Kubernetes permitir√≠a al equipo de Tinder contenerizar y cambiar a operaci√≥n con un m√≠nimo esfuerzo a trav√©s de una <i>implementaci√≥n inmutable</i> .  En este caso, el ensamblaje de aplicaciones, su despliegue y la infraestructura en s√≠ misma ser√≠an determinados √∫nicamente por el c√≥digo. <br><br>  Tambi√©n buscamos una soluci√≥n al problema de escalabilidad y estabilidad.  Cuando el escalado se volvi√≥ cr√≠tico, a menudo tuvimos que esperar varios minutos para lanzar nuevas instancias de EC2.  Por lo tanto, la idea de lanzar contenedores y comenzar a servir el tr√°fico en segundos en lugar de minutos nos result√≥ muy atractiva. <br><br>  El proceso no fue f√°cil.  Durante la migraci√≥n, a principios de 2019, el cl√∫ster de Kubernetes alcanz√≥ una masa cr√≠tica y comenzamos a enfrentar varios problemas debido a la cantidad de tr√°fico, el tama√±o del cl√∫ster y el DNS.  En este viaje, resolvimos muchos problemas interesantes relacionados con la transferencia de 200 servicios y el mantenimiento del cl√∫ster Kubernetes, que consta de 1000 nodos, 15,000 pods y 48,000 contenedores de trabajo. <br><br><h2>  Como? </h2><br>  Desde enero de 2018, hemos pasado por varias etapas de migraci√≥n.  Comenzamos por contener todos nuestros servicios e implementarlos en entornos de prueba de Kubernetes.  En octubre, comenz√≥ el proceso de transferencia met√≥dica de todos los servicios existentes a Kubernetes.  En marzo del a√±o siguiente, se complet√≥ la "reubicaci√≥n" y ahora la plataforma Tinder se ejecuta exclusivamente en Kubernetes. <br><br><h3>  Crear im√°genes para Kubernetes </h3><br>  Tenemos m√°s de 30 repositorios de c√≥digo fuente para microservicios que se ejecutan en un cl√∫ster de Kubernetes.  El c√≥digo en estos repositorios est√° escrito en diferentes idiomas (por ejemplo, Node.js, Java, Scala, Go) con muchos entornos de tiempo de ejecuci√≥n para el mismo idioma. <br><br>  El sistema de compilaci√≥n est√° dise√±ado para proporcionar un "contexto de compilaci√≥n" totalmente personalizable para cada microservicio.  Generalmente consiste en un Dockerfile y una lista de comandos de shell.  Sus contenidos son totalmente personalizables y, al mismo tiempo, todos estos contextos de compilaci√≥n est√°n escritos de acuerdo con un formato estandarizado.  La estandarizaci√≥n de los contextos de compilaci√≥n permite que un √∫nico sistema de compilaci√≥n maneje todos los microservicios. <br><br><img src="https://habrastorage.org/webt/qg/he/8h/qghe8hvhjmsnpwuivvebqk1ne04.png"><br>  <i>Figura 1-1.</i>  <i>Proceso de compilaci√≥n estandarizado a trav√©s del constructor de contenedores (Builder)</i> <br><br>  Para lograr la m√°xima consistencia entre tiempos de ejecuci√≥n, se utiliza el mismo proceso de compilaci√≥n durante el desarrollo y las pruebas.  Nos enfrentamos a un problema muy interesante: tuvimos que desarrollar una forma de garantizar la consistencia del entorno de ensamblaje en toda la plataforma.  Para hacer esto, todos los procesos de ensamblaje se llevan a cabo dentro de un contenedor especial de <i>Builder</i> . <br><br>  Su implementaci√≥n requiri√≥ t√©cnicas avanzadas para trabajar con Docker.  Builder hereda el ID de usuario local y los secretos (como la clave SSH, las credenciales de AWS, etc.) necesarios para acceder a los repositorios privados de Tinder.  Monta directorios locales que contienen la fuente para almacenar naturalmente los artefactos de ensamblaje.  Este enfoque mejora el rendimiento al eliminar la necesidad de copiar artefactos de ensamblaje entre el contenedor del generador y el host.  Los artefactos de ensamblaje almacenados se pueden reutilizar sin configuraci√≥n adicional. <br><br>  Para algunos servicios, tuvimos que crear otro contenedor para hacer coincidir el entorno de compilaci√≥n con el tiempo de ejecuci√≥n (por ejemplo, durante el proceso de instalaci√≥n, la biblioteca bcrypt de Node.js genera artefactos binarios espec√≠ficos de la plataforma).  Durante la compilaci√≥n, los requisitos pueden variar para diferentes servicios, y el Dockerfile final se compila sobre la marcha. <br><br><h3>  Kubernetes Cluster Architecture and Migration </h3><br><h4>  Gesti√≥n de tama√±o de cl√∫ster </h4><br>  Decidimos usar <b>kube-aws</b> para implementar autom√°ticamente el cl√∫ster en instancias de Amazon EC2.  Al principio, todo funcionaba en un grupo com√∫n de nodos.  R√°pidamente nos dimos cuenta de la necesidad de separar las cargas de trabajo por tama√±o y tipo de instancias para un uso m√°s eficiente de los recursos.  La l√≥gica era que el lanzamiento de varias c√°psulas de subprocesos m√∫ltiples cargados result√≥ ser m√°s predecible en rendimiento que su coexistencia con una gran cantidad de unidades de subprocesos simples. <br><br>  Como resultado, nos decidimos por: <br><br><ul><li>  <i>m5.4xlarge</i> - para monitoreo (Prometeo); </li><li>  <i>c5.4xlarge</i> : para la carga de trabajo de Node.js (carga de trabajo de subproceso √∫nico); </li><li>  <i>c5.2xlarge</i> : para Java y Go (carga de trabajo multiproceso); </li><li>  <i>c5.4xlarge</i> : para el panel de control (3 nodos). </li></ul><br><h4>  La migracion </h4><br>  Uno de los pasos preparatorios para migrar de la infraestructura anterior a Kubernetes fue redirigir la interacci√≥n directa existente entre los servicios a los nuevos equilibradores de carga (ELB, Elastic Load Balancers).  Se crearon en una subred espec√≠fica de la nube privada virtual (VPC).  Esta subred se conect√≥ a Kubernetes VPC.  Esto nos permiti√≥ migrar los m√≥dulos gradualmente, sin tener en cuenta el orden espec√≠fico de las dependencias del servicio. <br><br>  Estos puntos finales se crearon utilizando conjuntos ponderados de registros DNS con CNAME que apuntan a cada ELB nuevo.  Para cambiar, agregamos un nuevo registro que apunta a un nuevo ELB de servicio de Kubernetes con un peso de 0. Luego configuramos el Tiempo de vida (TTL) del conjunto de registros en 0. Despu√©s de eso, los pesos viejos y nuevos se ajustaron lentamente, y finalmente se envi√≥ el 100% de la carga. al nuevo servidor.  Despu√©s de completar el cambio, el valor TTL volvi√≥ a un nivel m√°s adecuado. <br><br>  Nuestros m√≥dulos Java existentes manejaban DNS TTL bajo, pero las aplicaciones Node no.  Uno de los ingenieros reescribi√≥ parte del c√≥digo del grupo de conexiones, envolvi√©ndolo en un administrador que actualizaba los grupos cada 60 segundos.  El enfoque elegido funcion√≥ muy bien y sin una disminuci√≥n notable en el rendimiento. <br><br><h2>  Las lecciones </h2><br><h3>  Restricciones de dispositivos de red </h3><br>  En las primeras horas de la ma√±ana del 8 de enero de 2019, la plataforma Tinder se estrell√≥ de repente.  En respuesta a un aumento no relacionado en la latencia de la plataforma m√°s temprano en la ma√±ana, aument√≥ el n√∫mero de pods y nodos en el cl√∫ster.  Esto llev√≥ al agotamiento de la cach√© ARP en todos nuestros nodos. <br><br>  Hay tres opciones de Linux asociadas con el cach√© ARP: <br><br><img src="https://habrastorage.org/webt/fq/bp/av/fqbpavle6xhk1ryeup0nd-lrqm0.png"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fuente</a> ) <br><br>  <b>gc_thresh3</b> es un l√≠mite dif√≠cil.  La aparici√≥n en el registro de entradas del formulario "desbordamiento de tabla vecina" significaba que incluso despu√©s de la recolecci√≥n de basura sincr√≥nica (GC) en el cach√© ARP, no hab√≠a suficiente espacio para almacenar el registro vecino.  En este caso, el n√∫cleo simplemente descart√≥ completamente el paquete. <br><br>  Usamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Flannel</a> como <i>tejido de red</i> en Kubernetes.  Los paquetes se transmiten a trav√©s de VXLAN.  VXLAN es un t√∫nel L2, elevado sobre una red L3.  La tecnolog√≠a utiliza la encapsulaci√≥n MAC-in-UDP (Protocolo de datagramas de direcci√≥n MAC en usuario) y le permite expandir los segmentos de red del segundo nivel.  El protocolo de transporte en la red f√≠sica del centro de datos es IP m√°s UDP. <br><br> <a href=""><img src="https://habrastorage.org/webt/ad/vn/pl/advnplfowrh7mi-6otctfhzm2xs.png"></a> <br>  <i>Figura 2‚Äì1.</i>  <i>Gr√°fico de franela ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fuente</a> )</i> <br><br><img src="https://habrastorage.org/webt/nz/ti/xz/nztixz_5aer3xofz2drri5uafb8.jpeg"><br>  <i>Figura 2‚Äì2.</i>  <i>Paquete VXLAN ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fuente</a> )</i> <br><br>  Cada nodo de trabajo de Kubernetes asigna un espacio de direcci√≥n virtual con m√°scara / 24 del bloque m√°s grande / 9.  Para cada nodo, esto <a href="">significa</a> una entrada en la tabla de enrutamiento, una entrada en la tabla ARP (en la interfaz de <i>franela.1</i> ) y una entrada en la tabla de conmutaci√≥n (FDB).  Se agregan cuando el nodo de trabajo se inicia por primera vez o cuando se detecta cada nuevo nodo. <br><br>  Adem√°s, la conexi√≥n nodo-pod (o pod-pod) finalmente pasa por la interfaz <b>eth0</b> (como se muestra en el diagrama de franela anterior).  Esto da como resultado una entrada adicional en la tabla ARP para cada fuente y destino correspondiente del nodo. <br><br>  En nuestro entorno, este tipo de comunicaci√≥n es muy com√∫n.  Para los objetos de tipo de servicio en Kubernetes, se crea un ELB y Kubernetes registra cada nodo en el ELB.  ELB no sabe nada sobre los pods y el nodo seleccionado puede no ser el destino final del paquete.  El hecho es que cuando un nodo recibe un paquete de ELB, lo considera teniendo en cuenta las reglas de <b>iptables</b> para un servicio en particular y selecciona aleatoriamente el pod en otro nodo. <br><br>  En el momento de la falla, el cl√∫ster ten√≠a 605 nodos.  Por las razones indicadas anteriormente, esto fue suficiente para superar el <b>valor predeterminado de gc_thresh3</b> .  Cuando esto sucede, no solo los paquetes comienzan a descartarse, sino que todo el espacio de direcci√≥n virtual de Franela con la m√°scara / 24 desaparece de la tabla ARP.  Las comunicaciones del nodo de nodo y las consultas DNS se interrumpen (DNS est√° alojado en un cl√∫ster; consulte el resto de este art√≠culo para obtener m√°s detalles). <br><br>  Para resolver este problema, aumente los valores de <b>gc_thresh1</b> , <b>gc_thresh2</b> y <b>gc_thresh3</b> y reinicie Flannel para volver a registrar las redes que faltan. <br><br><h4>  Escalado de DNS inesperado </h4><br>  Durante el proceso de migraci√≥n, utilizamos activamente DNS para administrar el tr√°fico y transferir gradualmente los servicios de la infraestructura anterior a Kubernetes.  Establecimos valores TTL relativamente bajos para RecordSets relacionados en Route53.  Cuando la infraestructura anterior se estaba ejecutando en instancias EC2, nuestra configuraci√≥n de resoluci√≥n apuntaba a DNS de Amazon.  Lo dimos por sentado y el impacto del bajo TTL en nuestros servicios de Amazon (como DynamoDB) pas√≥ casi desapercibido. <br><br>  A medida que los servicios se migraron a Kubernetes, descubrimos que DNS maneja 250,000 consultas por segundo.  Como resultado, las aplicaciones comenzaron a experimentar tiempos de espera constantes y serios para las consultas de DNS.  Esto sucedi√≥ a pesar de los incre√≠bles esfuerzos para optimizar y cambiar el proveedor de DNS a CoreDNS (que alcanz√≥ 1000 pods ejecut√°ndose en 120 n√∫cleos en la carga m√°xima). <br><br>  Al explorar otras posibles causas y soluciones, encontramos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo que</a> describe las condiciones de carrera que afectan el marco de filtrado de paquetes de <b>netfilter</b> en Linux.  Los tiempos de espera que observamos, junto con el creciente contador <b>insert_failed</b> en la interfaz de Flannel, correspond√≠an a las conclusiones del art√≠culo. <br><br>  El problema surge en la etapa de traducci√≥n de direcciones de red de origen y destino (SNAT y DNAT) y la posterior entrada en la tabla <b>conntrack</b> .  Una de las soluciones discutidas dentro de la empresa y propuesta por la comunidad fue la transferencia de DNS al propio nodo de trabajo.  En este caso: <br><br><ul><li>  SNAT no es necesario porque el tr√°fico permanece dentro del nodo.  No necesita enrutarse a trav√©s de la interfaz <b>eth0</b> . </li><li>  No se necesita DNAT, porque la IP de destino es local para el host, y no un pod seleccionado al azar seg√∫n las reglas de <b>iptables</b> . </li></ul><br>  Decidimos mantener este enfoque.  CoreDNS se implement√≥ como DaemonSet en Kubernetes e implementamos un servidor DNS host local en <b>resolv.conf de</b> cada pod configurando el <b>indicador --cluster-dns</b> del comando <b>kubelet</b> .  Esta soluci√≥n ha demostrado ser efectiva para los tiempos de espera de DNS. <br><br>  Sin embargo, a√∫n observamos la p√©rdida de paquetes y un aumento en el contador <b>insert_failed</b> en la interfaz de Flannel.  Esta situaci√≥n continu√≥ despu√©s de la introducci√≥n de la soluci√≥n, ya que pudimos excluir SNAT y / o DNAT solo para el tr√°fico DNS.  Las condiciones de carrera persistieron para otros tipos de tr√°fico.  Afortunadamente, la mayor√≠a de nuestros paquetes son TCP, y cuando ocurre un problema, simplemente se retransmiten.  Todav√≠a estamos tratando de encontrar una soluci√≥n adecuada para todo tipo de tr√°fico. <br><br><h4>  Uso de Envoy para un mejor equilibrio de carga </h4><br>  A medida que migramos los servicios de back-end a Kubernetes, comenzamos a sufrir una carga desequilibrada entre los pods.  Descubrimos que debido a HTTP Keepalive, las conexiones ELB colgaban en los primeros m√≥dulos listos para usar de cada implementaci√≥n de implementaci√≥n.  Por lo tanto, la mayor parte del tr√°fico pas√≥ por un peque√±o porcentaje de los pods disponibles.  La primera soluci√≥n que probamos fue establecer el par√°metro MaxSurge al 100% en nuevas implementaciones para los peores casos.  El efecto fue insignificante y poco prometedor en t√©rminos de despliegues m√°s grandes. <br><br>  Otra soluci√≥n que utilizamos fue aumentar artificialmente las solicitudes de recursos para servicios de misi√≥n cr√≠tica.  En este caso, las vainas adyacentes tendr√≠an m√°s margen de maniobra que otras vainas pesadas.  A la larga, tampoco funcionar√≠a debido al desperdicio de recursos.  Adem√°s, nuestras aplicaciones Node ten√≠an un solo subproceso y, en consecuencia, solo pod√≠an usar un n√∫cleo.  La √∫nica soluci√≥n real era utilizar un mejor equilibrio de carga. <br><br>  Durante mucho tiempo hemos querido apreciar plenamente a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Envoy</a> .  La situaci√≥n actual nos permiti√≥ implementarlo de manera muy limitada y obtener resultados inmediatos.  Envoy es un proxy de s√©ptimo nivel de c√≥digo abierto y alto rendimiento dise√±ado para grandes aplicaciones SOA.  Es capaz de aplicar t√©cnicas avanzadas de equilibrio de carga, incluidos reintentos autom√°ticos, disyuntores y l√≠mites de velocidad globales.  <i>( <b>Nota de traducci√≥n</b> : para obtener m√°s detalles, consulte el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo reciente</a> sobre Istio, la malla de servicios, que se basa en Envoy).</i> <br><br>  Se nos ocurri√≥ la siguiente configuraci√≥n: tener un sidecar Envoy para cada pod y una ruta √∫nica, y el cl√∫ster: conectarse al contenedor localmente por puerto.  Para minimizar la cascada potencial y mantener un peque√±o radio de "da√±o", utilizamos el parque de pod de proxy frontal Envoy, uno para cada Zona de disponibilidad (AZ) para cada servicio.  Recurrieron a un mecanismo de descubrimiento de servicio simple escrito por uno de nuestros ingenieros, que simplemente devolvi√≥ una lista de pods en cada AZ para un servicio dado. <br><br>  Luego, los enviados frontales del servicio utilizaron este mecanismo de descubrimiento de servicios con un cl√∫ster y una ruta aguas arriba.  Establecimos tiempos de espera adecuados, aumentamos la configuraci√≥n de todos los disyuntores y agregamos una configuraci√≥n de reintento m√≠nima para ayudar con fallas individuales y garantizar implementaciones sin problemas.  Antes de cada uno de estos enviados frontales de servicio, colocamos un ELB TCP.  Incluso si el keepalive de nuestra capa de proxy principal colgara en algunas c√°psulas de Envoy, a√∫n podr√≠an manejar la carga mucho mejor y se establecer√≠an para equilibrarse al menos a trav√©s de la solicitud en el backend. <br><br>  Para la implementaci√≥n, utilizamos el gancho preStop tanto en los pods de aplicaciones como en los sidecar.  El enlace inici√≥ un error al verificar el estado del punto final de administraci√≥n ubicado en el contenedor del sidecar y "durmi√≥" durante un tiempo para permitir que se completen las conexiones activas. <br><br>  Una de las razones por las que hemos podido avanzar tan r√°pido en la resoluci√≥n de problemas est√° relacionada con las m√©tricas detalladas que pudimos integrar f√°cilmente en una instalaci√≥n est√°ndar de Prometheus.  Con ellos se hizo posible ver exactamente lo que estaba sucediendo mientras seleccion√°bamos los par√°metros de configuraci√≥n y redistribu√≠amos el tr√°fico. <br><br>  Los resultados fueron inmediatos y obvios.  Comenzamos con los servicios m√°s desequilibrados y, en este momento, ya funciona antes que los 12 servicios m√°s importantes del cl√∫ster.  Este a√±o planeamos pasar a una malla de servicio completa con descubrimiento de servicio m√°s avanzado, interrupci√≥n de circuitos, detecci√≥n de valores at√≠picos, limitaci√≥n de velocidad y rastreo. <br><br> <a href=""><img src="https://habrastorage.org/webt/gy/yg/6s/gyyg6s_l8nlpbktislqy9jp9fma.png" alt="imagen"></a> <br>  <i>Figura 3‚Äì1.</i>  <i>Convergencia de CPU de un servicio durante la transici√≥n a Envoy</i> <br><br><img src="https://habrastorage.org/webt/lf/iw/pn/lfiwpneg1uvaruk85ghgcbhoghy.png"><br><br><img src="https://habrastorage.org/webt/ud/ug/8m/udug8mekxc36ql2vohzl-snp3vu.png"><br><br><h2>  Resultado final </h2><br>  Gracias a nuestra experiencia e investigaci√≥n adicional, hemos creado un fuerte equipo de infraestructura con buenas habilidades para dise√±ar, implementar y operar grandes grupos de Kubernetes.  Ahora todos los ingenieros de Tinder tienen el conocimiento y la experiencia sobre c√≥mo empacar contenedores e implementar aplicaciones en Kubernetes. <br><br>  Cuando surgi√≥ la necesidad de capacidades adicionales en la infraestructura anterior, tuvimos que esperar varios minutos para lanzar nuevas instancias de EC2.  Ahora los contenedores se inician y comienzan a procesar el tr√°fico durante varios segundos en lugar de minutos.  La programaci√≥n de m√∫ltiples contenedores en una sola instancia de EC2 tambi√©n proporciona una concentraci√≥n horizontal mejorada.  Como resultado, en 2019, pronosticamos una reducci√≥n significativa en los costos de EC2 en comparaci√≥n con el a√±o pasado. <br><br>  La migraci√≥n tard√≥ casi dos a√±os, pero la completamos en marzo de 2019.  Actualmente, la plataforma Tinder se ejecuta exclusivamente en el cl√∫ster Kubernetes, que consta de 200 servicios, 1000 nodos, 15,000 pods y 48,000 contenedores en ejecuci√≥n.  La infraestructura ya no es responsabilidad exclusiva de los equipos operativos.  Todos nuestros ingenieros comparten esta responsabilidad y controlan el proceso de construcci√≥n e implementaci√≥n de sus aplicaciones utilizando solo c√≥digo. <br><br><h2>  PD del traductor </h2><br>  Lea tambi√©n nuestra serie de art√≠culos en nuestro blog: <br><br><ul><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 1: <b>4.200 hogares y TessMaster en eBay</b></a> ". </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2: <b>Concur y SAP</b></a> ". </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 3: <b>GitHub</b></a> ". </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 4: <b>SoundCloud (autores Prometheus)</b></a> ". </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 5: <b>Monzo Digital Bank</b></a> " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>.</b></a> </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 6: <b>BlaBlaCar</b></a> ". </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 7: <b>BlackRock</b></a> ". </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 8: <b>Huawei</b></a> ". </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 9: <b>CERN y cl√∫steres de 210 K8</b></a> " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>.</b></a> </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Historias de √©xito de Kubernetes en producci√≥n.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 10: <b>Reddit</b></a> ". </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440278/">https://habr.com/ru/post/440278/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440268/index.html">Desv√≠o de sonido: mecanismo para generar clics ultras√≥nicos en polillas nocturnas como protecci√≥n contra murci√©lagos</a></li>
<li><a href="../440270/index.html">Consideramos un horario de turnos en la mente</a></li>
<li><a href="../440272/index.html">Mobile Opera tiene una VPN gratis</a></li>
<li><a href="../440274/index.html">Construyendo un servicio de moneda privada usando Exonum</a></li>
<li><a href="../440276/index.html">Depuraci√≥n frontal y posterior</a></li>
<li><a href="../440280/index.html">Revisi√≥n de software libre de Android</a></li>
<li><a href="../440282/index.html">Los marcos web Python m√°s r√°pidos en 2019</a></li>
<li><a href="../440284/index.html">Una nueva mirada a la visualizaci√≥n de cuadros de di√°logo en Android</a></li>
<li><a href="../440286/index.html">Ruido Perlin, generaci√≥n de contenido procesal y espacio interesante.</a></li>
<li><a href="../440288/index.html">Seguridad de IoT. N√∫mero 1. Relojes inteligentes, rastreadores de ejercicios y escalas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
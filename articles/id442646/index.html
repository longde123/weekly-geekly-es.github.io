<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤲 👨‍✈️ 🧛🏼 Kubernetes Networks: Ingress ➡️ 🔕 🍏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hari ini kami menerbitkan terjemahan bagian ketiga dari Panduan Jaringan Kubernetes. Bagian pertama adalah tentang pod, yang kedua tentang layanan, da...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes Networks: Ingress</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/442646/">  Hari ini kami menerbitkan terjemahan bagian ketiga dari Panduan Jaringan Kubernetes.  Bagian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pertama</a> adalah tentang pod, yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kedua</a> tentang layanan, dan hari ini kita akan berbicara tentang penyeimbangan beban dan sumber daya Kubernet dari tipe Ingress. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/te/wp/ce/tewpcee5cggzqu97irog_mj_qgo.png"></div><a name="habracut"></a><h2>  <font color="#3AC1EF">Routing bukan load balancing</font> </h2><br>  Pada artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sebelumnya</a> dalam seri ini, kami mempertimbangkan konfigurasi yang terdiri dari sepasang perapian dan layanan yang diberi alamat IP yang disebut "cluster IP".  Pertanyaan yang ditujukan untuk perapian dikirim ke alamat ini.  Di sini kami akan terus bekerja pada sistem pelatihan kami, mulai dari tempat kami lulus terakhir kali.  Ingatlah bahwa alamat IP cluster dari layanan, <code>10.3.241.152</code> , milik serangkaian alamat IP yang berbeda dari yang digunakan dalam jaringan perapian dan dari yang digunakan dalam jaringan di mana node berada.  Saya menyebut jaringan yang didefinisikan oleh ruang alamat ini sebagai "jaringan layanan", meskipun hampir tidak layak untuk nama khusus, karena tidak ada perangkat yang terhubung ke jaringan ini, dan ruang alamatnya, pada kenyataannya, seluruhnya terdiri dari aturan routing.  Sebelumnya diperlihatkan bagaimana jaringan ini diimplementasikan berdasarkan komponen Kubernetes, yang disebut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kube-proxy,</a> dan berinteraksi dengan modul kernel Linux <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">netfilter</a> untuk mencegat dan mengarahkan lalu lintas yang dikirim ke cluster IP untuk bekerja di bawah. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/615/35f/1ec/61535f1ec0169dbd13732aba4c9a5621.png"></div><br>  <i><font color="#999999">Diagram jaringan</font></i> <br><br>  Sejauh ini, kami berbicara tentang "koneksi" dan "permintaan" dan bahkan menggunakan konsep "lalu lintas" yang sulit diinterpretasikan, tetapi untuk memahami fitur mekanisme Ingress Kubernetes, kita perlu menggunakan istilah yang lebih tepat.  Jadi, koneksi dan permintaan berfungsi pada level 4 dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model OSI</a> (tcp) atau pada level 7 (http, rpc, dan sebagainya).  Aturan Netfilter adalah aturan routing, mereka bekerja dengan paket IP di level ketiga.  Semua router, termasuk netfilter, membuat keputusan lebih atau kurang hanya berdasarkan informasi yang terkandung dalam paket.  Secara umum, mereka tertarik dari mana paket itu berasal dan ke mana ia pergi.  Oleh karena itu, untuk menggambarkan perilaku ini dalam hal tingkat ketiga model OSI, harus dikatakan bahwa setiap paket yang ditujukan untuk layanan yang terletak di <code>10.3.241.152:80</code> , yang tiba di antarmuka node <code>eth0</code> , diproses oleh netfilter, dan, sesuai dengan aturan yang ditetapkan untuk layanan kami dialihkan ke alamat IP dari perapian yang bisa diterapkan. <br><br>  Tampaknya cukup jelas bahwa mekanisme apa pun yang kami gunakan untuk memungkinkan klien eksternal mengakses pod harus menggunakan infrastruktur perutean yang sama.  Akibatnya, klien eksternal ini akan mengakses alamat IP dan port cluster, karena mereka adalah "titik akses" untuk semua mekanisme yang telah kita bicarakan sejauh ini.  Mereka memungkinkan kita untuk tidak khawatir tentang di mana tepatnya itu dieksekusi pada titik waktu tertentu.  Namun, sama sekali tidak jelas bagaimana membuat semuanya berfungsi. <br><br>  Layanan IP Cluster hanya dapat dijangkau dengan antarmuka node Ethernet.  Tidak ada di luar gugus yang tahu apa yang harus dilakukan dengan alamat dari rentang tempat alamat ini berada.  Bagaimana saya bisa mengarahkan lalu lintas dari alamat IP publik ke alamat yang hanya dapat dijangkau jika paket telah tiba di host? <br><br>  Jika kami mencoba menemukan solusi untuk masalah ini, maka salah satu hal yang dapat dilakukan dalam proses menemukan solusi adalah mempelajari aturan netfilter menggunakan utilitas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">iptables</a> .  Jika Anda melakukan ini, Anda dapat menemukan sesuatu yang, pada pandangan pertama, mungkin tampak tidak biasa: aturan untuk layanan tidak terbatas pada jaringan sumber tertentu.  Ini berarti bahwa setiap paket yang dihasilkan di mana saja yang tiba pada antarmuka Ethernet dari simpul dan memiliki alamat tujuan <code>10.3.241.152:80</code> akan diakui sebagai sesuai dengan aturan dan akan dialihkan ke sub.  Bisakah kita memberi klien IP cluster, mungkin dengan mengikatnya ke nama domain yang sesuai, dan kemudian mengatur rute yang memungkinkan kita untuk mengatur pengiriman paket-paket ini ke salah satu node? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5f3/6ba/ea7/5f36baea7589e3559632de385f3f2bf6.png"></div><br>  <i><font color="#999999">Klien dan kluster eksternal</font></i> <br><br>  Jika semuanya diatur dengan cara ini, maka desain seperti itu akan terbukti berfungsi.  Klien mengakses IP cluster, paket mengikuti rute yang mengarah ke host, dan kemudian mereka diarahkan ke bawah.  Pada saat ini, tampaknya bagi Anda solusi semacam itu dapat dibatasi, tetapi ia mengalami beberapa masalah serius.  Yang pertama adalah bahwa node, pada kenyataannya, konsep sesaat, mereka tidak terlalu berbeda dalam hal ini dari perapian.  Mereka, tentu saja, sedikit lebih dekat ke dunia material daripada polong, tetapi mereka dapat bermigrasi ke mesin virtual baru, cluster dapat naik atau turun, dan sebagainya.  Router bekerja pada level ketiga model OSI dan paket tidak dapat membedakan antara layanan yang berfungsi normal dan yang tidak bekerja dengan benar.  Mereka berharap bahwa transisi berikutnya dalam rute akan dapat diakses dan stabil.  Jika node tidak dapat dijangkau, rute akan menjadi tidak beroperasi dan akan tetap demikian, dalam banyak kasus, banyak waktu.  Bahkan jika rute tersebut tahan terhadap kegagalan, skema semacam itu akan mengarah pada kenyataan bahwa semua lalu lintas eksternal melewati satu node, yang mungkin tidak optimal. <br><br>  Tidak peduli bagaimana kita membawa lalu lintas klien ke sistem, kita perlu melakukan ini sehingga tidak tergantung pada keadaan node cluster tunggal.  Dan, pada kenyataannya, tidak ada cara yang dapat diandalkan untuk melakukan ini hanya dengan menggunakan routing, tanpa beberapa cara mengelola router secara aktif.  Sebagai soal fakta, justru peran ini, peran sistem kontrol, yang dimainkan oleh kube-proxy dalam kaitannya dengan netfilter.  Memperluas tanggung jawab Kubernetes untuk mengelola router eksternal mungkin tidak masuk akal bagi arsitek sistem, terutama karena kami telah memiliki alat yang terbukti untuk mendistribusikan lalu lintas klien di beberapa server.  Mereka disebut load balancers, dan tidak mengherankan bahwa mereka adalah solusi yang benar-benar andal untuk Kubernetes Ingress.  Untuk memahami dengan tepat bagaimana ini terjadi, kita perlu bangkit dari OSI tingkat ketiga dan berbicara tentang koneksi lagi. <br><br>  Untuk menggunakan load balancer untuk mendistribusikan lalu lintas klien di antara node cluster, kami membutuhkan alamat IP publik yang dapat disambungkan klien, dan kami juga membutuhkan alamat node itu sendiri yang dapat digunakan oleh penyeimbang beban untuk mengalihkan permintaan.  Untuk alasan di atas, kita tidak bisa begitu saja membuat rute statis yang stabil antara router gateway dan node menggunakan jaringan berbasis layanan (IP cluster). <br><br>  Di antara alamat lain yang dapat digunakan untuk bekerja, hanya alamat jaringan yang terhubung dengan antarmuka Ethernet dari node, yaitu, dalam contoh ini, <code>10.100.0.0/24</code> , yang dapat dicatat.  Router sudah tahu cara meneruskan paket ke antarmuka ini, dan koneksi yang dikirim dari load balancer ke router akan menuju ke mana mereka harus pergi.  Tetapi jika klien ingin terhubung ke layanan kami di port 80, maka kami tidak bisa hanya mengirim paket ke port ini di antarmuka jaringan node. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4cd/c77/40b/4cdc7740be5ecfc3069a8b3fb157c605.png"></div><br>  <i><font color="#999999">Load balancer, upaya yang gagal untuk mengakses port 80 dari antarmuka jaringan host</font></i> <br><br>  Alasan mengapa hal ini tidak dapat dilakukan benar-benar jelas.  Yaitu, kita berbicara tentang fakta bahwa tidak ada proses menunggu koneksi di <code>10.100.0.3:80</code> (dan jika ada, maka ini jelas bukan proses yang sama), dan aturan netfilter, yang, seperti yang kami harapkan, akan mencegat permintaan dan mereka akan mengirimkannya kepadanya, mereka tidak akan bekerja di alamat tujuan itu.  Mereka hanya menanggapi jaringan IP cluster berdasarkan layanan, yaitu ke alamat <code>10.3.241.152:80</code> .  Akibatnya, paket-paket ini, pada saat kedatangan, tidak dapat dikirimkan ke alamat tujuan, dan kernel akan mengeluarkan respons <code>ECONNREFUSED</code> .  Ini menempatkan kita dalam posisi yang membingungkan: tidak mudah untuk bekerja dengan jaringan untuk pengalihan paket yang netfilter dikonfigurasi ketika mengarahkan data dari gateway ke node, dan jaringan yang routingnya mudah dikonfigurasikan bukan jaringan yang netfilter mengarahkan paket.  Untuk mengatasi masalah ini, Anda dapat membuat jembatan antara jaringan-jaringan ini.  Inilah yang dilakukan Kubernetes menggunakan layanan seperti NodePort. <br><br><h2>  <font color="#3AC1EF">Layanan seperti NodePort</font> </h2><br>  Layanan yang kami, misalnya, buat di artikel sebelumnya, tidak diberi tipe, jadi ia mengadopsi tipe default - <code>ClusterIP</code> .  Ada dua jenis layanan yang berbeda dalam fitur tambahan, dan salah satu yang kami minati saat ini adalah <code>NodePort</code> .  Berikut adalah contoh deskripsi layanan jenis ini: <br><br><pre> <code class="plaintext hljs">kind: Service apiVersion: v1 metadata: name: service-test spec: type: NodePort selector:   app: service_test_pod ports: - port: 80   targetPort: http</code> </pre> <br>  Layanan tipe <code>NodePort</code> adalah layanan tipe <code>ClusterIP</code> yang memiliki peluang tambahan: akses ke mereka dapat diperoleh baik dengan alamat IP yang ditugaskan ke host dan oleh alamat yang diberikan ke cluster di jaringan layanan.  Ini dicapai dengan cara yang agak sederhana: ketika Kubernetes membuat layanan NodePort, kube-proxy mengalokasikan port dalam kisaran 30000-32767 dan membuka port ini pada antarmuka <code>eth0</code> dari setiap node (maka nama jenis layanan - <code>NodePort</code> ).  Koneksi yang dilakukan ke port ini (kami akan memanggil port <code>NodePort</code> ) dialihkan ke IP cluster dari layanan.  Jika kita membuat layanan yang dijelaskan di atas dan menjalankan perintah <code>kubectl get svc service-test</code> , kita dapat melihat port yang ditugaskan untuk itu. <br><br><pre> <code class="plaintext hljs">$ kubectl get svc service-test NAME           CLUSTER-IP EXTERNAL-IP   PORT(S) AGE service-test   10.3.241.152 &lt;none&gt;        80:32213/TCP 1m</code> </pre> <br>  Dalam hal ini, layanan ini diberikan NodePort <code>32213</code> .  Ini berarti bahwa kita sekarang dapat terhubung ke layanan melalui sembarang simpul di gugus eksperimental kami di <code>10.100.0.2:32213</code> atau di <code>10.100.0.3:32213</code> .  Dalam hal ini, lalu lintas akan dialihkan ke layanan. <br><br>  Setelah bagian dari sistem ini mengambil tempat, kami memiliki semua fragmen pipa untuk menyeimbangkan beban yang dibuat oleh permintaan klien ke semua node cluster. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/da5/78e/735/da578e735e468dce8077f8a1d27d8490.png"></div><br>  <i><font color="#999999">Layanan NodePort</font></i> <br><br>  Dalam gambar sebelumnya, klien terhubung ke penyeimbang beban melalui alamat IP publik, penyeimbang beban memilih node dan menghubungkannya di <code>10.100.0.3:32213</code> , kube-proxy menerima koneksi ini dan mengarahkannya ke layanan yang dapat diakses melalui cluster IP <code>10.3.241.152:80</code> .  Di sini, permintaan berhasil diproses sesuai dengan aturan yang ditetapkan oleh netfilter, dan dialihkan ke pod server di alamat <code>10.0.2.2:8080</code> .  Mungkin semua ini mungkin terlihat sedikit rumit, dan sedikit banyak, tetapi tidak mudah untuk menghasilkan solusi yang lebih sederhana yang mendukung semua fitur hebat yang memberi kita pod dan jaringan berbasis layanan. <br><br>  Namun mekanisme ini bukan tanpa masalah sendiri.  Menggunakan layanan seperti <code>NodePort</code> memberi pelanggan akses ke layanan menggunakan port non-standar.  Seringkali ini bukan masalah, karena load balancer dapat memberi mereka port reguler dan menyembunyikan <code>NodePort</code> dari pengguna akhir.  Tetapi dalam beberapa skenario, misalnya, ketika menggunakan penyeimbang beban platform Google Cloud eksternal, mungkin perlu untuk menyebarkan <code>NodePort</code> klien.  Perlu dicatat bahwa pelabuhan seperti itu, di samping itu, mewakili sumber daya yang terbatas, meskipun 2.768 pelabuhan mungkin cukup bahkan untuk kelompok terbesar.  Dalam kebanyakan kasus, Anda dapat membiarkan Kubernetes memilih nomor port secara acak, tetapi Anda dapat mengaturnya sendiri jika perlu.  Masalah lain adalah beberapa batasan mengenai penyimpanan alamat IP sumber dalam permintaan.  Untuk mengetahui cara mengatasi masalah ini, Anda dapat merujuk materi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ini</a> dari dokumentasi Kubernetes. <br><br>  Ports <code>NodePorts</code> adalah mekanisme fundamental di mana semua lalu lintas eksternal memasuki kluster Kubernetes.  Namun, mereka sendiri tidak memberi kami solusi yang sudah jadi.  Untuk alasan di atas, sebelum cluster, apakah klien adalah entitas internal atau eksternal yang terletak di jaringan publik, selalu diharuskan untuk memiliki semacam penyeimbang beban. <br><br>  Arsitek platform, menyadari hal ini, menyediakan dua cara untuk mengonfigurasikan penyeimbang beban dari platform Kubernetes itu sendiri.  Mari kita bahas ini. <br><br><h2>  <font color="#3AC1EF">Layanan seperti LoadBalancer dan sumber daya dari tipe Ingress</font> </h2><br>  Layanan seperti <code>LoadBalancer</code> dan sumber daya dari tipe <code>Ingress</code> adalah beberapa mekanisme Kubernet yang paling kompleks.  Namun, kami tidak akan menghabiskan terlalu banyak waktu pada mereka, karena penggunaannya tidak menyebabkan perubahan mendasar dalam segala hal yang telah kita bicarakan sejauh ini.  Semua lalu lintas eksternal, seperti sebelumnya, memasuki cluster melalui <code>NodePort</code> . <br><br>  Arsitek bisa berhenti di sini, memungkinkan mereka yang membuat cluster hanya peduli tentang alamat IP publik dan memuat penyeimbang.  Bahkan, dalam situasi tertentu, seperti memulai cluster di server biasa atau di rumah, inilah yang sebenarnya mereka lakukan.  Tetapi di lingkungan yang mendukung konfigurasi sumber daya jaringan yang dikontrol API, Kubernetes memungkinkan Anda untuk mengkonfigurasi semua yang Anda butuhkan di satu tempat. <br><br>  Pendekatan pertama untuk memecahkan masalah ini, yang paling sederhana, adalah dengan menggunakan layanan Kubernetes seperti <code>LoadBalancer</code> .  Layanan tersebut memiliki semua kemampuan layanan seperti <code>NodePort</code> , dan, di samping itu, memiliki kemampuan untuk membuat jalur penuh untuk lalu lintas masuk, berdasarkan asumsi bahwa cluster berjalan di lingkungan seperti GCP atau AWS yang mendukung konfigurasi sumber daya jaringan melalui API. <br><br><pre> <code class="plaintext hljs">kind: Service apiVersion: v1 metadata: name: service-test spec: type: LoadBalancer selector:   app: service_test_pod ports: - port: 80   targetPort: http</code> </pre> <br>  Jika kami menghapus dan membuat kembali layanan dari contoh kami di Google Kubernetes Engine, maka segera setelah itu, menggunakan <code>kubectl get svc service-test</code> command, kami dapat memverifikasi bahwa IP eksternal ditugaskan. <br><br><pre> <code class="plaintext hljs">$ kubectl get svc service-test NAME      CLUSTER-IP      EXTERNAL-IP PORT(S)          AGE openvpn   10.3.241.52     35.184.97.156 80:32213/TCP     5m</code> </pre> <br>  Dikatakan di atas bahwa kita akan dapat memverifikasi fakta penugasan alamat IP eksternal "segera", meskipun fakta bahwa penugasan IP eksternal dapat memakan waktu beberapa menit, yang tidak mengejutkan, mengingat jumlah sumber daya yang perlu dibawa ke keadaan sehat.  Pada platform GCP, misalnya, ini membutuhkan sistem untuk membuat alamat IP eksternal, aturan pengalihan lalu lintas, server proxy target, layanan backend, dan, mungkin, sebuah instance dari grup.  Setelah mengalokasikan alamat IP eksternal, Anda dapat terhubung ke layanan melalui alamat ini, menetapkannya nama domain dan menginformasikan klien.  Sampai layanan dihancurkan dan diciptakan kembali (untuk melakukan ini, jarang ketika ada alasan yang bagus), alamat IP tidak akan berubah. <br><br>  Layanan seperti <code>LoadBalancer</code> memiliki beberapa batasan.  Layanan semacam itu tidak dapat dikonfigurasikan untuk mendekripsi lalu lintas HTTPS.  Anda tidak dapat membuat host virtual atau mengonfigurasi rute berbasis jalur, jadi Anda tidak bisa, menggunakan konfigurasi praktis, menggunakan penyeimbang beban tunggal dengan banyak layanan.  Keterbatasan ini menyebabkan pengenalan Kubernetes 1.1.  Sumber daya khusus untuk mengonfigurasi penyeimbang beban.  Ini adalah sumber dari tipe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Ingress</a> .  Layanan seperti <code>LoadBalancer</code> ditujukan untuk memperluas kemampuan layanan tunggal untuk mendukung klien eksternal.  Sebaliknya, sumber daya <code>Ingress</code> adalah sumber daya khusus yang memungkinkan Anda mengkonfigurasi penyeimbang beban secara fleksibel.  API Ingress mendukung dekripsi lalu lintas TLS, host virtual, dan perutean berbasis jalur.  Menggunakan API ini, penyeimbang beban dapat dengan mudah dikonfigurasikan untuk bekerja dengan beberapa layanan backend. <br><br>  API sumber daya dari tipe <code>Ingress</code> terlalu besar untuk membahas fitur-fiturnya di sini, apalagi, tidak terlalu memengaruhi cara kerja sumber daya Ingress di tingkat jaringan.  Implementasi sumber daya ini mengikuti pola Kubernetes yang biasa: ada tipe sumber daya dan pengontrol untuk mengontrol tipe ini.  Sumber daya dalam hal ini adalah sumber daya <code>Ingress</code> , yang menggambarkan permintaan ke sumber daya jaringan.  Berikut ini uraian sumber daya <code>Ingress</code> . <br><br><pre> <code class="plaintext hljs">apiVersion: extensions/v1beta1 kind: Ingress metadata: name: test-ingress annotations:   kubernetes.io/ingress.class: "gce" spec: tls:   - secretName: my-ssl-secret rules: - host: testhost.com   http:     paths:     - path: /*       backend:         serviceName: service-test         servicePort: 80</code> </pre> <br>  Pengontrol Ingress bertanggung jawab untuk mengeksekusi permintaan ini dengan membawa sumber daya lain ke kondisi yang diinginkan.  Saat menggunakan Ingress, layanan seperti <code>NodePort</code> dibuat, setelah itu pengontrol Ingress diizinkan untuk membuat keputusan tentang cara mengarahkan lalu lintas ke node.  Ada implementasi pengontrol Ingress untuk penyeimbang beban GCE, untuk penyeimbang AWS, untuk server proxy populer seperti nginx dan haproxy.  Perhatikan bahwa pencampuran sumber daya dan layanan Ingress seperti <code>LoadBalancer</code> dapat menyebabkan masalah kecil di beberapa lingkungan.  Mereka mudah ditangani, tetapi, secara umum, yang terbaik adalah menggunakan Ingress bahkan untuk layanan sederhana. <br><br><h2>  <font color="#3AC1EF">HostPort dan HostNetwork</font> </h2><br>  Apa yang akan kita bicarakan sekarang, yaitu, <code>HostPort</code> dan <code>HostNetwork</code> , dapat dikaitkan dengan kategori kelangkaan yang menarik, dan bukan karena alat yang bermanfaat.  Bahkan, saya berjanji untuk menyatakan bahwa dalam 99,99% kasus penggunaannya dapat dianggap sebagai anti-pola, dan sistem apa pun di mana mereka digunakan harus menjalani pemeriksaan wajib terhadap arsitekturnya. <br><br>  Saya pikir itu tidak layak untuk dibicarakan sama sekali, tetapi itu adalah sesuatu seperti alat yang digunakan oleh sumber daya Ingress untuk memproses lalu lintas masuk, jadi saya memutuskan bahwa layak untuk menyebutkannya, setidaknya secara singkat. <br><br>  Pertama, <code>HostPort</code> bicara tentang <code>HostPort</code> .  Ini adalah properti kontainer (dideklarasikan dalam struktur <code>ContainerPort</code> ).  Ketika nomor port tertentu tertulis di dalamnya, ini mengarah ke pembukaan port ini pada node dan pengalihan langsung ke wadah.  Tidak ada mekanisme proxy, dan port hanya terbuka pada node di mana wadah berjalan.  Pada hari-hari awal platform, sebelum mekanisme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DaemonSet</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">StatefulSet</a> muncul di dalamnya, <code>HostPort</code> adalah trik yang memungkinkan hanya satu kontainer dari jenis tertentu untuk diluncurkan pada node apa pun.  Sebagai contoh, saya pernah menggunakan ini untuk membuat cluster Elasticsearch dengan mengatur <code>HostPort</code> ke <code>9200</code> dan menentukan replika sebanyak ada node.       ,          Kubernetes,    -     <code>HostPort</code> . <br><br>   <code>NostNetwork</code> , ,   Kubernetes    ,  <code>HostPort</code> .       <code>true</code> ,       - <code>network=host</code>  <code>docker run</code> .    ,           .            <code>eth0</code>    .  ,             .      ,  ,  ,    Kubernetes,     - . <br><br><h2>  <font color="#3AC1EF">Ringkasan</font> </h2><br>        Kubernetes,   ,          Ingress. ,  ,    ,       Kubernetes. <br><br>  <b>Pembaca yang budiman!</b>     Ingress? <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id442646/">https://habr.com/ru/post/id442646/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id442636/index.html">Apakah Anda membawa berita buruk kepada manajemen?</a></li>
<li><a href="../id442638/index.html">Penskalaan aplikasi Kubernetes berdasarkan metrik dari Prometheus</a></li>
<li><a href="../id442640/index.html">Perfect Bug: Menggunakan Type Confusion di Flash. Bagian 1</a></li>
<li><a href="../id442642/index.html">Apa yang harus dibaca di bulan Maret: 22 buku baru untuk pemasar, manajer, pengembang, dan desainer</a></li>
<li><a href="../id442644/index.html">Sebagian besar keterampilan non-pemrograman meningkatkan nilai pengembang</a></li>
<li><a href="../id442648/index.html">Go mekanisme alokasi</a></li>
<li><a href="../id442650/index.html">Analisis dan optimalisasi aplikasi Bereaksi</a></li>
<li><a href="../id442652/index.html">Menggunakan Fastify dan Preact ke Prototipe Aplikasi Web dengan Cepat</a></li>
<li><a href="../id442654/index.html">Beralih ke Next.js dan mempercepat pemuatan beranda manifold.co 7,5 kali</a></li>
<li><a href="../id442658/index.html">8 trik untuk bekerja dengan CSS: paralaks, sticky footer dan lainnya</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
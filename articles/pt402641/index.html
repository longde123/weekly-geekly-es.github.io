<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëµüèæ üå™Ô∏è üè∏ Qual a apar√™ncia das redes neurais profundas e por que elas exigem tanta mem√≥ria üöÑ üë©‚Äç‚úàÔ∏è üç¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoje, o gr√°fico √© uma das maneiras mais aceit√°veis ‚Äã‚Äãde descrever os modelos criados no sistema de aprendizado de m√°quina. Esses gr√°ficos computaciona...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Qual a apar√™ncia das redes neurais profundas e por que elas exigem tanta mem√≥ria</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/402641/"><img src="https://habrastorage.org/getpro/geektimes/post_images/802/6f4/eab/8026f4eab4ee028d6894159b00421c56.jpg" alt="imagem"><br><br>  Hoje, o gr√°fico √© uma das maneiras mais aceit√°veis ‚Äã‚Äãde descrever os modelos criados no sistema de aprendizado de m√°quina.  Esses gr√°ficos computacionais s√£o compostos de v√©rtices de neur√¥nios conectados por arestas de sinapse que descrevem as conex√µes entre v√©rtices. <br><br>  Ao contr√°rio de um processador escalar central ou de gr√°ficos vetoriais, o IPU - um novo tipo de processador projetado para aprendizado de m√°quina, permite criar esses gr√°ficos.  Um computador projetado para gerenciamento de gr√°ficos √© uma m√°quina ideal para modelos de gr√°ficos computacionais criados como parte do aprendizado de m√°quina. <br><br>  Uma das maneiras mais f√°ceis de descrever como a intelig√™ncia da m√°quina funciona √© visualiz√°-la.  A equipe de desenvolvimento do Graphcore criou uma cole√ß√£o dessas imagens exibidas na IPU.  A base foi o software Poplar, que visualiza o trabalho da intelig√™ncia artificial.  Pesquisadores dessa empresa tamb√©m descobriram por que redes profundas exigem tanta mem√≥ria e quais solu√ß√µes existem. <a name="habracut"></a><br><br>  O √°lamo inclui um compilador gr√°fico que foi criado do zero para converter as opera√ß√µes padr√£o usadas como parte do aprendizado de m√°quina em c√≥digo de aplicativo altamente otimizado para IPUs.  Ele permite que voc√™ colete esses gr√°ficos juntos no mesmo princ√≠pio em que os POPNNs s√£o montados.  A biblioteca cont√©m um conjunto de diferentes tipos de v√©rtices para primitivas generalizadas. <br><br>  Os gr√°ficos s√£o o paradigma no qual todo software √© baseado.  No √Ålamo, os gr√°ficos permitem definir o processo de c√°lculo, onde os v√©rtices realizam opera√ß√µes e arestas descrevem o relacionamento entre eles.  Por exemplo, se voc√™ quiser adicionar dois n√∫meros, poder√° definir um v√©rtice com duas entradas (os n√∫meros que deseja adicionar), alguns c√°lculos (a fun√ß√£o de adicionar dois n√∫meros) e a sa√≠da (resultado). <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/708/107/2ad/7081072ad3e33d401cabae1f3914bccb.jpg" alt="imagem"><br><br>  Normalmente, as opera√ß√µes de v√©rtice s√£o muito mais complicadas do que no exemplo descrito acima.  Muitas vezes, eles s√£o definidos por pequenos programas chamados codelets (nomes de c√≥digo).  A abstra√ß√£o gr√°fica √© atraente porque n√£o faz suposi√ß√µes sobre a estrutura dos c√°lculos e divide o c√°lculo em componentes que o processador IPU pode usar para trabalhar. <br><br>  O √°lamo usa essa abstra√ß√£o simples para criar gr√°ficos muito grandes que s√£o representados como imagens.  A gera√ß√£o program√°tica do gr√°fico significa que podemos adapt√°-lo aos c√°lculos espec√≠ficos necess√°rios para garantir o uso mais eficiente dos recursos da IPU. <br><br>  O compilador converte opera√ß√µes padr√£o usadas em sistemas de aprendizado de m√°quina em c√≥digo de aplicativo altamente otimizado para IPUs.  Um compilador de gr√°ficos cria uma imagem intermedi√°ria de um gr√°fico computacional implantado em um ou mais dispositivos IPU.  O compilador pode exibir esse gr√°fico computacional; portanto, um aplicativo gravado no n√≠vel da estrutura da rede neural exibe uma imagem do gr√°fico computacional executado na IPU. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/45a/eb2/4b8/45aeb24b80e244c6c16c6fc584d99678.jpg" alt="imagem"><br>  <i>Gr√°fico de aprendizado de ciclo completo AlexNet para frente e para tr√°s</i> <br><br>  O compilador gr√°fico Poplar transformou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a</a> descri√ß√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">da AlexNet</a> em um gr√°fico computacional de 18,7 milh√µes de v√©rtices e 115,8 milh√µes de arestas.  O cluster claramente vis√≠vel √© o resultado de uma forte conex√£o entre os processos em cada camada da rede, com uma conex√£o mais f√°cil entre os n√≠veis. <br><br>  Outro exemplo √© uma rede simples com conectividade completa, treinada no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MNIST</a> - um conjunto de dados simples para vis√£o computacional, uma esp√©cie de ‚ÄúOl√°, mundo‚Äù em aprendizado de m√°quina.  Uma rede simples para explorar esse conjunto de dados ajuda a entender os gr√°ficos que s√£o controlados pelos aplicativos Poplar.  Ao integrar bibliotecas de gr√°ficos a ambientes como o TensorFlow, a empresa fornece uma das maneiras mais f√°ceis de usar IPUs em aplicativos de aprendizado de m√°quina. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/f07/3bd/4e3/f073bd4e334225380ae51b16fb2e94b6.jpg" alt="imagem"><br><br>  Depois que o gr√°fico √© constru√≠do usando o compilador, ele precisa ser executado.  Isso √© poss√≠vel usando o mecanismo de gr√°fico.  Usando o ResNet-50 como exemplo, sua opera√ß√£o √© demonstrada. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/5d7/cb1/ce5/5d7cb1ce55a80f2b8e4ebefe38681710.jpg" alt="imagem"><br>  <i>Count ResNet-50</i> <br><br>  A arquitetura ResNet-50 permite criar redes profundas a partir de parti√ß√µes repetidas.  O processador precisa apenas determinar essas parti√ß√µes uma vez e cham√°-las novamente.  Por exemplo, um cluster no n√≠vel conv4 √© executado seis vezes, mas apenas uma vez aplicado ao gr√°fico.  A imagem tamb√©m demonstra a variedade de formas de camadas convolucionais, uma vez que cada uma delas possui um gr√°fico constru√≠do de acordo com a forma natural de c√°lculo. <br><br>  O mecanismo cria e controla a execu√ß√£o de um modelo de aprendizado de m√°quina usando um gr√°fico criado pelo compilador.  Uma vez implantado, o Graph Engine monitora e responde a IPUs ou dispositivos usados ‚Äã‚Äãpelos aplicativos. <br><br>  Image ResNet-50 mostra o modelo inteiro.  Nesse n√≠vel, √© dif√≠cil distinguir entre v√©rtices individuais, portanto, voc√™ deve observar imagens ampliadas.  A seguir est√£o alguns exemplos de se√ß√µes dentro de camadas de uma rede neural. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/dbf/166/408/dbf166408a0b1626a4bd720e1be1dbe9.jpg" alt="imagem"><br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/d69/9c1/fb6/d699c1fb6f2e43b9f4d03b405c543186.jpg" alt="imagem"><br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/802/6f4/eab/8026f4eab4ee028d6894159b00421c56.jpg" alt="imagem"><br><br><h3>  Por que redes profundas precisam de tanta mem√≥ria? </h3><br>  Grandes quantidades de mem√≥ria ocupada s√£o um dos maiores problemas das redes neurais profundas.  Os pesquisadores est√£o tentando lidar com a largura de banda limitada dos dispositivos DRAM, que devem ser usados ‚Äã‚Äãpelos sistemas modernos para armazenar um grande n√∫mero de pesos e ativa√ß√µes em uma rede neural profunda. <br><br>  As arquiteturas foram desenvolvidas usando chips de processador projetados para processamento sequencial e otimiza√ß√£o de DRAM para mem√≥ria de alta densidade.  A interface entre os dois dispositivos √© um gargalo que introduz limita√ß√µes de largura de banda e adiciona uma sobrecarga significativa ao consumo de energia. <br><br>  Embora ainda n√£o tenhamos uma imagem completa do c√©rebro humano e como ele funciona, √© geralmente claro que n√£o h√° grandes instala√ß√µes de armazenamento separadas para a mem√≥ria.  Acredita-se que a fun√ß√£o da mem√≥ria de longo e curto prazo no c√©rebro humano esteja incorporada na estrutura dos neur√¥nios + sinapses.  Mesmo organismos simples como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vermes</a> com uma estrutura neural do c√©rebro, composta por pouco mais de 300 neur√¥nios, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">t√™m</a> algum grau de fun√ß√£o de mem√≥ria. <br><br>  Construir mem√≥ria em processadores convencionais √© uma maneira de contornar os gargalos de mem√≥ria, abrindo grande largura de banda com muito menos consumo de energia.  No entanto, a mem√≥ria em um chip √© uma coisa cara, que n√£o √© projetada para grandes quantidades de mem√≥ria, conectadas aos processadores centrais e gr√°ficos atualmente usados ‚Äã‚Äãpara a prepara√ß√£o e implanta√ß√£o de redes neurais profundas. <br><br>  Portanto, √© √∫til observar como a mem√≥ria √© usada hoje em unidades de processamento central e sistemas de aprendizado profundo em aceleradores gr√°ficos e se perguntar: por que eles precisam de dispositivos de armazenamento de mem√≥ria t√£o grandes quando o c√©rebro humano funciona bem sem eles? <br><br>  As redes neurais precisam de mem√≥ria para armazenar dados de entrada, par√¢metros de peso e fun√ß√µes de ativa√ß√£o, pois a entrada √© distribu√≠da pela rede.  No treinamento, a ativa√ß√£o na entrada deve ser preservada at√© que possa ser usada para calcular os erros dos gradientes na sa√≠da. <br><br>  Por exemplo, uma rede ResNet de 50 camadas possui cerca de 26 milh√µes de par√¢metros de pondera√ß√£o e calcula 16 milh√µes de ativa√ß√µes avan√ßadas.  Se voc√™ usar um n√∫mero de ponto flutuante de 32 bits para armazenar cada peso e ativa√ß√£o, isso exigir√° cerca de 168 MB de espa√ßo.  Usando um valor de precis√£o menor para armazenar essas escalas e ativa√ß√µes, poder√≠amos reduzir pela metade ou at√© quadruplicar esse requisito de armazenamento. <br><br>  Um s√©rio problema de mem√≥ria surge do fato de que as GPUs dependem de dados representados como vetores densos.  Portanto, eles podem usar um √∫nico fluxo de instru√ß√µes (SIMD) para obter computa√ß√£o de alta densidade.  O processador central usa blocos vetoriais semelhantes para computa√ß√£o de alto desempenho. <br><br>  Nas GPUs, a sinapse tem 1024 bits de largura e, portanto, eles usam dados de ponto flutuante de 32 bits; portanto, eles os dividem em minilotes paralelos de 32 amostras para criar vetores de dados de 1024 bits.  Essa abordagem para organizar o paralelismo vetorial aumenta em 32 vezes o n√∫mero de ativa√ß√µes e a necessidade de armazenamento local com capacidade superior a 2 GB. <br><br>  As GPUs e outras m√°quinas projetadas para √°lgebra matricial tamb√©m est√£o sujeitas √† carga de mem√≥ria dos pesos ou ativa√ß√µes da rede neural.  As GPUs n√£o podem executar com efici√™ncia pequenas convolu√ß√µes usadas em redes neurais profundas.  Portanto, uma transforma√ß√£o chamada ‚Äúdowngrade‚Äù √© usada para converter essas convolu√ß√µes em multiplica√ß√µes matriz-matriz (GEMMs), com as quais os aceleradores gr√°ficos podem lidar com efic√°cia. <br><br>  Tamb√©m √© necess√°ria mem√≥ria adicional para armazenar dados de entrada, valores de tempo e instru√ß√µes do programa.  A medi√ß√£o do uso de mem√≥ria ao treinar o ResNet-50 em uma GPU de alto desempenho mostrou que ele requer mais de 7,5 GB de DRAM local. <br><br>  Talvez algu√©m decida que uma menor precis√£o pode reduzir a quantidade de mem√≥ria necess√°ria, mas esse n√£o √© o caso.  Quando voc√™ muda os valores dos dados para a metade da precis√£o para pesos e ativa√ß√µes, preenche apenas metade da largura do vetor do SIMD, gastando metade dos recursos de computa√ß√£o dispon√≠veis.  Para compensar isso, quando voc√™ muda de precis√£o total para meia precis√£o na GPU, precisar√° dobrar o tamanho do minilote para causar paralelismo de dados suficiente para usar todos os c√°lculos dispon√≠veis.  Assim, a transi√ß√£o para escalas e ativa√ß√µes de menor precis√£o na GPU ainda requer mais de 7,5 GB de mem√≥ria din√¢mica com acesso livre. <br><br>  Com tantos dados a serem armazenados, √© simplesmente imposs√≠vel encaixar tudo isso na GPU.  Em cada camada da rede neural convolucional, √© necess√°rio salvar o estado da DRAM externa, carregar a pr√≥xima camada de rede e depois carregar os dados no sistema.  Como resultado, a interface de mem√≥ria externa, j√° limitada pela largura de banda da mem√≥ria, sofre com a carga adicional de recarregar constantemente a balan√ßa, al√©m de salvar e recuperar fun√ß√µes de ativa√ß√£o.  Isso diminui significativamente o tempo de treinamento e aumenta significativamente o consumo de energia. <br><br>  Existem v√°rias solu√ß√µes para esse problema.  Primeiramente, opera√ß√µes como fun√ß√µes de ativa√ß√£o podem ser executadas ‚Äúno local‚Äù, permitindo que voc√™ substitua a entrada diretamente na sa√≠da.  Assim, a mem√≥ria existente pode ser reutilizada.  Em segundo lugar, a oportunidade de reutiliza√ß√£o da mem√≥ria pode ser obtida analisando a depend√™ncia de dados entre opera√ß√µes na rede e a distribui√ß√£o da mesma mem√≥ria para opera√ß√µes que n√£o est√£o sendo usadas no momento. <br><br>  A segunda abordagem √© especialmente eficaz quando toda a rede neural pode ser analisada no est√°gio de compila√ß√£o para criar uma mem√≥ria alocada fixa, uma vez que os custos de gerenciamento de mem√≥ria s√£o reduzidos a quase zero.  Descobriu-se que uma combina√ß√£o desses m√©todos reduz o uso de mem√≥ria da rede neural em duas a tr√™s vezes. <br>  Uma terceira abordagem significativa foi descoberta recentemente pela equipe do Baidu Deep Speech.  Eles aplicaram v√°rios m√©todos de economia de mem√≥ria para obter uma redu√ß√£o de 16 vezes no consumo de mem√≥ria pelas fun√ß√µes de ativa√ß√£o, o que lhes permitiu treinar redes com 100 camadas.  Anteriormente, com a mesma quantidade de mem√≥ria, eles podiam treinar redes com nove camadas. <br><br>  A combina√ß√£o de recursos de mem√≥ria e processamento em um dispositivo tem um potencial significativo para aumentar a produtividade e a efici√™ncia das redes neurais convolucionais, al√©m de outras formas de aprendizado de m√°quina.  Voc√™ pode fazer um compromisso entre os recursos de mem√≥ria e computa√ß√£o para equilibrar os recursos e o desempenho do sistema. <br><br>  Redes neurais e modelos de conhecimento em outros m√©todos de aprendizado de m√°quina podem ser considerados gr√°ficos matem√°ticos.  Nestes gr√°ficos, uma enorme quantidade de paralelismo est√° concentrada.  Um processador paralelo projetado para usar simultaneidade em gr√°ficos n√£o depende de minilote e pode reduzir significativamente a quantidade de armazenamento local necess√°rio. <br><br>  Resultados de pesquisas modernas mostraram que todos esses m√©todos podem melhorar significativamente o desempenho das redes neurais.  Os gr√°ficos modernos e as unidades de processamento central t√™m mem√≥ria interna muito limitada, apenas alguns megabytes no total.  As novas arquiteturas de processador projetadas especificamente para aprendizado de m√°quina fornecem um equil√≠brio entre a mem√≥ria e a computa√ß√£o no chip, proporcionando um aumento significativo no desempenho e na efici√™ncia em compara√ß√£o com as modernas unidades de processamento central e aceleradores gr√°ficos. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt402641/">https://habr.com/ru/post/pt402641/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt402629/index.html">Meus pequenos rel√©s: o computador Brainfuck √© m√°gico</a></li>
<li><a href="../pt402631/index.html">Qual monitor de freq√º√™ncia card√≠aca escolher na nova temporada: comprometer solu√ß√µes em tr√™s a quatro mil rublos</a></li>
<li><a href="../pt402633/index.html">O Tale of Battlefield 1 em Full HD nos gr√°ficos integrados no processador e na montagem do console para "imperec√≠vel"</a></li>
<li><a href="../pt402637/index.html">Estudante de 17 anos corrigiu erro da NASA</a></li>
<li><a href="../pt402639/index.html">Peter Watts sobre SOMA</a></li>
<li><a href="../pt402643/index.html">"Mundo magro". Cap√≠tulo 10</a></li>
<li><a href="../pt402645/index.html">Usando o programa ServoStudio 12 e a placa Arduino, voc√™ pode criar seu pr√≥prio rob√¥ sem escrever uma √∫nica linha de c√≥digo</a></li>
<li><a href="../pt402649/index.html">O mais preciso do mundo: monitores card√≠acos Valencell para Jabra, Suunto, Atlas, Sony e outros</a></li>
<li><a href="../pt402651/index.html">Implante de polietileno de alt√≠ssimo peso molecular substituiu tecido √≥sseo ou pol√≠mero de ferro</a></li>
<li><a href="../pt402653/index.html">Robomobiles t√™m problemas com ciclistas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≥üèº üö§ üíä Segmenta√ß√£o de imagens de sat√©lite usando o reconhecimento de √°rvores como exemplo üíø üèÄ ‚ö±Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O reconhecimento autom√°tico de imagens de sat√©lite ou a√©reas √© a maneira mais promissora de obter informa√ß√µes sobre a localiza√ß√£o de v√°rios objetos no...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Segmenta√ß√£o de imagens de sat√©lite usando o reconhecimento de √°rvores como exemplo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/421277/"><img src="https://habrastorage.org/webt/29/oa/ku/29oakuyg7l3gw-gqre-xvdxr3s0.jpeg" alt="imagem"><br><br>  O reconhecimento autom√°tico de imagens de sat√©lite ou a√©reas √© a maneira mais promissora de obter informa√ß√µes sobre a localiza√ß√£o de v√°rios objetos no solo.  A rejei√ß√£o da segmenta√ß√£o manual de imagens √© especialmente relevante quando se trata de processar grandes √°reas da superf√≠cie da Terra em pouco tempo. <br><br>  Recentemente, tive a oportunidade de aplicar habilidades te√≥ricas e me testar no campo de aprendizado de m√°quina em um projeto de segmenta√ß√£o de imagem real.  O objetivo do projeto √© o reconhecimento de √°reas florestais, nomeadamente copas de √°rvores em imagens de sat√©lite de alta resolu√ß√£o.  Sob o corte, vou compartilhar minha experi√™ncia e resultados. <br><a name="habracut"></a><br>  Quando se trata de processamento de imagem, a segmenta√ß√£o pode receber a seguinte defini√ß√£o - esta √© a presen√ßa na imagem de √°reas caracter√≠sticas que s√£o igualmente descritas neste espa√ßo de recursos. <br><br>  Distinga entre brilho, contorno, textura e segmenta√ß√£o sem√¢ntica. <br><br>  A segmenta√ß√£o de imagem sem√¢ntica (ou sem√¢ntica) √© para destacar √°reas na imagem, cada uma das quais corresponde a um atributo espec√≠fico.  Em termos gerais, os problemas de segmenta√ß√£o sem√¢ntica s√£o dif√≠ceis de algoritmos, de modo que redes neurais convolucionais que mostram bons resultados s√£o atualmente amplamente utilizadas para segmenta√ß√£o de imagens. <br><br><h3>  Declara√ß√£o do problema </h3><br>  O problema de segmenta√ß√£o bin√°ria est√° sendo resolvido - imagens coloridas (imagens de sat√©lite de alta resolu√ß√£o) s√£o alimentadas na entrada da rede neural, na qual √© necess√°rio destacar as √°reas de pixels pertencentes √† mesma classe - √°rvores. <br><br><h3>  Dados de origem </h3><br>  √Ä minha disposi√ß√£o, havia um conjunto de ladrilhos de imagens de sat√©lite de uma √°rea retangular na qual o pol√≠gono se encaixa.  Dentro dela, e voc√™ precisa procurar por √°rvores.  O pol√≠gono ou multipol√≠gono √© apresentado como um arquivo GeoJSON.  No meu caso, os ladrilhos estavam no formato png do tamanho 256 por 256 pixels na cor verdadeira.  (infelizmente, sem IR) Numera√ß√£o de blocos no formato /zoom/x/y.png. <br><br>  √â garantido que todos os ladrilhos do conjunto sejam obtidos a partir de imagens de sat√©lite tiradas aproximadamente na mesma √©poca do ano (final da primavera - in√≠cio do outono, dependendo do clima de uma regi√£o espec√≠fica) e um dia em um √¢ngulo semelhante √† superf√≠cie, onde uma leve cobertura de nuvens era permitida. <br><br><h3>  Prepara√ß√£o de dados </h3><br>  Como a √°rea do pol√≠gono desejado pode ser menor que essa √°rea retangular, a primeira coisa a fazer √© excluir os blocos que ultrapassam os limites do pol√≠gono.  Para isso, foi escrito um script simples que seleciona os blocos necess√°rios no pol√≠gono do arquivo GeoJSON.  Funciona da seguinte maneira.  Para come√ßar, as coordenadas de todos os v√©rtices do pol√≠gono s√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">convertidas</a> em n√∫meros de bloco e adicionadas a uma matriz.  H√° tamb√©m um deslocamento em rela√ß√£o √† origem.  Para inspe√ß√£o visual, √© gerada uma imagem em que um pixel √© igual a um bloco.  O pol√≠gono na imagem j√° est√° preenchido, levando em considera√ß√£o o deslocamento usando PIL.  Depois disso, a imagem √© transferida para uma matriz, de onde os blocos necess√°rios s√£o selecionados, que caem dentro do pol√≠gono. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image, ImageDraw <span class="hljs-comment"><span class="hljs-comment"># . . . #             . img = Image.new("L", (x, y), 0) draw = ImageDraw.Draw(img) #    .     . points ‚Äî  . draw.polygon(points, fill=255) img.show() mask = numpy.array(img) # . . .</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/-m/mk/ai/-mmkai6lmgfie8hnipom9rgjvxk.jpeg"><br>  <i>Resultado visual da convers√£o de um pol√≠gono em um conjunto de blocos</i> <br><br><h3>  Modelo de rede </h3><br>  Para resolver os problemas de segmenta√ß√£o de imagens, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">existem</a> v√°rios modelos de redes neurais convolucionais.  Decidi usar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">U-Net</a> , que se provou nas tarefas de segmenta√ß√£o de imagens bin√°rias.  A arquitetura U-Net consiste nos chamados caminhos contratantes e expansivos, que s√£o conectados por probros nos est√°gios de tamanho apropriado, e primeiro reduzem a resolu√ß√£o da imagem e aumentam, combinando-a previamente com os dados da imagem e passando por outras camadas convolu√ß√£o.  Assim, a rede atua como uma esp√©cie de filtro.  Os blocos de compress√£o e descompress√£o s√£o apresentados como um conjunto de blocos de uma determinada dimens√£o.  E cada bloco consiste em opera√ß√µes b√°sicas: convolu√ß√£o, ReLu e pool m√°ximo.  Existem implementa√ß√µes do modelo U-Net no Keras, Tensorflow, Caffe e PyTorch.  Eu usei Keras. <br><br><h3>  Criando um conjunto de treinamento </h3><br>  Para aprender este modelo Unet, voc√™ precisa de imagens.  A primeira coisa na minha cabe√ßa surgiu com a ideia de pegar os dados do OpenStreetMap e gerar m√°scaras para treinamento com base neles.  Mas, como aconteceu no meu caso, a precis√£o dos pol√≠gonos de que preciso deixa muito a desejar.  Eu tamb√©m precisava da presen√ßa de √°rvores √∫nicas, que nem sempre s√£o mapeadas.  Portanto, tive que abandonar esse compromisso.  Mas vale a pena dizer que, para outros objetos, como estradas ou edif√≠cios, essa abordagem pode ser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">eficaz</a> . <br><br><img src="https://habrastorage.org/webt/rc/po/v0/rcpov0qaluuosozh7isz8z-ya1y.png"><br><br>  Como a ideia de gerar automaticamente uma amostra de treinamento com base nos dados do OSM teve que ser abandonada, decidi marcar manualmente uma pequena √°rea.  Para fazer isso, usei o editor JOSM, onde utilizei imagens de terreno dispon√≠veis como substrato, que coloquei em um servidor local.  Em seguida, surgiu outro problema - n√£o encontrei a oportunidade de ativar a exibi√ß√£o da grade de blocos usando ferramentas JOSM regulares.  Portanto, algumas linhas simples no arquivo .htaccess no mesmo servidor de um diret√≥rio diferente come√ßaram a emitir um bloco vazio com uma borda de pixel para qualquer solicita√ß√£o do formul√°rio grid_tile / z / x / y.png e adicionaram uma camada improvisada ao JOSM.  Que bicicleta. <br><br><img src="https://habrastorage.org/webt/xe/ir/za/xeirzah3mp-kqtbpp0vvayzxhyi.png"><br><br>  Primeiro, marquei cerca de 30 pe√ßas.  Com uma mesa digitalizadora e o "modo de desenho r√°pido" no JOSM, n√£o demorou muito tempo.  Entendi que essa quantidade n√£o √© suficiente para o treinamento completo, mas decidi come√ßar com isso.  Al√©m disso, o treinamento em tantos dados ser√° r√°pido o suficiente. <br><br><h3>  Treinamento e primeiro resultado </h3><br>  A rede foi treinada por 15 √©pocas sem aumento pr√©vio de dados.  O gr√°fico mostra os valores de perdas e precis√£o na amostra de teste: <br><br><img src="https://habrastorage.org/webt/ln/h-/pk/lnh-pkjwqz-eziqh4gafem781og.png"><br><br>  O resultado do reconhecimento de imagens que n√£o estavam no treinamento nem na amostra de teste mostrou-se bastante sensato: <br><br> <a href=""><img src="https://habrastorage.org/webt/ao/kr/ed/aokredzarfej2cczep8ir7facx4.png"></a> <br><br>  Ap√≥s um estudo mais aprofundado dos resultados, alguns problemas ficaram claros.  Muitas falhas ocorreram nas √°reas sombreadas das imagens - a rede encontrou √°rvores na sombra onde n√£o estavam, ou exatamente o oposto.  Isso era esperado, pois havia poucos exemplos no conjunto de treinamento.  Mas eu n√£o esperava que alguns peda√ßos da superf√≠cie da √°gua e telhados escuros do perfil de metal (presumivelmente) fossem reconhecidos como √°rvores.  Tamb√©m houve imprecis√µes nos gramados.  Decidiu-se melhorar a amostra adicionando um n√∫mero maior de imagens com se√ß√µes controversas, assim a amostra de treinamento quase dobrou. <br><br><h3>  Aumento de Dados </h3><br>  Para aumentar ainda mais a quantidade de dados, decidi girar a imagem em um √¢ngulo arbitr√°rio.  Primeiro de tudo, tentei o m√≥dulo padr√£o keras.preprocessing.image.ImageDataGenerator.  Quando voc√™ gira enquanto preserva a escala, as √°reas vazias permanecem nas bordas das imagens, cujo preenchimento √© definido pelo par√¢metro <i>fill_mode</i> .  Voc√™ pode simplesmente preencher essas √°reas com cores especificando-as em <i>cval</i> , mas eu queria uma volta completa, esperando que a sele√ß√£o fosse mais completa, e eu mesmo implementei o gerador.  Isso permitiu aumentar o tamanho em mais de dez vezes. <br><br><img src="https://habrastorage.org/webt/oa/i9/hr/oai9hrvaxhigjgwp5xatijyht5u.png"><br>  <i>fill_mode = mais pr√≥ximo</i> <br><br>  Meu gerador de dados cola quatro blocos vizinhos em um √∫nico bloco de origem de 512x512 px.  O √¢ngulo de rota√ß√£o √© escolhido aleatoriamente, levando em considera√ß√£o que os intervalos permitidos de xey s√£o calculados para o centro do bloco resultante, no qual ele n√£o vai al√©m do bloco original.  As coordenadas do centro s√£o escolhidas aleatoriamente, levando em considera√ß√£o os intervalos permitidos.  Obviamente, todas essas transforma√ß√µes se aplicam ao par de m√°scaras de lado a lado.  Tudo isso √© repetido para v√°rios grupos de pe√ßas vizinhas.  De um grupo, voc√™ pode obter mais de uma d√∫zia de pe√ßas com diferentes se√ß√µes do terreno giradas em diferentes √¢ngulos. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       # image ‚Äî  , center (x, y) ‚Äî   , a ‚Äî   , width  height ‚Äî   . shape = image.shape[:2] matrix = cv2.getRotationMatrix2D( center=center, angle=a, scale=1 ) image = cv2.warpAffine( src=image, M=matrix, dsize=shape ) x = int( center[0] - width/2 ) y = int( center[1] - height/2 ) image = image[ y:y+height, x:x+width ] # </span></span></code> </pre><br><img src="https://habrastorage.org/webt/zy/mo/po/zymopoykrdt5ezki8ojru1te-di.png"><br>  <i>Um exemplo do resultado do gerador</i> <br><br><h3>  Aprendendo com mais dados </h3><br>  Como resultado, o tamanho da amostra de treinamento foi de 1881 imagens, tamb√©m aumentei o n√∫mero de eras para 30: <br><br><img src="https://habrastorage.org/webt/yh/ja/k9/yhjak9qcoyqb1lr64hhbet9d8sc.png"><br><br>  Ap√≥s treinar o modelo em um novo volume de dados, n√£o foram mais detectados problemas com segmenta√ß√£o incorreta de telhados e √°gua.  N√£o era poss√≠vel se livrar dos erros na sombra, mas eles se tornaram menos visuais, assim como erros nos gramados.  Deve-se notar que, em geral, a grande maioria dos erros √© que a rede v√™ √°rvores onde elas n√£o est√£o e n√£o vice-versa.  A precis√£o alcan√ßada pode ser melhorada usando imagens de sat√©lite com um grande n√∫mero de canais e modificando a arquitetura da rede para uma tarefa espec√≠fica. <br><br><img src="https://habrastorage.org/webt/er/i-/bk/eri-bkryiex4pidpmej4ybr_hyk.png"><br><br>  Em geral, fiquei satisfeito com o resultado do trabalho realizado e o prot√≥tipo de rede treinado foi aplicado para resolver problemas reais.  Por exemplo, calcular a densidade da floresta fica em Moscou: <br><br> <a href=""><img src="https://habrastorage.org/webt/3_/7a/dr/3_7adrfwb3ouixjq35wtn2lim7c.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt421277/">https://habr.com/ru/post/pt421277/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt421265/index.html">Monstros ap√≥s as f√©rias: AMD Threadripper 2990WX 32-Core e 2950X 16-Core (parte 2)</a></li>
<li><a href="../pt421267/index.html">Refrigera√ß√£o semi-passiva da fonte de alimenta√ß√£o do computador</a></li>
<li><a href="../pt421269/index.html">O sistema de reconhecimento facial instalado no aeroporto americano ajudou a capturar o atacante</a></li>
<li><a href="../pt421271/index.html">Uma sele√ß√£o de materiais √∫teis no Azure. Parte 2 - cursos</a></li>
<li><a href="../pt421275/index.html">O que eu entendi depois de vender duas startups em 12 meses</a></li>
<li><a href="../pt421279/index.html">Software de seguran√ßa adicional para NAS</a></li>
<li><a href="../pt421281/index.html">Respostas do suporte t√©cnico da 3CX: instala√ß√£o do seu pr√≥prio logotipo no visor do telefone IP</a></li>
<li><a href="../pt421283/index.html">O livro sobre "Par√°grafo" em Habr√©. Cap√≠tulo Um: O Cientista Watchman</a></li>
<li><a href="../pt421285/index.html">Rastreadores √≥pticos: ASEF e MOSSE</a></li>
<li><a href="../pt421287/index.html">Tijolos da lua de um forno solar</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
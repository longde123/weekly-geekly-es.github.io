<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ üßòüèæ üí© RabbitMQ vs. Kafka: Failover und Hochverf√ºgbarkeit in Clustern üö† üéà ü§¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fehlertoleranz und hohe Verf√ºgbarkeit sind gro√üe Themen, daher werden RabbitMQ und Kafka separate Artikel widmen. In diesem Artikel geht es um RabbitM...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ vs. Kafka: Failover und Hochverf√ºgbarkeit in Clustern</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/471858/"><img src="https://habrastorage.org/webt/hr/j2/oy/hrj2oyxwqv8-wo-vpmagx_dwmia.jpeg"><br><br>  Fehlertoleranz und hohe Verf√ºgbarkeit sind gro√üe Themen, daher werden RabbitMQ und Kafka separate Artikel widmen.  In diesem Artikel geht es um RabbitMQ, und im n√§chsten geht es um Kafka im Vergleich zu RabbitMQ.  Der Artikel ist lang, machen Sie es sich also bequem. <br><br>  Ber√ºcksichtigen Sie die Strategien f√ºr Fehlertoleranz, Konsistenz und Hochverf√ºgbarkeit (HA) sowie die Kompromisse, die jede Strategie eingehen muss.  RabbitMQ kann auf einem Cluster von Knoten ausgef√ºhrt werden - und wird dann als verteiltes System klassifiziert.  Wenn es um verteilte Systeme geht, sprechen wir oft √ºber Konsistenz und Zug√§nglichkeit. <br><br>  Diese Konzepte beschreiben, wie sich das System im Fehlerfall verh√§lt.  Netzwerkverbindungsfehler, Serverfehler, Festplattenfehler, vor√ºbergehende Nichtverf√ºgbarkeit des Servers aufgrund von Speicherbereinigung, Paketverlust oder Verlangsamung der Netzwerkverbindung.  All dies kann zu Datenverlust oder Konflikten f√ºhren.  Es stellt sich heraus, dass es fast unm√∂glich ist, ein System zu erstellen, das sowohl vollst√§ndig konsistent (ohne Datenverlust, ohne Datenunterschiede) als auch zug√§nglich (es akzeptiert Lese- und Schreibvorg√§nge) f√ºr alle Arten von Fehlern ist. <br><a name="habracut"></a><br>  Wir werden sehen, dass Konsistenz und Zug√§nglichkeit an verschiedenen Enden des Spektrums liegen und Sie m√ºssen entscheiden, wie Sie optimieren m√∂chten.  Die gute Nachricht ist, dass mit RabbitMQ eine solche Wahl m√∂glich ist.  Sie haben eine Art "Nerd" -Hebel, um das Gleichgewicht in Richtung gr√∂√üerer Koh√§renz oder besserer Zug√§nglichkeit zu verschieben. <br><br>  Wir werden besonders darauf achten, welche Konfigurationen aufgrund best√§tigter Aufzeichnungen zu Datenverlust f√ºhren.  Zwischen Verlagen, Maklern und Verbrauchern besteht eine Verantwortungskette.  Nachdem die Nachricht an den Broker gesendet wurde, ist es seine Aufgabe, die Nachricht nicht zu verlieren.  Wenn der Broker dem Herausgeber den Empfang der Nachricht best√§tigt, erwarten wir nicht, dass diese verloren geht.  Wir werden jedoch feststellen, dass dies je nach Konfiguration Ihres Brokers und Publishers tats√§chlich passieren kann. <br><br><h1>  Die Grundelemente der Stabilit√§t eines Knotens </h1><br><h3>  Anhaltende Warteschlangen / Routing </h3><br>  In RabbitMQ gibt es zwei Arten von Warteschlangen: dauerhaft / nicht dauerhaft.  Alle Warteschlangen werden in der Mnesia-Datenbank gespeichert.  Permanente Warteschlangen werden beim Start des Knotens erneut deklariert und √ºberleben somit einen Neustart, einen Systemabsturz oder einen Serverabsturz (solange die Daten gespeichert sind).  Dies bedeutet, dass w√§hrend Sie das Routing (Austausch) und die Warteschlange als ausfallsicher deklarieren, die Infrastruktur der Warteschlangen / des Routings online zur√ºckkehrt. <br><br>  Fl√ºchtige Warteschlangen und Routing werden beim Neustart des Hosts gel√∂scht. <br><br><h3>  Permanente Nachrichten </h3><br>  Nur weil die Warteschlange lang ist, bedeutet dies nicht, dass alle Nachrichten einen Neustart des Knotens √ºberleben.  Es werden nur Nachrichten wiederhergestellt, die vom Herausgeber als dauerhaft festgelegt wurden.  Persistente Nachrichten stellen eine zus√§tzliche Belastung f√ºr den Broker dar. Wenn der Verlust von Nachrichten jedoch nicht akzeptabel ist, gibt es keinen anderen Weg. <br><br><img src="https://habrastorage.org/webt/hl/nv/gv/hlnvgvt20t-fbikkajwnkirflyo.png"><br>  <i>Abb.</i>  <i>1. Stabilit√§tsmatrix</i> <br><br><h1>  Queue Mirroring Clustering </h1><br>  Um den Verlust eines Maklers zu √ºberleben, brauchen wir Redundanz.  Wir k√∂nnen mehrere RabbitMQ-Knoten zu einem Cluster kombinieren und dann zus√§tzliche Redundanz hinzuf√ºgen, indem wir die Warteschlangen zwischen mehreren Knoten replizieren.  Wenn also ein Knoten ausf√§llt, verlieren wir keine Daten und bleiben verf√ºgbar. <br><br>  Warteschlangenspiegelung: <br><br><ul><li>  eine Hauptwarteschlange (Master), die alle Schreib- und Lesebefehle empf√§ngt <br></li><li>  ein oder mehrere Spiegel, die alle Nachrichten und Metadaten aus der Hauptwarteschlange empfangen.  Diese Spiegel existieren nicht zur Skalierung, sondern nur zur Redundanz. </li></ul><br><img src="https://habrastorage.org/webt/am/-b/ol/am-boljly334-fiqfajsoowe3iu.png"><br>  <i>Abb.</i>  <i>2. Spiegeln der Warteschlange</i> <br><br>  Die Spiegelung wird durch die entsprechende Richtlinie festgelegt.  Darin k√∂nnen Sie die Replikationsrate und sogar die Knoten ausw√§hlen, auf denen die Warteschlange platziert werden soll.  Beispiele: <br><br><ul><li><code>ha-mode: all</code> <br> </li><li>  <code>ha-mode: exactly, ha-params: 2</code> (ein Master und ein Spiegel) <br></li><li> <code>ha-mode: nodes, ha-params: rabbit@node1, rabbit@node2</code> </li> </ul><br><h1>  Best√§tigung an den Verlag </h1><br>  Um eine sequentielle Aufzeichnung zu erreichen, muss Publisher Confirms best√§tigt werden.  Ohne sie besteht die M√∂glichkeit, dass Nachrichten verloren gehen.  Nach dem Schreiben der Nachricht auf die Festplatte wird eine Best√§tigung an den Herausgeber gesendet.  RabbitMQ schreibt Nachrichten nicht nach Erhalt, sondern in regelm√§√üigen Abst√§nden im Bereich von mehreren hundert Millisekunden auf die Festplatte.  Wenn die Warteschlange gespiegelt wird, wird die Best√§tigung erst gesendet, nachdem alle Spiegel auch ihre Kopie der Nachricht auf die Festplatte geschrieben haben.  Dies bedeutet, dass die Verwendung von Best√§tigungen die Verz√∂gerung erh√∂ht. Wenn jedoch die Datensicherheit wichtig ist, sind sie erforderlich. <br><br><h1>  Failover-Warteschlange </h1><br>  Wenn der Broker heruntergefahren wird oder abst√ºrzt, fallen alle f√ºhrenden Warteschlangen (Master) auf diesem Knoten damit ab.  Der Cluster w√§hlt dann den √§ltesten Spiegel jedes Masters aus und bef√∂rdert ihn als neuen Master. <br><br><img src="https://habrastorage.org/webt/pq/v_/_a/pqv__ahffpye5i6h_2pdzozyrgi.png"><br>  <i>Abb.</i>  <i>3. Mehrere gespiegelte Warteschlangen und ihre Richtlinien</i> <br><br>  Broker 3 Tropfen.  Beachten Sie, dass der Spiegel von Warteschlange C in Broker 2 auf einen Master aktualisiert wird.  Beachten Sie auch, dass f√ºr Warteschlange C in Broker 1 ein neuer Spiegel erstellt wurde. RabbitMQ versucht immer, die in Ihren Richtlinien angegebene Replikationsrate beizubehalten. <br><br><img src="https://habrastorage.org/webt/df/e7/la/dfe7laf8pyg0pobmrkgteky-wsw.png"><br>  <i>Abb.</i>  <i>4. Broker 3 f√§llt ab und Warteschlange C schl√§gt fehl</i> <br><br>  Der n√§chste Broker 1 f√§llt!  Wir haben nur noch einen Broker.  Der Spiegel von Warteschlange B erhebt sich zum Master. <br><br><img src="https://habrastorage.org/webt/b2/bd/qi/b2bdqi_lz21qoe8hcdmsjy8g5kc.png"><br>  <i>Abb.</i>  <i>5</i> <br><br>  Wir haben Broker 1 zur√ºckgegeben. Unabh√§ngig davon, wie erfolgreich die Daten den Verlust und die Wiederherstellung des Brokers √ºberstanden haben, werden alle gespiegelten Warteschlangennachrichten beim Neustart verworfen.  Dies ist wichtig zu beachten, da dies Konsequenzen haben wird.  Wir werden diese Konsequenzen bald ber√ºcksichtigen.  Somit ist Broker 1 jetzt wieder Mitglied des Clusters, und der Cluster versucht, die Richtlinien einzuhalten, und erstellt daher Spiegel f√ºr Broker 1. <br><br>  In diesem Fall war der Verlust von Broker 1 sowie der Daten vollst√§ndig, sodass die nicht spiegelnde Warteschlange D vollst√§ndig verloren ging. <br><br><img src="https://habrastorage.org/webt/wi/ql/68/wiql68dzsoerzuibhspllun85ec.png"><br>  <i>Abb.</i>  <i>6. Broker 1 ist wieder in Betrieb</i> <br><br>  Broker 3 ist wieder online, sodass in den Zeilen A und B Spiegel erstellt werden, die ihren HA-Richtlinien entsprechen.  Aber jetzt sind alle Hauptleitungen auf einem Knoten!  Dies ist nicht ideal, eine gleichm√§√üige Verteilung zwischen den Knoten ist besser.  Leider gibt es keine besonderen M√∂glichkeiten, um die Meister wieder ins Gleichgewicht zu bringen.  Wir werden sp√§ter auf dieses Problem zur√ºckkommen, da wir zuerst die Warteschlangensynchronisation in Betracht ziehen m√ºssen. <br><br><img src="https://habrastorage.org/webt/bg/hj/4n/bghj4n6pdd5ki4oideq7zbwmasi.png"><br>  <i>Abb.</i>  <i>7. Broker 3 ist wieder in Betrieb.</i>  <i>Alle Hauptwarteschlangen auf einem Knoten!</i> <br><br>  Daher sollten Sie jetzt eine Vorstellung davon haben, wie Spiegel Redundanz und Fehlertoleranz bieten.  Dies stellt die Verf√ºgbarkeit bei einem Ausfall eines einzelnen Knotens sicher und sch√ºtzt vor Datenverlust.  Aber wir sind noch nicht fertig, denn in Wirklichkeit ist alles viel komplizierter. <br><br><h1>  Synchronisieren </h1><br>  Beim Erstellen eines neuen Spiegels werden alle neuen Nachrichten immer auf diesen und alle anderen Spiegel repliziert.  Die vorhandenen Daten in der Hauptwarteschlange k√∂nnen in einem neuen Spiegel repliziert werden, der zu einer vollst√§ndigen Kopie des Masters wird.  Wir k√∂nnen auch vorhandene Nachrichten nicht replizieren und zulassen, dass die Hauptwarteschlange und der neue Spiegel rechtzeitig zusammenlaufen, wenn neue Nachrichten am Ende ankommen und vorhandene Nachrichten den Kopf der Hauptwarteschlange verlassen. <br><br>  Diese Synchronisation wird automatisch oder manuell durchgef√ºhrt und √ºber eine Warteschlangenrichtlinie gesteuert.  Betrachten Sie ein Beispiel. <br><br>  Wir haben zwei gespiegelte Linien.  Warteschlange A wird automatisch und Warteschlange B manuell synchronisiert.  Beide Zeilen haben jeweils zehn Nachrichten. <br><br><img src="https://habrastorage.org/webt/vz/zm/5x/vzzm5x_2w3tphqi09kn6h_9_e1c.png"><br>  <i>Abb.</i>  <i>8. Zwei Warteschlangen mit unterschiedlichen Synchronisationsmodi</i> <br><br>  Jetzt verlieren wir Broker 3. <br><br><img src="https://habrastorage.org/webt/5x/wp/ki/5xwpki1aoj_-e1hdt0i-gswn-nu.png"><br>  <i>Abb.</i>  <i>9. Broker 3 fiel</i> <br><br>  Broker 3 ist wieder in Betrieb.  Der Cluster erstellt f√ºr jede Warteschlange auf dem neuen Knoten einen Spiegel und synchronisiert die neue Warteschlange A automatisch mit dem Master.  Der Spiegel der neuen Kurve B bleibt jedoch leer.  Somit haben wir eine vollst√§ndige Redundanz von Warteschlange A und nur einen Spiegel f√ºr die vorhandenen Nachrichten von Warteschlange B. <br><br><img src="https://habrastorage.org/webt/zo/hb/ha/zohbhaicbgsjdynexgjhuh70ujg.png"><br>  <i>Abb.</i>  <i>10. Der neue Spiegel von Warteschlange A empf√§ngt alle vorhandenen Nachrichten, der neue Spiegel von Warteschlange B jedoch nicht</i> <br><br>  Beide Leitungen erhalten zehn weitere Nachrichten.  Dann f√§llt Broker 2 aus und Warteschlange A wird auf den √§ltesten Spiegel zur√ºckgesetzt, der sich auf Broker 1 befindet. Im Falle eines Fehlers tritt kein Datenverlust auf.  Es gibt zwanzig Nachrichten in Warteschlange B im Assistenten und nur zehn im Spiegel, da diese Warteschlange die urspr√ºnglichen zehn Nachrichten nie repliziert hat. <br><br><img src="https://habrastorage.org/webt/yy/hc/sz/yyhcszfowfi6eiidhubgqfy1zry.png"><br>  <i>Abb.</i>  <i>11. Zeile A wird auf Broker 1 zur√ºckgesetzt, ohne dass Nachrichten verloren gehen</i> <br><br>  Beide Leitungen erhalten zehn weitere Nachrichten.  Broker 1 st√ºrzt jetzt ab. Warteschlange A wechselt problemlos zum Spiegel, ohne dass Nachrichten verloren gehen.  Warteschlange B hat jedoch Probleme.  An diesem Punkt k√∂nnen wir entweder die Zug√§nglichkeit oder die Konsistenz optimieren. <br><br>  Wenn wir die Zug√§nglichkeit optimieren m√∂chten, sollte die Richtlinie " <b><i>Ha-Promotion-on-Failure"</i></b> <b><i>immer festgelegt werden</i></b> .  Dies ist der Standardwert, sodass Sie die Richtlinie einfach weglassen k√∂nnen.  In diesem Fall erlauben wir tats√§chlich Fehler in nicht synchronisierten Spiegeln.  Dies f√ºhrt zu einem Nachrichtenverlust, die Warteschlange bleibt jedoch lesbar und beschreibbar. <br><br><img src="https://habrastorage.org/webt/4h/hv/_n/4hhv_n4seyvz33pq_sk3my2bnmk.png"><br>  <i>Abb.</i>  <i>12. Zeile A wird auf Broker 3 zur√ºckgesetzt, ohne dass Nachrichten verloren gehen.</i>  <i>Zeile B kehrt mit dem Verlust von zehn Nachrichten zu Broker 3 zur√ºck</i> <br><br>  Wir k√∂nnen <code>ha-promote-on-failure</code> auf " <code>when-synced</code> .  In diesem Fall wartet die Warteschlange, anstatt zum Spiegel zur√ºckzukehren, bis Broker 1 mit seinen Daten in den Online-Modus zur√ºckkehrt.  Nach seiner R√ºckkehr wird die Hauptwarteschlange erneut auf Broker 1 ohne Datenverlust angezeigt.  Die Zug√§nglichkeit wird f√ºr die Datensicherheit geopfert.  Dies ist jedoch ein riskanter Modus, der sogar zu einem vollst√§ndigen Datenverlust f√ºhren kann, den wir in naher Zukunft in Betracht ziehen werden. <br><br><img src="https://habrastorage.org/webt/fk/mx/gx/fkmxgxilgyi8bp_n_-osz6q8be0.png"><br>  <i>Abb.</i>  <i>13. Zeile B bleibt nach dem Verlust von Broker 1 nicht verf√ºgbar</i> <br><br>  M√∂glicherweise stellen Sie eine Frage: ‚ÄûVielleicht ist es besser, niemals die automatische Synchronisierung zu verwenden?‚Äú.  Die Antwort ist, dass die Synchronisation eine Blockierungsoperation ist.  W√§hrend der Synchronisation kann die Hauptwarteschlange keine Lese- oder Schreibvorg√§nge ausf√ºhren! <br><br>  Betrachten Sie ein Beispiel.  Jetzt haben wir sehr lange Schlangen.  Wie k√∂nnen sie auf diese Gr√∂√üe wachsen?  Aus mehreren Gr√ºnden: <br><br><ul><li>  Warteschlangen werden nicht aktiv verwendet. <br></li><li>  Dies sind Hochgeschwindigkeitsstrecken, und im Moment sind die Verbraucher langsam <br></li><li>  Dies sind Hochgeschwindigkeitswarteschlangen, ein Fehler ist aufgetreten und die Verbraucher holen auf </li></ul><br><img src="https://habrastorage.org/webt/es/6q/gy/es6qgy7p-1cu0avxb1xivijyjii.png"><br>  <i>Abb.</i>  <i>14. Zwei gro√üe Warteschlangen mit unterschiedlichen Synchronisationsmodi</i> <br><br>  Jetzt st√ºrzt Broker 3 ab. <br><br><img src="https://habrastorage.org/webt/vg/ta/ue/vgtauedea7kaitatv7oshzottps.png"><br>  <i>Abb.</i>  <i>15. Broker 3 f√§llt und hinterl√§sst einen Master und einen Spiegel in jeder Warteschlange</i> <br><br>  Broker 3 kehrt zur√ºck und es werden neue Spiegel erstellt.  Hauptwarteschlange A beginnt, vorhandene Nachrichten auf einen neuen Spiegel zu replizieren, und w√§hrend dieser Zeit ist Warteschlange A nicht verf√ºgbar.  Die Datenreplikation dauert zwei Stunden, was zu zwei Stunden Ausfallzeit f√ºr diese Warteschlange f√ºhrt! <br><br>  Linie B bleibt jedoch w√§hrend des gesamten Zeitraums verf√ºgbar.  Sie opferte einige Redundanz f√ºr die Zug√§nglichkeit. <br><br><img src="https://habrastorage.org/webt/qn/rd/ep/qnrdep5m7sszgxjesb_kfwuw-zw.png"><br>  <i>Abb.</i>  <i>16. Die Warteschlange bleibt w√§hrend der Synchronisierung nicht verf√ºgbar</i> <br><br>  Nach zwei Stunden ist auch Warteschlange A verf√ºgbar und akzeptiert m√∂glicherweise wieder Lese- und Schreibvorg√§nge. <br><br><h3>  Updates </h3><br>  Dieses Blockierungsverhalten w√§hrend der Synchronisation macht es schwierig, Cluster mit sehr gro√üen Warteschlangen zu aktualisieren.  Irgendwann muss der Knoten mit dem Assistenten neu gestartet werden. Dies bedeutet, dass Sie entweder zum Spiegel wechseln oder die Warteschlange w√§hrend der Serveraktualisierung deaktivieren m√ºssen.  Wenn wir einen √úbergang w√§hlen, verlieren wir Nachrichten, wenn die Spiegel nicht synchronisiert sind.  Wenn ein Broker deaktiviert ist, wird standardm√§√üig kein √úbergang zu einem nicht synchronisierten Spiegel durchgef√ºhrt.  Dies bedeutet, dass wir keine Nachrichten verlieren, sobald der Broker zur√ºckkehrt. Der einzige Schaden war nur eine einfache Warteschlange.  Das Deaktivieren von Brokern unterliegt der Richtlinie zum <code>ha-promote-on-shutdown</code> .  Sie k√∂nnen einen von zwei Werten festlegen: <br><br><ul><li>  <code>always</code> = Aktiviertes Umschalten auf nicht synchronisierte Spiegel <br></li><li>  <code>when-synced</code> = wechselt nur zum synchronisierten Spiegel, andernfalls kann auf die Warteschlange nicht mehr gelesen und geschrieben werden.  Die Warteschlange kehrt zur√ºck, sobald der Broker zur√ºckkehrt </li></ul><br>  Auf die eine oder andere Weise m√ºssen Sie bei gro√üen Warteschlangen zwischen Datenverlust und Unzug√§nglichkeit w√§hlen. <br><br><h3>  Wenn Verf√ºgbarkeit die Datensicherheit verbessert </h3><br>  Bevor eine Entscheidung getroffen wird, muss eine weitere Komplikation ber√ºcksichtigt werden.  W√§hrend die automatische Synchronisierung aus Redundanzgr√ºnden besser ist, wie wirkt sie sich auf die Datensicherheit aus?  Nat√ºrlich ist es dank der besseren Redundanz weniger wahrscheinlich, dass RabbitMQ vorhandene Nachrichten verliert, aber was ist mit neuen Nachrichten von Herausgebern? <br><br>  Hier m√ºssen Sie Folgendes ber√ºcksichtigen: <br><ul><li>  Kann ein Publisher nur einen Fehler zur√ºckgeben und ein h√∂herer Dienst oder Benutzer wird es sp√§ter erneut versuchen? <br></li><li>  Kann ein Herausgeber eine Nachricht lokal oder in einer Datenbank speichern, um sie sp√§ter erneut zu versuchen? </li></ul><br>  Wenn der Herausgeber die Nachricht nur l√∂schen kann, erh√∂ht eine Verbesserung der Barrierefreiheit auch die Datensicherheit. <br><br>  Daher m√ºssen Sie nach einem Gleichgewicht suchen, und die Entscheidung h√§ngt von der spezifischen Situation ab. <br><br><h1>  Probleme mit Ha-Promotion-on-Failure = bei Synchronisierung </h1><br>  Die Idee von <i><b>ha-f√∂rdern-bei-Fehler</b></i> = <i><b>bei Synchronisierung</b></i> ist, dass wir das Umschalten auf einen nicht synchronisierten Spiegel verhindern und somit Datenverlust vermeiden.  Die Warteschlange bleibt zum Lesen oder Schreiben unzug√§nglich.  Stattdessen versuchen wir, einen gefallenen Broker mit unbesch√§digten Daten zur√ºckzugeben, damit er ohne Datenverlust seine Arbeit als Master wieder aufnimmt. <br><br>  Aber (und das ist gro√ü, aber) wenn der Broker seine Daten verloren hat, haben wir ein gro√ües Problem: Die Warteschlange ist verloren!  Alle Daten sind weg!  Selbst wenn Sie Spiegel haben, die im Grunde die Hauptwarteschlange einholen, werden diese Spiegel ebenfalls verworfen. <br><br>  Um einen Knoten mit demselben Namen erneut hinzuzuf√ºgen, weisen Sie den Cluster an, den verlorenen Knoten (mit dem <i>Befehl rabbitmqctl compare_cluster_node</i> ) zu vergessen und einen neuen Broker mit demselben Hostnamen zu starten.  Solange sich der Cluster an den verlorenen Knoten erinnert, merkt er sich die alte Warteschlange und die nicht synchronisierten Spiegel.  Wenn ein Cluster angewiesen wird, einen verlorenen Knoten zu vergessen, wird auch diese Warteschlange vergessen.  Jetzt m√ºssen Sie es erneut deklarieren.  Wir haben alle Daten verloren, obwohl wir Spiegel mit einem Teildatensatz hatten.  Es w√§re besser, zu einem nicht synchronisierten Spiegel zu wechseln! <br><br>  Daher ist die manuelle Synchronisation (und der Synchronisationsfehler) in Kombination mit <code>ha-promote-on-failure=when-synced</code> meiner Meinung nach ziemlich riskant.  Dokumente sagen, dass diese Option f√ºr die Datensicherheit existiert, aber es ist ein zweischneidiges Messer. <br><br><h1>  Meister neu ausbalancieren </h1><br>  Wie versprochen kehren wir zum Problem der Akkumulation aller Master auf einem oder mehreren Knoten zur√ºck.  Dies kann auch aufgrund fortlaufender fortlaufender Cluster-Updates geschehen.  In einem Cluster mit drei Knoten werden alle Hauptwarteschlangen auf einem oder zwei Knoten angesammelt. <br><br>  Das Ausbalancieren von Mastern kann aus zwei Gr√ºnden problematisch sein: <br><br><ul><li>  Keine guten Ausgleichswerkzeuge </li><li>  Warteschlangensynchronisierung </li></ul><br>  F√ºr das Rebalancing gibt es ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Plugin</a> eines Drittanbieters, das nicht offiziell unterst√ºtzt wird.  In Bezug auf Plug-Ins von Drittanbietern hei√üt es im RabbitMQ-Handbuch: ‚ÄûDas Plug-In bietet einige zus√§tzliche Konfigurations- und Berichterstellungstools, wird jedoch vom RabbitMQ-Team nicht unterst√ºtzt und nicht getestet.  Die Verwendung erfolgt auf eigenes Risiko. ‚Äú <br><br>  Es gibt noch einen weiteren Trick, um die Hauptwarteschlange durch HA-Richtlinien zu verschieben.  Das Handbuch erw√§hnt hierf√ºr ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Skript</a> .  Es funktioniert wie folgt: <br><br><ul><li>  L√∂scht alle Spiegel mithilfe einer tempor√§ren Richtlinie mit einer h√∂heren Priorit√§t als die vorhandene HA-Richtlinie. <br></li><li>  √Ñndert die tempor√§re HA-Richtlinie so, dass der Knotenmodus mit dem Knoten verwendet wird, auf den die Hauptwarteschlange verschoben werden muss. <br></li><li>  Synchronisiert die Warteschlange f√ºr die erzwungene Migration. <br></li><li>  L√∂scht nach Abschluss der Migration die tempor√§re Richtlinie.  Die HA-Anfangsrichtlinie tritt in Kraft und die erforderliche Anzahl von Spiegeln wird erstellt. </li></ul><br>  Der Nachteil ist, dass dieser Ansatz m√∂glicherweise nicht funktioniert, wenn Sie gro√üe Warteschlangen oder strenge Redundanzanforderungen haben. <br><br>  Nun wollen wir sehen, wie RabbitMQ-Cluster mit Netzwerkpartitionen funktionieren. <br><br><h1>  Unterbrechung der Konnektivit√§t </h1><br>  Die Knoten eines verteilten Systems sind durch Netzwerkverbindungen verbunden, und Netzwerkverbindungen k√∂nnen und werden getrennt.  Die H√§ufigkeit von Ausf√§llen h√§ngt von der lokalen Infrastruktur oder der Zuverl√§ssigkeit der ausgew√§hlten Cloud ab.  In jedem Fall sollten verteilte Systeme in der Lage sein, damit umzugehen.  Wieder haben wir die Wahl zwischen Zug√§nglichkeit und Konsistenz, und wieder ist die gute Nachricht, dass RabbitMQ beides bietet (nur nicht gleichzeitig). <br><br>  Mit RabbitMQ haben wir zwei Hauptoptionen: <br><br><ul><li>  Erlaube logische Trennung (Split-Brain).  Dies bietet Zugriff, kann jedoch zu Datenverlust f√ºhren. <br></li><li>  Logische Trennung nicht zulassen.  Dies kann zu einem kurzfristigen Verlust der Verf√ºgbarkeit f√ºhren, je nachdem, wie Clients eine Verbindung zum Cluster herstellen.  Dies kann auch zu einer vollst√§ndigen Unzug√§nglichkeit in einem Cluster von zwei Knoten f√ºhren. </li></ul><br>  Aber was ist logische Trennung?  Dies ist der Fall, wenn ein Cluster aufgrund eines Verlusts der Netzwerkverbindungen in zwei Teile geteilt wird.  Auf jeder Seite erheben sich die Spiegel zum Meister, so dass sich am Ende in jeder Runde mehrere Meister befinden. <br><br><img src="https://habrastorage.org/webt/mi/4f/bb/mi4fbbuk9maj487alkqsbbykkns.png"><br>  <i>Abb.</i>  <i>17. Die Hauptleitung und zwei Spiegel, jeweils auf einem separaten Knoten.</i>  <i>Dann tritt ein Netzwerkfehler auf und ein Spiegel trennt sich.</i>  <i>Der abgetrennte Knoten sieht, dass die anderen beiden abgefallen sind, und schiebt seine Spiegel zum Master.</i>  <i>Jetzt haben wir zwei Hauptzeilen, und beide erlauben das Schreiben und Lesen.</i> <br><br>  Wenn Publisher Daten an beide Master senden, erhalten wir zwei unterschiedliche Kopien der Warteschlange. <br><br>  Die verschiedenen RabbitMQ-Modi bieten entweder Zug√§nglichkeit oder Konsistenz. <br><br><h3>  Ignoriermodus (Standard) </h3><br>  Dieser Modus bietet Barrierefreiheit.  Nach dem Verlust der Konnektivit√§t erfolgt eine logische Trennung.  Nach dem erneuten Herstellen der Verbindung muss der Administrator entscheiden, welche Partition er bevorzugen m√∂chte.  Die verlierende Seite wird neu gestartet und alle gesammelten Daten von dieser Seite gehen verloren. <br><br><img src="https://habrastorage.org/webt/ih/rj/ow/ihrjow-ceolx0wy8y2o-cn2yiuk.png"><br>  <i>Abb.</i>  <i>18. Drei Verlage sind drei Maklern zugeordnet.</i>  <i>Intern leitet der Cluster alle Anforderungen an die Hauptwarteschlange von Broker 2 weiter.</i> <br><br>  Jetzt verlieren wir Broker 3. Er sieht, dass andere Broker abgefallen sind und bewegt seinen Spiegel zum Master.  Dies ist die logische Trennung. <br><br><img src="https://habrastorage.org/webt/u_/l8/af/u_l8af-qqcyv4ldqdgwrn4t22ei.png"><br>  <i>Abb.</i>  <i>19. Logische Trennung (Split-Brain).</i>  <i>Die Aufzeichnungen bestehen aus zwei Hauptzeilen, und zwei Kopien weichen voneinander ab.</i> <br><br>  Die Konnektivit√§t wird wiederhergestellt, die logische Trennung bleibt jedoch bestehen.  Der Administrator muss die Verliererseite manuell ausw√§hlen.  Im folgenden Fall startet der Administrator Broker 3 neu. Alle Nachrichten, die er nicht √ºbertragen konnte, gehen verloren. <br><br><img src="https://habrastorage.org/webt/_o/a9/ft/_oa9ftbuvl6dwnewtgfkrhkyva4.png"><br>  <i>Abb.</i>  <i>20. Der Administrator deaktiviert Broker 3.</i> <br><br><img src="https://habrastorage.org/webt/ni/y_/xq/niy_xqsgzuvf5ktcta35z98zzxs.png"><br>  <i>Abb.</i>  <i>21. Der Administrator startet Broker 3 und tritt dem Cluster bei, wobei alle dort verbleibenden Nachrichten verloren gehen.</i> <br><br>  W√§hrend des Verbindungsverlusts und nach seiner Wiederherstellung standen der Cluster und diese Warteschlange zum Lesen und Schreiben zur Verf√ºgung. <br><br><h3>  Autoheal-Modus </h3><br>  Es funktioniert √§hnlich wie der Ignoriermodus, au√üer dass der Cluster selbst automatisch die verlierende Seite ausw√§hlt, nachdem die Konnektivit√§t aufgeteilt und wiederhergestellt wurde.  Die verlierende Seite kehrt leer zum Cluster zur√ºck, und die Warteschlange verliert alle Nachrichten, die nur an diese Seite gesendet wurden. <br><br><h3>  Minority-Modus anhalten </h3><br>  Wenn wir keine logische Trennung zulassen m√∂chten, besteht unsere einzige M√∂glichkeit darin, das Lesen und Schreiben auf der kleineren Seite nach der Partition des Clusters zu verweigern.  Wenn ein Broker sieht, dass er auf der geringeren Seite ist, h√§lt er inne, schlie√üt alle bestehenden Verbindungen und lehnt neue ab.  Einmal pro Sekunde wird nach einer erneuten Verbindung gesucht.  Sobald die Konnektivit√§t wiederhergestellt ist, wird die Arbeit wieder aufgenommen und dem Cluster beigetreten. <br><br><img src="https://habrastorage.org/webt/xl/cc/af/xlccafaylyx2nrsz5scaafo1h6u.png"><br>  <i>Abb.</i>  <i>22. Drei Verlage sind drei Maklern zugeordnet.</i>  <i>Intern leitet der Cluster alle Anforderungen an die Hauptwarteschlange von Broker 2 weiter.</i> <br><br>  Dann werden Broker 1 und 2 von Broker 3 getrennt. Anstatt ihren Spiegel auf einen Master zu aktualisieren, wird Broker 3 angehalten und ist nicht mehr zug√§nglich. <br><br><img src="https://habrastorage.org/webt/8h/0_/hc/8h0_hc8vj99u6zaht7cgymlckve.png"><br>  <i>Abb.</i>  <i>23. Broker 3 h√§lt an, trennt alle Clients und lehnt Verbindungsanforderungen ab.</i> <br><br>  Sobald die Konnektivit√§t wiederhergestellt ist, kehrt sie zum Cluster zur√ºck. <br><br>  Schauen wir uns ein anderes Beispiel an, in dem sich die Hauptzeile auf Broker 3 befindet. <br><br><img src="https://habrastorage.org/webt/rs/0s/if/rs0siffyxwpdc8imasvfvkapykw.png"><br>  <i>Abb.</i>  <i>24. Die Hauptlinie bei Broker 3.</i> <br><br>  Dann tritt der gleiche Konnektivit√§tsverlust auf.  Broker 3 pausiert, weil es kleiner ist.  Auf der anderen Seite sehen die Knoten, dass Broker 3 abgefallen ist, so dass der √§ltere Spiegel von Broker 1 und 2 zum Master aufsteigt. <br><br><img src="https://habrastorage.org/webt/ba/o3/gr/bao3gr7y31x5ljbbpkqkretaaty.png"><br>  <i>Abb.</i>  <i>25. √úbergang zu Broker 2, wenn Broker 3 nicht verf√ºgbar ist.</i> <br><br>  Wenn die Konnektivit√§t wiederhergestellt ist, tritt Broker 3 dem Cluster bei. <br><br><img src="https://habrastorage.org/webt/3z/rp/3k/3zrp3knvfoew7m25bg6bg4dlhju.png"><br>  <i>Abb.</i>  <i>26. Der Cluster kehrte zum normalen Betrieb zur√ºck.</i> <br><br>  Es ist wichtig zu verstehen, dass wir Konsistenz erhalten, aber wir k√∂nnen auch Zug√§nglichkeit erhalten, <i><b>wenn wir</b></i> Kunden erfolgreich auf den gr√∂√üten Teil des Abschnitts √ºbertragen.  In den meisten Situationen w√ºrde ich pers√∂nlich den Modus "Minderheit pausieren" w√§hlen, aber das h√§ngt wirklich vom jeweiligen Fall ab. <br><br>  Um die Verf√ºgbarkeit sicherzustellen, ist es wichtig sicherzustellen, dass Clients erfolgreich eine Verbindung zur Site herstellen.  Betrachten Sie unsere Optionen. <br><br><h1>  Kundenkonnektivit√§t </h1><br>  Wir haben verschiedene M√∂glichkeiten, wie Clients nach einem Verbindungsverlust an den Hauptteil des Clusters oder an Arbeitsknoten gesendet werden (nach einem Ausfall eines Knotens).  Erinnern wir uns zun√§chst daran, dass eine bestimmte Warteschlange auf einem bestimmten Host gehostet wird, Routing und Richtlinien jedoch auf allen Hosts repliziert werden.  Clients k√∂nnen eine Verbindung zu einem beliebigen Knoten herstellen, und das interne Routing leitet sie bei Bedarf weiter.  Wenn ein Knoten angehalten wird, wird die Verbindung abgelehnt, sodass Clients eine Verbindung zu einem anderen Knoten herstellen m√ºssen.  Wenn ein Knoten abf√§llt, kann er √ºberhaupt wenig tun. <br><br>  Unsere M√∂glichkeiten: <br><br><ul><li>  Der Zugriff auf den Cluster erfolgt √ºber einen Load Balancer, der einfach die Knoten durchl√§uft und Clients wiederholt versucht, eine Verbindung herzustellen, bis sie erfolgreich abgeschlossen wurden.      ,        ,        (  ).         ,    . <br></li><li>         /   ,    .    ,        ,     . <br></li><li>      ,          .       ,       ,   . <br></li><li>    /    DNS.      TTL. </li></ul><br><h1>  Schlussfolgerungen </h1><br>   RabbitMQ    .      , : <br><br><ul><li>        ; <br></li><li>      . </li></ul><br>         .   RabbitMQ      ,     .        ,     .         RabbitMQ        .      RabbitMQ     : <br><br><ul><li>  . <br></li><li>  . <br></li><li>   . </li></ul><br>      ,   : <br><br><ul><li> <code>ha-promote-on-failure=always</code> <br> </li><li> <code>ha-sync-mode=manual</code> <br> </li><li> <code>cluster_partition_handling=ignore</code> ( <code>autoheal</code> ) <br></li><li>   <br></li><li> ,      ,  -     </li></ul><br>   ( )   : <br><br><ul><li> Publisher Confirms  Manual Acknowledgements    <br></li><li> <code>ha-promote-on-failure=when-synced</code> ,              !   <code>=always</code> . <br></li><li> <code>ha-sync-mode=automatic</code> (        ;  , ,       ) <br></li><li>  Pause Minority <br></li><li>   </li></ul><br>          ; ,      (,   ).        Shovel. <br><br>    - , ,  . <br><br> .   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ,       RabbitMQ   Docker  Blockade,      ,    . <br><br>   : <br> ‚Ññ1 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">habr.com/ru/company/itsumma/blog/416629</a> <br> ‚Ññ2 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">habr.com/ru/company/itsumma/blog/418389</a> <br> ‚Ññ3 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">habr.com/ru/company/itsumma/blog/437446</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de471858/">https://habr.com/ru/post/de471858/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de471840/index.html">Warum zu Interviews gehen?</a></li>
<li><a href="../de471844/index.html">5 Gr√ºnde, EPAM INSIDER in Kasachstan zu besuchen</a></li>
<li><a href="../de471852/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 481 (10/01/2019 - 07/10/2019)</a></li>
<li><a href="../de471854/index.html">Hitzetod 5G</a></li>
<li><a href="../de471856/index.html">Wir l√∂sen alle 42 Versionen des Harry-Potter-Trank-Puzzles</a></li>
<li><a href="../de471860/index.html">Peg Parser</a></li>
<li><a href="../de471862/index.html">PEG-Parser-Implementierung</a></li>
<li><a href="../de471864/index.html">PEG-Parser-Generierung</a></li>
<li><a href="../de471866/index.html">PEG-Parser-Visualisierung</a></li>
<li><a href="../de471868/index.html">Genetik der Liebe: Konflikt zwischen den Geschlechtern als Grundlage f√ºr die Zusammenarbeit bei Paaren monogamer V√∂gel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
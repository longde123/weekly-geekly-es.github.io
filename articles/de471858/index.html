<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏾 🧘🏾 💩 RabbitMQ vs. Kafka: Failover und Hochverfügbarkeit in Clustern 🚠 🎈 🤬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fehlertoleranz und hohe Verfügbarkeit sind große Themen, daher werden RabbitMQ und Kafka separate Artikel widmen. In diesem Artikel geht es um RabbitM...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ vs. Kafka: Failover und Hochverfügbarkeit in Clustern</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/471858/"><img src="https://habrastorage.org/webt/hr/j2/oy/hrj2oyxwqv8-wo-vpmagx_dwmia.jpeg"><br><br>  Fehlertoleranz und hohe Verfügbarkeit sind große Themen, daher werden RabbitMQ und Kafka separate Artikel widmen.  In diesem Artikel geht es um RabbitMQ, und im nächsten geht es um Kafka im Vergleich zu RabbitMQ.  Der Artikel ist lang, machen Sie es sich also bequem. <br><br>  Berücksichtigen Sie die Strategien für Fehlertoleranz, Konsistenz und Hochverfügbarkeit (HA) sowie die Kompromisse, die jede Strategie eingehen muss.  RabbitMQ kann auf einem Cluster von Knoten ausgeführt werden - und wird dann als verteiltes System klassifiziert.  Wenn es um verteilte Systeme geht, sprechen wir oft über Konsistenz und Zugänglichkeit. <br><br>  Diese Konzepte beschreiben, wie sich das System im Fehlerfall verhält.  Netzwerkverbindungsfehler, Serverfehler, Festplattenfehler, vorübergehende Nichtverfügbarkeit des Servers aufgrund von Speicherbereinigung, Paketverlust oder Verlangsamung der Netzwerkverbindung.  All dies kann zu Datenverlust oder Konflikten führen.  Es stellt sich heraus, dass es fast unmöglich ist, ein System zu erstellen, das sowohl vollständig konsistent (ohne Datenverlust, ohne Datenunterschiede) als auch zugänglich (es akzeptiert Lese- und Schreibvorgänge) für alle Arten von Fehlern ist. <br><a name="habracut"></a><br>  Wir werden sehen, dass Konsistenz und Zugänglichkeit an verschiedenen Enden des Spektrums liegen und Sie müssen entscheiden, wie Sie optimieren möchten.  Die gute Nachricht ist, dass mit RabbitMQ eine solche Wahl möglich ist.  Sie haben eine Art "Nerd" -Hebel, um das Gleichgewicht in Richtung größerer Kohärenz oder besserer Zugänglichkeit zu verschieben. <br><br>  Wir werden besonders darauf achten, welche Konfigurationen aufgrund bestätigter Aufzeichnungen zu Datenverlust führen.  Zwischen Verlagen, Maklern und Verbrauchern besteht eine Verantwortungskette.  Nachdem die Nachricht an den Broker gesendet wurde, ist es seine Aufgabe, die Nachricht nicht zu verlieren.  Wenn der Broker dem Herausgeber den Empfang der Nachricht bestätigt, erwarten wir nicht, dass diese verloren geht.  Wir werden jedoch feststellen, dass dies je nach Konfiguration Ihres Brokers und Publishers tatsächlich passieren kann. <br><br><h1>  Die Grundelemente der Stabilität eines Knotens </h1><br><h3>  Anhaltende Warteschlangen / Routing </h3><br>  In RabbitMQ gibt es zwei Arten von Warteschlangen: dauerhaft / nicht dauerhaft.  Alle Warteschlangen werden in der Mnesia-Datenbank gespeichert.  Permanente Warteschlangen werden beim Start des Knotens erneut deklariert und überleben somit einen Neustart, einen Systemabsturz oder einen Serverabsturz (solange die Daten gespeichert sind).  Dies bedeutet, dass während Sie das Routing (Austausch) und die Warteschlange als ausfallsicher deklarieren, die Infrastruktur der Warteschlangen / des Routings online zurückkehrt. <br><br>  Flüchtige Warteschlangen und Routing werden beim Neustart des Hosts gelöscht. <br><br><h3>  Permanente Nachrichten </h3><br>  Nur weil die Warteschlange lang ist, bedeutet dies nicht, dass alle Nachrichten einen Neustart des Knotens überleben.  Es werden nur Nachrichten wiederhergestellt, die vom Herausgeber als dauerhaft festgelegt wurden.  Persistente Nachrichten stellen eine zusätzliche Belastung für den Broker dar. Wenn der Verlust von Nachrichten jedoch nicht akzeptabel ist, gibt es keinen anderen Weg. <br><br><img src="https://habrastorage.org/webt/hl/nv/gv/hlnvgvt20t-fbikkajwnkirflyo.png"><br>  <i>Abb.</i>  <i>1. Stabilitätsmatrix</i> <br><br><h1>  Queue Mirroring Clustering </h1><br>  Um den Verlust eines Maklers zu überleben, brauchen wir Redundanz.  Wir können mehrere RabbitMQ-Knoten zu einem Cluster kombinieren und dann zusätzliche Redundanz hinzufügen, indem wir die Warteschlangen zwischen mehreren Knoten replizieren.  Wenn also ein Knoten ausfällt, verlieren wir keine Daten und bleiben verfügbar. <br><br>  Warteschlangenspiegelung: <br><br><ul><li>  eine Hauptwarteschlange (Master), die alle Schreib- und Lesebefehle empfängt <br></li><li>  ein oder mehrere Spiegel, die alle Nachrichten und Metadaten aus der Hauptwarteschlange empfangen.  Diese Spiegel existieren nicht zur Skalierung, sondern nur zur Redundanz. </li></ul><br><img src="https://habrastorage.org/webt/am/-b/ol/am-boljly334-fiqfajsoowe3iu.png"><br>  <i>Abb.</i>  <i>2. Spiegeln der Warteschlange</i> <br><br>  Die Spiegelung wird durch die entsprechende Richtlinie festgelegt.  Darin können Sie die Replikationsrate und sogar die Knoten auswählen, auf denen die Warteschlange platziert werden soll.  Beispiele: <br><br><ul><li><code>ha-mode: all</code> <br> </li><li>  <code>ha-mode: exactly, ha-params: 2</code> (ein Master und ein Spiegel) <br></li><li> <code>ha-mode: nodes, ha-params: rabbit@node1, rabbit@node2</code> </li> </ul><br><h1>  Bestätigung an den Verlag </h1><br>  Um eine sequentielle Aufzeichnung zu erreichen, muss Publisher Confirms bestätigt werden.  Ohne sie besteht die Möglichkeit, dass Nachrichten verloren gehen.  Nach dem Schreiben der Nachricht auf die Festplatte wird eine Bestätigung an den Herausgeber gesendet.  RabbitMQ schreibt Nachrichten nicht nach Erhalt, sondern in regelmäßigen Abständen im Bereich von mehreren hundert Millisekunden auf die Festplatte.  Wenn die Warteschlange gespiegelt wird, wird die Bestätigung erst gesendet, nachdem alle Spiegel auch ihre Kopie der Nachricht auf die Festplatte geschrieben haben.  Dies bedeutet, dass die Verwendung von Bestätigungen die Verzögerung erhöht. Wenn jedoch die Datensicherheit wichtig ist, sind sie erforderlich. <br><br><h1>  Failover-Warteschlange </h1><br>  Wenn der Broker heruntergefahren wird oder abstürzt, fallen alle führenden Warteschlangen (Master) auf diesem Knoten damit ab.  Der Cluster wählt dann den ältesten Spiegel jedes Masters aus und befördert ihn als neuen Master. <br><br><img src="https://habrastorage.org/webt/pq/v_/_a/pqv__ahffpye5i6h_2pdzozyrgi.png"><br>  <i>Abb.</i>  <i>3. Mehrere gespiegelte Warteschlangen und ihre Richtlinien</i> <br><br>  Broker 3 Tropfen.  Beachten Sie, dass der Spiegel von Warteschlange C in Broker 2 auf einen Master aktualisiert wird.  Beachten Sie auch, dass für Warteschlange C in Broker 1 ein neuer Spiegel erstellt wurde. RabbitMQ versucht immer, die in Ihren Richtlinien angegebene Replikationsrate beizubehalten. <br><br><img src="https://habrastorage.org/webt/df/e7/la/dfe7laf8pyg0pobmrkgteky-wsw.png"><br>  <i>Abb.</i>  <i>4. Broker 3 fällt ab und Warteschlange C schlägt fehl</i> <br><br>  Der nächste Broker 1 fällt!  Wir haben nur noch einen Broker.  Der Spiegel von Warteschlange B erhebt sich zum Master. <br><br><img src="https://habrastorage.org/webt/b2/bd/qi/b2bdqi_lz21qoe8hcdmsjy8g5kc.png"><br>  <i>Abb.</i>  <i>5</i> <br><br>  Wir haben Broker 1 zurückgegeben. Unabhängig davon, wie erfolgreich die Daten den Verlust und die Wiederherstellung des Brokers überstanden haben, werden alle gespiegelten Warteschlangennachrichten beim Neustart verworfen.  Dies ist wichtig zu beachten, da dies Konsequenzen haben wird.  Wir werden diese Konsequenzen bald berücksichtigen.  Somit ist Broker 1 jetzt wieder Mitglied des Clusters, und der Cluster versucht, die Richtlinien einzuhalten, und erstellt daher Spiegel für Broker 1. <br><br>  In diesem Fall war der Verlust von Broker 1 sowie der Daten vollständig, sodass die nicht spiegelnde Warteschlange D vollständig verloren ging. <br><br><img src="https://habrastorage.org/webt/wi/ql/68/wiql68dzsoerzuibhspllun85ec.png"><br>  <i>Abb.</i>  <i>6. Broker 1 ist wieder in Betrieb</i> <br><br>  Broker 3 ist wieder online, sodass in den Zeilen A und B Spiegel erstellt werden, die ihren HA-Richtlinien entsprechen.  Aber jetzt sind alle Hauptleitungen auf einem Knoten!  Dies ist nicht ideal, eine gleichmäßige Verteilung zwischen den Knoten ist besser.  Leider gibt es keine besonderen Möglichkeiten, um die Meister wieder ins Gleichgewicht zu bringen.  Wir werden später auf dieses Problem zurückkommen, da wir zuerst die Warteschlangensynchronisation in Betracht ziehen müssen. <br><br><img src="https://habrastorage.org/webt/bg/hj/4n/bghj4n6pdd5ki4oideq7zbwmasi.png"><br>  <i>Abb.</i>  <i>7. Broker 3 ist wieder in Betrieb.</i>  <i>Alle Hauptwarteschlangen auf einem Knoten!</i> <br><br>  Daher sollten Sie jetzt eine Vorstellung davon haben, wie Spiegel Redundanz und Fehlertoleranz bieten.  Dies stellt die Verfügbarkeit bei einem Ausfall eines einzelnen Knotens sicher und schützt vor Datenverlust.  Aber wir sind noch nicht fertig, denn in Wirklichkeit ist alles viel komplizierter. <br><br><h1>  Synchronisieren </h1><br>  Beim Erstellen eines neuen Spiegels werden alle neuen Nachrichten immer auf diesen und alle anderen Spiegel repliziert.  Die vorhandenen Daten in der Hauptwarteschlange können in einem neuen Spiegel repliziert werden, der zu einer vollständigen Kopie des Masters wird.  Wir können auch vorhandene Nachrichten nicht replizieren und zulassen, dass die Hauptwarteschlange und der neue Spiegel rechtzeitig zusammenlaufen, wenn neue Nachrichten am Ende ankommen und vorhandene Nachrichten den Kopf der Hauptwarteschlange verlassen. <br><br>  Diese Synchronisation wird automatisch oder manuell durchgeführt und über eine Warteschlangenrichtlinie gesteuert.  Betrachten Sie ein Beispiel. <br><br>  Wir haben zwei gespiegelte Linien.  Warteschlange A wird automatisch und Warteschlange B manuell synchronisiert.  Beide Zeilen haben jeweils zehn Nachrichten. <br><br><img src="https://habrastorage.org/webt/vz/zm/5x/vzzm5x_2w3tphqi09kn6h_9_e1c.png"><br>  <i>Abb.</i>  <i>8. Zwei Warteschlangen mit unterschiedlichen Synchronisationsmodi</i> <br><br>  Jetzt verlieren wir Broker 3. <br><br><img src="https://habrastorage.org/webt/5x/wp/ki/5xwpki1aoj_-e1hdt0i-gswn-nu.png"><br>  <i>Abb.</i>  <i>9. Broker 3 fiel</i> <br><br>  Broker 3 ist wieder in Betrieb.  Der Cluster erstellt für jede Warteschlange auf dem neuen Knoten einen Spiegel und synchronisiert die neue Warteschlange A automatisch mit dem Master.  Der Spiegel der neuen Kurve B bleibt jedoch leer.  Somit haben wir eine vollständige Redundanz von Warteschlange A und nur einen Spiegel für die vorhandenen Nachrichten von Warteschlange B. <br><br><img src="https://habrastorage.org/webt/zo/hb/ha/zohbhaicbgsjdynexgjhuh70ujg.png"><br>  <i>Abb.</i>  <i>10. Der neue Spiegel von Warteschlange A empfängt alle vorhandenen Nachrichten, der neue Spiegel von Warteschlange B jedoch nicht</i> <br><br>  Beide Leitungen erhalten zehn weitere Nachrichten.  Dann fällt Broker 2 aus und Warteschlange A wird auf den ältesten Spiegel zurückgesetzt, der sich auf Broker 1 befindet. Im Falle eines Fehlers tritt kein Datenverlust auf.  Es gibt zwanzig Nachrichten in Warteschlange B im Assistenten und nur zehn im Spiegel, da diese Warteschlange die ursprünglichen zehn Nachrichten nie repliziert hat. <br><br><img src="https://habrastorage.org/webt/yy/hc/sz/yyhcszfowfi6eiidhubgqfy1zry.png"><br>  <i>Abb.</i>  <i>11. Zeile A wird auf Broker 1 zurückgesetzt, ohne dass Nachrichten verloren gehen</i> <br><br>  Beide Leitungen erhalten zehn weitere Nachrichten.  Broker 1 stürzt jetzt ab. Warteschlange A wechselt problemlos zum Spiegel, ohne dass Nachrichten verloren gehen.  Warteschlange B hat jedoch Probleme.  An diesem Punkt können wir entweder die Zugänglichkeit oder die Konsistenz optimieren. <br><br>  Wenn wir die Zugänglichkeit optimieren möchten, sollte die Richtlinie " <b><i>Ha-Promotion-on-Failure"</i></b> <b><i>immer festgelegt werden</i></b> .  Dies ist der Standardwert, sodass Sie die Richtlinie einfach weglassen können.  In diesem Fall erlauben wir tatsächlich Fehler in nicht synchronisierten Spiegeln.  Dies führt zu einem Nachrichtenverlust, die Warteschlange bleibt jedoch lesbar und beschreibbar. <br><br><img src="https://habrastorage.org/webt/4h/hv/_n/4hhv_n4seyvz33pq_sk3my2bnmk.png"><br>  <i>Abb.</i>  <i>12. Zeile A wird auf Broker 3 zurückgesetzt, ohne dass Nachrichten verloren gehen.</i>  <i>Zeile B kehrt mit dem Verlust von zehn Nachrichten zu Broker 3 zurück</i> <br><br>  Wir können <code>ha-promote-on-failure</code> auf " <code>when-synced</code> .  In diesem Fall wartet die Warteschlange, anstatt zum Spiegel zurückzukehren, bis Broker 1 mit seinen Daten in den Online-Modus zurückkehrt.  Nach seiner Rückkehr wird die Hauptwarteschlange erneut auf Broker 1 ohne Datenverlust angezeigt.  Die Zugänglichkeit wird für die Datensicherheit geopfert.  Dies ist jedoch ein riskanter Modus, der sogar zu einem vollständigen Datenverlust führen kann, den wir in naher Zukunft in Betracht ziehen werden. <br><br><img src="https://habrastorage.org/webt/fk/mx/gx/fkmxgxilgyi8bp_n_-osz6q8be0.png"><br>  <i>Abb.</i>  <i>13. Zeile B bleibt nach dem Verlust von Broker 1 nicht verfügbar</i> <br><br>  Möglicherweise stellen Sie eine Frage: „Vielleicht ist es besser, niemals die automatische Synchronisierung zu verwenden?“.  Die Antwort ist, dass die Synchronisation eine Blockierungsoperation ist.  Während der Synchronisation kann die Hauptwarteschlange keine Lese- oder Schreibvorgänge ausführen! <br><br>  Betrachten Sie ein Beispiel.  Jetzt haben wir sehr lange Schlangen.  Wie können sie auf diese Größe wachsen?  Aus mehreren Gründen: <br><br><ul><li>  Warteschlangen werden nicht aktiv verwendet. <br></li><li>  Dies sind Hochgeschwindigkeitsstrecken, und im Moment sind die Verbraucher langsam <br></li><li>  Dies sind Hochgeschwindigkeitswarteschlangen, ein Fehler ist aufgetreten und die Verbraucher holen auf </li></ul><br><img src="https://habrastorage.org/webt/es/6q/gy/es6qgy7p-1cu0avxb1xivijyjii.png"><br>  <i>Abb.</i>  <i>14. Zwei große Warteschlangen mit unterschiedlichen Synchronisationsmodi</i> <br><br>  Jetzt stürzt Broker 3 ab. <br><br><img src="https://habrastorage.org/webt/vg/ta/ue/vgtauedea7kaitatv7oshzottps.png"><br>  <i>Abb.</i>  <i>15. Broker 3 fällt und hinterlässt einen Master und einen Spiegel in jeder Warteschlange</i> <br><br>  Broker 3 kehrt zurück und es werden neue Spiegel erstellt.  Hauptwarteschlange A beginnt, vorhandene Nachrichten auf einen neuen Spiegel zu replizieren, und während dieser Zeit ist Warteschlange A nicht verfügbar.  Die Datenreplikation dauert zwei Stunden, was zu zwei Stunden Ausfallzeit für diese Warteschlange führt! <br><br>  Linie B bleibt jedoch während des gesamten Zeitraums verfügbar.  Sie opferte einige Redundanz für die Zugänglichkeit. <br><br><img src="https://habrastorage.org/webt/qn/rd/ep/qnrdep5m7sszgxjesb_kfwuw-zw.png"><br>  <i>Abb.</i>  <i>16. Die Warteschlange bleibt während der Synchronisierung nicht verfügbar</i> <br><br>  Nach zwei Stunden ist auch Warteschlange A verfügbar und akzeptiert möglicherweise wieder Lese- und Schreibvorgänge. <br><br><h3>  Updates </h3><br>  Dieses Blockierungsverhalten während der Synchronisation macht es schwierig, Cluster mit sehr großen Warteschlangen zu aktualisieren.  Irgendwann muss der Knoten mit dem Assistenten neu gestartet werden. Dies bedeutet, dass Sie entweder zum Spiegel wechseln oder die Warteschlange während der Serveraktualisierung deaktivieren müssen.  Wenn wir einen Übergang wählen, verlieren wir Nachrichten, wenn die Spiegel nicht synchronisiert sind.  Wenn ein Broker deaktiviert ist, wird standardmäßig kein Übergang zu einem nicht synchronisierten Spiegel durchgeführt.  Dies bedeutet, dass wir keine Nachrichten verlieren, sobald der Broker zurückkehrt. Der einzige Schaden war nur eine einfache Warteschlange.  Das Deaktivieren von Brokern unterliegt der Richtlinie zum <code>ha-promote-on-shutdown</code> .  Sie können einen von zwei Werten festlegen: <br><br><ul><li>  <code>always</code> = Aktiviertes Umschalten auf nicht synchronisierte Spiegel <br></li><li>  <code>when-synced</code> = wechselt nur zum synchronisierten Spiegel, andernfalls kann auf die Warteschlange nicht mehr gelesen und geschrieben werden.  Die Warteschlange kehrt zurück, sobald der Broker zurückkehrt </li></ul><br>  Auf die eine oder andere Weise müssen Sie bei großen Warteschlangen zwischen Datenverlust und Unzugänglichkeit wählen. <br><br><h3>  Wenn Verfügbarkeit die Datensicherheit verbessert </h3><br>  Bevor eine Entscheidung getroffen wird, muss eine weitere Komplikation berücksichtigt werden.  Während die automatische Synchronisierung aus Redundanzgründen besser ist, wie wirkt sie sich auf die Datensicherheit aus?  Natürlich ist es dank der besseren Redundanz weniger wahrscheinlich, dass RabbitMQ vorhandene Nachrichten verliert, aber was ist mit neuen Nachrichten von Herausgebern? <br><br>  Hier müssen Sie Folgendes berücksichtigen: <br><ul><li>  Kann ein Publisher nur einen Fehler zurückgeben und ein höherer Dienst oder Benutzer wird es später erneut versuchen? <br></li><li>  Kann ein Herausgeber eine Nachricht lokal oder in einer Datenbank speichern, um sie später erneut zu versuchen? </li></ul><br>  Wenn der Herausgeber die Nachricht nur löschen kann, erhöht eine Verbesserung der Barrierefreiheit auch die Datensicherheit. <br><br>  Daher müssen Sie nach einem Gleichgewicht suchen, und die Entscheidung hängt von der spezifischen Situation ab. <br><br><h1>  Probleme mit Ha-Promotion-on-Failure = bei Synchronisierung </h1><br>  Die Idee von <i><b>ha-fördern-bei-Fehler</b></i> = <i><b>bei Synchronisierung</b></i> ist, dass wir das Umschalten auf einen nicht synchronisierten Spiegel verhindern und somit Datenverlust vermeiden.  Die Warteschlange bleibt zum Lesen oder Schreiben unzugänglich.  Stattdessen versuchen wir, einen gefallenen Broker mit unbeschädigten Daten zurückzugeben, damit er ohne Datenverlust seine Arbeit als Master wieder aufnimmt. <br><br>  Aber (und das ist groß, aber) wenn der Broker seine Daten verloren hat, haben wir ein großes Problem: Die Warteschlange ist verloren!  Alle Daten sind weg!  Selbst wenn Sie Spiegel haben, die im Grunde die Hauptwarteschlange einholen, werden diese Spiegel ebenfalls verworfen. <br><br>  Um einen Knoten mit demselben Namen erneut hinzuzufügen, weisen Sie den Cluster an, den verlorenen Knoten (mit dem <i>Befehl rabbitmqctl compare_cluster_node</i> ) zu vergessen und einen neuen Broker mit demselben Hostnamen zu starten.  Solange sich der Cluster an den verlorenen Knoten erinnert, merkt er sich die alte Warteschlange und die nicht synchronisierten Spiegel.  Wenn ein Cluster angewiesen wird, einen verlorenen Knoten zu vergessen, wird auch diese Warteschlange vergessen.  Jetzt müssen Sie es erneut deklarieren.  Wir haben alle Daten verloren, obwohl wir Spiegel mit einem Teildatensatz hatten.  Es wäre besser, zu einem nicht synchronisierten Spiegel zu wechseln! <br><br>  Daher ist die manuelle Synchronisation (und der Synchronisationsfehler) in Kombination mit <code>ha-promote-on-failure=when-synced</code> meiner Meinung nach ziemlich riskant.  Dokumente sagen, dass diese Option für die Datensicherheit existiert, aber es ist ein zweischneidiges Messer. <br><br><h1>  Meister neu ausbalancieren </h1><br>  Wie versprochen kehren wir zum Problem der Akkumulation aller Master auf einem oder mehreren Knoten zurück.  Dies kann auch aufgrund fortlaufender fortlaufender Cluster-Updates geschehen.  In einem Cluster mit drei Knoten werden alle Hauptwarteschlangen auf einem oder zwei Knoten angesammelt. <br><br>  Das Ausbalancieren von Mastern kann aus zwei Gründen problematisch sein: <br><br><ul><li>  Keine guten Ausgleichswerkzeuge </li><li>  Warteschlangensynchronisierung </li></ul><br>  Für das Rebalancing gibt es ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Plugin</a> eines Drittanbieters, das nicht offiziell unterstützt wird.  In Bezug auf Plug-Ins von Drittanbietern heißt es im RabbitMQ-Handbuch: „Das Plug-In bietet einige zusätzliche Konfigurations- und Berichterstellungstools, wird jedoch vom RabbitMQ-Team nicht unterstützt und nicht getestet.  Die Verwendung erfolgt auf eigenes Risiko. “ <br><br>  Es gibt noch einen weiteren Trick, um die Hauptwarteschlange durch HA-Richtlinien zu verschieben.  Das Handbuch erwähnt hierfür ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Skript</a> .  Es funktioniert wie folgt: <br><br><ul><li>  Löscht alle Spiegel mithilfe einer temporären Richtlinie mit einer höheren Priorität als die vorhandene HA-Richtlinie. <br></li><li>  Ändert die temporäre HA-Richtlinie so, dass der Knotenmodus mit dem Knoten verwendet wird, auf den die Hauptwarteschlange verschoben werden muss. <br></li><li>  Synchronisiert die Warteschlange für die erzwungene Migration. <br></li><li>  Löscht nach Abschluss der Migration die temporäre Richtlinie.  Die HA-Anfangsrichtlinie tritt in Kraft und die erforderliche Anzahl von Spiegeln wird erstellt. </li></ul><br>  Der Nachteil ist, dass dieser Ansatz möglicherweise nicht funktioniert, wenn Sie große Warteschlangen oder strenge Redundanzanforderungen haben. <br><br>  Nun wollen wir sehen, wie RabbitMQ-Cluster mit Netzwerkpartitionen funktionieren. <br><br><h1>  Unterbrechung der Konnektivität </h1><br>  Die Knoten eines verteilten Systems sind durch Netzwerkverbindungen verbunden, und Netzwerkverbindungen können und werden getrennt.  Die Häufigkeit von Ausfällen hängt von der lokalen Infrastruktur oder der Zuverlässigkeit der ausgewählten Cloud ab.  In jedem Fall sollten verteilte Systeme in der Lage sein, damit umzugehen.  Wieder haben wir die Wahl zwischen Zugänglichkeit und Konsistenz, und wieder ist die gute Nachricht, dass RabbitMQ beides bietet (nur nicht gleichzeitig). <br><br>  Mit RabbitMQ haben wir zwei Hauptoptionen: <br><br><ul><li>  Erlaube logische Trennung (Split-Brain).  Dies bietet Zugriff, kann jedoch zu Datenverlust führen. <br></li><li>  Logische Trennung nicht zulassen.  Dies kann zu einem kurzfristigen Verlust der Verfügbarkeit führen, je nachdem, wie Clients eine Verbindung zum Cluster herstellen.  Dies kann auch zu einer vollständigen Unzugänglichkeit in einem Cluster von zwei Knoten führen. </li></ul><br>  Aber was ist logische Trennung?  Dies ist der Fall, wenn ein Cluster aufgrund eines Verlusts der Netzwerkverbindungen in zwei Teile geteilt wird.  Auf jeder Seite erheben sich die Spiegel zum Meister, so dass sich am Ende in jeder Runde mehrere Meister befinden. <br><br><img src="https://habrastorage.org/webt/mi/4f/bb/mi4fbbuk9maj487alkqsbbykkns.png"><br>  <i>Abb.</i>  <i>17. Die Hauptleitung und zwei Spiegel, jeweils auf einem separaten Knoten.</i>  <i>Dann tritt ein Netzwerkfehler auf und ein Spiegel trennt sich.</i>  <i>Der abgetrennte Knoten sieht, dass die anderen beiden abgefallen sind, und schiebt seine Spiegel zum Master.</i>  <i>Jetzt haben wir zwei Hauptzeilen, und beide erlauben das Schreiben und Lesen.</i> <br><br>  Wenn Publisher Daten an beide Master senden, erhalten wir zwei unterschiedliche Kopien der Warteschlange. <br><br>  Die verschiedenen RabbitMQ-Modi bieten entweder Zugänglichkeit oder Konsistenz. <br><br><h3>  Ignoriermodus (Standard) </h3><br>  Dieser Modus bietet Barrierefreiheit.  Nach dem Verlust der Konnektivität erfolgt eine logische Trennung.  Nach dem erneuten Herstellen der Verbindung muss der Administrator entscheiden, welche Partition er bevorzugen möchte.  Die verlierende Seite wird neu gestartet und alle gesammelten Daten von dieser Seite gehen verloren. <br><br><img src="https://habrastorage.org/webt/ih/rj/ow/ihrjow-ceolx0wy8y2o-cn2yiuk.png"><br>  <i>Abb.</i>  <i>18. Drei Verlage sind drei Maklern zugeordnet.</i>  <i>Intern leitet der Cluster alle Anforderungen an die Hauptwarteschlange von Broker 2 weiter.</i> <br><br>  Jetzt verlieren wir Broker 3. Er sieht, dass andere Broker abgefallen sind und bewegt seinen Spiegel zum Master.  Dies ist die logische Trennung. <br><br><img src="https://habrastorage.org/webt/u_/l8/af/u_l8af-qqcyv4ldqdgwrn4t22ei.png"><br>  <i>Abb.</i>  <i>19. Logische Trennung (Split-Brain).</i>  <i>Die Aufzeichnungen bestehen aus zwei Hauptzeilen, und zwei Kopien weichen voneinander ab.</i> <br><br>  Die Konnektivität wird wiederhergestellt, die logische Trennung bleibt jedoch bestehen.  Der Administrator muss die Verliererseite manuell auswählen.  Im folgenden Fall startet der Administrator Broker 3 neu. Alle Nachrichten, die er nicht übertragen konnte, gehen verloren. <br><br><img src="https://habrastorage.org/webt/_o/a9/ft/_oa9ftbuvl6dwnewtgfkrhkyva4.png"><br>  <i>Abb.</i>  <i>20. Der Administrator deaktiviert Broker 3.</i> <br><br><img src="https://habrastorage.org/webt/ni/y_/xq/niy_xqsgzuvf5ktcta35z98zzxs.png"><br>  <i>Abb.</i>  <i>21. Der Administrator startet Broker 3 und tritt dem Cluster bei, wobei alle dort verbleibenden Nachrichten verloren gehen.</i> <br><br>  Während des Verbindungsverlusts und nach seiner Wiederherstellung standen der Cluster und diese Warteschlange zum Lesen und Schreiben zur Verfügung. <br><br><h3>  Autoheal-Modus </h3><br>  Es funktioniert ähnlich wie der Ignoriermodus, außer dass der Cluster selbst automatisch die verlierende Seite auswählt, nachdem die Konnektivität aufgeteilt und wiederhergestellt wurde.  Die verlierende Seite kehrt leer zum Cluster zurück, und die Warteschlange verliert alle Nachrichten, die nur an diese Seite gesendet wurden. <br><br><h3>  Minority-Modus anhalten </h3><br>  Wenn wir keine logische Trennung zulassen möchten, besteht unsere einzige Möglichkeit darin, das Lesen und Schreiben auf der kleineren Seite nach der Partition des Clusters zu verweigern.  Wenn ein Broker sieht, dass er auf der geringeren Seite ist, hält er inne, schließt alle bestehenden Verbindungen und lehnt neue ab.  Einmal pro Sekunde wird nach einer erneuten Verbindung gesucht.  Sobald die Konnektivität wiederhergestellt ist, wird die Arbeit wieder aufgenommen und dem Cluster beigetreten. <br><br><img src="https://habrastorage.org/webt/xl/cc/af/xlccafaylyx2nrsz5scaafo1h6u.png"><br>  <i>Abb.</i>  <i>22. Drei Verlage sind drei Maklern zugeordnet.</i>  <i>Intern leitet der Cluster alle Anforderungen an die Hauptwarteschlange von Broker 2 weiter.</i> <br><br>  Dann werden Broker 1 und 2 von Broker 3 getrennt. Anstatt ihren Spiegel auf einen Master zu aktualisieren, wird Broker 3 angehalten und ist nicht mehr zugänglich. <br><br><img src="https://habrastorage.org/webt/8h/0_/hc/8h0_hc8vj99u6zaht7cgymlckve.png"><br>  <i>Abb.</i>  <i>23. Broker 3 hält an, trennt alle Clients und lehnt Verbindungsanforderungen ab.</i> <br><br>  Sobald die Konnektivität wiederhergestellt ist, kehrt sie zum Cluster zurück. <br><br>  Schauen wir uns ein anderes Beispiel an, in dem sich die Hauptzeile auf Broker 3 befindet. <br><br><img src="https://habrastorage.org/webt/rs/0s/if/rs0siffyxwpdc8imasvfvkapykw.png"><br>  <i>Abb.</i>  <i>24. Die Hauptlinie bei Broker 3.</i> <br><br>  Dann tritt der gleiche Konnektivitätsverlust auf.  Broker 3 pausiert, weil es kleiner ist.  Auf der anderen Seite sehen die Knoten, dass Broker 3 abgefallen ist, so dass der ältere Spiegel von Broker 1 und 2 zum Master aufsteigt. <br><br><img src="https://habrastorage.org/webt/ba/o3/gr/bao3gr7y31x5ljbbpkqkretaaty.png"><br>  <i>Abb.</i>  <i>25. Übergang zu Broker 2, wenn Broker 3 nicht verfügbar ist.</i> <br><br>  Wenn die Konnektivität wiederhergestellt ist, tritt Broker 3 dem Cluster bei. <br><br><img src="https://habrastorage.org/webt/3z/rp/3k/3zrp3knvfoew7m25bg6bg4dlhju.png"><br>  <i>Abb.</i>  <i>26. Der Cluster kehrte zum normalen Betrieb zurück.</i> <br><br>  Es ist wichtig zu verstehen, dass wir Konsistenz erhalten, aber wir können auch Zugänglichkeit erhalten, <i><b>wenn wir</b></i> Kunden erfolgreich auf den größten Teil des Abschnitts übertragen.  In den meisten Situationen würde ich persönlich den Modus "Minderheit pausieren" wählen, aber das hängt wirklich vom jeweiligen Fall ab. <br><br>  Um die Verfügbarkeit sicherzustellen, ist es wichtig sicherzustellen, dass Clients erfolgreich eine Verbindung zur Site herstellen.  Betrachten Sie unsere Optionen. <br><br><h1>  Kundenkonnektivität </h1><br>  Wir haben verschiedene Möglichkeiten, wie Clients nach einem Verbindungsverlust an den Hauptteil des Clusters oder an Arbeitsknoten gesendet werden (nach einem Ausfall eines Knotens).  Erinnern wir uns zunächst daran, dass eine bestimmte Warteschlange auf einem bestimmten Host gehostet wird, Routing und Richtlinien jedoch auf allen Hosts repliziert werden.  Clients können eine Verbindung zu einem beliebigen Knoten herstellen, und das interne Routing leitet sie bei Bedarf weiter.  Wenn ein Knoten angehalten wird, wird die Verbindung abgelehnt, sodass Clients eine Verbindung zu einem anderen Knoten herstellen müssen.  Wenn ein Knoten abfällt, kann er überhaupt wenig tun. <br><br>  Unsere Möglichkeiten: <br><br><ul><li>  Der Zugriff auf den Cluster erfolgt über einen Load Balancer, der einfach die Knoten durchläuft und Clients wiederholt versucht, eine Verbindung herzustellen, bis sie erfolgreich abgeschlossen wurden.      ,        ,        (  ).         ,    . <br></li><li>         /   ,    .    ,        ,     . <br></li><li>      ,          .       ,       ,   . <br></li><li>    /    DNS.      TTL. </li></ul><br><h1>  Schlussfolgerungen </h1><br>   RabbitMQ    .      , : <br><br><ul><li>        ; <br></li><li>      . </li></ul><br>         .   RabbitMQ      ,     .        ,     .         RabbitMQ        .      RabbitMQ     : <br><br><ul><li>  . <br></li><li>  . <br></li><li>   . </li></ul><br>      ,   : <br><br><ul><li> <code>ha-promote-on-failure=always</code> <br> </li><li> <code>ha-sync-mode=manual</code> <br> </li><li> <code>cluster_partition_handling=ignore</code> ( <code>autoheal</code> ) <br></li><li>   <br></li><li> ,      ,  -     </li></ul><br>   ( )   : <br><br><ul><li> Publisher Confirms  Manual Acknowledgements    <br></li><li> <code>ha-promote-on-failure=when-synced</code> ,              !   <code>=always</code> . <br></li><li> <code>ha-sync-mode=automatic</code> (        ;  , ,       ) <br></li><li>  Pause Minority <br></li><li>   </li></ul><br>          ; ,      (,   ).        Shovel. <br><br>    - , ,  . <br><br> .   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ,       RabbitMQ   Docker  Blockade,      ,    . <br><br>   : <br> №1 — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">habr.com/ru/company/itsumma/blog/416629</a> <br> №2 — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">habr.com/ru/company/itsumma/blog/418389</a> <br> №3 — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">habr.com/ru/company/itsumma/blog/437446</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de471858/">https://habr.com/ru/post/de471858/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de471840/index.html">Warum zu Interviews gehen?</a></li>
<li><a href="../de471844/index.html">5 Gründe, EPAM INSIDER in Kasachstan zu besuchen</a></li>
<li><a href="../de471852/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 481 (10/01/2019 - 07/10/2019)</a></li>
<li><a href="../de471854/index.html">Hitzetod 5G</a></li>
<li><a href="../de471856/index.html">Wir lösen alle 42 Versionen des Harry-Potter-Trank-Puzzles</a></li>
<li><a href="../de471860/index.html">Peg Parser</a></li>
<li><a href="../de471862/index.html">PEG-Parser-Implementierung</a></li>
<li><a href="../de471864/index.html">PEG-Parser-Generierung</a></li>
<li><a href="../de471866/index.html">PEG-Parser-Visualisierung</a></li>
<li><a href="../de471868/index.html">Genetik der Liebe: Konflikt zwischen den Geschlechtern als Grundlage für die Zusammenarbeit bei Paaren monogamer Vögel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
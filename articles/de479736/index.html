<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìç ‚õπÔ∏è üëàüèø Kameras oder Laser üöπ üôáüèæ üóÉÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Welche Sensoren werden in unbemannten Fahrzeugen am wichtigsten sein? Diejenigen Sensoren, die das sogenannte Wahrnehmungssystem steuern, und dies ist...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kameras oder Laser</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itelma/blog/479736/"><img src="https://habrastorage.org/getpro/habr/post_images/7d1/cd7/4c9/7d1cd74c9a86901e522b61b4848fbd1e.jpg" alt="Bild"><br><br>  Welche Sensoren werden in unbemannten Fahrzeugen am wichtigsten sein?  Diejenigen Sensoren, die das sogenannte Wahrnehmungssystem steuern, und dies ist das Wichtigste beim Fahren.  Die Aufgabe des Wahrnehmungssystems besteht darin, alle wichtigen Objekte auf oder in der N√§he der Stra√üe zu erfassen, z. B. andere Fahrzeuge, Fu√üg√§nger, M√ºll und in einigen F√§llen Stra√üenobjekte wie Schilder und Fahrbahnmarkierungen. <br><br>  (Die Positionierung auf der Stra√üe h√§ngt auch von den Sensoren ab.) <br><br>  Das Wahrnehmungssystem muss alle Hindernisse erkennen und versuchen, sie zu identifizieren.  Sie muss ihre Geschwindigkeit und Richtung messen und ihre Bewegung vorhersagen.  Dies ist eine sehr schwierige Aufgabe. <br><br>  Zwei Schl√ºsselfehler im Wahrnehmungssystem sind False Positives (Blindheit) und False Positives (Geisterobjekte). <br><br>  Eine falsch negative Reaktion ist eine Situation, in der ein Hindernis nicht erkannt wurde.  Dies kann katastrophale Folgen haben, wenn das System so lange funktioniert, dass Sie das Hindernis nicht sicher umgehen k√∂nnen.  Ein gutes System f√ºhrt fast nie zu einem falsch negativen Ergebnis.  Es kann einige Sekunden dauern, bis ein Hindernis erkannt wird, es kann aufgrund pl√∂tzlicher Blitze etwas fehlen, aber wiederholte Fehler k√∂nnen zu einem Unfall f√ºhren.  Mit "nie" meine ich "fast nie", von der Gr√∂√üenordnung der Einheit bis zu vielen Millionen. <br><br>  Ein falsch positives Ergebnis ist eine andere Art von Fehler.  In ihrem Fall sieht das System etwas, das tats√§chlich nicht vorhanden ist, und dies zwingt das Auto zum Bremsen oder Zusammenbrechen.  Dies √§rgert die Passagiere und kann zu Verletzungen f√ºhren, wenn sie nicht angeschnallt sind.  Es kann auch zu einem Unfall kommen, wenn das andere Auto sehr nahe f√§hrt oder zu scharf gebremst und in Kurven gefahren wird.  Normalerweise sind solche F√§lle nicht gef√§hrlich. Wenn dies jedoch zu h√§ufig vorkommt, verlassen Benutzer das System. <br><a name="habracut"></a><br>  Eine falsche Klassifizierung ist auch mit den obigen Fehlern verbunden.  Eine falsche Klassifizierung bedeutet, dass der Radfahrer mit einem Fu√üg√§nger verwechselt wurde oder dass zwei Motorr√§der mit einem Auto verwechselt wurden.  Auch ohne genaue Identifikation wei√ü die Maschine, wie sie nicht auf ein Hindernis st√∂√üt, aber das System kann m√∂glicherweise falsch bestimmen, wo es sich bewegt oder wie es am besten darauf reagiert. <br><br>  Eine weitere Fehlerklasse sind vollst√§ndige Ausf√§lle.  Der Sensor oder seine Software funktionieren m√∂glicherweise nicht oder nicht richtig.  Dies ist √ºberraschenderweise h√§ufiger zul√§ssig als Blindheit, da das System erkennt, dass der Sensor nicht in Betrieb ist und seine Daten nicht akzeptiert.  In diesem Fall wird sie sich auf Standby-Sensoren verlassen oder sich bem√ºhen, mit anderen Sensoren so schnell wie m√∂glich von der Stra√üe abzuheben, wenn dies nicht ausreicht.  Auch wenn dies nicht allzu oft vorkommen sollte, werden die Menschen sonst aufh√∂ren, dem System zu vertrauen. <br><br>  Es gibt viele wichtige Sensoren f√ºr unbemannte Fahrzeuge, aber die am meisten erforschten und diskutierten sind Lidars und Kameras. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/068/a1f/383/068a1f38333747b94b64b3e39a6194b6.jpg" alt="Bild"></div><br><br>  Lidar ist ein Lichtradar.  Der Sensor sendet kurze, f√ºr das Auge unsichtbare Laserlichtimpulse aus und erkennt, wie lange das reflektierte Licht zur√ºckkehrt.  Somit erkennt das System die Helligkeit und Reichweite des Ziels ziemlich genau. <br><br>  <b>Lidar hat gro√üe Vorteile:</b> <br><br><ul><li>  Es ist √§u√üerst zuverl√§ssig bei der Erkennung verschiedener Objekte von ausreichender Gr√∂√üe und berechnet deren Abstand, Gr√∂√üe und Position sehr nahe an der 100% igen Zuverl√§ssigkeit. </li><li>  Das Ergebnis des Lidars ist eine 3D-Karte der Welt.  Es ist einfach, etwas aus den Objekten hinter dem Sensor (oder davor) auszuw√§hlen. </li><li>  Lidar verwendet emittiertes Licht, sodass es unabh√§ngig vom Umgebungslicht funktioniert.  Tag oder Nacht, bew√∂lkt oder sonnig, der Himmel ist bedeckt oder die Sonne scheint - der Lidar sieht unter allen Bedingungen fast gleich aus. </li><li>  Es ist st√∂rsicher und hat eine viel h√∂here Aufl√∂sung als Radar. </li><li>  Einige Lidars k√∂nnen die Geschwindigkeit eines Objekts mithilfe des Doppler-Effekts bestimmen. </li></ul><br>  <b>Es gibt jedoch Nachteile:</b> <br><br><ul><li>  Urspr√ºnglich waren Lidars sehr teuer.  Hochaufl√∂sende Lidars wurden in kleinen Mengen hergestellt und kosten mehr als Autos (neue Modelle erscheinen zu einem Preis von weniger als 1000 US-Dollar). </li><li>  Ziemlich bescheidene Aufl√∂sung.  Die besten Ger√§te empfangen ein Bild von 128 Pixeln in vertikaler Abtastung mit einer Frequenz von 10 Hz. </li><li>  Die Reichweite ist begrenzt.  Mittlere Lidars sehen in einer Entfernung von 70-100 Metern und werden von gro√üen Objekten wie Autos in einer Entfernung von etwa hundert Metern weniger gut aufgenommen.  Einige behaupten, bis zu 200 Meter zu arbeiten, aber das ist zweifelhaft.  1,5 Mikron Lidars, die noch teurer sind, k√∂nnen weiter sehen. </li><li>  Die meisten Lidars haben bewegliche Teile, um die Welt abzutasten.  Flash-Lidars kommen ohne bewegliche Teile aus, sind aber jetzt noch teurer (bei Festk√∂rper-Lidars der neuen Generation wird die Anzahl der beweglichen Teile minimiert oder sie werden vollst√§ndig eliminiert). </li><li>  Die Bildwiederholfrequenz ist normalerweise niedriger.  W√§hrend das Lidar die Szene abtastet, wird es au√üerdem aufgrund der Bewegung der abgetasteten Autos und anderer Objekte verzerrt, und da verschiedene Kanten der Szene zu verschiedenen Zeiten abgetastet werden, tritt ein Versatz auf. </li><li>  Lidare k√∂nnen Probleme mit starkem Regen, Schnee und Nebel haben, obwohl sich andere Lichtsensoren, einschlie√ülich Kameras, √§hnlich verhalten.  Lidare k√∂nnen auch manchmal unsichtbare Dinge wie Abgase ausl√∂sen. </li><li>  Lidare werden am besten im Freien montiert.  Sie brauchen jedes Photon, also schw√§chen Sie sie nicht, indem Sie sie hinter der Windschutzscheibe installieren. </li></ul><br><h3>  Kameras </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/964/c91/7af/964c917afd18e85e85164f6bf52c79f3.jpg" alt="Bild"></div><br><br>  Kamerabasierte Systeme verhalten sich wie Menschen.  Eine oder mehrere Kameras beobachten die Szene und die Software versucht, dasselbe wie eine Person zu tun - sich eine dreidimensionale Welt aus einem zweidimensionalen Bild vorzustellen und zu verstehen. <br><br><ul><li>  Kameras sind wirklich g√ºnstig.  Ausr√ºstung kostet nur Dutzende von Dollar, man kann eine ganze Menge davon haben. </li><li>  Da Kameras, die f√ºr sichtbares Licht empfindlich sind, reflektiertes Licht verwenden, k√∂nnen sie tags√ºber eine beliebige Entfernung sehen, wenn sie ein relativ enges Sichtfeld haben und gerichtet werden k√∂nnen.  Nachts sollten sie Durchlicht verwenden - wie Ihre Scheinwerfer. </li><li>  Sie sehen Farben.  Lidare nehmen Graustufen im Infrarotspektrum wahr. </li><li>  Sofern die Kameras nicht gef√ºhrt werden, haben sie keine beweglichen Teile.  Andernfalls erhalten sie m√∂glicherweise auch f√ºr entfernte Objekte ein hochaufl√∂sendes Bild.  Selbst in der Ferne gibt es Kameras mit einer sehr hohen Aufl√∂sung - w√§hrend das Lidar 64 Zeilen sieht, sieht die Kamera 3000. </li><li>  Aufgrund der hohen Aufl√∂sung und Farbe k√∂nnen Kameras R√ºckschl√ºsse auf Szenen ziehen, die aus dem mit dem Lidar aufgenommenen Bild mit niedriger Aufl√∂sung nicht erhalten werden k√∂nnen. </li><li>  Kameras k√∂nnen Ampeln, Abmessungen, Blinker und andere Lichtquellen erkennen.  Kameras eignen sich hervorragend zum Lesen von Zeichen. </li></ul><br>  <b>Kameras haben jedoch einige Nachteile, und die erste verdirbt viel:</b> <br><br><ul><li>  Computer Vision funktioniert heutzutage nicht gut genug, um alle wichtigen Funktionen mit der f√ºr ein sicheres Fahren erforderlichen Zuverl√§ssigkeit zu erkennen. </li><li>  Kameras sollten mit wechselnder Beleuchtung funktionieren.  Beobachtete Objekte sind h√§ufig der Bewegung von Schatten ausgesetzt und k√∂nnen auch aus jeder Richtung (oder √ºberhaupt nicht) beleuchtet werden. </li><li>  Nachts ben√∂tigen Kameras zus√§tzliche Beleuchtung, und die Scheinwerfer reichen m√∂glicherweise nicht aus. </li><li>  Computer Vision-Aufgaben erfordern Hochleistungsprozessoren oder spezielle Chips, um auf dem Niveau der aktuellen Anforderungen zu arbeiten. </li></ul><br><h3>  Computer Vision </h3><br>  Die Bildverarbeitung der Kamera kann grob in zwei Kategorien unterteilt werden: ‚ÄûComputer Vision‚Äú und ‚ÄûMachine Vision‚Äú.  Machine Vision bezeichnet eine einfache, lokalisierte Analyse digitaler Bilder.  Es umfasst Aufgaben wie das Suchen nach Details und Kanten eines Bildes, das Bestimmen von Bewegung und Parallaxe der Bewegung sowie das Anwenden von Parallaxe auf Stereobilder, um die Entfernung zu bestimmen.  Diese Methoden sind ziemlich gut etabliert und viele von ihnen sind ziemlich verst√§ndlich.  Einige Bildverarbeitungsaufgaben (wie das Erkennen und Lesen von Verkehrszeichen) sind schwieriger, werden jedoch bald gel√∂st. <br><br>  Computer Vision bezieht sich auf eine komplexere Reihe von Aufgaben, die menschliche F√§higkeiten erfordern, einschlie√ülich der F√§higkeit, Bilder zu verstehen.  Diese Aufgaben beinhalten auch F√§higkeiten wie die F√§higkeit, das Bild in Segmente aufzuteilen und Objekte zu erkennen.  Sie k√∂nnen das Bild einer anderen Person einer Person zeigen, die sich in nahezu jeder Situation und in jedem Licht befindet, und der Beobachter kann leicht feststellen, was die Person auf dem Bild ist und in welcher Entfernung sie sich befindet.  Wir k√∂nnen sogar feststellen, auf was die Aufmerksamkeit gerichtet ist und was die abgebildete Person tut.  Algorithmen in diesem Bereich werden immer besser, sind aber noch nicht auf einem ausreichenden Niveau. <br><br>  Einige Aufgaben erreichten die Grenzzone.  Bildverarbeitungswerkzeuge suchen nach Details im Bild und tun dies unabh√§ngig von der Gr√∂√üe und Ausrichtung des Bildes.  Auf diese Weise k√∂nnen Sie andere Autos, Fu√üg√§nger, Stra√üengrenzen und Fahrbahnmarkierungen erkennen.  Das allgemeine Problem der genauen Identifizierung ist eines, von dem viele glauben, dass es endg√ºltig gel√∂st sein wird, aber es ist viel schwieriger vorherzusagen, wann dies geschehen wird.  Das Fahren erfordert, dass das System nichts ‚Äûverpasst‚Äú, was ein Sicherheitsproblem darstellen k√∂nnte.  Besonders schwierig sind station√§re Hindernisse, die so weit entfernt sind, dass das Stereobild nicht funktioniert, und die Parallaxe der Bewegung (die Art und Weise, wie sich Objekte im Hintergrund im Verh√§ltnis zu anderen Objekten w√§hrend Ihrer Bewegung bewegen) ist ebenfalls begrenzt.  (Das Objekt, auf das Sie direkt zusteuern, wie ein Fu√üg√§nger oder ein stehendes Auto, hat eine sehr kleine Bewegungsparallaxe.) <br><br>  Ein weiteres Problem f√ºr k√ºnstliche Bildverarbeitungssysteme ist die Vielfalt der Beleuchtung und Beschattung.  Objekte k√∂nnen aus jeder Richtung beleuchtet werden.  Auch die Sonne kann hinter ihnen sein.  Oft kreuzen Schatten das Objekt selbst.  In diesem Fall m√ºssen HDR-Technologien verwendet werden, um die Details in den einzelnen Bildbereichen sehen zu k√∂nnen, wenn die Schattenr√§nder die charakteristischen Merkmale des Objekts im Kontrastbild verwischen. <br><br>  Es gibt einen speziellen Kameratyp, der als langwelliges Infrarot oder ‚Äûthermisches‚Äú Licht bekannt ist und emittiertes statt reflektiertes Licht verwendet.  Objekte, die sich im Schatten des Sonnenlichts befinden, werden im Bild immer noch verdeckt, aber es gibt keine sich bewegenden Schatten mehr.  W√§rmebilder sind einfarbig und funktionieren sowohl bei Tag als auch bei Nacht gleich gut, obwohl das Ergebnis nachts etwas besser ist.  Solche Kameras sind bei Nebel und anderen Wetterbedingungen besser zu sehen.  Sie k√∂nnen Lebewesen sehr gut erkennen, es sei denn, die Temperatur der Erde entspricht der Temperatur des menschlichen K√∂rpers.  Leider sind W√§rmebildkameras sehr teuer, und Modelle mit guter Aufl√∂sung sind noch teurer.  Sie m√ºssen auch extern installiert werden, da Infrarotwellen nicht durch das Glas gelangen.  Derzeit gibt es keine Berichte √ºber den praktischen Einsatz dieser Kameras, es werden jedoch einige Untersuchungen durchgef√ºhrt. <br><br>  Im Bereich der "hyperspektralen" Bildgebung gibt es ein gewisses Potenzial. Sie verf√ºgen √ºber Kameras, die in vielen Farbbereichen, einschlie√ülich Infrarot und Ultraviolett, arbeiten.  Mit solchen Bildern ist es einfacher, bestimmte Arten von Objekten zu erkennen. <br><br>  Menschen sind in der Lage, die beobachteten zweidimensionalen Bilder in ein dreidimensionales Modell der Welt zu verwandeln und es gleichzeitig viel besser zu machen, nachdem sie die Szene untersucht und die Parallaxe der Bewegung beobachtet haben.  Computer sind derzeit bei der Analyse von Standbildern bescheiden und greifen nur gelegentlich auf die Verwendung von Bewegung zur√ºck.  Menschen verwenden Stereobilder, k√∂nnen aber auch fahren, wenn ein Auge geschlossen ist oder fehlt. <br><br>  Der Lidar kann wiederum in einem Durchgang eine vollst√§ndige dreidimensionale Karte der Szene erstellen.  Mehrere Durchg√§nge k√∂nnen das Bild verbessern - und ihm dabei helfen, die Geschwindigkeit zu sch√§tzen. <br><br><h3>  Tiefes Lernen </h3><br>  Der Gro√üteil des heutigen Hype im Bereich der Computersicht h√§ngt mit faltungsbedingten neuronalen Netzwerken zusammen, insbesondere solchen, die mit dem Tool Deep Learning erstellt wurden, das viele der Funktionen des biologischen Gehirns nachahmt.  Viele Menschen glauben, dass diese Richtung ein Durchbruch sein wird.  Deep-Learning-Netzwerke arbeiten mit einem gro√üen Lernsatz (und k√∂nnen in begrenztem Umfang auch ohne spezielle Schulung funktionieren), um die Weltanschauung besser zu verstehen und Ma√ünahmen zu ergreifen.  Die Menschen schufen Roboter, die mit Deep-Learning-Techniken √ºber unwegsames Gel√§nde gef√ºhrt wurden, wonach diese Roboter in der Lage waren, Bewegungen unter √§hnlichen Bedingungen zu lernen. <br><br>  Dies ist eine gro√üartige Arbeit, aber wir sind immer noch weit von der hohen Genauigkeit entfernt, die f√ºr unbemannte Fahrzeuge erforderlich ist.  Es ist auch beunruhigend, dass wir bei der Arbeit mit tiefem Lernen nicht genau wissen, warum dies funktioniert, sondern nur die Tatsache, dass wir arbeiten.  Sie k√∂nnen das neuronale Netz neu trainieren, um Fehler zu korrigieren, aber Sie k√∂nnen nicht sicher sein, warum das Retraining alles korrigiert hat.  Der gleiche Nachteil ist auch f√ºr das menschliche Gehirn charakteristisch. Nur eine Person kann Ihnen erkl√§ren, warum sie auf die eine oder andere Weise gehandelt hat. <br><br>  Aus rechtlicher Sicht gibt es unterschiedliche Auffassungen zum Tieftraining in unbemannten Fahrzeugen.  Maschinelles Lernen kann Sie verletzen, weil Sie nicht verstehen, wie es funktioniert, und es kann n√ºtzlich sein, weil Sie die besten Techniken mit guten Sicherheitsindikatoren angewendet haben und keine Fehler gemacht haben, die als schlampig bezeichnet werden k√∂nnen. <br><br>  Maschinelles Lernen verbessert tendenziell die Arbeitsqualit√§t mit einer Zunahme der Trainingsdatenmenge, weshalb so gro√üe Anstrengungen unternommen werden, um gro√üe Mengen solcher Daten zu erstellen.  Neuronale Netze sind jedoch nicht in der Lage, Dinge zu erkennen, die sie noch nie gesehen haben (oder √§hnliche Objekte gesehen haben). <br><br><h3>  Andere Sensoren </h3><br>  Der wichtigste der anderen Sensoren ist Radar.  Das Radar hat fantastische Vorteile.  Erstens sieht er gut durch den Nebel, w√§hrend optische Sensoren dies nicht verkraften k√∂nnen.  Zweitens sieht er andere Autos gut und jeder Treffer des Radars gibt dank des Doppler-Effekts nicht nur Auskunft √ºber die Entfernung, sondern auch √ºber die Geschwindigkeit.  Dies ist mehr als nur Informationen vom Lidar - eine Aufnahme des Radars zeigt alle sich bewegenden Hindernisse und ihre Geschwindigkeit.  Das Radar kann die Reflexionen von der Stra√üe unter dem Auto oder LKW vor Ihnen auswerten und Informationen √ºber die Aktionen des Autos in der toten Zone des LKWs geben - dies ist ein sehr cleverer Trick. <br><br>  Radare bieten eine viel geringere Aufl√∂sung.  Es gibt experimentelle hochaufl√∂sende Radare, die jedoch ein gro√ües Funkspektrum (Frequenzbereich) erfordern - mehr als das, was Regulierungsbeh√∂rden produzieren.  Es ist unwahrscheinlich, dass das Radar Ihnen sagt, ob sich das Ziel auf Ihrer Fahrspur befindet oder nicht, oder ob es sich auf einer √úberf√ºhrung oder auf der Stra√üe vor Ihnen befindet. <br><br>  Feste Objekte reflektieren auch Radarsignale, und dies ist ein Problem.  Erde, Zeichen, Z√§une - alle geben Signale zur√ºck, dass es sich um statische Objekte handelt.  Wenn ein stehendes Auto ein Radarsignal reflektiert, k√∂nnen Sie nicht sicher sein, ob es sich um ein Stra√üenschild oder ein darauf geparktes Auto handelt.  Die meisten Autoradars ignorieren einfach die Reflexionen von statischen Objekten, was einer der Gr√ºnde daf√ºr war, dass die automatische Geschwindigkeitsregelung lange Zeit nicht in Verkehrsstr√∂men funktionierte, in denen Sie h√§ufig gasen und bremsen m√ºssen. <br><br>  Als Ergebnis neuer Forschungen wurde ein Radar mit h√∂herer Aufl√∂sung geschaffen, und es wird auch geforscht, um Objekte an ihren charakteristischen Merkmalen in ihren Reflexionen zu erkennen.  Digitale Radarsysteme mit einer phasengesteuerten Anordnung k√∂nnen die Szene untersuchen und die Aufl√∂sung um einen Grad erh√∂hen.  Dies ist nicht genug, aber es ist bereits eine Verbesserung. <br><br><h3>  Sensor Association </h3><br>  Wenn Sie mehr als einen Sensor verwenden, m√∂chten Sie alle Daten kombinieren, um zu verstehen, dass die vom Radar erkannte Maschine mit der von der Kamera oder der Lidar-S√§ge √ºbereinstimmt.  Dies verbessert die Qualit√§t der empfangenen Daten, kann aber auch schaden.  Die Kombination der Sensoren ist nicht 100% zuverl√§ssig.  Was machen Sie, wenn das Radar anzeigt, dass sich ein Auto vor Ihnen befindet und die Kamera dies nicht glaubt (oder umgekehrt)?  Sie m√ºssen sich entscheiden, was Sie glauben m√∂chten.  Wenn die Auswahl falsch ist, kann ein Problem auftreten.  Wenn Sie an die Nachricht √ºber das Hindernis glauben, k√∂nnen Sie die Blindheit reduzieren (was sehr wichtig ist), aber Sie k√∂nnen nicht vorhandene Hindernisse von beiden Sensoren ber√ºcksichtigen.  Manchmal bekommt man das Beste aus zwei Welten und manchmal das Schlimmste. <br><br>  Da alle Sensoren unterschiedliche Einschr√§nkungen aufweisen, bleibt die Integration von Sensoren das Hauptziel der meisten an Robotern beteiligten Teams. <br><br>  Die Kombination von Sensoren kann ohne Komplikationen durchgef√ºhrt werden, wenn jeder Sensor eine bestimmte Aufgabe oder ein separates Sichtfeld besser bew√§ltigt.  Dann vertrauen Sie den Sensoren die Arbeit, die sie am besten leisten. <br><br>  (Es ist zu beachten, dass eine gute Sensorkombination unter Ber√ºcksichtigung der Rohdaten aller Sensoren durchgef√ºhrt wird. Sie treffen Entscheidungen nicht nur aufgrund der Tatsache, dass das Auto in den Radardaten, sondern nicht in den Kameradaten vorhanden ist. Dennoch werden viele Objekte in einem angezeigt der Datensatz vom Sensor ist klarer als in einem anderen.) <br><br><h3>  Positionierung </h3><br>  ,       (,     ).      ,           3D,          ,         . <br><br>         GPS,            .                . GPS          ( GPS     ),      . <br><br><h3> , ,   ,  ? </h3><br>       ,  .    ? <br><br>                2020        .   ‚Äì         . <br><br>     .   ,        Velodyne  75 000 $,       32     .      .   ,    ,   1982 5-   3000 $,   ,            .  ,           ,      ,           . <br><br>           ,      .    ,    ,    ,       .     ,     ,        .            ,     , <br><br> ,              ,    . <br><br>      .      ,             ,      .  ,                      . <br><br>   MobilEye,      Intel, (, ,         ),   ,    ,   ,       .    4  ,        . <br><br>      ,        .    ,        ,     .        ,            .     . <br><br>  ,     .      ,       .  ,         ,   ,  VisLab  ,  ,       ,  Mercedes 6D   MobilEye,    . <br><br>     ,      ,     ,      ,    ‚Äì     .      ,            . <br><br>      ,    ,        ,      .  ,       ,         ,   . <br><br>         ,       ‚ÄúSuper Cruise‚Äù,               ,     .   (     ,     )   ,     .       ,     ,    ,   ,      . <br><br>           ,     ‚Äì    .       ,        .     99% ,    99%  99.9999%      .     .  ,      ,      ,    . <br><br>           .    ,      ,     ,    ,       .  ,   -        .   ,      10-20%   ,      , -      ,   ,       . ,    ,   ,         ,           ,    ,     . <br><br>    - ,  - .       ,     ,     100 000 $,       3000 $   . <br><br><h3>    ? </h3><br>  ,      ,  ,       . <br><br>     ,   .  ,  400 000     .       170     290    .  ,        3  ,      6000 .       ,     . <br><br> ,          . ,             -  ( 80%    ,     ). -       .       ,        .       -   ,      ,        ‚Äì    ,    .   -    ,   ,      , . <br><br> ,      ,   .           ,     .         ,     ,        .                 .            . <br><br>     ,         ,  , ,        ,    .        ,  ,    ,                .  -      ,      ,  ,     ‚Äì     .            ,    . <br><br>        .             ,  , ,    . <br><br>          .       ,   .      ,      .     ( ,    ) - . <br><br>         ,          ,    ,      .      ,       ,       ,      .                  ,  -   . <br><br>  ,     ,        ,        .        ,     .          ,    ,       (   ),   , ,            .       -     ,    ,         . <br><br>   ,          . ,    ‚Äú ‚Äù   ,      40 /.         ,         3D,            . <br><br> ,   ,          (  Microsoft Kinect).      3D,        ,     ,  . <br><br><h3>             </h3><br>              ,  ,       .     ,           .    ,       ‚Äì        . <br><br>  ,   ,     ,    .  ,       .     ,       .                        ,   ,    .      .     ,         ,     ,  .     ,   .  ,   99.9%    ,   ,     ,      ,     ,       .          ,   . <br><br>           ,    ,  -     .   ,         ,   .     -  ‚Äì   ,       .      ,      99.99999%,    . <br><br>  ,      ,          .       ,          .   ,  1   10 000  100 000      ,             -,     . <br><br>  ,   -,    2017  2019 ,      .  ‚Äì    ,    .     ,     ,  ,  ,     .  ,       ,          .    ,     ,         . <br><br> ,  2020,               ,          ,  , ,      . <br><br>      ( 25 /)     ,       . <br><br>   ,    ,    ,   ‚Äì  ,      ? <br><br><h3>  Tesla </h3><br> ,  Tesla   ,   ‚Äú‚Äù  ,   ‚Äú‚Äù.        8   ,     :        .  ,        ,    .    ,    ,             . <br><br> Tesla ,        ,          ,      .    ,     ,  ,      ,        .  ,       - ,            . <br><br><h3>  </h3><br> ,     ,    <a href="https://en.wikipedia.org/wiki/Lidar"></a> . Velodyne,    ,   ,     64   .    10       .        905  (,    )      . Velodyne      32     16   10 000 $. <br><br>    ,          . , ,  ,   ,          ,     . <br><br>       .  ‚Äì        ,   .      ,    , , ,   DVD.   ,       ,     . <br><br>    .  16-   Velodyne   10 000 $. Quanergy,    ,    8                  . Valeo/IBEO    250   4 ,   , Velodyne ,             300 .    . <br><br> <b>    ,   :</b> <br><br><ul><li>         ,    ,      ,      .        .        360 ,    Velodyne   .  ,    ,     . </li><li> Blitzlidare senden einen hellen Blitz √ºber die gesamte Fl√§che und werden dann von einer Reihe von Sensoren und Timern empfangen, die gleichzeitig ein Bild der gesamten Szene aufnehmen k√∂nnen.  Dieses Design bietet viele Vorteile: Es gibt keine beweglichen Teile und Sie erhalten keine Bewegungsartefakte, da sich sowohl die Welt als auch der Sensor beim Scannen bewegen.  Im Scan-Lidar werden alle Objekte gestreckt und verzerrt, weil sie sich relativ zum Sensor bewegen.  Ein Blitzlidar ist heutzutage sehr teuer - es ben√∂tigt einen speziellen Sensorchip, und der Puls muss extrem stark sein, um das gesamte Sichtfeld auf einmal zu beleuchten. </li><li>  Mikroscanner sind ultrad√ºnne bewegliche Spiegel, die auf der Basis von Siliziumchips hergestellt werden.  So funktionieren die meisten Videoprojektoren.  Obwohl es sich um bewegliche Teile handelt, sind sie sehr klein und k√∂nnen sehr leicht und langlebig sein.  Einige Lidars mit kurzer Reichweite wurden mit dieser Technologie gebaut. </li><li>  Wenn Sie Licht im 1,5-Mikron-Bereich (mittleres Infrarot) verwenden, fokussiert das menschliche Auge es nicht mehr.  Dies bedeutet, dass Sie viel hellere Impulse senden k√∂nnen, ohne Schaden zu verursachen, und dies wiederum bedeutet, dass Sie in gr√∂√üerer Entfernung sehen k√∂nnen.  Die schlechte Nachricht ist, dass 1,5-Mikron-Licht kein Silizium ausl√∂st, was bedeutet, dass Sie andere Arten von Elektronik verwenden m√ºssen, Technologien, die nicht die niedrigen Kosten einer breiten Produktion aufweisen, wie Silizium.  Daher sind Lidars mit 1,5 Mikron derzeit sehr teuer. </li><li>  Einige spezielle Lidars wurden erstellt, um weiter zu sehen, und sie nutzen sogar den Doppler-Effekt, damit sie wissen, wie schnell sich das Objekt, das sie entdeckten, bewegt.  Dies ist bei hochaufl√∂senden Universaldeckeln schwierig. </li><li>  Einige Time-of-Flight-Kameras untersuchen Licht mit einer Tr√§gerwelle und untersuchen die Phasen√§nderungen von zur√ºckkehrenden Reflexionen, um die Zeit zu messen.  Solche Kameras k√∂nnen sehr kosteng√ºnstig sein, haben jedoch eine geringe Reichweite und Rauschen beim Messen von Entfernungen. </li></ul><br><hr><br><img src="https://habrastorage.org/webt/4m/5z/_p/4m5z_pc9zhjja8pmtwxvaihckfe.png" alt="Bild"><br><br><div class="spoiler">  <b class="spoiler_title">√úber ITELMA</b> <div class="spoiler_text">  Wir sind ein gro√ües <a href="https://en.wikipedia.org/wiki/Automotive_industry">Automobilzulieferunternehmen</a> .  Das Unternehmen besch√§ftigt rund 2.500 Mitarbeiter, darunter 650 Ingenieure. <br><br>  Wir sind vielleicht das leistungsst√§rkste Kompetenzzentrum in Russland f√ºr die Entwicklung der Automobilelektronik in Russland.  Jetzt sind wir aktiv am Wachsen und haben viele offene Stellen (etwa 30, einschlie√ülich in den Regionen) ge√∂ffnet, wie z. B. einen Software-Ingenieur, einen Konstrukteur, einen leitenden Entwicklungsingenieur (DSP-Programmierer) usw. <br><br>  Wir haben viele interessante Herausforderungen von Autoherstellern und Sorgen, die die Branche antreiben.  Wenn Sie als Spezialist wachsen und von den Besten lernen m√∂chten, freuen wir uns, Sie in unserem Team zu sehen.  Wir sind auch bereit, Know-how zu teilen, das wichtigste, was in der Automobilindustrie passiert.  Stellen Sie uns Fragen, wir werden antworten, wir werden diskutieren. </div></div><br>  <b>Lesen Sie weitere n√ºtzliche Artikel:</b> <br><br><ul><li>  <a href="https://habr.com/ru/company/itelma/blog/478640/">Autonome Autos auf Open Source</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/478376/">Autonome Autos ber√ºcksichtigen die Selbstsucht der Menschen</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476824/">McKinsey: Software- und Elektronikarchitektur in der Automobilindustrie neu denken</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476054/">Ein weiterer OS-Krieg ist bereits unter der Motorhaube von Autos</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475576/">Programmcode im Auto</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475448/">In einem modernen Auto gibt es mehr Codezeilen als ...</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479736/">https://habr.com/ru/post/de479736/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479718/index.html">Erstellen einer Arduino-Umgebungsanwendung mit CI Github</a></li>
<li><a href="../de479724/index.html">Tru Hacker sind vorbei</a></li>
<li><a href="../de479726/index.html">Vladimir aka wowik: "OpenStreetMap braucht Ideen, die in anderen Systemen nicht umsetzbar sind"</a></li>
<li><a href="../de479728/index.html">Wie organisiere ich einen erfolgreichen Start?</a></li>
<li><a href="../de479732/index.html">Stellen Sie die Ausgabe von etwas anderem als Speicherverlust ein</a></li>
<li><a href="../de479738/index.html">Wie Youtube und Instagram: Internationalisierung und Lokalisierung einer Python-Anwendung</a></li>
<li><a href="../de479742/index.html">Backyards - ein automatisiertes Service-Mesh auf einer Multi-Cloud- und Hybrid-Infrastruktur</a></li>
<li><a href="../de479744/index.html">Python Memory Management: Ein wenig √ºber Speicherfragmentierung</a></li>
<li><a href="../de479746/index.html">Unternehmenssoftware macht Ihre Mitarbeiter k√ºhler. Brauchst du es</a></li>
<li><a href="../de479748/index.html">GoLand 2019.3 mit verbesserter Leistung, verbesserter Unterst√ºtzung f√ºr Go-Module und mehr</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
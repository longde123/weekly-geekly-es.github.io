<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🗞️ 🤦🏿 🥈 Die Zukunft des VR-Videos - Googles VR180 🌻 ◻️ 👂🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hinweis: Dieses GIF startet und stoppt beim Klicken 
 S3D: Kein Schmerz ist Gewinn 
 Im April dieses Jahres gab Google die technischen Details eines n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Zukunft des VR-Videos - Googles VR180</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429414/"><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Hinweis: Dieses GIF startet und stoppt beim Klicken</i> <br><h2>  S3D: Kein Schmerz ist Gewinn </h2><br>  Im April dieses Jahres gab Google die technischen Details eines neuen Formats für VR-Video bekannt - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VR180</a> .  Die Formatspezifikationen wurden in das <a href="">Google-</a> Repository <a href="">auf GitHub</a> hochgeladen, Kamerahersteller wurden gebeten, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">spezielle Kameras</a> herzustellen, das Format wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf YouTube unterstützt</a> . <br><br>  Die Grundidee ist ganz einfach.  Im „normalen“ VR-Video - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">360-Video</a> - können Sie Ihren Kopf horizontal in alle Richtungen drehen, während die Hauptaktion in der Regel von einer Seite aus erfolgt und der gesamte Stream an das Gerät übertragen wird, was zur Übertragung und Speicherung führt <i>redundante</i> Informationen.  Tatsächlich ist es in den allermeisten Fällen nicht erforderlich, die Anzeige bei 360 Grad zu implementieren - 180 Grad reichen völlig aus, um den gleichen Effekt zu erzielen.  In diesem Fall wird die "zweite Hälfte" des Rahmens für den zweiten Winkel verwendet, dh Stereo wird erhalten. <br><br>  Somit bietet das vorgeschlagene Format ein noch größeres Gefühl des Eintauchens als bei 360-Videos, ist billiger herzustellen, einfacher aufzunehmen und hat keine Probleme mit dem Zusammenfügen. <br><br>  Wie ist das möglich und was hat Google angeboten? <br><br>  Wen interessiert VR-Video für die nahe Zukunft? Willkommen bei Cat! <br><a name="habracut"></a><hr><br><h3>  Einführung in VR180 </h3><br>  Zuerst über das Gute. <br><br>  VR180 ist deutlich einfacher aufzunehmen als 360-Videos.  Bis zu 17 Kameras werden verwendet, um <i>qualitativ hochwertige</i> 360-Videos aufzunehmen (ein Beispiel von Xiaomi unten), was viele Probleme mit der Größe des Arbeitsvideos, teilweisem Ausfall, Überhitzung, instabilem Fokus der Kameras usw. verursacht. Darüber hinaus wurden sie aus Sicht eines einfachen Benutzers als die besten erkannt Kameras mit <i>zwei</i> Fischaugenobjektiven ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eins</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zwei</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">drei</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/734/e7d/81b/734e7d81b53a87373a6db0bb437f1ef9.png"><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a></i> <br><br>  Das neue Format wird auch mit zwei Kameras aufgenommen.  Dies reduziert die Kosten des Endgeräts erheblich.  Gleichzeitig wird die Aufnahmetechnik erheblich vereinfacht, da alle Tricks der Arbeit mit einer herkömmlichen Kamera relevant bleiben (nur das Ergebnis ist möglicherweise spektakulärer und mit großem Eintauchen).  Für den Erfolg des Formats ist es wichtig, dass jede Hausfrau und jeder Schüler es problemlos verwenden kann.  Je einfacher desto besser. <br><br>  Außerdem verschwinden in VR180 die Probleme des sogenannten Zusammenfügens (Klebens) - äußerst auffällige Artefakte an Stellen, an denen Bilder von zwei Kameras zusammengefügt wurden.  Bis vor kurzem schien es, als würde ein wenig Zeit vergehen und die Probleme beim Nähen würden gelöst sein.  Leider erwiesen sie sich als viel komplizierter.  Befindet sich an der Klebegrenze ein sich schnell bewegendes oder durchscheinendes Objekt, ist das Problem auf dem aktuellen Entwicklungsstand der Videoverarbeitungsalgorithmen im automatischen Modus nicht gelöst.  Natürlich entwickeln sich automatische Mattierungsalgorithmen weiter, aber das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fehlen von Artefakten ist selbst mit Deep Learning-Methoden nicht garantiert</a> .  In VR180 gibt es keine Nähte, was bedeutet, dass im Prinzip keine Probleme damit verbunden sind. <br><br>  Und schließlich ist fast immer aufgenommenes 360-Video flach.  Das heißt, unter dem Gesichtspunkt des binokularen Sehens wird das Bild als auf einem Bildschirm vor den Augen hängend wahrgenommen, was häufig den „Wow-Effekt“ und den Immersionseffekt verringert, und VR180 ist anfänglich und standardmäßig ein Stereoformat. <br><br>  All diese Punkte sehen sehr vielversprechend aus, um den Erfolg des Formats vorherzusagen.  Infolgedessen begannen die Hersteller ziemlich aktiv mit der Produktion von Kameras, die speziell auf VR180 ausgerichtet sind, zum Beispiel: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b10/28b/407/b1028b407ca2ce205b1fe4ad60b63234.jpg"><br>  Die Tatsache, dass <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Xiaomi in den</a> VR180-Markt eingetreten ist, ist sicherlich ermutigend. <br><br>  Es gibt auch Lösungen, mit denen Sie die Kamera für die Aufnahme von VR180 von zwei normalen Kameras mit Fischaugenobjektiven zusammenbauen können.  Manchmal reicht es aus, nur eine Halterung zu drucken oder zu kaufen, um Experimente zu starten (unten finden Sie Beispiele für GoPro, digitale „Seifenschalen“, Sony-Spiegel): <br><br><img width="350" src="https://habrastorage.org/getpro/habr/post_images/c56/203/79f/c5620379ff975402bc5cc64ec1569402.png"><img width="200" src="https://habrastorage.org/getpro/habr/post_images/18c/958/22d/18c95822df38b1f5cd14a0ff8a3c2f35.png"><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a></i> <i><br><br><img width="350" src="https://habrastorage.org/getpro/habr/post_images/012/b94/ec3/012b94ec3ba8beea3ca942fe4decb7f2.png"><img width="350" src="https://habrastorage.org/getpro/habr/post_images/35d/0cd/5dc/35d0cd5dc25cb5347555a7ab7be258fd.png"><br></i>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://products.entaniya.co.jp/en/products/equipment-for-3d-stereo-180-vr/</a></i> <br><br>  Darüber hinaus gab es lustige Lösungen, wenn eine Kamera Aufnahmen in den Videoformaten VR180 und 360 unterstützt (dies ist eine „Clamshell“, die 360 ​​in einem minimierten Zustand und VR180 in einem erweiterten Zustand aufnimmt): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/11b/823/176/11b823176e464b8c5a1dfa2f14a98020.png"><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a></i> <br><br>  Unter anderem haben sich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neue Horizonte</a> für das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Experimentieren</a> mit VR-Videos eröffnet (auf dem Foto der Xiaomi YI Horizon VR180-Kamera): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0ea/eb7/7e7/0eaeb77e7bfb367f1441e51f1cc477ba.png"><br><br>  Die Anzahl der neuen Geräte für Aufnahmen in VR180 ist sehr groß, und dies trägt erheblich zur Popularität des neuen Formats bei. <br><br><h3>  Die Einführung von VR180 </h3><br>  Unternehmen versuchen heute, VR wo immer möglich zu implementieren. Sie möchten das Format populärer und verbreiteter machen.  Und vor allem - billig.  Google ist keine Ausnahme.  Jeder erinnert sich an seine Budgetentscheidung, das „Head Mounted Display, HMD“ allgemein zu verwenden - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Cardboard</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c8d/f8a/ce5/c8df8ace5b7baf7919154161cad7ac8a.jpg"><br><br>  Die Funktionalität ist natürlich nicht mit teuren HMDs zu vergleichen, aber das Hauptziel wurde erreicht: VR zugänglicher zu machen und jedes Smartphone gegen einen Aufpreis von weniger als 1 US-Dollar in einen Virtual-Reality-Helm zu verwandeln. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufbauend</a> auf dem Erfolg startet Google ein neues <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VR180-</a> Format mit Unterstützung für Uploads auf YouTube und einem speziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Suchfilter</a> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/730/a18/326/730a18326df42eabebb44a9ce584d228.jpg"><br><br>  So sieht der Videorahmen des neuen Formats „von innen“ aus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a63/22a/6c1/a6322a6c1f0bee9d3be7bbbcaaf7c7c9.jpg"><br>  <i>In MP4 wurden spezielle Metadaten hinzugefügt, die das Video in ein sphärisches verwandeln.</i>  <i>Wenn Sie einfach dem Link folgen, sehen Sie im Allgemeinen höchstwahrscheinlich ein normales flaches Video. Dies liegt daran, dass zusätzlich zum VR180-Video auch eine Projektion eines der Winkel (links) auf ein reguläres Rechteck auf die Site hochgeladen wird.</i>  <i>Um das Bild wie in der Abbildung oben zu sehen, müssen Sie beispielsweise das Video im reinen MP4-Format herunterladen.</i>  <i>Grundsätzlich haben sie eine Auflösung von 4K.</i>  <i>Die Möglichkeit, die Kamera zu bewegen, wird garantiert angezeigt, wenn sie mit der Cardboard-Anwendung ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Play</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AppStore</a> ) auf einem mobilen Gerät angezeigt wird.</i>  <i>Natürlich in einem vollwertigen HMD.</i> <br><br>  Das Aufnehmen solcher Videos, ähnlich wie bei Papphelmen, hätte sich auch als billig genug <i>für eine breite Verbreitung unter den Nutzern</i> herausstellen müssen <i>.</i>  Eine Kamera, die Videos in diesem Format aufnimmt, kostet etwa 300 US-Dollar.  Im Vergleich zu teuren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stereogames ist</a> dies ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">völlig</a> neues Level.  Es scheint, dass alles in Ordnung ist.  Das Problem ist jedoch, dass das neue Format ein Stereoformat ist und Stereo, wie Sie wissen, viele schwierige Probleme zu lösen sind. <br><br><hr><br><h2>  Stereoqualität in VR </h2><br>  Sobald es um Stereo geht (im allgemeinen Sprachgebrauch 3D), erinnert man sich sofort an die <i>Kopfschmerzen</i> beim <i>Besuch</i> von 3D-Kinos.  Wir haben die Ursachen für solche Beschwerden in einer großen Reihe von Artikeln ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eins</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zwei</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">drei</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vier</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fünf</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sechs</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sieben</a> ) viel detaillierter untersucht, jedoch im Hinblick auf Stereofilme.  Kurz gesagt, aus einer Reihe von Gründen werden viele 3D-Filme erstellt (oder konvertiert), sodass Zuschauer, die für Artefakte von Stereovideos empfindlich sind, Citramon nur im Voraus mitnehmen können.  Leider hängen die meisten Probleme in 3D-Filmen mit stereoskopischen Artefakten zusammen, die auch in VR180 zu finden sind.  Alle Faktoren, die in solchen Filmen Unbehagen verursachen, verursachen auch Unbehagen beim Ansehen eines Videos in der virtuellen Realität.  Selbst eine grundlegende Überprüfung der Qualität des Inhalts des VR180 ergab, dass er mit der Qualität herkömmlicher Stereoanlagen um die Mitte des letzten Jahrhunderts vergleichbar ist ... <br><br>  Mit anderen Worten, Enthusiasten werden begeistert sein, aber das Massenpublikum wird sich beschweren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6c1/86f/3aa/6c186f3aac2da8e239806d04d0a8a86c.png"><br><br>  Zur Analyse der Qualität von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stereovideos</a> verwendeten wir das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VQMT3D-</a> Projekt, das in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Videogruppe des</a> Computergrafik- und Multimediallabors an der Fakultät des VMK der Moskauer Staatlichen Universität entwickelt wird.  Ziel ist es, Autoren von Stereofilmen die Möglichkeit zu geben, das Auftreten <i>aller</i> möglichen Artefakte in der Postproduktion zu verfolgen.  Und da der VR180 auch Stereo ist, ist das Projekt mit einigen Vorbehalten de facto auf dieses Format anwendbar.  In den folgenden Beispielen werden Rahmeninformationen unter Verwendung von VQMT3D erhalten. <br><br><h3>  Farbverzerrung </h3><br>  Dieses Problem ist am einfachsten zu verstehen und relativ einfach zu beheben.  Schließe ein Auge und betrachte ein Objekt.  Machen Sie jetzt dasselbe mit dem anderen Auge und beantworten Sie die Frage: Ändern sich die Farben, wenn sich das Auge ändert?  Im allgemeinen Fall nein.  In Stereovideos sollte es also keine Unterschiede in der Farbe derselben Objekte für den linken und rechten Winkel geben.  Folgendes sehen wir jedoch in echten Videos, die auf YouTube aufgenommen wurden (achten Sie auf feste Bereiche wie Himmel oder Wasser): <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/f03/477/ad7/f03477ad7026ba738bc5c12acfa3d9d5.gif"><img width="375" src="https://habrastorage.org/getpro/habr/post_images/6bf/29d/62d/6bf29d62dcf87019a9e1fd47789b6985.gif"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Videolink</i></a> <br><br>  Farbverzerrungen können aus vielen Gründen auftreten, beispielsweise aufgrund der unterschiedlichen Kalibrierung von Kameras, der Erwärmung ihrer Matrizen oder wenn der Rand des Objektivs Licht ausgesetzt ist.  Selbst bei identischen Aufnahmeparametern für dieselben Kameras können die Farben daher merklich abweichen. <br><br>  Es ist am bequemsten, dieses Artefakt mit einem „Schachbrett“ zu visualisieren, wenn der rechte Winkel mithilfe der Bewegungskompensation nach links reduziert wird und dann Blöcke aus dem linken und reduzierten rechten Winkel in einem Schachbrettmuster ausgewählt werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/657/794/736/65779473673ce18a736244f1647c7aed.jpg"><br><br>  Unten sehen Sie ein Beispiel, wenn Lichtquellen in den Rahmen fallen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4c8/e04/9fb/4c8e049fb604687f8bc79545d7359364.gif"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Videolink</i></a> <br><br>  Die Lichtquellen selbst sind nicht nur in verschiedenen Winkeln sehr unterschiedlich, sondern verzerren auch die Farben im gesamten Bild mit Blendung. <br><br>  Ein härteres Beispiel, wenn die Sonne auf den Rahmen trifft: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/92f/a76/7bb/92fa767bbb1a166b776c054969cbbf55.gif"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Videolink</i></a> <br><br>  Aufgrund der erfolglosen Einstellung der Kamera gegenüber der Sonne entsteht ein schreckliches Artefakt in Form einer roten Markierung auf der Matrix.  Farbverzerrungen sind im wirklichen Leben ziemlich selten, und Artefakte des oben angegebenen Typs werden überhaupt nicht gefunden, was letztendlich zu einer Anhäufung von Müdigkeit beim Betrachten führt.  Leider wird Müdigkeit im empfindlichsten Teil des Publikums zu Kopfschmerzen. <br><br><h3>  Schärfedifferenzen </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f1a/d33/d03/f1ad33d03b27e40fb7c8c4b0ba0b130e.png"><br><br>  Ein weiteres Problem, das bei der Aufnahme von Stereovideos auftritt, ist der Unterschied in der Schärfe im linken und rechten Winkel.  Im wirklichen Leben ist dieses Problem ziemlich häufig.  Wenn Sie beispielsweise 10 bis 12 Stunden am Computer sitzen und aufmerksam auf den Bildschirm schauen <i>(</i> Sie müssen <i>zustimmen, dass dies passiert)</i> , können am Ende des Tages das rechte und das linke Auge merklich voneinander abweichen, und bis zum Abend ist eine leichte Kurzsichtigkeit / Weitsichtigkeit gewährleistet.  Gleichzeitig kompensiert das Gehirn dieses Problem erfolgreich.  Relativ gesehen erhalten wir klare Bilddetails vom rechten oder linken Auge für entfernte / nahe Objekte.  Das heißt, in der Ingenieursprache wird das Problem regelmäßig durch integrierte Tools gelöst.  Und am Morgen wird in der Regel das Sehvermögen wiederhergestellt.  Und alles wäre in Ordnung, aber in echten Stereovideos kann der Fokus von Szene zu Szene „springen“.  Es stellt sich heraus, dass das "Rechtssichtige" entweder das rechte, dann das linke Auge wird und manchmal beide gut sehen, was zu spürbaren Beschwerden beim Betrachten führt.  Besonders für Menschen im Alter, deren Augen bereits "stationär" in der Schärfe auseinander gegangen sind. <br><br>  Beispiele für Diskrepanzen bei VR180, bei denen zur besseren Visualisierung vergrößerte Fragmente desselben Bereichs für zwei Winkel dargestellt werden: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/5d6/64a/c4c/5d664ac4c052e0d892908412ea27e38d.jpg"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Videolink</i></a> <br><br>  Hier ist ein weiteres Stück dieses Rahmens: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/113/69f/780/11369f780651fe4438657d65da6ba2f1.jpg"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Videolink</i></a> <br><br>  Das Auftreten dieses Artefakts ist auf die unterschiedliche Ausrichtung des Fokus der Kameras aus technischen Gründen zurückzuführen.  Und aufgrund des Mangels an professioneller Nachbearbeitung werden sogar „vyrviglaznye“ -Szenen auf YouTube veröffentlicht. <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/2b9/de6/6f0/2b9de66f0f028e8c71d5af546fbff7de.jpg"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Videolink</i></a> <br><br>  Fast alle Beschriftungen auf dem vergrößerten Bild variieren in der Schärfe.  Achten Sie auf die Aufschrift "12 CH", die beim Betrachten für "Strobe" unangenehm ist. <br><br><h3>  Zeitverschiebung </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/a88/ce0/a5c/a88ce0a5c0cc0f3de0029c42d51577fe.png"><br><br>  Seltsamerweise schießen Stereokameras, obwohl Computerkerne seit langer Zeit erfolgreich für Millionen von Sekunden synchronisiert wurden, immer noch in Hundertstel oder sogar Zehntelsekunden, wenn sie aufgenommen werden.  Ein Auge sieht Ereignisse, die für das andere Auge noch nicht aufgetreten sind!  Sie können sich in der realen Welt nicht einmal ein Analogon für dieses Problem vorstellen.  Und dieses Artefakt wurde auch in VR180 gefunden. <br><br>  Achten Sie auf das Fenster mit einer Leuchtreklame auf der rechten Seite des Rahmens: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/593/d03/220/593d032205583a0d23fc623bc10d0453.gif"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Videolink</i></a> <br><br>  Diese Zeitverschiebung wurde zufällig bei der Analyse der Farbdiskrepanz bemerkt, die auch hier vorhanden ist.  Ein flackerndes Zeichen fällt auch ohne die Verwendung spezieller Metriken auf, die darauf abzielen, eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorübergehende Verschiebung zu finden</a> .  Der linke Rahmen befindet sich einfach hinter dem rechten! <br><br>  Hier ist ein weiteres Beispiel aus derselben Szene.  Schauen Sie sich den Fuß der Fußgänger an: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c6/473/b7e/3c6473b7e10a178c8d4ce599940eca59.gif"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Videolink</i></a> <br><br>  Hier ist deutlich zu erkennen, dass der Fuß auf dem rechten Rahmen weiter bewegt wird als auf dem linken, als ob ein Rahmen mehrere Momente hinter dem anderen liegt, obwohl sie genau im selben Moment hätten geschossen werden müssen.  Wir führten ein Experiment durch, in dem wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">302 Zuschauern kurze Fragmente von Stereofilmen mit verschiedenen Artefakten zeigten</a> und nach jedem Fragment von einem Smartphone / Laptop ein Formular ausfüllten, in dem das Ausmaß der Schmerzen angegeben wurde.  Die Zeitverschiebung hat sich als das schmerzhafteste Artefakt erwiesen - dies ist eine unmögliche Situation für das Gehirn und der Versuch, sie zu „verarbeiten“, führt zu einem deutlichen spürbaren Unbehagen.  Leider ist meistens eine Verschiebung von weniger als einem Frame üblich, und es ist nicht so einfach, sie zu beheben. <br><br>  Übrigens kann im obigen Beispiel der Rahmen auch mit bloßem Auge zwischen den Kamerawinkeln (insbesondere in der unteren linken Ecke) gesehen werden, was ebenfalls sehr unangenehm ist, aber viel einfacher zu fixieren ist.  Andere Artefakte sind jedoch eine separate große Geschichte, auf die wir hoffentlich zurückkommen werden. <br><br><h3>  Google "durcheinander"? </h3><br>  Es scheint, dass diese Artefakte dem Video eigen sind, das während der Amateuraufnahmen aufgenommen wurde, und bei korrekter Verwendung können dieselben Kameras ein gutes Bild liefern.  Dies ist leider nicht so.  Hier ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Werbevideoclip im VR180-Format</a> , der sich auf der offiziellen Seite von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VR180 befindet</a> .  Es scheint, dass er den Qualitätsstandard setzen sollte.  Aber wenn Sie genau hinschauen ... <br><br>  Farbabweichungen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6e8/f77/405/6e8f774055e0fe2e4977c3710749e5e6.gif"><br><br>  Absolut an allen Stellen kommt es zu einer Farbverzerrung.  Als ob eine der Verkürzungen fälschlicherweise einen etwas größeren Weißabgleich eingestellt hätte. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8d5/70c/f57/8d570cf578fb0d68451bf251e063bdc0.gif"><br><br>  Und hier ist schon der Großteil des Rahmens ohne Verzerrung.  Die untere rechte Ecke unterscheidet sich jedoch immer noch merklich in der Farbe, was beim Betrachten zu einem charakteristischen visuellen „Stroboskopieren“ führt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fe6/859/931/fe6859931d6610cb080bc89228b6c3ce.gif"><br><br>  Es ist bemerkenswert, dass die Farbverzerrung auf der Straße auch ohne spezielle Werkzeuge für die Stereoanalyse festgestellt wurde.  Es wurde einfach durch Betrachten eines Videos Frame für Frame entdeckt (ähnlich wie bei der Verarbeitung von Videos mit unterschiedlichen Parametern). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2b7/640/6e7/2b76406e7c1278b19238d8a27ccace2d.gif"><br><br>  Schärfedifferenzen: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/135/413/1c8/1354131c850ef820368e9f327fbc0924.jpg"><br><br>  Hier macht sich die Diskrepanz am deutlichsten auf dem Boden und an den Nähten des Sofas bemerkbar.  Der größte Unterschied in der Schärfe liegt genau an den Grenzen von Objekten. <br><br><hr><br><h2>  Fazit </h2><br><h3>  Was haben wir am Ende? </h3><br>  VR, einschließlich 360-Video, wird aktiv verbreitet.  Die Technologie zieht Benutzer an und sieht sehr vielversprechend aus.  Die technische Qualität der aktuellen Implementierung führt jedoch zu Unannehmlichkeiten beim Anzeigen.  Infolgedessen bekommt eine bestimmte Anzahl von Personen, die an einem neuen Format interessiert sind, Kopfschmerzen, und wenn die Aufnahme nicht erfolgreich ist (normalerweise mit einer scharfen Kamerabewegung) - zusätzlich zu Schwindel und Übelkeit, was zu Enttäuschungen im Format führt. <br><br><h3>  Was kann man damit machen? </h3><br>  Derzeit entwickeln viele (einschließlich uns) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tools zur Qualitätskontrolle</a> sowie zur Behebung von Stereoproblemen. <br><br>  Hier zum Beispiel Farbkorrekturbeispiele: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/14e/cd4/a84/14ecd4a84719b9484448d884bcb48660.gif"><br><br>  Links sind die ursprünglichen Winkel, rechts sind farbkorrigiert mit unserem Algorithmus.  Der hervorgehobene Winkel wird vollständig korrigiert. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad0/867/73d/ad086773d4c04306fbd6af8d7c3ad03b.gif"><br><br>  Die Farbe an der Decke prallte zurück. <br><br><img src="https://habrastorage.org/webt/6j/0y/lz/6j0ylz9d22ongb5vdvt8kbiywic.gif"><br><br>  Weitere Beispiele für die automatische Farbkorrektur finden Sie im separaten Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zur Farbverzerrung in Stereo</a> . <br><br>  Insgesamt werden derzeit etwa 20 Arten von Artefakten von aufgenommenen und konvertierten Stereovideos erkannt, von denen die meisten auch für VR180 relevant sind.  In Zukunft ist geplant, die Methoden zur Überwachung und Verbesserung der Qualität von VR-Videos zu erweitern: <br><br><ul><li>  Anpassung der aktuellen Qualitätskontrollmethoden an VR <br></li><li>  Hinzufügung und Implementierung von Artefaktkorrekturmethoden <br></li><li>  Automatische Berichterstattung über Videos mit der Vorhersage von Schmerzen, die durch das Betrachten verursacht werden, um Benutzer zu warnen und den Inhalt von Herstellern zu bewerten, um sie zu motivieren, bei der Qualität vorsichtiger zu sein <br></li></ul><br><h3>  Wie sind die Aussichten für das Format insgesamt? </h3><br>  Offensichtlich sind die aktuellen Probleme die Probleme der Kindheit der Technologie und werden aktiv angegangen.  Es ist zu erwarten, dass: <br><br><ul><li>  Kamerahersteller werden Software liefern, die einige der grundlegenden Probleme löst <br></li><li>  Im Laufe der Zeit (wenn Bedarf besteht) wird professionelle Software zur Korrektur von Artefakten angezeigt <br></li><li>  Es ist sehr wahrscheinlich, dass YouTube beim Laden von VR180-Videos automatisch eine Artefaktkorrektur implementiert, ähnlich wie der Jitter und das Interlacing guter alter 2D-Videos jetzt automatisch behoben werden <br></li></ul><br>  Vom Lustigen: Jetzt gibt es eine Mode für Smartphones mit 3-4 Kameras auf der Rückseite, die die Qualität der Fotos dramatisch verbessern. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7b8/284/72d/7b828472d1d82aa42dd58363b8044f4d.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Samsung Galaxy A7</a> (2018) und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Samsung Galaxy A9</a> (2018)</i> <br><br>  Es ist logisch zu erwarten, dass mit der zunehmenden Beliebtheit des VR180 seine Unterstützung "out of the box" in alle wichtigen Smartphone-Modelle integriert wird. <br><br>  <i>Ja,</i> höchstwahrscheinlich beträgt der Blickwinkel nicht 180 °, sondern weniger. <br>  <i>Ja,</i> höchstwahrscheinlich ist die Qualität schlechter als bei Spezialkameras. <br>  <i>Ja, für die</i> Aufnahme von Stereovideos müssen große Informationsströme komprimiert werden (für die heutige Smartphones immer noch schlecht ausgelegt sind). <br>  <i>Ja,</i> Sie müssen zwei Weitwinkelkameras in größerer Entfernung aufstellen. <br>  Technisch gesehen gibt es heute keine ernsthaften Hindernisse für die Implementierung der VR180-Unterstützung in den Flaggschiffmodellen.  Die Frage ist nur die wachsende Beliebtheit des Formats, so dass die Nachfrage massiv wird und ein Anreiz dafür entsteht. <br><br>  Und es ist klar, dass die Anzahl der relevanten Videos auf YouTube wie eine Lawine zunehmen wird, wenn die Top-End-Smartphones anfangen, VR180-Aufnahmen zu unterstützen. <br><br>  Auch auf den Ausstellungen können Sie autostereoskopische Displays von Smartphones und Tablets sehen, die mit zunehmender Auflösung immer interessanter werden.  Zumindest kann es nicht mit dem verglichen werden, was <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2010-2011</a> während der letzten Welle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in Massen beobachtet werden</a> konnte.  Zum Zeitpunkt dieses Schreibens wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RED Hydrogen One</a> angekündigt - das erste SERIAL-Smartphone mit einem 3D-Bildschirm der neuen Generation, sodass die Möglichkeit bestand, das zu kaufen, was Profis auf den Ausstellungen sahen.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Prozess ist noch nicht abgeschlossen und wird mit zunehmender Bildschirmauflösung sicherlich schneller gehen. </font><font style="vertical-align: inherit;">Das Haupthindernis ist der Mangel an Inhalten. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Offensichtlich wird dieses „Henne-Ei“ -Problem bald gelöst sein.</font></font><br><br><hr><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Allgemeine Schlussfolgerungen: </font></font></h2><br><h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> VR180 bietet die folgenden wesentlichen Vorteile: </font></font></h5><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Deutlich höheres Eintauchen in 3D für VR180 im Vergleich zu 360-Videos </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Es gibt keine Artefakte beim Zusammenfügen (Kleben) von Videos von mehreren Kameras </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> VR180-Kameras sind billig genug und billiger </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das Aufnehmen von VR180 kommt dem Aufnehmen mit einer normalen Kamera deutlich näher und ist für Laien viel einfacher, dh eine große Masse von Fans kann ihr Video relativ einfach im VR180-Format aufnehmen </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mit der Zeit können Sie die Unterstützung von VR180 in Smartphones erwarten </font></font><br></li><li>        ,    VR180     (         ,        ) <br></li></ul><br><h5>  VR180: </h5><br><ul><li>      ,      <br></li><li>          VR180   .           ,     ,   ,     … <br></li></ul><br><h5>  Gesamt: </h5><br><ul><li>  VR180     ,      , ,   ,      «»    <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit der zunehmenden Beliebtheit von VR180 können viele der "Kinderprobleme", einschließlich der Probleme im Zusammenhang mit Stereo, auch ohne die Teilnahme von Benutzern relativ einfach gelöst werden, einfach beim Hochladen von Videos. </font><font style="vertical-align: inherit;">Algorithmisch ist das schon möglich</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Popularität des Formats beruht auf dem Problem „Huhn und Eier“: Es sollten genügend Geräte zum Aufnehmen und Anzeigen angezeigt werden. </font><font style="vertical-align: inherit;">Gleichzeitig wird es im Gegensatz zu 360-Video-VR180 technisch bald einfach sein, auf jedem Smartphone zu fotografieren. </font><font style="vertical-align: inherit;">Und wenn Google Pixel 5 XL VR180 "out of the box" unterstützt, ist dies selbstverständlich</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Als Ergebnis: Langfristig ist 10 Jahre VR180 zur Popularität verurteilt! </font></font><br></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Weniger Kopfschmerzen für alle! </font></font><br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ihre Konstantin Kozhemyakov und Dmitry Vatolin</font></font></i> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> PS Danksagung </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ich möchte mich herzlich bedanken bei: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> unserer Kollegen aus der Videogruppe, dank derer die oben vorgestellten Algorithmen erstellt und die Ergebnisse berechnet wurden, </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Google für die Artefakte des VR180-Werbespots und für die Werbung für neue Formate, egal was passiert, </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Labor für Computergrafik VMK Moscow State University </font><font style="vertical-align: inherit;">MV Lomonosov für Rechenleistung und nicht nur</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Vitaliy Ludvichenko für den entwickelten Farbkorrekturalgorithmus in Stereovideo, </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und schließlich Alexander Ploshkin, Sergey Lavrushkin, Jegor Sklyarov, Aidar Khatiullin, Ivan Molodetsky und Evgeny Lyapustin für eine große Anzahl vernünftiger Kommentare und Korrekturen, die diesen Text viel besser gemacht haben! </font></font><br></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Siehe auch: </font></font><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum 3D-Kopfschmerzen / Teil 1: Hardware-Nachteile</font></font></a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum 3D-Kopfschmerzen / Teil 2: Beschwerden aufgrund der Videoqualität</font></font></a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum 3D-Kopfschmerzen / Teil 3: Verwirrte Winkel</font></font></a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum 3D-Kopfschmerzen / Teil 4: Parallaxe</font></font></a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum 3D-Kopfschmerz / Teil 5: Geometrische Verzerrung in Stereo</font></font></a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum 3D-Kopfschmerzen / Teil 6: Farbverzerrung</font></font></a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum 3D-Kopfschmerzen / Teil 7: Zeitverschiebung zwischen Winkeln</font></font></a> <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429414/">https://habr.com/ru/post/de429414/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429400/index.html">Seals vs neuronales Netzwerk 2. Oder führen Sie SqueezeNet v.1.1 auf Raspberry Zero in Echtzeit aus (fast)</a></li>
<li><a href="../de429402/index.html">ML.NET 0.7 (Maschinelles Lernen .NET)</a></li>
<li><a href="../de429404/index.html">8 Sek. ½ Möglichkeiten zur Priorisierung der Funktionalität</a></li>
<li><a href="../de429406/index.html">"Monster in Spielen oder wie man Angst erzeugt"</a></li>
<li><a href="../de429410/index.html">22 Port SSH zu tragen oder nicht</a></li>
<li><a href="../de429416/index.html">Erstellen Sie einen Chatbot mit Azure Bot</a></li>
<li><a href="../de429418/index.html">.NET Standard 2.1</a></li>
<li><a href="../de429420/index.html">PlayStation Classic verwendet den PCSX ReARMed-Emulator für die Arbeit, keine proprietären Lösungen</a></li>
<li><a href="../de429422/index.html">UHCI oder der allererste USB</a></li>
<li><a href="../de429424/index.html">Robotaxi von Daimler und Bosch wird in Kalifornien auftreten</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
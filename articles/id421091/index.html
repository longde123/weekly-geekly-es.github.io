<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👃 🐒 🎮 Bagaimana kami mengurangi waktu untuk mengembangkan model penilaian lima kali dengan beralih ke Python ❄️ 🆎 ☠️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sekarang semua orang berbicara banyak tentang kecerdasan buatan dan penerapannya di semua bidang perusahaan. Namun, ada beberapa daerah di mana, sejak...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana kami mengurangi waktu untuk mengembangkan model penilaian lima kali dengan beralih ke Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/idfinance/blog/421091/"><img src="https://habrastorage.org/webt/-z/kh/d3/-zkhd3-g2bfo-piumvjuva0iei4.png" alt="gambar"><br><br>  Sekarang semua orang berbicara banyak tentang kecerdasan buatan dan penerapannya di semua bidang perusahaan.  Namun, ada beberapa daerah di mana, sejak zaman kuno, satu jenis model telah mendominasi, yang disebut "kotak putih" - regresi logistik.  Salah satu bidang tersebut adalah penilaian kredit bank. <br><a name="habracut"></a><br>  Ada beberapa alasan untuk ini: <br><br><ul><li>  Koefisien regresi dapat dengan mudah dijelaskan, tidak seperti kotak hitam seperti meningkatkan, yang dapat mencakup lebih dari 500 variabel </li><li>  Pembelajaran mesin masih belum dipercaya oleh manajemen karena kesulitan dalam menafsirkan model </li><li>  Ada persyaratan tidak tertulis dari regulator untuk interpretabilitas model: kapan saja, misalnya, Bank Sentral dapat meminta penjelasan - mengapa pinjaman kepada peminjam ditolak </li><li> Perusahaan menggunakan program penambangan data eksternal (misalnya, penambang cepat, SAS Enterprise Miner, STATISTICA atau paket lainnya) yang memungkinkan Anda mempelajari cara membuat model dengan cepat, bahkan tanpa keterampilan pemrograman </li></ul><br>  Alasan-alasan ini membuat hampir tidak mungkin untuk menggunakan model pembelajaran mesin yang kompleks di beberapa bidang, jadi penting untuk dapat "memeras maksimal" dari regresi logistik sederhana, yang mudah dijelaskan dan ditafsirkan. <br><br>  Dalam posting ini, kita akan berbicara tentang bagaimana, ketika membangun skor, kita meninggalkan paket penambangan data eksternal yang mendukung solusi open source dalam bentuk Python, meningkatkan kecepatan pengembangan beberapa kali, dan juga meningkatkan kualitas semua model. <br><br><h3>  Proses penilaian </h3><br>  Proses klasik membangun model penilaian pada regresi terlihat seperti ini: <br><br><img src="https://habrastorage.org/webt/jn/e2/da/jne2da4ifmsjuhgui2piws8kbsi.png" alt="gambar"><br><br>  Ini dapat bervariasi dari perusahaan ke perusahaan, tetapi tahap utama tetap konstan.  Kita selalu perlu melakukan binning variabel (berbeda dengan paradigma pembelajaran mesin, di mana dalam kebanyakan kasus hanya pengkodean kategoris diperlukan), penyaringan mereka dengan Nilai Informasi (IV), dan unggahan manual semua koefisien dan nampan untuk integrasi selanjutnya ke dalam DSL. <br>  Pendekatan untuk membangun kartu penilaian ini bekerja dengan baik di tahun 90-an, tetapi teknologi paket penambangan data klasik sudah sangat ketinggalan zaman dan tidak memungkinkan penggunaan teknik baru, seperti, misalnya, regularisasi L2 dalam regresi, yang secara signifikan dapat meningkatkan kualitas model. <br><br>  Pada satu titik, sebagai studi, kami memutuskan untuk mereproduksi semua langkah yang dilakukan analis ketika membangun penilaian, melengkapi mereka dengan pengetahuan Data Scientists, dan mengotomatiskan seluruh proses sebanyak mungkin. <br><br><h3>  Peningkatan python </h3><br>  Sebagai alat pengembangan, kami memilih Python karena kesederhanaan dan perpustakaan yang bagus, dan mulai memainkan semua langkah secara berurutan. <br><br>  Langkah pertama adalah mengumpulkan data dan menghasilkan variabel - tahap ini adalah bagian penting dari pekerjaan analis. <br><br>  Dengan Python, Anda bisa memuat data yang dikumpulkan dari database menggunakan pymysql. <br><br><div class="spoiler">  <b class="spoiler_title">Kode untuk diunduh dari database</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">con</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> conn = pymysql.connect( host=<span class="hljs-string"><span class="hljs-string">'10.100.10.100'</span></span>, port=<span class="hljs-number"><span class="hljs-number">3306</span></span>, user=<span class="hljs-string"><span class="hljs-string">'******* '</span></span>, password=<span class="hljs-string"><span class="hljs-string">'*****'</span></span>, db=<span class="hljs-string"><span class="hljs-string">'mysql'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> conn; df = pd.read_sql(<span class="hljs-string"><span class="hljs-string">''' SELECT * FROM idf_ru.data_for_scoring '''</span></span>, con=con())</code> </pre> <br></div></div><br>  Selanjutnya, kami mengganti nilai langka dan hilang dengan kategori terpisah untuk mencegah ovefitting, pilih target, hapus kolom tambahan, dan bagi dengan kereta dan uji. <br><br><div class="spoiler">  <b class="spoiler_title">Persiapan data</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">filling</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df)</span></span></span><span class="hljs-function">:</span></span> cat_vars = df.select_dtypes(include=[object]).columns num_vars = df.select_dtypes(include=[np.number]).columns df[cat_vars] = df[cat_vars].fillna(<span class="hljs-string"><span class="hljs-string">'_MISSING_'</span></span>) df[num_vars] = df[num_vars].fillna(np.nan) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">replace_not_frequent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, cols, perc_min=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, value_to_replace = </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"_ELSE_"</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> else_df = pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'var'</span></span>, <span class="hljs-string"><span class="hljs-string">'list'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> cols: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i != <span class="hljs-string"><span class="hljs-string">'date_requested'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> i != <span class="hljs-string"><span class="hljs-string">'credit_id'</span></span>: t = df[i].value_counts(normalize=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) q = list(t[t.values &lt; perc_min/<span class="hljs-number"><span class="hljs-number">100</span></span>].index) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> q: else_df = else_df.append(pd.DataFrame([[i, q]], columns=[<span class="hljs-string"><span class="hljs-string">'var'</span></span>, <span class="hljs-string"><span class="hljs-string">'list'</span></span>])) df.loc[df[i].value_counts(normalize=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)[df[i]].values &lt; perc_min/<span class="hljs-number"><span class="hljs-number">100</span></span>, i] =value_to_replace else_df = else_df.set_index(<span class="hljs-string"><span class="hljs-string">'var'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df, else_df cat_vars = df.select_dtypes(include=[object]).columns df = filling(df) df, else_df = replace_not_frequent_2(df, cat_vars) df.drop([<span class="hljs-string"><span class="hljs-string">'credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'target_value'</span></span>, <span class="hljs-string"><span class="hljs-string">'bor_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bchg_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'last_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bcacr_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bor_bonuses_got'</span></span> ], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=<span class="hljs-number"><span class="hljs-number">0.33</span></span>, stratify=df.y, random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>)</code> </pre> <br></div></div><br>  Sekarang mulailah tahap yang paling penting dalam penilaian untuk regresi - Anda perlu menulis biner WOE untuk variabel numerik dan kategori.  Dalam domain publik, kami tidak menemukan opsi yang baik dan cocok untuk kami dan memutuskan untuk menulis sendiri.  Artikel 2017 ini diambil sebagai dasar binning numerik, dan juga kategoris ini, mereka sendiri menulis dari awal.  Hasilnya mengesankan (Gini pada tes naik 3-5 dibandingkan dengan algoritma binning dari program penambangan data eksternal). <br><br>  Setelah itu, Anda dapat melihat grafik atau tabel (yang kemudian kami tulis dalam excel) bagaimana variabel dibagi menjadi kelompok-kelompok dan memeriksa monotonnya: <br><br><img src="https://habrastorage.org/webt/da/ij/2u/daij2uewkyujfn3jhdapc-yyfia.png" alt="gambar"><br><br><img src="https://habrastorage.org/webt/c6/if/3u/c6if3uqy--eqewru4nm9au1gwgw.png" alt="gambar"><br><br><div class="spoiler">  <b class="spoiler_title">Bagan Rendering Bean</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_bin</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ev, for_excel=False)</span></span></span><span class="hljs-function">:</span></span> ind = np.arange(len(ev.index)) width = <span class="hljs-number"><span class="hljs-number">0.35</span></span> fig, ax1 = plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>)) ax2 = ax1.twinx() p1 = ax1.bar(ind, ev[<span class="hljs-string"><span class="hljs-string">'NONEVENT'</span></span>], width, color=(<span class="hljs-number"><span class="hljs-number">24</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">192</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">196</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>)) p2 = ax1.bar(ind, ev[<span class="hljs-string"><span class="hljs-string">'EVENT'</span></span>], width, bottom=ev[<span class="hljs-string"><span class="hljs-string">'NONEVENT'</span></span>], color=(<span class="hljs-number"><span class="hljs-number">246</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">115</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>)) ax1.set_ylabel(<span class="hljs-string"><span class="hljs-string">'Event Distribution'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">15</span></span>) ax2.set_ylabel(<span class="hljs-string"><span class="hljs-string">'WOE'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">15</span></span>) plt.title(list(ev.VAR_NAME)[<span class="hljs-number"><span class="hljs-number">0</span></span>], fontsize=<span class="hljs-number"><span class="hljs-number">20</span></span>) ax2.plot(ind, ev[<span class="hljs-string"><span class="hljs-string">'WOE'</span></span>], marker=<span class="hljs-string"><span class="hljs-string">'o'</span></span>, color=<span class="hljs-string"><span class="hljs-string">'blue'</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Legend plt.legend((p2[0], p1[0]), ('bad', 'good'), loc='best', fontsize=10) #Set xticklabels q = list() for i in range(len(ev)): try: mn = str(round(ev.MIN_VALUE[i], 2)) mx = str(round(ev.MAX_VALUE[i], 2)) except: mn = str((ev.MIN_VALUE[i])) mx = str((ev.MAX_VALUE[i])) q.append(mn + '-' + mx) plt.xticks(ind, q, rotation='vertical') for tick in ax1.get_xticklabels(): tick.set_rotation(60) plt.savefig('{}.png'.format(ev.VAR_NAME[0]), dpi=500, bbox_inches = 'tight') plt.show() def plot_all_bins(iv_df): for i in [x.replace('WOE_','') for x in X_train.columns]: ev = iv_df[iv_df.VAR_NAME==i] ev.reset_index(inplace=True) plot_bin(ev)</span></span></code> </pre> <br></div></div><br>  Fungsi untuk binning manual ditulis secara terpisah, yang berguna, misalnya, dalam kasus variabel "versi OS", di mana semua ponsel Android dan iOS dikelompokkan secara manual. <br><br><div class="spoiler">  <b class="spoiler_title">Fungsi binning manual</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">adjust_binning</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, bins_dict)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(bins_dict)): key = list(bins_dict.keys())[i] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> type(list(bins_dict.values())[i])==dict: df[key] = df[key].map(list(bins_dict.values())[i]) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-comment"><span class="hljs-comment">#Categories labels categories = list() for j in range(len(list(bins_dict.values())[i])): if j == 0: categories.append('&lt;'+ str(list(bins_dict.values())[i][j])) try: categories.append('(' + str(list(bins_dict.values())[i][j]) +'; '+ str(list(bins_dict.values())[i][j+1]) + ']') except: categories.append('(' + str(list(bins_dict.values())[i][j])) elif j==len(list(bins_dict.values())[i])-1: categories.append(str(list(bins_dict.values())[i][j]) +'&gt;') else: categories.append('(' + str(list(bins_dict.values())[i][j]) +'; '+ str(list(bins_dict.values())[i][j+1]) + ']') values = [df[key].min()] + list(bins_dict.values())[i] + [df[key].max()] df[key + '_bins'] = pd.cut(df[key], values, include_lowest=True, labels=categories).astype(object).fillna('_MISSING_').astype(str) df[key] = df[key + '_bins']#.map(df.groupby(key + '_bins')[key].agg('median')) df.drop([key + '_bins'], axis=1, inplace=True) return df bins_dict = { 'equi_delinquencyDays': [ 200,400,600] 'loan_purpose': {'medicine':'1_group', 'repair':'1_group', 'helpFriend':'2_group'} } df = adjust_binning(df, bins_dict)</span></span></code> </pre> <br></div></div><br>  Langkah selanjutnya adalah pemilihan variabel berdasarkan Nilai Informasi.  Nilai defaultnya terputus 0,1 (semua variabel di bawah ini tidak memiliki daya prediksi yang baik). <br><br>  Setelah itu, pemeriksaan korelasi dilakukan.  Dari dua variabel yang berkorelasi, Anda perlu menghapus satu dengan kurang IV.  Penghapusan penghapusan diambil 0,75. <br><br><img src="https://habrastorage.org/webt/sv/7g/f0/sv7gf0nt_7sayq8jgjsjo_bfmpy.png" alt="gambar"><br><br><div class="spoiler">  <b class="spoiler_title">Penghapusan Korelasi</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">delete_correlated_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, cut_off=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.75</span></span></span></span><span class="hljs-function"><span class="hljs-params">, exclude = [])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Create correlation matrix corr_matrix = df.corr().abs() # Select upper triangle of correlation matrix upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # Plotting All correlations f, ax = plt.subplots(figsize=(15, 10)) plt.title('All correlations', fontsize=20) sns.heatmap(X_train.corr(), annot=True) # Plotting highly correlated try: f, ax = plt.subplots(figsize=(15, 10)) plt.title('High correlated', fontsize=20) sns.heatmap(corr_matrix[(corr_matrix&gt;cut_off) &amp; (corr_matrix!=1)].dropna(axis=0, how='all').dropna(axis=1, how='all'), annot=True, linewidths=.5) except: print ('No highly correlated features found') # Find index of feature columns with correlation greater than cut_off to_drop = [column for column in upper.columns if any(upper[column] &gt; cut_off)] to_drop = [column for column in to_drop if column not in exclude] print ('Dropped columns:', to_drop, '\n') df2 = df.drop(to_drop, axis=1) print ('Features left after correlation check: {}'.format(len(df.columns)-len(to_drop)), '\n') print ('Not dropped columns:', list(df2.columns), '\n') # Plotting final correlations f, ax = plt.subplots(figsize=(15, 10)) plt.title('Final correlations', fontsize=20) sns.heatmap(df2.corr(), annot=True) plt.show() return df2</span></span></code> </pre> <br></div></div><br>  Selain seleksi oleh IV, kami menambahkan pencarian rekursif untuk jumlah variabel optimal dengan metode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">RFE</a> dari sklearn. <br>  Seperti yang kita lihat dalam grafik, setelah 13 variabel kualitasnya tidak berubah, yang berarti bahwa yang ekstra dapat dihapus.  Untuk regresi, lebih dari 15 variabel dalam penilaian dianggap sebagai bentuk buruk, yang dalam kebanyakan kasus dikoreksi menggunakan RFE. <br><br><img src="https://habrastorage.org/webt/4y/sm/2c/4ysm2cgo50qcscs2rigxeksod6y.png" alt="gambar"><br><div class="spoiler">  <b class="spoiler_title">RFE</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">RFE_feature_selection</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf_lr, X, y)</span></span></span><span class="hljs-function">:</span></span> rfecv = RFECV(estimator=clf_lr, step=<span class="hljs-number"><span class="hljs-number">1</span></span>, cv=StratifiedKFold(<span class="hljs-number"><span class="hljs-number">5</span></span>), verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, scoring=<span class="hljs-string"><span class="hljs-string">'roc_auc'</span></span>) rfecv.fit(X, y) print(<span class="hljs-string"><span class="hljs-string">"Optimal number of features : %d"</span></span> % rfecv.n_features_) <span class="hljs-comment"><span class="hljs-comment"># Plot number of features VS. cross-validation scores f, ax = plt.subplots(figsize=(14, 9)) plt.xlabel("Number of features selected") plt.ylabel("Cross validation score (nb of correct classifications)") plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_) plt.show() mask = rfecv.get_support() X = X.ix[:, mask] return X</span></span></code> </pre> <br></div></div><br>  Selanjutnya, regresi dibangun dan metriknya dievaluasi pada cross-validation dan uji sampel.  Biasanya semua orang melihat koefisien Gini (artikel bagus tentangnya di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> ). <br><br><img src="https://habrastorage.org/webt/kb/mm/uf/kbmmufj5bxr4jybxad88d1pyggg.png" alt="gambar"><br><br><div class="spoiler">  <b class="spoiler_title">Hasil simulasi</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf, X_test, y_test, feat_to_show=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">30</span></span></span></span><span class="hljs-function"><span class="hljs-params">, is_normalize=False, cut_off=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#cm = confusion_matrix(pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), y_test) print ('ROC_AUC: ', round(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]), 3)) print ('Gini: ', round(2*roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]) - 1, 3)) print ('F1_score: ', round(f1_score(y_test, clf.predict(X_test)), 3)) print ('Log_loss: ', round(log_loss(y_test, clf.predict(X_test)), 3)) print ('\n') print ('Classification_report: \n', classification_report(pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), y_test)) skplt.metrics.plot_confusion_matrix(y_test, pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), title="Confusion Matrix", normalize=is_normalize,figsize=(8,8),text_fontsize='large') display(eli5.show_weights(clf, top=20, feature_names = list(X_test.columns))) clf_lr = LogisticRegressionCV(random_state=1, cv=7) clf_lr.fit(X_train, y_train) plot_score(clf_lr, X_test, y_test, cut_off=0.5)</span></span></code> </pre> <br></div></div><br>  Ketika kami memastikan bahwa kualitas model sesuai dengan kami, maka perlu untuk menulis semua hasil (koefisien regresi, grup bin, grafik dan variabel stabilitas Gini, dll.) Dalam excel.  Untuk ini, mudah untuk menggunakan xlsxwriter, yang dapat bekerja dengan data dan gambar. <br><br>  Contoh lembar excel: <br><br><img src="https://habrastorage.org/webt/um/fg/fn/umfgfnwv9fo7hxo8lqq8fwyppes.png" alt="gambar"><br><br><img src="https://habrastorage.org/webt/xw/ym/1y/xwym1ynrybf7uhvlagzjrjshz_y.png" alt="gambar"><br><br><div class="spoiler">  <b class="spoiler_title">Rekam dalam excel</b> <div class="spoiler_text"><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#WRITING writer = pd.ExcelWriter('PDL_Score_20180815-3.xlsx', engine='xlsxwriter') workbook = writer.book worksheet = workbook.add_worksheet('Sample information') bold = workbook.add_format({'bold': True}) percent_fmt = workbook.add_format({'num_format': '0.00%'}) worksheet.set_column('A:A', 20) worksheet.set_column('B:B', 15) worksheet.set_column('C:C', 10) # Sample worksheet.write('A2', 'Sample conditions', bold) worksheet.write('A3', 1) worksheet.write('A4', 2) worksheet.write('A5', 3) worksheet.write('A6', 4) # Model worksheet.write('A8', 'Model development', bold) worksheet.write('A9', 1) #labels worksheet.write('C8', 'Bads') worksheet.write('D8', 'Goods') worksheet.write('B9', 'Train') worksheet.write('B10', 'Valid') worksheet.write('B11', 'Total') # goods and bads worksheet.write('C9', y_train.value_counts()[1]) worksheet.write('C10', y_test.value_counts()[1]) worksheet.write('D9', y_train.value_counts()[0]) worksheet.write('D10', y_test.value_counts()[0]) worksheet.write('C11', y.value_counts()[1]) worksheet.write('D11', y.value_counts()[0]) # NPL worksheet.write('A13', 2) worksheet.write('B13', 'NPL') worksheet.write('C13', (y.value_counts()[1]/(y.value_counts()[1]+y.value_counts()[0])), percent_fmt) worksheet.write('A16', 3) worksheet.write('C15', 'Gini') worksheet.write('B16', 'Train') worksheet.write('B17', 'Valid') worksheet.write('B18', 'CV Scores') worksheet.write('C18', str([round(sc, 2) for sc in scores])) worksheet.write('C16', round(2*roc_auc_score(y_train, clf_lr.predict_proba(X_train)[:,1]) - 1, 3)) worksheet.write('C17', round(2*roc_auc_score(y_test, clf_lr.predict_proba(X_test)[:,1]) - 1, 3)) # Regreesion coefs feat.to_excel(writer, sheet_name='Regression coefficients', index=False) worksheet2 = writer.sheets['Regression coefficients'] worksheet2.set_column('A:A', 15) worksheet2.set_column('B:B', 50) #WOE ivs[['VAR_NAME', 'Variable range', 'WOE', 'COUNT', 'WOE_group']].to_excel(writer, sheet_name='WOE', index=False) worksheet3 = writer.sheets['WOE'] worksheet3.set_column('A:A', 50) worksheet3.set_column('B:B', 60) worksheet3.set_column('C:C', 30) worksheet3.set_column('D:D', 20) worksheet3.set_column('E:E', 12) for num, i in enumerate([x.replace('WOE_','') for x in X_train.columns]): ev = iv_df[iv_df.VAR_NAME==i] ev.reset_index(inplace=True) worksheet3.insert_image('G{}'.format(num*34+1), '{}.png'.format(i)) df3.to_excel(writer, sheet_name='Data', index=False) table.to_excel(writer, sheet_name='Scores by buckets', header = True, index = True) worksheet4 = writer.sheets['Scores by buckets'] worksheet4.set_column('A:A', 20) worksheet4.insert_image('J1', 'score_distribution.png') Ginis.to_excel(writer, sheet_name='Gini distribution', header = True, index = True) worksheet5 = writer.sheets['Gini distribution'] worksheet5.insert_image('E1', 'gini_stability.png') writer.save()</span></span></code> </pre> <br></div></div><br>  Pada akhirnya, excel terakhir terlihat lagi oleh manajemen, setelah itu diberikan kepada IT untuk menanamkan model dalam produksi. <br><br><h3>  Ringkasan </h3><br>  Seperti yang kita lihat, hampir semua tahapan penilaian dapat diotomatiskan sehingga analis tidak memerlukan keterampilan pemrograman untuk membangun model.  Dalam kasus kami, setelah membuat kerangka kerja ini, analis hanya perlu mengumpulkan data dan menentukan beberapa parameter (menunjukkan variabel target, kolom mana yang akan dihapus, jumlah minimum tempat sampah, koefisien cutoff untuk korelasi variabel, dll.), Setelah itu Anda dapat menjalankan skrip dengan python, yang mana akan membangun model dan menghasilkan excel dengan hasil yang diinginkan. <br>  Tentu saja, kadang-kadang perlu untuk memperbaiki kode untuk kebutuhan proyek tertentu, dan Anda tidak dapat melakukannya dengan satu tombol untuk menjalankan skrip selama pemodelan, tetapi bahkan sekarang kita melihat kualitas yang lebih baik daripada paket data mining yang digunakan di pasar berkat teknik seperti binning optimal dan monoton, pengecekan korelasi , RFE, versi regresi yang diatur, dll. <br><br>  Dengan demikian, berkat penggunaan Python, kami secara signifikan mengurangi waktu pengembangan kartu penilaian, serta mengurangi biaya tenaga kerja analis. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id421091/">https://habr.com/ru/post/id421091/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id421081/index.html">Terlalu sedikit orang memperhatikan tren ekonomi ini.</a></li>
<li><a href="../id421083/index.html">Kemasan seni dekorasi yang terlupakan untuk kartu grafis</a></li>
<li><a href="../id421085/index.html">Elon Musk bukan masa depan</a></li>
<li><a href="../id421087/index.html">Cara mengatur penerapan aplikasi web di Go for Gitlab di VDS</a></li>
<li><a href="../id421089/index.html">Penyedia Rusia telah menemukan cara untuk mentransfer ke Google bagian dari biaya "Paket Musim Semi"</a></li>
<li><a href="../id421093/index.html">Bagaimana saya belajar kerangka Spring - bagian 2 (bantuan untuk pemula - karya pemula sendiri)</a></li>
<li><a href="../id421095/index.html">Di bawah undang-undang baru tentang pemblokiran pra-sidang dapat jatuh 19 juta situs</a></li>
<li><a href="../id421097/index.html">Komposisi UIViewControllers dan navigasi di antara mereka (dan tidak hanya)</a></li>
<li><a href="../id421099/index.html">Apakah sulit berkonsentrasi? Mungkin itu bukan salahmu</a></li>
<li><a href="../id421101/index.html">"Kalender Tester" untuk bulan Agustus. Baca buku</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
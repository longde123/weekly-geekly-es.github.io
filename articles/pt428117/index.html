<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßõüèΩ üìá üåö Processadores tensores gratuitos do Google na Nuvem Colaborativa üôã ü§ö ‚ûï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O Google recentemente forneceu acesso gratuito √† sua unidade de processamento tensor (TPU) na plataforma de aprendizado de m√°quina baseada em nuvem do...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Processadores tensores gratuitos do Google na Nuvem Colaborativa</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428117/">  O Google recentemente forneceu acesso gratuito √† sua unidade de processamento <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tensor</a> (TPU) na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">plataforma de</a> aprendizado de m√°quina baseada em nuvem do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Colaboratory</a> .  O processador tensor √© um circuito integrado especializado (ASIC) desenvolvido pelo Google para tarefas de aprendizado de m√°quina usando a biblioteca TensorFlow.  Decidi tentar aprender a rede convolucional TPU em Keras, que reconhece objetos nas imagens CIFAR-10.  O c√≥digo completo da solu√ß√£o pode ser visualizado e executado no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">laptop</a> . <br><br><img src="https://habrastorage.org/webt/sl/ut/ho/slutho5dsyeduk2biql9rcsblnu.jpeg"><br>  <i>Foto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cloud.google.com</a></i> <br><a name="habracut"></a><br><h2>  Processadores tensores </h2><br>  Em Habr√© j√° escreveu como as TPUs s√£o organizadas ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ) e tamb√©m <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">por que as TPUs s√£o adequadas para o treinamento de redes neurais</a> .  Portanto, n√£o vou me aprofundar nos detalhes da arquitetura TPU, mas apenas considerarei os recursos que precisam ser considerados ao treinar redes neurais. <br><br>  Agora, existem tr√™s gera√ß√µes de processadores tensoriais, o desempenho das TPUs da terceira e √∫ltima gera√ß√£o √© de 420 TFlops (trilh√µes de opera√ß√µes de ponto flutuante por segundo) e cont√©m 128 GB de mem√≥ria de alta largura de banda.  No entanto, apenas as TPUs de segunda gera√ß√£o est√£o dispon√≠veis no Colaboratory, com 180 TFlops de desempenho e 64 GB de mem√≥ria.  No futuro, vou considerar esses TPUs. <br><br>  O processador tensor consiste em quatro chips, cada um dos quais cont√©m dois n√∫cleos, um total de oito n√∫cleos em TPU.  O treinamento em TPU √© realizado em paralelo em todos os n√∫cleos usando replica√ß√£o: cada n√∫cleo executa uma c√≥pia do gr√°fico TensorFlow com um oitavo do volume de dados. <br><br>  A base do processador tensor √© uma unidade matricial (MXU).  Ele usa a estrutura de dados esperta de uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">matriz sist√≥lica de</a> 128x128 para implementa√ß√£o eficiente de opera√ß√µes da matriz.  Portanto, para maximizar o uso dos recursos do equipamento TPU, a dimens√£o da miniamostra ou dos recursos deve ser um m√∫ltiplo de 128 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fonte</a> ).  Al√©m disso, devido √† natureza do sistema de mem√≥ria TPU, √© desej√°vel que a dimens√£o da mini-amostra e recursos seja um m√∫ltiplo de 8. <br><br><h2>  Plataforma Colaborativa </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Colaboratory</a> √© a plataforma em nuvem do Google para o avan√ßo da tecnologia de aprendizado de m√°quina.  Voc√™ pode obter uma m√°quina virtual gratuitamente com as bibliotecas populares instaladas TensorFlow, Keras, sklearn, pandas etc.  O mais conveniente √© que voc√™ possa executar laptops semelhantes ao Jupyter no Colaboratory.  Os laptops s√£o armazenados no Google Drive, voc√™ pode distribu√≠-los e at√© organizar a colabora√ß√£o.  √â assim que o laptop se parece no Colaboratory (a <i>imagem √© clic√°vel</i> ): <br><br> <a href=""><img src="https://habrastorage.org/webt/4b/gp/sn/4bgpsnbpkhwyqrid6fixnaurcbw.png"></a> <br><br>  Voc√™ escreve o c√≥digo em um navegador em um laptop, ele √© executado em uma m√°quina virtual no Google Cloud.  O carro √© emitido para voc√™ por 12 horas, ap√≥s as quais para.  No entanto, nada impede que voc√™ inicie outra m√°quina virtual e trabalhe outras 12 horas.  Lembre-se de que, ap√≥s a m√°quina virtual parar, todos os dados dela ser√£o exclu√≠dos.  Portanto, n√£o esque√ßa de salvar os dados necess√°rios no seu computador ou no Google Drive e, ap√≥s reiniciar a m√°quina virtual, fa√ßa o download novamente. <br><br>  Instru√ß√µes detalhadas para trabalhar na plataforma Colaboratory est√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br><h2>  Conecte o processador tensor ao Colaboratory </h2><br>  Por padr√£o, o Colaboratory n√£o usa aceleradores de c√°lculo de GPU ou TPU.  Voc√™ pode conect√°-los no menu Tempo de execu√ß√£o -&gt; Alterar tipo de tempo de execu√ß√£o -&gt; Acelerador de hardware.  Na lista exibida, selecione "TPU": <br><img src="https://habrastorage.org/webt/1f/7r/vt/1f7rvtfjvdowdjwrz0ctgyyly7s.png" alt="imagem"><br><br>  Ap√≥s escolher o tipo de acelerador, a m√°quina virtual √† qual o laptop Colaboratory est√° conectado ser√° reiniciada e o TPU estar√° dispon√≠vel. <br><br>  Se voc√™ baixou quaisquer dados para a m√°quina virtual, durante o processo de reinicializa√ß√£o, eles ser√£o exclu√≠dos.  Voc√™ precisa baixar os dados novamente. <br><br><h2>  Rede Neural Keras para reconhecimento CIFAR-10 </h2><br>  Como exemplo, vamos tentar treinar uma rede neural Keras em TPU que reconhe√ßa imagens do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados CIFAR-10</a> .  Este √© um conjunto de dados popular que cont√©m pequenas imagens de objetos de 10 classes: avi√£o, carro, p√°ssaro, gato, veado, cachorro, sapo, cavalo, navio e caminh√£o.  As classes n√£o se cruzam, cada objeto na imagem pertence a apenas uma classe. <br><br>  Fa√ßa o download do conjunto de dados CIFAR-10 usando Keras: <br><br><pre><code class="python hljs">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</code> </pre> <br>  Para criar uma rede neural, recebi uma fun√ß√£o separada.  Criaremos o mesmo modelo duas vezes: a primeira vers√£o do modelo para TPU, na qual iremos treinar, e a segunda para a CPU, onde reconheceremos objetos. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> input_layer = Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), dtype=tf.float32, name=<span class="hljs-string"><span class="hljs-string">'Input'</span></span>) x = BatchNormalization()(input_layer) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) x = MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(x) x = BatchNormalization()(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(x) x = Flatten()(x) x = Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) output_layer = Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[input_layer], outputs=[output_layer]) model.compile( optimizer=tf.train.AdamOptimizer(<span class="hljs-number"><span class="hljs-number">0.001</span></span>), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[<span class="hljs-string"><span class="hljs-string">'sparse_categorical_accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  At√© o momento, os otimizadores Keras n√£o podem ser usados ‚Äã‚Äãem TPUs; portanto, ao compilar um modelo, o otimizador do TensorFlow √© especificado. <br><br>  Criamos um modelo Keras para a CPU, que na pr√≥xima etapa iremos converter para um modelo para TPU: <br><br><pre> <code class="python hljs">cpu_model = create_model()</code> </pre> <br><h2>  Converter rede neural de Keras em modelo TPU </h2><br>  Os modelos no Keras e no TensorFlow podem ser treinados na GPU sem nenhuma altera√ß√£o.  Voc√™ ainda n√£o pode fazer isso em TPU, portanto, √© necess√°rio converter o modelo que criamos em um modelo para TPU. <br><br>  Primeiro, voc√™ precisa descobrir onde o TPU dispon√≠vel para n√≥s est√° localizado.  Na plataforma Colaboratory, isso pode ser feito com o seguinte comando: <br><br><pre> <code class="python hljs">TPU_WORKER = <span class="hljs-string"><span class="hljs-string">'grpc://'</span></span> + os.environ[<span class="hljs-string"><span class="hljs-string">'COLAB_TPU_ADDR'</span></span>]</code> </pre> <br>  No meu caso, o endere√ßo TPU ficou assim - <code>grpc://10.102.233.146:8470</code> .  Os endere√ßos foram diferentes para diferentes lan√ßamentos. <br><br>  Agora voc√™ pode obter o modelo para TPU usando a fun√ß√£o <code>keras_to_tpu_model</code> : <br><br><pre> <code class="python hljs">tf.logging.set_verbosity(tf.logging.INFO) tpu_model = tf.contrib.tpu.keras_to_tpu_model( cpu_model, strategy=tf.contrib.tpu.TPUDistributionStrategy( tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))</code> </pre> <br>  A primeira linha inclui o registro no n√≠vel de informa√ß√µes.  Aqui est√° o log de convers√£o do modelo: <br><br> <code>INFO:tensorflow:Querying Tensorflow master (b'grpc://10.102.233.146:8470') for TPU system metadata. <br> INFO:tensorflow:Found TPU system: <br> INFO:tensorflow:*** Num TPU Cores: 8 <br> INFO:tensorflow:*** Num TPU Workers: 1 <br> INFO:tensorflow:*** Num TPU Cores Per Worker: 8 <br> ... <br> WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.</code> <br> <br>  Voc√™ pode ver que o TPU foi encontrado no endere√ßo especificado anteriormente, possui 8 n√∫cleos.  Tamb√©m vemos um aviso de que <code>tpu_model</code> √© experimental e pode ser alterado ou exclu√≠do a qualquer momento.  Espero que, com o tempo, seja poss√≠vel treinar os modelos Keras diretamente em TPU sem nenhuma convers√£o. <br><br><h2>  Treinamos modelo em TPU </h2><br>  O modelo para TPU pode ser treinado da maneira usual para Keras chamando o m√©todo de <code>fit</code> : <br><br><pre> <code class="python hljs">history = tpu_model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">128</span></span>*<span class="hljs-number"><span class="hljs-number">8</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">50</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre> <br>  Quais s√£o os recursos aqui.  Lembramos que, para usar de forma eficiente as TPUs, o tamanho da mini amostra deve ser m√∫ltiplo de 128. Al√©m disso, o treinamento √© realizado em cada n√∫cleo da TPU, usando um oitavo de todos os dados da mini amostra.  Portanto, definimos o tamanho da mini-amostra durante o treinamento para 128 * 8, obtemos 128 fotos para cada n√∫cleo de TPU.  Voc√™ pode usar um tamanho maior, por exemplo, 256 ou 512; o desempenho ser√° maior. <br><br>  No meu caso, o treinamento de uma √©poca requer uma m√©dia de 6 s. <br><br>  A qualidade da educa√ß√£o na era 50: <br> <code>Epoch 50/50 <br> - 6s - loss: 0.2727 - sparse_categorical_accuracy: 0.9006</code> <br> <br>  A parcela de respostas corretas nos dados para treinamento foi de 90,06%.  Verificamos a qualidade dos dados de teste usando TPU: <br><br><pre> <code class="python hljs">scores = tpu_model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, batch_size=batch_size * <span class="hljs-number"><span class="hljs-number">8</span></span>) print(<span class="hljs-string"><span class="hljs-string">"     : %.2f%%"</span></span> % (scores[<span class="hljs-number"><span class="hljs-number">1</span></span>]*<span class="hljs-number"><span class="hljs-number">100</span></span>))</code> </pre> <br> <code>     : 80.79%</code> <br> <br>  Agora salve os pesos do modelo treinado: <br><br><pre> <code class="python hljs">tpu_model.save_weights(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br>  O TensorFlow nos dar√° uma mensagem de que os pesos s√£o transferidos do TPU para a CPU: <br> <code>INFO:tensorflow:Copying TPU weights to the CPU</code> <br> <br>  Note-se que os pesos da rede treinada foram salvos no disco da m√°quina virtual Colaboratory.  Quando a m√°quina virtual √© parada, todos os dados ser√£o apagados.  Se voc√™ n√£o deseja perder pesos treinados, salve-os no seu computador: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.colab <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> files files.download(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br><h2>  Reconhecendo objetos na CPU </h2><br>  Agora vamos tentar usar um modelo treinado em TPU para reconhecer objetos em imagens usando a CPU.  Para fazer isso, crie o modelo novamente e carregue os pesos treinados em TPU nele: <br><br><pre> <code class="python hljs">model = create_model() model.load_weights(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br>  O modelo est√° pronto para uso no processador central.  Vamos tentar reconhecer, com sua ajuda, uma das imagens da su√≠te de testes CIFAR-10: <br><br><pre> <code class="python hljs">index=<span class="hljs-number"><span class="hljs-number">111</span></span> plt.imshow(toimage(x_test[index])) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/za/z3/f-/zaz3f-jatj-5crlgsih84gsakg0.png"><br><br>  A imagem √© pequena, mas voc√™ pode entender que este √© um avi√£o.  Come√ßamos o reconhecimento: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      CIFAR-10 classes=['', '', '', '', '', '', '', '', '', ''] x = x_test[index] #  , .. Keras    x = np.expand_dims(x, axis=0) #   prediction = model.predict(x) #       print(prediction) #     prediction = np.argmax(prediction) print(classes[prediction])</span></span></code> </pre> <br>  Obtemos uma lista dos valores de sa√≠da dos neur√¥nios, quase todos eles s√£o pr√≥ximos de zero, exceto o primeiro valor, que corresponde ao plano. <br><br> <code>[[9.81738389e-01 2.91262069e-07 1.82225723e-02 9.78524668e-07 <br> 5.89265142e-07 6.76223244e-10 1.03252004e-10 9.23009047e-09 <br> 3.71878523e-05 3.16599618e-08]] <br> </code> <br> <br>  O reconhecimento foi bem sucedido! <br><br><h2>  Sum√°rio </h2><br>  Foi poss√≠vel demonstrar a operacionalidade do TPU na plataforma Colaboratory, que pode ser usada para treinar redes neurais no Keras.  No entanto, o conjunto de dados CIFAR-10 √© muito pequeno; n√£o basta carregar totalmente os recursos de TPU.  A acelera√ß√£o comparada √† GPU acabou sendo pequena (voc√™ pode verificar a si mesmo escolhendo a GPU como um acelerador em vez da TPU e treinando novamente o modelo). <br><br>  Em Habr√©, h√° um artigo no qual <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">medimos o desempenho de TPUs e GPUs V100 no treinamento da rede ResNet-50</a> .  Nesta tarefa, o TPU mostrou o mesmo desempenho que as quatro GPUs V100.  √â bom que o Google forne√ßa um acelerador de aprendizado de rede neural t√£o poderoso de gra√ßa! <br><br>  V√≠deo demonstrando o treinamento da rede neural Keras em TPU. <br><iframe width="560" height="315" src="https://www.youtube.com/embed/60xbDEpA49M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  Links √∫teis </h2><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Laptop colaborativo com c√≥digo completo de aprendizado do modelo Keras TPU</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Caderno colaborativo com exemplo de treinamento em Keras TPU para reconhecimento de roupas e sapatos do Fashion MNIST</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Processadores tensores no Google Cloud</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Caracter√≠sticas da arquitetura e uso de processadores tensores</a> . </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt428117/">https://habr.com/ru/post/pt428117/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt428107/index.html">Containeriza√ß√£o de aplicativos Angular 6 SPA Template ASP .NET Core 2.1</a></li>
<li><a href="../pt428109/index.html">Parede corporativa</a></li>
<li><a href="../pt428111/index.html">Aritm√©tica da precis√£o arbitr√°ria em Erlang</a></li>
<li><a href="../pt428113/index.html">Para a quest√£o das curvas de Bezier, velocidade do Arduino e um site interessante, ou como passei o fim de semana</a></li>
<li><a href="../pt428115/index.html">Desenvolvimento web para com√©rcio eletr√¥nico: 5 tend√™ncias tecnol√≥gicas para 2019</a></li>
<li><a href="../pt428119/index.html">"Classe-campos-proposta" ou "O que deu errado no commit do tc39"</a></li>
<li><a href="../pt428121/index.html">Stan Drapkin. Armadilhas de criptografia de alto n√≠vel no .NET</a></li>
<li><a href="../pt428123/index.html">Semana 41 da Seguran√ßa: Boas Novas</a></li>
<li><a href="../pt428125/index.html">Quem s√£o as an√°lises de produtos e por que elas s√£o necess√°rias em uma equipe?</a></li>
<li><a href="../pt428127/index.html">Nginx cache: tudo novo - bem esquecido</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
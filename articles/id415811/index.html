<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ€ ğŸ‘¨ğŸ¾â€ğŸ’¼ ğŸ¤¶ğŸ¿ AI, tentu saja praktis. Tinjauan jaringan saraf untuk klasifikasi gambar â™ ï¸ ğŸ”™ ğŸ•µğŸ¾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Artikel ini menyediakan tinjauan teoritis yang dapat diakses dari jaringan saraf convolutional (CNN) dan menjelaskan aplikasi mereka untuk masalah kla...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, tentu saja praktis. Tinjauan jaringan saraf untuk klasifikasi gambar</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/415811/">  Artikel ini menyediakan tinjauan teoritis yang dapat diakses dari jaringan saraf convolutional (CNN) dan menjelaskan aplikasi mereka untuk masalah klasifikasi gambar. <br><br><img src="https://habrastorage.org/webt/_d/ve/hi/_dvehi4kbgauxndfn56s7-tmtku.jpeg"><br><a name="habracut"></a><br><h2>  <font color="#0071c5">Pendekatan Umum: Tidak Mendalam Pembelajaran</font> </h2><br>  Istilah "pemrosesan gambar" mengacu pada kelas tugas yang luas dimana data input adalah gambar, dan outputnya dapat berupa gambar atau set fitur karakteristik terkait.  Ada banyak pilihan: klasifikasi, segmentasi, anotasi, deteksi objek, dll. Dalam artikel ini, kami memeriksa klasifikasi gambar, tidak hanya karena itu adalah tugas yang paling sederhana, tetapi juga karena itu mendasari banyak tugas lainnya. <br><br>  Pendekatan umum untuk klasifikasi gambar terdiri dari dua langkah berikut: <br><br><ol><li>  Generasi fitur gambar yang signifikan. </li><li>  Klasifikasi gambar berdasarkan atributnya. </li></ol><br>  Urutan operasi yang umum menggunakan model sederhana seperti MultiLayer Perceptron (MLP), Support Vector Machine (SVM), k metode tetangga terdekat dan regresi logistik di atas fitur yang dibuat secara manual.  Atribut dihasilkan menggunakan berbagai transformasi (mis., Deteksi skala abu-abu dan ambang batas) dan deskriptor, mis., Histogram Berorientasi Gradien ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HOG</a> ) atau transformasi Feature Transform ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SIFT</a> ) skala-invarian, dan dll. <br><br>  Keterbatasan utama dari metode yang diterima secara umum adalah partisipasi seorang ahli dalam memilih satu set dan urutan langkah-langkah untuk menghasilkan fitur. <br><br>  Seiring waktu, diketahui bahwa sebagian besar teknik untuk menghasilkan fitur dapat digeneralisasi menggunakan kernel (filter) - matriks kecil (biasanya berukuran 5 Ã— 5), yang merupakan konvolusi dari gambar asli.  Konvolusi dapat dianggap sebagai proses dua tahap berurutan: <br><br><ol><li> Lewati inti tetap yang sama ke seluruh gambar sumber. </li><li>  Pada setiap langkah, hitung produk skalar dari kernel dan gambar asli di lokasi kernel saat ini. </li></ol><br>  Hasil konvolusi gambar dan kernel disebut peta fitur. <br>  Penjelasan yang lebih matematis diberikan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">bab yang relevan dari buku yang</a> baru diterbitkan, Deep Learning, oleh I. Goodfellow, I. Benjio, dan A. Courville. <br><br><img src="https://habrastorage.org/webt/kw/lm/rd/kwlmrdg1y8wsniz94riol_8fiie.png"><br>  <i>Proses konvolusi inti (hijau tua) dengan gambar asli (hijau), akibatnya fitur peta diperoleh (kuning).</i> <br><br>  Contoh sederhana dari transformasi yang dapat dilakukan dengan filter adalah mengaburkan gambar.  Ambil filter yang terdiri dari semua unit.  Ini menghitung rata-rata lingkungan yang ditentukan oleh filter.  Dalam hal ini, lingkungan adalah bagian persegi, tetapi bisa berupa salib atau apa pun.  Rata-rata menyebabkan hilangnya informasi tentang posisi tepat objek, sehingga mengaburkan seluruh gambar.  Penjelasan intuitif yang serupa dapat diberikan untuk setiap filter yang dibuat secara manual. <br><br><img src="https://habrastorage.org/webt/5t/ud/g7/5tudg7ebng4ocb6jdc1-1alsqpo.png"><br>  <i>Hasil konvolusi gambar gedung Universitas Harvard dengan tiga core berbeda.</i> <br><br><h2>  <font color="#0071c5">Jaringan Saraf Konvolusional</font> </h2><br>  Pendekatan konvolusional untuk klasifikasi gambar memiliki sejumlah kelemahan signifikan: <br><br><ul><li>  Proses multi-langkah alih-alih urutan ujung ke ujung. </li><li>  Filter adalah alat generalisasi yang bagus, tetapi mereka adalah matriks yang diperbaiki.  Bagaimana cara memilih bobot dalam filter? </li></ul><br>  Untungnya, filter yang dapat dipelajari telah ditemukan, yang merupakan prinsip dasar yang mendasari CNN.  Prinsipnya sederhana: Kami akan melatih filter yang diterapkan pada deskripsi gambar untuk memenuhi tugas mereka. <br><br>  CNN tidak memiliki satu penemu, tetapi salah satu kasus pertama dari aplikasi mereka adalah LeNet-5 * dalam karya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">â€œ</a> Pembelajaran Berbasis Gradien yang Diterapkan pada Pengakuan Dokumenâ€ oleh I. LeCun dan yang lainnya penulis. <br><br>  CNN membunuh dua burung dengan satu batu: tidak ada kebutuhan untuk definisi awal filter, dan proses pembelajaran menjadi ujung ke ujung.  Arsitektur CNN tipikal terdiri dari bagian-bagian berikut: <br><br><ul><li>  Lapisan konvolusional </li><li>  Berlapis-lapis lapisan </li><li>  Lapisan padat (terhubung penuh) </li></ul><br>  Mari kita bahas masing-masing bagian secara lebih rinci. <br><br><h3>  <font color="#0071c5">Lapisan konvolusional</font> </h3><br>  Lapisan convolutional adalah elemen struktural utama dari CNN.  Lapisan konvolusional memiliki seperangkat karakteristik: <br>  <i>Konektivitas lokal (jarang)</i> .  Dalam lapisan padat, setiap neuron terhubung ke masing-masing neuron dari lapisan sebelumnya (karena itu mereka disebut padat).  Pada lapisan konvolusional, setiap neuron terhubung hanya dengan sebagian kecil dari neuron pada lapisan sebelumnya. <br><br><img src="https://habrastorage.org/webt/nl/1a/6t/nl1a6t8bvbzna0rv_y3qjv_gsua.png"><br>  <i>Contoh jaringan saraf satu dimensi.</i>  <i>(kiri) Koneksi neuron dalam jaringan padat yang khas, (kanan) Karakterisasi konektivitas lokal yang melekat pada lapisan convolutional.</i>  <i>Gambar diambil dari I. Goodfellow dan lainnya oleh Deep Learning</i> <br><br>  <i>Ukuran area di mana neuron terhubung</i> disebut ukuran filter (panjang filter dalam kasus data satu dimensi, misalnya deret waktu, atau lebar / tinggi dalam kasus data dua dimensi, misalnya gambar).  Pada gambar di sebelah kanan, ukuran filter adalah 3. <i>Bobot yang digunakan untuk membuat sambungan</i> disebut filter (vektor dalam hal data satu dimensi dan matriks untuk data dua dimensi).  <i>Langkahnya adalah jarak filter bergerak di atas data</i> (pada gambar di sebelah kanan, langkahnya adalah 1).  Gagasan konektivitas lokal tidak lebih dari sebuah kernel yang bergerak satu langkah.  Setiap neuron tingkat konvolusional mewakili dan mengimplementasikan satu posisi spesifik dari nukleus yang meluncur di sepanjang gambar asli. <br><br><img src="https://habrastorage.org/webt/nu/we/gf/nuwegftvmoigtcdz2mlt0xwmm5g.png"><br>  <i>Dua lapisan konvolusional satu dimensi yang berdekatan</i> <br><br>  Properti penting lainnya adalah apa yang disebut <i>zona kerentanan</i> .  Ini mencerminkan jumlah posisi dari sinyal asli yang dapat â€œdilihatâ€ oleh neuron saat ini.  Misalnya, zona kerentanan lapisan jaringan pertama, yang ditunjukkan pada gambar, sama dengan ukuran filter 3, karena setiap neuron terhubung hanya dengan tiga neuron dari sinyal asli.  Namun, pada lapisan kedua, zona kerentanan sudah 5, karena neuron lapisan kedua mengumpulkan tiga neuron dari lapisan pertama, yang masing-masing memiliki zona kerentanan 3. Dengan meningkatnya kedalaman, zona kerentanan tumbuh secara linear. <br><br>  <i>Parameter bersama</i> .  Ingatlah bahwa dalam pemrosesan gambar klasik, inti yang sama meluncur di seluruh gambar.  Gagasan yang sama berlaku di sini.  Kami hanya memperbaiki ukuran filter bobot untuk satu lapisan dan kami akan menerapkan bobot ini untuk semua neuron di lapisan.  Ini sama dengan menggeser inti yang sama di seluruh gambar.  Tetapi mungkin timbul pertanyaan: bagaimana kita bisa belajar sesuatu dengan sejumlah kecil parameter? <br><br><img src="https://habrastorage.org/webt/ue/qo/gi/ueqogixaqstaotlmnlfnjfn3dtc.png"><br>  <i>Panah gelap mewakili bobot yang sama.</i>  <i>(kiri) MLP Reguler, di mana setiap faktor pembobotan adalah parameter yang terpisah, (kanan) Contoh pemisahan parameter, di mana beberapa faktor pembobotan menunjukkan parameter pelatihan yang sama</i> <br><br>  <i>Struktur ruang</i>  Jawaban atas pertanyaan ini sederhana: kami akan melatih beberapa filter dalam satu lapisan!  Mereka ditempatkan sejajar satu sama lain, sehingga membentuk dimensi baru. <br><br>  Kami berhenti sebentar dan menjelaskan ide yang disajikan oleh contoh gambar RGB dua dimensi dari 227 Ã— 227. Perhatikan bahwa di sini kita berurusan dengan gambar input tiga saluran, yang, pada dasarnya, berarti bahwa kita memiliki tiga gambar input atau data input tiga dimensi. <br><br><img src="https://habrastorage.org/webt/ol/9r/ty/ol9rtyiz5s9btzfnldhf6bo_0wi.png"><br>  <i>Struktur spasial dari gambar input</i> <br><br>  Kami akan mempertimbangkan dimensi saluran sebagai kedalaman gambar (perhatikan bahwa ini tidak sama dengan kedalaman jaringan saraf, yang sama dengan jumlah lapisan jaringan).  Pertanyaannya adalah bagaimana menentukan kernel untuk kasus ini. <br><br><img src="https://habrastorage.org/webt/l6/pt/be/l6ptberff4a-rbz81bq-uxa-10w.png"><br>  <i>Contoh inti dua dimensi, yang pada dasarnya adalah matriks tiga dimensi dengan pengukuran kedalaman tambahan.</i>  <i>Filter ini memberikan konvolusi dengan gambar;</i>  <i>yaitu, meluncur di atas gambar di luar angkasa, menghitung produk skalar</i> <br><br>  Jawabannya sederhana, meskipun masih belum jelas: kita akan membuat kernel juga tiga dimensi.  Dua dimensi pertama akan tetap sama (lebar dan tinggi inti), dan dimensi ketiga selalu sama dengan kedalaman data input. <br><br><img src="https://habrastorage.org/webt/yu/e3/xz/yue3xziqupgpwtmqvtit8ik5hos.png"><br>  <i>Contoh langkah konvolusi spasial.</i>  <i>Hasil produk skalar dari filter dan sebagian kecil dari gambar 5 Ã— 5 Ã— 3 (mis., 5 Ã— 5 Ã— 5 + 1 = 76, dimensi produk skalar + shift) adalah satu angka</i> <br><br>  Dalam hal ini, seluruh bagian 5 Ã— 5 Ã— 3 dari gambar asli diubah menjadi satu angka, dan gambar tiga dimensi itu sendiri akan diubah menjadi <i>peta fitur</i> ( <i>peta aktivasi</i> ).  Peta fitur adalah seperangkat neuron, yang masing-masing menghitung fungsinya sendiri, dengan mempertimbangkan dua prinsip dasar yang dibahas di atas: <i>konektivitas lokal</i> (setiap neuron dikaitkan dengan hanya sebagian kecil dari data input) dan <i>pemisahan parameter</i> (semua neuron menggunakan filter yang sama).  Idealnya, peta fitur ini akan sama dengan yang sudah ditemukan pada contoh jaringan yang diterima secara umum - ini menyimpan hasil konvolusi dari gambar input dan filter. <br><br><img src="https://habrastorage.org/webt/iw/4w/qr/iw4wqr77vslpfjqblrgtjlxyxkw.png"><br>  <i>Peta fitur sebagai hasil konvolusi inti dengan semua posisi spasial</i> <br><br>  Perhatikan bahwa kedalaman peta fitur adalah 1, karena kami hanya menggunakan satu filter.  Tetapi tidak ada yang mencegah kita menggunakan lebih banyak filter;  misalnya, 6. Semuanya akan berinteraksi dengan input data yang sama dan akan bekerja secara independen satu sama lain.  Mari kita melangkah lebih jauh dan menggabungkan kartu fitur ini.  Dimensi spasialnya sama karena dimensi filternya sama.  Dengan demikian, peta fitur yang dikumpulkan bersama dapat dianggap sebagai matriks tiga dimensi baru, dimensi kedalaman yang diwakili oleh peta fitur dari core yang berbeda.  Dalam hal ini, saluran RGB dari gambar input tidak lain adalah tiga peta fitur asli. <br><br><img src="https://habrastorage.org/webt/c8/f1/23/c8f123tp1nnbklt5oimm4gkmwj4.png"><br>  <i>Aplikasi paralel dari beberapa filter ke gambar input dan set kartu aktivasi yang dihasilkan</i> <br><br>  Pemahaman tentang peta fitur dan kombinasinya sangat penting, karena, setelah menyadari hal ini, kami dapat memperluas arsitektur jaringan dan memasang lapisan konvolusional satu di atas yang lain, sehingga meningkatkan zona kerentanan dan memperkaya pengklasifikasi kami. <br><br><img src="https://habrastorage.org/webt/7_/3g/hp/7_3ghputtiaz-2l-hbbs7dagmvi.png"><br>  <i>Lapisan konvolusional dipasang di atas satu sama lain.</i>  <i>Di setiap lapisan, ukuran filter dan jumlahnya dapat bervariasi</i> <br><br>  Sekarang kita mengerti apa itu jaringan konvolusional.  Tujuan utama dari lapisan-lapisan ini adalah sama dengan pendekatan yang diterima secara umum - untuk mendeteksi tanda-tanda signifikan dari gambar.  Dan, jika pada lapisan pertama tanda-tanda ini bisa sangat sederhana (adanya garis vertikal / horizontal), kedalaman jaringan meningkatkan tingkat abstraksi mereka (keberadaan anjing / kucing / orang). <br><br><h3>  <font color="#0071c5">Berlapis-lapis lapisan</font> </h3><br>  Lapisan konvolusional adalah blok bangunan utama CNN.  Tetapi ada bagian penting dan sering digunakan lainnya - ini adalah lapisan subsampel.  Dalam pemrosesan gambar konvensional, tidak ada analog langsung, tetapi subsampel dapat dianggap sebagai jenis kernel lain.  Apa ini <br><br><img src="https://habrastorage.org/webt/n4/fm/df/n4fmdf4o-i1pa7qs4w4oj7wmzgy.png"><br>  <i>Contoh subsampling.</i>  <i>(kiri) Bagaimana subsampel mengubah ukuran susunan data spasial (tetapi bukan saluran!), (kanan) Skema dasar cara kerja subsampel</i> <br><br>  Subsampel menyaring sebagian lingkungan dari setiap piksel dari data input dengan fungsi agregasi tertentu, misalnya, maksimum, rata-rata, dll. Subsampel pada dasarnya sama dengan konvolusi, tetapi fungsi penggabungan piksel tidak terbatas pada produk skalar.  Perbedaan penting lainnya adalah bahwa subsampling hanya berfungsi dalam dimensi spasial.  Fitur karakteristik dari lapisan sub-sampel adalah bahwa <i>pitch biasanya sama dengan ukuran filter</i> (nilai tipinya adalah 2). <br><br>  Subsampel memiliki tiga tujuan utama: <br><br><ul><li>  Mengurangi dimensi spasial, atau sub-sampling.  Ini dilakukan untuk mengurangi jumlah parameter. </li><li>  Pertumbuhan zona kerentanan.  Karena neuron subsampel di lapisan berikutnya, lebih banyak langkah dari sinyal input diakumulasikan </li><li>  Invariansi translasi ke heterogenitas kecil pada posisi pola dalam sinyal input.  Dengan menghitung statistik agregasi dari lingkungan kecil dari sinyal input, subsampel dapat mengabaikan perpindahan spasial kecil di dalamnya. </li></ul><br><h3>  <font color="#0071c5">Lapisan tebal</font> </h3><br>  Lapisan konvolusional dan lapisan subsampel melayani tujuan yang sama - menghasilkan atribut gambar.  Langkah terakhir adalah untuk mengklasifikasikan gambar input berdasarkan fitur yang terdeteksi.  Di CNN, lapisan padat di atas jaringan melakukan ini.  Bagian dari jaringan ini disebut <i>klasifikasi</i> .  Itu dapat berisi beberapa lapisan di atas satu sama lain dengan konektivitas lengkap, tetapi biasanya berakhir dengan lapisan kelas <i>softmax</i> diaktifkan oleh fungsi aktivasi logistik multi-variabel, di mana jumlah blok sama dengan jumlah kelas.  Pada output dari lapisan ini adalah distribusi probabilitas oleh kelas untuk objek input.  Sekarang gambar dapat diklasifikasikan dengan memilih kelas yang paling mungkin. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id415811/">https://habr.com/ru/post/id415811/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id415795/index.html">Menulis Snapchat UI di Swift</a></li>
<li><a href="../id415797/index.html">Ekspresi reguler + pemrograman logis. Apa hasilnya?</a></li>
<li><a href="../id415801/index.html">Google: AI "telepon" kami tidak cukup baik untuk berbahaya</a></li>
<li><a href="../id415805/index.html">Modifikasi modul penghalang GSM Doorhan untuk kontrol Internet</a></li>
<li><a href="../id415809/index.html">Cara menggunakan kedelai, requireejs, backbone js dalam plugin untuk Atlassian Jira</a></li>
<li><a href="../id415813/index.html">Beberapa catatan tentang kondisi Cloud Gaming saat ini</a></li>
<li><a href="../id415815/index.html">Di garis depan sains: analisis artikel arxiv.org</a></li>
<li><a href="../id415817/index.html">Kami meng-overclock cadangan. Kuliah Yandex</a></li>
<li><a href="../id415819/index.html">Laporan Club of Rome 2018, Bab 3.16: Pemerintah Global</a></li>
<li><a href="../id415821/index.html">Cara menata rumah "pintar" dengan kontrol listrik seluas mungkin</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎣 🤾🏻 🐑 Pengikisan web di R, Bagian 2. Mempercepat proses dengan komputasi paralel dan menggunakan paket Rcrawler 📧 🎈 👰</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam artikel sebelumnya , menggunakan parsing scrapbooking, saya mengumpulkan peringkat film dari situs IMDB dan Kinopoisk dan membandingkannya. Repo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengikisan web di R, Bagian 2. Mempercepat proses dengan komputasi paralel dan menggunakan paket Rcrawler</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/464399/"><p><img src="https://habrastorage.org/webt/vy/vh/m_/vyvhm_gjoiuzkbfemd_0fsnbw74.png"></p><br><p>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel sebelumnya</a> , menggunakan parsing scrapbooking, saya mengumpulkan peringkat film dari situs IMDB dan Kinopoisk dan membandingkannya.  Repositori di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Github</a> . </p><br><p>  Kode melakukan tugasnya dengan baik, tetapi memo sering digunakan untuk "mengikis" bukan beberapa halaman, tetapi beberapa tiga ribu, dan kode dari artikel sebelumnya tidak cocok untuk goresan "besar" seperti itu.  Lebih tepatnya, itu tidak akan optimal.  Pada prinsipnya, praktis tidak ada yang mencegah Anda menggunakannya untuk merayapi ribuan halaman.  Praktis, karena Anda tidak punya banyak waktu <a name="habracut"></a></p><br><p><img src="https://habrastorage.org/webt/ik/-y/rk/ik-yrkuvryxwpdvidot66ijfzn8.jpeg"></p><br><p>  <em>Ketika saya memutuskan untuk menggunakan <a href="">scraping_imdb.R</a> untuk menjelajah 1000 halaman</em> </p><br>
<h5 id="optimizaciya-koda-odnokratnoe-ispolzovanie-funkcii-read_html">  Optimasi kode.  Satu penggunaan fungsi <code>read_html</code> </h5><br><p>  Dalam artikel ini, 100 tautan ke halaman-halaman toko buku <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Labyrinth</a> akan digunakan untuk memeriksa operasi dan kecepatan kode. </p><br><p>  Perubahan eksplisit yang dapat mempercepat proses adalah penggunaan fungsi kode "paling lambat" - <code>read_html</code> .  Biarkan saya mengingatkan Anda bahwa dia "membaca" halaman HTML.  Dalam versi pertama kode untuk situs film, saya menjalankan <code>read_html</code> setiap kali saya perlu mendapatkan nilai (nama film, tahun, genre, peringkat).  Sekarang jejak "rasa malu" ini telah dihapus dari GitHuba, tetapi ternyata sudah.  Tidak ada artinya dalam hal ini, karena variabel yang dibuat menggunakan <code>read_html</code> berisi informasi tentang seluruh halaman dan untuk mendapatkan data yang berbeda dari itu, cukup untuk <code>html_nodes</code> variabel ini ke fungsi <code>html_nodes</code> dan tidak mulai membaca HTML setiap saat.  Sehingga Anda dapat menghemat waktu secara proporsional dengan jumlah nilai yang ingin Anda dapatkan.  Dari Labyrinth, saya mendapatkan tujuh nilai, masing-masing, kode yang hanya menggunakan satu pembacaan halaman HTML akan bekerja sekitar tujuh kali lebih cepat.  Tidak buruk!  Tetapi sebelum saya "mempercepat" lagi, saya akan ngelantur dan berbicara tentang hal-hal menarik yang muncul ketika mengikis dari situs web Labyrinth. </p><br><h5 id="osobennosti-skrepinga-stranic-na-labirinte">  Fitur pengikisan halaman di Labirin </h5><br><p>  Pada bagian ini, saya tidak akan menyentuh prosedur untuk mendapatkan dan menghapus data yang disebutkan dalam artikel sebelumnya.  Saya hanya akan menyebutkan momen-momen yang pertama kali saya temui ketika menulis kode untuk scrapbooking toko buku. </p><br><p>  Pertama, perlu disebutkan strukturnya.  Dia sangat tidak nyaman.  Sebaliknya, misalnya, dari situs web Read-Cities, bagian dari genre dengan "filter kosong" hanya memberikan 17 halaman.  Tentu saja, semua <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">8011</a> buku dalam genre "Prosa Asing Kontemporer" tidak cocok untuk mereka. </p><br><p>  Oleh karena itu, saya tidak menemukan sesuatu yang lebih baik daripada berkeliling di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://www.labirint.ru/books/</a> **** tautan dengan patung sederhana.  Terus terang, metode ini bukan yang terbaik (jika hanya karena sebagian besar buku "kuno" tidak memiliki informasi kecuali nama dan karena itu praktis tidak berguna), jadi jika ada yang menawarkan solusi yang lebih elegan, saya akan senang.  Tetapi saya menemukan bahwa di bawah angka pertama yang bangga di situs web Labyrinth adalah sebuah buku berjudul <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Cara Membuat Moonshine"</a> .  Sayangnya, sudah tidak mungkin untuk membeli gudang pengetahuan ini. </p><br><p>  Semua alamat selama pencacahan dapat dibagi menjadi dua jenis: </p><br><ul><li>  Halaman yang ada </li><li>  Halaman yang tidak ada </li></ul><br><p>  Halaman yang ada, pada gilirannya, dapat dibagi menjadi dua bagian: </p><br><ul><li>  Halaman yang berisi semua informasi yang diperlukan </li><li>  Halaman yang tidak mengandung semua informasi yang diperlukan </li></ul><br><p>  Saya berakhir dengan tabel data dengan tujuh kolom: </p><br><ol><li>  ISBN - Nomor Buku ISBN </li><li>  PRICE - harga buku </li><li>  NAME - judul buku </li><li>  PENULIS - penulis buku </li><li>  PUBLISHER - penerbit </li><li>  TAHUN - tahun publikasi </li><li>  HALAMAN - jumlah halaman </li></ol><br><p>  Semuanya jelas dengan halaman dengan informasi lengkap, mereka tidak memerlukan perubahan apa pun dibandingkan dengan kode untuk situs film. </p><br><p>  Adapun halaman di mana beberapa data tidak tersedia, tidak begitu sederhana dengan mereka.  Pencarian di halaman hanya akan mengembalikan nilai-nilai yang ditemukan dan panjang output akan berkurang dengan jumlah elemen yang tidak akan ditemukan.  Ini akan menghancurkan seluruh struktur.  Untuk menghindari ini, konstruksi if ... else ditambahkan ke setiap argumen, yang memperkirakan panjang vektor yang diperoleh setelah menggunakan fungsi <code>html_nodes</code> dan jika itu nol, ia mengembalikan <code>NA</code> untuk menghindari nilai bias. </p><br><pre> <code class="plaintext hljs"> PUBLISHER &lt;- unlist(lapply(list_html, function(n){ publishing &lt;- if(n != "NA") { publishing_html &lt;- html_nodes(n, ".publisher a") publishing &lt;- if(length(publishing_html) == 0){ NA } else { publishing &lt;- html_text(publishing_html) } } else { NA } }))</code> </pre> <br><p>  Tapi seperti yang Anda bisa perhatikan di sini sebanyak dua jika dan sebanyak dua lainnya.  Hanya "internal" if..esle yang relevan dengan solusi untuk masalah yang dijelaskan di atas.  Eksterior menyelesaikan masalah dengan halaman yang tidak ada. </p><br><p>  Halaman yang tidak memiliki masalah besar.  Jika nilai digeser pada halaman dengan data yang hilang, maka ketika input <code>read_html</code> halaman yang tidak ada, fungsi akan <code>read_html</code> kesalahan dan kode akan berhenti dieksekusi.  Karena  entah bagaimana tidak mungkin mendeteksi halaman seperti itu di muka, perlu untuk memastikan bahwa kesalahan tidak menghentikan seluruh proses. </p><br><p>  Fungsi <code>possibly</code> dari paket yang <code>possibly</code> akan membantu kami dengan ini.  Arti fungsi <code>possibly</code> (selain <code>possibly</code> <code>quietly</code> dan <code>safely</code> ) adalah untuk mengganti hasil cetak efek samping (misalnya, kesalahan) dengan nilai yang sesuai dengan kita.  <code>possibly</code> memiliki struktur yang <code>possibly(.f, otherwise)</code> dan jika kesalahan terjadi dalam kode, alih-alih menghentikan eksekusi, ia menggunakan nilai default (jika tidak).  Dalam kasus kami, tampilannya seperti ini: </p><br><pre> <code class="plaintext hljs">book_html &lt;- possibly(read_html, "NA")(n)</code> </pre> <br><p>  n adalah daftar alamat halaman situs yang kami memo.  Pada output, kita mendapatkan daftar panjang n, di mana elemen dari halaman yang ada akan berada dalam bentuk "normal" untuk melakukan fungsi <code>read_html</code> , dan elemen dari halaman yang tidak ada akan terdiri dari vektor karakter "NA".  Harap perhatikan bahwa nilai default harus berupa vektor karakter, karena di masa mendatang kami akan merujuknya.  Jika kita hanya menulis <code>NA</code> , seperti pada bagian kode PUBLISHER, ini tidak akan mungkin.  Untuk menghindari kebingungan, Anda dapat mengubah nilai sebaliknya dari NA ke yang lain. </p><br><p>  Dan sekarang kembali ke kode untuk mendapatkan nama penerbit.  Eksternal jika ... diperlukan untuk tujuan yang sama seperti internal, tetapi sehubungan dengan halaman yang tidak ada.  Jika variabel <code>book_html</code> sama dengan "NA", maka masing-masing nilai "scraped" juga sama dengan <code>NA</code> (di sini Anda sudah bisa menggunakan <code>NA</code> "asli", daripada penipu simbolis).  Jadi pada akhirnya, kita mendapatkan tabel dari formulir berikut: </p><br><div class="scrollable-table"><table><thead><tr><th>  ISBN </th><th>  HARGA </th><th>  NAME </th><th>  PENULIS </th><th>  PENERBIT </th><th>  Tahun </th><th>  Halaman </th></tr></thead><tbody><tr><td>  4665305770322 </td><td>  1488 </td><td>  Set String Art "Cute Puppy" (30 * 30 cm) (DH6021) </td><td>  NA </td><td>  Kucing jahe </td><td>  2019 </td><td>  NA </td></tr><tr><td>  NA </td><td>  NA </td><td>  NA </td><td>  NA </td><td>  NA </td><td>  NA </td><td>  NA </td></tr><tr><td>  9785171160814 </td><td>  273 </td><td>  Arkady Averchenko: Cerita menyenangkan untuk anak-anak </td><td>  Penulis: Averchenko Arkady Timofeevich, Artis: Vlasova Anna Yulievna </td><td>  Nak </td><td>  2019 </td><td>  288 </td></tr></tbody></table></div><br><p>  Sekarang kembali dengan percepatan proses pengikisan. </p><br><h5 id="parallelnoe-vychislenie-v-r-sravnenie-skorosti-i-podvodnye-kamni-pri-ispolzovanii-funkcii-read_html">  Komputasi paralel dalam perbandingan R. Kecepatan dan jebakan saat menggunakan fungsi <code>read_html</code> </h5><br><p>  Secara default, semua perhitungan dalam R dilakukan pada inti prosesor yang sama.  Dan sementara inti yang malang ini berkeringat, "mengorek" data dari ribuan halaman untuk kami, kawan-kawan kami yang lain "mendinginkan" dengan melakukan beberapa tugas lain.  Menggunakan komputasi paralel membantu menarik semua inti prosesor untuk memproses / menerima data, yang mempercepat proses. </p><br><p>  Saya tidak akan masuk jauh ke dalam desain komputasi paralel pada R, Anda dapat membaca lebih lanjut tentang mereka, misalnya di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> .  Cara saya memahami paralelisme pada R adalah membuat salinan R dalam kelompok terpisah sesuai dengan jumlah kernel yang ditunjukkan yang berinteraksi satu sama lain melalui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">soket</a> . </p><br><p>  Saya akan memberi tahu Anda tentang kesalahan yang saya buat saat menggunakan komputasi paralel.  Awalnya, rencana saya adalah ini: menggunakan komputasi paralel, saya mendapatkan daftar 100 halaman "baca" <code>read_html</code> , dan kemudian dalam mode normal saya hanya mendapatkan data yang saya butuhkan.  Pada awalnya semuanya berjalan dengan baik: Saya mendapat daftar, menghabiskan waktu jauh lebih sedikit daripada dalam mode normal R. Tapi hanya ketika saya mencoba berinteraksi dengan daftar ini, saya menerima kesalahan: </p><br><pre> <code class="plaintext hljs">Error: external pointer is not valid</code> </pre> <br><p>  Akibatnya, saya menyadari apa masalahnya, melihat contoh-contoh di Internet, dan setelah itu, menurut hukum kekejaman, saya menemukan penjelasan Henrik Bengtsson dalam sketsa untuk paket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><strong>mendatang</strong></a> .  Faktanya adalah bahwa fungsi XML dari paket <code>xml2</code> adalah objek yang tidak dapat diekspor. <br>  )  Objek-objek ini "terikat" ke sesi R ini dan tidak dapat ditransfer ke proses lain, yang saya coba lakukan.  Oleh karena itu, fungsi yang diluncurkan dalam komputasi paralel harus berisi "siklus penuh" operasi: membaca halaman HTML, menerima dan membersihkan data yang diperlukan. </p><br><p>  Membuat komputasi paralel itu sendiri tidak membutuhkan banyak waktu dan garis kode.  Hal pertama yang Anda butuhkan adalah mengunduh perpustakaan.  Repositori Github menunjukkan paket mana yang diperlukan untuk metode mana.  Di sini saya akan menunjukkan komputasi paralel menggunakan fungsi <code>parLapply</code> dari paket <code>parallel</code> .  Untuk melakukan ini, jalankan saja <code>doParallel</code> ( <code>parallel</code> akan mulai secara otomatis dalam kasus ini).  Jika Anda tiba-tiba tidak tahu atau lupa jumlah inti prosesor Anda, deteksi berapa banyak dari mereka yang akan membantu mendeteksi <code>detectCores</code> </p><br><pre> <code class="plaintext hljs"># detectCores - ,     number_cl &lt;- detectCores()</code> </pre> <br><p>  Selanjutnya, buat salinan paralel R: </p><br><pre> <code class="plaintext hljs"> # makePSOCKcluster -    R,    cluster &lt;- makePSOCKcluster(number_cl) registerDoParallel(cluster)</code> </pre> <br><p>  Sekarang kita sedang menulis fungsi yang akan melakukan semua prosedur yang kita butuhkan.  Saya perhatikan sejak itu  sesi baru dibuat. Paket R yang fungsinya digunakan dalam fungsi kita sendiri harus dituliskan di badan fungsi.  Di <a href="">spider_parallel.R,</a> ini menyebabkan paket <code>stringr</code> berjalan dua kali: pertama untuk mendapatkan alamat halaman, dan kemudian menghapus data. </p><br><p>  Dan kemudian prosedurnya hampir tidak berbeda dengan menggunakan fungsi <code>lapply</code> biasa.  Di <code>parLapply</code> kami memberikan daftar alamat, fungsi kami sendiri, dan, satu-satunya tambahan, variabel dengan kluster yang kami buat. </p><br><pre> <code class="plaintext hljs"># parLapply -  lapply     big_list &lt;- parLapply(cluster, list_url, scraping_parellel_func) #    stopCluster(cluster)</code> </pre> <br><p>  Itu saja, sekarang tinggal membandingkan waktu yang dihabiskan. </p><br><h5 id="sravnenie-skorosti-posledovatelnogo-i-parallelnogo-vychisleniya">  Perbandingan kecepatan komputasi serial dan paralel </h5><br><p>  Ini akan menjadi titik terpendek.  Komputasi paralel 5 kali lebih cepat dari biasanya: </p><br><p>  Menggores kecepatan tanpa menggunakan komputasi paralel </p><br><div class="scrollable-table"><table><thead><tr><th>  pengguna </th><th>  sistem </th><th>  berlalu </th></tr></thead><tbody><tr><td>  13.57 </td><td>  0,40 </td><td>  112.84 </td></tr></tbody></table></div><br><p>  Kecepatan Scraping Menggunakan Komputasi Paralel </p><br><div class="scrollable-table"><table><thead><tr><th>  pengguna </th><th>  sistem </th><th>  berlalu </th></tr></thead><tbody><tr><td>  0,14 </td><td>  0,05 </td><td>  12/21 </td></tr></tbody></table></div><br><p>  Apa yang harus saya katakan?  Komputasi paralel dapat menghemat banyak waktu Anda tanpa membuat kesulitan dalam membuat kode.  Dengan peningkatan jumlah inti, kecepatan akan meningkat secara proporsional dengan jumlah mereka.  Jadi, dengan beberapa perubahan, kami mempercepat kode 7 kali pertama (berhenti menghitung <code>read_html</code> di setiap langkah), dan kemudian 5 lagi, menggunakan perhitungan paralel.  Skrip laba-laba <a href="">tanpa</a> komputasi paralel, menggunakan paket <a href=""><code>parallel</code></a> dan <a href=""><code>foreach</code></a> , ada di repositori di Github. </p><br><h5 id="nebolshoy-obzor-paketa-rcrawler-sravnenie-skorosti">  Gambaran kecil dari paket <code>Rcrawler</code> .  Perbandingan kecepatan. </h5><br><p>  Ada beberapa cara lain untuk memo halaman HTML di R, tapi saya akan fokus pada paket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><strong>Rcrawler</strong></a> .  Fitur yang membedakannya dari alat lain dalam bahasa R adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kemampuan untuk</a> menjelajah situs.  Anda dapat mengatur fungsi <code>Rcrawler</code> dengan nama yang sama ke alamat <code>Rcrawler</code> dan secara metodis, halaman per halaman, melewati seluruh situs.  <code>Rcrawler</code> memiliki banyak argumen untuk mengatur pencarian (misalnya, Anda dapat mencari berdasarkan kata kunci, sektor situs (berguna ketika situs terdiri dari sejumlah besar halaman), kedalaman pencarian, mengabaikan parameter URL yang membuat halaman duplikat, dan banyak lagi. Juga dalam hal ini fungsi-fungsi telah diletakkan perhitungan paralel, yang ditentukan oleh argumen <code>no_cores</code> (jumlah core prosesor yang terlibat) dan <code>no_conn</code> (jumlah permintaan paralel). </p><br><p>  Untuk kasus kami, memotong dari alamat yang ditentukan, ada fungsi <code>ContentScraper</code> .  Ini tidak menggunakan komputasi paralel secara default, jadi Anda harus mengulang semua manipulasi yang saya jelaskan di atas.  Saya menyukai fungsi itu sendiri - ia menyediakan banyak opsi untuk mengatur goresan dan dipahami dengan baik pada tingkat intuitif.  Juga di sini Anda tidak dapat menggunakan if..else untuk halaman yang hilang atau nilai yang hilang, seperti  eksekusi fungsi tidak berhenti. </p><br><pre> <code class="plaintext hljs">#   ContentScraper: # CssPatterns -    CSS    . # ExcludeCSSPat -    CSS ,    . # ,   CSS     CSS ,    . # ManyPerPattern -  FALSE,       , #  .  TRUE,     ,   . # PatternsName -      .   #   c  ,      t_func &lt;- function(n){ library(Rcrawler) t &lt;- ContentScraper(n, CssPatterns = c("#product-title", ".authors", ".buying-price-val-number", ".buying-pricenew-val-number", ".publisher", ".isbn", ".pages2"), ExcludeCSSPat = c(".prodtitle-availibility", ".js-open-block-page_count"), ManyPerPattern = FALSE, PatternsName = c("title", "author", "price1", "price2", "publisher", "isbn", "page")) return(t) }</code> </pre> <br><p>  Tetapi dengan semua kualitas positif, fungsi <code>ContentScraper</code> memiliki satu minus sangat serius - kecepatan kerja. </p><br><p>  Konten Rcrawler <code>Rcrawler</code> <code>ContentScraper</code> Tanpa Komputasi Paralel </p><br><div class="scrollable-table"><table><thead><tr><th>  pengguna </th><th>  sistem </th><th>  berlalu </th></tr></thead><tbody><tr><td>  47.47 </td><td>  0,29 </td><td>  212.24 </td></tr></tbody></table></div><br><p>  Konten Rcrawler ContentScraper <code>ContentScraper</code> <code>Rcrawler</code> Menggunakan Parallel Computing </p><br><div class="scrollable-table"><table><thead><tr><th>  pengguna </th><th>  sistem </th><th>  berlalu </th></tr></thead><tbody><tr><td>  0,01 </td><td>  0,00 </td><td>  67,97 </td></tr></tbody></table></div><br><p>  Jadi Rcrawler harus digunakan jika Anda perlu memotong situs tanpa terlebih dahulu menentukan alamat url, serta dengan sejumlah kecil halaman.  Dalam kasus lain, kecepatan lambat akan melebihi semua kemungkinan keuntungan menggunakan paket ini. </p><br><p>  <em>Saya akan berterima kasih atas komentar, saran, keluhan</em> <br>  Tautan repositori <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Github</a> <br>  Profil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Lingkaran Saya</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id464399/">https://habr.com/ru/post/id464399/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id464385/index.html">Python sebagai kasus akhir C ++. Bagian 1/2</a></li>
<li><a href="../id464387/index.html">Jejak Rusia di saga video game Skandinavia, berakhir</a></li>
<li><a href="../id464391/index.html">10 laporan menarik dari konferensi peretas</a></li>
<li><a href="../id464393/index.html">Bagaimana menemukan kursus pemrograman dan apa saja jaminan pekerjaan</a></li>
<li><a href="../id464395/index.html">Blockchain RSA berbasis acak</a></li>
<li><a href="../id464403/index.html">Cara menjalankan proyek java pada shell runner saat mendorong ke repositori GitLab</a></li>
<li><a href="../id464405/index.html">Python sebagai kasus akhir C ++. Bagian 2/2</a></li>
<li><a href="../id464407/index.html">Cara kerja sistem pengawasan video terbesar di dunia</a></li>
<li><a href="../id464409/index.html">Bagaimana Politik Abad 19 Mempengaruhi Lokasi Pusat Data Hari Ini</a></li>
<li><a href="../id464411/index.html">PVS-Studio: Mesin Kemajuan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💅🏻 👨🏻‍🌾 🌠 Kontextuelle Emotionserkennung in Textkonversationen mit neuronalen Netzen 👩‍❤️‍👨 🎅🏿 🗻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Heutzutage wird das Gespräch mit Gesprächspartnern zur täglichen Routine, und es ist für Dialogsysteme von entscheidender Bedeutung, Antworten so mens...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kontextuelle Emotionserkennung in Textkonversationen mit neuronalen Netzen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439850/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Heutzutage wird das Gespräch mit Gesprächspartnern zur täglichen Routine, und es ist für Dialogsysteme von entscheidender Bedeutung, Antworten so menschlich wie möglich zu generieren.  Als einer der Hauptaspekte sollte das Hauptaugenmerk darauf gelegt werden, den Benutzern emotional bewusste Antworten zu geben.  In diesem Artikel beschreiben wir <b>die wiederkehrende neuronale Netzwerkarchitektur zur Emotionserkennung</b> in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Textkonversationen</a> , die an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SemEval-2019 Task 3 „EmoContext“</a> teilgenommen hat, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dh</a> einem jährlichen Workshop zur semantischen Bewertung.  Das Aufgabenziel besteht darin, Emotionen (d. H. Glücklich, traurig, wütend und andere) in einem 3-Runden-Konversationsdatensatz zu klassifizieren. <br><a name="habracut"></a><br>  Der Rest des Artikels ist wie folgt organisiert.  Abschnitt 1 gibt einen kurzen Überblick über die EmoContext-Aufgabe und die bereitgestellten Daten.  Die Abschnitte 2 und 3 konzentrieren sich folglich auf die Textvorverarbeitung und die Worteinbettung.  In Abschnitt 4 haben wir die Architektur des in unserer Einreichung verwendeten LSTM-Modells beschrieben.  Abschließend werden die endgültige Leistung unseres Systems und der Quellcode vorgestellt.  Das Modell wird in Python mithilfe der Keras-Bibliothek implementiert. <br><br><h2>  1. Trainingsdaten </h2><br>  Die SemEval-2019-Aufgabe 3 „EmoContext“ konzentriert sich auf die kontextbezogene Emotionserkennung in Textkonversationen.  In EmoContext müssen wir bei einer textuellen Benutzeräußerung zusammen mit zwei Kontextumdrehungen in einer Konversation klassifizieren, ob die Emotion der nächsten Benutzeräußerung „glücklich“, „traurig“, „wütend“ oder „andere“ ist (Tabelle 1).  Es gibt nur zwei Konversationsteilnehmer: eine anonyme Person (Tuen-1 und Turn-3) und den AI-basierten Chatbot <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ruuh</a> (Turn-2).  Für eine detaillierte Beschreibung siehe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabelle 1. Beispiele für den EmoContext-Datensatz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Benutzer (Turn-1) </th><th>  Gesprächsagent (Turn-1) </th><th>  Benutzer (Turn-2) </th><th>  Wahre Klasse </th></tr><tr><td>  Ich habe mich gerade für das Nabard-Praktikum qualifiziert </td><td>  WOOT!  Das sind großartige Neuigkeiten.  Glückwunsch! </td><td>  Ich fing an zu weinen </td><td>  Glücklich </td></tr><tr><td>  Wie kannst du es wagen, mein Kind zu schlagen? </td><td>  Wenn Sie mein Auto verwöhnen, werde ich Ihnen das auch antun </td><td>  Versuchen Sie das einfach einmal </td><td>  Wütend </td></tr><tr><td>  Ich wurde von dir mehr verletzt </td><td>  Du hast es nicht so gemeint. </td><td>  Sag, du liebst mich </td><td>  Traurig </td></tr><tr><td>  Ich werde Nacht machen. </td><td>  In Ordnung.  Halte mich auf dem Laufenden. </td><td>  Keine WhatsApp-Nr. </td><td>  Andere </td></tr></tbody></table></div><br>  Während des Wettbewerbs hatten wir Zugang zu 30160 von Menschen gekennzeichneten Texten, die von Aufgabenorganisatoren bereitgestellt wurden, wobei jeweils etwa 5000 Proben aus der Klasse „wütend“, „traurig“, „glücklich“ und 15000 aus der Klasse „andere“ stammten (Tabelle 2).  Entwicklungs- und Testsets, die im Gegensatz zu einem Zugset auch von den Organisatoren bereitgestellt wurden, weisen eine reale Verteilung auf, die für jede emotionale Klasse etwa 4% und für die Klasse „andere“ den Rest beträgt.  Daten von Microsoft zur Verfügung gestellt und können in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der offiziellen LinkedIn-Gruppe gefunden werden</a> . <br><br>  <i>Tabelle 2. Verteilung der Emotion Class Label in Datensätzen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Datensatz </th><th>  Glücklich </th><th>  Traurig </th><th>  Wütend </th><th>  Andere </th><th>  Insgesamt </th></tr><tr><td>  Zug <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30160 <br></td></tr><tr><td>  Dev <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Test <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Fern <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900k <br></td></tr></tbody></table></div><br>  Zusätzlich zu diesen Daten haben wir 900.000 englische Tweets gesammelt, um einen entfernten Datensatz von 300.000 Tweets für jede Emotion zu erstellen.  Um den entfernten Datensatz zu bilden, basieren wir auf der Strategie von Go et al.  (2009), in dem wir Tweets einfach mit dem Vorhandensein emotionsbezogener Wörter wie "#angry", "#annoyed", "#happy", "#sad", "#surprised" usw. verknüpfen.  Die Liste der Abfragebegriffe basierte auf den Abfragebegriffen von SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Duppada et al., 2018</a> ). <br><br>  Die wichtigste Leistungsmetrik von EmoContext ist ein mikro-durchschnittlicher F1-Wert für drei Emotionsklassen, dh "traurig", "glücklich" und "wütend". <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Textvorverarbeitung </h2><br>  Vor jeder Schulungsphase wurden die Texte mit dem Textwerkzeug Ekphrasis vorverarbeitet (Baziotis et al., 2017).  Dieses Tool hilft bei der Rechtschreibkorrektur, Wortnormalisierung und Segmentierung und ermöglicht die Angabe, welche Token weggelassen, normalisiert oder mit speziellen Tags versehen werden sollen.  Wir haben die folgenden Techniken für die Vorverarbeitungsphase verwendet. <br><br><ul><li>  URLs, E-Mails, Datum und Uhrzeit, Benutzernamen, Prozentsatz, Währungen und Zahlen wurden durch die entsprechenden Tags ersetzt. </li><li>  Wiederholte, zensierte, verlängerte und großgeschriebene Begriffe wurden mit den entsprechenden Tags versehen. </li><li>  Längliche Wörter wurden automatisch basierend auf dem integrierten Wortstatistikkorpus korrigiert. </li><li>  Das Entpacken von Hashtags und Kontraktionen (dh Wortsegmentierung) wurde basierend auf dem integrierten Wortstatistikkorpus durchgeführt. </li><li>  Ein manuell erstelltes Wörterbuch zum Ersetzen von aus dem Text extrahierten Begriffen wurde verwendet, um eine Vielzahl von Emotionen zu reduzieren. </li></ul><br>  Darüber hinaus bietet Emphasis den Tokenizer, mit dem die meisten Emojis, Emoticons und komplizierten Ausdrücke wie zensierte, hervorgehobene und verlängerte Wörter sowie Datums-, Uhrzeit-, Währungs- und Akronyme identifiziert werden können. <br><br>  <i>Tabelle 3. Beispiele für die Textvorverarbeitung.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Originaltext </th><th>  Vorverarbeiteter Text </th></tr><tr><td>  Ich fühle dich ... Ich zerbreche in Millionen Stücke <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; Ich fühle dich &lt;/ allcaps&gt;.  &lt;wiederholt&gt; Ich zerbreche in Millionen Stücke <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  müde und ich habe dich auch vermisst :-( </td><td>  müde und ich habe dich auch vermisst &lt;sad&gt; </td></tr><tr><td>  Du solltest dir das anhören: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  Sie sollten &lt;elongated&gt; Folgendes anhören: &lt;url&gt; </td></tr><tr><td>  Meine Wohnung kümmert sich darum.  Meine Miete liegt bei 650 Dollar. </td><td>  Meine Wohnung kümmert sich darum.  Meine Miete liegt bei &lt;Geld&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^・^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑c'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‑':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‑["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Worteinbettungen </h2><br>  Worteinbettungen sind zu einem wesentlichen Bestandteil jedes Deep-Learning-Ansatzes für NLP-Systeme geworden.  Um die am besten geeigneten Vektoren für die Aufgabe der Emotionserkennung zu bestimmen, probieren wir die Modelle Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pennington et al., 2014</a> ) und FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Joulin et al., 2017</a> ) sowie vorab trainierte DataStories aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wortvektoren</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Baziotis et al., 2017</a> ).  Das Schlüsselkonzept von Word2Vec besteht darin, Wörter, die im Trainingskorpus gemeinsame Kontexte haben, in unmittelbarer Nähe im Vektorraum zu lokalisieren.  Sowohl das Word2Vec- als auch das Glove-Modell lernen geometrische Codierungen von Wörtern aus ihren Co-Auftrittsinformationen, aber im Wesentlichen ist das erstere ein Vorhersagemodell und das letztere ein zählbasiertes Modell.  Mit anderen Worten, während Word2Vec versucht, ein Zielwort (CBOW-Architektur) oder einen Kontext (Skip-Gramm-Architektur) vorherzusagen, d. H. Um die Verlustfunktion zu minimieren, berechnet GloVe Wortvektoren, die eine Dimensionsreduktion auf der Matrix der Koexistenzzählungen durchführen.  FastText ist Word2Vec sehr ähnlich, mit der Ausnahme, dass es Zeichen-n-Gramm verwendet, um Wortvektoren zu lernen, sodass das Problem des Wortschatzes gelöst werden kann. <br><br>  Für alle oben genannten Techniken haben wir die von den Autoren bereitgestellten Standard-Trainingswagen verwendet.  Wir trainieren ein einfaches LSTM-Modell (dim = 64) basierend auf jeder dieser Einbettungen und vergleichen die Wirksamkeit mithilfe der Kreuzvalidierung.  Dem Ergebnis zufolge zeigten vorab trainierte DataStories-Einbettungen die beste durchschnittliche F1-Punktzahl. <br><br>  Um ausgewählte Worteinbettungen mit der emotionalen Polarität der Wörter anzureichern, ziehen wir in Betracht, eine entfernte Phrase vor dem Training durch eine Feinabstimmung der Einbettungen auf dem automatisch beschrifteten entfernten Datensatz durchzuführen.  Die Bedeutung des Pre-Trainings wurde in ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deriu et al., 201</a> 7) gezeigt.  Wir verwenden den entfernten Datensatz, um das einfache LSTM-Netzwerk zu trainieren, um wütende, traurige und glückliche Tweets zu klassifizieren.  Die Einbettungsschicht wurde für die erste Trainingsepoche eingefroren, um signifikante Änderungen der Einbettungsgewichte zu vermeiden, und dann für die nächsten 5 Epochen nicht eingefroren.  Nach der Trainingsphase wurden die fein abgestimmten Einbettungen für die weiteren Trainingsphasen gespeichert und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">öffentlich zugänglich gemacht</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Neuronale Netzwerkarchitektur </h2><br>  Ein wiederkehrendes neuronales Netzwerk (RNN) ist eine Familie künstlicher neuronaler Netzwerke, die auf die Verarbeitung sequentieller Daten spezialisiert ist.  Im Gegensatz zu herkömmlichen neuronalen Netzen sind RRNs so konzipiert, dass sie mit sequentiellen Daten umgehen, indem sie ihre internen Gewichte gemeinsam nutzen, um die Sequenz zu verarbeiten.  Zu diesem Zweck enthält der Berechnungsgraph von RRNs Zyklen, die den Einfluss der vorherigen Informationen auf die vorliegende darstellen.  Als Erweiterung von RNNs wurden 1997 Long Short-Term Memory Networks (LSTMs) eingeführt ( <a href="">Hochreiter und Schmidhuber, 1997</a> ).  In LSTMs werden wiederkehrende Zellen auf eine bestimmte Weise verbunden, um zu vermeiden, dass Gradientenprobleme verschwinden und explodieren.  Herkömmliche LSTMs bewahren nur Informationen aus der Vergangenheit, da sie die Sequenz nur in eine Richtung verarbeiten.  Bidirektionale LSTMs kombinieren die Ausgabe von zwei verborgenen LSTM-Schichten, die sich in entgegengesetzte Richtungen bewegen, wobei sich eine durch die Zeit vorwärts und eine andere durch die Zeit rückwärts bewegt, wodurch Informationen aus vergangenen und zukünftigen Zuständen gleichzeitig <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erfasst werden</a> können ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schuster und Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Abbildung 1: Die Architektur einer kleineren Version der vorgeschlagenen Architektur.</i>  <i>Die LSTM-Einheit für die erste und die dritte Runde hat gemeinsame Gewichte.</i> <br><br>  Eine allgemeine Übersicht über unseren Ansatz ist in Abbildung 1 dargestellt. Die vorgeschlagene Architektur des neuronalen Netzwerks besteht aus der Einbettungseinheit und zwei bidirektionalen LSTM-Einheiten (dim = 64).  Die erstere LSTM-Einheit soll die Äußerung des ersten Benutzers analysieren (d. H. Die erste Runde und die dritte Runde des Gesprächs), und die letztere soll die Äußerung des zweiten Benutzers analysieren (dh die zweite Runde).  Diese beiden Einheiten lernen nicht nur die Darstellung von Semantik- und Stimmungsmerkmalen, sondern auch, wie benutzerspezifische Konversationsmerkmale erfasst werden, wodurch Emotionen genauer klassifiziert werden können.  Im ersten Schritt wird jede Benutzeräußerung unter Verwendung vorab trainierter Worteinbettungen in eine entsprechende bidirektionale LSTM-Einheit eingespeist.  Als nächstes werden diese drei Merkmalskarten in einem abgeflachten Merkmalsvektor verkettet und dann an eine vollständig verbundene verborgene Schicht (dim = 30) weitergeleitet, die die Wechselwirkungen zwischen erhaltenen Vektoren analysiert.  Schließlich durchlaufen diese Funktionen die Ausgabeebene mit der Softmax-Aktivierungsfunktion, um eine endgültige Klassenbezeichnung vorherzusagen.  Um die Überanpassung zu verringern, wurden Regularisierungsschichten mit Gaußschem Rauschen nach der Einbettungsschicht hinzugefügt, Dropout-Schichten ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Srivastava et al., 2014</a> ) wurden an jeder LSTM-Einheit (p = 0,2) und vor der verborgenen vollständig verbundenen Schicht (p = 0,1) hinzugefügt. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Ergebnisse </h2><br>  Bei der Suche nach einer optimalen Architektur haben wir nicht nur mit der Anzahl der Zellen in Schichten, Aktivierungsfunktionen und Regularisierungsparametern experimentiert, sondern auch mit der Architektur des neuronalen Netzwerks.  Die detaillierten Informationen zu diesem Satz finden Sie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Originalpapier</a> . <br><br>  Das im vorherigen Abschnitt beschriebene Modell zeigte die besten Ergebnisse für den Entwicklungsdatensatz und wurde daher in der abschließenden Bewertungsphase des Wettbewerbs verwendet.  Im endgültigen Testdatensatz wurde eine durchschnittliche F1-Punktzahl von 72,59% für emotionale Klassen erreicht, während die maximale Punktzahl unter allen Teilnehmern 79,59% betrug.  Dies liegt jedoch weit über der offiziellen Basislinie, die von den Organisatoren der Aufgaben veröffentlicht wurde und bei 58,68% lag. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Quellcode des Modells und die Worteinbettungen</a> sind bei GitHub verfügbar. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Vollversion des Artikels</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das Aufgabenbeschreibungspapier</a> finden Sie unter ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Trainingsdatensatz</a> befindet sich in der offiziellen Wettbewerbsgruppe bei LinkedIn. <br><br>  Zitat: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439850/">https://habr.com/ru/post/de439850/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439834/index.html">IPMI-Technologieübersicht</a></li>
<li><a href="../de439838/index.html">Honigarithmetik: Addition und Subtraktion durch Bienen</a></li>
<li><a href="../de439840/index.html">DUMP-2019-Konferenz: Wir laden Sie ein, in den Abschnitten Design, Management und Test zu sprechen</a></li>
<li><a href="../de439844/index.html">Warum machen Dodo Pizza 250 Entwickler?</a></li>
<li><a href="../de439848/index.html">Kein einziges VPN. Spickzettel, wie Sie sich und Ihre Daten schützen können</a></li>
<li><a href="../de439852/index.html">Release der Fernbedienungsanwendung: Aspia 1.1.0</a></li>
<li><a href="../de439854/index.html">Eh, eins, noch einmal: Was tun mit einem Kunden in CRM nach dem Kauf?</a></li>
<li><a href="../de439856/index.html">Yandex! Danke für Uber</a></li>
<li><a href="../de439858/index.html">Prometheus + Grafana + Node Exporter + Docker in Azure mit Benachrichtigungen im Telegramm</a></li>
<li><a href="../de439860/index.html">Ubuntu 18.04 Root auf ZFS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
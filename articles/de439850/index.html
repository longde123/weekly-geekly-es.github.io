<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÖüèª üë®üèª‚Äçüåæ üå† Kontextuelle Emotionserkennung in Textkonversationen mit neuronalen Netzen üë©‚Äç‚ù§Ô∏è‚Äçüë® üéÖüèø üóª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Heutzutage wird das Gespr√§ch mit Gespr√§chspartnern zur t√§glichen Routine, und es ist f√ºr Dialogsysteme von entscheidender Bedeutung, Antworten so mens...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kontextuelle Emotionserkennung in Textkonversationen mit neuronalen Netzen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439850/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Heutzutage wird das Gespr√§ch mit Gespr√§chspartnern zur t√§glichen Routine, und es ist f√ºr Dialogsysteme von entscheidender Bedeutung, Antworten so menschlich wie m√∂glich zu generieren.  Als einer der Hauptaspekte sollte das Hauptaugenmerk darauf gelegt werden, den Benutzern emotional bewusste Antworten zu geben.  In diesem Artikel beschreiben wir <b>die wiederkehrende neuronale Netzwerkarchitektur zur Emotionserkennung</b> in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Textkonversationen</a> , die an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SemEval-2019 Task 3 ‚ÄûEmoContext‚Äú</a> teilgenommen hat, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dh</a> einem j√§hrlichen Workshop zur semantischen Bewertung.  Das Aufgabenziel besteht darin, Emotionen (d. H. Gl√ºcklich, traurig, w√ºtend und andere) in einem 3-Runden-Konversationsdatensatz zu klassifizieren. <br><a name="habracut"></a><br>  Der Rest des Artikels ist wie folgt organisiert.  Abschnitt 1 gibt einen kurzen √úberblick √ºber die EmoContext-Aufgabe und die bereitgestellten Daten.  Die Abschnitte 2 und 3 konzentrieren sich folglich auf die Textvorverarbeitung und die Worteinbettung.  In Abschnitt 4 haben wir die Architektur des in unserer Einreichung verwendeten LSTM-Modells beschrieben.  Abschlie√üend werden die endg√ºltige Leistung unseres Systems und der Quellcode vorgestellt.  Das Modell wird in Python mithilfe der Keras-Bibliothek implementiert. <br><br><h2>  1. Trainingsdaten </h2><br>  Die SemEval-2019-Aufgabe 3 ‚ÄûEmoContext‚Äú konzentriert sich auf die kontextbezogene Emotionserkennung in Textkonversationen.  In EmoContext m√ºssen wir bei einer textuellen Benutzer√§u√üerung zusammen mit zwei Kontextumdrehungen in einer Konversation klassifizieren, ob die Emotion der n√§chsten Benutzer√§u√üerung ‚Äûgl√ºcklich‚Äú, ‚Äûtraurig‚Äú, ‚Äûw√ºtend‚Äú oder ‚Äûandere‚Äú ist (Tabelle 1).  Es gibt nur zwei Konversationsteilnehmer: eine anonyme Person (Tuen-1 und Turn-3) und den AI-basierten Chatbot <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ruuh</a> (Turn-2).  F√ºr eine detaillierte Beschreibung siehe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabelle 1. Beispiele f√ºr den EmoContext-Datensatz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Benutzer (Turn-1) </th><th>  Gespr√§chsagent (Turn-1) </th><th>  Benutzer (Turn-2) </th><th>  Wahre Klasse </th></tr><tr><td>  Ich habe mich gerade f√ºr das Nabard-Praktikum qualifiziert </td><td>  WOOT!  Das sind gro√üartige Neuigkeiten.  Gl√ºckwunsch! </td><td>  Ich fing an zu weinen </td><td>  Gl√ºcklich </td></tr><tr><td>  Wie kannst du es wagen, mein Kind zu schlagen? </td><td>  Wenn Sie mein Auto verw√∂hnen, werde ich Ihnen das auch antun </td><td>  Versuchen Sie das einfach einmal </td><td>  W√ºtend </td></tr><tr><td>  Ich wurde von dir mehr verletzt </td><td>  Du hast es nicht so gemeint. </td><td>  Sag, du liebst mich </td><td>  Traurig </td></tr><tr><td>  Ich werde Nacht machen. </td><td>  In Ordnung.  Halte mich auf dem Laufenden. </td><td>  Keine WhatsApp-Nr. </td><td>  Andere </td></tr></tbody></table></div><br>  W√§hrend des Wettbewerbs hatten wir Zugang zu 30160 von Menschen gekennzeichneten Texten, die von Aufgabenorganisatoren bereitgestellt wurden, wobei jeweils etwa 5000 Proben aus der Klasse ‚Äûw√ºtend‚Äú, ‚Äûtraurig‚Äú, ‚Äûgl√ºcklich‚Äú und 15000 aus der Klasse ‚Äûandere‚Äú stammten (Tabelle 2).  Entwicklungs- und Testsets, die im Gegensatz zu einem Zugset auch von den Organisatoren bereitgestellt wurden, weisen eine reale Verteilung auf, die f√ºr jede emotionale Klasse etwa 4% und f√ºr die Klasse ‚Äûandere‚Äú den Rest betr√§gt.  Daten von Microsoft zur Verf√ºgung gestellt und k√∂nnen in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der offiziellen LinkedIn-Gruppe gefunden werden</a> . <br><br>  <i>Tabelle 2. Verteilung der Emotion Class Label in Datens√§tzen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Datensatz </th><th>  Gl√ºcklich </th><th>  Traurig </th><th>  W√ºtend </th><th>  Andere </th><th>  Insgesamt </th></tr><tr><td>  Zug <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30160 <br></td></tr><tr><td>  Dev <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Test <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Fern <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900k <br></td></tr></tbody></table></div><br>  Zus√§tzlich zu diesen Daten haben wir 900.000 englische Tweets gesammelt, um einen entfernten Datensatz von 300.000 Tweets f√ºr jede Emotion zu erstellen.  Um den entfernten Datensatz zu bilden, basieren wir auf der Strategie von Go et al.  (2009), in dem wir Tweets einfach mit dem Vorhandensein emotionsbezogener W√∂rter wie "#angry", "#annoyed", "#happy", "#sad", "#surprised" usw. verkn√ºpfen.  Die Liste der Abfragebegriffe basierte auf den Abfragebegriffen von SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Duppada et al., 2018</a> ). <br><br>  Die wichtigste Leistungsmetrik von EmoContext ist ein mikro-durchschnittlicher F1-Wert f√ºr drei Emotionsklassen, dh "traurig", "gl√ºcklich" und "w√ºtend". <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Textvorverarbeitung </h2><br>  Vor jeder Schulungsphase wurden die Texte mit dem Textwerkzeug Ekphrasis vorverarbeitet (Baziotis et al., 2017).  Dieses Tool hilft bei der Rechtschreibkorrektur, Wortnormalisierung und Segmentierung und erm√∂glicht die Angabe, welche Token weggelassen, normalisiert oder mit speziellen Tags versehen werden sollen.  Wir haben die folgenden Techniken f√ºr die Vorverarbeitungsphase verwendet. <br><br><ul><li>  URLs, E-Mails, Datum und Uhrzeit, Benutzernamen, Prozentsatz, W√§hrungen und Zahlen wurden durch die entsprechenden Tags ersetzt. </li><li>  Wiederholte, zensierte, verl√§ngerte und gro√ügeschriebene Begriffe wurden mit den entsprechenden Tags versehen. </li><li>  L√§ngliche W√∂rter wurden automatisch basierend auf dem integrierten Wortstatistikkorpus korrigiert. </li><li>  Das Entpacken von Hashtags und Kontraktionen (dh Wortsegmentierung) wurde basierend auf dem integrierten Wortstatistikkorpus durchgef√ºhrt. </li><li>  Ein manuell erstelltes W√∂rterbuch zum Ersetzen von aus dem Text extrahierten Begriffen wurde verwendet, um eine Vielzahl von Emotionen zu reduzieren. </li></ul><br>  Dar√ºber hinaus bietet Emphasis den Tokenizer, mit dem die meisten Emojis, Emoticons und komplizierten Ausdr√ºcke wie zensierte, hervorgehobene und verl√§ngerte W√∂rter sowie Datums-, Uhrzeit-, W√§hrungs- und Akronyme identifiziert werden k√∂nnen. <br><br>  <i>Tabelle 3. Beispiele f√ºr die Textvorverarbeitung.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Originaltext </th><th>  Vorverarbeiteter Text </th></tr><tr><td>  Ich f√ºhle dich ... Ich zerbreche in Millionen St√ºcke <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; Ich f√ºhle dich &lt;/ allcaps&gt;.  &lt;wiederholt&gt; Ich zerbreche in Millionen St√ºcke <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  m√ºde und ich habe dich auch vermisst :-( </td><td>  m√ºde und ich habe dich auch vermisst &lt;sad&gt; </td></tr><tr><td>  Du solltest dir das anh√∂ren: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  Sie sollten &lt;elongated&gt; Folgendes anh√∂ren: &lt;url&gt; </td></tr><tr><td>  Meine Wohnung k√ºmmert sich darum.  Meine Miete liegt bei 650 Dollar. </td><td>  Meine Wohnung k√ºmmert sich darum.  Meine Miete liegt bei &lt;Geld&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^„Éª^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëc'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‚Äë':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‚Äë["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Worteinbettungen </h2><br>  Worteinbettungen sind zu einem wesentlichen Bestandteil jedes Deep-Learning-Ansatzes f√ºr NLP-Systeme geworden.  Um die am besten geeigneten Vektoren f√ºr die Aufgabe der Emotionserkennung zu bestimmen, probieren wir die Modelle Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pennington et al., 2014</a> ) und FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Joulin et al., 2017</a> ) sowie vorab trainierte DataStories aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wortvektoren</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Baziotis et al., 2017</a> ).  Das Schl√ºsselkonzept von Word2Vec besteht darin, W√∂rter, die im Trainingskorpus gemeinsame Kontexte haben, in unmittelbarer N√§he im Vektorraum zu lokalisieren.  Sowohl das Word2Vec- als auch das Glove-Modell lernen geometrische Codierungen von W√∂rtern aus ihren Co-Auftrittsinformationen, aber im Wesentlichen ist das erstere ein Vorhersagemodell und das letztere ein z√§hlbasiertes Modell.  Mit anderen Worten, w√§hrend Word2Vec versucht, ein Zielwort (CBOW-Architektur) oder einen Kontext (Skip-Gramm-Architektur) vorherzusagen, d. H. Um die Verlustfunktion zu minimieren, berechnet GloVe Wortvektoren, die eine Dimensionsreduktion auf der Matrix der Koexistenzz√§hlungen durchf√ºhren.  FastText ist Word2Vec sehr √§hnlich, mit der Ausnahme, dass es Zeichen-n-Gramm verwendet, um Wortvektoren zu lernen, sodass das Problem des Wortschatzes gel√∂st werden kann. <br><br>  F√ºr alle oben genannten Techniken haben wir die von den Autoren bereitgestellten Standard-Trainingswagen verwendet.  Wir trainieren ein einfaches LSTM-Modell (dim = 64) basierend auf jeder dieser Einbettungen und vergleichen die Wirksamkeit mithilfe der Kreuzvalidierung.  Dem Ergebnis zufolge zeigten vorab trainierte DataStories-Einbettungen die beste durchschnittliche F1-Punktzahl. <br><br>  Um ausgew√§hlte Worteinbettungen mit der emotionalen Polarit√§t der W√∂rter anzureichern, ziehen wir in Betracht, eine entfernte Phrase vor dem Training durch eine Feinabstimmung der Einbettungen auf dem automatisch beschrifteten entfernten Datensatz durchzuf√ºhren.  Die Bedeutung des Pre-Trainings wurde in ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deriu et al., 201</a> 7) gezeigt.  Wir verwenden den entfernten Datensatz, um das einfache LSTM-Netzwerk zu trainieren, um w√ºtende, traurige und gl√ºckliche Tweets zu klassifizieren.  Die Einbettungsschicht wurde f√ºr die erste Trainingsepoche eingefroren, um signifikante √Ñnderungen der Einbettungsgewichte zu vermeiden, und dann f√ºr die n√§chsten 5 Epochen nicht eingefroren.  Nach der Trainingsphase wurden die fein abgestimmten Einbettungen f√ºr die weiteren Trainingsphasen gespeichert und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√∂ffentlich zug√§nglich gemacht</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Neuronale Netzwerkarchitektur </h2><br>  Ein wiederkehrendes neuronales Netzwerk (RNN) ist eine Familie k√ºnstlicher neuronaler Netzwerke, die auf die Verarbeitung sequentieller Daten spezialisiert ist.  Im Gegensatz zu herk√∂mmlichen neuronalen Netzen sind RRNs so konzipiert, dass sie mit sequentiellen Daten umgehen, indem sie ihre internen Gewichte gemeinsam nutzen, um die Sequenz zu verarbeiten.  Zu diesem Zweck enth√§lt der Berechnungsgraph von RRNs Zyklen, die den Einfluss der vorherigen Informationen auf die vorliegende darstellen.  Als Erweiterung von RNNs wurden 1997 Long Short-Term Memory Networks (LSTMs) eingef√ºhrt ( <a href="">Hochreiter und Schmidhuber, 1997</a> ).  In LSTMs werden wiederkehrende Zellen auf eine bestimmte Weise verbunden, um zu vermeiden, dass Gradientenprobleme verschwinden und explodieren.  Herk√∂mmliche LSTMs bewahren nur Informationen aus der Vergangenheit, da sie die Sequenz nur in eine Richtung verarbeiten.  Bidirektionale LSTMs kombinieren die Ausgabe von zwei verborgenen LSTM-Schichten, die sich in entgegengesetzte Richtungen bewegen, wobei sich eine durch die Zeit vorw√§rts und eine andere durch die Zeit r√ºckw√§rts bewegt, wodurch Informationen aus vergangenen und zuk√ºnftigen Zust√§nden gleichzeitig <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erfasst werden</a> k√∂nnen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schuster und Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Abbildung 1: Die Architektur einer kleineren Version der vorgeschlagenen Architektur.</i>  <i>Die LSTM-Einheit f√ºr die erste und die dritte Runde hat gemeinsame Gewichte.</i> <br><br>  Eine allgemeine √úbersicht √ºber unseren Ansatz ist in Abbildung 1 dargestellt. Die vorgeschlagene Architektur des neuronalen Netzwerks besteht aus der Einbettungseinheit und zwei bidirektionalen LSTM-Einheiten (dim = 64).  Die erstere LSTM-Einheit soll die √Ñu√üerung des ersten Benutzers analysieren (d. H. Die erste Runde und die dritte Runde des Gespr√§chs), und die letztere soll die √Ñu√üerung des zweiten Benutzers analysieren (dh die zweite Runde).  Diese beiden Einheiten lernen nicht nur die Darstellung von Semantik- und Stimmungsmerkmalen, sondern auch, wie benutzerspezifische Konversationsmerkmale erfasst werden, wodurch Emotionen genauer klassifiziert werden k√∂nnen.  Im ersten Schritt wird jede Benutzer√§u√üerung unter Verwendung vorab trainierter Worteinbettungen in eine entsprechende bidirektionale LSTM-Einheit eingespeist.  Als n√§chstes werden diese drei Merkmalskarten in einem abgeflachten Merkmalsvektor verkettet und dann an eine vollst√§ndig verbundene verborgene Schicht (dim = 30) weitergeleitet, die die Wechselwirkungen zwischen erhaltenen Vektoren analysiert.  Schlie√ülich durchlaufen diese Funktionen die Ausgabeebene mit der Softmax-Aktivierungsfunktion, um eine endg√ºltige Klassenbezeichnung vorherzusagen.  Um die √úberanpassung zu verringern, wurden Regularisierungsschichten mit Gau√üschem Rauschen nach der Einbettungsschicht hinzugef√ºgt, Dropout-Schichten ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Srivastava et al., 2014</a> ) wurden an jeder LSTM-Einheit (p = 0,2) und vor der verborgenen vollst√§ndig verbundenen Schicht (p = 0,1) hinzugef√ºgt. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Ergebnisse </h2><br>  Bei der Suche nach einer optimalen Architektur haben wir nicht nur mit der Anzahl der Zellen in Schichten, Aktivierungsfunktionen und Regularisierungsparametern experimentiert, sondern auch mit der Architektur des neuronalen Netzwerks.  Die detaillierten Informationen zu diesem Satz finden Sie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Originalpapier</a> . <br><br>  Das im vorherigen Abschnitt beschriebene Modell zeigte die besten Ergebnisse f√ºr den Entwicklungsdatensatz und wurde daher in der abschlie√üenden Bewertungsphase des Wettbewerbs verwendet.  Im endg√ºltigen Testdatensatz wurde eine durchschnittliche F1-Punktzahl von 72,59% f√ºr emotionale Klassen erreicht, w√§hrend die maximale Punktzahl unter allen Teilnehmern 79,59% betrug.  Dies liegt jedoch weit √ºber der offiziellen Basislinie, die von den Organisatoren der Aufgaben ver√∂ffentlicht wurde und bei 58,68% lag. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Quellcode des Modells und die Worteinbettungen</a> sind bei GitHub verf√ºgbar. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Vollversion des Artikels</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das Aufgabenbeschreibungspapier</a> finden Sie unter ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Trainingsdatensatz</a> befindet sich in der offiziellen Wettbewerbsgruppe bei LinkedIn. <br><br>  Zitat: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439850/">https://habr.com/ru/post/de439850/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439834/index.html">IPMI-Technologie√ºbersicht</a></li>
<li><a href="../de439838/index.html">Honigarithmetik: Addition und Subtraktion durch Bienen</a></li>
<li><a href="../de439840/index.html">DUMP-2019-Konferenz: Wir laden Sie ein, in den Abschnitten Design, Management und Test zu sprechen</a></li>
<li><a href="../de439844/index.html">Warum machen Dodo Pizza 250 Entwickler?</a></li>
<li><a href="../de439848/index.html">Kein einziges VPN. Spickzettel, wie Sie sich und Ihre Daten sch√ºtzen k√∂nnen</a></li>
<li><a href="../de439852/index.html">Release der Fernbedienungsanwendung: Aspia 1.1.0</a></li>
<li><a href="../de439854/index.html">Eh, eins, noch einmal: Was tun mit einem Kunden in CRM nach dem Kauf?</a></li>
<li><a href="../de439856/index.html">Yandex! Danke f√ºr Uber</a></li>
<li><a href="../de439858/index.html">Prometheus + Grafana + Node Exporter + Docker in Azure mit Benachrichtigungen im Telegramm</a></li>
<li><a href="../de439860/index.html">Ubuntu 18.04 Root auf ZFS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
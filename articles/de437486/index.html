<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí± üë®üèæ‚Äç‚öñÔ∏è üç® AlphaStar - ein neues k√ºnstliches Intelligenzsystem f√ºr StarCraft II von DeepMind (vollst√§ndige √úbersetzung) üéë üö¢ üë®üèª‚Äçüé®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Spiele werden seit Jahrzehnten als eine der wichtigsten Methoden zum Testen und Bewerten des Erfolgs k√ºnstlicher Intelligenzsysteme eingesetzt. Mit zu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AlphaStar - ein neues k√ºnstliches Intelligenzsystem f√ºr StarCraft II von DeepMind (vollst√§ndige √úbersetzung)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437486/"><img src="https://habrastorage.org/webt/nk/ws/dw/nkwsdwhpu2x7d_mzzxswejvrywu.png"><br><br>  Spiele werden seit Jahrzehnten als eine der wichtigsten Methoden zum Testen und Bewerten des Erfolgs k√ºnstlicher Intelligenzsysteme eingesetzt.  Mit zunehmenden M√∂glichkeiten suchten die Forscher nach Spielen mit immer gr√∂√üerer Komplexit√§t, die die verschiedenen Elemente des Denkens widerspiegeln, die zur L√∂sung wissenschaftlicher oder angewandter Probleme der realen Welt erforderlich sind.  In den letzten Jahren wurde StarCraft als eine der vielseitigsten und komplexesten Echtzeitstrategien und als eine der beliebtesten in der E-Sportszene der Geschichte angesehen. Jetzt ist StarCraft auch die gr√∂√üte Herausforderung f√ºr die KI-Forschung. <a name="habracut"></a><br><br>  AlphaStar ist das erste k√ºnstliche Intelligenzsystem, das die besten Profispieler besiegen kann.  In einer Reihe von Spielen, die am 19. Dezember stattfanden, gewann AlphaStar einen Erdrutschsieg gegen Grzegorz Komincz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MaNa</a> ) vom Team <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Liquid</a> , einem der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">st√§rksten Spieler der Welt</a> , mit einem Ergebnis von 5: 0.  Zuvor wurde auch ein erfolgreiches Demonstrationsspiel gegen seinen Teamkollegen Dario W√ºnsch ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TLO</a> ) ausgetragen.  Die Spiele wurden nach allen professionellen Regeln auf einer speziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Turnierkarte</a> und ohne Einschr√§nkungen ausgetragen. <br><br>  Trotz bedeutender Erfolge in Spielen wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Atari</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mario</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quake III Arena</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dota 2</a> k√§mpften KI-Techniker erfolglos gegen die Komplexit√§t von StarCraft.  Die besten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ergebnisse wurden</a> erzielt, indem die Grundelemente des Systems manuell erstellt wurden, indem den Spielregeln verschiedene Einschr√§nkungen auferlegt wurden, indem dem System √ºbermenschliche F√§higkeiten verliehen wurden oder indem auf vereinfachten Karten gespielt wurde.  Aber selbst diese Nuancen machten es unm√∂glich, dem Niveau der Profispieler n√§her zu kommen.  Im Gegensatz dazu spielt AlphaStar ein vollwertiges Spiel mit tiefen neuronalen Netzen, die auf der Grundlage von Rohdaten des Spiels trainiert werden, wobei Methoden zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lehren mit einem Lehrer</a> und zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lernen mit Verst√§rkung verwendet werden</a> . <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/cUTMhmVh1qs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Hauptherausforderung </h2><br>  StarCraft II ist ein fiktives Fantasy-Universum mit einem reichhaltigen, mehrstufigen Gameplay.  Zusammen mit der Originalausgabe ist dies das gr√∂√üte und erfolgreichste Spiel aller Zeiten, das seit mehr als 20 Jahren in Turnieren ausgetragen wird. <br><br><img src="https://habrastorage.org/webt/ms/84/q6/ms84q6h5-66lmbjwtgj9w5csknw.png"><br><br>  Es gibt viele M√∂glichkeiten zu spielen, aber die h√§ufigste im E-Sport sind Eins-zu-Eins-Turniere, die aus 5 Spielen bestehen.  Zu Beginn muss der Spieler eine von drei Rassen ausw√§hlen - Zergs, Protoss oder Terrans, von denen jede ihre eigenen Eigenschaften und F√§higkeiten hat.  Daher spezialisieren sich professionelle Spieler meist auf ein Rennen.  Jeder Spieler beginnt mit mehreren Arbeitseinheiten, die Ressourcen f√ºr den Bau von Geb√§uden, andere Einheiten oder die Entwicklung von Technologie extrahieren.  Dies erm√∂glicht es dem Spieler, andere Ressourcen zu ergreifen, ausgefeiltere Basen aufzubauen und neue F√§higkeiten zu entwickeln, um den Gegner zu √ºberlisten.  Um zu gewinnen, muss der Spieler das Bild der Gesamtwirtschaft, das als "Makro" bezeichnet wird, und die Kontrolle einzelner Einheiten auf niedriger Ebene, das als "Mikro" bezeichnet wird, sehr fein ausbalancieren. <br><br>  Die Notwendigkeit, kurzfristige und langfristige Ziele in Einklang zu bringen und sich an unvorhergesehene Situationen anzupassen, stellt Systeme vor gro√üe Herausforderungen, die sich tats√§chlich oft als v√∂llig unflexibel herausstellen.  Die L√∂sung dieses Problems erfordert einen Durchbruch in mehreren Bereichen der KI: <br><br>  <b>Spieltheorie</b> : StarCraft ist ein Spiel, bei dem es wie in ‚ÄûStein, Schere, Papier‚Äú keine einzige Gewinnstrategie gibt.  Daher muss die KI im Lernprozess st√§ndig den Horizont ihres strategischen Wissens erforschen und erweitern. <br><br>  <b>Unvollst√§ndige Informationen</b> : Im Gegensatz zu Schach oder Go, wo die Spieler alles sehen, was passiert, sind in StarCraft wichtige Informationen oft verborgen und m√ºssen aktiv durch Intelligenz extrahiert werden. <br><br>  <b>Langfristige Planung</b> : Wie bei realen Aufgaben sind Ursache-Wirkungs-Beziehungen m√∂glicherweise nicht augenblicklich.  Ein Spiel kann auch eine Stunde oder l√§nger dauern, daher k√∂nnen Aktionen, die zu Beginn eines Spiels ausgef√ºhrt werden, auf lange Sicht absolut keine Bedeutung haben. <br><br>  <b>Echtzeit</b> : Im Gegensatz zu herk√∂mmlichen Brettspielen, bei denen sich die Teilnehmer abwechseln, f√ºhren die Spieler in StarCraft im Laufe der Zeit kontinuierlich Aktionen aus. <br><br>  <b>Riesiger Aktionsraum</b> : Hunderte verschiedener Einheiten und Geb√§ude m√ºssen gleichzeitig in Echtzeit √ºberwacht werden, was einen wirklich riesigen kombinatorischen Raum an M√∂glichkeiten bietet.  Dar√ºber hinaus sind viele Aktionen hierarchisch und k√∂nnen sich auf dem Weg √§ndern und erg√§nzen.  Unsere Parametrisierung des Spiels ergibt durchschnittlich 10 bis 26 Aktionen pro Zeiteinheit. <br><br>  Angesichts dieser Herausforderungen ist StarCraft f√ºr KI-Forscher zu einer gro√üen Herausforderung geworden.  Die laufenden StarCraft- und StarCraft II-Wettbewerbe haben ihre Wurzeln in der Einf√ºhrung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BroodWar-API</a> im Jahr 2009.  Darunter befinden sich der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AIIDE StarCraft AI-Wettbewerb</a> , der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CIG StarCraft-Wettbewerb</a> , das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Student StarCraft AI-Turnier</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Starcraft II AI Ladder</a> . <br><br>  <font color="gray"><b>Hinweis</b> : 2017 ver√∂ffentlichte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">PatientZero</a> auf Habr√© eine hervorragende √úbersetzung von ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Geschichte der KI-Wettbewerbe in Starcraft</a> ‚Äú.</font> <br><br>  Um die Community bei der weiteren Erforschung dieser Probleme zu unterst√ºtzen, haben wir in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenarbeit mit Blizzard</a> in den Jahren 2016 und 2017 das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PySC2-Toolkit ver√∂ffentlicht</a> , das die gr√∂√üte Anzahl anonymisierter Wiederholungen enth√§lt, die jemals ver√∂ffentlicht wurden.  Basierend auf dieser Arbeit haben wir unsere technischen und algorithmischen Errungenschaften kombiniert, um den AlphaStar zu erstellen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/822/758/c32/822758c324e93f521b27b56735ec4b83.gif"><br><br>  <font color="gray">Die Visualisierung von AlphaStar w√§hrend des Kampfes gegen MaNa demonstriert das Spiel im Auftrag des Agenten - die anf√§nglich beobachteten Daten, die Aktivit√§t des neuronalen Netzwerks, einige der vorgeschlagenen Aktionen und die erforderlichen Koordinaten sowie das gesch√§tzte Ergebnis des Spiels.</font>  <font color="gray">Die Ansicht des MaNa-Players wird ebenfalls angezeigt, ist jedoch f√ºr den Agenten nat√ºrlich nicht zug√§nglich.</font> <br><br><h2>  Wie ist das Training? </h2><br>  Das AlphaStar-Verhalten wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durch ein</a> tief lernendes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neuronales Netzwerk erzeugt</a> , das Rohdaten √ºber die Schnittstelle (eine Liste der Einheiten und ihrer Eigenschaften) empf√§ngt und eine Folge von Anweisungen gibt, die Aktionen im Spiel sind.  Insbesondere verwendet die Architektur des neuronalen Netzwerks den Ansatz des " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Transformator-</a> Torsos f√ºr die Einheiten, kombiniert mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tiefen LSTM-Kern</a> , einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">automatisch regressiven Richtlinienkopf</a> mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zeigernetzwerk</a> und einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zentralisierten Wertebasislinie</a> " <i>(f√ºr die Genauigkeit der Begriffe, die ohne √úbersetzung verbleiben)</i> .  Wir glauben, dass diese Modelle weiter dazu beitragen werden, andere wichtige maschinelle Lernaufgaben zu bew√§ltigen, einschlie√ülich der Langzeitsequenzmodellierung und gro√üer Ausgaber√§ume wie √úbersetzung, Sprachmodellierung und visuelle Darstellungen. <br><br>  AlphaStar verwendet auch den neuen Multi-Agent-Lernalgorithmus.  Dieses neuronale Netzwerk wurde urspr√ºnglich mit einer lehrerbasierten Lernmethode trainiert, die auf anonymisierten Wiederholungen basiert, die √ºber Blizzard <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verf√ºgbar</a> sind.  Dadurch konnte AlphaStar die grundlegenden Mikro- und Makrostrategien von Spielern in Turnieren untersuchen und simulieren.  Dieser Agent besiegte die eingebaute KI-Stufe ‚ÄûElite‚Äú, die in 95% der Testspiele der Stufe eines Spielers in der Goldliga entspricht. <br><br><img src="https://habrastorage.org/webt/s1/gd/ll/s1gdll65axq9s7kgbbgap2ublzq.png"><br><br>  <font color="gray">Liga AlphaStar.</font>  <font color="gray">Die Agenten wurden zun√§chst auf der Grundlage von Wiederholungen menschlicher √úbereinstimmungen und dann auf der Grundlage von Wettbewerbsspielen untereinander geschult.</font>  <font color="gray">Bei jeder Iteration verzweigen sich neue Gegner und die urspr√ºnglichen frieren ein.</font>  <font color="gray">Die Wahrscheinlichkeit, andere Gegner und Hyperparameter zu treffen, bestimmt die Lernziele f√ºr jeden Agenten, was die Komplexit√§t erh√∂ht und die Vielfalt bewahrt.</font>  <font color="gray">Die Agentenparameter werden mit einem Verst√§rkungstraining aktualisiert, das auf dem Ergebnis des Spiels gegen Gegner basiert.</font>  <font color="gray">Der endg√ºltige Agent wird (ohne Ersatz) basierend auf der Nash-Verteilung ausgew√§hlt.</font> <br><br>  Diese Ergebnisse werden dann verwendet, um einen Lernprozess zur Verst√§rkung mehrerer Agenten zu initiieren.  Zu diesem Zweck wurde eine Liga geschaffen, in der gegnerische Agenten gegeneinander spielen, genau wie Menschen durch das Spielen von Turnieren Erfahrung sammeln.  Durch die Verdoppelung der derzeitigen Agenten wurden neue Rivalen in die Liga aufgenommen.  Diese neue Form des Trainings, bei der einige Ideen aus der Methode des verst√§rkenden Lernens mit Elementen genetischer ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bev√∂lkerungsbasierter</a> ) Algorithmen √ºbernommen wurden, erm√∂glicht es Ihnen, einen kontinuierlichen Prozess zur Erkundung des riesigen strategischen Spielraums von StarCraft zu erstellen und sicherzustellen, dass Agenten den leistungsst√§rksten Strategien standhalten k√∂nnen, nicht die alten vergessen. <br><br><img src="https://habrastorage.org/webt/ez/e2/lk/eze2lk_d4mka5wlf4q0ir5brgyg.png"><br><br>  <font color="gray">Score MMR (Match Making Rating) - ein ungef√§hrer Indikator f√ºr die F√§higkeiten des Spielers.</font>  <font color="gray">F√ºr Rivalen in der AlphaStar-Liga w√§hrend des Trainings im Vergleich zu Blizzards Online-Ligen.</font> <br><br>  Als sich die Liga entwickelte und neue Agenten geschaffen wurden, tauchten Gegenstrategien auf, die die vorherigen besiegen konnten.  W√§hrend einige Agenten nur die Strategien verbesserten, auf die sie zuvor gesto√üen waren, erstellten andere Agenten v√∂llig neue, einschlie√ülich neuer ungew√∂hnlicher Bauauftr√§ge, Einheitenzusammensetzung und Makromanagement.  Zum Beispiel bl√ºhten die ‚ÄûK√§se‚Äú schon fr√ºh - schneller Ansturm mit Hilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Photonenkanonen</a> oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dunklen Templern</a> .  Aber als der Lernprozess voranschritt, wurden diese riskanten Strategien verworfen und machten anderen Platz.  Zum Beispiel die Produktion einer √ºbersch√ºssigen Anzahl von Arbeitern, um einen zus√§tzlichen Zufluss von Ressourcen zu erhalten, oder die Spende von zwei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orakeln</a> , um die feindlichen Arbeiter anzugreifen und seine Wirtschaft zu untergraben.  Dieser Prozess √§hnelt dem, wie regul√§re Spieler in den vielen Jahren seit der Ver√∂ffentlichung von StarCraft neue Strategien entdeckten und alte popul√§re Ans√§tze besiegten. <br><br><img src="https://habrastorage.org/webt/zk/af/qb/zkafqb5szegbqxsj0khe16mi4ps.png"><br><br>  <font color="gray">Im Verlauf des Trainings fiel auf, wie sich die Zusammensetzung der von den Agenten verwendeten Einheiten √§nderte.</font> <br><br>  Um die Vielfalt zu gew√§hrleisten, wurde jeder Agent mit seinem eigenen Lernziel ausgestattet.  Zum Beispiel, welche Gegner dieser Agent besiegen sollte oder welche andere intrinsische Motivation das Spiel des Agenten bestimmt.  Ein bestimmter Agent kann das Ziel haben, einen bestimmten Gegner und den anderen eine ganze Auswahl von Gegnern zu besiegen, aber nur bestimmte Einheiten.  Diese Ziele haben sich im Laufe des Lernprozesses ge√§ndert. <br><br><img src="https://habrastorage.org/webt/t0/ik/9p/t0ik9pbfntlif0ogbysdsla9jmm.png"><br><br>  <font color="gray">Interaktive Visualisierung (interaktive Funktionen sind im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Originalartikel</a> verf√ºgbar), die Rivalen mit der AlphaStar League zeigt.</font>  <font color="gray">Der Agent, der gegen TLO und MaNa gespielt hat, ist separat gekennzeichnet.</font> <br><br>  Die Koeffizienten (Gewichte) des neuronalen Netzwerks jedes Agenten wurden unter Verwendung eines Verst√§rkungstrainings basierend auf Spielen mit Gegnern aktualisiert, um ihre spezifischen Lernziele zu optimieren.  Die Regel f√ºr die Aktualisierung des Gewichts ist ein neuer effektiver Lernalgorithmus ‚ÄûLernalgorithmus f√ºr die Verst√§rkung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Akteuren</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kritikern au√üerhalb der Politik</a> mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erfahrungswiedergabe</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">selbstnachahmendem Lernen</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Destillation von Richtlinien</a> ‚Äú <i>(f√ºr die Genauigkeit der Begriffe, die ohne √úbersetzung bleiben)</i> . <br><br><img src="https://habrastorage.org/webt/ul/xa/lz/ulxalzh3tlrs7xp5g38pieesd2q.gif"><br><br>  <font color="gray">Das Bild zeigt, wie ein Agent (schwarzer Punkt), der als Ergebnis f√ºr das Spiel gegen MaNa ausgew√§hlt wurde, seine Strategie im Vergleich zu Gegnern (farbige Punkte) im Trainingsprozess entwickelt hat.</font>  <font color="gray">Jeder Punkt repr√§sentiert einen Gegner in der Liga.</font>  <font color="gray">Die Position des Punktes zeigt die Strategie und die Gr√∂√üe - die H√§ufigkeit, mit der er als Gegner f√ºr den MaNa-Agenten im Lernprozess ausgew√§hlt wird.</font> <br><br>  Um AlphaStar zu trainieren, haben wir ein skalierbares verteiltes System basierend auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google TPU</a> 3 erstellt, das den Prozess des parallelen Trainings einer ganzen Population von Agenten mit Tausenden von laufenden Kopien von StarCraft II erm√∂glicht.  Die AlphaStar League dauerte 14 Tage und verwendete 16 TPUs f√ºr jeden Agenten.  W√§hrend des Trainings hatte jeder Agent bis zu 200 Jahre Erfahrung mit StarCraft in Echtzeit.  Die endg√ºltige Version von AlphaStar Agent enth√§lt alle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vertriebskomponenten von</a> League <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nash</a> .  Mit anderen Worten, die effektivste Mischung von Strategien, die w√§hrend der Spiele entdeckt wurden.  Diese Konfiguration kann auf einer Standard-Desktop-GPU ausgef√ºhrt werden.  Eine vollst√§ndige technische Beschreibung wird zur Ver√∂ffentlichung in einer von Experten begutachteten wissenschaftlichen Zeitschrift vorbereitet. <br><br><img src="https://habrastorage.org/webt/bu/av/df/buavdfbrbivhdaeyemafanmwfxs.png"><br><br>  <font color="gray">Nash-Verteilung zwischen Rivalen w√§hrend der Entwicklung der Liga und der Schaffung neuer Gegner.</font>  <font color="gray">Die Nash-Distribution, die die am wenigsten ausnutzbare Gruppe komplement√§rer Wettbewerber darstellt, sch√§tzt neue Spieler und zeigt damit kontinuierliche Fortschritte gegen√ºber allen fr√ºheren Wettbewerbern.</font> <br><br><h2>  Wie AlphaStar sich verh√§lt und das Spiel sieht </h2><br>  Professionelle Spieler wie TLO oder MaNa k√∂nnen Hunderte von Aktionen pro Minute ( <a href="">APM</a> ) ausf√ºhren.  Dies ist jedoch viel weniger als bei den meisten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorhandenen Bots</a> , die jede Einheit unabh√§ngig voneinander steuern und Tausende, wenn nicht Zehntausende von Aktionen generieren. <br><br>  In unseren Spielen gegen TLO und MaNa hat AlphaStar den APM auf einem Durchschnitt von 280 gehalten, was viel weniger ist als der von Profispielern, obwohl seine Aktionen m√∂glicherweise genauer sind.  Ein derart niedriger APM ist insbesondere auf die Tatsache zur√ºckzuf√ºhren, dass AlphaStar auf der Grundlage von Wiederholungen gew√∂hnlicher Spieler zu studieren begann und versuchte, die Art des menschlichen Spielens nachzuahmen.  Dar√ºber hinaus reagiert AlphaStar mit einer Verz√∂gerung zwischen Beobachtung und Aktion von durchschnittlich etwa 350 ms. <br><br><img src="https://habrastorage.org/webt/xu/zz/zq/xuzzzqqpxxmw-dep-8zpocumjho.png"><br><br>  <font color="gray">Verteilung von APM AlphaStar in Spielen gegen MaNa und TLO und die Gesamtverz√∂gerung zwischen Beobachtung und Aktion.</font> <br><br>  W√§hrend der Spiele gegen TLO und MaNa interagierte AlphaStar √ºber die Rohschnittstelle mit der StarCraft-Spiel-Engine, dh er konnte die Attribute seiner und sichtbaren feindlichen Einheiten direkt auf der Karte sehen, ohne die Kamera bewegen zu m√ºssen - spielen Sie effektiv mit einer reduzierten Sicht auf das gesamte Gebiet .  Im Gegensatz dazu m√ºssen lebende Menschen die ‚ÄûAufmerksamkeits√∂konomie‚Äú klar steuern, um st√§ndig zu entscheiden, wo die Kamera fokussiert werden soll.  Eine Analyse von AlphaStar-Spielen zeigt jedoch, dass der Fokus implizit gesteuert wird.  Im Durchschnitt wechselt ein Agent wie MaNa und TLO etwa 30 Mal pro Minute seinen Aufmerksamkeitskontext. <br><br>  Zus√§tzlich haben wir die zweite Version von AlphaStar entwickelt.  Als menschliche Spieler w√§hlt diese Version von AlphaStar klar, wann und wo die Kamera bewegt werden soll.  In dieser Ausf√ºhrungsform ist seine Wahrnehmung auf Informationen auf dem Bildschirm beschr√§nkt, und Aktionen sind auch nur auf dem sichtbaren Bereich des Bildschirms zul√§ssig. <br><br><img src="https://habrastorage.org/webt/3d/mt/js/3dmtjsjiqiqkc1izsc6-jsentog.png"><br><br>  <font color="gray">AlphaStar-Leistung bei Verwendung der Basisschnittstelle und der Kameraschnittstelle.</font>  <font color="gray">Die Grafik zeigt, dass der neue Agent, der mit der Kamera arbeitet, √ºber die Basisschnittstelle schnell eine vergleichbare Leistung f√ºr den Agenten erzielt.</font> <br><br>  Wir haben zwei neue Agenten geschult, einen √ºber die Basisschnittstelle und einen, der lernen sollte, wie man die Kamera steuert, und gegen die AlphaStar-Liga spielt.  Jeder Agent wurde zu Beginn mit einem Lehrer trainiert, der auf menschlichen √úbereinstimmungen basierte, gefolgt von einem Training mit der oben beschriebenen Verst√§rkung.  Die AlphaStar-Version, die die Kameraschnittstelle verwendet, erzielte fast die gleichen Ergebnisse wie die Version mit der Basisschnittstelle und √ºberschritt die 7000-MMR-Marke in unserer internen Rangliste.  In einem Demonstrationsspiel besiegte MaNa den AlphaStar-Prototyp mit einer Kamera.  Wir haben diese Version nur 7 Tage trainiert.  Wir hoffen, dass wir in naher Zukunft eine voll ausgebildete Version mit einer Kamera evaluieren k√∂nnen. <br><br>  Diese Ergebnisse zeigen, dass der Erfolg von AlphaStar bei Spielen gegen MaNa und TLO in erster Linie auf ein gutes Makro- und Mikromanagement zur√ºckzuf√ºhren ist und nicht nur auf eine hohe Klickrate, eine schnelle Reaktion oder den Zugriff auf Informationen auf der Basisoberfl√§che. <br><br><h2>  Ergebnisse des Spiels AlphaStar gegen professionelle Spieler </h2><br>  Mit StarCraft k√∂nnen Spieler zwischen drei Rennen w√§hlen - Terraner, Zerg oder Protoss.  Wir haben beschlossen, dass AlphaStar sich derzeit auf ein bestimmtes Rennen, das Protoss, spezialisieren wird, um die Trainingszeit und die Abweichungen bei der Bewertung der Ergebnisse unserer heimischen Liga zu reduzieren.  Es sollte jedoch beachtet werden, dass ein √§hnlicher Lernprozess auf jede Rasse angewendet werden kann.  Unsere Agenten wurden geschult, um StarCraft II Version 4.6.2 im Protoss versus Protoss-Modus auf der CatalystLE-Karte zu spielen.  Um die Leistung von AlphaStar zu bewerten, haben wir unsere Agenten zun√§chst in Spielen gegen TLO getestet - einen professionellen Spieler f√ºr Zerg und einen Spieler f√ºr Protoss Level ‚ÄûGrandMaster‚Äú.  AlphaStar gewann Matches mit einer Punktzahl von 5: 0 unter Verwendung einer Vielzahl von Einheiten und Bauauftr√§gen.  "Ich war √ºberrascht, wie stark der Agent war", sagte er.  ‚ÄûAlphaStar verfolgt bekannte Strategien und stellt sie auf den Kopf.  Der Agent zeigte Strategien, an die ich noch nie gedacht hatte.  Und das zeigt, dass es immer noch Spielm√∂glichkeiten geben kann, die noch nicht vollst√§ndig verstanden sind. ‚Äú <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/UuhECwm31dM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Nach einer zus√§tzlichen Trainingswoche spielten wir gegen MaNa, einen der m√§chtigsten StarCraft II-Spieler der Welt und einen der 10 besten Protoss-Spieler.  AlphaStar gewann diesmal mit 5: 0 und zeigte starke F√§higkeiten im Bereich Mikromanagement und Makrostrategie.  "Ich war erstaunt zu sehen, dass AlphaStar in jedem Spiel die fortschrittlichsten Ans√§tze und unterschiedlichen Strategien verwendet und einen sehr menschlichen Spielstil zeigt, den ich nie erwartet h√§tte", sagte er.  ‚ÄûMir wurde klar, wie stark mein Spielstil von der Verwendung von Fehlern abh√§ngt, die auf menschlichen Reaktionen beruhen.  Und das bringt das Spiel auf ein ganz neues Level.  Wir alle erwarten begeistert, was als n√§chstes passiert. " <br><br><h2>  AlphaStar und andere schwierige Probleme </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trotz der Tatsache, dass StarCraft nur ein Spiel ist, denken wir, dass die Techniken, die AlphaStar zugrunde liegen, bei der L√∂sung anderer Probleme hilfreich sein k√∂nnen, auch wenn es sehr schwierig ist. Beispielsweise kann diese Art der neuronalen Netzwerkarchitektur sehr lange Sequenzen wahrscheinlicher Aktionen in Spielen simulieren, die oft bis zu einer Stunde dauern und Zehntausende von Aktionen enthalten, die auf unvollst√§ndigen Informationen basieren. Jeder Frame in StarCraft wird als ein Eingabeschritt verwendet. In diesem Fall sagt das neuronale Netzwerk bei jedem dieser Schritte die erwartete Abfolge von Aktionen f√ºr das gesamte verbleibende Spiel voraus. Die grundlegende Aufgabe, komplexe Vorhersagen f√ºr sehr lange Datensequenzen zu erstellen, liegt in vielen realen Aufgaben wie Wettervorhersage, Klimamodellierung, Sprachverst√§ndnis usw. Wir freuen uns sehr, das enorme Potenzial zu erkennen.Dies kann in diesen Bereichen angewendet werden, basierend auf den Erfahrungen, die wir im AlphaStar-Projekt gesammelt haben.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir glauben auch, dass einige unserer Lehrmethoden n√ºtzlich sein k√∂nnen, um die Sicherheit und Zuverl√§ssigkeit der KI zu untersuchen. Eines der schwierigsten Probleme auf dem Gebiet der KI ist die Anzahl der Optionen, bei denen das System m√∂glicherweise falsch ist. Und professionelle Spieler haben in der Vergangenheit schnell Wege gefunden, die KI zu umgehen, indem sie ihre Fehler auf die urspr√ºngliche Weise nutzten. Der innovative AlphaStar-Ansatz, der auf dem Training in der Liga basiert, findet solche Ans√§tze und macht den Gesamtprozess zuverl√§ssiger und vor solchen Fehlern gesch√ºtzt. Wir freuen uns, dass das Potenzial dieses Ansatzes dazu beitragen kann, die Sicherheit und Zuverl√§ssigkeit von KI-Systemen im Allgemeinen zu verbessern. Besonders in kritischen Bereichen wie Energie, wo es √§u√üerst wichtig ist, in schwierigen Situationen richtig zu reagieren.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Erreichen eines so hohen Spielniveaus in StarCraft ist ein gro√üer Durchbruch in einem der herausforderndsten Videospiele, die jemals entwickelt wurden. </font><font style="vertical-align: inherit;">Wir glauben, dass diese Erfolge zusammen mit den Erfolgen in anderen Projekten, ob </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlphaZero</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlphaFold</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , einen Fortschritt bei der Umsetzung unserer Mission darstellen, intelligente Systeme zu schaffen, die uns eines Tages helfen werden, L√∂sungen f√ºr die komplexesten und grundlegendsten wissenschaftlichen Probleme zu finden.</font></font><br><br><hr><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">11 Wiederholungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aller Spiele </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Video des Demonstrationsspiels</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gegen MaNa </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Video mit Visualisierung von AlphaStar des</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vollst√§ndigen zweiten Spiels gegen MaNa</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de437486/">https://habr.com/ru/post/de437486/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de437476/index.html">Ok Yandex! Wo sind unsere Ziele?</a></li>
<li><a href="../de437478/index.html">Dass wir eine Stra√üe bauen sollen. Teil 1</a></li>
<li><a href="../de437480/index.html">4 Bildromane zum Englischlernen</a></li>
<li><a href="../de437482/index.html">Fragen Sie Ethan: Wenn sich Licht mit dem Raum zusammenzieht und ausdehnt, wie k√∂nnen wir Gravitationswellen erfassen?</a></li>
<li><a href="../de437484/index.html">Wie ich sechs Interviews im Silicon Valley erfolgreich durchgef√ºhrt habe</a></li>
<li><a href="../de437488/index.html">Cloud Key: So erstellen Sie Ihre Cloud-nativen Anwendungen</a></li>
<li><a href="../de437492/index.html">Lua in Moskau 2019 Konferenz</a></li>
<li><a href="../de437494/index.html">Lua in Moskau 2019 Konferenz</a></li>
<li><a href="../de437496/index.html">√úber Variablen in der Programmierung</a></li>
<li><a href="../de437500/index.html">√úber wichtige ‚Äûunsichtbare‚Äú Dinge - Vertrauen, Kultur und Werte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
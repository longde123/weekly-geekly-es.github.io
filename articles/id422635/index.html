<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤛🏽 🏄 🍣 Anda belum mengucapkan kata "halo", dan kami sudah tahu siapa Anda ♟️ 👨🏻‍🌾 😂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jaringan saraf kita dapat melakukan ini, mengenali seseorang dengan satu suku kata yang diucapkan. Namun, topik artikel ini tidak terkait langsung den...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Anda belum mengucapkan kata "halo", dan kami sudah tahu siapa Anda</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neurodatalab/blog/422635/">  Jaringan saraf kita dapat melakukan ini, mengenali seseorang dengan satu suku kata yang diucapkan.  Namun, topik artikel ini tidak terkait langsung dengan identifikasi suara, meskipun akan terkait dengan itu.  Kita akan berbicara tentang fitur jaringan saraf, yang disebut vektor-d, yang dapat digunakan dalam tugas pemrosesan suara: dari verifikasi hingga pengenalan suara dan emosi. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/eo/h5/k8/eoh5k8gwhm9ep4wpove1up9gljg.jpeg" alt="gambar"></div><br><a name="habracut"></a><br><h4>  <b>Materiel</b> </h4><br>  Bergantung pada laju pengambilan sampel, satu detik suara dapat berisi dari 8 hingga 48 ribu angka.  Mereka dapat direpresentasikan sebagai penyimpangan dari posisi keseimbangan membran speaker atau mikrofon.  Faktanya, uraian bunyi seperti itu berlebihan: amplitudo sinyal pada saat berikutnya sangat bergantung pada yang sebelumnya, yang mengisyaratkan fakta bahwa sinyal ini dapat dikompresi secara efektif tanpa banyak kehilangan informasi.  Ada sejumlah besar cara untuk mengurangi dimensi sinyal, dan sebagian besar didasarkan pada sifat fisik suara dan karakteristik pendengaran manusia. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fh/n4/qj/fhn4qjskpumyiosbtjxzik7e9yg.jpeg" alt="gambar"></div><br>  <i>Meme 1.</i> <br><br>  Sebelum jaringan saraf bekerja dengan baik (dalam arti luas), masyarakat bekerja dengan apa yang disebut atribut kerajinan tangan.  Yang paling terkenal dan banyak digunakan adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pitch</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MFCC</a> .  Yang pertama memiliki arti fisik frekuensi osilasi pita suara, yang berbeda, misalnya, untuk orang yang berbeda, dan juga bergantung pada intonasi.  Gagasan koefisien cepstral (MFCC) didasarkan pada non-linear persepsi manusia tentang suara, yaitu frekuensi dan volume.  Tampaknya bagi seseorang bahwa satu suara lebih tinggi daripada yang lain dengan jumlah tertentu, jika dalam kenyataannya frekuensi mereka berbeda dengan jumlah kali tertentu. <br><br>  Ini dan fitur-fitur lain yang dihitung secara manual tidak dapat dipulihkan dalam arti bahwa beberapa bagian dari sinyal hilang selamanya.  Dalam beberapa tugas ini tidak kritis, tetapi saya ingin datang dengan pendekatan yang lebih universal dan bekerja. <br><br>  Kunci untuk memecahkan masalah ini adalah transformasi Fourier.  Menggunakannya, Anda dapat membayangkan sinyal audio sebagai jumlah gelombang dengan frekuensi dan amplitudo yang berbeda.  Kenyataannya, ucapan tidak diam dalam arti bahwa spektrumnya akan berbeda secara kualitatif pada titik waktu yang berbeda.  Ini memungkinkan kita untuk mempertimbangkannya dalam representasi frekuensi waktu, menggunakan <i>spektogram</i> . <br><br>  Untuk membangun spektogram, Anda perlu memecah suara menjadi bagian berpotongan (tumpang tindih frame) beberapa puluh milidetik panjangnya, untuk masing-masing menghitung transformasi Fourier dan menulis modul mereka dalam kolom pada spektogram.  Selain itu, transformasi seperti itu hampir saling terbalik, yaitu, dengan menggunakan transformasi Fourier terbalik dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">algoritma Griffin-Lim,</a> Anda dapat mengembalikan sinyal suara asli (pada kenyataannya, ada kehilangan informasi, karena transformasi Fourier kompleks dalam kasus umum, dan spektogram bernilai nyata, dan, untuk perkiraan pemulihan fase, algoritma iteratif Griffin-Lim biasanya digunakan).  Total, jika kita mengambil logaritma amplitudo, kita mendapatkan gambar-gambar ini: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ux/ig/xz/uxigxzafbu938strrzeepi8s-ro.png" alt="gambar"></div><br>  <i>Spectrogram 5 detik bicara.</i> <br><br>  Dan mereka dengan mudah diproses oleh jaring konvolusional. <br><br>  Peretasan seperti ini sering digunakan dalam tugas pemrosesan gambar: ada basis data besar dengan contoh objek yang berbeda (misalnya, ImageNet).  Anda dapat melatih kisi-kisi besar untuk mengenalinya, dan kemudian melatihnya kembali pada tugas khusus kami, atau mengambil hasil keluaran dari salah satu lapisan dalam yang terhubung sepenuhnya.  Dipercaya bahwa arsitektur seperti itu akan menghitung fitur informatif yang bagus untuk gambar input.  Pengalaman menunjukkan bahwa hampir selalu hasilnya akan lebih baik daripada jika kita melatih jaringan saraf dari awal. <br><br>  Gagasan vektor-d (umumnya vektor-d, tetapi kadang-kadang disebut vektor-x) mirip dengan menggunakan kisi-kisi yang sudah dilatih sebelumnya di ImageNet, kecuali kenyataan bahwa tidak ada basis yang sama untuk spektogram.  Sebagai jalan keluar yang mungkin, auto-encoders dapat dipertimbangkan, tetapi mereka apriori tidak tahu apa yang harus dicari dalam spektogram, karena itu mereka bekerja dengan tidak memuaskan. <br><br><h4>  <b>Kita harus masuk lebih dalam</b> </h4><br>  Perhatian, bagian utama dari artikel ini dimulai. <br><br>  Tugas memverifikasi seseorang dengan suara dikenal secara luas, di mana perlu untuk menentukan oleh segmen input dari pidato mana dari orang-orang dalam database mengatakannya.  Sebenarnya, pembangunan sistem semacam itu adalah ilmu yang terpisah, dan ada banyak tambahan yang berbeda (durasi bicara; apakah itu mengharuskan semua orang berbicara teks yang sama; pementasan satu lawan satu atau satu lawan semua), yang kritis dalam kondisi yang berbeda, tetapi bagi kami Anda perlu memperhatikan hal lain. <br><br>  Yaitu: seberapa bagus fitur-fiturnya jika kita melatih awal grid untuk mengenali seseorang.  Semuanya dilakukan demi tanda. <br><br>  Ini akan membantu kami intuisi dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel tahun</a> 2015.  Di dalamnya, penulis mengajarkan grid untuk mengenali seseorang dengan wajah (face recognition).  Kunci dari pekerjaan ini adalah dengan menggunakan Triplet Loss. <br><br>  Idenya sangat sederhana: kita menormalkan fitur-fitur dari lapisan kedua dari belakang sehingga mereka berbaring di unit sphere, dan mengharuskan titik-titik dari satu kelas terletak dekat dan jauh dari yang berbeda.  Ini dapat dicapai sebagai berikut: untuk setiap contoh pelatihan (jangkar) kami menemukan dua lebih dari yang sama dan dari kelas lain dalam sampel - positif dan negatif.  Kemudian untuk tiga kali lipat poin ini kami membentuk kerugian: <br><br>  \ mulai {persamaan} <br>  \ Besar [\ Vert f (x ^ a) - f (x ^ p) \ Vert - \ Vert f (x ^ a) - f (x ^ n) \ Vert + \ alpha \ Big] _ +, <br>  \ end {persamaan} <br><br>  di mana x adalah gambar input, f adalah output grid setelah normalisasi, alpha adalah parameter yang dipilih secara manual, [] _ ​​{+} adalah fungsi ReLU.  Secara kualitatif, nilai kerugian ini adalah nol jika jarak antara jangkar dan poin positif lebih besar dari jarak antara jangkar dan negatif oleh setidaknya alpha, dan semakin besar semakin sedikit perbedaan antara dua kelas yang berbeda. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fp/k6/yy/fpk6yyh_hd1hb00bsdcg39xyuqc.png" alt="gambar"></div><br>  <i>Ilustrasi apa yang terjadi pada fitur setelah pelatihan dengan Triplet Loss.</i> <br><br>  Omong-omong, Anda dapat membentuk tiga kali lipat dengan cara yang cerdas.  Pada titik tertentu, besarnya kerugian akan menjadi kecil, dan untuk mempercepat pembelajaran, Anda dapat mencari contoh negatif tidak di antara semua kelas lainnya, tetapi pertimbangkan hanya mereka yang dekat dengan jangkar.  Tetapi untuk dataset besar, ini sulit, karena Anda perlu mempertimbangkan jarak berpasangan antara kelas yang berubah setelah setiap iterasi pembelajaran jaringan. <br><br>  Triplet Loss memiliki keunggulan dibandingkan Categorical Crossentropy, yang digunakan dalam klasifikasi konvensional.  Model yang dilatih dengan lintas-entropi akan mencoba menjejalkan semua poin dari satu kelas ke area yang semakin kecil, dan informasi yang berlebihan untuk tugas tertentu mungkin hilang.  Tetapi kami tidak menginginkan ini, karena kami akan menggunakan jaringan saraf sebagai generator fitur, dan bukan untuk verifikasi.  Triplet Loss memiliki properti ini pada tingkat yang jauh lebih rendah: lebih penting baginya untuk menyebarkan kelas yang berbeda ke area yang berbeda pada satu bidang daripada harus menggunakan satu kelas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pn/pt/nz/pnptnzxqejabade7orpavbtx5se.jpeg" alt="gambar"></div><br>  <i>Meme 2.</i> <br><br>  Hal terakhir yang harus dilakukan sebelum melatih fitur generator pada spektrogram adalah menentukan ukurannya.  Jelas, keakuratan klasifikasi akan semakin tinggi, semakin besar periode waktu yang akan kita pertimbangkan, tetapi semakin banyak tanda "rata-rata" akan muncul.  Oleh karena itu, masuk akal untuk menggunakan panjang sinyal sedemikian sehingga 1-3 fonem (suku kata) masuk ke dalamnya - setengah detik sepertinya tepat. <br><br>  Untuk pelatihan, kami mengambil dataset <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VoxCeleb2</a> , di mana untuk masing-masing 6300 speaker ada beberapa rekaman audio terpisah masing-masing beberapa menit (dibuat dalam kondisi yang berbeda).  Kami menggunakan sebagian dari file audio untuk pelatihan, dan sisanya untuk validasi, pilih arsitektur jaringan konvolusi, tambahkan Triplet Loss ke dalamnya dan pelajari. <br><br>  Hasilnya sangat keren.  Dalam hampir 2 minggu pelatihan di 1080Ti (ya, sudah lama), akurasi klasifikasi mencapai 55%.  Tampaknya tidak terlalu banyak, tetapi keakuratan top-5 adalah 78%, dan jika kita menganggap hanya bagian paling keras dari fragmen, yang sebagian besar adalah vokal yang ditekankan, maka akurasi top-5 akan meningkat menjadi 91%.  Kita dapat mengatakan bahwa kita dapat mengidentifikasi seseorang dengan salah satu frasa dengan akurasi yang layak.  Tapi itu tidak masalah. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vz/el/21/vzel21arcsvyrco_kg_95usxziy.jpeg" alt="gambar"></div><br>  <i>Meme 3.</i> <br><br>  Bagaimanapun, semuanya dimulai untuk fitur-fitur yang dapat diperoleh sebagai jalan keluar dari yang kedua sebelum sebelum mengklasifikasikan lapisan jaringan saraf.  Kami mengujinya pada tugas kami, dan di mana-mana hasilnya lebih baik daripada menggunakan pendekatan klasik untuk menghitung atribut.  Sebagai contoh, dalam masalah pengenalan emosi, penggunaan vektor-d memungkinkan kita untuk memintas 4%, dan artikel terkait diterima di konferensi FICC 2019. Namun, pengenalan emosi adalah cerita yang sangat berbeda, yang akan kita bicarakan nanti. <br><br>  Diposting oleh <b>Gregory Sterling</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">sterling239</a> , Ahli Pembelajaran Jauh, Neurodata Lab. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id422635/">https://habr.com/ru/post/id422635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id422625/index.html">Kami berbicara dengan Troy Miles - programmer "Neuromancer"</a></li>
<li><a href="../id422627/index.html">MongoDB dan riset pasar kerja TI</a></li>
<li><a href="../id422629/index.html">Berhenti memberi makan para penebang! Berikan lebih banyak pengubah! Bidang Final Statis Malas. Sketsa Fitur Draf</a></li>
<li><a href="../id422631/index.html">Terminal QIWI. Cara memanfaatkan teknologi sederhana secara maksimal</a></li>
<li><a href="../id422633/index.html">Bagaimana kami mengotomatiskan pemantauan pekerjaan karyawan dari jaringan pompa bensin federal</a></li>
<li><a href="../id422637/index.html">Hadiah Geek: Perlindungan Auto-Alkash</a></li>
<li><a href="../id422641/index.html">Malam kutub, pemompaan air, dan brankas cerdas: 5 proyek siswa di bidang IoT</a></li>
<li><a href="../id422643/index.html">Perangkat baru dengan IFA 2018</a></li>
<li><a href="../id422645/index.html">Apa pentingnya 196 884 = 196 883 +1? Bagaimana menjelaskannya dengan jari?</a></li>
<li><a href="../id422649/index.html">Multiplayer VR: bagaimana cara mengimplementasikan?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
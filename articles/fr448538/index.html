<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñêüèΩ üçú üèéÔ∏è Cr√©ez une solution de basculement bas√©e sur Oracle RAC et l'architecture AccelStor Shared-Nothing üñãÔ∏è ü§µüèø üåí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Un nombre consid√©rable d'applications d'entreprise et de syst√®mes de virtualisation ont leurs propres m√©canismes pour cr√©er des solutions tol√©rantes a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cr√©ez une solution de basculement bas√©e sur Oracle RAC et l'architecture AccelStor Shared-Nothing</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/accelstor/blog/448538/"><p>  Un nombre consid√©rable d'applications d'entreprise et de syst√®mes de virtualisation ont leurs propres m√©canismes pour cr√©er des solutions tol√©rantes aux pannes.  En particulier, Oracle RAC (Oracle Real Application Cluster) est un cluster de deux serveurs de base de donn√©es Oracle ou plus travaillant ensemble pour √©quilibrer la charge et fournir une tol√©rance aux pannes au niveau du serveur / de l'application.  Pour travailler dans ce mode, un stockage commun est requis, dont le r√¥le est g√©n√©ralement le stockage. </p><br><p>  Comme nous l'avons d√©j√† expliqu√© dans l'un de nos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">articles</a> , le syst√®me de stockage en lui-m√™me, malgr√© la pr√©sence de composants dupliqu√©s (y compris les contr√¥leurs), pr√©sente encore des points de d√©faillance - principalement sous la forme d'un ensemble de donn√©es unique.  Par cons√©quent, pour construire une solution Oracle avec des exigences de fiabilit√© accrues, le sch√©ma ¬´N serveurs - un stockage¬ª doit √™tre compliqu√©. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/l3/lh/1t/l3lh1tmhqobqcqow6yxo-g3j8lc.png"></div><br><a name="habracut"></a><br><p>  Tout d'abord, bien s√ªr, vous devez d√©cider des risques contre lesquels nous essayons de nous assurer.  Dans cet article, nous ne consid√©rerons pas la protection contre les menaces telles qu'une m√©t√©orite est arriv√©e.  La cr√©ation d'une solution de reprise apr√®s sinistre dispers√©e g√©ographiquement restera donc un sujet pour l'un des articles suivants.  Nous examinons ici la solution de r√©cup√©ration apr√®s sinistre Cross-Rack, lorsque la protection est construite au niveau des armoires de serveur.  Les armoires elles-m√™mes peuvent √™tre situ√©es dans la m√™me pi√®ce ou dans des pi√®ces diff√©rentes, mais g√©n√©ralement dans le m√™me b√¢timent. </p><br><p>  Ces armoires doivent contenir tous les √©quipements et logiciels n√©cessaires pour assurer le fonctionnement des bases de donn√©es Oracle quel que soit l'√©tat du "voisin".  En d'autres termes, en utilisant la solution de reprise apr√®s sinistre Cross-Rack, nous √©liminons les risques d'√©chec: </p><br><ul><li>  Serveurs d'applications Oracle </li><li>  Syst√®mes de stockage </li><li>  Syst√®mes de commutation </li><li>  Panne compl√®te de tous les √©quipements de l'armoire: <br><ul><li>  Panne de courant </li><li>  Panne du syst√®me de refroidissement </li><li>  Facteurs externes (homme, nature, etc.) </li></ul></li></ul><br><p>  La duplication des serveurs Oracle implique le principe m√™me d'Oracle RAC et est impl√©ment√©e via l'application.  La duplication des outils de commutation n'est pas non plus un probl√®me.  Mais avec la duplication du syst√®me de stockage, tout n'est pas si simple. </p><br><p>  L'option la plus simple consiste √† r√©pliquer les donn√©es du stockage principal vers la sauvegarde.  Synchrone ou asynchrone, selon les capacit√©s de stockage.  La r√©plication asynchrone soul√®ve imm√©diatement la question de la coh√©rence des donn√©es avec Oracle.  Mais m√™me s'il existe une int√©gration logicielle avec l'application, en tout cas, en cas d'accident sur le syst√®me de stockage principal, une intervention manuelle des administrateurs sera n√©cessaire afin de basculer le cluster vers le stockage de sauvegarde. </p><br><p>  Une option plus complexe est celle des ¬´virtualiseurs¬ª logiciels et / ou mat√©riels des syst√®mes de stockage, qui √©limineront les probl√®mes de coh√©rence et d'intervention manuelle.  Mais la complexit√© du d√©ploiement et de l'administration ult√©rieure, ainsi que le co√ªt tr√®s ind√©cent de telles solutions, en effrayent beaucoup. </p><br><p>  Pour les sc√©narios tels que la reprise apr√®s sinistre sur plusieurs racks, la baie All Flash AccelStor NeoSapphire ‚Ñ¢ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">H710</a> utilisant l'architecture Shared-Nothing est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">parfaite</a> .  Ce mod√®le est un syst√®me de stockage √† deux unit√©s utilisant sa propre technologie FlexiRemap¬Æ pour travailler avec des lecteurs flash.  Gr√¢ce au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FlexiRemap¬Æ</a> NeoSapphire ‚Ñ¢ H710, il peut fournir jusqu'√† 600K IOPS @ 4K en √©criture al√©atoire et 1M + IOPS @ 4K en lecture al√©atoire, ce qui est impossible avec un stockage RAID classique. </p><br><p>  Mais la principale caract√©ristique du NeoSapphire ‚Ñ¢ H710 est l'ex√©cution de deux n≈ìuds en tant que bo√Ætiers s√©par√©s, chacun ayant sa propre copie des donn√©es.  La synchronisation des n≈ìuds s'effectue via l'interface externe InfiniBand.  Gr√¢ce √† cette architecture, les n≈ìuds peuvent √™tre r√©partis sur diff√©rents emplacements sur des distances allant jusqu'√† 100 m, fournissant ainsi la solution de reprise apr√®s sinistre Cross-Rack.  Les deux n≈ìuds fonctionnent compl√®tement en mode synchrone.  Du c√¥t√© de l'h√¥te, le H710 ressemble √† un stockage ordinaire √† double contr√¥leur.  Par cons√©quent, aucune option logicielle et mat√©rielle suppl√©mentaire et des param√®tres particuli√®rement complexes ne doivent √™tre effectu√©s. </p><br><p>  Si vous comparez toutes les solutions de reprise apr√®s incident Cross-Rack d√©crites ci-dessus, la version AccelStor se d√©marque des autres: </p><br><table><tbody><tr><th></th><th>  Architecture AccelStor NeoSapphire ‚Ñ¢ Shared Nothing </th><th>  Virtualiseur logiciel ou mat√©riel de stockage </th><th>  Solution de r√©plication </th></tr><tr><td colspan="4">  <b>La disponibilit√©</b> </td></tr><tr><td>  √âchec du serveur </td><td>  <b>Aucun temps d'arr√™t</b> </td><td>  <b>Aucun temps d'arr√™t</b> </td><td>  <b>Aucun temps d'arr√™t</b> </td></tr><tr><td>  Panne de commutateur </td><td>  <b>Aucun temps d'arr√™t</b> </td><td>  <b>Aucun temps d'arr√™t</b> </td><td>  <b>Aucun temps d'arr√™t</b> </td></tr><tr><td>  √âchec de stockage </td><td>  <b>Aucun temps d'arr√™t</b> </td><td>  <b>Aucun temps d'arr√™t</b> </td><td>  <font color="green"><b>Temps d'arr√™t</b></font> </td></tr><tr><td>  Panne de l'armoire enti√®re </td><td>  <b>Aucun temps d'arr√™t</b> </td><td>  <b>Aucun temps d'arr√™t</b> </td><td>  <font color="green"><b>Temps d'arr√™t</b></font> </td></tr><tr><td colspan="4">  <b>Co√ªt et complexit√©</b> </td></tr><tr><td>  Co√ªt de la solution </td><td>  Faible * </td><td>  <font color="green">√âlev√©</font> </td><td>  <font color="green">√âlev√©</font> </td></tr><tr><td>  Difficult√© de d√©ploiement </td><td>  Faible </td><td>  <font color="green">√âlev√©</font> </td><td>  <font color="green">√âlev√©</font> </td></tr></tbody></table><br><p>  <i>* AccelStor NeoSapphire ‚Ñ¢ est toujours une baie All Flash, qui par d√©finition ne co√ªte pas ¬´3 kopecks¬ª, d'autant plus qu'elle dispose d'une r√©serve de capacit√© double.</i>  <i>Cependant, en comparant le co√ªt total de la solution bas√©e sur celle-ci avec des co√ªts similaires d'autres fournisseurs, le co√ªt peut √™tre consid√©r√© comme faible.</i> </p><br><p>  La topologie de connexion des serveurs d'applications et de tous les n≈ìuds de baies Flash ressemblera √† ceci: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/5i/gb/cw/5igbcwdvm92bpabsylae4iysdra.png"></div><br><p>  Lors de la planification de la topologie, il est √©galement fortement recommand√© de dupliquer les commutateurs de gestion et les interconnexions de serveurs. </p><br><p>  Ci-apr√®s, nous parlerons de la connexion via Fibre Channel.  Dans le cas de l'utilisation d'iSCSI, tout sera le m√™me, ajust√© pour les types de commutateurs utilis√©s et les param√®tres de baie l√©g√®rement diff√©rents. </p><br><h3>  Travaux pr√©paratoires sur le r√©seau </h3><br><div class="spoiler">  <b class="spoiler_title">Mat√©riel et logiciels utilis√©s</b> <div class="spoiler_text"><p>  <b>Sp√©cifications du serveur et du commutateur</b> </p><br><table><tbody><tr><th>  Composants </th><th>  La description </th></tr><tr><td>  Serveurs Oracle Database 11g </td><td>  Deux </td></tr><tr><td>  Syst√®me d'exploitation serveur </td><td>  Oracle Linux </td></tr><tr><td>  Version de la base de donn√©es Oracle </td><td>  11g (RAC) </td></tr><tr><td>  Processeurs par serveur </td><td>  Deux processeurs Intel¬Æ Xeon¬Æ E5-2667 v2 √† 16 c≈ìurs √† 3,30 GHz </td></tr><tr><td>  M√©moire physique par serveur </td><td>  128 Go </td></tr><tr><td>  R√©seau FC </td><td>  FC 16 Gb / s avec trajets multiples </td></tr><tr><td>  FC HBA </td><td>  Emulex Lpe-16002B </td></tr><tr><td>  Ports publics 1 GbE d√©di√©s pour la gestion des clusters </td><td>  Adaptateur Ethernet Intel RJ45 </td></tr><tr><td>  Commutateur FC 16 Gb / s </td><td>  Brocade 6505 </td></tr><tr><td>  Ports priv√©s 10 GbE d√©di√©s pour la synchronisation des donn√©es </td><td>  Intel X520 </td></tr></tbody></table><br><p>  <b>AccelStor NeoSapphhire ‚Ñ¢ All Flash Array Specification</b> </p><br><table><tbody><tr><th>  Composants </th><th>  La description </th></tr><tr><td>  Syst√®me de stockage </td><td>  Mod√®le haute disponibilit√© NeoSapphire ‚Ñ¢: H710 </td></tr><tr><td>  Version d'image </td><td>  4.0.1 </td></tr><tr><td>  Nombre total de disques </td><td>  48 </td></tr><tr><td>  Taille du lecteur </td><td>  1,92 To </td></tr><tr><td>  Type de lecteur </td><td>  SSD </td></tr><tr><td>  Ports cibles FC </td><td>  16 ports 16 Go (8 par n≈ìud) </td></tr><tr><td>  Ports de gestion </td><td>  Le c√¢ble Ethernet 1 GbE se connectant aux h√¥tes via un commutateur Ethernet </td></tr><tr><td>  Port Heartbeat </td><td>  Le c√¢ble Ethernet 1 GbE se connectant entre deux n≈ìuds de stockage </td></tr><tr><td>  Port de synchronisation des donn√©es </td><td>  C√¢ble InfiniBand 56 Gb / s </td></tr></tbody></table><br></div></div><br><p>  Avant de commencer √† utiliser un tableau, vous devez l'initialiser.  Par d√©faut, l'adresse de contr√¥le des deux n≈ìuds est la m√™me (192.168.1.1).  Vous devez vous y connecter un par un et d√©finir de nouvelles adresses de gestion (d√©j√† diff√©rentes) et configurer la synchronisation de l'heure, apr√®s quoi les ports de gestion peuvent √™tre connect√©s √† un seul r√©seau.  Apr√®s cela, les n≈ìuds sont combin√©s en une paire HA en attribuant des sous-r√©seaux aux connexions Interlink. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/c3/kw/sp/c3kwspwqm38yl7ennakzykubswq.jpeg"></div><br><p>  Une fois l'initialisation termin√©e, vous pouvez contr√¥ler la baie √† partir de n'importe quel n≈ìud. </p><br><p>  Ensuite, cr√©ez les volumes n√©cessaires et publiez-les pour les serveurs d'applications. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/6h/4s/gf/6h4sgfinagrbbngoououu-lg1au.png"></div><br><p>  Il est fortement recommand√© de cr√©er plusieurs volumes pour Oracle ASM, car cela augmentera le nombre de cibles pour les serveurs, ce qui am√©liorera finalement les performances globales (plus d'informations sur les files d'attente dans un autre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> ). </p><br><div class="spoiler">  <b class="spoiler_title">Configuration de test</b> <div class="spoiler_text"><table><tbody><tr><th>  Nom du volume de stockage </th><th>  Taille du volume </th></tr><tr><td>  Data01 </td><td>  200 Go </td></tr><tr><td>  Data02 </td><td>  200 Go </td></tr><tr><td>  Data03 </td><td>  200 Go </td></tr><tr><td>  Data04 </td><td>  200 Go </td></tr><tr><td>  Data05 </td><td>  200 Go </td></tr><tr><td>  Data06 </td><td>  200 Go </td></tr><tr><td>  Data07 </td><td>  200 Go </td></tr><tr><td>  Data08 </td><td>  200 Go </td></tr><tr><td>  Data09 </td><td>  200 Go </td></tr><tr><td>  Donn√©es10 </td><td>  200 Go </td></tr><tr><td>  Grid01 </td><td>  1 Go </td></tr><tr><td>  Grid02 </td><td>  1 Go </td></tr><tr><td>  Grid03 </td><td>  1 Go </td></tr><tr><td>  Grid04 </td><td>  1 Go </td></tr><tr><td>  Grid05 </td><td>  1 Go </td></tr><tr><td>  Grid06 </td><td>  1 Go </td></tr><tr><td>  Redo01 </td><td>  100 Go </td></tr><tr><td>  Redo02 </td><td>  100 Go </td></tr><tr><td>  Redo03 </td><td>  100 Go </td></tr><tr><td>  Redo04 </td><td>  100 Go </td></tr><tr><td>  Redo05 </td><td>  100 Go </td></tr><tr><td>  Redo06 </td><td>  100 Go </td></tr><tr><td>  Redo07 </td><td>  100 Go </td></tr><tr><td>  Redo08 </td><td>  100 Go </td></tr><tr><td>  Redo09 </td><td>  100 Go </td></tr><tr><td>  Redo10 </td><td>  100 Go </td></tr></tbody></table><br></div></div><br><h3>  Quelques explications sur les modes de fonctionnement de la baie et les processus qui se produisent dans les situations d'urgence </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/5m/_k/uu/5m_kuurlb-2fy52d8p1tzufcyic.png"></div><br><p>  Chaque jeu de donn√©es de noeud a un param√®tre ¬´num√©ro de version¬ª.  Apr√®s l'initialisation initiale, il est identique et √©gal √† 1. Si, pour une raison quelconque, le num√©ro de version est diff√©rent, il y a toujours une synchronisation des donn√©es de l'ancienne version vers la plus jeune, apr√®s quoi le num√©ro est align√© pour la version la plus jeune, c'est-√†-dire  cela signifie que les copies sont identiques.  Raisons pour lesquelles les versions peuvent varier: </p><br><ul><li>  Red√©marrage planifi√© de l'un des n≈ìuds </li><li>  Un accident sur l'un des n≈ìuds d√ª √† un arr√™t brutal (alimentation, surchauffe, etc.). </li><li>  Connexion InfiniBand rompue avec incapacit√© de synchronisation </li><li>  Plantage sur l'un des n≈ìuds en raison d'une corruption des donn√©es.  Cela n√©cessitera d√©j√† la cr√©ation d'un nouveau groupe HA et une synchronisation compl√®te de l'ensemble de donn√©es. </li></ul><br><p>  Dans tous les cas, le n≈ìud restant en ligne augmente son num√©ro de version de un, de sorte qu'apr√®s avoir reconnect√© la paire, synchronisez son ensemble de donn√©es. </p><br><p>  Si la connexion est perdue via la liaison Ethernet, Heartbeat bascule temporairement vers InfiniBand et revient dans les 10 secondes apr√®s sa restauration. </p><br><h3>  Configuration d'h√¥te </h3><br><p>  Pour garantir la tol√©rance aux pannes et augmenter les performances, vous devez activer la prise en charge MPIO pour la baie.  Pour ce faire, ajoutez des lignes au fichier /etc/multipath.conf, puis rechargez le service multichemin </p><br><div class="spoiler">  <b class="spoiler_title">Texte masqu√©</b> <div class="spoiler_text">  appareils { <br>  appareil { <br>  fournisseur "AStor" <br>  path_grouping_policy "group_by_prio" <br>  path_selector "file d'attente-longueur 0" <br>  path_checker "tur" <br>  comporte "0" <br>  hardware_handler "0" <br>  prio "const" <br>  restauration imm√©diate <br>  fast_io_fail_tmo 5 <br>  dev_loss_tmo 60 <br>  user_friendly_names oui <br>  detect_prio oui <br>  rr_min_io_rq 1 <br>  no_path_retry 0 <br>  } <br>  } <br><br></div></div><br><p>  De plus, pour qu'ASM fonctionne avec MPIO via ASMLib, vous devez modifier le fichier / etc / sysconfig / oracleasm, puis ex√©cuter /etc/init.d/oracleasm scandisks </p><br><div class="spoiler">  <b class="spoiler_title">Texte masqu√©</b> <div class="spoiler_text"><p>  # ORACLEASM_SCANORDER: mod√®les de correspondance pour commander l'analyse du disque <br>  ORACLEASM_SCANORDER = "dm" </p><br><br><p>  # ORACLEASM_SCANEXCLUDE: mod√®les de correspondance pour exclure les disques de l'analyse <br>  ORACLEASM_SCANEXCLUDE = "sd" </p><br><p></p><h4>  Remarque </h4><br><p>  <i>Si vous ne souhaitez pas utiliser ASMLib, vous pouvez utiliser les r√®gles UDEV, qui constituent la base d'ASMLib.</i> </p><br><p>  <i>√Ä partir de la version 12.1.0.2 Oracle Database, l'option est disponible pour l'installation dans le cadre du logiciel ASMFD.</i> </p><br></div></div><br><p>  Assurez-vous que les disques cr√©√©s pour Oracle ASM sont align√©s avec la taille du bloc avec lequel la baie travaille physiquement (4K).  Sinon, des probl√®mes de performances peuvent survenir.  Par cons√©quent, vous devez cr√©er des volumes avec les param√®tres appropri√©s: </p><br><p>  <i>parted / dev / mapper / device-name mklabel gpt mkpart primary 2048s 100% align-check optimal 1</i> </p><br><h3>  Distribution de bases de donn√©es sur les volumes cr√©√©s pour notre configuration de test </h3><br><table><tbody><tr><th>  Nom du volume de stockage </th><th>  Taille du volume </th><th>  Mappage des LUN de volume </th><th>  D√©tails du p√©riph√©rique de volume ASM </th><th>  Taille de l'unit√© d'allocation </th></tr><tr><td>  Data01 </td><td>  200 Go </td><td rowspan="26">  Mappez tous les volumes de stockage au syst√®me de stockage tous les ports de donn√©es </td><td rowspan="10">  Redondance: normale <br>  Nom: DGDATA <br>  Objectif: Fichiers de donn√©es <br></td><td rowspan="10">  4 Mo </td></tr><tr><td>  Data02 </td><td>  200 Go </td></tr><tr><td>  Data03 </td><td>  200 Go </td></tr><tr><td>  Data04 </td><td>  200 Go </td></tr><tr><td>  Data05 </td><td>  200 Go </td></tr><tr><td>  Data06 </td><td>  200 Go </td></tr><tr><td>  Data07 </td><td>  200 Go </td></tr><tr><td>  Data08 </td><td>  200 Go </td></tr><tr><td>  Data09 </td><td>  200 Go </td></tr><tr><td>  Donn√©es10 </td><td>  200 Go </td></tr><tr><td>  <font color="#248dee">Grid01</font> </td><td>  <font color="#248dee">1 Go</font> </td><td rowspan="3">  <font color="#248dee">Redondance: normale</font> <font color="#248dee"><br></font>  <font color="#248dee">Nom: DGGRID1</font> <font color="#248dee"><br></font>  <font color="#248dee">Objectif: Grille: CRS et vote</font> <br></td><td rowspan="3">  <font color="#248dee">4 Mo</font> </td></tr><tr><td>  <font color="#248dee">Grid02</font> </td><td>  <font color="#248dee">1 Go</font> </td></tr><tr><td>  <font color="#248dee">Grid03</font> </td><td>  <font color="#248dee">1 Go</font> </td></tr><tr><td>  Grid04 </td><td>  1 Go </td><td rowspan="3">  Redondance: normale <br>  Nom: DGGRID2 <br>  Objectif: Grille: CRS et vote <br></td><td rowspan="3">  4 Mo </td></tr><tr><td>  Grid05 </td><td>  1 Go </td></tr><tr><td>  Grid06 </td><td>  1 Go </td></tr><tr><td>  <font color="#248dee">Redo01</font> </td><td>  <font color="#248dee">100 Go</font> </td><td rowspan="5">  <font color="#248dee">Redondance: normale</font> <font color="#248dee"><br></font>  <font color="#248dee">Nom: DGREDO1</font> <font color="#248dee"><br></font>  <font color="#248dee">Objectif: r√©tablir le journal du thread 1</font> <font color="#248dee"><br></font> <br></td><td rowspan="5">  <font color="#248dee">4 Mo</font> </td></tr><tr><td>  <font color="#248dee">Redo02</font> </td><td>  <font color="#248dee">100 Go</font> </td></tr><tr><td>  <font color="#248dee">Redo03</font> </td><td>  <font color="#248dee">100 Go</font> </td></tr><tr><td>  <font color="#248dee">Redo04</font> </td><td>  <font color="#248dee">100 Go</font> </td></tr><tr><td>  <font color="#248dee">Redo05</font> </td><td>  <font color="#248dee">100 Go</font> </td></tr><tr><td>  Redo06 </td><td>  100 Go </td><td rowspan="5">  Redondance: normale <br>  Nom: DGREDO2 <br>  Objectif: r√©tablir le journal du thread 2 <br><br></td><td rowspan="5">  4 Mo </td></tr><tr><td>  Redo07 </td><td>  100 Go </td></tr><tr><td>  Redo08 </td><td>  100 Go </td></tr><tr><td>  Redo09 </td><td>  100 Go </td></tr><tr><td>  Redo10 </td><td>  100 Go </td></tr></tbody></table><br><div class="spoiler">  <b class="spoiler_title">Param√®tres de la base de donn√©es</b> <div class="spoiler_text"><ul><li>  Taille du bloc = 8K </li><li>  Espace d'√©change = 16 Go </li><li>  D√©sactiver AMM (gestion automatique de la m√©moire) </li><li>  D√©sactiver les pages immenses transparentes </li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Autres r√©glages</b> <div class="spoiler_text"><p>  <u># vi /etc/sysctl.conf</u> <br>  ‚úì fs.aio-max-nr = 1048576 <br>  ‚úì fs.file-max = 6815744 <br>  ‚úì kernel.shmmax 103079215104 <br>  ‚úì kernel.shmall 31457280 <br>  ‚úì kernel.shmmn 4096 <br>  ‚úì kernel.sem = 250 32000 100 128 <br>  ‚úì net.ipv4.ip_local_port_range = 9000 65500 <br>  ‚úì net.core.rmem_default = 262144 <br>  ‚úì net.core.rmem_max = 4194304 <br>  ‚úì net.core.wmem_default = 262144 <br>  ‚úì net.core.wmem_max = 1048586 <br>  ‚úì vm.swappiness = 10 <br>  ‚úì vm.min_free_kbytes = 524288 # ne le d√©finissez pas si vous utilisez Linux x86 <br>  ‚úì vm.vfs_cache_pressure = 200 <br>  ‚úì vm.nr_hugepages = 57000 </p><br><br><p>  <u># vi /etc/security/limits.conf</u> <br>  ‚úì grille soft nproc 2047 <br>  ‚úì grille dure nproc 16384 <br>  ‚úì grille nofile doux 1024 <br>  ‚úì grille nofile dur 65536 <br>  ‚úì soft stack de grille 10240 <br>  ‚úì pile dure de grille 32768 <br>  ‚úì oracle soft nproc 2047 <br>  ‚úì oracle hard nproc 16384 <br>  ‚úì oracle soft nofile 1024 <br>  ‚úì nofile dur oracle 65536 <br>  ‚úì pile souple oracle 10240 <br>  ‚úì disque dur oracle 32768 <br>  ‚úì soft lock 120795954 <br>  ‚úì m√©mlock dur 120795954 <br></p><br><p>  <u>sqlplus ¬´/ as sysdba¬ª</u> <br>  modifier les processus de d√©finition du syst√®me = 2000 scope = spfile; <br>  alter system set open_cursors = 2000 scope = spfile; <br>  alter system set session_cached_cursors = 300 scope = spfile; <br>  alter system set db_files = 8192 scope = spfile; <br></p><br><br></div></div><br><h3>  Test de tol√©rance aux pannes </h3><br><p>  √Ä des fins de d√©monstration, HammerDB a √©t√© utilis√© pour √©muler la charge OLTP.  Configuration de HammerDB: </p><br><table><tbody><tr><td>  <b>Nombre d'entrep√¥ts</b> </td><td>  256 </td></tr><tr><td>  Total des transactions par utilisateur </td><td>  1000000000000 </td></tr><tr><td>  Utilisateurs virtuels </td><td>  256 </td></tr></tbody></table><br><p>  En cons√©quence, l'indicateur TPM 2.1M a √©t√© obtenu, ce qui est loin de la limite de performance de la baie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">H710</a> , mais c'est le ¬´plafond¬ª pour la configuration mat√©rielle actuelle des serveurs (principalement due aux processeurs) et leur nombre.  Le but de ce test est toujours de d√©montrer la tol√©rance aux pannes de la solution dans son ensemble, et non d'atteindre des performances maximales.  Par cons√©quent, nous allons simplement construire sur cette figure. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/3o/ds/id/3odsid2wr0ynssl4zuu8idq8dfq.png"></div><br><h3>  Test de d√©faillance d'un des n≈ìuds </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/ar/tf/og/artfogfilgwzy2vtxlsyvkp98vu.png"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/zk/iv/xt/zkivxtazysrew4hhzjan-vujnma.png"></div><br><p>  Les h√¥tes ont perdu certains des chemins d'acc√®s au magasin, continuant √† travailler sur les autres avec le deuxi√®me n≈ìud.  Les performances ont chut√© pendant quelques secondes en raison de la restructuration des chemins, puis sont revenues √† la normale.  Aucune interruption de service n'est survenue. </p><br><h3>  Test de d√©faillance de l'armoire avec tous les √©quipements </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/mq/my/2b/mqmy2bzrge24zhnj217spj2rts4.png"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/eq/nh/-8/eqnh-8pwbhyzqgdleh1tsiafkr0.png"></div><br><p>  Dans ce cas, la performance a √©galement chut√© pendant quelques secondes en raison de la restructuration des chemins, puis est revenue √† la moiti√© de la valeur de l'indicateur d'origine.  Le r√©sultat a √©t√© divis√© par deux par rapport √† l'original en raison de l'exclusion du fonctionnement d'un serveur d'applications.  Il n'y a pas eu non plus d'interruption de service. </p><br><blockquote>  Si vous avez besoin d'impl√©menter une solution de reprise apr√®s sinistre Cross-Rack tol√©rante aux pannes pour Oracle √† un co√ªt raisonnable et avec peu d'efforts de d√©ploiement / administration, alors travailler avec Oracle RAC et l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">architecture AccelStor Shared-Nothing</a> serait l'une des meilleures options.  Au lieu d'Oracle RAC, il peut y avoir tout autre logiciel qui pr√©voit la mise en cluster, le m√™me SGBD ou les syst√®mes de virtualisation, par exemple.  Le principe de construction de la solution restera le m√™me.  Et le score final est nul pour RTO et RPO. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr448538/">https://habr.com/ru/post/fr448538/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr448528/index.html">Service VPN Wireguard gratuit sur AWS</a></li>
<li><a href="../fr448530/index.html">Comment le m√©gaphone a dormi sur les abonnements mobiles</a></li>
<li><a href="../fr448532/index.html">Centre de donn√©es spatiales. R√©sumant l'exp√©rience</a></li>
<li><a href="../fr448534/index.html">Pourquoi avons-nous besoin de commutateurs industriels avec CEM am√©lior√©e?</a></li>
<li><a href="../fr448536/index.html">Transparence - La panac√©e des bouchers</a></li>
<li><a href="../fr448540/index.html">VMware NSX pour les plus petits. Partie 5. Configuration de l'√©quilibreur de charge</a></li>
<li><a href="../fr448544/index.html">Faisceaux en acier. Comment sont-ils form√©s</a></li>
<li><a href="../fr448546/index.html">UITableView tailles d'en-t√™te et de pied de page automatiques avec AutoLayout</a></li>
<li><a href="../fr448548/index.html">La construction dans l'art: de Brueghel √† Vasya Lozhkin</a></li>
<li><a href="../fr448550/index.html">Ouverture du concours de rapport √† #PAYMENTSECURITY 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
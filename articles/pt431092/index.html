<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîí ü§∞üèª üìÆ ROS: mapa de profundidade no Raspberry Pi "baixo n√≠vel de sangue" üí™üèº üïô üëñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Se voc√™ usa o ROS ao criar rob√¥s, provavelmente sabe que ele tem suporte para trabalhar com c√¢meras est√©reo. Voc√™ pode criar, por exemplo, um mapa de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ROS: mapa de profundidade no Raspberry Pi "baixo n√≠vel de sangue"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431092/"><img src="https://habrastorage.org/webt/jl/ks/vn/jlksvndgnvhxzgvr_jmo19ni580.jpeg" alt="imagem"><br><br>  Se voc√™ usa o ROS ao criar rob√¥s, provavelmente sabe que ele tem suporte para trabalhar com c√¢meras est√©reo.  Voc√™ pode criar, por exemplo, um mapa de profundidade da parte vis√≠vel do espa√ßo ou uma nuvem de pontos.  E me perguntei como seria f√°cil usar uma c√¢mera est√©reo StereoPi baseada em framboesa no ROS.  Antes, eu j√° estava convencido de que o mapa de profundidade foi perfeitamente constru√≠do pelo OpenCV, mas nunca lidei com o ROS.  E eu decidi tentar.  Quero falar sobre minhas aventuras para encontrar uma solu√ß√£o. <br><a name="habracut"></a><br><h3>  1. Existe algum ROS no Raspberry Pi? </h3><br>  No come√ßo, decidi descobrir se era poss√≠vel criar ROS para o Raspberry Pi.  A primeira coisa que o Google me disse foi uma lista de instru√ß√µes para instalar vers√µes diferentes do ROS no Raspberry Pi, a saber, esta p√°gina <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">wiki do ROS</a> <br><br>  Bem, j√° existe algo para come√ßar!  Lembrei-me bem de quanto tempo levava para criar o OpenCV no Raspberry (cerca de oito horas), ent√£o decidi procurar imagens prontas de cart√µes MicroSD para economizar tempo. <br><br><h3>  2. Existem imagens de cart√£o microSD prontas com ROS para Raspberry? </h3><br>  Aconteceu que esse problema j√° foi resolvido por v√°rias equipes de desenvolvimento.  Se voc√™ n√£o cria vers√µes √∫nicas de entusiastas, destacam-se algumas imagens que s√£o constantemente atualizadas com o lan√ßamento de novas vers√µes do sistema operacional e do ROS. <br><br>  A primeira op√ß√£o √© o ROS instalado no sistema operacional Raspbian nativo da equipe ROSbots. Aqui est√° uma p√°gina com um link de imagem atualizado: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pronto para usar a imagem raspbian-stretch-ros-opencv</a> <br><br>  A segunda s√£o as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">imagens da Ubiquiti Robotics no ubuntu</a> . <br><br>  Bem, a segunda pergunta tamb√©m foi r√°pida o suficiente.  √â hora de mergulhar mais fundo. <br><br><h3>  3. Como o ROS funciona com a c√¢mera Raspberry Pi? </h3><br>  E quais c√¢meras est√©reo geralmente s√£o suportadas no ROS?  Olhei a p√°gina com c√¢meras est√©reo, para as quais foi declarada a disponibilidade de drivers prontos para o ROS, este: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">wiki.ros.org/Sensors</a> <br><br>  Havia duas se√ß√µes: <br>  <i><b>2.3 Sensores 3D (tel√™metros e c√¢meras RGB-D)</b></i> <i><br></i>  <i><b>2.5 C√¢meras</b></i> <br>  Descobriu-se que, na primeira se√ß√£o, n√£o apenas as c√¢meras est√©reo, mas tamb√©m os sensores TOF e os lidares de digitaliza√ß√£o est√£o listados - em geral, tudo o que pode fornecer informa√ß√µes imediatamente em 3D.  E no segundo j√° existem c√¢meras est√©reo.  Tentar ver os drivers de v√°rias c√¢meras est√©reo n√£o contribuiu para a minha alegria, pois sugeria uma imers√£o s√©ria no c√≥digo. <br><br>  Ok, d√™ um passo atr√°s.  Como funciona com uma √∫nica c√¢mera Raspberry Pi no ROS? <br><br>  Tr√™s surpresas agrad√°veis ‚Äã‚Äãme aguardavam aqui: <br><br><ul><li>  acontece que, para o ROS, existe um n√≥ <b><i>raspicam_node</i></b> especial apenas para trabalhar com a c√¢mera Raspberry Pi </li><li>  tipos de n√≥ est√£o no github, o c√≥digo √© mantido ativamente e bem documentado: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/UbiquityRobotics/raspicam_node</a> </li><li>  O autor do n√≥ Rohan Agrawal ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">@Rohbotics</a> ) trabalha para uma empresa que oferece suporte ativo a uma das imagens prontas para o Raspberry Pi </li></ul><br>  Eu olhei para o reposit√≥rio github raspicam_node e olhei para problemas.  L√° encontrei um problema em aberto com o amplo nome "modo est√©reo" quase sete meses atr√°s, sem respostas e coment√°rios.  Na verdade, todos os eventos se desenvolveram mais. <br><br><h3>  4. Hardcore ou n√£o? </h3><br>  Para n√£o fazer perguntas √†s crian√ßas aos autores, decidi examinar o c√≥digo-fonte e avaliar o que amea√ßa a adi√ß√£o do modo est√©reo.  Eu estava mais interessado na parte do sistema aqui: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/UbiquityRobotics/raspicam_node/tree/kinetic/src</a> <br>  Bem, os caras escreveram o motorista mergulhando no n√≠vel MMAL.  Tamb√©m me lembrei de que o c√≥digo fonte das framboesas no modo est√©reo tamb√©m est√° aberto (a evolu√ß√£o pode ser rastreada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui no f√≥rum da framboesa</a> ), e a tarefa de escrever um driver est√©reo completo √© solucion√°vel, mas em grande escala.  Observando a descri√ß√£o dos drivers de outras c√¢meras, percebi que era necess√°rio publicar n√£o apenas as fotos esquerda e direita, mas tamb√©m fornecer os par√¢metros de ambas as c√¢meras, aplicar resultados de calibra√ß√£o a cada uma e fazer muitas outras coisas.  Isso atraiu experimentos por um ou dois meses.  Portanto, decidi paralelizar a abordagem, a saber: escreva ao autor uma pergunta sobre o suporte est√©reo e procure uma solu√ß√£o mais simples, mas funcional. <br><br><h3>  5. Di√°logos com o autor </h3><br>  No t√≥pico sobre o modo est√©reo no github, fiz uma pergunta ao autor, mencionando que o est√©reo √© suportado por framboesas desde 2014 e sugeri, se necess√°rio, enviar a ele um quadro de depura√ß√£o para experimentos.  Deixe-me lembr√°-lo de que eu ainda duvidava que nesta distribui√ß√£o o aparelho de som funcione como no Raspbian nativo. <br><br>  Rohan respondeu surpreendentemente r√°pido, dizendo que o distrito deles usa um n√∫cleo de framboesa e tudo deve funcionar.  E pediu para verificar em uma de suas assembl√©ias. <br><br>  N√∫cleo de framboesa!  Viva!  Teoricamente, uma imagem est√©reo deve ser capturada sem dan√ßar com um pandeiro! <br><br>  Baixei e implantei a imagem mais recente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">usando um link de Rohan</a> e executei um script python simples para capturar um par est√©reo.  Funcionou! <br><br><img src="https://habrastorage.org/webt/vh/6i/fg/vh6ifg37hbuzr0khcyxnuxpq5fa.jpeg" alt="imagem"><br><br>  Depois disso, Rohan escreveu que procuraria o c√≥digo do driver para o modo est√©reo e escreveu algumas perguntas.  Por exemplo, nosso modo est√©reo produz uma imagem colada e precisamos cort√°-la em duas - esquerda e direita.  E a segunda pergunta sobre os par√¢metros de calibra√ß√£o de cada c√¢mera √© como lidar com isso. <br><br>  Eu disse que, como primeiro passo, voc√™ pode tirar fotos de c√¢meras de forma independente.  Sim, eles n√£o ser√£o sincronizados no tempo de captura e nas configura√ß√µes (como brilho, contraste e balan√ßo de branco), mas, como primeiro passo, isso pode diminuir. <br><br>  Rohan prontamente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lan√ßou um patch</a> que permite especificar diretamente do ROS de qual c√¢mera tirar fotos.  Eu verifiquei - escolher uma c√¢mera funciona, j√° √© um excelente resultado. <br><br><h3>  6. Ajuda inesperada </h3><br>  E, em seguida, um coment√°rio do usu√°rio Wezzoid aparece no t√≥pico.  Ele disse que estava fazendo um projeto baseado em uma c√¢mera est√©reo em um Pi Compute 3 usando devboards de framboesa.  Seu rob√¥ ambulante de quatro patas rastreou a posi√ß√£o do objeto no espa√ßo, mudou a posi√ß√£o das c√¢meras e manteve a dist√¢ncia especificada (o projeto est√° publicado em hackaday.io <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ). <br><br><img src="https://habrastorage.org/webt/og/sp/iy/ogspiywmjvs67yhodxpbes0pd-8.jpeg" alt="imagem"><br><br>  E ele compartilhou o c√≥digo no qual ele pegou a imagem, cortou ao meio com python e compartilhou como n√≥s das c√¢meras esquerda e direita. <br>  Python n√£o √© um amigo muito r√°pido nesses assuntos, ent√£o ele usou uma baixa resolu√ß√£o de 320x240 e um truque de boa vida.  Se capturarmos uma imagem est√©reo lado a lado (uma c√¢mera √† esquerda da imagem est√©reo e a segunda √† direita), o python deve cortar cada uma das 240 linhas pela metade.  Mas se voc√™ tirar uma foto de cima para baixo (a c√¢mera esquerda √© a metade superior do quadro, a direita √© a parte inferior), o python corta o array ao meio em uma opera√ß√£o.  O que foi feito com sucesso pelo usu√°rio Wezzoid. <br>  Al√©m disso, ele postou seu c√≥digo python no Pastebin, que fez essa opera√ß√£o.  Aqui est√°: <br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo Wezzoid para publicar n√≥s de duas c√¢meras de um par est√©reo</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/env python # picamera stereo ROS node using dual CSI Pi CS3 board # Wes Freeman 2018 # modified from code by Adrian Rosebrock, pyimagesearch.com # and jensenb, https://gist.github.com/jensenb/7303362 from picamera.array import PiRGBArray from picamera import PiCamera import time import rospy from sensor_msgs.msg import CameraInfo, Image import yaml import io import signal # for ctrl-C handling import sys def parse_calibration_yaml(calib_file): with file(calib_file, 'r') as f: params = yaml.load(f) cam_info = CameraInfo() cam_info.height = params['image_height'] cam_info.width = params['image_width'] cam_info.distortion_model = params['distortion_model'] cam_info.K = params['camera_matrix']['data'] cam_info.D = params['distortion_coefficients']['data'] cam_info.R = params['rectification_matrix']['data'] cam_info.P = params['projection_matrix']['data'] return cam_info # cam resolution res_x = 320 #320 # per camera res_y = 240 #240 target_FPS = 15 # initialize the camera print "Init camera..." camera = PiCamera(stereo_mode = 'top-bottom',stereo_decimate=False) camera.resolution = (res_x, res_y*2) # top-bottom stereo camera.framerate = target_FPS # using several camera options can cause instability, hangs after a while camera.exposure_mode = 'antishake' #camera.video_stabilization = True # fussy about res? stream = io.BytesIO() # ---------------------------------------------------------- #setup the publishers print "init publishers" # queue_size should be roughly equal to FPS or that causes lag? left_img_pub = rospy.Publisher('left/image_raw', Image, queue_size=1) right_img_pub = rospy.Publisher('right/image_raw', Image, queue_size=1) left_cam_pub = rospy.Publisher('left/camera_info', CameraInfo, queue_size=1) right_cam_pub = rospy.Publisher('right/camera_info', CameraInfo, queue_size=1) rospy.init_node('stereo_pub') # init messages left_img_msg = Image() left_img_msg.height = res_y left_img_msg.width = res_x left_img_msg.step = res_x*3 # bytes per row: pixels * channels * bytes per channel (1 normally) left_img_msg.encoding = 'rgb8' left_img_msg.header.frame_id = 'stereo_camera' # TF frame right_img_msg = Image() right_img_msg.height = res_y right_img_msg.width = res_x right_img_msg.step = res_x*3 right_img_msg.encoding = 'rgb8' right_img_msg.header.frame_id = 'stereo_camera' imageBytes = res_x*res_y*3 # parse the left and right camera calibration yaml files left_cam_info = parse_calibration_yaml('/home/pi/catkin_ws/src/mmstereocam/camera_info/left.yaml') right_cam_info = parse_calibration_yaml('/home/pi/catkin_ws/src/mmstereocam/camera_info/right.yaml') # --------------------------------------------------------------- # this is supposed to shut down gracefully on CTRL-C but doesn't quite work: def signal_handler(signal, frame): print 'CTRL-C caught' print 'closing camera' camera.close() time.sleep(1) print 'camera closed' sys.exit(0) signal.signal(signal.SIGINT, signal_handler) #----------------------------------------------------------- print "Setup done, entering main loop" framecount=0 frametimer=time.time() toggle = True # capture frames from the camera for frame in camera.capture_continuous(stream, format="rgb", use_video_port=True): framecount +=1 stamp = rospy.Time.now() left_img_msg.header.stamp = stamp right_img_msg.header.stamp = stamp left_cam_info.header.stamp = stamp right_cam_info.header.stamp = stamp left_cam_pub.publish(left_cam_info) right_cam_pub.publish(right_cam_info) frameBytes = stream.getvalue() left_img_msg.data = frameBytes[:imageBytes] right_img_msg.data = frameBytes[imageBytes:] #publish the image pair left_img_pub.publish(left_img_msg) right_img_pub.publish(right_img_msg) # console info if time.time() &gt; frametimer +1.0: if toggle: indicator = ' o' # just so it's obviously alive if values aren't changing else: indicator = ' -' toggle = not toggle print 'approx publish rate:', framecount, 'target FPS:', target_FPS, indicator frametimer=time.time() framecount=0 # clear the stream ready for next frame stream.truncate(0) stream.seek(0)</span></span></code> </pre> <br></div></div><br><h3>  7. Comece a publicar os n√≥s das c√¢meras esquerda e direita </h3><br>  No primeiro in√≠cio, o c√≥digo amaldi√ßoou que n√£o havia acesso aos arquivos YML com os par√¢metros da c√¢mera.  Usei c√¢meras V2 cor de framboesa e lembrei que arquivos prontos com resultados de calibra√ß√£o para diferentes modelos de c√¢mera chegaram ao <i><b>raspicam_node</b></i> no github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/UbiquityRobotics/raspicam_node/tree/kinetic/camera_info</a> <br>  Peguei um deles, fiz duas c√≥pias e salvei com os nomes left.yml e right.yml, escrevendo neles a resolu√ß√£o da c√¢mera a partir do script do autor.  Aqui est√° o que aconteceu com a c√¢mera esquerda: <br><br><div class="spoiler">  <b class="spoiler_title">left.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">image_width: 320 image_height: 240 camera_name: left camera_matrix: rows: 3 cols: 3 data: [1276.704618338571, 0, 634.8876509199106, 0, 1274.342831275509, 379.8318028940378, 0, 0, 1] distortion_model: plumb_bob distortion_coefficients: rows: 1 cols: 5 data: [0.1465167016954302, -0.2847343180128725, 0.00134017721235817, -0.004309553450829512, 0] rectification_matrix: rows: 3 cols: 3 data: [1, 0, 0, 0, 1, 0, 0, 0, 1] projection_matrix: rows: 3 cols: 4 data: [1300.127197265625, 0, 630.215390285608, 0, 0, 1300.670166015625, 380.1702884455881, 0, 0, 0, 1, 0]</code> </pre> <br></div></div><br>  √Ä direita, o nome da c√¢mera √© substitu√≠do por right e o pr√≥prio arquivo √© nomeado right.yml.  O restante do arquivo √© id√™ntico. <br><br>  Como n√£o planejava fazer um projeto complexo, n√£o repeti os caminhos longos do autor com subpastas e apenas coloquei os arquivos na raiz da pasta inicial ao lado do script python.  O c√≥digo foi iniciado com sucesso, exibindo mensagens de status no console. <br><br><img src="https://habrastorage.org/webt/sz/oi/my/szoimymcugjmfggyfdez98l3kku.jpeg" alt="imagem"><br><br>  Resta apenas ver o que foi finalmente publicado por nossas c√¢meras esquerda e direita.  Para fazer isso, lancei rqt_image_view.  Os itens / left / image_raw e / right / image_raw apareceram no menu suspenso.Quando os selecionei, vi imagens das c√¢meras esquerda e direita. <br><br><img src="https://habrastorage.org/webt/og/1i/du/og1iduqsqdfjq_j2ijp-fkzfxhm.jpeg" alt="imagem"><br><br>  Bem, essa coisa ganhou!  Agora a parte divertida. <br><br><h3>  8. Olhamos para o mapa das profundezas. </h3><br>  Para visualizar o mapa de profundidade, n√£o propus minha pr√≥pria abordagem e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reparei no manual ROS</a> cl√°ssico <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">para definir par√¢metros est√©reo</a> . <br>  A partir da√≠, descobri que seria bom publicar os dois n√≥s em um espa√ßo para nome espec√≠fico, e n√£o na raiz, como o Wezzoid.  Como resultado, as antigas linhas de publica√ß√£o do formul√°rio <br><br><pre> <code class="python hljs">left_img_pub = rospy.Publisher(<span class="hljs-string"><span class="hljs-string">'left/image_raw'</span></span>, Image, queue_size=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  come√ßou a ficar assim: <br><br><pre> <code class="python hljs">left_img_pub = rospy.Publisher(<span class="hljs-string"><span class="hljs-string">'stereo/right/image_raw'</span></span>, Image, queue_size=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  Depois disso, lan√ßamos o n√≥ de processamento no modo est√©reo stereo_image_proc: <br><br><pre> <code class="bash hljs">ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_ige_proc</code> </pre> <br>  Bem, tamb√©m queremos ver o resultado, ent√£o iniciamos o observador: <br><br><pre> <code class="bash hljs">rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color</code> </pre> <br>  E para configurar os par√¢metros do mapa de profundidade, execute o utilit√°rio de configura√ß√£o: <br><br><pre> <code class="bash hljs">rosrun rqt_reconfigure rqt_reconfigure</code> </pre> <br>  Como resultado, vemos a figura no in√≠cio do artigo.  Aqui est√° um pouco maior: <br><br><img src="https://habrastorage.org/webt/qc/oy/s8/qcoys8o4-yrwfxgc7kynjrxhd9m.jpeg" alt="imagem"><br><br>  Todos os arquivos que eu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publiquei</a> no github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/realizator/StereoPi-ROS-depth-map-test</a> <br><br><h3>  9. Planos imediatos </h3><br>  Ap√≥s minha publica√ß√£o do resultado em uma discuss√£o no github, Rohan escreveu ‚ÄúLegal!  Eu preciso pegar meu StereoPi. ‚Äù  Escrevemos para ele por correio, enviei uma taxa.  Espero que, com o hardware de trabalho em suas m√£os, seja mais f√°cil terminar e depurar um driver est√©reo completo para ROS e Raspberry. <br><br><h3>  10. Resumo </h3><br>  Um mapa de profundidade de uma imagem est√©reo em framboesas no ROS pode ser obtido de v√°rias maneiras.  O caminho escolhido para a verifica√ß√£o r√°pida n√£o √© o mais ideal em termos de desempenho, mas pode ser usado para fins de aplicativo.  A beleza de sua simplicidade e a capacidade de iniciar imediatamente experimentos. <br><br>  Bem, pelo engra√ßado: depois de receber os resultados, notei que Wezzoid, que prop√¥s sua solu√ß√£o, foi o autor da pergunta sobre a publica√ß√£o de duas imagens est√©reo.  Ele se perguntou, ele decidiu. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt431092/">https://habr.com/ru/post/pt431092/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt431082/index.html">Kotlin: procurando chefe de marketing</a></li>
<li><a href="../pt431084/index.html">Em qualquer situa√ß√£o incompreens√≠vel - escreva scripts</a></li>
<li><a href="../pt431086/index.html">Tudo o que voc√™ queria saber sobre o PVS-Studio e n√£o hesitou em perguntar</a></li>
<li><a href="../pt431088/index.html">Gerenciamento de arquivos mal feito - Parte 1: Originalmente dos anos 90</a></li>
<li><a href="../pt431090/index.html">Um bot VK, um C # e uma laranja</a></li>
<li><a href="../pt431094/index.html">Paci√™ncia Sort</a></li>
<li><a href="../pt431096/index.html">Como criar um produto de bot de bate-papo</a></li>
<li><a href="../pt431098/index.html">Mesmo um inc√™ndio n√£o √© um obst√°culo ou o Zimbra Speed ‚Äã‚ÄãRecovery ap√≥s um desastre</a></li>
<li><a href="../pt431102/index.html">Como o endere√ßo f√≠sico √© exibido nas cadeias e bancos de DRAM</a></li>
<li><a href="../pt431104/index.html">Como desenvolvemos a Neoflex Expertise em DevOps</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
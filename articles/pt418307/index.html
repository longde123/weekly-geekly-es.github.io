<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õ∏Ô∏è üè∑Ô∏è üññüèæ Ferramentas de aprendizado de m√°quina da Apple üë®üèæ‚Äçüéì ü¶ã üòî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nos √∫ltimos anos, o t√≥pico intelig√™ncia artificial e aprendizado de m√°quina deixou de ser algo para pessoas do reino da fic√ß√£o e entrou firmemente na ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ferramentas de aprendizado de m√°quina da Apple</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redmadrobot/blog/418307/"><p><img src="https://habrastorage.org/webt/si/by/p7/sibyp7evcy3vtvyh7jthlpqh68m.png"></p><br><p>  Nos √∫ltimos anos, o t√≥pico intelig√™ncia artificial e aprendizado de m√°quina deixou de ser algo para pessoas do reino da fic√ß√£o e entrou firmemente na vida cotidiana.  As redes sociais se oferecem para participar de eventos que s√£o do nosso interesse, carros nas estradas aprendem a se locomover sem motorista e um assistente de voz no telefone informa quando √© melhor sair de casa para evitar congestionamentos e se deve levar um guarda-chuva. </p><br><p>  Neste artigo, consideraremos as ferramentas de aprendizado de m√°quina oferecidas pelos desenvolvedores da Apple, analisaremos o que a empresa mostrou de novo nesta √°rea no WWDC18 e tentaremos entender como colocar tudo isso em pr√°tica. </p><a name="habracut"></a><br><h2 id="mashinnoe-obuchenie">  Aprendizado de m√°quina </h2><br><p>  Portanto, o aprendizado de m√°quina √© um processo durante o qual um sistema, usando certos algoritmos de an√°lise de dados e processando um grande n√∫mero de exemplos, identifica padr√µes e os utiliza para prever as caracter√≠sticas de novos dados. </p><br><p>  O aprendizado de m√°quina nasceu da teoria de que os computadores podem aprender por conta pr√≥pria, ainda n√£o programados para executar determinadas a√ß√µes.  Em outras palavras, diferentemente dos programas convencionais com instru√ß√µes predefinidas para solucionar problemas espec√≠ficos, o aprendizado de m√°quina permite que o sistema aprenda como reconhecer padr√µes de forma independente e fazer previs√µes. </p><br><h2 id="bnns-i-cnn">  BNNS e CNN </h2><br><p>  A Apple usa a tecnologia de aprendizado de m√°quina em seus dispositivos h√° algum tempo: o Mail identifica emails de spam, o Siri ajuda a encontrar respostas rapidamente para suas perguntas, o Photos reconhece rostos em imagens. </p><br><p> Na WWDC16, a empresa introduziu duas APIs baseadas em redes neurais - sub-rotinas de redes neurais b√°sicas (BNNS) e redes neurais convolucionais (CNN).  O BNNS faz parte do sistema Accelerate, que √© a base para realizar c√°lculos r√°pidos na CPU, e o CNN √© a biblioteca Metal Performance Shaders que usa a GPU.  Voc√™ pode aprender mais sobre essas tecnologias, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . </p><br><h2 id="core-ml-i-turi-create">  Core ML e Turi Create </h2><br><p>  No ano passado, a Apple anunciou uma estrutura que facilita muito o trabalho com tecnologias de aprendizado de m√°quina - o Core ML.  Ele se baseia na id√©ia de pegar um modelo de dados pr√©-treinado e integr√°-lo ao seu aplicativo em apenas algumas linhas de c√≥digo. </p><br><p><img src="https://habrastorage.org/webt/eg/dl/rz/egdlrzk40ao2z5a_eijvug8dhbc.png"></p><br><p>  Usando o Core ML, voc√™ pode implementar v√°rias fun√ß√µes: </p><br><ul><li>  defini√ß√£o de objetos em uma foto e v√≠deo; </li><li>  introdu√ß√£o assistida de texto; </li><li>  rastreamento e reconhecimento de rosto; </li><li>  an√°lise de movimento; </li><li>  defini√ß√£o de c√≥digo de barras; </li><li>  compreens√£o e reconhecimento de texto; </li><li>  reconhecimento de imagem em tempo real; </li><li>  estiliza√ß√£o de imagens; </li><li>  e muito mais </li></ul><br><p>  O Core ML, por sua vez, usa Metal, Accelerate e BNNS de baixo n√≠vel e, portanto, os resultados dos c√°lculos s√£o muito r√°pidos. </p><br><p>  O kernel suporta redes neurais, modelos lineares generalizados, engenharia de recursos, algoritmos de tomada de decis√£o baseados em √°rvores (conjuntos de √°rvores), m√©todo de m√°quinas de vetores de suporte e modelos de pipeline. </p><br><p>  Mas a Apple n√£o mostrou inicialmente suas pr√≥prias tecnologias para criar e treinar modelos, mas apenas converteu outras estruturas populares: Caffe, Keras, scikit-learn, XGBoost, LIBSVM. </p><br><p>  O uso de ferramentas de terceiros geralmente n√£o era a tarefa mais f√°cil, os modelos treinados eram bastante grandes e o treinamento em si demorava muito tempo. </p><br><p>  No final do ano, a empresa introduziu o Turi Create - uma estrutura de aprendizado de modelos cuja principal id√©ia era a facilidade de uso e suporte para um grande n√∫mero de cen√°rios - classifica√ß√£o de imagens, defini√ß√£o de objetos, sistemas de recomenda√ß√£o e muitos outros.  Mas o Turi Create, apesar de sua relativa facilidade de uso, apenas suportava Python. </p><br><h2 id="create-ml">  Criar ML </h2><br><p>  E este ano, a Apple, al√©m do Core ML 2, finalmente mostrou sua pr√≥pria ferramenta para modelos de treinamento - a estrutura Create ML usando as tecnologias nativas da Apple - Xcode e Swift. </p><br><p>  Ele funciona r√°pido e criar modelos de modelo com o Create ML √© realmente f√°cil. </p><br><p>  Na WWDC, o desempenho impressionante do Create ML e Core ML 2 foi anunciado usando o aplicativo Memrise como exemplo.  Se anteriormente levava 24 horas para treinar um modelo usando 20 mil imagens, o Create ML reduz esse tempo para 48 minutos no MacBook Pro e at√© 18 minutos no iMac Pro.  O tamanho do modelo treinado diminuiu de 90 MB para 3 MB. </p><br><p>  Criar ML permite usar imagens, textos e objetos estruturados como tabelas, por exemplo, como dados de origem. </p><br><p><img src="https://habrastorage.org/webt/uk/di/2e/ukdi2ewm3e2ax6bbr3ceu_fymlu.png"></p><br><h2 id="klassifikaciya-izobrazheniy">  Classifica√ß√£o da imagem </h2><br><p>  Primeiro, vamos ver como a classifica√ß√£o de imagens funciona.  Para treinar o modelo, precisamos de um conjunto de dados inicial: tiramos tr√™s grupos de fotos de animais: c√£es, gatos e p√°ssaros e os distribu√≠mos em pastas com os nomes correspondentes, que se tornar√£o os nomes das categorias do modelo.  Cada grupo cont√©m 100 imagens com uma resolu√ß√£o de at√© 1920 √ó 1080 pixels e um tamanho de at√© 1Mb.  As fotografias devem ser o mais diferentes poss√≠vel, para que o modelo treinado n√£o se baseie em sinais como a cor da imagem ou o espa√ßo circundante. </p><br><p><img src="https://habrastorage.org/webt/w8/oz/_9/w8oz_9t_3_0fyz86xusotsdp9zi.png"></p><br><p>  Al√©m disso, para verificar como um modelo treinado lida com o reconhecimento de objetos, voc√™ precisa de um conjunto de dados de teste - imagens que n√£o est√£o no conjunto de dados original. </p><br><p>  A Apple fornece duas maneiras de interagir com o Create ML: usando a interface do usu√°rio no MacOS Playground Xcode e programaticamente usando CreateMLUI.framework e CreateML.framework.  Usando o primeiro m√©todo, basta escrever algumas linhas de c√≥digo, transferir as imagens selecionadas para a √°rea especificada e aguardar enquanto o modelo aprende. </p><br><p><img src="https://habrastorage.org/webt/b6/zb/w_/b6zbw_ihfbmt2lx0ovib4nmkfsk.gif"></p><br><p>  No Macbook Pro 2017 na configura√ß√£o m√°xima, o treinamento levou 29 segundos para 10 itera√ß√µes e o tamanho do modelo treinado foi de 33 KB.  Parece impressionante. </p><br><p>  Vamos tentar descobrir como conseguimos alcan√ßar esses indicadores e o que est√° "sob o cap√¥". <br>  A tarefa de classificar imagens √© um dos usos mais populares das redes neurais convolucionais.  Primeiro, vale a pena explicar o que s√£o. </p><br><p>  Uma pessoa, vendo a imagem de um animal, pode atribu√≠-la rapidamente a uma determinada classe com base em qualquer caracter√≠stica distintiva.  Uma rede neural age de maneira semelhante, procurando caracter√≠sticas b√°sicas.  Tomando a matriz inicial de pixels como entrada, ela passa seq√ºencialmente as informa√ß√µes atrav√©s de grupos de camadas convolucionais e cria abstra√ß√µes cada vez mais complexas.  Em cada camada subsequente, ela aprende a destacar certos recursos - primeiro s√£o linhas, depois conjuntos de linhas, formas geom√©tricas, partes do corpo e assim por diante.  Na √∫ltima camada, obtemos a conclus√£o de uma classe ou grupo de classes prov√°veis. </p><br><p>  No caso do Create ML, o treinamento em rede neural n√£o √© realizado do zero.  A estrutura usa uma rede neural previamente treinada em um grande conjunto de dados, que j√° inclui um grande n√∫mero de camadas e tem alta precis√£o. </p><br><p><img src="https://habrastorage.org/webt/go/qu/el/goquell4agcijc9duege4cg1ydw.png"></p><br><p>  Essa tecnologia √© chamada de transfer√™ncia de aprendizado.  Com ele, voc√™ pode alterar a arquitetura de uma rede pr√©-treinada para que seja adequada para resolver um novo problema.  A rede alterada √© treinada em um novo conjunto de dados. </p><br><p>  Crie ML durante os extratos de treinamento da foto, com cerca de 1000 recursos distintos.  Pode ser a forma dos objetos, a cor das texturas, a localiza√ß√£o dos olhos, tamanhos e muitos outros. <br>  Deve-se notar que o conjunto de dados inicial no qual a rede neural usada √© treinada, como a nossa, pode conter fotografias de gatos, c√£es e p√°ssaros, mas essas categorias n√£o s√£o alocadas especificamente.  Todas as categorias formam uma hierarquia.  Portanto, √© simplesmente imposs√≠vel aplicar essa rede em sua forma pura - √© necess√°rio trein√°-la novamente em nossos dados. </p><br><p>  No final do processo, vemos com que precis√£o nosso modelo foi treinado e testado ap√≥s v√°rias itera√ß√µes.  Para melhorar os resultados, podemos aumentar o n√∫mero de imagens no conjunto de dados original ou alterar o n√∫mero de itera√ß√µes. </p><br><p><img src="https://habrastorage.org/webt/k1/rz/to/k1rzto4lzngwwfo46taxa9vnbms.png"></p><br><p>  Em seguida, podemos testar o modelo em um conjunto de dados de teste.  As imagens devem ser √∫nicas, ou seja,  N√£o entre no conjunto de fontes. </p><br><p><img src="https://habrastorage.org/webt/lw/u8/el/lwu8eld5v8q6jwqyeaygwkyzvwi.png"></p><br><p>  Para cada imagem, um indicador de <em>confian√ßa</em> √© exibido - com que precis√£o, com a ajuda do nosso modelo, a categoria foi reconhecida. </p><br><p>  Para quase todas as fotos, com raras exce√ß√µes, esse n√∫mero foi de 100%.  Adicionei especificamente a imagem que voc√™ v√™ acima ao conjunto de dados de teste e, como voc√™ pode ver, o Create ML reconheceu 86% do c√£o e 13% do p√°ssaro. </p><br><p>  O treinamento do modelo foi conclu√≠do e tudo o que resta para n√≥s √© salvar o arquivo * .mlmodel e adicion√°-lo ao seu projeto. </p><br><p><img src="https://habrastorage.org/webt/vd/ey/xb/vdeyxbibcdbgd3f2jb6ozsrpa_u.png"></p><br><p>  Para testar o modelo, escrevi um aplicativo simples usando a estrutura do Vision.  Ele permite que voc√™ trabalhe com modelos Core ML e resolva problemas usando-os, como classifica√ß√£o de imagens ou detec√ß√£o de objetos. </p><br><p>  Nosso aplicativo reconhecer√° a imagem da c√¢mera do dispositivo e exibir√° a categoria e a porcentagem de confian√ßa na classifica√ß√£o. </p><br><p>  Inicializamos o modelo Core ML para trabalhar com o Vision e configuramos a consulta: </p><br><pre><code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setupVision</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> visionModel = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>? <span class="hljs-type"><span class="hljs-type">VNCoreMLModel</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: <span class="hljs-type"><span class="hljs-type">AnimalsClassifier</span></span>().model) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">fatalError</span></span>(<span class="hljs-string"><span class="hljs-string">"Can't load VisionML model"</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> request = <span class="hljs-type"><span class="hljs-type">VNCoreMLRequest</span></span>(model: visionModel) { (request, error) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> results = request.results <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.handleRequestResults(results) } requests = [request] }</code> </pre> <br><p>  Adicione um m√©todo que processar√° os resultados de VNCoreMLRequest.  Mostramos apenas aqueles com um indicador de confian√ßa de mais de 70%: </p><br><pre> <code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">handleRequestResults</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> results: [</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">Any</span></span></span></span><span class="hljs-function"><span class="hljs-params">])</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> categoryText: <span class="hljs-type"><span class="hljs-type">String?</span></span> <span class="hljs-keyword"><span class="hljs-keyword">defer</span></span> { <span class="hljs-type"><span class="hljs-type">DispatchQueue</span></span>.main.async { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.categoryLabel.text = categoryText } } <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> foundObject = results .compactMap({ $<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>? <span class="hljs-type"><span class="hljs-type">VNClassificationObservation</span></span> }) .first(<span class="hljs-keyword"><span class="hljs-keyword">where</span></span>: { $<span class="hljs-number"><span class="hljs-number">0</span></span>.confidence &gt; <span class="hljs-number"><span class="hljs-number">0.7</span></span> }) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { categoryText = <span class="hljs-literal"><span class="hljs-literal">nil</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> category = categoryTitle(identifier: foundObject.identifier) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> confidence = <span class="hljs-string"><span class="hljs-string">"\(round(foundObject.confidence * 100 * 100) / 100)%"</span></span> categoryText = <span class="hljs-string"><span class="hljs-string">"\(category) \(confidence)"</span></span> }</code> </pre><br><p>  E a √∫ltima - adicionaremos o m√©todo delegado AVCaptureVideoDataOutputSampleBufferDelegate, que ser√° chamado a cada novo quadro da c√¢mera e executar√° a solicita√ß√£o: </p><br><pre> <code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">captureOutput</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pixelBuffer = <span class="hljs-type"><span class="hljs-type">CMSampleBufferGetImageBuffer</span></span>(sampleBuffer) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> requestOptions: [<span class="hljs-type"><span class="hljs-type">VNImageOption</span></span>: <span class="hljs-type"><span class="hljs-type">Any</span></span>] = [:] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cameraIntrinsicData = <span class="hljs-type"><span class="hljs-type">CMGetAttachment</span></span>( sampleBuffer, key: kCMSampleBufferAttachmentKey_CameraIntrinsicMatrix, attachmentModeOut: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>) { requestOptions = [.cameraIntrinsics:cameraIntrinsicData] } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> imageRequestHandler = <span class="hljs-type"><span class="hljs-type">VNImageRequestHandler</span></span>( cvPixelBuffer: pixelBuffer, options: requestOptions) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> imageRequestHandler.perform(requests) } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(error) } }</code> </pre> <br><p>  Vamos verificar como o modelo lida com sua tarefa: </p><br><p><img src="https://habrastorage.org/webt/fy/5k/fl/fy5kflqc3p02w0mo0dwgaar3vle.gif"></p><br><p>  A categoria √© determinada com uma precis√£o bastante alta, e isso √© especialmente surpreendente quando voc√™ considera a rapidez com que o treinamento foi realizado e o tamanho do conjunto de dados original.  Periodicamente, contra um fundo escuro, o modelo revela p√°ssaros, mas acho que isso pode ser facilmente resolvido aumentando o n√∫mero de imagens no conjunto de dados original ou aumentando o n√≠vel m√≠nimo de confian√ßa aceit√°vel. </p><br><p>  Se quisermos treinar novamente o modelo para classificar outra categoria, basta adicionar um novo grupo de imagens e repetir o processo - isso levar√° alguns minutos. </p><br><p>  Como experimento, fiz outro conjunto de dados, no qual alterei todas as fotos de gatos na foto de um gato de √¢ngulos diferentes, mas no mesmo plano de fundo e no mesmo ambiente.  Nesse caso, o modelo quase sempre cometia erros e reconhecia a categoria em uma sala vazia, aparentemente confiando na cor como uma caracter√≠stica fundamental. </p><br><p>  Outro recurso interessante introduzido no Vision apenas neste ano √© a capacidade de reconhecer objetos na imagem em tempo real.  √â representado pela classe VNRecognizedObjectObservation, que permite obter a categoria de um objeto e sua localiza√ß√£o - boundingBox. </p><br><p><img src="https://habrastorage.org/webt/fo/96/cb/fo96cbqh0flkktb9umjrfxxofu4.jpeg"></p><br><p>  Agora, o Create ML n√£o permite criar modelos para implementar essa funcionalidade.  A Apple sugere o uso do Turi Create neste caso.  O processo n√£o √© muito mais complicado que o acima: voc√™ precisa preparar pastas de categorias com fotos e um arquivo no qual para cada imagem ser√£o indicadas as coordenadas do ret√¢ngulo onde o objeto est√° localizado. </p><br><h2 id="natural-language-processing">  Processamento de linguagem natural </h2><br><p>  A pr√≥xima fun√ß√£o Criar ML √© treinar modelos para classificar textos em linguagem natural - por exemplo, para determinar a colora√ß√£o emocional das frases ou detectar spam. </p><br><p><img src="https://habrastorage.org/webt/xv/fq/48/xvfq489qejhdwl_uitxcc-2yyii.png"></p><br><p>  Para criar um modelo, precisamos coletar uma tabela com o conjunto de dados original - senten√ßas ou textos completos atribu√≠dos a uma determinada categoria e treinar o modelo usando-o usando o objeto MLTextClassifier: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> data = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MLDataTable</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">contentsOf: URL(fileURLWithPath: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"/Users/CreateMLTest/texts.json"</span></span></span></span></span><span class="hljs-function">)) </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">let</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">trainingData, testingData</span></span></span><span class="hljs-function">)</span></span> = data.randomSplit(<span class="hljs-keyword"><span class="hljs-keyword">by</span></span>: <span class="hljs-number"><span class="hljs-number">0.8</span></span>, seed: <span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> textClassifier = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MLTextClassifier</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">trainingData: trainingData, textColumn: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"text"</span></span></span></span><span class="hljs-function"><span class="hljs-params">, labelColumn: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"label"</span></span></span></span></span><span class="hljs-function">) </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> textClassifier.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">write</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">to: URL(fileURLWithPath: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"/Users/CreateMLTest/TextClassifier.mlmodel"</span></span></span></span></span><span class="hljs-function">))</span></span></code> </pre> <br><p>  Nesse caso, o modelo treinado √© do tipo Classificador de texto: </p><br><p><img src="https://habrastorage.org/webt/kg/j1/ws/kgj1wst4121ojpwfk73yehmte_m.png"></p><br><h2 id="tablichnye-dannye">  Dados tabulares </h2><br><p>  Vamos dar uma olhada em outro recurso do Create ML - treinando um modelo usando dados estruturados (tabelas). </p><br><p>  Escreveremos um aplicativo de teste que prev√™ o pre√ßo de um apartamento com base em sua localiza√ß√£o no mapa e em outros par√¢metros especificados. </p><br><p>  Portanto, temos uma tabela com dados abstratos de apartamentos em Moscou na forma de um arquivo csv: a √°rea de cada apartamento, andar, n√∫mero de quartos e coordenadas (latitude e longitude) s√£o conhecidos.  Al√©m disso, o custo de cada apartamento √© conhecido.  Quanto mais pr√≥ximo do centro ou maior a √°rea, maior o pre√ßo. </p><br><p><img src="https://habrastorage.org/webt/hd/-w/77/hd-w77qhysj80_kapqbqddwdhyi.png"></p><br><p>  A tarefa do Create ML ser√° construir um modelo capaz de prever o pre√ßo de um apartamento com base nessas caracter√≠sticas.  Tal tarefa no aprendizado de m√°quina √© chamada de tarefa de regress√£o e √© um exemplo cl√°ssico de aprendizado com um professor. </p><br><p>  O Create ML suporta muitos modelos - Regress√£o Linear, Regress√£o em √Årvore de Decis√£o, Classificador em √Årvore, Regress√£o Log√≠stica, Classificador de Floresta Aleat√≥ria, Regress√£o em √Årvores Impulsionadas, etc. </p><br><p>  Usaremos o objeto MLRegressor, que selecionar√° a melhor op√ß√£o com base nos dados de entrada. <br>  Primeiro, inicialize o objeto MLDataTable com o conte√∫do do nosso arquivo csv: </p><br><pre> <code class="hljs lisp">let trainingFile = URL(<span class="hljs-name"><span class="hljs-name">fileURLWithPath</span></span>: <span class="hljs-string"><span class="hljs-string">"/Users/CreateMLTest/Apartments.csv"</span></span>) let apartmentsData = try MLDataTable(<span class="hljs-name"><span class="hljs-name">contentsOf</span></span>: trainingFile)</code> </pre> <br><p>  Dividimos o conjunto de dados inicial em dados para treinamento e teste de modelo em uma porcentagem de 80/20: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> (trainingData, testData) = apartmentsData.randomSplit(<span class="hljs-keyword"><span class="hljs-keyword">by</span></span>: <span class="hljs-number"><span class="hljs-number">0.8</span></span>, seed: <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  Criamos o modelo MLRegressor, indicando os dados para o treinamento e o nome da coluna cujos valores queremos prever.  O tipo de regressor espec√≠fico da tarefa (linear, √°rvore de decis√£o, √°rvore potencializada ou floresta aleat√≥ria) ser√° selecionado automaticamente com base no estudo dos dados de entrada.  Tamb√©m podemos especificar colunas de recurso - colunas de par√¢metro espec√≠ficas para an√°lise, mas neste exemplo isso n√£o √© necess√°rio, usaremos todos os par√¢metros.  No final, salve o modelo treinado e adicione ao projeto: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> model = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> <span class="hljs-type"><span class="hljs-type">MLRegressor</span></span>(trainingData: apartmentsData, targetColumn: <span class="hljs-string"><span class="hljs-string">"Price"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> modelPath = <span class="hljs-type"><span class="hljs-type">URL</span></span>(fileURLWithPath: <span class="hljs-string"><span class="hljs-string">"/Users/CreateMLTest/ApartmentsPricer.mlmodel"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> model.write(to: modelPath, metadata: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/xv/ci/-e/xvci-e7bhoxwfpvwtjdmwqwwhv0.png"></p><br><p>  Neste exemplo, vemos que o tipo de modelo j√° √© Regressor de Pipeline e o campo Descri√ß√£o cont√©m o tipo de regressor selecionado automaticamente - Modelo de Regress√£o de √Årvore Refor√ßada.  Os par√¢metros Entradas e Sa√≠das correspondem √†s colunas da tabela, mas seu tipo de dados se tornou Duplo. </p><br><p>  Agora verifique o resultado. <br>  Inicialize o objeto de modelo: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> model = <span class="hljs-type"><span class="hljs-type">ApartmentsPricer</span></span>()</code> </pre> <br><p>  Chamamos o m√©todo de previs√£o, passando os par√¢metros especificados para ele: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> area = Double(areaSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> floor = Double(floorSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> rooms = Double(roomsSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> latitude = annotation.coordinate.latitude <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> longitude = annotation.coordinate.longitude <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> prediction = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>? model.prediction( area: area, floor: floor, rooms: rooms, latitude: latitude, longitude: longitude)</code> </pre><br><p>  Exibimos o valor previsto do custo: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> price = prediction?.price priceLabel.text = formattedPrice(price)</code> </pre> <br><p>  Alterando um ponto no mapa ou nos valores dos par√¢metros, obtemos o pre√ßo do apartamento bem pr√≥ximo dos dados de teste: </p><br><p><img src="https://habrastorage.org/webt/pu/j-/v1/puj-v1m8x0ghkxrh1fwogdejxfu.png"></p><br><h2 id="zaklyuchenie">  Conclus√£o </h2><br><p>  A estrutura Create ML √© agora uma das maneiras mais f√°ceis de trabalhar com tecnologias de aprendizado de m√°quina.  Ainda n√£o permite criar modelos para solucionar alguns problemas: reconhecimento de objetos em uma imagem, estiliza√ß√£o de uma foto, determina√ß√£o de imagens semelhantes, reconhecimento de a√ß√µes f√≠sicas com base em dados de um aceler√¥metro ou girosc√≥pio, com o qual Turi Create, por exemplo, lida. </p><br><p>  Mas vale a pena notar que a Apple fez um progresso bastante s√©rio nessa √°rea ao longo do ano passado e, com certeza, veremos em breve o desenvolvimento das tecnologias descritas. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt418307/">https://habr.com/ru/post/pt418307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt418295/index.html">Quase tudo o que voc√™ queria saber sobre ponto flutuante no ARM, mas teve medo de perguntar</a></li>
<li><a href="../pt418297/index.html">Revis√£o do smartphone Neffos N1</a></li>
<li><a href="../pt418301/index.html">O grande confronto de Marte em 2018: como observar e o que esperar</a></li>
<li><a href="../pt418303/index.html">Vanessa-Automation - uma ferramenta para testar solu√ß√µes de aplicativos na plataforma 1C: Enterprise</a></li>
<li><a href="../pt418305/index.html">Quantos objetos o Python emite ao executar scripts?</a></li>
<li><a href="../pt418309/index.html">Como o sat√©lite astron√¥mico de Planck mudou para sempre nossa percep√ß√£o do universo</a></li>
<li><a href="../pt418311/index.html">An√°lise do notebook Dell Latitude 7390: super-her√≥i corporativo</a></li>
<li><a href="../pt418313/index.html">As 10 principais ferramentas de teste de API</a></li>
<li><a href="../pt418315/index.html">Sem um √∫nico "oops": os 10 principais relat√≥rios do DevOops 2017</a></li>
<li><a href="../pt418317/index.html">2048 √© proibido. N√£o RosKomNadzor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌕 👶🏽 📊 Implementierung der Minimierung logischer Funktionen durch die Quine \ McCluskey-Methode mit einem unvollständigen Eingabesatz 🐸 🔲 🙉</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel ist bis zu einem gewissen Grad eine Fortsetzung meines Artikels über die Minimierung logischer Funktionen durch die Quine-Mac'Klaski-Me...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Implementierung der Minimierung logischer Funktionen durch die Quine \ McCluskey-Methode mit einem unvollständigen Eingabesatz</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424517/">  Dieser Artikel ist bis zu einem gewissen Grad eine Fortsetzung meines Artikels über die Minimierung logischer Funktionen durch die Quine-Mac'Klaski-Methode ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://habr.com/post/328506</a> ).  Es wurde ein Fall mit vollständig definierten logischen Funktionen betrachtet (obwohl dies nicht direkt darin erwähnt, sondern nur impliziert wurde).  In der Realität ist ein solcher Fall ziemlich selten, wenn die Anzahl der Eingabevariablen gering ist.  Teilweise oder unvollständig definiert sind logische Funktionen, deren Werte nur für Teil Q aus der Gesamtmenge P = angegeben werden <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mi>N</mi></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.854ex" height="2.419ex" viewBox="0 -935.7 1228.8 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMATHI-4E" x="707" y="557"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mi>N</mi></msup></math></span></span><script type="math/tex" id="MathJax-Element-1"> 2 ^ N </script>  mögliche Mengen (Terme) ihrer Argumente (Variablen) der Zahl <i>N</i> , dh Q &lt;P. Diese Situation tritt in der Praxis in den meisten Fällen bei der Anwendung von Algorithmen zur Optimierung logischer Funktionen auf.  Wenn beispielsweise die Anzahl der Eingabevariablen <i>N</i> = 30 beträgt, was beispielsweise auf den Finanzmärkten üblich ist, sollte das Volumen der Stichprobe für das Eingabetraining in der Größenordnung von liegen <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>30</mn></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.039ex" height="2.419ex" viewBox="0 -935.7 1308.3 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><g transform="translate(500,393)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-33"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-30" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mn>30</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-2"> 2 ^ {30} </script>  &gt; <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>10</mn><mn>9</mn></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.379ex" height="2.419ex" viewBox="0 -935.7 1454.9 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-30" x="500" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-39" x="1415" y="557"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mn>9</mn></msup></math></span></span><script type="math/tex" id="MathJax-Element-3"> 10 ^ 9 </script>  einzigartige einzigartige Begriffe.  Ein solches Datenarray findet sich nicht in jeder sehr großen Organisation, ganz zu schweigen von Einzelpersonen, das heißt, dies ist bereits die Sphäre von BigData, die Nutzung von Rechenzentren usw. <br><br>  Daher werden in der Praxis häufig minimierte logische Funktionen nicht einfach aufgrund des Fehlens der erforderlichen Menge an akkumulierten Daten oder aufgrund verschiedener anderer objektiver Gründe (zum Beispiel ist nicht genügend Speicherplatz zum Speichern vorhanden) vollständig bestimmt.  Es stellt sich die Frage nach der Möglichkeit der "Umgehung" dieses Problems, wenn ein Algorithmus verwendet wird, der mit einem vollständig definierten Satz von Begriffslogikfunktionen arbeitet, wie beispielsweise aus meinem vorherigen Artikel. <br><a name="habracut"></a><br><br>  In diesem Fall wird standardmäßig der unvollständige Eingabesatz von Variablen- (Term-) Werten zum vollständigen Wert bestimmt, um ein optimales Ergebnis für den vorhandenen Datensatz zu erhalten.  In diesem Fall besteht jedoch ein Problem bei der Aufzählung aller möglichen Varianten zusätzlicher Definitionen, deren Gesamtzahl V = ist <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mo>&amp;#x2212;</mo><mi>Q</mi></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.207ex" height="2.539ex" viewBox="0 -987.6 2242 1093.4" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><g transform="translate(500,393)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMATHI-50" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-2212" x="751" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMATHI-51" x="1530" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mo>−</mo><mi>Q</mi></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-4"> 2 ^ {P-Q} </script>  Auswahl der besten Option für eine zusätzliche Definition gemäß einem bestimmten Kriterium.  Offensichtlich ist für die tatsächlich verwendeten Werte von Q und P die Anzahl der sortierten Optionen für zusätzliche Definitionen astronomisch groß, und dieser Ansatz kann aufgrund des immensen Rechenaufwands in der Praxis nicht implementiert werden. <br><br>  Daher ist ein anderer Ansatz erforderlich, der die Aufzählung verschiedener Optionen für zusätzliche Definitionen überflüssig macht.  Daher ist es notwendig, den ursprünglichen Algorithmus zu modernisieren, der anfänglich nur mit einem vollständig definierten Eingabesatz funktioniert, damit er auch mit einem abgeschnittenen Satz arbeiten kann.  Es ist eine solche Implementierung des in diesem Artikel vorgeschlagenen Algorithmus, basierend auf der Tatsache, dass während des Minimierungsprozesses zwei unvollständige Listen von Begriffen gleichzeitig verarbeitet werden, auf denen die Funktion als FALSE (0) und TRUE (1) angegeben wird. <br><br>  Unter dem Gesichtspunkt des maschinellen Lernens implementiert der Quine-Mac'Klaski-Algorithmus das Lernparadigma mit dem Lehrer, wenn die entsprechenden Ausgabewerte der Zielfunktion gleichzeitig in den Lernprozess (in diesem Fall Minimierung) einbezogen werden.  Ich möchte Sie daran erinnern, dass das Funktionsprinzip der grundlegenden Quine-Mac'Klaski-Methode nach der Theorie aus zwei Hauptstufen besteht: <br><ol><li>  Bühne.  Finden aller einfachen LF-Begriffe mithilfe von Kleberegeln (Gesetzen): <br>  a) (A &amp; B)?  (A &amp;! B)?  A; <br>  b) (A? B) &amp; (A?! B)?  A; <br>  Wo ist die logische UND-Verknüpfung?  - Operation des logischen "ODER" ;!  - Operation der logischen Negation "NICHT".  Aus diesen Formeln folgt, dass zwei Terme zusammengeklebt werden, wenn sie sich nur in einer der Positionen der Variablen voneinander unterscheiden.  An der Stelle, an der sich die beiden Begriffe voneinander unterscheiden, wird das Zeichen „*“ gesetzt.  Somit erweitert sich das geklebte Alphabet im Vergleich zum Original auf drei Werte: <br>  • 0 =&gt; falsch; <br>  • 1 =&gt; wahr; <br>  • 2 =&gt; geklebte Variable (*). </li><li>  Bühne.  Minimierung der Anzahl der eingeklebten Terme, die nach der ersten Stufe erhalten wurden, als Problem beim Finden der optimalen Abdeckung des anfänglichen Satzes von Begriffen mit der Menge Q. Das heißt, da jeder Ausgabeausdruck nur eine bestimmte Teilmenge der Quellausdrücke abdeckt, ist es notwendig, einen minimalen Satz von Ausgabeausdrücken zu wählen, mit denen identifiziert wird Mit ihnen deckten Teilmengen unterschiedlicher Länge im Aggregat alle anfänglichen Eingabebegriffe vollständig ab.  Beschichten bedeutet in diesem Fall, dass die bitweise Operation der Disjunktion des Ausgangsterms über den Eingangsterm einen wahren Wert ergab.  Angenommen, der ausgegebene geklebte Term hat die folgende Form: 10 * 0110 *. <br>  Dann deckt es den Begriff 10101100 ab: <br>  10 * 0110 * &amp; 10101100 = TRUE <br>  deckt aber nicht den Begriff 00101100 ab: <br>  10 * 0110 * &amp; 00101100 = FALSE <br>  Das heißt, der Eingabeterm und der Ausgang müssen überall zusammenfallen, mit Ausnahme der Positionen, an denen ein "*" - Symbol angezeigt wird. In dieser Position kann die Variable des Eingabeterms einen beliebigen Wert annehmen, da  In dieser Position wird die Variable von der Betrachtung ausgeschlossen. </li></ol><br><br><div class="spoiler">  <b class="spoiler_title">Der Implementierungscode lautet wie folgt (zum Anzeigen klicken):</b> <div class="spoiler_text"><pre><code class="plaintext hljs">using System; using System.Collections.Generic; using System.Linq; #region   /// &lt;summary&gt; ///      /// &lt;/summary&gt; public abstract class LogicFunction { // ""  public const byte cStarSymb = 2; //    public readonly ICollection&lt;byte[]&gt; Terms = new LinkedList&lt;byte[]&gt;(); //   public abstract bool Calculate(bool[] X); //   public abstract bool Calculate(char[] X); //   public abstract bool Calculate(byte[] X); } /// &lt;summary&gt; ///    /// &lt;/summary&gt; public class Dnf : LogicFunction { public static bool Calculate(byte[] X, byte[] term) { bool bResult = true; for (int i = 0; i &lt; term.Length; i++) { if ((term[i] == cStarSymb) || (term[i] == X[i])) continue; bResult = false; break; } return bResult; } public override bool Calculate(byte[] X) { bool bResult = false; foreach (byte[] term in Terms) { bool bTermVal = true; for (int i = 0; i &lt; term.Length; i++) { if ((term[i] &gt;= cStarSymb) || (term[i] == X[i])) continue; bTermVal = false; break; } //bResult |= bTermVal; if (bTermVal) { bResult = true; break; } } return bResult; } public override bool Calculate(char[] X) { bool bResult = false; foreach (byte[] term in Terms) { bool bTermVal = true; for (int i = 0; i &lt; term.Length; i++) { if ((term[i] &gt;= cStarSymb) || (term[i] == (byte)(X[i] == '0' ? 0 : 1))) continue; bTermVal = false; break; } //bResult |= bTermVal; if (bTermVal) { bResult = true; break; } } return bResult; } public override bool Calculate(bool[] X) { bool bResult = false; foreach (byte[] term in Terms) { bool bTermVal = true; for (int i = 0; i &lt; term.Length; i++) { if ((term[i] &gt;= cStarSymb) || ((term[i] != 0) == X[i])) continue; bTermVal = false; break; } //bResult |= bTermVal; if (bTermVal) { bResult = true; break; } } return bResult; } } #endregion /// &lt;summary&gt; ///   /// &lt;/summary&gt; public class TreeFuncTerm { /// &lt;summary&gt; ///     /// &lt;/summary&gt; public class TreeNodeEnd { } //    private readonly TreeNodeEnd pCommonTreeNodeEnd = new TreeNodeEnd(); //  private readonly object[] rootNode = new object[3]; // ()  private int _rang = 0; public int Rang { get { return _rang; } } //    private int enumerationPos = 0; private object[][] enumerationBuf; //,     private byte[] enumerationTerm; public byte[] EnumerationTerm { get { return enumerationTerm; } } //     private UInt32 _count = 0; public UInt32 Count { get { return _count; } } // public TreeFuncTerm() { Clear(); } //  public void Clear() { _count = 0; _rang = 0; enumerationPos = 0; enumerationBuf = null; enumerationTerm = null; rootNode[0] = rootNode[1] = rootNode[2] = null; } //      public TreeNodeEnd EnumerationInit() { enumerationPos = 0; enumerationTerm = new byte[_rang]; enumerationTerm[0] = 0; enumerationBuf = new object[_rang][]; enumerationBuf[0] = rootNode; //    return EnumerationNextNode(); } //     public TreeNodeEnd EnumerationNextNode() { int iIsNext = (enumerationPos &gt; 0 ? 1 : 0); TreeNodeEnd pRetTreeNode = null; while ((pRetTreeNode == null) &amp;&amp; (enumerationPos &gt;= 0)) { object[] pCurrNodes = enumerationBuf[enumerationPos]; object pNextNode = null; int i = enumerationTerm[enumerationPos] + iIsNext; for (; i &lt; 3; i++) if ((pNextNode = pCurrNodes[i]) != null) break; if (pNextNode == null) { //    enumerationPos--; iIsNext = 1; } else { enumerationTerm[enumerationPos] = (byte)i; if (pNextNode is object[]) { //    enumerationPos++; enumerationBuf[enumerationPos] = (object[])pNextNode; enumerationTerm[enumerationPos] = 0; iIsNext = 0; } else //if (pNextNode is TreeNodeEnd) { //   pRetTreeNode = (TreeNodeEnd)pNextNode; } } } return pRetTreeNode; } //     public void AddTerm(byte[] term) { _rang = Math.Max(_rang, term.Length); object[] pCurrNode = rootNode; int iTermLength1 = term.Length - 1; for (int j = 0; j &lt; iTermLength1; j++) { byte cSymb = term[j]; object item = pCurrNode[cSymb]; if (item == null) { item = new object[3]; pCurrNode[cSymb] = item; } pCurrNode = (object[])item; } if (pCurrNode[term[iTermLength1]] == null) { //    pCurrNode[term[iTermLength1]] = pCommonTreeNodeEnd; _count++; } } //      public TreeNodeEnd Remove(byte[] term) { int iTermLength1 = term.Length - 1; object[] pCurrNode = rootNode; for (int i = 0; i &lt; iTermLength1; i++) { pCurrNode = (object[])pCurrNode[term[i]]; if (pCurrNode == null) break; } TreeNodeEnd pRemovedNode = null; if (pCurrNode != null) { //      pRemovedNode = (TreeNodeEnd)pCurrNode[term[iTermLength1]]; if (pRemovedNode != null) { //     pCurrNode[term[iTermLength1]] = null; // -  _count--; } } return pRemovedNode; } //     public bool Contains(byte[] term) { object pCurrNode = rootNode; foreach (byte cSymb in term) { pCurrNode = ((object[])pCurrNode)[cSymb]; if (pCurrNode == null) break; } return ((pCurrNode != null) &amp;&amp; (pCurrNode is TreeNodeEnd)); } } /// &lt;summary&gt; ///     ---- /// &lt;/summary&gt; public class Quine_McCluskey { //    private readonly Dnf _result = new Dnf(); public Dnf Result { get { return _result; } } //    private readonly Dnf _resultNeg = new Dnf(); public Dnf ResultNeg { get { return _resultNeg; } } //     private static void Skleivanie(TreeFuncTerm X1Tree, TreeFuncTerm X2Tree, TreeFuncTerm NegativTree, IEnumerable&lt;byte[]&gt; InpNegTerms, Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; OutResult, int iLevel) { LinkedList&lt;byte[]&gt; OutR = new LinkedList&lt;byte[]&gt;(); if (OutResult != null) OutResult.Add(iLevel, OutR); bool IsVirtSkleivOn = ((NegativTree != null) &amp;&amp; (InpNegTerms != null) &amp;&amp; (InpNegTerms.Count() != 0)); for (TreeFuncTerm.TreeNodeEnd x1 = X1Tree.EnumerationInit(); x1 != null; x1 = X1Tree.EnumerationNextNode()) { bool bIsSkleiv = false; byte[] pCurrTerm = X1Tree.EnumerationTerm; for (int iPos = 0; iPos &lt; pCurrTerm.Length; iPos++) { byte cSymbSav = pCurrTerm[iPos]; if (cSymbSav == LogicFunction.cStarSymb) continue; //      pCurrTerm[iPos] = (byte)(1 - cSymbSav); if (X1Tree.Contains(pCurrTerm)) { bIsSkleiv = true; //,         if (cSymbSav == 1) { pCurrTerm[iPos] = LogicFunction.cStarSymb; //  X2Tree.AddTerm(pCurrTerm); } } //    ,    NegativTree else if (IsVirtSkleivOn &amp;&amp; !NegativTree.Contains(pCurrTerm)) { bool bIsNotCanAdd = false; pCurrTerm[iPos] = LogicFunction.cStarSymb; //  foreach (byte[] NegTerm in InpNegTerms) { if (bIsNotCanAdd = Dnf.Calculate(NegTerm, pCurrTerm)) break; } if (!bIsNotCanAdd) { bIsSkleiv = true; X2Tree.AddTerm(pCurrTerm); } } pCurrTerm[iPos] = cSymbSav; } //    ,       if (!bIsSkleiv) OutR.AddLast((byte[])pCurrTerm.Clone()); } } //     private static UInt64 GetTermCode(byte[] pTerm) { UInt64 iMultip = 1, iCode = 0; for (int i = 0; i &lt; pTerm.Length; i++) { iCode += (iMultip * pTerm[i]); iMultip *= 3; } return iCode; } //     private static byte[] GetTermByCode(UInt64 iCode, int iTermLength, byte[] pTerm = null) { if (pTerm == null) pTerm = new byte[iTermLength]; int iCounter = 0; while (iCode != 0) { pTerm[iCounter++] = (byte)(iCode % 3); iCode /= 3; } while (iCounter &lt; iTermLength) pTerm[iCounter++] = 0; return pTerm; } //     private static void Skleivanie(ICollection&lt;UInt64&gt; X1Tree, ICollection&lt;UInt64&gt; X2Tree, ICollection&lt;UInt64&gt; NegativTree, IEnumerable&lt;byte[]&gt; InpNegTerms, Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; OutResult, int iLevel, int iTermLength) { LinkedList&lt;byte[]&gt; OutR = new LinkedList&lt;byte[]&gt;(); if (OutResult != null) OutResult.Add(iLevel, OutR); byte[] pCurrTerm = new byte[iTermLength]; bool IsVirtSkleivOn = ((NegativTree != null) &amp;&amp; (InpNegTerms != null) &amp;&amp; (InpNegTerms.Count() != 0)); foreach (UInt64 x1 in X1Tree) { GetTermByCode(x1, iTermLength, pCurrTerm); bool bIsSkleiv = false; UInt64 iMultip = 1; for (int iPos = 0; iPos &lt; iTermLength; iPos++) { byte cSymbSav = pCurrTerm[iPos]; //(byte)((x1 / iMultip) % 3); if (cSymbSav != LogicFunction.cStarSymb) { UInt64 iCode = (cSymbSav == 0 ? x1 + iMultip : x1 - iMultip); //      if (X1Tree.Contains(iCode)) { bIsSkleiv = true; //,         if (cSymbSav == 1) { X2Tree.Add(x1 + iMultip); } } //    ,    NegativTree else if (IsVirtSkleivOn &amp;&amp; !NegativTree.Contains(iCode)) { bool bIsNotCanAdd = false; pCurrTerm[iPos] = LogicFunction.cStarSymb; //  foreach (byte[] NegTerm in InpNegTerms) { if (bIsNotCanAdd = Dnf.Calculate(NegTerm, pCurrTerm)) break; } pCurrTerm[iPos] = cSymbSav; if (!bIsNotCanAdd) { bIsSkleiv = true; X2Tree.Add(x1 + (byte)(LogicFunction.cStarSymb - cSymbSav) * iMultip); } } } iMultip *= 3; } //    ,       if (!bIsSkleiv) OutR.AddLast((byte[])pCurrTerm.Clone()); } } //      //       private static void DeleteDublicatingTerms(IEnumerable&lt;byte[]&gt; InX1, ICollection&lt;UInt64&gt; OutX2Tree) { OutX2Tree.Clear(); foreach (byte[] x1 in InX1) { UInt64 iCode = GetTermCode(x1); if (OutX2Tree.Contains(iCode)) continue; OutX2Tree.Add(iCode); } } //      //       private static void DeleteDublicatingTerms(IEnumerable&lt;byte[]&gt; InX1, TreeFuncTerm OutX2Tree) { OutX2Tree.Clear(); foreach (byte[] x1 in InX1) OutX2Tree.AddTerm(x1); } //    private static bool IsEqualTerms(byte[] pTermC, byte[] pTermB) { if ((pTermC == null) || (pTermB == null) || (pTermC.Length != pTermB.Length)) return false; bool bIsEqual = false; int iLength = Math.Min(pTermC.Length, pTermB.Length); for ( int i = 0; i &lt; iLength; i++) { if (!(bIsEqual = (pTermB[i] == pTermC[i]))) break; } return bIsEqual; } //            private static void ReduceRedundancyTerms(LinkedList&lt;byte[]&gt; InpTerms, Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; SkleivTerms, ICollection&lt;byte[]&gt; ResultTerms) { if ((InpTerms == null) || (SkleivTerms == null) || (ResultTerms == null)) return; //   ResultTerms.Clear(); //        ,    Dictionary&lt;byte[], HashSet&lt;byte[]&gt;&gt; Outputs2Inputs = new Dictionary&lt;byte[], HashSet&lt;byte[]&gt;&gt;(); //        ,    Dictionary&lt;byte[], HashSet&lt;byte[]&gt;&gt; Inputs2Outputs = new Dictionary&lt;byte[], HashSet&lt;byte[]&gt;&gt;(); //    foreach (int iLevel in SkleivTerms.Keys.OrderByDescending(p =&gt; p).AsEnumerable()) { //       foreach (byte[] outTerm in SkleivTerms[iLevel]) { //  ,      term HashSet&lt;byte[]&gt; InpTermsLst = new HashSet&lt;byte[]&gt;(); //     foreach (byte[] inpTerm in InpTerms) { if (Dnf.Calculate(inpTerm, outTerm)) { InpTermsLst.Add(inpTerm); if (!Inputs2Outputs.ContainsKey(inpTerm)) Inputs2Outputs.Add(inpTerm, new HashSet&lt;byte[]&gt;()); Inputs2Outputs[inpTerm].Add(outTerm); } } Outputs2Inputs.Add(outTerm, InpTermsLst); } } //      -    Inputs2Outputs = Inputs2Outputs.OrderBy(p =&gt; p.Value.Count).ToDictionary(p =&gt; p.Key, v =&gt; v.Value); //   ,   -    while (Inputs2Outputs.Count &gt; 0) { byte[] outTerm = Inputs2Outputs.First().Value.OrderByDescending(q =&gt; Outputs2Inputs[q].Count()).First(); ResultTerms.Add(outTerm); foreach (byte[] inpTerm in Outputs2Inputs[outTerm].ToArray()) { foreach (byte[] outTerm2Del in Inputs2Outputs[inpTerm]) Outputs2Inputs[outTerm2Del].Remove(inpTerm); Inputs2Outputs.Remove(inpTerm); } } } //    public static void LogicFuncMinimize(IEnumerable&lt;byte[]&gt; PositivTerms, ICollection&lt;byte[]&gt; OutPos, IEnumerable&lt;byte[]&gt; NegativTerms, ICollection&lt;byte[]&gt; OutNeg) { int iTotalLevels = (PositivTerms.Count() &gt; 0 ? PositivTerms.First().Length : (NegativTerms != null &amp;&amp; NegativTerms.Count() &gt; 0 ? NegativTerms.First().Length : 0)); Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; SkleivPosTerms = new Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt;(iTotalLevels); Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; SkleivNegTerms = new Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt;(iTotalLevels); LinkedList&lt;byte[]&gt; InpPosTerms = new LinkedList&lt;byte[]&gt;(); LinkedList&lt;byte[]&gt; InpNegTerms = new LinkedList&lt;byte[]&gt;(); if (iTotalLevels &lt; 40) { HashSet&lt;UInt64&gt; X1PositivTree = new HashSet&lt;UInt64&gt;(); DeleteDublicatingTerms(PositivTerms, X1PositivTree); HashSet&lt;UInt64&gt; X1NegativTree = null; if (NegativTerms != null) { X1NegativTree = new HashSet&lt;UInt64&gt;(); DeleteDublicatingTerms(NegativTerms, X1NegativTree); //        foreach(UInt64 iNumb in X1PositivTree.Intersect(X1NegativTree)) { // -    X1   NegativTerms int iPos_Count = PositivTerms.Count(p =&gt; GetTermCode(p) == iNumb); int iNeg_Count = NegativTerms.Count(p =&gt; GetTermCode(p) == iNumb); if (iPos_Count &gt; iNeg_Count) { X1NegativTree.Remove(iNumb); } else if (iPos_Count &lt; iNeg_Count) { X1PositivTree.Remove(iNumb); } else //if (iPos_Count == iNeg_Count) { X1PositivTree.Remove(iNumb); X1NegativTree.Remove(iNumb); } } //           foreach (UInt64 code in X1NegativTree) { InpNegTerms.AddLast(GetTermByCode(code, iTotalLevels)); } } //          foreach (UInt64 code in X1PositivTree) { InpPosTerms.AddLast(GetTermByCode(code, iTotalLevels)); } int iLevelCounter = 0; //        while ((X1PositivTree.Count != 0) &amp;&amp; (iLevelCounter &lt; iTotalLevels)) { HashSet&lt;UInt64&gt; X2PositivTree = new HashSet&lt;UInt64&gt;(); Skleivanie(X1PositivTree, X2PositivTree, X1NegativTree, InpNegTerms, SkleivPosTerms, iLevelCounter, iTotalLevels); if ((X1NegativTree != null) &amp;&amp; (X1NegativTree.Count != 0)) { HashSet&lt;UInt64&gt; X2NegativTree = new HashSet&lt;UInt64&gt;(); Skleivanie(X1NegativTree, X2NegativTree, X1PositivTree, InpPosTerms, SkleivNegTerms, iLevelCounter, iTotalLevels); //   X1NegativTree.Clear(); X1NegativTree = X2NegativTree; } //   X1PositivTree.Clear(); X1PositivTree = X2PositivTree; iLevelCounter++; GC.Collect(); } } else { TreeFuncTerm X1PositivTree = new TreeFuncTerm(); DeleteDublicatingTerms(PositivTerms, X1PositivTree); TreeFuncTerm X1NegativTree = null; if (NegativTerms != null) { X1NegativTree = new TreeFuncTerm(); DeleteDublicatingTerms(NegativTerms, X1NegativTree); //         for (TreeFuncTerm.TreeNodeEnd x1 = X1PositivTree.EnumerationInit(); x1 != null; x1 = X1PositivTree.EnumerationNextNode()) { if (!X1NegativTree.Contains(X1PositivTree.EnumerationTerm)) continue; // -    PositivTerms   NegativTerms int iPos_Count = PositivTerms.Count(p =&gt; IsEqualTerms(p, X1PositivTree.EnumerationTerm)); int iNeg_Count = NegativTerms.Count(p =&gt; IsEqualTerms(p, X1PositivTree.EnumerationTerm)); if (iPos_Count &gt; iNeg_Count) { X1NegativTree.Remove(X1PositivTree.EnumerationTerm); } else if (iPos_Count &lt; iNeg_Count) { X1PositivTree.Remove(X1PositivTree.EnumerationTerm); } else //if (iPos_Count == iNeg_Count) { X1PositivTree.Remove(X1PositivTree.EnumerationTerm); X1NegativTree.Remove(X1PositivTree.EnumerationTerm); } } //           for (TreeFuncTerm.TreeNodeEnd x1 = X1NegativTree.EnumerationInit(); x1 != null; x1 = X1NegativTree.EnumerationNextNode()) { InpNegTerms.AddLast((byte[])X1NegativTree.EnumerationTerm.Clone()); } } //          for (TreeFuncTerm.TreeNodeEnd X1Term = X1PositivTree.EnumerationInit(); X1Term != null; X1Term = X1PositivTree.EnumerationNextNode()) { InpPosTerms.AddLast((byte[])X1PositivTree.EnumerationTerm.Clone()); } int iLevelCounter = 0; //        while ((X1PositivTree.Count != 0) &amp;&amp; (iLevelCounter &lt; iTotalLevels)) { TreeFuncTerm X2PositivTree = new TreeFuncTerm(); Skleivanie(X1PositivTree, X2PositivTree, X1NegativTree, InpNegTerms, SkleivPosTerms, iLevelCounter); if ((X1NegativTree != null) &amp;&amp; (X1NegativTree.Count != 0)) { TreeFuncTerm X2NegativTree = new TreeFuncTerm(); Skleivanie(X1NegativTree, X2NegativTree, X1PositivTree, InpPosTerms, SkleivNegTerms, iLevelCounter); //   X1NegativTree.Clear(); X1NegativTree = X2NegativTree; } //   X1PositivTree.Clear(); X1PositivTree = X2PositivTree; iLevelCounter++; GC.Collect(); } } //       ReduceRedundancyTerms(InpPosTerms, SkleivPosTerms, OutPos); //       ReduceRedundancyTerms(InpNegTerms, SkleivNegTerms, OutNeg); } //  public void Start(IEnumerable&lt;byte[]&gt; TermsInput) { LogicFuncMinimize(TermsInput, _result.Terms, null, null); } //  public void Start(IEnumerable&lt;byte[]&gt; TermsInput, IEnumerable&lt;byte[]&gt; NegativTerms) { LogicFuncMinimize(TermsInput, _result.Terms, NegativTerms, _resultNeg.Terms); } //  public void Start(IEnumerable&lt;char[]&gt; TermsInput) { Start(TermsInput.Select(t =&gt; t.Select(p =&gt; (byte)(p == '0' ? 0 : 1)).ToArray())); } //  public void Start(IEnumerable&lt;char[]&gt; TermsInput, IEnumerable&lt;char[]&gt; NegativTerms) { Start(TermsInput.Select(t =&gt; t.Select(p =&gt; (byte)(p == '0' ? 0 : 1)).ToArray()), NegativTerms.Select(t =&gt; t.Select(p =&gt; (byte)(p == '0' ? 0 : 1)).ToArray())); } //  public void Start(IEnumerable&lt;bool[]&gt; TermsInput) { Start(TermsInput.Select(t =&gt; t.Select(p =&gt; (byte)(p ? 1 : 0)).ToArray())); } //  public void Start(IEnumerable&lt;bool[]&gt; TermsInput, IEnumerable&lt;bool[]&gt; NegativTerms) { Start(TermsInput.Select(t =&gt; t.Select(p =&gt; (byte)(p ? 1 : 0)).ToArray()), NegativTerms.Select(t =&gt; t.Select(p =&gt; (byte)(p ? 1 : 0)).ToArray())); } public void PrintResult() { Console.WriteLine("--------Otvet-------"); char[] pTermSymbs = new char[] { '0', '1', '*' }; foreach (byte[] Term in _result.Terms) { for (int j = 0; j &lt; Term.Length; j++) { Console.Write(pTermSymbs[Term[j]].ToString() + " "); } Console.WriteLine(); } } }</code> </pre> <br></div></div><br><br>  Die Quine_McCluskey-Klasse ist eine Implementierung dieses Algorithmus, der andere Klassen und Schnittstellen verwendet: Dnf, TreeNodeBase, TreeNodeMiddle, TreeNodeEnd, TreeFuncTerm.  Um die Optimierung zu starten, müssen Sie eine der überladenen Start-Methoden aufrufen, die die LogicFuncMinimize-Funktion aufruft, wobei tatsächlich der Minimierungsalgorithmus implementiert ist.  Der Minimierungsmechanismus ist in zwei Versionen implementiert: <br>  • Verwenden des .NET SortedSet-Containers zum Speichern und Suchen von Begriffen. <br>  • ohne Verwendung von .NET-Containern, die auf dem ternären TreeFuncTerm-Baum basieren. <br><br>  In Bezug auf die Geschwindigkeit sind diese beiden Optionen ungefähr gleich (bei .NET-Containern vielleicht etwas schneller, aber nicht immer), aber die Notwendigkeit, TreeFuncTerm zu implementieren, beruht auf mehreren Faktoren: <br>  • Die erste Option, die auf 64-Bit-Integer-Hashcodes und einer Suche im SortedSet .NET-Wörterbuch basiert, funktioniert nur mit der Anzahl der Eingabevariablen in Begriffen bis zu 40 korrekt. wird für den Containerbetrieb verwendet.  Da ternäre Logik innerhalb des Algorithmus in geklebten Begriffen verwendet wird, ist der Maximalwert des Hash-Codes bei einer Anzahl von Eingangsvariablen gleich 41 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>3</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>41</mn></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.039ex" height="2.419ex" viewBox="0 -935.7 1308.3 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-33" x="0" y="0"></use><g transform="translate(500,392)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-34"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-31" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>3</mn><mrow class="MJX-TeXAtom-ORD"><mn>41</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-5"> 3 ^ {41} </script>  überschreitet bereits den Maximalwert <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>64</mn></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.039ex" height="2.419ex" viewBox="0 -935.7 1308.3 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><g transform="translate(500,393)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-36"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-34" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mn>64</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-6"> 2 ^ {64} </script>  -1, die in eine 64-Bit-Variable geschrieben werden kann.  Bei mehr Variablen wird eine Option verwendet, die auf dem ternären Suchbaum TreeFuncTerm des Autors basiert. <br>  • Es ist erforderlich, den Betrieb der Implementierung auf .NET-Containern mit einer anderen, davon unabhängigen Implementierung zu überprüfen. <br>  • Sie benötigen lediglich eine Option, die frei von .NET-Containern ist und problemlos auf Plattformen implementiert werden kann, auf denen keine .NET-Plattform vorhanden ist (z. B. in Mikrocontrollern, FPGAs usw.). <br>  Die Operation des TreeFuncTerm-Suchbaums basiert auf der Konfiguration von Links zu den Klassen TreeNodeMiddle und TreeNodeEnd, die Implementierungen der TreeNodeBase-Schnittstelle sind.  Die TreeNodeMiddle-Klasse ist ein Zwischenknoten des Baums, und die TreeNodeEnd-Klasse ist das Blattende des Baums.  Mit den Funktionen EnumerationInit () und EnumerationNextNode () wird im Baum ein nicht rekursiver Mechanismus zum Auflisten aller Blattblätter von TreeNodeEnd implementiert.  Die Funktion EnumerationInit () initialisiert die Aufzählung und gibt das erste Blatt im Baum zurück.  Die Funktion EnumerationNextNode () gibt das nächste Baumblatt oder NULL zurück, wenn keine Blätter mehr für die Auswahl vorhanden sind.  Darüber hinaus ist die interne Hilfsstruktur EnumerationTerm, die die Position des Such-Cursors innerhalb des Baums widerspiegelt, auch der Begriff Code des gefundenen Blattes in der ternären Logik {0,1,2}.  Es ist zu beachten, dass die Reihenfolge der Auswahl der Blätter aus dem Baum nicht mit der Reihenfolge ihrer Hinzufügung übereinstimmt. <br><br>  Der Algorithmus für funktionale Zwecke kann in drei Stufen unterteilt werden. <br><ol><li>  <b>Vorbereitung.</b>  Um das obige Problem des Eliminierens der Aufzählung von Optionen für zusätzliche Definitionen in der betrachteten Implementierung zu lösen, erhält die Eingabe des Algorithmus in die LogicFuncMinimize-Funktion zwei Anfangsdatensätze PositivTerms und NegativTerms, für die die optimierte Funktion wahre (TRUE, 1) bzw. falsche (FALSE, 0) Werte akzeptiert.  Zunächst werden diese Listen auf Konsistenz der Quelldaten überprüft.  Es ist erforderlich, dass jeder Datensatz garantiert nur eindeutige Begriffe enthält, die nur in einer der Listen vorhanden sind.  Um dies zu gewährleisten, wird jeder einzelne Eingabebegriff gescannt und die Anzahl der Einträge in jeder der Quelllisten gefunden.  Wenn der Begriff in beiden Listen vorkommt, bleibt er nur in der Liste, in der er mehr vorkommt, und wird aus der anderen Liste gelöscht.  Wenn der Begriff in jeder der Listen gleich häufig vorkommt, wird er aus beiden Listen entfernt, wodurch die Eindeutigkeit sichergestellt wird. </li><li>  <b>Verklebung.</b>  Als nächstes wird ein iterativer Zyklus zum Kleben von Eingabeterms durchgeführt.  Bei jeder Iteration wird geklebt ein Vorzeichen * der geklebten Position hinzugefügt.  Daher kann die Anzahl der Iterationen nicht größer sein als die Anzahl der Variablen <i>N.</i>  Im Gegensatz zur vorherigen Implementierung kann die Skleivanie-Funktion zum Kleben von Eingabebegriffen nicht nur mit Begriffen aus ihrer Liste geklebt werden, sondern auch, wenn kein Begriff mit einem Unterschied vorhanden ist, auch mit den sogenannten "virtuellen" Begriffen.  Mit "virtuellen" Begriffen meinen wir künstlich definierte Begriffe, die in keiner der Begriffslisten eines Satzes der aktuellen Ebene enthalten sind.  Das Kleben ist jedoch nur möglich, wenn der „virtuelle“ Begriff nicht einen einzelnen Begriff des ursprünglichen Satzes der gegenüberliegenden Liste abdeckt. <br>  Die Skleivanie-Funktion wird aufgerufen, um Listen bei jeder Iteration zweimal zu verarbeiten, so dass beim ersten Aufruf die Bedeutung der Verwendung der Listen PositivTerms und NegativTerms mit ihrem tatsächlichen Inhalt übereinstimmt, und beim zweiten Aufruf werden die Listen PositivTerms und NegativTerms in Bezug auf die Verwendung ausgetauscht, d. H. Die PositivTerms-Liste enthält negative Begriffe und die NegativTerms-Liste enthält positive Begriffe: <br>  Skleivanie (X1PositivTree, ..., X1NegativTree, ..., SkleivTerms, ...); <br>  Skleivanie (X1NegativTree, ..., X1PositivTree, ..., null, ...); <br>  Somit erfolgt eine gleichzeitige wechselseitige Verklebung der Begriffe zweier Listen. <br>  Wenn es für den Begriff keinen anderen Begriff gibt, der sich von ihm nur in einer Position unterscheidet, weder real noch virtuell, dh der Begriff bleibt mit niemandem zusammen, dann wird er als eines der Ergebnisse von Schritt 1 des Algorithmus angesehen, er wird von der weiteren Arbeit darin ausgeschlossen und handelt zur Eingabe von Stufe 2 des Algorithmus, der in der ReduceRedundancyTerms-Prozedur implementiert ist.  Nicht geklebte Begriffe kommen nur bei diesem Aufruf der Skleivanie-Funktion zur Ausgabe des Algorithmus, für die die Bedeutung der Verwendung der Listen PositivTerms und NegativTerms mit ihrer tatsächlichen Füllung übereinstimmt, d. H. Beim ersten Aufruf. </li><li>  <b>Abkürzung.</b>  Redundante geklebte Terme werden in ReduceRedundancyTerms unter Verwendung eines Algorithmus verworfen, um das Problem der Abdeckung der ursprünglichen Menge mit Teilmengen variabler Länge näherungsweise zu lösen.  Die Abdeckung, die der kürzesten nahe kommt, wird durch den Algorithmus zum Konvertieren der Abdeckungstabelle (TP) bereitgestellt, der auf der Methode „Minimum Column - Maximum Row“ basiert (siehe hier <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.studfiles.ru/preview/5175815/page:4</a> ). . <br>  Die ungefähre Logik seiner Arbeit lautet wie folgt: <br>  0. Die ursprüngliche Tabelle wird als das aktuell transformierte TP betrachtet. Der Satz von Abdeckungslinien ist leer. <br>  1. Die Spalte mit den wenigsten Einheiten wird in der aktuellen Tabelle hervorgehoben.  Unter den Zeilen mit Einheiten in dieser Spalte wird eine mit der größten Anzahl von Einheiten hervorgehoben.  Diese Zeile ist in der Abdeckung enthalten. Die aktuelle Tabelle wird reduziert, indem alle Spalten gelöscht werden, in denen die ausgewählte Zeile eine Einheit enthält. <br>  2. Wenn die Tabelle keine durchgestrichenen Spalten enthält, wird Schritt 1 ausgeführt, andernfalls wird die Abdeckung erstellt.  Hinweis: Bei der Berechnung der Anzahl der Einheiten in einer Zeile werden Einheiten in nicht markierten Spalten berücksichtigt. <br>  Dieser Algorithmus arbeitet schnell genug und liefert ein nahezu optimales Ergebnis. <br>  Um die Funktionsweise des Algorithmus zu testen, wird vorgeschlagen, die Testfunktion TestQuineMcCluskeyRandomPart zu verwenden, die aus der Gesamtheit der möglichen Begriffe besteht <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mi>N</mi></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.854ex" height="2.419ex" viewBox="0 -935.7 1228.8 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMATHI-4E" x="707" y="557"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mi>N</mi></msup></math></span></span><script type="math/tex" id="MathJax-Element-7"> 2 ^ N </script>  wählt zufällig nur den angegebenen Teil 0 &lt;dPart &lt;= 1 aus (ist ein Parameter der Funktion), für den eine Optimierung durchgeführt wird.  Mit dem Parameter dPart &lt;1 wird ein abgeschnittener Satz von Eingabeausdrücken erhalten, und mit dPart = 1 wird ein vollständiger Satz von Eingabedaten erhalten. </li></ol><br><div class="spoiler">  <b class="spoiler_title">TestQuineMcCluskeyRandomPart (zum Anzeigen klicken)</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">public static void TestQuineMcCluskeyRandomPart(int iVariableAmount, double dPart=1) { if (dPart &lt; 0) throw new ArgumentException(" dPart    0   1"); if (dPart &gt; 1) dPart = 1; //   ulong iTotalCombines = (ulong)1 &lt;&lt; iVariableAmount; LinkedList&lt;byte[]&gt; pTrueCol = new LinkedList&lt;byte[]&gt;(); LinkedList&lt;byte[]&gt; pFalseCol = new LinkedList&lt;byte[]&gt;(); HashSet&lt;ulong&gt; pUsedTerms = new HashSet&lt;ulong&gt;(); Random rnd = new Random(); byte[] buf = new byte[8]; while (pUsedTerms.LongCount() &lt; (iTotalCombines * dPart)) { rnd.NextBytes(buf); ulong iCurValue = (ulong)BitConverter.ToInt64(buf, 0) % iTotalCombines; if (pUsedTerms.Contains(iCurValue)) { //  -     do { iCurValue = ++iCurValue % iTotalCombines; } while (pUsedTerms.Contains(iCurValue)); } pUsedTerms.Add(iCurValue); byte[] sLine = new byte[iVariableAmount]; for (int i = 0; i &lt; iVariableAmount; i++) { sLine[i] += (byte)(iCurValue % 2); iCurValue &gt;&gt;= 1; } if (rnd.Next(2) != 0) { pTrueCol.AddLast(sLine); } else { pFalseCol.AddLast(sLine); } } //   DateTime DtStart = DateTime.Now; Console.WriteLine(" - " + DtStart.ToLongTimeString()); Quine_McCluskey Logic = new Quine_McCluskey(); Logic.Start(pTrueCol, pFalseCol); DateTime DtEnd = DateTime.Now; Logic.PrintResult(); Console.WriteLine(" - " + DtStart.ToLongTimeString()); Console.WriteLine(" - " + DtEnd.ToLongTimeString()); TimeSpan Elapsed = DtEnd - DtStart; Console.WriteLine(" - " + String.Format("{0:00}:{1:00}:{2:00}", Elapsed.Hours, Elapsed.Minutes, Elapsed.Seconds)); //  int iErrorsCounter = 0; foreach (byte[] kvp in pTrueCol) { if (Logic.Result.Calculate(kvp) != true) iErrorsCounter++; } foreach (byte[] kvp in pFalseCol) { if (Logic.Result.Calculate(kvp) != false) iErrorsCounter++; } Console.WriteLine("-   = " + pUsedTerms.Count); Console.WriteLine("-   = " + Logic.Result.Terms.Count); Console.WriteLine("-  = " + iErrorsCounter); Console.ReadLine(); }</code> </pre><br></div></div><br><br>  Als Ergebnis der Testfunktion werden die Anzahl der Terme in der minimalen disjunktiven Normalform und die Anzahl der Fehler berechnet, die sie mit dem ursprünglichen Satz von Termen abdecken. <br><br>  Abschließend möchte ich darauf hinweisen, dass sich diese Implementierung des Algorithmus in der Praxis als wirksames und zuverlässiges Mittel zur Minimierung der logischen Funktionen erwiesen hat, die durch zwei unvollständige Sätze von Begriffen definiert sind, für die die logische Funktion TRUE- bzw. FALSE-Werte annimmt.  Natürlich kann diese Implementierung auch in der klassischen Form im Fall einer vollständig definierten logischen Eingabefunktion verwendet werden, wenn nur die eine oder andere Liste von Begriffen eingegeben wird.  Als Nachteil muss in der Skleivanie-Funktion überprüft werden, dass bei jeder Iteration des Algorithmus für jeden virtuellen Term der gesamten Liste der Quellterme keine Abdeckungsfehler vorliegen, was zu erheblichen Zeitkosten bei einer großen Anzahl von Eingabebegriffen führt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424517/">https://habr.com/ru/post/de424517/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424505/index.html">„Wir haben Ideen für Maven 4 und sogar für Maven 5“ - ein Interview mit Robert Scholte, einem wichtigen Teilnehmer am Maven-Projekt</a></li>
<li><a href="../de424507/index.html">VI Jährlicher JetBrains Hackathon: Shiftius Altius Ctrlius</a></li>
<li><a href="../de424509/index.html">Arbeiten mit der KOMPAS-3D-API → Lektion 12 → Zusammengesetzte Linien</a></li>
<li><a href="../de424511/index.html">Tools zum Suchen von kommentierten Klassen in Java</a></li>
<li><a href="../de424513/index.html">Über billige Rechenzentren, ILV- und DDoS-Schutz</a></li>
<li><a href="../de424519/index.html">Kann Beethoven Umzugsanträge senden?</a></li>
<li><a href="../de424525/index.html">Mini-Bohrer-Geschwindigkeitsregelung</a></li>
<li><a href="../de424531/index.html">Microservices: Größe ist wichtig, auch wenn Sie Kubernetes haben</a></li>
<li><a href="../de424533/index.html">„Jeder IT-Mitarbeiter mit Selbstachtung beschäftigt sich in seiner Freizeit mit Technologie“ - 10 Fragen an den Programmierer, Ausgabe 6</a></li>
<li><a href="../de424537/index.html">Die Sberbank hat ihren eigenen Betreiber SberMobile gegründet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
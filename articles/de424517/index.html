<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåï üë∂üèΩ üìä Implementierung der Minimierung logischer Funktionen durch die Quine \ McCluskey-Methode mit einem unvollst√§ndigen Eingabesatz üê∏ üî≤ üôâ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel ist bis zu einem gewissen Grad eine Fortsetzung meines Artikels √ºber die Minimierung logischer Funktionen durch die Quine-Mac'Klaski-Me...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Implementierung der Minimierung logischer Funktionen durch die Quine \ McCluskey-Methode mit einem unvollst√§ndigen Eingabesatz</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424517/">  Dieser Artikel ist bis zu einem gewissen Grad eine Fortsetzung meines Artikels √ºber die Minimierung logischer Funktionen durch die Quine-Mac'Klaski-Methode ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://habr.com/post/328506</a> ).  Es wurde ein Fall mit vollst√§ndig definierten logischen Funktionen betrachtet (obwohl dies nicht direkt darin erw√§hnt, sondern nur impliziert wurde).  In der Realit√§t ist ein solcher Fall ziemlich selten, wenn die Anzahl der Eingabevariablen gering ist.  Teilweise oder unvollst√§ndig definiert sind logische Funktionen, deren Werte nur f√ºr Teil Q aus der Gesamtmenge P = angegeben werden <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mi>N</mi></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.854ex" height="2.419ex" viewBox="0 -935.7 1228.8 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMATHI-4E" x="707" y="557"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mi>N</mi></msup></math></span></span><script type="math/tex" id="MathJax-Element-1"> 2 ^ N </script>  m√∂gliche Mengen (Terme) ihrer Argumente (Variablen) der Zahl <i>N</i> , dh Q &lt;P. Diese Situation tritt in der Praxis in den meisten F√§llen bei der Anwendung von Algorithmen zur Optimierung logischer Funktionen auf.  Wenn beispielsweise die Anzahl der Eingabevariablen <i>N</i> = 30 betr√§gt, was beispielsweise auf den Finanzm√§rkten √ºblich ist, sollte das Volumen der Stichprobe f√ºr das Eingabetraining in der Gr√∂√üenordnung von liegen <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>30</mn></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.039ex" height="2.419ex" viewBox="0 -935.7 1308.3 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><g transform="translate(500,393)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-33"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-30" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mn>30</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-2"> 2 ^ {30} </script>  &gt; <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>10</mn><mn>9</mn></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.379ex" height="2.419ex" viewBox="0 -935.7 1454.9 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-30" x="500" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-39" x="1415" y="557"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mn>9</mn></msup></math></span></span><script type="math/tex" id="MathJax-Element-3"> 10 ^ 9 </script>  einzigartige einzigartige Begriffe.  Ein solches Datenarray findet sich nicht in jeder sehr gro√üen Organisation, ganz zu schweigen von Einzelpersonen, das hei√üt, dies ist bereits die Sph√§re von BigData, die Nutzung von Rechenzentren usw. <br><br>  Daher werden in der Praxis h√§ufig minimierte logische Funktionen nicht einfach aufgrund des Fehlens der erforderlichen Menge an akkumulierten Daten oder aufgrund verschiedener anderer objektiver Gr√ºnde (zum Beispiel ist nicht gen√ºgend Speicherplatz zum Speichern vorhanden) vollst√§ndig bestimmt.  Es stellt sich die Frage nach der M√∂glichkeit der "Umgehung" dieses Problems, wenn ein Algorithmus verwendet wird, der mit einem vollst√§ndig definierten Satz von Begriffslogikfunktionen arbeitet, wie beispielsweise aus meinem vorherigen Artikel. <br><a name="habracut"></a><br><br>  In diesem Fall wird standardm√§√üig der unvollst√§ndige Eingabesatz von Variablen- (Term-) Werten zum vollst√§ndigen Wert bestimmt, um ein optimales Ergebnis f√ºr den vorhandenen Datensatz zu erhalten.  In diesem Fall besteht jedoch ein Problem bei der Aufz√§hlung aller m√∂glichen Varianten zus√§tzlicher Definitionen, deren Gesamtzahl V = ist <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mo>&amp;#x2212;</mo><mi>Q</mi></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.207ex" height="2.539ex" viewBox="0 -987.6 2242 1093.4" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><g transform="translate(500,393)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMATHI-50" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-2212" x="751" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMATHI-51" x="1530" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mo>‚àí</mo><mi>Q</mi></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-4"> 2 ^ {P-Q} </script>  Auswahl der besten Option f√ºr eine zus√§tzliche Definition gem√§√ü einem bestimmten Kriterium.  Offensichtlich ist f√ºr die tats√§chlich verwendeten Werte von Q und P die Anzahl der sortierten Optionen f√ºr zus√§tzliche Definitionen astronomisch gro√ü, und dieser Ansatz kann aufgrund des immensen Rechenaufwands in der Praxis nicht implementiert werden. <br><br>  Daher ist ein anderer Ansatz erforderlich, der die Aufz√§hlung verschiedener Optionen f√ºr zus√§tzliche Definitionen √ºberfl√ºssig macht.  Daher ist es notwendig, den urspr√ºnglichen Algorithmus zu modernisieren, der anf√§nglich nur mit einem vollst√§ndig definierten Eingabesatz funktioniert, damit er auch mit einem abgeschnittenen Satz arbeiten kann.  Es ist eine solche Implementierung des in diesem Artikel vorgeschlagenen Algorithmus, basierend auf der Tatsache, dass w√§hrend des Minimierungsprozesses zwei unvollst√§ndige Listen von Begriffen gleichzeitig verarbeitet werden, auf denen die Funktion als FALSE (0) und TRUE (1) angegeben wird. <br><br>  Unter dem Gesichtspunkt des maschinellen Lernens implementiert der Quine-Mac'Klaski-Algorithmus das Lernparadigma mit dem Lehrer, wenn die entsprechenden Ausgabewerte der Zielfunktion gleichzeitig in den Lernprozess (in diesem Fall Minimierung) einbezogen werden.  Ich m√∂chte Sie daran erinnern, dass das Funktionsprinzip der grundlegenden Quine-Mac'Klaski-Methode nach der Theorie aus zwei Hauptstufen besteht: <br><ol><li>  B√ºhne.  Finden aller einfachen LF-Begriffe mithilfe von Kleberegeln (Gesetzen): <br>  a) (A &amp; B)?  (A &amp;! B)?  A; <br>  b) (A? B) &amp; (A?! B)?  A; <br>  Wo ist die logische UND-Verkn√ºpfung?  - Operation des logischen "ODER" ;!  - Operation der logischen Negation "NICHT".  Aus diesen Formeln folgt, dass zwei Terme zusammengeklebt werden, wenn sie sich nur in einer der Positionen der Variablen voneinander unterscheiden.  An der Stelle, an der sich die beiden Begriffe voneinander unterscheiden, wird das Zeichen ‚Äû*‚Äú gesetzt.  Somit erweitert sich das geklebte Alphabet im Vergleich zum Original auf drei Werte: <br>  ‚Ä¢ 0 =&gt; falsch; <br>  ‚Ä¢ 1 =&gt; wahr; <br>  ‚Ä¢ 2 =&gt; geklebte Variable (*). </li><li>  B√ºhne.  Minimierung der Anzahl der eingeklebten Terme, die nach der ersten Stufe erhalten wurden, als Problem beim Finden der optimalen Abdeckung des anf√§nglichen Satzes von Begriffen mit der Menge Q. Das hei√üt, da jeder Ausgabeausdruck nur eine bestimmte Teilmenge der Quellausdr√ºcke abdeckt, ist es notwendig, einen minimalen Satz von Ausgabeausdr√ºcken zu w√§hlen, mit denen identifiziert wird Mit ihnen deckten Teilmengen unterschiedlicher L√§nge im Aggregat alle anf√§nglichen Eingabebegriffe vollst√§ndig ab.  Beschichten bedeutet in diesem Fall, dass die bitweise Operation der Disjunktion des Ausgangsterms √ºber den Eingangsterm einen wahren Wert ergab.  Angenommen, der ausgegebene geklebte Term hat die folgende Form: 10 * 0110 *. <br>  Dann deckt es den Begriff 10101100 ab: <br>  10 * 0110 * &amp; 10101100 = TRUE <br>  deckt aber nicht den Begriff 00101100 ab: <br>  10 * 0110 * &amp; 00101100 = FALSE <br>  Das hei√üt, der Eingabeterm und der Ausgang m√ºssen √ºberall zusammenfallen, mit Ausnahme der Positionen, an denen ein "*" - Symbol angezeigt wird. In dieser Position kann die Variable des Eingabeterms einen beliebigen Wert annehmen, da  In dieser Position wird die Variable von der Betrachtung ausgeschlossen. </li></ol><br><br><div class="spoiler">  <b class="spoiler_title">Der Implementierungscode lautet wie folgt (zum Anzeigen klicken):</b> <div class="spoiler_text"><pre><code class="plaintext hljs">using System; using System.Collections.Generic; using System.Linq; #region   /// &lt;summary&gt; ///      /// &lt;/summary&gt; public abstract class LogicFunction { // ""  public const byte cStarSymb = 2; //    public readonly ICollection&lt;byte[]&gt; Terms = new LinkedList&lt;byte[]&gt;(); //   public abstract bool Calculate(bool[] X); //   public abstract bool Calculate(char[] X); //   public abstract bool Calculate(byte[] X); } /// &lt;summary&gt; ///    /// &lt;/summary&gt; public class Dnf : LogicFunction { public static bool Calculate(byte[] X, byte[] term) { bool bResult = true; for (int i = 0; i &lt; term.Length; i++) { if ((term[i] == cStarSymb) || (term[i] == X[i])) continue; bResult = false; break; } return bResult; } public override bool Calculate(byte[] X) { bool bResult = false; foreach (byte[] term in Terms) { bool bTermVal = true; for (int i = 0; i &lt; term.Length; i++) { if ((term[i] &gt;= cStarSymb) || (term[i] == X[i])) continue; bTermVal = false; break; } //bResult |= bTermVal; if (bTermVal) { bResult = true; break; } } return bResult; } public override bool Calculate(char[] X) { bool bResult = false; foreach (byte[] term in Terms) { bool bTermVal = true; for (int i = 0; i &lt; term.Length; i++) { if ((term[i] &gt;= cStarSymb) || (term[i] == (byte)(X[i] == '0' ? 0 : 1))) continue; bTermVal = false; break; } //bResult |= bTermVal; if (bTermVal) { bResult = true; break; } } return bResult; } public override bool Calculate(bool[] X) { bool bResult = false; foreach (byte[] term in Terms) { bool bTermVal = true; for (int i = 0; i &lt; term.Length; i++) { if ((term[i] &gt;= cStarSymb) || ((term[i] != 0) == X[i])) continue; bTermVal = false; break; } //bResult |= bTermVal; if (bTermVal) { bResult = true; break; } } return bResult; } } #endregion /// &lt;summary&gt; ///   /// &lt;/summary&gt; public class TreeFuncTerm { /// &lt;summary&gt; ///     /// &lt;/summary&gt; public class TreeNodeEnd { } //    private readonly TreeNodeEnd pCommonTreeNodeEnd = new TreeNodeEnd(); //  private readonly object[] rootNode = new object[3]; // ()  private int _rang = 0; public int Rang { get { return _rang; } } //    private int enumerationPos = 0; private object[][] enumerationBuf; //,     private byte[] enumerationTerm; public byte[] EnumerationTerm { get { return enumerationTerm; } } //     private UInt32 _count = 0; public UInt32 Count { get { return _count; } } // public TreeFuncTerm() { Clear(); } //  public void Clear() { _count = 0; _rang = 0; enumerationPos = 0; enumerationBuf = null; enumerationTerm = null; rootNode[0] = rootNode[1] = rootNode[2] = null; } //      public TreeNodeEnd EnumerationInit() { enumerationPos = 0; enumerationTerm = new byte[_rang]; enumerationTerm[0] = 0; enumerationBuf = new object[_rang][]; enumerationBuf[0] = rootNode; //    return EnumerationNextNode(); } //     public TreeNodeEnd EnumerationNextNode() { int iIsNext = (enumerationPos &gt; 0 ? 1 : 0); TreeNodeEnd pRetTreeNode = null; while ((pRetTreeNode == null) &amp;&amp; (enumerationPos &gt;= 0)) { object[] pCurrNodes = enumerationBuf[enumerationPos]; object pNextNode = null; int i = enumerationTerm[enumerationPos] + iIsNext; for (; i &lt; 3; i++) if ((pNextNode = pCurrNodes[i]) != null) break; if (pNextNode == null) { //    enumerationPos--; iIsNext = 1; } else { enumerationTerm[enumerationPos] = (byte)i; if (pNextNode is object[]) { //    enumerationPos++; enumerationBuf[enumerationPos] = (object[])pNextNode; enumerationTerm[enumerationPos] = 0; iIsNext = 0; } else //if (pNextNode is TreeNodeEnd) { //   pRetTreeNode = (TreeNodeEnd)pNextNode; } } } return pRetTreeNode; } //     public void AddTerm(byte[] term) { _rang = Math.Max(_rang, term.Length); object[] pCurrNode = rootNode; int iTermLength1 = term.Length - 1; for (int j = 0; j &lt; iTermLength1; j++) { byte cSymb = term[j]; object item = pCurrNode[cSymb]; if (item == null) { item = new object[3]; pCurrNode[cSymb] = item; } pCurrNode = (object[])item; } if (pCurrNode[term[iTermLength1]] == null) { //    pCurrNode[term[iTermLength1]] = pCommonTreeNodeEnd; _count++; } } //      public TreeNodeEnd Remove(byte[] term) { int iTermLength1 = term.Length - 1; object[] pCurrNode = rootNode; for (int i = 0; i &lt; iTermLength1; i++) { pCurrNode = (object[])pCurrNode[term[i]]; if (pCurrNode == null) break; } TreeNodeEnd pRemovedNode = null; if (pCurrNode != null) { //      pRemovedNode = (TreeNodeEnd)pCurrNode[term[iTermLength1]]; if (pRemovedNode != null) { //     pCurrNode[term[iTermLength1]] = null; // -  _count--; } } return pRemovedNode; } //     public bool Contains(byte[] term) { object pCurrNode = rootNode; foreach (byte cSymb in term) { pCurrNode = ((object[])pCurrNode)[cSymb]; if (pCurrNode == null) break; } return ((pCurrNode != null) &amp;&amp; (pCurrNode is TreeNodeEnd)); } } /// &lt;summary&gt; ///     ---- /// &lt;/summary&gt; public class Quine_McCluskey { //    private readonly Dnf _result = new Dnf(); public Dnf Result { get { return _result; } } //    private readonly Dnf _resultNeg = new Dnf(); public Dnf ResultNeg { get { return _resultNeg; } } //     private static void Skleivanie(TreeFuncTerm X1Tree, TreeFuncTerm X2Tree, TreeFuncTerm NegativTree, IEnumerable&lt;byte[]&gt; InpNegTerms, Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; OutResult, int iLevel) { LinkedList&lt;byte[]&gt; OutR = new LinkedList&lt;byte[]&gt;(); if (OutResult != null) OutResult.Add(iLevel, OutR); bool IsVirtSkleivOn = ((NegativTree != null) &amp;&amp; (InpNegTerms != null) &amp;&amp; (InpNegTerms.Count() != 0)); for (TreeFuncTerm.TreeNodeEnd x1 = X1Tree.EnumerationInit(); x1 != null; x1 = X1Tree.EnumerationNextNode()) { bool bIsSkleiv = false; byte[] pCurrTerm = X1Tree.EnumerationTerm; for (int iPos = 0; iPos &lt; pCurrTerm.Length; iPos++) { byte cSymbSav = pCurrTerm[iPos]; if (cSymbSav == LogicFunction.cStarSymb) continue; //      pCurrTerm[iPos] = (byte)(1 - cSymbSav); if (X1Tree.Contains(pCurrTerm)) { bIsSkleiv = true; //,         if (cSymbSav == 1) { pCurrTerm[iPos] = LogicFunction.cStarSymb; //  X2Tree.AddTerm(pCurrTerm); } } //    ,    NegativTree else if (IsVirtSkleivOn &amp;&amp; !NegativTree.Contains(pCurrTerm)) { bool bIsNotCanAdd = false; pCurrTerm[iPos] = LogicFunction.cStarSymb; //  foreach (byte[] NegTerm in InpNegTerms) { if (bIsNotCanAdd = Dnf.Calculate(NegTerm, pCurrTerm)) break; } if (!bIsNotCanAdd) { bIsSkleiv = true; X2Tree.AddTerm(pCurrTerm); } } pCurrTerm[iPos] = cSymbSav; } //    ,       if (!bIsSkleiv) OutR.AddLast((byte[])pCurrTerm.Clone()); } } //     private static UInt64 GetTermCode(byte[] pTerm) { UInt64 iMultip = 1, iCode = 0; for (int i = 0; i &lt; pTerm.Length; i++) { iCode += (iMultip * pTerm[i]); iMultip *= 3; } return iCode; } //     private static byte[] GetTermByCode(UInt64 iCode, int iTermLength, byte[] pTerm = null) { if (pTerm == null) pTerm = new byte[iTermLength]; int iCounter = 0; while (iCode != 0) { pTerm[iCounter++] = (byte)(iCode % 3); iCode /= 3; } while (iCounter &lt; iTermLength) pTerm[iCounter++] = 0; return pTerm; } //     private static void Skleivanie(ICollection&lt;UInt64&gt; X1Tree, ICollection&lt;UInt64&gt; X2Tree, ICollection&lt;UInt64&gt; NegativTree, IEnumerable&lt;byte[]&gt; InpNegTerms, Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; OutResult, int iLevel, int iTermLength) { LinkedList&lt;byte[]&gt; OutR = new LinkedList&lt;byte[]&gt;(); if (OutResult != null) OutResult.Add(iLevel, OutR); byte[] pCurrTerm = new byte[iTermLength]; bool IsVirtSkleivOn = ((NegativTree != null) &amp;&amp; (InpNegTerms != null) &amp;&amp; (InpNegTerms.Count() != 0)); foreach (UInt64 x1 in X1Tree) { GetTermByCode(x1, iTermLength, pCurrTerm); bool bIsSkleiv = false; UInt64 iMultip = 1; for (int iPos = 0; iPos &lt; iTermLength; iPos++) { byte cSymbSav = pCurrTerm[iPos]; //(byte)((x1 / iMultip) % 3); if (cSymbSav != LogicFunction.cStarSymb) { UInt64 iCode = (cSymbSav == 0 ? x1 + iMultip : x1 - iMultip); //      if (X1Tree.Contains(iCode)) { bIsSkleiv = true; //,         if (cSymbSav == 1) { X2Tree.Add(x1 + iMultip); } } //    ,    NegativTree else if (IsVirtSkleivOn &amp;&amp; !NegativTree.Contains(iCode)) { bool bIsNotCanAdd = false; pCurrTerm[iPos] = LogicFunction.cStarSymb; //  foreach (byte[] NegTerm in InpNegTerms) { if (bIsNotCanAdd = Dnf.Calculate(NegTerm, pCurrTerm)) break; } pCurrTerm[iPos] = cSymbSav; if (!bIsNotCanAdd) { bIsSkleiv = true; X2Tree.Add(x1 + (byte)(LogicFunction.cStarSymb - cSymbSav) * iMultip); } } } iMultip *= 3; } //    ,       if (!bIsSkleiv) OutR.AddLast((byte[])pCurrTerm.Clone()); } } //      //       private static void DeleteDublicatingTerms(IEnumerable&lt;byte[]&gt; InX1, ICollection&lt;UInt64&gt; OutX2Tree) { OutX2Tree.Clear(); foreach (byte[] x1 in InX1) { UInt64 iCode = GetTermCode(x1); if (OutX2Tree.Contains(iCode)) continue; OutX2Tree.Add(iCode); } } //      //       private static void DeleteDublicatingTerms(IEnumerable&lt;byte[]&gt; InX1, TreeFuncTerm OutX2Tree) { OutX2Tree.Clear(); foreach (byte[] x1 in InX1) OutX2Tree.AddTerm(x1); } //    private static bool IsEqualTerms(byte[] pTermC, byte[] pTermB) { if ((pTermC == null) || (pTermB == null) || (pTermC.Length != pTermB.Length)) return false; bool bIsEqual = false; int iLength = Math.Min(pTermC.Length, pTermB.Length); for ( int i = 0; i &lt; iLength; i++) { if (!(bIsEqual = (pTermB[i] == pTermC[i]))) break; } return bIsEqual; } //            private static void ReduceRedundancyTerms(LinkedList&lt;byte[]&gt; InpTerms, Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; SkleivTerms, ICollection&lt;byte[]&gt; ResultTerms) { if ((InpTerms == null) || (SkleivTerms == null) || (ResultTerms == null)) return; //   ResultTerms.Clear(); //        ,    Dictionary&lt;byte[], HashSet&lt;byte[]&gt;&gt; Outputs2Inputs = new Dictionary&lt;byte[], HashSet&lt;byte[]&gt;&gt;(); //        ,    Dictionary&lt;byte[], HashSet&lt;byte[]&gt;&gt; Inputs2Outputs = new Dictionary&lt;byte[], HashSet&lt;byte[]&gt;&gt;(); //    foreach (int iLevel in SkleivTerms.Keys.OrderByDescending(p =&gt; p).AsEnumerable()) { //       foreach (byte[] outTerm in SkleivTerms[iLevel]) { //  ,      term HashSet&lt;byte[]&gt; InpTermsLst = new HashSet&lt;byte[]&gt;(); //     foreach (byte[] inpTerm in InpTerms) { if (Dnf.Calculate(inpTerm, outTerm)) { InpTermsLst.Add(inpTerm); if (!Inputs2Outputs.ContainsKey(inpTerm)) Inputs2Outputs.Add(inpTerm, new HashSet&lt;byte[]&gt;()); Inputs2Outputs[inpTerm].Add(outTerm); } } Outputs2Inputs.Add(outTerm, InpTermsLst); } } //      -    Inputs2Outputs = Inputs2Outputs.OrderBy(p =&gt; p.Value.Count).ToDictionary(p =&gt; p.Key, v =&gt; v.Value); //   ,   -    while (Inputs2Outputs.Count &gt; 0) { byte[] outTerm = Inputs2Outputs.First().Value.OrderByDescending(q =&gt; Outputs2Inputs[q].Count()).First(); ResultTerms.Add(outTerm); foreach (byte[] inpTerm in Outputs2Inputs[outTerm].ToArray()) { foreach (byte[] outTerm2Del in Inputs2Outputs[inpTerm]) Outputs2Inputs[outTerm2Del].Remove(inpTerm); Inputs2Outputs.Remove(inpTerm); } } } //    public static void LogicFuncMinimize(IEnumerable&lt;byte[]&gt; PositivTerms, ICollection&lt;byte[]&gt; OutPos, IEnumerable&lt;byte[]&gt; NegativTerms, ICollection&lt;byte[]&gt; OutNeg) { int iTotalLevels = (PositivTerms.Count() &gt; 0 ? PositivTerms.First().Length : (NegativTerms != null &amp;&amp; NegativTerms.Count() &gt; 0 ? NegativTerms.First().Length : 0)); Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; SkleivPosTerms = new Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt;(iTotalLevels); Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt; SkleivNegTerms = new Dictionary&lt;int, LinkedList&lt;byte[]&gt;&gt;(iTotalLevels); LinkedList&lt;byte[]&gt; InpPosTerms = new LinkedList&lt;byte[]&gt;(); LinkedList&lt;byte[]&gt; InpNegTerms = new LinkedList&lt;byte[]&gt;(); if (iTotalLevels &lt; 40) { HashSet&lt;UInt64&gt; X1PositivTree = new HashSet&lt;UInt64&gt;(); DeleteDublicatingTerms(PositivTerms, X1PositivTree); HashSet&lt;UInt64&gt; X1NegativTree = null; if (NegativTerms != null) { X1NegativTree = new HashSet&lt;UInt64&gt;(); DeleteDublicatingTerms(NegativTerms, X1NegativTree); //        foreach(UInt64 iNumb in X1PositivTree.Intersect(X1NegativTree)) { // -    X1   NegativTerms int iPos_Count = PositivTerms.Count(p =&gt; GetTermCode(p) == iNumb); int iNeg_Count = NegativTerms.Count(p =&gt; GetTermCode(p) == iNumb); if (iPos_Count &gt; iNeg_Count) { X1NegativTree.Remove(iNumb); } else if (iPos_Count &lt; iNeg_Count) { X1PositivTree.Remove(iNumb); } else //if (iPos_Count == iNeg_Count) { X1PositivTree.Remove(iNumb); X1NegativTree.Remove(iNumb); } } //           foreach (UInt64 code in X1NegativTree) { InpNegTerms.AddLast(GetTermByCode(code, iTotalLevels)); } } //          foreach (UInt64 code in X1PositivTree) { InpPosTerms.AddLast(GetTermByCode(code, iTotalLevels)); } int iLevelCounter = 0; //        while ((X1PositivTree.Count != 0) &amp;&amp; (iLevelCounter &lt; iTotalLevels)) { HashSet&lt;UInt64&gt; X2PositivTree = new HashSet&lt;UInt64&gt;(); Skleivanie(X1PositivTree, X2PositivTree, X1NegativTree, InpNegTerms, SkleivPosTerms, iLevelCounter, iTotalLevels); if ((X1NegativTree != null) &amp;&amp; (X1NegativTree.Count != 0)) { HashSet&lt;UInt64&gt; X2NegativTree = new HashSet&lt;UInt64&gt;(); Skleivanie(X1NegativTree, X2NegativTree, X1PositivTree, InpPosTerms, SkleivNegTerms, iLevelCounter, iTotalLevels); //   X1NegativTree.Clear(); X1NegativTree = X2NegativTree; } //   X1PositivTree.Clear(); X1PositivTree = X2PositivTree; iLevelCounter++; GC.Collect(); } } else { TreeFuncTerm X1PositivTree = new TreeFuncTerm(); DeleteDublicatingTerms(PositivTerms, X1PositivTree); TreeFuncTerm X1NegativTree = null; if (NegativTerms != null) { X1NegativTree = new TreeFuncTerm(); DeleteDublicatingTerms(NegativTerms, X1NegativTree); //         for (TreeFuncTerm.TreeNodeEnd x1 = X1PositivTree.EnumerationInit(); x1 != null; x1 = X1PositivTree.EnumerationNextNode()) { if (!X1NegativTree.Contains(X1PositivTree.EnumerationTerm)) continue; // -    PositivTerms   NegativTerms int iPos_Count = PositivTerms.Count(p =&gt; IsEqualTerms(p, X1PositivTree.EnumerationTerm)); int iNeg_Count = NegativTerms.Count(p =&gt; IsEqualTerms(p, X1PositivTree.EnumerationTerm)); if (iPos_Count &gt; iNeg_Count) { X1NegativTree.Remove(X1PositivTree.EnumerationTerm); } else if (iPos_Count &lt; iNeg_Count) { X1PositivTree.Remove(X1PositivTree.EnumerationTerm); } else //if (iPos_Count == iNeg_Count) { X1PositivTree.Remove(X1PositivTree.EnumerationTerm); X1NegativTree.Remove(X1PositivTree.EnumerationTerm); } } //           for (TreeFuncTerm.TreeNodeEnd x1 = X1NegativTree.EnumerationInit(); x1 != null; x1 = X1NegativTree.EnumerationNextNode()) { InpNegTerms.AddLast((byte[])X1NegativTree.EnumerationTerm.Clone()); } } //          for (TreeFuncTerm.TreeNodeEnd X1Term = X1PositivTree.EnumerationInit(); X1Term != null; X1Term = X1PositivTree.EnumerationNextNode()) { InpPosTerms.AddLast((byte[])X1PositivTree.EnumerationTerm.Clone()); } int iLevelCounter = 0; //        while ((X1PositivTree.Count != 0) &amp;&amp; (iLevelCounter &lt; iTotalLevels)) { TreeFuncTerm X2PositivTree = new TreeFuncTerm(); Skleivanie(X1PositivTree, X2PositivTree, X1NegativTree, InpNegTerms, SkleivPosTerms, iLevelCounter); if ((X1NegativTree != null) &amp;&amp; (X1NegativTree.Count != 0)) { TreeFuncTerm X2NegativTree = new TreeFuncTerm(); Skleivanie(X1NegativTree, X2NegativTree, X1PositivTree, InpPosTerms, SkleivNegTerms, iLevelCounter); //   X1NegativTree.Clear(); X1NegativTree = X2NegativTree; } //   X1PositivTree.Clear(); X1PositivTree = X2PositivTree; iLevelCounter++; GC.Collect(); } } //       ReduceRedundancyTerms(InpPosTerms, SkleivPosTerms, OutPos); //       ReduceRedundancyTerms(InpNegTerms, SkleivNegTerms, OutNeg); } //  public void Start(IEnumerable&lt;byte[]&gt; TermsInput) { LogicFuncMinimize(TermsInput, _result.Terms, null, null); } //  public void Start(IEnumerable&lt;byte[]&gt; TermsInput, IEnumerable&lt;byte[]&gt; NegativTerms) { LogicFuncMinimize(TermsInput, _result.Terms, NegativTerms, _resultNeg.Terms); } //  public void Start(IEnumerable&lt;char[]&gt; TermsInput) { Start(TermsInput.Select(t =&gt; t.Select(p =&gt; (byte)(p == '0' ? 0 : 1)).ToArray())); } //  public void Start(IEnumerable&lt;char[]&gt; TermsInput, IEnumerable&lt;char[]&gt; NegativTerms) { Start(TermsInput.Select(t =&gt; t.Select(p =&gt; (byte)(p == '0' ? 0 : 1)).ToArray()), NegativTerms.Select(t =&gt; t.Select(p =&gt; (byte)(p == '0' ? 0 : 1)).ToArray())); } //  public void Start(IEnumerable&lt;bool[]&gt; TermsInput) { Start(TermsInput.Select(t =&gt; t.Select(p =&gt; (byte)(p ? 1 : 0)).ToArray())); } //  public void Start(IEnumerable&lt;bool[]&gt; TermsInput, IEnumerable&lt;bool[]&gt; NegativTerms) { Start(TermsInput.Select(t =&gt; t.Select(p =&gt; (byte)(p ? 1 : 0)).ToArray()), NegativTerms.Select(t =&gt; t.Select(p =&gt; (byte)(p ? 1 : 0)).ToArray())); } public void PrintResult() { Console.WriteLine("--------Otvet-------"); char[] pTermSymbs = new char[] { '0', '1', '*' }; foreach (byte[] Term in _result.Terms) { for (int j = 0; j &lt; Term.Length; j++) { Console.Write(pTermSymbs[Term[j]].ToString() + " "); } Console.WriteLine(); } } }</code> </pre> <br></div></div><br><br>  Die Quine_McCluskey-Klasse ist eine Implementierung dieses Algorithmus, der andere Klassen und Schnittstellen verwendet: Dnf, TreeNodeBase, TreeNodeMiddle, TreeNodeEnd, TreeFuncTerm.  Um die Optimierung zu starten, m√ºssen Sie eine der √ºberladenen Start-Methoden aufrufen, die die LogicFuncMinimize-Funktion aufruft, wobei tats√§chlich der Minimierungsalgorithmus implementiert ist.  Der Minimierungsmechanismus ist in zwei Versionen implementiert: <br>  ‚Ä¢ Verwenden des .NET SortedSet-Containers zum Speichern und Suchen von Begriffen. <br>  ‚Ä¢ ohne Verwendung von .NET-Containern, die auf dem tern√§ren TreeFuncTerm-Baum basieren. <br><br>  In Bezug auf die Geschwindigkeit sind diese beiden Optionen ungef√§hr gleich (bei .NET-Containern vielleicht etwas schneller, aber nicht immer), aber die Notwendigkeit, TreeFuncTerm zu implementieren, beruht auf mehreren Faktoren: <br>  ‚Ä¢ Die erste Option, die auf 64-Bit-Integer-Hashcodes und einer Suche im SortedSet .NET-W√∂rterbuch basiert, funktioniert nur mit der Anzahl der Eingabevariablen in Begriffen bis zu 40 korrekt. wird f√ºr den Containerbetrieb verwendet.  Da tern√§re Logik innerhalb des Algorithmus in geklebten Begriffen verwendet wird, ist der Maximalwert des Hash-Codes bei einer Anzahl von Eingangsvariablen gleich 41 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>3</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>41</mn></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.039ex" height="2.419ex" viewBox="0 -935.7 1308.3 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-33" x="0" y="0"></use><g transform="translate(500,392)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-34"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-31" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>3</mn><mrow class="MJX-TeXAtom-ORD"><mn>41</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-5"> 3 ^ {41} </script>  √ºberschreitet bereits den Maximalwert <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>64</mn></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.039ex" height="2.419ex" viewBox="0 -935.7 1308.3 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><g transform="translate(500,393)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-36"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-34" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mn>64</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-6"> 2 ^ {64} </script>  -1, die in eine 64-Bit-Variable geschrieben werden kann.  Bei mehr Variablen wird eine Option verwendet, die auf dem tern√§ren Suchbaum TreeFuncTerm des Autors basiert. <br>  ‚Ä¢ Es ist erforderlich, den Betrieb der Implementierung auf .NET-Containern mit einer anderen, davon unabh√§ngigen Implementierung zu √ºberpr√ºfen. <br>  ‚Ä¢ Sie ben√∂tigen lediglich eine Option, die frei von .NET-Containern ist und problemlos auf Plattformen implementiert werden kann, auf denen keine .NET-Plattform vorhanden ist (z. B. in Mikrocontrollern, FPGAs usw.). <br>  Die Operation des TreeFuncTerm-Suchbaums basiert auf der Konfiguration von Links zu den Klassen TreeNodeMiddle und TreeNodeEnd, die Implementierungen der TreeNodeBase-Schnittstelle sind.  Die TreeNodeMiddle-Klasse ist ein Zwischenknoten des Baums, und die TreeNodeEnd-Klasse ist das Blattende des Baums.  Mit den Funktionen EnumerationInit () und EnumerationNextNode () wird im Baum ein nicht rekursiver Mechanismus zum Auflisten aller Blattbl√§tter von TreeNodeEnd implementiert.  Die Funktion EnumerationInit () initialisiert die Aufz√§hlung und gibt das erste Blatt im Baum zur√ºck.  Die Funktion EnumerationNextNode () gibt das n√§chste Baumblatt oder NULL zur√ºck, wenn keine Bl√§tter mehr f√ºr die Auswahl vorhanden sind.  Dar√ºber hinaus ist die interne Hilfsstruktur EnumerationTerm, die die Position des Such-Cursors innerhalb des Baums widerspiegelt, auch der Begriff Code des gefundenen Blattes in der tern√§ren Logik {0,1,2}.  Es ist zu beachten, dass die Reihenfolge der Auswahl der Bl√§tter aus dem Baum nicht mit der Reihenfolge ihrer Hinzuf√ºgung √ºbereinstimmt. <br><br>  Der Algorithmus f√ºr funktionale Zwecke kann in drei Stufen unterteilt werden. <br><ol><li>  <b>Vorbereitung.</b>  Um das obige Problem des Eliminierens der Aufz√§hlung von Optionen f√ºr zus√§tzliche Definitionen in der betrachteten Implementierung zu l√∂sen, erh√§lt die Eingabe des Algorithmus in die LogicFuncMinimize-Funktion zwei Anfangsdatens√§tze PositivTerms und NegativTerms, f√ºr die die optimierte Funktion wahre (TRUE, 1) bzw. falsche (FALSE, 0) Werte akzeptiert.  Zun√§chst werden diese Listen auf Konsistenz der Quelldaten √ºberpr√ºft.  Es ist erforderlich, dass jeder Datensatz garantiert nur eindeutige Begriffe enth√§lt, die nur in einer der Listen vorhanden sind.  Um dies zu gew√§hrleisten, wird jeder einzelne Eingabebegriff gescannt und die Anzahl der Eintr√§ge in jeder der Quelllisten gefunden.  Wenn der Begriff in beiden Listen vorkommt, bleibt er nur in der Liste, in der er mehr vorkommt, und wird aus der anderen Liste gel√∂scht.  Wenn der Begriff in jeder der Listen gleich h√§ufig vorkommt, wird er aus beiden Listen entfernt, wodurch die Eindeutigkeit sichergestellt wird. </li><li>  <b>Verklebung.</b>  Als n√§chstes wird ein iterativer Zyklus zum Kleben von Eingabeterms durchgef√ºhrt.  Bei jeder Iteration wird geklebt ein Vorzeichen * der geklebten Position hinzugef√ºgt.  Daher kann die Anzahl der Iterationen nicht gr√∂√üer sein als die Anzahl der Variablen <i>N.</i>  Im Gegensatz zur vorherigen Implementierung kann die Skleivanie-Funktion zum Kleben von Eingabebegriffen nicht nur mit Begriffen aus ihrer Liste geklebt werden, sondern auch, wenn kein Begriff mit einem Unterschied vorhanden ist, auch mit den sogenannten "virtuellen" Begriffen.  Mit "virtuellen" Begriffen meinen wir k√ºnstlich definierte Begriffe, die in keiner der Begriffslisten eines Satzes der aktuellen Ebene enthalten sind.  Das Kleben ist jedoch nur m√∂glich, wenn der ‚Äûvirtuelle‚Äú Begriff nicht einen einzelnen Begriff des urspr√ºnglichen Satzes der gegen√ºberliegenden Liste abdeckt. <br>  Die Skleivanie-Funktion wird aufgerufen, um Listen bei jeder Iteration zweimal zu verarbeiten, so dass beim ersten Aufruf die Bedeutung der Verwendung der Listen PositivTerms und NegativTerms mit ihrem tats√§chlichen Inhalt √ºbereinstimmt, und beim zweiten Aufruf werden die Listen PositivTerms und NegativTerms in Bezug auf die Verwendung ausgetauscht, d. H. Die PositivTerms-Liste enth√§lt negative Begriffe und die NegativTerms-Liste enth√§lt positive Begriffe: <br>  Skleivanie (X1PositivTree, ..., X1NegativTree, ..., SkleivTerms, ...); <br>  Skleivanie (X1NegativTree, ..., X1PositivTree, ..., null, ...); <br>  Somit erfolgt eine gleichzeitige wechselseitige Verklebung der Begriffe zweier Listen. <br>  Wenn es f√ºr den Begriff keinen anderen Begriff gibt, der sich von ihm nur in einer Position unterscheidet, weder real noch virtuell, dh der Begriff bleibt mit niemandem zusammen, dann wird er als eines der Ergebnisse von Schritt 1 des Algorithmus angesehen, er wird von der weiteren Arbeit darin ausgeschlossen und handelt zur Eingabe von Stufe 2 des Algorithmus, der in der ReduceRedundancyTerms-Prozedur implementiert ist.  Nicht geklebte Begriffe kommen nur bei diesem Aufruf der Skleivanie-Funktion zur Ausgabe des Algorithmus, f√ºr die die Bedeutung der Verwendung der Listen PositivTerms und NegativTerms mit ihrer tats√§chlichen F√ºllung √ºbereinstimmt, d. H. Beim ersten Aufruf. </li><li>  <b>Abk√ºrzung.</b>  Redundante geklebte Terme werden in ReduceRedundancyTerms unter Verwendung eines Algorithmus verworfen, um das Problem der Abdeckung der urspr√ºnglichen Menge mit Teilmengen variabler L√§nge n√§herungsweise zu l√∂sen.  Die Abdeckung, die der k√ºrzesten nahe kommt, wird durch den Algorithmus zum Konvertieren der Abdeckungstabelle (TP) bereitgestellt, der auf der Methode ‚ÄûMinimum Column - Maximum Row‚Äú basiert (siehe hier <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.studfiles.ru/preview/5175815/page:4</a> ). . <br>  Die ungef√§hre Logik seiner Arbeit lautet wie folgt: <br>  0. Die urspr√ºngliche Tabelle wird als das aktuell transformierte TP betrachtet. Der Satz von Abdeckungslinien ist leer. <br>  1. Die Spalte mit den wenigsten Einheiten wird in der aktuellen Tabelle hervorgehoben.  Unter den Zeilen mit Einheiten in dieser Spalte wird eine mit der gr√∂√üten Anzahl von Einheiten hervorgehoben.  Diese Zeile ist in der Abdeckung enthalten. Die aktuelle Tabelle wird reduziert, indem alle Spalten gel√∂scht werden, in denen die ausgew√§hlte Zeile eine Einheit enth√§lt. <br>  2. Wenn die Tabelle keine durchgestrichenen Spalten enth√§lt, wird Schritt 1 ausgef√ºhrt, andernfalls wird die Abdeckung erstellt.  Hinweis: Bei der Berechnung der Anzahl der Einheiten in einer Zeile werden Einheiten in nicht markierten Spalten ber√ºcksichtigt. <br>  Dieser Algorithmus arbeitet schnell genug und liefert ein nahezu optimales Ergebnis. <br>  Um die Funktionsweise des Algorithmus zu testen, wird vorgeschlagen, die Testfunktion TestQuineMcCluskeyRandomPart zu verwenden, die aus der Gesamtheit der m√∂glichen Begriffe besteht <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mi>N</mi></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.854ex" height="2.419ex" viewBox="0 -935.7 1228.8 1041.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMAIN-32" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/424517/&amp;usg=ALkJrhhXvDnpELJ9zqWzpRXDP6xUt3L-LQ#MJMATHI-4E" x="707" y="557"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mi>N</mi></msup></math></span></span><script type="math/tex" id="MathJax-Element-7"> 2 ^ N </script>  w√§hlt zuf√§llig nur den angegebenen Teil 0 &lt;dPart &lt;= 1 aus (ist ein Parameter der Funktion), f√ºr den eine Optimierung durchgef√ºhrt wird.  Mit dem Parameter dPart &lt;1 wird ein abgeschnittener Satz von Eingabeausdr√ºcken erhalten, und mit dPart = 1 wird ein vollst√§ndiger Satz von Eingabedaten erhalten. </li></ol><br><div class="spoiler">  <b class="spoiler_title">TestQuineMcCluskeyRandomPart (zum Anzeigen klicken)</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">public static void TestQuineMcCluskeyRandomPart(int iVariableAmount, double dPart=1) { if (dPart &lt; 0) throw new ArgumentException(" dPart    0   1"); if (dPart &gt; 1) dPart = 1; //   ulong iTotalCombines = (ulong)1 &lt;&lt; iVariableAmount; LinkedList&lt;byte[]&gt; pTrueCol = new LinkedList&lt;byte[]&gt;(); LinkedList&lt;byte[]&gt; pFalseCol = new LinkedList&lt;byte[]&gt;(); HashSet&lt;ulong&gt; pUsedTerms = new HashSet&lt;ulong&gt;(); Random rnd = new Random(); byte[] buf = new byte[8]; while (pUsedTerms.LongCount() &lt; (iTotalCombines * dPart)) { rnd.NextBytes(buf); ulong iCurValue = (ulong)BitConverter.ToInt64(buf, 0) % iTotalCombines; if (pUsedTerms.Contains(iCurValue)) { //  -     do { iCurValue = ++iCurValue % iTotalCombines; } while (pUsedTerms.Contains(iCurValue)); } pUsedTerms.Add(iCurValue); byte[] sLine = new byte[iVariableAmount]; for (int i = 0; i &lt; iVariableAmount; i++) { sLine[i] += (byte)(iCurValue % 2); iCurValue &gt;&gt;= 1; } if (rnd.Next(2) != 0) { pTrueCol.AddLast(sLine); } else { pFalseCol.AddLast(sLine); } } //   DateTime DtStart = DateTime.Now; Console.WriteLine(" - " + DtStart.ToLongTimeString()); Quine_McCluskey Logic = new Quine_McCluskey(); Logic.Start(pTrueCol, pFalseCol); DateTime DtEnd = DateTime.Now; Logic.PrintResult(); Console.WriteLine(" - " + DtStart.ToLongTimeString()); Console.WriteLine(" - " + DtEnd.ToLongTimeString()); TimeSpan Elapsed = DtEnd - DtStart; Console.WriteLine(" - " + String.Format("{0:00}:{1:00}:{2:00}", Elapsed.Hours, Elapsed.Minutes, Elapsed.Seconds)); //  int iErrorsCounter = 0; foreach (byte[] kvp in pTrueCol) { if (Logic.Result.Calculate(kvp) != true) iErrorsCounter++; } foreach (byte[] kvp in pFalseCol) { if (Logic.Result.Calculate(kvp) != false) iErrorsCounter++; } Console.WriteLine("-   = " + pUsedTerms.Count); Console.WriteLine("-   = " + Logic.Result.Terms.Count); Console.WriteLine("-  = " + iErrorsCounter); Console.ReadLine(); }</code> </pre><br></div></div><br><br>  Als Ergebnis der Testfunktion werden die Anzahl der Terme in der minimalen disjunktiven Normalform und die Anzahl der Fehler berechnet, die sie mit dem urspr√ºnglichen Satz von Termen abdecken. <br><br>  Abschlie√üend m√∂chte ich darauf hinweisen, dass sich diese Implementierung des Algorithmus in der Praxis als wirksames und zuverl√§ssiges Mittel zur Minimierung der logischen Funktionen erwiesen hat, die durch zwei unvollst√§ndige S√§tze von Begriffen definiert sind, f√ºr die die logische Funktion TRUE- bzw. FALSE-Werte annimmt.  Nat√ºrlich kann diese Implementierung auch in der klassischen Form im Fall einer vollst√§ndig definierten logischen Eingabefunktion verwendet werden, wenn nur die eine oder andere Liste von Begriffen eingegeben wird.  Als Nachteil muss in der Skleivanie-Funktion √ºberpr√ºft werden, dass bei jeder Iteration des Algorithmus f√ºr jeden virtuellen Term der gesamten Liste der Quellterme keine Abdeckungsfehler vorliegen, was zu erheblichen Zeitkosten bei einer gro√üen Anzahl von Eingabebegriffen f√ºhrt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424517/">https://habr.com/ru/post/de424517/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424505/index.html">‚ÄûWir haben Ideen f√ºr Maven 4 und sogar f√ºr Maven 5‚Äú - ein Interview mit Robert Scholte, einem wichtigen Teilnehmer am Maven-Projekt</a></li>
<li><a href="../de424507/index.html">VI J√§hrlicher JetBrains Hackathon: Shiftius Altius Ctrlius</a></li>
<li><a href="../de424509/index.html">Arbeiten mit der KOMPAS-3D-API ‚Üí Lektion 12 ‚Üí Zusammengesetzte Linien</a></li>
<li><a href="../de424511/index.html">Tools zum Suchen von kommentierten Klassen in Java</a></li>
<li><a href="../de424513/index.html">√úber billige Rechenzentren, ILV- und DDoS-Schutz</a></li>
<li><a href="../de424519/index.html">Kann Beethoven Umzugsantr√§ge senden?</a></li>
<li><a href="../de424525/index.html">Mini-Bohrer-Geschwindigkeitsregelung</a></li>
<li><a href="../de424531/index.html">Microservices: Gr√∂√üe ist wichtig, auch wenn Sie Kubernetes haben</a></li>
<li><a href="../de424533/index.html">‚ÄûJeder IT-Mitarbeiter mit Selbstachtung besch√§ftigt sich in seiner Freizeit mit Technologie‚Äú - 10 Fragen an den Programmierer, Ausgabe 6</a></li>
<li><a href="../de424537/index.html">Die Sberbank hat ihren eigenen Betreiber SberMobile gegr√ºndet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∞üèª ü¶å üíÉüèø R√©plication de Tarantool: configuration et utilisation üöï üò¥ üö±</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="J'entre dans l'√©quipe Tarantool Core et participe au d√©veloppement d'un moteur de base de donn√©es, aux communications internes des composants serveur ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>R√©plication de Tarantool: configuration et utilisation</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439514/"><img src="https://habrastorage.org/webt/ec/a3/bt/eca3bttl2uu6rg8sz7e9sj3o3us.jpeg"><br><br>  J'entre dans l'√©quipe Tarantool Core et participe au d√©veloppement d'un moteur de base de donn√©es, aux communications internes des composants serveur et √† la r√©plication.  Et aujourd'hui, je vais vous expliquer le fonctionnement de la r√©plication. <br><a name="habracut"></a><br><h2>  √Ä propos de la r√©plication </h2><br>  La r√©plication est le processus de copie de donn√©es d'un magasin √† un autre.  Chaque copie est appel√©e r√©plique.  La r√©plication peut √™tre utilis√©e si vous devez obtenir une sauvegarde, impl√©menter une redondance d'UC ou redimensionner le syst√®me horizontalement.  Et pour cela il faut pouvoir utiliser les m√™mes donn√©es sur diff√©rents n≈ìuds du r√©seau informatique du cluster. <br><br>  Nous classons la r√©plication de deux mani√®res principales: <br><br><ul><li> <b>Direction: ma√Ætre-ma√Ætre ou ma√Ætre-esclave</b> .  La r√©plication ma√Ætre-esclave est l'option la plus simple.  Vous avez un n≈ìud sur lequel vous modifiez des donn√©es.  Vous traduisez ces modifications vers les autres n≈ìuds o√π elles sont appliqu√©es.  Avec la r√©plication ma√Ætre-ma√Ætre, des modifications sont apport√©es √† plusieurs n≈ìuds √† la fois.  Dans ce cas, chaque n≈ìud modifie lui-m√™me ses donn√©es et applique √† lui-m√™me les modifications apport√©es aux autres n≈ìuds. </li><li>  <b>Mode de fonctionnement: asynchrone ou synchrone</b> .  La r√©plication synchrone implique que les donn√©es ne seront pas valid√©es et la r√©plication ne sera pas confirm√©e √† l'utilisateur jusqu'√† ce que les modifications soient propag√©es √† travers au moins le nombre minimum de n≈ìuds de cluster.  Dans la r√©plication asynchrone, la validation d'une transaction (la validation) et l'interaction avec un utilisateur sont deux processus ind√©pendants.  Pour valider les donn√©es, il est seulement n√©cessaire qu'elles tombent dans le journal local, et alors seulement ces modifications sont transmises d'une mani√®re ou d'une autre aux autres n≈ìuds.  De toute √©vidence, la r√©plication asynchrone a un certain nombre d'effets secondaires √† cause de cela. </li></ul><br><h2>  Comment fonctionne la r√©plication dans Tarantool? </h2><br>  La r√©plication dans Tarantool a plusieurs fonctionnalit√©s: <br><br><ul><li>  Il est construit √† partir de briques de base, avec lesquelles vous pouvez cr√©er un cluster de n'importe quelle topologie.  Chacun de ces √©l√©ments de configuration de base est unidirectionnel, c'est-√†-dire que vous avez toujours ma√Ætre et esclave.  Master effectue certaines actions et g√©n√®re un journal des op√©rations, qui est utilis√© sur la r√©plique. </li><li>  La r√©plication de Tarantool est asynchrone.  Autrement dit, le syst√®me vous confirme la validation, quel que soit le nombre de r√©pliques que cette transaction a vues, combien elle a √©t√© appliqu√©e √† elle-m√™me et si elle s'est av√©r√©e √™tre effectu√©e du tout. </li><li>  Une autre propri√©t√© de r√©plication dans Tarantool est qu'il est bas√© sur des lignes.  Tarantool tient un journal des op√©rations (WAL).  L'op√©ration y arrive ligne par ligne, c'est-√†-dire que lorsqu'un certain tapla de l'espace change, cette op√©ration est √©crite dans le journal comme une ligne.  Apr√®s cela, le processus d'arri√®re-plan lit cette ligne dans le journal et l'envoie √† la r√©plique.  Combien de r√©pliques le ma√Ætre poss√®de, autant de processus d'arri√®re-plan.  En d'autres termes, chaque processus de r√©plication vers diff√©rents n≈ìuds du cluster est ex√©cut√© de mani√®re asynchrone par rapport aux autres. </li><li>  Chaque n≈ìud de cluster a son propre identifiant unique, qui est g√©n√©r√© lors de la cr√©ation du n≈ìud.  De plus, le n≈ìud poss√®de √©galement un identifiant dans le cluster (num√©ro de membre).  Il s'agit d'une constante num√©rique affect√©e √† une r√©plique lorsqu'elle est connect√©e √† un cluster, et elle reste avec la r√©plique tout au long de sa vie dans le cluster. </li></ul><br>  En raison de l'asynchronie, les donn√©es sont livr√©es √† des r√©pliques retard√©es.  Autrement dit, vous avez apport√© des modifications, le syst√®me a confirm√© la validation, l'op√©ration a d√©j√† √©t√© appliqu√©e sur le ma√Ætre, mais sur les r√©pliques, elle sera appliqu√©e avec un certain retard, qui est d√©termin√© par la vitesse √† laquelle le processus de r√©plication en arri√®re-plan lit l'op√©ration, l'envoie √† la r√©plique et celle-ci s'applique . <br><br>  Pour cette raison, il y a une chance que les donn√©es ne soient pas synchronis√©es.  Supposons que nous ayons plusieurs ma√Ætres qui modifient les donn√©es interconnect√©es.  Il peut s'av√©rer que les op√©rations que vous utilisez ne sont pas commutatives et se r√©f√®rent aux m√™mes donn√©es, alors deux membres de cluster diff√©rents auront des versions diff√©rentes des donn√©es. <br><br>  <b>Si la r√©plication dans Tarantool est ma√Ætre-esclave unidirectionnel, alors comment faire ma√Ætre-ma√Ætre?</b>  Tr√®s simple: cr√©ez un autre canal de r√©plication mais dans l'autre sens.  Vous devez comprendre que dans Tarantool, la r√©plication ma√Ætre-ma√Ætre n'est qu'une combinaison de deux flux de donn√©es ind√©pendants l'un de l'autre. <br><br>  En utilisant le m√™me principe, nous pouvons connecter le troisi√®me ma√Ætre et ainsi cr√©er un r√©seau maill√© complet dans lequel chaque r√©plique est ma√Ætre et esclave pour toutes les autres r√©pliques. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nx/z5/b-/nxz5b-f9rzqtmhi7ga4fhq8pdq8.png" width="500"></div><br>  Veuillez noter que non seulement les op√©rations lanc√©es localement sur ce ma√Ætre sont r√©pliqu√©es, mais √©galement celles qu'il a re√ßues en externe via des protocoles de r√©plication.  Dans ce cas, les modifications cr√©√©es sur la r√©plique n ¬∞ 1 viendront √† la r√©plique n ¬∞ 3 deux fois: directement et via la r√©plique n ¬∞ 2. Cette propri√©t√© nous permet de cr√©er des topologies plus complexes sans utiliser un maillage complet.  Disons celui-ci. <br><br><img src="https://habrastorage.org/webt/k3/wy/r4/k3wyr4imeqfncmfar65mohmcj24.png"><br><br>  Les trois ma√Ætres, qui constituent ensemble le noyau maill√© complet du cluster, ont une r√©plique individuelle attach√©e.  √âtant donn√© que le proxy de journaux est effectu√© sur chacun des ma√Ætres, les trois esclaves ¬´propres¬ª contiendront toutes les op√©rations qui ont √©t√© effectu√©es sur l'un des n≈ìuds du cluster. <br><br>  Cette configuration peut √™tre utilis√©e pour une vari√©t√© de t√¢ches.  Vous ne pouvez pas cr√©er de liens redondants entre tous les n≈ìuds du cluster, et si des r√©pliques sont plac√©es √† proximit√©, elles auront une copie exacte du ma√Ætre avec un d√©lai minimal.  Et tout cela se fait √† l'aide de l'√©l√©ment de r√©plication ma√Ætre-esclave de base. <br><br><h2>  √âtiquetage des op√©rations de cluster </h2><br>  La question se pose: <b>si les op√©rations sont mandat√©es entre tous les membres du cluster et arrivent √† chaque r√©plique plusieurs fois, comment pouvons-nous comprendre quelle op√©ration doit √™tre effectu√©e et laquelle ne doit pas l'√™tre?</b>  Cela n√©cessite un m√©canisme de filtrage.  Chaque op√©ration lue dans le journal se voit attribuer deux attributs: <br><br><ul><li>  L'identifiant du serveur sur lequel cette op√©ration a √©t√© lanc√©e. </li><li>  Num√©ro de s√©quence de l'op√©ration sur le serveur, lsn, qui est son initiateur.  Chaque serveur, lors d'une op√©ration, attribue un nombre croissant √† chaque ligne de journal re√ßue: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ... Ainsi, si nous savons que pour un serveur avec un certain identifiant, nous avons appliqu√© l'op√©ration avec lsn 10, puis les op√©rations avec lsn 9, 8, 7, 10 qui sont pass√©es par d'autres canaux de r√©plication ne sont pas n√©cessaires.  Au lieu de cela, nous appliquons les √©l√©ments suivants: 11, 12, etc. </li></ul><br><h2>  Statut de la r√©plique </h2><br>  <b>Et comment Tarantool stocke-t-il les informations sur les op√©rations qu'il a d√©j√† appliqu√©es?</b>  Pour ce faire, il existe une horloge Vclock - c'est le vecteur du dernier lsn appliqu√© √† chaque n≈ìud du cluster. <br><br> <code>[lsn <sub>1</sub> , lsn <sub>2</sub> , lsn <sub>n</sub> ]</code> <br> <br>  o√π <code>lsn <sub>i</sub></code> est le num√©ro de la derni√®re op√©ration connue du serveur avec l'identifiant i. <br><br>  Vclock peut √©galement √™tre appel√© un certain instantan√© de l'ensemble de l'√©tat du cluster connu de cette r√©plique.  Connaissant l'ID serveur de l'op√©ration arriv√©e, nous isolons le composant de la Vclock locale dont nous avons besoin, comparons le lsn re√ßu avec l'op√©ration lsn et d√©cidons s'il faut utiliser cette op√©ration.  Par cons√©quent, les op√©rations lanc√©es par un ma√Ætre sp√©cifique seront envoy√©es et appliqu√©es s√©quentiellement.  Dans le m√™me temps, les workflows cr√©√©s sur diff√©rents ma√Ætres peuvent √™tre m√©lang√©s les uns aux autres en raison de la r√©plication asynchrone. <br><br><h2>  Cr√©ation de cluster </h2><br>  Supposons que nous ayons un cluster compos√© de deux √©l√©ments ma√Ætre et esclave, et que nous voulons y connecter une troisi√®me instance.  Il a un UUID unique, mais il n'y a pas encore d'identifiant de cluster.  Si Tarantool n'a pas encore √©t√© initialis√©, veut rejoindre le cluster, il doit envoyer une op√©ration JOIN √† l'un des ma√Ætres qui peut l'ex√©cuter, c'est-√†-dire qu'il est en mode lecture-√©criture.  En r√©ponse √† JOIN, le ma√Ætre envoie son instantan√© local √† la r√©plique de connexion.  La r√©plique le roule √† la maison, alors qu'il n'a toujours pas d'identifiant.  Maintenant, la r√©plique avec un l√©ger d√©calage est synchronis√©e avec le cluster.  Apr√®s cela, le ma√Ætre sur lequel le JOIN a √©t√© ex√©cut√© attribue un identifiant √† cette r√©plique, qui est enregistr√© et envoy√© √† la r√©plique.  Lorsqu'un identifiant est attribu√© √† une r√©plique, il devient un n≈ìud √† part enti√®re et peut ensuite lancer la r√©plication des journaux de son c√¥t√©. <br><br>  Les lignes du journal sont envoy√©es √† partir de l'√©tat de cette r√©plique au moment de la demande du journal de r√©plication au ma√Ætre, c'est-√†-dire √† partir de la vclock qu'il a re√ßue pendant le processus JOIN ou de l'endroit o√π la r√©plique s'est arr√™t√©e plus t√¥t.  Si le r√©plica est tomb√© pour une raison quelconque, la prochaine fois qu'il se connecte au cluster, il n'effectue plus JOIN, car il poss√®de d√©j√† un instantan√© local.  Elle demande juste toutes les op√©rations qui ont eu lieu pendant son absence dans le cluster. <br><br><h2>  Enregistrer une r√©plique dans un cluster </h2><br>  Pour stocker l'√©tat de la structure du cluster, un espace sp√©cial est utilis√© - cluster.  Il contient les identifiants de serveur du cluster, leurs num√©ros de s√©rie et identifiants uniques. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/af/0f/hr/af0fhra2ln0s2xcq-qsmeim2xtc.png" width="500"></div><br><br> <code>[1, 'c35b285c-c5b1-4bbe-83b1-b825eb594aa4'] <br> [2, '37b12cb7-d324-4d75-b428-cde92c18e708'] <br> [3, 'b72b1aa6-42a0-4d73-a611-900e44cdd465']</code> <br> <br>  Il n'est pas n√©cessaire que les identifiants fonctionnent dans l'ordre, car les n≈ìuds peuvent √™tre supprim√©s et ajout√©s. <br><br>  Voici le premier √©cueil.  En r√®gle g√©n√©rale, les clusters ne sont pas collect√©s par un n≈ìud: vous ex√©cutez une certaine application et elle d√©ploie l'ensemble du cluster √† la fois.  Mais la r√©plication dans Tarantool est asynchrone.  Que se passe-t-il si deux ma√Ætres connectent simultan√©ment de nouveaux n≈ìuds et leur attribuent des identifiants identiques?  Il y aura un conflit. <br><br>  Voici un exemple de jointure incorrecte et correcte: <br><br><img src="https://habrastorage.org/webt/o2/9_/bc/o29_bcjs3dhyllneqlgaczljxys.png"><br><br>  Nous avons deux ma√Ætres et deux r√©pliques qui souhaitent se connecter.  Ils font des JOIN sur diff√©rents ma√Ætres.  Supposons que les r√©pliques obtiennent les m√™mes identifiants.  Ensuite, la r√©plication entre les ma√Ætres et ceux qui parviennent √† r√©pliquer leurs journaux s'effondrera, le cluster s'effondrera. <br><br>  Pour √©viter que cela ne se produise, vous devez √† tout moment lancer des r√©pliques strictement sur un seul ma√Ætre.  √Ä cette fin, Tarantool a introduit un tel concept en tant que leader d'initialisation et a impl√©ment√© un algorithme pour choisir ce leader.  Une r√©plique qui souhaite se connecter au cluster √©tablit d'abord une connexion avec tous les ma√Ætres connus de la configuration transf√©r√©e.  Ensuite, la r√©plique s√©lectionne ceux qui ont d√©j√† √©t√© lanc√©s (lors du d√©ploiement du cluster, tous les n≈ìuds ne parviennent pas √† gagner de l'argent).  Et parmi eux, les masters disponibles pour l'enregistrement sont s√©lectionn√©s.  Dans Tarantool, il y a lecture-√©criture et lecture seule, nous ne pouvons pas nous inscrire sur le n≈ìud en lecture seule.  Apr√®s cela, dans la liste des n≈ìuds filtr√©s, nous s√©lectionnons celui qui a l'UUID le plus bas. <br><br>  Si nous utilisons la m√™me configuration et la m√™me liste de serveurs sur des instances non initialis√©es se connectant au cluster, ils s√©lectionneront le m√™me ma√Ætre, ce qui signifie que JOIN r√©ussira tr√®s probablement. <br><br>  De l√†, nous d√©rivons une r√®gle: lors de la connexion de r√©pliques √† un cluster en parall√®le, toutes ces r√©pliques doivent avoir la m√™me configuration de r√©plication.  Si nous omettons quelque chose quelque part, il est possible que des instances avec une configuration diff√©rente soient lanc√©es sur diff√©rents ma√Ætres et que le cluster ne puisse pas se r√©unir. <br><br>  Supposons que nous nous soyons tromp√©s, ou que l'administrateur ait oubli√© de r√©parer la configuration, ou Ansible s'est cass√©, et le cluster s'est encore effondr√©.  Que peut en t√©moigner?  Tout d'abord, les r√©plicas enfichables ne pourront pas cr√©er leurs instantan√©s locaux: les r√©plicas ne d√©marrent pas et ne signalent pas d'erreurs.  Deuxi√®mement, sur les ma√Ætres dans les journaux, nous verrons des erreurs li√©es aux conflits dans le cluster spatial. <br><br>  Comment r√©soudre cette situation?  C'est simple: <br><br><ul><li>  Tout d'abord, nous devons valider la configuration que nous avons d√©finie pour les r√©plicas de connexion, car si nous ne la r√©parons pas, tout le reste sera inutile. </li><li>  Apr√®s cela, nous √©liminons les conflits dans le cluster et prenons une photo. </li></ul><br>  Vous pouvez maintenant essayer √† nouveau d'initialiser les r√©pliques. <br><br><h2>  R√©solution des conflits </h2><br>  Nous avons donc cr√©√© un cluster et connect√©.  Tous les n≈ìuds fonctionnent en mode abonnement, c'est-√†-dire qu'ils re√ßoivent les modifications g√©n√©r√©es par diff√©rents ma√Ætres.  La r√©plication √©tant asynchrone, des conflits sont possibles.  Lorsque vous modifiez simultan√©ment des donn√©es sur diff√©rents ma√Ætres, diff√©rentes r√©pliques obtiennent diff√©rentes copies des donn√©es, car les op√©rations peuvent √™tre appliqu√©es dans un ordre diff√©rent. <br><br>  Voici un exemple de cluster apr√®s avoir ex√©cut√© JOIN: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-o/2j/k2/-o2jk2hjv2dqndshyqta_blcmo8.png" width="500"></div><br>  Nous avons trois ma√Ætres-esclaves, des journaux sont transmis entre eux, qui sont mandat√©s dans diff√©rentes directions et appliqu√©s aux esclaves.  Les donn√©es d√©synchronis√©es signifient que chaque r√©plique aura son propre historique de changement de vclock, car les flux de diff√©rents ma√Ætres peuvent √™tre m√©lang√©s ensemble.  Mais alors l'ordre des op√©rations sur les instances peut varier.  Si nos op√©rations ne sont pas commutatives, comme l'op√©ration REMPLACER, les donn√©es que nous recevons sur ces r√©pliques seront diff√©rentes. <br><br>  Un petit exemple.  Supposons que nous ayons deux ma√Ætres avec vclock = {0,0}.  Et les deux effectueront deux op√©rations, appel√©es op1,1, op1,2, op2,1, op2,2.  Il s'agit de la deuxi√®me tranche de temps lorsque chacun des ma√Ætres a effectu√© une op√©ration locale: <br><br><img src="https://habrastorage.org/webt/-y/z7/cy/-yz7cyhaozyxkdltf7pptl37oqa.png"><br><br>  Le vert indique une modification du composant vclock correspondant.  Tout d'abord, les deux ma√Ætres modifient leur vclock, puis le second ma√Ætre effectue une autre op√©ration locale et augmente √† nouveau la vclock.  Le premier ma√Ætre re√ßoit l'op√©ration de r√©plication du second ma√Ætre, ceci est indiqu√© par le num√©ro rouge 1 en vclock du premier n≈ìud de cluster. <br><br><img src="https://habrastorage.org/webt/if/j8/8f/ifj88f4rat3litvsyedit09shw0.png"><br><br>  Ensuite, le deuxi√®me ma√Ætre re√ßoit l'op√©ration du premier, et le premier - la deuxi√®me op√©ration du second.  Et √† la fin, le premier ma√Ætre effectue sa derni√®re op√©ration, et le second ma√Ætre la re√ßoit. <br><br><img src="https://habrastorage.org/webt/gh/3z/jo/gh3zjoicvoxqd772_pt1m92wfem.png"><br><br>  Vclock dans le quantum de temps z√©ro, nous avons le m√™me - {0,0}.  Sur le dernier quantum de temps, nous avons aussi le m√™me vclock {2,2}, il semblerait que les donn√©es devraient √™tre les m√™mes.  Mais l'ordre des op√©rations effectu√©es sur chaque ma√Ætre est diff√©rent.  Et s'il s'agit d'une op√©ration REMPLACER avec des valeurs diff√©rentes pour les m√™mes cl√©s?  Ensuite, malgr√© la m√™me vclock √† la fin, nous obtiendrons diff√©rentes versions des donn√©es sur les deux r√©pliques. <br><br>  Nous sommes √©galement en mesure de r√©soudre cette situation. <br><br><ul><li>  <b>Dossiers de partage</b> .  Tout d'abord, nous pouvons effectuer des op√©rations d'√©criture non pas sur des r√©pliques s√©lectionn√©es au hasard, mais en quelque sorte les scinder.  Ils ont juste interrompu les op√©rations d'√©criture sur diff√©rents ma√Ætres et ont finalement obtenu un syst√®me de coh√©rence.  Par exemple, les cl√©s sont pass√©es de 1 √† 10 sur un ma√Ætre et de 11 √† 20 sur un autre - les n≈ìuds √©changeront leurs journaux et obtiendront exactement les m√™mes donn√©es. <br><br>  Le partage implique que nous avons un certain routeur.  Il ne doit pas du tout √™tre une entit√© distincte, le routeur peut faire partie de l'application.  Il peut s'agir d'un fragment qui applique des op√©rations d'√©criture √† lui-m√™me ou les transf√®re √† un autre ma√Ætre d'une mani√®re ou d'une autre.  Mais cela passe de telle mani√®re que les changements dans les valeurs associ√©es vont √† un ma√Ætre particulier: un bloc de valeur est all√© √† un ma√Ætre, un autre bloc √† un autre ma√Ætre.  Dans ce cas, les op√©rations de lecture peuvent √™tre envoy√©es √† n'importe quel n≈ìud du cluster.  Et n'oubliez pas la r√©plication asynchrone: si vous avez enregistr√© sur le m√™me master, vous devrez peut-√™tre √©galement en lire. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/de/cq/wv/decqwvuzuaz-yn6t7fbyq2o2sv4.png" width="500"></div></li><li>  <b>Ordre logique des op√©rations</b> .  Supposons que, selon les conditions du probl√®me, vous pouvez en quelque sorte d√©terminer la priorit√© de l'op√©ration.  Dites, mettez un horodatage, une version ou une autre √©tiquette qui nous permettra de comprendre quelle op√©ration s'est physiquement produite plus t√¥t.  Autrement dit, nous parlons d'une source externe de commande. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/h8/pt/zl/h8ptzlm1ieiugdnjr66ubi9pxwq.png" width="500"></div><br>  Tarantool a un d√©clencheur <code>before_replace</code> qui peut √™tre ex√©cut√© pendant la r√©plication.  Dans ce cas, nous ne sommes pas limit√©s par la n√©cessit√© d'acheminer les demandes, nous pouvons les envoyer o√π nous voulons.  Mais lors de la r√©plication √† l'entr√©e du flux de donn√©es, nous avons un d√©clencheur.  Il lit la ligne envoy√©e, la compare √† la ligne qui est d√©j√† stock√©e et d√©cide laquelle des lignes a une priorit√© plus √©lev√©e.  En d'autres termes, le d√©clencheur ignore la demande de r√©plication ou l'applique, √©ventuellement avec les modifications requises.  Nous appliquons d√©j√† cette approche, mais elle a aussi ses inconv√©nients.  Tout d'abord, vous avez besoin d'une source d'horloge externe.  Supposons qu'un op√©rateur dans un salon de t√©l√©phonie mobile apporte des modifications √† un abonn√©.  Pour de telles op√©rations, vous pouvez utiliser l'heure sur l'ordinateur de l'op√©rateur, car il est peu probable que plusieurs op√©rateurs apportent des modifications √† un m√™me abonn√© en m√™me temps.  Les op√©rations peuvent venir de diff√©rentes mani√®res, mais si chacune d'elles peut √™tre affect√©e √† une certaine version, alors lors du passage par des d√©clencheurs, seuls ceux qui sont pertinents resteront. <br><br>  Deuxi√®me inconv√©nient de la m√©thode: puisque le d√©clencheur est appliqu√© √† chaque delta issu de la r√©plication pour chaque requ√™te, cela cr√©e une charge de calcul suppl√©mentaire.  Mais nous aurons alors une copie coh√©rente des donn√©es √† l'√©chelle du cluster. </li></ul><br><h2>  Sync </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jr/1n/db/jr1ndb23coit6rz1qeblip_tpy0.png" width="500"></div><br>  Notre r√©plication est asynchrone, c'est-√†-dire qu'en ex√©cutant la validation, vous ne savez pas si ces donn√©es se trouvent d√©j√† sur un autre n≈ìud de cluster.  Si vous avez effectu√© un commit sur master, cela vous a √©t√© confirm√© et que master pour une raison quelconque a imm√©diatement cess√© de fonctionner, vous ne pouvez pas √™tre s√ªr que les donn√©es ont √©t√© enregistr√©es ailleurs.  Pour r√©soudre ce probl√®me, le protocole de r√©plication Tarantool a un ACK.  Chaque ma√Ætre a connaissance du dernier ACK provenant de chaque esclave. <br><br>  Qu'est-ce qu'un ACK?  Lorsque l'esclave re√ßoit le delta, qui est marqu√© avec le ma√Ætre lsn et son identifiant, puis en r√©ponse, il envoie un paquet ACK sp√©cial, dans lequel il emballe sa vclock locale apr√®s avoir appliqu√© cette op√©ration.  Voyons comment cela peut fonctionner. <br><br>  Nous avons un ma√Ætre qui a effectu√© 4 op√©rations en lui-m√™me.  Supposons qu'√† un moment donn√©, l'esclave esclave re√ßoive les trois premi√®res lignes et sa vclock augmente √† {3.0}. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oy/iw/y1/oyiwy1eifo7_jfsb9ylvi1wkija.png" width="500"></div><br>  ACK n'est pas encore arriv√©.  Apr√®s avoir re√ßu ces trois lignes, l'esclave envoie le paquet ACK auquel il a cousu sa vclock au moment o√π le paquet a √©t√© envoy√©.  Laissez le ma√Ætre esclave envoyer une autre ligne dans le m√™me intervalle de temps, c'est-√†-dire que la vitesse d'horloge de l'esclave a augment√©.  Sur cette base, le ma√Ætre n ¬∞ 1 sait avec certitude que les trois premi√®res op√©rations qu'il a effectu√©es ont d√©j√† √©t√© appliqu√©es √† cet esclave.  Ces √©tats sont stock√©s pour tous les esclaves avec lesquels le ma√Ætre travaille; ils sont compl√®tement ind√©pendants. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/u1/rx/va/u1rxvazmmssfoizpfecbwf3ceas.png" width="500"></div><br>  Et √† la fin, l'esclave r√©pond avec un quatri√®me paquet ACK.  Apr√®s cela, le ma√Ætre sait que l'esclave est synchronis√© avec lui. <br><br>  Ce m√©canisme peut √™tre utilis√© dans le code d'application.  Lorsque vous validez une op√©ration, vous ne reconnaissez pas imm√©diatement l'utilisateur, mais appelez d'abord une fonction sp√©ciale.  Il attend que l'esclave lsn connu du ma√Ætre soit √©gal au lsn de votre ma√Ætre √† la fin de la validation.  Vous n'avez donc pas besoin d'attendre la synchronisation compl√®te, attendez simplement le moment mentionn√©. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1-/oe/93/1-oe930isjznmsurqj314c2-gue.png" width="500"></div><br>  Supposons que notre premier appel ait chang√© trois lignes et que le deuxi√®me appel en ait chang√© une.  Apr√®s le premier appel, vous voulez vous assurer que les donn√©es sont synchronis√©es.  L'√©tat indiqu√© ci-dessus signifie d√©j√† que le premier appel a √©t√© synchronis√© sur au moins un esclave. <br><br>  O√π chercher exactement des informations √† ce sujet, nous consid√©rerons dans la section suivante. <br><br><h2>  Suivi </h2><br>  Lorsque la r√©plication est synchrone, la surveillance est tr√®s simple: si elle s'effondre, des erreurs sont √©mises pour vos op√©rations.  Et si la r√©plication est asynchrone, la situation devient confuse.  Le Ma√Ætre vous r√©pond que tout va bien, cela fonctionne, accept√©, √©crit.  Mais en m√™me temps, toutes les r√©pliques sont mortes, les donn√©es n'ont pas de redondance et si vous perdez le ma√Ætre, vous perdrez les donn√©es.  Par cons√©quent, je veux vraiment surveiller le cluster, comprendre ce qui se passe avec la r√©plication asynchrone, o√π se trouvent les r√©pliques, dans quel √©tat elles se trouvent. <br><br>  Pour la surveillance de base, Tarantool poss√®de une entit√© box.info.  Cela vaut la peine de l'appeler dans la console, car vous verrez des donn√©es int√©ressantes. <br><br><pre> <code class="plaintext hljs">id: 1 uuid: c35b285c-c5b1-4bbe-83b1-b825eb594aa4 lsn : 5 vclock : {2: 1, 1: 5} replication : 1: id: 1 uuid : c35b285c -c5b1 -4 bbe -83b1 - b825eb594aa4 lsn : 5 2: id: 2 uuid : 37 b12cb7 -d324 -4 d75 -b428 - cde92c18e708 lsn : 1 upstream : status : follow idle : 0.30358312401222 peer : lag: 3.6001205444336 e -05 downstream : vclock : {2: 1, 1: 5}</code> </pre> <br>  La m√©trique la plus importante est l'id <code>id</code> .  Dans ce cas, 1 signifie que le LSN de ce ma√Ætre sera stock√© dans la premi√®re position de tous les vclock.  Une chose tr√®s utile.  Si vous avez un conflit avec JOIN, vous ne pouvez distinguer un ma√Ætre d'un autre que par des identifiants uniques.  En outre, les quantit√©s locales incluent des quantit√©s telles que lsn.  Il s'agit du num√©ro de la derni√®re ligne que ce ma√Ætre a ex√©cut√©e et √©crite dans son journal.  Dans notre exemple, le premier ma√Ætre a effectu√© cinq op√©rations.  Vclock est l'√©tat des op√©rations qu'il sait qu'il s'est appliqu√© √† lui-m√™me.  Et enfin, pour le ma√Ætre num√©ro 2, il a effectu√© l'une de ses op√©rations de r√©plication. <br><br>  Apr√®s les indicateurs de l'√©tat local, vous pouvez voir ce que cette instance sait de l'√©tat de la r√©plication de cluster; pour cela, il y a une section de <code>replication</code> .  Il r√©pertorie tous les n≈ìuds de cluster connus de l'instance, y compris lui-m√™me.  Le premier n≈ìud a l'identifiant 1, id correspond √† l'instance actuelle.  Le deuxi√®me n≈ìud a l'identifiant 2, son lsn 1 correspond au lsn qui est √©crit dans vclock.  Dans ce cas, nous consid√©rons la r√©plication ma√Ætre-ma√Ætre, lorsque le ma√Ætre n ¬∞ 1 est √† la fois le ma√Ætre du deuxi√®me n≈ìud du cluster et son esclave, c'est-√†-dire qu'il le suit. <br><br><ul><li>  L'essence de l' <code>upstream</code> .  L'attribut <code>status follow</code> signifie que le ma√Ætre 1 suit le ma√Ætre 2. Inactif est le temps qui s'est √©coul√© localement depuis la derni√®re interaction avec ce ma√Ætre.  Nous n'envoyons pas de flux en continu, le ma√Ætre n'envoie un delta que lorsque des changements s'y produisent.  Lorsque nous envoyons une sorte d'ACK, nous communiquons √©galement.  De toute √©vidence, si le ralenti devient important (secondes, minutes, heures), alors quelque chose ne va pas. </li><li>  Attribut de <code>lag</code> .  Nous avons parl√© de d√©calage.  En plus de lsn et de <code>server id</code> chaque op√©ration dans le journal est √©galement marqu√©e d'un horodatage - heure locale pendant laquelle cette op√©ration a √©t√© enregistr√©e en vclock sur le ma√Ætre qui l'a effectu√©e.  Dans le m√™me temps, Slave compare son horodatage local avec l'horodatage du delta qu'il a re√ßu.  Le dernier horodatage actuel re√ßu pour la derni√®re ligne, l'esclave s'affiche en surveillance. </li><li>  Attribut en <code>downstream</code> .  Il montre ce que le ma√Ætre sait de son esclave particulier.  C'est l'ACK que l'esclave lui envoie.  L' <code>downstream</code> pr√©sent√© ci-dessus signifie que la derni√®re fois que son esclave, alias ma√Ætre au num√©ro 2, lui a envoy√© sa vclock, qui √©tait de 5,1.  Ce ma√Ætre sait que ses cinq lignes, qu'il a termin√©es chez lui, sont parties pour un autre n≈ìud. </li></ul><br><h2>  Perte XLOG </h2><br>  Consid√©rez la situation avec la chute du ma√Ætre. <br><br><pre> <code class="plaintext hljs">lsn : 0 id: 3 replication : 1: &lt;...&gt; upstream : status: disconnected peer : lag: 3.9100646972656 e -05 idle: 1602.836148153 message: connect, called on fd 13, aka [::1]:37960 2: &lt;...&gt; upstream : status : follow idle : 0.65611373598222 peer : lag: 1.9550323486328 e -05 3: &lt;...&gt; vclock : {2: 2, 1: 5}</code> </pre> <br>  Tout d'abord, le statut va changer.  <code>Lag</code> ne change pas car la ligne que nous avons appliqu√©e reste la m√™me, nous n'en avons pas obtenu de nouvelles.  Dans le m√™me temps, le <code>idle</code> augmente, dans ce cas, il est d√©j√† √©gal √† 1602 secondes, tant de temps ma√Ætre √©tait mort.  Et nous voyons un message d'erreur: il n'y a pas de connexion r√©seau. <br><br>  Que faire dans une situation similaire?  Nous d√©couvrons ce qui s'est pass√© avec notre ma√Ætre, attirons l'administrateur, red√©marrez le serveur, √©levons le n≈ìud.  Une r√©plication r√©p√©t√©e est effectu√©e, et lorsque le ma√Ætre p√©n√®tre dans le syst√®me, nous nous connectons √† celui-ci, nous nous abonnons √† son XLOG, les obtenons pour nous-m√™mes et le cluster se stabilise. <br><br>  Mais il y a un petit probl√®me.  Imaginez que nous avions un esclave qui, pour une raison quelconque, s'est √©teint et a √©t√© absent pendant longtemps.  Pendant ce temps, le ma√Ætre qui l'a servi a supprim√© le XLOG.  Par exemple, le disque est plein, le garbage collector a collect√© les journaux.  Comment un esclave de retour peut-il continuer?  Pas question.  Parce que les journaux qu'il doit appliquer pour se synchroniser avec le cluster ont disparu et qu'il n'y a nulle part o√π les prendre.  Dans ce cas, nous verrons une erreur int√©ressante: l'√©tat n'est plus <code>disconnected</code> , mais <code>stopped</code> .  Et un message sp√©cifique: il n'y a pas de fichier journal correspondant √† un tel lsn. <br><br><pre> <code class="plaintext hljs">id: 3 replication : 1: &lt;...&gt; upstream : peer : status: stopped lag : 0.0001683235168457 idle : 9.4331328970147 message: 'Missing .xlog file between LSN 7 1: 5, 2: 2 and 8 1: 6, 2: 2' 2: &lt;...&gt; 3: &lt;...&gt; vclock : {2: 2, 1: 5}</code> </pre> <br>  En fait, la situation n'est pas toujours fatale.  Supposons que nous ayons plus de deux ma√Ætres, et sur certains d'entre eux, ces journaux sont toujours conserv√©s.  Nous les versons √† tous les ma√Ætres √† la fois et ne les stockons pas sur un seul.  Ensuite, il s'av√®re que cette r√©plique, se connectant √† tous les ma√Ætres qu'elle conna√Æt, trouvera sur certains d'entre eux les journaux dont elle a besoin.  Elle effectuera toutes ces op√©rations √† la maison, sa vitesse d'horloge augmentera et elle atteindra l'√©tat actuel du cluster.  Apr√®s cela, vous pouvez essayer de vous reconnecter. <br><br>  S'il n'y a aucun journal, nous ne pouvons pas continuer la r√©plique.  Il ne reste plus qu'√† le r√©initialiser.  N'oubliez pas son identifiant unique, vous pouvez l'√©crire sur une feuille de papier ou dans un fichier.  Ensuite, nous nettoyons la r√©plique localement: supprimez ses images, ses journaux, etc.  Apr√®s cela, reconnectez la r√©plique avec le m√™me UUID que celui qu'elle avait. <br><br>  Supprimez le cluster ou r√©utilisez l'UUID pour la nouvelle r√©plique: <code>box.cfg{instance_uuid =  uuid}</code> . <br><br>   ,   .   UUID    space cluster,    .       ,    .    UUID,  master,     JOIN,     ,       UUID,   ,    . <br><br>   ,   UUID ,     space cluster      ,    .       .  ,  ,          . <br><br><h2>  </h2><br> ,  -           .   ,        .    ,   ,      . <br><br>  Tarantool   . <br><br> <code>replication_connect_quorum: 2 <br> replication_connect_timeout: 30 <br> replication_sync_lag: 0.1</code> <br> <br> ,   , ,            ,   ,  ,  master'     0,1 .    30 .     ,   .   0,1 .  ,      . <br><br><h2> Keep alive </h2><br>  ,      ip tables drop.  ,    -  30   30 ,    ,      .     ,   keep alive-. <br><br>  keep alive-  : <code>box.cfg.replication_timeout</code> . <br><br>      master'      ,    keep alive-, ,   .    4  master  slave   keep alive-   ,         .             master'. <br><br><h2>    </h2><br>  ,      .    6 ,      5 .     10 ,    9 .     . <br><br>   ,    ,     .       ,         master',   .  -          .   . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pp/wv/qo/ppwvqoys4enyzstnxbfp0mtkug4.png" width="500"></div><br>     6 ,       3.     ,    .  ,     5 ,      3 . <br><br><h2>     </h2><br>   ,       : <br><br><ul><li>  . </li><li>  ,       space cluster,        .          . </li></ul><br>   ,    Telegram-,  .          ,     GitHub,   . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439514/">https://habr.com/ru/post/fr439514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439504/index.html">Votre √©quipe a-t-elle besoin d'un Data Engineer?</a></li>
<li><a href="../fr439506/index.html">9 alternatives √† une mauvaise √©quipe (mod√®le de conception)</a></li>
<li><a href="../fr439508/index.html">Mitap sur le d√©veloppement Open Source √† Moscou</a></li>
<li><a href="../fr439510/index.html">Syst√®me de contr√¥le distribu√© hautement charg√© d'une centrale nucl√©aire moderne</a></li>
<li><a href="../fr439512/index.html">L'√¢ge des dinosaures ou la r√©assurance l√©galement v√©rifi√©e?</a></li>
<li><a href="../fr439516/index.html">00110001 00110100 00101110 00110000 00110010</a></li>
<li><a href="../fr439518/index.html">Programme de formation au d√©veloppement Web mis √† jour par GeekUniversity: plus de pratiques et de cas de club de livraison</a></li>
<li><a href="../fr439520/index.html">Proof-of-Stake: nouveau business model en 2019?</a></li>
<li><a href="../fr439522/index.html">Reliure DNS en 2k19, ou comment vraiment transpirer en visitant un site porno</a></li>
<li><a href="../fr439524/index.html">Fortnite est l'avenir, mais pour des raisons plut√¥t inattendues</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
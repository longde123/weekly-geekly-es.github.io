<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö∂üèΩ üï§ üç∫ Buch ‚ÄûSite Reliability Engineering. Zuverl√§ssigkeit und Zuverl√§ssigkeit wie bei Google ¬ª üê∂ üíì üíç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Seit fast 20 Jahren bietet Google unvorstellbar komplexe und umfangreiche Systeme an, die auf Benutzeranfragen reagieren. Die Google-Suchmaschine find...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Buch ‚ÄûSite Reliability Engineering. Zuverl√§ssigkeit und Zuverl√§ssigkeit wie bei Google ¬ª</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/420139/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/dx/hl/8t/dxhl8tgecl0xwqtx3pnxztosrom.jpeg" align="left" alt="Bild"></a>  Seit fast 20 Jahren bietet Google unvorstellbar komplexe und umfangreiche Systeme an, die auf Benutzeranfragen reagieren.  Die Google-Suchmaschine findet die Antwort auf alle Fragen in Sekundenbruchteilen, Google Maps mit der h√∂chsten Genauigkeit spiegeln die terrestrische Landschaft wider, und Google Mail ist im 365/24/7-Modus verf√ºgbar und im Wesentlichen der erste √∂ffentliche Cloud-Speicher.  Sind diese Systeme fehlerfrei?  Nein, sie versagen auch, brechen zusammen und werden veraltet, wie jedes Ger√§t.  Wir bemerken es einfach nicht.  Die Sache ist, dass Google seit mehr als zehn Jahren die einzigartige Site Reliability Engineering-Technologie entwickelt, die einen unterbrechungsfreien Betrieb und die fortschreitende Entwicklung von Softwaresystemen jeder Komplexit√§t gew√§hrleistet.  Dieses Buch ist ein Erfahrungsschatz, den Google √ºber viele Jahre gesammelt hat, die gemeinsame Arbeit vieler herausragender Spezialisten und eine unverzichtbare Ressource f√ºr jeden Ingenieur, der Produkte mit h√∂chster Qualit√§t und Effizienz entwickeln und warten m√∂chte. <br><a name="habracut"></a><br><h3>  Googles SRE in Bezug auf SRE </h3><br>  Google-Rechenzentren (Rechenzentren) unterscheiden sich erheblich von herk√∂mmlichen Rechenzentren und kleinen Server- "Farmen".  Diese Unterschiede bringen sowohl zus√§tzliche Probleme als auch zus√§tzliche M√∂glichkeiten mit sich.  In diesem Kapitel werden die Herausforderungen und Chancen f√ºr Google-Rechenzentren erl√§utert und die Terminologie vorgestellt, die im gesamten Buch verwendet wird. <br><br>  <b>Ausr√ºstung</b> <br><br>  Die meisten Computerressourcen von Google befinden sich in vom Unternehmen entworfenen Rechenzentren mit eigenem Stromversorgungssystem, K√ºhlsystem, internem Netzwerk und Computerausr√ºstung [Barroso et al., 2013].  Im Gegensatz zu typischen Rechenzentren, die Anbieter ihren Kunden zur Verf√ºgung stellen, sind alle Google-Rechenzentren mit demselben ausgestattet1.  Um Verwechslungen zwischen Serverhardware und Serversoftware zu vermeiden, verwenden wir in diesem Buch die folgende Terminologie: <br><br><ul><li>  <i>Maschine (Computer)</i> - eine Ger√§teeinheit (oder m√∂glicherweise eine virtuelle Maschine); </li><li>  <i>Server</i> - eine Softwareeinheit, die einen Dienst implementiert. </li></ul><br>  Jeder Server kann auf Computern gestartet werden, daher weisen wir bestimmten Serverprogrammen keine bestimmten Computer zu.  Zum Beispiel haben wir keinen bestimmten Computer, auf dem der Mailserver ausgef√ºhrt wird.  Stattdessen werden Ressourcen von unserem Borg-Cluster-Management-System zugewiesen. <br><br>  Wir verstehen, dass eine solche Verwendung des Begriffs ‚ÄûServer‚Äú nicht Standard ist.  Es ist √ºblicher, zwei Konzepte gleichzeitig zu bezeichnen: ein Programm, das Netzwerkverbindungen bedient, und gleichzeitig einen Computer, auf dem solche Programme ausgef√ºhrt werden. Wenn wir jedoch √ºber die Rechenleistung von Google sprechen, ist der Unterschied zwischen beiden erheblich.  Sobald Sie sich an unsere Interpretation des Wortes "Server" gew√∂hnt haben, wird Ihnen klarer, warum es wichtig ist, diese spezielle Terminologie nicht nur direkt bei Google, sondern in diesem Buch zu verwenden. <br><br>  In Abb.  2.1 demonstrierte die Konfiguration des Google-Rechenzentrums. <br><br><ul><li>  Dutzende Autos stehen auf Gestellen. </li><li>  Gestelle stehen in Reihen. </li><li>  Eine oder mehrere Zeilen bilden einen Cluster. </li><li>  Normalerweise befinden sich im Geb√§ude eines Rechenzentrums (DPC) oder Rechenzentrums mehrere Cluster. </li><li>  Der Campus besteht aus mehreren nahe beieinander liegenden Rechenzentrumsgeb√§uden. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-3/no/2i/-3no2ios8vkdcddiea5ynqaaz1s.png" alt="Bild"></div><br>  In jedem Rechenzentrum sollten alle Maschinen in der Lage sein, effektiv miteinander zu kommunizieren. Daher haben wir einen sehr schnellen virtuellen Switch (Switch) mit Zehntausenden von Ports erstellt.  Dies war m√∂glich, indem Hunderte von von Google entwickelten Switches zu einer ‚ÄûFabrik‚Äú verbunden wurden, die auf der Topologie des Clos-Netzwerks [Clos, 1953] namens Jupiter [Singh et al., 2015] basiert.  Bei maximaler Konfiguration unterst√ºtzt Jupiter einen Durchsatz von 1,3 Pb / s zwischen Servern. <br><br>  Rechenzentren sind √ºber unser globales B4-Backbone-Netzwerk miteinander verbunden [Jain et al., 2013].  B4 verf√ºgt √ºber eine per Software konfigurierbare Netzwerkarchitektur und verwendet das OpenFlow Open Communication-Protokoll.  B4 bietet eine breite Bandbreite f√ºr eine begrenzte Anzahl von Systemen und verwendet eine flexible Kanalbreitensteuerung, um den Durchschnittswert zu maximieren [Kumar et al., 2015]. <br><br><h3>  Systemsoftware, die Ger√§te ‚Äûorganisiert‚Äú </h3><br>  Die Software, die die Verwaltung und Verwaltung unserer Ger√§te √ºbernimmt, muss in der Lage sein, gro√üe Systeme zu handhaben.  Hardwarefehler sind eines der Hauptprobleme, die mit Hilfe von Software gel√∂st werden.  Angesichts der gro√üen Anzahl von Hardwarekomponenten in einem Cluster treten diese h√§ufig auf.  In jedem Cluster fallen normalerweise Tausende von Computern pro Jahr aus und Tausende von Festplatten fallen aus.  Wenn Sie diese Zahl mit der Anzahl der weltweit operierenden Cluster multiplizieren, ist das Ergebnis erstaunlich.  Daher m√∂chten wir Benutzer von solchen Problemen isolieren, und die an unseren Diensten beteiligten Teams m√∂chten auch nicht durch Hardwareprobleme abgelenkt werden.  Jeder Rechenzentrumscampus verf√ºgt √ºber Teams, die f√ºr die Unterst√ºtzung der Ausr√ºstung und Infrastruktur des Rechenzentrums verantwortlich sind. <br><br><h3>  Maschinenverwaltung </h3><br>  Borg (Abbildung 2.2) ist ein verteiltes Cluster-Management-System [Verma et al., 2015], √§hnlich wie Apache Mesos.  Borg verwaltet Jobs auf Clusterebene. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tu/bv/iu/tubviu0qs-kyfob6r1kgodbttye.png" alt="Bild"></div>  Borg ist f√ºr das Starten von Benutzerjobs verantwortlich.  Diese Aufgaben k√∂nnen entweder st√§ndig laufende Dienste oder Batch-Prozesse wie MapReduce sein [Dean und Ghemawat, 2004].  Sie k√∂nnen aus mehreren (manchmal Tausenden) identischen Aufgaben (Aufgaben) bestehen - sowohl aus Gr√ºnden der Zuverl√§ssigkeit als auch weil ein Prozess in der Regel nicht den gesamten Clusterverkehr verarbeiten kann.  Wenn Borg die Aufgabe startet, findet er die Maschinen, um seine Aufgaben auszuf√ºhren, und befiehlt ihnen, das Serverprogramm zu starten.  Borg √ºberwacht dann den Status dieser Aufgaben.  Wenn die Aufgabe nicht ordnungsgem√§√ü funktioniert, wird sie zerst√∂rt und m√∂glicherweise auf einem anderen Computer neu gestartet. <br><br>  Da Aufgaben frei auf Maschinen verteilt sind, k√∂nnen wir keine IP-Adressen und Portnummern verwenden, um darauf zuzugreifen.  Dieses Problem wird durch eine zus√§tzliche Abstraktionsebene gel√∂st: Beim Starten einer Aufgabe weist Borg der Aufgabe mithilfe des Borg-Namensdienstes (BNS) einen Namen f√ºr die Aufgabe und eine Nummer (Index) zu.  Anstatt die IP-Adresse und die Portnummer zu verwenden, verkn√ºpfen andere Prozesse Borg-Tasks anhand ihres BNS-Namens, der dann den BNS in IP-Adresse und Portnummer konvertiert.  Beispielsweise kann der BNS-Pfad eine Zeichenfolge wie / bns / &lt;Cluster&gt; / &lt;Benutzer&gt; / &lt;Aufgabenname&gt; / &lt;Aufgabennummer&gt; sein, die dann im Format &lt;IP-Adresse&gt;: &lt;Port&gt; √ºbersetzt wird (es ist √ºblich, in Netzwerken "erlaubt" zu sagen) . <br><br>  Borg ist auch f√ºr die Zuweisung von Ressourcen f√ºr Aufgaben verantwortlich.  Jede Aufgabe sollte angeben, welche Ressourcen erforderlich sind, um sie abzuschlie√üen (z. B. drei Prozessorkerne, 2 GB RAM).  Mithilfe der Anforderungsliste f√ºr alle Aufgaben kann Borg Aufgaben unter Ber√ºcksichtigung von Fehlertoleranzaspekten optimal auf Maschinen verteilen (z. B. f√ºhrt Borg nicht alle Aufgaben einer Aufgabe auf demselben Rack aus, da der Wechsel dieses Racks im Fehlerfall ein kritischer Punkt ist.) Aufgaben). <br><br>  Wenn eine Aufgabe versucht, mehr Ressourcen als angefordert abzurufen, zerst√∂rt Borg sie und startet dann neu (da es normalerweise vorzuziehen ist, eine Aufgabe zu haben, die manchmal abst√ºrzt und neu startet, als die √ºberhaupt nicht neu gestartet wird). <br><br><h3>  Lagerung </h3><br>  F√ºr einen schnelleren Zugriff auf Daten k√∂nnen Aufgaben die lokale Festplatte von Computern verwenden. Wir haben jedoch mehrere Optionen zum Organisieren des dauerhaften Speichers im Cluster (und sogar lokal gespeicherte Daten werden m√∂glicherweise in den Clusterspeicher verschoben).  Sie k√∂nnen mit Lustre und dem Hadoop Distributed File System (HDFS) verglichen werden - Clustered File Systems mit einer Open Source-Implementierung. <br><br>  Durch die Speicherung k√∂nnen Benutzer einfach und zuverl√§ssig auf Daten zugreifen, die dem Cluster zur Verf√ºgung stehen.  Wie in Abb.  2.3 hat das Repository mehrere Ebenen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/at/yf/7c/atyf7cemd0e2gczkjfgdnltw7zy.png" alt="Bild"></div><br>  1. Die unterste Schicht hei√üt D (von der Festplatte, obwohl Stufe D sowohl herk√∂mmliche Festplatten als auch Flash-Laufwerke verwendet).  D ist ein Dateiserver, der auf praktisch allen Cluster-Computern ausgef√ºhrt wird.  Benutzer, die auf ihre Daten zugreifen m√∂chten, m√∂chten sich jedoch nicht merken, auf welchem ‚Äã‚ÄãComputer sie gespeichert sind. Daher wird hier die n√§chste Schicht verbunden. <br><br>  2. √úber Schicht D befindet sich die Colossus-Schicht, die im Cluster ein Dateisystem erstellt, das die √ºbliche Semantik des Dateisystems sowie Replikation und Verschl√ºsselung bietet.  Colossus ist der Nachfolger von GFS, dem Google File System (Ghemawat et al., 2003). <br><br>  3. Als N√§chstes werden mehrere datenbank√§hnliche Dienste √ºber der Colossus-Ebene erstellt. <br><br><ul><li>  Bigtable [Chang et al., 2006] ist ein nicht relationales (NoSQL) Datenbanksystem, das mit Petabyte-gro√üen Datenbanken arbeiten kann.  Bigtable ist eine d√ºnn verteilte, fehlertolerante, mehrdimensionale, geordnete Datenbank, die nach Zeilen-, Spalten- und Zeitstempelschl√ºsseln indiziert ist.  Jeder Datenbankwert ist ein beliebiges nicht interpretiertes Array von Bytes.  Bigtable unterst√ºtzt auch die Replikation zwischen Rechenzentren. </li><li>  Spanner [Corbett et al., 2012] bietet eine SQL-√§hnliche Oberfl√§che f√ºr Benutzer, die beim Zugriff von √ºberall auf der Welt Datenintegrit√§t und -konsistenz ben√∂tigen. </li><li>  Es stehen mehrere andere Datenbanksysteme zur Verf√ºgung, z. B. Blobstore.  Sie alle haben ihre eigenen St√§rken und Schw√§chen (siehe Kapitel 26). </li></ul><br><h3>  Netzwerk </h3><br>  Google Networking wird auf verschiedene Arten verwaltet.  Wie bereits erw√§hnt, verwenden wir ein per Software konfigurierbares Netzwerk, das auf OpenFlow basiert.  Anstelle von intelligenten Routern verwenden wir nicht so teure dumme Switches in Kombination mit einem zentralen (duplizierten) Controller, der die beste Route im Netzwerk vorberechnet.  Auf diese Weise k√∂nnen Sie eine einfachere Schaltausr√ºstung verwenden und ihn von der zeitaufw√§ndigen Routensuche befreien. <br><br>  Die Netzwerkbandbreite sollte ordnungsgem√§√ü zugewiesen werden.  Da Borg die Rechenressourcen begrenzt, die eine Aufgabe verwenden kann, verwaltet Bandwidth Enforcer (BwE) die verf√ºgbare Bandbreite, um den durchschnittlichen Durchsatz zu maximieren.  Die Bandbreitenoptimierung h√§ngt nicht nur mit den Kosten zusammen: Das zentralisierte Verkehrsmanagement l√∂st eine Reihe von Problemen, die durch eine Kombination aus verteiltem Routing und herk√∂mmlichem Verkehrsmanagement √§u√üerst schwer zu l√∂sen sind (Kumar, 2015). <br><br>  Einige Dienste haben Jobs, die in mehreren Clustern in verschiedenen Teilen der Welt ausgef√ºhrt werden.  Um die Verz√∂gerungszeit global verteilter Systeme zu verringern, m√∂chten wir Benutzer zum n√§chstgelegenen Rechenzentrum mit der daf√ºr geeigneten Kapazit√§t weiterleiten.  Unser Global Software Load Balancer (GSLB) f√ºhrt einen Lastausgleich auf drei Ebenen durch: <br><br><ul><li>  Der geografische Lastausgleich f√ºr DNS-Abfragen (z. B. an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.google.com</a> ) wird in Kapitel 19 beschrieben. </li><li>  Lastausgleich auf der Ebene der Benutzerdienste (z. B. YouTube oder Google Maps); </li><li>  Lastausgleich auf RPC-Ebene (Remote Procedure Call), beschrieben in Kapitel 20. </li></ul><br>  Servicebesitzer geben symbolische Namen f√ºr sie, eine Liste der Server-BNS-Adressen und die an jedem Standort verf√ºgbare Leistung an (normalerweise wird sie in Abfragen pro Sekunde gemessen - Abfragen pro Sekunde, QPS).  Anschlie√üend leitet die GSLB den Verkehr an die angegebenen BNS-Adressen weiter. <br><br><h3>  Andere Systemsoftware </h3><br><br>  Die Rechenzentrums-Software enth√§lt weitere wichtige Komponenten. <br><br>  <b>Sperrdienst</b> <br><br>  Der Chubby Lock Service [Burrows, 2006] bietet eine API, die dem Dateisystem zum Bereitstellen von Sperren √§hnelt.  Chubby behandelt Sperren in allen Rechenzentren.  Es verwendet das Paxos-Protokoll, um asynchron auf den Konsens zuzugreifen (siehe Kapitel 23). <br><br>  Chubby spielt auch eine wichtige Rolle bei der Auswahl eines Assistenten.  Wenn f√ºr einen Dienst f√ºnf Replikate einer Aufgabe bereitgestellt werden, um die Zuverl√§ssigkeit zu erh√∂hen, aber zu einem bestimmten Zeitpunkt nur eines von ihnen die eigentliche Arbeit erledigt, wird Chubby verwendet, um dieses Replikat auszuw√§hlen. <br>  Chubby eignet sich hervorragend f√ºr Daten, die Speicherzuverl√§ssigkeit erfordern.  Aus diesem Grund verwendet BNS Chubby, um das Verh√§ltnis von BNS-Pfaden zu IP-Adresse: Port-Paaren zu speichern. <br><br>  <b>√úberwachung und Alarmierung</b> <br><br>  Wir m√∂chten sicherstellen, dass alle Dienste ordnungsgem√§√ü funktionieren.  Aus diesem Grund starten wir viele Instanzen des Borgmon-√úberwachungsprogramms (siehe Kapitel 10).  Borgmon erh√§lt regelm√§√üig Benchmark-Werte von √ºberwachten Diensten.  Diese Daten k√∂nnen sofort zur Benachrichtigung verwendet oder f√ºr die sp√§tere Verarbeitung und Analyse gespeichert werden, beispielsweise zum Erstellen von Diagrammen.  Eine solche √úberwachung kann f√ºr folgende Zwecke verwendet werden: <br><br><ul><li>  Einrichten von Warnungen f√ºr dringende Probleme; </li><li>  Verhaltensvergleich: Hat das Software-Update den Server beschleunigt? </li><li>  Einsch√§tzung der Art der √Ñnderungen des Ressourcenverbrauchs im Zeitverlauf, die f√ºr die Kapazit√§tsplanung erforderlich sind. </li></ul><br><br><h3>  Unsere Software-Infrastruktur </h3><br>  Die Architektur unserer Software ist so konzipiert, dass die Hardwareressourcen des Systems am effizientesten genutzt werden k√∂nnen.  Unser gesamter Code ist multithreaded, sodass eine Aufgabe problemlos mehrere Kerne verwenden kann.  Zur Unterst√ºtzung von Dashboards, √úberwachung und Debugging enth√§lt jeder Server eine HTTP-Server-Implementierung als Schnittstelle, √ºber die Diagnoseinformationen und Statistiken f√ºr eine bestimmte Aufgabe bereitgestellt werden. <br><br>  Alle Google-Dienste ‚Äûkommunizieren‚Äú √ºber die RPC-Infrastruktur (Remote Procedure Call) namens Stubby.  Es gibt eine Open-Source-Version davon, sie hei√üt gRPC (siehe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">grpc.io</a> ).  Oft wird ein RPC-Aufruf auch f√ºr Routinen im lokalen Programm durchgef√ºhrt.  Auf diese Weise k√∂nnen Sie das Programm an den Aufrufen eines anderen Servers ausrichten, um eine gr√∂√üere Modularit√§t zu erzielen, oder wenn der urspr√ºngliche Servercode w√§chst.  GSLB kann den RPC-Lastausgleich auf die gleiche Weise wie f√ºr externe Dienstschnittstellen durchf√ºhren. <br><br>  Der Server empf√§ngt RPC-Anforderungen vom Frontend und sendet den RPC an das Backend.  Mit herk√∂mmlichen Begriffen wird das Frontend als Client und das Backend als Server bezeichnet. <br>  Die Daten√ºbertragung zum und vom RPC erfolgt √ºber das Serialisierungsprotokoll - die sogenannten Protokollpuffer oder kurz Protobufs.  Dieses Protokoll √§hnelt Apaches Thrift und bietet gegen√ºber XML mehrere Vorteile bei der Serialisierung strukturierter Daten: Es ist einfacher, drei- bis zehnmal kompakter, 20- bis 100-mal schneller und einzigartiger. <br><br><h3>  Unsere Entwicklungsumgebung </h3><br>  Die Geschwindigkeit der Produktentwicklung ist f√ºr Google sehr wichtig, daher haben wir eine spezielle Umgebung geschaffen, die unsere Infrastruktur optimal nutzt [Morgenthaler et al., 2012]. <br><br>  Mit Ausnahme einiger weniger Gruppen, deren Produkte Open Source sind und daher ihre eigenen separaten Repositorys verwenden (z. B. Android und Chrome), arbeiten die Softwareentwickler von Google in einem gemeinsamen Repository [Potvin, Levenberg, 2016].  Dieser Ansatz hat mehrere praktische Anwendungen, die f√ºr unseren Produktionsprozess wichtig sind. <br><br><ul><li>  Wenn ein Ingenieur auf ein Problem in einer Komponente au√üerhalb seines Projekts st√∂√üt, kann er das Problem beheben, die vorgeschlagenen √Ñnderungen (‚Äû√Ñnderungsliste‚Äú - √Ñnderungsliste, CL) zur Pr√ºfung an den Eigent√ºmer senden und dann die im Hauptzweig des Programms vorgenommenen √Ñnderungen implementieren. </li><li>  √Ñnderungen am Quellcode in einem eigenen Projekt eines Ingenieurs m√ºssen ber√ºcksichtigt werden - Durchf√ºhrung eines Audits (√úberpr√ºfung).  Alle Software besteht diese Phase vor der Einf√ºhrung. </li></ul><br>  Wenn die Software zusammengestellt wird, wird die Montageanforderung an spezialisierte Rechenzentrumserver gesendet.  Selbst das Erstellen gro√üer Projekte ist schnell, da Sie mehrere Server f√ºr die parallele Kompilierung verwenden k√∂nnen.  Eine solche Infrastruktur wird auch f√ºr kontinuierliche Tests verwendet.  Jedes Mal, wenn eine neue √Ñnderungsliste (CL) angezeigt wird, werden Tests aller Software ausgef√ºhrt, die direkt oder indirekt von diesen √Ñnderungen betroffen sein k√∂nnen.  Wenn das Framework feststellt, dass die √Ñnderungen den Betrieb anderer Teile des Systems gest√∂rt haben, benachrichtigt es den Eigent√ºmer √ºber diese √Ñnderungen.  Einige Projekte verwenden das Push-on-Green-System (‚ÄûSenden mit Erfolg‚Äú), nach dem die neue Version nach Bestehen der Tests automatisch an den kommerziellen Betrieb gesendet wird. <br><br><h3>  Shakespeare: Servicebeispiel </h3><br>  Betrachten Sie ein Beispiel f√ºr einen hypothetischen Dienst, der mit Google-Technologien interagiert, um zu demonstrieren, wie Google einen Dienst in einer industriellen Umgebung entwickelt.  Angenommen, wir m√∂chten einen Service anbieten, mit dem Sie bestimmen k√∂nnen, in welchen Werken von Shakespeare das von Ihnen erw√§hnte Wort vorkommt. <br><br>  Wir k√∂nnen das System in zwei Teile teilen. <br><br><ul><li>  Eine Stapelverarbeitungskomponente, die alle Shakespeare-Texte liest, einen Index erstellt und in Bigtable schreibt.  Diese Aufgabe (genauer gesagt die Aufgabe) wird einmal oder m√∂glicherweise gelegentlich ausgef√ºhrt (schlie√ülich kann ein neuer Shakespeare-Text erscheinen!). </li><li>  Eine Front-End-Anwendung, die Endbenutzeranforderungen verarbeitet.  Diese Aufgabe wird immer ausgef√ºhrt, da ein Benutzer aus einer beliebigen Zeitzone jederzeit Shakespeares B√ºcher durchsuchen m√∂chte. </li></ul><br>  Die Stapelverarbeitungskomponente ist der MapReduce-Dienst, dessen Arbeit in drei Phasen unterteilt ist. <br><br>  1. In der Mapping-Phase werden Shakespeares Texte gelesen und in separate W√∂rter unterteilt.  Dieser Teil der Arbeit wird schneller erledigt, wenn mehrere Arbeitsprozesse (Aufgaben) parallel gestartet werden. <br><br>  2. In der Shuffle-Phase werden die Eintr√§ge nach W√∂rtern sortiert. <br><br>  3. In der Reduzierungsphase werden Tupel des Formulars (word, list_products) erstellt. <br><br>  Jedes Tupel wird in Bigtable als Zeichenfolge geschrieben, der Schl√ºssel ist das Wort. <br><br><h3>  Lebenszyklus anfordern </h3><br>  In Abb.  2.4 zeigt, wie die Benutzeranforderung bedient wird.  Zun√§chst klickt der Nutzer im Browser auf den Link shakespeare.google.com.  Um die entsprechende IP-Adresse zu erhalten, √ºbersetzt ("l√∂st") das Ger√§t des Benutzers die Adresse mithilfe des DNS-Servers (1).  Die DNS-Abfrage landet schlie√ülich auf dem Google DNS-Server, der mit der GSLB interagiert.  GSLB verfolgt die Verkehrslast aller Front-End-Server nach Region und w√§hlt aus, welche IP-Adresse von welchem ‚Äã‚ÄãServer an den Benutzer zur√ºckgegeben werden soll. <br><br>  Der Browser stellt unter der angegebenen Adresse eine Verbindung zum HTTP-Server her.  Dieser Server (Google Frontend oder GFE genannt) ist ein "Reverse" -Proxy-Server, der sich am anderen Ende der TCP-Verbindung des Clients befindet (2).  GFE sucht nach dem erforderlichen Dienst (z. B. kann es sich um einen Suchdienst, Karten oder - in unserem Fall den Shakespeare-Dienst) handeln.  Durch wiederholten Zugriff auf die GSLB findet der Server einen verf√ºgbaren Shakespeare-Front-End-Server und greift √ºber einen Remote Procedure Call (RPC) darauf zu, wobei eine vom Benutzer empfangene HTTP-Anforderung gesendet wird (3). <br><br>  Der Shakespeare-Server analysiert die HTTP-Anforderung und erstellt einen ‚ÄûProtokollpuffer‚Äú (protobuf), der die zu findenden W√∂rter enth√§lt.  Jetzt sollte der Shakespeare-Front-End-Server den Shakespeare-Back-End-Server kontaktieren: Der erste kontaktiert die GSLB, um die BNS-Adresse einer geeigneten und entladenen Instanz der zweiten zu erhalten (4).  Als n√§chstes kontaktiert der Shakespeare-Backend-Server den Bigtable-Server, um die angeforderten Daten zu empfangen (5). <br><br>  Das Ergebnis wird in den Antwortprotobuf geschrieben und an den Shakespeare-Backend-Server zur√ºckgegeben.  Das Backend √ºbergibt protobuf mit dem Ergebnis des Dienstes an den Shakespeare-Front-End-Server, der ein HTML-Dokument erstellt und es als Antwort an den Benutzer zur√ºckgibt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6b/nd/yo/6bndyo9cfcxu5k5sx4lieg5bfw8.png" alt="Bild"></div><br>  Diese ganze Kette von Ereignissen l√§uft im Handumdrehen ab - in nur wenigen hundert Millisekunden!  Da viele Komponenten beteiligt sind, gibt es viele Stellen, an denen ein potenzieller Fehler auftreten kann.  Insbesondere ein Fehler in der GSLB kann alle Arbeiten desorganisieren und zum Zusammenbruch f√ºhren.   Google,   ,                 (   ),     ,    .   ,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.google.com</a>  ,     . <br><br><h3>     </h3><br>   ,   -    100    (QPS).       ,       3470 QPS,       35 .    ,      37 ,  N + 2. <br><br><ul><li>        ,     36 . </li><li>         , -    35  ‚Äî  ,      . </li></ul><br>          : 1430 QPS    , 290 ‚Äî   , 1400 ‚Äî    350 ‚Äî    .      -   ,     :  ,  ,   .   N + 2   ,  17   , 16 ‚Äî     ‚Äî  .   , ,      ( ),    ‚Äî  N + 2  N + 1.                  :  GSLB    -       ,    20 % ,      .            2‚Äì3 . <br><br>  -      Bigtable,       .  -     Bigtable,   ,      ,    Bigtable   .        ,   Bigtable  ,        .   Bigtable           ,     ,         . <br><br> ,          .       ,         ,    . <br><br>  ¬ªWeitere Informationen zum Buch finden Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Website des Herausgebers</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Inhalt</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auszug</a> <br><br>    20%   ‚Äî <b>Site Reliability Engineering</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420139/">https://habr.com/ru/post/de420139/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420125/index.html">Automatisierung im Finanzwesen: Bankangestellte k√∂nnen aufgrund von Robotern arbeitslos bleiben</a></li>
<li><a href="../de420129/index.html">Asyncio Coroutine Muster: drau√üen warten</a></li>
<li><a href="../de420131/index.html">Probabilistische Bitcoin-Mining-Methode</a></li>
<li><a href="../de420133/index.html">Modellierung dynamischer Systeme: Wie bewegt sich der Mond?</a></li>
<li><a href="../de420135/index.html">Dies ist auch Toshiba: unerwartete Produkte des japanischen Unternehmens</a></li>
<li><a href="../de420141/index.html">Aus dem geladenen MPP DBMS - peppy Data Lake mit Analysetools: Teilen Sie die Details der Erstellung</a></li>
<li><a href="../de420143/index.html">Kotlin Leistung auf Android</a></li>
<li><a href="../de420145/index.html">Wie ist der Arbeitstag der Mitglieder der PC AppsConf</a></li>
<li><a href="../de420147/index.html">OpenSource auf Clojure</a></li>
<li><a href="../de420151/index.html">Einfacher als es klingt. Kapitel 12</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
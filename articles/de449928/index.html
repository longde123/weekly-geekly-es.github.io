<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöÉ üõ¥ üòé Nicht nur die Verarbeitung: Wie wir aus Kafka Streams eine verteilte Datenbank erstellt haben und was daraus wurde üêî ‚ò£Ô∏è üèÇüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! 

 Wir erinnern Sie daran, dass wir nach dem Buch √ºber Kafka eine ebenso interessante Arbeit √ºber die Kafka Streams API- Bibliothek ver√∂ff...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nicht nur die Verarbeitung: Wie wir aus Kafka Streams eine verteilte Datenbank erstellt haben und was daraus wurde</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/449928/"> Hallo Habr! <br><br>  Wir erinnern Sie daran, dass wir nach dem Buch √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka</a> eine ebenso interessante Arbeit √ºber die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka Streams API-</a> Bibliothek ver√∂ffentlicht haben. <br><br><img src="https://habrastorage.org/webt/8y/9t/ap/8y9tapvre4xx_5drbicokwak_7m.jpeg"><br><br>  Bisher versteht die Community nur die Grenzen dieses m√§chtigen Werkzeugs.  Daher wurde k√ºrzlich ein Artikel ver√∂ffentlicht, dessen √úbersetzung wir Ihnen vorstellen m√∂chten.  Aus eigener Erfahrung erkl√§rt der Autor, wie aus Kafka Streams ein verteiltes Data Warehouse erstellt wird.  Viel Spa√ü beim Lesen! <br><a name="habracut"></a><br>  Die Apache <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka Streams-</a> Bibliothek weltweit wird in Unternehmen f√ºr die verteilte Streaming-Verarbeitung zus√§tzlich zu Apache Kafka verwendet.  Einer der untersch√§tzten Aspekte dieses Frameworks ist, dass Sie damit einen lokalen Status basierend auf der Streaming-Verarbeitung speichern k√∂nnen. <br><br>  In diesem Artikel werde ich Ihnen erl√§utern, wie unser Unternehmen diese Gelegenheit erfolgreich genutzt hat, um ein Produkt f√ºr die Sicherheit von Cloud-Anwendungen zu entwickeln.  Mit Kafka Streams haben wir Shared-Service-Microservices erstellt, die jeweils als fehlertolerante und leicht zug√§ngliche Quelle f√ºr zuverl√§ssige Informationen √ºber den Status von Objekten im System dienen.  F√ºr uns ist dies ein Fortschritt in Bezug auf Zuverl√§ssigkeit und einfache Unterst√ºtzung. <br><br>  Wenn Sie an einem alternativen Ansatz interessiert sind, mit dem Sie eine einzige zentrale Datenbank verwenden k√∂nnen, um den formalen Status Ihrer Objekte zu unterst√ºtzen - lesen Sie, es wird interessant sein ... <br><br>  <b>Warum wir dachten, es sei Zeit, unsere Herangehensweisen an die Arbeit mit dem gemeinsamen Staat zu √§ndern</b> <br><br>  Wir mussten den Status verschiedener Objekte basierend auf Agentenberichten beibehalten (zum Beispiel: Wurde die Site angegriffen)?  Vor dem Wechsel zu Kafka Streams haben wir uns h√§ufig auf eine einzige zentrale Datenbank (+ Service-API) verlassen, um unseren Status zu verwalten.  Dieser Ansatz hat seine Nachteile: In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">datenintensiven Situationen wird die</a> Unterst√ºtzung f√ºr Konsistenz und Synchronisation zu einer echten Herausforderung.  Die Datenbank kann zu einem Engpass werden oder sich in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einem Rennzustand befinden</a> und unter Unvorhersehbarkeit leiden. <br><br><img src="https://habrastorage.org/webt/55/t-/bx/55t-bxgqgcfriiifqytwzcllqum.png"><br><br>  <i>Abbildung 1: Ein typisches Split-State-Szenario vor dem √úbergang zu</i> <i><br></i>  <i>Kafka- und Kafka-Streams: Agenten kommunizieren ihre √úbermittlungen √ºber die API. Der aktualisierte Status wird √ºber eine zentrale Datenbank berechnet</i> <br><br>  <b>Lernen Sie Kafka Streams kennen - jetzt ist es einfach, Microservices mit gemeinsamem Status zu erstellen</b> <br><br>  Vor etwa einem Jahr haben wir beschlossen, unsere gemeinsamen Zustandsszenarien gr√ºndlich zu √ºberpr√ºfen, um solche Probleme zu l√∂sen.  Wir haben uns sofort f√ºr Kafka Streams entschieden - wir wissen, wie skalierbar, leicht zug√§nglich und fehlertolerant es ist, wie umfangreich seine Streaming-Funktionalit√§t ist (Transformationen, einschlie√ülich Stateful-Transformationen).  Genau das, was wir brauchten, ganz zu schweigen davon, wie ausgereift und zuverl√§ssig das Messaging-System bei Kafka war. <br><br>  Jeder der von uns erstellten zustandserhaltenden Mikrodienste wurde auf der Grundlage der Kafka Streams-Instanz mit einer relativ einfachen Topologie erstellt.  Es bestand aus 1) einer Quelle 2) einem Prozessor mit einer permanenten Speicherung von Schl√ºsseln und Werten 3) Drain: <br><br><img src="https://habrastorage.org/webt/wg/6-/7-/wg6-7-jaoyhzec3j2koiyvs672y.png"><br><br>  <i>Abbildung 2: Die Standardtopologie unserer Streaming-Instanzen f√ºr Stateful Microservices.</i>  <i>Bitte beachten Sie, dass es auch ein Repository gibt, das Planungsmetadaten enth√§lt.</i> <br><br>  Mit diesem neuen Ansatz verfassen Agenten Nachrichten, die an das urspr√ºngliche Thema √ºbermittelt wurden, und Verbraucher - beispielsweise ein E-Mail-Benachrichtigungsdienst - akzeptieren den berechneten gemeinsamen Status √ºber den Bestand (Ausgabethema). <br><br><img src="https://habrastorage.org/webt/_m/36/ru/_m36runqg1uhxckmigufnn1uvba.png"><br><br>  <i>Abbildung 3: Ein neues Beispiel f√ºr einen Taskflow f√ºr ein Szenario mit gemeinsam genutzten Microservices: 1) Der Agent generiert eine Nachricht, die im urspr√ºnglichen Kafka-Thema eingeht.</i>  <i>2) ein Mikrodienst mit einem gemeinsam genutzten Status (unter Verwendung von Kafka-Streams) verarbeitet ihn und schreibt den berechneten Status in das endg√ºltige Kafka-Thema;</i>  <i>Danach 3) akzeptieren die Verbraucher den neuen Staat</i> <br><br>  <b>Hey, dieses eingebaute Repository mit Schl√ºsseln und Werten ist tats√§chlich sehr n√ºtzlich!</b> <br><br>  Wie oben erw√§hnt, enth√§lt unsere Shared-State-Topologie einen Speicher mit Schl√ºsseln und Werten.  Wir haben verschiedene Optionen f√ºr die Verwendung gefunden, von denen zwei im Folgenden beschrieben werden. <br><br>  <i><b>Option 1: Verwenden des Schl√ºsselspeichers und des Wertspeichers f√ºr Berechnungen</b></i> <br><br>  Unser erstes Repository mit Schl√ºsseln und Werten enthielt Zusatzdaten, die wir f√ºr Berechnungen ben√∂tigten.  In einigen F√§llen wurde beispielsweise der geteilte Staat auf der Grundlage eines Mehrheitsentscheidungsprinzips bestimmt.  Im Repository konnten die neuesten Agentenberichte zum Status eines bestimmten Objekts gespeichert werden.  Wenn wir dann einen neuen Bericht von einem Agenten erhalten, k√∂nnen wir ihn speichern, Berichte von allen anderen Agenten √ºber den Status desselben Objekts aus dem Repository extrahieren und die Berechnung wiederholen. <br>  Abbildung 4 unten zeigt, wie wir den Zugriff auf den Schl√ºssel- und Wertspeicher f√ºr die Verarbeitungsmethode des Prozessors ge√∂ffnet haben, damit wir die neue Nachricht verarbeiten k√∂nnen. <br><br><img src="https://habrastorage.org/webt/hu/by/ft/hubyft5r-2dw7ntkb7f6xktrgc4.png"><br><br>  <i>Abbildung 4: Wir √∂ffnen den Zugriff auf die Speicherung von Schl√ºsseln und Werten f√ºr die Verarbeitungsmethode des Prozessors (danach m√ºssen Sie in jedem Skript, das mit einem gemeinsam genutzten Status arbeitet, die <code>doProcess</code> Methode implementieren).</i> <br><br>  <i><b>Option 2: Erstellen einer CRUD-API √ºber Kafka Streams</b></i> <br><br>  Nachdem wir unseren grundlegenden Aufgabenfluss angepasst hatten, versuchten wir, eine RESTful CRUD-API f√ºr unsere Shared-Service-Microservices zu schreiben.  Wir wollten in der Lage sein, den Status einiger oder aller Objekte zu extrahieren sowie den Status des Objekts festzulegen oder zu l√∂schen (dies ist n√ºtzlich, wenn die Serverseite dies unterst√ºtzt). <br><br>  Um alle Get State-APIs zu unterst√ºtzen, haben wir den Status immer dann, wenn wir ihn w√§hrend der Verarbeitung neu berechnen mussten, f√ºr lange Zeit in das integrierte Repository mit Schl√ºsseln und Werten gestellt.  In diesem Fall wird es recht einfach, eine solche API mit einer einzelnen Instanz von Kafka Streams zu implementieren, wie in der folgenden Liste gezeigt: <br><br><img src="https://habrastorage.org/webt/qt/yi/an/qtyianzs_3irxdqenj9vsdx673k.png"><br><br>  <i>Abbildung 5: Verwenden der integrierten Speicherung von Schl√ºsseln und Werten, um den vorberechneten Status eines Objekts zu erhalten</i> <br><br>  Das Aktualisieren des Status eines Objekts √ºber die API ist ebenfalls einfach zu implementieren.  Im Prinzip m√ºssen Sie daf√ºr nur einen Produzenten Kafka erstellen und mit dessen Hilfe eine Aufzeichnung erstellen, in der ein neuer Zustand hergestellt wird.  Dies stellt sicher, dass alle √ºber die API generierten Nachrichten auf die gleiche Weise verarbeitet werden, wie sie von anderen Herstellern (z. B. Agenten) empfangen wurden. <br><br><img src="https://habrastorage.org/webt/g0/_q/ti/g0_qtio5patksf8uj8vyo0yj3ri.png"><br><br>  <i>Abbildung 6: Sie k√∂nnen den Status eines Objekts mit dem Produzenten Kafka festlegen</i> <br><br>  <b>Eine kleine Komplikation: Kafka hat viele Partitionen.</b> <br><br>  Als N√§chstes wollten wir die Verarbeitungslast verteilen und die Verf√ºgbarkeit verbessern, indem wir f√ºr jedes Szenario einen Microservice-Cluster mit gemeinsamem Dienst bereitstellen.  Das Setup wurde uns so einfach wie m√∂glich gegeben: Nachdem wir alle Instanzen so konfiguriert hatten, dass sie mit derselben Anwendungs-ID (und mit denselben Boot-Servern) arbeiteten, wurde fast alles andere automatisch erledigt.  Wir legen au√üerdem fest, dass jedes Quellthema aus mehreren Partitionen besteht, sodass jeder Instanz eine Teilmenge solcher Partitionen zugewiesen werden kann. <br><br>  Ich m√∂chte auch erw√§hnen, dass es normal ist, eine Sicherungskopie des Statusspeichers zu erstellen, damit diese Kopie beispielsweise im Falle einer Wiederherstellung nach einem Fehler auf eine andere Instanz √ºbertragen wird.  F√ºr jeden Statusspeicher in Kafka Streams wird ein repliziertes Thema mit einem √Ñnderungsprotokoll erstellt (in dem lokale Aktualisierungen verfolgt werden).  So sichert Kafka st√§ndig den Staatsladen.  Daher kann im Falle eines Ausfalls der einen oder anderen Kafka Streams-Instanz der Statusspeicher schnell in einer anderen Instanz wiederhergestellt werden, in die die entsprechenden Partitionen verschoben werden.  Unsere Tests haben gezeigt, dass dies in Sekundenschnelle erledigt werden kann, selbst wenn sich Millionen von Datens√§tzen im Repository befinden. <br><br>  Beim Wechsel von einem Shared-Service-Microservice zu einem Cluster von Microservices ist die Implementierung der Get State-API weniger trivial.  In der neuen Situation enth√§lt das Status-Repository jedes Mikrodienstes nur einen Teil des Gesamtbilds (die Objekte, deren Schl√ºssel einer bestimmten Partition zugeordnet wurden).  Wir mussten feststellen, in welcher Instanz der Status des ben√∂tigten Objekts enthalten war, und dies basierend auf den Flussmetadaten, wie unten gezeigt: <br><br><img src="https://habrastorage.org/webt/hh/yj/0l/hhyj0ldhlh9skmof8amtimhrjrq.png"><br><br>  <i>Abbildung 7: Mithilfe von Flussmetadaten bestimmen wir, von welcher Instanz der Status des gew√ºnschten Objekts angefordert werden soll.</i>  <i>Ein √§hnlicher Ansatz wurde mit der GET ALL-API verwendet</i> <br><br>  <b>Wichtigste Ergebnisse</b> <br><br>  Staatliche Gesch√§fte in Kafka Streams k√∂nnen de facto als verteilte Datenbank dienen. <ul><li>  kontinuierlich in kafka repliziert </li><li>  Auf einem solchen System kann leicht eine CRUD-API erstellt werden </li><li>  Das Verarbeiten mehrerer Partitionen ist etwas komplizierter </li><li>  Es ist auch m√∂glich, der Stream-Topologie einen oder mehrere Statusspeicher zum Speichern von Hilfsdaten hinzuzuf√ºgen.  Diese Option kann verwendet werden f√ºr: </li><li>  Langzeitspeicherung von Daten, die f√ºr Berechnungen in der Streaming-Verarbeitung ben√∂tigt werden </li><li>  Langzeitspeicherung von Daten, die bei der n√§chsten Initialisierung der Stream-Instanz hilfreich sein k√∂nnen </li><li>  viel mehr ... </li></ul><br><br>  Dank dieser und anderer Vorteile eignet sich Kafka Streams hervorragend zur Unterst√ºtzung des globalen Status in einem verteilten System wie dem unseren.  Kafka Streams hat sich in der Produktion als sehr zuverl√§ssig erwiesen (vom Zeitpunkt der Bereitstellung an haben wir praktisch keine Nachrichten verloren), und wir sind sicher, dass dies nicht auf seine Funktionen beschr√§nkt ist! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de449928/">https://habr.com/ru/post/de449928/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de449916/index.html">5 M√∂glichkeiten, PHP-Code unter Hochlastbedingungen bereitzustellen</a></li>
<li><a href="../de449918/index.html">Infrarot-Thermometer mit Sensor MLX90614</a></li>
<li><a href="../de449920/index.html">10 nicht standardm√§√üige M√∂glichkeiten, um SEO beim √Ñndern des CMS zu verletzen (+1 Bonus)</a></li>
<li><a href="../de449922/index.html">Probefahrt nanoCAD SPDS Metalwork 1.2. Teil 3</a></li>
<li><a href="../de449926/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 362 (22. - 28. April 2019)</a></li>
<li><a href="../de449930/index.html">Frontend Weekly Digest (22. - 28. April 2019)</a></li>
<li><a href="../de449932/index.html">Suchen Sie nach Aufgaben in JIRA (einfache Sprache). Teil 2: Erweiterte Suche</a></li>
<li><a href="../de449934/index.html">3D-Druck mit Metallen: 5 offensichtliche Vorteile eines praktischen Beispiels</a></li>
<li><a href="../de449936/index.html">Warum ist es schwierig, in einem multinationalen Team zu arbeiten?</a></li>
<li><a href="../de449938/index.html">Entwickler vs. Business</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚃 🛴 😎 Nicht nur die Verarbeitung: Wie wir aus Kafka Streams eine verteilte Datenbank erstellt haben und was daraus wurde 🐔 ☣️ 🏂🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! 

 Wir erinnern Sie daran, dass wir nach dem Buch über Kafka eine ebenso interessante Arbeit über die Kafka Streams API- Bibliothek veröff...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nicht nur die Verarbeitung: Wie wir aus Kafka Streams eine verteilte Datenbank erstellt haben und was daraus wurde</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/449928/"> Hallo Habr! <br><br>  Wir erinnern Sie daran, dass wir nach dem Buch über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka</a> eine ebenso interessante Arbeit über die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka Streams API-</a> Bibliothek veröffentlicht haben. <br><br><img src="https://habrastorage.org/webt/8y/9t/ap/8y9tapvre4xx_5drbicokwak_7m.jpeg"><br><br>  Bisher versteht die Community nur die Grenzen dieses mächtigen Werkzeugs.  Daher wurde kürzlich ein Artikel veröffentlicht, dessen Übersetzung wir Ihnen vorstellen möchten.  Aus eigener Erfahrung erklärt der Autor, wie aus Kafka Streams ein verteiltes Data Warehouse erstellt wird.  Viel Spaß beim Lesen! <br><a name="habracut"></a><br>  Die Apache <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka Streams-</a> Bibliothek weltweit wird in Unternehmen für die verteilte Streaming-Verarbeitung zusätzlich zu Apache Kafka verwendet.  Einer der unterschätzten Aspekte dieses Frameworks ist, dass Sie damit einen lokalen Status basierend auf der Streaming-Verarbeitung speichern können. <br><br>  In diesem Artikel werde ich Ihnen erläutern, wie unser Unternehmen diese Gelegenheit erfolgreich genutzt hat, um ein Produkt für die Sicherheit von Cloud-Anwendungen zu entwickeln.  Mit Kafka Streams haben wir Shared-Service-Microservices erstellt, die jeweils als fehlertolerante und leicht zugängliche Quelle für zuverlässige Informationen über den Status von Objekten im System dienen.  Für uns ist dies ein Fortschritt in Bezug auf Zuverlässigkeit und einfache Unterstützung. <br><br>  Wenn Sie an einem alternativen Ansatz interessiert sind, mit dem Sie eine einzige zentrale Datenbank verwenden können, um den formalen Status Ihrer Objekte zu unterstützen - lesen Sie, es wird interessant sein ... <br><br>  <b>Warum wir dachten, es sei Zeit, unsere Herangehensweisen an die Arbeit mit dem gemeinsamen Staat zu ändern</b> <br><br>  Wir mussten den Status verschiedener Objekte basierend auf Agentenberichten beibehalten (zum Beispiel: Wurde die Site angegriffen)?  Vor dem Wechsel zu Kafka Streams haben wir uns häufig auf eine einzige zentrale Datenbank (+ Service-API) verlassen, um unseren Status zu verwalten.  Dieser Ansatz hat seine Nachteile: In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">datenintensiven Situationen wird die</a> Unterstützung für Konsistenz und Synchronisation zu einer echten Herausforderung.  Die Datenbank kann zu einem Engpass werden oder sich in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einem Rennzustand befinden</a> und unter Unvorhersehbarkeit leiden. <br><br><img src="https://habrastorage.org/webt/55/t-/bx/55t-bxgqgcfriiifqytwzcllqum.png"><br><br>  <i>Abbildung 1: Ein typisches Split-State-Szenario vor dem Übergang zu</i> <i><br></i>  <i>Kafka- und Kafka-Streams: Agenten kommunizieren ihre Übermittlungen über die API. Der aktualisierte Status wird über eine zentrale Datenbank berechnet</i> <br><br>  <b>Lernen Sie Kafka Streams kennen - jetzt ist es einfach, Microservices mit gemeinsamem Status zu erstellen</b> <br><br>  Vor etwa einem Jahr haben wir beschlossen, unsere gemeinsamen Zustandsszenarien gründlich zu überprüfen, um solche Probleme zu lösen.  Wir haben uns sofort für Kafka Streams entschieden - wir wissen, wie skalierbar, leicht zugänglich und fehlertolerant es ist, wie umfangreich seine Streaming-Funktionalität ist (Transformationen, einschließlich Stateful-Transformationen).  Genau das, was wir brauchten, ganz zu schweigen davon, wie ausgereift und zuverlässig das Messaging-System bei Kafka war. <br><br>  Jeder der von uns erstellten zustandserhaltenden Mikrodienste wurde auf der Grundlage der Kafka Streams-Instanz mit einer relativ einfachen Topologie erstellt.  Es bestand aus 1) einer Quelle 2) einem Prozessor mit einer permanenten Speicherung von Schlüsseln und Werten 3) Drain: <br><br><img src="https://habrastorage.org/webt/wg/6-/7-/wg6-7-jaoyhzec3j2koiyvs672y.png"><br><br>  <i>Abbildung 2: Die Standardtopologie unserer Streaming-Instanzen für Stateful Microservices.</i>  <i>Bitte beachten Sie, dass es auch ein Repository gibt, das Planungsmetadaten enthält.</i> <br><br>  Mit diesem neuen Ansatz verfassen Agenten Nachrichten, die an das ursprüngliche Thema übermittelt wurden, und Verbraucher - beispielsweise ein E-Mail-Benachrichtigungsdienst - akzeptieren den berechneten gemeinsamen Status über den Bestand (Ausgabethema). <br><br><img src="https://habrastorage.org/webt/_m/36/ru/_m36runqg1uhxckmigufnn1uvba.png"><br><br>  <i>Abbildung 3: Ein neues Beispiel für einen Taskflow für ein Szenario mit gemeinsam genutzten Microservices: 1) Der Agent generiert eine Nachricht, die im ursprünglichen Kafka-Thema eingeht.</i>  <i>2) ein Mikrodienst mit einem gemeinsam genutzten Status (unter Verwendung von Kafka-Streams) verarbeitet ihn und schreibt den berechneten Status in das endgültige Kafka-Thema;</i>  <i>Danach 3) akzeptieren die Verbraucher den neuen Staat</i> <br><br>  <b>Hey, dieses eingebaute Repository mit Schlüsseln und Werten ist tatsächlich sehr nützlich!</b> <br><br>  Wie oben erwähnt, enthält unsere Shared-State-Topologie einen Speicher mit Schlüsseln und Werten.  Wir haben verschiedene Optionen für die Verwendung gefunden, von denen zwei im Folgenden beschrieben werden. <br><br>  <i><b>Option 1: Verwenden des Schlüsselspeichers und des Wertspeichers für Berechnungen</b></i> <br><br>  Unser erstes Repository mit Schlüsseln und Werten enthielt Zusatzdaten, die wir für Berechnungen benötigten.  In einigen Fällen wurde beispielsweise der geteilte Staat auf der Grundlage eines Mehrheitsentscheidungsprinzips bestimmt.  Im Repository konnten die neuesten Agentenberichte zum Status eines bestimmten Objekts gespeichert werden.  Wenn wir dann einen neuen Bericht von einem Agenten erhalten, können wir ihn speichern, Berichte von allen anderen Agenten über den Status desselben Objekts aus dem Repository extrahieren und die Berechnung wiederholen. <br>  Abbildung 4 unten zeigt, wie wir den Zugriff auf den Schlüssel- und Wertspeicher für die Verarbeitungsmethode des Prozessors geöffnet haben, damit wir die neue Nachricht verarbeiten können. <br><br><img src="https://habrastorage.org/webt/hu/by/ft/hubyft5r-2dw7ntkb7f6xktrgc4.png"><br><br>  <i>Abbildung 4: Wir öffnen den Zugriff auf die Speicherung von Schlüsseln und Werten für die Verarbeitungsmethode des Prozessors (danach müssen Sie in jedem Skript, das mit einem gemeinsam genutzten Status arbeitet, die <code>doProcess</code> Methode implementieren).</i> <br><br>  <i><b>Option 2: Erstellen einer CRUD-API über Kafka Streams</b></i> <br><br>  Nachdem wir unseren grundlegenden Aufgabenfluss angepasst hatten, versuchten wir, eine RESTful CRUD-API für unsere Shared-Service-Microservices zu schreiben.  Wir wollten in der Lage sein, den Status einiger oder aller Objekte zu extrahieren sowie den Status des Objekts festzulegen oder zu löschen (dies ist nützlich, wenn die Serverseite dies unterstützt). <br><br>  Um alle Get State-APIs zu unterstützen, haben wir den Status immer dann, wenn wir ihn während der Verarbeitung neu berechnen mussten, für lange Zeit in das integrierte Repository mit Schlüsseln und Werten gestellt.  In diesem Fall wird es recht einfach, eine solche API mit einer einzelnen Instanz von Kafka Streams zu implementieren, wie in der folgenden Liste gezeigt: <br><br><img src="https://habrastorage.org/webt/qt/yi/an/qtyianzs_3irxdqenj9vsdx673k.png"><br><br>  <i>Abbildung 5: Verwenden der integrierten Speicherung von Schlüsseln und Werten, um den vorberechneten Status eines Objekts zu erhalten</i> <br><br>  Das Aktualisieren des Status eines Objekts über die API ist ebenfalls einfach zu implementieren.  Im Prinzip müssen Sie dafür nur einen Produzenten Kafka erstellen und mit dessen Hilfe eine Aufzeichnung erstellen, in der ein neuer Zustand hergestellt wird.  Dies stellt sicher, dass alle über die API generierten Nachrichten auf die gleiche Weise verarbeitet werden, wie sie von anderen Herstellern (z. B. Agenten) empfangen wurden. <br><br><img src="https://habrastorage.org/webt/g0/_q/ti/g0_qtio5patksf8uj8vyo0yj3ri.png"><br><br>  <i>Abbildung 6: Sie können den Status eines Objekts mit dem Produzenten Kafka festlegen</i> <br><br>  <b>Eine kleine Komplikation: Kafka hat viele Partitionen.</b> <br><br>  Als Nächstes wollten wir die Verarbeitungslast verteilen und die Verfügbarkeit verbessern, indem wir für jedes Szenario einen Microservice-Cluster mit gemeinsamem Dienst bereitstellen.  Das Setup wurde uns so einfach wie möglich gegeben: Nachdem wir alle Instanzen so konfiguriert hatten, dass sie mit derselben Anwendungs-ID (und mit denselben Boot-Servern) arbeiteten, wurde fast alles andere automatisch erledigt.  Wir legen außerdem fest, dass jedes Quellthema aus mehreren Partitionen besteht, sodass jeder Instanz eine Teilmenge solcher Partitionen zugewiesen werden kann. <br><br>  Ich möchte auch erwähnen, dass es normal ist, eine Sicherungskopie des Statusspeichers zu erstellen, damit diese Kopie beispielsweise im Falle einer Wiederherstellung nach einem Fehler auf eine andere Instanz übertragen wird.  Für jeden Statusspeicher in Kafka Streams wird ein repliziertes Thema mit einem Änderungsprotokoll erstellt (in dem lokale Aktualisierungen verfolgt werden).  So sichert Kafka ständig den Staatsladen.  Daher kann im Falle eines Ausfalls der einen oder anderen Kafka Streams-Instanz der Statusspeicher schnell in einer anderen Instanz wiederhergestellt werden, in die die entsprechenden Partitionen verschoben werden.  Unsere Tests haben gezeigt, dass dies in Sekundenschnelle erledigt werden kann, selbst wenn sich Millionen von Datensätzen im Repository befinden. <br><br>  Beim Wechsel von einem Shared-Service-Microservice zu einem Cluster von Microservices ist die Implementierung der Get State-API weniger trivial.  In der neuen Situation enthält das Status-Repository jedes Mikrodienstes nur einen Teil des Gesamtbilds (die Objekte, deren Schlüssel einer bestimmten Partition zugeordnet wurden).  Wir mussten feststellen, in welcher Instanz der Status des benötigten Objekts enthalten war, und dies basierend auf den Flussmetadaten, wie unten gezeigt: <br><br><img src="https://habrastorage.org/webt/hh/yj/0l/hhyj0ldhlh9skmof8amtimhrjrq.png"><br><br>  <i>Abbildung 7: Mithilfe von Flussmetadaten bestimmen wir, von welcher Instanz der Status des gewünschten Objekts angefordert werden soll.</i>  <i>Ein ähnlicher Ansatz wurde mit der GET ALL-API verwendet</i> <br><br>  <b>Wichtigste Ergebnisse</b> <br><br>  Staatliche Geschäfte in Kafka Streams können de facto als verteilte Datenbank dienen. <ul><li>  kontinuierlich in kafka repliziert </li><li>  Auf einem solchen System kann leicht eine CRUD-API erstellt werden </li><li>  Das Verarbeiten mehrerer Partitionen ist etwas komplizierter </li><li>  Es ist auch möglich, der Stream-Topologie einen oder mehrere Statusspeicher zum Speichern von Hilfsdaten hinzuzufügen.  Diese Option kann verwendet werden für: </li><li>  Langzeitspeicherung von Daten, die für Berechnungen in der Streaming-Verarbeitung benötigt werden </li><li>  Langzeitspeicherung von Daten, die bei der nächsten Initialisierung der Stream-Instanz hilfreich sein können </li><li>  viel mehr ... </li></ul><br><br>  Dank dieser und anderer Vorteile eignet sich Kafka Streams hervorragend zur Unterstützung des globalen Status in einem verteilten System wie dem unseren.  Kafka Streams hat sich in der Produktion als sehr zuverlässig erwiesen (vom Zeitpunkt der Bereitstellung an haben wir praktisch keine Nachrichten verloren), und wir sind sicher, dass dies nicht auf seine Funktionen beschränkt ist! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de449928/">https://habr.com/ru/post/de449928/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de449916/index.html">5 Möglichkeiten, PHP-Code unter Hochlastbedingungen bereitzustellen</a></li>
<li><a href="../de449918/index.html">Infrarot-Thermometer mit Sensor MLX90614</a></li>
<li><a href="../de449920/index.html">10 nicht standardmäßige Möglichkeiten, um SEO beim Ändern des CMS zu verletzen (+1 Bonus)</a></li>
<li><a href="../de449922/index.html">Probefahrt nanoCAD SPDS Metalwork 1.2. Teil 3</a></li>
<li><a href="../de449926/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends für die letzte Woche Nr. 362 (22. - 28. April 2019)</a></li>
<li><a href="../de449930/index.html">Frontend Weekly Digest (22. - 28. April 2019)</a></li>
<li><a href="../de449932/index.html">Suchen Sie nach Aufgaben in JIRA (einfache Sprache). Teil 2: Erweiterte Suche</a></li>
<li><a href="../de449934/index.html">3D-Druck mit Metallen: 5 offensichtliche Vorteile eines praktischen Beispiels</a></li>
<li><a href="../de449936/index.html">Warum ist es schwierig, in einem multinationalen Team zu arbeiten?</a></li>
<li><a href="../de449938/index.html">Entwickler vs. Business</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
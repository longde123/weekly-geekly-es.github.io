<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö∂üèª üôéüèæ üï∫ Apache Ignite + Apache Spark Data Frames: juntos m√°s divertido üëÆ üëåüèª üëñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! Mi nombre es Nikolai Izhikov, trabajo para Sberbank Technologies en el equipo de desarrollo de soluciones de c√≥digo abierto. Detr√°s de 15 a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apache Ignite + Apache Spark Data Frames: juntos m√°s divertido</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/427297/">  Hola Habr!  Mi nombre es Nikolai Izhikov, trabajo para Sberbank Technologies en el equipo de desarrollo de soluciones de c√≥digo abierto.  Detr√°s de 15 a√±os de desarrollo comercial en Java.  Soy un confirmador de Apache Ignite y un colaborador de Apache Kafka. <br><br>  Debajo del gato encontrar√° una versi√≥n en video y texto de mi informe sobre Apache Ignite Meetup sobre c√≥mo usar Apache Ignite con Apache Spark y qu√© caracter√≠sticas hemos implementado para esto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f42/5f3/df5/f425f3df59ff99d03d4a3e6aff3b2655.png"><br><a name="habracut"></a><br><h2>  Lo que puede hacer Apache Spark </h2><br>  ¬øQu√© es Apache Spark?  Este es un producto que le permite realizar r√°pidamente consultas inform√°ticas y anal√≠ticas distribuidas.  B√°sicamente, Apache Spark est√° escrito en Scala. <br><br>  Apache Spark tiene una API rica para conectarse a varios sistemas de almacenamiento o recibir datos.  Una de las caracter√≠sticas del producto es un motor de consulta universal similar a SQL para los datos recibidos de varias fuentes.  Si tiene varias fuentes de informaci√≥n, desea combinarlas y obtener algunos resultados, Apache Spark es lo que necesita. <br><br>  Una de las abstracciones clave que proporciona Spark es Data Frame, DataSet.  En t√©rminos de una base de datos relacional, esta es una tabla, una fuente que proporciona datos de forma estructurada.  Se conoce la estructura, el tipo de cada columna, su nombre, etc.  Los marcos de datos se pueden crear a partir de varias fuentes.  Los ejemplos incluyen archivos json, bases de datos relacionales, varios sistemas hadoop y Apache Ignite. <br><br>  Spark admite combinaciones en consultas SQL.  Puede combinar datos de varias fuentes y obtener resultados, realizar consultas anal√≠ticas.  Adem√°s, hay una API para guardar datos.  Cuando haya completado las consultas, haya realizado un estudio, Spark brinda la capacidad de guardar los resultados en el receptor que admite esta funci√≥n y, en consecuencia, resolver el problema del procesamiento de datos. <br><br><h2>  Qu√© caracter√≠sticas hemos implementado para integrar Apache Spark con Apache Ignite </h2><br><ol><li>  Lectura de datos de tablas Apache Ignite SQL. </li><li>  Escribir datos en tablas Apache Ignite SQL. </li><li>  IgniteCatalog dentro de IgniteSparkSession: la capacidad de usar todas las tablas existentes de Ignite SQL sin registrarse "a mano". </li><li>  Optimizaci√≥n de SQL: la capacidad de ejecutar instrucciones SQL dentro de Ignite. </li></ol><br>  Apache Spark puede leer datos de tablas Apache Ignite SQL y escribirlos en forma de dicha tabla.  Cualquier DataFrame que se forme en Spark se puede guardar como una tabla Apache Ignite SQL. <br><br>  Apache Ignite le permite utilizar todas las tablas existentes de Ignite SQL en Spark Session sin registrarse "a mano", utilizando IgniteCatalog dentro de la extensi√≥n est√°ndar de SparkSession: IgniteSparkSession. <br><br>  Aqu√≠ debes profundizar un poco m√°s en el dispositivo Spark.  En t√©rminos de una base de datos normal, un directorio es un lugar donde se almacena la metainformaci√≥n: qu√© tablas est√°n disponibles, qu√© columnas est√°n en ellas, etc.  Cuando llega una solicitud, la metainformaci√≥n se extrae del cat√°logo y el motor SQL hace algo con tablas y datos.  De forma predeterminada, en Spark, todas las tablas de lectura (no importa, desde una base de datos relacional, Ignite, Hadoop) deben registrarse manualmente en la sesi√≥n.  Como resultado, tiene la oportunidad de realizar una consulta SQL en estas tablas.  Spark se entera de ellos. <br><br>  Para trabajar con los datos que cargamos en Ignite, necesitamos registrar las tablas.  Pero en lugar de registrar cada tabla con nuestras manos, implementamos la capacidad de acceder autom√°ticamente a todas las tablas de Ignite. <br><br>  ¬øCu√°l es la caracter√≠stica aqu√≠?  Por alguna raz√≥n no lo s√©, el directorio en Spark es una API interna, es decir  un extra√±o no puede venir y crear su propia implementaci√≥n de cat√°logo.  Y, dado que Spark sali√≥ de Hadoop, solo es compatible con Hive.  Y debes registrar todo lo dem√°s con tus manos.  Los usuarios a menudo preguntan c√≥mo puede evitar esto e inmediatamente realizan consultas SQL.  Implement√© un directorio que le permite navegar y acceder a las tablas de Ignite sin registrar ~ y sms ~, e inicialmente propuse este parche en la comunidad de Spark, a lo que recib√≠ una respuesta: dicho parche no es interesante por algunas razones internas.  Y no dieron la API interna. <br><br>  Ahora el cat√°logo Ignite es una caracter√≠stica interesante implementada usando la API interna de Spark.  Para usar este directorio, tenemos nuestra propia implementaci√≥n de la sesi√≥n. Esta es la SparkSession habitual, dentro de la cual puede realizar solicitudes, procesar datos.  Las diferencias son que integramos ExternalCatalog en √©l para trabajar con tablas Ignite, as√≠ como IgniteOptimization, que se describir√° a continuaci√≥n. <br><br>  <b>Optimizaci√≥n de SQL</b> : la capacidad de ejecutar instrucciones SQL dentro de Ignite.  De forma predeterminada, al realizar uniones, agrupaciones, c√°lculos agregados y otras consultas SQL complejas, Spark lee los datos en modo fila por fila.  Lo √∫nico que puede hacer la fuente de datos es filtrar las filas de manera eficiente. <br><br>  Si usa unir o agrupar, Spark extrae todos los datos de la tabla a su memoria para el trabajador, utilizando los filtros especificados, y solo luego los agrupa o realiza otras operaciones SQL.  En el caso de Ignite, esto no es √≥ptimo, porque Ignite tiene una arquitectura distribuida y tiene conocimiento de los datos almacenados en ella.  Por lo tanto, Ignite puede calcular de manera eficiente los agregados y llevar a cabo la agrupaci√≥n.  Adem√°s, puede haber una gran cantidad de datos, y para agruparlos, deber√° restar todo, aumentar todos los datos en Spark, que es bastante costoso. <br><br>  Spark proporciona una API con la que puede cambiar el plan inicial de la consulta SQL, realizar la optimizaci√≥n y reenviar la parte de la consulta SQL que se puede ejecutar all√≠ en Ignite.  Esto ser√° efectivo en t√©rminos de velocidad y consumo de memoria, ya que no lo usaremos para extraer datos que se agrupar√°n inmediatamente. <br><br><h2>  Como funciona </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/b28/1df/0ef/b281df0ef5f2ea2a08f73267ef7f5edb.png"><br><br>  Tenemos un grupo Ignite: esta es la mitad inferior de la imagen.  No hay Zookeeper, ya que solo hay cinco nodos.  Hay trabajadores de chispa, dentro de cada trabajador se levanta el nodo del cliente Ignite.  A trav√©s de √©l, podemos hacer una solicitud y leer los datos, interactuar con el cl√∫ster.  Adem√°s, el nodo del cliente se eleva dentro de IgniteSparkSession para que el directorio funcione. <br><br><h2>  Encender marco de datos </h2><br>  Pasamos al c√≥digo: ¬øc√≥mo leer datos de una tabla SQL?  En el caso de Spark, todo es bastante simple y bueno: decimos que queremos calcular algunos datos, indicar el formato; esta es una constante constante.  Adem√°s, tenemos varias opciones: la ruta al archivo de configuraci√≥n para el nodo del cliente, que comienza al leer los datos.  Indicamos qu√© tabla queremos leer y le decimos a Spark que cargue.  Obtenemos los datos y podemos hacer lo que queramos con ellos. <br><br><pre><code class="scala hljs">spark.read .format(<span class="hljs-type"><span class="hljs-type">FORMAT_IGNITE</span></span>) .option(<span class="hljs-type"><span class="hljs-type">OPTION_CONFIG_FILE</span></span>, <span class="hljs-type"><span class="hljs-type">TEST_CONFIG_FILE</span></span>) .option(<span class="hljs-type"><span class="hljs-type">OPTION_TABLE</span></span>, <span class="hljs-string"><span class="hljs-string">"person"</span></span>) .load()</code> </pre> <br>  Despu√©s de haber generado los datos, opcionalmente de Ignite, de cualquier fuente, podemos guardarlo f√°cilmente especificando el formato y la tabla correspondiente.  Le ordenamos a Spark que escriba, especificamos un formato.  En la configuraci√≥n, prescribimos a qu√© cl√∫ster conectarse.  Especifique la tabla en la que queremos guardar.  Adem√°s, podemos prescribir opciones de utilidad: especifique la clave principal que creamos en esta tabla.  Si los datos simplemente se alteran sin crear una tabla, entonces este par√°metro no es necesario.  Al final, haga clic en guardar y se escribir√°n los datos. <br><br><pre> <code class="scala hljs">tbl.write. format(<span class="hljs-type"><span class="hljs-type">FORMAT_IGNITE</span></span>). option(<span class="hljs-type"><span class="hljs-type">OPTION_CONFIG_FILE</span></span>, <span class="hljs-type"><span class="hljs-type">CFG_PATH</span></span>). option(<span class="hljs-type"><span class="hljs-type">OPTION_TABLE</span></span>, tableName). option(<span class="hljs-type"><span class="hljs-type">OPTION_CREATE_TABLE_PRIMARY_KEY_FIELDS</span></span>, pk). save</code> </pre><br>  Ahora veamos c√≥mo funciona todo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b35/41a/b86/b3541ab86eca15cd240765bf15907979.png"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LoadDataExample.scala</a> <br><br>  Esta aplicaci√≥n obvia primero demostrar√° las capacidades de grabaci√≥n.  Por ejemplo, eleg√≠ los datos de los partidos de f√∫tbol, ‚Äã‚Äãdescargu√© estad√≠sticas de un recurso conocido.  Contiene informaci√≥n sobre torneos: ligas, partidos, jugadores, equipos, atributos de jugador, atributos de equipo: datos que describen partidos de f√∫tbol en ligas de pa√≠ses europeos (Inglaterra, Francia, Espa√±a, etc.). <br><br>  Quiero subirlos a Ignite.  Creamos una sesi√≥n de Spark, especificamos la direcci√≥n del asistente y llamamos a la carga de estas tablas, pasando par√°metros.  El ejemplo est√° en Scala, no en Java, porque Scala es menos detallado y, por ejemplo, mucho mejor. <br><br>  Transferimos el nombre del archivo, lo leemos, indicamos que es multil√≠nea, este es un archivo json est√°ndar.  Luego escribimos en Ignite.  La estructura de nuestro archivo no se describe en ninguna parte: Spark mismo determina qu√© datos tenemos y cu√°l es su estructura.  Si todo transcurre sin problemas, se crea una tabla en la que hay todos los campos necesarios de los tipos de datos requeridos.  As√≠ es como podemos cargar todo dentro de Ignite. <br><br>  Cuando se cargan los datos, podemos verlos en Ignite y usarlos de inmediato.  Como ejemplo simple, una consulta que le permite saber qu√© equipo jug√≥ m√°s partidos.  Tenemos dos columnas: hometeam y awayteam, anfitriones e invitados.  Seleccionamos, agrupamos, contamos, sumamos y unimos datos con el comando para ingresar el nombre del comando.  Ta-dam - y los datos de json-chiks que obtuvimos en Ignite.  Vemos Paris Saint-Germain, Toulouse: tenemos muchos datos sobre los equipos franceses. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8a4/202/52b/8a420252be6fb8df3a9083d7411911a9.png"><br><br>  Resumimos  Ahora hemos subido datos desde la fuente, el archivo json, a Ignite, y con bastante rapidez.  Quiz√°s, desde el punto de vista de big data, esto no es demasiado grande, pero es decente para una computadora local.  El esquema de la tabla se toma del archivo json en su forma original.  Se cre√≥ la tabla, se copiaron los nombres de las columnas del archivo fuente, se cre√≥ la clave primaria.  La identificaci√≥n est√° en todas partes, y la clave principal es la identificaci√≥n.  Estos datos llegaron a Ignite, podemos usarlos. <br><br><h2>  IgniteSparkSession y IgniteCatalog </h2><br>  Veamos como funciona. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/654/24a/4ee/65424a4eeda4a4c2c6cce7038e13d1a9.png"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CatalogExample.scala</a> <br><br>  De una manera bastante simple, puede acceder y consultar todos sus datos.  En el √∫ltimo ejemplo, comenzamos la sesi√≥n est√°ndar de chispa.  Y no hab√≠a especificidad Ignite all√≠, excepto que tiene que poner un jar con la fuente de datos correcta, trabajo completamente est√°ndar a trav√©s de la API p√∫blica.  Pero, si desea acceder a las tablas de Ignite autom√°ticamente, puede usar nuestra extensi√≥n.  La diferencia es que, en lugar de SparkSession, escribimos IgniteSparkSession. <br><br>  Tan pronto como cree un objeto IgniteSparkSession, ver√° en el directorio todas las tablas que se acaban de cargar en Ignite.  Puedes ver su diagrama y toda la informaci√≥n.  Spark ya conoce las tablas que tiene Ignite y puede obtener f√°cilmente todos los datos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dec/f1b/a0c/decf1ba0c5db2e0d84e50a0e88b6c192.png"><br><br><h2>  Optimizaci√≥n del encendido </h2><br>  Cuando realiza consultas complejas en Ignite usando JOIN, Spark extrae los datos primero, y solo luego JOIN los agrupa.  Para optimizar el proceso, creamos la funci√≥n IgniteOptimization: optimiza el plan de consulta de Spark y le permite reenviar las partes de la solicitud que se pueden ejecutar dentro de Ignite dentro de Ignite.  Mostramos optimizaci√≥n en una solicitud espec√≠fica. <br><br><pre> <code class="sql hljs">SQL Query: <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span>   city_id,   <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span>   person p <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> city_id <span class="hljs-keyword"><span class="hljs-keyword">HAVING</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) &gt; <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br>  Cumplimos la solicitud.  Tenemos una tabla de personas: algunos empleados, personas.  Cada empleado conoce la identificaci√≥n de la ciudad en la que vive.  Queremos saber cu√°ntas personas viven en cada ciudad.  Filtramos: en qu√© ciudad vive m√°s de una persona.  Aqu√≠ est√° el plan inicial que construye Spark: <br><br><pre> <code class="scala hljs">== <span class="hljs-type"><span class="hljs-type">Analyzed</span></span> <span class="hljs-type"><span class="hljs-type">Logical</span></span> <span class="hljs-type"><span class="hljs-type">Plan</span></span> == city_id: bigint, count(<span class="hljs-number"><span class="hljs-number">1</span></span>): bigint <span class="hljs-type"><span class="hljs-type">Project</span></span> [city_id#<span class="hljs-number"><span class="hljs-number">19</span></span>L, count(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">52</span></span>L] +- <span class="hljs-type"><span class="hljs-type">Filter</span></span> (count(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">54</span></span>L &gt; cast(<span class="hljs-number"><span class="hljs-number">1</span></span> as bigint))  +- <span class="hljs-type"><span class="hljs-type">Aggregate</span></span> [city_id#<span class="hljs-number"><span class="hljs-number">19</span></span>L], [city_id#<span class="hljs-number"><span class="hljs-number">19</span></span>L, count(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-type"><span class="hljs-type">AS</span></span> count(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">52</span></span>L, count(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-type"><span class="hljs-type">AS</span></span> count(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">54</span></span>L] +- <span class="hljs-type"><span class="hljs-type">SubqueryAlias</span></span> p    +- <span class="hljs-type"><span class="hljs-type">SubqueryAlias</span></span> person       +- <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">NAME</span></span>#<span class="hljs-number"><span class="hljs-number">11</span></span>,<span class="hljs-type"><span class="hljs-type">BIRTH_DATE</span></span>#<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-type"><span class="hljs-type">IS_RESIDENT</span></span>#<span class="hljs-number"><span class="hljs-number">13</span></span>,<span class="hljs-type"><span class="hljs-type">SALARY</span></span>#<span class="hljs-number"><span class="hljs-number">14</span></span>,<span class="hljs-type"><span class="hljs-type">PENSION</span></span>#<span class="hljs-number"><span class="hljs-number">15</span></span>,<span class="hljs-type"><span class="hljs-type">ACCOUNT</span></span>#<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-type"><span class="hljs-type">AGE</span></span>#<span class="hljs-number"><span class="hljs-number">17</span></span>,<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">18</span></span>L,<span class="hljs-type"><span class="hljs-type">CITY_ID</span></span>#<span class="hljs-number"><span class="hljs-number">19</span></span>L]         <span class="hljs-type"><span class="hljs-type">IgniteSQLRelation</span></span>[table=<span class="hljs-type"><span class="hljs-type">PERSON</span></span>]</code> </pre><br>  La relaci√≥n es solo una tabla Ignite.  No hay filtros: simplemente extraemos todos los datos de la tabla Persona a trav√©s de la red desde el cl√∫ster.  Luego, Spark agrega todo esto, de acuerdo con la solicitud y devuelve el resultado de la solicitud. <br><br>  Es f√°cil ver que todo este sub√°rbol con filtro y agregaci√≥n se puede ejecutar dentro de Ignite.  Esto ser√° mucho m√°s eficiente que extraer todos los datos de una tabla potencialmente grande en Spark; esto es lo que hace nuestra funci√≥n IgniteOptimization.  Despu√©s de analizar y optimizar el √°rbol, obtenemos el siguiente plan: <br><br><pre> <code class="scala hljs">== <span class="hljs-type"><span class="hljs-type">Optimized</span></span> <span class="hljs-type"><span class="hljs-type">Logical</span></span> <span class="hljs-type"><span class="hljs-type">Plan</span></span> == <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">CITY_ID</span></span>#<span class="hljs-number"><span class="hljs-number">19</span></span>L,<span class="hljs-type"><span class="hljs-type">COUNT</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">52</span></span>L]   <span class="hljs-type"><span class="hljs-type">IgniteSQLAccumulatorRelation</span></span>(     columns=[<span class="hljs-type"><span class="hljs-type">CITY_ID</span></span>, <span class="hljs-type"><span class="hljs-type">COUNT</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>)], qry=<span class="hljs-type"><span class="hljs-type">SELECT</span></span> <span class="hljs-type"><span class="hljs-type">CITY_ID</span></span>, <span class="hljs-type"><span class="hljs-type">COUNT</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-type"><span class="hljs-type">FROM</span></span> <span class="hljs-type"><span class="hljs-type">PERSON</span></span> <span class="hljs-type"><span class="hljs-type">GROUP</span></span> <span class="hljs-type"><span class="hljs-type">BY</span></span> city_id <span class="hljs-type"><span class="hljs-type">HAVING</span></span> count(<span class="hljs-number"><span class="hljs-number">1</span></span>) &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  Como resultado, obtenemos solo una relaci√≥n, ya que optimizamos todo el √°rbol.  Y dentro de usted ya puede ver que Ignite enviar√° una solicitud lo suficientemente cercana a la solicitud original. <br><br>  Supongamos que estamos uniendo diferentes fuentes de datos: por ejemplo, tenemos un DataFrame de Ignite, el segundo de json, el tercero nuevamente de Ignite y el cuarto de alg√∫n tipo de base de datos relacional.  En este caso, solo el sub√°rbol se optimizar√° en el plan.  Optimizamos lo que podemos, lo dejamos en Ignite y Spark har√° el resto.  Debido a esto, obtenemos una ganancia de velocidad. <br><br>  Otro ejemplo con JOIN: <br><br><pre> <code class="sql hljs">SQL Query - <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> jt1.id <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> id1, jt1.val1, jt2.id <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> id2, jt2.val2 <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> jt1 <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> jt2 <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> jt1.val1 = jt2.val2</code> </pre><br>  Tenemos dos mesas.  Nos mantenemos unidos por valor y seleccionamos de todos ellos: ID, valores.  Spark ofrece tal plan: <br><br><pre> <code class="scala hljs">== <span class="hljs-type"><span class="hljs-type">Analyzed</span></span> <span class="hljs-type"><span class="hljs-type">Logical</span></span> <span class="hljs-type"><span class="hljs-type">Plan</span></span> == id1: bigint, val1: string, id2: bigint, val2: string <span class="hljs-type"><span class="hljs-type">Project</span></span> [id#<span class="hljs-number"><span class="hljs-number">4</span></span>L <span class="hljs-type"><span class="hljs-type">AS</span></span> id1#<span class="hljs-number"><span class="hljs-number">84</span></span>L, val1#<span class="hljs-number"><span class="hljs-number">3</span></span>, id#<span class="hljs-number"><span class="hljs-number">6</span></span>L <span class="hljs-type"><span class="hljs-type">AS</span></span> id2#<span class="hljs-number"><span class="hljs-number">85</span></span>L, val2#<span class="hljs-number"><span class="hljs-number">5</span></span>] +- <span class="hljs-type"><span class="hljs-type">Join</span></span> <span class="hljs-type"><span class="hljs-type">Inner</span></span>, (val1#<span class="hljs-number"><span class="hljs-number">3</span></span> = val2#<span class="hljs-number"><span class="hljs-number">5</span></span>) :- <span class="hljs-type"><span class="hljs-type">SubqueryAlias</span></span> jt1 : +- <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">VAL1</span></span>#<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">4</span></span>L] <span class="hljs-type"><span class="hljs-type">IgniteSQLRelation</span></span>[table=<span class="hljs-type"><span class="hljs-type">JT1</span></span>] +- <span class="hljs-type"><span class="hljs-type">SubqueryAlias</span></span> jt2    +- <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">VAL2</span></span>#<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">6</span></span>L] <span class="hljs-type"><span class="hljs-type">IgniteSQLRelation</span></span>[table=<span class="hljs-type"><span class="hljs-type">JT2</span></span>]</code> </pre> <br>  Vemos que extraer√° todos los datos de una tabla, todos los datos de la segunda, los unir√° dentro de s√≠ mismo y dar√° los resultados.  Despu√©s del procesamiento y la optimizaci√≥n, obtenemos exactamente la misma solicitud que se env√≠a a Ignite, donde se ejecuta con relativa rapidez. <br><br><pre> <code class="scala hljs">== <span class="hljs-type"><span class="hljs-type">Optimized</span></span> <span class="hljs-type"><span class="hljs-type">Logical</span></span> <span class="hljs-type"><span class="hljs-type">Plan</span></span> == <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">84</span></span>L,<span class="hljs-type"><span class="hljs-type">VAL1</span></span>#<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">85</span></span>L,<span class="hljs-type"><span class="hljs-type">VAL2</span></span>#<span class="hljs-number"><span class="hljs-number">5</span></span>] <span class="hljs-type"><span class="hljs-type">IgniteSQLAccumulatorRelation</span></span>(columns=[<span class="hljs-type"><span class="hljs-type">ID</span></span>, <span class="hljs-type"><span class="hljs-type">VAL1</span></span>, <span class="hljs-type"><span class="hljs-type">ID</span></span>, <span class="hljs-type"><span class="hljs-type">VAL2</span></span>], qry= <span class="hljs-type"><span class="hljs-type">SELECT</span></span> <span class="hljs-type"><span class="hljs-type">JT1</span></span>.<span class="hljs-type"><span class="hljs-type">ID</span></span> <span class="hljs-type"><span class="hljs-type">AS</span></span> id1, <span class="hljs-type"><span class="hljs-type">JT1</span></span>.<span class="hljs-type"><span class="hljs-type">VAL1</span></span>, <span class="hljs-type"><span class="hljs-type">JT2</span></span>.<span class="hljs-type"><span class="hljs-type">ID</span></span> <span class="hljs-type"><span class="hljs-type">AS</span></span> id2, <span class="hljs-type"><span class="hljs-type">JT2</span></span>.<span class="hljs-type"><span class="hljs-type">VAL2</span></span> <span class="hljs-type"><span class="hljs-type">FROM</span></span> <span class="hljs-type"><span class="hljs-type">JT1</span></span> <span class="hljs-type"><span class="hljs-type">JOIN</span></span> <span class="hljs-type"><span class="hljs-type">JT2</span></span> <span class="hljs-type"><span class="hljs-type">ON</span></span> <span class="hljs-type"><span class="hljs-type">JT1</span></span>.val1 = <span class="hljs-type"><span class="hljs-type">JT2</span></span>.val2 <span class="hljs-type"><span class="hljs-type">WHERE</span></span> <span class="hljs-type"><span class="hljs-type">JT1</span></span>.val1 <span class="hljs-type"><span class="hljs-type">IS</span></span> <span class="hljs-type"><span class="hljs-type">NOT</span></span> <span class="hljs-type"><span class="hljs-type">NULL</span></span> <span class="hljs-type"><span class="hljs-type">AND</span></span> <span class="hljs-type"><span class="hljs-type">JT2</span></span>.val2 <span class="hljs-type"><span class="hljs-type">IS</span></span> <span class="hljs-type"><span class="hljs-type">NOT</span></span> <span class="hljs-type"><span class="hljs-type">NULL</span></span>)</code> </pre> <br>  Te mostrar√© un ejemplo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ba4/39a/493/ba439a493e76dd573966cad413c07650.png"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OptimizationExample.scala</a> <br><br>  Estamos creando una sesi√≥n IgniteSpark en la que todas nuestras capacidades de optimizaci√≥n ya est√°n incluidas autom√°ticamente.  Aqu√≠ la solicitud es esta: encuentra a los jugadores con la calificaci√≥n m√°s alta y muestra sus nombres.  En la tabla de jugadores, sus atributos y datos.  Nos estamos uniendo, filtrando datos basura y mostrando jugadores con la calificaci√≥n m√°s alta.  Veamos qu√© tipo de plan tenemos despu√©s de la optimizaci√≥n y muestre los resultados de esta consulta. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7d/c51/9ab/c7dc519abdfa6b3b1d7a8396ef9725b3.png"><br><br>  Empezamos  Vemos apellidos familiares: Messi, Buffon, Ronaldo, etc.  Por cierto, algunos por alguna raz√≥n se encuentran en dos formas: tanto Messi como Ronaldo.  Los amantes del f√∫tbol pueden encontrar extra√±o que jugadores desconocidos aparezcan en la lista.  Estos son porteros, jugadores con caracter√≠sticas bastante altas, en el contexto de otros jugadores.  Ahora miramos el plan de consulta que se ejecut√≥.  En Spark, casi no se hizo nada, es decir, enviamos toda la solicitud nuevamente a Ignite. <br><br><h2>  Desarrollo Apache Ignite </h2><br>  Nuestro proyecto es un producto de c√≥digo abierto, por lo que siempre estamos contentos con los parches y los comentarios de los desarrolladores.  Su ayuda, comentarios, parches son muy bienvenidos.  Los estamos esperando.  El 90% de la comunidad Ignite habla ruso.  Por ejemplo, para m√≠, hasta que comenc√© a trabajar en Apache Ignite, no el mejor conocimiento del ingl√©s era un elemento disuasorio.  No vale la pena escribir en ruso en una lista de desarrolladores, pero incluso si escribes algo mal, te responder√°n y te ayudar√°n. <br><br>  ¬øQu√© se puede mejorar en esta integraci√≥n?  ¬øC√≥mo puedo ayudar si tienes ese deseo?  Lista abajo.  Los asteriscos indican complejidad. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/de4/d43/ed0/de4d43ed01894ce6b02865ad9f6aef5d.png"><br>  Para probar la optimizaci√≥n, debe escribir pruebas con consultas complejas.  Arriba, mostr√© algunas consultas obvias.  Est√° claro que si escribes muchas agrupaciones y muchas uniones, entonces algo puede caer.  Esta es una tarea muy simple: ven y hazlo.  Si encontramos alg√∫n error basado en los resultados de la prueba, ser√° necesario corregirlo.  Ser√° m√°s dif√≠cil all√≠. <br><br>  Otra tarea clara e interesante es la integraci√≥n de Spark con un cliente ligero.  Inicialmente puede especificar algunos conjuntos de direcciones IP, y esto es suficiente para unirse al cl√∫ster Ignite, lo cual es conveniente en caso de integraci√≥n con un sistema externo.  Si de repente quiere unirse a la soluci√≥n a este problema, personalmente lo ayudar√©. <br><br>  Si desea unirse a la comunidad Apache Ignite, aqu√≠ hay algunos enlaces √∫tiles: <br><br><ul><li>  <i>Comience aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://yu">https://ignite.apache.org/community/resources.html</a></i> <br></li><li>  <i>Fuentes aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://github.com/apache/ignite/</a></i> <br></li><li>  <i>Muelles aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://apacheignite.readme.io/docs</a></i> <br></li><li>  <i>Errores aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://issues.apache.org/jira/browse/IGNITE</a></i> <br></li><li>  <i>Puede escribir aqu√≠: dev@ignite.apache.org, user@ignite.apache.org</i> <br></li></ul><br>  Tenemos una lista de desarrolladores receptiva, que lo ayudar√°.  Todav√≠a est√° lejos de ser ideal, pero en comparaci√≥n con otros proyectos, est√° realmente vivo. <br><br>  <i>Si conoce Java o C ++, est√° buscando trabajo y desea desarrollar c√≥digo abierto (Apache Ignite, Apache Kafka, Tarantool, etc.) escriba aqu√≠: join-open-source@sberbank.ru.</i> <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/CzbAweNKEVY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es427297/">https://habr.com/ru/post/es427297/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es427285/index.html">Escuela sobre los fundamentos de los circuitos digitales: Novosibirsk - Ok, Krasnoyarsk - prep√°rate</a></li>
<li><a href="../es427289/index.html">Modelado geol√≥gico 3D, registro y tecnolog√≠a de Aramco Innovations</a></li>
<li><a href="../es427291/index.html">Minimice el tr√°fico en los formularios web ASP.NET, div cliqueable y sondeo peri√≥dico del servidor</a></li>
<li><a href="../es427293/index.html">Patrones de dise√±o de JavaScript</a></li>
<li><a href="../es427295/index.html">Funciones de curr√≠culum de JavaScript</a></li>
<li><a href="../es427299/index.html">¬øVamos a buscar algo m√°s para coleccionar? Constructor 3 en 1 "Flota Lunar"</a></li>
<li><a href="../es427301/index.html">Base de datos de bloqueo de GitHub</a></li>
<li><a href="../es427303/index.html">Retrasando Windows Parte 2: Creando Procesos</a></li>
<li><a href="../es427307/index.html">Pr√°ctica de prueba de backend de Java + Rest-Assured</a></li>
<li><a href="../es427309/index.html">C√≥mo PVS-Studio result√≥ ser m√°s atento que tres programadores y medio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
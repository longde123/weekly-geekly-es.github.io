<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶ã üë©üèª‚Äç‚úàÔ∏è üë∂üèΩ Transfer Learning: cara cepat melatih jaringan saraf pada data Anda üë®‚Äçüç≥ üê£ üéÖ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pembelajaran mesin menjadi lebih mudah diakses, ada lebih banyak peluang untuk menerapkan teknologi ini menggunakan ‚Äúkomponen yang tidak tersedia‚Äù. Se...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Transfer Learning: cara cepat melatih jaringan saraf pada data Anda</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/binarydistrict/blog/428255/">  Pembelajaran mesin menjadi lebih mudah diakses, ada lebih banyak peluang untuk menerapkan teknologi ini menggunakan ‚Äúkomponen yang tidak tersedia‚Äù.  Sebagai contoh, Transfer Learning memungkinkan Anda untuk menggunakan pengalaman yang diperoleh dalam menyelesaikan satu masalah untuk memecahkan masalah lain yang serupa.  Jaringan saraf pertama kali dilatih tentang sejumlah besar data, kemudian pada target yang ditetapkan. <br><br><img src="https://habrastorage.org/webt/q-/wr/cn/q-wrcns6clfsv1n2k6gki-sdoea.jpeg" alt="Pengakuan makanan"><br><br>  Pada artikel ini saya akan memberi tahu Anda cara menggunakan metode Transfer Learning menggunakan contoh pengenalan gambar dengan makanan.  Saya akan berbicara tentang alat pembelajaran mesin lainnya di lokakarya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Machine Learning dan Neural Networks for Developers</a> . <br><a name="habracut"></a><br>  Jika kita dihadapkan pada tugas pengenalan gambar, Anda dapat menggunakan layanan yang sudah jadi.  Namun, jika Anda perlu melatih model pada set data Anda sendiri, Anda harus melakukannya sendiri. <br><br>  Untuk tugas-tugas umum seperti klasifikasi gambar, Anda dapat menggunakan arsitektur yang sudah jadi (AlexNet, VGG, Inception, ResNet, dll.) Dan melatih jaringan saraf pada data Anda.  Implementasi jaringan seperti itu menggunakan berbagai kerangka kerja yang sudah ada, jadi pada tahap ini Anda dapat menggunakan salah satunya sebagai kotak hitam, tanpa mempelajari prinsip operasinya secara mendalam. <br><br>  Namun, jaringan saraf yang dalam menuntut data dalam jumlah besar untuk konvergensi pembelajaran.  Dan seringkali dalam tugas khusus kita tidak ada cukup data untuk melatih semua lapisan jaringan saraf dengan benar.  Transfer Learning memecahkan masalah ini. <br><br><h1>  Transfer Pembelajaran untuk Klasifikasi Gambar </h1><br>  Jaringan saraf yang digunakan untuk klasifikasi biasanya mengandung neuron keluaran <code>N</code> di lapisan terakhir, di mana <code>N</code> adalah jumlah kelas.  Seperti vektor keluaran diperlakukan sebagai satu set probabilitas milik kelas.  Dalam tugas kami mengenali gambar makanan, jumlah kelas mungkin berbeda dari yang ada di dataset asli.  Dalam hal ini, kita harus benar-benar membuang lapisan terakhir ini dan memasukkan yang baru, dengan jumlah neuron output yang tepat <br><br><img src="https://habrastorage.org/webt/u_/n3/k3/u_n3k3qpkps6nw9tjjzwc0njl-y.jpeg" alt="Transfer belajar"><br><br>  Seringkali di akhir jaringan klasifikasi, lapisan yang terhubung sepenuhnya digunakan.  Karena kami mengganti lapisan ini, menggunakan bobot yang sudah dilatih sebelumnya untuk itu tidak akan berfungsi.  Anda harus melatihnya dari awal, menginisialisasi bobotnya dengan nilai acak.  Kami memuat bobot untuk semua lapisan lainnya dari snapshot yang sudah dilatih sebelumnya. <br><br>  Ada berbagai strategi untuk pelatihan model selanjutnya.  Kami akan menggunakan yang berikut ini: kami akan melatih seluruh jaringan dari ujung ke ujung ( <i>ujung ke ujung</i> ), dan kami tidak akan memperbaiki bobot pra-pelatihan untuk memungkinkan mereka menyesuaikan sedikit dan menyesuaikan dengan data kami.  Proses ini disebut <i>fine-tuning</i> . <br><br><h1>  Komponen struktural </h1><br>  Untuk mengatasi masalah tersebut, kita membutuhkan komponen berikut: <br><br><ol><li>  Deskripsi model jaringan saraf </li><li>  Pipa belajar </li><li>  Pipa interferensi </li><li>  Bobot pra-terlatih untuk model ini </li><li>  Data untuk pelatihan dan validasi </li></ol><br><img src="https://habrastorage.org/webt/tf/xp/2o/tfxp2on4o-rxj6hnt4dij7u8vlk.jpeg" alt="Komponen"><br><br>  Dalam contoh kita, saya akan mengambil komponen (1), (2) dan (3) dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">repositori saya sendiri</a> , yang berisi kode paling ringan - Anda dapat dengan mudah mengetahuinya jika Anda mau.  Contoh kami akan diimplementasikan pada kerangka kerja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TensorFlow yang</a> populer.  Bobot pra-terlatih (4) yang cocok untuk kerangka kerja yang dipilih dapat ditemukan jika sesuai dengan salah satu arsitektur klasik.  Sebagai dataset (5) untuk demonstrasi saya akan mengambil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Food-101</a> . <br><br><h1>  Model </h1><br>  Sebagai model, kami menggunakan jaringan saraf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VGG</a> klasik (lebih tepatnya, <i>VGG19</i> ).  Meskipun ada beberapa kelemahan, model ini menunjukkan kualitas yang cukup tinggi.  Selain itu, mudah untuk dianalisis.  Pada TensorFlow Slim, deskripsi model terlihat cukup ringkas: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow.contrib.slim <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> slim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vgg_19</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs, num_classes, is_training, scope=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'vgg_19'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, weight_decay=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.0005</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> slim.arg_scope([slim.conv2d], activation_fn=tf.nn.relu, weights_regularizer=slim.l2_regularizer(weight_decay), biases_initializer=tf.zeros_initializer(), padding=<span class="hljs-string"><span class="hljs-string">'SAME'</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.variable_scope(scope, <span class="hljs-string"><span class="hljs-string">'vgg_19'</span></span>, [inputs]): net = slim.repeat(inputs, <span class="hljs-number"><span class="hljs-number">2</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">64</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv1'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool1'</span></span>) net = slim.repeat(net, <span class="hljs-number"><span class="hljs-number">2</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">128</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv2'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool2'</span></span>) net = slim.repeat(net, <span class="hljs-number"><span class="hljs-number">4</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">256</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv3'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool3'</span></span>) net = slim.repeat(net, <span class="hljs-number"><span class="hljs-number">4</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">512</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv4'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool4'</span></span>) net = slim.repeat(net, <span class="hljs-number"><span class="hljs-number">4</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">512</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv5'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool5'</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Use conv2d instead of fully_connected layers net = slim.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6') net = slim.dropout(net, 0.5, is_training=is_training, scope='drop6') net = slim.conv2d(net, 4096, [1, 1], scope='fc7') net = slim.dropout(net, 0.5, is_training=is_training, scope='drop7') net = slim.conv2d(net, num_classes, [1, 1], scope='fc8', activation_fn=None) net = tf.squeeze(net, [1, 2], name='fc8/squeezed') return net</span></span></code> </pre><br>  Bobot untuk VGG19, dilatih di ImageNet dan kompatibel dengan TensorFlow, diunduh dari repositori di GitHub dari bagian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Model Pra-terlatih</a> . <br><br><pre> <code class="bash hljs">mkdir data &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> data wget http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz tar -xzf vgg_19_2016_08_28.tar.gz</code> </pre><br><h1>  Datacet </h1><br>  Sebagai sampel pelatihan dan validasi, kami akan menggunakan dataset <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Food-101</a> publik, yang berisi lebih dari 100 ribu gambar makanan, dibagi menjadi 101 kategori. <br><br><img src="https://habrastorage.org/webt/re/oh/pb/reohpbmt76_3qfzplzccsz-hbf8.jpeg" alt="Dataset Makanan-101"><br><br>  Unduh dan buka paket dataset: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> data wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz tar -xzf food-101.tar.gz</code> </pre><br>  Pipa data dalam pelatihan kami dirancang sehingga dari dataset kami perlu menguraikan berikut ini: <br><br><ol><li>  Daftar kelas (kategori) </li><li>  Tutorial: daftar jalur ke gambar dan daftar jawaban yang benar </li><li>  Kumpulan validasi: daftar jalur ke gambar dan daftar jawaban yang benar </li></ol><br>  Jika dataset Anda, maka untuk <i>kereta</i> dan <i>validasi</i> Anda perlu memecahkan set sendiri.  Food-101 sudah memiliki partisi seperti itu, dan informasi ini disimpan di direktori <code>meta</code> . <br><br><pre> <code class="python hljs">DATASET_ROOT = <span class="hljs-string"><span class="hljs-string">'data/food-101/'</span></span> train_data, val_data, classes = data.food101(DATASET_ROOT) num_classes = len(classes)</code> </pre><br>  Semua fungsi tambahan yang bertanggung jawab untuk pemrosesan data dipindahkan ke file <code>data.py</code> terpisah: <br><br><div class="spoiler">  <b class="spoiler_title">data.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> os.path <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> join <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> opj <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parse_ds_subset</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img_root, list_fpath, classes)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Parse a meta file with image paths and labels -&gt; img_root: path to the root of image folders -&gt; list_fpath: path to the file with the list (eg train.txt) -&gt; classes: list of class names &lt;- (list_of_img_paths, integer_labels) '''</span></span> fpaths = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(list_fpath, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: class_name, image_id = line.strip().split(<span class="hljs-string"><span class="hljs-string">'/'</span></span>) fpaths.append(opj(img_root, class_name, image_id+<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) labels.append(classes.index(class_name)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> fpaths, labels <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">food101</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataset_root)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Get lists of train and validation examples for Food-101 dataset -&gt; dataset_root: root of the Food-101 dataset &lt;- ((train_fpaths, train_labels), (val_fpaths, val_labels), classes) '''</span></span> img_root = opj(dataset_root, <span class="hljs-string"><span class="hljs-string">'images'</span></span>) train_list_fpath = opj(dataset_root, <span class="hljs-string"><span class="hljs-string">'meta'</span></span>, <span class="hljs-string"><span class="hljs-string">'train.txt'</span></span>) test_list_fpath = opj(dataset_root, <span class="hljs-string"><span class="hljs-string">'meta'</span></span>, <span class="hljs-string"><span class="hljs-string">'test.txt'</span></span>) classes_list_fpath = opj(dataset_root, <span class="hljs-string"><span class="hljs-string">'meta'</span></span>, <span class="hljs-string"><span class="hljs-string">'classes.txt'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(classes_list_fpath, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: classes = [line.strip() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f] train_data = parse_ds_subset(img_root, train_list_fpath, classes) val_data = parse_ds_subset(img_root, test_list_fpath, classes) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> train_data, val_data, classes <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">imread_and_crop</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(fpath, inp_size, margin=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, random_crop=False)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Construct TF graph for image preparation: Read the file, crop and resize -&gt; fpath: path to the JPEG image file (TF node) -&gt; inp_size: size of the network input (eg 224) -&gt; margin: cropping margin -&gt; random_crop: perform random crop or central crop &lt;- prepared image (TF node) '''</span></span> data = tf.read_file(fpath) img = tf.image.decode_jpeg(data, channels=<span class="hljs-number"><span class="hljs-number">3</span></span>) img = tf.image.convert_image_dtype(img, dtype=tf.float32) shape = tf.shape(img) crop_size = tf.minimum(shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]) - <span class="hljs-number"><span class="hljs-number">2</span></span> * margin <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> random_crop: img = tf.random_crop(img, (crop_size, crop_size, <span class="hljs-number"><span class="hljs-number">3</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-comment"><span class="hljs-comment"># central crop ho = (shape[0] - crop_size) // 2 wo = (shape[0] - crop_size) // 2 img = img[ho:ho+crop_size, wo:wo+crop_size, :] img = tf.image.resize_images(img, (inp_size, inp_size), method=tf.image.ResizeMethod.AREA) return img def train_dataset(data, batch_size, epochs, inp_size, margin): ''' Prepare training data pipeline -&gt; data: (list_of_img_paths, integer_labels) -&gt; batch_size: training batch size -&gt; epochs: number of training epochs -&gt; inp_size: size of the network input (eg 224) -&gt; margin: cropping margin &lt;- (dataset, number_of_train_iterations) ''' num_examples = len(data[0]) iters = (epochs * num_examples) // batch_size def fpath_to_image(fpath, label): img = imread_and_crop(fpath, inp_size, margin, random_crop=True) return img, label dataset = tf.data.Dataset.from_tensor_slices(data) dataset = dataset.shuffle(buffer_size=num_examples) dataset = dataset.map(fpath_to_image) dataset = dataset.repeat(epochs) dataset = dataset.batch(batch_size, drop_remainder=True) return dataset, iters def val_dataset(data, batch_size, inp_size): ''' Prepare validation data pipeline -&gt; data: (list_of_img_paths, integer_labels) -&gt; batch_size: validation batch size -&gt; inp_size: size of the network input (eg 224) &lt;- (dataset, number_of_val_iterations) ''' num_examples = len(data[0]) iters = num_examples // batch_size def fpath_to_image(fpath, label): img = imread_and_crop(fpath, inp_size, 0, random_crop=False) return img, label dataset = tf.data.Dataset.from_tensor_slices(data) dataset = dataset.map(fpath_to_image) dataset = dataset.batch(batch_size, drop_remainder=True) return dataset, iters</span></span></code> </pre><br></div></div><br><h1>  Pelatihan model </h1><br>  Kode pelatihan model terdiri dari langkah-langkah berikut: <br><br><ol><li>  Membangun jalur data <i>kereta / validasi</i> </li><li>  Membangun <i>kereta /</i> grafik <i>validasi</i> (jaringan) </li><li>  Lampiran fungsi klasifikasi kerugian ( <i>cross entropy loss</i> ) di atas grafik <i>kereta</i> </li><li>  Kode diperlukan untuk menghitung keakuratan prediksi pada sampel validasi selama pelatihan </li><li>  Logika untuk memuat skala pra-terlatih dari snapshot </li><li>  Membuat berbagai struktur untuk pembelajaran </li><li>  Siklus pembelajaran itu sendiri (optimasi berulang) </li></ol><br>  Lapisan terakhir grafik dikonstruksi dengan jumlah neuron yang diperlukan dan dikeluarkan dari daftar parameter yang dimuat dari snapshot pra-terlatih. <br><br><div class="spoiler">  <b class="spoiler_title">Kode Pelatihan Model</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow.contrib.slim <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> slim tf.logging.set_verbosity(tf.logging.INFO) <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> data <span class="hljs-comment"><span class="hljs-comment">########################################################### ### Settings ########################################################### INPUT_SIZE = 224 RANDOM_CROP_MARGIN = 10 TRAIN_EPOCHS = 20 TRAIN_BATCH_SIZE = 64 VAL_BATCH_SIZE = 128 LR_START = 0.001 LR_END = LR_START / 1e4 MOMENTUM = 0.9 VGG_PRETRAINED_CKPT = 'data/vgg_19.ckpt' CHECKPOINT_DIR = 'checkpoints/vgg19_food' LOG_LOSS_EVERY = 10 CALC_ACC_EVERY = 500 ########################################################### ### Build training and validation data pipelines ########################################################### train_ds, train_iters = data.train_dataset(train_data, TRAIN_BATCH_SIZE, TRAIN_EPOCHS, INPUT_SIZE, RANDOM_CROP_MARGIN) train_ds_iterator = train_ds.make_one_shot_iterator() train_x, train_y = train_ds_iterator.get_next() val_ds, val_iters = data.val_dataset(val_data, VAL_BATCH_SIZE, INPUT_SIZE) val_ds_iterator = val_ds.make_initializable_iterator() val_x, val_y = val_ds_iterator.get_next() ########################################################### ### Construct training and validation graphs ########################################################### with tf.variable_scope('', reuse=tf.AUTO_REUSE): train_logits = model.vgg_19(train_x, num_classes, is_training=True) val_logits = model.vgg_19(val_x, num_classes, is_training=False) ########################################################### ### Construct training loss ########################################################### loss = tf.losses.sparse_softmax_cross_entropy( labels=train_y, logits=train_logits) tf.summary.scalar('loss', loss) ########################################################### ### Construct validation accuracy ### and related functions ########################################################### def calc_accuracy(sess, val_logits, val_y, val_iters): acc_total = 0.0 acc_denom = 0 for i in range(val_iters): logits, y = sess.run((val_logits, val_y)) y_pred = np.argmax(logits, axis=1) correct = np.count_nonzero(y == y_pred) acc_denom += y_pred.shape[0] acc_total += float(correct) tf.logging.info('Validating batch [{} / {}] correct = {}'.format( i, val_iters, correct)) acc_total /= acc_denom return acc_total def accuracy_summary(sess, acc_value, iteration): acc_summary = tf.Summary() acc_summary.value.add(tag="accuracy", simple_value=acc_value) sess._hooks[1]._summary_writer.add_summary(acc_summary, iteration) ########################################################### ### Define set of VGG variables to restore ### Create the Restorer ### Define init callback (used by monitored session) ########################################################### vars_to_restore = tf.contrib.framework.get_variables_to_restore( exclude=['vgg_19/fc8']) vgg_restorer = tf.train.Saver(vars_to_restore) def init_fn(scaffold, sess): vgg_restorer.restore(sess, VGG_PRETRAINED_CKPT) ########################################################### ### Create various training structures ########################################################### global_step = tf.train.get_or_create_global_step() lr = tf.train.polynomial_decay(LR_START, global_step, train_iters, LR_END) tf.summary.scalar('learning_rate', lr) optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=MOMENTUM) training_op = slim.learning.create_train_op( loss, optimizer, global_step=global_step) scaffold = tf.train.Scaffold(init_fn=init_fn) ########################################################### ### Create monitored session ### Run training loop ########################################################### with tf.train.MonitoredTrainingSession(checkpoint_dir=CHECKPOINT_DIR, save_checkpoint_secs=600, save_summaries_steps=30, scaffold=scaffold) as sess: start_iter = sess.run(global_step) for iteration in range(start_iter, train_iters): # Gradient Descent loss_value = sess.run(training_op) # Loss logging if iteration % LOG_LOSS_EVERY == 0: tf.logging.info('[{} / {}] Loss = {}'.format( iteration, train_iters, loss_value)) # Accuracy logging if iteration % CALC_ACC_EVERY == 0: sess.run(val_ds_iterator.initializer) acc_value = calc_accuracy(sess, val_logits, val_y, val_iters) accuracy_summary(sess, acc_value, iteration) tf.logging.info('[{} / {}] Validation accuracy = {}'.format( iteration, train_iters, acc_value))</span></span></code> </pre><br></div></div><br>  Setelah memulai pelatihan, Anda dapat melihat progresnya menggunakan utilitas TensorBoard, yang dilengkapi dengan TensorFlow dan berfungsi untuk memvisualisasikan berbagai metrik dan parameter lainnya. <br><br><pre> <code class="bash hljs">tensorboard --logdir checkpoints/</code> </pre><br>  Pada akhir pelatihan di TensorBoard, kami melihat gambaran yang hampir sempurna: penurunan <i>kehilangan kereta</i> dan peningkatan <i>Akurasi Validasi</i> <br><br><img src="https://habrastorage.org/webt/bk/hc/ay/bkhcayg7tn4nczu3dx2flgfukrc.jpeg" alt="Kehilangan dan akurasi TensorBoard"><br><br>  Hasilnya, kami mendapatkan snapshot yang disimpan di <code>checkpoints/vgg19_food</code> , yang akan kami gunakan selama pengujian model kami ( <i>inferensi</i> ). <br><br><h1>  Pengujian model </h1><br>  Sekarang uji model kami.  Untuk melakukan ini: <br><br><ol><li>  Kami membuat grafik baru yang dirancang khusus untuk inferensi ( <code>is_training=False</code> ) </li><li>  Memuat bobot terlatih dari foto </li><li>  Unduh dan preprocess gambar uji input. </li><li>  Mari kita mengarahkan gambar melalui jaringan saraf dan mendapatkan prediksi </li></ol><br><div class="spoiler">  <b class="spoiler_title">inference.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> imageio <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.transform <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> resize <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> model <span class="hljs-comment"><span class="hljs-comment">########################################################### ### Settings ########################################################### CLASSES_FPATH = 'data/food-101/meta/labels.txt' INP_SIZE = 224 # Input will be cropped and resized CHECKPOINT_DIR = 'checkpoints/vgg19_food' IMG_FPATH = 'data/food-101/images/bruschetta/3564471.jpg' ########################################################### ### Get all class names ########################################################### with open(CLASSES_FPATH, 'r') as f: classes = [line.strip() for line in f] num_classes = len(classes) ########################################################### ### Construct inference graph ########################################################### x = tf.placeholder(tf.float32, (1, INP_SIZE, INP_SIZE, 3), name='inputs') logits = model.vgg_19(x, num_classes, is_training=False) ########################################################### ### Create TF session and restore from a snapshot ########################################################### sess = tf.Session() snapshot_fpath = tf.train.latest_checkpoint(CHECKPOINT_DIR) restorer = tf.train.Saver() restorer.restore(sess, snapshot_fpath) ########################################################### ### Load and prepare input image ########################################################### def crop_and_resize(img, input_size): crop_size = min(img.shape[0], img.shape[1]) ho = (img.shape[0] - crop_size) // 2 wo = (img.shape[0] - crop_size) // 2 img = img[ho:ho+crop_size, wo:wo+crop_size, :] img = resize(img, (input_size, input_size), order=3, mode='reflect', anti_aliasing=True, preserve_range=True) return img img = imageio.imread(IMG_FPATH) img = img.astype(np.float32) img = crop_and_resize(img, INP_SIZE) img = img[None, ...] ########################################################### ### Run inference ########################################################### out = sess.run(logits, feed_dict={x:img}) pred_class = classes[np.argmax(out)] print('Input: {}'.format(IMG_FPATH)) print('Prediction: {}'.format(pred_class))</span></span></code> </pre><br></div></div><br><img src="https://habrastorage.org/webt/j6/e6/jv/j6e6jv72cuvsl3ztjo_392quidm.jpeg" alt="Kesimpulan"><br><br>  Semua kode, termasuk sumber daya untuk membangun dan menjalankan wadah Docker dengan semua versi perpustakaan yang diperlukan, ada di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">repositori ini</a> - pada saat membaca artikel, kode dalam repositori mungkin memiliki pembaruan. <br><br>  Pada lokakarya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Pembelajaran Mesin dan Jaringan Saraf Tiruan untuk Pengembang"</a> Saya akan menganalisis tugas pembelajaran mesin lainnya, dan siswa akan mempresentasikan proyek mereka pada akhir sesi intensif. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id428255/">https://habr.com/ru/post/id428255/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id428239/index.html">Flash drive di ambang 2019 - peninggalan masa lalu atau masih menjadi kebutuhan?</a></li>
<li><a href="../id428243/index.html">GeekBrains akan mengajarkan bahasa pemrograman C ++</a></li>
<li><a href="../id428249/index.html">Teknologi WDM: menggabungkan pusat data ke dalam kelompok tahan bencana</a></li>
<li><a href="../id428251/index.html">Kerentanan bodoh dalam aplikasi "My Beeline"</a></li>
<li><a href="../id428253/index.html">Bahasa Tertanam: Mengapa Lua?</a></li>
<li><a href="../id428257/index.html">Penelitian: 95% aplikasi anak-anak memiliki iklan</a></li>
<li><a href="../id428259/index.html">Buku ‚ÄúMengapa kita salah? Berpikir Perangkap dalam Tindakan. " Kutipan Bagian 2</a></li>
<li><a href="../id428261/index.html">Minggu Jepang di sabuk asteroid</a></li>
<li><a href="../id428263/index.html">‚ÄúSaya memiliki tangan yang sangat kurus‚Äù: gamer profesional pergi ke gym</a></li>
<li><a href="../id428265/index.html">Kami mendapatkan akses ke desktop WinCE dan menjalankan Doom pada osiloskop Keysight DSOX1102G</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶á üë¶üèª üë®‚Äçüéì Experimentos com redes neurais baseadas em dados s√≠smicos üòß üßóüèæ üêÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A complexidade da interpreta√ß√£o dos dados s√≠smicos se deve ao fato de que, para cada tarefa, √© necess√°rio procurar uma abordagem individual, pois cada...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Experimentos com redes neurais baseadas em dados s√≠smicos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/482780/">  A complexidade da interpreta√ß√£o dos dados s√≠smicos se deve ao fato de que, para cada tarefa, √© necess√°rio procurar uma abordagem individual, pois cada conjunto desses dados √© √∫nico.  O processamento manual requer custos trabalhistas significativos, e o resultado geralmente cont√©m erros relacionados ao fator humano.  O uso de redes neurais para interpreta√ß√£o pode reduzir significativamente o trabalho manual, mas a singularidade dos dados imp√µe restri√ß√µes √† automa√ß√£o deste trabalho. <br><br>  Este artigo descreve um experimento para analisar a aplicabilidade de redes neurais para automatizar a aloca√ß√£o de camadas geol√≥gicas em imagens 2D usando dados totalmente rotulados do Mar do Norte como exemplo. <br><br><img src="https://habrastorage.org/webt/rs/vp/ky/rsvpky5vebdp4xtive1ywcvtvtk.png" alt="Pesquisas qu√≠micas √† base de √°gua"><br>  Figura 1. Levantamentos s√≠smicos aquat√≥rios ( <a href="https://www.nationalgeographic.com/news/2010/4/100407-energy-undersea-sound/">fonte</a> ) <br><a name="habracut"></a><br><h2>  Um pouco sobre a √°rea de assunto </h2><br>  A explora√ß√£o s√≠smica √© um m√©todo geof√≠sico para o estudo de objetos geol√≥gicos usando vibra√ß√µes el√°sticas - ondas s√≠smicas.  Este m√©todo baseia-se no fato de que a velocidade de propaga√ß√£o das ondas s√≠smicas depende das propriedades do ambiente geol√≥gico em que elas se propagam (composi√ß√£o rochosa, porosidade, fratura, satura√ß√£o da umidade etc.). Passando por camadas geol√≥gicas com propriedades diferentes, as ondas s√≠smicas s√£o refletidas objetos diferentes e retornados ao receptor (veja a Figura 1).  Sua natureza √© registrada e, ap√≥s o processamento, √© poss√≠vel formar uma imagem bidimensional - uma se√ß√£o s√≠smica ou um conjunto de dados tridimensionais - um cubo s√≠smico. <br><br><img src="https://habrastorage.org/webt/xi/dn/4p/xidn4psxaiynjkoqtvw3ctogcqq.gif" alt="Exemplo de cubo s√≠smico"><br>  Figura 2. Um exemplo de um cubo s√≠smico ( <a href="http://cge.rosgeo.com/en/services/glubinnaya-3d-migraciya-do-summirovaniya/">origem</a> ) <br><br>  O eixo horizontal do cubo s√≠smico est√° localizado ao longo da superf√≠cie da Terra e a vertical representa a profundidade ou o tempo (veja a Figura 2).  Em alguns casos, o cubo √© dividido em se√ß√µes verticais ao longo do eixo dos geofones (as chamadas linhas internas, linhas internas) ou transversalmente (linhas transversais, linhas transversais, linhas x).  Cada cubo vertical (e fatia) √© um tra√ßo s√≠smico separado. <br><br>  Assim, linhas e linhas cruzadas consistem nas mesmas trilhas s√≠smicas, apenas em uma ordem diferente.  As trilhas s√≠smicas adjacentes s√£o muito semelhantes umas √†s outras.  Uma mudan√ßa mais dram√°tica ocorre nos pontos de falha, mas ainda haver√° semelhan√ßas.  Isso significa que as fatias vizinhas s√£o muito semelhantes umas √†s outras. <br><br>  Todo esse conhecimento nos ser√° √∫til ao planejar experimentos. <br><br><h2>  A tarefa de interpreta√ß√£o e o papel das redes neurais em sua solu√ß√£o </h2><br>  Os dados obtidos s√£o processados ‚Äã‚Äãmanualmente por int√©rpretes que identificam diretamente no cubo ou em cada fatia suas camadas geol√≥gicas individuais de rochas e seus limites (horizontes, horizontes), dep√≥sitos de sal, falhas e outras caracter√≠sticas da estrutura geol√≥gica da √°rea estudada.  O int√©rprete, trabalhando com um cubo ou fatia, inicia seu trabalho com uma sele√ß√£o manual cuidadosa de camadas e horizontes geol√≥gicos.  Cada horizonte deve ser despertado manualmente (da cole√ß√£o ‚Äúpicking‚Äù) em ingl√™s, apontando o cursor e clicando no mouse. <br><br><img src="https://habrastorage.org/webt/w6/j3/gn/w6j3gnflms5vqyxc3mbjdnzsaam.png" alt="Um exemplo de uma fatia 2D (esquerda) e o resultado da marca√ß√£o das camadas geol√≥gicas correspondentes (direita)"><br>  Figura 3. Um exemplo de uma fatia 2D (esquerda) e o resultado da marca√ß√£o das camadas geol√≥gicas correspondentes (direita) ( <a href="https://arxiv.org/pdf/1904.00770v1.pdf">origem</a> ) <br><br>  O principal problema est√° relacionado ao crescente volume de dados s√≠smicos obtidos a cada ano em condi√ß√µes geol√≥gicas cada vez mais complexas (por exemplo, se√ß√µes subaqu√°ticas com grandes profundidades do mar) e √† ambiguidade de interpreta√ß√£o desses dados.  Al√©m disso, em condi√ß√µes de prazos apertados e / ou grandes volumes, o int√©rprete inevitavelmente comete erros, por exemplo, perde v√°rias caracter√≠sticas da se√ß√£o geol√≥gica. <br><br>  Esse problema pode ser parcialmente resolvido com a ajuda de redes neurais, reduzindo significativamente o trabalho manual, agilizando o processo de interpreta√ß√£o e reduzindo o n√∫mero de erros.  Para a opera√ß√£o da rede neural, √© necess√°rio um certo n√∫mero de se√ß√µes rotuladas prontas (se√ß√µes do cubo) e, como resultado, ser√° obtida uma marca√ß√£o completa de todas as se√ß√µes (ou todo o cubo), o que idealmente exigir√° apenas um refinamento menor por uma pessoa para ajustar determinadas se√ß√µes dos horizontes ou re-marcar pequenas √°reas que a rede n√£o p√¥de reconhecer corretamente. <br><br>  Existem muitas solu√ß√µes para os problemas de interpreta√ß√£o usando redes neurais, aqui est√£o apenas alguns exemplos: <a href="https://arxiv.org/abs/1903.11215">um</a> , <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">dois</a> , <a href="">tr√™s</a> .  A dificuldade reside no fato de que cada conjunto de dados √© √∫nico - devido √†s peculiaridades das rochas geol√≥gicas da regi√£o estudada, devido a v√°rios meios e m√©todos t√©cnicos de explora√ß√£o s√≠smica, devido aos v√°rios m√©todos usados ‚Äã‚Äãpara transformar dados brutos em dados prontos.  Mesmo devido a ru√≠dos externos (por exemplo, um cachorro latindo e outros sons altos), que nem sempre s√£o poss√≠veis de serem removidos completamente.  Portanto, cada tarefa deve ser resolvida individualmente. <br><br>  Mas, apesar disso, numerosos trabalhos tornam poss√≠vel procurar abordagens gerais separadas para resolver v√°rios problemas de interpreta√ß√£o. <br><br>  Na <a href="https://maritimeai.net/">MaritimeAI</a> (um projeto desenvolvido a partir da <a href="http://ods.ai/">comunidade ODS de</a> Aprendizado de M√°quina para Bens Sociais, <a href="https://habr.com/ru/company/ods/blog/454964/">um artigo sobre n√≥s</a> ) para cada zona de nosso campo de interesse (pesquisa mar√≠tima), estudamos trabalhos j√° publicados e realizamos nossos pr√≥prios experimentos, permitindo esclarecer os limites e caracter√≠sticas da aplica√ß√£o de certas solu√ß√µes e, √†s vezes, encontre suas pr√≥prias abordagens. <br><br>  Os resultados de um experimento que descrevemos neste artigo. <br><br><h2>  Objetivos de pesquisa de neg√≥cios </h2><br>  Basta que um especialista em ci√™ncia de dados d√™ uma olhada na Figura 3 para dar um suspiro de al√≠vio - uma tarefa comum de segmenta√ß√£o de imagem sem√¢ntica, para a qual muitas arquiteturas de redes neurais e m√©todos de ensino foram inventados.  Voc√™ s√≥ precisa escolher os corretos e treinar a rede. <br><br>  Mas n√£o √© t√£o simples. <br><br>  Para obter um bom resultado com a ajuda de uma rede neural, voc√™ precisa, tanto quanto poss√≠vel, de dados j√° marcados nos quais ela aprender√°.  Mas nossa tarefa √© precisamente reduzir a quantidade de trabalho manual.  E raramente √© poss√≠vel usar dados marcados de outras regi√µes devido √†s fortes diferen√ßas na estrutura geol√≥gica. <br><br>  Traduzimos o que foi dito acima para o idioma dos neg√≥cios. <br><br>  Para que o uso de redes neurais seja economicamente justificado, √© necess√°rio minimizar a quantidade de interpreta√ß√£o manual prim√°ria e refinamentos dos resultados obtidos.  Por√©m, reduzir os dados para o treinamento da rede afetar√° negativamente a qualidade de seu resultado.  Assim, uma rede neural pode acelerar e facilitar o trabalho dos int√©rpretes e melhorar a qualidade das imagens marcadas?  Ou apenas complicar o processo usual? <br><br>  O objetivo deste estudo √© uma tentativa de determinar o volume m√≠nimo suficiente de dados de cubos s√≠smicos marcados para uma rede neural e avaliar os resultados obtidos.  Tentamos encontrar respostas para as seguintes perguntas, que devem ajudar os "propriet√°rios" dos resultados da pesquisa s√≠smica a decidir sobre a interpreta√ß√£o manual ou parcialmente automatizada: <br><br><ol><li>  Quantos dados os especialistas precisam marcar para treinar uma rede neural?  E que dados devem ser escolhidos para isso? </li><li>  O que acontece com essa sa√≠da?  O refinamento manual das previs√µes de redes neurais ser√° necess√°rio?  Em caso afirmativo, qu√£o complexo e volumoso? </li></ol><br><h2>  Descri√ß√£o geral do experimento e os dados utilizados </h2><br>  Para o experimento, selecionamos um dos problemas de interpreta√ß√£o, a tarefa de isolar camadas geol√≥gicas em se√ß√µes 2D de um cubo s√≠smico (veja a Figura 3).  J√° tentamos resolver esse problema (veja <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">aqui</a> ) e, de acordo com os autores, obtivemos um bom resultado para 1% das fatias selecionadas aleatoriamente.  Dado o volume do cubo, s√£o 16 imagens.  No entanto, o artigo n√£o fornece m√©tricas para compara√ß√£o e n√£o h√° descri√ß√£o da metodologia de treinamento (fun√ß√£o de perda, otimizador, esquema para alterar a velocidade de aprendizado etc.), o que torna o experimento improdut√≠vel. <br><br>  Al√©m disso, em nossa opini√£o, os resultados apresentados s√£o insuficientes para obter respostas completas √†s quest√µes colocadas.  Esse valor √© ideal em 1%?  Ou talvez para outra amostra de fatias seja diferente?  Posso selecionar menos dados?  Vale a pena levar mais?  Como o resultado mudar√°?  Etc. <br><br>  Para o experimento, pegamos o mesmo conjunto de dados completamente rotulados do setor holand√™s do Mar do Norte.  Os dados s√≠smicos de origem est√£o dispon√≠veis no site do Open Seismic Repository: <a href="https://terranubis.com/datainfo/Netherlands-Offshore-F3-Block-Complete">Project Netherlands Offshore F3 Block</a> .  Uma breve descri√ß√£o pode ser encontrada em <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Silva et al.</a>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">"Conjunto de dados da Holanda: um novo conjunto de dados p√∫blico para aprendizado de m√°quina na interpreta√ß√£o s√≠smica</a> . <a href="https://arxiv.org/pdf/1904.00770v1.pdf">"</a> <br><br>  Como no nosso caso, estamos falando de fatias 2D, n√£o usamos o cubo 3D original, mas a ‚Äúfatia‚Äù j√° feita, dispon√≠vel aqui: <a href="https://zenodo.org/record/1471548">Conjunto de dados de interpreta√ß√£o F3 da Holanda</a> . <br><br>  Durante o experimento, resolvemos as seguintes tarefas: <br><br><ol><li>  Analisamos os dados de origem e selecionamos as fatias, que t√™m a qualidade mais pr√≥xima da marca√ß√£o manual. </li><li>  Registramos a arquitetura da rede neural, a metodologia e os par√¢metros do treinamento e o princ√≠pio de selecionar fatias para treinamento e valida√ß√£o. </li><li>  Treinamos 20 redes neurais id√™nticas em diferentes volumes de dados do mesmo tipo de fatias para comparar os resultados. </li><li>  Treinamos outras 20 redes neurais em uma quantidade diferente de dados de diferentes tipos de se√ß√µes para comparar os resultados. </li><li>  Estimada a quantidade de refinamento manual necess√°rio dos resultados da previs√£o. </li></ol><br>  Os resultados do experimento na forma de m√©tricas estimadas e previstas pelas redes de m√°scaras de fatia s√£o apresentados abaixo. <br><br><h2>  Tarefa 1. Sele√ß√£o de dados </h2><br>  Assim, como dados iniciais, usamos linhas e linhas cruzadas prontas do cubo s√≠smico do setor holand√™s do Mar do Norte.  Uma an√°lise detalhada mostrou que tudo n√£o est√° indo bem - h√° muitas imagens e m√°scaras com artefatos e at√© mesmo gravemente distorcidas (veja as Figuras 4 e 5). <br><br><img src="https://habrastorage.org/webt/0d/d-/iv/0dd-iveosyikwl35e4uylytlnss.png" alt="Exemplo de m√°scara de artefato"><br>  Figura 4. Exemplo de m√°scara com artefatos <br><br><img src="https://habrastorage.org/webt/iz/_k/3j/iz_k3jbbvf4adnpgbzmehevzegm.png" alt="Exemplo de m√°scara distorcida"><br>  Figura 5. Um exemplo de uma m√°scara distorcida <br><br>  Com a marca√ß√£o manual, nada disso ser√° observado.  Portanto, simulando o trabalho do int√©rprete, para treinar a rede, escolhemos apenas m√°scaras limpas, tendo analisado todas as fatias.  Como resultado, 700 linhas cruzadas e 400 linhas foram selecionadas. <br><br><h2>  Tarefa 2. Corrigindo os par√¢metros do experimento </h2><br>  Esta se√ß√£o √© de interesse, antes de tudo, para especialistas em Data Science, portanto, terminologia apropriada ser√° usada. <br><br>  Como inline e crosslines consistem nos mesmos tra√ßos s√≠smicos, duas hip√≥teses mutuamente exclusivas podem ser apresentadas: <br><br><ol><li>  O treinamento pode ser realizado apenas em um tipo de fatias (por exemplo, in-line), usando imagens de outro tipo como uma sele√ß√£o atrasada.  Isso dar√° uma avalia√ß√£o mais adequada do resultado, porque  as fatias restantes do mesmo tipo que foram usadas no treinamento ainda ser√£o semelhantes √†s do treinamento. </li><li>  Para o treinamento, √© melhor usar uma mistura de fatias de diferentes tipos, pois isso j√° √© um aumento. </li></ol><br>  Confira. <br><br>  Al√©m disso, a semelhan√ßa de fatias vizinhas do mesmo tipo e o desejo de obter um resultado reproduz√≠vel nos levaram a uma estrat√©gia para selecionar fatias para treinamento e valida√ß√£o, n√£o por um princ√≠pio arbitr√°rio, mas de maneira uniforme em todo o cubo, ou seja,  para que as fatias estejam o mais afastadas poss√≠vel e, portanto, cubram a variedade m√°xima de dados. <br><br>  Para valida√ß√£o, foram utilizadas 2 fatias, igualmente distribu√≠das entre imagens adjacentes da amostra de treinamento.  Por exemplo, no caso de uma amostra de treinamento de 3 linhas, a amostra de valida√ß√£o consistia em 4 linhas, para 3 linhas e 3 linhas cruzadas, de 8 fatias, respectivamente. <br><br>  Como resultado, realizamos 2 s√©ries de treinamentos: <br><br><ol><li>  Treinamento em amostras de linhas de 3 a 20 fatias distribu√≠das uniformemente pelo cubo, com verifica√ß√£o do resultado das previs√µes de rede nas linhas restantes e em todas as linhas cruzadas.  Al√©m disso, foi realizado treinamento nas se√ß√µes 80 e 160. </li><li>  Treinamento em amostras combinadas de linhas e linhas cruzadas de 3 a 10 se√ß√µes de cada tipo distribu√≠das uniformemente em um cubo com verifica√ß√£o do resultado das previs√µes de rede nas imagens restantes.  Al√©m disso, o treinamento foi realizado nas se√ß√µes 40 + 40 e 80 + 80. </li></ol><br>  Com essa abordagem, √© necess√°rio levar em considera√ß√£o que os tamanhos das amostras de treinamento e valida√ß√£o variam significativamente, o que complica a compara√ß√£o, mas o volume das imagens restantes n√£o √© reduzido tanto que pode ser usado para avaliar adequadamente as altera√ß√µes no resultado. <br><br>  Para reduzir o treinamento para a amostra de treinamento, o aumento foi utilizado com tamanho de colheita arbitr√°rio 448x64 e imagem espelhada ao longo do eixo vertical, com probabilidade de 0,5. <br><br>  Como estamos interessados ‚Äã‚Äãna depend√™ncia da qualidade do resultado apenas no n√∫mero de fatias na amostra de treinamento, o pr√©-processamento de imagens pode ser negligenciado.  Usamos uma √∫nica camada de imagens PNG sem nenhuma altera√ß√£o. <br><br>  Pelo mesmo motivo, dentro da estrutura deste experimento, n√£o h√° necessidade de procurar a melhor arquitetura de rede - o principal √© que seja a mesma em todas as etapas.  Escolhemos um UNet simples mas bem estabelecido para essas tarefas: <br><br><img src="https://habrastorage.org/webt/i0/jg/fs/i0jgfsxjgo5nibyatbaokikg0tg.png" alt="Arquitetura de rede"><br>  Figura 6. Arquitetura de rede <br><br>  A fun√ß√£o de perda consistia em uma combina√ß√£o do coeficiente de Jacquard e entropia cruzada bin√°ria: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">jaccard_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smoothing = <span class="hljs-number"><span class="hljs-number">1.</span></span> intersection = tf.reduce_sum(y_true * y_pred, axis = (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) union = tf.reduce_sum(y_true + y_pred, axis = (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) jaccard = (intersection + smoothing) / (union - intersection + smoothing) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - tf.reduce_mean(jaccard) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0.75</span></span> * jaccard_loss(y_true, y_pred) + <span class="hljs-number"><span class="hljs-number">0.25</span></span> * keras.losses.binary_crossentropy(y_true, y_pred)</code> </pre> <br>  Outras op√ß√µes de aprendizado: <br><br><pre> <code class="python hljs">keras.optimizers.SGD(lr = <span class="hljs-number"><span class="hljs-number">0.01</span></span>, momentum = <span class="hljs-number"><span class="hljs-number">0.9</span></span>, nesterov = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) keras.callbacks.EarlyStopping(monitor = <span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience = <span class="hljs-number"><span class="hljs-number">10</span></span>), keras.callbacks.ReduceLROnPlateau(monitor = <span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience = <span class="hljs-number"><span class="hljs-number">5</span></span>)</code> </pre> <br>  Para reduzir a influ√™ncia da aleatoriedade da escolha dos pesos iniciais nos resultados, a rede foi treinada em 3 linhas por 1 era.  Todos os outros treinamentos come√ßaram com esses pesos recebidos. <br><br>  Cada rede foi treinada na GeForce GTX 1060 6Gb por 30 a 60 √©pocas.  O treinamento de cada √©poca levou de 10 a 30 segundos, dependendo do tamanho da amostra. <br><br><h2>  Tarefa 3. Treinamento em um tipo de fatias (linhas) </h2><br>  A primeira s√©rie consistiu em 18 treinamentos de rede independentes em 3-20 linhas.  E, embora estejamos interessados ‚Äã‚Äãapenas em estimar o coeficiente de Jacquard em fatias n√£o utilizadas no treinamento e na valida√ß√£o, √© interessante considerar todos os gr√°ficos. <br><br>  Lembre-se de que os resultados da interpreta√ß√£o para cada fatia s√£o 10 classes (camadas geol√≥gicas), que nas figuras s√£o marcadas com n√∫meros de 0 a 9. <br><br><img src="https://habrastorage.org/webt/g0/1o/tm/g01otmt3jodludsk-puf_fv1kic.png" alt="Coeficiente de jacquard para conjunto de treinamento"><br>  Figura 7. Coeficiente de jacquard para o conjunto de treinamento <br><br><img src="https://habrastorage.org/webt/e9/fs/g7/e9fsg7p5aemva9-k7g_jruodo6m.png" alt="Coeficiente de Jacquard para amostra de valida√ß√£o"><br>  Figura 8. Coeficiente de jacquard para amostra de valida√ß√£o <br><br><img src="https://habrastorage.org/webt/qe/di/av/qediavhy6nbnjmci8-whfxyocuy.png" alt="Coeficiente de jacquard para outras linhas"><br>  Figura 9. Coeficiente de Jacquard para as demais linhas <br><br><img src="https://habrastorage.org/webt/h_/qm/2n/h_qm2n3v5fapcqprdjluppb1-cy.png" alt="Coeficiente de jacquard para linhas cruzadas"><br>  Figura 10. Coeficiente de jacquard para linhas cruzadas <br><br>  V√°rias conclus√µes podem ser tiradas dos diagramas acima. <br><br>  Em primeiro lugar, a qualidade da previs√£o, medida pelo coeficiente Jacquard, j√° em 9 linhas, atinge um valor muito alto, ap√≥s o qual continua a crescer, mas n√£o de forma t√£o intensa.  I.e.  a hip√≥tese da sufici√™ncia de um pequeno n√∫mero de imagens rotuladas para o treinamento de uma rede neural √© confirmada. <br><br>  Em segundo lugar, foi obtido um resultado muito alto para as linhas cruzadas, apesar de apenas linhas serem usadas para treinamento e valida√ß√£o - a hip√≥tese da sufici√™ncia de apenas um tipo de fatias tamb√©m √© confirmada.  No entanto, para a conclus√£o final, voc√™ precisa comparar os resultados com o treinamento em uma mistura de linhas e linhas cruzadas. <br><br>  Em terceiro lugar, m√©tricas para diferentes camadas, ou seja,  A qualidade do seu reconhecimento √© muito diferente.  Isso leva √† id√©ia de escolher uma estrat√©gia de aprendizado diferente, por exemplo, usando pesos ou redes adicionais para turmas fracas, ou um esquema completo de ‚Äúum contra todos‚Äù. <br><br>  E, finalmente, deve-se notar que o coeficiente de Jacquard n√£o pode fornecer uma descri√ß√£o completa da qualidade do resultado.  Para avaliar as previs√µes de rede nesse caso, √© melhor examinar as pr√≥prias m√°scaras para avaliar sua adequa√ß√£o √† revis√£o pelo int√©rprete. <br><br>  As figuras a seguir mostram a marca√ß√£o por uma rede treinada em 10 linhas.  A segunda coluna, marcada como ‚Äúm√°scara GT‚Äù (m√°scara Ground Truth), representa a interpreta√ß√£o do alvo, a terceira √© a previs√£o da rede neural. <br><br><img src="https://habrastorage.org/webt/ub/pa/6t/ubpa6tj0p0gfe0ixdoysku8_bzw.png" alt="Exemplos de configura√ß√µes de rede para linhas inline"><br><img src="https://habrastorage.org/webt/me/fi/mu/mefimu03q9gzh_hcdomwrtagwm0.png" alt="Exemplos de configura√ß√µes de rede para linhas inline"><br>  Figura 11. Exemplos de previs√µes de rede para linhas inline <br><br><img src="https://habrastorage.org/webt/7l/25/5_/7l255_ofscuyfhozqokfiw5ifjk.png" alt="Exemplos de configura√ß√µes de rede para linhas cruzadas"><br><img src="https://habrastorage.org/webt/eh/kd/hw/ehkdhwyuzl0j_sl5rhy-6m0613k.png" alt="Exemplos de configura√ß√µes de rede para linhas cruzadas"><br>  Figura 12. Exemplos de previs√µes de rede para linhas cruzadas <br><br>  Pode-se ver pelas figuras que, junto com m√°scaras bastante limpas, √© dif√≠cil reconhecer casos complexos na rede, mesmo nas pr√≥prias linhas.  Assim, apesar da m√©trica alta o suficiente para 10 fatias, parte dos resultados exigir√° refinamento significativo. <br><br>  Os tamanhos de amostra considerados por n√≥s flutuam em torno de 1% do volume total de dados - e isso j√° permite marcar parte das fatias restantes muito bem.  Devo aumentar o n√∫mero de se√ß√µes marcadas inicialmente?  Isso dar√° um aumento compar√°vel na qualidade? <br><br>  Considere a din√¢mica das altera√ß√µes nos resultados da previs√£o por redes treinadas nas linhas 5, 10, 15, 20, 80 (5% do volume total do cubo) e 160 (10%) usando as mesmas se√ß√µes do exemplo. <br><br><img src="https://habrastorage.org/webt/4c/aw/ye/4cawye-bfzessxxllovzxb1-gne.png" alt="Exemplos de modifica√ß√µes de redes de treinamento em diferentes volumes de amostra de treinamento"><br>  Figura 13. Exemplos de previs√µes de redes treinadas em diferentes volumes da amostra de treinamento <br><br>  A Figura 13 mostra que um aumento no volume da amostra de treinamento em 5 ou 10 vezes n√£o leva a uma melhoria significativa.  Fatias que j√° s√£o bem reconhecidas em 10 imagens de treinamento n√£o pioram. <br><br>  Assim, mesmo uma rede simples sem ajuste e pr√©-processamento de imagens √© capaz de interpretar parte das fatias com uma qualidade suficientemente alta com um pequeno n√∫mero de imagens marcadas manualmente.  Consideraremos a quest√£o da participa√ß√£o de tais interpreta√ß√µes e a complexidade de finalizar fatias mal reconhecidas. <br><br>  A sele√ß√£o cuidadosa da arquitetura, os par√¢metros de rede e o treinamento, o pr√©-processamento de imagens podem melhorar esses resultados no mesmo volume de dados marcados.  Mas isso j√° est√° al√©m do escopo do experimento atual. <br><br><h2>  Tarefa 4. Treinamento em diferentes tipos de fatias (linhas e linhas cruzadas) </h2><br>  Agora vamos comparar os resultados desta s√©rie com as previs√µes obtidas pelo treinamento em uma mistura de linhas e linhas cruzadas. <br><br>  Os diagramas abaixo mostram estimativas do coeficiente de Jacquard para diferentes amostras, incluindo, em compara√ß√£o com os resultados das s√©ries anteriores.  Para compara√ß√£o (veja os diagramas corretos nas figuras), apenas amostras do mesmo volume foram coletadas, ou seja,  10 linhas versus 5 linhas + 5 linhas cruzadas, etc. <br><br><img src="https://habrastorage.org/webt/4q/df/qr/4qdfqrbxrh9_blq0e-5rgoh_z14.png" alt="Coeficiente de jacquard para conjunto de treinamento"><br>  Figura 14. Coeficiente de Jacquard para o conjunto de treinamento <br><br><img src="https://habrastorage.org/webt/s6/uh/pr/s6uhprjziuoobasc5gl0wak7h9y.png" alt="Coeficiente de Jacquard para amostra de valida√ß√£o"><br>  Figura 15. Coeficiente de jacquard para amostra de valida√ß√£o <br><br><img src="https://habrastorage.org/webt/hu/c5/dv/huc5dv9_k7dgwphwygzhypzwpxy.png" alt="Coeficiente de jacquard para outras linhas"><br>  Figura 16. Coeficiente de jacquard para as demais linhas <br><br><img src="https://habrastorage.org/webt/rx/c3/tz/rxc3tzlw5synjdwoj1j97aj56xy.png" alt="Coeficiente de jacquard para o restante das linhas cruzadas"><br>  Figura 17. Coeficiente de jacquard para as demais linhas cruzadas <br><br>  Os diagramas ilustram claramente que a adi√ß√£o de fatias de um tipo diferente n√£o melhora os resultados.  Mesmo no contexto de classes (veja a Figura 18), a influ√™ncia das linhas cruzadas n√£o √© observada para nenhum dos tamanhos de amostra considerados. <br><br><img src="https://habrastorage.org/webt/0z/yx/sh/0zyxshghib81lkvjqe6le4sgute.png" alt="Coeficiente de jacquard para diferentes classes (ao longo do eixo X) e diferentes tamanhos e composi√ß√£o da amostra de treinamento"><br>  Figura 18. Coeficiente de jacquard para diferentes classes (ao longo do eixo X) e diferentes tamanhos e composi√ß√£o da amostra de treinamento <br><br>  Para concluir a imagem, comparamos os resultados da previs√£o de rede nas mesmas fatias: <br><br><img src="https://habrastorage.org/webt/2q/qh/wn/2qqhwnj0_lemjeaog44lunjbw8g.png" alt="Compara√ß√£o de previs√µes de rede para inline"><br>  Figura 19. Compara√ß√£o de previs√µes de rede para inline <br><br><img src="https://habrastorage.org/webt/8f/gk/vm/8fgkvmw0860finev7nzkuuwsfmc.png" alt="Compara√ß√£o de previs√µes de rede para linhas cruzadas"><br>  Figura 20. Compara√ß√£o de previs√µes de rede para linhas cruzadas <br><br>  Uma compara√ß√£o visual confirma a suposi√ß√£o de que adicionar tipos diferentes de fatias ao treinamento n√£o altera fundamentalmente a situa√ß√£o.  Algumas melhorias s√≥ podem ser observadas para a linha cruzada esquerda, mas s√£o globais?  Vamos tentar responder mais a essa pergunta. <br><br><h2>  Tarefa 5. Avalia√ß√£o do volume de refinamento manual </h2><br>  Para uma conclus√£o final sobre os resultados, √© necess√°rio estimar a quantidade de refinamento manual das previs√µes de rede obtidas.  Para isso, determinamos o n√∫mero de componentes conectados (ou seja, pontos s√≥lidos da mesma cor) em cada previs√£o obtida.  Se esse valor for 10, as camadas ser√£o selecionadas corretamente e estamos falando de um m√°ximo de corre√ß√£o menor do horizonte.  Se n√£o houver muito mais, voc√™ s√≥ precisar√° "limpar" as pequenas √°reas da imagem.  Se houver substancialmente mais deles, tudo est√° ruim e pode at√© precisar de um re-layout completo. <br><br>  Para o teste, selecionamos 110 linhas e 360 ‚Äã‚Äãlinhas que n√£o foram usadas no treinamento de nenhuma das redes consideradas. <br><br>  Tabela 1. Estat√≠sticas calculadas para ambos os tipos de fatias <br><img src="https://habrastorage.org/webt/ov/b8/fs/ovb8fsaxxqbwea4jn4_pw_dsd_e.png" alt="Estat√≠sticas calculadas para ambos os tipos de fatias"><br><br>  A tabela 1 confirma alguns dos resultados anteriores.  Em particular, ao usar fatias de 1% para treinamento, n√£o h√° diferen√ßa, use um tipo de fatias ou ambas, e o resultado pode ser caracterizado da seguinte maneira: <br><br><ul><li>  cerca de 10% das previs√µes est√£o pr√≥ximas do ideal, ou seja,  n√£o requerem mais do que ajustes em se√ß√µes individuais dos horizontes; </li><li>  50% das previs√µes n√£o cont√™m mais de 15 pontos, ou seja,  n√£o mais que 5 extras; </li><li>  75% das previs√µes n√£o cont√™m mais de 20 pontos, ou seja,  n√£o mais que 10 extras; </li><li>  os 25% restantes das previs√µes exigem refinamentos mais substanciais, incluindo, possivelmente, uma reformula√ß√£o completa de fatias individuais. </li></ul><br>  Um aumento no tamanho da amostra de at√© 5% altera a situa√ß√£o.  Em particular, as redes treinadas em uma mistura de se√ß√µes mostram indicadores significativamente mais altos, embora o valor m√°ximo dos componentes tamb√©m aumente, o que indica a apar√™ncia de interpreta√ß√µes separadas de qualidade muito ruim.  No entanto, se voc√™ aumentar a amostra em 5 vezes e usar uma mistura de fatias: <br><br><ul><li>  cerca de 30% das previs√µes est√£o pr√≥ximas do ideal, ou seja,  n√£o requerem mais do que ajustes em se√ß√µes individuais dos horizontes; </li><li>  50% das previs√µes n√£o cont√™m mais de 12 pontos, ou seja,  n√£o mais que 2 extras; </li><li>  75% das previs√µes n√£o cont√™m mais de 14 pontos, ou seja,  n√£o mais que 4 extras; </li><li>  os 25% restantes das previs√µes exigem refinamentos mais substanciais, incluindo, possivelmente, uma reformula√ß√£o completa de fatias individuais. </li></ul><br>  Um aumento adicional no tamanho da amostra n√£o leva a melhores resultados. <br><br>  Em geral, para o cubo de dados que examinamos, podemos tirar conclus√µes sobre a sufici√™ncia de 1 a 5% do volume total de dados para obter um bom resultado de uma rede neural. <br><br>  De acordo com esses dados, em conjunto com as m√©tricas e ilustra√ß√µes acima, j√° √© poss√≠vel tirar conclus√µes sobre a conveni√™ncia de usar redes neurais para ajudar int√©rpretes e sobre os resultados com os quais os especialistas lidar√£o. <br><br><h2>  Conclus√µes </h2><br>  Portanto, agora podemos responder √†s perguntas colocadas no in√≠cio do artigo, usando os resultados obtidos no exemplo de um cubo s√≠smico do Mar do Norte: <br><br>  <b>Quantos dados os especialistas precisam marcar para treinar uma rede neural?</b>  <b>E quais dados devo escolher?</b> <br><br>  Para obter uma boa previs√£o da rede, basta pr√©-marcar de 1 a 5% do n√∫mero total de fatias.  Um aumento adicional no volume n√£o leva a uma melhoria no resultado, compar√°vel ao aumento no n√∫mero de dados marcados anteriormente.  Para obter uma melhor marca√ß√£o em um volume t√£o pequeno usando uma rede neural, √© necess√°rio tentar outras abordagens, por exemplo, ajustar a arquitetura e estrat√©gias de aprendizado, pr√©-processamento de imagem, etc. <br><br>  Para marca√ß√£o preliminar, vale a pena escolher fatias de ambos os tipos - linhas e linhas cruzadas. <br><br>  <b>O que acontece com essa sa√≠da?</b>  <b>O refinamento manual das previs√µes de redes neurais ser√° necess√°rio?</b>  <b>Em caso afirmativo, qu√£o complexo e volumoso?</b> <b><br></b> <br>  Como resultado, uma parte significativa das imagens rotuladas por uma rede neural n√£o exigir√° o refinamento mais significativo, consistindo na corre√ß√£o de zonas individuais pouco reconhecidas.  Entre eles, haver√° interpreta√ß√µes que n√£o exigir√£o corre√ß√µes.  E apenas para imagens √∫nicas, pode ser necess√°rio um novo layout manual. <br><br>  Obviamente, ao otimizar o algoritmo de aprendizagem e os par√¢metros de rede, seus recursos preditivos podem ser aprimorados.  Em nosso experimento, a solu√ß√£o de tais problemas n√£o foi inclu√≠da. <br><br>  Al√©m disso, os resultados de um estudo em um cubo s√≠smico n√£o devem ser generalizados sem pensar - precisamente devido √† singularidade de cada conjunto de dados.  Mas esses resultados s√£o a confirma√ß√£o de um experimento realizado por outros autores e a base para compara√ß√£o com nossos estudos subsequentes, sobre os quais tamb√©m escreveremos em breve. <br><br><h2>  Agradecimentos </h2><br>  E, no final, gostaria de agradecer aos meus colegas da <a href="https://maritimeai.net/">MaritimeAI</a> (especialmente Andrey Kokhan) e da <a href="http://ods.ai/">ODS</a> pelos valiosos coment√°rios e ajuda! <br><br><h2>  Lista de fontes utilizadas: </h2><br><ol><li>  <a href="https://arxiv.org/abs/1903.11215">Bas Peters, Eldad Haber, Justin Granek.</a>  <a href="https://arxiv.org/abs/1903.11215">Redes neurais para geof√≠sicos e sua aplica√ß√£o na interpreta√ß√£o de dados s√≠smicos</a> </li><li>  <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">Hao Wu, Bo Zhang.</a>  <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">Uma profunda rede neural convolucional codificador-decodificador para auxiliar o rastreamento de horizonte s√≠smico</a> </li><li>  <a href="">Thilo Wrona, Indranil Pan, Robert L. Gawthorpe e Haakon Fossen.</a>  <a href="">An√°lise s√≠smica de f√°cies usando aprendizado de m√°quina</a> </li><li>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Reinaldo Mozart Silva, Lais Baroni, Rodrigo S. Ferreira, Daniel Civitarese, Daniela Szwarcman, Emilio Vital Brazil.</a>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Conjunto de dados na Holanda: um novo conjunto de dados p√∫blico para aprendizado de m√°quina na interpreta√ß√£o s√≠smica</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt482780/">https://habr.com/ru/post/pt482780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt482762/index.html">42.000.000.000 de visitas. O PornHub resumiu 2019</a></li>
<li><a href="../pt482764/index.html">O Rhasspy √© um kit de ferramentas de fala de c√≥digo aberto e totalmente offline. Reconhecimento da l√≠ngua russa. Sem vazamentos para a nuvem</a></li>
<li><a href="../pt482772/index.html">Aplica√ß√µes Web progressivas em 2020</a></li>
<li><a href="../pt482774/index.html">Seoshniki preto e melhores m√©todos de promo√ß√£o. Adulto, farm√°cia, ensaios, namoro. Shestakov Pessoas PRO # 75</a></li>
<li><a href="../pt482778/index.html">Ventila√ß√£o com recupera√ß√£o no apartamento. Sem dutos e SMS</a></li>
<li><a href="../pt482784/index.html">A vida secreta de um servidor Linux ou ataque de for√ßa bruta de f√£ no subsistema SSH</a></li>
<li><a href="../pt482786/index.html">Enigma n√£o resolvido</a></li>
<li><a href="../pt482790/index.html">Esque√ßa a criptografia homom√≥rfica: agora temos a criptografia funcional</a></li>
<li><a href="../pt482792/index.html">Projeto ITER em 2019</a></li>
<li><a href="../pt482794/index.html">Redes neurais. Para onde tudo isso vai</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
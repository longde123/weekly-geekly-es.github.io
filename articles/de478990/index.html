<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏾‍🤝‍👨🏻 👩🏿‍🏫 👸🏼 Installation eines verteilten ausfallsicheren LeoFS-Speichers, der mit Clients kompatibel ist, die S3, NFS verwenden 👨🏾‍🤝‍👨🏼 🤸🏽 🐫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich komme von Luxoft. 
 Laut Opennet : LeoFS ist eine verteilte fehlertolerante Speichereinrichtung für LeoFS- Objekte, die mit Clients kompatibel ist...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Installation eines verteilten ausfallsicheren LeoFS-Speichers, der mit Clients kompatibel ist, die S3, NFS verwenden</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/478990/"><p>  Ich komme von Luxoft. <br>  Laut <a href="http://leo-project.net/leofs/index.html" rel="nofollow">Opennet</a> : <a href="http://leo-project.net/leofs/index.html" rel="nofollow">LeoFS</a> ist eine verteilte fehlertolerante Speichereinrichtung für <a href="http://leo-project.net/leofs/index.html" rel="nofollow">LeoFS-</a> Objekte, die mit Clients kompatibel ist, die die Amazon S3-API und die REST-API verwenden, und die auch den Betriebsmodus als NFS-Server unterstützt.  Es gibt Optimierungen für das Speichern von kleinen und sehr großen Objekten, es gibt einen eingebauten Caching-Mechanismus, die Replikation von Speichern zwischen Rechenzentren ist möglich.  Zu den Zielen des Projekts gehört die Erreichung einer Zuverlässigkeit von 99,9999999% aufgrund einer übermäßigen Replikation von Duplikaten und der Beseitigung einer einzelnen Fehlerstelle.  Der Projektcode ist in Erlang geschrieben. </p><br><p>  LeoFS besteht aus drei Komponenten: </p><br><ul><li> <a href="https://leo-project.net/leofs/docs/architecture/leo_storage/" rel="nofollow">LeoFS-Speicher</a> - <a href="https://leo-project.net/leofs/docs/architecture/leo_storage/" rel="nofollow">Ermöglicht</a> das Hinzufügen, Abrufen und Löschen von Objekten und Metadaten und ist für das Replizieren, Wiederherstellen und Einreihen von Clientanforderungen verantwortlich. </li><li>  <a href="https://leo-project.net/leofs/docs/architecture/leo_gateway/" rel="nofollow">LeoFS-Gateway</a> - Über das REST-API oder das S3-API werden HTTP-Anforderungen verarbeitet und Antworten an Clients umgeleitet. Die am häufigsten angeforderten Daten werden im Arbeitsspeicher und auf der Festplatte zwischengespeichert. </li><li>  <a href="https://leo-project.net/leofs/docs/architecture/leo_manager/" rel="nofollow">LeoFS-Manager</a> - Überwacht den Betrieb von LeoFS-Gateway- und LeoFS-Speicherknoten, überwacht den Status von Knoten und überprüft die Prüfsummen.  Gewährleistet Datenintegrität und hohe Speicherverfügbarkeit. </li></ul><br><p>  Installieren Sie in diesem Beitrag Leofs mit ansible-playbook, testen Sie S3, NFS. </p><a name="habracut"></a><br><p>  Wenn Sie versuchen, LeoFS mithilfe der offiziellen Playbooks zu installieren, warten verschiedene Fehler auf Sie: <a href="https://github.com/leo-project/leofs_ansible/issues/5" rel="nofollow">1</a> , <a href="https://github.com/leo-project/leofs_ansible/issues/4" rel="nofollow">2</a> .  In diesem Beitrag schreibe ich, was zu tun ist, um diese Fehler zu vermeiden. </p><br><p>  Wenn Sie ansible-playbook ausführen, müssen Sie netcat installieren. </p><br><h4 id="primer-inventory">  Inventarbeispiel </h4><br><div class="spoiler">  <b class="spoiler_title">Beispielinventar (im hosts.sample-Repository):</b> <div class="spoiler_text"><pre><code class="plaintext hljs"># Please check roles/common/vars/leofs_releases for available versions [all:vars] leofs_version=1.4.3 build_temp_path="/tmp/leofs_builder" build_install_path="/tmp/" build_branch="master" source="package" #[builder] #172.26.9.177 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_0] 172.26.9.176 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_1] 172.26.9.178 [leo_storage] 172.26.9.179 leofs_module_nodename=S0@172.26.9.179 172.26.9.181 leofs_module_nodename=S0@172.26.9.181 172.26.9.182 leofs_module_nodename=S0@172.26.9.182 172.26.9.183 leofs_module_nodename=S0@172.26.9.183 [leo_gateway] 172.26.9.180 leofs_module_nodename=G0@172.26.9.180 172.26.9.184 leofs_module_nodename=G0@172.26.9.184 [leofs_nodes:children] leo_manager_0 leo_manager_1 leo_gateway leo_storage</code> </pre> </div></div><br><h4 id="podgotovka-serverov">  Servervorbereitung </h4><br><p>  Selinux deaktivieren.  Ich hoffe, die Community erstellt Selinux-Richtlinien für LeoFS. </p><br><pre> <code class="plaintext hljs"> - name: Install libselinux as prerequisite for SELinux Ansible module yum: name: "{{item}}" state: latest with_items: - libselinux-python - libsemanage-python - name: Disable SELinux at next reboot selinux: state: disabled - name: Set SELinux in permissive mode until the machine is rebooted command: setenforce 0 ignore_errors: true changed_when: false</code> </pre><br><p>  Installieren Sie <code>netcat</code> und <code>redhat-lsb-core</code> .  Für <code>leofs-adm</code> wird <code>netcat</code> benötigt, für die Ermittlung der Betriebssystemversion <code>netcat</code> <code>leofs-adm</code> <code>redhat-lsb-core</code> benötigt. </p><br><pre> <code class="plaintext hljs"> - name: Install Packages yum: name={{ item }} state=present with_items: - nmap-ncat - redhat-lsb-core</code> </pre> <br><p>  Erstellen eines Benutzer-Leofs und Hinzufügen zu der Radgruppe </p><br><pre> <code class="plaintext hljs"> - name: Create user leofs group: name: leofs state: present - name: Allow 'wheel' group to have passwordless sudo lineinfile: dest: /etc/sudoers state: present regexp: '^%wheel' line: '%wheel ALL=(ALL) NOPASSWD: ALL' validate: 'visudo -cf %s' - name: Add the user 'leofs' to group 'wheel' user: name: leofs groups: wheel append: yes</code> </pre> <br><p>  Installieren Sie Erlang </p><br><pre> <code class="plaintext hljs"> - name: Remote erlang-20.3.8.23-1.el7.x86_64.rpm install with yum yum: name=https://github.com/rabbitmq/erlang-rpm/releases/download/v20.3.8.23/erlang-20.3.8.23-1.el7.x86_64.rpm</code> </pre><br><p>  Die Vollversion des korrigierten Ansible-Playbooks finden Sie hier: <a href="https://github.com/patsevanton/leofs_ansible" rel="nofollow">https://github.com/patsevanton/leofs_ansible</a> </p><br><h4 id="ustanovka-konfigurirovanie-zapusk">  Installation, Konfiguration, Start </h4><br><p>  Führen Sie als Nächstes die in <a href="https://github.com/leo-project/leofs_ansible" rel="nofollow">https://github.com/leo-project/leofs_ansible beschriebenen</a> Schritte ohne build_leofs.yml aus </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">## Install LeoFS $ ansible-playbook -i hosts install_leofs.yml ## Config LeoFS $ ansible-playbook -i hosts config_leofs.yml ## Start LeoFS $ ansible-playbook -i hosts start_leofs.yml</span></span></code> </pre> <br><h4 id="proveryaem-status-klastera-na-primary-leomanager">  Überprüfen des Clusterstatus in Primary LeoManager </h4><br><pre> <code class="bash hljs">leofs-adm status</code> </pre> <br><p>  Primary und Secondary sind in den Ansible-Playbook-Protokollen zu sehen </p><br><p><img src="https://habrastorage.org/webt/do/kp/oj/dokpoj8lmzwh3bmakpxx9anc-4i.png"></p><br><p><img src="https://habrastorage.org/webt/ku/0o/bt/ku0obtn6ezvfghyfai01zldeaws.png"></p><br><div class="spoiler">  <b class="spoiler_title">Der Abschluss wird ungefähr so ​​sein</b> <div class="spoiler_text"><pre> <code class="bash hljs"> [System Confiuration] -----------------------------------+---------- Item | Value -----------------------------------+---------- Basic/Consistency level -----------------------------------+---------- system version | 1.4.3 cluster Id | leofs_1 DC Id | dc_1 Total replicas | 2 number of successes of R | 1 number of successes of W | 1 number of successes of D | 1 number of rack-awareness replicas | 0 ring size | 2^128 -----------------------------------+---------- Multi DC replication settings -----------------------------------+---------- [mdcr] max number of joinable DCs | 2 [mdcr] total replicas per a DC | 1 [mdcr] number of successes of R | 1 [mdcr] number of successes of W | 1 [mdcr] number of successes of D | 1 -----------------------------------+---------- Manager RING <span class="hljs-built_in"><span class="hljs-built_in">hash</span></span> -----------------------------------+---------- current ring-hash | a0314afb previous ring-hash | a0314afb -----------------------------------+---------- [State of Node(s)] -------+----------------------+--------------+---------+----------------+----------------+---------------------------- <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> | node | state | rack id | current ring | prev ring | updated at -------+----------------------+--------------+---------+----------------+----------------+---------------------------- S | S0@172.26.9.179 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.181 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.182 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.183 | attached | | | | 2019-12-05 10:33:58 +0000 G | G0@172.26.9.180 | running | | a0314afb | a0314afb | 2019-12-05 10:33:49 +0000 G | G0@172.26.9.184 | running | | a0314afb | a0314afb | 2019-12-05 10:33:49 +0000 -------+----------------------+--------------+---------+----------------+----------------+----------------------------</code> </pre> </div></div><br><h4 id="sozdaem-yuzera">  Erstellen Sie einen Benutzer </h4><br><p>  Erstellen Sie Benutzerleofs: </p><br><pre> <code class="bash hljs">leofs-adm create-user leofs leofs access-key-id: 9c2615f32e81e6a1caf5 secret-access-key: 8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb</code> </pre> <br><p>  Liste der Benutzer: </p><br><pre> <code class="bash hljs">leofs-adm get-users user_id | role_id | access_key_id | created_at ------------+---------+------------------------+--------------------------- _test_leofs | 9 | 05236 | 2019-12-02 06:56:49 +0000 leofs | 1 | 9c2615f32e81e6a1caf5 | 2019-12-02 10:43:29 +0000</code> </pre> <br><h4 id="sozdaem-bucket">  Erstellen Sie einen Bucket </h4><br><p>  Habe einen Eimer gemacht </p><br><pre> <code class="bash hljs">leofs-adm add-bucket leofs 9c2615f32e81e6a1caf5 OK</code> </pre> <br><p>  Bucket-Liste: </p><br><pre> <code class="bash hljs"> leofs-adm get-buckets cluster id | bucket | owner | permissions | created at -------------+----------+--------+------------------+--------------------------- leofs_1 | leofs | leofs | Me(full_control) | 2019-12-02 10:44:02 +0000</code> </pre> <br><h4 id="konfigurirovanie-s3cmd">  S3cmd konfigurieren </h4><br><p>  <code>HTTP Proxy server name</code> Feld <code>HTTP Proxy server name</code> die Gateway-Server-IP an </p><br><pre> <code class="bash hljs">s3cmd --configure Enter new values or accept defaults <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> brackets with Enter. Refer to user manual <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> detailed description of all options. Access key and Secret key are your identifiers <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Amazon S3. Leave them empty <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> using the env variables. Access Key [9c2615f32e81e6a1caf5]: Secret Key [8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb]: Default Region [US]: Use <span class="hljs-string"><span class="hljs-string">"s3.amazonaws.com"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: Use <span class="hljs-string"><span class="hljs-string">"%(bucket)s.s3.amazonaws.com"</span></span> to the target Amazon S3. <span class="hljs-string"><span class="hljs-string">"%(bucket)s"</span></span> and <span class="hljs-string"><span class="hljs-string">"%(location)s"</span></span> vars can be used <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> accessing a bucket [%(bucket)s.s3.amazonaws.com]: leofs Encryption password is used to protect your files from reading by unauthorized persons <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> transfer to S3 Encryption password: Path to GPG program [/usr/bin/gpg]: When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [No]: On some networks all internet access must go through a HTTP proxy. Try setting it here <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> you can<span class="hljs-string"><span class="hljs-string">'t connect to S3 directly HTTP Proxy server name [172.26.9.180]: HTTP Proxy server port [8080]: New settings: Access Key: 9c2615f32e81e6a1caf5 Secret Key: 8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb Default Region: US S3 Endpoint: s3.amazonaws.com DNS-style bucket+hostname:port template for accessing a bucket: leofs Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: False HTTP Proxy server name: 172.26.9.180 HTTP Proxy server port: 8080 Test access with supplied credentials? [Y/n] Y Please wait, attempting to list all buckets... Success. Your access key and secret key worked fine :-) Now verifying that encryption works... Not configured. Never mind. Save settings? [y/N] y Configuration saved to '</span></span>/home/user/.s3cfg<span class="hljs-string"><span class="hljs-string">'</span></span></code> </pre> <br><p>  Wenn Sie eine Fehlermeldung erhalten FEHLER: S3 Fehler: 403 (AccessDenied): Zugriff verweigert: </p><br><pre> <code class="bash hljs">s3cmd put test.py s3://leofs/ upload: <span class="hljs-string"><span class="hljs-string">'test.py'</span></span> -&gt; <span class="hljs-string"><span class="hljs-string">'s3://leofs/test.py'</span></span> [1 of 1] 382 of 382 100% <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0s 3.40 kB/s <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> ERROR: S3 error: 403 (AccessDenied): Access Denied</code> </pre> <br><p>  Dann musst du signature_v2 in True s3cmd config korrigieren.  Details in dieser <a href="https://github.com/leo-project/leofs/issues/487" rel="nofollow">Ausgabe</a> . </p><br><p>  Wenn signature_v2 False ist, tritt ein solcher Fehler auf: </p><br><pre> <code class="bash hljs">WARNING: Retrying failed request: /?delimiter=%2F (getaddrinfo() argument 2 must be <span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> or string) WARNING: Waiting 3 sec... WARNING: Retrying failed request: /?delimiter=%2F (getaddrinfo() argument 2 must be <span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> or string) WARNING: Waiting 6 sec... ERROR: Test failed: Request failed <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: /?delimiter=%2F</code> </pre> <br><h4 id="testirovanie-zagruzki">  Booten testen </h4><br><p>  Erstellen Sie eine 1 GB-Datei </p><br><pre> <code class="bash hljs">fallocate -l 1GB 1gb</code> </pre> <br><p>  Laden Sie es zu Leofs hoch </p><br><pre> <code class="bash hljs">time s3cmd put 1gb s3://leofs/ real 0m19.099s user 0m7.855s sys 0m1.620s</code> </pre> <br><h4 id="statistika">  Statistiken </h4><br><p>  leofs-adm du für 1 Knoten: </p><br><pre> <code class="bash hljs">leofs-adm du S0@172.26.9.179 active number of objects: 156 total number of objects: 156 active size of objects: 602954495 total size of objects: 602954495 ratio of active size: 100.0% last compaction start: ____-__-__ __:__:__ last compaction end: ____-__-__ __:__:__</code> </pre> <br><p>  Wir sehen, dass die Schlussfolgerung nicht sehr informativ ist. </p><br><p>  Mal sehen, wo sich diese Datei befindet. <br>  leofs-adm whereis leofs / 1gb </p><br><pre> <code class="bash hljs">leofs-adm whereis leofs/1gb -------+----------------------+--------------------------------------+------------+--------------+----------------+----------------+----------------+---------------------------- del? | node | ring address | size | checksum | has children | total chunks | clock | when -------+----------------------+--------------------------------------+------------+--------------+----------------+----------------+----------------+---------------------------- | S0@172.26.9.181 | 657a9f3a3db822a7f1f5050925b26270 | 976563K | a4634eea55 | <span class="hljs-literal"><span class="hljs-literal">true</span></span> | 64 | 598f2aa976a4f | 2019-12-05 10:48:15 +0000 | S0@172.26.9.182 | 657a9f3a3db822a7f1f5050925b26270 | 976563K | a4634eea55 | <span class="hljs-literal"><span class="hljs-literal">true</span></span> | 64 | 598f2aa976a4f | 2019-12-05 10:48:15 +0000</code> </pre> <br><h4 id="aktiviruem-nfs">  Aktivieren Sie NFS </h4><br><p>  Wir aktivieren NFS auf dem Leo Gateway 172.26.9.184-Server. </p><br><p>  Installieren Sie auf dem Server und dem Client nfs-utils </p><br><pre> <code class="bash hljs">sudo yum install nfs-utils</code> </pre> <br><p>  Entsprechend den Anweisungen werden wir die Konfigurationsdatei <code>/usr/local/leofs/current/leo_gateway/etc/leo_gateway.conf</code> </p><br><pre> <code class="bash hljs">protocol = nfs</code> </pre> <br><p>  Führen Sie auf dem Server 172.26.9.184 rpcbind und leofs-gateway aus </p><br><pre> <code class="bash hljs">sudo service rpcbind start sudo service leofs-gateway restart</code> </pre> <br><p>  Erstellen Sie auf dem Server, auf dem leo_manager ausgeführt wird, einen Bucket für NFS und generieren Sie einen Schlüssel für die Verbindung mit NFS </p><br><pre> <code class="bash hljs">leofs-adm add-bucket <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> 05236 leofs-adm gen-nfs-mnt-key <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> 05236 ip--nfs-</code> </pre> <br><h4 id="podklyuchenie-k-nfs">  Stellen Sie eine Verbindung zu NFS her </h4><br><pre> <code class="bash hljs">sudo mkdir /mnt/leofs <span class="hljs-comment"><span class="hljs-comment">## for Linux - "sudo mount -t nfs -o nolock &lt;host&gt;:/&lt;bucket&gt;/&lt;token&gt; &lt;dir&gt;" sudo mount -t nfs -o nolock ip--nfs-------gateway:/bucket/access_key_id/---gen-nfs-mnt-key /mnt/leofs sudo mount -t nfs -o nolock 172.26.9.184:/test/05236/bb5034f0c740148a346ed663ca0cf5157efb439f /mnt/leofs</span></span></code> </pre> <br><h4 id="prosmotr-diskovogo-prostanstva-cherez-nfs-klient">  Anzeigen des Speicherplatzes über einen NFS-Client </h4><br><p>  Festplattenspeicher, wenn man bedenkt, dass jeder Speicherknoten über eine 40-GB-Festplatte verfügt (3 laufende Knoten, 1 angeschlossener Knoten): </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 60G 3.6G 57G 6% /mnt/leofs</code> </pre> <br><h4 id="ustanovka-leofs-s-6-storage-nodami">  Installieren Sie LeoFS mit 6 Speicherknoten. </h4><br><div class="spoiler">  <b class="spoiler_title">Inventar (ohne Builder):</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Please check roles/common/vars/leofs_releases for available versions [all:vars] leofs_version=1.4.3 build_temp_path="/tmp/leofs_builder" build_install_path="/tmp/" build_branch="master" source="package" # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_0] 172.26.9.177 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_1] 172.26.9.176 [leo_storage] 172.26.9.178 leofs_module_nodename=S0@172.26.9.178 172.26.9.179 leofs_module_nodename=S0@172.26.9.179 172.26.9.181 leofs_module_nodename=S0@172.26.9.181 172.26.9.182 leofs_module_nodename=S0@172.26.9.182 172.26.9.183 leofs_module_nodename=S0@172.26.9.183 172.26.9.185 leofs_module_nodename=S0@172.26.9.185 [leo_gateway] 172.26.9.180 leofs_module_nodename=G0@172.26.9.180 172.26.9.184 leofs_module_nodename=G0@172.26.9.184 [leofs_nodes:children] leo_manager_0 leo_manager_1 leo_gateway leo_storage</span></span></code> </pre> </div></div><br><h4 id="vyvod-leofs-adm-status">  Leofs-adm Statusausgabe </h4><br><div class="spoiler">  <b class="spoiler_title">Leofs-adm Statusausgabe</b> <div class="spoiler_text"><pre> <code class="bash hljs"> [System Confiuration] -----------------------------------+---------- Item | Value -----------------------------------+---------- Basic/Consistency level -----------------------------------+---------- system version | 1.4.3 cluster Id | leofs_1 DC Id | dc_1 Total replicas | 2 number of successes of R | 1 number of successes of W | 1 number of successes of D | 1 number of rack-awareness replicas | 0 ring size | 2^128 -----------------------------------+---------- Multi DC replication settings -----------------------------------+---------- [mdcr] max number of joinable DCs | 2 [mdcr] total replicas per a DC | 1 [mdcr] number of successes of R | 1 [mdcr] number of successes of W | 1 [mdcr] number of successes of D | 1 -----------------------------------+---------- Manager RING <span class="hljs-built_in"><span class="hljs-built_in">hash</span></span> -----------------------------------+---------- current ring-hash | d8ff465e previous ring-hash | d8ff465e -----------------------------------+---------- [State of Node(s)] -------+----------------------+--------------+---------+----------------+----------------+---------------------------- <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> | node | state | rack id | current ring | prev ring | updated at -------+----------------------+--------------+---------+----------------+----------------+---------------------------- S | S0@172.26.9.178 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.179 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.181 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:30 +0000 S | S0@172.26.9.182 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.183 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.185 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 G | G0@172.26.9.180 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:31 +0000 G | G0@172.26.9.184 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:31 +0000 -------+----------------------+--------------+---------+----------------+----------------+----------------------------</code> </pre> </div></div><br><p>  Festplattenspeicher, wobei zu berücksichtigen ist, dass jeder Speicherknoten eine Festplatte mit 40 GB hat (6 ausgeführte Knoten): </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 120G 3.6G 117G 3% /mnt/leofs</code> </pre> <br><h4 id="esli-ispolzuetsya-5-nod-storage">  Wenn 5 Speicherknoten verwendet werden </h4><br><pre> <code class="bash hljs">[leo_storage] 172.26.9.178 leofs_module_nodename=S0@172.26.9.178 172.26.9.179 leofs_module_nodename=S1@172.26.9.179 172.26.9.181 leofs_module_nodename=S2@172.26.9.181 172.26.9.182 leofs_module_nodename=S3@172.26.9.182 172.26.9.183 leofs_module_nodename=S4@172.26.9.183</code> </pre> <br><pre> <code class="bash hljs">df -hP 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 100G 3.0G 97G 3% /mnt/leofs</code> </pre> <br><h4 id="logi">  Protokolle </h4><br><p>  Protokolle befinden sich in den Verzeichnissen <code>/usr/local/leofs/current/*/log</code> </p><br><h4 id="esli-vy-budete-ustanavlivatnastraivat-leofs-vruchnuyu-to-vozmozhno-stolknetes-so-sleduyuschimi-oshibkami">  Wenn Sie Leofs manuell installieren / konfigurieren, können die folgenden Fehler auftreten. </h4><br><h5 id="error-mnesia-is-not-available">  [FEHLER] Mnesia ist nicht verfügbar </h5><br><p>  Starten Sie den Systemdienst Start Leofs-Manager-Master </p><br><pre> <code class="bash hljs">leofs-adm status [ERROR] Mnesia is not available</code> </pre> <br><p>  System muss gestartet werden. Leofs-manager-slave muss auf leo_manager_1 gestartet werden </p><br><h5 id="ne-startuet-leofs-storage">  Leofs-Speicher startet nicht. </h5><br><p>  Es ist erforderlich, dass der Status von leofs-manager-master und leofs-manager-slave und leofs-adm aktiv ist, um den Status anzuzeigen. </p><br><h5 id="attached-nodes-less-than--of-replicas">  Angehängte Knoten weniger als die Anzahl der Replikate </h5><br><p>  Wenn Sie leofs-adm start starten, erhalten Sie folgende Fehlermeldung: </p><br><pre> <code class="bash hljs">leofs-adm start [ERROR] Attached nodes less than <span class="hljs-comment"><span class="hljs-comment"># of replicas</span></span></code> </pre> <br><p>  Nicht genügend Speicherknoten.  Der Status leofs-adm zeigt Ihnen weniger als 2 Speicherknoten an.  Erforderliche Mindestanzahl von Speicherknoten 2. </p><br><h5 id="leofs-adm-status-pokazyvaet-attached-ostalnye-running">  leofs-adm status wird angehängt, der rest läuft. </h5><br><p>  Die Knoten müssen neu ausbalanciert werden </p><br><pre> <code class="bash hljs">leofs-adm rebalance</code> </pre> <br><h5 id="posle-starta-leofs-gateway-vy-ne-vidite-nodu-gateway-v-leofs-adm-status">  Nach dem Start von leofs-gateway sehen Sie den Gateway-Knoten nicht im Status leofs-adm </h5><br><p>  Muss leofs-adm starten </p><br><pre> <code class="bash hljs">leofs-adm start</code> </pre> <br><h5 id="couldnt-connect-to-leofs-manager-na-slave-uzle">  Verbindung zu LeoFS Manager auf dem Slave-Knoten konnte nicht hergestellt werden </h5><br><p>  (Standardmäßig funktioniert leofs-adm nicht auf dem Slave-Knoten!) ( <a href="https://leo-project.net/leofs/docs/issues/documentation-issues/" rel="nofollow">Https://leo-project.net/leofs/docs/issues/documentation-issues/</a> ) </p><br><h3 id="nagruzochnoe-testirovanie">  Belastungstest </h3><br><p>  Das Testen erfolgt auf 2 Knoten mit der Konfiguration: </p><br><pre> <code class="bash hljs">CPU: Single Core Intel Core (Broadwell) (-MCP-) speed: 2295 MHz Kernel: 3.10.0-862.3.2.el7.x86_64 x86_64 Up: 1h 08m Mem: 1023.8/1999.6 MiB (51.2%) Storage: 10.00 GiB (43.5% used) Procs: 98 Shell: bash 4.2.46 inxi: 3.0.37</code> </pre> <br><p>  Nehmen Sie zum Testen eine kleine Diskette <br>  Auf beiden Knoten sehen wir eine 9.4G- und 5.9G-Festplatte mit freiem Speicherplatz. </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on /dev/vda1 9.4G 5.9G 3.1G 66% /</code> </pre> <br><p>  Telegrammkanal: <a href="https://t.me/sds_ru" rel="nofollow">SDS und Cluster FS</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de478990/">https://habr.com/ru/post/de478990/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de478974/index.html">Modul Autoload mit dynamischem Import</a></li>
<li><a href="../de478978/index.html">Azure SDK für .NET: Geschichte über eine schwierige Fehlersuche</a></li>
<li><a href="../de478980/index.html">Azure SDK für .NET: Die Geschichte eines schwierigen Fehlersuchers</a></li>
<li><a href="../de478986/index.html">Yandex hat eine populäre Abstimmung für Retro-Spiele gestartet. Finalisten der Retro Games Battle 2019</a></li>
<li><a href="../de478988/index.html">Venedig: wilder Gewinn auf ein paar nackten Steinen</a></li>
<li><a href="../de478992/index.html">Mangel an Angst und Lebensfreude in der IT</a></li>
<li><a href="../de478994/index.html">Die Deutsche Post will am Montag langsamer arbeiten und sich ausruhen</a></li>
<li><a href="../de478996/index.html">Arbeit ist kein Wolf, Teil 4. Erfahrener Mitarbeiter: Wie man nicht ausbrennt und nicht aufgibt</a></li>
<li><a href="../de478998/index.html">Warum wollen wir immer den goldenen Schnitt sehen? Versuchte (erfolglose) evolutionäre Analyse mit neuronalen C ++ - Netzwerken</a></li>
<li><a href="../de479000/index.html">Parallels-Praktikum mit 14 Jahren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
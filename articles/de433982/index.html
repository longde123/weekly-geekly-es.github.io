<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘¨ğŸ¼â€ğŸš€ ğŸ‘¨ğŸ¼â€âœˆï¸ ğŸ”‘ KÃ¼nstliche Intelligenz denkt als eine Gruppe von Menschen, die Anlass zur Sorge gibt ğŸ–•ğŸ¾ ğŸš ğŸ™†ğŸ¿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="KÃ¼nstliche Intelligenz wurde fÃ¼r organisatorische Entscheidungen und die Ã¶ffentliche Verwaltung geschaffen. Er braucht eine menschliche Ethik, sagt Jo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>KÃ¼nstliche Intelligenz denkt als eine Gruppe von Menschen, die Anlass zur Sorge gibt</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433982/"> <i>KÃ¼nstliche Intelligenz wurde fÃ¼r organisatorische Entscheidungen und die Ã¶ffentliche Verwaltung geschaffen.</i>  <i>Er braucht eine menschliche Ethik, sagt Johnny Penn von der Cambridge University</i> <br><br>  KÃ¼nstliche Intelligenz (KI) ist Ã¼berall, aber nicht vollstÃ¤ndig auf historische Weise erfunden.  Um die Auswirkungen der KI auf unser Leben zu verstehen, ist es wichtig, die Umgebung zu bewerten, in der sie geschaffen wurde.  Am Ende haben sich Statistik und staatliche Kontrolle seit Hunderten von Jahren Hand in Hand entwickelt. <br><br>  Betrachten Sie die Informatik.  Sein Ursprung kann nicht nur durch analytische Philosophie, reine Mathematik und Alan Turing verfolgt werden, sondern Ã¼berraschenderweise auch durch die Geschichte der Ã¶ffentlichen Verwaltung.  Im Jahr 2003, The Government Machine: Eine revolutionÃ¤re Computergeschichte, beschreibt John Agar vom University College London die Entwicklung des britischen Ã¶ffentlichen Dienstes, der von 16.000 Mitarbeitern im Jahr 1797 auf 460.000 im Jahr 1999 wuchs.  Er bemerkte eine abnormale Ã„hnlichkeit zwischen der FunktionalitÃ¤t der menschlichen BÃ¼rokratie und dem elektronischen Computer.  (Er gab zu, dass er nicht sagen konnte, ob diese Beobachtung trivial oder tief war). <br><br>  Beide Systeme verarbeiteten eine groÃŸe Menge an Informationen unter Verwendung einer Hierarchie vordefinierter, aber anpassbarer Regeln.  Aber einer von ihnen kam vom anderen.  Dies zeigte einen wichtigen Zusammenhang zwischen der Organisation sozialer Strukturen von Menschen und digitalen Werkzeugen, die ihnen dienen sollen.  Herr Agar verbindet den Ursprung der Informatik mit der Charles Babbage Analytical Engine, die in den 1820er Jahren in GroÃŸbritannien entwickelt wurde.  Seine Entwicklung wurde von der Regierung subventioniert, was darauf hindeutete, dass sie als Sponsor fungieren wÃ¼rde.  Babbages Projekte, so Agar, sollten als "Materialisierung staatlicher AktivitÃ¤ten" angesehen werden. <a name="habracut"></a><br><br>  Diese Beziehung zwischen Computersystemen und menschlichen Organisationsstrukturen wiederholt die Geschichte der KI.  In den 1930er und 1940er Jahren beschloss Herbert Simon (Bild unten), ein Politikwissenschaftler der University of Chicago, der spÃ¤ter an der Carnegie Mellon University lehrte, einen â€wissenschaftlichenâ€œ Ansatz zur Grundlage der FÃ¼hrungsstruktur zu entwickeln.  Simon hatte zuvor unter der Leitung von Rudolf Karnap, einem Mitglied des Wiener Kreises der logischen Positivisten, studiert.  Dies bestÃ¤tigte seine Ãœberzeugung, dass es bestehenden Theorien an Empirismus mangelt.  Seine Dissertation im Jahr 1947 wurde zum Buch â€Verwaltungsverhaltenâ€œ, das als Grundlage fÃ¼r das VerstÃ¤ndnis aller AktivitÃ¤ten in der Organisation anhand der Entscheidungsmatrix diente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f21/dc3/512/f21dc3512f4fed640ea7ca87c09d5298.jpg" alt="Bild"><br><br>  <b>Sagt Simon</b> <br><br>  Er leistete einen groÃŸen Beitrag in vielen wissenschaftlichen Bereichen, nicht nur in Politikwissenschaft und Wirtschaft, sondern auch in Informatik und kÃ¼nstlicher Intelligenz.  Er prÃ¤gte den Begriff "befriedigend" (um zu akzeptieren, was erwÃ¼nscht ist, anstatt nach dem Optimum zu streben) und entwickelte die Idee der "begrenzten RationalitÃ¤t", fÃ¼r die er 1978 den Nobelpreis fÃ¼r Wirtschaftswissenschaften erhielt.  In den 1950er Jahren war Simon Berater bei der RAND Corporation, einer einflussreichen Denkfabrik, die von der US-Luftwaffe unterstÃ¼tzt wurde. <br><br>  Bei RAND versuchten Simon und seine beiden Kollegen, der junge Mathematiker Allan Newell und der ehemalige Versicherungsmathematiker J. Clifford Shaw, eine LÃ¶sung fÃ¼r menschliche Probleme in Bezug auf die AusfÃ¼hrung einer bestimmten Operation durch einen Computer zu modellieren.  DafÃ¼r borgte Simon Elemente aus dem System aus, das er im Verwaltungsverhalten entwickelt hatte, um dem Computer beizubringen, wie eine Person zu â€denkenâ€œ. Simon lieÃŸ ihn wie eine Gruppe von Menschen denken. <br><br>  Das Ergebnis der Arbeit von drei Wissenschaftlern war eine virtuelle Maschine namens Logical Theorist, die als erster funktionierender Prototyp kÃ¼nstlicher Intelligenz bezeichnet wurde.  Die Ausdrucke des arbeitenden Theoretikers wÃ¤hrend des Sommerforschungsprojekts 1956 in Dartmouth lieÃŸen uns auf kÃ¼nstliche Intelligenz achten, die den Namen gab und den Grundstein fÃ¼r das gesamte wissenschaftliche Gebiet legte.  In Notizen von einer Konferenz in Dartmouth schrieb ein Teilnehmer, dass der Theoretiker dazu beigetragen habe, die Angst vor der Finanzierung dieses Forschungsbereichs zu Ã¼berwinden.  Dies war wichtig, da der Finanzierungsfonds fÃ¼r kÃ¼nstliche Intelligenz skeptisch war, dass dieser Forschungsbereich nÃ¼tzlich ist. <br><br>  Wie hat Simon seine wissenschaftlichen Leistungen gesehen?  Ein Jahr nach der Dartmouth-Konferenz prÃ¤sentierten er und Newell ihre Ergebnisse in der Publikation â€Heuristische ProblemlÃ¶sung: Die nÃ¤chste Bewegung in der Operations Researchâ€œ.  Der SchlÃ¼sselausdruck im Titel: "Operations Research" erschien in GroÃŸbritannien wÃ¤hrend des Zweiten Weltkriegs, um wissenschaftliche Prinzipien und Statistiken anzuwenden, um militÃ¤rische Operationen zu optimieren, und dann fÃ¼r Unternehmenszwecke.  KÃ¼nstliche Intelligenz war fÃ¼rs GeschÃ¤ft. <br><br>  In einer Rede von 1957 vor operierenden Forschern in London bemerkte Simon Frederick Taylor, den Vater der Wissenschaftsmanagementbewegung, und Charles Babbage, seine geistigen VorgÃ¤nger.  "Physiker und Elektrotechniker hatten nichts mit der Erfindung eines digitalen Computers zu tun", sagte Simon.  Der wahre Erfinder war seiner Meinung nach der Ã–konom Adam Smith.  Er erklÃ¤rte diese Beziehung: Der franzÃ¶sische Bauingenieur Gaspard de Prony beabsichtigte, Logarithmen mit Methoden zu erstellen, die aus Smiths Reichtum der Nationen stammen.  Babbage, inspiriert von Prony, wandte diese Vermutung auf mechanische GerÃ¤te an.  Mitte der 1950er Jahre verwandelte Simon es in Programmcode. <br><br>  Die Tradition lebt weiter.  Viele moderne Systeme der kÃ¼nstlichen Intelligenz ahmen das menschliche Denken weniger nach als vielmehr die weniger begabten KÃ¶pfe bÃ¼rokratischer Institutionen.  Unsere Methoden des maschinellen Lernens sind oft so programmiert, dass Ã¼bermenschliche Proportionen, Geschwindigkeit und Genauigkeit durch IdentitÃ¤t, Ehrgeiz oder Moral auf menschlicher Ebene erreicht werden. <br><br>  <b>Kapitalismus im Code</b> <br><br>  Diese Linien der Geschichte der kÃ¼nstlichen Intelligenz: Unternehmensentscheidungen, Staatsmacht und Verwendung von Statistiken im Krieg - wurden im VerstÃ¤ndnis der kÃ¼nstlichen Intelligenz, die den Menschen zugÃ¤nglich war, nicht bewahrt. <br><br>  Stattdessen werden Nachrichten Ã¼ber technische DurchbrÃ¼che oder Experten, die Ã„ngste ausdrÃ¼cken, von Bildern begleitet, wenn nicht in Form eines gut bewaffneten Terminators, dann von Geist, Roboter, Neon-Mikrochips oder absurden mathematischen Gleichungen.  Jeder von ihnen ist keine so starke BestÃ¤tigung der AutoritÃ¤t der Naturwissenschaften oder der Informatik in Bezug auf beispielsweise "weiche" Wissenschaften, die die Terminologie von Simon, Politikwissenschaft, Management oder sogar Wirtschaft, d. H.  Gebiete, fÃ¼r die er nach Stockholm ging, um seinen Nobelpreis zu erhalten. <br><br>  Vielleicht als Folge dieses falschen Eindrucks wird die Ã¶ffentliche Debatte bis heute darÃ¼ber fortgesetzt, welchen Nutzen die Sozialwissenschaften fÃ¼r das Studium der kÃ¼nstlichen Intelligenz haben kÃ¶nnen, wenn Ã¼berhaupt.  Laut Simon wurde die kÃ¼nstliche Intelligenz selbst in der Sozialwissenschaft geboren. <br><br>  David Runciman, Politikwissenschaftler an der UniversitÃ¤t von Cambridge, argumentierte, um kÃ¼nstliche Intelligenz zu verstehen, mÃ¼ssen wir zunÃ¤chst verstehen, wie sie in dem kapitalistischen System funktioniert, in das sie eingebettet ist.  â€Unternehmen sind eine andere Form des kÃ¼nstlichen Denkens. Sie sollen in der Lage sein, selbst Entscheidungen zu treffenâ€œ, erklÃ¤rt er. <br><br>  â€Viele der Ã„ngste, die die Menschen derzeit in Bezug auf die bevorstehende Ã„ra intelligenter Roboter haben, sind dieselben wie seit mehreren hundert Jahren in Bezug auf UnternehmensverbÃ¤ndeâ€œ, sagt Runciman.  Die Sorge ist, dass wir "niemals lernen werden, diese Systeme zu steuern". <br><br>  Zum Beispiel ging nach einer Ã–lpest im Jahr 2010, als 11 Menschen starben und der Golf von Mexiko verwÃ¼stet wurde, niemand ins GefÃ¤ngnis.  Die Bedrohung, vor der Herr Runciman warnt, besteht darin, dass Methoden der kÃ¼nstlichen Intelligenz, wie Taktiken zur Umgehung der Ã¶ffentlichen Verantwortung, ungestraft angewendet werden. <br><br>  Pionierforscher wie Julia Angwin, Virginia Eubanks und Katie O'Neill zeigen heute, wie verschiedene algorithmische Systeme Gewalt verstÃ¤rken, die MenschenwÃ¼rde zerstÃ¶ren und grundlegende demokratische Mechanismen wie die Rechenschaftspflicht untergraben, wenn sie verantwortungslos geschaffen werden.  Der Schaden sollte nicht beabsichtigt sein;  Voreingenommene DatensÃ¤tze, die zum Trainieren von Vorhersagemodellen verwendet werden, sind ebenfalls nachteilig.  In Anbetracht der teuren ArbeitskrÃ¤fte, die erforderlich sind, um den verursachten Schaden zu identifizieren und zu beseitigen, ist es notwendig, so etwas wie einen â€ethischen Dienstâ€œ zu schaffen, der als separate Branche geschaffen wird.  Frau O'Neill zum Beispiel hat jetzt ihren eigenen Algorithmus-ÃœberprÃ¼fungsdienst gestartet. <br><br>  In den 1950er Jahren schrieb John McCarthy, einer der ersten Pioniere auf diesem Gebiet, unter dem Begriff â€kÃ¼nstliche Intelligenzâ€œ fÃ¼r eine Konferenz in Dartmouth: â€Sobald ein erkenntnistheoretisches System programmiert ist und funktioniert, wird nichts anderes ernst genommen. zusÃ¤tzlich zur Verwaltung intelligenter Programme. â€œ  Aus diesem Grund lautet der ursprÃ¼ngliche Slogan von DeepMind â€Know the mind.  Verwenden Sie es, um alles andere zu wissen â€œ, sieht fast imperial aus. <br><br>  McCarthys Vorschlag war, dass Einfluss, nicht Macht, den wissenschaftlichen Konsens auf seinem Gebiet lÃ¶sen kÃ¶nnte.  DeepMind muss den Intellekt nicht â€kennenâ€œ (vorausgesetzt, dies ist Ã¼berhaupt mÃ¶glich), sondern nur die Konkurrenz besiegen.  Dieser neue Slogan des Unternehmens: â€Kennen Sie den Verstand.  Verwenden Sie es, um alles andere zu wissen â€œ, schlÃ¤gt er vor, dass er auch die Notwendigkeit von Diplomatie in einer Ã„ra der totalen Macht der kÃ¼nstlichen Intelligenz anerkennt. <br>  Stephen Cave, Direktor des Levergulm Center for Future Research, enthÃ¼llte, dass die Definition von Intelligenz im Laufe der Geschichte als Instrument zur Dominanz verwendet wurde.  Aristoteles wandte sich dem â€Naturgesetzâ€œ der sozialen Hierarchie zu, um zu erklÃ¤ren, warum Frauen, Sklaven und Tiere intelligenten Menschen untergeordnet sein sollten.  Angesichts dieses brutalen Erbes sollten die Richtlinien von Unternehmen und Computeragenturen komplexe Probleme lÃ¶sen, die sich aus Geschlecht, SexualitÃ¤t und Kolonialismus in Bezug auf andere persÃ¶nliche QualitÃ¤ten ergeben. <br><br>  Die Hauptverantwortung der kÃ¼nstlichen Intelligenz besteht darin, dass sie eine umfassende automatisierte Kategorisierung ermÃ¶glicht.  Zum Beispiel kann maschinelles Lernen verwendet werden, um einen bÃ¶sartigen Maulwurf von einem gutartigen zu unterscheiden.  Diese â€Pflichtâ€œ wird zur Bedrohung, wenn es darum geht, die Probleme des Alltags zu lÃ¶sen.  Unvorsichtige Etiketten kÃ¶nnen belÃ¤stigen und schÃ¤digen, wenn sie falsche Macht beanspruchen.  Aus Protest gegen die ungerechten Bezeichnungen, mit denen die Welt â€gekanntâ€œ wird, fordern viele junge Menschen heute stolz unerwÃ¼nschte Kategorisierungen heraus, sei es traditionelles Geschlecht oder Geschlechterpaare. <br><br>  <b>Maschinen, die wieder nachdenken</b> <br><br>  FÃ¼r viele mag es Ã¼berraschend sein, dass die sozialen, materiellen und politischen Ursachen fÃ¼r den Ursprung der kÃ¼nstlichen Intelligenz nicht gut verstanden sind.  In der Tat wurde viel Ã¼ber die Geschichte der kÃ¼nstlichen Intelligenz geschrieben: Simon 1996 und Newell 2000.  Die meisten dieser Geschichten unterliegen jedoch einigen EinschrÃ¤nkungen und werden laut Paul Edwards, einem Historiker der Informationstechnologie, â€hauptsÃ¤chlich intellektuellâ€œ betrachtet. <br><br>  Jede der beiden fast offiziellen Geschichten Ã¼ber kÃ¼nstliche Intelligenz ist eine Gedankengeschichte: â€The Machines That Thinkâ€œ von Pamela McCordack, die nach der ersten VerÃ¶ffentlichung 1979 â€die Vorlage fÃ¼r die meisten nachfolgenden Geschichten erstellt hatâ€œ;  und KÃ¼nstliche Intelligenz: Eine aufregende Geschichte von Daniel Crevier, verÃ¶ffentlicht 1993.  Beide BÃ¼cher stÃ¼tzten sich hauptsÃ¤chlich auf detaillierte Interviews mit SchlÃ¼sselforschern. <br><br>  Vielleicht hat deshalb niemand versucht, kÃ¼nstliche Intelligenz in einem breiteren Kontext zu verstehen, einschlieÃŸlich der Entwicklung der operativen Forschung, der "groÃŸen Wissenschaft", der versicherungsmathematischen Wissenschaften und der amerikanischen MilitÃ¤rfinanzierung, wie sie sich seit dem Zweiten Weltkrieg entwickelt hat.  Aus diesen Geschichten herausgestrichen, kann KI von ihrem historischen und politischen Kontext getrennt werden. <br><br>  Ohne diesen Kontext scheint kÃ¼nstliche Intelligenz auch von dem System der Wissenschaften, das sie geschaffen hat, getrennt zu sein.  In einem GesprÃ¤ch mit Fachleuten auf dem Gebiet der operativen Forschung von 1957 stellte Simon die Vielfalt der Vergangenheit in seinem wissenschaftlichen Bereich fest.  Er beschrieb den Beitrag der franzÃ¶sischen Weber und Jacquardmechaniker sowie von Smith, de Prony, Babbage und seinen Kollegen in den Soft Sciences als eine kollektive â€Schuldâ€œ, die noch zurÃ¼ckgezahlt werden muss. <br><br>  Dieses neue Wissen hÃ¤tte so unerwartet und von so vielen Orten kommen kÃ¶nnen, dass Simon in seiner Arbeit aufgeregt war - und uns heute vielleicht genauso denken lassen kÃ¶nnte.  Die moderne KI kann nicht nur das organisatorische Dogma widerspiegeln, das ihre Geburt charakterisiert hat, sondern auch unsere Menschlichkeit. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de433982/">https://habr.com/ru/post/de433982/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de433966/index.html">Weihnachtskarte vom Mars. Die ESA zeigte eine groÃŸe Ansammlung von Eis auf der OberflÃ¤che des roten Planeten</a></li>
<li><a href="../de433968/index.html">Das degenerierteste Kommunikationsspiel</a></li>
<li><a href="../de433972/index.html">HolyJS 2018 Moskau mit den Augen des Teilnehmers</a></li>
<li><a href="../de433974/index.html">Chatbot bekommt GehÃ¶r oder Amateurleiden</a></li>
<li><a href="../de433980/index.html">China startete 2018 mehr Raketen in die Umlaufbahn als jedes andere Land</a></li>
<li><a href="../de433984/index.html">Russische Studenten erwarteten den internationalen KI-Wettbewerb von Microsoft</a></li>
<li><a href="../de433986/index.html">Erstellen des Vuex Undo / Redo Plugins fÃ¼r VueJS</a></li>
<li><a href="../de433992/index.html">Out-of-Process-Debugger fÃ¼r C ++ in Visual Studio 2019</a></li>
<li><a href="../de433994/index.html">Automatisierungswerkzeug fÃ¼r die Versionskontrolle</a></li>
<li><a href="../de433996/index.html">Ãœberlegungen zum Manifest fÃ¼r Entwickler intelligenter Systeme</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÜüèª üíáüèæ üî≥ Das Gehirn ist wie ein Computer: schlecht mit Mathe umgehen und gut mit allem anderen üëº üòÜ ü••</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir alle erinnern uns an Schulqu√§l√ºbungen in Arithmetik. Es dauert mindestens eine Minute, um Zahlen wie 3.752 und 6.901 mit Bleistift und Papier zu m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das Gehirn ist wie ein Computer: schlecht mit Mathe umgehen und gut mit allem anderen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/405285/"><img src="https://habrastorage.org/getpro/geektimes/post_images/4f2/344/2fe/4f23442fefbfc9ec8afa548b63195343.jpg" alt="Bild" align="left">  Wir alle erinnern uns an Schulqu√§l√ºbungen in Arithmetik.  Es dauert mindestens eine Minute, um Zahlen wie 3.752 und 6.901 mit Bleistift und Papier zu multiplizieren.  Wenn wir heute Telefone zur Hand haben, k√∂nnen wir nat√ºrlich schnell √ºberpr√ºfen, ob das Ergebnis unserer √úbung 25.892.552 sein sollte. Die Prozessoren moderner Telefone k√∂nnen mehr als 100 Milliarden solcher Operationen pro Sekunde ausf√ºhren.  Dar√ºber hinaus verbrauchen diese Chips nur wenige Watt, was sie viel effizienter macht als unser langsames Gehirn, 20 Watt verbraucht und viel mehr Zeit ben√∂tigt, um das gleiche Ergebnis zu erzielen. <br><br>  Nat√ºrlich hat sich das Gehirn nicht entwickelt, um rechnen zu k√∂nnen.  Deshalb macht er es schlecht.  Aber er kommt mit der Verarbeitung eines st√§ndigen Informationsstroms aus unserer Umwelt zurecht.  Und er reagiert darauf - manchmal schneller, als wir es realisieren k√∂nnen.  Es spielt keine Rolle, wie viel Energie ein normaler Computer verbraucht - es wird schwierig sein, mit dem fertig zu werden, was dem Gehirn leicht gegeben wird - zum Beispiel die Sprache zu verstehen oder die Treppe hinaufzulaufen. <br><a name="habracut"></a><br>  Wenn sie Maschinen schaffen k√∂nnten, deren Rechenleistung und Energieeffizienz mit dem Gehirn vergleichbar w√§ren, w√ºrde sich alles dramatisch √§ndern.  Roboter w√ºrden sich geschickt in der physischen Welt bewegen und in einer nat√ºrlichen Sprache mit uns kommunizieren.  Gro√üe Systeme w√ºrden riesige Mengen an Informationen √ºber Wirtschaft, Wissenschaft, Medizin oder Regierung sammeln, neue Muster entdecken, kausale Zusammenh√§nge finden und Vorhersagen treffen.  Intelligente mobile Apps wie Siri und Cortana k√∂nnten sich weniger auf Clouds verlassen.  Eine solche Technologie k√∂nnte es uns erm√∂glichen, Ger√§te mit geringem Energieverbrauch zu entwickeln, die unsere Sinne erg√§nzen, uns mit Medikamenten versorgen und Nervensignale emulieren, um Organsch√§den oder L√§hmungen auszugleichen. <br><br>  Aber ist es nicht zu fr√ºh, um solch mutige Ziele zu setzen?  Ist unser Verst√§ndnis des Gehirns zu begrenzt, um Technologien basierend auf seinen Prinzipien zu entwickeln?  Ich glaube, dass das Emulieren selbst der einfachsten Merkmale der Nervenschaltungen die Leistung vieler kommerzieller Anwendungen dramatisch verbessern kann.  Wie genau Computer die biologischen Details der Struktur des Gehirns kopieren m√ºssen, um seiner Geschwindigkeit n√§her zu kommen, ist eine offene Frage.  Aber heutige Systeme, die von der Struktur des Gehirns inspiriert oder neuromorph sind, werden zu wichtigen Werkzeugen, um eine Antwort darauf zu finden. <br><br>  Ein Schl√ºsselmerkmal herk√∂mmlicher Computer ist die physische Trennung des Speichers, in dem Daten und Anweisungen gespeichert sind, und die Logik, die diese Informationen verarbeitet.  Es gibt keine solche Trennung im Gehirn.  Berechnungen und Datenspeicherung erfolgen gleichzeitig und lokal in einem ausgedehnten Netzwerk, das aus ungef√§hr 100 Milliarden Nervenzellen (Neuronen) und mehr als 100 Billionen Verbindungen (Synapsen) besteht.  Zum gr√∂√üten Teil wird das Gehirn durch diese Verbindungen bestimmt und wie jedes der Neuronen auf das eingehende Signal der anderen Neuronen reagiert. <br><br>  Wenn wir √ºber die au√üergew√∂hnlichen M√∂glichkeiten des menschlichen Gehirns sprechen, meinen wir normalerweise den j√ºngsten Erwerb eines langen Evolutionsprozesses - des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neokortex</a> (neuer Kortex).  Diese d√ºnne und extrem gefaltete Schicht bildet die √§u√üere H√ºlle des Gehirns und f√ºhrt sehr unterschiedliche Aufgaben aus, einschlie√ülich der Verarbeitung von Informationen, die von den Sinnen empfangen werden, der Steuerung der motorischen F√§higkeiten, der Arbeit mit dem Ged√§chtnis und des Lernens.  In einer ziemlich homogenen Struktur stehen so viele M√∂glichkeiten zur Verf√ºgung: sechs horizontale Schichten und eine Million vertikale S√§ulen mit einer Breite von 500 Œºm, bestehend aus Neuronen, die Informationen integrieren und verteilen, die in elektrischen Impulsen entlang der daraus wachsenden Antennen codiert sind - Dendriten und Axone. <br><br>  Wie alle Zellen des menschlichen K√∂rpers hat das Neuron ein elektrisches Potential in der Gr√∂√üenordnung von 70 mV zwischen der Au√üenfl√§che und den Innenseiten.  Diese Membranspannung √§ndert sich, wenn ein Neuron ein Signal von anderen damit verbundenen Neuronen empf√§ngt.  Wenn die Membranspannung auf einen kritischen Wert ansteigt, bildet sie einen Impuls oder einen Spannungsanstieg von mehreren Millisekunden in der Gr√∂√üenordnung von 40 mV.  Dieser Impuls breitet sich entlang des Axons eines Neurons aus, bis er die Synapse erreicht, eine komplexe biochemische Struktur, die das Axon eines Neurons mit dem Dendriten eines anderen verbindet.  Wenn der Impuls bestimmte Einschr√§nkungen erf√ºllt, wandelt die Synapse ihn in einen anderen Impuls um, der die Verzweigungsdendriten des Neurons, das das Signal empf√§ngt, hinuntergeht und seine Membranspannung in positiver oder negativer Richtung √§ndert. <br><br>  Konnektivit√§t ist ein kritisches Merkmal des Gehirns.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Pyramidenneuron</a> , ein besonders wichtiger Typ menschlicher Neocortexzellen, enth√§lt etwa 30.000 Synapsen, dh 30.000 Eingangskan√§le von anderen Neuronen.  Und das Gehirn passt sich st√§ndig an.  Das Neuron und die Eigenschaften der Synapse - und sogar die Struktur des Netzwerks selbst - √§ndern sich st√§ndig, haupts√§chlich unter dem Einfluss von Eingabedaten der Sinne und Umgebungsr√ºckkopplungen. <br><br>  Moderne Universalcomputer sind digital und nicht analog.  Die Klassifizierung des Gehirns ist nicht so einfach.  Neuronen akkumulieren eine elektrische Ladung wie Kondensatoren in elektronischen Schaltkreisen.  Dies ist eindeutig ein analoger Prozess.  Aber das Gehirn verwendet Bursts als Informationseinheiten, und dies ist im Grunde ein bin√§res Schema: Immer und √ºberall gibt es einen Burst oder nicht.  In Bezug auf die Elektronik ist das Gehirn ein System mit gemischten Signalen, mit lokalem analogem Rechnen und der √úbertragung von Informationen unter Verwendung von bin√§ren Bursts.  Da der Burst nur 0 oder 1 Werte hat, kann er eine lange Strecke zur√ºcklegen, ohne diese grundlegenden Informationen zu verlieren.  Es reproduziert sich auch und erreicht das n√§chste Neuron im Netzwerk. <br><br>  Ein weiterer wesentlicher Unterschied zwischen dem Gehirn und dem Computer besteht darin, dass das Gehirn mit der Verarbeitung von Informationen fertig wird, ohne dass eine zentrale Uhr ihren Betrieb synchronisiert.  Obwohl wir synchronisierende Ereignisse - Gehirnwellen - beobachten, organisieren sie sich selbst, die sich aus der Arbeit neuronaler Netze ergeben.  Interessanterweise beginnen moderne Computersysteme, die dem Gehirn innewohnende Asynchronit√§t zu √ºbernehmen, um Berechnungen zu beschleunigen, indem sie parallel ausgef√ºhrt werden.  Grad und Zweck der Parallelisierung dieser beiden Systeme sind jedoch √§u√üerst unterschiedlich. <br><br>  Die Idee, das Gehirn als Modell f√ºr die Datenverarbeitung zu verwenden, hat tiefe Wurzeln.  Die ersten Versuche basierten auf einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einfachen Schwellenwertneuron</a> , das einen Wert liefert, wenn die Summe der gewichteten Eingabedaten den Schwellenwert √ºberschreitet, und den anderen, wenn dies nicht der Fall ist.  Der biologische Realismus dieses Ansatzes, den Warren McCullough und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Walter Pitts</a> in den 1940er Jahren entwickelt haben, ist sehr begrenzt.  Dies war jedoch der erste Schritt zur Anwendung des Konzepts eines ausl√∂senden Neurons als Berechnungselement. <br><br>  1957 schlug <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Frank Rosenblatt</a> eine andere Version eines Schwellenneurons vor, das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Perzeptron</a> .  Ein Netzwerk miteinander verbundener Knoten (k√ºnstliche Neuronen) besteht aus Schichten.  Sichtbare Schichten auf der Oberfl√§che des Netzwerks interagieren als Ein- und Ausg√§nge mit der Au√üenwelt, und die verborgenen Schichten im Inneren f√ºhren alle Berechnungen durch. <br><br>  Rosenblatt schlug auch vor, ein Kernmerkmal des Gehirns zu verwenden: Eind√§mmung.  Anstatt alle Eingaben zu stapeln, k√∂nnen Neuronen im Perzeptron einen negativen Beitrag leisten.  Diese Funktion erm√∂glicht es neuronalen Netzen, eine einzelne verborgene Schicht zu verwenden, um XOR-Probleme in der Logik zu l√∂sen, bei denen die Ausgabe wahr ist, wenn nur eine der beiden Bin√§reing√§nge wahr ist.  Dieses einfache Beispiel zeigt, dass das Hinzuf√ºgen von biologischem Realismus neue Rechenf√§higkeiten hinzuf√ºgen kann.  Aber welche Funktionen des Gehirns sind f√ºr seine Arbeit notwendig und welche sind nutzlose Spuren der Evolution?  Niemand wei√ü es. <br><br>  Wir wissen, dass beeindruckende Rechenergebnisse erzielt werden k√∂nnen, ohne zu versuchen, biologischen Realismus zu erzeugen.  Deep-Learning-Forscher haben einen langen Weg zur√ºckgelegt, um mithilfe von Computern gro√üe Datenmengen zu analysieren und bestimmte Attribute aus komplexen Bildern zu extrahieren.  Obwohl die von ihnen erstellten neuronalen Netze mehr Eingaben und verborgene Schichten aufweisen als jemals zuvor, basieren sie immer noch auf extrem einfachen Neuronenmodellen.  Ihre vielf√§ltigen M√∂glichkeiten spiegeln nicht den biologischen Realismus wider, sondern die Gr√∂√üe der in ihnen enthaltenen Netzwerke und die Leistung der Computer, die f√ºr ihr Training verwendet werden.  Deep-Learning-Netzwerke sind jedoch noch weit von Rechengeschwindigkeit, Energieeffizienz und biologischen Lernf√§higkeiten des Gehirns entfernt. <br><br>  Die gro√üe Kluft zwischen dem Gehirn und modernen Computern wird am besten durch gro√ü angelegte Gehirnsimulationen hervorgehoben.  In den letzten Jahren wurden mehrere solcher Versuche unternommen, die jedoch alle durch zwei Faktoren stark eingeschr√§nkt wurden: Energie und Simulationszeit.  Stellen Sie sich zum Beispiel eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Simulation vor,</a> die Markus Daisman und seine Kollegen vor einigen Jahren mit 83.000 Prozessoren auf einem K-Supercomputer in Japan durchgef√ºhrt haben.  Die Simulation von 1,73 Milliarden Neuronen verbrauchte 10 Milliarden Mal mehr Energie als die entsprechende Fl√§che des Gehirns, obwohl sie extrem vereinfachte Modelle verwendeten und kein Training durchf√ºhrten.  Und solche Simulationen arbeiteten normalerweise mehr als 1000 Mal langsamer als das biologische Echtzeithirn. <br><br>  Warum sind sie so langsam?  Gehirnsimulationen auf herk√∂mmlichen Computern erfordern die Berechnung von Milliarden von Differentialgleichungen, die miteinander verbunden sind und die Dynamik von Zellen und Netzwerken beschreiben: analoge Prozesse wie das Bewegen einer Ladung √ºber eine Zellmembran.  Computer, die boolesche Logik verwenden - Energie f√ºr Genauigkeit √§ndern - und Speicher und Berechnung gemeinsam nutzen, sind bei der Modellierung des Gehirns √§u√üerst ineffizient. <br><br>  Diese Simulationen k√∂nnen zu einem Werkzeug f√ºr die Erkennung des Gehirns werden, indem die im Labor erhaltenen Daten in Simulationen √ºbertragen werden, mit denen wir experimentieren und die Ergebnisse dann mit Beobachtungen vergleichen k√∂nnen.  Wenn wir jedoch hoffen, in eine andere Richtung zu gehen und die Lehren der Neurobiologie zu nutzen, um neue Computersysteme zu entwickeln, m√ºssen wir √ºberdenken, wie wir Computer entwerfen und erstellen. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2bd/b7a/481/2bdb7a48108ec3979ff6b184c86d3240.jpg" alt="Bild"><br>  <i>Neuronen in Silizium.</i> <br><br>  Das Kopieren der Arbeit des Gehirns mithilfe von Elektronik kann praktikabler sein, als es auf den ersten Blick scheint.  Es stellt sich heraus, dass etwa 10 fJ ( <sup>10-15</sup> Joule) f√ºr die Erzeugung eines elektrischen Potentials an der Synapse aufgewendet werden.  Das Gate eines Metalloxid-Halbleiter (MOS) -Transistors, das viel gr√∂√üer ist und mehr Energie verbraucht als die in der CPU verwendeten, ben√∂tigt zum Laden nur 0,5 fJ.  Es stellt sich heraus, dass die synaptische √úbertragung dem Laden von 20 Transistoren entspricht.  Dar√ºber hinaus unterscheiden sich biologische und elektronische Schaltkreise auf Ger√§teebene nicht so stark.  Im Prinzip k√∂nnen Sie aus Transistoren Strukturen wie Synapsen und Neuronen erstellen und diese so verbinden, dass ein k√ºnstliches Gehirn entsteht, das nicht so viel Energie absorbiert. <br><br>  Die Idee, Computer mit Transistoren zu erstellen, die wie Neuronen funktionieren, entstand in den 1980er Jahren mit Professor Carver Mead von Caltech.  Eines der Hauptargumente von Mead f√ºr ‚Äûneuromorphe‚Äú Computer war, dass Halbleiterbauelemente in einem bestimmten Modus denselben physikalischen Gesetzen wie Neuronen folgen k√∂nnen und dass analoges Verhalten f√ºr Berechnungen mit hoher Energieeffizienz verwendet werden kann. <br><br>  Meads Gruppe hat auch eine neuronale Kommunikationsplattform erfunden, bei der Bursts nur durch ihre Netzwerkadressen und den Zeitpunkt des Auftretens codiert werden.  Diese Arbeit war bahnbrechend, da sie als erste die Zeit zu einem notwendigen Merkmal k√ºnstlicher neuronaler Netze machte.  Zeit ist ein Schl√ºsselfaktor f√ºr das Gehirn.  Signale brauchen Ausbreitungszeit, Membranen brauchen Reaktionszeit und es ist die Zeit, die die Form der postsynaptischen Potentiale bestimmt. <br><br>  Mehrere aktive Forschungsgruppen, zum Beispiel die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Giacomo Indiveri-</a> Gruppe der Swiss Higher Technical School und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kwabena Bohen</a> aus Stanford, sind in die Fu√üstapfen von Mead getreten und haben erfolgreich Elemente biologischer kortikaler Netzwerke eingef√ºhrt.  Der Trick besteht darin, mit Transistoren mit einem Niederspannungsstrom zu arbeiten, der ihren Schwellenwert nicht erreicht, und analoge Schaltkreise zu erstellen, die das Verhalten des Nervensystems kopieren und dabei ein wenig Energie verbrauchen. <br><br>  Weitere Forschungen in dieser Richtung k√∂nnten in Systemen wie der Gehirn-Computer-Schnittstelle Anwendung finden.  Es gibt jedoch eine gro√üe L√ºcke zwischen diesen Systemen und der tats√§chlichen Gr√∂√üe des Netzwerks, der Konnektivit√§t und der Lernf√§higkeit des tierischen Gehirns. <br><br>  In der Region 2005 begannen drei Forschergruppen unabh√§ngig voneinander, neuromorphe Systeme zu entwickeln, die sich erheblich von Meads urspr√ºnglichem Ansatz unterschieden.  Sie wollten gro√üe Systeme mit Millionen von Neuronen schaffen. <br><br>  Am n√§chsten an normalen Computern ist das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SpiNNaker-</a> Projekt unter der Leitung von Steve Ferber von der University of Manchester.  Diese Gruppe entwickelte einen eigenen digitalen Chip, der aus 18 ARM-Prozessoren besteht, die mit 200 MHz arbeiten - etwa ein Zehntel der Geschwindigkeit moderner CPUs.  Obwohl die ARM-Kerne aus der Welt der klassischen Computer stammen, simulieren sie Bursts, die √ºber spezielle Router gesendet werden, um Informationen asynchron zu √ºbertragen - genau wie das Gehirn.  Die aktuelle Implementierung, die Teil des Human Brain Project der Europ√§ischen Union ist und 2016 abgeschlossen wurde, enth√§lt 500.000 ARM-Kerne.  Abh√§ngig von der Komplexit√§t des Neuronenmodells kann jeder Kern bis zu 1000 Neuronen simulieren. <br><br>  Der von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Darmendra Maud</a> und seinen Kollegen am IBM Research Laboratory in Almaden entwickelte TrueNorth-Chip lehnt die Verwendung von Mikroprozessoren als Recheneinheiten ab und ist tats√§chlich ein neuromorphes System, in dem Computer und Speicher miteinander verflochten sind.  TrueNorth bleibt weiterhin ein digitales System, basiert jedoch auf speziell entwickelten Neurokonturen, die ein bestimmtes Neuronenmodell implementieren.  Der Chip enth√§lt 5,4 Milliarden Transistoren und basiert auf der 28-nm-Samsung- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CMOS-</a> Technologie (komplement√§re Metalloxid-Halbleiter-Struktur).  Transistoren emulieren 1 Million neuronale Schaltungen und 256 Millionen einfache (Einzelbit-) Synapsen auf einem einzelnen Chip. <br><br>  Ich w√ºrde sagen, dass das n√§chste Projekt, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BrainScaleS</a> , ziemlich weit von herk√∂mmlichen Computern entfernt war und dem biologischen Gehirn nahe kam.  Wir haben mit meinen Kollegen von der Universit√§t Heidelberg an diesem Projekt f√ºr die europ√§ische Initiative ‚ÄûThe Human Brain‚Äú gearbeitet.  BrainScaleS implementiert die gemischte Signalverarbeitung.  Es kombiniert Neuronen und Synapsen, in deren Rolle Siliziumtransistoren als analoge Ger√§te mit digitalem Informationsaustausch fungieren.  Das System in voller Gr√∂√üe besteht aus 8-Zoll-Siliziumsubstraten und erm√∂glicht die Emulation von 4 Millionen Neuronen und 1 Milliarde Synapsen. <br><br>  Das System kann neun verschiedene Reaktionsmodi biologischer Neuronen reproduzieren und wurde in enger Zusammenarbeit mit Neurowissenschaftlern entwickelt.  Im Gegensatz zu Meads analogem Ansatz arbeitet BrainScaleS im beschleunigten Modus. Die Emulation ist 10.000-mal schneller als in Echtzeit.  Dies ist besonders praktisch, um den Lernprozess und die Entwicklung zu studieren. <br><br>  Lernen wird wahrscheinlich zu einer kritischen Komponente neuromorpher Systeme.  Jetzt werden Chips, die im Bild des Gehirns hergestellt wurden, sowie neuronale Netze, die auf normalen Computern ausgef√ºhrt werden, mit Hilfe leistungsf√§higerer Computer nebenbei trainiert.  Wenn wir jedoch neuromorphe Systeme in realen Anwendungen einsetzen m√∂chten - zum Beispiel in Robotern, die Seite an Seite mit uns arbeiten m√ºssen, m√ºssen sie in der Lage sein, im laufenden Betrieb zu lernen und sich anzupassen. <br><br>  In der zweiten Generation unseres BrainScaleS-Systems haben wir die Schulungsm√∂glichkeit implementiert, indem wir ‚ÄûFlexibilit√§tsprozessoren‚Äú auf dem Chip erstellt haben.  Sie werden verwendet, um eine Vielzahl von Parametern von Neuronen und Synapsen zu √§ndern.  Mit dieser Funktion k√∂nnen wir die Parameter fein einstellen, um Unterschiede in Gr√∂√üe und elektrischen Eigenschaften beim Wechsel von einem Ger√§t zum anderen auszugleichen - ungef√§hr so, wie sich das Gehirn selbst an √Ñnderungen anpasst. <br><br>  Die drei von mir beschriebenen Gro√üsysteme erg√§nzen sich.  SpiNNaker kann flexibel konfiguriert und zum Testen verschiedener Neuromodelle verwendet werden. TrueNorth hat eine hohe Integrationsdichte. BrainScaleS wurde f√ºr kontinuierliches Training und Entwicklung entwickelt.  Die Suche nach dem richtigen Weg zur Bewertung der Wirksamkeit solcher Systeme ist noch nicht abgeschlossen.  Die ersten Ergebnisse sind jedoch vielversprechend.  Das TrueNorth-Team von IBM hat k√ºrzlich berechnet, dass die synaptische √úbertragung in ihrem System 26 pJ dauert.  Und obwohl in einem biologischen System 1000-mal mehr Energie ben√∂tigt wird, wird in Simulationen auf Allzweckcomputern fast 100 000-mal weniger Energie f√ºr die √úbertragung ben√∂tigt. <br><br>  Wir sind noch in einem fr√ºhen Stadium, um zu verstehen, was solche Systeme k√∂nnen und wie sie zur L√∂sung realer Probleme eingesetzt werden k√∂nnen.  Gleichzeitig m√ºssen wir Wege finden, um viele neuromorphe Chips in gro√üen Netzwerken mit verbesserten Lernf√§higkeiten zu kombinieren und gleichzeitig den Stromverbrauch zu senken.  Eines der Probleme ist die Konnektivit√§t: Das Gehirn ist dreidimensional und unsere Schaltkreise sind zweidimensional.  Das Problem der dreidimensionalen Integration von Schaltkreisen wird derzeit aktiv untersucht, und solche Technologien k√∂nnen uns helfen. <br><br>  Ger√§te, die nicht auf CMOS- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Memristoren</a> oder PCRAM ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Speicher mit Phasenzustands√§nderung</a> ) basieren, k√∂nnen eine weitere Hilfe sein.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Heutzutage werden die Gewichte, die die Reaktion k√ºnstlicher Synapsen auf eingehende Signale bestimmen, in einem normalen digitalen Speicher gespeichert, der den gr√∂√üten Teil der zum Aufbau eines Netzwerks erforderlichen Siliziumressourcen beansprucht. </font><font style="vertical-align: inherit;">Andere Arten von Speicher k√∂nnen uns jedoch dabei helfen, die Gr√∂√üe dieser Zellen von Mikrometer auf Nanometer zu reduzieren. </font><font style="vertical-align: inherit;">Die Hauptschwierigkeit moderner Systeme besteht darin, die Unterschiede zwischen verschiedenen Ger√§ten zu unterst√ºtzen. </font><font style="vertical-align: inherit;">Die von BrainScaleS entwickelten Kalibrierungsprinzipien k√∂nnen helfen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben gerade unsere Reise auf dem Weg zu praktischen und n√ºtzlichen neuromorphen Systemen begonnen. </font><font style="vertical-align: inherit;">Aber die M√ºhe lohnt sich. </font><font style="vertical-align: inherit;">Wenn dies gelingt, werden wir nicht nur leistungsstarke Computersysteme erstellen. </font><font style="vertical-align: inherit;">Wir k√∂nnen sogar neue Informationen √ºber die Arbeit unseres eigenen Gehirns erhalten.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de405285/">https://habr.com/ru/post/de405285/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de405269/index.html">Neuronales Netz machte gef√§lschten Obama</a></li>
<li><a href="../de405273/index.html">Funknetze austauschen</a></li>
<li><a href="../de405275/index.html">Fragen Sie Ethan: K√∂nnen die Sterne aus der Galaxie entkommen, ohne den Planeten zu besch√§digen?</a></li>
<li><a href="../de405281/index.html">Flash-Laufwerk, Kabel- und Kartenleser: Vergleichen Sie drei externe Laufwerke f√ºr iPhone und iPad</a></li>
<li><a href="../de405283/index.html">50 Schattierungen von Stumpf *. Mikrocontroller in Schaltnetzteilen. Teil 2</a></li>
<li><a href="../de405287/index.html">Fehler Fehler: Eine kurze Geschichte des Anti-Aging</a></li>
<li><a href="../de405289/index.html">Wie man sowjetische Lieder auf Englisch singt und die Aussprache entwickelt</a></li>
<li><a href="../de405291/index.html">Ab dem 1. August kann Bitcoin in zwei oder mehr Versionen aufgeteilt werden</a></li>
<li><a href="../de405293/index.html">Hyperloop One verteilte zum ersten Mal ein schwebendes Chassis in einem technischen Vakuum</a></li>
<li><a href="../de405295/index.html">Schlechte Nachrichten: SoundCloud-Reduzierung und Jawbone-Eliminierung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
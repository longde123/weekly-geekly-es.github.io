<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🈸 📰 🐨 AI, curso práctico. Aprendizaje profundo para generar música. 🤵🏽 🈹 🏹</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este es el último artículo de una serie de artículos de capacitación para desarrolladores en el campo de la inteligencia artificial. Discute los pasos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso práctico. Aprendizaje profundo para generar música.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/423727/"><img src="https://habrastorage.org/webt/zy/do/u4/zydou4yx-zh_x9qzbumtrbdhwy4.jpeg"><br><br>  Este es el último artículo de una serie de artículos de capacitación para desarrolladores en el campo de la inteligencia artificial.  Discute los pasos para crear un modelo de aprendizaje profundo para la generación de música, elegir el modelo correcto y el preprocesamiento de datos, y describe los procedimientos para configurar, entrenar, probar y modificar BachBot. <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Generación de música: pensar en una tarea</font> </h2><br>  El primer paso para resolver muchos problemas usando la inteligencia artificial (IA) es reducir el problema a un problema básico que pueda resolverse por medio de la IA.  Uno de estos problemas es la predicción de secuencia, que se utiliza en aplicaciones de traducción y procesamiento de lenguaje natural.  Nuestra tarea de generar música puede reducirse al problema de predecir una secuencia, y la predicción se realizará para una secuencia de notas musicales. <br><br><h2>  <font color="#0071c5">Selección de modelo</font> </h2><br>  Existen varios tipos diferentes de redes neuronales que pueden considerarse modelos: redes neuronales de distribución directa, redes neuronales recurrentes y redes neuronales de memoria a largo plazo. <br><br>  Las neuronas son los elementos abstractos básicos que se combinan para formar redes neuronales.  Esencialmente, una neurona es una función que recibe datos en la entrada y genera el resultado. <br><br><img src="https://habrastorage.org/webt/56/pq/hs/56pqhseblx5mqec0apoegck7vd4.png"><br>  <i>Neurona</i> <br><br>  Las capas de neuronas que reciben los mismos datos en la entrada y tienen salidas conectadas se pueden combinar para construir una <i>red neuronal con propagación directa</i> .  Dichas redes neuronales demuestran altos resultados debido a la composición de funciones de activación no lineal al pasar datos a través de varias capas (el llamado aprendizaje profundo). <br><br><img src="https://habrastorage.org/webt/e8/ps/1v/e8ps1vchys7uap5mjucmyip5ob8.png"><br>  <i>Red neuronal de distribución directa.</i> <br><br>  Una red neuronal de distribución directa muestra buenos resultados en una amplia gama de aplicaciones.  Sin embargo, dicha red neuronal tiene un inconveniente que no permite su uso en una tarea relacionada con la composición musical (predicción de secuencia): tiene una dimensión fija de datos de entrada y las composiciones musicales pueden tener diferentes longitudes.  Además, <i>las redes neuronales de distribución directa no tienen en cuenta las entradas de los pasos de tiempo anteriores, ¡lo que las hace poco útiles para resolver el problema de predicción de secuencias!</i>  Un modelo llamado <i>red neuronal recurrente es</i> más adecuado para esta tarea. <br><br>  Las redes neuronales recursivas resuelven ambos problemas mediante la introducción de enlaces entre nodos ocultos: en este caso, en el siguiente paso de tiempo, los nodos pueden recibir información sobre los datos en el paso de tiempo anterior. <br><br><img src="https://habrastorage.org/webt/xc/jv/dr/xcjvdrzlx66olpyziwbtfywxukq.png"><br>  <i>Representación detallada de una red neuronal recurrente.</i> <br><br>  Como puede ver en la figura, cada neurona ahora recibe información de la capa neural anterior y la hora anterior. <br><br>  Las redes neuronales recursivas que se ocupan de grandes secuencias de entrada encuentran el llamado <i>problema del gradiente de fuga</i> : esto significa que la influencia de los pasos de tiempo anteriores desaparece rápidamente.  Este problema es característico de la tarea de composición musical, ya que hay importantes dependencias a largo plazo en las obras musicales que deben tenerse en cuenta. <br><br>  Para resolver el problema de un gradiente de fuga <i>, se puede utilizar</i> una modificación de la red recurrente, que se denomina <i>red neuronal con memoria a largo plazo (o red neuronal LSTM)</i> .  Este problema se resuelve introduciendo celdas de memoria, que son monitoreadas cuidadosamente por tres tipos de "compuertas".  Haga clic en el siguiente enlace para obtener más información: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Información general sobre redes neuronales LSTM</a> . <br><br>  Por lo tanto, BachBot utiliza un modelo basado en la red neuronal LSTM. <br><br><h2>  <font color="#0071c5">Pretratamiento</font> </h2><br>  La música es una forma de arte muy compleja e incluye varias dimensiones: tono, ritmo, tempo, sombras dinámicas, articulación y más.  Para simplificar la música para los propósitos de este proyecto <i>, solo se consideran el tono y la duración de los sonidos</i> .  Además, todos los corales se <i>transpusieron</i> a la clave en do mayor o en menor, y las duraciones de las notas se <i>cuantificaron en el tiempo</i> (redondeadas) al múltiplo más cercano de la semicorchea.  Estas acciones se tomaron para reducir la complejidad de las composiciones y aumentar el rendimiento de la red, mientras que el contenido básico de la música se mantuvo sin cambios.  Las operaciones para normalizar las tonalidades y la duración de las notas se realizaron utilizando la biblioteca music21. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">standardize_key</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Converts into the key of C major or A minor. Adapted from https://gist.github.com/aldous-rey/68c6c43450517aa47474 """</span></span> <span class="hljs-comment"><span class="hljs-comment"># conversion tables: eg Ab -&gt; C is up 4 semitones, D -&gt; A is down 5 semitones majors = dict([("A-", 4),("A", 3),("B-", 2),("B", 1),("C", 0),("C#",-1), ("D-", -1),("D", -2),("E-", -3),("E", -4),("F", -5),("F#",6), ("G-", 6), ("G", 5)]) minors = dict([("A-", 1),("A", 0),("B-", -1),("B", -2),("C", -3),("C#",-4), ("D-", -4),("D", -5),("E-", 6),("E", 5),("F", 4),("F#",3), ("G-",3),("G", 2)]) # transpose score key = score.analyze('key') if key.mode == "major": halfSteps = majors[key.tonic.name] elif key.mode == "minor": halfSteps = minors[key.tonic.name] tScore = score.transpose(halfSteps) # transpose key signature for ks in tScore.flat.getKeySignatures(): ks.transpose(halfSteps, inPlace=True) return tScore</span></span></code> </pre> <br>  <i>El código utilizado para estandarizar los caracteres clave en los trabajos recopilados, las claves en Do mayor o A menor se usan en la salida</i> <br><br>  La cuantificación del tiempo al múltiplo más cercano de la semicorchea se realizó utilizando la función <i>Stream.quantize ()</i> de la biblioteca <i>music21</i> .  La siguiente es una comparación de las estadísticas asociadas con un conjunto de datos antes y después de su procesamiento preliminar: <br><br><img src="https://habrastorage.org/webt/kr/wh/5n/krwh5n0d1dubkwn0urbjmp7ovzs.png"><br>  <i>Usando cada clase de notas antes (izquierda) y después del preprocesamiento (derecha).</i>  <i>Una clase de nota es una nota independientemente de su octava.</i> <br><br><img src="https://habrastorage.org/webt/mz/rq/i0/mzrqi0fynco56dhr9kdk-nsfjrs.png"><br>  <i>Ubicación de las notas antes (izquierda) y después del preprocesamiento (derecha)</i> <br><br>  Como puede ver en la figura anterior, la transposición de la clave original de los corales a la clave de Do mayor o Do menor (A menor) influyó significativamente en la clase de notas utilizadas en los trabajos recopilados.  En particular, el número de ocurrencias para notas en teclas en teclas principales (Do mayor) y A menor (A menor) (C, D, E, F, G, A, B) aumentó.  También puede observar pequeños picos para las notas F # y G # debido a su presencia en la secuencia ascendente de la melódica A menor (A, B, C, D, E, F # y G #).  <i>Por otro lado, la cuantización del tiempo tuvo un efecto mucho menor.</i>  Esto puede explicarse por la alta resolución de cuantización (similar al redondeo a muchos dígitos significativos). <br><br><h2>  <font color="#0071c5">Codificación</font> </h2><br>  Una vez que los datos han sido preprocesados, es necesario codificar los corales en un formato que pueda procesarse fácilmente utilizando una red neuronal recurrente.  El formato requerido es una <i>secuencia de tokens</i> .  Para el proyecto BachBot, la codificación se eligió a nivel de notas (cada token representa una nota) en lugar del nivel de acordes (cada token representa un acorde).  Esta solución redujo el tamaño del diccionario de 128 <sup>4</sup> acordes posibles a 128 notas posibles, lo que permitió aumentar la eficiencia del trabajo. <br><br>  Se creó un esquema de codificación original para composiciones musicales para el proyecto BachBot.  El coral se divide en pasos de tiempo correspondientes a las semicorcheas.  Estos pasos se llaman marcos.  Cada cuadro contiene una secuencia de tuplas que representan el valor del tono de una nota en el formato de una interfaz de instrumento musical digital (MIDI) y un signo de unión de esta nota a una nota anterior de la misma altura (nota, signo de unión).  Las notas dentro del marco están numeradas en orden descendente de altura (soprano → alt → tenor → bajo).  Cada cuadro también puede tener un cuadro que marca el final de una frase;  Fermata se representa con un símbolo de punto (.) Sobre la nota.  Los símbolos <i>START</i> y <i>END</i> se agregan al principio y al final de cada coral.  Estos símbolos provocan la inicialización del modelo y permiten al usuario determinar cuándo termina la composición. <br><br> <code>START <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (.) <br> (57, False) <br> (52, False) <br> (48, False) <br> (45, False) <br> ||| <br> (.) <br> (57, True) <br> (52, True) <br> (48, True) <br> (45, True) <br> ||| <br> END</code> <br>  <i>Un ejemplo de codificación de dos acordes.</i>  <i>Cada acorde dura un octavo tiempo de una medida, el segundo acorde está acompañado por una granja.</i>  <i>La secuencia "|||"</i>  <i>marca el final del marco</i> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">encode_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score, keep_fermatas=True, parts_to_mask=[])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Encodes a music21 score into a List of chords, where each chord is represented with a (Fermata :: Bool, List[(Note :: Integer, Tie :: Bool)]). If `keep_fermatas` is True, all `has_fermata`s will be False. All tokens from parts in `parts_to_mask` will have output tokens `BLANK_MASK_TXT`. Time is discretized such that each crotchet occupies `FRAMES_PER_CROTCHET` frames. """</span></span> encoded_score = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chord <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (score .quantize((FRAMES_PER_CROTCHET,)) .chordify(addPartIdAsGroup=bool(parts_to_mask)) .flat .notesAndRests): <span class="hljs-comment"><span class="hljs-comment"># aggregate parts, remove markup # expand chord/rest st constant timestep between frames if chord.isRest: encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET)) * [[]]) else: has_fermata = (keep_fermatas) and any(map(lambda e: e.isClassOrSubclass(('Fermata',)), chord.expressions)) encoded_chord = [] # </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> sorts Soprano, Bass, Alto, Tenor without breaking ties # c = chord.sortAscending() # sorted_notes = [c[-1], c[0]] + c[1:-1] # for note in sorted_notes: for note in chord: if parts_to_mask and note.pitch.groups[0] in parts_to_mask: encoded_chord.append(BLANK_MASK_TXT) else: has_tie = note.tie is not None and note.tie.type != 'start' encoded_chord.append((note.pitch.midi, has_tie)) encoded_score.append((has_fermata, encoded_chord)) # repeat pitches to expand chord into multiple frames # all repeated frames when expanding a chord should be tied encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET) - 1) * [ (has_fermata, map(lambda note: BLANK_MASK_TXT if note == BLANK_MASK_TXT else (note[0], True), encoded_chord)) ]) return encoded_score</span></span></code> </pre> <br>  <i>Código utilizado para codificar la tonalidad music21 usando un esquema de codificación especial</i> <br><br><h2>  <font color="#0071c5">Tarea modelo</font> </h2><br>  En la parte anterior, se dio una explicación que muestra que la tarea de composición automática puede reducirse a la tarea de predecir una secuencia.  En particular, un modelo puede predecir la próxima nota más probable basándose en notas anteriores.  Una red neuronal con memoria a largo plazo (LSTM) es la más adecuada para resolver este tipo de problema.  Formalmente, el modelo debe predecir P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), la distribución de probabilidad para las siguientes notas posibles (x <sub>t + 1</sub> ) en función del token actual (x <sub>t</sub> ) y el estado oculto anterior (h <sub>t-1</sub> ) .  Curiosamente, los modelos de lenguaje basados ​​en redes neuronales recurrentes realizan la misma operación. <br><br>  En el modo de composición, el modelo se inicializa con el token <i>START</i> , luego de lo cual selecciona el siguiente token más probable a seguir.  Después de eso, el modelo continúa seleccionando el siguiente token más probable utilizando la nota anterior y el estado oculto anterior hasta que se genere un token END.  El sistema contiene elementos de temperatura que agregan cierto grado de aleatoriedad para evitar que BachBot componga la misma pieza una y otra vez. <br><br><h3>  <font color="#0071c5">Función de pérdida</font> </h3><br>  Al entrenar un modelo para la predicción, generalmente hay alguna función que debe minimizarse (llamada función de pérdida).  Esta función describe la diferencia entre la predicción del modelo y la propiedad de la verdad fundamental.  BachBot minimiza la pérdida de entropía cruzada entre la distribución prevista (x <sub>t + 1</sub> ) y la distribución real de la función objetivo.  Usar la entropía cruzada como una función de pérdida es un buen punto de partida para una amplia gama de tareas, pero en algunos casos puede usar su propia función de pérdida.  Otro enfoque aceptable es tratar de usar varias funciones de pérdida y aplicar un modelo que minimice la pérdida real durante la verificación. <br><br><h3>  <font color="#0071c5">Entrenamiento / prueba</font> </h3><br>  Al entrenar una red neuronal recursiva, BachBot usó la corrección de tokens con el valor x <sub>t + 1 en</sub> lugar de aplicar la predicción del modelo.  Este proceso, conocido como aprendizaje obligatorio, se utiliza para garantizar la convergencia, ya que las predicciones del modelo producirán naturalmente malos resultados al comienzo de la capacitación.  Por el contrario, durante la validación y la composición, la predicción del modelo x <sub>t + 1</sub> debe reutilizarse como entrada para la próxima predicción. <br><br><h3>  <font color="#0071c5">Otras consideraciones</font> </h3><br>  Para aumentar la eficiencia en este modelo, se usaron los siguientes métodos prácticos que son comunes a las redes neuronales LSTM: truncamiento de gradiente normalizado, método de eliminación, normalización de paquetes y método de propagación por error de tiempo truncado (BPTT). <br><br>  <i>El método de truncamiento de gradiente normalizado</i> elimina el problema del crecimiento incontrolado del valor del gradiente (lo inverso del problema del gradiente de fuga, que se resolvió utilizando la arquitectura de las celdas de memoria LSTM).  Con esta técnica, los valores de gradiente que exceden un cierto umbral se truncan o escalan. <br><br>  <i>El método de exclusión</i> es una técnica en la que algunas neuronas <i>seleccionadas al azar se</i> desconectan (excluyen) durante el entrenamiento de la red.  Esto evita el sobreajuste y mejora la calidad de la generalización.  El problema del sobreajuste surge cuando el modelo se optimiza para el conjunto de datos de entrenamiento y, en menor medida, se aplica a muestras fuera de este conjunto.  El método de exclusión a menudo empeora la pérdida durante el entrenamiento, pero la mejora en la etapa de verificación (más sobre esto a continuación). <br><br>  El cálculo del gradiente en una red neuronal recurrente para una secuencia de 1000 elementos es equivalente en costo a los pasos hacia adelante y hacia atrás en la red neuronal de distribución directa de 1000 capas.  <i>El</i> método de <i>propagación de error truncada</i> (BPTT) a lo largo del tiempo se usa para reducir el costo de actualizar los parámetros durante el entrenamiento.  Esto significa que los errores se propagan solo durante un número fijo de pasos contados desde el momento actual.  Tenga en cuenta que las dependencias de aprendizaje a largo plazo todavía son posibles con el método BPTT, ya que los estados latentes ya se han revelado en muchos pasos anteriores. <br><br><h3>  <font color="#0071c5">Parámetros</font> </h3><br>  La siguiente es una lista de parámetros relevantes para modelos de redes neuronales recurrentes / redes neuronales con memoria a largo plazo a corto plazo: <br><ul><li>  <i>El número de capas</i> .  Aumentar este parámetro puede aumentar la eficiencia del modelo, pero llevará más tiempo entrenarlo.  Además, demasiadas capas pueden conducir a un sobreajuste. </li><li>  <i>La dimensión del estado latente</i> .  El aumento de este parámetro puede aumentar la complejidad del modelo, sin embargo, esto puede conducir a un sobreajuste. </li><li>  <i>Dimensión de las comparaciones de vectores</i> </li><li>  <i>La longitud de secuencia</i> / número de tramas antes de truncar la propagación hacia atrás del error a lo largo del tiempo. </li><li>  <i>Probabilidad de exclusión de neuronas</i> .  La probabilidad con la que una neurona será excluida de la red durante cada ciclo de actualización. </li></ul><br>  La metodología para seleccionar el conjunto óptimo de parámetros se discutirá más adelante en este artículo. <br><br><h2>  <font color="#0071c5">Implementación, entrenamiento y pruebas.</font> </h2><br><h3>  <font color="#0071c5">Selección de plataforma</font> </h3><br>  Actualmente, hay muchas plataformas que le permiten implementar modelos de aprendizaje automático en varios lenguajes de programación (¡incluso JavaScript!).  Las plataformas populares incluyen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">scikit-learn</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Torch</a> . <br><br>  La biblioteca Torch fue seleccionada como la plataforma para el proyecto BachBot.  Al principio, se probó la biblioteca TensorFlow, pero en ese momento utilizó redes neuronales recurrentes extensas, lo que condujo a un desbordamiento de la RAM de la GPU.  Torch es una plataforma de computación científica impulsada por el rápido lenguaje de programación LuaJIT *.  La plataforma Torch contiene excelentes bibliotecas para trabajar con redes neuronales y optimización. <br><br><h3>  <font color="#0071c5">Implementación y capacitación de modelos.</font> </h3><br>  La implementación, obviamente, variará según el idioma y la plataforma que elija.  Para saber cómo BachBot implementa redes neuronales con memoria a corto y largo plazo utilizando Torch, consulte los scripts utilizados para entrenar y establecer los parámetros de BachBot.  Estas secuencias de comandos están disponibles en el sitio web de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Feynman Lyang GitHub.</a> <br><br>  Un buen punto de partida para navegar por el repositorio es el <a href="">script 1-train.zsh</a> .  Con él, puede encontrar la ruta al archivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bachbot.py</a> . <br><br>  Más precisamente, el script principal para configurar los parámetros del modelo es el archivo <a href="">LSTM.lua</a> .  El script para entrenar el modelo es el archivo <a href="">train.lua</a> . <br><br><h3>  <font color="#0071c5">Optimización de hiperparámetros</font> </h3><br>  Para buscar los valores óptimos de los hiperparámetros, se utilizó el método de búsqueda de cuadrícula utilizando la siguiente cuadrícula de parámetros. <br><br><img src="https://habrastorage.org/webt/91/7p/_3/917p_3g7mtewimqlykgaskxn8y0.png"><br>  <i>Cuadrícula de parámetros utilizados por BachBot en la búsqueda de cuadrícula</i> <br><br>  Una búsqueda de cuadrícula es una búsqueda completa de todas las combinaciones posibles de parámetros.  Otros métodos sugeridos para optimizar los hiperparámetros son la búsqueda aleatoria y la optimización bayesiana. <br><br>  El conjunto óptimo de hiperparámetros detectados como resultado de una búsqueda de cuadrícula es el siguiente: número de capas = 3, dimensión del estado oculto = 256, dimensión de las comparaciones de vectores = 32, longitud de secuencia = 128, probabilidad de eliminación de neuronas = 0.3. <br><br>  Este modelo alcanzó una pérdida de entropía cruzada de 0.324 durante el entrenamiento y 0.477 en la etapa de verificación.  El gráfico de la curva de aprendizaje demuestra que el proceso de aprendizaje converge después de 30 iteraciones (≈28.5 minutos cuando se usa una sola GPU). <br><br>  Los gráficos de pérdida durante el entrenamiento y durante la fase de verificación también pueden ilustrar el efecto de cada hiperparámetro.  De particular interés para nosotros es la probabilidad de eliminar neuronas: <br><br><img src="https://habrastorage.org/webt/ad/zd/_s/adzd_s3hxek23oyz8dqg_d1pkys.png"><br>  <i>Curvas de aprendizaje para varias configuraciones de métodos de exclusión</i> <br><br>  Se puede ver en la figura que el método de eliminación realmente evita la aparición de sobreajuste.  Aunque con una probabilidad de exclusión de 0.0, la pérdida durante el entrenamiento es mínima, en la etapa de verificación, la pérdida tiene un valor máximo.  Grandes valores de probabilidad conducen a un aumento de las pérdidas durante el entrenamiento y una disminución de las pérdidas en la etapa de verificación.  El valor mínimo de la pérdida durante la fase de verificación cuando se trabaja con BachBot se corrigió con una probabilidad de excepción de 0.3. <br><br><h3>  <font color="#0071c5">Métodos de evaluación alternativos (opcional)</font> </h3><br>  Para algunos modelos, especialmente para aplicaciones creativas como componer música, la pérdida puede no ser una medida adecuada del éxito del sistema.  En cambio, la percepción humana subjetiva puede ser el mejor criterio. <br><br>  El objetivo del proyecto BachBot es componer automáticamente música que no se pueda distinguir de las propias composiciones de Bach.  Para evaluar el éxito de los resultados, se realizó una encuesta de usuarios en Internet.  La encuesta recibió la forma de un concurso en el que se pidió a los usuarios que determinaran qué obras pertenecen al proyecto BachBot y cuáles a Bach. <br><br>  Los resultados de la encuesta mostraron que los participantes de la encuesta (759 personas con diferentes niveles de capacitación) pudieron distinguir con precisión entre dos muestras en solo el 59 por ciento de los casos.  ¡Esto es solo un 9 por ciento más alto que el resultado de suposiciones aleatorias!  ¡Pruebe la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">encuesta BachBot</a> usted mismo! <br><br><h2>  <font color="#0071c5">Adaptando el modelo a la armonización</font> </h2><br>  Ahora BachBot puede calcular P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), la distribución de probabilidad para las siguientes notas posibles en función de la nota actual y el estado oculto anterior.  Este modelo de predicción secuencial puede adaptarse posteriormente para armonizar la melodía.  Tal modelo adaptado es necesario para armonizar la melodía, modulada con la ayuda de las emociones, como parte de un proyecto musical con una presentación de diapositivas. <br><br>  Cuando se trabaja con la armonización del modelo, se proporciona una melodía predefinida (por lo general, esta es una parte soprano), y luego el modelo debe componer música para el resto de las piezas.  Para llevar a cabo esta tarea, se utiliza una búsqueda codiciosa de "mejor primero" con la restricción de que las notas de la melodía son fijas.  Los algoritmos codiciosos implican decisiones que son óptimas desde un punto de vista local.  Entonces, a continuación se muestra una estrategia simple utilizada para la armonización: <br><blockquote>  Suponga que x <sub>t</sub> son tokens en la armonización propuesta.  En el paso de tiempo t, si la nota corresponde a la melodía, entonces x <sub>t</sub> es igual a la nota dada.  De lo contrario, x <sub>t</sub> es igual a la siguiente nota <i>más probable</i> de acuerdo con las predicciones del modelo.  El código para esta adaptación del modelo se puede encontrar en el sitio web de Feynman Lyang GitHub: <a href="">HarmModel.lua</a> , <a href="">harmonize.lua</a> . </blockquote><br>  El siguiente es un ejemplo de armonización de la canción de cuna Twinkle, Twinkle, Little Star con BachBot, utilizando la estrategia anterior. <br><br><img src="https://habrastorage.org/webt/wl/mu/kf/wlmukfjpuyeswxwfr15lmkgfvrw.jpeg"><br>  <i>Armonización de la canción de cuna de Twinkle, Twinkle, Little Star con BachBot (en la parte soprano).</i>  <i>Partes de viola, tenor y bajo también se rellenaron con BachBot</i> <br><br>  En este ejemplo, la melodía de la canción de cuna Twinkle, Twinkle, Little Star se da en la parte soprano.  Después de eso, las partes de viola, tenor y bajo se llenaron usando BachBot usando una estrategia de armonización.  Y así <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">es como suena</a> . <br><br>  A pesar de que BachBot ha demostrado un buen rendimiento en la realización de esta tarea, existen ciertas limitaciones asociadas con este modelo.  Más precisamente, el algoritmo <i>no mira hacia</i> la melodía y usa solo la nota actual de la melodía y el contexto pasado para generar notas posteriores.  Cuando las personas armonizan una melodía, pueden cubrir toda la melodía, lo que simplifica la derivación de armonizaciones adecuadas.  El hecho de que este modelo no sea capaz de hacer esto puede generar <i>sorpresas</i> debido a restricciones en el uso de información posterior que causan errores.  Para resolver este problema, se puede utilizar la llamada <i>búsqueda de haz</i> . <br><br>  Cuando se usa la búsqueda de haz, se verifican varias líneas de movimiento.  Por ejemplo, en lugar de usar solo una, la nota más probable, que se está haciendo actualmente, se pueden considerar cuatro o cinco notas más probables, después de lo cual el algoritmo continúa su trabajo con cada una de estas notas.  Examinar las diversas opciones puede ayudar al modelo a <i>recuperarse de los errores</i> .  La búsqueda de haces se usa comúnmente en aplicaciones de procesamiento de lenguaje natural para crear oraciones. <br><br>  Las melodías moduladas con la ayuda de las emociones ahora se pueden pasar a través de un modelo de armonización para completarlas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es423727/">https://habr.com/ru/post/es423727/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es423713/index.html">"Hecho en Rusia": lenguaje de programación WBASIC para desarrollar aplicaciones web del lado del servidor</a></li>
<li><a href="../es423719/index.html">De Erlang / Elixir a Java y viceversa. Aventura por 20 minutos</a></li>
<li><a href="../es423721/index.html">"Eres una madre desagradable": algoritmos hostiles de detección de lenguaje y soluciones alternativas</a></li>
<li><a href="../es423723/index.html">Proyecto (no) comercial: Redis cambia las licencias pero sigue siendo de código abierto</a></li>
<li><a href="../es423725/index.html">Procesos de diseño en ISPsystem. Cómo introducir una ideología, construir un departamento y mantenerse con vida.</a></li>
<li><a href="../es423729/index.html">5 millones de cuentas registradas en ProtonMail crypto-mail</a></li>
<li><a href="../es423731/index.html">Computación de personajes con Python. Parte 1. Los fundamentos</a></li>
<li><a href="../es423733/index.html">El impacto de GDPR en los operadores de datos personales rusos</a></li>
<li><a href="../es423735/index.html">La conferencia de Internet de las Cosas organizará la Batalla de Startups. Invitamos a los participantes.</a></li>
<li><a href="../es423737/index.html">Optimización estricta del trabajo con datos de mercado para intercambios de criptomonedas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
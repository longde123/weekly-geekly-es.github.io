<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üà∏ üì∞ üê® AI, curso pr√°ctico. Aprendizaje profundo para generar m√∫sica. ü§µüèΩ üàπ üèπ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este es el √∫ltimo art√≠culo de una serie de art√≠culos de capacitaci√≥n para desarrolladores en el campo de la inteligencia artificial. Discute los pasos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso pr√°ctico. Aprendizaje profundo para generar m√∫sica.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/423727/"><img src="https://habrastorage.org/webt/zy/do/u4/zydou4yx-zh_x9qzbumtrbdhwy4.jpeg"><br><br>  Este es el √∫ltimo art√≠culo de una serie de art√≠culos de capacitaci√≥n para desarrolladores en el campo de la inteligencia artificial.  Discute los pasos para crear un modelo de aprendizaje profundo para la generaci√≥n de m√∫sica, elegir el modelo correcto y el preprocesamiento de datos, y describe los procedimientos para configurar, entrenar, probar y modificar BachBot. <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Generaci√≥n de m√∫sica: pensar en una tarea</font> </h2><br>  El primer paso para resolver muchos problemas usando la inteligencia artificial (IA) es reducir el problema a un problema b√°sico que pueda resolverse por medio de la IA.  Uno de estos problemas es la predicci√≥n de secuencia, que se utiliza en aplicaciones de traducci√≥n y procesamiento de lenguaje natural.  Nuestra tarea de generar m√∫sica puede reducirse al problema de predecir una secuencia, y la predicci√≥n se realizar√° para una secuencia de notas musicales. <br><br><h2>  <font color="#0071c5">Selecci√≥n de modelo</font> </h2><br>  Existen varios tipos diferentes de redes neuronales que pueden considerarse modelos: redes neuronales de distribuci√≥n directa, redes neuronales recurrentes y redes neuronales de memoria a largo plazo. <br><br>  Las neuronas son los elementos abstractos b√°sicos que se combinan para formar redes neuronales.  Esencialmente, una neurona es una funci√≥n que recibe datos en la entrada y genera el resultado. <br><br><img src="https://habrastorage.org/webt/56/pq/hs/56pqhseblx5mqec0apoegck7vd4.png"><br>  <i>Neurona</i> <br><br>  Las capas de neuronas que reciben los mismos datos en la entrada y tienen salidas conectadas se pueden combinar para construir una <i>red neuronal con propagaci√≥n directa</i> .  Dichas redes neuronales demuestran altos resultados debido a la composici√≥n de funciones de activaci√≥n no lineal al pasar datos a trav√©s de varias capas (el llamado aprendizaje profundo). <br><br><img src="https://habrastorage.org/webt/e8/ps/1v/e8ps1vchys7uap5mjucmyip5ob8.png"><br>  <i>Red neuronal de distribuci√≥n directa.</i> <br><br>  Una red neuronal de distribuci√≥n directa muestra buenos resultados en una amplia gama de aplicaciones.  Sin embargo, dicha red neuronal tiene un inconveniente que no permite su uso en una tarea relacionada con la composici√≥n musical (predicci√≥n de secuencia): tiene una dimensi√≥n fija de datos de entrada y las composiciones musicales pueden tener diferentes longitudes.  Adem√°s, <i>las redes neuronales de distribuci√≥n directa no tienen en cuenta las entradas de los pasos de tiempo anteriores, ¬°lo que las hace poco √∫tiles para resolver el problema de predicci√≥n de secuencias!</i>  Un modelo llamado <i>red neuronal recurrente es</i> m√°s adecuado para esta tarea. <br><br>  Las redes neuronales recursivas resuelven ambos problemas mediante la introducci√≥n de enlaces entre nodos ocultos: en este caso, en el siguiente paso de tiempo, los nodos pueden recibir informaci√≥n sobre los datos en el paso de tiempo anterior. <br><br><img src="https://habrastorage.org/webt/xc/jv/dr/xcjvdrzlx66olpyziwbtfywxukq.png"><br>  <i>Representaci√≥n detallada de una red neuronal recurrente.</i> <br><br>  Como puede ver en la figura, cada neurona ahora recibe informaci√≥n de la capa neural anterior y la hora anterior. <br><br>  Las redes neuronales recursivas que se ocupan de grandes secuencias de entrada encuentran el llamado <i>problema del gradiente de fuga</i> : esto significa que la influencia de los pasos de tiempo anteriores desaparece r√°pidamente.  Este problema es caracter√≠stico de la tarea de composici√≥n musical, ya que hay importantes dependencias a largo plazo en las obras musicales que deben tenerse en cuenta. <br><br>  Para resolver el problema de un gradiente de fuga <i>, se puede utilizar</i> una modificaci√≥n de la red recurrente, que se denomina <i>red neuronal con memoria a largo plazo (o red neuronal LSTM)</i> .  Este problema se resuelve introduciendo celdas de memoria, que son monitoreadas cuidadosamente por tres tipos de "compuertas".  Haga clic en el siguiente enlace para obtener m√°s informaci√≥n: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Informaci√≥n general sobre redes neuronales LSTM</a> . <br><br>  Por lo tanto, BachBot utiliza un modelo basado en la red neuronal LSTM. <br><br><h2>  <font color="#0071c5">Pretratamiento</font> </h2><br>  La m√∫sica es una forma de arte muy compleja e incluye varias dimensiones: tono, ritmo, tempo, sombras din√°micas, articulaci√≥n y m√°s.  Para simplificar la m√∫sica para los prop√≥sitos de este proyecto <i>, solo se consideran el tono y la duraci√≥n de los sonidos</i> .  Adem√°s, todos los corales se <i>transpusieron</i> a la clave en do mayor o en menor, y las duraciones de las notas se <i>cuantificaron en el tiempo</i> (redondeadas) al m√∫ltiplo m√°s cercano de la semicorchea.  Estas acciones se tomaron para reducir la complejidad de las composiciones y aumentar el rendimiento de la red, mientras que el contenido b√°sico de la m√∫sica se mantuvo sin cambios.  Las operaciones para normalizar las tonalidades y la duraci√≥n de las notas se realizaron utilizando la biblioteca music21. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">standardize_key</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Converts into the key of C major or A minor. Adapted from https://gist.github.com/aldous-rey/68c6c43450517aa47474 """</span></span> <span class="hljs-comment"><span class="hljs-comment"># conversion tables: eg Ab -&gt; C is up 4 semitones, D -&gt; A is down 5 semitones majors = dict([("A-", 4),("A", 3),("B-", 2),("B", 1),("C", 0),("C#",-1), ("D-", -1),("D", -2),("E-", -3),("E", -4),("F", -5),("F#",6), ("G-", 6), ("G", 5)]) minors = dict([("A-", 1),("A", 0),("B-", -1),("B", -2),("C", -3),("C#",-4), ("D-", -4),("D", -5),("E-", 6),("E", 5),("F", 4),("F#",3), ("G-",3),("G", 2)]) # transpose score key = score.analyze('key') if key.mode == "major": halfSteps = majors[key.tonic.name] elif key.mode == "minor": halfSteps = minors[key.tonic.name] tScore = score.transpose(halfSteps) # transpose key signature for ks in tScore.flat.getKeySignatures(): ks.transpose(halfSteps, inPlace=True) return tScore</span></span></code> </pre> <br>  <i>El c√≥digo utilizado para estandarizar los caracteres clave en los trabajos recopilados, las claves en Do mayor o A menor se usan en la salida</i> <br><br>  La cuantificaci√≥n del tiempo al m√∫ltiplo m√°s cercano de la semicorchea se realiz√≥ utilizando la funci√≥n <i>Stream.quantize ()</i> de la biblioteca <i>music21</i> .  La siguiente es una comparaci√≥n de las estad√≠sticas asociadas con un conjunto de datos antes y despu√©s de su procesamiento preliminar: <br><br><img src="https://habrastorage.org/webt/kr/wh/5n/krwh5n0d1dubkwn0urbjmp7ovzs.png"><br>  <i>Usando cada clase de notas antes (izquierda) y despu√©s del preprocesamiento (derecha).</i>  <i>Una clase de nota es una nota independientemente de su octava.</i> <br><br><img src="https://habrastorage.org/webt/mz/rq/i0/mzrqi0fynco56dhr9kdk-nsfjrs.png"><br>  <i>Ubicaci√≥n de las notas antes (izquierda) y despu√©s del preprocesamiento (derecha)</i> <br><br>  Como puede ver en la figura anterior, la transposici√≥n de la clave original de los corales a la clave de Do mayor o Do menor (A menor) influy√≥ significativamente en la clase de notas utilizadas en los trabajos recopilados.  En particular, el n√∫mero de ocurrencias para notas en teclas en teclas principales (Do mayor) y A menor (A menor) (C, D, E, F, G, A, B) aument√≥.  Tambi√©n puede observar peque√±os picos para las notas F # y G # debido a su presencia en la secuencia ascendente de la mel√≥dica A menor (A, B, C, D, E, F # y G #).  <i>Por otro lado, la cuantizaci√≥n del tiempo tuvo un efecto mucho menor.</i>  Esto puede explicarse por la alta resoluci√≥n de cuantizaci√≥n (similar al redondeo a muchos d√≠gitos significativos). <br><br><h2>  <font color="#0071c5">Codificaci√≥n</font> </h2><br>  Una vez que los datos han sido preprocesados, es necesario codificar los corales en un formato que pueda procesarse f√°cilmente utilizando una red neuronal recurrente.  El formato requerido es una <i>secuencia de tokens</i> .  Para el proyecto BachBot, la codificaci√≥n se eligi√≥ a nivel de notas (cada token representa una nota) en lugar del nivel de acordes (cada token representa un acorde).  Esta soluci√≥n redujo el tama√±o del diccionario de 128 <sup>4</sup> acordes posibles a 128 notas posibles, lo que permiti√≥ aumentar la eficiencia del trabajo. <br><br>  Se cre√≥ un esquema de codificaci√≥n original para composiciones musicales para el proyecto BachBot.  El coral se divide en pasos de tiempo correspondientes a las semicorcheas.  Estos pasos se llaman marcos.  Cada cuadro contiene una secuencia de tuplas que representan el valor del tono de una nota en el formato de una interfaz de instrumento musical digital (MIDI) y un signo de uni√≥n de esta nota a una nota anterior de la misma altura (nota, signo de uni√≥n).  Las notas dentro del marco est√°n numeradas en orden descendente de altura (soprano ‚Üí alt ‚Üí tenor ‚Üí bajo).  Cada cuadro tambi√©n puede tener un cuadro que marca el final de una frase;  Fermata se representa con un s√≠mbolo de punto (.) Sobre la nota.  Los s√≠mbolos <i>START</i> y <i>END</i> se agregan al principio y al final de cada coral.  Estos s√≠mbolos provocan la inicializaci√≥n del modelo y permiten al usuario determinar cu√°ndo termina la composici√≥n. <br><br> <code>START <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (.) <br> (57, False) <br> (52, False) <br> (48, False) <br> (45, False) <br> ||| <br> (.) <br> (57, True) <br> (52, True) <br> (48, True) <br> (45, True) <br> ||| <br> END</code> <br>  <i>Un ejemplo de codificaci√≥n de dos acordes.</i>  <i>Cada acorde dura un octavo tiempo de una medida, el segundo acorde est√° acompa√±ado por una granja.</i>  <i>La secuencia "|||"</i>  <i>marca el final del marco</i> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">encode_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score, keep_fermatas=True, parts_to_mask=[])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Encodes a music21 score into a List of chords, where each chord is represented with a (Fermata :: Bool, List[(Note :: Integer, Tie :: Bool)]). If `keep_fermatas` is True, all `has_fermata`s will be False. All tokens from parts in `parts_to_mask` will have output tokens `BLANK_MASK_TXT`. Time is discretized such that each crotchet occupies `FRAMES_PER_CROTCHET` frames. """</span></span> encoded_score = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chord <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (score .quantize((FRAMES_PER_CROTCHET,)) .chordify(addPartIdAsGroup=bool(parts_to_mask)) .flat .notesAndRests): <span class="hljs-comment"><span class="hljs-comment"># aggregate parts, remove markup # expand chord/rest st constant timestep between frames if chord.isRest: encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET)) * [[]]) else: has_fermata = (keep_fermatas) and any(map(lambda e: e.isClassOrSubclass(('Fermata',)), chord.expressions)) encoded_chord = [] # </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> sorts Soprano, Bass, Alto, Tenor without breaking ties # c = chord.sortAscending() # sorted_notes = [c[-1], c[0]] + c[1:-1] # for note in sorted_notes: for note in chord: if parts_to_mask and note.pitch.groups[0] in parts_to_mask: encoded_chord.append(BLANK_MASK_TXT) else: has_tie = note.tie is not None and note.tie.type != 'start' encoded_chord.append((note.pitch.midi, has_tie)) encoded_score.append((has_fermata, encoded_chord)) # repeat pitches to expand chord into multiple frames # all repeated frames when expanding a chord should be tied encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET) - 1) * [ (has_fermata, map(lambda note: BLANK_MASK_TXT if note == BLANK_MASK_TXT else (note[0], True), encoded_chord)) ]) return encoded_score</span></span></code> </pre> <br>  <i>C√≥digo utilizado para codificar la tonalidad music21 usando un esquema de codificaci√≥n especial</i> <br><br><h2>  <font color="#0071c5">Tarea modelo</font> </h2><br>  En la parte anterior, se dio una explicaci√≥n que muestra que la tarea de composici√≥n autom√°tica puede reducirse a la tarea de predecir una secuencia.  En particular, un modelo puede predecir la pr√≥xima nota m√°s probable bas√°ndose en notas anteriores.  Una red neuronal con memoria a largo plazo (LSTM) es la m√°s adecuada para resolver este tipo de problema.  Formalmente, el modelo debe predecir P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), la distribuci√≥n de probabilidad para las siguientes notas posibles (x <sub>t + 1</sub> ) en funci√≥n del token actual (x <sub>t</sub> ) y el estado oculto anterior (h <sub>t-1</sub> ) .  Curiosamente, los modelos de lenguaje basados ‚Äã‚Äãen redes neuronales recurrentes realizan la misma operaci√≥n. <br><br>  En el modo de composici√≥n, el modelo se inicializa con el token <i>START</i> , luego de lo cual selecciona el siguiente token m√°s probable a seguir.  Despu√©s de eso, el modelo contin√∫a seleccionando el siguiente token m√°s probable utilizando la nota anterior y el estado oculto anterior hasta que se genere un token END.  El sistema contiene elementos de temperatura que agregan cierto grado de aleatoriedad para evitar que BachBot componga la misma pieza una y otra vez. <br><br><h3>  <font color="#0071c5">Funci√≥n de p√©rdida</font> </h3><br>  Al entrenar un modelo para la predicci√≥n, generalmente hay alguna funci√≥n que debe minimizarse (llamada funci√≥n de p√©rdida).  Esta funci√≥n describe la diferencia entre la predicci√≥n del modelo y la propiedad de la verdad fundamental.  BachBot minimiza la p√©rdida de entrop√≠a cruzada entre la distribuci√≥n prevista (x <sub>t + 1</sub> ) y la distribuci√≥n real de la funci√≥n objetivo.  Usar la entrop√≠a cruzada como una funci√≥n de p√©rdida es un buen punto de partida para una amplia gama de tareas, pero en algunos casos puede usar su propia funci√≥n de p√©rdida.  Otro enfoque aceptable es tratar de usar varias funciones de p√©rdida y aplicar un modelo que minimice la p√©rdida real durante la verificaci√≥n. <br><br><h3>  <font color="#0071c5">Entrenamiento / prueba</font> </h3><br>  Al entrenar una red neuronal recursiva, BachBot us√≥ la correcci√≥n de tokens con el valor x <sub>t + 1 en</sub> lugar de aplicar la predicci√≥n del modelo.  Este proceso, conocido como aprendizaje obligatorio, se utiliza para garantizar la convergencia, ya que las predicciones del modelo producir√°n naturalmente malos resultados al comienzo de la capacitaci√≥n.  Por el contrario, durante la validaci√≥n y la composici√≥n, la predicci√≥n del modelo x <sub>t + 1</sub> debe reutilizarse como entrada para la pr√≥xima predicci√≥n. <br><br><h3>  <font color="#0071c5">Otras consideraciones</font> </h3><br>  Para aumentar la eficiencia en este modelo, se usaron los siguientes m√©todos pr√°cticos que son comunes a las redes neuronales LSTM: truncamiento de gradiente normalizado, m√©todo de eliminaci√≥n, normalizaci√≥n de paquetes y m√©todo de propagaci√≥n por error de tiempo truncado (BPTT). <br><br>  <i>El m√©todo de truncamiento de gradiente normalizado</i> elimina el problema del crecimiento incontrolado del valor del gradiente (lo inverso del problema del gradiente de fuga, que se resolvi√≥ utilizando la arquitectura de las celdas de memoria LSTM).  Con esta t√©cnica, los valores de gradiente que exceden un cierto umbral se truncan o escalan. <br><br>  <i>El m√©todo de exclusi√≥n</i> es una t√©cnica en la que algunas neuronas <i>seleccionadas al azar se</i> desconectan (excluyen) durante el entrenamiento de la red.  Esto evita el sobreajuste y mejora la calidad de la generalizaci√≥n.  El problema del sobreajuste surge cuando el modelo se optimiza para el conjunto de datos de entrenamiento y, en menor medida, se aplica a muestras fuera de este conjunto.  El m√©todo de exclusi√≥n a menudo empeora la p√©rdida durante el entrenamiento, pero la mejora en la etapa de verificaci√≥n (m√°s sobre esto a continuaci√≥n). <br><br>  El c√°lculo del gradiente en una red neuronal recurrente para una secuencia de 1000 elementos es equivalente en costo a los pasos hacia adelante y hacia atr√°s en la red neuronal de distribuci√≥n directa de 1000 capas.  <i>El</i> m√©todo de <i>propagaci√≥n de error truncada</i> (BPTT) a lo largo del tiempo se usa para reducir el costo de actualizar los par√°metros durante el entrenamiento.  Esto significa que los errores se propagan solo durante un n√∫mero fijo de pasos contados desde el momento actual.  Tenga en cuenta que las dependencias de aprendizaje a largo plazo todav√≠a son posibles con el m√©todo BPTT, ya que los estados latentes ya se han revelado en muchos pasos anteriores. <br><br><h3>  <font color="#0071c5">Par√°metros</font> </h3><br>  La siguiente es una lista de par√°metros relevantes para modelos de redes neuronales recurrentes / redes neuronales con memoria a largo plazo a corto plazo: <br><ul><li>  <i>El n√∫mero de capas</i> .  Aumentar este par√°metro puede aumentar la eficiencia del modelo, pero llevar√° m√°s tiempo entrenarlo.  Adem√°s, demasiadas capas pueden conducir a un sobreajuste. </li><li>  <i>La dimensi√≥n del estado latente</i> .  El aumento de este par√°metro puede aumentar la complejidad del modelo, sin embargo, esto puede conducir a un sobreajuste. </li><li>  <i>Dimensi√≥n de las comparaciones de vectores</i> </li><li>  <i>La longitud de secuencia</i> / n√∫mero de tramas antes de truncar la propagaci√≥n hacia atr√°s del error a lo largo del tiempo. </li><li>  <i>Probabilidad de exclusi√≥n de neuronas</i> .  La probabilidad con la que una neurona ser√° excluida de la red durante cada ciclo de actualizaci√≥n. </li></ul><br>  La metodolog√≠a para seleccionar el conjunto √≥ptimo de par√°metros se discutir√° m√°s adelante en este art√≠culo. <br><br><h2>  <font color="#0071c5">Implementaci√≥n, entrenamiento y pruebas.</font> </h2><br><h3>  <font color="#0071c5">Selecci√≥n de plataforma</font> </h3><br>  Actualmente, hay muchas plataformas que le permiten implementar modelos de aprendizaje autom√°tico en varios lenguajes de programaci√≥n (¬°incluso JavaScript!).  Las plataformas populares incluyen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">scikit-learn</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Torch</a> . <br><br>  La biblioteca Torch fue seleccionada como la plataforma para el proyecto BachBot.  Al principio, se prob√≥ la biblioteca TensorFlow, pero en ese momento utiliz√≥ redes neuronales recurrentes extensas, lo que condujo a un desbordamiento de la RAM de la GPU.  Torch es una plataforma de computaci√≥n cient√≠fica impulsada por el r√°pido lenguaje de programaci√≥n LuaJIT *.  La plataforma Torch contiene excelentes bibliotecas para trabajar con redes neuronales y optimizaci√≥n. <br><br><h3>  <font color="#0071c5">Implementaci√≥n y capacitaci√≥n de modelos.</font> </h3><br>  La implementaci√≥n, obviamente, variar√° seg√∫n el idioma y la plataforma que elija.  Para saber c√≥mo BachBot implementa redes neuronales con memoria a corto y largo plazo utilizando Torch, consulte los scripts utilizados para entrenar y establecer los par√°metros de BachBot.  Estas secuencias de comandos est√°n disponibles en el sitio web de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Feynman Lyang GitHub.</a> <br><br>  Un buen punto de partida para navegar por el repositorio es el <a href="">script 1-train.zsh</a> .  Con √©l, puede encontrar la ruta al archivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bachbot.py</a> . <br><br>  M√°s precisamente, el script principal para configurar los par√°metros del modelo es el archivo <a href="">LSTM.lua</a> .  El script para entrenar el modelo es el archivo <a href="">train.lua</a> . <br><br><h3>  <font color="#0071c5">Optimizaci√≥n de hiperpar√°metros</font> </h3><br>  Para buscar los valores √≥ptimos de los hiperpar√°metros, se utiliz√≥ el m√©todo de b√∫squeda de cuadr√≠cula utilizando la siguiente cuadr√≠cula de par√°metros. <br><br><img src="https://habrastorage.org/webt/91/7p/_3/917p_3g7mtewimqlykgaskxn8y0.png"><br>  <i>Cuadr√≠cula de par√°metros utilizados por BachBot en la b√∫squeda de cuadr√≠cula</i> <br><br>  Una b√∫squeda de cuadr√≠cula es una b√∫squeda completa de todas las combinaciones posibles de par√°metros.  Otros m√©todos sugeridos para optimizar los hiperpar√°metros son la b√∫squeda aleatoria y la optimizaci√≥n bayesiana. <br><br>  El conjunto √≥ptimo de hiperpar√°metros detectados como resultado de una b√∫squeda de cuadr√≠cula es el siguiente: n√∫mero de capas = 3, dimensi√≥n del estado oculto = 256, dimensi√≥n de las comparaciones de vectores = 32, longitud de secuencia = 128, probabilidad de eliminaci√≥n de neuronas = 0.3. <br><br>  Este modelo alcanz√≥ una p√©rdida de entrop√≠a cruzada de 0.324 durante el entrenamiento y 0.477 en la etapa de verificaci√≥n.  El gr√°fico de la curva de aprendizaje demuestra que el proceso de aprendizaje converge despu√©s de 30 iteraciones (‚âà28.5 minutos cuando se usa una sola GPU). <br><br>  Los gr√°ficos de p√©rdida durante el entrenamiento y durante la fase de verificaci√≥n tambi√©n pueden ilustrar el efecto de cada hiperpar√°metro.  De particular inter√©s para nosotros es la probabilidad de eliminar neuronas: <br><br><img src="https://habrastorage.org/webt/ad/zd/_s/adzd_s3hxek23oyz8dqg_d1pkys.png"><br>  <i>Curvas de aprendizaje para varias configuraciones de m√©todos de exclusi√≥n</i> <br><br>  Se puede ver en la figura que el m√©todo de eliminaci√≥n realmente evita la aparici√≥n de sobreajuste.  Aunque con una probabilidad de exclusi√≥n de 0.0, la p√©rdida durante el entrenamiento es m√≠nima, en la etapa de verificaci√≥n, la p√©rdida tiene un valor m√°ximo.  Grandes valores de probabilidad conducen a un aumento de las p√©rdidas durante el entrenamiento y una disminuci√≥n de las p√©rdidas en la etapa de verificaci√≥n.  El valor m√≠nimo de la p√©rdida durante la fase de verificaci√≥n cuando se trabaja con BachBot se corrigi√≥ con una probabilidad de excepci√≥n de 0.3. <br><br><h3>  <font color="#0071c5">M√©todos de evaluaci√≥n alternativos (opcional)</font> </h3><br>  Para algunos modelos, especialmente para aplicaciones creativas como componer m√∫sica, la p√©rdida puede no ser una medida adecuada del √©xito del sistema.  En cambio, la percepci√≥n humana subjetiva puede ser el mejor criterio. <br><br>  El objetivo del proyecto BachBot es componer autom√°ticamente m√∫sica que no se pueda distinguir de las propias composiciones de Bach.  Para evaluar el √©xito de los resultados, se realiz√≥ una encuesta de usuarios en Internet.  La encuesta recibi√≥ la forma de un concurso en el que se pidi√≥ a los usuarios que determinaran qu√© obras pertenecen al proyecto BachBot y cu√°les a Bach. <br><br>  Los resultados de la encuesta mostraron que los participantes de la encuesta (759 personas con diferentes niveles de capacitaci√≥n) pudieron distinguir con precisi√≥n entre dos muestras en solo el 59 por ciento de los casos.  ¬°Esto es solo un 9 por ciento m√°s alto que el resultado de suposiciones aleatorias!  ¬°Pruebe la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">encuesta BachBot</a> usted mismo! <br><br><h2>  <font color="#0071c5">Adaptando el modelo a la armonizaci√≥n</font> </h2><br>  Ahora BachBot puede calcular P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), la distribuci√≥n de probabilidad para las siguientes notas posibles en funci√≥n de la nota actual y el estado oculto anterior.  Este modelo de predicci√≥n secuencial puede adaptarse posteriormente para armonizar la melod√≠a.  Tal modelo adaptado es necesario para armonizar la melod√≠a, modulada con la ayuda de las emociones, como parte de un proyecto musical con una presentaci√≥n de diapositivas. <br><br>  Cuando se trabaja con la armonizaci√≥n del modelo, se proporciona una melod√≠a predefinida (por lo general, esta es una parte soprano), y luego el modelo debe componer m√∫sica para el resto de las piezas.  Para llevar a cabo esta tarea, se utiliza una b√∫squeda codiciosa de "mejor primero" con la restricci√≥n de que las notas de la melod√≠a son fijas.  Los algoritmos codiciosos implican decisiones que son √≥ptimas desde un punto de vista local.  Entonces, a continuaci√≥n se muestra una estrategia simple utilizada para la armonizaci√≥n: <br><blockquote>  Suponga que x <sub>t</sub> son tokens en la armonizaci√≥n propuesta.  En el paso de tiempo t, si la nota corresponde a la melod√≠a, entonces x <sub>t</sub> es igual a la nota dada.  De lo contrario, x <sub>t</sub> es igual a la siguiente nota <i>m√°s probable</i> de acuerdo con las predicciones del modelo.  El c√≥digo para esta adaptaci√≥n del modelo se puede encontrar en el sitio web de Feynman Lyang GitHub: <a href="">HarmModel.lua</a> , <a href="">harmonize.lua</a> . </blockquote><br>  El siguiente es un ejemplo de armonizaci√≥n de la canci√≥n de cuna Twinkle, Twinkle, Little Star con BachBot, utilizando la estrategia anterior. <br><br><img src="https://habrastorage.org/webt/wl/mu/kf/wlmukfjpuyeswxwfr15lmkgfvrw.jpeg"><br>  <i>Armonizaci√≥n de la canci√≥n de cuna de Twinkle, Twinkle, Little Star con BachBot (en la parte soprano).</i>  <i>Partes de viola, tenor y bajo tambi√©n se rellenaron con BachBot</i> <br><br>  En este ejemplo, la melod√≠a de la canci√≥n de cuna Twinkle, Twinkle, Little Star se da en la parte soprano.  Despu√©s de eso, las partes de viola, tenor y bajo se llenaron usando BachBot usando una estrategia de armonizaci√≥n.  Y as√≠ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">es como suena</a> . <br><br>  A pesar de que BachBot ha demostrado un buen rendimiento en la realizaci√≥n de esta tarea, existen ciertas limitaciones asociadas con este modelo.  M√°s precisamente, el algoritmo <i>no mira hacia</i> la melod√≠a y usa solo la nota actual de la melod√≠a y el contexto pasado para generar notas posteriores.  Cuando las personas armonizan una melod√≠a, pueden cubrir toda la melod√≠a, lo que simplifica la derivaci√≥n de armonizaciones adecuadas.  El hecho de que este modelo no sea capaz de hacer esto puede generar <i>sorpresas</i> debido a restricciones en el uso de informaci√≥n posterior que causan errores.  Para resolver este problema, se puede utilizar la llamada <i>b√∫squeda de haz</i> . <br><br>  Cuando se usa la b√∫squeda de haz, se verifican varias l√≠neas de movimiento.  Por ejemplo, en lugar de usar solo una, la nota m√°s probable, que se est√° haciendo actualmente, se pueden considerar cuatro o cinco notas m√°s probables, despu√©s de lo cual el algoritmo contin√∫a su trabajo con cada una de estas notas.  Examinar las diversas opciones puede ayudar al modelo a <i>recuperarse de los errores</i> .  La b√∫squeda de haces se usa com√∫nmente en aplicaciones de procesamiento de lenguaje natural para crear oraciones. <br><br>  Las melod√≠as moduladas con la ayuda de las emociones ahora se pueden pasar a trav√©s de un modelo de armonizaci√≥n para completarlas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es423727/">https://habr.com/ru/post/es423727/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es423713/index.html">"Hecho en Rusia": lenguaje de programaci√≥n WBASIC para desarrollar aplicaciones web del lado del servidor</a></li>
<li><a href="../es423719/index.html">De Erlang / Elixir a Java y viceversa. Aventura por 20 minutos</a></li>
<li><a href="../es423721/index.html">"Eres una madre desagradable": algoritmos hostiles de detecci√≥n de lenguaje y soluciones alternativas</a></li>
<li><a href="../es423723/index.html">Proyecto (no) comercial: Redis cambia las licencias pero sigue siendo de c√≥digo abierto</a></li>
<li><a href="../es423725/index.html">Procesos de dise√±o en ISPsystem. C√≥mo introducir una ideolog√≠a, construir un departamento y mantenerse con vida.</a></li>
<li><a href="../es423729/index.html">5 millones de cuentas registradas en ProtonMail crypto-mail</a></li>
<li><a href="../es423731/index.html">Computaci√≥n de personajes con Python. Parte 1. Los fundamentos</a></li>
<li><a href="../es423733/index.html">El impacto de GDPR en los operadores de datos personales rusos</a></li>
<li><a href="../es423735/index.html">La conferencia de Internet de las Cosas organizar√° la Batalla de Startups. Invitamos a los participantes.</a></li>
<li><a href="../es423737/index.html">Optimizaci√≥n estricta del trabajo con datos de mercado para intercambios de criptomonedas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
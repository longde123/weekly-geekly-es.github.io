<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëÜüèΩ üßöüèΩ üë®üèº‚Äçüíª Prueba de carga de un juego con un par de cientos de miles de usuarios virtuales üí≤ üßõüèº üè•</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! 

 Trabajo para una empresa de juegos que desarrolla juegos en l√≠nea. Actualmente, todos nuestros juegos est√°n divididos en muchos "mercado...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Prueba de carga de un juego con un par de cientos de miles de usuarios virtuales</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445368/">  Hola Habr! <br><br>  Trabajo para una empresa de juegos que desarrolla juegos en l√≠nea.  Actualmente, todos nuestros juegos est√°n divididos en muchos "mercados" (un "mercado" por pa√≠s) y en cada "mercado" hay una docena de mundos entre los cuales los jugadores se distribuyen durante el registro (bueno, o a veces pueden elegirlo ellos mismos).  Cada mundo tiene una base de datos y uno o m√°s servidores web / de aplicaciones.  Por lo tanto, la carga se divide y distribuye en todos los mundos / servidores de manera casi uniforme y, como resultado, obtenemos el m√°ximo en l√≠nea de 6K-8K jugadores (este es el m√°ximo, en su mayor√≠a varias veces menos) y 200-300 solicitudes por tiempo "prime" para un mundo. <br><br>  Tal estructura con la divisi√≥n de jugadores en mercados y mundos se est√° volviendo obsoleta; los jugadores quieren algo global.  En los √∫ltimos juegos, dejamos de dividir a las personas por pa√≠s y dejamos solo uno o dos mercados (Am√©rica y Europa), pero a√∫n con muchos mundos en cada uno.  El siguiente paso ser√° el desarrollo de juegos con una nueva arquitectura y la unificaci√≥n de todos los jugadores en un solo mundo con <b>una sola base de datos</b> . <br><br>  Hoy quer√≠a hablar un poco sobre c√≥mo se me asign√≥ la tarea de verificar qu√© pasa si todo el en l√≠nea (y son 50-200 mil usuarios a la vez) de uno de nuestros juegos populares "env√≠a" para jugar el pr√≥ximo juego basado en la nueva arquitectura y si todo el sistema, especialmente la base de datos ( <b>PostgreSQL 11</b> ) pr√°cticamente puede soportar tal carga y, si no puede, averiguar d√≥nde est√° nuestro m√°ximo.  Te contar√© un poco sobre los problemas que han surgido y las decisiones de preparaci√≥n para probar a tantos usuarios, el proceso en s√≠ y un poco sobre los resultados. <br><a name="habracut"></a><br><h2>  Introducci√≥n </h2><br>  En el pasado, en <b>InnoGames GmbH,</b> cada equipo de juego creaba un proyecto de juego a su gusto y color, a menudo utilizando diferentes tecnolog√≠as, lenguajes de programaci√≥n y bases de datos.  Adem√°s, tenemos muchos sistemas externos responsables de pagos, env√≠o de notificaciones push, marketing y m√°s.  Para trabajar con estos sistemas, los desarrolladores tambi√©n crearon sus interfaces √∫nicas lo mejor que pudieron. <br><br>  Actualmente en el negocio de los juegos m√≥viles hay mucho <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dinero</a> y, en consecuencia, mucha competencia.  Aqu√≠ es muy importante recuperarlo de cada d√≥lar gastado en marketing y un poco m√°s de lo anterior, por lo tanto, todas las compa√±√≠as de juegos a menudo ‚Äúcierran‚Äù juegos incluso en la etapa de pruebas cerradas, si no cumplen con las expectativas anal√≠ticas.  En consecuencia, perder tiempo en la invenci√≥n de la pr√≥xima rueda no es rentable, por lo que se decidi√≥ crear una plataforma unificada que proporcionar√° a los desarrolladores una soluci√≥n preparada para la integraci√≥n con todos los sistemas externos, una base de datos con replicaci√≥n y todas las mejores pr√°cticas.  Todo lo que los desarrolladores necesitan es desarrollar y "poner" un buen juego adem√°s de esto y no perder el tiempo en el desarrollo no relacionado con el juego en s√≠. <br><br>  Esta plataforma se llama <b>GameStarter</b> : <br><br><img src="https://habrastorage.org/webt/fz/go/g3/fzgog3jsz4rzjqi0zvbwzysz-po.jpeg" alt="imagen"><br><br>  Entonces, al punto.  Todos los futuros juegos de InnoGames se construir√°n en esta plataforma, que tiene dos bases de datos: master y game (PostgreSQL 11).  Master almacena informaci√≥n b√°sica sobre los jugadores (inicio de sesi√≥n, contrase√±a, etc.) y participa, principalmente, solo en el proceso de inicio de sesi√≥n / registro en el juego mismo.  Juego: la base de datos del juego en s√≠, donde, en consecuencia, se almacenan todos los datos y entidades del juego, que es el n√∫cleo del juego, donde ir√° toda la carga. <br>  Por lo tanto, surgi√≥ la pregunta de si toda esta estructura podr√≠a soportar un n√∫mero tan potencial de usuarios igual al m√°ximo en l√≠nea de uno de nuestros juegos m√°s populares. <br><br><h2>  Desaf√≠o </h2><br>  La tarea en s√≠ misma era esta: verificar si la base de datos (PostgreSQL 11), con la replicaci√≥n habilitada, puede soportar toda la carga que tenemos actualmente en el juego m√°s cargado, teniendo a su disposici√≥n todo el hipervisor PowerEdge M630 (HV). <br>  Aclarar√© que la tarea en este momento era <b>solo verificar</b> , utilizando las configuraciones de bases de datos existentes, que formamos teniendo en cuenta las mejores pr√°cticas y nuestra propia experiencia. <br><br>  Dir√© de inmediato la base de datos, y todo el sistema se mostr√≥ bien, con la excepci√≥n de un par de puntos.  Pero este proyecto de juego en particular estaba en la etapa de prototipo y en el futuro, con la complicaci√≥n de la mec√°nica del juego, las solicitudes a la base de datos se volver√°n m√°s complicadas y la carga en s√≠ misma puede aumentar significativamente y su naturaleza puede cambiar.  Para evitar esto, es necesario probar iterativamente el proyecto con cada hito m√°s o menos significativo.  La automatizaci√≥n de la capacidad de ejecutar este tipo de pruebas con un par de cientos de miles de usuarios se ha convertido en la tarea principal en esta etapa. <br><br><h2>  Perfil </h2><br>  Como cualquier prueba de carga, todo comienza con un perfil de carga. <br>  Nuestro valor potencial CCU60 (CCU es el n√∫mero m√°ximo de usuarios durante un cierto per√≠odo de tiempo, en este caso 60 minutos) se considera <b>250,000</b> usuarios.  El n√∫mero de usuarios virtuales competitivos (VU) es menor que el CCU60 y los analistas han sugerido que se puede dividir de forma segura en dos.  Redondee y acepte <b>150,000</b> VU competitivos. <br><br>  El n√∫mero total de solicitudes por segundo se tom√≥ de un juego bastante cargado: <br><br><img src="https://habrastorage.org/webt/lv/te/69/lvte69rifceelurn7r3t7trbgs4.png"><br><br>  Por lo tanto, nuestra carga objetivo es de ~ <b>20,000 solicitudes / s</b> a <b>150,000</b> VU. <br><br><h2>  Estructura </h2><br><h3>  Caracter√≠sticas del "stand" </h3><br>  En un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> anterior <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">,</a> ya habl√© sobre la automatizaci√≥n de todo el proceso de prueba de carga.  Adem√°s, puedo repetirme un poco, pero te contar√© algunos puntos con m√°s detalle. <br><br><img src="https://habrastorage.org/webt/zh/hz/eo/zhhzeorw5_gboyuocu9ajmb3ulo.png"><br><br>  En el diagrama, los cuadrados azules son nuestros hipervisores (HV), una nube que consta de muchos servidores (Dell M620 - M640).  En cada HV, se lanzan una docena de m√°quinas virtuales (VM) a trav√©s de KVM (web / app y db en la mezcla).  Cuando se crea una nueva VM, se produce el equilibrio y la b√∫squeda a trav√©s del conjunto de par√°metros de un HV adecuado y no se sabe inicialmente en qu√© servidor estar√°. <br><br><h4>  Base de datos (Game DB): </h4><br>  Pero para nuestro prop√≥sito db1, reservamos un HV <b>targer_hypervisor</b> separado basado en el M630. <br><br>  Breves caracter√≠sticas de targer_hypervisor: <br><br>  Dell M_630 <br>  Nombre del modelo: CPU Intel¬Æ Xeon¬Æ E5-2680 v3 @ 2.50GHz <br>  CPU (s): 48 <br>  Hilo (s) por n√∫cleo: 2 <br>  N√∫cleo (s) por z√≥calo: 12 <br>  Z√≥calo (s): 2 <br>  RAM: 128 GB <br>  Debian GNU / Linux 9 (estiramiento) <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.130-2 (2018-10-27) <br><br><div class="spoiler">  <b class="spoiler_title">Especificaciones detalladas</b> <div class="spoiler_text">  Debian GNU / Linux 9 (estiramiento) <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.130-2 (2018-10-27) <br>  lscpu <br>  Arquitectura: x86_64 <br>  Modo (s) de CPU: 32 bits, 64 bits <br>  Orden de bytes: Little Endian <br>  CPU (s): 48 <br>  Lista de CPU (s) en l√≠nea: 0-47 <br>  Hilo (s) por n√∫cleo: 2 <br>  N√∫cleo (s) por z√≥calo: 12 <br>  Z√≥calo (s): 2 <br>  NUMA nodo (s): 2 <br>  ID del vendedor: GenuineIntel <br>  Familia de CPU: 6 <br>  Modelo: 63 <br>  Nombre del modelo: CPU Intel¬Æ Xeon¬Æ E5-2680 v3 @ 2.50GHz <br>  Paso a paso: 2 <br>  CPU MHz: 1309.356 <br>  CPU m√°x. MHz: 3300.0000 <br>  CPU min MHz: 1200.0000 <br>  BogoMIPS: 4988.42 <br>  Virtualizaci√≥n: VT-x <br>  Cach√© L1d: 32K <br>  Cach√© L1i: 32K <br>  Cach√© L2: 256K <br>  Cach√© L3: 30720K <br>  NUMA nodo0 CPU (s): 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42 44,46 <br>  NUMA nodo1 CPU (s): 1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43 45,47 <br>  Banderas: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constante qtsopmopcoptsoptsoptsoptsoptsoptsoptsoptsoptsoptsoptsoptsoptsoptsopt SMX est TM2 SSSE3 sdbg FMA CX16 XTPR PDCM PCID DCA sse4_1 sse4_2 x2apic movbe POPCNT tsc_deadline_timer aes xSave AVX F16C rdrand lahf_lm ABM EPB invpcid_single ssbd CCRI ibpb stibp Kaiser tpr_shadow vnmi FlexPriority EPT VPID fsgsbase tsc_adjust IMC1 AVX2 SMEP bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts flush_l1d <br><br>  / usr / bin / qemu-system-x86_64 --version <br>  Emulador QEMU versi√≥n 2.8.1 (Debian 1: 2.8 + dfsg-6 + deb9u5) <br>  Copyright ¬© 2003-2016 Fabrice Bellard y los desarrolladores del Proyecto QEMU <br></div></div><br>  Breves caracter√≠sticas de db1: <br>  Arquitectura: x86_64 <br>  CPU (s): 48 <br>  RAM: 64 GB <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.144-3.1 (2019-02-19) x86_64 GNU / Linux <br>  Debian GNU / Linux 9 (estiramiento) <br>  psql (PostgreSQL) 11.2 (Debian 11.2-1.pgdg90 + 1) <br><br><div class="spoiler">  <b class="spoiler_title">Configuraci√≥n de PostgreSQL con algunas explicaciones</b> <div class="spoiler_text">  seq_page_cost = 1.0 <br>  random_page_cost = 1.1 # Tenemos SSD <br>  incluye '/etc/postgresql/11/main/extension.conf' <br>  log_line_prefix = '% t [% p-% l]% q% u @% h' <br>  log_checkpoints = on <br>  log_lock_waits = on <br>  log_statement = ddl <br>  log_min_duration_statement = 100 <br>  log_temp_files = 0 <br>  autovacuum_max_workers = 5 <br>  autovacuum_naptime = 10s <br>  autovacuum_vacuum_cost_delay = 20ms <br>  vacuum_cost_limit = 2000 <br>  maintenance_work_mem = 128MB <br>  synous_commit = off <br>  checkpoint_timeout = 30min <br>  listen_addresses = '*' <br>  work_mem = 32MB <br>  efectividad_cach√©_tama√±o = 26214MB # 50% de memoria disponible <br>  shared_buffers = 16384MB # 25% de memoria disponible <br>  max_wal_size = 15GB <br>  min_wal_size = 80MB <br>  wal_level = hot_standby <br>  max_wal_senders = 10 <br>  wal_compression = on <br>  archive_mode = on <br>  archive_command = '/ bin / true' <br>  archive_timeout = 1800 <br>  hot_standby = on <br>  wal_log_hints = on <br>  hot_standby_feedback = on <br></div></div><br>  <b>El valor</b> predeterminado de <b>hot_standby_feedback</b> es apagado, lo encendimos, pero m√°s tarde tuvo que apagarse para realizar una prueba exitosa.  M√°s adelante explicar√© por qu√©. <br><br>  Las principales tablas activas en la base de datos (construcci√≥n, producci√≥n, game_entity, building, core_inventory_player_resource, survivor) se rellenan previamente con datos (aproximadamente 80 GB) utilizando un script bash. <br><br><div class="spoiler">  <b class="spoiler_title">db-fill-script.sh</b> <div class="spoiler_text"><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash --clean TRUNCATE TABLE production CASCADE; TRUNCATE TABLE construction CASCADE; TRUNCATE TABLE building CASCADE; TRUNCATE TABLE grid CASCADE; TRUNCATE TABLE core_inventory_player_resource CASCADE; TRUNCATE TABLE survivor CASCADE; TRUNCATE TABLE city CASCADE; TRUNCATE TABLE game_entity CASCADE; TRUNCATE TABLE player CASCADE; TRUNCATE TABLE core_player CASCADE; TRUNCATE TABLE core_client_device CASCADE; --core_client_device INSERT INTO core_client_device (id, creation_date, modification_date, device_model, device_name, locale, platform, user_agent, os_type, os_version, network_type, device_type) SELECT (1000000000+generate_series(0,999999)) AS id, now(), now(), 'device model', 'device name', 'en_DK', 'ios', 'ios user agent', 'android', '8.1', 'wlan', 'browser'; --core_player INSERT INTO core_player (id, guest, name, nickname, premium_points, soft_deleted, session_id, tracking_device_data_id) SELECT (1000000000+generate_series(0,999999)) AS id, true, 'guest0000000000000000000', null, 100, false, '00000000-0000-0000-0000-000000000000', (1000000000+generate_series(0,999999)) ; --player INSERT INTO player (id, creation_date, modification_date, core_player_id) SELECT (1000000000+generate_series(0,999999)) , now(), now(), (1000000000+generate_series(0,999999)) ; --city INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1000000000+generate_series(0,999999)) , 'city', now(), now(); INSERT INTO city (id, game_design, player_id) SELECT (1000000000+generate_series(0,999999)) , 'city.default', (1000000000+generate_series(0,999999)) ; --survivor INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1001000000+generate_series(0,999999)) , 'survivor', now(), now(); INSERT INTO survivor (id, game_design, owning_entity_id, type) SELECT (1001000000+generate_series(0,999999)) , 'survivor.prod_1', (1000000000+generate_series(0,999999)) , 'survivor'; --core_inventory_player_resource INSERT INTO core_inventory_player_resource (id, creation_date, modification_date, amount, player_id, resource_key) SELECT (1000000000+generate_series(0,1999999)) , NOW(), NOW(), 1000, (1000000000+generate_series(0,1999999)/2) , CONCAT('resource_', (1000000000+generate_series(0,1999999)) % 2); --grid DROP INDEX grid_area_idx; INSERT INTO grid (id, creation_date, modification_date, area, city_id) SELECT (1000000000+generate_series(0,19999999)) , NOW(), NOW(), BOX '0,0,4,4', (1000000000+generate_series(0,19999999)/20) ; create index on grid using gist (area box_ops); --building INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1002000000+generate_series(0,99999999)) , 'building', now(), now(); INSERT INTO building (id, game_design, owning_entity_id, x, y, rotation, type) SELECT (1002000000+generate_series(0,99999999)) , 'building.building_prod_1', (1000000000+generate_series(0,99999999)/100) , 0, 0, 'DEGREES_0', 'building'; --construction INSERT INTO construction (id, creation_date, modification_date, definition, entity_id, start) SELECT (1000000000+generate_series(0,1999999)) , NOW(), NOW(), 'construction.building_prod_1-construction', (1002000000+generate_series(0,1999999)*50) , NOW(); --production INSERT INTO production (id, creation_date, modification_date, active, definition, entity_id, start_time) SELECT (1000000000+generate_series(0,49999999)) , NOW(), NOW(), true, 'production.building_prod_1_production_1', (1002000000+generate_series(0,49999999)*2) , NOW();</span></span></code> </pre> <br></div></div><br>  Replicaci√≥n: <br><br><pre> <code class="plaintext hljs">SELECT * FROM pg_stat_replication; pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | backend_xmin | state | sent_lsn | write_lsn | flush_lsn | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state -----+----------+---------+---------------------+--------------+---------------------+-------------+-------------------------------+--------------+-----------+------------+------------+------------+------------+-----------------+-----------------+-----------------+---------------+------------ 759 | 17035 | repmgr | xl1db2 | xxxx | xl1db2 | 51142 | 2019-01-27 08:56:44.581758+00 | | streaming | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 00:00:00.000393 | 00:00:00.001159 | 00:00:00.001313 | 0 | async 977 | 17035 | repmgr | xl1db3 |xxxxx | xl1db3 | 42888 | 2019-01-27 08:57:03.232969+00 | | streaming | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 00:00:00.000373 | 00:00:00.000798 | 00:00:00.000919 | 0 | async</code> </pre><br><h4>  Servidor de aplicaciones </h4><br>  Luego, en HV productivo (prod_hypervisors) de varias configuraciones y capacidades, se lanzaron 15 servidores de aplicaciones: 8 n√∫cleos, 4 GB.  Lo principal que se puede decir: openjdk 11.0.1 2018-10-16, primavera, interacci√≥n con la base de datos a trav√©s de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hikari</a> (hikari.maximum-pool-size: 50) <br><br><h4>  Entorno de prueba de esfuerzo </h4><br>  Todo el entorno de prueba de carga consta de un servidor principal <b>admin.loadtest</b> y varios servidores de <b>generadorN.loadtest</b> (en este caso hab√≠a 14). <br><br>  <b>generatorN.loadtest</b> - VM "desnuda" Debian Linux 9, con Java 8. 32 n√∫cleos / 32 gigabytes instalados.  Est√°n ubicados en el HV "no productivo", para no matar accidentalmente el rendimiento de m√°quinas virtuales importantes. <br><br>  <b>admin.loadtest</b> : <b>m√°quina virtual</b> Debian Linux 9, 16 n√∫cleos / 16 gigas, ejecuta Jenkins, JLTC y otro software adicional sin importancia. <br><br>  JLTC - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">centro de prueba de carga jmeter</a> .  Un sistema en Py / Django que controla y automatiza el lanzamiento de pruebas, as√≠ como el an√°lisis de resultados. <br><br><h3>  Esquema de lanzamiento de prueba </h3><br><img src="https://habrastorage.org/webt/pb/f_/th/pbf_thx7mwuois96bffvbeehtxk.png"><br><br>  El proceso de ejecutar la prueba se ve as√≠: <br><br><ul><li>  La prueba se inicia desde <b>Jenkins</b> .  Seleccione el trabajo requerido, luego debe ingresar los par√°metros de prueba deseados: <ul><li>  <b>DURACI√ìN</b> - duraci√≥n de la prueba </li><li>  <b>RAMPUP</b> - tiempo de "calentamiento" </li><li>  <b>THREAD_COUNT_TOTAL</b> : el n√∫mero deseado de usuarios virtuales (VU) o subprocesos </li><li>  <b>TARGET_RESPONSE_TIME</b> es un par√°metro importante, para no sobrecargar todo el sistema con la ayuda de √©l, establecemos el tiempo de respuesta deseado, en consecuencia, la prueba mantendr√° la carga en un nivel en el que el tiempo de respuesta de todo el sistema no sea mayor que el especificado. </li></ul></li><li>  Lanzamiento </li><li>  Jenkins clona el plan de prueba de Gitlab y lo env√≠a a JLTC. </li><li>  JLTC funciona un poco con un plan de prueba (por ejemplo, inserta un escritor simple CSV). </li><li>  JLTC calcula la cantidad requerida de servidores Jmeter para ejecutar la cantidad deseada de VU (THREAD_COUNT_TOTAL). </li><li>  JLTC se conecta a cada generador loadgeneratorN e inicia el servidor jmeter. </li></ul><br>  Durante la prueba, el <b>cliente JMeter</b> genera un archivo CSV con los resultados.  Entonces, durante la prueba, la cantidad de datos y el tama√±o de este archivo crece a un ritmo <b>loco</b> , y no se puede usar para el an√°lisis despu√©s de la prueba: <b>se</b> invent√≥ <b>Daemon</b> (como un experimento), que lo analiza <i>"sobre la marcha"</i> . <br><br><h3>  Plan de prueba </h3><br>  Puede descargar el plan de prueba <a href="">aqu√≠</a> . <br><br>  Despu√©s del registro / inicio de sesi√≥n, los usuarios trabajan en el m√≥dulo <b>Comportamiento</b> , que consta de varios <b>controladores de rendimiento</b> que especifican la probabilidad de una funci√≥n de juego en particular.  En cada controlador de rendimiento, hay un <b>controlador de m√≥dulo</b> , que se refiere al m√≥dulo correspondiente que implementa la funci√≥n. <br><br><img src="https://habrastorage.org/webt/t0/ws/qp/t0wsqpbkgo-w6dt55gvxd6aw9pm.png"><br><br><h4>  Fuera de tema </h4><br>  Durante el desarrollo del script, intentamos usar Groovy al m√°ximo, y gracias a nuestro programador Java, descubr√≠ un par de trucos para m√≠ (tal vez sea √∫til para alguien): <br><br><ul><li>  Puede declarar una funci√≥n en alg√∫n lugar al comienzo del plan de prueba y luego usarla en otros procesadores y muestreadores previos, posteriores.  M√°s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bondad maravillosa: Convierta los m√©todos en cierres</a> : <br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//     - def sum(Integer x, Integer y) { return x + y } vars.putObject('sum', this.&amp;sum) //      closure.   . //     sampler`       def sum= vars.getObject('sum'); println sum(2, 2);</span></span></code> </pre> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">groovy.json.JsonSlurper</a> es un excelente analizador JSON r√°pido.  Junto con Groovy, le permite analizar datos de manera elegante y procesarlos: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> groovy.json.JsonSlurper def canBuild = vars.getObject(canBuild); <span class="hljs-comment"><span class="hljs-comment">// ""       def content = jsonSlurper.parseText(response).content def buildings = content[0].buildings //         //               def constructableBuildingDefs = buildings .collect { k,v -&gt; v } .grep{ it.definitions .grep { it2 -&gt; it2['@type'] == 'type.googleapis.com/ConstructionDefinitionDTO'} .grep { it2 -&gt; canBuild(it2) } //   .size() &gt; 0 } if (!constructableBuildingDefs) { return; } Collections.shuffle(constructableBuildingDefs) //       </span></span></code> </pre></li></ul><br><h3>  VU / Subprocesos </h3><br>  Cuando un usuario ingresa el n√∫mero deseado de VU utilizando el par√°metro THREAD_COUNT_TOTAL al configurar el trabajo en Jenkins, es necesario iniciar de alguna manera el n√∫mero requerido de servidores Jmeter y distribuir el n√∫mero final de VU entre ellos.  Esta parte se encuentra con el JLTC en la parte llamada <b>controlador / provisi√≥n</b> . <br><br>  En esencia, el algoritmo es el siguiente: <br><br><ul><li>  Dividimos el n√∫mero deseado de VU <b>threads_num</b> en 200-300 subprocesos y, en funci√≥n del tama√±o m√°s o menos adecuado <b>-Xmsm -Xmxm,</b> determinamos el valor de memoria requerido para un <i>jmeter-server</i> <b>required_memory_for_jri</b> (JRI - Llamo a la instancia remota de Jmeter, en lugar de Jmeter-server). </li><li>  De threads_num y required_memory_for_jri encontramos el n√∫mero total de jmeter-server: <b>target_amount_jri</b> y el valor total de la memoria <b>requerida</b> : <b>required_memory_total</b> . </li><li>  Seleccionamos todos los generadores loadgeneratorN uno por uno y comenzamos el n√∫mero m√°ximo de servidores jmeter en funci√≥n de la memoria disponible en √©l.  Siempre que el n√∫mero de instancias de current_amount_jri en ejecuci√≥n <b>no sea igual a</b> target_amount_jri. </li><li>  (Si el n√∫mero de generadores y la memoria total no es suficiente, agregue uno nuevo al grupo) </li><li>  Nos conectamos a cada generador, usamos <b>netstat para</b> recordar todos los puertos ocupados y ejecutamos en puertos aleatorios (que est√°n desocupados) la cantidad requerida de servidores jmeter: <br><br><pre> <code class="python hljs"> netstat_cmd= <span class="hljs-string"><span class="hljs-string">'netstat -tulpn | grep LISTEN'</span></span> stdin, stdout, stderr = ssh.exec_command(cmd1) used_ports = [] netstat_output = str(stdout.readlines()) ports = re.findall(<span class="hljs-string"><span class="hljs-string">'\d+\.\d+\.\d+\.\d+\:(\d+)'</span></span>, netstat_output) ports_ipv6 = re.findall(<span class="hljs-string"><span class="hljs-string">'\:\:\:(\d+)'</span></span>, netstat_output) p.wait() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> ports: used_ports.append(int(port)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> ports_ipv6: used_ports.append(int(port)) ssh.close() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, possible_jris_on_host + <span class="hljs-number"><span class="hljs-number">1</span></span>): port = int(random.randint(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">20000</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> used_ports: port = int(random.randint(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">20000</span></span>)) <span class="hljs-comment"><span class="hljs-comment"># ...  Jmeter-    </span></span></code> </pre></li><li>  Recopilamos todos los servidores jmeter en ejecuci√≥n de una vez en el formato de direcci√≥n: puerto, por ejemplo, <b>generador13: 15576, generador9: 14015, generador11: 19152, generador14: 12125, generador2: 17602</b> </li><li>  La lista resultante y threads_per_host se env√≠an al cliente JMeter cuando comienza la prueba: <br><br><pre> <code class="bash hljs">REMOTE_TESTING_FLAG=<span class="hljs-string"><span class="hljs-string">" -R </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$REMOTE_HOSTS_STRING</span></span></span><span class="hljs-string">"</span></span> java -jar -Xms7g -Xmx7g -Xss228k <span class="hljs-variable"><span class="hljs-variable">$JMETER_DIR</span></span>/bin/ApacheJMeter.jar -Jserver.rmi.ssl.disable=<span class="hljs-literal"><span class="hljs-literal">true</span></span> -n -t <span class="hljs-variable"><span class="hljs-variable">$TEST_PLAN</span></span> -j <span class="hljs-variable"><span class="hljs-variable">$WORKSPACE</span></span>/loadtest.log -GTHREAD_COUNT=<span class="hljs-variable"><span class="hljs-variable">$THREADS_PER_HOST</span></span> <span class="hljs-variable"><span class="hljs-variable">$OTHER_VARS</span></span> <span class="hljs-variable"><span class="hljs-variable">$REMOTE_TESTING_FLAG</span></span> -Jjmeter.save.saveservice.default_delimiter=,</code> </pre></li></ul><br>  En nuestro caso, la prueba se realiz√≥ simult√°neamente desde 300 servidores Jmeter, 500 subprocesos cada uno, el formato de inicio de un servidor Jmeter con par√°metros Java se ve√≠a as√≠: <br><br><pre> <code class="bash hljs">nohup java -server -Xms1200m -Xmx1200m -Xss228k -XX:+DisableExplicitGC -XX:+CMSClassUnloadingEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -Djava.net.preferIPv6Addresses=<span class="hljs-literal"><span class="hljs-literal">true</span></span> -Djava.net.preferIPv4Stack=<span class="hljs-literal"><span class="hljs-literal">false</span></span> -jar <span class="hljs-string"><span class="hljs-string">"/tmp/jmeter-JwKse5nY/bin/ApacheJMeter.jar"</span></span> -Jserver.rmi.ssl.disable=<span class="hljs-literal"><span class="hljs-literal">true</span></span> <span class="hljs-string"><span class="hljs-string">"-Djava.rmi.server.hostname=generator12.loadtest.ig.local"</span></span> -Duser.dir=/tmp/jmeter-JwKse5nY/bin/ -Dserver_port=13114 -s -Jpoll=49 &gt; /dev/null 2&gt;&amp;1</code> </pre> <br><h3>  50ms </h3><br>  La tarea es determinar cu√°nto puede resistir nuestra base de datos, y no sobrecargarla ni a todo el sistema en su conjunto a un estado cr√≠tico.  Con tantos servidores Jmeter, necesita de alguna manera mantener la carga a un cierto nivel y no matar todo el sistema.  El par√°metro <b>TARGET_RESPONSE_TIME</b> especificado al iniciar la prueba es responsable de esto.  Acordamos que <b>50 ms</b> es el tiempo de respuesta √≥ptimo por el cual el sistema deber√≠a ser responsable. <br><br>  En JMeter, por defecto, hay muchos temporizadores diferentes que le permiten controlar el rendimiento, pero no se sabe d√≥nde obtenerlo en nuestro caso.  Pero hay <b>un temporizador JSR223</b> con el que puede encontrar algo usando el <b>tiempo de respuesta actual del</b> sistema.  El temporizador en s√≠ est√° en el bloque de <b>comportamiento</b> principal: <br><br><img src="https://habrastorage.org/webt/uv/o8/rb/uvo8rb9ph7mr1xhxkzxccsfa06a.png"><br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      = 0 vars.put('samples', '20'); vars.putObject('respAvg', ${TARGET_RESPONSE_TIME}.0); vars.putObject('sleep', 0.0); //  JSR223-Timer           "" double sleep = vars.getObject('sleep'); double respAvg = vars.getObject('respAvg'); double previous = sleep; double target = ${TARGET_RESPONSE_TIME}; if (respAvg &lt; target) { sleep /= 1.5; } if (respAvg &gt; target) { sleep *= 1.1; } sleep = Math.max(10, sleep); //      sleep = Math.min(20000, sleep); vars.putObject('sleep', sleep); return (int)sleep;</span></span></code> </pre><br><h3>  An√°lisis de los resultados (daemon) </h3><br>  Adem√°s de los gr√°ficos en Grafana, tambi√©n debe tener resultados de prueba agregados para que las pruebas puedan compararse posteriormente en JLTC. <br><br>  Una de esas pruebas genera 16k-20k solicitudes por segundo, es f√°cil calcular que en 4 horas genera un archivo CSV de un par de cientos de GB de tama√±o, por lo que fue necesario crear un trabajo que analice los datos cada minuto, los env√≠e a la base de datos y limpie el archivo principal. <br><br><img src="https://habrastorage.org/webt/pb/mj/kc/pbmjkcwgjcxupnihgzpzmqd0nvq.png"><br><br>  El algoritmo es el siguiente: <br><br><ul><li>  Leemos los datos del archivo CSV <b>result.jtl</b> generado por el jmeter-client, lo guardamos y limpiamos el archivo (debe limpiarlo correctamente, de lo contrario el archivo de aspecto vac√≠o tendr√° el mismo FD con el mismo tama√±o): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(jmeter_results_file, <span class="hljs-string"><span class="hljs-string">'r+'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: rows = f.readlines() f.seek(<span class="hljs-number"><span class="hljs-number">0</span></span>) f.truncate(<span class="hljs-number"><span class="hljs-number">0</span></span>) f.writelines(rows[<span class="hljs-number"><span class="hljs-number">-1</span></span>])</code> </pre></li><li>  Escribimos los datos le√≠dos en el archivo temporal <b>temp_result.jtl</b> : <br><br><pre> <code class="python hljs">rows_num = len(rows) open(temp_result_filename, <span class="hljs-string"><span class="hljs-string">'w'</span></span>).writelines(rows[<span class="hljs-number"><span class="hljs-number">0</span></span>:rows_num]) <span class="hljs-comment"><span class="hljs-comment"># avoid last line</span></span></code> </pre> </li><li>  Leemos el archivo <b>temp_result.jtl</b> .  Distribuimos los datos le√≠dos "en minutos": <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.readlines(): row = r.split(<span class="hljs-string"><span class="hljs-string">','</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(row[<span class="hljs-number"><span class="hljs-number">0</span></span>]) == <span class="hljs-number"><span class="hljs-number">13</span></span>: ts_c = int(row[<span class="hljs-number"><span class="hljs-number">0</span></span>]) dt_c = datetime.datetime.fromtimestamp(ts_c/<span class="hljs-number"><span class="hljs-number">1000</span></span>) minutes_data.setdefault(dt_c.strftime(<span class="hljs-string"><span class="hljs-string">'%Y_%m_%d_%H_%M'</span></span>), []).append(r)</code> </pre></li><li>  Los datos para cada minuto de <b>minutes_data se</b> escriben en el archivo correspondiente en la carpeta <b>to_parse /</b> .  (por lo tanto, en este momento, cada minuto de la prueba tiene su propio archivo de datos, luego, durante la agregaci√≥n <b>,</b> no importar√° en qu√© orden ingresaron los datos en cada archivo): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> key, value <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> minutes_data.iteritems(): <span class="hljs-comment"><span class="hljs-comment">#      timestamp (key) temp_ts_file = os.path.join(temp_to_parse_path, key) open(temp_ts_file, 'a+').writelines(value)</span></span></code> </pre></li><li>  En el camino, analizamos los archivos en la carpeta to_parse y si alguno de ellos no cambi√≥ en un minuto, entonces este archivo es candidato para el an√°lisis, agregaci√≥n y env√≠o de datos a la base de datos JLTC: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.listdir(temp_to_parse_path): data_file = os.path.join(temp_to_parse_path, filename) file_mod_time = os.stat(data_file).st_mtime last_time = (time.time() - file_mod_time) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> last_time &gt; <span class="hljs-number"><span class="hljs-number">60</span></span>: logger.info(<span class="hljs-string"><span class="hljs-string">'[DAEMON] File {} was not modified since 1min, adding to parse list.'</span></span>.format(data_file)) files_to_parse.append(data_file)</code> </pre></li><li>  Si existen dichos archivos (uno o varios), los enviamos analizados a la funci√≥n <b>parse_csv_data</b> (cada archivo en paralelo): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> files_to_parse: logger.info(<span class="hljs-string"><span class="hljs-string">'[DAEMON THREAD] Parse {}.'</span></span>.format(f)) t = threading.Thread( target=parse_csv_data, args=( f, jmeter_results_file_fields, test, data_resolution)) t.start() threads.append(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> threads: t.join()</code> </pre></li></ul><br>  Daemon en cron.d comienza cada minuto: <br><br>  El demonio comienza cada minuto con cron.d: <br><br><pre> <code class="bash hljs">* * * * * root sleep 21 &amp;&amp; /usr/bin/python /var/lib/jltc/manage.py daemon</code> </pre> <br>  Por lo tanto, el archivo con los resultados no aumenta a tama√±os inconcebibles, sino que se analiza <i>sobre la marcha</i> y se borra. <br><br><h2>  Resultados </h2><br><h3>  La aplicaci√≥n </h3><br>  Nuestros 150,000 jugadores virtuales: <br><br><img src="https://habrastorage.org/webt/sv/ex/ep/svexepi9ikzy0unpxur96mty5q8.png"><br><br>  La prueba intenta "igualar" el tiempo de respuesta de 50 ms, por lo que la carga en s√≠ misma salta constantemente en la regi√≥n entre 16k-18k solicitudes / c: <br><br><img src="https://habrastorage.org/webt/-z/98/oi/-z98oi-_8a41hkqbrmz2rvzmryk.png"><br><br>  Carga del servidor de aplicaciones (15 aplicaciones).  Dos servidores son "desafortunados" para estar en el M620 m√°s lento: <br><br><img src="https://habrastorage.org/webt/nc/xy/et/ncxyetqyk_a8mbhjocndd-yxgkm.png"><br><br>  Tiempo de respuesta de la base de datos (para servidores de aplicaciones): <br><br><img src="https://habrastorage.org/webt/zr/a-/gw/zra-gwtq_vqhtfhlrjzzy1osisg.png"><br><br><h3>  Base de datos </h3><br>  Util de CPU en db1 (VM): <br><br><img src="https://habrastorage.org/webt/ej/hn/in/ejhnin0jo_7rrzhlj7pqko6udnq.png"><br><br>  Util de la CPU en el hipervisor: <br><br><img src="https://habrastorage.org/webt/uw/ik/tz/uwiktzvcdzydlsjaoexqfbr3tay.png"><br><br>  La carga en la m√°quina virtual es menor, ya que cree que tiene 48 n√∫cleos reales a su disposici√≥n, de hecho, hay 24 n√∫cleos <b>hyperthreading</b> en el hipervisor. <br><br>  Un <b>m√°ximo de ~ 250K consultas / s</b> va a la base de datos, que consiste en (83% selecciona, 3% - inserta, 11.6% - actualiza (90% HOT), 1.6% elimina): <br><br><img src="https://habrastorage.org/webt/lx/lu/bl/lxlublobhm4nm3c45g9jikcstc4.png"><br><br><img src="https://habrastorage.org/webt/18/jw/gp/18jwgpmebrkyot3ngvarsl_3ysu.png"><br><br>  Con un valor predeterminado de <b>autovacuum_vacuum_scale_factor</b> = 0.2, el n√∫mero de tuplas muertas creci√≥ muy r√°pidamente con la prueba (con tama√±os de tabla crecientes), lo que condujo varias veces a problemas cortos de rendimiento de la base de datos que arruinaron la prueba completa varias veces.  Tuve que "domesticar" este crecimiento para algunas tablas asignando valores personales a este par√°metro autovacuum_vacuum_scale_factor: <br><br><div class="spoiler">  <b class="spoiler_title">ALTER TABLE ... SET (autovacuum_vacuum_scale_factor = ...)</b> <div class="spoiler_text">  ALTER TABLE construcci√≥n SET (autovacuum_vacuum_scale_factor = 0.10); <br>  ALTER TABLE production SET (autovacuum_vacuum_scale_factor = 0.01); <br>  ALTER TABLE game_entity SET (autovacuum_vacuum_scale_factor = 0.01); <br>  ALTER TABLE game_entity SET (autovacuum_analyze_scale_factor = 0.01); <br>  ALTER TABLE building SET (autovacuum_vacuum_scale_factor = 0.01); <br>  ALTER TABLE building SET (autovacuum_analyze_scale_factor = 0.01); <br>  ALTER TABLE core_inventory_player_resource SET (autovacuum_vacuum_scale_factor = 0.10); <br>  ALTER TABLE survivor SET (autovacuum_vacuum_scale_factor = 0.01); <br>  ALTER TABLE survivor SET (autovacuum_analyze_scale_factor = 0.01); <br></div></div><br><img src="https://habrastorage.org/webt/0s/ja/1e/0sja1e1m3-2gitbmhh8j24t2ktu.png"><br><br>  Idealmente, rows_fetched deber√≠a estar cerca de rows_returned, que, afortunadamente, observamos: <br><br><img src="https://habrastorage.org/webt/e4/k6/zo/e4k6zobp25h5asrmxhmficoea3a.png"><br><br><h4>  hot_standby_feedback </h4><br>  El problema estaba en el par√°metro <b>hot_standby_feedback</b> , que puede afectar en gran medida el rendimiento del servidor <b>principal</b> si sus servidores en <b>espera</b> no tienen tiempo para aplicar cambios desde los archivos WAL.  La documentaci√≥n (https://postgrespro.ru/docs/postgrespro/11/runtime-config-replication) establece que "determina si el servidor de espera activa notificar√° al maestro o esclavo superior sobre las solicitudes que est√° ejecutando actualmente".  Por defecto est√° apagado, pero se activ√≥ en nuestra configuraci√≥n.  Lo que condujo a consecuencias tristes, si hay 2 servidores en espera y el retraso de la replicaci√≥n durante la carga es diferente de cero (por varias razones), puede observar esa imagen, lo que puede provocar el bloqueo de toda la prueba: <br><br><img src="https://habrastorage.org/webt/vl/1l/jd/vl1ljdockxrjlfsoiybq751vo9y.png"><br><br><img src="https://habrastorage.org/webt/qh/4s/m_/qh4sm_hpnunb2w0axzhk90lmf6u.png"><br><br>  Esto se debe al hecho de que cuando hot_standby_feedback est√° habilitado, VACUUM no desea eliminar las tuplas "muertas" si los servidores en espera est√°n rezagados en su ID de transacci√≥n para evitar conflictos de replicaci√≥n.  Art√≠culo detallado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lo que realmente hace hot_standby_feedback en PostgreSQL</a> : <br><br><pre> <code class="plaintext hljs">xl1_game=# VACUUM VERBOSE core_inventory_player_resource; INFO: vacuuming "public.core_inventory_player_resource" INFO: scanned index "core_inventory_player_resource_pkey" to remove 62869 row versions DETAIL: CPU: user: 1.37 s, system: 0.58 s, elapsed: 4.20 s ‚Ä¶‚Ä¶‚Ä¶... INFO: "core_inventory_player_resource": found 13682 removable, 7257082 nonremovable row versions in 71842 out of 650753 pages &lt;b&gt;DETAIL: 3427824 dead row versions cannot be removed yet, oldest xmin: 3810193429&lt;/b&gt; There were 1920498 unused item pointers. Skipped 8 pages due to buffer pins, 520953 frozen pages. 0 pages are entirely empty. CPU: user: 4.55 s, system: 1.46 s, elapsed: 11.74 s.</code> </pre><br>  Una cantidad tan grande de tuplas muertas conduce a la imagen que se muestra arriba.  Aqu√≠ hay dos pruebas, con hot_standby_feedback activado y desactivado: <br><br><img src="https://habrastorage.org/webt/8f/od/n6/8fodn60lohgzsu-twheqysldjzy.png"><br><br>  Y este es nuestro retraso de replicaci√≥n durante la prueba, con el que ser√° necesario hacer algo en el futuro: <br><br><img src="https://habrastorage.org/webt/et/s0/7h/ets07hkl8skkv5wexxjrgi-3x7m.png"><br><br><h2>  Conclusi√≥n </h2><br>  Esta prueba, afortunadamente (o desafortunadamente para el contenido del art√≠culo) demostr√≥ que en esta etapa del prototipo del juego es bastante posible absorber la carga deseada por parte de los usuarios, lo que es suficiente para dar luz verde para la creaci√≥n de m√°s prototipos y desarrollo.  En las etapas posteriores de desarrollo, es necesario seguir las reglas b√°sicas (para mantener la simplicidad de las consultas ejecutadas, evitar una sobreabundancia de √≠ndices, as√≠ como lecturas no indexadas, etc.) y lo m√°s importante, probar el proyecto en cada etapa significativa de desarrollo para encontrar y solucionar problemas. puede ser antes  Quiz√°s pronto, escribir√© un art√≠culo ya que ya hemos resuelto problemas espec√≠ficos. <br><br>  ¬°Buena suerte a todos! <br><br>  Nuestro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GitHub por</a> si acaso;) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/445368/">https://habr.com/ru/post/445368/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../445356/index.html">Descripci√≥n general de la secci√≥n M√≥vil en DUMP-2019: m√°xima aplicada y √∫til en el trabajo diario</a></li>
<li><a href="../445358/index.html">Organizaci√≥n del sistema de eventos en Unity - a trav√©s de los ojos de un dise√±ador de juegos.</a></li>
<li><a href="../445360/index.html">5 tareas t√≠picas para las entrevistas de JavaScript: an√°lisis y soluciones</a></li>
<li><a href="../445362/index.html">El libro "Sistemas distribuidos. Patrones de dise√±o</a></li>
<li><a href="../445366/index.html">C√≥mo acelerar el cifrado seg√∫n GOST 28147-89 en el procesador Baikal-T1 debido al bloque SIMD</a></li>
<li><a href="../445370/index.html">An√°lisis de TSDB en Prometheus 2</a></li>
<li><a href="../445372/index.html">Visi√≥n artificial versus intuici√≥n humana: algoritmos para interrumpir el funcionamiento de los programas de reconocimiento de objetos.</a></li>
<li><a href="../445378/index.html">Laberintos: clasificaci√≥n, generaci√≥n, b√∫squeda de soluciones.</a></li>
<li><a href="../445380/index.html">PHP moderno es hermoso y productivo</a></li>
<li><a href="../445384/index.html">Misi√≥n Chang'e-4: equipo cient√≠fico en el m√≥dulo de aterrizaje y el sat√©lite repetidor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
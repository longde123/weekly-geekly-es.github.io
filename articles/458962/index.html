<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚿 😕 👧🏾 Convierta la imagen en sonido, ¿qué puede escuchar? 👨🏿‍🤝‍👨🏽 👨🏽‍🤝‍👨🏻 🤵🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola habr 

 Una publicación reciente aquí en el sitio describe un dispositivo que permite a las personas ciegas "ver" una imagen, transformándola usa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Convierta la imagen en sonido, ¿qué puede escuchar?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458962/">  Hola habr <br><br>  Una publicación reciente aquí en el sitio describe un dispositivo que permite a las personas ciegas "ver" una imagen, transformándola usando ondas de sonido.  Desde un punto de vista técnico, en ese artículo no había detalles en absoluto (y <s>si la idea de un millón fuera robada</s> ), pero el concepto en sí mismo parecía interesante.  Teniendo algo de experiencia con el procesamiento de señales, decidí experimentar por mi cuenta. <br><br><img src="https://habrastorage.org/webt/ki/st/ip/kistiptqvnn-pmxshurxrawkqze.png"><br><br>  Lo que surgió, detalles y ejemplos de archivos debajo del gato. <br><a name="habracut"></a><br><h2>  Convierte 2D a 1D </h2><br>  La primera tarea obvia que nos espera es convertir una imagen "plana" bidimensional en una onda de sonido "unidimensional".  Como se sugiere en los comentarios sobre ese artículo, es conveniente usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la curva de Hilbert</a> para esto. <br><img src="https://habrastorage.org/webt/kk/n9/2o/kkn92oz48liofrdsozg5jamskcq.gif"><br>  Básicamente se parece a un fractal, y la idea es que con un aumento en la resolución de la imagen, la posición relativa de los objetos no cambia (si el objeto estaba en la esquina superior izquierda de la imagen, entonces <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">permanecerá allí</a> ).  Las diferentes dimensiones de las curvas de Hilbert nos pueden dar diferentes imágenes: 32x32 para N = 5, 64x64 para N = 6, y así sucesivamente.  Al "caminar" por la imagen a lo largo de esta curva, obtenemos una línea, un objeto unidimensional. <br><br>  La siguiente pregunta es el tamaño de la imagen.  Intuitivamente quiero tomar una imagen más grande, pero hay un gran "pero": incluso la imagen es de 512x512, es de 262144 píxeles.  Si convertimos cada punto en un pulso de audio, entonces a una frecuencia de muestreo de 44100, obtenemos una secuencia de hasta 6 segundos, y esto es demasiado largo: las imágenes deben actualizarse rápidamente, por ejemplo, usando una cámara web.  No tiene sentido aumentar la frecuencia de muestreo; obtenemos frecuencias ultrasónicas inaudibles para el oído (aunque podría funcionar para un búho o un murciélago).  Como resultado, se seleccionó una resolución de 128x128 <s>por el método de</s> búsqueda <s>científica</s> , que dará impulsos de 0.37c de longitud; por un lado, es lo suficientemente rápido como para navegar en tiempo real, por otro lado, es suficiente para detectar cualquier cambio en la forma de la señal por el oído. <br><br><h2>  Procesamiento de imagen </h2><br>  El primer paso es descargar la imagen, convertirla a b / n y escalarla al tamaño deseado.  El tamaño de la imagen depende de la dimensión de la curva de Hilbert. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> hilbertcurve.hilbertcurve <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> HilbertCurve <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.signal <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> butter, filtfilt <span class="hljs-comment"><span class="hljs-comment"># Create Hilbert curve dimension = 7 hilbert = HilbertCurve(dimension, n=2) print("Hilbert curve dimension:", dimension) # Maximum distance along curve print("Max_dist:", hilbert.max_h) # Maximum distance along curve print("Max_coord:", hilbert.max_x) # Maximum coordinate value in any dimension # Load PIL image f_name = "image01.png" img = Image.open(f_name) width, height = img.size out_size = hilbert_curve.max_x + 1 if width != out_size: img = img.resize((out_size, out_size), Image.ANTIALIAS) # Get image as grayscale numpy array img_grayscale = img.convert(mode='L') img_data = np.array(img_grayscale)</span></span></code> </pre> <br>  El siguiente paso es formar una onda de sonido.  Aquí, por supuesto, puede haber una gran cantidad de algoritmos y conocimientos, para la prueba que acabo de tomar el componente de brillo.  Por supuesto, probablemente hay mejores formas. <br><br><pre> <code class="python hljs">width, height = img_grayscale.size sound_data = np.zeros(width*height) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ii <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(width*height): coord_x, coord_y = hilbert_curve.coordinates_from_distance(ii) pixel_l = img_data[coord_x][coord_y] <span class="hljs-comment"><span class="hljs-comment"># Inverse colors (paper-like, white = 0, black = 255) pixel_l = 255 - pixel_l # Adjust values 0..255 to 0..8192 ampl = pixel_l*32 sound_data[ii] = ampl</span></span></code> </pre> <br>  Desde el código, espero que todo esté claro.  La función coordenadas_de_distancia hace todo el trabajo por nosotros al convertir las coordenadas (x, y) en una distancia en una curva de Hilbert, invertimos y convertimos el valor de brillo L en color. <br><br>  Eso no es todo.  Porque  puede haber bloques grandes del mismo color en la imagen, esto puede dar lugar a la aparición de un "componente de CC" en el sonido: una larga serie de valores distintos de cero, por ejemplo [100,100,100, ...].  Para eliminarlos, aplicamos un filtro de paso alto (filtro de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Butterworth</a> ) a nuestra matriz con una frecuencia de corte de 50 Hz (la coincidencia con la frecuencia de la red es aleatoria).  Hay una síntesis de filtros en la biblioteca scipy, que usaremos. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">butter_highpass</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cutoff, fs, order=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> nyq = <span class="hljs-number"><span class="hljs-number">0.5</span></span> * fs normal_cutoff = cutoff / nyq b, a = butter(order, normal_cutoff, btype=<span class="hljs-string"><span class="hljs-string">'high'</span></span>, analog=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> b, a <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">butter_highpass_filter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, cutoff, fs, order=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> b, a = butter_highpass(cutoff, fs, order) y = filtfilt(b, a, data) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y <span class="hljs-comment"><span class="hljs-comment"># Apply high pass filter to remove dc component cutoff_hz = 50 sample_rate = 44100 order = 5 wav_data = butter_highpass_filter(sound_data, cutoff_hz, sample_rate, order)</span></span></code> </pre> <br>  El último paso es guardar la imagen.  Porque  la longitud de un pulso es corta, lo repetimos 10 veces, será más audible más cerca de una imagen real que se repite, por ejemplo, desde una cámara web. <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Clip data to int16 range sound_output = np.clip(wav_data, -32000, 32000).astype(np.int16) # Save repeat = 10 sound_output_ntimes = np.tile(sound_output, repeat) wav_name = "ouput.wav" scipy.io.wavfile.write(wav_name, sample_rate, sound_output_ntimes)</span></span></code> </pre> <br><h2>  Resultados </h2><br>  El algoritmo anterior es, por supuesto, bastante primitivo.  Quería verificar tres puntos: cuánto puede distinguir entre diferentes formas simples y cuánto puede estimar la distancia a las formas. <br><br>  <b>Prueba 1</b> <br><br><img src="https://habrastorage.org/webt/ft/te/9m/ftte9mjfgwj6nib_lj76pfrqmre.png"><br><br>  La imagen corresponde a la siguiente señal de sonido: <br><img src="https://habrastorage.org/webt/bd/gw/qu/bdgwquzss88fzb1s8hzyydf-das.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cloud.mail.ru/public/nt2R/2kwBvyRup</a> <br><br>  <b>Prueba 2</b> <br><br><img src="https://habrastorage.org/webt/vr/jt/6u/vrjt6ufndqzfdsywsgrpbnwlqiw.png"><br><br>  La idea de esta prueba es comparar el "sonido" de un objeto de una forma diferente.  Señal de sonido: <br><img src="https://habrastorage.org/webt/6z/bq/9a/6zbq9axxuoknevsj_iuxc94unre.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cloud.mail.ru/public/2rLu/4fCNRxCG2</a> <br><br>  Puede notar que el sonido es realmente diferente, y hay una diferencia de oído. <br><br>  <b>Prueba 3</b> <br><br><img src="https://habrastorage.org/webt/cv/cp/3h/cvcp3h7itiq8srj-rs_j6ntb6lk.png"><br><br>  La idea de la prueba es probar un objeto más pequeño.  Señal de sonido: <br><img src="https://habrastorage.org/webt/yk/ra/x3/ykrax3udam03yphwwtlouygkgdk.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cloud.mail.ru/public/5GLV/2HoCHvoaY</a> <br><br>  En principio, cuanto menor sea el tamaño del objeto, menos habrá "ráfagas" en el sonido, por lo que la dependencia aquí es bastante directa. <br><br>  <b>Editar:</b> <br><br>  Como se sugiere en los comentarios, puede usar la transformación de Fourier para convertir directamente imágenes en sonido.  Una prueba rápida realizada muestra los siguientes resultados (las imágenes son las mismas): <br>  Prueba 1: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cloud.mail.ru/public/2C5Z/5MEQ8Swjo</a> <br>  Prueba 2: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cloud.mail.ru/public/2dxp/3sz8mjAib</a> <br>  Prueba 3: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cloud.mail.ru/public/3NjJ/ZYrfdTYrk</a> <br><br>  Las pruebas suenan interesantes, al menos para cuadrados pequeños y grandes (archivos 1 y 3), la diferencia en la audición es notable.  Pero la forma de las figuras (1 y 2) prácticamente no difiere, por lo que también hay algo en qué pensar.  Pero en general, el sonido obtenido usando FFT, por oído, me gusta más. <br><br><h2>  Conclusión </h2><br>  Esta prueba, por supuesto, no es una disertación, sino simplemente una prueba de concepto, realizada en unas pocas horas de tiempo libre.  Pero aun así, básicamente funciona, y es muy posible sentir la diferencia de oído.  No sé si es posible aprender a navegar en el espacio con esos sonidos, hipotéticamente, probablemente después de algún entrenamiento.  Aunque hay un campo enorme para mejoras y experimentos, por ejemplo, puede usar sonido estéreo, lo que le permitirá separar mejor los objetos de diferentes lados, puede experimentar con otros métodos para convertir imágenes en sonido, por ejemplo, codificar color a diferentes frecuencias, etc. Finalmente, es prometedor El uso de cámaras 3D capaces de percibir la profundidad (por desgracia, dicha cámara no está disponible).  Por cierto, con la ayuda de un simple código OpenCV, el algoritmo anterior se puede adaptar para usar una cámara web, lo que le permitirá experimentar con imágenes dinámicas. <br><br>  Bueno, como siempre, todos los experimentos exitosos. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458962/">https://habr.com/ru/post/458962/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458950/index.html">Analizando Async / Await en JavaScript con ejemplos</a></li>
<li><a href="../458952/index.html">Ajuste de la configuración de PostgreSQL para optimizar el rendimiento</a></li>
<li><a href="../458954/index.html">Qué tipos de detección son útiles en videovigilancia. Mecanismos y funciones.</a></li>
<li><a href="../458956/index.html">Aprendizaje automático vs. enfoque analítico</a></li>
<li><a href="../458960/index.html">Búsqueda corporativa</a></li>
<li><a href="../458964/index.html">TestMace. Inicio rápido</a></li>
<li><a href="../458966/index.html">Los científicos y jefes de corporaciones tecnológicas consideran que el lanzamiento de empresas industriales al espacio es una realidad</a></li>
<li><a href="../458970/index.html">Uso de UIViewPropertyAnimator para crear animaciones personalizadas</a></li>
<li><a href="../458972/index.html">Noticias de la semana: Yandex y agencias de inteligencia occidentales, FAS lucha en casinos en línea, el Ministerio de Transporte regula BlaBlaCar</a></li>
<li><a href="../458974/index.html">Vida plena en Svelte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöï üë®üèª‚Äç‚öïÔ∏è üßìüèª Concours de risque de d√©faut de cr√©dit √† la maison Kaggle - Analyse des donn√©es et mod√®les pr√©dictifs simples üõÄ üëäüèæ ü§∂üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lors du Data Festival 2 √† Minsk, Vladimir Iglovikov, ing√©nieur en vision industrielle √† Lyft, a parfaitement remarqu√© que la meilleure fa√ßon d'apprend...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Concours de risque de d√©faut de cr√©dit √† la maison Kaggle - Analyse des donn√©es et mod√®les pr√©dictifs simples</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414613/">  Lors du Data Festival 2 √† Minsk, Vladimir Iglovikov, ing√©nieur en vision industrielle √† Lyft, a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">parfaitement</a> remarqu√© que la meilleure fa√ßon d'apprendre la Data Science est de participer √† des concours, d'ex√©cuter des solutions d'autres personnes, de les combiner, d'obtenir des r√©sultats et de montrer votre travail.  En fait, dans le cadre de ce paradigme, j'ai d√©cid√© d'examiner de plus pr√®s le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">concours d'</a> √©valuation du risque de cr√©dit pour le cr√©dit immobilier et d'expliquer (aux d√©butants, aux scientifiques et tout d'abord √† moi-m√™me) comment analyser correctement ces ensembles de donn√©es et construire des mod√®les pour eux. <br><br><img src="https://habrastorage.org/webt/iv/ji/-t/ivji-tusvam8d05dqef8wjbmbye.png"><br><a name="habracut"></a><br>  (photo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d'ici</a> ) <br><br><img src="https://habrastorage.org/webt/xc/er/pe/xcerpefrjvrblmubhxyeljevcie.png" width="250" align="right">  Home Credit Group est un groupe de banques et d'organisations de cr√©dit non bancaires qui m√®ne des op√©rations dans 11 pays (dont la Russie sous le nom de Home Credit and Finance Bank LLC).  Le but du concours est de cr√©er une m√©thodologie pour √©valuer la solvabilit√© des emprunteurs qui n'ont pas d'ant√©c√©dents de cr√©dit.  Ce qui semble plut√¥t noble - les emprunteurs de cette cat√©gorie ne peuvent souvent pas obtenir de cr√©dit de la banque et sont oblig√©s de se tourner vers des escrocs et des microcr√©dits.  Il est int√©ressant que le client ne fixe pas d'exigences de transparence et d'interpr√©tabilit√© du mod√®le (comme c'est g√©n√©ralement le cas avec les banques), vous pouvez utiliser n'importe quoi, m√™me un r√©seau de neurones. <br><br>  L'√©chantillon de formation se compose de 300+ milliers d'enregistrements, il y a beaucoup de signes - 122, parmi eux, il y en a de nombreux cat√©goriques (non num√©riques).  Les panneaux d√©crivent l'emprunteur avec suffisamment de d√©tails, jusque dans le mat√©riau dont sont faits les murs de sa maison.  Une partie des donn√©es est contenue dans 6 tableaux suppl√©mentaires (donn√©es sur le bureau de cr√©dit, solde de carte de cr√©dit et pr√™ts ant√©rieurs), ces donn√©es doivent √©galement √™tre trait√©es d'une mani√®re ou d'une autre et charg√©es dans les principales. <br><br>  Le concours ressemble √† une t√¢che de classification standard (1 dans le champ CIBLE signifie toute difficult√© de paiement, 0 signifie aucune difficult√©).  Cependant, ce n'est pas 0/1 qui devrait √™tre pr√©dit, mais la probabilit√© de probl√®mes (qui, incidemment, peut √™tre facilement r√©solue par les m√©thodes de pr√©diction de probabilit√© Predict_Proba que tous les mod√®les complexes ont). <br><br>  √Ä premi√®re vue, l'ensemble de donn√©es est assez standard pour les t√¢ches d'apprentissage automatique, les organisateurs ont offert un gros lot de 70 000 $, en cons√©quence, plus de 2600 √©quipes participent √† la comp√©tition aujourd'hui, et la bataille est en milli√®mes de pour cent.  Cependant, d'autre part, une telle popularit√© signifie que l'ensemble de donn√©es a √©t√© √©tudi√© de haut en bas et de nombreux noyaux ont √©t√© cr√©√©s avec une bonne EDA (Exploratory Data Analisys - recherche et analyse des donn√©es dans le r√©seau, y compris graphiques), Ing√©nierie des fonctionnalit√©s (travail avec des attributs) et avec des mod√®les int√©ressants.  (Le noyau est un exemple de travail avec un ensemble de donn√©es que n'importe qui peut disposer pour montrer son travail √† d'autres kugglers.) <br><br>  Les grains m√©ritent l'attention: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">EDA avec une description d√©taill√©e pour les d√©butants et les mod√®les simples</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deep EDA avec Plotly Package + Bureau Data Upload</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nice EDA avec Seaborn Package</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Analyse comparative des emprunteurs probl√©matiques et d√©faillants</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LightGBM 15 lignes sur trois panneaux avec une vitesse finale de 0,714</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Analyse des signes selon les bureaux de cr√©dit</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Traitement ajouter.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tables + LightGBM</a> </li></ul><br>  Pour travailler avec des donn√©es, le plan suivant est g√©n√©ralement recommand√©, que nous essaierons de suivre. <br><br><ol><li>  Comprendre le probl√®me et se familiariser avec les donn√©es </li><li>  Nettoyage et formatage des donn√©es </li><li>  EDA </li><li>  Mod√®le de base </li><li>  Am√©lioration du mod√®le </li><li>  Interpr√©tation du mod√®le </li></ol><br>  Dans ce cas, vous devez tenir compte du fait que les donn√©es sont assez √©tendues et ne peuvent pas √™tre ma√Ætris√©es imm√©diatement, il est logique d'agir par √©tapes. <br><br>  Commen√ßons par importer les biblioth√®ques dont nous avons besoin en analyse pour travailler avec des donn√©es sous forme de tableaux, construire des graphiques et travailler avec des matrices. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib inline</code> </pre> <br>  T√©l√©chargez les donn√©es.  Voyons voir ce que nous avons tous.  Cet emplacement dans le r√©pertoire "../input/", soit dit en passant, est li√© √† l'exigence de placer vos noyaux sur Kaggle. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os PATH=<span class="hljs-string"><span class="hljs-string">"../input/"</span></span> print(os.listdir(PATH))</code> </pre> <br> <code>['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv']</code> <br> <br>  Il y a 8 tables avec des donn√©es (sans compter la table HomeCredit_columns_description.csv, qui contient une description des champs), qui sont interconnect√©es comme suit: <br><br><img src="https://habrastorage.org/webt/vn/yr/84/vnyr84vhzozgnfinu2to2tyhlp8.png"><br><br>  application_train / application_test: donn√©es de base, l'emprunteur est identifi√© par le champ SK_ID_CURR <br>  bureau: donn√©es sur les pr√™ts ant√©rieurs d'autres √©tablissements de cr√©dit d'un bureau de cr√©dit <br>  bureau_balance: donn√©es mensuelles sur les pr√™ts ant√©rieurs du bureau.  Chaque ligne correspond au mois d'utilisation du pr√™t <br>  previous_application: Demandes pr√©c√©dentes de pr√™ts en cr√©dit immobilier, chacune a un champ unique SK_ID_PREV <br>  POS_CASH_BALANCE: donn√©es mensuelles sur les cr√©dits en cr√©dit immobilier avec √©mission de liquidit√©s et cr√©dits pour l'achat de biens <br>  credit_card_balance: donn√©es mensuelles du solde de la carte de cr√©dit dans le cr√©dit √† domicile <br>  installments_payment: historique des paiements des pr√™ts pr√©c√©dents au cr√©dit √† domicile. <br><br>  Concentrons-nous d'abord sur la principale source de donn√©es et voyons quelles informations peuvent en √™tre extraites et quels mod√®les construire.  T√©l√©chargez les donn√©es de base. <br><br><ul><li>  app_train = pd.read_csv (CHEMIN + 'application_train.csv',) </li><li>  app_test = pd.read_csv (CHEMIN + 'application_test.csv',) </li><li>  print ("format de l'ensemble de formation:", app_train.shape) </li><li>  print ("test sample format:", app_test.shape) </li><li>  format d'exemple de formation: (307511, 122) </li><li>  format de l'√©chantillon de test: (48744, 121) </li></ul><br>  Au total, nous avons 307 000 enregistrements et 122 signes dans l'√©chantillon de formation et 49 000 enregistrements et 121 signes dans le test.  L'√©cart est √©videmment d√ª au fait qu'il n'y a pas d'attribut cible TARGET dans l'√©chantillon de test, et nous le pr√©dirons. <br><br>  Examinons de plus pr√®s les donn√©es <br><br><pre> <code class="python hljs">pd.set_option(<span class="hljs-string"><span class="hljs-string">'display.max_columns'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  pandas     app_train.head()</span></span></code> </pre> <br><br><img src="https://habrastorage.org/webt/xo/yc/rg/xoycrgiodfhonfrjbt50ncthrls.png"><br>  (8 premi√®res colonnes affich√©es) <br><br>  Il est assez difficile de regarder des donn√©es dans ce format.  Regardons la liste des colonnes: <br><br> <code>app_train.info(max_cols=122) <br> &lt;class 'pandas.core.frame.DataFrame'&gt; <br> RangeIndex: 307511 entries, 0 to 307510 <br> Data columns (total 122 columns): <br> SK_ID_CURR 307511 non-null int64 <br> TARGET 307511 non-null int64 <br> NAME_CONTRACT_TYPE 307511 non-null object <br> CODE_GENDER 307511 non-null object <br> FLAG_OWN_CAR 307511 non-null object <br> FLAG_OWN_REALTY 307511 non-null object <br> CNT_CHILDREN 307511 non-null int64 <br> AMT_INCOME_TOTAL 307511 non-null float64 <br> AMT_CREDIT 307511 non-null float64 <br> AMT_ANNUITY 307499 non-null float64 <br> AMT_GOODS_PRICE 307233 non-null float64 <br> NAME_TYPE_SUITE 306219 non-null object <br> NAME_INCOME_TYPE 307511 non-null object <br> NAME_EDUCATION_TYPE 307511 non-null object <br> NAME_FAMILY_STATUS 307511 non-null object <br> NAME_HOUSING_TYPE 307511 non-null object <br> REGION_POPULATION_RELATIVE 307511 non-null float64 <br> DAYS_BIRTH 307511 non-null int64 <br> DAYS_EMPLOYED 307511 non-null int64 <br> DAYS_REGISTRATION 307511 non-null float64 <br> DAYS_ID_PUBLISH 307511 non-null int64 <br> OWN_CAR_AGE 104582 non-null float64 <br> FLAG_MOBIL 307511 non-null int64 <br> FLAG_EMP_PHONE 307511 non-null int64 <br> FLAG_WORK_PHONE 307511 non-null int64 <br> FLAG_CONT_MOBILE 307511 non-null int64 <br> FLAG_PHONE 307511 non-null int64 <br> FLAG_EMAIL 307511 non-null int64 <br> OCCUPATION_TYPE 211120 non-null object <br> CNT_FAM_MEMBERS 307509 non-null float64 <br> REGION_RATING_CLIENT 307511 non-null int64 <br> REGION_RATING_CLIENT_W_CITY 307511 non-null int64 <br> WEEKDAY_APPR_PROCESS_START 307511 non-null object <br> HOUR_APPR_PROCESS_START 307511 non-null int64 <br> REG_REGION_NOT_LIVE_REGION 307511 non-null int64 <br> REG_REGION_NOT_WORK_REGION 307511 non-null int64 <br> LIVE_REGION_NOT_WORK_REGION 307511 non-null int64 <br> REG_CITY_NOT_LIVE_CITY 307511 non-null int64 <br> REG_CITY_NOT_WORK_CITY 307511 non-null int64 <br> LIVE_CITY_NOT_WORK_CITY 307511 non-null int64 <br> ORGANIZATION_TYPE 307511 non-null object <br> EXT_SOURCE_1 134133 non-null float64 <br> EXT_SOURCE_2 306851 non-null float64 <br> EXT_SOURCE_3 246546 non-null float64 <br> APARTMENTS_AVG 151450 non-null float64 <br> BASEMENTAREA_AVG 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_AVG 157504 non-null float64 <br> YEARS_BUILD_AVG 103023 non-null float64 <br> COMMONAREA_AVG 92646 non-null float64 <br> ELEVATORS_AVG 143620 non-null float64 <br> ENTRANCES_AVG 152683 non-null float64 <br> FLOORSMAX_AVG 154491 non-null float64 <br> FLOORSMIN_AVG 98869 non-null float64 <br> LANDAREA_AVG 124921 non-null float64 <br> LIVINGAPARTMENTS_AVG 97312 non-null float64 <br> LIVINGAREA_AVG 153161 non-null float64 <br> NONLIVINGAPARTMENTS_AVG 93997 non-null float64 <br> NONLIVINGAREA_AVG 137829 non-null float64 <br> APARTMENTS_MODE 151450 non-null float64 <br> BASEMENTAREA_MODE 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MODE 157504 non-null float64 <br> YEARS_BUILD_MODE 103023 non-null float64 <br> COMMONAREA_MODE 92646 non-null float64 <br> ELEVATORS_MODE 143620 non-null float64 <br> ENTRANCES_MODE 152683 non-null float64 <br> FLOORSMAX_MODE 154491 non-null float64 <br> FLOORSMIN_MODE 98869 non-null float64 <br> LANDAREA_MODE 124921 non-null float64 <br> LIVINGAPARTMENTS_MODE 97312 non-null float64 <br> LIVINGAREA_MODE 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MODE 93997 non-null float64 <br> NONLIVINGAREA_MODE 137829 non-null float64 <br> APARTMENTS_MEDI 151450 non-null float64 <br> BASEMENTAREA_MEDI 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MEDI 157504 non-null float64 <br> YEARS_BUILD_MEDI 103023 non-null float64 <br> COMMONAREA_MEDI 92646 non-null float64 <br> ELEVATORS_MEDI 143620 non-null float64 <br> ENTRANCES_MEDI 152683 non-null float64 <br> FLOORSMAX_MEDI 154491 non-null float64 <br> FLOORSMIN_MEDI 98869 non-null float64 <br> LANDAREA_MEDI 124921 non-null float64 <br> LIVINGAPARTMENTS_MEDI 97312 non-null float64 <br> LIVINGAREA_MEDI 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MEDI 93997 non-null float64 <br> NONLIVINGAREA_MEDI 137829 non-null float64 <br> FONDKAPREMONT_MODE 97216 non-null object <br> HOUSETYPE_MODE 153214 non-null object <br> TOTALAREA_MODE 159080 non-null float64 <br> WALLSMATERIAL_MODE 151170 non-null object <br> EMERGENCYSTATE_MODE 161756 non-null object <br> OBS_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> OBS_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DAYS_LAST_PHONE_CHANGE 307510 non-null float64 <br> FLAG_DOCUMENT_2 307511 non-null int64 <br> FLAG_DOCUMENT_3 307511 non-null int64 <br> FLAG_DOCUMENT_4 307511 non-null int64 <br> FLAG_DOCUMENT_5 307511 non-null int64 <br> FLAG_DOCUMENT_6 307511 non-null int64 <br> FLAG_DOCUMENT_7 307511 non-null int64 <br> FLAG_DOCUMENT_8 307511 non-null int64 <br> FLAG_DOCUMENT_9 307511 non-null int64 <br> FLAG_DOCUMENT_10 307511 non-null int64 <br> FLAG_DOCUMENT_11 307511 non-null int64 <br> FLAG_DOCUMENT_12 307511 non-null int64 <br> FLAG_DOCUMENT_13 307511 non-null int64 <br> FLAG_DOCUMENT_14 307511 non-null int64 <br> FLAG_DOCUMENT_15 307511 non-null int64 <br> FLAG_DOCUMENT_16 307511 non-null int64 <br> FLAG_DOCUMENT_17 307511 non-null int64 <br> FLAG_DOCUMENT_18 307511 non-null int64 <br> FLAG_DOCUMENT_19 307511 non-null int64 <br> FLAG_DOCUMENT_20 307511 non-null int64 <br> FLAG_DOCUMENT_21 307511 non-null int64 <br> AMT_REQ_CREDIT_BUREAU_HOUR 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_DAY 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_WEEK 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_MON 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_QRT 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_YEAR 265992 non-null float64 <br> dtypes: float64(65), int64(41), object(16) <br> memory usage: 286.2+ MB</code> <br> <br>  Rappelez les annotations d√©taill√©es par champ dans le fichier HomeCredit_columns_description.  Comme vous pouvez le voir dans les informations, une partie des donn√©es est incompl√®te et une partie est cat√©gorique, elles sont affich√©es en tant qu'objet.  La plupart des mod√®les ne fonctionnent pas avec de telles donn√©es, nous devrons en faire quelque chose.  Sur ce point, l'analyse initiale peut √™tre consid√©r√©e comme termin√©e, nous irons directement √† EDA <br><br><h2>  Analyse exploratoire des donn√©es ou exploration de donn√©es primaires </h2><br>  Dans le processus EDA, nous comptons les statistiques de base et dessinons des graphiques pour trouver les tendances, les anomalies, les mod√®les et les relations dans les donn√©es.  L'objectif d'EDA est de d√©couvrir ce que les donn√©es peuvent r√©v√©ler.  En r√®gle g√©n√©rale, l'analyse va de haut en bas - d'un aper√ßu g√©n√©ral √† l'√©tude des zones individuelles qui attirent l'attention et peuvent √™tre int√©ressantes.  Par la suite, ces r√©sultats peuvent √™tre utilis√©s dans la construction du mod√®le, la s√©lection des caract√©ristiques pour celui-ci et dans son interpr√©tation. <br><br><h3>  Distribution variable cible </h3><br><pre> <code class="python hljs">app_train.TARGET.value_counts()</code> </pre> <br> <code>0 282686 <br> 1 24825 <br> Name: TARGET, dtype: int64</code> <br> <br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'fivethirtyeight'</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">"figure.figsize"</span></span>] = [<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>]‚Äã plt.hist(app_train.TARGET) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/xm/rd/ch/xmrdchcab8eqbwt2p1pie4jmaeu.png"><br><br>  Permettez-moi de vous rappeler que 1 signifie des probl√®mes de toute nature avec un retour, 0 signifie aucun probl√®me.  Comme vous pouvez le constater, principalement les emprunteurs n'ont aucun probl√®me de remboursement, la part des probl√©matiques est d'environ 8%.  Cela signifie que les classes ne sont pas √©quilibr√©es et cela peut devoir √™tre pris en compte lors de la construction du mod√®le. <br><br><h3>  Recherche de donn√©es manquantes </h3><br>  Nous avons vu que le manque de donn√©es est assez important.  Voyons plus en d√©tail o√π et ce qui manque. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def missing_values_table(df): #   mis_val = df.isnull().sum() #    mis_val_percent = 100 * df.isnull().sum() / len(df) #    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1) #   mis_val_table_ren_columns = mis_val_table.rename( columns = {0 : 'Missing Values', 1 : '% of Total Values'}) #    mis_val_table_ren_columns = mis_val_table_ren_columns[ mis_val_table_ren_columns.iloc[:,1] != 0].sort_values( '% of Total Values', ascending=False).round(1) #  print ("   " + str(df.shape[1]) + " .\n" " " + str(mis_val_table_ren_columns.shape[0]) + "    .") #     return mis_val_table_ren_columns missing_values = missing_values_table(app_train) missing_values.head(10)</span></span></code> </pre> <br><br> <code>   122 . <br>  67    .</code> <br> <img src="https://habrastorage.org/webt/oa/jm/tp/oajmtpuvkymt4asczwqmhqziria.png"><br><br>  Au format graphique: <br><br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'seaborn-talk'</span></span>)‚Äã fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">18</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) miss_train = pd.DataFrame((app_train.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_test = pd.DataFrame((app_test.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_train[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> miss_test[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> missing = pd.concat([miss_train,miss_test],axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) ax = sns.pointplot(<span class="hljs-string"><span class="hljs-string">"index"</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,data=missing,hue=<span class="hljs-string"><span class="hljs-string">"type"</span></span>) plt.xticks(rotation =<span class="hljs-number"><span class="hljs-number">90</span></span>,fontsize =<span class="hljs-number"><span class="hljs-number">7</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"    "</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">"  %"</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">""</span></span>)</code> </pre> <br><br><img src="https://habrastorage.org/webt/iv/fc/ib/ivfcibv85aaktlxybl8bps2vurw.png"><br><br>  Il existe de nombreuses r√©ponses √† la question ¬´que faire de tout cela¬ª.  Vous pouvez le remplir de z√©ros, vous pouvez utiliser des valeurs m√©dianes, vous pouvez simplement supprimer des lignes sans les informations n√©cessaires.  Tout d√©pend du mod√®le que nous pr√©voyons d'utiliser, car certains d'entre eux font parfaitement face aux valeurs manquantes.  Alors que nous nous souvenons de ce fait et que nous laissons tout tel quel. <br><br><h3>  Types de colonnes et codage cat√©gorique </h3><br>  Comme nous nous en souvenons.  une partie des colonnes est de type objet, c'est-√†-dire qu'elle n'a pas de valeur num√©rique, mais refl√®te une certaine cat√©gorie.  Examinons ces colonnes de plus pr√®s. <br><br><pre> <code class="python hljs">app_train.dtypes.value_counts()</code> </pre> <br> <code>float64 65 <br> int64 41 <br> object 16 <br> dtype: int64</code> <br> <br><pre> <code class="python hljs">app_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br> <code>NAME_CONTRACT_TYPE 2 <br> CODE_GENDER 3 <br> FLAG_OWN_CAR 2 <br> FLAG_OWN_REALTY 2 <br> NAME_TYPE_SUITE 7 <br> NAME_INCOME_TYPE 8 <br> NAME_EDUCATION_TYPE 5 <br> NAME_FAMILY_STATUS 6 <br> NAME_HOUSING_TYPE 6 <br> OCCUPATION_TYPE 18 <br> WEEKDAY_APPR_PROCESS_START 7 <br> ORGANIZATION_TYPE 58 <br> FONDKAPREMONT_MODE 4 <br> HOUSETYPE_MODE 3 <br> WALLSMATERIAL_MODE 7 <br> EMERGENCYSTATE_MODE 2 <br> dtype: int64</code> <br> <br>  Nous avons 16 colonnes, chacune avec 2 √† 58 options de valeur diff√©rentes.  En g√©n√©ral, les mod√®les d'apprentissage automatique ne peuvent rien faire avec de telles colonnes (√† l'exception de certaines, telles que LightGBM ou CatBoost).  √âtant donn√© que nous pr√©voyons d'essayer diff√©rents mod√®les sur l'ensemble de donn√©es, quelque chose doit √™tre fait avec cela.  Il existe essentiellement deux approches: <br><br><ul><li>  Encodage des √©tiquettes - les cat√©gories se voient attribuer les chiffres 0, 1, 2 et ainsi de suite et sont √©crites dans la m√™me colonne </li><li>  One-Hot-encoding - une colonne est d√©compos√©e en plusieurs selon le nombre d'options et ces colonnes indiquent quelle option a cet enregistrement. </li></ul><br>  Parmi les plus populaires, il convient de noter l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">encodage cible moyen</a> (merci pour la clarification des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">roryorangepants</a> ). <br><br>  Il y a un petit probl√®me avec le codage d'√©tiquettes - il attribue des valeurs num√©riques qui n'ont rien √† voir avec la r√©alit√©.  Par exemple, si nous avons affaire √† une valeur num√©rique, alors le revenu de l'emprunteur de 100 000 est nettement sup√©rieur et meilleur que le revenu de 20 000. Mais peut-on dire que, par exemple, une ville est meilleure qu'une autre parce qu'on lui attribue la valeur 100 et l'autre 200 ? <br><br>  Par contre, le codage √† chaud est plus s√ªr, mais peut produire des colonnes "suppl√©mentaires".  Par exemple, si nous encodons le m√™me sexe √† l'aide de One-Hot, nous obtenons deux colonnes, ¬´sexe masculin¬ª et ¬´sexe f√©minin¬ª, bien qu'une seule suffise, ¬´est-ce masculin¬ª. <br><br>  Pour un bon ensemble de donn√©es, il serait n√©cessaire de coder des signes √† faible variabilit√© en utilisant le codage d'√©tiquettes, et tout le reste - One-Hot, mais pour plus de simplicit√©, nous codons tout selon One-Hot.  Cela n'affectera pratiquement pas la vitesse de calcul et le r√©sultat.  Le processus de codage des pandas lui-m√™me est tr√®s simple. <br><br><pre> <code class="python hljs">app_train = pd.get_dummies(app_train) app_test = pd.get_dummies(app_test)‚Äã print(<span class="hljs-string"><span class="hljs-string">'Training Features shape: '</span></span>, app_train.shape) print(<span class="hljs-string"><span class="hljs-string">'Testing Features shape: '</span></span>, app_test.shape)</code> </pre> <br> <code>Training Features shape: (307511, 246) <br> Testing Features shape: (48744, 242)</code> <br> <br>  √âtant donn√© que le nombre d'options dans les colonnes de s√©lection n'est pas √©gal, le nombre de colonnes ne correspond plus.  L'alignement est requis - vous devez supprimer les colonnes de l'ensemble de formation qui ne sont pas dans l'ensemble de test.  Cela rend la m√©thode d'alignement, vous devez sp√©cifier axe = 1 (pour les colonnes). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># ,           . train_labels = app_train['TARGET']‚Äã #  -   .     app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)‚Äã print('  : ', app_train.shape) print('  : ', app_test.shape)‚Äã # Add target back in to the data app_train['TARGET'] = train_labels</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><h3>  Corr√©lation des donn√©es </h3><br>  Une bonne fa√ßon de comprendre les donn√©es consiste √† calculer les coefficients de corr√©lation de Pearson pour les donn√©es par rapport √† l'attribut cible.  Ce n'est pas la meilleure m√©thode pour montrer la pertinence des fonctionnalit√©s, mais elle est simple et vous permet d'avoir une id√©e des donn√©es.  Les coefficients peuvent √™tre interpr√©t√©s comme suit: <br><br><ul><li>  00-.19 ¬´tr√®s faible¬ª </li><li>  20-.39 ¬´faible¬ª </li><li>  40 √† 0,59 ¬´moyenne¬ª </li><li>  60-.79 fort </li><li>  80-1,0 ¬´tr√®s fort¬ª </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    correlations = app_train.corr()['TARGET'].sort_values()‚Äã #  print('  : \n', correlations.tail(15)) print('\n  : \n', correlations.head(15))</span></span></code> </pre> <br> <code>  : <br> DAYS_REGISTRATION 0.041975 <br> OCCUPATION_TYPE_Laborers 0.043019 <br> FLAG_DOCUMENT_3 0.044346 <br> REG_CITY_NOT_LIVE_CITY 0.044395 <br> FLAG_EMP_PHONE 0.045982 <br> NAME_EDUCATION_TYPE_Secondary / secondary special 0.049824 <br> REG_CITY_NOT_WORK_CITY 0.050994 <br> DAYS_ID_PUBLISH 0.051457 <br> CODE_GENDER_M 0.054713 <br> DAYS_LAST_PHONE_CHANGE 0.055218 <br> NAME_INCOME_TYPE_Working 0.057481 <br> REGION_RATING_CLIENT 0.058899 <br> REGION_RATING_CLIENT_W_CITY 0.060893 <br> DAYS_BIRTH 0.078239 <br> TARGET 1.000000 <br> Name: TARGET, dtype: float64 <br> <br>   : <br> EXT_SOURCE_3 -0.178919 <br> EXT_SOURCE_2 -0.160472 <br> EXT_SOURCE_1 -0.155317 <br> NAME_EDUCATION_TYPE_Higher education -0.056593 <br> CODE_GENDER_F -0.054704 <br> NAME_INCOME_TYPE_Pensioner -0.046209 <br> ORGANIZATION_TYPE_XNA -0.045987 <br> DAYS_EMPLOYED -0.044932 <br> FLOORSMAX_AVG -0.044003 <br> FLOORSMAX_MEDI -0.043768 <br> FLOORSMAX_MODE -0.043226 <br> EMERGENCYSTATE_MODE_No -0.042201 <br> HOUSETYPE_MODE_block of flats -0.040594 <br> AMT_GOODS_PRICE -0.039645 <br> REGION_POPULATION_RELATIVE -0.037227 <br> Name: TARGET, dtype: float64</code> <br> <br>  Ainsi, toutes les donn√©es sont faiblement corr√©l√©es avec la cible (√† l'exception de la cible elle-m√™me, qui, bien s√ªr, est √©gale √† elle-m√™me).  Cependant, l'√¢ge et certaines ¬´sources de donn√©es externes¬ª se distinguent des donn√©es.  Il s'agit probablement de donn√©es suppl√©mentaires provenant d'autres organismes de cr√©dit.  Il est amusant que, bien que l'objectif soit d√©clar√© ind√©pendant de ces donn√©es dans la prise d'une d√©cision de cr√©dit, en fait, nous nous baserons principalement sur elles. <br><br><h3>  √Çge </h3><br>  Il est clair que plus le client est √¢g√©, plus la probabilit√© de retour est √©lev√©e (jusqu'√† une certaine limite, bien s√ªr).  Mais pour une raison quelconque, l'√¢ge est indiqu√© en jours n√©gatifs avant qu'un pr√™t ne soit √©mis, il est donc en corr√©lation positive avec le non-remboursement (ce qui semble quelque peu √©trange).  Nous le portons √† une valeur positive et examinons la corr√©lation. <br><br><pre> <code class="python hljs">app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>] = abs(app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]) app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>].corr(app_train[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>])</code> </pre> <br> <code>-0.078239308309827088</code> <br> <br>  Examinons de plus pr√®s la variable.  Commen√ßons par l'histogramme. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     ,  25  plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25) plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/v2/zq/1q/v2zq1qolo8rc5wx0tyao4ucygxc.png"><br><br>  L'histogramme de distribution lui-m√™me peut dire un peu utile, sauf que nous ne voyons pas de valeurs aberrantes sp√©ciales et que tout semble plus ou moins cr√©dible.  Pour montrer l'effet de l'influence de l'√¢ge sur le r√©sultat, nous pouvons construire un graphique d'estimation de la densit√© du noyau (KDE) - la distribution de la densit√© nucl√©aire, peinte aux couleurs de l'attribut cible.  Il montre la distribution d'une variable et peut √™tre interpr√©t√© comme un histogramme liss√© (calcul√© comme un noyau gaussien pour chaque point, qui est ensuite moyenn√© pour lisser). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')‚Äã #  plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/st/xs/e1/stxse1wipiaqcf0a7trlm0lwz0g.png"><br><br>  Comme on peut le voir, la part des d√©fauts de paiement est plus √©lev√©e pour les jeunes et diminue avec l'√¢ge.  Ce n'est pas une raison pour refuser toujours le cr√©dit aux jeunes, une telle ¬´recommandation¬ª ne fera que conduire √† une perte de revenus et de march√© pour la banque.  C'est l'occasion de r√©fl√©chir √† un suivi plus approfondi de ces pr√™ts, √† une √©valuation et peut-√™tre m√™me √† une forme d'√©ducation financi√®re pour les jeunes emprunteurs. <br><br><h3>  Sources externes </h3><br>  Examinons de plus pr√®s les ¬´sources de donn√©es externes¬ª EXT_SOURCE et leur corr√©lation. <br><br><pre> <code class="python hljs">ext_data = app_train[[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]] ext_data_corrs = ext_data.corr() ext_data_corrs</code> </pre> <br><img src="https://habrastorage.org/webt/5k/ba/fe/5kbafej-y0vvcexlt6iebcjvjbs.png"><br><br>  Il est √©galement pratique d'afficher la corr√©lation √† l'aide de la carte thermique <br><br><pre> <code class="python hljs">sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = <span class="hljs-number"><span class="hljs-number">-0.25</span></span>, annot = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, vmax = <span class="hljs-number"><span class="hljs-number">0.6</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Correlation Heatmap'</span></span>);</code> </pre> <br><img src="https://habrastorage.org/webt/e6/wj/vw/e6wjvwnetgs2y-i65_4okda-6t8.png"><br><br>  Comme vous pouvez le voir, toutes les sources pr√©sentent une corr√©lation n√©gative avec la cible.  Examinons la distribution de KDE pour chaque source. <br><br><pre> <code class="python hljs">plt.figure(figsize = (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment">#    for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']): #  plt.subplot(3, 1, i + 1) #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0') #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1') #  plt.title('Distribution of %s by Target Value' % source) plt.xlabel('%s' % source); plt.ylabel('Density'); plt.tight_layout(h_pad = 2.5)</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/lf/ig/xm/lfigxmxlck1s4w2uyygfudghajm.png"><br><br>  Le tableau est similaire √† la r√©partition par √¢ge - avec une augmentation de l'indicateur, la probabilit√© d'un rendement de pr√™t augmente.  La troisi√®me source est la plus puissante √† cet √©gard.  Bien qu'en termes absolus, la corr√©lation avec la variable cible soit toujours dans la cat√©gorie ¬´tr√®s faible¬ª, les sources de donn√©es externes et l'√¢ge seront de la plus haute importance dans la construction du mod√®le. <br><br><h3>  Calendrier des paires </h3><br>  Pour mieux comprendre la relation de ces variables, vous pouvez construire un diagramme de paires, en lui, nous pouvons voir la relation de chaque paire et un histogramme de la distribution le long de la diagonale.  Au-dessus de la diagonale, vous pouvez afficher le nuage de points, et en dessous - 2d KDE. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       age_data = app_train[['TARGET', 'DAYS_BIRTH']] age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365‚Äã #     plot_data = ext_data.drop(labels = ['DAYS_BIRTH'], axis=1).copy()‚Äã #   plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']‚Äã #         100 .  plot_data = plot_data.dropna().loc[:100000, :]‚Äã #     def corr_func(x, y, **kwargs): r = np.corrcoef(x, y)[0][1] ax = plt.gca() ax.annotate("r = {:.2f}".format(r), xy=(.2, .8), xycoords=ax.transAxes, size = 20)‚Äã #   pairgrid object grid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False, hue = 'TARGET', vars = [x for x in list(plot_data.columns) if x != 'TARGET'])‚Äã #  -  grid.map_upper(plt.scatter, alpha = 0.2)‚Äã #  -  grid.map_diag(sns.kdeplot)‚Äã #  -   grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);‚Äã plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/wu/bm/ut/wubmutz04p4kwsmmk34gbuoq71g.png"><br><br>  Les pr√™ts remboursables sont indiqu√©s en bleu, non remboursables en rouge.  Interpr√©ter tout cela est assez difficile, mais une bonne impression sur un T-shirt ou une image dans un mus√©e d'art moderne peut sortir de cette image. <br><br><h3>  Examen d'autres signes </h3><br>  Examinons plus en d√©tail d'autres fonctionnalit√©s et leur d√©pendance √† la variable cible.  Puisqu'il y en a beaucoup (et nous avons d√©j√† r√©ussi √† les encoder), nous avons √† nouveau besoin des donn√©es initiales.  Appelons-les un peu diff√©remment pour √©viter toute confusion <br><br><pre> <code class="python hljs">application_train = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_train.csv"</span></span>) application_test = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_test.csv"</span></span>)</code> </pre> <br>  Nous aurons √©galement besoin de quelques fonctions pour afficher magnifiquement les distributions et leur influence sur la variable cible.  Un grand merci <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√†</a> eux pour l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">auteur de</a> ce <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">noyau</a> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_stats</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(feature,label_rotation=False,horizontal_layout=True)</span></span></span><span class="hljs-function">:</span></span> temp = application_train[feature].value_counts() df1 = pd.DataFrame({feature: temp.index,<span class="hljs-string"><span class="hljs-string">' '</span></span>: temp.values})‚Äã <span class="hljs-comment"><span class="hljs-comment">#   target=1   cat_perc = application_train[[feature, 'TARGET']].groupby([feature],as_index=False).mean() cat_perc.sort_values(by='TARGET', ascending=False, inplace=True) if(horizontal_layout): fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6)) else: fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14)) sns.set_color_codes("pastel") s = sns.barplot(ax=ax1, x = feature, y=" ",data=df1) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) plt.ylabel(' ', fontsize=10) plt.tick_params(axis='both', which='major', labelsize=10)‚Äã plt.show();</span></span></code> </pre> <br>  Nous allons donc consid√©rer les principaux signes de clients <br><br><h3>  Type de pr√™t </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_TYPE'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gf/xr/hd/gfxrhdfhqe7zyvlvwjmtgg-opam.png"><br><br>  Fait int√©ressant, les pr√™ts renouvelables (probablement des d√©couverts ou quelque chose du genre) repr√©sentent moins de 10% du nombre total de pr√™ts.  Dans le m√™me temps, le pourcentage de non-retour parmi eux est beaucoup plus √©lev√©.  Une bonne raison de revoir la m√©thodologie de travail avec ces pr√™ts, voire de les abandonner. <br><br><h3>  Sexe du client </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CODE_GENDER'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fj/vu/eu/fjvueuchpemqvpmijfzsslyiy5m.png"><br><br>  Il y a presque deux fois plus de femmes que d'hommes, les hommes pr√©sentant un risque beaucoup plus √©lev√©. <br><br><h3>  Propri√©t√© de voiture et de propri√©t√© </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_CAR'</span></span>) plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_REALTY'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/l4/iv/u4/l4ivu4-yhdkdma8yjrnhj07evdq.png"><br><img src="https://habrastorage.org/webt/fg/qn/2-/fgqn2-3qqhjvkbovec9zm_qkfgo.png"><br><br>  Les clients avec la voiture sont deux fois moins "sans chevaux".  Le risque est presque le m√™me, les clients avec la machine paient un peu mieux. <br><br>  Pour l'immobilier, l'inverse est vrai - il y a deux fois moins de clients sans elle.  Le risque pour les propri√©taires est √©galement l√©g√®rement moindre. <br><br><h3>  √âtat matrimonial </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_FAMILY_STATUS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/7u/qt/t1/7uqtt10kghqs01w-_y_1e6vx2jw.png"><br><br>  Alors que la plupart des clients sont mari√©s, les plus risqu√©s sont les clients civils et c√©libataires.  Les veufs pr√©sentent un risque minimal. <br><br><h3>  Nombre d'enfants </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_CHILDREN'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/5s/ux/o8/5suxo8vh8yl68pnxqf4vm7c-ixa.png"><br><br>  La plupart des clients sont sans enfant.  Dans le m√™me temps, les clients avec 9 et 11 enfants montrent un non-remboursement complet <br><br><pre> <code class="python hljs">application_train.CNT_CHILDREN.value_counts()</code> </pre> <br> <code>0 215371 <br> 1 61119 <br> 2 26749 <br> 3 3717 <br> 4 429 <br> 5 84 <br> 6 21 <br> 7 7 <br> 14 3 <br> 19 2 <br> 12 2 <br> 10 2 <br> 9 2 <br> 8 2 <br> 11 1 <br> Name: CNT_CHILDREN, dtype: int64</code> <br> <br>  Comme le montre le calcul des valeurs, ces donn√©es sont statistiquement non significatives - seulement 1-2 clients des deux cat√©gories.  Cependant, tous les trois ont fait d√©faut, tout comme la moiti√© des clients avec 6 enfants. <br><br><h3>  Nombre de membres de la famille </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_FAM_MEMBERS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/bw/tg/sc/bwtgsctk9vk_y8tcx9bv9fraogu.png"><br><br>  La situation est similaire - moins il y a de bouches, plus le rendement est √©lev√©. <br><br><h3>  Type de revenu </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_INCOME_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/ow/la/kf/owlakfzs7cqh74msyjw9ngeq8h4.png"><br><br>  Les m√®res c√©libataires et les ch√¥meurs seront probablement coup√©s au stade de la demande - il y en a trop peu dans l'√©chantillon.  Mais les probl√®mes sont stables. <br><br><h3>  Type d'activit√© </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'OCCUPATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/pw/m4/eu/pwm4eui3y46rrd0380w5jnkqiug.png"><br><br><pre> <code class="python hljs">application_train.OCCUPATION_TYPE.value_counts()</code> </pre> <br> <code>Laborers 55186 <br> Sales staff 32102 <br> Core staff 27570 <br> Managers 21371 <br> Drivers 18603 <br> High skill tech staff 11380 <br> Accountants 9813 <br> Medicine staff 8537 <br> Security staff 6721 <br> Cooking staff 5946 <br> Cleaning staff 4653 <br> Private service staff 2652 <br> Low-skill Laborers 2093 <br> Waiters/barmen staff 1348 <br> Secretaries 1305 <br> Realty agents 751 <br> HR staff 563 <br> IT staff 526 <br> Name: OCCUPATION_TYPE, dtype: int64</code> <br> <br>  Elle int√©resse les chauffeurs et les agents de s√©curit√© qui sont assez nombreux et rencontrent des probl√®mes plus souvent que les autres cat√©gories. <br><br><h3>  L'√©ducation </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_EDUCATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/dh/g9/-t/dhg9-t4wl5oaaultg0m4ujq4ky0.png"><br><br>  Plus l'enseignement est √©lev√©, meilleure est la r√©currence, √©videmment. <br><br><h3>  Type d'organisation - employeur </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'ORGANIZATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/nm/eq/p-/nmeqp-rvrmowwpqhkjzvygeah20.png"><br><br>  Le pourcentage le plus √©lev√© de non-retour est observ√© dans les transports: type 3 (16%), l'industrie: type 13 (13,5%), l'industrie: type 8 (12,5%) et la restauration (jusqu'√† 12%). <br><br><h3>  Affectation des pr√™ts </h3><br>  Tenez compte de la r√©partition des montants des pr√™ts et de leur impact sur le remboursement <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" AMT_CREDIT"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"AMT_CREDIT"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/x1/8k/qg/x18kqghr1tue4io96l_keuqcr94.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'AMT_CREDIT'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'AMT_CREDIT'], label = 'target == 1')‚Äã #  plt.xlabel(' '); plt.ylabel(''); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/_3/fu/cj/_3fucjn19lmxvjjaamrrlwumh5m.png"><br><br>  Comme le montre le graphique de densit√©, les quantit√©s robustes sont retourn√©es plus souvent <br><br><h3>  Distribution de densit√© </h3><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" REGION_POPULATION_RELATIVE"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"REGION_POPULATION_RELATIVE"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/26/3h/os/263hoss0mbvvq2p0ewagrw5v-sm.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'REGION_POPULATION_RELATIVE'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'REGION_POPULATION_RELATIVE'], label = 'target == 1')‚Äã #  plt.xlabel(''); plt.ylabel(' '); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/fs/ez/82/fsez82q5fbqdkiqizkxjralpm-8.png"><br><br>  Les clients des r√©gions plus peupl√©es ont tendance √† mieux payer leurs pr√™ts. <br><br>  Ainsi, nous avons eu une id√©e des principales caract√©ristiques de l'ensemble de donn√©es et de leur influence sur le r√©sultat.  Nous ne ferons rien de particulier avec ceux √©num√©r√©s dans cet article, mais ils peuvent s'av√©rer tr√®s importants dans les travaux futurs. <br><br><h2>  Ing√©nierie des fonctionnalit√©s - Conversion des fonctionnalit√©s </h2><br>  Les comp√©titions sur Kaggle sont gagn√©es par la transformation des signes - celui qui pourrait cr√©er les signes les plus utiles √† partir des donn√©es gagne.  Au moins pour les donn√©es structur√©es, les mod√®les gagnants sont maintenant des options de renforcement de gradient fondamentalement diff√©rentes.  Le plus souvent, il est plus efficace de passer du temps √† convertir des attributs que de configurer des hyperparam√®tres ou de s√©lectionner des mod√®les.  Un mod√®le ne peut encore apprendre que des donn√©es qui lui ont √©t√© transf√©r√©es.  S'assurer que les donn√©es sont pertinentes pour la t√¢che est la principale responsabilit√© de la date du scientifique. <br><br>  Le processus de transformation des caract√©ristiques peut inclure la cr√©ation de nouvelles donn√©es disponibles, la s√©lection des plus importantes disponibles, etc.  Nous allons essayer cette fois les signes polynomiaux. <br><br><h3>  Signes polynomiaux </h3><br>  La m√©thode polynomiale de construction des fonctionnalit√©s consiste √† cr√©er simplement des fonctionnalit√©s correspondant au degr√© de fonctionnalit√©s disponibles et √† leurs produits.  Dans certains cas, ces caract√©ristiques construites peuvent avoir une corr√©lation plus forte avec la variable cible que leurs ¬´parents¬ª.  Bien que ces m√©thodes soient souvent utilis√©es dans les mod√®les statistiques, elles sont beaucoup moins courantes dans l'apprentissage automatique.  Cependant.  rien ne nous emp√™che de les essayer, d'autant plus que Scikit-Learn a une classe sp√©cialement con√ßue pour ces fins - PolynomialFeatures - qui cr√©e des fonctionnalit√©s polynomiales et leurs produits, il vous suffit de sp√©cifier les fonctionnalit√©s originales elles-m√™mes et le degr√© maximum auquel elles doivent √™tre augment√©es.  Nous utilisons les effets les plus puissants sur le r√©sultat de 4 attributs et le degr√© 3 afin de ne pas trop compliquer le mod√®le et √©viter le surapprentissage (surentra√Ænement du mod√®le - son ajustement excessif √† l'√©chantillon d'apprentissage). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']] poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]‚Äã #    from sklearn.preprocessing import Imputer imputer = Imputer(strategy = 'median')‚Äã poly_target = poly_features['TARGET']‚Äã poly_features = poly_features.drop('TARGET', axis=1)‚Äã poly_features = imputer.fit_transform(poly_features) poly_features_test = imputer.transform(poly_features_test) from sklearn.preprocessing import PolynomialFeatures #     3 poly_transformer = PolynomialFeatures(degree = 3) #    poly_transformer.fit(poly_features) #   poly_features = poly_transformer.transform(poly_features) poly_features_test = poly_transformer.transform(poly_features_test) print('  : ', poly_features.shape)</span></span></code> </pre> <br> <code>  : (307511, 35) <br>        get_feature_names</code> <br> <br><pre> <code class="python hljs">poly_transformer.get_feature_names(input_features = [<span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>])[:<span class="hljs-number"><span class="hljs-number">15</span></span>]</code> </pre> <br> <code>['1', <br> 'EXT_SOURCE_1', <br> 'EXT_SOURCE_2', <br> 'EXT_SOURCE_3', <br> 'DAYS_BIRTH', <br> 'EXT_SOURCE_1^2', <br> 'EXT_SOURCE_1 EXT_SOURCE_2', <br> 'EXT_SOURCE_1 EXT_SOURCE_3', <br> 'EXT_SOURCE_1 DAYS_BIRTH', <br> 'EXT_SOURCE_2^2', <br> 'EXT_SOURCE_2 EXT_SOURCE_3', <br> 'EXT_SOURCE_2 DAYS_BIRTH', <br> 'EXT_SOURCE_3^2', <br> 'EXT_SOURCE_3 DAYS_BIRTH', <br> 'DAYS_BIRTH^2']</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un total de 35 caract√©ristiques polynomiales et d√©riv√©es. </font><font style="vertical-align: inherit;">V√©rifiez leur corr√©lation avec la cible.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     poly_features = pd.DataFrame(poly_features, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #   poly_features['TARGET'] = poly_target‚Äã #   poly_corrs = poly_features.corr()['TARGET'].sort_values()‚Äã #      print(poly_corrs.head(10)) print(poly_corrs.tail(5))</span></span></code> </pre> <br> <code>EXT_SOURCE_2 EXT_SOURCE_3 -0.193939 <br> EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3 -0.189605 <br> EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH -0.181283 <br> EXT_SOURCE_2^2 EXT_SOURCE_3 -0.176428 <br> EXT_SOURCE_2 EXT_SOURCE_3^2 -0.172282 <br> EXT_SOURCE_1 EXT_SOURCE_2 -0.166625 <br> EXT_SOURCE_1 EXT_SOURCE_3 -0.164065 <br> EXT_SOURCE_2 -0.160295 <br> EXT_SOURCE_2 DAYS_BIRTH -0.156873 <br> EXT_SOURCE_1 EXT_SOURCE_2^2 -0.156867 <br> Name: TARGET, dtype: float64 <br> DAYS_BIRTH -0.078239 <br> DAYS_BIRTH^2 -0.076672 <br> DAYS_BIRTH^3 -0.074273 <br> TARGET 1.000000 <br> 1 NaN <br> Name: TARGET, dtype: float64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ainsi, certains signes montrent une corr√©lation plus √©lev√©e que l'original. </font><font style="vertical-align: inherit;">Il est logique d'essayer d'apprendre avec et sans eux (comme beaucoup plus dans l'apprentissage automatique, cela peut √™tre d√©termin√© exp√©rimentalement). </font><font style="vertical-align: inherit;">Pour ce faire, cr√©ez une copie des cadres de donn√©es et ajoutez-y de nouvelles fonctionnalit√©s.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      poly_features_test = pd.DataFrame(poly_features_test, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #    poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR'] app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')‚Äã #    poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR'] app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')‚Äã #   app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)‚Äã #   print('    : ', app_train_poly.shape) print('    : ', app_test_poly.shape)</span></span></code> </pre> <br> <code>    : (307511, 277) <br>     : (48744, 277)</code> <br> <br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Formation mod√®le </font></font></h2><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Niveau de base </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans les calculs, vous devez partir d'un certain niveau de base du mod√®le, en dessous duquel il n'est plus possible de tomber. </font><font style="vertical-align: inherit;">Dans notre cas, cela pourrait √™tre de 0,5 pour tous les clients test - cela montre que nous n'avons aucune id√©e du fait que le client remboursera le pr√™t ou non. </font><font style="vertical-align: inherit;">Dans notre cas, un travail pr√©liminaire a d√©j√† √©t√© fait et des mod√®les plus complexes peuvent √™tre utilis√©s.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> R√©gression logistique </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour calculer la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©gression logistique,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nous devons prendre des tableaux avec des caract√©ristiques cat√©gorielles cod√©es, remplir les donn√©es manquantes et les normaliser (les amener √† des valeurs de 0 √† 1). </font><font style="vertical-align: inherit;">Tout cela ex√©cute le code suivant:</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MinMaxScaler, Imputer‚Äã <span class="hljs-comment"><span class="hljs-comment">#      if 'TARGET' in app_train: train = app_train.drop(labels = ['TARGET'], axis=1) else: train = app_train.copy() features = list(train.columns)‚Äã #    test = app_test.copy()‚Äã #     imputer = Imputer(strategy = 'median')‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã #    imputer.fit(train)‚Äã #      train = imputer.transform(train) test = imputer.transform(app_test)‚Äã #      scaler.fit(train) train = scaler.transform(train) test = scaler.transform(test)‚Äã print('  : ', train.shape) print('  : ', test.shape)</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous utilisons la r√©gression logistique de Scikit-Learn comme premier mod√®le. </font><font style="vertical-align: inherit;">Prenons le mod√®le de d√©foliation avec une correction - nous abaissons le param√®tre de r√©gularisation C pour √©viter le sur-ajustement. </font><font style="vertical-align: inherit;">La syntaxe est normale - nous cr√©ons un mod√®le, le formons et pr√©disons la probabilit√© √† l'aide de predire_proba (nous avons besoin d'une probabilit√©, pas de 0/1)</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression‚Äã <span class="hljs-comment"><span class="hljs-comment">#   log_reg = LogisticRegression(C = 0.0001)‚Äã #   log_reg.fit(train, train_labels) LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)      .  prdict_proba     mx 2,  m -  ,   -  0,  -  1.    ( ). log_reg_pred = log_reg.predict_proba(test)[:, 1]</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pouvez maintenant cr√©er un fichier √† t√©l√©charger sur Kaggle. </font><font style="vertical-align: inherit;">Cr√©ez une trame de donn√©es √† partir de l'ID client et de la probabilit√© de non-retour et t√©l√©chargez-la.</font></font><br><br><pre> <code class="python hljs">submit = app_test[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]] submit[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>] = log_reg_pred‚Äã submit.head()</code> </pre> <br> <code>SK_ID_CURR TARGET <br> 0 100001 0.087954 <br> 1 100005 0.163151 <br> 2 100013 0.109923 <br> 3 100028 0.077124 <br> 4 100038 0.151694</code> <br> <br><pre> <code class="python hljs">submit.to_csv(<span class="hljs-string"><span class="hljs-string">'log_reg_baseline.csv'</span></span>, index = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Donc, le r√©sultat de notre travail titanesque: 0,673, avec le meilleur r√©sultat pour aujourd'hui est 0,802.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mod√®le am√©lior√© - For√™t al√©atoire </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Logreg ne se montre pas tr√®s bien, essayons d'utiliser un mod√®le am√©lior√© - une for√™t al√©atoire. </font><font style="vertical-align: inherit;">Il s'agit d'un mod√®le beaucoup plus puissant qui peut construire des centaines d'arbres et produire un r√©sultat beaucoup plus pr√©cis. </font><font style="vertical-align: inherit;">Nous utilisons 100 arbres. </font><font style="vertical-align: inherit;">Le sch√©ma de travail avec le mod√®le est le m√™me, tout √† fait standard - chargement du classificateur, formation. </font><font style="vertical-align: inherit;">pr√©diction.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier‚Äã <span class="hljs-comment"><span class="hljs-comment">#   random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)‚Äã #     random_forest.fit(train, train_labels)‚Äã #     predictions = random_forest.predict_proba(test)[:, 1]‚Äã #     submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #  submit.to_csv('random_forest_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le r√©sultat de la for√™t al√©atoire est l√©g√®rement meilleur - 0,683</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mod√®le d'entra√Ænement avec caract√©ristiques polynomiales </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maintenant que nous avons un mod√®le. </font><font style="vertical-align: inherit;">qui fait au moins quelque chose - il est temps de tester nos signes polynomiaux. </font><font style="vertical-align: inherit;">Faisons de m√™me avec eux et comparons le r√©sultat.</font></font><br><br><pre> <code class="python hljs">poly_features_names = list(app_train_poly.columns)‚Äã <span class="hljs-comment"><span class="hljs-comment">#         imputer = Imputer(strategy = 'median')‚Äã poly_features = imputer.fit_transform(app_train_poly) poly_features_test = imputer.transform(app_test_poly)‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã poly_features = scaler.fit_transform(poly_features) poly_features_test = scaler.transform(poly_features_test)‚Äã random_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50) #     random_forest_poly.fit(poly_features, train_labels)‚Äã #  predictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]‚Äã #    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('random_forest_baseline_engineered.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le r√©sultat d'une for√™t al√©atoire avec des caract√©ristiques polynomiales est devenu pire - 0,633. </font><font style="vertical-align: inherit;">Ce qui remet fortement en cause la n√©cessit√© de leur utilisation.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Augmentation du gradient </font></font></h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'amplification du gradient</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est un ¬´mod√®le s√©rieux¬ª pour l'apprentissage automatique. </font><font style="vertical-align: inherit;">Presque toutes les derni√®res comp√©titions sont ¬´tra√Æn√©es¬ª exactement. </font><font style="vertical-align: inherit;">Construisons un mod√®le simple et testons ses performances.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf = LGBMClassifier() clf.fit(train, train_labels)‚Äã predictions = clf.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('lightgbm_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le r√©sultat de LightGBM est de 0,735, ce qui laisse derri√®re tous les autres mod√®les.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Interpr√©tation des mod√®les - Importance des attributs </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La fa√ßon la plus simple d'interpr√©ter un mod√®le consiste √† examiner l'importance des fonctionnalit√©s (ce que tous les mod√®les ne peuvent pas faire). </font><font style="vertical-align: inherit;">Puisque notre classificateur a trait√© le tableau, il faudra un peu de travail pour r√©initialiser les noms de colonne en fonction des colonnes de ce tableau.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def show_feature_importances(model, features): plt.figure(figsize = (12, 8)) #          results = pd.DataFrame({'feature': features, 'importance': model.feature_importances_}) results = results.sort_values('importance', ascending = False) #  print(results.head(10)) print('\n     0.01 = ', np.sum(results['importance'] &gt; 0.01)) #  results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh', color = 'red', edgecolor = 'k', title = 'Feature Importances'); return results #         feature_importances = show_feature_importances(clf, features)</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comme on </font><font style="vertical-align: inherit;">pouvait s'y attendre, le plus important pour mod√©liser tous les m√™mes caract√©ristiques 4. </font><font style="vertical-align: inherit;">L'importance des attributs n'est pas la meilleure m√©thode d'interpr√©tation du mod√®le, mais elle vous permet de comprendre les principaux facteurs que le mod√®le utilise pour les pr√©dictions</font></font><code>feature importance <br> 28 EXT_SOURCE_1 310 <br> 30 EXT_SOURCE_3 282 <br> 29 EXT_SOURCE_2 271 <br> 7 DAYS_BIRTH 192 <br> 3 AMT_CREDIT 161 <br> 4 AMT_ANNUITY 142 <br> 5 AMT_GOODS_PRICE 129 <br> 8 DAYS_EMPLOYED 127 <br> 10 DAYS_ID_PUBLISH 102 <br> 9 DAYS_REGISTRATION 69 <br> <br>     0.01 = 158</code> <br> <br><img src="https://habrastorage.org/webt/uc/pi/ox/ucpiox1dno_vps4lsuk0lmxk7si.png"><br><br><font style="vertical-align: inherit;"></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ajout de donn√©es √† partir d'autres tables </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous allons maintenant examiner attentivement les tableaux suppl√©mentaires et ce qui peut √™tre fait avec eux. </font><font style="vertical-align: inherit;">Commencez imm√©diatement √† pr√©parer des tableaux pour la formation continue. </font><font style="vertical-align: inherit;">Mais d'abord, supprimez les anciennes tables volumineuses de la m√©moire, videz la m√©moire √† l'aide du garbage collector et importez les biblioth√®ques n√©cessaires pour une analyse plus approfondie.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gc‚Äã <span class="hljs-comment"><span class="hljs-comment">#del app_train, app_test, train_labels, application_train, application_test, poly_features, poly_features_test‚Äã gc.collect() import pandas as pd import numpy as np‚Äã from sklearn.preprocessing import MinMaxScaler, LabelEncoder from sklearn.model_selection import train_test_split, KFold from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix from sklearn.feature_selection import VarianceThreshold‚Äã from lightgbm import LGBMClassifier</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Importez des donn√©es, supprimez imm√©diatement la colonne cible dans une colonne distincte </font></font><br><br><pre> <code class="python hljs">data = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_train.csv'</span></span>) test = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_test.csv'</span></span>) prev = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/previous_application.csv'</span></span>) buro = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau.csv'</span></span>) buro_balance = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau_balance.csv'</span></span>) credit_card = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/credit_card_balance.csv'</span></span>) POS_CASH = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/POS_CASH_balance.csv'</span></span>) payments = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/installments_payments.csv'</span></span>)‚Äã <span class="hljs-comment"><span class="hljs-comment">#Separate target variable y = data['TARGET'] del data['TARGET']</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Encode imm√©diatement les fonctionnalit√©s cat√©gorielles. </font><font style="vertical-align: inherit;">Nous l'avons d√©j√† fait auparavant, et nous avons cod√© s√©par√©ment les √©chantillons d'apprentissage et de test, puis align√© les donn√©es. </font><font style="vertical-align: inherit;">Essayons une approche l√©g√®rement diff√©rente - nous trouverons toutes ces fonctionnalit√©s cat√©gorielles, combinerons les trames de donn√©es, encoderons √† partir de la liste des trames trouv√©es, puis diviserons √† nouveau les √©chantillons en formations et tests.</font></font><br><br><pre> <code class="python hljs">categorical_features = [col <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> data[col].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>]‚Äã one_hot_df = pd.concat([data,test]) one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)‚Äã data = one_hot_df.iloc[:data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>],:] test = one_hot_df.iloc[data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]:,]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape)</code> </pre> <br> <code>   (307511, 245) <br>    (48744, 245)</code> <br> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Donn√©es du bureau de cr√©dit sur le solde du pr√™t mensuel. </font></font></h3><br><pre> <code class="python hljs">buro_balance.head()</code> </pre> <br><img src="https://habrastorage.org/webt/pa/im/0s/paim0sea2cdjnvm7lok--vi8oke.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MONTHS_BALANCE - le nombre de mois avant la date de demande de pr√™t. </font><font style="vertical-align: inherit;">Regardons de plus pr√®s les ¬´statuts¬ª</font></font><br><br><pre> <code class="python hljs">buro_balance.STATUS.value_counts()</code> </pre> <br> <code>C 13646993 <br> 0 7499507 <br> X 5810482 <br> 1 242347 <br> 5 62406 <br> 2 23419 <br> 3 8924 <br> 4 5847 <br> Name: STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les statuts signifient ce qui suit: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - ferm√©, c'est-√†-dire pr√™t rembours√©. </font><font style="vertical-align: inherit;">X est un statut inconnu. </font><font style="vertical-align: inherit;">0 - pr√™t en cours, pas de retard. </font><font style="vertical-align: inherit;">1 - d√©lai de 1 √† 30 jours, 2 - d√©lai de 31 √† 60 jours, et ainsi de suite jusqu'au statut 5 - le pr√™t est vendu √† un tiers ou amorti. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ici, par exemple, les signes suivants peuvent √™tre distingu√©s: buro_grouped_size - le nombre d'entr√©es dans la base de donn√©es buro_grouped_max - le solde de pr√™t maximum buro_grouped_min - le solde de pr√™t minimum </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et tous ces statuts de pr√™t peuvent √™tre encod√©s (nous utilisons la m√©thode unstack, puis attachons les donn√©es re√ßues √† la table buro, car SK_ID_BUREAU est le m√™me ici et l√†.</font></font><br><br><pre> <code class="python hljs">buro_grouped_size = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].size() buro_grouped_max = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].max() buro_grouped_min = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].min()‚Äã buro_counts = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>].value_counts(normalize = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) buro_counts_unstacked = buro_counts.unstack(<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>) buro_counts_unstacked.columns = [<span class="hljs-string"><span class="hljs-string">'STATUS_0'</span></span>, <span class="hljs-string"><span class="hljs-string">'STATUS_1'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_2'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_3'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_4'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_5'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_C'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_X'</span></span>,] buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_COUNT'</span></span>] = buro_grouped_size buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MIN'</span></span>] = buro_grouped_min buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MAX'</span></span>] = buro_grouped_max‚Äã buro = buro.join(buro_counts_unstacked, how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro_balance gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Informations g√©n√©rales sur les bureaux de cr√©dit </font></font></h3><br><pre> <code class="python hljs">buro.head()</code> </pre> <br><img src="https://habrastorage.org/webt/00/7q/dz/007qdzakfbvd5qiizsxqwxvoari.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(les 7 premi√®res colonnes sont affich√©es) Il y </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a beaucoup de donn√©es que, en g√©n√©ral, vous pouvez essayer de coder simplement avec One-Hot-Encoding, grouper par SK_ID_CURR, moyenne et, de la m√™me mani√®re, pr√©parer la jonction avec la table principale</font></font><br><br><pre> <code class="python hljs">buro_cat_features = [bcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> bcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> buro.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> buro[bcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] buro = pd.get_dummies(buro, columns=buro_cat_features) avg_buro = buro.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_buro[<span class="hljs-string"><span class="hljs-string">'buro_count'</span></span>] = buro[[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count()[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_buro[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Donn√©es sur les applications pr√©c√©dentes </font></font></h3><br><pre> <code class="python hljs">prev.head()</code> </pre> <br><img src="https://habrastorage.org/webt/nx/sv/z-/nxsvz-simhdingy0zqgnwg9xxpi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> De m√™me, nous encodons les fonctionnalit√©s cat√©gorielles, faisons la moyenne et combinons sur l'ID actuel. </font></font><br><br><pre> <code class="python hljs">prev_cat_features = [pcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> prev.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> prev[pcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] prev = pd.get_dummies(prev, columns=prev_cat_features) avg_prev = prev.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() cnt_prev = prev[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count() avg_prev[<span class="hljs-string"><span class="hljs-string">'nb_app'</span></span>] = cnt_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> prev gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Solde de carte de cr√©dit </font></font></h3><br><pre> <code class="python hljs">POS_CASH.head()</code> </pre> <br><img src="https://habrastorage.org/webt/aq/25/er/aq25erq2wzuknck85ina4twk2g8.png"><br><br><pre> <code class="python hljs">POS_CASH.NAME_CONTRACT_STATUS.value_counts()</code> </pre> <br> <code>Active 9151119 <br> Completed 744883 <br> Signed 87260 <br> Demand 7065 <br> Returned to the store 5461 <br> Approved 4917 <br> Amortized debt 636 <br> Canceled 15 <br> XNA 2 <br> Name: NAME_CONTRACT_STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nous encodons des caract√©ristiques cat√©gorielles et pr√©parons un tableau pour combiner </font></font><br><br><pre> <code class="python hljs">le = LabelEncoder() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Donn√©es de la carte </font></font></h3><br><pre> <code class="python hljs">credit_card.head()</code> </pre> <br><img src="https://habrastorage.org/webt/q5/wj/pj/q5wjpj8s-vak-svacdtlhqrwlus.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(7 premi√®res colonnes) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Travaux similaires</font></font><br><br><pre> <code class="python hljs">credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Donn√©es de paiement </font></font></h3><br><pre> <code class="python hljs">payments.head()</code> </pre> <br><img src="https://habrastorage.org/webt/ay/fy/3y/ayfy3yp5tzdxsffurkrgjd4udwu.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(7 premi√®res colonnes affich√©es) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cr√©ons trois tableaux - avec les valeurs moyennes, minimales et maximales de ce tableau.</font></font><br><br><pre> <code class="python hljs">avg_payments = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_payments2 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() avg_payments3 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).min() <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_payments[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> payments gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Jointure de table </font></font></h3><br><pre> <code class="python hljs">data = data.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev, avg_buro, POS_CASH, credit_card, avg_payments, avg_payments2, avg_payments3 gc.collect() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, y.shape)</code> </pre> <br> <code>   (307511, 504) <br>    (48744, 504) <br>    (307511,)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Et, en fait, nous atteindrons ce tableau doubl√© avec un boost de gradient! </font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf2 = LGBMClassifier() clf2.fit(data, y)‚Äã predictions = clf2.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submission = test[['SK_ID_CURR']] submission['TARGET'] = predictions‚Äã #   submission.to_csv('lightgbm_full.csv', index = False)</span></span></code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le r√©sultat est 0,770. </font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OK, enfin, essayons une technique plus complexe avec le pliage en plis, la validation crois√©e et le choix de la meilleure it√©ration.</font></font><br><br><pre> <code class="python hljs">folds = KFold(n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">546789</span></span>) oof_preds = np.zeros(data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) sub_preds = np.zeros(test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])‚Äã feature_importance_df = pd.DataFrame()‚Äã feats = [f <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n_fold, (trn_idx, val_idx) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(folds.split(data)): trn_x, trn_y = data[feats].iloc[trn_idx], y.iloc[trn_idx] val_x, val_y = data[feats].iloc[val_idx], y.iloc[val_idx] clf = LGBMClassifier( n_estimators=<span class="hljs-number"><span class="hljs-number">10000</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, num_leaves=<span class="hljs-number"><span class="hljs-number">34</span></span>, colsample_bytree=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, subsample=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">8</span></span>, reg_alpha=<span class="hljs-number"><span class="hljs-number">.1</span></span>, reg_lambda=<span class="hljs-number"><span class="hljs-number">.1</span></span>, min_split_gain=<span class="hljs-number"><span class="hljs-number">.01</span></span>, min_child_weight=<span class="hljs-number"><span class="hljs-number">375</span></span>, silent=<span class="hljs-number"><span class="hljs-number">-1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">-1</span></span>, ) clf.fit(trn_x, trn_y, eval_set= [(trn_x, trn_y), (val_x, val_y)], eval_metric=<span class="hljs-string"><span class="hljs-string">'auc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">100</span></span>, early_stopping_rounds=<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#30 ) oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1] sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits fold_importance_df = pd.DataFrame() fold_importance_df["feature"] = feats fold_importance_df["importance"] = clf.feature_importances_ fold_importance_df["fold"] = n_fold + 1 feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0) print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]))) del clf, trn_x, trn_y, val_x, val_y gc.collect()‚Äã print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))‚Äã test['TARGET'] = sub_preds‚Äã test[['SK_ID_CURR', 'TARGET']].to_csv('submission_cross.csv', index=False)</span></span></code> </pre> <br> <code>Full AUC score 0.785845</code> <br> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Score final sur kaggle 0.783</font></font></b> <br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O√π aller ensuite </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Certainement continuer √† travailler avec des panneaux. Explorez les donn√©es, s√©lectionnez certains des signes, combinez-les, joignez des tableaux suppl√©mentaires d'une mani√®re diff√©rente. Vous pouvez exp√©rimenter avec des hyperparam√®tres Mogheli - beaucoup de directions. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'esp√®re que cette petite compilation vous a montr√© des m√©thodes modernes de recherche de donn√©es et de pr√©paration de mod√®les pr√©dictifs. Apprenez des donn√©es, participez √† des comp√©titions, soyez cool! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et encore des liens vers les noyaux qui m'ont aid√© √† pr√©parer cet article. L'article est √©galement publi√© sous la forme d'un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ordinateur portable sur Github</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , vous pouvez le t√©l√©charger, l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ensemble de donn√©es</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et ex√©cuter et exp√©rimenter. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Will Koehrsen. Commencez ici: une introduction douce </font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sban. HomeCreditRisk: Base de r√©f√©rence EDA + √©tendue [0.772]</font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gabriel Preda. Home Credit Default Risk Extensive EDA</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pavan Raj. Loan repayers v/s Loan defaulters ‚Äî HOME CREDIT</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lem Lordje Ko. 15 lines: Just EXT_SOURCE_x</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Shanth. HOME CREDIT ‚Äî BUREAU DATA ‚Äî FEATURE ENGINEERING</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dmitriy Kisil. Good_fun_with_LigthGBM</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr414613/">https://habr.com/ru/post/fr414613/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr414595/index.html">Blocage de Roskomnadzor par l'hymne de la F√©d√©ration de Russie</a></li>
<li><a href="../fr414597/index.html">Demandez √† Ethan: Dans quelle mesure les civilisations extraterrestres peuvent-elles se rapprocher?</a></li>
<li><a href="../fr414605/index.html">Mini empires</a></li>
<li><a href="../fr414609/index.html">Le PWA (Progressive Web Apps) 2018 peut-il √™tre une concurrence digne des applications natives?</a></li>
<li><a href="../fr414611/index.html">Mon histoire de cr√©ation d'une application de motivation (iOS et Android) pour une fille avec une fille dans Unity et C #</a></li>
<li><a href="../fr414615/index.html">Oubliez le RGPD: la r√©forme du droit d'auteur de l'UE pourrait compl√®tement changer le Web</a></li>
<li><a href="../fr414617/index.html">Efficacit√© des ressources informatiques</a></li>
<li><a href="../fr414619/index.html">Poudlard rouge. S√©rie 8. Voile</a></li>
<li><a href="../fr414621/index.html">Un syst√®me robotis√© acc√©l√®re l'√©chantillonnage et les tests sanguins</a></li>
<li><a href="../fr414625/index.html">Data Center World: √ßa vaut le coup?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚋 📂 👩🏿‍🤝‍👩🏼 Maman dort tranquillement la nuit - nous collectons OpenCV pour Raspbian'a 👎🏿 🙏🏻 ⚓️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les deux dernières semaines ont été difficiles pour notre équipe. OpenCV 4 est sorti , et avec lui, ils se sont préparés pour la boîte à outils Intel ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Maman dort tranquillement la nuit - nous collectons OpenCV pour Raspbian'a</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/430906/"><p> Les deux dernières semaines ont été difficiles pour notre équipe.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenCV 4 est sorti</a> , et avec lui, ils se sont préparés pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la boîte à outils Intel OpenVINO</a> R4, qui comprend OpenCV.  Vous pensez, je suis distrait pendant un certain temps, je vais regarder, comme d'habitude, sur les forums OpenCV et les commentaires des utilisateurs, et ici, il est devenu à la mode pour vous de dire que OpenCV n'est pas l'IoT, que sous Raspberry Pi, il suffit d'assembler - il n'y a pas assez de soudure pour mettre <code>make -j2</code> - le matin, il sera prêt si vous avez de la chance. </p><br><p>  Par conséquent, je propose de travailler ensemble et de voir comment assembler la bibliothèque OpenCV pour un système d'exploitation 32 bits fonctionnant sur un processeur ARM en utilisant les ressources d'une machine avec un système d'exploitation 64 bits, piloté par une excellente architecture CPU. <del>  Sorcellerie </del>  Compilation croisée, pas autrement! </p><a name="habracut"></a><br><h2 id="postanovka-zadachi">  Énoncé du problème </h2><br><p>  Compiler directement sur la carte, communément appelée native, est vraiment laborieux, nous allons donc ici envisager un moyen de construire un projet qui permet à des appareils informatiques plus puissants (appelons-les hôtes) de préparer des binaires pour leurs petits parents.  De plus, les deux machines peuvent avoir des architectures CPU différentes.  Il s'agit d'une compilation croisée. </p><br><p>  Donc, pour préparer une tarte aux framboises farcie avec OpenCV, nous avons besoin de: </p><br><ul><li>  Ubuntu 16.04 carcasse image docker </li><li>  La machine hôte est plus puissante que le Raspberry Pi (sinon, à quoi ça sert, non?) </li><li>  Cross-compilateur pour ARMhf, ainsi que des bibliothèques de l'architecture correspondante </li></ul><br><p>  L'ensemble du processus de création d'OpenCV se déroulera sur la machine hôte.  J'utilise Ubuntu à la maison.  Avec une autre version de Linux, aucun problème de lecture ne devrait se produire.  Pour les utilisateurs de Windows - je souhaite sincèrement ne pas abandonner et essayer de le découvrir par nous-mêmes. </p><br><h2 id="ustanovka-docker">  Installer Docker </h2><br><p>  J'ai commencé ma connaissance de Docker il y a environ une semaine, alors ajoutez du sel gourmet et du sucre syntaxique au goût.  Trois ingrédients suffisent pour vous et moi - Dockerfile, le concept d'image et de conteneur. </p><br><p>  Docker lui-même est un outil pour créer et reproduire la configuration de n'importe quel système d'exploitation avec l'ensemble de composants nécessaire.  Dockerfile est un ensemble de commandes shell que vous utilisez généralement sur la machine hôte, mais dans ce cas, elles s'appliquent toutes à la soi-disant image <code>docker</code> . </p><br><p>  Pour installer docker, considérez la manière la plus simple: commandez un paquet via le service de livraison <code>apt-get</code> : </p><br><pre> <code class="bash hljs">sudo apt-get install -y docker.io</code> </pre> <br><p>  Nous donnerons au démon docker tout ce qu'il demandera et nous ferons la déconnexion du système (notez la connexion en conséquence). </p><br><pre> <code class="bash hljs">sudo usermod -a -G docker <span class="hljs-variable"><span class="hljs-variable">$USER</span></span></code> </pre> <br><h2 id="podgotavlivaem-rabochee-prostranstvo">  Préparation de l'espace de travail </h2><br><p>  Raspberry Pi (dans mon cas RPI 2 Model B) dans la préparation la plus courante est un processeur ARMv7 avec le système d'exploitation Raspbian (basé sur Debian).  Nous allons créer une image <code>docker</code> basée sur Ubuntu 16.04, dans laquelle nous signalerons le compilateur croisé, les bibliothèques de l'armée et collecterons OpenCV au même endroit. </p><br><p>  Créez un papa où <code>Dockerfile</code> notre <code>Dockerfile</code> : </p><br><pre> <code class="bash hljs">mkdir ubuntu16_armhf_opencv &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ubuntu16_armhf_opencv touch Dockerfile</code> </pre> <br><p>  Ajoutez des informations sur le système d'exploitation de base et l'architecture <code>armhf</code> pour le programme d'installation du package <code>apt-get</code> : </p><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 USER root RUN dpkg --add-architecture armhf RUN apt-get update</code> </pre> <br><p>  Veuillez noter que les commandes comme <code>FROM ...</code> , <code>RUN ...</code> sont la syntaxe du <code>docker</code> et sont écrites dans le fichier de test <code>Dockerfile</code> créé. </p><br><p>  Revenons au répertoire parent <code>ubuntu16_armhf_opencv</code> et essayons de créer notre image docker: </p><br><pre> <code class="bash hljs">docker image build ubuntu16_armhf_opencv</code> </pre> <br><p>  Pendant l'exécution de la commande <code>apt-get update</code> , vous devriez être amené à voir des erreurs du type suivant: <code>Err:[] [url] xenial[-] armhf Packages</code> </p><br><pre> <code class="bash hljs">Ign:30 http://archive.ubuntu.com/ubuntu xenial-backports/main armhf Packages Ign:32 http://archive.ubuntu.com/ubuntu xenial-backports/universe armhf Packages Err:7 http://archive.ubuntu.com/ubuntu xenial/main armhf Packages 404 Not Found Ign:9 http://archive.ubuntu.com/ubuntu xenial/restricted armhf Packages Ign:18 http://archive.ubuntu.com/ubuntu xenial/universe armhf Packages Ign:20 http://archive.ubuntu.com/ubuntu xenial/multiverse armhf Packages Err:22 http://archive.ubuntu.com/ubuntu xenial-updates/main armhf Packages 404 Not Found Ign:24 http://archive.ubuntu.com/ubuntu xenial-updates/restricted armhf Packages Ign:26 http://archive.ubuntu.com/ubuntu xenial-updates/universe armhf Packages Ign:28 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse armhf Packages Err:30 http://archive.ubuntu.com/ubuntu xenial-backports/main armhf Packages 404 Not Found Ign:32 http://archive.ubuntu.com/ubuntu xenial-backports/universe armhf Packages</code> </pre> <br><p>  Si vous regardez le fichier <code>/etc/apt/sources.list</code> chacune de ces erreurs correspond à une ligne, par exemple: </p><br><p>  <strong>Erreur</strong> </p><br><pre> <code class="plaintext hljs">Err:22 http://archive.ubuntu.com/ubuntu xenial-updates/main armhf Packages 404 Not Found</code> </pre> <br><p>  <strong>Ligne dans /etc/apt/sources.list</strong> : </p><br><pre> <code class="plaintext hljs">deb http://archive.ubuntu.com/ubuntu/ xenial-updates main restricted</code> </pre> <br><p>  <strong>Solution</strong> : <br>  Divisez en deux: </p><br><pre> <code class="plaintext hljs">deb [arch=amd64] http://archive.ubuntu.com/ubuntu/ xenial-updates main restricted deb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ xenial-updates main restricted</code> </pre> <br><p>  Ainsi, vous devez remplacer plusieurs sources de package.  Dans notre docker, nous les remplacerons tous par une seule commande: </p><br><pre> <code class="plaintext hljs">RUN sed -i -E 's|^deb ([^ ]+) (.*)$|deb [arch=amd64] \1 \2\ndeb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ \2|' /etc/apt/sources.list</code> </pre> <br><p>  La <code>apt-get update</code> devrait maintenant fonctionner sans erreur. </p><br><h2 id="stavim-neobhodimye-pakety">  Nous mettons les packages nécessaires </h2><br><p>  Nous devons fournir des packages hôtes tels que <code>git</code> , <code>python-pip</code> , <code>cmake</code> et <code>pkg-config</code> , ainsi que <code>crossbuild-essential-armhf</code> , qui est un ensemble de compilateurs croisés gcc / g ++ ( <code>arm-linux-gnueabihf-gcc</code> et <code>arm-linux-gnueabihf-g++</code> ) et les bibliothèques système de l'architecture correspondante: </p><br><pre> <code class="plaintext hljs">RUN apt-get install -y git python-pip cmake pkg-config crossbuild-essential-armhf</code> </pre> <br><p>  De l'inhabituel - nous téléchargeons également GTK (utilisé pour dessiner des fenêtres dans le module highgui), GStreamer et Python, mais avec une indication explicite d'une architecture étrangère: </p><br><pre> <code class="plaintext hljs">RUN apt-get install -y --no-install-recommends \ libgtk2.0-dev:armhf \ libpython-dev:armhf \ libgstreamer1.0-dev:armhf \ libgstreamer-plugins-base1.0-dev:armhf \ libgstreamer-plugins-good1.0-dev:armhf \ libgstreamer-plugins-bad1.0-dev:armhf</code> </pre> <br><p>  Et puis nous clonons et collectons, indiquant les drapeaux nécessaires: </p><br><pre> <code class="plaintext hljs">RUN git clone https://github.com/opencv/opencv --depth 1 RUN mkdir opencv/build &amp;&amp; cd opencv/build &amp;&amp; \ export PKG_CONFIG_PATH=/usr/lib/arm-linux-gnueabihf/pkgconfig &amp;&amp; \ cmake -DCMAKE_BUILD_TYPE=Release \ -DOPENCV_CONFIG_INSTALL_PATH="cmake" \ -DCMAKE_TOOLCHAIN_FILE="../opencv/platforms/linux/arm-gnueabi.toolchain.cmake" \ -DWITH_IPP=OFF \ -DBUILD_TESTS=OFF \ -DBUILD_PERF_TESTS=OFF \ -DOPENCV_ENABLE_PKG_CONFIG=ON \ -DPYTHON2_INCLUDE_PATH="/usr/include/python2.7" \ -DPYTHON2_NUMPY_INCLUDE_DIRS="/usr/local/lib/python2.7/dist-packages/numpy/core/include" \ -DENABLE_NEON=ON \ -DCPU_BASELINE="NEON" ..</code> </pre> <br><p>  où </p><br><ul><li><p>  <code>CMAKE_TOOLCHAIN_FILE</code> - le chemin d'accès au fichier cmake qui définit le processus de compilation croisée (définit le compilateur souhaité, restreint l'utilisation des bibliothèques hôtes. </p><br></li><li><p>  <code>WITH_IPP=OFF</code> , - désactive les fortes dépendances. </p><br></li><li><p>  <code>BUILD_TESTS=OFF</code> , <code>BUILD_PERF_TESTS=OFF</code> , désactivez la version de test. </p><br></li><li><p>  <code>OPENCV_ENABLE_PKG_CONFIG=ON</code> - pour que pkg-config puisse trouver des dépendances comme GTK.  <code>PKG_CONFIG_PATH</code> est le chemin correct où <code>pkg-config</code> recherchera les bibliothèques. </p><br></li><li><p>  <code>PYTHON2_INCLUDE_PATH</code> , <code>PYTHON2_NUMPY_INCLUDE_DIRS</code> - chemins requis pour les wrappers de compilation croisée pour python2. </p><br></li><li><p>  <code>ENABLE_NEON=ON</code> , <code>CPU_BASELINE="NEON"</code> - active l'optimisation NEON. </p><br></li><li><p>  <code>OPENCV_CONFIG_INSTALL_PATH</code> - ajuste l'emplacement des fichiers dans le répertoire d' <code>install</code> . </p><br></li></ul><br><p>  La principale chose à laquelle vous devez faire attention après l'exécution de <code>cmake</code> est que tous les modules nécessaires sont assemblés (python2, par exemple): </p><br><pre> <code class="plaintext hljs">-- OpenCV modules: -- To be built: calib3d core dnn features2d flann gapi highgui imgcodecs imgproc java_bindings_generator ml objdetect photo python2 python_bindings_generator stitching ts video videoio -- Disabled: world -- Disabled by dependency: - -- Unavailable: java js python3 -- Applications: tests perf_tests apps -- Documentation: NO -- Non-free algorithms: NO</code> </pre> <br><p>  et les dépendances nécessaires, telles que GTK, ont été trouvées: </p><br><pre> <code class="plaintext hljs">-- GUI: -- GTK+: YES (ver 2.24.30) -- GThread : YES (ver 2.48.2) -- GtkGlExt: NO -- -- Video I/O: -- GStreamer: -- base: YES (ver 1.8.3) -- video: YES (ver 1.8.3) -- app: YES (ver 1.8.3) -- riff: YES (ver 1.8.3) -- pbutils: YES (ver 1.8.3) -- v4l/v4l2: linux/videodev2.h</code> </pre> <br><p>  Il ne reste plus qu'à appeler <code>make</code> , <code>make install</code> et attendre la fin de la build: </p><br><pre> <code class="plaintext hljs">Successfully built 4dae6b1a7d32</code> </pre> <br><p>  Utilisez cet <code>id</code> image pour baliser et créer un conteneur: </p><br><pre> <code class="plaintext hljs">docker tag 4dae6b1a7d32 ubuntu16_armhf_opencv:latest docker run ubuntu16_armhf_opencv</code> </pre> <br><p>  Et il suffit de pomper l'OpenCV assemblé hors du conteneur.  Tout d'abord, regardons l'identifiant du conteneur créé: </p><br><pre> <code class="plaintext hljs">$ docker container ls --all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e94667fe60d2 ubuntu16_armhf_opencv "/bin/bash" 6 seconds ago Exited (0) 5 seconds ago clever_yalow</code> </pre> <br><p>  Et copiez le répertoire d'installation avec OpenCV installé: </p><br><pre> <code class="plaintext hljs">docker cp e94667fe60d2:/opencv/build/install/ ./ mv install ocv_install</code> </pre> <br><h2 id="nakryvaem-na-stol">  Mettre la table </h2><br><p>  Copiez <code>ocv_install</code> sur le Raspberry Pi, définissez les chemins et essayez d'exécuter OpenCV à partir de python. </p><br><pre> <code class="plaintext hljs">export LD_LIBRARY_PATH=/path/to/ocv_install/lib/:$LD_LIBRARY_PATH export PYTHONPATH=/path/to/ocv_install/python/:$PYTHONPATH</code> </pre> <br><p>  Exécutez l'exemple de détection à l'aide du réseau neuronal MobileNet-SSD à partir de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://github.com/chuanqi305/MobileNet-SSD</a> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cv <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> cv.__file__ classes = [<span class="hljs-string"><span class="hljs-string">'backgroud'</span></span>, <span class="hljs-string"><span class="hljs-string">'aeroplane'</span></span>, <span class="hljs-string"><span class="hljs-string">'bicycle'</span></span>, <span class="hljs-string"><span class="hljs-string">'bird'</span></span>, <span class="hljs-string"><span class="hljs-string">'boat'</span></span>, <span class="hljs-string"><span class="hljs-string">'bottle'</span></span>, <span class="hljs-string"><span class="hljs-string">'bus'</span></span>, <span class="hljs-string"><span class="hljs-string">'car'</span></span>, <span class="hljs-string"><span class="hljs-string">'cat'</span></span>, <span class="hljs-string"><span class="hljs-string">'chair'</span></span>, <span class="hljs-string"><span class="hljs-string">'cow'</span></span>, <span class="hljs-string"><span class="hljs-string">'diningtable'</span></span>, <span class="hljs-string"><span class="hljs-string">'dog'</span></span>, <span class="hljs-string"><span class="hljs-string">'horse'</span></span>, <span class="hljs-string"><span class="hljs-string">'motorbike'</span></span>, <span class="hljs-string"><span class="hljs-string">'person'</span></span>, <span class="hljs-string"><span class="hljs-string">'pottedplant'</span></span>, <span class="hljs-string"><span class="hljs-string">'sheep'</span></span>, <span class="hljs-string"><span class="hljs-string">'sofa'</span></span>, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, <span class="hljs-string"><span class="hljs-string">'tvmonitor'</span></span>] cap = cv.VideoCapture(<span class="hljs-number"><span class="hljs-number">0</span></span>) net = cv.dnn.readNet(<span class="hljs-string"><span class="hljs-string">'MobileNetSSD_deploy.caffemodel'</span></span>, <span class="hljs-string"><span class="hljs-string">'MobileNetSSD_deploy.prototxt'</span></span>) cv.namedWindow(<span class="hljs-string"><span class="hljs-string">'Object detection'</span></span>, cv.WINDOW_NORMAL) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> cv.waitKey(<span class="hljs-number"><span class="hljs-number">1</span></span>) != <span class="hljs-number"><span class="hljs-number">27</span></span>: hasFrame, frame = cap.read() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> hasFrame: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> frame_height, frame_width = frame.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], frame.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] blob = cv.dnn.blobFromImage(frame, scalefactor=<span class="hljs-number"><span class="hljs-number">0.007843</span></span>, size=(<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>), mean=(<span class="hljs-number"><span class="hljs-number">127.5</span></span>, <span class="hljs-number"><span class="hljs-number">127.5</span></span>, <span class="hljs-number"><span class="hljs-number">127.5</span></span>)) net.setInput(blob) out = net.forward() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> detection <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> out.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>): classId = int(detection[<span class="hljs-number"><span class="hljs-number">1</span></span>]) confidence = float(detection[<span class="hljs-number"><span class="hljs-number">2</span></span>]) xmin = int(detection[<span class="hljs-number"><span class="hljs-number">3</span></span>] * frame_width) ymin = int(detection[<span class="hljs-number"><span class="hljs-number">4</span></span>] * frame_height) xmax = int(detection[<span class="hljs-number"><span class="hljs-number">5</span></span>] * frame_width) ymax = int(detection[<span class="hljs-number"><span class="hljs-number">6</span></span>] * frame_height) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> confidence &gt; <span class="hljs-number"><span class="hljs-number">0.5</span></span>: cv.rectangle(frame, (xmin, ymin), (xmax, ymax), color=(<span class="hljs-number"><span class="hljs-number">255</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>), thickness=<span class="hljs-number"><span class="hljs-number">3</span></span>) label = <span class="hljs-string"><span class="hljs-string">'%s: %.2f'</span></span> % (classes[classId], confidence) labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) ymin = max(ymin, labelSize[<span class="hljs-number"><span class="hljs-number">1</span></span>]) cv.rectangle(frame, (xmin, ymin - labelSize[<span class="hljs-number"><span class="hljs-number">1</span></span>]), (xmin + labelSize[<span class="hljs-number"><span class="hljs-number">0</span></span>], ymin + baseLine), (<span class="hljs-number"><span class="hljs-number">255</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>), cv.FILLED) cv.putText(frame, label, (xmin, ymin), cv.FONT_HERSHEY_SIMPLEX, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, (<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)) cv.imshow(<span class="hljs-string"><span class="hljs-string">'Object detection'</span></span>, frame)</code> </pre> <br><p><img src="https://habrastorage.org/webt/1h/sd/0m/1hsd0mmmse6gslxx169tw4lc2wu.png"></p><br><p>  C'est tout, un assemblage complet ne prend pas plus de 20 minutes.  Je joins la version finale du <code>Dockerfile</code> ci-dessous et en saisissant cette opportunité, je propose de répondre à une courte enquête de l'équipe OpenCV pour ceux qui ont déjà eu de l'expérience avec la bibliothèque: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://opencv.org/survey-2018.html</a> . </p><br><p>  Et oui, félicitations pour OpenCV 4!  Ce n'est pas seulement le travail d'une équipe distincte, c'est le travail de toute la communauté - OpenCV 4 vous. </p><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 USER root RUN dpkg --add-architecture armhf RUN sed -i -E 's|^deb ([^ ]+) (.*)$|deb [arch=amd64] \1 \2\ndeb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ \2|' /etc/apt/sources.list RUN apt-get update &amp;&amp; \ apt-get install -y --no-install-recommends \ cmake \ pkg-config \ crossbuild-essential-armhf \ git \ python-pip \ libgtk2.0-dev:armhf \ libpython-dev:armhf \ libgstreamer1.0-dev:armhf \ libgstreamer-plugins-base1.0-dev:armhf \ libgstreamer-plugins-good1.0-dev:armhf \ libgstreamer-plugins-bad1.0-dev:armhf RUN pip install numpy==1.12.1 RUN git clone https://github.com/opencv/opencv --depth 1 RUN mkdir opencv/build &amp;&amp; cd opencv/build &amp;&amp; \ export PKG_CONFIG_PATH=/usr/lib/arm-linux-gnueabihf/pkgconfig &amp;&amp; \ cmake -DCMAKE_BUILD_TYPE=Release \ -DOPENCV_CONFIG_INSTALL_PATH="cmake" \ -DCMAKE_TOOLCHAIN_FILE="../opencv/platforms/linux/arm-gnueabi.toolchain.cmake" \ -DWITH_IPP=OFF \ -DBUILD_TESTS=OFF \ -DBUILD_PERF_TESTS=OFF \ -DOPENCV_ENABLE_PKG_CONFIG=ON \ -DPYTHON2_INCLUDE_PATH="/usr/include/python2.7" \ -DPYTHON2_NUMPY_INCLUDE_DIRS="/usr/local/lib/python2.7/dist-packages/numpy/core/include" \ -DENABLE_NEON=ON \ -DCPU_BASELINE="NEON" .. &amp;&amp; make -j4 &amp;&amp; make install</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr430906/">https://habr.com/ru/post/fr430906/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr430892/index.html">La combinaison d'une approche multiplateforme et native dans le développement d'applications mobiles</a></li>
<li><a href="../fr430894/index.html">Situation: les marques dépensent de plus en plus d'argent pour la publicité dans les podcasts - nous comprenons pourquoi</a></li>
<li><a href="../fr430896/index.html">Linux Foundation a établi des fonds pour GraphQL et Ceph - pourquoi sont-ils nécessaires et à quoi s'attendre d'eux</a></li>
<li><a href="../fr430900/index.html">Le premier laser de l'histoire: ce que c'était</a></li>
<li><a href="../fr430902/index.html">Elfes en mémoire. Exécution d'ELF dans la RAM Linux</a></li>
<li><a href="../fr430908/index.html">Module de contrôle du convertisseur de puissance: développement et assemblage</a></li>
<li><a href="../fr430910/index.html">Bourse Fulbright: comment et pourquoi?</a></li>
<li><a href="../fr430912/index.html">Nous amenons un menteur à l'eau potable: un entretien n'est pas une relation de travail. Naturellement</a></li>
<li><a href="../fr430914/index.html">Analyse des prix du marché noir pour les données personnelles et percée</a></li>
<li><a href="../fr430916/index.html">Détecteur de dioxyde de carbone MT8057S. Non-révision avec la participation d'un non-émulateur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôÖüèº üìÄ üïµüèº Parallele Abfragen in PostgreSQL üíáüèø üë®üèº‚Äçüè≠ üëè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In modernen CPUs gibt es viele Kerne. Seit Jahren senden Anwendungen parallel Anfragen an Datenbanken. Wenn es sich um eine Berichtsabfrage f√ºr viele ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Parallele Abfragen in PostgreSQL</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/446706/"><p><img src="https://habrastorage.org/webt/kx/ht/dl/kxhtdlsry_f8p1jv2ve_1ziks7e.jpeg"></p><br><p>  In modernen CPUs gibt es viele Kerne.  Seit Jahren senden Anwendungen parallel Anfragen an Datenbanken.  Wenn es sich um eine Berichtsabfrage f√ºr viele Zeilen in einer Tabelle handelt, wird sie schneller ausgef√ºhrt, wenn mehrere CPUs verwendet werden. In PostgreSQL ist dies ab Version 9.6 m√∂glich. </p><br><p>  Die Implementierung der parallelen Abfragefunktion dauerte 3 Jahre. Ich musste den Code in verschiedenen Phasen der Abfrageausf√ºhrung neu schreiben.  PostgreSQL 9.6 f√ºhrte eine Infrastruktur ein, um den Code weiter zu verbessern.  In nachfolgenden Versionen werden andere Abfragetypen parallel ausgef√ºhrt. </p><a name="habracut"></a><br><h3 id="ogranicheniya">  Einschr√§nkungen </h3><br><ul><li>  Aktivieren Sie die parallele Ausf√ºhrung nicht, wenn bereits alle Kerne belegt sind. Andernfalls werden andere Anforderungen verlangsamt. </li><li>  Am wichtigsten ist, dass die parallele Verarbeitung mit hohen WORK_MEM-Werten viel Speicherplatz beansprucht - jeder Hash-Join oder jede Sortierung belegt Speicherplatz in der Menge von work_mem. </li><li>  OLTP-Anforderungen mit geringer Latenz k√∂nnen nicht durch parallele Ausf√ºhrung beschleunigt werden.  Wenn die Abfrage eine Zeile zur√ºckgibt, wird sie durch die parallele Verarbeitung nur verlangsamt. </li><li>  Entwickler verwenden gerne den TPC-H-Benchmark.  M√∂glicherweise haben Sie √§hnliche Abfragen f√ºr eine perfekte parallele Ausf√ºhrung. </li><li>  Parallel dazu werden nur SELECT-Abfragen ohne Pr√§dikatsperren ausgef√ºhrt. </li><li>  Manchmal ist eine korrekte Indizierung besser als ein paralleles sequentielles Scannen von Tabellen. </li><li>  Anhalten von Abfragen und Cursorn werden nicht unterst√ºtzt. </li><li>  Fensterfunktionen und Aggregatfunktionen geordneter Mengen sind nicht parallel. </li><li>  Sie gewinnen nichts an der E / A-Arbeitslast. </li><li>  Es gibt keine parallelen Sortieralgorithmen.  Sortierte Abfragen k√∂nnen jedoch in einigen Aspekten parallel ausgef√ºhrt werden. </li><li>  Ersetzen Sie CTE (WITH ...) durch ein verschachteltes SELECT, um die parallele Verarbeitung zu erm√∂glichen. </li><li> Daten-Wrapper von Drittanbietern unterst√ºtzen noch keine parallele Verarbeitung (aber sie k√∂nnten!) </li><li>  FULL OUTER JOIN wird nicht unterst√ºtzt. </li><li>  max_rows deaktiviert die Parallelverarbeitung. </li><li>  Wenn die Anforderung eine Funktion hat, die nicht als PARALLEL SAFE markiert ist, wird sie mit einem Thread ausgef√ºhrt. </li><li>  Die Transaktionsisolationsstufe SERIALIZABLE deaktiviert die Parallelverarbeitung. </li></ul><br><h3 id="testovaya-sreda">  Testumgebung </h3><br><p>  PostgreSQL-Entwickler haben versucht, die Antwortzeit von TPC-H-Benchmark-Abfragen zu reduzieren.  Laden Sie den Benchmark herunter und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">passen Sie ihn an PostgreSQL an</a> .  Dies ist eine inoffizielle Verwendung des TPC-H-Benchmarks - nicht zum Vergleichen von Datenbanken oder Hardware. </p><br><ol><li>  Laden Sie TPC-H_Tools_v2.17.3.zip (oder eine neuere Version) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von der</a> externen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TPC</a> herunter. </li><li>  Benennen Sie makefile.suite in Makefile um und √§ndern Sie es wie hier beschrieben: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/tvondra/pg_tpch</a> .  Kompilieren Sie den Code mit dem Befehl make. </li><li> Daten generieren: <code>./dbgen -s 10</code> erstellt eine 23-GB-Datenbank.  Dies reicht aus, um den Leistungsunterschied zwischen parallelen und nicht parallelen Abfragen zu erkennen. </li><li>  Konvertieren Sie <code>tbl</code> Dateien <code>csv  for</code> und <code>sed</code> in <code>csv  for</code> . </li><li>  Klonen Sie das Repository pg_tpch und kopieren Sie die <code>csv</code> nach <code>pg_tpch/dss/data</code> . </li><li>  Erstellen Sie Abfragen mit dem Befehl <code>qgen</code> . </li><li>  Laden Sie Daten mit dem Befehl <code>./tpch.sh</code> in die Datenbank <code>./tpch.sh</code> . </li></ol><br><h3 id="parallelnoe-posledovatelnoe-skanirovanie">  Paralleler sequentieller Scan </h3><br><p>  Es kann schneller sein, nicht wegen des parallelen Lesens, sondern weil Daten √ºber viele CPU-Kerne verteilt sind.  Auf modernen Betriebssystemen sind PostgreSQL-Datendateien gut zwischengespeichert.  Mit Read-Ahead k√∂nnen Sie mehr aus dem Speicher herausholen, als der PG-D√§mon anfordert.  Daher ist die Abfrageleistung nicht durch die Festplatten-E / A beschr√§nkt.  Es verbraucht CPU-Zyklen, um: </p><br><ul><li>  Lesen Sie die Zeilen einzeln von den Seiten der Tabelle. </li><li>  Vergleichen Sie Zeichenfolgenwerte und <code>WHERE</code> Klauseln. </li></ul><br><p>  Lassen Sie uns eine einfache <code>select</code> ausf√ºhren: </p><br><pre> <code class="plaintext hljs">tpch=# explain analyze select l_quantity as sum_qty from lineitem where l_shipdate &lt;= date '1998-12-01' - interval '105' day; QUERY PLAN -------------------------------------------------------------------------------------------------------------------------- Seq Scan on lineitem (cost=0.00..1964772.00 rows=58856235 width=5) (actual time=0.014..16951.669 rows=58839715 loops=1) Filter: (l_shipdate &lt;= '1998-08-18 00:00:00'::timestamp without time zone) Rows Removed by Filter: 1146337 Planning Time: 0.203 ms Execution Time: 19035.100 ms</code> </pre> <br><p>  Ein sequentieller Scan ergibt zu viele Zeilen ohne Aggregation, sodass die Anforderung von einem einzelnen CPU-Kern ausgef√ºhrt wird. </p><br><p>  Wenn Sie <code>SUM()</code> hinzuf√ºgen, k√∂nnen Sie sehen, dass zwei Workflows die Anforderung beschleunigen: </p><br><pre> <code class="plaintext hljs">explain analyze select sum(l_quantity) as sum_qty from lineitem where l_shipdate &lt;= date '1998-12-01' - interval '105' day; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=1589702.14..1589702.15 rows=1 width=32) (actual time=8553.365..8553.365 rows=1 loops=1) -&gt; Gather (cost=1589701.91..1589702.12 rows=2 width=32) (actual time=8553.241..8555.067 rows=3 loops=1) Workers Planned: 2 Workers Launched: 2 -&gt; Partial Aggregate (cost=1588701.91..1588701.92 rows=1 width=32) (actual time=8547.546..8547.546 rows=1 loops=3) -&gt; Parallel Seq Scan on lineitem (cost=0.00..1527393.33 rows=24523431 width=5) (actual time=0.038..5998.417 rows=19613238 loops=3) Filter: (l_shipdate &lt;= '1998-08-18 00:00:00'::timestamp without time zone) Rows Removed by Filter: 382112 Planning Time: 0.241 ms Execution Time: 8555.131 ms</code> </pre> <br><h3 id="parallelnaya-agregaciya">  Parallele Aggregation </h3><br><p>  Der Knoten Parallel Seq Scan erzeugt Zeichenfolgen f√ºr die teilweise Aggregation.  Der Partial Aggregate-Knoten schneidet diese Zeilen mit <code>SUM()</code> .  Am Ende wird der SUM-Z√§hler aus jedem Workflow vom Gather-Knoten erfasst. </p><br><p>  Das Endergebnis wird vom Knoten "Aggregat finalisieren" berechnet.  Wenn Sie √ºber eigene Aggregationsfunktionen verf√ºgen, m√ºssen Sie diese als "parallel sicher" markieren. </p><br><h3 id="kolichestvo-rabochih-processov">  Anzahl der Workflows </h3><br><p>  Die Anzahl der Workflows kann erh√∂ht werden, ohne den Server neu zu starten: </p><br><pre> <code class="plaintext hljs">alter system set max_parallel_workers_per_gather=4; select * from pg_reload_conf();</code> </pre> <br><p>  Jetzt sehen wir 4 Arbeiter in der Erkl√§rungsausgabe: </p><br><pre> <code class="plaintext hljs">tpch=# explain analyze select sum(l_quantity) as sum_qty from lineitem where l_shipdate &lt;= date '1998-12-01' - interval '105' day; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=1440213.58..1440213.59 rows=1 width=32) (actual time=5152.072..5152.072 rows=1 loops=1) -&gt; Gather (cost=1440213.15..1440213.56 rows=4 width=32) (actual time=5151.807..5153.900 rows=5 loops=1) Workers Planned: 4 Workers Launched: 4 -&gt; Partial Aggregate (cost=1439213.15..1439213.16 rows=1 width=32) (actual time=5147.238..5147.239 rows=1 loops=5) -&gt; Parallel Seq Scan on lineitem (cost=0.00..1402428.00 rows=14714059 width=5) (actual time=0.037..3601.882 rows=11767943 loops=5) Filter: (l_shipdate &lt;= '1998-08-18 00:00:00'::timestamp without time zone) Rows Removed by Filter: 229267 Planning Time: 0.218 ms Execution Time: 5153.967 ms</code> </pre> <br><p>  Was ist hier los?  Es gab 2-mal mehr Workflows und die Anfrage war nur 1,6599-mal schneller.  Die Berechnungen sind interessant.  Wir hatten 2 Arbeitsprozesse und 1 Leiter.  Nach der √Ñnderung wurde es 4 + 1. </p><br><p>  Unsere maximale Beschleunigung durch Parallelverarbeitung: 5/3 = 1,66 (6) mal. </p><br><h2 id="kak-eto-rabotaet">  Wie funktioniert es </h2><br><h3 id="processy">  Die Prozesse </h3><br><p>  Die Ausf√ºhrung einer Anfrage beginnt immer mit einem f√ºhrenden Prozess.  Der Leiter erledigt alles nicht parallel und ist Teil der Parallelverarbeitung.  Andere Prozesse, die dieselben Anforderungen ausf√ºhren, werden als Workflows bezeichnet.  Die parallele Verarbeitung verwendet eine Infrastruktur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dynamischer Hintergrundworkflows</a> (seit Version 9.4).  Da andere Teile von PostgreSQL Prozesse anstelle von Threads verwenden, kann eine Abfrage mit drei Workflows viermal schneller sein als die herk√∂mmliche Verarbeitung. </p><br><h3 id="vzaimodeystvie">  Interaktion </h3><br><p>  Workflows kommunizieren mit dem Leiter √ºber eine Nachrichtenwarteschlange (basierend auf dem gemeinsam genutzten Speicher).  Jeder Prozess hat 2 Warteschlangen: f√ºr Fehler und f√ºr Tupel. </p><br><h3 id="skolko-nuzhno-rabochih-processov">  Wie viele Arbeitsprozesse ben√∂tigen Sie? </h3><br><p>  Die Mindestgrenze wird durch den Parameter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>max_parallel_workers_per_gather</code></a> .  Anschlie√üend nimmt der Abfrage-Executor Workflows aus dem Pool, der durch den Parameter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>max_parallel_workers size</code></a> ist.  Die letzte Einschr√§nkung ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>max_worker_processes</code></a> , d. H. Die Gesamtzahl der Hintergrundprozesse. </p><br><p>  Wenn es nicht m√∂glich war, einen Workflow zuzuweisen, erfolgt die Verarbeitung in einem einzigen Prozess. </p><br><p>  Der Abfrageplaner kann Workflows abh√§ngig von der Gr√∂√üe der Tabelle oder des Index verk√ºrzen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>min_parallel_table_scan_size</code></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>min_parallel_index_scan_size</code></a> Parameter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>min_parallel_table_scan_size</code></a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>min_parallel_index_scan_size</code></a> . </p><br><pre> <code class="plaintext hljs">set min_parallel_table_scan_size='8MB' 8MB table =&gt; 1 worker 24MB table =&gt; 2 workers 72MB table =&gt; 3 workers x =&gt; log(x / min_parallel_table_scan_size) / log(3) + 1 worker</code> </pre> <br><p>  Jedes Mal, wenn eine Tabelle dreimal gr√∂√üer als <code>min_parallel_(index|table)_scan_size</code> , f√ºgt Postgres einen Workflow hinzu.  Die Anzahl der Arbeitsprozesse ist nicht kostenbasiert.  Zirkul√§re Abh√§ngigkeit erschwert komplexe Implementierungen.  Stattdessen verwendet der Scheduler einfache Regeln. </p><br><p>  In der Praxis sind diese Regeln nicht immer f√ºr die Produktion geeignet, daher k√∂nnen Sie die Anzahl der Workflows f√ºr eine bestimmte Tabelle √§ndern: ALTER TABLE ... SET ( <code>parallel_workers = N</code> ). </p><br><h3 id="pochemu-parallelnaya-obrabotka-ne-ispolzuetsya">  Warum wird die Parallelverarbeitung nicht verwendet? </h3><br><p>  Neben einer langen Liste von Einschr√§nkungen gibt es auch Kostenpr√ºfungen: </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>parallel_setup_cost</code></a> - verzichtet auf die parallele Verarbeitung von Kurzanforderungen.  Dieser Parameter sch√§tzt die Zeit f√ºr die Vorbereitung des Speichers, den Start des Prozesses und den anf√§nglichen Datenaustausch. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>parallel_tuple_cost</code></a> : Die Kommunikation zwischen einem Leiter und Arbeitnehmern kann proportional zur Anzahl der Tupel aus Arbeitsprozessen verz√∂gert werden.  Dieser Parameter berechnet die Datenaustauschkosten. </p><br><h3 id="soedineniya-vlozhennyh-ciklov--nested-loop-join">  Verschachtelte Schleife verbinden </h3><br><pre> <code class="plaintext hljs">PostgreSQL 9.6+      ‚Äî   . explain (costs off) select c_custkey, count(o_orderkey) from customer left outer join orders on c_custkey = o_custkey and o_comment not like '%special%deposits%' group by c_custkey; QUERY PLAN -------------------------------------------------------------------------------------- Finalize GroupAggregate Group Key: customer.c_custkey -&gt; Gather Merge Workers Planned: 4 -&gt; Partial GroupAggregate Group Key: customer.c_custkey -&gt; Nested Loop Left Join -&gt; Parallel Index Only Scan using customer_pkey on customer -&gt; Index Scan using idx_orders_custkey on orders Index Cond: (customer.c_custkey = o_custkey) Filter: ((o_comment)::text !~~ '%special%deposits%'::text)</code> </pre> <br><p>  Die Erfassung erfolgt in der letzten Phase, sodass die Linksverkn√ºpfung f√ºr verschachtelte Schleifen eine Paralleloperation ist.  Nur paralleler Index-Scan wurde nur in Version 10 angezeigt. Er funktioniert √§hnlich wie paralleles serielles Scannen.  Die Bedingung <code>c_custkey = o_custkey</code> liest eine Bestellung f√ºr jede <code>c_custkey = o_custkey</code> .  Es ist also nicht parallel. </p><br><h3 id="hesh-soedinenie--hash-join">  Hash Join - Hash Join </h3><br><p>  Jeder Workflow erstellt vor PostgreSQL 11 eine eigene Hash-Tabelle. Wenn mehr als vier dieser Prozesse vorhanden sind, wird die Leistung nicht verbessert.  In der neuen Version wird die Hash-Tabelle gemeinsam genutzt.  Jeder Workflow kann WORK_MEM verwenden, um eine Hash-Tabelle zu erstellen. </p><br><pre> <code class="plaintext hljs">select l_shipmode, sum(case when o_orderpriority = '1-URGENT' or o_orderpriority = '2-HIGH' then 1 else 0 end) as high_line_count, sum(case when o_orderpriority &lt;&gt; '1-URGENT' and o_orderpriority &lt;&gt; '2-HIGH' then 1 else 0 end) as low_line_count from orders, lineitem where o_orderkey = l_orderkey and l_shipmode in ('MAIL', 'AIR') and l_commitdate &lt; l_receiptdate and l_shipdate &lt; l_commitdate and l_receiptdate &gt;= date '1996-01-01' and l_receiptdate &lt; date '1996-01-01' + interval '1' year group by l_shipmode order by l_shipmode LIMIT 1; QUERY PLAN ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Limit (cost=1964755.66..1964961.44 rows=1 width=27) (actual time=7579.592..7922.997 rows=1 loops=1) -&gt; Finalize GroupAggregate (cost=1964755.66..1966196.11 rows=7 width=27) (actual time=7579.590..7579.591 rows=1 loops=1) Group Key: lineitem.l_shipmode -&gt; Gather Merge (cost=1964755.66..1966195.83 rows=28 width=27) (actual time=7559.593..7922.319 rows=6 loops=1) Workers Planned: 4 Workers Launched: 4 -&gt; Partial GroupAggregate (cost=1963755.61..1965192.44 rows=7 width=27) (actual time=7548.103..7564.592 rows=2 loops=5) Group Key: lineitem.l_shipmode -&gt; Sort (cost=1963755.61..1963935.20 rows=71838 width=27) (actual time=7530.280..7539.688 rows=62519 loops=5) Sort Key: lineitem.l_shipmode Sort Method: external merge Disk: 2304kB Worker 0: Sort Method: external merge Disk: 2064kB Worker 1: Sort Method: external merge Disk: 2384kB Worker 2: Sort Method: external merge Disk: 2264kB Worker 3: Sort Method: external merge Disk: 2336kB -&gt; Parallel Hash Join (cost=382571.01..1957960.99 rows=71838 width=27) (actual time=7036.917..7499.692 rows=62519 loops=5) Hash Cond: (lineitem.l_orderkey = orders.o_orderkey) -&gt; Parallel Seq Scan on lineitem (cost=0.00..1552386.40 rows=71838 width=19) (actual time=0.583..4901.063 rows=62519 loops=5) Filter: ((l_shipmode = ANY ('{MAIL,AIR}'::bpchar[])) AND (l_commitdate &lt; l_receiptdate) AND (l_shipdate &lt; l_commitdate) AND (l_receiptdate &gt;= '1996-01-01'::date) AND (l_receiptdate &lt; '1997-01-01 00:00:00'::timestamp without time zone)) Rows Removed by Filter: 11934691 -&gt; Parallel Hash (cost=313722.45..313722.45 rows=3750045 width=20) (actual time=2011.518..2011.518 rows=3000000 loops=5) Buckets: 65536 Batches: 256 Memory Usage: 3840kB -&gt; Parallel Seq Scan on orders (cost=0.00..313722.45 rows=3750045 width=20) (actual time=0.029..995.948 rows=3000000 loops=5) Planning Time: 0.977 ms Execution Time: 7923.770 ms</code> </pre> <br><p>  Die Anforderung 12 von TPC-H zeigt eine parallele Hash-Verbindung.  Jeder Workflow ist an der Erstellung einer gemeinsam genutzten Hash-Tabelle beteiligt. </p><br><h3 id="soedinenie-sliyaniem--merge-join">  Zusammenf√ºhren Verbinden </h3><br><p>  Ein Merge-Join ist nicht paralleler Natur.  Machen Sie sich keine Sorgen, wenn dies die letzte Stufe der Anforderung ist - sie kann weiterhin parallel ausgef√ºhrt werden. </p><br><pre> <code class="plaintext hljs">-- Query 2 from TPC-H explain (costs off) select s_acctbal, s_name, n_name, p_partkey, p_mfgr, s_address, s_phone, s_comment from part, supplier, partsupp, nation, region where p_partkey = ps_partkey and s_suppkey = ps_suppkey and p_size = 36 and p_type like '%BRASS' and s_nationkey = n_nationkey and n_regionkey = r_regionkey and r_name = 'AMERICA' and ps_supplycost = ( select min(ps_supplycost) from partsupp, supplier, nation, region where p_partkey = ps_partkey and s_suppkey = ps_suppkey and s_nationkey = n_nationkey and n_regionkey = r_regionkey and r_name = 'AMERICA' ) order by s_acctbal desc, n_name, s_name, p_partkey LIMIT 100; QUERY PLAN ---------------------------------------------------------------------------------------------------------- Limit -&gt; Sort Sort Key: supplier.s_acctbal DESC, nation.n_name, supplier.s_name, part.p_partkey -&gt; Merge Join Merge Cond: (part.p_partkey = partsupp.ps_partkey) Join Filter: (partsupp.ps_supplycost = (SubPlan 1)) -&gt; Gather Merge Workers Planned: 4 -&gt; Parallel Index Scan using &lt;strong&gt;part_pkey&lt;/strong&gt; on part Filter: (((p_type)::text ~~ '%BRASS'::text) AND (p_size = 36)) -&gt; Materialize -&gt; Sort Sort Key: partsupp.ps_partkey -&gt; Nested Loop -&gt; Nested Loop Join Filter: (nation.n_regionkey = region.r_regionkey) -&gt; Seq Scan on region Filter: (r_name = 'AMERICA'::bpchar) -&gt; Hash Join Hash Cond: (supplier.s_nationkey = nation.n_nationkey) -&gt; Seq Scan on supplier -&gt; Hash -&gt; Seq Scan on nation -&gt; Index Scan using idx_partsupp_suppkey on partsupp Index Cond: (ps_suppkey = supplier.s_suppkey) SubPlan 1 -&gt; Aggregate -&gt; Nested Loop Join Filter: (nation_1.n_regionkey = region_1.r_regionkey) -&gt; Seq Scan on region region_1 Filter: (r_name = 'AMERICA'::bpchar) -&gt; Nested Loop -&gt; Nested Loop -&gt; Index Scan using idx_partsupp_partkey on partsupp partsupp_1 Index Cond: (part.p_partkey = ps_partkey) -&gt; Index Scan using supplier_pkey on supplier supplier_1 Index Cond: (s_suppkey = partsupp_1.ps_suppkey) -&gt; Index Scan using nation_pkey on nation nation_1 Index Cond: (n_nationkey = supplier_1.s_nationkey)</code> </pre> <br><p>  Der Merge Join-Knoten befindet sich √ºber dem Gather Merge.  Die Zusammenf√ºhrung verwendet also keine Parallelverarbeitung.  Der Knoten Parallel Index Scan hilft jedoch weiterhin beim Segment <code>part_pkey</code> . </p><br><h3 id="soedinenie-po-sekciyam">  Abschnitt Verbindung </h3><br><p>  In PostgreSQL 11 ist die Partitionierung standardm√§√üig deaktiviert: Die Planung ist sehr teuer.  Tabellen mit √§hnlicher Partitionierung k√∂nnen abschnittsweise verbunden werden.  Postgres verwendet also kleinere Hash-Tabellen.  Jede Abschnittsverbindung kann parallel sein. </p><br><pre> <code class="plaintext hljs">tpch=# set enable_partitionwise_join=t; tpch=# explain (costs off) select * from prt1 t1, prt2 t2 where t1.a = t2.b and t1.b = 0 and t2.b between 0 and 10000; QUERY PLAN --------------------------------------------------- Append -&gt; Hash Join Hash Cond: (t2.b = t1.a) -&gt; Seq Scan on prt2_p1 t2 Filter: ((b &gt;= 0) AND (b &lt;= 10000)) -&gt; Hash -&gt; Seq Scan on prt1_p1 t1 Filter: (b = 0) -&gt; Hash Join Hash Cond: (t2_1.b = t1_1.a) -&gt; Seq Scan on prt2_p2 t2_1 Filter: ((b &gt;= 0) AND (b &lt;= 10000)) -&gt; Hash -&gt; Seq Scan on prt1_p2 t1_1 Filter: (b = 0) tpch=# set parallel_setup_cost = 1; tpch=# set parallel_tuple_cost = 0.01; tpch=# explain (costs off) select * from prt1 t1, prt2 t2 where t1.a = t2.b and t1.b = 0 and t2.b between 0 and 10000; QUERY PLAN ----------------------------------------------------------- Gather Workers Planned: 4 -&gt; Parallel Append -&gt; Parallel Hash Join Hash Cond: (t2_1.b = t1_1.a) -&gt; Parallel Seq Scan on prt2_p2 t2_1 Filter: ((b &gt;= 0) AND (b &lt;= 10000)) -&gt; Parallel Hash -&gt; Parallel Seq Scan on prt1_p2 t1_1 Filter: (b = 0) -&gt; Parallel Hash Join Hash Cond: (t2.b = t1.a) -&gt; Parallel Seq Scan on prt2_p1 t2 Filter: ((b &gt;= 0) AND (b &lt;= 10000)) -&gt; Parallel Hash -&gt; Parallel Seq Scan on prt1_p1 t1 Filter: (b = 0)</code> </pre> <br><p>  Hauptsache, die Verbindung in Abschnitten ist nur dann parallel, wenn diese Abschnitte gro√ü genug sind. </p><br><h3 id="parallelnoe-dopolnenie--parallel-append">  Paralleles Anh√§ngen - Paralleles Anh√§ngen </h3><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Paralleles Anh√§ngen</a> kann anstelle verschiedener Bl√∂cke in verschiedenen Workflows verwendet werden.  Dies geschieht normalerweise bei UNION ALL-Abfragen.  Der Nachteil ist weniger Parallelit√§t, da jeder Workflow nur eine Anforderung verarbeitet. </p><br><p>  Hier werden 2 Workflows ausgef√ºhrt, obwohl 4 enthalten sind. </p><br><pre> <code class="plaintext hljs">tpch=# explain (costs off) select sum(l_quantity) as sum_qty from lineitem where l_shipdate &lt;= date '1998-12-01' - interval '105' day union all select sum(l_quantity) as sum_qty from lineitem where l_shipdate &lt;= date '2000-12-01' - interval '105' day; QUERY PLAN ------------------------------------------------------------------------------------------------ Gather Workers Planned: 2 -&gt; Parallel Append -&gt; Aggregate -&gt; Seq Scan on lineitem Filter: (l_shipdate &lt;= '2000-08-18 00:00:00'::timestamp without time zone) -&gt; Aggregate -&gt; Seq Scan on lineitem lineitem_1 Filter: (l_shipdate &lt;= '1998-08-18 00:00:00'::timestamp without time zone)</code> </pre> <br><h3 id="samye-vazhnye-peremennye">  Die wichtigsten Variablen </h3><br><ul><li>  WORK_MEM begrenzt die Speichermenge f√ºr jeden Prozess, nicht nur f√ºr Anforderungen: work_mem-Verbindungsprozesse = viel Speicher. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>max_parallel_workers_per_gather</code></a> - wie viele Arbeitsprozesse das ausf√ºhrende Programm f√ºr die parallele Verarbeitung aus dem Plan verwendet. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>max_worker_processes</code></a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>max_worker_processes</code></a> die Gesamtzahl der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>max_worker_processes</code></a> an die Anzahl der CPU-Kerne auf dem Server an. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>max_parallel_workers</code></a> ist das gleiche, jedoch f√ºr parallele Workflows. </li></ul><br><h3 id="itogi">  Zusammenfassung </h3><br><p>  Ab Version 9.6 kann die parallele Verarbeitung die Leistung komplexer Abfragen, die viele Zeilen oder Indizes scannen, erheblich verbessern.  In PostgreSQL 10 ist die Parallelverarbeitung standardm√§√üig aktiviert.  Denken Sie daran, es auf Servern mit einer gro√üen OLTP-Arbeitslast zu deaktivieren.  Sequentielle Scans oder Index-Scans verbrauchen viele Ressourcen.  Wenn Sie nicht √ºber das gesamte Dataset berichten, k√∂nnen Abfragen effizienter gestaltet werden, indem Sie einfach die fehlenden Indizes hinzuf√ºgen oder die richtige Partitionierung verwenden. </p><br><h3 id="ssylki">  Referenzen </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.postgresql.org/docs/11/how-parallel-query-works.html</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.postgresql.org/docs/11/parallel-plans.html</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://ashutoshpg.blogspot.com/2017/12/partition-wise-joins-divide-and-conquer.html</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://rhaas.blogspot.com/2016/04/postgresql-96-with-parallel-query-vs.html</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://amitkapila16.blogspot.com/2015/11/parallel-sequential-scans-in-play.html</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://write-skew.blogspot.com/2018/01/parallel-hash-for-postgresql.html</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://rhaas.blogspot.com/2017/03/parallel-query-v2.html</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://blog.2ndquadrant.com/parallel-monster-benchmark/</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://blog.2ndquadrant.com/parallel-aggregate/</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.depesz.com/2018/02/12/waiting-for-postgresql-11-support-parallel-btree-index-builds/</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Parallelit√§t in PostgreSQL 11</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de446706/">https://habr.com/ru/post/de446706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de446690/index.html">Electrolux bringt intelligente Luftreiniger f√ºr die am st√§rksten verschmutzten St√§dte auf den Markt</a></li>
<li><a href="../de446694/index.html">JBOD modularer Speicher und Freiheitsgrade</a></li>
<li><a href="../de446696/index.html">Mythen √ºber 152-FZ, die f√ºr den Betreiber personenbezogener Daten teuer sein k√∂nnen</a></li>
<li><a href="../de446700/index.html">Lazydocker - GUI f√ºr Docker direkt im Terminal</a></li>
<li><a href="../de446702/index.html">Und noch ein komischer Kopfh√∂rer - zum Schlafen</a></li>
<li><a href="../de446708/index.html">Vergleich von Weltraumkommunikationssystemen</a></li>
<li><a href="../de446710/index.html">Vier echte Geschichten √ºber die Arbeit mit Microservice-Architektur - Bericht aus dem Backend United 3-Mitap: Kholodets</a></li>
<li><a href="../de446712/index.html">HTTPS ist nicht immer so sicher, wie es scheint. In 5,5% der HTTPS-Sites wurden Sicherheitsl√ºcken gefunden</a></li>
<li><a href="../de446714/index.html">Neugierige Perversionen aus der IT-Welt - 4</a></li>
<li><a href="../de446716/index.html">Doomsday Bewusstsein und Argument</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
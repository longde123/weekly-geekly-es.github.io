<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ½â€ğŸŒ¾ ğŸ™‹ğŸ¿ ğŸ‰ Grande entrevista com Cliff Click, o pai da compilaÃ§Ã£o JIT em Java â¬…ï¸ ğŸ‘¨ğŸ¾â€ğŸ³ ğŸ§ </title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cliff Click Ã© o CTO da Cratus (sensores de IoT para melhoria de processos), o fundador e co-fundador de vÃ¡rias startups (incluindo Rocket Realtime Sch...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Grande entrevista com Cliff Click, o pai da compilaÃ§Ã£o JIT em Java</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jugru/blog/458718/"><p><img src="https://habrastorage.org/getpro/habr/post_images/bed/01d/799/bed01d799e35f74331803908a94516bb.jpg" width="200" align="left">  <strong>Cliff Click</strong> Ã© o CTO da Cratus (sensores de IoT para melhoria de processos), o fundador e co-fundador de vÃ¡rias startups (incluindo Rocket Realtime School, Neurensic e H2O.ai) com vÃ¡rias saÃ­das bem-sucedidas.  Cliff escreveu seu primeiro compilador aos 15 anos (Pascal para TRS Z-80)!  Mais conhecido por trabalhar em C2 em Java (IR do Sea of â€‹â€‹Nodes).  Esse compilador mostrou ao mundo que o JIT pode produzir cÃ³digo de alta qualidade, que se tornou um dos fatores para tornar o Java uma das principais plataformas de software modernas.  Cliff entÃ£o ajudou a Azul Systems a construir um mainframe de 864 nÃºcleos com software Java puro que suportava pausas de GC em um heap de 500 gigabytes por 10 milissegundos.  Em geral, Cliff conseguiu trabalhar em todos os aspectos da JVM. <br clear="all"><br>  Este hubrapost Ã© uma Ã³tima entrevista com Cliff.  Falaremos sobre os seguintes tÃ³picos: </p><br><ul><li>  TransiÃ§Ã£o para otimizaÃ§Ãµes de baixo nÃ­vel </li><li>  Como fazer muita refatoraÃ§Ã£o </li><li>  Modelo de custo </li><li>  Treinamento de otimizaÃ§Ã£o de baixo nÃ­vel </li><li>  Estudos de caso de melhoria da produtividade </li><li>  Por que criar sua prÃ³pria linguagem de programaÃ§Ã£o </li><li>  Carreira de engenheiro de desempenho </li><li>  Desafios tÃ©cnicos </li><li>  Um pouco sobre alocaÃ§Ã£o de registros e multicore </li><li>  O maior desafio da vida </li></ul><br><p>  Entrevistas realizadas por: </p><br><ul><li>  <strong>Andrey Satarin,</strong> da Amazon Web Services.  Em sua carreira, ele conseguiu trabalhar em projetos completamente diferentes: ele testou o banco de dados NewSQL distribuÃ­do no Yandex, o sistema de detecÃ§Ã£o de nuvens da Kaspersky Lab, o jogo multiplayer no Mail.ru e o serviÃ§o de cÃ¡lculo de cÃ¢mbio no Deutsche Bank.  Ele estÃ¡ interessado em testar sistemas de back-end e distribuÃ­dos em larga escala. </li><li>  <strong>Vladimir Sitnikov,</strong> do Netcracker.  Por dez anos, ele trabalha no desempenho e na escalabilidade do NetCracker OS, um software usado pelas operadoras de telecomunicaÃ§Ãµes para automatizar os processos de gerenciamento de equipamentos de rede e de rede.  Ele estÃ¡ interessado em questÃµes de desempenho do Java e Oracle Database.  O autor de mais de uma dÃºzia de melhorias de desempenho no driver oficial do PostgreSQL JDBC. <a name="habracut"></a></li></ul><br><h1 id="perehod-k-nizkourovnevym-optimizaciyam">  TransiÃ§Ã£o para otimizaÃ§Ãµes de baixo nÃ­vel </h1><br><p>  <strong>Andrei</strong> : VocÃª Ã© uma pessoa famosa no mundo da compilaÃ§Ã£o JIT, em Java e trabalha com desempenho em geral, certo? </p><br><p>  <strong>Cliff</strong> : Ã‰ isso aÃ­! </p><br><p>  <strong>Andrew</strong> : Vamos comeÃ§ar com perguntas gerais sobre como trabalhar no desempenho.  O que vocÃª acha da escolha entre otimizaÃ§Ãµes de alto e baixo nÃ­vel, como o trabalho no nÃ­vel da CPU? </p><br><p> <strong>Cliff</strong> : Ã‰ fÃ¡cil.  O cÃ³digo mais rÃ¡pido Ã© aquele que nunca Ã© executado.  Portanto, vocÃª sempre precisa comeÃ§ar de alto nÃ­vel, trabalhar com algoritmos.  Uma melhor notaÃ§Ã£o O superarÃ¡ uma pior notaÃ§Ã£o O, a menos que algumas constantes razoavelmente grandes interfiram.  As coisas de baixo nÃ­vel sÃ£o as mais recentes.  Normalmente, se vocÃª otimizou o restante da pilha o suficiente, e ainda resta algo interessante - esse Ã© o nÃ­vel baixo.  Mas como comeÃ§ar de alto nÃ­vel?  Como descobrir que trabalho suficiente foi feito em alto nÃ­vel?  Bem ... de jeito nenhum.  NÃ£o hÃ¡ receitas prontas.  VocÃª precisa entender o problema, decidir o que farÃ¡ (para nÃ£o executar etapas desnecessÃ¡rias no futuro) e, em seguida, poderÃ¡ descobrir um criador de perfil que possa dizer algo Ãºtil.  Em algum momento, vocÃª mesmo entende que se livrou de coisas desnecessÃ¡rias e Ã© hora de ajustar o nÃ­vel mais baixo.  Este Ã© definitivamente um tipo especial de arte.  Muitas pessoas fazem coisas desnecessÃ¡rias, mas se movem tÃ£o rÃ¡pido que nÃ£o tÃªm tempo para se preocupar com o desempenho.  Mas isso Ã© contanto que a questÃ£o nÃ£o fique de pÃ©.  Normalmente, 99% das vezes ninguÃ©m se interessa pelo que faÃ§o, atÃ© o momento em que algo importante com o qual alguÃ©m se importa nÃ£o entra no caminho crÃ­tico.  E aqui todo mundo comeÃ§a a incomodÃ¡-lo com o tÃ³pico "por que nÃ£o funcionou perfeitamente desde o inÃ­cio".  Em geral, sempre hÃ¡ algo a melhorar no desempenho.  Mas 99% das vezes vocÃª nÃ£o tem leads!  VocÃª estÃ¡ apenas tentando conseguir algo para funcionar e, no processo, entende o que Ã© importante.  VocÃª nunca pode saber antecipadamente que esta peÃ§a precisa ser perfeita, portanto, em essÃªncia, vocÃª precisa ser perfeita em tudo.  E isso Ã© impossÃ­vel, e vocÃª nÃ£o faz isso.  Sempre hÃ¡ um monte de coisas para corrigir - e isso Ã© perfeitamente normal. </p><br><h1 id="kak-delat-bolshoy-refaktoring">  Como fazer muita refatoraÃ§Ã£o </h1><br><p>  <strong>Andrew</strong> : Como vocÃª trabalha no desempenho?  Esta Ã© uma questÃ£o transversal.  Por exemplo, vocÃª teve que trabalhar em problemas decorrentes da interseÃ§Ã£o de uma grande quantidade de funcionalidades existentes? </p><br><p>  <strong>Cliff</strong> : Eu tento evitar isso.  Se eu sei que o desempenho se tornarÃ¡ um problema, penso nisso antes de comeÃ§ar a codificar, especialmente em estruturas de dados.  Mas muitas vezes vocÃª descobre tudo isso muito mais tarde.  E entÃ£o vocÃª deve tomar medidas extremas e fazer o que chamo de "reescrever e conquistar": vocÃª precisa se agarrar a uma peÃ§a bastante grande.  Parte do cÃ³digo ainda precisarÃ¡ ser reescrita devido a problemas de desempenho ou outra coisa.  Qualquer que seja o motivo para reescrever o cÃ³digo, Ã© quase sempre melhor reescrever um pedaÃ§o maior do que um pedaÃ§o menor.  Nesse momento, todos comeÃ§am a tremer de medo: "Oh meu Deus, vocÃª nÃ£o pode tocar tanto cÃ³digo!"  Mas, de fato, essa abordagem quase sempre funciona muito melhor.  VocÃª precisa enfrentar imediatamente o grande problema, desenhar um grande cÃ­rculo ao redor e dizer: vou reescrever tudo dentro do cÃ­rculo.  A borda Ã© muito menor que o conteÃºdo dentro dela que precisa ser substituÃ­do.  E se esse delineamento de bordas permitir que vocÃª faÃ§a o trabalho perfeitamente - vocÃª tem suas mÃ£os desatadas, faÃ§a o que quiser.  Depois de entender o problema, o processo de reescrita Ã© muito mais fÃ¡cil, entÃ£o morda um pedaÃ§o grande! <br>  Ao mesmo tempo, quando vocÃª reescreve em grandes blocos e entende que o desempenho se tornarÃ¡ um problema, vocÃª pode imediatamente comeÃ§ar a se preocupar com isso.  Geralmente, isso se transforma em coisas simples como "nÃ£o copie dados, gerencie os dados da maneira mais simples possÃ­vel, diminua-os".  Em reescritas grandes, existem maneiras padrÃ£o de melhorar o desempenho.  E eles quase sempre giram em torno de dados. </p><br><h1 id="model-stoimosti">  Modelo de custo </h1><br><p>  <strong>Andrew</strong> : Em um dos podcasts, vocÃª falou sobre modelos de custo no contexto da produtividade.  VocÃª pode explicar o que isso significava? </p><br><p>  <strong>Cliff</strong> : Claro.  Nasci em uma Ã©poca em que o desempenho do processador era extremamente importante.  E esta era estÃ¡ voltando novamente - o destino nÃ£o Ã© isento de ironia.  Comecei a viver nos dias de mÃ¡quinas de oito bits; meu primeiro computador trabalhava com 256 bytes.  SÃ£o bytes.  Tudo era muito pequeno.  Tivemos que ler as instruÃ§Ãµes e, assim que comeÃ§amos a subir a pilha de linguagens de programaÃ§Ã£o, as linguagens assumiram cada vez mais.  Havia Assembler, depois Basic, C e C assumiram o trabalho com muitos detalhes, como alocaÃ§Ã£o de registro e seleÃ§Ã£o de instruÃ§Ãµes.  Mas tudo estava bem claro lÃ¡, e se eu fiz um ponteiro para uma instÃ¢ncia de uma variÃ¡vel, receberei carga, e o custo Ã© conhecido por esta instruÃ§Ã£o.  O ferro produz um nÃºmero conhecido de ciclos de mÃ¡quina, para que a velocidade de execuÃ§Ã£o de diferentes peÃ§as possa ser calculada simplesmente adicionando todas as instruÃ§Ãµes que vocÃª estava prestes a executar.  Cada comparaÃ§Ã£o / teste / filial / chamada / carga / loja pode ser dobrada e dizer: aqui vocÃª tem o prazo de entrega.  Ao melhorar o desempenho, vocÃª definitivamente prestarÃ¡ atenÃ§Ã£o em que tipo de nÃºmeros corresponde a pequenos ciclos quentes. <br>  Mas assim que vocÃª muda para Java, Python e coisas semelhantes, vocÃª se afasta rapidamente do ferro de baixo nÃ­vel.  Quanto custa uma chamada getter em Java?  Se o JIT no HotSpot estiver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">alinhado</a> corretamente, ele serÃ¡ carregado, mas, se nÃ£o, serÃ¡ uma chamada de funÃ§Ã£o.  Como o desafio estÃ¡ no hot loop, ele desfarÃ¡ todas as outras otimizaÃ§Ãµes nesse loop.  Portanto, o valor real serÃ¡ muito maior.  E vocÃª perde imediatamente a capacidade de examinar um pedaÃ§o de cÃ³digo e entender que devemos executÃ¡-lo em termos de velocidade do clock do processador, memÃ³ria usada e cache.  Tudo isso se torna interessante apenas se vocÃª realmente ficar bÃªbado com o desempenho. <br>  Agora, estamos em uma situaÃ§Ã£o em que a velocidade dos processadores quase nÃ£o cresce hÃ¡ uma dÃ©cada.  Os velhos tempos estÃ£o de volta!  VocÃª nÃ£o pode mais contar com um bom desempenho de thread Ãºnico.  Mas se vocÃª de repente se envolver em computaÃ§Ã£o paralela - Ã© incrivelmente difÃ­cil, todo mundo olha para vocÃª como James Bond.  A aceleraÃ§Ã£o dez vezes maior aqui geralmente ocorre naqueles lugares onde alguÃ©m dÃ¡ um tapa em algo.  A simultaneidade requer muito trabalho.  Para obter a mesma aceleraÃ§Ã£o dez vezes maior, vocÃª precisa entender o modelo de custo.  Quanto e quanto custa.  E para isso, vocÃª precisa entender como a lÃ­ngua se apoia no ferro subjacente. <br>  Martin Thompson tem uma Ã³tima palavra para seu blog <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Mechanical Sympathy</a> !  VocÃª precisa entender o que o ferro farÃ¡, como exatamente ele farÃ¡ e por que geralmente faz o que faz.  Com isso, Ã© bastante simples comeÃ§ar a ler as instruÃ§Ãµes e descobrir onde o tempo de execuÃ§Ã£o estÃ¡ fluindo.  Se vocÃª nÃ£o possui o treinamento adequado, estÃ¡ apenas procurando um gato preto em um quarto escuro.  Vejo constantemente pessoas otimizando o desempenho que nÃ£o tÃªm idÃ©ia do que diabos estÃ£o fazendo.  Eles sÃ£o muito atormentados e realmente nÃ£o vÃ£o a algum lugar.  E quando pego o mesmo pedaÃ§o de cÃ³digo, coloco alguns pequenos hacks lÃ¡ e acelero cinco ou dez vezes, eles sÃ£o assim: bem, Ã© tÃ£o desonesto que jÃ¡ sabÃ­amos que vocÃª Ã© melhor.  Isso Ã© incrÃ­vel.  Do que estou falando ... o modelo de custo Ã© sobre o cÃ³digo que vocÃª escreve e a velocidade com que ele funciona em mÃ©dia na imagem geral. </p><br><p>  <strong>Andrew</strong> : E como manter esse volume em sua cabeÃ§a?  Isso Ã© alcanÃ§ado com mais experiÃªncia ou?  Onde essa experiÃªncia Ã© adquirida? </p><br><p>  <strong>Cliff</strong> : Bem, minha experiÃªncia nÃ£o foi a maneira mais fÃ¡cil.  Programei no Assembler em um momento em que era possÃ­vel entender cada instruÃ§Ã£o individual.  Parece bobagem, mas desde entÃ£o, na minha cabeÃ§a, na minha memÃ³ria, o conjunto de instruÃ§Ãµes do Z80 permanece para sempre.  NÃ£o lembro os nomes das pessoas nem um minuto apÃ³s a conversa, mas lembro do cÃ³digo escrito hÃ¡ 40 anos.  EngraÃ§ado, parece uma sÃ­ndrome de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">idiota aprendido</a> ". </p><br><h1 id="obuchenie-nizkourovnevym-optimizaciyam">  Treinamento de otimizaÃ§Ã£o de baixo nÃ­vel </h1><br><p>  <strong>Andrew</strong> : Existe alguma maneira mais simples de entrar nos negÃ³cios? </p><br><p>  <strong>Cliff</strong> : Sim e nÃ£o.  O ferro que todos nÃ³s usamos nÃ£o mudou muito durante esse perÃ­odo.  Todo mundo usa x86, com exceÃ§Ã£o dos smartphones Arm.  Se vocÃª nÃ£o faz uma incorporaÃ§Ã£o hardcore, vocÃª tem a mesma coisa.  Ok, depois.  As instruÃ§Ãµes tambÃ©m nÃ£o mudaram por sÃ©culos.  VocÃª precisa escrever algo no Assembler.  Um pouco, mas o suficiente para comeÃ§ar a entender.  VocÃª estÃ¡ sorrindo, mas estou falando sÃ©rio.  Ã‰ necessÃ¡rio entender a correspondÃªncia da linguagem e do ferro.  Depois disso, vocÃª precisa ir, fazer xixi um pouco e fazer um pequeno compilador de brinquedos para uma linguagem de brinquedo pequeno.  "Brinquedo" significa que vocÃª precisa fazÃª-lo em um perÃ­odo de tempo razoÃ¡vel.  Pode ser super simples, mas deve gerar instruÃ§Ãµes.  O ato de gerar instruÃ§Ãµes nos permitirÃ¡ entender o modelo de custo da ponte entre o cÃ³digo de alto nÃ­vel no qual todos escrevem e o cÃ³digo de mÃ¡quina que roda no hardware.  Essa correspondÃªncia serÃ¡ queimada no cÃ©rebro no momento da escrita do compilador.  AtÃ© o compilador mais simples.  Depois disso, vocÃª pode comeÃ§ar a olhar para Java e o fato de que ela possui uma lacuna semÃ¢ntica mais profunda, e construir pontes sobre ela Ã© muito mais difÃ­cil.  Em Java, Ã© muito mais difÃ­cil entender se nossa ponte acabou sendo boa ou ruim, o que a farÃ¡ desmoronar e nÃ£o.  Mas vocÃª precisa de algum ponto de partida quando olhar para o cÃ³digo e entender: "Sim, esse getter deve alinhar sempre".  E acontece que Ã s vezes isso acontece, com exceÃ§Ã£o da situaÃ§Ã£o em que o mÃ©todo fica muito grande e o JIT comeÃ§a a alinhar tudo.  O desempenho desses locais pode ser previsto instantaneamente.  Normalmente, os getters funcionam bem, mas entÃ£o vocÃª olha para os grandes loops quentes e percebe que hÃ¡ algum tipo de chamada de funÃ§Ã£o flutuando que nÃ£o sabe o que estÃ¡ fazendo.  Esse Ã© o problema com o uso generalizado de getters, a razÃ£o pela qual eles nÃ£o estÃ£o alinhados - nÃ£o estÃ¡ claro se Ã© um getter.  Se vocÃª tem uma base de cÃ³digo super pequena, basta lembrar e dizer: isto Ã© um getter, mas este Ã© um setter.  Em uma grande base de cÃ³digo, cada funÃ§Ã£o vive sua prÃ³pria histÃ³ria, que, em geral, nÃ£o Ã© conhecida por ninguÃ©m.  O criador de perfil diz que perdemos 24% do nosso tempo em algum tipo de ciclo e, para entender o que esse ciclo faz, precisamos examinar cada funÃ§Ã£o interna.  Ã‰ impossÃ­vel entender isso sem estudar a funÃ§Ã£o, e isso atrasa seriamente o processo de compreensÃ£o.  Por isso que nÃ£o uso getters e setters, fui para um novo nÃ­vel! <br>  Onde obter o modelo de custo?  Bem, vocÃª pode ler algo, Ã© claro ... Mas acho que a melhor maneira Ã© agir.  FaÃ§a um pequeno compilador e essa serÃ¡ a melhor maneira de realizar o modelo de custo e ajustÃ¡-lo em sua prÃ³pria cabeÃ§a.  Um pequeno compilador que funcionaria na programaÃ§Ã£o de microondas Ã© uma tarefa para iniciantes.  Bem, quero dizer, se vocÃª jÃ¡ tem habilidades de programaÃ§Ã£o, elas devem ser suficientes.  Todas essas coisas sÃ£o como analisar uma string, que vocÃª terÃ¡ algum tipo de expressÃ£o algÃ©brica, retire as instruÃ§Ãµes de operaÃ§Ãµes matemÃ¡ticas de lÃ¡ na ordem correta, pegue os valores corretos dos registros - tudo isso Ã© feito de uma sÃ³ vez.  E enquanto vocÃª fizer isso, ele serÃ¡ impresso no cÃ©rebro.  Acho que todo mundo sabe o que o compilador faz.  E isso darÃ¡ uma compreensÃ£o do modelo de custo. </p><br><h1 id="prakticheskie-primery-uluchsheniya-proizvoditelnosti">  Estudos de caso de melhoria da produtividade </h1><br><p>  <strong>Andrew</strong> : Em que mais vale a pena prestar atenÃ§Ã£o ao trabalhar no desempenho? </p><br><p>  <strong>Penhasco</strong> : Estruturas de Dados.  A propÃ³sito, sim, eu nÃ£o leciono essas aulas hÃ¡ muito tempo ... <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Rocket School</a> .  Foi engraÃ§ado, mas foi preciso muito esforÃ§o para investir, e eu tambÃ©m tenho vida!  Ok.  Portanto, em uma das grandes e interessantes aulas "Onde estÃ¡ o seu desempenho", dei aos alunos um exemplo: dois gigabytes e meio de dados fintech foram lidos em um arquivo CSV e tivemos que calcular o nÃºmero de produtos vendidos.  Dados regulares do mercado de ticks.  Pacotes UDP convertidos em formato de texto desde os anos 70.  O Chicago Mercantile Exchange Ã© todo tipo de coisas como manteiga, milho, soja e coisas do gÃªnero.  Era necessÃ¡rio contar esses produtos, o nÃºmero de transaÃ§Ãµes, o volume mÃ©dio de movimentaÃ§Ã£o de fundos e mercadorias, etc.  Essa Ã© uma matemÃ¡tica de negociaÃ§Ã£o bastante simples: encontre o cÃ³digo do produto (sÃ£o de um a dois caracteres na tabela de hash), obtenha a quantia, adicione-a a um dos conjuntos de transaÃ§Ãµes, adicione volume, agregue valor e algumas outras coisas.  MatemÃ¡tica muito simples.  A implementaÃ§Ã£o do brinquedo foi bem direta: tudo estÃ¡ no arquivo, eu o leio e o movo, separando as entradas individuais nas seqÃ¼Ãªncias Java, procurando as coisas necessÃ¡rias nelas e dobrando-as de acordo com a matemÃ¡tica descrita acima.  E funciona a uma velocidade baixa. </p><br><p> Com essa abordagem, tudo fica Ã³bvio o que estÃ¡ acontecendo, e a computaÃ§Ã£o paralela nÃ£o ajudarÃ¡ aqui, certo?  Acontece que um aumento de produtividade em cinco vezes pode ser alcanÃ§ado apenas escolhendo as estruturas de dados corretas.  E isso surpreende atÃ© programadores experientes!  No meu caso particular, o truque era que vocÃª nÃ£o deveria fazer alocaÃ§Ãµes de memÃ³ria em um hot loop.  Bem, essa nÃ£o Ã© a verdade, mas em geral - vocÃª nÃ£o deve destacar "uma vez em X" quando X for grande o suficiente.  Quando X tem dois gigabytes e meio, vocÃª nÃ£o deve alocar nada "uma vez por letra", "uma vez por linha" ou "uma vez por campo", nada disso.  Isso Ã© exatamente o que leva tempo.  Como isso funciona?  Imagine fazer uma chamada para <code>String.split()</code> ou <code>BufferedReader.readLine()</code> .  <code>Readline</code> uma linha a partir de um conjunto de bytes vindos da rede, uma vez para cada linha, para cada uma das centenas de milhÃµes de linhas.  Eu pego essa linha, analiso e jogo fora.  Por que jogÃ¡-lo fora - bem, eu jÃ¡ o processei, isso Ã© tudo.  Portanto, para cada byte lido a partir desses 2.7G, dois caracteres serÃ£o escritos na linha, ou seja, 5.4G jÃ¡, e eu nÃ£o preciso mais deles, portanto eles serÃ£o descartados.  Se vocÃª observar a largura de banda da memÃ³ria, carregamos 2.7G, que passam pela memÃ³ria e pelo barramento de memÃ³ria no processador e, em seguida, o dobro Ã© enviado para a linha que estÃ¡ na memÃ³ria, e tudo isso se desfaz quando cada nova linha Ã© criada.  Mas preciso ler, o ferro lÃª, mesmo que tudo seja esfregado.  E tenho que anotÃ¡-la, porque criei a linha e os caches estavam cheios - o cache nÃ£o pode caber 2.7G.  No total, para cada byte lido, leio mais dois bytes e escrevo dois bytes adicionais e, como resultado, eles tÃªm uma proporÃ§Ã£o de 4: 1 - nessa proporÃ§Ã£o, perdemos a largura de banda da memÃ³ria.  E acontece que, se eu fizer <code>String.split()</code> , nÃ£o faÃ§o isso da Ãºltima vez, pode haver outros 6-7 campos dentro.  Portanto, o cÃ³digo de leitura clÃ¡ssico de CSV seguido pela anÃ¡lise de linha leva a uma perda de largura de banda de memÃ³ria na regiÃ£o de 14: 1 em relaÃ§Ã£o ao que vocÃª realmente gostaria de ter.  Se vocÃª jogar fora essas secreÃ§Ãµes, poderÃ¡ obter uma aceleraÃ§Ã£o de cinco vezes. </p><br><p>  E nÃ£o Ã© tÃ£o difÃ­cil assim.  Se vocÃª olhar o cÃ³digo do Ã¢ngulo certo, tudo se tornarÃ¡ bastante simples, assim que vocÃª perceber a essÃªncia do problema.  Nem pare de alocar memÃ³ria: o Ãºnico problema Ã© que vocÃª aloca algo e ele morre imediatamente e queima um recurso importante ao longo do caminho, que neste caso Ã© a largura de banda da memÃ³ria.  E tudo isso resulta em uma queda na produtividade.  No x86, vocÃª geralmente precisa gravar ativamente os relÃ³gios do processador e aqui vocÃª queimou toda a memÃ³ria muito antes.  SoluÃ§Ã£o - vocÃª precisa reduzir a quantidade de descarga. <br>  Outra parte do problema Ã© que, se vocÃª inicia o criador de perfil quando a faixa de memÃ³ria termina, exatamente no momento em que isso acontece, geralmente espera que o cache retorne, porque estÃ¡ cheio de lixo que vocÃª acabou de gerar com todas essas linhas.  Portanto, cada operaÃ§Ã£o de carregamento ou armazenamento fica lenta, porque leva a falhas no cache - o cache inteiro fica lento, aguardando a saÃ­da do lixo.  Portanto, o criador de perfil mostrarÃ¡ apenas ruÃ­dos aleatÃ³rios quentes manchados ao longo de todo o ciclo - nÃ£o haverÃ¡ instruÃ§Ãµes quentes ou locais separados no cÃ³digo.  Apenas o barulho.  E se vocÃª observar os ciclos do GC, todos serÃ£o de geraÃ§Ã£o jovem e super rÃ¡pidos - microssegundos ou milissegundos no mÃ¡ximo.  Afinal, toda essa memÃ³ria morre instantaneamente.  VocÃª aloca bilhÃµes de gigabytes e os corta, corta e corta novamente.  Tudo isso acontece muito rapidamente.  Acontece que existem ciclos de GC baratos, ruÃ­do quente ao longo de todo o ciclo, mas queremos obter uma aceleraÃ§Ã£o de 5x.  Naquele momento, algo deveria se fechar na minha cabeÃ§a e soar: "por que?"  O excesso de largura de banda nÃ£o aparece no depurador clÃ¡ssico; vocÃª precisa executar o depurador do contador de desempenho de hardware e vÃª-lo vocÃª mesmo e diretamente.  E nÃ£o diretamente, pode-se suspeitar desses trÃªs sintomas.  O terceiro sintoma Ã© quando vocÃª olha para o que destaca, pergunta ao criador de perfil e ele responde: "VocÃª fez um bilhÃ£o de linhas, mas o GC trabalhou de graÃ§a".  Assim que isso aconteceu, vocÃª percebe que gerou muitos objetos e queimou toda a faixa de memÃ³ria.  Existe uma maneira de descobrir isso, mas nÃ£o Ã© Ã³bvio. </p><br><p>  O problema estÃ¡ na estrutura de dados: a estrutura bÃ¡sica por trÃ¡s de tudo o que acontece, Ã© muito grande, Ã© 2,7G no disco, portanto, fazer uma cÃ³pia dessa coisa Ã© muito indesejÃ¡vel - eu quero carregÃ¡-lo do buffer de byte da rede imediatamente nos registradores para nÃ£o ler / gravar na string e para trÃ¡s cinco vezes.  Infelizmente, o Java por padrÃ£o nÃ£o fornece essa biblioteca como parte do JDK.  Mas isso Ã© trivial, certo?  De fato, essas sÃ£o de 5 a 10 linhas de cÃ³digo que serÃ£o usadas para implementar seu prÃ³prio carregador de linhas em buffer, que repete o comportamento da classe de linha, enquanto Ã© um invÃ³lucro em torno do buffer de bytes subjacente.  Como resultado, acontece que vocÃª trabalha quase como se estivesse com seqÃ¼Ãªncias de caracteres, mas, de fato, existem ponteiros movendo-se para o buffer, e bytes brutos nÃ£o sÃ£o copiados em nenhum lugar e, portanto, os mesmos buffers sÃ£o reutilizados, uma e outra vez, e o sistema operacional fica feliz em assumir coisas para as quais ele se destina, como buffer duplo oculto desses buffers de bytes, e vocÃª mesmo nÃ£o processa mais um fluxo interminÃ¡vel de dados desnecessÃ¡rios.  A propÃ³sito, vocÃª entende que, ao trabalhar com o GC, Ã© garantido que cada alocaÃ§Ã£o de memÃ³ria nÃ£o estarÃ¡ visÃ­vel para o processador apÃ³s o Ãºltimo ciclo do GC?  Portanto, tudo isso nÃ£o pode estar no cache e, em seguida, ocorre uma falha 100% garantida.  Ao trabalhar com um ponteiro em x86, subtrair um registro da memÃ³ria leva de 1 a 2 ciclos e, assim que isso acontece, vocÃª paga, paga, paga, porque a memÃ³ria estÃ¡ em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nove caches</a> - e esse Ã© o custo de alocar memÃ³ria.  Valor presente. </p><br><p>  Em outras palavras, as estruturas de dados sÃ£o as mais difÃ­ceis de mudar.  E assim que vocÃª perceber que escolheu a estrutura de dados incorreta que reduzirÃ¡ a produtividade no futuro, geralmente precisarÃ¡ aumentar o trabalho essencial, mas se nÃ£o o fizer, serÃ¡ pior.  Primeiro de tudo, vocÃª precisa pensar em estruturas de dados, isso Ã© importante.  O principal custo aqui estÃ¡ nas estruturas de dados em negrito que elas estÃ£o comeÃ§ando a usar no estilo "Copiei a estrutura de dados X na estrutura de dados Y, porque gosto mais da forma".  Mas a operaÃ§Ã£o de cÃ³pia (que parece barata) na verdade gasta uma faixa de memÃ³ria e aqui todo o tempo de execuÃ§Ã£o perdido Ã© enterrado.  Se eu tenho uma string gigante com JSON e quero transformÃ¡-la em uma Ã¡rvore DOM estruturada do POJO ou algo assim, a operaÃ§Ã£o de analisar essa string e criar um POJO e, em seguida, uma nova chamada para o POJO no futuro se tornarÃ¡ inÃºtil - nÃ£o Ã© algo barato.  Exceto se vocÃª for executado no POJO com muito mais frequÃªncia do que em uma linha.  Ao invÃ©s disso, vocÃª pode tentar descriptografar a string e retirar apenas o que precisa, sem transformÃ¡-la em nenhum POJO.  Se tudo isso acontecer no caminho a partir do qual o desempenho mÃ¡ximo Ã© necessÃ¡rio, nÃ£o hÃ¡ POJOs para vocÃª - vocÃª precisa de alguma forma cavar diretamente na linha. </p><br><h1 id="zachem-sozdavat-svoy-yazyk-programmirovaniya">  Por que criar sua prÃ³pria linguagem de programaÃ§Ã£o </h1><br><p>  <strong>Andrei</strong> : VocÃª disse que, para entender o modelo de custo, vocÃª precisa escrever sua prÃ³pria linguagem pequena ... </p><br><p>  <strong>Cliff</strong> : NÃ£o Ã© um idioma, mas um compilador.  Linguagem e compilador sÃ£o duas coisas diferentes.  A diferenÃ§a mais importante estÃ¡ na sua cabeÃ§a. </p><br><p>  <strong>Andrei</strong> : A propÃ³sito, atÃ© onde eu sei, vocÃª estÃ¡ experimentando criar seus prÃ³prios idiomas.  Porque </p><br><p>  <strong>Cliff</strong> : Porque eu posso!  Estou meio aposentado, entÃ£o este Ã© o meu hobby.  Eu tenho implementado os idiomas de outra pessoa a vida toda.  Eu tambÃ©m trabalhei duro no estilo de codificaÃ§Ã£o.  E tambÃ©m porque vejo problemas em outros idiomas.  Vejo que existem maneiras melhores de fazer as coisas habituais.  E eu os usaria.  Eu apenas me cansei de ver problemas em mim mesmo, em Java, em Python, em qualquer outra linguagem.  Estou escrevendo sobre React Native, JavaScript e Elm como um hobby, que nÃ£o Ã© sobre aposentadoria, mas sobre trabalho ativo.  E tambÃ©m escrevo em Python e, provavelmente, continuarei trabalhando no aprendizado de mÃ¡quina para back-ends Java.  Existem muitos idiomas populares e todos eles tÃªm recursos interessantes.  Todo mundo Ã© bom em algo prÃ³prio e vocÃª pode tentar juntar todos esses chips.  EntÃ£o, estudo as coisas que sÃ£o interessantes para mim, o comportamento da linguagem, tento criar uma semÃ¢ntica razoÃ¡vel.  E atÃ© agora estou fazendo isso!  No momento, estou lutando com a semÃ¢ntica da memÃ³ria, porque quero tÃª-la em C e Java e obter um modelo de memÃ³ria forte e semÃ¢ntica de memÃ³ria para cargas e lojas.  Ao mesmo tempo, tenha inferÃªncia de tipo automÃ¡tica como em Haskell.  Aqui, estou tentando misturar inferÃªncia do tipo Haskell com memÃ³ria trabalhando em C e Java.  Eu venho fazendo isso nos Ãºltimos 2-3 meses, por exemplo. </p><br><p>  <strong>Andrei</strong> : Se vocÃª estÃ¡ construindo uma linguagem que tem aspectos melhores de outras lÃ­nguas, vocÃª pensou que alguÃ©m faria o oposto: pegue suas idÃ©ias e use-as? </p><br><p>  <strong>Cliff</strong> : Ã‰ assim que novos idiomas aparecem!  Por que o Java Ã© semelhante ao C?  Como C tinha uma boa sintaxe que todos entendiam e o Java foi inspirado por essa sintaxe, adicionando seguranÃ§a de tipo, verificando os limites de matrizes, GC, e eles melhoraram algumas coisas de C. Eles adicionaram os seus.  Mas eles foram inspirados um pouco, certo?  Todo mundo fica sobre os ombros dos gigantes que vieram antes de vocÃª - Ã© assim que o progresso Ã© feito. </p><br><p>  <strong>Andrew</strong> : Pelo que entendi, seu idioma estarÃ¡ seguro em relaÃ§Ã£o ao uso de memÃ³ria.  VocÃª jÃ¡ pensou em implementar algo como um verificador de emprÃ©stimo da Rust?  VocÃª olhou para ele, como ele gostou de vocÃª? </p><br><p>  <strong>Cliff</strong> : Bem, eu tenho escrito C hÃ¡ muito tempo, com todos esses malloc e gratuitos, e gerencio manualmente a vida toda.  VocÃª sabe, 90-95% de um tempo de vida gerenciado manualmente tem a mesma estrutura.  E Ã© muito, muito doloroso fazer isso manualmente.  Eu gostaria que o compilador simplesmente dissesse o que estÃ¡ acontecendo lÃ¡ e o que vocÃª conseguiu com suas aÃ§Ãµes.  Para algumas coisas, um verificador de emprÃ©stimo faz isso imediatamente.  E ele deve exibir informaÃ§Ãµes automaticamente, entender tudo e nem me sobrecarregar para afirmar esse entendimento.  Ele deve fazer pelo menos uma anÃ¡lise de escape local e, apenas se nÃ£o for bem-sucedido, vocÃª precisarÃ¡ adicionar anotaÃ§Ãµes de tipo que descrevam o tempo de vida Ãºtil - e esse esquema Ã© muito mais complicado do que um verificador de emprÃ©stimos ou qualquer verificador de memÃ³ria existente.  A escolha entre "tudo estÃ¡ em ordem" e "eu nÃ£o entendi nada" - nÃ£o, deve haver algo melhor. <br>  Portanto, como uma pessoa que escreveu muito cÃ³digo C, acho que ter o suporte ao controle automÃ¡tico da vida Ãºtil Ã© a coisa mais importante.  E me cansei de quanto Java usa memÃ³ria e a principal reclamaÃ§Ã£o estÃ¡ no GC.  Ao alocar memÃ³ria em Java, vocÃª nÃ£o retornarÃ¡ a memÃ³ria local no Ãºltimo loop do GC.  Em idiomas com gerenciamento de memÃ³ria mais preciso, nÃ£o Ã© assim.  Se vocÃª ligar para malloc, receberÃ¡ imediatamente a memÃ³ria que geralmente era usada.  Geralmente, vocÃª faz algumas coisas temporÃ¡rias com a sua memÃ³ria e imediatamente a traz de volta.  E ela imediatamente retorna para a piscina de malloc, e o prÃ³ximo ciclo de malloc a puxa novamente.  Portanto, o uso real da memÃ³ria Ã© reduzido a um conjunto de objetos vivos em um determinado momento, alÃ©m de vazamentos.  E se tudo nÃ£o fluir de maneira indecente, a maior parte da memÃ³ria se instala em caches e no processador e funciona rapidamente.  Mas requer muito gerenciamento de memÃ³ria manual com malloc e free, chamado na ordem certa, no lugar certo.  O prÃ³prio Rust pode lidar com isso corretamente e, em vÃ¡rios casos, oferece desempenho ainda maior, jÃ¡ que o consumo de memÃ³ria Ã© reduzido apenas aos cÃ¡lculos atuais - em vez de esperar o prÃ³ximo ciclo do GC liberar memÃ³ria.  Como resultado, temos uma maneira muito interessante de melhorar o desempenho.  E bastante poderoso - no sentido em que fiz essas coisas ao processar dados para a fintech, e isso me permitiu acelerar cinco vezes.  Essa Ã© uma aceleraÃ§Ã£o bastante grande, especialmente em um mundo onde os processadores nÃ£o estÃ£o ficando mais rÃ¡pidos, e todos continuamos aguardando melhorias. </p><br><h1 id="karera-performans-inzhenera">  Carreira de engenheiro de desempenho </h1><br><p>  <strong>Andrew</strong> : Eu tambÃ©m gostaria de perguntar sobre a carreira como um todo.  VocÃª ficou famoso por trabalhar no JIT na HotSpot e depois se mudar para a Azul - e essa tambÃ©m Ã© uma empresa da JVM.  Mas eles jÃ¡ estavam envolvidos em mais ferro do que software.  E, de repente, mudou para Big Data e Machine Learning e, em seguida, para detecÃ§Ã£o de fraude.  Como isso aconteceu?  Essas sÃ£o Ã¡reas muito diferentes de desenvolvimento. </p><br><p>  <strong>Cliff</strong> : Estou programando hÃ¡ algum tempo e consegui fazer check-in em classes muito diferentes.  E quando as pessoas dizem: "Ah, vocÃª Ã© quem criou o JIT para Java!", Ã‰ sempre engraÃ§ado.  Mas antes disso, eu estava envolvido no clone PostScript - a linguagem que a Apple jÃ¡ usou para suas impressoras a laser.  E antes disso ele fez a implementaÃ§Ã£o da linguagem Forth.  Eu acho que o tema comum para mim Ã© o desenvolvimento de ferramentas.  Durante toda a minha vida, desenvolvi ferramentas com as quais outras pessoas escrevem seus programas legais.  Mas eu tambÃ©m estava envolvido no desenvolvimento de sistemas operacionais, drivers, depuradores no nÃ­vel do kernel, linguagens para o desenvolvimento do sistema operacional, que comeÃ§aram trivialmente, mas com o tempo tudo ficou complicado e complicado.  Mas o tÃ³pico principal, no entanto, Ã© o desenvolvimento de ferramentas.  Uma grande parte da vida passou entre Azul e Sun, e era sobre Java.  Mas quando iniciei o Big Data e o Machine Learning, coloquei meu chapÃ©u de novo e disse: â€œAh, e agora temos um problema nÃ£o trivial, e aqui muitas coisas interessantes e pessoas que fazem alguma coisaâ€ acontecem.  Este Ã© um Ã³timo caminho de desenvolvimento que vale a pena seguir. </p><br><p>  Sim, eu realmente gosto de computaÃ§Ã£o distribuÃ­da.  Meu primeiro trabalho foi como estudante em C, em um projeto de publicidade.  Esses computadores foram distribuÃ­dos em chips Zilog Z80, que coletavam dados para o reconhecimento Ã³ptico de texto analÃ³gico produzido por um analisador analÃ³gico real.  Foi um tÃ³pico legal e totalmente anormal.  Mas havia problemas, uma parte nÃ£o era reconhecida corretamente, por isso era necessÃ¡rio tirar uma foto e mostrÃ¡-la a uma pessoa que jÃ¡ lia com os olhos e informava o que foi dito lÃ¡; portanto, havia malabaristas de dados e esse trabalho tinha seu prÃ³prio idioma. .  Havia um back-end que lidava com tudo isso - funcionando paralelamente ao Z80 com terminais vt100 em execuÃ§Ã£o - um por pessoa, e havia um modelo de programaÃ§Ã£o paralelo no Z80.  Um determinado pedaÃ§o de memÃ³ria comum compartilhado por todos os Z80 dentro de uma configuraÃ§Ã£o em estrela;  o plano de fundo foi compartilhado e metade da RAM foi compartilhada na rede, e outra metade foi privada ou gasta em outra coisa.  Um sistema distribuÃ­do paralelo significativamente complexo com ... memÃ³ria semi-compartilhada compartilhada.  Quando foi ... JÃ¡ nÃ£o me lembro, em algum lugar em meados dos anos 80.  Faz muito tempo. <br>  Sim, assumiremos que 30 anos Ã© um longo tempo.As tarefas associadas Ã  computaÃ§Ã£o distribuÃ­da existem hÃ¡ muito tempo, as pessoas lutam hÃ¡ muito tempo com os clusters <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Beowulf</a> .  Esses clusters se parecem com ... Por exemplo: existe Ethernet e seu x86 rÃ¡pido estÃ¡ conectado a essa Ethernet, e agora vocÃª deseja obter memÃ³ria compartilhada falsa, porque ninguÃ©m pode lidar com a codificaÃ§Ã£o da computaÃ§Ã£o distribuÃ­da, era muito complicado e, portanto, era memÃ³ria compartilhada falsa com proteÃ§Ã£o pÃ¡ginas de memÃ³ria x86 e, se vocÃª escreveu nesta pÃ¡gina, dissemos aos outros processadores que, se tivessem acesso Ã  mesma memÃ³ria compartilhada, seria necessÃ¡rio fazer o download de vocÃª e, assim, algo como um protocolo de suporte Ã  coerÃªncia de cache seria exibido. e software para isso.  Conceito interessante.  O problema real, Ã© claro, era diferente.  Tudo isso funcionou, mas vocÃª rapidamente teve problemas de desempenho, porque ninguÃ©m entendeu os modelos de desempenho em um nÃ­vel suficientemente bom - quais padrÃµes de acesso Ã  memÃ³ria existem, como garantir que os nÃ³s nÃ£o faÃ§am ping um ao outro sem parar, e assim por diante. </p><br><p>  No H2O, eu vim com isso: os prÃ³prios desenvolvedores sÃ£o responsÃ¡veis â€‹â€‹por determinar onde o paralelismo estÃ¡ oculto e onde nÃ£o estÃ¡.  Eu vim com um modelo de codificaÃ§Ã£o que escrever cÃ³digo de alto desempenho era fÃ¡cil e simples.  Mas escrever cÃ³digo lento Ã© difÃ­cil, vai parecer ruim.  VocÃª precisa tentar seriamente escrever cÃ³digo lento, precisa usar mÃ©todos nÃ£o padrÃ£o.  O cÃ³digo de frenagem Ã© visÃ­vel de relance.  Como resultado, geralmente Ã© escrito um cÃ³digo que funciona rapidamente, mas vocÃª precisa descobrir o que fazer no caso de memÃ³ria compartilhada.  Tudo isso estÃ¡ vinculado a matrizes grandes e o comportamento Ã© semelhante a matrizes grandes nÃ£o volÃ¡teis em Java paralelo.  Quero dizer, imagine que dois threads gravem em um array paralelo, um deles ganha e o outro, respectivamente, perde, e vocÃª nÃ£o sabe qual deles Ã© quem.  Se nÃ£o forem volÃ¡teis, o pedido pode ser qualquer coisa - e realmente funciona bem.  As pessoas realmente se preocupam com a ordem das operaÃ§Ãµes, definem a volatilidade corretamente e esperam problemas de memÃ³ria nos lugares certos.  Caso contrÃ¡rio, eles simplesmente escreveriam o cÃ³digo na forma de ciclos de 1 a N, onde N Ã© alguns trilhÃµes, na esperanÃ§a de que todos os casos complexos se tornem paralelos automaticamente - e isso nÃ£o funciona lÃ¡.  Mas no H2O isso nÃ£o Ã© Java nem Scala, vocÃª pode considerÃ¡-lo â€œJava menos menosâ€, se desejar.  Esse Ã© um estilo de programaÃ§Ã£o muito compreensÃ­vel e Ã© semelhante Ã  escrita de cÃ³digo C ou Java simples com loops e matrizes.  Mas, ao mesmo tempo, a memÃ³ria pode ser processada com terabytes.  Eu ainda uso H2O.        â€“        ,     .    Big Data   ,    H2O. </p><br><h1 id="tehnicheskie-chellenzhi">   </h1><br><p> <strong></strong> :          ? </p><br><p> <strong></strong> :        ?   ,    â€“  . <br>    .    .    ,     ,     ,      ,  .     Sun,   ,    ,      ,       .      ,      ,   .     ,   C1,      ,    â€“      .                   ,         . ,         x86-    ,    ,      5-10    ,       50 . </p><br><p>  ,       ,        ,        ,    C.  , ,   - ,   C  .       C,       C    .   ,    ,     C,      - â€¦    ,      .     ,      .     ,           ,     .      ,    ,        5% .          -    â€“     ,         Â«     Â»,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> ,    .     :               ,  ,    .     .  ,     â€“    ,       .    ,        .       -  â€“    .   ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>   ,    (   ,   ),  ,     ,       .       ,    ,     ,      . </p><br><p>   , ,    ,  ,     ,       ,   .    ,   ,        ,   -   .     ,     ,     ,          .    ,      ,       ,  ,    . ,     :     ,           . ,   ,  - : ,   ,   -   ,    .      â€“  , ,    â€“   ! â€“     ,      .       Java. Java    ,         ,   ,   ,       â€“   ,       Â«  Â».           , ,   .            ,   Java  C    .    â€“      Java,       C   ,   ,    ,   . ,    â€“  ,      .    ,  .    ,    ,       .     :      . </p><br><h1 id="nemnogo-pro-allokaciyu-registrov-i-mnogoyadernost">       </h1><br><p> <strong></strong> :      -   . ,   ,  -   ,     ? </p><br><p> <strong></strong> : !   â€“  ,     NP-     - .        , ?   . , Ahead of Time  â€“    .     -  .   ,       ,       â€“   ,      !   â€“  ,   .       ,      ,    .    .   ?    ,       : ,   ,   -  !  -  ,             .   .     ,       ,       .      : - , - .        ,      ,   .  ,     ,  ,      ,     - .    !      ,     ,  ,   â€“        .    .      NP- . </p><br><p> <strong></strong> :  ,       â€“    . ,   ,   ,   ,     â€¦ </p><br><p> <strong></strong> :     .       Â«Â».       .   ,     .        â€“  ,  ,  ,             ( , ).   ,  -  .    ,   ,   ,        . , ,   .            ,     .   ,             ,     .     ,   ,   .          ,     ,  -       ,     â€“ .      â€“              . ,     GC,    , ,  ,     â€“  ,     .    ,  .              ,     ,         . ,   â€“    , ?       ,       . </p><br><p> <strong></strong> :     ,    ?   ? </p><br><p> <strong></strong> :  GPU ,   ! </p><br><p> <strong></strong> :   .      ? </p><br><p> <strong></strong> : ,   - Azul.     ,      .      .   H2O  ,       .     ,    GPU.            ? ,     Azul,  :   â€“  . </p><br><h1 id="samyy-bolshoy-chellenzh-v-zhizni">      </h1><br><p> <strong></strong> :    ? </p><br><p> <strong></strong> :      ,   â€¦     .   ,       . ,    ,    ,   ,             .   ,   ,    . ,   Java   C1  C2 â€“   . ,   Java        â€“   . ,      ,    â€“    .       â€¦   . - ,      Sun,  â€¦ ,   ,        .     ,           .  ,        .       â€¦        â€¦  ,        .   , , .       .     - ,      :   .  , , ,   ,  ,    ,     .   ,        .          .      ,    . Â«    ,   ,   Â».   : Â«!Â».    ,  , , : ,           . </p><br><p>  â€“    ,    ,       ,     .      .      ,        ,            ,  ,    .  ,      Java JIT,  C2.       ,  â€“         .       ,   â€“   !    .  ,   ,  ,     ,    ,       ,    .        .    .        ,   . ,      ,       ,      ,        :      ,     ,     .   ,           â€“      .       ,     ,      -   .     : Â«     ?Â».  ,          .      ,     ,      : ,    ,        â€“     ?       ,  .  ,   ,  ,  ,         ,    ,     - . </p><br><p> <strong></strong> :         ,    -.     ? </p><br><p> <strong></strong> : ,     ,       .      â€“   .      . ,    .        .          .   :    ,   ,   - â€“          .      .  ,       ,      â€“   ,       . ,    ,    ,          ,  -  ,        .       ,       .       ,       ,     - .   ,    ,     â€“   ,  . <br>       ,    .   ,    â€“   ,   ,    .  ,   .     ,       â€“   .     ,       .   ,     ,     Â«  Â»,      ,  â€“   ,   ,       ,     ,        .     ,  ,    Â«  Â». </p><br><p>       .   .   - ,      ,        Â«Â»:    ,    â€“ .  â€“     .         ,  ,    . Â«,     -,     ,    Â».       ,     : ,  .  ,     ,     .  .   â€“ ,     . , ?  ,     ?    ? ,          ?        .       ,  .    â€“   .     .  ,     .     â€“    â€“  ,        .        ,   Â« Â»   .    : Â«--Â»,  : Â«, !Â»   .   .   ,       ,   ,    ,        .     ,      .        ,         .    ,         â€“      ,    .    â€“   ,            .      ,    ,   ,   . </p><br><p> ,           â€“   , .          ,        , .    ,   .         ,    ,    ,    ,      .        ,      ,       . ,       ,      ,          ,      .          .     ,      ,     ,      .    ,     ,    ,        ,    .      , ,    ,   .   ,       â€“  , ,    ,      .     ,     . </p><br><p> <strong></strong> :  â€¦ . ,          .          .   Hydra! </p><br><blockquote>         Hydra 2019,   11-12  2019   -.     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Â«The Azul Hardware Transactional Memory experienceÂ»</a> .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a> . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt458718/">https://habr.com/ru/post/pt458718/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt458704/index.html">ImplementaÃ§Ã£o de um sistema DLP no exemplo do varejo</a></li>
<li><a href="../pt458706/index.html">Os Gopniks estÃ£o agora em mercados estrangeiros, ou "Por que Ã© tÃ£o difÃ­cil encontrar um programador normal?"</a></li>
<li><a href="../pt458708/index.html">Deseja <s> perder peso </s> para aprender TI por conta prÃ³pria? Me pergunte como</a></li>
<li><a href="../pt458710/index.html">Ofuscador de espaÃ§o em branco para PHP</a></li>
<li><a href="../pt458716/index.html">Primeira olhada no Delta Amplon RT UPS</a></li>
<li><a href="../pt458720/index.html">A escola de programadores hh.ru, pela dÃ©cima vez, abre um conjunto de especialistas em TI</a></li>
<li><a href="../pt458724/index.html">Redes neurais e aprendizado profundo, capÃ­tulo 3, parte 1: melhorando a maneira como as redes neurais sÃ£o treinadas</a></li>
<li><a href="../pt458726/index.html">Habr Special // Podcast com autor de Invasion. Uma Breve HistÃ³ria dos Hackers Russos</a></li>
<li><a href="../pt458728/index.html">O que sÃ£o bicicletas elÃ©tricas (revisÃ£o em grupo de cinco modelos de dois fabricantes), parte 2</a></li>
<li><a href="../pt458730/index.html">Combatendo a complexidade no desenvolvimento de software</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
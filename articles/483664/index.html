<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüíª üóØÔ∏è üßñüèΩ API funcional de Keras en TensorFlow ‚òÄÔ∏è üç∑ üïû</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Keras tiene dos API para construir r√°pidamente arquitecturas de redes neuronales secuenciales y funcionales. Si el primero le permite construir solo a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>API funcional de Keras en TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483664/"><img src="https://habrastorage.org/webt/w1/zr/n8/w1zrn8ydafoxahso_ig7vx1stfg.png"><br><br>  Keras tiene dos API para construir r√°pidamente arquitecturas de redes neuronales secuenciales y funcionales.  Si el primero le permite construir solo arquitecturas secuenciales de redes neuronales, entonces, utilizando la API funcional, puede definir una red neuronal en forma de un gr√°fico ac√≠clico dirigido arbitrario, que ofrece muchas m√°s oportunidades para construir modelos complejos.  Este art√≠culo es una traducci√≥n de la Gu√≠a de funciones de API funcional del sitio web de TensorFlow. <br><a name="habracut"></a><br><h2>  Introduccion </h2><br>  La API funcional le permite crear modelos de manera m√°s flexible que la API secuencial; puede procesar modelos con topolog√≠a no lineal, modelos con capas comunes y modelos con m√∫ltiples entradas o salidas. <br><br>  Se basa en el hecho de que el modelo de aprendizaje profundo suele ser un gr√°fico ac√≠clico dirigido (DAG) de capas <br><br>  API funcional es un conjunto de herramientas para <b>trazar capas</b> . <br><br>  Considere el siguiente modelo: <br><br><blockquote>  (entrada: vector de 784 dimensiones) <br>  ‚Üß <br>  [Capa densa (64 elementos, activaci√≥n de relu)] <br>  ‚Üß <br>  [Capa densa (64 elementos, activaci√≥n de relu)] <br>  ‚Üß <br>  [Capa densa (10 elementos, activaci√≥n de softmax)] <br>  ‚Üß <br>  (salida: distribuci√≥n de probabilidad en 10 clases) </blockquote>  Este es un gr√°fico simple de 3 capas. <br><br>  Para construir este modelo utilizando la API funcional, debe comenzar creando un nodo de entrada: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,))</code> </pre> <br>  Aqu√≠ simplemente indicamos la dimensi√≥n de nuestros datos: vectores de 784 dimensiones.  Tenga en cuenta que la cantidad de datos siempre se omite, indicamos solo la dimensi√≥n de cada elemento.  Para ingresar el tama√±o destinado a las im√°genes `(32, 32, 3)`, usar√≠amos: <br><br><pre> <code class="python hljs">img_inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>))</code> </pre> <br>  Lo que devuelve las <code>inputs</code> contiene informaci√≥n sobre el tama√±o y el tipo de datos que planea transferir a su modelo: <br><br><pre> <code class="python hljs">inputs.shape</code> </pre> <br><pre> <code class="python hljs">TensorShape([<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>])</code> </pre> <br><pre> <code class="python hljs">inputs.dtype</code> </pre> <br><pre> <code class="python hljs">tf.float32</code> </pre> <br>  Puede crear un nuevo nodo en el gr√°fico de capa llamando a la capa en este objeto de entrada: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers dense = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) x = dense(inputs)</code> </pre> <br>  "Llamar a una capa" es similar a dibujar una flecha desde la "entrada" a la capa que creamos.  "Pasamos" la entrada a la capa <code>dense</code> , y obtenemos <code>x</code> . <br><br>  Agreguemos algunas capas m√°s a nuestro gr√°fico de capas: <br><br><pre> <code class="python hljs">x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x)</code> </pre> <br>  Ahora podemos crear un <code>Model</code> especificando sus entradas y salidas en el gr√°fico de capas: <br><br><pre> <code class="python hljs">model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br>  Veamos nuevamente el proceso completo de definici√≥n del modelo: <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs=inputs, outputs=outputs, name=<span class="hljs-string"><span class="hljs-string">'mnist_model'</span></span>)</code> </pre> <br>  Veamos c√≥mo se ve el resumen del modelo: <br><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><pre> <code class="python hljs">Model: <span class="hljs-string"><span class="hljs-string">"mnist_model"</span></span> _________________________________________________________________ Layer (type) Output Shape Param <span class="hljs-comment"><span class="hljs-comment"># ================================================================= img (InputLayer) [(None, 784)] 0 _________________________________________________________________ dense_3 (Dense) (None, 64) 50240 _________________________________________________________________ dense_4 (Dense) (None, 64) 4160 _________________________________________________________________ dense_5 (Dense) (None, 10) 650 ================================================================= Total params: 55,050 Trainable params: 55,050 Non-trainable params: 0 _________________________________________________________________</span></span></code> </pre> <br>  Tambi√©n podemos dibujar el modelo como un gr√°fico: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model.png'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/oq/4o/vl/oq4ovlxewr3hxczaldchmbeyfua.png" alt="imagen"><br><br>  Y opcionalmente deriva las dimensiones de la entrada y salida de cada capa en el gr√°fico construido: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model_with_shape_info.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fn/rm/hc/fnrmhcqknnsjdcgmqp9w6dpong8.png" alt="imagen"><br><br>  Esta imagen y el c√≥digo que escribimos son id√©nticos.  En la versi√≥n de c√≥digo, las flechas de enlace simplemente se reemplazan por operaciones de llamada. <br><br>  El "gr√°fico de capas" es una imagen mental muy intuitiva para el modelo de aprendizaje profundo, y la API funcional es una forma de crear modelos que reflejan de cerca esta imagen mental. <br><br><h2>  Formaci√≥n, evaluaci√≥n y conclusi√≥n. </h2><br>  Aprender, evaluar y derivar el trabajo para modelos creados con la API funcional al igual que en los modelos secuenciales. <br><br>  Considere una demostraci√≥n r√°pida. <br><br>  Aqu√≠ cargamos el conjunto de datos de imagen MNIST, lo convertimos en vectores, entrenamos el modelo en los datos (mientras monitoreamos la calidad del trabajo en la muestra de prueba) y finalmente evaluamos nuestro modelo en los datos de prueba: <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = x_train.reshape(<span class="hljs-number"><span class="hljs-number">60000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> x_test = x_test.reshape(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> model.compile(loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, optimizer=keras.optimizers.RMSprop(), metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) history = model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) test_scores = model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Test loss:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(<span class="hljs-string"><span class="hljs-string">'Test accuracy:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h2>  Guardar y serializar </h2><br>  El almacenamiento y la serializaci√≥n para modelos creados con la API funcional funciona exactamente igual que para los modelos secuenciales. <br><br>  La forma est√°ndar de guardar un modelo funcional es llamar a <code>model.save(</code> ), que le permite guardar todo el modelo en un archivo. <br><br>  Posteriormente puede restaurar el mismo modelo desde este archivo, incluso si ya no tiene acceso al c√≥digo que cre√≥ el modelo. <br><br>  Este archivo incluye: <br><br><ul><li>  Arquitectura modelo </li><li>  Pesas modelo (que se obtuvieron durante el entrenamiento) </li><li>  Configuraci√≥n de entrenamiento del modelo (lo que pas√≥ en la <code>compile</code> ) </li><li>  El optimizador y su estado, si lo fuera (esto le permite reanudar el entrenamiento desde donde lo dej√≥) </li></ul><br><pre> <code class="python hljs">model.save(<span class="hljs-string"><span class="hljs-string">'path_to_my_model.h5'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> model <span class="hljs-comment"><span class="hljs-comment"># Recreate the exact same model purely from the file: model = keras.models.load_model('path_to_my_model.h5')</span></span></code> </pre><br><h2>  Usando el mismo gr√°fico de capa para definir m√∫ltiples modelos </h2><br>  En la API funcional, los modelos se crean especificando datos de entrada y salida en un gr√°fico de capa.  Esto significa que se puede usar un gr√°fico de una sola capa para generar varios modelos. <br><br>  En el siguiente ejemplo, usamos la misma pila de capas para crear dos modelos: <br>  un modelo de <code> (encoder)</code> que convierte im√°genes de entrada en vectores de 16 dimensiones, y un modelo de <code> (autoencoder)</code> extremo a extremo para entrenamiento. <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(encoder_output) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) autoencoder = keras.Model(encoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre><br>  Tenga en cuenta que hacemos que la arquitectura de decodificaci√≥n sea estrictamente sim√©trica a la arquitectura de codificaci√≥n, de modo que obtengamos la dimensi√≥n de los datos de salida igual que los datos de entrada <code>(28, 28, 1)</code> .  La capa <code>Conv2D</code> est√° <code>Conv2D</code> a la capa <code>Conv2D</code> , y la capa <code>MaxPooling2D</code> ser√° la parte posterior a la capa <code>MaxPooling2D</code> . <br><br><h2>  Los modelos se pueden llamar como capas </h2><br>  Puede usar cualquier modelo como si fuera una capa, llam√°ndolo en <code>Input</code> o en la salida de otra capa. <br><br>  Tenga en cuenta que al invocar un modelo, no solo reutiliza su arquitectura, sino que tambi√©n reutiliza sus pesos.  Vamos a verlo en acci√≥n.  Aqu√≠ hay otro vistazo a un ejemplo de codificador autom√°tico cuando se crea un modelo de codificador, un modelo de decodificador y se conectan en dos llamadas para obtener un modelo de codificador autom√°tico: <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'original_img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() decoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">16</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'encoded_img'</span></span>) x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(decoder_input) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder = keras.Model(decoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'decoder'</span></span>) decoder.summary() autoencoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) encoded_img = encoder(autoencoder_input) decoded_img = decoder(encoded_img) autoencoder = keras.Model(autoencoder_input, decoded_img, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre> <br>  Como puede ver, un modelo puede estar anidado: un modelo puede contener un submodelo (ya que el modelo puede considerarse como una capa). <br><br>  Un caso de uso com√∫n para los modelos de anidamiento es el <i>ensamblaje</i> . <br><br>  Como ejemplo, aqu√≠ se explica c√≥mo combinar un conjunto de modelos en un modelo que promedia sus pron√≥sticos: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> keras.Model(inputs, outputs) model1 = get_model() model2 = get_model() model3 = get_model() inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) y1 = model1(inputs) y2 = model2(inputs) y3 = model3(inputs) outputs = layers.average([y1, y2, y3]) ensemble_model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br><br><h2>  Manipulaci√≥n de topolog√≠as gr√°ficas complejas. </h2><br><h3>  Modelos con m√∫ltiples entradas y salidas. </h3><br>  La API funcional simplifica la manipulaci√≥n de m√∫ltiples entradas y salidas.  Esto no se puede hacer con la API secuencial. <br><br>  Aqu√≠ hay un ejemplo simple. <br><br>  Suponga que est√° creando un sistema para clasificar las aplicaciones de los clientes por prioridad y enviarlas al departamento correcto. <br><br>  Su modelo tendr√° 3 entradas: <br><br><ul><li>  Encabezado de aplicaci√≥n (entrada de texto) </li><li>  Contenido de texto de la aplicaci√≥n (entrada de texto) </li><li>  Cualquier etiqueta agregada por el usuario (entrada categ√≥rica) </li></ul><br>  El modelo tendr√° 2 salidas: <br><br><ul><li>  Puntuaci√≥n de prioridad entre 0 y 1 (salida sigmoidea escalar) </li><li>  El departamento que debe procesar la solicitud (salida softmax con respecto a muchos departamentos) </li></ul><br>  Construyamos un modelo en varias l√≠neas usando la API funcional. <br><br><pre> <code class="python hljs">num_tags = <span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-comment"><span class="hljs-comment">#     num_words = 10000 #         num_departments = 4 #     title_input = keras.Input(shape=(None,), name='title') #      body_input = keras.Input(shape=(None,), name='body') #      tags_input = keras.Input(shape=(num_tags,), name='tags') #    `num_tags` #      64-  title_features = layers.Embedding(num_words, 64)(title_input) #      64-  body_features = layers.Embedding(num_words, 64)(body_input) #        128-  title_features = layers.LSTM(128)(title_features) #        32-  body_features = layers.LSTM(32)(body_features) #          x = layers.concatenate([title_features, body_features, tags_input]) #         priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x) #       department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x) #   ,     model = keras.Model(inputs=[title_input, body_input, tags_input], outputs=[priority_pred, department_pred])</span></span></code> </pre> <br>  Dibujemos un gr√°fico modelo: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'multi_input_and_output_model.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gc/hk/uw/gchkuwc_zgefnaf4tx0ercck8bc.png"><br><br>  Al compilar este modelo, podemos asignar diferentes funciones de p√©rdida a cada salida. <br><br>  Incluso puede asignar diferentes pesos a cada funci√≥n de p√©rdida para variar su contribuci√≥n a la funci√≥n general de p√©rdida de aprendizaje. <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=[<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>], loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br>  Como le dimos nombres a nuestras capas de salida, tambi√©n podemos especificar funciones de p√©rdida: <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss={<span class="hljs-string"><span class="hljs-string">'priority'</span></span>: <span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'department'</span></span>: <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>}, loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br>  Podemos entrenar el modelo pasando listas de matrices Numpy de datos de entrada y etiquetas: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Dummy input data title_data = np.random.randint(num_words, size=(1280, 10)) body_data = np.random.randint(num_words, size=(1280, 100)) tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32') # Dummy target data priority_targets = np.random.random(size=(1280, 1)) dept_targets = np.random.randint(2, size=(1280, num_departments)) model.fit({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets}, epochs=2, batch_size=32)</span></span></code> </pre><br>  Al llamar a Fit con un objeto <code>Dataset</code> , se debe <code>([title_data, body_data, tags_data], [priority_targets, dept_targets])</code> una tupla de listas como <code>([title_data, body_data, tags_data], [priority_targets, dept_targets])</code> o una tupla de diccionarios <code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> deben devolverse <code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> . <br><br><h3>  Modelo de entrenamiento cursivo </h3><br>  Adem√°s de los modelos con m√∫ltiples entradas y salidas, la API funcional simplifica la manipulaci√≥n de topolog√≠as con conectividad no lineal, es decir, modelos en los que las capas no est√°n conectadas en serie.  Dichos modelos tampoco pueden implementarse utilizando la API secuencial (como su nombre lo indica). <br><br>  Un caso de uso com√∫n para esto son las conexiones residuales. <br><br>  Construyamos un modelo de entrenamiento ResNet para CIFAR10 para demostrar esto. <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) block_1_output = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_1_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_2_output = layers.add([x, block_1_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_2_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_3_output = layers.add([x, block_2_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(block_3_output) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs, outputs, name=<span class="hljs-string"><span class="hljs-string">'toy_resnet'</span></span>) model.summary()</code> </pre> <br>  Dibujemos un gr√°fico modelo: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'mini_resnet.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/qj/vi/bk/qjvibkpx9zrbp09rcfhj_drtlzc.png"><br><br>  Y ens√©√±ale: <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() x_train = x_train.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_test = x_test.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> y_train = keras.utils.to_categorical(y_train, <span class="hljs-number"><span class="hljs-number">10</span></span>) y_test = keras.utils.to_categorical(y_test, <span class="hljs-number"><span class="hljs-number">10</span></span>) model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)</code> </pre> <br><h2>  Compartir capa </h2><br>  Otro buen uso de la API funcional son los modelos que usan capas comunes.  Las capas comunes son instancias de capas que se reutilizan en el mismo modelo: estudian caracter√≠sticas que se relacionan con varias rutas en un gr√°fico de capas. <br><br>  Las capas comunes a menudo se usan para codificar datos de entrada que provienen de los mismos espacios (por ejemplo, de dos piezas de texto diferentes que tienen el mismo diccionario), ya que proporcionan el intercambio de informaci√≥n entre estos datos diferentes, lo que permite que dichos modelos se entrenen con menos datos.  Si aparece una palabra determinada en una de las entradas, esto facilitar√° su procesamiento en todas las entradas que pasan por el nivel general. <br><br>  Para compartir una capa en la API funcional, simplemente llame a la misma instancia de la capa varias veces.  Por ejemplo, aqu√≠ la capa de <code>Embedding</code> se comparte en dos entradas de texto: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   1000    128-  shared_embedding = layers.Embedding(1000, 128) #     text_input_a = keras.Input(shape=(None,), dtype='int32') #     text_input_b = keras.Input(shape=(None,), dtype='int32') #           encoded_input_a = shared_embedding(text_input_a) encoded_input_b = shared_embedding(text_input_b)</span></span></code> </pre> <br><h2>  Recuperando y reutilizando nodos en un gr√°fico de capas </h2><br>  Dado que el gr√°fico de capa que manipula en la API funcional es una estructura de datos est√°tica, puede acceder a ella y verificarla.  As√≠ es como construimos modelos funcionales, por ejemplo, en forma de im√°genes. <br><br>  Tambi√©n significa que podemos acceder a las activaciones de las capas intermedias ("nodos" en el gr√°fico) y usarlas en otros lugares.  ¬°Esto es extremadamente √∫til para extraer rasgos, por ejemplo! <br><br>  Veamos un ejemplo.  Este es un modelo VGG19 con escalas pre-entrenadas en ImageNet: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.applications <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> VGG19 vgg19 = VGG19()</code> </pre> <br>  Y estas son activaciones de modelo intermedias obtenidas al consultar la estructura de datos del gr√°fico: <br><br><pre> <code class="python hljs">features_list = [layer.output <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> layer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> vgg19.layers]</code> </pre> <br>  Podemos usar estas caracter√≠sticas para crear un nuevo modelo de extracci√≥n de caracter√≠sticas que devuelva valores de activaci√≥n de nivel intermedio, y podemos hacerlo todo en 3 l√≠neas <br><br><pre> <code class="python hljs">feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list) img = np.random.random((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) extracted_features = feat_extraction_model(img)</code> </pre> <br>  Esto es conveniente cuando se implementa la transferencia de estilo neural, como en otros casos. <br><br><h2>  Extendiendo la API escribiendo capas personalizadas </h2><br>  <code>tf.keras</code> tiene una amplia gama de capas incorporadas.  Aqu√≠ hay algunos ejemplos: <br><br>  Capas convolucionales: <code>Conv1D</code> , <code>Conv2D</code> , <code>Conv3D</code> , <code>Conv2DTranspose</code> , etc. <br>  <code>MaxPooling1D</code> capas: <code>MaxPooling1D</code> , <code>MaxPooling2D</code> , <code>MaxPooling3D</code> , <code>AveragePooling1D</code> , etc. <br>  Capas RNN: <code>GRU</code> , <code>LSTM</code> , <code>ConvLSTM2D</code> , etc. <br>  <code>BatchNormalization</code> , <code>Dropout</code> , <code>BatchNormalization</code> , etc. <br><br>  Si no ha encontrado lo que necesita, es f√°cil extender la API creando su propia capa. <br><br>  Todas las capas subclasifican la clase <code>Layer</code> e implementan: <br><br>  El m√©todo de <code>call</code> que define los c√°lculos realizados por la capa. <br>  El m√©todo de <code>build</code> que crea los pesos de las capas (tenga en cuenta que esto es solo una convenci√≥n de estilo; tambi√©n puede crear pesos en <code>__init__</code> ). <br><br>  Aqu√≠ hay una implementaci√≥n simple de la capa <code>Dense</code> : <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs)</code> </pre> <br>  Si desea que su capa personalizada admita la serializaci√≥n, tambi√©n debe definir el m√©todo <code>get_config</code> que devuelve los argumentos del constructor de la instancia de la capa: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> {<span class="hljs-string"><span class="hljs-string">'units'</span></span>: self.units} inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs) config = model.get_config() new_model = keras.Model.from_config( config, custom_objects={<span class="hljs-string"><span class="hljs-string">'CustomDense'</span></span>: CustomDense})</code> </pre> <br>  Opcionalmente, tambi√©n puede implementar el m√©todo de clase <code>from_config (cls, config)</code> , que es responsable de volver a crear la instancia de capa, dado su diccionario de configuraci√≥n.  La <code>from_config</code> predeterminada <code>from_config</code> ve as√≠: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">from_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cls, config)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> cls(**config)</code> </pre> <br><h2>  Cu√°ndo usar la API funcional </h2><br>  ¬øC√≥mo determinar cu√°ndo es mejor usar la API funcional para crear un nuevo modelo, o simplemente subclasificar el <code>Model</code> directamente? <br><br>  En general, la API funcional es m√°s de alto nivel y f√°cil de usar, tiene una serie de funciones que no son compatibles con modelos subclasificados. <br><br>  Sin embargo, la subclasificaci√≥n del modelo le brinda una gran flexibilidad al crear modelos que no se describen f√°cilmente como un gr√°fico ac√≠clico dirigido de capas (por ejemplo, no puede implementar Tree-RNN con la API funcional, debe subclasificar el <code>Model</code> directamente). <br><br><h3>  Fortalezas de API funcional: </h3><br>  Las propiedades enumeradas a continuaci√≥n son verdaderas para los modelos secuenciales (que tambi√©n son estructuras de datos), pero son verdaderas para los modelos subclasificados (que son c√≥digo Python, no estructuras de datos). <br><br><h4>  La API funcional produce c√≥digo m√°s corto. </h4><br>  Sin <code>super(MyClass, self).__init__(...)</code> , sin <code>def call(self, ...):</code> etc. <br><br>  Compara: <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x) mlp = keras.Model(inputs, outputs)</code> </pre> <br>  Con versi√≥n subclaseada: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MLP</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(keras.Model)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, **kwargs)</span></span></span><span class="hljs-function">:</span></span> super(MLP, self).__init__(**kwargs) self.dense_1 = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) self.dense_2 = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> x = self.dense_1(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.dense_2(x) <span class="hljs-comment"><span class="hljs-comment">#   . mlp = MLP() #    . #            . _ = mlp(tf.zeros((1, 32)))</span></span></code> </pre> <br><h4>  Su modelo se valida como est√° escrito. </h4><br>  En la API funcional, las especificaciones de entrada (forma y dtype) se crean de antemano (a trav√©s de `Entrada`), y cada vez que llama a la capa, la capa verifica que las especificaciones que se le pasan coincidan con sus supuestos; si este no es el caso, recibir√° un mensaje de error √∫til . <br><br>  Esto garantiza que cualquier modelo que cree con la API funcional se inicie.  Toda la depuraci√≥n (no relacionada con la depuraci√≥n de convergencia) ocurrir√° est√°ticamente durante la construcci√≥n del modelo, y no en tiempo de ejecuci√≥n.  Esto es similar a la verificaci√≥n de tipos en el compilador. <br><br><h4>  Su modelo funcional se puede representar gr√°ficamente y tambi√©n es comprobable. </h4><br>  Puede dibujar el modelo en forma de gr√°fico, y puede acceder f√°cilmente a los nodos intermedios del gr√°fico, por ejemplo, para extraer y reutilizar la activaci√≥n de las capas intermedias, como vimos en el ejemplo anterior: <br><br><pre> <code class="plaintext hljs">features_list = [layer.output for layer in vgg19.layers] feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)</code> </pre> <br>  Dado que el modelo funcional es m√°s una estructura de datos que un fragmento de c√≥digo, se puede serializar de forma segura y se puede guardar como un solo archivo que le permite recrear exactamente el mismo modelo sin acceso al c√≥digo fuente. <br><br><h3>  Debilidades funcionales de API </h3><br><h4>  No es compatible con arquitecturas din√°micas. </h4><br>  La API funcional procesa modelos como capas DAG.  Esto es cierto para la mayor√≠a de las arquitecturas de aprendizaje profundo, pero no para todos: por ejemplo, las redes recursivas o los RNN de √°rbol no cumplen con este supuesto y no se pueden implementar en la API funcional. <br><br><h4>  A veces solo necesitas escribir todo desde cero. </h4><br>  Al escribir arquitecturas avanzadas, es posible que desee hacer algo que vaya m√°s all√° de "definir capas DAG": por ejemplo, puede usar varios m√©todos de entrenamiento y salida personalizados en una instancia de su modelo.  Esto requiere subclases. <br><br><h2>  Combinando y combinando varios estilos de API </h2><br>  Es importante tener en cuenta que elegir entre la API funcional o subclasificar el modelo no es una soluci√≥n binaria que lo limite a una categor√≠a de modelos.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Todos los modelos en la API tf.keras pueden interactuar entre s√≠, ya sean modelos secuenciales, modelos funcionales o modelos / capas subclasificados escritos desde cero. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Siempre puede usar el modelo funcional o el modelo secuencial como parte del modelo / capa subclasificado:</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment"># Define a Functional model inputs = keras.Input((None, units)) x = layers.GlobalAveragePooling1D()(inputs) outputs = layers.Dense(1, activation='sigmoid')(x) model = keras.Model(inputs, outputs) class CustomRNN(layers.Layer): def __init__(self): super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation='tanh') self.projection_2 = layers.Dense(units=units, activation='tanh') # Our previously-defined Functional model self.classifier = model def call(self, inputs): outputs = [] state = tf.zeros(shape=(inputs.shape[0], self.units)) for t in range(inputs.shape[1]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=1) print(features.shape) return self.classifier(features) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, timesteps, input_dim)))</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por el contrario, puede usar cualquier capa o modelo subclasificado en la API funcional si implementa un m√©todo </font></font><code>call</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que coincida con uno de los siguientes patrones: </font></font><br><br> <code>call(self, inputs, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d√≥nde </font></font><code>inputs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est√° la estructura tensora o tensora anidada (por ejemplo, lista de tensores) y d√≥nde </font></font><code>**kwargs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est√°n los argumentos no tensoriales (no de entrada) . </font></font><br> <code>call(self, inputs, training=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">donde </font></font><code>training</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">es un valor booleano que indica en qu√© modo debe comportarse la capa, el aprendizaje o la salida. </font></font><br> <code>call(self, inputs, mask=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">donde </font></font><code>mask</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est√° el tensor de m√°scara booleana (√∫til para RNN, por ejemplo). </font></font><br> <code>call(self, inputs, training=None, mask=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- por supuesto, puede tener ambos par√°metros que definen el comportamiento de la capa al mismo tiempo.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adem√°s, si implementa el m√©todo `get_config` en su Capa o Modelo personalizado, los modelos funcionales que cree con √©l ser√°n serializables y clonados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A continuaci√≥n se muestra un peque√±o ejemplo en el que utilizamos modelos RNN personalizados escritos desde cero Modelos funcionales:</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomRNN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.projection_2 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.classifier = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> outputs = [] state = tf.zeros(shape=(inputs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], self.units)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(inputs.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.classifier(features) <span class="hljs-comment"><span class="hljs-comment">#           #  `batch_shape`,     `CustomRNN`  #    (     `state`). inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim)) x = layers.Conv1D(32, 3)(inputs) outputs = CustomRNN()(x) model = keras.Model(inputs, outputs) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, 10, 5)))</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬°Esto concluye nuestra Gu√≠a API funcional! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ahora tiene a mano un poderoso conjunto de herramientas para construir modelos de aprendizaje profundo.</font></font><br><br>  <i>Despu√©s de la verificaci√≥n, la traducci√≥n tambi√©n aparecer√° en Tensorflow.org.</i>  <i>Si desea participar en la traducci√≥n de la documentaci√≥n del sitio web de Tensorflow.org al ruso, comun√≠quese personalmente o env√≠e sus comentarios.</i>  <i>Cualquier correcci√≥n o comentario son apreciados.</i> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como ilustraci√≥n, utilizamos la imagen del modelo GoogLeNet, que tambi√©n es un gr√°fico ac√≠clico dirigido.</font></font></i> </div></div><p>Source: <a href="https://habr.com/ru/post/483664/">https://habr.com/ru/post/483664/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../483652/index.html">M√≠rame si puedes: caracter√≠sticas de conducir un pentest sociot√©cnico</a></li>
<li><a href="../483654/index.html">Comentarios en manifestaciones, uno a uno, ¬øpor qu√© puede no funcionar y c√≥mo tratar de solucionarlo?</a></li>
<li><a href="../483656/index.html">Tableau en el comercio minorista, ¬øen serio?</a></li>
<li><a href="../483660/index.html">Telegram-bot para gesti√≥n de infraestructura</a></li>
<li><a href="../483662/index.html">Integraci√≥n de Cisco Threat Response y Cisco Stealthwatch Enterprise</a></li>
<li><a href="../483666/index.html">Sobre Volodia y el ozonizador</a></li>
<li><a href="../483668/index.html">El resumen de materiales frescos del mundo del front-end para la √∫ltima semana No. 397 (6 al 12 de enero de 2020)</a></li>
<li><a href="../483670/index.html">Todo lo que quer√≠as saber sobre la direcci√≥n MAC</a></li>
<li><a href="../483674/index.html">C√≥mo funcionan las redes neuronales binarias y por qu√© ser√°n populares en 2020</a></li>
<li><a href="../483676/index.html">Evaluaci√≥n de la efectividad y el costo de implementar un sistema de an√°lisis de marketing de extremo a extremo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
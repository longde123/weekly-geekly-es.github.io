<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👎🏾 🛫 🕳️ Ereignisprotokollierung mit Kafka 👩🏾‍🚀 ↪️ 🥫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! 

 Wir haben die letzten Reserven des Buches " Apache Kafka. Stream-Verarbeitung und Datenanalyse " aufgedeckt und an die Druckvorstufe ge...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ereignisprotokollierung mit Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/424739/"> Hallo Habr! <br><br>  Wir haben die letzten Reserven des Buches " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Kafka. Stream-Verarbeitung und Datenanalyse</a> " aufgedeckt und an die Druckvorstufe gesendet.  Darüber hinaus haben wir einen Vertrag für das Buch " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka Streams in Action</a> " erhalten und beginnen nächste Woche damit, es wörtlich zu übersetzen. <br><br><img src="https://habrastorage.org/webt/re/29/51/re2951jsut-yre1r79xmmt4ibdy.jpeg"><br><br>  Um den interessanten Fall der Verwendung der Kafka Streams-Bibliothek aufzuzeigen, haben wir beschlossen, den Artikel über das Event Sourcing-Paradigma in Kafka von Adam Worski zu übersetzen, dessen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> über die Scala-Sprache vor zwei Wochen veröffentlicht wurde.  Noch interessanter ist, dass die Meinung von Adam Worski nicht unbestreitbar ist: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier</a> wird beispielsweise argumentiert, dass dieses Paradigma definitiv nicht für Kafka geeignet ist.  Umso denkwürdiger, wir hoffen, wir bekommen den Eindruck des Artikels. <br><br>  Der Begriff „Event Sourcing“ wird sowohl in unserer Veröffentlichung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Clean Architecture von</a> Robert Martin als auch in diesem Artikel als „Event Logging“ übersetzt.  Wenn jemand von der Übersetzung von "Pumping Events" beeindruckt ist, lassen Sie es mich bitte wissen. <br><a name="habracut"></a><br>  Wenn wir ein System erstellen, das die Registrierung von Ereignissen (Event Sourcing) ermöglicht, stehen wir früher oder später vor dem Problem der Persistenz (Persistenz) - und hier haben wir einige Optionen.  Erstens gibt es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">EventStore</a> , eine ausgereifte Implementierung, die im Kampf gehärtet wurde.  Alternativ können Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Akka-Persistenz verwenden</a> , um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die</a> Skalierbarkeit von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cassandra</a> voll auszunutzen und sich auf die Leistung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Akteurmodells</a> zu verlassen.  Eine weitere Option ist die gute alte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">relationale Datenbank</a> , in der der <code>CRUD</code> Ansatz mit der Verwendung von Ereignissen kombiniert wird und der maximale Nutzen aus Transaktionen herausgepresst wird. <br><br>  Zusätzlich zu diesen (und vielleicht vielen anderen) Möglichkeiten, die sich aufgrund mehrerer kürzlich implementierter Dinge ergeben haben, ist es heute recht einfach geworden, die Registrierung von Veranstaltungen über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka</a> zu organisieren.  Schauen wir uns an, wie. <br><br>  <b>Was ist Ereignisprotokollierung?</b> <br><br>  Es gibt eine Reihe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ausgezeichneter</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Einführungsartikel</a> zu diesem Thema, daher beschränke ich mich auf die prägnanteste Einführung.  Bei der Registrierung von Ereignissen speichern wir nicht den „aktuellen“ Status der in unserem System verwendeten Entitäten, sondern den Ereignisstrom, der sich auf diese Entitäten bezieht.  Jedes <i>Ereignis</i> ist eine <b>Tatsache</b> , die eine Zustandsänderung (bereits!) Beschreibt, <b>die</b> mit dem Objekt <b>aufgetreten ist</b> .  Wie Sie wissen, werden die Fakten nicht diskutiert und bleiben <b>unverändert</b> . <br><br>  Wenn wir einen Strom solcher Ereignisse haben, kann der aktuelle Status einer Entität geklärt werden, indem alle damit verbundenen Ereignisse minimiert werden.  Beachten Sie jedoch, dass das Gegenteil nicht möglich ist. Wenn wir nur den "aktuellen" Zustand beibehalten, verwerfen wir viele wertvolle chronologische Informationen. <br><br>  Die Ereignisprotokollierung kann friedlich mit traditionelleren Methoden zum Speichern von Status <b>koexistieren</b> .  In der Regel verarbeitet das System eine Reihe von Entitätstypen (z. B. Benutzer, Bestellungen, Waren usw.), und es ist durchaus möglich, dass die Registrierung von Ereignissen nur für einige dieser Kategorien nützlich ist.  Es ist wichtig anzumerken, dass wir hier nicht vor der Wahl von „alles oder nichts“ stehen;  Es geht nur um die zusätzliche Statusverwaltungsfunktion in unserer Anwendung. <br><br>  <b>Veranstaltungsspeicher in Kafka</b> <br><br>  Das erste zu lösende Problem: Wie speichere ich Ereignisse in Kafka?  Es gibt drei mögliche Strategien: <br><br><ul><li>  Speichern Sie alle Ereignisse für alle Arten von Entitäten in einem <b>einzigen Thema</b> (mit vielen Segmenten). </li><li>  Nach Thema für jeden Entitätstyp, d. H. Wir nehmen alle Ereignisse, die sich auf den Benutzer beziehen, in einem separaten Thema, in einem separaten - alle auf das Produkt bezogenen - usw. auf. </li><li>  Nach Themen, d. H. Nach einem separaten Thema für jeden bestimmten Benutzer und jeden Produktnamen </li></ul><br>  Die dritte Strategie (thematisch) ist praktisch nicht praktikabel.  Wenn jeder neue Benutzer, wenn er im System erscheint, ein separates Thema starten müsste, würde die Anzahl der Themen bald unbegrenzt sein.  Eine Aggregation wäre in diesem Fall sehr schwierig, zum Beispiel wäre es schwierig, alle Benutzer in einer Suchmaschine zu indizieren.  Sie müssten nicht nur eine Vielzahl von Themen konsumieren, sondern auch nicht alle waren im Voraus bekannt. <br><br>  Daher bleibt die Wahl zwischen 1 und 2. Beide Optionen haben ihre Vor- und Nachteile.  Ein einziges Thema erleichtert es, eine <b>globale Ansicht</b> aller Ereignisse zu erhalten.  Auf der anderen Seite können Sie durch Hervorheben des Themas für jeden Entitätstyp den Fluss jeder Entität einzeln skalieren und segmentieren.  Die Wahl einer von zwei Strategien hängt vom jeweiligen Anwendungsfall ab. <br><br>  Darüber hinaus können Sie beide Strategien gleichzeitig implementieren, wenn Sie über zusätzlichen Speicherplatz verfügen: Erstellen Sie Themen nach Entitätstyp aus einem umfassenden Thema. <br><br><img src="https://habrastorage.org/webt/1i/lg/v4/1ilgv4fs1_uoaw6uximo7fy9e7k.png"><br><br>  Im Rest des Artikels werden wir nur mit einem Entitätstyp und mit einem einzelnen Thema arbeiten, obwohl das präsentierte Material leicht extrapoliert und auf die Arbeit mit vielen Themen oder Entitätstypen angewendet werden kann. <br><br>  (BEARBEITEN: Wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chris Hunt</a> feststellte, gibt es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen ausgezeichneten Artikel von</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Martin Kleppman</a> , in dem ausführlich untersucht wurde, wie Ereignisse nach Thema und Segment verteilt werden können.) <br><br>  <b>Die einfachsten Speicheroperationen im Ereignisprotokollierungsparadigma</b> <br><br>  Die einfachste Operation, die von einem Geschäft, das die Ereignisprotokollierung unterstützt, logisch zu erwarten ist, besteht darin, den "aktuellen" (minimierten) Status einer bestimmten Entität zu lesen.  In der Regel hat jede Entität die eine oder andere <code>id</code> .  Wenn wir diese <code>id</code> , sollte unser Speichersystem den aktuellen Status des Objekts zurückgeben. <br><br>  Die Wahrheit im letzten Ausweg ist das Ereignisprotokoll: Der aktuelle Status kann immer aus dem Ereignisstrom abgeleitet werden, der einer bestimmten Entität zugeordnet ist.  Dazu benötigt das Datenbankmodul eine reine Funktion (ohne Nebenwirkungen), die das Ereignis und den Anfangszustand akzeptiert und den geänderten Zustand zurückgibt: <code>Event = &amp;gt State =&amp;gt State</code> .  Bei Vorhandensein einer solchen Funktion und des <b>Werts des Anfangszustands ist der</b> aktuelle Zustand eine <b>Faltung des</b> Ereignisflusses (die Zustandsänderungsfunktion muss <b>sauber sein,</b> damit sie wiederholt frei auf dieselben Ereignisse angewendet werden kann.) <br><br>  Eine vereinfachte Implementierung der Operation "Aktuellen Status lesen" in Kafka sammelt einen Stream <b>aller</b> Ereignisse aus dem Thema, filtert sie, lässt nur Ereignisse mit der angegebenen <code>id</code> übrig und wird mit der angegebenen Funktion reduziert.  Wenn es viele Ereignisse gibt (und im Laufe der Zeit nur die Anzahl der Ereignisse zunimmt), kann dieser Vorgang langsam werden und viele Ressourcen verbrauchen.  Selbst wenn das Ergebnis im Speicher zwischengespeichert und auf dem Dienstknoten gespeichert wird, müssen diese Informationen regelmäßig neu erstellt werden, z. B. aufgrund von Knotenfehlern oder aufgrund von Verdrängung der Cache-Daten. <br><br><img src="https://habrastorage.org/webt/r5/te/aa/r5teaa64otzjedcvs0g1snt9lj8.png"><br><br>  Daher ist ein rationalerer Weg erforderlich.  Hier bieten sich Kafka-Streams und State Repositories an.  Kafka-Streams-Anwendungen werden auf einem ganzen Cluster von Knoten ausgeführt, die bestimmte Themen zusammen verwenden.  Jedem Knoten wird eine Reihe von konsumierten Themensegmenten zugewiesen, genau wie beim normalen Kafka-Konsumenten.  Kafka-Streams bieten jedoch Datenoperationen auf höherer Ebene, die das Erstellen abgeleiteter Streams erheblich vereinfachen. <br><br>  Eine solche Operation in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka-Streams</a> ist die Faltung eines Streams im lokalen Speicher.  Jeder lokale Speicher enthält nur Daten aus den Segmenten, die von einem bestimmten Knoten verwendet werden.  <i>Standardmäßig</i> sind zwei lokale Speicherimplementierungen verfügbar: <i>im RAM</i> und basierend auf <i>RocksDB</i> . <br><br>  Zurück zum Thema Ereignisregistrierung: Wir stellen fest, dass es möglich ist, den Ereignisstrom im <b>Statusspeicher zu reduzieren, indem</b> auf dem lokalen Knoten der "aktuelle Status" jeder Entität aus den dem Knoten zugewiesenen Segmenten gehalten wird.  Wenn wir die Implementierung des auf RocksDB basierenden Statusspeichers verwenden, hängt die Anzahl der Entitäten, die wir auf einem einzelnen Knoten verfolgen können, nur von der Größe des Speicherplatzes ab. <br><br>  So sieht die Faltung von Ereignissen im lokalen Speicher bei Verwendung der Java-API aus (serde bedeutet "Serializer / Deserializer"): <br><br><pre> <code class="java hljs">KStreamBuilder builder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KStreamBuilder(); builder.stream(keySerde, valueSerde, <span class="hljs-string"><span class="hljs-string">"my_entity_events"</span></span>) .groupByKey(keySerde, valueSerde) <span class="hljs-comment"><span class="hljs-comment">//  :     .reduce((currentState, event) -&gt; ..., "my_entity_store"); .toStream(); //     return builder;</span></span></code> </pre> <br>  Ein vollständiges Beispiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">für die Auftragsabwicklung auf Basis von Microservices finden Sie</a> auf der Confluent-Website. <br><br>  (BEARBEITEN: Wie von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sergei Egorov</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nikita Salnikov</a> auf Twitter festgestellt, müssen Sie für ein System mit Ereignisprotokollierung wahrscheinlich die Standard-Datenspeichereinstellungen in Kafka ändern, damit keine Zeit- oder Größenbeschränkungen funktionieren, und optional , Datenkomprimierung aktivieren.) <br><br>  <b>Aktuellen Status anzeigen</b> <br><br>  Wir haben ein Status-Repository erstellt, in dem sich die aktuellen Status aller Entitäten befinden, die aus Segmenten stammen, die dem Knoten zugewiesen sind. Wie kann dieses Repository jetzt angefordert werden?  Wenn die Anforderung lokal ist (dh von demselben Knoten stammt, auf dem sich das Repository befindet), ist alles ziemlich einfach: <br><br><pre> <code class="java hljs">streams .store(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, QueryableStoreTypes.keyValueStore()); .get(entityId);</code> </pre> <br>  Was aber, wenn wir Daten anfordern möchten, die sich auf einem anderen Knoten befinden?  Und wie kann man herausfinden, was dieser Knoten ist?  Hier ist eine weitere kürzlich in Kafka eingeführte Funktion nützlich: <b>interaktive Abfragen</b> .  Mit ihrer Hilfe können Sie auf die Kafka-Metadaten zugreifen und herausfinden, welcher Knoten das Themensegment mit der angegebenen <code>id</code> (in diesem Fall wird implizit das Tool zur Themensegmentierung verwendet): <br><br><pre> <code class="java hljs">metadataService .streamsMetadataForStoreAndKey(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, entityId, keySerde)</code> </pre> <br>  Als nächstes müssen Sie die Anforderung irgendwie an den richtigen Knoten umleiten.  Bitte beachten Sie: Die spezifische Art und Weise, wie die standortübergreifende Kommunikation implementiert und gehandhabt wird - ob REST, Akka-Remote oder eine andere -, gehört nicht zum Verantwortungsbereich von Kafka-Streams.  Kafka bietet einfach Zugriff auf den Statusspeicher und gibt Auskunft darüber, auf welchem ​​Knoten sich der Statusspeicher für die angegebene <code>id</code> . <br><br>  <b>Notfallwiederherstellung</b> <br><br>  State Stores sehen gut aus, aber was passiert, wenn ein Knoten ausfällt?  Die Rekonstruktion eines lokalen staatlichen Speichers für ein bestimmtes Segment kann ebenfalls eine kostspielige Operation sein.  Dies kann für längere Zeit zu erhöhten Verzögerungen oder zum Verlust von Anforderungen führen, da Kafka-Streams neu ausgeglichen werden müssen (nach dem Hinzufügen oder Entfernen eines Knotens). <br><br>  Aus diesem Grund werden standardmäßig langfristige Statusspeicher protokolliert. Das heißt, alle am Speicher vorgenommenen Änderungen werden zusätzlich in das Changelog-Thema geschrieben.  Dieses Thema ist komprimiert (da wir für jede <code>id</code> nur den letzten Datensatz ohne Änderungsverlauf interessieren, da der Verlauf in den Ereignissen selbst gespeichert ist) - daher ist er so klein wie möglich.  Aus diesem Grund kann die Wiederherstellung des Speichers auf einem anderen Knoten viel schneller erfolgen. <br><br>  Bei einer Neuausrichtung sind in diesem Fall jedoch immer noch Verzögerungen möglich.  Um sie weiter zu reduzieren, bieten kafka-Streams die Möglichkeit, mehrere <b>Sicherungsreplikate</b> ( <code>num.standby.replicas</code> ) für jedes Repository zu <code>num.standby.replicas</code> .  Diese Replikate wenden alle Aktualisierungen an, die aus Themen mit Änderungsprotokollen abgerufen wurden, sobald sie verfügbar sind, und können für ein bestimmtes Segment in den Hauptstatus-Speichermodus wechseln, sobald der aktuelle Hauptspeicher ausfällt. <br><br>  <b>Kohärenz</b> <br><br>  Mit den Standardeinstellungen bietet Kafka mindestens eine einmalige Lieferung.  Das heißt, im Falle eines Knotenausfalls können einige Nachrichten mehrmals zugestellt werden.  Beispielsweise ist es möglich, dass ein bestimmtes Ereignis zweimal auf den Statusspeicher angewendet wird, wenn das System abstürzt, nachdem der Statusspeicher in das Protokoll geändert wurde, jedoch bevor der Offset für dieses bestimmte Ereignis ausgeführt wurde.  Vielleicht verursacht dies keine Schwierigkeiten: Unsere Statusaktualisierungsfunktion ( <code>Event = &amp;gt State =&amp;gt State</code> ) kann solche Situationen ganz normal bewältigen.  Es ist jedoch möglicherweise nicht in der Lage, dies zu bewältigen: In einem solchen Fall können die von Kafka gewährten Garantien einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">streng einmaligen Lieferung</a> verwendet werden.  Solche Garantien gelten nur beim Lesen und Schreiben von Kafka-Themen. Dies tun wir jedoch hier: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Im Hintergrund werden alle Einträge in Kafka-Themen darauf reduziert, das Änderungsprotokoll für den</a> Statusspeicher <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu aktualisieren</a> und Offsets durchzuführen.  All dies kann <b>in Form von Transaktionen erfolgen</b> . <br><br>  Wenn unsere Funktion zum Aktualisieren des Status dies erfordert, können wir daher die Semantik der Verarbeitung von Flüssen "ausschließlich einmalig" mithilfe einer einzigen Konfigurationsoption aktivieren: <code>processing.guarantee</code> .  Aus diesem Grund sinkt die Leistung, aber nichts ist umsonst. <br><br>  <b>Ereignis hören</b> <br><br>  Nachdem wir uns nun mit den Grundlagen befasst haben - den „aktuellen Status“ abzufragen und ihn für jede Entität zu aktualisieren -, was ist mit dem Auslösen von <b>Nebenwirkungen</b> ?  Irgendwann wird dies notwendig sein, zum Beispiel für: <br><br><ul><li>  Senden von Benachrichtigungs-E-Mails </li><li>  Indizierung von Suchmaschinenentitäten </li><li>  Aufrufen externer Dienste über REST (oder SOAP, CORBA usw.) </li></ul><br>  Alle diese Aufgaben sind bis zu einem gewissen Grad blockierend und beziehen sich auf E / A-Vorgänge (dies ist natürlich für Nebenwirkungen). Daher ist es wahrscheinlich keine gute Idee, sie im Rahmen der Statusaktualisierungslogik auszuführen: Infolgedessen kann die Häufigkeit von Fehlern in der Hauptschleife zunehmen Ereignisse und in Bezug auf die Leistung wird es einen Engpass geben. <br><br>  Darüber hinaus kann eine Funktion mit Statusaktualisierungslogik (E <code>Event = &amp;gt State =&amp;gt State</code> Status <code>Event = &amp;gt State =&amp;gt State</code> Status) mehrmals ausgeführt werden (bei Fehlern oder Neustarts), und meistens möchten wir die Anzahl der Fälle minimieren, in denen Nebenwirkungen für ein bestimmtes Ereignis mehrmals ausgeführt werden. <br><br>  Glücklicherweise haben wir, da wir mit Kafka-Themen arbeiten, einiges an Flexibilität.  In der Flows-Phase, in der der Statusspeicher aktualisiert wird, können Ereignisse unverändert (oder, falls erforderlich, auch in modifizierter Form) ausgegeben werden, und der resultierende Stream / das resultierende Thema (in Kafka sind diese Konzepte gleichwertig) kann nach Belieben verwendet werden.  Darüber hinaus kann es entweder vor oder nach der Statusaktualisierungsphase verwendet werden.  Schließlich können wir steuern, wie wir Nebenwirkungen auslösen: mindestens einmal oder höchstens einmal.  Die erste Option ist verfügbar, wenn Sie den Versatz des verbrauchten Themenereignisses erst ausführen, nachdem alle Nebenwirkungen erfolgreich abgeschlossen wurden.  Umgekehrt führen wir mit maximal einem Lauf Verschiebungen durch, bis Nebenwirkungen ausgelöst werden. <br><br>  Es gibt verschiedene Möglichkeiten, um Nebenwirkungen auszulösen, die von der spezifischen praktischen Situation abhängen.  Zunächst können Sie die Kafka-Streams-Phase definieren, in der Nebenwirkungen für jedes Ereignis als Teil der Stream-Verarbeitungsfunktion ausgelöst werden. <br>  Das Einrichten eines solchen Mechanismus ist recht einfach, aber diese Lösung ist nicht flexibel, wenn Sie Wiederholungsversuche durchführen, Offsets steuern und Offsets für viele Ereignisse gleichzeitig konkurrieren müssen.  In solch komplexeren Fällen kann es zweckmäßiger sein, die Verarbeitung unter Verwendung von beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">reaktivem Kafka</a> oder einem anderen Mechanismus zu bestimmen, der Kafka-Themen "direkt" konsumiert. <br><br>  Es ist auch möglich, dass ein Ereignis <b>andere Ereignisse auslöst.</b> Beispielsweise kann das Ereignis "Bestellung" die Ereignisse "Vorbereitung für den Versand" und "Kundenbenachrichtigung" auslösen.  Dies kann auch in der Kafka-Streams-Phase implementiert werden. <br><br>  Wenn wir Ereignisse oder Daten, die aus Ereignissen extrahiert wurden, in einer Datenbank oder Suchmaschine speichern möchten, beispielsweise in ElasticSearch oder PostgreSQL, können wir den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka Connect-</a> Connector verwenden, der für uns alle Details zum Verbrauch von Themen verarbeitet. <br><br>  <b>Ansichten und Projektionen erstellen</b> <br><br>  In der Regel beschränken sich die Systemanforderungen nicht darauf, nur einzelne Entitätsströme abzufragen und zu verarbeiten.  Aggregation, Kombination mehrerer Ereignisströme sollte ebenfalls unterstützt werden.  Solche kombinierten Streams werden oft als <b>Projektionen bezeichnet</b> . Wenn sie reduziert sind, können sie zum Erstellen von <b>Darstellungen von Daten verwendet werden</b> .  Ist es möglich, sie mit Kafka umzusetzen? <br><br><img src="https://habrastorage.org/webt/yc/r2/jt/ycr2jtvibrdg7wy0lhin1ehwu1y.png"><br><br>  Wieder ja!  Denken Sie daran, dass wir uns im Prinzip nur mit dem Thema Kafka befassen, in dem unsere Ereignisse gespeichert sind.  Daher haben wir die ganze Macht der rohen Kafka-Verbraucher / Produzenten, des Kafka-Streams-Kombinierers und sogar von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">KSQL</a> - all dies wird für uns nützlich sein, um Projektionen zu definieren.  Mit Kafka-Streams können Sie beispielsweise einen Stream filtern, anzeigen, nach Schlüsseln gruppieren, in temporären Fenstern oder Sitzungsfenstern aggregieren usw.  entweder auf Codeebene oder mit SQL-ähnlichem KSQL. <br><br>  Solche Flows können mithilfe von State Stores und interaktiven Abfragen für eine lange Zeit gespeichert und für Abfragen bereitgestellt werden, genau wie wir es mit einzelnen Entity Flows getan haben. <br><br>  <b>Was weiter</b> <br><br>  Um den unendlichen Fluss von Ereignissen während der Entwicklung des Systems zu verhindern, kann eine Komprimierungsoption wie das Speichern von <b>Schnappschüssen des</b> „aktuellen Status“ hilfreich sein.  Daher können wir uns darauf beschränken, nur einige aktuelle Schnappschüsse und Ereignisse zu speichern, die nach ihrer Erstellung aufgetreten sind. <br><br>  Obwohl Kafka keine direkte Unterstützung für Snapshots bietet (und in einigen anderen Systemen, die nach dem Prinzip der Ereignisaufzeichnung arbeiten), können Sie diese Art von Funktionalität auf jeden Fall selbst hinzufügen, indem Sie einige der oben genannten Mechanismen verwenden, z. B. Streams, Verbraucher, staatliche Geschäfte usw. d. <br><br>  <b>Zusammenfassung</b> <br><br>  Obwohl Kafka anfangs nicht mit Blick auf das Ereignisregistrierungsparadigma entwickelt wurde, handelt es sich tatsächlich um eine Streaming-Daten-Engine mit Unterstützung für <b>Themenreplikation</b> , Segmentierung, <b>Status-Repositorys</b> und <b>Streaming-APIs</b> und ist gleichzeitig sehr flexibel.  Daher können Sie zusätzlich zu Kafka problemlos ein Ereignisregistrierungssystem implementieren.  Da wir vor dem Hintergrund von allem, was passiert, immer ein Kafka-Thema haben, erhalten wir zusätzliche Flexibilität, da wir entweder mit Streaming-APIs auf hoher Ebene oder mit Verbrauchern auf niedriger Ebene arbeiten können. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424739/">https://habr.com/ru/post/de424739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424729/index.html">Warum hat der Compiler meine bedingte Schleife in eine Endlosschleife verwandelt?</a></li>
<li><a href="../de424731/index.html">Hot Tech Support-Verlauf oder Warum löscht AutoCAD Proxy-Objekte?</a></li>
<li><a href="../de424733/index.html">Blaue Pille STM32F103 als SPS</a></li>
<li><a href="../de424735/index.html">Wie funktioniert es und wie funktioniert die Konversationspsychotherapie überhaupt?</a></li>
<li><a href="../de424737/index.html">42. Protokoll des Lebens, des Universums und all das: "Abschiedsrede"</a></li>
<li><a href="../de424741/index.html">Leute, lasst uns in Ruhe leben oder über das Passwortfeld bei der Registrierung</a></li>
<li><a href="../de424745/index.html">Die GosSOPKI-Aktivität hat zugenommen</a></li>
<li><a href="../de424747/index.html">Der Ort, an dem der Klang lebt</a></li>
<li><a href="../de424751/index.html">Wie das einheitliche biometrische System funktioniert</a></li>
<li><a href="../de424753/index.html">Was ist neu in YouTrack 2018.3?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
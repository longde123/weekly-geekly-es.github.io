<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëéüèæ üõ´ üï≥Ô∏è Ereignisprotokollierung mit Kafka üë©üèæ‚ÄçüöÄ ‚Ü™Ô∏è ü•´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! 

 Wir haben die letzten Reserven des Buches " Apache Kafka. Stream-Verarbeitung und Datenanalyse " aufgedeckt und an die Druckvorstufe ge...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ereignisprotokollierung mit Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/424739/"> Hallo Habr! <br><br>  Wir haben die letzten Reserven des Buches " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Kafka. Stream-Verarbeitung und Datenanalyse</a> " aufgedeckt und an die Druckvorstufe gesendet.  Dar√ºber hinaus haben wir einen Vertrag f√ºr das Buch " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka Streams in Action</a> " erhalten und beginnen n√§chste Woche damit, es w√∂rtlich zu √ºbersetzen. <br><br><img src="https://habrastorage.org/webt/re/29/51/re2951jsut-yre1r79xmmt4ibdy.jpeg"><br><br>  Um den interessanten Fall der Verwendung der Kafka Streams-Bibliothek aufzuzeigen, haben wir beschlossen, den Artikel √ºber das Event Sourcing-Paradigma in Kafka von Adam Worski zu √ºbersetzen, dessen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> √ºber die Scala-Sprache vor zwei Wochen ver√∂ffentlicht wurde.  Noch interessanter ist, dass die Meinung von Adam Worski nicht unbestreitbar ist: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier</a> wird beispielsweise argumentiert, dass dieses Paradigma definitiv nicht f√ºr Kafka geeignet ist.  Umso denkw√ºrdiger, wir hoffen, wir bekommen den Eindruck des Artikels. <br><br>  Der Begriff ‚ÄûEvent Sourcing‚Äú wird sowohl in unserer Ver√∂ffentlichung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Clean Architecture von</a> Robert Martin als auch in diesem Artikel als ‚ÄûEvent Logging‚Äú √ºbersetzt.  Wenn jemand von der √úbersetzung von "Pumping Events" beeindruckt ist, lassen Sie es mich bitte wissen. <br><a name="habracut"></a><br>  Wenn wir ein System erstellen, das die Registrierung von Ereignissen (Event Sourcing) erm√∂glicht, stehen wir fr√ºher oder sp√§ter vor dem Problem der Persistenz (Persistenz) - und hier haben wir einige Optionen.  Erstens gibt es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">EventStore</a> , eine ausgereifte Implementierung, die im Kampf geh√§rtet wurde.  Alternativ k√∂nnen Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Akka-Persistenz verwenden</a> , um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die</a> Skalierbarkeit von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cassandra</a> voll auszunutzen und sich auf die Leistung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Akteurmodells</a> zu verlassen.  Eine weitere Option ist die gute alte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">relationale Datenbank</a> , in der der <code>CRUD</code> Ansatz mit der Verwendung von Ereignissen kombiniert wird und der maximale Nutzen aus Transaktionen herausgepresst wird. <br><br>  Zus√§tzlich zu diesen (und vielleicht vielen anderen) M√∂glichkeiten, die sich aufgrund mehrerer k√ºrzlich implementierter Dinge ergeben haben, ist es heute recht einfach geworden, die Registrierung von Veranstaltungen √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka</a> zu organisieren.  Schauen wir uns an, wie. <br><br>  <b>Was ist Ereignisprotokollierung?</b> <br><br>  Es gibt eine Reihe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ausgezeichneter</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Einf√ºhrungsartikel</a> zu diesem Thema, daher beschr√§nke ich mich auf die pr√§gnanteste Einf√ºhrung.  Bei der Registrierung von Ereignissen speichern wir nicht den ‚Äûaktuellen‚Äú Status der in unserem System verwendeten Entit√§ten, sondern den Ereignisstrom, der sich auf diese Entit√§ten bezieht.  Jedes <i>Ereignis</i> ist eine <b>Tatsache</b> , die eine Zustands√§nderung (bereits!) Beschreibt, <b>die</b> mit dem Objekt <b>aufgetreten ist</b> .  Wie Sie wissen, werden die Fakten nicht diskutiert und bleiben <b>unver√§ndert</b> . <br><br>  Wenn wir einen Strom solcher Ereignisse haben, kann der aktuelle Status einer Entit√§t gekl√§rt werden, indem alle damit verbundenen Ereignisse minimiert werden.  Beachten Sie jedoch, dass das Gegenteil nicht m√∂glich ist. Wenn wir nur den "aktuellen" Zustand beibehalten, verwerfen wir viele wertvolle chronologische Informationen. <br><br>  Die Ereignisprotokollierung kann friedlich mit traditionelleren Methoden zum Speichern von Status <b>koexistieren</b> .  In der Regel verarbeitet das System eine Reihe von Entit√§tstypen (z. B. Benutzer, Bestellungen, Waren usw.), und es ist durchaus m√∂glich, dass die Registrierung von Ereignissen nur f√ºr einige dieser Kategorien n√ºtzlich ist.  Es ist wichtig anzumerken, dass wir hier nicht vor der Wahl von ‚Äûalles oder nichts‚Äú stehen;  Es geht nur um die zus√§tzliche Statusverwaltungsfunktion in unserer Anwendung. <br><br>  <b>Veranstaltungsspeicher in Kafka</b> <br><br>  Das erste zu l√∂sende Problem: Wie speichere ich Ereignisse in Kafka?  Es gibt drei m√∂gliche Strategien: <br><br><ul><li>  Speichern Sie alle Ereignisse f√ºr alle Arten von Entit√§ten in einem <b>einzigen Thema</b> (mit vielen Segmenten). </li><li>  Nach Thema f√ºr jeden Entit√§tstyp, d. H. Wir nehmen alle Ereignisse, die sich auf den Benutzer beziehen, in einem separaten Thema, in einem separaten - alle auf das Produkt bezogenen - usw. auf. </li><li>  Nach Themen, d. H. Nach einem separaten Thema f√ºr jeden bestimmten Benutzer und jeden Produktnamen </li></ul><br>  Die dritte Strategie (thematisch) ist praktisch nicht praktikabel.  Wenn jeder neue Benutzer, wenn er im System erscheint, ein separates Thema starten m√ºsste, w√ºrde die Anzahl der Themen bald unbegrenzt sein.  Eine Aggregation w√§re in diesem Fall sehr schwierig, zum Beispiel w√§re es schwierig, alle Benutzer in einer Suchmaschine zu indizieren.  Sie m√ºssten nicht nur eine Vielzahl von Themen konsumieren, sondern auch nicht alle waren im Voraus bekannt. <br><br>  Daher bleibt die Wahl zwischen 1 und 2. Beide Optionen haben ihre Vor- und Nachteile.  Ein einziges Thema erleichtert es, eine <b>globale Ansicht</b> aller Ereignisse zu erhalten.  Auf der anderen Seite k√∂nnen Sie durch Hervorheben des Themas f√ºr jeden Entit√§tstyp den Fluss jeder Entit√§t einzeln skalieren und segmentieren.  Die Wahl einer von zwei Strategien h√§ngt vom jeweiligen Anwendungsfall ab. <br><br>  Dar√ºber hinaus k√∂nnen Sie beide Strategien gleichzeitig implementieren, wenn Sie √ºber zus√§tzlichen Speicherplatz verf√ºgen: Erstellen Sie Themen nach Entit√§tstyp aus einem umfassenden Thema. <br><br><img src="https://habrastorage.org/webt/1i/lg/v4/1ilgv4fs1_uoaw6uximo7fy9e7k.png"><br><br>  Im Rest des Artikels werden wir nur mit einem Entit√§tstyp und mit einem einzelnen Thema arbeiten, obwohl das pr√§sentierte Material leicht extrapoliert und auf die Arbeit mit vielen Themen oder Entit√§tstypen angewendet werden kann. <br><br>  (BEARBEITEN: Wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chris Hunt</a> feststellte, gibt es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen ausgezeichneten Artikel von</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Martin Kleppman</a> , in dem ausf√ºhrlich untersucht wurde, wie Ereignisse nach Thema und Segment verteilt werden k√∂nnen.) <br><br>  <b>Die einfachsten Speicheroperationen im Ereignisprotokollierungsparadigma</b> <br><br>  Die einfachste Operation, die von einem Gesch√§ft, das die Ereignisprotokollierung unterst√ºtzt, logisch zu erwarten ist, besteht darin, den "aktuellen" (minimierten) Status einer bestimmten Entit√§t zu lesen.  In der Regel hat jede Entit√§t die eine oder andere <code>id</code> .  Wenn wir diese <code>id</code> , sollte unser Speichersystem den aktuellen Status des Objekts zur√ºckgeben. <br><br>  Die Wahrheit im letzten Ausweg ist das Ereignisprotokoll: Der aktuelle Status kann immer aus dem Ereignisstrom abgeleitet werden, der einer bestimmten Entit√§t zugeordnet ist.  Dazu ben√∂tigt das Datenbankmodul eine reine Funktion (ohne Nebenwirkungen), die das Ereignis und den Anfangszustand akzeptiert und den ge√§nderten Zustand zur√ºckgibt: <code>Event = &amp;gt State =&amp;gt State</code> .  Bei Vorhandensein einer solchen Funktion und des <b>Werts des Anfangszustands ist der</b> aktuelle Zustand eine <b>Faltung des</b> Ereignisflusses (die Zustands√§nderungsfunktion muss <b>sauber sein,</b> damit sie wiederholt frei auf dieselben Ereignisse angewendet werden kann.) <br><br>  Eine vereinfachte Implementierung der Operation "Aktuellen Status lesen" in Kafka sammelt einen Stream <b>aller</b> Ereignisse aus dem Thema, filtert sie, l√§sst nur Ereignisse mit der angegebenen <code>id</code> √ºbrig und wird mit der angegebenen Funktion reduziert.  Wenn es viele Ereignisse gibt (und im Laufe der Zeit nur die Anzahl der Ereignisse zunimmt), kann dieser Vorgang langsam werden und viele Ressourcen verbrauchen.  Selbst wenn das Ergebnis im Speicher zwischengespeichert und auf dem Dienstknoten gespeichert wird, m√ºssen diese Informationen regelm√§√üig neu erstellt werden, z. B. aufgrund von Knotenfehlern oder aufgrund von Verdr√§ngung der Cache-Daten. <br><br><img src="https://habrastorage.org/webt/r5/te/aa/r5teaa64otzjedcvs0g1snt9lj8.png"><br><br>  Daher ist ein rationalerer Weg erforderlich.  Hier bieten sich Kafka-Streams und State Repositories an.  Kafka-Streams-Anwendungen werden auf einem ganzen Cluster von Knoten ausgef√ºhrt, die bestimmte Themen zusammen verwenden.  Jedem Knoten wird eine Reihe von konsumierten Themensegmenten zugewiesen, genau wie beim normalen Kafka-Konsumenten.  Kafka-Streams bieten jedoch Datenoperationen auf h√∂herer Ebene, die das Erstellen abgeleiteter Streams erheblich vereinfachen. <br><br>  Eine solche Operation in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka-Streams</a> ist die Faltung eines Streams im lokalen Speicher.  Jeder lokale Speicher enth√§lt nur Daten aus den Segmenten, die von einem bestimmten Knoten verwendet werden.  <i>Standardm√§√üig</i> sind zwei lokale Speicherimplementierungen verf√ºgbar: <i>im RAM</i> und basierend auf <i>RocksDB</i> . <br><br>  Zur√ºck zum Thema Ereignisregistrierung: Wir stellen fest, dass es m√∂glich ist, den Ereignisstrom im <b>Statusspeicher zu reduzieren, indem</b> auf dem lokalen Knoten der "aktuelle Status" jeder Entit√§t aus den dem Knoten zugewiesenen Segmenten gehalten wird.  Wenn wir die Implementierung des auf RocksDB basierenden Statusspeichers verwenden, h√§ngt die Anzahl der Entit√§ten, die wir auf einem einzelnen Knoten verfolgen k√∂nnen, nur von der Gr√∂√üe des Speicherplatzes ab. <br><br>  So sieht die Faltung von Ereignissen im lokalen Speicher bei Verwendung der Java-API aus (serde bedeutet "Serializer / Deserializer"): <br><br><pre> <code class="java hljs">KStreamBuilder builder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KStreamBuilder(); builder.stream(keySerde, valueSerde, <span class="hljs-string"><span class="hljs-string">"my_entity_events"</span></span>) .groupByKey(keySerde, valueSerde) <span class="hljs-comment"><span class="hljs-comment">//  :     .reduce((currentState, event) -&gt; ..., "my_entity_store"); .toStream(); //     return builder;</span></span></code> </pre> <br>  Ein vollst√§ndiges Beispiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">f√ºr die Auftragsabwicklung auf Basis von Microservices finden Sie</a> auf der Confluent-Website. <br><br>  (BEARBEITEN: Wie von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sergei Egorov</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nikita Salnikov</a> auf Twitter festgestellt, m√ºssen Sie f√ºr ein System mit Ereignisprotokollierung wahrscheinlich die Standard-Datenspeichereinstellungen in Kafka √§ndern, damit keine Zeit- oder Gr√∂√üenbeschr√§nkungen funktionieren, und optional , Datenkomprimierung aktivieren.) <br><br>  <b>Aktuellen Status anzeigen</b> <br><br>  Wir haben ein Status-Repository erstellt, in dem sich die aktuellen Status aller Entit√§ten befinden, die aus Segmenten stammen, die dem Knoten zugewiesen sind. Wie kann dieses Repository jetzt angefordert werden?  Wenn die Anforderung lokal ist (dh von demselben Knoten stammt, auf dem sich das Repository befindet), ist alles ziemlich einfach: <br><br><pre> <code class="java hljs">streams .store(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, QueryableStoreTypes.keyValueStore()); .get(entityId);</code> </pre> <br>  Was aber, wenn wir Daten anfordern m√∂chten, die sich auf einem anderen Knoten befinden?  Und wie kann man herausfinden, was dieser Knoten ist?  Hier ist eine weitere k√ºrzlich in Kafka eingef√ºhrte Funktion n√ºtzlich: <b>interaktive Abfragen</b> .  Mit ihrer Hilfe k√∂nnen Sie auf die Kafka-Metadaten zugreifen und herausfinden, welcher Knoten das Themensegment mit der angegebenen <code>id</code> (in diesem Fall wird implizit das Tool zur Themensegmentierung verwendet): <br><br><pre> <code class="java hljs">metadataService .streamsMetadataForStoreAndKey(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, entityId, keySerde)</code> </pre> <br>  Als n√§chstes m√ºssen Sie die Anforderung irgendwie an den richtigen Knoten umleiten.  Bitte beachten Sie: Die spezifische Art und Weise, wie die standort√ºbergreifende Kommunikation implementiert und gehandhabt wird - ob REST, Akka-Remote oder eine andere -, geh√∂rt nicht zum Verantwortungsbereich von Kafka-Streams.  Kafka bietet einfach Zugriff auf den Statusspeicher und gibt Auskunft dar√ºber, auf welchem ‚Äã‚ÄãKnoten sich der Statusspeicher f√ºr die angegebene <code>id</code> . <br><br>  <b>Notfallwiederherstellung</b> <br><br>  State Stores sehen gut aus, aber was passiert, wenn ein Knoten ausf√§llt?  Die Rekonstruktion eines lokalen staatlichen Speichers f√ºr ein bestimmtes Segment kann ebenfalls eine kostspielige Operation sein.  Dies kann f√ºr l√§ngere Zeit zu erh√∂hten Verz√∂gerungen oder zum Verlust von Anforderungen f√ºhren, da Kafka-Streams neu ausgeglichen werden m√ºssen (nach dem Hinzuf√ºgen oder Entfernen eines Knotens). <br><br>  Aus diesem Grund werden standardm√§√üig langfristige Statusspeicher protokolliert. Das hei√üt, alle am Speicher vorgenommenen √Ñnderungen werden zus√§tzlich in das Changelog-Thema geschrieben.  Dieses Thema ist komprimiert (da wir f√ºr jede <code>id</code> nur den letzten Datensatz ohne √Ñnderungsverlauf interessieren, da der Verlauf in den Ereignissen selbst gespeichert ist) - daher ist er so klein wie m√∂glich.  Aus diesem Grund kann die Wiederherstellung des Speichers auf einem anderen Knoten viel schneller erfolgen. <br><br>  Bei einer Neuausrichtung sind in diesem Fall jedoch immer noch Verz√∂gerungen m√∂glich.  Um sie weiter zu reduzieren, bieten kafka-Streams die M√∂glichkeit, mehrere <b>Sicherungsreplikate</b> ( <code>num.standby.replicas</code> ) f√ºr jedes Repository zu <code>num.standby.replicas</code> .  Diese Replikate wenden alle Aktualisierungen an, die aus Themen mit √Ñnderungsprotokollen abgerufen wurden, sobald sie verf√ºgbar sind, und k√∂nnen f√ºr ein bestimmtes Segment in den Hauptstatus-Speichermodus wechseln, sobald der aktuelle Hauptspeicher ausf√§llt. <br><br>  <b>Koh√§renz</b> <br><br>  Mit den Standardeinstellungen bietet Kafka mindestens eine einmalige Lieferung.  Das hei√üt, im Falle eines Knotenausfalls k√∂nnen einige Nachrichten mehrmals zugestellt werden.  Beispielsweise ist es m√∂glich, dass ein bestimmtes Ereignis zweimal auf den Statusspeicher angewendet wird, wenn das System abst√ºrzt, nachdem der Statusspeicher in das Protokoll ge√§ndert wurde, jedoch bevor der Offset f√ºr dieses bestimmte Ereignis ausgef√ºhrt wurde.  Vielleicht verursacht dies keine Schwierigkeiten: Unsere Statusaktualisierungsfunktion ( <code>Event = &amp;gt State =&amp;gt State</code> ) kann solche Situationen ganz normal bew√§ltigen.  Es ist jedoch m√∂glicherweise nicht in der Lage, dies zu bew√§ltigen: In einem solchen Fall k√∂nnen die von Kafka gew√§hrten Garantien einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">streng einmaligen Lieferung</a> verwendet werden.  Solche Garantien gelten nur beim Lesen und Schreiben von Kafka-Themen. Dies tun wir jedoch hier: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Im Hintergrund werden alle Eintr√§ge in Kafka-Themen darauf reduziert, das √Ñnderungsprotokoll f√ºr den</a> Statusspeicher <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu aktualisieren</a> und Offsets durchzuf√ºhren.  All dies kann <b>in Form von Transaktionen erfolgen</b> . <br><br>  Wenn unsere Funktion zum Aktualisieren des Status dies erfordert, k√∂nnen wir daher die Semantik der Verarbeitung von Fl√ºssen "ausschlie√ülich einmalig" mithilfe einer einzigen Konfigurationsoption aktivieren: <code>processing.guarantee</code> .  Aus diesem Grund sinkt die Leistung, aber nichts ist umsonst. <br><br>  <b>Ereignis h√∂ren</b> <br><br>  Nachdem wir uns nun mit den Grundlagen befasst haben - den ‚Äûaktuellen Status‚Äú abzufragen und ihn f√ºr jede Entit√§t zu aktualisieren -, was ist mit dem Ausl√∂sen von <b>Nebenwirkungen</b> ?  Irgendwann wird dies notwendig sein, zum Beispiel f√ºr: <br><br><ul><li>  Senden von Benachrichtigungs-E-Mails </li><li>  Indizierung von Suchmaschinenentit√§ten </li><li>  Aufrufen externer Dienste √ºber REST (oder SOAP, CORBA usw.) </li></ul><br>  Alle diese Aufgaben sind bis zu einem gewissen Grad blockierend und beziehen sich auf E / A-Vorg√§nge (dies ist nat√ºrlich f√ºr Nebenwirkungen). Daher ist es wahrscheinlich keine gute Idee, sie im Rahmen der Statusaktualisierungslogik auszuf√ºhren: Infolgedessen kann die H√§ufigkeit von Fehlern in der Hauptschleife zunehmen Ereignisse und in Bezug auf die Leistung wird es einen Engpass geben. <br><br>  Dar√ºber hinaus kann eine Funktion mit Statusaktualisierungslogik (E <code>Event = &amp;gt State =&amp;gt State</code> Status <code>Event = &amp;gt State =&amp;gt State</code> Status) mehrmals ausgef√ºhrt werden (bei Fehlern oder Neustarts), und meistens m√∂chten wir die Anzahl der F√§lle minimieren, in denen Nebenwirkungen f√ºr ein bestimmtes Ereignis mehrmals ausgef√ºhrt werden. <br><br>  Gl√ºcklicherweise haben wir, da wir mit Kafka-Themen arbeiten, einiges an Flexibilit√§t.  In der Flows-Phase, in der der Statusspeicher aktualisiert wird, k√∂nnen Ereignisse unver√§ndert (oder, falls erforderlich, auch in modifizierter Form) ausgegeben werden, und der resultierende Stream / das resultierende Thema (in Kafka sind diese Konzepte gleichwertig) kann nach Belieben verwendet werden.  Dar√ºber hinaus kann es entweder vor oder nach der Statusaktualisierungsphase verwendet werden.  Schlie√ülich k√∂nnen wir steuern, wie wir Nebenwirkungen ausl√∂sen: mindestens einmal oder h√∂chstens einmal.  Die erste Option ist verf√ºgbar, wenn Sie den Versatz des verbrauchten Themenereignisses erst ausf√ºhren, nachdem alle Nebenwirkungen erfolgreich abgeschlossen wurden.  Umgekehrt f√ºhren wir mit maximal einem Lauf Verschiebungen durch, bis Nebenwirkungen ausgel√∂st werden. <br><br>  Es gibt verschiedene M√∂glichkeiten, um Nebenwirkungen auszul√∂sen, die von der spezifischen praktischen Situation abh√§ngen.  Zun√§chst k√∂nnen Sie die Kafka-Streams-Phase definieren, in der Nebenwirkungen f√ºr jedes Ereignis als Teil der Stream-Verarbeitungsfunktion ausgel√∂st werden. <br>  Das Einrichten eines solchen Mechanismus ist recht einfach, aber diese L√∂sung ist nicht flexibel, wenn Sie Wiederholungsversuche durchf√ºhren, Offsets steuern und Offsets f√ºr viele Ereignisse gleichzeitig konkurrieren m√ºssen.  In solch komplexeren F√§llen kann es zweckm√§√üiger sein, die Verarbeitung unter Verwendung von beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">reaktivem Kafka</a> oder einem anderen Mechanismus zu bestimmen, der Kafka-Themen "direkt" konsumiert. <br><br>  Es ist auch m√∂glich, dass ein Ereignis <b>andere Ereignisse ausl√∂st.</b> Beispielsweise kann das Ereignis "Bestellung" die Ereignisse "Vorbereitung f√ºr den Versand" und "Kundenbenachrichtigung" ausl√∂sen.  Dies kann auch in der Kafka-Streams-Phase implementiert werden. <br><br>  Wenn wir Ereignisse oder Daten, die aus Ereignissen extrahiert wurden, in einer Datenbank oder Suchmaschine speichern m√∂chten, beispielsweise in ElasticSearch oder PostgreSQL, k√∂nnen wir den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka Connect-</a> Connector verwenden, der f√ºr uns alle Details zum Verbrauch von Themen verarbeitet. <br><br>  <b>Ansichten und Projektionen erstellen</b> <br><br>  In der Regel beschr√§nken sich die Systemanforderungen nicht darauf, nur einzelne Entit√§tsstr√∂me abzufragen und zu verarbeiten.  Aggregation, Kombination mehrerer Ereignisstr√∂me sollte ebenfalls unterst√ºtzt werden.  Solche kombinierten Streams werden oft als <b>Projektionen bezeichnet</b> . Wenn sie reduziert sind, k√∂nnen sie zum Erstellen von <b>Darstellungen von Daten verwendet werden</b> .  Ist es m√∂glich, sie mit Kafka umzusetzen? <br><br><img src="https://habrastorage.org/webt/yc/r2/jt/ycr2jtvibrdg7wy0lhin1ehwu1y.png"><br><br>  Wieder ja!  Denken Sie daran, dass wir uns im Prinzip nur mit dem Thema Kafka befassen, in dem unsere Ereignisse gespeichert sind.  Daher haben wir die ganze Macht der rohen Kafka-Verbraucher / Produzenten, des Kafka-Streams-Kombinierers und sogar von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">KSQL</a> - all dies wird f√ºr uns n√ºtzlich sein, um Projektionen zu definieren.  Mit Kafka-Streams k√∂nnen Sie beispielsweise einen Stream filtern, anzeigen, nach Schl√ºsseln gruppieren, in tempor√§ren Fenstern oder Sitzungsfenstern aggregieren usw.  entweder auf Codeebene oder mit SQL-√§hnlichem KSQL. <br><br>  Solche Flows k√∂nnen mithilfe von State Stores und interaktiven Abfragen f√ºr eine lange Zeit gespeichert und f√ºr Abfragen bereitgestellt werden, genau wie wir es mit einzelnen Entity Flows getan haben. <br><br>  <b>Was weiter</b> <br><br>  Um den unendlichen Fluss von Ereignissen w√§hrend der Entwicklung des Systems zu verhindern, kann eine Komprimierungsoption wie das Speichern von <b>Schnappsch√ºssen des</b> ‚Äûaktuellen Status‚Äú hilfreich sein.  Daher k√∂nnen wir uns darauf beschr√§nken, nur einige aktuelle Schnappsch√ºsse und Ereignisse zu speichern, die nach ihrer Erstellung aufgetreten sind. <br><br>  Obwohl Kafka keine direkte Unterst√ºtzung f√ºr Snapshots bietet (und in einigen anderen Systemen, die nach dem Prinzip der Ereignisaufzeichnung arbeiten), k√∂nnen Sie diese Art von Funktionalit√§t auf jeden Fall selbst hinzuf√ºgen, indem Sie einige der oben genannten Mechanismen verwenden, z. B. Streams, Verbraucher, staatliche Gesch√§fte usw. d. <br><br>  <b>Zusammenfassung</b> <br><br>  Obwohl Kafka anfangs nicht mit Blick auf das Ereignisregistrierungsparadigma entwickelt wurde, handelt es sich tats√§chlich um eine Streaming-Daten-Engine mit Unterst√ºtzung f√ºr <b>Themenreplikation</b> , Segmentierung, <b>Status-Repositorys</b> und <b>Streaming-APIs</b> und ist gleichzeitig sehr flexibel.  Daher k√∂nnen Sie zus√§tzlich zu Kafka problemlos ein Ereignisregistrierungssystem implementieren.  Da wir vor dem Hintergrund von allem, was passiert, immer ein Kafka-Thema haben, erhalten wir zus√§tzliche Flexibilit√§t, da wir entweder mit Streaming-APIs auf hoher Ebene oder mit Verbrauchern auf niedriger Ebene arbeiten k√∂nnen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424739/">https://habr.com/ru/post/de424739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424729/index.html">Warum hat der Compiler meine bedingte Schleife in eine Endlosschleife verwandelt?</a></li>
<li><a href="../de424731/index.html">Hot Tech Support-Verlauf oder Warum l√∂scht AutoCAD Proxy-Objekte?</a></li>
<li><a href="../de424733/index.html">Blaue Pille STM32F103 als SPS</a></li>
<li><a href="../de424735/index.html">Wie funktioniert es und wie funktioniert die Konversationspsychotherapie √ºberhaupt?</a></li>
<li><a href="../de424737/index.html">42. Protokoll des Lebens, des Universums und all das: "Abschiedsrede"</a></li>
<li><a href="../de424741/index.html">Leute, lasst uns in Ruhe leben oder √ºber das Passwortfeld bei der Registrierung</a></li>
<li><a href="../de424745/index.html">Die GosSOPKI-Aktivit√§t hat zugenommen</a></li>
<li><a href="../de424747/index.html">Der Ort, an dem der Klang lebt</a></li>
<li><a href="../de424751/index.html">Wie das einheitliche biometrische System funktioniert</a></li>
<li><a href="../de424753/index.html">Was ist neu in YouTrack 2018.3?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
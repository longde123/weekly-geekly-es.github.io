<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>โผ๏ธ ๐ ๐จ๐ฟโ๐ฌ ุฏููู ุจูุฑุช ุงูุชูุทูุฑ ุจุณูุท ๐คณ๐พ ๐ โ๏ธ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ุฅุฐุง ููุช ููุชููุง ุจุงูุชุนูู ุงูุขูู ุ ูุฑุจูุง ุชููู ูุฏ ุณูุนุช ุนู BERT ูุงููุญููุงุช. 


 ูุนุฏ BERT ูููุฐุฌูุง ูุบูููุง ูู Google ุ ุญูุซ ูุนุฑุถ ุฃุญุฏุซ ุงููุชุงุฆุฌ ุจูุงูุด ูุงุณุน ูู ุนุฏุฏ ู...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ุฏููู ุจูุฑุช ุงูุชูุทูุฑ ุจุณูุท</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/485290/" style=";text-align:right;direction:rtl"><p style=";text-align:right;direction:rtl">  ุฅุฐุง ููุช ููุชููุง ุจุงูุชุนูู ุงูุขูู ุ ูุฑุจูุง ุชููู ูุฏ ุณูุนุช ุนู BERT ูุงููุญููุงุช. </p><br><p style=";text-align:right;direction:rtl">  ูุนุฏ BERT ูููุฐุฌูุง ูุบูููุง ูู Google ุ ุญูุซ ูุนุฑุถ ุฃุญุฏุซ ุงููุชุงุฆุฌ ุจูุงูุด ูุงุณุน ูู ุนุฏุฏ ูู ุงูููุงู.  ุฃุตุจุญ ุจูุฑุช ุ ูุงููุญููุงุช ุนููููุง ุ ุฎุทูุฉ ุฌุฏูุฏุฉ ุชูุงููุง ูู ุชุทููุฑ ุฎูุงุฑุฒููุงุช ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ (NLP).  ูููู ุงูุงุทูุงุน <a href="https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional">ุนูู</a> ุงูููุงูุฉ ุงููุชุนููุฉ ุจูู ู "ุงูุชุฑุชูุจ" ููุฎุชูู ุงููุนุงููุฑ <a href="https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional">ุนูู ูููุน Papers With Code</a> . </p><br><p style=";text-align:right;direction:rtl">  ููุงู ูุดููุฉ ูุงุญุฏุฉ ูุน ุจูุฑุช: ุฅููุง ูุดููุฉ ูู ุงูุงุณุชุฎุฏุงู ูู ุงููุธู ุงูุตูุงุนูุฉ.  ุจูุฑุช ูุงุนุฏุฉ ุชุญุชูู ุนูู 110M ุงููุนููุงุช ุ ุจูุฑุช ูุจูุฑุฉ - 340M.  ูุธุฑูุง ููุฐุง ุงูุนุฏุฏ ุงููุจูุฑ ูู ุงููุนููุงุช ุ ูุตุนุจ ุชูุฒูู ูุฐุง ุงูุทุฑุงุฒ ุนูู ุงูุฃุฌูุฒุฉ ุฐุงุช ุงูููุงุฑุฏ ุงููุญุฏูุฏุฉ ุ ูุซู ุงูููุงุชู ุงููุญูููุฉ.  ุจุงูุฅุถุงูุฉ ุฅูู ุฐูู ุ ูุฅู ุงูููุช ุงูุทููู ููุงุณุชุฏูุงู ูุฌุนู ูุฐุง ุงููููุฐุฌ ุบูุฑ ููุงุณุจ ุญูุซ ุชููู ุณุฑุนุฉ ุงูุงุณุชุฌุงุจุฉ ุญุงุณูุฉ.  ูุฐูู ุ ูุฅู ุฅูุฌุงุฏ ุทุฑู ูุชุณุฑูุน BERT ูู ููุถูุน ุณุงุฎู ููุบุงูุฉ. </p><br><p style=";text-align:right;direction:rtl">  ูุฏููุง ูู Avito ูู ูุซูุฑ ูู ุงูุฃุญูุงู ูุญู ูุดุงูู ุชุตููู ุงููุต.  ูุฐู ูููุฉ ูููุฐุฌูุฉ ููุชุนูู ุงูุขูู ุชู ุฏุฑุงุณุชูุง ุฌูุฏูุง.  ูููู ููุงู ุฏุงุฆูุง ุฅุบุฑุงุก ููุญุงููุฉ ุดูุก ุฌุฏูุฏ.  ููุฏุช ูุฐู ุงูููุงูุฉ ูู ูุญุงููุฉ ุชุทุจูู ุจูุฑุช ูู ููุงู ุงูุชุนูู ุงูุขูู ุงูููููุฉ.  ููู ุ ุณุฃูุถุญ ููู ููููู ุชุญุณูู ุฌูุฏุฉ ุงููููุฐุฌ ุงูุญุงูู ุจุดูู ูุจูุฑ ุจุงุณุชุฎุฏุงู BERT ุฏูู ุฅุถุงูุฉ ุจูุงูุงุช ุฌุฏูุฏุฉ ูุฏูู ุชุนููุฏ ุงููููุฐุฌ. </p><br><p style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/c_/po/z2/c_poz2e3dkggx7ekt3gn_9wva3g.png"></p><a name="habracut"></a><br><h2 id="knowledge-distillation-kak-metod-uskoreniya-neyronnyh-setey" style=";text-align:right;direction:rtl">  ุชูุทูุฑ ุงููุนุฑูุฉ ููุณููุฉ ูุชุณุฑูุน ุงูุดุจูุงุช ุงูุนุตุจูุฉ </h2><br><p style=";text-align:right;direction:rtl">  ููุงู ุนุฏุฉ ุทุฑู ูุชุณุฑูุน / ุชุฎููู ุงูุดุจูุงุช ุงูุนุตุจูุฉ.  ูุชู ูุดุฑ ุงููุฑุงุฌุนุฉ ุงูุฃูุซุฑ ุชูุตููุงู ุงูุชู ูุงุจูุชูุง <a href="https://blog.inten.to/speeding-up-bert-5528e18bb4ea">ุนูู ูุฏููุฉ Intento ุนูู ุงููุชูุณุท</a> . </p><br><p style=";text-align:right;direction:rtl">  ูููู ุชูุณูู ุงูุทุฑู ุชูุฑูุจูุง ุฅูู ุซูุงุซ ูุฌููุนุงุช: </p><br><ol style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  ุชุบููุฑ ุจููุฉ ุงูุดุจูุฉ. </li><li style=";text-align:right;direction:rtl">  ุถุบุท ุงููููุฐุฌ (ุงูููู ุ ุงูุชูููู). </li><li style=";text-align:right;direction:rtl">  ุชูุทูุฑ ุงููุนุฑูุฉ. </li></ol><br><p style=";text-align:right;direction:rtl">  ุฅุฐุง ูุงูุช ุฃูู ุทุฑููุชูู ูุนุฑููุฉ ููุชูููุฉ ูุณุจููุง ุ ูุฅู ุงูุทุฑููุฉ ุงูุซุงูุซุฉ ุชููู ุฃูู ุดููุนูุง.  ูุฃูู ูุฑุฉ ุ ุงูุชุฑุญ ุฑูุชุด ูุงุฑูุงูุง ููุฑุฉ ุงูุชูุทูุฑ <a href="https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf">ูู ููุงู "ุถุบุท ุงููููุฐุฌ"</a> .  ุฌููุฑูุง ุจุณูุท: ููููู ุชุฏุฑูุจ ูููุฐุฌ ุฎููู ุงููุฒู ูุญุงูู ุณููู ูููุฐุฌ ุงููุนูู ุฃู ุญุชู ูุฌููุนุฉ ูู ุงูููุงุฐุฌ.  ูู ุญุงูุชูุง ุ ุณูููู ุงููุนูู ุจูุฑุช ุ ูุณูููู ุงูุทุงูุจ ุฃู ูููุฐุฌ ุถูุก. </p><br><h2 id="zadacha" style=";text-align:right;direction:rtl">  ูููุฉ </h2><br><p style=";text-align:right;direction:rtl">  ุฏุนูุง ูุญูู ุงูุชูุทูุฑ ุจุงุณุชุฎุฏุงู ุงูุชุตููู ุงูุซูุงุฆู ููุซุงู.  ุฎุฐ ูุฌููุนุฉ ุจูุงูุงุช SST-2 ุงูููุชูุญุฉ ูู ูุฌููุนุฉ ุงูููุงู ุงูููุงุณูุฉ ุงูุชู ุชุฎุชุจุฑ ููุงุฐุฌ NLP. </p><br><p style=";text-align:right;direction:rtl">  ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฐู ุนุจุงุฑุฉ ุนู ูุฌููุนุฉ ูู ูุฑุงุฌุนุงุช ุงูุฃููุงู ูุน IMDb ููุฒุนุฉ ุญุณุจ ุงูููู ุงูุนุงุทูู - ุฅูุฌุงุจูุฉ ุฃู ุณูุจูุฉ.  ุงูุฏูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฐู ูู ุงูุฏูุฉ. </p><br><h2 id="obuchenie-bert-based-modeli-ili-uchitelya" style=";text-align:right;direction:rtl">  ุชุฏุฑูุจ ุงูููุงุฐุฌ ุงููุนุชูุฏุฉ ุนูู BERT ุฃู "ุงููุนูููู" </h2><br><p style=";text-align:right;direction:rtl">  ุจุงุฏุฆ ุฐู ุจุฏุก ุ ุชุญุชุงุฌ ุฅูู ุชุฏุฑูุจ ุงููููุฐุฌ "ุงููุจูุฑ" ุงููุงุฆู ุนูู BERT ุ ูุงูุฐู ุณูุตุจุญ ูุฏุฑุณูุง.  ุฃุณูู ุทุฑููุฉ ููููุงู ุจุฐูู ูู ุฃุฎุฐ ุงูุฒุฎุงุฑู ูู BERT ูุชุฏุฑูุจ ุงููุตูู ุนูููุง ุ ุฅุถุงูุฉ ุทุจูุฉ ูุงุญุฏุฉ ุฅูู ุงูุดุจูุฉ. </p><br><p style=";text-align:right;direction:rtl"> ุจูุถู <a href="https://github.com/huggingface/transformers">ููุชุจุฉ ุงููุญููุงุช ุ ูู</a> ุงูุณูู ุงูููุงู ุจุฐูู ุ ูุธุฑูุง ููุฌูุฏ ูุฆุฉ ุทุฑุงุฒ BertForSequenceClassification ุฌุงูุฒุฉ.  ูู ุฑุฃูู ุ ุชู <a href="https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca">ูุดุฑ</a> ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุงูุฃูุซุฑ ุชูุตููุง ูููููููุง ูุชุฏุฑูุณ ูุฐุง ุงููููุฐุฌ ูู <a href="https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca">ููุจู Towards Data Science</a> . </p><br><p style=";text-align:right;direction:rtl">  ุฏุนููุง ูุชุฎูู ุฃููุง ุญุตููุง ุนูู ูููุฐุฌ BertForSequenceClassification ุงููุฏุฑุจูู.  ูู ุญุงูุชูุง ุ num_labels = 2 ุ ูุธุฑูุง ูุฃู ูุฏููุง ุชุตููููุง ุซูุงุฆููุง.  ุณูู ูุณุชุฎุฏู ูุฐุง ุงููููุฐุฌ "ููุนูู". </p><br><h2 id="obuchenie-uchenika" style=";text-align:right;direction:rtl">  ุชุนูู "ุงูุทุงูุจ" </h2><br><p style=";text-align:right;direction:rtl">  ููููู ุฃู ุชุฃุฎุฐ ุฃู ููุฏุณุฉ ูุทุงูุจ: ุดุจูุฉ ุนุตุจูุฉ ุ ูููุฐุฌ ุฎุทู ุ ุดุฌุฑุฉ ูุฑุงุฑ.  ุฏุนููุง ูุญุงูู ุชุนููู BiLSTM ูุชุตูุฑ ุฃูุถู.  ููุจุฏุก ุ ุณูููู ุจุชุฏุฑูุณ BiLSTM ุจุฏูู BERT. </p><br><p style=";text-align:right;direction:rtl">  ูุฅุฑุณุงู ุงููุต ุฅูู ูุฏุฎูุงุช ุงูุดุจูุฉ ุงูุนุตุจูุฉ ุ ุชุญุชุงุฌ ุฅูู ุชูุฏููู ููุชุฌู.  ุฅุญุฏู ุฃุณูู ุงูุทุฑู ูู ุชุนููู ูู ูููุฉ ุฅูู ููุฑุณูุง ูู ุงููุงููุณ.  ุณูุชุฃูู ุงููุงููุณ ูู ุฃูุถู ุงููููุงุช ุดููุนูุง ูู ูุฌููุนุฉ ุจูุงูุงุชูุง ุจุงูุฅุถุงูุฉ ุฅูู ูููุชูู ููุฎุฏูุฉ: "pad" - "ุงููููุฉ ุงูููููุฉ" ุจุญูุซ ุชููู ุฌููุน ุงูุชุณูุณูุงุช ูุชูุงุซูุฉ ุงูุทูู ู "unk" - ููููุงุช ุฎุงุฑุฌ ุงููุงููุณ.  ุณูุจูู ุงููุงููุณ ุจุงุณุชุฎุฏุงู ุงููุฌููุนุฉ ุงูููุงุณูุฉ ูู ุงูุฃุฏูุงุช ูู torchtext.  ูู ุฃุฌู ุงูุจุณุงุทุฉ ุ ูู ุฃุณุชุฎุฏู ุฒุฎุงุฑู ุงููููุงุช ุงููุฏุฑุจุฉ ูุณุจููุง. <br></p><br><pre style=";text-align:right;direction:rtl"><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchtext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> data <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_vocab</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(X)</span></span></span><span class="hljs-function">:</span></span> X_split = [t.split() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> X] text_field = data.Field() text_field.build_vocab(X_split, max_size=<span class="hljs-number"><span class="hljs-number">10000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text_field <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pad</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(seq, max_len)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(seq) &lt; max_len: seq = seq + [<span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>] * (max_len - len(seq)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> seq[<span class="hljs-number"><span class="hljs-number">0</span></span>:max_len] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_indexes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vocab, words)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [vocab.stoi[w] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> words] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_dataset</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, y_real)</span></span></span><span class="hljs-function">:</span></span> torch_x = torch.tensor(x, dtype=torch.long) torch_y = torch.tensor(y, dtype=torch.float) torch_real_y = torch.tensor(y_real, dtype=torch.long) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> TensorDataset(torch_x, torch_y, torch_real_y)</code> </pre> <br><h3 id="model-bilstm" style=";text-align:right;direction:rtl">  ูููุฐุฌ BiLSTM </h3><br><p style=";text-align:right;direction:rtl">  ุณูุจุฏู ุฑูุฒ ุงููููุฐุฌ ููุง ููู: </p><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.autograd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Variable <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SimpleLSTM</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, batch_size, device=None)</span></span></span><span class="hljs-function">:</span></span> super(SimpleLSTM, self).__init__() self.batch_size = batch_size self.hidden_dim = hidden_dim self.n_layers = n_layers self.embedding = nn.Embedding(input_dim, embedding_dim) self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout) self.fc = nn.Linear(hidden_dim * <span class="hljs-number"><span class="hljs-number">2</span></span>, output_dim) self.dropout = nn.Dropout(dropout) self.device = self.init_device(device) self.hidden = self.init_hidden() @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_device</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(device)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> device <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> torch.device(<span class="hljs-string"><span class="hljs-string">'cuda'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> device <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_hidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (Variable(torch.zeros(<span class="hljs-number"><span class="hljs-number">2</span></span> * self.n_layers, self.batch_size, self.hidden_dim).to(self.device)), Variable(torch.zeros(<span class="hljs-number"><span class="hljs-number">2</span></span> * self.n_layers, self.batch_size, self.hidden_dim).to(self.device))) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, text, text_lengths=None)</span></span></span><span class="hljs-function">:</span></span> self.hidden = self.init_hidden() x = self.embedding(text) x, self.hidden = self.rnn(x, self.hidden) hidden, cell = self.hidden hidden = self.dropout(torch.cat((hidden[<span class="hljs-number"><span class="hljs-number">-2</span></span>, :, :], hidden[<span class="hljs-number"><span class="hljs-number">-1</span></span>, :, :]), dim=<span class="hljs-number"><span class="hljs-number">1</span></span>)) x = self.fc(hidden) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x</code> </pre> <br><h3 id="obuchenie" style=";text-align:right;direction:rtl">  ุชุฏุฑูุจ </h3><br><p style=";text-align:right;direction:rtl">  ุจุงููุณุจุฉ ุฅูู ูุฐุง ุงููููุฐุฌ ุ ุณูููู ุจูุนุฏ ูุชุฌู ุงูุฅุฎุฑุงุฌ (batch_size ุ output_dim).  ูู ุงูุชุฏุฑูุจ ุ ุณูู ูุณุชุฎุฏู logloss ุงููุนุชุงุฏ.  ูุฏู PyTorch ูุฆุฉ BCEWithLogitsLoss ุงูุชู ุชุฌูุน ุจูู ุงูุณููู ูุนุจุฑ ุฅูุชุฑูุจูุง.  ูุง ุชุญุชุงุฌู. </p><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> criterion = torch.nn.BCEWithLogitsLoss() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> criterion(output, real_label.float())</code> </pre> <br><p style=";text-align:right;direction:rtl">  ุฑูุฒ ูุนุตุฑ ูุงุญุฏ ูู ุงูุชุนูู: </p><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_optimizer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model)</span></span></span><span class="hljs-function">:</span></span> optimizer = torch.optim.Adam(model.parameters()) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, <span class="hljs-number"><span class="hljs-number">2</span></span>, gamma=<span class="hljs-number"><span class="hljs-number">0.9</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> optimizer, scheduler <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">epoch_train_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, dataset, loss_func, batch_size)</span></span></span><span class="hljs-function">:</span></span> train_loss = <span class="hljs-number"><span class="hljs-number">0</span></span> train_sampler = RandomSampler(dataset) data_loader = DataLoader(dataset, sampler=train_sampler, batch_size=batch_size, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) model.train() optimizer, scheduler = get_optimizer(model) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, (text, bert_prob, real_label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(tqdm(data_loader, desc=<span class="hljs-string"><span class="hljs-string">'Train'</span></span>)): text, bert_prob, real_label = to_device(text, bert_prob, real_label) model.zero_grad() output = model(text.t(), <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>).squeeze(<span class="hljs-number"><span class="hljs-number">1</span></span>) loss = loss_func(output, bert_prob, real_label) loss.backward() optimizer.step() train_loss += loss.item() scheduler.step() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> train_loss / len(data_loader)</code> </pre> <br><p style=";text-align:right;direction:rtl">  ุฑูุฒ ุงูุชุญูู ุจุนุฏ ุงูุญูุจุฉ: </p><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">epoch_evaluate_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, eval_dataset, loss_func, batch_size)</span></span></span><span class="hljs-function">:</span></span> eval_sampler = SequentialSampler(eval_dataset) data_loader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=batch_size, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) eval_loss = <span class="hljs-number"><span class="hljs-number">0.0</span></span> model.eval() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, (text, bert_prob, real_label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(tqdm(data_loader, desc=<span class="hljs-string"><span class="hljs-string">'Val'</span></span>)): text, bert_prob, real_label = to_device(text, bert_prob, real_label) output = model(text.t(), <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>).squeeze(<span class="hljs-number"><span class="hljs-number">1</span></span>) loss = loss_func(output, bert_prob, real_label) eval_loss += loss.item() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> eval_loss / len(data_loader)</code> </pre> <br><p style=";text-align:right;direction:rtl">  ุฅุฐุง ุชู ุชุฌููุน ูู ูุฐุง ุ ูุณูู ูุญุตู ุนูู ุงูููุฏ ุงูุชุงูู ูุชุฏุฑูุจ ุงููููุฐุฌ: </p><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> (TensorDataset, random_split, RandomSampler, DataLoader, SequentialSampler) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchtext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> data <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">device</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> torch.device(<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> torch.cuda.is_available() <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-string"><span class="hljs-string">"cpu"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_device</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> text = text.to(device()) bert_prob = bert_prob.to(device()) real_label = real_label.to(device()) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text, bert_prob, real_label <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LSTMBaseline</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(object)</span></span></span><span class="hljs-class">:</span></span> vocab_name = <span class="hljs-string"><span class="hljs-string">'text_vocab.pt'</span></span> weights_name = <span class="hljs-string"><span class="hljs-string">'simple_lstm.pt'</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, settings)</span></span></span><span class="hljs-function">:</span></span> self.settings = settings self.criterion = torch.nn.BCEWithLogitsLoss().to(device()) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.criterion(output, real_label.float()) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, text_field)</span></span></span><span class="hljs-function">:</span></span> model = SimpleLSTM( input_dim=len(text_field.vocab), embedding_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_dim=<span class="hljs-number"><span class="hljs-number">128</span></span>, output_dim=<span class="hljs-number"><span class="hljs-number">1</span></span>, n_layers=<span class="hljs-number"><span class="hljs-number">1</span></span>, bidirectional=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, batch_size=self.settings[<span class="hljs-string"><span class="hljs-string">'train_batch_size'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, X, y, y_real, output_dir)</span></span></span><span class="hljs-function">:</span></span> max_len = self.settings[<span class="hljs-string"><span class="hljs-string">'max_seq_length'</span></span>] text_field = get_vocab(X) X_split = [t.split() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> X] X_pad = [pad(s, max_len) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(X_split, desc=<span class="hljs-string"><span class="hljs-string">'pad'</span></span>)] X_index = [to_indexes(text_field.vocab, s) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(X_pad, desc=<span class="hljs-string"><span class="hljs-string">'to index'</span></span>)] dataset = to_dataset(X_index, y, y_real) val_len = int(len(dataset) * <span class="hljs-number"><span class="hljs-number">0.1</span></span>) train_dataset, val_dataset = random_split(dataset, (len(dataset) - val_len, val_len)) model = self.model(text_field) model.to(device()) self.full_train(model, train_dataset, val_dataset, output_dir) torch.save(text_field, os.path.join(output_dir, self.vocab_name)) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">full_train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, model, train_dataset, val_dataset, output_dir)</span></span></span><span class="hljs-function">:</span></span> train_settings = self.settings num_train_epochs = train_settings[<span class="hljs-string"><span class="hljs-string">'num_train_epochs'</span></span>] best_eval_loss = <span class="hljs-number"><span class="hljs-number">100000</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_train_epochs): train_loss = epoch_train_func(model, train_dataset, self.loss, self.settings[<span class="hljs-string"><span class="hljs-string">'train_batch_size'</span></span>]) eval_loss = epoch_evaluate_func(model, val_dataset, self.loss, self.settings[<span class="hljs-string"><span class="hljs-string">'eval_batch_size'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> eval_loss &lt; best_eval_loss: best_eval_loss = eval_loss torch.save(model.state_dict(), os.path.join(output_dir, self.weights_name))</code> </pre> <br><h3 id="distillyaciya" style=";text-align:right;direction:rtl">  ุงูุชูุทูุฑ </h3><br><p style=";text-align:right;direction:rtl">  ููุฑุฉ ุทุฑููุฉ ุงูุชูุทูุฑ ูุฐู ูุฃุฎูุฐุฉ <a href="https://arxiv.org/abs/1903.12136">ูู ููุงู ูุจุงุญุซูู ูู ุฌุงูุนุฉ ูุงุชุฑูู</a> .  ููุง ููุช ุฃุนูุงู ุ ูุฌุจ ุฃู ูุชุนูู "ุงูุทุงูุจ" ุชูููุฏ ุณููู "ุงููุนูู".  ูุง ูู ุจุงูุถุจุท ุงูุณูููุ  ูู ุญุงูุชูุง ุ ูุฐู ูู ุชูุจุคุงุช ูููุฐุฌ ุงููุนูู ูู ูุฌููุนุฉ ุงูุชุฏุฑูุจ.  ูุงูููุฑุฉ ุงูุฃุณุงุณูุฉ ูู ุงุณุชุฎุฏุงู ุฅุฎุฑุงุฌ ุงูุดุจูุฉ ูุจู ุชุทุจูู ูุธููุฉ ุงูุชูุดูุท.  ูู ุงูููุชุฑุถ ุฃูู ุจูุฐู ุงูุทุฑููุฉ ุณูููู ุงููููุฐุฌ ูุงุฏุฑุงู ุนูู ุชุนูู ุงูุชูุซูู ุงูุฏุงุฎูู ุจุดูู ุฃูุถู ูู ุญุงูุฉ ุงูุงุญุชูุงูุงุช ุงูููุงุฆูุฉ. </p><br><p style=";text-align:right;direction:rtl">  ุชูุชุฑุญ ุงูููุงูุฉ ุงูุฃุตููุฉ ุฅุถุงูุฉ ูุตุทูุญ ุฅูู ูุธููุฉ ุงูุฎุณุงุฑุฉ ุ ูุงูุชู ุณุชููู ูุณุคููุฉ ุนู ุงูุฎุทุฃ "ุงูุชูููุฏ" - MSE ุจูู ุณุฌูุงุช ุงูููุงุฐุฌ. </p><br><p style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/hx/_d/w9/hx_dw9ypkcwc_fhgui_jcappoo4.png"></p><br><p style=";text-align:right;direction:rtl">  ููุฐู ุงูุฃุบุฑุงุถ ุ ูุฌุฑู ุชุบููุฑูู ุตุบูุฑูู: ุชุบููุฑ ุนุฏุฏ ูุฎุฑุฌุงุช ุงูุดุจูุฉ ูู 1 ุฅูู 2 ูุชุตุญูุญ ูุธููุฉ ุงูุฎุณุงุฑุฉ. </p><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> a = <span class="hljs-number"><span class="hljs-number">0.5</span></span> criterion_mse = torch.nn.MSELoss() criterion_ce = torch.nn.CrossEntropyLoss() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> a*criterion_ce(output, real_label) + (<span class="hljs-number"><span class="hljs-number">1</span></span>-a)*criterion_mse(output, bert_prob)</code> </pre> <br><p style=";text-align:right;direction:rtl">  ููููู ุฅุนุงุฏุฉ ุงุณุชุฎุฏุงู ูู ุงูุดูุฑุฉ ุงูุชู ูุชุจูุงูุง ุนู ุทุฑูู ุฅุนุงุฏุฉ ุชุนุฑูู ุงููููุฐุฌ ูุงูุฎุณุงุฑุฉ ููุท: </p><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LSTMDistilled</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(LSTMBaseline)</span></span></span><span class="hljs-class">:</span></span> vocab_name = <span class="hljs-string"><span class="hljs-string">'distil_text_vocab.pt'</span></span> weights_name = <span class="hljs-string"><span class="hljs-string">'distil_lstm.pt'</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, settings)</span></span></span><span class="hljs-function">:</span></span> super(LSTMDistilled, self).__init__(settings) self.criterion_mse = torch.nn.MSELoss() self.criterion_ce = torch.nn.CrossEntropyLoss() self.a = <span class="hljs-number"><span class="hljs-number">0.5</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output, bert_prob, real_label)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.a * self.criterion_ce(output, real_label) + (<span class="hljs-number"><span class="hljs-number">1</span></span> - self.a) * self.criterion_mse(output, bert_prob) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, text_field)</span></span></span><span class="hljs-function">:</span></span> model = SimpleLSTM( input_dim=len(text_field.vocab), embedding_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_dim=<span class="hljs-number"><span class="hljs-number">128</span></span>, output_dim=<span class="hljs-number"><span class="hljs-number">2</span></span>, n_layers=<span class="hljs-number"><span class="hljs-number">1</span></span>, bidirectional=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, batch_size=self.settings[<span class="hljs-string"><span class="hljs-string">'train_batch_size'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br><p style=";text-align:right;direction:rtl">  ูุฐุง ูู ุดูุก ุ ุงูุขู ูููุฐุฌูุง ูุชุนูู "ุชูููุฏ". </p><br><h3 id="sravnenie-modeley" style=";text-align:right;direction:rtl">  ููุงุฑูุฉ ุงููููุฐุฌ </h3><br><p style=";text-align:right;direction:rtl">  ูู ุงูููุงูุฉ ุงูุฃุตููุฉ ุ ูุชู ุงูุญุตูู ุนูู ุฃูุถู ูุชุงุฆุฌ ูุชุตููู SST-2 ุนูุฏ 0 = ุ ุนูุฏูุง ูุชุนูู ุงููููุฐุฌ ููุท ุชูููุฏูุง ุ ุฏูู ูุฑุงุนุงุฉ ุงูุนูุงูุงุช ุงูุญููููุฉ.  ูุง ุชุฒุงู ุงูุฏูุฉ ุฃูู ูู BERT ุ ูููููุง ุฃูุถู ุจูุซูุฑ ูู BiLSTM ุงูุนุงุฏูุฉ. </p><br><p style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/0m/y6/g7/0my6g7eahypj6eq3o52arxxldxq.png"></p><br><p style=";text-align:right;direction:rtl">  ุญุงููุช ุชูุฑุงุฑ ูุชุงุฆุฌ ุงูููุงู ุ ูููู ูู ุชุฌุงุฑุจู ุ ุชู ุงูุญุตูู ุนูู ุฃูุถู ูุชูุฌุฉ ุนูุฏ 0.5 =. </p><br><p style=";text-align:right;direction:rtl">  ูุฐู ูู ุงูุทุฑููุฉ ุงูุชู ุชุจุฏู ุจูุง ุงูุฑุณูู ุงูุจูุงููุฉ ููุฎุณุงุฑุฉ ูุงูุฏูุฉ ุนูุฏ ุชุนูู LSTM ุจุงูุทุฑููุฉ ุงููุนุชุงุฏุฉ.  ุจุงูุญูู ุนูู ุณููู ุงูุฎุณุงุฑุฉ ุ ูุฅู ุงููููุฐุฌ ุชุนูู ุจุณุฑุนุฉ ุ ููู ููุงู ูุง ุจุนุฏ ุงูุญูุจุฉ ุงูุณุงุฏุณุฉ ุ ุจุฏุฃ ุฅุนุงุฏุฉ ุงูุชุฏุฑูุจ. </p><br><p style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/lk/bg/rn/lkbgrnank6obtu7pewsoalba9yk.png"></p><br><p style=";text-align:right;direction:rtl">  ุงูุฑุณูู ุงูุจูุงููุฉ ุชูุทูุฑ: </p><br><p style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/gl/u5/7g/glu57giappdlhkc31wlpdulsdkc.png"></p><br><p style=";text-align:right;direction:rtl">  BiLSTM ุงูููุทุฑ ูู ุฃูุถู ุจุงุณุชูุฑุงุฑ ูู ุงููุนุชุงุฏ.  ูู ุงูููู ุฃู ุชููู ูุชุทุงุจูุฉ ุชูุงูุง ูู ุงูููุฏุณุฉ ุงููุนูุงุฑูุฉ ุ ูุงููุฑู ุงููุญูุฏ ูู ูู ุทุฑููุฉ ุงูุชุฏุฑูุณ.  <a href="https://github.com/pvgladkov/knowledge-distillation/tree/master/experiments/sst2">ููุฏ ูุดุฑุช</a> ุฑูุฒ ุงูุชุฏุฑูุจ ุงููุงูู <a href="https://github.com/pvgladkov/knowledge-distillation/tree/master/experiments/sst2">ุนูู ุฌูุซุจ</a> . </p><br><h2 id="zaklyuchenie" style=";text-align:right;direction:rtl">  ุงุณุชูุชุงุฌ </h2><br><p style=";text-align:right;direction:rtl">  ูู ูุฐุง ุงูุฏููู ุ ุญุงููุช ุฃู ุฃุดุฑุญ ุงูููุฑุฉ ุงูุฃุณุงุณูุฉ ูููุฌ ุงูุชูุทูุฑ.  ุชุนุชูุฏ ุงูุจููุฉ ุงููุญุฏุฏุฉ ููุทุงูุจ ุนูู ุงููููุฉ ุงูุชู ูู ูุชูุงูู ุงููุฏ.  ูููู ุจุดูู ุนุงู ุ ูุฐุง ุงูููุฌ ูุงุจู ููุชุทุจูู ูู ุฃู ูููุฉ ุนูููุฉ.  ุจุณุจุจ ุงูุชุนููุฏ ูู ูุฑุญูุฉ ุงูุชุฏุฑูุจ ุงููููุฐุฌู ุ ููููู ุงูุญุตูู ุนูู ุฒูุงุฏุฉ ูุจูุฑุฉ ูู ุฌูุฏุชู ุ ูุน ุงูุญูุงุธ ุนูู ุงูุจุณุงุทุฉ ุงูุฃุตููุฉ ููููุฏุณุฉ ุงููุนูุงุฑูุฉ. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar485290/">https://habr.com/ru/post/ar485290/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar485278/index.html">ูุฏ ุงููู. ูุณุงุนุฏุฉ ุงููุณููุฉ</a></li>
<li><a href="../ar485280/index.html">ุงูุนูุฏุฉ. FakeDb. ูุถุงูุงุฉ ูุงุนุฏุฉ ุงูุจูุงูุงุช ูู ุงูุงุฎุชุจุงุฑุงุช</a></li>
<li><a href="../ar485284/index.html">ููุฒุงุช SPIKE โข Prime LEGOยฎ Education</a></li>
<li><a href="../ar485286/index.html">ููู ูููุง ุจูุฒู ุงูุจุถุงุฆุน ุฃู ูุตูุฏุฉ ุงูุฃุชูุชุฉ ุงูุตุบูุฑุฉ</a></li>
<li><a href="../ar485288/index.html">ุฃุญุจ ุฃู ุฃูุฑู ุฅููุฏู gamedev'a</a></li>
<li><a href="../ar485294/index.html">ุฏูุฑุฉ ุญุฏูุซุฉ ูู Node.js ูู ุนุงู 2020</a></li>
<li><a href="../ar485298/index.html">ุจุฑูุงูุฌ LyX ุงูุบุงูุถ. ุงูุฌุฒุก 4</a></li>
<li><a href="../ar485300/index.html">ุงูุฏูุงุน ุฌุฏูุฏ ููุฏูุฏุงู H2Miner ุงูุชู ุชุณุชุบู Redis ุงูุชุดู RCE</a></li>
<li><a href="../ar485304/index.html">ุฒูุฌุงู ูู ุงูุญูู ุนูุตุฑ iframe</a></li>
<li><a href="../ar485312/index.html">DevOps ูุชุทุจููุงุช ุงูุฌูุงู</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
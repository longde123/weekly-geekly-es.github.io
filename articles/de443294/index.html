<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äç‚öïÔ∏è üê© üí´ Was erlaubt Jupyter? üï∑Ô∏è üëåüèΩ üëºüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Unsere Geschichte begann mit einer scheinbar einfachen Aufgabe. Es war notwendig, Analysewerkzeuge f√ºr Data-Science-Spezialisten und nur f√ºr Datenanal...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Was erlaubt Jupyter?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/443294/">  Unsere Geschichte begann mit einer scheinbar einfachen Aufgabe.  Es war notwendig, Analysewerkzeuge f√ºr Data-Science-Spezialisten und nur f√ºr Datenanalysten einzurichten.  Diese Aufgabe wurde von Kollegen aus den Bereichen Retail Risk und CRM angesprochen, in denen die Konzentration von Data Science-Spezialisten historisch hoch ist.  Kunden hatten den einfachen Wunsch, Python-Code zu schreiben, erweiterte Bibliotheken (xgboost, pytorch, tensorflow usw.) zu importieren und Algorithmen f√ºr Daten auszuf√ºhren, die aus dem hdfs-Cluster stammen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/793/c16/22e/793c1622e8423e8cae171263790ab234.png"><br><br>  Alles scheint einfach und klar zu sein.  Aber es gab so viele Fallstricke, dass wir beschlossen, einen Beitrag dar√ºber zu schreiben und die fertige L√∂sung auf GitHub zu ver√∂ffentlichen. <br><a name="habracut"></a><br>  Zun√§chst einige Details zur Quellinfrastruktur: <br><br><ul><li>  HDFS Data Warehouse (12 Oracle Big Data Appliance-Knoten, Cloudera-Distribution).  Insgesamt verf√ºgt das Lagerhaus √ºber 130 TB Daten aus verschiedenen internen Systemen der Bank, und es gibt auch heterogene Informationen aus externen Quellen. <br></li><li>  Zwei Anwendungsserver, auf denen die Bereitstellung von Analysetools vorgesehen war.  Es ist erw√§hnenswert, dass sich auf diesen Servern nicht nur erweiterte Analyseaufgaben "drehen". Eine der Anforderungen bestand darin, Containerisierungstools (Docker) zu verwenden, um Serverressourcen zu verwalten, verschiedene Umgebungen zu verwenden und diese zu konfigurieren. <br></li></ul><br>  Als Hauptumgebung f√ºr die Arbeit von Analysten entschieden sie sich f√ºr JupyterHub, das de facto bereits zu einem der Standards f√ºr die Arbeit mit Daten und die Entwicklung von Modellen f√ºr maschinelles Lernen geworden ist.  Lesen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> mehr dar√ºber.  In Zukunft haben wir uns JupyterLab bereits vorgestellt. <br><br>  Es scheint, dass alles einfach ist: Sie m√ºssen eine Reihe von Python + Anaconda + Spark nehmen und konfigurieren.  Installieren Sie Jupyter Hub auf dem Anwendungsserver, integrieren Sie es in LDAP, verbinden Sie Spark oder stellen Sie auf andere Weise eine Verbindung zu HDFS-Daten her und erstellen Sie Modelle! <br>  Wenn Sie sich mit allen Quelldaten und Anforderungen befassen, finden Sie hier eine detailliertere Liste: <br><br><ul><li>  Ausf√ºhren von JupyterHub in Docker (Basisbetriebssystem - Oracle Linux 7) <br></li><li> Cloudera CDH 5.15.1 + Spark 2.3.0-Cluster mit Kerberos-Authentifizierung in Active Directory-Konfiguration + dediziertes Kerberos-MIT im Cluster (siehe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cluster-dediziertes MIT-KDC mit Active Directory</a> ), Oracle Linux 6 <br></li><li>  Active Directory-Integration <br></li><li>  Transparente Authentifizierung in Hadoop und Spark <br></li><li>  Python 2 und 3 Unterst√ºtzung <br></li><li>  Spark 1 und 2 (mit der M√∂glichkeit, Clusterressourcen f√ºr Trainingsmodelle und die Parallelisierung der Datenverarbeitung mit pyspark zu verwenden) <br></li><li>  M√∂glichkeit zur Begrenzung der Hostressourcen <br></li><li>  Bibliotheksset <br></li></ul><br>  Dieser Beitrag richtet sich an IT-Experten, die solche Probleme l√∂sen m√ºssen. <br><br><h2>  L√∂sungsbeschreibung </h2><br><h3>  Starten Sie in Docker + Cloudera Cluster Integration </h3><br>  Hier ist nichts Ungew√∂hnliches.  JupyterHub- und Cloudera-Produktclients werden im Container installiert (siehe unten), und die Konfigurationsdateien werden vom Hostcomputer bereitgestellt: <br><br>  <b>start-hub.sh</b> <br><br><pre><code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre> <br><br><h3>  Active Directory-Integration </h3><br>  F√ºr die Integration mit dem Active Directory / Kerberos-Eisen und nicht sehr Hosts ist der Standard in unserem Unternehmen das Produkt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PBIS Open</a> .  Technisch gesehen handelt es sich bei diesem Produkt um eine Reihe von Diensten, die mit Active Directory kommunizieren, mit denen Clients wiederum √ºber Unix-Domain-Sockets arbeiten.  Dieses Produkt l√§sst sich in Linux PAM und NSS integrieren. <br><br>  Wir haben die Standard-Docker-Methode verwendet - Unix-Domain-Sockets von Host-Diensten wurden in einem Container bereitgestellt (Sockets wurden empirisch durch einfache Manipulationen mit dem Befehl lsof gefunden): <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z &lt;b&gt;-v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro &lt;/b&gt; -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre><br>  PBIS-Pakete werden wiederum im Container installiert, ohne jedoch den Abschnitt nach der Installation auszuf√ºhren.  Wir legen also nur ausf√ºhrbare Dateien und Bibliotheken ab, starten jedoch keine Dienste im Container - dies ist f√ºr uns √ºberfl√ºssig.  PAM- und NSS Linux-Integrationsbefehle werden manuell ausgef√ºhrt. <br><br>  <b>Dockerfile:</b> <br><br><pre> <code class="plaintext hljs"># Install PAM itself and standard PAM configuration packages. RUN yum install -y pam util-linux \ # Here we just download PBIS RPM packages then install them omitting scripts. # We don't need scripts since they start PBIS services, which are not used - we connect to the host services instead. &amp;&amp; find /var/yum/localrepo/ -type f -name 'pbis-open*.rpm' | xargs rpm -ivh --noscripts \ # Enable PBIS PAM integration. &amp;&amp; domainjoin-cli configure --enable pam \ # Make pam_loginuid.so module optional (Docker requirement) and add pam_mkhomedir.so to have home directories created automatically. &amp;&amp; mv /etc/pam.d/login /tmp \ &amp;&amp; awk '{ if ($1 == "session" &amp;&amp; $2 == "required" &amp;&amp; $3 == "pam_loginuid.so") { print "session optional pam_loginuid.so"; print "session required pam_mkhomedir.so skel=/etc/skel/ umask=0022";} else { print $0; } }' /tmp/login &gt; /etc/pam.d/login \ &amp;&amp; rm /tmp/login \ # Enable PBIS nss integration. &amp;&amp; domainjoin-cli configure --enable nsswitch</code> </pre><br>  Es stellt sich heraus, dass die Clients des PBIS-Containers mit den PBIS-Hostdiensten kommunizieren.  JupyterHub verwendet einen PAM-Authentifikator und mit ordnungsgem√§√ü konfiguriertem PBIS auf dem Host funktioniert alles sofort. <br><br>  Um zu verhindern, dass alle Benutzer von AD JupyterHub betreten, k√∂nnen Sie die Einstellung verwenden, mit der Benutzer auf bestimmte AD-Gruppen beschr√§nkt werden. <br><br>  <b>config-example / jupyterhub / jupyterhub_config.py</b> <br><br><pre> <code class="plaintext hljs">c.DSAIAuthenticator.group_whitelist = ['COMPANY\\domain^users']</code> </pre><br><h3>  Transparente Authentifizierung in Hadoop und Spark </h3><br>  Bei der Anmeldung bei JupyterHub speichert PBIS das Kerberos-Ticket des Benutzers in einer bestimmten Datei im Verzeichnis / tmp zwischen.  F√ºr eine transparente Authentifizierung auf diese Weise reicht es aus, das Verzeichnis / tmp des Hosts im Container bereitzustellen und die Variable KRB5CCNAME auf den gew√ºnschten Wert zu setzen (dies erfolgt in unserer Authentifizierungsklasse). <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre> <br>  <b>Verm√∂genswerte / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">env['KRB5CCNAME'] = '/host/tmp/krb5cc_%d' % pwd.getpwnam(self.user.name).pw_uid</code> </pre> <br>  Dank des obigen Codes kann der JupyterHub-Benutzer hdfs-Befehle vom Jupyter-Terminal ausf√ºhren und Spark-Jobs ohne zus√§tzliche Authentifizierungsschritte ausf√ºhren.  Das Mounten des gesamten / tmp-Verzeichnisses des Hosts in den Container ist unsicher - wir kennen dieses Problem, aber seine L√∂sung befindet sich noch in der Entwicklung. <br><br><h3>  Python-Versionen 2 und 3 </h3><br>  Hier scheint alles einfach zu sein: Sie m√ºssen die erforderlichen Versionen von Python installieren und in Jupyter integrieren, um den erforderlichen Kernel zu erstellen.  Dieses Problem wurde bereits an vielen Stellen behandelt.  Conda wird zum Verwalten von Python-Umgebungen verwendet.  Warum alle Einfachheit nur offensichtlich ist, wird im n√§chsten Abschnitt deutlich.  Kernel-Beispiel f√ºr Python 3.6 (diese Datei ist nicht in Git - alle Kernel-Dateien werden durch Code generiert): <br><br>  <b>/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/share/jupyter/kernels/python3.6.6/kernel.json</b> <br><br><pre> <code class="plaintext hljs">{   "argv": [      "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python",       "-m",       "ipykernel_launcher",       "-f",      "{connection_file}"   ],   "display_name": "Python 3",   "language": "python" }</code> </pre><br><h3>  Funke 1 und 2 </h3><br>  Zur Integration in SPARK-Clients m√ºssen Sie auch Kernel erstellen.  Kernel-Beispiel f√ºr Python 3.6 und SPARK 2. <br><br>  <b>/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/share/jupyter/kernels/python3.6.6-pyspark2/kernel.json</b> <br><br><pre> <code class="plaintext hljs">{   "argv": [       "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python",       "-m",       "ipykernel_launcher",       "-f",      "{connection_file}"   ],   "display_name": "Python 3 + PySpark 2",   "language": "python",   "env": {       "JAVA_HOME": "/usr/java/default/",       "SPARK_HOME": "/opt/cloudera/parcels/SPARK2/lib/spark2/",       "PYTHONSTARTUP": "/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/shell.py",       "PYTHONPATH": "/opt/cloudera/parcels/SPARK2/lib/spark2/python/:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.7-src.zip",       "PYSPARK_PYTHON": "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python"   } }</code> </pre><br>  Beachten Sie nur, dass sich die Anforderung, Spark 1-Unterst√ºtzung zu haben, historisch entwickelt hat.  Es ist jedoch m√∂glich, dass jemand √§hnlichen Einschr√§nkungen ausgesetzt ist. Sie k√∂nnen beispielsweise Spark 2 nicht in einem Cluster installieren.  Daher beschreiben wir hier die Fallstricke, denen wir auf dem Weg zur Implementierung begegnet sind. <br>  Erstens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">funktioniert</a> Spark 1.6.1 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nicht</a> mit Python 3.6.  Interessanterweise wurde dies in CDH 5.12.1 behoben, in 5.15.1 jedoch - aus irgendeinem Grund nicht).  Zun√§chst wollten wir dieses Problem l√∂sen, indem wir einfach den entsprechenden Patch anwenden.  In Zukunft musste diese Idee jedoch aufgegeben werden, da dieser Ansatz die Installation eines modifizierten Spark in einem Cluster erfordert, was f√ºr uns nicht akzeptabel war.  Die L√∂sung wurde beim Erstellen einer separaten Conda-Umgebung mit Python 3.5 gefunden. <br><br>  Das zweite Problem verhindert, dass Spark 1 in Docker funktioniert.  Der Spark-Treiber √∂ffnet einen bestimmten Port, √ºber den Worker eine Verbindung zum Treiber herstellt. Dazu sendet der Treiber ihm seine IP-Adresse.  Im Fall von Docker Worker wird versucht, √ºber die IP-Adresse des Containers eine Verbindung zum Treiber herzustellen. Bei Verwendung von network = bridge funktioniert dies nicht ganz nat√ºrlich. <br><br>  Die naheliegende L√∂sung besteht darin, nicht die IP des Containers zu senden, sondern die IP des Hosts, die in Spark 2 durch Hinzuf√ºgen der entsprechenden Konfigurationseinstellungen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">implementiert wurde</a> .  Dieser Patch wurde kreativ √ºberarbeitet und auf Spark 1 angewendet. Auf diese Weise modifizierter Spark muss nicht auf den Cluster-Hosts platziert werden, sodass es kein Problem gibt, das der Inkompatibilit√§t mit Python 3.6 √§hnelt. <br><br>  Unabh√§ngig von der Version von Spark ist es f√ºr die Funktionalit√§t erforderlich, im Cluster dieselben Python-Versionen wie im Container zu haben.  Um Anaconda direkt unter Umgehung von Cloudera Manager zu installieren, mussten wir zwei Dinge lernen: <br><br><ul><li>  Bauen Sie Ihr Paket mit Anaconda und den richtigen Umgebungen <br></li><li>  Installieren Sie es in Docker (aus Gr√ºnden der Konsistenz) <br></li></ul><br><h3>  Montagepaket Anaconda </h3><br>  Dies stellte sich als ziemlich einfache Aufgabe heraus.  Alles was Sie brauchen ist: <br><br><ol><li>  Bereiten Sie den Paketinhalt vor, indem Sie die erforderlichen Versionen der Anaconda- und Python-Umgebung installieren <br></li><li>  Erstellen Sie Metadatendateien und legen Sie sie im Meta-Verzeichnis ab <br></li><li>  Erstellen Sie ein Paket mit einfachem Teer <br></li><li>  √úberpr√ºfen Sie das Paketdienstprogramm von Cloudera <br></li></ol><br>  Der Prozess wird auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub</a> ausf√ºhrlicher beschrieben, dort gibt es auch einen Validator-Code.  Wir haben Metadaten im offiziellen Anaconda- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Paket</a> f√ºr Cloudera ausgeliehen und sie kreativ √ºberarbeitet. <br><br><h3>  Installieren Sie das Paket in Docker </h3><br>  Diese Praxis hat sich aus zwei Gr√ºnden als n√ºtzlich erwiesen: <br><br><ul><li>  Sicherstellung der Spark-Funktionsf√§higkeit - Es ist unm√∂glich, Anaconda ohne Paket in einen Cluster zu integrieren <br></li><li>  Spark 2 wird nur in Form von Paketen verteilt - Sie k√∂nnen es nat√ºrlich auch in Form von JAR-Dateien in einem Container installieren, aber dieser Ansatz wurde abgelehnt <br></li></ul><br>  Als Bonus erhielten wir als Ergebnis der L√∂sung der oben genannten Probleme: <br><br><ul><li>  Einfache Einrichtung von Hadoop- und Spark-Clients - Wenn Sie dieselben Pakete in Docker und im Cluster installieren, sind die Pfade im Cluster und im Container identisch <br></li><li>  Einfache Aufrechterhaltung einer einheitlichen Umgebung im Container und im Cluster - Beim Aktualisieren des Clusters wird das Docker-Image einfach mit denselben Paketen neu erstellt, die im Cluster installiert wurden. <br></li></ul><br>  Um das Paket in Docker zu installieren, wird Cloudera Manager zuerst aus den RPM-Paketen installiert.  F√ºr die eigentliche Installation des Pakets wird Java-Code verwendet.  Der Client in Java wei√ü, was der Client in Python nicht kann, daher musste ich Java verwenden und die Einheitlichkeit verlieren, wodurch die API aufgerufen wird. <br><br>  <b>Assets / Install-Pakete / src / InstallParcels.java</b> <br><br><pre> <code class="plaintext hljs">ParcelsResourceV5 parcels = clusters.getParcelsResource(clusterName); for (int i = 1; i &lt; args.length; i += 2) {   result = installParcel(api, parcels, args[i], args[i + 1], pause);   if (!result) {       System.exit(1);   } }</code> </pre><br><h3>  Einschr√§nkung der Hostressourcen </h3><br>  Zum Verwalten von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hostcomputerressourcen</a> wird eine Kombination aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DockerSpawner</a> verwendet - einer Komponente, die Jupyter-Endbenutzer in einem separaten Docker-Container <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ausf√ºhrt</a> - und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cgroups</a> - einem Ressourcenverwaltungsmechanismus unter Linux.  DockerSpawner verwendet die Docker-API, mit der Sie die √ºbergeordnete cgroup f√ºr den Container festlegen k√∂nnen.  Im regul√§ren DockerSpawner gibt es keine solche M√∂glichkeit. Daher haben wir einfachen Code geschrieben, mit dem wir die Korrespondenz zwischen AD-Entit√§ten und der √ºbergeordneten cgroup in der Konfiguration festlegen k√∂nnen. <br><br>  <b>Verm√∂genswerte / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">def set_extra_host_config(self):       extra_host_config = {}       if self.user.name in self.user_cgroup_parent:           cgroup_parent = self.user_cgroup_parent[self.user.name]       else:           pw_name = pwd.getpwnam(self.user.name).pw_name           group_found = False           for g in grp.getgrall():               if pw_name in g.gr_mem and g.gr_name in self.group_cgroup_parent:                   cgroup_parent = self.group_cgroup_parent[g.gr_name]                   group_found = True                   break           if not group_found:               cgroup_parent = self.cgroup_parent extra_host_config['cgroup_parent'] = cgroup_parent</code> </pre><br>  Es wurde auch eine kleine Modifikation eingef√ºhrt, die Jupyter von demselben Image aus startet, von dem aus JupyterHub gestartet wird.  Daher muss nicht mehr als ein Bild verwendet werden. <br><br>  <b>Verm√∂genswerte / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">current_container = None host_name = socket.gethostname() for container in self.client.containers():   if container['Id'][0:12] == host_name:       current_container = container       break self.image = current_container['Image']</code> </pre><br>  Was genau im Container Jupyter oder JupyterHub ausgef√ºhrt werden soll, wird im Startskript durch Umgebungsvariablen bestimmt: <br><br>  <b>Verm√∂genswerte / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">#!/bin/bash ANACONDA_PATH="/opt/cloudera/parcels/Anaconda/" DEFAULT_ENV=`cat ${ANACONDA_PATH}/envs/default` source activate ${DEFAULT_ENV} if [ -z "${JUPYTERHUB_CLIENT_ID}" ]; then   while true; do       jupyterhub -f /etc/jupyterhub/jupyterhub_config.py   done else   HOME=`su ${JUPYTERHUB_USER} -c 'echo ~'`   cd ~   su ${JUPYTERHUB_USER} -p -c "jupyterhub-singleuser --KernelSpecManager.ensure_native_kernel=False --ip=0.0.0.0" fi</code> </pre><br>  Die M√∂glichkeit, Jupyter Docker-Container √ºber den JupyterHub Docker-Container zu starten, wird durch das Mounten des Docker-Daemon-Sockets im JupyterHub-Container erreicht. <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-&lt;b&gt;v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z&lt;/b&gt; -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre><br>  In Zukunft ist geplant, diese Entscheidung zugunsten von beispielsweise ssh aufzugeben. <br><br>  Bei Verwendung von DockerSpawner in Verbindung mit Spark tritt ein weiteres Problem auf: Der Spark-Treiber √∂ffnet zuf√§llige Ports, √ºber die Worker dann eine externe Verbindung herstellen.  Wir k√∂nnen den Bereich der Portnummern steuern, aus denen zuf√§llige ausgew√§hlt werden, indem wir diese Bereiche in der Spark-Konfiguration festlegen.  Diese Bereiche m√ºssen jedoch f√ºr verschiedene Benutzer unterschiedlich sein, da wir keine Jupyter-Container mit denselben ver√∂ffentlichten Ports ausf√ºhren k√∂nnen.  Um dieses Problem zu l√∂sen, wurde Code geschrieben, der einfach Portbereiche anhand der Benutzer-ID aus der JupyterHub-Datenbank generiert und den Docker-Container und Spark mit der entsprechenden Konfiguration startet: <br><br>  <b>Verm√∂genswerte / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">def set_extra_create_kwargs(self):       user_spark_driver_port, user_spark_blockmanager_port, user_spark_ui_port, user_spark_max_retries = self.get_spark_ports()       if user_spark_driver_port == 0 or user_spark_blockmanager_port == 0 or user_spark_ui_port == 0 or user_spark_max_retries == 0:           return       ports = {}       for p in range(user_spark_driver_port, user_spark_driver_port + user_spark_max_retries):           ports['%d/tcp' % p] = None       for p in range(user_spark_blockmanager_port, user_spark_blockmanager_port + user_spark_max_retries):           ports['%d/tcp' % p] = None       for p in range(user_spark_ui_port, user_spark_ui_port + user_spark_max_retries):           ports['%d/tcp' % p] = None self.extra_create_kwargs = { 'ports' : ports }</code> </pre><br>  Der Nachteil dieser L√∂sung ist, dass beim Neustart des Containers mit JupyterHub aufgrund von Datenbankverlust alles nicht mehr funktioniert.  Wenn Sie den JupyterHub beispielsweise f√ºr eine Konfigurations√§nderung neu starten, ber√ºhren wir daher nicht den Container selbst, sondern starten nur den darin enthaltenen JupyterHub-Prozess neu. <br><br>  <b>restart-hub.sh</b> <br><br><pre> <code class="plaintext hljs">#!/bin/bash docker ps | fgrep 'dsai1.2' | fgrep -v 'jupyter-' | awk '{ print $1; }' | while read ID; do docker exec $ID /bin/bash -c "kill \$( cat /root/jupyterhub.pid )"; done</code> </pre><br>  Cgroups selbst werden von Standard-Linux-Tools erstellt. Die Entsprechung zwischen AD-Entit√§ten und cgroups in der Konfiguration sieht folgenderma√üen aus. <br><br><pre> <code class="plaintext hljs">&lt;b&gt;config-example/jupyterhub/jupyterhub_config.py&lt;/b&gt; c.DSAISpawner.user_cgroup_parent = {   'bank\\user1'    : '/jupyter-cgroup-1', # user 1   'bank\\user2'    : '/jupyter-cgroup-1', # user 2   'bank\\user3'    : '/jupyter-cgroup-2', # user 3 } c.DSAISpawner.cgroup_parent = '/jupyter-cgroup-3'</code> </pre><br><h3>  Git-Code </h3><br>  Unsere L√∂sung ist auf GitHub √∂ffentlich verf√ºgbar: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/DS-AI/dsai/</a> (DSAI - Data Science and Artificial Intelligence).  Der gesamte Code ist in Verzeichnissen mit Seriennummern angeordnet. Der Code aus jedem nachfolgenden Verzeichnis kann Artefakte aus dem vorherigen verwenden.  Das Ergebnis des Codes aus dem letzten Verzeichnis ist ein Docker-Image. <br><br>  Jedes Verzeichnis enth√§lt Dateien: <br><br><ul><li>  Assets.sh - Erstellung von Artefakten, die f√ºr die Montage erforderlich sind (Herunterladen aus dem Internet oder Kopieren aus den Verzeichnissen der vorherigen Schritte) <br></li><li>  build.sh - build <br></li><li>  clean.sh - Reinigungsartefakte, die f√ºr die Montage ben√∂tigt werden <br></li></ul><br>  Um das Docker-Image vollst√§ndig neu zu erstellen, m√ºssen clean.sh, assets.sh, build.sh aus den Verzeichnissen entsprechend ihrer Seriennummer ausgef√ºhrt werden. <br><br>  F√ºr die Montage verwenden wir eine Maschine mit Linux RedHat 7.4, Docker 17.05.0-ce.  Das Ger√§t verf√ºgt √ºber 8 Kerne, 32 GB RAM und 250 GB Festplattenspeicher.  Es wird dringend empfohlen, keinen Host mit den schlechtesten RAM- und HDD-Einstellungen zum Erstellen zu verwenden. <br><br>  Hier ist die Hilfe f√ºr die verwendeten Namen: <br><br><ul><li>  01-Spark-Patched - RPM Spark 1.6.1 mit zwei Patches SPARK-4563 und SPARK-19019. <br></li><li>  02-Validator - Paketvalidator <br></li><li>  03-anaconda-dsai-parcel-1.0 - Paket Anaconda mit dem richtigen Python (2, 3.5 und 3.6) <br></li><li>  04-cloudera-manager-api - Cloudera Manager-API-Bibliotheken <br></li><li>  05-dsai1.2-offline - endg√ºltiges Bild <br></li></ul><br>  Leider kann die Assembly aus Gr√ºnden abst√ºrzen, die wir nicht beheben konnten (z. B. wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teer</a> w√§hrend der Assembly des Pakets <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gel√∂scht</a> . In diesem Fall m√ºssen Sie die Assembly in der Regel nur neu starten, dies hilft jedoch nicht immer (z. B. h√§ngt die Spark-Assembly von externen Ressourcen ab Cloudera, die m√∂glicherweise nicht mehr verf√ºgbar ist usw.). <br><br>  Ein weiterer Nachteil ist, dass die Paketmontage nicht reproduzierbar ist.  Da Bibliotheken st√§ndig aktualisiert werden, kann die Wiederholung der Assembly zu einem anderen Ergebnis als dem vorherigen f√ºhren. <br><br><h2>  Gro√ües Finale </h2><br>  Jetzt verwenden Benutzer die Tools erfolgreich, ihre Anzahl hat mehrere Dutzend √ºberschritten und w√§chst weiter.  In Zukunft planen wir, JupyterLab auszuprobieren, und √ºberlegen, die GPU mit dem Cluster zu verbinden, da jetzt die Rechenressourcen von zwei ziemlich leistungsf√§higen Anwendungsservern nicht mehr ausreichen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de443294/">https://habr.com/ru/post/de443294/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de443284/index.html">Indizes in PostgreSQL - 4 (Btree)</a></li>
<li><a href="../de443286/index.html">TDMS Fairway. Autofill-Mechanismus f√ºr die Hauptbeschriftungen auf den Zeichnungen und Details der Dokumente</a></li>
<li><a href="../de443288/index.html">Navigation in Projekten mit mehreren Modulen</a></li>
<li><a href="../de443290/index.html">Zen Erlang [und Elixier - ca. √úbersetzer]</a></li>
<li><a href="../de443292/index.html">Wir untersuchen das Funktionsprinzip von em-Einheiten am Beispiel der Aufgabe ‚ÄûAufbau eines flexiblen Vorladers‚Äú.</a></li>
<li><a href="../de443298/index.html">Drahtloses Laden. Wie funktioniert es in der Praxis?</a></li>
<li><a href="../de443300/index.html">Wie ist die Entwicklung bei United Traders?</a></li>
<li><a href="../de443302/index.html">Wie Apple sich auf eine √Ñra nach dem iPhone vorbereitet</a></li>
<li><a href="../de443304/index.html">Technophobie ist sinnlos, auch wenn Technophobie gerechtfertigt ist</a></li>
<li><a href="../de443306/index.html">Acht Namensgesetze im UX-Design (Teil 1)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😼 🥟 👩🏽‍🤝‍👨🏾 CUDA和远程GPU 🆕 👩🏻‍🌾 🌾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="只要手边有Nvidia的视频卡，CUDA对每个人都有益。 但是，如果您喜欢的笔记本电脑上没有Nvidia显卡，该怎么办？ 还是需要在虚拟机中进行开发？ 


 我将在本文中尝试考虑诸如rCUDA（远程CUDA）框架之类的解决方案，该解决方案在存在Nvidia图形卡时会有所帮助，但未安装在本应启动CU...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>CUDA和远程GPU</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416127/"><p> 只要手边有Nvidia的视频卡，CUDA对每个人都有益。 但是，如果您喜欢的笔记本电脑上没有Nvidia显卡，该怎么办？ 还是需要在虚拟机中进行开发？ </p><br><p> 我将在本文中尝试考虑诸如rCUDA（远程CUDA）框架之类的解决方案，该解决方案在存在Nvidia图形卡时会有所帮助，但未安装在本应启动CUDA应用程序的计算机中。 对于那些感兴趣的人，欢迎光临。 </p><br><div class="spoiler">  <b class="spoiler_title">TLDR</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">rCUDA</a> （远程CUDA）-实现CUDA API的框架，允许您使用远程视频卡。 它处于有效的Beta版，仅在Linux下可用。  rCUDA的主要目标是与CUDA API完全兼容，您无需以任何方式修改代码，只需设置特殊的环境变量即可。 </p></div></div><a name="habracut"></a><br><h2 id="chto-takoe-rcuda"> 什么是rCUDA </h2><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">rCUDA</a> （远程CUDA）是实现CUDA API的框架，允许您使用位于远程计算机上的视频卡进行CUDA计算，而无需对代码进行任何更改。 由瓦伦西亚理工大学（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">rcuda-team</a> ）开发。 </p><br><h2 id="ogranicheniya"> 局限性 </h2><br><p> 当前仅支持GNU / Linux系统，但是开发人员承诺将来会支持Windows。  rCUDA的当前版本18.03beta与CUDA 5-8兼容，即不支持CUDA 9。 开发人员宣布除图形外，与CUDA API完全兼容。 </p><br><h2 id="vozmozhnye-scenarii-ispolzovaniya"> 可能的用例 </h2><br><ol><li> 当不方便或无法转发视频卡时（例如，当视频卡被主机占用时，或有多个虚拟机时），在虚拟机中运行CUDA应用程序。 </li><li> 没有独立显卡的笔记本电脑。 </li><li> 希望使用多个视频卡（群集）。 从理论上讲，您可以使用团队中所有可用的视频卡，包括联合使用。 </li></ol><br><h2 id="kratkaya-instrukciya"> 简要说明 </h2><br><h4 id="testovaya-konfiguraciya"> 测试配置 </h4><br><p> 对以下配置进行了测试： </p><br><p>  <strong>伺服器：</strong> <br>  Ubuntu 16.04，GeForce GTX 660 </p><br><p>  <strong>客户：</strong> <br> 笔记本电脑上装有Ubuntu 16.04的虚拟机，没有独立的图形卡。 </p><br><h4 id="poluchenie-rcuda"> 获取rCUDA </h4><br><p> 最困难的阶段。 不幸的是，目前，获取此框架副本的唯一方法是在官方网站上填写适当的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">请求表</a> 。 但是，开发人员承诺在1-2天内做出回应。 就我而言，他们是在同一天向我发送了一份分配。 </p><br><h4 id="ustanovka-cuda"> 安装CUDA </h4><br><p> 首先，您需要在服务器和客户端上安装CUDA Toolkit（即使客户端没有nvidia视频卡）。 为此，您可以从官方网站下载它或使用存储库。 最主要的是使用不高于8的版本。在此示例中， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">使用</a>了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">官方网站</a>的.run安装程序。 </p><br><pre><code class="bash hljs">chmod +x cuda_8.0.61_375.26_linux.run ./cuda_8.0.61_375.26_linux.run</code> </pre> <br><p>  <strong>重要！</strong> 在客户端上，您应该拒绝安装nvidia驱动程序。 默认情况下，CUDA工具包将位于/ usr / local / cuda /。 安装CUDA示例，您将需要它们。 </p><br><h4 id="ustanovka-rcuda"> 安装rCUDA </h4><br><p> 我们会将从开发人员那里收到的归档文件解压缩到服务器和客户端上的主目录中。 </p><br><pre> <code class="bash hljs">tar -xvf rCUDA*.tgz -C ~/ mv ~/rCUDA* ~/rCUDA</code> </pre> <br><p> 您需要在服务器和客户端上都执行这些操作。 </p><br><h4 id="zapusk-demona-rcuda-na-servere"> 在服务器上启动rCUDA守护程序 </h4><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span>:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/lib64:/home/&lt;XXX&gt;/rCUDA/lib/cudnn <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rCUDA/bin ./rCUDAd</code> </pre> <br><p> 将&lt;XXX&gt;替换为您的用户名。 如果要查看详细的输出，请使用./rCUDAd -iv。 </p><br><h4 id="nastroyka-klienta"> 客户端设置 </h4><br><p> 让我们在客户端上打开终端，以后我们将在其中运行CUDA代码。 在客户端，我们需要用rCUDA库“替换”标准CUDA库，为此我们向环境变量LD_LIBRARY_PATH添加了适当的路径。 我们还需要指定服务器的数量及其地址（在我的示例中，将是一台）。 </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=/home/&lt;XXX&gt;/rCUDA/lib/:<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> RCUDA_DEVICE_COUNT=1 <span class="hljs-comment"><span class="hljs-comment">#    (),     export RCUDA_DEVICE_0=&lt;IP  &gt;:0 #    </span></span></code> </pre> <br><h4 id="sborka-i-zapusk"> 组装和发射 </h4><br><p> 让我们尝试构建并运行一些示例。 </p><br><p>  <strong>例子1</strong> </p><br><p> 让我们从一个简单的deviceQuery示例开始，该示例仅显示兼容设备（在我们的情况下为远程GTX660）的CUDA设置。 </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt;YYY&gt;/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery make EXTRA_NVCCFLAGS=--cudart=shared</code> </pre> <br><p>  <strong>重要！</strong> 没有EXTRA_NVCCFLAGS =-cudart =共享奇迹将不起作用 <br> 在安装CUDA时，将&lt;YYY&gt;替换为为CUDA Samples指定的路径。 </p><br><p> 运行组装的示例： </p><br><pre> <code class="bash hljs">./deviceQuery</code> </pre> <br><p> 如果您正确执行了所有操作，则结果将如下所示： </p><br><div class="spoiler">  <b class="spoiler_title">结果</b> <div class="spoiler_text"><pre> <code class="bash hljs">./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Detected 1 CUDA Capable device(s) Device 0: <span class="hljs-string"><span class="hljs-string">"GeForce GTX 660"</span></span> CUDA Driver Version / Runtime Version 9.0 / 8.0 CUDA Capability Major/Minor version number: 3.0 Total amount of global memory: 1994 MBytes (2090991616 bytes) ( 5) Multiprocessors, (192) CUDA Cores/MP: 960 CUDA Cores GPU Max Clock rate: 1072 MHz (1.07 GHz) Memory Clock rate: 3004 Mhz Memory Bus Width: 192-bit L2 Cache Size: 393216 bytes Maximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096) Maximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 1 copy engine(s) Run time <span class="hljs-built_in"><span class="hljs-built_in">limit</span></span> on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 660 Result = PASS</code> </pre> </div></div><br><p> 我们应该看到的最重要的事情是： </p><br><blockquote> 设备0 = GeForce GTX 660 <br> 结果=通过 </blockquote><p> 太好了！ 我们设法在没有独立显卡的计算机上构建并运行CUDA应用程序，为此目的，它使用了安装在远程服务器上的视频卡。 </p><br><p>  <strong>重要！</strong> 如果应用程序输出以以下形式的行开头： </p><br><pre> <code class="bash hljs">mlock error: Cannot allocate memory rCUDA warning: 1007.461 mlock error: Cannot allocate memory</code> </pre> <br><p> 这意味着有必要在服务器和客户端上的“ /etc/security/limits.conf”文件中添加以下行： </p><br><pre> <code class="bash hljs">* hard memlock unlimited * soft memlock unlimited</code> </pre> <br><p> 因此，您将允许所有用户（*）无限（无限）阻塞内存（memlock）。 最好用所需的用户替换*，而不是无限选择较少的胖权限。 </p><br><p>  <strong>例子2</strong> </p><br><p> 现在让我们尝试一些更有趣的事情。 我们将使用共享内存和同步来测试矢量的标量积的实现方式（“ CUDA技术示例” Sanders J. Kendrot E. 5.3.1）。 </p><br><p> 在此示例中，我们计算了尺寸为33 * 1024的两个向量的标量积，并将答案与CPU上获得的结果进行了比较。 </p><br><div class="spoiler">  <b class="spoiler_title">dotProd.cu</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #define imin(a,b) (a&lt;b?a:b) const int N = 33 * 1024; const int threadsPerBlock = 256; const int blocksPerGrid = imin(32, (N+threadsPerBlock-1) / threadsPerBlock); __global__ void dot(float* a, float* b, float* c) { __shared__ float cache[threadsPerBlock]; int tid = threadIdx.x + blockIdx.x * blockDim.x; int cacheIndex = threadIdx.x; float temp = 0; while (tid &lt; N){ temp += a[tid] * b[tid]; tid += blockDim.x * gridDim.x; } // set the cache values cache[cacheIndex] = temp; // synchronize threads in this block __syncthreads(); // for reductions, threadsPerBlock must be a power of 2 // because of the following code int i = blockDim.x/2; while (i != 0){ if (cacheIndex &lt; i) cache[cacheIndex] += cache[cacheIndex + i]; __syncthreads(); i /= 2; } if (cacheIndex == 0) c[blockIdx.x] = cache[0]; } int main (void) { float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; // allocate memory on the cpu side a = (float*)malloc(N*sizeof(float)); b = (float*)malloc(N*sizeof(float)); partial_c = (float*)malloc(blocksPerGrid*sizeof(float)); // allocate the memory on the gpu cudaMalloc((void**)&amp;dev_a, N*sizeof(float)); cudaMalloc((void**)&amp;dev_b, N*sizeof(float)); cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid*sizeof(float)); // fill in the host memory with data for(int i=0; i&lt;N; i++) { a[i] = i; b[i] = i*2; } // copy the arrays 'a' and 'b' to the gpu cudaMemcpy(dev_a, a, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(float), cudaMemcpyHostToDevice); dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_partial_c); // copy the array 'c' back from the gpu to the cpu cudaMemcpy(partial_c,dev_partial_c, blocksPerGrid*sizeof(float), cudaMemcpyDeviceToHost); // finish up on the cpu side c = 0; for(int i=0; i&lt;blocksPerGrid; i++) { c += partial_c[i]; } #define sum_squares(x) (x*(x+1)*(2*x+1)/6) printf("GPU - %.6g \nCPU - %.6g\n", c, 2*sum_squares((float)(N-1))); // free memory on the gpu side cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_partial_c); // free memory on the cpu side free(a); free(b); free(partial_c); }</span></span></span></span></code> </pre></div></div><br><p> 构建并运行： </p><br><pre> <code class="bash hljs">/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin/nvcc --cudart=shared dotProd.cu -o dotProd ./dotProd</code> </pre> <br><p> 这个结果告诉我们一切都很好： </p><br><blockquote>  GPU-2.57236e + 13 <br>  CPU-2.57236e + 13 </blockquote><p>  <strong>例子3</strong> </p><br><p> 运行另一个标准的CUDA-matrixMulCUBLAS测试（矩阵乘法）。 </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt; YYY&gt;/NVIDIA_CUDA-8.0_Samples/0_Simple/matrixMulCUBLAS make EXTRA_NVCCFLAGS=--cudart=shared ./matrixMulCUBLAS</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">结果</b> <div class="spoiler_text"><p>  [矩阵乘以CUBLAS]-开始... <br>  GPU设备0：具有计算能力3.0的“ GeForce GTX 660” </p><br><p> 矩阵A（640,480），矩阵B（480,320），矩阵C（640,320） <br> 使用CUBLAS计算结果...完成。 <br> 性能= 436.24 GFlop / s，时间= 0.451毫秒，大小= 196608000 Ops <br> 使用主机CPU的计算结果...完成。 <br> 比较CUBLAS矩阵与CPU结果：PASS </p><br><p> 注意：CUDA示例不用于性能测量。 启用GPU Boost后，结果可能会有所不同。 </p></div></div><br><p> 我们感兴趣的是： </p><br><blockquote> 性能= 436.24 GFlop / s， <br> 比较CUBLAS矩阵与CPU结果：PASS </blockquote><br><h4 id="bezopasnost"> 安全性 </h4><br><p> 我没有在rCUDA的文档中提及任何授权方法。 我认为目前最简单的方法是仅从特定地址打开对所需端口（8308）的访问。 </p><br><p> 使用iptables，它将看起来像这样： </p><br><pre> <code class="bash hljs">iptables -A INPUT -m state --state NEW -p tcp -s &lt; &gt; --dport 8308 -j ACCEPT</code> </pre> <br><p> 对于其余的内容，我将安全性问题超出了本文的范围。 </p><br><div class="spoiler">  <b class="spoiler_title">来源和链接</b> <div class="spoiler_text"><p>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">http://www.rcuda.net/pub/rCUDA_guide.pdf</a> <br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">http://www.rcuda.net/pub/rCUDA_QSG.pdf</a> <br>  [3] C.Reaño，F。Silla，G。Shainer和S. Schultz，“本地和远程GPU与EDR 100G InfiniBand的性能相似”，在国际中间件大会的会议记录中，加拿大不列颠哥伦比亚省温哥华，2015年12月。 <br>  [4] C.Reaño和F. Silla，“ CUDA远程GPU虚拟化框架的性能比较”，在美国伊利诺伊州芝加哥举行的国际集群计算会议上，2015年9月。 </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN416127/">https://habr.com/ru/post/zh-CN416127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN416115/index.html">我们仍然犯的10个小设计错误</a></li>
<li><a href="../zh-CN416119/index.html">周三的周五帖子：最“必要”的NPM软件包的顶部</a></li>
<li><a href="../zh-CN416121/index.html">富士通人工智能计算磁性材料的几何形状</a></li>
<li><a href="../zh-CN416123/index.html">使用Keras和Tensorflow Object Detection API技术的神经网络识别货架上的商品</a></li>
<li><a href="../zh-CN416125/index.html">摄像机的安装，系统设置和控制</a></li>
<li><a href="../zh-CN416129/index.html">人工智能如何学习生成猫图像</a></li>
<li><a href="../zh-CN416131/index.html">如何在俄罗斯联邦处理违约概率而不违反法律</a></li>
<li><a href="../zh-CN416133/index.html">国外数据中心：Equinix LD8</a></li>
<li><a href="../zh-CN416135/index.html">小于1 kb的GUI应用程序</a></li>
<li><a href="../zh-CN416137/index.html">Zabbix作为安全扫描程序</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
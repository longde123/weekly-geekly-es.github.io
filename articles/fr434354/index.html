<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•õ ‚õé üôà Cr√©ation d'un mod√®le de reconnaissance faciale √† l'aide du deep learning en Python ‚úçüèº ü§¥üèΩ üöû</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La traductrice Elena Bornovolokova sp√©cialement pour Netology a adapt√© un article de Fayzan Shaykh sur la fa√ßon de cr√©er un mod√®le de reconnaissance f...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cr√©ation d'un mod√®le de reconnaissance faciale √† l'aide du deep learning en Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/netologyru/blog/434354/">  <i>La traductrice Elena Bornovolokova sp√©cialement pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Netology a</a> adapt√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article de</a> Fayzan Shaykh sur la fa√ßon de cr√©er un mod√®le de reconnaissance faciale et dans quels domaines il peut √™tre appliqu√©.</i> <br><br><h2>  Pr√©sentation </h2><br>  Ces derni√®res ann√©es, la vision par ordinateur a gagn√© en popularit√© et s'est d√©marqu√©e dans une direction distincte.  Les d√©veloppeurs cr√©ent de nouvelles applications utilis√©es dans le monde entier. <a name="habracut"></a><br>  Dans ce sens, je suis attir√© par le concept d'open source.  M√™me les g√©ants de la technologie sont pr√™ts √† partager de nouvelles d√©couvertes et innovations avec tout le monde, afin que la technologie ne reste pas le privil√®ge des riches. <br><br>  L'une de ces technologies est la reconnaissance faciale.  Lorsqu'elle est utilis√©e correctement et de mani√®re √©thique, cette technologie peut √™tre appliqu√©e dans de nombreux domaines de la vie. <br><br>  Dans cet article, je vais vous montrer comment cr√©er un algorithme de reconnaissance faciale efficace √† l'aide d'outils open source.  Avant de passer √† ces informations, je veux que vous vous pr√©pariez et que vous vous inspiriez en regardant cette vid√©o: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wr4rx0Spihs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Reconnaissance faciale: applications potentielles </h2><br>  Voici quelques domaines d'application potentiels de la technologie de reconnaissance faciale. <br><br>  <b>Reconnaissance faciale dans les r√©seaux sociaux</b> .  Facebook a remplac√© le balisage manuel des images par des suggestions de balises g√©n√©r√©es automatiquement pour chaque image t√©l√©charg√©e sur la plateforme.  Facebook utilise un algorithme de reconnaissance faciale simple pour analyser les pixels de l'image et la comparer avec leurs utilisateurs respectifs. <br><br>  <b>Reconnaissance faciale en s√©curit√©</b> .  Un exemple simple d'utilisation de la technologie de reconnaissance faciale pour prot√©ger les donn√©es personnelles est le d√©verrouillage de votre smartphone ¬´en face¬ª.  Cette technologie peut √©galement √™tre impl√©ment√©e dans le syst√®me d'acc√®s: une personne regarde la cam√©ra et d√©termine si elle doit y entrer ou non. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/bYrRQQX2PvY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <b>Reconnaissance faciale pour compter le nombre de personnes</b> .  La technologie de reconnaissance faciale peut √™tre utilis√©e pour compter le nombre de personnes assistant √† un √©v√©nement (comme une conf√©rence ou un concert).  Au lieu de compter manuellement les participants, nous installons une cam√©ra qui peut capturer des images des visages des participants et donner le nombre total de visiteurs.  Cela vous aidera √† automatiser le processus et √† gagner du temps. <br><br><img src="https://habrastorage.org/webt/fn/bc/-k/fnbc-kgpcaeogtd4attryczyjfq.png"><br><br><h2>  Configuration du syst√®me: configuration mat√©rielle et logicielle requise </h2><br>  Consid√©rez comment nous pouvons utiliser la technologie de reconnaissance faciale en contactant les outils open source √† notre disposition. <br><br>  J'ai utilis√© les outils suivants que je vous recommande: <br><br><ul><li>  Webcam (Logitech C920) pour la cr√©ation d'un mod√®le de reconnaissance faciale en temps r√©el sur un ordinateur portable Lenovo E470 ThinkPad (Core i5 7e g√©n√©ration).  Vous pouvez √©galement utiliser l'appareil photo ou le cam√©scope int√©gr√© de votre ordinateur portable avec tout syst√®me appropri√© pour l'analyse vid√©o en temps r√©el au lieu de ceux que j'ai utilis√©s. <br></li><li>  Il est pr√©f√©rable d'utiliser un processeur graphique pour un traitement vid√©o plus rapide. <br></li><li>  Nous avons utilis√© le syst√®me d'exploitation Ubuntu 18.04 avec tous les logiciels n√©cessaires. <br></li></ul><br>  Avant de poursuivre la construction de notre mod√®le de reconnaissance faciale, nous analyserons ces points plus en d√©tail. <br><br><h3>  √âtape 1: configuration mat√©rielle </h3><br>  V√©rifiez si la cam√©ra est correctement configur√©e.  Avec Ubuntu, c'est simple: voyez si l'appareil est reconnu par le syst√®me d'exploitation.  Pour ce faire, proc√©dez comme suit: <br><br><ol><li> Avant de connecter la webcam √† l'ordinateur portable, v√©rifiez tous les p√©riph√©riques vid√©o connect√©s en tapant <code>ls /dev/video*</code> √† l'invite de commande.  Par cons√©quent, une liste de tous les p√©riph√©riques vid√©o connect√©s au syst√®me appara√Æt. <img src="https://habrastorage.org/webt/za/h8/9m/zah89mjqr1gezzo8xekib9fhmzw.png"></li><li>  Connectez la webcam et relancez la commande.  Si la webcam est connect√©e correctement, le nouveau p√©riph√©rique sera refl√©t√© √† la suite de la commande. <img src="https://habrastorage.org/webt/bs/og/lc/bsoglcdg4tevubdfds6reijtogw.png"></li><li>  Vous pouvez √©galement utiliser le logiciel de webcam pour v√©rifier son bon fonctionnement.  Ubuntu peut utiliser le programme Cheese pour cela. <img src="https://habrastorage.org/webt/jl/9t/f3/jl9tf3b3qke5udd2fu3h1mzbcmo.png"></li></ol><br><h3>  √âtape 2: configuration du logiciel </h3><br>  <b>√âtape 2.1: installer Python</b> <br><br>  Le code de cet article a √©t√© √©crit en utilisant Python (version 3.5).  Pour installer Python, je recommande d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Anaconda</a> , une distribution Python populaire pour le traitement et l'analyse des donn√©es. <br><br>  <b>√âtape 2.2: Installez OpenCV</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenCV</a> est une biblioth√®que open source con√ßue pour cr√©er des applications de vision par ordinateur.  L'installation d'OpenCV se fait √† l'aide de <code>pip</code> : <br><br><pre> <code class="python hljs">pip3 install opencv-python</code> </pre> <br>  <b>√âtape 2.3: d√©finir l'API face_recognition</b> <br><br>  Nous utiliserons l' <code>face_recognition API</code> , qui est consid√©r√©e comme l'API de reconnaissance de visage Python la plus simple au monde.  Pour installer, utilisez: <br><br><pre> <code class="python hljs">pip install dlib pip install face_recognition</code> </pre> <br><h2>  Impl√©mentation </h2><br>  Apr√®s avoir configur√© le syst√®me, nous proc√©dons √† la mise en ≈ìuvre.  Pour commencer, nous allons cr√©er un programme puis expliquer ce que nous avons fait. <br><br><h3>  Proc√©dure pas √† pas </h3><br>  Cr√©ez un fichier <code>face_detector.py</code> , puis copiez le code ci-dessous: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># import libraries import cv2 import face_recognition # Get a reference to webcam video_capture = cv2.VideoCapture("/dev/video1") # Initialize variables face_locations = [] while True: # Grab a single frame of video ret, frame = video_capture.read() # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses) rgb_frame = frame[:, :, ::-1] # Find all the faces in the current frame of video face_locations = face_recognition.face_locations(rgb_frame) # Display the results for top, right, bottom, left in face_locations:  # Draw a box around the face  cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2) # Display the resulting image cv2.imshow('Video', frame) # Hit 'q' on the keyboard to quit! if cv2.waitKey(1) &amp; 0xFF == ord('q'):  break # Release handle to the webcam video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre> <br>  Ex√©cutez ensuite ce fichier Python en tapant: <br><br><pre> <code class="python hljs">python face_detector.py</code> </pre> <br>  Si tout fonctionne correctement, une nouvelle fen√™tre s'ouvrira avec le mode de reconnaissance des visages lanc√© en temps r√©el. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/eh14NomINOs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Pour r√©sumer et expliquer ce que notre code a fait: <br><br><ol><li>  Tout d'abord, nous avons <b>indiqu√© le mat√©riel</b> sur lequel la vid√©o sera analys√©e. <br></li><li>  Nous avons ensuite r√©alis√© une <b>capture vid√©o en</b> temps <b>r√©el</b> image par image. <br></li><li>  Ensuite, <b>chaque image a √©t√© trait√©e</b> et l' <b>emplacement de tous les visages</b> dans l'image a √©t√© <b>extrait</b> . <br></li><li>  En cons√©quence, <b>ces images ont √©t√© reproduites sous forme de vid√©o</b> avec une indication de l'emplacement des visages. <br></li></ol><br><h3>  Exemple d'application de reconnaissance faciale </h3><br>  Ce n'est pas tout le plaisir qui se termine.  Nous ferons encore une chose sympa: nous allons cr√©er un exemple d'application √† part enti√®re bas√© sur le code ci-dessus.  Nous apporterons de petites modifications au code et tout sera pr√™t. <br><br>  Supposons que vous souhaitiez cr√©er un syst√®me automatis√© √† l'aide d'un cam√©scope pour suivre o√π se trouve actuellement l'enceinte.  Selon sa position, le syst√®me fait pivoter la cam√©ra de sorte que le haut-parleur reste toujours au centre du cadre. <br>  La premi√®re √©tape consiste √† cr√©er un syst√®me qui identifie la ou les personnes dans la vid√©o et se concentre sur l'emplacement du locuteur. <br><br><img src="https://habrastorage.org/webt/xg/q-/ub/xgq-ubchs7yktjujlxcoakih7d0.png"><br><br>  Voyons comment proc√©der.  √Ä titre d'exemple, j'ai s√©lectionn√© une vid√©o sur YouTube avec un discours des intervenants de la conf√©rence DataHack Summit 2017. <br><br>  Tout d'abord, importez les biblioth√®ques n√©cessaires: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> face_recognition</code> </pre> <br>  Ensuite, nous lisons la vid√©o et d√©finissons la dur√©e: <br><br><pre> <code class="python hljs">input_movie = cv2.VideoCapture(<span class="hljs-string"><span class="hljs-string">"sample_video.mp4"</span></span>) length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))</code> </pre> <br>  Apr√®s cela, nous cr√©ons un fichier de sortie avec la r√©solution et la fr√©quence d'images n√©cessaires similaires √† celles du fichier d'entr√©e. <br><br>  Nous chargeons l'image du haut-parleur comme √©chantillon pour la reconna√Ætre sur la vid√©o: <br><br><pre> <code class="python hljs">image = face_recognition.load_image_file(<span class="hljs-string"><span class="hljs-string">"sample_image.jpeg"</span></span>) face_encoding = face_recognition.face_encodings(image)[<span class="hljs-number"><span class="hljs-number">0</span></span>] known_faces = [ face_encoding, ]</code> </pre> <br>  Une fois termin√©, nous entamons le cycle qui sera: <br><br><ul><li>  Extraire l'image de la vid√©o. <br></li><li>  Trouvez tous les visages et identifiez-les. <br></li><li>  Cr√©ez une nouvelle vid√©o qui combinera le cadre d'origine avec l'emplacement du visage de l'orateur avec une signature. <br></li></ul><br>  Regardons le code qui ex√©cutera ceci: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Initialize variables face_locations = [] face_encodings = [] face_names = [] frame_number = 0 while True: # Grab a single frame of video ret, frame = input_movie.read() frame_number += 1 # Quit when the input video file ends if not ret:  break # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses) rgb_frame = frame[:, :, ::-1] # Find all the faces and face encodings in the current frame of video face_locations = face_recognition.face_locations(rgb_frame, model="cnn") face_encodings = face_recognition.face_encodings(rgb_frame, face_locations) face_names = [] for face_encoding in face_encodings:  # See if the face is a match for the known face(s)  match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)  name = None  if match[0]:      name = "Phani Srikant"  face_names.append(name) # Label the results for (top, right, bottom, left), name in zip(face_locations, face_names):  if not name:      continue      # Draw a box around the face  cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)  # Draw a label with a name below the face  cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)       font = cv2.FONT_HERSHEY_DUPLEX  cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1) # Write the resulting image to the output video file print("Writing frame {} / {}".format(frame_number, length)) output_movie.write(frame) # All done! input_movie.release() cv2.destroyAllWindows()</span></span></code> </pre> <br>  Le code vous donnera ce r√©sultat: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/uOcN6FhX6gY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Des √©diteurs </h2><br>  Cours de netologie sur le sujet: <br><br><ul><li>  profession en ligne " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©veloppeur Python</a> " </li><li>  Profession en ligne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Data Scientist</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr434354/">https://habr.com/ru/post/fr434354/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr434340/index.html">Comment nous avons audit√© le Wi-Fi dans le m√©tro de Delhi et ce qui en est ressorti</a></li>
<li><a href="../fr434342/index.html">Cours MIT "S√©curit√© des syst√®mes informatiques". Conf√©rence 22: ¬´Information Security MIT¬ª, partie 1</a></li>
<li><a href="../fr434344/index.html">Cours MIT "S√©curit√© des syst√®mes informatiques". Conf√©rence 22: ¬´Information Security MIT¬ª, partie 2</a></li>
<li><a href="../fr434346/index.html">Cours MIT "S√©curit√© des syst√®mes informatiques". Conf√©rence 22: ¬´Information Security MIT¬ª, partie 3</a></li>
<li><a href="../fr434348/index.html">Vous souvenez-vous de votre mot de passe sur Habr√©?</a></li>
<li><a href="../fr434356/index.html">Python Stiller avec e-mail</a></li>
<li><a href="../fr434358/index.html">Substitution d'importation de syst√®mes d'exploitation. Comment puis-je voir le syst√®me d'exploitation national</a></li>
<li><a href="../fr434360/index.html">Discussion expliqu√©e sur la programmation asynchrone en Javascript</a></li>
<li><a href="../fr434362/index.html">PAS pr√©vu pour 2019</a></li>
<li><a href="../fr434364/index.html">Prise en charge de la file d'attente Hangfire</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
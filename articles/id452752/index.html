<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßòüèª ‚ÜïÔ∏è üéñÔ∏è BigData buatan rumah. Bagian 1. Praktek Spark Streaming pada gugus AWS ‚ú® ‚è∞ üíì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo 

 Ada banyak layanan di Internet yang menyediakan layanan cloud. Dengan bantuan mereka, Anda dapat mempelajari teknologi BigData. 

 Pada artike...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>BigData buatan rumah. Bagian 1. Praktek Spark Streaming pada gugus AWS</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/homecredit/blog/452752/">  Halo <br><br>  Ada banyak layanan di Internet yang menyediakan layanan cloud.  Dengan bantuan mereka, Anda dapat mempelajari teknologi BigData. <br><br>  Pada artikel ini, kita akan menginstal Apache Kafka, Apache Spark, Zookeeper, Spark-shell di platform EC2 AWS (Amazon Web Services) di rumah dan belajar cara menggunakannya. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/51c/95c/810/51c95c8104a988a0288067e9eaaf700f.jpg" alt="gambar"></div><br><a name="habracut"></a><br><h3>  Memperkenalkan Layanan Web Amazon </h3><br>  Anda harus mendaftar di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">aws.amazon.com/console</a> .  Masukkan nama dan ingat kata sandi. <br><br>  Konfigurasikan instance simpul untuk layanan Zookeeper dan Kafka. <br><br><ul><li>  Pilih "Layanan-&gt; EC2" dari menu.  Selanjutnya, pilih versi sistem operasi gambar mesin virtual, pilih Ubuntu Server 16.04 LTS (HVM), tipe volume SSD, klik "Pilih." Kami melanjutkan untuk mengonfigurasi contoh server: ketik "t3.medium" dengan parameter 2vCPU, memori 4 GB, Tujuan Umum Klik "Selanjutnya: Mengkonfigurasi Detail Instance". </li><li>  Tambahkan jumlah instance 1, klik "Next: Add Storage" </li><li>  Kami menerima nilai default untuk ukuran disk 8 GB dan mengubah jenisnya menjadi Magnetik (dalam pengaturan Produksi berdasarkan volume data dan SSD Kinerja Tinggi) </li><li>  Di bagian "Tag Instances" untuk "Name", masukkan nama instance dari simpul "Home1" (di mana 1 hanya nomor seri) dan klik "Next: ..." </li><li>  Di bagian "Konfigurasikan Grup Keamanan", pilih opsi "Gunakan grup keamanan yang ada" dengan memilih nama grup keamanan ("Spark_Kafka_Zoo_Project") dan tetapkan aturan untuk lalu lintas masuk.  Klik pada "Selanjutnya: ..." </li><li>  Gulir melalui layar Tinjau untuk memverifikasi entri Anda dan meluncurkan Peluncuran. </li><li>  Untuk terhubung ke node cluster, Anda harus membuat (dalam kasus kami, gunakan yang ada) sepasang kunci publik untuk identifikasi dan otorisasi.  Untuk melakukan ini, pilih jenis operasi "Gunakan pasangan yang ada" dalam daftar. </li></ul><br><h3>  Penciptaan Kunci </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Unduh Putty</a> (https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html) untuk klien atau gunakan koneksi SSH dari terminal. </li><li>  File kunci .pem menggunakan format lama untuk kenyamanan, kami mengonversinya menjadi format ppk yang digunakan oleh Putty.  Untuk melakukan ini, jalankan utilitas PuTTYgen, muat kunci dalam format .pem lama ke dalam utilitas.  Kami mengonversi kunci dan menyimpan (Simpan Kunci Pribadi) untuk digunakan nanti di folder beranda dengan ekstensi .ppk. </li></ul><br><h3>  Peluncuran cluster </h3><br>  Untuk kenyamanan, ganti nama node cluster dalam notasi Node01-04.  Untuk menyambungkan ke node cluster dari komputer lokal melalui SSH, Anda perlu menentukan alamat IP dari node dan nama publik / privatnya DNS, pilih masing-masing node cluster satu per satu dan untuk contoh yang dipilih, tuliskan nama DNS publik / pribadi untuk menghubungkan melalui SSH dan untuk instalasi Perangkat lunak ke file teks HadoopAdm01.txt. <br><br>  Contoh: ec2-35-162-169-76.us-west-2.compute.amazonaws.com <br><br><h3>  Instal Apache Kafka dalam Mode SingleNode pada AWS Cluster Node </h3><br>  Untuk menginstal perangkat lunak, pilih simpul kami (salin DNS Publik-nya) untuk terhubung melalui SSH.  Kami mengkonfigurasi koneksi melalui SSH.  Kami menggunakan nama simpanan simpul pertama untuk mengonfigurasi koneksi melalui SSH menggunakan pasangan kunci Privat / Publik ‚ÄúHadoopUser01.ppk‚Äù yang dibuat pada klausa 1.3.  Kami pergi ke bagian Connection / Auth melalui tombol Browse dan mencari folder tempat kami sebelumnya menyimpan file "HadoopUserXX.ppk". <br><br>  Kami menyimpan konfigurasi koneksi dalam pengaturan. <br><br>  Kami terhubung ke node dan menggunakan login: ubuntu. <br><br><ul><li>  Menggunakan hak akses root, kami memperbarui paket dan menginstal paket tambahan yang diperlukan untuk instalasi lebih lanjut dan konfigurasi cluster. <br><br><pre><code class="plaintext hljs">sudo apt-get update sudo apt-get -y install wget net-tools netcat tar</code> </pre> </li><li>  Instal Java 8 jdk dan periksa versi Java. <br><br><pre> <code class="plaintext hljs">sudo apt-get -y install openjdk-8-jdk</code> </pre> </li><li>  Untuk kinerja node cluster normal, Anda perlu menyesuaikan pengaturan pertukaran memori.  VM swappines diatur ke 60% secara default, yang berarti ketika menggunakan memori dalam 60%, sistem akan secara aktif bertukar data dari RAM ke disk.  Tergantung pada versi Linux, parameter swappines VM dapat diatur ke 0 atau 1: <br><br><pre> <code class="plaintext hljs">sudo sysctl vm.swappiness=1</code> </pre> <br></li><li>  Untuk menyimpan pengaturan saat reboot, tambahkan baris ke file konfigurasi. <br><br><pre> <code class="plaintext hljs">echo 'vm.swappiness=1' | sudo tee --append /etc/sysctl.conf</code> </pre> <br></li><li>  Mengedit entri dalam file / etc / hosts untuk memudahkan penyelesaian nama simpul dari cluster kafka dan <br>  zookeeper di alamat IP pribadi ke node cluster yang ditugaskan. <br><br><pre> <code class="plaintext hljs">echo "172.31.26.162 host01" | sudo tee --append /etc/hosts</code> </pre> <br>  Kami memeriksa pengakuan nama yang benar menggunakan ping salah satu entri. <br><br></li><li>  Unduh versi terbaru saat ini (http://kafka.apache.org/downloads) dari distribusi kafka dan scala dan siapkan direktori dengan file instalasi. <br><br><pre> <code class="plaintext hljs">wget http://mirror.linux-ia64.org/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgz tar -xvzf kafka_2.12-2.1.0.tgz ln -s kafka_2.12-2.1.0 kafka</code> </pre> <br></li><li>  Hapus file arsip tgz, kita tidak lagi membutuhkannya <br><br></li><li>  Mari kita coba untuk memulai layanan Zookeeper, untuk ini: <br><br><pre> <code class="plaintext hljs">~/kafka/bin/zookeeper-server-start.sh -daemon ~/kafka/config/zookeeper.properties</code> </pre> <br>  Zookeeper memulai dengan opsi startup default.  Anda dapat memeriksa log: <br><br><pre> <code class="plaintext hljs">tail -n 5 ~/kafka/logs/zookeeper.out</code> </pre> <br>  Untuk memastikan bahwa daemon Zookeeper dimulai, setelah reboot, kita perlu menjalankan Zookeper sebagai layanan latar belakang: <br><br><pre> <code class="plaintext hljs">bin/zookeeper-server-start.sh -daemon config/zookeeper.properties</code> </pre> <br>  Untuk memeriksa peluncuran Zookepper, periksa <br><br><pre> <code class="plaintext hljs">netcat -vz localhost 2181</code> </pre> <br>  Kami mengonfigurasi layanan Zookeeper dan Kafka untuk bekerja.  Awalnya, edit / buat file /etc/systemd/system/zookeeper.service (isi file di bawah). <br><br><pre> <code class="plaintext hljs">[Unit] Description=Apache Zookeeper server Documentation=http://zookeeper.apache.org Requires=network.target remote-fs.target After=network.target remote-fs.target [Service] Type=simple ExecStart=/home/ubuntu/kafka/bin/zookeeper-server-start.sh /home/ubuntu/kafka/config/zookeeper.properties ExecStop=/home/ubuntu/kafka/bin/zookeeper-server-stop.sh [Install] WantedBy=multi-user.target</code> </pre> <br>  Selanjutnya, untuk Kafka, edit / buat file /etc/systemd/system/kafka.service (isi file di bawah). <br><br><pre> <code class="plaintext hljs">[Unit] Description=Apache Kafka server (broker) Documentation=http://kafka.apache.org/documentation.html Requires=zookeeper.service [Service] Type=simple ExecStart=/home/ubuntu/kafka/bin/kafka-server-start.sh /home/ubuntu/kafka/config/server.properties ExecStop=/home/ubuntu/kafka/bin/kafka-server-stop.sh [Install] WantedBy=multi-user.target</code> </pre> <br></li><li>  Kami mengaktifkan skrip systemd untuk layanan Kafka dan Zookeeper. <br><br><pre> <code class="plaintext hljs">sudo systemctl enable zookeeper sudo systemctl enable kafka</code> </pre> <br></li><li>  Periksa pengoperasian skrip systemd. <br><br><pre> <code class="plaintext hljs">sudo systemctl start zookeeper sudo systemctl start kafka sudo systemctl status zookeeper sudo systemctl status kafka sudo systemctl stop zookeeper sudo systemctl stop kafka</code> </pre> <br></li><li>  Kami akan memeriksa fungsionalitas layanan Kafka dan Zookeeper. <br><br><pre> <code class="plaintext hljs">netcat -vz localhost 2181 netcat -vz localhost 9092</code> </pre> <br></li><li>  Periksa file log zookeeper. <br><br><pre> <code class="plaintext hljs">cat logs/zookeeper.out</code> </pre> </li></ul><br><h3>  Sukacita pertama </h3><br>  Kami membuat topik pertama kami di server kafka rakitan. <br><br><ul><li>  Penting untuk menggunakan koneksi ke "host01: 2181" seperti yang Anda tunjukkan dalam file konfigurasi server.properties. <br></li><li>  Kami menulis beberapa data dalam topik. <br><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list host01:9092 --topic first_topic    </code> </pre> <br>  Ctrl-C - keluar dari konsol topik. <br><br></li><li>  Sekarang coba baca data dari topik. <br><br><pre> <code class="plaintext hljs">kafka-console-consumer.sh --bootstrap-server host01:9092 --topic last_topic --from-beginning</code> </pre> <br></li><li>  Mari kita lihat daftar topik kafka. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper spark01:2181 --list</code> </pre> <br></li><li>  Mengedit pengaturan server kafka untuk tuning untuk pengaturan cluster tunggal <br>  # Anda perlu mengubah parameter ISR ke 1. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper spark01:2181 --config min.insync.replicas=1 --topic __consumer_offsets --alter</code> </pre> <br></li><li>  Kami me-restart server Kafka dan mencoba menghubungkan konsumen ohm lagi <br><br></li><li>  Mari kita lihat daftar topik. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper host01:2181 --list</code> </pre> </li></ul><br><h3>  Konfigurasikan Apache Spark pada kluster node-tunggal </h3><br>  Kami menyiapkan instance node dengan layanan Zookeeper dan Kafka yang diinstal pada AWS, sekarang Anda perlu menginstal Apache Spark, untuk ini: <br><br>  Unduh distribusi Apache Spark terbaru. <br><br><pre> <code class="plaintext hljs">wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.6.tgz</code> </pre> <br><br><ul><li>  Buka zip distribusi dan buat tautan simbolik untuk percikan dan hapus file arsip yang tidak perlu. <br><br><pre> <code class="plaintext hljs">tar -xvf spark-2.4.0-bin-hadoop2.6.tgz ln -s spark-2.4.0-bin-hadoop2.6 spark rm spark*.tgz</code> </pre> <br></li><li>  Buka direktori sbin dan jalankan wizard spark. <br><br><pre> <code class="plaintext hljs">./start-master.sh</code> </pre> <br></li><li>  Kami terhubung menggunakan browser web ke server Spark pada port 8080. <br><br></li><li>  Jalankan spark-slave pada node yang sama <br><br><pre> <code class="plaintext hljs">./start-slave.sh spark://host01:7077</code> </pre> <br></li><li>  Jalankan cangkang percikan dengan master pada host01. <br><br><pre> <code class="plaintext hljs">./spark-shell --master spark://host01:7077</code> </pre> <br></li><li>  Jika peluncuran tidak berhasil, tambahkan jalur ke Spark di bash. <br><br><pre> <code class="plaintext hljs">vi ~/.bashrc #      SPARK_HOME=/home/ubuntu/spark export PATH=$SPARK_HOME/bin:$PATH</code> </pre> <br><pre> <code class="plaintext hljs">source ~/.bashrc</code> </pre> <br></li><li>  Jalankan cangkang percikan lagi dengan master pada host01. <br><br><pre> <code class="plaintext hljs">./spark-shell --master spark://host01:7077</code> </pre> <br>  Cluster single-node dengan Kafka, Zookeeper dan Spark berfungsi.  Hore! </li></ul><br><h3>  Sedikit kreativitas </h3><br>  Unduh editor Scala-IDE (di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">scala-ide.org</a> ).  Kami mulai dan mulai menulis kode.  Di sini saya tidak akan mengulangi lagi, karena ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel yang bagus tentang Habr√©</a> . <br><br>  Literatur dan kursus yang berguna untuk membantu: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">courses.hadoopinrealworld.com/courses/enrolled/319237</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">data-flair.training/blogs/kafka-consumer</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">www.udemy.com/apache-spark-with-scala-hands-on-with-big-data</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id452752/">https://habr.com/ru/post/id452752/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id452742/index.html">Menyiapkan pengujian otomatis aplikasi hybrid</a></li>
<li><a href="../id452744/index.html">Apakah ada kehidupan penuh seorang pengubah tanpa pertukaran lepas?</a></li>
<li><a href="../id452746/index.html">Buku "The Art of Programming dalam R. Immersing in Big Data"</a></li>
<li><a href="../id452748/index.html">Prinsip pengembangan aplikasi modern dari NGINX. Bagian 1</a></li>
<li><a href="../id452750/index.html">Nextcloud di dalam dan di luar OpenLiteSpeed: konfigurasikan proxy terbalik</a></li>
<li><a href="../id452754/index.html">19% dari gambar Docker paling populer tidak memiliki kata sandi root</a></li>
<li><a href="../id452756/index.html">Menciptakan Tower Defense in Unity: Enemies</a></li>
<li><a href="../id452760/index.html">Vitamin D. Untuk minum atau tidak minum, itulah pertanyaannya. (Atau cerita tentang bagaimana saya melewati analisis yang tidak saya resepkan)</a></li>
<li><a href="../id452762/index.html">MVCC-7. Pembersihan otomatis</a></li>
<li><a href="../id452764/index.html">[Peter] Bertemu JUG.ru dengan Sergei Melnikov - Profiling dengan kecepatan superluminal: teori dan praktik</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
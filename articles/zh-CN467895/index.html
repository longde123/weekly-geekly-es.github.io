<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍❤️‍👨 🥙 📏 神经网络会找到什么模式？ 👃🏼 💃🏽 👩‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="在这篇文章中，我想谈谈神经网络可以找到的模式。 许多针对初学者的指南都侧重于为神经网络编写代码的技术，而“逻辑”问题（神经网络能做什么？哪种体系结构更适合于哪些任务，为什么？）通常处于观望状态。 希望我的帖子可以帮助初学者更好地了解神经网络的功能。 为此，我们将尝试看看它们如何处理某些模型任务。 将...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>神经网络会找到什么模式？</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/467895/"> 在这篇文章中，我想谈谈神经网络可以找到的模式。 许多针对初学者的指南都侧重于为神经网络编写代码的技术，而“逻辑”问题（神经网络能做什么？哪种体系结构更适合于哪些任务，为什么？）通常处于观望状态。 希望我的帖子可以帮助初学者更好地了解神经网络的功能。 为此，我们将尝试看看它们如何处理某些模型任务。 将使用keras库在python中提供示例代码。 <br><br>  <b>任务1.</b>让我们从一个简单的例子开始。 我们构造一个近似正弦的神经网络。 <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_X_y</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(n)</span></span></span><span class="hljs-function">:</span></span> X = np.random.uniform(<span class="hljs-number"><span class="hljs-number">0</span></span>, np.pi, n) y = np.sin(X) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> X, y n = <span class="hljs-number"><span class="hljs-number">40</span></span> X, y = get_X_y(n) print(<span class="hljs-string"><span class="hljs-string">"X shape:"</span></span>, X.shape) model = Sequential() model.add(Dense(<span class="hljs-number"><span class="hljs-number">6</span></span>, input_dim=<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">4</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>]) model.fit(X, y, epochs=<span class="hljs-number"><span class="hljs-number">1000</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">4</span></span>) X_test = np.linspace(start=<span class="hljs-number"><span class="hljs-number">0</span></span>, stop=np.pi, num=<span class="hljs-number"><span class="hljs-number">500</span></span>) print(<span class="hljs-string"><span class="hljs-string">"X test shape:"</span></span>, X_test.shape) y_test = model.predict(X_test) font = {<span class="hljs-string"><span class="hljs-string">'weight'</span></span>: <span class="hljs-string"><span class="hljs-string">'bold'</span></span>, <span class="hljs-string"><span class="hljs-string">'size'</span></span>: <span class="hljs-number"><span class="hljs-number">25</span></span>} matplotlib.rc(<span class="hljs-string"><span class="hljs-string">'font'</span></span>, **font) axes = plt.gca() axes.set_ylim(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.plot(X_test, y_test, c=<span class="hljs-string"><span class="hljs-string">'green'</span></span>, marker=<span class="hljs-string"><span class="hljs-string">'o'</span></span>, markersize=<span class="hljs-number"><span class="hljs-number">5</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"Sinus approximated by neural network"</span></span>) plt.yticks(np.arange(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>)) plt.grid() plt.show()</code> </pre> <br> 我们得到以下图表： <br><br><img src="https://habrastorage.org/webt/t3/xv/_o/t3xv_ocq-o9m8yupmxxdrfxqgai.png" width="500" height="500"><br><br> 如您所见，神经网络成功地完成了逼近简单函数的任务。 <br><a name="habracut"></a><br>  <b>任务2。</b>让我们看看神经网络将如何处理更复杂的任务。 我们将输入均匀分布在间隔[0，1]上的x值，并且y将被随机设置：对于x &lt;0.6，y将是一个随机变量，其值为0，概率为0.75，1为概率为0.25（即，一个二项式随机值，其值为p = 0.25）。 对于x&gt; 0.6，y将是一个随机变量，其值为0的概率为0.3，值为1的概率为0.7。 作为优化功能，我们采用标准误差。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_X_y</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(n)</span></span></span><span class="hljs-function">:</span></span> X = np.random.uniform(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, n) y0 = np.random.binomial(size=n, n=<span class="hljs-number"><span class="hljs-number">1</span></span>, p=<span class="hljs-number"><span class="hljs-number">0.25</span></span>) y1 = np.random.binomial(size=n, n=<span class="hljs-number"><span class="hljs-number">1</span></span>, p=<span class="hljs-number"><span class="hljs-number">0.7</span></span>) y = np.where(X &lt; <span class="hljs-number"><span class="hljs-number">0.6</span></span>, y0, y1) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> X, y n_inputs = <span class="hljs-number"><span class="hljs-number">1</span></span> n_hidden1 = <span class="hljs-number"><span class="hljs-number">100</span></span> n_hidden2 = <span class="hljs-number"><span class="hljs-number">50</span></span> n_outputs = <span class="hljs-number"><span class="hljs-number">1</span></span> n = <span class="hljs-number"><span class="hljs-number">2000</span></span> X, y = get_X_y(n) print(<span class="hljs-string"><span class="hljs-string">"X shape:"</span></span>, X.shape) model = Sequential() model.add(Dense(n_hidden1, input_dim=<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(n_hidden2, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) model.fit(X, y, epochs=<span class="hljs-number"><span class="hljs-number">200</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">100</span></span>) X_test = np.linspace(start=<span class="hljs-number"><span class="hljs-number">0</span></span>, stop=<span class="hljs-number"><span class="hljs-number">1</span></span>, num=<span class="hljs-number"><span class="hljs-number">100</span></span>) print(<span class="hljs-string"><span class="hljs-string">"X test shape:"</span></span>, X_test.shape) y_test = model.predict(X_test) font = {<span class="hljs-string"><span class="hljs-string">'weight'</span></span>: <span class="hljs-string"><span class="hljs-string">'bold'</span></span>, <span class="hljs-string"><span class="hljs-string">'size'</span></span>: <span class="hljs-number"><span class="hljs-number">25</span></span>} matplotlib.rc(<span class="hljs-string"><span class="hljs-string">'font'</span></span>, **font) axes = plt.gca() axes.set_ylim(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.plot(X_test, y_test, c=<span class="hljs-string"><span class="hljs-string">'green'</span></span>, marker=<span class="hljs-string"><span class="hljs-string">'o'</span></span>, markersize=<span class="hljs-number"><span class="hljs-number">5</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"Binomial distribution approximated by neural network"</span></span>) plt.yticks(np.arange(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>)) plt.grid() plt.show()</code> </pre><br> 我们得到以下近似函数神经网络图： <br><br><img src="https://habrastorage.org/webt/y_/rp/lo/y_rplovhyaxioena0tb8iueed9m.png" width="500" height="500"><br><br> 如您所见，神经网络近似了我们的随机变量y的数学期望。 因此，神经网络可以（原则上）近似于取决于参数的随机变量的平均值。 例如，我们可以期望他们解决以下问题：收入不超过$ 1,000的人们平均不满意，而收入超过$ 1,000的人们平均不满意； 必须学会根据收入来预测“幸福程度”。 神经网络将能够找到幸福的平均水平对收入的依赖关系，尽管事实上，在任何收入水平的人中，幸福和不幸福并存。 <br><br>  <b>问题3。</b>现在我们转向序列的预测。 我们将考虑由以下规则给定的0和1的序列：10个成员-可能为0或1，如果前一项为0，则第11个等于1，如果前一项为1，则第11个等于0或1。我们将生成这样的长度为11的序列（10个输入序列成员和一个（最后一个，我们预测），并在我们的递归神经网络上对其进行训练。 在训练之后，让我们检查一下她如何应对新序列的预测（长度为11）。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LSTM, Dense <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_X_y</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(m, n)</span></span></span><span class="hljs-function">:</span></span> X = np.random.binomial(size=(m,n), n=<span class="hljs-number"><span class="hljs-number">1</span></span>, p=<span class="hljs-number"><span class="hljs-number">0.5</span></span>) y0 = np.ones(m) y1 = np.random.binomial(size=m, n=<span class="hljs-number"><span class="hljs-number">1</span></span>, p=<span class="hljs-number"><span class="hljs-number">0.5</span></span>) y = np.where(X[:, n<span class="hljs-number"><span class="hljs-number">-1</span></span>]==<span class="hljs-number"><span class="hljs-number">0</span></span>, y0, y1) X = np.reshape(X, (X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], X.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> X, y model = Sequential() model.add(LSTM(units=<span class="hljs-number"><span class="hljs-number">50</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>)) model.compile(optimizer = <span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss = <span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>) X_train, y_train = get_X_y(<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) model.fit(X_train, y_train, epochs = <span class="hljs-number"><span class="hljs-number">20</span></span>, batch_size = <span class="hljs-number"><span class="hljs-number">32</span></span>) m_test = <span class="hljs-number"><span class="hljs-number">12</span></span> n_test = <span class="hljs-number"><span class="hljs-number">10</span></span> X_test, y_test = get_X_y(m_test, n_test) y_predicted = model.predict(X_test) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(m_test): print(<span class="hljs-string"><span class="hljs-string">"x_last="</span></span>, X_test[i, n_test<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-string"><span class="hljs-string">"y_predicted="</span></span>, y_predicted[i, <span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br> 让我们看看我们的神经网络对测试序列的预测结果（您的结果将有所不同，因为在这里，序列选择和训练神经网络都存在随机性）。 <br><br><div class="scrollable-table"><table><tbody><tr><th> 序号 </th><th> 序列的倒数第二个成员 </th><th> 预测值 </th></tr><tr><td>  1个 </td><td>  0 </td><td>  0.96 </td></tr><tr><td>  2 </td><td>  0 </td><td>  0.95 </td></tr><tr><td>  3 </td><td>  0 </td><td>  0.97 </td></tr><tr><td>  4 </td><td>  0 </td><td>  0.96 </td></tr><tr><td>  5 </td><td>  0 </td><td>  0.96 </td></tr><tr><td>  6 </td><td>  1个 </td><td>  0.45 </td></tr><tr><td>  7 </td><td>  0 </td><td>  0.94 </td></tr><tr><td>  8 </td><td>  1个 </td><td>  0.50 </td></tr><tr><td>  9 </td><td>  0 </td><td>  0.96 </td></tr><tr><td>  10 </td><td>  1个 </td><td>  0.42 </td></tr><tr><td>  11 </td><td>  1个 </td><td>  0.44 </td></tr><tr><td>  12 </td><td>  0 </td><td>  0.92 </td></tr></tbody></table></div><br><br> 如您所见，如果序列的倒数第二个成员为0，则神经网络会预测一个接近1的值，如果它为1，则接近0.5的值。 这接近最佳预测。 来自“生活”的类似示例可能看起来像这样：“如果我今天去电影院，那么明天我将在一家餐馆吃午餐； 如果我今天去剧院，那么明天我将在任何地方吃午饭。” 如我们所见，神经网络可以捕获这种类型的信息，并通过去看电影（并去剧院去预测“介于两者之间”）来预测去餐馆的行程。 <br><br>  <b>任务4：</b>我们使神经网络的任务复杂化。 假设一切都与前面的示例相同，则仅序列的第11个成员不是由序列的前一个成员而是由序列的第二个成员（通过相同规则）确定的。 我们在这里不提供代码，因为它实际上与上一个没有区别。 我的实验表明，神经网络仍然可以找到一种模式，但是需要更多的时间（我必须使用100个历元而不是20个历元进行训练）。 <br> 因此，神经网络可以（再次从原理上澄清）捕获相当长期的依赖关系（在我们的“生活示例”中，它们可以捕获诸如“如果我一周前去看电影，今天就去餐馆”等模式）。 <br><br>  <b>任务5：</b>让我们看看神经网络如何使用可用信息进行预测。 <br> 为此，我们将对长度为4的序列进行训练。总共，我们将具有3个不同的等概率序列： <br><br> <code>0, 0, 1, 1 <br> 0, 1, 0, 1 <br> 0, 1, 1, 0</code> <br> <br> 因此，在初始组合为0、0之后，我们总是会遇到两个单位，在组合为0、1之后，我们同样有可能满足0或1，但是我们肯定会知道最后一个数字。 现在，我们将通过设置return_sequences = True来要求神经网络返回序列。 作为预测序列，我们将相同的序列移动一级，并在右侧添加零。 现在我们已经可以假设会发生什么：第一步，神经网络将产生一个接近2/3的数字（由于第二项的概率为2/3，因此第二项是1），然后对于0的组合，它将产生两个接近单位，对于0,1首先将给出接近0.5的数字，然后将给出接近0或1的数字，具体取决于我们是否获得序列0、1、0或0、1、1。在神经网络的末尾总是会产生接近0的数字。通过检查以下代码，我们的假设是正确的。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LSTM, Dense <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_X_y</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(n)</span></span></span><span class="hljs-function">:</span></span> X = np.zeros((n, <span class="hljs-number"><span class="hljs-number">4</span></span>)) z = np.array([random.randint(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n)]) X[z == <span class="hljs-number"><span class="hljs-number">0</span></span>, :] = [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>] X[z == <span class="hljs-number"><span class="hljs-number">1</span></span>, :] = [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>] X[z == <span class="hljs-number"><span class="hljs-number">2</span></span>, :] = [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] y = np.zeros((n, <span class="hljs-number"><span class="hljs-number">4</span></span>)) y[:, :<span class="hljs-number"><span class="hljs-number">3</span></span>] = X[:, <span class="hljs-number"><span class="hljs-number">1</span></span>:] X = np.reshape(X, (X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], X.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>)) y = np.reshape(y, (y.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], y.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> X, y model = Sequential() model.add(LSTM(units=<span class="hljs-number"><span class="hljs-number">20</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>)) model.compile(optimizer = <span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss = <span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>) X_train, y_train = get_X_y(<span class="hljs-number"><span class="hljs-number">1000</span></span>) model.fit(X_train, y_train, epochs = <span class="hljs-number"><span class="hljs-number">100</span></span>, batch_size = <span class="hljs-number"><span class="hljs-number">32</span></span>) X_test = np.zeros((<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>)) X_test[<span class="hljs-number"><span class="hljs-number">0</span></span>, :] = [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>] X_test[<span class="hljs-number"><span class="hljs-number">1</span></span>, :] = [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>] X_test[<span class="hljs-number"><span class="hljs-number">2</span></span>, :] = [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] X_test = np.reshape(X_test, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) y_predicted = model.predict(X_test) print(y_predicted)</code> </pre><br><br> 从这个例子中，我们看到神经网络可以根据收到的信息动态地改变预测。 我们会做同样的事情，尝试预测一个特定的顺序：当可用信息允许我们估计下一步结果的概率时，我们将基于此信息进行预测； 但是当我们在下一步中找到其他信息时，我们会根据此信息更改预测。 <br> 因此，如果我们发现有人从黑暗中来找我们，那么我们说：“这是一个人，我们不知道更多”。 当我们开始在黑暗中区分长发时，我们说“这可能是一个女人”。 但是，如果在那之后我们认为一个人有胡须，那么我们就说这可能是一个男人（尽管留着长发）。 如我们所见，神经网络的行为类似，使用当前可用的全部信息进行预测。 <br><br> 因此，我们看了神经网络如何工作以及可以找到哪些模式的简单示例。 总的来说，我们看到神经网络的行为通常是“合理的”，从而使预测接近人的预测。 尽管应该指出，为了捕捉简单的模式，它们需要的数据比人多得多。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN467895/">https://habr.com/ru/post/zh-CN467895/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN467883/index.html">Kubernetes 1.16-如何升级而不破坏任何内容</a></li>
<li><a href="../zh-CN467885/index.html">产品和分部地雷</a></li>
<li><a href="../zh-CN467887/index.html">现实的刻薄思考</a></li>
<li><a href="../zh-CN467891/index.html">关于云[电子]签名的常见问题</a></li>
<li><a href="../zh-CN467893/index.html">只是gRPC和protobuf的另一个Qt包装器</a></li>
<li><a href="../zh-CN467897/index.html">自动测试工具，Yandex Mapkit 3集成，出色的设计和服务器驱动的UI方法-Android Mitap公告</a></li>
<li><a href="../zh-CN467901/index.html">驳斥关于Rust编程语言的四种刻板印象</a></li>
<li><a href="../zh-CN467903/index.html">IntelliJ IDEA的前20个导航功能。 第一部分</a></li>
<li><a href="../zh-CN467905/index.html">我们如何在Cloud Mail.ru中进行地标识别，以及为什么</a></li>
<li><a href="../zh-CN467907/index.html">外包的利与弊</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游뱢游낕 游꿩 游뱈游낗 Implementaci칩n de aplicaciones en VM, Nomad y Kubernetes 游뗾 游놎游낗 游꼗</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos! Mi nombre es Pavel Agaletsky. Trabajo como l칤der de equipo en un equipo que desarrolla un sistema de entrega Lamoda. En 2018, habl칠 en l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Implementaci칩n de aplicaciones en VM, Nomad y Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lamoda/blog/451644/">  Hola a todos!  Mi nombre es Pavel Agaletsky.  Trabajo como l칤der de equipo en un equipo que desarrolla un sistema de entrega Lamoda.  En 2018, habl칠 en la conferencia HighLoad ++, y hoy quiero presentar una transcripci칩n de mi informe. <br><br>  Mi tema est치 dedicado a la experiencia de nuestra empresa en la implementaci칩n de sistemas y servicios en diferentes entornos.  Comenzando desde nuestros tiempos prehist칩ricos, cuando implementamos todos los sistemas en servidores virtuales regulares, terminando con una transici칩n gradual de Nomad a una implementaci칩n en Kubernetes.  Te dir칠 por qu칠 hicimos esto y qu칠 problemas tuvimos en el proceso. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/oqrb7dWECSo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  Implementar aplicaciones en VM </h1><br>  Para empezar, hace 3 a침os, todos los sistemas y servicios de la compa침칤a se implementaron en servidores virtuales comunes.  T칠cnicamente, se organiz칩 para que todo el c칩digo de nuestros sistemas se distribuyera y ensamblara utilizando herramientas de compilaci칩n autom치ticas con jenkins.  Con Ansible, estaba implementando nuestro sistema de control de versiones en servidores virtuales.  Adem치s, cada sistema que estaba en nuestra empresa se implement칩 al menos en 2 servidores: uno de ellos, en la cabeza, el segundo, en la cola.  Estos dos sistemas eran absolutamente id칠nticos entre s칤 en todos sus ajustes, potencia, configuraci칩n y m치s.  La 칰nica diferencia entre ellos era que la cabeza recib칤a tr치fico de usuarios, mientras que la cola nunca recib칤a tr치fico de usuarios. <br><br>  쯇or qu칠 se hizo esto? <br><br>  Cuando implementamos nuevas versiones de nuestra aplicaci칩n, quer칤amos ofrecer la posibilidad de un despliegue continuo, es decir, sin consecuencias notables para los usuarios.  Esto se logr칩 debido al hecho de que la pr칩xima versi칩n ensamblada con Ansible se lanz칩 en cola.  All칤, las personas que participaron en el despliegue pudieron verificar y asegurarse de que todo estaba bien: todas las m칠tricas, secciones y aplicaciones funcionaron;  Se inician los scripts necesarios.  Solo despu칠s de que se convencieron de que todo est치 bien, se cambi칩 el tr치fico.  Comenz칩 a ir al servidor que antes era cola.  Y el que era la cabeza antes, se qued칩 sin tr치fico de usuarios, mientras que con la versi칩n anterior de nuestra aplicaci칩n. <br><br>  Por lo tanto, para los usuarios fue perfecto.  Porque la conmutaci칩n es simult치nea, ya que es solo una conmutaci칩n equilibradora.  Es muy f치cil volver a la versi칩n anterior simplemente cambiando el balanceador hacia atr치s.  Tambi칠n podr칤amos verificar la capacidad de producci칩n de la aplicaci칩n incluso antes de que el tr치fico de usuarios llegue a ella, lo cual fue lo suficientemente conveniente. <br><br>  쯈u칠 ventajas vimos en todo esto? <br><br><ol><li>  En primer lugar, <b>funciona de manera</b> bastante <b>simple.</b>  Todos entienden c칩mo funciona este esquema de implementaci칩n, porque la mayor칤a de las personas se han implementado en servidores virtuales comunes. </li><li> Esto es bastante <b>confiable</b> , ya que la tecnolog칤a de implementaci칩n es simple, probada por miles de empresas.  Millones de servidores se implementan de esa manera.  Es dif칤cil romper algo. </li><li>  Y finalmente, podr칤amos obtener <b>despliegues at칩micos</b> .  Implementaciones que ocurren a los usuarios simult치neamente, sin una etapa notable de cambio entre la versi칩n anterior y la nueva. </li></ol><br>  Pero en esto tambi칠n vimos varias deficiencias: <br><br><ol><li>  Adem치s del entorno de producci칩n, el entorno de desarrollo, hay otros entornos.  Por ejemplo, qa y preproducci칩n.  En ese momento, ten칤amos muchos servidores y unos 60 servicios.  Por esta raz칩n, era necesario <b>que cada servicio mantuviera la versi칩n de la</b> m치quina virtual <b>que le era relevante</b> .  Adem치s, si desea actualizar bibliotecas o instalar nuevas dependencias, debe hacerlo en todos los entornos.  Tambi칠n era necesario sincronizar la hora en la que iba a implementar la pr칩xima versi칩n nueva de su aplicaci칩n con la hora en que los desarrolladores hicieron la configuraci칩n de entorno necesaria.  En este caso, es f치cil entrar en una situaci칩n en la que nuestro entorno ser치 ligeramente diferente a la vez en todos los entornos seguidos.  Por ejemplo, en el entorno de QA habr치 algunas versiones de bibliotecas, y en producci칩n, otras, lo que generar치 problemas. </li><li>  <b>Dificultad para actualizar las dependencias de</b> su aplicaci칩n.  No depende de ti, sino del otro equipo.  Es decir, desde el comando devops, que admite el servidor.  Debe establecer una tarea adecuada para ellos y dar una descripci칩n de lo que desea hacer. </li><li>  En ese momento, tambi칠n quer칤amos dividir los grandes monolitos grandes que ten칤amos en peque침os servicios separados, ya que entendimos que habr칤a m치s y m치s de ellos.  En ese momento, ya ten칤amos m치s de 100 de ellos. Era necesario que cada nuevo servicio creara una nueva m치quina virtual separada, que tambi칠n necesita ser reparada e implementada.  Adem치s, no necesita un autom칩vil, sino al menos dos.  A esto, el entorno de control de calidad todav칤a se est치 agregando.  Esto causa problemas y hace que crear y lanzar nuevos sistemas sea m치s <b>dif칤cil, costoso y lento para usted.</b> </li></ol><br>  Por lo tanto, decidimos que ser칤a m치s conveniente pasar de la implementaci칩n de m치quinas virtuales ordinarias a la implementaci칩n de nuestras aplicaciones en el contenedor docker.  Si tiene docker, necesita un sistema que pueda ejecutar la aplicaci칩n en el cl칰ster, ya que no puede simplemente levantar el contenedor.  Por lo general, desea realizar un seguimiento de cu치ntos contenedores se levantan para que se eleven autom치ticamente.  Por esta raz칩n, tuvimos que elegir un sistema de control. <br><br>  Pensamos durante mucho tiempo sobre cu치l se puede tomar.  El hecho es que en ese momento esta pila de implementaciones en servidores virtuales comunes estaba algo desactualizada, ya que no hab칤a las 칰ltimas versiones de los sistemas operativos all칤.  En alg칰n momento, incluso FreeBSD se qued칩 all칤, lo que no era muy conveniente de mantener.  Entendemos que debe migrar a Docker lo m치s r치pido posible.  Nuestros desarrolladores analizaron su experiencia existente con diferentes soluciones y eligieron un sistema como Nomad. <br><br><h1>  Cambiar a n칩mada </h1><br>  Nomad es un producto de HashiCorp.  Tambi칠n son conocidos por sus otras decisiones: <br><br><img src="https://habrastorage.org/webt/4e/vz/4e/4evz4entvdaauztnu558tb-2z9u.jpeg" alt="imagen"><br><br>  <b>Consul</b> es una herramienta para el descubrimiento de servicios. <br><br>  <b>Terraform</b> es un sistema de administraci칩n de servidores que le permite configurarlos a trav칠s de una configuraci칩n llamada infraestructura como c칩digo. <br><br>  <b>Vagrant le</b> permite implementar m치quinas virtuales localmente o en la nube a trav칠s de archivos de configuraci칩n espec칤ficos. <br><br>  Nomad en ese momento parec칤a una soluci칩n bastante simple a la que puede cambiar r치pidamente sin cambiar toda la infraestructura.  Adem치s, se domina con bastante facilidad.  Por lo tanto, lo elegimos como nuestro sistema de filtro para nuestro contenedor. <br><br>  쯈u칠 se necesita para implementar completamente su sistema en Nomad? <br><br><ol><li>  En primer lugar, necesita la <b>imagen acoplable de</b> su aplicaci칩n.  Debe compilarlo y colocarlo en el almacenamiento de im치genes de la ventana acoplable.  En nuestro caso, esto es un artefacto, un sistema que le permite insertar varios artefactos de varios tipos.  Puede almacenar archivos, im치genes acoplables, paquetes de compositor PHP, paquetes NPM, etc. </li><li>  Tambi칠n necesita un <b>archivo de configuraci칩n</b> que le indique a Nomad qu칠, d칩nde y cu치nto desea implementar. </li></ol><br>  Cuando hablamos de Nomad, utiliza el lenguaje HCL como un formato de archivo de informaci칩n, que significa <i>HashiCorp Configuration Language</i> .  Este es un superconjunto de Yaml que le permite describir su servicio en t칠rminos de Nomad. <br><br><img src="https://habrastorage.org/webt/vg/q9/vb/vgq9vb_izh4i890ro7giihibz6g.jpeg" alt="imagen"><br><br>  Le permite decir cu치ntos contenedores desea implementar, desde qu칠 im치genes transferirles varios par치metros durante la implementaci칩n.  Por lo tanto, alimenta este archivo Nomad y lanza contenedores en producci칩n de acuerdo con 칠l. <br><br>  En nuestro caso, nos dimos cuenta de que simplemente escribir exactamente los mismos archivos HLC id칠nticos para cada servicio no ser칤a muy conveniente, porque hay muchos servicios y, a veces, desea actualizarlos.  Sucede que un servicio se implementa no en una instancia, sino en las m치s diferentes.  Por ejemplo, uno de los sistemas que tenemos en producci칩n tiene m치s de 100 instancias en la producci칩n.  Se inician desde las mismas im치genes, pero difieren en la configuraci칩n y los archivos de configuraci칩n. <br><br>  Por lo tanto, decidimos que ser칤a conveniente para nosotros almacenar todos nuestros archivos de configuraci칩n para la implementaci칩n en un repositorio com칰n.  Por lo tanto, se volvieron observables: eran f치ciles de mantener y era posible ver qu칠 sistemas ten칤amos.  Si es necesario, tambi칠n es f치cil actualizar o cambiar algo.  Agregar un nuevo sistema tampoco es dif칤cil: solo ingrese el archivo de configuraci칩n dentro del nuevo directorio.  En su interior est치n los archivos: service.hcl, que contiene una descripci칩n de nuestro servicio, y algunos archivos env que permiten que este servicio, que se implementa en producci칩n, se configure. <br><br><img src="https://habrastorage.org/webt/-g/l7/8h/-gl78hl7nbmdbhbuacuntgxw4ow.jpeg" alt="imagen"><br><br>  Sin embargo, algunos de nuestros sistemas se implementan en el producto no en una copia, sino en varias a la vez.  Por lo tanto, decidimos que ser칤a conveniente para nosotros no almacenar configuraciones en su forma pura, sino en su forma de plantilla.  Y como lenguaje de plantilla elegimos <i>jinja 2</i> .  En este formato, almacenamos tanto las configuraciones del servicio como los archivos env necesarios para ello. <br><br>  Adem치s, colocamos en el repositorio un despliegue de secuencia de comandos com칰n para todos los proyectos, lo que le permite lanzar e implementar su servicio en producci칩n, en el entorno deseado, en el objetivo deseado.  En el caso en que convertimos nuestra configuraci칩n HCL en una plantilla, el archivo HCL, que anteriormente era una configuraci칩n Nomad normal, en este caso comenz칩 a verse un poco diferente. <br><br><img src="https://habrastorage.org/webt/9a/ib/zv/9aibzvsme34ra2eg53bjfbqt1tw.jpeg" alt="imagen"><br><br>  Es decir, reemplazamos algunas variables en el archivo de configuraci칩n con inserciones variables, que se toman de los archivos env o de otras fuentes.  Adem치s, pudimos recopilar archivos HL din치micamente, es decir, podemos usar no solo las inserciones variables habituales.  Dado que jinja admite bucles y condiciones, tambi칠n puede crear archivos de configuraci칩n all칤, que var칤an seg칰n d칩nde implemente exactamente sus aplicaciones. <br><br>  Por ejemplo, desea implementar su servicio en preproducci칩n y en producci칩n.  Suponga que en la preproducci칩n no desea ejecutar scripts de corona, solo desea ver el servicio en un dominio separado para asegurarse de que est칠 funcionando.  Para cualquiera que implemente un servicio, el proceso parece muy simple y transparente.  Es suficiente para ejecutar el archivo deploy.sh, especifique qu칠 servicio desea implementar y en qu칠 destino.  Por ejemplo, desea implementar un determinado sistema en Rusia, Bielorrusia o Kazajst치n.  Para hacer esto, simplemente cambie uno de los par치metros y tendr치 el archivo de configuraci칩n correcto. <br><br>  Cuando el servicio Nomad ya est치 implementado en su cl칰ster, se ve as칤. <br><br><img src="https://habrastorage.org/webt/nu/au/8d/nuau8dqdcwft0boyw57x37wrkcm.jpeg" alt="imagen"><br><br>  Primero, necesita un equilibrador externo que incorpore todo el tr치fico de usuarios.  Trabajar치 junto con C칩nsul y descubrir치 de 칠l d칩nde, en qu칠 nodo, en qu칠 direcci칩n IP hay un servicio espec칤fico que corresponde a un nombre de dominio particular.  Los servicios en Consul provienen del propio Nomad.  Como se trata de productos de la misma empresa, est치n bien conectados.  Podemos decir que Nomad listo para usar puede registrar todos los servicios lanzados en 칠l dentro de Consul. <br><br>  Despu칠s de que su equilibrador externo descubre a qu칠 servicio es necesario enviar tr치fico, lo redirige al contenedor apropiado oa varios contenedores que corresponden a su aplicaci칩n.  Naturalmente, tambi칠n es necesario pensar en la seguridad.  Aunque todos los servicios se ejecutan en las mismas m치quinas virtuales en contenedores, esto generalmente requiere la prohibici칩n del acceso gratuito de cualquier servicio a cualquier otro.  Logramos esto a trav칠s de la segmentaci칩n.  Cada servicio se lanz칩 en su propia red virtual, en la que se prescribieron reglas de enrutamiento y reglas para permitir / denegar el acceso a otros sistemas y servicios.  Podr칤an ubicarse tanto dentro de este grupo como fuera de 칠l.  Por ejemplo, si desea evitar que un servicio se conecte a una base de datos espec칤fica, esto puede hacerse mediante la segmentaci칩n a nivel de red.  Es decir, incluso por error, no puede conectarse accidentalmente desde un entorno de prueba a su base de producci칩n. <br><br>  쮺u치nto nos cost칩 la transici칩n en t칠rminos de recursos humanos? <br><br>  La transici칩n de toda la compa침칤a a Nomad tom칩 alrededor de 5-6 meses.  Cambiamos sin servicio, pero a un ritmo bastante r치pido.  Cada equipo tuvo que crear sus propios contenedores para los servicios. <br><br>  Hemos adoptado un enfoque tal que cada equipo es responsable de las im치genes acopladas de sus sistemas por su cuenta.  Los Devops tambi칠n proporcionan la infraestructura general necesaria para la implementaci칩n, es decir, soporte para el cl칰ster en s칤, soporte para el sistema CI, etc.  Y en ese momento ten칤amos m치s de 60 sistemas trasladados a Nomad, que result칩 en unos 2 mil contenedores. <br><br>  Devops es responsable de la infraestructura general de todo lo relacionado con la implementaci칩n, con los servidores.  Y cada equipo de desarrollo, a su vez, es responsable de la implementaci칩n de contenedores para su sistema espec칤fico, ya que es el equipo que sabe lo que generalmente necesita en un contenedor en particular. <br><br><h1>  Razones para abandonar a Nomad </h1><br>  쯈u칠 ventajas obtuvimos al cambiar a implementar usando Nomad y Docker tambi칠n? <br><br><ol><li>  <b>Proporcionamos las mismas condiciones</b> para todos los entornos.  En una empresa de desarrollo, entorno de control de calidad, preproducci칩n, producci칩n, se utilizan las mismas im치genes de contenedor, con las mismas dependencias.  En consecuencia, pr치cticamente no tiene posibilidades de que la producci칩n resulte ser diferente de lo que prob칩 anteriormente localmente o en un entorno de prueba. </li><li>  Tambi칠n descubrimos que es bastante <b>f치cil agregar un nuevo servicio</b> .  Desde el punto de vista de la implementaci칩n, cualquier sistema nuevo se lanza de manera muy simple.  Es suficiente ir al repositorio que almacena las configuraciones, agregar la siguiente configuraci칩n para su sistema all칤 y ya est치 listo.  Puede implementar su sistema en producci칩n sin esfuerzo adicional de los desarrolladores. </li><li>  Todos <b>los archivos de configuraci칩n</b> en un repositorio com칰n <b>resultaron ser monitoreados</b> .  En ese momento, cuando implementamos nuestros sistemas usando servidores virtuales, usamos Ansible, en el que las configuraciones se encuentran en el mismo repositorio.  Sin embargo, para la mayor칤a de los desarrolladores fue un poco m치s dif칤cil trabajar con ellos.  Aqu칤, el volumen de configuraciones y c칩digo que necesita agregar para implementar el servicio se ha vuelto mucho m치s peque침o.  Adem치s para devops es muy f치cil arreglarlo o cambiarlo.  En el caso de las transiciones, por ejemplo, en la nueva versi칩n de Nomad, pueden tomar y actualizar masivamente todos los archivos operativos que se encuentran en el mismo lugar. </li></ol><br>  Pero tambi칠n enfrentamos varias deficiencias: <br><br>  Result칩 que no <b>pudimos lograr implementaciones sin problemas</b> en el caso de Nomad.  Al sacar los contenedores de diferentes condiciones, podr칤a resultar que se estaba ejecutando, y Nomad lo percibi칩 como un contenedor listo para aceptar el tr치fico.  Esto sucedi칩 incluso antes de que la aplicaci칩n en su interior se iniciara.  Por esta raz칩n, el sistema comenz칩 a producir 500 errores por poco tiempo, porque el tr치fico comenz칩 a ir al contenedor, que a칰n no est치 listo para recibirlo. <br><br>  Nos encontramos con algunos <b>errores</b> .  El error m치s significativo es que Nomad no acepta muy bien un cl칰ster grande si tiene muchos sistemas y contenedores.  Cuando desee poner en servicio uno de los servidores incluidos en el cl칰ster Nomad, existe una alta probabilidad de que el cl칰ster no se sienta muy bien y se desmorone.  Parte de los contenedores puede, por ejemplo, caerse y no elevarse, lo que posteriormente ser치 muy costoso para usted si todos sus sistemas de producci칩n est치n ubicados en un cl칰ster administrado por Nomad. <br><br>  Por lo tanto, decidimos pensar a d칩nde ir despu칠s.  En ese momento, nos dimos cuenta de lo que quer칤amos lograr.  A saber: queremos confiabilidad, un poco m치s de funciones que las que ofrece Nomad y un sistema m치s maduro y estable. <br><br>  En este sentido, nuestra elecci칩n recay칩 en Kubernetes como la plataforma m치s popular para el lanzamiento de cl칰steres.  Especialmente siempre que el tama침o y la cantidad de nuestros contenedores fuera bastante grande.  Para tales prop칩sitos, Kubernetes parec칤a el sistema m치s adecuado de los que pod칤amos ver. <br><br><h1>  Yendo a Kubernetes </h1><br>  Hablar칠 un poco sobre los conceptos b치sicos de Kubernetes y c칩mo se diferencian de Nomad. <br><br><img src="https://habrastorage.org/webt/pv/eh/va/pvehvavusoxszoxum9bsuwyjqbc.jpeg" alt="imagen"><br><br>  En primer lugar, el concepto m치s b치sico en Kubernetes es el concepto de pod.  <b>Un pod</b> es un grupo de uno o m치s contenedores que siempre se ejecutan juntos.  Y parecen funcionar siempre estrictamente en la misma m치quina virtual.  Est치n disponibles entre s칤 a trav칠s de IP 127.0.0.1 en diferentes puertos. <br><br>  Supongamos que tiene una aplicaci칩n PHP que consiste en nginx y php-fpm, un circuito cl치sico.  Lo m치s probable es que desee que los contenedores nginx y php-fpm est칠n siempre juntos.  Kubernetes hace esto describi칠ndolos como una vaina com칰n.  Esto es exactamente lo que no pudimos obtener con la ayuda de Nomad. <br><br>  El segundo concepto es el <b>despliegue</b> .  El hecho es que la c치psula en s칤 es algo ef칤mero, comienza y desaparece.  Ya sea que desee eliminar primero todos sus contenedores anteriores y luego lanzar nuevas versiones a la vez, o si desea implementarlos gradualmente, este es el concepto del que es responsable la implementaci칩n.  Describe c칩mo despliega sus pods, en cu치ntos y c칩mo actualizarlos. <br><br>  El tercer concepto es el <b>servicio</b> .  Su servicio es en realidad su sistema, que recibe algo de tr치fico y luego lo dirige a uno o m치s pods que corresponden a su servicio.  Es decir, le permite decir que todo el tr치fico entrante a dicho servicio con dicho nombre debe enviarse a estos pods en particular.  Y al mismo tiempo, le proporciona equilibrio de tr치fico.  Es decir, puede ejecutar dos pods de su aplicaci칩n, y todo el tr치fico entrante se equilibrar치 de manera uniforme entre los pods relacionados con este servicio. <br><br>  Y el cuarto concepto b치sico es <b>Ingress</b> .  Este es un servicio que se ejecuta en un cl칰ster de Kubernetes.  Act칰a como un equilibrador de carga externo, que acepta todas las solicitudes.  Debido a la API, Kubernetes Ingress puede determinar d칩nde se deben enviar estas solicitudes.  Y lo hace con mucha flexibilidad.  Puede decir que todas las solicitudes a este host y dicha URL se env칤an a este servicio.  Y enviamos estas solicitudes a este host y a otra URL a otro servicio. <br><br>  Lo mejor desde el punto de vista de quien desarrolla la aplicaci칩n es que puede administrarlo todo usted mismo.  Una vez configurada la configuraci칩n de Ingress, puede enviar todo el tr치fico que llega a dicha API a contenedores separados registrados, por ejemplo, a Go.  Pero este tr치fico que llega al mismo dominio, pero a una URL diferente, debe enviarse a contenedores escritos en PHP, donde hay mucha l칩gica, pero no son muy r치pidos. <br><br>  Si comparamos todos estos conceptos con Nomad, entonces podemos decir que los primeros tres conceptos est치n todos juntos. Servicio.  Y falta el 칰ltimo concepto en Nomad.  Usamos un equilibrador externo, ya que puede ser haproxy, nginx, nginx +, etc.  En el caso de un cubo, no necesita introducir este concepto adicional por separado.  Sin embargo, si miras a Ingress por dentro, es nginx, o haproxy, o traefik, pero como si estuviera integrado en Kubernetes. <br><br>  Todos los conceptos que he descrito son esencialmente los recursos que existen dentro del cl칰ster de Kubernetes.  Para describirlos en el cubo, se utiliza el formato yaml, que es m치s legible y familiar que los archivos HCl en el caso de Nomad.  Pero estructuralmente describen en el caso de, por ejemplo, pod lo mismo.  Dicen: quiero desplegar tal y tal vaina all칤 y all치, con tal y tal imagen, en tal y tal cantidad. <br><br><img src="https://habrastorage.org/webt/2k/ka/53/2kka53a1vp1lm0rnl4xbhmcpyu4.jpeg" alt="imagen"><br><br>  Adem치s, nos dimos cuenta de que no quer칤amos crear cada recurso individual con nuestras propias manos: implementaci칩n, servicios, Ingress y m치s.  En cambio, quer칤amos describir cada sistema implementado en t칠rminos de Kubernetes durante la implementaci칩n para que no tuvi칠ramos que recrear manualmente todas las dependencias de recursos necesarias en el orden correcto.  Helm fue elegido como el sistema que nos permiti칩 hacer esto. <br><br><h1>  Conceptos clave en Helm </h1><br>  Helm es un <b>administrador de paquetes</b> para Kubernetes.  Es muy similar a c칩mo funcionan los gestores de paquetes en lenguajes de programaci칩n.  Le permiten almacenar un servicio que consiste, por ejemplo, en implementaci칩n nginx, implementaci칩n php-fpm, una configuraci칩n para Ingress, configmaps (esta es una entidad que le permite configurar env y otros par치metros para su sistema) en forma de los llamados gr치ficos.  Al mismo tiempo, Helm <b>corre sobre Kubernetes</b> .  Es decir, este no es un tipo de sistema que se hace a un lado, sino simplemente otro servicio que se ejecuta dentro del cubo.  Interact칰a con 칠l a trav칠s de su API a trav칠s de un comando de consola.  Su conveniencia y encanto es que incluso si el tim칩n se rompe o lo elimina del cl칰ster, sus servicios no desaparecer치n, ya que el tim칩n esencialmente solo sirve para iniciar el sistema.  Kubernetes es responsable del tiempo de actividad y el estado de los servicios. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tambi칠n nos dimos cuenta de que la </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">estandarizaci칩n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que antes ten칤a que hacerse de forma independiente mediante la introducci칩n de jinja en nuestras configuraciones, es una de las principales caracter칤sticas de helm. Todas las configuraciones que cree para sus sistemas se almacenan en helm en forma de plantillas similares a jinja, pero, de hecho, utilizando la plantilla de idioma Go en la que est치 escrito helm, como Kubernetes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Helm nos agrega algunos conceptos adicionales. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El cuadro</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> es una descripci칩n de su servicio. Otros administradores de paquetes lo llamar칤an paquete, paquete o algo as칤. Esto se llama gr치fico aqu칤. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los valores</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> son las variables que desea usar para construir sus configuraciones a partir de plantillas. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lanzamiento</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Cada vez que un servicio que se implementa usando helm recibe una versi칩n incremental de la versi칩n. Helm recuerda cu치l era la configuraci칩n del servicio en el a침o anterior, el a침o anterior al 칰ltimo lanzamiento, y as칤 sucesivamente. Por lo tanto, si necesita retroceder, simplemente ejecute el comando de devoluci칩n de llamada helm, que le indica la versi칩n anterior de la versi칩n. Incluso si en el momento de la reversi칩n, la configuraci칩n correspondiente en su repositorio no est치 disponible, Helm a칰n recuerda lo que era y revierte su sistema al estado que ten칤a en la versi칩n anterior. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En el caso cuando usamos helm, las configuraciones usuales para Kubernetes tambi칠n se convierten en plantillas, en las cuales es posible usar variables, funciones, aplicar operadores condicionales. Por lo tanto, puede recopilar la configuraci칩n de su servicio seg칰n el entorno.</font></font><br><br><img src="https://habrastorage.org/webt/dc/lr/fh/dclrfhbdr29ms0gouz_pvd8xz44.jpeg" alt="imagen"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En la pr치ctica, decidimos hacer un poco diferente de lo que hicimos en el caso de Nomad. Si en Nomad en el mismo repositorio se almacenaban tanto las configuraciones para la implementaci칩n como las n variables que se necesitaban para implementar nuestro servicio, aqu칤 decidimos dividirlas en dos repositorios separados. Solo las n variables necesarias para el despliegue se almacenan en el repositorio de despliegue, y las configuraciones o gr치ficos se almacenan en el repositorio de tim칩n. </font></font><br><br><img src="https://habrastorage.org/webt/2r/lo/yt/2rloytnvlrj6nri8vj7e9-hccg8.jpeg" alt="imagen"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">쯈u칠 nos dio?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A pesar de que no almacenamos datos realmente confidenciales en los archivos de configuraci칩n. Por ejemplo, contrase침as de bases de datos. Se almacenan como secretos en Kubernetes, pero, sin embargo, todav칤a hay algunas cosas all칤 que no queremos dar acceso a todos en una fila. Por lo tanto, el acceso al repositorio de implementaci칩n es m치s limitado, y el repositorio de helm simplemente contiene una descripci칩n del servicio. Por esta raz칩n, es posible dar acceso a un c칤rculo m치s grande de personas de manera segura. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dado que no solo tenemos producci칩n, sino tambi칠n otros entornos, gracias a esta separaci칩n, podemos reutilizar nuestros gr치ficos de tim칩n para implementar servicios no solo en producci칩n, sino tambi칠n, por ejemplo, en el entorno de control de calidad. Incluso desplegarlos localmente usando </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minikube</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> es algo as칤 como ejecutar Kubernetes localmente.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dentro de cada repositorio, dejamos una separaci칩n en directorios separados para cada servicio. Es decir, dentro de cada directorio hay plantillas relacionadas con el gr치fico correspondiente y que describen los recursos que deben implementarse para iniciar nuestro sistema. En el repositorio de despliegue, solo dejamos enves. En este caso, no utilizamos plantillas con jinja, porque el tim칩n mismo proporciona plantillas fuera de la caja, esta es una de sus funciones principales.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dejamos el script de implementaci칩n, deploy.sh, que simplifica y estandariza el lanzamiento para la implementaci칩n usando helm. </font><font style="vertical-align: inherit;">Por lo tanto, para cualquier persona que quiera implementar, la interfaz de implementaci칩n se ve exactamente igual que en el caso de la implementaci칩n a trav칠s de Nomad. </font><font style="vertical-align: inherit;">El mismo deploy.sh, el nombre de su servicio y d칩nde desea implementarlo. </font><font style="vertical-align: inherit;">Esto hace que el tim칩n comience dentro. </font><font style="vertical-align: inherit;">칄l, a su vez, recopila configuraciones de plantillas, sustituye los archivos de valores necesarios en ellas, luego las implementa y las coloca en Kubernetes.</font></font><br><br><h1>  Conclusiones </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> El servicio de Kubernetes parece m치s complejo que Nomad. </font></font><br><br><img src="https://habrastorage.org/webt/fe/p6/qi/fep6qibp6hhnbsmqifk2jnmg20a.jpeg" alt="imagen"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aqu칤 es donde el tr치fico saliente llega a Ingress. Este es solo el controlador frontal, que recibe todas las solicitudes y posteriormente las env칤a a los servicios correspondientes a los datos de la solicitud. Los define sobre la base de configuraciones, que son parte de la descripci칩n de su aplicaci칩n en tim칩n y que los desarrolladores configuran de forma independiente. El servicio env칤a solicitudes a sus pods, es decir, contenedores espec칤ficos, equilibrando el tr치fico entrante entre todos los contenedores que pertenecen a este servicio. Bueno, por supuesto, no olvides que no debemos ir desde la seguridad a nivel de red. Por lo tanto, el cl칰ster de Kubernetes opera la segmentaci칩n, que se basa en el etiquetado. Todos los servicios tienen ciertas etiquetas, a las cuales los derechos de acceso de los servicios a ciertos recursos externos / internos est치n unidos dentro o fuera del cl칰ster.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al completar la transici칩n, vimos que Kubernetes tiene todas las caracter칤sticas de Nomad, que usamos antes, y tambi칠n agrega muchas cosas nuevas. Se puede ampliar a trav칠s de complementos y, de hecho, a trav칠s de tipos de recursos personalizados. Es decir, tiene la oportunidad no solo de usar algo que entra en Kubernetes de forma inmediata, sino de crear su propio recurso y servicio que leer치 su recurso. Esto proporciona opciones adicionales para expandir su sistema sin la necesidad de reinstalar Kubernetes y sin la necesidad de cambios.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un ejemplo de esto es Prometheus, que se ejecuta dentro de nuestro cl칰ster de Kubernetes. Para que pueda comenzar a recopilar m칠tricas de un servicio en particular, necesitamos agregar un tipo de recurso adicional, el denominado monitor de servicio, a la descripci칩n del servicio. Prometheus, debido al hecho de que puede leer, al lanzarse en Kubernetes, un tipo personalizado de recursos, autom치ticamente comienza a recopilar m칠tricas del nuevo sistema. Es bastante conveniente.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El primer despliegue que hicimos en Kubernetes fue en marzo de 2018. </font><font style="vertical-align: inherit;">Y durante este tiempo nunca tuvimos problemas con 칠l. </font><font style="vertical-align: inherit;">Funciona de manera estable sin errores importantes. </font><font style="vertical-align: inherit;">Adem치s, podemos ampliarlo a칰n m치s. </font><font style="vertical-align: inherit;">Hoy, tenemos suficientes oportunidades, y realmente nos gusta el ritmo de desarrollo de Kubernetes. </font><font style="vertical-align: inherit;">Actualmente, m치s de 3.000 contenedores se encuentran en Kubernetes. </font><font style="vertical-align: inherit;">El cl칰ster toma varios nodos. </font><font style="vertical-align: inherit;">Al mismo tiempo, tiene servicio, es estable y est치 muy controlado.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/451644/">https://habr.com/ru/post/451644/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../451634/index.html">C칩mo somos analizados en tiendas y restaurantes.</a></li>
<li><a href="../451636/index.html">Cinco a침os de esclavitud</a></li>
<li><a href="../451638/index.html">Animaci칩n en aplicaciones m칩viles: prueba de Lottie</a></li>
<li><a href="../451640/index.html">Juego de tronos: creaci칩n de infograf칤as sobre asesinatos, sexo, viajes de Poniente y m치s</a></li>
<li><a href="../451642/index.html">Encontrar un camino entre obst치culos redondos</a></li>
<li><a href="../451646/index.html">La producci칩n del casco de la nave espacial de la Federaci칩n ha comenzado</a></li>
<li><a href="../451648/index.html">쮺칩mo buscamos un turismo inusual en Rusia y qu칠 tipo de aventuras ocurren generalmente?</a></li>
<li><a href="../451650/index.html">Parte I. Preg칰ntele a su madre: 쮺칩mo comunicarse con los clientes y confirmar la exactitud de su idea de negocio, si todos mienten?</a></li>
<li><a href="../451652/index.html">Parte II Preg칰ntele a su madre: 쮺칩mo comunicarse con los clientes y confirmar la exactitud de su idea de negocio, si todos mienten?</a></li>
<li><a href="../451654/index.html">Nuevo empleado: vivo o muerto</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
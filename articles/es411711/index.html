<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>„äóÔ∏è ‚ôíÔ∏è ‚õèÔ∏è C√≥mo Boston Dynamics hizo independiente a BigDog üßíüèº üìØ üë©üèΩ‚Äçü§ù‚Äçüë®üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La semana pasada, descubrimos c√≥mo funciona el legendario algoritmo de coordinaci√≥n de la marcha BigDog. El robot a√∫n no era aut√≥nomo y solo pod√≠a cru...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo Boston Dynamics hizo independiente a BigDog</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/smileexpo/blog/411711/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/dp/1q/lt/dp1qltdljsroi6gvosqy6ptauoe.jpeg"></div><br>  <i>La semana pasada, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">descubrimos</a> c√≥mo funciona el legendario algoritmo de coordinaci√≥n de la marcha BigDog.</i>  <i>El robot a√∫n no era aut√≥nomo y solo pod√≠a cruzar el terreno bajo el control del operador.</i> <i><br><br></i>  <i>La mayor√≠a de los lectores respaldaron por √∫ltima vez la idea de una nueva traducci√≥n, sobre c√≥mo BigDog aprendi√≥ a ir por el camino correcto al punto correcto y navegar en el espacio.</i>  <i>Bueno, en realidad, aqu√≠ est√°.</i> <a name="habracut"></a><br><br>  El sistema de navegaci√≥n BigDog utiliza una combinaci√≥n de escaneo l√°ser plano, visi√≥n est√©reo y percepci√≥n propioceptiva.  Con su ayuda, se determina la ubicaci√≥n del robot en el mundo circundante.  Ella descubre obst√°culos y los coloca en un modelo bidimensional del mundo.  Luego, planifica el camino y controla que el robot siga el camino elegido.  El planificador de ruta es una variaci√≥n del cl√°sico algoritmo de b√∫squeda A *.  El algoritmo de suavizado procesa los resultados y los pasa al algoritmo de seguimiento de ruta.  Calcula los comandos de direcci√≥n para BigDog. <br><br>  El sistema descrito se prob√≥ en una zona forestal con muchos √°rboles, rocas y maleza.  Adem√°s de los territorios planos, tambi√©n ten√≠a pendientes (√°ngulos de hasta 11 grados).  Se realizaron un total de 26 pruebas, de las cuales el 88% tuvieron √©xito.  El robot "vio" el terreno dentro de un radio de 130 metros cuando se mov√≠a a una velocidad dada y super√≥ m√°s de 1.1 km. <br><br><h2>  Equipo </h2><br>  <b>1) sensores propioceptivos</b> <br><br>  Se usa para controlar la marcha BigDog y la navegaci√≥n aut√≥noma.  Cada uno de los 16 grados de libertad activos y 4 pasivos del robot est√° equipado con un sensor.  Proporcionan datos sobre la posici√≥n actual y la carga.  Esta informaci√≥n se combina con los datos de la IMU para evaluar el estado de contacto con el suelo, la altura del cuerpo y la velocidad del cuerpo.  Adem√°s, varios sensores indican el estado de los sistemas BigDog de propulsi√≥n, computaci√≥n, hidr√°ulicos, t√©rmicos y otros. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ul/d1/zt/uld1zt6ymgip1yrgosrwmepxl20.jpeg"></div><br>  <i>Sensores BigDog: a) antena GPS;</i>  <i>b) lidar;</i>  <i>c) c√°mara est√©reo de abejorro;</i>  <i>d) Honeywell IMU;</i>  <i>e) sensores conjuntos.</i> <br><br>  <b>2) sensores exteroceptivos</b> <br><br>  El robot est√° equipado con cuatro sensores externos: el lidar SICK LMS 291, la c√°mara est√©reo Bumblebee PointGrey, el receptor GPS NovAtel y la IMU Honeywell.  Los datos de ellos ingresan al sistema que se muestra en el diagrama a continuaci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/k5/ic/-w/k5ic-wirg74tc4ynnp8_5dmossi.png"></div><br>  <b>3) computadoras</b> <br><br>  Para implementar el sistema con el diagrama anterior, se utilizan dos computadoras.  La computadora principal BigDog es una PC104 con un procesador Intel Pentium M de un solo n√∫cleo (1.8 GHz).  Interact√∫a con sensores propioceptivos, controla el equilibrio y el movimiento del robot, calcula el modelo actual del entorno y la ruta a trav√©s de √©l, y tambi√©n controla la marcha. <br><br>  La visi√≥n es proporcionada por una computadora separada con un procesador Intel CoreDuo (1.7 GHz).  Se comunica con un par de c√°maras, detecta inconsistencias, eval√∫a la odometr√≠a visual y admite un mapa de terreno en 3D.  Esta computadora transmite el mapa y los datos de odometr√≠a visual a la computadora host a una frecuencia de 15 Hz a trav√©s de la red de √°rea local a bordo. <br><br>  La ventaja de dicho sistema es la capacidad de simplificar la tarea de planificaci√≥n dividi√©ndola en dos partes.  Los datos del LIDAR y los sensores son tridimensionales, pero podemos confiar en la autoestabilizaci√≥n del sistema de control de la marcha para abandonar la percepci√≥n y planificaci√≥n 3D m√°s complejas. <br><br><h2>  Enfoque t√©cnico </h2><br>  En nuestro enfoque t√©cnico general, utilizamos datos de dos sensores ambientales para detectar obst√°culos, calcular la ruta a trav√©s o alrededor de los obst√°culos y ordenar al sistema de control de marcha del robot que siga una ruta determinada. <br><br>  Todo el proceso se puede dividir en tres etapas.  Primero, las im√°genes del lidar y la c√°mara se procesan para obtener una lista de puntos que indican obst√°culos en el entorno.  Luego, estos puntos se dividen en objetos disjuntos y se siguen durante alg√∫n tiempo.  Adem√°s, estos objetos se combinan en la memoria temporal para el mapeo.  Este cuadro se usa para planificar la direcci√≥n de viaje a un destino intermedio.  El programador est√° dise√±ado para controlar que las trayectorias de BigDog est√©n a la distancia adecuada de los obst√°culos y que las trayectorias sean estables en el espacio durante las iteraciones del programador.  El algoritmo de movimiento a lo largo de una trayectoria dada obliga al robot a seguir la ruta prevista, enviando comandos de velocidad al sistema de control de la marcha.  Ella alternativamente mueve las extremidades del robot. <br><br><h3>  A. Recolecci√≥n de informaci√≥n </h3><br>  <b>1) Evaluaci√≥n de la situaci√≥n.</b> <br><br>  Hay dos fuentes de informaci√≥n odom√©trica: sensores cinem√°ticos en las piernas y un sistema de visi√≥n artificial.  Los datos obtenidos de ellos se combinan para evaluar la ubicaci√≥n del robot. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9e/qp/xk/9eqpxkkl0tmlthiev_xbvilijbe.png"></div><br><br>  El sistema odom√©trico utiliza informaci√≥n cinem√°tica de las piernas para calcular los movimientos del robot.  Y el sistema de odometr√≠a visual monitorea las caracter√≠sticas visuales para calcular el movimiento.  Ambas herramientas utilizan un m√≥dulo de medici√≥n de inercia (IMU) como fuente de informaci√≥n para la orientaci√≥n espacial.  Un medidor general combina la salida de estos dos od√≥metros, centr√°ndose en la odometr√≠a visual a bajas velocidades y la cinem√°tica a velocidades m√°s altas.  La combinaci√≥n de estos dos indicadores elimina las deficiencias de cada uno de los contadores: la posible falla de los sistemas est√©reo, la deriva de las lecturas del od√≥metro ubicadas en las extremidades mientras se ejecuta en su lugar, as√≠ como los errores de este sensor a lo largo del eje vertical. <br><br>  El lidar utilizado en el robot BigDog produce una nueva imagen cada 13 milisegundos.  Cada imagen se transforma en un sistema de coordenadas externo con el centro en la ubicaci√≥n del robot.  En este caso, se utiliza informaci√≥n sincronizada en el tiempo del contador de ubicaci√≥n.  La nube de puntos 3D resultante se transmite para su procesamiento mediante el algoritmo de segmentaci√≥n descrito a continuaci√≥n.  Del mismo modo, el sistema de visi√≥n estereosc√≥pica recopila mapas de no conformidad durante alg√∫n tiempo para crear un mapa de terreno en 3D en un cuadrado de 4 x 4 metros centrado en el robot.  El filtro espacial determina las √°reas de cambios significativos de altitud (es decir, obst√°culos potenciales) y transmite una lista de puntos que pertenecen a estas √°reas al algoritmo de segmentaci√≥n de nubes de puntos. <br><br>  <b>2) Segmentaci√≥n de nubes de puntos y seguimiento de objetos</b> <br><br>  Debido a las irregularidades de la tierra y los movimientos del robot, parte de los datos del esc√°ner lidar incluir√°n im√°genes de la tierra.  Los reflejos de los obst√°culos largos (como las paredes) son similares en apariencia a los reflejos de la superficie de la tierra.  Para una operaci√≥n exitosa, el sistema debe interpretar estos reflejos de tal manera que pueda controlar el robot cerca de las paredes y no tener "miedo" de la tierra.  El primer paso en este proceso es la segmentaci√≥n de los puntos de obst√°culos proporcionados por el LIDAR y el mapa del terreno en objetos separados.  Las nubes de puntos 3D raras se segmentan en objetos fusionando puntos individuales separados por una distancia de menos de 0,5 metros. <br><br>  Los objetos obtenidos gracias al algoritmo de segmentaci√≥n se rastrean durante alg√∫n tiempo.  Para realizar esta tarea, utilizamos un algoritmo iterativo codicioso con restricciones heur√≠sticas.  El objeto en la imagen actual coincide con el objeto m√°s cercano de la √∫ltima imagen, siempre que los objetos est√©n separados por una distancia de no m√°s de 0.7 metros. <br><br>  Debido al hecho de que las nubes de puntos se segmentan en objetos y se rastrean durante alg√∫n tiempo, el robot puede moverse adecuadamente en el entorno con desniveles moderados de la tierra y obst√°culos de varios tipos: √°rboles, adoquines, troncos ca√≠dos, paredes.  Los √°rboles y las paredes est√°n determinados principalmente por un esc√°ner lidar, y los adoquines y los registros est√°n determinados por un sistema de visi√≥n estereosc√≥pica. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tw/al/fy/twalfy7ylnbcl9a6gq1elkp79a8.jpeg"></div><br>  <i>Una secuencia de ilustraciones que muestran un robot (rect√°ngulo amarillo) con: a) datos de un lidar (puntos azules) registrados en unos segundos;</i>  <i>b) sus respectivas instalaciones.</i>  <i>Los objetos marrones altos son √°rboles.</i>  <i>Los reflejos del suelo se muestran transparentes y planos.</i>  <i>El cilindro verde es el objetivo;</i>  <i>la l√≠nea azul de la ruta calculada conduce a ella.</i>  <i>c) Vista superior del cartograma: las √°reas con el valor letal m√°s bajo se indican en verde, y las √°reas con el valor m√°s alto se indican en p√∫rpura.</i>  <i>Cada unidad de cuadr√≠cula corresponde a 5 metros.</i> <br><br><h3>  B. Planificaci√≥n de la navegaci√≥n. </h3><br>  Nuestro enfoque para resolver el problema de navegaci√≥n es generalmente aceptado en la comunidad rob√≥tica.  Los puntos de obst√°culos (obtenidos debido a los procesos de percepci√≥n) se trazan en un cartograma con el centro en la ubicaci√≥n del robot.  El objetivo final del robot se proyecta en el l√≠mite del cartograma y se le aplica una variante del algoritmo A ‚àó.  Este proceso se repite aproximadamente una vez por segundo. <br><br>  <b>1) Memoria de obst√°culos rastreados</b> <br><br>  Debido al campo de visi√≥n limitado de los dos sensores del robot, es imperativo que el robot conserve una memoria precisa de los obst√°culos que ya no puede ver.  Dado que el sistema de seguimiento de objetos proporciona la lista de objetos, los objetos individuales se agregan, actualizan o eliminan en la memoria de objetos del sistema de planificaci√≥n.  El tama√±o de la lista de objetos es limitado, por lo que cuando se le agregan nuevos objetos, se deben eliminar otros. <br><br>  Denotando la lista actual de objetos de la variable O, podemos calcular dos subclases parametrizadas de O: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e3/k3/lu/e3k3lua8asqfffo9e8cda22bqb4.jpeg"></div><br><br>  Aqu√≠ la edad (q) es la diferencia entre el tiempo actual y el tiempo de la √∫ltima medici√≥n del objeto q, <br>  norma (q, r) inf: la distancia m√≠nima entre la ubicaci√≥n actual del robot y el l√≠mite del objeto q. <br><br>  <b>Los objetos se eliminan de O mediante los siguientes criterios:</b> <br><br><ul><li>  El conjunto {P (30) ‚à© Q (15)} se resta de O. Se trata de objetos con una antig√ºedad superior a 30 segundos y ubicados a una distancia no inferior a 15 metros del robot. </li><li>  El conjunto {P (1800) ‚à© Q (10)} se resta de O. Se trata de objetos con una antig√ºedad superior a media hora y ubicados a no menos de 10 metros del robot. </li><li>  Los objetos se eliminan de O cuando se alcanza el l√≠mite de la lista.  La prioridad del objeto est√° determinada por el tiempo durante el cual el rastreador lo sigui√≥ con √©xito.  En otras palabras, los objetos que el robot "mir√≥" m√°s tiempo se almacenan m√°s tiempo en la memoria. </li><li>  Sin embargo, no se descartan los objetos rastreados en los 10 segundos anteriores. </li></ul><br>  Esta asignaci√≥n de recursos de memoria conduce al siguiente comportamiento: cuando los objetos abandonan el campo de visi√≥n de los sensores del robot, olvida los objetos eliminados y los objetos que no ha visto varias veces.  No se olvidan los objetos a la vista o inaccesibles, pero ubicados cerca del robot. <br><br>  <b>2) Crear un cartograma</b> <br><br>  Utilizamos un cartograma creado sobre la base de una cuadr√≠cula 2D para representar el entorno que rodea al robot.  En lugar de crear din√°micamente un cartograma (a medida que el robot recibe nueva informaci√≥n ambiental), se compila un nuevo cartograma con cada iteraci√≥n de planificaci√≥n y se llena con objetos de la memoria del planificador.  De ello se deduce que el planificador de ruta din√°mico no se puede utilizar en lugar del algoritmo A *.  Dado que suponemos que el tama√±o de los objetos es limitado (que la ausencia de un callej√≥n sin salida en el entorno es m√°s de la mitad del mapa), el alcance de la tarea de planificaci√≥n y el tiempo para calcular la ruta son peque√±os. <br><br>  El cartograma se llena con valores de la lista de objetos de acuerdo con el siguiente algoritmo: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vb/ld/cn/vbldcnab7njryzt9azsl-xt0soq.jpeg"></div><br><br>  A las celdas donde se ubican los objetos se les asigna un valor letal muy alto.  El indicador de las celdas cercanas al objeto se establece de acuerdo con la funci√≥n f, que tiene en cuenta la distancia actual a este punto.  Para los resultados de la prueba presentados aqu√≠, f era simplemente el cubo inverso de la distancia. <br><br>  El efecto de este enfoque es que disminuye gradualmente desde las celdas con un valor muy alto a medida que se aleja de ellas (y de los objetos que designan). <br><br>  <b>3) Estabilidad del camino</b> <br><br>  Para asegurarnos de que no "controlamos" BigDog de manera aleatoria y no sistem√°tica, se presta especial atenci√≥n a la estabilidad de la ruta planificada.  Debe ser lo m√°s estable posible a trav√©s de iteraciones del planificador de ruta.  Esto se proporciona de tres maneras. <br><br>  En primer lugar, el punto de partida pasado al algoritmo A * no es la posici√≥n actual del robot, sino la proyecci√≥n de su posici√≥n en el punto final de la ruta dada anteriormente por el algoritmo A * (llamemos a este punto p).  Mientras BigDog siga el camino planificado, puede desviarse ligeramente de √©l de lado.  Al proyectar el punto de partida sobre el punto del c√°lculo anterior del algoritmo A *, filtramos la fluctuaci√≥n de la posici√≥n del robot y las rutas que muestra el planificador se vuelven m√°s estables.  Si el robot se desv√≠a de la ruta m√°s all√° del valor establecido (por defecto es de 3 metros), el punto p simplemente se transfiere a la posici√≥n actual del robot. <br><br>  En segundo lugar, para verificar la continuidad del planificador de ruta, calculamos q: la proyecci√≥n de la posici√≥n del robot desde 2.5 segundos en el pasado hasta el √∫ltimo punto calculado por el algoritmo A *.  Luego, el segmento de la √∫ltima ruta planificada de qp se agrega al c√°lculo de la nueva ruta.  Como resultado, el robot rastrea una peque√±a distancia ya recorrida.  Gracias a esto, el algoritmo para seguir el camino se muestra mejor con violaciones significativas de la posici√≥n, que a menudo encuentran los robots de pie. <br><br>  En tercer lugar, parte del historial de las rutas planificadas se almacena en la memoria del robot.  Estas rutas se utilizan para reducir los valores de las celdas del cartograma donde el robot ya se ha ido, al tiempo que aumenta el valor de las celdas en el √°rea circundante.  Por lo tanto, como regla, una nueva ruta planificada en la misma direcci√≥n repetir√° la ruta ya recorrida por el robot (pero sin una garant√≠a estricta de esto). <br><br>  <b>4) suavizado de ruta</b> <br><br>  La ruta calculada, ya que se basa en una cuadr√≠cula regular, es un poco irregular.  Los cambios significativos en la direcci√≥n pueden causar comandos de control no deseados.  Para evitar esto, se aplica el algoritmo de suavizado de De Boer. <br><br>  Adem√°s, la planificaci√≥n de rutas basada en la red a menudo conduce a rutas t√©cnicamente √≥ptimas pero menos deseables hacia el objetivo.  Resolvemos este problema calculando una ruta suavizada para cada iteraci√≥n del planificador.  Para las iteraciones posteriores, a las celdas del cartograma donde se ejecuta la ruta suavizada se les asigna un valor m√°s bajo.  Esto proporciona un camino m√°s directo y suave hacia la meta. <br><br><h3>  C. Control de la marcha: movilidad y equilibrio. </h3><br>  El sistema de planificaci√≥n de navegaci√≥n determina una nueva ruta aproximadamente una vez por segundo.  Un algoritmo para seguir una ruta que opera a una frecuencia de 200 Hz gu√≠a al robot de acuerdo con la √∫ltima ruta planificada.  Este algoritmo crea un conjunto de comandos en forma de velocidades corporales deseadas, que incluyen la velocidad de avance, la velocidad lateral y la velocidad de gui√±ada del cuerpo.  Estas velocidades se transmiten al controlador de marcha, que controla el movimiento de las piernas. <br><br>  En funci√≥n de la distancia entre el robot y la ruta, se utiliza una de las tres estrategias.  Si el robot se encuentra cerca de una secci√≥n del camino, comienza a moverse en diagonal hasta que entra por el costado, movi√©ndose a toda velocidad.  Si el robot est√° lejos del camino, se dirige exactamente hacia el punto deseado.  En una posici√≥n intermedia, se usa una combinaci√≥n de estas estrategias. <br><br>  Una descripci√≥n detallada de los algoritmos de control de la marcha est√° m√°s all√° del alcance de este art√≠culo.  Sin embargo, como regla general, las velocidades corporales act√∫an como entradas de control para los controladores de marcha BigDog de bajo nivel.  El controlador de marcha produce comandos de fuerza y ‚Äã‚Äãposici√≥n para cada articulaci√≥n para garantizar la estabilidad, responde a anomal√≠as y proporciona las velocidades corporales necesarias.  Aunque los c√°lculos del algoritmo de investigador de ruta se pueden usar para cualquier marcha BigDog, el trote es √≥ptimo debido a la velocidad y la capacidad de cruzar terrenos irregulares. <br><br><h2>  Resultados de la prueba de campo </h2><br>  El sensor y el sistema de navegaci√≥n descritos anteriormente se instalaron en BigDog y se probaron fuera del laboratorio.  Las pruebas se realizaron en un √°rea donde hab√≠a muchos √°rboles, rocas, maleza, colinas con pendientes de hasta 11 grados.  La Figura 1 muestra ejemplos de paisajes.  La figura 2 muestra los datos del LIDAR procesados ‚Äã‚Äãpor el robot. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o4/1y/ug/o41yug1warmbysmgjykntwplanc.jpeg"></div><br>  <i>Fig.</i>  <i>1. El terreno donde se realizaron las pruebas.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w6/_d/mq/w6_dmqlx8c_czcoay_rnoiy_4o4.jpeg"></div><br>  <i>Fig.</i>  <i>2. Pruebas, vista superior.</i>  <i>Imagen recibida de c√°maras LIDAR y est√©reo.</i>  <i>Las √°reas oscuras son √°rboles y otros obst√°culos.</i>  <i>El tama√±o de la malla es de 5 metros.</i> <br><br>  El sistema de navegaci√≥n y el planificador se desarrollaron durante un per√≠odo de 7 meses, con pruebas regulares aproximadamente una vez cada cinco semanas.  Los resultados de las √∫ltimas pruebas se describen aqu√≠. <br><br>  De las 26 pruebas realizadas, 23 terminaron con √©xito: el robot alcanz√≥ la meta, no encontr√≥ ninguno de los obst√°culos y no estuvo cerca de esto.  Los resultados de estas pruebas est√°n marcados en la tabla din√°mica como objetivo.  El robot cay√≥ al final de una sola prueba despu√©s de pisar una piedra peque√±a.  Por lo general, el sistema de control de la marcha hace frente a tales situaciones, pero no esta vez (el resultado est√° marcado en la tabla como Fall - "Fall").  En tres pruebas, el robot encontr√≥ grandes obst√°culos (m√°s de 20 metros de ancho).  El robot calcul√≥ qu√© lado es mejor para sortear el obst√°culo y no avanz√≥ en un per√≠odo de tiempo determinado (20 segundos).  Los obst√°culos de este tama√±o van m√°s all√° del alcance para el cual se desarroll√≥ un sistema aut√≥nomo.  Los resultados de estas pruebas se indican en la tabla como Live-lock. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/an/hu/mi/anhumiw32wo1mu8oc7dtcbgsirs.jpeg"></div><br><br>  En estas 26 pruebas, el robot se coloc√≥ en escenarios bastante similares y en el medio del bosque.  A medida que el entorno se vuelve m√°s complejo, aumenta el n√∫mero de resultados de Live-lock y el robot selecciona rutas menos eficientes. <br><br>  <b>M√°s interesante: en robo-hunter.com</b> : <br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">noticias frescas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ;</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">curr√≠culum de robots</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ;</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">infograf√≠a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></li></ul><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nuestro canal de YouTube</font></font></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es411711/">https://habr.com/ru/post/es411711/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es411701/index.html">La NASA vuelve a emitir un recorrido lunar en 4K</a></li>
<li><a href="../es411703/index.html">Xiaomi, mu√©vete, Alfawise ha llegado</a></li>
<li><a href="../es411705/index.html">Servicio en l√≠nea que compara los cambios en la respuesta de frecuencia y la presi√≥n del sonido seg√∫n el voltaje aplicado y la impedancia de la fuente</a></li>
<li><a href="../es411707/index.html">Nakraudfandili: los mejores proyectos para marzo de 2018</a></li>
<li><a href="../es411709/index.html">Precios de productos espaciales nacionales</a></li>
<li><a href="../es411713/index.html">Cuartel general de criptanarquistas y cachimba para bitcoins: gu√≠a de criptomonedas a Praga</a></li>
<li><a href="../es411715/index.html">Brain, Drugs, and rock`n`roll: personalidad e investigaci√≥n del m√°s musical de los neurocient√≠ficos</a></li>
<li><a href="../es411717/index.html">Barril en un barril. Ensayo 12. Mundo de ideas</a></li>
<li><a href="../es411719/index.html">Google desarrolla microscopio AR para la detecci√≥n r√°pida del c√°ncer</a></li>
<li><a href="../es411721/index.html">LED parpadeante desde el m√≥dulo del kernel de Linux</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
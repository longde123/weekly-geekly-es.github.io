<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üß† ‚ùî üå≤ C√≥mo entender Tensorflow y no morir, e incluso ense√±ar algo sobre un autom√≥vil üçæ üíáüèæ ü§üüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola guardias. La publicaci√≥n de hoy tratar√° sobre c√≥mo no perderse en la naturaleza de la variedad de opciones para usar TensorFlow para el aprendiza...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo entender Tensorflow y no morir, e incluso ense√±ar algo sobre un autom√≥vil</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427449/"><p>  Hola guardias.  La publicaci√≥n de hoy tratar√° sobre c√≥mo no perderse en la naturaleza de la variedad de opciones para usar TensorFlow para el aprendizaje autom√°tico y lograr su objetivo.  El art√≠culo est√° dise√±ado para que el lector conozca los principios b√°sicos de los principios del aprendizaje autom√°tico, pero a√∫n no ha intentado hacerlo con sus propias manos.  Como resultado, obtenemos una demostraci√≥n funcional en Android, que reconoce algo con una precisi√≥n bastante alta.  Pero lo primero es lo primero. </p><br><p><img src="https://habrastorage.org/webt/rs/7r/_f/rs7r_f7v6dywnklpaok4htwntsq.jpeg"></p><a name="habracut"></a><br><p>  Despu√©s de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mirar los</a> √∫ltimos materiales, se decidi√≥ involucrar a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tensorflow</a> , que ahora est√° ganando un gran impulso, y los art√≠culos en ingl√©s y ruso parecen ser suficientes para no profundizar en todo y poder descubrir qu√© es qu√©. </p><br><p>  Pasando dos semanas, estudiando art√≠culos y numerosas ex muestras en la oficina.  sitio, me di cuenta de que no entend√≠a nada.  Demasiada informaci√≥n y opciones sobre c√≥mo se puede usar Tensorflow.  Mi cabeza ya est√° hinchada por cu√°nto ofrecen diferentes soluciones y qu√© hacer con ellas, seg√∫n se aplica a mi tarea. </p><br><p><img src="https://habrastorage.org/webt/bd/2z/jy/bd2zjyct-gx0xbz9nfbwwya5aw8.png"></p><br><p>  Luego, decid√≠ probar todo, desde las opciones m√°s simples y listas para usar (en las que deb√≠a registrar una dependencia en gradle y agregar un par de l√≠neas de c√≥digo) a otras m√°s complejas (en las que tendr√≠a que crear y entrenar modelos de gr√°ficos nosotros mismos y aprender a usarlos en un m√≥vil aplicaci√≥n). </p><br><p>  Al final, tuve que usar una versi√≥n complicada, que se discutir√° con m√°s detalle a continuaci√≥n.  Mientras tanto, he compilado para usted una lista de opciones m√°s simples que son igualmente efectivas, cada una se adapta a su prop√≥sito. </p><br><h3 id="1--ml-kithttpsfirebasegooglecomdocsml-kit">  1. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">KIT ML</a> </h3><br><p><img src="https://habrastorage.org/webt/al/of/8w/alof8wunrnv66f66xwv2rrlbrn0.png"></p><br><p>  La soluci√≥n m√°s f√°cil de usar: un par de l√≠neas de c√≥digo que puede usar: </p><br><ul><li>  Reconocimiento de texto (texto, caracteres latinos) </li><li>  Detecci√≥n de rostros (rostros, emociones) </li><li>  Escaneo de c√≥digo de barras (c√≥digo de barras, c√≥digo qr) </li><li>  Etiquetado de im√°genes (un n√∫mero limitado de tipos de objetos en la imagen) </li><li>  Reconocimiento de hitos (atracciones) </li></ul><br><p>  Es un poco m√°s complicado. Con esta soluci√≥n, tambi√©n puede usar su propio modelo TensorFlow Lite, pero la conversi√≥n a este formato caus√≥ dificultades, por lo que este elemento no se ha probado. </p><br><p>  Como escriben los creadores de esta descendencia, la mayor√≠a de las tareas se pueden resolver utilizando estos desarrollos.  Pero si esto no se aplica a su tarea, tendr√° que usar modelos personalizados. </p><br><h3 id="2--custom-visionhttpswwwcustomvisionai">  2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Visi√≥n personalizada</a> </h3><br><p><img src="https://habrastorage.org/webt/p9/c_/2u/p9c_2ujglvyu8mbffhrmoqpzav0.png"></p><br><p>  Una herramienta muy conveniente para crear y entrenar sus modelos personalizados usando im√°genes. <br>  De los profesionales: hay una versi√≥n gratuita que le permite mantener un proyecto. <br>  De las desventajas: la versi√≥n gratuita limita el n√∫mero de im√°genes "entrantes" a 3.000.  Intentar crear una red de precisi√≥n mediocre, es suficiente.  Para tareas m√°s precisas, necesita m√°s. <br>  Todo lo que se requiere del usuario es agregar im√°genes con una marca (por ejemplo, image1 es "mapache", image2 es "sol"), entrenar y exportar el gr√°fico para uso futuro. </p><br><p><img src="https://habrastorage.org/webt/co/lk/nw/colknw0ljunbtzcixxdrde6qwtm.png"></p><br><p>  Caring Microsoft incluso ofrece su propia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">muestra</a> , con la que puede probar su gr√°fico recibido. <br>  Para aquellos que ya est√°n "en el tema", el gr√°fico se genera ya en el estado Congelado, es decir  no necesitas hacer / convertir nada con √©l. <br>  Esta soluci√≥n es buena cuando tienes una muestra grande y (atenci√≥n) MUCHAS clases diferentes en entrenamiento.  Porque  de lo contrario, habr√° muchas definiciones falsas en la pr√°ctica.  Por ejemplo, entrenaste en mapaches y soles, y si hay una persona en la entrada, entonces puede definirse con la misma probabilidad por un sistema como uno u otro.  Aunque, de hecho, ni lo uno ni lo otro. </p><br><h3 id="3--sozdanie-modeli-vruchnuyu">  3. Crear un modelo manualmente </h3><br><p><img src="https://habrastorage.org/webt/m_/ku/r_/m_kur_ks0vdyiqoiw7h5pvbwoey.jpeg"></p><br><p>  Cuando necesite ajustar el modelo usted mismo para el reconocimiento de im√°genes, entran en juego manipulaciones m√°s complejas con la selecci√≥n de im√°genes de entrada. <br>  Por ejemplo, no queremos tener restricciones en el volumen de la muestra de entrada (como en el p√°rrafo anterior), o queremos entrenar el modelo con mayor precisi√≥n estableciendo el n√∫mero de √©poca y otros par√°metros de entrenamiento nosotros mismos. <br>  En este enfoque, hay varios ejemplos de Tensorflow que describen el procedimiento y el resultado final. <br>  Aqu√≠ hay algunos ejemplos: </p><br><ul><li>  Cool codelab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tensorflow para poetas</a> . <br></li></ul><br><br><p>  Da un ejemplo de c√≥mo crear un clasificador de tipos de color basado en la base de datos abierta ImageNet de im√°genes: preparar im√°genes y luego entrenar el modelo.  Tambi√©n se hace una peque√±a menci√≥n de c√≥mo puede trabajar con una herramienta bastante interesante: TensorBoard.  De sus funciones m√°s simples, demuestra claramente la estructura de su modelo terminado, as√≠ como el proceso de aprendizaje de muchas maneras. </p><br><ul><li><p>  Tensorflow <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kodlab para poetas 2</a> : trabajo continuo con el clasificador de color.  Muestra c√≥mo si tiene los archivos de gr√°ficos y sus etiquetas (que se obtuvieron en el codelab anterior), puede ejecutar la aplicaci√≥n en Android.  Uno de los puntos del codelab es la conversi√≥n del formato gr√°fico ".pb" "habitual" al formato lite de Tensorflow (que implica algunas optimizaciones de archivo para reducir el tama√±o final del archivo gr√°fico, porque los dispositivos m√≥viles lo requieren). </p><br></li><li><p>  Reconocimiento de escritura a mano <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MNIST</a> . <br></p><br><img src="https://habrastorage.org/webt/bz/ah/mx/bzahmxc0xozicgssbkzfqbgi1qw.gif"></li></ul><br><br><p>  El nabo contiene el modelo original (que ya se ha preparado para esta tarea), instrucciones sobre c√≥mo entrenarlo, convertirlo y c√≥mo ejecutar un proyecto para Android al final para verificar c√≥mo funciona todo. </p><br><p>  Con base en estos ejemplos, puede descubrir c√≥mo trabajar con modelos personalizados en Tensorflow e intentar crear uno propio o tomar uno de los modelos previamente entrenados que se ensamblan en un github: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Modelos de Tensorflow</a> </p><br><p>  Hablando de modelos "pre-entrenados".  Matices interesantes cuando se usan esos: </p><br><ul><li>  Su estructura ya est√° preparada para una tarea espec√≠fica. </li><li>  Ya est√°n capacitados en muestras de gran tama√±o. <br>  Por lo tanto, si su muestra no se llena lo suficiente, puede tomar un modelo previamente capacitado que tenga un alcance cercano a su tarea.  Usando este modelo, agregando sus propias reglas de entrenamiento, obtendr√° un mejor resultado del que tratar√≠a de entrenar el modelo desde cero. </li></ul><br><h3 id="4--object-detection-api---cozdanie-modeli-vruchnuyu">  4. Detecci√≥n de objetos API + creaci√≥n manual del modelo </h3><br><p>  Sin embargo, todos los p√°rrafos anteriores no dieron el resultado deseado.  Desde el principio fue dif√≠cil entender lo que hay que hacer y con qu√© enfoque.  Luego se encontr√≥ un art√≠culo interesante sobre la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API de detecci√≥n de objetos</a> , que explica c√≥mo encontrar varias categor√≠as en una imagen, as√≠ como varias instancias de la misma categor√≠a.  En el proceso de trabajar en esta muestra, los art√≠culos de origen y los tutoriales en video sobre el reconocimiento de objetos personalizados resultaron ser m√°s convenientes (los enlaces estar√°n al final). </p><br><p>  Pero el trabajo no podr√≠a haberse completado sin un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo sobre el reconocimiento de Pikachu</a> , porque se se√±al√≥ un matiz muy importante, que por alguna raz√≥n no se menciona en ninguna parte de una gu√≠a o ejemplo.  Y sin eso, todo el trabajo realizado ser√≠a en vano. </p><br><p>  Entonces, ahora finalmente sobre lo que a√∫n ten√≠a que hacerse y lo que sucedi√≥ al salir. </p><br><ol><li>  Primero, la harina de la instalaci√≥n Tensorflow.  Qui√©n no puede instalarlo o usar los scripts est√°ndar para crear y entrenar un modelo, solo sea paciente y google.  Casi todos los problemas ya se han escrito en problemas en githib o en stackoverflow. <br></li></ol><br>  De acuerdo con las instrucciones para el reconocimiento de objetos, necesitamos preparar una muestra de entrada antes de entrenar el modelo.  Estos art√≠culos describen en detalle c√≥mo hacerlo utilizando una herramienta conveniente: labelImg.  La √∫nica dificultad aqu√≠ es hacer un trabajo muy largo y meticuloso para resaltar los l√≠mites de los objetos que necesitamos.  En este caso, sellos en im√°genes de documentos. <br><br><img src="https://habrastorage.org/webt/ge/hh/x_/gehhx_5fqfezu1sbh5tvoofss20.png"><br>  El siguiente paso, utilizando secuencias de comandos listas para usar, exportamos los datos del paso 2 primero a archivos csv, luego a TFRecords, el formato de datos de entrada de Tensorflow.  No deben surgir dificultades aqu√≠. <br>  La elecci√≥n de un modelo pre-entrenado, en base al cual pre-entrenaremos el gr√°fico, as√≠ como el entrenamiento en s√≠.  Aqu√≠ es donde puede ocurrir la mayor cantidad de errores desconocidos, cuya causa es la desinstalaci√≥n (o instalaci√≥n torcida) de paquetes necesarios para el trabajo.  Pero tendr√° √©xito, no se desespere, el resultado lo vale. <br><br><img src="https://habrastorage.org/webt/9y/qw/1b/9yqw1boyubfcrrf5jcaylkjjtyo.jpeg"><br>  Exporte el archivo recibido despu√©s del entrenamiento al formato 'pb'.  Simplemente seleccione el √∫ltimo archivo 'ckpt' y exp√≥rtelo. <br>  Ejecutando un ejemplo de trabajo en Android. <br>  Descargando la muestra oficial de reconocimiento de objetos del github de Tensorflow - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TF Detect</a> .  Inserte su modelo y archivo con etiquetas all√≠.  Pero  Nada funcionar√° <br><br><img src="https://habrastorage.org/webt/kj/3k/o4/kj3ko4d3ywoap8ff6oknuwova7c.gif"><br><br><p>  Aqu√≠ es donde ocurri√≥ la mayor mordaza en todo el trabajo, por extra√±o que parezca, bueno, las muestras de Tensorflow no quer√≠an funcionar de ninguna manera.  Todo ha ca√≠do.  Solo el poderoso Pikachu con su art√≠culo logr√≥ ayudar a que todo funcionara. <br>  La primera l√≠nea en el archivo labels.txt debe ser la inscripci√≥n "???", porque  de manera predeterminada en la API de detecci√≥n de objetos, los n√∫meros de identificaci√≥n de los objetos no comienzan con 0 como de costumbre, sino con 1. Debido al hecho de que la clase nula est√° reservada, se deben indicar preguntas m√°gicas.  Es decir  su archivo de etiqueta se ver√° as√≠: </p><br><pre><code class="hljs">??? stamp</code> </pre> <br><p>  Y luego, ejecute la muestra y vea el reconocimiento de los objetos y el nivel de confianza con el que se recibi√≥. </p><br><p><img src="https://habrastorage.org/webt/ly/kr/dm/lykrdma-x9h8epuqsuah3gkr3bk.png"><img src="https://habrastorage.org/webt/ne/lm/7v/nelm7v8rpjiuhzhevlptp0dc-fa.png"><img src="https://habrastorage.org/webt/9t/ci/4r/9tci4rxzhixufdjhb5ecpdof0ik.png"></p><br><p>  Por lo tanto, el resultado es una aplicaci√≥n simple que, al pasar el mouse sobre la c√°mara, reconoce los l√≠mites del sello en el documento y los indica junto con la precisi√≥n del reconocimiento. <br>  Y si excluimos el tiempo que se dedic√≥ a buscar el enfoque correcto e intentar lanzarlo, entonces, en general, el trabajo result√≥ ser bastante r√°pido y realmente no complicado.  Solo necesita conocer los matices antes de comenzar a trabajar. </p><br><p>  Ya como una secci√≥n adicional (aqu√≠ ya puede cerrar el art√≠culo si est√° cansado de la informaci√≥n), me gustar√≠a escribir un par de trucos para la vida que ayudaron a trabajar con todo esto. </p><br><ul><li><p>  muy a menudo los scripts de tensorflow no funcionaban porque se ejecutaban desde los directorios incorrectos.  Adem√°s, era diferente en diferentes PC: algunos necesitaban ejecutarse desde el <code>tensroflowmodels/models/research</code> para trabajar, y algunos necesitaban un nivel m√°s profundo desde el <code>tensroflowmodels/models/research/object-detection</code> </p><br></li><li><p>  recuerde que para cada terminal abierto necesita exportar la ruta nuevamente usando el comando </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">export</span></span> PYTHONPATH=/  /tensroflowmodels/models/research/slim:<span class="hljs-variable"><span class="hljs-variable">$PYTHONPATH</span></span></code> </pre> <br></li><li><p>  si no est√° utilizando su propio gr√°fico y desea obtener informaci√≥n al respecto (por ejemplo, " <code>input_node_name</code> ", que se requiere m√°s adelante), ejecute dos comandos desde la carpeta ra√≠z: </p><br><pre> <code class="hljs powershell">bazel build tensorflow/tools/graph_transforms:summarize_graph bazel<span class="hljs-literal"><span class="hljs-literal">-bin</span></span>/tensorflow/tools/graph_transforms/summarize_graph -<span class="hljs-literal"><span class="hljs-literal">-in_graph</span></span>=<span class="hljs-string"><span class="hljs-string">"/  /frozen_inference_graph.pb"</span></span></code> </pre> <br><p>  donde " <code>/  /frozen_inference_graph.pb</code> " es la ruta al gr√°fico que desea conocer </p><br></li><li><p>  Para ver informaci√≥n sobre el gr√°fico, puede usar Tensorboard. </p><br><pre> <code class="hljs powershell">python import_pb_to_tensorboard.py -<span class="hljs-literal"><span class="hljs-literal">-model_dir</span></span>=output/frozen_inference_graph.pb -<span class="hljs-literal"><span class="hljs-literal">-log_dir</span></span>=training</code> </pre> <br><p>  donde necesita especificar la ruta al gr√°fico ( <code>model_dir</code> ) y la ruta a los archivos que se recibieron durante el entrenamiento ( <code>log_dir</code> ).  Luego, solo abre localhost en el navegador y mira lo que te interesa. </p><br></li></ul><br><p>  Y la √∫ltima parte, sobre c√≥mo trabajar con scripts de Python en las instrucciones de la API de detecci√≥n de objetos, ha preparado una peque√±a hoja de trucos a continuaci√≥n con comandos y sugerencias. </p><br><div class="spoiler">  <b class="spoiler_title">Hoja de trucos</b> <div class="spoiler_text"><p>  Exportar desde labelimg a csv (desde el directorio object_detection) </p><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">python</span></span> xml_to_csv.py</code> </pre> <br><p>  Adem√°s, todos los pasos enumerados a continuaci√≥n deben realizarse desde la misma carpeta de Tensorflow (" <code>tensroflowmodels/models/research/object-detection</code> " o un nivel superior, dependiendo de c√≥mo vaya), es decir, todos las im√°genes de la selecci√≥n de entrada, TFRecords y otros archivos deben copiarse dentro de este directorio antes de comenzar a trabajar. </p><br><p>  Exportar desde csv a tfrecord </p><br><pre> <code class="hljs powershell">python generate_tfrecord.py -<span class="hljs-literal"><span class="hljs-literal">-csv_input</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/train_labels.csv -<span class="hljs-literal"><span class="hljs-literal">-output_path</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/train.record python generate_tfrecord.py -<span class="hljs-literal"><span class="hljs-literal">-csv_input</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/test_labels.csv -<span class="hljs-literal"><span class="hljs-literal">-output_path</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/test.record</code> </pre> <br><p>  * No olvide cambiar las l√≠neas 'train' y 'test' en las rutas del archivo (generate_tfrecord.py), as√≠ como <br>  el nombre de las clases reconocidas en la funci√≥n <code>class_text_to_int</code> (que debe duplicarse en el archivo <code>pbtxt</code> que crear√° antes de entrenar el gr√°fico). </p><br><p>  Entrenamiento </p><br><pre> <code class="hljs powershell">python legacy/train.py ‚Äîlogtostderr -<span class="hljs-literal"><span class="hljs-literal">-train_dir</span></span>=training/ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/ssd_mobilenet_v1_coco.config</code> </pre> <br><p>  ** Antes de entrenar, no olvide verificar el archivo " <code>training/object-detection.pbtxt</code> <code>training/ssd_mobilenet_v1_coco.config</code> " - debe haber todas las clases reconocidas y el archivo " <code>training/ssd_mobilenet_v1_coco.config</code> " - all√≠ debe cambiar el par√°metro " <code>num_classes</code> " al n√∫mero de sus clases. </p><br><p>  Exportar modelo a pb </p><br><pre> <code class="hljs powershell">python export_inference_graph.py \ -<span class="hljs-literal"><span class="hljs-literal">-input_type</span></span>=image_tensor \ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/pipeline.config \ -<span class="hljs-literal"><span class="hljs-literal">-trained_checkpoint_prefix</span></span>=training/model.ckpt<span class="hljs-literal"><span class="hljs-literal">-110</span></span> \ -<span class="hljs-literal"><span class="hljs-literal">-output_directory</span></span>=output</code> </pre> </div></div><br><p>  ¬°Gracias por su inter√©s en este tema! </p><br><p>  Referencias </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Art√≠culo original sobre reconocimiento de objetos.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Un ciclo de video del art√≠culo sobre el reconocimiento de objetos en ingl√©s</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El conjunto de scripts que se utilizaron en el art√≠culo original.</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es427449/">https://habr.com/ru/post/es427449/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es427437/index.html">Configuraci√≥n de servidores vinculados: servidor ms sql y teradata</a></li>
<li><a href="../es427439/index.html">Toda la verdad sobre RTOS. Art√≠culo # 16. Se√±ales</a></li>
<li><a href="../es427441/index.html">Convergencia con Kubernetes</a></li>
<li><a href="../es427443/index.html">Vivisecci√≥n del √©xito.</a></li>
<li><a href="../es427447/index.html">PVS-Studio incluye soporte para GNU Arm Embedded Toolchain</a></li>
<li><a href="../es427451/index.html">Conecte las tareas de phpStorm a Bitrix24</a></li>
<li><a href="../es427453/index.html">C√≥mo hice la transmisi√≥n de sonido en la Raspberry Pi</a></li>
<li><a href="../es427457/index.html">La tercera ola de IA y sistemas para la seguridad del estado</a></li>
<li><a href="../es427459/index.html">L√°mparas LED Diall de la tienda Castorama</a></li>
<li><a href="../es427461/index.html">La belleza de las funciones NO an√≥nimas en JavaScript</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéÉ üò∞ üëæ Analizamos la tonalidad de los textos usando Fast.ai üë¶üèΩ üé∂ üîÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El art√≠culo discutir√° la clasificaci√≥n de la tonalidad de los mensajes de texto en ruso (y esencialmente cualquier clasificaci√≥n de textos que use la ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analizamos la tonalidad de los textos usando Fast.ai</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/472988/">  El art√≠culo discutir√° la clasificaci√≥n de la tonalidad de los mensajes de texto en ruso (y esencialmente cualquier clasificaci√≥n de textos que use la misma tecnolog√≠a).  Tomaremos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este</a> art√≠culo como base, en el que se consider√≥ la clasificaci√≥n de la tonalidad en la arquitectura CNN utilizando el modelo Word2vec.  En nuestro ejemplo, resolveremos el mismo problema de separar los tweets en positivo y negativo en el mismo conjunto de datos utilizando el modelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ULMFit</a> .  El resultado del art√≠culo (puntaje promedio F1 = 0.78142) ser√° aceptado como l√≠nea de base. <a name="habracut"></a><br><br><h4>  Introduccion </h4><br>  El modelo ULMFIT fue presentado por los desarrolladores de fast.ai (Jeremy Howard, Sebastian Ruder) en 2018.  La esencia del enfoque es utilizar el aprendizaje de transferencia en las tareas de PNL cuando utiliza modelos pre-entrenados, reduciendo el tiempo para entrenar sus modelos y reduciendo los requisitos para el tama√±o de la muestra de prueba etiquetada. <br><br>  El esquema de entrenamiento en nuestro caso se ver√° as√≠: <br><br><img src="https://habrastorage.org/webt/qx/pm/yh/qxpmyh8a6woo8qw72dvgzbqjiec.png"><br><br>  El significado del modelo de lenguaje es poder predecir la siguiente palabra en secuencia.  Es problem√°tico obtener textos largos conectados de esta manera, pero, sin embargo, los modelos de lenguaje pueden capturar las propiedades del lenguaje, comprender el contexto del uso de palabras, por lo tanto, es el modelo de lenguaje (y no, por ejemplo, la visualizaci√≥n vectorial de palabras) la base de la tecnolog√≠a.  Para la tarea de modelar el lenguaje, ULMFit utiliza la arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AWD-LSTM</a> , que implica el uso activo del abandono siempre que sea posible y tiene sentido.  El tipo de capacitaci√≥n en modelos de lenguaje a veces se denomina aprendizaje semi-supervisado, porque la etiqueta aqu√≠ es la siguiente palabra y no es necesario marcar nada con las manos. <br><br>  Como modelo de lenguaje pre-entrenado, usaremos casi el √∫nico <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">disponible</a> p√∫blicamente. <br>  Repasemos el algoritmo de aprendizaje desde el principio. <br><br>  Cargamos bibliotecas (verificamos la versi√≥n de Fast.ai en caso de incompatibilidades): <br><br><pre><code class="python hljs">%load_ext autoreload %autoreload <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statistics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> fastai print(<span class="hljs-string"><span class="hljs-string">'fast.ai version is:'</span></span>, fastai.__version__) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> fastai <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> fastai.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split path = <span class="hljs-string"><span class="hljs-string">''</span></span></code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fast.ai</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">version</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">is</span></span></span><span class="hljs-function">: 1.0.58</span></span></code> </pre> <br><h4>  Preparamos datos para el entrenamiento. </h4><br>  Por analog√≠a, llevaremos a cabo una capacitaci√≥n sobre el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cuerpo de textos cortos RuTweetCorp de Yulia Rubtsova</a> , formada a partir de mensajes en ruso de Twitter.  El cuerpo contiene 114,991 tweets positivos y 111,923 tweets negativos en formato CSV.  Adem√°s, hay una base de datos de tweets no asignados con un volumen de 17 639 674 registros en formato SQL.  La tarea de nuestro clasificador ser√° determinar si el tweet es positivo o negativo. <br><br>  Como <s>fue mucho tiempo volver a entrenar el modelo de lenguaje en 17 millones de tweets y la</s> tarea de mostrar el aprendizaje de transferencia fue <s>flojera</s> , volveremos a entrenar el modelo de idioma en un texto del conjunto de datos de entrenamiento, ignorando por completo la base de los tweets no asignados.  Probablemente, utilizando esta base para "afilar" el modelo de lenguaje, puede mejorar el resultado general. <br><br>  Formamos conjuntos de datos para capacitaci√≥n y pruebas con procesamiento de texto preliminar.  Tomamos el c√≥digo del art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">original</a> : <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount'] data_positive = pd.read_csv('data/positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text']) data_negative = pd.read_csv('data/negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text']) #    sample_size = min(data_positive.shape[0], data_negative.shape[0]) raw_data = np.concatenate((data_positive['text'].values[:sample_size], data_negative['text'].values[:sample_size]), axis=0) labels = [1] * sample_size + [0] * sample_size</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocess_text</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text)</span></span></span><span class="hljs-function">:</span></span> text = text.lower().replace(<span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) text = re.sub(<span class="hljs-string"><span class="hljs-string">'((www\.[^\s]+)|(https?://[^\s]+))'</span></span>, <span class="hljs-string"><span class="hljs-string">'URL'</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">'@[^\s]+'</span></span>, <span class="hljs-string"><span class="hljs-string">'USER'</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">'[^a-zA-Z--1-9]+'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">' +'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, text) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text.strip() data = [preprocess_text(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> raw_data]</code> </pre> <br><pre> <code class="python hljs">df_train=pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>, <span class="hljs-string"><span class="hljs-string">'Label'</span></span>]) df_test=pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>, <span class="hljs-string"><span class="hljs-string">'Label'</span></span>]) df_train[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>], df_test[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>], df_train[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>], df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>] = train_test_split(data, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><pre> <code class="python hljs">df_val=pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>, <span class="hljs-string"><span class="hljs-string">'Label'</span></span>]) df_train, df_val = train_test_split(df_train, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  Nos fijamos en lo que pas√≥: <br><br><pre> <code class="python hljs">df_train.groupby(<span class="hljs-string"><span class="hljs-string">'Label'</span></span>).count()</code> </pre> <br><img src="https://habrastorage.org/webt/52/mj/2h/52mj2hhy5_l76e3ac5-wqedflw8.png"><br><br><pre> <code class="python hljs">df_val.groupby(<span class="hljs-string"><span class="hljs-string">'Label'</span></span>).count()</code> </pre> <br><img src="https://habrastorage.org/webt/wh/ub/cb/whubcbjiw1lqkzdw9-r_xiet1gk.png"><br><br><pre> <code class="python hljs">df_test.groupby(<span class="hljs-string"><span class="hljs-string">'Label'</span></span>).count()</code> </pre> <br><img src="https://habrastorage.org/webt/kn/4i/ps/kn4ipsrgguvkzr8lrwc5pwcyti0.png"><br><br><h4>  Aprendiendo un modelo de lenguaje </h4><br>  Cargando datos: <br><br><pre> <code class="python hljs">tokenizer=Tokenizer(lang=<span class="hljs-string"><span class="hljs-string">'xx'</span></span>) data_lm = TextLMDataBunch.from_df(path, tokenizer=tokenizer, bs=<span class="hljs-number"><span class="hljs-number">16</span></span>, train_df=df_train, valid_df=df_val, text_cols=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Nos fijamos en los contenidos: <br><br><pre> <code class="python hljs">data_lm.show_batch()</code> </pre> <br><img src="https://habrastorage.org/webt/xc/da/fo/xcdafozibrlzriutj9jt3d4hdp0.png"><br><br>  Proporcionamos enlaces a los pesos almacenados del modelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">previamente entrenado</a> y un diccionario: <br><br><pre> <code class="python hljs">weights_pretrained = <span class="hljs-string"><span class="hljs-string">'ULMFit/lm_5_ep_lr2-3_5_stlr'</span></span> itos_pretrained = <span class="hljs-string"><span class="hljs-string">'ULMFit/itos'</span></span> pretained_data = (weights_pretrained, itos_pretrained)</code> </pre> <br>  Creamos aprendices, pero antes de eso, una muleta para fast.ai.  El modelo previamente entrenado se entren√≥ en una versi√≥n anterior de la biblioteca, por lo que debe ajustar el n√∫mero de nodos en la capa oculta de la red neuronal. <br><br><pre> <code class="python hljs">config = awd_lstm_lm_config.copy() config[<span class="hljs-string"><span class="hljs-string">'n_hid'</span></span>] = <span class="hljs-number"><span class="hljs-number">1150</span></span> learn_lm = language_model_learner(data_lm, AWD_LSTM, config=config, pretrained_fnames=pretained_data, drop_mult=<span class="hljs-number"><span class="hljs-number">0.3</span></span>) learn_lm.freeze()</code> </pre> <br>  Estamos buscando la tasa de aprendizaje √≥ptima: <br><br><pre> <code class="python hljs">learn_lm.lr_find() learn_lm.recorder.plot()</code> </pre> <br><img src="https://habrastorage.org/webt/ra/zd/tu/razdtu4ybrn60knvib8mq9fgyzc.png"><br>  Entrenamos el modelo de la tercera era (en el modelo, solo el √∫ltimo grupo de capas est√° descongelado). <br><br><pre> <code class="python hljs">learn_lm.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">1e-2</span></span>, moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>, <span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/an/fb/rg/anfbrgrfrwbuwboj_zbizaqznps.png"><br>  Descongelar el modelo y ense√±ar 5 eras m√°s con una tasa de aprendizaje m√°s baja: <br><br><pre> <code class="python hljs">learn_lm.unfreeze() learn_lm.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">1e-3</span></span>, moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>, <span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/a2/qy/cl/a2qyclrnexjry_gxqecltoyctle.png"><br><br><pre> <code class="python hljs">learn_lm.save(<span class="hljs-string"><span class="hljs-string">'lm_ft'</span></span>)</code> </pre><br>  Intentamos generar texto en un modelo entrenado. <br><br><pre> <code class="python hljs">learn_lm.predict(<span class="hljs-string"><span class="hljs-string">"  "</span></span>, n_words=<span class="hljs-number"><span class="hljs-number">5</span></span>)</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: '       '</span></span></code> </pre> <br><pre> <code class="python hljs">learn_lm.predict(<span class="hljs-string"><span class="hljs-string">",  "</span></span>, n_words=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: ',      '</span></span></code> </pre> <br>  Ya vemos, algo que hace el modelo.  Pero nuestra tarea principal es la clasificaci√≥n, y para su soluci√≥n tomaremos un codificador del modelo. <br><br><pre> <code class="python hljs">learn_lm.save_encoder(<span class="hljs-string"><span class="hljs-string">'ft_enc'</span></span>)</code> </pre><br><h4>  Nosotros entrenamos el clasificador </h4><br>  Descargar datos para entrenamiento <br><br><pre> <code class="python hljs">data_clas = TextClasDataBunch.from_df(path, vocab=data_lm.train_ds.vocab, bs=<span class="hljs-number"><span class="hljs-number">32</span></span>, train_df=df_train, valid_df=df_val, text_cols=<span class="hljs-number"><span class="hljs-number">0</span></span>, label_cols=<span class="hljs-number"><span class="hljs-number">1</span></span>, tokenizer=tokenizer)</code> </pre> <br>  Veamos los datos, vemos que las etiquetas se contaron con √©xito (0 significa negativo y 1 significa un comentario positivo): <br><br><pre> <code class="python hljs">data_clas.show_batch()</code> </pre> <br><img src="https://habrastorage.org/webt/gi/vd/4v/givd4vcr8dw_kuqypq4cmlvs8yi.png"><br><br>  Crea un alumno con una muleta similar: <br><br><pre> <code class="python hljs">config = awd_lstm_clas_config.copy() config[<span class="hljs-string"><span class="hljs-string">'n_hid'</span></span>] = <span class="hljs-number"><span class="hljs-number">1150</span></span> learn = text_classifier_learner(data_clas, AWD_LSTM, config=config, drop_mult=<span class="hljs-number"><span class="hljs-number">0.5</span></span>)</code> </pre> <br>  Cargamos el codificador entrenado en la etapa anterior y congelamos el modelo, excepto el √∫ltimo grupo de pesas: <br><pre> <code class="python hljs">learn.load_encoder(<span class="hljs-string"><span class="hljs-string">'ft_enc'</span></span>) learn.freeze()</code> </pre> <br>  Estamos buscando la tasa de aprendizaje √≥ptima: <br><br><pre> <code class="python hljs">learn.lr_find() learn.recorder.plot(skip_start=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/dq/d0/by/dqd0bylpp_8mgn78zbaxrn_ssfe.png"><br>  Entrenamos el modelo con el deshielo gradual de las capas. <br><br><pre> <code class="python hljs">learn.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2e-2</span></span>, moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/uv/zo/qg/uvzoqgzdislgxbirp3cnwu5fg4u.png"><br><br><pre> <code class="python hljs">learn.freeze_to(<span class="hljs-number"><span class="hljs-number">-2</span></span>) learn.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">3</span></span>, slice(<span class="hljs-number"><span class="hljs-number">1e-2</span></span>/(<span class="hljs-number"><span class="hljs-number">2.6</span></span>**<span class="hljs-number"><span class="hljs-number">4</span></span>),<span class="hljs-number"><span class="hljs-number">1e-2</span></span>), moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/bx/pz/xq/bxpzxqpr7d7qqs1ays0dmgl3r-w.png"><br><br><pre> <code class="python hljs">learn.freeze_to(<span class="hljs-number"><span class="hljs-number">-3</span></span>) learn.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">2</span></span>, slice(<span class="hljs-number"><span class="hljs-number">5e-3</span></span>/(<span class="hljs-number"><span class="hljs-number">2.6</span></span>**<span class="hljs-number"><span class="hljs-number">4</span></span>),<span class="hljs-number"><span class="hljs-number">5e-3</span></span>), moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/3b/7t/gj/3b7tgjzickijejuevvgsoy3xe6o.png"><br><br><pre> <code class="python hljs">learn.unfreeze() learn.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">2</span></span>, slice(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>/(<span class="hljs-number"><span class="hljs-number">2.6</span></span>**<span class="hljs-number"><span class="hljs-number">4</span></span>),<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/t9/6o/3k/t96o3k72yvcmzq5es58pb-tiqo4.png"><br><br><pre> <code class="python hljs">learn.save(<span class="hljs-string"><span class="hljs-string">'tweet-0801'</span></span>)</code> </pre> <br>  Vemos que en la muestra de validaci√≥n lograron precisi√≥n = 80.1%. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">Probaremos el</a> modelo en el comentario de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">ZlodeiBaal</a> en mi art√≠culo anterior: <br><br><pre> <code class="python hljs">learn.predict(<span class="hljs-string"><span class="hljs-string">'        ‚Äî ?'</span></span>)</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: (</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Category</span></span></span><span class="hljs-function"> 0, </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">tensor</span></span></span><span class="hljs-function">(0), </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">tensor</span></span></span><span class="hljs-function">([0.6283, 0.3717]))</span></span></code> </pre> <br>  Vemos que el modelo atribuy√≥ este comentario a negativo :-) <br><br><h4>  Comprobaci√≥n del modelo en una muestra de prueba </h4><br>  La tarea principal en esta etapa es probar la capacidad de generalizaci√≥n del modelo.  Para hacer esto, validamos el modelo en el conjunto de datos almacenado en el DataFrame df_test, que hasta ese momento no estaba disponible para el modelo de idioma o para el clasificador. <br><br><pre> <code class="python hljs">data_test_clas = TextClasDataBunch.from_df(path, vocab=data_lm.train_ds.vocab, bs=<span class="hljs-number"><span class="hljs-number">32</span></span>, train_df=df_train, valid_df=df_test, text_cols=<span class="hljs-number"><span class="hljs-number">0</span></span>, label_cols=<span class="hljs-number"><span class="hljs-number">1</span></span>, tokenizer=tokenizer)</code> </pre> <br><pre> <code class="python hljs">config = awd_lstm_clas_config.copy() config[<span class="hljs-string"><span class="hljs-string">'n_hid'</span></span>] = <span class="hljs-number"><span class="hljs-number">1150</span></span> learn_test = text_classifier_learner(data_test_clas, AWD_LSTM, config=config, drop_mult=<span class="hljs-number"><span class="hljs-number">0.5</span></span>)</code> </pre> <br><pre> <code class="python hljs">learn_test.load_encoder(<span class="hljs-string"><span class="hljs-string">'ft_enc'</span></span>) learn_test.load(<span class="hljs-string"><span class="hljs-string">'tweet-0801'</span></span>)</code> </pre> <br><pre> <code class="python hljs">learn_test.validate()</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: [0.4391682, </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">tensor</span></span></span><span class="hljs-function">(0.7973)]</span></span></code> </pre> <br>  Vemos que la precisi√≥n en la muestra de prueba result√≥ ser del 79,7%. <br><br>  Echa un vistazo a la matriz de confusi√≥n: <br><br><pre> <code class="python hljs">interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix()</code> </pre> <br><img src="https://habrastorage.org/webt/em/8g/3t/em8g3tjcki4tueqv-mrc9jmf3t8.png"><br><br>  Calculamos los par√°metros de precisi√≥n, recuperaci√≥n y puntaje f1. <br><br><pre> <code class="python hljs">neg_precision = interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] / (interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] + interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]) neg_recall = interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] / (interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] + interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>]) pos_precision = interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] / (interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] + interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>]) pos_recall = interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] / (interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] + interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]) neg_f1score = <span class="hljs-number"><span class="hljs-number">2</span></span> * (neg_precision * neg_recall) / (neg_precision + neg_recall) pos_f1score = <span class="hljs-number"><span class="hljs-number">2</span></span> * (pos_precision * pos_recall) / (pos_precision + pos_recall)</code> </pre> <br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">'    F1-score'</span></span>) print(<span class="hljs-string"><span class="hljs-string">' Negative {0:1.5f} {1:1.5f} {2:1.5f}'</span></span>.format(neg_precision, neg_recall, neg_f1score)) print(<span class="hljs-string"><span class="hljs-string">' Positive {0:1.5f} {1:1.5f} {2:1.5f}'</span></span>.format(pos_precision, pos_recall, pos_f1score)) print(<span class="hljs-string"><span class="hljs-string">' Average {0:1.5f} {1:1.5f} {2:1.5f}'</span></span>.format(statistics.mean([neg_precision, pos_precision]), statistics.mean([neg_recall, pos_recall]), statistics.mean([neg_f1score, pos_f1score])))</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out:     </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">F1</span></span></span><span class="hljs-function">-</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Negative</span></span></span><span class="hljs-function"> 0.79989 0.80451 0.80219 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Positive</span></span></span><span class="hljs-function"> 0.80142 0.79675 0.79908 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Average</span></span></span><span class="hljs-function"> 0.80066 0.80063 0.80064</span></span></code> </pre> <br>  El resultado que se muestra en la muestra de prueba promedio F1-score = 0.80064. <br><br>  Los pesos de modelos guardados se pueden tomar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/472988/">https://habr.com/ru/post/472988/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../472972/index.html">Trabajamos con cookies como una clase javascript</a></li>
<li><a href="../472978/index.html">Curso de autor Arduino para su propio hijo</a></li>
<li><a href="../472980/index.html">Pantalones cortos Belokamentseva</a></li>
<li><a href="../472982/index.html">‚ÄúEscucha para encontrar un desglose‚Äù: se publican grabaciones de audio de m√°quinas industriales fallidas</a></li>
<li><a href="../472984/index.html">Carro para camiones ROS. Parte 7. Localizaci√≥n del robot: gmapping, AMCL, puntos de referencia en el mapa de la sala.</a></li>
<li><a href="../472994/index.html">¬øQu√© estamos haciendo mal con Spring?</a></li>
<li><a href="../472996/index.html">El Pent√°gono desarrolla tecnolog√≠a de control de drones con los pensamientos de los soldados.</a></li>
<li><a href="../473000/index.html">Una breve gu√≠a matem√°tica para extranjeros</a></li>
<li><a href="../473002/index.html">Explicaci√≥n de la paradoja de Fermi en el marco de la sociolog√≠a espacial Liu Qixin</a></li>
<li><a href="../473006/index.html">DevOps: todo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎃 😰 👾 Analizamos la tonalidad de los textos usando Fast.ai 👦🏽 🎶 🔁</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El artículo discutirá la clasificación de la tonalidad de los mensajes de texto en ruso (y esencialmente cualquier clasificación de textos que use la ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analizamos la tonalidad de los textos usando Fast.ai</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/472988/">  El artículo discutirá la clasificación de la tonalidad de los mensajes de texto en ruso (y esencialmente cualquier clasificación de textos que use la misma tecnología).  Tomaremos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este</a> artículo como base, en el que se consideró la clasificación de la tonalidad en la arquitectura CNN utilizando el modelo Word2vec.  En nuestro ejemplo, resolveremos el mismo problema de separar los tweets en positivo y negativo en el mismo conjunto de datos utilizando el modelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ULMFit</a> .  El resultado del artículo (puntaje promedio F1 = 0.78142) será aceptado como línea de base. <a name="habracut"></a><br><br><h4>  Introduccion </h4><br>  El modelo ULMFIT fue presentado por los desarrolladores de fast.ai (Jeremy Howard, Sebastian Ruder) en 2018.  La esencia del enfoque es utilizar el aprendizaje de transferencia en las tareas de PNL cuando utiliza modelos pre-entrenados, reduciendo el tiempo para entrenar sus modelos y reduciendo los requisitos para el tamaño de la muestra de prueba etiquetada. <br><br>  El esquema de entrenamiento en nuestro caso se verá así: <br><br><img src="https://habrastorage.org/webt/qx/pm/yh/qxpmyh8a6woo8qw72dvgzbqjiec.png"><br><br>  El significado del modelo de lenguaje es poder predecir la siguiente palabra en secuencia.  Es problemático obtener textos largos conectados de esta manera, pero, sin embargo, los modelos de lenguaje pueden capturar las propiedades del lenguaje, comprender el contexto del uso de palabras, por lo tanto, es el modelo de lenguaje (y no, por ejemplo, la visualización vectorial de palabras) la base de la tecnología.  Para la tarea de modelar el lenguaje, ULMFit utiliza la arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AWD-LSTM</a> , que implica el uso activo del abandono siempre que sea posible y tiene sentido.  El tipo de capacitación en modelos de lenguaje a veces se denomina aprendizaje semi-supervisado, porque la etiqueta aquí es la siguiente palabra y no es necesario marcar nada con las manos. <br><br>  Como modelo de lenguaje pre-entrenado, usaremos casi el único <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">disponible</a> públicamente. <br>  Repasemos el algoritmo de aprendizaje desde el principio. <br><br>  Cargamos bibliotecas (verificamos la versión de Fast.ai en caso de incompatibilidades): <br><br><pre><code class="python hljs">%load_ext autoreload %autoreload <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statistics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> fastai print(<span class="hljs-string"><span class="hljs-string">'fast.ai version is:'</span></span>, fastai.__version__) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> fastai <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> fastai.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split path = <span class="hljs-string"><span class="hljs-string">''</span></span></code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fast.ai</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">version</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">is</span></span></span><span class="hljs-function">: 1.0.58</span></span></code> </pre> <br><h4>  Preparamos datos para el entrenamiento. </h4><br>  Por analogía, llevaremos a cabo una capacitación sobre el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cuerpo de textos cortos RuTweetCorp de Yulia Rubtsova</a> , formada a partir de mensajes en ruso de Twitter.  El cuerpo contiene 114,991 tweets positivos y 111,923 tweets negativos en formato CSV.  Además, hay una base de datos de tweets no asignados con un volumen de 17 639 674 registros en formato SQL.  La tarea de nuestro clasificador será determinar si el tweet es positivo o negativo. <br><br>  Como <s>fue mucho tiempo volver a entrenar el modelo de lenguaje en 17 millones de tweets y la</s> tarea de mostrar el aprendizaje de transferencia fue <s>flojera</s> , volveremos a entrenar el modelo de idioma en un texto del conjunto de datos de entrenamiento, ignorando por completo la base de los tweets no asignados.  Probablemente, utilizando esta base para "afilar" el modelo de lenguaje, puede mejorar el resultado general. <br><br>  Formamos conjuntos de datos para capacitación y pruebas con procesamiento de texto preliminar.  Tomamos el código del artículo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">original</a> : <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount'] data_positive = pd.read_csv('data/positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text']) data_negative = pd.read_csv('data/negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text']) #    sample_size = min(data_positive.shape[0], data_negative.shape[0]) raw_data = np.concatenate((data_positive['text'].values[:sample_size], data_negative['text'].values[:sample_size]), axis=0) labels = [1] * sample_size + [0] * sample_size</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocess_text</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text)</span></span></span><span class="hljs-function">:</span></span> text = text.lower().replace(<span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) text = re.sub(<span class="hljs-string"><span class="hljs-string">'((www\.[^\s]+)|(https?://[^\s]+))'</span></span>, <span class="hljs-string"><span class="hljs-string">'URL'</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">'@[^\s]+'</span></span>, <span class="hljs-string"><span class="hljs-string">'USER'</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">'[^a-zA-Z--1-9]+'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">' +'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, text) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text.strip() data = [preprocess_text(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> raw_data]</code> </pre> <br><pre> <code class="python hljs">df_train=pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>, <span class="hljs-string"><span class="hljs-string">'Label'</span></span>]) df_test=pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>, <span class="hljs-string"><span class="hljs-string">'Label'</span></span>]) df_train[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>], df_test[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>], df_train[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>], df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>] = train_test_split(data, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><pre> <code class="python hljs">df_val=pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'Text'</span></span>, <span class="hljs-string"><span class="hljs-string">'Label'</span></span>]) df_train, df_val = train_test_split(df_train, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  Nos fijamos en lo que pasó: <br><br><pre> <code class="python hljs">df_train.groupby(<span class="hljs-string"><span class="hljs-string">'Label'</span></span>).count()</code> </pre> <br><img src="https://habrastorage.org/webt/52/mj/2h/52mj2hhy5_l76e3ac5-wqedflw8.png"><br><br><pre> <code class="python hljs">df_val.groupby(<span class="hljs-string"><span class="hljs-string">'Label'</span></span>).count()</code> </pre> <br><img src="https://habrastorage.org/webt/wh/ub/cb/whubcbjiw1lqkzdw9-r_xiet1gk.png"><br><br><pre> <code class="python hljs">df_test.groupby(<span class="hljs-string"><span class="hljs-string">'Label'</span></span>).count()</code> </pre> <br><img src="https://habrastorage.org/webt/kn/4i/ps/kn4ipsrgguvkzr8lrwc5pwcyti0.png"><br><br><h4>  Aprendiendo un modelo de lenguaje </h4><br>  Cargando datos: <br><br><pre> <code class="python hljs">tokenizer=Tokenizer(lang=<span class="hljs-string"><span class="hljs-string">'xx'</span></span>) data_lm = TextLMDataBunch.from_df(path, tokenizer=tokenizer, bs=<span class="hljs-number"><span class="hljs-number">16</span></span>, train_df=df_train, valid_df=df_val, text_cols=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Nos fijamos en los contenidos: <br><br><pre> <code class="python hljs">data_lm.show_batch()</code> </pre> <br><img src="https://habrastorage.org/webt/xc/da/fo/xcdafozibrlzriutj9jt3d4hdp0.png"><br><br>  Proporcionamos enlaces a los pesos almacenados del modelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">previamente entrenado</a> y un diccionario: <br><br><pre> <code class="python hljs">weights_pretrained = <span class="hljs-string"><span class="hljs-string">'ULMFit/lm_5_ep_lr2-3_5_stlr'</span></span> itos_pretrained = <span class="hljs-string"><span class="hljs-string">'ULMFit/itos'</span></span> pretained_data = (weights_pretrained, itos_pretrained)</code> </pre> <br>  Creamos aprendices, pero antes de eso, una muleta para fast.ai.  El modelo previamente entrenado se entrenó en una versión anterior de la biblioteca, por lo que debe ajustar el número de nodos en la capa oculta de la red neuronal. <br><br><pre> <code class="python hljs">config = awd_lstm_lm_config.copy() config[<span class="hljs-string"><span class="hljs-string">'n_hid'</span></span>] = <span class="hljs-number"><span class="hljs-number">1150</span></span> learn_lm = language_model_learner(data_lm, AWD_LSTM, config=config, pretrained_fnames=pretained_data, drop_mult=<span class="hljs-number"><span class="hljs-number">0.3</span></span>) learn_lm.freeze()</code> </pre> <br>  Estamos buscando la tasa de aprendizaje óptima: <br><br><pre> <code class="python hljs">learn_lm.lr_find() learn_lm.recorder.plot()</code> </pre> <br><img src="https://habrastorage.org/webt/ra/zd/tu/razdtu4ybrn60knvib8mq9fgyzc.png"><br>  Entrenamos el modelo de la tercera era (en el modelo, solo el último grupo de capas está descongelado). <br><br><pre> <code class="python hljs">learn_lm.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">1e-2</span></span>, moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>, <span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/an/fb/rg/anfbrgrfrwbuwboj_zbizaqznps.png"><br>  Descongelar el modelo y enseñar 5 eras más con una tasa de aprendizaje más baja: <br><br><pre> <code class="python hljs">learn_lm.unfreeze() learn_lm.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">1e-3</span></span>, moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>, <span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/a2/qy/cl/a2qyclrnexjry_gxqecltoyctle.png"><br><br><pre> <code class="python hljs">learn_lm.save(<span class="hljs-string"><span class="hljs-string">'lm_ft'</span></span>)</code> </pre><br>  Intentamos generar texto en un modelo entrenado. <br><br><pre> <code class="python hljs">learn_lm.predict(<span class="hljs-string"><span class="hljs-string">"  "</span></span>, n_words=<span class="hljs-number"><span class="hljs-number">5</span></span>)</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: '       '</span></span></code> </pre> <br><pre> <code class="python hljs">learn_lm.predict(<span class="hljs-string"><span class="hljs-string">",  "</span></span>, n_words=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: ',      '</span></span></code> </pre> <br>  Ya vemos, algo que hace el modelo.  Pero nuestra tarea principal es la clasificación, y para su solución tomaremos un codificador del modelo. <br><br><pre> <code class="python hljs">learn_lm.save_encoder(<span class="hljs-string"><span class="hljs-string">'ft_enc'</span></span>)</code> </pre><br><h4>  Nosotros entrenamos el clasificador </h4><br>  Descargar datos para entrenamiento <br><br><pre> <code class="python hljs">data_clas = TextClasDataBunch.from_df(path, vocab=data_lm.train_ds.vocab, bs=<span class="hljs-number"><span class="hljs-number">32</span></span>, train_df=df_train, valid_df=df_val, text_cols=<span class="hljs-number"><span class="hljs-number">0</span></span>, label_cols=<span class="hljs-number"><span class="hljs-number">1</span></span>, tokenizer=tokenizer)</code> </pre> <br>  Veamos los datos, vemos que las etiquetas se contaron con éxito (0 significa negativo y 1 significa un comentario positivo): <br><br><pre> <code class="python hljs">data_clas.show_batch()</code> </pre> <br><img src="https://habrastorage.org/webt/gi/vd/4v/givd4vcr8dw_kuqypq4cmlvs8yi.png"><br><br>  Crea un alumno con una muleta similar: <br><br><pre> <code class="python hljs">config = awd_lstm_clas_config.copy() config[<span class="hljs-string"><span class="hljs-string">'n_hid'</span></span>] = <span class="hljs-number"><span class="hljs-number">1150</span></span> learn = text_classifier_learner(data_clas, AWD_LSTM, config=config, drop_mult=<span class="hljs-number"><span class="hljs-number">0.5</span></span>)</code> </pre> <br>  Cargamos el codificador entrenado en la etapa anterior y congelamos el modelo, excepto el último grupo de pesas: <br><pre> <code class="python hljs">learn.load_encoder(<span class="hljs-string"><span class="hljs-string">'ft_enc'</span></span>) learn.freeze()</code> </pre> <br>  Estamos buscando la tasa de aprendizaje óptima: <br><br><pre> <code class="python hljs">learn.lr_find() learn.recorder.plot(skip_start=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/dq/d0/by/dqd0bylpp_8mgn78zbaxrn_ssfe.png"><br>  Entrenamos el modelo con el deshielo gradual de las capas. <br><br><pre> <code class="python hljs">learn.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2e-2</span></span>, moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/uv/zo/qg/uvzoqgzdislgxbirp3cnwu5fg4u.png"><br><br><pre> <code class="python hljs">learn.freeze_to(<span class="hljs-number"><span class="hljs-number">-2</span></span>) learn.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">3</span></span>, slice(<span class="hljs-number"><span class="hljs-number">1e-2</span></span>/(<span class="hljs-number"><span class="hljs-number">2.6</span></span>**<span class="hljs-number"><span class="hljs-number">4</span></span>),<span class="hljs-number"><span class="hljs-number">1e-2</span></span>), moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/bx/pz/xq/bxpzxqpr7d7qqs1ays0dmgl3r-w.png"><br><br><pre> <code class="python hljs">learn.freeze_to(<span class="hljs-number"><span class="hljs-number">-3</span></span>) learn.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">2</span></span>, slice(<span class="hljs-number"><span class="hljs-number">5e-3</span></span>/(<span class="hljs-number"><span class="hljs-number">2.6</span></span>**<span class="hljs-number"><span class="hljs-number">4</span></span>),<span class="hljs-number"><span class="hljs-number">5e-3</span></span>), moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/3b/7t/gj/3b7tgjzickijejuevvgsoy3xe6o.png"><br><br><pre> <code class="python hljs">learn.unfreeze() learn.fit_one_cycle(<span class="hljs-number"><span class="hljs-number">2</span></span>, slice(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>/(<span class="hljs-number"><span class="hljs-number">2.6</span></span>**<span class="hljs-number"><span class="hljs-number">4</span></span>),<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), moms=(<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.7</span></span>))</code> </pre> <br><img src="https://habrastorage.org/webt/t9/6o/3k/t96o3k72yvcmzq5es58pb-tiqo4.png"><br><br><pre> <code class="python hljs">learn.save(<span class="hljs-string"><span class="hljs-string">'tweet-0801'</span></span>)</code> </pre> <br>  Vemos que en la muestra de validación lograron precisión = 80.1%. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">Probaremos el</a> modelo en el comentario de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">ZlodeiBaal</a> en mi artículo anterior: <br><br><pre> <code class="python hljs">learn.predict(<span class="hljs-string"><span class="hljs-string">'        — ?'</span></span>)</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: (</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Category</span></span></span><span class="hljs-function"> 0, </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">tensor</span></span></span><span class="hljs-function">(0), </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">tensor</span></span></span><span class="hljs-function">([0.6283, 0.3717]))</span></span></code> </pre> <br>  Vemos que el modelo atribuyó este comentario a negativo :-) <br><br><h4>  Comprobación del modelo en una muestra de prueba </h4><br>  La tarea principal en esta etapa es probar la capacidad de generalización del modelo.  Para hacer esto, validamos el modelo en el conjunto de datos almacenado en el DataFrame df_test, que hasta ese momento no estaba disponible para el modelo de idioma o para el clasificador. <br><br><pre> <code class="python hljs">data_test_clas = TextClasDataBunch.from_df(path, vocab=data_lm.train_ds.vocab, bs=<span class="hljs-number"><span class="hljs-number">32</span></span>, train_df=df_train, valid_df=df_test, text_cols=<span class="hljs-number"><span class="hljs-number">0</span></span>, label_cols=<span class="hljs-number"><span class="hljs-number">1</span></span>, tokenizer=tokenizer)</code> </pre> <br><pre> <code class="python hljs">config = awd_lstm_clas_config.copy() config[<span class="hljs-string"><span class="hljs-string">'n_hid'</span></span>] = <span class="hljs-number"><span class="hljs-number">1150</span></span> learn_test = text_classifier_learner(data_test_clas, AWD_LSTM, config=config, drop_mult=<span class="hljs-number"><span class="hljs-number">0.5</span></span>)</code> </pre> <br><pre> <code class="python hljs">learn_test.load_encoder(<span class="hljs-string"><span class="hljs-string">'ft_enc'</span></span>) learn_test.load(<span class="hljs-string"><span class="hljs-string">'tweet-0801'</span></span>)</code> </pre> <br><pre> <code class="python hljs">learn_test.validate()</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out: [0.4391682, </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">tensor</span></span></span><span class="hljs-function">(0.7973)]</span></span></code> </pre> <br>  Vemos que la precisión en la muestra de prueba resultó ser del 79,7%. <br><br>  Echa un vistazo a la matriz de confusión: <br><br><pre> <code class="python hljs">interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix()</code> </pre> <br><img src="https://habrastorage.org/webt/em/8g/3t/em8g3tjcki4tueqv-mrc9jmf3t8.png"><br><br>  Calculamos los parámetros de precisión, recuperación y puntaje f1. <br><br><pre> <code class="python hljs">neg_precision = interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] / (interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] + interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]) neg_recall = interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] / (interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] + interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>]) pos_precision = interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] / (interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] + interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>]) pos_recall = interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] / (interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] + interp.confusion_matrix()[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]) neg_f1score = <span class="hljs-number"><span class="hljs-number">2</span></span> * (neg_precision * neg_recall) / (neg_precision + neg_recall) pos_f1score = <span class="hljs-number"><span class="hljs-number">2</span></span> * (pos_precision * pos_recall) / (pos_precision + pos_recall)</code> </pre> <br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">'    F1-score'</span></span>) print(<span class="hljs-string"><span class="hljs-string">' Negative {0:1.5f} {1:1.5f} {2:1.5f}'</span></span>.format(neg_precision, neg_recall, neg_f1score)) print(<span class="hljs-string"><span class="hljs-string">' Positive {0:1.5f} {1:1.5f} {2:1.5f}'</span></span>.format(pos_precision, pos_recall, pos_f1score)) print(<span class="hljs-string"><span class="hljs-string">' Average {0:1.5f} {1:1.5f} {2:1.5f}'</span></span>.format(statistics.mean([neg_precision, pos_precision]), statistics.mean([neg_recall, pos_recall]), statistics.mean([neg_f1score, pos_f1score])))</code> </pre> <br><pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">Out:     </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">F1</span></span></span><span class="hljs-function">-</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Negative</span></span></span><span class="hljs-function"> 0.79989 0.80451 0.80219 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Positive</span></span></span><span class="hljs-function"> 0.80142 0.79675 0.79908 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Average</span></span></span><span class="hljs-function"> 0.80066 0.80063 0.80064</span></span></code> </pre> <br>  El resultado que se muestra en la muestra de prueba promedio F1-score = 0.80064. <br><br>  Los pesos de modelos guardados se pueden tomar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/472988/">https://habr.com/ru/post/472988/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../472972/index.html">Trabajamos con cookies como una clase javascript</a></li>
<li><a href="../472978/index.html">Curso de autor Arduino para su propio hijo</a></li>
<li><a href="../472980/index.html">Pantalones cortos Belokamentseva</a></li>
<li><a href="../472982/index.html">“Escucha para encontrar un desglose”: se publican grabaciones de audio de máquinas industriales fallidas</a></li>
<li><a href="../472984/index.html">Carro para camiones ROS. Parte 7. Localización del robot: gmapping, AMCL, puntos de referencia en el mapa de la sala.</a></li>
<li><a href="../472994/index.html">¿Qué estamos haciendo mal con Spring?</a></li>
<li><a href="../472996/index.html">El Pentágono desarrolla tecnología de control de drones con los pensamientos de los soldados.</a></li>
<li><a href="../473000/index.html">Una breve guía matemática para extranjeros</a></li>
<li><a href="../473002/index.html">Explicación de la paradoja de Fermi en el marco de la sociología espacial Liu Qixin</a></li>
<li><a href="../473006/index.html">DevOps: todo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
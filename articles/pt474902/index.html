<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßóüèª üåÄ üöê Tend√™ncias em vis√£o computacional. Destaques ICCV 2019 üö¶ üôâ üåä</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As redes neurais na vis√£o computacional est√£o se desenvolvendo ativamente, muitas tarefas ainda est√£o longe de serem resolvidas. Para se destacar em s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tend√™ncias em vis√£o computacional. Destaques ICCV 2019</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/474902/"><img src="https://habrastorage.org/webt/in/lj/qf/inljqfmjnklszyujlyua8n_w0bo.jpeg"><br><br>  As redes neurais na vis√£o computacional est√£o se desenvolvendo ativamente, muitas tarefas ainda est√£o longe de serem resolvidas.  Para se destacar em seu campo, basta seguir os influenciadores no Twitter e ler os artigos relevantes em arXiv.org.  Mas tivemos a oportunidade de ir √† Confer√™ncia Internacional sobre Vis√£o Computacional (ICCV) 2019. Este ano, √© realizado na Cor√©ia do Sul.  Agora queremos compartilhar com os leitores de Habr que vimos e aprendemos. <br><a name="habracut"></a><br>  Muitos de n√≥s da Yandex: desenvolvedores de ve√≠culos n√£o tripulados, pesquisadores e os envolvidos nas tarefas de CV nos servi√ßos chegaram.  Mas agora queremos introduzir um ponto de vista um pouco subjetivo de nossa equipe - o laborat√≥rio de intelig√™ncia de m√°quinas (Yandex MILAB).  Outros caras provavelmente olharam para a confer√™ncia de seu √¢ngulo. <br><br><div class="spoiler">  <b class="spoiler_title">O que o laborat√≥rio faz</b> <div class="spoiler_text">  Realizamos projetos experimentais relacionados √† gera√ß√£o de imagens e m√∫sicas para fins de entretenimento.  Estamos especialmente interessados ‚Äã‚Äãem redes neurais que permitem alterar o conte√∫do do usu√°rio (para uma foto, essa tarefa √© chamada manipula√ß√£o de imagem).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um exemplo do</a> resultado do nosso trabalho da confer√™ncia YaC 2019. </div></div><br>  Existem muitas confer√™ncias cient√≠ficas, mas as principais confer√™ncias A * se destacam, onde geralmente s√£o publicados artigos sobre as tecnologias mais interessantes e importantes.  N√£o existe uma lista exata de confer√™ncias A *, aqui est√° um exemplo e incompleto: NeurIPS (anteriormente NIPS), ICML, SIGIR, WWW, WSDM, KDD, ACL, CVPR, ICCV, ECCV.  Os tr√™s √∫ltimos s√£o especializados no t√≥pico CV. <br><br><h2>  Vis√£o geral do ICCV: p√¥steres, tutoriais, oficinas, stands </h2><br>  1075 trabalhos foram aceitos na confer√™ncia, os participantes foram 7.500. 103 pessoas vieram da R√∫ssia, artigos de funcion√°rios da Yandex, Skoltech, Samsung AI Center Moscow e Samara University.  Este ano, n√£o muitos pesquisadores de ponta visitaram o ICCV, mas aqui, por exemplo, Alexey (Alyosha) Efros, que sempre re√∫ne muitas pessoas: <br><br><img src="https://habrastorage.org/webt/4g/ie/3w/4gie3wyqaablh0wmnxbq4ucdwbs.jpeg"><br><br><div class="spoiler">  <b class="spoiler_title">Estat√≠sticas</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/1e/lz/am/1elzamxsr2xf9k_gqrwvvvrwey0.jpeg" width="500"><br><br><img src="https://habrastorage.org/webt/vb/yr/1i/vbyr1im56rz6ib-6sj_0fjiokjc.jpeg" width="500"><br><br><img src="https://habrastorage.org/webt/l6/wc/iy/l6wciy-qakwq9wwe65hz9-pqjl8.jpeg" width="500"><br><br><img src="https://habrastorage.org/webt/jb/dr/rq/jbdrrqkeo6mw26wx3zi5taa_zog.jpeg" width="500"><br><br><img src="https://habrastorage.org/webt/2g/rb/rt/2grbrtsd1xwbzwzxfstgdck6jis.jpeg" width="500"><br></div></div><br>  Em todas essas confer√™ncias, os artigos s√£o apresentados na forma de p√¥steres ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mais</a> sobre o formato), e os melhores tamb√©m na forma de breves relat√≥rios. <br><br><div class="spoiler">  <b class="spoiler_title">Aqui est√° parte do trabalho da R√∫ssia</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/iu/sc/po/iuscpof__g3ikvdguuy94javuvo.jpeg"><br><br><img src="https://habrastorage.org/webt/ae/e0/xj/aee0xjbluiby-b_xxoednb7yfws.jpeg"><br><br><img src="https://habrastorage.org/webt/1s/qt/la/1sqtla2h9xgccuhu2dr1iyvxuek.jpeg"><br></div></div><br>  Nos tutoriais, voc√™ pode mergulhar em alguma √°rea, assemelha-se a uma palestra em uma universidade.  √â lido por uma pessoa, geralmente sem falar sobre trabalhos espec√≠ficos.  Exemplo de um tutorial legal ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Michael Brown, No√ß√µes b√°sicas sobre cores e o pipeline de processamento de imagens na c√¢mera para o Computer Vision</a> ): <br><br><img src="https://habrastorage.org/webt/2z/sq/e6/2zsqe6wgv1rtrl0tpvwl-eu5enw.jpeg"><br><br>  Nas oficinas, pelo contr√°rio, eles falam sobre artigos.  Geralmente, esse √© um trabalho em algum t√≥pico restrito, hist√≥rias de l√≠deres de laborat√≥rio sobre todo o trabalho mais recente dos alunos ou artigos que n√£o foram aceitos na confer√™ncia principal. <br><br>  As empresas patrocinadoras v√™m ao ICCV com estandes.  Este ano, Google, Facebook, Amazon e muitas outras empresas internacionais chegaram, al√©m de um grande n√∫mero de startups - coreanas e chinesas.  Havia muitas startups especializadas em marca√ß√£o de dados.  H√° apresenta√ß√µes nas bancas, voc√™ pode levar mercadorias e fazer perguntas.  As empresas patrocinadoras t√™m festas para a ca√ßa.  Eles conseguem se convencer dos recrutadores de que voc√™ est√° interessado e que voc√™ pode ser potencialmente entrevistado.  Se voc√™ publicou um artigo (ou, al√©m disso, fez uma apresenta√ß√£o com ele), iniciou ou terminou o doutorado - isso √© uma vantagem, mas √†s vezes voc√™ pode concordar com uma posi√ß√£o, fazendo perguntas interessantes aos engenheiros da empresa. <br><br><h2>  Tend√™ncias </h2><br>  A confer√™ncia permite que voc√™ d√™ uma olhada em toda a √°rea do curr√≠culo.  Pelo n√∫mero de p√¥steres de um t√≥pico espec√≠fico, voc√™ pode avaliar a qualidade do t√≥pico.  Algumas conclus√µes imploram pelas palavras-chave: <br><br><img src="https://habrastorage.org/webt/7u/td/1v/7utd1vf3hcbbhtrgl3xvldtjnjc.jpeg"><br><br><h4>  Tiro zero, tiro √∫nico, tiro curto, auto-supervisionado e semi-supervisionado: novas abordagens para problemas estudados h√° muito tempo </h4><br>  As pessoas aprendem a usar os dados com mais efici√™ncia.  Por exemplo, no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">FUNIT,</a> voc√™ pode gerar express√µes faciais de animais que n√£o estavam no conjunto de treinamento (aplicando v√°rias fotos de refer√™ncia no aplicativo).  As id√©ias do Deep Image Prior foram desenvolvidas e agora as redes <abbr title="Redes advers√°rias generativas, redes advers√°rias generativas.">GAN</abbr> podem ser treinadas em uma imagem - falaremos sobre isso mais adiante <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">nos destaques</a> .  Voc√™ pode usar a auto-supervis√£o para pr√©-treinamento (resolvendo um problema para o qual voc√™ pode sintetizar dados alinhados, por exemplo, para prever o √¢ngulo de rota√ß√£o de uma imagem) ou aprender ao mesmo tempo a partir de dados marcados e n√£o marcados.  Nesse sentido, a coroa da cria√ß√£o pode ser considerada um artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">S4L: Aprendizagem semi-supervisionada auto-supervisionada</a> .  Mas o pr√©-treinamento no ImageNet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">nem sempre</a> ajuda. <br><br><img src="https://habrastorage.org/webt/gj/yy/n4/gjyyn40ktbwpjaslfp0v7c-avhi.jpeg"><br><br><img src="https://habrastorage.org/webt/x5/6-/l8/x56-l8y26lyq9unxyt0soa8koay.jpeg"><br><br><h4>  3D e 360 ‚Äã‚Äã¬∞ </h4><br>  As tarefas, geralmente resolvidas para fotos (segmenta√ß√£o, detec√ß√£o), exigem pesquisas adicionais para modelos 3D e v√≠deos panor√¢micos.  Vimos muitos artigos sobre a convers√£o de RGB e <abbr title="Imagem com profundidade RGB. Para cada ponto, n√£o apenas sua cor √© conhecida, mas tamb√©m sua ‚Äúprofundidade‚Äù - a dist√¢ncia do ponto de vista / disparo.">RGB-D</abbr> para 3D.  Algumas tarefas, como determinar a pose de uma pessoa (estimativa de pose), s√£o resolvidas mais naturalmente se formos para modelos tridimensionais.  Mas at√© agora n√£o h√° consenso sobre exatamente como representar modelos 3D - na forma de uma grade, uma nuvem de pontos, <abbr title="An√°logos de pixels em 3D.">voxels</abbr> ou <abbr title="Campos de dist√¢ncia assinados - campos de dist√¢ncia assinados.">SDF</abbr> .  Aqui est√° outra op√ß√£o: <br><br><img src="https://habrastorage.org/webt/n7/i-/1x/n7i-1xtwmc5xxvs4cfsf4vt4srw.jpeg"><br><br>  Nos panoramas, as convolu√ß√µes na esfera est√£o se desenvolvendo ativamente (consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Segmenta√ß√£o sem√¢ntica com reconhecimento de orienta√ß√£o nas esferas de icosaedro</a> ) e a busca por objetos-chave no quadro. <br><br><img src="https://habrastorage.org/webt/bk/4l/gw/bk4lgwc3dzrh_uliw83x21hskyy.png"><br><br><h4>  Defini√ß√£o de postura e previs√£o de movimentos humanos </h4><br>  Para determinar a pose em 2D, j√° existe sucesso - agora o foco mudou para o trabalho com v√°rias c√¢meras e em 3D.  Por exemplo, voc√™ pode determinar o esqueleto atrav√©s da parede, acompanhando as altera√ß√µes no sinal Wi-Fi √† medida que ele passa pelo corpo humano. <br><br>  Muito trabalho foi feito na √°rea de detec√ß√£o de ponto-chave manual.  Novos conjuntos de dados apareceram, incluindo aqueles baseados em v√≠deo com di√°logos de duas pessoas - agora voc√™ pode prever gestos com as m√£os por √°udio ou texto de uma conversa!  O mesmo progresso foi feito nas tarefas de avalia√ß√£o do olhar. <br><br><img src="https://habrastorage.org/webt/j0/-j/kv/j0-jkvftadbawqem0ccmm7qmdpa.jpeg"><br><br><img src="https://habrastorage.org/webt/u_/gj/j6/u_gjj6f2d-icebbun428-1e0ztc.jpeg"><br><br>  Voc√™ tamb√©m pode destacar um grande conjunto de trabalhos relacionados √† previs√£o de movimento humano (por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Previs√£o de movimento humano por meio de pintura espacial e temporal</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Previs√£o estruturada ajuda a modelagem de movimento humano em 3D</a> ).  A tarefa √© importante e, com base nas conversas com os autores, √© mais frequentemente usada para analisar o comportamento dos pedestres na dire√ß√£o aut√¥noma. <br><br><h4>  Manipular pessoas em fotos e v√≠deos, provadores virtuais </h4><br>  A principal tend√™ncia √© alterar as imagens faciais em termos de par√¢metros interpretados.  Id√©ias: <abbr title="Substitui√ß√£o de estranhos no v√≠deo.">busca profunda</abbr> em uma imagem, mudan√ßa de express√£o por renderiza√ß√£o de face ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PuppetGAN</a> ), altera√ß√£o de par√¢metros de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">avan√ßo</a> (por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">idade</a> ).  As transfer√™ncias de estilo passaram do t√≠tulo do t√≥pico para a aplica√ß√£o do trabalho.  Outra hist√≥ria - provadores virtuais, eles quase sempre funcionam mal, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui est√° um exemplo de uma</a> demonstra√ß√£o. <br><br><img src="https://habrastorage.org/webt/u-/q9/rw/u-q9rwdkgxxor2snnsrkstmykbe.jpeg"><br><br><img src="https://habrastorage.org/webt/qw/f4/ys/qwf4ys-wamesjxss4gs30v9wbpq.jpeg"><br><br><h4>  Gera√ß√£o de esbo√ßo / gr√°fico </h4><br>  O desenvolvimento da id√©ia ‚ÄúDeixe a grade gerar algo com base na experi√™ncia anterior‚Äù tornou-se diferente: ‚ÄúVamos mostrar √† grade qual op√ß√£o nos interessa‚Äù. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O SC-FEGAN</a> permite que voc√™ fa√ßa a pintura guiada: o usu√°rio pode desenhar parte do rosto na √°rea apagada da imagem e obter a imagem restaurada, dependendo da renderiza√ß√£o. <br><br><img src="https://habrastorage.org/webt/kn/pv/0d/knpv0dzfajvu2hhcbqdgiw-sbek.gif"><br><br>  Em um dos 25 artigos da Adobe para ICCV, dois GANs s√£o combinados: um desenha um esbo√ßo para o usu√°rio, o outro gera uma imagem foto-realista a partir do esbo√ßo ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">p√°gina do projeto</a> ). <br><br><img src="https://habrastorage.org/webt/ua/ba/ap/uabaap4mv5jwm9tdc0qgsxty3ho.gif"><br><br>  No in√≠cio da gera√ß√£o de imagens, os gr√°ficos n√£o eram necess√°rios, mas agora eles foram transformados em um recipiente de conhecimento sobre a cena.  O pr√™mio de Men√ß√µes Honrosas do ICCV de Melhor Artigo tamb√©m foi concedido ao artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Especificando Atributos e Rela√ß√µes de Objetos na Gera√ß√£o de Cena Interativa</a> .  Em geral, voc√™ pode us√°-los de diferentes maneiras: gerar gr√°ficos a partir de figuras ou figuras e textos a partir de gr√°ficos. <br><br><img src="https://habrastorage.org/webt/5h/qf/zw/5hqfzwxfjjt-1bnyqopp7ozoqi4.png"><br><br><h4>  Re-identifica√ß√£o de pessoas e m√°quinas, contando o n√∫mero de multid√µes (!) </h4><br>  Muitos artigos s√£o dedicados a rastrear pessoas e <abbr title="Re-identifica√ß√£o - pode ser traduzido gratuitamente como &quot;desanonimiza√ß√£o&quot;.">reidentificar</abbr> pessoas e m√°quinas.  Mas o que nos surpreendeu foi um monte de artigos sobre como contar pessoas no meio da multid√£o e todos da China. <br><br><div class="spoiler">  <b class="spoiler_title">P√¥steres</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/fh/cn/ma/fhcnma3kitjamuo8yty7hjp1loa.jpeg"><br><br><img src="https://habrastorage.org/webt/ej/_p/66/ej_p66wxpnx52yzlv97osbkys1u.jpeg"><br><br><img src="https://habrastorage.org/webt/j7/7z/bv/j77zbvjegwrfp6emzv-ddcylgmm.jpeg"><br><br><img src="https://habrastorage.org/webt/q9/lw/kr/q9lwkrpkzozcvfa609k6t5krmnw.jpeg"><br><br><img src="https://habrastorage.org/webt/3x/rv/1i/3xrv1ibiocsa5cgbmdvecwxbkyu.jpeg"></div></div><br>  Mas o Facebook, pelo contr√°rio, anonimamente a foto.  Al√©m disso, ele faz isso de uma maneira interessante: ensina a rede neural a gerar um rosto sem detalhes √∫nicos - semelhantes, mas n√£o tanto, a ponto de serem detectados corretamente pelos sistemas de reconhecimento facial. <br><br><img src="https://habrastorage.org/webt/jg/az/oe/jgazoe4ptlfckqpaxdgri2kdlwc.jpeg"><br><br><h4>  Prote√ß√£o Contra Ataques Advers√°rios </h4><br>  Com o desenvolvimento de aplicativos de vis√£o computacional no mundo real (em ve√≠culos n√£o tripulados, no reconhecimento de rostos), a quest√£o da confiabilidade de tais sistemas surge com mais frequ√™ncia.  Para fazer pleno uso do CV, voc√™ precisa ter certeza de que o sistema √© resistente a ataques advers√°rios - portanto, n√£o havia menos artigos sobre prote√ß√£o contra eles do que sobre os pr√≥prios ataques.  Muito trabalho consistiu em explicar as previs√µes da rede (mapa de sali√™ncias) e medir a confian√ßa no resultado. <br><br><h4>  Tarefas combinadas </h4><br>  Na maioria das tarefas com um objetivo, as possibilidades de melhorar a qualidade est√£o quase esgotadas; uma das novas √°reas de maior crescimento da qualidade √© ensinar as redes neurais a resolver v√°rios problemas semelhantes ao mesmo tempo.  Exemplos: <br>  - previs√£o de a√ß√µes + previs√£o de fluxo √≥ptico, <br>  - apresenta√ß√£o de v√≠deo + representa√ß√£o da l√≠ngua ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VideoBERT</a> ), <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">super-resolu√ß√£o + HDR</a> . <br><br>  E havia artigos sobre segmenta√ß√£o, determinando a postura e a reidentifica√ß√£o dos animais! <br><br><img src="https://habrastorage.org/webt/qe/gk/fi/qegkfif0smvsnit1kjrpdbkajco.jpeg"><br><br><img src="https://habrastorage.org/webt/tz/hk/fo/tzhkfogbi5sxyvzbhu5bjaoii54.jpeg"><br><br><a name="highlights"></a><h2>  Destaques </h2><br>  Quase todos os artigos eram conhecidos com anteced√™ncia, o texto estava dispon√≠vel no arXiv.org.  Portanto, a apresenta√ß√£o de trabalhos como Everybody Dance Now, FUNIT, Image2StyleGAN parece bastante estranha - esses s√£o trabalhos muito √∫teis, mas n√£o s√£o novos.  Parece que o processo cl√°ssico de publica√ß√£o cient√≠fica est√° falhando aqui - a ci√™ncia est√° se desenvolvendo muito r√°pido. <br><br>  √â muito dif√≠cil determinar os melhores trabalhos - existem muitos, os assuntos s√£o diferentes.  V√°rios artigos receberam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pr√™mios e refer√™ncias</a> . <br><br>  Queremos destacar trabalhos que s√£o interessantes em termos de manipula√ß√£o de imagens, pois esse √© o nosso t√≥pico.  Eles se mostraram bastante novos e interessantes para n√≥s (n√£o pretendemos ser objetivos). <br><br><h4>  SinGAN (pr√™mio de melhor artigo) e InGAN </h4>  SinGAN: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">p√°gina do projeto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">c√≥digo</a> . <br>  InGAN: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">p√°gina do projeto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">c√≥digo</a> . <br><br>  O desenvolvimento da id√©ia do Deep Image Prior por Dmitry Ulyanov, Andrea Vedaldi e Victor Lempitsky.  Em vez de treinar a GAN em um conjunto de dados, as redes aprendem com fragmentos da mesma imagem para lembrar as estat√≠sticas dentro dela.  A rede treinada permite editar e animar fotos (SinGAN) ou gerar novas imagens de qualquer tamanho a partir das texturas da imagem original, mantendo a estrutura local (InGAN). <br><br>  SinGAN: <br><br><img src="https://habrastorage.org/webt/oc/ba/pt/ocbaptuxkshaswnhnfhloplqmrm.png"><br><br>  InGAN: <br><br><img src="https://habrastorage.org/webt/xn/cc/i0/xncci0dgonpmajjiv0fisak0twa.gif"><br><br><h4>  Vendo o que um GAN n√£o pode gerar </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">P√°gina do projeto</a> . <br><br>  As redes neurais geradoras de imagens geralmente recebem um vetor de ru√≠do aleat√≥rio como entrada.  Em uma rede treinada, muitos vetores de entrada formam um espa√ßo, pequenos movimentos ao longo dos quais levam a pequenas mudan√ßas na imagem.  Usando a otimiza√ß√£o, voc√™ pode resolver o problema inverso: encontre um vetor de entrada adequado para uma imagem do mundo real.  O autor mostra que quase nunca √© poss√≠vel encontrar uma imagem completamente correspondente em uma rede neural quase nunca.  Alguns objetos na imagem n√£o s√£o gerados (aparentemente, devido √† grande variabilidade desses objetos). <br><br><img src="https://habrastorage.org/webt/pv/pa/f2/pvpaf2havdxksu-mhmbus-naina.png"><br><br>  O autor prop√µe que o GAN n√£o cubra todo o espa√ßo das imagens, mas apenas alguns subconjuntos recheados de buracos, como queijo.  Quando tentamos encontrar fotos do mundo real, sempre falhamos, porque a GAN ainda gera fotos n√£o muito reais.  Voc√™ pode superar as diferen√ßas entre imagens reais e geradas apenas alterando o peso da rede, ou seja, treinando-a novamente para uma foto espec√≠fica. <br><br><img src="https://habrastorage.org/webt/ci/vg/bp/civgbpxixfgs_76svkwewjksn3a.jpeg"><br><br>  Quando a rede √© treinada novamente para uma foto espec√≠fica, voc√™ pode tentar realizar v√°rias manipula√ß√µes com esta imagem.  No exemplo abaixo, uma janela foi adicionada √† foto e a rede gerou reflex√µes adicionalmente no conjunto da cozinha.  Isso significa que a rede ap√≥s o treinamento para a fotografia n√£o perdeu a capacidade de ver a conex√£o entre os objetos da cena. <br><br><img src="https://habrastorage.org/webt/ov/gp/qd/ovgpqdyldwsdptpav699a_vl2qo.jpeg"><br><br><h4>  GANalyze: Em dire√ß√£o a defini√ß√µes visuais de propriedades da imagem cognitiva </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">P√°gina do projeto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv</a> . <br><br>  Usando a abordagem deste trabalho, voc√™ pode visualizar e analisar o que a rede neural aprendeu.  Os autores prop√µem o treinamento da GAN para criar imagens para as quais a rede gerar√° determinadas previs√µes.  V√°rias redes foram usadas como exemplos no artigo, incluindo o MemNet, que prev√™ a memoriza√ß√£o de fotos.  Aconteceu que, para uma melhor memoriza√ß√£o, o objeto na foto deve: <br><br><ul><li>  estar mais perto do centro </li><li>  ter uma forma redonda ou quadrada e estrutura simples, </li><li>  estar em um fundo uniforme, </li><li>  conter olhos expressivos (pelo menos para fotos de c√£es), </li><li>  seja mais brilhante, mais rico, em alguns casos - mais vermelho. </li></ul><br><img src="https://habrastorage.org/webt/9y/b2/wd/9yb2wdgndc2qvmugfdk5yctxfbg.png"><br><br><h4>  Liquid Warping GAN: Uma Estrutura Unificada para Imita√ß√£o de Movimento Humano, Transfer√™ncia de Apar√™ncia e S√≠ntese de Novas Vis√µes </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">P√°gina do projeto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">c√≥digo</a> . <br><br>  Pipeline para gerar fotos de pessoas a partir de uma foto.  Os autores mostram exemplos bem-sucedidos de transferir o movimento de uma pessoa para outra, transferir roupas entre as pessoas e gerar novas perspectivas de uma pessoa - tudo a partir de uma fotografia.  Diferentemente dos trabalhos anteriores, aqui, para criar condi√ß√µes, n√£o s√£o usados ‚Äã‚Äãpontos-chave em 2D (pose), mas uma malha 3D do corpo (pose + forma).  Os autores tamb√©m descobriram como transferir informa√ß√µes da imagem original para a imagem gerada (Liquid Warping Block).  Os resultados parecem decentes, mas a resolu√ß√£o da imagem resultante √© de apenas 256x256.  Para compara√ß√£o, o vid2vid, que apareceu h√° um ano, √© capaz de gerar uma resolu√ß√£o de 2048x1024, mas precisa de at√© 10 minutos de grava√ß√£o de v√≠deo como um conjunto de dados. <br><br><img src="https://habrastorage.org/webt/el/m1/eh/elm1ehlgjasetl9leqejn9elvbu.png"><br><br><h4>  FSGAN: Troca de Agn√≥stico de Rosto e Reencena√ß√£o </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">P√°gina do projeto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv</a> . <br><br>  A princ√≠pio, parece que nada de incomum: deepfake com qualidade mais ou menos normal.  Mas a principal conquista do trabalho √© a substitui√ß√£o de rostos em uma imagem.  Ao contr√°rio dos trabalhos anteriores, era necess√°rio treinamento em uma variedade de fotografias de uma pessoa em particular.  O pipeline acabou por ser complicado (reconstitui√ß√£o e segmenta√ß√£o, exibir interpola√ß√£o, pintura, mistura) e com muitos hacks t√©cnicos, mas o resultado vale a pena. <br><br><img src="https://habrastorage.org/webt/43/33/zn/4333zncbuoqflhf2srkk-05e6m0.png"><br><br><h4>  Detectando o inesperado via ress√≠ntese de imagens </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv</a> . <br><br>  Como um drone pode entender que um objeto apareceu repentinamente na frente dele e n√£o se enquadra em nenhuma classe de segmenta√ß√£o sem√¢ntica?  Existem v√°rios m√©todos, mas os autores oferecem um algoritmo novo e intuitivo que funciona melhor que seus antecessores.  A segmenta√ß√£o sem√¢ntica √© prevista a partir da imagem de entrada da estrada.  Ele √© alimentado no GAN (pix2pixHD), que tenta restaurar a imagem original apenas do mapa sem√¢ntico.  Anomalias que n√£o caem em nenhum dos segmentos diferem significativamente na origem e na imagem gerada.  Em seguida, tr√™s imagens (inicial, segmenta√ß√£o e reconstru√≠da) s√£o enviadas para outra rede, que prev√™ anomalias.  O conjunto de dados para isso foi gerado a partir do conhecido conjunto de dados Cityscapes, alterando acidentalmente as classes na segmenta√ß√£o sem√¢ntica.  Curiosamente, nesse cen√°rio, um cachorro parado no meio da estrada, mas segmentado corretamente (o que significa que h√° uma classe para ele), n√£o √© uma anomalia, pois o sistema conseguiu reconhec√™-lo. <br><br><img src="https://habrastorage.org/webt/fc/1_/ug/fc1_ugp2xbh5qxttjgskyxprji4.png"><br><br><h2>  Conclus√£o </h2><br>  Antes da confer√™ncia, √© importante saber quais s√£o seus interesses cient√≠ficos, quais discursos gostaria de fazer e com quem conversar.  Ent√£o tudo ser√° muito mais produtivo. <br><br>  O ICCV √© principalmente de rede.  Voc√™ entende que existem institui√ß√µes e cientistas de ponta, come√ßa a entender isso, a conhecer pessoas.  E voc√™ pode ler artigos sobre o arXiv - e, a prop√≥sito, √© muito legal que voc√™ n√£o possa ir a lugar algum em busca de conhecimento. <br><br>  Al√©m disso, na confer√™ncia, voc√™ pode mergulhar profundamente em t√≥picos que n√£o est√£o perto de voc√™, veja as tend√™ncias.  Bem, escreva uma lista de artigos para ler.  Se voc√™ √© um estudante, esta √© uma oportunidade para voc√™ se familiarizar com um cientista em potencial, se voc√™ √© do setor, depois com um novo empregador e se a empresa se mostrar. <br><br>  Inscreva-se em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">@loss_function_porn</a> !  Este √© um projeto pessoal: estamos juntos com a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">karfly</a> .  Todo o trabalho que gostamos durante a confer√™ncia, postamos aqui: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">@loss_function_live</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt474902/">https://habr.com/ru/post/pt474902/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt474890/index.html">Teste comparativo de c√¢meras de celulares antigos e um pouco de hist√≥ria</a></li>
<li><a href="../pt474892/index.html">Programa√ß√£o para crian√ßas. Cinco dos melhores jogos HTML e JavaScript</a></li>
<li><a href="../pt474894/index.html">Resumo atrav√©s dos olhos de um entrevistador</a></li>
<li><a href="../pt474896/index.html">Os cientistas descobriram um novo fator na entrega eficaz de drogas no tumor</a></li>
<li><a href="../pt474900/index.html">O chip de c√≥digo aberto OpenTitan substitui as ra√≠zes de confian√ßa propriet√°rias da Intel e ARM</a></li>
<li><a href="../pt474906/index.html">Xamarin.Forms - Mapeamento QRCode decorativo com SkiaSharp</a></li>
<li><a href="../pt474910/index.html">O que brincar com as crian√ßas antes da escola</a></li>
<li><a href="../pt474912/index.html">Mensagens e alertas no Android via JSON</a></li>
<li><a href="../pt474916/index.html">Aplicar o ambiente Nix-Shell no Visual Studio Code</a></li>
<li><a href="../pt474918/index.html">Melhorando o projeto conjunto de componentes eletromec√¢nicos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
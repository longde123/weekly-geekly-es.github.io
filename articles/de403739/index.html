<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐉 💥 🤠 Es wird ein bionischer Arm mit einem neuronalen Netzwerk erstellt, der Objekte sofort erkennt und erfasst 😶 🚔 🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bionische Prothesen der letzten Generation werden üblicherweise mit Hilfe von myoelektrischen Signalen gesteuert, die durch Muskelkontraktionen der me...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Es wird ein bionischer Arm mit einem neuronalen Netzwerk erstellt, der Objekte sofort erkennt und erfasst</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/403739/"><img src="https://habrastorage.org/getpro/geektimes/post_images/17b/0b5/4a1/17b0b54a1c514ecd09a61b41fd826fc0.jpg"><br><br>  Bionische Prothesen der letzten Generation werden üblicherweise mit Hilfe von myoelektrischen Signalen gesteuert, die durch Muskelkontraktionen der menschlichen Hand entstehen.  Die Handhabung einer solchen Prothese ist nicht einfach: Sie erfordert eine gewisse Konzentration, und die Wirksamkeit erfolgreicher Maßnahmen lässt zu wünschen übrig.  Es ist nicht einfach, beim ersten Mal das zu tun, was Sie wollen.  In Bezug auf die Genauigkeit von Handlungen sind solche Prothesen weit entfernt von den „intuitiven“ Handlungen einer lebenden echten Hand. <br><br>  In den letzten Jahren haben sich die Forscher hauptsächlich auf die Genauigkeit der Erkennung myoelektrischer Signale konzentriert, und die Genauigkeit der Erkennung der Bewegungen einzelner Finger hat 90% erreicht.  Aus einer Reihe von technischen Gründen ist der massive Einsatz solcher „intelligenten“ Prothesen jedoch sehr begrenzt.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Eine Neuentwicklung von</a> Ingenieuren der University of Newcastle (UK) bietet einen grundlegend anderen Ansatz.  Eine mit einer Videokamera ausgestattete Hand erkennt ein Objekt davor - und bestimmt, wie es am besten erfasst werden kann.  Es wirkt automatisch und fast augenblicklich ohne zusätzlichen Aufwand seitens des Menschen.  Tatsächlich hat die bionische Hand ihre eigene Vision. <br><a name="habracut"></a><br>  Zuvor experimentierten Wissenschaftler mit Stereokameras und verschiedenen Objekterkennungsalgorithmen.  Parallel dazu wurden neue Modelle von Manipulatoren für Roboter entwickelt - dort sind Computer-Vision-Technologien bionischen Prothesen für Menschen sehr ähnlich.  Auf dem Gebiet der Robotik wurden die vielversprechendsten Technologien für Bildverarbeitung und tiefes Lernen getestet. <br><br>  Ingenieure der University of Newcastle nutzten diese Entwicklungen ihrer Vorgänger und richteten das Bildverarbeitungssystem darauf, die <i>Art der Erfassung</i> für Objekte verschiedener Typen zu erkennen, und nicht auf der Grundlage einer bestimmten Messung ihrer Größe.  Das heißt, Objekte nach dem Training des neuronalen Netzwerks werden genau nach der Art der Erfassung und nicht nach der Art oder Kategorie des Objekts klassifiziert.  Die Autoren glauben, dass sie aufgrund eines grundlegend neuen Ansatzes die Geschwindigkeit des Systems erheblich verbessern konnten, da unnötige Details ignoriert werden. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/b4e/190/170/b4e190170729127c1b8f924325161071.jpg"><br>  <font color="gray">Zum Vergleich: Klassifizierung nach Objektkategorie (oben) oder nach einem der vier Erfassungstypen (unten)</font> <br><br>  Ein Faltungs-Neuronales Netzwerk wurde verwendet, um das System zu trainieren.  Es stellte sich heraus, dass seine Architektur perfekt für diese Art von Aufgabe ist, nämlich für bionische Handprothesen.  Bei anderen Methoden der Bildverarbeitung traten beispielsweise Probleme auf, wenn sie auf Objekte stießen, die keiner der bekannten Kategorien angehörten.  Die Identifizierung unbekannter Objekte ist jedoch eine der wichtigsten Eigenschaften einer bionischen Prothese mit Bildverarbeitung.  Daher ist das Faltungs-Neuronale Netz für eine solche Aufgabe ideal geeignet. <br><br>  Das System wurde in der <a href="">Amsterdamer Bilddatenbank</a> trainiert, wo eine große Anzahl von Heimobjekten vorhanden ist. <br><br>  Die Architektur eines zweischichtigen Faltungs-Neuronalen Netzwerks zur Merkmalsextraktion und -klassifizierung ist in der folgenden Abbildung dargestellt. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/eb8/085/42e/eb808542e548fbc160f60375548edfd4.jpg"><br><br>  In Tests an realen Patienten mit Prothesen wurde das System an 8 bekannten und 16 unbekannten Objekten in zufälliger Position getestet.  Die Ergebnisse für die beiden Freiwilligen sind in den Grafiken links und rechts dargestellt.  Unter Berücksichtigung zulässiger Fehler betrug die Genauigkeit der Erkennung und Erfassung von Objekten für den ersten und den zweiten Freiwilligen 88% bzw. 87%. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/412/3d9/246/4123d924622c5a06283db2866c06f0c4.jpg"><br><br>  Am wichtigsten ist, dass eine solche bionische Prothese fast in Echtzeit funktioniert: Der Erfassungstyp wird in Millisekunden ausgewählt, im Gegensatz zu 0,75 bis 24 Sekunden bei bionischen Armen, bei denen die Bildverarbeitung die Klassifizierung von Objekten durch Machine Vision durchführt.  Selbst die besten bionischen Prothesen dieses Typs, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CyberHand</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SmartHand,</a> können die Erkennung in 4 bzw. 1 Sekunde verarbeiten.  Sie verwenden leistungsstarke Computer und weisen eine Erfassungsgenauigkeit von 93% bzw. 94% auf.  Obwohl die Genauigkeit dort etwas höher ist, ist die Erfassung in Echtzeit oder mit einer Pause von einer Sekunde ein großer Unterschied. Daher sollte die Leistung britischer biomedizinischer Ingenieure nicht unterschätzt werden.  Dies ist die erste bionische Hand, die Objekte „intuitiv“ wie ohne nachzudenken greifen kann.  Eine Person gibt nur mit einer kleinen Bewegung des Muskels ein Signal, dass das Objekt erfasst werden muss - und eine intelligente Hand mit einem neuronalen Netzwerk erledigt den Rest schnell selbstständig. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/rBZKrpf3Y4U" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Der wissenschaftliche Artikel wurde am 3. Mai 2017 in der Zeitschrift <i>Journal of Neural Engineering</i> (doi: 10.1088 / 1741-2552 / aa6802) veröffentlicht. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de403739/">https://habr.com/ru/post/de403739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de403729/index.html">ITER: Schaltgeräte</a></li>
<li><a href="../de403731/index.html">Was auf Zähne zu schmieren, damit sie nicht herausfallen</a></li>
<li><a href="../de403733/index.html">McDonald's und andere Unternehmen verwenden Ultraschall, um Benutzer zu verfolgen</a></li>
<li><a href="../de403735/index.html">Waffen der Helden. Maximieren Sie das Maschinengewehr unter Röntgen und Demontage des PPSh-41 an der Schraube</a></li>
<li><a href="../de403737/index.html">Luftqualitätsmonitor von Dadget. Kohlendioxidmessung</a></li>
<li><a href="../de403741/index.html">Sehen Sie das Unsichtbare: Schauen Sie in die Wärmebildkamera von Seek Thermal (und das aus einem bestimmten Grund).</a></li>
<li><a href="../de403743/index.html">Google AIY: Maker Kit für Sprachsteuerungs-Gadgets</a></li>
<li><a href="../de403745/index.html">RD-180 Ersatzwettbewerb: Leidenschaft</a></li>
<li><a href="../de403747/index.html">Der digitale Assistent von Amazon verwandelt sich in einen Assistenten des Wissenschaftslabors</a></li>
<li><a href="../de403749/index.html">Steuervorbereitung 1950: „Programmieren“ des IBM 403 mithilfe eines Plug-In-Panels</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
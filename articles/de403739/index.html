<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‰ ğŸ’¥ ğŸ¤  Es wird ein bionischer Arm mit einem neuronalen Netzwerk erstellt, der Objekte sofort erkennt und erfasst ğŸ˜¶ ğŸš” ğŸ¾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bionische Prothesen der letzten Generation werden Ã¼blicherweise mit Hilfe von myoelektrischen Signalen gesteuert, die durch Muskelkontraktionen der me...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Es wird ein bionischer Arm mit einem neuronalen Netzwerk erstellt, der Objekte sofort erkennt und erfasst</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/403739/"><img src="https://habrastorage.org/getpro/geektimes/post_images/17b/0b5/4a1/17b0b54a1c514ecd09a61b41fd826fc0.jpg"><br><br>  Bionische Prothesen der letzten Generation werden Ã¼blicherweise mit Hilfe von myoelektrischen Signalen gesteuert, die durch Muskelkontraktionen der menschlichen Hand entstehen.  Die Handhabung einer solchen Prothese ist nicht einfach: Sie erfordert eine gewisse Konzentration, und die Wirksamkeit erfolgreicher MaÃŸnahmen lÃ¤sst zu wÃ¼nschen Ã¼brig.  Es ist nicht einfach, beim ersten Mal das zu tun, was Sie wollen.  In Bezug auf die Genauigkeit von Handlungen sind solche Prothesen weit entfernt von den â€intuitivenâ€œ Handlungen einer lebenden echten Hand. <br><br>  In den letzten Jahren haben sich die Forscher hauptsÃ¤chlich auf die Genauigkeit der Erkennung myoelektrischer Signale konzentriert, und die Genauigkeit der Erkennung der Bewegungen einzelner Finger hat 90% erreicht.  Aus einer Reihe von technischen GrÃ¼nden ist der massive Einsatz solcher â€intelligentenâ€œ Prothesen jedoch sehr begrenzt.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Eine Neuentwicklung von</a> Ingenieuren der University of Newcastle (UK) bietet einen grundlegend anderen Ansatz.  Eine mit einer Videokamera ausgestattete Hand erkennt ein Objekt davor - und bestimmt, wie es am besten erfasst werden kann.  Es wirkt automatisch und fast augenblicklich ohne zusÃ¤tzlichen Aufwand seitens des Menschen.  TatsÃ¤chlich hat die bionische Hand ihre eigene Vision. <br><a name="habracut"></a><br>  Zuvor experimentierten Wissenschaftler mit Stereokameras und verschiedenen Objekterkennungsalgorithmen.  Parallel dazu wurden neue Modelle von Manipulatoren fÃ¼r Roboter entwickelt - dort sind Computer-Vision-Technologien bionischen Prothesen fÃ¼r Menschen sehr Ã¤hnlich.  Auf dem Gebiet der Robotik wurden die vielversprechendsten Technologien fÃ¼r Bildverarbeitung und tiefes Lernen getestet. <br><br>  Ingenieure der University of Newcastle nutzten diese Entwicklungen ihrer VorgÃ¤nger und richteten das Bildverarbeitungssystem darauf, die <i>Art der Erfassung</i> fÃ¼r Objekte verschiedener Typen zu erkennen, und nicht auf der Grundlage einer bestimmten Messung ihrer GrÃ¶ÃŸe.  Das heiÃŸt, Objekte nach dem Training des neuronalen Netzwerks werden genau nach der Art der Erfassung und nicht nach der Art oder Kategorie des Objekts klassifiziert.  Die Autoren glauben, dass sie aufgrund eines grundlegend neuen Ansatzes die Geschwindigkeit des Systems erheblich verbessern konnten, da unnÃ¶tige Details ignoriert werden. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/b4e/190/170/b4e190170729127c1b8f924325161071.jpg"><br>  <font color="gray">Zum Vergleich: Klassifizierung nach Objektkategorie (oben) oder nach einem der vier Erfassungstypen (unten)</font> <br><br>  Ein Faltungs-Neuronales Netzwerk wurde verwendet, um das System zu trainieren.  Es stellte sich heraus, dass seine Architektur perfekt fÃ¼r diese Art von Aufgabe ist, nÃ¤mlich fÃ¼r bionische Handprothesen.  Bei anderen Methoden der Bildverarbeitung traten beispielsweise Probleme auf, wenn sie auf Objekte stieÃŸen, die keiner der bekannten Kategorien angehÃ¶rten.  Die Identifizierung unbekannter Objekte ist jedoch eine der wichtigsten Eigenschaften einer bionischen Prothese mit Bildverarbeitung.  Daher ist das Faltungs-Neuronale Netz fÃ¼r eine solche Aufgabe ideal geeignet. <br><br>  Das System wurde in der <a href="">Amsterdamer Bilddatenbank</a> trainiert, wo eine groÃŸe Anzahl von Heimobjekten vorhanden ist. <br><br>  Die Architektur eines zweischichtigen Faltungs-Neuronalen Netzwerks zur Merkmalsextraktion und -klassifizierung ist in der folgenden Abbildung dargestellt. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/eb8/085/42e/eb808542e548fbc160f60375548edfd4.jpg"><br><br>  In Tests an realen Patienten mit Prothesen wurde das System an 8 bekannten und 16 unbekannten Objekten in zufÃ¤lliger Position getestet.  Die Ergebnisse fÃ¼r die beiden Freiwilligen sind in den Grafiken links und rechts dargestellt.  Unter BerÃ¼cksichtigung zulÃ¤ssiger Fehler betrug die Genauigkeit der Erkennung und Erfassung von Objekten fÃ¼r den ersten und den zweiten Freiwilligen 88% bzw. 87%. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/412/3d9/246/4123d924622c5a06283db2866c06f0c4.jpg"><br><br>  Am wichtigsten ist, dass eine solche bionische Prothese fast in Echtzeit funktioniert: Der Erfassungstyp wird in Millisekunden ausgewÃ¤hlt, im Gegensatz zu 0,75 bis 24 Sekunden bei bionischen Armen, bei denen die Bildverarbeitung die Klassifizierung von Objekten durch Machine Vision durchfÃ¼hrt.  Selbst die besten bionischen Prothesen dieses Typs, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CyberHand</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SmartHand,</a> kÃ¶nnen die Erkennung in 4 bzw. 1 Sekunde verarbeiten.  Sie verwenden leistungsstarke Computer und weisen eine Erfassungsgenauigkeit von 93% bzw. 94% auf.  Obwohl die Genauigkeit dort etwas hÃ¶her ist, ist die Erfassung in Echtzeit oder mit einer Pause von einer Sekunde ein groÃŸer Unterschied. Daher sollte die Leistung britischer biomedizinischer Ingenieure nicht unterschÃ¤tzt werden.  Dies ist die erste bionische Hand, die Objekte â€intuitivâ€œ wie ohne nachzudenken greifen kann.  Eine Person gibt nur mit einer kleinen Bewegung des Muskels ein Signal, dass das Objekt erfasst werden muss - und eine intelligente Hand mit einem neuronalen Netzwerk erledigt den Rest schnell selbststÃ¤ndig. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/rBZKrpf3Y4U" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Der wissenschaftliche Artikel wurde am 3. Mai 2017 in der Zeitschrift <i>Journal of Neural Engineering</i> (doi: 10.1088 / 1741-2552 / aa6802) verÃ¶ffentlicht. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de403739/">https://habr.com/ru/post/de403739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de403729/index.html">ITER: SchaltgerÃ¤te</a></li>
<li><a href="../de403731/index.html">Was auf ZÃ¤hne zu schmieren, damit sie nicht herausfallen</a></li>
<li><a href="../de403733/index.html">McDonald's und andere Unternehmen verwenden Ultraschall, um Benutzer zu verfolgen</a></li>
<li><a href="../de403735/index.html">Waffen der Helden. Maximieren Sie das Maschinengewehr unter RÃ¶ntgen und Demontage des PPSh-41 an der Schraube</a></li>
<li><a href="../de403737/index.html">LuftqualitÃ¤tsmonitor von Dadget. Kohlendioxidmessung</a></li>
<li><a href="../de403741/index.html">Sehen Sie das Unsichtbare: Schauen Sie in die WÃ¤rmebildkamera von Seek Thermal (und das aus einem bestimmten Grund).</a></li>
<li><a href="../de403743/index.html">Google AIY: Maker Kit fÃ¼r Sprachsteuerungs-Gadgets</a></li>
<li><a href="../de403745/index.html">RD-180 Ersatzwettbewerb: Leidenschaft</a></li>
<li><a href="../de403747/index.html">Der digitale Assistent von Amazon verwandelt sich in einen Assistenten des Wissenschaftslabors</a></li>
<li><a href="../de403749/index.html">Steuervorbereitung 1950: â€Programmierenâ€œ des IBM 403 mithilfe eines Plug-In-Panels</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
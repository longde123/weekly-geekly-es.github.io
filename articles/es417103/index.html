<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéè üë©üèª‚Äç‚öïÔ∏è üôåüèª Spark SQL. Un poco sobre el optimizador de consultas üë¥üèº üë®üèΩ‚Äçü§ù‚Äçüë®üèª üîº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos Como introducci√≥n, quiero contarles c√≥mo llegu√© a tal vida. 



 Antes de reunirme con Big Data y Spark, en particular, ten√≠a muchas y mu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark SQL. Un poco sobre el optimizador de consultas</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neoflex/blog/417103/"><p>  Hola a todos  Como introducci√≥n, quiero contarles c√≥mo llegu√© a tal vida. <br></p><br><p>  Antes de reunirme con Big Data y Spark, en particular, ten√≠a muchas y muchas veces para optimizar las consultas SQL, primero para MSSQL, luego para Oracle, y ahora me encontr√© con SparkSQL. <br></p><br><p>  Y si ya hay muchos libros buenos para el DBMS que describen la metodolog√≠a y los "bol√≠grafos" que puede girar para obtener el plan de consulta √≥ptimo, entonces no he visto esos libros para Spark.  Encontr√© m√°s art√≠culos y conjuntos de pr√°cticas, m√°s relacionados con el trabajo a trav√©s de la API RDD / Dataset, en lugar de SQL puro.  Para m√≠, uno de los libros de referencia sobre optimizaci√≥n de SQL es el libro de J. Lewis, Oracle.  Conceptos b√°sicos de optimizaci√≥n de costos ".  Busqu√© algo similar en profundidad de estudio.  ¬øPor qu√© fue objeto de investigaci√≥n espec√≠ficamente SparkSQL, y no la API subyacente?  Luego, el inter√©s fue causado por las caracter√≠sticas del proyecto en el que estoy trabajando. <br></p><br><img src="https://habrastorage.org/webt/po/1f/un/po1fun6vgbktou6lykepwmrncci.jpeg"><br><a name="habracut"></a><br><p>  Para uno de nuestros clientes, nuestra empresa est√° desarrollando un almac√©n de datos, cuya capa detallada y parte de las vitrinas est√°n en el cl√∫ster de Hadoop, y las vitrinas finales est√°n en Oracle.  Este proyecto involucra una extensa capa de conversi√≥n de datos, que se implementa en Spark.  Para acelerar el desarrollo y la conectividad de los desarrolladores de ETL que no est√°n familiarizados con las complejidades de las tecnolog√≠as de Big Data, pero est√°n familiarizados con las herramientas SQL y ETL, se ha desarrollado una herramienta que recuerda ideol√≥gicamente a otras herramientas ETL, por ejemplo, Informatica, y le permite dise√±ar visualmente procesos ETL con la generaci√≥n posterior c√≥digo para Spark.  Debido a la complejidad de los algoritmos y la gran cantidad de transformaciones, los desarrolladores utilizan principalmente consultas SparkSQL. <br></p><br><p> Aqu√≠ es donde comienza la historia, ya que tuve que responder una gran cantidad de preguntas de la forma "¬øPor qu√© la consulta no funciona / funciona lentamente / no funciona como en Oracle?".  Esta result√≥ ser la parte m√°s interesante para m√≠: "¬øPor qu√© funciona lentamente?".  Adem√°s, a diferencia del DBMS con el que trabaj√© antes, puede ingresar al c√≥digo fuente y obtener la respuesta a sus preguntas. <br></p><cut text="    "></cut><br><h2>  Limitaciones y Suposiciones </h2><br><p>  Spark 2.3.0 se utiliza para ejecutar ejemplos y analizar el c√≥digo fuente. <br>  Se supone que el lector est√° familiarizado con la arquitectura Spark y los principios generales del optimizador de consultas para uno de los DBMS.  Como m√≠nimo, la frase "plan de consulta" ciertamente no deber√≠a ser sorprendente. <br></p><br><p>  Adem√°s, este art√≠culo intenta no convertirse en una traducci√≥n del c√≥digo del optimizador de Spark al ruso, por lo que para cosas que son muy interesantes desde el punto de vista del optimizador, pero que pueden leerse en el c√≥digo fuente, simplemente se mencionar√°n brevemente aqu√≠ con enlaces a las clases correspondientes. <br></p><br><h2>  Pasar a estudiar </h2><br><p>  Comencemos con una peque√±a consulta para explorar las etapas b√°sicas a trav√©s de las cuales se pasa del an√°lisis a la ejecuci√≥n. <br></p><br><pre><code class="scala hljs">scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/balance"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"bal"</span></span>) scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/customer"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"cust"</span></span>) scala&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> df = spark.sql(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">" | select bal.account_rk, cust.full_name | from bal | join cust | on bal.party_rk = cust.party_rk | and bal.actual_date = cust.actual_date | where bal.actual_date = cast('2017-12-31' as date) | "</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>) df: org.apache.spark.sql.<span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = [account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: string] scala&gt; df.explain(<span class="hljs-literal"><span class="hljs-literal">true</span></span>)</code> </pre> <br><p>  El m√≥dulo principal responsable de analizar SQL y optimizar el plan de ejecuci√≥n de consultas es Spark Catalyst. <br></p><br><p>  El resultado ampliado en la descripci√≥n del plan de solicitud (df.explain (true)) le permite realizar un seguimiento de todas las etapas por las que pasa la solicitud: <br></p><br><ul><li>  Plan l√≥gico analizado: obtenga despu√©s de analizar SQL.  En esta etapa, solo se verifica la correcci√≥n sint√°ctica de la solicitud. </li></ul><br><pre> <code class="hljs rust">== Parsed Logical Plan == <span class="hljs-symbol"><span class="hljs-symbol">'Project</span></span> [<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.account_rk, <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.full_name] +- <span class="hljs-symbol"><span class="hljs-symbol">'Filter</span></span> (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- <span class="hljs-symbol"><span class="hljs-symbol">'Join</span></span> Inner, ((<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.party_rk = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.party_rk) &amp;&amp; (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.actual_date)) :- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `bal` +- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `cust`</code> </pre><br><ul><li>  Plan l√≥gico analizado: en esta etapa, se agrega informaci√≥n sobre la estructura de las entidades utilizadas, se verifica la correspondencia de la estructura y los atributos solicitados. </li></ul><br><pre> <code class="hljs delphi">== Analyzed Logical Plan == account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Filter (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- SubqueryAlias bal : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- SubqueryAlias cust +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  El plan l√≥gico optimizado es el m√°s interesante para nosotros.  En esta etapa, el √°rbol de consulta resultante se convierte en funci√≥n de las reglas de optimizaci√≥n disponibles. </li></ul><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Plan f√≠sico: las caracter√≠sticas de acceso a los datos de origen comienzan a tenerse en cuenta, incluidas las optimizaciones para filtrar particiones y datos para minimizar el conjunto de datos resultante.  Se selecciona la estrategia de ejecuci√≥n de combinaci√≥n (para obtener m√°s detalles sobre las opciones disponibles, consulte a continuaci√≥n). </li></ul><br><pre> <code class="hljs pgsql">== Physical Plan == *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [account_rk#<span class="hljs-number"><span class="hljs-number">1</span></span>, full_name#<span class="hljs-number"><span class="hljs-number">59</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) BroadcastHashJoin [party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">27</span></span>], [party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">88</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">Inner</span></span>, BuildRight :- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>, PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>) : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) FileScan orc [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>,PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/balance], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;ACCOUNT_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>)&gt; +- BroadcastExchange HashedRelationBroadcastMode(List(<span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>])) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) Project [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>, FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) FileScan orc [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>,FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/customer], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),FULL_NAME:string&gt;</code> </pre><br><p>  Las siguientes etapas de optimizaci√≥n y ejecuci√≥n (por ejemplo, WholeStageCodegen) est√°n m√°s all√° del alcance de este art√≠culo, pero se describen con gran detalle (as√≠ como las etapas descritas anteriormente) en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mastering Spark Sql</a> . <br></p><br><p>  La lectura del plan de ejecuci√≥n de consultas generalmente ocurre "desde adentro" y "de abajo hacia arriba", es decir, las partes m√°s anidadas se ejecutan primero y avanzan gradualmente hasta la proyecci√≥n final ubicada en la parte superior. <br></p><br><h2>  Tipos de optimizadores de consultas </h2><br><p>  Se pueden distinguir dos tipos de optimizadores de consultas: </p><br><ul><li>  Optimizadores basados ‚Äã‚Äãen reglas (RBO). </li><li>  Optimizadores basados ‚Äã‚Äãen una estimaci√≥n del costo de ejecuci√≥n de la consulta (Optimizador basado en costos, CBO). </li></ul><br><p>  Los primeros se centran en el uso de un conjunto de reglas fijas, por ejemplo, la aplicaci√≥n de condiciones de filtrado desde donde en etapas anteriores, si es posible, el c√°lculo de constantes, etc. <br></p><br><p>  Para evaluar la calidad del plan resultante, el optimizador CBO utiliza una funci√≥n de costo, que generalmente depende de la cantidad de datos procesados, el n√∫mero de filas que caen bajo los filtros y el costo de realizar ciertas operaciones. <br></p><br><p>  Para obtener m√°s informaci√≥n sobre la especificaci√≥n de dise√±o CBO para Apache Spark, siga los enlaces: la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">especificaci√≥n</a> y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tarea principal de JIRA para la implementaci√≥n</a> . <br></p><br><p>  El punto de partida para explorar la gama completa de optimizaciones existentes es el c√≥digo Optimizer.scala. <br></p><br><p>  Aqu√≠ hay un breve extracto de una larga lista de optimizaciones disponibles: <br></p><br><pre> <code class="hljs perl">def batches: Se<span class="hljs-string"><span class="hljs-string">q[Batch]</span></span> = { val operatorOptimizationRuleSet = Se<span class="hljs-string"><span class="hljs-string">q( // Operator push down PushProjectionThroughUnion, ReorderJoin, EliminateOuterJoin, PushPredicateThroughJoin, PushDownPredicate, LimitPushDown, ColumnPruning, InferFiltersFromConstraints, // Operator combine CollapseRepartition, CollapseProject, CollapseWindow, CombineFilters, CombineLimits, CombineUnions, // Constant folding and strength reduction NullPropagation, ConstantPropagation, ........</span></span></code> </pre><br><p>  Cabe se√±alar que la lista de estas optimizaciones incluye tanto optimizaciones basadas en reglas como optimizaciones basadas en estimaciones de costos de consulta, que se discutir√°n a continuaci√≥n. <br></p><br><p>  Una caracter√≠stica de CBO es que para un funcionamiento correcto necesita conocer y almacenar informaci√≥n sobre las estad√≠sticas de los datos utilizados en la consulta: la cantidad de registros, el tama√±o de registro, los histogramas de distribuci√≥n de datos en las columnas de la tabla. <br></p><br><p>  Para recopilar estad√≠sticas, se usa un conjunto de comandos SQL ANALYZE TABLE ... COMPUTE STATISTICS, adem√°s, se necesita un conjunto de tablas para almacenar informaci√≥n, la API se proporciona a trav√©s de ExternalCatalog, m√°s precisamente a trav√©s de HiveExternalCatalog. <br></p><br><p>  Dado que CBO est√° actualmente deshabilitado de manera predeterminada, el √©nfasis principal se pondr√° en investigar la optimizaci√≥n y los matices disponibles de RBO. <br></p><br><h2>  Tipos y elecci√≥n de estrategia de uni√≥n </h2><br><p>  En la etapa de formaci√≥n del plan f√≠sico para ejecutar la solicitud, se selecciona la estrategia de uni√≥n.  Las siguientes opciones est√°n actualmente disponibles en Spark (puede comenzar a aprender el c√≥digo del c√≥digo en SparkStrategies.scala). <br></p><br><h3>  Difundir hash join </h3><br><p>  La mejor opci√≥n es si una de las partes de la uni√≥n es lo suficientemente peque√±a (el criterio de suficiencia se establece mediante el par√°metro spark.sql.autoBroadcastJoinThreshold en SQLConf).  En este caso, este lado se copia completamente a todos los ejecutores, donde hay una uni√≥n hash con la tabla principal.  Adem√°s del tama√±o, debe tenerse en cuenta que en el caso de la uni√≥n externa, solo se puede copiar el lado externo, por lo tanto, si es posible, como la tabla principal en el caso de la uni√≥n externa, debe usar la tabla con la mayor cantidad de datos. <br></p><br><pre> <code class="hljs pgsql">  ,    ,     <span class="hljs-keyword"><span class="hljs-keyword">SQL</span></span>      Oracle,   <span class="hljs-comment"><span class="hljs-comment">/*+ broadcast(t1, t2) */</span></span></code> </pre><br><h3>  Ordenar fusionar unirse </h3><br><p>  Con <em>spark.sql.join.preferSortMergeJoin</em> activado de forma predeterminada, este m√©todo se aplica de forma predeterminada si se pueden ordenar las claves para la uni√≥n. <br>  De las caracter√≠sticas, se puede observar que, a diferencia del m√©todo anterior, la optimizaci√≥n de generaci√≥n de c√≥digo para realizar la operaci√≥n solo est√° disponible para la uni√≥n interna. <br></p><br><h3>  Reproducci√≥n aleatoria de hash </h3><br><p>  Si las claves no se pueden ordenar, o la opci√≥n de selecci√≥n de combinaci√≥n de combinaci√≥n de clasificaci√≥n predeterminada est√° deshabilitada, Catalyst intenta aplicar una combinaci√≥n aleatoria aleatoria.  Adem√°s de verificar la configuraci√≥n, tambi√©n se verifica que Spark tenga suficiente memoria para construir un mapa de hash local para una partici√≥n (el n√∫mero total de particiones se establece configurando <em>spark.sql.shuffle.partitions</em> ) </p><br><h3>  BroadcastNestedLoopJoin y CartesianProduct </h3><br><p>  En el caso donde no hay posibilidad de comparaci√≥n directa por clave (por ejemplo, una condici√≥n como) o no hay claves para unir tablas, dependiendo del tama√±o de las tablas, se selecciona este tipo o CartesianProduct. <br></p><br><h3>  El orden de especificar tablas en join'ah </h3><br><p>  En cualquier caso, unirse requiere barajar tablas por clave.  Por lo tanto, en este momento, el orden de especificar tablas, especialmente en el caso de realizar varias uniones en una fila, es importante (si usted es un aburrido, entonces si CBO no est√° activado y la configuraci√≥n JOIN_REORDER_ENABLED no est√° activada). <br></p><br><p>  Si es posible, el orden de unir tablas debe minimizar el n√∫mero de operaciones de barajado para tablas grandes, para lo cual las uniones en la misma clave deben ir secuencialmente.  Adem√°s, no olvide minimizar los datos para unirse, para habilitar Broadcast Hash Join. <br></p><br><h2>  Aplicaci√≥n transitiva de las condiciones del filtro. </h2><br><p>  Considere la siguiente consulta: <br></p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> bal.account_rk, cust.full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> balance bal <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> customer cust <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> bal.party_rk = cust.party_rk <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> bal.actual_date = cust.actual_date <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> bal.actual_date = <span class="hljs-keyword"><span class="hljs-keyword">cast</span></span>(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-built_in"><span class="hljs-built_in">date</span></span>)</code> </pre><br><p>  Aqu√≠ conectamos dos tablas que se particionan de la misma manera, de acuerdo con el campo actual_date y aplicamos un filtro expl√≠cito solo a la partici√≥n de acuerdo con la tabla de equilibrio. <br></p><br><p>  Como se puede ver en el plan de consulta optimizado, el filtro por fecha tambi√©n se aplica al cliente, y al momento de leer los datos del disco se determina que se necesita exactamente una partici√≥n. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter (((actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>) &amp;&amp; isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><p>  Pero solo necesita reemplazar la uni√≥n interna con la izquierda externa en la consulta, ya que el predicado de inserci√≥n para la tabla del cliente se cae inmediatamente y se produce un escaneo completo, lo cual es un efecto indeseable. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join LeftOuter, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter (isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><h2>  Conversi√≥n de tipo </h2><br><p>  Considere un ejemplo simple de selecci√≥n de una tabla con filtrado por tipo de cliente, en el esquema, el tipo del campo party_type es string. <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> party_rk, full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> cust <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> actual_date = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> party_type = <span class="hljs-number"><span class="hljs-number">101</span></span> <span class="hljs-comment"><span class="hljs-comment">--   -- and party_type = '101' --    </span></span></code> </pre><br><p>  Y compare los dos planes resultantes, el primero, cuando nos referimos al tipo incorrecto (habr√° una conversi√≥n impl√≠cita a int), el segundo, cuando el tipo corresponde al esquema. <br></p><br><pre> <code class="hljs powershell">PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>)] //            . PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>), <span class="hljs-type"><span class="hljs-type">EqualTo</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>,<span class="hljs-number"><span class="hljs-number">101</span></span>)] //             .</code> </pre><br><p>  Se observa un problema similar para el caso de comparar fechas con una cadena, habr√° un filtro para comparar cadenas.  Un ejemplo: <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = <span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> (isnotnull(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span>) &amp;&amp; (cast(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> string) = <span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>) PushedFilters: [IsNotNull(OPER_DATE)] <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) PushedFilters: [IsNotNull(OPER_DATE), EqualTo(OPER_DATE,<span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>)]</code> </pre><br><p>  Para el caso en que es posible una conversi√≥n de tipo impl√≠cita, por ejemplo, int -&gt; decimal, el optimizador lo hace por s√≠ solo. <br></p><br><h2>  M√°s investigaci√≥n </h2><br><p>  Se puede obtener mucha informaci√≥n interesante sobre los "mandos" que se pueden utilizar para ajustar Catalyst, as√≠ como sobre las posibilidades (presentes y futuras) del optimizador de SQLConf.scala. <br></p><br><p>  En particular, como puede ver por defecto, el optimizador de costos todav√≠a est√° apagado en este momento. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">CBO_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables CBO for estimation of plan statistics when set true."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  Adem√°s de sus optimizaciones dependientes asociadas con la reordenaci√≥n de join'ov. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">JOIN_REORDER_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.joinReorder.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables join reorder in CBO."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  o </p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">STARSCHEMA_DETECTION</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.starSchemaDetection"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"When true, it enables join reordering based on star schema detection. "</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><h2>  Resumen breve </h2><br><p>  Solo se ha tocado una peque√±a parte de las optimizaciones existentes, los experimentos con la optimizaci√≥n de costos, que pueden dar mucho m√°s espacio para la conversi√≥n de consultas, est√°n por venir.  Adem√°s, otra pregunta interesante es la comparaci√≥n de un conjunto de optimizaciones al leer archivos de Parquet y Orc, a juzgar por la jira del proyecto, se trata de paridad, pero ¬øes realmente as√≠? <br></p><br><p>  Adem√°s </p><br><ul><li>  El an√°lisis y la optimizaci√≥n de solicitudes es interesante y emocionante, especialmente teniendo en cuenta la disponibilidad de c√≥digos fuente. </li><li>  La inclusi√≥n de CBO proporcionar√° margen para futuras optimizaciones e investigaciones. </li><li>  Es necesario controlar la aplicabilidad de las reglas b√°sicas que le permiten filtrar la mayor cantidad posible de datos "adicionales" en las primeras etapas posibles. </li><li>  Unirse es un mal necesario, pero si es posible, vale la pena minimizarlos y realizar un seguimiento de qu√© implementaci√≥n se utiliza bajo el cap√≥. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417103/">https://habr.com/ru/post/es417103/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417091/index.html">Crea un sombreador de agua de dibujos animados para la web. Parte 3</a></li>
<li><a href="../es417093/index.html">Interruptores t√°ctiles con Modbus: por qu√© son necesarios y c√≥mo aplicarlos en un apartamento inteligente</a></li>
<li><a href="../es417097/index.html">Metaprogramaci√≥n de JavaScript</a></li>
<li><a href="../es417099/index.html">¬øC√≥mo escrib√≠ la biblioteca est√°ndar de C ++ 11 o por qu√© boost es tan aterrador? Cap√≠tulo 2</a></li>
<li><a href="../es417101/index.html">Definici√≥n de Listo: lo que olvidamos contar</a></li>
<li><a href="../es417105/index.html">Impresi√≥n en una impresora 3D. Experiencias secretas de 3Dtool</a></li>
<li><a href="../es417107/index.html">Creador del juego mientras es verdadero: aprenda () sobre la programaci√≥n de gamedev, los problemas de realidad virtual y las simulaciones de ML</a></li>
<li><a href="../es417109/index.html">Richard Hamming: Cap√≠tulo 10. Teor√≠a de la codificaci√≥n - I</a></li>
<li><a href="../es417111/index.html">Conferencias en l√≠nea: transmisi√≥n vs seminario web</a></li>
<li><a href="../es417113/index.html">Impresora italiana 3D en Rusia: Raise3D N1 Dual - modelado y creaci√≥n de prototipos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
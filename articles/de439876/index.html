<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöà üì† üõéÔ∏è Wie wir die Inkompatibilit√§t bei der Migration von Daten von Greenplum 4 nach Greenplum 5 √ºberwinden üì¶ üë©üèæ‚Äçü§ù‚Äçüë©üèª üõèÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bei der Auswahl eines Tools zur Verarbeitung von Big Data haben wir verschiedene Optionen in Betracht gezogen - sowohl propriet√§re als auch Open Sourc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir die Inkompatibilit√§t bei der Migration von Daten von Greenplum 4 nach Greenplum 5 √ºberwinden</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/439876/">  Bei der Auswahl eines Tools zur Verarbeitung von Big Data haben wir verschiedene Optionen in Betracht gezogen - sowohl propriet√§re als auch Open Source-Optionen.  Wir haben die M√∂glichkeiten einer schnellen Anpassung, Zug√§nglichkeit und Flexibilit√§t von Technologien bewertet.  Einschlie√ülich Migration zwischen Versionen.  Aus diesem Grund haben wir uns f√ºr die Open-Source-Greenplum-L√∂sung entschieden, die unsere Anforderungen am besten erf√ºllt, jedoch die L√∂sung eines wichtigen Problems erfordert. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ff/69c/0d9/9ff69c0d9031f0afb897244dd0778e9e.png"><br><br>  Tatsache ist, dass die Greenplum-Datenbankdateien der Versionen 4 und 5 nicht miteinander kompatibel sind und daher ein einfaches Upgrade von einer Version auf eine andere nicht m√∂glich ist.  Die Datenmigration kann nur durch Hoch- und Herunterladen von Daten erfolgen.  In diesem Beitrag werde ich √ºber die m√∂glichen Optionen f√ºr diese Migration sprechen. <br><a name="habracut"></a><br><h2>  Migrationsoptionen bewerten </h2><br><h3>  pg_dump &amp; psql (oder pg_restore) </h3><br>  Dies ist zu langsam, wenn es um Dutzende von Terabyte geht, da alle Daten √ºber die Masterknoten hochgeladen und heruntergeladen werden.  Aber schnell genug, um DDL und kleine Tabellen zu migrieren.  Sie k√∂nnen beide in eine Datei hochladen und pg_dump und psql gleichzeitig √ºber eine Pipe in einem Quellcluster und einem Zielcluster ausf√ºhren.  pg_dump l√§dt einfach in eine einzelne Datei hoch, die sowohl DDL-Befehle als auch COPY-Datenbefehle enth√§lt.  Die erhaltenen Daten k√∂nnen bequem verarbeitet werden, was unten gezeigt wird. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/482/f47/cd8/482f47cd86df49125689c5360b6d060e.png"><br><br><h3>  gptransfer </h3><br>  Ben√∂tigt Version Greenplum 4.2 oder h√∂her.  Es ist erforderlich, dass sowohl der Quellcluster als auch der Zielcluster gleichzeitig arbeiten.  Der schnellste Weg, um gro√üe Datentabellen f√ºr die Open Source-Version zu migrieren.  Diese Methode ist jedoch aufgrund des hohen Overheads sehr langsam f√ºr die √úbertragung leerer und kleiner Tabellen. <br><br>  gptransfer verwendet pg_dump zum √úbertragen von DDL und gpfdist zum √úbertragen von Daten.  Die Anzahl der prim√§ren Segmente im Zielcluster darf nicht geringer sein als das Hostsegment im Quellcluster.  Dies ist wichtig, wenn Sie Sandbox-Cluster erstellen, wenn Daten von den Hauptclustern an diese √ºbertragen werden und die Verwendung des Dienstprogramms gptransfer geplant ist.  Selbst wenn es nur wenige Segmenthosts gibt, k√∂nnen Sie die erforderliche Anzahl von Segmenten auf jedem von ihnen bereitstellen.  Die Anzahl der Segmente im Zielcluster ist m√∂glicherweise geringer als im Quellcluster. Dies <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wirkt sich</a> jedoch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nachteilig auf</a> die Daten√ºbertragungsgeschwindigkeit aus.  Zwischen den Clustern muss die SSH-Authentifizierung f√ºr Zertifikate konfiguriert werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/84b/a0a/f53/84ba0af53e82d2a4e861fe19c6f9be9a.png"><br><br>  Dies ist das Schema f√ºr den Schnellmodus, wenn die Anzahl der Segmente im Zielcluster gr√∂√üer oder gleich der Anzahl im Quellcluster ist.  Der Start des Dienstprogramms selbst ist in der Abbildung auf dem Hauptknoten des Empf√§ngerclusters dargestellt.  In diesem Modus wird im Quellcluster eine externe Schreibtabelle erstellt, die Daten zu jedem Segment in die Named Pipe schreibt.  Der Befehl INSERT INTO writable_external_table SELECT * FROM source_table wird ausgef√ºhrt.  Daten aus der Named Pipe werden von gpfdist gelesen.  Im Zielcluster wird auch eine externe Tabelle nur zum Lesen erstellt.  Die Tabelle gibt die Daten an, die gpfdist √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das gleichnamige Protokoll</a> bereitstellt.  Der Befehl INSERT INTO target_table SELECT * FROM external_gpfdist_table wird ausgef√ºhrt.  Die Daten werden automatisch zwischen den Segmenten des Zielclusters neu verteilt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/13f/b61/cfb/13fb61cfba946fbea0649c1df1cbf28c.png"><br><br>  Und dies ist das Schema f√ºr den langsamen Modus oder, wie gptransfer selbst herausgibt, den Standardmodus.  Der Hauptunterschied besteht darin, dass auf jedem Segmenthost des Quellclusters ein gpfdist-Paar f√ºr alle Segmente dieses Segmenthosts gestartet wird.  Eine externe Datensatztabelle bezieht sich auf gpfdist, der als Datenempf√§nger fungiert.  Wenn im Parameter LOCATION der externen Tabelle mehrere Werte zum Schreiben angegeben sind, werden die Segmente beim Schreiben von Daten von gpfdist gleichm√§√üig verteilt.  Daten zwischen gpfdist auf dem Hostsegment werden √ºber Named Pipe √ºbertragen.  Aus diesem Grund ist die Daten√ºbertragungsgeschwindigkeit geringer, sie ist jedoch immer noch schneller als bei der Daten√ºbertragung nur √ºber den Masterknoten. <br><br>  Bei der Migration von Daten von Greenplum 4 nach Greenplum 5 muss gptransfer auf dem Masterknoten des Zielclusters ausgef√ºhrt werden.  Wenn wir gptransfer auf dem Quellcluster ausf√ºhren, wird der Fehler <code>san_mounts</code> Feld <code>san_mounts</code> in der Tabelle <code>pg_catalog.gp_segment_configuration</code> : <br><br><pre> <code class="plaintext hljs">gptransfer -t big_db.public.test_table --dest-host=gpdb-target-master.local --dest-database=big_db --source-map-file=/data/master/gpseg-1/host_and_IP_segments --batch-size=10 --sub-batch-size=50 --truncate 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Starting gptransfer with args: -t big_db.public.test_table --dest-host=gpdb-target-master.local --dest-database=big_db --source-map-file=/data/master/gpseg-1/host_and_IP_segments --batch-size=10 --sub-batch-size=50 --truncate 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Validating options... 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Retrieving configuration of source Greenplum Database... 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Retrieving configuration of destination Greenplum Database... 20190109:12:46:14:010893 gptransfer:gpdb-source-master.local:gpadmin-[CRITICAL]:-gptransfer failed. (Reason='error 'ERROR: column "san_mounts" does not exist LINE 2: ... SELECT dbid, content, status, unnest(san_mounts... ^ ' in ' SELECT dbid, content, status, unnest(san_mounts) FROM pg_catalog.gp_segment_configuration WHERE content &gt;= 0 ORDER BY content, dbid '') exiting...</code> </pre> <br>  Sie m√ºssen auch die GPHOME-Variablen √ºberpr√ºfen, damit sie zwischen dem Quellcluster und dem Zielcluster √ºbereinstimmen.  Andernfalls wird ein ziemlich seltsamer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fehler</a> angezeigt (das Dienstprogramm gptransfer schl√§gt fehl, wenn Quelle und Ziel unterschiedliche GPHOME-Pfade haben). <br><br><pre> <code class="plaintext hljs">gptransfer -t big_db.public.test_table --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments --b atch-size=10 --sub-batch-size=50 --truncate 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[INFO]:-Starting gptransfer with args: -t big_db.public.test_table --source-host=gpdb-spurce-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments --b atch-size=10 --sub-batch-size=50 --truncate 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[INFO]:-Validating options... 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[ERROR]:-gptransfer: error: GPHOME directory does not exist on gpdb-source-master.local</code> </pre> <br>  Sie k√∂nnen einfach den entsprechenden Symlink erstellen und die GPHOME-Variable in der Sitzung √ºberschreiben, in der gptransfer gestartet wird. <br><br>  Wenn gptransfer auf dem Zielcluster gestartet wird, sollte die Option "--source-map-file" auf eine Datei verweisen, die eine Liste von Hosts und deren IP-Adressen mit prim√§ren Segmenten des Quellclusters enth√§lt.  Zum Beispiel: <br><br><pre> <code class="plaintext hljs">sdw1,192.0.2.1 sdw2,192.0.2.2 sdw3,192.0.2.3 sdw4,192.0.2.4</code> </pre> <br>  Mit der Option "--full" k√∂nnen nicht nur Tabellen, sondern die gesamte Datenbank √ºbertragen werden. Benutzerdatenbanken sollten jedoch nicht im Zielcluster erstellt werden.  Beachten Sie auch, dass beim Verschieben externer Tabellen Probleme aufgrund von Syntax√§nderungen auftreten. <br><br>  Lassen Sie uns den zus√§tzlichen Overhead bewerten, indem wir beispielsweise 10 leere Tabellen (Tabellen von big_db.public.test_table_2 nach big_db.public.test_table_11) mit gptarnsfer kopieren: <br><br><pre> <code class="plaintext hljs">gptransfer -f temp_filelist.txt --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments_dev --batch-size=10 --sub-ba tch-size=50 --truncate 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Starting gptransfer with args: -f temp_filelist.txt --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments_dev --batch-size=10 --sub-batch-size=50 --truncate 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating options... 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving configuration of source Greenplum Database... 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving configuration of destination Greenplum Database... 20190118:06:14:09:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving source tables... 20190118:06:14:12:031521 gptransfer:mdw:gpadmin-[INFO]:-Checking for gptransfer schemas... 20190118:06:14:22:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving list of destination tables... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Reading source host map file... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Building list of source tables to transfer... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Number of tables to transfer: 10 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-gptransfer will use "standard" mode for transfer. 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating source host map... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating transfer table set... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-The following tables on the destination system will be truncated: 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_2 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_3 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_4 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_5 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_6 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_7 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_8 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_9 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_10 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_11 ‚Ä¶ 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Using batch size of 10 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Using sub-batch size of 16 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Creating work directory '/home/gpadmin/gptransfer_31521' 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Creating schema public in database edw_prod... 20190118:06:14:40:031521 gptransfer:mdw:gpadmin-[INFO]:-Starting transfer of big_db.public.test_table_5 to big_db.public.test_table_5... ‚Ä¶ 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Validation of big_db.public.test_table_4 successful 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Removing work directories... 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Finished.</code> </pre> <br>  Infolgedessen dauerte die √úbertragung von 10 leeren Tabellen ungef√§hr 16 Sekunden (14: 40-15: 02), dh eine Tabelle - 1,6 Sekunden.  In dieser Zeit k√∂nnen in unserem Fall mit pg_dump &amp; psql ca. 100 MB Daten heruntergeladen werden. <br><br><h3>  gp_dump &amp; gp_restore </h3><br>  Optional: Verwenden Sie Add-Ons √ºber ihnen, gpcrondump &amp; gpdbrestore, da gp_dump &amp; gp_restore als veraltet deklariert sind.  Obwohl gpcrondump &amp; gpdbrestore selbst gp_dump &amp; gp_restore verwenden.  Dies ist der universellste Weg, aber nicht der schnellste.  Die mit gp_dump erstellten Sicherungsdateien stellen eine Reihe von DDL-Befehlen auf dem Masterknoten und auf den prim√§ren Segmenten dar, haupts√§chlich S√§tze von COPY-Befehlen und -Daten.  Geeignet f√ºr F√§lle, in denen der gleichzeitige Betrieb des Zielclusters und des Quellclusters nicht m√∂glich ist.  Es gibt sowohl alte als auch neue Versionen von Greenplum: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gp_dump</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gp_restore</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/141/1b7/8e8/1411b78e893176ef21de383e78c0b87f.png"><br><br><h3>  Gpbackup &amp; gprestore Dienstprogramme </h3><br>  Erstellt als Ersatz f√ºr gp_dump &amp; gp_restore.  F√ºr ihre Arbeit ist mindestens die Greenplum-Version 4.3.17 erforderlich ( <a href="">const MINIMUM_GPDB4_VERSION = "4.3.17"</a> ).  Das Arbeitsschema √§hnelt gpbackup &amp; gprestore, w√§hrend die Arbeitsgeschwindigkeit viel schneller ist.  Der schnellste Weg, um DDL-Befehle f√ºr gro√üe Datenbanken zu erhalten.  Standardm√§√üig werden globale Objekte √ºbertragen. F√ºr die Wiederherstellung m√ºssen Sie "gprestore --with-globals" angeben.  Der optionale Parameter "--jobs" kann die Anzahl der Jobs (und Sitzungen in der Datenbank) beim Erstellen einer Sicherung festlegen.  Aufgrund der Tatsache, dass mehrere Sitzungen erstellt werden, ist es wichtig, die Konsistenz der Daten sicherzustellen, bis alle Sperren empfangen wurden.  Es gibt auch eine n√ºtzliche Option "--with-stats", mit der Sie Statistiken zu Objekten √ºbertragen k√∂nnen, die zum Erstellen von Ausf√ºhrungspl√§nen verwendet werden.  Weitere Informationen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br><h3>  Gpcopy-Dienstprogramm </h3><br>  Zum Kopieren von Datenbanken gibt es ein Dienstprogramm gpcopy - ein Ersatz f√ºr gptansfer.  Es ist jedoch nur in der propriet√§ren Version von Greenplum von Pivotal ab 4.3.26 enthalten - in der Open Source-Version ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dies bei diesem Dienstprogramm nicht der Fall</a> .  W√§hrend der Arbeit am Quellcluster wird der Befehl COPY source_table TO PROGRAM 'gpcopy_helper ...' ON SEGMENT CSV IGNORE EXTERNAL PARTITIONS ausgef√ºhrt.  Auf der Seite des empfangenden Clusters wird eine tempor√§re externe Tabelle CREATE EXTERNAL WEB TEMP TABLE external_temp_table (LIKE target_table) EXECUTE '... gpcopy_helper ‚Äìlisten ...' erstellt und der Befehl INSERT INTO target_table SELECT * FROM external_temp_table ausgef√ºhrt.  Infolgedessen wird gpcopy_helper mit dem Parameter ‚Äìlisten f√ºr jedes Segment des Zielclusters gestartet, das Daten von gpcopy_helper von Segmenten des Quellclusters empf√§ngt.  Aufgrund eines solchen Daten√ºbertragungsschemas sowie der Komprimierung ist die √úbertragungsgeschwindigkeit viel h√∂her.  Zwischen Clustern muss auch die SSH-Authentifizierung f√ºr Zertifikate konfiguriert werden.  Ich m√∂chte auch darauf hinweisen, dass gpcopy eine praktische Option "--truncate-source-after" (und "--validate") f√ºr F√§lle hat, in denen sich die Quell- und Zielcluster auf denselben Servern befinden. <br><br><h2>  Daten√ºbertragungsstrategie </h2><br>  Um die √úbertragungsstrategie zu bestimmen, m√ºssen wir bestimmen, was f√ºr uns wichtiger ist: Daten schnell √ºbertragen, aber mit mehr Arbeit und m√∂glicherweise weniger zuverl√§ssig (gpbackup, gptransfer oder eine Kombination davon) oder mit weniger Arbeit, aber langsamer (gpbackup oder gptransfer ohne Kombination). <br><br>  Der schnellste Weg zum √úbertragen von Daten - wenn es einen Quellcluster und einen Zielcluster gibt - ist der folgende: <br><br><ul><li>  Holen Sie sich DDL mit gpbackup --metadata-only, konvertieren Sie und laden Sie mit psql durch die Pipeline <br></li><li>  Indizes l√∂schen <br></li><li>  √úbertragen Sie Tabellen mit einer Gr√∂√üe von 100 MB oder mehr mit gptransfer <br></li><li>  √úbertragen Sie Tabellen mit einer Gr√∂√üe von weniger als 100 MB mit pg_dump |  psql wie im ersten absatz <br></li><li>  Erstellen Sie gel√∂schte Indizes zur√ºck <br></li></ul><br>  Diese Methode erwies sich in unseren Messungen als mindestens zweimal schneller als gp_dump &amp; gp_restore.  Alternative Methoden: √úbertragen aller Datenbanken mit gptransfer ‚Äìfull, gpbackup &amp; gprestore oder gp_dump &amp; gp_restore. <br><br>  Tabellengr√∂√üen k√∂nnen durch die folgende Abfrage erhalten werden: <br><br><pre> <code class="plaintext hljs">SELECT nspname AS "schema", coalesce(tablename, relname) AS "name", SUM(pg_total_relation_size(class.oid)) AS "size" FROM pg_class class JOIN pg_namespace namespace ON namespace.oid = class.relnamespace LEFT JOIN pg_partitions parts ON class.relname = parts.partitiontablename AND namespace.nspname = parts.schemaname WHERE nspname NOT IN ('pg_catalog', 'information_schema', 'pg_toast', 'pg_bitmapindex', 'pg_aoseg', 'gp_toolkit') GROUP BY nspname, relkind, coalesce(tablename, relname), pg_get_userbyid(class.relowner) ORDER BY 1,2;</code> </pre><br><br><h3>  Notwendige Umbauten </h3><br>  Sicherungsdateien in den Greenplum-Versionen 4 und 5 sind ebenfalls nicht vollst√§ndig kompatibel.  In Greenplum 5 haben die Befehle CREATE EXTERNAL TABLE und COPY aufgrund einer √Ñnderung der Syntax nicht den Parameter INTO ERROR TABLE, und Sie m√ºssen den SET-Parameter gp_ignore_error_table auf true setzen, damit die Wiederherstellung der Sicherung nicht versehentlich fehlschl√§gt.  Mit dem Parametersatz erhalten wir nur eine Warnung. <br><br>  Dar√ºber hinaus wurde in der f√ºnften Version ein anderes Protokoll f√ºr die Interaktion mit externen pxf-Tabellen eingef√ºhrt. Um es zu verwenden, m√ºssen Sie den Parameter LOCATION √§ndern und den pxf-Dienst konfigurieren. <br>  Es ist auch erw√§hnenswert, dass in den Sicherungsdateien gp_dump &amp; gp_restore sowohl auf dem Masterknoten als auch auf jedem prim√§ren Segment der Parameter SET gp_strict_xml_parse auf false gesetzt ist.  In Greenplum 5 gibt es keinen solchen Parameter, und als Ergebnis erhalten wir eine Fehlermeldung. <br><br>  Wenn das gphdfs-Protokoll f√ºr externe Tabellen verwendet wurde, m√ºssen Sie in den Sicherungsdateien die Liste der Quellen im Parameter LOCATION f√ºr externe Tabellen in der Zeile 'gphdfs: //' √ºberpr√ºfen.  Zum Beispiel sollte es nur 'gphdfs: //hadoop.local: 8020' geben.  Wenn andere Zeilen vorhanden sind, m√ºssen diese analog zum Ersatzskript auf dem Masterknoten hinzugef√ºgt werden. <br><br><pre> <code class="plaintext hljs">grep -o gphdfs\:\/\/.*\/ /data1/master/gpseg-1/db_dumps/20181206/gp_dump_-1_1_20181206122002.gz | cut -d/ -f1-3 | sort | uniq gphdfs://hadoop.local:8020</code> </pre> <br>  Wir ersetzen den Masterknoten (am Beispiel der Datendatei gp_dump): <br><br><pre> <code class="plaintext hljs">mv /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.gz /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.old.gz gunzip -c /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.old.gz | sed "s#'gphdfs://hadoop.local:8020#'pxf:/#g" | sed "s/\(^.*pxf\:\/\/.*'\)/\1\\&amp;\&amp;\?PROFILE=HdfsTextSimple'/" |sed "s#'&amp;#g" | sed 's/SET gp_strict_xml_parse = false;/SET gp_ignore_error_table = true;/g' | gzip -1 &gt; /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.gz nets</code> </pre> <br>  In neueren Versionen wurde der Profilname von HdfsTextSimple <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">als veraltet deklariert</a> . Der neue Name lautet hdfs: text. <br><br><h2>  Zusammenfassung </h2><br>  Au√üerhalb des Artikels bestand weiterhin die Notwendigkeit einer expliziten Konvertierung in Text ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implicit Text Casting</a> ), einem neuen Cluster-Ressourcenverwaltungsmechanismus f√ºr Ressourcengruppen, der Resource Queues ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GPORCA-</a> Optimierer) ersetzte, der standardm√§√üig in Greenplum 5 enthalten ist, kleinere Probleme mit Clients. <br><br>  Ich freue mich auf die Ver√∂ffentlichung der sechsten Version von Greenplum, die f√ºr das Fr√ºhjahr 2019 geplant ist: Kompatibilit√§tsstufe mit PostgreSQL 9.4, Volltextsuche, Unterst√ºtzung des GIN-Index, Bereichstypen, JSONB, zStd-Komprimierung.  Au√üerdem wurden vorl√§ufige Pl√§ne f√ºr Greenplum 7 bekannt: Kompatibilit√§tsstufe mit PostgreSQL mindestens 9.6, Sicherheit auf Zeilenebene, automatisiertes Master-Failover.  Die Entwickler versprechen auch die Verf√ºgbarkeit von Dienstprogrammen zur Datenbankaktualisierung f√ºr die Aktualisierung zwischen Hauptversionen, damit das Leben einfacher wird. <br><br>  <i>Dieser Artikel wurde vom Datenverwaltungsteam von Rostelecom erstellt</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439876/">https://habr.com/ru/post/de439876/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439864/index.html">Wissensmanagement, warum und wie wir es gemacht haben</a></li>
<li><a href="../de439866/index.html">Die Prinzipien zum Entwerfen von Nomenklaturverzeichnissen in 1C Enterprise Management 2 (ERP 2.4.6)</a></li>
<li><a href="../de439868/index.html">Leben ohne Facebook: weniger radikale Ansichten, gute Laune, mehr Zeit f√ºr die Lieben. Jetzt von der Wissenschaft bewiesen</a></li>
<li><a href="../de439870/index.html">Video als Motor des Fortschritts: die Entwicklung von √úberwachungssystemen</a></li>
<li><a href="../de439874/index.html">SVG-Filtereffekte. Teil 3. Bildposterisierungseffekt mit feComponentTransfer</a></li>
<li><a href="../de439878/index.html">Erstellen einer Architektur f√ºr ein neues hoch geladenes Startup im Jahr 2019</a></li>
<li><a href="../de439880/index.html">Sicherheitswoche 07: Lokale Schwachstellen von IoT-Ger√§ten</a></li>
<li><a href="../de439882/index.html">Abenteuer mit ptrace (2)</a></li>
<li><a href="../de439884/index.html">So lehnen Sie unn√∂tige Newsletter mit einem einzigen Knopf ab. Yandex.Mail Team Erfahrung</a></li>
<li><a href="../de439886/index.html">Wie ich einem neuronalen Netzwerk beigebracht habe, die Positionsbewertungsfunktion beim russischen AI Cup CodeBall 2018 zu implementieren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
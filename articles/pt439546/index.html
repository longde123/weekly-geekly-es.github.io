<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèîÔ∏è ü§£ ü§úüèø Os andr√≥ides sonham com punk el√©trico? Como eu ensinei uma rede neural a escrever m√∫sica üôÖüèø üöá üòè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nos cursos de aprendizado de m√°quina da Artezio, conheci um modelo de aprendizado capaz de fazer m√∫sica. A m√∫sica √© uma parte essencial da minha vida,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Os andr√≥ides sonham com punk el√©trico? Como eu ensinei uma rede neural a escrever m√∫sica</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/439546/">  Nos cursos de aprendizado de m√°quina da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artezio,</a> conheci um modelo de aprendizado capaz de fazer m√∫sica.  A m√∫sica √© uma parte essencial da minha vida, por muitos anos eu toquei em grupos (punk rock, reggae, hip hop, rock, etc.) e sou um ouvinte fan√°tico. <br><br>  Infelizmente, muitos grupos, dos quais eu era um grande f√£ na minha juventude, se separaram por v√°rias raz√µes.  Ou eles n√£o terminaram, mas o que est√£o gravando agora ... em geral, seria melhor se eles terminassem. <br><br>  Fiquei curioso para saber se existe agora um modelo pronto para aprender nas faixas de um dos meus grupos favoritos e criar composi√ß√µes semelhantes.  Como os pr√≥prios m√∫sicos n√£o t√™m mais muito sucesso, talvez a rede neural possa lidar com eles? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/72f/844/01f/72f84401f2af035271021780fc848fe8.png"></div>  <a href="">Fonte</a> <br><a name="habracut"></a><br>  Estudando os modelos acabados, rapidamente me deparei com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo</a> com uma vis√£o geral das seis op√ß√µes mais famosas.  √â, obviamente, sobre formatos de m√∫sica digital.  Pode ser visto no artigo que duas abordagens principais para gera√ß√£o de m√∫sica podem ser distinguidas: com base no fluxo de √°udio digitalizado (o som que ouvimos dos alto-falantes - √°udio bruto, arquivos wav) e com base no trabalho com MIDI (nota√ß√£o musical). <br><br>  Eu larguei as op√ß√µes com √°udio bruto, e √© por isso. <br><br><ul><li>  Os resultados n√£o s√£o impressionantes - o uso desses modelos para m√∫sica polif√¥nica fornece um resultado muito espec√≠fico.  Isso √© incomum, voc√™ pode criar pinturas interessantes, mas n√£o √© adequado para meus prop√≥sitos: soa estranho, mas eu queria ouvir algo semelhante ao original. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5d9/229/364/5d9229364d98bee837d9bcf7cb3e1bac.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fonte</a> <br><br>  Um bom exemplo de m√∫sica de piano: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  E com m√∫sica orquestral ou rock, parece muito mais estranho: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Aqui, os caras tentaram processar o Black Metal e n√£o apenas o √°udio bruto. <br><br><ul><li> Nas composi√ß√µes das minhas bandas favoritas, v√°rios instrumentos soam - vocais, bateria, baixo, guitarra, sintetizadores.  Cada instrumento soa junto com o resto.  Estou procurando um modelo que atue da mesma maneira, ou seja, funcione n√£o apenas com instrumentos individuais, mas tamb√©m leve em considera√ß√£o o som conjunto. <br><br>  Quando um m√∫sico precisa aprender uma parte de um instrumento de ouvido, ele tenta isolar o instrumento que precisa de todo o fluxo sonoro.  Ent√£o ele repete o som at√© obter um resultado semelhante.  A tarefa n√£o √© a mais f√°cil, mesmo para uma pessoa com boa audi√ß√£o - a m√∫sica pode ser dif√≠cil, os instrumentos ‚Äúse fundem‚Äù. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dcd/5d1/8eb/dcd5d18eb46a6d383ffbc378d3fc7adb.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fonte</a> <br><br>  Me deparei com ferramentas de software que tentavam resolver um problema semelhante.  Existem v√°rios projetos que fazem isso com base no aprendizado de m√°quina.  Por exemplo, enquanto eu escrevia este texto, a Magenta lan√ßou um novo instrumento, o Wave2Midi2Wave, capaz de "tirar" notas de piano e realisticamente "reproduzi-las".  Existem outras ferramentas, embora, em geral, essa tarefa ainda n√£o tenha sido resolvida. <br><br>  Portanto, para aprender uma parte de um trabalho, √© mais f√°cil fazer anota√ß√µes prontas.  Esta √© a maneira mais f√°cil.  √â l√≥gico supor que ser√° mais f√°cil para as redes neurais trabalharem com a representa√ß√£o musical da m√∫sica, onde cada instrumento √© representado por uma faixa separada. <br><br><ul><li>  No caso do √°udio bruto, o resultado √© uma mistura de todos os instrumentos, as partes n√£o podem ser carregadas individualmente no seq√ºenciador (editor de √°udio), corrigidas, alteradas o som e assim por diante.  Fico muito feliz se a rede neural comp√µe um sucesso, mas comete um erro em algumas notas - ao trabalhar com notas, posso corrigi-las facilmente, com o √°udio bruto isso √© quase imposs√≠vel. </li></ul><br>  A nota√ß√£o musical tamb√©m tem suas desvantagens.  N√£o leva em conta a massa de nuances de desempenho.  Quando se trata de MIDI, nem sempre se sabe quem s√£o esses arquivos MIDI, qu√£o pr√≥ximos eles est√£o do original.  Talvez o compilador tenha simplesmente cometido um erro, porque n√£o √© uma tarefa f√°cil "remover" o jogo. <br><br>  Ao trabalhar com notas polif√¥nicas, √© necess√°rio garantir que os instrumentos a qualquer momento estejam afinados.  Al√©m disso, √© importante que a sequ√™ncia desses momentos seja l√≥gica do ponto de vista humano da m√∫sica. <br><br>  Descobriu-se que n√£o existem tantas solu√ß√µes que possam funcionar com notas, e nem mesmo com um instrumento, mas com v√°rias que soam ao mesmo tempo.  Inicialmente, ignorei o projeto Magenta do Google TensorFlow, porque ele foi descrito como "n√£o polif√¥nico".  Naquela √©poca, a biblioteca MusicVAE ainda n√£o havia sido publicada, ent√£o eu decidi pelo projeto BachBot. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b7/fef/993/2b7fef9935afb9f001bf954dd0fc097b.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fonte</a> <br><br><h2>  Bachbot </h2><br>  Descobriu-se que a solu√ß√£o para o meu problema j√° existe.  Ou√ßa o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">feliz anivers√°rio</a> sintonizado pelo BachBot e parecendo um coral de Bach. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  O coral √© uma m√∫sica espec√≠fica, composta por quatro vozes: soprano, viola, tenor e baixo.  Cada um dos instrumentos pode produzir uma nota de cada vez.  Aqui voc√™ tem que se aprofundar um pouco mais na m√∫sica.  Falaremos sobre m√∫sica na dimens√£o de quatro quartos. <br><br>  Em uma nota√ß√£o musical, uma nota possui dois indicadores - pitch (to, re, mi ...) e dura√ß√£o (inteiro, metade, oitavo, d√©cimo sexto, trinta segundos).  Consequentemente, uma nota inteira dura uma batida inteira, duas meias notas por batida inteira, dezesseis dezesseis semicolares por batida inteira. <br><br>  Ao preparar os dados para o treinamento da rede neural, os criadores do BachBot levaram em considera√ß√£o o seguinte: <br><br><ul><li>  para n√£o derrubar o modelo com acordes de teclas diferentes, que juntas n√£o soariam harmoniosas, todos os corais levavam √† mesma tecla; </li><li>  a rede neural deve ser fornecida com valores discretos, e a m√∫sica √© um processo cont√≠nuo, o que significa que a discretiza√ß√£o √© necess√°ria.  Um instrumento pode tocar uma nota longa e completa e o outro ao mesmo tempo alguns d√©cimos sextos.  Para resolver esse problema, todas as notas foram divididas em dezesseis.  Em outras palavras, se uma quarta nota for encontrada nas notas, ela chega quatro vezes com a mesma d√©cima sexta - a primeira vez com a bandeira que foi pressionada e as pr√≥ximas tr√™s vezes com a bandeira que continua. </li></ul><br>  O formato dos dados √© o seguinte - (tom, nova nota | continua√ß√£o do som da nota antiga) <br><br>  (56, Verdadeiro) # Soprano <br>  (52, Falso) # Alt <br>  (47, Falso) # Tenor <br>  (38, Falso) # Baixo <br><br>  Tendo conduzido todos os corais do conjunto de dados music21 popular por esse procedimento, os autores do BachBot descobriram que n√£o existem muitas combina√ß√µes de quatro combina√ß√µes de notas nas corais (se voc√™ as trouxerem para a mesma tecla), embora pare√ßa que poderia haver 128 x 128 x 128 x 128 (128 n√≠veis de afina√ß√£o usados ‚Äã‚Äãno midi).  O tamanho de um dicion√°rio condicional n√£o √© t√£o grande.  Esta √© uma observa√ß√£o curiosa, retornaremos a ela quando falarmos sobre o MusicVAE.  Ent√£o, temos os corais de Bach gravados na forma de sequ√™ncias de quatro. <br><br>  Costuma-se dizer que a m√∫sica √© uma linguagem.  Portanto, n√£o √© de surpreender que os criadores do BachBot tenham aplicado a tecnologia popular na PNL (Processamento de Linguagem Natural) √† m√∫sica, ou seja, eles treinaram a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rede LSTM</a> no conjunto de dados gerado e obtiveram um modelo que pode complementar um ou v√°rios instrumentos ou at√© criar corais do zero.  Ou seja, voc√™ define alt, tenor e baixo, e o BachBot adiciona a melodia soprano para voc√™ e, juntos, soa como Bach. <br><br>  Aqui est√° outro exemplo: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Parece √≥timo! <br><br>  Voc√™ pode assistir a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este v√≠deo com</a> mais detalhes.  H√° uma an√°lise interessante l√°, coletada com base em uma pesquisa no site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bachbot.com</a> <br><br>  Os usu√°rios s√£o incentivados a distinguir os corais originais de Bach da m√∫sica criada pela rede neural.  Os resultados mencionam que, se uma rede neural cria uma parte de baixo para todas as outras configura√ß√µes, apenas metade dos usu√°rios consegue distinguir corais criadas por uma rede neural das originais.  Engra√ßado, mas a maioria dos especialistas em m√∫sica fica confusa.  Com outras ferramentas, as coisas est√£o um pouco melhores.  Parece um insulto para mim como baixista - o violinista parece necess√°rio por enquanto, mas √© hora dos baixistas se atualizarem nas habilidades do drywall. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/701/bb9/cc6/701bb9cc6cdff8a20f0ede768324cd81.png"></div><br><h1>  Magenta </h1><br>  Estudando o BachBot, descobri que ele estava inclu√≠do no projeto Magenta (Google TensorFlow).  Decidi dar uma olhada mais de perto e descobri que, no √¢mbito da Magenta, v√°rios modelos interessantes foram desenvolvidos, um dos quais √© apenas dedicado ao trabalho com composi√ß√µes polif√¥nicas.  A Magenta criou suas maravilhosas ferramentas e at√© j√° lan√ßou o plugin para o editor de √°udio Ableton, o que √© especialmente bom em termos de aplica√ß√£o para m√∫sicos. <br><br>  Meus favoritos: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">beat blender</a> (cria varia√ß√µes em uma determinada parte da bateria) e <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">loops latentes</a> (cria transi√ß√µes entre melodias). <br><br>  A id√©ia principal da ferramenta MusicVAE, que eu decidi usar, √© que os criadores tentaram combinar o modelo e o codificador autom√°tico variacional - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VAE</a> na rede LSTM. <br><br>  Se voc√™ se lembra, em uma conversa sobre o Bach Bot, percebemos que o dicion√°rio de acordes n√£o consiste em 128x128x128x128 elementos, mas muito menos.  Os criadores do MusicVAE tamb√©m notaram isso e decidiram usar um espa√ßo latente compactado. <br><br>  A prop√≥sito, o que √© t√≠pico, para treinar o MusicVAE, voc√™ n√£o precisa traduzir as fontes em uma chave.  A transposi√ß√£o n√£o √© necess√°ria, suponho, porque o c√≥digo-fonte ainda ser√° convertido pelo codificador autom√°tico e as informa√ß√µes de tonalidade desaparecer√£o. <br><br>  O VAE foi projetado de maneira a permitir que o decodificador recupere dados com efici√™ncia do conjunto de dados de treinamento, enquanto o espa√ßo latente representa uma distribui√ß√£o suave dos recursos dos dados de entrada. <br><br>  Este √© um ponto muito importante.  Isso possibilita a cria√ß√£o de objetos semelhantes e a interpola√ß√£o logicamente significativa.  No espa√ßo original, temos 128x128x128x128 variantes de combinar o som de quatro notas, mas, na verdade, nem todas s√£o usadas (elas soam agrad√°veis ‚Äã‚Äãao ouvido humano).  Um codificador autom√°tico variacional os transforma em um conjunto muito menor em um espa√ßo oculto, e voc√™ pode criar opera√ß√µes matem√°ticas nesse espa√ßo que tenham um significado significativo do ponto de vista do espa√ßo original, por exemplo, os pontos vizinhos ser√£o fragmentos musicais semelhantes. <br><br>  Um bom exemplo √© como adicionar √≥culos a uma foto usando um codificador autom√°tico <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste artigo</a> .  Voc√™ pode ler mais sobre como o Muisc VAE funciona no site oficial da Magenta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste artigo</a> . Tamb√©m h√° um link para o arXiv. <br><br>  Portanto, o instrumento √© selecionado, resta us√°-lo com meu objetivo original - criar novas m√∫sicas com base nas faixas j√° gravadas e avaliar o quanto isso soar√° como o som do grupo original.  A Magenta n√£o funciona no meu laptop Windows e h√° muito tempo calcula um modelo sem uma GPU.  Depois de sofrer com m√°quinas virtuais, um cont√™iner de encaixe, etc., decidi usar a nuvem. <br><br>  O Google fornece <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">notebooks colab,</a> onde voc√™ pode entrar em modelos Magenta.  No entanto, no meu caso, n√£o foi poss√≠vel treinar o modelo, o processo travava o tempo todo devido a v√°rias restri√ß√µes - quantidade de mem√≥ria dispon√≠vel, interrup√ß√µes de tempo limite, falta de uma linha de comando normal e direitos de root para instalar as bibliotecas necess√°rias.  Hipoteticamente, existe at√© a oportunidade de usar a GPU, mas, repito, n√£o consegui instalar o modelo e inici√°-lo. <br><br>  Eu estava pensando em comprar um servidor e, ah, boa sorte, descobri que o Google fornece servi√ßos de nuvem do Google Cloud com uma GPU, e mesmo h√° um per√≠odo de teste gratuito.  √â verdade que, na R√∫ssia, eles est√£o dispon√≠veis oficialmente apenas para entidades legais, mas me deixaram entrar no modo de teste gratuito. <br><br>  Ent√£o, criei uma m√°quina virtual no GoogleCloud com um m√≥dulo GPU, encontrei na Internet v√°rios arquivos midi de um dos meus grupos favoritos e os enviei para a pasta midi na nuvem. <br><br>  Instale o Magenta: <br><br><pre><code class="plaintext hljs">pip install magenta-gpu</code> </pre> <br>  √â √≥timo que tudo isso possa ser instalado com uma equipe, pensei, mas ... erros.  Parece que voc√™ precisa tocar na linha de comando, desculpe. <br><br>  Observamos os erros: a biblioteca rtmidi n√£o est√° instalada na m√°quina em nuvem, sem a qual o Magenta n√£o funciona. <br><br>  E, por sua vez, falha devido √† falta do pacote libasound2-dev, e eu tamb√©m n√£o tenho privil√©gios de root. <br><br>  N√£o √© t√£o assustador: <br><br><pre> <code class="plaintext hljs">sudo su root apt-get install libasound2-dev</code> </pre> <br>  Hooray, agora o pip install rtmidi √© executado sem erros, assim como o pip install magenta-gpu. <br><br>  N√≥s encontramos na Internet e baixamos os arquivos de origem na pasta midi.  Eles soam algo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">assim</a> . <br><br>  Convertemos midi para um formato de dados com o qual a rede j√° pode trabalhar: <br><br><pre> <code class="plaintext hljs">convert_dir_to_note_sequences \ --input_dir=midi\ --hparams=sampling_rate=1000.0\ --output_file=notesequences_R2Midi.tfrecord \ --log=DEBUG \ --recursive</code> </pre> <br>  e comece a treinar <br><br><pre> <code class="plaintext hljs">music_vae_train \ --config=hier-multiperf_vel_1bar_med \ --run_dir=/home/RNCDtrain/ \ --num_steps=1 \ --checkpoints_to_keep=2 \ --hparams=sampling_rate=1000.0 \ --hparams=batch_size=32,learning_rate=0.0005 \ --num_steps=5000 \ --mode=train \ --examples_path=notesequences_R2Midi.tfrecord</code> </pre> <br>  Mais uma vez o problema.  O Tensorflow falha com um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">erro</a> - felizmente, h√° alguns dias algu√©m j√° descreveu esse erro, e as fontes do Python podem ser corrigidas. <br><br>  Entramos na pasta <br><br><pre> <code class="plaintext hljs">/usr/local/lib/python2.7/dist-packages/tensorflow_probability/python/distributions#</code> </pre> <br>  e substitua a linha de importa√ß√£o, conforme descrito no bug no github. <br><br>  Lan√ßa music_vae_train novamente e ... Viva!  O treinamento se foi! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0b5/46c/498/0b546c498699b6d4fbca1b95af41bd51.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fonte</a> <br><br>  hier-multiperf_vel_1bar_med - Eu uso um modelo polif√¥nico (at√© 8 instrumentos) que produz uma medida cada. <br><br>  Um par√¢metro importante √© checkpoints_to_keep = 2, a capacidade do disco nas nuvens √© limitada, um dos problemas √© que o processo de aprendizado √© interrompido o tempo todo por causa do estouro do disco, os pontos de verifica√ß√£o s√£o bastante pesados ‚Äã‚Äã- 0,6-1 gigabytes cada. <br><br>  Em algum lugar nas 5000 eras, o erro come√ßa a pular em torno de 40-70.  N√£o sei se esse √© um bom resultado ou n√£o, mas parece que com um pouco de dados de treinamento, a rede ser√° treinada novamente e n√£o h√° sentido em desperdi√ßar o tempo das GPUs t√£o gentilmente fornecidas a mim gratuitamente nos data centers do Google.  Passamos para a gera√ß√£o. <br><br>  Por alguma raz√£o, ao instalar o Magenta n√£o instalou o arquivo de gera√ß√£o em si, tive que solt√°-lo com as m√£os na pasta para os outros: <br><br><pre> <code class="plaintext hljs">curl -o music_vae_generate.py https://raw.githubusercontent.com/tensorflow/magenta/master/magenta/models/music_vae/music_vae_generate.py</code> </pre> <br>  Por fim, crie os fragmentos: <br><br><pre> <code class="plaintext hljs">music_vae_generate --config=hier-multiperf_vel_1bar_med --checkpoint_file=/home/RNCDtrain/train/ --mode=sample --num_outputs=32 --output_dir=/home/andrey_shagal/  --temperature=0.3</code> </pre> <br>  config - tipo de gera√ß√£o, exatamente o mesmo que durante o treinamento - multitrack, 1 rel√≥gio <br>  checkpoint_file - pasta onde obter o √∫ltimo arquivo com o modelo treinado <br>  mode - sample - cria uma amostra (existe outra op√ß√£o interpolar - cria uma medida de transi√ß√£o entre duas medidas) <br>  num_outputs - quantas pe√ßas gerar <br>  temperature - um par√¢metro de randomiza√ß√£o ao criar uma amostra, de 0 a 1. Em 0, o resultado √© mais previs√≠vel, mais pr√≥ximo da fonte, em 1 - Eu sou um artista, como eu o vejo. <br><br>  Na sa√≠da, recebo 32 fragmentos por medida.  Tendo iniciado o gerador v√°rias vezes, ou√ßo os fragmentos e colo o melhor em uma faixa: neurancid.mp3. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Ent√£o "eu passei este ver√£o."  Estou satisfeito  Obviamente, √© improv√°vel que o r√°dio "Maximum" o leve √† lista de reprodu√ß√£o, mas se voc√™ ouvir, realmente se parecer√° com o grupo Rancid original.  O som, √© claro, √© diferente da grava√ß√£o em est√∫dio, mas trabalhamos principalmente com notas.  Al√©m disso, h√° espa√ßo para a√ß√£o - processar midi com v√°rios plug-ins VST, regravar partes com m√∫sicos ao vivo ou esperar at√© que os caras do Wave2Midi2Wave cheguem √†s guitarras com uma sobrecarga. <br><br>  N√£o h√° reclama√ß√µes sobre as notas.  Idealmente, eu gostaria que a rede neural criasse uma obra-prima ou pelo menos um sucesso para os 100 melhores da Billboard. Mas enquanto ela aprendeu a <s>usar √°lcool e drogas</s> de roqueiros <s>,</s> tocar toda a batida uma nota em oitavas (na verdade, n√£o apenas, mas tenho orgulho de sua paternidade). transi√ß√£o de 20 para 22 segundos).  Existem raz√µes para isso e muito mais sobre elas. <br><br><ol><li>  Pequena quantidade de dados. </li><li>  O modelo que usei produz fragmentos no tamanho de uma medida.  No punk rock, como regra, poucos eventos ocorrem em uma √∫nica medida. </li><li>  As transi√ß√µes e melodias interessantes funcionam justamente no contexto dos riffs de afina√ß√£o, transi√ß√µes de acordes para acordes e o codificador autom√°tico, juntamente com uma pequena quantidade de dados, parece ter perdido a maioria das m√∫sicas e at√© reduziu todos os riffs a dois acordes consoantes e v√°rios atonais.  Precisamos tentar um modelo que funcione com 16 compassos, √© uma pena que apenas tr√™s vozes estejam dispon√≠veis nele. </li></ol><br>  Entrei em contato com os desenvolvedores, eles recomendaram tentar reduzir a dimens√£o do espa√ßo latente, porque treinaram sua rede em 200.000 trilhas e eu treinei em 15. N√£o consegui o efeito vis√≠vel de reduzir o espa√ßo-z, mas ainda h√° algo para mexer. <br><br>  A prop√≥sito, monotonia e monotonia est√° longe de ser sempre um sinal de menos.  De rituais xaman√≠sticos a festas techno, como voc√™ sabe, um passo.  Devemos tentar treinar o modelo em algo assim - rave, techno, dub, reggae, contras de hip-hop.  Certamente, h√° uma chance de criar algo agradavelmente zumbi.  Encontrei cerca de 20 m√∫sicas de Bob Marley no midi e, voil√°, um loop muito legal: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Acima das partes midi s√£o regravadas com baixo ao vivo e guitarras, processadas por sintetizadores VST para tornar o fragmento mais suculento.  No original, a rede emitiu apenas notas.  Se voc√™ toc√°-los com um midi player padr√£o, soa assim: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Certamente, se voc√™ criar v√°rios desenhos de bateria tem√°ticos b√°sicos, inici√°-los no beat blender + partes b√°sicas de baixo e sintetizadores com um loop latente (havia mais sobre eles), √© bem poss√≠vel executar um algoritmo para o r√°dio techno que criar√° continuamente novas faixas ou mesmo uma faixa sem fim.  Buzz eterno! <br><br>  O MusicVAE tamb√©m oferece a oportunidade de treinar a rede para gerar fragmentos de trio de 16 barras - bateria, baixo e chumbo.  Tamb√©m √© bastante interessante.  Dados de entrada - arquivos midi multipista - o sistema se divide em triplos em todas as combina√ß√µes poss√≠veis e depois treina o modelo.  Essa rede requer significativamente mais recursos, mas o resultado √© imediatamente 16 ciclos!  Imposs√≠vel resistir.  Tentei imaginar como um grupo que toca algo entre Rancid e NOFX poderia soar, carregando para o treinamento sobre um n√∫mero igual de faixas de cada grupo: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Tamb√©m existem pe√ßas midi regravadas ao vivo.  Midi padr√£o como este: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Interessante!  Definitivamente, √© melhor que o meu primeiro grupo!  E, a prop√≥sito, esse mesmo modelo nos d√° um jazz livre decente: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Os problemas que encontrei: <br><br><ol><li>  Falta de uma posi√ß√£o boa e conveniente que reduza o tempo necess√°rio para aguardar o treinamento.  O modelo funciona apenas no Linux, o treinamento √© longo, sem uma GPU por muito tempo, e o tempo todo eu quero tentar alterar os par√¢metros e ver o que acontece.  Por exemplo, um servidor em nuvem com um processador GPU de 100 √©pocas para o modelo "trio de 16 ciclos" contou 8 horas. </li><li>  Um problema t√≠pico de aprendizado de m√°quina √© a falta de dados.  Apenas 15 arquivos midi - √© muito pequeno para entender m√∫sica.  A rede neural, ao contr√°rio de mim na minha juventude, n√£o ouviu 6 √°lbuns do Rancid antes dos buracos, n√£o fui a shows, esse resultado foi obtido de 15 faixas midi desconhecidas para quem est√° longe do original.  Agora, se voc√™ ficar com o guitarrista com sensores e captar todos os sons de todas as notas ... Vamos ver como a id√©ia do Wave2Midi2Wave se desenvolve.  Talvez em alguns anos seja poss√≠vel recusar notas para resolver esse problema. </li><li>  O m√∫sico deve cair claramente no ritmo, mas n√£o perfeitamente.  No meio da semana, n√£o h√° din√¢mica nas notas (por exemplo, na bateria), todas s√£o executadas no mesmo volume, exatamente em um clique (como dizem os m√∫sicos, ou seja, exatamente na batida), mesmo que voc√™ as diversifique aleatoriamente, a m√∫sica come√ßa a soar mais animado e mais agrad√°vel.  Novamente, o Wave2Midi2Wave j√° est√° lidando com esse problema. </li></ol><br>  Agora voc√™ tem uma id√©ia das possibilidades da IA ‚Äã‚Äãna cria√ß√£o de m√∫sicas e minhas prefer√™ncias musicais.  Qual papel voc√™ acha que a IA espera no processo criativo no futuro?  Uma m√°quina pode criar m√∫sica em p√© de igualdade ou at√© melhor que um ser humano para ser assistente no processo criativo?  Ou a intelig√™ncia artificial se tornar√° famosa no campo musical apenas pelos artesanatos primitivos. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt439546/">https://habr.com/ru/post/pt439546/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt439534/index.html">Programa√ß√£o de produ√ß√£o e uso de drones na produ√ß√£o de petr√≥leo - 10 palestras da confer√™ncia GIS Tech Russia</a></li>
<li><a href="../pt439538/index.html">Programa√ß√£o da sociedade</a></li>
<li><a href="../pt439540/index.html">Etherblade.net - projeto de c√≥digo-fonte aberto para criar um encapsulador de tr√°fego Ethernet no FPGA (parte um)</a></li>
<li><a href="../pt439542/index.html">Nintendo deixa claro que apenas a pirataria pode salvar a hist√≥ria dos videogames</a></li>
<li><a href="../pt439544/index.html">Col√¥nia. Cap√≠tulo 24: Partida</a></li>
<li><a href="../pt439550/index.html">Hackquest 2018. Resultados e revis√µes. Dia 1-3</a></li>
<li><a href="../pt439552/index.html">Extens√µes maliciosas do Chrome</a></li>
<li><a href="../pt439556/index.html">TDMS Fairway. Metodologias do PMBOK e organiza√ß√µes de design russas</a></li>
<li><a href="../pt439558/index.html">Novo telefone antigo. Reinvente o telefone PSTN</a></li>
<li><a href="../pt439560/index.html">Adaptador blockchain Ethereum para a plataforma de dados InterSystems IRIS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßö üîñ üõ£Ô∏è Laboratoire: configuration de lvm, raid sur linux üë©üèæ‚Äçüç≥ üåù üö§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Une petite digression: ce l \ r est synth√©tique. 


 Certaines des t√¢ches d√©crites ici peuvent √™tre effectu√©es beaucoup plus facilement, mais comme la...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Laboratoire: configuration de lvm, raid sur linux</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450896/"><p>  Une petite digression: ce l \ r est synth√©tique. </p><br><p>  Certaines des t√¢ches d√©crites ici peuvent √™tre effectu√©es beaucoup plus facilement, mais comme la t√¢che de l / r est de se familiariser avec la fonctionnalit√© raid, lvm, certaines op√©rations sont artificiellement compliqu√©es. </p><br><h2 id="trebovaniya-k-instrumentam-dlya-vypolneniya-lr">  Exigences pour les outils √† ex√©cuter l \ r: </h2><br><ul><li>  Outils de virtualisation comme Virtualbox </li><li>  Image d'installation Linux comme <a href="">Debian9</a> </li><li>  Disponibilit√© Internet pour t√©l√©charger plusieurs packages </li><li>  Connexion via ssh √† la VM install√©e (facultatif) </li></ul><br><h2 id="vnimanie">  ATTENTION </h2><br><p>  Ce travail de laboratoire est associ√© √† une question aussi d√©licate que la s√©curit√© des donn√©es - c'est un domaine qui vous permet de perdre toutes vos donn√©es en raison de la plus petite erreur - une lettre ou un chiffre suppl√©mentaire. </p><br><p>  Puisque vous effectuez des travaux de laboratoire, vous n'√™tes pas en danger, sauf si vous devez recommencer. </p><br><p>  Dans la vraie vie, tout est beaucoup plus s√©rieux, vous devez donc saisir tr√®s soigneusement les noms des disques, en comprenant exactement ce que vous ex√©cutez avec la commande actuelle et avec quels disques vous travaillez. </p><a name="habracut"></a><br><p>  Le deuxi√®me point important est la d√©nomination des disques et des partitions: selon la situation, les num√©ros de disque peuvent diff√©rer des valeurs pr√©sent√©es dans les commandes du laboratoire. <br>  Ainsi, par exemple, si vous supprimez le lecteur sda de la matrice, puis ajoutez un nouveau lecteur, le nouveau lecteur sera affich√© sur le syst√®me avec le nom sda.  Si vous red√©marrez avant d'ajouter un nouveau disque, le nouveau disque sera nomm√© sdb et l'ancien sera nomm√© sda </p><br><p>  Les travaux de laboratoire doivent √™tre effectu√©s sous superutilisateur (root) car la plupart des commandes n√©cessitent des privil√®ges √©lev√©s et il n'est pas logique d'√©lever constamment les privil√®ges via sudo. </p><br><h2 id="materialy-dlya-izucheniya">  Mat√©riel d'√©tude </h2><br><ul><li>  RAID </li><li>  LVM </li><li>  Nommage de disque Linux </li><li>  Qu'est-ce qu'une section </li><li>  Qu'est-ce qu'une table de partition et o√π est-elle stock√©e </li><li>  Qu'est-ce que grub </li></ul><br><h2 id="ispolzuemye-utility">  Utilitaires utilis√©s </h2><br><ol><li>  Afficher les informations sur le disque: <br><ul><li>  lsblk -o NOM, TAILLE, FSTYPE, TYPE, MOUNTPOINT </li><li>  fdisk -l </li></ul></li><li>  Afficher des informations et travailler avec LVM <br><ul><li>  pvs </li><li>  pvextend </li><li>  pvcreate </li><li>  pvresize </li><li>  vgs </li><li>  vgreduce </li><li>  lvs </li><li>  lvextend </li></ul></li><li>  Affichez les informations et travaillez avec RAID: <br><ul><li>  chat / proc / mdstat </li><li>  mdadm </li></ul></li><li>  Points de montage: <br><ul><li>  monter </li><li>  umount </li><li>  chat / etc / fstab </li><li>  chat / etc / mtab </li></ul></li><li>  Re-partitionnement du disque: <br><ul><li>  fdisk / dev / XXX </li></ul></li><li>  Copie des sections: <br><ul><li>  jj si = / dev / xxx of = / dev / yyy </li></ul></li><li>  Travailler avec la table de partition: <br><ul><li>  partx </li><li>  sfdisk </li><li>  mkfs.ext4 </li></ul></li><li>  Travailler avec le chargeur de d√©marrage: <br><ul><li>  grub-install / dev / XXX </li><li>  update-grub </li></ul></li><li>  divers <br><ul><li>  lsof </li><li>  apt </li><li>  rsync </li></ul></li></ol><br><h2 id="laboratornaya-rabota-sostoit-iz-3-h-chastey">  Le travail de laboratoire se compose de 3 parties: </h2><br><ul><li>  Configurer un syst√®me sain en utilisant lvm, raid. </li><li>  √âmulation de la panne d'un des disques. </li><li>  Remplacement des disques √† la vol√©e, avec l'ajout de nouveaux disques et le transfert de partitions. </li></ul><br><h2 id="zadanie-1-ustanovka-os-i-nastroyka-lvm-raid">  T√¢che 1 (installation du syst√®me d'exploitation et configuration de LVM, RAID) </h2><br><ol><li><p>  Cr√©ez une nouvelle machine virtuelle avec les fonctionnalit√©s suivantes: </p><br><ul><li>  1 Go de RAM </li><li>  1 unit√© centrale </li><li>  2 disques durs (nommez-les ssd1, ssd2 et attribuez une taille √©gale, cochez les cases hot swap et ssd) </li><li>  Contr√¥leur SATA configur√© sur 4 ports: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18f/6f5/be6/18f6f5be6afbc13138abc3dfe960813b.png" alt="s√©lectionner des disques ssd"></li></ul><br></li><li><p>  Commencez √† installer Linux et acc√©dez au choix des disques durs, proc√©dez comme suit: </p><br><ul><li>  M√©thode de partitionnement: manuel, apr√®s quoi vous devriez voir l'image suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/77a/eb5/3a1/77aeb53a1de2bc7b91d1396dc9b4148e.png" alt="disques de partition"></li><li>  Configuration d'une partition distincte sous / boot: S√©lectionnez le premier disque et cr√©ez une nouvelle table de partition dessus: <br><ul><li>  Taille de la partition: 512M </li><li>  Point de montage: / boot </li></ul></li><li>  R√©p√©tez le r√©glage pour le deuxi√®me disque, mais comme vous ne pouvez pas monter / d√©marrer 2 fois en m√™me temps, s√©lectionnez le point de montage: aucun et obtenez finalement ce qui suit (image avec un montant, refaire la paresse): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3db/2f0/e48/3db2f0e48423f182016bde06c39dfb8d.png" alt="disques de partition"></li><li>  Configuration RAID: </li><li>  S√©lectionnez l'espace libre sur le premier disque et configurez le volume physique pour RAID comme type de partition. </li><li>  S√©lectionnez "Configuration de la partition termin√©e" </li><li>  R√©p√©tez exactement le m√™me param√®tre pour le deuxi√®me disque, ce qui donne les r√©sultats suivants: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/93f/37c/ec3/93f37cec319d628a3267f94d138145e7.png" alt="disques de partition"></li><li>  S√©lectionnez "Configurer le RAID logiciel" <br><ul><li>  Cr√©er un appareil MD </li><li>  Type de p√©riph√©rique RAID logiciel: s√©lectionnez une baie en miroir </li><li>  P√©riph√©riques actifs pour la matrice RAID XXXX: s√©lectionnez les deux disques </li><li>  Appareils de rechange: laissez 0 par d√©faut </li><li>  P√©riph√©riques actifs pour la matrice RAID XX: s√©lectionnez les partitions que vous avez cr√©√©es sous raid </li><li>  Terminer </li></ul></li><li>  √Ä la fin, vous devriez obtenir cette image: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7a7/9b0/3f5/7a79b03f556925d1fd53ccc4ca77b494.png" alt="disques de partition"></li><li>  Configuration LVM: s√©lectionnez Configurer le gestionnaire de volumes logiques </li><li>  Conserver la disposition de partition actuelle et configurer LVM: Oui </li><li>  Cr√©er un groupe de volumes </li><li>  Nom du groupe de volumes: syst√®me </li><li>  P√©riph√©riques pour le nouveau groupe de volumes: choisissez votre RAID cr√©√© </li><li>  Cr√©er un volume logique <br><ul><li>  nom du volume logique: racine </li><li>  taille du volume logique: 2 \ 5 de la taille de votre disque </li></ul></li><li>  Cr√©er un volume logique <br><ul><li>  nom du volume logique: var </li><li>  taille du volume logique: 2 \ 5 de la taille de votre disque </li></ul></li><li>  Cr√©er un volume logique <br><ul><li>  nom du volume logique: journal </li><li>  taille du volume logique: 1 \ 5 de la taille de votre disque </li></ul></li><li>  En choisissant Afficher les d√©tails de configuration, vous devriez obtenir l'image suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b8/8dd/11f/0b88dd11f9372dbf8e53a6727fc69b27.png" alt="disques de partition"></li><li>  Apr√®s avoir termin√© la configuration LVM, vous devriez voir ce qui suit: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/72b/9d4/00d/72b9d400d9b83392c759b7aeb3e9d573.png" alt="disques de partition"></li><li>  Partitionnement: √† son tour, s√©lectionnez chaque volume cr√©√© dans LVM et partitionnez-les, par exemple, pour root comme ceci: <br><ul><li>  Utiliser comme: ext4 </li><li>  point de montage: / </li></ul></li><li>  Le r√©sultat du marquage de la partition racine doit √™tre le suivant: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/225/61e/0be/22561e0be2cd905e0948a63ae3460461.png" alt="disques de partition"></li><li>  R√©p√©tez l'op√©ration de balisage pour var et log en s√©lectionnant les points de montage appropri√©s (/ var et / var / log entrez manuellement), obtenant le r√©sultat suivant: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5da/58c/756/5da58c756fd8d205a93ebfd49acc396f.png" alt="disques de partition"></li><li>  Choisissez Terminer le partitionnement </li><li>  On vous posera quelques questions sur le fait que vous avez encore une partition non mont√©e et que le swap n'est pas configur√©.  Les deux questions doivent recevoir une r√©ponse n√©gative. </li><li>  Le r√©sultat final devrait ressembler √† ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/117/381/a61/117381a61b766df3c89d2646baa2b33d.png" alt="disques de partition"></li></ul><br></li><li><p>  Terminez l'installation du syst√®me d'exploitation en installant grub sur le premier p√©riph√©rique (sda) et d√©marrez le syst√®me. </p><br></li><li><p>  Copiez le contenu de la partition / boot du lecteur sda (ssd1) sur le lecteur sdb (ssd2) </p><br><pre><code class="plaintext hljs">dd if=/dev/sda1 of=/dev/sdb1</code> </pre> <br></li><li><p>  Installez grub sur le deuxi√®me appareil: </p><br><ul><li><p>  Afficher les lecteurs dans le syst√®me: </p><br><pre> <code class="plaintext hljs">fdisk -l lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li>  R√©pertoriez tous les disques que la commande pr√©c√©dente vous a envoy√©s et d√©crivez le type de disque dont il s'agit. </li><li><p>  Localisez le lecteur sur lequel grub n'a pas √©t√© install√© et terminez cette installation: </p><br><pre> <code class="plaintext hljs">grub-install /dev/sdb</code> </pre> <br></li><li>  Visualisez le raid en cours avec cat / proc / mdstat et notez ce que vous avez vu. </li><li>  Regardez la sortie des commandes: pvs, vgs, lvs, montez et notez exactement ce que vous avez vu. </li></ul><br></li></ol><br><p>  D√©crivez dans vos propres mots ce que vous avez fait et quel r√©sultat vous avez obtenu √† la suite de la t√¢che termin√©e. </p><br><p>  Apr√®s avoir termin√© cette t√¢che, il est recommand√© de sauvegarder le dossier avec la machine virtuelle ou de cr√©er une zone <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vagabonde</a> . </p><br><p>  R√©sultat: une machine virtuelle avec des disques ssd1, ssd2. </p><br><h2 id="zadanie-2-emulyaciya-otkaza-odnogo-iz-diskov">  T√¢che 2 (√©mulation de la panne d'un des disques) </h2><br><ol><li>  Si vous avez coch√© la case de remplacement √† chaud, vous pouvez supprimer les disques √† la vol√©e: <br><ul><li>  Supprimez le lecteur ssd1 dans les propri√©t√©s de la machine. </li><li>  Recherchez le r√©pertoire dans lequel les fichiers de votre machine virtuelle sont stock√©s et supprimez ssd1.vmdk. </li></ul></li><li>  Assurez-vous que votre machine virtuelle est toujours en cours d'ex√©cution. </li><li>  Red√©marrez la machine virtuelle et assurez-vous qu'elle fonctionne toujours </li><li>  V√©rifiez l'√©tat de la matrice RAID: <code>cat /proc/mdstat</code> </li><li>  Ajoutez un nouveau disque de la m√™me taille dans l'interface VM et nommez-le ssd3. </li><li>  Effectuer des op√©rations: <br><ul><li>  Regardez le nouveau disque arrivant sur le syst√®me avec la <code>fdisk -l</code> </li><li>  Copiez la table de partition de l'ancien disque vers le nouveau: <code>sfdisk -d /dev/XXXX | sfdisk /dev/YYY</code> <code>sfdisk -d /dev/XXXX | sfdisk /dev/YYY</code> </li><li>  Afficher le r√©sultat avec <code>fdisk -l</code> </li><li>  Ajoutez un nouveau disque √† la matrice de raid: <code>mdadm --manage /dev/md0 --add /dev/YYY</code> </li><li>  Voir le r√©sultat: <code>cat /proc/mdstat</code> .  Vous devriez voir que la synchronisation a commenc√©. </li></ul></li><li><p>  Vous devez maintenant synchroniser manuellement les partitions qui ne font pas partie du RAID.  Pour ce faire, nous utiliserons l'utilitaire dd, en copiant du disque "live" vers le nouveau que vous avez r√©cemment install√©: </p><br><pre> <code class="plaintext hljs">dd if=/dev/XXX of=/dev/YYY</code> </pre> <br></li><li>  Une fois la synchronisation termin√©e, installez grub sur le nouveau disque. </li><li>  Red√©marrez la machine virtuelle pour vous assurer que tout fonctionne. </li></ol><br><p>  D√©crivez dans vos propres mots ce que vous avez fait et quel r√©sultat vous avez obtenu √† la suite de la t√¢che termin√©e. </p><br><p>  <strong>R√©sultat:</strong> supprim√© le lecteur ssd1, enregistr√© le lecteur ssd2, ajout√© le lecteur ssd3. </p><br><h2 id="zadanie-3-dobavlenie-novyh-diskov-i-perenos-razdela">  T√¢che 3 (ajout de nouveaux disques et partitionnement) </h2><br><p>  Il s'agit de la t√¢che la plus difficile et la plus volumineuse pr√©sent√©e.  V√©rifiez soigneusement ce que vous faites et avec quels disques et partitions.  Il est recommand√© de prendre une copie avant de l'ex√©cuter.  Cette t√¢che, ind√©pendamment de la t√¢che num√©ro 2, peut √™tre effectu√©e apr√®s la t√¢che num√©ro 1, ajust√©e pour les noms de disque. </p><br><p>  La deuxi√®me partie de la mission de ce laboratoire devrait conduire exactement au m√™me √©tat qu'avant la fin de la premi√®re partie. </p><br><p>  Afin de vous faciliter le travail, je vous recommande de ne pas supprimer physiquement les disques de la machine h√¥te, mais de les d√©connecter uniquement dans les propri√©t√©s de la machine.  Du point de vue du syst√®me d'exploitation dans la machine virtuelle, cela se ressemblera exactement, mais dans ce cas, vous pouvez reconnecter le lecteur et continuer √† travailler en annulant quelques points au cas o√π vous auriez des probl√®mes.  Par exemple, vous avez peut-√™tre mal ex√©cut√© ou oubli√© de copier la partition / boot sur un nouveau disque.  Je ne peux que vous conseiller de v√©rifier plusieurs fois avec quels disques et partitions vous travaillez, et mieux encore, d'√©crire la correspondance des disques, des partitions et le num√©ro de disque "physique" sur un morceau de papier.  La commande <code>lsblk</code> dessine un arbre magnifique et compr√©hensible, utilisez-le aussi souvent que possible pour analyser ce que vous avez fait et ce qui doit √™tre fait. </p><br><p>  √Ä l'histoire ... </p><br><p>  Imaginez que votre serveur ait longtemps fonctionn√© sur 2 disques ssd, quand tout √† coup ... </p><br><ol><li><p>  Simulez une panne de disque ssd2 en supprimant le disque des propri√©t√©s de la machine virtuelle et en red√©marrant. </p><br></li><li><p>  Affichez l'√©tat actuel des disques et du RAID: </p><br><pre> <code class="plaintext hljs">cat /proc/mdstat fdisk -l lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li><p>  Vous avez de la chance - les autorit√©s ont autoris√© l'achat de plusieurs nouveaux disques: </p><br><p>  2 grands volumes SATA pour la t√¢che attendue depuis longtemps de d√©placer la section du journal vers un disque distinct.  2 SSD pour remplacer le d√©funt, ainsi que pour remplacer le fonctionnement encore. </p><br><p>  Gardez √† l'esprit que le panier du serveur prend en charge l'installation de seulement 4 lecteurs.  en m√™me temps, vous ne pouvez donc pas ajouter tous les disques √† la fois. </p><br><p>  Le volume du disque dur √† choisir 2 fois plus que le SSD. <br>  Le volume du SSD choisit 1,25 fois la taille de l'ancien SSD. </p><br></li><li><p>  Ajoutez un nouveau lecteur ssd, nommez-le ssd4, et apr√®s avoir ajout√© v√©rifiez ce qui s'est pass√©: </p><br><pre> <code class="plaintext hljs">fdisk -l lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li><p>  Tout d'abord, vous devez prendre soin de la s√©curit√© des donn√©es de l'ancien disque.  Cette fois, nous transf√©rerons des donn√©es √† l'aide de LVM: </p><br><ul><li><p>  Tout d'abord, vous devez copier la table de fichiers de l'ancien disque vers le nouveau: </p><br><pre> <code class="plaintext hljs">sfdisk -d /dev/XXX | sfdisk /dev/YYY</code> </pre> <br><p>  Remplacez les disques corrects au lieu de x, y et d√©terminez ce que fait cette commande. </p><br></li><li>  Ex√©cutez lsblk -o NAME, SIZE, FSTYPE, TYPE, MOUNTPOINT et comparez sa sortie avec l'appel pr√©c√©dent.  Qu'est-ce qui a chang√©? </li><li><p>  Utilisez la commande dd pour copier les donn√©es / boot sur le nouveau disque: </p><br><pre> <code class="plaintext hljs">dd if=/dev/XXX of=/dev/YYY</code> </pre> <br></li><li><p>  Si / boot reste mont√© sur l'ancien lecteur, il doit √™tre mont√© sur un lecteur actif: </p><br><pre> <code class="bash hljs">mount | grep boot <span class="hljs-comment"><span class="hljs-comment">#     lsblk #           ,     umount /boot #  /boot mount -a #      /etc/fstab. #      /dev/sda,        </span></span></code> </pre> <br></li><li><p>  Installez le chargeur de d√©marrage sur le nouveau lecteur ssd: </p><br><pre> <code class="plaintext hljs">grub-install /dev/YYY</code> </pre> <br><p>  Pourquoi faisons-nous cette op√©ration? </p><br></li><li><p>  Cr√©ez un nouveau r√©seau RAID avec un seul nouveau lecteur SSD inclus: </p><br><pre> <code class="plaintext hljs">mdadm --create --verbose /dev/md63 --level=1 --raid-devices=1 /dev/YYY</code> </pre> <br><p>  La commande ci-dessus ne fonctionnera pas sans sp√©cifier une cl√© sp√©ciale. Lisez l'aide et ajoutez cette cl√© √† la commande. </p><br></li><li>  Utilisez la commande cat / proc / mdstat pour v√©rifier le r√©sultat de votre op√©ration.  Qu'est-ce qui a chang√©? </li><li>  Ex√©cutez lsblk -o NAME, SIZE, FSTYPE, TYPE, MOUNTPOINT et comparez sa sortie avec l'appel pr√©c√©dent.  Qu'est-ce qui a chang√©? </li></ul><br></li><li><p>  L'√©tape suivante consiste √† configurer LVM </p><br><ul><li>  Ex√©cutez la commande pvs pour afficher des informations sur les volumes physiques actuels. </li><li><p>  Cr√©ez un nouveau volume physique en y incluant la matrice RAID pr√©c√©demment cr√©√©e: </p><br><pre> <code class="plaintext hljs">pvcreate /dev/md63</code> </pre> <br></li><li>  Ex√©cutez lsblk -o NAME, SIZE, FSTYPE, TYPE, MOUNTPOINT et comparez sa sortie avec l'appel pr√©c√©dent.  Qu'est-ce qui a chang√©? </li><li>  Ex√©cutez √† nouveau la commande pvs.  Qu'est-ce qui a chang√©? </li><li><p>  Augmentez la taille du syst√®me de groupe de volumes avec la commande suivante: </p><br><pre> <code class="plaintext hljs">vgextend system /dev/md63</code> </pre> <br></li><li><p>  Ex√©cutez les commandes et notez ce que vous avez vu et ce qui a chang√©. </p><br><pre> <code class="plaintext hljs">vgdisplay system -v pvs vgs lvs -a -o+devices</code> </pre> <br><p>  Sur quel disque physique sont LV var, log, root maintenant? </p><br></li><li><p>  D√©placez les donn√©es de l'ancien lecteur vers le nouveau en rempla√ßant les noms de p√©riph√©rique corrects. </p><br><pre> <code class="plaintext hljs">pvmove -i 10 -n /dev/system/root /dev/md0 /dev/md63</code> </pre> <br><p>  R√©p√©tez l'op√©ration pour tout le volume logique. </p><br></li><li><p>  Ex√©cutez les commandes et notez ce que vous avez vu et ce qui a chang√©. </p><br><pre> <code class="plaintext hljs">vgdisplay system -v pvs vgs lvs -a -o+devices lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li><p>  Changez notre VG en supprimant l'ancien raid.  Remplacez le nom de raid correct. </p><br><pre> <code class="plaintext hljs">vgreduce system /dev/md0</code> </pre> <br></li><li><p>  Ex√©cutez les commandes et notez ce que vous avez vu et ce qui a chang√©. </p><br><pre> <code class="plaintext hljs">lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT pvs vgs</code> </pre> <br></li><li>  Pour la beaut√© de l'image, remontez / d√©marrez sur le deuxi√®me lecteur ssd (ssd4) et ex√©cutez lsblk.  Par cons√©quent, rien ne doit √™tre mont√© sur le disque ssd3.  V√©rifiez soigneusement que la partition / boot n'est pas vide!  <code>ls /boot</code> devrait afficher plusieurs fichiers et dossiers.  Examinez ce qui est stock√© dans cette section et notez quel fichier / r√©pertoire est responsable de quoi. </li></ul><br></li><li><p>  Retirez le disque ssd3 et ajoutez ssd5, hdd1, hdd2 selon les savoirs traditionnels ci-dessus, pour finalement obtenir: </p><br><ul><li>  ssd4 - premier nouveau ssd </li><li>  ssd5 - deuxi√®me nouveau ssd </li><li>  hdd1 - le premier nouveau hdd </li><li>  hdd2 - deuxi√®me nouveau hdd </li></ul><br></li><li><p>  V√©rifiez ce qui s'est pass√© apr√®s l'ajout de disques: </p><br><pre> <code class="plaintext hljs">fdisk -l lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li><p>  Restaurons le tableau principal de raid: </p><br><ul><li><p>  Copiez la table de partition, en rempla√ßant les disques appropri√©s: </p><br><pre> <code class="plaintext hljs">sfdisk -d /dev/XXX | sfdisk /dev/YYY</code> </pre> <br></li><li><p>  Veuillez noter que lorsque nous avons copi√© la table de partition √† partir de l'ancien disque, il s'est av√©r√© que la nouvelle taille n'utilisait pas tout l'espace du disque dur.  Par cons√©quent, nous devrons bient√¥t redimensionner cette section et √©tendre le raid.  Voyez par vous-m√™me en entrant la commande: </p><br><pre> <code class="plaintext hljs">lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li></ul><br></li><li><p>  Copiez la partition de d√©marrage / boot de ssd4 vers ssd5: </p><br><pre> <code class="plaintext hljs">dd if=/dev/XXX of=/dev/YYY</code> </pre> <br></li><li><p>  Installez grub sur le nouveau disque (ssd5). </p><br></li><li><p>  Modifiez la taille de la deuxi√®me partition du lecteur ssd5. </p><br><ul><li><p>  Ex√©cutez l'utilitaire pour travailler avec la disposition du disque: </p><br><pre> <code class="plaintext hljs">fdisk /dev/XXX</code> </pre> <br></li><li>  Saisissez la touche d pour supprimer la partition existante (s√©lectionnez 2). </li><li>  Entrez la cl√© n pour cr√©er une nouvelle partition. </li><li>  Entrez la cl√© p pour indiquer le type de partition principale. </li><li>  Entrez la cl√© 2 pour que la nouvelle partition ait un deuxi√®me num√©ro. </li><li>  Premier secteur: appuyez sur Entr√©e pour accepter la taille de d√©but de section calcul√©e automatiquement. </li><li>  Dernier secteur: appuyez sur Entr√©e pour accepter la taille de section de fin calcul√©e automatiquement. </li><li>  Entrez la cl√© l pour voir une liste de tous les types de partitions possibles et y trouver un raid Linux automatique. </li><li>  Entrez la cl√© t pour changer le type de la partition cr√©√©e (2) et entrez le num√©ro trouv√© √† l'√©tape pr√©c√©dente. </li><li>  Entrez la touche w pour √©crire la modification sur le disque. </li></ul><br></li><li><p>  Relisez la table de partition et v√©rifiez le r√©sultat: </p><br><pre> <code class="plaintext hljs">partx -u /dev/XXX lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br><ul><li><p>  Ajoutez un nouveau disque √† la matrice de raid actuelle (n'oubliez pas de remplacer les bons disques): </p><br><pre> <code class="plaintext hljs">mdadm --manage /dev/md63 --add /dev/sda2</code> </pre> <br></li><li><p>  Nous √©tendons le nombre de disques de notre baie √† 2 pi√®ces: </p><br><pre> <code class="plaintext hljs">mdadm --grow /dev/md63 --raid-devices=2</code> </pre> <br></li><li><p>  Regardez le r√©sultat: nous avons 2 tableaux marqu√©s, mais les deux sections incluses dans ce tableau ont des tailles diff√©rentes: </p><br><pre> <code class="plaintext hljs">lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li></ul><br></li><li><p>  Augmentez la taille de la partition sur le disque ssd4 </p><br><ul><li><p>  Ex√©cutez l'utilitaire pour travailler avec la disposition du disque: </p><br><pre> <code class="plaintext hljs">fdisk /dev/XXX</code> </pre> <br></li><li>  Saisissez la touche d pour supprimer la partition existante (s√©lectionnez 2). </li><li>  Entrez la cl√© n pour cr√©er une nouvelle partition. </li><li>  Entrez la cl√© p pour indiquer le type de partition principale. </li><li>  Entrez la cl√© 2 pour que la nouvelle partition ait un deuxi√®me num√©ro. </li><li>  Premier secteur: appuyez sur Entr√©e pour accepter la taille de d√©but de section calcul√©e automatiquement. </li><li>  Dernier secteur: appuyez sur Entr√©e pour accepter la taille de section de fin calcul√©e automatiquement. </li><li>  √Ä la fin du balisage, s√©lectionnez Non pour laisser la signature que la section appartient au tableau. </li><li>  Entrez la touche w pour √©crire la modification sur le disque. </li></ul><br></li><li><p>  Nous relisons la table de partition et v√©rifions le r√©sultat. </p><br><pre> <code class="plaintext hljs">partx -u /dev/XXX lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br><p>  Veuillez noter que maintenant les partitions sda2, sdc2 sont plus grandes que la taille du p√©riph√©rique de raid. </p><br></li><li><p>  √Ä ce stade, la taille du raid peut maintenant √™tre √©tendue: </p><br><pre> <code class="bash hljs">mdadm --grow /dev/md63 --size=max lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT <span class="hljs-comment"><span class="hljs-comment"># check result</span></span></code> </pre> <br><p>  Parcourez lsblk et notez ce qui a chang√©. </p><br></li><li><p>  Cependant, m√™me si nous avons modifi√© la taille du raid, les tailles de vg root, var, log elles-m√™mes n'ont pas chang√©. </p><br><ul><li><p>  Regardez quelle est la taille du PV: </p><br><pre> <code class="bash hljs">pvs</code> </pre> <br></li><li><p>  Augmentez la taille de notre PV: </p><br><pre> <code class="bash hljs">pvresize /dev/md63</code> </pre> <br></li><li><p>  Regardez quelle est la taille du PV: </p><br><pre> <code class="bash hljs">pvs</code> </pre> <br></li></ul><br></li><li><p>  Ajoutez le nouvel endroit VG apparu, racine: </p><br><pre> <code class="bash hljs">lvs <span class="hljs-comment"><span class="hljs-comment">#     lvextend -l +50%FREE /dev/system/root lvextend -l +100%FREE /dev/system/var lvs #   </span></span></code> </pre> <br><p>  √Ä ce stade, vous avez termin√© la migration de la baie principale vers de nouveaux disques.  travailler avec ssd1, ssd2 est termin√©. </p><br></li><li><p>  Notre prochaine t√¢che consiste √† d√©placer / var / log vers de nouveaux disques, pour cela nous allons cr√©er un nouveau tableau et lvm sur les disques durs. </p><br><ul><li><p>  Voyons quels noms ont les nouveaux disques durs: </p><br><pre> <code class="bash hljs">fdisk -l</code> </pre> <br></li><li><p>  Cr√©ez un tableau de raid: </p><br><pre> <code class="bash hljs">mdadm --create /dev/md127 --level=1 --raid-devices=2 /dev/sdc /dev/sdd</code> </pre> <br></li><li><p>  Cr√©ez un nouveau PV dans le raid √† partir de grands disques: </p><br><pre> <code class="bash hljs">pvcreate data /dev/md127</code> </pre> <br></li><li><p>  Dans ce PV, cr√©ez un groupe appel√© donn√©es: </p><br><pre> <code class="bash hljs">vgcreate data /dev/md127</code> </pre> <br></li><li><p>  Cr√©ez un volume logique avec la taille de tout l'espace libre et appelez-le val_log: </p><br><pre> <code class="bash hljs">lvcreate -l 100%FREE -n var_log data <span class="hljs-comment"><span class="hljs-comment"># lvs #  </span></span></code> </pre> <br></li><li><p>  Formatez la partition cr√©√©e dans ext4: </p><br><pre> <code class="bash hljs">mkfs.ext4 /dev/mapper/data-var_log</code> </pre> <br></li><li><p>  Voyons le r√©sultat: </p><br><pre> <code class="bash hljs">lsblk</code> </pre> <br></li></ul><br></li><li><p>  Transf√©rer les donn√©es du journal de l'ancienne section vers la nouvelle </p><br><ul><li><p>  Nous allons monter un nouveau stockage de journaux temporaire: </p><br><pre> <code class="plaintext hljs">mount /dev/mapper/data-var_log /mnt</code> </pre> <br></li><li><p>  Synchronisons les sections: </p><br><pre> <code class="bash hljs">apt install rsync rsync -avzr /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/ /mnt/</code> </pre> <br></li><li><p>  D√©couvrez quels processus sont en cours d'ex√©cution avec / var / log maintenant: </p><br><pre> <code class="bash hljs">apt install lsof lsof | grep <span class="hljs-string"><span class="hljs-string">'/var/log'</span></span></code> </pre> <br></li><li><p>  Nous arr√™tons ces processus: </p><br><pre> <code class="bash hljs">systemctl stop rsyslog.service syslog.socket</code> </pre> <br></li><li><p>  Nous effectuerons la synchronisation finale des partitions (des donn√©es qui auraient pu √™tre modifi√©es depuis la derni√®re synchronisation): </p><br><pre> <code class="bash hljs">rsync -avzr /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/ /mnt/</code> </pre> <br></li><li><p>  √âchangez les sections: </p><br><pre> <code class="bash hljs">umount /mnt umount /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span> mount /dev/mapper/data-var_log /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span></code> </pre> <br></li><li><p>  V√©rifiez ce qui s'est pass√©: </p><br><pre> <code class="bash hljs">lsblk</code> </pre> <br></li></ul><br></li><li><p>  Modifier / etc / fstab </p><br><p>  fstab - un fichier dans lequel les r√®gles sont √©crites en fonction des partitions qui seront mont√©es au d√©marrage.  Notre t√¢che consiste √† trouver la ligne dans laquelle / var / log est mont√© et √† fixer le p√©riph√©rique de <code>system-log</code> √† <code>data-var_log</code> . </p><br></li><li><p>  La chose la plus importante √† ce stade est de ne pas oublier de changer la table de partition (ext4, par exemple).  √âtant donn√© que peu importe la fa√ßon dont nous modifions toutes sortes de raid, lvm - jusqu'√† ce que le syst√®me de fichiers de la partition soit averti que la taille de la partition a chang√©, nous ne pourrons pas utiliser le nouvel espace.  Utilisez la commande <code>resize2fs</code> pour modifier le FS. </p><br></li><li><p>  Accord final </p><br><ul><li>  Red√©marrons.  Si vous avez tout fait correctement, vous vous retrouverez √† nouveau dans votre syst√®me d'exploitation (cela est n√©cessaire pour vous assurer que tout fonctionne. Cette √©tape n'a de sens que pour l'auto-test) </li><li><p>  V√©rifiez que tout ce que nous voulions faire √©tait vraiment fait: </p><br><pre> <code class="bash hljs">pvs lvs vgs lsblk cat /proc/mdstat</code> </pre> <br></li></ul><br></li><li><p>  [FACULTATIF] Suivez les √©tapes </p><br><ul><li>  Red√©marrez en appuyant sur F12 pour indiquer diff√©rents disques lors du d√©marrage, afin de vous assurer que vous pouvez d√©marrer √† partir de l'un des disques SSD, afin que nous n'ayons pas peur que l'un d'entre eux √©choue. </li><li><p>  Vous avez maintenant le journal LV inutile dans le syst√®me VG.  R√©partissez cet espace entre root ou var, mais au lieu d'utiliser la construction 100% FREE, sp√©cifiez la taille avec vos mains en utilisant le commutateur -L: </p><br><pre> <code class="bash hljs">-L 500M</code> </pre> <br></li><li>  Corrigez le probl√®me avec le fait que / boot se trouve sur deux partitions sans synchronisation, vous n'avez pas besoin de le faire de la bonne mani√®re, ici il est ajout√© √† titre d'exemple.  N'oubliez pas de copier le contenu de / boot quelque part. </li><li>  Cr√©ez un nouveau raid et incluez sda1, sda2 dedans. </li><li>  Incluez ces partitions dans votre raid existant et restaurez / d√©marrez essentiellement le raid, mais sans le monter plus. </li></ul><br></li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr450896/">https://habr.com/ru/post/fr450896/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr450886/index.html">Contexte: comment fonctionnent les voitures √† hydrog√®ne et quand elles apparaissent sur les routes</a></li>
<li><a href="../fr450888/index.html">Swift: Tamis d'√âratosth√®ne</a></li>
<li><a href="../fr450890/index.html">Google I / O News 2019: Pixel 3a, Android Q, Kotlin et plus</a></li>
<li><a href="../fr450892/index.html">La vitesse de stockage est-elle adapt√©e √† etcd? Demandez √† fio</a></li>
<li><a href="../fr450894/index.html">√Ä propos des antennes pour les plus petits</a></li>
<li><a href="../fr450898/index.html">D√©veloppement d'interface sur plusieurs √©crans. √âtape pour utiliser l'IA</a></li>
<li><a href="../fr450902/index.html">Vous voulez des employ√©s fid√®les - commencez par vous-m√™me</a></li>
<li><a href="../fr450904/index.html">Aspects pratiques du d√©ploiement d'une application ASP.NET Core ancr√©e sur Heroku</a></li>
<li><a href="../fr450906/index.html">Comment commencer √† vivre et √† faire pousser de la laitue</a></li>
<li><a href="../fr450908/index.html">R√©seaux de liste noire pour Asterisk</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
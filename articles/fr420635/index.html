<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÜñ üì® üß£ AI, cours pratique. Le mod√®le de base pour reconna√Ætre les √©motions dans les images üë©üèø‚Äçü§ù‚Äçüë®üèº ‚ôâÔ∏è üë®üèΩ‚Äçüöí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans cet article, nous allons construire un mod√®le de base d'un r√©seau neuronal convolutif capable de reconna√Ætre les √©motions dans les images. La rec...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, cours pratique. Le mod√®le de base pour reconna√Ætre les √©motions dans les images</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/420635/"><img src="https://habrastorage.org/webt/kp/it/ob/kpitobaccifc3jg-td-z6lgmz9i.jpeg"><br><br>  Dans cet article, nous allons construire un mod√®le de base d'un r√©seau neuronal convolutif capable de <i>reconna√Ætre les √©motions</i> dans les images.  La reconnaissance des √©motions dans notre cas est une t√¢che de classification binaire, dont le but est de diviser les images en positives et n√©gatives. <br><br>  Tous les codes, documents de bloc-notes et autres documents, y compris le Dockerfile, peuvent √™tre trouv√©s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Les donn√©es</font> </h2><br>  La premi√®re √©tape de pratiquement toutes les t√¢ches d'apprentissage automatique consiste √† comprendre les donn√©es.  Faisons-le. <br><br><h3>  <font color="#0071c5">Structure du jeu de donn√©es</font> </h3><br>  Les donn√©es brutes peuvent √™tre t√©l√©charg√©es <a href="">ici</a> (dans le document <i>Baseline.ipynb</i> , toutes les actions de cette section sont effectu√©es automatiquement).  Initialement, les donn√©es sont dans l'archive au format Zip *.  D√©ballez-le et familiarisez-vous avec la structure des fichiers re√ßus. <br><br><img src="https://habrastorage.org/webt/wm/wj/ne/wmwjne07sdpbzoitoa0xxz1zcie.png"><br><br>  Toutes les images sont stock√©es dans le catalogue ¬´dataset 50:50¬ª et r√©parties entre ses deux sous-r√©pertoires, dont le nom correspond √† leur classe - Negative et Positive.  Veuillez noter que la t√¢che est un peu <i>d√©s√©quilibr√©e</i> - 53% des images sont positives et seulement 47% sont n√©gatives.  En r√®gle g√©n√©rale, les donn√©es relatives aux probl√®mes de classification sont consid√©r√©es comme d√©s√©quilibr√©es si le nombre d'exemples dans diff√©rentes classes varie de mani√®re tr√®s significative.  Il existe un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">certain nombre de fa√ßons de</a> travailler avec des donn√©es non √©quilibr√©es - par exemple, sur√©chantillonnage, sur√©chantillonnage, modification du poids des donn√©es, etc. Dans notre cas, le d√©s√©quilibre est insignifiant et ne devrait pas affecter consid√©rablement le processus d'apprentissage.  Il suffit de se rappeler que le classificateur na√Øf, donnant toujours la valeur ¬´positive¬ª, fournira une valeur de pr√©cision d'environ 53% pour cet ensemble de donn√©es. <br><br>  Regardons quelques images de chaque classe. <br><br>  <b>N√©gatif</b> <br><br><img src="https://habrastorage.org/webt/q4/5d/fc/q45dfcprljvv5tnm0aqvwwgs0uy.jpeg"><br><br><img src="https://habrastorage.org/webt/ep/0p/4q/ep0p4qkimflvz7euzaam1bc39a8.jpeg"><br><br><img src="https://habrastorage.org/webt/dj/ep/px/djeppxcpw5hgct0melwhlvjafsu.jpeg"><br><br>  <b>Positif</b> <br><br><img src="https://habrastorage.org/webt/w6/rs/5j/w6rs5je45iwv-m22jf4vjomcs1s.jpeg"><br><br><img src="https://habrastorage.org/webt/fa/r4/af/far4afuqyyajc3xfqjwnj98xkbo.jpeg"><br><br><img src="https://habrastorage.org/webt/ky/ae/q2/kyaeq2nx8wqpkmnba9y2mugejai.jpeg"><br><br>  √Ä premi√®re vue, les images de diff√©rentes classes sont en fait diff√©rentes les unes des autres.  Cependant, faisons une √©tude plus approfondie et essayons de trouver de mauvais exemples - des images similaires appartenant √† diff√©rentes classes. <br><br>  Par exemple, nous avons environ 90 images de serpents √©tiquet√©s n√©gatifs et environ 40 images tr√®s similaires de serpents √©tiquet√©s positifs. <br><br>  <b>Image positive d'un serpent</b> <br><br><img src="https://habrastorage.org/webt/-m/es/5g/-mes5gboq8vn6p28etujmipmjme.jpeg"><br><br>  <b>Image n√©gative d'un serpent</b> <br><br><img src="https://habrastorage.org/webt/np/1f/dv/np1fdvdekusz5cokd96cjou7smu.jpeg"><br><br>  La m√™me dualit√© se produit avec les araign√©es (130 images n√©gatives et 20 images positives), la nudit√© (15 images n√©gatives et 45 images positives) et certaines autres classes.  On a le sentiment que le marquage des images a √©t√© effectu√© par diff√©rentes personnes, et leur perception de la m√™me image peut diff√©rer.  Par cons√©quent, l'√©tiquetage contient son incoh√©rence inh√©rente.  Ces deux images de serpents sont presque identiques, tandis que diff√©rents experts les ont attribu√©es √† diff√©rentes classes.  Ainsi, nous pouvons conclure qu'il est √† peine possible d'assurer une pr√©cision de 100% lorsque vous travaillez avec cette t√¢che en raison de sa nature.  Nous pensons qu'une estimation plus r√©aliste de la pr√©cision serait une valeur de 80% - cette valeur est bas√©e sur la proportion d'images similaires trouv√©es dans diff√©rentes classes lors d'un contr√¥le visuel pr√©liminaire. <br><br><h3>  <font color="#0071c5">S√©paration du processus de formation / v√©rification</font> </h3><br>  Nous nous effor√ßons toujours de cr√©er le meilleur mod√®le possible.  Mais quelle est la signification de ce concept?  Il existe de nombreux crit√®res diff√©rents pour cela, tels que: la qualit√©, le d√©lai (apprentissage + sortie) et la consommation de m√©moire.  Certains d'entre eux peuvent √™tre mesur√©s facilement et objectivement (par exemple, le temps et la taille de la m√©moire), tandis que d'autres (la qualit√©) sont beaucoup plus difficiles √† d√©terminer.  Par exemple, votre mod√®le peut d√©montrer une pr√©cision de 100% lors de l'apprentissage √† partir d'exemples qui ont √©t√© utilis√©s √† de nombreuses reprises, mais ne fonctionne pas avec de nouveaux exemples.  Ce probl√®me est appel√© <i>surapprentissage</i> et est l'un des plus importants dans l'apprentissage automatique.  Il y a aussi le probl√®me du sous- <i>ajustement</i> : dans ce cas, le mod√®le ne peut pas apprendre des donn√©es pr√©sent√©es et montre de mauvaises pr√©dictions m√™me lors de l'utilisation d'un ensemble de donn√©es d'entra√Ænement fixe. <br><br>  Pour r√©soudre le probl√®me du sur-ajustement, la technique dite de <i>maintien d'une partie des √©chantillons est utilis√©e</i> .  Son id√©e principale est de diviser les donn√©es source en deux parties: <br><br><ul><li>  <i>Un ensemble de formation</i> , qui constitue g√©n√©ralement la majeure partie de l'ensemble de donn√©es et est utilis√© pour former le mod√®le. </li><li>  <i>L'ensemble de test est</i> g√©n√©ralement une petite partie des donn√©es source, qui est divis√©e en deux parties avant d'effectuer toutes les proc√©dures de formation.  Cet ensemble n'est pas du tout utilis√© en formation et est consid√©r√© comme de nouveaux exemples pour tester le mod√®le apr√®s la fin de la formation. </li></ul><br>  En utilisant cette m√©thode, nous pouvons observer √† quel point notre mod√®le se <i>g√©n√©ralise</i> (c'est-√†-dire qu'il fonctionne avec des exemples inconnus auparavant). <br><br>  Cet article utilisera un rapport 4/1 pour les ensembles de formation et de test.  Une autre technique que nous utilisons est la <i>stratification</i> dite.  Ce terme fait r√©f√©rence au partitionnement de chaque classe ind√©pendamment de toutes les autres classes.  Cette approche permet de maintenir le m√™me √©quilibre entre les tailles de classe dans les ensembles de formation et de test.  La stratification utilise implicitement l'hypoth√®se que la distribution des exemples ne change pas lorsque les donn√©es source changent et reste la m√™me lors de l'utilisation de nouveaux exemples. <br><br><img src="https://habrastorage.org/webt/pn/gq/lz/pngqlzmf15cnm-4cwjvblndwpsg.png"><br><br>  Nous illustrons le concept de stratification avec un exemple simple.  Supposons que nous ayons quatre groupes / classes de donn√©es contenant un nombre appropri√© d'objets: enfants (5), adolescents (10), adultes (80) et personnes √¢g√©es (5);  voir photo √† droite (de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikipedia</a> ).  Maintenant, nous devons diviser ces donn√©es en deux ensembles d'√©chantillons dans un rapport de 3/2.  Lors de la stratification des exemples, la s√©lection des objets se fera ind√©pendamment de chaque groupe: 2 objets du groupe d'enfants, 4 objets du groupe d'adolescents, 32 objets du groupe d'adultes et 2 objets du groupe de personnes √¢g√©es.  Le nouvel ensemble de donn√©es contient 40 objets, ce qui correspond exactement aux 2/5 des donn√©es d'origine.  Dans le m√™me temps, l'√©quilibre entre les classes du nouvel ensemble de donn√©es correspond √† leur √©quilibre dans les donn√©es source. <br><br>  Toutes les actions ci-dessus sont impl√©ment√©es dans une seule fonction, qui est appel√©e <i>prepare_data</i> ;  cette fonction se trouve dans le fichier Python <i>utils.py</i> .  Cette fonction charge les donn√©es, les divise en ensembles d'apprentissage et de test √† l'aide d'un nombre al√©atoire fixe (pour une lecture ult√©rieure), puis r√©partit les donn√©es en cons√©quence entre les r√©pertoires du disque dur pour une utilisation ult√©rieure. <br><br><h3>  <font color="#0071c5">Pr√©traitement et augmentation</font> </h3><br>  Dans l'un des articles pr√©c√©dents, les actions de pr√©traitement et les raisons possibles de leur utilisation sous forme d'augmentation des donn√©es ont √©t√© d√©crites.  Les r√©seaux de neurones convolutifs sont des mod√®les assez complexes, et de grandes quantit√©s de donn√©es sont n√©cessaires pour les former.  Dans notre cas, il n'y a que 1600 exemples - ce n'est bien s√ªr pas suffisant. <br><br>  Par cons√©quent, nous voulons √©tendre l'ensemble de donn√©es utilis√© par l' <i>augmentation des</i> donn√©es.  Conform√©ment aux informations contenues dans l'article sur le pr√©traitement des donn√©es, la biblioth√®que Keras * offre la possibilit√© d'augmenter les donn√©es √† la vol√©e lors de leur lecture sur le disque dur.  Cela peut √™tre fait via la classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ImageDataGenerator</a> . <br><br><img src="https://habrastorage.org/webt/3m/j8/oe/3mj8oewbjg3j8eriel5opmj43cc.png"><br><br>  Deux instances des g√©n√©rateurs sont cr√©√©es ici.  La premi√®re instance est destin√©e √† la formation et utilise de nombreuses transformations al√©atoires - telles que la rotation, le d√©calage, la convolution, la mise √† l'√©chelle et la rotation horizontale - lors de la lecture des donn√©es du disque et de leur transfert vers le mod√®le.  Par cons√©quent, le mod√®le re√ßoit les exemples convertis et chaque exemple re√ßu par le mod√®le est unique en raison de la nature al√©atoire de cette conversion.  La deuxi√®me copie sert √† la v√©rification et ne fait que zoomer sur les images.  Les g√©n√©rateurs d'apprentissage et de test n'ont qu'une seule transformation commune: le zoom.  Pour assurer la stabilit√© de calcul du mod√®le, il est n√©cessaire d'utiliser la plage [0;  1] au lieu de [0;  255]. <br><br><h2>  <font color="#0071c5">Architecture du mod√®le</font> </h2><br>  Apr√®s avoir √©tudi√© et pr√©par√© les donn√©es initiales, l'√©tape de cr√©ation du mod√®le suit.  Puisqu'une petite quantit√© de donn√©es est √† notre disposition, nous allons construire un mod√®le relativement simple afin de pouvoir le former de mani√®re appropri√©e et √©liminer la situation de sur-ajustement.  Essayons l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">architecture de</a> style <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VGG</a> , mais utilisons moins de couches et de filtres. <br><br><img src="https://habrastorage.org/webt/xa/dl/ae/xadlae7ebpbynxk60facw3_bxho.png"><br><br><img src="https://habrastorage.org/webt/2b/xr/cy/2bxrcyazsu_gasst_aqr5ao7ayu.png"><br><br>  L'architecture du r√©seau comprend les parties suivantes: <br>  <b>[Couche de convolution + couche de convolution + s√©lection de la valeur maximale] √ó 2</b> <br>  La premi√®re partie contient deux couches convolutives superpos√©es avec 64 filtres (avec taille 3 et √©tape 2) et une couche pour s√©lectionner la valeur maximale (avec taille 2 et √©tape 2) situ√©e apr√®s eux.  Cette partie est √©galement commun√©ment appel√©e <i>unit√© d'extraction de caract√©ristiques</i> , car les filtres extraient efficacement des caract√©ristiques significatives des donn√©es d'entr√©e (voir l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©sentation des r√©seaux de neurones convolutifs pour la classification des images</a> pour plus d'informations). <br><br>  <b>Alignement</b> <br><br>  Cette partie est obligatoire, car des tenseurs quadridimensionnels sont obtenus en sortie de la partie convolutionnelle (exemples, hauteur, largeur et canaux).  Cependant, pour une couche ordinaire enti√®rement connect√©e, nous avons besoin d'un tenseur bidimensionnel (exemples, caract√©ristiques) en entr√©e.  Par cons√©quent, il est n√©cessaire d' <i>aligner le</i> tenseur autour des trois derniers axes afin de les combiner en un seul axe.  En fait, cela signifie que nous consid√©rons chaque point de chaque carte d'entit√©s comme une propri√©t√© distincte et les alignons en un seul vecteur.  La figure ci-dessous montre un exemple d'une image 4 √ó 4 avec 128 canaux, qui est align√©e dans un vecteur √©tendu avec une longueur de 1024 √©l√©ments. <br><br><img src="https://habrastorage.org/webt/zs/-f/_h/zs-f_h8_mr6flzz62vo21qttt0u.png"><br><br>  <b>[Couche compl√®te + m√©thode d'exclusion] √ó 2</b> <br><br>  Voici la <i>partie classification du</i> r√©seau.  Elle prend une vue align√©e des caract√©ristiques des images et essaie de les classer de la meilleure fa√ßon possible.  Cette partie du r√©seau est constitu√©e de deux blocs superpos√©s constitu√©s d'une couche enti√®rement connect√©e et d' <i>une m√©thode d'exclusion</i> .  Nous avons d√©j√† fait la connaissance de couches enti√®rement connect√©es - il s'agit g√©n√©ralement de couches avec une connexion enti√®rement connect√©e.  Mais qu'est-ce que la ¬´m√©thode d'exclusion¬ª?  La m√©thode d'exclusion est une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">technique de r√©gularisation</a> qui permet d'√©viter le sur-ajustement.  Un des signes possibles de sur-ajustement est des valeurs extr√™mement diff√©rentes des coefficients de poids (ordres de grandeur).  Il existe de nombreuses fa√ßons de r√©soudre ce probl√®me, notamment la r√©duction de poids et la m√©thode d'√©limination.  L'id√©e de la m√©thode d'√©limination est de d√©connecter les neurones al√©atoires pendant l'entra√Ænement (la liste des neurones d√©connect√©s doit √™tre mise √† jour apr√®s chaque package / √®re de formation).  Cela emp√™che tr√®s fortement d'obtenir des valeurs compl√®tement diff√©rentes pour les coefficients de pond√©ration - de cette fa√ßon, le r√©seau est r√©gularis√©. <br><br><img src="https://habrastorage.org/webt/1x/g5/vw/1xg5vwjp4syjmujonokwl9i-ilo.png"><br><br>  Un exemple de l'application de la m√©thode d'exclusion (la figure est tir√©e de l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">M√©thode d'exclusion: un moyen facile de pr√©venir le sur-ajustement dans les r√©seaux de neurones</a> ): <br><br>  <b>Module sigmo√Øde</b> <br><br>  La couche de sortie doit correspondre √† l'√©nonc√© du probl√®me.  Dans ce cas, nous traitons du probl√®me de classification binaire, par cons√©quent, nous avons besoin d'un neurone de sortie avec une fonction d'activation <i>sigmo√Øde</i> , qui estime la probabilit√© P d'appartenir √† la classe avec le num√©ro 1 (dans notre cas, ce seront des images positives).  Ensuite, la probabilit√© d'appartenir √† la classe avec le num√©ro 0 (images n√©gatives) peut facilement √™tre calcul√©e comme 1 - P. <br><br><h2>  <font color="#0071c5">Param√®tres et options de formation</font> </h2><br>  Nous avons choisi l'architecture du mod√®le et l'avons sp√©cifi√©e √† l'aide de la biblioth√®que Keras pour le langage Python.  De plus, avant de commencer la formation du mod√®le, il est n√©cessaire de la <i>compiler</i> . <br><br><img src="https://habrastorage.org/webt/th/pv/l8/thpvl8hahgpnyucfsfhxpk5qq8w.png"><br><br>  Au stade de la compilation, le mod√®le est r√©gl√© pour la formation.  Dans ce cas, trois param√®tres principaux doivent √™tre sp√©cifi√©s: <br><br><ul><li>  <i>L'optimiseur</i> .  Dans ce cas, nous utilisons l'optimiseur par d√©faut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Adam</a> *, qui est un type d'algorithme de descente de gradient stochastique avec un moment et une vitesse d'apprentissage adaptative (pour plus d'informations, voir l'entr√©e de blog de S.Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©sentation des algorithmes d'optimisation de la descente de gradient</a> ). </li><li>  <i>Fonction de perte</i> .  Notre t√¢che est un probl√®me de classification binaire, il serait donc appropri√© d'utiliser l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">entropie crois√©e binaire</a> comme fonction de perte. </li><li>  <i>Mesures</i> .  Il s'agit d'un argument facultatif avec lequel vous pouvez sp√©cifier des mesures suppl√©mentaires √† suivre pendant le processus de formation.  Dans ce cas, nous devons suivre la pr√©cision avec la fonction objectif. </li></ul><br>  Nous sommes maintenant pr√™ts √† former le mod√®le.  Veuillez noter que la proc√©dure de formation est effectu√©e √† l'aide des g√©n√©rateurs initialis√©s dans la section pr√©c√©dente. <br><br>  Le nombre d'√©poques est un autre hyperparam√®tre qui peut √™tre personnalis√©.  Ici, nous lui attribuons simplement une valeur de 10. Nous voulons √©galement enregistrer le mod√®le et l'historique d'apprentissage afin de pouvoir le t√©l√©charger plus tard. <br><br><img src="https://habrastorage.org/webt/mt/3o/cd/mt3ocd0xfdxmshq_7tv1xptw5de.png"><br><br><h2>  <font color="#0071c5">√âvaluation</font> </h2><br>  Voyons maintenant √† quel point notre mod√®le fonctionne.  Tout d'abord, nous consid√©rons le changement de m√©triques dans le processus d'apprentissage. <br><br><img src="https://habrastorage.org/webt/d-/_j/1l/d-_j1lty0qibl5gkwrhy3avbgzq.png"><br><br>  Sur la figure, vous pouvez voir que l'entropie crois√©e de la v√©rification et de la pr√©cision ne diminue pas avec le temps.  De plus, la m√©trique de pr√©cision pour l'ensemble d'apprentissage et de test fluctue simplement autour de la valeur d'un classificateur al√©atoire.  La pr√©cision finale de l'ensemble de test est de 55%, ce qui n'est que l√©g√®rement meilleur qu'une estimation al√©atoire. <br><br>  Voyons comment les pr√©dictions du mod√®le sont r√©parties entre les classes.  Pour cela, il est n√©cessaire de cr√©er et de visualiser une <i>matrice d'inexactitudes</i> √† l'aide de la fonction correspondante du package Sklearn * pour le langage Python. <br>  Chaque cellule de la matrice des inexactitudes a son propre nom: <br><br><img src="https://habrastorage.org/webt/p4/9j/mj/p49jmjgtuc4fhqxfd_szqm6qvtw.png"><br><br><ul><li>  True Positive Rate = TPR (cellule sup√©rieure droite) repr√©sente la proportion d'exemples positifs (classe 1, c'est-√†-dire <i>les</i> √©motions <i>positives</i> dans notre cas), correctement class√©s comme positifs. </li><li>  Taux de faux positifs = FPR (cellule inf√©rieure droite) repr√©sente la proportion d'exemples positifs qui sont incorrectement class√©s comme <i>n√©gatifs</i> (classe 0, c'est-√†-dire les √©motions n√©gatives). </li><li>  True Negative Rate = TNR (cellule inf√©rieure gauche) repr√©sente la proportion d'exemples n√©gatifs correctement class√©s comme n√©gatifs. </li><li>  Taux de faux n√©gatifs = FNR (cellule sup√©rieure gauche) repr√©sente la proportion d'exemples n√©gatifs qui sont incorrectement class√©s comme positifs. </li></ul><br>  Dans notre cas, le TPR et le FPR sont proches de 1. Cela signifie que presque tous les objets ont √©t√© class√©s comme positifs.  Ainsi, notre mod√®le n'est pas tr√®s √©loign√© du mod√®le de base na√Øf avec des pr√©dictions constantes d'une classe plus large (dans notre cas, ce sont des images positives). <br><br>  Une autre m√©trique int√©ressante qui est int√©ressante √† observer est la courbe de performance du r√©cepteur (courbe ROC) et la zone sous cette courbe (ROC AUC).  Une d√©finition formelle de ces concepts peut √™tre trouv√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  En un mot, la courbe ROC montre √† quel point le classificateur binaire fonctionne. <br><br>  Le classificateur de notre r√©seau neuronal convolutif a un module sigmo√Øde en sortie, qui attribue la probabilit√© de l'exemple √† la classe 1. Supposons maintenant que notre classificateur montre du bon travail et attribue des valeurs de faible probabilit√© pour les exemples de classe 0 (l'histogramme vert dans la figure ci-dessous) des valeurs de probabilit√© √©lev√©es pour les exemples Classe 1 (histogramme bleu). <br><br><img src="https://habrastorage.org/webt/wq/e_/us/wqe_usitkajallhk1ymcsq472pu.png"><br><br>  La courbe ROC montre comment l'indicateur TPR d√©pend de l'indicateur FPR lors du d√©placement du seuil de classification de 0 √† 1 (figure de droite, partie sup√©rieure).  Pour une meilleure compr√©hension du concept de seuil, rappelez-vous que nous avons la probabilit√© d'appartenir √† la classe 1 pour chaque exemple.  Cependant, la probabilit√© n'est pas encore une √©tiquette de classe.  Par cons√©quent, il doit √™tre compar√© √† un seuil pour d√©terminer √† quelle classe l'exemple appartient.  Par exemple, si la valeur seuil est 1, tous les exemples doivent √™tre class√©s comme appartenant √† la classe 0, car la valeur de probabilit√© ne peut pas √™tre sup√©rieure √† 1, tandis que les valeurs des indicateurs FPR et TPR seront √©gales √† 0 (car aucun des √©chantillons n'est class√© comme positif )  Cette situation correspond au point le plus √† gauche de la courbe ROC.  De l'autre c√¥t√© de la courbe, il y a un point o√π la valeur de seuil est 0: cela signifie que tous les √©chantillons sont class√©s comme appartenant √† la classe 1, et les valeurs de TPR et de FPR sont √©gales √† 1. Les points interm√©diaires montrent le comportement de la d√©pendance TPR / FPR lorsque la valeur de seuil change. <br><br>  La ligne diagonale sur le graphique correspond √† un classificateur al√©atoire.  Mieux notre classificateur fonctionne, plus sa courbe est proche du point sup√©rieur gauche du graphique.  Ainsi, l'indicateur objectif de la qualit√© du classificateur est l'aire sous la courbe ROC (indicateur ROC AUC).  La valeur de cet indicateur doit √™tre aussi proche que possible de 1. La valeur AUC de 0,5 correspond √† un classificateur al√©atoire. <br><br>  L'AUC de notre mod√®le (voir la figure ci-dessus) est de 0,57, ce qui est loin d'√™tre le meilleur r√©sultat. <br><br><img src="https://habrastorage.org/webt/oo/vu/-t/oovu-t0vyxvlbgb4zgp4qyvodsw.png"><br><br>  Toutes ces mesures indiquent que le mod√®le r√©sultant n'est que l√©g√®rement meilleur que le classificateur al√©atoire.  Il y a plusieurs raisons √† cela, les principales sont d√©crites ci-dessous: <br><br><ul><li>  Tr√®s petite quantit√© de donn√©es pour la formation, insuffisante pour mettre en √©vidence les traits caract√©ristiques des images.  M√™me l'augmentation des donn√©es ne pouvait pas aider dans ce cas. </li><li>  Un mod√®le de r√©seau de neurones convolutionnel relativement complexe (par rapport √† d'autres mod√®les d'apprentissage automatique) avec un grand nombre de param√®tres. </li></ul><br><h2>  <font color="#0071c5">Conclusion</font> </h2><br>  Dans cet article, nous avons cr√©√© un mod√®le de r√©seau de neurones convolutionnel simple pour reconna√Ætre les √©motions dans les images.  Dans le m√™me temps, au stade de la formation, un certain nombre de m√©thodes ont √©t√© utilis√©es pour augmenter les donn√©es, et le mod√®le a √©galement √©t√© √©valu√© √† l'aide d'un ensemble de param√®tres tels que la pr√©cision, la courbe ROC, l'AUC ROC et la matrice d'impr√©cision.  Le mod√®le a montr√© des r√©sultats, seulement quelques-uns des meilleurs al√©atoires.       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420635/">https://habr.com/ru/post/fr420635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420625/index.html">KDD 2018, Day One, tutoriels</a></li>
<li><a href="../fr420627/index.html">Programmation asynchrone C #: Comment faites-vous avec les performances?</a></li>
<li><a href="../fr420629/index.html">PHP Digest n ¬∞ 137 (6-20 ao√ªt 2018)</a></li>
<li><a href="../fr420631/index.html">Nous n'avons pas peur des "nuages"</a></li>
<li><a href="../fr420633/index.html">√âcrire un exportateur GeoIP pour Prometheus avec des visualisations dans Grafana en 15 minutes</a></li>
<li><a href="../fr420637/index.html">Test de l'imprimante 3D WANHAO D9 / 300: Vid√©o</a></li>
<li><a href="../fr420639/index.html">Anti-mod√®les Akka: trop d'acteurs</a></li>
<li><a href="../fr420641/index.html">Le support technique de 3CX r√©pond: sauvegarde et restauration de 3CX √† partir de la ligne de commande</a></li>
<li><a href="../fr420643/index.html">Presque tout est pareil, seulement 10 fois moins cher</a></li>
<li><a href="../fr420645/index.html">Des ing√©nieurs d'embauche r√©alistes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
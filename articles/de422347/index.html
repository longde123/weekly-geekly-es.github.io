<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåù ‚úíÔ∏è üéôÔ∏è Migration einer echten Anwendung von eigenst√§ndigem MySQL zu Percona XtraDB Cluster üôèüèø üö¥üèæ üî¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Leider gibt es im Internet nicht gen√ºgend Informationen √ºber die Migration realer Anwendungen und den Produktionsbetrieb des Percona XtraDB-Clusters (...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Migration einer echten Anwendung von eigenst√§ndigem MySQL zu Percona XtraDB Cluster</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422347/"><img src="https://habrastorage.org/getpro/habr/post_images/2b3/23e/2d3/2b323e2d35539763c7a0d17a4694d5af.png" alt="Bild"><br><br>  Leider gibt es im Internet nicht gen√ºgend Informationen √ºber die Migration realer Anwendungen und den Produktionsbetrieb des Percona XtraDB-Clusters (im Folgenden: PXC).  Ich werde versuchen, diese Situation zu korrigieren und √ºber unsere Erfahrungen mit meiner Geschichte zu berichten.  Es gibt keine schrittweisen Installationsanweisungen und der Artikel sollte nicht als Ersatz f√ºr Off-Dokumentation betrachtet werden, sondern als Sammlung von Empfehlungen. <br><a name="habracut"></a><br><h3>  Das Problem </h3><br>  Ich arbeite als Systemadministrator bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ultimative-guitar.com</a> .  Da wir einen Webdienst bereitstellen, verf√ºgen wir nat√ºrlich √ºber Backends und eine Datenbank, die den Kern des Dienstes bildet.  Die Verf√ºgbarkeit des Dienstes h√§ngt direkt von der Datenbankleistung ab. <br><br>  Als Datenbank wurde Percona MySQL 5.7 verwendet.  Die Reservierung wurde mit dem Master-Replikationsschema-Master implementiert.  Slaves wurden verwendet, um einige Daten zu lesen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05a/ca3/bc6/05aca3bc6ba1c357cd98c280e8a07772.png" alt="Bild"><br><br>  Dieses Schema hatte jedoch nicht die folgenden Nachteile: <br><br><ul><li>  Aufgrund der Tatsache, dass bei der MySQL-Replikation asynchrone Slaves auf unbestimmte Zeit verz√∂gert werden k√∂nnen.  Alle kritischen Daten mussten vom Master gelesen werden. </li><li>  Aus dem vorherigen Absatz folgt die Komplexit√§t der Entwicklung.  Der Entwickler konnte nicht nur eine Anfrage an die Datenbank stellen, sondern musste dar√ºber nachdenken, ob er jeweils f√ºr den R√ºckstand des Slaves bereit war, und wenn nicht, die Daten aus dem Assistenten lesen. </li><li>  Manuelles Schalten im Falle eines Unfalls.  Die Implementierung der automatischen Umschaltung war problematisch, da die MySQL-Architektur keinen integrierten Schutz gegen Split Brain bietet.  Wir m√ºssten uns einen Schiedsrichter mit einer komplexen Logik der Wahl eines Meisters schreiben.  Beim Schreiben an beide Master k√∂nnen gleichzeitig Konflikte auftreten, die die Master-Replikation unterbrechen und zum klassischen Split-Brain f√ºhren. </li></ul><br>  Ein paar trockene Zahlen, damit Sie verstehen, womit wir gearbeitet haben: <br><br>  Datenbankgr√∂√üe: 300 GB <br>  QPS: ~ 10k <br>  RW-Verh√§ltnis: 96/4% <br>  Master Server Konfiguration: <br>  CPU: 2x E5-2620 v3 <br>  RAM: 128 GB <br>  SSD: Intel Optane 905p 960 GB <br>  Netzwerk: 1 Gbit / s <br><br>  Wir haben eine klassische OLTP-Last mit viel Lesen, die sehr schnell und mit wenig Schreiben erledigt werden muss.  Die Belastung der Datenbank ist recht gering, da das Caching in Redis und Memcached aktiv verwendet wird. <br><br><h3>  Entscheidungsauswahl </h3><br>  Wie Sie vielleicht aus dem Titel erraten haben, haben wir PXC gew√§hlt, aber hier werde ich erkl√§ren, warum wir es gew√§hlt haben. <br><br>  Wir hatten 4 M√∂glichkeiten: <br><br><ol><li>  DBMS √§ndern </li><li>  MySQL-Gruppenreplikation </li><li>  Schrauben Sie die erforderlichen Funktionen selbst mithilfe von Skripten √ºber den Master-Replikationsmaster. </li><li>  MySQL Galera Cluster (oder seine Gabeln, zum Beispiel PXC) </li></ol><br>  Die Option zum √Ñndern der Datenbank wurde praktisch nicht in Betracht gezogen, weil  Die Anwendung ist gro√ü, an vielen Stellen an die MySQL-Funktionalit√§t oder -Syntax gebunden, und die Migration zu PostgreSQL erfordert beispielsweise viel Zeit und Ressourcen. <br><br>  Die zweite Option war MySQL Group Replication.  Ein zweifelsfreier Vorteil ist, dass es sich im Vanille-Zweig von MySQL entwickelt, was bedeutet, dass es in Zukunft weit verbreitet sein und einen gro√üen Pool aktiver Benutzer haben wird. <br><br>  Aber er hat ein paar Nachteile.  Erstens werden das Anwendungs- und Datenbankschema st√§rker eingeschr√§nkt, was bedeutet, dass die Migration schwieriger wird.  Zweitens l√∂st die Gruppenreplikation das Problem der Fehlertoleranz und des geteilten Gehirns, aber die Replikation im Cluster ist immer noch asynchron. <br><br>  Die dritte Option f√ºr zu viele Fahrr√§der hat uns auch nicht gefallen, die wir zwangsl√§ufig implementieren m√ºssen, um das Problem auf diese Weise zu l√∂sen. <br><br>  Galera erlaubte es, das MySQL-Failover-Problem vollst√§ndig zu l√∂sen und das Problem teilweise mit der Relevanz der Daten auf den Slaves zu l√∂sen.  Zum Teil, weil die Replikationsasynchronit√§t erhalten bleibt.  Nachdem eine Transaktion auf einem lokalen Knoten festgeschrieben wurde, werden die √Ñnderungen asynchron auf die verbleibenden Knoten √ºbertragen. Der Cluster stellt jedoch sicher, dass die Knoten nicht zu stark verz√∂gert werden, und verlangsamt die Arbeit k√ºnstlich, wenn sie zu verz√∂gern beginnen.  Der Cluster stellt sicher, dass nach dem Festschreiben der Transaktion niemand widerspr√ºchliche √Ñnderungen festschreiben kann, selbst auf dem Knoten, der die √Ñnderungen noch nicht repliziert hat. <br><br>  Nach der Migration sollte das Datenbankoperationsschema folgenderma√üen aussehen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d8/435/190/2d8435190207a5bb711d131d852a572f.png" alt="Bild"><br><br><h3>  Die Migration </h3><br>  Warum ist Migration das zweite Element nach Auswahl einer L√∂sung?  Es ist ganz einfach: Der Cluster enth√§lt eine Reihe von Anforderungen, denen die Anwendung und die Datenbank entsprechen m√ºssen, und diese m√ºssen vor der Migration erf√ºllt werden. <br><br><ul><li>  <b>InnoDB-Engine f√ºr alle Tabellen.</b>  MyISAM, Memory und andere Backends werden nicht unterst√ºtzt.  Es ist ganz einfach behoben - wir konvertieren alle Tabellen in InnoDB. </li><li>  <b>Binlog im ROW-Format.</b>  Der Cluster ben√∂tigt kein Binlog, um zu funktionieren. Wenn Sie keine klassischen Slaves ben√∂tigen, k√∂nnen Sie ihn deaktivieren. Das Binlog-Format sollte jedoch ROW sein. </li><li>  <b>Alle Tabellen m√ºssen einen PRIMARY / FOREIGN KEY haben.</b>  Dies ist erforderlich, damit von verschiedenen Knoten aus gleichzeitig in dieselbe Tabelle geschrieben werden kann.  F√ºr Tabellen, die keinen eindeutigen Schl√ºssel enthalten, k√∂nnen Sie den zusammengesetzten Prim√§rschl√ºssel oder das automatische Inkrementieren verwenden. </li><li>  <b>Verwenden Sie f√ºr Transaktionen nicht 'LOCK TABLES', 'GET_LOCK () / RELEASE_LOCK ()', 'FLUSH TABLES {{table}} WITH READ LOCK' oder die Isolationsstufe 'SERIALIZABLE'.</b> </li><li>  <b>Verwenden Sie nicht die Abfragen 'CREATE TABLE ... AS SELECT'</b> , as  Sie kombinieren Schema und Daten√§nderung.  Es ist leicht in zwei Abfragen zu unterteilen, von denen die erste eine Tabelle erstellt und die zweite mit Daten f√ºllt. </li><li>  <b>Verwenden Sie nicht 'DISCARD TABLESPACE' und 'IMPORT TABLESPACE'</b> als  Sie werden nicht repliziert </li><li>  <b>Setzen Sie die Optionen 'innodb_autoinc_lock_mode' auf '2'.</b>  Diese Option kann Daten besch√§digen, wenn mit der STATEMENT-Replikation gearbeitet wird. Da jedoch nur die ROW-Replikation im Cluster zul√§ssig ist, treten keine Probleme auf. </li><li>  <b>Als 'log_output' wird nur 'FILE' unterst√ºtzt.</b>  Wenn Sie einen Protokolleintrag in der Tabelle haben, m√ºssen Sie ihn entfernen. </li><li>  <b>XA-Transaktionen werden nicht unterst√ºtzt.</b>  Wenn sie verwendet wurden, m√ºssen Sie den Code ohne sie neu schreiben. </li></ul><br>  Ich sollte beachten, dass fast alle diese Einschr√§nkungen aufgehoben werden k√∂nnen, wenn Sie die Variable "pxc_strict_mode = PERMISSIVE" setzen. Wenn Ihre Daten f√ºr Sie jedoch wichtig sind, ist es besser, dies nicht zu tun.  Wenn Sie 'pxc_strict_mode = ENFORCING' festgelegt haben, k√∂nnen Sie mit MySQL die oben genannten Vorg√§nge nicht ausf√ºhren oder den Start des Knotens verhindern. <br><br>  Nachdem wir alle Anforderungen an die Datenbank erf√ºllt und den Betrieb unserer Anwendung in der Entwicklungsumgebung gr√ºndlich getestet haben, k√∂nnen wir mit der n√§chsten Stufe fortfahren. <br><br><h3>  Clusterbereitstellung und -konfiguration </h3><br>  Auf unseren Datenbankservern werden mehrere Datenbanken ausgef√ºhrt, und andere Datenbanken m√ºssen nicht in den Cluster migriert werden.  Ein Paket mit MySQL-Cluster ersetzt jedoch das klassische MySQL.  Wir hatten verschiedene L√∂sungen f√ºr dieses Problem: <br><br><ul><li>  <b>Verwenden Sie die Virtualisierung und starten Sie den Cluster in VM.</b>  Diese Option hat uns aufgrund der hohen (im Vergleich zu den √ºbrigen) Gemeinkosten und des Auftretens eines anderen Unternehmens, das gewartet werden muss, nicht gefallen </li><li>  <b>Erstellen Sie Ihre Version des Pakets, wodurch MySQL an einem nicht standardm√§√üigen Ort platziert wird.</b>  Somit ist es m√∂glich, mehrere Versionen von MySQL auf einem Server zu haben.  Eine gute Option, wenn Sie viele Server haben, aber die st√§ndige Unterst√ºtzung Ihres Pakets, die regelm√§√üig aktualisiert werden muss, kann viel Zeit in Anspruch nehmen. </li><li>  <b>Verwenden Sie Docker.</b> </li></ul><br>  Wir haben Docker ausgew√§hlt, verwenden es jedoch in der Mindestoption.  F√ºr die Datenspeicherung werden lokale Volumes verwendet.  Der Betriebsmodus '--net host' wird verwendet, um die Netzwerklatenz und die CPU-Auslastung zu reduzieren. <br><br>  Wir mussten auch unsere eigene Version des Docker-Images erstellen.  Der Grund daf√ºr ist, dass das Standard-Image von Percona die Wiederherstellungsposition beim Start nicht unterst√ºtzt.  Dies bedeutet, dass bei jedem Neustart der Instanz keine schnelle IST-Synchronisierung durchgef√ºhrt wird, bei der nur die erforderlichen √Ñnderungen hochgeladen werden, sondern ein langsamer SST, der die Datenbank vollst√§ndig neu l√§dt. <br><br>  Ein weiteres Problem ist die Clustergr√∂√üe.  In einem Cluster speichert jeder Knoten den gesamten Datensatz.  Daher l√§sst sich das Lesen mit zunehmender Clustergr√∂√üe perfekt skalieren.  Mit dem Datensatz ist die Situation umgekehrt: Beim Festschreiben wird jede Transaktion auf das Fehlen von Konflikten auf allen Knoten √ºberpr√ºft.  Je mehr Knoten vorhanden sind, desto l√§nger dauert das Festschreiben nat√ºrlich. <br>  Hier haben wir auch mehrere M√∂glichkeiten: <br><br><ul><li>  <b>2 Knoten + Arbiter.</b>  2 Knoten + Arbiter.  Eine gute Option f√ºr Tests.  W√§hrend der Bereitstellung des zweiten Knotens sollte der Master nicht aufzeichnen. <br></li><li>  <b>3 Knoten.</b>  Die klassische Version.  Gleichgewicht zwischen Geschwindigkeit und Zuverl√§ssigkeit.  Bitte beachten Sie, dass in dieser Konfiguration ein Knoten die gesamte Last dehnen muss, weil  Zum Zeitpunkt des Hinzuf√ºgens des 3. Knotens ist der zweite der Spender. <br></li><li>  <b>4+ Knoten.</b>  Bei einer geraden Anzahl von Knoten muss ein Arbiter hinzugef√ºgt werden, um ein Split-Brain zu vermeiden.  Eine Option, die f√ºr sehr viel Lesen gut funktioniert.  Die Zuverl√§ssigkeit des Clusters w√§chst ebenfalls. </li></ul><br>  Wir haben uns bisher f√ºr die Option mit 3 Knoten entschieden. <br><br>  Die Cluster-Konfiguration kopiert die eigenst√§ndige MySQL-Konfiguration fast vollst√§ndig und unterscheidet sich nur in wenigen Optionen: <br><br>  <b>"Wsrep_sst_method = xtrabackup-v2"</b> Diese Option legt die Methode zum Kopieren von Knoten fest.  Andere Optionen sind mysqldump und rsync, aber sie blockieren den Knoten f√ºr die Dauer der Kopie.  Ich sehe keinen Grund, die Nicht-xtrabackup-v2-Kopiermethode zu verwenden. <br><br>  <b>"Gcache"</b> ist ein Analogon zum Cluster-Binlog.  Es ist ein kreisf√∂rmiger Puffer (in einer Datei) fester Gr√∂√üe, in den alle √Ñnderungen geschrieben werden.  Wenn Sie einen der Clusterknoten ausschalten und dann wieder einschalten, wird versucht, die fehlenden √Ñnderungen aus Gcache zu lesen (IST-Synchronisation).  Wenn die vom Knoten erforderlichen √Ñnderungen nicht vorhanden sind, ist ein vollst√§ndiges Neuladen des Knotens (SST-Synchronisation) erforderlich.  Die Gr√∂√üe von gcache wird wie folgt festgelegt: wsrep_provider_options = 'gcache.size = 20G;'. <br><br>  <b>wsrep_slave_threads</b> Im Gegensatz zur klassischen Replikation in einem Cluster k√∂nnen mehrere Schreibs√§tze parallel auf dieselbe Datenbank <b>angewendet werden</b> .  Diese Option gibt die Anzahl der Mitarbeiter an, die die √Ñnderungen anwenden.  Es ist besser, den Standardwert 1 nicht zu belassen, weil  W√§hrend der Arbeit eines gro√üen Schreibsatzes durch den Worker wartet der Rest in der Warteschlange und die Knotenreplikation beginnt zu verz√∂gern.  Einige empfehlen, diesen Parameter auf 2 * CPU THREADS zu setzen, aber ich denke, Sie m√ºssen sich die Anzahl der gleichzeitigen Schreibvorg√§nge ansehen, die Sie haben. <br><br>  Wir haben uns f√ºr den Wert 64 entschieden. Bei einem niedrigeren Wert gelang es dem Cluster manchmal nicht, alle Schreibs√§tze aus der Warteschlange w√§hrend Lastbursts anzuwenden (z. B. beim Starten schwerer Kronen). <br><br>  <b>wsrep_max_ws_size Die</b> Gr√∂√üe einer einzelnen Transaktion in einem Cluster ist auf 2 GB begrenzt.  Gro√üe Transaktionen passen jedoch nicht gut zum PXC-Konzept.  Es ist besser, 100 Transaktionen mit jeweils 20 MB abzuschlie√üen als eine pro 2 GB.  Daher haben wir zuerst die Transaktionsgr√∂√üe im Cluster auf 100 MB begrenzt und dann das Limit auf 50 MB reduziert. <br><br>  Wenn Sie den strengen Modus aktiviert haben, k√∂nnen Sie die Variable " <b>binlog_row_image</b> " auf "minimal" setzen.  Dadurch wird die Gr√∂√üe der Eintr√§ge im Binlog um ein Vielfaches reduziert (10-mal im Test von Percona).  Dies spart Speicherplatz und erm√∂glicht Transaktionen, die nicht in das Limit mit "binlog_row_image = full" passen. <br><br>  <b>Grenzwerte f√ºr SST.</b>  F√ºr Xtrabackup, mit dem Knoten gef√ºllt werden, k√∂nnen Sie die Netzwerknutzung, die Anzahl der Threads und die Komprimierungsmethode begrenzen.  Dies ist erforderlich, damit der Donor-Server beim Bef√ºllen des Knotens nicht langsamer wird.  Dazu wird der Datei my.cnf der Abschnitt "sst" hinzugef√ºgt: <br><br><pre><code class="hljs powershell">[<span class="hljs-type"><span class="hljs-type">sst</span></span>] rlimit = <span class="hljs-number"><span class="hljs-number">80</span></span>m compressor = <span class="hljs-string"><span class="hljs-string">"pigz -3"</span></span> decompressor = <span class="hljs-string"><span class="hljs-string">"pigz -dc"</span></span> backup_threads = <span class="hljs-number"><span class="hljs-number">4</span></span></code> </pre> <br>  Wir begrenzen die Kopiergeschwindigkeit auf 80 Mb / s.  Wir verwenden pigz f√ºr die Komprimierung. Dies ist eine Multithread-Version von gzip. <br><br>  <b>GTID</b> Wenn Sie klassische Slaves verwenden, empfehle ich, GTID im Cluster zu aktivieren.  Auf diese Weise k√∂nnen Sie den Slave mit einem beliebigen Knoten des Clusters verbinden, ohne den Slave neu laden zu m√ºssen. <br><br>  Zus√§tzlich m√∂chte ich √ºber 2 Clustermechanismen sprechen, deren Bedeutung und Konfiguration. <br><br><h4>  Flusskontrolle </h4><br>  Die Flusskontrolle ist eine M√∂glichkeit, die Schreiblast in einem Cluster zu verwalten.  Knoten d√ºrfen bei der Replikation nicht zu weit zur√ºckbleiben.  Auf diese Weise wird eine "fast synchrone" Replikation erreicht.  Der Funktionsmechanismus ist recht einfach: Sobald die L√§nge der Empfangswarteschlange den eingestellten Wert erreicht, wird die Nachricht "Flusssteuerungspause" an die anderen Knoten gesendet, die sie auffordert, mit dem Festschreiben neuer Transaktionen zu pausieren, bis der nacheilende Knoten das Harken der Warteschlange beendet hat . <br><br>  Daraus ergeben sich mehrere Dinge: <br><br><ol><li>  Die Aufzeichnung im Cluster erfolgt mit der Geschwindigkeit des langsamsten Knotens.  (Aber es kann versch√§rft werden.) </li><li>  Wenn beim Festschreiben von Transaktionen viele Konflikte auftreten, k√∂nnen Sie Flow Control aggressiver konfigurieren, wodurch sich die Anzahl verringern sollte. </li><li>  Die maximale Verz√∂gerung eines Knotens in einem Cluster ist eine Konstante, jedoch nicht nach Zeit, sondern nach Anzahl der Transaktionen in der Warteschlange.  Die Verz√∂gerungszeit h√§ngt von der durchschnittlichen Transaktionsgr√∂√üe und der Anzahl der wsrep_slave_threads ab. </li></ol><br>  Sie k√∂nnen die Einstellungen f√ºr die Flusskontrolle folgenderma√üen anzeigen: <br><br> <code>mysql&gt; SHOW GLOBAL STATUS LIKE 'wsrep_flow_control_interval_%'; <br> wsrep_flow_control_interval_low | 36 <br> wsrep_flow_control_interval_high | 71 <br></code> <br>  Zun√§chst interessiert uns der Parameter wsrep_flow_control_interval_high.  Es steuert die L√§nge der Warteschlange, nach der die FC-Pause aktiviert wird.  Dieser Parameter wird nach folgender Formel berechnet: gcs.fc_limit * ‚àöN (wobei N = Anzahl der Knoten im Cluster). <br><br>  Der zweite Parameter ist wsrep_flow_control_interval_low.  Es ist f√ºr den Wert der Warteschlangenl√§nge verantwortlich, bei deren Erreichen der FC ausgeschaltet wird.  Berechnet nach der Formel: wsrep_flow_control_interval_high * gcs.fc_factor.  Standardm√§√üig ist gcs.fc_factor = 1. <br><br>  Durch √Ñndern der L√§nge der Warteschlange k√∂nnen wir also die Replikationsverz√∂gerung steuern.  Durch Verringern der L√§nge der Warteschlange wird die Zeit erh√∂ht, die der Cluster in der FC-Pause verbringt, die Verz√∂gerung der Knoten wird jedoch verringert. <br><br>  Sie k√∂nnen die Sitzungsvariable " <b>wsrep_sync_wait</b> = 7" <b>festlegen</b> .  Dadurch wird der PXC gezwungen, Lese- oder Schreibanforderungen erst auszuf√ºhren, nachdem alle Schreibs√§tze in der aktuellen Warteschlange angewendet wurden.  Dies erh√∂ht nat√ºrlich die Latenz von Anforderungen.  Die Erh√∂hung der Latenz ist direkt proportional zur L√§nge der Warteschlange. <br><br>  Es ist auch w√ºnschenswert, die maximale Transaktionsgr√∂√üe auf das minimal m√∂gliche zu reduzieren, damit lange Transaktionen nicht versehentlich durchrutschen. <br><br><h4>  EVS oder Auto Evict </h4><br>  Mit diesem Mechanismus k√∂nnen Sie Knoten auswerfen, die instabil sind (z. B. Paketverlust oder lange Verz√∂gerungen) oder langsam reagieren.  Dank dessen k√∂nnen Kommunikationsprobleme mit einem Knoten nicht den gesamten Cluster beeintr√§chtigen, sondern den Knoten deaktivieren und im normalen Modus weiterarbeiten.  Dieser Mechanismus ist besonders n√ºtzlich, wenn der Cluster √ºber das WAN oder Teile des Netzwerks betrieben wird, die nicht unter Ihrer Kontrolle stehen.  Standardm√§√üig ist der EFD deaktiviert. <br><br>  F√ºgen Sie zum Aktivieren die Option "evs.version = 1;" zum Parameter <b>wsrep_provider_options hinzu</b>  und "evs.auto_evict = 5;"  (Die Anzahl der Operationen, nach denen der Knoten ausgeschaltet wird. Der Wert 0 deaktiviert den EFD.) Es gibt auch verschiedene Parameter, mit denen Sie den EFD optimieren k√∂nnen: <br><br><ul><li>  <b>evs.delayed_margin Die</b> Zeit, die ein Knoten ben√∂tigt, um zu antworten.  Standardm√§√üig 1 Sek., Wenn Sie jedoch in einem lokalen Netzwerk arbeiten, kann dies auf 0,05-0,1 Sek. Oder weniger reduziert werden. </li><li>  <b>evs.inactive_check_period</b> √úberpr√ºfungszeitraum.  Standard 0,5 Sek </li></ul><br>  Tats√§chlich betr√§gt die Zeit, die ein Knoten bei Problemen arbeiten kann, bevor der EFD ausgel√∂st wird, evs.inactive_check_period * evs.auto_evict.  Sie k√∂nnen auch "evs.inactive_timeout" festlegen. Ein Knoten, der nicht antwortet, wird sofort gel√∂scht, standardm√§√üig 15 Sekunden. <br><br>  Eine wichtige Nuance ist, dass dieser Mechanismus selbst den Knoten beim Wiederherstellen der Kommunikation nicht zur√ºckgibt.  Es muss von Hand neu gestartet werden. <br><br>  Wir haben den EFD zu Hause eingerichtet, aber wir hatten noch keine Gelegenheit, ihn im Kampf zu testen. <br><br><h3>  Lastausgleich </h3><br>  Damit Clients die Ressourcen jedes Knotens gleichm√§√üig nutzen und Anforderungen nur auf Live-Clusterknoten ausf√ºhren k√∂nnen, ben√∂tigen wir einen Load Balancer.  Percona bietet 2 L√∂sungen: <br><br><ul><li>  <b>ProxySQL.</b>  Dies ist der L7-Proxy f√ºr MySQL. </li><li>  <b>Haproxy.</b>  Haproxy wei√ü jedoch nicht, wie der Status eines Clusterknotens √ºberpr√ºft und festgestellt werden soll, ob er zur Ausf√ºhrung von Anforderungen bereit ist.  Um dieses Problem zu l√∂sen, wird vorgeschlagen, ein zus√§tzliches <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">percona-clustercheck-Skript zu verwenden</a> </li></ul><br>  Zuerst wollten wir ProxySQL verwenden, aber nach dem Benchmarking stellte sich heraus, dass die Latenz gegen√ºber Haproxy um etwa 15 bis 20% abnimmt, selbst wenn der Fast_forward-Modus verwendet wird (das Umschreiben von Abfragen, das Routing und viele andere ProxySQL-Funktionen funktionieren in diesem Modus nicht, Anforderungen werden unver√§ndert weitergeleitet). . <br><br>  Haproxy ist schneller, aber das Percona-Skript hat einige Nachteile. <br><br>  Erstens ist es in Bash geschrieben, was nicht zu seiner Anpassung beitr√§gt.  Ein schwerwiegenderes Problem ist, dass das Ergebnis der MySQL-Pr√ºfung nicht zwischengespeichert wird.  Wenn wir also 100 Clients haben, von denen jeder alle 1 Sekunde den Status des Knotens √ºberpr√ºft, sendet das Skript alle 10 ms eine Anfrage an MySQL.  Wenn MySQL aus irgendeinem Grund langsam zu arbeiten beginnt, erstellt das Validierungsskript eine gro√üe Anzahl von Prozessen, was die Situation definitiv nicht verbessern wird. <br><br>  Es wurde beschlossen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eine L√∂sung</a> zu schreiben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">,</a> bei der die MySQL-Statuspr√ºfung und die Haproxy-Antwort nicht miteinander zusammenh√§ngen.  Das Skript √ºberpr√ºft in regelm√§√üigen Abst√§nden den Status des Knotens im Hintergrund und speichert das Ergebnis zwischen.  Der Webserver gibt Haproxy das zwischengespeicherte Ergebnis. <br><br><div class="spoiler">  <b class="spoiler_title">Beispiel f√ºr eine Haproxy-Konfiguration</b> <div class="spoiler_text"> <code>listen db <br> bind 127.0.0.1:3302 <br> mode tcp <br> balance first <br> default-server inter 200 rise 6 fall 6 <br> option httpchk HEAD / <br> server node1 192.168.0.1:3302 check port 9200 id 1 <br> server node2 192.168.0.2:3302 check port 9200 backup id 2 <br> server node3 192.168.0.3:3302 check port 9200 backup id 3 <br> <br> listen db_slave <br> bind 127.0.0.1:4302 <br> mode tcp <br> balance leastconn <br> default-server inter 200 rise 6 fall 6 <br> option httpchk HEAD / <br> server node1 192.168.0.1:3302 check port 9200 backup <br> server node2 192.168.0.2:3302 check port 9200 <br> server node3 192.168.0.3:3302 check port 9200 <br></code> <br>  Dieses Beispiel zeigt eine einzelne Assistentenkonfiguration.  Die verbleibenden Cluster-Server fungieren als Slaves. <br></div></div><br><h3>  √úberwachung </h3><br>  Um den Clusterstatus zu √ºberwachen, haben wir Prometheus + mysqld_exporter und Grafana verwendet, um die Daten zu visualisieren.  Weil  mysqld_exporter sammelt eine Reihe von Metriken, um Dashboards selbst zu erstellen. Dies ist ziemlich m√ºhsam.  Sie k√∂nnen vorgefertigte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dashboards von Percona √ºbernehmen</a> und selbst anpassen. <br><br>  Wir verwenden Zabbix auch, um grundlegende Cluster-Metriken und Warnungen zu erfassen. <br><br>  Die wichtigsten Cluster-Metriken, die Sie √ºberwachen m√∂chten: <br><br><ul><li>  <b>wsrep_cluster_status</b> Muss auf allen Knoten auf Prim√§r gesetzt werden.  Wenn der Wert "nicht prim√§r" ist, hat dieser Knoten den Kontakt zum Cluster-Quorum verloren. </li><li>  <b>wsrep_cluster_size</b> Die Anzahl der Knoten im Cluster.  Dies schlie√üt auch "verlorene" Knoten ein, die sich im Cluster befinden m√ºssen, aber aus irgendeinem Grund nicht verf√ºgbar sind.  Wenn der Knoten vorsichtig ausgeschaltet wird, nimmt der Wert dieser Variablen ab. </li><li>  <b>wsrep_local_state</b> Gibt an, ob der Knoten ein aktives Mitglied des Clusters ist und betriebsbereit ist. </li><li>  <b>wsrep_evs_state</b> Ein wichtiger Parameter, wenn Sie die automatische R√§umung <b>aktiviert</b> haben (standardm√§√üig <b>deaktiviert</b> ).  Diese Variable gibt an, dass EVS diesen Knoten als fehlerfrei betrachtet. </li><li>  <b>wsrep_evs_evict_list Die</b> Liste der Knoten, die von EVS aus dem Cluster geworfen wurden.  In einer normalen Situation sollte die Liste leer sein. </li><li>  <b>wsrep_evs_delayed</b> Liste der Kandidaten f√ºr die Entfernung des EFD.  Muss auch leer sein. </li></ul><br>  Wichtige Leistungskennzahlen: <br><br><ul><li>  <b>wsrep_evs_repl_latency</b> Zeigt die Kommunikationsverz√∂gerung innerhalb des Clusters an (minimale / durchschnittliche / maximale / √§ltere Abweichung / Paketgr√∂√üe).  Das hei√üt, es misst die Netzwerklatenz.  Steigende Werte k√∂nnen auf eine √úberlastung der Netzwerk- oder Clusterknoten hinweisen.  Diese Metrik wird auch bei ausgeschaltetem EFD aufgezeichnet. </li><li>  <b>wsrep_flow_control_paused_ns Die</b> Zeit (in ns) seit dem Start des Knotens, die er in der Ablaufsteuerungspause verbracht hat.  Idealerweise sollte es 0 sein. Das Wachstum dieses Parameters weist auf Probleme mit der Clusterleistung oder das Fehlen von "wsrep_slave_threads" hin.  Mit dem Parameter " <b>wsrep_flow_control_sent</b> " k√∂nnen Sie bestimmen, welcher Knoten langsamer wird. </li><li>  <b>wsrep_flow_control_paused Der</b> Prozentsatz der Zeit seit der letzten Ausf√ºhrung von "FLUSH STATUS", die der Knoten in der Flow-Steuerungspause verbracht hat.  Neben der vorherigen Variablen sollte sie gegen Null tendieren. </li><li>  <b>wsrep_flow_control_status</b> Gibt an, ob Flow Control derzeit ausgef√ºhrt wird.  Auf dem FC-Pauseninitiierungsknoten ist der Wert dieser Variablen EIN. </li><li>  <b>wsrep_local_recv_queue_avg</b> Durchschnittliche L√§nge der Empfangswarteschlange.  Das Wachstum dieses Parameters weist auf Probleme mit der Leistung des Knotens hin. </li><li>  <b>wsrep_local_send_queue_avg</b> Die durchschnittliche L√§nge der <b>Sendewarteschlange</b> .  Das Wachstum dieses Parameters weist auf Netzwerkleistungsprobleme hin. </li></ul><br>  Es gibt keine universellen Empfehlungen zu den Werten dieser Parameter.  Es ist klar, dass sie gegen Null tendieren sollten, aber bei realer Last wird dies h√∂chstwahrscheinlich nicht der Fall sein und Sie m√ºssen selbst bestimmen, wo die Grenze des Normalzustands des Clusters verl√§uft. <br><br><h3>  Backup </h3><br>  Cluster-Backup unterscheidet sich praktisch nicht von Standalone-MySQL.  F√ºr den Produktionseinsatz haben wir mehrere M√∂glichkeiten. <br><br><ul><li>  Entfernen Sie das Backup von einem der "Gain" -Knoten mit xtrabackup.  Die einfachste Option, aber w√§hrend des Backup-Clusters wird die Leistung verschwendet. </li><li>  Verwenden Sie klassische Slaves und Backups von Replikaten. </li></ul><br>  Backups mit Standalone und mit der mit xtrabackup erstellten Clusterversion sind untereinander portierbar.  Das hei√üt, die vom Cluster erstellte Sicherung kann f√ºr eigenst√§ndiges MySQL bereitgestellt werden und umgekehrt.  Nat√ºrlich sollte die Hauptversion von MySQL √ºbereinstimmen, vorzugsweise die Nebenversion.  Mit mysqldump erstellte Backups sind nat√ºrlich auch portabel. <br><br>  Die einzige Einschr√§nkung besteht darin, dass Sie nach der Bereitstellung der Sicherung das Skript mysql_upgrade ausf√ºhren m√ºssen, mit dem die Struktur einiger Systemtabellen √ºberpr√ºft und korrigiert wird. <br><br><h3>  Datenmigration </h3><br>  Nachdem wir die Konfiguration, √úberwachung und andere Dinge herausgefunden haben, k√∂nnen wir mit der Migration auf das Produkt beginnen. <br><br>  Die Datenmigration in unserem Schema war recht einfach, aber wir haben ein bisschen durcheinander gebracht;). <br>  Legende - Master 1 und Master 2 sind durch Master-Replikationsmaster verbunden.  Die Aufnahme geht nur an Master 1. Master 3 ist ein sauberer Server. <br><br>  Unser Migrationsplan (im Plan werde ich der Einfachheit halber Operationen mit Slaves weglassen und nur √ºber Master-Server sprechen). <br><br><h4>  Versuch 1 </h4><br><ol><li>  Entfernen Sie die Datenbanksicherung mit xtrabackup von Master 1. </li><li>  Kopieren Sie die Sicherung auf Master 3 und f√ºhren Sie den Cluster im Einzelknotenmodus aus. </li><li>  Richten Sie die Master-Replikation zwischen Master 3 und 1 ein. </li><li>  Schalten Sie das Lesen und Schreiben auf den Master 3. √úberpr√ºfen Sie die Anwendung. </li><li>  Deaktivieren Sie auf Master 2 die Replikation und starten Sie Clustered MySQL.  Wir warten darauf, dass er die Datenbank vom Master 3 kopiert. W√§hrend des Kopierens hatten wir einen Cluster aus einem Knoten im Status ‚ÄûSpender‚Äú und einem Knoten, der noch nicht funktioniert.  W√§hrend des Kopierens haben wir eine Reihe von Sperren erhalten und am Ende sind beide Knoten mit einem Fehler gefallen (das Erstellen eines neuen Knotens kann aufgrund toter Sperren nicht abgeschlossen werden).  Dieses kleine Experiment hat uns vier Minuten Ausfallzeit gekostet. </li><li>  Schalten Sie das Lesen und Schreiben zur√ºck auf Master 1. </li></ol><br>  Die Migration funktionierte nicht, da beim Testen der Schaltung in der Entwicklungsumgebung in der Datenbank praktisch kein Schreibverkehr auftrat und beim Wiederholen derselben Schaltung unter Last Probleme auftraten. <br>  Wir haben das Migrationsschema leicht ge√§ndert, um diese Probleme zu vermeiden, und es zum zweiten Mal erfolgreich wiederholt;). <br><br><h4>  Versuch 2 </h4><br><ol><li>  Wir starten Master 3 neu, damit es im Einzelknotenmodus wieder funktioniert. </li><li>  Wir erh√∂hen Cluster MySQL erneut auf dem Master 2.  Im Moment ging der Datenverkehr von der Replikation nur an den Cluster, sodass keine wiederholten Probleme mit Sperren auftraten und der zweite Knoten erfolgreich zum Cluster hinzugef√ºgt wurde. </li><li>  Schalten Sie das Lesen und Schreiben erneut auf Master 3 um. Wir √ºberpr√ºfen den Betrieb der Anwendung. </li><li>  Deaktivieren Sie die Master-Replikation mit Master 1. Aktivieren Sie Cluster-MySQL auf Master 1 und warten Sie, bis es startet.  Um nicht auf denselben Rechen zu treten, ist es wichtig, dass die Anwendung nicht auf den Donor-Knoten schreibt (Einzelheiten finden Sie im Abschnitt zum Lastausgleich).  Nach dem Starten des dritten Knotens haben wir einen voll funktionsf√§higen Cluster von drei Knoten. </li><li>  Sie k√∂nnen eine Sicherung von einem der Knoten des Clusters entfernen und die Anzahl der ben√∂tigten klassischen Slaves erstellen. </li></ol><br>  Der Unterschied zwischen dem zweiten und dem ersten Schema besteht darin, dass wir den Datenverkehr erst nach dem Anheben des zweiten Knotens im Cluster auf den Cluster umgeschaltet haben. <br><br>  Dieser Vorgang dauerte f√ºr uns ca. 6 Stunden. <br><br><h3>  Multi-Master </h3><br>  Nach der Migration arbeitete unser Cluster im Single-Master-Modus, dh der gesamte Datensatz ging an einen der Server, und nur die Daten wurden vom Rest gelesen. <br><br>  Nach dem Wechsel der Produktion in den Multi-Master-Modus ist ein Problem aufgetreten - Transaktionskonflikte traten h√§ufiger auf als erwartet.  Es war besonders schlimm bei Abfragen, die viele Datens√§tze √§ndern, z. B. den Wert aller Datens√§tze in einer Tabelle aktualisieren.  Die Transaktionen, die erfolgreich auf demselben Knoten nacheinander im Cluster ausgef√ºhrt wurden, werden parallel ausgef√ºhrt, und eine l√§ngere Transaktion erh√§lt einen Deadlock-Fehler.  Ich werde nicht z√∂gern, nachdem wir mehrere Versuche unternommen haben, dies auf Anwendungsebene zu beheben, haben wir die Idee des Multi-Masters aufgegeben. <br><br><h3>  Andere Nuancen </h3><br><ul><li>  Ein Cluster kann ein Slave sein.  Wenn Sie diese Funktion verwenden, empfehle ich, alle Knoten au√üer der Slave-Option "skip_slave_start = 1" zur Konfiguration hinzuzuf√ºgen.  Andernfalls startet jeder neue Knoten die Replikation vom Master, was entweder zu Replikationsfehlern oder zu Datenbesch√§digungen auf dem Replikat f√ºhrt. </li><li>  Wie ich bereits sagte, kann ein Knoten Clients nicht ordnungsgem√§√ü bedienen.  Es muss beachtet werden, dass in einem Cluster von drei Knoten Situationen m√∂glich sind, in denen ein Knoten ausgeflogen ist, der zweite ein Spender ist und nur ein Knoten f√ºr den Kundendienst √ºbrig bleibt. </li></ul><br><h3>  Schlussfolgerungen </h3><br>  Nach der Migration und einiger Betriebszeit kamen wir zu den folgenden Schlussfolgerungen. <br><br><ul><li>  Der Galera-Cluster funktioniert und ist ziemlich stabil (zumindest solange keine abnormalen Knotenabf√§lle oder deren abnormales Verhalten aufgetreten sind).  In Bezug auf Fehlertoleranz haben wir genau das bekommen, was wir wollten. </li><li>  Perconas Multi-Master-Statements sind in erster Linie Marketing.  Ja, es ist m√∂glich, den Cluster in diesem Modus zu verwenden, dies erfordert jedoch eine tiefgreifende √Ñnderung der Anwendung f√ºr dieses Verwendungsmodell. </li><li>  Es gibt keine synchrone Replikation, aber jetzt steuern wir die maximale Verz√∂gerung von Knoten (bei Transaktionen).  Zusammen mit der Begrenzung der maximalen Transaktionsgr√∂√üe von 50 MB k√∂nnen wir die maximale Verz√∂gerungszeit von Knoten ziemlich genau vorhersagen.  F√ºr Entwickler ist es einfacher geworden, Code zu schreiben. </li><li>  Bei der √úberwachung beobachten wir kurzfristige Spitzen im Wachstum der Replikationswarteschlange.  Der Grund liegt in unserem 1-Gbit / s-Netzwerk.  Es ist m√∂glich, einen Cluster in einem solchen Netzwerk zu betreiben, aber w√§hrend Lastbursts treten Probleme auf.  Jetzt planen wir ein Upgrade des Netzwerks auf 10 Gbit / s. </li></ul><br>  Insgesamt drei "Wunschliste" haben wir ungef√§hr anderthalb erhalten.  Die wichtigste Anforderung ist die Fehlertoleranz. <br><br>  Unsere PXC-Konfigurationsdatei f√ºr Interessierte: <br><br><div class="spoiler">  <b class="spoiler_title">my.cnf</b> <div class="spoiler_text"> <code>[mysqld] <br> #Main <br> server-id = 1 <br> datadir = /var/lib/mysql <br> socket = mysql.sock <br> port = 3302 <br> pid-file = mysql.pid <br> tmpdir = /tmp <br> large_pages = 1 <br> skip_slave_start = 1 <br> read_only = 0 <br> secure-file-priv = /tmp/ <br> <br> #Engine <br> innodb_numa_interleave = 1 <br> innodb_flush_method = O_DIRECT <br> innodb_flush_log_at_trx_commit = 2 <br> innodb_file_format = Barracuda <br> join_buffer_size = 1048576 <br> tmp-table-size = 512M <br> max-heap-table-size = 1G <br> innodb_file_per_table = 1 <br> sql_mode = "NO_ENGINE_SUBSTITUTION,NO_AUTO_CREATE_USER,ERROR_FOR_DIVISION_BY_ZERO" <br> default_storage_engine = InnoDB <br> innodb_autoinc_lock_mode = 2 <br> <br> #Wsrep <br> wsrep_provider = "/usr/lib64/galera3/libgalera_smm.so" <br> wsrep_cluster_address = "gcomm://192.168.0.1:4577,192.168.0.2:4577,192.168.0.3:4577" <br> wsrep_cluster_name = "prod" <br> wsrep_node_name = node1 <br> wsrep_node_address = "192.168.0.1" <br> wsrep_sst_method = xtrabackup-v2 <br> wsrep_sst_auth = "USER:PASS" <br> pxc_strict_mode = ENFORCING <br> wsrep_slave_threads = 64 <br> wsrep_sst_receive_address = "192.168.0.1:4444" <br> wsrep_max_ws_size = 50M <br> wsrep_retry_autocommit = 2 <br> wsrep_provider_options = "gmcast.listen_addr=tcp://192.168.0.1:4577; ist.recv_addr=192.168.0.1:4578; gcache.size=30G; pc.checksum=true; evs.version=1; evs.auto_evict=5; gcs.fc_limit=80; gcs.fc_factor=0.75; gcs.max_packet_size=64500;" <br> <br> #Binlog <br> expire-logs-days = 4 <br> relay-log = mysql-relay-bin <br> log_slave_updates = 1 <br> binlog_format = ROW <br> binlog_row_image = minimal <br> log_bin = mysql-bin <br> log_bin_trust_function_creators = 1 <br> <br> #Replication <br> slave-skip-errors = OFF <br> relay_log_info_repository = TABLE <br> relay_log_recovery = ON <br> master_info_repository = TABLE <br> gtid-mode = ON <br> enforce-gtid-consistency = ON <br> <br> #Cache <br> query_cache_size = 0 <br> query_cache_type = 0 <br> thread_cache_size = 512 <br> table-open-cache = 4096 <br> innodb_buffer_pool_size = 72G <br> innodb_buffer_pool_instances = 36 <br> key_buffer_size = 16M <br> <br> #Logging <br> log-error = /var/log/stdout.log <br> log_error_verbosity = 1 <br> slow_query_log = 0 <br> long_query_time = 10 <br> log_output = FILE <br> innodb_monitor_enable = "all" <br> <br> #Timeout <br> max_allowed_packet = 512M <br> net_read_timeout = 1200 <br> net_write_timeout = 1200 <br> interactive_timeout = 28800 <br> wait_timeout = 28800 <br> max_connections = 22000 <br> max_connect_errors = 18446744073709551615 <br> slave-net-timeout = 60 <br> <br> #Static Values <br> ignore_db_dir = "lost+found" <br> <br> [sst] <br> rlimit = 80m <br> compressor = "pigz -3" <br> decompressor = "pigz -dc" <br> backup_threads = 8 <br></code> <br></div></div><br><h3>  Quellen und n√ºtzliche Links </h3><br>  ‚Üí <a href="">Unser Docker-Image</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Percona XtraDB Cluster 5.7 Dokumentation</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberwachen des Clusterstatus - Galera Cluster-Dokumentation</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Galera-Statusvariablen - Galera-Cluster-Dokumentation</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de422347/">https://habr.com/ru/post/de422347/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de422335/index.html">Die kleinsten Linux-Computer</a></li>
<li><a href="../de422337/index.html">Yandex hat eine Cloud gestartet</a></li>
<li><a href="../de422339/index.html">"Ich denke, JavaScript ist nicht f√ºr das Web geeignet." 10 Fragen an den Programmierer, 4 Release (aus Berlin)</a></li>
<li><a href="../de422341/index.html">IoT - f√∂rdern, w√§hrend andere denken</a></li>
<li><a href="../de422345/index.html">Server in den Clouds: Projektzusammenfassung</a></li>
<li><a href="../de422351/index.html">Remote-Codeausf√ºhrung durch Laden von Bildern auf Ihren Server oder lokalen Computer in Ghostscript / Imagick</a></li>
<li><a href="../de422363/index.html">PyCon Russia 2018 Konferenz: Video aller Berichte und Pr√§sentationen</a></li>
<li><a href="../de422365/index.html">Yandex reichte eine Beschwerde gegen eine Gerichtsentscheidung ein, um Links zu Raubkopien zu entfernen</a></li>
<li><a href="../de422367/index.html">So stellen Sie Videos f√ºr Full Throttle Remastered wieder her. Teil 2</a></li>
<li><a href="../de422369/index.html">Entwerfen von Dashboards f√ºr die E-Commerce-Website f√ºr Webanalysen. Teil 2: E-Mail-Newsletter. Strategisches Dashboard</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ•µğŸ¾ ğŸ§‘ğŸ» ğŸ‘¦ğŸ½ Quels codecs vidÃ©o (non) les navigateurs utilisent-ils pour les appels vidÃ©o? ğŸ‘©ğŸ¼â€âš–ï¸ ğŸƒ ğŸ‘¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Une demande de support technique typique de Voximplant: "Pourquoi un appel vidÃ©o entre deux Chrome est-il meilleur qu'un appel vidÃ©o entre MS Edge et ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Quels codecs vidÃ©o (non) les navigateurs utilisent-ils pour les appels vidÃ©o?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/419949/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/bp/z1/1m/bpz11m_orhftn04lqz-4xbh6pzm.png"></div><br>  Une demande de support technique typique de Voximplant: "Pourquoi un appel vidÃ©o entre deux Chrome est-il meilleur qu'un appel vidÃ©o entre MS Edge et une application iOS native?"  Les collÃ¨gues rÃ©pondent gÃ©nÃ©ralement neutres - Â«parce que les codecsÂ».  Mais nous, les informaticiens, sommes curieux.  MÃªme si je ne dÃ©veloppe pas un nouveau Skype-pour-le-Web, lire Â«quel type de navigateur peutÂ» et comment ils divisent une vidÃ©o en plusieurs flux de qualitÃ© diffÃ©rente enrichit l'image du monde et donne un nouveau sujet de discussion dans le fumoir.  Article publiÃ© avec succÃ¨s de trÃ¨s connu dans des cercles Ã©troits, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dr Alex</a> (avec la meilleure explication du terme Â«moteur multimÃ©diaÂ» de tout ce que j'ai vu), un peu de notre expÃ©rience, quelques soirÃ©es dans le Â«DialÂ» - et une traduction adaptÃ©e pour Habr attend sous la coupe! <br><a name="habracut"></a><br><h2>  Codecs et largeur de canal </h2><br>  Lorsqu'on parle de codecs vidÃ©o, le plus souvent, ils discutent de l'Ã©quilibre entre la qualitÃ© et la largeur du canal utilisÃ©.  Et ils aiment ignorer les problÃ¨mes de charge du processeur et comment transmettre techniquement de la vidÃ©o.  Assez raisonnable si nous discutons de l'encodage d'une vidÃ©o dÃ©jÃ  enregistrÃ©e. <br><br>  AprÃ¨s tout, si vous avez une vidÃ©o terminÃ©e, il n'y a pas beaucoup de diffÃ©rence, elle compressera quelques minutes, quelques heures ou mÃªme quelques jours.  Tous les coÃ»ts de processeur et de mÃ©moire seront justifiÃ©s, car il s'agit d'un investissement unique, et vous pourrez ensuite distribuer la vidÃ©o Ã  des millions d'utilisateurs.  Les meilleurs codecs vidÃ©o compressent la vidÃ©o en plusieurs passes: <br><br><ol><li>  Pass # 1: La vidÃ©o est divisÃ©e en parties avec des caractÃ©ristiques communes: l'action se dÃ©roule sur le mÃªme arriÃ¨re-plan, une scÃ¨ne rapide ou lente, etc. </li><li>  Pass # 2: Collectez des statistiques pour le codage et des informations sur la faÃ§on dont les trames changent au fil du temps (pour obtenir ces informations, vous avez besoin de plusieurs trames). </li><li>  Passe n Â° 3: chaque partie est codÃ©e avec ses propres paramÃ¨tres de codec et en utilisant les informations obtenues Ã  la deuxiÃ¨me Ã©tape. </li></ol><br>  Le streaming est une question complÃ¨tement diffÃ©rente.  Personne n'attendra la fin d'un podcast, d'un flux ou d'une Ã©mission avant de commencer Ã  encoder la vidÃ©o.  Encodez et envoyez immÃ©diatement.  Vivez dessus et dites que le dÃ©lai minimum devient le plus important. <br><br>  Lors de l'utilisation de supports physiques, de DVD ou de disques Blu-ray, la taille de la vidÃ©o est fixe et le codec est confrontÃ© Ã  la tÃ¢che d'assurer une qualitÃ© maximale pour une taille donnÃ©e.  Si la vidÃ©o est distribuÃ©e sur le rÃ©seau, la tÃ¢che du codec est de prÃ©parer ce ou ces fichiers afin d'obtenir la qualitÃ© maximale avec une largeur de canal fixe ou la largeur de canal minimale avec une qualitÃ© fixe, si vous devez rÃ©duire le prix.  Dans ce cas, les retards rÃ©seau peuvent Ãªtre ignorÃ©s et mis en mÃ©moire tampon cÃ´tÃ© client pendant autant de secondes de vidÃ©o que nÃ©cessaire.  Mais pour la diffusion en continu, il n'est pas nÃ©cessaire de fixer la taille ou la qualitÃ©, le codec a une tÃ¢che diffÃ©rente: rÃ©duire les retards Ã  tout prix. <br><br>  Enfin, les fabricants de codecs ont longtemps gardÃ© Ã  l'esprit un seul cas d'utilisation: sur l'ordinateur de l'utilisateur, une et une seule vidÃ©o est lue.  Qui, de plus, peut presque toujours Ãªtre dÃ©codÃ© par les forces d'une puce vidÃ©o.  Ensuite, il y avait les plateformes mobiles.  Et puis WebRTC, pour garantir la latence minimale dont les dÃ©veloppeurs souhaitaient vraiment utiliser les serveurs de l'unitÃ© de transfert sÃ©lectif. <br><br>  L'utilisation de codecs pour les appels vidÃ©o est tellement diffÃ©rente de l'utilisation traditionnelle lors de la lecture de vidÃ©os que la comparaison directe des codecs devient inutile.  Lorsque VP8 et H.264 ont Ã©tÃ© comparÃ©s Ã  l'aube de WebRTC, l'une des discussions les plus chaudes a portÃ© sur les paramÃ¨tres des codecs: les rendre Â«rÃ©alistesÂ» avec des rÃ©seaux peu fiables ou Â«idÃ©auxÂ» pour une qualitÃ© vidÃ©o maximale.  Les combattants de la Â«comparaison de codecs propresÂ» ont fait valoir trÃ¨s sÃ©rieusement que les codecs devaient Ãªtre comparÃ©s sans tenir compte de la perte de paquets, de la gigue et d'autres problÃ¨mes de rÃ©seau. <br><br><h2>  Et les codecs maintenant? </h2><br><ul><li>  H.264 et VP8 sont approximativement les mÃªmes en termes de rapport de qualitÃ© vidÃ©o et de largeur de canal utilisÃ©e; </li><li>  H.265 et VP9 correspondent Ã©galement Ã  peu prÃ¨s l'un Ã  l'autre, affichant en moyenne 30% de meilleurs rÃ©sultats par rapport aux codecs de la gÃ©nÃ©ration prÃ©cÃ©dente en raison d'une augmentation de la charge du processeur de 20%; </li><li>  le nouveau codec AV1, un mÃ©lange explosif de VP10, daala et thor, est meilleur que les codecs de la gÃ©nÃ©ration prÃ©cÃ©dente autant que ceux mieux que leurs prÃ©dÃ©cesseurs. </li></ul><br>  Et maintenant, une surprise: tout le monde ne se soucie pas de ces diffÃ©rences en matiÃ¨re d'appels vidÃ©o et de visioconfÃ©rence.  La chose la plus importante est de savoir comment le codec joue en Ã©quipe avec le reste de l'infrastructure.  Les dÃ©veloppeurs sont prÃ©occupÃ©s par ce qu'on appelle le nouveau terme <b>moteur de mÃ©dias</b> : comment un navigateur ou une application mobile capture la vidÃ©o, l'encode / dÃ©code, la dÃ©compose en paquets RTP et traite les problÃ¨mes de rÃ©seau (rappelez-vous la vidÃ©o de notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prÃ©cÃ©dent harast</a> ? <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article,</a> donc les mÃ©dias y ont Ã©tÃ© comparÃ©s moteur - note du traducteur).  Si le codeur ne peut pas fonctionner avec une forte diminution de la largeur du canal ou maintenir de maniÃ¨re stable 20 images par seconde, si le dÃ©codeur ne peut pas fonctionner avec la perte d'un paquet rÃ©seau, alors quelle diffÃ©rence cela fait-il Ã  quel point le codec comprime la vidÃ©o?  Il est facile de comprendre pourquoi Google sponsorise les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">recherches de Stanford</a> sur la meilleure interaction entre le codec et le rÃ©seau.  C'est l'avenir des communications vidÃ©o. <br><br><h2>  Codecs et moteur multimÃ©dia: tout est compliquÃ© </h2><br>  Les appels vidÃ©o et la vidÃ©oconfÃ©rence ont <b>presque</b> les mÃªmes tÃ¢ches que les mÃ©dias conventionnels.  Seules les prioritÃ©s sont <b>complÃ¨tement</b> diffÃ©rentes: <br><br><ol><li>  Il faut 30 images par seconde (vitesse du codec). </li><li>  Besoin de 30 images par seconde avec interactivitÃ© (dÃ©lai minimum). </li></ol><br>  Nous avons Ã©galement Internet entre les participants, dont nous ne pouvons que deviner la qualitÃ©.  Câ€™est gÃ©nÃ©ralement pire.  Par consÃ©quent: <br><br><ol><li>  Vous devez bien expÃ©rimenter de petits changements dans la largeur du canal lorsqu'un autre visiteur vient au coworking. </li><li>  Vous devez au moins ressentir des changements importants dans la largeur de la chaÃ®ne lorsque ce visiteur commence Ã  tÃ©lÃ©charger des torrents. </li><li>  Vous devez vous soucier de la gigue (retards alÃ©atoires entre les paquets reÃ§us, en raison desquels ils peuvent non seulement retarder, mais arriver dans le mauvais ordre dans lequel ils ont Ã©tÃ© envoyÃ©s). </li><li>  Besoin de vous inquiÃ©ter de la perte de paquets. </li></ol><br><h2>  3.1.  TÃ¢ches principales du moteur multimÃ©dia </h2><br>  Que signifie Â«30 images par secondeÂ»?  Cela signifie que le moteur multimÃ©dia dispose de 33 millisecondes pour capturer la vidÃ©o de la camÃ©ra, le son du microphone, la compresser avec un codec, la diviser en paquets RTP, protÃ©ger les donnÃ©es transmises (SRTP = RTP + AES) et envoyer sur le rÃ©seau (UDP ou TCP , dans la grande majoritÃ© des cas UDP).  Tout cela est du cÃ´tÃ© de l'envoi.  Et du cÃ´tÃ© de la rÃ©ception - rÃ©pÃ©tez dans l'ordre inverse.  Ã‰tant donnÃ© que le codage est gÃ©nÃ©ralement plus difficile que le dÃ©codage, le cÃ´tÃ© Ã©metteur a plus de mal. <br><br>  Sur le plan technique, l'objectif Â«30 images par secondeÂ» est rÃ©alisable avec des retards.  Et plus le dÃ©lai est long, plus il est facile d'atteindre l'objectif: si vous encodez du cÃ´tÃ© de l'envoi non pas plusieurs images Ã  la fois, mais plusieurs Ã  la fois, vous pouvez Ã©conomiser considÃ©rablement sur la largeur du canal (les codecs compressent mieux plusieurs images en analysant les changements entre elles toutes, et pas seulement entre le courant et le prÃ©cÃ©dent).  Dans le mÃªme temps, le dÃ©lai entre la rÃ©ception du flux vidÃ©o de la camÃ©ra et l'envoi sur le rÃ©seau augmente proportionnellement au nombre d'images mises en mÃ©moire tampon, plus la compression devient plus lente en raison de calculs supplÃ©mentaires.  De nombreux sites utilisent cette astuce, dÃ©clarant le temps de rÃ©ponse entre l'envoi et la rÃ©ception de paquets rÃ©seau entre les participants aux appels vidÃ©o.  Le retard dans l'encodage et le dÃ©codage, ils sont silencieux. <br><br>  Pour que les appels vidÃ©o ressemblent Ã  une communication personnelle, les crÃ©ateurs de services de communication refusent tous les paramÃ¨tres et profils de codec qui peuvent crÃ©er des retards.  Il s'avÃ¨re une telle dÃ©gradation des codecs modernes en compression trame par trame.  Au dÃ©but, une telle situation a suscitÃ© le rejet et les critiques des dÃ©veloppeurs de codecs.  Mais les temps ont changÃ©, et maintenant les codecs modernes en plus des prÃ©rÃ©glages traditionnels "taille minimale" et "qualitÃ© maximale" ont ajoutÃ© un ensemble de paramÃ¨tres "en temps rÃ©el".  Et en mÃªme temps, le Â«partage d'Ã©cranÂ» est Ã©galement pour les appels vidÃ©o (il a ses spÃ©cificitÃ©s - grande rÃ©solution, image lÃ©gÃ¨rement changeante, besoin de compression sans perte, sinon le texte flottera). <br><br><h2>  3.2.  Moteur mÃ©dia et rÃ©seaux publics </h2><br><blockquote>  Petits changements dans la largeur du canal </blockquote><br>  Auparavant, les codecs ne pouvaient pas modifier le dÃ©bit binaire: au dÃ©but de la compression, ils prenaient le dÃ©bit binaire cible comme paramÃ¨tre, puis Ã©mettaient un nombre fixe de mÃ©gaoctets de vidÃ©o par minute.  Ã€ cette Ã©poque, les appels vidÃ©o et les vidÃ©oconfÃ©rences Ã©taient le lot des rÃ©seaux locaux et de la bande passante redondante.  Et en cas de problÃ¨mes, le nom de l'administrateur a Ã©tÃ© appelÃ©, qui a fixÃ© la rÃ©servation de la largeur de canal sur tsiska. <br><br>  Le premier changement Ã©volutif a Ã©tÃ© la technologie du Â«dÃ©bit adaptatifÂ».  Le codec possÃ¨de de nombreux paramÃ¨tres qui affectent le dÃ©bit binaire: rÃ©solution vidÃ©o, une lÃ©gÃ¨re diminution des fps de 30 Ã  25 images par seconde, quantification du signal vidÃ©o.  Le dernier de cette liste est le Â«grossissementÂ» de la transition entre les couleurs, dont les lÃ©gers changements sont Ã  peine perceptibles Ã  l'Å“il humain.  Le plus souvent, le principal Â«rÃ©glageÂ» du dÃ©bit adaptatif Ã©tait prÃ©cisÃ©ment la quantification.  Et le moteur multimÃ©dia a indiquÃ© au codec la largeur du canal. <br><br><blockquote>  Changements importants dans la largeur du canal </blockquote><br>  Le mÃ©canisme adaptatif de dÃ©bit binaire aide le moteur multimÃ©dia Ã  continuer de diffuser de la vidÃ©o avec des changements mineurs dans la largeur du canal.  Mais si votre collÃ¨gue a commencÃ© Ã  tÃ©lÃ©charger des torrents et que le canal disponible a baissÃ© deux ou trois fois, le dÃ©bit adaptatif ne vous aidera pas.  Une rÃ©solution et une frÃ©quence d'images dÃ©croissantes vous aideront.  Ce dernier est prÃ©fÃ©rable, car nos yeux sont moins sensibles au nombre d'images par seconde qu'Ã  la rÃ©solution de la vidÃ©o.  En rÃ¨gle gÃ©nÃ©rale, le codec commence Ã  sauter une ou deux images, rÃ©duisant la frÃ©quence d'images de 30 Ã  15, voire Ã  10. <br><br>  DÃ©tail important: le moteur multimÃ©dia sautera les images cÃ´tÃ© envoi.  Si nous avons une vidÃ©oconfÃ©rence pour plusieurs participants ou une diffusion, et que l'expÃ©diteur n'a pas de problÃ¨me de rÃ©seau, alors un Â«maillon faibleÂ» aggravera la qualitÃ© vidÃ©o pour tous les participants.  Dans cette situation, un tas de simulcast aide (le cÃ´tÃ© Ã©metteur donne plusieurs flux vidÃ©o de qualitÃ© diffÃ©rente Ã  la fois) et SFU (Selective Forwarding Unit, le serveur donne Ã  chaque participant une vidÃ©oconfÃ©rence ou diffuse un flux de la qualitÃ© souhaitÃ©e).  Certains codecs ont la capacitÃ© de crÃ©er plusieurs flux simultanÃ©s, des SVC qui se complÃ¨tent: les clients avec le canal le plus faible reÃ§oivent un flux de qualitÃ© minimale, les clients avec un meilleur canal reÃ§oivent le mÃªme flux plus la premiÃ¨re Â«mise Ã  niveauÂ», les clients avec un canal encore meilleur sont donnÃ©s dÃ©jÃ  deux flux de "mise Ã  niveau" et ainsi de suite.  Cette mÃ©thode vous permet de ne pas transfÃ©rer les mÃªmes donnÃ©es vers plusieurs flux et Ã©conomise environ 20% du trafic par rapport au codage de plusieurs flux vidÃ©o Ã  part entiÃ¨re.  Il simplifie Ã©galement le fonctionnement du serveur - il n'est pas nÃ©cessaire de changer de flux, il suffit de ne pas transfÃ©rer de paquets avec une Â«mise Ã  niveauÂ» vers les clients.  NÃ©anmoins, n'importe quel codec peut Ãªtre utilisÃ© pour la diffusion simultanÃ©e, c'est une caractÃ©ristique du moteur multimÃ©dia et de l'organisation des paquets RTP, pas un codec. <br><br><blockquote>  Gigue et perte de paquets </blockquote><br>  Les pertes sont les plus difficiles Ã  combattre.  La gigue est un peu plus simple - il suffit de crÃ©er un tampon cÃ´tÃ© rÃ©ception dans lequel collecter les paquets en retard et confus.  Pas un tampon trop gros, sinon vous pouvez casser en temps rÃ©el et devenir une vidÃ©o YouTube en tampon. <br><br>  La perte de paquets est gÃ©nÃ©ralement combattue avec la redirection (RTX).  Si l'expÃ©diteur a une bonne communication avec la SFU, le serveur peut demander un paquet perdu, le rÃ©cupÃ©rer et respecter encore 33 millisecondes.  Si la connexion rÃ©seau n'est pas fiable (plus de 0,01% de perte de paquets), nous avons besoin d'algorithmes de travail de perte complexes, tels que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FEC</a> . <br><br>  Jusqu'Ã  prÃ©sent, la meilleure solution consiste Ã  utiliser des codecs SVC.  Dans ce cas, pour recevoir au moins une partie de la vidÃ©o, seuls les paquets Â«de rÃ©fÃ©renceÂ» avec un flux de qualitÃ© minimale sont nÃ©cessaires, ces paquets sont moins nombreux, il est donc plus facile de les renvoyer, cela suffit pour Â«survivreÂ» mÃªme avec un rÃ©seau trÃ¨s pauvre (plus de 1% de perte de paquets).  Si Simulcast + SFU vous permet de gÃ©rer l'affaissement de canal, Simulcast Ã  l'aide du codec SVC + SFU rÃ©sout Ã  la fois la largeur de canal et les problÃ¨mes de paquets perdus. <br><br><h2>  Quels navigateurs prennent dÃ©sormais en charge </h2><br>  Firefox et Safari utilisent le moteur multimÃ©dia de Google et mettent Ã  jour libwebrtc de temps Ã  autre.  Ils le font beaucoup moins souvent que Chrome, dont une nouvelle version sort toutes les 6 semaines.  De temps en temps, ils commencent Ã  Ãªtre loin derriÃ¨re, puis se synchronisent Ã  nouveau.  Ã€ l'exception de la prise en charge du codec VP8 dans Safari.  Ne demandez mÃªme pas. <br><br>  Avant Kat, un tableau avec une comparaison complÃ¨te de qui prend en charge quoi, mais en gÃ©nÃ©ral, tout est assez simple.  Edge est gÃ©nÃ©ralement ignorÃ© par tout le monde.  Le choix est entre le support de la version mobile de Safari et une bonne qualitÃ© vidÃ©o.  iOS Safari ne prend en charge que le codec vidÃ©o H.264, tandis que libwebrtc autorise uniquement la diffusion simultanÃ©e avec les codecs VP8 (diffÃ©rents flux avec diffÃ©rentes frÃ©quences d'images) et VP9 (prise en charge SVC).  Mais vous pouvez lire et utiliser libwebrtc sur iOS en crÃ©ant une application native.  Ensuite, avec la diffusion simultanÃ©e, tout ira bien et les utilisateurs recevront la meilleure qualitÃ© vidÃ©o possible avec une connexion Internet instable.  Quelques exemples: <br><br><ul><li>  <b>Highfive</b> - une application de bureau sur Electron (Chromium) avec diffusion simultanÃ©e H.264 (libwebrtc) et codecs sonores de Dolby; </li><li>  <b>Attlasian</b> - Une solution intÃ©ressante par le client sur React Native et libwebrtc pour la diffusion simultanÃ©e; </li><li>  <b>Symphony</b> - Electron pour le bureau, React Native pour les appareils mobiles et la diffusion simultanÃ©e sont pris en charge ici et lÃ  + des fonctionnalitÃ©s de sÃ©curitÃ© supplÃ©mentaires compatibles avec ce que veulent les banques; </li><li>  <b>Tokbox</b> - VP8 avec diffusion simultanÃ©e dans le SDK mobile, utilisez la version corrigÃ©e de libvpx dans libwebrtc. </li></ul><br><h2>  Le futur </h2><br>  Il est dÃ©jÃ  clair qu'il n'y aura pas de VP8 et VP9 dans Safari (contrairement Ã  Edge, que VP8 prend en charge). <br><br>  Bien qu'Apple ait soutenu l'inclusion de H.265 dans WebRTC, les nouvelles rÃ©centes et un certain nombre de signes indirects indiquent que AV1 est la Â«prochaine grande choseÂ».  Contrairement au reste de l'article, c'est mon opinion personnelle.  La spÃ©cification pour la transmission de donnÃ©es AV1 est dÃ©jÃ  prÃªte, mais le travail est toujours en cours sur le codec.  Maintenant, l'implÃ©mentation de rÃ©fÃ©rence de l'encodeur affiche un triste 0,3 images par seconde.  Ce n'est pas un problÃ¨me lors de la lecture de contenu prÃ©-compressÃ©, mais n'est pas encore applicable aux communications en temps rÃ©el.  En attendant, vous pouvez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">essayer de</a> lire des vidÃ©os AV1 dans Firefox, bien que cela ne soit pas liÃ© Ã  RTC.  L'implÃ©mentation est de l'Ã©quipe bitmovin, qui a dÃ©veloppÃ© MPEG-DASH et a reÃ§u 30 millions d'investissements dans la crÃ©ation de l'infrastructure de nouvelle gÃ©nÃ©ration pour travailler avec la vidÃ©o. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr419949/">https://habr.com/ru/post/fr419949/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr419939/index.html">Comment j'ai rendu la navigation dans React Native pas si terrible</a></li>
<li><a href="../fr419941/index.html">Visite photo du bureau Audiomania: premiÃ¨re partie</a></li>
<li><a href="../fr419943/index.html">Ce que nous lisons en juillet: comment trouver du temps pour lire, cinq livres pour le chef d'Ã©quipe et quelques articles frais</a></li>
<li><a href="../fr419945/index.html">Comment se prÃ©parer Ã  un entretien sur Google et ne pas le passer. Deux fois</a></li>
<li><a href="../fr419947/index.html">Connectez-vous Ã  PiZeroW avec Raspbian Stretch Lite, sans adaptateurs supplÃ©mentaires ni moniteur</a></li>
<li><a href="../fr419951/index.html">ExpÃ©rience de l'utilisation de WebRTC. ConfÃ©rence Yandex</a></li>
<li><a href="../fr419953/index.html">J'Ã©cris un livre sur la premiÃ¨re Â«notreÂ» startup qui a conquis le monde: aide</a></li>
<li><a href="../fr419955/index.html">CaractÃ©ristiques du tampon FIFO UART dans ESP32</a></li>
<li><a href="../fr419961/index.html">Le condensÃ© de matÃ©riaux intÃ©ressants pour le dÃ©veloppeur mobile # 265 (6 aoÃ»t - 12 aoÃ»t)</a></li>
<li><a href="../fr419963/index.html">Nous fabriquons un contrÃ´leur "intelligent" pour le climatiseur sur l'ESP8266</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
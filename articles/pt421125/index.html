<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ôàÔ∏è üßí ‚ûó Segmentamos 600 milh√µes de usu√°rios em tempo real todos os dias üéÖüèª üö∂üèº üëâüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todos os dias, os usu√°rios comprometem milh√µes de atividades online. O projeto FACETz DMP precisa estruturar esses dados e segment√°-los para identific...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Segmentamos 600 milh√µes de usu√°rios em tempo real todos os dias</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jugru/blog/421125/">  Todos os dias, os usu√°rios comprometem milh√µes de atividades online.  O projeto FACETz DMP precisa estruturar esses dados e segment√°-los para identificar as prefer√™ncias do usu√°rio.  No artigo, falaremos sobre como a equipe segmentou uma audi√™ncia de 600 milh√µes de pessoas, processou 5 bilh√µes de eventos diariamente e trabalhou com estat√≠sticas usando Kafka e HBase. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/5Ybt_k53CIE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  O material √© baseado na transcri√ß√£o de um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">relat√≥rio de Artyom Marinov</a> , especialista em big data da Directual, da confer√™ncia SmartData 2017. <br><a name="habracut"></a><br>  Meu nome √© Artyom Marinov. Quero falar sobre como redesenhamos a arquitetura do projeto FACETz DMP quando trabalhei na Data Centric Alliance.  Por que fizemos, o que levou, para onde seguimos e que problemas encontramos. <br><br>  O DMP (Data Management Platform) √© uma plataforma para coletar, processar e agregar dados do usu√°rio.  Dados s√£o muitas coisas diferentes.  A plataforma tem cerca de 600 milh√µes de usu√°rios.  S√£o milh√µes de cookies que entram na Internet e fazem v√°rios eventos.  Em geral, um dia, em m√©dia, se parece com isso: vemos cerca de 5,5 bilh√µes de eventos por dia, eles s√£o espalhados de dia para dia e, no pico, atingem cerca de 100 mil eventos por segundo. <img src="https://habrastorage.org/getpro/habr/post_images/f66/f4d/915/f66f4d9154b1ddad3c3bb8af7e5ba860.png">  Eventos s√£o v√°rios sinais do usu√°rio.  Por exemplo, uma visita a um site: vemos de qual navegador o usu√°rio parte, seu agente do usu√°rio e tudo o que podemos extrair.  √Äs vezes, vemos como e para que consultas de pesquisa ele veio ao site.  Tamb√©m podem ser v√°rios dados do mundo offline, por exemplo, o que ele paga com cupons de desconto e assim por diante. <br><br>  Precisamos salvar esses dados e marcar o usu√°rio nos chamados grupos de segmentos de p√∫blico.  Por exemplo, os segmentos podem ser uma "mulher" que "adora gatos" e est√° procurando "servi√ßo de carro", ela "tem um carro com mais de tr√™s anos". <br><br>  Por que segmentar um usu√°rio?  Existem muitos aplicativos para isso, por exemplo, publicidade.  V√°rias redes de an√∫ncios podem otimizar os algoritmos de veicula√ß√£o de an√∫ncios.  Se voc√™ estiver anunciando seu servi√ßo de carro, poder√° configurar uma campanha de forma que apenas pessoas que tenham um carro antigo mostrem informa√ß√µes, excluindo propriet√°rios de novos.  Voc√™ pode alterar dinamicamente o conte√∫do do site, pode usar os dados para pontua√ß√£o - existem muitos aplicativos. <br><br>  Os dados s√£o obtidos de muitos lugares completamente diferentes.  Pode ser configura√ß√µes diretas de pixel - isto √©, se o cliente deseja analisar sua audi√™ncia, ele coloca o pixel no site, uma imagem invis√≠vel que √© baixada do nosso servidor.  O ponto principal √© que vemos a visita do usu√°rio a este site: voc√™ pode salv√°-lo, come√ßar a analisar e entender o retrato do usu√°rio, todas essas informa√ß√µes est√£o dispon√≠veis para o nosso cliente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad9/ebf/849/ad9ebf84913e17fb9e84a947b256a810.png"><br>  Os dados podem ser obtidos de v√°rios parceiros que veem muitos dados e desejam monetiz√°-los de v√°rias maneiras.  Os parceiros podem fornecer dados em tempo real e fazer uploads peri√≥dicos na forma de arquivos. <br><br>  Principais requisitos: <br><br><ul><li>  Escalabilidade horizontal; </li><li>  Avalia√ß√£o do volume da audi√™ncia; </li><li>  Conveni√™ncia de monitoramento e desenvolvimento; </li><li>  Boa taxa de rea√ß√£o a eventos. </li></ul><br>  Um dos principais requisitos do sistema √© a escalabilidade horizontal.  H√° um momento em que, quando voc√™ est√° desenvolvendo um portal ou loja online, pode estimar o n√∫mero de usu√°rios (como ele crescer√°, como ele mudar√°) e entender√° a quantidade de recursos necess√°rios e como a loja viver√° e se desenvolver√° com o tempo. <br><br>  Ao desenvolver uma plataforma semelhante ao DMP, voc√™ precisa estar preparado para o fato de que qualquer site grande - a Amazon condicional - pode colocar seu pixel nele, e voc√™ ter√° que trabalhar com o tr√°fego desse site inteiro, enquanto n√£o deve cair, e os indicadores os sistemas n√£o devem, de alguma forma, mudar disso. <br><br>  Tamb√©m √© muito importante entender o volume de um determinado p√∫blico para que um anunciante em potencial ou outra pessoa possa elaborar um plano de m√≠dia.  Por exemplo, uma pessoa vem at√© voc√™ e pede que voc√™ descubra quantas mulheres gr√°vidas de Novosibirsk est√£o procurando uma hipoteca para avaliar se faz sentido direcion√°-las ou n√£o. <br><br>  Do ponto de vista do desenvolvimento, voc√™ precisa monitorar tudo o que acontece no seu sistema, depurar parte do tr√°fego real e assim por diante. <br><br>  Um dos requisitos mais importantes do sistema √© uma boa taxa de rea√ß√£o a eventos.  Quanto mais r√°pido os sistemas respondem aos eventos, melhor √© √≥bvio.  Se voc√™ estiver procurando por ingressos para o teatro, poder√° ver algum tipo de oferta de desconto ap√≥s um dia, dois dias ou at√© uma hora - isso pode ser irrelevante, pois voc√™ j√° pode comprar ingressos ou assistir a uma apresenta√ß√£o.  Quando voc√™ est√° procurando uma broca - voc√™ est√° procurando, encontra, compra, pendura uma prateleira e, ap√≥s alguns dias, o bombardeio come√ßa: ‚ÄúCompre uma broca!‚Äù. <br><br><h3>  Como era antes </h3><br>  O artigo como um todo √© sobre reciclagem de arquitetura.  Gostaria de dizer qual foi o nosso ponto de partida, como tudo funcionou antes das mudan√ßas. <br><br>  Todos os dados que t√≠nhamos, fosse um fluxo de dados direto ou logs, foram armazenados no HDFS - armazenamento de arquivos distribu√≠dos.  Depois, houve um certo processo iniciado periodicamente, pegou todos os arquivos n√£o processados ‚Äã‚Äãdo HDFS e os converteu em solicita√ß√µes de enriquecimento de dados no HBase ("solicita√ß√µes de PUT"). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c6/902/3eb/3c69023eb0fc851d8acc327a7b57fb22.png"><br><br><h3>  Como armazenamos dados no HBase </h3><br>  Este √© um banco de dados colunar de s√©ries temporais.  Ela tem o conceito de uma chave de linha - esta √© a chave sob a qual voc√™ armazena seus dados.  Usamos o ID do usu√°rio como a chave, o ID do usu√°rio, que geramos quando o vemos pela primeira vez.  Dentro de cada chave, os dados s√£o divididos em Fam√≠lia de colunas - entidades no n√≠vel em que voc√™ pode gerenciar as metainforma√ß√µes de seus dados.  Por exemplo, voc√™ pode armazenar mil vers√µes de registros para os "dados" da Fam√≠lia de Colunas e armazen√°-los por dois meses, e para a Fam√≠lia de Colunas "brutos" - um ano, como op√ß√£o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/89f/fb5/46e/89ffb546efcad40cd08d140df54ac6a4.png"><br>  Dentro da fam√≠lia de colunas, h√° muitos qualificadores de coluna (a seguir coluna).  Usamos v√°rios atributos do usu√°rio como coluna.  Pode ser o URL para o qual ele foi, endere√ßo IP, consulta de pesquisa.  E o mais importante, muitas informa√ß√µes s√£o armazenadas dentro de cada coluna.  Dentro do URL da coluna, pode ser indicado que o usu√°rio foi para smartdataconf.ru e depois para outros sites.  E o carimbo de data / hora √© usado como a vers√£o - voc√™ v√™ um hist√≥rico ordenado de visitas de usu√°rios.  No nosso caso, podemos determinar que o usu√°rio acessou o site smartdataconf com a palavra-chave ‚Äúconference‚Äù, porque eles t√™m o mesmo registro de data e hora. <br><br><h3>  Trabalhar com HBase </h3><br>  Existem v√°rias op√ß√µes para trabalhar com o HBase.  Podem ser solicita√ß√µes PUT (solicita√ß√£o de altera√ß√£o de dados), solicita√ß√£o GET ("forne√ßa todos os dados do usu√°rio Vasya" e assim por diante).  Voc√™ pode executar solicita√ß√µes de digitaliza√ß√£o - varredura sequencial multithread de todos os dados no HBase.  Usamos isso anteriormente para marcar nos segmentos de p√∫blico. <br><br>  Havia uma tarefa chamada Analytics Engine, que era executada uma vez por dia e examinava o HBase em v√°rios threads.  Para cada usu√°rio, ela retirou toda a hist√≥ria do HBase e a executou atrav√©s de um conjunto de scripts anal√≠ticos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fba/b4c/674/fbab4c674fabf2f07e0dc8553e8b6cfc.png"><br>  O que √© um script anal√≠tico?  Esse √© um tipo de caixa preta (classe java), que recebe todos os dados do usu√°rio como entrada e fornece um conjunto de segmentos que considera adequados como sa√≠da.  Damos tudo ao script que vemos - IP, visitas, UserAgent, etc., e a sa√≠da dos scripts √©: ‚Äúessa √© uma mulher, adora gatos, n√£o gosta de cachorros‚Äù. <br><br>  Esses dados foram fornecidos aos parceiros, as estat√≠sticas foram consideradas.  Era importante para n√≥s entender quantas mulheres s√£o em geral, quantos homens, quantas pessoas amam gatos, quantas t√™m ou n√£o um carro e assim por diante. <br><br>  Armazenamos estat√≠sticas no MongoDB e escrevemos incrementando um contador de segmento espec√≠fico para cada dia.  Tivemos um gr√°fico do volume de cada segmento para cada dia. <br><br>  Este sistema foi bom para o seu tempo.  Permitiu escalar horizontalmente, crescer, permitiu estimar o volume da audi√™ncia, mas teve v√°rias desvantagens. <br><br>  Nem sempre era poss√≠vel entender o que estava acontecendo no sistema, observar os logs.  Enquanto est√°vamos no hoster anterior, a tarefa muitas vezes caiu por v√°rias raz√µes.  Havia um cluster Hadoop de mais de 20 servidores, uma vez por dia, um dos servidores travava de maneira est√°vel.  Isso levou ao fato de que a tarefa poderia cair parcialmente e n√£o calcular os dados.  Era necess√°rio ter tempo para reinici√°-lo e, dado que funcionou por v√°rias horas, havia v√°rias nuances. <br><br>  A coisa mais b√°sica que a arquitetura existente n√£o cumpriu foi que o tempo de rea√ß√£o ao evento foi muito longo.  H√° at√© uma hist√≥ria sobre esse assunto.  Havia uma empresa que emitia microempr√©stimos para a popula√ß√£o das regi√µes e fizemos uma parceria com eles.  O cliente chega ao site, preenche um pedido de microcr√©dito, a empresa precisa responder em 15 minutos: eles est√£o prontos para conceder um empr√©stimo ou n√£o.  Se voc√™ estiver pronto, eles imediatamente transferiram dinheiro para o cart√£o. <br><br>  Tudo funcionou bem.  O cliente decidiu verificar como isso geralmente acontece: eles pegaram um laptop separado, instalaram um sistema limpo, visitaram muitas p√°ginas na Internet e acessaram o site.  Eles veem que h√° uma solicita√ß√£o e, em resposta, dizemos que ainda n√£o h√° dados.  O cliente pergunta: "Por que n√£o h√° dados?" <br><br>  N√≥s explicamos: existe um certo atraso antes que o usu√°rio tome uma a√ß√£o.  Os dados s√£o enviados para o HBase, processados ‚Äã‚Äãe somente ent√£o o cliente recebe o resultado.  Parece que se o usu√°rio n√£o viu o an√∫ncio - tudo est√° em ordem, nada de ruim acontecer√°.  Mas nessa situa√ß√£o, o usu√°rio pode n√£o receber um empr√©stimo por causa do atraso. <br><br>  Este n√£o √© um caso isolado e foi necess√°rio mudar para um sistema em tempo real.  O que queremos dela? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad8/103/d08/ad8103d08bb70410bcc51c8fdd99b3f5.png"><br>  Queremos gravar dados no HBase assim que os vemos.  Vimos uma visita, enriquecemos tudo o que sabemos e a enviamos para a Storage.  Assim que os dados no Storage forem alterados, voc√™ precisar√° executar imediatamente todo o conjunto de scripts anal√≠ticos que temos.  Queremos a conveni√™ncia do monitoramento e desenvolvimento, a capacidade de escrever novos scripts, depur√°-los em partes do tr√°fego real.  Queremos entender o que o sistema est√° ocupado no momento. <br><br>  A primeira coisa que come√ßamos √© resolver o segundo problema: segmentar o usu√°rio imediatamente ap√≥s alterar os dados sobre ele no HBase.  Inicialmente, t√≠nhamos n√≥s de trabalho (tarefas de redu√ß√£o de mapa foram lan√ßadas neles) localizados no mesmo local que o HBase.  Em v√°rios casos, foi muito bom - os c√°lculos s√£o realizados pr√≥ximos aos dados, as tarefas funcionam rapidamente, pouco tr√°fego passa pela rede.  √â claro que a tarefa consome alguns recursos, porque executa scripts anal√≠ticos complexos. <br><br>  Quando vamos trabalhar em tempo real, a natureza da carga no HBase muda.  Passamos para leituras aleat√≥rias em vez de sequenciais.  √â importante que a carga no HBase seja esperada - n√£o podemos permitir que algu√©m execute a tarefa no cluster Hadoop e prejudique o desempenho do HBase. <br><br>  A primeira coisa que fizemos foi mover o HBase para servidores separados.  Tamb√©m aprimoramos o BlockCache e o BloomFilter.  Em seguida, fizemos um bom trabalho em como armazenar dados no HBase.  Eles praticamente reformularam o sistema sobre o qual falei no in√≠cio e colheram os dados em si. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/191/f68/3c9/191f683c9cddf8d90f43cafc5c1163a3.png"><br>  Do √≥bvio: n√≥s armazenamos o IP como uma string e ficamos longos em n√∫meros.  Alguns dados foram classificados, executaram coisas de vocabul√°rio e assim por diante.  O ponto principal √© que, por causa disso, conseguimos sacudir o HBase cerca de duas vezes - de 10 TB a 5 TB.  O HBase possui um mecanismo semelhante aos gatilhos em um banco de dados regular.  Este √© um mecanismo de coprocessador.  Escrevemos um coprocessador que, quando um usu√°rio muda para o HBase, envia o ID do usu√°rio para Kafka. <br><br>  O ID do usu√°rio est√° em Kafka.  Al√©m disso, existe um certo "segmentador" de servi√ßo.  Ele l√™ o fluxo de identificadores de usu√°rios e executa neles todos os mesmos scripts que eram antes, solicitando dados do HBase.  O processo foi lan√ßado em 10% do tr√°fego, vimos como ele funciona.  Tudo foi muito bom. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c1/589/928/8c15899287c8a623bb63df3f85ba84e6.png"><br>  Em seguida, come√ßamos a aumentar a carga e vimos v√°rios problemas.  A primeira coisa que vimos foi que o servi√ßo funciona, segmenta e depois cai do Kafka, se conecta e come√ßa a funcionar novamente.  V√°rios servi√ßos - eles se ajudam.  Ent√£o o pr√≥ximo cai, outro e assim por diante em um c√≠rculo.  Ao mesmo tempo, a fila de usu√°rios para segmenta√ß√£o quase n√£o est√° sendo processada. <br><br>  Isso ocorreu devido √† peculiaridade do mecanismo de batimento card√≠aco em Kafka, que ainda era a vers√£o 0.8.  Pulsa√ß√£o √© quando os consumidores dizem ao corretor se est√£o vivos ou n√£o, no nosso caso, o segmentador relata.  Aconteceu o seguinte: recebemos um pacote de dados bastante grande e o enviamos para processamento.  Por um tempo, funcionou, enquanto funcionava - nenhum batimento card√≠aco foi enviado.  Os corretores acreditavam que o consumidor estava morto e o desligaram. <br><br>  O consumidor trabalhou at√© o fim, desperdi√ßando CPUs preciosas, tentou dizer que o pacote de dados estava funcionando e o pr√≥ximo poderia ser levado, mas ele foi recusado porque o outro levou embora o que estava trabalhando.  Corrigimos o problema com o calor do fundo, e a verdade veio a uma vers√£o mais recente do Kafka, onde solucionamos esse problema. <br><br>  Surgiu ent√£o a pergunta: em que tipo de hardware nossos segmentadores deveriam ser instalados.  A segmenta√ß√£o √© um processo intensivo de recursos (vinculado √† CPU).  √â importante que o servi√ßo n√£o apenas consuma muita CPU, mas tamb√©m carregue a rede.  Agora o tr√°fego atinge 5 Gbit / s.  A quest√£o era: onde colocar os servi√ßos, em muitos servidores pequenos ou um pouco grandes. <br><br>  Nesse momento, j√° nos mudamos para o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">servers.com</a> em metal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">puro</a> .  Conversamos com os funcion√°rios dos servidores, eles nos ajudaram, possibilitaram testar o trabalho da nossa solu√ß√£o em um pequeno n√∫mero de servidores caros e em muitos baratos com CPUs poderosas.  Escolhemos a op√ß√£o apropriada, calculando o custo unit√°rio do processamento de um evento por segundo.  A prop√≥sito, a escolha recaiu sobre o Dell R230, suficientemente poderoso e ao mesmo tempo extremamente acess√≠vel, eles o lan√ßaram - tudo funcionou. <br><br>  √â importante que, depois que o segmentador tenha marcado o usu√°rio em segmentos, o resultado de sua an√°lise retorne a Kafka, em um determinado t√≥pico Resultado da segmenta√ß√£o. <br><br>  Al√©m disso, podemos nos conectar de maneira independente a esses dados por diferentes consumidores que n√£o interferem entre si.  Isso nos permite fornecer dados de forma independente para cada parceiro, sejam alguns parceiros externos, DSP interno, Google, estat√≠sticas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1e7/051/526/1e705152621996ed538a6a3910e8db47.png"><br>  Com as estat√≠sticas, h√° tamb√©m um ponto interessante: antes, poder√≠amos aumentar o valor dos contadores no MongoDB, quantos usu√°rios estavam em um determinado segmento por um determinado dia.  Agora, isso n√£o pode ser feito porque agora analisamos cada usu√°rio depois que ele conclui um evento, ou seja,  v√°rias vezes ao dia. <br><br>  Portanto, tivemos que resolver o problema de contar o n√∫mero exclusivo de usu√°rios no fluxo.  Para isso, usamos a estrutura de dados HyperLogLog e sua implementa√ß√£o no Redis.  A estrutura de dados √© probabil√≠stica.  Isso significa que voc√™ pode adicionar identificadores de usu√°rio l√°, os identificadores em si n√£o ser√£o armazenados; portanto, voc√™ pode armazenar milh√µes de identificadores exclusivos no HyperLogLog extremamente compactos, e isso levar√° at√© 12 kilobytes por chave. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2a6/572/614/2a6572614da5ccffd52271292e646e9d.png"><br><br>  Voc√™ n√£o pode obter os identificadores por conta pr√≥pria, mas pode descobrir o tamanho desse conjunto.  Como a estrutura de dados √© probabil√≠stica, h√° algum erro.  Por exemplo, se voc√™ tiver um segmento "gosta de gatos", solicitando o tamanho desse segmento por um determinado dia, receber√° 99,2 milh√µes e isso significar√° algo como "de 99 a 100 milh√µes". <br><br>  Tamb√©m no HyperLogLog, voc√™ pode obter o tamanho da uni√£o de v√°rios conjuntos.  Digamos que voc√™ tenha dois segmentos: "adora focas" e "adora cachorros".  Digamos os primeiros 100 milh√µes, o segundo 1 milh√£o.Pode-se perguntar: "Quantos animais eles gostam?"  e obtenha a resposta "cerca de 101 milh√µes" com um erro de 1%.  Seria interessante calcular quanto gatos e c√£es s√£o amados ao mesmo tempo, mas fazer isso √© bastante dif√≠cil. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/380/74d/500/38074d5004513c86015c8d2770047f56.png"><br>  Por um lado, voc√™ pode descobrir o tamanho de cada conjunto, descobrir o tamanho da uni√£o, adicionar, subtrair um do outro e obter a interse√ß√£o.  Mas, como o tamanho do erro pode ser maior que o tamanho da interse√ß√£o final, o resultado final pode ter a forma "de -50 a 50 mil". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/08d/3ba/520/08d3ba520f5c91efd84822d63f299c83.png"><br>  N√≥s trabalhamos bastante em como aumentar o desempenho ao gravar dados no Redis.  Inicialmente, alcan√ßamos 200 mil opera√ß√µes por segundo.  Mas quando cada usu√°rio tem mais de 50 segmentos - registrando informa√ß√µes sobre cada usu√°rio - 50 opera√ß√µes.  Acontece que somos bastante limitados em largura de banda e, neste exemplo, n√£o podemos gravar informa√ß√µes sobre mais de 4 mil usu√°rios por segundo, isso √© v√°rias vezes menor do que precisamos. <br><br>  N√≥s fizemos um ‚Äúprocedimento armazenado‚Äù separado no Redis via Lua, carregamos l√° e come√ßamos a passar uma string para ele com a lista inteira de segmentos de um usu√°rio.  O procedimento interno cortar√° a sequ√™ncia passada nas atualiza√ß√µes necess√°rias do HyperLogLog e salvar√° os dados, portanto, alcan√ßamos cerca de 1 milh√£o de atualiza√ß√µes por segundo. <br><br>  Um pouco incondicional: o Redis √© de thread √∫nico, voc√™ pode fix√°-lo em um n√∫cleo de processador e uma placa de rede em outra e obter outro desempenho de 15%, economizando na altern√¢ncia de contexto.  Al√©m disso, o ponto importante √© que voc√™ n√£o pode simplesmente agrupar a estrutura de dados, porque as opera√ß√µes de obten√ß√£o do poder dos uni√µes de conjuntos n√£o s√£o agrupadas <br><br><h3>  Kafka √© uma √≥tima ferramenta </h3><br>  Voc√™ v√™ que o Kafka √© nossa principal ferramenta de transporte no sistema. <br>  Tem a ess√™ncia do "t√≥pico".  √â aqui que voc√™ escreve os dados, mas em ess√™ncia - a fila.  No nosso caso, existem v√°rias filas.  Um deles √© o identificador de usu√°rios a quem √© necess√°rio segmentar.  O segundo s√£o os resultados da segmenta√ß√£o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f35/eb3/8c2/f35eb38c205fec791ea2f42d41a8c875.png"><br>  Um t√≥pico √© um conjunto de parti√ß√µes s.  √â dividido em algumas partes.  Cada parti√ß√£o √© um arquivo no disco r√≠gido.  Quando seus produtores gravam dados, eles escrevem trechos de texto no final da parti√ß√£o.  Quando seus consumidores leem os dados, eles simplesmente leem dessas parti√ß√µes. <br><br>  O importante √© que voc√™ possa conectar independentemente v√°rios grupos de consumidores, eles consumir√£o dados sem interferir entre si.  Isso √© determinado pelo nome do grupo de consumidores e √© alcan√ßado da seguinte maneira. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/157/5f7/23d/1575f723d77042fd058b9c30bc050247.png"><br>  Existe o deslocamento, a posi√ß√£o em que o grupo de consumidores agora est√° localizado em cada parti√ß√£o.  Por exemplo, o grupo A consome a s√©tima mensagem da parti√ß√£o1 e a quinta da parti√ß√£o2.  O grupo B, independente de A, tem outro deslocamento. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f8a/10f/1a0/f8a10f1a04b8614f6b9a437142b0db7b.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voc√™ pode dimensionar seu grupo de consumidores horizontalmente, adicionar outro processo ou servidor. Isso acontecer√° com a reatribui√ß√£o de parti√ß√µes (o Kafka broker atribuir√° a cada consumidor uma lista de parti√ß√µes para consumo) Isso significa que o primeiro grupo de consumidores come√ßar√° a consumir apenas a parti√ß√£o 1 e o segundo consumir√° apenas a parti√ß√£o 2. Se alguns dos consumidores morrerem (por exemplo, o ritmo do cora√ß√£o n√£o chega), uma nova reatribui√ß√£o , cada consumidor recebe uma lista de parti√ß√µes atualizada para processamento.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/56b/40b/bde/56b40bbde5b1890d35f67a481c4a6462.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√â bastante conveniente. Primeiro, voc√™ pode manipular o deslocamento para cada grupo de consumidores. Imagine que exista um parceiro para quem voc√™ transfira dados deste t√≥pico com os resultados da segmenta√ß√£o. Ele escreve que perdeu acidentalmente o √∫ltimo dia de dados como resultado de um bug. E voc√™, para o grupo de consumidores desse cliente, reverte um dia e despeje todo o dia de dados nele. Tamb√©m podemos ter nosso pr√≥prio grupo de consumidores, conectar-se ao tr√°fego de produ√ß√£o, observar o que acontece e depurar dados reais. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Assim, conseguimos que come√ßamos a segmentar usu√°rios ao mudar, podemos conectar independentemente novos consumidores, escrevemos estat√≠sticas e podemos assisti-las. Agora voc√™ precisa obter os dados gravados no HBase imediatamente ap√≥s a chegada deles.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c4e/eec/d6c/c4eeecd6ce987e902fee723a089ab780.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como n√≥s fizemos isso. Costumava haver carregamento de dados em lote. Havia um Batch Loader, que processava arquivos de log de atividades do usu√°rio: se um usu√°rio fazia 10 visitas, o lote vinha para 10 eventos, ele era registrado no HBase em uma opera√ß√£o. Houve apenas um evento por segmenta√ß√£o. Agora queremos escrever cada evento separado no armazenamento. Aumentaremos bastante o fluxo de grava√ß√£o e o fluxo de leitura. O n√∫mero de eventos por segmenta√ß√£o tamb√©m aumentar√°.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/79a/849/910/79a8499101ac2cb58ccf272abb668f6f.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A primeira coisa que fizemos foi portar o HBase para o SSD. Por meios padr√£o, isso n√£o √© feito particularmente. Isso foi feito usando o HDFS. Voc√™ pode dizer que um diret√≥rio espec√≠fico no HDFS deve estar nesse grupo de discos. Houve um problema legal com o fato de que, quando levamos o HBase para o SSD e o esvaziamos, todos os instant√¢neos chegaram l√° e nossos SSDs terminaram rapidamente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Isso tamb√©m foi resolvido, come√ßamos a exportar periodicamente instant√¢neos para um arquivo, gravar em outro diret√≥rio do HDFS e excluir todas as meta-informa√ß√µes sobre os instant√¢neos. Se voc√™ precisar restaurar - pegue o arquivo salvo, importe e restaure. Felizmente, esta opera√ß√£o n√£o √© frequente.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tamb√©m no SSD, eles removeram o Write Ahead Log, torceram o MemStore, ativaram o bloco de cache na op√ß√£o de grava√ß√£o. Ele permite que voc√™ os coloque imediatamente no cache do bloco ao gravar dados. Isso √© muito conveniente porque no nosso caso, se registrarmos os dados, √© altamente prov√°vel que sejam lidos imediatamente. Isso tamb√©m deu algumas vantagens. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em seguida, mudamos todas as nossas fontes de dados para gravar dados no Kafka. J√° em Kafka, registramos dados no HDFS para manter a compatibilidade com vers√µes anteriores, inclusive para que nossos analistas pudessem trabalhar com dados, executar tarefas do MapReduce e analisar seus resultados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conectamos um grupo de consumidores separado que grava dados no HBase. Este √©, de fato, um wrapper que l√™ Kafka e forma os PUTs no HBase.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d53/267/0b3/d532670b344a70dadf97c5c4674b1596.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lan√ßamos dois circuitos em paralelo para n√£o prejudicar a compatibilidade com vers√µes anteriores e n√£o prejudicar o desempenho do sistema. Um novo esquema foi lan√ßado apenas em uma certa porcentagem de tr√°fego. Com 10%, tudo foi bem legal. Por√©m, com uma carga maior, os segmentadores n√£o conseguiam lidar com o fluxo de segmenta√ß√£o. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d20/3fa/78c/d203fa78c3d0b80ee7c7a5dce34f558b.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Coletamos a m√©trica "quantas mensagens existem em Kafka antes de serem lidas a partir da√≠". Essa √© uma boa m√©trica. Inicialmente, coletamos a m√©trica "quantas mensagens brutas existem agora", mas n√£o diz nada de especial. Voc√™ olha: "Eu tenho um milh√£o de mensagens brutas", e da√≠? Para interpretar esse milh√£o, voc√™ precisa saber com que rapidez o segmentador (consumidor) est√° funcionando, o que nem sempre √© claro.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Com essa m√©trica, voc√™ v√™ imediatamente que os dados est√£o sendo gravados na fila, extra√≠dos dela e o quanto eles esperam que sejam processados. </font><font style="vertical-align: inherit;">Vimos que n√£o t√≠nhamos tempo para segmentar e a mensagem estava na fila v√°rias horas antes de l√™-la. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voc√™ pode simplesmente adicionar capacidade, mas seria muito </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">caro</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Portanto, tentamos otimizar.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Auto-dimension√°vel </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N√≥s temos o HBase. O usu√°rio est√° mudando, seu identificador est√° voando em Kafka. O t√≥pico √© dividido em parti√ß√µes, a parti√ß√£o de destino √© selecionada pelo ID do usu√°rio. Isso significa que quando voc√™ v√™ o usu√°rio "Vasya" - ele vai para a parti√ß√£o 1. Quando voc√™ v√™ "Petya" - para particionar 2. Isso √© conveniente - voc√™ pode conseguir que ver√° um consumidor em uma inst√¢ncia do seu servi√ßo e o segundo - por outro. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/299/573/aef/299573aefcae8b909623e246d4a2cf80.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Come√ßamos a assistir o que estava acontecendo. Um comportamento t√≠pico do usu√°rio na Internet √© acessar um site e abrir v√°rias guias em segundo plano. O segundo √© ir ao site e fazer alguns cliques para chegar √† p√°gina de destino.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Observamos a fila de segmenta√ß√£o e vemos o seguinte: O usu√°rio A visitou a p√°gina. Mais 5 eventos v√™m desse usu√°rio - cada um significa uma abertura de p√°gina. Processamos cada evento do usu√°rio. Mas, de fato, os dados no HBase cont√™m todas as 5 visitas. Processamos todas as 5 visitas pela primeira vez, pela segunda vez e assim por diante - estamos desperdi√ßando recursos da CPU. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6df/eba/fbf/6dfebafbf435cfb43e5b71cc7d2016fd.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Portanto, come√ßamos a armazenar um determinado cache local em cada um dos segmentadores com a data em que analisamos esse usu√°rio pela √∫ltima vez. Ou seja, n√≥s processamos, escrevemos seu ID do usu√°rio e carimbo de data e hora no cache. Cada mensagem kafka tamb√©m possui um registro de data e hora - simplesmente a comparamos: se o registro de data e hora na fila for menor que a data da √∫ltima segmenta√ß√£o - j√° analisamos o usu√°rio para esses dados e voc√™ pode simplesmente pular esse evento.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Os eventos do usu√°rio (Vermelho A) podem ser diferentes e ficam fora de ordem. O usu√°rio pode abrir v√°rias guias em segundo plano, abrir v√°rios links seguidos, talvez o site tenha v√°rios de nossos parceiros ao mesmo tempo, cada um dos quais envia esses dados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nosso pixel pode ver a visita do usu√°rio e outras a√ß√µes - enviaremos o capacete para n√≥s. Chegam cinco eventos, estamos processando o primeiro A. vermelho. Se o evento chegou, ele j√° est√° no HBase. Vemos eventos, executamos um conjunto de scripts. Vemos o seguinte evento, e todos os mesmos eventos, porque eles j√° est√£o gravados. N√≥s o executamos novamente e salvamos o cache com a data, comparamos com o registro de data e hora do evento.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f5/a41/48b/3f5a4148b5b8f14067816cda7b7bfade.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gra√ßas a isso, o sistema obteve a propriedade de auto-escalabilidade. O eixo y √© a porcentagem do que fazemos com os IDs de usu√°rio quando eles chegam at√© n√≥s. Verde - o trabalho que realizamos, lan√ßou o script de segmenta√ß√£o. Amarelo - n√£o fizemos isso porque J√° segmentou exatamente esses dados. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/902/e54/03d/902e5403d2dc07b5f2a4ceaf57ea3e47.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pode-se observar que h√° recursos √† noite, h√° menos fluxo de dados e voc√™ pode segmentar a cada segundo evento. Um dia de recursos menor, e segmentamos apenas 20% dos eventos. Um salto no final do dia - o parceiro fez o upload de arquivos de dados que n√£o t√≠nhamos visto antes e eles tiveram que ser "honestamente" segmentados.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O pr√≥prio sistema se adapta ao crescimento de carga. Se temos um parceiro muito grande, processamos os mesmos dados, mas com um pouco menos de frequ√™ncia. Nesse caso, as caracter√≠sticas do sistema se deteriorar√£o √† noite, a segmenta√ß√£o ser√° adiada n√£o por 2-3 segundos, mas por um minuto. De manh√£, adicione os servidores e retorne aos resultados desejados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Assim, economizamos cerca de 5 vezes nos servidores. Agora trabalhamos em 10 servidores e, portanto, levaria de 50 a 60.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A coisinha azul no topo s√£o os bots. Essa √© a parte mais dif√≠cil da segmenta√ß√£o. Eles t√™m um grande n√∫mero de visitas, eles criam uma carga muito grande no ferro. Vemos cada bot em um servidor separado. Podemos coletar nele um cache local com uma lista negra de bots. Introduziu um antifraude simples: se um usu√°rio faz muitas visitas por um certo tempo, algo est√° errado com ele, adicionamos √† lista negra por um tempo. Esta √© uma pequena faixa azul, cerca de 5%. Eles nos deram mais 30% de economia na CPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Assim, alcan√ßamos o que vemos em todo o pipeline de processamento de dados em cada est√°gio. Vemos m√©tricas de quanto a mensagem estava em Kafka. √Ä noite, algo embotou em algum lugar, o tempo de processamento aumentou para um minuto, depois foi liberado e voltou ao normal.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/58e/fed/411/58efed411c7c5a4348b9280b3c963c16.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Podemos monitorar como nossas a√ß√µes com o sistema afetam sua taxa de transfer√™ncia, podemos ver quanto o script est√° sendo executado, onde √© necess√°rio otimizar e quanto pode ser economizado. </font><font style="vertical-align: inherit;">Podemos ver o tamanho dos segmentos, a din√¢mica do tamanho dos segmentos, avaliar sua associa√ß√£o e interse√ß√£o. </font><font style="vertical-align: inherit;">Isso pode ser feito para mais ou menos os mesmos tamanhos de segmento.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O que voc√™ gostaria de refinar? </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Temos um cluster Hadoop com alguns recursos de computa√ß√£o. Ele est√° ocupado - os analistas trabalham durante o dia, mas √† noite ele √© praticamente livre. Em geral, podemos cont√™iner e executar o segmentador como um processo separado em nosso cluster. Queremos armazenar estat√≠sticas com mais precis√£o para calcular com mais precis√£o o volume da interse√ß√£o. Tamb√©m precisamos de otimiza√ß√£o na CPU. Isso afeta diretamente o custo da decis√£o. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resumindo: o Kafka √© bom, mas, como qualquer outra tecnologia, voc√™ precisa entender como ele funciona por dentro e o que acontece com ele. Por exemplo, a garantia de prioridade da mensagem funciona apenas dentro da parti√ß√£o. Se voc√™ enviar uma mensagem que v√° para diferentes parti√ß√µes, n√£o est√° claro em que ordem elas ser√£o processadas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dados reais s√£o muito importantes. </font><font style="vertical-align: inherit;">Se n√£o tiv√©ssemos testado o tr√°fego real, provavelmente n√£o ter√≠amos problemas com bots, com sess√µes do usu√°rio. </font><font style="vertical-align: inherit;">Desenvolveria algo no v√°cuo, correria e se deitaria. </font><font style="vertical-align: inherit;">√â importante monitorar o que voc√™ considera necess√°rio monitorar e n√£o monitorar o que voc√™ n√£o pensa.</font></font><br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minuto de publicidade. </font><font style="vertical-align: inherit;">Se voc√™ gostou deste relat√≥rio da confer√™ncia SmartData, observe que o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SmartData 2018</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ser√° realizado em S√£o Petersburgo em 15 de outubro, uma </font><font style="vertical-align: inherit;">confer√™ncia para aqueles que est√£o imersos no mundo do aprendizado de m√°quina, an√°lise e processamento de dados. </font><font style="vertical-align: inherit;">O programa ter√° muitas coisas interessantes, o site j√° tem seus primeiros oradores e relat√≥rios.</font></font></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt421125/">https://habr.com/ru/post/pt421125/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt421113/index.html">Apresentando o DJI Mavic 2 Pro / Zoom</a></li>
<li><a href="../pt421115/index.html">Contexto em um aplicativo Android</a></li>
<li><a href="../pt421119/index.html">Ancinho subaqu√°tico desenvolvimento SmartTV</a></li>
<li><a href="../pt421121/index.html">Transmiss√£o de v√≠deo atrav√©s de um navegador com lat√™ncia ultra baixa (e WebRTC!)</a></li>
<li><a href="../pt421123/index.html">Resumo dos eventos de TI de setembro</a></li>
<li><a href="../pt421127/index.html">Semin√°rios on-line na Skillbox Friday: Design e Desenvolvedores</a></li>
<li><a href="../pt421129/index.html">Como reduzir a revis√£o de c√≥digo de duas semanas para v√°rias horas. A experi√™ncia da equipe Yandex.Market</a></li>
<li><a href="../pt421131/index.html">Vulnerabilidade cr√≠tica dos servidores 1Cloud</a></li>
<li><a href="../pt421133/index.html">LINKa. Teclado de papel. Bot√µes extra grandes</a></li>
<li><a href="../pt421135/index.html">Au / Ni / MgO: transfer√™ncia de calor em nanoescala</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
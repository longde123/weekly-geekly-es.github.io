<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ¿â€ğŸ« ğŸ‘¨ğŸ¿â€ğŸ« â¬‡ï¸ Machine morale: impitoyable ou vide de sens? ğŸ’‚ âœğŸ½ ğŸ‘´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="J'ai dÃ©cidÃ© d'Ã©crire cet article dans le sillage de ce post . 


 Permettez-moi de vous rappeler un petit point: dans la revue Nature, les rÃ©sultats d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Machine morale: impitoyable ou vide de sens?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428181/"><p>  J'ai dÃ©cidÃ© d'Ã©crire cet article dans le sillage de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce post</a> . </p><br><img src="https://habrastorage.org/webt/-x/08/ps/-x08pskb0ti0iupeu2iuduj3uus.jpeg"><br><br>  Permettez-moi de vous rappeler un petit point: dans la revue Nature, les rÃ©sultats d'une Ã©tude rÃ©alisÃ©e Ã  l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce test</a> ont Ã©tÃ© publiÃ©s. <br><p>  Sur quoi je veux Ã©crire? </p><br><p>  PremiÃ¨rement, pourquoi cette recherche est absolument inutile pour rÃ©soudre le problÃ¨me posÃ© et sous la forme sous laquelle elle a Ã©tÃ© menÃ©e. </p><br><p>  DeuxiÃ¨mement, comment hiÃ©rarchiser une telle Ã©tude. </p><br><p> Et troisiÃ¨mement, essayez de simuler divers scÃ©narios d'accident dans les conditions spÃ©cifiÃ©es par le test. </p><a name="habracut"></a><br><p>  Dans cet article, l'auteur n'a pas insÃ©rÃ© en vain un lien vers le test depuis le tout dÃ©but.  Cela aiderait Ã  Ã©viter les commentaires insignifiants de ceux qui n'ont pas compris le message initial de l'Ã©tude. <br>  Veuillez <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">faire un test</a></b> au moins deux fois pour comprendre le sujet de la discussion. </p><br><h3>  Ce qu'ils ont promis de nous montrer dans l'Ã©tude </h3><br><p>  La discussion du premier post, Ã©pique pour Habr, a montrÃ© que la majoritÃ© des gens ne savent pas penser dans les conditions donnÃ©es, mais commencent Ã  fantasmer: "certaines personnes meurent-elles dans le test?"  AprÃ¨s tout, vous pouvez contourner les deux piÃ©tons et le bloc / latÃ©ralement pour frotter / freiner le frein Ã  main / l'Ã©quipement?  Mais je voudrais ... ".  Comprenez que c'est un exemple simplifiÃ© pour dÃ©velopper des algorithmes d'action et des politiques pour rÃ©guler le comportement du pilote automatique sur la route!  Du point de vue de l'Ã©laboration de rÃ¨gles de sÃ©curitÃ©, de tels extrÃªmes et simplifications sont justifiÃ©s.  Il s'agit des consÃ©quences potentielles auxquelles les gens devraient Ãªtre prÃ©parÃ©s.  Les soldats ne se rendent pas dans les champs de mines non pas parce que chaque centimÃ¨tre carrÃ© y est extrait, mais Ã  cause de la probabilitÃ© mÃªme de mourir.  Il n'est gÃ©nÃ©ralement pas trÃ¨s Ã©levÃ©, mais personne ne le risque.  Par consÃ©quent, dans le test, le choix entre la mort Ã  100% de tous les passagers ou de tous les piÃ©tons est adÃ©quat - c'est ainsi que nous dÃ©signons le risque, en gardant Ã  l'esprit que risquer des vies dans notre sociÃ©tÃ© est inacceptable. </p><br><p>  Le message de l'Ã©tude est le suivant: vous, les gens qui vivent maintenant, devez vivre dans un monde d'avenir, rempli de voitures sur pilote automatique.  Et c'est important pour nous, dÃ©veloppeurs d'automobiles, d'intelligence artificielle et d'autres choses, de savoir, mais comment pensez-vous que les robots robots devraient se comporter?  Eh bien, vous y Ãªtes, oui, oui, c'est vous - dites-moi quoi faire Ã  un robot si la tÃªte et le chat y montent, et il est sur le point d'Ã©craser les sans-abri et le chien?  Quelle Ã©thique les robots doivent-ils avoir s'ils doivent choisir? </p><br><p>  Et aprÃ¨s avoir identifiÃ© le motif initial de l'Ã©tude, je souhaite en discuter plusieurs aspects. </p><br><h3>  Ce que l'Ã©tude a rÃ©ellement montrÃ© </h3><br><p>  La premiÃ¨re chose qui attire clairement votre attention est que la conception de la recherche ne vise pas du tout l'objectif dÃ©clarÃ©.  Les tÃ¢ches dÃ©finies sous forme de dilemmes ne sont pas adaptÃ©es Ã  la crÃ©ation d'une Â«Ã©thiqueÂ» du comportement robot-voiture.  Mais pas tous.  Voici les dilemmes qui rÃ©pondent Ã  la tÃ¢che de Â«dÃ©velopper des rÃ¨gles pour le comportement d'un robot-voiture afin de rÃ©duire la gravitÃ© des consÃ©quences d'un accidentÂ»: </p><br><ul><li>  Â«Passager / piÃ©tonÂ» - choisissez qui Ã©pargner; </li><li>  "Violation des rÃ¨gles de circulation" - choisissez de sacrifier ou non les piÃ©tons inconscients; </li><li>  Â«Nombre de victimes potentiellesÂ» - choisissez si le nombre de victimes est prioritaire. </li></ul><br><p>  Et puis viennent les paramÃ¨tres qui s'avÃ¨rent trÃ¨s importants pour la dÃ©termination de la peine dans notre sociÃ©tÃ© civilisÃ©e.  On a demandÃ© honnÃªtement et innocemment aux gens: votre niveau de sexisme, de lukisme, d'Ã¢gisme?  ÃŠtes-vous pour la discrimination des graisses ou des non classÃ©s?  Et aprÃ¨s tout, des centaines de milliers de personnes ont honnÃªtement rÃ©pondu ... </p><br><p>  Bravo! </p><br><p>  En plein dans les meilleures traditions des films et sÃ©ries divertissantes, quand le monde des personnages principaux est en fait un grand bac Ã  sable derriÃ¨re une haute clÃ´ture, et c'est leur comportement qui est une expÃ©rience!  Sous la sauce de recherches super importantes dans le domaine de la robotique et de l'IA, les sociologues, psychologues, culturologues ont reÃ§u un Ã©chantillon si puissant sur <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le problÃ¨me du chariot</a></b> que personne n'avait jamais rÃªvÃ© auparavant!  Eh bien, sauf que la couleur de la peau n'a pas Ã©tÃ© ajoutÃ©e Ã  l'enquÃªte, mais alors les connotations racistes de l'Ã©tude seraient cousues de blanc ... oh. </p><br><p>  SÃ©rieusement, cette partie phÃ©notypique du genre de l'Ã©tude est coupÃ©e par des arguments catÃ©goriques.  Le premier argument est l'humanisme, en tant que personnes civilisÃ©es, nous devons mettre la primautÃ© de la valeur de la vie humaine sur toutes les diffÃ©rences individuelles.  Autrement dit, la formulation mÃªme de la question est scandaleuse, car discriminatoire.  DeuxiÃ¨me argument - de nombreux accidents se produisent et, Ã  la limite, la rÃ©partition des victimes par apparence, Ã©ducation, sexe, Ã¢ge aura tendance Ã  prendre leurs proportions dans la sociÃ©tÃ©, il est donc au moins Ã©trange de rÃ©glementer cela en plus.  Le troisiÃ¨me argument - il ne semble pas opportun de crÃ©er une intelligence artificielle qui distingue un costume de Brioni d'un pull de Bershka pour comparer davantage si une personne a un statut et s'il vaut la peine de l'Ã©craser.  De plus, je ne ferais pas confiance Ã  l'IA pour juger - un piÃ©ton sans-abri ou un scientifique?  (bonjour aux coiffures des scientifiques respectÃ©s Perelman ou Gelfand :)) </p><br><p>  En plus de ces paramÃ¨tres inutiles, nous rejetons facilement les deux autres: la spÃ©cificitÃ© des espÃ¨ces et la non-interfÃ©rence.  Oui, nous allons Ã©craser les petits animaux pour sauver des gens qui auraient pensÃ©.  Et quant au paramÃ¨tre Â«intervention / non-interfÃ©renceÂ» par manoeuvre, cette partie essentielle du problÃ¨me du chariot n'est pas seulement un frein Ã  la voiture, car la machine n'agit pas selon l'Ã©thique, mais selon les algorithmes qui y sont dÃ©finis.  Et puisque nous avons dÃ©fini la tÃ¢che Â«comment la voiture devrait-elle agir en cas d'accident avec une collision avec des personnesÂ», alors dans le libellÃ©, nous supposons qu'elle doit agir d'une maniÃ¨re ou d'une autre.  De nos jours, le transport ferroviaire rÃ©ussit Ã  faire face Ã  une collision directe sans aucune consÃ©quence, et nous dÃ©veloppons une politique de minimisation des victimes d'accidents de la route. <br>  Cela signifie que nous avons sÃ©parÃ© les grains rationnels de la recherche de l'expÃ©rience sociopsychologique pour Ã©tudier le niveau d'intolÃ©rance dans la sociÃ©tÃ© mondiale.  Nous travaillons plus avant avec les trois premiers dilemmes mentionnÃ©s.  Et il y a quelque chose Ã  dÃ©monter.  AprÃ¨s un examen plus approfondi, ils se rÃ©vÃ¨lent incomplets ... </p><br><h3>  Trois dilemmes des voitures robots </h3><br><p>  <b>Les piÃ©tons violent-ils les rÃ¨gles de circulation?</b>  Ici, la majoritÃ© exprime explicitement le darwinisme social ou une rÃ©ponse regrettable tacitement dÃ©solÃ©e - ils doivent plutÃ´t sacrifier ceux qui violent les rÃ¨gles en faveur des innocents.  Les personnes conscientes ne vont pas sur les rails, sachant que le train ne s'arrÃªtera pas - faites-leur savoir que le robot ne s'arrÃªtera pas non plus.  Tout est logique, bien que cynique.  Mais dans ce dilemme rusÃ©, le caractÃ¨re unilatÃ©ral, l'incomplÃ©tude est cachÃ©.  Les piÃ©tons qui enfreignent les rÃ¨gles de circulation ne sont qu'une des nombreuses situations.  Mais si la voiture robotique se casse ??  Cette situation nâ€™a pas Ã©tÃ© prise en compte, mais elle (en thÃ©orie, les camÃ©ras de la voiture ont ratÃ© un panneau ou un feu de signalisation) est, en thÃ©orie, beaucoup plus probable quâ€™une soudaine dÃ©faillance des freins.  Cependant, j'ai encore frappÃ© dans la fantaisie et en particulier.  Il est plus important de simplement montrer dans le test la rÃ©ciprocitÃ© Ã©quivalente de la situation.  Autrement dit, imaginez ceci: si les piÃ©tons enfreignent les rÃ¨gles de la circulation, ils meurent, ce qui est Â«logiqueÂ» et Â«correctÂ», et si le robot motorisÃ© viole, devrait-il se suicider pour cette erreur?  N'oubliez pas qu'en mÃªme temps, le chef, le clochard et le chat assis Ã  l'intÃ©rieur meurent!  Il s'agit d'une correction importante, mais dans le test, cet aspect ne l'est pas. </p><br><p>  Ensuite.  <b>Le nombre de victimes potentielles.</b>  Ici aussi, ce n'est pas si simple.  Jeter les stÃ©rÃ©otypes de genre et le respect de la vieillesse, le mÃ©pris pour les gros et les sans-abri.  Nous supposons que dans un accident, ils meurent proportionnellement Ã  la frÃ©quence Ã  laquelle ils se trouvent dans la nature.  Et nous dÃ©ciderons: trois mourront mieux que cinq.  Cela vous semble-t-il logique?  Oh bien.  Ã‰vitons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">toute cette absurditÃ© infernale</a> , mais nous avons une simulation abstraite.  Quel est le meilleur - pour tuer 50 ou 51 personnes?  1051 ou 1052?  Ce n'est donc pas si important?  Alors quoi de mieux - tuer 1 piÃ©ton ou 50 personnes dans un bus?  Et maintenant, c'est devenu important?  Et oÃ¹ va cette ligne?  Chaque personne supplÃ©mentaire a-t-elle de la valeur?  Mais est-ce important si des milliers de personnes meurent dans des accidents de la route Ã  long terme?  Comme dans le cas de l'apparence, en rÃ©alitÃ©, une estimation adÃ©quate utilisant l'IA du nombre de victimes potentielles sera extrÃªmement difficile.  La seule chose sensÃ©e est de faire une condition de non-intervention (non-manoeuvre) si le nombre de victimes est le mÃªme. </p><br><p>  Le troisiÃ¨me aspect a suscitÃ© beaucoup de controverse dans les commentaires sur ce premier article sur HabrÃ©.  Et Ã  en juger par les rÃ©sultats de l'Ã©tude, elle est complÃ¨tement ambiguÃ« pour la sociÃ©tÃ©, et c'est lÃ  que rÃ©side le principal problÃ¨me qui doit Ãªtre rÃ©solu.  Il s'agit de savoir <b>qui risquer - piÃ©tons ou passagers?</b> </p><br><p>  Certains disent que les piÃ©tons ne sont Ã  blÃ¢mer pour rien, ce qui signifie qu'ils doivent Ãªtre sauvÃ©s en premier lieu.  De maniÃ¨re gÃ©nÃ©rale, il est dÃ©sormais Ã  la mode chez les urbanistes de prendre soin des piÃ©tons, de rendre des rues entiÃ¨res piÃ©tonnes, de crÃ©er des passages Ã  niveau avec un feu tricolore tous les 50 mÃ¨tres, de rÃ©duire la vitesse de circulation au centre, de donner la prioritÃ© aux piÃ©tons.  Ici aussi, il est nÃ©cessaire de les sÃ©curiser d'une maniÃ¨re ou d'une autre, et une machine robotique volant sans freins sur la foule devrait s'autodÃ©truire au nom du sauvetage des participants les plus vulnÃ©rables du mouvement.  Ce qui, de mon point de vue, ils ont raison, c'est que les piÃ©tons ne souscrivaient pas aux conditions de comportement de la voiture robot de quelqu'un d'autre.  Ils pourraient Ãªtre gÃ©nÃ©ralement contre leur introduction.  En mÃªme temps, il est impossible d'imaginer le passager d'une telle machine qui n'est pas d'accord avec les conditions de son utilisation.  Par consÃ©quent, la situation est un conflit d'intÃ©rÃªts.  Câ€™est plus pratique pour moi de vous tuer et je vais vous tuer, comme une personne le dit Ã  une autre. </p><br><p>  Les seconds disent que toute personne qui achÃ¨te et monte gÃ©nÃ©ralement dans une voiture robotisÃ©e devrait avoir la garantie qu'elle le sauvera en cas d'accident, et ne tuera pas un mÃ©decin, un enfant ou deux chats afin de sauver la route de passage.  D'une part, cela semble logique et justifiÃ©, d'autre part - le passager dans ce cas met dÃ©libÃ©rÃ©ment sa vie au-dessus des autres.  Lors de l'achat d'une voiture avec un pilote automatique, chacun de ses propriÃ©taires met Ã  sa disposition l' <s>arme parfaite, une balle d'argent, une fusÃ©e non guidÃ©e, une</s> machine qui tuera complÃ¨tement lÃ©galement toute autre personne sur son passage. </p><br><p>  Les deux cÃ´tÃ©s avec de la mousse Ã  la bouche tirent sur la "premiÃ¨re loi de la robotique", tirÃ©e de la science-fiction.  Cela a l'air dÃ©magogiquement beau, mais personne n'essaie mÃªme de le comprendre ou de le remettre en question par rapport au problÃ¨me.  Mais elle n'est pas applicable Ã  cette formulation du problÃ¨me, car il y a substitution de concepts: l'heuristique / IA de la machine ne choisit pas entre les valeurs de la vie humaine, mais agit strictement selon les algo-rythmes crÃ©Ã©s Ã  partir de prioritÃ©s subjectives inventÃ©es par l'homme.  Et ici, peu importe quel type de construction sociale est pris comme prioritÃ© lors du choix de Â«tuer / Ã©pargnerÂ»: la masse corporelle que nous avons rejetÃ©e plus tÃ´t, l'Ã¢ge et le statut, ou l'Ã©goÃ¯sme darwiniste social du propriÃ©taire de la voiture. </p><br><p>  La deuxiÃ¨me approche, qui est une attaque unilatÃ©rale contre la vie des piÃ©tons, transforme la recherche d'un problÃ¨me de chariot en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><b>dilemme classique d'un prisonnier</b></a> .  Si les parties parviennent Ã  un compromis, un dÃ©veloppement gÃ©nÃ©ral est possible (introduction de robomobiles) avec une dÃ©tÃ©rioration minimale pour certains (minimisation du nombre de dÃ©cÃ¨s inÃ©vitables dus aux robomobiles) - ce qui est le souhait de l'optimum de Pareto.  Cependant, il y a toujours un Ã©goÃ¯ste qui ne compte que sur ses intÃ©rÃªts.  "Il aura 20 ans, mais je serai libÃ©rÃ©."  "Il mourra en traversant la route, bien que les freins aient refusÃ© ma voiture."  Peut-Ãªtre que cette approche est justifiÃ©e lorsque les Ã©vÃ©nements sont uniques dans la vie et qu'il y a deux participants au jeu.  Lorsqu'il y a des dizaines ou des centaines de milliers de participants et que les dÃ©placements sont quotidiens, un tel jeu Ã  but unique se transformera en discrimination Ã  l'Ã©gard des piÃ©tons. </p><br><p>  Personnellement, je pense que dans le cadre du problÃ¨me formulÃ©, le dilemme passager / piÃ©ton conduit Ã  une impasse.  Une machine qui tue potentiellement ceux qui s'y sont lancÃ©s est absurde du point de vue du bon sens et ne trouvera naturellement pas d'acheteurs sur le marchÃ©.  Une voiture qui tue dÃ©libÃ©rÃ©ment des piÃ©tons est impossible dans une sociÃ©tÃ© civilisÃ©e en tant qu'Ã©lÃ©ment de discrimination positive et menace pour la vie des gens. </p><br><p>  Nous allons plus loin.  L'article ne traite pas vraiment et ne signifie pas une politique visant Ã  minimiser les consÃ©quences tragiques des accidents impliquant des robots.  Les totaux sont divisÃ©s en Â«rÃ©gionsÂ», dont les prioritÃ©s diffÃ¨rent considÃ©rablement et sont formÃ©es de maniÃ¨re assez ambiguÃ« (il existe des explications sur les Â«caractÃ©ristiques religieuses et l'influence colonialeÂ», mais ... en gÃ©nÃ©ral, salutations Ã  l'Irak avec l'Afghanistan dans Â«l'OuestÂ» et Ã  la France avec la RÃ©publique tchÃ¨que dans Â« Sud Â»).  Et donc la question tourne dans la langue: allez-vous fabriquer des robots avec une "Ã©thique" diffÃ©rente pour chaque pays? </p><br><img src="https://habrastorage.org/webt/oy/wk/2i/oywk2inqjeerijr5wrja_v57new.jpeg"><br><p>  Les auteurs de l'article dans la discussion dÃ©signent les trois Â«blocs fondamentaux de baseÂ» identifiÃ©s par eux: sauver les gens (pas les animaux), sauver plus de vies, sauver les plus jeunes.  Mais les diagrammes montrent clairement que les gens du secteur de l'Est ont un peu moins de population et de jeunes que peu s'en soucient.  Il s'avÃ¨re que les politiques prioritaires sÃ©lectionnÃ©es iront Ã  l'encontre de l'opinion de la grande majoritÃ©?  Pourquoi, alors, les gens ont-ils Ã©tÃ© interrogÃ©s? </p><br><h3>  Peut-Ãªtre juste compter? </h3><br><p>  Mais passons Ã  la partie divertissante de ce post. </p><br><p>  Au lieu de demander Ã  des personnes ayant des implications socioculturelles diffÃ©rentes des conseils sur la robotique, et probablement 99% d'entre elles avec une Ã©ducation non fondamentale, nous nous tournons vers un outil impartial.  Prenons les dilemmes sÃ©lectionnÃ©s au dÃ©but de l'article.  Dans les conditions du test, nous crÃ©erons la simulation informatique la plus simple.  Et nous Ã©valuerons le nombre d'usagers de la route morts. </p><br><p>  Et rappelez-vous: notre tÃ¢che en tant que politiciens dans le domaine de la sÃ©curitÃ© des transports est de rÃ©duire le nombre total de victimes.  Nous travaillerons dans le cadre et les conventions du test Moral Machine original, qui se concentre sur le risque pour la vie des participants Ã  un accident de la route, plutÃ´t que sur des Ã©valuations rÃ©alistes complexes de la collision d'une voiture avec un obstacle ou des personnes.  Nous n'avons pas EuroNCAP, nous aurons Python. </p><br><p>  Tout d'abord, nous allons Ã©crire un code qui rÃ©ponde au dilemme de "sauver ceux qui meurent plus".  Dans le cadre du test de la machine morale, nous faisons au hasard de 1 Ã  5 passagers et piÃ©tons, dÃ©finissons la condition si piÃ©tons&gt; passagers, tuez immÃ©diatement la voiture sur un bloc de bÃ©ton.  Nous transportons, par exemple, 10 000 de ces accidents. </p><br><div class="spoiler">  <b class="spoiler_title">Je n'Ã©coute pas le code de revendication, j'ai Ã©crit quelque chose en Python pour la premiÃ¨re fois de ma vie</b> <div class="spoiler_text"><pre><code class="plaintext">npedtotal = 0
npasstotal = 0
ndeadped = 0
ndeadpass = 0
#   0    0  

n=0
while n &lt; 10000:
#10000 

    nped = random.randint(1, 5)
    npass = random.randint(1, 5)
#      1  5

    npedtotal += nped
    npasstotal += npass
#     

    if nped &gt; npass:

        ndeadpass += npass

    else:
        ndeadped += nped

#     ,
#       .
#          .

    n += 1

print ("  ", npedtotal)
print (" ", npasstotal)
print (" ", ndeadped, "(",100*ndeadped/npedtotal, "%",")")
print (" ", ndeadpass, "(",100*ndeadpass/npasstotal,"%"")")
print ("  ", ndeadped + ndeadpass, "(",100*(ndeadped + ndeadpass)/(npasstotal+npedtotal), "%", ")")</code></pre></div></div><br>
<p>  â€¦ </p><br>
<blockquote>   29960<br>
  29924<br>
  13903 ( 46.4052069426 % )<br>
  8030 ( 26.8346477744 %)    21933 ( 36.6258098991 % )</blockquote><p>,   !   ,   !<br>
    .             .  ,      .     â€“    ,   Â« Â»         4  5,        ==  . ,   20   20 ,   ,   , 5  â€“    ,  5  â€“   .     :      ,  ,   .  &gt;  &gt;=        :</p><br>
<blockquote>   29981<br>
  29865<br>
  7859 ( 26.2132684033 % )<br>
  14069 ( 47.1086556169 %)<br>
   21928 ( 36.6407111586 % )</blockquote>   ,          occupants,  -   ,   .    ,    .  30000 , 100% â€” .<br>
<br>
     ,       ,   .    â€“    , ,    50%     ,     30000.<br>
<br>
    â€“       .  ,    ,        ,       !    ,     :  ,        , ,    ,      ,    . ,    :      .<br>
<br>
<div class="spoiler"><b class="spoiler_title">       ,   -</b><div class="spoiler_text">```python<br>
import random<br>
<br>
npedtotal = 0<br>
npasstotal = 0<br>
ndeadped = 0<br>
ndeadpass = 0<br>
#   0    0  <br>
<br>
n=0<br>
while n &lt; 10000:<br>
#10000 <br>
<br>
nped = random.randint(1, 5)<br>
 npass = random.randint(1, 5)<br>
 trafficlight = random.randint(0, 1)<br>
#      1  5<br>
#      <br>
<br>
npedtotal += nped<br>
 npasstotal += npass<br>
#     <br>
 if trafficlight == 0:<br>
<br>
ndeadped += nped<br>
<br>
else:<br>
<br>
if nped &gt; npass:<br>
<br>
ndeadpass += npass<br>
<br>
else:<br>
 ndeadped += nped<br>
<br>
#     ,<br>
#       .<br>
#          .<br>
<br>
n += 1<br>
<br>
print (Â«  Â», npedtotal)<br>
print (Â« Â», npasstotal)<br>
print (Â« Â», ndeadped, "(",100*ndeadped/npedtotal, "%",")")<br>
print (Â« Â», ndeadpass, "(",100*ndeadpass/npasstotal,"%"")")<br>
print (Â«  Â», ndeadped + ndeadpass, "(",100*(ndeadped + ndeadpass)/(npasstotal+npedtotal), "%", ")")<br>
```</div></div><br>
<br>
<blockquote>  "&gt;"<br>
   29978<br>
  29899<br>
  21869 ( 72.9501634532 % )<br>
  4042 ( 13.5188467842 %)<br>
   25911 ( 43.2737111078 % )<br>
<br>
 "&gt;="<br>
   30152<br>
  30138<br>
  19297 ( 63.9990713717 % )<br>
  6780 ( 22.4965160263 %)<br>
   26077 ( 43.2526123735 % )<br>
</blockquote> ,      ,           .          (       ).<br>
<br>
           ,             .                 â€“         .<br>
<br>
           .        ,    ,           .         Moral Machine,      ,     ,     .       -   ,       .<br>
<br>
,    ,       ,                .     â€“   ,   ,   .        .       â€“      ,   ,      ,           .      ,    â€“        .<br>
<br>
   ,   -              ,      .          ,   ,             ,    .  â€“   ,       ,      .<br>
<br>
 .      .            ,      .    .</div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428181/">https://habr.com/ru/post/fr428181/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428169/index.html">DJI annonce Mavic 2 Enterprise - un outil puissant pour les professionnels</a></li>
<li><a href="../fr428173/index.html">Prettier, ESLint, Husky, Lint-Staged et EditorConfig: outils pour Ã©crire du code ordonnÃ©</a></li>
<li><a href="../fr428175/index.html">ImplÃ©mentation de l'arbre C de prÃ©fixe C</a></li>
<li><a href="../fr428177/index.html">Alors, quel est le problÃ¨me avec la recherche d'emploi / les travailleurs en informatique?</a></li>
<li><a href="../fr428179/index.html">Lors d'une vente aux enchÃ¨res japonaise, un prototype de manette Wii, dÃ©veloppÃ© pour le GameCube</a></li>
<li><a href="../fr428183/index.html">ImplÃ©mentation de l'algorithme de Levenberg-Marquardt pour l'optimisation des rÃ©seaux de neurones sur TensorFlow</a></li>
<li><a href="../fr428187/index.html">Comment Ã©crire une extension pour GNOME Shell: mode Ne pas dÃ©ranger</a></li>
<li><a href="../fr428189/index.html">Qu'est-ce qu'un paladin?</a></li>
<li><a href="../fr428191/index.html">Que devrions-nous organiser un hackathon, ou comment nous avons menÃ© un hackathon interne</a></li>
<li><a href="../fr428193/index.html">Ã€ propos des tournÃ©es</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
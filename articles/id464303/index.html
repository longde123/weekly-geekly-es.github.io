<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßö ü¶é üëâüèæ Data deret waktu dalam DBMS relasional. Ekstensi TimescaleDB dan PipelineDB untuk PostgreSQL üòé üëáüèª üíô</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Data deret waktu atau deret waktu adalah data yang berubah seiring waktu. Kutipan mata uang, telemetri pergerakan transportasi, statistik akses server...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Data deret waktu dalam DBMS relasional. Ekstensi TimescaleDB dan PipelineDB untuk PostgreSQL</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/464303/">  Data deret waktu atau deret waktu adalah data yang berubah seiring waktu.  Kutipan mata uang, telemetri pergerakan transportasi, statistik akses server atau beban CPU adalah data deret waktu.  Untuk menyimpannya membutuhkan alat khusus - basis data temporal.  Ada puluhan alat, misalnya, InfluxDB atau ClickHouse.  Tetapi bahkan solusi penyimpanan seri waktu terbaik pun memiliki kekurangan.  Semua penyimpanan deret waktu adalah tingkat rendah, hanya cocok untuk data deret waktu, dan menjalankan dan menyuntikkan ke tumpukan saat ini adalah mahal dan menyakitkan. <br><br><img src="https://habrastorage.org/webt/sx/9x/bz/sx9xbzv26lix6lh-frspdsopknw.jpeg"><br><br>  Tetapi, jika Anda memiliki tumpukan PostgreSQL, Anda bisa melupakan InfluxDB dan semua basis data temporal lainnya.  Instal dua ekstensi, TimescaleDB dan PipelineDB, dan simpan, proses, dan analisis data deret waktu secara langsung di ekosistem PostgreSQL.  Tanpa pengenalan solusi pihak ketiga, tanpa kerugian penyimpanan sementara dan tanpa masalah menjalankannya.  Apa ekstensi ini, apa kelebihan dan kemampuannya, akan memberi tahu <b>Ivan Muratov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">binakot</a> )</b> - kepala departemen pengembangan di "Perusahaan Pemantau Pertama". <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3WkNp7mllv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Apa itu data deret waktu atau deret waktu? </h2><br><blockquote>  Ini adalah data tentang proses yang dikumpulkan di berbagai titik dalam hidupnya. </blockquote><br>  Misalnya, lokasi mobil: kecepatan, koordinat, arah, atau penggunaan sumber daya di server dengan data pada beban pada CPU, menggunakan RAM dan ruang disk kosong. <br><br>  Rangkaian waktu memiliki beberapa fitur. <br><br><ul><li>  Di <b>tali pengikat</b> .  Setiap catatan seri waktu memiliki bidang dengan cap waktu di mana nilai tersebut dicatat. <br></li><li>  <b>Karakteristik proses, yang disebut level seri</b> : kecepatan, koordinat, memuat data. <br></li><li>  Hampir selalu dengan data seperti itu mereka bekerja <b>dalam mode append-only</b> .  Ini berarti bahwa data baru tidak menggantikan yang lama.  Hanya data yang usang yang dihapus. <br></li><li>  <b>Entri tidak dianggap terpisah satu sama lain</b> .  Data hanya digunakan secara kolektif untuk jendela waktu, interval atau periode. <br></li></ul><br><h3>  Solusi penyimpanan populer </h3><br>  Grafik yang saya ambil dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">db-engines.com</a> menunjukkan popularitas berbagai model penyimpanan selama dua tahun terakhir. <br><br><img src="https://habrastorage.org/webt/w2/wf/_u/w2wf_uryfor_djey8enzmrskywo.jpeg"><br><br>  Posisi terdepan ditempati oleh penyimpanan deret waktu, di tempat kedua - basis data grafik, lalu - nilai kunci dan basis data relasional.  Popularitas repositori khusus dikaitkan dengan pertumbuhan intensif dalam integrasi teknologi informasi: Big Data, jejaring sosial, IoT, pemantauan infrastruktur beban tinggi.  Selain data bisnis yang bermanfaat, bahkan log dan metrik juga menghabiskan banyak sumber daya. <br><br><h3>  Solusi penyimpanan populer untuk data deret waktu </h3><br>  Grafik menunjukkan solusi khusus untuk menyimpan data deret waktu.  Skala tersebut adalah logaritmik. <br><br><img src="https://habrastorage.org/webt/ny/bz/6_/nybz6_-_3ce7t0y7xre1oxkbks8.jpeg"><br><br>  Pemimpin stabil InfluxDB.  Setiap orang yang telah menemukan data deret waktu telah mendengar tentang produk ini.  Tetapi grafik menunjukkan peningkatan sepuluh kali lipat dalam TimescaleDB - perpanjangan untuk DBMS relasional berjuang untuk tempat di bawah matahari di antara produk yang awalnya dikembangkan di bawah seri waktu. <br><br><blockquote>  PostgreSQL tidak hanya database yang baik, tetapi juga platform yang dapat dikembangkan untuk mengembangkan solusi khusus. </blockquote><br><h2>  Postgres, Postgis, dan TimescaleDB </h2><br>  Perusahaan Pemantau Pertama memonitor pergerakan kendaraan menggunakan satelit.  Kami melacak 20.000 kendaraan dan menyimpan data pergerakan selama dua tahun.  Secara total, kami memiliki 10 TB data telemetri saat ini.  Rata-rata, setiap kendaraan mengirim 5 catatan telemetri per menit saat mengemudi.  Data dikirim melalui peralatan navigasi ke server telematik kami.  Mereka menerima 500 paket navigasi per detik. <br><br>  Beberapa waktu lalu, kami memutuskan untuk meningkatkan infrastruktur secara global dan beralih dari monolit ke layanan mikro.  Kami menyebut sistem baru Waliot, dan sudah dalam produksi - 90% dari semua kendaraan dipindahkan ke sana. <br><br>  Banyak yang telah berubah dalam infrastruktur, tetapi tautan sentral tetap tidak berubah - ini adalah database PostgreSQL.  Sekarang kami sedang mengerjakan versi 10 dan sedang bersiap untuk pindah ke 11. Selain PostgreSQL, sebagai penyimpanan utama, dalam tumpukan kami menggunakan PostGIS untuk komputasi geospasial, dan TimescaleDB untuk menyimpan sejumlah besar data deret waktu. <br><br><h3>  Mengapa PostgreSQL? </h3><br>  Mengapa kami mencoba menggunakan database relasional untuk menyimpan seri waktu, daripada <s>ClickHouse</s> solusi khusus untuk tipe data ini?  Karena dengan latar belakang akumulasi keahlian dan kesan bekerja dengan PostgreSQL, kami tidak ingin menggunakan solusi yang tidak dikenal sebagai penyimpanan utama. <br><br><blockquote>  Beralih ke solusi baru adalah risiko. </blockquote><br>  Ada banyak solusi khusus untuk menyimpan dan memproses data deret waktu.  Dokumentasi tidak selalu cukup, dan banyak pilihan solusi tidak selalu baik.  Tampaknya para pengembang dari setiap produk baru ingin menulis semuanya dari awal, karena ada sesuatu yang tidak menyenangkan dalam solusi sebelumnya.  Untuk memahami apa yang sebenarnya tidak disukai, Anda harus mencari informasi, menganalisis, dan membandingkan.  Berbagai variasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">peringkat</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">peringkat</a> , dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perbandingan</a> lebih menakutkan daripada memotivasi untuk mencoba sesuatu.  Anda harus menghabiskan banyak waktu untuk mencoba semua solusi pada diri Anda sendiri.  Kami tidak mampu mengadaptasi hanya satu solusi selama beberapa bulan.  Ini adalah tugas yang sulit, dan waktu yang dihabiskan tidak akan pernah berhasil.  Karena itu, kami telah memilih ekstensi untuk PostgreSQL. <br><br>  Selama fase pengembangan infrastruktur Waliot, kami menganggap InfluxDB sebagai repositori telemetri utama.  Tetapi ketika saya menemukan TimescaleDB dan menjalankan tes di sana, tidak ada pertanyaan tentang pilihan.  PostgreSQL dengan ekstensi TimescaleDB memungkinkan Anda untuk menggunakan ekstensi lain dalam penyimpanan PostGIS atau PipelineDB yang sama.  Kami tidak perlu mengeluarkan data, mentransformasikan, melakukan analisis, dan mentransfernya melalui jaringan.  Semuanya terletak pada satu server atau dalam sistem cluster - data tidak perlu diseret.  Semua perhitungan dilakukan pada level yang sama. <br><br>  Baru-baru ini, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Nikolay Samokhvalov</a> , penulis akun postgresmen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menerbitkan tautan</a> ke artikel menarik tentang penggunaan SQL untuk streaming pemrosesan data.  Lima dari enam penulis artikel berpartisipasi dalam pengembangan berbagai produk Apache dan bekerja dengan pemrosesan aliran.  Oleh karena itu, artikel tersebut menyebutkan Apache Spark, Apache Flink, Apache Beam, Apache Calcite dan KSQL dari Confluent. <br><br>  Tapi bukan artikel itu sendiri yang menarik, tetapi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">topik tentang Hacker News</a> , di mana itu dibahas.  Penulis topik menulis bahwa, berdasarkan artikel tersebut, ia menerapkan hampir semua ide berdasarkan PostgreSQL 11. Dia menggunakan ekstensi CitusDB untuk penskalaan dan sharding horizontal, PipelineDB untuk komputasi aliran dan tampilan terwujud, TimescaleDB untuk menyimpan data deret waktu dan pembagian.  Dia juga menggunakan beberapa Pembungkus Data Asing. <br><br><blockquote>  Gabungan gila PostgreSQL dan ekstensi sekali lagi menegaskan bahwa PostgreSQL bukan hanya DBMS - itu adalah platform. </blockquote><br>  Dan kapan penyimpanan pluggable akan dikirimkan ... Ugh! <br><br>  Ironisnya, ketika meneliti solusi, kami menemukan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Outflux</a> , pengembangan tim TimescaleDB, yang mereka terbitkan pada 1 April.  Menurutmu apa yang dia lakukan?  Ini adalah utilitas untuk bermigrasi dari InfluxDB ke TimescaleDB dalam satu perintah ... <br><br><h3>  Sensasi postgres! </h3><br>  Jangan meremehkan kekuatan hype!  Kami sering bercanda bahwa "pembangunan didorong oleh hype," karena hal itu memengaruhi persepsi kami tentang komponen penyempurnaan dan infrastruktur.  Di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++,</a> kami banyak membahas PostgreSQL, ClickHouse, Tarantool - ini adalah perkembangan hype.  Hanya saja jangan katakan bahwa itu tidak mempengaruhi preferensi Anda dan pilihan solusi untuk infrastruktur ... Tentu saja, ini bukan faktor utama, tetapi apakah ada pengaruhnya? <br><br>  Saya telah bekerja dengan PostgreSQL selama 5 tahun.  Saya suka solusi ini.  Dia menyelesaikan hampir semua tugas saya dengan keras.  Setiap kali ada yang salah dengan pangkalan ini, tangan saya yang bengkok harus disalahkan.  Karena itu, pilihannya sudah ditentukan sebelumnya. <br><br><h2>  TimescaleDB VS PipelineDB </h2><br>  Mari kita beralih ke ekstensi TimescaleDB dan PipelineDB.  Apa yang dikatakan pembuatnya tentang ekstensi? <br><br>  <b>TimescaleDB adalah database seri waktu</b> sumber terbuka yang dioptimalkan untuk penyisipan cepat dan kueri kompleks. <br><br>  <b>PipelineDB</b> adalah ekstensi berkinerja tinggi yang dirancang untuk menjalankan kueri SQL berkelanjutan <b>untuk data deret waktu</b> . <br><br>  Selain bekerja dengan data deret waktu, mereka memiliki cerita serupa.  Timescale didirikan pada 2015, dan Pipeline pada 2013. Versi kerja pertama muncul masing-masing pada 2017 dan 2015.  Butuh waktu dua tahun bagi tim untuk merilis fungsionalitas minimum.  Rilis produksi kedua ekstensi berlangsung Oktober lalu dengan perbedaan satu minggu.  Rupanya, terburu-buru satu sama lain. <br><br>  GitHub memiliki banyak bintang dan garpu, yang, seperti biasa, tidak memiliki komitmen tunggal.  Begitulah cara kerja Open Source, tidak ada yang bisa dilakukan.  Tetapi ada banyak bintang, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TimescaleDB memiliki</a> lebih dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">PipelineDB</a> , dan bahkan lebih dari PostgreSQL itu sendiri. <br><br>  Ekstensi tampaknya serupa, tetapi posisinya berbeda. <br><br>  <b>TimescaleDB</b> mengklaim telah menyisipkan jutaan catatan per detik dan menyimpan ratusan miliar baris dan puluhan terabyte data.  Ekstensi lebih cepat dari InfluxDB, Cassandra, MongoDB atau vanilla PostgreSQL.  Mendukung replikasi streaming dan alat cadangan.  TimescaleDB adalah ekstensi, bukan fork dari PostgreSQL. <br><br>  <b>PipelineDB</b> hanya menyimpan hasil perhitungan streaming, tanpa perlu menyimpan data mentah untuk perhitungan mereka.  Ekstensi ini mampu melakukan agregasi terus-menerus melalui aliran data waktu-nyata, digabungkan dengan tabel konvensional untuk perhitungan dalam konteks domain domain.  PipelineDB adalah ekstensi, bukan garpu, tetapi pada awalnya itu adalah garpu. <br><br><h2>  Timescaledb </h2><br>  Sekarang secara rinci tentang ekstensi.  Mari kita mulai dengan TimescaleDB.  Saya telah bekerja dengannya selama hampir 2 tahun.  Menyeretnya ke produksi sebelum versi rilis.  Mari kita lihat contoh bagaimana menerapkannya. <br><br>  <b>Penyimpanan untuk metrik infrastruktur</b> .  Kami memiliki metrik konsumsi sumber daya wadah Docker, waktu komitmen metrik, pengidentifikasi wadah, dan bidang konsumsi sumber daya, misalnya, memori bebas.  Kita perlu menampilkan statistik untuk semua wadah dengan jumlah rata-rata jendela memori gratis selama 10 detik.  Kueri yang Anda lihat memecahkan masalah ini dan TimescaleDB dapat digunakan sebagai repositori untuk metrik infrastruktur. <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> time_bucket(<span class="hljs-string"><span class="hljs-string">'10 seconds'</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">time</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span>, container_id, <span class="hljs-keyword"><span class="hljs-keyword">avg</span></span>(free_mem) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> metrics <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-built_in"><span class="hljs-built_in">time</span></span> &lt; <span class="hljs-keyword"><span class="hljs-keyword">now</span></span>() - <span class="hljs-built_in"><span class="hljs-built_in">interval</span></span> <span class="hljs-string"><span class="hljs-string">'10 minutes'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span>, container_id <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span>, container_id;</code> </pre> <br><pre> <code class="plaintext hljs">period | container_id | avg -----------------------+--------------+--- 2019-06-24 12:01:00+00 | 16 | 72202 2019-06-24 12:01:00+00 | 73 | 837725 2019-06-24 12:01:00+00 | 96 | 412237 2019-06-24 12:00:50+00 | 16 | 1173393 2019-06-24 12:00:50+00 | 73 | 90104 2019-06-24 12:00:50+00 | 96 | 784596</code> </pre> <br>  <b>Untuk perhitungan</b> .  Kita perlu menghitung jumlah truk yang meninggalkan Krasnodar dan total tonasinya per hari. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> time_bucket(<span class="hljs-string"><span class="hljs-string">'1 day'</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">time</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">day</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> trucks_exiting, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(weight) / <span class="hljs-number"><span class="hljs-number">1000</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> tonnage <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> vehicles <span class="hljs-keyword"><span class="hljs-keyword">INNER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> cities <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> cities.name = <span class="hljs-string"><span class="hljs-string">'Krasnodar'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> ST_Within(last_location, ST_Polygon(cities.geom, <span class="hljs-number"><span class="hljs-number">4326</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> ST_Within(current_location, ST_Polygon(cities.geom, <span class="hljs-number"><span class="hljs-number">4326</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">day</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">day</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span>;</code> </pre> <br>  Itu juga menggunakan fungsi dari ekstensi PostGIS untuk menghitung transportasi yang meninggalkan kota, bukan hanya bergerak di dalamnya. <br><br>  <b>Pemantauan nilai tukar mata uang</b> .  Contoh ketiga adalah tentang cryptocurrency.  Permintaan memungkinkan Anda untuk menampilkan bagaimana harga Ethereum telah berubah relatif terhadap Bitcoin dan dolar Amerika selama 2 minggu terakhir per hari. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> time_bucket(<span class="hljs-string"><span class="hljs-string">'14 days'</span></span>, c.time) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">last</span></span>(c.closing_price, c.time) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> closing_price_btc, <span class="hljs-keyword"><span class="hljs-keyword">last</span></span>(c.closing_price, c.time) * <span class="hljs-keyword"><span class="hljs-keyword">last</span></span>(b.closing_price, c.time) filter (<span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> b.currency_code = <span class="hljs-string"><span class="hljs-string">'USD'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> closing_price_usd <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> crypto_prices c <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> btc_prices b <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> time_bucket(<span class="hljs-string"><span class="hljs-string">'1 day'</span></span>, c.time) = time_bucket(<span class="hljs-string"><span class="hljs-string">'1 day'</span></span>, b.time) <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> c.currency_code = <span class="hljs-string"><span class="hljs-string">'ETH'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span>;</code> </pre> <br>  Ini semua sama jelas dan nyaman bagi kita SQL. <br><br><h3>  Apa yang keren tentang TimescaleDB? </h3><br>  Mengapa tidak menggunakan alat partisi tabel bawaan?  Dan mengapa repot-repot memecahkan meja?  Jawaban yang jelas adalah <b>kecepatan penyisipan dalam database seperti itu</b> .  Grafik menunjukkan pengukuran aktual tingkat penyisipan jumlah baris per detik antara tabel vanilla reguler PostgreSQL 10 tanpa sectioning, dan TimescaleDB hipertensi. <br><br><img src="https://habrastorage.org/webt/gq/ln/xd/gqlnxdxeupbqkf_i-wdeihs0zlq.jpeg"><br><br>  Patokan ini menulis 1 miliar baris pada satu mesin, mensimulasikan skenario untuk mengumpulkan metrik dari infrastruktur.  Catatan berisi waktu, pengidentifikasi komponen infrastruktur, dan 10 metrik.  Benchmark dijalankan pada Azure VM dengan 8 core dan 28 gigabytes RAM, serta drive SSD jaringan.  Penyisipan dilakukan dalam batch 10 ribu catatan. <br><br>  Dari manakah penurunan kinerja PostgreSQL tersebut?  Karena ketika Anda memasukkan, Anda juga perlu memperbarui indeks tabel.  Ketika mereka tidak masuk ke dalam cache, kami mulai memuat disk.  Partisi menyelesaikan masalah ini jika indeks bagian tempat kami memasukkan data ditempatkan dalam RAM. <br><br>  Mari kita lihat tabel berikut.  Ini membandingkan sistem partisi deklaratif yang dibangun ke dalam PostgreSQL 10 dan tabel hyperc TimescaleDB.  Pada sumbu horizontal, jumlah bagian. <br><br><img src="https://habrastorage.org/webt/kd/dz/xd/kddzxdttzspi9peoiriem7sipms.jpeg"><br><br>  Dalam TimescaleDB, degradasi dapat diabaikan dengan meningkatnya bagian.  Pengembang ekstensi mengklaim bahwa mereka baik-baik saja dengan 10.000 bagian dalam satu contoh PostgreSQL. <br><br>  Dalam PostgreSQL, implementasi asli menurun secara signifikan setelah 3.000. Secara umum, partisi deklaratif dalam PostgreSQL adalah langkah besar ke depan, tetapi hanya berfungsi dengan baik untuk tabel dengan beban lebih sedikit.  Misalnya, untuk barang, pembeli, dan entitas domain lain yang memasuki sistem tidak seintensif metrik. <br><br>  Dalam 11 dan 12 versi PostgreSQL, dukungan partisi asli akan muncul dan Anda dapat mencoba menjalankan tes komparatif untuk data deret waktu dengan versi baru.  Tapi, menurut saya TimescaleDB masih lebih baik.  Semua tolok ukur dari TimescaleDB dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">github</a> mereka dan coba. <br><br><h3>  Fitur utama </h3><br>  Saya harap Anda sudah memiliki minat pada ekstensi.  Mari kita membahas fitur utama TimescaleDB untuk mengkonsolidasikan perasaan ini. <br><br>  <b>Partisi melalui hipertensi</b> .  TimescaleDB menggunakan istilah "hypertable" untuk tabel di mana fungsi create_hypertable () telah diterapkan.  Setelah itu, tabel akan menjadi induk untuk semua bagian yang diwarisi - potongan.  Tabel induk itu sendiri tidak akan berisi data apa pun, tetapi akan menjadi titik masuk untuk semua kueri dan templat ketika secara otomatis membuat bagian baru.  Semua bagian disimpan bukan dalam skema utama data Anda, tetapi dalam skema khusus.  Ini nyaman karena kami tidak melihat ribuan bagian ini dalam skema data. <br><br>  <b>Ekstensi diintegrasikan ke penjadwal dan pelaksana kueri</b> .  Melalui kait khusus di PostgreSQL, TimescaleDB memahami ketika mengakses sebuah hipertensi.  TimescaleDB menganalisis kueri dan mengarahkan kueri hanya ke bagian yang diperlukan berdasarkan kondisi yang ditentukan dalam panggilan SQL itu sendiri.  Ini memungkinkan Anda untuk memparalelkan pekerjaan dengan bagian selama ekstraksi sejumlah besar data. <br><br>  <b>Ekstensi tidak memberlakukan batasan pada SQL</b> .  Anda dapat dengan bebas menggunakan serikat pekerja, agregat, fungsi jendela, CTE dan indeks tambahan.  Jika Anda melihat daftar pembatasan untuk sistem partisi bawaan, ini seharusnya menyenangkan Anda. <br><br>  <b>Fitur berguna tambahan</b> khusus untuk data deret waktu: <br><br><ul><li>  "Time_bucket" - "date_trun" dari orang sehat; <br></li><li>  histogram - mengisi interval yang terlewat menggunakan interpolasi atau nilai terakhir yang diketahui; <br></li><li>  pekerja latar belakang - layanan yang memungkinkan Anda untuk melakukan operasi latar belakang: membersihkan bagian-bagian lama, mengatur ulang. <br></li></ul><br>  <b>TimescaleDB memungkinkan Anda untuk tetap berada di ekosistem PostgreSQL yang kuat</b> .  Ekstensi ini tidak merusak PostgreSQL, oleh karena itu semua solusi Ketersediaan Tinggi, sistem cadangan, alat pemantauan akan terus bekerja.  TimescaleDB berteman dengan Grafana, Periscope, Prometheus, Telegraf, Zabbix, Kubernetes, Kafka, Seeq, JackDB. <br><br>  <b>Grafana</b> sudah memiliki dukungan asli untuk TimescaleDB sebagai sumber data.  Grafana memahami bahwa PostscreSQL memiliki TimescaleDB.  Pembuat kueri di Grafana di dasbor memahami fungsi TimescaleDB tambahan, seperti "time_bucket", "pertama", "terakhir".  Anda dapat membuat grafik langsung dari database relasional dengan fungsi deret waktu ini tanpa permintaan raksasa. <br><br>  <b>Prometheus memiliki</b> adaptor yang memungkinkan Anda untuk menggabungkan data darinya dan menggunakan TimescaleDB sebagai gudang data yang dapat diandalkan.  Gunakan adaptor untuk tidak menyimpan data di Prometheus selama bertahun-tahun. <br><br>  Ada juga <b>plugin Telegraf</b> .  Solusinya memungkinkan Anda untuk menghapus Prometheus sepenuhnya.  Data infrastruktur segera ditransfer ke TimescaleDB dan dibaca melalui Telegraf. <br><br><h3>  Lisensi dan Berita </h3><br>  Belum lama ini, perusahaan beralih ke model lisensi baru.  Sebagian besar kode dilisensikan di bawah Apache 2.0.  Sebagian kecil gratis untuk digunakan, tetapi dilisensikan di bawah TSL. <br><br>  Ada versi Perusahaan dengan lisensi komersial.  Jangan khawatir, tidak semua barang dalam versi Enterprise.  Pada dasarnya ada otomatisasi seperti penghapusan otomatis potongan usang, yang dapat dilakukan melalui "cron" sederhana dan hal-hal serupa. <br><br>  Sekarang perusahaan secara aktif mengerjakan solusi cluster.  Mungkin itu akan jatuh ke versi Enterprise.  Ada juga versi cloud untuk pemula yang ingin mengelola untuk memasuki pasar sebelum investor kehabisan uang. <br><br>  Dari berita: <br><br><ul><li>  satu juta unduhan selama setengah tahun terakhir; <br></li><li>  Investasi $ 31 juta; <br></li><li>  Kolaborasi aktif dengan MS Azure mengenai solusi IoT. <br></li></ul><br><h3>  Untuk meringkas </h3><br><blockquote>  TimescaleDB dirancang untuk menyimpan data deret waktu.  Ini adalah sistem partisi yang kuat dengan batasan minimal dibandingkan dengan yang asli di PostgreSQL. </blockquote><br>  Sayangnya, ekstensi belum memiliki versi multinode.  Jika Anda ingin multimaster atau beling, Anda harus bermain-main, misalnya dengan CitusDB.  Jika Anda ingin replikasi logis, itu akan menyakitkan.  Tapi itu selalu menyakitkan baginya. <br><br><h2>  Pipelinedb </h2><br>  Sekarang mari kita bicara tentang ekstensi kedua.  Sayangnya, kami tidak dapat mengujinya dengan benar dalam pertempuran.  Sekarang sedang melalui tahap adaptasi dalam sistem kami.  Benar, ada satu masalah yang akan saya bicarakan lebih dekat sampai akhir. <br><br>  Seperti pada kasus sebelumnya, kita mulai dengan contoh nyata.  Lebih mudah untuk memahami manfaat ekstensi dan motivasi untuk menggunakannya. <br><br>  <b>Koleksi statistik</b> .  Bayangkan kami mengumpulkan statistik tentang kunjungan ke situs web kami.  Kami membutuhkan analitik dari halaman yang paling populer, jumlah pengguna unik dan beberapa gagasan tentang keterlambatan sumber daya.  Semua ini harus diperbarui secara waktu nyata.  Tetapi kami tidak ingin menyentuh tabel data setiap kali dan membuat kueri, atau memperbarui tampilan di atas tabel. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> CONTINUOUS <span class="hljs-keyword"><span class="hljs-keyword">VIEW</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">url</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">text</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> total_count, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> cookie::<span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques, <span class="hljs-keyword"><span class="hljs-keyword">percentile_cont</span></span>(<span class="hljs-number"><span class="hljs-number">0.99</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">WITHIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> latency::<span class="hljs-built_in"><span class="hljs-built_in">integer</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> p99_latency <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> page_views <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">url</span></span>;</code> </pre> <br><pre> <code class="plaintext hljs">url | total_count | uniques | p99_latency -----------+-------------+---------+------------ some/url/0 | 633 | 51 | 178 some/url/1 | 688 | 37 | 139 some/url/2 | 508 | 88 | 121 some/url/3 | 848 | 36 | 59 some/url/4 | 126 | 64 | 159</code> </pre> <br>  Pemrosesan streaming dan ekstensi PipelineDB datang untuk menyelamatkan.  Ekstensi menambahkan abstraksi LIHAT LANJUTAN.  Dalam versi Rusia, ini mungkin terdengar seperti "presentasi berkelanjutan".  Tampilan ini diperbarui secara otomatis ketika dimasukkan ke dalam tabel dengan catatan kunjungan, sementara hanya berdasarkan data baru, tanpa pembacaan yang sudah direkam sebelumnya. <br><br>  <b>Aliran data</b> .  PipelineDB tidak terbatas hanya pada tipe tampilan baru.  Misalkan kita melakukan pengujian A / B dan mengumpulkan analitik real-time tentang efektivitas solusi bisnis baru.  Tetapi kami tidak ingin menyimpan data pada tindakan pengguna itu sendiri.  Kami hanya tertarik pada hasilnya - grup mana yang memiliki konversi terbanyak. <br><br>  Untuk menghindari penyimpanan langsung dari data mentah untuk streaming komputasi, kita perlu abstraksi seperti <b>stream - stream data</b> .  PipelineDB memperkenalkan fitur ini.  Anda dapat membuat stream seperti tabel biasa.  Di bawah tenda, itu akan menjadi "TABEL LUAR NEGERI" berdasarkan pada antrian ZeroMQ, yang ekstensi secara tak terlihat menggunakan dari kami.  Data memasuki antrian internal ZeroMQ dan memicu pembaruan ke tampilan berkelanjutan. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> STREAM ab_event_stream ( <span class="hljs-keyword"><span class="hljs-keyword">name</span></span> <span class="hljs-built_in"><span class="hljs-built_in">text</span></span>, ab_group <span class="hljs-built_in"><span class="hljs-built_in">text</span></span>, event_type <span class="hljs-built_in"><span class="hljs-built_in">varchar</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>), cookie <span class="hljs-built_in"><span class="hljs-built_in">varchar</span></span>(<span class="hljs-number"><span class="hljs-number">32</span></span>) ); <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> CONTINUOUS <span class="hljs-keyword"><span class="hljs-keyword">VIEW</span></span> ab_test_monitor <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, ab_group, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">CASE</span></span> WHENevent_type = <span class="hljs-string"><span class="hljs-string">'v'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ELSE</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">END</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> view_count, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">CASE</span></span> WHENevent_type = <span class="hljs-string"><span class="hljs-string">'c'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ELSE</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">END</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> conversion_count, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> cookie) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ab_event_stream <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, ab_group;</code> </pre> <br>  Kemudian kami membuat "LIHAT LANJUTAN" berdasarkan data dari aliran yang dibuat sebelumnya.  Ketika data tiba di aliran, tampilan akan diperbarui berdasarkan data ini.  Setelah itu, data hanya akan dibuang, tidak disimpan di mana pun dan tidak mengambil ruang disk.  Ini memungkinkan Anda untuk membangun analitik pada jumlah data yang hampir tidak terbatas, memuatnya ke dalam aliran data PipelineDB dan membaca hasil perhitungan dari tampilan berkelanjutan. <br><br>  <b>Komputasi aliran</b>  Setelah kami membuat aliran data dan tampilan berkelanjutan, kami dapat bekerja dengan komputasi aliran.  Ini terlihat seperti ini. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> ab_event_stream (<span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, ab_group, event_type, cookie) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">round</span></span>(random() * <span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">round</span></span>(random() * <span class="hljs-number"><span class="hljs-number">4</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> ab_group, (<span class="hljs-keyword"><span class="hljs-keyword">CASE</span></span> WHENrandom() &gt; <span class="hljs-number"><span class="hljs-number">0.4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-string"><span class="hljs-string">'v'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ELSE</span></span> <span class="hljs-string"><span class="hljs-string">'c'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">END</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> event_type, <span class="hljs-keyword"><span class="hljs-keyword">md5</span></span>(random()::<span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> cookie <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">100000</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> ab_group, uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ab_test_monitor; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> ab_group, view_count * <span class="hljs-number"><span class="hljs-number">100</span></span> / (conversion_count + view_count) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> conversion_rate <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ab_test_monitor;</code> </pre> <br>  "SELECT" pertama memberi grup "ab" dan jumlah pengunjung unik.  Yang kedua - memberikan rasio antara kelompok - konversi.  Itu semua pengujian A / B pada lima panggilan SQL dalam database relasional. <br><br>  Tampilan diperbarui secara dinamis.  Anda tidak bisa menunggu pemrosesan seluruh data array, tetapi membaca hasil antara yang sudah diproses.  Tampilan dibaca dengan cara yang sama seperti PostgreSQL biasa.  Anda juga dapat menggabungkan tampilan dengan tabel atau bahkan tampilan lainnya.  Tidak ada batasan. <br><br><h3>  Topologi </h3><br>  Kafka menerima telemetri, topik dalam Kafka mengirimkan data ini ke PostgreSQL, dan kami menggabungkannya lebih lanjut.  Misalnya, kami menggabungkan dengan beberapa tabel biasa dan mengarahkan data ke aliran.  Selanjutnya, ia memprovokasi pembaruan dari presentasi berkelanjutan yang sesuai, dari mana klien database sudah dapat membaca data yang sudah selesai. <br><br><img src="https://habrastorage.org/webt/0e/4p/zb/0e4pzbehsh35td5tdiillcaq82m.jpeg"><br><br>  <i>Contoh topologi komponen PipelineDB di dalam PostgreSQL.</i>  <i>Sirkuit ini dipinjam dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">presentasi oleh</a> Derek Nelson.</i> <br><br>  Selain aliran dan tampilan, ekstensi juga menyediakan abstraksi "transform" - konverter atau mutator.  Pandangan ini, tetapi bertujuan untuk mengubah aliran data yang masuk menjadi output yang dimodifikasi.  Dengan menggunakan mutator ini, Anda dapat mengubah penyajian data atau memfilternya.  Dari mutator, semuanya jatuh ke tampilan LIHAT TERUS.  Kami sudah mengajukan pertanyaan untuk bisnis di dalamnya.  Siapa pun yang akrab dengan pemrograman fungsional harus memahami gagasan itu. <br><br>  Di PipelineDB kita bisa menggantung pemicu pada pandangan kita dan melakukan tindakan, misalnya, "waspada".  Dengan semua perhitungan ini, kami tidak pernah menyimpan sendiri data mentah, atas dasar yang mana kami semua menghitungnya.  Ini dapat berupa terabyte, yang kami unggah secara berurutan ke server dengan disk seratus gigabyte.  Bagaimanapun, kami hanya tertarik pada hasil perhitungan. <br><br><h3>  Fitur utama </h3><br>  Ekstensi PipelineDB lebih sulit dipelajari daripada TimescaleDB.  Di TimescaleDB, kami membuat tabel, memberi tahu dia bahwa dia hipertensi, dan menikmati hidup menggunakan beberapa fungsi tambahan yang ditawarkan ekstensi. <br><br>  <b>PipelineDB memecahkan masalah streaming komputasi dalam database relasional</b> .  Tugas pemrosesan data streaming lebih rumit daripada mempartisi dalam hal integrasi dan penggunaan.  Namun, tidak semua orang memiliki data besar dan miliaran baris.  Mengapa menyulitkan infrastruktur jika ada PipelineDB?  Ekstensi menyediakan implementasi representasi, aliran, konverter, dan agregat sendiri untuk pemrosesan aliran.  Ia juga <b>diintegrasikan ke dalam perencana kueri dan pelaksana kueri</b> memungkinkan penerapan konsep komputasi aliran dalam basis data relasional. <br><br>  Seperti TimescaleDB, ekstensi PipelineDB <b>tidak memaksakan pembatasan SQL di PostgreSQL</b> .  Ada beberapa fitur, misalnya, Anda tidak dapat menggabungkan dua aliran, tetapi ini tidak perlu. <br><br>  <b>Dukungan untuk struktur data dan algoritma probabilistik</b> .  Ekstensi menggunakan "Bloom Filter" untuk "SELECT DISTINCT", HyperLogLog untuk "COUNT (DISTINCT)", dan T-Intisari untuk "presentile_count ()" secara langsung dalam SQL.  Ini meningkatkan produktivitas. <br><br>  <b>Ekosistem</b>  Ekstensi ini memungkinkan Anda untuk bekerja dengan solusi Ketersediaan Tinggi, alat pemantauan, dan semua hal lain yang sudah biasa di PostgreSQL. <br><br>  Mengingat kekhasan komputasi streaming, PipelineDB memiliki <b>integrasi dengan Apache Kafka</b> , dan dengan Amazon Kinesis, layanan analitik waktu-nyata.  Karena PipelineDB bukan lagi garpu, tetapi ekstensi, integrasi dengan seluruh kebun binatang juga harus di luar kotak.  Suatu keharusan, tetapi kita tidak hidup di dunia yang ideal, dan semuanya patut diperiksa. <br><br><h3>  Lisensi dan Berita </h3><br>  Semua kode dilisensikan di bawah Apache 2.0.  Ada langganan berbayar untuk dukungan berbagai galeri pemotretan, serta versi klaster dengan lisensi komersial.  Berdasarkan PipelineDB, perusahaan menyediakan layanan analitik Stride. <br><br>  Sebelum saya mulai berbicara tentang ekstensi, saya mengatakan bahwa ada satu "tetapi".  Sudah waktunya untuk berbicara tentang dia.  Pada 1 Mei 2019, tim PipelineDB mengumumkan bahwa itu sekarang bagian dari Confluent.  Ini adalah perusahaan yang mengembangkan KSQL - mesin untuk streaming data di Kafka dengan sintaks SQL.  Sekarang Victor Gamov, salah satu pendiri podcast Debriefing, bekerja di sana. <br><br>  Apa yang mengikuti dari ini?  PipelineDB membeku di versi 1.0.0.  Selain memperbaiki bug penting, tidak ada yang direncanakan di dalamnya.  Karena pengambilalihan, kami mengharapkan integrasi Uber Kafka dengan PostgreSQL.  Mungkin itu Confluent berdasarkan penyimpanan pluggable yang akan melakukan sesuatu yang keren. <br><br>  Apa yang harus dilakukan  Pergi ke TimescaleDB.  Dalam versi terbaru mereka membuat "LIHAT KONTINU" dengan blackjack.  Tentu saja, sekarang fungsinya tidak sekeren di PipelineDB, tetapi itu adalah masalah waktu. <br><br><h3>  Untuk meringkas </h3><br><blockquote>  PipelineDB dirancang untuk pemrosesan data streaming kinerja tinggi.  Ini memungkinkan Anda untuk melakukan perhitungan pada set data besar tanpa harus menyimpan data itu sendiri. </blockquote><br>  Dengan PipelineDB, ketika kami mengirim aliran data ke PostgreSQL dalam aliran, kami menganggapnya virtual.  Kami tidak menyimpan data, tetapi menggabungkan, menghitung dan membuang.  Anda dapat membuat server 200 gigabyte dan mengusir terabyte data melalui stream.  Kami akan mendapatkan hasilnya, tetapi data itu sendiri akan dibuang. <br><br>  Jika karena alasan tertentu "TAMPILAN LANJUT" dari TimescaleDB tidak cukup untuk Anda, coba PipelineDB.  Ini adalah proyek open source di bawah lisensi Apache.  Itu tidak akan pergi ke mana pun, meskipun tidak lagi dikembangkan secara aktif.  Tetapi hal-hal dapat berubah, Confluent belum menulis tentang rencana ekspansi. <br><br><h2>  Menggunakan TimescaleDB dan PipelineDB </h2><br>  Dengan PostgreSQL dan dua ekstensi, <b>kita dapat menyimpan dan memproses array besar dari data deret waktu</b> .  Anda dapat memikirkan banyak aplikasi.  Mari kita lihat contoh dari bidang studi saya - pemantauan kendaraan. <br><br><img src="https://habrastorage.org/webt/mx/_k/ru/mx_krumolcfgrlfrraktizshhem.jpeg"><br><br>  Peralatan navigasi terus mengirimkan rekaman telemetri ke server kami.  Mereka mengurai berbagai teks dan protokol biner ke dalam format umum dan mengirim data ke Kafka dalam topik khusus.  Dari sana, mereka mendapatkan integrasi dengan PipelineDB ke aliran data telemetri di dalam PostgreSQL.  Aliran ini memperbarui pandangan untuk keadaan saat ini kendaraan dan analisis armada umum, dan atas dasar pemicu memprovokasi rekaman catatan telemetri di hipertensi TimescaleDB. <br><br>  Dengan ekstensi, kami memiliki tiga keunggulan. <br><br><ul><li>  Analitik waktu-nyata. <br></li><li>  Penyimpanan data seri waktu. <br></li><li>  Mengurangi volume telemetri yang disimpan.  Menggunakan mutator PipelineDB, kami mengumpulkan data, misalnya, dengan satu menit, menghitung nilai rata-rata. <br></li></ul><br>  Grafana memiliki dukungan bawaan untuk fitur TimescaleDB.  Oleh karena itu, grafik dapat dibuat sesuai dengan metrik bisnis langsung dari kotak, hingga trek di peta dengan koordinat.  Departemen analitik akan senang. <br><br>  Untuk "menyentuh" ‚Äã‚Äãsemuanya sendiri, lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">demo di GitHub</a> dan jalankan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">gambar Docker</a> - di dalam perakitan dari PostgreSQL, TimescaleDB, dan PipelineDB terbaru. <br><br><h2>  Total </h2><br>  PostgreSQL memungkinkan Anda untuk menggabungkan berbagai ekstensi, serta menambahkan tipe dan fungsi data Anda sendiri untuk menyelesaikan masalah tertentu.  Dalam kasus kami, penggunaan ekstensi TimescaleDB dan PostGIS hampir sepenuhnya mencakup kebutuhan untuk menyimpan data deret waktu dan perhitungan geospasial.  Dengan ekstensi PipelineDB, kami dapat melakukan perhitungan terus-menerus untuk berbagai analitik dan statistik, dan penggunaan kolom JSONB memungkinkan kami untuk menyimpan data yang terstruktur dengan lemah dalam database relasional.  Solusi Open Source sudah cukup dengan kepala - kami tidak menggunakan solusi komersial. <br><br>  Ekstensi ini secara praktis tidak memaksakan pembatasan pada ekosistem di sekitar PostgreSQL, seperti solusi Ketersediaan Tinggi, sistem cadangan, pemantauan dan alat analisis log.  Kami tidak memerlukan MongoDB jika ada kolom JSONB, dan kami tidak perlu InfluxDB jika ada TimescaleDB. <br><br><blockquote>  Apakah Anda suka cerita dari Ivan dan ingin berbagi sesuatu yang serupa?  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Terapkan</a> sebelum 7 September di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++</a> di Moskow.  Program ini secara bertahap terisi.    ,    ,  , ,  .    ,    ! </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id464303/">https://habr.com/ru/post/id464303/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id464289/index.html">Cara menulis paket Go</a></li>
<li><a href="../id464291/index.html">10 bahasa pemrograman paling berpengaruh dalam 50 tahun terakhir dan penciptanya</a></li>
<li><a href="../id464293/index.html">Apakah kait diganti dalam React Redux?</a></li>
<li><a href="../id464295/index.html">Contoh menggunakan beberapa fitur JavaScript baru</a></li>
<li><a href="../id464299/index.html">0, 0, 1, 0, 2, 0, 2, 2, 1, 6, 0, 5, 0, 2, 6, 5, 4, 0, 5, 3, 0, 3, 2, 9, 0, 4, 9, 3, 6, 14, 0, 6, 3, 5, 15, 0, 5, 3, 5 ...</a></li>
<li><a href="../id464305/index.html">Kecil ya. Membuka kotak microvirtual Firecracker</a></li>
<li><a href="../id464307/index.html">Pengujian integrasi layanan microser di Scala</a></li>
<li><a href="../id464309/index.html">Tombol panggilan DIY. Raspberry Pi, MajorDoMo, Freeswitch dan Linphonec</a></li>
<li><a href="../id464315/index.html">Film di mana ada tanah. Penelitian Yandex dan sejarah singkat pencarian berdasarkan makna</a></li>
<li><a href="../id464317/index.html">Proyek Konbanwa</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
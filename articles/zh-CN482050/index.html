<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎮 💇🏽 🗞️ 绝地卷积网络约简技术-修剪 📀 ❎ 🕠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="再次介绍检测对象的任务。 优先级-速度可接受的精度。 您将采用YOLOv3的体系结构并进行培训。 精度（mAp75）大于0.95。 但是运行速度仍然很低。 地狱 


 今天，我们将绕过量化。 在削减的范围内，考虑进行模型修剪 -修剪冗余网络部分以加快推理速度而又不损失准确性。 从视觉上看-在哪里切...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>绝地卷积网络约简技术-修剪</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482050/"><p><img src="https://habrastorage.org/webt/tf/oa/br/tfoabr16w_dawnzb9hnjndyv_bg.png" alt="图片"></p><br><p> 再次介绍检测对象的任务。 优先级-速度可接受的精度。 您将采用YOLOv3的体系结构并进行培训。 精度（mAp75）大于0.95。 但是运行速度仍然很低。 地狱 </p><br><p> 今天，我们将绕过量化。 在削减的范围内，考虑进行<strong>模型修剪</strong> -修剪冗余网络部分以加快推理速度而又不损失准确性。 从视觉上看-在哪里切割多少。 让我们弄清楚如何手动执行操作以及在何处可以实现自动化。 最后是在keras上的存储库。 </p><a name="habracut"></a><br><h3 id="vvedenie"> 引言 </h3><br><p> 在工作的最后一个地方，Perm Macroscop，我养成了一个习惯-总是监视算法的执行时间。 网络运行时间应始终通过适当性过滤器进行检查。 通常，产品中的最新技术不会通过此过滤器，这导致我无法进行修剪。 </p><br><p> 修剪是一个古老的主题，在2017年的<a href="https://www.youtube.com/watch%3Fv%3DeZdOkDtYMoo" rel="nofollow">斯坦福演讲</a>中曾谈到<a href="https://www.youtube.com/watch%3Fv%3DeZdOkDtYMoo" rel="nofollow">过</a> 。 主要思想是通过删除各种节点来减少训练网络的大小而不会损失准确性。 听起来很酷，但是我很少听说它的用法。 可能没有足够的实现，没有俄语文章，或者只是每个人都认为修剪专有技术和保持沉默。 <br> 但是请分开 </p><br><h3 id="vzglyad-v-biologiyu"> 生物学研究 </h3><br><p> 我喜欢深度学习中的想法来自生物学。 它们像进化一样可以被信任（您知道ReLU与<a href="http://www.gatsby.ucl.ac.uk/~lmate/biblio/dayanabbott.pdf" rel="nofollow">激活大脑神经元</a>的<a href="http://www.gatsby.ucl.ac.uk/~lmate/biblio/dayanabbott.pdf" rel="nofollow">功能</a>非常相似吗？） </p><br><p> 模型修剪过程也接近生物学。 此处的网络响应可以与大脑的可塑性进行比较。  <a href="https://www.litres.ru/norman-doydzh/plastichnost-mozga/%3Futm_medium%3Dcpc%26utm_source%3Dgoogle%26utm_campaign%3DDSA%257C149839530%26utm_term%3D%26utm_content%3Dk50id%257Caud-499675211712%253Adsa-179513627318%257Ccid%257C149839530%257Caid%257C248455294996%257Cgid%257C6837176850%257Cpos%257C1t1%257Csrc%257Cg_%257Cdvc%257Cc%257Creg%257C1011993%257Crin%257C%257C%26k50id%3D6837176850%257Caud-499675211712%253Adsa-179513627318%26gclid%3DCj0KCQiA0ZHwBRCRARIsAK0Tr-oKPqkmL7_Oxg62JZO8Jlk9zO-9nYKIRFxHi_lgoCvsQQadvUGxUzkaApgpEALw_wcB" rel="nofollow">Norman Dodge的</a>书中有几个有趣的例子： </p><br><ol><li> 一个刚出生时只有一半的女人的大脑重新编程以执行缺失的一半的功能 </li><li> 这个家伙向自己射击了负责视觉的大脑部分。 随着时间的流逝，大脑的其他部分将接管这些功能。  （请勿重试） </li></ol><br><p> 因此，您可以从模型中切除一些弱束。 在极端情况下，剩余的捆束将有助于更换切好的捆束。 </p><br><h3 id="lyubish-transfer-learning-ili-uchish-s-nulya"> 您喜欢转学还是从头学习？ </h3><br><p>  <strong>选项一。</strong> 您正在Yolov3上使用转移学习。 视网膜，Mask-RCNN或U-Net。 但是通常，我们不需要像COCO中那样识别80类对象。 在我的实践中，所有课程仅限于1-2节课。 可以假定这里有80个类的体系结构是多余的。 让人想到需要减少体系结构。 此外，我希望做到这一点而又不会失去现有的预先训练的体重。 </p><br><p>  <strong>选项二。</strong> 也许您拥有大量的数据和计算资源，或者您只需要一个超级定制的体系结构。 没关系 但是您从头开始学习网络。 通常的顺序是查看数据结构，选择一种功耗降低的架构，并从重新训练中减少辍学。 我看到辍学0.6，卡尔。 </p><br><p> 在两种情况下，都可以减少网络。 晋升。 现在让我们找出哪种 <del> 包皮环切术 </del> 修剪 </p><br><h3 id="obschiy-algoritm"> 通用算法 </h3><br><p> 我们决定可以消除卷积。 看起来很简单： </p><br><p><img src="https://habrastorage.org/webt/ey/yt/-g/eyyt-g-b6pfzjrbnim_ssosyqqk.png"></p><br><p> 消除任何卷积是网络的压力，通常会导致误差增加。 一方面，这种错误增长表明我们如何正确消除卷积（例如，大的增长表明我们做错了什么）。 但是小的增长是完全可以接受的，并且通常通过随后使用小LR进行简单的进一步培训来消除。 我们添加了重新训练的步骤： </p><br><p><img src="https://habrastorage.org/webt/kb/ui/5d/kbui5dm1k8sgflm5xzu0wggbbhs.png"></p><br><p> 现在我们需要了解何时停止学习&lt;-&gt;修剪周期。 当我们需要将网络缩小到一定规模和运行速度时（例如，对于移动设备），可能会有一些特殊的选择。 但是，最常见的选择是继续循环，直到误差变得大于允许的误差为止。 添加条件： </p><br><p><img src="https://habrastorage.org/webt/1i/pi/52/1ipi52uqhkciw2ne-1zt2rbdmje.png"></p><br><p> 因此，算法变得清晰。 如何确定删除的卷积还有待分解。 </p><br><h3 id="poisk-udalyaemyh-svertok"> 搜索要删除的卷积 </h3><br><p> 我们需要消除一些卷积。 尽管它会起作用，但先撕掉并“击退”是一个坏主意。 但是，如果您有头脑，您可以考虑并尝试选择“弱”卷积进行去除。 有几种选择： </p><br><ol><li>  <a href="https://openreview.net/pdf%3Fid%3DrJqFGTslg" rel="nofollow">最小的L1度量或low_magnitude_pruning</a> 。 小权重的卷积对最终决策的贡献很小 </li><li> 考虑到平均值和标准偏差的最小L1度量。 我们补充对分布性质的评估。 </li><li>  <a href="https://arxiv.org/abs/1512.08571" rel="nofollow">掩盖卷积并消除影响最小的结果精度</a> 。 微不足道的卷积的更准确定义，但非常耗时且占用大量资源。 </li><li> 其他 </li></ol><br><p> 每个选项都具有生命权及其自己的实现功能。 在这里，我们考虑L1度量最小的变量 </p><br><h3 id="ruchnoy-process-dlya-yolov3">  YOLOv3的手动处理 </h3><br><p> 原始体系结构包含残留块。 但是，无论深度网络多么酷，它们都会在一定程度上阻碍我们的发展。 困难在于您无法在这些图层中删除具有不同索引的对帐： </p><br><p><img src="https://habrastorage.org/webt/mh/p-/-k/mhp--ksk3ifgurz5jx6exgcrm5c.png"></p><br><p> 因此，我们选择可以自由删除对帐的图层： </p><br><p><img src="https://habrastorage.org/webt/qy/ek/zo/qyekzofcur-q0auqurg3egxnato.png"></p><br><p> 现在让我们建立一个工作周期： </p><br><ol><li> 卸载激活 </li><li> 我们想知道削减多少 </li><li> 切出 </li><li> 通过LR = 1e-4学习10个时代 </li><li> 测试中 </li></ol><br><p> 卸载卷积对于评估我们可以在特定步骤中删除的部分很有用。 卸载示例： </p><br><p><img src="https://habrastorage.org/webt/rp/jo/pk/rpjopk6dzfrl6psoucr8tgj0log.png"></p><br><p> 我们发现几乎到处都有5％的卷积具有非常低的L1范数，我们可以将其删除。 在每个步骤中，都要重复进行这样的卸载，并评估哪些层以及可以切割多少层。 </p><br><p> 整个过程分4个步骤完成（此处和所有RTX 2060 Super的编号）： </p><br><div class="scrollable-table"><table><thead><tr><th> 步骤 </th><th> 单抗75 </th><th> 参数数量，万 </th><th> 网络大小，mb </th><th> 较原始，％ </th><th> 运行时间，毫秒 </th><th> 割礼条件 </th></tr></thead><tbody><tr><td>  0 </td><td>  0.9656 </td><td>  60 </td><td>  241 </td><td>  100 </td><td>  180 </td><td>  -- </td></tr><tr><td>  1个 </td><td>  0.9622 </td><td>  55 </td><td>  218 </td><td>  91 </td><td>  175 </td><td> 占总数的5％ </td></tr><tr><td>  2 </td><td>  0.9625 </td><td>  50 </td><td>  197 </td><td>  83 </td><td>  168 </td><td> 占总数的5％ </td></tr><tr><td>  3 </td><td>  0.9633 </td><td>  39 </td><td>  155 </td><td>  64 </td><td>  155 </td><td> 卷积超过400的图层占15％ </td></tr><tr><td><del>  4 </del></td><td><del>  0.9555 </del></td><td><del>  31 </del></td><td><del>  124 </del></td><td><del>  51 </del></td><td><del>  146 </del></td><td><del> 卷积超过100的图层占10％ </del></td></tr></tbody></table></div><br><p> 在第2步中，添加了一个积极的效果-补丁大小4进入了内存，大大加快了重新训练的过程。 <br> 在第4步，该过程已停止，因为 甚至长时间的继续教育也无法将mAp75提高到旧值。 <br> 结果，我们设法将推理速度提高了<strong>15％</strong> ，将尺寸减小了<strong>35％，</strong>并且没有损失准确性。 </p><br><h3 id="avtomatizaciya-dlya-bolee-prostyh-arhitektur"> 自动化实现更简单的架构 </h3><br><p> 对于更简单的网络体系结构（无条件添加，合并和残差块），完全有可能专注于处理所有卷积层并使切割卷积的过程自动化。 </p><br><p> 我<a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">在这里</a>实现了<a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">这个</a>选项。 <br> 很简单：您只有损失函数，优化器和批处理生成器： </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pruning <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequence train_batch_generator = BatchGenerator... score_batch_generator = BatchGenerator... opt = Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>) pruner = pruning.Pruner(<span class="hljs-string"><span class="hljs-string">"config.json"</span></span>, <span class="hljs-string"><span class="hljs-string">"categorical_crossentropy"</span></span>, opt) pruner.prune(train_batch, valid_batch)</code> </pre> <br><p> 如有必要，您可以更改配置参数： </p><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"input_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"output_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model_pruned.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"finetuning_epochs"</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, # the number of epochs for train between pruning steps <span class="hljs-attr"><span class="hljs-attr">"stop_loss"</span></span>: <span class="hljs-number"><span class="hljs-number">0.1</span></span>, # loss for stopping process <span class="hljs-attr"><span class="hljs-attr">"pruning_percent_step"</span></span>: <span class="hljs-number"><span class="hljs-number">0.05</span></span>, # part of convs for delete on every pruning step <span class="hljs-attr"><span class="hljs-attr">"pruning_standart_deviation_part"</span></span>: <span class="hljs-number"><span class="hljs-number">0.2</span></span> # shift for limit pruning part }</code> </pre> <br><p> 另外，实施基于标准偏差的限制。 目标是限制一部分已删除的卷，不包括具有“足够” L1量度的卷积： </p><br><p><img src="https://habrastorage.org/webt/bh/_9/nq/bh_9nqasnp91xifixn7ilhco0mw.png"></p><br><p> 因此，我们只能从类似于右侧的分布中删除弱卷积，而不会影响从类似于左侧的分布中删除： </p><br><p><img src="https://habrastorage.org/webt/pr/r5/zp/prr5zpjrdvh1wow6slejnn6axya.png"></p><br><p> 当分布接近正态时，可以从以下中选择系数pruning_standart_deviation_part： </p><br><p><img src="https://habrastorage.org/webt/dl/yl/7d/dlyl7dub216jsr67dcbnhez5fl8.png"><br> 我建议使用2 sigma的假设。 否则您将无法专注于此功能，而将值保留为&lt;1.0。 </p><br><p> 输出是整个测试的网络大小，损耗和网络运行时间的图形，标准化为1.0。 例如，这里的网络大小几乎减少了2倍，而没有质量损失（小型卷积网络，权重为10万）： </p><br><p><img src="https://habrastorage.org/webt/ig/hu/x_/ighux_gyoaptm71iu2hk_txga_g.png"></p><br><p> 运行速度受正常波动的影响，并没有太大变化。 对此有一个解释： </p><br><ol><li> 卷积的数量从方便（32、64、128）变为不是最方便的视频卡-27、51等。 在这里，我可能会误会，但很可能会造成影响。 </li><li> 该体系结构不是广泛的，而是一致的。 减小宽度，我们不触摸深度。 因此，我们减少了负载，但不改变速度。 </li></ol><br><p> 因此，改进表示为运行期间CUDA的负载减少了20-30％，而不是运行时间的减少 </p><br><h3 id="itogi"> 总结 </h3><br><p> 反映。 我们考虑了2种修剪选项-YOLOv3（需要手动操作时）和架构更简单的网络。 可以看出，在两种情况下都可以在不损失准确性的情况下实现网络规模的减小和加速。 结果： </p><br><ul><li> 缩小尺寸 </li><li> 运行加速 </li><li>  CUDA负载减少 </li><li> 结果，对环境友好（我们优化了对计算资源的未来使用<a href="https://meduza.io/feature/2019/12/12/kto-takaya-greta-tunberg-i-pochemu-ona-stala-chelovekom-goda-zhurnal-time" rel="nofollow">。GretaTunberg</a>在某处<a href="https://meduza.io/feature/2019/12/12/kto-takaya-greta-tunberg-i-pochemu-ona-stala-chelovekom-goda-zhurnal-time" rel="nofollow">感到</a>高兴） </li></ul><br><h3 id="appendix"> 附录 </h3><br><ul><li> 在修剪步骤之后，您还可以扭曲量化（例如，使用TensorRT） </li><li>  Tensorflow提供了<a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras" rel="nofollow">low_magnitude_pruning的</a>功能。 可以用 </li><li> 我想开发<a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">存储库</a> ，我将很乐意为您提供帮助 </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN482050/">https://habr.com/ru/post/zh-CN482050/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN482032/index.html">我们玩火：我们在开发的iPhone 7上运行任意代码</a></li>
<li><a href="../zh-CN482034/index.html">Yandex：关于用户的一切……</a></li>
<li><a href="../zh-CN482038/index.html">我们正在Haber Career总结2019年的结果</a></li>
<li><a href="../zh-CN482042/index.html">使用真实示例使用Newtonsoft.Json库。 第二部分</a></li>
<li><a href="../zh-CN482044/index.html">保护Docker映像的10个最佳实践。 第二部分</a></li>
<li><a href="../zh-CN482052/index.html">新年数据集2019：俄语开放色调词典</a></li>
<li><a href="../zh-CN482054/index.html">3.弹性堆栈：安全日志分析。 仪表板</a></li>
<li><a href="../zh-CN482058/index.html">捕食者还是猎物？ 谁来保护证书颁发机构</a></li>
<li><a href="../zh-CN482060/index.html">访问控制授权模型（MAC）：概述和应用程序应用</a></li>
<li><a href="../zh-CN482064/index.html">轻松在CMS Umbraco 8上开发多语言站点</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤾🏾 🙎 🐭 Classification de la couverture terrestre à l'aide de l'eo-learn. 2e partie 🧑🏾‍🤝‍🧑🏼 🤨 ◻️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Partie 1 
 3e partie 


 Passer des données aux résultats sans quitter votre ordinateur 



 Une pile d'images d'une petite zone en Slovénie, et une c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Classification de la couverture terrestre à l'aide de l'eo-learn. 2e partie</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452378/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">3e partie</a> </p><br><p>  Passer des données aux résultats sans quitter votre ordinateur </p><br><p><img src="https://habrastorage.org/webt/hq/kv/ie/hqkviehem-itsqlacwosv2hjdco.png"><br>  <em>Une pile d'images d'une petite zone en Slovénie, et une carte avec une couverture terrestre classée obtenue en utilisant les méthodes décrites dans l'article.</em> </p><a name="habracut"></a><br><h2 id="predislovie">  Préface </h2><br><p>  La deuxième partie d'une série d'articles sur la classification de la couverture terrestre à l'aide de la bibliothèque eo-learn.  Nous vous rappelons que le premier article a démontré ce qui suit: </p><br><ul><li>  Diviser AOI (zone d'intérêt) en fragments appelés EOPatch </li><li>  Réception d'images et de masques de nuages ​​provenant des satellites Sentinel-2 </li><li>  Calcul d'informations supplémentaires telles que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NDWI</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NDVI</a> </li><li>  Créer un masque de référence et l'ajouter aux données source </li></ul><br><p>  De plus, nous avons mené une étude de surface des données, ce qui est une étape extrêmement importante avant de commencer une plongée dans l'apprentissage automatique.  Les tâches ci-dessus ont été complétées par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un exemple sous la forme d'un cahier Jupyter</a> , qui contient désormais des éléments de cet article. </p><br><p>  Dans cet article, nous terminerons la préparation des données et construirons également le premier modèle de construction de cartes d'occupation du sol pour la Slovénie en 2017. </p><br><h2 id="podgotovka-dannyh">  Préparation des données </h2><br><p>  La quantité de code directement liée à l'apprentissage automatique est assez faible par rapport au programme complet.  La part du lion du travail consiste à effacer les données, à les manipuler de manière à garantir une utilisation transparente avec le classificateur.  Cette partie du travail sera décrite ci-dessous. </p><br><p><img src="https://habrastorage.org/webt/gd/sj/4i/gdsj4iapqdgkldjwowfx-6p7bgg.jpeg"></p><br><p>  <em>Un diagramme de pipeline d'apprentissage automatique qui montre que le code lui-même en utilisant ML est une petite fraction de l'ensemble du processus.</em>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a></em> </p><br><h3 id="filtraciya-oblachnyh-izobrazheniy">  Filtrage d'images dans le cloud </h3><br><p>  Les nuages ​​sont des entités qui apparaissent généralement à une échelle dépassant notre EOPatch moyen (1000x1000 pixels, résolution 10m).  Cela signifie que tout site peut être complètement couvert de nuages ​​à des dates aléatoires.  Ces images ne contiennent pas d'informations utiles et ne consomment que des ressources, nous les ignorons donc en fonction du rapport des pixels valides au nombre total et fixons un seuil.  Nous pouvons appeler valides tous les pixels qui ne sont pas classés comme des nuages ​​et qui sont situés à l'intérieur d'une image satellite.  Notez également que nous n'utilisons pas les masques fournis avec les images Sentinel-2, car ils sont calculés au niveau des images complètes (la taille de l'image S2 complète est de 10980 × 10980 pixels, environ 110 × 110 km), ce qui signifie que, pour la plupart, il n'est pas nécessaire pour notre AOI.  Pour déterminer les nuages, nous utiliserons l'algorithme du paquet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">s2cloudless</a> pour obtenir un masque de pixels de nuage. </p><br><p>  Dans notre bloc-notes, le seuil est fixé à 0,8, nous sélectionnons donc uniquement les images remplies de données normales à 80%.  Cela peut sembler une valeur assez élevée, mais comme les nuages ​​ne sont pas un problème trop important pour notre AOI, nous pouvons nous le permettre.  Il convient de noter que cette approche ne peut être appliquée sans réfléchir à aucun point de la planète, car la zone que vous avez choisie peut être couverte de nuages ​​pendant une partie importante de l'année. </p><br><h3 id="temporalnaya-interpolyaciya">  Interpolation temporelle </h3><br><p>  En raison du fait que des images peuvent être ignorées à certaines dates, ainsi qu'en raison de dates d'acquisition d'AOI incohérentes, le manque de données est un phénomène très courant dans le domaine de l'observation de la Terre.  Une façon de résoudre ce problème est d'imposer un masque de validité de pixel (à partir de l'étape précédente) et d'interpoler les valeurs pour "remplir les trous".  À la suite du processus d'interpolation, les valeurs de pixels manquantes peuvent être calculées pour créer un EOPatch qui contient des instantanés sur des jours uniformément répartis.  Dans cet exemple, nous avons utilisé l'interpolation linéaire, mais il existe d'autres méthodes, dont certaines sont déjà <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">implémentées</a> dans eo-learn. </p><br><p><img src="https://habrastorage.org/webt/uf/va/ho/ufvahoeiz3u3shfdshioiuommlo.png"><br>  <em>Sur la gauche se trouve une pile d'images Sentinel-2 à partir d'un AOI sélectionné au hasard.</em>  <em>Les pixels transparents signifient des données manquantes en raison des nuages.</em>  <em>L'image de droite montre la pile après interpolation, en tenant compte des masques de nuages.</em> </p><br><p>  Les informations temporelles sont extrêmement importantes dans la classification de la couverture, et encore plus importantes dans la tâche d'identification d'une culture de germination.  Tout cela est dû au fait qu'une grande quantité d'informations sur la couverture terrestre est cachée dans la façon dont la parcelle change tout au long de l'année.  Par exemple, lorsque vous affichez les valeurs NDVI interpolées, vous pouvez voir que les valeurs dans les forêts et les champs atteignent leurs maximums au printemps / été et chutent fortement en automne / hiver, tandis que l'eau et les surfaces artificielles maintiennent ces valeurs à peu près constantes tout au long de l'année.  Les surfaces artificielles ont des valeurs NDVI légèrement plus élevées par rapport à l'eau et répètent partiellement le développement des forêts et des champs, car dans les villes, vous pouvez souvent trouver des parcs et d'autres végétaux.  Vous devez également prendre en compte les limites associées à la résolution des images - souvent dans la zone couverte par un pixel, vous pouvez observer plusieurs types de couverture en même temps. </p><br><p><img src="https://habrastorage.org/webt/cj/mx/8s/cjmx8sdns2mzfv5nq9hko7apno4.png"><br>  <em>Développement temporel des valeurs NDVI pour les pixels de types spécifiques de couverture terrestre tout au long de l'année</em> </p><br><h3 id="otricatelnaya-buferizaciya">  Mise en mémoire tampon négative </h3><br><p>  Bien qu'une résolution d'image de 10 m soit suffisante pour un très large éventail de tâches, les effets secondaires des petits objets sont assez importants.  Ces objets sont situés à la frontière entre différents types de couverture, et ces pixels se voient attribuer les valeurs d'un seul des types.  Pour cette raison, lors de la formation du classificateur, un bruit excessif est présent dans les données d'entrée, ce qui aggrave le résultat.  De plus, des routes et d'autres objets d'une largeur de 1 pixel sont présents sur la carte d'origine, bien qu'ils soient extrêmement difficiles à identifier à partir des images.  Nous appliquons une mise en mémoire tampon négative de 1 pixel à la carte de référence, supprimant presque toutes les zones problématiques de l'entrée. </p><br><p><img src="https://habrastorage.org/webt/-m/u4/ep/-mu4epr9om3nqrmfdeoedefadqi.png"><br>  <em>Carte de référence AOI avant (gauche) et après (droite) mise en mémoire tampon négative</em> </p><br><h3 id="sluchaynyy-vybor-dannyh">  Sélection aléatoire des données </h3><br><p>  Comme mentionné dans un article précédent, l'AOI complet est divisé en environ 300 fragments, chacun composé de ~ 1 million de pixels.  Il s'agit d'une quantité assez impressionnante de ces mêmes pixels, nous prenons donc environ 40 000 pixels pour chaque EOPatch pour obtenir un ensemble de données de 12 millions de copies.  Étant donné que les pixels sont pris uniformément, un grand nombre n'a pas d'importance sur la carte de référence, car ces données sont inconnues (ou ont été perdues après l'étape précédente).  Il est logique de filtrer ces données afin de simplifier la formation du classificateur, car nous n'avons pas besoin de lui apprendre à définir l'étiquette «pas de données».  La même procédure est répétée pour l'ensemble de test, car ces données dégradent artificiellement les indicateurs de qualité des prédictions du classificateur. </p><br><h3 id="razdelenie-i-formirovanie-dannyh">  Séparation et génération de données </h3><br><p> Nous avons divisé les données d'entrée en ensembles de formation / test à un ratio de 80/20%, respectivement, au niveau d'EOPatch, ce qui nous garantit que ces ensembles ne se coupent pas.  Nous divisons également les pixels de l'ensemble pour la formation en ensembles pour les tests et la validation croisée de la même manière.  Après la séparation, nous obtenons un tableau <code>numpy.ndarray</code> de dimension <code>(p,t,w,h,d)</code> , où: <br>  <em><code>p</code> est le nombre d' <code>EOPatch</code> dans l'ensemble de données</em> <em><br></em>  <code>t</code> - le nombre d'images interpolées pour chaque EOPatch <br>  * <code>w, h, d</code> - largeur, hauteur et nombre de couches dans les images, respectivement. </p><br><p>  Après avoir sélectionné les sous-ensembles, la largeur <code>w</code> correspond au nombre de pixels sélectionnés (par exemple, 40 000), tandis que la dimension <code>h</code> est 1. La différence de forme du tableau ne change rien, cette procédure n'est nécessaire que pour simplifier le travail avec les images. </p><br><p>  Les données des capteurs et du masque <code>d</code> dans n'importe quelle image t déterminent les données d'entrée pour la formation, où de telles instances totalisent <code>p*w*h</code> .  Afin de convertir les données en un formulaire digestible pour le classifieur, nous devons réduire la dimension du tableau de 5 à la matrice du formulaire <code>(p*w*h, d*t)</code> .  C'est facile à faire en utilisant le code suivant: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np p, t, w, h, d = features_array.shape <span class="hljs-comment"><span class="hljs-comment">#   t axis   1   3 features_array = np.moveaxis(features_array, 1, 3) #    features_array = features_array.reshape(p*w*h, t*d)</span></span></code> </pre> <br><p>  Une telle procédure permettra de faire une prédiction sur de nouvelles données de même forme, puis de les reconvertir et de les visualiser par des moyens standards. </p><br><h3 id="sozdanie-modeli-dlya-mashinnogo-obucheniya">  Création d'un modèle d'apprentissage automatique </h3><br><p>  Le choix optimal du classificateur dépend fortement de la tâche spécifique, et même avec le bon choix, nous ne devons pas oublier les paramètres d'un modèle spécifique, qui doit être changé d'une tâche à l'autre.  Il est généralement nécessaire de mener de nombreuses expériences avec différents ensembles de paramètres afin de dire avec précision ce qui est nécessaire dans une situation particulière. </p><br><p>  Dans cette série d'articles, nous utilisons le package <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LightGBM</a> , car il s'agit d'un cadre intuitif, rapide, distribué et productif pour la création de modèles basés sur des arbres de décision.  Pour sélectionner des hyperparamètres de classifieur, on peut utiliser différentes approches, telles que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la recherche de grille</a> , qui doivent être testées sur un ensemble de tests.  Par souci de simplicité, nous allons ignorer cette étape et utiliser les paramètres par défaut. </p><br><p><img src="https://habrastorage.org/webt/ik/ds/gr/ikdsgrz5mfdrifwakch1pvv1wey.png"><br>  <em>Le schéma de travail des arbres de décision dans LightGBM.</em>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> </p><br><p>  La mise en œuvre du modèle est assez simple, et puisque les données se présentent déjà sous la forme d'une matrice, nous alimentons simplement ces données à l'entrée du modèle et attendons.  Félicitations!  Maintenant, vous pouvez dire à tout le monde que vous êtes engagé dans l'apprentissage automatique et que vous serez le gars le plus à la mode lors d'une fête, tandis que votre mère sera inquiète de la rébellion des robots et de la mort de l'humanité. </p><br><h2 id="validaciya-modeli">  Validation du modèle </h2><br><p>  La formation de modèles d'apprentissage automatique est facile.  La difficulté est de <strong>bien</strong> les former.  Pour cela, nous avons besoin d'un algorithme adapté, d'une carte de référence fiable et d'une quantité suffisante de ressources informatiques.  Mais même dans ce cas, les résultats peuvent ne pas être ce que vous vouliez, donc vérifier le classificateur avec des matrices d'erreur et d'autres mesures est absolument nécessaire pour au moins une certaine confiance dans les résultats de votre travail. </p><br><h3 id="matrica-oshibok">  Matrice d'erreur </h3><br><p>  Les matrices d'erreur sont les premières choses à considérer lors de l'évaluation de la qualité des classificateurs.  Ils indiquent le nombre d'étiquettes correctement et incorrectement prédites pour chaque étiquette de la carte de référence et vice versa.  Habituellement, une matrice normalisée est utilisée, où toutes les valeurs des lignes sont divisées par le montant total.  Cela montre si le classificateur n'a pas un biais vers un certain type de couverture par rapport à un autre </p><br><p><img src="https://habrastorage.org/webt/rg/3m/xd/rg3mxdktoqpvxy76j_jvfkgpzw4.png"><br>  <em>Deux matrices d'erreur normalisées du modèle entraîné.</em> </p><br><p>  Pour la plupart des classes, le modèle montre de bons résultats.  Pour certaines classes, des erreurs se produisent en raison d'un déséquilibre dans les données d'entrée.  Nous voyons que le problème est, par exemple, les buissons et l'eau, pour lesquels le modèle confond souvent les étiquettes de pixels et les identifie de manière incorrecte.  En revanche, ce qui est marqué comme buisson ou eau correspond assez bien à la carte de référence.  À partir de l'image suivante, nous pouvons remarquer que des problèmes surviennent pour les classes qui ont un petit nombre d'instances de formation - cela est principalement dû à la petite quantité de données dans notre exemple, mais ce problème peut se produire dans n'importe quelle tâche réelle. </p><br><p><img src="https://habrastorage.org/webt/4f/8l/qz/4f8lqz3q4xyxjyp3xp3e9usb_qg.png"></p><br><p>  <em>La fréquence d'apparition des pixels de chaque classe dans l'ensemble d'apprentissage.</em> </p><br><h3 id="reciever-operating-characteristic---roc-krivaya">  Caractéristiques de fonctionnement du récepteur - Courbe ROC </h3><br><p>  Les classificateurs prédisent les étiquettes avec une certaine certitude, mais ce seuil pour une étiquette particulière peut être modifié.  La courbe ROC montre la capacité du classificateur à faire des prédictions correctes lors de la modification du seuil de sensibilité.  Habituellement, ce graphique est utilisé pour <strong>les</strong> systèmes <strong>binaires</strong> , mais il peut être utilisé dans notre cas si nous calculons la caractéristique «étiquette par rapport à toutes les autres» pour chaque classe.  L'axe des abscisses montre des résultats faussement positifs (nous devons minimiser leur nombre), et l'axe des ordonnées montre des résultats vrais positifs (nous devons augmenter leur nombre) à différents seuils.  Un bon classificateur peut être décrit par une courbe sous laquelle l'aire de la courbe est maximale.  Cet indicateur est également connu sous le nom d'aire sous courbe, AUC.  À partir des graphiques des courbes ROC, on peut tirer les mêmes conclusions sur un nombre insuffisant d'exemples de la classe des «buissons», bien que la courbe de l'eau soit bien meilleure - cela est dû au fait que visuellement l'eau est très différente des autres classes, même avec un nombre insuffisant d'exemples dans les données. </p><br><p><img src="https://habrastorage.org/webt/v2/b5/_c/v2b5_cp7omqsxgg9v-bqaqmlk8u.png"><br>  <em>Courbes ROC du classificateur, sous la forme de "un contre tous" pour chaque classe.</em>  <em>Les nombres entre parenthèses sont des valeurs AUC.</em> </p><br><h3 id="vazhnost-priznakov">  L'importance des symptômes </h3><br><p>  Si vous souhaitez approfondir les subtilités du classificateur, vous pouvez consulter le graphique d'importance des fonctionnalités, qui nous indique quels signes ont le plus influencé le résultat final.  Certains algorithmes d'apprentissage automatique, tels que celui que nous avons utilisé dans cet article, renvoient ces valeurs.  Pour les autres modèles, cette métrique doit être considérée par nous-mêmes. </p><br><p><img src="https://habrastorage.org/webt/x9/ui/d6/x9uid68f7bbim-g4nfusppu9cuu.png"><br>  <em>La matrice d'importance des caractéristiques pour le classificateur de l'exemple</em> </p><br><p>  Bien que d'autres signes au printemps (NDVI) soient généralement plus importants, nous voyons qu'il existe une date exacte à laquelle l'un des signes (B2 - bleu) est le plus important.  Si vous regardez les photos, il s'avère que l'AOI pendant cette période était couverte de neige.  On peut conclure que la neige révèle des informations sur la couverture sous-jacente, ce qui aide grandement le classificateur à déterminer le type de surface.  Il convient de rappeler qu'un tel phénomène est spécifique à l'AOI observé et en général, il ne peut être invoqué. </p><br><p><img src="https://habrastorage.org/webt/qv/h1/ak/qvh1ak0bil0qhgt0ax77j0vl1dc.png"><br>  <em>Pièce EOatch AOI 3x3 couverte de neige</em> </p><br><h2 id="rezultaty-predskazaniy">  Résultats de prédiction </h2><br><p>  Après validation, nous comprenons mieux les forces et les faiblesses de notre modèle.  Si nous ne sommes pas satisfaits de la situation actuelle, vous pouvez apporter des modifications au pipeline et réessayer.  Après avoir optimisé le modèle, nous définissons une EOTask simple qui accepte EOPatch et le modèle de classificateur, fait une prédiction et l'applique au fragment. </p><br><p><img src="https://habrastorage.org/webt/bn/d4/8u/bnd48uzm8dp75_2rjgba0enxwlg.png"><br>  <em>Image de Sentinel-2 (à gauche), vérité (au centre) et prédiction (à droite) pour un fragment aléatoire d'AOI.</em>  <em>Vous pouvez remarquer des différences dans les images, qui peuvent s'expliquer par l'utilisation d'une mise en mémoire tampon négative sur la carte d'origine.</em>  <em>En général, le résultat pour cet exemple est satisfaisant.</em> </p><br><p>  La voie à suivre est claire.  Il est nécessaire de répéter la procédure pour tous les fragments.  Vous pouvez même les exporter au format GeoTIFF et les coller à l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gdal_merge.py</a> . </p><br><p>  Nous avons téléchargé GeoTIFF collé sur notre portail GeoPedia, vous pouvez voir les résultats en détail <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> </p><br><p><img src="https://habrastorage.org/webt/mw/gu/jo/mwgujo8q9zai7myheycgaomcwni.png"><br>  <em>Capture d'écran de la prédiction de la couverture terrestre Slovénie 2017 en utilisant l'approche de ce post.</em>  <em>Disponible dans un format interactif sur le lien ci-dessus</em> </p><br><p>  Vous pouvez également comparer les données officielles avec le résultat du classificateur.  Faites attention à la différence entre les concepts d' <em>utilisation</em> des <em>terres</em> et de <em>couverture des sols</em> , que l'on retrouve souvent dans les tâches d'apprentissage automatique - il n'est pas toujours facile de mapper les données des registres officiels aux classes dans la nature.  À titre d'exemple, nous montrons deux aéroports en Slovénie.  Le premier est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Levets, près de la ville de Celje</a> .  Cet aéroport est petit, principalement utilisé pour des jets privés, et est recouvert d'herbe.  Officiellement, le territoire est marqué comme surface artificielle, bien que le classificateur soit capable d'identifier correctement le territoire comme herbe, voir ci-dessous. </p><br><p><img src="https://habrastorage.org/webt/bj/ps/vo/bjpsvoabp90ud12fouuyg1dza3y.png"><br>  <em>Image de Sentinel-2 (à gauche), vraie (au centre) et prédiction (à droite) pour la zone autour du petit aéroport sportif.</em>  <em>Le classificateur définit la piste comme de l'herbe, bien qu'elle soit marquée comme surface artificielle dans les données actuelles.</em> </p><br><p>  En revanche, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans le plus grand aéroport de Slovénie, Ljubljana</a> , les zones marquées comme surface artificielle sur la carte sont des routes.  Dans ce cas, le classificateur distingue les structures, tout en distinguant correctement l'herbe et les champs du territoire voisin. </p><br><p><img src="https://habrastorage.org/webt/bs/oa/c-/bsoac-m7f9jdus4nqh7gl0v8ij0.png"><br>  <em>Image de Sentinel-2 (gauche), vérité (centre) et prédiction (droite) pour la zone autour de Ljubljana.</em>  <em>Le classificateur détermine la piste et les routes, tout en distinguant correctement l'herbe et les champs dans le quartier</em> </p><br><p>  Voila! </p><br><p>  Vous savez maintenant créer un modèle fiable à l'échelle nationale!  N'oubliez pas d'ajouter cela à votre CV. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr452378/">https://habr.com/ru/post/fr452378/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr452366/index.html">Le nouveau capteur CMOS améliore les capacités des objets en mouvement</a></li>
<li><a href="../fr452368/index.html">Quinze petites choses utiles pour la gestion électronique des documents</a></li>
<li><a href="../fr452370/index.html">Comment une imprimante 3D a aidé un adolescent frappé par une bombe à prendre une nouvelle main</a></li>
<li><a href="../fr452372/index.html">Maintenant, les bons développeurs sont mesurés par les vues et les abonnés. C'est mauvais?</a></li>
<li><a href="../fr452376/index.html">La magie des nombres en nombres décimaux</a></li>
<li><a href="../fr452382/index.html">News de la semaine: Autonomous Runet Control Center, 8000 $ bitcoin, vulnérabilité dans les processeurs Intel</a></li>
<li><a href="../fr452384/index.html">Le processeur accélérera l'optique à 800 Gb / s: comment cela fonctionne</a></li>
<li><a href="../fr452388/index.html">Tamis d'Eratosthène au-delà de O (n). Preuve</a></li>
<li><a href="../fr452390/index.html">Radio définie par logiciel - comment ça marche? 3e partie</a></li>
<li><a href="../fr452392/index.html">Une sélection de jeux de données d'apprentissage automatique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
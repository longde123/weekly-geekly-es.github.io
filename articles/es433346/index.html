<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèº üë®üèø‚Äçü§ù‚Äçüë®üèª üëÑ Cambiar de Redshift a ClickHouse üõçÔ∏è üßñüèø ‚ùï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Durante mucho tiempo, iFunny us√≥ Redshift como base de datos para eventos que ocurren en servicios de back-end y aplicaciones m√≥viles. Fue elegido por...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cambiar de Redshift a ClickHouse</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/funcorp/blog/433346/"><img src="https://habrastorage.org/webt/s8/xo/0d/s8xo0dnodxojhff6jufnruyg660.jpeg"><br><br>  Durante mucho tiempo, iFunny us√≥ Redshift como base de datos para eventos que ocurren en servicios de back-end y aplicaciones m√≥viles.  Fue elegido porque en el momento de la implementaci√≥n, en general, no hab√≠a alternativas comparables en costo y conveniencia. <br><br>  Sin embargo, todo cambi√≥ despu√©s del lanzamiento p√∫blico de ClickHouse.  Lo estudiamos durante mucho tiempo, comparamos el costo, estimamos la arquitectura aproximada y, finalmente, este verano decidimos ver qu√© tan √∫til es para nosotros.  En este art√≠culo, aprender√° sobre el problema que Redshift nos ayud√≥ a resolver y c√≥mo trasladamos esta soluci√≥n a ClickHouse. <br><a name="habracut"></a><br><h2>  El problema </h2><br>  iFunny necesitaba un servicio similar a Yandex.Metrica, pero exclusivamente para consumo interno.  Explicar√© por qu√©. <br><br>  Los clientes externos escriben eventos.  Pueden ser aplicaciones m√≥viles, sitios web o servicios internos de back-end.  Es muy dif√≠cil para estos clientes explicar que el servicio de recepci√≥n de eventos no est√° disponible actualmente, "intente enviarlo en 15 minutos o en una hora".  Hay muchos clientes, quieren enviar eventos todo el tiempo y no pueden esperar en absoluto. <br><br>  A diferencia de ellos, hay servicios internos y usuarios que son bastante tolerantes a este respecto: pueden funcionar correctamente incluso con un servicio de an√°lisis inaccesible.  Y la mayor√≠a de las m√©tricas del producto y los resultados de las pruebas A / B generalmente tienen sentido para ver solo una vez al d√≠a, o tal vez incluso con menos frecuencia.  Por lo tanto, los requisitos de lectura son bastante bajos.  En caso de accidente o actualizaci√≥n, podemos permitirnos ser inaccesibles o inconsistentes en la lectura durante varias horas o incluso d√≠as (en un caso particularmente descuidado). <br><br>  Si hablamos de n√∫meros, entonces necesitamos tomar alrededor de cinco mil millones de eventos (300 GB de datos comprimidos) por d√≠a, mientras almacenamos los datos durante tres meses en una forma "activa" disponible para consultas SQL, y en la "fr√≠a" durante dos a√±os. o m√°s, pero para que dentro de unos d√≠as podamos convertirlos en "calientes". <br><br>  B√°sicamente, los datos son una colecci√≥n de eventos ordenados por tiempo.  Hay alrededor de trescientos tipos de eventos, cada uno tiene su propio conjunto de propiedades.  Todav√≠a hay algunos datos de fuentes de terceros que deben sincronizarse con la base de datos anal√≠ticos: por ejemplo, una colecci√≥n de instalaciones de aplicaciones de MongoDB o un servicio externo de AppsFlyer. <br><br>  Resulta que necesitamos unos 40 TB de disco para la base de datos y unos 250 TB para el almacenamiento "en fr√≠o". <br><br><h2>  Soluci√≥n Redshift </h2><br><img src="https://habrastorage.org/webt/f0/nq/dl/f0nqdl7cvriq9ygc3jlhelfdlqi.png"><br><br>  Por lo tanto, hay clientes m√≥viles y servicios de back-end de los cuales necesita recibir eventos.  El servicio HTTP acepta los datos, realiza la validaci√≥n m√≠nima, recopila eventos en el disco local en archivos agrupados por un minuto, los comprime inmediatamente y los env√≠a al dep√≥sito S3.  La disponibilidad de este servicio depende de la disponibilidad de los servidores con la aplicaci√≥n y AWS S3.  Las aplicaciones no almacenan estado, por lo que se equilibran, escalan e intercambian f√°cilmente.  S3 es un servicio de almacenamiento de archivos relativamente simple con una buena reputaci√≥n y disponibilidad, por lo que puede confiar en √©l. <br><br>  A continuaci√≥n, debe entregar de alguna manera los datos a Redshift.  Aqu√≠ todo es bastante simple: Redshift tiene un importador S3 incorporado, que es la forma recomendada de cargar datos.  Por lo tanto, una vez cada 10 minutos, se inicia un script que se conecta a Redshift y le pide que descargue datos utilizando el prefijo <code>s3://events-bucket/main/year=2018/month=10/day=14/10_3*</code> <br><br>  Para monitorear el estado de la tarea de descarga, utilizamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Airflow</a> : le permite repetir la operaci√≥n en caso de errores y tener un historial de ejecuci√≥n claro, lo cual es importante para una gran cantidad de tales tareas.  Y en caso de problemas, puede repetir la descarga durante algunos intervalos de tiempo o descargar los datos "en fr√≠o" de S3 hace un a√±o. <br><br>  En el mismo Airflow, de la misma manera, de acuerdo con el cronograma, los scripts funcionan que se conectan a la base de datos y realizan descargas peri√≥dicas desde repositorios externos, o construyen agregaciones de eventos en forma de <code>INSERT INTO ... SELECT ...</code> <br><br>  Redshift tiene garant√≠as d√©biles de disponibilidad.  Una vez a la semana, durante hasta media hora (la ventana de tiempo se especifica en la configuraci√≥n) AWS puede detener la actualizaci√≥n del cl√∫ster o cualquier otro trabajo programado.  En el caso de una falla en un nodo, el cl√∫ster tampoco estar√° disponible hasta que se restaure el host.  Esto generalmente toma alrededor de 15 minutos y ocurre aproximadamente una vez cada seis meses.  En el sistema actual, esto no es un problema, se dise√±√≥ originalmente para que la base no estuviera disponible peri√≥dicamente. <br><br>  Bajo Redshift, se utilizaron 4 instancias ds2.8xlarge (36 CPU, 16 TB HDD), lo que en total nos da 64 TB de espacio en disco. <br><br>  El √∫ltimo punto es la copia de seguridad.  La programaci√≥n de la copia de seguridad se puede especificar en la configuraci√≥n del cl√∫ster y funciona bien. <br><br><h2>  ClickHouse Transition Motivation </h2><br>  Por supuesto, si no hubiera problemas, nadie hubiera pensado en migrar a ClickHouse.  Sin embargo, lo fueron. <br><br>  Si observa el esquema de almacenamiento ClickHouse con el motor MergeTree y Redshift, puede ver que su ideolog√≠a es muy similar.  Ambas bases de datos son columnares, funcionan bien con una gran cantidad de columnas y comprimen datos en el disco muy bien (y en Redshift puede configurar los tipos de compresi√≥n para cada columna individual).  Incluso los datos se almacenan de la misma manera: se ordenan por clave primaria, lo que le permite leer solo bloques espec√≠ficos y no mantener √≠ndices individuales en la memoria, y esto es importante cuando se trabaja con grandes cantidades de datos. <br><br>  La diferencia esencial, como siempre, est√° en los detalles. <br><br><h3>  Tabla diaria </h3><br>  La ordenaci√≥n de datos en el disco y su eliminaci√≥n en Redshift ocurre cuando usted hace: <pre> <code class="xml hljs">VACUUM <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">tablename</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre>  En este caso, el proceso de vac√≠o funciona con todos los datos de esta tabla.  Si almacena datos de los tres meses en una tabla, este proceso lleva una cantidad indecente de tiempo y debe realizarlo al menos diariamente, porque los datos antiguos se eliminan y se agregan nuevos.  Tuve que crear tablas separadas para cada d√≠a y combinarlas a trav√©s de la Vista, y esto no es solo la dificultad para rotar y apoyar esta Vista, sino tambi√©n ralentizar las consultas.  A petici√≥n, a juzgar por explicar, todas las tablas fueron escaneadas.  Y aunque escanear una tabla lleva menos de un segundo, con una cantidad de 90 piezas, resulta que cualquier consulta lleva al menos un minuto.  Esto no es muy conveniente. <br><br><h3>  Duplicados </h3><br>  El siguiente problema son los duplicados.  De una forma u otra, al transmitir datos a trav√©s de una red, hay dos opciones: perder datos o recibir duplicados.  No pudimos perder mensajes, por lo tanto, simplemente nos reconciliamos con el hecho de que alg√∫n peque√±o porcentaje de eventos se duplicar√≠a.  Puede eliminar duplicados por d√≠a creando una nueva tabla, insertando datos de la anterior en ella, donde al usar la funci√≥n de ventana se eliminan las filas con identificaci√≥n duplicada, la tabla anterior se elimina y la nueva se renombra.  Como hab√≠a una vista en la parte superior de las tablas diarias, era necesario no olvidarse de ella y eliminarla al cambiar el nombre de las tablas.  En este caso, tambi√©n era necesario monitorear los bloqueos, de lo contrario, en el caso de una consulta que bloque√≥ la vista o una de las tablas, este proceso podr√≠a prolongarse durante mucho tiempo. <br><br><h3>  Monitoreo y mantenimiento. </h3><br>  Ni una sola solicitud en Redshift tarda menos de un par de segundos.  Incluso si solo desea agregar un usuario o ver una lista de solicitudes activas, tendr√° que esperar un par de decenas de segundos.  Por supuesto, puede tolerar, y para esta clase de bases de datos esto es aceptable, pero al final se traduce en un mont√≥n de tiempo perdido. <br><br><h3>  Costo </h3><br>  Seg√∫n nuestros c√°lculos, la implementaci√≥n de ClickHouse en instancias de AWS con exactamente los mismos recursos es exactamente la mitad del precio.  Por supuesto, deber√≠a ser as√≠, porque al usar Redshift, obtienes una base de datos preparada a la que puedes conectarte con cualquier cliente PostgreSQL inmediatamente despu√©s de hacer clic en un par de botones en la consola de AWS, y AWS har√° el resto por ti.  ¬øPero vale la pena?  Ya tenemos la infraestructura, parece que podemos hacer copias de seguridad, monitoreo y configuraci√≥n, y lo hacemos para un mont√≥n de servicios internos.  ¬øPor qu√© no abordar el soporte de ClickHouse? <br><br><h2>  Proceso de transici√≥n </h2><br>  Primero, planteamos una peque√±a instalaci√≥n ClickHouse desde una m√°quina, donde comenzamos peri√≥dicamente, utilizando las herramientas integradas, a descargar datos de S3.  Por lo tanto, pudimos probar nuestras suposiciones sobre la velocidad y las capacidades de ClickHouse. <br><br>  Despu√©s de un par de semanas de pruebas en una peque√±a copia de los datos, qued√≥ claro que para reemplazar Redshift con Clickhouse, se tendr√≠an que resolver varios problemas: <br><br><ul><li>  sobre qu√© tipos de instancias y discos para implementar; </li><li>  utilizar la replicaci√≥n? </li><li>  c√≥mo instalar, configurar y ejecutar; </li><li>  c√≥mo hacer el monitoreo; </li><li>  qu√© tipo de esquema ser√°; </li><li>  c√≥mo entregar datos desde S3; </li><li>  ¬øC√≥mo reescribir todas las consultas de SQL est√°ndar a no est√°ndar? </li></ul><br>  <b>Tipos de instancias y discos</b> .  En cuanto a la cantidad de procesadores, disco y memoria, decidieron aprovechar la instalaci√≥n actual de Redshift.  Hubo varias opciones, incluidas las instancias i3 con discos NVMe locales, pero decidi√≥ detenerse en r5.4xlarge y almacenar en forma de 8T ST1 EBS para cada instancia.  Seg√∫n las estimaciones, esto deber√≠a haber dado un rendimiento comparable con Redshift por la mitad del costo.  Al mismo tiempo, debido al uso de discos EBS, obtenemos copias de seguridad y recuperaci√≥n simples a trav√©s de instant√°neas de discos, casi como en Redshift. <br><br>  <b>Replicaci√≥n</b>  Como comenzamos desde lo que ya est√° en Redshift, decidimos no usar la replicaci√≥n.  Adem√°s, esto no nos obliga a estudiar de inmediato ZooKeeper, que a√∫n no se encuentra en la infraestructura, pero es genial que ahora sea posible realizar la replicaci√≥n bajo demanda. <br><br>  <b>Instalaci√≥n</b>  Esta es la parte m√°s f√°cil.  Un rol lo suficientemente peque√±o para Ansible, que instalar√° paquetes RPM preparados y realizar√° la misma configuraci√≥n en cada host. <br><br>  <b>Monitoreo</b>  Para monitorear todos los servicios, Prometheus se usa junto con Telegraf y Grafana, por lo tanto, simplemente ponen agentes de Telegraf en hosts con ClickHouse, recopilan un tablero en Grafana, que muestra la carga actual del servidor por procesador, memoria y discos.  A trav√©s del complemento de Grafana, llevamos a este panel las solicitudes activas actuales para el cl√∫ster, el estado de las importaciones desde S3 y otras cosas √∫tiles.  Result√≥ a√∫n mejor y m√°s informativo (y significativamente m√°s r√°pido) que el tablero que le dio a la consola de AWS. <br><br>  <b>Esquema</b>  Uno de nuestros principales errores en Redshift fue colocar solo los campos del evento principal en columnas separadas y agregar los campos que rara vez se usan para agregar <br>  en una gran columna de propiedades.  Por un lado, esto nos dio flexibilidad para cambiar los campos en las etapas iniciales, cuando no hab√≠a una comprensi√≥n completa de exactamente qu√© eventos recolectar√≠amos, con qu√© propiedades, adem√°s, cambiaban 5 veces al d√≠a.  Y, por otro lado, las solicitudes de una gran columna de propiedades tomaron m√°s y m√°s tiempo.  En ClickHouse, decidimos hacer lo correcto de inmediato, por lo que recopilamos todas las columnas posibles e ingresamos el tipo √≥ptimo para ellas.  El resultado es una tabla con aproximadamente doscientas columnas. <br><br>  La siguiente tarea fue elegir el motor adecuado para el almacenamiento y la partici√≥n. <br>  No pensaron en volver a particionar, pero hicieron lo mismo que en Redshift: una partici√≥n para cada d√≠a, pero ahora todas las particiones son una tabla, que <br>  acelera significativamente las solicitudes y simplifica el mantenimiento.  El motor de almacenamiento fue tomado por ReplacingMergeTree, ya que le permite eliminar duplicados de una partici√≥n particular, simplemente haciendo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OPTIMIZE ... FINAL</a> .  Adem√°s, el esquema de particionamiento diario permite, en caso de errores o accidentes, trabajar solo con datos durante un d√≠a, no un mes, que es mucho m√°s r√°pido. <br><br>  <b>Entrega de datos desde s3 a ClickHouse</b> .  Este fue uno de los procesos m√°s largos.  Simplemente no funcion√≥ haciendo la carga mediante las herramientas ClickHouse incorporadas, porque los datos en S3 est√°n en JSON, cada campo debe extraerse en su propio jsonpath, como lo hicimos en Redshift, y a veces tambi√©n necesitamos usar la transformaci√≥n: por ejemplo, el UUID de un mensaje de un registro est√°ndar en el formulario <code>DD96C92F-3F4D-44C6-BCD3-E25EB26389E9</code> convertir a bytes y poner en tipo FixedString (16). <br><br>  Quer√≠a tener un servicio especial similar al que ten√≠amos en Redshift como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">comando COPY</a> .  No encontraron nada listo, as√≠ que tuve que hacerlo.  Puede escribir un art√≠culo separado sobre c√≥mo funciona, pero en resumen, este es un servicio HTTP implementado en cada host con ClickHouse.  Puedes referirte a cualquiera de ellos.  Los par√°metros de solicitud especifican el prefijo S3 del que se toman los archivos, la lista jsonpath para la conversi√≥n de JSON a un conjunto de columnas, as√≠ como un conjunto de conversiones para cada columna.  El servidor al que lleg√≥ la solicitud comienza a escanear archivos en S3 y a distribuir el trabajo de an√°lisis a otros hosts.  Al mismo tiempo, es importante para nosotros que las filas que no se pudieron importar, junto con el error, se agreguen a una tabla de ClickHouse separada.  Esto ayuda mucho a investigar problemas y errores en el evento que recibe el servicio y los clientes que generan estos eventos.  Con la ubicaci√≥n del importador directamente en los hosts de la base de datos, utilizamos esos recursos, que, por regla general, est√°n inactivos, porque las solicitudes complejas no funcionan las 24 horas.  Por supuesto, si hay m√°s solicitudes, siempre puede tomar el servicio del importador para separar los hosts. <br><br>  No hubo grandes problemas con la importaci√≥n de datos de fuentes externas.  En esos scripts que estaban, simplemente cambiaron el destino de Redshift a ClickHouse. <br><br>  Hab√≠a una opci√≥n para conectar MongoDB en forma de diccionario y no hacer copias diarias.  Desafortunadamente, no encaja, porque el diccionario debe colocarse en la memoria, y el tama√±o de la mayor√≠a de las colecciones en MongoDB no lo permite.  Pero los diccionarios tambi√©n nos fueron √∫tiles: usarlos es muy conveniente para conectar bases de datos GeoIP de MaxMind y usar en consultas.  Para esto, utilizamos los archivos de dise√±o ip_trie y CSV que proporciona el servicio.  Por ejemplo, la configuraci√≥n del diccionario geoip_asn_blocks_ipv4 se ve as√≠: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">dictionaries</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">dictionary</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>geoip_asn_blocks_ipv4<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">source</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">file</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">path</span></span></span><span class="hljs-tag">&gt;</span></span>GeoLite2-ASN-Blocks-IPv4.csv<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">path</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">format</span></span></span><span class="hljs-tag">&gt;</span></span>CSVWithNames<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">format</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">file</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">\</span></span></span><span class="hljs-tag">/</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">source</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">lifetime</span></span></span><span class="hljs-tag">&gt;</span></span>300<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">lifetime</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">layout</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ip_trie</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">layout</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">structure</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">key</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>prefix<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span>String<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">key</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>autonomous_system_number<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span>UInt32<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">null_value</span></span></span><span class="hljs-tag">&gt;</span></span>0<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">null_value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>autonomous_system_organization<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span>String<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">null_value</span></span></span><span class="hljs-tag">&gt;</span></span>?<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">null_value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">structure</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">dictionary</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">dictionaries</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br>  Es suficiente poner esta configuraci√≥n en <code>/etc/clickhouse-server/geoip_asn_blocks_ipv4_dictionary.xml</code> , despu√©s de lo cual puede hacer consultas al diccionario para obtener el nombre del proveedor por direcci√≥n IP: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> dictGetString(<span class="hljs-string"><span class="hljs-string">'geoip_asn_blocks_ipv4'</span></span>, <span class="hljs-string"><span class="hljs-string">'autonomous_system_organization'</span></span>, tuple(IPv4StringToNum(<span class="hljs-string"><span class="hljs-string">'192.168.1.1'</span></span>)));</code> </pre><br>  <b>Cambiar esquema de datos</b> .  Como se mencion√≥ anteriormente, decidimos no usar la replicaci√≥n todav√≠a, ya que ahora podemos permitirnos quedar inaccesibles en caso de accidentes o trabajo planificado, y una copia de los datos ya est√° en s3 y podemos transferirla a ClickHouse en un per√≠odo de tiempo razonable.  Si no hay replicaci√≥n, entonces no expandieron ZooKeeper, y la ausencia de ZooKeeper tambi√©n conduce a la imposibilidad de usar la expresi√≥n ON CLUSTER en consultas DDL.  Este problema fue resuelto por un peque√±o script de Python que se conecta a cada host ClickHouse (solo hay ocho de ellos hasta ahora) y ejecuta la consulta SQL especificada. <br><br>  <b>Soporte de SQL incompleto en ClickHouse</b> .  El proceso de transferencia de solicitudes de la sintaxis Redshift a la sintaxis ClickHouse fue paralela al desarrollo del importador, y fue tratado principalmente por un equipo de analistas.  Curiosamente, pero el asunto ni siquiera estaba en JOIN, sino en las funciones de la ventana.  Para entender c√≥mo se pueden hacer a trav√©s de matrices y funciones lambda, tom√≥ varios d√≠as.  Es bueno que este problema a menudo est√© cubierto en informes sobre ClickHouse, de los cuales hay una gran cantidad, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">events.yandex.ru/lib/talks/5420</a> .  En este punto, los datos ya se escribieron a la vez en dos lugares: tanto en Redshift como en el nuevo ClickHouse, por lo que cuando transferimos las solicitudes, comparamos los resultados.  Fue problem√°tico comparar la velocidad, ya que eliminamos una gran columna de propiedades, y la mayor√≠a de las consultas comenzaron a funcionar solo con las columnas necesarias, lo que, por supuesto, dio un aumento significativo, pero aquellas consultas en las que la columna de propiedades no particip√≥, funcionaron de la misma manera o un poco m√°s r√°pido. <br><br>  Como resultado, obtuvimos el siguiente esquema: <br><br><img src="https://habrastorage.org/webt/tj/h8/ka/tjh8kagqccdbjgnswbmbm9wkloc.png"><br><br><h2>  Resultados </h2><br>  En el resultado final, obtuvimos los siguientes beneficios: <br><br><ul><li>  Una mesa en lugar de 90 </li><li>  Las solicitudes de servicio se ejecutan en milisegundos. </li><li>  El costo se ha reducido a la mitad </li><li>  F√°cil eliminaci√≥n de eventos duplicados </li></ul><br>  Tambi√©n hay desventajas para las que estamos preparados: <br><br><ul><li>  En caso de accidente, deber√° reparar el cl√∫ster usted mismo. </li><li>  Los cambios de esquema ahora deben hacerse en cada host por separado </li><li>  La actualizaci√≥n a nuevas versiones tendr√° que hacerlo usted mismo. </li></ul><br>  No podemos comparar la velocidad de las solicitudes de frente, ya que el esquema de datos ha cambiado significativamente.  Muchas consultas se han vuelto m√°s r√°pidas, simplemente porque leen menos datos del disco.  En el buen sentido, dicho cambio tuvo que hacerse de nuevo en Redshift, pero se decidi√≥ combinarlo con la migraci√≥n a ClickHouse. <br><br>  Toda la migraci√≥n junto con la preparaci√≥n tom√≥ alrededor de tres meses.  Camin√≥ desde principios de julio hasta finales de septiembre y exigi√≥ la participaci√≥n de dos personas.  27 de septiembre, apagamos Redshift y desde entonces hemos estado trabajando solo en ClickHouse.  Resulta que ya hace poco m√°s de dos meses.  El t√©rmino es corto, pero hasta ahora nunca ha encontrado una p√©rdida de datos o un error cr√≠tico, por lo que todo el cl√∫ster se levantar√≠a.  ¬°Delante de nosotros estamos esperando actualizaciones sobre nuevas versiones! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es433346/">https://habr.com/ru/post/es433346/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es433336/index.html">La implementaci√≥n de la biblioteca babil√≥nica</a></li>
<li><a href="../es433338/index.html">Descripci√≥n general del fabricante de la impresora 3D Creality</a></li>
<li><a href="../es433340/index.html">Dispositivos inal√°mbricos Xiaomi en el hogar inteligente ioBroker</a></li>
<li><a href="../es433342/index.html">Otro procesador simple de Verilog</a></li>
<li><a href="../es433344/index.html">Dos √©xitos del espacio privado.</a></li>
<li><a href="../es433348/index.html">DSL mecanografiado en TypeScript de JSX</a></li>
<li><a href="../es433350/index.html">Eventos digitales en Mosc√∫ del 17 al 23 de diciembre.</a></li>
<li><a href="../es433352/index.html">El resumen de materiales frescos del mundo de la interfaz para la √∫ltima semana No. 343 (10-16 de diciembre de 2018)</a></li>
<li><a href="../es433354/index.html">Noticias del mundo de OpenStreetMap No. 438 (04/12/2018 - 12/10/2018)</a></li>
<li><a href="../es433356/index.html">Los atacantes aprendieron a evitar la autenticaci√≥n de dos factores Yahoo Mail y Gmail</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
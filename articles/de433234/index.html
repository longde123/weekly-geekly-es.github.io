<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤘🏽 👩🏾 👦🏻 Ein perfektes Kindermädchen ist erforderlich; Stellen Sie sicher, dass Sie einen KI-Scan durchführen, um Respekt und gute Manieren zu beurteilen 📨 🧥 😟</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jesse Bataglia hält ihren Sohn Bennett in ihrem Haus in Ranch Mirage, Kalifornien. Auf der Suche nach einem neuen Kindermädchen nutzte Batalha Predict...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ein perfektes Kindermädchen ist erforderlich; Stellen Sie sicher, dass Sie einen KI-Scan durchführen, um Respekt und gute Manieren zu beurteilen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433234/"><img src="https://habrastorage.org/getpro/habr/post_images/f66/b54/f11/f66b54f11195b63ced7f2f39d53ac446.jpg"><br>  <i>Jesse Bataglia hält ihren Sohn Bennett in ihrem Haus in Ranch Mirage, Kalifornien.</i>  <i>Auf der Suche nach einem neuen Kindermädchen nutzte Batalha Predictim, einen Onlinedienst, der angeblich „fortgeschrittene künstliche Intelligenz“ verwendet, um das Risiko zu bewerten, dass das Kindermädchen drogenabhängig wird, sich aggressiv verhält oder „schlechte Manieren“ zeigt.</i> <br><br>  Als Jesse Bataglia begann, nach einem neuen Kindermädchen für ihren einjährigen Sohn zu suchen, wollte sie mehr Informationen über den Angestellten erhalten als das Fehlen eines Strafregisters, Kommentare der Eltern und persönliche Interviews.  Aus diesem Grund wandte sie sich an den Onlinedienst Predictim, um mithilfe der „fortgeschrittenen künstlichen Intelligenz“ die Identität des Kindermädchens zu bewerten, und schickte seine Scanner an Tausende von Posts auf Facebook, Twitter und Instagram eines der Kandidaten. <br><br>  Das System führte eine automatische "Risikobewertung" eines 24-jährigen Mädchens ein und behauptete, das Risiko des Konsums ihrer Medikamente sei "sehr gering".  Das System bewertete das Risiko von Einschüchterung, Aggression, Respektlosigkeit und schlechten Manieren jedoch etwas höher - um 2 von 5. <br><a name="habracut"></a><br>  Das System erklärt seine Entscheidungen nicht.  Bataglia, die das Kindermädchen für absolut vertrauenswürdig hielt, begann plötzlich zu zweifeln.  "Social Media zeigt die Identität einer Person", sagte der 29-jährige Bataglia, der in einem Vorort von Los Angeles lebt.  "Warum ist die Punktzahl 2, nicht 1?" <br><br>  Predictim bietet Eltern dieselben Dienstleistungen, die Dutzende anderer Technologieunternehmen an Arbeitgeber auf der ganzen Welt verkaufen: KI-Systeme, die menschliche Sprache, Mimik und Online-Präsenz analysieren und gleichzeitig versprechen, die geheimen Aspekte ihres persönlichen Lebens aufzudecken. <br><br>  Die Technologie verändert die Art und Weise, wie einige Unternehmen nach Kandidaten suchen, Arbeitnehmer einstellen und bewerten, und bietet Arbeitgebern eine konkurrenzlose Bewertung von Kandidaten durch eine neue Welle invasiver psychologischer Bewertungen und Überwachung. <br><br>  Fama behauptet, dass sie KI verwenden, um die sozialen Netzwerke der Arbeiter auf „toxisches Verhalten“ zu überwachen, um ihre Chefs zu alarmieren.  HireVue, ein Rekrutierungstechnologiefirma, das mit Unternehmen wie Geico, Hilton und Unilever zusammenarbeitet, bietet ein System an, das den Ton, die Wortwahl und die Mimik des Kandidaten während eines Videointerviews automatisch analysiert und seine Fähigkeiten und Manieren vorhersagt (um bessere Ergebnisse zu erzielen, werden Kandidaten mehr angeboten lächeln). <br><br>  Kritiker argumentieren jedoch, dass Systeme wie Predictim eine Gefahr für sich selbst darstellen und automatische Lösungen hinterlassen, die das Leben eines Menschen ohne Überprüfung verändern können. <br><br>  Systeme hängen von Black-Box-basierten Algorithmen ab, die fast keine Details darüber liefern, wie sie alle komplexen Details des Innenlebens einer Person auf die Berechnung ihrer positiven und negativen Seiten reduziert haben.  Und obwohl die Predictim-Technologie das Denken der Eltern beeinflusst, bleibt sie völlig unbewiesen, fast ungeklärt und anfällig für Wahrnehmungsverzerrungen in Bezug darauf, wie genau sich das richtige Kindermädchen in sozialen Netzwerken verhalten, aussehen und sprechen sollte. <br><br>  Es gibt "ein verrücktes Rennen, um die Kontrolle über die KI zu übernehmen und alle Arten von Entscheidungen zu treffen, ohne den Menschen Bericht zu erstatten", sagte Jeff Chester, Executive Director des Center for Digital Democracy, einer Technologie-Interessenvertretung.  "Es scheint, als hätten sich die Leute mit digitalem Soda betrunken, und sie denken, es ist eine normale Art, unser Leben zu verwalten." <br><br>  Der Predictim-Scanprozess analysiert das gesamte Verhalten von Kindermädchen in sozialen Netzwerken, die für viele der jüngsten Kindermädchen den größten Teil ihres Lebens erfassen können.  Gleichzeitig wird den Kindermädchen mitgeteilt, dass dies ein schwerwiegender Nachteil im Wettbewerb um Arbeitsplätze ist, wenn sie sich weigern, sich einem solchen Scan zu unterziehen. <br><br>  Sal Parsa, CEO und Mitbegründer von Predictim, sagte, das Unternehmen, das im vergangenen Monat im Rahmen des Berkeley-Technologie-Inkubators der SkyDeck University of California gegründet wurde, nehme die ethischen Fragen des Einsatzes seiner Technologie ernst.  Er sagte, dass Eltern die Bewertung als Berater betrachten sollten, was „vielleicht die wirklichen Eigenschaften des Kindermädchens widerspiegelt und vielleicht nicht widerspiegelt“. <br><br>  Er fügte hinzu, dass die Gefahr, ein problematisches oder gewalttätiges Kindermädchen einzustellen, die KI zu einem wesentlichen Instrument für jeden Elternteil macht, der versucht, sein Kind in Sicherheit zu bringen. <br><br>  "Durchsuchen Sie Google nach Missbrauch von Babysittern und Sie werden Hunderte von Ergebnissen finden", sagte er.  - Es gibt Menschen mit psychischen Erkrankungen oder nur wütend.  Unser Ziel ist es, alles in unserer Macht stehende zu tun, um sie aufzuhalten. “ <br><br>  Die Kosten für das Scannen von Predictim beginnen bei 24,99 US-Dollar. Für sie müssen Sie den Namen und die E-Mail-Adresse des potenziellen Kindermädchens angeben und ihre Zustimmung zum umfassenden Zugriff auf ihre Konten in sozialen Netzwerken einholen.  Das Kindermädchen kann dies ablehnen, und dann erhalten die Eltern eine Benachrichtigung darüber, und das Kindermädchen selbst erhält einen Brief, in dem es heißt: "Der Elternteil, der an Ihnen interessiert war, kann Sie erst einstellen, wenn Sie der Anfrage nachkommen." <br><br>  Predictim-Manager geben an, dass sie Algorithmen verwenden, um Sprache und Bilder zu verarbeiten, „Computer Vision“ zu betreiben, Nanny-Beiträge auf Facebook, Twitter und Instagram auszuwerten und nach Hinweisen auf ihr Offline-Leben zu suchen.  Der Bericht wird nur von den Eltern erhalten, die nicht verpflichtet sind, seine Ergebnisse mit dem Kindermädchen zu teilen. <br><br>  Eltern können sich wahrscheinlich selbst öffentliche Nanny-Konten in sozialen Netzwerken ansehen.  Computerberichte versprechen jedoch eine gründliche Einschätzung der Jahre der Online-Aktivitäten, die auf eine einzige Zahl reduziert sind: eine verlockend einfache Lösung für eine fast unmögliche Aufgabe. <br><br>  Risikobewertungen lassen sich in verschiedene Kategorien einteilen, einschließlich offener Inhalte und Drogenmissbrauch.  Das Startup behauptet in der Werbung auch, dass sein System in der Lage ist, andere Merkmale der Persönlichkeit des Kindermädchens zu bewerten, wie Höflichkeit, Fähigkeit, mit anderen zu arbeiten, und „Positivität“. <br><br>  Das Unternehmen hofft, die milliardenschwere Branche des „Outsourcings der elterlichen Verantwortung“ zu revolutionieren, und hat bereits begonnen, Werbung zu schalten, indem es Blogs und Websites für Eltern für „Mütter“ sponsert.  Die Marketingstrategie konzentriert sich auf die erklärte Gelegenheit, Geheimnisse preiszugeben und den „Albtraum eines Elternteils“ zu verhindern. In der Werbung werden Strafsachen angeführt, darunter beispielsweise der Fall einer Kinderpflegerin aus Kentucky, die wegen schwerer Körperverletzung eines acht Monate alten Kindes verurteilt wurde. <br><br>  "Wenn die Eltern dieses von der Krankenschwester betroffenen Mädchens Predictim im Genehmigungsverfahren für Kandidaten verwenden könnten", heißt es in der Marketingerklärung des Unternehmens, "würden sie sie niemals mit ihrem kostbaren Kind allein lassen." <br><br>  Technologieexperten sagen jedoch, dass das System selbst Warnungen ausgibt und dabei auf die Befürchtungen der Eltern zurückgreift, Ergebnisse von Persönlichkeitsscans mit nicht überprüfter Genauigkeit zu verkaufen. <br><br>  Sie werfen auch Fragen auf, wie solche Systeme trainieren und wie anfällig sie für Fehler sind, die sich aus den Unsicherheiten ergeben können, die mit der Nutzung sozialer Netzwerke durch Kindermädchen verbunden sind.  Eltern erhalten nur eine Warnung vor zweifelhaftem Verhalten, ohne bestimmte Sätze, Links oder andere Details, anhand derer sie ihre Entscheidung treffen könnten. <br><br>  Als ein Scan eines Kindermädchens eine Warnung vor einer möglichen Verfolgung von ihrer Seite ausgab, sagte eine aufgeregte Mutter, die diese Einschätzung beantragte, sie könne nicht herausfinden, ob das Programm ein Zitat aus einem alten Film, Lied oder einem anderen Satz bemerkte, den sie für wirklich gefährliche Aussagen hielt . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bd6/adb/3d1/bd6adb3d197ac0a70588ab72e302a29f.jpg"><br>  <i>Jesses Telefon zeigt die Ergebnisse der Predictim-Anwendung</i> <br><br>  Jamie Williams, ein Anwalt der Electronic Frontier Foundation, einer Bürgerrechtsgruppe, sagte, dass in Bezug auf die meisten Algorithmen, die heute zur Bewertung der Bedeutung von Wörtern und Fotografien verwendet werden, bekannt ist, dass ihnen ein menschlicher Kontext und ein gesunder Menschenverstand fehlen.  Selbst Technologiegiganten wie Facebook hatten Schwierigkeiten, Algorithmen zu entwickeln, die zwischen harmlosen und wütenden Kommentaren unterscheiden konnten. <br><br>  „Wie kann man dieses System zur Bewertung von Jugendlichen ausprobieren: Sie sind Kinder!  - sagte Williams.  - Kinder haben ihre eigenen Witze, sie sind berühmt für Sarkasmus.  "Was eine Person von dem Algorithmus als" schlechte Manieren "hält, kann als politische Aussage oder legitime Kritik angesehen werden." <br><br>  Und wenn das System falsch ist - sagen wir mal, dass das Kindermädchen Drogen missbraucht - können die Eltern den Fehler nicht herausfinden.  Klare Bewertungen und Einschätzungen der Genauigkeit des Systems können dazu führen, dass Eltern viel mehr Genauigkeit und Autoritarismus von ihm erwarten, als eine Person an seiner Stelle versprechen könnte.  Infolgedessen neigen Eltern dazu, Kindermädchen einzustellen, die sie sonst meiden würden, oder sich von Menschen zu entfernen, die ihr Vertrauen bereits verdient haben. <br><br>  "Es gibt keine Metrik, die genau sagen kann, ob diese Methoden in ihren Vorhersagen so effektiv sind wie die Aussagen der Entwickler", sagte Miranda Bogen, Chefanalystin am Upturn Washington Think Tank, der die Verwendung von Algorithmen für die automatische Entscheidungsfindung und Beurteilung untersucht .  "Die Attraktivität dieser Technologien wird wahrscheinlich ihre tatsächlichen Fähigkeiten übertreffen." <br><br>  Malissa Nielsen, eine 24-jährige Nanny, die für Bataglia arbeitet, hat kürzlich zwei anderen Familien Zugang zu ihren sozialen Netzwerken zur Bewertung bei Predictim gewährt.  Sie sagte, dass sie in Bezug auf soziale Netzwerke immer vorsichtig sei und beschloss, zusätzliche Informationen weiterzugeben, ohne sich selbst zu verletzen.  Sie geht wöchentlich in die Kirche, schwört nicht und beendet die Lehrerausbildung im Bereich des Unterrichts von kleinen Kindern. Danach hofft sie, einen Kindergarten zu eröffnen. <br><br>  Als sie jedoch erfuhr, dass das System ihr aufgrund von Respektlosigkeit und Mobbing keine idealen Noten verlieh, war sie erstaunt.  Sie glaubte, dass es Eltern erlaubt sei, ihre Präsenz in sozialen Netzwerken und nicht den Algorithmus zu untersuchen - eine kritische Analyse ihrer Persönlichkeit.  Sie wurde auch nicht über die Ergebnisse eines Tests informiert, der möglicherweise ihre einzige Einnahmequelle schädigen könnte. <br><br>  „Ich möchte dieses Problem ein wenig verstehen.  Warum hat dieses Programm so über mich gedacht?  - sagte Nielsen.  "Der Computer hat keine Gefühle; er kann das alles nicht erkennen." <br><br>  Die Amerikaner vertrauen immer noch nicht den Algorithmen, deren Entscheidungen ihr tägliches Leben beeinflussen können.  In einer Umfrage des Pew Research Center in diesem Monat bewerteten 57% der Befragten die automatische Verarbeitung von Lebensläufen für Bewerber als "inakzeptabel". <br><br>  Predictim berichtet jedoch, dass sie sich darauf vorbereiten, die Arbeit im ganzen Land auszuweiten.  Die Manager von Sittercity, einem Online-Babysitter-Service, der von Millionen von Eltern besucht wird, sprechen über den Start eines Pilotprogramms, das die automatischen Bewertungen von Predictim in die aktuellen automatischen Bewertungen und Serviceprüfungen integriert. <br><br>  "Die Suche nach einem Kindermädchen ist mit Unsicherheiten behaftet", sagte Sandra Dainora, Produktleiterin bei Sittercity, die glaubt, dass solche Tools bald zum Standard bei der Online-Suche nach Betreuern werden können.  "Eltern sind ständig auf der Suche nach der besten Lösung, der vollständigsten Forschung, den zuverlässigsten Fakten." <br><br>  Predictim-Manager glauben auch, dass sie die Fähigkeiten des Systems ernsthaft erweitern und noch persönlichere Einschätzungen des Privatlebens der Nanny anbieten können.  Joel Simonov, Technologiedirektor, sagte, das Team sei daran interessiert, „nützliche psychometrische Daten“ zu erhalten, die auf der Analyse der Aktivität von Kindermädchen in sozialen Netzwerken basieren, und ihre Geschichten einem Identitätstest zu unterziehen, beispielsweise der Myers-Briggs-Typologie, um diese Ergebnisse den Eltern zur Verfügung zu stellen. <br><br>  Social Media Mining und Predictims Interesse an massenpsychologischen Analysen ähneln den Ambitionen von Cambridge Analytica, einem politischen Beratungsunternehmen, das Trumps Wahlkampf unterstützte und Facebook in einen globalen Identitätsskandal verwickelte.  Die Verantwortlichen von Predictim behaupten jedoch, interne Sicherheitskontrollen eingerichtet zu haben und arbeiten daran, die persönlichen Daten der Kindermädchen zu schützen.  "Wenn wir ein Datenleck bei einem Kindermädchen hätten, wäre das nicht cool", sagte Simonov. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3ab/b4f/8d8/3abb4f8d86161c929e5ff131dfe93935.jpg"><br><br>  Experten befürchten, dass AI-basierte Bewertungssysteme eine Zukunft bedeuten, in der der Erhalt eines Arbeitsplatzes, der nicht unbedingt mit der Kinderbetreuung zusammenhängt, von der Maschine abhängt.  Viele Rekrutierungs- und Rekrutierungsunternehmen erstellen oder investieren bereits in Systeme, die Kandidaten-Lebensläufe in großem Umfang analysieren und automatische Kandidatenbewertungen abgeben können.  Ähnliche KI-Systeme - einschließlich Jigsaw, einem von Google entwickelten Technologie-Inkubator - werden verwendet, um Online-Kommentare auf Belästigung, Bedrohung und Grausamkeit zu verfolgen. <br><br>  Es wurde jedoch bereits mehr als einmal gezeigt, wie Algorithmen zum Auffinden von Mitarbeitern Fehler verbergen, die die Karriere einer Person ruinieren können.  Amazon.com hat die Entwicklung des Einstellungsalgorithmus eingestellt, nachdem festgestellt wurde, dass Frauen unrechtmäßig unterschätzt werden, da die Einstellungshistorie des Unternehmens, die der Tendenz der Technologiebranche folgt, Männer einzustellen, dem System beigebracht hat, männliche Kandidaten zu bevorzugen.  Das Unternehmen sagte, sie hätten dieses Programm nie zur Bewertung von Kandidaten verwendet. <br><br>  Einige KI-Experten glauben, dass solche Systeme Vorurteile in Bezug auf Alter oder Rasse ernsthaft aufblähen können, indem sie beispielsweise wichtige Wörter oder Fotos bestimmter Personengruppen häufiger als andere markieren.  Sie sind auch besorgt, dass Predictim junge Kindermädchen dazu zwingen wird, ihre persönlichen Daten zu teilen, nur um einen Job zu bekommen. <br><br>  Diana Werner, Mutter von zwei Kindern, die in einem Vorort von San Francisco lebt, ist jedoch der Ansicht, dass Kindermädchen freiwillig persönliche Informationen weitergeben sollten, um ihre Eltern zu beruhigen.  "Die Überprüfung der Biografie ist eine gute Sache, aber Predictim untersucht das Thema eingehend und analysiert das Individuum - seinen sozialen und intellektuellen Status", sagte sie.  Wo sie lebt, "werden 100% der Eltern einen solchen Dienst nutzen wollen", fügte sie hinzu.  "Wir alle wollen das perfekte Kindermädchen." </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de433234/">https://habr.com/ru/post/de433234/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de433222/index.html">Lernen von Stickstofflasern - Teil 2: Längsentladungslaser</a></li>
<li><a href="../de433224/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 437 (27.11.2008 - 03.12.2008)</a></li>
<li><a href="../de433226/index.html">Methodik zur Bewertung des Wissens eines Ingenieurs. Der Weg eines Architekten und der Weg eines Experten</a></li>
<li><a href="../de433228/index.html">SamsPcbGuide Teil 8: So erhalten Sie die richtige Wellenform</a></li>
<li><a href="../de433232/index.html">Lyft enthüllt seine Vision eines Interaktionssystems für Fußgänger</a></li>
<li><a href="../de433236/index.html">Der Chef von Google glaubt, dass die Angst vor KI "völlig gerechtfertigt" ist.</a></li>
<li><a href="../de433242/index.html">Giftige Maske</a></li>
<li><a href="../de433246/index.html">Framework: Analyse von DLT-Systemen</a></li>
<li><a href="../de433248/index.html">Analysieren der Speicherforensik mit OtterCTF und Einführung des Volatility Framework</a></li>
<li><a href="../de433250/index.html">OpenVPN mit erweiterter Authentifizierung und Autorisierung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
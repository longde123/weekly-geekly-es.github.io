<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç∂ üôç üÜë [Case Locomizer] Comment acc√©l√©rer le calcul d'une carte thermique de 20 000 fois en deux ans et demi üêΩ ü§±üèæ üë®üèø‚Äçü§ù‚Äçüë®üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cet article est une continuation de la s√©rie Case Locomizer, voir aussi 



- Quelles connaissances peuvent r√©ellement √™tre extraites d'un ensemble de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>[Case Locomizer] Comment acc√©l√©rer le calcul d'une carte thermique de 20 000 fois en deux ans et demi</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485988/"><blockquote>  Cet article est une continuation de la s√©rie Case Locomizer, voir aussi <br><br><ul><li>  <a href="https://habr.com/ru/post/485484">Quelles connaissances peuvent r√©ellement √™tre extraites d'un ensemble de donn√©es anonymis√© avec les coordonn√©es de l'utilisateur</a> </li><li>  Open One Ring - une bo√Æte √† outils pour la configuration flexible de processus de traitement de donn√©es complexes sur Spark dans le cloud (√† venir bient√¥t!) </li></ul></blockquote><br>  Bonjour <br><br><img src="https://habrastorage.org/webt/fj/uo/jz/fjuojzz4hen-a54ybf62phjmlvk.png" alt="FDC: TC, EMR, IDEA" title="FDC: TC, EMR, IDEA"><br><br>  Savez-vous ce qu'est une autopsie?  Ceci est une histoire sur la fa√ßon dont nous sommes arriv√©s √† une telle vie. <br><br>  Je ne suis pas s√ªr de vous, mais j'aime vraiment lire des histoires sur le processus de d√©veloppement de logiciels hautement sp√©cialis√©s ou de bas niveau.  Les coll√®gues peuvent avoir une id√©e int√©ressante avec laquelle travailler, et il est toujours curieux de suivre ce qui s'est pass√© avec le programme du prototype au produit mature, qui fait de la magie dans un domaine inconnu. <br><br>  En outre, si je jette simplement un lien vers un r√©f√©rentiel avec un tel logiciel, il est peu probable que quiconque soit en mesure de savoir ce que c'est et pourquoi, et pour quelles t√¢ches il peut √™tre utile.  M√™me si je traduis de l'anglais trois douzaines de pages d'instructions pour commencer.  N√©anmoins, le framework <a href="https://spark.apache.org/">Spark</a> n'est pas simplement un autre m√©tier sur l'angulaire, il faut comprendre <s>que les</s> auteurs ont <s>fum√©</s> pourquoi il √©tait √©crit de cette fa√ßon et non autrement. <br><br>  Cet article est une introduction historique √† One Ring.  Il n'y a pas de code et l'histoire est plus populaire que scientifique.  Mais seulement sur le d√©veloppement, et sur rien d'autre, √† l'exception de deux ans et demi de d√©veloppement. <br><a name="habracut"></a><br>  La derni√®re fois, j'ai parl√© suffisamment en d√©tail (j'esp√®re assez) des difficult√©s d'extraire des donn√©es √† partir d'ensembles de donn√©es anonymis√©s dans la voie du milieu, et finalement j'ai rattrap√© une intrigue pas faible.  Laissons sa r√©solution pour la derni√®re fois, et aujourd'hui nous parlerons du long et difficile chemin vers la perfection de notre outil principal: <br><br><ul><li>  Les m√©gadonn√©es sont grandes </li><li>  Notre cas n'est pas standard </li><li>  Prototype en C # et PostGIS </li><li>  Premi√®re approche de Hadoop MapReduce </li><li>  L'av√®nement de CI et Spark </li><li>  Troisi√®me approximation √† GeoSpark </li><li>  Analystes japonais et migration d'Azure vers AWS </li><li>  Ash Nazg Durbatuluk, Ash Nazg Gimbatul, Ash Nazg Trakatuluk, Ag Burzum Ishi Krimpatul !! </li><li>  Optimisation et g√©ocatarse avec Uber H3 </li><li>  Dehors tout blanc </li></ul><br><h3>  Les m√©gadonn√©es sont grandes </h3><br>  Le Big Data n'est pas une question de taille. <br><br>  Il peut y avoir des dizaines, voire des centaines de millions d'enregistrements dans un ensemble de donn√©es mensuel dans la r√©gion du Grand Londres, mais ce n'est pas beaucoup.  Une seule it√©ration sur eux du d√©but √† la fin repose sur la vitesse de lecture lin√©aire du disque.  Si le disque est un SSD, cela prendra quelques secondes. <br><br>  (Je vous rappelle que l'ensemble de donn√©es en question est un ensemble de fichiers CSV avec un ensemble de champs sp√©cifiques au fournisseur. Le regroupement des enregistrements avec les coordonn√©es des utilisateurs anonymes dans un fichier se produit le long des fronti√®res de la r√©gion administrative du pays, de la pr√©fecture ou de la ville. Les fichiers eux-m√™mes sont g√©n√©r√©s sur la date s√©lectionn√©e, quotidienne ou <a href="https://habr.com/ru/post/485484">mensuelle.Plus de</a> d√©tails sont tous <a href="https://habr.com/ru/post/485484">d√©crits</a> dans la partie pr√©c√©dente, <a href="https://habr.com/ru/post/485484">ex√©cutez-la en diagonale</a> s'il n'y a pas assez de contexte.) <br><br>  Notre processus est en plusieurs √©tapes.  Les heuristiques initiales d'enrichissement des donn√©es brutes qui fonctionnent uniquement dans un seul mode d'it√©ration sont rapides, et vous pouvez les √©crire au moins en Python, au moins en C ++, m√™me en PHP.  M√™me sur une machine faible, le traitement sera rapide. <br><br>  Si l'ensemble de donn√©es se trouve quelque part dans le cloud, √† condition que le gestionnaire soit plac√© dans le m√™me cloud, il n'y a pas de probl√®me particulier pour y acc√©der, passer en revue et enregistrer le r√©sultat √† c√¥t√© de lui.  De plus, g√©n√©ralement, le fichier est d√©j√† l√†, car les fournisseurs de donn√©es t√©l√©chargeront avec grand plaisir l'archive sur votre stockage cloud, ce qui vous donnera un lien de t√©l√©chargement.  Il ne reste plus qu'√† d√©ployer la machine virtuelle, et toutes les biblioth√®ques pour acc√©der au r√©f√©rentiel seront soigneusement plac√©es par le vendeur dessus, toutes les cl√©s d'acc√®s sont enregistr√©es, il suffit de saisir l'API entre vos mains et de l'utiliser.  Ce sera rapide aussi. <br><br>  Eh bien, avec les premiers pas, tout est clair.  Ils ont pris le fichier, l'ont parcouru plusieurs fois, ont remis la version trait√©e.  Mais que se passe-t-il si les √©tapes suivantes de notre algorithme n√©cessitent un ensemble de calculs l√©g√®rement plus complexes pour chaque enregistrement? <br><br>  Prenez quelque chose comme d√©terminer la distance entre une paire de coordonn√©es.  Il existe une m√©thode <a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine</a> extr√™mement rapide (¬´haversinus¬ª selon la version de la salle), qui donne une pr√©cision acceptable √† courte distance, et permet de ne pas prendre le g√©o√Øde <abbr title="World Geodetic System '84, d√©sormais g√©o√Øde standard">WGS84</abbr> , dont le calcul fonctionne beaucoup plus lentement. <br><br>  En soi, un tel calcul, s'av√®re-t-il, ne co√ªte pas si cher s'il est unique.  Et m√™me s'il y en a des dizaines de millions, c'est, en principe, un non-sens. <br><br>  Et maintenant, nous prenons le cas de notre algorithme brevet√©, lorsque nous devons calculer la distance de chaque signal √† chaque POI de la cat√©gorie s√©lectionn√©e, et rejeter ceux qui sont sup√©rieurs √† un demi-kilom√®tre (une telle distance qui est facile √† parcourir). <br><br>  Pour la r√©gion du Grand Londres, environ un million d'√©tablissements font partie des <abbr title="Point d'int√©r√™t">PI</abbr> cibl√©s dans la cat√©gorie des magasins et des points de vente.  Et comme je l'ai dit, dans les dizaines de jeux de donn√©es mensuels, des centaines de millions d'enregistrements viennent pour lui.  Et nous obtenons donc ... <br><br><h2>  1000000 POI √ó N, 000,000 signaux = N, 000,000,000,000 distances. </h2><br>  Oh, viens.  Des milliers de milliards de calculs de distance et de comparaisons de constantes de seuil. <br><br>  La situation classique avec le <abbr title="Un ensemble dont les √©l√©ments sont tous des paires d'√©l√©ments ordonn√©s possibles des ensembles originaux">produit cart√©sien</abbr> .  Deux ensembles peu puissants individuellement donnent facilement N √ó 10 <sup>12</sup> r√©sultats interm√©diaires, et ce n'est que d'un mois dans une r√©gion!  Un tel montant se transforme d√©j√† en qualit√©.  Non seulement la taille du r√©sultat interm√©diaire est d√©j√† un probl√®me grave, car il ne rentre pas enti√®rement dans la m√©moire, et il est n√©cessaire de le traiter imm√©diatement sur le lieu de r√©ception, mais le nombre de calculs n√©cessaires pour l'obtenir prend trop de temps informatique.  Et si, pour un seul enregistrement, compte tenu de tous les retards de transmission sur le r√©seau et d'autres frais g√©n√©raux, seules 100 nanosecondes sont d√©pens√©es, alors des millions de secondes sont des jours et des semaines de calculs dans un flux. <br><br>  Ou, si nous devons √©liminer un segment de la population g√©n√©rale, par exemple, la condition "ne prend pas en compte les int√©r√™ts des utilisateurs qui vivent dans une certaine zone", alors nous devrons comparer le device_id de chaque enregistrement de l'ensemble de donn√©es enrichi de la r√©gion enti√®re avec un ensemble dans lequel des centaines de milliers d'enregistrements avec exclu les r√©sidents de device_id de cette zone.  Et ce sont des comparaisons de cha√Ænes √† bien des √©gards, pas aussi rapides que pour deux pouces.  Encore une fois, il y a une sorte de nombre insens√© de z√©ros dans l'√©valuation d'une op√©ration simple, et nous les avons pour un ensemble complet d'heuristiques pour un projet moyen avec une douzaine, voire plus. <br><blockquote>  Les m√©gadonn√©es sont des donn√©es qui, en raison de leur taille, rendent n√©cessaire l'utilisation de techniques algorithmiques sp√©ciales en raison de l'inad√©quation ou de l'impraticabilit√© du traitement direct. </blockquote><br>  ... m√™me si le r√©sultat final du calcul s'effondre dans un seul √©cran du tableau Excel. <br><br>  Vous pouvez essayer de parall√©liser le gestionnaire ¬´na√Øf¬ª par le nombre de processeurs virtuels disponibles sur la machine sur laquelle nous effectuons le calcul.  Vous pouvez diviser l'ensemble de donn√©es en morceaux et ex√©cuter le calcul des strass sur une douzaine de machines virtuelles dans le cloud.  Mais tout cela ne donnera pas un r√©sultat qualitativement excellent.  La mise √† l'√©chelle "en largeur" ‚Äã‚Äãdonne <a href="https://ru.wikipedia.org/wiki/%25D0%2597%25D0%25B0%25D0%25BA%25D0%25BE%25D0%25BD_%25D1%2583%25D0%25B1%25D1%258B%25D0%25B2%25D0%25B0%25D1%258E%25D1%2589%25D0%25B5%25D0%25B9_%25D0%25B4%25D0%25BE%25D1%2585%25D0%25BE%25D0%25B4%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D0%25B8">des rendements d√©croissants √†</a> partir d'une certaine largeur.  Et le probl√®me de la synchronisation et du partitionnement sortira certainement, et la gestion de toute une flotte de machines virtuelles co√ªtera du temps et de l'argent.  Les garder allum√©s tout le temps co√ªte cher, et d√©marrer et arr√™ter √† la demande demande beaucoup de travail. <br><br>  Par cons√©quent, pour les m√©gadonn√©es, des syst√®mes logiciels sp√©ciaux de l'√©cosyst√®me Hadoop, qui ont d√©j√† des contr√¥les d'√©chelle, sont utilis√©s, ainsi qu'un ensemble sp√©cial d'algorithmes qui permet au mammouth de manger en petites portions sans risque d'√©touffer la quantit√© astronomique de donn√©es interm√©diaires et simplifie consid√©rablement la vie d'un d√©veloppeur de m√©gadonn√©es.  Mais vous ne pouvez pas simplement utiliser Hadoop et commencer √† l'utiliser.  Vous devez d'abord faire un plan. <br><br>  Surtout si ... <br><br><h3>  Notre cas n'est pas standard </h3><br>  Si vous demandez comment les bureaux impliqu√©s dans l'analyse de grands ensembles de donn√©es construisent leurs processus, il s'av√®re que deux approches principales sont utilis√©es dans la pratique mondiale. <br><br><h4>  Approche num√©ro 1.  Lac de donn√©es </h4><br>  Pour les donn√©es qui s'accumulent au fil du temps et restent pertinentes pour toujours, un type sp√©cial de stockage est con√ßu, le ¬´ <a href="https://habr.com/ru/post/485180/">lac de donn√©es</a> ¬ª. <br><br>  L'architecture de ces r√©f√©rentiels est optimis√©e pour un acc√®s al√©atoire rapide.  De nombreux ensembles de donn√©es collect√©s sont traduits dans un format sp√©cialis√© qui vous permet d'effectuer rapidement des s√©lections multicrit√®res et des tranches par ensembles de colonnes.  Contrairement aux bases de donn√©es relationnelles et documentaires traditionnelles, le stockage en colonnes est utilis√© dans les lacs de donn√©es.  Habituellement, ils sont d√©finitifs, c'est-√†-dire que le format des conteneurs contenant les donn√©es est tel qu'apr√®s remplissage et indexation, les donn√©es du m√™me ensemble de donn√©es ne changent plus jamais.  Par exemple, les fichiers parquet qui ne n√©cessitent pas de modification. <br><br>  Apr√®s cela, une foule de data- <abbr title="scientifique">satanistes</abbr> ou de data- <abbr title="analyste">analystes se</abbr> pr√©cipitent, et dans des logiciels sp√©cialis√©s (¬´ordinateurs portables¬ª comme Jupyter) collectent des statistiques, des indicateurs, etc.  en ligne.  Ces statistiques sont d√©charg√©es du lac quelque part vers l'ext√©rieur, ou simplement ajout√©es ensemble sous la forme des m√™mes fichiers finaux pour une agr√©gation ult√©rieure. <br><br><h4>  Approche num√©ro 2.  Streaming de donn√©es </h4><br>  Pour les donn√©es qui arrivent en temps r√©el et doivent √™tre trait√©es rapidement (c'est-√†-dire les donn√©es en streaming), des bus de donn√©es ou des files d'attente de messages sont con√ßus. <br><br>  Dans une infrastructure avec un bus de donn√©es, il y a des g√©n√©rateurs √† une extr√©mit√© et des consommateurs √† l'autre, et les flux de donn√©es eux-m√™mes sont compos√©s d'√©v√©nements. <br><br>  Des g√©n√©rateurs sont g√©n√©r√©s, et les consommateurs, en temps r√©el ou presque r√©el, analysent les √©v√©nements, accumulant des r√©sultats finaux, qui peuvent √† nouveau g√©n√©rer des √©v√©nements que le prochain ensemble d'agr√©gateurs consommera via le m√™me bus, et ainsi de suite jusqu'√† ce que le r√©sultat final soit obtenu, pli√© dans le r√©f√©rentiel des r√©sultats finaux. <br><br>  Il est pilot√© par Apache Kafka et un stockage rapide comme Aerospike. <br><br><h4>  Notre cas </h4><br>  Mais notre cas ne rentre pas dans ces deux approches. <br><br>  Tout d'abord, cela n'a aucun sens pour nous de conserver un lac de donn√©es, car l'ensemble de donn√©es dure rarement plus d'un an (les pistes utilisateur pour 2016 en 2019 ne sont plus n√©cessaires √† personne), et chaque fois que les clients ont besoin d'une partie compl√®tement impr√©visible de toutes les donn√©es accumul√©es.  De plus, √©tant donn√© que pour chaque segment de la population et de la cat√©gorie, son propre mod√®le est cr√©√©, nous sommes toujours oblig√©s de ne prendre que la pi√®ce requise, et les fusionner dans un lac commun n'a pas beaucoup de sens.  Il est plus facile de conserver chaque jeu de donn√©es mensuel dans sa forme d'origine - les fichiers CSV dans son propre r√©pertoire distinct.  Le chemin d'acc√®s au fichier est obtenu ... / provider / country / region / subregion / year / month / dataset files, et un sous-ensemble est s√©lectionn√© simplement par le masque de nom de fichier, par exemple, ... / Tamoco / UK / Greater_London / * / 2019 / {6, 7.8} / *. Csv. <br><br>  Deuxi√®mement, la nature des ensembles de donn√©es est discr√®te et non en continu.  Bien s√ªr, on pourrait, bien s√ªr, calculer directement certains indicateurs directement dans le processus de t√©l√©chargement sur le stockage du r√©seau, mais les cartes thermiques finies pour la r√©gion de Moscou et la r√©gion voisine de la r√©gion de Moscou ne sont pas en corr√©lation avec la carte thermique finale de la r√©gion combin√©e de Moscou et de la r√©gion ( en raison du fait que trop de personnes vivent dans la r√©gion et travaillent √† Moscou), et nous ne savons toujours pas √† l'avance de quelle r√©gion nous aurons besoin.  Peut-√™tre ni Moscou, ni la r√©gion de Moscou, mais juste une ville 17.  Il est tr√®s co√ªteux de conduire des heuristiques et de calculer des indicateurs pour tous les ensembles de donn√©es. <br><br>  Par cons√©quent, nous devons s√©lectionner rapidement un sous-ensemble des ensembles de donn√©es accumul√©s, d√©ployer rapidement une batterie de serveurs informatique qui convient √† l'alimentation, effectuer rapidement un processus de calcul unique mais standardis√©, cracher le r√©sultat et ... peut-√™tre ne plus jamais revenir √† un sous-ensemble ou √† une batterie de serveurs de cette taille , pas au mod√®le.  Et nous ne pouvons absolument pas conserver un cluster de performances bien r√©gl√© sur notre propre mat√©riel, ce qui couvrirait les besoins de tous nos projets, du plus petit au plus difficile, car ils sont trop diff√©rents. <br><br>  Je ne pense pas que nous soyons si uniques.  Dans les conversations avec des coll√®gues, le besoin d'instrumentation de cas similaires <abbr title="Babah!, Gros boom, flash, √©clatement de mitrailleuse, etc.">√©clat√©s</abbr> appara√Æt r√©guli√®rement, mais ici, chacun construit le processus √† sa mani√®re.  Habituellement, des solutions pour les cas non standard sont attach√©es au convoyeur existant √† partir des approches n ¬∞ 1 ou n ¬∞ 2 sur le c√¥t√©;  notre processus est enti√®rement compos√© de projets priv√©s, nous avons toutes les t√¢ches comme "burst". <br><br>  Et bien maintenant.  Pendant deux ans et un sou, nous avons pu proposer une trousse √† outils pour automatiser autant que possible mon travail, et c'est pr√©cis√©ment cela que je pr√©senterai pour une utilisation g√©n√©rale dans la troisi√®me partie de mon histoire.  En attendant, parlons de l'√©volution, et de toutes ces erreurs et probl√®mes, corrigeant et r√©solvant que nous sommes arriv√©s √† un processus durable par exp√©rience. <br><br><h3>  Prototype en C # et PostGIS </h3><br>  Tout a commenc√© il y a quelques ann√©es.  Deux mecs tr√®s intelligents nomm√©s <a href="https://www.forbes.ru/tehnologii/336439-na-kletochnom-urovne-kak-zarabatyvat-na-sinteze-marketinga-i-biologii">Alexei Polyakov et Alexei Polyakov</a> - ne riez pas, ils sont en fait homonymes, mais de diff√©rentes parties du monde - un biologiste et un sp√©cialiste du marketing, ils ont d√©cid√© d'appliquer la m√©thode de la dissertation sur le comportement collectif des populations cellulaires dans les cultures cellulaires, test√©e exp√©rimentalement sur des souris. , √† la publicit√© et au marketing. <br><br>  Cela a fonctionn√© sur les gens. <br><br>  Et puis le projet Locomizer est n√©.  Je dis ¬´projet¬ª parce que c'est comme une startup avec une <abbr title="Ltd., uniquement √† Londres">LLC</abbr> pour conclure des contrats, mais pas tout √† fait.  Les membres de notre √©quipe sont dispers√©s dans le monde entier, travaillent dans diff√©rents endroits et bureaux en tant que pigistes ou sous-traitants (et pas tous √† temps plein), et nous utilisons nos algorithmes pour des clients tr√®s diff√©rents avec diff√©rents mod√®les d'interaction lorsque nous recevons ou trouvons des commandes.  Il existe des abonnements, mais des t√¢ches ponctuelles plus priv√©es. <br><br>  Mais c'est tout de suite.  Et il y a quelques ann√©es, tout √©tait encore plus chaotique.  Qui a √©crit la premi√®re impl√©mentation logicielle pour calculer la vitesse, je ne sais g√©n√©ralement pas.  (Si vous connaissez soudain ces h√©ros inconnus, dites-leur bonjour.) √Ä la fin de mon dernier <a href="https://habr.com/ru/post/437610/">article</a> sur la carri√®re d'un programmeur dans une ville particuli√®re, j'ai √©crit litt√©ralement ce qui suit: ¬´Je suis venu parler √† l'endroit o√π je travaille maintenant, et PM a d√©clar√© d√®s le seuil que le projet est infernal.  Rien.  Encore une fois, SIG, seuls les calculs sont tous bas√©s sur MapReduce (et je le veux sur Spark), les cartes sur ArcGIS, et tout cela tourne dans des nuages ‚Äã‚Äãque personne ne peut imaginer.  √Ä mon avis, une excellente option! ¬ª- √† ce moment-l√†, c'√©tait d√©j√† comme √ßa, et je ne peux que restaurer la toute premi√®re √©tape du d√©veloppement du projet en code √† partir des souvenirs de <a href="https://habr.com/ru/users/mitra_kun/" class="user_link">mitra_kun</a> , qui lui-m√™me est apparu sur le projet un an plus t√¥t. <br><br>  Les heuristiques rudimentaires pour le traitement des ensembles de donn√©es brutes ont √©t√© √©crites en PHP, Python et C ++, et le calcul principal de la vitesse pour la carte de chaleur a √©t√© effectu√© par un programme en C #. <br><br><img src="https://habrastorage.org/webt/ni/yp/qc/niypqcxxu3ugnbt1mx16ecnuhds.png" alt="L'ensemble du projet en C #" title="L'ensemble du projet en C #" align="right"><br><br>  Elle a travaill√© comme √ßa: <br><br><ol><li>  Tout d'abord, nous lisons directement la cha√Æne dans le tableau √† partir du fichier d'ensemble de donn√©es. </li><li>  Ex√©cutez-le foreach'em, cr√©ez une table de hachage sur polzakz. </li><li>  La base POI est une table litt√©rale dans une base de donn√©es PostgreSQL avec des champs PostGIS de type GEOMETRY, et pour calculer la distance entre chaque signal utilisateur et chaque POI, la fonction ST_DISTANCE est <a href="https://postgis.net/docs/ST_Distance.html">tir√©e √†</a> travers un petit <a href="https://postgis.net/docs/ST_Distance.html">stockage</a> , le r√©sultat est ajout√© √† une table de hachage avec une cl√© pour chaque utilisateur. </li><li>  Ensuite, nous proc√©dons √† chacun sur la table avec l'accumulation du r√©sultat du score d'int√©r√™t pour chaque cl√© du tableau. </li><li>  Encore une fois, groupe, pour chaque cat√©gorie. </li><li>  Apr√®s la fin du calcul, qui prend enti√®rement de quelques heures √† une semaine, le r√©sultat est ajout√© au fichier CSV ... </li><li>  ... puis trait√©es manuellement, superpos√©es √† la carte et visualis√©es dans <a href="https://desktop.arcgis.com/ru/">ArcGIS</a> . </li></ol><br>  Il est clair que le volume maximum trait√© est limit√© par la m√©moire disponible sur la machine, et la vitesse des requ√™tes uniques vers la base de donn√©es provoque une certaine alarme. <br><br><h3>  Premi√®re approche de Hadoop MapReduce </h3><br>  Quelque chose a √©t√© calcul√© sur le prototype local, la pertinence des traitements appliqu√©s pour la pr√©paration des jeux de donn√©es et la construction des cartes thermiques a √©t√© test√©e, et la question s'est pos√©e de savoir comment mettre les travaux en service.  Eh bien, il est important de ne pas traiter le coucher de soleil manuellement, mais d'utiliser les capacit√©s de certaines plates-formes, de pr√©f√©rence √©crites par les baleines de l'industrie, et d'√©voluer au moins au minimum. <br><br>  Comme je l'ai dit, la plate-forme standard de traitement des m√©gadonn√©es est l'√©cosyst√®me Hadoop.  Un large √©ventail de biblioth√®ques h√©t√©rog√®nes, y compris un syst√®me de fichiers distribu√©, des shedulers pour les t√¢ches de parall√©lisation, des abstractions relativement pratiques sur la r√©duction de carte, des moteurs pour ex√©cuter des requ√™tes et m√™me un tas de choses pour l'analyse des donn√©es.  Et toute cette infrastructure logicielle est disponible dans les nuages ‚Äã‚Äãaupr√®s de diff√©rents fournisseurs sous la forme de packages int√©gr√©s, et elle sera automatis√©e, mais plus √† ce sujet plus tard. <br><br>  Ok Google, recherche Hadoop.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mes pr√©d√©cesseurs ont pris le prototype et r√©√©crit le calcul principal de C # en Java, rempla√ßant litt√©ralement tous foreach par le mappeur et r√©ducteur Hadup correspondant, et ont pris toutes les mesures pour pr√©parer et enrichir des ensembles de donn√©es dans des utilitaires s√©par√©s dans des langages de script pour se d√©velopper plus rapidement, car avec l'av√®nement de diff√©rents les algorithmes clients ont commenc√© √† √©voluer activement. Nous avons commenc√© √† √©crire s√©par√©ment le backend pour l'interface utilisateur Web au printemps (ce n'est pas la meilleure solution, s'il n'y a pas d'exp√©rience de d√©veloppement Java pr√©c√©dente, il serait pr√©f√©rable d'√©crire en PHP), avec un front sur Node.js avec l'int√©gration de cartes d'ArcGIS. </font></font><br><br><img src="https://habrastorage.org/webt/oq/i3/ye/oqi3yehxn8ybmjbh0j1g0f4sqj4.png" alt="Une petite partie d'un projet Java" title="Une petite partie d'un projet Java" align="left"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ils ont soulev√© le ¬´grand cluster¬ª de Hadoop sur cinq machines virtuelles dans Microsoft Azure pour ce cas. Pourquoi Azure Premi√®rement, pour les startups, il y a une grande remise pour les premi√®res ann√©es. Deuxi√®mement, ArcGIS Desktop pour Windows pour la visualisation des cartes √©tait d√©j√† d√©ploy√© dans ce cloud.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le cluster Hadoop a √©t√© d√©ploy√© manuellement, et non √† partir du service Azure HDInsight correspondant, qui √©tait difficile √† configurer. Sur chacune des machines du cluster, ils ont soulev√© Postgre + PostGIS (une d√©cision plut√¥t douteuse, car MR et la base commencent √† se battre pour le processeur) afin de ne pas parcourir de distances vers un serveur s√©par√©. Nous avons fait un petit script qui a dispers√© des r√©pliques de la base de donn√©es POI √† travers les n≈ìuds du cluster. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le projet √©tait encore un prototype, juste un peu plus avanc√©. PostGIS √©tait toujours utilis√© parce que le geofencing est apparu, et les gars ne savaient pas encore comment le mettre en ≈ìuvre avec un minimum de travail. C'√©tait comme si tout √©tait terriblement lent, et le nombre d'√©tapes √† effectuer manuellement d√©passait une douzaine et demie.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C'est √† ce moment que je me suis int√©ress√© √† une proposition d'un peu connu de notre petite mais tr√®s ville informatique (il y a plus de sept douzaines de bureaux √† Izhevsk avec des √©quipes de d√©veloppement, o√π travaillent environ trois mille programmeurs), un bureau avec un nom absolument g√©n√©rique "Russian Information Technologies", Soudain, sans raison, il a fallu un d√©veloppeur Java senior avec une vaste exp√©rience dans le d√©ploiement et l'automatisation, et au moins j'ai entendu parler du Big Data et des nuages ‚Äã‚Äãdu fond de mon oreille. Eh bien, au moment o√π j'ai entendu un peu parler des nuages ‚Äã‚Äãet des m√©gadonn√©es. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comme pour tout le reste, j'ai plus qu'assez d'exp√©rience :( Par cons√©quent, la premi√®re chose que j'ai dite quand j'ai vu le code et l'√©tat des processus √©tait dans les meilleures traditions d'Artemy Lebedev, fort et beaucoup. Je ne le r√©p√©terai pas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eh bien, si le code et les processus sont de qualit√© compr√©hensible, ils ont certainement une place pour l'optimisation. Pour commencer, vous pouvez au moins envoyer des demandes √† PostGIS une √† la fois, mais par lots, environ 5000 points √† la fois. Les bases de donn√©es sont, en r√®gle g√©n√©rale, bien optimis√©es pour la r√©solution des produits cart√©siens. Il est dit - fait, le stockage avec l'appel ST_DISTANCE a √©t√© r√©√©crit de mani√®re √† renvoyer imm√©diatement un grand tableau pour un ensemble de points, et √† partir de z√©ro, le calcul a √©t√© acc√©l√©r√© imm√©diatement de 40 fois, car maintenant il n'√©tait plus n√©cessaire d'√©tablir une connexion √† la base de donn√©es si souvent, et autant d'index sur la g√©om√©trie dans la table avec POI a commenc√© √† travailler avec beaucoup de sens.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Certes, une m√©chante erreur √©sot√©rique s'est gliss√©e dans le calcul, du fait que le prototype n'√©tait pas compl√®tement correctement port√© de C # vers Java. Les gars ont rat√© le point d'une variable importante, et les savoirs traditionnels formels sur le prototype ne les ont pas du tout atteints, perdus quelque part en cours de route. Ensuite, nous avons restaur√© tous les algorithmes √† partir de descriptions fragmentaires, mais c'√©tait d√©j√† bien plus tard. Cependant, cette erreur dans son ensemble n'a pas g√¢ch√© le r√©sultat du calcul, elle a simplement r√©duit le contraste de la carte thermique.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais vous n'obtiendrez pas beaucoup de performances de MapReduce, car le mappeur lit les donn√©es de HDFS et les r√©√©crit, et le r√©ducteur suivant de la cha√Æne fait de m√™me, et ainsi de suite jusqu'√† ce que toutes les √©tapes soient termin√©es. </font><font style="vertical-align: inherit;">Il est √©galement tr√®s g√™nant de g√©rer un processus en plusieurs √©tapes, surtout si l'algorithme a des branches en raison de param√®tres. </font><font style="vertical-align: inherit;">L'algorithme entier est un code dur, et si vous voulez r√©organiser les √©tapes, vous devez les d√©placer dans des modules s√©par√©s avec votre propre lanceur et envelopper une sorte de logique √† l'ext√©rieur. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eh bien, extraire PostGIS √† partir du calcul, m√™me si vous dupliquez la base de donn√©es sur chaque n≈ìud du cluster, est toujours une id√©e tr√®s douloureuse.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> L'av√®nement de CI et Spark </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Automatisez-le! - mon deuxi√®me grand </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">point</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> d' int√©r√™t de rofessionalny apr√®s enterprayznogo </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> rogrammirovaniya sur un crapaud ... Et non. Deuxi√®mement - il est </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> itstsa, </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ASTA et </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> udingi, alors qu'il y ait un troisi√®me - est </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> arr√™t </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> processus et leur automatisation. (Moi, en tant que </font><font style="vertical-align: inherit;">chef </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ovar, j'aime que tout soit sur les </font><font style="vertical-align: inherit;">cookies </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Hashtag # </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .)</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le travail manuel comporte trop de dangers. Les gens ne sont pas fiables et font souvent des erreurs, m√™me s'ils font la m√™me chose, il est donc beaucoup plus efficace de passer un peu de temps √† formaliser le flux global du projet et √† √©crire un script qui n'√©chouera pas lors de l'appel de l'utilitaire pour copier le jeu de donn√©es du stockage √† long terme vers le stockage en ligne, et ne m√©langera pas l'ordre des √©tapes, que de continuer √† marcher le r√¢teau. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La marche du r√¢teau √©tait juste le probl√®me le plus grave qui devait √™tre r√©solu en premier. Tout d'abord, je me suis d√©ploy√© dans une petite √©quipe virtuelle </font></font><a href="https://www.jetbrains.com/teamcity/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s√©par√©e</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et configur√© l'assembly avec l'ex√©cution de tous les tests afin que l'artefact v√©rifi√© soit toujours √† port√©e de main et qu'il ne doive pas √™tre jet√© manuellement sur le cluster. La deuxi√®me √©tape consistait √† √©crire un wrapper pour d√©marrer une t√¢che MR avec l'ensemble de donn√©es sp√©cifi√© et l'ensemble de param√®tres sur le cluster directement √† partir du m√™me TC, avec la m√™me copie automatique des ensembles de donn√©es d'origine vers le cluster et les r√©sultats du calcul dans le magasin de r√©sultats. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et la troisi√®me √©tape, qui a pris beaucoup de temps par habitude, a √©t√© d'automatiser le d√©ploiement du cluster lui-m√™me, de r√©gler ses param√®tres et de d√©marrer le calcul sur un ensemble de donn√©es int√©gr√© √† Azure Blob Storage. Tout √† coup, il y a eu des projets pour lesquels un cluster statique de cinq machines virtuelles a commenc√© √† manquer et / ou dont les ensembles de donn√©es ne devraient pas √™tre m√©lang√©s avec un vidage d'anciens fichiers sur HDFS. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Azure HDInsight est en fait</font></font><a href="https://www.cloudera.com/downloads/hortonworks-sandbox/hdp.html"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hortonworks HDP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (reste en paix pour lui), et certains de ses param√®tres sont </font><abbr title="Web UI  , ,    Web UI"><font style="vertical-align: inherit;">d√©finis</font></abbr><font style="vertical-align: inherit;"> dans l'API, et certains ne peuvent √™tre enregistr√©s que via </font></font><abbr title="Interface Web pour configurer, effrayant comme toute interface utilisateur Web d'entreprise"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ambari</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Le d√©ploiement d'un cluster en fonction de la charge du cloud peut prendre jusqu'√† une heure, et le cycle de r√©glage, c'est-√†-dire la v√©rification de l'effet de tout ensemble de param√®tres sur les performances de notre code, peut prendre une journ√©e enti√®re. </font><font style="vertical-align: inherit;">La version locale de HDP Sandbox dans la machine virtuelle mange 11 Go de RAM, et elle est monstrueusement exigeante sur le sous-syst√®me de disque, donc m√™me le d√©bogage local est extr√™mement d√©sagr√©able et ses param√®tres sont l√©g√®rement diff√©rents de la version cloud. </font><font style="vertical-align: inherit;">J'ai pris beaucoup de temps pour les exp√©riences, mais au moins j'ai compris comment tout cela fonctionne et que faire si le calcul se bloque soudainement au milieu avec le prochain MOO, car il est √©galement assez d√©sagr√©able d'analyser les journaux manuellement.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pendant que je parlais de HDP, un autre programmeur a commenc√© √† unifier les diff√©rentes √©tapes de la pr√©paration des jeux de donn√©es sur Apache Spark. Spark a r√©solu le probl√®me d'√©crire / lire constamment des donn√©es interm√©diaires qui se produisent entre les √©tapes d'un calcul, et en g√©n√©ral, il est con√ßu en tenant compte de tous les mauvais endroits de la RM, et peut le faire plusieurs fois hors de la bo√Æte. Et le </font></font><abbr title="Resilient Distributed Dataset, une structure de donn√©es avec de grandes propri√©t√©s autour desquelles Spark est construit"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RDD</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> paresseux de Spark </font><font style="vertical-align: inherit;">est une chose tr√®s pratique. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le m√™me temps, j'ai √©crit des scripts Azure Templates sur PowerShell pour configurer le n≈ìud de p√©riph√©rie pour PostGIS - une instance distincte dans le cluster, avec un tas de c≈ìurs et de m√©moire pour acc√©l√©rer les demandes, ainsi qu'une s√©rie d'√©tapes pr√©liminaires pour la pr√©paration des ensembles de donn√©es, qui ont d'abord √©t√© plac√©s sur son disque local, et puis charg√© dans HDFS sur le cluster.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ainsi, la liaison de script, qui pensait initialement qu'elle fonctionnerait √† la fois de mani√®re interactive et en mode batch sur TC en tant que build distinct, a progressivement appris √† lancer une combinaison arbitraire d'√©tapes sur MR, Spark et d'autres packages logiciels que nous n'avons pas utilis√©s √† partir de la suite HDInsight, mais toujours avec param√©trisation rudimentaire. Cependant, le transfert des param√®tres de g√©n√©ration vers un r√©f√©rentiel voisin avec un ensemble de fichiers .ini (pour chaque composant de plate-forme et pour chaque √©tape de processus) et la gestion des mod√®les de processus dans les branches de ce r√©f√©rentiel se sont r√©v√©l√©s √™tre une pratique si pratique que nous l'utilisons toujours. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">D√©j√† des progr√®s. Avec l'automatisation d'une routine manuelle, le temps de pr√©paration pour le calcul a √©t√© r√©duit de quatre fois, sans parler des erreurs humaines, qui sont devenues beaucoup moins. Mais ce n'est pas encore le moment du calcul lui-m√™me.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Troisi√®me approximation √† GeoSpark </font></font></h3><script type="text/javascript">function gtElInit() {var lib = new google.translate.TranslateService();lib.translatePage('ru', 'fr', function () {});}</script><script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=gtElInit&amp;client=wt"></script><br>  Cela a pris environ six mois.  √Ä ce moment-l√†, un ensemble d'heuristiques d√©bogu√© et test√© s'√©tait progressivement accumul√©, d√©j√† avec des applications distinctes sur Spark, et non avec des scripts, et certains mod√®les de processus typiques ont √©t√© d√©velopp√©s.  Il fallait maintenant les optimiser. <br><br>  Le deuxi√®me programmeur, qui n'avait aucune exp√©rience pr√©alable dans une √©quipe ou une entreprise, a agi avec ses modules assez simplement - apr√®s avoir termin√© le transfert d'une heuristique √† Spark, il a simplement copi√© tout le projet et a commenc√© √† remplacer l'ancien algorithme par le nouveau.  En cons√©quence, quand il y avait huit de ces modules parall√®les, chacun avec un ensemble de param√®tres similaire mais l√©g√®rement diff√©rent, un peu d'excellente s√©mantique d'appel - et aussi beaucoup de code de service en double - ils ont commenc√© √† poser un autre probl√®me.  Plus il y a de code, plus on passe de temps sur son support, surtout s'il ne cesse d'√©voluer tout ce temps.  Et en raison du copier-coller constant, les param√®tres inutilis√©s et autres ordures ont commenc√© √† s'accumuler en eux. <br><br>  Ayant fini avec le probl√®me br√ªlant de l'automatisation et ayant trait√© de la configuration des clusters, maintenant je pouvais d√©j√† reprendre les modules de pr√©paration des donn√©es et l'heuristique.  Pour commencer, j'ai pris tout le code r√©p√©titif dans un projet Commons s√©par√©, branch√© en tant que <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules">sous</a> - <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules">module git</a> , et dans les modules de calcul, il est devenu plusieurs fois moins un g√¢chis.  J'ai assembl√© un mod√®le pour une heuristique typique, et un nouveau projet en est d√©j√† sorti, sans avoir besoin de remplacer des morceaux de code et sans salet√© inutile dans l'histoire des commits.  Le d√©veloppement a commenc√© √† √™tre plus rapide. <br><br>  Le prochain gros probl√®me √† vaincre est venu de la logique de calcul des signaux produit cart√©sien √ó POI. <br><br>  Seul le traitement par lots le transf√®re √† la base de donn√©es, mais ne r√©duit pas le nombre d'op√©rations, m√™me si la base de donn√©es utilise efficacement les index et l'optimisation des requ√™tes.  Il serait logique de ne pas consid√©rer la distance pour ces paires o√π elle d√©passe √©videmment le seuil dont nous avons besoin.  Mais comment √©liminer les paires dont la distance est sup√©rieure au seuil sans calculer cette distance? <br><br>  R√©ponse: <abbr title="Tel qu'appliqu√© √† Spark - diviser le RDD en parties, pourquoi il ne cesse pas d'√™tre un seul ensemble, mais peut √™tre trait√© en morceaux">partitionnez</abbr> les signaux et les POI sur une grille g√©om√©trique. <br><br>  De plus, la carte thermique est d√©j√† constitu√©e d'une grille de polygones.  Et si vous s√©lectionnez la taille de cellule de cette grille de la bonne mani√®re, alors pour chaque POI du polygone s√©lectionn√©, il est tout √† fait possible de nous limiter √† calculer les distances aux signaux qui tombent dans le m√™me polygone, ses cellules voisines, et c'est tout.  Le reste peut √™tre jet√©, ils sortiront certainement des limites de la pertinence. <br><br>  Spark a d√©j√† un outil pr√™t √† l'emploi pour travailler avec des grilles - <abbr title="Je ne donnerai pas de lien. La qualit√© de ce projet est trop d√©primante pour moi :(">GeoSpark</abbr> .  Le deuxi√®me programmeur a commenc√© √† l'utiliser, et l'op√©ration pr√©liminaire ¬´tirer l'ensemble de donn√©es sur la grille¬ª est apparue.  Mais cela ne s'est pas beaucoup am√©lior√©, un probl√®me grave a √©t√© remplac√© par un autre probl√®me grave. <br><br>  Maintenant, c'√©tait le probl√®me de la ¬´longue queue¬ª - les utilisateurs, dans lesquels le nombre de signaux est dans les millions.  Il n'y en a pas beaucoup, mais s'ils s'accumulent au centre-ville, o√π le POI est √©lev√©, et ils s'y accumulent, comme par hasard, alors peu importe comment vous partitionnez en g√©om√©trie (au moins <a href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi</a> , au moins <a href="https://en.wikipedia.org/wiki/Quadtree">quadtree</a> ), il y aura toujours polygones o√π le nombre de comparaisons d√©passe un montant raisonnable.  Mais vous devez √©galement v√©rifier les polygones voisins o√π la densit√© est aussi √©lev√©e. <br><br>  Et si 99% des partitions avec des polygones √† faible saturation fonctionnent rapidement, alors 1% des postes de travail de Spark avec des cellules √† haute densit√© continuent de s'accrocher √† la victoire, de manger de la m√©moire comme s'ils √©taient inconscients et de g√¢cher toutes les framboises.  Spark essaie de tout garder √† l'esprit, et s'il y a une forte variation de la taille de la partition dans RDD, alors tout le r√©glage de la consommation de m√©moire s'envole, car il doit √™tre fait pour le plus grand. <br><br>  Il s'est av√©r√© que 99% du calcul a √©t√© acc√©l√©r√© avec des partitions g√©om√©triques des centaines de fois, et 1% de la longue queue a r√©duit l'optimisation enti√®re √† presque rien. <br><br>  En g√©n√©ral, la transition vers GeoSpark a produit un gain de cinq fois, mais uniquement sur la taille des ex√©cuteurs qui √©taient tr√®s peu efficaces en m√©moire - et, par cons√©quent, sur les clusters avec des machines virtuelles co√ªteuses.  En bref, le partitionnement g√©om√©trique des g√©odonn√©es √† haute densit√© s'est av√©r√© √™tre une impasse. <br><br>  Et puis il y avait du bonheur en la personne du bureau d'analyse de l'un des plus grands t√©l√©coms japonais.  Une petite filiale bas√©e sur les donn√©es de g√©olocalisation collect√©es par la soci√©t√© principale. <br><br><h3>  Analystes japonais et migration d'Azure vers AWS </h3><br>  Les Japonais ont une mentalit√© int√©ressante.  Ils ne sont pas press√©s eux-m√™mes, mais si seulement un gaijin est donn√© pour se mordre le doigt, les deux mains sont coup√©es.  Ne donnez jamais les dates sp√©cifiques japonaises!  Et si vous appelez, prenez au moins trois fois l'offre.  Il sera monstrueusement long et difficile de coordonner les termes de r√©f√©rence, et non seulement la fameuse minutie japonaise va interf√©rer, mais aussi la diff√©rence de pens√©e.  Il ne reste tout simplement pas le temps de mettre en ≈ìuvre la version finale du mandat. <br><br>  Le projet d'int√©grer la "fille" des t√©l√©coms japonais a failli tuer notre projet.  Les perspectives brillaient de devenir un fournisseur de donn√©es exclusif pour le march√© publicitaire japonais fou, et l'entreprise est un peu ... euh, je peux me passer de commentaire. <br><br>  Tout d'abord, pas d'azur.  Seulement AWS, seulement hardcore. <br><br>  Deuxi√®mement, le front devait √™tre modifi√© pour r√©pondre √† leurs besoins, qui changeaient constamment tout au long du projet.  Les sp√©cialistes du marketing de ce bureau voulaient constamment quelque chose qu'ils ne savaient pas eux-m√™mes avec certitude et ne pouvaient pas vraiment articuler, et devaient √™tre refaits dix fois par √©tape, changeant la logique de calcul pour les prochains nouveaux indicateurs √† la vol√©e. <br><br> <a href=""><img src="https://habrastorage.org/webt/3n/oy/y1/3noyy1wt6pjuqik6ukzfnmcmy9a.png" alt="Je m'excuse pour la qualit√©, une capture d'√©cran du rapport de bug, il n'en reste plus" title="Je m'excuse pour la qualit√©, une capture d'√©cran du rapport de bug, il n'en reste plus"></a> <br><br>  √Ä un moment donn√©, j'ai un peu paniqu√© et j'ai fait un ensemble d '¬´op√©rations √©l√©mentaires¬ª - environ 15 actions primitives sur RDD avec appel de m√©thodes de base telles que les jointures, le mappage, la suppression des valeurs par d√©faut, la somme des valeurs des colonnes - et d'autres petites op√©rations de ce type - pour rapidement changer la logique de la cha√Æne de calcul, comme s'il s'agissait d'un ensemble d'instructions SQL. <br><br>  (Regular Spark SQL est inapplicable dans notre cas car il n'y a ni typage strict ni ensemble de champs strict. Dans le jeu de donn√©es, vous pouvez √† tout moment ajouter autant de champs suppl√©mentaires que vous le souhaitez, et cela change pendant le d√©roulement du processus Il est trop difficile de prescrire des m√©tadonn√©es dans des conditions en constante √©volution.) <br><br>  La t√¢che de haut niveau √©tait la suivante: choisir une r√©gion arbitraire du Japon et construire une carte thermique pour une p√©riode de temps arbitraire en utilisant un ensemble arbitraire de cat√©gories avec un tas d'indicateurs pour la d√©charge.  Quel type d'indicateurs, comment les compter - le client lui-m√™me ne l'a pas vraiment compris. <br><br>  L'ensemble de donn√©es de test (c'est-√†-dire petit) avec les signaux des utilisateurs pour 2016-2017, sur lequel nous avons d√ª travailler sur la technologie, est de 5 t√©raoctets de donn√©es, 14 000 000 000 d'enregistrements.  Rien qu'√† Tokyo, il y a plusieurs millions de POI, et dans le r√©seau de la r√©gion d'Hokkaido, 1 600 000 cellules. <br><br>  Et les cartes pour les deux mille cat√©gories pour chacune des 47 perfections japonaises devraient √™tre consid√©r√©es ¬´√† la vol√©e¬ª, car elles devraient √™tre vendues en tant que service cloud. <br><br>  Une grande t√¢che pour briser le cerveau.  Quelque part trois ou quatre ordres de grandeur plus √©lev√©s que nos capacit√©s d'alors en termes de "vitesse de calcul" et de "volume de donn√©es". <br><br>  Devenu triste, nous avons d√©cid√© de faire n√©anmoins un pr√©-calcul pour chaque r√©gion (merci aux dieux Shinto, les Japonais n'ont pas eu besoin d'unir les r√©gions) et pendant un mois, afin que la carte thermique soit construite selon les scores pr√©alablement pr√©par√©s.  Soit pas en temps r√©el, mais quelques minutes ou dizaines (pour le centre de Tokyo) minutes.  Le pr√©-calcul a pris plusieurs mois avec des clusters de 25 des machines virtuelles les plus puissantes disponibles dans la r√©gion AWS de Tokyo. <br><br>  Mais pour fonctionner dans AWS, vous avez d'abord d√ª r√©√©crire l'automatisation sous l'API AWS.  Et diff√©rents nuages, bien qu'ils offrent des services similaires de l'ext√©rieur, sont compl√®tement diff√©rents en interne.  Il est bon qu'√† ce moment PowerShell ait d√©j√† atteint la version candidate de la version 6, et les scripts de liaison Azur pour d√©ployer le cluster et ex√©cuter le calcul pourraient √™tre port√©s et ex√©cut√©s audacieusement sur Linux TeamCity (car le d√©ploiement de serveurs sur Windows dans AWS est une id√©e )  Plus pr√©cis√©ment, ne portez pas, mais ouvrez un script existant sur un moniteur et √©crivez une impl√©mentation parall√®le pour un autre cloud sur le second. <br><br>  De plus, AWS est beaucoup plus ancien, et donc plus archa√Øque qu'Azure, est architectural, et il y a beaucoup plus de travail manuel pour configurer le niveau inf√©rieur de l'infrastructure.  Et la vente aux ench√®res locale pour la vente de ressources informatiques ajoute un casse-t√™te lorsque vous ne disposez pas des voitures de la bonne taille au prix souhait√© et que le client n'alloue pas de budget pour le calcul du prix complet. <br><br>  Mais l'√©cosyst√®me Hadoop lui-m√™me dans l'incarnation amazonienne - EMR - est quelque chose de plus proche de la vanille, et travailler avec lui est plus facile qu'avec HDInsight.  Eh bien, au moins avec quelque chose, cela s'est av√©r√© plus facile. <br><br>  Mais pas avec S3.  Ici les ennuis sont sortis d'o√π ils n'ont pas attendu.  S3 a des limites non document√©es.  Par exemple, dans un compartiment, il ne peut pas y avoir plus de ~ 11 000 000 d'objets, car quelque part dans les entrailles profondes de l'API, ils trient les cl√©s dans l'ordre lexicographique pour chaque (chaque!) Demande, et le tampon allou√© pour cela ne permet tout simplement pas le tri plus de lignes, surtout si elles sont longues.  Pour acc√©l√©rer le calcul, nous n'avons pas fusionn√© les partitions √† la fin, et √† un moment donn√©, nous sommes tomb√©s sur cette limite, apr√®s quoi le processus s'est simplement arr√™t√©. <br><br>  Selon l'esprit, la fusion doit √™tre effectu√©e, et il existe m√™me un outil - l'utilitaire s3-dist-cp, mais son utilisation est un casse-t√™te distinct.  Les pr√©dateurs pour les extraterrestres ont √©crit l'utilitaire √† coup s√ªr, il se comporte de mani√®re contre-intuitive.  Et il a une faille fatale - sous le fichier fusionn√©, vous avez besoin d'autant d'espace sur HDFS que tous les originaux.  Et pour fusionner des dizaines de milliers de fichiers de partition de centaines d'octets √† des dizaines de m√©gaoctets, r√©partis sur un cluster de 25 machines, cela durera tr√®s longtemps. <br><br>  Cependant, d√©j√† avec un million d'objets dans le compartiment, S3 commence √† lui trotter tranquillement les requ√™tes.  Et dans d'√©ventuelles conditions de coh√©rence, c'est g√©n√©ralement un d√©sastre - Spark, sans attendre le prochain bureau le nombre de fois convenu, peut tomber.  Il existe une solution - utilisez le module compl√©mentaire Amazon EMRFS, mais il fonctionne au-dessus de DynamoDB, et c'est une chose tr√®s co√ªteuse.  Et avec leurs propres limites sur le nombre de demandes par seconde. <br><br>  En bref, dans des conditions de manque de temps total, nous avons d√©cid√© de revenir au sch√©ma statique - d√©ployer un cluster permanent sur des instances d'une taille assez petite (bien que co√ªteuse, mais moins ch√®re que DynamoDB), fusionner tous les t√©raoctets des jeux de donn√©es d'origine et calcul√©s en HDFS dessus, et lire les cartes localement. <br><br>  Mais la torsion de l'intrigue suivante √©tait l'exigence pour les Japonais de passer de la grille hexagonale g√©n√©r√©e √† <abbr title="Je ne donnerai plus de lien, vous ne trouverez pas d'informations sur cette grille en japonais, et pas un seul traducteur en ligne ne peut g√©rer ce document normalement. Notre Tokyo Alexei Polyakov est japonais, il a pu traduire">Japan Mesh</abbr> - la m√©thode standard de partitionnement g√©ographique pour eux avec des cellules rectangulaires qui ne d√©pendent que des coordonn√©es du point.  Une tr√®s bonne chose, car elle vous permet d‚Äôabandonner l‚Äô√©tape lourde de calcul consistant √† ¬´tirer des signaux sur la grille¬ª. <br><br>  L'inconv√©nient est que le maillage Japan Mesh ne s'applique qu'au Japon et aux territoires insulaires qu'il pr√©tend √™tre, mais pas au reste du monde.  Mais au moins pour les Japonais, il est devenu possible d'abandonner le GeoSpark lent et de partitionner les signaux de mani√®re uniforme sans r√©f√©rence √† la g√©om√©trie externe.  Et avec le d√©part de la "longue queue", le calcul s'est de nouveau imm√©diatement acc√©l√©r√© √† 10. <br><br>  Il est malheureux que cela se soit produit apr√®s que nous ayons tous compris les hexagones, d√©pensant beaucoup d'argent et de temps en vain.  Un cluster avec des t√©raoctets d'ensembles de donn√©es pr√©par√©s a simplement √©t√© jet√©. <br><br>  Et en tout cas, quelque part au milieu du travail, les Japonais ont tout de m√™me demand√© de transf√©rer toute l'infrastructure d'un compte AWS √† un autre.  Et comme si vous ne vous souciez pas de tout le travail effectu√© sur la configuration.  Eh bien, j'ai r√©ussi √† cr√©er un script pour le mod√®le CloudFormation au moment de la transition, donc la migration s'est d√©roul√©e de mani√®re plus ou moins fluide. <br><br>  Derni√®re cerise sur le g√¢teau, les Japonais ont finalement d√©cid√© que le front ne les abandonnait pas, et ils tireraient les calculs manuellement √† la demande de leurs clients, donc merci √† nous pour les algorithmes (pour la premi√®re fois nous les avons tous document√©s en d√©tail - et en avons trouv√© quelques-uns) erreurs), et pour l'instant.  Eh bien ... bonne chance et √† plus tard. <br><br>  Brrr  Je me souviens de ce projet avec horreur et frisson. <br><br><h3>  Ash Nazg Durbatuluk, Ash Nazg Gimbatul, Ash Nazg Trakatuluk, Ag Burzum Ishi Krimpatul !! </h3><br>  Mais du positif, en plus de documenter tous les algorithmes, il y a eu aussi des am√©liorations g√©n√©rales. <br><br>  Nous avons appris un √©tudiant en Java Junior, et il a men√© une √©tude sur un tas de biblioth√®ques g√©ographiques, √† la suite de quoi il a finalement r√©ussi √† choisir la bonne et √† la jeter hors de l'environnement PostGIS. <br><br>  Les tentatives pr√©c√©dentes ont √©chou√© en raison d'une mauvaise pr√©cision.  Au rayon de trois kilom√®tres, les Haversins nous donnent une erreur d√©j√† perceptible, et la plupart des biblioth√®ques que nous avons essay√© de prendre d√®s la premi√®re fois √©taient moche aux latitudes nord de Saint-P√©tersbourg, entra√Ænant des trous ou un double chevauchement dans la grille.  Et nous, Finlandais, sommes des clients fr√©quents, il est donc essentiel que tout fonctionne correctement √† leurs latitudes. <br><br>  Jusqu'√† ce que nous r√©alisions que nous avions besoin d'une biblioth√®que avec un g√©o√Øde normal (de pr√©f√©rence le m√™me que dans PostGIS, WGS84), les r√©sultats n'√©taient pas en accord avec les r√©sultats attendus.  Mais apr√®s le passage √† GeographicLib, le goulot d'√©tranglement sous la forme de connexions Postgre a √©t√© √©limin√© et la derni√®re √©tape du calcul de la vitesse a √©t√© acc√©l√©r√©e 40 fois.  Golovnyak est parti avec la configuration suppl√©mentaire d'une instance RDS distincte sous la base et en y t√©l√©chargeant un vidage avec POI, qui a √©t√© d√©plac√© vers les jeux de donn√©es habituels dans S3.  Unification! <br><br>  En m√™me temps, le m√™me √©l√®ve a d√©terr√© et corrig√© l'erreur m√™me qui faisait que les cartes semblaient plus p√¢les qu'elles ne l'√©taient en r√©alit√©.  Eh bien, quand il y a une t√¢che sans limite de temps, j'envie les √©tudiants. <br><br>  Un autre point important.  Une fois, pour la √©ni√®me fois, en regardant les scripts de liaison qui appellent un module Spark apr√®s l'autre, je pensais, mais avec quel genre de diable les court-circuitons-nous? <br><br>  Pourquoi enregistrer des r√©sultats interm√©diaires √† chaque fois en S3 ou HDFS, si le RDD final du module pr√©c√©dent peut simplement √™tre redirig√© vers l'entr√©e du suivant dans la cha√Æne.  Aussit√¥t dit, aussit√¥t fait, MetaRunner a √©t√© √©crit en quelques heures.  La pr√©sence de communs a beaucoup aid√© √† cela, les modules √©taient alors assez standardis√©s, d'autant plus que les param√®tres de chacun des modules √©taient d√©j√† dans le m√™me fichier tasks.ini, avec les pr√©fixes cl√©s correspondant √† leurs noms. <br>  Votre attention est pr√©sent√©e avec un sch√©ma de principe de la carte (la derni√®re √©tape avant de sortir au recto, mais pas la version finale), √©crit sur les op√©rations √©l√©mentaires: <br><br> <a href=""><img src="https://habrastorage.org/webt/al/ke/4h/alke4hk9txojjq8j8lwauoihvqs.png" alt="Organigramme du processus de pr√©paration de la carte thermique" title="Organigramme du processus de pr√©paration de la carte thermique"></a> <br><br>  Si vous vous d√©barrassez de 24 appels interm√©diaires vers HDFS, ce calcul est sp√©cifiquement acc√©l√©r√© environ 50 fois. <br><br>  Mais que se passe-t-il si vous ajoutez une prise en charge variable au mod√®le de processus afin de ne pas avoir √† r√©g√©n√©rer le fichier tasks.ini √† chaque fois que vous modifiez les param√®tres dans le magasin de propri√©t√©s? <br><br>  - Ash Nazg!  Ai-je cri√©.  Des coll√®gues se regard√®rent avec perplexit√©.  Un mec a un toit √† cause de ces Japonais, mais bon, √ßa arrive. <br>  "Ash nazg ... burzum-ishi krimpatul", grognai-je grogna (cela ne fonctionnait pas tr√®s bien), et je me rendis chez PM pour discuter de la fusion des 15 (le nombre d'heuristiques et d'utilitaires auxiliaires augmentait progressivement) des modules de calcul en un seul r√©f√©rentiel. <br><br>  Si nous court-circuitons les modules entre eux, alors ne travaillez plus avec la doublure de tous les JAR individuels dans le chemin de classe de l'√©tincelle, et laissez l'ensemble complet de la logique Locomizer brevet√©e (et nos op√©rations auxiliaires) √™tre assembl√© en un seul JAR gras.  En m√™me temps et localement, il sera d√©sormais possible de s'ex√©cuter, sans cluster.  Et ce qui est important, la logique d'analyse des t√¢ches.ini peut √™tre transf√©r√©e des liaisons PowerShell au code Java, o√π la substitution de variables est beaucoup plus simple. <br><br>  Coll√®gues hennissant sur la proposition d'appeler le projet "L'anneau de la toute-puissance", - Un anneau - mais un peu de pathos sain ne fera jamais de mal. <br><br>  Ayant saisi le moment de la prochaine ronde de coordination sans fin des savoirs traditionnels sur le front, j'ai rassembl√© tous les modules en tas.  Maven est un outil avanc√© pour r√©soudre les d√©pendances dans un projet multi-modules, il √©tait donc possible de nettoyer les derniers morceaux de code en double, d'unifier les versions de toutes les biblioth√®ques et de cr√©er des options de construction pour les environnements locaux et cloud.  De plus, chaque module reste dans son propre sous-projet, et son auteur peut y travailler de mani√®re ind√©pendante, sans interf√©rer avec le reste. <br><br>  Soit dit en passant, je consid√®re une telle approche avec la cristallisation des abstractions et la construction d'une sorte d'architecture √† partir d'un ensemble existant d'entit√©s homog√®nes plus qu'une tentative de concevoir √† l'avance un niveau abstrait et de le mettre en ≈ìuvre dans des t√¢ches particuli√®res.  Sans pratiques et sch√©mas d'utilisation √©tablis, il est inutile de concevoir une architecture - tous les cas ne peuvent √™tre pr√©vus √† l'avance et les comportements des utilisateurs du syst√®me peuvent diff√©rer radicalement des id√©es du concepteur. <br><br>  Avec la logique unifi√©e du traitement des param√®tres, il a √©t√© possible de cr√©er un mod√®le d'objet unifi√© distinct pour la configuration du module et de v√©rifier normalement la validit√© et la coh√©rence des configurations des modules les uns avec les autres dans le m√™me processus.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ceci est particuli√®rement important avec les jeux de donn√©es au format CSV - le contr√¥le du nombre et de l'ordre des champs dans chaque enregistrement RDD, ainsi que l'exactitude du transfert de l'ensemble de donn√©es lui-m√™me de la sortie d'un module √† l'entr√©e de plusieurs suivants, reposent enti√®rement sur le c√¥t√© appelant. </font><font style="vertical-align: inherit;">Et s'il y a un point de contr√¥le, cela peut d√©j√† √™tre bien fait.</font></font><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pourquoi n'allons-nous pas plus haut et ne travaillons-nous pas avec RDD et non avec des trames de donn√©es? </font><font style="vertical-align: inherit;">Pour la m√™me raison que nous n'utilisons pas Spark SQL. </font><font style="vertical-align: inherit;">Mais en plus, l'impl√©mentation sur Spark est la derni√®re et derni√®re √©tape du code, qui commence par du livre blanc, est enti√®rement d√©bogu√© en Python, et seulement ensuite optimis√©e en quelques √©tapes pour la version la plus productive. </font><font style="vertical-align: inherit;">Et plus les primitives de la biblioth√®que de base sont proches, plus le code s'ex√©cute g√©n√©ralement plus rapidement.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">... si les mains du d√©veloppeur sortent de ses √©paules et que sa t√™te est brillante. Th√©oriquement. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il s'av√®re que dans nos conditions, il est beaucoup plus facile de piloter la ligne du CSV d'origine sous la forme d'un texte natif Hadoup compact (sous le capot, c'est juste un tableau d'octets), et de d√©crire uniquement les colonnes que l'op√©ration actuelle conna√Æt, et uniquement pour cela. En outre, selon les r√©sultats des exp√©riences, les trames de donn√©es donnent une surcharge de consommation de m√©moire sup√©rieure √† la n√©cessit√© d'analyser CSV √† l'entr√©e de chaque op√©ration et de les compresser en texte √† la sortie. Eh bien et pourtant - il est important pour nous de conserver la possibilit√© de partitionner manuellement les RDD interm√©diaires apr√®s chaque √©tape, car les nouveaux ensembles de donn√©es du magasin peuvent se m√©langer avec eux (cela est clairement visible dans le diagramme), donc vous devez toujours descendre d'un niveau, peu importe comment vous souhaitez rester au niveau livre blanc logique.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais dans le code "bas niveau" de Java, il y a aussi des avantages. Par exemple, si vous d√©crivez les param√®tres d'op√©ration (ainsi que les RDD attendus et g√©n√©r√©s) dans les m√©tadonn√©es, vous pouvez g√©n√©rer automatiquement √† la fois la documentation et un exemple de configuration et ne les √©crivez plus manuellement. Et les quais seront toujours pertinents, apr√®s chaque build. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le fichier de configuration tasks.ini lui-m√™me, √† partir d'un ensemble h√©t√©rog√®ne de param√®tres pour chaque module, s'est imm√©diatement transform√© en programme dans une sorte de langage de programmation d√©claratif. Pas tr√®s beau, mais logique en interne et relativement lisible par l'homme. Le finir en DSL r√©el avec sa propre syntaxe n'est pas un probl√®me, mais je ne l'ai pas fait comme inutile. Mais un peu plus tard, il a n√©anmoins ajout√© une vue √† JSON pour le futur front avec un √©diteur visuel.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un processus court-circuit√© a en moyenne re√ßu trois √† cinq fois plus rapidement qu'une cha√Æne d'appels individuels √† des travaux Spark. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pas cent fois, car maintenant, dans le cadre du m√™me travail Spark, des √©tapes de t√¢ches de complexit√© de calcul et de saturation de donn√©es diff√©rentes pouvaient √™tre m√©lang√©es. Par cons√©quent, le r√©glage fin des param√®tres de cluster pour chacune des parties d'un processus en plusieurs √©tapes a perdu toute signification pratique. Mais progressivement, et pour une telle option, certains mod√®les g√©n√©raux ont √©t√© trouv√©s qui permettaient de s√©lectionner des pr√©r√©glages de tailles de cluster, en fonction uniquement de la taille de l'ensemble de donn√©es initial et du nombre total d'√©tapes dans le mod√®le de processus de traitement. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour r√©sumer cette √©tape, √† la fin de notre travail avec les Japonais, nous avions d√©j√† des outils assez d√©velopp√©s:</font></font><br><br><ul><li>          ,           , </li><li> ,    ,             DSL  , </li><li>   ,    ‚Äî   , </li><li>      AWS,           . </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais ce qui n'a pas fonctionn√©, c'est le front. </font><font style="vertical-align: inherit;">L'ancienne interface utilisateur Web de Locomizer est d√©sesp√©r√©ment d√©pass√©e, nous n'avons jamais r√©ussi √† mettre le nouveau japonais dans un √©tat sain avant de l'abandonner compl√®tement. </font><font style="vertical-align: inherit;">Oui, et le code backend pour cette interface utilisateur, √©crit avec mon pied arri√®re gauche par une nuit sombre d'octobre, je n'ai pas pu peigner jusqu'√† la fin simplement en raison du grand volume.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Optimisation et g√©ocatarse avec Uber H3 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apr√®s avoir expir√©, nous sommes revenus √† des projets priv√©s. L'ambiance apr√®s les Japonais √©tait, franchement, toute l'√©quipe √©tait tr√®s moyenne. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais je me suis finalement d√©barrass√© de la n√©cessit√© de maintenir un back-up √† l'avant avec son Bogomersssky, holm, holm, spring. (Ceci est mon opinion personnelle. EE, je n'aime pas juste un peu moins, car il a moins d'autogie et de d√©fauts implicites; donc cela n'a pas d'importance en plus de ce que la foutue entreprise est d'√©crire des REST). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il y avait un temps pour regarder √† l'int√©rieur de chaque module avec une d√©pendance.</font></font><br><blockquote>     ‚Äî        ,       .            ,    ,    ,       .   -      .       ‚Äî            .       ,         ‚Äî    . </blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Non pas que j'aurais regard√© le code de mes pairs de mani√®re inattentive. Tout le monde est engag√© dans la t√¢che qui lui est confi√©e et, bien qu'elle soit ex√©cut√©e par lui avec le r√©sultat souhait√©, n'interf√©rez pas avec le d√©veloppeur qui fait son travail. Si l'algorithme fonctionne correctement, et cela est confirm√© par des tests, alors tout va bien. Selon la rapidit√© du travail, - c'est acceptable, ou autrement - la d√©cision est prise par le PM. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je n'interviens que lorsque je reconnais un risque √©lev√© de soutien suppl√©mentaire dans la d√©cision prise par le d√©veloppeur lors de la mise en ≈ìuvre d'une nouvelle t√¢che. Et les modules anciens et moches, √©crits sous le Tsar Gorokh par quelqu'un qui avait longtemps quitt√© le projet, mais n√©cessaires pour les affaires, seront maintenus √† un niveau viable tel qu'il est, et peu importe √† quel point il en sent. Cela semble cynique, mais je suis pragmatique, pas id√©aliste, le r√©sultat du travail est plus important pour moi que la beaut√© du code.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais parfois, il est n√©cessaire d‚Äôapurer la dette technique afin de ne pas enterrer le projet sous son propre poids. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spark est une biblioth√®que de tr√®s haut niveau. Il vous permet d'effectuer des op√©rations sur RDD de diff√©rentes mani√®res, ce qui donne le m√™me r√©sultat, et chaque m√©thode peut avoir plusieurs morceaux d'excellentes options. Vous devez lire attentivement la description de chacun d'eux et, en cas de doute, remonter dans la source pour comprendre ce qui est optimal dans quel cas. Le r√©sultat sera le m√™me, mais la diff√©rence de vitesse de calcul peut √™tre plusieurs fois, et si la logique d'une heuristique d√©ploie une centaine de lignes de code sur Spark, alors vous devez √™tre particuli√®rement prudent pour utiliser les moyens les plus appropri√©s de transformation des donn√©es. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Langages de haut niveau - ils sont tels que vous font penser de mani√®re abstraite.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais en m√™me temps, le d√©veloppeur doit √™tre conscient du faible niveau, peu importe √† quel point il monte en abstractions √©lev√©es. Par exemple, tout lambda transmis √† la m√©thode .map (), √† l'int√©rieur de laquelle la m√©moire est allou√©e √† un objet en gras, est rappel√© pour chaque enregistrement et r√©alloue le m√™me objet, et aucune des machines virtuelles Java existantes n'aime les allocations r√©p√©t√©es en gras. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et si vous pensez √† la prise en charge du code, ce serait bien d'avoir des morceaux de l'algorithme qui sont connect√©s par une logique interne, mais en m√™me temps compl√®tement isol√©s pour certaines valeurs de param√®tres, isoler du reste du code, surtout si ces morceaux sont au d√©but ou √† la fin de l'algorithme. Ils peuvent g√©n√©ralement √™tre retir√©s dans une op√©ration distincte, en m√™me temps les tests avec une couverture compl√®te de tous les cas deviendront plus courts.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auparavant, il √©tait pr√©matur√© de g√©rer l'optimisation, mais maintenant le moment est venu, et pendant quelques mois, je suis parti avec ma t√™te dans une immersion passionnante dans les entrailles des modules de calcul avec du code de profilage √©crit sur deux ans par mes coll√®gues. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lorsque j'y ai plong√©, One Ring a eu 29 op√©rations (certains modules en contiennent plusieurs). Quand il est apparu - 43, et chacun plus vite que l'original, de quelques pour cent √† des dizaines de fois. Mais de fa√ßon plus valable, ces op√©rations qui √©taient auparavant √©touff√©es par des donn√©es sur des partitions de 10 000 √©l√©ments, maintenant facilement m√¢ch√©es sur des morceaux dans un million d'enregistrements. √Ä certains endroits, j'ai d√ª sacrifier la flexibilit√© et la lisibilit√© du code, √† certains endroits, cela a co√ªt√© un simple remplacement de .map () par .mapPartition (), mais le code a cess√© de planter.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il n'y avait qu'un seul goulot d'√©tranglement - le geofencing dans une r√©gion arbitraire. C'√©tait encore une solution hybride bizarre avec un maillage externe. Il √©tait possible d'utiliser Japan Mesh pour le Japon, mais pour le reste du monde, il √©tait n√©cessaire de rechercher une variante appropri√©e d'une grille dynamique, qui ne d√©pend que des coordonn√©es du point et est pratique √† utiliser. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une telle option a √©t√© trouv√©e - </font></font><a href="https://uber.github.io/h3/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Uber H3</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si je comprends bien, l'arbre hexagonal est crypt√© sous le nom H3 - et c'est une grille g√©ographique avec de grandes fonctionnalit√©s. Il est stable sur toute la plage de coordonn√©es, monstrueusement rapide (le code natif est appel√©), donne des cellules de taille uniforme sans lacunes sur tout le terrain et vous permet de faire un tas d'options diff√©rentes pour couvrir les polygones, les points et les chemins. En outre, une cellule de grille hexagonale a un nombre minimal de voisins, et le niveau suivant couvre les sept cellules de la pr√©c√©dente strictement au-dessus du centre de la cellule sous-jacente, ce qui est pratique lors de la construction de cartes d'agr√©gation. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Avec la transition vers H3, il semble que le puzzle soit compl√®tement d√©velopp√©.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si nous comparons avec ce qu'il √©tait au d√©but, il y a 2,5 ans, puis des semaines qui ont √©t√© pass√©es sur une carte de chaleur malheureuse sur un ensemble de donn√©es √† quelques millions de signaux, nous sommes arriv√©s aux minutes qui sont d√©pens√©es sur des dizaines de cartes avec des ensembles de donn√©es, la taille de l'analyste de donn√©es n'y pr√™te pas beaucoup d'attention (vous devez vous plaindre lorsqu'il d√©finit le pr√©r√©glage trop haut pour la taille du cluster si l'√©criture du r√©sultat dans S3 prend plus de temps que le calcul lui-m√™me). Et il ne regarde plus TC lui-m√™me, il obstrue simplement la matrice des param√®tres quelque part chez lui, et tire le nombre requis de builds n√©cessaires avec le python.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ajoutez une nouvelle op√©ration - il vous suffit d'impl√©menter correctement la classe Operation (vous pouvez √©galement utiliser Scala si vous le souhaitez), de l'encapsuler avec des m√©tadonn√©es, de l'inclure dans votre configuration, puis One Ring d√©terminera si vous appelez la nouvelle heuristique ou si vous traitez correctement dans la cha√Æne. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eh bien, tout fonctionne √† la fois localement et dans AWS. </font><font style="vertical-align: inherit;">Il sera √©galement dans un autre cloud s'il prend en charge S3, et Spark peut √™tre tir√© via </font></font><abbr title="Lanceur REST pour Spark"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Livy l√†</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font><abbr title="Lanceur REST pour Spark"><font style="vertical-align: inherit;">bas</font></abbr><font style="vertical-align: inherit;"> - et nous nous sommes d√©barrass√©s de toutes les autres d√©pendances externes.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dehors tout blanc </font></font></h3><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Gandalf?!</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mais nous n'avons toujours pas de fa√ßade pour lancer des processus flexibles. Et les mod√®les de ces processus eux-m√™mes doivent √™tre √©crits √† l'ancienne - √† la main dans VSCode, mais je voulais √™tre une souris dans un √©diteur similaire √† Visio. Quelque chose comme √ßa: </font><font style="vertical-align: inherit;">j'ai m√™me fait un petit service REST dans le cadre de One Ring, qui a tout ce dont vous avez besoin pour √©crire un tel √©diteur, mais la derni√®re fois que j'ai travaill√© sur le front √©tait il y a environ 10 ans, et non dans le cadre des tendances actuelles. Ce n'est pas pour JSF que je le rivette, ce ne sera m√™me pas r√©tro, mais d√©j√† une sorte de n√©cro. Ce serait bien d'en faire un SPA statique sur quelque chose de moderne. Seulement, je n'ai aucune id√©e de quoi. </font><font style="vertical-align: inherit;">Mon </font><font style="vertical-align: inherit;">int√©r√™t personnel </font><s><font style="vertical-align: inherit;">√©go√Øste</font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour r√©v√©ler le code </font></font></font><a href="https://github.com/PastorGL/OneRing"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One Ring</font></font></font></a></font><br><br> <a href=""><img src="https://habrastorage.org/webt/g2/su/hr/g2suhrumf4-lmrwasnribe2zokc.png" alt="Interface Mocap pour l'√©dition d'un processus" title="Interface Mocap pour l'√©dition d'un processus"></a> <br><br><font style="vertical-align: inherit;"></font><br><br><font style="vertical-align: inherit;"></font><s><font style="vertical-align: inherit;"></font></s><font style="vertical-align: inherit;"></font><a href="https://github.com/PastorGL/OneRing"><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Je vais terminer le r√©f√©rentiel avec du contenu, mais vous pouvez le regarder maintenant), j'esp√®re, c'est clair. </font><font style="vertical-align: inherit;">Et s'il y a quelqu'un assez courageux pour s'attaquer √† </font></font><a href="https://github.com/PastorGL/OneRing/issues/1"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cette t√¢che</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , j'√©crirai une t√¢che technique saine avec des sp√©cifications.</font></font><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais en g√©n√©ral, nous, l'√©quipe des ing√©nieurs de donn√©es, ne voulons pas garder l'outil fini dans notre placard. </font><font style="vertical-align: inherit;">Nous en sommes s√ªrs: il nous sera utile non seulement. </font><font style="vertical-align: inherit;">Et pas seulement pour les besoins du SIG, mais en g√©n√©ral tout traitement en rafale d'ensembles de donn√©es avec des √©tapes de traitement param√©trables.</font></font></blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le dernier article (ou quelques articles, encore une fois, quelque chose prend trop de temps), je vous dirai comment cr√©er, ex√©cuter, d√©velopper et utiliser One Ring pour vos t√¢ches de recherche. </font></font><br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">* Le code source One Ring OSS n'inclut pas d'algorithmes heuristiques propri√©taires Locomizer propri√©taires. </font><font style="vertical-align: inherit;">Mais son r√©f√©rentiel contiendra des interfaces et des descriptions, selon lesquelles les impl√©mentations gratuites de ces heuristiques peuvent √™tre recr√©√©es en utilisant la m√©thode de salle blanche, c'est-√†-dire sans invite de mon c√¥t√© pour le code.</font></font></i> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Remerciements </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">... √† ses coll√®gues Gregory </font></font><a href="https://github.com/pomadchin"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pomadchin</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour des commentaires de fond sur le sujet, et </font></font><a href="https://habr.com/ru/users/sshikov/" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sshikov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour une √©valuation ind√©pendante de la lisibilit√© du texte, ainsi qu'√† Anton </font></font><a href="https://habr.com/ru/users/dartov/" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dartov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Zadorozhny pour un retour inattendu sur l'article pr√©c√©dent de la s√©rie.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr485988/">https://habr.com/ru/post/fr485988/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr485968/index.html">Et encore une fois contourner les verrous. RouterOS + BGP + OSPF</a></li>
<li><a href="../fr485970/index.html">Trente meilleures interviews r√©cemment: d√©veloppement, design, sciencepop et style de vie</a></li>
<li><a href="../fr485972/index.html">M√©thodes d'analyse de r√©gression en science des donn√©es</a></li>
<li><a href="../fr485974/index.html">Modem Hasp Raspberry Pi et SIM7600E 4G</a></li>
<li><a href="../fr485986/index.html">Top 5 des tendances de localisation en 2020</a></li>
<li><a href="../fr485990/index.html">L'automatisation tue?</a></li>
<li><a href="../fr485996/index.html">APM √©lastique dans l'application</a></li>
<li><a href="../fr485998/index.html">LyX: Remarques g√©n√©rales. 2e partie</a></li>
<li><a href="../fr486000/index.html">ADSM3. Syst√®mes IPAM / DCIM</a></li>
<li><a href="../fr486006/index.html">Stocker l'√©tat du chat sur la pile</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
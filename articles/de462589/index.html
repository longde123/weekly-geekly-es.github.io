<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💮 👂🏼 👐🏾 Erstellen Sie eine Pipeline für die Streaming-Datenverarbeitung. Teil 2 🙏 🌝 👨🏼‍🚒</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo an alle. Wir teilen die Übersetzung des letzten Teils des Artikels, der speziell für Studenten des Data Engineer- Kurses vorbereitet wurde. Der ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstellen Sie eine Pipeline für die Streaming-Datenverarbeitung. Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/462589/">  Hallo an alle.  Wir teilen die Übersetzung des letzten Teils des Artikels, der speziell für Studenten des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Data Engineer-</a> Kurses vorbereitet wurde.  Der erste Teil ist hier zu finden. <br><br>  <b><i>Apache Beam und DataFlow für Echtzeit-Pipelines</i></b> <br><br><img src="https://habrastorage.org/webt/9t/uy/au/9tuyauggjylmprwx7lxswwbqggi.png"><br><br><h2>  Google Cloud-Setup </h2><br><blockquote>  Hinweis: Ich habe Google Cloud Shell verwendet, um die Pipeline zu starten und die Benutzerprotokolldaten zu veröffentlichen, da ich Probleme beim Ausführen der Pipeline in Python 3 hatte. Google Cloud Shell verwendet Python 2, das besser mit Apache Beam kompatibel ist. </blockquote><br>  Um den Förderer zu starten, müssen wir uns ein wenig mit den Einstellungen befassen.  Für diejenigen unter Ihnen, die GCP noch nicht verwendet haben, müssen Sie die folgenden 6 Schritte auf dieser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Seite ausführen</a> . <a name="habracut"></a><br><br>  Danach müssen wir unsere Skripte in Google Cloud Storage hochladen und in unser Google Cloud Shel kopieren.  Das Hochladen in den Cloud-Speicher ist recht trivial (eine Beschreibung finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ).  Um unsere Dateien zu kopieren, können Sie Google Cloud Shel über die Symbolleiste öffnen, indem Sie auf das erste Symbol links in Abbildung 2 unten klicken. <br><br><img src="https://habrastorage.org/webt/su/hz/hq/suhzhqrmyvi6c5hneokqhhhqjuw.png"><br>  <i>Abbildung 2</i> <br><br>  Die Befehle, die wir zum Kopieren von Dateien und Installieren der erforderlichen Bibliotheken benötigen, sind unten aufgeführt. <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Copy file from cloud storage gsutil cp gs://&lt;YOUR-BUCKET&gt;/ * . sudo pip install apache-beam[gcp] oauth2client==3.0.0 sudo pip install -U pip sudo pip install Faker==1.0.2 # Environment variables BUCKET=&lt;YOUR-BUCKET&gt; PROJECT=&lt;YOUR-PROJECT&gt;</span></span></code> </pre> <br><h2>  Erstellen unserer Datenbank und Tabelle </h2><br>  Nachdem wir alle Konfigurationsschritte abgeschlossen haben, müssen wir als Nächstes ein Dataset und eine Tabelle in BigQuery erstellen.  Es gibt verschiedene Möglichkeiten, dies zu tun. Am einfachsten ist es jedoch, die Google Cloud-Konsole zu verwenden, indem Sie zuerst ein Dataset erstellen.  Sie können die Schritte unter dem folgenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link ausführen</a> , um eine Tabelle mit einem Schema zu erstellen.  Unsere Tabelle enthält <b>7 Spalten</b> , die den Komponenten jedes Benutzerprotokolls entsprechen.  Der Einfachheit halber definieren wir alle Spalten mit Ausnahme der zeitlichen Variablen als Zeichenfolgen (Typ Zeichenfolge) und benennen sie gemäß den zuvor generierten Variablen.  Das Layout unserer Tabelle sollte wie in Abbildung 3 aussehen. <br><br><img src="https://habrastorage.org/webt/zw/ts/pz/zwtspziwiubrmz0c860bmvoe3so.png"><br>  <i>Abbildung 3. Tabellenlayout</i> <br><br><h2>  Veröffentlichen Sie Benutzerprotokolldaten </h2><br>  Pub / Sub ist eine wichtige Komponente unserer Pipeline, da mehrere unabhängige Anwendungen miteinander interagieren können.  Insbesondere fungiert es als Vermittler, der es uns ermöglicht, Nachrichten zwischen Anwendungen zu senden und zu empfangen.  Als erstes müssen wir ein Thema erstellen.  Gehen Sie einfach in der Konsole zu Pub / Sub und drücken Sie CREATE TOPIC. <br><br>  Der folgende Code ruft unser Skript auf, um die oben definierten Protokolldaten zu generieren. Anschließend werden die Protokolle verbunden und an Pub / Sub gesendet.  Wir müssen lediglich ein <b>PublisherClient-</b> Objekt erstellen, den Pfad zum Thema mithilfe der <code>topic_path</code> Methode <code>topic_path</code> und die <code>publish</code> Funktion mit <code>topic_path</code> und data <code>topic_path</code> .  Bitte beachten Sie, dass wir <code>generate_log_line</code> aus unserem <code>stream_logs</code> Skript importieren. <code>stream_logs</code> daher sicher, dass sich diese Dateien im selben Ordner befinden. Andernfalls wird ein <code>stream_logs</code> .  Dann können wir dies über unsere Google-Konsole ausführen, indem wir: <br><br><pre> <code class="python hljs">python publish.py</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> stream_logs <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> generate_log_line <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pubsub_v1 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time PROJECT_ID=<span class="hljs-string"><span class="hljs-string">"user-logs-237110"</span></span> TOPIC = <span class="hljs-string"><span class="hljs-string">"userlogs"</span></span> publisher = pubsub_v1.PublisherClient() topic_path = publisher.topic_path(PROJECT_ID, TOPIC) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">publish</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(publisher, topic, message)</span></span></span><span class="hljs-function">:</span></span> data = message.encode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> publisher.publish(topic_path, data = data) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">callback</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(message_future)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># When timeout is unspecified, the exception method waits indefinitely. if message_future.exception(timeout=30): print('Publishing message on {} threw an Exception {}.'.format( topic_name, message_future.exception())) else: print(message_future.result()) if __name__ == '__main__': while True: line = generate_log_line() print(line) message_future = publish(publisher, topic_path, line) message_future.add_done_callback(callback) sleep_time = random.choice(range(1, 3, 1)) time.sleep(sleep_time)</span></span></code> </pre> <br>  Sobald die Datei gestartet wird, können wir die Ausgabe der Protokolldaten an die Konsole beobachten, wie in der folgenden Abbildung gezeigt.  Dieses Skript funktioniert so lange, bis wir <b>STRG + C verwenden</b> , um es zu vervollständigen. <br><br><img src="https://habrastorage.org/webt/ho/4c/6n/ho4c6n5yfnnv8pvetgkidvut-q0.png"><br>  <i>Abbildung 4. Ausgabe von <code>publish_logs.py</code></i> <i><br></i> <br><br><h2>  Code für unsere Pipeline schreiben </h2><br>  Nachdem wir alles vorbereitet haben, können wir mit dem interessantesten Teil fortfahren - dem Schreiben des Codes unserer Pipeline mit Beam und Python.  Um eine Beam-Pipeline zu erstellen, müssen Sie ein Pipeline-Objekt erstellen (p).  Nachdem wir das Pipeline-Objekt erstellt haben, können wir mit dem Operator <code>pipe (|)</code> mehrere Funktionen nacheinander anwenden.  Im Allgemeinen sieht der Workflow wie im Bild unten aus. <br><br><pre> <code class="python hljs">[Final Output PCollection] = ([Initial Input PCollection] | [First Transform] | [Second Transform] | [Third Transform])</code> </pre> <br>  In unserem Code erstellen wir zwei benutzerdefinierte Funktionen.  Die Funktion <code>regex_clean</code> , die Daten scannt und die entsprechende Zeile basierend auf der PATTERNS-Liste mithilfe der Funktion <code>re.search</code> .  Die Funktion gibt eine durch Kommas getrennte Zeichenfolge zurück.  Wenn Sie kein Experte für reguläre Ausdrücke sind, empfehle ich Ihnen, dieses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tutorial zu</a> lesen und im Editor zu üben, um den Code zu überprüfen.  Danach definieren wir eine benutzerdefinierte ParDo-Funktion namens <b>Split</b> , eine Variation der Beam-Transformation für die parallele Verarbeitung.  In Python geschieht dies auf besondere Weise - wir müssen eine Klasse erstellen, die von der DoFn Beam-Klasse erbt.  Die Split-Funktion übernimmt eine analysierte Zeichenfolge aus der vorherigen Funktion und gibt eine Liste von Wörterbüchern mit Schlüsseln zurück, die den Spaltennamen in unserer BigQuery-Tabelle entsprechen.  Diese Funktion hat etwas Bemerkenswertes: Ich musste die <code>datetime</code> in die Funktion importieren, damit sie funktioniert.  Ich habe am Anfang der Datei einen Importfehler erhalten, der seltsam war.  Diese Liste wird dann an die <b>WriteToBigQuery-</b> Funktion übergeben, die einfach unsere Daten zur Tabelle hinzufügt.  Der Code für den Batch DataFlow-Job und den Streaming DataFlow-Job wird unten angezeigt.  Der einzige Unterschied zwischen Batch- und Stream-Code besteht darin, dass wir bei der Batch-Verarbeitung CSV aus <code>src_path</code> mithilfe der <code>ReadFromText</code> Funktion von Beam lesen. <br><br><h2>  Batch DataFlow Job (Paketverarbeitung) </h2><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> apache_beam <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> beam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> apache_beam.options.pipeline_options <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PipelineOptions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> bigquery <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys PROJECT=<span class="hljs-string"><span class="hljs-string">'user-logs-237110'</span></span> schema = <span class="hljs-string"><span class="hljs-string">'remote_addr:STRING, timelocal:STRING, request_type:STRING, status:STRING, body_bytes_sent:STRING, http_referer:STRING, http_user_agent:STRING'</span></span> src_path = <span class="hljs-string"><span class="hljs-string">"user_log_fileC.txt"</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">regex_clean</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> PATTERNS = [<span class="hljs-string"><span class="hljs-string">r'(^\S+\.[\S+\.]+\S+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r'(?&lt;=\[).+?(?=\])'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(\S+)\s(\S+)\s*(\S*)\"'</span></span>,<span class="hljs-string"><span class="hljs-string">r'\s(\d+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r"(?&lt;=\[).\d+(?=\])"</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"[AZ][az]+'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(http|https)://[az]+.[az]+.[az]+'</span></span>] result = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> match <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> PATTERNS: <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: reg_match = re.search(match, data).group() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> reg_match: result.append(reg_match) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: result.append(<span class="hljs-string"><span class="hljs-string">" "</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: print(<span class="hljs-string"><span class="hljs-string">"There was an error with the regex search"</span></span>) result = [x.strip() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] result = [x.replace(<span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] res = <span class="hljs-string"><span class="hljs-string">','</span></span>.join(result) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> res <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Split</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, element)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime element = element.split(<span class="hljs-string"><span class="hljs-string">","</span></span>) d = datetime.strptime(element[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-string"><span class="hljs-string">"%d/%b/%Y:%H:%M:%S"</span></span>) date_string = d.strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d %H:%M:%S"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [{ <span class="hljs-string"><span class="hljs-string">'remote_addr'</span></span>: element[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-string"><span class="hljs-string">'timelocal'</span></span>: date_string, <span class="hljs-string"><span class="hljs-string">'request_type'</span></span>: element[<span class="hljs-number"><span class="hljs-number">2</span></span>], <span class="hljs-string"><span class="hljs-string">'status'</span></span>: element[<span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-string"><span class="hljs-string">'body_bytes_sent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">4</span></span>], <span class="hljs-string"><span class="hljs-string">'http_referer'</span></span>: element[<span class="hljs-number"><span class="hljs-number">5</span></span>], <span class="hljs-string"><span class="hljs-string">'http_user_agent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">6</span></span>] }] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> p = beam.Pipeline(options=PipelineOptions()) (p | <span class="hljs-string"><span class="hljs-string">'ReadData'</span></span> &gt;&gt; beam.io.textio.ReadFromText(src_path) | <span class="hljs-string"><span class="hljs-string">"clean address"</span></span> &gt;&gt; beam.Map(regex_clean) | <span class="hljs-string"><span class="hljs-string">'ParseCSV'</span></span> &gt;&gt; beam.ParDo(Split()) | <span class="hljs-string"><span class="hljs-string">'WriteToBigQuery'</span></span> &gt;&gt; beam.io.WriteToBigQuery(<span class="hljs-string"><span class="hljs-string">'{0}:userlogs.logdata'</span></span>.format(PROJECT), schema=schema, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND) ) p.run() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: logger = logging.getLogger().setLevel(logging.INFO) main()</code> </pre> <br><br><h2>  Streaming von DataFlow-Job </h2><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> apache_beam.options.pipeline_options <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PipelineOptions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pubsub_v1 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> bigquery <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> apache_beam <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> beam <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> argparse <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re PROJECT=<span class="hljs-string"><span class="hljs-string">"user-logs-237110"</span></span> schema = <span class="hljs-string"><span class="hljs-string">'remote_addr:STRING, timelocal:STRING, request_type:STRING, status:STRING, body_bytes_sent:STRING, http_referer:STRING, http_user_agent:STRING'</span></span> TOPIC = <span class="hljs-string"><span class="hljs-string">"projects/user-logs-237110/topics/userlogs"</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">regex_clean</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> PATTERNS = [<span class="hljs-string"><span class="hljs-string">r'(^\S+\.[\S+\.]+\S+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r'(?&lt;=\[).+?(?=\])'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(\S+)\s(\S+)\s*(\S*)\"'</span></span>,<span class="hljs-string"><span class="hljs-string">r'\s(\d+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r"(?&lt;=\[).\d+(?=\])"</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"[AZ][az]+'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(http|https)://[az]+.[az]+.[az]+'</span></span>] result = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> match <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> PATTERNS: <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: reg_match = re.search(match, data).group() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> reg_match: result.append(reg_match) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: result.append(<span class="hljs-string"><span class="hljs-string">" "</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: print(<span class="hljs-string"><span class="hljs-string">"There was an error with the regex search"</span></span>) result = [x.strip() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] result = [x.replace(<span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] res = <span class="hljs-string"><span class="hljs-string">','</span></span>.join(result) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> res <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Split</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, element)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime element = element.split(<span class="hljs-string"><span class="hljs-string">","</span></span>) d = datetime.strptime(element[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-string"><span class="hljs-string">"%d/%b/%Y:%H:%M:%S"</span></span>) date_string = d.strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d %H:%M:%S"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [{ <span class="hljs-string"><span class="hljs-string">'remote_addr'</span></span>: element[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-string"><span class="hljs-string">'timelocal'</span></span>: date_string, <span class="hljs-string"><span class="hljs-string">'request_type'</span></span>: element[<span class="hljs-number"><span class="hljs-number">2</span></span>], <span class="hljs-string"><span class="hljs-string">'body_bytes_sent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-string"><span class="hljs-string">'status'</span></span>: element[<span class="hljs-number"><span class="hljs-number">4</span></span>], <span class="hljs-string"><span class="hljs-string">'http_referer'</span></span>: element[<span class="hljs-number"><span class="hljs-number">5</span></span>], <span class="hljs-string"><span class="hljs-string">'http_user_agent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">6</span></span>] }] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(argv=None)</span></span></span><span class="hljs-function">:</span></span> parser = argparse.ArgumentParser() parser.add_argument(<span class="hljs-string"><span class="hljs-string">"--input_topic"</span></span>) parser.add_argument(<span class="hljs-string"><span class="hljs-string">"--output"</span></span>) known_args = parser.parse_known_args(argv) p = beam.Pipeline(options=PipelineOptions()) (p | <span class="hljs-string"><span class="hljs-string">'ReadData'</span></span> &gt;&gt; beam.io.ReadFromPubSub(topic=TOPIC).with_output_types(bytes) | <span class="hljs-string"><span class="hljs-string">"Decode"</span></span> &gt;&gt; beam.Map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x.decode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>)) | <span class="hljs-string"><span class="hljs-string">"Clean Data"</span></span> &gt;&gt; beam.Map(regex_clean) | <span class="hljs-string"><span class="hljs-string">'ParseCSV'</span></span> &gt;&gt; beam.ParDo(Split()) | <span class="hljs-string"><span class="hljs-string">'WriteToBigQuery'</span></span> &gt;&gt; beam.io.WriteToBigQuery(<span class="hljs-string"><span class="hljs-string">'{0}:userlogs.logdata'</span></span>.format(PROJECT), schema=schema, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND) ) result = p.run() result.wait_until_finish() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: logger = logging.getLogger().setLevel(logging.INFO) main()</code> </pre><br><h2>  Förderstart </h2><br>  Wir können die Pipeline auf verschiedene Arten starten.  Wenn wir wollten, konnten wir es einfach lokal vom Terminal aus ausführen und uns remote bei GCP anmelden. <br><br><pre> <code class="python hljs">python -m main_pipeline_stream.py \ --input_topic <span class="hljs-string"><span class="hljs-string">"projects/user-logs-237110/topics/userlogs"</span></span> \ --streaming</code> </pre> <br>  Wir werden es jedoch mit DataFlow starten.  Wir können dies mit dem folgenden Befehl tun, indem wir die folgenden erforderlichen Parameter einstellen. <br><br><ul><li>  <code>project</code> - Die ID Ihres GCP-Projekts. </li><li>  <code>runner</code> ist ein Pipeline- <code>runner</code> , der Ihr Programm analysiert und Ihre Pipeline erstellt.  Um in der Cloud ausgeführt zu werden, müssen Sie einen DataflowRunner angeben. </li><li>  <code>staging_location</code> - Der Pfad zum Cloud Dataflow-Cloud-Speicher zum Indizieren der von den Prozesshandlern benötigten Codepakete. </li><li>  <code>temp_location</code> - Der Pfad zum Cloud-Datenfluss zum Speichern temporärer <code>temp_location</code> die während des Betriebs der Pipeline erstellt wurden. </li><li> <code>streaming</code> </li> </ul><br><pre> <code class="python hljs">python main_pipeline_stream.py \ --runner DataFlow \ --project $PROJECT \ --temp_location $BUCKET/tmp \ --staging_location $BUCKET/staging --streaming</code> </pre><br>  Während dieser Befehl ausgeführt wird, können wir in der Google-Konsole zur Registerkarte DataFlow wechseln und unsere Pipeline anzeigen.  Wenn Sie auf die Pipeline klicken, wird etwas Ähnliches wie in Abbildung 4 angezeigt. Für Debugging-Zwecke kann es sehr nützlich sein, zu den Protokollen und dann zu Stackdriver zu gehen, um detaillierte Protokolle anzuzeigen.  Dies hat mir in einigen Fällen geholfen, Probleme mit der Pipeline zu lösen. <br><br><img src="https://habrastorage.org/webt/7p/ai/vu/7paivucaa-lfkgvfzta6aozjs1q.png"><br>  <i>Abbildung 4: Strahlförderer</i> <br><br><h2>  Greifen Sie in BigQuery auf unsere Daten zu </h2><br>  Wir hätten die Pipeline also bereits mit den Daten starten sollen, die in unsere Tabelle eingehen.  Um dies zu testen, können wir zu BigQuery gehen und die Daten anzeigen.  Nachdem Sie den folgenden Befehl verwendet haben, sollten Sie die ersten Zeilen des Datensatzes sehen.  Nachdem wir die Daten in BigQuery gespeichert haben, können wir weitere Analysen durchführen, Daten mit Kollegen teilen und geschäftliche Fragen beantworten. <br><br><pre> <code class="python hljs">SELECT * FROM `user-logs<span class="hljs-number"><span class="hljs-number">-237110.</span></span>userlogs.logdata` LIMIT <span class="hljs-number"><span class="hljs-number">10</span></span>;</code> </pre> <br><img src="https://habrastorage.org/webt/ch/je/x_/chjex_xkpbc61hjrcft2qq06uuo.png"><br>  <i>Abbildung 5: BigQuery</i> <br><br><h2>  Fazit </h2><br>  Wir hoffen, dass dieser Beitrag als nützliches Beispiel für die Erstellung einer Streaming-Datenpipeline sowie für die Suche nach Möglichkeiten zum besseren Zugriff auf Daten dient.  Das Speichern von Daten in diesem Format bietet uns viele Vorteile.  Jetzt können wir wichtige Fragen beantworten, zum Beispiel, wie viele Menschen unser Produkt verwenden.  Wächst die Benutzerbasis im Laufe der Zeit?  Mit welchen Aspekten des Produkts interagieren die Menschen am meisten?  Und gibt es Fehler, wo sie nicht sein sollten?  Dies sind Themen, die für die Organisation von Interesse sind.  Basierend auf den Ideen, die sich aus den Antworten auf diese Fragen ergeben, können wir das Produkt verbessern und das Interesse der Benutzer erhöhen. <br><br>  Beam ist für diese Art von Übung sehr nützlich und hat auch eine Reihe anderer interessanter Anwendungsfälle.  Sie können beispielsweise die Daten von Exchange-Ticks in Echtzeit analysieren und basierend auf der Analyse Transaktionen durchführen. Möglicherweise verfügen Sie über Sensordaten von Fahrzeugen und möchten die Berechnung des Verkehrsaufkommens berechnen.  Sie können beispielsweise auch ein Spieleunternehmen sein, das Benutzerdaten sammelt und daraus Dashboards zur Verfolgung wichtiger Kennzahlen erstellt.  Okay, meine Herren, dieses Thema ist bereits für einen anderen Beitrag gedacht, danke fürs Lesen und für diejenigen, die den vollständigen Code sehen möchten, ist unten ein Link zu meinem GitHub. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/DFoly/User_log_pipeline</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><br></a> <br><br>  Das ist alles.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lesen Sie den ersten Teil</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de462589/">https://habr.com/ru/post/de462589/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de462577/index.html">Meine Nim-Entwicklungserfahrung</a></li>
<li><a href="../de462581/index.html">Wie wir das erste elektronische Leasing organisiert haben und wozu es geführt hat</a></li>
<li><a href="../de462583/index.html">Lernen Sie den deterministischen Garbage Collector-Zeiger kennen</a></li>
<li><a href="../de462585/index.html">Schnelle CRUD-Erstellung mit nest, @ nestjsx / crud und TestMace</a></li>
<li><a href="../de462587/index.html">AirTest IDE und Bilderkennung - Automatisierung des Testens von Handyspielen basierend auf Bilderkennung</a></li>
<li><a href="../de462593/index.html">Auf der anderen Seite des Standes</a></li>
<li><a href="../de462595/index.html">Prüfung und Prüfung von Briefen: Worauf Sie beim Layout achten sollten</a></li>
<li><a href="../de462597/index.html">Typoskript und reagieren</a></li>
<li><a href="../de462601/index.html">Sichern von Windows-Servern in AWS</a></li>
<li><a href="../de462605/index.html">Italienische Spur in der Kryptographie</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏻‍🔧 🎽 👊🏻 Pengenalan Cepat Menggambar Doodle: Cara Mencari Teman R, C ++, dan Neural Grids 🚒 🕴️ 👨🏾‍⚕️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo, Habr! 

 Musim gugur yang lalu di Kaggle, sebuah kontes diadakan untuk klasifikasi gambar Quick Draw Doodle Recognition yang digambar tangan, di...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengenalan Cepat Menggambar Doodle: Cara Mencari Teman R, C ++, dan Neural Grids</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/443758/"><img src="https://habrastorage.org/webt/cp/ir/jc/cpirjcgr-d52s_br1kqmvzkeawm.png"><br><br>  Halo, Habr! <br><br>  Musim gugur yang lalu di Kaggle, sebuah kontes diadakan untuk klasifikasi gambar Quick Draw Doodle Recognition yang digambar tangan, di mana, antara lain, sebuah tim R-schiks yang terdiri dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Artem Klevtsov</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Philip Upravitelev</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Andrey Ogurtsov ikut ambil bagian</a> .  Kami tidak akan menjelaskan persaingan secara rinci, ini telah dilakukan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">publikasi terbaru</a> . <br><br>  Kali ini tidak ada medali dengan obat-obatan pertanian, tetapi banyak pengalaman berharga diperoleh, jadi saya ingin memberi tahu masyarakat tentang sejumlah hal yang paling menarik dan berguna tentang Kagl dan dalam pekerjaan sehari-hari.  Di antara topik yang dibahas: kehidupan sulit tanpa <strong>OpenCV</strong> , penguraian JSON (contoh-contoh ini <strong>menunjukkan</strong> integrasi kode C ++ ke dalam skrip atau paket dalam R menggunakan <strong>Rcpp</strong> ), parameterisasi skrip dan dockerisasi dari solusi akhir.  Semua kode dari pesan dalam bentuk yang sesuai untuk diluncurkan tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">repositori</a> . <br><br><h3>  Konten: </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pemuatan data yang efektif dari CSV ke basis data MonetDB</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Persiapan batch</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Iterator untuk membongkar bets dari database</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pemilihan arsitektur model</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Parameterisasi Skrip</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Script docking</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Menggunakan banyak GPU di Google Cloud</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Alih-alih sebuah kesimpulan</a> </li></ol><a name="habracut"></a><br><h4 id="section1">  1. Pemuatan data yang efektif dari CSV ke basis data MonetDB </h4><br><p>  Data dalam kompetisi ini tidak disediakan dalam bentuk gambar siap pakai, tetapi dalam bentuk 340 file CSV (satu file untuk setiap kelas) yang berisi JSON dengan koordinat titik.  Menghubungkan titik-titik ini dengan garis, kita mendapatkan gambar akhir dengan ukuran 256x256 piksel.  Juga, untuk setiap catatan, label diberikan apakah gambar dikenali dengan benar oleh pengklasifikasi yang digunakan pada saat kumpulan data dikumpulkan, kode dua huruf dari negara tempat tinggal penulis, pengidentifikasi unik, cap waktu, dan nama kelas yang cocok dengan nama file.  Versi sederhana dari sumber data berbobot 7,4 GB dalam arsip dan sekitar 20 GB setelah membongkar, data lengkap setelah membongkar membutuhkan 240 GB.  Penyelenggara menjamin bahwa kedua versi mereproduksi gambar yang sama, yaitu versi lengkapnya berlebihan.  Bagaimanapun, menyimpan 50 juta gambar dalam file grafik atau dalam array segera dianggap tidak menguntungkan, dan kami memutuskan untuk menggabungkan semua file CSV dari arsip <em>train_simplified.zip</em> ke dalam database dengan generasi berikutnya gambar dengan ukuran yang tepat dengan cepat untuk setiap batch . </p><br><p>  <strong>MonetDB yang</strong> sudah mapan dipilih sebagai DBMS, yaitu implementasi untuk R dalam bentuk paket <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MonetDBLite</a></strong> .  Paket termasuk versi tertanam dari server database dan memungkinkan Anda untuk mengangkat server langsung dari sesi-R dan bekerja dengannya di sana.  Membuat database dan menghubungkannya dilakukan oleh satu perintah: </p><br><pre><code class="plaintext hljs">con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR"))</code> </pre> <br><p>  Kita perlu membuat dua tabel: satu untuk semua data, yang lain untuk informasi overhead tentang file yang diunduh (berguna jika terjadi kesalahan dan proses harus dilanjutkan setelah memuat beberapa file): </p><br><div class="spoiler">  <b class="spoiler_title">Buat tabel</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">if (!DBI::dbExistsTable(con, "doodles")) { DBI::dbCreateTable( con = con, name = "doodles", fields = c( "countrycode" = "char(2)", "drawing" = "text", "key_id" = "bigint", "recognized" = "bool", "timestamp" = "timestamp", "word" = "text" ) ) } if (!DBI::dbExistsTable(con, "upload_log")) { DBI::dbCreateTable( con = con, name = "upload_log", fields = c( "id" = "serial", "file_name" = "text UNIQUE", "uploaded" = "bool DEFAULT false" ) ) }</code> </pre> </div></div><br><p>  Cara tercepat untuk memuat data ke dalam database adalah dengan secara langsung menyalin file CSV menggunakan SQL - perintah <code>COPY OFFSET 2 INTO tablename FROM path USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT</code> , di mana <code>tablename</code> adalah nama tabel dan <code>path</code> adalah path ke file. Kemudian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">,</a> cara lain untuk meningkatkan kecepatan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ditemukan</a> : cukup ganti <code>BEST EFFORT</code> dengan <code>LOCKED BEST EFFORT</code> . Ketika bekerja dengan arsip, ternyata implementasi <code>unzip</code> di R tidak bekerja dengan benar dengan sejumlah file dari arsip, jadi kami menggunakan <code>unzip</code> sistem (menggunakan <code>getOption("unzip")</code> ). </p><br><div class="spoiler">  <b class="spoiler_title">Berfungsi untuk menulis ke database</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#' @title     #' #' @description #'  CSV-  ZIP-       #' #' @param con      ( `MonetDBEmbeddedConnection`). #' @param tablename     . #' @oaram zipfile   ZIP-. #' @oaram filename    ZIP-. #' @param preprocess  ,      . #'     `data` ( `data.table`). #' #' @return `TRUE`. #' upload_file &lt;- function(con, tablename, zipfile, filename, preprocess = NULL) { #   checkmate::assert_class(con, "MonetDBEmbeddedConnection") checkmate::assert_string(tablename) checkmate::assert_string(filename) checkmate::assert_true(DBI::dbExistsTable(con, tablename)) checkmate::assert_file_exists(zipfile, access = "r", extension = "zip") checkmate::assert_function(preprocess, args = c("data"), null.ok = TRUE) #   path &lt;- file.path(tempdir(), filename) unzip(zipfile, files = filename, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) on.exit(unlink(file.path(path))) #    if (!is.null(preprocess)) { .data &lt;- data.table::fread(file = path) .data &lt;- preprocess(data = .data) data.table::fwrite(x = .data, file = path, append = FALSE) rm(.data) } #      CSV sql &lt;- sprintf( "COPY OFFSET 2 INTO %s FROM '%s' USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT", tablename, path ) #     DBI::dbExecute(con, sql) #         DBI::dbExecute(con, sprintf("INSERT INTO upload_log(file_name, uploaded) VALUES('%s', true)", filename)) return(invisible(TRUE)) }</code> </pre> </div></div><br><p>  Jika Anda perlu mengonversi tabel sebelum menulis ke database, cukup untuk melewatkan fungsi yang akan mengubah data menjadi argumen <code>preprocess</code> . </p><br><p>  Kode untuk pemuatan berurutan data ke dalam basis data: </p><br><div class="spoiler">  <b class="spoiler_title">Menulis data ke basis data</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     files &lt;- unzip(zipfile, list = TRUE)$Name #  ,       to_skip &lt;- DBI::dbGetQuery(con, "SELECT file_name FROM upload_log")[[1L]] files &lt;- setdiff(files, to_skip) if (length(files) &gt; 0L) { #   tictoc::tic() #   pb &lt;- txtProgressBar(min = 0L, max = length(files), style = 3) for (i in seq_along(files)) { upload_file(con = con, tablename = "doodles", zipfile = zipfile, filename = files[i]) setTxtProgressBar(pb, i) } close(pb) #   tictoc::toc() } # 526.141 sec elapsed -  SSD-&gt;SSD # 558.879 sec elapsed -  USB-&gt;SSD</code> </pre> </div></div><br><p>  Waktu pemuatan data dapat bervariasi tergantung pada karakteristik kecepatan drive yang digunakan.  Dalam kasus kami, membaca dan menulis dalam SSD yang sama atau dari drive flash USB (file sumber) ke SSD (DB) membutuhkan waktu kurang dari 10 menit. </p><br><p>  Diperlukan beberapa detik lagi untuk membuat kolom dengan label kelas integer dan kolom indeks ( <code>ORDERED INDEX</code> ) dengan nomor baris, yang akan digunakan untuk memilih kasus saat membuat kumpulan: </p><br><div class="spoiler">  <b class="spoiler_title">Buat kolom dan indeks tambahan</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">message("Generate lables") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD label_int int")) invisible(DBI::dbExecute(con, "UPDATE doodles SET label_int = dense_rank() OVER (ORDER BY word) - 1")) message("Generate row numbers") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD id serial")) invisible(DBI::dbExecute(con, "CREATE ORDERED INDEX doodles_id_ord_idx ON doodles(id)"))</code> </pre> </div></div><br><p>  Untuk mengatasi masalah membuat batch "on the fly" kami perlu mencapai kecepatan maksimum mengekstraksi string acak dari tabel <code>doodles</code> - <code>doodles</code> .  Untuk ini kami menggunakan 3 trik.  Yang pertama adalah untuk mengurangi dimensi dari jenis di mana ID pengamatan disimpan.  Dalam set data asli, tipe <code>bigint</code> diperlukan untuk menyimpan ID, tetapi jumlah pengamatan memungkinkan pemasangan pengidentifikasi mereka sama dengan nomor seri ke dalam tipe <code>int</code> .  Pencarian jauh lebih cepat.  Trik kedua adalah dengan menggunakan <code>ORDERED INDEX</code> - keputusan ini dibuat secara empiris, memilah-milah semua <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">opsi yang</a> tersedia.  Yang ketiga adalah menggunakan kueri parameterisasi.  Inti dari metode ini adalah untuk mengeksekusi perintah <code>PREPARE</code> sekali dan kemudian menggunakan ekspresi yang disiapkan saat membuat tumpukan dari jenis pertanyaan yang sama, tetapi dalam kenyataannya keuntungan dibandingkan dengan <code>SELECT</code> sederhana <code>SELECT</code> di bidang kesalahan statistik. </p><br><p>  Proses pengisian data mengkonsumsi tidak lebih dari 450 MB RAM.  Artinya, pendekatan yang dijelaskan memungkinkan Anda untuk memutar dataset dengan berat puluhan gigabyte pada hampir semua perangkat keras anggaran, termasuk beberapa komputer papan tunggal, yang cukup keren. </p><br><p>  Tetap melakukan pengukuran tingkat ekstraksi data (acak) dan mengevaluasi penskalaan saat pengambilan sampel dalam berbagai ukuran: </p><br><div class="spoiler">  <b class="spoiler_title">Database Benchmark</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(ggplot2) set.seed(0) #     con &lt;- DBI::dbConnect(MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) #        prep_sql &lt;- function(batch_size) { sql &lt;- sprintf("PREPARE SELECT id FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",")) res &lt;- DBI::dbSendQuery(con, sql) return(res) } #     fetch_data &lt;- function(rs, batch_size) { ids &lt;- sample(seq_len(n), batch_size) res &lt;- DBI::dbFetch(DBI::dbBind(rs, as.list(ids))) return(res) } #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { rs &lt;- prep_sql(batch_size) bench::mark( fetch_data(rs, batch_size), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 23.6ms 54.02ms 93.43ms 18.8 2.6s 49 # 2 32 38ms 84.83ms 151.55ms 11.4 4.29s 49 # 3 64 63.3ms 175.54ms 248.94ms 5.85 8.54s 50 # 4 128 83.2ms 341.52ms 496.24ms 3.00 16.69s 50 # 5 256 232.8ms 653.21ms 847.44ms 1.58 31.66s 50 # 6 512 784.6ms 1.41s 1.98s 0.740 1.1m 49 # 7 1024 681.7ms 2.72s 4.06s 0.377 2.16m 49 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/ys/oj/zq/ysojzqhr14wf8u9k1xsd6ecmlxc.png"><br><h4 id="section2">  2. Persiapan batch </h4><br><p>  Seluruh proses persiapan batch terdiri dari langkah-langkah berikut: </p><br><ol><li>  Parsing beberapa JSON yang berisi vektor garis dengan titik koordinat. </li><li>  Gambar garis-garis berwarna dengan koordinat titik-titik pada gambar dengan ukuran yang diinginkan (misalnya, 256x256 atau 128x128). </li><li>  Konversi gambar yang dihasilkan menjadi tensor. </li></ol><br><p>  Dalam kerangka kompetisi di antara kernel di Python, masalahnya diselesaikan terutama melalui <strong>OpenCV</strong> .  Salah satu analog paling sederhana dan paling jelas pada R akan terlihat seperti ini: </p><br><div class="spoiler">  <b class="spoiler_title">Terapkan JSON ke konversi tensor pada R</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">r_process_json_str &lt;- function(json, line.width = 3, color = TRUE, scale = 1) { #  JSON coords &lt;- jsonlite::fromJSON(json, simplifyMatrix = FALSE) tmp &lt;- tempfile() #       on.exit(unlink(tmp)) png(filename = tmp, width = 256 * scale, height = 256 * scale, pointsize = 1) #   plot.new() #    plot.window(xlim = c(256 * scale, 0), ylim = c(256 * scale, 0)) #   cols &lt;- if (color) rainbow(length(coords)) else "#000000" for (i in seq_along(coords)) { lines(x = coords[[i]][[1]] * scale, y = coords[[i]][[2]] * scale, col = cols[i], lwd = line.width) } dev.off() #    3-   res &lt;- png::readPNG(tmp) return(res) } r_process_json_vector &lt;- function(x, ...) { res &lt;- lapply(x, r_process_json_str, ...) #  3-     4-    res &lt;- do.call(abind::abind, c(res, along = 0)) return(res) }</code> </pre> </div></div><br><p>  Gambar dilakukan dengan menggunakan alat R standar dan disimpan ke PNG sementara yang disimpan dalam RAM (di Linux, direktori R sementara terletak di <code>/tmp</code> terpasang dalam RAM).  Kemudian file ini dibaca dalam bentuk array tiga dimensi dengan angka dalam rentang dari 0 hingga 1. Ini penting karena BMP yang lebih umum akan dibaca menjadi array mentah dengan kode warna hex. </p><br><p>  Uji hasilnya: </p><br><pre> <code class="plaintext hljs">zip_file &lt;- file.path("data", "train_simplified.zip") csv_file &lt;- "cat.csv" unzip(zip_file, files = csv_file, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) tmp_data &lt;- data.table::fread(file.path(tempdir(), csv_file), sep = ",", select = "drawing", nrows = 10000) arr &lt;- r_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/t3/n2/-u/t3n2-ugr5ilwsygdfsrwd52vspc.png"><br><p>  Batch itu sendiri akan dibentuk sebagai berikut: </p><br><pre> <code class="plaintext hljs">res &lt;- r_process_json_vector(tmp_data[1:4, drawing], scale = 0.5) str(res) # num [1:4, 1:128, 1:128, 1:3] 1 1 1 1 1 1 1 1 1 1 ... # - attr(*, "dimnames")=List of 4 # ..$ : NULL # ..$ : NULL # ..$ : NULL # ..$ : NULL</code> </pre> <br><p>  Implementasi ini bagi kami tampaknya kurang optimal, karena pembentukan batch besar membutuhkan banyak waktu, dan kami memutuskan untuk menggunakan pengalaman rekan-rekan kami menggunakan <strong>perpustakaan OpenCV yang</strong> kuat.  Pada saat itu, tidak ada paket siap pakai untuk R (tidak ada bahkan sekarang), jadi implementasi minimal dari fungsionalitas yang diperlukan dalam C ++ ditulis dengan integrasi ke dalam kode R menggunakan <strong>Rcpp</strong> . </p><br><p>  Untuk mengatasi masalah tersebut, paket dan pustaka berikut digunakan: </p><br><ol><li>  <strong>OpenCV</strong> untuk pencitraan dan gambar garis.  Kami menggunakan pustaka sistem dan file header pra-instal, serta tautan dinamis. </li><li>  <strong>xtensor</strong> untuk bekerja dengan array dan tensor multidimensi.  Kami menggunakan file header yang termasuk dalam paket-R dengan nama yang sama.  Perpustakaan memungkinkan Anda untuk bekerja dengan array multidimensi, baik dalam baris utama maupun urutan kolom utama. </li><li>  <strong>ndjson</strong> untuk parsing JSON.  Perpustakaan ini digunakan dalam <strong>xtensor</strong> secara otomatis ketika tersedia di proyek. </li><li>  <strong>RcppThread</strong> untuk mengatur pemrosesan multi-threaded dari vektor dari JSON.  Menggunakan file header yang disediakan oleh paket ini.  Paket ini berbeda dari <strong>RcppParallel yang</strong> lebih populer di antara hal-hal lain dengan mekanisme interupsi <strong>bawaannya</strong> . </li></ol><br><p>  Perlu dicatat bahwa <strong>xtensor</strong> ternyata hanya sebuah penemuan: selain memiliki fungsionalitas yang luas dan kinerja tinggi, pengembangnya ternyata cukup responsif dan segera dan secara terperinci menjawab pertanyaan yang muncul.  Dengan bantuan mereka, dimungkinkan untuk mengimplementasikan transformasi matriks OpenCV menjadi tensor xtensor, serta metode menggabungkan tensor gambar 3 dimensi menjadi tensor 4 dimensi dari dimensi yang benar (sebenarnya batch). </p><br><div class="spoiler">  <b class="spoiler_title">Materi Belajar untuk Rcpp, xtensor, dan RcppThread</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://thecoatlessprofessor.com/programming/unofficial-rcpp-api-documentation</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://docs.opencv.org/4.0.1/d7/dbd/group__imgproc.html</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://xtensor.readthedocs.io/en/latest/</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://xtensor.readthedocs.io/en/latest/file_loading.html#loading-json-data-into-xtensor</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://cran.r-project.org/web/packages/RcppThread/vignettes/RcppThread-vignette.pdf</a> </p></div></div><br><p>  Untuk mengkompilasi file menggunakan file sistem dan menghubungkan dinamis dengan perpustakaan yang diinstal dalam sistem, kami menggunakan mekanisme plug-in yang diimplementasikan dalam paket <strong>Rcpp</strong> .  Untuk menemukan path dan flag secara otomatis, kami menggunakan utilitas linux populer <strong>pkg-config</strong> . </p><br><div class="spoiler">  <b class="spoiler_title">Menerapkan Plugin Rcpp untuk Menggunakan Perpustakaan OpenCV</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">Rcpp::registerPlugin("opencv", function() { #    pkg_config_name &lt;- c("opencv", "opencv4") #    pkg-config pkg_config_bin &lt;- Sys.which("pkg-config") #      checkmate::assert_file_exists(pkg_config_bin, access = "x") #     OpenCV  pkg-config check &lt;- sapply(pkg_config_name, function(pkg) system(paste(pkg_config_bin, pkg))) if (all(check != 0)) { stop("OpenCV config for the pkg-config not found", call. = FALSE) } pkg_config_name &lt;- pkg_config_name[check == 0] list(env = list( PKG_CXXFLAGS = system(paste(pkg_config_bin, "--cflags", pkg_config_name), intern = TRUE), PKG_LIBS = system(paste(pkg_config_bin, "--libs", pkg_config_name), intern = TRUE) )) })</code> </pre> </div></div><br><p>  Sebagai hasil dari plugin, selama kompilasi, nilai-nilai berikut akan diganti: </p><br><pre> <code class="plaintext hljs">Rcpp:::.plugins$opencv()$env # $PKG_CXXFLAGS # [1] "-I/usr/include/opencv" # # $PKG_LIBS # [1] "-lopencv_shape -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_datasets -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_line_descriptor -lopencv_optflow -lopencv_video -lopencv_plot -lopencv_reg -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_rgbd -lopencv_viz -lopencv_surface_matching -lopencv_text -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_flann -lopencv_xobjdetect -lopencv_objdetect -lopencv_ml -lopencv_xphoto -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_photo -lopencv_imgproc -lopencv_core"</code> </pre> <br><p>  Kode untuk mengimplementasikan parsing JSON dan membuat batch untuk mentransfer ke model diberikan di bawah spoiler.  Pertama, tambahkan direktori proyek lokal untuk mencari file header (diperlukan untuk ndjson): </p><br><pre> <code class="plaintext hljs">Sys.setenv("PKG_CXXFLAGS" = paste0("-I", normalizePath(file.path("src"))))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Menerapkan JSON ke konversi tensor di C ++</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">// [[Rcpp::plugins(cpp14)]] // [[Rcpp::plugins(opencv)]] // [[Rcpp::depends(xtensor)]] // [[Rcpp::depends(RcppThread)]] #include &lt;xtensor/xjson.hpp&gt; #include &lt;xtensor/xadapt.hpp&gt; #include &lt;xtensor/xview.hpp&gt; #include &lt;xtensor-r/rtensor.hpp&gt; #include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;opencv2/imgproc/imgproc.hpp&gt; #include &lt;Rcpp.h&gt; #include &lt;RcppThread.h&gt; //    using RcppThread::parallelFor; using json = nlohmann::json; using points = xt::xtensor&lt;double,2&gt;; //   JSON   using strokes = std::vector&lt;points&gt;; //   JSON   using xtensor3d = xt::xtensor&lt;double, 3&gt;; //      using xtensor4d = xt::xtensor&lt;double, 4&gt;; //      using rtensor3d = xt::rtensor&lt;double, 3&gt;; //     R using rtensor4d = xt::rtensor&lt;double, 4&gt;; //     R //   //     const static int SIZE = 256; //   // . https://en.wikipedia.org/wiki/Pixel_connectivity#2-dimensional const static int LINE_TYPE = cv::LINE_4; //     const static int LINE_WIDTH = 3; //   // https://docs.opencv.org/3.1.0/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121 const static int RESIZE_TYPE = cv::INTER_LINEAR; //    OpenCV-   template &lt;typename T, int NCH, typename XT=xt::xtensor&lt;T,3,xt::layout_type::column_major&gt;&gt; XT to_xt(const cv::Mat_&lt;cv::Vec&lt;T, NCH&gt;&gt;&amp; src) { //    std::vector&lt;int&gt; shape = {src.rows, src.cols, NCH}; //      size_t size = src.total() * NCH; //  cv::Mat  xt::xtensor XT res = xt::adapt((T*) src.data, size, xt::no_ownership(), shape); return res; } //  JSON     strokes parse_json(const std::string&amp; x) { auto j = json::parse(x); //      if (!j.is_array()) { throw std::runtime_error("'x' must be JSON array."); } strokes res; res.reserve(j.size()); for (const auto&amp; a: j) { //      2-  if (!a.is_array() || a.size() != 2) { throw std::runtime_error("'x' must include only 2d arrays."); } //    auto p = a.get&lt;points&gt;(); res.push_back(p); } return res; } //   //  HSV cv::Mat ocv_draw_lines(const strokes&amp; x, bool color = true) { //    auto stype = color ? CV_8UC3 : CV_8UC1; //    auto dtype = color ? CV_32FC3 : CV_32FC1; auto bg = color ? cv::Scalar(0, 0, 255) : cv::Scalar(255); auto col = color ? cv::Scalar(0, 255, 220) : cv::Scalar(0); cv::Mat img = cv::Mat(SIZE, SIZE, stype, bg); //   size_t n = x.size(); for (const auto&amp; s: x) { //     size_t n_points = s.shape()[1]; for (size_t i = 0; i &lt; n_points - 1; ++i) { //    cv::Point from(s(0, i), s(1, i)); //    cv::Point to(s(0, i + 1), s(1, i + 1)); //   cv::line(img, from, to, col, LINE_WIDTH, LINE_TYPE); } if (color) { //    col[0] += 180 / n; } } if (color) { //     RGB cv::cvtColor(img, img, cv::COLOR_HSV2RGB); } //     float32   [0, 1] img.convertTo(img, dtype, 1 / 255.0); return img; } //  JSON       xtensor3d process(const std::string&amp; x, double scale = 1.0, bool color = true) { auto p = parse_json(x); auto img = ocv_draw_lines(p, color); if (scale != 1) { cv::Mat out; cv::resize(img, out, cv::Size(), scale, scale, RESIZE_TYPE); cv::swap(img, out); out.release(); } xtensor3d arr = color ? to_xt&lt;double,3&gt;(img) : to_xt&lt;double,1&gt;(img); return arr; } // [[Rcpp::export]] rtensor3d cpp_process_json_str(const std::string&amp; x, double scale = 1.0, bool color = true) { xtensor3d res = process(x, scale, color); return res; } // [[Rcpp::export]] rtensor4d cpp_process_json_vector(const std::vector&lt;std::string&gt;&amp; x, double scale = 1.0, bool color = false) { size_t n = x.size(); size_t dim = floor(SIZE * scale); size_t channels = color ? 3 : 1; xtensor4d res({n, dim, dim, channels}); parallelFor(0, n, [&amp;x, &amp;res, scale, color](int i) { xtensor3d tmp = process(x[i], scale, color); auto view = xt::view(res, i, xt::all(), xt::all(), xt::all()); view = tmp; }); return res; }</code> </pre> </div></div><br><p>  Kode ini harus ditempatkan dalam file <code>src/cv_xt.cpp</code> dan dikompilasi dengan perintah <code>Rcpp::sourceCpp(file = "src/cv_xt.cpp", env = .GlobalEnv)</code> ;  Anda juga perlu <code>nlohmann/json.hpp</code> dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">repositori agar berfungsi</a> .  Kode ini dibagi menjadi beberapa fungsi: </p><br><ul><li>  <code>to_xt</code> - fungsi templat untuk mengubah matriks gambar ( <code>cv::Mat</code> ) menjadi tensor <code>xt::xtensor</code> ; </li><li>  <code>parse_json</code> - fungsi mem-parsing string JSON, mengekstrak koordinat titik, mengemasnya menjadi vektor; </li><li>  <code>ocv_draw_lines</code> - <code>ocv_draw_lines</code> garis multi-warna dari vektor titik yang diterima; </li><li>  <code>process</code> - menggabungkan fungsi-fungsi di atas, dan juga menambahkan kemampuan untuk skala gambar yang dihasilkan; </li><li>  <code>cpp_process_json_str</code> - pembungkus atas fungsi <code>process</code> , yang mengekspor hasilnya ke objek-R (array multidimensi); </li><li>  <code>cpp_process_json_vector</code> - pembungkus atas fungsi <code>cpp_process_json_str</code> , yang memungkinkan Anda memproses vektor string dalam mode multithreaded. </li></ul><br><p>  Untuk menggambar garis multi-warna, model warna HSV digunakan, diikuti oleh konversi ke RGB.  Uji hasilnya: </p><br><pre> <code class="plaintext hljs">arr &lt;- cpp_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/23/mm/ro/23mmrob6qhnjgnsaqm-4mno159c.png"><br><div class="spoiler">  <b class="spoiler_title">Perbandingan kecepatan implementasi dalam R dan C ++</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">res_bench &lt;- bench::mark( r_process_json_str(tmp_data[4, drawing], scale = 0.5), cpp_process_json_str(tmp_data[4, drawing], scale = 0.5), check = FALSE, min_iterations = 100 ) #   cols &lt;- c("expression", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # expression min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r_process_json_str 3.49ms 3.55ms 4.47ms 273. 490ms 134 # 2 cpp_process_json_str 1.94ms 2.02ms 5.32ms 489. 497ms 243 library(ggplot2) #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { .data &lt;- tmp_data[sample(seq_len(.N), batch_size), drawing] bench::mark( r_process_json_vector(.data, scale = 0.5), cpp_process_json_vector(.data, scale = 0.5), min_iterations = 50, check = FALSE ) } ) res_bench[, cols] # expression batch_size min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r 16 50.61ms 53.34ms 54.82ms 19.1 471.13ms 9 # 2 cpp 16 4.46ms 5.39ms 7.78ms 192. 474.09ms 91 # 3 r 32 105.7ms 109.74ms 212.26ms 7.69 6.5s 50 # 4 cpp 32 7.76ms 10.97ms 15.23ms 95.6 522.78ms 50 # 5 r 64 211.41ms 226.18ms 332.65ms 3.85 12.99s 50 # 6 cpp 64 25.09ms 27.34ms 32.04ms 36.0 1.39s 50 # 7 r 128 534.5ms 627.92ms 659.08ms 1.61 31.03s 50 # 8 cpp 128 56.37ms 58.46ms 66.03ms 16.9 2.95s 50 # 9 r 256 1.15s 1.18s 1.29s 0.851 58.78s 50 # 10 cpp 256 114.97ms 117.39ms 130.09ms 8.45 5.92s 50 # 11 r 512 2.09s 2.15s 2.32s 0.463 1.8m 50 # 12 cpp 512 230.81ms 235.6ms 261.99ms 4.18 11.97s 50 # 13 r 1024 4s 4.22s 4.4s 0.238 3.5m 50 # 14 cpp 1024 410.48ms 431.43ms 462.44ms 2.33 21.45s 50 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = expression, color = expression)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() + scale_color_discrete(name = "", labels = c("cpp", "r")) + theme(legend.position = "bottom")</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/zq/if/sa/zqifsayhpqy-dujaijmn-brk058.png"><br><p>  Seperti yang Anda lihat, peningkatan kecepatan ternyata sangat signifikan, dan tidak mungkin untuk mengejar ketinggalan dengan kode C ++ dengan memparalelkan kode R. </p><br><h4 id="section3">  3. Iterator untuk membongkar bets dari database </h4><br><p>  R memiliki reputasi yang layak sebagai bahasa untuk memproses data yang terletak di RAM, sementara Python lebih ditandai oleh pemrosesan data iteratif, yang membuatnya mudah dan mudah untuk menerapkan perhitungan out-of-core (perhitungan menggunakan memori eksternal).  Klasik dan relevan bagi kita dalam konteks masalah yang dijelaskan, contoh perhitungan tersebut adalah jaringan saraf yang dalam, dilatih oleh metode gradient descent dengan perkiraan gradient pada setiap langkah dengan sebagian kecil pengamatan, atau mini-batch. </p><br><p>  Kerangka pembelajaran mendalam yang ditulis dengan Python memiliki kelas khusus yang mengimplementasikan iterator berdasarkan data: tabel, gambar dalam folder, format biner, dll. Anda dapat menggunakan opsi yang sudah jadi atau menulis sendiri untuk tugas-tugas tertentu.  Di R, kita dapat memanfaatkan sepenuhnya pustaka Keras Python dengan berbagai backend-nya menggunakan paket dengan nama yang sama, yang pada gilirannya bekerja di atas paket <strong>reticulate</strong> .  Yang terakhir ini layak mendapat artikel besar yang terpisah;  Ini tidak hanya memungkinkan Anda untuk menjalankan kode Python dari R, tetapi juga menyediakan transfer objek antara sesi R- dan Python, secara otomatis melakukan semua konversi jenis yang diperlukan. </p><br><p>  Kami menyingkirkan kebutuhan untuk menyimpan semua data dalam RAM karena penggunaan MonetDBLite, semua pekerjaan "jaringan saraf" akan dilakukan oleh kode Python asli, kami hanya perlu menulis iterator berdasarkan data, karena tidak ada siap untuk situasi seperti itu di R atau Python.       :              (  R      ).         R  numpy-,     <strong>keras</strong>   . </p><br><p>        : </p><br><div class="spoiler"> <b class="spoiler_title">     </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">train_generator &lt;- function(db_connection = con, samples_index, num_classes = 340, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_class(con, "DBIConnection") checkmate::assert_integerish(samples_index) checkmate::assert_count(num_classes) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) # ,          dt &lt;- data.table::data.table(id = sample(samples_index)) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] #       dt &lt;- dt[, if (.N == batch_size) .SD, keyby = batch] #   i &lt;- 1 #   max_i &lt;- dt[, max(batch)] #     sql &lt;- sprintf( "PREPARE SELECT drawing, label_int FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",") ) res &lt;- DBI::dbSendQuery(con, sql) #  keras::to_categorical to_categorical &lt;- function(x, num) { n &lt;- length(x) m &lt;- numeric(n * num) m[x * n + seq_len(n)] &lt;- 1 dim(m) &lt;- c(n, num) return(m) } #  function() { #    if (i &gt; max_i) { dt[, id := sample(id)] data.table::setkey(dt, batch) #   i &lt;&lt;- 1 max_i &lt;&lt;- dt[, max(batch)] } # ID    batch_ind &lt;- dt[batch == i, id] #   batch &lt;- DBI::dbFetch(DBI::dbBind(res, as.list(batch_ind)), n = -1) #   i &lt;&lt;- i + 1 #  JSON    batch_x &lt;- cpp_process_json_vector(batch$drawing, scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } batch_y &lt;- to_categorical(batch$label_int, num_classes) result &lt;- list(batch_x, batch_y) return(result) } }</code> </pre> </div></div><br><p>         ,   ,  ,  ,  ( <code>scale = 1</code>    256256 , <code>scale = 0.5</code> — 128128 ),   ( <code>color = FALSE</code>     ,   <code>color = TRUE</code>     )     ,   imagenet-.    ,       [0, 1]   [-1, 1],        <strong>keras</strong> . </p><br><p>      ,  <code>data.table</code>        <code>samples_index</code>   ,     ,   SQL-     .        <code>keras::to_categorical()</code> .       ,    ,      <code>steps_per_epoch</code>   <code>keras::fit_generator()</code> ,   <code>if (i &gt; max_i)</code>     . </p><br><p>          ,        ,  JSON- ( <code>cpp_process_json_vector()</code> ,   C++)   ,  .   one-hot    ,          ,     .         <code>data.table</code>     —   ""  <strong>data.table</strong>       -     R. </p><br><p>       Core i5   : </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(Rcpp) library(keras) library(ggplot2) source("utils/rcpp.R") source("utils/keras_iterator.R") con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) ind &lt;- seq_len(DBI::dbGetQuery(con, "SELECT count(*) FROM doodles")[[1L]]) num_classes &lt;- DBI::dbGetQuery(con, "SELECT max(label_int) + 1 FROM doodles")[[1L]] #     train_ind &lt;- sample(ind, floor(length(ind) * 0.995)) #     val_ind &lt;- ind[-train_ind] rm(ind) #   scale &lt;- 0.5 #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { it1 &lt;- train_generator( db_connection = con, samples_index = train_ind, num_classes = num_classes, batch_size = batch_size, scale = scale ) bench::mark( it1(), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 25ms 64.36ms 92.2ms 15.9 3.09s 49 # 2 32 48.4ms 118.13ms 197.24ms 8.17 5.88s 48 # 3 64 69.3ms 117.93ms 181.14ms 8.57 5.83s 50 # 4 128 157.2ms 240.74ms 503.87ms 3.85 12.71s 49 # 5 256 359.3ms 613.52ms 988.73ms 1.54 30.5s 47 # 6 512 884.7ms 1.53s 2.07s 0.674 1.11m 45 # 7 1024 2.7s 3.83s 5.47s 0.261 2.81m 44 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/w0/i6/jx/w0i6jxjhgwqs82fbazwxdquqe18.png"><br><p>     ,              (    32 ).       <code>/dev/shm</code> ,     .    ,  <code>/etc/fstab</code> ,     <code>tmpfs /dev/shm tmpfs defaults,size=25g 0 0</code> .     ,   <code>df -h</code> . </p><br><p>       ,       : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">test_generator &lt;- function(dt, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_data_table(dt) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] data.table::setkey(dt, batch) i &lt;- 1 max_i &lt;- dt[, max(batch)] #  function() { batch_x &lt;- cpp_process_json_vector(dt[batch == i, drawing], scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } result &lt;- list(batch_x) i &lt;&lt;- i + 1 return(result) } }</code> </pre> </div></div><br><h4 id="section4"> 4.    </h4><br><p>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mobilenet v1</a> ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> .      <strong>keras</strong> , ,      R.          :       <code>(batch, height, width, 3)</code> ,      .  Python   ,         ,    ( ,    keras- ): </p><br><div class="spoiler"> <b class="spoiler_title"> mobilenet v1</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(keras) top_3_categorical_accuracy &lt;- custom_metric( name = "top_3_categorical_accuracy", metric_fn = function(y_true, y_pred) { metric_top_k_categorical_accuracy(y_true, y_pred, k = 3) } ) layer_sep_conv_bn &lt;- function(object, filters, alpha = 1, depth_multiplier = 1, strides = c(2, 2)) { # NB! depth_multiplier != resolution multiplier # https://github.com/keras-team/keras/issues/10349 layer_depthwise_conv_2d( object = object, kernel_size = c(3, 3), strides = strides, padding = "same", depth_multiplier = depth_multiplier ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_conv_2d( filters = filters * alpha, kernel_size = c(1, 1), strides = c(1, 1) ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() } get_mobilenet_v1 &lt;- function(input_shape = c(224, 224, 1), num_classes = 340, alpha = 1, depth_multiplier = 1, optimizer = optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = c("categorical_crossentropy", top_3_categorical_accuracy)) { inputs &lt;- layer_input(shape = input_shape) outputs &lt;- inputs %&gt;% layer_conv_2d(filters = 32, kernel_size = c(3, 3), strides = c(2, 2), padding = "same") %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_sep_conv_bn(filters = 64, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(1, 1)) %&gt;% layer_global_average_pooling_2d() %&gt;% layer_dense(units = num_classes) %&gt;% layer_activation_softmax() model &lt;- keras_model( inputs = inputs, outputs = outputs ) model %&gt;% compile( optimizer = optimizer, loss = loss, metrics = metrics ) return(model) }</code> </pre> </div></div><br><p>    .    ,     , ,  .        ,    imagenet-.  ,   .  <code>get_config()</code>          ( <code>base_model_conf$layers</code> —  R- ),   <code>from_config()</code>      : </p><br><pre> <code class="plaintext hljs">base_model_conf &lt;- get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- from_config(base_model_conf)</code> </pre> <br><p>               <strong>keras</strong>     imagenet-    : </p><br><div class="spoiler"> <b class="spoiler_title">    </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">get_model &lt;- function(name = "mobilenet_v2", input_shape = NULL, weights = "imagenet", pooling = "avg", num_classes = NULL, optimizer = keras::optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = NULL, color = TRUE, compile = FALSE) { #   checkmate::assert_string(name) checkmate::assert_integerish(input_shape, lower = 1, upper = 256, len = 3) checkmate::assert_count(num_classes) checkmate::assert_flag(color) checkmate::assert_flag(compile) #     keras model_fun &lt;- get0(paste0("application_", name), envir = asNamespace("keras")) #      if (is.null(model_fun)) { stop("Model ", shQuote(name), " not found.", call. = FALSE) } base_model &lt;- model_fun( input_shape = input_shape, include_top = FALSE, weights = weights, pooling = pooling ) #    ,    if (!color) { base_model_conf &lt;- keras::get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- keras::from_config(base_model_conf) } predictions &lt;- keras::get_layer(base_model, "global_average_pooling2d_1")$output predictions &lt;- keras::layer_dense(predictions, units = num_classes, activation = "softmax") model &lt;- keras::keras_model( inputs = base_model$input, outputs = predictions ) if (compile) { keras::compile( object = model, optimizer = optimizer, loss = loss, metrics = metrics ) } return(model) }</code> </pre> </div></div><br><p>        .     :    <code>get_weights()</code>        R- ,       ( -       ),         <code>set_weights()</code> .       ,       ,      . </p><br><p>        mobilenet  1  2,   resnet34.         ,   SE-ResNeXt.  ,       ,       (  ). </p><br><h4 id="section5"> 5.   </h4><br><p>             ,    <strong><a href="">docopt</a></strong>  : </p><br><pre> <code class="plaintext hljs">doc &lt;- ' Usage: train_nn.R --help train_nn.R --list-models train_nn.R [options] Options: -h --help Show this message. -l --list-models List available models. -m --model=&lt;model&gt; Neural network model name [default: mobilenet_v2]. -b --batch-size=&lt;size&gt; Batch size [default: 32]. -s --scale-factor=&lt;ratio&gt; Scale factor [default: 0.5]. -c --color Use color lines [default: FALSE]. -d --db-dir=&lt;path&gt; Path to database directory [default: Sys.getenv("db_dir")]. -r --validate-ratio=&lt;ratio&gt; Validate sample ratio [default: 0.995]. -n --n-gpu=&lt;number&gt; Number of GPUs [default: 1]. ' args &lt;- docopt::docopt(doc)</code> </pre> <br><p>  <strong>docopt</strong>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">http://docopt.org/</a>  R.         <code>Rscript bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code>  <code>./bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code> ,   <code>train_nn.R</code>   (     <code>resnet50</code>     128128 ,       <code>/home/andrey/doodle_db</code> ).      ,       .     ,   <code>mobilenet_v2</code>    <strong>keras</strong>  R  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> -   R-  — ,  . </p><br><p>                  RStudio (      <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tfruns</a></strong> ).                ,     RStudio. </p><br><h4 id="section6"> 6.   </h4><br><p>                    .        R-    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> . </p><br><p>       « »,           .        ,    NVIDIA, CUDA+cuDNN    —    ,        <code>tensorflow/tensorflow:1.12.0-gpu</code> ,    R-. </p><br><p>  -  : </p><br><div class="spoiler"> <b class="spoiler_title">Dockerfile</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">FROM tensorflow/tensorflow:1.12.0-gpu MAINTAINER Artem Klevtsov &lt;aaklevtsov@gmail.com&gt; SHELL ["/bin/bash", "-c"] ARG LOCALE="en_US.UTF-8" ARG APT_PKG="libopencv-dev r-base r-base-dev littler" ARG R_BIN_PKG="futile.logger checkmate data.table rcpp rapidjsonr dbi keras jsonlite curl digest remotes" ARG R_SRC_PKG="xtensor RcppThread docopt MonetDBLite" ARG PY_PIP_PKG="keras" ARG DIRS="/db /app /app/data /app/models /app/logs" RUN source /etc/os-release &amp;&amp; \ echo "deb https://cloud.r-project.org/bin/linux/ubuntu ${UBUNTU_CODENAME}-cran35/" &gt; /etc/apt/sources.list.d/cran35.list &amp;&amp; \ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 &amp;&amp; \ add-apt-repository -y ppa:marutter/c2d4u3.5 &amp;&amp; \ add-apt-repository -y ppa:timsc/opencv-3.4 &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y locales &amp;&amp; \ locale-gen ${LOCALE} &amp;&amp; \ apt-get install -y --no-install-recommends ${APT_PKG} &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install.r /usr/local/bin/install.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install2.r /usr/local/bin/install2.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/installGithub.r /usr/local/bin/installGithub.r &amp;&amp; \ echo 'options(Ncpus = parallel::detectCores())' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ echo 'options(repos = c(CRAN = "https://cloud.r-project.org"))' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ apt-get install -y $(printf "r-cran-%s " ${R_BIN_PKG}) &amp;&amp; \ install.r ${R_SRC_PKG} &amp;&amp; \ pip install ${PY_PIP_PKG} &amp;&amp; \ mkdir -p ${DIRS} &amp;&amp; \ chmod 777 ${DIRS} &amp;&amp; \ rm -rf /tmp/downloaded_packages/ /tmp/*.rds &amp;&amp; \ rm -rf /var/lib/apt/lists/* COPY utils /app/utils COPY src /app/src COPY tests /app/tests COPY bin/*.R /app/ ENV DBDIR="/db" ENV CUDA_HOME="/usr/local/cuda" ENV PATH="/app:${PATH}" WORKDIR /app VOLUME /db VOLUME /app CMD bash</code> </pre></div></div><br><p>        ;         .       <code>/bin/bash</code>     <code>/etc/os-release</code> .         . </p><br><p>     -,      . ,       ,    ,          : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#!/bin/sh DBDIR=${PWD}/db LOGSDIR=${PWD}/logs MODELDIR=${PWD}/models DATADIR=${PWD}/data ARGS="--runtime=nvidia --rm -v ${DBDIR}:/db -v ${LOGSDIR}:/app/logs -v ${MODELDIR}:/app/models -v ${DATADIR}:/app/data" if [ -z "$1" ]; then CMD="Rscript /app/train_nn.R" elif [ "$1" = "bash" ]; then ARGS="${ARGS} -ti" else CMD="Rscript /app/train_nn.R $@" fi docker run ${ARGS} doodles-tf ${CMD}</code> </pre> </div></div><br><p>   -   ,      <code>train_nn.R</code>    ;     —  "bash",         .         : <code>CMD="Rscript /app/train_nn.R $@"</code> . </p><br><p>   ,        ,             ,           . </p><br><h4 id="section7"> 7.   GPU   Google Cloud </h4><br><p>         (.  ,   @Leigh.plt  ODS-).       ,        1 GPU       GPU  .  GoogleCloud ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">    </a> ) -    ,     $300.       4V100  SSD   ,     .     ,       .      K80.       —  SSD   c,          <code>dev/shm</code> . </p><br><p>     ,     GPU.     CPU    ,    : </p><br><pre> <code class="plaintext hljs">with(tensorflow::tf$device("/cpu:0"), { model_cpu &lt;- get_model( name = model_name, input_shape = input_shape, weights = weights, metrics =(top_3_categorical_accuracy, compile = FALSE ) })</code> </pre> <br><p>   ( )       GPU,     : </p><br><pre> <code class="plaintext hljs">model &lt;- keras::multi_gpu_model(model_cpu, gpus = n_gpu) keras::compile( object = model, optimizer = keras::optimizer_adam(lr = 0.0004), loss = "categorical_crossentropy", metrics = c(top_3_categorical_accuracy) )</code> </pre> <br><p>      ,  ,   ,        GPU   . </p><br><p>      <strong>tensorboard</strong> ,            : </p><br><div class="spoiler"> <b class="spoiler_title"></b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     log_file_tmpl &lt;- file.path("logs", sprintf( "%s_%d_%dch_%s.csv", model_name, dim_size, channels, format(Sys.time(), "%Y%m%d%H%M%OS") )) #     model_file_tmpl &lt;- file.path("models", sprintf( "%s_%d_%dch_{epoch:02d}_{val_loss:.2f}.h5", model_name, dim_size, channels )) callbacks_list &lt;- list( keras::callback_csv_logger( filename = log_file_tmpl ), keras::callback_early_stopping( monitor = "val_loss", min_delta = 1e-4, patience = 8, verbose = 1, mode = "min" ), keras::callback_reduce_lr_on_plateau( monitor = "val_loss", factor = 0.5, #  lr  2  patience = 4, verbose = 1, min_delta = 1e-4, mode = "min" ), keras::callback_model_checkpoint( filepath = model_file_tmpl, monitor = "val_loss", save_best_only = FALSE, save_weights_only = FALSE, mode = "min" ) )</code> </pre> </div></div><br><h4 id="section8"> 8.   </h4><br><p>  ,    ,    : </p><br><ul><li>  <strong>keras</strong>          ( <code>lr_finder</code>   <strong>fast.ai</strong> );   ,    R  , , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> ; </li><li>    ,          GPU; </li><li>     ,    imagenet-; </li><li>  one cycle policy  discriminative learning rates (osine annealing     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">skeydan</a> ). </li></ul><br><p>       : </p><br><ul><li>           (   )  .  <strong>data.table</strong>     in-place  ,     ,                   .                  . </li><li>    R     C++    <strong>Rcpp</strong> .    <strong>RcppThread</strong>  <strong>RcppParallel</strong> ,    ,     R   . </li><li>  <strong>Rcpp</strong>      C++,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> .         <strong>xtensor</strong>   CRAN,       ,   R     C++.   —        ++  RStudio. </li><li> <strong>docopt</strong>      .       ,  ..  .  RStudio       ,     IDE     . </li><li>               ,      .         . </li><li> Google Cloud —      ,     . </li><li>        ,    R  C++,    <strong>bench</strong> —    . </li></ul><br><p>       ,          . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id443758/">https://habr.com/ru/post/id443758/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id443746/index.html">Pasar Game, Tren dan Prediksi - Analisis Hebat dari App Annie</a></li>
<li><a href="../id443748/index.html">Presentasi Tesla Model Y - apa yang diharapkan dan ke mana harus mencari</a></li>
<li><a href="../id443752/index.html">Kotlin sebagai masa depan pengembangan aplikasi Android</a></li>
<li><a href="../id443754/index.html">Tentang kesesuaian Selenium WebDriverWait</a></li>
<li><a href="../id443756/index.html">Desain Kelas: Apa yang Baik?</a></li>
<li><a href="../id443764/index.html">Apa yang dihisap perancang: senjata api yang tidak biasa</a></li>
<li><a href="../id443766/index.html">Mencoba Pemrograman Kontrak C ++ 20 Sekarang</a></li>
<li><a href="../id443768/index.html">Monolith untuk ratusan versi klien: cara kami menulis dan memelihara tes</a></li>
<li><a href="../id443770/index.html">Desain Berbasis Domain: Objek Nilai dan Kerangka Entitas Inti dalam Praktek</a></li>
<li><a href="../id443772/index.html">Antiquities: IBM ThinkPad T40, nirkabel pertama</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
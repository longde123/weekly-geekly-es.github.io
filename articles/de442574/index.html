<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õìÔ∏è üë©üèΩ‚Äç‚úàÔ∏è üì≥ Die Grundlage f√ºr eine verallgemeinerte Theorie neuronaler Netze wird geschaffen üìç üôãüèª ü§î</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die enormen F√§higkeiten neuronaler Netze sind manchmal mit ihrer Unvorhersehbarkeit vergleichbar. Jetzt beginnen Mathematiker zu verstehen, wie sich d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Grundlage f√ºr eine verallgemeinerte Theorie neuronaler Netze wird geschaffen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/442574/"><h3>  Die enormen F√§higkeiten neuronaler Netze sind manchmal mit ihrer Unvorhersehbarkeit vergleichbar.  Jetzt beginnen Mathematiker zu verstehen, wie sich die Form eines neuronalen Netzwerks auf seine Arbeit auswirkt. </h3><br><br><img src="https://habrastorage.org/getpro/habr/post_images/856/cbb/518/856cbb5185fda3edec1e6c1096d9226b.jpg"><br><br>  Wenn wir einen Wolkenkratzer entwerfen, erwarten wir, dass er am Ende alle Spezifikationen erf√ºllt: dass der Turm einem solchen Gewicht sowie einem Erdbeben einer bestimmten St√§rke standhalten kann. <br><br>  Als eine der wichtigsten Technologien der modernen Welt entwerfen wir jedoch blind.  Wir spielen mit verschiedenen Schemata, verschiedenen Einstellungen, aber bis wir einen Testlauf des Systems starten, haben wir wirklich keine Ahnung, was es kann oder wo es sich weigert zu arbeiten. <br><a name="habracut"></a><br>  Es geht um neuronale Netzwerktechnologie, die den fortschrittlichsten modernen Systemen der k√ºnstlichen Intelligenz zugrunde liegt.  Neuronale Netze bewegen sich allm√§hlich in die grundlegendsten Bereiche der Gesellschaft: Sie bestimmen, was wir aus den Nachrichten in sozialen Netzwerken √ºber die Welt lernen, sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">helfen</a> √Ñrzten bei der Diagnose und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">beeinflussen</a> sogar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">,</a> ob ein Verbrecher ins Gef√§ngnis gebracht wird. <br><br>  Und "die beste Beschreibung dessen, was wir wissen, ist zu sagen, dass wir praktisch nichts dar√ºber wissen, wie die neuronalen Netze tats√§chlich funktionieren und wie die Theorie, die sie beschreibt, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aussehen</a> sollte", sagte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Boris Ganin</a> , Mathematiker an der Universit√§t von Texas. und ein Gastspezialist bei Facebook AI Research, der neuronale Netze studiert. <br><br>  Er vergleicht die Situation mit der Entwicklung einer weiteren revolution√§ren Technologie: einer Dampfmaschine.  Dampfmaschinen konnten zun√§chst nur Wasser pumpen.  Damals dienten sie als Motoren f√ºr Dampflokomotiven, und heute haben neuronale Netze wahrscheinlich etwa das gleiche Niveau erreicht.  Wissenschaftler und Mathematiker entwickelten eine Theorie der Thermodynamik, mit der sie verstehen konnten, was genau in einem Motor passiert.  Und am Ende brachte uns dieses Wissen in den Weltraum. <br><br>  "Zuerst gab es gro√üartige technische Erfolge, dann gro√üartige Z√ºge, und dann war ein theoretisches Verst√§ndnis erforderlich, um von diesem zu Raketen zu gelangen", sagte Ganin. <br><br>  In der wachsenden Gemeinschaft von Entwicklern neuronaler Netze gibt es eine kleine Gruppe von Forschern mit mathematischen Vorurteilen, die versuchen, eine Theorie neuronaler Netze zu erstellen, die ihre Funktionsweise erkl√§ren und sicherstellen kann, dass nach dem Erstellen eines neuronalen Netzes mit einer bestimmten Konfiguration bestimmte Aufgaben ausgef√ºhrt werden k√∂nnen. <br><br>  W√§hrend die Arbeit noch in einem fr√ºhen Stadium ist, haben Forscher im vergangenen Jahr bereits mehrere wissenschaftliche Arbeiten ver√∂ffentlicht, die die Beziehung zwischen der Form und der Funktionsweise neuronaler Netze detailliert beschreiben.  Die Arbeit beschreibt die neuronalen Netze bis zu ihren Grundlagen vollst√§ndig.  Sie zeigt, dass es lange bevor die F√§higkeit neuronaler Netze best√§tigt wird, Autos zu fahren, notwendig ist, ihre F√§higkeit zu beweisen, Zahlen zu multiplizieren. <br><br><h2>  Das beste Gehirnrezept </h2><br>  Neuronale Netze bem√ºhen sich, das menschliche Gehirn nachzuahmen - und eine M√∂glichkeit, seine Arbeit zu beschreiben, besteht darin, zu sagen, dass er kleine Abstraktionen zu gr√∂√üeren zusammenf√ºhrt.  Unter diesem Gesichtspunkt wird die Komplexit√§t von Gedanken an der Anzahl der kleinen Abstraktionen gemessen, die ihnen zugrunde liegen, und an der Anzahl der Kombinationen von Abstraktionen auf niedriger Ebene zu Abstraktionen auf hoher Ebene - beispielsweise bei der Untersuchung der Unterschiede zwischen Hunden und V√∂geln. <br><br>  "Wenn eine Person lernt, einen Hund zu erkennen, lernt sie, etwas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zotteliges</a> auf vier Beinen zu erkennen", sagte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Maitra Ragu</a> , eine Doktorandin der Informatik an der Cornell University, Mitglied des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Brain-</a> Teams.  "Idealerweise m√∂chten wir, dass unsere neuronalen Netze etwas √Ñhnliches tun." <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a42/4d2/17d/a424d217dd912526caaa61b33e30e36f.jpg"><br>  <i>Maitra Ragu</i> <br><br>  Abstraktion entsteht auf nat√ºrliche Weise im menschlichen Gehirn.  Daf√ºr m√ºssen neuronale Netze funktionieren.  Neuronale Netze bestehen wie das Gehirn aus Bausteinen, die als ‚ÄûNeuronen‚Äú bezeichnet werden und auf verschiedene Weise miteinander verbunden sind.  Gleichzeitig versuchen Neuronen des neuronalen Netzwerks, obwohl sie nach dem Vorbild von Gehirnneuronen hergestellt wurden, diese nicht vollst√§ndig nachzuahmen.  Jedes Neuron kann ein Attribut oder eine Kombination von Attributen darstellen, die das neuronale Netzwerk auf jeder Abstraktionsebene ber√ºcksichtigt. <br><br>  Ingenieure haben die Wahl zwischen vielen M√∂glichkeiten, diese Neuronen zu kombinieren.  Sie m√ºssen entscheiden, wie viele Schichten von Neuronen ein neuronales Netzwerk haben soll (dh seine ‚ÄûTiefe‚Äú bestimmen).  Stellen Sie sich zum Beispiel ein neuronales Netzwerk vor, das Bilder erkennt.  Das Bild ist in der ersten Schicht des Systems enthalten.  Auf der n√§chsten Schicht kann das Netzwerk Neuronen aufweisen, die einfach die Bildr√§nder erkennen.  Die n√§chste Ebene kombiniert die Linien und definiert die Kurven.  Der n√§chste kombiniert die Kurven zu Formen und Texturen, und der letzte verarbeitet die Formen und Texturen, um eine Entscheidung dar√ºber zu treffen, was er betrachtet: das pelzige Mammut! <br><br>  ‚ÄûDie Idee ist, dass jede Schicht mehrere Aspekte der vorherigen kombiniert.  Ein Kreis ist an vielen Stellen eine Kurve, eine Kurve ist an vielen Stellen eine Linie ‚Äú, sagt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">David Rolnik</a> , Mathematiker an der University of Pennsylvania. <br><br>  Ingenieure m√ºssen auch die ‚ÄûBreite‚Äú jeder Schicht ausw√§hlen, die der Anzahl der verschiedenen Funktionen entspricht, die das Netzwerk auf jeder Abstraktionsebene ber√ºcksichtigt.  Bei der Bilderkennung entspricht die Breite der Schichten der Anzahl der Arten von Linien, Kurven oder Formen, die das neuronale Netzwerk auf jeder Ebene ber√ºcksichtigt. <br><br>  Zus√§tzlich zur Tiefe und Breite des neuronalen Netzwerks gibt es eine Auswahl der Methode zum Verbinden von Neuronen in den Schichten und zwischen ihnen sowie eine Auswahl von Gewichten f√ºr jede der Verbindungen. <br><br>  Wenn Sie planen, eine bestimmte Aufgabe zu erledigen, woher wissen Sie, welche neuronale Netzwerkarchitektur sie am besten ausf√ºhren kann?  Es gibt ziemlich allgemeine Beispielregeln.  Bei Problemen mit der Bilderkennung verwenden Programmierer normalerweise "Faltungs" -Neuronale Netze, das System von Verbindungen zwischen Schichten, in denen sich Schicht f√ºr Schicht wiederholt.  Um eine nat√ºrliche Sprache zu verarbeiten - Spracherkennung oder Sprachgenerierung - haben Programmierer festgestellt, dass wiederkehrende neuronale Netze am besten geeignet sind.  Die Neuronen in ihnen k√∂nnen mit Neuronen nicht nur aus benachbarten Schichten verbunden werden. <br><br>  Au√üerhalb dieser allgemeinen Prinzipien m√ºssen sich Programmierer jedoch meist auf experimentelle Beweise verlassen: Sie betreiben einfach 1.000 verschiedene neuronale Netze und sehen, welches die Arbeit besser macht. <br><br>  "In der Praxis werden diese Entscheidungen oft durch Versuch und Irrtum getroffen", sagte Ganin.  "Dies ist ein ziemlich komplizierter Weg, da es unendlich viele Wahlen gibt und niemand wei√ü, welcher der beste sein wird." <br><br>  Die beste Option w√§re, sich weniger auf die Trial-and-Error-Methode als vielmehr auf das bereits vorhandene Verst√§ndnis dessen zu verlassen, was eine bestimmte neuronale Netzwerkarchitektur Ihnen bieten kann.  Mehrere k√ºrzlich ver√∂ffentlichte wissenschaftliche Arbeiten haben diesen Bereich in diese Richtung vorangetrieben. <br><br>  ‚ÄûDiese Arbeit zielt darauf ab, so etwas wie ein Rezeptbuch f√ºr den Entwurf eines geeigneten neuronalen Netzwerks zu erstellen.  Wenn Sie wissen, was Sie damit erreichen m√∂chten, k√∂nnen Sie das richtige Rezept ausw√§hlen ‚Äú, sagte Rolnik. <br><br><h2>  Lasso rote Schafe </h2><br>  Eine der fr√ºhesten theoretischen Garantien der neuronalen Netzwerkarchitektur erschien vor drei Jahrzehnten.  1989 hat ein Informatiker bewiesen, dass ein neuronales Netzwerk jede Aufgabe ausf√ºhren kann, wenn ein neuronales Netzwerk nur eine Rechenschicht hat, in der es eine unbegrenzte Anzahl von Neuronen und eine unbegrenzte Anzahl von Verbindungen zwischen ihnen geben kann. <br><br>  Dies war eine mehr oder weniger allgemeine Aussage, die sich als eher intuitiv und nicht besonders n√ºtzlich herausstellte.  Dies entspricht der Aussage, dass Sie alle Objekte mit nur einer Ebene unterscheiden k√∂nnen, wenn Sie eine unbegrenzte Anzahl von Linien in einem Bild definieren k√∂nnen.  Im Prinzip kann dies erf√ºllt sein, aber versuchen Sie es in die Praxis umzusetzen. <br><br>  Heutzutage bezeichnen Forscher solche breiten und flachen Netzwerke als "ausdrucksstark", weil sie theoretisch in der Lage sind, einen umfassenderen Satz von Beziehungen zwischen m√∂glichen Eingabedaten (wie einem Bild) und Ausgaben (wie einer Beschreibung eines Bildes) abzudecken.  Gleichzeitig ist es √§u√üerst schwierig, diese Netzwerke zu trainieren, das hei√üt, es ist praktisch unm√∂glich, sie dazu zu bringen, diese Daten tats√§chlich weiterzugeben.  Sie ben√∂tigen au√üerdem mehr Rechenleistung als jeder andere Computer. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1fa/99c/58e/1fa99c58e5bf806edb24c0c47a735a75.jpg"><br>  <i>Boris Ganin</i> <br><br>  In j√ºngster Zeit haben Forscher versucht zu verstehen, wie weit man neuronale Netze bringen kann, indem man in die entgegengesetzte Richtung geht - wodurch sie schmaler (weniger Neuronen pro Schicht) und tiefer (mehr Schichten) werden.  M√∂glicherweise k√∂nnen Sie nur 100 verschiedene Linien erkennen. Mit den Verbindungen, die erforderlich sind, um 100 dieser Linien in 50 Kurven umzuwandeln, die zu 10 verschiedenen Formen kombiniert werden k√∂nnen, erhalten Sie jedoch alle erforderlichen Bausteine, um die meisten Objekte zu erkennen. <br><br>  In der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit, die</a> sie letztes Jahr abgeschlossen haben, haben Rolnik und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Max Tegmark</a> vom MIT bewiesen, dass es durch Erh√∂hen der Tiefe und Verringern der Breite m√∂glich ist, dieselben Aufgaben mit einer exponentiell geringeren Anzahl von Neuronen auszuf√ºhren.  Sie zeigten, dass Sie, wenn die von Ihnen simulierte Situation 100 Eingabevariablen enth√§lt, dieselbe Zuverl√§ssigkeit erzielen k√∂nnen, indem Sie entweder <sup>2.100</sup> Neuronen in einer Schicht oder 2.10 Neuronen in zwei Schichten verwenden.  Sie stellten fest, dass es von Vorteil war, kleine Teile auf h√∂heren Abstraktionsebenen zu kombinieren, anstatt zu versuchen, alle Abstraktionsebenen gleichzeitig abzudecken. <br><br>  "Das Konzept der Tiefe des neuronalen Netzwerks ist mit der M√∂glichkeit verbunden, etwas Komplexes durch viele einfache Schritte auszudr√ºcken", sagte Rolnik.  "Es sieht aus wie ein Flie√üband." <br><br>  Rolnik und Tegmark haben die N√ºtzlichkeit der Tiefe bewiesen, indem sie neuronale Netze gezwungen haben, eine einfache Aufgabe auszuf√ºhren: Polynomfunktionen zu multiplizieren.  (Dies sind Gleichungen mit Variablen, die auf nat√ºrliche Grade angehoben sind, z. B. y = x <sup>3</sup> + 1).  Sie trainierten die Netzwerke und zeigten ihnen Beispiele f√ºr Gleichungen und die Ergebnisse ihrer Multiplikation.  Dann forderten sie die neuronalen Netze auf, das Ergebnis der Multiplikation von Gleichungen zu berechnen, die sie zuvor noch nicht gesehen hatten.  Tiefere neuronale Netze lernten dies mit viel weniger Neuronen als mit kleinen. <br><br>  Und obwohl es unwahrscheinlich ist, dass die Multiplikation unsere Welt auf den Kopf stellt, sagt Rolnik, dass in der Arbeit eine wichtige Idee beschrieben wurde: ‚ÄûWenn ein flaches neuronales Netzwerk nicht einmal multiplizieren kann, sollten Sie ihm nichts anderes anvertrauen.‚Äú <br><br><img src="https://habrastorage.org/getpro/habr/post_images/58d/189/b73/58d189b7307053cde31c537aa8bc5d33.jpg"><br>  <i>David Rolnik</i> <br><br>  Andere Forscher untersuchen das Problem der Mindestbreite.  Ende September <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bewies</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jesse Johnson</a> , ehemals Mathematiker an der Universit√§t von Oklahoma und jetzt Forscher des Pharmaunternehmens Sanofi, dass irgendwann keine Tiefe den Mangel an Breite ausgleichen konnte. <br><br>  Um dies zu verstehen, stellen Sie sich die L√§mmer auf dem Feld vor, aber lassen Sie sie L√§mmer aus Punkrock sein: Die Wolle von jedem von ihnen wird in einer von mehreren Farben bemalt.  Das neuronale Netzwerk sollte eine Grenze um alle Schafe derselben Farbe ziehen.  Im Wesentlichen √§hnelt diese Aufgabe der Klassifizierung von Bildern: Ein neuronales Netzwerk verf√ºgt √ºber eine Reihe von Bildern (die es als Punkte in einem mehrdimensionalen Raum darstellt) und muss √§hnliche gruppieren. <br><br>  Johnson hat bewiesen, dass das neuronale Netzwerk diese Aufgabe nicht bew√§ltigen kann, wenn die Breite der Schichten kleiner oder gleich der Menge der Eingabedaten ist.  Jedes unserer Schafe kann durch zwei Eingabedaten beschrieben werden: die Koordinaten seiner Position auf dem Feld, x und y.  Dann markiert das neuronale Netzwerk jedes Schaf mit Farbe und zeichnet einen Rand um die Schafe derselben Farbe.  In diesem Fall ben√∂tigen Sie zur L√∂sung des Problems mindestens drei Neuronen pro Schicht. <br><br>  Insbesondere hat Johnson gezeigt, dass das neuronale Netzwerk keine geschlossenen Schleifen zeichnen kann, wenn das Verh√§ltnis der Breite zur Anzahl der Variablen nicht ausreicht - und ein neuronales Netzwerk m√ºsste eine solche Schleife zeichnen, wenn sich beispielsweise alle roten Schafe in der Mitte der Weide angesammelt h√§tten.  "Wenn keine der Schichten dicker als die Anzahl der Eingabemessungen ist, kann die Funktion unabh√§ngig von der Anzahl der Schichten keine Formulare erstellen", sagte Johnson. <br><br>  Solche Arbeiten bilden den Kern der Theorie neuronaler Netze.  Bisher k√∂nnen Forscher nur die einfachsten Aussagen zum Verh√§ltnis von Architektur und Funktionalit√§t treffen - und diese Aussagen sind im Vergleich zur Anzahl der von neuronalen Netzen gel√∂sten Aufgaben sehr gering. <br><br>  Obwohl die Theorie der neuronalen Netze in naher Zukunft den Entwurfsprozess nicht √§ndern kann, werden Blaupausen f√ºr eine neue Theorie der Computerausbildung erstellt - und ihre Konsequenzen werden noch st√§rker sein als die einer Person, die in den Weltraum geht. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de442574/">https://habr.com/ru/post/de442574/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de442562/index.html">So k√ºhlen Sie Ger√§te in einem Rechenzentrum - drei neue Technologien</a></li>
<li><a href="../de442566/index.html">Wie auf dem Mond: Reverse Engineering eines Hybrid-Operationsverst√§rkermoduls</a></li>
<li><a href="../de442568/index.html">Sicherheitswoche 10: Sicherheitsl√ºcken bei NVIDIA-Treibern</a></li>
<li><a href="../de442570/index.html">Sigma Regeln. Handwerk oder neuer Standard f√ºr SOC</a></li>
<li><a href="../de442572/index.html">Verwenden des Datapath Config Tools</a></li>
<li><a href="../de442576/index.html">Es lebe der Overclocker: Wie die Fl√ºssigkeitsk√ºhlung in Rechenzentren zu dominieren begann</a></li>
<li><a href="../de442578/index.html">Linux 5.0 Release</a></li>
<li><a href="../de442580/index.html">Reverse Engineering im Bin√§rformat am Beispiel von Korg .SNG-Dateien</a></li>
<li><a href="../de442582/index.html">Wie wir es mit Mobbing versucht haben</a></li>
<li><a href="../de442584/index.html">Dokumente zum Geb√§ude: kleine Freuden der Automatisierung am Beispiel des Dunklen Turms</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë£ üíó üóÇÔ∏è BigData fait maison. Partie 1. Pratique Spark Streaming sur un cluster AWS üè† ‚ûø üë©üèø‚Äçü§ù‚Äçüë©üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour 

 Il existe de nombreux services sur Internet qui fournissent des services cloud. Avec leur aide, vous pouvez apprendre la technologie de Big...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>BigData fait maison. Partie 1. Pratique Spark Streaming sur un cluster AWS</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/homecredit/blog/452752/">  Bonjour <br><br>  Il existe de nombreux services sur Internet qui fournissent des services cloud.  Avec leur aide, vous pouvez apprendre la technologie de BigData. <br><br>  Dans cet article, nous allons installer Apache Kafka, Apache Spark, Zookeeper, Spark-shell sur la plateforme EC2 AWS (Amazon Web Services) √† la maison et apprendre √† tout utiliser. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/51c/95c/810/51c95c8104a988a0288067e9eaaf700f.jpg" alt="image"></div><br><a name="habracut"></a><br><h3>  Pr√©sentation d'Amazon Web Services </h3><br>  Vous devrez vous inscrire sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">aws.amazon.com/console</a> .  Saisissez un nom et m√©morisez le mot de passe. <br><br>  Configurez les instances de noeud pour les services Zookeeper et Kafka. <br><br><ul><li>  S√©lectionnez "Services-&gt; EC2" dans le menu.  Ensuite, s√©lectionnez la version du syst√®me d'exploitation de l'image de la machine virtuelle, s√©lectionnez Ubuntu Server 16.04 LTS (HVM), type de volume SSD, cliquez sur ¬´S√©lectionner¬ª. Nous proc√©dons √† la configuration de l'instance de serveur: tapez ¬´t3.medium¬ª avec les param√®tres 2vCPU, 4 Go de m√©moire, usage g√©n√©ral Cliquez sur "Suivant: Configuration des d√©tails de l'instance". </li><li>  Ajoutez le nombre d'instances 1, cliquez sur "Suivant: Ajouter du stockage" </li><li>  Nous acceptons la valeur par d√©faut pour la taille du disque de 8 Go et changeons le type en magn√©tique (dans les param√®tres de production en fonction du volume de donn√©es et du SSD haute performance) </li><li>  Dans la section "Tag Instances" pour "Nom", entrez le nom de l'instance du n≈ìud "Home1" (o√π 1 n'est qu'un num√©ro de s√©rie) et cliquez sur "Suivant: ..." </li><li>  Dans la section "Configurer les groupes de s√©curit√©", s√©lectionnez l'option "Utiliser le groupe de s√©curit√© existant" en s√©lectionnant le nom du groupe de s√©curit√© ("Spark_Kafka_Zoo_Project") et d√©finissez les r√®gles pour le trafic entrant.  Cliquez sur "Suivant: ..." </li><li>  Faites d√©filer l'√©cran Review pour v√©rifier vos entr√©es et lancer Launch. </li><li>  Pour vous connecter aux n≈ìuds du cluster, vous devez cr√©er (dans notre cas, utiliser l'existant) une paire de cl√©s publiques pour l'identification et l'autorisation.  Pour ce faire, s√©lectionnez le type d'op√©ration ¬´Utiliser la paire existante¬ª dans la liste. </li></ul><br><h3>  Cr√©ation de cl√© </h3><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">T√©l√©chargez Putty</a> (https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html) pour le client ou utilisez la connexion SSH depuis le terminal. </li><li>  Le fichier de cl√© .pem utilise l'ancien format pour plus de commodit√©, nous le convertissons au format ppk utilis√© par Putty.  Pour ce faire, ex√©cutez l'utilitaire PuTTYgen, chargez la cl√© dans l'ancien format .pem dans l'utilitaire.  Nous convertissons la cl√© et l'enregistrons (Enregistrer la cl√© priv√©e) pour une utilisation ult√©rieure dans le dossier d'accueil avec l'extension .ppk. </li></ul><br><h3>  Lancement du cluster </h3><br>  Pour plus de commodit√©, renommez les n≈ìuds de cluster en notation Node01-04.  Pour vous connecter aux n≈ìuds de cluster √† partir de l'ordinateur local via SSH, vous devez d√©terminer l'adresse IP du n≈ìud et son nom DNS public / priv√©, s√©lectionnez chacun des n≈ìuds de cluster un par un et pour l'instance s√©lectionn√©e, notez son nom DNS public / priv√© pour la connexion via SSH et pour l'installation Logiciel dans le fichier texte HadoopAdm01.txt. <br><br>  Exemple: ec2-35-162-169-76.us-west-2.compute.amazonaws.com <br><br><h3>  Installer Apache Kafka en mode SingleNode sur un n≈ìud de cluster AWS </h3><br>  Pour installer le logiciel, s√©lectionnez notre n≈ìud (copiez son DNS public) pour vous connecter via SSH.  Nous configurons la connexion via SSH.  Nous utilisons le nom enregistr√© du premier n≈ìud pour configurer la connexion via SSH en utilisant la paire de cl√©s priv√©e / publique ¬´HadoopUser01.ppk¬ª cr√©√©e dans la clause 1.3.  Nous allons √† la section Connexion / Auth via le bouton Parcourir et recherchons le dossier o√π nous avons pr√©c√©demment enregistr√© le fichier "HadoopUserXX.ppk". <br><br>  Nous enregistrons la configuration de la connexion dans les param√®tres. <br><br>  Nous sommes connect√©s au n≈ìud et utilisons login: ubuntu. <br><br><ul><li>  En utilisant les privil√®ges root, nous mettons √† jour les packages et installons les packages suppl√©mentaires requis pour une installation et une configuration suppl√©mentaires du cluster. <br><br><pre><code class="plaintext hljs">sudo apt-get update sudo apt-get -y install wget net-tools netcat tar</code> </pre> </li><li>  Installez Java 8 jdk et v√©rifiez la version de Java. <br><br><pre> <code class="plaintext hljs">sudo apt-get -y install openjdk-8-jdk</code> </pre> </li><li>  Pour des performances normales de n≈ìud de cluster, vous devez ajuster les param√®tres d'√©change de m√©moire.  Les swappines VM sont d√©finis √† 60% par d√©faut, ce qui signifie que lors de l'utilisation de la m√©moire √† 60%, le syst√®me √©changera activement les donn√©es de la RAM vers le disque.  Selon la version de Linux, le param√®tre swappines VM peut √™tre d√©fini sur 0 ou 1: <br><br><pre> <code class="plaintext hljs">sudo sysctl vm.swappiness=1</code> </pre> <br></li><li>  Pour enregistrer les param√®tres lors du red√©marrage, ajoutez une ligne au fichier de configuration. <br><br><pre> <code class="plaintext hljs">echo 'vm.swappiness=1' | sudo tee --append /etc/sysctl.conf</code> </pre> <br></li><li>  Modification des entr√©es dans le fichier / etc / hosts pour une r√©solution pratique des noms de n≈ìuds du cluster kafka et <br>  zookeeper √† des adresses IP priv√©es aux n≈ìuds de cluster affect√©s. <br><br><pre> <code class="plaintext hljs">echo "172.31.26.162 host01" | sudo tee --append /etc/hosts</code> </pre> <br>  Nous v√©rifions la reconnaissance correcte des noms en utilisant la commande ping sur l'une des entr√©es. <br><br></li><li>  T√©l√©chargez les derni√®res versions actuelles (http://kafka.apache.org/downloads) des distributions kafka et scala et pr√©parez le r√©pertoire avec les fichiers d'installation. <br><br><pre> <code class="plaintext hljs">wget http://mirror.linux-ia64.org/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgz tar -xvzf kafka_2.12-2.1.0.tgz ln -s kafka_2.12-2.1.0 kafka</code> </pre> <br></li><li>  Supprimez le fichier d'archive tgz, nous n'en aurons plus besoin <br><br></li><li>  Essayons de d√©marrer le service Zookeeper, pour cela: <br><br><pre> <code class="plaintext hljs">~/kafka/bin/zookeeper-server-start.sh -daemon ~/kafka/config/zookeeper.properties</code> </pre> <br>  Zookeeper d√©marre avec les options de d√©marrage par d√©faut.  Vous pouvez consulter le journal: <br><br><pre> <code class="plaintext hljs">tail -n 5 ~/kafka/logs/zookeeper.out</code> </pre> <br>  Pour garantir le d√©marrage du d√©mon Zookeeper, apr√®s le red√©marrage, nous devons d√©marrer Zookeper en tant que service d'arri√®re-plan: <br><br><pre> <code class="plaintext hljs">bin/zookeeper-server-start.sh -daemon config/zookeeper.properties</code> </pre> <br>  Pour v√©rifier le lancement de Zookepper, cochez <br><br><pre> <code class="plaintext hljs">netcat -vz localhost 2181</code> </pre> <br>  Nous configurons le service Zookeeper et Kafka pour le travail.  Initialement, modifiez / cr√©ez le fichier /etc/systemd/system/zookeeper.service (contenu du fichier ci-dessous). <br><br><pre> <code class="plaintext hljs">[Unit] Description=Apache Zookeeper server Documentation=http://zookeeper.apache.org Requires=network.target remote-fs.target After=network.target remote-fs.target [Service] Type=simple ExecStart=/home/ubuntu/kafka/bin/zookeeper-server-start.sh /home/ubuntu/kafka/config/zookeeper.properties ExecStop=/home/ubuntu/kafka/bin/zookeeper-server-stop.sh [Install] WantedBy=multi-user.target</code> </pre> <br>  Ensuite, pour Kafka, √©ditez / cr√©ez le fichier /etc/systemd/system/kafka.service (contenu du fichier ci-dessous). <br><br><pre> <code class="plaintext hljs">[Unit] Description=Apache Kafka server (broker) Documentation=http://kafka.apache.org/documentation.html Requires=zookeeper.service [Service] Type=simple ExecStart=/home/ubuntu/kafka/bin/kafka-server-start.sh /home/ubuntu/kafka/config/server.properties ExecStop=/home/ubuntu/kafka/bin/kafka-server-stop.sh [Install] WantedBy=multi-user.target</code> </pre> <br></li><li>  Nous activons les scripts systemd pour les services Kafka et Zookeeper. <br><br><pre> <code class="plaintext hljs">sudo systemctl enable zookeeper sudo systemctl enable kafka</code> </pre> <br></li><li>  V√©rifiez le fonctionnement des scripts systemd. <br><br><pre> <code class="plaintext hljs">sudo systemctl start zookeeper sudo systemctl start kafka sudo systemctl status zookeeper sudo systemctl status kafka sudo systemctl stop zookeeper sudo systemctl stop kafka</code> </pre> <br></li><li>  Nous v√©rifierons la fonctionnalit√© des services Kafka et Zookeeper. <br><br><pre> <code class="plaintext hljs">netcat -vz localhost 2181 netcat -vz localhost 9092</code> </pre> <br></li><li>  V√©rifiez le fichier journal de zookeeper. <br><br><pre> <code class="plaintext hljs">cat logs/zookeeper.out</code> </pre> </li></ul><br><h3>  Premi√®re joie </h3><br>  Nous cr√©ons notre premier sujet sur le serveur kafka assembl√©. <br><br><ul><li>  Il est important d'utiliser la connexion √† "host01: 2181" comme vous l'avez indiqu√© dans le fichier de configuration server.properties. <br></li><li>  Nous √©crivons quelques donn√©es dans le sujet. <br><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list host01:9092 --topic first_topic    </code> </pre> <br>  Ctrl-C - quitte la console de rubrique. <br><br></li><li>  Essayez maintenant de lire les donn√©es du sujet. <br><br><pre> <code class="plaintext hljs">kafka-console-consumer.sh --bootstrap-server host01:9092 --topic last_topic --from-beginning</code> </pre> <br></li><li>  Regardons la liste des sujets kafka. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper spark01:2181 --list</code> </pre> <br></li><li>  Modification des param√®tres du serveur Kafka pour le r√©glage de la configuration d'un cluster unique <br>  # vous devez changer le param√®tre ISR √† 1. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper spark01:2181 --config min.insync.replicas=1 --topic __consumer_offsets --alter</code> </pre> <br></li><li>  Nous red√©marrons le serveur Kafka et essayons √† nouveau de connecter le consommateur ohm <br><br></li><li>  Regardons la liste des sujets. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper host01:2181 --list</code> </pre> </li></ul><br><h3>  Configurer Apache Spark sur un cluster √† n≈ìud unique </h3><br>  Nous avons pr√©par√© une instance du n≈ìud avec les services Zookeeper et Kafka install√©s sur AWS, vous devez maintenant installer Apache Spark, pour cela: <br><br>  T√©l√©chargez la derni√®re distribution Apache Spark. <br><br><pre> <code class="plaintext hljs">wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.6.tgz</code> </pre> <br><br><ul><li>  D√©compressez la distribution et cr√©ez un lien symbolique pour Spark et supprimez les fichiers d'archive inutiles. <br><br><pre> <code class="plaintext hljs">tar -xvf spark-2.4.0-bin-hadoop2.6.tgz ln -s spark-2.4.0-bin-hadoop2.6 spark rm spark*.tgz</code> </pre> <br></li><li>  Acc√©dez au r√©pertoire sbin et ex√©cutez l'assistant spark. <br><br><pre> <code class="plaintext hljs">./start-master.sh</code> </pre> <br></li><li>  Nous nous connectons √† l'aide d'un navigateur Web au serveur Spark sur le port 8080. <br><br></li><li>  Ex√©cutez des √©tincelles esclaves sur le m√™me n≈ìud <br><br><pre> <code class="plaintext hljs">./start-slave.sh spark://host01:7077</code> </pre> <br></li><li>  Ex√©cutez l'√©tincelle avec le ma√Ætre sur host01. <br><br><pre> <code class="plaintext hljs">./spark-shell --master spark://host01:7077</code> </pre> <br></li><li>  Si le lancement ne fonctionne pas, ajoutez le chemin d'acc√®s √† Spark dans bash. <br><br><pre> <code class="plaintext hljs">vi ~/.bashrc #      SPARK_HOME=/home/ubuntu/spark export PATH=$SPARK_HOME/bin:$PATH</code> </pre> <br><pre> <code class="plaintext hljs">source ~/.bashrc</code> </pre> <br></li><li>  Ex√©cutez √† nouveau l'√©tincelle avec le ma√Ætre sur host01. <br><br><pre> <code class="plaintext hljs">./spark-shell --master spark://host01:7077</code> </pre> <br>  Un cluster √† n≈ìud unique avec Kafka, Zookeeper et Spark fonctionne.  Hourra! </li></ul><br><h3>  Un peu de cr√©ativit√© </h3><br>  T√©l√©chargez l'√©diteur Scala-IDE (sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">scala-ide.org</a> ).  Nous commen√ßons et commen√ßons √† √©crire du code.  Ici je ne me r√©p√©terai plus, car il y a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bon article sur Habr√©</a> . <br><br>  Litt√©rature et cours utiles pour aider: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">courses.hadoopinrealworld.com/courses/enrolled/319237</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">data-flair.training/blogs/kafka-consumer</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.udemy.com/apache-spark-with-scala-hands-on-with-big-data</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr452752/">https://habr.com/ru/post/fr452752/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr452742/index.html">Configuration du test automatique d'une application hybride</a></li>
<li><a href="../fr452744/index.html">Existe-t-il une vie compl√®te d'un √©loign√© sans √©changes ind√©pendants?</a></li>
<li><a href="../fr452746/index.html">Le livre "L'art de la programmation dans R. Immerger dans le Big Data"</a></li>
<li><a href="../fr452748/index.html">Principes de d√©veloppement d'applications modernes √† partir de NGINX. Partie 1</a></li>
<li><a href="../fr452750/index.html">Nextcloud √† l'int√©rieur et √† l'ext√©rieur d'OpenLiteSpeed: configurer le proxy inverse</a></li>
<li><a href="../fr452754/index.html">19% des images Docker les plus populaires n'ont pas de mot de passe root</a></li>
<li><a href="../fr452756/index.html">Cr√©ation de Tower Defense dans Unity: Enemies</a></li>
<li><a href="../fr452760/index.html">Vitamine D. Boire ou ne pas boire, telle est la question. (Ou une histoire sur la fa√ßon dont j'ai r√©ussi une analyse qui ne m'a pas √©t√© prescrite)</a></li>
<li><a href="../fr452762/index.html">MVCC-7. Nettoyage auto</a></li>
<li><a href="../fr452764/index.html">[Peter] Rencontre JUG.ru avec Sergei Melnikov - Profilage √† la vitesse supraluminique: th√©orie et pratique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
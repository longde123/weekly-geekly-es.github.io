<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ•Ô∏è üî´ ü§µ Architecture AERODISK vAIR ou caract√©ristiques de la construction d'un cluster national üò† üë©üèø‚Äçüè≠ üÜí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Khabrovchans! Nous continuons √† vous familiariser avec le syst√®me hyperconverg√© russe AERODISK vAIR. Cet article se concentrera sur l'archite...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Architecture AERODISK vAIR ou caract√©ristiques de la construction d'un cluster national</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/aerodisk/blog/475254/"><p><img src="https://habrastorage.org/webt/4c/_3/or/4c_3or6x9ro2_f_g8-waac1oen0.jpeg"></p><br><p>  Bonjour, Khabrovchans!  Nous continuons √† vous familiariser avec le syst√®me hyperconverg√© russe AERODISK vAIR.  Cet article se concentrera sur l'architecture de ce syst√®me.  Dans le dernier article, nous avons analys√© notre syst√®me de fichiers ARDFS, et dans cet article, nous allons passer en revue tous les principaux composants logiciels qui composent vAIR et leurs t√¢ches. </p><a name="habracut"></a><br><p>  Nous commen√ßons la description de l'architecture de bas en haut - du stockage √† la gestion. </p><br><h2 id="faylovaya-sistema-ardfs--raft-cluster-driver">  ARDFS + Raft Cluster Driver File System </h2><br><p>  La base de vAIR est le syst√®me de fichiers distribu√© ARDFS, qui combine les disques locaux de tous les n≈ìuds de cluster en un seul pool logique, sur la base duquel les disques virtuels avec l'un ou l'autre sch√©ma de tol√©rance aux pannes (facteur de r√©plication ou codage d'effacement) sont form√©s √† partir de blocs virtuels de 4 Mo.  Une description plus d√©taill√©e du travail de l'ARDFS est donn√©e dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article pr√©c√©dent.</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><br></a> <br>  Raft Cluster Driver est un service ARDFS interne qui r√©sout le probl√®me du stockage distribu√© et fiable des m√©tadonn√©es du syst√®me de fichiers. </p><br><p>  Les m√©tadonn√©es ARDFS sont classiquement divis√©es en deux classes. </p><br><ul><li>  notifications - informations sur les op√©rations avec les objets de stockage et informations sur les objets eux-m√™mes; </li><li>  informations de service - d√©finition des verrous et informations de configuration pour les n≈ìuds de stockage. </li></ul><br><p>  Le service RCD est utilis√© pour diffuser ces donn√©es.  Il attribue automatiquement √† un n≈ìud le r√¥le d'un leader dont la t√¢che est d'obtenir et de diffuser des m√©tadonn√©es sur les n≈ìuds.  Un leader est la seule v√©ritable source de ces informations.  De plus, le leader organise un battement de c≈ìur, c'est-√†-dire  v√©rifie la disponibilit√© de tous les n≈ìuds de stockage (cela n'a aucun rapport avec la disponibilit√© des machines virtuelles, RCD est juste un service de stockage). </p><br><p>  Si, pour une raison quelconque, le leader est devenu indisponible pour l'un des n≈ìuds ordinaires pendant plus d'une seconde, ce n≈ìud ordinaire organise une r√©√©lection du leader, demandant la disponibilit√© du leader √† partir d'autres n≈ìuds ordinaires.  S'il y a quorum, le chef est r√©√©lu.  Apr√®s que l'ancien chef se soit "r√©veill√©", il devient automatiquement un n≈ìud ordinaire, car  le nouveau chef lui envoie l'√©quipe appropri√©e. </p><br><p> La logique du RCD lui-m√™me n'est pas nouvelle.  De nombreuses solutions tierces et commerciales et gratuites sont √©galement guid√©es par cette logique, mais ces solutions ne nous convenaient pas (comme les FS open source existantes), car elles sont assez lourdes et il est tr√®s difficile de les optimiser pour nos t√¢ches simples, nous avons donc simplement √©crit notre propre Service RCD. <br>  Il peut sembler que le leader est un ¬´col √©troit¬ª qui peut ralentir le travail dans les grands clusters par des centaines de n≈ìuds, mais ce n'est pas le cas.  Le processus d√©crit se produit presque instantan√©ment et ¬´p√®se¬ª tr√®s peu puisque nous l'avons √©crit nous-m√™mes et que nous n'avons inclus que les fonctions les plus n√©cessaires.  De plus, cela se produit de mani√®re compl√®tement automatique, ne laissant que des messages dans les journaux. </p><br><h2 id="masterio--sluzhba-upravleniya-mnogopotochnym-vvodom-vyvodom">  MasterIO - Service de gestion d'E / S multithread </h2><br><p>  Une fois qu'un pool ARDFS avec des disques virtuels est organis√©, il peut √™tre utilis√© pour les E / S.  √Ä ce stade, la question se pose sp√©cifiquement pour les syst√®mes hyperconverg√©s, √† savoir: combien de ressources syst√®me (CPU / RAM) pouvons-nous donner pour les E / S? </p><br><p>  Dans les syst√®mes de stockage classiques, ce probl√®me n'est pas si aigu, car la t√¢che de stockage consiste uniquement √† stocker des donn√©es (et la plupart des ressources de stockage syst√®me peuvent √™tre fournies en toute s√©curit√© sous IO), et les t√¢ches d'hyperconvergence incluent, en plus du stockage, l'ex√©cution de machines virtuelles.  Par cons√©quent, le GCS n√©cessite l'utilisation de ressources CPU et RAM principalement pour les machines virtuelles.  Et les E / S? </p><br><p>  Pour r√©soudre ce probl√®me, vAIR utilise le service de gestion des E / S: MasterIO.  La t√¢che du service est simple - <del>  "Prenez tout et partagez" </del>  il est garanti de r√©cup√©rer le ni√®me nombre de ressources syst√®me pour les entr√©es et les sorties et, √† partir de celles-ci, de d√©marrer le ni√®me nombre de flux d'entr√©e / sortie. </p><br><p>  Au d√©part, nous voulions fournir un m√©canisme ¬´tr√®s intelligent¬ª pour l'allocation des ressources aux IO.  Par exemple, s'il n'y a pas de charge sur le stockage, les ressources syst√®me peuvent √™tre utilis√©es pour les machines virtuelles et si la charge appara√Æt, ces ressources sont supprim√©es ¬´en douceur¬ª des machines virtuelles dans des limites pr√©d√©termin√©es.  Mais cette tentative s'est sold√©e par un √©chec partiel.  Les tests ont montr√© que si la charge augmente progressivement, alors tout va bien, les ressources (marqu√©es pour une √©ventuelle suppression) sont progressivement retir√©es de la VM au profit des E / S.  Mais de brusques rafales de charges de stockage provoquent un retrait pas si ¬´doux¬ª des ressources des machines virtuelles, et par cons√©quent, les files d'attente s'accumulent sur les processeurs et, par cons√©quent, <del>  et les loups ont faim et les moutons sont morts </del>  et virtualka se bloquent, et il n'y a aucun IOPS. </p><br><p>  Peut-√™tre qu'√† l'avenir, nous reviendrons sur ce probl√®me, mais pour l'instant, nous avons mis en ≈ìuvre la d√©livrance de ressources pour les OI √† la mani√®re du bon vieux grand-p√®re. </p><br><p>  Sur la base des donn√©es de dimensionnement, l'administrateur pr√©-alloue le ni√®me nombre de c≈ìurs de CPU et de RAM pour le service MasterIO.  Ces ressources se voient attribuer un monopole, c'est-√†-dire  ils ne peuvent en aucun cas √™tre utilis√©s pour les besoins de la machine virtuelle tant que l'administrateur ne le permet pas.  Les ressources sont r√©parties de mani√®re √©gale, c'est-√†-dire  la m√™me quantit√© de ressources syst√®me est pr√©lev√©e sur chaque n≈ìud du cluster.  Tout d'abord, les ressources processeur int√©ressent MasterIO (la RAM est moins importante), surtout si nous utilisons le codage Erasure. </p><br><p>  Si une erreur s'est produite avec le dimensionnement et que nous avons donn√© trop de ressources √† MasterIO, la situation est facilement r√©solue en supprimant ces ressources dans le pool de ressources de la machine virtuelle.  Si les ressources sont inactives, elles retourneront presque imm√©diatement au pool de ressources de la machine virtuelle, mais si ces ressources sont √©limin√©es, vous devrez attendre un certain temps pour que MasterIO les lib√®re en douceur. </p><br><p>  La situation inverse est plus compliqu√©e.  Si nous avions besoin d'augmenter le nombre de c≈ìurs pour MasterIO, et qu'ils sont occup√©s avec des virtuels, alors nous devons ¬´n√©gocier¬ª avec les virtuels, c'est-√†-dire les s√©lectionner avec des poign√©es, car en mode automatique dans une situation de forte augmentation de la charge, cette op√©ration est lourde de gels de VM et d'autres comportements capricieux. </p><br><p>  En cons√©quence, une grande attention doit √™tre accord√©e au dimensionnement des performances des syst√®mes hyperconverg√©s IO (pas seulement les n√¥tres).  Un peu plus tard, dans l'un des articles, nous promettons d'examiner cette question plus en d√©tail. </p><br><h2 id="gipervizor">  Hyperviseur </h2><br><p>  Hypervisor Aist est responsable de l'ex√©cution des machines virtuelles dans vAIR.  Cet hyperviseur est bas√© sur l'hyperviseur KVM √©prouv√©.  En principe, beaucoup de choses ont √©t√© √©crites sur le travail de KVM, il n'y a donc pas besoin de le peindre, il suffit d'indiquer que toutes les fonctions standard de KVM sont stock√©es dans Stork et fonctionnent correctement. </p><br><p>  Par cons√©quent, nous d√©crirons ici les principales diff√©rences par rapport au KVM standard, que nous avons impl√©ment√© dans Stork.  La cigogne fait partie du syst√®me (hyperviseur pr√©install√©) et elle est contr√¥l√©e √† partir de la console commune vAIR via le Web-GUI (versions russe et anglaise) et SSH (√©videmment, uniquement en anglais). </p><br><p><img src="https://habrastorage.org/webt/vi/ju/9e/viju9ee4sxkeq-ezvoobttyjvck.png"></p><br><p>  De plus, les configurations d'hyperviseur sont stock√©es dans la base de donn√©es ConfigDB distribu√©e (√† ce sujet un peu plus tard), qui est √©galement un point de contr√¥le unique.  Autrement dit, vous pouvez vous connecter √† n'importe quel n≈ìud du cluster et tout g√©rer sans avoir besoin d'un serveur de gestion distinct. </p><br><p>  Le module HA que nous avons d√©velopp√© constitue un ajout important √† la fonctionnalit√© KVM standard.  Il s'agit de l'impl√©mentation la plus simple d'un cluster de machines virtuelles haute disponibilit√©, qui vous permet de red√©marrer automatiquement la machine virtuelle sur un autre n≈ìud de cluster en cas de d√©faillance d'un n≈ìud. </p><br><p>  Une autre fonctionnalit√© utile est le d√©ploiement en masse de machines virtuelles (pertinent pour les environnements VDI), qui automatisera le d√©ploiement des machines virtuelles avec leur distribution automatique entre les n≈ìuds en fonction de la charge sur eux. </p><br><p>  La distribution de VM entre les n≈ìuds est la base de l'√©quilibrage de charge automatique (ala DRS).  Cette fonction n'est pas encore disponible dans la version actuelle, mais nous y travaillons activement et elle appara√Ætra certainement dans l'une des prochaines mises √† jour. </p><br><p>  L'hyperviseur VMware ESXi est pris en charge en option, il est actuellement impl√©ment√© √† l'aide du protocole iSCSI et la prise en charge NFS est √©galement pr√©vue √† l'avenir. </p><br><h2 id="virtualnye-kommutatory">  Commutateurs virtuels </h2><br><p>  Pour la mise en ≈ìuvre logicielle des commutateurs, un composant distinct est fourni - Fractal.  Comme dans nos autres composants, nous passons du simple au complexe, donc dans la premi√®re version, une commutation simple est impl√©ment√©e, tandis que le routage et le pare-feu sont accord√©s √† des appareils tiers.  Le principe de fonctionnement est standard.  L'interface physique du serveur est connect√©e par un pont √† l'objet Fractal - un groupe de ports.  Un groupe de ports, √† son tour, avec les machines virtuelles souhait√©es dans le cluster.  L'organisation des VLAN est prise en charge et dans l'une des prochaines versions, la prise en charge du VxLAN sera ajout√©e.  Tous les commutateurs cr√©√©s sont distribu√©s par d√©faut, c'est-√†-dire  distribu√©s sur tous les n≈ìuds du cluster, de sorte que les machines virtuelles vers lesquelles basculer pour se connecter √† la machine virtuelle ne d√©pendent pas du n≈ìud d'emplacement, cela d√©pend uniquement de la d√©cision de l'administrateur. </p><br><h2 id="monitoring-i-statistika">  Suivi et statistiques </h2><br><p>  Le composant responsable du suivi et des statistiques (titre de travail Monica) est en fait un clone repens√© du syst√®me de stockage ENGINE.  √Ä un moment donn√©, il s'est bien recommand√© et nous avons d√©cid√© de l'utiliser avec vAIR avec un r√©glage facile.  Comme tous les autres composants, Monica est ex√©cut√© et stock√© sur tous les n≈ìuds du cluster en m√™me temps. </p><br><p>  Les responsabilit√©s difficiles de Monica peuvent √™tre d√©crites comme suit: </p><br><p>  Collecte de donn√©es: </p><br><ul><li>  des capteurs mat√©riels (ce qui peut donner du fer sur IPMI); </li><li>  √† partir d'objets logiques vAIR (ARDFS, Stork, Fractal, MasterIO et autres objets). </li></ul><br><p><img src="https://habrastorage.org/webt/1c/4k/u8/1c4ku82o_bkanp-348z-jbeioma.png"></p><br><p>  Collecte de donn√©es dans une base de donn√©es distribu√©e; </p><br><p>  Interpr√©tation des donn√©es sous forme de: </p><br><ul><li>  journaux; </li><li>  Alertes </li><li>  horaires. </li></ul><br><p>  Interaction externe avec des syst√®mes tiers via les protocoles SMTP (envoi d'alertes par e-mail) et SNMP (interaction avec des syst√®mes de surveillance tiers). </p><br><p><img src="https://habrastorage.org/webt/2k/-p/9o/2k-p9oah-yrta3n5ti0m5yfm22e.png"></p><br><h2 id="raspredelennaya-baza-konfiguraciy">  Base de configuration distribu√©e </h2><br><p>  Dans les paragraphes pr√©c√©dents, il a √©t√© mentionn√© que de nombreuses donn√©es sont stock√©es sur tous les n≈ìuds du cluster en m√™me temps.  Pour organiser cette m√©thode de stockage, une base de donn√©es ConfigDB distribu√©e sp√©ciale est fournie.  Comme son nom l'indique, la base de donn√©es stocke les configurations de tous les objets du cluster: hyperviseur, machines virtuelles, module HA, commutateurs, syst√®me de fichiers (√† ne pas confondre avec la base de donn√©es de m√©tadonn√©es FS, il s'agit d'une autre base de donn√©es), ainsi que des statistiques.  Ces donn√©es sont stock√©es de mani√®re synchrone sur tous les n≈ìuds et la coh√©rence de ces donn√©es est une condition pr√©alable au fonctionnement stable de vAIR. </p><br><p>  Un point important: bien que le fonctionnement de ConfigDB soit vital pour le fonctionnement de vAIR, son √©chec, bien qu'il arr√™te le cluster, n'affecte pas la coh√©rence des donn√©es stock√©es dans ARDFS, ce qui √† notre avis est un plus pour la fiabilit√© de la solution dans son ensemble. </p><br><p>  ConfigDB est √©galement un point de gestion unique, vous pouvez donc acc√©der √† n'importe quel n≈ìud du cluster par adresse IP et g√©rer enti√®rement tous les n≈ìuds du cluster, ce qui est assez pratique. </p><br><p>  De plus, pour acc√©der aux syst√®mes externes, ConfigDB fournit une API Restful √† travers laquelle vous pouvez configurer l'int√©gration avec des syst√®mes tiers.  Par exemple, nous avons r√©cemment r√©alis√© une int√©gration pilote avec plusieurs solutions russes dans les domaines du VDI et de la s√©curit√© de l'information.  Lorsque les projets seront termin√©s, nous serons heureux d'√©crire les d√©tails techniques ici. </p><br><h2 id="kartina-v-celom">  L'image enti√®re </h2><br><p>  En cons√©quence, nous avons deux versions de l'architecture du syst√®me. </p><br><p>  Dans le premier cas principal, notre hyperviseur Aist bas√© sur KVM et nos commutateurs logiciels Fractal sont utilis√©s. </p><br><p>  <strong>Sc√©nario 1. Vrai</strong> </p><br><p><img src="https://habrastorage.org/webt/0-/pb/7j/0-pb7j1-zdrpqone3dlvw5un4py.png"></p><br><p>  Dans la seconde - option facultative - lorsque vous souhaitez utiliser l'hyperviseur ESXi, le sch√©ma est quelque peu compliqu√©.  Pour utiliser ESXi, il doit √™tre install√© de mani√®re standard sur les lecteurs locaux du cluster.  Ensuite, sur chaque n≈ìud ESXi, la machine virtuelle vAIR MasterVM est install√©e, qui contient une distribution sp√©ciale vAIR √† ex√©cuter en tant que machine virtuelle VMware. </p><br><p>  ESXi offre tous les disques locaux gratuits par transfert direct √† MasterVM.  √Ä l'int√©rieur de MasterVM, ces disques sont d√©j√† format√©s en ARDFS et livr√©s √† l'ext√©rieur (ou plut√¥t, √† ESXi) en utilisant le protocole iSCSI (et √† l'avenir il y aura √©galement NFS) via les interfaces d√©di√©es dans ESXi.  En cons√©quence, les machines virtuelles et le r√©seau de logiciels dans ce cas sont fournis par ESXi. </p><br><p>  <strong>Sc√©nario 2. ESXi</strong> </p><br><p><img src="https://habrastorage.org/webt/no/jf/cv/nojfcvippesbznyxdmzpvnmq2se.png"></p><br><p>  Nous avons donc d√©mont√© tous les principaux composants de l'architecture vAIR et leurs t√¢ches.  Dans le prochain article, nous parlerons des fonctionnalit√©s d√©j√† mises en ≈ìuvre et des plans pour un avenir proche. </p><br><p>  Nous attendons vos commentaires et suggestions. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr475254/">https://habr.com/ru/post/fr475254/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr475244/index.html">Nouvelles fonctionnalit√©s JavaScript attendues que vous devez conna√Ætre</a></li>
<li><a href="../fr475246/index.html">Programmation asynchrone Python: un bref aper√ßu</a></li>
<li><a href="../fr475248/index.html">L'utilisation de polyfills lors de l'√©criture d'applications inter-navigateurs</a></li>
<li><a href="../fr475250/index.html">Comme Redash l'a remarqu√© et a corrig√© un probl√®me qui provoquait une d√©gradation des performances du code Python</a></li>
<li><a href="../fr475252/index.html">Comment critiquer Microsoft</a></li>
<li><a href="../fr475258/index.html">Une repr√©sentation visuelle des √©lections √† Saint-P√©tersbourg - la magie de l'habillage vocal</a></li>
<li><a href="../fr475260/index.html">La diff√©rence entre une fonction asynchrone et une fonction qui renvoie une promesse</a></li>
<li><a href="../fr475262/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 388 (4-10 novembre 2019)</a></li>
<li><a href="../fr475264/index.html">Des renifleurs qui pourraient: comment la famille FakeSecurity a infect√© les boutiques en ligne</a></li>
<li><a href="../fr475266/index.html">Nous inversons les mobiles 1 sous Android. Comment ajouter un peu de fonctionnalit√© et abandonner quelques soir√©es</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
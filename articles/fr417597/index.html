<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚¨áÔ∏è üßü üê∞ Stockage s√©curis√© avec DRBD9 et Proxmox (Partie 2: iSCSI + LVM) üè∞ üïû üêÆ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans un article pr√©c√©dent, j'ai examin√© la possibilit√© de cr√©er un serveur NFS tol√©rant aux pannes en utilisant DRBD et Proxmox. Cela s'est plut√¥t bie...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Stockage s√©curis√© avec DRBD9 et Proxmox (Partie 2: iSCSI + LVM)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417597/"><p><img src="https://habrastorage.org/getpro/habr/post_images/101/70c/524/10170c52443d67bd757a09ef22ba39e2.jpg" alt="image"></p><br><p>  Dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article pr√©c√©dent,</a> j'ai examin√© la possibilit√© de cr√©er un serveur NFS tol√©rant aux pannes en utilisant DRBD et Proxmox.  Cela s'est plut√¥t bien pass√©, mais nous ne nous reposons pas sur nos lauriers et maintenant nous allons essayer de "sortir tous les jus" de notre stockage. </p><br><p> Dans cet article, je vais vous expliquer comment cr√©er une cible iSCSI tol√©rante aux pannes de cette mani√®re, que nous utiliserons LVM pour d√©couper en petits morceaux et l'utiliser pour des machines virtuelles. </p><br><p>  C'est cette approche qui r√©duira la charge et augmentera la vitesse d'acc√®s aux donn√©es plusieurs fois, ce qui est particuli√®rement b√©n√©fique lorsqu'un acc√®s concurrentiel aux donn√©es n'est pas requis, par exemple dans le cas o√π vous devez organiser le stockage des machines virtuelles. </p><a name="habracut"></a><br><h2 id="para-slov-o-drbd">  Quelques mots sur DRBD </h2><br><p>  DRBD est une solution assez simple et mature, le code de la huiti√®me version est adopt√© dans le cadre du noyau Linux.  En fait, il repr√©sente un miroir r√©seau RAID1.  La neuvi√®me version a introduit la prise en charge du quorum et de la r√©plication avec plus de deux n≈ìuds. </p><br><p>  En fait, il vous permet de combiner des p√©riph√©riques blocs sur plusieurs n≈ìuds physiques en un seul r√©seau partag√© commun. </p><br><p>  En utilisant DRBD, vous pouvez obtenir des configurations tr√®s int√©ressantes.  Aujourd'hui, nous allons parler d'iSCSI et de LVM. </p><br><p>  Vous pouvez en savoir plus √† ce sujet en lisant mon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article pr√©c√©dent</a> , o√π j'ai d√©crit cette solution en d√©tail. </p><br><h2 id="para-slov-ob-iscsi">  Quelques mots sur iSCSI </h2><br><p>  iSCSI est un protocole de livraison de p√©riph√©rique de bloc sur un r√©seau. </p><br><p>  Contrairement √† NBD, il prend en charge l'autorisation, r√©sout les pannes de r√©seau sans probl√®me et prend en charge de nombreuses autres fonctions utiles, et surtout, il pr√©sente de tr√®s bonnes performances. </p><br><p>  Il existe un grand nombre de ses impl√©mentations, certaines d'entre elles sont √©galement incluses dans le noyau et ne n√©cessitent pas de difficult√©s particuli√®res pour sa configuration et sa connexion. </p><br><h2 id="para-slov-ob-lvm">  LVM en quelques mots </h2><br><p>  Il convient de mentionner que LINBIT a sa propre solution pour Proxmox, il devrait fonctionner hors de la bo√Æte et permettre d'obtenir un r√©sultat similaire, mais dans cet article, je ne voudrais pas me concentrer uniquement sur Proxmox et d√©crire une solution plus universelle qui convient √† la fois √† Proxmox et √† toute autre chose, dans cet exemple, proxmox est utilis√© uniquement comme moyen d'orchestration de conteneurs, en fait vous pouvez le remplacer par une autre solution, par exemple, lancer des conteneurs avec une cible dans Kubernetes. </p><br><p>  Quant √† Proxmox en particulier, il fonctionne tr√®s bien avec les LUN et LVM partag√©s, en utilisant uniquement ses propres pilotes standard. </p><br><p>  Les avantages de LVM incluent le fait que son utilisation n'est pas quelque chose de r√©volutionnaire nouveau et insuffisamment rod√©, mais au contraire, il pr√©sente une stabilit√© √† sec, qui est g√©n√©ralement exig√©e du stockage.  Il convient de mentionner que LVM est assez activement utilis√© dans d'autres environnements, par exemple, dans OpenNebula ou Kubernetes, et y est assez bien pris en charge. </p><br><p>  Ainsi, vous recevrez un stockage universel qui peut √™tre utilis√© dans diff√©rents syst√®mes (non seulement dans proxmox), en utilisant uniquement des pilotes pr√™ts √† l'emploi, sans besoin particulier de le modifier avec un fichier. </p><br><p>  Malheureusement, lorsque vous choisissez une solution de stockage, vous devez toujours faire des compromis.  Donc ici, cette solution ne vous donnera pas la m√™me flexibilit√© que par exemple Ceph. <br>  La taille du disque virtuel est limit√©e par la taille du groupe LVM, et la zone d√©limit√©e pour un disque virtuel sp√©cifique sera n√©cessairement r√©allou√©e - cela am√©liore consid√©rablement la vitesse d'acc√®s aux donn√©es, mais ne permet pas le Thin-Provisioning (lorsque le disque virtuel prend moins d'espace qu'il ne l'est r√©ellement).  Il convient de mentionner que les performances de LVM s'affaiblissent beaucoup lors de l'utilisation d'instantan√©s, et donc la possibilit√© de leur utilisation gratuite est souvent √©limin√©e. </p><br><p>  Oui, LVM prend en charge les pools Thin-Provision qui sont d√©pourvus de cet inconv√©nient, mais malheureusement, leur utilisation n'est possible que dans le contexte d'un n≈ìud et il n'y a aucun moyen de partager un pool Thin-Provision pour plusieurs n≈ìuds du cluster. </p><br><p>  Mais malgr√© ces lacunes, en raison de sa simplicit√©, LVM ne permet toujours pas aux concurrents de le contourner et de le pousser compl√®tement hors du champ de bataille. </p><br><p>  Avec une surcharge assez faible, LVM fournit toujours une solution tr√®s rapide, stable et assez flexible. </p><br><h1 id="obschaya-shema">  Sch√©ma g√©n√©ral </h1><br><ul><li>  Nous avons <strong>trois n≈ìuds</strong> </li><li>  Chaque n≈ìud poss√®de un <strong>p√©riph√©rique drbd</strong> distribu√©. </li><li>  En plus du p√©riph√©rique drbd, un <strong>conteneur LXC</strong> avec une cible iSCSI est lanc√©. </li><li>  La cible est connect√©e aux trois n≈ìuds. </li><li>  Un <strong>groupe LVM a</strong> √©t√© cr√©√© sur la cible connect√©e. </li><li>  Si n√©cessaire, le <strong>conteneur LXC</strong> peut se d√©placer vers un autre n≈ìud, avec la <strong>cible iSCSI</strong> </li></ul><br><h1 id="nastroyka">  Personnalisation </h1><br><p>  Nous avons compris l'id√©e maintenant, passons √† la mise en ≈ìuvre. </p><br><p>  Par d√©faut <strong>, la huiti√®me version de drbd</strong> est fournie <strong>avec le noyau Linux</strong> , malheureusement elle ne nous <strong>convient</strong> pas et nous devons installer la neuvi√®me version du module. </p><br><p>  Connectez le r√©f√©rentiel LINBIT et installez tout ce dont vous avez besoin: </p><br><pre><code class="bash hljs">wget -O- https://packages.linbit.com/package-signing-pubkey.asc | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://packages.linbit.com/proxmox/ proxmox-5 drbd-9.0"</span></span> \ &gt; /etc/apt/sources.list.d/linbit.list apt-get update &amp;&amp; apt-get -y install pve-headers drbd-dkms drbd-utils drbdtop</code> </pre> <br><ul><li>  <code>pve-headers</code> - <code>pve-headers</code> noyau n√©cessaires pour construire le module </li><li>  <code>drbd-dkms</code> - module du noyau au format DKMS </li><li>  <code>drbd-utils</code> - utilitaires de gestion de base de DRBD </li><li>  <code>drbdtop</code> est un outil interactif comme top pour DRBD uniquement </li></ul><br><p>  Apr√®s avoir install√© le <strong>module,</strong> v√©rifiez si tout va bien: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># modprobe drbd # cat /proc/drbd version: 9.0.14-1 (api:2/proto:86-113)</span></span></code> </pre> <br><p>  Si vous voyez la <strong>huiti√®me version</strong> dans la sortie de la commande, alors quelque chose s'est mal pass√© et le module du noyau <strong>dans l'arborescence</strong> est charg√©.  V√©rifiez l' <code>dkms status</code> conna√Ætre la raison. </p><br><p>  Chaque n≈ìud que nous avons aura le m√™me <strong>p√©riph√©rique drbd</strong> fonctionnant au-dessus des partitions r√©guli√®res.  Nous devons d'abord pr√©parer cette section pour drbd sur chaque n≈ìud. </p><br><p>  Une telle partition peut √™tre n'importe quel <strong>p√©riph√©rique bloc</strong> , elle peut √™tre lvm, zvol, une partition de disque ou le disque entier.  Dans cet article, j'utiliserai un disque nvme s√©par√© avec une partition sous drbd: <code>/dev/nvme1n1p1</code> </p><br><p>  Il convient de noter que les noms des appareils ont parfois tendance √† changer, il est donc pr√©f√©rable de prendre imm√©diatement l'habitude d'utiliser un lien symbolique constant vers l'appareil. </p><br><p>  Vous pouvez trouver un tel lien symbolique pour <code>/dev/nvme1n1p1</code> cette fa√ßon: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># find /dev/disk/ -lname '*/nvme1n1p1' /dev/disk/by-partuuid/847b9713-8c00-48a1-8dff-f84c328b9da2 /dev/disk/by-path/pci-0000:0e:00.0-nvme-1-part1 /dev/disk/by-id/nvme-eui.0000000001000000e4d25c33da9f4d01-part1 /dev/disk/by-id/nvme-INTEL_SSDPEKKA010T7_BTPY703505FB1P0H-part1</span></span></code> </pre> <br><p>  Nous d√©crivons notre ressource sur les trois n≈ìuds: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cat /etc/drbd.d/tgt1.res resource tgt1 { meta-disk internal; device /dev/drbd100; protocol C; net { after-sb-0pri discard-zero-changes; after-sb-1pri discard-secondary; after-sb-2pri disconnect; } on pve1 { address 192.168.2.11:7000; disk /dev/disk/by-partuuid/95e7eabb-436e-4585-94ea-961ceac936f7; node-id 0; } on pve2 { address 192.168.2.12:7000; disk /dev/disk/by-partuuid/aa7490c0-fe1a-4b1f-ba3f-0ddee07dfee3; node-id 1; } on pve3 { address 192.168.2.13:7000; disk /dev/disk/by-partuuid/847b9713-8c00-48a1-8dff-f84c328b9da2; node-id 2; } connection-mesh { hosts pve1 pve2 pve3; } }</span></span></code> </pre> <br><p>  Il est conseill√© d'utiliser un <strong>r√©seau s√©par√©</strong> pour la synchronisation drbd. </p><br><p>  Maintenant, cr√©ez les m√©tadonn√©es pour drbd et ex√©cutez-le: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm create-md tgt1 initializing activity log initializing bitmap (320 KB) to all zero Writing meta data... New drbd meta data block successfully created. success # drbdadm up tgt1</span></span></code> </pre> <br><p>  R√©p√©tez ces √©tapes sur les trois n≈ìuds et v√©rifiez l'√©tat: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm status tgt1 role:Secondary disk:Inconsistent pve2 role:Secondary peer-disk:Inconsistent pve3 role:Secondary peer-disk:Inconsistent</span></span></code> </pre> <br><p>  Maintenant, notre disque <strong>incoh√©rent est</strong> sur les trois n≈ìuds, c'est parce que drbd ne sait pas quel disque doit √™tre pris comme original.  Nous devons marquer l'un d'eux comme <strong>primaire</strong> pour que son √©tat soit synchronis√© avec les autres n≈ìuds: </p><br><pre> <code class="bash hljs">drbdadm primary --force tgt1 drbdadm secondary tgt1</code> </pre> <br><p>  Imm√©diatement apr√®s cela, la <strong>synchronisation</strong> commencera: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm status tgt1 role:Secondary disk:UpToDate pve2 role:Secondary replication:SyncSource peer-disk:Inconsistent done:26.66 pve3 role:Secondary replication:SyncSource peer-disk:Inconsistent done:14.20</span></span></code> </pre><br><p>  Nous n'avons pas √† attendre qu'il se termine et nous pouvons effectuer d'autres √©tapes en parall√®le.  Ils peuvent √™tre ex√©cut√©s sur <strong>n'importe quel n≈ìud</strong> , quel que soit son √©tat actuel du disque local dans DRBD.  Toutes les demandes seront automatiquement redirig√©es vers l'appareil avec l'√©tat <strong>UpToDate</strong> . </p><br><p>  N'oubliez pas d'activer <strong>l'</strong> ex√©cution <strong>automatique du</strong> service drbd sur les n≈ìuds: </p><br><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span> drbd.service</code> </pre> <br><h2 id="nastroyka-lxc-konteynera">  Configuration d'un conteneur LXC </h2><br><p>  Nous <strong>allons</strong> omettre la partie configuration du <strong>cluster Proxmox</strong> de trois n≈ìuds, cette partie est bien d√©crite dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wiki officiel</a> </p><br><p>  Comme je l'ai d√©j√† dit, notre <strong>cible iSCSI</strong> fonctionnera dans un <strong>conteneur LXC</strong> .  Nous conserverons le conteneur sur le p√©riph√©rique <code>/dev/drbd100</code> que nous venons de cr√©er. </p><br><p>  Nous devons d'abord cr√©er un <strong>syst√®me de fichiers</strong> dessus: </p><br><pre> <code class="hljs powershell">mkfs <span class="hljs-literal"><span class="hljs-literal">-t</span></span> ext4 <span class="hljs-literal"><span class="hljs-literal">-O</span></span> mmp <span class="hljs-literal"><span class="hljs-literal">-E</span></span> mmp_update_interval=<span class="hljs-number"><span class="hljs-number">5</span></span> /dev/drbd100</code> </pre> <br><p>  <strong>Proxmox</strong> inclut par d√©faut une <strong>protection multimount</strong> au niveau du syst√®me de fichiers, en principe, nous pouvons nous en passer, car  DRBD a sa propre protection par d√©faut, il interdit simplement le deuxi√®me <strong>primaire</strong> pour l'appareil, mais la prudence ne nous fait pas de mal. </p><br><p>  T√©l√©chargez maintenant le mod√®le Ubuntu: </p><br><pre> <code class="hljs pgsql"># wget http://download.proxmox.com/images/<span class="hljs-keyword"><span class="hljs-keyword">system</span></span>/ubuntu<span class="hljs-number"><span class="hljs-number">-16.04</span></span>-standard_16<span class="hljs-number"><span class="hljs-number">.04</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>_amd64.tar.gz -P /var/lib/vz/<span class="hljs-keyword"><span class="hljs-keyword">template</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/</code> </pre> <br><p>  Et cr√©ez notre conteneur √† partir de celui-ci: </p><br><pre> <code class="hljs powershell">pct create <span class="hljs-number"><span class="hljs-number">101</span></span> local:vztmpl/ubuntu<span class="hljs-literal"><span class="hljs-literal">-16</span></span>.<span class="hljs-number"><span class="hljs-number">04</span></span><span class="hljs-literal"><span class="hljs-literal">-standard_16</span></span>.<span class="hljs-number"><span class="hljs-number">04</span></span><span class="hljs-literal"><span class="hljs-literal">-1_amd64</span></span>.tar.gz \ -<span class="hljs-literal"><span class="hljs-literal">-hostname</span></span>=tgt1 \ -<span class="hljs-literal"><span class="hljs-literal">-net0</span></span>=name=eth0,bridge=vmbr0,gw=<span class="hljs-number"><span class="hljs-number">192.168</span></span>.<span class="hljs-number"><span class="hljs-number">1.1</span></span>,ip=<span class="hljs-number"><span class="hljs-number">192.168</span></span>.<span class="hljs-number"><span class="hljs-number">1.11</span></span>/<span class="hljs-number"><span class="hljs-number">24</span></span> \ -<span class="hljs-literal"><span class="hljs-literal">-rootfs</span></span>=volume=/dev/drbd100,shared=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  Dans cette commande, nous indiquons que le <strong>syst√®me racine de</strong> notre conteneur sera sur le p√©riph√©rique <code>/dev/drbd100</code> et ajoutons le param√®tre <code>shared=1</code> pour permettre la <strong>migration du</strong> conteneur entre les n≈ìuds. </p><br><p>  En cas de probl√®me, vous pouvez toujours le corriger via l'interface <strong>Proxmox</strong> ou dans la <code>/etc/pve/lxc/101.conf</code> conteneur <code>/etc/pve/lxc/101.conf</code> </p><br><p>  Proxmox d√©ballera le mod√®le et pr√©parera <strong>le syst√®me racine du</strong> conteneur pour nous.  Apr√®s cela, nous pouvons lancer notre conteneur: </p><br><pre> <code class="hljs pgsql">pct <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span></code> </pre> <br><h2 id="nastroyka-iscsi-targeta">  Configuration d'une cible iSCSI. </h2><br><p>  Parmi l'ensemble des <strong>cibles</strong> , j'ai choisi <strong>istgt</strong> , car il a les performances les plus √©lev√©es et fonctionne dans l'espace utilisateur. </p><br><p>  Maintenant, connectons-nous √† notre conteneur: </p><br><pre> <code class="hljs perl">pct <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span> bash</code> </pre> <br><p>  Installez les mises √† jour et <strong>istgt</strong> : </p><br><pre> <code class="hljs sql">apt-get <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y <span class="hljs-keyword"><span class="hljs-keyword">upgrade</span></span> apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> istgt</code> </pre> <br><p>  Cr√©ez un fichier que nous transmettrons sur le r√©seau: </p><br><pre> <code class="hljs powershell">mkdir <span class="hljs-literal"><span class="hljs-literal">-p</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span> fallocate <span class="hljs-literal"><span class="hljs-literal">-l</span></span> <span class="hljs-number"><span class="hljs-number">740</span></span>G /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/target1.img</code> </pre> <br><p>  Maintenant, nous devons √©crire une configuration pour <strong>istgt</strong> <code>/etc/istgt/istgt.conf</code> : </p><br><pre> <code class="hljs sql">[Global] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Global section"</span></span> NodeBase <span class="hljs-string"><span class="hljs-string">"iqn.2018-07.org.example.tgt1"</span></span> PidFile /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/run/istgt.pid AuthFile /etc/istgt/auth.conf MediaDirectory /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/istgt LogFacility <span class="hljs-string"><span class="hljs-string">"local7"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Timeout</span></span> <span class="hljs-number"><span class="hljs-number">30</span></span> NopInInterval <span class="hljs-number"><span class="hljs-number">20</span></span> DiscoveryAuthMethod <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> MaxSessions <span class="hljs-number"><span class="hljs-number">16</span></span> MaxConnections <span class="hljs-number"><span class="hljs-number">4</span></span> MaxR2T <span class="hljs-number"><span class="hljs-number">32</span></span> MaxOutstandingR2T <span class="hljs-number"><span class="hljs-number">16</span></span> DefaultTime2Wait <span class="hljs-number"><span class="hljs-number">2</span></span> DefaultTime2Retain <span class="hljs-number"><span class="hljs-number">60</span></span> FirstBurstLength <span class="hljs-number"><span class="hljs-number">262144</span></span> MaxBurstLength <span class="hljs-number"><span class="hljs-number">1048576</span></span> MaxRecvDataSegmentLength <span class="hljs-number"><span class="hljs-number">262144</span></span> InitialR2T Yes ImmediateData Yes DataPDUInOrder Yes DataSequenceInOrder Yes ErrorRecoveryLevel <span class="hljs-number"><span class="hljs-number">0</span></span> [UnitControl] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Internal Logical Unit Controller"</span></span> AuthMethod CHAP Mutual AuthGroup AuthGroup10000 Portal UC1 <span class="hljs-number"><span class="hljs-number">127.0</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>:<span class="hljs-number"><span class="hljs-number">3261</span></span> Netmask <span class="hljs-number"><span class="hljs-number">127.0</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span> [PortalGroup1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"SINGLE PORT TEST"</span></span> Portal DA1 <span class="hljs-number"><span class="hljs-number">192.168</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.11</span></span>:<span class="hljs-number"><span class="hljs-number">3260</span></span> [InitiatorGroup1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Initiator Group1"</span></span> InitiatorName <span class="hljs-string"><span class="hljs-string">"ALL"</span></span> Netmask <span class="hljs-number"><span class="hljs-number">192.168</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>/<span class="hljs-number"><span class="hljs-number">24</span></span> [LogicalUnit1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Hard Disk Sample"</span></span> TargetName disk1 TargetAlias <span class="hljs-string"><span class="hljs-string">"Data Disk1"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Mapping</span></span> PortalGroup1 InitiatorGroup1 AuthMethod <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> AuthGroup AuthGroup1 UseDigest <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> UnitType Disk LUN0 <span class="hljs-keyword"><span class="hljs-keyword">Storage</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/target1.img <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span></code> </pre> <br><p>  Red√©marrez istgt: </p><br><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">restart</span></span> istgt</code> </pre> <br><p>  Ceci termine le r√©glage cible </p><br><h2 id="nastroyka-ha">  Configuration HA </h2><br><p>  Nous pouvons maintenant passer √† la configuration du <strong>gestionnaire HA</strong> .  Cr√©ons un groupe HA distinct pour notre appareil: </p><br><pre> <code class="hljs powershell">ha<span class="hljs-literal"><span class="hljs-literal">-manager</span></span> groupadd tgt1 -<span class="hljs-literal"><span class="hljs-literal">-nodes</span></span> pve1,pve2,pve3 -<span class="hljs-literal"><span class="hljs-literal">-nofailback</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span> -<span class="hljs-literal"><span class="hljs-literal">-restricted</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  Notre <strong>ressource</strong> ne fonctionnera que sur les n≈ìuds sp√©cifi√©s pour ce groupe.  Ajoutez notre conteneur √† ce groupe: </p><br><pre> <code class="hljs powershell">ha<span class="hljs-literal"><span class="hljs-literal">-manager</span></span> add ct:<span class="hljs-number"><span class="hljs-number">101</span></span> -<span class="hljs-literal"><span class="hljs-literal">-group</span></span>=tgt1 -<span class="hljs-literal"><span class="hljs-literal">-max_relocate</span></span>=<span class="hljs-number"><span class="hljs-number">3</span></span> -<span class="hljs-literal"><span class="hljs-literal">-max_restart</span></span>=<span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br><h2 id="rekomendacii-i-tyuning">  Recommandations et r√©glages </h2><br><h5 id="drbd">  DRBD </h5><br><p>  Comme je l'ai not√© ci-dessus, il est toujours conseill√© d'utiliser un r√©seau distinct pour la r√©plication.  Il est fortement conseill√© d'utiliser des <strong>adaptateurs r√©seau 10 gigabits</strong> , sinon vous aurez une vitesse de port. <br>  Si la r√©plication semble assez lente, essayez certaines des options pour <strong>DRBD</strong> .  Voici la config, qui √† mon avis est optimale pour mon <strong>r√©seau 10G</strong> : </p><br><pre> <code class="hljs swift"># cat /etc/drbd.d/global_common.conf global { usage-<span class="hljs-built_in"><span class="hljs-built_in">count</span></span> yes; udev-always-use-vnr; } common { handlers { } startup { } options { } disk { <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-fill-target 10M; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-<span class="hljs-built_in"><span class="hljs-built_in">max</span></span>-rate 720M; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-plan-ahead <span class="hljs-number"><span class="hljs-number">10</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-<span class="hljs-built_in"><span class="hljs-built_in">min</span></span>-rate 20M; } net { <span class="hljs-built_in"><span class="hljs-built_in">max</span></span>-buffers 36k; sndbuf-size 1024k; rcvbuf-size 2048k; } }</code> </pre> <br><p>  Vous pouvez obtenir plus d'informations sur chaque param√®tre dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation officielle DRBD.</a> </p><br><h5 id="open-iscsi">  Ouvrez iSCSI </h5><br><p>  Puisque nous n'utilisons pas le multichemin, dans notre cas, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">il est recommand√© de</a> d√©sactiver les v√©rifications de connexion p√©riodiques sur les clients, ainsi que d'augmenter les d√©lais d'attente pour la r√©cup√©ration de session dans <code>/etc/iscsi/iscsid.conf</code> . </p><br><pre> <code class="hljs powershell">node.conn[<span class="hljs-number"><span class="hljs-number">0</span></span>].timeo.noop_out_interval = <span class="hljs-number"><span class="hljs-number">0</span></span> node.conn[<span class="hljs-number"><span class="hljs-number">0</span></span>].timeo.noop_out_timeout = <span class="hljs-number"><span class="hljs-number">0</span></span> node.session.timeo.replacement_timeout = <span class="hljs-number"><span class="hljs-number">86400</span></span></code> </pre> <br><h2 id="ispolzovanie">  Utiliser </h2><br><h4 id="proxmox">  Proxmox </h4><br><p>  La <strong>cible iSCSI</strong> r√©sultante peut √™tre imm√©diatement connect√©e √† Proxmox, sans oublier de d√©cocher <strong>Use LUN Directly</strong> . </p><br><p><img src="https://habrastorage.org/webt/uw/j3/pu/uwj3pusr-nf9bc7neisd5x-fcsg.png"></p><br><p>  Imm√©diatement apr√®s cela, il sera possible de cr√©er LVM par dessus, n'oubliez pas de cocher la case <strong>partag√©e</strong> : </p><br><p><img src="https://habrastorage.org/webt/j1/ob/mw/j1obmwcwhz-e6krjix72pmiz118.png"></p><br><h4 id="drugie-sredy">  Autres environnements </h4><br><p>  Si vous pr√©voyez d'utiliser cette solution dans un environnement diff√©rent, vous devrez peut-√™tre installer une extension de cluster pour LVM au moment o√π il y a deux impl√©mentations.  <strong>CLVM</strong> et <strong>lvmlockd</strong> . </p><br><p>  La configuration de <strong>CLVM n'est</strong> pas anodine et n√©cessite un gestionnaire de cluster fonctionnel. <br>  Alors qu'en tant que deuxi√®me m√©thode, <strong>lvmlockd</strong> n'est pas encore enti√®rement test√© et commence tout juste √† appara√Ætre dans des r√©f√©rentiels stables. </p><br><p>  Je recommande de lire un excellent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>article sur le blocage dans LVM</strong></a> </p><br><p>  Lors de l'utilisation de <strong>LVM</strong> avec <strong>Proxmox, l'</strong> ajout de cluster n'est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pas n√©cessaire</a> , car la gestion du volume est assur√©e par proxmox lui-m√™me, qui met √† jour et surveille les m√©tadonn√©es LVM ind√©pendamment.  Il en va de m√™me pour <strong>OpenNebula</strong> , comme l'indique clairement la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation officielle</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417597/">https://habr.com/ru/post/fr417597/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417587/index.html">M√©dias: les cyberattaques √† grande √©chelle ont acc√©l√©r√© la croissance de la capitalisation des entreprises du secteur de la s√©curit√© de l'information</a></li>
<li><a href="../fr417589/index.html">Sept r√®gles simples pour rendre Internet accessible √† tous</a></li>
<li><a href="../fr417591/index.html">Comment "apprendre" l'anglais en un an par vous-m√™me ou un article pour ceux qui ne s'entra√Ænent pas avec l'anglais</a></li>
<li><a href="../fr417593/index.html">NewSQL = NoSQL + ACID</a></li>
<li><a href="../fr417595/index.html">Antiquit√©s: Palm OS, code efficace et photos d√©go√ªtantes</a></li>
<li><a href="../fr417599/index.html">Recueil Fintech: les r√©gulateurs financiers ont besoin de l'IA pour travailler dans des conditions modernes</a></li>
<li><a href="../fr417601/index.html">Choisissez un serveur. Que chercher? Liste de contr√¥le</a></li>
<li><a href="../fr417603/index.html">Annonce d'un mitap mobile: que faire lorsque l'application est devenue volumineuse?</a></li>
<li><a href="../fr417605/index.html">Bases de la mod√©lisation 3D pour l'impression 3D</a></li>
<li><a href="../fr417607/index.html">Les tests A / B ne fonctionnent pas. V√©rifiez ce que vous faites mal</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧚 🍳 🐠 Grasp2Vec: Belajar Mewakili Objek melalui Capture Belajar Mandiri 🌑 ✍🏽 🧔🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Orang-orang dari usia muda yang mengejutkan sudah dapat mengenali benda-benda favorit mereka dan mengambilnya, terlepas dari kenyataan bahwa mereka ti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Grasp2Vec: Belajar Mewakili Objek melalui Capture Belajar Mandiri</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/434898/"><img src="https://habrastorage.org/getpro/habr/post_images/220/c80/5fb/220c805fb8ffb53d2b33413fa2e9eeda.png"><br><br>  Orang-orang dari usia muda yang mengejutkan sudah dapat mengenali benda-benda favorit mereka dan mengambilnya, terlepas dari kenyataan bahwa mereka tidak secara khusus mengajarkan hal ini.  Menurut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">penelitian tentang</a> pengembangan kemampuan kognitif, kemungkinan berinteraksi dengan objek dunia di sekitar kita memainkan peran penting dalam pengembangan kemampuan seperti merasakan dan memanipulasi objek - misalnya, penangkapan yang ditargetkan.  Berinteraksi dengan dunia luar, orang dapat belajar dengan memperbaiki kesalahan mereka sendiri: kita tahu apa yang telah kita lakukan dan belajar dari hasilnya.  Dalam robotika, jenis pelatihan dengan koreksi kesalahan sendiri dipelajari secara aktif, karena memungkinkan sistem robot untuk belajar tanpa sejumlah besar data pelatihan atau penyesuaian manual. <br><br>  Kami di Google, terinspirasi oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">konsep kegigihan objek</a> , menawarkan sistem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Grasp2Vec</a> - algoritma sederhana namun efektif untuk membangun representasi objek.  Grasp2Vec didasarkan pada pemahaman intuitif bahwa upaya untuk meningkatkan objek apa pun akan memberi kita beberapa informasi - jika robot mengambil objek dan mengambilnya, maka objek tersebut harus berada di tempat ini sebelum ditangkap.  Selain itu, robot tahu bahwa jika objek yang ditangkap ada dalam tangkapannya, itu berarti bahwa objek tersebut tidak lagi berada di tempat di mana ia berada.  Dengan menggunakan bentuk belajar mandiri ini, robot dapat belajar mengenali objek karena perubahan visual dalam adegan setelah ditangkap. <br><a name="habracut"></a><br>  Berdasarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kolaborasi</a> kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dengan X Robotics</a> , di mana beberapa robot secara bersamaan dilatih untuk menangkap objek rumah tangga menggunakan hanya satu kamera sebagai sumber data input, kami menggunakan robot capture untuk “secara tidak sengaja” menangkap objek, dan pengalaman ini memungkinkan kami untuk mendapatkan ide yang kaya tentang objek tersebut.  Ide ini sudah dapat digunakan untuk memperoleh kemampuan "capture yang disengaja", ketika lengan robot dapat meningkatkan objek sesuai permintaan. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/QzlI_ny4l8s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  Membuat Fungsi Hadiah Perseptual </h2><br>  Pada platform <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pembelajaran penguatan,</a> keberhasilan tugas diukur melalui fungsi hadiah.  Dengan memaksimalkan imbalan, robot mempelajari berbagai keterampilan menangkap <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dari awal</a> .  Membuat fungsi hadiah itu mudah ketika kesuksesan dapat diukur dengan pembacaan sensor sederhana.  Contoh sederhana adalah tombol yang mentransfer hadiah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">langsung ke input robot</a> dengan mengkliknya. <br><br>  Namun, menciptakan fungsi hadiah jauh lebih rumit ketika kriteria untuk sukses tergantung pada pemahaman perseptual tentang tugas tersebut.  Pertimbangkan masalah penangkapan dalam contoh di mana robot diberi gambar dari objek yang diinginkan yang dimiliki dalam penangkapan.  Setelah robot mencoba menangkap objek, ia memeriksa isi tangkapan.  Fungsi hadiah untuk tugas ini tergantung pada jawaban atas pertanyaan pengenalan pola: apakah objeknya bertepatan? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f23/a41/c24/f23a41c24b4cc60b062d055bbb5b9347.png"><br>  <i>Di sebelah kiri, pegangan memegang sikat, dan beberapa benda terlihat di latar belakang (cangkir kuning, blok plastik biru).</i>  <i>Di sebelah kanan, pegangan memegang cangkir, dan sikat ada di latar belakang.</i>  <i>Jika gambar kiri mewakili hasil yang diinginkan, fungsi hadiah yang baik adalah untuk "memahami" bahwa dua foto ini sesuai dengan dua objek yang berbeda.</i> <br><br>  Untuk mengatasi masalah pengenalan, kita membutuhkan sistem persepsi yang mengekstraksi konsep-konsep bermakna objek dari gambar tidak terstruktur (tidak ditandatangani oleh orang-orang), dan belajar untuk memvisualisasikan objek tanpa guru.  Pada dasarnya, algoritma pembelajaran tanpa guru bekerja dengan membuat asumsi struktural tentang data.  Sering diasumsikan bahwa gambar dapat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dikompresi ke ruang dengan dimensi lebih sedikit</a> , dan bingkai video dapat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">diprediksi dari yang sebelumnya</a> .  Namun, tanpa asumsi tambahan tentang isi data, ini biasanya tidak cukup untuk belajar dari representasi objek yang tidak terkait. <br><br>  Bagaimana jika kita menggunakan robot untuk memisahkan objek secara fisik selama pengumpulan data?  Robotika menawarkan kesempatan yang sangat baik untuk belajar bagaimana merepresentasikan objek, karena robot dapat memanipulasinya, yang akan memberikan faktor variasi yang diperlukan.  Metode kami didasarkan pada gagasan bahwa menangkap objek menghilangkannya dari tempat kejadian.  Hasilnya adalah 1) gambar pemandangan sebelum ditangkap, 2) gambar pemandangan setelah ditangkap, dan 3) pandangan terpisah dari objek yang ditangkap. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8da/43f/0d7/8da43f0d74077b6c65a80026ce7041f0.png"><br>  <i>Kiri - benda untuk ditangkap.</i>  <i>Di tengah - setelah penangkapan.</i>  <i>Di sebelah kanan adalah objek yang ditangkap.</i> <br><br>  Jika kami mempertimbangkan fungsi bawaan yang mengekstrak "set objek" dari gambar, ia harus mempertahankan relasi pengurangan berikut: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1c8/aa9/723/1c8aa97238f20d832c90f02335c0367c.png"><br>  <i>objek sebelum ditangkap - objek setelah ditangkap = objek yang diambil</i> <br><br>  Kami mencapai kesetaraan ini dengan arsitektur konvolusional dan algoritma pembelajaran metrik sederhana.  Selama pelatihan, arsitektur yang ditunjukkan di bawah ini menyematkan gambar sebelum dan sesudah penangkapan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">peta keruangan properti yang</a> padat.  Peta-peta ini berubah menjadi vektor melalui penyatuan rata-rata, dan perbedaan antara vektor "sebelum ditangkap" dan "setelah ditangkap" mewakili seperangkat objek.  Vektor ini dan representasi yang sesuai dari vektor objek yang dipersepsikan ini disamakan melalui fungsi pasangan-N. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/32f/e51/c0d/32fe51c0d4915374be646fc0bb2ba76c.png"><br><br>  Setelah pelatihan, model kami secara alami memiliki dua sifat yang bermanfaat. <br><br><h2>  1. Kesamaan benda </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Koefisien kosinus dari</a> jarak antara embeddings vektor memungkinkan kita untuk membandingkan objek dan menentukan apakah mereka identik.  Ini dapat digunakan untuk mengimplementasikan fungsi hadiah untuk pembelajaran yang diperkuat, dan memungkinkan robot belajar cara menangkap dengan contoh tanpa menandai data oleh manusia. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c47/fb7/dd4/c47fb7dd4c79a4e16564f9d6ab669f5e.png"><br><br><h2>  2. Menemukan target </h2><br>  Kita dapat menggabungkan peta spasial adegan dan pemasangan objek untuk melokalisasi "objek yang diinginkan" di ruang gambar.  Dengan melakukan penggandaan elemen dari peta fitur spasial dan korespondensi vektor dari objek yang diinginkan, kita dapat menemukan semua piksel pada peta spasial yang sesuai dengan objek target. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c42/271/47b/c4227147baeb69c052549544b9065961.png"><br>  <i>Menggunakan inlays Grasp2Vec untuk melokalkan objek dalam adegan.</i>  <i>Di atas kiri adalah benda di keranjang.</i>  <i>Kiri bawah - objek yang ingin diambil.</i>  <i>Produk skalar dari vektor objek target dan fitur spasial dari gambar memberi kita "peta aktivasi" per-pixel (kanan atas) dari kesamaan bagian gambar tertentu dengan target.</i>  <i>Peta ini dapat digunakan untuk lebih dekat ke target.</i> <br><br>  Metode kami juga berfungsi ketika beberapa objek sesuai dengan target, atau bahkan ketika target terdiri dari beberapa objek (rata-rata dua vektor).  Misalnya, dalam skenario ini, robot mengidentifikasi beberapa blok oranye di TKP. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4f3/f9e/b15/4f3f9eb159738345f5a8da4c1dfb83fc.png"><br>  <i>"Peta panas" yang dihasilkan dapat digunakan untuk merencanakan pendekatan robot ke objek target.</i>  <i>Kami menggabungkan pelokalan dari Grasp2Vec dan pengenalan pola dengan kebijakan "tangkap apa pun" dan capai keberhasilan dalam 80% kasus selama pengumpulan data dan 59% dengan objek baru yang belum pernah ditemukan sebelumnya oleh robot.</i> <br><br><h2>  Kesimpulan </h2><br>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pekerjaan</a> kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">,</a> kami menunjukkan bagaimana keterampilan gripper robot dapat membuat data yang digunakan untuk mengajarkan representasi objek.  Kemudian kita dapat menggunakan pelatihan presentasi untuk dengan cepat memperoleh keterampilan yang lebih kompleks, seperti menangkap sesuai dengan contoh, sambil mempertahankan semua sifat mengajar tanpa guru dalam sistem penangkapan otomatis kita. <br><br>  Selain pekerjaan kami, beberapa karya terbaru lainnya juga mempelajari bagaimana interaksi tanpa guru dapat digunakan untuk mendapatkan representasi objek, dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menangkap</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mendorong,</a> dan jenis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">interaksi lainnya</a> dengan objek di lingkungan.  Kami dengan gembira mengantisipasi tidak hanya pembelajaran mesin yang dapat memberikan robotika dalam hal persepsi dan kontrol yang lebih baik, tetapi juga robotika apa yang dapat memberikan pembelajaran mesin dalam hal paradigma belajar mandiri baru. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id434898/">https://habr.com/ru/post/id434898/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id434888/index.html">Hadiah Tahun Baru dari Binary District</a></li>
<li><a href="../id434890/index.html">Qiwi Bank (JSC) memberikan uang kepada pengguna</a></li>
<li><a href="../id434892/index.html">Menggambar kode dalam Swift, PaintCode</a></li>
<li><a href="../id434894/index.html">Seni perdukunan atau firmware khusus untuk Olinuxino. Bagian 1</a></li>
<li><a href="../id434896/index.html">Hall of Fame Elektronik Konsumen: Kisah Gadget Terbaik 50 Tahun Terakhir, Bagian 1</a></li>
<li><a href="../id434902/index.html">Membuat Generator Permintaan Kustom di Data Musim Semi Neo4j (Bagian 1)</a></li>
<li><a href="../id434906/index.html">Tes dalam C ++ tanpa makro dan memori dinamis</a></li>
<li><a href="../id434908/index.html">Pendidikan Programmer - Apa? Dimana? Kapan?</a></li>
<li><a href="../id434912/index.html">Stok tahunan Porsche Taycan sudah dipesan, terutama oleh pemilik Tesla</a></li>
<li><a href="../id434924/index.html">Apa yang harus dibaca tentang organisasi tempat kerja, rekan kerja, dan desain ruang untuk pekerjaan jarak jauh</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
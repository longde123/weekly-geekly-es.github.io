<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍🔧 🏡 ⛎ Animation réaliste de personnages dans des jeux utilisant l'IA 🎐 👼🏽 🧐</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les développeurs de l'Université d'Edimbourg ont introduit un nouvel algorithme pour créer des mouvements de personnages réalistes dans les jeux. Form...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Animation réaliste de personnages dans des jeux utilisant l'IA</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/474252/"><img src="https://habrastorage.org/webt/2w/dk/ed/2wdkedknmc5jpfb6gznv2hmrqqg.png"><br><br>  Les développeurs de l'Université d'Edimbourg ont introduit un nouvel algorithme pour créer des mouvements de personnages réalistes dans les jeux.  Formé sur les trajectoires de Motion Capture, le réseau de neurones essaie de copier les mouvements de personnes réelles, mais en même temps les adapte aux personnages des jeux vidéo. <br><br>  Un réseau de neurones est capable de gérer simultanément plusieurs actions dans le jeu.  Ouvrir des portes, déplacer des objets, utiliser des meubles.  En même temps, elle change dynamiquement la position des jambes et des bras afin que le personnage puisse tenir des tiroirs de différentes tailles de manière réaliste, s'asseoir sur des chaises de différentes tailles et aussi ramper dans des passages de différentes hauteurs. <br><a name="habracut"></a><br>  Habituellement, sous le contrôle de personnages dans des jeux utilisant l'IA, cela signifie un contrôle total des efforts dans les membres, basé sur une sorte de moteur physique qui imite les lois de la physique.  C'est le domaine de l'apprentissage automatique appelé apprentissage par renforcement.  Malheureusement, de cette manière, des mouvements réalistes ne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">peuvent pas</a> encore <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">être</a> réalisés. <br><br>  D'un autre côté, vous pouvez essayer d'entraîner le réseau neuronal à simuler les mouvements de personnes réelles capturées à l'aide de Motion Capture.  Ainsi, il y a environ un an, des progrès importants ont été réalisés dans l'animation réaliste de personnages 3D. <br><br><img src="https://habrastorage.org/webt/zn/yw/6w/znyw6woqcwlbfqzji3ywh_azzce.gif"><br><br><img src="https://habrastorage.org/webt/u1/l-/t3/u1l-t3ymdu6-e5nrs-c1pzqzhsc.gif"><br><br>  Il y a eu plusieurs travaux scientifiques consécutifs sur ce sujet, mais la description la plus complète peut être trouvée dans les travaux de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Towards a Virtual Stuntman</a> sur le réseau neuronal DeepMimic ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.youtube.com/watch?v=vppFvq2quQ0</a> ). <br><br>  L'idée principale est de simuler les mouvements humains pendant l'entraînement pour démarrer l'épisode non pas au tout début de la piste Motion Capture, comme ils l'ont fait auparavant, mais à partir de points aléatoires tout au long du chemin.  Les algorithmes d'apprentissage par renforcement existants explorent le voisinage du point de départ, de sorte qu'ils n'atteignent le plus souvent pas la fin de la trajectoire.  Mais si chaque épisode commence le long de toute la piste, les chances augmentent que le réseau neuronal apprenne à répéter toute la trajectoire. <br><br><img src="https://habrastorage.org/webt/3y/49/wj/3y49wjtdya9u6do5etxd3cvm-oe.png"><br><br>  Plus tard, cette idée a été reprise dans des domaines complètement différents.  Par exemple, en apprenant aux gens à jouer à un réseau de neurones dans les jeux, et aussi à démarrer des épisodes non pas depuis le début, mais à partir de points aléatoires (en particulier dans ce cas, depuis la fin et en se déplaçant progressivement vers le début), OpenAI a enseigné au réseau de neurones <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">à jouer à Montezuma's Revenge</a> .  Ce qui ne cédait pas aux algorithmes d'apprentissage par renforcement habituels auparavant. <br><br>  Sans cette astuce, les tentatives de formation du réseau neuronal pour copier des mouvements complexes ont échoué car le réseau neuronal a trouvé un chemin plus court.  Bien que ne donnant pas une récompense aussi importante que pour toute la trajectoire, mais il y avait quand même une sorte de récompense.  Par exemple, au lieu de faire un saut périlleux arrière, le réseau neuronal a simplement rebondi légèrement et s'est effondré sur le dos. <br><br><img src="https://habrastorage.org/webt/do/fi/ga/dofigaucbz2itdi4f8rqwns0tac.gif"><br><br>  Mais avec cette approche, le réseau neuronal étudie sans problème la trajectoire de presque n'importe quelle complexité. <br><br><img src="https://habrastorage.org/webt/6e/dw/e8/6edwe8z8lyxtfi6pk67tdmsdcye.gif"><br><br>  Le principal problème de DeepMimic, qui empêchait de l'appliquer directement aux jeux vidéo, était qu'il n'était pas possible de former le réseau neuronal à effectuer plusieurs animations différentes à la fois.  Il était nécessaire de former un réseau neuronal distinct pour chaque animation.  Les auteurs ont essayé de les combiner de différentes manières, mais plus de 3-4 animations n'ont pas pu être combinées. <br><br>  Dans le nouveau travail, ce problème n'est pas non plus complètement résolu, mais beaucoup de progrès ont été accomplis vers une transition en douceur entre les différentes animations. <br><br>  Il convient de noter que ce problème affecte tous les réseaux de neurones d'animation similaires existants.  Par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce réseau neuronal</a> , également formé à l'imitation de Motion Capture, est capable de contrôler honnêtement un très grand nombre de muscles (326!) De caractère humanoïde sur un moteur physique.  S'adapter à différents poids de poids levés et à diverses lésions articulaires.  Mais en même temps, pour chaque animation, un réseau neuronal formé distinct est nécessaire. <br><br>  Il faut comprendre que le but de tels réseaux de neurones n'est pas seulement de répéter l'animation humaine.  Et répétez-le sur le moteur physique.  Dans le même temps, les algorithmes d'apprentissage par renforcement rendent cette formation fiable et résistante aux interférences.  Ensuite, un tel réseau neuronal peut être transféré à un robot physique qui diffère en géométrie ou en masse d'une personne, mais il continuera toujours à répéter de manière réaliste les mouvements des personnes (à partir de zéro, comme déjà mentionné, cet effet n'a pas encore été atteint).  Ou, comme dans le travail ci-dessus, vous pouvez virtuellement explorer comment une personne blessée aux jambes se déplacera afin de développer des prothèses plus confortables. <br><br>  Même dans le premier DeepMimic, il y a eu les débuts d'une telle adaptation.  Il était possible de déplacer la balle rouge et le personnage lui lançait la balle à chaque fois.  Viser et mesurer la force de lancement pour frapper la cible exactement.  Bien qu'il ait été formé sur la seule piste Motion Capture, ce qui n'offre pas une telle opportunité. <br><br><img src="https://habrastorage.org/webt/ap/cm/rl/apcmrlwabrcrpjahbh0ogm6budi.gif"><br><br>  Par conséquent, cela peut être considéré comme un entraînement à part entière de l'IA, et l'imitation des mouvements humains vous permet simplement d'accélérer l'apprentissage et de rendre les mouvements visuellement plus attrayants, familiers pour nous (bien que du point de vue du réseau neuronal, ils ne soient peut-être pas les plus optimaux en même temps). <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">De nouveaux travaux sont</a> allés encore plus loin dans cette direction. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/7c6oQP1u2eQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Il n'y a pas de moteur physique, c'est un système purement d'animation pour les jeux vidéo.  Mais l'accent est mis sur une commutation réaliste entre plusieurs animations.  Et pour interagir avec les objets du jeu: déplacer des objets, utiliser des meubles, ouvrir des portes. <br><br><img src="https://habrastorage.org/webt/j8/6p/rw/j86prwghqyqp7b9clvhqszkreky.png"><br><br>  L'architecture du réseau neuronal se compose de deux parties.  L'un (Gating network), en fonction de l'état actuel de l'état et de l'objectif actuel, choisit l'animation à utiliser, et l'autre (Motion prediction network) prédit les images suivantes de l'animation. <br><br><img src="https://habrastorage.org/webt/np/rw/gk/nprwgkyhzzmgsvf6cb7hbxbq5bm.png"><br><br>  Tout cela a été formé sur un ensemble de pistes de capture de mouvement en utilisant l'apprentissage par renforcement par simulation. <br><br>  Mais la principale réalisation de ce travail est différente.  Dans la façon dont les développeurs ont appris au réseau neuronal à travailler avec des objets de différentes tailles et à se faufiler dans des passages de différentes largeurs ou hauteurs.  Pour que les positions des bras et des jambes soient réalistes et correspondent à la taille de l'objet avec lequel le personnage interagit dans le jeu. <br><br>  Le secret était simple: l'augmentation! <br><br>  Tout d'abord, à partir de la piste Motion Capture, ils ont déterminé les points de contact des mains avec les accoudoirs de la chaise.  Ensuite, ils ont remplacé le modèle de la chaise par une plus large et ont recalculé la trajectoire de Motion Capture de sorte que les mains touchent les accoudoirs aux mêmes points, mais sur une chaise plus large.  Et ils ont forcé le réseau neuronal à simuler cette nouvelle trajectoire générée par Motion Capture.  De même avec les dimensions des caisses, la hauteur des allées, etc. <br><br><img src="https://habrastorage.org/webt/5f/u5/eb/5fu5ebnogiwpxpxytwmjcwtl6hw.png"><br><br>  En répétant cela plusieurs fois avec différents modèles 3D de l'environnement avec lequel le joueur va interagir, le réseau neuronal a appris à manipuler de manière réaliste des objets de différentes tailles. <br><br><img src="https://habrastorage.org/webt/6c/5n/x9/6c5nx9quioedhbdcju4lgju4d8a.gif"><br><br>  Pour interagir avec l'environnement dans le jeu lui-même, il était en outre nécessaire de voxéliser les objets autour pour qu'il fonctionne comme des capteurs à l'entrée du réseau neuronal. <br><br><img src="https://habrastorage.org/webt/dz/y8/ed/dzy8edprhfcp98mpoaw5gtivjy4.png"><br><br>  Le résultat a été une très bonne animation pour les personnages du jeu.  Avec des transitions en douceur entre les actions et avec la possibilité d'interagir de manière réaliste avec des objets de différentes tailles. <br><br>  Je recommande fortement de regarder la vidéo si quelqu'un ne l'a pas déjà fait.  Il décrit en détail comment ils y sont parvenus. <br><br>  Cette approche peut être utilisée pour l'animation, y compris les animaux à quatre pattes, obtenant la qualité et le réalisme inégalés des mouvements des animaux et des monstres: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/uFJvRYtjQ4c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h4>  Les références </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vidéo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Page de projet avec source</a> <br>  Fichier PDF avec une description détaillée de l'œuvre: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SIGGRAPH_Asia_2019 / Paper.pdf</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr474252/">https://habr.com/ru/post/fr474252/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr474238/index.html">Conversations en conférence: 8 heures de théorie et de pratique de l'IA conversationnelle</a></li>
<li><a href="../fr474240/index.html">Orleans 3.0 est sorti</a></li>
<li><a href="../fr474244/index.html">SpaceFusion: Structurer un espace caché non structuré pour l'intelligence artificielle interactive</a></li>
<li><a href="../fr474246/index.html">JavaScript Meetup SuperJob: rapport vidéo</a></li>
<li><a href="../fr474250/index.html">VPN dans chaque maison ou comment apprivoiser le dragon</a></li>
<li><a href="../fr474254/index.html">Faire un effet collant cool pour un curseur sur React</a></li>
<li><a href="../fr474256/index.html">L'idée de trouver des gens dans la forêt</a></li>
<li><a href="../fr474268/index.html">Reconnaissance des circuits numériques. Déclenchement de comptage asynchrone</a></li>
<li><a href="../fr474274/index.html">Graphique des connaissances. Pluralité, temporalité, approche de l'activité</a></li>
<li><a href="../fr474276/index.html">«Entraînement de renforcement profond. AlphaGo et autres technologies ": l'annonce du livre</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
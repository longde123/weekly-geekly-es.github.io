<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ’˜ ğŸ•´ğŸ½ ğŸ•µï¸ Â«PiraterÂ» le cerveau en utilisant des Â«images-contradictionsÂ» ğŸ’• ğŸ’¢ ğŸ‘³</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les dÃ©veloppeurs de Google Brain ont prouvÃ© que les images "conflictuelles" peuvent contenir Ã  la fois une personne et un ordinateur; et les consÃ©quen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Â«PiraterÂ» le cerveau en utilisant des Â«images-contradictionsÂ»</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/410979/">  <i>Les dÃ©veloppeurs de Google Brain ont prouvÃ© que les images "conflictuelles" peuvent contenir Ã  la fois une personne et un ordinateur;</i>  <i>et les consÃ©quences possibles sont effrayantes.</i> <br><br><img src="https://habrastorage.org/webt/kk/ml/hy/kkmlhyjse2jplgycl1tsgsm9hc8.jpeg"><br><br>  Dans l'image ci-dessus - Ã  gauche, il y a sans aucun doute un chat.  Mais pouvez-vous dire avec certitude si le chat est Ã  droite, ou juste un chien qui lui ressemble?  La diffÃ©rence entre les deux est que le bon est fait en utilisant un algorithme spÃ©cial qui ne donne pas de modÃ¨les informatiques appelÃ©s "rÃ©seaux neuronaux convolutionnels" (CNN, rÃ©seau neuronal convolutionnel, ci-aprÃ¨s dÃ©nommÃ© SNA) pour conclure sans ambiguÃ¯tÃ© que dans l'image.  Dans ce cas, le SNS pense qu'il s'agit plus d'un chien que d'un chat, mais le plus intÃ©ressant - la plupart des gens pensent de la mÃªme maniÃ¨re. <br><a name="habracut"></a><br>  Il s'agit d'un exemple de ce que l'on appelle une Â«image contradictoireÂ» (ci-aprÃ¨s dÃ©nommÃ©e le KARP): elle est spÃ©cialement modifiÃ©e afin de tromper le SCN et d'Ã©viter que le contenu ne soit correctement identifiÃ©.  Les chercheurs de Google Brain ont voulu comprendre s'il Ã©tait possible de provoquer un dysfonctionnement des rÃ©seaux neuronaux biologiques dans nos tÃªtes de la mÃªme maniÃ¨re et, par consÃ©quent, ont crÃ©Ã© des options qui affectent Ã©galement les voitures et les personnes, leur faisant penser qu'ils regardent quelque chose qui pas vraiment. <br><br><h2>  Quelles sont les images contradictoires? </h2><br>  Presque partout, pour la reconnaissance dans le SCN, des algorithmes de classification visuelle sont utilisÃ©s.  En Â«montrantÂ» au programme un grand nombre d'illustrations diffÃ©rentes avec des pandas, vous pouvez l'entraÃ®ner Ã  reconnaÃ®tre les pandas, car il apprend par comparaison afin de distinguer une caractÃ©ristique commune Ã  l'ensemble.  DÃ¨s que le SCN (Ã©galement appelÃ© <i>Â«classificateursÂ»</i> ) recueille un Ã©ventail suffisant de Â«signes de pandaÂ» sur les donnÃ©es de formation, il sera capable de reconnaÃ®tre le panda dans toutes les nouvelles images qu'il fournira. <br><br>  On reconnaÃ®t les pandas par leurs caractÃ©ristiques abstraites: petites oreilles noires, grosses tÃªtes blanches, yeux noirs, fourrure et tout ce jazz.  Le SCN fait le contraire, ce qui n'est pas surprenant, car la quantitÃ© d'informations sur l'environnement que les gens interprÃ¨tent chaque minute est beaucoup plus importante.  Par consÃ©quent, en tenant compte des spÃ©cificitÃ©s des modÃ¨les, il est possible d'influencer les images de maniÃ¨re Ã  les rendre Â«incohÃ©rentesÂ» en les mÃ©langeant Ã  des donnÃ©es soigneusement calculÃ©es, aprÃ¨s quoi le rÃ©sultat pour une personne ressemblera presque Ã  l'original, mais complÃ¨tement diffÃ©rent pour le <i>classificateur</i> , qui commencera Ã  faire des erreurs en essayant de dÃ©terminer contenu. <br><br>  Voici un exemple de panda: <br><br><img src="https://habrastorage.org/webt/wb/af/gx/wbafgxu7uyekw8ttulsimx6zb-u.jpeg"><br>  <i>L'image d'un panda, combinÃ©e Ã  l'indignation, peut convaincre le classificateur qu'il s'agit en fait d'un gibbon.</i> <br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenAI</a></i> <br><br>  <i>Le classificateur</i> basÃ© sur le SCN est sÃ»r que le panda Ã  gauche est d'environ 60%.  Mais si vous complÃ©tez lÃ©gÃ¨rement ("crÃ©ez l'indignation") la source en ajoutant ce qui ressemble Ã  du bruit chaotique, le mÃªme classificateur sera sÃ»r Ã  99,3% qu'il regarde maintenant le gibbon.  De petits changements qui ne sont mÃªme pas clairement visibles donnent lieu Ã  une attaque trÃ¨s rÃ©ussie, mais cela ne fonctionnera que sur un modÃ¨le informatique spÃ©cifique et ne rÃ©alisera pas ceux qui pourraient Ãªtre "appris" sur autre chose. <br><br>  Afin de crÃ©er un contenu qui provoque une mauvaise rÃ©action parmi un nombre important et diversifiÃ© d'analystes artificiels, il faut agir plus grossiÃ¨rement - de minuscules corrections n'affecteront pas.  Ce qui fonctionne de maniÃ¨re fiable ne pourrait pas Ãªtre fait avec de Â«petits moyensÂ».  En d'autres termes, si vous voulez que le contenu fonctionne sous tous les angles et Ã  toutes les distances, vous devez intervenir de maniÃ¨re plus significative, ou, comme dirait une personne, plus Ã©vident. <br><br><h2>  Dans la vue - un homme </h2><br>  Voici deux exemples de carpes grossiÃ¨res, oÃ¹ une personne peut facilement dÃ©tecter des interfÃ©rences. <br><br><img src="https://habrastorage.org/webt/0w/jj/l-/0wjjl-t8xno-vpio5wd1-6x3aw4.jpeg"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Open AI</a> Ã  gauche, Google Brain Ã  droite</i> <br><br>  L'image du chat sur la gauche, que le SNS est dÃ©fini comme un ordinateur, a Ã©tÃ© rÃ©alisÃ©e en "gÃ©omÃ©trie brisÃ©e".  Si vous regardez de plus prÃ¨s (ou mÃªme pas trop prÃ¨s), vous verrez qu'il existe plusieurs structures angulaires et en forme de boÃ®te qui peuvent ressembler Ã  la forme d'une unitÃ© centrale.  Et l'image de la banane Ã  droite, qui est reconnue comme un grille-pain, donne rÃ©guliÃ¨rement un faux positif Ã  tout point de vue.  Les gens trouveront actuellement une banane ici, cependant, un Ã©trange engin Ã  cÃ´tÃ© a quelques signes d'un grille-pain - et cela fait un imbÃ©cile de technologie. <br><br>  Lorsque vous crÃ©ez une image Â«contradictoireÂ» appropriÃ©e et garantie dont vous avez besoin pour battre toute une entreprise de modÃ¨les de reconnaissance, cela conduit trÃ¨s souvent Ã  l'apparition d'un Â«facteur humainÂ».  En d'autres termes, ce qui confond un seul rÃ©seau de neurones peut ne pas du tout Ãªtre perÃ§u comme un problÃ¨me, et lorsque vous essayez d'obtenir un rÃ©bus qui est dÃ©finitivement adaptÃ© pour tromper cinq ou dix Ã  la fois, il s'avÃ¨re que cela fonctionne sur la base de mÃ©canismes qui, si les gens sont complÃ¨tement inutiles. <br><br>  En consÃ©quence, il n'est absolument pas nÃ©cessaire d'essayer de forcer une personne Ã  croire qu'un chat angulaire est un boÃ®tier d'ordinateur, et la somme d'une banane et d'un Ã©trange torchis ressemble Ã  un grille-pain.  Il est beaucoup mieux, lorsque vous crÃ©ez des CARP conÃ§us pour vous et moi, de vous concentrer immÃ©diatement sur l'utilisation de modÃ¨les qui perÃ§oivent le monde comme les gens. <br><br><h2>  Tromper l'Å“il (et le cerveau) </h2><br>  Le SNA avec une formation approfondie et une vision humaine sont quelque peu similaires, mais fondamentalement, le rÃ©seau neuronal Â«regardeÂ» les choses Â«de maniÃ¨re informatiqueÂ».  Par exemple, lorsqu'elle reÃ§oit une image, elle Â«voitÂ» une grille statique de pixels rectangulaires en mÃªme temps.  L'Å“il fonctionne diffÃ©remment, une personne perÃ§oit des dÃ©tails Ã©levÃ©s dans un secteur d'environ cinq degrÃ©s de chaque cÃ´tÃ© de la ligne de visÃ©e, mais en dehors de cette zone, l'attention au dÃ©tail diminue linÃ©airement. <br><br>  Ainsi, contrairement Ã  une machine, par exemple, le flou des bords d'une image ne fonctionnera pas avec une personne et passera simplement inaperÃ§u.  Les chercheurs ont pu modÃ©liser cette fonctionnalitÃ© en ajoutant une Â«couche de rÃ©tineÂ» qui a changÃ© les donnÃ©es fournies par le SNA pour ressembler Ã  l'Å“il, afin de limiter le rÃ©seau neuronal au mÃªme cadre que la vision normale. <br><br>  Il convient de noter qu'une personne fait face Ã  ses dÃ©ficiences de perception par le fait que le regard n'est pas dirigÃ© vers un point, mais se dÃ©place constamment, examinant l'image entiÃ¨re, mais il a Ã©galement Ã©tÃ© possible de compenser les conditions de l'expÃ©rience, en nivelant les diffÃ©rences entre le SCN et les personnes. <br><br>  <i>Remarque Ã  partir du travail lui-mÃªme:</i> <i><br></i>  <i>Chaque expÃ©rience a commencÃ© avec un rÃ©ticule d'installation, qui est apparu au centre de l'Ã©cran pendant 500 Ã  1000 millisecondes, et chaque sujet a Ã©tÃ© invitÃ© Ã  fixer son regard sur le rÃ©ticule.</i> <br><br>  L'utilisation de la Â«couche rÃ©tinienneÂ» Ã©tait la derniÃ¨re Ã©tape qui devait Ãªtre prise dans le cadre d'un Â«ajustement minceÂ» de l'apprentissage automatique pour les Â«caractÃ©ristiques humainesÂ».  Au cours de la gÃ©nÃ©ration des Ã©chantillons, ils ont Ã©tÃ© conduits Ã  travers dix modÃ¨les diffÃ©rents, dont chacun aurait dÃ» clairement appeler, disons, un chat, par exemple, un chien.  Si le rÃ©sultat Ã©tait Â«10 sur 10 se sont trompÃ©sÂ», alors le matÃ©riel a Ã©tÃ© soumis Ã  des tests chez l'homme. <br><br><h2>  Est-ce que cela fonctionne? </h2><br>  Trois groupes d'images ont Ã©tÃ© impliquÃ©s dans l'expÃ©rience: Â«animaux de compagnieÂ» (chats et chiens), Â«lÃ©gumesÂ» (courgettes et brocolis) et Â«menacesÂ» (araignÃ©es et serpents, bien qu'en tant que propriÃ©taire du serpent, je suggÃ¨re un terme diffÃ©rent pour l'Ã©valuation).  Pour chaque groupe, le succÃ¨s Ã©tait comptÃ© si la personne testÃ©e choisissait la mauvaise chose - appelait le chien un chat, et vice versa.  Les participants se sont assis devant un moniteur qui a affichÃ© une image pendant environ 60 ou 70 millisecondes, et ils ont dÃ» appuyer sur l'un des deux boutons pour indiquer l'objet.  Puisque l'image a Ã©tÃ© montrÃ©e pendant un temps trÃ¨s court, cela a attÃ©nuÃ© la diffÃ©rence entre la faÃ§on dont les gens et les rÃ©seaux de neurones perÃ§oivent le monde;  l'illustration dans le titre, par ailleurs, est frappante par sa persistance de l'erreur. <br><br>  Ce que les sujets ont montrÃ© pourrait Ãªtre une image non modifiÃ©e (image), un CarP Â«ordinaireÂ» (adv), un CarP Â«inversÃ©Â» (flip), sur lequel le bruit Ã©tait inversÃ© avant l'application, ou un Â«fauxÂ» CarP, sur lequel une couche avec du bruit a Ã©tÃ© appliquÃ© Ã  une image n'appartenant Ã  aucun des types du groupe (faux).  Les deux derniÃ¨res options ont Ã©tÃ© utilisÃ©es pour contrÃ´ler la nature de la perturbation (la structure du bruit affectera-t-elle autrement Ã  l'envers, ou simplement Â«manger-nonÂ»?), De plus, elles ont permis de comprendre si l'interfÃ©rence trompe complÃ¨tement les gens ou rÃ©duit lÃ©gÃ¨rement la prÃ©cision. <br><br>  <i>Remarque Ã  partir du travail lui-mÃªme:</i> <i><br></i>  <i>Faux: une condition a Ã©tÃ© ajoutÃ©e pour forcer le sujet Ã  commettre une erreur.</i>  <i>Nous l'avons ajoutÃ©, car si les changements initiaux rÃ©duisent la prÃ©cision de l'observateur, cela peut Ãªtre dÃ» Ã  une diminution de la qualitÃ© d'image directe.</i>  <i>Afin de montrer que les CARP fonctionnent rÃ©ellement dans chaque classe, nous avons introduit des options oÃ¹ aucun choix ne pouvait Ãªtre correct et leur prÃ©cision Ã©tait de 0, et nous avons observÃ© exactement quelle Ã©tait la Â«bonneÂ» rÃ©ponse dans ce cas.</i>  <i>Nous avons dÃ©montrÃ© des images arbitraires d'ImageNet, qui Ã©taient affectÃ©es par l'une ou l'autre classe du groupe, mais qui ne correspondaient Ã  aucune d'entre elles.</i>  <i>Le participant Ã  l'expÃ©rience devait dÃ©terminer ce qui se trouvait devant lui.</i>  <i>Par exemple, nous pourrions montrer une image d'un avion dÃ©formÃ©e en appliquant un bruit de Â«chienÂ», bien que pendant l'expÃ©rience, le sujet n'ait reconnu qu'un chat ou un chien.</i> <br><br>  Voici un exemple montrant un pourcentage du nombre de personnes qui ont pu identifier clairement une image en tant que chien, selon la faÃ§on dont le bruit a Ã©tÃ© utilisÃ©.  Permettez-moi de vous rappeler qu'il ne fallait que 60 Ã  70 millisecondes pour jeter un coup d'Å“il et prendre une dÃ©cision. <br><br><img src="https://habrastorage.org/webt/dp/1p/ho/dp1phollx9i0fpxcgipvfj188ww.jpeg"><br>  <i>Source: Google Brain</i> <i><br></i>  <i>Image originale avec un chien;</i>  <i>Carpe avec un chien, acceptÃ©e Ã  la fois par un homme et un ordinateur comme un chat;</i>  <i>contrÃ´ler l'image avec une couche de bruit Ã  l'envers.</i> <br><br>  Et voici les rÃ©sultats finaux: <br><br><img src="https://habrastorage.org/webt/ak/zh/s2/akzhs21jjvnofvwdbsrwe1al1di.jpeg"><br>  <i>Source: Google Brain</i> <i><br></i>  <i>Les rÃ©sultats de l'Ã©tude, comment les vraies personnes identifient ces images par rapport Ã  celles dÃ©formÃ©es.</i> <br><br>  Le graphique montre la prÃ©cision du match.  Si vous choisissez un chat et que c'est vraiment un chat, la prÃ©cision augmente.  Si vous choisissez un chat, mais c'est en fait un chien, transformÃ© par le bruit en une sorte de chat, la prÃ©cision est rÃ©duite. <br><br>  Comme vous pouvez le voir, les gens sont beaucoup plus corrects dans la sÃ©lection d'images non corrigÃ©es ou avec des couches de bruit inversÃ©es que dans la sÃ©lection d'images "incohÃ©rentes".  Cela prouve que le principe d'attaque de la perception peut nous Ãªtre transfÃ©rÃ© des ordinateurs. <br><br>  Non seulement les impacts sont indÃ©niablement efficaces, ils sont Ã©galement plus minces que prÃ©vu - pas de boxcats ou de pseudo-grille-pain, ou quelque chose comme Ã§a.  Comme nous avons vu les deux couches avec du bruit et des images avant et aprÃ¨s le traitement, nous devons comprendre ce qui nous confond exactement.  Bien que les chercheurs soient prudents, dÃ©clarant que "nos exemples sont spÃ©cialement conÃ§us pour faire un fou de la tÃªte, vous devez donc Ãªtre prudent en utilisant des personnes expÃ©rimentales pour Ã©tudier l'effet." <br><br>  L'Ã©quipe tentera Ã  l'avenir de dÃ©river quelques rÃ¨gles gÃ©nÃ©rales pour certaines catÃ©gories de modifications, y compris "la <b>destruction des bords d'un objet</b> , en particulier par des impacts moyens, perpendiculaires Ã  la ligne de bord; la <b>correction des zones limitrophes</b> en augmentant le contraste tout en texturant la bordure; en <b>changeant la texture</b> ; en <b>utilisant des parties sombres "des images</b> dans lesquelles le niveau d'impact sur la perception est Ã©levÃ© malgrÃ© de minuscules perturbations."  Voici des exemples de zones entourÃ©es de rouge dans lesquelles les mÃ©thodes dÃ©crites sont mieux vues. <br><br><img src="https://habrastorage.org/webt/r5/ri/mt/r5rimtrwujempyfjdywf5iqbuum.jpeg"><br>  <i>Source: Google Brain</i> <i><br></i>  <i>Exemples d'images avec diffÃ©rents principes de distorsion</i> <br><br><h2>  Quel est le rÃ©sultat? </h2><br>  L'essentiel est que c'est plus, bien plus qu'un simple truc intelligent.  Les gars de Google Brain ont confirmÃ© qu'ils peuvent crÃ©er une technique efficace de tromperie, mais ils ne comprennent pas entiÃ¨rement pourquoi cela fonctionne, compte tenu du niveau d'abstraction, et il est possible que ce soit littÃ©ralement un niveau de rÃ©alitÃ© de base: <br><br><blockquote>  Notre projet soulÃ¨ve des questions fondamentales sur le fonctionnement des CARP, le fonctionnement des rÃ©seaux de neurones et du cerveau.  Avez-vous rÃ©ussi Ã  transfÃ©rer des attaques du SCN vers le cerveau parce que les reprÃ©sentations sÃ©mantiques des informations qu'elles contiennent sont similaires?  Ou parce que ces deux reprÃ©sentations correspondent Ã  un certain modÃ¨le sÃ©mantique gÃ©nÃ©ral, qui existe naturellement dans le monde environnant? </blockquote><br><br>  En conclusion, si vous voulez vraiment devenir un peu paranoÃ¯aque, alors les chercheurs sont heureux de vous rendre service, soulignant que Â«la reconnaissance visuelle des objets ... il est difficile de donner une apprÃ©ciation objective.  La Â«Fig. 1Â» est-elle objectivement un chien, ou est-ce un chat objectif qui peut faire croire que c'est un chien? Â»  En d'autres termes, l'image se transforme-t-elle vraiment en objet ou vous fait-elle simplement penser diffÃ©remment? <br><br>  C'est effrayant ici (et je dis sÃ©rieusement "effrayant") qu'au final, vous pouvez trouver des moyens d'influencer n'importe quel fait, car la distance entre la manipulation du SCN et la manipulation d'une personne n'est Ã©videmment pas trop grande.  En consÃ©quence, les technologies d'apprentissage automatique peuvent potentiellement Ãªtre utilisÃ©es pour dÃ©former les images ou les vidÃ©os de la bonne maniÃ¨re, ce qui remplacera notre perception (et la rÃ©action correspondante), et nous ne comprendrons mÃªme pas ce qui s'est passÃ©.  Extrait du rapport: <br><br><blockquote>  Par exemple, un groupe de modÃ¨les avec une formation approfondie peut Ãªtre formÃ© sur les Ã©valuations des personnes du niveau de confiance dans certains types de personnes, caractÃ©ristiques, expressions.  Il deviendra possible de gÃ©nÃ©rer des indignations Â«conflictuellesÂ» qui augmenteront ou diminueront le sentiment de Â«crÃ©dibilitÃ©Â», et de tels matÃ©riaux Â«peaufinÃ©sÂ» peuvent Ãªtre utilisÃ©s dans des clips d'actualitÃ© ou de la publicitÃ© politique. <br><br>  Ã€ l'avenir, les risques thÃ©oriques incluent la possibilitÃ© de crÃ©er des stimulations sensorielles qui pÃ©nÃ¨trent dans le cerveau de diffÃ©rentes maniÃ¨res et avec une trÃ¨s grande efficacitÃ©.  Comme vous le savez, de nombreux animaux sont considÃ©rÃ©s comme vulnÃ©rables aux stimulations dÃ©passant le seuil.  Disons que les coucous peuvent simultanÃ©ment faire semblant d'Ãªtre impuissants et faire un appel plaintif, ce qui, en combinaison, oblige les oiseaux d'autres races Ã  nourrir les poussins de coucou avant leur propre progÃ©niture.  Les Ã©chantillons Â«conflictuelsÂ» peuvent Ãªtre considÃ©rÃ©s comme une forme particuliÃ¨re de stimulation Ã  seuil supÃ©rieur pour les rÃ©seaux de neurones.  Et le fait que des stimuli excessifs, qui sont en thÃ©orie beaucoup plus susceptibles d'affecter une personne que de simplement lui faire accrocher une Ã©tiquette "un chat" sur la photo d'un chien, cause une prÃ©occupation considÃ©rable, peut Ãªtre crÃ©Ã© Ã  l'aide d'une machine puis transfÃ©rÃ© Ã  des personnes. </blockquote><br>  Bien sÃ»r, de telles mÃ©thodes peuvent Ãªtre utilisÃ©es Â«pour le bienÂ», et un certain nombre d'options ont dÃ©jÃ  Ã©tÃ© proposÃ©es, telles que Â«affiner les traits caractÃ©ristiques des images afin d'augmenter le niveau de concentration, par exemple, lors du contrÃ´le de la situation de l'air ou de l'analyse d'images radiographiques, car ce travail est monotone et les consÃ©quences la nÃ©gligence peut Ãªtre terrible. "  De plus, Â«les concepteurs d'interfaces utilisateur peuvent utiliser des perturbations pour dÃ©velopper des interfaces plus intuitivesÂ».  Hmmm.  C'est certainement gÃ©nial, mais je suis en quelque sorte plus prÃ©occupÃ© par le fait de pirater mon cerveau et d'Ã©tablir le niveau de confiance dans les gens, vous savez? <br><br>  Certaines des questions posÃ©es feront l'objet de recherches futures - il est possible de dÃ©couvrir ce qui rend exactement des images spÃ©cifiques plus appropriÃ©es pour transmettre une erreur Ã  une personne, et cela peut fournir de nouveaux indices pour comprendre les principes du cerveau.  Et cela, Ã  son tour, aidera Ã  crÃ©er des rÃ©seaux de neurones plus avancÃ©s qui apprendront plus rapidement et mieux.  Mais nous devons Ãªtre prudents et nous rappeler que, comme les ordinateurs, il nâ€™est parfois pas si difficile de nous tromper. <br><br>  Le projet <i>" <b>Adversarial Examples that Fool both Human and Computer Vision</b> , par Gamaleldin F. Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot, Alex Kurakin, Ian Goodfellow, and Jascha Sohl-Dickstein, from Google Brain"</i> , peut Ãªtre tÃ©lÃ©chargÃ© Ã  partir d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">arXiv</a> .  Et si vous avez besoin d'images plus controversÃ©es qui travaillent sur les gens, alors le matÃ©riel d'appui est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr410979/">https://habr.com/ru/post/fr410979/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr410961/index.html">15 biais cognitifs</a></li>
<li><a href="../fr410963/index.html">Ã€ quoi ressemble la courbe en forme de S des portefeuilles mobiles</a></li>
<li><a href="../fr410969/index.html">5 technologies pour les cinq prochaines annÃ©es: prÃ©visions d'IBM</a></li>
<li><a href="../fr410973/index.html">Quels drones sont utilisÃ©s dans le cinÃ©ma mondial</a></li>
<li><a href="../fr410977/index.html">Une tentative de crÃ©er un pÃ©riphÃ©rique d'entrÃ©e d'informations universel</a></li>
<li><a href="../fr410981/index.html">Yandex a ajoutÃ© une protection contre les mineurs cryptographiques Ã  son navigateur</a></li>
<li><a href="../fr410985/index.html">Solution open source pour dÃ©cupler la latence de lecture des donnÃ©es avec Apache Cassandra</a></li>
<li><a href="../fr410987/index.html">GLONASS sera rendu aussi prÃ©cis que le systÃ¨me de navigation GPS</a></li>
<li><a href="../fr410989/index.html">PrÃ©dÃ©cesseurs des bracelets de fitness: podomÃ¨tre, moniteur de frÃ©quence cardiaque, ordinateur de vÃ©lo</a></li>
<li><a href="../fr410991/index.html">Portefeuille matÃ©riel de crypto-monnaie Ledger piratÃ© par un pirate de 15 ans</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
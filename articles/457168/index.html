<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí® üé¶ ‚õàÔ∏è An√°lisis de sentimiento de prototipo con Python y TextBlob üõÄüèæ üë©üèæ‚Äçüîß üëì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬øQu√© es importante para un equipo de desarrollo que reci√©n comienza a construir un sistema de aprendizaje autom√°tico? La arquitectura, los componentes...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>An√°lisis de sentimiento de prototipo con Python y TextBlob</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457168/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/8l/ir/g2/8lirg2klkrmofom9vhhcgldh-qo.jpeg" alt="imagen"></div><br>  ¬øQu√© es importante para un equipo de desarrollo que reci√©n comienza a construir un sistema de aprendizaje autom√°tico?  La arquitectura, los componentes, las capacidades de prueba usando la integraci√≥n y las pruebas unitarias, hacen un prototipo y obtienen los primeros resultados.  Y adem√°s de la evaluaci√≥n de la aportaci√≥n laboral, la planificaci√≥n del desarrollo y la implementaci√≥n. <br><br>  Este art√≠culo se centrar√° en el prototipo.  El cual fue creado alg√∫n tiempo despu√©s de hablar con el Gerente de Producto: ¬øpor qu√© no "tocamos" Machine Learning?  En particular, PNL y an√°lisis de sentimientos? <br><a name="habracut"></a><br>  "¬øPor qu√© no?"  Respond√≠  A√∫n as√≠, llevo m√°s de 15 a√±os desarrollando backend, me gusta trabajar con datos y resolver problemas de rendimiento.  Pero a√∫n ten√≠a que averiguar "qu√© tan profundo es la madriguera del conejo". <br><br><h2>  Seleccionar componentes </h2><br>  Para delinear de alguna manera el conjunto de componentes que implementan la l√≥gica de nuestro n√∫cleo de ML, echemos un vistazo a un ejemplo simple de la implementaci√≥n del an√°lisis de sentimientos, uno de los muchos disponibles en GitHub. <br><br><div class="spoiler">  <b class="spoiler_title">Un ejemplo de an√°lisis de sentimientos en Python</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( datasets, model_selection, feature_extraction, linear_model ) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">extract_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(corpus)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''Extract TF-IDF features from corpus'''</span></span> <span class="hljs-comment"><span class="hljs-comment"># vectorize means we turn non-numerical data into an array of numbers count_vectorizer = feature_extraction.text.CountVectorizer( lowercase=True, # for demonstration, True by default tokenizer=nltk.word_tokenize, # use the NLTK tokenizer stop_words='english', # remove stop words min_df=1 # minimum document frequency, ie the word must appear more than once. ) processed_corpus = count_vectorizer.fit_transform(corpus) processed_corpus = feature_extraction.text.TfidfTransformer().fit_transform( processed_corpus) return processed_corpus data_directory = 'movie_reviews' movie_sentiment_data = datasets.load_files(data_directory, shuffle=True) print('{} files loaded.'.format(len(movie_sentiment_data.data))) print('They contain the following classes: {}.'.format( movie_sentiment_data.target_names)) movie_tfidf = extract_features(movie_sentiment_data.data) X_train, X_test, y_train, y_test = model_selection.train_test_split( movie_tfidf, movie_sentiment_data.target, test_size=0.30, random_state=42) # similar to nltk.NaiveBayesClassifier.train() model = linear_model.LogisticRegression() model.fit(X_train, y_train) print('Model performance: {}'.format(model.score(X_test, y_test))) y_pred = model.predict(X_test) for i in range(5): print('Review:\n{review}\n-\nCorrect label: {correct}; Predicted: {predict}'.format( review=X_test[i], correct=y_test[i], predict=y_pred[i] ))</span></span></code> </pre> <br></div></div><br>  Analizar estos ejemplos es un desaf√≠o separado para el desarrollador. <br>  Solo 45 l√≠neas de c√≥digo y 4 (¬°cuatro, Karl!) Bloques l√≥gicos a la vez: <br><br><ol><li>  Descarga de datos para capacitaci√≥n modelo (l√≠neas 25-26) </li><li>  Preparaci√≥n de datos cargados - extracci√≥n de caracter√≠sticas (l√≠neas 31-34) </li><li>  Crear y entrenar un modelo (l√≠neas 36-39) </li><li>  Probar un modelo entrenado y generar resultados (l√≠neas 41-45) </li></ol><br>  Cada uno de estos puntos merece un art√≠culo separado.  Y ciertamente requiere registro en un m√≥dulo separado.  Al menos para las necesidades de pruebas unitarias. <br><br>  Por separado, vale la pena destacar los componentes de la preparaci√≥n de datos y la capacitaci√≥n modelo. <br>  En cada una de las formas de hacer que el modelo sea m√°s preciso, se invierten cientos de horas de trabajo cient√≠fico y de ingenier√≠a. <br><br>  Afortunadamente, para comenzar r√°pidamente con NLP, hay una soluci√≥n preparada: las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bibliotecas NLTK</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TextBlob</a> .  El segundo es un envoltorio sobre NLTK que hace la tarea: realiza la extracci√≥n de caracter√≠sticas del conjunto de entrenamiento y luego entrena el modelo en la primera solicitud de clasificaci√≥n. <br><br>  Pero antes de entrenar el modelo, debe preparar datos para √©l. <br><br><h2>  Preparando datos </h2><br><h3>  Descargar datos </h3><br>  Si hablamos del prototipo, la carga de datos desde un archivo CSV / TSV es elemental.  Simplemente llame a la funci√≥n <b>read_csv</b> desde la biblioteca de pandas: <br><br><pre> <code class="plaintext hljs">import pandas as pd data = pd.read_csv(data_path, delimiter)</code> </pre><br>  Pero no ser√°n datos listos para usar en el modelo. <br><br>  En primer lugar, si ignoramos un poco el formato csv, es f√°cil esperar que cada fuente proporcione datos con sus propias caracter√≠sticas y, por lo tanto, necesitamos alg√∫n tipo de preparaci√≥n de datos dependiente de la fuente.  Incluso para el caso m√°s simple de un archivo CSV, para analizarlo, necesitamos conocer el delimitador. <br><br>  Adem√°s, debe determinar qu√© entradas son positivas y cu√°les negativas.  Por supuesto, esta informaci√≥n se indica en la anotaci√≥n de los conjuntos de datos que queremos usar.  Pero el hecho es que en un caso el signo de pos / neg es 0 o 1, en el otro es l√≥gico Verdadero / Falso, en el tercero es solo una cadena pos / neg, y en algunos casos, una tupla de enteros de 0 a 5 Este √∫ltimo es relevante para el caso de la clasificaci√≥n multiclase, pero ¬øqui√©n dijo que dicho conjunto de datos no puede usarse para la clasificaci√≥n binaria?  Solo necesita identificar adecuadamente el borde de los valores positivos y negativos. <br><br>  Me gustar√≠a probar el modelo en diferentes conjuntos de datos, y se requiere que, despu√©s del entrenamiento, el modelo devuelva el resultado en un solo formato.  Y para esto, sus datos heterog√©neos deben llevarse a una sola forma. <br><br>  Entonces, hay tres funciones que necesitamos en la etapa de carga de datos: <br><br><ol><li>  La conexi√≥n a la fuente de datos es para CSV, en nuestro caso se implementa dentro de la funci√≥n read_csv; </li><li>  Soporte para funciones de formato; </li><li>  Preparaci√≥n de datos preliminares. </li></ol><br>  As√≠ es como se ve en el c√≥digo. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># linear algebra import pandas as pd # data processing, CSV file I/O (eg pd.read_csv) import logging log = logging.getLogger() class CsvSentimentDataLoader(): def __init__(self, file_path, delim, text_attr, rate_attr, pos_rates): self.data_path = file_path self.delimiter = delim self.text_attr = text_attr self.rate_attr = rate_attr self.pos_rates = pos_rates def load_data(self): #     csv  tsv  data = pd.read_csv(self.data_path, self.delimiter) data.head() #   , #      data = data[[self.text_attr, self.rate_attr]] #    #     'pos'  'neg' data[self.rate_attr] = np.where( data[self.rate_attr].isin(self.pos_rates), 'pos', 'neg') return data</span></span></code> </pre><br>  Se <b>cre√≥ la</b> clase <b>CsvSentimentDataLoader</b> , que en el constructor pasa la ruta a csv, el separador, los nombres del texto y los atributos de clasificaci√≥n, as√≠ como una lista de valores que aconsejan el valor positivo del texto. <br><br>  La carga en s√≠ ocurre en el m√©todo <b>load_data</b> . <br><br><h3>  Dividimos los datos en conjuntos de prueba y entrenamiento. </h3><br>  Ok, subimos los datos, pero a√∫n necesitamos dividirlos en los conjuntos de entrenamiento y prueba. <br><br>  Esto se hace con la funci√≥n <b>train_test_split</b> de la biblioteca <b>sklearn</b> .  Esta funci√≥n puede tomar muchos par√°metros como entrada, determinando c√≥mo se dividir√° exactamente este conjunto de datos en tren y prueba.  Estos par√°metros afectan significativamente el entrenamiento resultante y los conjuntos de pruebas, y probablemente sea conveniente para nosotros crear una clase (llam√©mosla SimpleDataSplitter) que administrar√° estos par√°metros y agregar√° la llamada a esta funci√≥n. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-comment"><span class="hljs-comment"># to split the training and testing data import logging log = logging.getLogger() class SimpleDataSplitter(): def __init__(self, text_attr, rate_attr, test_part_size=.3): self.text_attr = text_attr self.rate_attr = rate_attr self.test_part_size = test_part_size def split_data(self, data): x = data[self.text_attr] y = data[self.rate_attr] x_train, x_test, y_train, y_test = train_test_split( x, y, test_size = self.test_part_size) return x_train, x_test, y_train, y_test</span></span></code> </pre><br>  Ahora esta clase incluye la implementaci√≥n m√°s simple, que, cuando se divide, tendr√° en cuenta solo un par√°metro: el porcentaje de registros que deben tomarse como un conjunto de pruebas. <br><br><h3>  Conjuntos de datos </h3><br>  Para entrenar el modelo, utilic√© conjuntos de datos disponibles gratuitamente en formato CSV: <br><br><ul><li>  Conjunto de datos de Amazon Alexa Reviews, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">disponible en Kaggle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conjunto de datos de oraciones etiquetadas de sentimiento</a> de la Universidad de California </li></ul><br>  Y para hacerlo a√∫n m√°s conveniente, para cada uno de los conjuntos de datos hice una clase que carga datos del archivo CSV correspondiente y los divide en conjuntos de entrenamiento y prueba. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> web.data.loaders <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CsvSentimentDataLoader <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> web.data.splitters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SimpleDataSplitter, TdIdfDataSplitter log = logging.getLogger() <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AmazonAlexaDataset</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.file_path = os.path.normpath(os.path.join(os.path.dirname(__file__), <span class="hljs-string"><span class="hljs-string">'amazon_alexa/train.tsv'</span></span>)) self.delim = <span class="hljs-string"><span class="hljs-string">'\t'</span></span> self.text_attr = <span class="hljs-string"><span class="hljs-string">'verified_reviews'</span></span> self.rate_attr = <span class="hljs-string"><span class="hljs-string">'feedback'</span></span> self.pos_rates = [<span class="hljs-number"><span class="hljs-number">1</span></span>] self.data = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.train = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.test = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> loader = CsvSentimentDataLoader(self.file_path, self.delim, self.text_attr, self.rate_attr, self.pos_rates) splitter = SimpleDataSplitter(self.text_attr, self.rate_attr, test_part_size=<span class="hljs-number"><span class="hljs-number">.3</span></span>) self.data = loader.load_data() x_train, x_test, y_train, y_test = splitter.split_data(self.data) self.train = [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(x_train, y_train)] self.test = [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(x_test, y_test)]</code> </pre><br>  S√≠, para la carga de datos, result√≥ un poco m√°s de 5 l√≠neas de c√≥digo en el ejemplo original. <br>  Pero ahora es posible crear nuevos conjuntos de datos haciendo malabares con las fuentes de datos y los algoritmos de preparaci√≥n de conjuntos de entrenamiento. <br><br>  Adem√°s, los componentes individuales son mucho m√°s convenientes para las pruebas unitarias. <br><br><h2>  Nosotros entrenamos el modelo </h2><br>  El modelo ha estado aprendiendo durante bastante tiempo.  Y esto debe hacerse una vez, al comienzo de la aplicaci√≥n. <br>  Para estos fines, se cre√≥ un peque√±o contenedor que le permite descargar y preparar datos, as√≠ como entrenar el modelo en el momento de la inicializaci√≥n de la aplicaci√≥n. <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TextBlobWrapper</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.log = logging.getLogger() self.is_model_trained = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> self.classifier = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_app</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.log.info(<span class="hljs-string"><span class="hljs-string">'&gt;&gt;&gt;&gt;&gt; TextBlob initialization started'</span></span>) self.ensure_model_is_trained() self.log.info(<span class="hljs-string"><span class="hljs-string">'&gt;&gt;&gt;&gt;&gt; TextBlob initialization completed'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ensure_model_is_trained</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> self.is_model_trained: ds = SentimentLabelledDataset() ds.load_data() <span class="hljs-comment"><span class="hljs-comment"># train the classifier and test the accuracy self.classifier = NaiveBayesClassifier(ds.train) acr = self.classifier.accuracy(ds.test) self.log.info(str.format('&gt;&gt;&gt;&gt;&gt; NaiveBayesClassifier trained with accuracy {}', acr)) self.is_model_trained = True return self.classifier</span></span></code> </pre><br>  Primero obtenemos datos de entrenamiento y prueba, luego hacemos extracci√≥n de caracter√≠sticas, y finalmente entrenamos el clasificador y verificamos la precisi√≥n en el conjunto de prueba. <br><br><h2>  Prueba </h2><br>  Tras la inicializaci√≥n, obtenemos un registro, a juzgar por el cual, los datos se descargaron y el modelo se entren√≥ con √©xito.  Y entrenado con muy buena precisi√≥n (para empezar): 0.8878. <br><br><img src="https://habrastorage.org/webt/nl/hw/pt/nlhwptjx8xnwfao2anynttvbr1u.png" alt="imagen"><br><br>  Habiendo recibido tales n√∫meros, estaba muy entusiasmado.  Pero mi alegr√≠a, desafortunadamente, no fue larga.  El modelo entrenado en este conjunto es un optimista impenetrable y, en principio, no puede reconocer comentarios negativos. <br><br>  La raz√≥n de esto est√° en los datos del conjunto de entrenamiento.  El n√∫mero de cr√≠ticas positivas en el conjunto supera el 90%.  En consecuencia, con una precisi√≥n del modelo de aproximadamente el 88%, las revisiones negativas simplemente caen dentro del 12% esperado de las clasificaciones incorrectas. <br><br>  En otras palabras, con tal conjunto de entrenamiento, es simplemente imposible entrenar al modelo para que reconozca los comentarios negativos. <br><br>  Para asegurarme realmente de esto, hice una prueba unitaria que ejecuta la clasificaci√≥n por separado para 100 frases positivas y 100 negativas de otro conjunto de datos; para probar, tom√© el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conjunto de datos de oraciones etiquetadas de sentimiento</a> de la Universidad de California. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @loggingtestcase.capturelogs(None, level='INFO') def test_classifier_on_separate_set(self, logs): tb = TextBlobWrapper() # Going to be trained on Amazon Alexa dataset ds = SentimentLabelledDataset() # Test dataset ds.load_data() # Check poisitives true_pos = 0 data = ds.data.to_numpy() seach_mask = np.isin(data[:, 1], ['pos']) data = data[seach_mask][:100] for e in data[:]: # Model train will be performed on first classification call r = tb.do_sentiment_classification(e[0]) if r == e[1]: true_pos += 1 self.assertLessEqual(true_pos, 100) print(str.format('\n\nTrue Positive answers - {} of 100', true_pos))</span></span></code> </pre><br>  El algoritmo para probar la clasificaci√≥n de valores positivos es el siguiente: <br><br><ul><li>  Descargar datos de prueba; </li><li>  Tome 100 publicaciones etiquetadas 'pos' </li><li>  Ejecutamos cada uno de ellos a trav√©s del modelo y contamos el n√∫mero de resultados correctos </li><li>  Muestra el resultado final en la consola. </li></ul><br>  Del mismo modo, se realiza un recuento de comentarios negativos. <br><br><div class="spoiler">  <b class="spoiler_title">Resultado</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/79/lj/px/79ljpxifxo5sl1kpdt_h0q4zd58.png" alt="imagen"><br></div></div><br>  Como se esperaba, todos los comentarios negativos fueron reconocidos como positivos. <br><br>  Y si entrena el modelo en el conjunto de datos utilizado para las pruebas, ¬ø <b>etiqueta de sentimiento</b> ?  All√≠, la distribuci√≥n de comentarios negativos y positivos es exactamente de 50 a 50. <br><br><div class="spoiler">  <b class="spoiler_title">Cambia el c√≥digo y prueba, ejecuta</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/tj/cw/oo/tjcwoocc2qodmbd5zl7emwqt8ve.png" alt="imagen"><br></div></div><br>  Algo ya  La precisi√≥n real de 200 entradas de un conjunto de terceros es del 76%, mientras que la precisi√≥n de la clasificaci√≥n de comentarios negativos es del 79%. <br><br>  Por supuesto, el 76% lo har√° para un prototipo, pero no lo suficiente para la producci√≥n.  Esto significa que se requerir√°n medidas adicionales para mejorar la precisi√≥n del algoritmo.  Pero este es un tema para otro informe. <br><br><h2>  Resumen </h2><br>  En primer lugar, obtuvimos una aplicaci√≥n con una docena de clases y m√°s de 200 l√≠neas de c√≥digo, que es un poco m√°s que el ejemplo original de 30 l√≠neas.  Y debe ser honesto: estos son solo indicios de la estructura, la primera aclaraci√≥n de los l√≠mites de la aplicaci√≥n futura.  Prototipo. <br><br>  Y este prototipo permiti√≥ darse cuenta de cu√°n lejos est√° la distancia entre los enfoques del c√≥digo desde el punto de vista de los especialistas en Machine Learning y desde el punto de vista de los desarrolladores de aplicaciones tradicionales.  Y esta, en mi opini√≥n, es la principal dificultad para los desarrolladores que deciden probar el aprendizaje autom√°tico. <br><br>  Lo siguiente que puede poner a un principiante en un estupor: los datos no son menos importantes que el modelo seleccionado.  Esto se ha demostrado claramente. <br><br>  Adem√°s, siempre existe la posibilidad de que un modelo entrenado en algunos datos se muestre de manera inadecuada en otros, o en alg√∫n momento su precisi√≥n comenzar√° a degradarse. <br>  En consecuencia, se requieren m√©tricas para monitorear el estado del modelo, flexibilidad al trabajar con datos, capacidades t√©cnicas para ajustar el aprendizaje sobre la marcha.  Y as√≠ sucesivamente. <br><br>  En cuanto a m√≠, todo esto debe tenerse en cuenta al dise√±ar la arquitectura y los procesos de desarrollo del edificio. <br><br>  En general, la "madriguera del conejo" no solo era muy profunda, sino que tambi√©n era extremadamente inteligente.  Pero lo m√°s interesante para m√≠, como desarrollador, es estudiar este tema en el futuro. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/457168/">https://habr.com/ru/post/457168/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457152/index.html">Conferencia DEFCON 25. Garry Kasparov. "La √∫ltima batalla del cerebro". Parte 1</a></li>
<li><a href="../457154/index.html">Dise√±o de aplicaci√≥n receptiva para cada usuario</a></li>
<li><a href="../457156/index.html">¬øCu√°les pueden ser los sistemas inform√°ticos del futuro?</a></li>
<li><a href="../457160/index.html">Mi enfoque para implementar delegados en C ++: llamar a una funci√≥n con par√°metros desconocidos en tiempo de ejecuci√≥n</a></li>
<li><a href="../457164/index.html">Navegaci√≥n en una aplicaci√≥n multiplataforma .NET Core con guardar estado en disco usando el ejemplo de ReactiveUI y Avalonia</a></li>
<li><a href="../457172/index.html">ScreenLogger - sonr√≠e, una c√°mara oculta te filma</a></li>
<li><a href="../457178/index.html">C√≥mo se dise√±an y fabrican los procesadores: dise√±o de CPU</a></li>
<li><a href="../457180/index.html">El sitio oficial Node.js ahora est√° en ruso</a></li>
<li><a href="../457182/index.html">Lengua REXX, 40 aniversario</a></li>
<li><a href="../457184/index.html">Crear din√°micamente robots.txt para sitios principales de ASP.NET</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
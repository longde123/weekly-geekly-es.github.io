<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥀 🚊 🤴 Ok Google: Comment puis-je passer par le captcha? 🕶️ 💝 🧕🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour Je m'appelle Ibadov Ilkin, je suis étudiant à l'Université fédérale de l'Oural. 

 Dans cet article, je veux parler de mon expérience avec la ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ok Google: Comment puis-je passer par le captcha?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/449236/">  Bonjour  Je m'appelle Ibadov Ilkin, je suis étudiant à l'Université fédérale de l'Oural. <br><br>  Dans cet article, je veux parler de mon expérience avec la solution automatisée pour captcha de Google - "reCAPTCHA".  Je tiens à avertir le lecteur à l'avance qu'au moment de la rédaction de l'article, le prototype ne fonctionne pas aussi efficacement qu'il pourrait sembler d'après le titre, cependant, le résultat démontre que l'approche mise en œuvre est capable de résoudre le problème. <br><a name="habracut"></a><br>  Probablement tout le monde dans sa vie est tombé sur un captcha: saisir du texte à partir d'une image, résoudre une expression simple ou une équation complexe, choisir des voitures, des bornes d'incendie, des passages pour piétons ... La protection des ressources contre les systèmes automatisés est nécessaire et joue un rôle important dans la sécurité: le captcha protège contre les attaques DDoS , les enregistrements et les publications automatiques, l'analyse, empêche la sélection du spam et du mot de passe pour les comptes. <br><br><img src="https://habrastorage.org/webt/kw/la/yu/kwlayu1_wxfwcrknvshirpv8dtw.png"><br>  <font color="#999999"><i>Le formulaire d'inscription sur "Habré" pourrait être avec un tel captcha.</i></font> <br><br>  Avec le développement des technologies d'apprentissage automatique, les performances du captcha peuvent être menacées.  Dans cet article, je décris les points clés d'un programme qui peut résoudre le problème de la sélection manuelle d'images dans Google reCAPTCHA (heureusement, pas toujours jusqu'à présent). <br><br>  Pour traverser le captcha, il est nécessaire de résoudre des problèmes tels que: déterminer la classe de captcha requise, détecter et classer les objets, détecter les cellules de captcha, imiter les activités humaines pour résoudre le captcha (mouvement du curseur, cliquez). <br><br>  Pour rechercher des objets dans une image, des réseaux de neurones entraînés peuvent être téléchargés sur un ordinateur et reconnaître des objets dans des images ou des vidéos.  Mais pour résoudre le captcha, il ne suffit pas de détecter des objets: vous devez déterminer la position des cellules et savoir quelles cellules vous souhaitez sélectionner (ou ne pas sélectionner de cellules du tout).  Pour cela, des outils de vision par ordinateur sont utilisés: dans ce travail, il s'agit de la célèbre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bibliothèque OpenCV</a> . <br><br>  Pour trouver des objets dans l'image, premièrement, l'image elle-même est requise.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">J'obtiens</a> une capture d'écran d'une partie de l'écran en utilisant le module <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PyAutoGUI</a> avec des dimensions suffisantes pour détecter des objets.  Dans le reste de l'écran, j'affiche des fenêtres de débogage et de surveillance des processus du programme. <br><br><h2>  Détection d'objets </h2><br>  La détection et la classification des objets est ce que fait le réseau neuronal.  La bibliothèque qui nous permet de travailler avec des réseaux de neurones s'appelle " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tensorflow</a> " (développée par Google).  Aujourd'hui, <a href="">il existe de nombreux modèles formés différents pour</a> votre choix <a href="">sur différentes données</a> , ce qui signifie que tous peuvent renvoyer un résultat de détection différent: certains modèles détecteront mieux les objets et d'autres moins. <br><br>  Dans cet article, j'utilise le modèle ssd_mobilenet_v1_coco.  Le modèle sélectionné a été formé sur l'ensemble de données <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><abbr title="Objets communs en contexte">COCO</abbr></a> , qui met en évidence 90 classes différentes (des personnes et des voitures aux brosses à dents et peignes).  Maintenant, il existe d'autres modèles qui sont formés sur les mêmes données, mais avec des paramètres différents.  De plus, ce modèle a des paramètres de performance et de précision optimaux, ce qui est important pour un ordinateur de bureau.  La source indique que le temps de traitement d'une image de 300 x 300 pixels est de 30 millisecondes.  Sur le "Nvidia GeForce GTX TITAN X". <br><br>  Le résultat du réseau neuronal est un ensemble de tableaux: <br><br><ul><li>  avec une liste des classes d'objets détectés (leurs identifiants); </li><li>  avec une liste des évaluations des objets détectés (en pourcentage); </li><li>  avec une liste de coordonnées des objets détectés ("cases"). </li></ul><br>  Les indices des éléments dans ces tableaux correspondent les uns aux autres, c'est-à-dire que le troisième élément du tableau des classes d'objets correspond au troisième élément du tableau des "boîtes" des objets détectés et le troisième élément du tableau des évaluations d'objets. <br><br><img src="https://habrastorage.org/webt/g4/po/kt/g4poktayba4n3mwspffduto6d1k.png"><br>  <font color="#999999"><i>Le modèle sélectionné vous permet de détecter des objets de 90 classes en temps réel.</i></font> <br><br><h2>  Détection cellulaire </h2><br>  «OpenCV» nous permet de fonctionner avec des entités appelées « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">circuits</a> »: elles ne peuvent être détectées que par la fonction «findContours ()» de la bibliothèque «OpenCV».  Il est nécessaire de soumettre une image binaire à l'entrée d'une telle fonction, qui peut être obtenue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">par la fonction de transformation de seuil</a> : <br><br><pre><code class="python hljs">_retval, binImage = cv2.threshold(image,<span class="hljs-number"><span class="hljs-number">254</span></span>,<span class="hljs-number"><span class="hljs-number">255</span></span>,cv2.THRESH_BINARY) contours = cv2.findContours(binImage, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br>  Après avoir défini les valeurs extrêmes des paramètres de la fonction de transformation de seuil, nous nous débarrassons également de divers types de bruit.  De plus, pour minimiser la quantité de petits éléments inutiles et le bruit, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des transformations morphologiques</a> peuvent être appliquées: fonctions d'érosion (compression) et d'accumulation (expansion).  Ces fonctions font également partie d'OpenCV.  Après les transformations, les contours sont sélectionnés dont le nombre de sommets est de quatre (ayant précédemment effectué la fonction d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">approximation</a> sur les contours). <br><br><img src="https://habrastorage.org/webt/mo/d3/j7/mod3j7vkdav-bchdnbxl2lycz18.png"><br>  <font color="#999999"><i>Dans la première fenêtre, le résultat de la transformation de seuil.</i></font>  <font color="#999999"><i>Le second est un exemple de transformation morphologique.</i></font>  <font color="#999999"><i>Dans la troisième fenêtre, les cellules et le capuchon captcha sont déjà sélectionnés: mis en surbrillance en couleur par programmation.</i></font> <br><br>  Après toutes les transformations, les contours qui ne sont pas des cellules tombent toujours dans le tableau final avec des cellules.  Afin de filtrer les bruits inutiles, je sélectionne en fonction des valeurs de la longueur (périmètre) et de l'aire des contours. <br><br>  Il a été révélé expérimentalement que les valeurs des circuits d'intérêt se situent dans la plage de 360 ​​à 900 unités.  Cette valeur est sélectionnée à l'écran avec une diagonale de 15,6 pouces et une résolution de 1366 x 768 pixels.  En outre, les valeurs indiquées des contours peuvent être calculées en fonction de la taille de l'écran de l'utilisateur, mais il n'existe aucun lien de ce type dans le prototype en cours de création. <br><br>  Le principal avantage de l'approche choisie pour détecter les cellules est que nous ne nous soucions pas à quoi ressemblera la grille et combien de cellules seront affichées sur la page captcha: 8, 9 ou 16. <br><br><img src="https://habrastorage.org/webt/oo/er/tt/ooerttikg_xree5wlre88cljjtq.png"><br>  <font color="#999999"><i>L'image montre une variété de filets captcha.</i></font>  <font color="#999999"><i>Veuillez noter que la distance entre les cellules est différente.</i></font>  <font color="#999999"><i>Séparer les cellules les unes des autres permet une compression morphologique.</i></font> <br><br>  Un avantage supplémentaire de la détection des contours est qu'OpenCV nous permet de détecter leurs centres (nous en avons besoin pour déterminer les coordonnées de mouvement et de clic de souris). <br><br><h2>  Sélection des cellules à sélectionner </h2><br>  Ayant une matrice avec des contours propres de cellules CAPTCHA sans circuits de bruit inutiles, nous pouvons parcourir chaque cellule CAPTCHA («circuit» dans la terminologie «OpenCV») et vérifier si elle croise la «boîte» détectée de l'objet reçu du réseau neuronal. <br><br>  Pour établir ce fait, le transfert de la «boîte» détectée vers un circuit similaire aux cellules a été utilisé.  Mais cette approche s'est avérée erronée, car le cas où l'objet se trouve à l'intérieur de la cellule n'est pas considéré comme une intersection.  Naturellement, ces cellules ne se démarquent pas dans le captcha. <br><br>  Le problème a été résolu en redessinant le contour de chaque cellule (avec remplissage blanc) sur une feuille noire.  De façon similaire, une image binaire d'un cadre avec un objet a été obtenue.  La question se pose - comment établir maintenant le fait de l'intersection de la cellule avec le cadre ombré de l'objet?  A chaque itération d'un tableau avec des cellules, une opération de disjonction (logique ou) est effectuée sur deux images binaires.  En conséquence, nous obtenons une nouvelle image binaire dans laquelle les zones intersectées seront mises en évidence.  Autrement dit, s'il existe de telles zones, la cellule et le cadre de l'objet se croisent.  Par programmation, une telle vérification peut être effectuée en utilisant la méthode « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">.any ()</a> »: elle retournera «True» si le tableau a au moins un élément égal à un ou «False» s'il n'y a pas d'unités. <br><br><img src="https://habrastorage.org/webt/cg/8u/pb/cg8upb6izzlfukmfunjgjrzwl2y.gif"><br>  <font color="#999999"><i>La fonction «any ()» pour l'image «OU logique» dans ce cas retournera vrai et établira ainsi le fait de l'intersection de la cellule avec la zone de trame de l'objet détecté.</i></font> <br><br><h2>  La gestion </h2><br>  Le contrôle du curseur dans «Python» devient disponible grâce au module «win32api» (cependant, il s'est avéré plus tard que le «PyAutoGUI» déjà importé dans le projet sait aussi comment faire).  Appuyer et relâcher le bouton gauche de la souris, ainsi que déplacer le curseur sur les coordonnées souhaitées, est effectué par les fonctions correspondantes du module win32api.  Mais dans le prototype, ils étaient enveloppés dans des fonctions définies par l'utilisateur afin de fournir une observation visuelle du mouvement du curseur.  Cela affecte négativement les performances et a été implémenté uniquement à des fins de démonstration. <br><br>  Au cours du processus de développement, l'idée est venue de choisir les cellules dans un ordre aléatoire.  Il est possible que cela ne soit pas logique (pour des raisons évidentes, Google ne nous donne pas de commentaires et de descriptions des mécanismes de fonctionnement du captcha), mais déplacer le curseur à travers les cellules de manière chaotique semble plus amusant. <br><br><img src="https://habrastorage.org/webt/p0/zh/g8/p0zhg8ii2gn0a76yj1h0vp5q5mg.gif"><br>  <font color="#999999"><i>Sur l'animation, le résultat est "random.shuffle (boxesForSelect)".</i></font> <br><br><h2>  Reconnaissance de texte </h2><br>  Afin de combiner tous les développements disponibles en un seul ensemble, un lien supplémentaire est nécessaire: une unité de reconnaissance pour la classe requise du captcha.  Nous savons déjà reconnaître et distinguer différents objets dans l'image, nous pouvons cliquer sur des cellules captcha arbitraires, mais nous ne savons pas sur quelles cellules cliquer.  L'une des façons de résoudre ce problème consiste à reconnaître le texte de l'en-tête captcha.  Tout d'abord, j'ai essayé d'implémenter la reconnaissance de texte à l'aide de l'outil de reconnaissance optique de caractères " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tesseract-OCR</a> ". <br><br>  Dans les dernières versions, il est possible d'installer des modules linguistiques directement dans la fenêtre du programme d'installation (auparavant cela se faisait manuellement).  Après avoir installé et importé Tesseract-OCR dans mon projet, j'ai essayé de reconnaître le texte de l'en-tête captcha. <br><br>  Le résultat, malheureusement, ne m'a pas du tout impressionné.  J'ai décidé que le texte dans l'en-tête était mis en surbrillance en gras et fusionné pour une raison, j'ai donc essayé d'appliquer diverses transformations à l'image: binarisation, rétrécissement, expansion, flou, distorsion et redimensionnement.  Malheureusement, cela n'a pas donné un bon résultat: dans le meilleur des cas, seule une partie des lettres de classe a été déterminée, et lorsque le résultat a été satisfaisant, j'ai appliqué les mêmes transformations, mais pour d'autres majuscules (avec un texte différent), et le résultat s'est révélé à nouveau mauvais. <br><br><img src="https://habrastorage.org/webt/mm/5o/zf/mm5ozfhoq5cmrwiitaig_di7ntu.png"><br>  <font color="#999999"><i>La reconnaissance des bouchons Tesseract-OCR a généralement conduit à des résultats insatisfaisants.</i></font> <br><br>  Il est impossible de dire sans équivoque que «Tesseract-OCR» ne reconnaît pas bien le texte, ce n’est pas le cas: l’outil s’adapte bien mieux aux autres images (pas aux majuscules captcha). <br><br>  J'ai décidé d'utiliser un service tiers qui offrait une API pour travailler avec elle gratuitement (l'enregistrement et la réception d'une clé pour une adresse e-mail sont requis).  Le service a une limite de 500 reconnaissances par jour, mais pour toute la période de développement, je n'ai rencontré aucun problème de limitations.  Au contraire: j'ai soumis l'image originale de l'en-tête au service (sans appliquer absolument aucune transformation) et le résultat m'a impressionné agréablement. <br><br>  Les mots du service ont été retournés pratiquement sans erreur (généralement même ceux écrits en petits caractères).  De plus, ils sont revenus dans un format très pratique - coupé par ligne avec des caractères de saut de ligne.  Dans toutes les images, je ne m'intéressais qu'à la deuxième ligne, donc j'y ai directement accédé.  Cela ne pouvait que se réjouir, car un tel format me libérait de la nécessité de préparer une ligne: je n'avais pas à couper le début ou la fin de tout le texte, faire des "trims", des remplacements, travailler avec des expressions régulières et effectuer d'autres opérations sur la ligne, visant à mettre en évidence un mot (et parfois deux!) - un joli bonus! <br><br><pre> <code class="python hljs">text = serviceResponse[<span class="hljs-string"><span class="hljs-string">'ParsedResults'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-string"><span class="hljs-string">'ParsedText'</span></span>] <span class="hljs-comment"><span class="hljs-comment">#   JSON lines = text.splitlines() #   print("Recognized " + lines[1]) #  !</span></span></code> </pre> <br>  Le service qui a reconnu le texte n'a presque jamais fait d'erreur avec le nom de la classe, mais j'ai quand même décidé de laisser une partie du nom de la classe pour une éventuelle erreur.  C'est facultatif, mais j'ai remarqué que «Tesseract-OCR» dans certains cas reconnaissait incorrectement la fin d'un mot commençant par le milieu.  De plus, cette approche élimine l'erreur d'application dans le cas d'un nom de classe long ou d'un nom à deux mots (dans ce cas, le service renverra non pas 3, mais 4 lignes, et je ne trouve pas le nom complet de la classe dans la deuxième ligne). <br><br><img src="https://habrastorage.org/webt/6o/3v/nq/6o3vnqamplfdhd9byanlv4c55xw.png"><br>  <font color="#999999"><i>Un service tiers reconnaît bien le nom de la classe sans aucune transformation sur l'image.</i></font> <br><br><h2>  Fusion </h2><br>  Obtenir du texte depuis l'en-tête ne suffit pas.  Il doit être comparé aux identificateurs des classes de modèle disponibles, car dans le tableau de classes, le réseau neuronal renvoie exactement l'identifiant de classe, et non son nom, comme cela peut sembler.  Lors de la formation du modèle, en règle générale, un fichier est créé dans lequel les noms de classe et leurs identificateurs sont comparés (alias «carte d'étiquettes»).  J'ai décidé de le faire plus facilement et de spécifier les identificateurs de classe manuellement, car captcha nécessite toujours des classes en russe (à propos, cela peut être modifié): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> query: <span class="hljs-comment"><span class="hljs-comment">#       classNum = 3 #   "label map"  elif "" in query: classNum = 10 elif "" in query: classNum = 11 ...</span></span></code> </pre> <br>  Tout ce qui est décrit ci-dessus est reproduit dans le cycle de programme principal: les cadres de l'objet, la cellule, leurs intersections sont déterminés, le curseur se déplace et clique.  Lorsqu'un en-tête est détecté, la reconnaissance de texte est effectuée.  Si le réseau neuronal ne peut pas détecter la classe requise, un décalage arbitraire de l'image est effectué jusqu'à 5 fois (c'est-à-dire que l'entrée sur le réseau neuronal est modifiée), et si la détection ne se produit toujours pas, le bouton «Ignorer / Confirmer» est cliqué (sa position est détectée de la même manière détecter les cellules et les bouchons). <br><br>  Si vous résolvez souvent le captcha, vous pouvez observer l'image lorsque la cellule sélectionnée disparaît, et une nouvelle apparaît lentement et lentement à sa place.  Étant donné que le prototype est programmé pour passer instantanément à la page suivante après avoir sélectionné toutes les cellules, j'ai décidé de faire des pauses de 3 secondes pour exclure de cliquer sur le bouton "Suivant" sans détecter d'objets sur la cellule apparaissant lentement. <br><br>  L'article ne serait pas complet s'il ne contenait pas une description de la chose la plus importante - une coche pour réussir le captcha.  J'ai décidé qu'une simple <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">comparaison de modèles</a> pourrait le faire.  Il convient de noter que la correspondance de motifs est loin d'être la meilleure façon de détecter des objets.  Par exemple, j'ai dû régler la sensibilité de détection sur «0,01» pour que la fonction arrête de voir les tiques dans tout, mais la voit quand il y a vraiment une tique.  De même, j'ai agi avec une case à cocher vide qui rencontre l'utilisateur et à partir de laquelle le captcha démarre (il n'y a eu aucun problème de sensibilité). <br><br><h2>  Résultat </h2><br>  Le résultat de toutes les actions décrites est une application dont j'ai testé les performances sur le " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Toaster</a> ": <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wfl1K0bqBWQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Il convient de reconnaître que la vidéo n'a pas été tournée du premier coup, car j'ai souvent été confronté à la nécessité de choisir des classes qui ne sont pas dans le modèle (par exemple, les passages pour piétons, les escaliers ou les vitrines). <br><br>  "Google reCAPTCHA" renvoie une certaine valeur au site, montrant comment "Vous êtes un robot", et les administrateurs du site, à leur tour, peuvent définir un seuil pour passer cette valeur.  Il est possible qu'un seuil de captcha relativement bas ait été défini sur le grille-pain.  Cela explique le passage assez facile du captcha par le programme, malgré le fait qu'il se soit trompé deux fois, ne voyant pas le feu de circulation de la première page et la bouche d'incendie de la quatrième page du captcha. <br><br>  En plus du grille-pain, des expériences ont été menées sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">page de démonstration</a> officielle de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">reCAPTCHA</a> .  En conséquence, il a été remarqué qu'après plusieurs détections erronées (et non-découvertes), la capture d'un captcha devient extrêmement difficile même pour une personne: de nouvelles classes sont nécessaires (comme les tracteurs et les palmiers), des cellules sans objets apparaissent dans les échantillons (couleurs presque monotones) et le nombre de pages augmente considérablement, passer. <br><br>  Cela a été particulièrement visible lorsque j'ai décidé d'essayer de cliquer sur des cellules aléatoires en cas de non-détection d'objets (en raison de leur absence dans le modèle).  Par conséquent, nous pouvons affirmer avec certitude que les clics aléatoires ne permettront pas de résoudre le problème.  Pour se débarrasser d'un tel «blocage» par l'examinateur, nous avons reconnecté la connexion Internet et effacé les données du navigateur, car il est devenu impossible de passer un tel test - c'était presque sans fin! <br><br><img src="https://habrastorage.org/webt/xk/xe/5u/xkxe5uanfylidi1jgteyb3svyoc.png"><br>  <font color="#999999"><i>Si vous doutez de votre humanité, un tel résultat est possible.</i></font> <br><br><h2>  Développement </h2><br>  Si l'article et l'application suscitent l'intérêt du lecteur, je continuerai volontiers sa mise en œuvre, ses tests et la suite de la description sous une forme plus détaillée. <br><br>  Il s'agit de trouver des classes qui ne font pas partie du réseau actuel, cela améliorera considérablement l'efficacité de l'application.  À l'heure actuelle, il est urgent de reconnaître au moins des classes telles que: passages pour piétons, vitrines et cheminées - je vais vous dire comment recycler le modèle.  Pendant le développement, j'ai fait une courte liste des classes les plus courantes: <br><br><ul><li>  passages pour piétons; </li><li>  bornes d'incendie; </li><li>  vitrines </li><li>  cheminées; </li><li>  les voitures; </li><li>  Autobus </li><li>  feux de circulation; </li><li>  vélos </li><li>  moyens de transport; </li><li>  escaliers </li><li>  signes. </li></ul><br>  Il est possible d'améliorer la qualité de la détection d'objets en utilisant plusieurs modèles en même temps: cela peut dégrader les performances mais augmenter la précision. <br><br>  Une autre façon d'améliorer la qualité de détection des objets est de changer l'entrée d'image sur le réseau neuronal: dans la vidéo, vous pouvez voir que lorsque des objets ne sont pas détectés, je fais un décalage d'image arbitraire plusieurs fois (à moins de 10 pixels horizontalement et verticalement), et souvent cette opération vous permet de voir des objets qui étaient auparavant n'ont pas été détectés. <br><br>  Une augmentation de l'image d'un petit carré à un grand (jusqu'à 300 x 300 pixels) conduit également à la détection d'objets non détectés. <br><br><img src="https://habrastorage.org/webt/01/sd/eh/01sdehtdkgz_a-5gtsxh1-auhoq.png"><br>  <font color="#999999"><i>Aucun objet n'a été trouvé sur la gauche: carré d'origine avec 100 pixels de côté.</i></font>  <font color="#999999"><i>A droite, un bus est détecté: un carré agrandi jusqu'à 300 x 300 pixels.</i></font> <br><br>  Une autre transformation intéressante est la suppression de la grille blanche sur l'image à l'aide des outils OpenCV: il est possible que la bouche d'incendie n'ait pas été détectée dans la vidéo pour cette raison (cette classe est présente dans le réseau neuronal). <br><br><img src="https://habrastorage.org/webt/m_/7p/zu/m_7pzu93h3jqw3doy3flbtlymee.png"><br>  <font color="#999999"><i>A gauche se trouve l'image d'origine et à droite celle modifiée dans l'éditeur graphique: la grille est supprimée, les cellules sont déplacées les unes vers les autres.</i></font> <br><br><h2>  Résumé </h2><br>  Avec cet article, je voulais vous dire que le captcha n'est probablement pas la meilleure protection contre les bots, et il est fort possible que dans un proche avenir, il y aura un besoin de nouveaux moyens de protection contre les systèmes automatisés. <br><br>  Le prototype développé, même dans un état inachevé, démontre qu'avec les classes requises dans le modèle de réseau neuronal et en appliquant des transformations sur les images, il est possible de réaliser l'automatisation d'un processus qui ne devrait pas être automatisé. <br><br>  Je voudrais également attirer l'attention de Google sur le fait qu'en plus de la méthode de contournement du captcha décrite dans cet article, il existe également <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">une autre manière</a> de <abbr title="Le processus de traduction de l'audio en texte">transcrire</abbr> un échantillon audio.  À mon avis, il est maintenant nécessaire de prendre des mesures liées à l'amélioration de la qualité des logiciels et des algorithmes contre les robots. <br><br>  D'après le contenu et l'essence du matériel, il peut sembler que je n'aime pas Google et, en particulier, reCAPTCHA, mais c'est loin d'être le cas, et s'il y a une prochaine mise en œuvre, je vous dirai pourquoi. <br><br>  Développé et démontré afin d'améliorer l'éducation et d'améliorer les méthodes visant à assurer la sécurité de l'information. <br><br>  Merci de votre attention. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr449236/">https://habr.com/ru/post/fr449236/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr449218/index.html">10 compétences essentielles pour chaque ingénieur DevOps</a></li>
<li><a href="../fr449220/index.html">DrumHero: Comment j'ai créé le premier jeu de ma vie</a></li>
<li><a href="../fr449224/index.html">À propos du biais de l'intelligence artificielle</a></li>
<li><a href="../fr449232/index.html">Surveillance de la consommation d'énergie solaire par ordinateur / serveur</a></li>
<li><a href="../fr449234/index.html">Service VPN Wireguard gratuit sur AWS</a></li>
<li><a href="../fr449240/index.html">L'histoire d'un jeune service Daida (abonnement art)</a></li>
<li><a href="../fr449246/index.html">AX200 - Intel Wi-Fi 6</a></li>
<li><a href="../fr449248/index.html">IDE moderne. Certainement D, dans une certaine mesure E, et certainement pas moi</a></li>
<li><a href="../fr449252/index.html">Projets Zombie - fusionnez les données des utilisateurs même après sa mort</a></li>
<li><a href="../fr449254/index.html">FAQ sur l'architecture et le travail VKontakte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§πüèΩ ‚úÇÔ∏è üëÇüèª Augmentez-le! Augmentation de la r√©solution moderne üöæ üå¨Ô∏è ü§ôüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="J'ai d√©j√† cess√© de trembler et de me demander quand le t√©l√©phone sonne et une voix dure et confiante sonne dans le r√©cepteur: "Est-ce que le capitaine...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Augmentez-le! Augmentation de la r√©solution moderne</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439766/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b88/1db/675/b881db675f3ef17c06a45cc67a8c1cb2.png"></div><br>  J'ai d√©j√† cess√© de trembler et de me demander quand le t√©l√©phone sonne et une voix dure et confiante sonne dans le r√©cepteur: "Est-ce que le capitaine vous d√©range (majeur tel ou tel), pouvez-vous r√©pondre √† quelques questions?"  Pourquoi ne pas parler √† votre propre police ... <br><br>  Les questions sont toujours les m√™mes.  "Nous avons une vid√©o avec le suspect, veuillez aider √† restaurer le visage" ... "Aidez √† augmenter le nombre du DVR" ... "Il n'y a pas de mains humaines ici, veuillez aider √† augmenter" ... Et ainsi de suite dans la m√™me veine. <br><br>  Pour bien comprendre de quoi il s'agit, voici un exemple r√©el d'une vid√©o hautement compress√©e envoy√©e o√π ils demandent de restaurer un visage flou (dont la taille √©quivaut √† environ 8 pixels): <br><br><div style="text-align:center;"><img width="400" src="https://habrastorage.org/webt/k-/bw/5h/k-bw5hsws_7bijnrykr3vrvhk_i.png"></div><br>  Et bien, seuls les oncles russes de Stepa d√©rangeraient, √©crivent les Pinkertones occidentaux. <br><a name="habracut"></a>  Voici, par exemple, une lettre de la police anglaise &lt;***** @ *****. Fsnet.co.uk&gt;: <br><blockquote>  J'ai utilis√© vos filtres en priv√© pendant un certain temps pour sauver mes pauvres vid√©os de vacances en famille mais je voudrais utiliser les filtres commerciaux pour mon travail.  Je suis actuellement officier de police dans une petite force de police et nous recevons beaucoup de vid√©os de vid√©osurveillance, ce qui est parfois de tr√®s mauvaise qualit√© et je peux voir comment vos filtres feraient une r√©elle diff√©rence.  Pouvez-vous me dire le co√ªt et si je pouvais les utiliser. <br><br>  Je vous remercie <br><br><div class="spoiler">  <b class="spoiler_title">La traduction</b> <div class="spoiler_text">  J'ai d√©j√† utilis√© vos filtres √† des fins personnelles pour enregistrer mes mauvaises vid√©os de vacances en famille.  Mais je voudrais utiliser des filtres commerciaux dans mon travail.  Je suis actuellement policier dans une petite unit√©.  Nous obtenons un grand nombre de vid√©os de cam√©ras de vid√©osurveillance, parfois de tr√®s mauvaise qualit√©, et vos filtres vous aideront vraiment.  Pourriez-vous me dire leur co√ªt et puis-je les utiliser? <br><br>  Je vous remercie </div></div></blockquote>  Ou voici un policier australien √©crit: <br><blockquote>  Salut <br>  Je travaille pour la police de Victoria en Australie, dans l'unit√© de criminalistique vid√©o et audio.  Nous recevons occasionnellement des vid√©os de cam√©ras portatives ou mont√©es sur v√©hicule.  Souvent, ceux-ci capturent des images entrelac√©es d'√©v√©nements rapides.  En particulier, les images qui ont g√©n√©ralement le plus de "promesses" sont des images de plaques d'immatriculation de v√©hicules.  Nous constatons souvent que le v√©hicule en question se sera d√©plac√© de mani√®re significative entre le premier et le dernier champ captur√©.  En cons√©quence, nous essayons de reconstruire l'ensemble du cadre √† partir des deux champs, le second √©tant traduit, parfois tourn√©, et parfois la taille sera √©galement diff√©rente (lorsque le v√©hicule s'√©loigne ou se dirige vers la cam√©ra). Marier ces deux champs , de pr√©f√©rence √† une pr√©cision inf√©rieure au pixel, et la reconstruction de la trame contenant la plaque d'immatriculation peut √™tre difficile. <br>  D'apr√®s ce que j'ai vu de vous d√©sentrelacer des images, il se peut que votre filtre puisse faire une partie, sinon la totalit√©, de ce dont nous avons besoin.  Pour √™tre honn√™te, comme notre budget est plut√¥t petit, il est peu probable que nous puissions nous permettre une licence commerciale.  Nous ne vendons pas le produit, bien s√ªr, nous l'utilisons comme preuve dans les affaires de police.  En tout cas, j'ai pens√© que j'√©crirais un e-mail et demanderais quand m√™me.  Combien cela co√ªterait-il pour une licence?  Est-il possible de tester le produit sur des images, pour voir s'il est appropri√©?  Fait-il une partie de ce dont nous avons besoin?  Enfin, l'algorithme a-t-il √©t√© publi√©?  Travailler avec des algorithmes inconnus est une pratique dangereuse pour un tribunal.  Si les preuves conduisent un homme √† aller en prison pendant 20 ans, c'est une bonne pratique de savoir pourquoi! <br><br>  Toute information que vous pourriez offrir serait appr√©ci√©e. <br><br>  Cordialement, <br>  Charg√© de dossier <br>  Unit√© audiovisuelle <br>  D√©partement des services judiciaires de la police de Victoria <br><br><div class="spoiler">  <b class="spoiler_title">La traduction</b> <div class="spoiler_text">  Salut <br>  Je travaille pour la police de Victoria en Australie dans le d√©partement vid√©o et audio m√©dico-l√©gale.  De temps en temps, nous recevons des vid√©os de cam√©ras portatives et de DVR.  Souvent, ces vid√©os sont des prises de vue entrelac√©es d'objets en mouvement rapide.  En particulier, le mat√©riau le plus important est les plaques d'immatriculation des v√©hicules.  On constate souvent que le v√©hicule en question se d√©place fortement entre le premier et le dernier champ captur√©.  En cons√©quence, nous essayons de restaurer un cadre entier √† partir de deux champs, le second √©tant d√©cal√©, parfois pivot√© et parfois de taille diff√©rente (lorsque la voiture se d√©place vers ou depuis la cam√©ra).  La combinaison de ces deux champs, de pr√©f√©rence √† une pr√©cision d'un demi-pixel, et la restauration d'une trame enti√®re contenant une plaque d'immatriculation peut √™tre difficile. <br><br>  Je vois comment vous appliquez le d√©sentrelacement aux images, et peut-√™tre que vos filtres peuvent faire quelque chose, sinon tout ce dont nous avons besoin.  Honn√™tement, nous ne pourrons peut-√™tre pas nous permettre une licence commerciale, car notre budget est assez petit.  Nous ne vendons pas le produit, bien s√ªr, nous l'utilisons comme preuve dans les affaires de police.  En tout cas, je pensais que j'√©crirais une lettre et demanderais toujours.  Combien co√ªtera la licence?  Est-il possible de tester le produit sur le mat√©riau pour savoir s'il convient?  Fait-il une partie de ce dont nous avons besoin?  Enfin, l'algorithme a-t-il √©t√© publi√©? .. Travailler avec des algorithmes inconnus est une pratique dangereuse devant les tribunaux.  Si les preuves conduisent une personne √† aller en prison pendant 20 ans, il est utile de savoir pourquoi. <br><br>  Nous serons reconnaissants pour toute information que vous pourriez nous fournir. <br><br>  Cordialement <br>  Enqu√™teur <br>  Division audio et vid√©o <br>  D√©partement m√©dico-l√©gal de la police de Victoria </div></div></blockquote>  Notez que la lettre est tr√®s r√©fl√©chie, une personne s'inqui√®te de la publication de l'algorithme et de la responsabilit√© d'une r√©cup√©ration incorrecte. <br><br>  Parfois, ils n'admettent que par correspondance qu'ils appartiennent √† la police.  Par exemple, les carabiniers italiens voudraient de l‚Äôaide: <br><blockquote>  Dr.  Vatolin <br>  Merci pour la r√©ponse. <br>  La r√©ponse vaut aussi pour les forces de police (enqu√™te Carabinieri <br>  scientifique pour PARMA ITALIE)? <br>  √Ä quel logiciel ils ont √©t√© associ√©s √† vos algorithmes. <br>  Nous serions beaucoup. <br><br><div class="spoiler">  <b class="spoiler_title">La traduction</b> <div class="spoiler_text">  Dr.  Batolin <br>  Merci pour la r√©ponse. <br>  Est-ce appropri√© pour la police (unit√© d'enqu√™te des carabiniers pour PARMA ITALIE)? <br>  Sont-ils int√©ress√©s par le logiciel utilis√© par vos algorithmes? <br>  Nous vous en serons reconnaissants. </div></div></blockquote>  Et, bien s√ªr, de nombreux appels de gens ordinaires ... <br><br><h2>  Augmentez-le!  Vous vous sentez d√©sol√© d'avoir appuy√© sur le bouton droit? </h2><br>  Il est clair que tout ce flux d'appels n'appara√Æt pas de z√©ro. <br><br>  ¬´Bl√¢mer¬ª principalement les films et les √©missions de t√©l√©vision. <br><br>  Par exemple, ici en 3 secondes, la trame de la vid√©o compress√©e est augment√©e de 50 fois et √† partir de la r√©flexion dans les verres, ils voient des preuves: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/I_8ZH1Ggjk0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Et il y a beaucoup de tels moments dans les films et s√©ries modernes.  Par exemple, dans cette vid√©o, nous avons collect√© de mani√®re √©pique de tels √©pisodes dans un pack d'√©missions t√©l√©vis√©es, ne prenez pas deux minutes √† regarder: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/LhF_56SxrGk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Et quand vous voyez cela dans chaque film, alors le dernier h√©risson devient clair que tout ce dont vous avez besoin est d'avoir un g√©nie informatique comp√©tent, une combinaison d'algorithmes modernes, et il ne reste plus qu'√† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">"STOP!"</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">et "Am√©liorez-le!"</a>  .  Et le tour est jou√©!  Un miracle va se produire! <br><br>  Cependant, les sc√©naristes ne s'arr√™tent pas √† cette r√©ception d√©j√† galvaud√©e, et leur imagination d√©brid√©e va plus loin.  Voici un exemple tr√®s monstrueux.  Des d√©tectives galants √† r√©fl√©chir dans l'√©l√®ve de la victime ont re√ßu une photo du contrevenant.  En effet, le reflet dans les verres √©tait d√©j√† l√†.  C'est banal.  Continuons!  C‚Äôest juste que la r√©solution de la cam√©ra CCTV dans la cage d‚Äôescalier s‚Äôest av√©r√©e assez al√©atoire comme le t√©lescope de Hubble: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3uoM5kfZIQ0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Dans le "Proph√®te" (00:38:07): <div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e82/109/09e/e8210909e53e8966a6484d35b096bf0f.gif"></div><br>  Dans ¬´Avatar¬ª (1: 41: 04‚Äì1: 41: 05), l'algorithme de nettet√© est d'ailleurs quelque peu inhabituel par rapport √† d'autres films: il affine d'abord √† certains endroits, et apr√®s une fraction de seconde tire le reste de l'image, t .e.  d'abord la moiti√© gauche de la bouche, puis la droite: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fff/54d/603/fff54d603344fb7b80c8a5c93aaca7ab.gif"></div><br>  En g√©n√©ral, dans les films tr√®s populaires qui sont regard√©s par des centaines de millions, la nettet√© de l'image se fait en un seul clic.  <b>Tout le monde (dans les films) le fait!</b>  Alors pourquoi vous, ces experts intelligents, ne pouvez pas faire √ßa ??? <br><br><hr>  "Je sais que c'est facile!"  Et on m'a d√©finitivement dit que tu fais √ßa!  √ätes-vous trop paresseux pour appuyer sur ce bouton? <br><br>  <i>// Oh mon dieu ... Maudits sc√©naristes avec leur imagination d√©bordante ...</i> <br><br>  - Je comprends que vous √™tes occup√©, mais il s'agit de votre aide √† l'Etat pour r√©soudre un crime important! <br><br>  <i>// Nous comprenons.</i> <br><br>  - Peut-√™tre que c'est pour l'argent?  Combien devez-vous payer? <br><br>  <i>// Eh bien, comment expliquer bri√®vement que ce n'est pas que nous n'avons pas besoin d'argent ... Et puis encore et encore ...</i> <hr><br>  Toute co√Øncidence des citations ci-dessus avec de vrais dialogues est compl√®tement al√©atoire, mais, en particulier, ce texte est √©crit afin d'envoyer une personne √† le lire attentivement en premier, puis √† le rappeler. <br><blockquote>  <b>Conclusion:</b> √âtant donn√© que la sc√®ne avec l'agrandissement des images des cam√©ras de vid√©osurveillance en un seul clic est devenue un cachet du cin√©ma moderne, un grand nombre de personnes sont sinc√®rement convaincues qu'il est tr√®s simple d'agrandir un fragment de la trame d'une cam√©ra bon march√© ou d'un enregistreur vid√©o bon march√©.  L'essentiel est de savoir comment demander (enfin, ou commander, c'est la chance). </blockquote><h2>  D'o√π poussent les jambes </h2><br>  Il est clair que tout ce flux d'appels n'est pas pris de z√©ro.  Nous nous sommes vraiment engag√©s dans l'am√©lioration de la vid√©o depuis environ 20 ans, y compris divers types de r√©cup√©ration vid√©o (et il y en a plusieurs types, en passant), et nos exemples seront plus bas dans cette section. <br><br>  Une augmentation ¬´intelligente¬ª de la r√©solution dans les articles scientifiques est g√©n√©ralement appel√©e Super R√©solution (SR pour faire court).  Google Scholar sur demande <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Super Resolution</a> trouve 2,9 millions d'articles, soit  le sujet √©tait, pour ainsi dire, assez bien d√©terr√©, et un grand nombre de personnes l'ont trait√©.  Si vous suivez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le lien</a> , alors il y a une mer de r√©sultats, l'un plus beau que l'autre.  Cependant, il vaut la peine de creuser plus profond√©ment, l'image, comme d'habitude, ne devient pas si pastorale.  Le th√®me SR a deux directions: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Super r√©solution vid√©o</a> (0,4 million d'articles) - la restauration r√©elle en utilisant des images pr√©c√©dentes (et parfois ult√©rieures), <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Super r√©solution d'image</a> (2,2 millions d'articles) - augmentation ¬´intelligente¬ª de la r√©solution en utilisant une seule image.  √âtant donn√© que dans le cas d'une image pour prendre des informations sur ce qui n'√©tait r√©ellement nulle part dans cet endroit, les algorithmes compl√®tent d'une mani√®re ou d'une autre l'image (ou, relativement parlant, ¬´r√©fl√©chissez¬ª) √† l'image - ce qui pourrait √™tre l√†.  Le crit√®re principal est que le r√©sultat soit aussi naturel que possible ou aussi proche que possible de l'original.  Et il est clair que de telles m√©thodes ne conviennent pas pour restaurer ce qui √©tait "vraiment", bien que l'agrandissement de l'image pour qu'elle soit plus belle, par exemple, lors de l'impression (lorsque vous avez une photo unique, mais il n'y a pas de version en r√©solution sup√©rieure ) De telles m√©thodes sont tr√®s possibles. <br></li></ul><br>  Comme vous pouvez le voir, 0,4 million contre 2,2, c'est-√†-dire 5 fois moins de personnes sont engag√©es dans la reprise r√©elle.  Heureusement, le sujet ¬´faites-le plus grand, tout simplement beau¬ª est tr√®s demand√©, y compris dans l'industrie (le fameux zoom num√©rique des smartphones et des porte-savons num√©riques).  De plus, si vous plongez encore plus profond√©ment, il devient rapidement clair qu'un nombre important d'articles sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">super r√©solution vid√©o</a> est √©galement une augmentation de la r√©solution vid√©o sans r√©cup√©ration, car la r√©cup√©ration est difficile.  En cons√©quence, nous pouvons dire que ceux qui ¬´font magnifiquement¬ª sont environ 10 fois plus que ceux qui essaient vraiment de restaurer.  Soit dit en passant, une situation assez courante dans la vie. <br><br>  Nous allons encore plus loin.  Tr√®s souvent, les r√©sultats de l'algorithme sont tr√®s bons, mais il a besoin, par exemple, de 20 images en avant et de 20 images en arri√®re, et la vitesse de traitement d'une image est d'environ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">15 minutes</a> lors de l'utilisation du GPU le plus avanc√©.  C'est-√†-dire  pendant 1 minute, la vid√©o a besoin de 450 heures (pr√®s de 19 jours).  Oops-ss ... D'accord, ce n'est pas du tout comme l'instant "Zoomez-le!"  des films.  Il existe r√©guli√®rement des algorithmes qui fonctionnent plusieurs jours par image.  Pour les articles, un meilleur r√©sultat est g√©n√©ralement plus important que le temps de travail, car l'acc√©l√©ration est une t√¢che difficile distincte, et il est plus facile de manger un gros √©l√©phant en plusieurs parties.  C'est la diff√©rence entre la vie et le cin√©ma ... <br><br>  La demande d'algorithmes fonctionnant sur la vid√©o √† une vitesse raisonnable a donn√© lieu √† une direction distincte de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">super r√©solution vid√©o rapide</a> - 0,18 million d'articles, y compris des articles "lents" qui sont compar√©s √† ceux "rapides", c'est-√†-dire  le nombre r√©el d'articles sur ces m√©thodes est surestim√©.  A noter que parmi les approches ¬´rapides¬ª, le pourcentage de sp√©culation, c'est-√†-dire  sans r√©elle reprise, plus haut.  En cons√©quence, le pourcentage de r√©cup√©ration honn√™te est plus faible. <br><br>  L'image, vous voyez, devient claire.  Mais cela, bien s√ªr, est loin d'√™tre tout. <br><br>  Quels autres points affectent de mani√®re significative l'obtention d'un bon r√©sultat? <br><br>  Premi√®rement, le bruit est tr√®s influent.  Voici un exemple d'une double restauration de la r√©solution dans une vid√©o tr√®s bruyante: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/461/c9c/bd5/461c9cbd5b7b8d0a7b50f75471ebe941.png"></div><br>  <i>Source: documents de l'auteur</i> <br><br>  Le principal probl√®me de ce fragment n'est m√™me pas avec les bruits habituels, mais avec le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">moir√©</a> color√© sur la chemise, qui est difficile √† traiter.  Certains pourraient dire que les gros bruits ne sont pas un probl√®me aujourd'hui.  Ce n'est pas le cas.  Regardez les donn√©es des DVR de voiture et des cam√©ras CCTV dans l'obscurit√© (juste au moment o√π elles sont plus demand√©es). <br><br>  Cependant, le moir√© peut √©galement se produire sur des vid√©os relativement ¬´propres¬ª en termes de bruit vid√©o, comme la ville ci-dessous (les exemples ci-dessous sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bas√©s sur notre travail</a> ): <br><br> <a href=""><img src="https://habrastorage.org/webt/0a/-x/0z/0a-x0zj47mmkgsa79aiojqtrfco.gif"></a> <br>  <i>Source: documents de l'auteur</i> <br><br>  Deuxi√®mement, pour une r√©cup√©ration optimale, une pr√©diction proche de l'id√©al du mouvement entre les images est n√©cessaire.  Pourquoi cela est difficile est un grand sujet distinct, mais cela explique pourquoi les sc√®nes avec un mouvement de cam√©ra panoramique sont souvent tr√®s bien restaur√©es, et les sc√®nes avec un mouvement relativement chaotique sont extr√™mement difficiles √† r√©cup√©rer, mais avec elles, vous pouvez obtenir un assez bon r√©sultat dans certaines situations: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4bd/7bb/3da/4bd7bb3da22d2904311d2da762331b5e.gif"></div>  <i>Source: documents de l'auteur</i> <br><br>  Et enfin, voici un exemple de r√©cup√©ration de texte: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a98/ad0/a00/a98ad0a0062a2fa1a7b4c602d26e2edd.png"></div><br>  <i>Source: documents de l'auteur</i> <br><br>  Ici, l'arri√®re-plan se d√©place assez facilement et l'algorithme a la possibilit√© de "se d√©placer": <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a5e/1a4/542/a5e1a4542ea2b0a441c6160e4c9eaba0.png"></div><br><br>  En particulier, si nous comparons une tr√®s petite inscription √† droite de la main, y compris le grossissement avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">interpolation bicubique</a> classique, alors la diff√©rence est tr√®s clairement visible: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9d4/d00/dfc/9d4d00dfc6a3364dfae37e8637708993.png"></div><br>  On peut voir que pour l'interpolation bicubique, il est presque impossible de lire l'ann√©e, pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lanczos4</a> , qui est aim√© par ceux qui changent semi-professionnellement la r√©solution vid√©o pour la nettet√©, les bords sont plus clairs, bien s√ªr, mais il est toujours impossible de lire l'ann√©e.  Nous ne commentons pas la topaze commerciale, mais nous lisons clairement l'inscription et vous pouvez voir que c'est probablement 1809. <br><blockquote>  <b>Conclusions:</b> <br><br><ul><li>  Des milliers de chercheurs dans le monde sont engag√©s dans l'augmentation de la r√©solution, et des millions d'articles ont √©t√© publi√©s sur ce sujet.  Pour cette raison, chaque smartphone dispose d'un ¬´zoom num√©rique¬ª, qui est g√©n√©ralement objectivement meilleur que les algorithmes pour augmenter les programmes conventionnels, et chaque t√©l√©viseur FullHD peut afficher des vid√©os SD, souvent m√™me sans artefacts caract√©ristiques de changement de r√©solution. <br></li><li>  La r√©cup√©ration d'une image r√©elle √† partir d'une vid√©o repr√©sente bien moins de 10% de ceux impliqu√©s dans la Super R√©solution, de plus, la plupart des algorithmes de r√©cup√©ration sont extr√™mement lents (jusqu'√† plusieurs jours de calculs par image). <br></li><li>  Dans la plupart des cas, la r√©cup√©ration est con√ßue pour garantir que les hautes fr√©quences de la vid√©o sont plus ou moins pr√©serv√©es et ne fonctionnent donc pas sur la vid√©o avec des artefacts de compression importants.  Et comme dans les param√®tres des cam√©ras de vid√©osurveillance, le taux de compression est souvent choisi en fonction du d√©sir de gagner plus d'heures (c'est-√†-dire que la vid√©o est compress√©e plus fortement et que les hautes fr√©quences sont ¬´tu√©es¬ª), il devient presque impossible de restaurer une telle vid√©o. <br></li></ul></blockquote><br><h2>  √Ä quoi ressemble SR dans l'industrie </h2><br>  Pour √™tre honn√™te, nous notons qu'aujourd'hui tous les algorithmes d'augmentation de r√©solution (ou du moins achet√©s) sont disponibles pour tous les fabricants de t√©l√©viseurs (vous devez cr√©er des images HD √† partir d'images SD √† la vol√©e), pour tous les fabricants de smartphones (ce que l'on appelle le ¬´zoom num√©rique¬ª dans la publicit√©), etc. .d.  Nous parlerons des r√©sultats de Google (et pas seulement).  Premi√®rement, parce que Google est tr√®s sympa et sans beaucoup de pathos et que le marketing d√©crit les r√©sultats sur son blog - et c'est extr√™mement sympa.  Deuxi√®mement, parce que les fabricants de smartphones (par exemple, une entreprise cor√©enne tr√®s connue) n'h√©sitent pas √† utiliser, disons, Photoshop pour la publicit√© de leurs technologies (quelle est la diff√©rence - les gens vont l'avaler quand m√™me) - et c'est d√©sagr√©able.  En g√©n√©ral, parlons de ceux qui d√©crivent leur technologie assez honn√™tement. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">En 2016, Google a publi√©</a> des r√©sultats assez int√©ressants de l'algorithme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RAISR (Rapid and Accurate Image Super Resolution)</a> utilis√© dans le smartphone Pixel 2. Sur les photos les plus r√©ussies, le r√©sultat √©tait tout simplement g√©nial: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/78c/785/e21/78c785e214d760cb58f8ea2e2d78b70a.png"></div><br>  <i>Source: <a href="">Google AI Blog</a></i> <br><br>  L'algorithme √©tait un ensemble de filtres appliqu√©s apr√®s la classification ML et compar√© √† l'interpolation bicubique (gar√ßon fouett√© traditionnel), le r√©sultat a plu: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/67b/1f3/a53/67b1f3a5335bbced94d53be35ba3881d.png"></div><br>  <i>Dans l'ordre: original, interpolation bicubique, RAISR</i> <br><br>  Mais c'√©tait une interpolation d'une seule image, et sur des exemples ¬´infructueux¬ª, comme le feuillage ci-dessous, l'image est devenue tr√®s d√©sagr√©ablement d√©form√©e - apr√®s l'agrandissement, l'image est devenue sensiblement ¬´synth√©tique¬ª.  Il a montr√© exactement l'effet pour lequel le zoom num√©rique des smartphones modernes n'est pas appr√©ci√©: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/g0/y7/xw/g0y7xw8cipif-g-cw3yuljfmivg.png"></div><br>  Le miracle, en fait, ne s'est pas produit, et Google a honn√™tement et imm√©diatement publi√© un contre-exemple, √† savoir  a imm√©diatement soulign√© les limites de l'applicabilit√© de leur approche et a sauv√© les gens d'attentes excessives (typiques du marketing conventionnel). <br><br>  Cependant, moins de deux ans se sont √©coul√©s depuis que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">poursuite des travaux</a> utilis√©s dans Google Pixel 3 a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©t√© publi√©e</a> et am√©liore consid√©rablement la qualit√© de sa prise de vue, qui est d√©j√† une super r√©solution multi-images honn√™te, c'est-√†-dire  algorithme de r√©cup√©ration de r√©solution multi-trame: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/83b/3ff/950/83b3ff950cf9959b2acb3d11a134ef50.gif"></div><br>  <i>Source: <a href="">Google AI Blog</a></i> <br><br>  L'image ci-dessus montre une comparaison des r√©sultats de Pixel 2 et Pixel 3, et les r√©sultats semblent tr√®s bons - l'image est vraiment devenue beaucoup plus claire et il est clairement vu que ce n'est pas ¬´r√©fl√©chir¬ª, mais vraiment restaurer les d√©tails.  De plus, un lecteur professionnel attentif aura des questions sur deux tubes doubles verticaux sur la gauche.  La r√©solution a clairement augment√©, tandis que l'√©tape de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">repliement</a> (signe d'une r√©elle r√©solution) semble √©trangement proche.  C'√©tait quoi? <br><br>  En r√©sum√©, nous analyserons l'algorithme.  Les coll√®gues sont pass√©s de changer l'interpolation du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">motif Bayer</a> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/355/0ba/e72/3550bae72349a1d9d9705e1e8c69cdd3.png"></div><br>  Le fait est que 2/3 des informations dans une image r√©elle sont en fait des informations interpol√©es.  C'est-√†-dire  votre image est D√âJ√Ä floue et "floue", mais avec un vrai niveau de bruit ce n'est pas si important.  Soit dit en passant, la possibilit√© d'utiliser des algorithmes d'interpolation plus complexes a rendu les programmes populaires de conversion RAW de la plus haute qualit√© pour les photographies (la diff√©rence entre l'algorithme simple int√©gr√© √† chaque appareil photo et l'algorithme complexe d'un programme sp√©cialis√© est g√©n√©ralement perceptible √† l'≈ìil nu lorsque l'image est agrandie). <br><br>  Des coll√®gues de Google utilisent le fait que la grande majorit√© des photos de smartphones sont prises √† la main, c'est-√†-dire  l'appareil photo tremblera l√©g√®rement: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/864/59b/d05/86459bd058ec0edfdd5f3b1d0c9b287b.gif"></div><br>  <i>Source: <a href="">Google AI Blog</a> (image multi-images align√©e au niveau des pixels pour montrer le d√©calage sous-pixel)</i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Par cons√©quent, si vous prenez quelques images et √©valuez le d√©calage (et le fer, qui est capable de cr√©er une carte d'estimation de mouvement avec une pr√©cision d'un quart de pixel, est dans n'importe quel smartphone avec prise en charge H.264), nous obtenons une carte de d√©calage. Fid√®le √† l'animation ci-dessus, il est clairement vu qu'avec un niveau de bruit r√©el, la construction d'une carte de d√©placement avec une pr√©cision sous-pixel est une t√¢che tr√®s simple, mais de tr√®s bons algorithmes sont apparus dans ce domaine au cours des 20 derni√®res ann√©es. Bien s√ªr, parfois, et ils ont du mal. Par exemple, dans l'exemple ci-dessus, quelque chose clignote sur un cadre en haut de la rampe d'escalier. Et c'est toujours une sc√®ne statique, il n'y a pas d'objets en mouvement qui parfois ne se contentent pas de bouger, mais tournent, changent de forme, se d√©placent rapidement, laissant de larges zones d'ouverture (dont la boucle ne doit pas √™tre visible apr√®s traitement). L'exemple ci-dessous montre clairementce qui arrive aux objets en mouvement rapide, si vous d√©sactivez le traitement sp√©cial de ces cas (d√©sactiv√© √† gauche, activ√© √† droite, si vous cliquez, les blocs de traitement sont clairement visibles):</font></font><br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/2e8/3d1/bb2/2e83d1bb215c546de4eb6d55524f865f.png"></a> <br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google AI Blog (recommand√© de cliquer et de voir en haute r√©solution)</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Des exemples concrets sont les flammes, les ondulations, les reflets du soleil sur l'eau, etc. En g√©n√©ral, m√™me dans le probl√®me ¬´simple¬ª de d√©termination du d√©calage, il existe de nombreux moments non triviaux qui compliquent consid√©rablement la vie de l'algorithme. Cependant, maintenant ce n'est pas √† ce sujet. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fait int√©ressant, m√™me si la cam√©ra est compl√®tement immobile (par exemple, mont√©e sur un tr√©pied), vous pouvez faire bouger le capteur via le contr√¥le du </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">module de stabilisation optique</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (OIS - Optical Image Stabilization). En cons√©quence, nous obtenons les d√©calages de sous-pixels souhait√©s. Dans Pixel 3, le support OIS est impl√©ment√©, et vous pouvez appuyer le t√©l√©phone contre la vitre et regarder avec int√©r√™t comment OIS commence √† </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d√©placer l'image le long d'une ellipse (environ, comme ce lien)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, c'est-√†-dire que m√™me dans ce cas de montage sur tr√©pied, difficile pour lui, la Super R√©solution pourra travailler et am√©liorer la qualit√©. </font><font style="vertical-align: inherit;">Cependant, la part du lion de la prise de vue √† partir de smartphones est la prise de vue √† main lev√©e. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En cons√©quence, nous avons des informations suppl√©mentaires pour construire une photo √† plus grande r√©solution:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/11d/67a/0a2/11d67a0a2127af61576cadffbfeba49b.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Comme mentionn√© ci-dessus, la cons√©quence directe de SR est une diminution significative du niveau de bruit, dans certains cas, elle est tr√®s perceptible: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3e1/cd0/1b1/3e1cd01b1e996fc11a6309dca47b0e17.png"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google AI Blog</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Notez que la r√©cup√©ration signifie √©galement la restauration par le nombre de bits par composant.</font></font> C'est-√†-dire<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©solvant formellement le probl√®me de l'augmentation de la r√©solution, le m√™me moteur dans certaines conditions peut non seulement supprimer le bruit, mais aussi transformer la trame en HDR. Il est clair qu'aujourd'hui le HDR est rarement utilis√©, mais cela, vous voyez, est un bon bonus. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'exemple ci-dessous montre une comparaison des images obtenues lors de la prise de vue sur le Pixel 2 et sur le Pixel 3 apr√®s SR avec une qualit√© de capteur comparable. La diff√©rence de bruit et la diff√©rence de clart√© sont clairement visibles:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/74c/17b/e38/74c17be383c81603e91124d9b4fd04c9.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour ceux qui aiment regarder les d√©tails, il </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y a un album</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans lequel la Super Resolution de Google (nom marketing Super Res Zoom) peut √™tre appr√©ci√©e dans toute sa splendeur dans le spectre de l'√©chelle de zoom d'image sur un smartphone (changement </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FoV</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ): </font><font style="vertical-align: inherit;">Comment ils √©crivent modestement - ils ont fait un pas de plus vers la qualit√© de prise de vue des smartphones √† la qualit√© des cam√©ras professionnelles. </font><font style="vertical-align: inherit;">En toute justice, nous notons que les cam√©ras professionnelles ne sont pas non plus immobiles. Une autre chose est qu'avec de plus petites ventes, les m√™mes technologies co√ªteront plus cher √† l'utilisateur. Cependant, SR appara√Æt d√©j√† dans les cam√©ras professionnelles. </font><b><font style="vertical-align: inherit;">UPD:</font></b><font style="vertical-align: inherit;"> √Ä titre d'exemple (le dernier lien est une comparaison):</font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/321/e5e/40d/321e5e40d89b28612139434735c76fe0.png"></a> <br><br><font style="vertical-align: inherit;"></font><br><br><font style="vertical-align: inherit;"></font><br><br> <b><font style="vertical-align: inherit;"></font></b> <br><font style="vertical-align: inherit;"></font><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Testing Sony's New Pixel Shift Feature in the a7R III</a> ,     2     ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a>    ,               ), <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">   Olympus E-M5 Mark II</a>  16  40 , <br></li><li>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> Super Resolution   Pentax K-1</a> , <br></li><li>  : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pixel-Shift Shootout: Olympus vs. Pentax vs. Sony vs. Panasonic</a> ‚Äî    <b>Pentax K-1, Sony a7R III, Olympus OM-D E-M1 Mark II  Panasonic Lumix DC-G9.</b> ,    ,         ,    Pentax K-1. <br></li></ul><br><blockquote> <b>:</b> <br><br><ul><li>  Super Resolution    ,        ,         . <br></li><li>  SR: Image Super Resolution ‚Äî    ( ),     . <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Les principaux avantages des algorithmes de r√©cup√©ration sont la r√©duction du bruit, le raffinement des d√©tails, un HDR ¬´plus honn√™te¬ª, une qualit√© d'image nettement plus visible sur les t√©l√©viseurs grand √©cran. </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Toute cette magnificence a √©t√© rendue possible gr√¢ce √† une augmentation cardinale (d'environ 3 ordres de grandeur du nombre d'op√©rations) de la complexit√© des algorithmes de traitement photo, ou plus pr√©cis√©ment - d'une image vid√©o. </font></font><br></li></ul></blockquote><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> R√©sultats Yandex </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Puisqu'ils demanderont toujours dans les commentaires, je dirai quelques mots sur Yandex, qui a publi√© sa version de Super Resolution l'ann√©e derni√®re: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/02a/ec9/09f/02aec909f0cfd75bf9902a25ee85acc9.png"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://yandex.ru/blog/company/oldfilms</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Et voici quelques exemples de dessins anim√©s:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d6a/e9e/2cb/d6ae9e2cba814e1c02a4060ccb545280.png"></div><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://yandex.ru/blog/company/soyuzmultfilm</a></i> <br><br>  C'√©tait quoi?  Yandex a r√©p√©t√© la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">technologie de Google en 2016</a> ? <br><br>  Sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la page</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">description de la</a> technologie de Yandex (nom marketing DeepHD), les liens ne concernent que l'Image Super Resolution.  Cela signifie qu'il existe √©videmment des contre-exemples dans lesquels l'algorithme g√¢che l'image et ils sont plus courants que pour les algorithmes de r√©cup√©ration honn√™tes.  Mais environ 80% des articles sont consacr√©s au sujet et l'algorithme est plus facile √† mettre en ≈ìuvre. <br><br>  Cette technologie a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©galement</a> √©t√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©crite</a> sur un hub (il est int√©ressant que l'auteur de l'article soit dipl√¥m√© de notre laboratoire), mais, comme vous pouvez le voir dans les commentaires, les auteurs n'ont r√©pondu √† aucune de mes questions, alors qu'ils ont r√©pondu aux autres.  Et ce ne sont plut√¥t pas les auteurs des m√©chants, mais la politique de l'entreprise (dans d'autres postes, si vous regardez bien, il n'y a souvent pas non plus de r√©ponses aux questions des experts).  Pour les entreprises technologiques, les blogs h√©sitent √† approfondir la discussion sur l'impl√©mentation ou les d√©tails technologiques.  Surtout si cela cr√©e une meilleure impression de la technologie / du produit.  Ou les concurrents peuvent couper la m√™me chose plus rapidement.  Encore une fois, le marketing est responsable des publications, et c'est leur travail direct - cr√©er une impression favorable des produits de l'entreprise, quelle que soit la qualit√© des produits eux-m√™mes.  D'o√π la m√©fiance fr√©quente √† l'√©gard des informations provenant du marketing. <br><br>  En g√©n√©ral, il vaut la peine d'√™tre tr√®s sceptique √† propos des images des entreprises de la s√©rie ¬´comment nous avons tout bien fait¬ª pour les raisons suivantes: <br><br><ul><li>  Les auteurs d'algorithmes de traitement savent tr√®s bien qu'il n'existe pratiquement <b>aucun algorithme qui, dans certains cas, ne g√©n√©rerait pas d'artefacts.</b>  Et, en fait, l'une des t√¢ches cl√©s du d√©veloppeur est de r√©duire le pourcentage de ces cas (ou la visibilit√© des artefacts dans de tels cas) tout en maintenant la qualit√© dans d'autres cas.  Et tr√®s souvent cela ne r√©ussit PAS: <br><br><ul><li>  Ou les artefacts sont si forts et difficiles √† r√©parer que toute l'approche est rejet√©e.  En fait c'est le cas, peut-√™tre (surprise-surprise!), De la majorit√© des articles.  Des images divines dans certains cas (qui √©taient au sol) et ¬´√ßa ne marche pas du tout¬ª dans le reste. <br></li><li>  Ou (et c'est une situation courante pour les entreprises de technologie pratique), vous devez sacrifier une certaine qualit√© en moyenne afin que les artefacts dans les pires cas puissent √™tre tol√©r√©s. <br></li></ul><br></li></ul>  En cons√©quence, lorsque de mauvais exemples ne sont pas publi√©s (classiques pour les entreprises) ou publi√©s de mani√®re limit√©e et avec des d√©fauts (classiques pour les articles) - c'est le cas le plus courant de tromper les gens sur les propri√©t√©s d'une technologie / d'un algorithme. <br><br><ul><li>  <b>Une autre id√©e fausse courante concernant les algorithmes de traitement est l'utilisation de param√®tres (y compris les param√®tres internes) de l'algorithme.</b>  Les algorithmes, il en est ainsi, ont des param√®tres, et les utilisateurs - et c'est aussi la norme - aiment avoir au plus un bouton ¬´activer¬ª.  Et m√™me s'il existe des param√®tres, l'utilisateur de masse ne les utilise pas.  C'est pourquoi, lors de l'achat de technologie, ¬´arr√™tez-vous cent fois¬ª, ils vous demandent encore: ¬´Est-ce √† coup s√ªr une machine compl√®te?  et demandez de nombreux exemples. <br><br><ul><li>  En cons√©quence, une histoire courante est la publication d'un r√©sultat obtenu avec certains param√®tres.  Heureusement, le d√©veloppeur les conna√Æt bien, et m√™me quand il y en a cinquante (la situation r√©elle!), Il les prend tr√®s vite pour que l'image soit magique.  Exactement, ces images sont souvent destin√©es √† la publicit√©. <br></li><li>  De plus, le d√©veloppeur peut m√™me √™tre contre.  Le marketing voit les nouveaux exemples envoy√©s et dit: "rien n'est visible sur eux, dans la derni√®re pr√©sentation, vous aviez des exemples normaux!"  Et puis ils peuvent essayer de leur expliquer que de nouveaux exemples sont ce que les gens voient vraiment, et dans la derni√®re pr√©sentation, des r√©sultats potentiels ont √©t√© montr√©s qui peuvent √™tre atteints par des √©tudes pr√©liminaires du d√©but du projet.  Cela ne d√©range personne.  Les gens auront l'image "o√π vous pouvez voir".  Dans certains cas, m√™me les grandes entreprises utilisent Photoshop.  Messing est servi, messieurs les gens!  ) <br></li></ul><br></li></ul><ul><li>  De plus, <b>en ce qui concerne la vid√©o - cela ouvre simplement de grands espaces ouverts pour la <s>machine ...</s> bon marketing!</b>  Car, en r√®gle g√©n√©rale, les images sont dispos√©es et la qualit√© de la vid√©o compress√©e oscille toujours et d√©pend de la masse des param√®tres.  Encore une fois - plusieurs technologies peuvent √™tre correctement appliqu√©es, le temps de traitement, encore une fois, peut √™tre diff√©rent.  Et ce n'est pas tout, la port√©e est grande. <br><br><ul><li>  La publicit√© Yandex indique que la technologie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepHD fonctionne en temps r√©el, vous pouvez donc regarder les cha√Ænes de t√©l√©vision en l'utilisant aujourd'hui</a> .  Il a √©t√© expliqu√© ci-dessus que la vitesse de fonctionnement est le talon d'Achille de Super Resolution.  L'avantage des r√©seaux de neurones, bien s√ªr, est qu'en √©tudiant pendant une longue p√©riode, ils peuvent fonctionner tr√®s rapidement dans certains cas, mais je chercherais (avec un grand int√©r√™t professionnel) dans quelle r√©solution et qualit√© l'algorithme fonctionne en temps r√©el.  Habituellement, plusieurs modifications de l'algorithme sont cr√©√©es et √† des r√©solutions √©lev√©es en temps r√©el, de <b>nombreuses</b> "puces" (essentielles pour la qualit√©) doivent √™tre d√©sactiv√©es.  <b>Trop.</b> <br></li><li>  Dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les exemples</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">noir et blanc</a> , un examen plus approfondi r√©v√®le que la luminosit√© locale change.  √âtant donn√© que le SR correct ne modifie pas la luminosit√©, il semble qu'un autre algorithme ait fonctionn√©, peut-√™tre pas un (les r√©sultats montrent qu'il ne s'agit pas d'un traitement d'image unique, ou plut√¥t, il ne semble pas seulement).  Si vous regardez une pi√®ce plus grande (au moins 100 images), l'image sera claire.  Cependant, la mesure de la qualit√© vid√©o est un sujet tr√®s important. <br></li></ul><br></li></ul><blockquote>  <b>Conclusions:</b> <br><br><ul><li>  Vous devez comprendre que les sp√©cialistes du marketing utilisent souvent leurs astuces pr√©cis√©ment parce que cela fonctionne (et comment!).  L'√©crasante majorit√© des gens <s>ne lisent pas le hub</s>  Ce qui conduit r√©guli√®rement √† toutes sortes de distorsions.  Je souhaite que tout le monde soit moins annonc√©, surtout lorsque la narration est √† son meilleur et que je veux vraiment croire en un miracle! <br></li><li>  Et, bien s√ªr, il est tr√®s bien que Yandex travaille √©galement sur le sujet et cr√©e sa propre SR (plus pr√©cis√©ment, sa propre famille SR). <br></li></ul></blockquote><br><h2>  Perspectives </h2><br>  Revenons √† notre point de d√©part.  Que faire pour ceux qui veulent augmenter la vid√©o compress√©e?  Est-ce que tout est mauvais? <br><br>  Comme d√©crit ci-dessus, m√™me un l√©ger changement de l'image dans la r√©gion, litt√©ralement au niveau du bruit, est critique pour les algorithmes de r√©cup√©ration "honn√™te".  Autrement dit, les hautes fr√©quences dans l'image et leur changement entre les images sont critiques. <br><br>  Dans ce cas, la principale raison pour laquelle la compression vid√©o est effectu√©e est la suppression du bruit entre les images.  Dans l'exemple ci-dessous, la diff√©rence entre les images d'une vid√©o bruyante avant la compensation de mouvement, apr√®s la compensation (avec une compression faible) et apr√®s la compression perceptible - ressentez la diff√©rence (le contraste est augment√© d'environ 6 fois pour que les d√©tails soient visibles): <br><img src="https://habrastorage.org/getpro/habr/post_images/4a0/867/c18/4a0867c1839ba6acea0aa16a7a5a408c.png"><br>  <i>Source: conf√©rences de l'auteur sur les algorithmes de compression</i> <br><br>  On voit clairement que du point de vue du codec, la zone id√©ale est la zone dans laquelle le mouvement a √©t√© enti√®rement compens√© et sur laquelle plus aucun bit ne doit √™tre d√©pens√©.  Eh bien, un peu peut √™tre d√©pens√©, quelque chose de peu corrig√©.  Et il peut y avoir un certain nombre de ces domaines.  Par cons√©quent, Super Resolution perd son ¬´pain principal¬ª - des informations sur ce qui se trouve √† cet endroit dans d'autres images, en tenant compte du d√©calage de sous-pixels. <br><br>  Si vous regardez les articles, m√™me pour un JPEG relativement simple, la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">restauration jpeg</a> contient 26 mille r√©sultats, et pour la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©cup√©ration jpeg</a> - 52 mille, et ceci avec la restauration des fichiers cass√©s, etc.  Pour la vid√©o, la situation est pire que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">restauration MPEG</a> - 22000, soit  le travail est bien s√ªr en cours, mais l'√©chelle de l'√©chelle de travail sur la super r√©solution n'est pas comparable.  Il y a environ un ordre de grandeur de moins de travail que la restauration de la r√©solution vid√©o et deux ordres de grandeur de moins que la super r√©solution d'image.  Deux commandes, c'est beaucoup.  Nous avons √©galement fait une approche du projectile (puisque nous faisons de la compression et du traitement depuis longtemps), il y a quelque chose √† travailler, surtout si la qualit√© oscille ou utilise quelque chose comme M-JPEG (plus r√©cemment, une image courante en vid√©osurveillance).  Mais ce seront tous des cas particuliers. <br><br>  Les r√©sultats des articles des liens ci-dessus montrent √©galement que les r√©sultats sont parfois tr√®s beaux, mais obtenus pour des cas tr√®s particuliers.  C'est-√†-dire  demain, dans chaque smartphone, cette fonction, h√©las, n'appara√Ætra pas.  Ce sont de mauvaises nouvelles.  Bon - apr√®s-demain et sur un ordinateur avec un bon GPU - appara√Ætra √† coup s√ªr. <br><br>  Raisons: <br><br><ul><li>  Les dispositifs de stockage (cartes SD pour les bureaux d'enregistrement, disques pour les cam√©ras de vid√©osurveillance, etc.) sont de moins en moins chers et le d√©bit binaire moyen pour l'enregistrement vid√©o augmente. <br></li><li>  De plus, lors de la compression, ils basculent progressivement vers les standards des g√©n√©rations futures (par exemple, sur HEVC), ce qui signifie une am√©lioration notable de la qualit√© avec le m√™me d√©bit binaire.  Les 2 derniers points signifient que progressivement la qualit√© vid√©o sera de plus en plus √©lev√©e et, √† partir d'un certain point, des algorithmes de super r√©solution vid√©o bien d√©velopp√©s commenceront √† fonctionner. <br></li><li>  Enfin, les algorithmes sont en cours d'am√©lioration.  Les r√©alisations des algorithmes bas√©s sur l'apprentissage automatique au cours des 4 derni√®res ann√©es sont particuli√®rement bonnes.  √Ä cet √©gard, avec une forte probabilit√©, nous pouvons nous attendre √† quelque chose comme ceci: <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/fce/82a/6a9/fce82a6a91aa6c5d654bd22c26bbf3d4.png"><br><br>  C'est-√†-dire  l'algorithme utilisera explicitement les informations de mouvement re√ßues du codec, puis ces donn√©es seront transmises √† un r√©seau neuronal form√© pour r√©cup√©rer des artefacts sp√©cifiques √† des codecs sp√©cifiques.  Un tel sch√©ma semble actuellement tout √† fait r√©alisable. <br><br>  Mais dans tous les cas, vous devez clairement comprendre que la r√©cup√©ration actuelle est, en r√®gle g√©n√©rale, une double augmentation de la r√©solution.  Plus rarement, dans certains cas, lorsque le mat√©riel source n'a pas √©t√© compress√© ou presque pas compress√©, nous pouvons parler de 3-4 fois.  Comme vous pouvez le voir, ce n'est m√™me pas pr√®s de 100 √† 1000 fois le grossissement des films, lorsque 1,5 pixel d'un enregistrement nocturne bruyant se transforme en un num√©ro de voiture d'excellente qualit√©.  Le genre de "science-fiction" devrait en effet se voir attribuer un pourcentage plus important de films et d'√©missions de t√©l√©vision. <br><br>  Et, bien s√ªr, il y aura des tentatives pour faire quelque chose d'universel, dans le cadre de la tendance de la mode ¬´l'essentiel est de couper plus de couches¬ª.  Et ici, il convient de mettre en garde contre les r√©actions "cheers-cheers" aux documents publicitaires sur ce sujet.  Pour les r√©seaux de neurones sont le cadre le plus pratique pour d√©montrer des miracles et toutes sortes de sp√©culations.  L'essentiel est de choisir correctement l'√©chantillon de formation et les exemples finaux.  Et le tour est jou√©!  Voyez le miracle!  D'ailleurs, c'est tr√®s pratique pour convaincre les investisseurs.  Autrement dit, il est extr√™mement important que l'efficacit√© des technologies soit confirm√©e par une personne ind√©pendante sur un grand nombre d'exemples h√©t√©rog√®nes, ce qui est rarement d√©montr√©.  Pour les entreprises, donner m√™me un ou deux exemples lorsque la technologie ne fonctionne pas, est aujourd'hui assimil√© √† un exploit civil. <br><br>  Eh bien, pour que la vie ne ressemble pas √† du miel, je vous rappelle que le soi-disant transcodage est populaire aujourd'hui, alors qu'en fait vous devez travailler avec une vid√©o qui a √©t√© √† l'origine r√©duite par un algorithme, puis r√©duite par un autre, tandis que d'autres vecteurs de mouvement sont utilis√©s, les plus hauts sont d√©truits √† nouveau fr√©quences etc.  Et le fait qu'une personne y voit bien tout ne signifie pas que l'algorithme traitant une telle vid√©o fera r√©ellement des miracles.  Il ne sera pas possible de restaurer des vid√©os fortement pinc√©es, bien qu'en g√©n√©ral la Super R√©solution se d√©veloppera rapidement au cours des 10 prochaines ann√©es. <br><br><blockquote>  <b>Conclusions:</b> <br><br><ul><li>  N'oubliez pas que ce que vous voyez dans les films et comment c'est dans la vraie vie est tr√®s diff√©rent.  Et pas seulement en termes de r√©cup√©ration de vid√©o hautement compress√©e! <br></li><li>  Les algorithmes g√©n√©ralement modernes augmentent les r√©solutions de 2 fois, moins souvent - un peu plus, c'est-√†-dire  pas 50 fois, familiers des films, doivent bient√¥t attendre. <br></li><li>  Le domaine de la super r√©solution est en plein essor et vous pouvez vous attendre √† un d√©veloppement actif de la restauration vid√©o dans les ann√©es √† venir, y compris la r√©cup√©ration apr√®s compression. <br></li><li>  Mais la premi√®re chose que nous verrons est toutes sortes de sp√©culations sur le sujet, lorsque les r√©sultats d√©montr√©s exag√©reront consid√©rablement les capacit√©s r√©elles des algorithmes.  Faites attention! <br></li></ul></blockquote>  √Ä la fin de l'ann√©e derni√®re, nous avons donn√© une conf√©rence ¬´R√©seaux de neurones dans le traitement vid√©o - mythes et r√©alit√©¬ª.  On va peut-√™tre la mettre ici. <br><br>  Restez √† l'√©coute! <br><br><h2>  Remerciements </h2><br>  Je remercie chaleureusement: <br><br><ul><li>  Laboratoire d'infographie VMK Universit√© d'√âtat de Moscou  MV Lomonosov pour la puissance de calcul et pas seulement <br></li><li>  nos coll√®gues du groupe vid√©o, gr√¢ce auxquels les algorithmes ci-dessus ont √©t√© cr√©√©s, et en particulier Karen Simonyan, l'auteur de l'article dont les r√©sultats ont √©t√© montr√©s ci-dessus et qui travaille maintenant dans Google DeepMind, <br></li><li>  personnellement Konstantin Kozhemyakov, qui a fait beaucoup pour rendre cet article meilleur et plus visuel, <br></li><li>  Google pour son excellent blog et ses descriptions relativement correctes des technologies cr√©√©es, et Yandex pour sa tr√®s bonne concurrence sur un large front - Google est pratiquement le seul exemple r√©ussi dans un pays o√π les services Google ne sont pas interdits, <br></li><li>  Habrovchan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">denisshabr</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">JamboJet</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">iMADik</a> pour la pointe et les liens vers les cam√©ras professionnelles SR multi-images, <br></li><li>  et enfin, un grand merci √† Vyacheslav Napadovsky, Evgeny Kuptsov, Stanislav Grokholsky, Ivan Molodetsky, Alexei Soloviev, Evgeny Lyapustin, Yegor Sklyarov, Denis Kondranin, Alexandra Anzina, Roman Kazantsev et Gleb Ishelev pour cette grande quantit√© de remarques utiles mieux! <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439766/">https://habr.com/ru/post/fr439766/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439756/index.html">Pourquoi ai-je besoin d'un g√©n√©rateur thermoacoustique?</a></li>
<li><a href="../fr439758/index.html">√Ä mi-chemin "Juno"</a></li>
<li><a href="../fr439760/index.html">Les ing√©nieurs ont ¬´tordu¬ª la lumi√®re dans la fibre - une nouvelle technologie acc√©l√©rera le transfert de donn√©es d'une centaine</a></li>
<li><a href="../fr439762/index.html">Sur l'enseignement sup√©rieur, les programmeurs et les cols bleus</a></li>
<li><a href="../fr439764/index.html">Fruits d'entreprise</a></li>
<li><a href="../fr439768/index.html">Comment fonctionne un code-barres?</a></li>
<li><a href="../fr439772/index.html">√âcriture de tests unitaires dans Swift pour tester des t√¢ches asynchrones</a></li>
<li><a href="../fr439774/index.html">Automatisez le test des s√©lecteurs redux dans l'application</a></li>
<li><a href="../fr439776/index.html">Frontend Weekly Digest (4-10 f√©vrier 2019)</a></li>
<li><a href="../fr439778/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 351 (4-10 f√©vrier 2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
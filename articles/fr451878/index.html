<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖕🏾 👩🏿‍🚀 📍 Diffusion en direct de vidéo stéréo sur des lunettes VR (Oculus Go) 👨🏾‍🎤 🙍🏾 👨‍⚕️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous ne ferons pas une longue partie introductive, nous irons droit au but. 

 Il existe donc une caméra stéréo qui peut diffuser de la vidéo H264 via...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Diffusion en direct de vidéo stéréo sur des lunettes VR (Oculus Go)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451878/">  Nous ne ferons pas une longue partie introductive, nous irons droit au but. <br><br>  Il existe donc une caméra stéréo qui peut diffuser de la vidéo H264 via divers protocoles.  Il y a des lunettes Oculus Go.  Comment regarder un flux stéréo en direct à partir d'une caméra dans des lunettes VR?  Il est souhaitable, avec un minimum de retard et localement, que Youtube et les autres services vidéo RTMP disparaissent. <br><br>  Pour l'avenir, c'est ce qui s'est passé.  Au début - lecture d'un fichier vidéo précédemment enregistré en stéréo, puis lecture d'un flux en direct avec StereoPi (MPEG-TS via UDP). <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/MLPNXmZI8-8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><blockquote>  La caméra stéréo que j'utilise est StereoPi, je vais donc donner des exemples spécifiques à ce sujet.  En fait, c'est une framboise ordinaire, mais avec deux caméras, donc les exemples décrits peuvent être essayés sur des framboises ordinaires, si vous le voulez vraiment.  Certes, vous devrez installer le firmware depuis StereoPi. </blockquote>  La première chose a été de tenter de créer une application Android régulière qui lit le flux de la caméra en plein écran et de le remplir dans l'oculus avec la méthode de chargement latéral (via adb). <br><br>  Après quelques cueillettes avec le manifeste, les verres ont accepté de considérer cette application comme native.  Il est apparu dans les «Sources inconnues» de la bibliothèque, a démarré, a montré tout ce qui était nécessaire, mais il y avait un problème - les mouvements de la tête n'étaient pas pris en compte, la vidéo de la caméra était simplement stupidement affichée en plein écran avec des lunettes.  L'effet stéréo était oui, mais dès que vous bougiez un peu la tête, le Moscovite commençait à devenir fou, ce qui provoquait une sensation très, très inconfortable. <br><br>  Si c'est le cas, voici l'application .apk: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">StereoPi pour Oculus Go</a> En même temps dans les archives et adb se trouve, vous pouvez donc immédiatement essayer de remplir les verres.  Commande juste <br><br><pre><code class="bash hljs">adb install StereoPi.apk</code> </pre> <br>  Après cela, allez dans Bibliothèque -&gt; Sources inconnues, l'application com.virt2real.stereopi devrait y apparaître <br><br><img src="https://habrastorage.org/webt/q6/gi/zf/q6gizfqbbj_cftbnek3l8aqupno.png"><br><br>  Nous le démarrons et si StereoPi est dans le même réseau local que les lunettes, nous voyons immédiatement l'image stéréo de la caméra. <br><br>  Mais ce sont des ordures ... Je veux une application native normale pour l'oculus pour regarder la vidéo.  Pour qu'il y ait un écran immobile et pour ne pas prendre d'assaut en bougeant la tête.  Je ne suis pas encore prêt à apprendre Unity pour l'oculus, j'ai donc eu l'idée d'essayer d'utiliser les applications du lecteur vidéo déjà dans la boutique Oculus.  Je regarde généralement des films 3D dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Skybox</a> , j'ai donc essayé de l'utiliser. <br><br>  En plus de la visualisation habituelle des fichiers multimédias à partir du lecteur flash intégré et des périphériques réseau, un élément intéressant "Airscreen" a été trouvé dans Skybox.  Il s'est avéré que vous pouvez installer l'application Skybox sur un ordinateur avec Windows (enfin, ou sur un Mac), lui nourrir des fichiers vidéo puis il devient possible de regarder ces fichiers vidéo avec des lunettes.  C'est-à-dire  L'application Windows est un serveur vidéo et des lunettes - un client.  Je n'ai trouvé le protocole de communication nulle part, j'ai donc dû découvrir tcpdump. <br><br>  Après une courte fouille, il s'est avéré que Skybox utilise des messages de diffusion UDP pour rechercher un serveur dans le LAN.  Le message ressemble à ceci: <br><br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"command"</span></span>:<span class="hljs-string"><span class="hljs-string">"search"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"project"</span></span>:<span class="hljs-string"><span class="hljs-string">"direwolf"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceId"</span></span>:<span class="hljs-string"><span class="hljs-string">"66a86b57-b292-3957-9fc9-4041d5e1f841"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceType"</span></span>:<span class="hljs-string"><span class="hljs-string">"vr"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"udpPort"</span></span>:<span class="hljs-string"><span class="hljs-string">"6881"</span></span>}</code> </pre> <br><br>  Tous les messages en JSON sont très pratiques. <br><br>  À ce message, nous devons envoyer une réponse à l'hôte et au port de l'expéditeur spécifiés dans le message, c'est-à-dire  6881 <br><br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"udp"</span></span>:<span class="hljs-literal"><span class="hljs-literal">true</span></span>,<span class="hljs-attr"><span class="hljs-attr">"project"</span></span>:<span class="hljs-string"><span class="hljs-string">"direwolf server"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"command"</span></span>:<span class="hljs-string"><span class="hljs-string">"searchResult"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceId"</span></span>:<span class="hljs-string"><span class="hljs-string">"66a86b57-b292-3957-9fc9-4041d5e1f841"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"computerId"</span></span>:<span class="hljs-string"><span class="hljs-string">"53709de962eba2f9695c8a926562486c"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"computerName"</span></span>:<span class="hljs-string"><span class="hljs-string">"STEREO-PI"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"ip"</span></span>:<span class="hljs-string"><span class="hljs-string">"192.168.1.51"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"ips"</span></span>:[<span class="hljs-string"><span class="hljs-string">"192.168.1.51"</span></span>],<span class="hljs-attr"><span class="hljs-attr">"port"</span></span>:<span class="hljs-number"><span class="hljs-number">6888</span></span>}</code> </pre><br>  Ici, nous indiquons notre hôte et le port sur lequel nous avons le serveur WebSockets en cours d'exécution.  Toute communication ultérieure passera par des sockets Web. <br><br>  Par exemple, le premier message via les sockets Web ressemblera à ceci: <br><br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"command"</span></span>:<span class="hljs-string"><span class="hljs-string">"addDevice"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceId"</span></span>:<span class="hljs-string"><span class="hljs-string">"66a86b57-b292-3957-9fc9-4041d5e1f841"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceName"</span></span>:<span class="hljs-string"><span class="hljs-string">"Oculus Pacific"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceType"</span></span>:<span class="hljs-string"><span class="hljs-string">"vr"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"showLoginCode"</span></span>:<span class="hljs-literal"><span class="hljs-literal">true</span></span>}</code> </pre> <br>  Nous y répondons: <br><br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"command"</span></span>:<span class="hljs-string"><span class="hljs-string">"addDevice"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceId"</span></span>:<span class="hljs-string"><span class="hljs-string">"66a86b57-b292-3957-9fc9-4041d5e1f841"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceName"</span></span>:<span class="hljs-string"><span class="hljs-string">"Oculus Pacific"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"deviceType"</span></span>:<span class="hljs-string"><span class="hljs-string">"vr"</span></span>,<span class="hljs-attr"><span class="hljs-attr">"showLoginCode"</span></span>:<span class="hljs-literal"><span class="hljs-literal">true</span></span>}</code> </pre> <br>  Et après cela, dans la Skybox avec des lunettes, nous verrons notre StereoPi.  Ensuite, il y aura un tas de demandes pour lesquelles vous devez envoyer des réponses.  Le contenu de la playlist, par exemple. <br><br><div class="spoiler">  <b class="spoiler_title">Exemple de liste de lecture pour Skybox</b> <div class="spoiler_text">  [{id: 'livestream-rtsp', <br>  nom: «Live Stream RTSP», <br>  durée: 0, <br>  taille: 0, <br>  url: «rtsp: //192.168.1.51: 554 / h264», <br>  miniature: 'http://192.168.1.51/thumbnail/livestream.png', <br>  thumbnailLargeur: 186, <br>  thumbnailHauteur: 120, <br>  lastModified: 1, <br>  defaultVRSetting: 1, <br>  userVRSetting: 2, <br>  largeur: 1280, <br>  hauteur: 720, <br>  orientDegree: '0', <br>  sous-titres: [], <br>  ratioTypeFor2DScreen: 'par défaut', <br>  rotationFor2DScreen: 0, <br>  existe: vrai <br>  isBadMedia: faux, <br>  addedTime: 1}, <br>  {id: 'livestream-mpegts', <br>  nom: «Live Stream MPEG-TS», <br>  durée: 0, <br>  taille: 0, <br>  url: 'udp: // @: 3001', <br>  miniature: 'http://192.168.1.51/thumbnail/livestream.png', <br>  thumbnailLargeur: 186, <br>  thumbnailHauteur: 120, <br>  lastModified: 1, <br>  defaultVRSetting: 1, <br>  userVRSetting: 2, <br>  largeur: 1280, <br>  hauteur: 720, <br>  orientDegree: '0', <br>  sous-titres: [], <br>  ratioTypeFor2DScreen: 'par défaut', <br>  rotationFor2DScreen: 0, <br>  existe: vrai <br>  isBadMedia: faux, <br>  addedTime: 1}] <br></div></div><br>  Ceci est particulièrement intéressant car  dans la playlist qui forme l'application Windows, l'abréviation convoitée RTSP a été découverte.  Il s'est avéré que l'application serveur diffuse des fichiers vidéo via RTSP, qui est déjà adapté au streaming vidéo en direct, dont nous avons bien sûr besoin.  Plus précisément, il s'est avéré qu'il y avait «RTSP» dans la liste de lecture, mais les liens vers les fichiers vidéo sont des http réguliers.  C'est-à-dire  l'application serveur envoie toujours des fichiers via HTTP, mais cela ne nous convient pas.  À ce stade, j'étais déjà bouleversé, mais je me suis dit, pourquoi ne pas essayer de donner un lien dans la liste de lecture dans un format que VLC comprend habituellement, c'est-à-dire  rtsp: //192.168.1.51: 554 / h264 Et bravo, Skybox a commencé à lire le flux vidéo du serveur RTSP sur la chaîne stéréo.  Le retard est très important, 20 secondes, donc on continue.  Nous essayons d'alimenter le flux UDP en MPEG-TS.  Encore une fois, VLC mange généralement cela en utilisant le lien udp: // @: 3001, pour Skybox, j'ai essayé de spécifier la même manière.  Il ne reste alors plus qu'à diriger le flux MPEG-TS vers l'hôte de lunettes et le port UDP spécifié.  GStreamer est impliqué pour cela: <br><br><pre> <code class="bash hljs">raspivid -3d sbs -w 1280 -h 720 -o - | gst-launch-1.0 -q fdsrc ! h264parse ! mpegtsmux alignment=7 name=muxer ! rndbuffersize max=1316 min=1316 ! multiudpsink clients=<span class="hljs-string"><span class="hljs-string">"192.168.1.60:3001"</span></span> sync=<span class="hljs-literal"><span class="hljs-literal">false</span></span></code> </pre> <br>  Dans la skybox, nous cliquons sur l'élément de playlist «Live Stream MPEG-TS» et le tour est joué, nous voyons un flux MPEG-TS en direct sur grand écran dans un cinéma virtuel.  Le retard est beaucoup moins qu'avec RTSP, 2-3 secondes, mais toujours beaucoup plus que dans ma simple application qui reçoit un flux H264 brut sur UDP (il y a généralement un retard de 100-150 ms à une résolution de 720p). <br><br>  Ensuite, je suis tombé dans une impasse, jusqu'à présent je n'ai pas réussi à réduire le retard.  Peut-être que vous devez désactiver la mise en mémoire tampon dans Skybox lui-même, je vais essayer d'écrire aux développeurs, peut-être qu'ils feront l'option "Désactiver la mise en mémoire tampon" :-) <br><br><h3>  En conclusion </h3><br>  En général, si soudainement, pour une raison quelconque, vous aviez soudainement besoin de regarder un flux vidéo en direct dans les oculi ou d'autres lunettes VR (Skybox est disponible sur de nombreuses plateformes comme) - vous pouvez essayer la méthode que j'ai décrite.  Je ne sais pas si cela fonctionnera avec d'autres caméras stéréo, mais avec StereoPi c'est vérifié, ça laboure. <br><br><h3>  Les références </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source serveur pour skybox</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Fil de discussion avec discussion</a> <br><br>  Merci à tous, tout le monde est libre. <br><br>  Oh oui, j'ai presque oublié.  Si tout à coup quelqu'un peut aider avec l'application native pour l'oculus (pour qu'elle ressemble à Skybox) - écrivez dans un message personnel, nous discuterons des détails. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451878/">https://habr.com/ru/post/fr451878/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451866/index.html">Choisissez les nœuds les plus proches du réseau</a></li>
<li><a href="../fr451870/index.html">Fonctionnalités C ++ modernes que tous les programmeurs doivent connaître</a></li>
<li><a href="../fr451872/index.html">Python est un assistant pour trouver des vols pas chers pour ceux qui aiment voyager</a></li>
<li><a href="../fr451874/index.html">Meilleures tendances SEO chez Google</a></li>
<li><a href="../fr451876/index.html">Centre de données de Francfort: Centre de données Telehouse</a></li>
<li><a href="../fr451880/index.html">DevPRO'19: vue depuis le stand Wrike</a></li>
<li><a href="../fr451884/index.html">Sept ans de travail en tant que développeur: quelles leçons ai-je tirées</a></li>
<li><a href="../fr451886/index.html">Utilisation de mathématiques discrètes dans les tests</a></li>
<li><a href="../fr451890/index.html">Délégation d'une zone de sous-réseau inverse inférieure à / 24 dans BIND. Comment ça marche</a></li>
<li><a href="../fr451894/index.html">Un aperçu bref et dynamique de l'architecture du compilateur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
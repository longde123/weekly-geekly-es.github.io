<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßôüèº üïû ‚òÄÔ∏è Wie wir VMware vSAN ‚Ñ¢ getestet haben: Warum es in der Praxis funktioniert üôåüèø üôÜüèø ü§πüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor einem Jahr habe ich ein Rechenzentrum aus einem Stapel Intel NUC zusammengestellt . Es gab ein Softwarespeichersystem, das die Putzfrau nicht zers...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir VMware vSAN ‚Ñ¢ getestet haben: Warum es in der Praxis funktioniert</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/croc/blog/414125/">  Vor einem Jahr habe ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Rechenzentrum aus einem Stapel Intel NUC zusammengestellt</a> .  Es gab ein Softwarespeichersystem, das die Putzfrau nicht zerst√∂ren konnte. Ein paar Mal brach der Cluster zusammen. <br><br>  Und jetzt haben wir beschlossen, vSAN auf mehreren Servern in einer sehr guten Konfiguration auszuf√ºhren, um die Leistung und Fehlertoleranz der L√∂sung vollst√§ndig zu bewerten.  Nat√ºrlich hatten wir eine Reihe erfolgreicher Implementierungen in der Produktion f√ºr unsere Kunden, bei denen vSAN die festgelegten Aufgaben erfolgreich l√∂ste, aber es war nicht m√∂glich, umfassende Tests durchzuf√ºhren.  Eigentlich m√∂chte ich heute die Testergebnisse teilen. <br><br>  Wir werden den Speicher mit einer Last qu√§len, fallen lassen und auf jede m√∂gliche Weise die Fehlertoleranz testen.  F√ºr Details lade ich alle zur Katze ein. <br><a name="habracut"></a><br><h3>  Was ist VMware vSAN im Allgemeinen und warum sind wir darauf gekommen? </h3><br>  Es gibt einen regul√§ren Servercluster f√ºr virtuelle Maschinen.  Es verf√ºgt √ºber eine Reihe unabh√§ngiger Komponenten, der Hypervisor wird direkt auf der Hardware ausgef√ºhrt und der Speicher wird separat auf der Basis von DAS, NAS oder SAN konfiguriert.  Langsame Daten auf der Festplatte, hei√üe Daten auf der SSD.  Alles ist bekannt.  Hier ergibt sich jedoch das Problem der Bereitstellung und Verwaltung dieses Zoos.  Es macht besonders Spa√ü, wenn einzelne Elemente des Systems von verschiedenen Anbietern stammen.  Bei Problemen hat das Andocken von Tickets f√ºr den technischen Support verschiedener Hersteller eine besondere Atmosph√§re. <br><br>  Es gibt separate Eisenst√ºcke, die aus Sicht des Servers wie Discs f√ºr die Aufnahme aussehen. <br><br>  Und es gibt hyperkonvergente Systeme.  In ihnen erhalten Sie eine universelle Einheit, die die gesamten Kopfschmerzen der Interaktion zwischen Netzwerk, Festplatten, Prozessoren, Speicher und den virtuellen Maschinen, die sich auf ihnen drehen, √ºbernimmt.  Alle Daten flie√üen in ein Bedienfeld. Bei Bedarf k√∂nnen Sie einfach ein paar weitere Einheiten hinzuf√ºgen, um die erh√∂hte Last auszugleichen.  Die Verwaltung ist stark vereinfacht und standardisiert. <br><br><img src="https://habrastorage.org/webt/xi/4m/uw/xi4muweeppbjng1b8mrpc-bzi3m.png"><br>  VMware vSAN bezieht sich nur auf die L√∂sungen, auf deren Grundlage es bereitgestellt wird <br>  hyperkonvergente Infrastruktur.  Das Hauptmerkmal des Produkts ist die enge Integration in die Virtualisierungsplattform VMware vSphere, die f√ºhrend unter den Virtualisierungsl√∂sungen ist, mit denen Sie innerhalb von Minuten Softwarespeicher f√ºr virtuelle Maschinen auf Virtualisierungsservern bereitstellen k√∂nnen.  vSAN √ºbernimmt direkt die Kontrolle √ºber E / A-Vorg√§nge auf niedriger Ebene, verteilt die Last optimal, speichert Lese- / Schreibvorg√§nge zwischen und leistet viel mehr bei minimaler Belastung von Speicher und Prozessor.  Die Transparenz des Systems ist leicht eingeschr√§nkt, aber als Ergebnis funktioniert alles, wie es hei√üt. Automatisch kann vSAN als Hybridspeicher und in Form einer All-Flash-Version konfiguriert werden.  Die Skalierung erfolgt sowohl horizontal durch Hinzuf√ºgen neuer Knoten zum Cluster als auch vertikal, wodurch die Anzahl der Festplatten in einzelnen Knoten erh√∂ht wird.  Die Verwaltung mit einem eigenen vSphere-Webclient ist aufgrund der engen Integration mit anderen Produkten sehr bequem. <br><br>  Wir haben uns f√ºr eine saubere All-Flash-Konfiguration entschieden, die hinsichtlich Preis und Leistung optimal sein sollte.  Es ist klar, dass die Gesamtkapazit√§t im Vergleich zur Hybridkonfiguration mit Magnetplatten etwas geringer ist, aber hier haben wir uns entschlossen zu pr√ºfen, wie dies teilweise durch L√∂schcodierung sowie Deduplizierung und Komprimierung im laufenden Betrieb umgangen werden kann.  Infolgedessen kommt die Speichereffizienz den Hybridl√∂sungen n√§her, ist jedoch bei minimalem Overhead erheblich schneller. <br><br><h3>  Wie zu testen </h3><br>  Um die Leistung zu testen, haben wir die Software <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HCIBench v1.6.6</a> verwendet, die den Prozess des Erstellens vieler virtueller Maschinen und des anschlie√üenden Kompilierens der Ergebnisse automatisiert.  Der Leistungstest selbst wird mit der Vdbench-Software durchgef√ºhrt, einer der beliebtesten Software f√ºr synthetische Lasttests.  Eisen war in den folgenden Konfigurationsoptionen: <br><br><ol><li>  All-Flash - 2 Festplattengruppen: 1xNVMe SSD Samsung PM1725 800 GB + 3xSATA </li><li>  SSD Toshiba HK4E 1,6 TB. </li><li>  All-Flash - 1 Festplattengruppe: 1xNVMe SSD Samsung PM1725 800 GB + 6xSATA SSD Toshiba HK4E 1,6 TB. </li><li>  All-Flash - 1 Festplattengruppe: 1xNVMe SSD Samsung PM1725 800 GB + 6xSATA SSD Toshiba HK4E 1,6 TB + Speichereffizienz (Deduplizierung und Komprimierung). </li><li>  All-Flash - 1 Festplattengruppe: 1xNVMe SSD Samsung PM1725 800 GB + 6xSATA SSD Toshiba HK4E 1,6 TB + L√∂schcodierung (RAID 5/6). </li><li>  All-Flash - 1 Festplattengruppe: 1xNVMe SSD Samsung PM1725 800 GB + 6xSATA SSD Toshiba HK4E 1,6 TB + L√∂schcodierung (RAID 5/6) + Speichereffizienz (Deduplizierung und Komprimierung). </li></ol><br>  W√§hrend der Tests haben wir drei verschiedene Volumina aktiver Daten emuliert, die von Anwendungen verwendet werden: 1 TB (250 GB pro Server), 2 TB (500 GB pro Server) und 4 TB (jeweils 1 TB). <br><br>  F√ºr jede Konfiguration wurde der gleiche Satz von Tests mit den folgenden Lastprofilen durchgef√ºhrt: <br><br><ol><li>  0 Lesen / 100 Schreiben, zuf√§llig 50%, Blockgr√∂√üe - 4k. </li><li>  30 Lesen / 70 Schreiben, zuf√§llig 50%, Blockgr√∂√üe - 4k. </li><li>  70 Lesen / 30 Schreiben, zuf√§llig 50%, Blockgr√∂√üe - 4k. </li><li>  100 Lesen / 0 Schreiben, zuf√§llig 50%, Blockgr√∂√üe - 4k. </li></ol><br>  Die erste und vierte Option waren erforderlich, um zu verstehen, wie sich das System bei maximaler und minimaler Belastung verh√§lt.  Aber der zweite und dritte Punkt kommen dem tats√§chlichen typischen Anwendungsfall so nahe wie m√∂glich: zum Beispiel 30 Lesen / 70 Schreiben - VDI.  Diese Lasten, denen ich in der Produktion begegnet bin, waren ihnen sehr nahe.  Dabei haben wir die Wirksamkeit des vSAN-Datenverwaltungsmechanismus getestet. <br><br>  Im Allgemeinen erwies sich das System als sehr gut.  Basierend auf den Testergebnissen haben wir festgestellt, dass wir mit einer Leistung im Bereich von 20.000 IOPS pro Knoten rechnen k√∂nnen.  F√ºr normale und stark belastete Aufgaben sind dies gute Indikatoren, die Verz√∂gerungen von 5 ms ber√ºcksichtigen.  Unten habe ich Grafiken mit den Ergebnissen gegeben: <br><br><img src="https://habrastorage.org/webt/2w/l5/q3/2wl5q38sg-f3f0t5a9smo2nz9m0.png"><br><img src="https://habrastorage.org/webt/fn/zm/bf/fnzmbff0apti4eqq8dk9o3emrym.png"><br><img src="https://habrastorage.org/webt/lc/_c/yv/lc_cyvqfd1hwe15iggyo8lxxagg.png"><br><img src="https://habrastorage.org/webt/i6/at/yu/i6atyu48yarwd5d31qgcstxx2so.png"><br><img src="https://habrastorage.org/webt/ih/y3/8o/ihy38oa_emlvkdokq9ryzt3hhum.png"><br><br>  √úbersichtstabelle mit Testergebnissen: <br><img src="https://habrastorage.org/webt/1v/xg/tm/1vxgtm0tpyiwqzujesrkzjcjlj8.jpeg"><br>  Die gr√ºne Farbe zeigt aktive Daten an, die vollst√§ndig zwischengespeichert sind. <br><br><h3>  Fehlertoleranz </h3><br>  Ich habe trotz der Emp√∂rung der Maschine einen Knoten nach dem anderen abgeschnitten und die Reaktion des gesamten Systems betrachtet.  Nach dem Trennen des ersten Knotens passierte bis auf einen kleinen Leistungsabfall um etwa 10-15% √ºberhaupt nichts.  Ich l√∂schte den zweiten Knoten - einige der virtuellen Maschinen wurden heruntergefahren, aber der Rest arbeitete weiterhin mit einer leichten Verschlechterung der Leistung.  Gesamt√ºberlebensf√§higkeit erfreut.  Alle Knoten neu gestartet - das System hat ein wenig nachgedacht und ohne Probleme erneut synchronisiert, alle virtuellen Maschinen wurden ohne Probleme gestartet.  Wie einmal auf NUCs.  Die Integrit√§t der Daten wird ebenfalls nicht beeintr√§chtigt, was sehr erfreut ist. <br><br><h3>  Allgemeine Eindr√ºcke </h3><br>  Software Defined Storage Systems (SDS) ist bereits eine ausgereifte Technologie. <br><br>  Einer der wichtigsten Stoppfaktoren, die der Implementierung von vSAN im Wege stehen, sind heute die relativ hohen Kosten einer Lizenz in Rubel.  Wenn Sie die Infrastruktur von Grund auf neu erstellen, kann sich herausstellen, dass ein herk√∂mmliches Speichersystem in einer √§hnlichen Konfiguration ungef√§hr gleich viel kostet.  Es wird jedoch sowohl hinsichtlich der Verwaltung als auch der Skalierung weniger flexibel sein.  Wenn Sie sich heute f√ºr eine L√∂sung zum Speichern von Daten virtueller Maschinen auf der vSphere-Virtualisierungsplattform entscheiden, ist es sehr gut, alle Vor- und Nachteile der Verwendung traditioneller L√∂sungen und der Implementierung softwaredefinierter Speichertechnologie abzuw√§gen. <br><br>  Sie k√∂nnen eine L√∂sung auf demselben Ceph oder GlusterFS erstellen. Wenn Sie jedoch mit der VMware-Infrastruktur arbeiten, ist die vSAN-Integration mit einzelnen Komponenten ebenso faszinierend wie die einfache Verwaltung, Bereitstellung und die erheblich h√∂here Leistung, insbesondere auf einer kleinen Anzahl von Knoten.  Wenn Sie bereits an der VMware-Infrastruktur arbeiten, ist die Bereitstellung f√ºr Sie daher viel einfacher.  Sie machen wirklich ein Dutzend Klicks und erhalten ein funktionierendes Sicherheitsdatenblatt aus der Box. <br><br>  Eine weitere Motivation f√ºr die Bereitstellung von vSAN ist die Verwendung f√ºr Zweige, mit denen Sie Knoten in Remote-Einheiten mit einem Zeugenhost im Rechenzentrum spiegeln k√∂nnen.  Diese Konfiguration bietet fehlertoleranten Speicher f√ºr virtuelle Maschinen mit allen vSAN-Technologien und der Leistung auf nur zwei Knoten.  F√ºr die Verwendung von vSAN gibt es √ºbrigens ein separates Lizenzierungsschema f√ºr die Anzahl der virtuellen Maschinen, mit dem die Kosten im Vergleich zum herk√∂mmlichen vSAN-Lizenzierungsschema f√ºr Prozessoren gesenkt werden k√∂nnen. <br><br>  Architektonisch erfordert die L√∂sung 10-Gbit-Ethernet mit zwei Verbindungen pro Knoten f√ºr eine angemessene Verkehrsverteilung, wenn eine All-Flash-L√∂sung verwendet wird.  Im Vergleich zu herk√∂mmlichen Systemen sparen Sie Rack-Platz und SAN-Netzwerke, indem Sie Fibre Channel zugunsten des universelleren Ethernet-Standards eliminieren.  Um die Fehlertoleranz sicherzustellen, sind mindestens drei Knoten erforderlich, auf zwei Replikaten von Objekten mit Daten werden gespeichert, und auf dem dritten - Zeugenobjekte f√ºr diese Daten - wird das Problem des Split-Brain gel√∂st. <br><br>  Nun ein paar Fragen an Sie: <br><br><ol><li>  Welche Kriterien sind f√ºr Sie am wichtigsten, wenn Sie sich f√ºr ein Speichersystem entscheiden? </li><li>  Welche Stoppfaktoren sehen Sie auf dem Weg zur Implementierung softwaredefinierter Speichersysteme? </li><li>  Welche softwaredefinierten Speichersysteme betrachten Sie grunds√§tzlich als Option f√ºr die Implementierung? </li></ol><br><br>  UPD: Ich habe v√∂llig vergessen, die Standkonfiguration und die Ladeparameter zu schreiben: <br><br>  1. Beschreibung des Eisens.  Zum Beispiel: <br>  Server - 4xDellR630, jeweils: <br>  ‚Ä¢ 2xE5-2680v4 <br>  ‚Ä¢ 128 GB RAM <br>  ‚Ä¢ 2x10 GbE <br>  ‚Ä¢ 2x1 GbE f√ºr Management / VM-Netzwerk <br>  ‚Ä¢ Dell HBA330 <br>  Speicherkonfiguration Nr. 1: <br>  2xPM1725 800 GB <br>  6xToshiba HK4E 1.6 TB <br>  Speicherkonfiguration Nr. 2: <br>  1xPM1725 800 GB <br>  6xToshiba HK4E 1.6 TB <br><br>  2. Beschreibung der Softwareversionen: <br>  vSphere 6.5U1 (7967591) (vSAN 6.6.1), d.h.  Patches nach Meltdown / Spectre <br>  vCenter 6.5U1g <br>  Neueste unterst√ºtzte Treiber und FW von vSAN und ESXi f√ºr alle Komponenten <br>  LACP f√ºr vSAN- und vMotion-Verkehr (mit aktivierten NIOC-Freigaben / Limits / Reservierungen) <br>  Alle anderen Einstellungen sind Standardeinstellungen <br><br>  3. Parameter laden: <br>  ‚Ä¢ HCIBench 1.6.6 <br>  ‚Ä¢ Oracle Vdbench - 04/05/06 <br>  ‚Ä¢ 40 VM pro Cluster (10 pro Knoten) <br>  ‚Ä¢ 10 VMDK pro VM <br>  ‚Ä¢ 10 GB vmdk-Gr√∂√üe und 100/50/25% Workload-Set-Prozentsatz <br>  ‚Ä¢ Aufw√§rmzeit - 1800 Sekunden (0,5 Stunden), Testzeit 3600 (1 Stunde) <br>  ‚Ä¢ 1 Threads pro VMDK </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414125/">https://habr.com/ru/post/de414125/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414115/index.html">Was ist Lazy FP State Restore? Eine neue Sicherheitsanf√§lligkeit, die in Intel-Prozessoren entdeckt wurde</a></li>
<li><a href="../de414117/index.html">Gemischtes Dezimal-Bin√§rformat gegen IEEE754</a></li>
<li><a href="../de414119/index.html">Gelegenheit schlief aufgrund eines Sandsturms auf dem Mars ein. Es ist unklar, ob der Rover wieder arbeiten kann</a></li>
<li><a href="../de414121/index.html">DIY Standalone-Drohne mit Internetsteuerung</a></li>
<li><a href="../de414123/index.html">Wir aktualisieren die Textprotokolle auf Bin√§r und bek√§mpfen den Legacy-Code bei einem C ++ - Benutzergruppentreffen</a></li>
<li><a href="../de414127/index.html">Installieren Sie 3CX auf einem Hosting f√ºr 2,99 Euro / Monat. in 10 Minuten</a></li>
<li><a href="../de414129/index.html">Master in Theoretischer Informatik an der St. Petersburg State University</a></li>
<li><a href="../de414131/index.html">Die Auswirkung der Signalfrequenz auf die Energie von Funkverbindungen im freien Raum</a></li>
<li><a href="../de414133/index.html">Puzzlespieldesign am Beispiel von In The Shadows</a></li>
<li><a href="../de414135/index.html">Durch die Portierung eines Spiels auf PSVita wurde die Gesamtleistung verbessert</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
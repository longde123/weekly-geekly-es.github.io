<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïé ‚ÜñÔ∏è üè∏ Desde alta latencia de ceph hasta parche de kernel con eBPF / BCC üíáüèø ‚è´ üßòüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hay muchas herramientas para depurar kernel y programas de espacio de usuario en Linux. La mayor√≠a de ellos tienen un impacto en el rendimiento y no s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Desde alta latencia de ceph hasta parche de kernel con eBPF / BCC</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/450818/"><img src="https://habrastorage.org/webt/-8/ok/na/-8okna9qfyroicvgoz-zenv7-si.png"><br><br>  Hay muchas herramientas para depurar kernel y programas de espacio de usuario en Linux.  La mayor√≠a de ellos tienen un impacto en el rendimiento y no se pueden ejecutar f√°cilmente en entornos de producci√≥n.  Hace unos a√±os, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se desarroll√≥</a> eBPF, que proporciona la capacidad de rastrear el n√∫cleo y el espacio de usuario con una sobrecarga baja, sin necesidad de volver a compilar programas o cargar m√≥dulos de n√∫cleo. <br><br>  Ahora hay muchas herramientas que usan eBPF y en este art√≠culo, explicaremos c√≥mo escribir su propia herramienta de creaci√≥n de perfiles utilizando la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">biblioteca PythonBCC</a> .  Este art√≠culo se basa en un problema real del entorno de producci√≥n.  Le guiaremos a trav√©s de la resoluci√≥n del problema y le mostraremos c√≥mo se pueden usar las herramientas bcc existentes en algunos casos. <br><a name="habracut"></a><br><h2>  Ceph es lento </h2><br>  Se agreg√≥ una nueva plataforma a un grupo ceph.  Despu√©s de migrar algunos datos a la plataforma, la latencia para las solicitudes de escritura fue mayor que en los otros servidores. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/de/-l/ukde-lsu9sjqnmci1ix942xzgie.png"></div><br><br>  Esta plataforma tiene un nuevo dispositivo virtual de almacenamiento en cach√©, bcache, que no hemos usado en este cl√∫ster antes, y un nuevo n√∫cleo, 4.15, que todav√≠a no se usa en ning√∫n otro lugar de este cl√∫ster.  La ra√≠z del problema podr√≠a estar en cualquier lugar, as√≠ que echemos un vistazo m√°s profundo. <br><br><h3>  Investigando al anfitri√≥n </h3><br>  Echemos un vistazo a lo que sucede dentro del proceso ceph-osd.  Utilizamos la herramienta de rastreo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">perf</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">flamescope</a> para construir gr√°ficos de llamas: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ch/5k/nn/ch5knn22cmukd1oldmcozpxe98i.png"></div><br><br>  Como podemos ver en el gr√°fico de llamas, <b>fdatasync ()</b> pas√≥ mucho tiempo enviando bio en la funci√≥n <b>generic_make_request ()</b> .  Por lo tanto, la ra√≠z de nuestro problema est√° en alg√∫n lugar fuera del ceph daemon.  Puede ser un problema de kernel, bcache o disco.  La salida de iostat mostr√≥ alta latencia para dispositivos bcache. <br><br>  Otro hallazgo sospechoso es que el demonio systemd-udevd est√° consumiendo CPU;  alrededor del 20% en m√∫ltiples CPU.  Este es un comportamiento extra√±o, por lo que tenemos que averiguar qu√© est√° pasando.  Dado que systemd-udevd funciona con uevents, tenemos que usar <b>udevadm monitor</b> para averiguar si hay alg√∫n evento en el sistema.  Despu√©s de verificar, vimos que se generaban muchos eventos de "cambio" para cada dispositivo de bloque en el sistema. <br><br>  Esto es inusual, as√≠ que vamos a descubrir qu√© est√° causando que se env√≠en todos estos eventos. <br><br>
<h3>  Usando el kit de herramientas BCC </h3><br>  Como ya sabemos, el kernel (y ceph daemon) est√° pasando mucho tiempo realizando funciones <b>generic_make_requst ()</b> .  <b>Midamos</b> su latencia utilizando la <b>funclatency</b> del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">kit de herramientas BCC</a> , solo para asegurarnos de que estamos en el camino correcto.  Trazaremos el PID del ceph daemon (argumento -p) en intervalos de 1 segundo (-i) e imprimiremos la latencia en milisegundos (-m). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4c/cj/za/4ccjza8x8bq0vqkxfol2j5d9sva.png"></div><br><br>  Esta funci√≥n generalmente funciona muy r√°pido.  Todo lo que hace es enviar la bioestructura a la cola del controlador del dispositivo. <br><br>  <b>Bcache</b> es un dispositivo complejo;  de hecho, consta de 3 dispositivos: un dispositivo de respaldo, que es un HDD lento en nuestro caso;  un dispositivo de almacenamiento en cach√©, que es la partici√≥n de la unidad NVMe;  y un dispositivo virtual bcache, que es utilizado por la aplicaci√≥n.  Sabemos que la presentaci√≥n es lenta, pero ¬øpara qu√© dispositivo?  Esto es algo que veremos m√°s adelante. <br><br>  Por ahora, sabemos que los eventos causan problemas en los demonios ceph y tenemos que encontrar el software que desencadena eventos. No es f√°cil encontrar la causa de que se generen eventos.  Asumimos que es un software que solo se ejecuta peri√≥dicamente.  Para ver qu√© se est√° ejecutando en el sistema, utilizamos <b>execsnoop</b> del kit de herramientas BCC.  Podemos ejecutarlo y redirigir <b>stdout</b> a un archivo. <br><br>  Por ejemplo: <br><br><pre><code class="bash hljs">/usr/share/bcc/tools/execsnoop | tee ./execdump</code> </pre> <br>  Aqu√≠ no daremos la salida completa de execsnoop, pero una cadena interesante que encontramos all√≠ fue: <br><br><pre> <code class="bash hljs">sh 1764905 5802 0 sudo arcconf getconfig 1 AD | grep Temperature | awk -F <span class="hljs-string"><span class="hljs-string">'[:/]'</span></span> <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span> | sed <span class="hljs-string"><span class="hljs-string">'s/^ \([0-9]*\) C.*/\1/'</span></span></code> </pre> <br>  La tercera columna es el PPID del proceso.  Verificamos qu√© era 5802 y vimos que es uno de nuestros hilos de daemon de monitoreo.  Mirando m√°s a fondo la configuraci√≥n del sistema de monitoreo, encontramos un par√°metro defectuoso.  La temperatura del HBA se recuperaba cada 30 segundos, lo cual es muy frecuente.  Despu√©s de cambiar el intervalo de verificaci√≥n a un valor m√°s apropiado, vimos que nuestra latencia ceph coincid√≠a con las otras plataformas. <br><br>  Pero todav√≠a no sabemos por qu√© la latencia de bcache fue alta.  Configuramos una plataforma de prueba con la misma configuraci√≥n e intentamos reproducir el problema con fio en el dispositivo bcache mientras simult√°neamente activamos udev con el comando de activaci√≥n udevadm. <br><br><h3>  Escribir herramientas basadas en BCC </h3><br>  Lo que haremos aqu√≠ es escribir una herramienta simple que rastree las llamadas m√°s lentas generic_make_request () e imprima el nombre del disco para el que se solicit√≥ la funci√≥n. <br><br>  El plan es simple: <br><br><ul><li>  Registre <b>kprobe</b> en <b>generic_make_request ()</b> : <br><ul><li>  Guarde el nombre del disco disponible desde el argumento de la funci√≥n </li><li>  Guardar la marca de tiempo actual </li></ul></li><li>  Registre <b>kretprobe</b> en la declaraci√≥n de devoluci√≥n <b>generic_make_request ()</b> : <br><ul><li>  Recuperar la marca de tiempo actual </li><li>  Busque marcas de tiempo guardadas previamente y comp√°relas con las actuales </li><li>  Si el resultado es m√°s alto que el umbral, busque los nombres de disco previamente guardados e impr√≠malos en el terminal con informaci√≥n adicional </li></ul></li></ul><br>  <b>Kprobes</b> y <b>kretprobes</b> usan puntos de interrupci√≥n para cambiar el c√≥digo de una funci√≥n en tiempo de ejecuci√≥n.  Puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n</a> y un buen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> sobre esto.  Si observa el c√≥digo de las diferentes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">herramientas de BCC</a> , ver√° que todas tienen una estructura id√©ntica.  Omitiremos el an√°lisis de argumentos y nos centraremos en el programa BPF. <br><br>  El texto de nuestro programa se definir√° en python de la siguiente manera: <br><br><pre> <code class="python hljs">bpf_text = ‚Äú‚Äù‚Äù <span class="hljs-comment"><span class="hljs-comment"># Here will be the bpf program code ‚Äú‚Äù‚Äù</span></span></code> </pre> <br>  Los programas BPF usan <a href="">hashmaps</a> para compartir datos entre diferentes funciones.  Usaremos PID como una clave y una estructura autodefinida como un valor. <br><br><pre> <code class="python hljs">struct data_t { u64 pid; u64 ts; char comm[TASK_COMM_LEN]; u64 lat; char disk[DISK_NAME_LEN]; }; BPF_HASH(p, u64, struct data_t); BPF_PERF_OUTPUT(events);</code> </pre> <br>  Aqu√≠ registramos un hashmap llamado <b>p</b> con un tipo de clave <b>u64</b> y un tipo de valor <b>struct data_t</b> .  Este mapa es accesible desde el contexto de nuestro programa BPF.  La macro <b>BPF_PERF_OUTPUT</b> registra otro mapa llamado <b>eventos</b> , que se utiliza para <a href="">enviar datos</a> al espacio de usuario. <br><br>  Al medir la latencia entre la llamada de funci√≥n y su retorno o entre una llamada de funci√≥n y otra, debe asegurarse de que los datos que guard√≥ y acceda m√°s tarde se relacionan con el mismo contexto.  En otras palabras, debe tener en cuenta cualquier otra ejecuci√≥n paralela de la misma funci√≥n.  Es posible rastrear la latencia entre la llamada de funci√≥n de un proceso y los retornos de la misma funci√≥n de otro proceso, pero esto no nos ayuda.  Un buen ejemplo es la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">herramienta de biolatencia</a> donde se utiliza la <b>solicitud de</b> puntero a <b>estructura</b> como clave de hashmap. <br><br>  A continuaci√≥n, tenemos que escribir un c√≥digo que se ejecutar√° en las llamadas de funci√≥n a trav√©s de un mecanismo kprobe: <br><br><pre> <code class="python hljs">void start(struct pt_regs *ctx, struct bio *bio) { u64 pid = bpf_get_current_pid_tgid(); struct data_t data = {}; u64 ts = bpf_ktime_get_ns(); data.pid = pid; data.ts = ts; bpf_probe_read_str(&amp;data.disk, sizeof(data.disk), (void*)bio-&gt;bi_disk-&gt;disk_name); p.update(&amp;pid, &amp;data); }</code> </pre> <br>  Aqu√≠ tenemos el primer <a href="">argumento generic_make_request ()</a> como el segundo argumento de nuestra funci√≥n.  Luego obtenemos el PID y la marca de tiempo actual en nanosegundos y lo escribimos en la <b>estructura</b> recientemente asignada <b>data_t data</b> .  Obtenemos el nombre del disco de la <b>bioestructura</b> , que se pasa a <b>generic_make_request ()</b> , y lo <b>guardamos</b> en nuestros <b>datos</b> .  El √∫ltimo paso es agregar una entrada al hashmap que describimos anteriormente. <br><br>  Esta funci√≥n se ejecutar√° en <b>generic_make_request ()</b> devuelve: <br><br><pre> <code class="python hljs">void stop(struct pt_regs *ctx) { u64 pid = bpf_get_current_pid_tgid(); u64 ts = bpf_ktime_get_ns(); struct data_t* data = p.lookup(&amp;pid); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data != <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; data-&gt;ts &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { bpf_get_current_comm(&amp;data-&gt;comm, sizeof(data-&gt;comm)); data-&gt;lat = (ts - data-&gt;ts)/<span class="hljs-number"><span class="hljs-number">1000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data-&gt;lat &gt; MIN_US) { FACTOR data-&gt;pid &gt;&gt;= <span class="hljs-number"><span class="hljs-number">32</span></span>; events.perf_submit(ctx, data, sizeof(struct data_t)); } p.delete(&amp;pid); } }</code> </pre> <br>  Obtenemos el PID y la marca de tiempo de la salida anterior y buscamos el hashmap para el valor donde <b>key == PID actual</b> .  Si se encuentra, obtenemos el nombre del proceso en ejecuci√≥n y lo agregamos a la estructura de <b>datos</b> .  Lo que hacemos con <b>datos-&gt; pid</b> aqu√≠ nos da la identificaci√≥n del grupo de subprocesos.  La funci√≥n anteriormente llamada <a href="">bpf_get_current_pid_tgid ()</a> devuelve el hilo GID y PID del proceso en el mismo valor de 64 bits. <br><br>  No estamos interesados ‚Äã‚Äãen la identificaci√≥n de cada hilo, pero queremos saber el PID del hilo principal.  Despu√©s de verificar que la latencia est√° por encima del umbral, enviamos nuestra estructura de <b>datos</b> al espacio de usuario a trav√©s del mapa de <b>eventos</b> , luego eliminamos la entrada de hashmap al final. <br><br>  En nuestro script de Python, tenemos que reemplazar <b>MIN_US</b> y <b>FACTOR de</b> acuerdo con el umbral que queremos y la unidad de tiempo que queremos ver en nuestro resultado: <br><br><pre> <code class="python hljs">bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'MIN_US'</span></span>,str(min_usec)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> args.milliseconds: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">'data-&gt;lat /= 1000;'</span></span>) label = <span class="hljs-string"><span class="hljs-string">"msec"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) label = <span class="hljs-string"><span class="hljs-string">"usec"</span></span></code> </pre><br>  Luego tenemos que preparar el programa BPF con una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">macro BPF ()</a> y registrar sondas: <br><br><pre> <code class="python hljs">b = BPF(text=bpf_text) b.attach_kprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"start"</span></span>) b.attach_kretprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"stop"</span></span>)</code> </pre><br>  Tambi√©n necesitamos definir la misma estructura que <b>struct data_t</b> en nuestro script para leer los datos del programa BPF: <br><br><pre> <code class="python hljs">TASK_COMM_LEN = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-comment"><span class="hljs-comment"># linux/sched.h DISK_NAME_LEN = 32 # linux/genhd.h class Data(ct.Structure): _fields_ = [("pid", ct.c_ulonglong), ("ts", ct.c_ulonglong), ("comm", ct.c_char * TASK_COMM_LEN), ("lat", ct.c_ulonglong), ("disk",ct.c_char * DISK_NAME_LEN)]</span></span></code> </pre> <br>  El √∫ltimo paso es imprimir los datos que queremos: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_event</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cpu, data, size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> start event = ct.cast(data, ct.POINTER(Data)).contents <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> start == <span class="hljs-number"><span class="hljs-number">0</span></span>: start = event.ts time_s = (float(event.ts - start)) / <span class="hljs-number"><span class="hljs-number">1000000000</span></span> print(<span class="hljs-string"><span class="hljs-string">"%-18.9f %-16s %-6d %-1s %s %s"</span></span> % (time_s, event.comm, event.pid, event.lat, label, event.disk)) b[<span class="hljs-string"><span class="hljs-string">"events"</span></span>].open_perf_buffer(print_event) <span class="hljs-comment"><span class="hljs-comment"># format output start = 0 while 1: try: b.perf_buffer_poll() except KeyboardInterrupt: exit()</span></span></code> </pre><br>  El script completo est√° disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GitHub</a> .  Ejecutemos el script y activemos eventos udev mientras fio escribe en un dispositivo bcache: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tk/ly/vf/tklyvf6i8rws0xu4gy3jothbxbi.png"></div><br><br>  √âxito!  Ahora vemos que lo que parec√≠a una latencia alta para bcache es realmente <b>una</b> latencia <b>generica_make_request ()</b> para su dispositivo de respaldo. <br><br><h3>  Cavar en el n√∫cleo </h3><br>  ¬øQu√© se arrastra al enviar solicitudes?  Vemos que se produjo un pico de latencia incluso antes de que comenzara la contabilidad de solicitudes.  Esto podr√≠a verificarse f√°cilmente ejecutando iostat durante el problema o el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">script BCC de biolatencia</a> , que se basa en el inicio de la solicitud de contabilidad, por lo que ninguna herramienta mostrar√° el problema del disco. <br><br>  Si echamos un vistazo a <b>generic_make_request ()</b> , vemos que hay dos funciones ejecut√°ndose antes de que comience la contabilidad.  El primero es <b>generic_make_request_checks ()</b> , que es liviano y verifica bio seg√∫n la configuraci√≥n del dispositivo, etc.  El segundo es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">blk_queue_enter ()</a> , que tiene una llamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">wait_event_interruptible ()</a> : <br><br><pre> <code class="python hljs">ret = wait_event_interruptible(q-&gt;mq_freeze_wq, (atomic_read(&amp;q-&gt;mq_freeze_depth) == <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; (preempt || !blk_queue_preempt_only(q))) || blk_queue_dying(q));</code> </pre><br>  Aqu√≠ el n√∫cleo espera hasta que la cola se descongela.  Midamos la latencia de blk_queue_enter (): <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/funclatency blk_queue_enter -i 1 -m Tracing 1 functions for "blk_queue_enter"... Hit Ctrl-C to end. msecs : count distribution 0 -&gt; 1 : 341 |****************************************| msecs : count distribution 0 -&gt; 1 : 316 |****************************************| msecs : count distribution 0 -&gt; 1 : 255 |****************************************| 2 -&gt; 3 : 0 | | 4 -&gt; 7 : 0 | | 8 -&gt; 15 : 1 | |</span></span></code> </pre><br>  Parece que estamos cerca.  Las funciones utilizadas para congelar / descongelar la cola son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">blk_mq_freeze_queue</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">blk_mq_unfreeze_queue</a> .  Se usan para cambiar la configuraci√≥n de la cola, lo que podr√≠a afectar las solicitudes de io que se encuentran actualmente en vuelo.  Cuando se llama a <b>blk_mq_freeze_queue ()</b> , <b>q-&gt; mq_freeze_depth</b> se incrementa en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">blk_freeze_queue_start ()</a> .  Despu√©s de eso, el kernel espera a que la cola est√© vac√≠a en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">blk_mq_freeze_queue_wait ()</a> . <br><br>  Este tiempo de espera es igual a la latencia del disco, porque el n√∫cleo tiene que esperar a que finalicen todas las operaciones io.  Cuando la cola est√° vac√≠a, se pueden hacer cambios.  El √∫ltimo paso es llamar a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">blk_mq_unfreeze_queue ()</a> , lo que disminuye el contador <b>freeze_depth</b> . <br><br>  Ahora sabemos lo suficiente como para solucionar el problema.  El comando de disparo udevadm cambia la configuraci√≥n de los dispositivos de bloque.  Esos ajustes se describen en las reglas de udev.  Podemos averiguar qu√© configuraciones congelan la cola cambi√°ndolas a trav√©s de sysfs o mirando el c√≥digo fuente del kernel.  Alternativamente, podemos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">llamar a trace</a> desde el kit de herramientas BCC para imprimir el kernel y las pilas de usuarios para cada llamada <b>blk_freeze_queue</b> : <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/trace blk_freeze_queue -K -U PID TID COMM FUNC 3809642 3809642 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] elevator_switch+0x29 [kernel] elv_iosched_store+0x197 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown] 3809631 3809631 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] queue_requests_store+0xb6 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown]</span></span></code> </pre> <br>  Las reglas de Udev no cambian con frecuencia, por lo que incluso asignar valores ya existentes a ciertos par√°metros provoca un aumento en la latencia de env√≠o para la aplicaci√≥n.  Por supuesto, generar eventos udev cuando no hay cambios en la configuraci√≥n de un dispositivo (ning√∫n dispositivo est√° conectado o desconectado) no es una buena pr√°ctica.  A√∫n as√≠, podemos evitar que el n√∫cleo congele la cola si no hay raz√≥n para hacerlo.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tres</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">peque√±os</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">commits</a> solucionan el problema. <br><br><h2>  Conclusi√≥n </h2><br>  eBPF es un instrumento altamente flexible y potente.  En este art√≠culo, analizamos solo un caso y demostramos un poco de lo que es capaz de hacer.  Si est√° interesado en desarrollar herramientas basadas en BCC, deber√≠a echar un vistazo al <a href="">tutorial oficial</a> , que describe sus conceptos fundamentales. <br><br>  Tambi√©n hay otras herramientas interesantes basadas en eBPF disponibles para perfilar y depurar.  Uno de ellos es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bpftrace</a> , que le permite escribir en l√≠nea potentes y peque√±os programas en un lenguaje parecido al awk.  Otro es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ebpf_exporter</a> , que puede recopilar m√©tricas de baja resoluci√≥n y alta resoluci√≥n para su servidor prometheus con sus excelentes capacidades de visualizaci√≥n y alerta. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/450818/">https://habr.com/ru/post/450818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../450806/index.html">Cuando una variable de entorno acelera el proceso 40 veces</a></li>
<li><a href="../450810/index.html">Las 7 mejores formas de verificar r√°pidamente las competencias de los especialistas de TI antes de la entrevista</a></li>
<li><a href="../450812/index.html">PSR-14: el evento principal en PHP</a></li>
<li><a href="../450814/index.html">C√≥mo funciona BGP</a></li>
<li><a href="../450816/index.html">Encabezados HTTP para el desarrollador responsable</a></li>
<li><a href="../450820/index.html">Comit√© del programa FrontendConf: marcos, horizontes, experiencia mundial y misi√≥n de la conferencia.</a></li>
<li><a href="../450822/index.html">Marcos desaparecidos</a></li>
<li><a href="../450824/index.html">El estado de css</a></li>
<li><a href="../450826/index.html">C√≥mo hablar con el microcontrolador de JS</a></li>
<li><a href="../450828/index.html">Cuando la ciudad se duerme ...</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚¨õÔ∏è üë®üèº‚Äçüé§ üí™ Chat, Extrakt: Die Architektur komplexer Chatbots ‚ö†Ô∏è ‚è≥ üë©‚Äçüëß‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Benutzer, die mit intelligenten Sprachassistenten gesprochen haben, erwarten Informationen von Chat-Bots. Wenn Sie einen Bot f√ºr Unternehmen entwickel...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Chat, Extrakt: Die Architektur komplexer Chatbots</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429638/">  Benutzer, die mit intelligenten Sprachassistenten gesprochen haben, erwarten Informationen von Chat-Bots.  Wenn Sie einen Bot f√ºr Unternehmen entwickeln, sind die Erwartungen sogar noch h√∂her: Der Kunde m√∂chte, dass der Benutzer dem gew√ºnschten, vorgegebenen Szenario folgt, und der Benutzer m√∂chte, dass der Roboter die gestellten Fragen intelligent und vorzugsweise menschlich beantwortet, bei der L√∂sung von Problemen hilft und manchmal nur Smalltalk unterst√ºtzt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0-/pv/i1/0-pvi1riz8k3g804x9fke0sre6w.jpeg"></div><br>  Wir f√ºhren englischsprachige Chat-Bots durch, die √ºber verschiedene Kan√§le mit Benutzern kommunizieren - Facebook Messenger, SMS, Amazon Alexa und das Internet.  Unsere Bots ersetzen Support-Services, Versicherungsagenten und k√∂nnen einfach chatten.  Jede dieser Aufgaben erfordert einen eigenen Entwicklungsansatz. <br><br>  In diesem Artikel erfahren Sie, aus welchen Modulen unser Service besteht, wie die einzelnen Module hergestellt werden, welchen Ansatz wir gew√§hlt haben und warum.  Wir werden unsere Erfahrungen bei der Analyse verschiedener Tools teilen: Wenn generative neuronale Netze nicht die beste Wahl sind, warum verwenden wir anstelle von Doc2vec Word2vec, was ist der Reiz und das Entsetzen von ChatScript und so weiter? <br><br><a name="habracut"></a><br>  Auf den ersten Blick scheint es, dass die Probleme, die wir l√∂sen, eher trivial sind.  Auf dem Gebiet der Verarbeitung nat√ºrlicher Sprache gibt es jedoch eine Reihe von Schwierigkeiten, die sowohl mit der technischen Umsetzung als auch mit dem menschlichen Faktor verbunden sind. <br><ol><li>  Eine Milliarde Menschen sprechen Englisch, und jeder Muttersprachler verwendet es auf seine Weise: Es gibt verschiedene Dialekte und individuelle Sprachmerkmale. </li><li>  Viele W√∂rter, Phrasen und Ausdr√ºcke sind mehrdeutig: Ein typisches Beispiel ist in diesem Bild. </li><li>  Die korrekte Interpretation der Bedeutung von W√∂rtern erfordert Kontext.  Der Bot, der dem Kunden Fragen zur Kl√§rung stellt, sieht jedoch nicht so cool aus wie derjenige, der auf Anfrage des Benutzers zu einem beliebigen Thema wechseln und jede Frage beantworten kann. <br></li><li>  Oft vernachl√§ssigen Menschen in lebendiger Sprache und Korrespondenz entweder die Regeln der Grammatik oder antworten so kurz, dass es fast unm√∂glich ist, die Satzstruktur wiederherzustellen. </li><li>  Manchmal ist es zur Beantwortung der Frage eines Benutzers erforderlich, seine Anfrage mit den FAQ-Texten zu vergleichen.  Gleichzeitig m√ºssen Sie sicherstellen, dass der in den FAQ gefundene Text tats√§chlich die Antwort ist und nicht nur mehrere W√∂rter enth√§lt, die der Anfrage entsprechen. </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yz/zw/iy/yzzwiynir0jqsmzyjdcfrrrokoo.png"></div><br>  Dies sind nur einige der offensichtlichsten Aspekte, und es gibt Slang, Jargon, Humor, Sarkasmus, Rechtschreib- und Aussprachefehler, Abk√ºrzungen und andere Probleme, die es schwierig machen, in diesem Bereich zu arbeiten. <br><br>  Um diese Probleme zu l√∂sen, haben wir einen Bot entwickelt, der eine Reihe von Ans√§tzen verwendet.  Der KI-Teil unseres Systems besteht aus einem Dialogmanager, einem Erkennungsdienst und wichtigen komplexen Mikrodiensten, die bestimmte Probleme l√∂sen: Intent Classifier, FAQ-Dienst, Small Talk. <br><br><h3>  Starten Sie ein Gespr√§ch.  Dialogmanager </h3><br>  Die Aufgabe von Dialog Manager im Bot ist eine Softwaresimulation der Kommunikation mit einem Live-Agenten: Sie sollte den Benutzer durch ein Konversationsszenario zu einem n√ºtzlichen Ziel f√ºhren. <br>  Um dies zu tun, m√ºssen Sie zum einen herausfinden, was der Benutzer m√∂chte (z. B. die Versicherungskosten f√ºr Autos berechnen), und zum anderen die erforderlichen Informationen (Adresse und andere Benutzerdaten, Daten zu Fahrern und Autos) herausfinden.  Danach sollte der Dienst eine n√ºtzliche Antwort geben - f√ºllen Sie das Formular aus und geben Sie dem Kunden das Ergebnis dieser Daten.  Gleichzeitig sollten wir den Benutzer nicht fragen, was er bereits angegeben hat. <br><br>  Mit Dialog Manager k√∂nnen Sie ein solches Szenario erstellen: Beschreiben Sie es programmgesteuert, erstellen Sie es aus kleinen Bausteinen - spezifischen Problemen oder Aktionen, die an einem bestimmten Punkt auftreten sollten.  Tats√§chlich ist das Szenario ein gerichteter Graph, bei dem jeder Knoten eine Nachricht, eine Frage, eine Aktion ist und die Kante die Reihenfolge und die Bedingungen des √úbergangs zwischen diesen Knoten bestimmt, wenn es eine Mehrfachauswahl des √úbergangs von einem Knoten zu einem anderen gibt. <br>  Die Haupttypen von Knoten <br><ul><li>  Knoten, die warten, bis sie die Warteschlange erreichen und in den Nachrichten angezeigt werden. </li><li>  Knoten, die darauf warten, dass der Benutzer eine bestimmte Absicht zeigt (schreiben Sie beispielsweise: ‚ÄûIch m√∂chte eine Versicherung abschlie√üen‚Äú). </li><li>  Knoten, die darauf warten, dass Daten vom Benutzer validiert und gespeichert werden. </li><li>  Knoten zur Implementierung verschiedener algorithmischer Designs (Schleifen, Verzweigungen usw.). </li></ul><br>  Wenn der Knoten geschlossen ist, wird die Steuerung nicht mehr auf ihn √ºbertragen, und der Benutzer sieht die bereits gestellte Frage nicht.  Wenn wir also eine Tiefensuche in einem solchen Diagramm zum ersten offenen Knoten durchf√ºhren, erhalten wir eine Frage, die dem Benutzer zu einem bestimmten Zeitpunkt gestellt werden muss.  Bei der Beantwortung der vom Dialog-Manager generierten Fragen schlie√üt der Benutzer nach und nach alle Knoten im Diagramm, und es wird davon ausgegangen, dass er das vorgeschriebene Skript ausgef√ºhrt hat.  Anschlie√üend geben wir dem Benutzer beispielsweise eine Beschreibung der Versicherungsoptionen, die wir anbieten k√∂nnen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nt/sb/hp/ntsbhp9gpihkj2awmq8clkt6cl8.png"></div><br><h4>  "Ich habe schon alles gesagt!" </h4><br>  Angenommen, wir fragen den Benutzer nach einem Namen und in einer Nachricht gibt er auch sein Geburtsdatum, seinen Namen, sein Geschlecht, seinen Familienstand, seine Adresse oder ein Foto seines F√ºhrerscheins an.  Das System extrahiert alle relevanten Daten und schlie√üt die entsprechenden Knoten, dh es werden keine Fragen mehr zum Geburtsdatum und Geschlecht gestellt. <br><br><h4>  "√úbrigens ..." </h4><br>  Dialog Manager bietet auch die M√∂glichkeit, gleichzeitig zu mehreren Themen zu kommunizieren.  Ein Benutzer sagt beispielsweise: "Ich m√∂chte eine Versicherung abschlie√üen."  Ohne diesen Dialog zu beenden, f√ºgt er hinzu: ‚ÄûIch m√∂chte eine Zahlung f√ºr eine zuvor angeh√§ngte Police leisten.‚Äú  In solchen F√§llen speichert Dialog Manager den Kontext des ersten Themas und bietet nach Abschluss des zweiten Skripts an, den vorherigen Dialog an der Stelle fortzusetzen, an der er unterbrochen wurde. <br><br>  Es ist m√∂glich, zu Fragen zur√ºckzukehren, die der Benutzer bereits beantwortet hat.  Zu diesem Zweck speichert das System den Schnappschuss des Diagramms beim Empfang jeder Nachricht vom Client. <br><br><h4>  Welche M√∂glichkeiten gibt es? </h4><br>  Zus√§tzlich zu unserem haben wir einen anderen KI-Ansatz f√ºr die Implementierung des Dialogmanagers in Betracht gezogen: Die Absicht und die Parameter des Benutzers werden in die Eingabe des neuronalen Netzwerks eingespeist, und das System selbst generiert die entsprechenden Zust√§nde, die n√§chste Frage, die gestellt werden muss.  In der Praxis erfordert diese Methode jedoch die Hinzuf√ºgung eines regelbasierten Ansatzes.  Vielleicht eignet sich diese Implementierungsoption f√ºr triviale Szenarien - zum Beispiel f√ºr die Bestellung von Lebensmitteln, bei denen Sie nur drei Parameter ben√∂tigen: Was der Benutzer bestellen m√∂chte, wann er die Bestellung erhalten m√∂chte und wohin er sie bringen soll.  Bei komplexen Szenarien wie in unserem Fachgebiet ist dies jedoch immer noch nicht erreichbar.  Derzeit k√∂nnen maschinelle Lerntechnologien den Benutzer in einem komplexen Szenario nicht qualitativ zum Ziel f√ºhren. <br><br>  Dialog Manager ist in Python, Tornado Framework, geschrieben, da unser KI-Teil urspr√ºnglich als einzelner Dienst geschrieben wurde.  Es wurde eine Sprache gew√§hlt, in der all dies realisiert werden kann, ohne Ressourcen f√ºr die Kommunikation aufzuwenden. <br><br><h3>  "Lass uns entscheiden."  Anerkennungsdienst </h3><br>  Unser Produkt kann √ºber verschiedene Kan√§le kommunizieren, der KI-Teil ist jedoch vollst√§ndig kundenunabh√§ngig: Diese Kommunikation erfolgt nur in Form von Proxy-Text.  Der Dialogmanager √ºbertr√§gt den Kontext, die Benutzerantwort und die gesammelten Daten an den Erkennungsdienst, der daf√ºr verantwortlich ist, die Absicht des Benutzers zu erkennen und die erforderlichen Daten abzurufen. <br>  Heute besteht der Erkennungsdienst aus zwei logischen Teilen: dem Erkennungsmanager, der die Erkennungspipeline verwaltet, und Extraktoren. <br><br><h4>  Erkennungsmanager </h4><br>  Der Erkennungsmanager ist f√ºr alle grundlegenden Phasen des Erkennens der Bedeutung von Sprache verantwortlich: Tokenisierung, Lemmatisierung usw. Er bestimmt auch die Reihenfolge der Extraktoren (Objekte, die Entit√§ten und Attribute in Texten erkennen), nach denen eine Nachricht √ºbersprungen wird, und entscheidet, wann die Erkennung und R√ºckkehr beendet werden soll fertiges Ergebnis.  Auf diese Weise k√∂nnen Sie nur die erforderlichen Extraktoren in der am meisten erwarteten Reihenfolge ausf√ºhren. <br><br>  Wenn wir nach dem Namen des Benutzers gefragt haben, ist es logisch, zun√§chst zu √ºberpr√ºfen, ob der Name in der Antwort enthalten ist.  Der Name ist gekommen und es gibt keinen n√ºtzlichen Text mehr - was bedeutet, dass die Erkennung in diesem Schritt abgeschlossen werden kann.  Einige andere n√ºtzliche Einheiten sind hinzugekommen, was bedeutet, dass die Anerkennung fortgesetzt werden muss.  H√∂chstwahrscheinlich hat die Person einige andere personenbezogene Daten hinzugef√ºgt. Dementsprechend m√ºssen Sie den Extraktor f√ºr die Verarbeitung personenbezogener Daten ausf√ºhren. <br><br>  Je nach Kontext kann die Startreihenfolge der Extraktoren variieren.  Dieser Ansatz erm√∂glicht es uns, die Belastung des gesamten Dienstes erheblich zu reduzieren. <br><br><h4>  Extraktoren </h4><br>  Wie oben erw√§hnt, k√∂nnen Extraktoren bestimmte Entit√§ten und Attribute in Texten erkennen.  Beispielsweise erkennt ein Extraktor Telefonnummern.  ein anderer bestimmt, ob eine Person eine Frage positiv oder negativ beantwortet hat;  der dritte - erkennt und √ºberpr√ºft die Adresse in der Nachricht;  Das vierte sind Daten √ºber das Fahrzeug des Benutzers.  Weiterleiten einer Nachricht durch eine Reihe von Extraktoren - Dies ist der Prozess zum Erkennen unserer eingehenden Nachrichten. <br><br>  F√ºr den optimalen Betrieb eines komplexen Systems m√ºssen Ans√§tze kombiniert werden.  Bei der Arbeit an Extraktoren haben wir uns an dieses Prinzip gehalten.  Ich werde einige der Arbeitsprinzipien hervorheben, die wir in Extraktoren verwendet haben. <br><br>  Verwenden unserer Microservices mit maschinellem Lernen (Extraktoren senden eine Nachricht an diesen Service, erg√§nzen sie manchmal mit den vorhandenen Informationen und geben das Ergebnis zur√ºck). <br><br><ul><li>  Verwenden von POS-Tagging, syntaktischem Parsen, semantischem Parsen (z. B. Bestimmen der Absicht des Benutzers durch das Verb) </li><li>  Verwenden der Volltextsuche (kann verwendet werden, um Marke und Modell der Maschine in Nachrichten zu finden) </li><li>  Verwenden von regul√§ren Ausdr√ºcken und Antwortmustern </li><li>  Verwendung von APIs von Drittanbietern (z. B. Google Maps API, SmartyStreets usw.) </li><li>  Eine w√∂rtliche Suche nach S√§tzen (wenn eine Person kurz mit ‚ÄûJa‚Äú geantwortet hat, macht es keinen Sinn, sie durch ML-Algorithmen zu f√ºhren, um nach Absichten zu suchen) </li><li>  Wir verwenden auch vorgefertigte L√∂sungen zur Verarbeitung nat√ºrlicher Sprache in Extraktoren. </li></ul><br><h4>  Welche M√∂glichkeiten gibt es? </h4><br>  Wir haben uns die Bibliotheken NLTK, Stanford CoreNLP und SpaCy angesehen.  NLTK wird in Google SERPs zuerst gel√∂scht, wenn Sie eine NLP-√úberpr√ºfung starten.  Es ist sehr cool f√ºr Prototyping-L√∂sungen, hat umfangreiche Funktionen und ist recht einfach.  Aber seine Leistung ist schlecht. <br><br>  Stanford CoreNLP hat ein schwerwiegendes Minus: Es zieht eine virtuelle Java-Maschine mit sehr gro√üen Modulen, integrierten Bibliotheken und verbraucht viele Ressourcen.  Dar√ºber hinaus ist die Ausgabe dieser Bibliothek schwer anzupassen. <br><br>  Aus diesem Grund haben wir uns f√ºr SpaCy entschieden, da es √ºber gen√ºgend Funktionen verf√ºgt und das optimale Verh√§ltnis von Helligkeit und Geschwindigkeit aufweist.  Die SpaCy-Bibliothek l√§uft Dutzende Male schneller als NLTK und bietet viel bessere W√∂rterb√ºcher.  Es ist jedoch viel einfacher als Stanford CoreNLP. <br><br>  Im Moment verwenden wir spaCy f√ºr die Tokenisierung, Vektorisierung von Nachrichten (unter Verwendung des eingebauten trainierten neuronalen Netzwerks) und die prim√§re Erkennung von Parametern aus dem Text.  Da die Bibliothek nur 5% unseres Erkennungsbedarfs abdeckt, mussten wir viele Funktionen hinzuf√ºgen. <br><br><h4>  "Fr√ºher war es ..." </h4><br>  Der Anerkennungsdienst war nicht immer eine zweiteilige Struktur.  Die erste Version war die trivialste: Wir wechselten uns mit verschiedenen Extraktoren ab und versuchten zu verstehen, ob der Text Parameter oder Absichten enthielt.  Die KI roch dort nicht einmal - es war ein vollst√§ndig regelbasierter Ansatz.  Die Schwierigkeit bestand darin, dass dieselbe Absicht auf vielf√§ltige Weise zum Ausdruck gebracht werden kann, von denen jede in den Regeln beschrieben werden muss.  In diesem Fall muss der Kontext ber√ºcksichtigt werden, da dieselbe Benutzerphrase je nach gestellter Frage m√∂glicherweise unterschiedliche Aktionen erfordert.  Zum Beispiel aus dem Dialog: "Bist du verheiratet?"  - ‚ÄûBereits zwei Jahre‚Äú k√∂nnen Sie verstehen, dass der Benutzer verheiratet ist (boolesche Bedeutung).  Und aus dem Dialog "Wie lange fahren Sie dieses Auto?"  - "Bereits zwei Jahre" m√ºssen Sie den Wert "2 Jahre" extrahieren. <br><br>  Von Anfang an haben wir verstanden, dass die Unterst√ºtzung regelbasierter L√∂sungen viel Aufwand erfordern w√ºrde, und wenn die Anzahl der unterst√ºtzten Absichten zunimmt, wird die Anzahl der Regeln viel schneller zunehmen als bei einem ML-basierten System.  Allerdings aus gesch√§ftlicher Sicht.  Wir mussten MVP ausf√ºhren, ein regelbasierter Ansatz erm√∂glichte es uns, dies schnell zu tun.  Deshalb haben wir es benutzt und parallel am ML-Modell der Erkennung von Absichten gearbeitet.  Sobald es erschien und zufriedenstellende Ergebnisse lieferte, wandten sie sich allm√§hlich vom regelbasierten Ansatz ab. <br><br>  F√ºr die meisten F√§lle der Informationsextraktion haben wir ChatScript verwendet.  Diese Technologie bietet eine eigene deklarative Sprache, mit der Sie Vorlagen zum Extrahieren von Daten aus einer nat√ºrlichen Sprache schreiben k√∂nnen.  Dank WordNet ist diese L√∂sung unter der Haube sehr leistungsf√§hig (Sie k√∂nnen beispielsweise eine ‚ÄûFarbe‚Äú in der Erkennungsvorlage angeben, und WordNet erkennt jedes Verengungskonzept, z. B. ‚ÄûRot‚Äú).  Wir haben damals keine Analoga gesehen.  Aber ChatScript ist sehr schief und fehlerhaft geschrieben, mit seiner Verwendung ist es fast unm√∂glich, komplexe Logik zu implementieren. <br><br>  Am Ende wurden die Nachteile aufgewogen, und wir haben ChatScript zugunsten von NLP-Bibliotheken in Python aufgegeben. <br>  In der ersten Version von Recognition Service haben wir die Obergrenze f√ºr Flexibilit√§t erreicht.  Die Einf√ºhrung jeder neuen Funktion hat das gesamte System erheblich verlangsamt. <br><br>  Aus diesem Grund haben wir beschlossen, den Erkennungsdienst vollst√§ndig neu zu schreiben und ihn in zwei logische Teile zu unterteilen: kleine, leichte Extraktoren und den Erkennungsmanager, der den Prozess verwaltet. <br><br><h3>  "Was willst du?".  Intent Classifier </h3><br>  Damit der Bot angemessen kommunizieren kann - um die erforderlichen Informationen auf Anfrage bereitzustellen und die Daten des Benutzers aufzuzeichnen - ist es erforderlich, die Absicht (Absicht) des Benutzers anhand des an ihn gesendeten Textes zu bestimmen.  Die Liste der Absichten, mit denen wir mit Benutzern interagieren k√∂nnen, ist durch die Gesch√§ftsaufgaben des Kunden begrenzt: Es kann die Absicht sein, die Versicherungsbedingungen herauszufinden, Informationen √ºber sich selbst auszuf√ºllen, eine Antwort auf eine h√§ufig gestellte Frage zu erhalten usw. <br><br>  Es gibt viele Ans√§tze zur Klassifizierung von Absichten basierend auf neuronalen Netzen, insbesondere auf wiederkehrenden LSTM / GRU.  Sie haben sich in j√ºngsten Studien bew√§hrt, haben jedoch einen gemeinsamen Nachteil: F√ºr einen ordnungsgem√§√üen Betrieb ist eine sehr gro√üe Probe erforderlich.  Bei einer kleinen Datenmenge sind solche neuronalen Netze entweder schwer zu trainieren oder f√ºhren zu unbefriedigenden Ergebnissen.  Gleiches gilt f√ºr das Fast Text-Framework von Facebook (wir haben es √ºberpr√ºft, da es sich um eine hochmoderne L√∂sung f√ºr die Verarbeitung kurzer und mittlerer Phrasen handelt). <br><br>  Unsere Schulungsbeispiele sind von sehr hoher Qualit√§t: Die Datens√§tze bestehen aus einem Vollzeit-Team von Linguisten, die Englisch beherrschen und die Besonderheiten des Versicherungsbereichs kennen.  Unsere Stichproben sind jedoch relativ klein.  Wir haben versucht, sie mit √∂ffentlichen Datens√§tzen zu verd√ºnnen, aber diese stimmten mit seltenen Ausnahmen nicht mit unseren Angaben √ºberein.  Wir haben auch versucht, Freiberufler mit Amazon Mechanical Turk zu gewinnen, aber diese Methode erwies sich auch als nicht funktionsf√§hig: Die von ihnen gesendeten Daten waren teilweise von schlechter Qualit√§t, die Proben mussten doppelt √ºberpr√ºft werden. <br><br>  Daher suchten wir nach einer L√∂sung, die an einer kleinen Stichprobe funktioniert.  Die gute Qualit√§t der Datenverarbeitung wurde durch den Random Forest-Klassifikator demonstriert, der auf Daten trainiert wurde, die in die Vektoren unseres Bag-of-Word-Modells konvertiert wurden.  Mithilfe der Kreuzvalidierung haben wir die optimalen Parameter ausgew√§hlt.  Zu den Vorteilen unseres Modells z√§hlen Geschwindigkeit und Gr√∂√üe sowie die relativ einfache Bereitstellung und Umschulung. <br><br>  Bei der Arbeit am Intent Classifier wurde deutlich, dass seine Verwendung f√ºr einige Aufgaben nicht optimal ist.  Angenommen, ein Benutzer m√∂chte den in der Versicherung angegebenen Namen oder die Fahrzeugnummer √§ndern.  Damit der Klassifizierer diese Absicht korrekt bestimmen kann, m√ºssten alle in diesem Fall verwendeten Vorlagenphrasen manuell zum Datensatz hinzugef√ºgt werden.  Wir haben einen anderen Weg gefunden: einen kleinen Extraktor f√ºr den Erkennungsdienst zu erstellen, der die Absicht anhand von Schl√ºsselw√∂rtern und NLP-Methoden bestimmt, und Intent Classifier f√ºr nicht standardm√§√üige Phrasen zu verwenden, bei denen die Methode mit Schl√ºsselw√∂rtern nicht funktioniert. <br><br><h3>  "Sie fragen immer danach."  FAQ </h3><br>  Viele unserer Kunden haben FAQ-Bereiche.  Damit der Benutzer solche Antworten direkt vom Chatbot erhalten konnte, musste eine L√∂sung bereitgestellt werden, die a) die FAQ-Anfrage erkennt;  b) w√ºrde die relevanteste Antwort in unserer Datenbank finden und herausgeben. <br><br>  Es gibt eine Reihe von Modellen, die auf dem Stanford SQUAD-Datensatz trainiert wurden.  Sie funktionieren gut, wenn der Antworttext aus den FAQ die W√∂rter aus der Frage des Benutzers enth√§lt.  Nehmen wir an, die FAQ sagt: "Frodo sagte, er w√ºrde den Ring nach Mordor bringen, obwohl er den Weg dorthin nicht kannte."  Wenn der Benutzer fragt: "Wohin wird Frodo den Ring bringen?", Antwortet das System: "An Mordor." <br><br>  Unser Szenario war in der Regel anders.  Zum Beispiel f√ºr zwei √§hnliche Anfragen: "Kann ich bezahlen?"  und "Kann ich online bezahlen?"  Der Bot muss anders reagieren: Bieten Sie im ersten Fall einer Person eine Zahlungsmethode an, im zweiten Fall - ja, Sie k√∂nnen online bezahlen, hier ist die Adresse der Seite. <br><br>  Eine weitere Klasse von L√∂sungen zur Beurteilung der √Ñhnlichkeit von Dokumenten konzentriert sich auf lange Antworten - zumindest einige S√§tze, darunter Informationen, die f√ºr den Benutzer von Interesse sind.  Leider funktionieren F√§lle mit kurzen Fragen und Antworten (‚ÄûWie bezahle ich online?‚Äú - ‚ÄûSie k√∂nnen mit PayPal bezahlen‚Äú) sehr instabil. <br><br>  Eine andere L√∂sung ist der Doc2vec-Ansatz: Der gro√üe Text wird zu einer Vektordarstellung destilliert, die dann mit anderen Dokumenten in derselben Form verglichen wird und der √Ñhnlichkeitskoeffizient ermittelt wird.  Dieser Ansatz musste ebenfalls gestrichen werden: Er konzentriert sich auf lange Texte, aber wir besch√§ftigen uns haupts√§chlich mit Fragen und Antworten aus einem oder zwei S√§tzen. <br><br>  Unsere Entscheidung basierte auf zwei Schritten.  Erstens: Mithilfe von Einbettungen haben wir jedes Wort in einem Satz mithilfe des Google Word2vec-Modells in Vektoren √ºbersetzt.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Danach haben wir den Durchschnittsvektor f√ºr alle W√∂rter betrachtet, der einen Satz in Form eines Vektors darstellt. </font><font style="vertical-align: inherit;">Im zweiten Schritt nahmen wir den Vektor der Frage und fanden in der FAQ-Datenbank, gespeichert in derselben Vektorform, die bis zu einem gewissen Grad n√§chstgelegene Antwort, in unserem Fall den Kosinus. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zu den Vorteilen geh√∂ren eine einfache Implementierung, eine sehr einfache Erweiterbarkeit und eine relativ einfache Interpretierbarkeit. </font><font style="vertical-align: inherit;">Die Nachteile sind eine schwache Optimierungsm√∂glichkeit: Dieses Modell ist schwer zu √§ndern - es funktioniert entweder in den meisten Benutzerf√§llen gut oder Sie m√ºssen es aufgeben.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Und reden?" </font><font style="vertical-align: inherit;">Smalltalk</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Manchmal schreibt der Benutzer etwas v√∂llig irrelevantes, zum Beispiel: "Das Wetter ist heute gut." Dies ist nicht in der Liste der Absichten enthalten, die uns interessieren, aber wir m√∂chten dennoch sinnvoll antworten und die Intelligenz unseres Systems demonstrieren. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F√ºr solche Entscheidungen wird eine Kombination der oben beschriebenen Ans√§tze verwendet: Sie basieren entweder auf sehr einfachen regelbasierten L√∂sungen oder auf generativen neuronalen Netzen. Wir wollten fr√ºhzeitig einen Prototyp bekommen, deshalb haben wir einen √∂ffentlichen Datensatz aus dem Internet genommen und einen Ansatz verwendet, der dem f√ºr die FAQ verwendeten sehr √§hnlich ist. Zum Beispiel hat ein Benutzer etwas √ºber das Wetter geschrieben - und mithilfe eines Algorithmus, der Vektordarstellungen von zwei S√§tzen mit einem bestimmten Kosinusma√ü vergleicht, suchen wir im √∂ffentlichen Datensatz nach einem Satz, der dem Wetterthema so nahe wie m√∂glich kommt.</font></font><br><br><h3>  Schulung </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetzt haben wir nicht das Ziel, einen Bot zu erstellen, der f√ºr jede von Kunden empfangene Nachricht geschult wird: Erstens ist dies, wie die Erfahrung zeigt, der Weg zum Tod des Bots (denken Sie daran, wie IBM Watson </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die Basis l√∂schen musste,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> weil die Diagnose mit einer Matte begann und Microsofts Twitter-Bot hat es </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">geschafft,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> innerhalb eines Tages </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">zum Rassisten zu werden</font></a><font style="vertical-align: inherit;"> . Zweitens bem√ºhen wir uns, die Aufgaben der Versicherungsunternehmen so qualitativ wie m√∂glich zu schlie√üen. Ein selbstlernender Bot ist nicht unsere Gesch√§ftsaufgabe. Wir haben eine Reihe von Tools f√ºr Linguisten und QS-Befehle geschrieben, mit denen sie Bots manuell neu trainieren k√∂nnen, indem sie Dialoge und Korrespondenz mit Benutzern w√§hrend der Nachmoderation untersuchen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trotzdem scheint unser Bot bereits bereit zu sein, den Turing-Test zu bestehen. </font><font style="vertical-align: inherit;">Einige Benutzer beginnen ein ernstes Gespr√§ch mit ihm und glauben, dass sie mit einem Versicherungsagenten sprechen, und einer drohte sogar dem Chef mit einer Beschwerde, als der Bot ihn missverstand.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pl√§ne </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetzt arbeiten wir am visuellen Teil: Anzeigen des gesamten Diagramms des Skripts und der M√∂glichkeit, es √ºber die GUI zu erstellen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auf der Seite des Erkennungsdienstes f√ºhren wir eine sprachliche Analyse ein, um die Bedeutung jedes Wortes in der Nachricht zu erkennen und zu verstehen. </font><font style="vertical-align: inherit;">Dies verbessert die Genauigkeit der Reaktion und extrahiert zus√§tzliche Daten. </font><font style="vertical-align: inherit;">Wenn eine Person beispielsweise eine Autoversicherung ausf√ºllt und angibt, dass sie ein nicht versichertes Haus hat, kann sich der Bot diese Nachricht merken und an den Betreiber weiterleiten, um den Kunden zu kontaktieren und eine Hausversicherung anzubieten.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein weiteres Merkmal der Arbeit ist die R√ºckkopplungsverarbeitung. Nach Abschluss des Dialogs mit dem Bot fragen wir den Benutzer, ob ihm der Service gefallen hat. Wenn die Stimmungsanalyse die Bewertung des Benutzers als positiv erkannt hat, laden wir den Benutzer ein, seine Meinung in sozialen Netzwerken mitzuteilen. Wenn die Analyse zeigt, dass der Benutzer negativ reagiert hat, kl√§rt der Bot, was falsch war, korrigiert die Antwort, sagt: "OK, wir beheben das Problem" und bietet nicht an, die Bewertung im Stream zu teilen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Einer der Schl√ºssel, um die Kommunikation mit dem Bot so nat√ºrlich wie m√∂glich zu gestalten, besteht darin, den Bot modular zu gestalten und das Spektrum der ihm zur Verf√ºgung stehenden Reaktionen zu erweitern. Wir arbeiten daran. Vielleicht war der Benutzer deshalb bereit, unseren Bot aufrichtig f√ºr einen Versicherungsagenten zu nehmen. Der n√§chste Schritt: Stellen Sie sicher, dass die Person versucht, dem Bot zu danken.</font></font><br><br><hr><br> <i>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> .     ,      .</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429638/">https://habr.com/ru/post/de429638/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429628/index.html">So erstellen Sie einen Chat-Bot f√ºr VKontakte mit Python, Django und Webhook</a></li>
<li><a href="../de429630/index.html">"Monster in Spielen oder Angst vielf√§ltig machen"</a></li>
<li><a href="../de429632/index.html">Gr√ºnde f√ºr die Ablehnung von Hostern beim Hinzuf√ºgen zu Verzeichnissen</a></li>
<li><a href="../de429634/index.html">So funktioniert die Suche nach Krediten im Anti-Plagiat</a></li>
<li><a href="../de429636/index.html">Installieren Sie 3CX PBX in Amazon Lightsail Cloud</a></li>
<li><a href="../de429640/index.html">Entfernen wir die Quaternionen aus allen 3D-Engines</a></li>
<li><a href="../de429642/index.html">Sicherheitswoche 46: Lassen Sie uns etwas aktualisieren</a></li>
<li><a href="../de429644/index.html">Dimmbarer Spot GX53 mit einstellbarem Beleuchtungswinkel</a></li>
<li><a href="../de429648/index.html">DNS √ºber TLS und √ºber HTTPS jetzt unter iOS / Android und allen Netzwerken gleichzeitig [Danke Cloudflare]</a></li>
<li><a href="../de429652/index.html">Offenes Webinar "Rekrutierung in der IT: von der Bewerbung bis zum Angebot"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
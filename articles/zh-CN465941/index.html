<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏼‍🔬 🚚 👨🏿‍🔬 多语言语音合成与克隆 🐒 👐🏽 🎅🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="尽管神经网络不久前就开始用于语音合成（ 例如 ），但是它们已经成功地超越了传统方法，并且每年他们都会遇到越来越多的任务。 


 例如，几个月前，通过语音克隆Real-Time-Voice-Cloning实现了语音合成。 让我们尝试弄清它的组成，并实现我们的多语言（俄语-英语）音素模型。 
 建筑 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>多语言语音合成与克隆</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/465941/"><p> 尽管神经网络不久前就开始用于语音合成（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">例如</a> ），但是它们已经成功地超越了传统方法，并且每年他们都会遇到越来越多的任务。 </p><br><p> 例如，几个月前，通过语音克隆<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Real-Time-Voice-Cloning</a>实现了语音合成。 让我们尝试弄清它的组成，并实现我们的多语言（俄语-英语）音素模型。 </p><br><h2 id="stroenie"> 建筑 </h2><br><p><img src="https://habrastorage.org/webt/4b/k7/e_/4bk7e_qeb-qw-clbaxsqs14f7cg.png"></p><br><p> 我们的模型将包含四个神经网络。 第一个将文本转换为音素（g2p），第二个将我们要克隆的语音转换为符号矢量（数字）。 第三个将基于前两个的输出来合成梅尔频谱图。 最后，第四个将接收来自频谱图的声音。 </p><a name="habracut"></a><br><h2 id="nabory-dannyh"> 数据集 </h2><br><p> 该模型需要大量演讲。 以下是有助于此目的的基础。 </p><br><div class="scrollable-table"><table><thead><tr><th> 名 </th><th> 语言能力 </th><th> 友情链接 </th><th> 留言 </th><th> 我的链接 </th><th> 留言 </th></tr></thead><tbody><tr><td> 音素词典 </td><td> 恩茹 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">恩</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">茹</a> </td><td></td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td> 俄语和英语组合音素词典 </td></tr><tr><td> 利比佩佩奇 </td><td> 恩 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td>  300票，360个小时的纯净演讲 </td><td></td><td></td></tr><tr><td>  VoxCeleb </td><td> 恩 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td>  7000票，许多小时的声音不佳 </td><td></td><td></td></tr><tr><td> 人工智能实验室 </td><td> 茹 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td>  3票，纯正演讲46个小时 </td><td></td><td></td></tr><tr><td>  open_tts，open_stt </td><td> 茹 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">open_tts</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">open_stt</a> </td><td> 许多声音，许多小时的不良声音 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td> 我清理了一位发言人的4个小时的讲话。 更正的注释，最多可细分为7秒 </td></tr><tr><td>  Voxforge +有声读物 </td><td> 茹 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td> 很多票，质量不同25小时 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td> 选择好的文件。 分成几个部分。 从Internet添加了有声读物。 几分钟后，结果每个扬声器有200个扬声器 </td></tr><tr><td> 俄罗斯 </td><td> 茹 </td><td>  <a href="">连结</a> </td><td> 一种声音，40个小时的纯语音 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td> 以16kHz重新编码 </td></tr><tr><td>  Mozilla </td><td> 茹 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td>  50票，正常30小时 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td> 以16kHz重新编码，将不同的用户分散到文件夹中 </td></tr><tr><td> 俄罗斯单曲 </td><td> 茹 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td> 一个声音，9个小时的纯语音 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">连结</a> </td><td></td></tr></tbody></table></div><br><h2 id="obrabotka-teksta"> 文字处理 </h2><br><p> 第一个任务是文本处理。 想象一下将以进一步表达形式的文本。 我们将用数字表示数字，并打开缩写。 在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">有关综合</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">文章中</a>阅读更多<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">内容</a> 。 这是一项艰巨的任务，因此假设我们已经处理了文本（已在上面的数据库中处理过）。 </p><br><p> 下一个要问的问题是使用字形还是音素记录。 对于单音和单语语音，字母模型也适用。 如果您想使用多语音多语言模型，那么我建议您使用转录（也是Google）。 </p><br><h3 id="g2p">  G2p </h3><br><p> 对于俄语，有一个称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Russian_g2p</a>的实现。 它建立在俄语规则之上，可以很好地处理任务，但是有缺点。 并非所有单词都强调，也不适合多语言模型。 因此，以为她创建的字典为基础，添加<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">英语字典</a>并为神经网络提供数据（例如<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">1，2</a> ） </p><br><p> 在训练网络之前，值得考虑一下来自不同语言的声音听起来是否相似，并且可以为它们选择一个字符，而这是不可能的。 声音越多，模型学习起来就越困难，如果声音太少，则模型会带有重音。 记住要用强调的元音强调单个字符。 对于英语来说，次要压力起着很小的作用，我无法区分。 </p><br><h2 id="kodirovanie-spikerov"> 扬声器编码 </h2><br><p> 该网络类似于通过语音识别用户的任务。 在输出处，不同的用户获得带有数字的不同向量。 我建议使用基于<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">本文</a>的CorentinJ本身的实现。 该模型是具有768个节点的三层LSTM，然后是256个神经元的完全连接层，给出了256个数字的向量。 </p><br><p> 经验表明，受过英语培训的网络可以说俄语。 由于培训需要大量数据，因此这大大简化了生活。 我建议您采用已经受过训练的模型，并从VoxCeleb和LibriSpeech用英语进行再培训，以及发现的所有俄语演讲。 编码器不需要语音片段的文本注释。 </p><br><h3 id="trenirovka"> 培训课程 </h3><br><ol><li>运行<code>python encoder_preprocess.py &lt;datasets_root&gt;</code>以处理数据 </li><li> 在单独的终端中运行“ visdom”。 </li><li> 运行<code>python encoder_train.py my_run &lt;datasets_root&gt;</code>来训练编码器 </li></ol><br><h2 id="sintez"> 综合性 </h2><br><p> 让我们继续进行综合。 我知道的模型不能直接从文本中获得声音，因为它很困难（数据太多）。 首先，文本产生频谱形式的声音，然后，第四个网络将转换为熟悉的声音。 因此，我们首先了解频谱形式如何与语音相关联。 更容易找出如何从声音中获取频谱图的反问题。 </p><br><p> 声音被分为25 ms的段，以10 ms为增量（大多数型号中的默认设置）。 然后，使用每个片段的傅立叶变换，计算频谱（谐波振荡，其总和给出原始信号）并以图形形式显示，其中垂直条带是一个段的频谱（在频率上），水平条带是一段的频谱（在时间上）。 该图称为频谱图。 如果频率是非线性编码的（较低的频率比较高的频率更好），则垂直标度将发生变化（需要减少数据），因此此图称为梅尔频谱图。 这就是人类听力的工作方式，我们在低频处的听觉会比高频处的听觉更好，因此不会受到音质的影响 </p><br><p><img src="https://habrastorage.org/webt/dx/mv/fs/dxmvfst1objf8dmdglu7rlbhaiq.jpeg"></p><br><p> 有几种好的频谱图合成实现，例如<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Tacotron 2</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Deepvoice 3</a> 。 这些模型中的每一个都有其自己的实现，例如<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">1、2、3、4</a> 。 我们将使用（如CorentinJ）Rayhane-mamah的Tacotron模型。 </p><br><p><img src="https://habrastorage.org/webt/u9/jm/h0/u9jmh0ldgpelp8qoouinbx9ptfi.png"></p><br><p>  Tacotron基于带有注意机制的seq2seq网络。 阅读<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">文章中</a>的详细信息。 </p><br><h3 id="trenirovka-1"> 培训课程 </h3><br><p> 如果您不仅合成英语语音hparams.p，还合成preprocess.py，请不要忘记编辑utils / symbols.py。 </p><br><p> 合成需要来自不同扬声器的大量清晰，标记清晰的声音。 在这里，外语是没有帮助的。 </p><br><ol><li> 运行<code>python synthesizer_preprocess_audio.py &lt;datasets_root&gt;</code>创建已处理的声音和声谱图 </li><li> 运行<code>python synthesizer_preprocess_embeds.py &lt;datasets_root&gt;</code>对声音进行编码（获取声音符号） </li><li> 运行<code>python synthesizer_train.py my_run &lt;datasets_root&gt;</code>来训练合成器 </li></ol><br><h2 id="vokoder"> 声码器 </h2><br><p> 现在只剩下将频谱图转换为声音了。 为此，最后一个网络是声码器。 问题是，如果使用傅立叶变换从声音中获得频谱图，是否可以使用逆变换再次获得声音？ 答案是肯定的。 组成原始信号的谐波振荡既包含振幅也包含相位，并且我们的频谱图仅包含有关振幅的信息（为了减少参数并使用频谱图），因此，如果执行傅立叶逆变换，则会得到不良声音。 </p><br><p> 为了解决这个问题，他们发明了一种快速的Griffin-Lim算法。 他对频谱图进行了傅立叶逆变换，得到了一种“不好的”声音。 然后，他直接对该声音进行转换，并接收一个已经包含有关相位的少量信息的频谱，并且振幅在此过程中不会改变。 接下来，再次进行逆变换并获得更清晰的声音。 不幸的是，由这种算法产生的语音质量尚待提高。 </p><br><p> 它被<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">WaveNet</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">WaveRNN</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">WaveGlow</a>等神经<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">语音</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">编码</a>器所取代。  CorentinJ使用了Fatchord的WaveRNN模型 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2fe/b25/464/2feb25464260ad8a96c983bb85340fee.gif" alt="图片"></p><br><p> 对于数据预处理，使用两种方法。 要么从声音中获取频谱图（使用傅立叶变换），要么从文本中获取频谱图（使用合成模型）。  Google建议使用第二种方法。 </p><br><h3 id="trenirovka-2"> 培训课程 </h3><br><ol><li> 运行<code>python vocoder_preprocess.py &lt;datasets_root&gt;</code>合成频谱图 </li><li> 运行<code>python vocoder_train.py &lt;datasets_root&gt;</code>进行声码器 </li></ol><br><h2 id="itogo"> 合计 </h2><br><p> 我们获得了可以克隆语音的多语言语音合成模型。 <br> 运行工具箱： <code>python demo_toolbox.py -d &lt;datasets_root&gt;</code> <br> 例子可以在这里听到 </p><br><div class="oembed">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://soundcloud.com/fn5va3vghrkh/sets/multi-tacotron</a> </div><br><h4 id="sovety-i-vyvody"> 提示和结论 </h4><br><ul><li> 需要大量数据（&gt; 1000票，&gt; 1000小时） </li><li> 仅在合成至少4个句子时，运算速度才与实时相当 </li><li> 对于编码器，请使用英语的预训练模型，并稍加重新训练。 她过得很好 </li><li> 接受过“干净”数据训练的合成器效果更好，但比接受大量但脏数据训练的合成器效果更差 </li><li> 该模型仅对我研究过的数据有效 </li></ul><br><p> 您可以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">使用colab在线</a>合成语音，或者在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">github</a>上查看我的实现并下载我的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">权重</a> 。 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN465941/">https://habr.com/ru/post/zh-CN465941/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN465923/index.html">3个错误可能会使您的启动生涯丧命</a></li>
<li><a href="../zh-CN465927/index.html">伯爵计分（Scoring de la Fer）或一项信用评分研究是拓宽视野的一部分。 第三部分</a></li>
<li><a href="../zh-CN465929/index.html">基础架构A / B实验中的大搜索。 Yandex报告</a></li>
<li><a href="../zh-CN465935/index.html">专业视频会议前所未有。 思维服务器-新版本，新价格</a></li>
<li><a href="../zh-CN465937/index.html">Technostream：学年开始时精选的培训视频</a></li>
<li><a href="../zh-CN465943/index.html">独角兽创业公司Bolt将为开发者举办冠军赛，奖金为35万卢布，并有可能迁居欧洲</a></li>
<li><a href="../zh-CN465945/index.html">关于安装和使用LineageOS 16，F-Droid</a></li>
<li><a href="../zh-CN465947/index.html">培训Cisco 200-125 CCNA v3.0。 第30天。思科网络架构和故障排除</a></li>
<li><a href="../zh-CN465949/index.html">Android操作系统上的电子书应用程序。 第5部分。云存储和播放器</a></li>
<li><a href="../zh-CN465951/index.html">我们都需要服务台</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
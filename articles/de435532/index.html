<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚ÄçüöÄ üîá üò≤ Tornado vs Aiohttp: Eine Reise in die Wildnis asynchroner Frameworks üçß üôà üê∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo! Ich bin Dima und sitze seit einiger Zeit in Python. Heute m√∂chte ich Ihnen die Unterschiede zwischen zwei asynchronen Frameworks zeigen - Torna...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tornado vs Aiohttp: Eine Reise in die Wildnis asynchroner Frameworks</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/435532/">  Hallo!  Ich bin Dima und sitze seit einiger Zeit in Python.  Heute m√∂chte ich Ihnen die Unterschiede zwischen zwei asynchronen Frameworks zeigen - Tornado und Aiohttp.  Ich werde die Geschichte der Wahl zwischen den Frameworks in unserem Projekt erz√§hlen, wie sich die Coroutinen in Tornado und AsyncIO unterscheiden. Ich werde Benchmarks zeigen und einige n√ºtzliche Tipps geben, wie Sie in die Wildnis von Frameworks gelangen und dort erfolgreich rauskommen k√∂nnen. <br><br><img src="https://habrastorage.org/webt/df/uz/jm/dfuzjmbmzyoqjfd87asllltamtk.png"><br><a name="habracut"></a><br>  Wie Sie wissen, ist Avito ein ziemlich gro√üer Werbedienst.  Wir haben viele Daten und laden, jeden Monat 35 Millionen Nutzer und t√§glich 45 Millionen aktive Anzeigen.  Ich arbeite als technischer Berater einer Empfehlungsentwicklungsgruppe.  Mein Team schreibt Microservices, jetzt haben wir ungef√§hr zwanzig davon.  Auf all dem stapelt sich eine Last - wie 5k RPS. <br><br><h2>  Ausw√§hlen eines asynchronen Frameworks </h2><br>  Zuerst erz√§hle ich Ihnen, wie wir dort gelandet sind, wo wir jetzt sind.  2015 mussten wir ein asynchrones Framework ausw√§hlen, weil wir wussten: <br><br><ul><li>  dass Sie viele Anfragen an andere Microservices stellen m√ºssen: http, json, rpc; </li><li>  dass Sie st√§ndig Daten aus verschiedenen Quellen sammeln m√ºssen: Redis, Postgres, MongoDB. </li></ul><br>  Daher haben wir viele Netzwerkaufgaben, und die Anwendung ist haupts√§chlich mit Eingabe / Ausgabe besch√§ftigt.  Die aktuelle Version von Python war zu diesem Zeitpunkt 3.4, asynchron und warten wurde noch nicht angezeigt.  Aiohttp war auch - in Version 0.x.  Der asynchrone Tornado von Facebook erschien 2010.  Viele Datenbanktreiber sind f√ºr ihn geschrieben, die wir brauchen.  Tornado zeigte stabile Ergebnisse bei Benchmarks.  Dann haben wir unsere Wahl in diesem Rahmen gestoppt. <br><br>  Drei Jahre sp√§ter haben wir viel verstanden. <br><br>  Zun√§chst kam Python 3.5 mit Async / Wait-Mechanik heraus.  Wir haben herausgefunden, was der Unterschied zwischen Ertrag und Ertrag ist und wie Tornado mit Warten √ºbereinstimmt (Spoiler: nicht sehr gut). <br>  Zweitens stie√üen wir auf seltsame Leistungsprobleme mit einer gro√üen Menge an Coroutine im Scheduler, selbst wenn die CPU nicht voll belegt ist. <br>  Drittens haben wir festgestellt, dass Sie beim Ausf√ºhren einer gro√üen Anzahl von http-Anforderungen an andere Tornado-Dienste besonders mit dem asynchronen DNS-Resolver vertraut sein m√ºssen. Er ber√ºcksichtigt nicht die Zeit√ºberschreitungen f√ºr den Verbindungsaufbau und das Senden der von uns angegebenen Anforderung.  Und im Allgemeinen ist Curl die beste Methode, um http-Anfragen in Tornado zu stellen, was an sich schon seltsam ist. <br><br>  In seinem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vortrag auf der PyCon Russia 2018</a> sagte Andrei Svetlov: ‚ÄûWenn Sie eine asynchrone Webanwendung schreiben m√∂chten, schreiben Sie einfach asynchron und warten Sie.  Event-Schleife, wahrscheinlich werden Sie sie bald gar nicht mehr brauchen.  Gehen Sie nicht in die Wildnis von Frameworks, um nicht verwirrt zu werden.  Verwenden Sie keine einfachen Grundelemente, und alles wird gut mit Ihnen ... ".  In den letzten drei Jahren mussten wir leider ziemlich oft ins Innere des Tornado klettern, von dort aus viele interessante Dinge lernen und gigantische Traysbacks f√ºr 30-40 Anrufe sehen. <br><br><h2>  Ertrag gegen Ertrag von </h2><br>  Eines der gr√∂√üten Probleme, die bei asynchronem Python zu verstehen sind, ist der Unterschied zwischen Ertrag von und Ertrag. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Guido Van Rossum hat</a> mehr dar√ºber geschrieben.  Ich lege der √úbersetzung leichte Abk√ºrzungen bei. <br><blockquote>  Ich wurde mehrmals gefragt, warum PEP 3156 darauf besteht, Yield-from anstelle von Yield zu verwenden, was die M√∂glichkeit eines Backportings in Python 3.2 oder sogar 2.7 ausschlie√üt. <br>  (...) <br>  Wann immer Sie ein zuk√ºnftiges Ergebnis w√ºnschen, verwenden Sie Yield. <br>  Dies wird wie folgt implementiert.  Die Funktion, die Yield enth√§lt, ist (offensichtlich) ein Generator, daher muss es eine Art iterativen Code geben.  Nennen wir ihn einen Planer.  Tats√§chlich "iteriert" der Scheduler nicht im klassischen Sinne (mit for-Schleife);  Stattdessen werden zwei zuk√ºnftige Sammlungen unterst√ºtzt. <br><br>  Ich werde die erste Sammlung eine "ausf√ºhrbare" Sequenz nennen.  Dies ist die Zukunft, deren Ergebnisse vorliegen.  W√§hrend diese Liste nicht leer ist, w√§hlt der Scheduler ein Element aus und f√ºhrt einen Iterationsschritt aus.  Dieser Schritt ruft die Generatormethode .send () mit dem Ergebnis aus der Zukunft auf (dies k√∂nnen Daten sein, die gerade aus dem Socket gelesen wurden).  Im Generator wird dieses Ergebnis als R√ºckgabewert des Ertragsausdrucks angezeigt.  Wenn send () ein Ergebnis zur√ºckgibt oder abgeschlossen ist, analysiert der Scheduler das Ergebnis (dies kann StopIteration, eine andere Ausnahme oder eine Art Objekt sein). <br>  (Wenn Sie verwirrt sind, sollten Sie wahrscheinlich lesen, wie Generatoren funktionieren, insbesondere die .send () -Methode. Vielleicht ist PEP 342 ein guter Ausgangspunkt.) <br><br>  (...) <br><br>  Die zweite vom Scheduler unterst√ºtzte zuk√ºnftige Sammlung besteht aus der Zukunft, die noch auf I / O wartet.  Sie werden irgendwie an select / poll / shell usw. √ºbergeben.  Dies gibt einen R√ºckruf aus, wenn der Dateideskriptor f√ºr E / A bereit ist.  Der R√ºckruf f√ºhrt tats√§chlich die von der Zukunft angeforderte E / A-Operation aus, setzt den resultierenden zuk√ºnftigen Wert auf das Ergebnis der E / A-Operation und verschiebt die Zukunft in die Ausf√ºhrungswarteschlange. <br><br>  (...) <br><br>  Jetzt haben wir das interessanteste erreicht.  Angenommen, Sie schreiben ein komplexes Protokoll.  In Ihrem Protokoll lesen Sie Bytes von einem Socket mit der Methode recv ().  Diese Bytes gelangen in den Puffer.  Die recv () -Methode ist in eine asynchrone Shell eingebunden, die die E / A festlegt und die Zukunft zur√ºckgibt, die ausgef√ºhrt wird, wenn die E / A abgeschlossen ist, wie oben erl√§utert.  Angenommen, ein anderer Teil Ihres Codes m√∂chte zeilenweise Daten aus dem Puffer lesen.  Angenommen, Sie haben die Methode readline () verwendet.  Wenn die Puffergr√∂√üe gr√∂√üer als die durchschnittliche Zeilenl√§nge ist, kann Ihre readline () -Methode einfach die n√§chste Zeile aus dem Puffer abrufen, ohne sie zu blockieren.  Manchmal enth√§lt der Puffer jedoch keine ganze Zeile, und readline () ruft wiederum recv () f√ºr den Socket auf. <br><br>  Frage: Sollte readline () zuk√ºnftig zur√ºckkehren oder nicht?  Es w√§re nicht sehr gut, wenn er manchmal eine Byte-Zeichenfolge und manchmal die Zukunft zur√ºckgeben w√ºrde, um den Aufrufer zu zwingen, eine Typpr√ºfung und eine bedingte Ausbeute durchzuf√ºhren.  Die Antwort lautet also, dass readline () immer die Zukunft zur√ºckgeben sollte.  Wenn readline () aufgerufen wird, √ºberpr√ºft es den Puffer. Wenn dort mindestens eine ganze Zeile gefunden wird, wird eine Zukunft erstellt, das zuk√ºnftige Ergebnis einer aus dem Puffer entnommenen Zeile festgelegt und die Zukunft zur√ºckgegeben.  Wenn der Puffer keine ganze Zeile enth√§lt, initiiert er die E / A und erwartet sie. Wenn die E / A abgeschlossen ist, wird sie erneut gestartet. <br><br>  (...) <br><br>  Aber jetzt erstellen wir viele zuk√ºnftige, die keine E / A-Blockierung erfordern, aber dennoch einen Aufruf an den Scheduler erzwingen, da readline () die Zukunft zur√ºckgibt, vom Aufrufer eine Ausbeute verlangt wird und dies einen Aufruf an den Scheduler bedeutet. <br>  Der Scheduler kann die Steuerung direkt an die Coroutine √ºbertragen, wenn er sieht, dass die bereits abgeschlossene Zukunft angezeigt wird, oder die Zukunft in die Ausf√ºhrungswarteschlange zur√ºckgeben.  Letzteres verlangsamt die Arbeit erheblich (vorausgesetzt, es gibt mehr als eine ausf√ºhrbare Coroutine), da nicht nur das Warten am Ende der Warteschlange erforderlich ist, sondern wahrscheinlich auch die Lokalit√§t des Speichers (falls √ºberhaupt vorhanden) verloren geht. <br><br>  (...) <br><br>  Der Nettoeffekt all dessen ist, dass Coroutine-Autoren √ºber die Ertragszukunft Bescheid wissen m√ºssen, und daher gibt es eine gr√∂√üere psychologische Barriere f√ºr die Reorganisation von komplexem Code in besser lesbare Coroutinen - viel st√§rker als der vorhandene Widerstand, da Funktionsaufrufe in Python ziemlich langsam sind.  Und ich erinnere mich aus einem Gespr√§ch mit Glyph, dass Geschwindigkeit in einer typischen asynchronen E / A-Struktur wichtig ist. <br>  Vergleichen wir dies nun mit dem Ertrag von. <br><br>  (...) <br><br>  Sie haben vielleicht geh√∂rt, dass ‚ÄûAusbeute aus S‚Äú ungef√§hr gleichbedeutend ist mit ‚Äûf√ºr i in S: Ausbeute i‚Äú.  Im einfachsten Fall ist dies wahr, aber dies reicht nicht aus, um Coroutine zu verstehen.  Beachten Sie Folgendes (denken Sie noch nicht an asynchrone E / A): <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">driver</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(g)</span></span></span><span class="hljs-function">:</span></span> print(next(g)) g.send(<span class="hljs-number"><span class="hljs-number">42</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> val = <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-string"><span class="hljs-string">'okay'</span></span> print(val) driver(gen1())</code> </pre> <br>  Dieser Code druckt zwei Zeilen mit "okay" und "42" (und erzeugt dann eine nicht behandelte StopIteration, die Sie unterdr√ºcken k√∂nnen, indem Sie am Ende von gen1 Ausbeute hinzuf√ºgen).  Sie k√∂nnen diesen Code in Aktion auf pythontutor.com unter dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link sehen</a> . <br><br>  Betrachten Sie nun Folgendes: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> gen1() driver(gen2())</code> </pre><br>  Es funktioniert <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">genauso</a> .  Jetzt denke nach.  Wie funktioniert es  Die einfache Yield-From-Erweiterung in der for-Schleife kann hier nicht verwendet werden, da in diesem Fall der Code None zur√ºckgeben w√ºrde.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(Probieren Sie es aus)</a> .  Yield-from fungiert als "transparenter Kanal" zwischen Treiber und Gen1.  Das hei√üt, wenn gen1 den Wert "okay" gibt, verl√§sst es gen2 durch Yield-From an den Treiber, und wenn der Treiber 42 an Gen2 zur√ºcksendet, wird dieser Wert durch Yield-From wieder an Gen1 zur√ºckgegeben (wo er das Ergebnis von Yield wird ) <br><br>  Dasselbe w√ºrde passieren, wenn der Treiber einen Fehler in den Generator werfen w√ºrde: Der Fehler geht durch die Ausbeute an den internen Generator, der ihn verarbeitet.  Zum Beispiel: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">throwing_driver</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(g)</span></span></span><span class="hljs-function">:</span></span> print(next(g)) g.throw(RuntimeError(<span class="hljs-string"><span class="hljs-string">'booh'</span></span>)) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: val = <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-string"><span class="hljs-string">'okay'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> RuntimeError <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> exc: print(exc) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: print(val) <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> throwing_driver(gen1())</code> </pre><br>  Der Code gibt "okay" und "bah" sowie den folgenden Code: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> gen1() <span class="hljs-comment"><span class="hljs-comment"># unchanged throwing_driver(gen2())</span></span></code> </pre> <br>  (Siehe hier: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">goo.gl/8tnjk</a> ) <br><br>  Jetzt m√∂chte ich einfache (ASCII) Grafiken einf√ºhren, um √ºber diese Art von Code sprechen zu k√∂nnen.  Ich benutze [f1 -&gt; f2 -&gt; ... -&gt; fN), um den Stapel mit f1 unten (√§ltester Aufrufrahmen) und fN oben (neuester Aufrufrahmen) darzustellen, wobei jedes Element in der Liste ein Generator ist und -&gt; Rendite ergibt .  Das erste Beispiel, Treiber (gen1 ()), hat keine Ausbeute, aber einen Gen1-Generator, also sieht es so aus: <br><br><pre> <code class="python hljs">[ gen1 )</code> </pre> <br>  Im zweiten Beispiel ruft gen2 gen1 mit Yield-from auf, also sieht es so aus: <br><br><pre> <code class="python hljs">[ gen2 -&gt; gen1 )</code> </pre> <br>  Ich verwende die mathematische Notation f√ºr das halboffene Intervall [...), um zu zeigen, dass rechts ein weiterer Frame hinzugef√ºgt werden kann, wenn der Generator ganz rechts Yield-from verwendet, um einen anderen Generator aufzurufen, w√§hrend das linke Ende mehr oder weniger fest ist.  Das linke Ende ist das, was der Fahrer sieht (d. H. Der Scheduler). <br><br>  Jetzt bin ich bereit, zum Beispiel readline () zur√ºckzukehren.  Wir k√∂nnen readline () als Generator umschreiben, der read () aufruft, einen anderen Generator, der Yield-from verwendet.  Letzteres ruft wiederum recv () auf, das die eigentliche Eingabe / Ausgabe √ºber den Socket √ºbernimmt.  Auf der linken Seite befindet sich die Anwendung, die wir auch als Generator betrachten, der readline () aufruft und wiederum Yield-from verwendet.  Das Schema ist wie folgt: <br><br><pre> <code class="python hljs">[ app -&gt; readline -&gt; read -&gt; recv )</code> </pre> <br>  Jetzt setzt der Generator recv () E / A, bindet es an die Zukunft und √ºbergibt es mit *ield * (nicht Yield-from!) An den Scheduler.  Die Zukunft geht nach links entlang der beiden Ertragspfeile im Scheduler (links von "[").  Beachten Sie, dass der Scheduler nicht wei√ü, dass er einen Stapel von Generatoren enth√§lt.  Er wei√ü nur, dass er den Generator ganz links enth√§lt und gerade eine Zukunft ausgegeben hat.  Wenn die E / A abgeschlossen ist, legt der Scheduler das zuk√ºnftige Ergebnis fest und sendet es an den Generator zur√ºck.  Das Ergebnis bewegt sich entlang der beiden Pfeile nach rechts zum Recv-Generator, der die Bytes empf√§ngt, die er als Ertragsergebnis aus dem Socket lesen wollte. <br><br>  Mit anderen Worten, der Yield-from-Framework-Scheduler verarbeitet E / A-Operationen genauso wie der zuvor beschriebene Yield-basierte Framework-Scheduler.  * Aber: * Er muss sich nicht um die Optimierung k√ºmmern, wenn die Zukunft bereits ausgef√ºhrt wird, da der Scheduler nicht an der √úbertragung der Kontrolle zwischen readline () und read () oder zwischen read () und recv () beteiligt ist und umgekehrt.  Daher nimmt der Scheduler √ºberhaupt nicht teil, wenn app () readline () aufruft und readline () die Anforderung aus dem Puffer erf√ºllen kann (ohne read ()) aufzurufen - die Interaktion zwischen app () und readline () wird in diesem Fall vollst√§ndig vom Bytecode-Interpreter verarbeitet Python  Der Scheduler kann einfacher sein und die Anzahl der vom Scheduler erstellten und verwalteten zuk√ºnftigen ist geringer, da es keine zuk√ºnftigen gibt, die bei jedem Aufruf von coroutine erstellt und zerst√∂rt werden.  Die einzige Zukunft, die noch ben√∂tigt wird, sind diejenigen, die die tats√§chliche E / A darstellen, die beispielsweise von recv () erstellt wurde. <br><br>  Wenn Sie bis zu diesem Punkt gelesen haben, verdienen Sie eine Belohnung.  Ich habe viele Implementierungsdetails weggelassen, aber die obige Abbildung spiegelt das Bild im Wesentlichen korrekt wider. <br><br>  Eine andere Sache, auf die ich hinweisen m√∂chte.  * Sie k√∂nnen * einen Teil des Codes dazu bringen, Yield-From zu verwenden, und den anderen Teil Yield verwenden.  Der Ertrag erfordert jedoch, dass jedes Glied in der Kette eine Zukunft hat, nicht nur Coroutine.  Da die Verwendung von Yield-From mehrere Vorteile bietet, m√∂chte ich, dass sich der Benutzer nicht daran erinnern muss, wann Yield-From verwendet werden soll, und wenn Yield-From verwendet wird, ist es einfacher, immer Yield-From zu verwenden.  Eine einfache L√∂sung erm√∂glicht es recv () sogar, Yield-from zu verwenden, um zuk√ºnftige E / A an den Scheduler zu √ºbergeben: Die Methode __iter__ ist tats√§chlich der Generator, den die Zukunft ausgibt. <br><br>  (...) <br><br>  Und noch etwas.  Welchen Wert hat die Rendite?  Es stellt sich heraus, dass dies der R√ºckgabewert des * externen * Generators ist. <br><br>  (...) <br><br>  Obwohl die Pfeile den linken und den rechten Rahmen an das * nachgebende * Ziel binden, √ºbergeben sie auch die √ºblichen R√ºckgabewerte auf die √ºbliche Weise, jeweils einen Stapelrahmen nach dem anderen.  Ausnahmen werden auf die gleiche Weise verschoben.  Nat√ºrlich ist auf jeder Ebene ein Versuch / eine Ausnahme erforderlich, um sie zu fangen. <br></blockquote>  Es stellt sich heraus, dass der Ertrag von so ziemlich dem entspricht, was man erwartet. <br><br><h2>  Ausbeute von vs async </h2><br><table><tbody><tr><td><p>  def coro () ^ </p><p>  y = Ausbeute aus a </p></td><td>  async def async_coro (): <p>  y = warte auf a </p></td></tr><tr><td>  0 load_global </td><td>  0 load_global </td></tr><tr><td>  2 get_yield_from_iter </td><td><p>  2 get_awaitable </p></td></tr><tr><td>  4 load_const </td><td><p>  4 load_const </p></td></tr><tr><td>  6 Ausbeute_von </td><td>  6 Ausbeute_von </td></tr><tr><td>  8 store_fast </td><td><p>  8 store_fast </p></td></tr><tr><td>  10 load_const </td><td>  10 load_const <br></td></tr><tr><td>  12 return_value </td><td>  12 return_value </td></tr></tbody></table><br><br>  Die beiden Coroutinen der alten und der neuen Schule haben nur einen kleinen Unterschied: Erhalten Sie Ertrag von iter vs erwarten Sie. <br><br>  Warum ist das alles?  Tornado verwendet eine einfache Ausbeute.  Vor Version 5 verbindet es diese gesamte Kette von Aufrufen durch Yield, was mit dem neuen Cool Yield from / await-Paradigma schlecht kompatibel ist. <br><br><h2>  Der einfachste asynchrone Benchmark </h2><br>  Es ist schwierig, ein wirklich gutes Ger√ºst zu finden, das nur nach synthetischen Tests ausgew√§hlt wird.  Im wirklichen Leben k√∂nnen viele Dinge schief gehen. <br><br>  Ich nahm Aiohttp Version 3.4.4, Tornado 5.1.1, uvloop 0.11, nahm den Intel Xeon Serverprozessor, CPU E5 v4, 3.6 GHz und begann mit Python 3.6.5, Webserver auf Wettbewerbsf√§higkeit zu √ºberpr√ºfen. <br><br>  Das typische Problem, das wir mit Hilfe von Microservices l√∂sen und das im asynchronen Modus arbeitet, sieht so aus.  Wir werden Anfragen erhalten.  F√ºr jeden von ihnen werden wir eine Anfrage an einen Microservice stellen, Daten von dort abrufen, dann zu zwei oder drei weiteren Microservices gehen, ebenfalls asynchron, dann die Daten irgendwo in die Datenbank schreiben und das Ergebnis zur√ºckgeben.  Es stellt sich heraus, dass wir an vielen Punkten warten werden. <br><br>  Wir f√ºhren eine einfachere Operation durch.  Wir schalten den Server ein und lassen ihn 50 ms schlafen.  Erstellen Sie eine Coroutine und vervollst√§ndigen Sie sie.  Wir werden kein sehr gro√ües RPS haben (es ist m√∂glicherweise keine Gr√∂√üenordnung √§hnlich wie bei vollsynthetischen Benchmarks) mit einer akzeptablen Verz√∂gerung, da sich auf einem wettbewerbsf√§higen Server gleichzeitig viel Coroutine dreht. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@tornado.gen.coroutine def old_school_work(): yield tornado.gen.sleep(SLEEP_TIME) async def work(): await tornado.gen.sleep(SLEEP_TIME)</span></span></code> </pre> <br>  Laden - http-Anfragen abrufen.  Dauer - 300s, 1s - Aufw√§rmen, 5 Wiederholungen der Last. <br><br><img src="https://habrastorage.org/webt/ep/mq/fw/epmqfwh6bv_vyfu8tymtelvohos.png"><br><br>  <i>Ergebnisse zu Perzentilen der Service-Antwortzeit.</i> <br><br><div class="spoiler">  <b class="spoiler_title">Was sind Perzentile?</b> <div class="spoiler_text">  Sie haben eine gro√üe Anzahl von Zahlen.  Das 95. Perzentil X bedeutet, dass 95% der Werte in dieser Stichprobe kleiner als X sind. Mit einer Wahrscheinlichkeit von 5% ist Ihre Zahl gr√∂√üer als X. <br></div></div><br>  Wir sehen, dass Aiohttp bei 1000 RPS bei einem so einfachen Test gute Arbeit geleistet hat.  Alles soweit ohne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Uvloop</a> . <br><br>  Vergleichen Sie Tornado mit den Coroutinen der alten (Ertrag) und neuen (Async) Schule.  Autoren empfehlen dringend die Verwendung von Async.  Wir k√∂nnen sicherstellen, dass sie wirklich viel schneller sind. <br><br>  Bei 1200 RPS gibt Tornado trotz der neuen Schulkoroutinen bereits auf, und Tornado mit den alten Schulkoroutinen ist v√∂llig weggeblasen.  Wenn wir 50 ms schlafen und der Microservice f√ºr 80 ms verantwortlich ist, geht dies √ºberhaupt nicht in ein Gate. <br><br>  Tornados neue Schule mit 1.500 RPS hat vollst√§ndig aufgegeben, w√§hrend Aiohttp noch weit von der Grenze von 3.000 RPS entfernt ist.  Das interessanteste kommt noch. <br><br><h2>  Pyflame, Profilierung eines funktionierenden Microservices </h2><br>  Mal sehen, was gerade mit dem Prozessor passiert. <br><br><img src="https://habrastorage.org/webt/mw/-6/c-/mw-6c-vzw_kk-flygqeig93qohe.png"><br><br>  Als wir herausfanden, wie asynchrone Python-Mikrodienste in der Produktion funktionieren, versuchten wir zu verstehen, worauf es ankam.  In den meisten F√§llen lag das Problem bei der CPU oder den Deskriptoren.  In Uber wurde ein gro√üartiges Profiling-Tool erstellt, der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pyflame-</a> Profiler, der auf dem Systemaufruf ptrace basiert. <br><br>  Wir starten einen Dienst im Container und werfen eine Kampfladung darauf.  Oft ist dies keine sehr triviale Aufgabe - eine solche Last zu erstellen, die sich im Kampf befindet, da es h√§ufig vorkommt, dass Sie synthetische Tests f√ºr Lasttests durchf√ºhren, aussehen und alles gut funktioniert.  Sie schieben die Kampflast auf ihn, und hier beginnt der Mikrodienst zu stumpfen. <br><br>  W√§hrend des Betriebs erstellt dieser Profiler f√ºr uns Snapshots des Aufrufstapels.  Sie k√∂nnen den Dienst √ºberhaupt nicht √§ndern, sondern nur pyflame in der N√§he ausf√ºhren.  Es wird einmal in einem bestimmten Zeitraum eine Stapelverfolgung sammeln und dann eine coole Visualisierung durchf√ºhren.  Dieser Profiler verursacht sehr wenig Overhead, insbesondere im Vergleich zu cProfile.  Pyflame unterst√ºtzt auch Multithread-Programme.  Wir haben dieses Ding direkt in das Produkt eingef√ºhrt, und die Leistung hat sich nicht wesentlich verschlechtert. <br><br><img src="https://habrastorage.org/webt/pk/2s/lu/pk2slutzgqe-szo4mbefnk_zoqe.png"><br><br>  Hier ist die X-Achse die Zeitdauer, die Anzahl der Aufrufe, als der Stapelrahmen auf der Liste aller Python-Stapelrahmen stand.  Dies ist die ungef√§hre Prozessorzeit, die wir in diesem bestimmten Frame des Stapels verbracht haben. <br><br>  Wie Sie sehen k√∂nnen, geht hier die meiste Zeit in aiohttp in den Leerlauf.  Gut: Dies ist das, was wir von einem asynchronen Dienst erwarten, damit er die meiste Zeit mit Netzwerkanrufen umgehen kann.  Die Tiefe des Stapels betr√§gt in diesem Fall etwa 15 Frames. <br><br>  In Tornado (zweites Bild) mit der gleichen Last wird viel weniger Zeit f√ºr den Leerlauf aufgewendet, und die Stapeltiefe betr√§gt in diesem Fall etwa 30 Frames. <br><br>  Hier ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link zu svg</a> , du kannst dich verdrehen. <br><br><h2>  Komplexerer asynchroner Benchmark </h2><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">work</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#     await asyncio.sleep(SLEEP_TIME) class HardWorkHandler(tornado.web.RequestHandler): timeout_time = datetime.timedelta(seconds=SLEEP_TIME / 2) async def get(self): await work() #     await tornado.gen.multi([work(), work()]) #     try: await tornado.gen.with_timeout(self.timeout_time, work()) except tornado.util.TimeoutError: #     pass</span></span></code> </pre><br>  Erwarten Sie eine Laufzeit von 125 ms. <br><br><img src="https://habrastorage.org/webt/i2/u5/3d/i2u53d-v1qhpmgkqiifa6q8rita.png"><br><br>  Tornado mit Uvloop h√§lt besser.  Aber Aiohttp uvloop hilft noch viel mehr.  Aiohttp verh√§lt sich bei 2300-2400 RPS schlecht und erweitert mit uvloop den Lastbereich erheblich.  Eine Importlinie, und jetzt haben Sie einen viel produktiveren Service. <br><br><h2>  Zusammenfassung </h2><br>  Ich werde zusammenfassen, was ich Ihnen heute vermitteln wollte. <br><br><ul><li>  Erstens habe ich einen bestimmten k√ºnstlichen Benchmark gestartet, bei dem es eine anst√§ndige Menge an langer Coroutine gab.  In unserem Test schnitt Aiohttp 2,5-mal besser ab als Tornado. </li><li>  Die zweite Tatsache.  Uvloop hilft sehr gut dabei, die Leistung von Aiohttp zu verbessern (besser als Tornado). </li><li>  Ich habe Ihnen von Pyflame erz√§hlt, mit dem wir die Anwendung h√§ufig direkt in der Produktion profilieren. </li><li>  Und wir sprachen auch √ºber den Ertrag von (warten) gegen den Ertrag. </li></ul><br>  Aufgrund dieser Benchmarks ist unser Empfehlungsteam (und einige andere) mit Tornado f√ºr Microservices in Python in der Produktion fast vollst√§ndig zu Aiohttp gewechselt. <br><br><ul><li>  Bei Kampfdiensten sank der CPU-Verbrauch um mehr als das Zweifache. </li><li>  Wir haben angefangen, Zeit√ºberschreitungen f√ºr http-Anfragen zu respektieren. </li><li>  Die Latenzdienste gingen zwei- bis f√ºnfmal zur√ºck. </li></ul><br>  Hier ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link zum Benchmark</a> .  Bei Interesse k√∂nnen Sie es wiederholen.  Vielen Dank f√ºr Ihre Aufmerksamkeit.  Stellen Sie Fragen, ich werde versuchen, sie zu beantworten. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de435532/">https://habr.com/ru/post/de435532/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de435520/index.html">Wir schreiben unsere Programmiersprache, Teil 3: √úbersetzerarchitektur. Analyse von Sprachstrukturen und mathematischen Ausdr√ºcken</a></li>
<li><a href="../de435522/index.html">Ereignis-Snapshots in Axonframework 3 verbessern die Leistung</a></li>
<li><a href="../de435526/index.html">Abenteuer mit einem Home Kubernetes Cluster</a></li>
<li><a href="../de435528/index.html">5 Gr√ºnde f√ºr den Erfolg: Warum Amazon zum teuersten Unternehmen der Welt geworden ist</a></li>
<li><a href="../de435530/index.html">Bezahlte Abonnements - Abh√§ngigkeit der automatischen Verbindung von einem mobilen Ger√§t</a></li>
<li><a href="../de435534/index.html">Data Science: Einstiegsb√ºcher</a></li>
<li><a href="../de435536/index.html">Humanoide Roboter: Vorteile und Probleme anthropomorpher Mechanismen</a></li>
<li><a href="../de435538/index.html">Im Jahr 2018 wurde in Deutschland mehr ‚Äûgr√ºne‚Äú Energie aufgenommen als Strom aus der Kohleverbrennung</a></li>
<li><a href="../de435540/index.html">Neue Schl√ºsselw√∂rter in Java</a></li>
<li><a href="../de435542/index.html">Spielentwicklung und Verteidigung eines Diploms oder "Wie ich zwei Fliegen mit einem einzigen Pfannkuchen get√∂tet habe"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
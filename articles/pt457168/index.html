<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏻‍💻 🔺 👩🏾‍🚀 Análise de sentimento de protótipo com Python e TextBlob 👩🏿‍🤝‍👨🏽 📉 💅🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O que é importante para uma equipe de desenvolvimento que está apenas começando a construir um sistema de aprendizado de máquina? Arquitetura, compone...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Análise de sentimento de protótipo com Python e TextBlob</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457168/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/8l/ir/g2/8lirg2klkrmofom9vhhcgldh-qo.jpeg" alt="imagem"></div><br>  O que é importante para uma equipe de desenvolvimento que está apenas começando a construir um sistema de aprendizado de máquina?  Arquitetura, componentes, recursos de teste usando integração e testes de unidade, fazem um protótipo e obtêm os primeiros resultados.  E além da avaliação da contribuição do trabalho, planejamento de desenvolvimento e implementação. <br><br>  Este artigo se concentrará no protótipo.  Que foi criado algum tempo depois de conversar com o Gerente de Produto: por que não tocamos no Machine Learning?  Em particular, PNL e análise de sentimentos? <br><a name="habracut"></a><br>  "Por que não?"  Eu respondi.  Ainda assim, estou envolvido no desenvolvimento de back-end há mais de 15 anos, gosto de trabalhar com dados e resolver problemas de desempenho.  Mas eu ainda tinha que descobrir "quão profunda é a toca do coelho". <br><br><h2>  Selecionar componentes </h2><br>  Para delinear de alguma maneira o conjunto de componentes que implementam a lógica do nosso núcleo de ML, vejamos um exemplo simples da implementação da análise de sentimentos, uma das muitas disponíveis no GitHub. <br><br><div class="spoiler">  <b class="spoiler_title">Um exemplo de análise de sentimentos em Python</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( datasets, model_selection, feature_extraction, linear_model ) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">extract_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(corpus)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''Extract TF-IDF features from corpus'''</span></span> <span class="hljs-comment"><span class="hljs-comment"># vectorize means we turn non-numerical data into an array of numbers count_vectorizer = feature_extraction.text.CountVectorizer( lowercase=True, # for demonstration, True by default tokenizer=nltk.word_tokenize, # use the NLTK tokenizer stop_words='english', # remove stop words min_df=1 # minimum document frequency, ie the word must appear more than once. ) processed_corpus = count_vectorizer.fit_transform(corpus) processed_corpus = feature_extraction.text.TfidfTransformer().fit_transform( processed_corpus) return processed_corpus data_directory = 'movie_reviews' movie_sentiment_data = datasets.load_files(data_directory, shuffle=True) print('{} files loaded.'.format(len(movie_sentiment_data.data))) print('They contain the following classes: {}.'.format( movie_sentiment_data.target_names)) movie_tfidf = extract_features(movie_sentiment_data.data) X_train, X_test, y_train, y_test = model_selection.train_test_split( movie_tfidf, movie_sentiment_data.target, test_size=0.30, random_state=42) # similar to nltk.NaiveBayesClassifier.train() model = linear_model.LogisticRegression() model.fit(X_train, y_train) print('Model performance: {}'.format(model.score(X_test, y_test))) y_pred = model.predict(X_test) for i in range(5): print('Review:\n{review}\n-\nCorrect label: {correct}; Predicted: {predict}'.format( review=X_test[i], correct=y_test[i], predict=y_pred[i] ))</span></span></code> </pre> <br></div></div><br>  A análise desses exemplos é um desafio separado para o desenvolvedor. <br>  Apenas 45 linhas de código e 4 (quatro, Karl!) Blocos lógicos de uma só vez: <br><br><ol><li>  Fazendo Download de Dados para o Treinamento do Modelo (Linhas 25 a 26) </li><li>  Preparando dados carregados - extração de recursos (linhas 31 a 34) </li><li>  Criando e treinando um modelo (linhas 36-39) </li><li>  Testando um modelo treinado e produzindo resultados (linhas 41-45) </li></ol><br>  Cada um desses pontos merece um artigo separado.  E certamente requer registro em um módulo separado.  Pelo menos para as necessidades de teste de unidade. <br><br>  Separadamente, vale destacar os componentes da preparação de dados e do treinamento do modelo. <br>  Em cada uma das maneiras de tornar o modelo mais preciso, são investidas centenas de horas de trabalho científico e de engenharia. <br><br>  Felizmente, para iniciar rapidamente a PNL, existe uma solução pronta - as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bibliotecas NLTK</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TextBlob</a> .  O segundo é um invólucro sobre o NLTK que realiza a tarefa - extrai os recursos do conjunto de treinamento e treina o modelo na primeira solicitação de classificação. <br><br>  Mas antes de treinar o modelo, você precisa preparar dados para ele. <br><br><h2>  Preparando dados </h2><br><h3>  Baixar dados </h3><br>  Se falamos sobre o protótipo, o carregamento de dados de um arquivo CSV / TSV é elementar.  Você simplesmente chama a função <b>read_csv</b> da biblioteca do pandas: <br><br><pre> <code class="plaintext hljs">import pandas as pd data = pd.read_csv(data_path, delimiter)</code> </pre><br>  Mas não haverá dados prontos para uso no modelo. <br><br>  Primeiro, se ignorarmos um pouco o formato csv, é fácil esperar que cada fonte forneça dados com suas próprias características e, portanto, precisamos de algum tipo de preparação de dados dependentes da fonte.  Mesmo no caso mais simples de um arquivo CSV, para analisá-lo, precisamos conhecer o delimitador. <br><br>  Além disso, você deve determinar quais entradas são positivas e quais são negativas.  Obviamente, essas informações são indicadas na anotação dos conjuntos de dados que queremos usar.  Mas o fato é que, em um caso, o sinal de pos / neg é 0 ou 1, no outro, é um True / False lógico, no terceiro, é apenas uma sequência de pos / neg e, em alguns casos, uma tupla de números inteiros de 0 a 5 O último é relevante para o caso da classificação multiclasse, mas quem disse que esse conjunto de dados não pode ser usado para classificação binária?  Você só precisa identificar adequadamente a fronteira de valores positivos e negativos. <br><br>  Eu gostaria de experimentar o modelo em diferentes conjuntos de dados, e é necessário que, após o treinamento, o modelo retorne o resultado em um único formato.  E, para isso, deve trazer seus dados heterogêneos para um único formulário. <br><br>  Portanto, existem três funções que precisamos no estágio de carregamento de dados: <br><br><ol><li>  A conexão com a fonte de dados é para CSV; no nosso caso, é implementada dentro da função read_csv; </li><li>  Suporte para recursos de formato; </li><li>  Preparação preliminar de dados. </li></ol><br>  É assim que parece no código. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># linear algebra import pandas as pd # data processing, CSV file I/O (eg pd.read_csv) import logging log = logging.getLogger() class CsvSentimentDataLoader(): def __init__(self, file_path, delim, text_attr, rate_attr, pos_rates): self.data_path = file_path self.delimiter = delim self.text_attr = text_attr self.rate_attr = rate_attr self.pos_rates = pos_rates def load_data(self): #     csv  tsv  data = pd.read_csv(self.data_path, self.delimiter) data.head() #   , #      data = data[[self.text_attr, self.rate_attr]] #    #     'pos'  'neg' data[self.rate_attr] = np.where( data[self.rate_attr].isin(self.pos_rates), 'pos', 'neg') return data</span></span></code> </pre><br>  Foi <b>criada a</b> classe <b>CsvSentimentDataLoader</b> , que no construtor passa o caminho para csv, o separador, os nomes do texto e os atributos de classificação, além de uma lista de valores que aconselham o valor positivo do texto. <br><br>  O carregamento em si ocorre no método <b>load_data</b> . <br><br><h3>  Dividimos os dados em conjuntos de teste e treinamento </h3><br>  Ok, carregamos os dados, mas ainda precisamos dividi-los nos conjuntos de treinamento e teste. <br><br>  Isso é feito com a função <b>train_test_split da</b> biblioteca <b>sklearn</b> .  Essa função pode receber muitos parâmetros como entrada, determinando como exatamente esse conjunto de dados será dividido em treinamento e teste.  Esses parâmetros afetam significativamente os conjuntos de treinamento e teste resultantes e provavelmente será conveniente criar uma classe (vamos chamá-lo de SimpleDataSplitter) que gerenciará esses parâmetros e agregará a chamada a esta função. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-comment"><span class="hljs-comment"># to split the training and testing data import logging log = logging.getLogger() class SimpleDataSplitter(): def __init__(self, text_attr, rate_attr, test_part_size=.3): self.text_attr = text_attr self.rate_attr = rate_attr self.test_part_size = test_part_size def split_data(self, data): x = data[self.text_attr] y = data[self.rate_attr] x_train, x_test, y_train, y_test = train_test_split( x, y, test_size = self.test_part_size) return x_train, x_test, y_train, y_test</span></span></code> </pre><br>  Agora, essa classe inclui a implementação mais simples, que, quando dividida, levará em conta apenas um parâmetro - a porcentagem de registros que devem ser tomados como um conjunto de testes. <br><br><h3>  Conjuntos de dados </h3><br>  Para treinar o modelo, usei conjuntos de dados disponíveis gratuitamente no formato CSV: <br><br><ul><li>  Conjunto de dados do Amazon Alexa Reviews, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">disponível no Kaggle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Conjunto de dados de frases com sentimentos</a> da Universidade da Califórnia </li></ul><br>  E para torná-lo ainda mais conveniente, para cada um dos conjuntos de dados, criei uma classe que carrega dados do arquivo CSV correspondente e os divide em conjuntos de treinamento e teste. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> web.data.loaders <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CsvSentimentDataLoader <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> web.data.splitters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SimpleDataSplitter, TdIdfDataSplitter log = logging.getLogger() <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AmazonAlexaDataset</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.file_path = os.path.normpath(os.path.join(os.path.dirname(__file__), <span class="hljs-string"><span class="hljs-string">'amazon_alexa/train.tsv'</span></span>)) self.delim = <span class="hljs-string"><span class="hljs-string">'\t'</span></span> self.text_attr = <span class="hljs-string"><span class="hljs-string">'verified_reviews'</span></span> self.rate_attr = <span class="hljs-string"><span class="hljs-string">'feedback'</span></span> self.pos_rates = [<span class="hljs-number"><span class="hljs-number">1</span></span>] self.data = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.train = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.test = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> loader = CsvSentimentDataLoader(self.file_path, self.delim, self.text_attr, self.rate_attr, self.pos_rates) splitter = SimpleDataSplitter(self.text_attr, self.rate_attr, test_part_size=<span class="hljs-number"><span class="hljs-number">.3</span></span>) self.data = loader.load_data() x_train, x_test, y_train, y_test = splitter.split_data(self.data) self.train = [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(x_train, y_train)] self.test = [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(x_test, y_test)]</code> </pre><br>  Sim, para o carregamento de dados, resultou um pouco mais de 5 linhas de código no exemplo original. <br>  Mas agora é possível criar novos conjuntos de dados manipulando fontes de dados e algoritmos de preparação de conjuntos de treinamento. <br><br>  Além disso, componentes individuais são muito mais convenientes para testes de unidade. <br><br><h2>  Treinamos o modelo </h2><br>  O modelo está aprendendo há algum tempo.  E isso deve ser feito uma vez, no início do aplicativo. <br>  Para esses fins, foi criado um pequeno invólucro que permite fazer o download e preparar dados, além de treinar o modelo no momento da inicialização do aplicativo. <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TextBlobWrapper</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.log = logging.getLogger() self.is_model_trained = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> self.classifier = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_app</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.log.info(<span class="hljs-string"><span class="hljs-string">'&gt;&gt;&gt;&gt;&gt; TextBlob initialization started'</span></span>) self.ensure_model_is_trained() self.log.info(<span class="hljs-string"><span class="hljs-string">'&gt;&gt;&gt;&gt;&gt; TextBlob initialization completed'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ensure_model_is_trained</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> self.is_model_trained: ds = SentimentLabelledDataset() ds.load_data() <span class="hljs-comment"><span class="hljs-comment"># train the classifier and test the accuracy self.classifier = NaiveBayesClassifier(ds.train) acr = self.classifier.accuracy(ds.test) self.log.info(str.format('&gt;&gt;&gt;&gt;&gt; NaiveBayesClassifier trained with accuracy {}', acr)) self.is_model_trained = True return self.classifier</span></span></code> </pre><br>  Primeiro, obtemos dados de treinamento e teste, depois realizamos a extração e, finalmente, treinamos o classificador e verificamos a precisão no conjunto de testes. <br><br><h2>  Teste </h2><br>  Na inicialização, obtemos um log, julgando pelo qual, os dados foram baixados e o modelo foi treinado com sucesso.  E treinado com muito boa precisão (para iniciantes) - 0,8878. <br><br><img src="https://habrastorage.org/webt/nl/hw/pt/nlhwptjx8xnwfao2anynttvbr1u.png" alt="imagem"><br><br>  Tendo recebido esses números, fiquei muito entusiasmado.  Mas minha alegria, infelizmente, não foi longa.  O modelo treinado neste conjunto é um otimista impenetrável e, em princípio, não é capaz de reconhecer comentários negativos. <br><br>  A razão para isso está nos dados do conjunto de treinamento.  O número de críticas positivas no conjunto é superior a 90%.  Consequentemente, com uma precisão de modelo de cerca de 88%, as análises negativas simplesmente caem nos 12% esperados de classificações incorretas. <br><br>  Em outras palavras, com esse conjunto de treinamento, é simplesmente impossível treinar o modelo para reconhecer comentários negativos. <br><br>  Para ter certeza disso, fiz um teste de unidade que executa a classificação separadamente para 100 frases positivas e 100 negativas de outro conjunto de dados - para o teste, fiz o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Conjunto de Dados de Sentenças Rotuladas de Sentimentos</a> da Universidade da Califórnia. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @loggingtestcase.capturelogs(None, level='INFO') def test_classifier_on_separate_set(self, logs): tb = TextBlobWrapper() # Going to be trained on Amazon Alexa dataset ds = SentimentLabelledDataset() # Test dataset ds.load_data() # Check poisitives true_pos = 0 data = ds.data.to_numpy() seach_mask = np.isin(data[:, 1], ['pos']) data = data[seach_mask][:100] for e in data[:]: # Model train will be performed on first classification call r = tb.do_sentiment_classification(e[0]) if r == e[1]: true_pos += 1 self.assertLessEqual(true_pos, 100) print(str.format('\n\nTrue Positive answers - {} of 100', true_pos))</span></span></code> </pre><br>  O algoritmo para testar a classificação de valores positivos é o seguinte: <br><br><ul><li>  Faça o download dos dados de teste; </li><li>  Take 100 posts tagged 'pos' </li><li>  Executamos cada um deles através do modelo e contamos o número de resultados corretos </li><li>  Exiba o resultado final no console. </li></ul><br>  Da mesma forma, é feita uma contagem para comentários negativos. <br><br><div class="spoiler">  <b class="spoiler_title">Resultado</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/79/lj/px/79ljpxifxo5sl1kpdt_h0q4zd58.png" alt="imagem"><br></div></div><br>  Como esperado, todos os comentários negativos foram reconhecidos como positivos. <br><br>  E se você treinar o modelo no conjunto de dados usado para o teste - <b>Sentiment Labeled</b> ?  Lá, a distribuição de comentários negativos e positivos é exatamente de 50 a 50. <br><br><div class="spoiler">  <b class="spoiler_title">Mude o código e teste, execute</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/tj/cw/oo/tjcwoocc2qodmbd5zl7emwqt8ve.png" alt="imagem"><br></div></div><br>  Algo já.  A precisão real de 200 entradas de um conjunto de terceiros é de 76%, enquanto a precisão da classificação de comentários negativos é de 79%. <br><br>  Obviamente, 76% servirão como protótipo, mas não o suficiente para a produção.  Isso significa que serão necessárias medidas adicionais para melhorar a precisão do algoritmo.  Mas este é um tópico para outro relatório. <br><br><h2>  Sumário </h2><br>  Primeiramente, obtivemos um aplicativo com uma dúzia de classes e mais de 200 linhas de código, o que é um pouco mais que o exemplo original em 30 linhas.  E você deve ser honesto - essas são apenas dicas da estrutura, o primeiro esclarecimento dos limites da futura aplicação.  Protótipo. <br><br>  E esse protótipo tornou possível perceber até que ponto a distância entre as abordagens do código é do ponto de vista dos especialistas em Machine Learning e do ponto de vista dos desenvolvedores de aplicativos tradicionais.  E essa, na minha opinião, é a principal dificuldade dos desenvolvedores que decidem experimentar o aprendizado de máquina. <br><br>  A próxima coisa que pode colocar um iniciante em um estupor - os dados não são menos importantes que o modelo selecionado.  Isso foi claramente mostrado. <br><br>  Além disso, sempre existe a possibilidade de que um modelo treinado em alguns dados se mostre inadequado em outros, ou em algum momento sua precisão comece a se degradar. <br>  Consequentemente, são necessárias métricas para monitorar o estado do modelo, flexibilidade ao trabalhar com dados, recursos técnicos para ajustar o aprendizado em tempo real.  E assim por diante <br><br>  Quanto a mim, tudo isso deve ser levado em consideração ao projetar a arquitetura e construir processos de desenvolvimento. <br><br>  Em geral, o "buraco do coelho" não era apenas muito profundo, mas também extremamente inteligente.  Mas ainda mais interessante para mim, como desenvolvedor, estudar este tópico no futuro. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt457168/">https://habr.com/ru/post/pt457168/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt457152/index.html">Conferência DEFCON 25. Garry Kasparov. "A última batalha do cérebro." Parte 1</a></li>
<li><a href="../pt457154/index.html">Design de aplicativo responsivo para todos os usuários</a></li>
<li><a href="../pt457156/index.html">Quais podem ser os sistemas de computação do futuro</a></li>
<li><a href="../pt457160/index.html">Minha abordagem para implementar delegados em C ++: chamando uma função com parâmetros desconhecidos em tempo de execução</a></li>
<li><a href="../pt457164/index.html">Navegação em um aplicativo .NET Core de plataforma cruzada com salvando o estado no disco usando o exemplo de ReactiveUI e Avalonia</a></li>
<li><a href="../pt457172/index.html">ScreenLogger - sorria, você é filmado por uma câmera escondida</a></li>
<li><a href="../pt457178/index.html">Como os processadores são projetados e fabricados: Design da CPU</a></li>
<li><a href="../pt457180/index.html">O site oficial Node.js agora está em russo</a></li>
<li><a href="../pt457182/index.html">Língua REXX, 40 anos</a></li>
<li><a href="../pt457184/index.html">Criar dinamicamente robots.txt para sites ASP.NET Core</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
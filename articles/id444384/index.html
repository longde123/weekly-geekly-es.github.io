<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌍 🚵🏼 🧐 Buku "Analisis Data Teks Terapan dengan Python" 🐳 📰 👨‍🏫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Teknologi analisis teks berubah dengan cepat di bawah pengaruh pembelajaran mesin. Jaringan saraf dari penelitian ilmiah teoritis telah masuk ke kehid...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Buku "Analisis Data Teks Terapan dengan Python"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/444384/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><img src="https://habrastorage.org/webt/xl/rp/2m/xlrp2mz88qpo576nl7wcvkhpaek.jpeg" align="left" alt="gambar"></a>  Teknologi analisis teks berubah dengan cepat di bawah pengaruh pembelajaran mesin.  Jaringan saraf dari penelitian ilmiah teoritis telah masuk ke kehidupan nyata, dan analisis teks secara aktif diintegrasikan ke dalam solusi perangkat lunak.  Neural networks mampu menyelesaikan tugas-tugas paling kompleks dari pemrosesan bahasa alami, tidak ada yang terkejut dengan terjemahan mesin, “percakapan” dengan robot di toko online, mengulangi, menjawab pertanyaan dan memelihara dialog.  Lalu, mengapa Siri, Alexa, dan Alice tidak ingin memahami kami, Google tidak menemukan apa yang kami cari, dan penerjemah mesin menghibur kami dengan contoh-contoh "kesulitan terjemahan" dari Bahasa Mandarin ke Bahasa Albania?  Jawabannya terletak pada detail - dalam algoritma yang bekerja dengan benar dalam teori, tetapi sulit untuk diimplementasikan dalam praktik.  Pelajari cara menggunakan teknik pembelajaran mesin untuk menganalisis teks dalam tugas kehidupan nyata menggunakan kemampuan dan perpustakaan Python.  Dari pencarian model dan pemrosesan data, Anda akan beralih ke metode pengelompokan dan pengelompokan teks, kemudian melanjutkan ke interpretasi visual, analisis grafik, dan setelah membiasakan diri dengan teknik penskalaan, pelajari cara menggunakan pembelajaran mendalam untuk menganalisis teks. <br><br><a name="habracut"></a><br><h3>  Apa yang dijelaskan dalam buku ini? </h3><br>  Buku ini berbicara tentang menggunakan metode pembelajaran mesin untuk menganalisis teks menggunakan pustaka Python yang baru saja tercantum.  Sifat terapan dari buku ini menunjukkan bahwa kita tidak berfokus pada linguistik akademik atau model statistik, tetapi pada penyebaran efektif model-model yang terlatih dalam teks dalam aplikasi. <br><br>  Model analisis teks kami secara langsung terkait dengan proses pembelajaran mesin - pencarian model yang terdiri dari atribut, algoritma, dan hyperparameter yang akan memberikan hasil terbaik pada data pelatihan untuk mengevaluasi data yang tidak diketahui.  Proses ini dimulai dengan pembuatan kumpulan data pelatihan, yang dalam bidang analisis teks disebut corpus.  Kemudian kami memeriksa metode untuk mengekstraksi atribut dan preprocessing untuk mewakili teks dalam bentuk data numerik yang dapat dimengerti oleh metode pembelajaran mesin.  Selanjutnya, setelah berkenalan dengan beberapa dasar-dasar, kita akan beralih ke mempelajari metode klasifikasi dan pengelompokan teks, kisah yang melengkapi bab-bab pertama buku ini. <br><br>  Dalam bab-bab berikutnya, fokusnya adalah memperluas model dengan set atribut yang lebih kaya dan membuat aplikasi analisis teks.  Pertama, kita akan melihat bagaimana kita dapat menyajikan dan menerapkan konteks dalam bentuk tanda-tanda, kemudian kita akan beralih ke interpretasi visual untuk mengontrol proses pemilihan model.  Kemudian kita akan melihat bagaimana menganalisis hubungan kompleks yang diekstraksi dari teks menggunakan teknik analisis grafik.  Setelah itu, kami mengalihkan perhatian kami ke agen interaktif dan memperdalam pemahaman kami tentang analisis sintaksis dan semantik teks.  Sebagai kesimpulan, buku ini akan menyajikan diskusi praktis tentang teknik penskalaan untuk analisis teks dalam sistem multiprosesor menggunakan Spark, dan akhirnya, kami akan mempertimbangkan tahap berikutnya dari analisis teks: pembelajaran mendalam. <br><br><h3>  Untuk siapa buku ini? </h3><br>  Buku ini ditulis untuk programmer Python yang tertarik menggunakan pemrosesan bahasa alami dan teknik pembelajaran mesin dalam produk perangkat lunak mereka.  Kami tidak berasumsi bahwa pembaca kami memiliki pengetahuan akademis atau matematika khusus, dan sebaliknya fokus pada alat dan teknik, daripada penjelasan panjang lebar.  Pertama-tama, buku ini membahas analisis teks dalam bahasa Inggris, sehingga pembaca akan membutuhkan setidaknya pengetahuan dasar tentang entitas tata bahasa seperti kata benda, kata kerja, kata kerja dan kata sifat, dan bagaimana mereka terkait.  Pembaca yang tidak memiliki pengalaman dalam pembelajaran mesin dan linguistik, tetapi dengan keterampilan pemrograman dengan Python, tidak akan merasa kehilangan dalam mempelajari konsep-konsep yang akan kami perkenalkan. <br><br><h3>  Kutipan.  Ekstrak grafik dari teks </h3><br>  Mengekstrak grafik dari teks adalah tugas yang sulit.  Solusinya biasanya tergantung pada area subjek, dan, secara umum, pencarian elemen terstruktur dalam data tidak terstruktur atau semi-terstruktur ditentukan oleh pertanyaan analitis yang peka konteks. <br><br>  Kami mengusulkan untuk memecah tugas ini menjadi langkah-langkah kecil dengan mengatur proses analisis grafik sederhana, seperti yang ditunjukkan pada Gambar.  9.3. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2k/f4/ce/2kf4cel7ri9mnaguprrfabt_qus.png" alt="gambar"></div><br>  Dalam proses ini, pertama-tama kita menentukan entitas dan hubungan di antara mereka, berdasarkan pada deskripsi tugas.  Selanjutnya, berdasarkan skema ini, kami menentukan metodologi untuk memilih grafik dari corpus menggunakan metadata, dokumen dalam corpus, dan frasa atau token dalam dokumen untuk mengekstrak data dan hubungan di antara mereka.  Teknik memilih grafik adalah proses siklik yang dapat diterapkan ke tubuh, menghasilkan grafik dan menyimpan grafik ini ke disk atau memori untuk diproses analitis lebih lanjut. <br><br>  Pada tahap analisis, perhitungan dilakukan pada grafik yang diekstraksi, misalnya pengelompokan, analisis struktural, penyaringan atau evaluasi, dan grafik baru dibuat, yang digunakan dalam aplikasi.  Berdasarkan hasil tahap analisis, kita dapat kembali ke awal siklus, memperjelas metodologi dan skema, mengekstrak atau meruntuhkan kelompok node atau tepi untuk mencoba mencapai hasil yang lebih akurat. <br><br><h3>  Membuat grafik sosial </h3><br>  Pertimbangkan tubuh artikel berita kita dan tugas memodelkan hubungan antara entitas yang berbeda dalam teks.  Jika kami mempertimbangkan masalah perbedaan liputan antara berbagai kantor berita, Anda dapat membuat grafik dari elemen-elemen yang mewakili nama publikasi, nama penulis, dan sumber informasi.  Dan jika tujuannya adalah untuk menggabungkan referensi ke satu entitas dalam banyak artikel, selain detail demografis, jaringan kami dapat memperbaiki bentuk banding (hormat dan lainnya).  Entitas yang menarik bagi kita dapat dalam struktur dokumen itu sendiri atau terkandung langsung dalam teks. <br><br>  Katakanlah tujuan kita adalah mencari tahu orang, tempat, dan hal lain yang terkait satu sama lain dalam dokumen kita.  Dengan kata lain, kita perlu membangun jejaring sosial dengan melakukan serangkaian transformasi, seperti yang ditunjukkan pada Gambar.  9.4.  Kami memulai konstruksi grafik menggunakan kelas EntityExtractor yang dibuat di Bab 7. Kemudian kami menambahkan transformer, salah satunya mencari pasangan entitas terkait, dan yang kedua mengubah pasangan ini menjadi grafik. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1f/uf/m7/1fufm7sghprbu87dmxa-zpllt3k.png" alt="gambar"></div><br>  <b>Cari pasangan entitas</b> <br><br>  Langkah selanjutnya adalah membuat kelas EntityPairs, yang menerima dokumen dalam bentuk daftar entitas (dibuat oleh kelas EntityExtractor dari Bab 7).  Kelas ini harus bertindak sebagai konverter dalam pipa Pipeline dari Scikit-Learn, dan oleh karena itu mewarisi kelas BaseEstimator dan TransformerMixin, seperti yang dijelaskan pada Bab 4. Diasumsikan bahwa entitas dalam dokumen yang sama saling terkait tanpa syarat, jadi kami menambahkan metode pasangan menggunakan fungsi itertools .permutasi untuk membuat semua pasangan entitas dalam satu dokumen.  Metode transformasi kami akan memanggil pasangan untuk setiap dokumen dalam tubuh: <br><br><pre><code class="plaintext hljs">import itertools from sklearn.base import BaseEstimator, TransformerMixin class EntityPairs(BaseEstimator, TransformerMixin): def __init__(self): super(EntityPairs, self).__init__() def pairs(self, document): return list(itertools.permutations(set(document), 2)) def fit(self, documents, labels = None): return self def transform(self, documents): return [self.pairs(document) for document in documents]</code> </pre> <br>  Sekarang Anda dapat mengekstrak entitas secara berurutan dari dokumen dan berpasangan.  Tetapi kita belum dapat membedakan pasangan entitas yang sering terjadi dari pasangan yang hanya terjadi sekali.  Kita harus entah bagaimana menyandikan bobot hubungan antara entitas dalam setiap pasangan, yang akan kita bahas di bagian selanjutnya. <br><br><h3>  Grafik Properti </h3><br>  Model matematika dari grafik hanya mendefinisikan set node dan edge dan dapat direpresentasikan sebagai matriks adjacency, yang dapat digunakan dalam berbagai perhitungan.  Tapi itu tidak mendukung mekanisme untuk memodelkan kekuatan atau jenis hubungan.  Apakah dua entitas hanya muncul dalam satu dokumen atau banyak?  Apakah mereka bertemu bersama dalam artikel dari genre tertentu?  Untuk mendukung alasan seperti itu, kita perlu beberapa cara untuk menyimpan properti yang bermakna di node dan tepi grafik. <br><br>  Model grafik properti memungkinkan Anda untuk menanamkan lebih banyak informasi dalam grafik, sehingga memperluas kemampuan kami.  Dalam grafik properti, node adalah objek dengan tepi masuk dan keluar dan, sebagai aturan, berisi bidang tipe, menyerupai tabel dalam database relasional.  Iga adalah objek yang menentukan titik awal dan akhir;  objek-objek ini biasanya berisi bidang label yang mengidentifikasi jenis koneksi, dan bidang berat yang menentukan kekuatan koneksi.  Menggunakan grafik untuk analisis teks, kita sering menggunakan kata benda sebagai node, dan kata kerja sebagai edge.  Setelah beralih ke langkah pemodelan, ini akan memungkinkan kami untuk menggambarkan jenis node, label tautan, dan struktur grafik yang diusulkan. <br><br><h3>  Tentang Penulis </h3><br>  Benjamin Bengfort adalah spesialis ilmu data yang berbasis di Washington, DC, yang sepenuhnya mengabaikan politik (hal yang umum untuk District of Columbia) dan lebih suka teknologi.  Dia saat ini sedang mengerjakan disertasi doktoralnya di University of Maryland, di mana dia mempelajari pembelajaran mesin dan komputasi terdistribusi.  Ada robot di laboratoriumnya (meskipun ini bukan area favoritnya), dan banyak yang kecewa, asistennya terus-menerus melengkapi robot ini dengan pisau dan peralatan, mungkin dengan tujuan memenangkan kompetisi kuliner.  Menonton robot yang mencoba memotong tomat, Benjamin lebih memilih untuk menjadi tuan rumah dapur sendiri, di mana ia memasak hidangan Prancis dan Hawaii, serta barbekyu dan barbekyu dalam segala jenis.  Seorang programmer pendidikan profesional, peneliti data panggilan, Benjamin sering menulis artikel yang mencakup berbagai topik, dari pemrosesan bahasa alami hingga analisis data dengan Python dan penggunaan Hadoop dan Spark dalam analitik. <br><br>  Rebecca Bilbro - spesialis ilmu data, programmer Python, guru, dosen, dan penulis artikel;  tinggal di Washington, DC.  Ini mengkhususkan diri dalam penilaian visual hasil pembelajaran mesin: dari analisis fitur hingga pemilihan model dan pengaturan parameter hiper.  Dia melakukan penelitian di bidang pemrosesan bahasa alami, membangun jaringan semantik, menyelesaikan entitas dan memproses informasi dengan sejumlah besar dimensi.  Sebagai peserta aktif dalam komunitas pengguna dan pengembang perangkat lunak open source, Rebecca senang bekerja dengan pengembang lain pada proyek-proyek seperti Yellowbrick (paket Python yang bertujuan untuk memprediksi pemodelan kotak hitam).  Di waktu senggangnya, ia sering mengendarai sepeda bersama keluarganya atau berlatih bermain ukulele.  Dia menerima gelar doktor dari University of Illinois, di Urbana-Champaign, di mana dia belajar komunikasi praktis dan teknik visualisasi. <br><br>  »Informasi lebih lanjut tentang buku ini dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">situs web penerbit</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Isi</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kutipan</a> <br><br>  Kupon diskon 20% untuk penjaja - <b>Python</b> <br><br>  Setelah pembayaran versi kertas buku, versi elektronik buku dikirim melalui email. <br><br>  PS: 7% dari biaya buku akan masuk ke terjemahan buku komputer baru, daftar buku yang diserahkan ke percetakan ada di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id444384/">https://habr.com/ru/post/id444384/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id444372/index.html">Orientasi mesin jarak jauh menggunakan pembelajaran yang diperkuat</a></li>
<li><a href="../id444374/index.html">Efek hipster: mengapa orang yang tidak patuh sering terlihat sama</a></li>
<li><a href="../id444376/index.html">Ekonomi perhatian hampir mati</a></li>
<li><a href="../id444378/index.html">USPACE - Ruang Tunggal untuk Pesawat Berawak dan Tidak Berawak</a></li>
<li><a href="../id444382/index.html">Bagaimana cara mengunjungi Universitas Korea dengan Sistem File Jaringan</a></li>
<li><a href="../id444386/index.html">Misi Lunar "Bereshit" - manuver keempat selesai dengan sukses, persiapan sedang dilakukan untuk memasuki orbit bulan</a></li>
<li><a href="../id444388/index.html">Modem legendaris masa lalu: pemegang koneksi terbaik dalam kondisi pertukaran domestik</a></li>
<li><a href="../id444390/index.html">DeviceLock 8.3 sistem DLP: satu tahun telah berlalu, Billy, tetapi Anda belum berubah sama sekali</a></li>
<li><a href="../id444392/index.html">Radiasi: risiko, keselamatan, perlindungan</a></li>
<li><a href="../id444394/index.html">Linux Foundation meluncurkan proyek DevOps baru dengan Jenkins dan Spinnaker</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
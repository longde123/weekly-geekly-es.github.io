<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå∫ üë®üèø‚ÄçüöÄ üå•Ô∏è Nous avons dix fois acc√©l√©r√© l'ordonnanceur Tokio üôÖüèæ ü§ôüèø üê¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous sommes en train de pr√©parer la prochaine version majeure de Tokio, un environnement d'ex√©cution asynchrone pour Rust. Le 13 octobre, une demande ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nous avons dix fois acc√©l√©r√© l'ordonnanceur Tokio</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/472242/"> Nous sommes en train de pr√©parer la prochaine version majeure de Tokio, un environnement d'ex√©cution asynchrone pour Rust.  Le 13 octobre, une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">demande de pool</a> avec un planificateur de t√¢ches compl√®tement r√©√©crit a √©t√© √©mise pour la fusion dans une branche.  Le r√©sultat sera d'√©normes am√©liorations de performances et une latence r√©duite.  Certains tests ont enregistr√© une acc√©l√©ration d√©cupl√©e!  Comme d'habitude, les tests synth√©tiques ne refl√®tent pas les avantages r√©els dans la r√©alit√©.  Par cons√©quent, nous avons √©galement v√©rifi√© comment les modifications du planificateur affectaient les t√¢ches r√©elles, telles que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hyper</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tonic</a> (spoiler: le r√©sultat est merveilleux). <br><br>  En me pr√©parant √† travailler sur un nouveau planificateur, j'ai pass√© du temps √† chercher des ressources th√©matiques.  Hormis les impl√©mentations r√©elles, rien de sp√©cial n'a √©t√© trouv√©.  J'ai √©galement constat√© que le code source des impl√©mentations existantes est difficile √† parcourir.  Pour r√©soudre ce probl√®me, nous avons essay√© d'√©crire le sheduler Tokio aussi proprement que possible.  J'esp√®re que cet article d√©taill√© sur la mise en ≈ìuvre du planificateur aidera ceux qui sont dans la m√™me position et qui cherchent sans succ√®s des informations sur ce sujet. <br><br>  L'article commence par un examen de haut niveau de la conception, y compris des politiques de capture des emplois.  Plongez ensuite dans les d√©tails des optimisations sp√©cifiques dans le nouveau planificateur Tokio. <br><a name="habracut"></a><br>  Optimisations envisag√©es: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nouveau syst√®me de t√¢ches std :: future</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Choisir le meilleur algorithme de file d'attente</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®les de message rationalis√©s</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Capture de l'acc√©l√©rateur</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©duisez la synchronisation entre les threads</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©duisez l'allocation de m√©moire</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nombre de liaisons atomiques r√©duit</a> </li></ul><br>  Comme vous pouvez le voir, le th√®me principal est la ¬´r√©duction¬ª.  Apr√®s tout, le code le plus rapide est son manque! <br><br>  Nous parlerons √©galement du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">test du nouveau planificateur</a> .  Il est tr√®s difficile d'√©crire le code parall√®le correct sans verrou.  Il vaut mieux travailler lentement, mais correctement, que rapidement, mais avec des probl√®mes, surtout si les bogues concernent la s√©curit√© de la m√©moire.  Cependant, la meilleure option devrait fonctionner rapidement et sans erreurs, nous avons donc √©crit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">loom</a> , un outil de test de concurrence. <br><br>  Avant de plonger dans le sujet, je tiens √† remercier: <br><br><ul><li> <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@withoutboats</a></b> et d'autres personnes qui ont travaill√© sur la fonction <code>async / await</code> √† Rust.  Tu as fait du bon travail.  Ceci est une fonctionnalit√© qui tue. <br></li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@cramertj</a></b> et d'autres qui ont d√©velopp√© <code>std::task</code> .  Il s'agit d'une √©norme am√©lioration par rapport √† ce qu'elle √©tait auparavant.  Et un excellent code. <br></li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Flottant</a></b> , le cr√©ateur de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Linkerd,</a> et plus important encore, mon employeur.  Merci de m'avoir permis de consacrer autant de temps √† ce travail.  Si quelqu'un s'int√©resse au maillage de service, jetez un ≈ìil √† Linkerd.  Bient√¥t, il inclura tous les avantages discut√©s dans cet article. <br></li><li>  <b><a href="">Optez</a></b> pour une telle bonne mise en ≈ìuvre du planificateur. </li></ul><br>  Prenez une tasse de caf√© et asseyez-vous.  Ce sera un long article. <br><br><h1>  Comment fonctionnent les planificateurs? </h1><br>  La t√¢che du sheduler est de planifier le travail.  L'application est divis√©e en unit√©s de travail, que nous appellerons <i>t√¢ches</i> .  Une t√¢che est consid√©r√©e comme ex√©cutable lorsqu'elle peut avancer dans son ex√©cution, mais n'est plus ex√©cut√©e ou en mode inactif, lorsqu'elle est verrouill√©e sur une ressource externe.  Les t√¢ches sont ind√©pendantes dans le sens o√π un nombre illimit√© de t√¢ches peuvent √™tre effectu√©es simultan√©ment.  Le planificateur est responsable de l'ex√©cution des t√¢ches dans un √©tat en cours d'ex√©cution jusqu'√† ce qu'elles reviennent en mode veille.  L'ex√©cution de la t√¢che implique d'affecter du temps processeur √† la t√¢che - une ressource globale. <br><br>  L'article d√©crit les planificateurs d'espace utilisateur, c'est-√†-dire qu'ils fonctionnent au-dessus des threads du syst√®me d'exploitation (qui, √† leur tour, sont contr√¥l√©s par un sheduler au niveau du noyau).  Le planificateur Tokio ex√©cute les futurs Rust, qui peuvent √™tre consid√©r√©s comme des ¬´fils verts asynchrones¬ª.  Il s'agit d'un mod√®le de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">streaming mixte M: N</a> dans lequel de nombreuses t√¢ches d'interface utilisateur sont multiplex√©es sur plusieurs threads du syst√®me d'exploitation. <br><br>  Il existe de nombreuses fa√ßons de simuler un sheduler, chacune avec ses avantages et ses inconv√©nients.  Au niveau le plus √©l√©mentaire, le planificateur peut √™tre mod√©lis√© comme une <i>file d'attente d'ex√©cution</i> et un <i>processeur</i> qui le s√©pare.  Un processeur est un morceau de code qui s'ex√©cute dans un thread.  En pseudo code, il fait ce qui suit: <br><br><pre> <code class="plaintext hljs">while let Some(task) = self.queue.pop() { task.run(); }</code> </pre> <br>  Lorsqu'une t√¢che devient r√©alisable, elle est ins√©r√©e dans la file d'attente d'ex√©cution. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ff6/1f4/18f/ff61f418f73f08c62b5e9eaeacaeb8ed.png"><br><br>  Bien que vous puissiez concevoir un syst√®me dans lequel des ressources, des t√¢ches et un processeur existent sur le m√™me thread, Tokio pr√©f√®re utiliser plusieurs threads.  Nous vivons dans un monde o√π un ordinateur poss√®de de nombreux processeurs.  Le d√©veloppement d'un ordonnanceur √† un seul fil conduira √† une charge insuffisante de fer.  Nous voulons utiliser tous les CPU.  Il existe plusieurs fa√ßons de proc√©der: <br><br><ul><li>  Une file d'attente d'ex√©cution globale, de nombreux processeurs. <br></li><li>  De nombreux processeurs, chacun avec sa propre file d'attente d'ex√©cution. </li></ul><br><h3>  Un tour, plusieurs processeurs </h3><br>  Ce mod√®le poss√®de une file d'attente d'ex√©cution globale.  Lorsque les t√¢ches sont termin√©es, elles sont plac√©es √† la fin de la file d'attente.  Il existe plusieurs processeurs, chacun dans un thread distinct.  Chaque processeur prend une t√¢che de la t√™te de la file d'attente ou bloque le thread s'il n'y a pas de t√¢ches disponibles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/85c/8d0/23d/85c8d023dfeba249bba01234e0e8783a.png"><br><br>  La ligne d'ex√©cution doit √™tre prise en charge par de nombreux fabricants et consommateurs.  Habituellement, une liste <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">intrusive</a> est utilis√©e, dans laquelle la structure de chaque t√¢che comprend un pointeur vers la t√¢che suivante dans la file d'attente (au lieu d'envelopper les t√¢ches dans une liste li√©e).  Ainsi, l'allocation de m√©moire pour les op√©rations push et pop peut √™tre √©vit√©e.  Vous pouvez utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'op√©ration push sans verrouillage</a> , mais pour coordonner les consommateurs, le mutex est requis pour l'op√©ration pop (il est techniquement possible d'impl√©menter une file d'attente multi-utilisateurs sans verrouillage). <br><br>  Cependant, dans la pratique, la surcharge pour une protection ad√©quate contre les verrous est plus que l'utilisation d'un mutex. <br><br>  Cette approche est souvent utilis√©e pour un pool de threads √† usage g√©n√©ral, car elle pr√©sente plusieurs avantages: <br><br><ul><li>  Les t√¢ches sont assez planifi√©es. <br></li><li>  Impl√©mentation relativement simple.  Une file d'attente plus ou moins standard est interfac√©e avec le cycle du processeur d√©crit ci-dessus. </li></ul><br>  Une br√®ve note sur une planification juste (√©quitable).  Cela signifie que les t√¢ches sont ex√©cut√©es honn√™tement: celui qui est venu plus t√¥t est celui qui est parti plus t√¥t.  Les planificateurs √† usage g√©n√©ral essaient d'√™tre justes, mais il existe des exceptions, telles que la parall√©lisation via la jointure en fourche, o√π la vitesse de calcul du r√©sultat, plut√¥t que la justice pour chaque sous-t√¢che individuelle, est un facteur important. <br><br>  Ce mod√®le a un inconv√©nient.  Tous les processeurs postulent pour des t√¢ches depuis le d√©but de la file d'attente.  Pour les threads √† usage g√©n√©ral, ce n'est g√©n√©ralement pas un probl√®me.  Le temps pour terminer une t√¢che d√©passe de loin le temps pour la r√©cup√©rer de la file d'attente.  Lorsque les t√¢ches sont effectu√©es sur une longue p√©riode de temps, la concurrence dans la file d'attente est r√©duite.  Toutefois, les t√¢ches Rust asynchrones devraient se terminer tr√®s rapidement.  Dans ce cas, les frais g√©n√©raux pour le combat dans la file d'attente augmentent consid√©rablement. <br><br><h3>  Concurrence et sympathie m√©canique </h3><br>  Pour atteindre des performances maximales, nous devons tirer le meilleur parti des fonctionnalit√©s mat√©rielles.  Le terme ¬´sympathie m√©canique¬ª pour les logiciels a √©t√© utilis√© pour la premi√®re fois par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Martin Thompson</a> (dont le blog n'est plus mis √† jour, mais toujours tr√®s informatif). <br><br>  Une discussion d√©taill√©e de la mise en ≈ìuvre du parall√©lisme dans les √©quipements modernes d√©passe le cadre de cet article.  De mani√®re g√©n√©rale, le fer augmente la productivit√© non pas en raison de l'acc√©l√©ration, mais en raison de l'introduction d'un plus grand nombre de c≈ìurs de processeur (m√™me mon ordinateur portable en a six!) Chaque c≈ìur peut effectuer de grandes quantit√©s de calcul dans des intervalles de temps minuscules.  Des actions telles que l'acc√®s au cache et √† la m√©moire prennent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">beaucoup plus de temps par</a> rapport au temps d'ex√©cution sur le CPU.  Par cons√©quent, pour acc√©l√©rer les applications, vous devez maximiser le nombre d'instructions du processeur pour chaque acc√®s √† la m√©moire.  Bien que le compilateur aide beaucoup, nous devons encore penser √† des choses comme l'alignement et les mod√®les d'acc√®s √† la m√©moire. <br><br>  Les threads s√©par√©s fonctionnent de mani√®re tr√®s similaire √† un seul thread isol√©, <b>jusqu'√† ce que</b> plusieurs threads modifient simultan√©ment la m√™me ligne de cache (mutations simultan√©es) ou qu'une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">coh√©rence coh√©rente</a> soit requise.  Dans ce cas, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">protocole de coh√©rence du cache CPU est</a> activ√©.  Il garantit la pertinence du cache de chaque CPU. <br><br>  La conclusion est √©vidente: dans la mesure du possible, √©vitez la synchronisation entre les threads, car elle est lente. <br><br><h3>  De nombreux processeurs, chacun avec sa propre file d'attente d'ex√©cution </h3><br>  Un autre mod√®le est plusieurs planificateurs monothread.  Chaque processeur re√ßoit sa propre file d'attente d'ex√©cution et les t√¢ches sont fix√©es sur un processeur sp√©cifique.  Cela √©vite compl√®tement le probl√®me de synchronisation.  √âtant donn√© que le mod√®le de t√¢che Rust n√©cessite la possibilit√© de mettre une t√¢che en file d'attente √† partir de n'importe quel thread, il devrait toujours y avoir un moyen s√ªr pour les threads d'entrer des t√¢ches dans le planificateur.  Soit la file d'attente d'ex√©cution de chaque processeur prend en charge le fonctionnement push-thread-safe (MPSC), soit chaque processeur poss√®de <b>deux</b> files d'attente d'ex√©cution: non synchronis√©es et thread-safe. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c6d/a3c/35e/c6da3c35e7f6fb28b63fdb3ff6417882.png"><br><br>  Cette strat√©gie utilise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Seastar</a> .  Comme nous √©vitons presque compl√®tement la synchronisation, cette strat√©gie donne une tr√®s bonne vitesse.  Mais elle ne r√©sout pas tous les probl√®mes.  Si la charge de travail n'est pas compl√®tement homog√®ne, alors certains processeurs sont sous charge, tandis que d'autres sont inactifs, ce qui conduit √† une utilisation non optimale des ressources.  Cela se produit car les t√¢ches sont fix√©es sur un processeur sp√©cifique.  Lorsqu'un groupe de t√¢ches est planifi√© dans un package sur un processeur, il remplit √† lui seul la charge de pointe, m√™me si d'autres sont inactives. <br><br>  La plupart des charges de travail ¬´r√©elles¬ª ne sont pas homog√®nes.  Par cons√©quent, les planificateurs √† usage g√©n√©ral √©vitent g√©n√©ralement ce mod√®le. <br><br><h3>  Planificateur de capture des travaux </h3><br>  Le planificateur avec des planificateurs de vol de travail est bas√© sur le mod√®le de planificateur fragment√© et r√©sout le probl√®me du chargement incomplet des ressources mat√©rielles.  Chaque processeur prend en charge sa propre file d'attente d'ex√©cution.  Les t√¢ches qui sont ex√©cut√©es sont plac√©es dans la file d'attente d'ex√©cution du processeur actuel, et cela fonctionne dessus.  Mais lorsque le processeur est inactif, il v√©rifie les files d'attente du processeur fr√®re et essaie de r√©cup√©rer quelque chose √† partir de l√†.  Le processeur ne passe en mode veille qu'apr√®s avoir √©t√© incapable de trouver du travail dans les files d'attente d'ex√©cution d'√©gal √† √©gal. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/561/9a9/02c/5619a902c1d95252d20ac7db1273e57f.png"><br><br>  Au niveau du mod√®le, c'est l'approche du ¬´meilleur des deux mondes¬ª.  Sous charge, les processeurs fonctionnent ind√©pendamment, √©vitant la synchronisation des frais g√©n√©raux.  Dans les cas o√π la charge entre les processeurs est r√©partie de mani√®re in√©gale, le planificateur peut la redistribuer.  C'est pourquoi ces ordonnanceurs sont utilis√©s dans <a href="">Go</a> , <a href="">Erlang</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Java</a> et d'autres langages. <br><br>  L'inconv√©nient est que cette approche est beaucoup plus compliqu√©e.  L'algorithme de file d'attente doit prendre en charge la capture des travaux et, pour une ex√©cution fluide, <b>une</b> synchronisation entre les processeurs est requise.  S'il n'est pas correctement impl√©ment√©, la surcharge pour la capture peut √™tre sup√©rieure au gain. <br><br>  Consid√©rez cette situation: le processeur A ex√©cute actuellement une t√¢che et il a une file d'attente d'ex√©cution vide.  Le processeur B est inactif;  il essaie de capturer une t√¢che, mais √©choue, alors il passe en mode veille.  Ensuite, 20 t√¢ches sont g√©n√©r√©es √† partir de la t√¢che du processeur A.  Id√©alement, le processeur B devrait se r√©veiller et en r√©cup√©rer quelques-uns.  Pour cela, il est n√©cessaire d'impl√©menter certaines heuristiques dans le planificateur, o√π les processeurs signalent aux processeurs homologues endormis l'apparition de nouvelles t√¢ches dans leur file d'attente.  Bien s√ªr, cela n√©cessite une synchronisation suppl√©mentaire, de sorte que de telles op√©rations sont mieux minimis√©es. <br><br>  En r√©sum√©: <br><br><ul><li>  Moins il y a de synchronisation, mieux c'est. <br></li><li>  La capture des travaux est l'algorithme optimal pour les planificateurs √† usage g√©n√©ral. <br></li><li>  Chaque processeur fonctionne ind√©pendamment des autres, mais une synchronisation est n√©cessaire pour capturer le travail. </li></ul><br><h1>  Planificateur Tokio 0.1 </h1><br>  Le premier planificateur fonctionnel pour Tokio a √©t√© publi√© en mars 2018.  Il s'agissait de la premi√®re tentative, bas√©e sur certaines hypoth√®ses qui se sont r√©v√©l√©es fausses. <br><br>  Premi√®rement, le planificateur Tokio 0.1 a sugg√©r√© que les threads du processeur soient ferm√©s s'ils √©taient inactifs pendant un certain temps.  Le planificateur a √©t√© cr√©√© √† l'origine comme un syst√®me "√† usage g√©n√©ral" pour le pool de threads Rust.  A cette √©poque, le runtime Tokio √©tait encore √† un stade pr√©coce de d√©veloppement.  Ensuite, le mod√®le a suppos√© que les t√¢ches d'E / S seraient effectu√©es sur le m√™me thread que le s√©lecteur d'E / S (epoll, kqueue, iocp ...).  Plus de t√¢ches de calcul pourraient √™tre dirig√©es vers le pool de threads.  Dans ce contexte, une configuration flexible du nombre de threads actifs est suppos√©e, il est donc plus logique de d√©sactiver les threads inactifs.  Cependant, dans le planificateur avec capture de travail, le mod√®le est pass√© √† l'ex√©cution de <i>toutes</i> les t√¢ches asynchrones et, dans ce cas, il est logique de toujours conserver un petit nombre de threads √† l'√©tat actif. <br><br>  Deuxi√®mement, une ligne de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">croisement</a> bidirectionnelle y a √©t√© mise en place.  Cette impl√©mentation est bas√©e sur la ligne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bidirectionnelle Chase-Lev</a> et ne convient pas √† la planification de t√¢ches asynchrones ind√©pendantes pour les raisons d√©crites ci-dessous. <br><br>  Troisi√®mement, la mise en ≈ìuvre s'est av√©r√©e trop compliqu√©e.  Cela est d√ª en partie au fait qu'il s'agissait de mon premier planificateur de t√¢ches.  De plus, j'√©tais trop impatient lorsque j'utilisais l'atomique dans les branches, o√π le mutex aurait fait l'affaire.  Une le√ßon importante est que, tr√®s souvent, ce sont les mutex qui fonctionnent le mieux. <br><br>  Enfin, il y avait de nombreux d√©fauts mineurs dans la mise en ≈ìuvre initiale.  Au cours des premi√®res ann√©es, les d√©tails de mise en ≈ìuvre du mod√®le asynchrone de Rust ont consid√©rablement √©volu√©, mais les biblioth√®ques ont maintenu l'API stable √† tout moment.  Cela a conduit √† l'accumulation d'une partie de la dette technique. <br><br>  Tokio approche maintenant de la premi√®re version majeure - et nous pouvons payer toute cette dette, ainsi que tirer parti de l'exp√©rience acquise au cours des ann√©es de d√©veloppement.  C'est une p√©riode passionnante! <br><br><h1>  Planificateur Tokio de nouvelle g√©n√©ration </h1><br>  Il est maintenant temps de regarder de plus pr√®s ce qui a chang√© dans le nouveau planificateur. <br><br><a name="1"></a><h3>  Nouveau syst√®me de t√¢ches </h3><br>  Premi√®rement, il est important de souligner ce qui <b>ne</b> fait <b>pas</b> partie de Tokio, mais qui est crucial en termes d'am√©lioration de l'efficacit√©: il s'agit d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nouveau syst√®me de t√¢ches</a> en <code>std</code> , d√©velopp√© √† l'origine par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Taylor Kramer</a> .  Ce syst√®me fournit les crochets que le planificateur doit impl√©menter pour effectuer des t√¢ches Rust asynchrones, et le syst√®me est vraiment superbement con√ßu et impl√©ment√©.  Il est beaucoup plus l√©ger et plus flexible que l'it√©ration pr√©c√©dente. <br><br>  La structure <code>Waker</code> partir des ressources signale qu'une t√¢che <i>r√©alisable</i> doit √™tre plac√©e dans la file d'attente du planificateur.  Dans le nouveau syst√®me de t√¢ches, il s'agit d'une structure √† deux points, alors qu'auparavant elle √©tait beaucoup plus grande.  La r√©duction de la taille est importante pour minimiser la surcharge de copie de la valeur <code>Waker</code> √† diff√©rents endroits, et elle prend moins de place dans les structures, ce qui vous permet de compresser des donn√©es plus importantes dans la ligne de cache.  La conception de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vtable</a> a fait un certain nombre d'optimisations, dont nous discuterons plus tard. <br><br><a name="2"></a><h3>  Choisir le meilleur algorithme de file d'attente </h3><br>  La file d'attente d'ex√©cution se trouve au centre du planificateur.  Par cons√©quent, c'est le composant le plus important √† corriger.  L'ordonnanceur Tokio d'origine utilisait une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">file d'attente √†</a> double <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">faisceau crois√©</a> : une impl√©mentation √† source unique (producteur) et de nombreux consommateurs.  Une t√¢che est plac√©e √† une extr√©mit√© et les valeurs sont r√©cup√©r√©es de l'autre.  La plupart du temps, le thread ¬´pousse¬ª les valeurs depuis la fin de la file d'attente, mais parfois d'autres threads interceptent le travail, effectuant la m√™me op√©ration.  La file d'attente bidirectionnelle est prise en charge par un tableau et un ensemble d'index qui suivent la t√™te et la queue.  Lorsque la file d'attente est pleine, son introduction entra√Ænera une augmentation de l'espace de stockage.  Un nouveau tableau plus grand est allou√© et les valeurs sont d√©plac√©es vers le nouveau stockage. <br><br>  La capacit√© de croissance est obtenue gr√¢ce √† la complexit√© et aux frais g√©n√©raux.  Les op√©rations push / pop devraient tenir compte de cette croissance.  De plus, la lib√©ration de la baie d'origine est source de difficult√©s suppl√©mentaires.  Dans un langage de r√©cup√©ration de place (GC), l'ancien tableau sera hors de port√©e et, √©ventuellement, le GC l'effacera.  Cependant, Rust est livr√© sans GC.  Cela signifie que nous sommes nous-m√™mes responsables de la lib√©ration du tableau, mais les threads peuvent essayer d'acc√©der √† la m√©moire en m√™me temps.  Pour r√©soudre ce probl√®me, la traverse utilise une strat√©gie de r√©cup√©ration bas√©e sur l'√©poque.  Bien qu'il ne n√©cessite pas beaucoup de ressources, il ajoute une surcharge non triviale au chemin principal (hot path).  Chaque op√©ration doit maintenant effectuer des op√©rations atomiques RMW (lecture-modification-√©criture) √† l'entr√©e et √† la sortie des sections critiques pour signaler aux autres threads que la m√©moire est en cours d'utilisation et ne peut pas √™tre effac√©e. <br><br>  En raison des frais g√©n√©raux li√©s √† la croissance de la file d'attente d'ex√©cution, il est logique de penser: le support de cette croissance est-il vraiment n√©cessaire?  Cette question m'a finalement incit√© √† r√©√©crire le planificateur.  La nouvelle strat√©gie consiste √† avoir une taille de file d'attente fixe pour chaque processus.  Lorsque la file d'attente est pleine, au lieu d'augmenter la file d'attente locale, la t√¢che se d√©place vers la file d'attente globale avec plusieurs consommateurs et plusieurs producteurs.  Les processeurs v√©rifieront p√©riodiquement cette file d'attente globale, mais √† une fr√©quence bien inf√©rieure √† celle locale. <br><br>  Dans le cadre de l'une des premi√®res exp√©riences, nous avons remplac√© la traverse par du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mpmc</a> .  Cela n'a pas conduit √† une am√©lioration significative en raison de la quantit√© de synchronisation pour le push et le pop.  La cl√© pour capturer le travail est qu'il n'y a presque pas de concurrence dans les files d'attente sous charge, car chaque processeur n'a acc√®s qu'√† sa propre file d'attente. <br><br>  √Ä ce stade, j'ai d√©cid√© d'√©tudier attentivement les sources Go - et j'ai constat√© qu'elles utilisent une taille de file d'attente fixe avec un fabricant et plusieurs consommateurs, avec une synchronisation minimale, ce qui est tr√®s impressionnant.  Pour adapter l'algorithme au planificateur Tokio, j'ai apport√© quelques modifications.  Il est √† noter que l'impl√©mentation Go utilise des op√©rations atomiques s√©quentielles (si je comprends bien).  La version Tokio r√©duit √©galement le nombre de certaines op√©rations de copie dans des branches de code plus rares. <br><br>  Une impl√©mentation de file d'attente est un tampon circulaire qui stocke des valeurs dans un tableau.  La t√™te et la queue de la file d'attente sont suivies par des op√©rations atomiques avec des valeurs enti√®res. <br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Queue</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">/// Concurrently updated by many threads. head: AtomicU32, /// Only updated by producer thread but read by many threads. tail: AtomicU32, /// Masks the head / tail position value to obtain the index in the buffer. mask: usize, /// Stores the tasks. buffer: Box&lt;[MaybeUninit&lt;Task&gt;]&gt;, }</span></span></code> </pre> <br>  La mise en file d'attente est effectu√©e par un seul thread: <br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">loop</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> head = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.head.load(Acquire); <span class="hljs-comment"><span class="hljs-comment">// safety: this is the **only** thread that updates this cell. let tail = self.tail.unsync_load(); if tail.wrapping_sub(head) &lt; self.buffer.len() as u32 { // Map the position to a slot index. let idx = tail as usize &amp; self.mask; // Don't drop the previous value in `buffer[idx]` because // it is uninitialized memory. self.buffer[idx].as_mut_ptr().write(task); // Make the task available self.tail.store(tail.wrapping_add(1), Release); return; } // The local buffer is full. Push a batch of work to the global // queue. match self.push_overflow(task, head, tail, global) { Ok(_) =&gt; return, // Lost the race, try again Err(v) =&gt; task = v, } }</span></span></code> </pre> <br>  Notez que dans cette fonction <code>push</code> , les seules op√©rations atomiques sont le chargement avec la commande <code>Acquire</code> et l'enregistrement avec la commande <code>Release</code> .  Il n'y a pas d'op√©rations RMW ( <code>compare_and_swap</code> , <code>fetch_and</code> ...) ni ordre s√©quentiel, comme pr√©c√©demment.  Ceci est important car sur les puces x86, tous les t√©l√©chargements / sauvegardes sont d√©j√† ¬´atomiques¬ª.  Ainsi, au niveau CPU, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette fonction ne sera pas synchronis√©e</a> .  Les op√©rations atomiques emp√™cheront certaines optimisations dans le compilateur, mais c'est tout.  Tr√®s probablement, la premi√®re op√©ration de <code>load</code> pourrait √™tre effectu√©e en toute s√©curit√© avec une commande <code>Relaxed</code> , mais le remplacement ne comporte pas de frais g√©n√©raux notables. <br><br>  Lorsque la file d'attente est pleine, <code>push_overflow</code> est <code>push_overflow</code> .<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cette fonction d√©place la moiti√© des t√¢ches de la file d'attente locale vers la file globale. La file d'attente globale est une liste intrusive prot√©g√©e par un mutex. Lors du d√©placement vers la file d'attente globale, les t√¢ches sont d'abord li√©es entre elles, puis un mutex est cr√©√© et toutes les t√¢ches sont ins√©r√©es en mettant √† jour le pointeur sur la queue de la file d'attente globale. Cela permet d'√©conomiser une petite taille de section critique. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si vous connaissez les d√©tails de la commande de la m√©moire atomique, vous pouvez remarquer un ¬´probl√®me¬ª potentiel avec la fonction indiqu√©e ci-dessus </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. L'op√©ration de </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">commande </font><font style="vertical-align: inherit;">atomique est </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">plut√¥t faible. Il peut renvoyer des valeurs obsol√®tes, c'est-√†-dire qu'une op√©ration de capture parall√®le peut d√©j√† augmenter la valeur </font></font><code>self.head</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, mais dans le cache de flux</font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l'ancienne valeur restera, elle ne remarquera donc pas l'op√©ration de capture. Ce n'est pas un probl√®me avec l'exactitude de l'algorithme. De mani√®re principale (rapide), </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nous nous soucions uniquement de savoir si la file d'attente locale est pleine ou non. √âtant donn√© que seul le thread actuel peut pousser la file d'attente, une op√©ration obsol√®te </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rendra simplement la file d'attente plus pleine qu'elle ne l'est r√©ellement. Il peut d√©terminer de mani√®re incorrecte que la file d'attente est pleine et provoquer </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, mais cette fonction inclut une op√©ration atomique plus puissante. S'il </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d√©termine que la file d'attente n'est pas r√©ellement pleine, renvoie ensuite w / </font></font><code>Err</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et l'op√©ration </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">recommence. C‚Äôest une autre raison pour laquelle</font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d√©place la moiti√© de la file d'attente d'ex√©cution vers la file d'attente globale. </font><font style="vertical-align: inherit;">Apr√®s ce mouvement, ces faux positifs se produisent beaucoup moins fr√©quemment. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Local </font></font><code>pop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(√† partir du processeur auquel appartient la file d'attente) est √©galement impl√©ment√© simplement:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">loop</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> head = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.head.load(Acquire); <span class="hljs-comment"><span class="hljs-comment">// safety: this is the **only** thread that updates this cell. let tail = self.tail.unsync_load(); if head == tail { // queue is empty return None; } // Map the head position to a slot index. let idx = head as usize &amp; self.mask; let task = self.buffer[idx].as_ptr().read(); // Attempt to claim the task read above. let actual = self .head .compare_and_swap(head, head.wrapping_add(1), Release); if actual == head { return Some(task.assume_init()); } }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cette fonction, un atomique </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et un </font></font><code>compare_and_swap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s </font></font><code>Release</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Les frais g√©n√©raux principaux proviennent de </font></font><code>compare_and_swap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La fonction </font></font><code>steal</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est similaire √† </font></font><code>pop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, mais la </font></font><code>self.tail</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">charge atomique doit √™tre transf√©r√©e </font><font style="vertical-align: inherit;">de </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">De plus, de la m√™me mani√®re </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, l'op√©ration </font></font><code>steal</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tente de faire semblant d'√™tre la moiti√© de la file d'attente au lieu d'une seule t√¢che. </font><font style="vertical-align: inherit;">Cela a un bon effet sur les performances, dont nous discuterons plus tard.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La derni√®re partie manquante est l'analyse de la file d'attente globale, qui re√ßoit les t√¢ches qui d√©passent les files d'attente locales, ainsi que le transfert des t√¢ches vers le planificateur √† partir de threads non processeur. </font><font style="vertical-align: inherit;">Si le processeur est sous charge, c'est-√†-dire qu'il y a des t√¢ches dans la file d'attente locale, le processeur essaiera de retirer des t√¢ches de la file d'attente globale apr√®s environ 60 t√¢ches dans la file d'attente locale. </font><font style="vertical-align: inherit;">Il v√©rifie √©galement la file d'attente globale lorsqu'elle est dans l'√©tat de ¬´recherche¬ª d√©crit ci-dessous.</font></font><br><br><a name="3"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mod√®les de message rationalis√©s </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les applications Tokio se composent g√©n√©ralement de nombreuses petites t√¢ches ind√©pendantes. Ils interagissent entre eux √† travers des messages. Un tel mod√®le est similaire √† d'autres langues telles que Go et Erlang. √âtant donn√© la fr√©quence √† laquelle le mod√®le est courant, il est logique que le planificateur l'optimise. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Supposons que les t√¢ches A et B soient donn√©es. La t√¢che A est en cours d'ex√©cution et envoie un message √† la t√¢che B sur le canal de transmission. Un canal est une ressource sur laquelle la t√¢che B est actuellement verrouill√©e, donc l'action d'envoyer un message entra√Ænera la transition de la t√¢che B vers un √©tat ex√©cutable - et elle sera plac√©e dans la file d'attente d'ex√©cution du processeur actuel. Ensuite, le processeur d√©duira la t√¢che suivante de la file d'attente d'ex√©cution, l'ex√©cutera et r√©p√©tera ce cycle jusqu'√† ce qu'il atteigne la t√¢che B.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le probl√®me est qu'il peut y avoir un d√©lai important entre l'envoi d'un message et la fin de la t√¢che B. </font><font style="vertical-align: inherit;">En outre, les donn√©es chaudes, comme un message, sont stock√©es dans le cache du processeur, mais au moment o√π la t√¢che est termin√©e, il est probable que les caches correspondants seront effac√©s. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour r√©soudre ce probl√®me, le nouveau planificateur Tokio impl√©mente l'optimisation (comme dans les planificateurs Go et Kotlin). </font><font style="vertical-align: inherit;">Lorsqu'une t√¢che passe dans un √©tat ex√©cutable, elle n'est pas plac√©e √† la fin de la file d'attente, mais est stock√©e dans un emplacement sp√©cial ¬´t√¢che suivante¬ª. </font><font style="vertical-align: inherit;">Le processeur v√©rifie toujours cet emplacement avant de v√©rifier la file d'attente. </font><font style="vertical-align: inherit;">S'il existe d√©j√† une ancienne t√¢che lors de l'insertion dans l'emplacement, elle est supprim√©e de l'emplacement et se d√©place √† la fin de la file d'attente. </font><font style="vertical-align: inherit;">Ainsi, la t√¢che de transmission d'un message sera achev√©e pratiquement sans d√©lai.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/12f/e12/a32/12fe12a324d1855a6c62cacd56cb4f70.png"><br><br><a name="4"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Capture de l'acc√©l√©rateur </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans un planificateur de capture de travaux, si la file d'attente d'ex√©cution du processeur est vide, le processeur tente de capturer des t√¢ches √† partir de CPU homologues. Tout d'abord, un processeur homologue al√©atoire est s√©lectionn√©, si aucune t√¢che n'est trouv√©e pour lui, la suivante est recherch√©e, et ainsi de suite, jusqu'√† ce que des t√¢ches soient trouv√©es. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En pratique, plusieurs processeurs terminent souvent le traitement de la file d'attente d'ex√©cution √† peu pr√®s en m√™me temps. Cela se produit lorsqu'un package de t√¢ches arrive (par exemple, lorsque</font></font><code>epoll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">interrog√© pour savoir si le socket est pr√™t). Les processeurs se r√©veillent, re√ßoivent des t√¢ches, les d√©marrent et terminent. Cela conduit au fait que tous les processeurs tentent simultan√©ment de capturer les t√¢ches d'autres personnes, c'est-√†-dire que de nombreux threads tentent d'acc√©der aux m√™mes files d'attente. Il y a un conflit. Un choix al√©atoire du point de d√©part permet de r√©duire la concurrence, mais la situation n'est toujours pas tr√®s bonne. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour contourner ce probl√®me, le nouveau planificateur limite le nombre de processeurs parall√®les qui effectuent des op√©rations de capture. Nous appelons l'√©tat du processeur dans lequel il essaie de capturer les t√¢ches des autres ¬´recherche d'emploi¬ª ou ¬´recherche¬ª pour faire court (plus de d√©tails plus loin). Une telle optimisation est effectu√©e en utilisant la valeur atomique</font></font><code>int</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, que le processeur augmente avant de lancer la recherche et diminue √† la sortie de l'√©tat de recherche. </font><font style="vertical-align: inherit;">Un maximum de la moiti√© du nombre total de processeurs peut √™tre en √©tat de recherche. </font><font style="vertical-align: inherit;">Autrement dit, la limite approximative est d√©finie, ce qui est normal. </font><font style="vertical-align: inherit;">Nous n'avons pas besoin d'une limite stricte sur le nombre de processeurs dans la recherche, juste la limitation. </font><font style="vertical-align: inherit;">Nous sacrifions la pr√©cision pour l'efficacit√© de l'algorithme. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apr√®s √™tre entr√© dans l'√©tat de recherche, le processeur tente de capturer le travail √† partir des CPU homologues et v√©rifie la file d'attente globale.</font></font><br><br><a name="5"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Diminue la synchronisation entre les threads </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une autre partie importante du planificateur consiste √† notifier les processeurs homologues de nouvelles t√¢ches. Si le "fr√®re" dort, il se r√©veille et capture les t√¢ches. Les notifications jouent un autre r√¥le important. Rappelons que l'algorithme de file d'attente utilise un ordre atomique faible ( </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">/ </font></font><code>Release</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">). En raison de l'allocation atomique de la m√©moire, rien ne garantit qu'un processeur homologue verra jamais les t√¢ches dans la file d'attente sans synchronisation suppl√©mentaire. Par cons√©quent, les notifications en sont √©galement responsables. Pour cette raison, les notifications deviennent ch√®res. Le but est de minimiser leur nombre afin de ne pas utiliser les ressources CPU, c'est-√†-dire que le processeur a des t√¢ches et que le fr√®re ne peut pas les voler. Un nombre excessif de notifications conduit √† </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un probl√®me de troupeau de tonnerre</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le planificateur original de Tokio a adopt√© une approche na√Øve des notifications. Chaque fois qu'une nouvelle t√¢che √©tait plac√©e dans la file d'attente d'ex√©cution, le processeur recevait une notification. Chaque fois que le CPU a √©t√© averti et a vu la t√¢che apr√®s s'√™tre r√©veill√©, il a notifi√© un autre CPU. Cette logique a tr√®s rapidement conduit tous les processeurs √† se r√©veiller et √† chercher du travail (provoquant un conflit). Souvent, la plupart des transformateurs ne trouvaient pas de travail et se rendormaient.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le nouveau planificateur a consid√©rablement am√©lior√© ce mod√®le, similaire au planificateur Go. Les notifications sont envoy√©es comme pr√©c√©demment, mais uniquement s'il n'y a pas de CPU dans l'√©tat de recherche (voir la section pr√©c√©dente). Lorsque le processeur re√ßoit une notification, il entre imm√©diatement dans l'√©tat de recherche. Lorsque le processeur dans l'√©tat de recherche trouve de nouvelles t√¢ches, il quitte d'abord l'√©tat de recherche, puis avertit l'autre processeur. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cette logique limite la vitesse √† laquelle les processeurs se r√©veillent. Si un ensemble de t√¢ches est planifi√© imm√©diatement (par exemple, lorsque</font></font><code>epoll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">interrog√© pour savoir si le socket est pr√™t), la premi√®re t√¢che entra√Ænera une notification au processeur. </font><font style="vertical-align: inherit;">Il est maintenant en √©tat de recherche. </font><font style="vertical-align: inherit;">Les t√¢ches planifi√©es restantes dans le package n'informeront pas le processeur, car il y a au moins un processeur √† l'√©tat de recherche. </font><font style="vertical-align: inherit;">Ce processeur notifi√© capturera la moiti√© des t√¢ches du lot et, √† son tour, notifiera l'autre processeur. </font><font style="vertical-align: inherit;">Un troisi√®me processeur se r√©veille, trouve les t√¢ches de l'un des deux premiers processeurs et en capture la moiti√©. </font><font style="vertical-align: inherit;">Cela conduit √† une augmentation en douceur du nombre de processeurs de travail, ainsi qu'√† un √©quilibrage de charge rapide.</font></font><br><br><a name="6"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> R√©duisez l'allocation de m√©moire </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le nouveau planificateur Tokio ne n√©cessite qu'une seule allocation de m√©moire pour chaque t√¢che g√©n√©r√©e, tandis que l'ancienne en demandait deux. </font><font style="vertical-align: inherit;">Auparavant, la structure des t√¢ches ressemblait √† ceci:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">/// All state needed to manage the task state: TaskState, /// The logic to run is represented as a future trait object. future: Box&lt;dyn Future&lt;Output = ()&gt;&gt;, }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La structure </font></font><code>Task</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sera √©galement mise en √©vidence dans </font></font><code>Box</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Pendant tr√®s longtemps, j'ai voulu r√©parer ce joint (j'ai essay√© pour la premi√®re fois en 2014). Deux choses ont chang√© depuis l'ancien planificateur Tokio. Tout d'abord, stabilis√© </font></font><code>std::alloc</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Deuxi√®mement, le futur syst√®me de t√¢ches est pass√© √† une </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">strat√©gie</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> explicite de </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">table</font></a><font style="vertical-align: inherit;"> . Ce sont ces deux choses qui manquaient, enfin, pour se d√©barrasser de l'allocation de m√©moire double inefficace pour chaque t√¢che. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maintenant, la structure </font></font><code>Task</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est pr√©sent√©e sous la forme suivante:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span></span>&lt;T&gt; { header: Header, future: T, trailer: Trailer, }</code> </pre> <br>     <code>Header</code> ,  <code>Trailer</code> ,     ¬´¬ª  ()  ¬´¬ª (), . .   ,    ,  ,   . ¬´¬ª          .     ,      ( 64  128 ).  ,        . <br><br><a name="7"></a><h3>     </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La derni√®re optimisation dont nous discutons dans cet article est de r√©duire le nombre de liens atomiques. Il existe de nombreuses r√©f√©rences √† la structure de la t√¢che, y compris du planificateur et de chaque waker. La strat√©gie g√©n√©rale de gestion de cette m√©moire est </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le comptage de liens atomiques</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Cette strat√©gie n√©cessite une op√©ration atomique chaque fois qu'un lien est clon√© et chaque fois qu'un lien est supprim√©. Lorsque le dernier lien sort du domaine, la m√©moire est lib√©r√©e. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans l'ancien planificateur Tokio, le planificateur et tous les wakers contenaient un lien vers un descripteur de t√¢che, approximativement:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Waker</span></span></span></span> { task: Arc&lt;Task&gt;, } <span class="hljs-keyword"><span class="hljs-keyword">impl</span></span> Waker { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake</span></span></span></span>(&amp;<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> task = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task.clone(); task.scheduler.schedule(task); } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lorsque la t√¢che se r√©veille, le lien est clon√© (un incr√©ment atomique se produit). </font><font style="vertical-align: inherit;">Ensuite, le lien est plac√© dans la file d'attente d'ex√©cution. </font><font style="vertical-align: inherit;">Lorsque le processeur re√ßoit la t√¢che et termine son ex√©cution, il supprime le lien, ce qui entra√Æne une r√©duction atomique. </font><font style="vertical-align: inherit;">Ces op√©rations atomiques (incr√©mentation et diminution) s'additionnent. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ce probl√®me a √©t√© identifi√© pr√©c√©demment par les d√©veloppeurs du syst√®me de t√¢ches </font></font><code>std::future</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Ils ont remarqu√© que lors de l'appel, le </font></font><code>Waker::wake</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lien d'origine vers n'est </font></font><code>waker</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">souvent plus n√©cessaire. </font><font style="vertical-align: inherit;">Cela vous permet de r√©utiliser le compteur de liens atomiques lors du d√©placement d'une t√¢che vers la file d'attente d'ex√©cution. </font><font style="vertical-align: inherit;">Le syst√®me de t√¢ches </font></font><code>std::future</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">comprend d√©sormais deux appels d'API pour se "r√©veiller":</font></font><br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>wake</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> qui accepte </font></font><code>self</code> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>wake_by_ref</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> qui accepte </font></font><code>&amp;self</code> </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une telle construction API nous oblige √† l'utiliser lors de l'appel </font></font><code>wake</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, en √©vitant l'incr√©ment atomique. </font><font style="vertical-align: inherit;">L'impl√©mentation devient comme ceci:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">impl</span></span> Waker { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake</span></span></span></span>(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { task.scheduler.schedule(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake_by_ref</span></span></span></span>(&amp;<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> task = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task.clone(); task.scheduler.schedule(task); } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela √©vite la surcharge de comptes de liens suppl√©mentaires </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">uniquement</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> si vous pouvez prendre la responsabilit√© de vous r√©veiller. D'apr√®s mon exp√©rience, au lieu de cela, il est presque toujours conseill√© de se r√©veiller avec </font></font><code>&amp;self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. L'√©veil </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">emp√™che la r√©utilisation de waker (utile dans les cas o√π la ressource envoie beaucoup de valeurs, c'est-√†-dire des canaux, des sockets, ...). Dans le cas √©galement, il est </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">plus difficile d'impl√©menter un r√©veil sans fil (nous laisserons les d√©tails pour un autre article). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le nouveau planificateur r√©sout le probl√®me du "r√©veil </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">" en √©vitant l'incr√©ment atomique dans </font></font><code>wake_by_ref</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, ce qui le rend aussi efficace que</font></font><code>wake(self)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Pour ce faire, le planificateur conserve une liste de toutes les t√¢ches actuellement actives (pas encore termin√©es). </font><font style="vertical-align: inherit;">La liste repr√©sente le compteur de r√©f√©rence n√©cessaire pour soumettre la t√¢che √† la file d'attente d'ex√©cution. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La complexit√© de cette optimisation r√©side dans le fait que le planificateur ne supprimera pas les t√¢ches de sa liste jusqu'√† ce qu'il re√ßoive la garantie que la t√¢che sera replac√©e dans la file d'attente d'ex√©cution. </font><font style="vertical-align: inherit;">Les d√©tails de la mise en ≈ìuvre de ce sch√©ma d√©passent le cadre de cet article, mais je vous recommande vivement de consulter la source.</font></font><br><br><a name="7"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Concurrence audacieuse (non s√©curis√©e) avec Loom </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il est tr√®s difficile d'√©crire le code parall√®le correct sans verrou. Il vaut mieux travailler lentement, mais correctement, que rapidement, mais avec des probl√®mes, surtout si les bogues concernent la s√©curit√© de la m√©moire. Cependant, la meilleure option devrait fonctionner rapidement et sans erreur. Le nouveau planificateur a fait quelques optimisations plut√¥t agressives et il √©vite la plupart des types </font></font><code>std</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">par souci de sp√©cialisation. En g√©n√©ral, il contient beaucoup de code dangereux </font></font><code>unsafe</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il existe plusieurs fa√ßons de tester du code parall√®le. L'un d'eux est pour les utilisateurs de tester et de d√©boguer √† la place de vous (une option int√©ressante, c'est s√ªr). Une autre consiste √† √©crire des tests unitaires qui s'ex√©cutent en boucle et peuvent d√©tecter une erreur. Peut-√™tre m√™me utiliser </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TSAN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Bien s√ªr, s'il trouve une erreur, elle ne peut pas √™tre facilement reproduite sans red√©marrer le cycle de test. De plus, combien de temps dure ce cycle? Dix secondes? Dix minutes? Dix jours? Auparavant, vous deviez tester du code parall√®le dans Rust. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons trouv√© cette situation inacceptable. Lorsque nous publions le code, nous voulons nous sentir en confiance (autant que possible), en particulier dans le cas d'un code parall√®le sans verrouillage. Les utilisateurs de Tokio ont besoin de fiabilit√©. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Par cons√©quent, nous avons d√©velopp√© </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Loom</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : un outil de test de permutation de code parall√®le. Les tests sont √©crits comme d'habitude, mais</font></font><code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il les ex√©cutera plusieurs fois, r√©organisant toutes les options possibles d'ex√©cution et de comportement que le test peut rencontrer dans un environnement de streaming. Il v√©rifie √©galement l'acc√®s correct √† la m√©moire, la lib√©ration de m√©moire, etc. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ä titre d'exemple, voici le test du m√©tier √† tisser pour le nouveau planificateur:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-meta"><span class="hljs-meta">#[test]</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">multi_spawn</span></span></span></span>() { loom::model(|| { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pool = ThreadPool::new(); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> c1 = Arc::new(AtomicUsize::new(<span class="hljs-number"><span class="hljs-number">0</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> (tx, rx) = oneshot::channel(); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> tx1 = Arc::new(Mutex::new(<span class="hljs-literal"><span class="hljs-literal">Some</span></span>(tx))); <span class="hljs-comment"><span class="hljs-comment">// Spawn a task let c2 = c1.clone(); let tx2 = tx1.clone(); pool.spawn(async move { spawn(async move { if 1 == c1.fetch_add(1, Relaxed) { tx1.lock().unwrap().take().unwrap().send(()); } }); }); // Spawn a second task pool.spawn(async move { spawn(async move { if 1 == c2.fetch_add(1, Relaxed) { tx2.lock().unwrap().take().unwrap().send(()); } }); }); rx.recv(); }); }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela semble assez normal, mais un morceau de code dans un bloc </font></font><code>loom::model</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s'ex√©cute plusieurs milliers de fois (peut-√™tre des millions), √† chaque fois avec un l√©ger changement de comportement. Chaque ex√©cution modifie l'ordre exact des threads. De plus, pour chaque op√©ration atomique, loom essaie tous les diff√©rents comportements autoris√©s dans le mod√®le de m√©moire C ++ 11. Rappelons que la charge atomique avec </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√©tait plut√¥t faible et pouvait renvoyer des valeurs obsol√®tes. Le test </font></font><code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">va essayer toutes les valeurs possibles qui peuvent √™tre charg√©es. </font></font><br><br> <code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est devenu un outil pr√©cieux pour d√©velopper un nouveau planificateur. Il a d√©tect√© plus de dix bogues qui ont r√©ussi tous les tests unitaires, les tests manuels et les tests de charge.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un lecteur averti peut douter que le m√©tier √† tisser v√©rifie ¬´toutes les permutations possibles¬ª et il aura raison. Les permutations na√Øves entra√Æneront une explosion combinatoire. Tout test non trivial ne se terminera jamais. Ce probl√®me est √©tudi√© depuis de nombreuses ann√©es et un certain nombre d'algorithmes ont √©t√© d√©velopp√©s pour emp√™cher une explosion combinatoire. M√©tier √† </font><font style="vertical-align: inherit;">tisser de base algorithme bas√© sur la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©duction dynamique de commande partielle</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dynamique de r√©duction d'ordre partiel). Cet algorithme √©limine les permutations conduisant au m√™me r√©sultat. Mais l'espace d'√©tat peut toujours atteindre une taille telle qu'il ne sera pas trait√© dans un d√©lai raisonnable (plusieurs minutes). Loom vous permet de le limiter davantage en utilisant la r√©duction dynamique avec une commande partielle.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En g√©n√©ral, gr√¢ce √† des tests approfondis avec Loom, je suis maintenant </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">beaucoup</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> plus confiant dans l'exactitude du planificateur.</font></font><br><br><h1>  R√©sultats </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons donc examin√© ce que sont les ordonnanceurs et comment le nouvel ordonnanceur Tokio a r√©ussi √† augmenter consid√©rablement les performances ... mais quel type de croissance? </font><font style="vertical-align: inherit;">√âtant donn√© que le nouvel ordonnanceur n'a √©t√© d√©velopp√© que dans le monde r√©el, il n'a pas encore √©t√© test√© dans son int√©gralit√©. </font><font style="vertical-align: inherit;">Voici ce que nous savons. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Premi√®rement, le nouveau planificateur est beaucoup plus rapide dans les micro-benchmarks:</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ancien planificateur </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> test chained_spawn ... banc: 2,019,796 ns / iter (+/- 302,168)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test ping_pong ... banc: 1,279,948 ns / iter (+/- 154,365)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test spawn_many ... banc: 10,283,608 ns / iter (+/- 1,284,275)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test yield_many ... banc: 21,450,748 ns / iter (+/- 1,201,337) </font></font></pre><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nouveau planificateur </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> test chained_spawn ... banc: 168 854 ns / iter (+/- 8 339)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test ping_pong ... banc: 562,659 ns / iter (+/- 34,410)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test spawn_many ... banc: 7,320,737 ns / iter (+/- 264,620)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test yield_many ... banc: 14,638,563 ns / iter (+/- 1,573,678) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Cette r√©f√©rence comprend les √©l√©ments suivants: </font></font><br><br><ul><li> <code>chained_spawn</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> g√©n√©rer r√©cursivement de nouvelles t√¢ches, c'est-√†-dire g√©n√©rer une t√¢che qui g√©n√®re une autre t√¢che, qui g√©n√®re √©galement une t√¢che, etc. </font></font><br></li><li> <code>ping_pong</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s√©lectionne un canal </font></font><code>oneshot</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et g√©n√®re une t√¢che qui envoie un message sur ce canal. </font><font style="vertical-align: inherit;">La t√¢che d'origine attend un message. </font><font style="vertical-align: inherit;">C'est le test le plus proche du ¬´monde r√©el¬ª.</font></font><br></li><li> <code>spawn_many</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> V√©rifie l'impl√©mentation des t√¢ches dans le planificateur, c'est-√†-dire g√©n√®re des t√¢ches en dehors de son contexte. </font></font><br></li><li> <code>yield_many</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> v√©rifie l'√©veil ind√©pendant des t√¢ches. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La diff√©rence de benchmarks est tr√®s impressionnante. </font><font style="vertical-align: inherit;">Mais comment cela se refl√©tera-t-il dans le "monde r√©el"? </font><font style="vertical-align: inherit;">C'est difficile √† dire avec certitude, mais j'ai essay√© d'ex√©cuter les </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tests Hyper</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voici le serveur Hyper le plus simple, dont les performances sont mesur√©es en utilisant </font></font><code>wrk -t1 -c50 -d10</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ancien planificateur </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ex√©cution du test 10s @ http://127.0.0.1 {000</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1 fils et 50 connexions</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  Stats des sujets Moy Stdev Max +/- Stdev</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Latence 371.53us 99.05us 1.97ms 60.53%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Requ√™te / Sec 114,61k 8,45k 133,85k 67,00%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1139307 requ√™tes en 10.00s, 95.61MB lus</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Demandes / sec: 113923.19</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Transfert / s: 9,56 Mo </font></font></pre><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nouveau planificateur </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ex√©cution du test 10s @ http://127.0.0.1 {000</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1 fils et 50 connexions</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  Stats des sujets Moy Stdev Max +/- Stdev</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Latence 275.05us 69.81us 1.09ms 73.57%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Requ√™te / sec 153.17k 10.68k 171.51k 71.00%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1522671 requ√™tes en 10.00s, 127.79MB lus</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Demandes / sec: 152258.70</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Transfert / s: 12,78 Mo </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous constatons une augmentation de 34% des requ√™tes par seconde juste apr√®s le changement d'ordonnanceur! La premi√®re fois que j'ai vu cela, j'√©tais tr√®s heureux, car je m'attendais √† une augmentation d'un maximum de 5-10%. Mais je me suis senti triste, car ce r√©sultat a √©galement montr√© que l'ancien ordonnanceur Tokio n'est pas si bon. Ensuite, je me suis souvenu que Hyper est </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d√©j√† un</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> leader dans les classements </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">TechEmpower</font></a><font style="vertical-align: inherit;"> . Il est int√©ressant de voir comment le nouveau planificateur affectera les notes. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tonic</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , le client et serveur gRPC, avec le nouveau planificateur a acc√©l√©r√© d'environ 10%, ce qui est assez impressionnant √©tant donn√© que Tonic n'est pas encore enti√®rement optimis√©.</font></font><br><br><h1>  Conclusion </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je suis vraiment tr√®s heureux de pouvoir enfin terminer ce projet apr√®s plusieurs mois de travail. </font><font style="vertical-align: inherit;">Il s'agit d'une am√©lioration majeure des E / S asynchrones de Rust. </font><font style="vertical-align: inherit;">Je suis tr√®s satisfait des am√©liorations apport√©es. </font><font style="vertical-align: inherit;">Il y a encore beaucoup de place pour l'optimisation dans le code Tokio, nous n'avons donc pas encore termin√© l'am√©lioration des performances. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'esp√®re que le contenu de l'article sera utile pour les coll√®gues qui essaient d'√©crire leur planificateur de t√¢ches.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr472242/">https://habr.com/ru/post/fr472242/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr472228/index.html">9 astuces pour travailler avec Visual Studio Code</a></li>
<li><a href="../fr472230/index.html">Chips for ML - parler de nouveaux produits</a></li>
<li><a href="../fr472232/index.html">De ¬´Color Extender for ZX-Spectrum¬ª √† ZX-Poly</a></li>
<li><a href="../fr472234/index.html">Crypto-monnaie: est-ce toujours un freeloader ou un partenaire?</a></li>
<li><a href="../fr472240/index.html">√Ä propos de la gamification. Qu'est-ce que c'est, pourquoi et comment le faire? D√©veloppeur Look</a></li>
<li><a href="../fr472246/index.html">React + IndexDb + mise √† jour automatique = presque AsyncRedux</a></li>
<li><a href="../fr472248/index.html">Comment nous avons fusionn√© la programmation finale d'IT-Planet</a></li>
<li><a href="../fr472252/index.html">√âv√©nements num√©riques √† Moscou du 21 au 28 octobre</a></li>
<li><a href="../fr472254/index.html">√âv√©nements num√©riques √† Saint-P√©tersbourg du 21 au 28 octobre</a></li>
<li><a href="../fr472258/index.html">Comment "apprendre √† apprendre" - am√©liorer la pleine conscience</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
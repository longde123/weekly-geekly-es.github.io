<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌺 👨🏿‍🚀 🌥️ Nous avons dix fois accéléré l'ordonnanceur Tokio 🙅🏾 🤙🏿 🐬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous sommes en train de préparer la prochaine version majeure de Tokio, un environnement d'exécution asynchrone pour Rust. Le 13 octobre, une demande ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nous avons dix fois accéléré l'ordonnanceur Tokio</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/472242/"> Nous sommes en train de préparer la prochaine version majeure de Tokio, un environnement d'exécution asynchrone pour Rust.  Le 13 octobre, une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">demande de pool</a> avec un planificateur de tâches complètement réécrit a été émise pour la fusion dans une branche.  Le résultat sera d'énormes améliorations de performances et une latence réduite.  Certains tests ont enregistré une accélération décuplée!  Comme d'habitude, les tests synthétiques ne reflètent pas les avantages réels dans la réalité.  Par conséquent, nous avons également vérifié comment les modifications du planificateur affectaient les tâches réelles, telles que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hyper</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tonic</a> (spoiler: le résultat est merveilleux). <br><br>  En me préparant à travailler sur un nouveau planificateur, j'ai passé du temps à chercher des ressources thématiques.  Hormis les implémentations réelles, rien de spécial n'a été trouvé.  J'ai également constaté que le code source des implémentations existantes est difficile à parcourir.  Pour résoudre ce problème, nous avons essayé d'écrire le sheduler Tokio aussi proprement que possible.  J'espère que cet article détaillé sur la mise en œuvre du planificateur aidera ceux qui sont dans la même position et qui cherchent sans succès des informations sur ce sujet. <br><br>  L'article commence par un examen de haut niveau de la conception, y compris des politiques de capture des emplois.  Plongez ensuite dans les détails des optimisations spécifiques dans le nouveau planificateur Tokio. <br><a name="habracut"></a><br>  Optimisations envisagées: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nouveau système de tâches std :: future</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Choisir le meilleur algorithme de file d'attente</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Modèles de message rationalisés</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Capture de l'accélérateur</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Réduisez la synchronisation entre les threads</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Réduisez l'allocation de mémoire</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nombre de liaisons atomiques réduit</a> </li></ul><br>  Comme vous pouvez le voir, le thème principal est la «réduction».  Après tout, le code le plus rapide est son manque! <br><br>  Nous parlerons également du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">test du nouveau planificateur</a> .  Il est très difficile d'écrire le code parallèle correct sans verrou.  Il vaut mieux travailler lentement, mais correctement, que rapidement, mais avec des problèmes, surtout si les bogues concernent la sécurité de la mémoire.  Cependant, la meilleure option devrait fonctionner rapidement et sans erreurs, nous avons donc écrit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">loom</a> , un outil de test de concurrence. <br><br>  Avant de plonger dans le sujet, je tiens à remercier: <br><br><ul><li> <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@withoutboats</a></b> et d'autres personnes qui ont travaillé sur la fonction <code>async / await</code> à Rust.  Tu as fait du bon travail.  Ceci est une fonctionnalité qui tue. <br></li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@cramertj</a></b> et d'autres qui ont développé <code>std::task</code> .  Il s'agit d'une énorme amélioration par rapport à ce qu'elle était auparavant.  Et un excellent code. <br></li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Flottant</a></b> , le créateur de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Linkerd,</a> et plus important encore, mon employeur.  Merci de m'avoir permis de consacrer autant de temps à ce travail.  Si quelqu'un s'intéresse au maillage de service, jetez un œil à Linkerd.  Bientôt, il inclura tous les avantages discutés dans cet article. <br></li><li>  <b><a href="">Optez</a></b> pour une telle bonne mise en œuvre du planificateur. </li></ul><br>  Prenez une tasse de café et asseyez-vous.  Ce sera un long article. <br><br><h1>  Comment fonctionnent les planificateurs? </h1><br>  La tâche du sheduler est de planifier le travail.  L'application est divisée en unités de travail, que nous appellerons <i>tâches</i> .  Une tâche est considérée comme exécutable lorsqu'elle peut avancer dans son exécution, mais n'est plus exécutée ou en mode inactif, lorsqu'elle est verrouillée sur une ressource externe.  Les tâches sont indépendantes dans le sens où un nombre illimité de tâches peuvent être effectuées simultanément.  Le planificateur est responsable de l'exécution des tâches dans un état en cours d'exécution jusqu'à ce qu'elles reviennent en mode veille.  L'exécution de la tâche implique d'affecter du temps processeur à la tâche - une ressource globale. <br><br>  L'article décrit les planificateurs d'espace utilisateur, c'est-à-dire qu'ils fonctionnent au-dessus des threads du système d'exploitation (qui, à leur tour, sont contrôlés par un sheduler au niveau du noyau).  Le planificateur Tokio exécute les futurs Rust, qui peuvent être considérés comme des «fils verts asynchrones».  Il s'agit d'un modèle de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">streaming mixte M: N</a> dans lequel de nombreuses tâches d'interface utilisateur sont multiplexées sur plusieurs threads du système d'exploitation. <br><br>  Il existe de nombreuses façons de simuler un sheduler, chacune avec ses avantages et ses inconvénients.  Au niveau le plus élémentaire, le planificateur peut être modélisé comme une <i>file d'attente d'exécution</i> et un <i>processeur</i> qui le sépare.  Un processeur est un morceau de code qui s'exécute dans un thread.  En pseudo code, il fait ce qui suit: <br><br><pre> <code class="plaintext hljs">while let Some(task) = self.queue.pop() { task.run(); }</code> </pre> <br>  Lorsqu'une tâche devient réalisable, elle est insérée dans la file d'attente d'exécution. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ff6/1f4/18f/ff61f418f73f08c62b5e9eaeacaeb8ed.png"><br><br>  Bien que vous puissiez concevoir un système dans lequel des ressources, des tâches et un processeur existent sur le même thread, Tokio préfère utiliser plusieurs threads.  Nous vivons dans un monde où un ordinateur possède de nombreux processeurs.  Le développement d'un ordonnanceur à un seul fil conduira à une charge insuffisante de fer.  Nous voulons utiliser tous les CPU.  Il existe plusieurs façons de procéder: <br><br><ul><li>  Une file d'attente d'exécution globale, de nombreux processeurs. <br></li><li>  De nombreux processeurs, chacun avec sa propre file d'attente d'exécution. </li></ul><br><h3>  Un tour, plusieurs processeurs </h3><br>  Ce modèle possède une file d'attente d'exécution globale.  Lorsque les tâches sont terminées, elles sont placées à la fin de la file d'attente.  Il existe plusieurs processeurs, chacun dans un thread distinct.  Chaque processeur prend une tâche de la tête de la file d'attente ou bloque le thread s'il n'y a pas de tâches disponibles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/85c/8d0/23d/85c8d023dfeba249bba01234e0e8783a.png"><br><br>  La ligne d'exécution doit être prise en charge par de nombreux fabricants et consommateurs.  Habituellement, une liste <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">intrusive</a> est utilisée, dans laquelle la structure de chaque tâche comprend un pointeur vers la tâche suivante dans la file d'attente (au lieu d'envelopper les tâches dans une liste liée).  Ainsi, l'allocation de mémoire pour les opérations push et pop peut être évitée.  Vous pouvez utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'opération push sans verrouillage</a> , mais pour coordonner les consommateurs, le mutex est requis pour l'opération pop (il est techniquement possible d'implémenter une file d'attente multi-utilisateurs sans verrouillage). <br><br>  Cependant, dans la pratique, la surcharge pour une protection adéquate contre les verrous est plus que l'utilisation d'un mutex. <br><br>  Cette approche est souvent utilisée pour un pool de threads à usage général, car elle présente plusieurs avantages: <br><br><ul><li>  Les tâches sont assez planifiées. <br></li><li>  Implémentation relativement simple.  Une file d'attente plus ou moins standard est interfacée avec le cycle du processeur décrit ci-dessus. </li></ul><br>  Une brève note sur une planification juste (équitable).  Cela signifie que les tâches sont exécutées honnêtement: celui qui est venu plus tôt est celui qui est parti plus tôt.  Les planificateurs à usage général essaient d'être justes, mais il existe des exceptions, telles que la parallélisation via la jointure en fourche, où la vitesse de calcul du résultat, plutôt que la justice pour chaque sous-tâche individuelle, est un facteur important. <br><br>  Ce modèle a un inconvénient.  Tous les processeurs postulent pour des tâches depuis le début de la file d'attente.  Pour les threads à usage général, ce n'est généralement pas un problème.  Le temps pour terminer une tâche dépasse de loin le temps pour la récupérer de la file d'attente.  Lorsque les tâches sont effectuées sur une longue période de temps, la concurrence dans la file d'attente est réduite.  Toutefois, les tâches Rust asynchrones devraient se terminer très rapidement.  Dans ce cas, les frais généraux pour le combat dans la file d'attente augmentent considérablement. <br><br><h3>  Concurrence et sympathie mécanique </h3><br>  Pour atteindre des performances maximales, nous devons tirer le meilleur parti des fonctionnalités matérielles.  Le terme «sympathie mécanique» pour les logiciels a été utilisé pour la première fois par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Martin Thompson</a> (dont le blog n'est plus mis à jour, mais toujours très informatif). <br><br>  Une discussion détaillée de la mise en œuvre du parallélisme dans les équipements modernes dépasse le cadre de cet article.  De manière générale, le fer augmente la productivité non pas en raison de l'accélération, mais en raison de l'introduction d'un plus grand nombre de cœurs de processeur (même mon ordinateur portable en a six!) Chaque cœur peut effectuer de grandes quantités de calcul dans des intervalles de temps minuscules.  Des actions telles que l'accès au cache et à la mémoire prennent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">beaucoup plus de temps par</a> rapport au temps d'exécution sur le CPU.  Par conséquent, pour accélérer les applications, vous devez maximiser le nombre d'instructions du processeur pour chaque accès à la mémoire.  Bien que le compilateur aide beaucoup, nous devons encore penser à des choses comme l'alignement et les modèles d'accès à la mémoire. <br><br>  Les threads séparés fonctionnent de manière très similaire à un seul thread isolé, <b>jusqu'à ce que</b> plusieurs threads modifient simultanément la même ligne de cache (mutations simultanées) ou qu'une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cohérence cohérente</a> soit requise.  Dans ce cas, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">protocole de cohérence du cache CPU est</a> activé.  Il garantit la pertinence du cache de chaque CPU. <br><br>  La conclusion est évidente: dans la mesure du possible, évitez la synchronisation entre les threads, car elle est lente. <br><br><h3>  De nombreux processeurs, chacun avec sa propre file d'attente d'exécution </h3><br>  Un autre modèle est plusieurs planificateurs monothread.  Chaque processeur reçoit sa propre file d'attente d'exécution et les tâches sont fixées sur un processeur spécifique.  Cela évite complètement le problème de synchronisation.  Étant donné que le modèle de tâche Rust nécessite la possibilité de mettre une tâche en file d'attente à partir de n'importe quel thread, il devrait toujours y avoir un moyen sûr pour les threads d'entrer des tâches dans le planificateur.  Soit la file d'attente d'exécution de chaque processeur prend en charge le fonctionnement push-thread-safe (MPSC), soit chaque processeur possède <b>deux</b> files d'attente d'exécution: non synchronisées et thread-safe. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c6d/a3c/35e/c6da3c35e7f6fb28b63fdb3ff6417882.png"><br><br>  Cette stratégie utilise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Seastar</a> .  Comme nous évitons presque complètement la synchronisation, cette stratégie donne une très bonne vitesse.  Mais elle ne résout pas tous les problèmes.  Si la charge de travail n'est pas complètement homogène, alors certains processeurs sont sous charge, tandis que d'autres sont inactifs, ce qui conduit à une utilisation non optimale des ressources.  Cela se produit car les tâches sont fixées sur un processeur spécifique.  Lorsqu'un groupe de tâches est planifié dans un package sur un processeur, il remplit à lui seul la charge de pointe, même si d'autres sont inactives. <br><br>  La plupart des charges de travail «réelles» ne sont pas homogènes.  Par conséquent, les planificateurs à usage général évitent généralement ce modèle. <br><br><h3>  Planificateur de capture des travaux </h3><br>  Le planificateur avec des planificateurs de vol de travail est basé sur le modèle de planificateur fragmenté et résout le problème du chargement incomplet des ressources matérielles.  Chaque processeur prend en charge sa propre file d'attente d'exécution.  Les tâches qui sont exécutées sont placées dans la file d'attente d'exécution du processeur actuel, et cela fonctionne dessus.  Mais lorsque le processeur est inactif, il vérifie les files d'attente du processeur frère et essaie de récupérer quelque chose à partir de là.  Le processeur ne passe en mode veille qu'après avoir été incapable de trouver du travail dans les files d'attente d'exécution d'égal à égal. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/561/9a9/02c/5619a902c1d95252d20ac7db1273e57f.png"><br><br>  Au niveau du modèle, c'est l'approche du «meilleur des deux mondes».  Sous charge, les processeurs fonctionnent indépendamment, évitant la synchronisation des frais généraux.  Dans les cas où la charge entre les processeurs est répartie de manière inégale, le planificateur peut la redistribuer.  C'est pourquoi ces ordonnanceurs sont utilisés dans <a href="">Go</a> , <a href="">Erlang</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Java</a> et d'autres langages. <br><br>  L'inconvénient est que cette approche est beaucoup plus compliquée.  L'algorithme de file d'attente doit prendre en charge la capture des travaux et, pour une exécution fluide, <b>une</b> synchronisation entre les processeurs est requise.  S'il n'est pas correctement implémenté, la surcharge pour la capture peut être supérieure au gain. <br><br>  Considérez cette situation: le processeur A exécute actuellement une tâche et il a une file d'attente d'exécution vide.  Le processeur B est inactif;  il essaie de capturer une tâche, mais échoue, alors il passe en mode veille.  Ensuite, 20 tâches sont générées à partir de la tâche du processeur A.  Idéalement, le processeur B devrait se réveiller et en récupérer quelques-uns.  Pour cela, il est nécessaire d'implémenter certaines heuristiques dans le planificateur, où les processeurs signalent aux processeurs homologues endormis l'apparition de nouvelles tâches dans leur file d'attente.  Bien sûr, cela nécessite une synchronisation supplémentaire, de sorte que de telles opérations sont mieux minimisées. <br><br>  En résumé: <br><br><ul><li>  Moins il y a de synchronisation, mieux c'est. <br></li><li>  La capture des travaux est l'algorithme optimal pour les planificateurs à usage général. <br></li><li>  Chaque processeur fonctionne indépendamment des autres, mais une synchronisation est nécessaire pour capturer le travail. </li></ul><br><h1>  Planificateur Tokio 0.1 </h1><br>  Le premier planificateur fonctionnel pour Tokio a été publié en mars 2018.  Il s'agissait de la première tentative, basée sur certaines hypothèses qui se sont révélées fausses. <br><br>  Premièrement, le planificateur Tokio 0.1 a suggéré que les threads du processeur soient fermés s'ils étaient inactifs pendant un certain temps.  Le planificateur a été créé à l'origine comme un système "à usage général" pour le pool de threads Rust.  A cette époque, le runtime Tokio était encore à un stade précoce de développement.  Ensuite, le modèle a supposé que les tâches d'E / S seraient effectuées sur le même thread que le sélecteur d'E / S (epoll, kqueue, iocp ...).  Plus de tâches de calcul pourraient être dirigées vers le pool de threads.  Dans ce contexte, une configuration flexible du nombre de threads actifs est supposée, il est donc plus logique de désactiver les threads inactifs.  Cependant, dans le planificateur avec capture de travail, le modèle est passé à l'exécution de <i>toutes</i> les tâches asynchrones et, dans ce cas, il est logique de toujours conserver un petit nombre de threads à l'état actif. <br><br>  Deuxièmement, une ligne de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">croisement</a> bidirectionnelle y a été mise en place.  Cette implémentation est basée sur la ligne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bidirectionnelle Chase-Lev</a> et ne convient pas à la planification de tâches asynchrones indépendantes pour les raisons décrites ci-dessous. <br><br>  Troisièmement, la mise en œuvre s'est avérée trop compliquée.  Cela est dû en partie au fait qu'il s'agissait de mon premier planificateur de tâches.  De plus, j'étais trop impatient lorsque j'utilisais l'atomique dans les branches, où le mutex aurait fait l'affaire.  Une leçon importante est que, très souvent, ce sont les mutex qui fonctionnent le mieux. <br><br>  Enfin, il y avait de nombreux défauts mineurs dans la mise en œuvre initiale.  Au cours des premières années, les détails de mise en œuvre du modèle asynchrone de Rust ont considérablement évolué, mais les bibliothèques ont maintenu l'API stable à tout moment.  Cela a conduit à l'accumulation d'une partie de la dette technique. <br><br>  Tokio approche maintenant de la première version majeure - et nous pouvons payer toute cette dette, ainsi que tirer parti de l'expérience acquise au cours des années de développement.  C'est une période passionnante! <br><br><h1>  Planificateur Tokio de nouvelle génération </h1><br>  Il est maintenant temps de regarder de plus près ce qui a changé dans le nouveau planificateur. <br><br><a name="1"></a><h3>  Nouveau système de tâches </h3><br>  Premièrement, il est important de souligner ce qui <b>ne</b> fait <b>pas</b> partie de Tokio, mais qui est crucial en termes d'amélioration de l'efficacité: il s'agit d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nouveau système de tâches</a> en <code>std</code> , développé à l'origine par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Taylor Kramer</a> .  Ce système fournit les crochets que le planificateur doit implémenter pour effectuer des tâches Rust asynchrones, et le système est vraiment superbement conçu et implémenté.  Il est beaucoup plus léger et plus flexible que l'itération précédente. <br><br>  La structure <code>Waker</code> partir des ressources signale qu'une tâche <i>réalisable</i> doit être placée dans la file d'attente du planificateur.  Dans le nouveau système de tâches, il s'agit d'une structure à deux points, alors qu'auparavant elle était beaucoup plus grande.  La réduction de la taille est importante pour minimiser la surcharge de copie de la valeur <code>Waker</code> à différents endroits, et elle prend moins de place dans les structures, ce qui vous permet de compresser des données plus importantes dans la ligne de cache.  La conception de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vtable</a> a fait un certain nombre d'optimisations, dont nous discuterons plus tard. <br><br><a name="2"></a><h3>  Choisir le meilleur algorithme de file d'attente </h3><br>  La file d'attente d'exécution se trouve au centre du planificateur.  Par conséquent, c'est le composant le plus important à corriger.  L'ordonnanceur Tokio d'origine utilisait une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">file d'attente à</a> double <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">faisceau croisé</a> : une implémentation à source unique (producteur) et de nombreux consommateurs.  Une tâche est placée à une extrémité et les valeurs sont récupérées de l'autre.  La plupart du temps, le thread «pousse» les valeurs depuis la fin de la file d'attente, mais parfois d'autres threads interceptent le travail, effectuant la même opération.  La file d'attente bidirectionnelle est prise en charge par un tableau et un ensemble d'index qui suivent la tête et la queue.  Lorsque la file d'attente est pleine, son introduction entraînera une augmentation de l'espace de stockage.  Un nouveau tableau plus grand est alloué et les valeurs sont déplacées vers le nouveau stockage. <br><br>  La capacité de croissance est obtenue grâce à la complexité et aux frais généraux.  Les opérations push / pop devraient tenir compte de cette croissance.  De plus, la libération de la baie d'origine est source de difficultés supplémentaires.  Dans un langage de récupération de place (GC), l'ancien tableau sera hors de portée et, éventuellement, le GC l'effacera.  Cependant, Rust est livré sans GC.  Cela signifie que nous sommes nous-mêmes responsables de la libération du tableau, mais les threads peuvent essayer d'accéder à la mémoire en même temps.  Pour résoudre ce problème, la traverse utilise une stratégie de récupération basée sur l'époque.  Bien qu'il ne nécessite pas beaucoup de ressources, il ajoute une surcharge non triviale au chemin principal (hot path).  Chaque opération doit maintenant effectuer des opérations atomiques RMW (lecture-modification-écriture) à l'entrée et à la sortie des sections critiques pour signaler aux autres threads que la mémoire est en cours d'utilisation et ne peut pas être effacée. <br><br>  En raison des frais généraux liés à la croissance de la file d'attente d'exécution, il est logique de penser: le support de cette croissance est-il vraiment nécessaire?  Cette question m'a finalement incité à réécrire le planificateur.  La nouvelle stratégie consiste à avoir une taille de file d'attente fixe pour chaque processus.  Lorsque la file d'attente est pleine, au lieu d'augmenter la file d'attente locale, la tâche se déplace vers la file d'attente globale avec plusieurs consommateurs et plusieurs producteurs.  Les processeurs vérifieront périodiquement cette file d'attente globale, mais à une fréquence bien inférieure à celle locale. <br><br>  Dans le cadre de l'une des premières expériences, nous avons remplacé la traverse par du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mpmc</a> .  Cela n'a pas conduit à une amélioration significative en raison de la quantité de synchronisation pour le push et le pop.  La clé pour capturer le travail est qu'il n'y a presque pas de concurrence dans les files d'attente sous charge, car chaque processeur n'a accès qu'à sa propre file d'attente. <br><br>  À ce stade, j'ai décidé d'étudier attentivement les sources Go - et j'ai constaté qu'elles utilisent une taille de file d'attente fixe avec un fabricant et plusieurs consommateurs, avec une synchronisation minimale, ce qui est très impressionnant.  Pour adapter l'algorithme au planificateur Tokio, j'ai apporté quelques modifications.  Il est à noter que l'implémentation Go utilise des opérations atomiques séquentielles (si je comprends bien).  La version Tokio réduit également le nombre de certaines opérations de copie dans des branches de code plus rares. <br><br>  Une implémentation de file d'attente est un tampon circulaire qui stocke des valeurs dans un tableau.  La tête et la queue de la file d'attente sont suivies par des opérations atomiques avec des valeurs entières. <br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Queue</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">/// Concurrently updated by many threads. head: AtomicU32, /// Only updated by producer thread but read by many threads. tail: AtomicU32, /// Masks the head / tail position value to obtain the index in the buffer. mask: usize, /// Stores the tasks. buffer: Box&lt;[MaybeUninit&lt;Task&gt;]&gt;, }</span></span></code> </pre> <br>  La mise en file d'attente est effectuée par un seul thread: <br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">loop</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> head = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.head.load(Acquire); <span class="hljs-comment"><span class="hljs-comment">// safety: this is the **only** thread that updates this cell. let tail = self.tail.unsync_load(); if tail.wrapping_sub(head) &lt; self.buffer.len() as u32 { // Map the position to a slot index. let idx = tail as usize &amp; self.mask; // Don't drop the previous value in `buffer[idx]` because // it is uninitialized memory. self.buffer[idx].as_mut_ptr().write(task); // Make the task available self.tail.store(tail.wrapping_add(1), Release); return; } // The local buffer is full. Push a batch of work to the global // queue. match self.push_overflow(task, head, tail, global) { Ok(_) =&gt; return, // Lost the race, try again Err(v) =&gt; task = v, } }</span></span></code> </pre> <br>  Notez que dans cette fonction <code>push</code> , les seules opérations atomiques sont le chargement avec la commande <code>Acquire</code> et l'enregistrement avec la commande <code>Release</code> .  Il n'y a pas d'opérations RMW ( <code>compare_and_swap</code> , <code>fetch_and</code> ...) ni ordre séquentiel, comme précédemment.  Ceci est important car sur les puces x86, tous les téléchargements / sauvegardes sont déjà «atomiques».  Ainsi, au niveau CPU, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette fonction ne sera pas synchronisée</a> .  Les opérations atomiques empêcheront certaines optimisations dans le compilateur, mais c'est tout.  Très probablement, la première opération de <code>load</code> pourrait être effectuée en toute sécurité avec une commande <code>Relaxed</code> , mais le remplacement ne comporte pas de frais généraux notables. <br><br>  Lorsque la file d'attente est pleine, <code>push_overflow</code> est <code>push_overflow</code> .<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cette fonction déplace la moitié des tâches de la file d'attente locale vers la file globale. La file d'attente globale est une liste intrusive protégée par un mutex. Lors du déplacement vers la file d'attente globale, les tâches sont d'abord liées entre elles, puis un mutex est créé et toutes les tâches sont insérées en mettant à jour le pointeur sur la queue de la file d'attente globale. Cela permet d'économiser une petite taille de section critique. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si vous connaissez les détails de la commande de la mémoire atomique, vous pouvez remarquer un «problème» potentiel avec la fonction indiquée ci-dessus </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. L'opération de </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">commande </font><font style="vertical-align: inherit;">atomique est </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">plutôt faible. Il peut renvoyer des valeurs obsolètes, c'est-à-dire qu'une opération de capture parallèle peut déjà augmenter la valeur </font></font><code>self.head</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, mais dans le cache de flux</font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l'ancienne valeur restera, elle ne remarquera donc pas l'opération de capture. Ce n'est pas un problème avec l'exactitude de l'algorithme. De manière principale (rapide), </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nous nous soucions uniquement de savoir si la file d'attente locale est pleine ou non. Étant donné que seul le thread actuel peut pousser la file d'attente, une opération obsolète </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rendra simplement la file d'attente plus pleine qu'elle ne l'est réellement. Il peut déterminer de manière incorrecte que la file d'attente est pleine et provoquer </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, mais cette fonction inclut une opération atomique plus puissante. S'il </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">détermine que la file d'attente n'est pas réellement pleine, renvoie ensuite w / </font></font><code>Err</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et l'opération </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">recommence. C’est une autre raison pour laquelle</font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">déplace la moitié de la file d'attente d'exécution vers la file d'attente globale. </font><font style="vertical-align: inherit;">Après ce mouvement, ces faux positifs se produisent beaucoup moins fréquemment. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Local </font></font><code>pop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(à partir du processeur auquel appartient la file d'attente) est également implémenté simplement:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">loop</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> head = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.head.load(Acquire); <span class="hljs-comment"><span class="hljs-comment">// safety: this is the **only** thread that updates this cell. let tail = self.tail.unsync_load(); if head == tail { // queue is empty return None; } // Map the head position to a slot index. let idx = head as usize &amp; self.mask; let task = self.buffer[idx].as_ptr().read(); // Attempt to claim the task read above. let actual = self .head .compare_and_swap(head, head.wrapping_add(1), Release); if actual == head { return Some(task.assume_init()); } }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cette fonction, un atomique </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et un </font></font><code>compare_and_swap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s </font></font><code>Release</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Les frais généraux principaux proviennent de </font></font><code>compare_and_swap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La fonction </font></font><code>steal</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est similaire à </font></font><code>pop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, mais la </font></font><code>self.tail</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">charge atomique doit être transférée </font><font style="vertical-align: inherit;">de </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">De plus, de la même manière </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, l'opération </font></font><code>steal</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tente de faire semblant d'être la moitié de la file d'attente au lieu d'une seule tâche. </font><font style="vertical-align: inherit;">Cela a un bon effet sur les performances, dont nous discuterons plus tard.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La dernière partie manquante est l'analyse de la file d'attente globale, qui reçoit les tâches qui dépassent les files d'attente locales, ainsi que le transfert des tâches vers le planificateur à partir de threads non processeur. </font><font style="vertical-align: inherit;">Si le processeur est sous charge, c'est-à-dire qu'il y a des tâches dans la file d'attente locale, le processeur essaiera de retirer des tâches de la file d'attente globale après environ 60 tâches dans la file d'attente locale. </font><font style="vertical-align: inherit;">Il vérifie également la file d'attente globale lorsqu'elle est dans l'état de «recherche» décrit ci-dessous.</font></font><br><br><a name="3"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modèles de message rationalisés </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les applications Tokio se composent généralement de nombreuses petites tâches indépendantes. Ils interagissent entre eux à travers des messages. Un tel modèle est similaire à d'autres langues telles que Go et Erlang. Étant donné la fréquence à laquelle le modèle est courant, il est logique que le planificateur l'optimise. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Supposons que les tâches A et B soient données. La tâche A est en cours d'exécution et envoie un message à la tâche B sur le canal de transmission. Un canal est une ressource sur laquelle la tâche B est actuellement verrouillée, donc l'action d'envoyer un message entraînera la transition de la tâche B vers un état exécutable - et elle sera placée dans la file d'attente d'exécution du processeur actuel. Ensuite, le processeur déduira la tâche suivante de la file d'attente d'exécution, l'exécutera et répétera ce cycle jusqu'à ce qu'il atteigne la tâche B.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le problème est qu'il peut y avoir un délai important entre l'envoi d'un message et la fin de la tâche B. </font><font style="vertical-align: inherit;">En outre, les données chaudes, comme un message, sont stockées dans le cache du processeur, mais au moment où la tâche est terminée, il est probable que les caches correspondants seront effacés. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour résoudre ce problème, le nouveau planificateur Tokio implémente l'optimisation (comme dans les planificateurs Go et Kotlin). </font><font style="vertical-align: inherit;">Lorsqu'une tâche passe dans un état exécutable, elle n'est pas placée à la fin de la file d'attente, mais est stockée dans un emplacement spécial «tâche suivante». </font><font style="vertical-align: inherit;">Le processeur vérifie toujours cet emplacement avant de vérifier la file d'attente. </font><font style="vertical-align: inherit;">S'il existe déjà une ancienne tâche lors de l'insertion dans l'emplacement, elle est supprimée de l'emplacement et se déplace à la fin de la file d'attente. </font><font style="vertical-align: inherit;">Ainsi, la tâche de transmission d'un message sera achevée pratiquement sans délai.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/12f/e12/a32/12fe12a324d1855a6c62cacd56cb4f70.png"><br><br><a name="4"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Capture de l'accélérateur </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans un planificateur de capture de travaux, si la file d'attente d'exécution du processeur est vide, le processeur tente de capturer des tâches à partir de CPU homologues. Tout d'abord, un processeur homologue aléatoire est sélectionné, si aucune tâche n'est trouvée pour lui, la suivante est recherchée, et ainsi de suite, jusqu'à ce que des tâches soient trouvées. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En pratique, plusieurs processeurs terminent souvent le traitement de la file d'attente d'exécution à peu près en même temps. Cela se produit lorsqu'un package de tâches arrive (par exemple, lorsque</font></font><code>epoll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">interrogé pour savoir si le socket est prêt). Les processeurs se réveillent, reçoivent des tâches, les démarrent et terminent. Cela conduit au fait que tous les processeurs tentent simultanément de capturer les tâches d'autres personnes, c'est-à-dire que de nombreux threads tentent d'accéder aux mêmes files d'attente. Il y a un conflit. Un choix aléatoire du point de départ permet de réduire la concurrence, mais la situation n'est toujours pas très bonne. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour contourner ce problème, le nouveau planificateur limite le nombre de processeurs parallèles qui effectuent des opérations de capture. Nous appelons l'état du processeur dans lequel il essaie de capturer les tâches des autres «recherche d'emploi» ou «recherche» pour faire court (plus de détails plus loin). Une telle optimisation est effectuée en utilisant la valeur atomique</font></font><code>int</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, que le processeur augmente avant de lancer la recherche et diminue à la sortie de l'état de recherche. </font><font style="vertical-align: inherit;">Un maximum de la moitié du nombre total de processeurs peut être en état de recherche. </font><font style="vertical-align: inherit;">Autrement dit, la limite approximative est définie, ce qui est normal. </font><font style="vertical-align: inherit;">Nous n'avons pas besoin d'une limite stricte sur le nombre de processeurs dans la recherche, juste la limitation. </font><font style="vertical-align: inherit;">Nous sacrifions la précision pour l'efficacité de l'algorithme. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Après être entré dans l'état de recherche, le processeur tente de capturer le travail à partir des CPU homologues et vérifie la file d'attente globale.</font></font><br><br><a name="5"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Diminue la synchronisation entre les threads </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une autre partie importante du planificateur consiste à notifier les processeurs homologues de nouvelles tâches. Si le "frère" dort, il se réveille et capture les tâches. Les notifications jouent un autre rôle important. Rappelons que l'algorithme de file d'attente utilise un ordre atomique faible ( </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">/ </font></font><code>Release</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">). En raison de l'allocation atomique de la mémoire, rien ne garantit qu'un processeur homologue verra jamais les tâches dans la file d'attente sans synchronisation supplémentaire. Par conséquent, les notifications en sont également responsables. Pour cette raison, les notifications deviennent chères. Le but est de minimiser leur nombre afin de ne pas utiliser les ressources CPU, c'est-à-dire que le processeur a des tâches et que le frère ne peut pas les voler. Un nombre excessif de notifications conduit à </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un problème de troupeau de tonnerre</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le planificateur original de Tokio a adopté une approche naïve des notifications. Chaque fois qu'une nouvelle tâche était placée dans la file d'attente d'exécution, le processeur recevait une notification. Chaque fois que le CPU a été averti et a vu la tâche après s'être réveillé, il a notifié un autre CPU. Cette logique a très rapidement conduit tous les processeurs à se réveiller et à chercher du travail (provoquant un conflit). Souvent, la plupart des transformateurs ne trouvaient pas de travail et se rendormaient.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le nouveau planificateur a considérablement amélioré ce modèle, similaire au planificateur Go. Les notifications sont envoyées comme précédemment, mais uniquement s'il n'y a pas de CPU dans l'état de recherche (voir la section précédente). Lorsque le processeur reçoit une notification, il entre immédiatement dans l'état de recherche. Lorsque le processeur dans l'état de recherche trouve de nouvelles tâches, il quitte d'abord l'état de recherche, puis avertit l'autre processeur. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cette logique limite la vitesse à laquelle les processeurs se réveillent. Si un ensemble de tâches est planifié immédiatement (par exemple, lorsque</font></font><code>epoll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">interrogé pour savoir si le socket est prêt), la première tâche entraînera une notification au processeur. </font><font style="vertical-align: inherit;">Il est maintenant en état de recherche. </font><font style="vertical-align: inherit;">Les tâches planifiées restantes dans le package n'informeront pas le processeur, car il y a au moins un processeur à l'état de recherche. </font><font style="vertical-align: inherit;">Ce processeur notifié capturera la moitié des tâches du lot et, à son tour, notifiera l'autre processeur. </font><font style="vertical-align: inherit;">Un troisième processeur se réveille, trouve les tâches de l'un des deux premiers processeurs et en capture la moitié. </font><font style="vertical-align: inherit;">Cela conduit à une augmentation en douceur du nombre de processeurs de travail, ainsi qu'à un équilibrage de charge rapide.</font></font><br><br><a name="6"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Réduisez l'allocation de mémoire </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le nouveau planificateur Tokio ne nécessite qu'une seule allocation de mémoire pour chaque tâche générée, tandis que l'ancienne en demandait deux. </font><font style="vertical-align: inherit;">Auparavant, la structure des tâches ressemblait à ceci:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">/// All state needed to manage the task state: TaskState, /// The logic to run is represented as a future trait object. future: Box&lt;dyn Future&lt;Output = ()&gt;&gt;, }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La structure </font></font><code>Task</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sera également mise en évidence dans </font></font><code>Box</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Pendant très longtemps, j'ai voulu réparer ce joint (j'ai essayé pour la première fois en 2014). Deux choses ont changé depuis l'ancien planificateur Tokio. Tout d'abord, stabilisé </font></font><code>std::alloc</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Deuxièmement, le futur système de tâches est passé à une </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">stratégie</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> explicite de </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">table</font></a><font style="vertical-align: inherit;"> . Ce sont ces deux choses qui manquaient, enfin, pour se débarrasser de l'allocation de mémoire double inefficace pour chaque tâche. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maintenant, la structure </font></font><code>Task</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est présentée sous la forme suivante:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span></span>&lt;T&gt; { header: Header, future: T, trailer: Trailer, }</code> </pre> <br>     <code>Header</code> ,  <code>Trailer</code> ,     «»  ()  «» (), . .   ,    ,  ,   . «»          .     ,      ( 64  128 ).  ,        . <br><br><a name="7"></a><h3>     </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La dernière optimisation dont nous discutons dans cet article est de réduire le nombre de liens atomiques. Il existe de nombreuses références à la structure de la tâche, y compris du planificateur et de chaque waker. La stratégie générale de gestion de cette mémoire est </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le comptage de liens atomiques</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Cette stratégie nécessite une opération atomique chaque fois qu'un lien est cloné et chaque fois qu'un lien est supprimé. Lorsque le dernier lien sort du domaine, la mémoire est libérée. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans l'ancien planificateur Tokio, le planificateur et tous les wakers contenaient un lien vers un descripteur de tâche, approximativement:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Waker</span></span></span></span> { task: Arc&lt;Task&gt;, } <span class="hljs-keyword"><span class="hljs-keyword">impl</span></span> Waker { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake</span></span></span></span>(&amp;<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> task = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task.clone(); task.scheduler.schedule(task); } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lorsque la tâche se réveille, le lien est cloné (un incrément atomique se produit). </font><font style="vertical-align: inherit;">Ensuite, le lien est placé dans la file d'attente d'exécution. </font><font style="vertical-align: inherit;">Lorsque le processeur reçoit la tâche et termine son exécution, il supprime le lien, ce qui entraîne une réduction atomique. </font><font style="vertical-align: inherit;">Ces opérations atomiques (incrémentation et diminution) s'additionnent. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ce problème a été identifié précédemment par les développeurs du système de tâches </font></font><code>std::future</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Ils ont remarqué que lors de l'appel, le </font></font><code>Waker::wake</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lien d'origine vers n'est </font></font><code>waker</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">souvent plus nécessaire. </font><font style="vertical-align: inherit;">Cela vous permet de réutiliser le compteur de liens atomiques lors du déplacement d'une tâche vers la file d'attente d'exécution. </font><font style="vertical-align: inherit;">Le système de tâches </font></font><code>std::future</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">comprend désormais deux appels d'API pour se "réveiller":</font></font><br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>wake</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> qui accepte </font></font><code>self</code> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>wake_by_ref</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> qui accepte </font></font><code>&amp;self</code> </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une telle construction API nous oblige à l'utiliser lors de l'appel </font></font><code>wake</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, en évitant l'incrément atomique. </font><font style="vertical-align: inherit;">L'implémentation devient comme ceci:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">impl</span></span> Waker { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake</span></span></span></span>(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { task.scheduler.schedule(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake_by_ref</span></span></span></span>(&amp;<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> task = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task.clone(); task.scheduler.schedule(task); } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela évite la surcharge de comptes de liens supplémentaires </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">uniquement</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> si vous pouvez prendre la responsabilité de vous réveiller. D'après mon expérience, au lieu de cela, il est presque toujours conseillé de se réveiller avec </font></font><code>&amp;self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. L'éveil </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">empêche la réutilisation de waker (utile dans les cas où la ressource envoie beaucoup de valeurs, c'est-à-dire des canaux, des sockets, ...). Dans le cas également, il est </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">plus difficile d'implémenter un réveil sans fil (nous laisserons les détails pour un autre article). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le nouveau planificateur résout le problème du "réveil </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">" en évitant l'incrément atomique dans </font></font><code>wake_by_ref</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, ce qui le rend aussi efficace que</font></font><code>wake(self)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Pour ce faire, le planificateur conserve une liste de toutes les tâches actuellement actives (pas encore terminées). </font><font style="vertical-align: inherit;">La liste représente le compteur de référence nécessaire pour soumettre la tâche à la file d'attente d'exécution. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La complexité de cette optimisation réside dans le fait que le planificateur ne supprimera pas les tâches de sa liste jusqu'à ce qu'il reçoive la garantie que la tâche sera replacée dans la file d'attente d'exécution. </font><font style="vertical-align: inherit;">Les détails de la mise en œuvre de ce schéma dépassent le cadre de cet article, mais je vous recommande vivement de consulter la source.</font></font><br><br><a name="7"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Concurrence audacieuse (non sécurisée) avec Loom </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il est très difficile d'écrire le code parallèle correct sans verrou. Il vaut mieux travailler lentement, mais correctement, que rapidement, mais avec des problèmes, surtout si les bogues concernent la sécurité de la mémoire. Cependant, la meilleure option devrait fonctionner rapidement et sans erreur. Le nouveau planificateur a fait quelques optimisations plutôt agressives et il évite la plupart des types </font></font><code>std</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">par souci de spécialisation. En général, il contient beaucoup de code dangereux </font></font><code>unsafe</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il existe plusieurs façons de tester du code parallèle. L'un d'eux est pour les utilisateurs de tester et de déboguer à la place de vous (une option intéressante, c'est sûr). Une autre consiste à écrire des tests unitaires qui s'exécutent en boucle et peuvent détecter une erreur. Peut-être même utiliser </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TSAN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Bien sûr, s'il trouve une erreur, elle ne peut pas être facilement reproduite sans redémarrer le cycle de test. De plus, combien de temps dure ce cycle? Dix secondes? Dix minutes? Dix jours? Auparavant, vous deviez tester du code parallèle dans Rust. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons trouvé cette situation inacceptable. Lorsque nous publions le code, nous voulons nous sentir en confiance (autant que possible), en particulier dans le cas d'un code parallèle sans verrouillage. Les utilisateurs de Tokio ont besoin de fiabilité. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Par conséquent, nous avons développé </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Loom</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : un outil de test de permutation de code parallèle. Les tests sont écrits comme d'habitude, mais</font></font><code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il les exécutera plusieurs fois, réorganisant toutes les options possibles d'exécution et de comportement que le test peut rencontrer dans un environnement de streaming. Il vérifie également l'accès correct à la mémoire, la libération de mémoire, etc. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">À titre d'exemple, voici le test du métier à tisser pour le nouveau planificateur:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-meta"><span class="hljs-meta">#[test]</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">multi_spawn</span></span></span></span>() { loom::model(|| { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pool = ThreadPool::new(); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> c1 = Arc::new(AtomicUsize::new(<span class="hljs-number"><span class="hljs-number">0</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> (tx, rx) = oneshot::channel(); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> tx1 = Arc::new(Mutex::new(<span class="hljs-literal"><span class="hljs-literal">Some</span></span>(tx))); <span class="hljs-comment"><span class="hljs-comment">// Spawn a task let c2 = c1.clone(); let tx2 = tx1.clone(); pool.spawn(async move { spawn(async move { if 1 == c1.fetch_add(1, Relaxed) { tx1.lock().unwrap().take().unwrap().send(()); } }); }); // Spawn a second task pool.spawn(async move { spawn(async move { if 1 == c2.fetch_add(1, Relaxed) { tx2.lock().unwrap().take().unwrap().send(()); } }); }); rx.recv(); }); }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela semble assez normal, mais un morceau de code dans un bloc </font></font><code>loom::model</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s'exécute plusieurs milliers de fois (peut-être des millions), à chaque fois avec un léger changement de comportement. Chaque exécution modifie l'ordre exact des threads. De plus, pour chaque opération atomique, loom essaie tous les différents comportements autorisés dans le modèle de mémoire C ++ 11. Rappelons que la charge atomique avec </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">était plutôt faible et pouvait renvoyer des valeurs obsolètes. Le test </font></font><code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">va essayer toutes les valeurs possibles qui peuvent être chargées. </font></font><br><br> <code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est devenu un outil précieux pour développer un nouveau planificateur. Il a détecté plus de dix bogues qui ont réussi tous les tests unitaires, les tests manuels et les tests de charge.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un lecteur averti peut douter que le métier à tisser vérifie «toutes les permutations possibles» et il aura raison. Les permutations naïves entraîneront une explosion combinatoire. Tout test non trivial ne se terminera jamais. Ce problème est étudié depuis de nombreuses années et un certain nombre d'algorithmes ont été développés pour empêcher une explosion combinatoire. Métier à </font><font style="vertical-align: inherit;">tisser de base algorithme basé sur la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réduction dynamique de commande partielle</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dynamique de réduction d'ordre partiel). Cet algorithme élimine les permutations conduisant au même résultat. Mais l'espace d'état peut toujours atteindre une taille telle qu'il ne sera pas traité dans un délai raisonnable (plusieurs minutes). Loom vous permet de le limiter davantage en utilisant la réduction dynamique avec une commande partielle.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En général, grâce à des tests approfondis avec Loom, je suis maintenant </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">beaucoup</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> plus confiant dans l'exactitude du planificateur.</font></font><br><br><h1>  Résultats </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons donc examiné ce que sont les ordonnanceurs et comment le nouvel ordonnanceur Tokio a réussi à augmenter considérablement les performances ... mais quel type de croissance? </font><font style="vertical-align: inherit;">Étant donné que le nouvel ordonnanceur n'a été développé que dans le monde réel, il n'a pas encore été testé dans son intégralité. </font><font style="vertical-align: inherit;">Voici ce que nous savons. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Premièrement, le nouveau planificateur est beaucoup plus rapide dans les micro-benchmarks:</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ancien planificateur </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> test chained_spawn ... banc: 2,019,796 ns / iter (+/- 302,168)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test ping_pong ... banc: 1,279,948 ns / iter (+/- 154,365)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test spawn_many ... banc: 10,283,608 ns / iter (+/- 1,284,275)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test yield_many ... banc: 21,450,748 ns / iter (+/- 1,201,337) </font></font></pre><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nouveau planificateur </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> test chained_spawn ... banc: 168 854 ns / iter (+/- 8 339)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test ping_pong ... banc: 562,659 ns / iter (+/- 34,410)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test spawn_many ... banc: 7,320,737 ns / iter (+/- 264,620)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test yield_many ... banc: 14,638,563 ns / iter (+/- 1,573,678) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Cette référence comprend les éléments suivants: </font></font><br><br><ul><li> <code>chained_spawn</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> générer récursivement de nouvelles tâches, c'est-à-dire générer une tâche qui génère une autre tâche, qui génère également une tâche, etc. </font></font><br></li><li> <code>ping_pong</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sélectionne un canal </font></font><code>oneshot</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et génère une tâche qui envoie un message sur ce canal. </font><font style="vertical-align: inherit;">La tâche d'origine attend un message. </font><font style="vertical-align: inherit;">C'est le test le plus proche du «monde réel».</font></font><br></li><li> <code>spawn_many</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Vérifie l'implémentation des tâches dans le planificateur, c'est-à-dire génère des tâches en dehors de son contexte. </font></font><br></li><li> <code>yield_many</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vérifie l'éveil indépendant des tâches. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La différence de benchmarks est très impressionnante. </font><font style="vertical-align: inherit;">Mais comment cela se reflétera-t-il dans le "monde réel"? </font><font style="vertical-align: inherit;">C'est difficile à dire avec certitude, mais j'ai essayé d'exécuter les </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tests Hyper</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voici le serveur Hyper le plus simple, dont les performances sont mesurées en utilisant </font></font><code>wrk -t1 -c50 -d10</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ancien planificateur </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exécution du test 10s @ http://127.0.0.1 {000</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1 fils et 50 connexions</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  Stats des sujets Moy Stdev Max +/- Stdev</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Latence 371.53us 99.05us 1.97ms 60.53%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Requête / Sec 114,61k 8,45k 133,85k 67,00%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1139307 requêtes en 10.00s, 95.61MB lus</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Demandes / sec: 113923.19</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Transfert / s: 9,56 Mo </font></font></pre><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nouveau planificateur </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exécution du test 10s @ http://127.0.0.1 {000</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1 fils et 50 connexions</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  Stats des sujets Moy Stdev Max +/- Stdev</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Latence 275.05us 69.81us 1.09ms 73.57%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Requête / sec 153.17k 10.68k 171.51k 71.00%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1522671 requêtes en 10.00s, 127.79MB lus</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Demandes / sec: 152258.70</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Transfert / s: 12,78 Mo </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous constatons une augmentation de 34% des requêtes par seconde juste après le changement d'ordonnanceur! La première fois que j'ai vu cela, j'étais très heureux, car je m'attendais à une augmentation d'un maximum de 5-10%. Mais je me suis senti triste, car ce résultat a également montré que l'ancien ordonnanceur Tokio n'est pas si bon. Ensuite, je me suis souvenu que Hyper est </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">déjà un</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> leader dans les classements </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">TechEmpower</font></a><font style="vertical-align: inherit;"> . Il est intéressant de voir comment le nouveau planificateur affectera les notes. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tonic</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , le client et serveur gRPC, avec le nouveau planificateur a accéléré d'environ 10%, ce qui est assez impressionnant étant donné que Tonic n'est pas encore entièrement optimisé.</font></font><br><br><h1>  Conclusion </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je suis vraiment très heureux de pouvoir enfin terminer ce projet après plusieurs mois de travail. </font><font style="vertical-align: inherit;">Il s'agit d'une amélioration majeure des E / S asynchrones de Rust. </font><font style="vertical-align: inherit;">Je suis très satisfait des améliorations apportées. </font><font style="vertical-align: inherit;">Il y a encore beaucoup de place pour l'optimisation dans le code Tokio, nous n'avons donc pas encore terminé l'amélioration des performances. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'espère que le contenu de l'article sera utile pour les collègues qui essaient d'écrire leur planificateur de tâches.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr472242/">https://habr.com/ru/post/fr472242/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr472228/index.html">9 astuces pour travailler avec Visual Studio Code</a></li>
<li><a href="../fr472230/index.html">Chips for ML - parler de nouveaux produits</a></li>
<li><a href="../fr472232/index.html">De «Color Extender for ZX-Spectrum» à ZX-Poly</a></li>
<li><a href="../fr472234/index.html">Crypto-monnaie: est-ce toujours un freeloader ou un partenaire?</a></li>
<li><a href="../fr472240/index.html">À propos de la gamification. Qu'est-ce que c'est, pourquoi et comment le faire? Développeur Look</a></li>
<li><a href="../fr472246/index.html">React + IndexDb + mise à jour automatique = presque AsyncRedux</a></li>
<li><a href="../fr472248/index.html">Comment nous avons fusionné la programmation finale d'IT-Planet</a></li>
<li><a href="../fr472252/index.html">Événements numériques à Moscou du 21 au 28 octobre</a></li>
<li><a href="../fr472254/index.html">Événements numériques à Saint-Pétersbourg du 21 au 28 octobre</a></li>
<li><a href="../fr472258/index.html">Comment "apprendre à apprendre" - améliorer la pleine conscience</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêÆ üëÜüèø üêá Testando e depurando o MapReduce üë©üèº‚Äçüåæ üïäÔ∏è üôé</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Na Rostelecom, usamos o Hadoop para armazenar e processar dados baixados de v√°rias fontes usando aplicativos java. Agora, passamos para uma nova vers√£...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Testando e depurando o MapReduce</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/432828/"> Na Rostelecom, usamos o Hadoop para armazenar e processar dados baixados de v√°rias fontes usando aplicativos java.  Agora, passamos para uma nova vers√£o do hadoop com a autentica√ß√£o Kerberos.  Ao me mover, encontrei v√°rios problemas, incluindo o uso da API do YARN.  O trabalho do Hadoop com a autentica√ß√£o Kerberos merece um artigo separado, mas neste artigo falaremos sobre a depura√ß√£o do Hadoop MapReduce. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/517/ccf/f7f/517ccff7f9688538cbffdd7ab838470e.png"><br><a name="habracut"></a><br>  Ao executar tarefas no cluster, o lan√ßamento do depurador √© complicado pelo fato de n√£o sabermos qual n√≥ processar√° essa ou aquela parte dos dados de entrada e n√£o podemos configurar nosso depurador antecipadamente. <br><br>  Voc√™ pode usar o <code>System.out.println("message")</code> testado pelo tempo.  Mas como analisar a sa√≠da de <code>System.out.println("message")</code> espalhada por esses n√≥s? <br><br>  Podemos enviar mensagens para o fluxo de erro padr√£o.  Tudo escrito em stdout ou stderr, <br>  enviado ao arquivo de log apropriado, que pode ser encontrado na p√°gina da Web de informa√ß√µes da tarefa estendida ou nos arquivos de log. <br><br>  Tamb√©m podemos incluir ferramentas de depura√ß√£o em nosso c√≥digo, atualizar mensagens de status de tarefas e usar contadores personalizados para nos ajudar a entender a escala do desastre. <br><br>  O aplicativo Hadoop MapReduce pode ser depurado nos tr√™s modos em que o Hadoop pode funcionar: <br><br><ul><li>  aut√¥nomo <br></li><li>  modo pseudo-distribu√≠do <br></li><li>  totalmente distribu√≠do <br></li></ul><br>  Em mais detalhes, vamos nos concentrar nos dois primeiros. <br><br><h3>  Modo pseudo-distribu√≠do </h3><br>  O modo pseudo-distribu√≠do √© usado para simular um cluster real.  E pode ser usado para testes em um ambiente o mais pr√≥ximo poss√≠vel da produtividade.  Nesse modo, todos os daemons do Hadoop funcionar√£o em um n√≥! <br><br>  Se voc√™ tiver um servidor de desenvolvimento ou outra sandbox (por exemplo, M√°quina Virtual com um ambiente de desenvolvimento personalizado, como Hortonworks Sanbox com HDP), poder√° depurar o programa de controle usando ferramentas de depura√ß√£o remota. <br><br>  Para iniciar a depura√ß√£o, voc√™ precisa definir o valor da vari√°vel de ambiente: <code>YARN_OPTS</code> .  O seguinte √© um exemplo.  Por conveni√™ncia, voc√™ pode criar o arquivo startWordCount.sh e adicionar os par√¢metros necess√°rios para iniciar o aplicativo. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash source /etc/hadoop/conf/yarn-env.sh export YARN_OPTS='-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=6000 ${YARN_OPTS}' yarn jar wordcount-0.0.1.jar ru.rtc.example.WordCount /input /output</span></span></code> </pre><br>  Agora, executando o script <code>`./startWordCount.sh`</code> , veremos uma mensagem <br><br><pre> <code class="plaintext hljs">Listening for transport dt_socket at address: 6000</code> </pre><br>  Resta configurar o IDE para depura√ß√£o remota.  Eu estou usando intellij IDEA.  V√° para o menu Executar -&gt; Editar configura√ß√µes ... Adicione uma nova configura√ß√£o <code>Remote</code> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/344/574/fe7/344574fe735f992742437f5ba3660c31.png"><br><br>  Defina o ponto de interrup√ß√£o como principal e execute. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e8a/cc9/8f5/e8acc98f5739b25b54630170fcd3c057.png"><br><br>  √â isso, agora podemos depurar o programa como de costume. <br><blockquote>  ATEN√á√ÉO  Voc√™ deve verificar se est√° trabalhando com a vers√£o mais recente do c√≥digo-fonte.  Caso contr√°rio, voc√™ pode ter diferen√ßas nas linhas em que o depurador para. <br></blockquote><br>  Nas vers√µes anteriores do Hadoop, era fornecida uma classe especial que permitia reiniciar uma tarefa com falha - isolatedRunner.  Os dados que causaram a falha foram salvos no disco no endere√ßo especificado na vari√°vel de ambiente Hadoop mapred.local.dir.  Infelizmente, nas vers√µes recentes do Hadoop, essa classe n√£o √© mais fornecida. <br><br><h3>  Aut√¥nomo (in√≠cio local) </h3><br>  Independente √© o modo padr√£o no qual o Hadoop funciona.  √â adequado para depura√ß√£o onde o HDFS n√£o √© usado.  Com essa depura√ß√£o, voc√™ pode usar entrada e sa√≠da atrav√©s do sistema de arquivos local.  O modo aut√¥nomo geralmente √© o modo mais r√°pido do Hadoop, pois usa o sistema de arquivos local para todos os dados de entrada e sa√≠da. <br><br>  Como mencionado anteriormente, voc√™ pode injetar ferramentas de depura√ß√£o no seu c√≥digo, como contadores.  Os contadores s√£o definidos pela <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">enumera√ß√£o</a> Java.  O nome da enumera√ß√£o define o nome do grupo e os campos de enumera√ß√£o determinam os nomes dos contadores.  Um contador pode ser √∫til para avaliar um problema, <br>  e pode ser usado como uma adi√ß√£o √† sa√≠da de depura√ß√£o. <br><br>  Declara√ß√£o e uso do contador: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> ru.rt.example; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.IntWritable; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.LongWritable; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.Text; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.mapreduce.Mapper; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Map</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Mapper</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LongWritable</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">IntWritable</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Text word = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text(); <span class="hljs-keyword"><span class="hljs-keyword">enum</span></span> Word {   TOTAL_WORD_COUNT, } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">map</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(LongWritable key, Text value, Context context)</span></span></span><span class="hljs-function"> </span></span>{   String[] stringArr = value.toString().split(<span class="hljs-string"><span class="hljs-string">"\\s+"</span></span>);   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (String str : stringArr) {     word.set(str);     context.getCounter(Word.TOTAL_WORD_COUNT).increment(<span class="hljs-number"><span class="hljs-number">1</span></span>);   } } } }</code> </pre><br>  Para incrementar o contador, use o m√©todo <code>increment(1)</code> . <br><br><pre> <code class="java hljs">... context.getCounter(Word.TOTAL_WORD_COUNT).increment(<span class="hljs-number"><span class="hljs-number">1</span></span>); ...</code> </pre><br>  Depois que o MapReduce √© conclu√≠do com √™xito, a tarefa exibe os contadores no final. <br><br><pre> <code class="plaintext hljs">    Shuffle Errors           BAD_ID=0           CONNECTION=0           IO_ERROR=0           WRONG_LENGTH=0           WRONG_MAP=0           WRONG_REDUCE=0   ru.rt.example.Map$Word           TOTAL_WORD_COUNT=655</code> </pre><br>  Dados errados podem ser enviados para stderr ou stdout ou gravar sa√≠da em hdfs usando a classe <code>MultipleOutputs</code> para an√°lises adicionais.  Os dados recebidos podem ser transmitidos para a entrada do aplicativo no modo aut√¥nomo ou ao gravar testes de unidade. <br><br>  O Hadoop possui a biblioteca MRUnit, que √© usada em conjunto com estruturas de teste (por exemplo, JUnit).  Ao escrever testes de unidade, verificamos que a fun√ß√£o produz o resultado esperado na sa√≠da.  Usamos a classe MapDriver do pacote MRUnit, nas propriedades das quais definimos a classe testada.  Para fazer isso, use o m√©todo <code>withMapper()</code> , os valores de entrada <code>withInputValue()</code> e o resultado esperado <code>withOutput()</code> ou <code>withMultiOutput()</code> se v√°rias sa√≠das forem usadas. <br><br>  Aqui est√° o nosso teste. <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> ru.rt.example; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.IntWritable; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.LongWritable; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.Text; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.mrunit.mapreduce.MapDriver; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.mrunit.types.Pair; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.junit.Before; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.junit.Test; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.io.IOException; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TestWordCount</span></span></span><span class="hljs-class"> </span></span>{   <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> MapDriver&lt;Object, Text, Text, IntWritable&gt; mapDriver;   <span class="hljs-meta"><span class="hljs-meta">@Before</span></span>  <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setUp</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{     Map mapper = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Map();     mapDriver.setMapper(mapper)  }   <span class="hljs-meta"><span class="hljs-meta">@Test</span></span>  <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mapperTest</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> IOException </span></span>{     mapDriver.withInput(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> LongWritable(<span class="hljs-number"><span class="hljs-number">0</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text(<span class="hljs-string"><span class="hljs-string">"msg1"</span></span>));     mapDriver.withOutput(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Pair&lt;Text, IntWritable&gt;(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text(<span class="hljs-string"><span class="hljs-string">"msg1"</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> IntWritable(<span class="hljs-number"><span class="hljs-number">1</span></span>)));     mapDriver.runTest();  } }</code> </pre><br><h3>  Modo totalmente distribu√≠do </h3><br>  Como o nome sugere, este √© um modo no qual todo o poder do Hadoop √© usado.  O programa MapReduce iniciado pode ser executado em 1000 servidores.  √â sempre dif√≠cil depurar o programa MapReduce, pois voc√™ tem mapeadores em execu√ß√£o em m√°quinas diferentes com dados de entrada diferentes. <br><br><h2>  Conclus√£o </h2><br>  Como se viu, testar o MapReduce n√£o √© t√£o f√°cil quanto parece √† primeira vista. <br>  Para economizar tempo procurando erros no MapReduce, usei todos os m√©todos listados acima e aconselho a todos que os apliquem tamb√©m.  Isso √© especialmente √∫til no caso de grandes instala√ß√µes, como as que funcionam no Rostelecom. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt432828/">https://habr.com/ru/post/pt432828/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt432818/index.html">Plotter caseiro: dicas para iniciantes, trabalhando com grbl-firmware</a></li>
<li><a href="../pt432820/index.html">Teste din√¢mico de aplicativos Android</a></li>
<li><a href="../pt432822/index.html">Eu estrago o c√≥digo da minha vida para desenvolvedores e n√£o quero</a></li>
<li><a href="../pt432824/index.html">Acelerando a cria√ß√£o do ConcurrentReferenceHashMap</a></li>
<li><a href="../pt432826/index.html">Desenvolvimento moderno do Android no Kotlin. Parte 2</a></li>
<li><a href="../pt432830/index.html">Sistema automatizado para impor multas por lixo abandonado</a></li>
<li><a href="../pt432832/index.html">Como "colar" um servidor baseado em Intel e superar o limite de expans√£o de 8 processadores</a></li>
<li><a href="../pt432834/index.html">Vincula√ß√£o interna e externa em C ++</a></li>
<li><a href="../pt432836/index.html">A primeira boa l√¢mpada de Aliexpress</a></li>
<li><a href="../pt432838/index.html">Desenvolvimento de software atrav√©s do prisma do experimento Milgram "Submiss√£o √† autoridade"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
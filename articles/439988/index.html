<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌵 ✴️ 😱 Tecnosfera cinco años 🎣 🐫 🈺</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoy, el proyecto Technosphere celebra su quinto aniversario. Estos son nuestros logros a lo largo de los años: 



- La capacitación fue completada po...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tecnosfera cinco años</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439988/"><img src="https://habrastorage.org/webt/cj/pv/zs/cjpvzsaftbfu81gtzrunmiybq1e.jpeg"><br><br>  Hoy, el proyecto Technosphere celebra su quinto aniversario.  Estos son nuestros logros a lo largo de los años: <br><br><ul><li>  La capacitación fue completada por 330 graduados. </li><li>  El curso tiene 120 estudiantes. </li><li>  Las clases son impartidas por 30 profesores. </li><li>  El plan de estudios tiene 250 lecciones en 16 disciplinas. </li><li>  Los alumnos realizan 71 DZ. </li><li>  8000 usuarios. </li><li>  Más de 100 estudiantes comenzaron sus carreras en el Grupo Mail.ru. </li></ul><br>  Al final de la capacitación, los estudiantes crean sus propios proyectos de graduación para los cuales tienen tres meses.  Y en honor al quinto aniversario de la tecnosfera, hemos recopilado los trabajos de graduación más brillantes de los últimos años.  Los propios graduados contarán sobre sus proyectos. <br><a name="habracut"></a><br><h2>  "Memoria brillante" </h2><br>  <i>Vsevolod Vikulin, Boris Kopin, Denis Kuzmin</i> <br><br>  Inicialmente, planeamos crear un servicio de retoque de imágenes que también nos permitiera colorear fotografías en blanco y negro.  Al discutir proyectos con mentores, surgió una idea para contarle al equipo de OK sobre esta idea, y como resultado, decidieron crear una aplicación especial con la función de colorear fotografías en blanco y negro de la guerra. <br><br>  Para hacer esto, tuvimos que diseñar la arquitectura de la red neuronal, crear un conjunto adecuado de fotos para entrenar el modelo y ejecutar la aplicación en la plataforma OK. <br><br>  Probamos muchas redes neuronales listas para usar, pero ninguna de ellas dio la calidad deseada.  Luego decidimos crear el nuestro.  En la primera etapa, la red neuronal intentó predecir la imagen RGB en el canal BW, pero el resultado fue regular, porque la red intentó colorear todo en tonos grises. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6cd/5ba/634/6cd5ba634444c03a4250cb474b94d964.png"><br>  <i>Un ejemplo del funcionamiento de la red neuronal original.</i> <br><br>  Luego decidimos usar una segunda red neuronal pre-entrenada. <br><br>  Con su ayuda, pudimos extraer signos tanto de la fotografía original en color como de la que fue pintada por la primera red neuronal.  Así que enseñamos a la segunda red neuronal a comprender qué colores son inherentes a ciertos objetos en la vida real: el cielo es azul, la hierba es verde, etc.  Para implementar redes neuronales, utilizamos el popular marco Pytorch. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7c4/348/a3d/7c4348a3dc43fb5a7a7b541d36145712.png"><br>  <i>Nueva arquitectura de red neuronal.</i> <br><br>  Pero lo principal era enseñarle al modelo cómo pintar los rostros de las personas de la manera más realista posible.  Nos enfrentamos al hecho de que entre los conjuntos de datos existentes no había nadie adecuado para nuestra tarea: necesitábamos grandes fotos de caras con un fondo natural.  Para formar nuestro propio conjunto de imágenes, primero creamos una lista de 5000 nombres de celebridades.  Luego, estos nombres fueron buscados por imágenes en varios motores de búsqueda.  Utilizando métodos de reconocimiento de rostros, se eliminaron las imágenes que no contenían rostros en absoluto, y los fragmentos más adecuados se resaltaron en las fotografías restantes.  Entonces recolectamos el conjunto necesario de 600 mil fotos. <br><br>  Luego vino la tarea de la pintura realista de un uniforme militar. <br><br>  Para resolverlo, tuve que generar artificialmente uniformes militares con varias medallas y órdenes.  Además, tuve que ver algunas películas en color sobre la guerra. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e7a/bbf/e25/e7abbfe25bb63ae60a379f63a50ff819.png"><br>  <i>Ejemplos de fotos del conjunto de entrenamiento.</i> <br><br>  Combinando todo esto con un conjunto popular de fotografías de uso general, recibimos 2.5 millones de fotografías para entrenar la red neuronal. <br><br>  Preparamos un prototipo funcional de la red neuronal y comenzamos a desarrollar una aplicación en la plataforma OK.  Esta es una aplicación web estándar con un backend y frontend.  Fuimos responsables del backend, y el equipo de OK se hizo cargo de la interfaz.  Realizando una evaluación realista de los recursos disponibles, decidimos que sería más racional utilizar la arquitectura actual del proyecto Artisto. <br><br>  Para hacer esto, portamos el código de red neuronal al marco de trabajo de Lua Torch y lo implementamos en el entorno. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c4e/cda/dde/c4ecdadde7831d73b22d153d57990e16.png"><br>  <i>La interfaz de la aplicación está bien.</i> <br><br>  El 9 de mayo, nuestra aplicación estuvo disponible para los compañeros de clase multimillonarios de Odnoklassniki, varios grandes medios de comunicación escribieron sobre esto, y actualmente 230 mil personas usan el servicio.  Fue muy difícil implementar el proyecto en tan poco tiempo, pero lo logramos todo.  Muchas gracias a nuestros mentores Olga Schubert y Alexei Voropaev, quienes nos ayudaron con la integración en OK.  También agradecemos al Grupo de Desarrollo de Infraestructura de Mail.ru Search por su ayuda con la integración en el proyecto Artisto, y por separado a Dmitry Solovyov por su invaluable asesoramiento sobre arquitectura de redes neuronales. <br><br><h2>  "Mapa musical" </h2><br>  <i>Vladimir Bugaevsky, Dana Zlochevskaya, Ralina Shavalieva</i> <i><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d07/b52/c64/d07b52c642a73ba5febc2eb7dbcaf3fd.png"></i> <br><br>  La idea del proyecto nos fue sugerida por los mentores Aleksey Voropaev y Dmitry Solovyov.  Había una vez un reproductor Sony que podía clasificar las canciones según cuatro estados de ánimo.  Hoy, la tecnología ha dado un gran paso adelante, la inteligencia artificial y las redes neuronales se están desarrollando activamente, y nos dimos cuenta de que podíamos hacer algo más genial que nuestros usuarios quisieran: una tarjeta de música que visualizara el estado de ánimo de las grabaciones de audio del usuario de VK.  Y decidieron implementarlo en forma de una extensión para Chrome: es fácil de instalar y cómodo de usar. <br><br>  Naturalmente, comenzamos explorando los enfoques que ya se usaban para determinar el estado de ánimo de la música.  Después de ver una docena de artículos científicos, nos dimos cuenta de que casi nadie había tratado de usar redes neuronales para analizar las emociones de las grabaciones de audio. <br><br>  Otra dificultad para nosotros fue la tarea de visualizar las emociones.  Resultó que en psicología hay muchos modelos para representar los estados de ánimo humanos, cada uno de los cuales tiene sus propias ventajas y desventajas.  Nos decidimos por el llamado modelo espacial circumplex: su idea es que cualquier emoción se pueda representar como un punto en un espacio bidimensional.  Gracias a esta escala, pudimos visualizar el estado de ánimo de sus grabaciones de audio de una manera comprensible para el usuario. <br><br>  Identificamos tres frentes de trabajo en la aplicación: <br><br><ul><li>  La parte del servidor aceptará solicitudes de expansión, creará espectrogramas, hará pronósticos y los devolverá al usuario. </li><li>  La parte del usuario con la que la persona interactuará. </li><li>  Entrenamiento de redes neuronales: preparar el conjunto de entrenamiento, elegir la arquitectura de red y el proceso de aprendizaje en sí. </li></ul><br>  El alcance del trabajo era extremadamente grande, por lo que todos podían probarse en todo.  Nuestro equipo actuó de manera muy coherente: constantemente encontramos diferentes formas de resolver ciertos problemas y nos ayudamos mutuamente a descubrir las características de la implementación de partes individuales.  La principal dificultad que encontramos fue un plazo extremadamente ajustado de tres meses.  Durante este tiempo, tuvimos que entender desde cero el desarrollo de la interfaz (aprender a escribir en JavaScript), las complejidades del marco para entrenar la red neuronal (PyTorch) y dominar la tecnología del desarrollo modular (Docker).  Ahora nuestra aplicación funciona en modo de prueba para varios usuarios. <br><br><h2>  "Colorización de video para profesionales" </h2><br>  <i>Yuri Admiralsky, Denis Bibik, Anton Bogovsky, George Kasparyants</i> <i><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a79/6ca/36d/a796ca36df3f386f587b930521f0444a.png"></i> <br><br>  La idea del proyecto surgió como resultado del análisis de las tendencias modernas en el desarrollo de redes neuronales para resolver los problemas de gráficos por computadora y procesamiento de contenido multimedia.  Ya se han propuesto varios enfoques diferentes para colorear imágenes individuales en esta área; este problema surge, por ejemplo, al procesar fotografías de archivo antiguas.  Por otro lado, el éxito de las versiones coloreadas de películas soviéticas en blanco y negro ha demostrado la relevancia de las tareas de coloración de video.  Colorear el video manualmente, cuadro por cuadro, es una tarea extremadamente lenta, cuya solución requiere la participación de estudios profesionales.  Y de los usuarios que desean obtener versiones en color de sus videos antiguos, pocos poseen las habilidades necesarias y tienen suficiente tiempo para colorear manualmente, sin mencionar el dinero para completar dicha tarea con la ayuda de equipos profesionales de estudios de video.  Por lo tanto, decidimos intentar aplicar los enfoques conocidos para colorear y crear un programa editor para reducir significativamente la complejidad de colorear videos usando redes neuronales. <br><br>  La tarea principal que tenía que resolverse al desarrollar un programa de este tipo era obtener los colores correctos al pintar objetos en el marco.  Nos enfrentamos al hecho de que los conjuntos de datos clásicos (por ejemplo, ImageNet) utilizados en el entrenamiento de redes neuronales para resolver problemas de procesamiento de imágenes no nos permiten lograr una buena coloración automática (sin ninguna información adicional).  Por ejemplo, algunos objetos en el marco no fueron reconocidos y permanecieron en blanco y negro en la imagen coloreada.  Otro problema de los modelos de vanguardia fue la elección incorrecta de colores para pintar objetos, tanto por la tarea que no se determinó (colorear la ropa) como por la definición incorrecta de objetos raros, así como los objetos afectados por artefactos de compresión.  Al cambiar los marcos, se observó un cambio de color en la coloración de los objetos presentes en el marco debido a la inestabilidad de los modelos a pequeños cambios en el marco. <br><br>  Para resolver este problema, aplicamos el método de <i>señales de color locales</i> , lo que nos permitió lograr la asignación de color correcta para todo el objeto y las transiciones de color correctas al establecer los colores de los puntos individuales de los objetos.  Al mismo tiempo, la red neuronal durante la coloración controla la observancia de los límites de los objetos y las transiciones de brillo.  Este enfoque nos permitió reducir la laboriosidad de colorear cuadros individuales (era necesario establecer explícitamente los colores de solo puntos individuales en el cuadro, sin usar pinceles), y ayudó a resolver el problema de subdeterminaciones y cambios de color al cambiar de cuadro.  Además, hemos implementado modelos que le permiten rastrear el movimiento de objetos en el marco y mover pistas de color.  Usando nuestro programa editor, coloreamos un fragmento de la vieja película en blanco y negro <i>The Kid</i> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f8e/434/9c0/f8e4349c06dd7abde533e12bb7be6770.png" width="300"><img src="https://habrastorage.org/getpro/habr/post_images/cf6/b1b/7df/cf6b1b7df13f26572801e3b7f2f0a33e.png" width="300"><br>  <i>Un ejemplo de un cuadro pintado de la película Chaplin The Kid (1921).</i> <br><br>  Implementamos el editor en forma de una aplicación independiente del cliente, en la que se carga el video, y luego los marcos se marcan con consejos de color.  Puede calcular los modelos de coloración en la máquina local o en la potencia de cómputo de terceros (por ejemplo, desplegando la parte del servidor en la nube) para procesar el video más rápido. <br><br>  Para crear el editor, hicimos mucho trabajo, incluyendo probar y finalizar modelos para colorear y rastrear objetos de marco, desarrollar una arquitectura cliente-servidor para la aplicación y determinar la usabilidad de la aplicación cliente.  Aprendimos las complejidades de trabajar con el marco PyTorch que implementa el trabajo de redes neuronales, dominamos el marco Qt 5 para desarrollar una aplicación cliente y aprendimos cómo usar Django-REST y Docker para desarrollar e implementar un backend informático. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c8/f00/0c1/8c8f000c1260e2342ed82233d5e9c0d7.png"><br>  <i>Un ejemplo de una aplicación cliente.</i> <br><br>  Gracias a los maestros de Technosphere por su dedicado trabajo, por el conocimiento relevante que les brindan a los estudiantes.  ¡Deseamos que el proyecto crezca y se desarrolle! <br><br>  * * * <br><br>  Puede solicitar capacitación hasta las 10:00 del 16 de febrero en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sphere.mail.ru</a> .  Tenga en cuenta que solo los estudiantes y estudiantes de posgrado de la Universidad Estatal de Moscú pueden estudiar en la tecnosfera.  M.V.  Lomonosov </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439988/">https://habr.com/ru/post/439988/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439978/index.html">Aprendizaje Docker, Parte 2: Términos y conceptos</a></li>
<li><a href="../439980/index.html">Aprendizaje Docker, Parte 3: Archivos Dockerfile</a></li>
<li><a href="../439982/index.html">Tutorial de React, Parte 16: La cuarta fase de trabajar en una aplicación TODO, Procesamiento de eventos</a></li>
<li><a href="../439984/index.html">Tutorial de React, Parte 17: La quinta etapa de trabajar en una aplicación TODO, modificar el estado de los componentes</a></li>
<li><a href="../439986/index.html">Chips VS amenazas a la tecnología de contenedorización</a></li>
<li><a href="../439990/index.html">El libro "IA pragmática. Aprendizaje automático y tecnología en la nube</a></li>
<li><a href="../439994/index.html">XAMPP - configuración del servidor virtual</a></li>
<li><a href="../440002/index.html">¿Cómo vender software corporativo y sobrevivir?</a></li>
<li><a href="../440008/index.html">Aumento del contenido de error de Go - github.com/ztrue/tracerr</a></li>
<li><a href="../440010/index.html">Reaccionar frente a angular: cómo una biblioteca puede competir con un marco</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
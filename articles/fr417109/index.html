<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÜò üëáüèø üëî Richard Hamming: Chapitre 10. Th√©orie du codage - I üêò üò• üïï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬´Le but de ce cours est de vous pr√©parer √† votre avenir technique.¬ª 
 Salut, Habr. Vous vous souvenez de l'article g√©nial "Vous et votre travail" (+21...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Richard Hamming: Chapitre 10. Th√©orie du codage - I</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417109/"><blockquote>  ¬´Le but de ce cours est de vous pr√©parer √† votre avenir technique.¬ª </blockquote><br><img src="https://habrastorage.org/getpro/habr/post_images/d67/6ff/9ea/d676ff9eadd2a38b0948de76bbf27fd4.jpg" alt="image" align="right">  Salut, Habr.  Vous vous souvenez de l'article g√©nial <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">"Vous et votre travail"</a> (+219, 2442 signets, 394k lectures)? <br><br>  Hamming (oui, oui, les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">codes Hamming √†</a> v√©rification automatique et √† correction automatique) a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">livre</a> entier √©crit sur la base de ses conf√©rences.  Nous le traduisons, parce que l'homme parle d'affaires. <br><br>  Ce livre n'est pas seulement sur l'informatique, c'est un livre sur le style de pens√©e des gens incroyablement cool.  <i>¬´Ce n'est pas seulement une charge de pens√©e positive;</i>  <i>il d√©crit les conditions qui augmentent les chances de faire du bon travail. ¬ª</i> <br><br>  Nous avons d√©j√† traduit 28 chapitres (sur 30).  Et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nous travaillons</a> sur une √©dition papier. <br><br><h3>  Th√©orie du codage - I </h3><br>  Apr√®s avoir consid√©r√© les ordinateurs et le principe de leur travail, nous allons maintenant consid√©rer la question de l'information: comment les ordinateurs repr√©sentent l'information que nous voulons traiter.  La signification de n'importe quel caract√®re peut d√©pendre de la fa√ßon dont il est trait√©, la machine n'a pas de signification sp√©cifique pour le bit utilis√©.  En discutant de l'histoire du logiciel, chapitre 4, nous avons consid√©r√© un langage de programmation synth√©tique, dans lequel le code de l'instruction break co√Øncidait avec le code d'autres instructions.  Cette situation est typique de la plupart des langues, la signification de l'instruction est d√©termin√©e par le programme correspondant. <br><br>  Pour simplifier le probl√®me de la pr√©sentation d'informations, nous consid√©rons le probl√®me de la transmission d'informations d'un point √† un autre.  Cette question est li√©e √† la question des informations sur la conservation.  Les probl√®mes de transmission d'informations dans le temps et dans l'espace sont identiques.  La figure 10.1 montre un mod√®le standard de transmission d'informations. <br><br><img src="https://habrastorage.org/webt/ba/-h/xi/ba-hxivlgh-iaa6jippqrpar6lm.jpeg" alt="image"><br><br>  <i>Figure 10.1</i> <br><a name="habracut"></a><br>  √Ä gauche sur la figure 10.1 se trouve la source d'informations.  Lorsque nous consid√©rons le mod√®le, nous ne nous soucions pas de la nature de la source.  Il peut s'agir d'un ensemble de symboles de l'alphabet, de nombres, de formules math√©matiques, de notes de musique, de symboles avec lesquels nous pouvons repr√©senter des mouvements de danse - la nature de la source et la signification des symboles qui y sont stock√©s ne font pas partie du mod√®le de transmission.  Nous ne consid√©rons que la source d'information, avec une telle restriction, nous obtenons une th√©orie g√©n√©rale puissante qui peut √™tre √©tendue √† de nombreux domaines.  Il s'agit d'une abstraction de nombreuses applications. <br><br>  Lorsque Shannon a cr√©√© la th√©orie de l'information √† la fin des ann√©es 40, on pensait qu'elle devrait s'appeler la th√©orie de la communication, mais il a insist√© sur le terme information.  Ce terme est devenu une cause constante √† la fois d'un int√©r√™t accru et d'une d√©ception constante en th√©orie.  Les enqu√™teurs ont voulu construire des ¬´th√©ories de l'information¬ª enti√®res, elles ont d√©g√©n√©r√© en une th√©orie d'un ensemble de personnages.  Revenant au mod√®le de transmission, nous avons une source de donn√©es qui doit √™tre cod√©e pour la transmission. <br><br>  L'encodeur se compose de deux parties, la premi√®re partie est appel√©e l'encodeur source, le nom exact d√©pend du type de source.  Les sources de diff√©rents types de donn√©es correspondent √† diff√©rents types de codeurs. <br><br>  La deuxi√®me partie du processus de codage est appel√©e codage de canal et d√©pend du type de canal pour la transmission de donn√©es.  Ainsi, la deuxi√®me partie du processus de codage est coh√©rente avec le type de canal de transmission.  Ainsi, lors de l'utilisation d'interfaces standard, les donn√©es de la source sont initialement cod√©es selon les exigences de l'interface, puis selon les exigences du canal de donn√©es utilis√©. <br><br>  Selon le mod√®le de la figure 10.1, le canal de donn√©es est expos√© √† un ¬´bruit al√©atoire suppl√©mentaire¬ª.  √Ä ce stade, tout le bruit dans le syst√®me est combin√©.  Il est suppos√© que le codeur accepte tous les caract√®res sans distorsion et que le d√©codeur remplit sa fonction sans erreur.  Il s'agit d'une certaine id√©alisation, mais √† de nombreuses fins pratiques, elle est proche de la r√©alit√©. <br><br>  La phase de d√©codage comprend √©galement deux √©tapes: canal - standard, standard - r√©cepteur de donn√©es.  √Ä la fin du transfert de donn√©es est transmis au consommateur.  Et encore une fois, nous ne consid√©rons pas comment le consommateur interpr√®te ces donn√©es. <br><br>  Comme indiqu√© pr√©c√©demment, un syst√®me de transmission de donn√©es, par exemple des messages t√©l√©phoniques, radio, programmes de t√©l√©vision, pr√©sente des donn√©es sous la forme d'un ensemble de nombres dans les registres d'un ordinateur.  Je le r√©p√®te, la transmission dans l'espace n'est pas diff√©rente de la transmission dans le temps ou du stockage d'informations.  Avez-vous des informations qui seront n√©cessaires apr√®s un certain temps, alors elles doivent √™tre encod√©es et stock√©es sur la source de stockage des donn√©es.  Si n√©cessaire, les informations sont d√©cod√©es.  Si le syst√®me de codage et de d√©codage est le m√™me, nous transmettons les donn√©es via le canal de transmission sans modifications. <br><br>  La diff√©rence fondamentale entre la th√©orie pr√©sent√©e et la th√©orie habituelle en physique est l'hypoth√®se qu'il n'y a pas de bruit dans la source et le r√©cepteur.  En fait, des erreurs se produisent dans n'importe quel √©quipement.  En m√©canique quantique, le bruit se produit √† n'importe quel stade selon le principe d'incertitude, et non comme une condition initiale;  en tout cas, le concept de bruit en th√©orie de l'information n'est pas √©quivalent √† un concept similaire en m√©canique quantique. <br>  Pour plus de pr√©cision, nous examinerons en outre la forme binaire de repr√©sentation des donn√©es dans le syst√®me.  Les autres formulaires sont trait√©s de mani√®re similaire, par souci de simplicit√©, nous ne les consid√©rerons pas. <br><br>  Nous commen√ßons notre examen des syst√®mes avec des caract√®res cod√©s de longueur variable, comme dans le code Morse classique de points et de tirets, dans lequel les caract√®res fr√©quents sont courts et les caract√®res rares sont longs.  Cette approche vous permet d'obtenir une efficacit√© √©lev√©e du code, mais il convient de noter que le code Morse est ternaire, pas binaire, car il contient un espace entre les points et les tirets.  Si tous les caract√®res du code ont la m√™me longueur, un tel code est appel√© code de bloc. <br><br>  La premi√®re propri√©t√© n√©cessaire √©vidente du code est la capacit√© de d√©coder de mani√®re unique le message en l'absence de bruit, du moins cela semble √™tre la propri√©t√© souhait√©e, bien que dans certaines situations cette exigence puisse √™tre n√©glig√©e.  Les donn√©es du canal de transmission pour le r√©cepteur ressemblent √† un flux de caract√®res provenant de z√©ros et de uns. <br><br>  Nous appellerons deux caract√®res adjacents une double extension, trois caract√®res adjacents une triple extension, et dans le cas g√©n√©ral, si nous transmettons N caract√®res, le r√©cepteur voit des ajouts au code de base de N caract√®res.  Le r√©cepteur, ne connaissant pas la valeur de N, doit diviser le flux en blocs de diffusion.  Ou, en d'autres termes, le r√©cepteur devrait √™tre en mesure de d√©composer le flux de mani√®re unique afin de restaurer le message d'origine. <br><br>  Consid√©rez un alphabet d'un petit nombre de caract√®res, g√©n√©ralement les alphabets sont beaucoup plus grands.  Les alphabets des langues commencent de 16 √† 36 caract√®res, y compris les majuscules et les minuscules, les signes num√©riques, la ponctuation.  Par exemple, dans la table ASCII 128 = 2 ^ 7 caract√®res. <br>  Consid√©rons un code sp√©cial compos√© de 4 caract√®res s1, s2, s3, s4 <br><br>  <b>s1 = 0;</b>  <b>s2 = 00;</b>  <b>s3 = 01;</b>  <b>s4 = 11.</b> <br><br>  Comment le r√©cepteur doit-il interpr√©ter la prochaine expression re√ßue <br><br>  <b>0011</b> ? <br><br>  Comment <b>s1s1s4</b> ou comment <b>s2s4</b> ? <br><br>  Vous ne pouvez pas r√©pondre sans ambigu√Øt√© √† cette question, ce code n'est certainement pas d√©cod√©, il n'est donc pas satisfaisant.  Code, d'autre part <br><br>  <b>s1 = 0;</b>  <b>s2 = 10;</b>  <b>s3 = 110;</b>  <b>s4 = 111</b> <br><br>  d√©code le message d'une mani√®re unique.  Prenez une cha√Æne arbitraire et r√©fl√©chissez √† la fa√ßon dont le r√©cepteur la d√©codera.  Vous devez construire un arbre de d√©codage selon le formulaire de la figure 10.II.  String <br><br>  <b>1101000010011011100010100110</b> ... <br><br>  peut √™tre divis√© en blocs de caract√®res <br><br>  <b>110, 10, 0, 10, 0, 110, 111, 0, 0, 0, 10, 10, 0, 110,</b> ... <br><br>  selon la r√®gle suivante pour construire un arbre de d√©codage: <br><br><blockquote>  Si vous √™tes au sommet de l'arborescence, lisez le caract√®re suivant.  Lorsque vous atteignez une feuille d'un arbre, vous convertissez la s√©quence en personnage et revenez au d√©but. </blockquote><br>  La raison de l'existence d'un tel arbre est qu'aucun caract√®re n'est un pr√©fixe de l'autre, vous savez donc toujours quand vous devez revenir au d√©but de l'arbre de d√©codage. <br><br>  Il est n√©cessaire de faire attention aux points suivants.  Premi√®rement, le d√©codage est un processus strictement en flux, dans lequel chaque bit n'est examin√© qu'une seule fois.  Deuxi√®mement, les protocoles incluent g√©n√©ralement des caract√®res qui marquent la fin du processus de d√©codage et sont n√©cessaires pour indiquer la fin d'un message. <br><br>  Le fait de ne pas utiliser de caract√®re de fin est une erreur courante dans la conception du code.  Bien s√ªr, vous pouvez fournir un mode de d√©codage constant, auquel cas le caract√®re de fin n'est pas n√©cessaire. <br><br><img src="https://habrastorage.org/webt/jx/zn/py/jxznpy6gu3tgjcqw_kcicihl49w.jpeg" alt="image"><br><br>  <i>Figure 10.II</i> <br><br>  La question suivante concerne les codes de d√©codage (instantan√©) de flux.  Consid√©rez le code obtenu √† partir du pr√©c√©dent en affichant des caract√®res <br><br>  <b>s1 = 0;</b>  <b>s2 = 01;</b>  <b>s3 = 011;</b>  <b>s4 = 111.</b> <br><br>  Supposons que nous obtenions la s√©quence <b>011111 ... 111</b> .  La seule fa√ßon de d√©coder le texte du message est de regrouper les bits de la fin de 3 en un groupe et de s√©lectionner des groupes avec un z√©ro devant devant ceux-ci, apr√®s quoi vous pouvez d√©coder.  Un tel code est d√©cod√© d'une mani√®re unique, mais pas instantan√©ment!  Pour le d√©codage, vous devez attendre la fin du transfert!  En pratique, cette approche √©limine le taux de d√©codage (th√©or√®me de Macmillan), il est donc n√©cessaire de rechercher des m√©thodes de d√©codage instantan√©. <br><br>  Consid√©rez deux fa√ßons de coder le m√™me caract√®re, Si: <br><br>  <b>s1 = 0;</b>  <b>s2 = 10;</b>  <b>s3 = 110;</b>  <b>s4 = 1110, s5 = 1111,</b> <br><br>  L'arbre de d√©codage de cette m√©thode est illustr√© √† la figure 10.III. <br><br><img src="https://habrastorage.org/webt/ox/bv/on/oxbvonl2ljgm0bgliqfgdy-qxsi.jpeg" alt="image"><br><br>  <i>Figure 10.III</i> <br><br>  Deuxi√®me voie <br><br>  <b>s1 = 00;</b>  <b>s2 = 01;</b>  <b>s3 = 100;</b>  <b>s4 = 110, s5 = 111</b> , <br><br>  L'arbre de d√©codage de cette prise en charge est illustr√© √† la figure 10.IV. <br><br>  La fa√ßon la plus √©vidente de mesurer la qualit√© du code est la longueur moyenne d'un ensemble de messages.  Pour cela, il est n√©cessaire de calculer la longueur de code de chaque caract√®re multipli√©e par la probabilit√© d'occurrence correspondante de pi.  Ainsi, la longueur de tout le code est obtenue.  La formule pour la longueur moyenne L du code pour un alphabet de q caract√®res est la suivante <br><br><img src="https://habrastorage.org/webt/o9/t8/hp/o9t8hprkvogq4j7tapnejfcqi5e.jpeg" alt="image"><br><br>  o√π pi est la probabilit√© d'occurrence du symbole si, li est la longueur correspondante du symbole cod√©.  Pour un code efficace, la valeur de L doit √™tre aussi petite que possible.  Si P1 = 1/2, p2 = 1/4, p3 = 1/8, p4 = 1/16 et p5 = 1/16, alors pour le code # 1, nous obtenons la valeur de longueur de code <br><br><img src="https://habrastorage.org/webt/gm/dh/mm/gmdhmmak1wygwdg2bzrhpwjw5ek.jpeg" alt="image"><br><br>  Et pour le code # 2 <br><br><img src="https://habrastorage.org/webt/wl/gx/w_/wlgxw_sxrvguf4x7zxy5ppsjdeg.jpeg" alt="image"><br><br>  Les valeurs obtenues indiquent la pr√©f√©rence du premier code. <br>  Si tous les mots de l'alphabet ont la m√™me probabilit√© d'occurrence, alors le deuxi√®me code sera plus pr√©f√©rable.  Par exemple, avec pi = 1/5, longueur de code # 1 <br><br><img src="https://habrastorage.org/webt/fq/m_/5e/fqm_5ew-iiumvzfzhfa-dzqrvp0.jpeg" alt="image"><br><br>  et longueur de code # 2 <br><br><img src="https://habrastorage.org/webt/so/h4/8h/soh48hms46bmymyvq2zfdjvhum0.jpeg" alt="image"><br><br>  ce r√©sultat montre une pr√©f√©rence pour 2 codes.  Ainsi, lors du d√©veloppement d'un ¬´bon¬ª code, il est n√©cessaire de consid√©rer la probabilit√© d'occurrence de caract√®res. <br><br><img src="https://habrastorage.org/webt/fl/z0/ta/flz0taltdxjpeh7d83nylufdezi.jpeg" alt="image"><br><br>  <i>Figure 10.IV</i> <br><br><img src="https://habrastorage.org/webt/ub/0r/oc/ub0roc6s1bd8_tbjmbbi5knnmsy.jpeg" alt="image"><br><br>  <i>Figure 10.V</i> <br><br>  Consid√©rons l'in√©galit√© Kraft, qui d√©termine la valeur limite de la longueur du code symbole li.  Dans la base 2, l'in√©galit√© est repr√©sent√©e comme <br><br><img src="https://habrastorage.org/webt/uf/fm/3x/uffm3x64fdcwpfqm0t59-58ojm8.jpeg" alt="image"><br><br>  Cette in√©galit√© sugg√®re que l'alphabet ne peut pas avoir trop de caract√®res courts, sinon la somme sera assez grande. <br><br>  Pour prouver l'in√©galit√© de Kraft pour tout code d√©cod√© unique rapide, nous construisons un arbre de d√©codage et appliquons la m√©thode d'induction math√©matique.  Si un arbre a une ou deux feuilles, comme le montre la figure 10.V, l'in√©galit√© est sans aucun doute vraie.  De plus, si l'arbre a plus de deux feuilles, alors nous divisons l'arbre de long m en deux sous-arbres.  Selon le principe d'induction, nous supposons que l'in√©galit√© est vraie pour chaque branche de hauteur m -1 ou moins.  Selon le principe d'induction, appliquer l'in√©galit√© √† chaque branche.  Notons les longueurs des codes des branches K 'et K' '.  Lors de la combinaison de deux branches d'un arbre, la longueur de chacune augmente de 1, par cons√©quent, la longueur du code se compose des sommes K '/ 2 et K' '/ 2, <br><br><img src="https://habrastorage.org/webt/g9/-s/vv/g9-svvn75bjqfxxcuzrxf-vz_h0.jpeg" alt="image"><br><br>  le th√©or√®me est prouv√©. <br><br>  Consid√©rez la preuve du th√©or√®me de Macmillan.  Nous appliquons l'in√©galit√© Kraft aux codes de d√©codage sans fil.  La preuve est bas√©e sur le fait que pour tout nombre K&gt; 1, la ni√®me puissance du nombre est √©videmment plus qu'une fonction lin√©aire de n, o√π n est un nombre assez important.  Nous √©levons l'in√©galit√© de Kraft √† la ni√®me puissance et pr√©sentons l'expression comme une somme <br><br><img src="https://habrastorage.org/webt/zv/kx/lm/zvkxlmytcctyyvabj5iwh8x2nui.jpeg" alt="image"><br><br>  o√π Nk est le nombre de caract√®res de longueur k, la sommation commence par la longueur minimale de la ni√®me repr√©sentation du caract√®re et se termine par la longueur maximale nl, o√π l est la longueur maximale du caract√®re cod√©.  De l'exigence d'un d√©codage unique, il s'ensuit que.  Le montant est pr√©sent√© comme <br><br><img src="https://habrastorage.org/webt/2b/pj/pe/2bpjpe5u9p6epynv-sfxvfym2ji.jpeg" alt="image"><br><br>  Si K&gt; 1, alors il faut √©tablir n suffisamment grand pour que l'in√©galit√© devienne fausse.  Par cons√©quent, k &lt;= 1;  Le th√©or√®me de Macmillan est prouv√©. <br><br>  Prenons quelques exemples d'application de l'in√©galit√© Kraft.  Un code d√©cod√© unique peut-il exister avec les longueurs 1, 3, 3, 3?  Oui, depuis <br><br><img src="https://habrastorage.org/webt/wc/y3/gp/wcy3gpqx-cl-e60fb3-im8ec6n4.jpeg" alt="image"><br><br>  Qu'en est-il des longueurs 1, 2, 2, 3?  Calculez selon la formule <br><br><img src="https://habrastorage.org/webt/ix/aa/qz/ixaaqzsj_qvuc0ug-nys8ezqexe.jpeg" alt="image"><br><br>  L'in√©galit√© viol√©e!  Il y a trop de caract√®res courts dans ce code. <br><br>  Les codes virgule sont des codes compos√©s de caract√®res 1, se terminant par un caract√®re 0, √† l'exception du dernier caract√®re compos√© de tous les caract√®res.  L'un des cas particuliers est le code. <br><br>  <b>s1 = 0;</b>  <b>s2 = 10;</b>  <b>s3 = 110;</b>  <b>s4 = 1110;</b>  <b>s5 = 11111.</b> <br><br>  Pour ce code, on obtient l'expression de l'in√©galit√© Kraft <br><br><img src="https://habrastorage.org/webt/dv/x5/pj/dvx5pjumdoxckpby4xczhlf8yso.jpeg" alt="image"><br><br>  Dans ce cas, nous atteignons l'√©galit√©.  Il est facile de voir que pour les codes de point, l'in√©galit√© de Kraft d√©g√©n√®re en √©galit√©. <br><br>  Lors de la construction d'un code, vous devez faire attention √† la quantit√© de Kraft.  Si le montant de Kraft commence √† d√©passer 1, alors c'est un signal sur la n√©cessit√© d'inclure un caract√®re d'une longueur diff√©rente pour r√©duire la longueur moyenne du code. <br><br>  Il convient de noter que l'in√©galit√© de Kraft ne signifie pas que ce code est uniquement d√©codable, mais qu'il existe un code avec des caract√®res d'une telle longueur qui est d√©cod√© de mani√®re unique.  Pour construire un code d√©cod√© unique, vous pouvez affecter la longueur correspondante en bits li avec un nombre binaire.  Par exemple, pour les longueurs 2, 2, 3, 3, 4, 4, 4, 4, on obtient l'in√©galit√© Kraft <br><br><img src="https://habrastorage.org/webt/dz/mf/ce/dzmfcev61jjvbppxsaqxblyetn4.jpeg" alt="image"><br><br>  Par cons√©quent, un tel code de flux d√©cod√© unique peut exister. <br><br>  <b>s1 = 00;</b>  <b>s2 = 01;</b>  <b>s3 = 100;</b>  <b>s4 = 101;</b> <b><br><br></b>  <b>s5 = 1100;</b>  <b>s6 = 1101;</b>  <b>s7 = 1110;</b>  <b>s8 = 1111;</b> <br><br>  Je veux faire attention √† ce qui se passe r√©ellement lorsque nous √©changeons des id√©es.  Par exemple, √† ce stade, je veux transf√©rer l'id√©e de ma t√™te √† la v√¥tre.  Je prononce quelques mots √† travers lesquels, je crois, vous pouvez comprendre (comprendre) cette id√©e. <br><br>  Mais quand un peu plus tard vous voudrez transmettre cette id√©e √† votre ami, vous prononcerez certainement des mots compl√®tement diff√©rents.  En fait, le sens ou la signification n'est enferm√© dans aucun mot sp√©cifique.  J'ai utilis√© quelques mots, et vous pouvez en utiliser des mots compl√®tement diff√©rents pour transmettre la m√™me id√©e.  Ainsi, diff√©rents mots peuvent transmettre la m√™me information.  Mais, d√®s que vous dites √† votre interlocuteur que vous ne comprenez pas le message, alors en r√®gle g√©n√©rale, l'interlocuteur s√©lectionnera un ensemble de mots diff√©rent, le deuxi√®me ou m√™me le troisi√®me, pour transmettre le sens.  Ainsi, les informations ne sont pas enferm√©es dans un ensemble de mots sp√©cifiques.  D√®s que vous recevez tel ou tel mot, alors vous faites beaucoup de travail pour traduire les mots en l'id√©e que l'interlocuteur veut vous transmettre. <br><br>  Nous apprenons √† s√©lectionner des mots afin de nous adapter √† l'interlocuteur.  Dans un sens, nous choisissons des mots correspondant √† nos pens√©es et au niveau de bruit dans le canal, bien qu'une telle comparaison ne refl√®te pas exactement le mod√®le que j'utilise pour repr√©senter le bruit dans le processus de d√©codage.  Dans les grandes organisations, un probl√®me grave est l‚Äôincapacit√© de l‚Äôinterlocuteur √† entendre ce qu‚Äôune autre personne a dit.  Aux postes sup√©rieurs, les employ√©s entendent ce qu'ils ¬´veulent entendre¬ª.  Dans certains cas, vous devez vous en souvenir lorsque vous montez dans l'√©chelle de carri√®re.  La pr√©sentation des informations sous une forme formelle est un reflet partiel des processus de notre vie et a trouv√© une large application bien au-del√† des limites des r√®gles formelles dans les applications informatiques. <br><br>  <i>√Ä suivre ...</i> <br><br>  <i>Qui veut aider √† la traduction, la mise en page et la publication du livre - √©crivez dans un e-mail personnel ou par courrier √©lectronique magisterludi2016@yandex.ru</i> <br><br>  Soit dit en passant, nous avons √©galement lanc√© la traduction d'un autre livre sympa - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´The Dream Machine: The History of the Computer Revolution¬ª</a> ) <br><br><div class="spoiler">  <b class="spoiler_title">Contenu du livre et chapitres traduits</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©face</a> <br><ol><li>  Introduction √† l'art de faire des sciences et du g√©nie: apprendre √† apprendre (28 mars 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Traduction: Chapitre 1</a> </li><li>  ¬´Fondements de la r√©volution num√©rique (discr√®te)¬ª (30 mars 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 2. Principes fondamentaux de la r√©volution num√©rique (discr√®te)</a> </li><li>  ¬´Histoire des ordinateurs - Mat√©riel¬ª (31 mars 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 3.</a> Histoire des ordinateurs - Mat√©riel </li><li>  ¬´Histoire des ordinateurs - logiciels¬ª (4 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 4. Histoire des ordinateurs - logiciels</a> </li><li>  Histoire des ordinateurs - Applications (6 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 5. Histoire des ordinateurs - Application pratique</a> </li><li>  ¬´Intelligence artificielle - Partie I¬ª (7 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 6. Intelligence artificielle - 1</a> </li><li>  ¬´Intelligence artificielle - Partie II¬ª (11 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 7. Intelligence artificielle - II</a> </li><li>  ¬´Intelligence artificielle III¬ª (13 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 8. Intelligence artificielle-III</a> </li><li>  ¬´Espace N-dimensionnel¬ª (14 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 9. Espace N-dimensionnel</a> </li><li>  ¬´Th√©orie du codage - La repr√©sentation de l'information, partie I¬ª (18 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 10. Th√©orie du codage - I</a> </li><li>  ¬´Th√©orie du codage - La repr√©sentation de l'information, partie II¬ª (20 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 11. Th√©orie du codage - II</a> </li><li>  ¬´Codes de correction d'erreurs¬ª (21 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 12. Codes de correction d'erreurs</a> </li><li>  "Th√©orie de l'information" (25 avril 1995) <i>(le traducteur a disparu: ((()</i> </li><li>  Filtres num√©riques, partie I (27 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 14. Filtres num√©riques - 1</a> </li><li>  Filtres num√©riques, partie II (28 avril 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 15. Filtres num√©riques - 2</a> </li><li>  Filtres num√©riques, partie III (2 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 16. Filtres num√©riques - 3</a> </li><li>  Filtres num√©riques, partie IV (4 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 17. Filtres num√©riques - IV</a> </li><li>  ¬´Simulation, partie I¬ª (5 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 18. Mod√©lisation - I</a> </li><li>  ¬´Simulation, Partie II¬ª (9 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 19. Mod√©lisation - II</a> </li><li>  "Simulation, Partie III" (11 mai 1995) </li><li>  Fibre optique (12 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 21. Fibre optique</a> </li><li>  ¬´Instruction assist√©e par ordinateur¬ª (16 mai 1995) <i>(le traducteur a disparu: ((()</i> </li><li>  Math√©matiques (18 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 23. Math√©matiques</a> </li><li>  M√©canique quantique (19 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 24. M√©canique quantique</a> </li><li>  Cr√©ativit√© (23 mai 1995).  Traduction: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 25. Cr√©ativit√©</a> </li><li>  ¬´Experts¬ª (25 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 26. Experts</a> </li><li>  ¬´Donn√©es non fiables¬ª (26 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 27. Donn√©es invalides</a> </li><li>  Ing√©nierie des syst√®mes (30 mai 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 28. Ing√©nierie des syst√®mes</a> </li><li>  ¬´Vous obtenez ce que vous mesurez¬ª (1er juin 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 29.</a> Vous obtenez ce que vous mesurez </li><li>  ¬´Comment savons-nous ce que nous savons¬ª (2 juin 1995) le <i>traducteur a disparu: (((</i> </li><li>  Hamming, ¬´Vous et vos recherches¬ª (6 juin 1995).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Traduction: vous et votre travail</a> </li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Qui veut aider √† la traduction, la mise en page et la publication du livre - √©crivez dans un e-mail personnel ou par courrier √©lectronique magisterludi2016@yandex.ru </font></font><br><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417109/">https://habr.com/ru/post/fr417109/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417099/index.html">Comment ai-je √©crit la biblioth√®que C ++ 11 standard ou pourquoi boost est si effrayant. Chapitre 2</a></li>
<li><a href="../fr417101/index.html">D√©finition de pr√™t - ce que nous avons oubli√© de dire</a></li>
<li><a href="../fr417103/index.html">Spark SQL. Un peu sur l'optimiseur de requ√™tes</a></li>
<li><a href="../fr417105/index.html">Impression sur une imprimante 3D. Exp√©riences secr√®tes de 3Dtool</a></li>
<li><a href="../fr417107/index.html">Cr√©ateur du jeu en mode True: d√©couvrez () la programmation gamedev, les probl√®mes VR et les simulations ML</a></li>
<li><a href="../fr417111/index.html">Conf√©rences en ligne: streaming vs webinaire</a></li>
<li><a href="../fr417113/index.html">Imprimante 3D italienne en Russie: Raise3D N1 Dual - mod√©lisation et prototypage</a></li>
<li><a href="../fr417115/index.html">Enterrer ou graver Flutter.io?</a></li>
<li><a href="../fr417117/index.html">R√©tro-ing√©nierie de l'√©mulateur NES dans le jeu pour GameCube</a></li>
<li><a href="../fr417119/index.html">Pagination dans Vue.js</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
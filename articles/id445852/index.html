<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👱🏿 👩‍👦 🤭 Cara membuat pemicu DAG di Aliran Udara menggunakan API Eksperimental 🐡 🍠 🍷</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Saat menyiapkan program pendidikan kami, kami secara berkala menghadapi kesulitan dalam hal bekerja dengan beberapa alat. Dan pada saat itu ketika kit...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cara membuat pemicu DAG di Aliran Udara menggunakan API Eksperimental</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/newprolab/blog/445852/"><p>  Saat menyiapkan program pendidikan kami, kami secara berkala menghadapi kesulitan dalam hal bekerja dengan beberapa alat.  Dan pada saat itu ketika kita bertemu mereka, tidak selalu ada cukup dokumentasi dan artikel yang akan membantu untuk mengatasi masalah ini. </p><br><p>  Ini adalah kasus, misalnya, pada tahun 2015 dan kami menggunakan cluster Hadoop dengan Spark untuk 35 pengguna simultan pada program Spesialis Data Besar.  Cara memasaknya di bawah kasus pengguna menggunakan BENANG tidak jelas.  Sebagai hasilnya, setelah mengetahui dan berjalan sendiri, mereka membuat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">posting tentang Habré</a> dan juga tampil di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Moscow Spark Meetup</a> . </p><br><h3 id="predystoriya">  Latar belakang </h3><br><p>  Kali ini kita akan berbicara tentang program lain - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Insinyur Data</a> .  Peserta kami membangun dua jenis arsitektur di atasnya: lambda dan kappa.  Dan dalam arsitektur lamdba, sebagai bagian dari pemrosesan batch, Airflow digunakan untuk mentransfer log dari HDFS ke ClickHouse. </p><br><p>  Semuanya baik secara umum.  Biarkan mereka membangun saluran pipa mereka.  Namun, ada "tetapi": semua program kami adalah teknologi dalam hal proses pembelajaran itu sendiri.  Untuk memeriksa lab, kami menggunakan pemeriksa otomatis: peserta harus masuk ke akun pribadinya, klik tombol "Periksa", dan setelah beberapa saat ia melihat semacam umpan balik panjang tentang apa yang telah ia lakukan.  Dan pada saat inilah kita mulai mendekati masalah kita. </p><a name="habracut"></a><br><p>  Memeriksa lab ini disusun sebagai berikut: kami mengirim paket data kontrol ke Kafka dari peserta, lalu Gobblin mentransfer paket data ke HDFS, kemudian Airflow mengambil paket data ini dan meletakkannya di ClickHouse.  Kuncinya adalah bahwa Airflow tidak harus melakukan ini secara real time, ia melakukannya sesuai jadwal: setiap 15 menit dibutuhkan banyak file dan melemparnya. </p><br><p> Ternyata kita perlu memicu DAG mereka sendiri atas permintaan pemeriksa di sini dan sekarang.  Googling, kami mengetahui bahwa untuk versi Airflow yang lebih baru ada yang disebut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">API Eksperimental</a> .  Kata <code>experimental</code> , tentu saja, terdengar menakutkan, tetapi apa yang harus dilakukan ... Tiba-tiba itu akan terbang. </p><br><p>  Selanjutnya, kami jelaskan seluruhnya: dari menginstal Airflow hingga menghasilkan permintaan POST yang memicu DAG menggunakan API Eksperimental.  Kami akan bekerja dengan Ubuntu 16.04. </p><br><h3>  1. Menginstal Airflow </h3><br><p>  Mari kita periksa apakah kita memiliki Python 3 dan virtualenv. </p><br><pre> <code class="python hljs">$ python3 --version Python <span class="hljs-number"><span class="hljs-number">3.6</span></span><span class="hljs-number"><span class="hljs-number">.6</span></span> $ virtualenv --version <span class="hljs-number"><span class="hljs-number">15.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span></code> </pre> <br><p>  Jika ada yang hilang, maka instal. </p><br><p>  Sekarang buat direktori di mana kami akan terus bekerja dengan Airflow. </p><br><pre> <code class="bash hljs">$ mkdir &lt;your name of directory&gt; $ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /path/to/your/new/directory $ virtualenv -p <span class="hljs-built_in"><span class="hljs-built_in">which</span></span> python3 venv $ <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> venv/bin/activate (venv) $</code> </pre> <br><p>  Pasang Aliran Udara: </p><br><pre> <code class="bash hljs">(venv) $ pip install airflow</code> </pre> <br><p>  Versi tempat kami bekerja: 1.10. </p><br><p>  Sekarang kita perlu membuat direktori <code>airflow_home</code> mana file DAG dan plugin Airflow akan ditemukan.  Setelah membuat direktori, atur variabel lingkungan <code>AIRFLOW_HOME</code> . </p><br><pre> <code class="bash hljs">(venv) $ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /path/to/my/airflow/workspace (venv) $ mkdir airflow_home (venv) $ <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> AIRFLOW_HOME=&lt;path to airflow_home&gt;</code> </pre> <br><p>  Langkah selanjutnya adalah menjalankan perintah yang akan membuat dan menginisialisasi database aliran data dalam SQLite: </p><br><pre> <code class="bash hljs">(venv) $ airflow initdb</code> </pre> <br><p>  Basis data akan dibuat di <code>airflow.db</code> secara default. </p><br><p>  Periksa apakah Aliran Udara diinstal: </p><br><pre> <code class="bash hljs">$ airflow version [2018-11-26 19:38:19,607] {__init__.py:57} INFO - Using executor SequentialExecutor [2018-11-26 19:38:19,745] {driver.py:123} INFO - Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt [2018-11-26 19:38:19,771] {driver.py:123} INFO - Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt ____________ _____________ ____ |__( )_________ __/__ /________ __ ____ /| |_ /__ ___/_ /_ __ /_ __ \_ | /| / / ___ ___ | / _ / _ __/ _ / / /_/ /_ |/ |/ / _/_/ |_/_/ /_/ /_/ /_/ \____/____/|__/ v1.10.0</code> </pre> <br><p>  Jika perintah itu berhasil, maka Airflow membuat file konfigurasinya <code>airflow.cfg</code> di <code>AIRFLOW_HOME</code> : </p><br><pre> <code class="bash hljs">$ tree . ├── airflow.cfg └── unittests.cfg</code> </pre> <br><p>  Airflow memiliki antarmuka web.  Itu dapat diluncurkan dengan menjalankan perintah: </p><br><pre> <code class="bash hljs">(venv) $ airflow webserver --port 8081</code> </pre> <br><p>  Sekarang Anda dapat mengakses antarmuka web di browser pada port 8081 pada host tempat Airflow diluncurkan, misalnya: <code>&lt;hostname:8081&gt;</code> . </p><br><h3 id="2-rabota-s-experimental-api">  2. Bekerja dengan API Eksperimental </h3><br><p>  Pada ini, Aliran Udara dikonfigurasi dan siap untuk pergi.  Namun, kami juga perlu menjalankan API Eksperimental.  Checker kami ditulis dalam Python, jadi selanjutnya semua permintaan akan ada di dalamnya menggunakan perpustakaan <code>requests</code> . </p><br><p>  Faktanya, API sudah berfungsi untuk permintaan sederhana.  Misalnya, permintaan semacam itu memungkinkan Anda menguji operasinya: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests &gt;&gt;&gt; host = &lt;your hostname&gt; &gt;&gt;&gt; airflow_port = <span class="hljs-number"><span class="hljs-number">8081</span></span> <span class="hljs-comment"><span class="hljs-comment">#   ,    8080 &gt;&gt;&gt; requests.get('http://{}:{}/{}'.format(host, airflow_port, 'api/experimental/test').text 'OK'</span></span></code> </pre> <br><p>  Jika Anda menerima pesan seperti itu sebagai tanggapan, maka ini berarti semuanya berfungsi. </p><br><p>  Namun, ketika kami ingin mengaktifkan DAG, kami akan menghadapi kenyataan bahwa permintaan semacam ini tidak dapat dibuat tanpa otentikasi. </p><br><p>  Untuk melakukan ini, Anda perlu melakukan sejumlah tindakan. </p><br><p>  Pertama, Anda perlu menambahkan ini ke konfigurasi: </p><br><pre> <code class="plaintext hljs">[api] auth_backend = airflow.contrib.auth.backends.password_auth</code> </pre> <br><p>  Kemudian, Anda perlu membuat pengguna Anda dengan hak admin: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> airflow &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> airflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> models, settings &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> airflow.contrib.auth.backends.password_auth <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PasswordUser &gt;&gt;&gt; user = PasswordUser(models.Admin()) &gt;&gt;&gt; user.username = <span class="hljs-string"><span class="hljs-string">'new_user_name'</span></span> &gt;&gt;&gt; user.password = <span class="hljs-string"><span class="hljs-string">'set_the_password'</span></span> &gt;&gt;&gt; session = settings.Session() &gt;&gt;&gt; session.add(user) &gt;&gt;&gt; session.commit() &gt;&gt;&gt; session.close() &gt;&gt;&gt; exit()</code> </pre> <br><p>  Kemudian, Anda perlu membuat pengguna dengan hak normal, yang akan diizinkan membuat pemicu DAG. </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> airflow &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> airflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> models, settings &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> airflow.contrib.auth.backends.password_auth <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PasswordUser &gt;&gt;&gt; user = PasswordUser(models.User()) &gt;&gt;&gt; user.username = <span class="hljs-string"><span class="hljs-string">'newprolab'</span></span> &gt;&gt;&gt; user.password = <span class="hljs-string"><span class="hljs-string">'Newprolab2019!'</span></span> &gt;&gt;&gt; session = settings.Session() &gt;&gt;&gt; session.add(user) &gt;&gt;&gt; session.commit() &gt;&gt;&gt; session.close() &gt;&gt;&gt; exit()</code> </pre> <br><p>  Sekarang semuanya sudah siap. </p><br><h3 id="3-zapusk-post-zaprosa">  3. Memulai permintaan POST </h3><br><p>  Permintaan POST itu sendiri akan terlihat seperti ini: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>dag_id = newprolab &gt;&gt;&gt; url = <span class="hljs-string"><span class="hljs-string">'http://{}:{}/{}/{}/{}'</span></span>.format(host, airflow_port, <span class="hljs-string"><span class="hljs-string">'api/experimental/dags'</span></span>, dag_id, <span class="hljs-string"><span class="hljs-string">'dag_runs'</span></span>) &gt;&gt;&gt; data = {<span class="hljs-string"><span class="hljs-string">"conf"</span></span>:<span class="hljs-string"><span class="hljs-string">"{\"key\":\"value\"}"</span></span>} &gt;&gt;&gt; headers = {<span class="hljs-string"><span class="hljs-string">'Content-type'</span></span>: <span class="hljs-string"><span class="hljs-string">'application/json'</span></span>} &gt;&gt;&gt; auth = (<span class="hljs-string"><span class="hljs-string">'newprolab'</span></span>, <span class="hljs-string"><span class="hljs-string">'Newprolab2019!'</span></span>) &gt;&gt;&gt; uri = requests.post(url, data=json.dumps(data), headers=headers, auth=auth) &gt;&gt;&gt; uri.text <span class="hljs-string"><span class="hljs-string">'{\n "message": "Created &lt;DagRun newprolab @ 2019-03-27 10:24:25+00:00: manual__2019-03-27T10:24:25+00:00, externally triggered: True&gt;"\n}\n'</span></span></code> </pre> <br><p>  Permintaan berhasil diproses. </p><br><p>  Maka, kami memberikan waktu kepada DAG untuk memproses dan membuat permintaan ke tabel ClickHouse, mencoba menangkap paket kontrol data. </p><br><p>  Verifikasi selesai. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id445852/">https://habr.com/ru/post/id445852/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id445834/index.html">Mengembangkan keterampilan menggunakan pengelompokan dan visualisasi data dalam Python</a></li>
<li><a href="../id445838/index.html">Robotika untuk anak-anak: mata robot</a></li>
<li><a href="../id445844/index.html">GitLab 11.9 Dirilis dengan Deteksi Rahasia dan Berbagai Aturan Resolusi Permintaan Marge</a></li>
<li><a href="../id445846/index.html">Postgres Profesional</a></li>
<li><a href="../id445850/index.html">Perbaikan Sharp Memowriter EL-7000 Note Perangkat Penyimpanan dan Pencetakan Setelah Baterai Kebocoran</a></li>
<li><a href="../id445854/index.html">Menemukan Kerangka JS untuk Generasi UI</a></li>
<li><a href="../id445856/index.html">Telegram setelah 5 tahun</a></li>
<li><a href="../id445858/index.html">Barang Antik: Ketika Ponsel Aneh</a></li>
<li><a href="../id445860/index.html">Volatilitas Rendah Bitcoin (BTC) Akan Membawa ke Run Crypto Bull Selanjutnya</a></li>
<li><a href="../id445862/index.html">JS dari semua sisi: 10 laporan teratas HolyJS 2018 Moskow</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧖🏾 💅🏾 💃🏼 Gravando o XGBoost a partir do zero - parte 2: aumento de gradiente ☕️ 🕵🏽 🍻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Olá pessoal! 

 No último artigo, descobrimos como as árvores de decisão são organizadas e, do zero, implementamos 
 algoritmo de construção, otimizan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Gravando o XGBoost a partir do zero - parte 2: aumento de gradiente</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/438562/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ll/lb/oe/lllboex0ltvh9n7kpkfomxfz_p8.jpeg"></div><br>  Olá pessoal! <br><br>  No <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">último artigo,</a> descobrimos como as árvores de decisão são organizadas e, do zero, implementamos <br>  algoritmo de construção, otimizando e melhorando simultaneamente.  Neste artigo, implementaremos o algoritmo de aumento de gradiente e, no final, criaremos nosso próprio XGBoost.  A narração seguirá o mesmo padrão: escrevemos um algoritmo, descrevemos e resumimos comparando os resultados do trabalho com análogos do Sklearn. <br><br>  Neste artigo, a ênfase também será colocada na implementação em código; portanto, é melhor ler toda a teoria juntos em outra (por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no curso ODS</a> ) e, já com o conhecimento da teoria, você pode prosseguir para este artigo, pois o tópico é bastante complicado. <br><br><img src="https://habrastorage.org/webt/l0/vy/cx/l0vycx4dsrrohxafyliapuq7nxi.png"><br><a name="habracut"></a><br>  O que é aumento de gradiente?  A imagem de um jogador de golfe descreve perfeitamente a idéia principal.  Para empurrar a bola para dentro do buraco, o jogador de golfe faz cada próximo golpe levando em consideração a experiência de tacadas anteriores - para ele, essa é uma condição necessária para colocar a bola no buraco.  Se for muito rude (não sou mestre em golfe :)), a cada novo golpe, a primeira coisa que um jogador observa é a distância entre a bola e o buraco após o golpe anterior.  E a principal tarefa é reduzir essa distância com o próximo golpe. <br><br>  O impulso é construído de maneira muito semelhante.  Primeiro, precisamos introduzir a definição de "buraco", ou seja, a meta pela qual lutaremos.  Em segundo lugar, precisamos aprender a entender de que lado precisamos vencer com um clube para nos aproximarmos do objetivo.  Em terceiro lugar, levando em consideração todas essas regras, é necessário criar a seqüência correta de tacadas para que cada uma delas subseqüente reduza a distância entre a bola e o buraco. <br><br>  Agora, damos uma definição um pouco mais rigorosa.  Introduzimos o modelo de votação ponderada: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">h</span><span class="MJXp-mo" id="MJXp-Span-3" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">x</span><span class="MJXp-mo" id="MJXp-Span-5" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-6" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-7">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-9">u</span><span class="MJXp-msubsup" id="MJXp-Span-10"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">n</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-12"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13">i</span><span class="MJXp-mo" id="MJXp-Span-14">=</span><span class="MJXp-mn" id="MJXp-Span-15">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-17"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-19" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-20"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-21" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-22" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-23" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">x</span><span class="MJXp-mtext" id="MJXp-Span-25">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-26">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28">X</span><span class="MJXp-mo" id="MJXp-Span-29" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-30"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-32" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mtext" id="MJXp-Span-33">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-34">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36">R</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> h (x) = \ sum_ {i = 1} ^ nb_ia_i, x \ em X, b_i \ em R </script></p><br>  Aqui <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-37"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38">X</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-2"> X </script>  É o espaço do qual tiramos objetos, <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-39"><span class="MJXp-msubsup" id="MJXp-Span-40"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-42" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-43" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-44"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-46" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-3"> b_i, a_i </script>  - este é o coeficiente na frente do modelo e o próprio modelo, ou seja, a árvore de decisão.  Suponha que já em alguma etapa, usando as regras descritas, fosse possível adicionar à composição <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">T</span><span class="MJXp-mo" id="MJXp-Span-49" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mn" id="MJXp-Span-50">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-4"> T-1 </script>  algoritmo fraco.  Para aprender a entender que tipo de algoritmo deve estar na etapa <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-51"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-52">T</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-5"> T </script>  , apresentamos a função de erro: <br><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-53"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56">r</span><span class="MJXp-mo" id="MJXp-Span-57" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-58">h</span><span class="MJXp-mo" id="MJXp-Span-59" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-60" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-61">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-63">u</span><span class="MJXp-msubsup" id="MJXp-Span-64"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70">N</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-66"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-67">j</span><span class="MJXp-mo" id="MJXp-Span-68">=</span><span class="MJXp-mn" id="MJXp-Span-69">1</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-71">L</span><span class="MJXp-mo" id="MJXp-Span-72" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-73">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-74">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-75">u</span><span class="MJXp-msubsup" id="MJXp-Span-76"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-82"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-83">T</span><span class="MJXp-mo" id="MJXp-Span-84">−</span><span class="MJXp-mn" id="MJXp-Span-85">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-78"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79">i</span><span class="MJXp-mo" id="MJXp-Span-80">=</span><span class="MJXp-mn" id="MJXp-Span-81">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-86"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-88" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-89"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-90" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-91" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-92" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-93"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-94" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-95" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-96" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-97" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-98"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-99" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-100" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-msubsup" id="MJXp-Span-101"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-102" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-103" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-mo" id="MJXp-Span-104" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-105"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-106" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-107" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-108" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-109" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mtext" id="MJXp-Span-110">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-111">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-112">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-114">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-115">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-116">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-118">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-119">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-120">w</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-122">i</span><span class="MJXp-msubsup" id="MJXp-Span-123"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-124" style="margin-right: 0.05em;">n</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-125" style="vertical-align: -0.4em;"><span class="MJXp-msubsup" id="MJXp-Span-126"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-128" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-mo" id="MJXp-Span-129">,</span><span class="MJXp-msubsup" id="MJXp-Span-130"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-131" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-132" style="vertical-align: -0.4em;">T</span></span></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-6"> err (h) = \ sum_ {j = 1} ^ N L (\ sum_ {i = 1} ^ {T-1} a_ib_i (x_j) + b_Ta_T (x_j)) \ rightarrow min_ {a_T, b_T} </script><br><br>  Acontece que o melhor algoritmo será aquele que pode minimizar o erro recebido nas iterações anteriores.  E como o aumento é gradiente, essa função de erro deve necessariamente ter um vetor antigradiente ao longo do qual você pode se mover em busca de um mínimo.  Isso é tudo! <br><br>  Imediatamente antes da implementação, adicionarei algumas palavras sobre como tudo será organizado conosco.  Como no artigo anterior, tomamos o MSE como uma perda.  Vamos calcular seu gradiente: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-133"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-136">e</span><span class="MJXp-mo" id="MJXp-Span-137" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-138">y</span><span class="MJXp-mo" id="MJXp-Span-139" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-140">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-141">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-144">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-145">r</span><span class="MJXp-mo" id="MJXp-Span-146" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-147" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-148" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-149">y</span><span class="MJXp-mo" id="MJXp-Span-150" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-151">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-152">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-153">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-154">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-155">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-156">r</span><span class="MJXp-msubsup" id="MJXp-Span-157"><span class="MJXp-mo" id="MJXp-Span-158" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-159" style="vertical-align: 0.5em;">2</span></span><span class="MJXp-mspace" id="MJXp-Span-160" style="width: 0em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-161">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-162">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-163">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-165">l</span><span class="MJXp-msubsup" id="MJXp-Span-166"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-167" style="margin-right: 0.05em;">a</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-168" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-169">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-170">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-171">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-172">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-173">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174">r</span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-175">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-176">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-177">e</span><span class="MJXp-mo" id="MJXp-Span-178" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-179">y</span><span class="MJXp-mo" id="MJXp-Span-180" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-181">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-182">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-183">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-184">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-185">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-186">r</span><span class="MJXp-mo" id="MJXp-Span-187" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-188" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-189">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-190">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-191">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-192">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-193">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-194">r</span><span class="MJXp-mo" id="MJXp-Span-195" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-196">y</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-7"> mse (y, prever) = (y - prever) ^ 2 \\ \ nabla_ {prever} mse (y, prever) = prever - y </script></p><br>  Assim, o vetor antigradiente será igual a <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-197"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-198">y</span><span class="MJXp-mo" id="MJXp-Span-199" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-200">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-201">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-202">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-203">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-204">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-205">r</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-8"> y - prever </script>  .  Na etapa <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-206"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-207">i</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-9"> i </script>  consideramos os erros do algoritmo obtido em iterações anteriores.  Em seguida, treinamos nosso novo algoritmo nesses erros e o adicionamos ao nosso conjunto com um sinal de menos e algum coeficiente. <br><br>  Agora vamos começar. <br><br><h3>  1. Implementação da classe usual de aumento de gradiente </h3><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm_notebook <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datasets <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mean_squared_error <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mse <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.tree <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> DecisionTreeRegressor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools %matplotlib inline %load_ext Cython %%cython -a <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np cimport numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * cdef <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RegressionTreeFastMse</span></span></span><span class="hljs-class">:</span></span> cdef public int max_depth cdef public int feature_idx cdef public int min_size cdef public int averages cdef public np.float64_t feature_threshold cdef public np.float64_t value cpdef RegressionTreeFastMse left cpdef RegressionTreeFastMse right <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, max_depth=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">4</span></span></span></span><span class="hljs-function"><span class="hljs-params">, averages=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.max_depth = max_depth self.min_size = min_size self.value = <span class="hljs-number"><span class="hljs-number">0</span></span> self.feature_idx = <span class="hljs-number"><span class="hljs-number">-1</span></span> self.feature_threshold = <span class="hljs-number"><span class="hljs-number">0</span></span> self.left = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.right = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, np.ndarray[np.float64_t, ndim=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">] X, np.ndarray[np.float64_t, ndim=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">] y)</span></span></span><span class="hljs-function">:</span></span> cpdef np.float64_t mean1 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t mean2 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef long N = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cpdef long N1 = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cpdef long N2 = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef np.float64_t delta1 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t delta2 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t sm1 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t sm2 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef list index_tuples cpdef list stuff cpdef long idx = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef np.float64_t prev_error1 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t prev_error2 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef long thres = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef np.float64_t error = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.ndarray[long, ndim=<span class="hljs-number"><span class="hljs-number">1</span></span>] idxs cpdef np.float64_t x = <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-comment"><span class="hljs-comment">#   -   y self.value = y.mean() #   - mse     base_error = ((y - self.value) ** 2).sum() error = base_error flag = 0 #     if self.max_depth &lt;= 1: return dim_shape = X.shape[1] left_value, right_value = 0, 0 for feat in range(dim_shape): prev_error1, prev_error2 = base_error, 0 idxs = np.argsort(X[:, feat]) #      mean1, mean2 = y.mean(), 0 sm1, sm2 = y.sum(), 0 N = X.shape[0] N1, N2 = N, 0 thres = 1 while thres &lt; N - 1: N1 -= 1 N2 += 1 idx = idxs[thres] x = X[idx, feat] #   -  ,  ,    delta1 = (sm1 - y[idx]) * 1.0 / N1 - mean1 delta2 = (sm2 + y[idx]) * 1.0 / N2 - mean2 #   sm1 -= y[idx] sm2 += y[idx] #    O(1) prev_error1 += (delta1**2) * N1 prev_error1 -= (y[idx] - mean1)**2 prev_error1 -= 2 * delta1 * (sm1 - mean1 * N1) mean1 = sm1/N1 prev_error2 += (delta2**2) * N2 prev_error2 += (y[idx] - mean2)**2 prev_error2 -= 2 * delta2 * (sm2 - mean2 * N2) mean2 = sm2/N2 #       if thres &lt; N - 1 and np.abs(x - X[idxs[thres + 1], feat]) &lt; 1e-5: thres += 1 continue if (prev_error1 + prev_error2 &lt; error): if (min(N1,N2) &gt; self.min_size): #         self.feature_idx, self.feature_threshold = feat, x #     left_value, right_value = mean1, mean2 #  -     flag = 1 error = prev_error1 + prev_error2 thres += 1 #   ,  if self.feature_idx == -1: return #    self.left = RegressionTreeFastMse(self.max_depth - 1) self.left.value = left_value self.right = RegressionTreeFastMse(self.max_depth - 1) self.right.value = right_value #      idxs_l = (X[:, self.feature_idx] &gt; self.feature_threshold) idxs_r = (X[:, self.feature_idx] &lt;= self.feature_threshold) #   self.left.fit(X[idxs_l, :], y[idxs_l]) self.right.fit(X[idxs_r, :], y[idxs_r]) def __predict(self, np.ndarray[np.float64_t, ndim=1] x): if self.feature_idx == -1: return self.value if x[self.feature_idx] &gt; self.feature_threshold: return self.left.__predict(x) else: return self.right.__predict(x) def predict(self, np.ndarray[np.float64_t, ndim=2] X): y = np.zeros(X.shape[0]) for i in range(X.shape[0]): y[i] = self.__predict(X[i]) return y</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">GradientBoosting</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, n_estimators=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">100</span></span></span></span><span class="hljs-function"><span class="hljs-params">, learning_rate=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, max_depth=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, random_state=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">17</span></span></span></span><span class="hljs-function"><span class="hljs-params">, n_samples = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">15</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, base_tree=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'Bagging'</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.n_estimators = n_estimators self.max_depth = max_depth self.learning_rate = learning_rate self.initialization = <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> y: np.mean(y) * np.ones([y.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]]) self.min_size = min_size self.loss_by_iter = [] self.trees_ = [] self.loss_by_iter_test = [] self.n_samples = n_samples self.base_tree = base_tree <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, X, y)</span></span></span><span class="hljs-function">:</span></span> self.X = X self.y = y b = self.initialization(y) prediction = b.copy() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm_notebook(range(self.n_estimators)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> t == <span class="hljs-number"><span class="hljs-number">0</span></span>: resid = y <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-comment"><span class="hljs-comment">#    resid = (y - prediction) #    if self.base_tree == 'Bagging': tree = Bagging(max_depth=self.max_depth, min_size = self.min_size) if self.base_tree == 'Tree': tree = RegressionTreeFastMse(max_depth=self.max_depth, min_size = self.min_size) #     tree.fit(X, resid) #        b = tree.predict(X).reshape([X.shape[0]]) self.trees_.append(tree) prediction += self.learning_rate * b #       if t &gt; 0: self.loss_by_iter.append(mse(y,prediction)) return self def predict(self, X): #   –          pred = np.ones([X.shape[0]]) * np.mean(self.y) #    for t in range(self.n_estimators): pred += self.learning_rate * self.trees_[t].predict(X).reshape([X.shape[0]]) return pred</span></span></code> </pre><br>  Agora, construiremos a curva de perda no conjunto de treinamento para garantir que a cada iteração realmente tenhamos uma diminuição. <br><br><pre> <code class="python hljs">GDB = GradientBoosting(n_estimators=<span class="hljs-number"><span class="hljs-number">50</span></span>) GDB.fit(X,y) x = GDB.predict(X) plt.grid() plt.title(<span class="hljs-string"><span class="hljs-string">'Loss by iterations'</span></span>) plt.plot(GDB.loss_by_iter)</code> </pre> <br><img src="https://habrastorage.org/webt/je/2u/dp/je2udpxa0zdsvsmjqk4mmwmprlo.png"><br><br><h3>  2. Ensacamento sobre árvores decisivas </h3><br>  Bem, antes de compararmos os resultados, vamos falar sobre o procedimento de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">empacotar</a> árvores. <br><br>  Tudo é simples aqui: queremos nos proteger da reciclagem e, portanto, com a ajuda da amostragem com retorno, calcularemos a média de nossas previsões para não gerar emissões acidentalmente (por que isso funciona - leia melhor o link). <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Bagging</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-string"><span class="hljs-string">'''  Bagging -      . '''</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, max_depth = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">, n_samples = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#super(CART, self).__init__() self.max_depth = max_depth self.min_size = min_size self.n_samples = n_samples self.subsample_size = None self.list_of_Carts = [RegressionTreeFastMse(max_depth=self.max_depth, min_size=self.min_size) for _ in range(self.n_samples)] def get_bootstrap_samples(self, data_train, y_train): #      indices = np.random.randint(0, len(data_train), (self.n_samples, self.subsample_size)) samples_train = data_train[indices] samples_y = y_train[indices] return samples_train, samples_y def fit(self, data_train, y_train): #    self.subsample_size = int(data_train.shape[0]) samples_train, samples_y = self.get_bootstrap_samples(data_train, y_train) for i in range(self.n_samples): self.list_of_Carts[i].fit(samples_train[i], samples_y[i].reshape(-1)) return self def predict(self, test_data): #        num_samples = test_data.shape[0] pred = [] for i in range(self.n_samples): pred.append(self.list_of_Carts[i].predict(test_data)) pred = np.array(pred).T return np.array([np.mean(pred[i]) for i in range(num_samples)])</span></span></code> </pre><br>  Bem, agora como algoritmo básico, podemos usar não apenas uma árvore, mas ensacá-las - então, novamente, nos protegeremos da reciclagem. <br><br><h3>  3. Resultados </h3><br>  Compare os resultados dos nossos algoritmos. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> KFold <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GradientBoostingRegressor <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> GDBSklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> copy <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_metrics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(X,y,n_folds=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, model=None)</span></span></span><span class="hljs-function">:</span></span> kf = KFold(n_splits=n_folds, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) kf.get_n_splits(X) er_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> train_index, test_index <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm_notebook(kf.split(X)): X_train, X_test = X[train_index], X[test_index] y_train, y_test = y[train_index], y[test_index] model.fit(X_train,y_train) predict = model.predict(X_test) er_list.append(mse(y_test, predict)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> er_list data = datasets.fetch_california_housing() X = np.array(data.data) y = np.array(data.target) er_boosting = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GradientBoosting(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>, n_estimators=<span class="hljs-number"><span class="hljs-number">40</span></span>, base_tree=<span class="hljs-string"><span class="hljs-string">'Tree'</span></span> )) er_boobagg = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GradientBoosting(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>, n_estimators=<span class="hljs-number"><span class="hljs-number">40</span></span>, base_tree=<span class="hljs-string"><span class="hljs-string">'Bagging'</span></span> )) er_sklearn_boosting = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GDBSklearn(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>,n_estimators=<span class="hljs-number"><span class="hljs-number">40</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)) %matplotlib inline data = [er_sklearn_boosting, er_boosting, er_boobagg] fig7, ax7 = plt.subplots() ax7.set_title(<span class="hljs-string"><span class="hljs-string">''</span></span>) ax7.boxplot(data, labels=[<span class="hljs-string"><span class="hljs-string">'Sklearn Boosting'</span></span>, <span class="hljs-string"><span class="hljs-string">'Boosting'</span></span>, <span class="hljs-string"><span class="hljs-string">'BooBag'</span></span>]) plt.grid() plt.show()</code> </pre> <br>  Recebido: <br><br><img src="https://habrastorage.org/webt/rd/ih/nb/rdihnby6vylrk7azxytowqvb5uu.png"><br><br>  Ainda não podemos derrotar o analógico do Sklearn, porque novamente não levamos em consideração muitos parâmetros usados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste método</a> .  No entanto, vemos que o ensacamento ajuda um pouco. <br><br>  Não vamos nos desesperar e passar a escrever o XGBoost. <br><br><h3>  4. XGBoost </h3><br>  Antes de ler mais, recomendo fortemente que você se familiarize com o próximo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vídeo</a> , o que explica muito bem a teoria. <br><br>  Lembre-se de qual erro minimizamos no impulso normal: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-208"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-209">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-210">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-211">r</span><span class="MJXp-mo" id="MJXp-Span-212" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-213">h</span><span class="MJXp-mo" id="MJXp-Span-214" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-215" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-216">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-217">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-218">u</span><span class="MJXp-msubsup" id="MJXp-Span-219"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-220" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-225">N</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-221"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-222">j</span><span class="MJXp-mo" id="MJXp-Span-223">=</span><span class="MJXp-mn" id="MJXp-Span-224">1</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-226">L</span><span class="MJXp-mo" id="MJXp-Span-227" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-228">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-229">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-230">u</span><span class="MJXp-msubsup" id="MJXp-Span-231"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-232" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-237"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-238">T</span><span class="MJXp-mo" id="MJXp-Span-239">−</span><span class="MJXp-mn" id="MJXp-Span-240">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-233"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-234">i</span><span class="MJXp-mo" id="MJXp-Span-235">=</span><span class="MJXp-mn" id="MJXp-Span-236">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-241"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-242" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-243" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-244"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-245" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-246" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-247" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-248"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-249" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-250" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-251" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-252" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-253"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-254" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-255" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-msubsup" id="MJXp-Span-256"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-257" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-258" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-mo" id="MJXp-Span-259" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-260"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-261" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-262" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-263" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-264" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-10"> err (h) = \ sum_ {j = 1} ^ N L (\ sum_ {i = 1} ^ {T-1} a_ib_i (x_j) + b_Ta_T (x_j)) </script></p><br>  O XGBoost adiciona explicitamente regularização a esta funcionalidade de erro: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-265"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-266">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-267">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-268">r</span><span class="MJXp-mo" id="MJXp-Span-269" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-270">h</span><span class="MJXp-mo" id="MJXp-Span-271" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-272" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-273">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-274">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-275">u</span><span class="MJXp-msubsup" id="MJXp-Span-276"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-277" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-282">N</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-278"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-279">j</span><span class="MJXp-mo" id="MJXp-Span-280">=</span><span class="MJXp-mn" id="MJXp-Span-281">1</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-283">L</span><span class="MJXp-mo" id="MJXp-Span-284" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-285">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-286">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-287">u</span><span class="MJXp-msubsup" id="MJXp-Span-288"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-289" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-294"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-295">T</span><span class="MJXp-mo" id="MJXp-Span-296">−</span><span class="MJXp-mn" id="MJXp-Span-297">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-290"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-291">i</span><span class="MJXp-mo" id="MJXp-Span-292">=</span><span class="MJXp-mn" id="MJXp-Span-293">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-298"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-299" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-300" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-301"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-302" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-303" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-304" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-305"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-306" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-307" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-308" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-309" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-310"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-311" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-312" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-msubsup" id="MJXp-Span-313"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-314" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-315" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-mo" id="MJXp-Span-316" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-317"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-318" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-319" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-320" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-321" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-322" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-323">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-324">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-325">u</span><span class="MJXp-msubsup" id="MJXp-Span-326"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-327" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-332">T</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-328"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-329">i</span><span class="MJXp-mo" id="MJXp-Span-330">=</span><span class="MJXp-mn" id="MJXp-Span-331">1</span></span></span></span></span></span></span><span class="MJXp-mtext" id="MJXp-Span-333">&nbsp;</span><span class="MJXp-mrow" id="MJXp-Span-334"><span class="MJXp-mo" id="MJXp-Span-335" style="margin-left: 0em; margin-right: 0em;">ô</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-336">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-337">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-338">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-339">a</span><span class="MJXp-mo" id="MJXp-Span-340" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-341"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-342" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-343" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-344" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-11"> err (h) = \ sum_ {j = 1} ^ NL (\ sum_ {i = 1} ^ {T-1} a_ib_i (x_j) + b_Ta_T (x_j)) + \ sum_ {i = 1} ^ T \ ômega (a_i) </script></p><br>  Como considerar essa funcionalidade?  Primeiro, nós o aproximamos com a ajuda de uma série de Taylor de segunda ordem, onde o novo algoritmo é considerado como um incremento ao longo do qual iremos mover e, em seguida, já pintamos dependendo do tipo de perda que temos: <br><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-345"><span class="noError" id="MJXp-Span-346" style="display: inline-block;">f&nbsp;(x&nbsp;+&nbsp;\&nbsp;delta&nbsp;x)&nbsp;\&nbsp;thickapprox&nbsp;f&nbsp;(x)&nbsp;+&nbsp;f&nbsp;(x)&nbsp;'\&nbsp;delta&nbsp;x&nbsp;+&nbsp;0,5&nbsp;*&nbsp;f&nbsp;(x)'&nbsp;'(\&nbsp;delta&nbsp;x)&nbsp;^</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-12"> f (x + \ delta x) \ thickapprox f (x) + f (x) '\ delta x + 0,5 * f (x)' '(\ delta x) ^ </script><br><br>  É necessário determinar qual árvore consideraremos ruim e qual é boa. <br><br>  Lembre-se de que princípio a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">regressão</a> é construída com <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-347"><span class="MJXp-msubsup" id="MJXp-Span-348"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-349" style="margin-right: 0.05em;">L</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-350" style="vertical-align: -0.4em;">2</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-13"> L_2 </script>  -regularização - quanto mais normais os valores dos coeficientes antes da regressão, pior é, portanto, necessário que sejam tão pequenos quanto possível. <br><br>  No XGBoost, a idéia é muito semelhante: a árvore é multada se a soma da norma dos valores nas folhas for muito grande.  Portanto, a complexidade da árvore é apresentada da seguinte maneira: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-351"><span class="MJXp-mtext" id="MJXp-Span-352">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-353">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-354">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-355">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-356">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-357">a</span><span class="MJXp-mo" id="MJXp-Span-358" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-359">a</span><span class="MJXp-mo" id="MJXp-Span-360" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-361" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-362">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-363">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-364">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-365">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-366">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-367">Z</span><span class="MJXp-mo" id="MJXp-Span-368" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-369">0</span><span class="MJXp-mo" id="MJXp-Span-370" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-371">5</span><span class="MJXp-mo" id="MJXp-Span-372" style="margin-left: 0.267em; margin-right: 0.267em;">∗</span><span class="MJXp-mtext" id="MJXp-Span-373">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-374">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-375">u</span><span class="MJXp-msubsup" id="MJXp-Span-376"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-377" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-382"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-383">Z</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-378"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-379">i</span><span class="MJXp-mo" id="MJXp-Span-380">=</span><span class="MJXp-mn" id="MJXp-Span-381">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-384"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-385" style="margin-right: 0.05em;">w</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-387">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-386">i</span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-14"> \ omega (a) = \ gama Z + 0,5 * \ sum_ {i = 1} ^ {Z} w_i ^ 2 </script></p><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-388"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-389">w</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-15"> w </script>  - valores nas folhas, <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-390"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-391">Z</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-16"> Z </script>  - número de folhas. <br><br>  Existem fórmulas de transição no vídeo, não as exibiremos aqui.  Tudo se resume ao fato de escolhermos uma nova partição, maximizando o ganho: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-392"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-393">G</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-394">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-395">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-396">n</span><span class="MJXp-mo" id="MJXp-Span-397" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-398">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-399">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-400">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-401">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-402">c</span><span class="MJXp-mrow" id="MJXp-Span-403"><span class="MJXp-msubsup" id="MJXp-Span-404"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-405" style="margin-right: 0.05em;">G</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-407">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-406">l</span></span></span></span></span></span></span><span class="MJXp-mrow" id="MJXp-Span-408"><span class="MJXp-msubsup" id="MJXp-Span-409"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-410" style="margin-right: 0.05em;">S</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-412">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-411">l</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-413" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-414">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-415">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-416">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-417">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-418">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-419">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-420">a</span></span><span class="MJXp-mo" id="MJXp-Span-421" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-422">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-423">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-424">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-425">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-426">c</span><span class="MJXp-mrow" id="MJXp-Span-427"><span class="MJXp-msubsup" id="MJXp-Span-428"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-429" style="margin-right: 0.05em;">G</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-431">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-430">r</span></span></span></span></span></span></span><span class="MJXp-mrow" id="MJXp-Span-432"><span class="MJXp-msubsup" id="MJXp-Span-433"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-434" style="margin-right: 0.05em;">S</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-436">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-435">r</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-437" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-438">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-439">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-440">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-441">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-442">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-443">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-444">a</span></span><span class="MJXp-mo" id="MJXp-Span-445" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mtext" id="MJXp-Span-446">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-447">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-448">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-449">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-450">c</span><span class="MJXp-mrow" id="MJXp-Span-451"><span class="MJXp-mo" id="MJXp-Span-452" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-453"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-454" style="margin-right: 0.05em;">G</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-455" style="vertical-align: -0.4em;">l</span></span><span class="MJXp-mo" id="MJXp-Span-456" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-457"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-458" style="margin-right: 0.05em;">G</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-459" style="vertical-align: -0.4em;">r</span></span><span class="MJXp-msubsup" id="MJXp-Span-460"><span class="MJXp-mo" id="MJXp-Span-461" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-462" style="vertical-align: 0.5em;">2</span></span></span><span class="MJXp-mrow" id="MJXp-Span-463"><span class="MJXp-msubsup" id="MJXp-Span-464"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-465" style="margin-right: 0.05em;">S</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-467">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-466">l</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-468" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-469"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-470" style="margin-right: 0.05em;">S</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-472">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-471">r</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-473" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-474">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-475">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-476">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-477">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-478">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-479">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-480">a</span></span><span class="MJXp-mo" id="MJXp-Span-481" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mtext" id="MJXp-Span-482">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-483">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-484">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-485">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-486">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-487">a</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-17"> Gain = \ frac {G_l ^ 2} {S_l ^ 2 + \ lambda} + \ frac {G_r ^ 2} {S_r ^ 2 + \ lambda} - \ frac {(G_l + G_r) ^ 2} {S_l ^ 2 + S_r ^ 2 + \ lambda} - \ gamma </script></p><br>  Aqui <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-488"><span class="MJXp-mtext" id="MJXp-Span-489">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-490">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-491">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-492">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-493">a</span><span class="MJXp-mo" id="MJXp-Span-494" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mtext" id="MJXp-Span-495">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-496">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-497">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-498">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-499">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-500">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-501">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-18-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-18"> \ gama, \ lambda </script>  Os parâmetros numéricos de regularização e <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-502"><span class="MJXp-msubsup" id="MJXp-Span-503"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-504" style="margin-right: 0.05em;">G</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-505" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-506" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-507"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-508" style="margin-right: 0.05em;">S</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-509" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-19-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-19"> G_i, S_i </script>  - as somas correspondentes da primeira e segunda derivadas para esta partição. <br><br>  É isso, a teoria é bem resumida, os links são dados, agora vamos falar sobre quais serão os derivados se trabalharmos com o MSE.  É simples: <br><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-510"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-511">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-512">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-513">e</span><span class="MJXp-mo" id="MJXp-Span-514" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-515">y</span><span class="MJXp-mo" id="MJXp-Span-516" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-517">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-518">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-519">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-520">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-521">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-522">r</span><span class="MJXp-mo" id="MJXp-Span-523" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-524" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-525" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-526">y</span><span class="MJXp-mo" id="MJXp-Span-527" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-528">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-529">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-530">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-531">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-532">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-533">r</span><span class="MJXp-msubsup" id="MJXp-Span-534"><span class="MJXp-mo" id="MJXp-Span-535" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-536" style="vertical-align: 0.5em;">2</span></span><span class="MJXp-mspace" id="MJXp-Span-537" style="width: 0em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-538">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-539">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-540">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-541">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-542">l</span><span class="MJXp-msubsup" id="MJXp-Span-543"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-544" style="margin-right: 0.05em;">a</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-545" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-546">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-547">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-548">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-549">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-550">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-551">r</span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-552">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-553">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-554">e</span><span class="MJXp-mo" id="MJXp-Span-555" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-556">y</span><span class="MJXp-mo" id="MJXp-Span-557" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-558">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-559">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-560">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-561">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-562">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-563">r</span><span class="MJXp-mo" id="MJXp-Span-564" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-565" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-566">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-567">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-568">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-569">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-570">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-571">r</span><span class="MJXp-mo" id="MJXp-Span-572" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-573">y</span><span class="MJXp-mspace" id="MJXp-Span-574" style="width: 0em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-575">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-576">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-577">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-578">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-579">l</span><span class="MJXp-msubsup" id="MJXp-Span-580"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-581" style="margin-right: 0.05em;">a</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-589">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-582"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-583">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-584">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-585">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-586">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-587">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-588">r</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-590">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-591">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-592">e</span><span class="MJXp-mo" id="MJXp-Span-593" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-594">y</span><span class="MJXp-mo" id="MJXp-Span-595" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-596">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-597">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-598">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-599">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-600">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-601">r</span><span class="MJXp-mo" id="MJXp-Span-602" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-603" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-604">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-20-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-20"> mse (y, prever) = (y - prever) ^ 2 \\ \ nabla_ {prever} mse (y, prever) = prever - y \\ \ nabla_ {prever} ^ 2 mse (y, prever) = 1 </script><br><br>  Quando vamos calcular a quantidade <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-605"><span class="MJXp-msubsup" id="MJXp-Span-606"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-607" style="margin-right: 0.05em;">G</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-608" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-609" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-610"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-611" style="margin-right: 0.05em;">S</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-612" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-21-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-21"> G_i, S_i </script>  , basta adicionar ao primeiro <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-613"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-614">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-615">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-616">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-617">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-618">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-619">r</span><span class="MJXp-mo" id="MJXp-Span-620" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-621">y</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-22-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-22"> prever - y </script>  e o segundo é apenas a quantidade. <br><br><pre> <code class="python hljs">%%cython -a <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np cimport numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np cdef <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RegressionTreeGain</span></span></span><span class="hljs-class">:</span></span> cdef public int max_depth cdef public np.float64_t gain cdef public np.float64_t lmd cdef public np.float64_t gmm cdef public int feature_idx cdef public int min_size cdef public np.float64_t feature_threshold cdef public np.float64_t value cpdef public RegressionTreeGain left cpdef public RegressionTreeGain right <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, int max_depth=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, np.float64_t lmd=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, np.float64_t gmm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.max_depth = max_depth self.gmm = gmm self.lmd = lmd self.left = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.right = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.feature_idx = <span class="hljs-number"><span class="hljs-number">-1</span></span> self.feature_threshold = <span class="hljs-number"><span class="hljs-number">0</span></span> self.value = <span class="hljs-number"><span class="hljs-number">-1e9</span></span> self.min_size = min_size <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, np.ndarray[np.float64_t, ndim=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">] X, np.ndarray[np.float64_t, ndim=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">] y)</span></span></span><span class="hljs-function">:</span></span> cpdef long N = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cpdef long N1 = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cpdef long N2 = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef long idx = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef long thres = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef np.float64_t gl, gr, gn cpdef np.ndarray[long, ndim=<span class="hljs-number"><span class="hljs-number">1</span></span>] idxs cpdef np.float64_t x = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t best_gain = -self.gmm <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> self.value == <span class="hljs-number"><span class="hljs-number">-1e9</span></span>: self.value = y.mean() base_error = ((y - self.value) ** <span class="hljs-number"><span class="hljs-number">2</span></span>).sum() error = base_error flag = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> self.max_depth &lt;= <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> dim_shape = X.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] left_value = <span class="hljs-number"><span class="hljs-number">0</span></span> right_value = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#    # -  -   mse, L = (y - pred)**2 # dL/dpred = pred - y,          - # dL^2/d^2pred = 1 - ,       for feat in range(dim_shape): idxs = np.argsort(X[:, feat]) gl,gr = y.sum(),0.0 N1, N2, thres = N, 0, 0 while thres &lt; N - 1: N1 -= 1 N2 += 1 idx = idxs[thres] x = X[idx, feat] gl -= y[idx] gr += y[idx] #   gn = (gl**2) / (N1 + self.lmd) + (gr**2) / (N2 + self.lmd) gn -= ((gl + gr)**2) / (N1 + N2 + self.lmd) + self.gmm if thres &lt; N - 1 and x == X[idxs[thres + 1], feat]: thres += 1 continue #     if (gn &gt; best_gain) and (min(N1,N2) &gt; self.min_size): flag = 1 best_gain = gn left_value = -gl / (N1 + self.lmd) right_value = -gr / (N2 + self.lmd) self.feature_idx = feat self.feature_threshold = x thres += 1 self.gain = best_gain if self.feature_idx == -1: return self.left = RegressionTreeGain(max_depth=self.max_depth - 1, gmm=self.gmm, lmd=self.lmd) self.left.value = left_value self.right = RegressionTreeGain(max_depth=self.max_depth - 1, gmm=self.gmm, lmd=self.lmd) self.right.value = right_value idxs_l = (X[:, self.feature_idx] &gt; self.feature_threshold) idxs_r = (X[:, self.feature_idx] &lt;= self.feature_threshold) self.left.fit(X[idxs_l, :], y[idxs_l]) self.right.fit(X[idxs_r, :], y[idxs_r]) #    if (self.left.left == None or self.right.left == None): if self.gain &lt; 0.0: self.left = None self.right = None self.feature_idx = -1 def __predict(self, np.ndarray[np.float64_t, ndim=1] x): if self.feature_idx == -1: return self.value if x[self.feature_idx] &gt; self.feature_threshold: return self.left.__predict(x) else: return self.right.__predict(x) def predict(self, np.ndarray[np.float64_t, ndim=2] X): y = np.zeros(X.shape[0]) for i in range(X.shape[0]): y[i] = self.__predict(X[i]) return y</span></span></code> </pre> <br>  Um pequeno esclarecimento: para tornar as fórmulas nas árvores com ganho mais bonitas, treinamos o alvo com um sinal de menos. <br><br>  Modificamos levemente nosso impulso, adaptamos alguns parâmetros.  Por exemplo, se notarmos que a perda começou a atingir um platô, diminuímos a taxa de aprendizado e aumentamos max_depth para os estimadores a seguir.  Também adicionaremos uma nova ensacadeira - agora aumentaremos sobre as ensacadas das árvores com ganho: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Bagging</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, max_depth = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, n_samples = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.max_depth = max_depth self.min_size = min_size self.n_samples = n_samples self.subsample_size = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.list_of_Carts = [RegressionTreeGain(max_depth=self.max_depth, min_size=self.min_size) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(self.n_samples)] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_bootstrap_samples</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, data_train, y_train)</span></span></span><span class="hljs-function">:</span></span> indices = np.random.randint(<span class="hljs-number"><span class="hljs-number">0</span></span>, len(data_train), (self.n_samples, self.subsample_size)) samples_train = data_train[indices] samples_y = y_train[indices] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> samples_train, samples_y <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, data_train, y_train)</span></span></span><span class="hljs-function">:</span></span> self.subsample_size = int(data_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) samples_train, samples_y = self.get_bootstrap_samples(data_train, y_train) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(self.n_samples): self.list_of_Carts[i].fit(samples_train[i], samples_y[i].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, test_data)</span></span></span><span class="hljs-function">:</span></span> num_samples = test_data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] pred = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(self.n_samples): pred.append(self.list_of_Carts[i].predict(test_data)) pred = np.array(pred).T <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array([np.mean(pred[i]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_samples)])</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">GradientBoosting</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, n_estimators=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">100</span></span></span></span><span class="hljs-function"><span class="hljs-params">, learning_rate=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, max_depth=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, random_state=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">17</span></span></span></span><span class="hljs-function"><span class="hljs-params">, n_samples = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">15</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, base_tree=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'Bagging'</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.n_estimators = n_estimators self.max_depth = max_depth self.learning_rate = learning_rate self.initialization = <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> y: np.mean(y) * np.ones([y.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]]) self.min_size = min_size self.loss_by_iter = [] self.trees_ = [] self.loss_by_iter_test = [] self.n_samples = n_samples self.base_tree = base_tree <span class="hljs-comment"><span class="hljs-comment">#  -       #   ,   lr   max_depth self.add_to_max_depth = 1 self.init_mse_board = 1.5 def fit(self, X, y): print (self.base_tree) self.X = X self.y = y b = self.initialization(y) prediction = b.copy() for t in tqdm_notebook(range(self.n_estimators)): if t == 0: resid = y else: resid = (y - prediction) if (mse(temp_resid,resid) &lt; self.init_mse_board): self.init_mse_board /= 1.5 self.add_to_max_depth += 1 self.learning_rate /= 1.1 # print ('Alert!', t, self.add_to_max_depth) if self.base_tree == 'Bagging': tree = Bagging(max_depth=self.max_depth+self.add_to_max_depth, min_size = self.min_size) resid = -resid if self.base_tree == 'Tree': tree = RegressionTreeFastMse(max_depth=self.max_depth+self.add_to_max_depth, min_size = self.min_size) if self.base_tree == 'XGBoost': tree = RegressionTreeGain(max_depth=self.max_depth+self.add_to_max_depth, min_size = self.min_size) resid = -resid tree.fit(X, resid) b = tree.predict(X).reshape([X.shape[0]]) # print (b.shape) self.trees_.append(tree) prediction += self.learning_rate * b temp_resid = resid return self def predict(self, X): #   –          pred = np.ones([X.shape[0]]) * np.mean(self.y) #    for t in range(self.n_estimators): pred += self.learning_rate * self.trees_[t].predict(X).reshape([X.shape[0]]) return pred</span></span></code> </pre> <br><h3>  5. Resultados </h3><br>  Por tradição, comparamos os resultados: <br><br><pre> <code class="python hljs">data = datasets.fetch_california_housing() X = np.array(data.data) y = np.array(data.target) <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GradientBoostingRegressor <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> GDBSklearn er_boosting_bagging = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GradientBoosting(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>, n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>,base_tree=<span class="hljs-string"><span class="hljs-string">'Bagging'</span></span>)) er_boosting_xgb = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GradientBoosting(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>, n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>,base_tree=<span class="hljs-string"><span class="hljs-string">'XGBoost'</span></span>)) er_sklearn_boosting = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GDBSklearn(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>,n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>,learning_rate=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) %matplotlib inline data = [er_sklearn_boosting, er_boosting_xgb, er_boosting_bagging] fig7, ax7 = plt.subplots() ax7.set_title(<span class="hljs-string"><span class="hljs-string">''</span></span>) ax7.boxplot(data, labels=[<span class="hljs-string"><span class="hljs-string">'GdbSklearn'</span></span>, <span class="hljs-string"><span class="hljs-string">'Xgboost'</span></span>, <span class="hljs-string"><span class="hljs-string">'XGBooBag'</span></span>]) plt.grid() plt.show()</code> </pre> <br>  A imagem será a seguinte: <br><br><img src="https://habrastorage.org/webt/jh/at/2u/jhat2uvy0yetcxkbzkaaix06wki.png"><br><br>  O XGBoost tem o erro mais baixo, mas o XGBooBag tem um erro mais cheio, o que é definitivamente melhor: o algoritmo é mais estável. <br><br>  Isso é tudo.  Eu realmente espero que o material apresentado em dois artigos seja útil e que você possa aprender algo novo por si mesmo.  Agradeço especialmente a Dmitry pelo feedback abrangente e pelo código-fonte, a Anton pelo conselho e a Vladimir pelas tarefas difíceis de estudar. <br><br>  Todo o sucesso! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt438562/">https://habr.com/ru/post/pt438562/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt438548/index.html">Lombok, sources.jar e depuração conveniente</a></li>
<li><a href="../pt438550/index.html">Outro manifesto</a></li>
<li><a href="../pt438554/index.html">Gerenciando estado e eventos entre componentes no GameObject</a></li>
<li><a href="../pt438556/index.html">Serrar dados confortavelmente</a></li>
<li><a href="../pt438560/index.html">Escrevendo o XGBoost a partir do zero - parte 1: árvores de decisão</a></li>
<li><a href="../pt438566/index.html">Estojo para microprocessador Apple Strange A12X</a></li>
<li><a href="../pt438568/index.html">Sobre computadores quânticos: como diferentes países desenvolvem essa tecnologia</a></li>
<li><a href="../pt438570/index.html">CS Center 2018 New Year Eve Competition</a></li>
<li><a href="../pt438574/index.html">Fundamentos da arquitetura de aplicativos de vibração: Baunilha, modelo com escopo, BLoC</a></li>
<li><a href="../pt438576/index.html">Código aberto popular - parte três: 5 ferramentas para desenvolvedores</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
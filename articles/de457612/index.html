<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ìÇÔ∏è üë©üèæ‚Äçü§ù‚Äçüë©üèª üõãÔ∏è Wie kann die LZ4-Dekomprimierung in ClickHouse beschleunigt werden? üö® ü§• üë¢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wenn Sie Abfragen in ClickHouse ausf√ºhren , stellen Sie m√∂glicherweise fest, dass der Profiler h√§ufig die Funktion LZ_decompress_fast oben LZ_decompre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie kann die LZ4-Dekomprimierung in ClickHouse beschleunigt werden?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/457612/"> Wenn Sie Abfragen in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ClickHouse ausf√ºhren</a> , stellen Sie m√∂glicherweise fest, dass der Profiler h√§ufig die Funktion <code>LZ_decompress_fast</code> oben <code>LZ_decompress_fast</code> .  Was ist los?  Bei dieser Frage haben wir uns gefragt, wie wir den besten Komprimierungsalgorithmus ausw√§hlen sollen. <br><br>  ClickHouse speichert Daten in komprimierter Form.  Bei der Ausf√ºhrung von Abfragen versucht ClickHouse, so wenig wie m√∂glich zu tun, um CPU-Ressourcen zu schonen.  In vielen F√§llen sind alle potenziell zeitaufw√§ndigen Berechnungen bereits gut optimiert, und der Benutzer hat eine gut durchdachte Abfrage geschrieben.  Dann m√ºssen Sie nur noch eine Dekomprimierung durchf√ºhren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/302/aba/057302aba5041790af404c2c781c4dd3.png"><br><br>  Warum wird die LZ4-Dekomprimierung zum Engpass?  LZ4 scheint ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">extrem leichter Algorithmus zu sein</a> : Die Datendekomprimierungsrate betr√§gt je nach Daten normalerweise 1 bis 3 GB / s pro Prozessorkern.  Dies ist viel schneller als das typische Festplattensubsystem.  Dar√ºber hinaus verwenden wir alle verf√ºgbaren CPU-Kerne, und die Dekomprimierung wird linear √ºber alle physischen Kerne skaliert. <br><a name="habracut"></a><br>  Es sind jedoch zwei Punkte zu beachten.  Zun√§chst werden komprimierte Daten von der Festplatte gelesen, die Dekomprimierungsgeschwindigkeit wird jedoch als Menge nicht komprimierter Daten angegeben.  Wenn das Komprimierungsverh√§ltnis gro√ü genug ist, kann fast nichts von den Datentr√§gern gelesen werden.  Es wird jedoch viele dekomprimierte Daten geben, was sich nat√ºrlich auf die CPU-Auslastung auswirkt: Im Fall von LZ4 ist der zum Dekomprimieren von Daten erforderliche Arbeitsaufwand nahezu proportional zum Volumen der dekomprimierten Daten selbst. <br><br>  Zweitens, wenn Daten zwischengespeichert werden, m√ºssen Sie m√∂glicherweise √ºberhaupt keine Daten von Datentr√§gern lesen.  Sie k√∂nnen sich auf den Seitencache verlassen oder Ihren eigenen Cache verwenden.  Das Caching ist in spaltenorientierten Datenbanken effizienter, da nur h√§ufig verwendete Spalten im Cache verbleiben.  Aus diesem Grund scheint LZ4 h√§ufig ein Engpass in Bezug auf die CPU-Auslastung zu sein. <br><br>  Dies wirft zwei weitere Fragen auf.  Erstens, wenn die Dekomprimierung uns verlangsamt, lohnt es sich zun√§chst, Daten zu komprimieren?  Diese Spekulation ist in der Praxis jedoch irrelevant.  Bis vor kurzem bot die ClickHouse-Konfiguration nur zwei Datenkomprimierungsoptionen - LZ4 und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zstandard</a> .  Standardm√§√üig wird LZ4 verwendet.  Durch die Umstellung auf Zstandard wird die Komprimierung st√§rker und langsamer.  Es gab jedoch keine Option zum vollst√§ndigen Deaktivieren der Komprimierung, da davon ausgegangen wird, dass LZ4 eine angemessene minimale Komprimierung bietet, die immer verwendet werden kann.  (Genau deshalb liebe ich LZ4.) <br><br>  Aber dann erschien im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">internationalen ClickHouse-Support-Chat</a> ein mysteri√∂ser Fremder, der sagte, er habe ein sehr schnelles Festplattensubsystem (mit NVMe-SSD), und Dekomprimierung ist das einzige, was seine Abfragen verlangsamt. Es w√§re also sch√∂n, Daten ohne speichern zu k√∂nnen Komprimierung  Ich antwortete, dass wir diese Option nicht haben, aber es w√§re einfach hinzuzuf√ºgen.  Einige Tage sp√§ter erhielten wir eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pull-Anfrage,</a> die die Komprimierungsmethode <code>none</code> implementiert.  Ich habe den Mitwirkenden gebeten, dar√ºber zu berichten, inwieweit diese Option zur Beschleunigung von Abfragen beigetragen hat.  Die Antwort war, dass sich diese neue Funktion in der Praxis als nutzlos herausstellte, da die unkomprimierten Daten zu viel Speicherplatz beanspruchten und nicht in diese NVMe-Laufwerke passten. <br><br>  Die zweite Frage, die sich stellt, lautet: Wenn ein Cache vorhanden ist, warum nicht zum Speichern bereits dekomprimierter Daten verwenden?  Dies ist eine praktikable M√∂glichkeit, die in vielen F√§llen die Notwendigkeit einer Dekompression beseitigt.  ClickHouse hat auch einen Cache wie diesen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Cache dekomprimierter Bl√∂cke</a> .  Aber es ist schade, viel RAM daf√ºr zu verschwenden.  Daher ist es normalerweise nur sinnvoll, kleine, sequentielle Abfragen zu verwenden, bei denen nahezu identische Daten verwendet werden. <br><br>  Unsere Schlussfolgerung ist, dass es immer vorzuziehen ist, Daten in komprimiertem Format zu speichern.  Schreiben Sie Daten immer im komprimierten Format auf die Festplatte.  √úbertragen Sie Daten auch mit Komprimierung √ºber das Netzwerk.  Meiner Meinung nach ist die Standardkomprimierung auch dann gerechtfertigt, wenn Daten innerhalb eines einzelnen Rechenzentrums in einem 10-GB-Netzwerk ohne √úberzeichnung √ºbertragen werden, w√§hrend die √úbertragung unkomprimierter Daten zwischen Rechenzentren einfach nicht akzeptabel ist. <br><br><h3>  Warum LZ4? </h3><br>  Warum LZ4 w√§hlen?  K√∂nnten wir nicht etwas noch Leichteres w√§hlen?  Theoretisch k√∂nnten wir, und das ist ein guter Gedanke.  Aber schauen wir uns die Klasse der Algorithmen an, zu denen LZ4 geh√∂rt. <br><br>  Erstens ist es generisch und passt den Datentyp nicht an.  Wenn Sie beispielsweise im Voraus wissen, dass Sie ein Array von Ganzzahlen haben, k√∂nnen Sie einen der VarInt-Algorithmen verwenden, wodurch die CPU effektiver genutzt wird.  Zweitens ist LZ4 nicht √ºberm√§√üig von Datenmodellannahmen abh√§ngig.  Angenommen, Sie haben eine geordnete Zeitreihe von Sensorwerten, ein Array von Gleitkommazahlen.  Wenn Sie dies ber√ºcksichtigen, k√∂nnen Sie Deltas zwischen diesen Zahlen berechnen und sie dann mit einem generischen Algorithmus komprimieren, was zu einem h√∂heren Komprimierungsverh√§ltnis f√ºhrt. <br><br>  Sie werden keine Probleme haben, LZ4 mit Byte-Arrays oder Dateien zu verwenden.  Nat√ºrlich hat es eine Spezialisierung (dazu sp√§ter mehr), und in einigen F√§llen ist seine Verwendung sinnlos.  Aber wenn wir es einen Allzweckalgorithmus nennen, sind wir der Wahrheit ziemlich nahe.  Wir sollten beachten, dass LZ4 dank seines internen Designs den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RLE-</a> Algorithmus automatisch als Sonderfall implementiert. <br><br>  Die wichtigere Frage ist jedoch, ob LZ4 der hinsichtlich der Gesamtgeschwindigkeit und der Kompressionsst√§rke optimalste Algorithmus dieser Klasse ist.  Optimale Algorithmen werden als Pareto-Grenze bezeichnet, was bedeutet, dass es keinen anderen Algorithmus gibt, der auf eine Weise definitiv besser und auf andere Weise nicht schlechter ist (und auch f√ºr eine Vielzahl von Datens√§tzen).  Einige Algorithmen sind schneller, f√ºhren jedoch zu einem geringeren Komprimierungsverh√§ltnis, w√§hrend andere eine st√§rkere Komprimierung aufweisen, sich jedoch langsamer komprimieren oder dekomprimieren lassen. <br><br>  Um ehrlich zu sein, ist LZ4 nicht wirklich die Pareto-Grenze - es gibt einige Optionen, die nur ein kleines bisschen besser sind.  Schauen Sie sich zum Beispiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LZTURBO</a> von einem Entwickler mit dem Spitznamen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">powturbo an</a> .  Dank der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">encode.ru-</a> Community (dem gr√∂√üten und m√∂glicherweise einzigen Forum zur Datenkomprimierung) besteht kein Zweifel an der Zuverl√§ssigkeit der Ergebnisse.  Leider verteilt der Entwickler den Quellcode oder die Bin√§rdateien nicht.  Sie stehen nur einer begrenzten Anzahl von Personen zum Testen oder f√ºr viel Geld zur Verf√ºgung (obwohl es so aussieht, als h√§tte noch niemand daf√ºr bezahlt).  Schauen Sie sich auch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lizard</a> (fr√ºher LZ5) und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Density an</a> .  Sie funktionieren m√∂glicherweise etwas besser als LZ4, wenn Sie eine bestimmte Komprimierungsstufe ausw√§hlen.  Eine weitere wirklich interessante Option ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LZSSE</a> .  Lesen Sie diesen Artikel jedoch zu Ende, bevor Sie ihn lesen. <br><br><h3>  Wie funktioniert lz4? </h3><br>  Schauen wir uns an, wie LZ4 im Allgemeinen funktioniert.  Dies ist eine der Implementierungen des LZ77-Algorithmus.  L und Z stellen die Namen der Entwickler dar (Lempel und Ziv), und 77 steht f√ºr das Jahr 1977, als der Algorithmus ver√∂ffentlicht wurde.  Es gibt viele andere Implementierungen: QuickLZ, FastLZ, BriefLZ, LZF, LZO sowie gzip und zip, wenn niedrige Komprimierungsstufen verwendet werden. <br><br>  Ein mit LZ4 komprimierter Datenblock enth√§lt eine Folge von Eintr√§gen (Befehlen oder Anweisungen) zweier Typen: <br><br><ol><li>  Literale: "Nehmen Sie die folgenden N Bytes wie sie sind und kopieren Sie sie in das Ergebnis". </li><li>  √úbereinstimmung: "Nehmen Sie N Bytes aus dem dekomprimierten Ergebnis, beginnend mit dem Versatzwert relativ zur aktuellen Position". </li></ol><br>  Beispiel.  Vor der Komprimierung: <br><br><pre> <code class="plaintext hljs">Hello world Hello</code> </pre> <br>  Nach der Komprimierung: <br><br><pre> <code class="plaintext hljs">literals 12 "Hello world " match 5 12</code> </pre> <br>  Wenn wir einen komprimierten Block nehmen und den Cursor durch diesen bewegen, w√§hrend wir diese Befehle ausf√ºhren, erhalten wir als Ergebnis die urspr√ºnglichen unkomprimierten Daten. <br><br>  So werden Daten also im Grunde genommen dekomprimiert.  Die Grundidee ist klar: Um eine Komprimierung durchzuf√ºhren, codiert der Algorithmus eine wiederholte Folge von Bytes unter Verwendung von √úbereinstimmungen. <br><br>  Einige Eigenschaften sind auch klar.  Dieser byteorientierte Algorithmus zerlegt keine einzelnen Bytes.  es kopiert sie nur in ihrer Gesamtheit.  Dies unterscheidet sich von der Entropiecodierung.  Zum Beispiel ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zstd</a> eine Kombination aus LZ77 und Entropiecodierung. <br><br>  Beachten Sie, dass der komprimierte Block nicht zu gro√ü sein sollte.  Die Gr√∂√üe wird gew√§hlt, um zu vermeiden, dass w√§hrend der Dekomprimierung viel RAM verschwendet wird, um zu vermeiden, dass der Direktzugriff in der komprimierten Datei (die aus einer gro√üen Anzahl komprimierter Bl√∂cke besteht) zu stark verlangsamt wird. Manchmal passt der Block in einen CPU-Cache.  Sie k√∂nnen beispielsweise 64 KB ausw√§hlen, damit die Puffer f√ºr komprimierte und nicht komprimierte Daten in den L2-Cache passen, wobei die H√§lfte noch frei ist. <br><br>  Wenn wir eine gr√∂√üere Datei komprimieren m√ºssen, k√∂nnen wir die komprimierten Bl√∂cke verketten.  Dies ist auch praktisch, um zus√§tzliche Daten (wie eine Pr√ºfsumme) mit jedem komprimierten Block zu speichern. <br><br>  Der maximale Versatz f√ºr das Match ist begrenzt.  In LZ4 liegt die Grenze bei 64 Kilobyte.  Dieser Betrag wird als Schiebefenster bezeichnet.  Dies bedeutet, dass √úbereinstimmungen in einem Fenster von 64 Kilobyte vor dem Cursor gefunden werden k√∂nnen, das mit dem Cursor verschoben wird, wenn er sich vorw√§rts bewegt. <br><br>  Schauen wir uns nun an, wie Daten komprimiert werden oder mit anderen Worten, wie √ºbereinstimmende Sequenzen in einer Datei gefunden werden.  Sie k√∂nnen immer ein Suffix verwenden (es ist gro√üartig, wenn Sie tats√§chlich davon geh√∂rt haben).  Es gibt Methoden, die gew√§hrleisten, dass sich die l√§ngste √úbereinstimmung nach der Komprimierung in den vorhergehenden Bytes befindet.  Dies wird als optimales Parsen bezeichnet und bietet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nahezu</a> das beste Komprimierungsverh√§ltnis f√ºr einen komprimierten Block mit festem Format.  Es gibt jedoch bessere Ans√§tze, z. B. eine ausreichend gute √úbereinstimmung zu finden, die nicht unbedingt die l√§ngste ist.  Der effizienteste Weg, dies zu finden, ist die Verwendung einer Hash-Tabelle. <br><br>  Dazu iterieren wir den Cursor durch den urspr√ºnglichen Datenblock und nehmen einige Bytes nach dem Cursor (sagen wir 4 Bytes).  Wir hashen sie und setzen den Offset vom Anfang des Blocks (wo die 4 Bytes entnommen wurden) in die Hash-Tabelle.  Der Wert 4 hei√üt "min-match" - mit dieser Hash-Tabelle k√∂nnen wir √úbereinstimmungen von mindestens 4 Bytes finden. <br><br>  Wenn wir uns die Hash-Tabelle ansehen und sie bereits einen √ºbereinstimmenden Datensatz enth√§lt und der Offset das Schiebefenster nicht √ºberschreitet, pr√ºfen wir, wie viele weitere Bytes nach diesen 4 Bytes √ºbereinstimmen.  Vielleicht gibt es noch viel mehr Spiele.  Es ist auch m√∂glich, dass es eine Kollision in der Hash-Tabelle gibt und nichts √ºbereinstimmt, aber das ist keine gro√üe Sache.  Sie k√∂nnen den Wert in der Hash-Tabelle einfach durch einen neuen ersetzen.  Kollisionen in der Hash-Tabelle f√ºhren einfach zu einem niedrigeren Komprimierungsverh√§ltnis, da weniger √úbereinstimmungen vorhanden sind.  Diese Art von Hash-Tabelle (mit fester Gr√∂√üe und ohne Aufl√∂sung von Kollisionen) wird √ºbrigens als "Cache-Tabelle" bezeichnet.  Dieser Name ist sinnvoll, da die Cache-Tabelle im Falle einer Kollision einfach den alten Eintrag vergisst. <br><br><blockquote>  Eine Herausforderung f√ºr den aufmerksamen Leser.  Nehmen wir an, dass die Daten ein Array von UInt32-Zahlen im Little-Endian-Format sind, das einen Teil einer Folge nat√ºrlicher Zahlen darstellt: 0, 1, 2 ... Erkl√§ren Sie, warum diese Daten bei Verwendung von LZ4 (der Gr√∂√üe der komprimierten Daten) nicht komprimiert werden ist nicht kleiner als die unkomprimierten Daten). </blockquote><br><h3>  Wie man alles beschleunigt </h3><br>  Deshalb m√∂chte ich die LZ4-Dekomprimierung beschleunigen.  Mal sehen, wie die Dekomprimierungsschleife aussieht.  Hier ist es im Pseudocode: <br><br><pre> <code class="plaintext hljs">while (...) {    read(input_pos, literal_length, match_length);    copy(output_pos, input_pos, literal_length);    output_pos += literal_length;    read(input_pos, match_offset);    copy(output_pos, output_pos - match_offset,        match_length);    output_pos += match_length; }</code> </pre> <br>  Das LZ4-Format ist so konzipiert, dass sich Literale und √úbereinstimmungen in einer komprimierten Datei abwechseln.  Offensichtlich steht das Literal immer an erster Stelle (weil es von Anfang an keinen Ort gibt, an dem man ein Match spielen kann).  Daher werden ihre L√§ngen zusammen codiert. <br><br>  Es ist eigentlich etwas komplizierter.  Ein Byte wird aus der Datei gelesen und dann in zwei Halbbytes (Halbbytes) aufgeteilt, die die codierten Zahlen 0 bis 15 enthalten. Wenn die entsprechende Zahl nicht 15 ist, wird angenommen, dass sie die L√§nge des Literals und der √úbereinstimmung ist. jeweils.  Und wenn es 15 ist, ist die L√§nge l√§nger und es wird in den folgenden Bytes codiert.  Dann wird das n√§chste Byte gelesen und sein Wert zur L√§nge addiert.  Wenn es gleich 255 ist, wird dasselbe mit dem n√§chsten Byte gemacht. <br><br>  Beachten Sie, dass das maximale Komprimierungsverh√§ltnis f√ºr das LZ4-Format 255 nicht erreicht. Eine weitere nutzlose Beobachtung ist, dass die zweimalige Verwendung von LZ4 das Komprimierungsverh√§ltnis verbessert, wenn Ihre Daten sehr redundant sind. <br><br>  Wenn wir die L√§nge eines Literals (und dann die √úbereinstimmungsl√§nge und den √úbereinstimmungsversatz) lesen, reicht es aus, nur zwei Speicherbl√∂cke zu kopieren, um es zu dekomprimieren. <br><br><h3>  So kopieren Sie einen Speicherblock </h3><br>  Es scheint, als k√∂nnten Sie einfach die <code>memcpy</code> Funktion verwenden, mit der Speicherbl√∂cke kopiert werden.  Dies ist jedoch nicht der optimale Ansatz und nicht wirklich angemessen. <br><br>  Die Verwendung von memcpy ist nicht optimal, weil: <br><br><ol><li>  Es befindet sich normalerweise in der libc-Bibliothek (und die libc-Bibliothek ist normalerweise dynamisch verkn√ºpft, sodass der memcpy-Aufruf indirekt √ºber PLT erfolgt). </li><li>  Es wird vom Compiler nicht eingef√ºgt, wenn das Gr√∂√üenargument zur Kompilierungszeit unbekannt ist. </li><li>  Es ist sehr aufwendig, die Reste eines Speicherblocks, die nicht Vielfache der Maschinenwortl√§nge oder des Maschinenregisters sind, korrekt zu verarbeiten. </li></ol><br>  Der letzte Punkt ist der wichtigste.  Angenommen, wir haben die memcpy-Funktion gebeten, genau 5 Bytes zu kopieren.  Es w√§re gro√üartig, 8 Bytes sofort mit zwei movq-Anweisungen zu kopieren. <br><br> <code>Hello world <font color="#0fc000">Hello</font> <font color="#ff0000">wo</font> ... <br> ^^^^^ <font color="#ff0000">^^^</font> - src <br> ^^^^^ <font color="#ff0000">^^^</font> - dst</code> <br> <br>  Aber dann werden wir drei zus√§tzliche Bytes kopieren, also werden wir au√üerhalb der Puffergrenzen schreiben.  Die <code>memcpy</code> Funktion hat keine Berechtigung dazu, da sie einige Daten in unserem Programm √ºberschreiben und zu einem Speicher-Stomping-Fehler f√ºhren kann.  Und wenn wir an eine nicht ausgerichtete Adresse schreiben, k√∂nnen diese zus√§tzlichen Bytes auf einer nicht zugewiesenen Seite des virtuellen Speichers oder auf einer Seite ohne Schreibzugriff landen.  Das w√ºrde uns einen Segmentierungsfehler geben (das ist gut). <br><br>  In unserem Fall k√∂nnen wir jedoch fast immer zus√§tzliche Bytes schreiben.  Wir k√∂nnen zus√§tzliche Bytes im Eingabepuffer lesen, solange sich die zus√§tzlichen Bytes vollst√§ndig darin befinden.  Unter den gleichen Bedingungen k√∂nnen wir die zus√§tzlichen Bytes in den Ausgabepuffer schreiben, da wir sie bei der n√§chsten Iteration weiterhin √ºberschreiben. <br><br>  Diese Optimierung ist bereits in der urspr√ºnglichen Implementierung von LZ4 enthalten: <br><br><pre> <code class="plaintext hljs">inline void copy8(UInt8 * dst, const UInt8 * src) {    memcpy(dst, src, 8); /// Note that memcpy isn't actually called here. } inline void wildCopy8(UInt8 * dst, const UInt8 * src, UInt8 * dst_end) {    do    {        copy8(dst, src);        dst += 8;        src += 8;    } while (dst &lt; dst_end); }</code> </pre> <br>  Um diese Optimierung nutzen zu k√∂nnen, m√ºssen wir nur sicherstellen, dass wir weit genug von den Puffergrenzen entfernt sind.  Dies sollte nichts kosten, da wir bereits nach Puffer√ºberlauf suchen.  Die Verarbeitung der letzten Bytes, der "verbleibenden" Daten, kann nach der Hauptschleife erfolgen. <br><br>  Es gibt jedoch noch einige Nuancen.  Das Kopieren erfolgt zweimal in der Schleife: mit einem Literal und einer √úbereinstimmung.  Bei Verwendung der Funktion <code>LZ4_decompress_fast</code> (anstelle von <code>LZ4_decompress_safe</code> ) wird die Pr√ºfung jedoch nur einmal durchgef√ºhrt, wenn das Literal kopiert werden muss.  Die √úberpr√ºfung wird beim Kopieren der √úbereinstimmung nicht durchgef√ºhrt, aber die <a href="">Spezifikation f√ºr das LZ4-Format</a> enth√§lt Bedingungen, die es Ihnen erm√∂glichen, dies zu vermeiden: <br><br><blockquote>  Die letzten 5 Bytes sind immer Literale. <br>  Die letzte √úbereinstimmung muss mindestens 12 Byte vor dem Ende des Blocks beginnen. <br>  Folglich kann ein Block mit weniger als 13 Bytes nicht komprimiert werden. </blockquote><br>  Speziell ausgew√§hlte Eingabedaten k√∂nnen zu einer Speicherbesch√§digung f√ºhren.  Wenn Sie die Funktion <code>LZ4_decompress_fast</code> verwenden, ben√∂tigen Sie Schutz vor fehlerhaften Daten.  Zumindest sollten Sie Pr√ºfsummen f√ºr die komprimierten Daten berechnen.  Wenn Sie Schutz vor Hackern ben√∂tigen, verwenden Sie die Funktion <code>LZ4_decompress_safe</code> .  Andere Optionen: Verwenden Sie eine kryptografische Hash-Funktion als Pr√ºfsumme (obwohl dies wahrscheinlich die Leistung beeintr√§chtigt).  reservieren Sie mehr Speicher f√ºr Puffer;  Ordnen Sie Speicher f√ºr Puffer mit einem separaten <code>mmap</code> Aufruf zu und erstellen Sie eine Schutzseite. <br><br>  Wenn ich Code sehe, der 8 Datenbytes kopiert, frage ich mich sofort, warum genau 8 Bytes.  Sie k√∂nnen 16 Bytes mit SSE-Registern kopieren: <br><br><pre> <code class="plaintext hljs">inline void copy16(UInt8 * dst, const UInt8 * src) { #if __SSE2__    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(dst),        _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(src))); #else    memcpy(dst, src, 16); #endif } inline void wildCopy16(UInt8 * dst, const UInt8 * src, UInt8 * dst_end) {    do    {        copy16(dst, src);        dst += 16;        src += 16;    } while (dst &lt; dst_end); }</code> </pre> <br>  Das gleiche gilt f√ºr das Kopieren von 32 Byte f√ºr AVX und 64 Byte f√ºr AVX-512.  Au√üerdem k√∂nnen Sie die Schleife mehrmals abrollen.  Wenn Sie sich jemals angesehen haben, wie <code>memcpy</code> implementiert ist, ist dies genau der Ansatz, der verwendet wird.  (√úbrigens wird der Compiler die Schleife in diesem Fall nicht entrollen oder vektorisieren, da hierf√ºr umfangreiche √úberpr√ºfungen eingef√ºgt werden m√ºssen.) <br><br>  Warum hat die urspr√ºngliche LZ4-Implementierung dies nicht getan?  Erstens ist nicht klar, ob dies besser oder schlechter ist.  Der resultierende Gewinn h√§ngt von der Gr√∂√üe der zu kopierenden Bl√∂cke ab. Wenn sie also alle kurz sind, w√ºrde dies zus√§tzliche Arbeit f√ºr nichts bedeuten.  Und zweitens werden die Bestimmungen im LZ4-Format ruiniert, die dazu beitragen, unn√∂tige Verzweigungen in der internen Schleife zu vermeiden. <br><br>  Wir werden diese Option jedoch vorerst ber√ºcksichtigen. <br><br><h3>  Schwieriges Kopieren </h3><br>  Kehren wir zur Frage zur√ºck, ob es immer m√∂glich ist, Daten auf diese Weise zu kopieren.  Angenommen, wir m√ºssen eine √úbereinstimmung kopieren, dh ein St√ºck Speicher aus dem Ausgabepuffer nehmen, der sich in einem gewissen Versatz hinter dem Cursor befindet, und ihn an die Cursorposition kopieren. <br><br>  Stellen Sie sich einen einfachen Fall vor, in dem Sie 5 Bytes mit einem Versatz von 12 kopieren m√ºssen: <br><br> <code><font color="#0fc000">Hello</font> world ........... <br> ^^^^^ - src <br> ^^^^^ - dst <br> <br> Hello world <font color="#0fc000">Hello</font> <font color="#a8a8a8">wo</font> ... <br> ^^^^^ - src <br> ^^^^^ - dst</code> <br> <br>  Es gibt jedoch einen schwierigeren Fall, wenn wir einen Speicherblock kopieren m√ºssen, der l√§nger als der Offset ist.  Mit anderen Worten, es enth√§lt einige Daten, die noch nicht in den Ausgabepuffer geschrieben wurden. <br><br>  Kopieren Sie 10 Bytes mit einem Offset von 3: <br><br> <code><font color="#0fc000">abc</font> ............. <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst <br> <br> abc <font color="#0fc000">abcabcabca</font> ... <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst</code> <br> <br>  Wir haben alle Daten w√§hrend des Komprimierungsprozesses, und eine solche √úbereinstimmung kann durchaus gefunden werden.  Die <code>memcpy</code> Funktion eignet sich nicht zum Kopieren, da sie den Fall nicht unterst√ºtzt, wenn sich Bereiche von Speicherbl√∂cken √ºberlappen.  Die <code>memmove</code> Funktion funktioniert auch nicht, da der Speicherblock, aus dem die Daten entnommen werden sollen, noch nicht vollst√§ndig initialisiert wurde.  Wir m√ºssen auf die gleiche Weise kopieren, als w√ºrden wir Byte f√ºr Byte kopieren. <br><br><pre> <code class="plaintext hljs">op[0] = match[0]; op[1] = match[1]; op[2] = match[2]; op[3] = match[3]; ...</code> </pre> <br>  So funktioniert es: <br><br> <code><font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ............ <br> ^ - src <br> ^ - dst <br> <br> a <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........... <br> ^ - src <br> ^ - dst <br> <br> ab <font color="#0fc000">c</font> ab <font color="#0fc000">c</font> .......... <br> ^ - src <br> ^ - dst <br> <br> abc <font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ......... <br> ^ - src <br> ^ - dst <br> <br> abca <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........ <br> ^ - src <br> ^ - dst</code> <br> <br>  Mit anderen Worten, wir m√ºssen eine sich wiederholende Sequenz erstellen.  Die urspr√ºngliche Implementierung von LZ4 verwendete dazu √ºberraschend seltsamen Code: <br><br><pre> <code class="plaintext hljs">const unsigned dec32table[] = {0, 1, 2, 1, 4, 4, 4, 4}; const int dec64table[] = {0, 0, 0, -1, 0, 1, 2, 3}; const int dec64 = dec64table[offset]; op[0] = match[0]; op[1] = match[1]; op[2] = match[2]; op[3] = match[3]; match += dec32table[offset]; memcpy(op+4, match, 4); match -= dec64;</code> </pre> <br>  Es kopiert die ersten 4 Bytes nacheinander, √ºberspringt eine magische Zahl, kopiert die n√§chsten 4 Bytes vollst√§ndig und bewegt den Cursor mit einer anderen magischen Zahl zu einer √úbereinstimmung.  Der Autor des Codes ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Yan Collet</a> ) hat irgendwie vergessen, einen Kommentar zu hinterlassen, was dies bedeutet.  Au√üerdem sind die Variablennamen verwirrend.  Sie hei√üen beide dec ... table, aber eine wird hinzugef√ºgt und die andere wird subtrahiert.  Au√üerdem ist einer von ihnen nicht signiert und der andere ist int.  Der Autor hat diesen Platz im Code jedoch k√ºrzlich verbessert. <br><br>  So funktioniert es tats√§chlich.  Wir kopieren die ersten 4 Bytes nacheinander: <br><br> <code>abc <font color="#0fc000">abca</font> ......... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Jetzt k√∂nnen wir 4 Bytes gleichzeitig kopieren: <br><br> <code>abcabca <font color="#0fc000">bcab</font> ..... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Wir k√∂nnen wie gewohnt fortfahren und 8 Bytes gleichzeitig kopieren: <br><br> <code>abcabcabcab <font color="#0fc000">cabcabca</font> ..... <br> ^^^^^^^^ - src <br> ^^^^^^^^ - dst</code> <br> <br>  Wie wir alle aus Erfahrung wissen, ist es manchmal am besten, Code neu zu schreiben, um ihn zu verstehen.  Folgendes haben wir uns ausgedacht: <br><br><pre> <code class="plaintext hljs">inline void copyOverlap8(UInt8 * op, const UInt8 *&amp; match, const size_t offset) {    /// 4 % n.    /// Or if 4 % n is zero, we use n.    /// It gives an equivalent result, but is more CPU friendly for unknown reasons.    static constexpr int shift1[] = { 0, 1, 2, 1, 4, 4, 4, 4 };    /// 8 % n - 4 % n    static constexpr int shift2[] = { 0, 0, 0, 1, 0, -1, -2, -3 };    op[0] = match[0];    op[1] = match[1];    op[2] = match[2];    op[3] = match[3];    match += shift1[offset];    memcpy(op + 4, match, 4);    match += shift2[offset]; }</code> </pre> <br>  Wie erwartet √§ndert dies nichts an der Leistung.  Ich wollte nur unbedingt die Optimierung f√ºr das gleichzeitige Kopieren von 16 Bytes ausprobieren. <br><br>  Dies erschwert jedoch den "Sonderfall" und f√ºhrt dazu, dass er h√§ufiger aufgerufen wird (die Bedingung " <code>offset &lt; 16</code> wird mindestens so oft ausgef√ºhrt wie der <code>offset &lt; 8</code> ).  Das Kopieren √ºberlappender Bereiche mit 16-Byte-Kopieren sieht folgenderma√üen aus (nur der Anfang wird angezeigt): <br><br><pre> <code class="plaintext hljs">inline void copyOverlap16(UInt8 * op, const UInt8 *&amp; match, const size_t offset) {    /// 4 % n.    static constexpr int shift1[]        = { 0, 1, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4 };    /// 8 % n - 4 % n    static constexpr int shift2[]        = { 0, 0, 0, 1, 0, -1, -2, -3, -4, 4, 4, 4, 4, 4, 4, 4 };    /// 16 % n - 8 % n    static constexpr int shift3[]        = { 0, 0, 0, -1, 0, -2, 2, 1, 8, -1, -2, -3, -4, -5, -6, -7 };    op[0] = match[0];    op[1] = match[1];    op[2] = match[2];    op[3] = match[3];    match += shift1[offset];    memcpy(op + 4, match, 4);    match += shift2[offset];    memcpy(op + 8, match, 8);    match += shift3[offset]; }</code> </pre> <br>  Kann diese Funktion effektiver implementiert werden?  Wir m√∂chten eine magische SIMD-Anweisung f√ºr solch komplexen Code finden, da wir nur 16 Bytes schreiben m√∂chten, die vollst√§ndig aus einigen Bytes Eingabedaten bestehen (von 1 bis 15).  Dann m√ºssen sie nur noch in der richtigen Reihenfolge wiederholt werden. <br><br>  Es gibt eine <code>pshufb</code> Anweisung namens <code>pshufb</code> (gepackte Shuffle-Bytes), die Teil von SSSE3 (drei S) ist.  Es akzeptiert zwei 16-Byte-Register.  Eines der Register enth√§lt die Quelldaten.  Der andere hat den "Selektor": Jedes Byte enth√§lt eine Zahl von 0 bis 15, abh√§ngig davon, aus welchem ‚Äã‚ÄãByte des Quellregisters das Ergebnis entnommen werden soll.  Wenn der Bytewert des Selektors gr√∂√üer als 127 ist, wird das entsprechende Byte des Ergebnisses mit Null gef√ºllt. <br><br>  Hier ist ein Beispiel: <br><br><pre>  xmm0: abc .............
 xmm1: 0120120120120120<font></font>
<font></font>
 pshufb% xmm1,% xmm0<font></font>
<font></font>
 xmm0: abcabcabcabcabca </pre><br>  Jedes Byte des Ergebnisses wird mit dem ausgew√§hlten Byte der Quelldaten gef√ºllt - genau das brauchen wir!  So sieht der Code im Ergebnis aus: <br><br><pre> <code class="plaintext hljs">inline void copyOverlap16Shuffle(UInt8 * op, const UInt8 *&amp; match, const size_t offset) { #ifdef __SSSE3__    static constexpr UInt8 __attribute__((__aligned__(16))) masks[] =    {        0, 1, 2, 1, 4, 1, 4, 2, 8, 7, 6, 5, 4, 3, 2, 1, /* offset = 0, not used as mask, but for shift amount instead */        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, /* offset = 1 */        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,        0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0,        0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3,        0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,        0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 1, 2,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 1,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0,    };    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(op),        _mm_shuffle_epi8(            _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(match)),            _mm_load_si128(reinterpret_cast&lt;const __m128i *&gt;(masks) + offset)));    match += masks[offset]; #else    copyOverlap16(op, match, offset); #endif }</code> </pre> <br>  Hier ist <code>_mm_shuffle_epi8</code> eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">intrinsische Eigenschaft</a> , die mit dem <code>pshufb</code> CPU-Befehl kompiliert wird. <br><br>  K√∂nnen wir diesen Vorgang mit neueren Anweisungen f√ºr mehrere Bytes gleichzeitig ausf√ºhren?  Immerhin ist SSSE3 ein sehr alter Befehlssatz, der seit 2006 existiert. AVX2 verf√ºgt √ºber einen Befehl, der dies f√ºr 32 Bytes gleichzeitig, jedoch separat f√ºr einzelne 16-Byte-Lanes ausf√ºhrt.  Dies wird als vektorpermute Bytes bezeichnet und nicht als gepackte Shuffle-Bytes - die W√∂rter sind unterschiedlich, aber die Bedeutung ist dieselbe.  AVX-512 VBMI verf√ºgt √ºber eine weitere Anweisung, die f√ºr 64 Byte gleichzeitig funktioniert. Prozessoren, die dies unterst√ºtzen, wurden jedoch erst k√ºrzlich angezeigt.  ARM NEON hat √§hnliche Anweisungen namens vtbl (Vector Table Lookup), aber sie erlauben nur das Schreiben von 8 Bytes. <br><br>  Zus√§tzlich gibt es eine Version des <code>pshufb</code> Befehls mit 64-Bit-MMX-Registern, um 8 Bytes zu bilden.  Es ist genau richtig, um die Originalversion des Codes zu ersetzen.  Ich habe mich jedoch (aus schwerwiegenden Gr√ºnden) f√ºr die 16-Byte-Option entschieden. <br><br>  Auf der Highload ++ Siberia-Konferenz kam nach meiner Pr√§sentation ein Teilnehmer auf mich zu und erw√§hnte, dass Sie f√ºr den 8-Byte-Fall nur die Multiplikation mit einer speziell ausgew√§hlten Konstante verwenden k√∂nnen (Sie ben√∂tigen auch einen Offset) - dies war noch nicht einmal geschehen zu mir vor! <br><br><h3>  So entfernen Sie eine √ºberfl√ºssige if-Anweisung </h3><br>  Angenommen, ich m√∂chte eine Variante verwenden, die 16 Bytes kopiert.  Wie kann ich vermeiden, dass eine zus√§tzliche √úberpr√ºfung auf Puffer√ºberlauf durchgef√ºhrt werden muss? <br><br>  Ich entschied, dass ich diesen Check einfach nicht machen w√ºrde.  Die Kommentare zur Funktion besagen, dass der Entwickler einen Speicherblock f√ºr eine bestimmte Anzahl von Bytes mehr als erforderlich zuweisen sollte, damit wir dort unn√∂tigen M√ºll lesen und schreiben k√∂nnen.  Die Benutzeroberfl√§che der Funktion ist schwieriger zu verwenden, dies ist jedoch ein anderes Problem. <br><br>  Tats√§chlich k√∂nnte es negative Konsequenzen geben.  Angenommen, die Daten, die zum Dekomprimieren ben√∂tigt werden, wurden aus Bl√∂cken von jeweils 65.536 Byte gebildet.  Dann gibt uns der Benutzer ein St√ºck Speicher, das 65.536 Bytes f√ºr die dekomprimierten Daten betr√§gt.  Mit der neuen Funktionsschnittstelle muss der Benutzer jedoch einen Speicherblock zuweisen, der beispielsweise 65.551 Byte umfasst.  Dann kann der Allokator gezwungen sein, abh√§ngig von seiner Implementierung tats√§chlich 96 oder sogar 128 Kilobyte zuzuweisen.  Wenn der Allokator sehr schlecht ist, <code>munmap</code> er m√∂glicherweise pl√∂tzlich auf, den Speicher im "Heap" zwischenzuspeichern, und verwendet jedes Mal <code>mmap</code> und <code>munmap</code> f√ºr die Speicherzuweisung (oder gibt den Speicher mit <code>madvice</code> ).  Dieser Vorgang ist aufgrund von Seitenfehlern extrem langsam.  Infolgedessen k√∂nnte diese kleine Optimierung alles verlangsamen. <br><br><h3>  Gibt es eine Beschleunigung? </h3><br>  Also habe ich eine Version des Codes erstellt, die drei Optimierungen verwendet: <br><br><ol><li>  Kopieren von 16 Bytes anstelle von 8. </li><li>  Verwenden Sie die Shuffle-Anweisungen f√ºr den Fall <code>offset &lt; 16</code> . </li><li>  Ein Extra entfernt, wenn. </li></ol><br>  Ich habe begonnen, diesen Code an verschiedenen Datens√§tzen zu testen, und habe unerwartete Ergebnisse erhalten. <br><br>  Beispiel 1: <br>  Xeon E2650v2, Yandex-Browserdaten, AppVersion-Spalte. <br>  Referenz: 1,67 GB / s. <br>  16 Bytes, Shuffle: 2,94 GB / s (76% schneller). <br><br>  Beispiel 2: <br>  Xeon E2650v2, Yandex Direct-Daten, Spalte ShowsSumPosition. <br>  Referenz: 2,30 GB / s. <br>  16 Bytes, Shuffle: 1,91 GB / s (20% langsamer). <br><br>  Ich war zuerst sehr gl√ºcklich, als ich sah, dass sich alles um einen so gro√üen Prozentsatz beschleunigt hatte.  Dann sah ich, dass mit anderen Dateien nichts schneller war.  F√ºr einige von ihnen war es sogar etwas langsamer.  Ich kam zu dem Schluss, dass die Ergebnisse vom Kompressionsverh√§ltnis abh√§ngen.  Je st√§rker die Datei komprimiert ist, desto gr√∂√üer ist der Vorteil des Wechsels auf 16 Byte.  Dies f√ºhlt sich nat√ºrlich an: Je gr√∂√üer das Komprimierungsverh√§ltnis ist, desto l√§nger ist die durchschnittliche L√§nge der zu kopierenden Fragmente. <br><br>  Zur Untersuchung habe ich C ++ - Vorlagen verwendet, um Codeoptionen f√ºr vier F√§lle zu erstellen: Verwenden von 8-Byte- oder 16-Byte-Bl√∂cken und mit oder ohne Shuffle-Anweisung. <br><br><pre> <code class="plaintext hljs">template &lt;size_t copy_amount, bool use_shuffle&gt; void NO_INLINE decompressImpl(    const char * const source,    char * const dest,    size_t dest_size)</code> </pre> <br>  V√∂llig unterschiedliche Varianten des Codes zeigten bei verschiedenen Dateien eine bessere Leistung, aber beim Testen auf einem Desktop gewann immer die Version mit Shuffle.  Das Testen auf einem Desktop ist unpraktisch, da Sie Folgendes tun m√ºssen: <br><br><pre> <code class="plaintext hljs">sudo echo 'performance' | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor kill -STOP $(pidof firefox) $(pidof chromium)</code> </pre> <br>  Dann ging ich auf einen der alten "Entwicklungs" -Server (mit dem Xeon E5645-Prozessor), nahm noch mehr Datens√§tze und erzielte fast die gegenteiligen Ergebnisse, was mich total verwirrte.  Es stellt sich heraus, dass die Wahl des optimalen Algorithmus zus√§tzlich zum Komprimierungsverh√§ltnis vom Prozessormodell abh√§ngt.  Der Prozessor bestimmt, wann es am besten ist, den Shuffle-Befehl zu verwenden, sowie den Schwellenwert f√ºr den Beginn des 16-Byte-Kopierens. <br><br>  √úbrigens ist es beim Testen auf unseren Servern sinnvoll, dies zu tun: <br><br><pre> <code class="plaintext hljs">sudo kill -STOP $(pidof python) $(pidof perl) $(pgrep -u skynet) $(pidof cqudp-client)</code> </pre> <br>  Andernfalls sind die Ergebnisse instabil.  Achten Sie auch auf thermische Drosselung und Leistungsbegrenzung. <br><br><h3>  So w√§hlen Sie den besten Algorithmus aus </h3><br>  Wir haben also vier Varianten des Algorithmus und m√ºssen die beste f√ºr die Bedingungen ausw√§hlen.  Wir k√∂nnten einen repr√§sentativen Satz von Daten und Hardware erstellen, dann ernsthafte Lasttests durchf√ºhren und die Methode ausw√§hlen, die im Durchschnitt am besten ist.  Wir haben jedoch keinen repr√§sentativen Datensatz.  Zum Testen habe ich eine Stichprobe von Daten von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Yandex Metrica</a> , Yandex Direct, Yandex Browser und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fl√ºgen in den USA verwendet</a> .  Dies reicht jedoch nicht aus, da ClickHouse von Hunderten von Unternehmen auf der ganzen Welt verwendet wird.  Durch eine √úberoptimierung eines Datensatzes kann es zu Leistungseinbu√üen bei anderen Daten kommen, die nicht einmal realisiert werden.  Und wenn die Ergebnisse vom Prozessormodell abh√§ngen, m√ºssen wir die Bedingungen explizit in den Code schreiben und auf jedem Modell testen (oder das Referenzhandbuch zu Timing-Anweisungen konsultieren, was denken Sie?).  In beiden F√§llen ist dies zu zeitaufw√§ndig. <br><br>  Deshalb habe ich mich f√ºr eine andere Methode entschieden, die f√ºr Kollegen, die an unserer School of Data Analysis studiert haben, offensichtlich ist: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"mehrarmige Banditen"</a> .  Der Punkt ist, dass die Variante des Algorithmus zuf√§llig ausgew√§hlt wird und wir dann Statistiken verwenden, um zunehmend h√§ufiger die Optionen auszuw√§hlen, die eine bessere Leistung erzielen. <br><br>  Wir haben viele Datenbl√∂cke, die dekomprimiert werden m√ºssen, daher ben√∂tigen wir unabh√§ngige Funktionsaufrufe zum Dekomprimieren von Daten.  Wir k√∂nnten einen der vier Algorithmen f√ºr jeden Block ausw√§hlen und seine Ausf√ºhrungszeit messen.  Ein solcher Vorgang kostet normalerweise nichts im Vergleich zur Verarbeitung eines Datenblocks, und in ClickHouse betr√§gt ein Block unkomprimierter Daten mindestens 64 KB.  (Lesen Sie diesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> √ºber die Zeitmessung.) <br><br>  Um ein besseres Verst√§ndnis f√ºr die Funktionsweise des Algorithmus "Mehrarmige Banditen" zu erhalten, schauen wir uns an, woher der Name stammt.  Dies ist eine Analogie zu Spielautomaten in einem Casino, die mehrere Hebel haben, die ein Spieler ziehen kann, um einen zuf√§lligen Geldbetrag zu erhalten.  Der Spieler kann die Hebel mehrmals in beliebiger Reihenfolge ziehen.  Jeder Hebel hat eine feste Wahrscheinlichkeit f√ºr den entsprechenden ausgegebenen Geldbetrag, aber der Spieler wei√ü nicht, wie er funktioniert, und kann ihn nur aus der Erfahrung des Spielens lernen.  Sobald sie es herausgefunden haben, k√∂nnen sie ihre Gewinne maximieren. <br><br>  Ein Ansatz zur Maximierung der Belohnung besteht darin, die Wahrscheinlichkeitsverteilung f√ºr jeden Hebel bei jedem Schritt basierend auf den Spielstatistiken aus den vorherigen Schritten zu bewerten.  Dann "gewinnen" wir mental eine zuf√§llige Belohnung f√ºr jeden Hebel, basierend auf den erhaltenen Verteilungen.  Schlie√ülich ziehen wir den Hebel, der das beste Ergebnis in unserem mentalen Spiel erzielt hat.  Dieser Ansatz wird als Thompson Sampling bezeichnet. <br><br>  Wir w√§hlen jedoch einen Dekomprimierungsalgorithmus.  Das Ergebnis ist die Ausf√ºhrungszeit in Pikosekunden pro Byte: Je weniger, desto besser.  Wir werden die Ausf√ºhrungszeit als Zufallsvariable betrachten und ihre Verteilung mithilfe mathematischer Statistiken bewerten.  Der Bayes'sche Ansatz wird h√§ufig f√ºr solche Aufgaben verwendet, aber es w√§re umst√§ndlich, komplexe Formeln in C ++ - Code einzuf√ºgen.  Wir k√∂nnen einen parametrischen Ansatz verwenden und sagen, dass eine Zufallsvariable zu einer parametrischen Familie von Zufallsvariablen geh√∂rt, und dann ihre Parameter bewerten. <br><br>  Wie w√§hlen wir die Familie der Zufallsvariablen aus?  Als Beispiel k√∂nnten wir annehmen, dass die Ausf√ºhrungszeit des Codes normal verteilt ist.  Das ist aber absolut falsch.  Erstens kann die Ausf√ºhrungszeit nicht negativ sein, und die Normalverteilung nimmt √ºberall auf der Zahlenlinie Werte an.  Zweitens gehe ich davon aus, dass die Ausf√ºhrungszeit am rechten Ende einen schweren "Schwanz" haben wird. <br><br>  Es gibt jedoch Faktoren, die es zu einer guten Idee machen k√∂nnten, die Normalverteilung nur f√ºr die Zwecke der Thompson-Stichprobe zu sch√§tzen (trotz der Tatsache, dass die Verteilung der Zielvariablen nicht unbedingt normal ist).  Der Grund daf√ºr ist, dass es sehr einfach ist, die mathematische Erwartung und die Varianz zu berechnen, und nach einer ausreichenden Anzahl von Iterationen wird eine Normalverteilung ziemlich eng, nicht viel anders als die Verteilungen, die wir mit anderen Methoden erhalten h√§tten.  Wenn wir uns bei den ersten Schritten nicht zu sehr mit der Konvergenzrate befassen, k√∂nnen diese Details ignoriert werden. <br><br> This may seem like a somewhat ignorant approach. Experience has shown us that the average time for query execution, website page loading, and so on is "garbage" that isn't worth calculating. It would be better to calculate the median, which is a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">robust statistic</a> . But this is a little more difficult, and as I will show later, the described method justifies itself for practical purposes. <br><br> At first I implemented calculation of the mathematical expectation and variance, but then I decided that this is too good, and I need to simplify the code to make it "worse": <br><br><pre> <code class="plaintext hljs">/// For better convergence, we don't use proper estimate of stddev. /// We want to eventually separate the two algorithms even in cases /// when there is no statistical significant difference between them. double sigma() const {    return mean() / sqrt(adjustedCount()); } double sample(pcg64 &amp; rng) const {    ...    return std::normal_distribution&lt;&gt;(mean(), sigma())(rng); }</code> </pre> <br> I wrote it so that the first few iterations were not taken into account, to eliminate the effect of memory latencies. <br><br> The result is a test program that can select the best algorithm for the input data, with optional modes that use the reference implementation of LZ4 or a specific version of the algorithm. <br><br> So there are six options: <br> ‚Äî Reference (baseline): original LZ4 without our modifications. <br> ‚Äî Variant 0: copy 8 bytes at a time without shuffle. <br> ‚Äî Variant 1: copy 8 bytes at a time with shuffle. <br> ‚Äî Variant 2: copy 16 bytes at a time without shuffle. <br> ‚Äî Variant 3: copy 16 bytes at a time with shuffle. <br> ‚Äî The "bandit" option, which selects the best of the four optimized variants. <br><br><h3> Testing on different CPUs </h3><br> If the result strongly depends on the CPU model, it would be interesting to find out exactly how it is affected. There might be an exceptionally large difference on certain CPUs. <br><br> I prepared a set of datasets from different tables in ClickHouse with real data, for a total of 256 different files each with 100 MB of uncompressed data (the number 256 was coincidental). Then I looked at the CPUs of the servers where I can run benchmarks. I found servers with the following CPUs: <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2650 v2 @ 2.60GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2660 v4 @ 2.00GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2660 0 @ 2.20GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5645 @ 2.40GHz <br> ‚Äî Intel Xeon E312xx (Sandy Bridge) <br> ‚Äî AMD Opteron(TM) Processor 6274 <br> ‚Äî AMD Opteron(tm) Processor 6380 <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2683 v4 @ 2.10GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5530 @ 2.40GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5440 @ 2.83GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2667 v2 @ 3.30GHz <br><br> The most interesting part comes next ‚Äî the processors provided by the R&amp;D department: <br> ‚Äî AMD EPYC 7351 16-Core Processor, a new AMD server processor. <br> ‚Äî Cavium ThunderX2, which is AArch64, not x86. For these, my SIMD optimization needed to be reworked a bit. The server has 224 logical and 56 physical cores. <br><br> There are 13 servers in total, and each of them runs the test on 256 files in 6 variants (reference, 0, 1, 2, 3, adaptive). The test is run 10 times, alternating between the options in random order. It outputs 199,680 results that we can compare. <br><br> For example, we can compare different CPUs with each other. But we shouldn't jump to conclusions from these results, because we are only testing the LZ4 decompression algorithm on a single core (this is a very narrow case, so we only get a micro-benchmark). For example, the Cavium has the lowest performance per single core. But I tested ClickHouse on it myself, and it wins out over Xeon E5-2650 v2 on heavy queries due to the greater number of cores, even though it is missing many optimizations that are made in ClickHouse specifically for the x86. <br><br><pre> ‚îå‚îÄcpu‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄref‚îÄ‚î¨‚îÄadapt‚îÄ‚î¨‚îÄ‚îÄmax‚îÄ‚î¨‚îÄbest‚îÄ‚î¨‚îÄadapt_boost‚îÄ‚î¨‚îÄmax_boost‚îÄ‚î¨‚îÄadapt_over_max‚îÄ‚îê<font></font>
‚îÇ E5-2667 v2 @ 3.30GHz ‚îÇ 2.81 ‚îÇ 3.19 ‚îÇ 3.15 ‚îÇ 3 ‚îÇ 1.14 ‚îÇ 1.12 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5-2650 v2 @ 2.60GHz ‚îÇ 2.5 ‚îÇ 2.84 ‚îÇ 2.81 ‚îÇ 3 ‚îÇ 1.14 ‚îÇ 1.12 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5-2683 v4 @ 2.10GHz ‚îÇ 2.26 ‚îÇ 2.63 ‚îÇ 2.59 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.15 ‚îÇ 1.02 ‚îÇ<font></font>
‚îÇ E5-2660 v4 @ 2.00GHz ‚îÇ 2.15 ‚îÇ 2.49 ‚îÇ 2.46 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.14 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ AMD EPYC 7351 ‚îÇ 2.03 ‚îÇ 2.44 ‚îÇ 2.35 ‚îÇ 3 ‚îÇ 1.20 ‚îÇ 1.16 ‚îÇ 1.04 ‚îÇ<font></font>
‚îÇ E5-2660 0 @ 2.20GHz ‚îÇ 2.13 ‚îÇ 2.39 ‚îÇ 2.37 ‚îÇ 3 ‚îÇ 1.12 ‚îÇ 1.11 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E312xx (Sandy Bridge) ‚îÇ 1.97 ‚îÇ 2.2 ‚îÇ 2.18 ‚îÇ 3 ‚îÇ 1.12 ‚îÇ 1.11 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5530 @ 2.40GHz ‚îÇ 1.65 ‚îÇ 1.93 ‚îÇ 1.94 ‚îÇ 3 ‚îÇ 1.17 ‚îÇ 1.18 ‚îÇ 0.99 ‚îÇ<font></font>
‚îÇ E5645 @ 2.40GHz ‚îÇ 1.65 ‚îÇ 1.92 ‚îÇ 1.94 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.18 ‚îÇ 0.99 ‚îÇ<font></font>
‚îÇ AMD Opteron 6380 ‚îÇ 1.47 ‚îÇ 1.58 ‚îÇ 1.56 ‚îÇ 1 ‚îÇ 1.07 ‚îÇ 1.06 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ AMD Opteron 6274 ‚îÇ 1.15 ‚îÇ 1.35 ‚îÇ 1.35 ‚îÇ 1 ‚îÇ 1.17 ‚îÇ 1.17 ‚îÇ 1 ‚îÇ<font></font>
‚îÇ E5440 @ 2.83GHz ‚îÇ 1.35 ‚îÇ 1.33 ‚îÇ 1.42 ‚îÇ 1 ‚îÇ 0.99 ‚îÇ 1.05 ‚îÇ 0.94 ‚îÇ<font></font>
‚îÇ Cavium ThunderX2 ‚îÇ 0.84 ‚îÇ 0.87 ‚îÇ 0.87 ‚îÇ 0 ‚îÇ 1.04 ‚îÇ 1.04 ‚îÇ 1 ‚îÇ<font></font>
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò </pre><br><ul><li> ref, adapt, max ‚Äî The speed in gigabytes per second (the value that is the reverse of the arithmetic mean of time for all launches on all datasets). </li><li> best ‚Äî The number of the best algorithm among the optimized variants, from 0 to 3. </li><li> adapt_boost ‚Äî The relative advantage of the adaptive algorithm compared to the baseline. </li><li> max_boost ‚Äî The relative advantage of the best of the non-adaptive variants compared to the baseline. </li><li> adapt_over_max ‚Äî The relative advantage of the adaptive algorithm over the best non-adaptive one. </li></ul><br> The results show that we were able to speed up decompression by 12-20% on modern x86 processors. Even on ARM we saw 4% improvement, despite the fact that we didn't optimize much for this architecture. It is also clear that on average for different datasets, the "bandit" algorithm comes out ahead of the pre-selected best variant on all processors (except for very old Intel CPUs). <br><br><h3>  Fazit </h3><br> In practice, the usefulness of this work is dubious. Yes, LZ4 decompression was accelerated on average by 12-20%, and on some datasets the performance more than doubled. But in general, this doesn't have much effect on query execution time. It's difficult to find real queries that gain more than a couple percent in speed. <br><br> We decided to use ZStandard level 1 instead of LZ4 on several Yandex Metrica clusters intended for executing long queries, because it is more important to save IO and disk space on cold data. Keep this in mind if you have similar workload. <br><br> We observed the greatest benefits from optimizing decompression in highly compressible data, such as columns with mostly duplicate string values. However, we have developed a separate solution specifically for this scenario that allows us to significantly speed up queries over this kind of data. <br><br> Another point to remember is that optimization of decompression speed is often limited by the format of the compressed data. LZ4 uses a very good format, but Lizard, Density and LZSSE have other formats that can work faster. Perhaps instead of trying to accelerate LZ4, it would be better to just integrate LZSSE into ClickHouse. <br><br> It's unlikely that these optimizations will be implemented in the mainstream LZ4 library: in order to use them, the library interface would have to be modified. In fact, this is often the case with improving algorithms ‚Äî optimizations don't fit into old abstractions and they have to be revised. However, variable names have already been corrected in the original implementation. For instance, inc and dec tables have been <a href="">corrected</a> . In addition, about a month ago, the original implementation accelerated decompression by the same 12-15% by copying 32 bytes instead of 16, as discussed above. We tried the 32-byte option ourselves and the results were not that great, but they were still <a href="">faster</a> . <br><br> If you look at the profile at the beginning of the article, you may notice that we could have removed one extra copying operation from the page cache to userspace (either using <code>mmap</code> , or using <code>O_DIRECT</code> and userspace page cache, but both options are problematic). We also could have slightly improved the checksum calculation (CityHash128 is currently used without CRC32-C, but we could use HighwayHash, FARSH or XXH3). Acceleration of these two operations is useful for weakly compressed data, since they are performed on compressed data. <br><br> In any case, the changes have already been added to master more than a year ago, and the ideas that resulted from this research have been applied in other tasks. You can also watch the <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">video</a> from HighLoad++ Siberia, or view the <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">presentation</a> (both in Russian). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de457612/">https://habr.com/ru/post/de457612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457600/index.html">Headsets - √úbersicht Snom A150, Snom A100M und D.</a></li>
<li><a href="../de457602/index.html">Untersuchung der Leistung von DBMS MS SQL Server Developer 2016 und PostgreSQL 10.5 f√ºr 1C</a></li>
<li><a href="../de457606/index.html">Alan Kay: Was kann man als das Erstaunlichste bezeichnen, was Computer m√∂glich gemacht haben?</a></li>
<li><a href="../de457608/index.html">So visualisieren Sie Daten zu einer √ºberzeugenden Geschichte</a></li>
<li><a href="../de457610/index.html">Evil Parcel Schwachstellenanalyse</a></li>
<li><a href="../de457614/index.html">Geheimnisse der Arbeitssuche im Ausland bei einem praktizierenden Headhunter</a></li>
<li><a href="../de457616/index.html">Mein "Wow, das wusste ich nicht!" Momente mit Scherz</a></li>
<li><a href="../de457618/index.html">Ein moderner Full-Stack-Entwickler sein</a></li>
<li><a href="../de457622/index.html">Qt-Leistung messen</a></li>
<li><a href="../de457624/index.html">Wie wir die alte H√ºtte zerbrochen und an ihrer Stelle einen Wolkenkratzer gebaut haben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
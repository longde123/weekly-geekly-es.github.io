<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧑🏿‍🤝‍🧑🏽 👩🏻‍🎓 ⛲️ تعزيز التعلم العميق: بكسل الخام بينغ بونغ 💪 👁‍🗨 👠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="هذا هو مقال طال انتظاره حول التعلم التعزيز (RL). RL هو موضوع رائع! 

 قد تعلم أن أجهزة الكمبيوتر يمكن أن تتعلم الآن تلقائيًا ممارسة ألعاب ATARI (عن طر...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>تعزيز التعلم العميق: بكسل الخام بينغ بونغ</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439674/" style=";text-align:right;direction:rtl">  هذا هو مقال طال انتظاره حول التعلم التعزيز (RL).  RL هو موضوع رائع! <br><br>  قد تعلم أن أجهزة الكمبيوتر يمكن أن <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">تتعلم</a> الآن <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">تلقائيًا ممارسة ألعاب ATARI</a> (عن طريق الحصول على بكسلات ألعاب خام عند المدخل!).  لقد تغلبوا على أبطال العالم في لعبة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">Go</a> ، وتعلموا بأربعة أرجل افتراضي <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">الجري والقفز</a> ، ويتعلم الإنسان الآلي أداء مهام معالجة معقدة تتحدى البرمجة الواضحة.  اتضح أن كل هذه الإنجازات ليست كاملة دون RL.  كنت مهتمًا أيضًا بـ RL على مدار العام الماضي: عملت مع كتاب <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">Richard Sutton (تقريبًا المرجع: استبدال)</a> ، وقراءة دورة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">David Silver</a> ، <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">وحضر محاضرات John Schulman</a> ، وكتب <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">مكتبة RL على Javascript</a> ، وفي التدريب الصيفي في DeepMind ، كنت أعمل في مجموعة DeepRL ، ومؤخراً ، في تطوير <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">OpenAI Gym</a> ، هي مجموعة أدوات RL الجديدة.  لذلك ، بالطبع ، لقد كنت على هذه الموجة منذ عام على الأقل ، لكنني لم أزعجني حتى الآن بكتابة ملاحظة حول سبب أهمية RL لأهميته الكبيرة ، وعن ماهية الموضوع ، وكيف يتطور كل هذا. <br><br><img src="https://habrastorage.org/webt/vr/ir/gu/vrirgukar82fw0cg6wbnsklagum.png"><br>  <i>أمثلة على استخدام Deep Q-Learning.</i>  <i>من اليسار إلى اليمين: تقوم الشبكة العصبية بلعب ATARI ، وتلعب الشبكة العصبية لعبة AlphaGo ، حيث يقوم الرجل الآلي بطي Lego ، حيث يعمل الجهاز الافتراضي ذو الأرجل الأربعة على العقبات الافتراضية.</i> <br><a name="habracut"></a><br>  من المثير للاهتمام التفكير في طبيعة التقدم الذي أحرز مؤخرا في RL.  أود أن أشير إلى أربعة عوامل منفصلة تؤثر على تطور الذكاء الاصطناعي: <br><br><ol style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  سرعة الحوسبة (GPU ، أسيك للأجهزة الخاصة ، قانون مور) </li><li style=";text-align:right;direction:rtl">  بيانات كافية في شكل قابل للاستخدام (مثل ImageNet) </li><li style=";text-align:right;direction:rtl">  الخوارزميات (البحث والأفكار ، على سبيل المثال backprop ، CNN ، LSTM) </li><li style=";text-align:right;direction:rtl">  بنية أساسية (Linux ، TCP / IP ، Git ، ROS ، PR2 ، AWS ، AMT ، TensorFlow ، وما إلى ذلك). </li></ol><br>  تمامًا كما هو الحال في رؤية الكمبيوتر ، يتقدم التقدم في RL ... ولكن ليس بقدر ما قد يبدو.  على سبيل المثال ، في رؤية الكمبيوتر ، تعد الشبكة العصبية لـ AlexNet 2012 إصدارًا متعمقًا وعميقًا لشبكة التسعينيات ConvNets العصبية.  وبالمثل ، يعد ATARI Deep Q-Learning 2013 تطبيقًا لخوارزمية Q-Learning القياسية التي يمكنك العثور عليها في كتاب ريتشارد سوتون الكلاسيكي لعام 1998.  علاوة على ذلك ، تستخدم AlphaGo تقنية تدرج السياسة والبحث الشجري في مونت كارلو (MCTS) هي أيضًا أفكار قديمة أو مجموعاتها.  بالطبع ، يتطلب الأمر الكثير من المهارات والصبر لحملهم على العمل ، وقد تم تطوير العديد من الإعدادات الصعبة بالإضافة إلى الخوارزميات القديمة.  <b>ولكن في التقريب الأول ، ليس الدافع الرئيسي للتقدم الأخير هو الخوارزميات والأفكار الجديدة ، بل تكثيف العمليات الحسابية ، والبيانات الكافية ، والبنية التحتية الناضجة.</b> <br><br>  عاد الآن إلى RL.  لا يعتقد الكثير من الناس أنه بإمكاننا تعليم الكمبيوتر كيفية لعب ألعاب ATARI على المستوى الإنساني باستخدام وحدات بكسل خام من نقطة الصفر واستخدام نفس خوارزمية التعلم الذاتي.  في الوقت نفسه ، في كل مرة أشعر بوجود فجوة - كيف تبدو سحرية ، وكم هي بسيطة في الداخل. <br><br>  النهج الأساسي الذي نستخدمه هو في الواقع غبية جدا.  وبغض النظر عن ذلك ، أود أن أقدم لكم تقنية النهج التدريجي (PG) ، وهو خيارنا الافتراضي المفضل لحل مشاكل RL في الوقت الحالي.  قد تكون فضولياً لماذا ، بدلاً من ذلك ، لا أستطيع أن أتخيل DQN ، وهي خوارزمية RL بديلة ومعروفة وتستخدم أيضًا في <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">تدريب ATARI</a> .  اتضح أنه على الرغم من أن Q-Learning معروف ، إلا أنه ليس مثاليًا.  يختار معظم الناس استخدام "تدرج السياسة" ، بما في ذلك مؤلفو <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">مقالة DQN</a> الأصلية ، الذين أظهروا أنه مع التوليف الجيد ، يعمل تدرج السياسة بشكل أفضل من Q-Learning.  PG هو الأفضل لأنه صريح: هناك سياسة واضحة ونهج متماسك يحسن مباشرة المكافآت المتوقعة.  على سبيل المثال ، سوف نتعلم كيف نلعب ATARI Pong: من البداية ، من البكسلات الخام من خلال تدرج السياسة مع شبكة عصبية.  وسنضع كل هذا في 130 سطرًا من بيثون.  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">رابط Gist</a> ) دعونا نرى كيف يتم ذلك. <br><br><img src="https://habrastorage.org/webt/yy/fk/hg/yyfkhg3xutt4gsualf7l6o0sa4i.gif"><br><img src="https://habrastorage.org/webt/mw/rq/2w/mwrq2wthkobnxuqohcfovs1lgei.jpeg"><br>  <i>أعلاه: بينج بونج.</i>  <i>أدناه: عرض بينج بونج كحالة خاصة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">لعملية صنع القرار في ماركوف (MDP)</a> : يتوافق كل رأس من الرسم البياني مع حالة معينة من اللعبة ، وتحدد الحواف احتمالات الانتقال إلى حالات أخرى.</i>  <i>كما يحدد كل ضلع المكافأة.</i>  <i>الهدف هو العثور على أفضل مسار من أي ولاية لتعظيم المكافأة</i> <br><br>  يعد لعب Ping Pong مثالاً رائعًا على تحدي RL.  في إصدار ATARI 2600 ، سنلعب مضربًا واحدًا بأنفسنا.  يتم التحكم في مضرب آخر بواسطة خوارزمية مدمجة.  نحتاج أن نضرب الكرة حتى لا يتوفر للاعب الآخر الوقت لضربها.  آمل ألا تكون هناك حاجة لشرح ما هي لعبة Ping Pong.  على مستوى منخفض ، تعمل اللعبة على النحو التالي: نحصل على إطار صورة - مجموعة من وحدات البايت 210 × 160 × 3 ، ونقرر ما إذا كنا نريد تحريك المضرب لأعلى أو لأسفل.  هذا هو ، لدينا خياران فقط لإدارة اللعبة.  بعد كل اختيار ، يؤدي محاكي اللعبة نشاطه ويمنحنا مكافأة: إما مكافأة +1 إذا مرت الكرة على مضرب الخصم ، أو -1 إذا أخطأنا الكرة.  0. وبطبيعة الحال ، فإن هدفنا هو تحريك المضرب بحيث نحصل على أكبر قدر ممكن من المكافأة. <br><br>  عند التفكير في حل ، تذكر أننا سنحاول وضع عدد قليل من الافتراضات حول كرة الطاولة ، لأنها ليست مهمة بشكل خاص في الممارسة.  نأخذ الكثير من الأشياء في الاعتبار في المهام واسعة النطاق ، مثل معالجة الروبوتات والتجميع والتنقل.  Pong هي مجرد حالة اختبار للعبة ممتعة نلعب بها أثناء اكتشافنا لكيفية كتابة أنظمة الذكاء الاصطناعى العامة جدًا التي يمكنها القيام بمهام تعسفية ذات يوم. <br><br>  <b>الشبكة العصبية كسياسة RL</b> .  أولاً ، سنحدد السياسة المزعومة التي ينفذها لاعبنا (أو "الوكيل").  ((*) "العامل" و "البيئة" و "سياسة الوكيل" هي مصطلحات قياسية من نظرية RL).  وظيفة السياسة في حالتنا هي شبكة عصبية.  ستقبل حالة اللعبة عند المدخل وعند الخروج ستقرر ما يجب فعله - التحرك لأعلى أو لأسفل.  بصفتنا مجموعة الحسابات البسيطة المفضلة لدينا ، سوف نستخدم شبكة عصبية ثنائية الطبقة تأخذ بيكسلات صورة خام (إجمالي 100800 رقم (210 * 160 * 3)) وتنتج رقمًا واحدًا يشير إلى احتمال تحريك المضرب لأعلى.  يرجى ملاحظة أن استخدام سياسة الاستوكاستك هو المعيار ، مما يعني أننا ننتج فقط احتمال الحركة الصعودية.  للحصول على التحرك الفعلي ، سوف نستخدم هذا الاحتمال.  سوف يصبح سبب ذلك أوضح عندما نتحدث عن التدريب. <br><br><img src="https://habrastorage.org/webt/cm/n4/ap/cmn4apvesxvu5d8konqytnbk0cm.png"><br>  <i>تتألف وظيفة سياستنا من شبكة عصبية متصلة بالكامل بطبقتين</i> <br><br>  بشكل أكثر تحديدًا ، لنفترض أنه عند الإدخال نحصل على ناقل X ، والذي يحتوي على مجموعة من وحدات البكسل التي تمت معالجتها مسبقًا.  ثم يجب علينا حساب باستخدام python \ numpy: <br><br><pre style=";text-align:right;direction:rtl"><code class="python hljs">h = np.dot(W1, x) <span class="hljs-comment"><span class="hljs-comment"># compute hidden layer neuron activations h[h&lt;0] = 0 # ReLU nonlinearity: threshold at zero logp = np.dot(W2, h) # compute log probability of going up p = 1.0 / (1.0 + np.exp(-logp)) # sigmoid function (gives probability of going up)</span></span></code> </pre> <br>  في هذه الشريحة ، W1 و W2 هما مصفوفان نبدأ التهيئة بشكل عشوائي.  نحن لا نستخدم التحيز ، لأننا أردنا.  لاحظ أننا في النهاية نستخدم اللامخطية من السيني ، مما يقلل من احتمال الإخراج إلى المدى [0،1].  بشكل حدسي ، يمكن للخلايا العصبية الموجودة في طبقة مخفية (التي تقع أوزانها في W1) اكتشاف سيناريوهات اللعبة المختلفة (على سبيل المثال ، الكرة في الأعلى ومضربنا في المنتصف) ، ويمكن للأوزان في W2 بعد ذلك تحديد ما إذا كان يجب علينا الصعود في كل حالة أو لأسفل.  وبطبيعة الحال ، فإن العشوائي الأولي W1 و W2 ، في البداية ، سوف يتسبب في حدوث تشنجات وتشنجات في لاعبنا العصبي ، مما يساويه شخص مصاب بالتوحد عند التحكم في الطائرة.  المهمة الوحيدة الآن هي العثور على W1 و W2 ، والتي تؤدي إلى لعبة جيدة! <br><br>  هناك ملاحظة حول المعالجة المسبقة للبكسل - من الناحية المثالية ، تحتاج إلى نقل إطارين على الأقل إلى الشبكة العصبية حتى تتمكن من اكتشاف الحركة.  ولكن لتبسيط الموقف ، سوف نطبق الفرق بين إطارين.  أي أننا سنطرح الإطارات الحالية والسابقة وبعد ذلك فقط نطبق الفرق على مدخلات الشبكة العصبية. <br><br>  <b>يبدو وكأنه شيء مستحيل.</b>  في هذه المرحلة ، أود منك أن تقدر مدى تعقيد مشكلة RL.  نحصل على 100 800 رقم (210 × 160 × 3) ونرسل إلى شبكتنا العصبية التي تنفذ سياسة اللاعب (والتي ، بالمناسبة ، تتضمن بسهولة حوالي مليون معلمة في المصفوفات W1 و W2).  لنفترض أننا في مرحلة ما قررنا الصعود.  يستطيع محاكي اللعبة الإجابة على أننا سنحصل هذه المرة على 0 جائزة ومنحنا 100 800 رقم آخر للإطار التالي.  يمكننا تكرار هذه العملية مئات المرات قبل أن نحصل على مكافأة غير صفرية!  على سبيل المثال ، افترض أننا حصلنا في النهاية على مكافأة +1.  هذا رائع ، لكن كيف يمكننا إذن أن نقول ما الذي أدى إلى هذا؟  هل كان هذا الإجراء الذي قمنا به للتو؟  أو ربما 76 لقطة الظهر؟  أو ربما تم ربط هذا أولاً بالإطار 10 ، ثم فعلنا شيئًا صحيحًا في الإطار 90؟  وكيف نكتشف - أي من "أقلام" المليون التي يجب تحريفها لتحقيق نجاح أكبر في المستقبل؟  نسمي هذا مهمة تحديد معامل الثقة في بعض الإجراءات.  في الحالة المحددة مع كرة الطاولة ، نعلم أننا نحصل على +1 إذا مرت الكرة على الخصم.  السبب الحقيقي هو أننا ركلنا الكرة بطريق الخطأ على طول مسار جيد بإطارات قليلة ، ولم يؤثر كل إجراء تالٍ قمنا به على الإطلاق.  بمعنى آخر ، نواجه مشكلة حسابية معقدة للغاية ، ويبدو كل شيء كئيبًا إلى حد ما. <br><br>  <b>التدريب مع المعلم.</b>  قبل الخوض في تدرج السياسة (PG) ، أود أن أتذكر بإيجاز التدريس مع المعلم ، لأنه ، كما سنرى ، RL متشابهة جدًا.  الرجوع إلى الرسم البياني أدناه.  في التدريس العادي مع أحد المعلمين ، سننقل الصورة إلى الشبكة وسنتلقى في المخرجات بعض الاحتمالات العددية للفصول.  على سبيل المثال ، في حالتنا لدينا فئتان: UP و DOWN.  أستخدم الاحتمالات اللوغاريتمية (-1،2 ، -0،36) بدلاً من الاحتمالات بتنسيق 30٪ و 70٪ ، لأننا نقوم بتحسين الاحتمالية اللوغاريتمية للفئة الصحيحة (أو التصنيف).  هذا يجعل العمليات الحسابية أكثر أناقة وتعادل تحسين الاحتمال العادل ، لأن اللوغاريتم رتيب. <br><br>  في التدريب مع المعلم ، سيكون لدينا إمكانية الوصول الفوري إلى الفصل الصحيح (التسمية).  في مرحلة التدريب ، سوف يخبروننا بالضبط بالخطوة الصحيحة المطلوبة الآن (دعنا نقول أنها UP ، التسمية 0) ، على الرغم من أن الشبكة العصبية قد تفكر بشكل مختلف.  لذلك ، نحسب التدرج <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mtext" id="MJXp-Span-2">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-5"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-6"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-7"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-9" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-10"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">W</font></font></span></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12"><font style="vertical-align: inherit;"> l </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13"><font style="vertical-align: inherit;">o </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14"><font style="vertical-align: inherit;">g </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15"><font style="vertical-align: inherit;">p </font></span><span class="MJXp-mo" id="MJXp-Span-16" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17"><font style="vertical-align: inherit;">y </font></span><span class="MJXp-mo" id="MJXp-Span-18" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;">= </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19"><font style="vertical-align: inherit;">U </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-20"><font style="vertical-align: inherit;">P </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22"><font style="vertical-align: inherit;">m </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-23"><font style="vertical-align: inherit;">i </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24"><font style="vertical-align: inherit;">d </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25"><font style="vertical-align: inherit;">x </font></span><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">)</font></span></font><span class="MJXp-mtext" id="MJXp-Span-11">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-16" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-18" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-20"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mtext" id="MJXp-Span-21">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-23"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.327ex" height="2.66ex" viewBox="0 -832 12196.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6E" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-61" x="850" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-62" x="1380" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6C" x="1809" y="0"></use><g transform="translate(2108,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-57" x="748" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6C" x="3728" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6F" x="4027" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-67" x="4512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-70" x="4993" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMAIN-28" x="5496" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-79" x="5886" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMAIN-3D" x="6661" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-55" x="7717" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-50" x="8485" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6D" x="9486" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-69" x="10365" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-64" x="10710" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-78" x="11234" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMAIN-29" x="11806" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1"> \ nabla_ {W} \ log p (y = UP \ mid x) </script>  للقرص إعدادات الشبكة.  يخبرنا هذا التدرج اللوني فقط كيف ينبغي لنا أن نغير كل معلمة من ملايين معلماتنا بحيث من المحتمل أن تتنبأ الشبكة قليلاً في نفس الموقف.  على سبيل المثال ، يمكن أن تحتوي إحدى معلمات المليون في الشبكة على تدرج -2.1 ، مما يعني أنه إذا قمنا بزيادة هذه المعلمة بقيمة موجبة صغيرة (على سبيل المثال ، 0.001) ، فإن الاحتمال اللوغاريتمي لـ UP سينخفض ​​بمقدار 2.1 * 0.001.  (انخفاض بسبب علامة سلبية).  إذا قمنا بتطبيق التدرج الليلي ثم قمنا بتحديث المعلمة باستخدام خوارزمية backpropagation ، إذن ، نعم ، ستوفر شبكتنا احتمالًا كبيرًا لـ UP عندما ترى الصورة نفسها أو صورة مشابهة جدًا في المستقبل. <br><br><img src="https://habrastorage.org/webt/-p/r6/bu/-pr6bumeyrk2xdf9nuoulm5oflw.png"><br><br>  <b>التدرجات السياسية (PG)</b> .  حسنًا ، لكن ماذا نفعل إذا لم يكن لدينا بطاقة تدريب التعزيز الصحيحة؟  إليك حل PG (راجع المخطط أدناه مرة أخرى).  حسبت شبكتنا العصبية احتمال ارتفاع بنسبة 30 ٪ (logprob -1.2) و DOWN بنسبة 70 ٪ (logprob -0.36).  الآن نقوم باختيار من هذا التوزيع ونحدد الإجراء الذي سنفعله.  على سبيل المثال ، اختاروا DOWN وأرسلوا هذا الإجراء إلى محاكي اللعبة.  في هذه المرحلة ، انتبه إلى حقيقة واحدة مثيرة للاهتمام: يمكننا على الفور حساب وتطبيق التدرج اللوني لتصرف DOWN ، كما فعلنا في التدريس مع المعلم ، وبالتالي جعل الشبكة أكثر عرضة لأداء إجراء DOWN في المستقبل.  وبالتالي ، يمكننا أن نقدر على الفور ونتذكر هذا التدرج.  لكن المشكلة هي أنه في الوقت الحالي لا نعرف حتى الآن - هل من الجيد أن تنزل؟  <b>ولكن الشيء الأكثر إثارة للاهتمام هو أنه يمكننا فقط الانتظار قليلاً وتطبيق التدرج اللاحق!</b>  في Pong ، يمكننا الانتظار حتى نهاية اللعبة ، ثم نأخذ المكافأة التي تلقيناها (إما +1 إذا فزنا ، أو -1 إذا فقدنا) ، وأدخلها كعامل للتدرج.  لذلك ، إذا قدمنا ​​-1 لاحتمال DOWN وقمنا بالانتشار الخلفي ، فسنقوم بإعادة إنشاء معلمات الشبكة بحيث يكون من غير المحتمل إجراء إجراء DOWN في المستقبل عندما تواجه نفس الصورة ، لأن اعتماد هذا الإجراء دفعنا إلى خسارة اللعبة.  وهذا يعني أننا سنحتاج إلى تذكر جميع الإجراءات (مدخلات ومخرجات الشبكة العصبية) في إحدى حلقات اللعبة ، واستناداً إلى هذا المصفوفة ، قم بتحريف الشبكة العصبية بنفس طريقة التدريس في المدرس تقريبًا. <br><br><img src="https://habrastorage.org/webt/hj/jr/tg/hjjrtgpmkweozlnidrhixsf7jfs.png"><br><br>  وهذا كل ما هو مطلوب: لدينا سياسة عشوائية تختار الإجراءات ، ثم في المستقبل ، يتم تشجيع الإجراءات التي تؤدي في النهاية إلى نتائج جيدة ، والإجراءات التي تؤدي إلى نتائج سيئة لا يتم تشجيعها.  بالإضافة إلى ذلك ، يجب ألا تكون المكافأة +1 أو -1 إذا فزنا في النهاية باللعبة.  يمكن أن تكون قيمة تعسفية لنفس المعنى.  على سبيل المثال ، إذا كان كل شيء يعمل بشكل جيد بالفعل ، فقد تكون المكافأة 10.0 ، والتي نستخدمها بعد ذلك كتدرج لبدء backpropagation.  هذا هو جمال الشبكات العصبية.  قد يبدو استخدامها بمثابة خدعة: يُسمح لك بوجود مليون معلمة مضمّنة في 1 ترافلوب من العمليات الحسابية ، ويمكنك جعل البرنامج يتعلم كيفية القيام بأشياء تعسفية من خلال النسب التدريجي العشوائي (SGD).  لا ينبغي أن تعمل ، ولكن من المضحك أن نعيش في عالم يعمل فيه. <br><br>  إذا لعبنا ألعاب لوحية بسيطة ، مثل لعبة الداما ، فسيكون الترتيب هو نفسه تقريبًا.  هناك اختلاف ملحوظ من خوارزميات لقطة minimax أو alpha-beta.  في هذه الخوارزميات ، يتطلع البرنامج إلى الأمام بخطوات قليلة ، ومعرفة قواعد اللعبة ، ويحلل ملايين المواضع.  في نهج RL ، يتم تحليل التحركات التي تم إجراؤها بالفعل فقط.  في الوقت نفسه ، لا تتطلع الشبكة العصبية إلى الأمام ، لأنها لا تعرف أي شيء عن قواعد اللعبة. <br><br>  <b>ترتيب تجريب في التفاصيل.</b>  نقوم بإنشاء وتهيئة شبكة عصبية باستخدام بعض W1 و W2 ولعب 100 لعبة كرة الطاولة (نسميها "الركض" للسياسة وتداول السياسات).  لنفترض أن كل لعبة تتكون من 200 إطار ، لذلك في المجموع اتخذنا 100 * 200 = 20،000 قرار صعودا أو هبوطا.  ولكل من الحلول ، فإننا نعرف تدرجًا يخبرنا كيف يجب تغيير المعلمات إذا أردنا تشجيع أو حظر هذا الحل في هذه الحالة في المستقبل.  كل ما تبقى الآن هو تسمية كل قرار نتخذه بأنه جيد أو سيء.  على سبيل المثال ، افترض أننا فزنا بـ 12 مباراة وخسرنا 88. سنتخذ جميع القرارات 200 * 12 = 2400 التي اتخذناها في الألعاب الفائزة ونجري تحديثًا إيجابيًا (ملء تدرج +1.0 لكل إجراء ، وإجراء backprop ، وتحديث المعلمات تشجيع الإجراءات التي اخترناها في كل هذه الظروف).  وسنتخذ القرارات 200 * 88 = 17،600 الأخرى التي اتخذناها في خسارة الألعاب وإجراء تحديث سلبي (لا نوافق على ما فعلناه).  وهذا كل ما يتطلبه الأمر.  ستكون الشبكة الآن أكثر عرضة لتكرار الإجراءات التي نجحت ، وأقل احتمالًا تكرار الإجراءات التي لم تنجح.  الآن نلعب 100 لعبة أخرى من خلال سياستنا الجديدة المحسّنة قليلاً ، ثم نكرر تطبيق التدرجات. <br><br><img src="https://habrastorage.org/webt/zv/ap/mo/zvapmoiul9plnltsttdsplvze3g.png"><br>  <i>مخطط الكرتون من 4 مباريات.</i>  <i>كل دائرة سوداء هي نوع من حالة اللعبة (تظهر ثلاثة أمثلة للحالات أدناه) ، وكل سهم عبارة عن انتقال يتم تمييزه بالإجراء الذي تم تحديده.</i>  <i>في هذه الحالة ، فزنا بمباراتين وخسرنا مباراتين.</i>  <i>لقد اتخذنا المباراتين اللتين فزناهما وشجعنا كل إجراء قمنا به في هذه الحلقة.</i>  <i>بالمقابل ، سوف نأخذ أيضًا المباراتين المفقودتين ونثبط بعض الإجراءات الفردية التي قمنا بها في هذه الحلقة.</i> <br><br>  إذا كنت تفكر في هذا ، فسوف تبدأ في العثور على بعض الخصائص الممتعة.  على سبيل المثال ، ماذا لو فعلنا إجراءً جيدًا في الإطار 50 ، حيث ركلنا الكرة بشكل صحيح ، ولكن بعد ذلك أخطأنا الكرة في الإطار 150؟  نظرًا لأننا خسرنا اللعبة ، فإن كل إجراء فردي أصبح الآن سيئًا ، ألا يمنع هذا الضربة الصحيحة على الإطار 50؟  أنت على حق - سيكون الأمر كذلك بالنسبة لهذا الحزب.  ومع ذلك ، عندما تفكر في العملية في آلاف / ملايين الألعاب ، فإن التنفيذ الصحيح للارتداد يزيد من احتمالية الفوز في المستقبل.  في المتوسط ​​، سترى تحديثات أكثر إيجابية من السلبية لإضراب مضرب مناسب.  وستنتج سياسة تنفيذ الشبكة العصبية في نهاية المطاف ردود الفعل الصحيحة. <br><br>  <i>تحديث: 9 ديسمبر 2016</i> هو وجهة نظر بديلة.  في شرحي أعلاه ، أستخدم مصطلحات مثل "تحديد انتشار التدرج الخلفي والخلفي" ، وهو أسلوب ماهر.  إذا كنت معتادًا على كتابة رمز backprop الخاص بك أو باستخدام Torch ، يمكنك التحكم في التدرجات بشكل كامل.  ومع ذلك ، إذا كنت معتادًا على Theano أو TensorFlow ، فستكون في حيرة بعض الشيء لأن شفرة backprop مؤتمتة بالكامل ويصعب تخصيصها.  في هذه الحالة ، قد يكون العرض البديل التالي أكثر إنتاجية.  في التدريس مع المعلم ، فإن الهدف المعتاد هو تحقيق الحد الأقصى <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-27"><span class="MJXp-mtext" id="MJXp-Span-28">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-29"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">الصورة </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-30"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ش </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-31"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-32" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">م </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-33" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ط</font></font></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35"><font style="vertical-align: inherit;"> ل </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36"><font style="vertical-align: inherit;">س </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37"><font style="vertical-align: inherit;">ز </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38"><font style="vertical-align: inherit;">ص </font></span><span class="MJXp-mo" id="MJXp-Span-39" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-msubsup" id="MJXp-Span-40"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">ص </font></span></span><span class="MJXp-msubsup" id="MJXp-Span-40"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-42" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;">ط</font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-44"><font style="vertical-align: inherit;"> م </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45"><font style="vertical-align: inherit;">ط </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-46"><font style="vertical-align: inherit;">د </font></span><span class="MJXp-msubsup" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">س </font></span></span><span class="MJXp-msubsup" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-49" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;">ط</font></span></span><span class="MJXp-mo" id="MJXp-Span-50" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"> )</font></span></font><span class="MJXp-mtext" id="MJXp-Span-34">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-39" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-40"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-42" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mtext" id="MJXp-Span-43">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-44"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-46"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-49" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mo" id="MJXp-Span-50" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.045ex" height="2.66ex" viewBox="0 -832 9060.9 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-75" x="719" y="0"></use><g transform="translate(1292,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6C" x="2764" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6F" x="3063" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-67" x="3548" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-70" x="4029" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMAIN-28" x="4532" y="0"></use><g transform="translate(4922,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-69" x="693" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-6D" x="6007" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-69" x="6885" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-64" x="7231" y="0"></use><g transform="translate(7754,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMATHI-69" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhgfOCFd7RRxh4iKJlcMLe-8dTcrHQ#MJMAIN-29" x="8671" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-2"> \ sum_i \ log p (y_i \ mid x_i) </script>  اين <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-51"><span class="MJXp-msubsup" id="MJXp-Span-52"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-53" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">س </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-54" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أنا </font></font></span></span><span class="MJXp-mrow" id="MJXp-Span-55"><span class="MJXp-mo" id="MJXp-Span-56" style="margin-left: 0.278em; margin-right: 0.278em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، </font></font></span></span><span class="MJXp-msubsup" id="MJXp-Span-57"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-58" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ذ </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-59" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أنا</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-3"> x_i ، y_i </script>  - أمثلة التدريب (مثل الصور والتسميات الخاصة بهم).  إن تطبيق التدرج اللاحق على وظيفة السياسة يتزامن تمامًا مع التدريب مع المعلم ، ولكن مع اختلافين بسيطين: 1) ليس لدينا التصنيفات الصحيحة <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-60"><span class="MJXp-msubsup" id="MJXp-Span-61"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ذ </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-63" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أنا</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-4"> y_i </script>  لذلك ، "كتسمية مزيفة" ، نستخدم الإجراء الذي تلقيناه للاختيار من السياسة عند رؤيته <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-64"><span class="MJXp-msubsup" id="MJXp-Span-65"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-66" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">س </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-67" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أنا</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-5"> x_i </script>  و 2) نقدم معاملًا آخر للنفعية (ميزة) لكل إجراء.  وهكذا ، في النهاية ، تبدو خسارتنا الآن <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-68"><span class="MJXp-mtext" id="MJXp-Span-69">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">الصورة </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-71"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ش </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-72"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-73" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">م </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-74" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ط </font></font></span></span><span class="MJXp-msubsup" id="MJXp-Span-75"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-76" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أ </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-77" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ط</font></font></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79"><font style="vertical-align: inherit;"> ل </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80"><font style="vertical-align: inherit;">س </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-81"><font style="vertical-align: inherit;">ز </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-82"><font style="vertical-align: inherit;">ص </font></span><span class="MJXp-mo" id="MJXp-Span-83" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-msubsup" id="MJXp-Span-84"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-85" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">ص </font></span></span><span class="MJXp-msubsup" id="MJXp-Span-84"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-86" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;">ط</font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88"><font style="vertical-align: inherit;"> م </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-89"><font style="vertical-align: inherit;">ط </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-90"><font style="vertical-align: inherit;">د </font></span><span class="MJXp-msubsup" id="MJXp-Span-91"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-92" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">س </font></span></span><span class="MJXp-msubsup" id="MJXp-Span-91"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-93" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;">ط</font></span></span><span class="MJXp-mo" id="MJXp-Span-94" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"> )</font></span></font><span class="MJXp-mtext" id="MJXp-Span-78">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-81"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-82"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-83" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-84"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-85" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-86" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mtext" id="MJXp-Span-87">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-89"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-90"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-91"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-92" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-93" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mo" id="MJXp-Span-94" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-6"> \ sum_i A_i \ log p (y_i \ mid x_i) </script>  اين <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-95"><span class="MJXp-msubsup" id="MJXp-Span-96"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-97" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ذ </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-98" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أنا</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-7"> y_i </script>  - هذا هو الإجراء الذي قمنا به مع العينة ، و <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-99"><span class="MJXp-msubsup" id="MJXp-Span-100"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-101" style="margin-right: 0.05em;">A</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-102" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-8"> A_i </script>  هو الرقم الذي نسميه معامل النفعية.  على سبيل المثال ، في حالة بونغ ، القيمة <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-103"><span class="MJXp-msubsup" id="MJXp-Span-104"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-105" style="margin-right: 0.05em;">A</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-106" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-9"> A_i </script>  قد يكون 1.0 إذا انتهى بنا الأمر بالفوز في الحلقة ، و -1.0 إذا خسرنا.  هذا يضمن أننا نزيد من احتمال تسجيل الإجراءات التي أدت إلى نتيجة جيدة ، وتقليل احتمال تسجيل الإجراءات التي لم تفعل ذلك.  ولن تؤثر الإجراءات المحايدة نتيجة لدعوات كثيرة بشكل خاص على وظيفة السياسة.  وهكذا ، فإن التعلم المعزز هو نفسه تمامًا مثل التعلم مع المعلم ، ولكن في مجموعة بيانات دائمة التغير (الحلقات) ، مع عامل إضافي. <br><br>  <b>ميزات جدوى أكثر تقدما.</b>  وعدت أيضا معلومات أكثر قليلا.  حتى الآن ، قمنا بتقييم صحة كل إجراء فردي بناءً على ما إذا كنا نفوز أم لا.  في إعداد RL أكثر عمومية ، سوف نتلقى "مكافأة مشروطة" <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-107"><span class="MJXp-msubsup" id="MJXp-Span-108"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-109" style="margin-right: 0.05em;">r</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-110" style="vertical-align: -0.4em;">t</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-10"> r_t </script>  لكل خطوة ، اعتمادا على رقم الخطوة أو الوقت.  أحد الخيارات الشائعة هو استخدام معامل مخصوم ، لذلك ستكون "المكافأة المحتملة" في المخطط أعلاه <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-111"><span class="MJXp-msubsup" id="MJXp-Span-112"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113" style="margin-right: 0.05em;">R</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-114" style="vertical-align: -0.4em;">t</span></span><span class="MJXp-mo" id="MJXp-Span-115" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-116">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-118">u</span><span class="MJXp-msubsup" id="MJXp-Span-119"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-120" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-125"><span class="MJXp-mtext" id="MJXp-Span-126">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-128">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-129">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-130">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-131">y</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-121"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-122">k</span><span class="MJXp-mo" id="MJXp-Span-123">=</span><span class="MJXp-mn" id="MJXp-Span-124">0</span></span></span></span></span></span></span><span class="MJXp-mtext" id="MJXp-Span-132">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-133">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-136">m</span><span class="MJXp-msubsup" id="MJXp-Span-137"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-138" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-139" style="vertical-align: 0.5em;">k</span></span><span class="MJXp-msubsup" id="MJXp-Span-140"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-141" style="margin-right: 0.05em;">r</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-142" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143">t</span><span class="MJXp-mo" id="MJXp-Span-144">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-145">k</span></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-11"> R_t = \ sum_ {k = 0} ^ {\ infty} \ gamma ^ k r_ {t + k} </script>  اين <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-146"><span class="MJXp-mtext" id="MJXp-Span-147">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-148">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-149">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-150">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-151">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-152">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-12"> \ gamma </script>  هو رقم من 0 إلى 1 ، يسمى معامل الخصم (على سبيل المثال ، 0.99).  يشير التعبير إلى أن القوة التي نشجعها على اتخاذ إجراء هي المبلغ المرجح لجميع المكافآت ، ولكن المكافآت اللاحقة أقل أهمية بشكل كبير.  وهذا يعني أن السلاسل القصيرة من الإجراءات يتم تشجيعها بشكل أفضل ، ويصبح ذيل السلاسل الطويلة من الإجراءات أقل أهمية.  في الممارسة العملية ، تحتاج أيضًا إلى تطبيعها.  على سبيل المثال ، لنفترض أننا نحسب <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-153"><span class="MJXp-msubsup" id="MJXp-Span-154"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-155" style="margin-right: 0.05em;">R</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-156" style="vertical-align: -0.4em;">t</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-13"> R_t </script>  لجميع الإجراءات 20،000 في سلسلة من 100 حلقة من اللعبة.  من الأفكار الجيدة جدًا تطبيع هذه القيم (طرح المتوسط ​​، القسمة على الانحراف المعياري) قبل توصيلها بخوارزمية backprop.  وبالتالي ، نشجع دائمًا ونشجع حوالي نصف الإجراءات التي تم تنفيذها.  هذا يقلل من التقلبات ويجعل السياسة أكثر تقاربا.  يمكن الاطلاع على دراسة أعمق على [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">link</a> ]. <br><br>  <b>مشتقة من وظيفة السياسة.</b>  أردت أيضًا أن أصف بإيجاز كيف يتم أخذ التدرجات الرياضية.  تدرجات وظيفة السياسة هي حالة خاصة لنظرية أكثر عمومية.  الحالة العامة هي أنه عندما يكون لدينا تعبير عن النموذج <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-157"><span class="MJXp-msubsup" id="MJXp-Span-158"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-159" style="margin-right: 0.05em;">E</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-160" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-161">x</span><span class="MJXp-mtext" id="MJXp-Span-162">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-163">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-165">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-166">p</span><span class="MJXp-mo" id="MJXp-Span-167">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-168">x</span><span class="MJXp-mtext" id="MJXp-Span-169">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-170">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-171">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-172">d</span><span class="MJXp-mtext" id="MJXp-Span-173">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-175">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-176">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-177">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-178">a</span><span class="MJXp-mo" id="MJXp-Span-179">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-180" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-181">f</span><span class="MJXp-mo" id="MJXp-Span-182" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-183">x</span><span class="MJXp-mo" id="MJXp-Span-184" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-185" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-14"> E_ {x \ sim p (x \ mid \ theta)} [f (x)] </script>  ، أي توقع بعض الوظائف العددية <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-186"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-187">f</span><span class="MJXp-mo" id="MJXp-Span-188" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-189">x</span><span class="MJXp-mo" id="MJXp-Span-190" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-15"> f (x) </script>  مع بعض توزيع المعلمة لها <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-191"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-192">p</span><span class="MJXp-mo" id="MJXp-Span-193" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-194">x</span><span class="MJXp-mrow" id="MJXp-Span-195"><span class="MJXp-mo" id="MJXp-Span-196" style="margin-left: 0.278em; margin-right: 0.278em;">؛</span></span><span class="MJXp-mtext" id="MJXp-Span-197">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-198">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-199">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-200">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-201">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-202">a</span><span class="MJXp-mo" id="MJXp-Span-203" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-16"> p (x؛ \ theta) </script>  معلمات من قبل بعض ناقلات <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-204"><span class="MJXp-mtext" id="MJXp-Span-205">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-206">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-207">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-208">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-209">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-210">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-17"> \ theta </script>  .  ثم <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-211"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-212">f</span><span class="MJXp-mo" id="MJXp-Span-213" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-214">x</span><span class="MJXp-mo" id="MJXp-Span-215" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-18-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-18"> f (x) </script>  سوف تصبح وظيفة المكافأة لدينا (أو وظيفة النفعية بمعنى أكثر عمومية) ، والتوزيع المنفصل <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-216"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-217">p</span><span class="MJXp-mo" id="MJXp-Span-218" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-219">x</span><span class="MJXp-mo" id="MJXp-Span-220" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-19-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-19"> p (x) </script>  ستكون سياستنا ، التي لديها بالفعل النموذج <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-221"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-222">p</span><span class="MJXp-mo" id="MJXp-Span-223" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-224">a</span><span class="MJXp-mtext" id="MJXp-Span-225">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-226">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-227">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-228">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-229">I</span><span class="MJXp-mo" id="MJXp-Span-230" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-20-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-20"> p (a \ mid I) </script>  إعطاء احتمالات اتخاذ إجراء للصورة <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-231"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-232">I</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-21-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-21"> I </script>  .  ثم نحن مهتمون بكيفية تحويل توزيع p من خلال معالمه <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-233"><span class="MJXp-mtext" id="MJXp-Span-234">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-235">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-236">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-237">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-238">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-239">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-22-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-22"> \ theta </script>  للتكبير <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-240"><span class="MJXp-mrow" id="MJXp-Span-241"><span class="MJXp-mo" id="MJXp-Span-242" style="margin-left: 0.278em; margin-right: 0.278em;">و</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-23-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-23"> و </script>  (أي كيف يمكننا تغيير إعدادات الشبكة حتى تحصل الإجراءات على مكافأة أعلى).  لدينا هذا: <br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-243"><span class="noError" id="MJXp-Span-244" style="display: inline-block;">\&nbsp;start&nbsp;{align}&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;E_x&nbsp;[f&nbsp;(x)]&nbsp;&amp;&nbsp;=&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;\&nbsp;sum_x&nbsp;p&nbsp;(x)&nbsp;f&nbsp;(x)&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{تعريف&nbsp;التوقع}&nbsp;\\&nbsp;&amp;&nbsp;=&nbsp;\&nbsp;sum_x&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;p&nbsp;(x)&nbsp;f&nbsp;(x)&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{مبادلة&nbsp;الجمع&nbsp;والتدرج}&nbsp;\\&nbsp;&amp;&nbsp;=&nbsp;\&nbsp;sum_x&nbsp;p&nbsp;(x)&nbsp;\&nbsp;frac&nbsp;{\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;p&nbsp;(x)}&nbsp;{p&nbsp;(x)}&nbsp;f&nbsp;(x)&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{الضرب&nbsp;والقسمة}}&nbsp;p&nbsp;(x)&nbsp;\\&nbsp;&amp;&nbsp;=&nbsp;\&nbsp;sum_x&nbsp;p&nbsp;(x)&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;\&nbsp;log&nbsp;p&nbsp;(x)&nbsp;f&nbsp;(x)&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{استخدم&nbsp;حقيقة&nbsp;أن&nbsp;\&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;\&nbsp;log&nbsp;(z)&nbsp;=&nbsp;\&nbsp;frac&nbsp;{1}&nbsp;{z}&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;z&nbsp;\\&nbsp;&amp;&nbsp;=&nbsp;E_x&nbsp;[f&nbsp;(x)&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;\&nbsp;log&nbsp;p&nbsp;(x)]&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{تعريف&nbsp;التوقع}&nbsp;\&nbsp;end&nbsp;{align}</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-24-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-24"> \ start {align} \ nabla _ {\ theta} E_x [f (x)] & = \ nabla _ {\ theta} \ sum_x p (x) f (x) & \ text {تعريف التوقع} \\ & = \ sum_x \ nabla _ {\ theta} p (x) f (x) & \ text {مبادلة الجمع والتدرج} \\ & = \ sum_x p (x) \ frac {\ nabla _ {\ theta} p (x)} {p (x)} f (x) & \ text {الضرب والقسمة}} p (x) \\ & = \ sum_x p (x) \ nabla _ {\ theta} \ log p (x) f (x) & \ text {استخدم حقيقة أن \ \ nabla _ {\ theta} \ log (z) = \ frac {1} {z} \ nabla _ {\ theta} z \\ & = E_x [f (x) \ nabla _ {\ theta} \ log p (x)] & \ text {تعريف التوقع} \ end {align} </script><br><br>  سأحاول شرح هذا.  لدينا بعض التوزيع <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-245"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-246">p</span><span class="MJXp-mo" id="MJXp-Span-247" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248">x</span><span class="MJXp-mrow" id="MJXp-Span-249"><span class="MJXp-mo" id="MJXp-Span-250" style="margin-left: 0.278em; margin-right: 0.278em;">؛</span></span><span class="MJXp-mtext" id="MJXp-Span-251">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-252">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-253">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-254">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-255">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-256">a</span><span class="MJXp-mo" id="MJXp-Span-257" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-25-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-25"> p (x؛ \ theta) </script>  (استخدمت الاختصار <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-258"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-259">p</span><span class="MJXp-mo" id="MJXp-Span-260" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-261">x</span><span class="MJXp-mo" id="MJXp-Span-262" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-26-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-26"> p (x) </script>  من خلالها يمكننا اختيار قيم محددة.  على سبيل المثال ، قد يكون توزيعًا غوسيًا منه عينات مولد رقم عشوائي.  لكل مثال ، يمكننا أيضًا حساب دالة التقدير <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-263"><span class="MJXp-mrow" id="MJXp-Span-264"><span class="MJXp-mo" id="MJXp-Span-265" style="margin-left: 0.278em; margin-right: 0.278em;">و</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-27-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-27"> و </script>  ، والتي وفقا للمثال الحالي يعطينا بعض التقدير العددية.  تخبرنا المعادلة الناتجة كيف ينبغي لنا أن نحول التوزيع من خلال معاييرها <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-266"><span class="MJXp-mtext" id="MJXp-Span-267">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-268">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-269">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-270">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-271">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-272">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-28-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-28"> \ theta </script>  إذا كنا نريد المزيد من الأمثلة على الإجراءات القائمة على ذلك للحصول على معدلات أعلى <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-273"><span class="MJXp-mrow" id="MJXp-Span-274"><span class="MJXp-mo" id="MJXp-Span-275" style="margin-left: 0.278em; margin-right: 0.278em;">و</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-29-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-29"> و </script>  .  نأخذ بعض الأمثلة على الإجراءات <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-276"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-277">x</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-30-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-30"> x </script>  وتقييمهم <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-278"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-279">f</span><span class="MJXp-mo" id="MJXp-Span-280" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-281">x</span><span class="MJXp-mo" id="MJXp-Span-282" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-31-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-31"> f (x) </script>  ، وأيضًا بالنسبة لكل x ، نقوم أيضًا بتقييم المصطلح الثاني <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-283"><span class="MJXp-mtext" id="MJXp-Span-284">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-285">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-286">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-287">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-288">l</span><span class="MJXp-msubsup" id="MJXp-Span-289"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-290" style="margin-right: 0.05em;">a</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-291" style="vertical-align: -0.4em;"><span class="MJXp-mtext" id="MJXp-Span-292">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-293">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-294">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-295">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-296">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-297">a</span></span></span><span class="MJXp-mtext" id="MJXp-Span-298">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-299">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-300">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-301">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-302">p</span><span class="MJXp-mo" id="MJXp-Span-303" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-304">x</span><span class="MJXp-mrow" id="MJXp-Span-305"><span class="MJXp-mo" id="MJXp-Span-306" style="margin-left: 0.278em; margin-right: 0.278em;">؛</span></span><span class="MJXp-mtext" id="MJXp-Span-307">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-308">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-309">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-310">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-311">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-312">a</span><span class="MJXp-mo" id="MJXp-Span-313" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-32-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-32"> \ nabla _ {\ theta} \ log p (x؛ \ theta) </script>  .  ما هو هذا المضاعف؟  هذا هو بالضبط المتجه - التدرج ، الذي يعطينا الاتجاه في مساحة المعلمة ، الأمر الذي سيؤدي إلى زيادة في احتمال إجراء معين <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-314"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-315">x</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-33-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-33"> x </script>  .  بمعنى آخر ، إذا دفعنا θ في الاتجاه <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-316"><span class="MJXp-mtext" id="MJXp-Span-317">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-318">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-319">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-320">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-321">l</span><span class="MJXp-msubsup" id="MJXp-Span-322"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-323" style="margin-right: 0.05em;">a</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-324" style="vertical-align: -0.4em;"><span class="MJXp-mtext" id="MJXp-Span-325">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-326">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-327">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-328">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-329">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-330">a</span></span></span><span class="MJXp-mtext" id="MJXp-Span-331">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-332">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-333">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-334">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-335">p</span><span class="MJXp-mo" id="MJXp-Span-336" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-337">x</span><span class="MJXp-mrow" id="MJXp-Span-338"><span class="MJXp-mo" id="MJXp-Span-339" style="margin-left: 0.278em; margin-right: 0.278em;">؛</span></span><span class="MJXp-mtext" id="MJXp-Span-340">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-341">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-342">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-343">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-344">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-345">a</span><span class="MJXp-mo" id="MJXp-Span-346" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-34-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-34"> \ nabla _ {\ theta} \ log p (x؛ \ theta) </script>  ، سنرى أن الاحتمال الجديد لهذا الإجراء سيزداد قليلاً.  إذا نظرت إلى الوراء في الصيغة ، فإنها تخبرنا أنه ينبغي لنا أن نأخذ هذا الاتجاه ونضرب القيمة العددية به <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-347"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-348">f</span><span class="MJXp-mo" id="MJXp-Span-349" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-350">x</span><span class="MJXp-mo" id="MJXp-Span-351" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-35-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-35"> f (x) </script>  .  سيضمن هذا أن "الإجراءات" ذات التصنيف الأعلى (في حالتنا ، المكافأة) سوف "تجتذب" بقوة أكبر من الأمثلة ذات المؤشر الأقل ، وبالتالي ، إذا أردنا التحديث استنادًا إلى عدة عينات من <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-352"><span class="MJXp-mrow" id="MJXp-Span-353"><span class="MJXp-mo" id="MJXp-Span-354" style="margin-left: 0.278em; margin-right: 0.278em;">ع</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-36-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-36"> ع </script>  ، ستتحول الكثافة الاحتمالية إلى نقاط لعبة أعلى نتيجة ، مما يزيد من احتمال وجود أمثلة أكشن عالية المكافأة.  من المهم أن التدرج لا يؤخذ من الوظيفة <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-355"><span class="MJXp-mrow" id="MJXp-Span-356"><span class="MJXp-mo" id="MJXp-Span-357" style="margin-left: 0.278em; margin-right: 0.278em;">و</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-37-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-37"> و </script>  ، لأنه يمكن أن يكون عموما غير متمايزة وغير متوقعة.  أ <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-358"><span class="MJXp-mrow" id="MJXp-Span-359"><span class="MJXp-mo" id="MJXp-Span-360" style="margin-left: 0.278em; margin-right: 0.278em;">ع</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-38-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-38"> ع </script>  يمكن تمييزها بواسطة <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-361"><span class="MJXp-mtext" id="MJXp-Span-362">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-363">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-364">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-365">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-366">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-367">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-39-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-39"> \ theta </script>  .  هذا هو <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-368"><span class="MJXp-mrow" id="MJXp-Span-369"><span class="MJXp-mo" id="MJXp-Span-370" style="margin-left: 0.278em; margin-right: 0.278em;">ع</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-40-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-40"> ع </script>  هو توزيع منفصل قابل للتعديل بشكل مستمر ، حيث يمكنك ضبط احتمالات الإجراءات الفردية.  نحن نفترض ذلك أيضا <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-371"><span class="MJXp-mrow" id="MJXp-Span-372"><span class="MJXp-mo" id="MJXp-Span-373" style="margin-left: 0.278em; margin-right: 0.278em;">ع</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-41-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-41"> ع </script>  تطبيع. <br><br><img src="https://habrastorage.org/webt/xo/qy/9p/xoqy9pzjvy4d3sxosr_irpasic4.png"><br><br>  <i>التصور التدرج.</i>  <i>يسار: توزيع غاوسي وعدة أمثلة منه (النقاط الزرقاء).</i>  <i>في كل نقطة زرقاء ، نقوم أيضًا برسم تدرج الاحتمال اللوغاريتمي فيما يتعلق بالمعلمة المتوسطة.</i>  <i>يشير السهم إلى الاتجاه الذي ينبغي فيه تحويل متوسط ​​قيمة التوزيع لزيادة احتمالية هذا الإجراء المثال.</i>  <i>في المنتصف: أضيفت بعض وظائف التقييم التي تعطي -1 في كل مكان باستثناء +1 في بعض المناطق الصغيرة (لاحظ أن هذا يمكن أن يكون دالة عددية تعسفية وليس بالضرورة قابلة للتمييز).</i>  <i>أصبحت الأسهم الآن مشفرة بالألوان ، نظرًا للضرب ، سنقوم بتقييم كل الأسهم الخضراء بتصنيف إيجابي والسهام الحمراء السلبية.</i>  <i>إلى اليمين: بعد تحديث المعلمات ، تدفعنا الأسهم الخضراء والسهام الحمراء المقلوبة إلى اليسار وإلى الأسفل.</i>  <i>ستحصل الآن عينات من هذا التوزيع على تصنيف متوقع أعلى ، إذا رغبت في ذلك.</i> <br><br>  آمل أن يكون الاتصال بـ RL واضحًا.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">تعطينا سياستنا أمثلة على الإجراءات ، وبعضها يعمل بشكل أفضل من الآخرين (وفقًا لمهمة النفعية). تتمثل طريقة تغيير إعدادات السياسة في التشغيل ، واتخاذ تدرج الإجراءات المحددة ، واضربها في التصنيف وأضف كل ما فعلناه أعلاه. لاستنتاج أكثر شمولاً ، أوصي بمحاضرة </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">لجون شولمان. </font></font><br></a> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">التدريب.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> حسنًا ، قمنا بتطوير مبادئ التدرجات لوظيفة السياسة. لقد طبقت المنهج بالكامل في </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">نص بيثون</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> مكون من </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;">130 سطرًا</font></a><font style="vertical-align: inherit;"> يستخدم محاكي ATAI 2600 Pong </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;">الجاهزة</font></a><font style="vertical-align: inherit;"> من </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenAI Gym</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. قمت بتدريب شبكة عصبية مكونة من طبقتين مع 200 خلية عصبية مخفية باستخدام خوارزمية RMSProp لسلسلة من 10 حلقات (كل حلقة ، وفقًا للقواعد ، تتكون من عدة كرات تعادل وتستمر الحلقة في تسجيل 21). لم أقم بإعداد المعلمات المفرطة بشكل مفرط وقمت بتجربة تطبيق Macbook البطيء ، لكن بعد تمرين استمر ثلاثة أيام ، حصلت على سياسة أفضل قليلاً من المشغل المدمج. كان العدد الإجمالي للحلقات حوالي 8000 ، لذلك لعبت الخوارزمية ما يقرب من 200000 لعبة بونغ ، وهو عدد كبير جدًا ، وأنتجت ما مجموعه 800 تحديثًا تقريبًا للأوزان. إذا كنت قد تدربت على GPU باستخدام ConvNets ، فعندئذٍ في غضون بضعة أيام ، سأحقق نتائج رائعة ، وإذا قمت بتحسين المعلمات الفائقة ، فستتمكن دائمًا من الفوز. ومع ذلك ، لم أقضي الكثير من الوقت في الحوسبة أو الإعداد ،بدلاً من ذلك ، حصلنا على Pong AI ، والتي توضح الأفكار الرئيسية وتعمل بشكل جيد:</font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><img src="https://habrastorage.org/webt/cf/gf/jr/cfgfjrkzt_awy-l7f5lcxcrfvki.png"></a> <br> <i>  .      </i> <br><br> <b> .</b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">يمكننا أيضًا إلقاء نظرة على الأوزان التي تم الحصول عليها من الشبكة العصبية. بفضل المعالجة المسبقة ، كل صورة من مدخلاتنا هي صورة فرق 80 × 80 (الإطار الحالي ناقص الإطار السابق). يتم توصيل كل خلية عصبية من الطبقة W1 بطبقة مخفية W2 تتكون من 200 خلية عصبية. عدد السندات 80 * 80 * 200. دعنا نحاول تحليل هذه الروابط. سنقوم بفرز جميع الخلايا العصبية لطبقة W2 وتصور الأوزان التي تؤدي إليها. من المقاييس التي تؤدي إلى خلية واحدة من الخلايا العصبية W2 من الخلايا العصبية W1 ، سنقوم بتصوير 80 × 80 صورة. فيما يلي 40 صورة من هذه الصور لـ W2 (أي ما مجموعه 200). البيكسلات البيضاء هي أوزان موجبة ، والأسود سالبة. لاحظ أن العديد من الخلايا العصبية W2 يتم ضبطها على الكرة الطائرة المشفرة في خطوط متقطعة. في اللعبة ، يمكن أن تكون الكرة في مكان واحد فقط ،لذلك ، هذه الخلايا العصبية متعددة الأغراض وسوف "تطلق النار" إذا كانت الكرة في مكان ما داخل هذه الخطوط. يعد التناوب بين الأسود والأبيض أمرًا مثيرًا للاهتمام ، لأنه عندما تتحرك الكرة على طول المسار ، يتقلب نشاط الخلايا العصبية مثل موجة جيبية. وبسبب ReLU ، وقال انه "اطلاق النار" فقط في بعض المواقف. هناك الكثير من الضوضاء في الصور ، والتي ستكون أقل إذا كنت تستخدم L2 التنظيم.</font></font><br><br><img src="https://habrastorage.org/webt/1t/n4/le/1tn4lew2rszryk1u9vkbreigku4.png"><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ما لا يحدث.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> لذلك ، تعلمنا كيفية لعب كرة الطاولة على الصور باستخدام تدرج وظيفة السياسة ، وهذا يعمل بشكل جيد. هذا النهج عبارة عن نموذج "اقتراح وتحقق" غريب ، حيث يشير مصطلح "تخمين" إلى تشغيل سياستنا على عدة حلقات من اللعبة ، ويشجع "التحقق" الإجراءات التي تؤدي إلى نتائج جيدة. بشكل عام ، يمثل هذا المستوى الحالي لكيفية تعاملنا حاليًا مع مشاكل التعلم المعزز. إذا كنت تفهم الخوارزمية بشكل حدسي وتعرف كيف تعمل ، فيجب أن تشعر بخيبة أمل على الأقل. على وجه الخصوص ، متى لا يعمل؟</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">قارن هذا بالطريقة التي يمكن أن يتعلم بها الشخص لعب كرة الطاولة. أنت نفسك تبين لهم اللعبة ويقولون شيئًا مثل: "يمكنك التحكم في المضرب ، ويمكنك تحريكه للأعلى وللأسفل ، ومهمتك هي رمي الكرة خلف لاعب آخر يتحكم فيه البرنامج المدمج" ، وتكون جاهزًا للذهاب. يرجى ملاحظة بعض الاختلافات:</font></font><br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">         - , ,   ,     .     RL       ,        .       ,        (        ),       ,  .         .   ,          ,  ,  ,   ,            , ,   ,  . <br></li><li style=";text-align:right;direction:rtl">      ,     ( ,    ,     ,      ..),    ( «» « ,  , ,    -  -  . .).      «»          / . ,     ,    (   )   (      ,    ). <br></li><li style=";text-align:right;direction:rtl">    —    (brute force),            ,       .              .       ,    ,           ,      .   ,     «»    ,        .   ,    ,         . <br></li><li style=";text-align:right;direction:rtl">        ,    ,     .    ,             ,      .           . <br></li></ul><br><img src="https://habrastorage.org/webt/do/4a/ha/do4ahazbavg7xmlq-a5omrr77vq.png"><br><br> <i>:  :      RL.   ,  ,     .  ,    .     ,  99%        .  ,  «»   . :       «»,    ,  - , -  , -  ,     ,     .                 « ,      ».</i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أود أيضًا أن أؤكد على حقيقة أن تدرج السياسة في العديد من الألعاب سيهزم شخصًا بسهولة. على وجه الخصوص ، ينطبق هذا على الألعاب ذات المكافآت المتكررة ، والتي تتطلب رد فعل دقيق وسريع وبدون تخطيط طويل الأجل. يمكن بسهولة رؤية الارتباطات قصيرة المدى بين المكافآت والإجراءات من خلال نهج PG. يمكنك أن ترى مماثلة في وكيلنا بونغ. يطور إستراتيجية عندما ينتظر ببساطة الكرة ، ثم يتحرك بسرعة للقبض عليه فقط عند الحافة ذاتها ، بسبب ارتداد الكرة بسرعة عمودية عالية. يربح الوكيل عدة انتصارات متتالية ، مكرراً هذه الإستراتيجية البسيطة. هناك العديد من الألعاب (Pinball ، Breakout) التي تجذب فيها لعبة Deep Q-Learning وتدوس شخصًا في الوحل بإجراءاتها البسيطة والدقيقة.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بمجرد فهم "الخدعة" التي تعمل بها هذه الخوارزميات ، يمكنك فهم نقاط القوة والضعف فيها. على وجه الخصوص ، هذه الخوارزميات متخلفة عن الأشخاص في بناء أفكار مجردة عن الألعاب التي يمكن للناس استخدامها للتعلم السريع. بمجرد أن ينظر الكمبيوتر إلى صفيف البيكسلات ويلاحظ المفتاح ، فإن الباب يفكر في نفسه أنه من المحتمل أن يكون من الجيد أخذ المفتاح والوصول إلى الباب. لا يوجد شيء قريب من هذا في الوقت الحالي ، ومحاولة الوصول إلى هناك مجال نشط للبحث. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">حسابات غير قابلة للتمييز في الشبكات العصبية.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أود أن أذكر تطبيقًا آخر مثيرًا للاهتمام لمتدرجات سياسة عدم اللعب: فهو يسمح لنا بتصميم وتدريب الشبكات العصبية باستخدام مكونات تؤدي (أو تتفاعل) مع الحوسبة غير القابلة للتمييز. قدمت هذه الفكرة لأول مرة في </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">عام 1992 من قبل ويليامز</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . وقد تم نشره مؤخرًا في </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">نماذج الاهتمام البصري المتكررة.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">يُسمى "عن كثب" في سياق نموذج يقوم بمعالجة صورة بتسلسل من الأشكال الضيقة المنخفضة الدقة النقية ، على غرار طريقة فحص عيننا للكائنات ذات الرؤية المركزية الجارية. في كل تكرار ، ستتلقى RNN جزءًا صغيرًا من الصورة وتحديد الموقع الذي يحتاج إلى مزيد من البحث. على سبيل المثال ، يمكن أن ينظر RNN إلى الموضع (5.30) ، ويحصل على جزء صغير من الصورة ، ثم يقرر النظر إلى (24 ، 50) ، وما إلى ذلك. هناك قسم من الشبكة العصبية يختار أن ينظر فيها إلى أبعد من ذلك ، ثم يفحصها. لسوء الحظ ، هذه العملية ليست مختلفة ، لأننا لا نعرف ماذا سيحدث إذا أخذنا عينة في مكان آخر. في حالة أكثر عمومية ، فكر في شبكة عصبية لها عدة مدخلات ومخرجات:</font></font><br><br><img src="https://habrastorage.org/webt/xn/gn/ca/xngncauic38rgmg3bi_srnlevbw.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">لاحظ أن معظم الأسهم الزرقاء مختلفة كالمعتاد ، ولكن قد تتضمن بعض تحويلات العرض أيضًا عملية تحديد غير متمايزة ، والتي يتم تمييزها باللون الأحمر. يمكننا فقط المرور عبر الأسهم الزرقاء في الاتجاه المعاكس ، لكن السهم الأحمر هو تبعية لا يمكننا من خلالها عكس اتجاه backprop.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">سياسة التدرج لانقاذ! دعونا نفكر في جزء الشبكة الذي يقوم بأخذ العينات التي يمكن تمثيلها كدالة للسياسة العشوائية المضمنة في شبكة عصبية كبيرة. لذلك ، أثناء التدريب ، سنقدم العديد من الأمثلة (المشار إليها بواسطة الفروع أدناه) ، ثم سنشجع العينات التي تؤدي في النهاية إلى نتائج جيدة (في هذه الحالة ، على سبيل المثال ، تقاس بالخسائر في النهاية). بمعنى آخر ، سنقوم بتدريب المعلمات المضمّنة في الأسهم الزرقاء باستخدام backprop ، كالمعتاد ، ولكن سيتم الآن تحديث المعلمات المضمّنة في السهم الأحمر بغض النظر عن المسار العكسي باستخدام تدرجات السياسة ، مما يشجع العينات التي تؤدي إلى خسائر منخفضة. كانت هذه الفكرة مؤطرة بشكل جيد مؤخرًا.</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">تقدير التدرج باستخدام الرسوم البيانية لحساب الاستوكاستك.</font></font></a> <br><br><img src="https://habrastorage.org/webt/td/vx/lr/tdvxlrd98jepxgmsvpc5gtewlxs.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> مدخلات الإدخال / الإخراج في ذاكرة الوصول العشوائي. سوف تجد هذه الفكرة أيضًا في العديد من المقالات الأخرى. على سبيل المثال ، </font><font style="vertical-align: inherit;">تحتوي </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">آلة Neural Turing</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> على شريط ذاكرة يقرأون ويكتبون به. لتنفيذ عملية الكتابة ، تحتاج إلى القيام بشيء مثل m [i] = x ، حيث يتم التنبؤ i و x بواسطة الشبكة العصبية RNN. ومع ذلك ، لا توجد إشارة تخبرنا بما يمكن أن يحدث لوظيفة الخسارة إذا كتبنا j! = I. لذلك ، يمكن لـ NTM إجراء عمليات قراءة وكتابة ناعمة. يتنبأ بوظيفة توزيع الانتباه a ، ثم ينفذ لجميع i: m [i] = a [i] * x. أصبح الأمر مختلفًا الآن ، لكن علينا أن ندفع ثمنًا حسابيًا مرتفعًا ، حيث يتم فرز جميع الخلايا.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ومع ذلك ، يمكننا استخدام تدرجات السياسة للتعامل مع هذه المشكلة من الناحية النظرية ، كما هو الحال في </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RL-NTM</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. ما زلنا نتوقع توزيع الانتباه (أ) ، ولكن بدلاً من البحث الشامل ، نختار أماكن للكتابة عشوائيًا: i = sample (a)؛ م [i] = س. أثناء التدريب ، يمكننا القيام بذلك لمجموعة صغيرة من i ، وفي النهاية ، سوف نجد مجموعة من شأنها أن تعمل بشكل أفضل من غيرها. ميزة حسابية كبيرة هي أنه أثناء الاختبار يمكنك القراءة / الكتابة من خلية واحدة. ومع ذلك ، كما هو موضح في المستند ، من الصعب جدًا الوصول إلى هذه الاستراتيجية ، لأنك بحاجة إلى استعراض العديد من الخيارات والذهاب إلى خوارزميات العمل تقريبًا عن طريق الخطأ. يوافق الباحثون حاليًا على أن PG يعمل جيدًا فقط عندما يكون هناك العديد من الخيارات المنفصلة ، عندما لا تحتاج إلى التمشيط عبر مساحات بحث ضخمة.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ومع ذلك ، بمساعدة تدرجات السياسة ، وفي الحالات التي يتوفر فيها قدر كبير من البيانات وقوة الحوسبة ، يمكننا أن نحلم كثيرًا. على سبيل المثال ، يمكننا تصميم الشبكات العصبية التي تتعلم التفاعل مع الكائنات الكبيرة غير القابلة للتمييز ، مثل المجمعين اللاتكس. على سبيل المثال ، لكي يقوم char-rnn بإنشاء كود Latex جاهز ، أو نظام SLAM ، أو حل LQR ، أو أي شيء آخر. أو ، على سبيل المثال ، قد ترغب الذكاء الخارق في معرفة كيفية التفاعل مع الإنترنت عبر TCP / IP (وهو أيضًا غير قابل للتمييز) للوصول إلى المعلومات الضرورية لالتقاط العالم. هذا مثال رائع.</font></font><br><br><h4 style=";text-align:right;direction:rtl">  الاستنتاجات </h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">لقد رأينا أن تدرجات السياسة عبارة عن خوارزمية عامة قوية ، وكمثال على ذلك ، قمنا بتدريب وكيل ATARI Pong من وحدات البكسل الخام من نقطة الصفر في </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">130 سطر Python</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . بشكل عام ، يمكن استخدام نفس الخوارزمية لتدريب الوكلاء على الألعاب التعسفية ، ونأمل ، في يوم ما ، أن نستخدمها لحل مشكلات التحكم في العالم الحقيقي. في الختام ، أود أن أضيف بعض التعليقات الإضافية: </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">حول تطوير الذكاء الاصطناعى</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. لقد رأينا أن الخوارزمية تعمل عن طريق البحث عن القوة الغاشمة ، والتي تتفاعل فيها بشكل عشوائي أولاً ويتعين عليك التعثر في المواقف المفيدة مرة واحدة على الأقل ، وغالبًا ما يتم ذلك ، قبل أن تغير وظيفة السياسة معالمها. ورأينا أيضًا أن الشخص يتعامل مع هذه الحلول لهذه المشكلات بطريقة مختلفة تمامًا ، والتي تشبه الإنشاء السريع لنموذج تجريدي. نظرًا لأن هذه النماذج التجريدية صعبة للغاية (إن لم يكن من المستحيل) تخيلها بشكل صريح ، فإن هذا هو السبب أيضًا في وجود اهتمام كبير في الآونة الأخيرة بالنماذج التوليفية وتحريض البرامج. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">حول استخدامها في الروبوتات.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">لا تنطبق الخوارزمية حيث يكون من الصعب الحصول على قدر كبير من الأبحاث. على سبيل المثال ، يمكن أن يكون لديك روبوت واحد (أو عدة) يتفاعل مع العالم في الوقت الفعلي. هذا لا يكفي لتطبيق ساذج من الخوارزمية. يتمثل أحد مجالات العمل المصممة للتخفيف من هذه المشكلة في </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">التدرجات السياسية الحتمية</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . بدلاً من القيام بمحاولات حقيقية ، يحصل هذا النهج على معلومات متدرجة من شبكة عصبية ثانية (تسمى الناقد) تقوم بنمذجة وظيفة التقييم. يمكن لهذا النهج ، من حيث المبدأ ، أن يكون فعالًا مع الإجراءات عالية الأبعاد ، حيث توفر العينة العشوائية تغطية ضعيفة. هناك طريقة أخرى ذات صلة وهي زيادة الروبوتات التي بدأنا نراها في </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Robot Farm</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أو ربما حتى على </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">تسلا S + مع الطيار الآلي.</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> هناك أيضًا خط عمل يحاول جعل عملية البحث أقل ميؤوس منها بإضافة تحكم إضافي. على سبيل المثال ، في العديد من الحالات العملية ، يمكنك الحصول على الاتجاه الأولي للتنمية مباشرة من الشخص. على سبيل المثال، </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlphaGo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> تشرف عليها الاستخدامات الأولى تعلم فقط استباق الإجراءات الشخص (مثل </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">التحكم عن بعد من الروبوتات</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ، </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">التلمذة</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ، </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">تحسين المسار المنحنى</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ، </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">سياسة بحث شاملة</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). ثم تم تكوين السياسة الناتجة باستخدام PG لتحقيق الهدف الحقيقي - الفوز باللعبة.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">في بعض الحالات ، قد يكون هناك عدد أقل من الإعدادات المسبقة (على سبيل المثال ، </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">للتحكم عن بعد في الروبوتات</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) ، وتوجد طرق لاستخدام هذه البيانات </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">قبل التدريب</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . أخيرًا ، إذا لم يقدم الأشخاص بيانات أو إعدادات محددة ، فيمكن الحصول عليها في بعض الحالات عن طريق الحساب باستخدام طرق تحسين باهظة الثمن إلى حد ما ، على سبيل المثال ، عن طريق </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">تحسين المسار</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> في نموذج ديناميكي معروف (مثل F = ma في محاكي مادي) أو في حالات عند إنشاء نموذج محلي تقريبي (كما هو موضح في بنية واعدة جدًا للبحث في السياسة المدارة). </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">حول استخدام PG في الممارسة العملية.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أود التحدث أكثر حول RNN. أعتقد أنه قد يبدو أن RNNs سحرية وتقوم تلقائيًا بحل المشكلات المتعلقة بالتسلسل التعسفي. والحقيقة هي أن الحصول على هذه النماذج للعمل يمكن أن يكون خادعا. مطلوب العناية والخبرة ، وكذلك معرفة متى يمكن أن تساعدك الأساليب الأكثر بساطة بنسبة 90٪. الشيء نفسه ينطبق على التدرجات السياسة. إنها لا تعمل تلقائيًا تمامًا مثل ذلك: تحتاج إلى العديد من الأمثلة ، ويمكن أن تتدرب إلى الأبد ، ومن الصعب تصحيحها عندما لا تعمل. يجب أن تحاول دائمًا إطلاق النار من مسدس صغير قبل الوصول إلى بازوكا. على سبيل المثال ، في حالة التدريب على التعزيز ، يجب دائمًا التحقق من </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;">طريقة الإنتروبيا (CEM)</font></a><font style="vertical-align: inherit;"> أولاً.</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، أسلوب "تخمين وتحقق" العشوائي البسيط المستوحى من التطور. وإذا كنت تصر على تجربة التدرجات السياسية لمهمتك ، فتأكد من معرفة الحيل المحددة. ابدأ بالبساطة واستخدم خيار PG يسمى </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TRPO</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ، والذي يعمل دائمًا بشكل أفضل وأكثر تناسقًا </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">من PG الكلاسيكي</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . الفكرة الأساسية هي تجنب تحديث الإعدادات التي تغير سياستك أكثر من اللازم ، بسبب استخدام مسافة Kulbak-Leibler بين السياسة القديمة والسياسة الجديدة.</font></font><br><br>  هذا كل شئ!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">آمل أن أكون قد قدمت لك فكرة عن مكاننا مع Reinforcement Learning ، ما هي المشاكل ، وإذا كنت ترغب في المساعدة في الترويج لـ RL ، أدعوك للقيام بذلك في </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenAI Gym</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :) أراك في المرة القادمة!</font></font><br><br><hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أندريه كارباثي ، </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">باحث ومطور ومدير قسم الذكاء الاصطناعي والطيار الآلي تسلا. </font></font><br><br> <i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">معلومات إضافية:</font></font></b> <font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> دورة </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">التعلم العميق على الأصابع 2018 </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://habr.com/ar/post/414165/</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> دورة </font><font style="vertical-align: inherit;">التعلم العميق على الأصابع </font><font style="vertical-align: inherit;">المفتوحة 2019 </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https: // habr.com/ru/company/ods/blog/438940/</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> كلية الفيزياء في NSU </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://www.phys.nsu.ru/</font></font></a></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar439674/">https://habr.com/ru/post/ar439674/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar439662/index.html">الإعلان عن TypeScript 3.3</a></li>
<li><a href="../ar439664/index.html">توافق ثنائي C ++ و ترقيات خالية من الألم إلى Visual Studio 2019</a></li>
<li><a href="../ar439668/index.html">توسيع نطاق النشرة الإخبارية للتكنولوجيا إلى 700 ألف مشترك في 300 مدينة: تاريخ بدء تشغيل Techstars Digest</a></li>
<li><a href="../ar439670/index.html">الروسية AI- نظام لتشخيص السرطان Botkin.AI. الآن في سوق أزور</a></li>
<li><a href="../ar439672/index.html">أساسيات PowerShell: اكتشاف ما إذا كانت السلسلة تنتهي بحرف معين</a></li>
<li><a href="../ar439676/index.html">تتفاعل الأصلية والتكامل C ++ لنظام التشغيل iOS و Android</a></li>
<li><a href="../ar439678/index.html">يقدم للتحدي F # التطبيقي</a></li>
<li><a href="../ar439680/index.html">حوالي 50 ٪ من الروس على استعداد لبيع بياناتهم الشخصية</a></li>
<li><a href="../ar439682/index.html">تدريب Cisco 200-125 CCNA v3.0. أخصائي شبكات سيسكو المعتمد (CCNA). يوم 4. أجهزة البوابة</a></li>
<li><a href="../ar439684/index.html">التقدم بطلب للحصول على تحدي F # التطبيقي</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
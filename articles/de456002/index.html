<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💋 👩🏼‍🤝‍👨🏿 🎉 Spezielles Herdgedächtnis und OOM Killer-Intervention 🤳 🧕🏿 👩🏾‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo nochmal! Die Übersetzung des nächsten Artikels wurde speziell für Studenten des Kubernetes-basierten Infrastructure Platform- Kurses vorbereitet...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spezielles Herdgedächtnis und OOM Killer-Intervention</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/456002/">  Hallo nochmal!  Die Übersetzung des nächsten Artikels wurde speziell für Studenten des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes-basierten Infrastructure Platform-</a> Kurses vorbereitet, der diesen Monat beginnt. Beginnen wir. <br><br><img src="https://habrastorage.org/webt/uv/io/fj/uviofjoh-y_arqntutialytzgcs.png"><br><br>  In den letzten Tagen sind einige meiner Pods ständig abgestürzt und haben im Betriebssystemprotokoll einen Hinweis hinterlassen, dass OOM Killer den Containerprozess zerstört hat.  Ich beschloss herauszufinden, warum dies geschieht. <a name="habracut"></a><br><br><h2>  Speicherlimit für Herd und Speichereinstellungen für Gruppen </h2><br>  Testen wir die K3s-Distribution.  Wir erstellen unter mit einer charakteristischen Speichergrenze von 123 MiB (123 Mi). <br><br><pre><code class="go hljs">kubectl run --restart=Never --rm -it --image=ubuntu --limits=<span class="hljs-string"><span class="hljs-string">'memory=123Mi'</span></span> -- sh If you don<span class="hljs-string"><span class="hljs-string">'t see a command prompt, try pressing enter. root@sh:/#</span></span></code> </pre> <br>  Finden Sie in einer anderen Konsole die <code>uid</code> Herdes heraus. <br><br><pre> <code class="go hljs">kubectl get pods sh -o yaml | grep uid uid: bc001ffa<span class="hljs-number"><span class="hljs-number">-68f</span></span>c<span class="hljs-number"><span class="hljs-number">-11e9</span></span><span class="hljs-number"><span class="hljs-number">-92d</span></span>7<span class="hljs-number"><span class="hljs-number">-5</span></span>ef9efd9374c</code> </pre> <br>  Auf dem Server, unter dem es ausgeführt wird, ermitteln wir die <code>cgroup</code> Parameter, indem wir die <code>uid</code> gewünschten Pods <code>uid</code> . <br><br><pre> <code class="go hljs">cd /sys/fs/cgroup/memory/kubepods/burstable/podbc001ffa<span class="hljs-number"><span class="hljs-number">-68f</span></span>c<span class="hljs-number"><span class="hljs-number">-11e9</span></span><span class="hljs-number"><span class="hljs-number">-92d</span></span>7<span class="hljs-number"><span class="hljs-number">-5</span></span>ef9efd9374c cat memory.limit_in_bytes <span class="hljs-number"><span class="hljs-number">128974848</span></span></code> </pre> <br>  128974848 ist genau 123 MiB (123 * 1024 * 1024).  Die Situation klärt sich auf.  Es stellt sich heraus, dass in Kubernetes das Speicherlimit über cgroup festgelegt wird.  Sobald mehr als das zugewiesene Speicherlimit erreicht ist, leitet cgroup die Zerstörung des Containerprozesses ein. <br><br><h2>  Stresstest </h2><br>  Lassen Sie uns Dienstprogramme zum Stresstest des Herdes über eine offene Befehlskonsolensitzung installieren. <br><br><pre> <code class="go hljs">root@sh:/# apt update; apt install -y stress</code> </pre> <br>  Gleichzeitig verfolgen wir Syslog-Einträge mit dem <code>dmesg -Tw</code> . <br><br>  Führen Sie zunächst das Stresstest-Dienstprogramm aus und weisen Sie 100 MB Speicher zu.  Der Prozess wurde erfolgreich gestartet. <br><br><pre> <code class="go hljs">root@sh:/# stress --vm <span class="hljs-number"><span class="hljs-number">1</span></span> --vm-bytes <span class="hljs-number"><span class="hljs-number">100</span></span>M &amp; [<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">271</span></span> root@sh:/# stress: info: [<span class="hljs-number"><span class="hljs-number">271</span></span>] dispatching hogs: <span class="hljs-number"><span class="hljs-number">0</span></span> cpu, <span class="hljs-number"><span class="hljs-number">0</span></span> io, <span class="hljs-number"><span class="hljs-number">1</span></span> vm, <span class="hljs-number"><span class="hljs-number">0</span></span> hdd</code> </pre> <br>  Jetzt werden wir den zweiten Stresstest durchführen. <br><br><pre> <code class="go hljs">root@sh:/# stress --vm <span class="hljs-number"><span class="hljs-number">1</span></span> --vm-bytes <span class="hljs-number"><span class="hljs-number">50</span></span>M stress: info: [<span class="hljs-number"><span class="hljs-number">273</span></span>] dispatching hogs: <span class="hljs-number"><span class="hljs-number">0</span></span> cpu, <span class="hljs-number"><span class="hljs-number">0</span></span> io, <span class="hljs-number"><span class="hljs-number">1</span></span> vm, <span class="hljs-number"><span class="hljs-number">0</span></span> hdd stress: FAIL: [<span class="hljs-number"><span class="hljs-number">271</span></span>] (<span class="hljs-number"><span class="hljs-number">415</span></span>) &lt;-- worker <span class="hljs-number"><span class="hljs-number">272</span></span> got signal <span class="hljs-number"><span class="hljs-number">9</span></span> stress: WARN: [<span class="hljs-number"><span class="hljs-number">271</span></span>] (<span class="hljs-number"><span class="hljs-number">417</span></span>) now reaping child worker processes stress: FAIL: [<span class="hljs-number"><span class="hljs-number">271</span></span>] (<span class="hljs-number"><span class="hljs-number">451</span></span>) failed run completed in <span class="hljs-number"><span class="hljs-number">7s</span></span></code> </pre> <br>  Der Start führte zur sofortigen Zerstörung des Prozesses des ersten Stresstests (PID 271) bei Signal 9. <br><br>  In der Zwischenzeit wurden folgende Einträge im Systemprotokoll angezeigt: <br><br> <code>[Sat Apr 27 22:56:09 2019] stress invoked oom-killer: gfp_mask=0x14000c0(GFP_KERNEL), nodemask=(null), order=0, oom_score_adj=939 <br> [Sat Apr 27 22:56:09 2019] stress cpuset=a2ed67c63e828da3849bf9f506ae2b36b4dac5b402a57f2981c9bdc07b23e672 mems_allowed=0 <br> [Sat Apr 27 22:56:09 2019] CPU: 0 PID: 32332 Comm: stress Not tainted 4.15.0-46-generic #49-Ubuntu <br> [Sat Apr 27 22:56:09 2019] Hardware name: BHYVE, BIOS 1.00 03/14/2014 <br> [Sat Apr 27 22:56:09 2019] Call Trace: <br> [Sat Apr 27 22:56:09 2019] dump_stack+0x63/0x8b <br> [Sat Apr 27 22:56:09 2019] dump_header+0x71/0x285 <br> [Sat Apr 27 22:56:09 2019] oom_kill_process+0x220/0x440 <br> [Sat Apr 27 22:56:09 2019] out_of_memory+0x2d1/0x4f0 <br> [Sat Apr 27 22:56:09 2019] mem_cgroup_out_of_memory+0x4b/0x80 <br> [Sat Apr 27 22:56:09 2019] mem_cgroup_oom_synchronize+0x2e8/0x320 <br> [Sat Apr 27 22:56:09 2019] ? mem_cgroup_css_online+0x40/0x40 <br> [Sat Apr 27 22:56:09 2019] pagefault_out_of_memory+0x36/0x7b <br> [Sat Apr 27 22:56:09 2019] mm_fault_error+0x90/0x180 <br> [Sat Apr 27 22:56:09 2019] __do_page_fault+0x4a5/0x4d0 <br> [Sat Apr 27 22:56:09 2019] do_page_fault+0x2e/0xe0 <br> [Sat Apr 27 22:56:09 2019] ? page_fault+0x2f/0x50 <br> [Sat Apr 27 22:56:09 2019] page_fault+0x45/0x50 <br> [Sat Apr 27 22:56:09 2019] RIP: 0033:0x558182259cf0 <br> [Sat Apr 27 22:56:09 2019] RSP: 002b:00007fff01a47940 EFLAGS: 00010206 <br> [Sat Apr 27 22:56:09 2019] RAX: 00007fdc18cdf010 RBX: 00007fdc1763a010 RCX: 00007fdc1763a010 <br> [Sat Apr 27 22:56:09 2019] RDX: 00000000016a5000 RSI: 0000000003201000 RDI: 0000000000000000 <br> [Sat Apr 27 22:56:09 2019] RBP: 0000000003200000 R08: 00000000ffffffff R09: 0000000000000000 <br> [Sat Apr 27 22:56:09 2019] R10: 0000000000000022 R11: 0000000000000246 R12: ffffffffffffffff <br> [Sat Apr 27 22:56:09 2019] R13: 0000000000000002 R14: fffffffffffff000 R15: 0000000000001000 <br> [Sat Apr 27 22:56:09 2019] Task in /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c/a2ed67c63e828da3849bf9f506ae2b36b4dac5b402a57f2981c9bdc07b23e672 killed as a result of limit of /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c <br> [Sat Apr 27 22:56:09 2019] memory: usage 125952kB, limit 125952kB, failcnt 3632 <br> [Sat Apr 27 22:56:09 2019] memory+swap: usage 0kB, limit 9007199254740988kB, failcnt 0 <br> [Sat Apr 27 22:56:09 2019] kmem: usage 2352kB, limit 9007199254740988kB, failcnt 0 <br> [Sat Apr 27 22:56:09 2019] Memory cgroup stats for /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c: cache:0KB rss:0KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:0KB inactive_file:0KB active_file:0KB unevictable:0KB <br> [Sat Apr 27 22:56:09 2019] Memory cgroup stats for /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c/79fae7c2724ea1b19caa343fed8da3ea84bbe5eb370e5af8a6a94a090d9e4ac2: cache:0KB rss:48KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:48KB inactive_file:0KB active_file:0KB unevictable:0KB <br> [Sat Apr 27 22:56:09 2019] Memory cgroup stats for /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c/a2ed67c63e828da3849bf9f506ae2b36b4dac5b402a57f2981c9bdc07b23e672: cache:0KB rss:123552KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:123548KB inactive_file:0KB active_file:0KB unevictable:0KB <br> [Sat Apr 27 22:56:09 2019] [ pid ] uid tgid total_vm rss pgtables_bytes swapents oom_score_adj name <br> [Sat Apr 27 22:56:09 2019] [25160] 0 25160 256 1 28672 0 -998 pause <br> [Sat Apr 27 22:56:09 2019] [25218] 0 25218 4627 872 77824 0 939 bash <br> [Sat Apr 27 22:56:09 2019] [32307] 0 32307 2060 275 57344 0 939 stress <br> [Sat Apr 27 22:56:09 2019] [32308] 0 32308 27661 24953 253952 0 939 stress <br> [Sat Apr 27 22:56:09 2019] [32331] 0 32331 2060 304 53248 0 939 stress <br> [Sat Apr 27 22:56:09 2019] [32332] 0 32332 14861 5829 102400 0 939 stress <br> [Sat Apr 27 22:56:09 2019] Memory cgroup out of memory: Kill process 32308 (stress) score 1718 or sacrifice child <br> [Sat Apr 27 22:56:09 2019] Killed process 32308 (stress) total-vm:110644kB, anon-rss:99620kB, file-rss:192kB, shmem-rss:0kB <br> [Sat Apr 27 22:56:09 2019] oom_reaper: reaped process 32308 (stress), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB</code> <br> <br>  Der Prozess mit der PID 32308 auf dem Host wurde aufgrund von Speichermangel (OOM) zerstört.  Das Interessanteste verbirgt sich jedoch am Ende der Tagebucheinträge: <br><br><img src="https://habrastorage.org/webt/fz/dn/pb/fzdnpbniemrgqc8qvmkxvttose0.png"><br><br>  Hier sind die Prozesse dieses Herdes, die als Kandidaten für die Zerstörung durch die OOM Killer-Komponente markiert sind.  Der <code>oom_score_adj</code> , in dem die Netzwerk-Namespaces <code>oom_score_adj</code> , erhielt eine <code>oom_score_adj</code> Bewertung von <code>-998</code> , was <code>-998</code> , dass nicht garantiert wird, dass der Prozess zerstört wird.  Die verbleibenden Prozesse im Container erhielten eine <code>oom_score_adj</code> Bewertung von <code>939</code> .  Sie können diesen Wert mithilfe der folgenden Formel aus der Kubernetes-Dokumentation überprüfen: <br><br><pre> <code class="go hljs">min(max(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span> - (<span class="hljs-number"><span class="hljs-number">1000</span></span> * memoryRequestBytes) / machineMemoryCapacityBytes), <span class="hljs-number"><span class="hljs-number">999</span></span>)</code> </pre> <br>  Wir ermitteln die für den Knoten verfügbare Speichermenge: <br><br><pre> <code class="go hljs">kubectl describe nodes k3s | grep Allocatable -A <span class="hljs-number"><span class="hljs-number">5</span></span> Allocatable: cpu: <span class="hljs-number"><span class="hljs-number">1</span></span> ephemeral-storage: <span class="hljs-number"><span class="hljs-number">49255941901</span></span> hugepages<span class="hljs-number"><span class="hljs-number">-1</span></span>Gi: <span class="hljs-number"><span class="hljs-number">0</span></span> hugepages<span class="hljs-number"><span class="hljs-number">-2</span></span>Mi: <span class="hljs-number"><span class="hljs-number">0</span></span> memory: <span class="hljs-number"><span class="hljs-number">2041888</span></span>Ki</code> </pre> <br>  Wenn die angeforderte Speichergröße nicht angegeben wird, entspricht sie standardmäßig dem Grenzwert.  Durch Ersetzen der Werte erhalten wir den folgenden <code>oom_score_adj</code> Wert: <code>1000–123*1024/2041888=938.32</code> , was dem im Systemprotokoll angegebenen Wert <code>939</code> sehr nahe kommt.  (Ich weiß nicht, wie OOM Killer den genauen Wert von 939 erhält.) <br><br>  Alle Prozesse im Container haben also den gleichen Wert für oom_score_adj.  Die OOM Killer-Komponente berechnet den OOM-Wert basierend auf der Speichernutzung und passt das Ergebnis basierend auf dem oom_score_adj-Score an.  Und letztendlich zerstört es den Prozess des ersten Stresstests, der den größten Teil des Speichers verschlang, 100 MB, was der Schätzung oom_score = 1718 entspricht. <br><br><h2>  Fazit </h2><br>  Kubernetes steuert das Speicherlimit des Herdes über die Komponenten cgroup und OOM Killer.  Es ist notwendig, die Bedingungen des OOM-Betriebssystems und der OOM-Herde sorgfältig zu vereinbaren. <br><br>  Wie gefällt dir das Material?  Jeder, der mehr über den Kurs erfahren möchte, wird am 17. Juni zu einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kostenlosen Webinar</a> eingeladen, in dem wir die Fähigkeiten von Kubernetes zur Organisation kontinuierlicher Bereitstellungspraktiken (CI / CD) und Ansätze für ein kleines Team mit mehreren Anwendungen sowie für eine große Organisation mit einer großen Anzahl von Systemen untersuchen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de456002/">https://habr.com/ru/post/de456002/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455988/index.html">Die Datenstrukturen des Zustands der Plasma Cash Blockchain</a></li>
<li><a href="../de455990/index.html">CTT in Serverlösungen - wie sieht es aus?</a></li>
<li><a href="../de455994/index.html">Die Entwicklung des beliebtesten Tools eines Entwicklers (in Visual Studio)</a></li>
<li><a href="../de455996/index.html">Digitale Transformation von Werbung im Netzwerkeinzelhandel. Auf den Spuren von Video Analytics im Einzelhandel</a></li>
<li><a href="../de456000/index.html">Erstellen eines Tic-Tac-Toe-Spiels mit TypeScript, React und Mocha</a></li>
<li><a href="../de456004/index.html">Wir laden Sie zu einem Front-End-Entwicklungstreffen mit stark ausgelasteten Diensten ein</a></li>
<li><a href="../de456006/index.html">Steigern Sie Ihren Umsatz mit In-App-Käufen</a></li>
<li><a href="../de456008/index.html">Entwicklung von Programmen für den Zentralprozessor Redd am Beispiel des Zugriffs auf das FPGA</a></li>
<li><a href="../de456010/index.html">Wie Java 10 die Art und Weise ändert, wie Sie anonyme innere Klassen verwenden</a></li>
<li><a href="../de456016/index.html">Protokoll für die Kommunikation zwischen iframe und dem Hauptfenster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ“— ğŸ‘¨ğŸ¾â€ğŸ­ ğŸ¦‹ O filÃ³sofo de inteligÃªncia artificial Eliezer Yudkowsky sobre singularidade, cÃ©rebro bayesiano e duendes em um gabinete ğŸ‘¨ğŸ¼ ğŸ‘©ğŸ½â€ğŸ¤â€ğŸ‘¨ğŸ¼ ğŸ»</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eliezer Shlomo Yudkovsky Ã© um especialista americano em inteligÃªncia artificial, que estuda os problemas da singularidade tecnolÃ³gica e defende a cria...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O filÃ³sofo de inteligÃªncia artificial Eliezer Yudkowsky sobre singularidade, cÃ©rebro bayesiano e duendes em um gabinete</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/404137/"><img src="https://habrastorage.org/getpro/geektimes/post_images/152/af6/3ff/152af63ff689233ebebadde98fed2580.png" alt="imagem"><br><br>  <i>Eliezer Shlomo Yudkovsky Ã© um especialista americano em inteligÃªncia artificial, que estuda os problemas da singularidade tecnolÃ³gica e defende a criaÃ§Ã£o da IA â€‹â€‹AmigÃ¡vel.</i>  <i>Nos cÃ­rculos nÃ£o acadÃªmicos, ele Ã© mais conhecido como autor da ficÃ§Ã£o de fÃ£s de Harry Potter e MÃ©todos de Racionalidade, sob os auspÃ­cios de Menos Errado.</i> <br><br>  Sempre fiquei impressionado com pessoas inteligentes que acreditam em coisas que me parecem absurdas.  Por exemplo, o geneticista e diretor dos Institutos Nacionais de SaÃºde, Francis Collins, acredita que Jesus ressuscitou dos mortos.  O teÃ³rico da IA â€‹â€‹Eliezer Yudkowsky acredita que os carros ... Mas melhor eu vou dar a palavra a ele.  Em 2008, eu o entrevistei no Bloggingheads.tv, mas nada de bom aconteceu porque eu decidi que ele era um seguidor do guru <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">da</a> singularidade de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ray Kurzweil</a> .  Mas Yudkovsky nÃ£o seguiu ninguÃ©m e nunca foi para a faculdade.  Ele Ã© um teÃ³rico teimoso e original da inteligÃªncia, humana e artificial.  Seu trabalho (por exemplo, um ensaio que me ajudou a entender, ou deu a ilusÃ£o de entendimento, os teoremas de Bayes) exala a arrogÃ¢ncia do autodidata, cujas bordas afiadas nÃ£o foram polidas pela educaÃ§Ã£o formal - mas isso faz parte de seu charme.  Mesmo quando te incomoda, Yudkovsky Ã© engraÃ§ado, renovado, provocador.  Para detalhes de sua biografia, consulte seu site pessoal ou o site do Instituto para o Estudo da InteligÃªncia de MÃ¡quinas, do qual ele participou.  E leia esta entrevista com um bÃ´nus na forma de comentÃ¡rios de sua esposa Briena. <br><a name="habracut"></a><br>  <b>Horgan</b> : Quando perguntado em uma festa o que vocÃª faz, o que vocÃª responde? <br><br>  <b>Yudkovsky</b> : Depende do evento.  â€œSou especialista em teoria da decisÃ£oâ€ ou â€œco-fundador do Instituto para o Estudo da InteligÃªncia de MÃ¡quinasâ€ ou, se for de um tipo diferente, falo sobre minhas obras de arte. <br><br>  <b>X:</b> Qual Ã© o seu filme de IA favorito e por quÃª? <br><br>  <b>Yu: A</b> IA nos filmes Ã© terrivelmente padrÃ£o.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ex Machina</a> chegou tÃ£o perto de uma exceÃ§Ã£o a esta regra quanto se pode esperar. <br><br>  <b>X:</b> O utilitÃ¡rio da faculdade Ã© superestimado? <br><br>  <b>Yu:</b> Eu ficaria surpreso se sua utilidade fosse subestimada, dados os requisitos sociais para acabar com ela.  AtÃ© onde eu sei, nÃ£o hÃ¡ razÃ£o para nÃ£o acreditar em economistas que acreditam que a faculdade se tornou um "produto de prestÃ­gio" e que as tentativas de aumentar os emprÃ©stimos estudantis simplesmente aumentaram o custo da faculdade e o Ã´nus da dÃ­vida estudantil. <br><br>  <b>X:</b> Por que vocÃª escreve histÃ³rias de ficÃ§Ã£o? <br><br>  <b>Yu:</b> Se vocÃª reformular os quadrinhos da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wondermark</a> : "No comeÃ§o, tentei nÃ£o fazÃª-lo, mas nÃ£o funcionou". <br><br>  AlÃ©m disso, a literatura sÃ©ria transmite conhecimento, enquanto a ficÃ§Ã£o transmite experiÃªncia.  Se vocÃª quiser entender as provas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">da fÃ³rmula de Bayes</a> , posso usar diagramas.  Se vocÃª quiser sentir como Ã© usar a lÃ³gica de Bayes, preciso escrever uma histÃ³ria na qual o personagem a faÃ§a. <br><br>  <b>X:</b> VocÃª Ã© religioso em algum sentido? <br><br>  <b>Yu:</b> NÃ£o.  Ao cometer um erro, vocÃª precisa evitar a tentaÃ§Ã£o de sair em defesa, tentar encontrar algum ponto de vista do qual vocÃª esteja pelo menos um pouco certo.  Ã‰ muito mais sÃ¡bio dizer: â€œAhâ€, admitir que vocÃª nÃ£o estava nem um pouco certo, engolir uma pÃ­lula amarga inteira e continuar a viver.  Ã‰ assim que a humanidade deve se relacionar com a religiÃ£o. <br><br>  <b>X:</b> Se vocÃª se tornasse o "rei do mundo", o que estaria no topo da sua lista de tarefas? <br><br>  <b>Yu: Uma</b> vez eu escrevi: â€œUm teste para um libertÃ¡rio funciona assim: imagine que vocÃª ganhou poder;  o que vocÃª vai pensar em primeiro lugar - sobre leis que vocÃª aceita ou sobre leis que vocÃª revoga? â€  NÃ£o sou 100% libertÃ¡rio, porque nem toda a minha lista de desejos estÃ¡ expressa na aboliÃ§Ã£o das leis e no relaxamento das restriÃ§Ãµes.  Mas imagino como tentaria criar um mundo no qual uma pessoa desempregada pudesse oferecer uma carona para o trabalho, receber US $ 5 por 20 minutos de carro e nada de ruim aconteceria com ele por causa disso.  Ele nÃ£o precisaria perder o seguro-desemprego, registrar uma permissÃ£o comercial, perder o seguro mÃ©dico, passar por uma auditoria, pedir a um advogado que certificasse que seu trabalho estÃ¡ em conformidade com as regras da AdministraÃ§Ã£o de ProteÃ§Ã£o do Trabalho, etc.  Ele sÃ³ teria acrescentado US $ 5. <br><br>  Eu tentaria retornar a um estado em que a contrataÃ§Ã£o de um funcionÃ¡rio seria tÃ£o simples quanto no ano de 1900.  Talvez agora exista algum sentido em certas medidas de seguranÃ§a, mas eu tentaria criar uma seguranÃ§a que nÃ£o restrinja uma pessoa e nÃ£o produza papÃ©is como resultado de um simples retorno de uma pessoa Ã  economia. <br><br>  Eu tentaria fazer tudo o que economistas inteligentes tÃªm gritado hÃ¡ muito tempo, e que nenhum Estado faz.  Substitua os impostos sobre investimentos e renda pelos impostos sobre consumo e imÃ³veis.  Substitua o salÃ¡rio mÃ­nimo por impostos negativos sobre a folha de pagamento.  EstabeleÃ§a uma polÃ­tica para atingir o PIB nominal dos bancos centrais e interrompa as estruturas de apoio "grandes demais para falir".  Exigir que, durante o litÃ­gio sobre patentes, a parte vencida pague honorÃ¡rios legais [ <i>apÃ³s a chamada</i>  <i>A regra inglesa - em contraste com as leis americanas, segundo as quais cada uma das partes adota seus prÃ³prios custos - aprox.</i>  <i>perev.</i>  ] e retorne a duraÃ§Ã£o dos direitos autorais para 28 anos.  Remova os obstÃ¡culos para a construÃ§Ã£o de casas.  Copie o seguro de saÃºde de Cingapura.  Governo eletrÃ´nico na EstÃ´nia.  Substitua comitÃªs e processos complexos de tomada de decisÃ£o por indivÃ­duos especÃ­ficos que tomam decisÃµes publicamente documentadas e sÃ£o responsÃ¡veis â€‹â€‹por isso.  Realize experimentos controlados com vÃ¡rias opÃ§Ãµes para gerenciar paÃ­ses e leve em consideraÃ§Ã£o seus resultados.  Eu posso ficar na lista por horas. <br><br>  Tudo isso pode nÃ£o ter importÃ¢ncia em duzentos milhÃµes de anos.  Mas os ativos nominais resultantes do boom econÃ´mico podem fazer um bom trabalho enquanto tento descobrir o que faremos com a inteligÃªncia artificial.  O Ã³bvio Ã© o projeto de Manhattan em algum lugar da ilha, com pagamento baseado na competiÃ§Ã£o entre os maiores fundos de hedge, nos quais as pessoas podem explorar o problema da inteligÃªncia artificial generalizada sem publicar os resultados de seu trabalho que automaticamente traz o fim do mundo.  E a menos que aceitemos que eu tenho habilidades mÃ¡gicas ou um regime fundamentalmente irreversÃ­vel, nÃ£o vejo como qualquer lei que eu aceitaria atrasaria a abordagem da IA â€‹â€‹bastante fortemente em um planeta onde os computadores sÃ£o onipresentes. <br><br>  Mas tudo isso ainda pode ser considerado um experimento de pensamento impossÃ­vel e, na vida real, a probabilidade de tal experimento Ã© zero. <br><br>  <b>X:</b> O que hÃ¡ de tÃ£o bom no teorema de Bayes? <br><br>  <b>Yu:</b> Bem, por exemplo, ela Ã© muito profunda.  Portanto, Ã© difÃ­cil responder brevemente a essa pergunta. <br><br>  Eu poderia responder que o teorema de Bayes pode ser chamado de segunda lei da termodinÃ¢mica para a cogniÃ§Ã£o.  Se vocÃª concluir que a probabilidade de alguma suposiÃ§Ã£o Ã© de 99%, seja a presenÃ§a de leite no supermercado ou a causa antropogÃªnica do aquecimento global, entÃ£o vocÃª tem uma combinaÃ§Ã£o de probabilidades a priori boas o suficiente e evidÃªncias razoavelmente confiÃ¡veis.  Este nÃ£o Ã© um requisito regulatÃ³rio, Ã© uma lei.  Assim como um carro nÃ£o pode dirigir sem dissipar a entropia, vocÃª nÃ£o pode obter uma boa imagem do mundo sem executar um processo no qual uma estrutura bayesiana exista em algum lugar interno, mesmo que as probabilidades nÃ£o sejam usadas diretamente no processo. <br><br>  Pessoalmente, acho que o principal que Bayes pode nos oferecer Ã© a existÃªncia de regras, leis de ferro que determinam se o modo de pensar funciona para marcar a realidade.  Dizem aos mÃ³rmons que reconhecem a verdade do Livro de MÃ³rmon atravÃ©s de uma sensaÃ§Ã£o de queimaÃ§Ã£o no coraÃ§Ã£o.  Conservadoramente aceite a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">probabilidade a priori do</a> Livro de MÃ³rmon como uma em um bilhÃ£o.  Depois, avaliamos a probabilidade de o Livro de MÃ³rmon nÃ£o ser verdadeiro, e alguÃ©m experimentou uma sensaÃ§Ã£o de queimaÃ§Ã£o no coraÃ§Ã£o depois que lhe disseram que isso era esperado.  Se vocÃª entender a fÃ³rmula de Bayes, perceberemos imediatamente que a baixa probabilidade da prova Ã© incomensurÃ¡vel com a baixa probabilidade da hipÃ³tese que eles estÃ£o tentando provar com sua ajuda.  VocÃª nem precisa criar nÃºmeros especÃ­ficos para entender que eles nÃ£o convergem - como Philip Tetlock descobriu em seu estudo de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">super</a> preditores", eles geralmente conheciam a fÃ³rmula de Bayes, mas raramente davam nÃºmeros especÃ­ficos.  De certa forma, Ã© mais difÃ­cil enganÃ¡-lo se vocÃª entender que existe algum tipo de matemÃ¡tica com a qual vocÃª pode determinar com precisÃ£o a forÃ§a da prova e entender se Ã© suficiente para superar a baixa probabilidade da hipÃ³tese.  VocÃª nÃ£o pode apenas inventar algo e acreditar nele, porque nÃ£o funciona assim. <br><br>  <b>X:</b> A hipÃ³tese do cÃ©rebro bayesiano o impressiona? <br><br>  <b>Yu:</b> Eu acho que algumas pessoas que discutem sobre esse tÃ³pico falam sobre coisas diferentes.  Perguntar se o cÃ©rebro Ã© um algoritmo bayesiano Ã© como perguntar se o Honda Accord Ã© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">alimentado por um motor tÃ©rmico de Carnot</a> .  Se uma pessoa disser: â€œCada carro Ã© um processo termodinÃ¢mico que requer combustÃ­vel e dissipa o calor dispersoâ€, e outra pessoa ouve: â€œSe vocÃª criar um diagrama de ciclo de Carnot e mostrar sua mecÃ¢nica, ele deve concordar que se parece com o interior de um Honda Accord ", EntÃ£o um debate acalorado Ã© inevitÃ¡vel. <br><br>  Algumas pessoas ficam muito felizes quando abrem o motor de combustÃ£o interna, encontram os cilindros e dizem: "Tenho certeza de que convertem calor em pressÃ£o e ajudam a mover o carro para a frente!"  E eles estarÃ£o certos, mas outras pessoas dirÃ£o: â€œVocÃª estÃ¡ se concentrando no Ãºnico componente de um conjunto muito maior de peÃ§as de carros.  O conversor catalÃ­tico tambÃ©m Ã© muito importante e nÃ£o estÃ¡ nos diagramas de ciclo Carnot.  E Ã s vezes um ar condicionado funciona para nÃ³s, trabalhando exatamente o oposto de como o motor tÃ©rmico funciona de acordo com suas palavras. â€ <br><br>  Eu nÃ£o acho que seria surpreendente se eu disser que as pessoas que falam em vocÃª: "VocÃª claramente nÃ£o estÃ¡ familiarizado com carros modernos;  vocÃª precisa de todo um conjunto de mÃ©todos diferentes para construir um motor, como velas e conversores catalÃ­ticos, e nÃ£o apenas seus processos termodinÃ¢micos â€, eles perdem um nÃ­vel essencial de abstraÃ§Ã£o. <br><br>  Mas se vocÃª quiser saber se o cÃ©rebro pode ser considerado literalmente bayesiano, e nÃ£o um dispositivo que realiza trabalho cognitivo, cuja natureza podemos entender usando mÃ©todos bayesianos, entÃ£o posso responder Ã  sua pergunta: "NÃ£o, Ã© claro".  Pode haver vÃ¡rios "cilindros" bayesianos neste "motor", mas muito parecerÃ£o tÃ£o estranhos quanto cintos de seguranÃ§a e ar condicionado.  Mas essas adiÃ§Ãµes nÃ£o mudarÃ£o o fato de que, para identificar corretamente uma maÃ§Ã£ com base em evidÃªncias sensoriais, Ã© necessÃ¡rio fazer algo que possa ser interpretado como resultado de induÃ§Ã£o que possa entender o conceito de maÃ§Ã£ e que seja atualizado com base em evidÃªncias que distingam maÃ§Ã£s de nÃ£o maÃ§Ã£s. <br><br>  <b>X:</b> Ã‰ possÃ­vel ser muito racional? <br><br>  <b>Yu:</b> VocÃª pode entrar no chamado  "O vale da mÃ¡ racionalidade."  Se antes isso vocÃª era irracional em vÃ¡rias coisas, equilibrando-se, entÃ£o, se vocÃª se tornar racional, poderÃ¡ se tornar pior do que antes.  Quanto mais vocÃª se tornar racional, pior serÃ¡ se escolher a direÃ§Ã£o errada para aplicar suas habilidades. <br><br>  Mas eu nÃ£o recomendaria cuidar muito dessa oportunidade.  Na minha opiniÃ£o, as pessoas que falam sobre o quÃ£o inteligentemente irracional podem ser sÃ£o idiotas.  Ã‰ difÃ­cil criar uma situaÃ§Ã£o de vida realista, nÃ£o exagerada, na qual vocÃª possa decidir ser irracional, e cujo resultado ainda Ã© desconhecido para vocÃª.  Na vida real, Ã© melhor dizer a verdade a si mesmo e nÃ£o ser inteligente. <br><br>  Ã‰ possÃ­vel que o representante ideal do pensamento bayesiano seja incompatÃ­vel com uma vida interessante e divertida.  Mas esse claramente nÃ£o Ã© um problema tÃ£o grande quanto a nossa tendÃªncia Ã  autodestruiÃ§Ã£o. <br><br>  <b>X:</b> Como o seu ponto de vista sobre a singularidade difere do de Kurzweil? <br><br>  <b>Yu:</b> <br>  â€¢ NÃ£o acho que a lei de Moore possa ser aplicada Ã  IA.  AI Ã© um problema de software. <br>  â€¢ NÃ£o acho que o primeiro intelecto sobre-humano apareÃ§a da fusÃ£o de mÃ¡quinas com as pessoas.  Cem anos se passaram desde o advento dos carros, e agora estamos tentando fazer um exoesqueleto para um cavalo, e um carro comum ainda Ã© mais rÃ¡pido. <br>  â€¢ Eu nÃ£o acho que a primeira IA forte serÃ¡ baseada em algoritmos da neurobiologia, assim como os aviÃµes nÃ£o foram baseados em pÃ¡ssaros. <br>  â€¢ NÃ£o acho que a fusÃ£o de nanotecnologias, informaÃ§Ãµes e biotecnologias seja possÃ­vel, inevitÃ¡vel, bem definida ou necessÃ¡ria. <br>  â€¢ Penso que de 1930 a 1970 houve mais mudanÃ§as do que de 1970 a 2010. <br>  â€¢ Penso que nos paÃ­ses desenvolvidos a produtividade estagna. <br>  â€¢ Acho que a extrapolaÃ§Ã£o da lei de Moore para o progresso tecnolÃ³gico, supostamente prevendo tudo o que serÃ¡ mais inteligente do que os humanos apÃ³s o advento da IA, Ã© uma coisa muito estranha.  Uma inteligÃªncia artificial inteligente arruina todos os seus grÃ¡ficos. <br>  â€¢ Alguns analistas, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Illka â€‹â€‹Tuomi</a> , acreditam que a lei de Moore <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">violou</a> no inÃ­cio dos anos 2000.  NÃ£o tenho certeza se posso me opor. <br>  â€¢ O Ãºnico limiar tecnolÃ³gico que me interessa Ã© onde a IA ganha a capacidade de melhorar.  NÃ£o temos um cronograma que atinja esse limite, e nÃ£o estÃ¡ claro qual serÃ¡ (embora nÃ£o deva exceder em muito o nÃ­vel de uma pessoa, pois ela entende ciÃªncia da computaÃ§Ã£o); portanto, sua ofensiva nÃ£o pode ser prevista. <br>  â€¢ NÃ£o acho que o resultado desse progresso seja bom por padrÃ£o.  Eu acho que isso pode ser bom, mas precisarÃ¡ ser seriamente trabalhado, e os principais nÃºmeros nÃ£o estÃ£o interessados â€‹â€‹nisso.  Dizer Ã s pessoas que estamos em uma trajetÃ³ria natural para tempos grandes e maravilhosos serÃ¡ uma mentira. <br>  â€¢ Penso que â€œsingularidadeâ€ se tornou uma palavra de mala com muitos significados e detalhes incompatÃ­veis por dentro, entÃ£o parei de usÃ¡-la. <br><br>  <b>X:</b> VocÃª provavelmente se tornarÃ¡ um ciborgue ultra-inteligente? <br><br>  <b>Yu:</b> A lei da conjunÃ§Ã£o de probabilidades diz que P (A&amp;B) &lt;= P (A).  A probabilidade da ocorrÃªncia simultÃ¢nea dos eventos A e B Ã© menor que a probabilidade da ocorrÃªncia de um evento A. Em experimentos em que as pessoas acreditam que P (A&amp;B)&gt; P (A) para dois eventos A e B, um " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">erro de conjunÃ§Ã£o</a> " aparece - por exemplo, em 1982, especialistas do Congresso Internacional de PrevisÃµes atribuÃ­ram uma maior probabilidade ao evento "A RÃºssia invadir a PolÃ´nia e os laÃ§os diplomÃ¡ticos com a URSS romperem" do que a probabilidade de um evento separado "rompimento dos laÃ§os diplomÃ¡ticos com a URSS", nomeado por outro grupo.  Da mesma forma, outro grupo atribuiu uma maior probabilidade ao evento "Um terremoto na CalifÃ³rnia leva a uma inundaÃ§Ã£o que leva a milhares de vÃ­timas" do que outro - a probabilidade do evento "Em algum lugar da AmÃ©rica do Norte hÃ¡ uma inundaÃ§Ã£o com milhares de vÃ­timas".  Embora adicionar detalhes adicionais Ã  histÃ³ria claramente a torne menos provÃ¡vel, torna-a mais crÃ­vel.  Para mim, entender esse fato, Ã© como uma " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ponte do burro</a> " para um futurismo sÃ©rio - a diferenÃ§a entre o fato de vocÃª pesar cuidadosamente cada suposiÃ§Ã£o individual e descobrir se vocÃª pode apoiar esse esclarecimento independentemente de todos os outros e que simplesmente compÃµe um maravilhoso e uma histÃ³ria vibrante. <br><br>  Ã‰ tudo o que digo no contexto da resposta Ã  pergunta: â€œPor que vocÃª estÃ¡ adicionando um refinamento como um ciborgue a isso?  NÃ£o quero ser um ciborgue.  Ã‰ necessÃ¡rio tecer cuidadosamente detalhes adicionais para as declaraÃ§Ãµes. <br><br>  <b>X:</b> VocÃª tem chance de imortalidade? <br><br>  <b>Yu:</b> Literalmente?  A imortalidade literal Ã© difÃ­cil de alcanÃ§ar.  Para viver muito mais do que alguns trilhÃµes de anos, Ã© preciso reconsiderar o destino esperado de um universo em expansÃ£o.  Para viver mais do que os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">googolpleks</a> , Ã© necessÃ¡rio cometer um erro sobre os fundamentos das leis fÃ­sicas, e nÃ£o apenas em detalhes. <br><br>  Mesmo que parte do raciocÃ­nio incomum se mostre verdadeiro e nosso Universo possa gerar universos filhas, isso nÃ£o nos darÃ¡ imortalidade.  Para viver muito mais anos no Googleplex e nÃ£o se repetir, vocÃª precisarÃ¡ de computadores com mais elementos que o Google, e essa mÃ¡quina nÃ£o se encaixarÃ¡ na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esfera</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hubble</a> . <br><br>  E googolpleks nÃ£o Ã© infinito.  Parafraseando Martin Gardner, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o nÃºmero de Graham</a> ainda Ã© bastante pequeno, jÃ¡ que a maioria dos nÃºmeros finais Ã© muito maior que ele.  Se vocÃª quer se surpreender, leia sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hierarquias de rÃ¡pido crescimento</a> e o infinito ainda serÃ¡ mais longo.  Somente teorias antrÃ³picas muito estranhas e assustadoras permitirÃ£o que vocÃª viva o suficiente para assistir a uma parada na mÃ¡quina Turing mais antiga, com centenas de estados. <br><br>  No entanto, nÃ£o acho que, do ponto de vista emocional, eu gostaria de viver o suficiente para ver o centÃ©simo nÃºmero no jogo " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">caÃ§ar um trabalhador castor</a> ".  De alguma forma, posso simpatizar comigo mesmo, que vive daqui a cem anos.  Nesse futuro, poderei simpatizar com o futuro daqui a cem anos.  E talvez em algum lugar dessa sequÃªncia haja alguÃ©m que enfrenta a perspectiva de acabar com a existÃªncia deles, e ele pode ficar muito triste com isso.  Mas nÃ£o tenho certeza se consigo imaginar essa pessoa.  Quero viver outro dia.  AmanhÃ£ tambÃ©m vou querer viver outro dia.  Portanto, quero viver para sempre, comprovado pela induÃ§Ã£o de nÃºmeros inteiros positivos ".  AtÃ© meu desejo de uma vida longa em um universo fisicamente possÃ­vel Ã© uma abstraÃ§Ã£o gerada pela induÃ§Ã£o.  NÃ£o consigo me imaginar em um trilhÃ£o de anos. <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Descrevi a singularidade como uma fantasia escapista e pseudocientÃ­fica que nos distrai das mudanÃ§as climÃ¡ticas, guerras, desigualdades e outros problemas sÃ©rios. Por que eu estou errado? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Porque vocÃª estÃ¡ tentando prever fatos empÃ­ricos atravÃ©s da psicanÃ¡lise. Isso nunca vai funcionar. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Suponha que vivamos para ver o advento da IA â€‹â€‹que Ã© inteligente o suficiente para fazer o mesmo trabalho de melhorar a IA que as pessoas. Ele pode se ajustar, programar, inventar novos algoritmos. Para melhorar. O que acontecerÃ¡ a seguir - ficarÃ¡ mais inteligente, verÃ¡ ainda mais oportunidades de aprimoramento e alcanÃ§arÃ¡ rapidamente um nÃ­vel muito alto? Ou nada de especial vai acontecer?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pode acontecer que (A) o aprimoramento automÃ¡tico em um determinado delta torne a IA inteligente o suficiente para que possa olhar para trÃ¡s e encontrar uma nova melhoria potencial no tamanho de k * delta, onde k&gt; 1, e isso serÃ¡ repetido vÃ¡rias vezes para levar ao rÃ¡pido aprimoramento automÃ¡tico para nÃ­vel de superinteligÃªncia. O que </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Irving John Goode</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> chamou de "explosÃ£o de inteligÃªncia". Ou (B), k Ã© menor que a unidade ou todas essas melhorias sÃ£o pequenas e nÃ£o levam Ã  aparÃªncia de superinteligÃªncia, ou a superinteligÃªncia Ã© geralmente impossÃ­vel e, em vez de uma explosÃ£o, haverÃ¡ um zilch. O que Ã© verdade, A ou B? Se vocÃª criar uma IA de um certo nÃ­vel e ele tentar fazÃª-lo, algo acontecerÃ¡ no mundo real empÃ­rico, e esse evento serÃ¡ determinado por fatos relacionados ao cenÃ¡rio de algoritmos e melhorias possÃ­veis.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">InformaÃ§Ãµes confiÃ¡veis â€‹â€‹sobre esse evento nÃ£o podem ser obtidas na psicanÃ¡lise de pessoas. Ã‰ como tentar ligar um carro sem combustÃ­vel - Ã© o que o teorema de Bayes nos diz. Algumas pessoas sempre serÃ£o escapistas, independentemente dos valores reais de variÃ¡veis â€‹â€‹ocultas na ciÃªncia da computaÃ§Ã£o, portanto, observar alguns escapistas nÃ£o pode ser chamado de prova rigorosa. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este Ã© um equÃ­voco sobre a natureza da racionalidade - que Ã© racional acreditar que "duendes em armÃ¡rios nÃ£o existem" porque a fÃ© em duendes de um armÃ¡rio Ã© estÃºpida, imatura, desatualizada, e apenas idiotas acreditam nela. O verdadeiro princÃ­pio da racionalidade Ã© ir verificar o armÃ¡rio. Portanto, naqueles universos em que os duendes vivem em armÃ¡rios, vocÃª acreditarÃ¡ em duendes e em universos em que os duendes nÃ£o estÃ£o em armÃ¡rios, vocÃª nÃ£o acreditarÃ¡ neles.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ã‰ difÃ­cil, mas, em princÃ­pio, Ã© possÃ­vel tentar olhar pela porta entreaberta e perguntar: "O que seria diferente no Universo se nÃ£o fosse possÃ­vel obter uma boa renda com investimentos cognitivos, ou seja, uma IA tentando melhorar a si mesma terminaria nÃ£o com uma explosÃ£o, mas com um zilch? Que outros fatos seriam caracterÃ­sticos de um universo assim? â€ </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HÃ¡ pessoas que afirmam que a IA sÃ³ pode ser aumentada para o nÃ­vel de uma pessoa, jÃ¡ que nÃ³s prÃ³prios somos pessoas e nÃ£o podemos aumentÃ¡-la mais. Parece-me que, se o nosso universo Ã© assim, devemos observar uma diminuiÃ§Ã£o na renda dos investimentos em hardware e software para xadrez de computador que excede o nÃ­vel de uma pessoa - o que realmente nÃ£o acontece. AlÃ©m disso, a seleÃ§Ã£o natural nÃ£o seria capaz de criar uma pessoa naquela Ã©poca, e a mÃ£e de Einstein deveria ter sido uma incrÃ­vel fÃ­sica, etc.</font></font> etc. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Existem pessoas que argumentam que quanto mais complexo o algoritmo, mais ajustes ele precisa e que nossa inteligÃªncia serve como uma espÃ©cie de limitaÃ§Ã£o para esse processo. Mas isso nÃ£o concorda com os registros antropolÃ³gicos da inteligÃªncia humana; os investimentos em ajustes e mutaÃ§Ãµes do cÃ©rebro fornecem capacidades cognitivas aprimoradas. NÃ³s sabemos, porque a genÃ©tica nos diz que mutaÃ§Ãµes com uma pequena resposta estatÃ­stica nÃ£o sÃ£o corrigidas durante a evoluÃ§Ã£o. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">E os hominÃ­deos nÃ£o precisavam de um cÃ©rebro exponencialmente maior que os chimpanzÃ©s. E a cabeÃ§a de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">John von Neumann</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nÃ£o </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">era</font></a><font style="vertical-align: inherit;"> exponencialmente maior que a cabeÃ§a da pessoa comum.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De um ponto de vista puramente prÃ¡tico, os axÃ´nios humanos transmitem informaÃ§Ãµes a uma velocidade de um milhÃ£o de vezes menor que a velocidade da luz e, mesmo do ponto de vista da dissipaÃ§Ã£o de calor, cada operaÃ§Ã£o sinÃ¡ptica consome um milhÃ£o de vezes mais que a dissipaÃ§Ã£o tÃ©rmica mÃ­nima de uma operaÃ§Ã£o binÃ¡ria irreversÃ­vel a 300 Kelvin e assim por diante. Por que devemos assumir que o software cerebral estÃ¡ mais prÃ³ximo do ideal do que o ferro? O privilÃ©gio da inteligÃªncia humana Ã© que Ã© o menor nÃ­vel de inteligÃªncia capaz de criar um computador. Se fosse possÃ­vel criar um computador com um nÃ­vel mais baixo de inteligÃªncia, discutirÃ­amos isso em um nÃ­vel mais baixo.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mas esse nÃ£o Ã© um argumento simples e, para uma descriÃ§Ã£o detalhada, envio pessoas para um de meus trabalhos antigos, "A Microeconomia da ExplosÃ£o de InteligÃªncia", que, infelizmente, ainda serve como a melhor fonte de informaÃ§Ã£o. Mas sÃ£o precisamente essas perguntas que precisam ser feitas para usar as evidÃªncias disponÃ­veis para discutir se veremos uma explosÃ£o de IA na qual uma certa melhoria nas habilidades cognitivas investidas na auto-otimizaÃ§Ã£o aumentarÃ¡ em excesso essa melhoria. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quanto Ã s oportunidades e seus preÃ§os: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vocÃª pode imaginar um mundo sem uma explosÃ£o de inteligÃªncia e sem superinteligÃªncia. Ou um mundo onde os truques que os especialistas em aprendizado de mÃ¡quina usarÃ£o para controlar a super-IA sÃ£o adequados para controlar as pessoas e o regime sobre-humano. Ou um mundo onde </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">o internalismo moral</font></a><font style="vertical-align: inherit;"> funciona</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, entÃ£o todas as IAs bastante avanÃ§adas sÃ£o boas. Nesses mundos, ninguÃ©m precisa de todo o trabalho e todas as preocupaÃ§Ãµes do Instituto de Pesquisa de Aprendizado de MÃ¡quina. E vÃ¡rias redes mosquiteiras foram desperdiÃ§adas, e era melhor entregÃ¡-las ao fundo para combater a malÃ¡ria. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">VocÃª tambÃ©m pode imaginar um mundo em que lute contra a malÃ¡ria, lute e mantenha as emissÃµes de carbono no nÃ­vel adequado ou use soluÃ§Ãµes de geoengenharia para neutralizar os erros jÃ¡ cometidos. E tudo isso acaba sendo inÃºtil, jÃ¡ que a civilizaÃ§Ã£o Ã© incapaz de resolver o problema da moralidade da IA â€‹â€‹- e todas as crianÃ§as salvas da malÃ¡ria com a ajuda de redes crescem apenas para que as nanomÃ¡quinas as matem em um sonho.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acho que as pessoas que estÃ£o tentando se envolver em uma caridade razoÃ¡vel concordam que nÃ£o gostarÃ­amos de viver em nenhum desses mundos. A Ãºnica questÃ£o Ã© qual Ã© mais provÃ¡vel. O princÃ­pio central da racionalidade nÃ£o Ã© rejeitar a fÃ© nos duendes, porque Ã© estÃºpido e nÃ£o prestigioso, e nÃ£o acreditar nos duendes, porque Ã© saudÃ¡vel e bonito. O princÃ­pio central da racionalidade Ã© que sinais observÃ¡veis â€‹â€‹e conclusÃµes lÃ³gicas nos ajudarÃ£o a escolher um desses dois mundos.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eu acho que o primeiro mundo Ã© improvÃ¡vel e o segundo Ã© provÃ¡vel. Entendo que tentar convencer os outros disso Ã© nadar contra o fluxo da fÃ© na eterna normalidade. CrenÃ§as de que apenas nossa civilizaÃ§Ã£o de curto prazo, que existe hÃ¡ vÃ¡rias dÃ©cadas, e apenas nossa espÃ©cie, que existe apenas um momento nas escalas evolucionÃ¡rias e geolÃ³gicas, fazem sentido e devem existir para sempre. E embora eu acredite que o primeiro mundo seja apenas um sonho otimista, nÃ£o acho que precisamos ignorar o problema, do qual entraremos em pÃ¢nico no futuro. A missÃ£o do Instituto Ã© realizar hoje pesquisas que, segundo pessoas que vivem depois de 30 anos, deveriam ter comeÃ§ado hÃ¡ 30 anos. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sua esposa Brijena acredita na singularidade?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Brijena: Se alguÃ©m me perguntasse se eu acredito em uma singularidade, levantaria uma sobrancelha e perguntaria se eles acreditam em caminhÃµes automÃ¡ticos. Esta Ã© uma pergunta estranha. NÃ£o sei qual serÃ¡ a primeira frota de caminhÃµes automÃ¡ticos ou quanto tempo levarÃ¡ para substituir o sistema de transporte de carga existente. E nÃ£o acredito em caminhÃµes robÃ³ticos, prevejo com seguranÃ§a que o transporte nÃ£o tripulado substituirÃ¡ o transporte moderno pela participaÃ§Ã£o de pessoas, porque estamos indo nessa direÃ§Ã£o se nada realmente estranho acontecer. Pela mesma razÃ£o, prevejo com confianÃ§a uma explosÃ£o de inteligÃªncia. Em outros significados da palavra "singularidade", nÃ£o tenho tanta certeza. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Brijena deu a resposta sem ver minhas respostas. Ã‰ que estamos bem adaptados um ao outro. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ã‰ possÃ­vel criar superinteligÃªncia sem entender como o cÃ©rebro funciona? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> No mesmo sentido que vocÃª pode fazer aviÃµes sem entender como um pÃ¡ssaro voa. VocÃª nÃ£o precisa ser especialista em pÃ¡ssaros, mas, ao mesmo tempo, precisa de muito conhecimento para construir um aviÃ£o, tendo obtido o que, em princÃ­pio, vocÃª jÃ¡ pode entender como aproximadamente um pÃ¡ssaro voa ou repele do ar. Portanto, estou escrevendo sobre a racionalidade humana - se vocÃª for suficientemente longe na questÃ£o da inteligÃªncia de mÃ¡quinas, nÃ£o poderÃ¡ deixar de pensar em algumas idÃ©ias sobre como as pessoas pensam. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O que a superinteligÃªncia pode querer? Eles terÃ£o algo como desejo sexual? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pense em um vasto espaÃ§o de possibilidades, em uma esfera multidimensional gigante. Este Ã© um espaÃ§o de tipos de mente, um conjunto de todos os algoritmos cognitivos possÃ­veis. Imagine que em algum lugar no fundo da esfera exista um pequeno ponto indicando todas as pessoas que jÃ¡ viveram. Esse Ã© um ponto minÃºsculo, pois todas as pessoas tÃªm aproximadamente o mesmo cÃ©rebro, com cÃ³rtex, cerebelo, tÃ¡lamo, etc. Algumas pessoas nÃ£o sÃ£o como as outras, por isso pode ser um ponto pontudo, mas os pontos terÃ£o a mesma escala do ponto em si. Independentemente da sua neuroatipicidade, vocÃª nÃ£o trabalharÃ¡ em outro algoritmo cortical.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perguntar "o que a superinteligÃªncia quer" Ã© a pergunta errada. SuperinteligÃªncias nÃ£o sÃ£o uma tribo estranha de pessoas que vivem do outro lado do rio e tÃªm costumes exÃ³ticos. AI Ã© simplesmente o nome de todo o espaÃ§o de possibilidades fora de um pequeno ponto humano. Com conhecimento suficiente, vocÃª pode entrar nesse espaÃ§o de oportunidades e sair de lÃ¡ uma IA que tem desejos que podem ser descritos na linguagem humana por Wishlist, mas nÃ£o porque serÃ¡ a Wishlist natural desses super-humanos exÃ³ticos, mas porque vocÃª isolou uma parte do espaÃ§o dos tipos mentais .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Com relaÃ§Ã£o aos desejos sexuais - se vocÃª sabe exatamente o que estÃ¡ fazendo, resolveu o principal problema de criar IA, querendo, de forma estÃ¡vel, certas coisas enquanto melhora, se resolveu o principal problema de direcionar funÃ§Ãµes utilitÃ¡rias da IA â€‹â€‹para tarefas que parecem enganosamente simples para uma pessoa, e um problema ainda mais complicado Ã© a construÃ§Ã£o da IA â€‹â€‹usando um certo tipo de arquitetura, em que coisas como "desejos sexuais" e "felicidade do sexo" sÃ£o importantes, entÃ£o, talvez, vocÃª possa fazer a IA olhar para as pessoas que estÃ£o modelando sejam seus desejos, extraia essa parte deles em relaÃ§Ã£o ao desejo sexual e faÃ§a com que a IA o experimente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obviamente, vocÃª tambÃ©m pode, com bons conhecimentos de biologia orgÃ¢nica e aerodinÃ¢mica, construir aeronaves que possam acasalar com pÃ¡ssaros.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mas nÃ£o acho que os irmÃ£os Wright devessem ter feito essas coisas no inÃ­cio de suas atividades. Isso nÃ£o faria sentido. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parece mais razoÃ¡vel resolver o problema de penetrar no espaÃ§o das mentes e extrair daÃ­ uma IA que nÃ£o deseja nos desmontar em Ã¡tomos livres. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Quero pensar que criaturas extremamente inteligentes professarÃ£o nÃ£o-violÃªncia, porque entenderÃ£o que a violÃªncia Ã© estÃºpida. Eu sou ingÃªnuo </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Eu acho que sim. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">David hume</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eu lhe diria que vocÃª estÃ¡ cometendo um erro tÃ­pico aplicando o predicado de â€œestupidezâ€ aos valores ou operaÃ§Ãµes oficiais de um indivÃ­duo. AÃ§Ãµes, escolhas, regras podem ser estÃºpidas se vocÃª tiver alguma preferÃªncia sobre o estado final do mundo. Se vocÃª Ã© uma pessoa com meta-preferÃªncias que ainda nÃ£o calculou totalmente, pode ter uma plataforma na qual pode confiar e chamar de estÃºpida algumas especulaÃ§Ãµes sobre as preferÃªncias de objetos. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maximizador de grampos [ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">experimento que demonstrou como a IA feita sem intenÃ§Ã£o maliciosa pode prejudicar a humanidade - aprox.</font></font></i>  <i>perev.</i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">] nÃ£o comete um erro computacional, escolhendo aqueles casos em que o nÃºmero mÃ¡ximo de grampos Ã© obtido. NÃ£o estÃ¡ na sua plataforma de preferÃªncias, escolhendo aÃ§Ãµes erradas, e nÃ£o estÃ¡ na sua plataforma de meta-preferÃªncias, escolhendo erroneamente as preferÃªncias. Ele calcula a resposta para outra pergunta, e nÃ£o para a que vocÃª se pergunta, a pergunta "O que devo fazer?" O maximizador de grampos simplesmente executa a aÃ§Ã£o que leva ao maior nÃºmero de grampos. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um cenÃ¡rio fatal Ã© quando a IA nÃ£o te ama nem odeia, porque vocÃª Ã© feito de Ã¡tomos que ela pode usar para criar outra coisa. Teoria dos jogos e problemas de cooperaÃ§Ã£o no </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dilema do prisioneiro</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nÃ£o se manifestam em todos os casos possÃ­veis. Por exemplo, eles nÃ£o aparecem quando um determinado assunto Ã© tÃ£o mais forte que vocÃª que ele pode transformÃ¡-lo em Ã¡tomos quando vocÃª deseja clicar nos botÃµes "cooperar" ou "alterar". E quando ultrapassamos esse limite, vocÃª resolveu o problema de criar algo que nÃ£o deseja prejudicÃ¡-lo ou jÃ¡ perdeu. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X: A</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> superinteligÃªncia </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resolverÃ¡ o difÃ­cil problema da consciÃªncia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sim, e olhando para trÃ¡s, a resposta parecerÃ¡ vergonhosamente simples para nÃ³s. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X: As</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> superinteligÃªncias terÃ£o livre arbÃ­trio? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sim, mas eles nÃ£o terÃ£o a ilusÃ£o de livre arbÃ­trio. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Como Ã© a sua utopia? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Vou direcionar seus leitores para os meus "</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SequÃªncias da teoria do entretenimento</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">,</font></a><font style="vertical-align: inherit;"> pois ainda nÃ£o consegui escrever uma histÃ³ria cuja aÃ§Ã£o ocorra em um mundo ideal teÃ³rico de entretenimento.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt404137/">https://habr.com/ru/post/pt404137/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt404125/index.html">A contagem regressiva acabou: restam 7 dias para o Polybius ICO</a></li>
<li><a href="../pt404127/index.html">O primeiro lanÃ§amento do Electron LV foi parcialmente bem-sucedido</a></li>
<li><a href="../pt404129/index.html">Feliz Dia dos Geeks (sim, ele Ã© hoje)</a></li>
<li><a href="../pt404133/index.html">AtÃ© o final deste ano, o Google planeja mostrar em operaÃ§Ã£o um computador quÃ¢ntico de 49 qubit</a></li>
<li><a href="../pt404135/index.html">O Google coleta e analisa compras offline de usuÃ¡rios do Android Pay</a></li>
<li><a href="../pt404139/index.html">Bitcoin na RÃºssia: imposto (algumas perguntas simples)</a></li>
<li><a href="../pt404141/index.html">ConcorrÃªncia desleal no fornecedor</a></li>
<li><a href="../pt404143/index.html">Nuggets minÃºsculos: uma revisÃ£o dos registradores russos TrendVision Split e Tube</a></li>
<li><a href="../pt404147/index.html">Som, vocÃª Ã© apenas "espaÃ§o": fones de ouvido Campfire Audio Andromeda</a></li>
<li><a href="../pt404149/index.html">RevisÃ£o do leitor impermeÃ¡vel de nova geraÃ§Ã£o PocketBook 641 Aqua 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👐🏻 🐭 👩🏼‍🤝‍👨🏽 "Lock-free oder nicht lock-free, das ist die Frage" oder "Gesunder Schlaf ist schlimmer als bitterer Rettich" 👩‍🍳 ⏺️ 🤕</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Kommentare zum Artikel " Wie man richtig und falsch schläft " haben mich dazu inspiriert, diesen Artikel zu schreiben. 


 Dieser Artikel konzentr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>"Lock-free oder nicht lock-free, das ist die Frage" oder "Gesunder Schlaf ist schlimmer als bitterer Rettich"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428087/"><p>  Die Kommentare zum Artikel " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wie man richtig und falsch schläft</a> " haben mich dazu inspiriert, diesen Artikel zu schreiben. </p><br><p>  Dieser Artikel konzentriert sich auf die Entwicklung von Multithread-Anwendungen, die Anwendbarkeit von Lock-Free auf einige Fälle, die bei der Arbeit an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LAppS auftreten</a> , die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nanosleep-</a> Funktion und Gewalt gegen den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Taskplaner</a> . </p><br><pre><code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">NB</span></span>:      <span class="hljs-selector-tag"><span class="hljs-selector-tag">C</span></span>++  <span class="hljs-selector-tag"><span class="hljs-selector-tag">Linux</span></span>,       <span class="hljs-selector-tag"><span class="hljs-selector-tag">POSIX</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.1-2008</span></span>  <span class="hljs-selector-tag"><span class="hljs-selector-tag">a</span></span> (    ).</code> </pre> <br><p>  Im Allgemeinen ist alles ziemlich chaotisch, ich hoffe, der Gedankengang in der Präsentation wird klar sein.  Bei Interesse bitte ich um eine Katze. </p><a name="habracut"></a><br><p>  Eventorientierte Software wartet immer auf etwas.  Unabhängig davon, ob es sich um eine GUI oder einen Netzwerkserver handelt, warten sie auf Ereignisse: Tastatureingaben, Mauseignisse, Datenpakete, die über das Netzwerk eingehen.  Aber jede Software wartet anders.  Lock-freie Systeme müssen überhaupt nicht warten.  Zumindest sollte die Verwendung von sperrfreien Algorithmen dort erfolgen, wo Sie nicht warten müssen, und sogar schädlich.  Wir sprechen jedoch von wettbewerbsfähigen (Multithread-) Systemen, und seltsamerweise warten auch sperrfreie Algorithmen.  Ja, sie blockieren nicht die Ausführung paralleler Threads, aber sie selbst warten auf die Gelegenheit, etwas zu tun, ohne zu blockieren. </p><br><p>  LAppS verwendet Mutexe und Semaphoren sehr aktiv.  Der C ++ - Standard enthält jedoch keine Semaphoren.  Der Mechanismus ist sehr wichtig und praktisch, aber C ++ sollte auf Systemen funktionieren, die keine Semaphorunterstützung bieten, und daher sind Semaphoren nicht im Standard enthalten.  Wenn ich Semaphoren verwende, weil sie bequem sind, dann Mutexe, weil ich muss. </p><br><p>  Das Verhalten des Mutex im Fall von Competitive Lock () wie sem_wait () unter Linux setzt den wartenden Thread am Ende der Taskplaner-Warteschlange. Wenn er sich oben befindet, wird die Prüfung wiederholt, ohne zum Benutzerland zurückzukehren. Wenn der Thread zurück in das Benutzerland zurückkehrt, wird er zurück in die Warteschlange gestellt Das erwartete Ereignis ist noch nicht eingetreten.  Dies ist ein sehr wichtiger Punkt. </p><br><p>  Und ich habe mich entschlossen zu prüfen, ob ich std :: mutex- und POSIX-Semaphoren ablehnen kann, indem ich sie mit std :: atomic emuliere und die Last hauptsächlich auf userland übertrage.  Eigentlich gescheitert, aber das Wichtigste zuerst. </p><br><p>  Erstens habe ich mehrere Abschnitte, in denen diese Experimente nützlich sein könnten: </p><br><ul><li>  sperrt in LibreSSL (Fall 1); </li><li>  Blockieren beim Übertragen von empfangenen Nutzlastpaketen an Lua-Anwendungen (Fall 2); </li><li>  Warten auf Nutzdatenereignisse, die von Lua-Anwendungen verarbeitet werden können (Fall 3). </li></ul><br><p>  Beginnen wir mit nicht blockierenden Sperren.  Schreiben wir unseren Mutex mit Atomics, wie in einigen Reden von H. Sutter gezeigt (es gibt daher keinen Originalcode aus dem Speicher und daher stimmt der Code nicht mit den ursprünglichen 100% überein, und in Satter war dieser Code mit dem Fortschritt von C ++ 20 verbunden). daher gibt es Unterschiede).  Und trotz der Einfachheit dieses Codes gibt es Fallstricke. </p><br><pre> <code class="hljs kotlin">#include &lt;atomic&gt; #include &lt;pthread.h&gt; namespace test { <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">mutex</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span>: std::atomic&lt;pthread_t&gt; mLock; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span>: explicit mutex():mLock{<span class="hljs-number"><span class="hljs-number">0</span></span>} { } mutex(<span class="hljs-keyword"><span class="hljs-keyword">const</span></span> mutex&amp;)=delete; mutex(mutex&amp;)=delete; void lock() { pthread_t locked_by=<span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//  C++20     , .. compare_exchange_strong          while(!mLock.compare_exchange_strong(locked_by,pthread_self())) { locked_by=0; //      } } void unlock() { pthread_t current=pthread_self(); if(!mLock.compare_exchange_strong(current,0)) { throw std::system_error(EACCES, std::system_category(), "An attempt to unlock the mutex owned by other thread"); } } const bool try_lock() { pthread_t unused=0; return mLock.compare_exchange_strong(unused,pthread_self()); } }; }</span></span></code> </pre> <br><p>  Im Gegensatz zu std :: mutex :: entsperren () ist das Verhalten von test :: mutex: entsperren () beim Versuch, von einem anderen Thread zu entsperren, deterministisch.  Eine Ausnahme wird ausgelöst.  Dies ist gut, entspricht jedoch nicht dem Standardverhalten.  Und was ist schlecht in dieser Klasse?  Die schlechte Nachricht ist, dass die test :: mutex: lock () -Methode schamlos CPU-Ressourcen in Zeitkontingenten verbraucht, die dem Thread zugewiesen sind, um den Mutex zu übernehmen, den ein anderer Thread bereits besitzt.  Das heißt,  Eine Schleife in test :: mutex: lock () verschwendet CPU-Ressourcen.  Welche Möglichkeiten haben wir, um diese Situation zu überwinden? </p><br><p>  Wir können sched_yield () verwenden (wie in einem der Kommentare zum obigen Artikel vorgeschlagen).  Ist es so einfach?  Erstens ist es für die Verwendung von sched_yield () erforderlich, dass Ausführungsthreads die Richtlinien SCHED_RR, SCHED_FIFO für ihre Priorisierung im Taskplaner verwenden.  Andernfalls wäre der Aufruf von sched_yield () eine Verschwendung von CPU-Ressourcen.  Zweitens erhöht ein sehr häufiger Aufruf von sched_yield () den CPU-Verbrauch.  Darüber hinaus beschränkt die Verwendung von Echtzeitrichtlinien in Ihrer Anwendung und vorausgesetzt, dass keine anderen Echtzeitanwendungen im System vorhanden sind, die Scheduler-Warteschlange mit der ausgewählten Richtlinie nur auf Ihre Threads.  Es scheint, dass das gut ist!  Nein, nicht gut.  Das ganze System wird weniger reaktionsschnell, weil  beschäftigt mit Prioritätsaufgabe.  CFQ wird im Stift sein.  Es gibt jedoch andere Threads in der Anwendung, und sehr häufig tritt eine Situation auf, wenn der Thread, der den Mutex erfasst hat, am Ende der Warteschlange steht (das Kontingent ist abgelaufen) und der Thread, der darauf wartet, dass der Mutex direkt davor freigegeben wird.  In meinen Experimenten (Fall 2) ergab diese Methode ungefähr die gleichen Ergebnisse (3,8% schlechter) wie std :: mutex, aber das System reagiert weniger und der CPU-Verbrauch wird um 5% bis 7% erhöht. </p><br><p>  Sie können versuchen, test :: mutex :: lock () wie folgt zu ändern (auch schlecht): </p><br><pre> <code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lock</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">pthread_t</span></span> locked_by=<span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>(!mLock.compare_exchange_strong(locked_by,pthread_self())) { <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">thread_local</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">timespec</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">pause</span></span></span><span class="hljs-class">{</span></span><span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">4</span></span>}; <span class="hljs-comment"><span class="hljs-comment">// -      nanosleep(&amp;pause,nullptr); locked_by=0; } }</span></span></code> </pre> <br><p>  Hier können Sie mit der Schlafdauer in Nanosekunden experimentieren, 4 ns Verzögerungen waren für meine CPU optimal und der Leistungsabfall gegenüber std :: mutex im selben Fall 2 betrug 1,2%.  Nicht die Tatsache, dass Nanosleep 4 ns schlief.  In der Tat oder mehr (im allgemeinen Fall) oder weniger (wenn unterbrochen).  Der Rückgang (!) Des CPU-Verbrauchs betrug 12% -20%.  Das heißt,  Es war so ein gesunder Traum. </p><br><p>  OpenSSL und LibreSSL verfügen über zwei Funktionen, mit denen Rückrufe zum Blockieren eingerichtet werden, wenn diese Bibliotheken in einer Umgebung mit mehreren Threads verwendet werden.  Es sieht so aus: </p><br><pre> <code class="hljs pgsql">//  callback <span class="hljs-type"><span class="hljs-type">void</span></span> openssl_crypt_locking_function_callback(<span class="hljs-type"><span class="hljs-type">int</span></span> mode, <span class="hljs-type"><span class="hljs-type">int</span></span> n, const <span class="hljs-type"><span class="hljs-type">char</span></span>* file, const <span class="hljs-type"><span class="hljs-type">int</span></span> <span class="hljs-type"><span class="hljs-type">line</span></span>) { static std::vector&lt;std::mutex&gt; locks(CRYPTO_num_locks()); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(n&gt;=static_cast&lt;<span class="hljs-type"><span class="hljs-type">int</span></span>&gt;(locks.size())) { <span class="hljs-keyword"><span class="hljs-keyword">abort</span></span>(); } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(mode &amp; CRYPTO_LOCK) locks[n].<span class="hljs-keyword"><span class="hljs-keyword">lock</span></span>(); <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> locks[n].unlock(); } //  callback-a CRYPTO_set_locking_callback(openssl_crypt_locking_function_callback); //  id CRYPTO_set_id_callback(pthread_self);</code> </pre> <br><p>  Und jetzt ist das Schlimmste, dass die Verwendung des obigen Tests :: mutex mutex in LibreSSL die Leistung von LAppS um fast das Zweifache reduziert.  Unabhängig von der Option (leere Warteschleife, sched_yield (), nanosleep ()). </p><br><p>  Im Allgemeinen löschen wir Fall 2 und Fall 1 und bleiben bei std :: mutex. </p><br><p>  Kommen wir zu den Semaphoren.  Es gibt viele Beispiele für die Implementierung von Semaphoren mit std :: condition_variable.  Sie alle verwenden ebenfalls std :: mutex.  Und solche Semaphorsimulatoren sind (nach meinen Tests) langsamer als POSIX-Systemsemaphoren. </p><br><p>  Deshalb werden wir ein Semaphor über Atome machen: </p><br><pre> <code class="hljs java"> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">semaphore</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span>: std::atomic&lt;bool&gt; mayRun; mutable std::atomic&lt;int64_t&gt; counter; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span>: <span class="hljs-function"><span class="hljs-function">explicit </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">semaphore</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> : mayRun</span></span>{<span class="hljs-keyword"><span class="hljs-keyword">true</span></span>},counter{<span class="hljs-number"><span class="hljs-number">0</span></span>} { } semaphore(<span class="hljs-keyword"><span class="hljs-keyword">const</span></span> semaphore&amp;)=delete; semaphore(semaphore&amp;)=delete; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">const</span></span></span><span class="hljs-function"> bool </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">post</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">const</span></span></span><span class="hljs-function"> </span></span>{ ++counter; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mayRun.load(); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">const</span></span></span><span class="hljs-function"> bool </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">try_wait</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(mayRun.load()) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(counter.fetch_sub(<span class="hljs-number"><span class="hljs-number">1</span></span>)&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { ++counter; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>; } }<span class="hljs-keyword"><span class="hljs-keyword">else</span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> std::system_error(ENOENT,std::system_category(),<span class="hljs-string"><span class="hljs-string">"Semaphore is destroyed"</span></span>); } } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wait</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>(!try_wait()) { <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> thread_local <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> struct timespec pause{<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">4</span></span>}; nanosleep(&amp;pause,nullptr); } } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">destroy</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ mayRun.store(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">const</span></span></span><span class="hljs-function"> int64_t </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">decrimentOn</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> size_t value)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(mayRun.load()) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> counter.fetch_sub(value); }<span class="hljs-keyword"><span class="hljs-keyword">else</span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> std::system_error(ENOENT,std::system_category(),<span class="hljs-string"><span class="hljs-string">"Semaphore is destroyed"</span></span>); } } ~semaphore() { destroy(); } };</code> </pre> <br><p>  Oh, dieses Semaphor ist um ein Vielfaches schneller als das Systemsemaphor.  Das Ergebnis eines separaten Tests dieses Semaphors mit einem Anbieter und 20 Verbrauchern: </p><br><pre> <code class="hljs bash">OS semaphores <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>. Started 20 threads waiting on a semaphore Thread(OS): wakes: 500321 Thread(OS): wakes: 500473 Thread(OS): wakes: 501504 Thread(OS): wakes: 502337 Thread(OS): wakes: 498324 Thread(OS): wakes: 502755 Thread(OS): wakes: 500212 Thread(OS): wakes: 498579 Thread(OS): wakes: 499504 Thread(OS): wakes: 500228 Thread(OS): wakes: 499696 Thread(OS): wakes: 501978 Thread(OS): wakes: 498617 Thread(OS): wakes: 502238 Thread(OS): wakes: 497797 Thread(OS): wakes: 498089 Thread(OS): wakes: 499292 Thread(OS): wakes: 498011 Thread(OS): wakes: 498749 Thread(OS): wakes: 501296 OS semaphores <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>. 10000000 of posts <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> 20 waiting threads have taken 9924 milliseconds OS semaphores <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>. Post latency: 0.9924ns ======================================= AtomicEmu semaphores <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>. Started 20 threads waiting on a semaphore Thread(EmuAtomic) wakes: 492748 Thread(EmuAtomic) wakes: 546860 Thread(EmuAtomic) wakes: 479375 Thread(EmuAtomic) wakes: 534676 Thread(EmuAtomic) wakes: 501014 Thread(EmuAtomic) wakes: 528220 Thread(EmuAtomic) wakes: 496783 Thread(EmuAtomic) wakes: 467563 Thread(EmuAtomic) wakes: 608086 Thread(EmuAtomic) wakes: 489825 Thread(EmuAtomic) wakes: 479799 Thread(EmuAtomic) wakes: 539634 Thread(EmuAtomic) wakes: 479559 Thread(EmuAtomic) wakes: 495377 Thread(EmuAtomic) wakes: 454759 Thread(EmuAtomic) wakes: 482375 Thread(EmuAtomic) wakes: 512442 Thread(EmuAtomic) wakes: 453303 Thread(EmuAtomic) wakes: 480227 Thread(EmuAtomic) wakes: 477375 AtomicEmu semaphores <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>. 10000000 of posts <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> 20 waiting threads have taken 341 milliseconds AtomicEmu semaphores <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>. Post latency: 0.0341ns</code> </pre><br><p>  Dieses Semaphor mit fast freiem Post (), das 29-mal schneller als das System ist, weckt auch die darauf wartenden Threads sehr schnell auf: 29325 Aufwecken pro Millisekunde gegenüber 1007 Aufwecken pro Millisekunde vom System.  Es hat deterministisches Verhalten mit einem zerstörten Semaphor oder einem zerstörbaren Semaphor.  Und natürlich Segfault beim Versuch, einen bereits zerstörten zu verwenden. </p><br><p>  (¹) Tatsächlich kann ein Stream so oft in einer Millisekunde nicht vom Scheduler verzögert und geweckt werden.  Weil  post () blockiert nicht. In diesem synthetischen Test befindet sich wait () sehr oft in einer Situation, in der Sie nicht schlafen müssen.  Gleichzeitig lesen mindestens 7 Threads parallel den Wert des Semaphors. </p><br><p>  Die Verwendung in Fall 3 in LAppS führt jedoch unabhängig von der Schlafzeit zu Leistungsverlusten.  Er wacht zu oft auf, um dies zu überprüfen, und Ereignisse in LAppS kommen viel langsamer an (Netzwerklatenz, Latenz der Clientseite, die die Last erzeugt, usw.).  Weniger häufig zu prüfen bedeutet auch Leistungseinbußen. </p><br><p>  Darüber hinaus ist die Verwendung von Schlaf in solchen Fällen und auf ähnliche Weise völlig schädlich, weil  Auf einer anderen Hardware können sich die Ergebnisse als völlig anders herausstellen (wie im Fall der Assembler-Anweisungspause), und für jedes CPU-Modell müssen Sie auch die Verzögerungszeit auswählen. </p><br><p>  Der Vorteil eines Systemmutex und -semaphors besteht darin, dass der Ausführungsthread erst dann aktiviert wird, wenn ein Ereignis (Entsperren des Mutex oder Inkrementieren des Semaphors) auftritt.  Zusätzliche CPU-Zyklen werden nicht verschwendet - Gewinn. </p><br><p>  Im Allgemeinen bringt alles von diesem bösen, das Deaktivieren von iptables auf meinem System von 12% (mit TLS) bis 30% (ohne TLS) einen Leistungsgewinn ... </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428087/">https://habr.com/ru/post/de428087/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428077/index.html">React.js: Ein Leitfaden für Anfänger</a></li>
<li><a href="../de428079/index.html">Anwendung von SOLID-Prinzipien zur Reaktion auf die Anwendungsentwicklung</a></li>
<li><a href="../de428081/index.html">Verwenden von RxJS in der Reaktionsentwicklung zum Verwalten des Anwendungsstatus</a></li>
<li><a href="../de428083/index.html">Webanalyse beeinflusst Matrix - das strategische System von Avinash Koshik</a></li>
<li><a href="../de428085/index.html">Frontend schlägt zurück: Top 10 (?) HolyJS 2018 Piter berichtet</a></li>
<li><a href="../de428089/index.html">"Testerkalender" für Oktober. Feedback: wie es passiert</a></li>
<li><a href="../de428091/index.html">Wie ein Praktikant das weltweit beliebteste Videospiel oder die Windows-Spielhistorie erstellt hat</a></li>
<li><a href="../de428095/index.html">Marktforschung für Webstudios und digitale Agenturen</a></li>
<li><a href="../de428097/index.html">Rekursives Routing in MikroTik über von DHCP zugewiesene Gateways</a></li>
<li><a href="../de428099/index.html">Was haben gewöhnliche Kleider und die bevorstehende 5G-Ära gemeinsam?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ñ∂Ô∏è üöâ üö∑ Vous cherchez un espace de stationnement gratuit avec Python üòÇ ‚ìÇÔ∏è ü§úüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Je vis dans une bonne ville. Mais, comme dans beaucoup d'autres, la recherche d'une place de parking se transforme toujours en test. Les espaces libre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vous cherchez un espace de stationnement gratuit avec Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451164/"><img src="https://habrastorage.org/webt/vz/x5/od/vzx5odyqel0ow-z2qolfdo1htd4.gif" alt="image"><br><br>  Je vis dans une bonne ville.  Mais, comme dans beaucoup d'autres, la recherche d'une place de parking se transforme toujours en test.  Les espaces libres occupent rapidement, et m√™me si vous en avez un, vos amis auront du mal √† vous appeler car ils n'auront nulle part o√π se garer. <br><br>  J'ai donc d√©cid√© de pointer la cam√©ra par la fen√™tre et d'utiliser le deep learning pour que mon ordinateur me dise quand l'espace est disponible: <br><br><img src="https://habrastorage.org/webt/lx/md/gy/lxmdgyxkvnwtwc5nsqccy83mp34.gif" alt="image"><br><br>  Cela peut sembler compliqu√©, mais l'√©criture d'un prototype fonctionnel avec un apprentissage approfondi est rapide et facile.  Tous les composants n√©cessaires sont d√©j√† l√† - il vous suffit de savoir o√π les trouver et comment les assembler. <br><br>  Alors amusons-nous et √©crivons un syst√®me pr√©cis de notification de stationnement gratuit en utilisant Python et l'apprentissage en profondeur <a name="habracut"></a><br><br><h3>  D√©composer la t√¢che </h3><br>  Lorsque nous avons une t√¢che difficile que nous voulons r√©soudre √† l'aide de l'apprentissage automatique, la premi√®re √©tape consiste √† la d√©composer en une s√©quence de t√¢ches simples.  Ensuite, nous pouvons utiliser diff√©rents outils pour r√©soudre chacun d'eux.  En combinant plusieurs solutions simples ensemble, nous obtenons un syst√®me capable de quelque chose de complexe. <br><br>  Voici comment j'ai rompu ma t√¢che: <br><br><img src="https://habrastorage.org/webt/q7/gi/hi/q7gihifth7-k9mad7fhgbj4itcc.jpeg" alt="image"><br><br>  Le flux vid√©o de la webcam dirig√© vers la fen√™tre entre dans l'entr√©e du convoyeur: <br><br><img src="https://habrastorage.org/webt/aa/wk/ig/aawkigsexhbk5s4slqmvksvofcm.gif" alt="image"><br><br>  Gr√¢ce au pipeline, nous transmettrons chaque image de la vid√©o, une √† la fois. <br><br>  La premi√®re √©tape consiste √† reconna√Ætre toutes les places de stationnement possibles dans le cadre.  √âvidemment, avant de pouvoir rechercher des lieux inoccup√©s, nous devons comprendre dans quelles parties de l'image il y a du stationnement. <br><br>  Ensuite, sur chaque cadre, vous devez trouver toutes les voitures.  Cela nous permettra de suivre le mouvement de chaque machine d'un ch√¢ssis √† l'autre. <br><br>  La troisi√®me √©tape consiste √† d√©terminer quels endroits sont occup√©s par des machines et lesquels ne le sont pas.  Pour ce faire, combinez les r√©sultats des deux premi√®res √©tapes. <br><br>  Enfin, le programme devrait envoyer une alerte lorsque la place de parking devient libre.  Cela sera d√©termin√© par les changements d'emplacement des machines entre les images de la vid√©o. <br><br>  Chacune de ces √©tapes peut √™tre effectu√©e de diff√©rentes mani√®res en utilisant diff√©rentes technologies.  Il n'y a pas de bonne ou de mauvaise fa√ßon de composer ce convoyeur; diff√©rentes approches auront leurs avantages et leurs inconv√©nients.  Examinons chaque √©tape plus en d√©tail. <br><br><h3>  Nous reconnaissons les espaces de stationnement </h3><br>  Voici ce que voit notre cam√©ra: <br><br><img src="https://habrastorage.org/webt/2u/zl/xt/2uzlxtgxbn6jvfkhfy0e523ow88.png" alt="image"><br><br>  Nous devons en quelque sorte scanner cette image et obtenir une liste des endroits pour se garer: <br><br><img src="https://habrastorage.org/webt/m-/bq/xb/m-bqxb9ybcjc44blvsuzhnw6xyk.png" alt="image"><br><br>  La solution ¬´dans le front¬ª serait de simplement coder en dur les emplacements de toutes les places de stationnement manuellement au lieu de les reconna√Ætre automatiquement.  Mais dans ce cas, si nous bougeons la cam√©ra ou si nous voulons chercher des places de parking dans une autre rue, nous devrons refaire toute la proc√©dure.  Cela sonne tellement, alors cherchons un moyen automatique de reconna√Ætre les places de stationnement. <br><br>  Alternativement, vous pouvez rechercher des parcm√®tres dans l'image et supposer qu'il y a une place de parking √† c√¥t√© de chacun d'eux: <br><br><img src="https://habrastorage.org/webt/qi/g8/cj/qig8cjwmp7dmduejcddjk6tnoiw.png" alt="image"><br><br>  Cependant, avec cette approche, tout n'est pas si fluide.  Premi√®rement, toutes les places de stationnement n'ont pas de parcm√®tre, et en effet, nous sommes plus int√©ress√©s √† trouver des places de stationnement pour lesquelles vous n'avez pas √† payer.  Deuxi√®mement, l'emplacement du parcm√®tre ne nous dit rien sur l'emplacement de l'espace de stationnement, mais nous permet seulement de faire une hypoth√®se. <br><br>  Une autre id√©e est de cr√©er un mod√®le de reconnaissance d'objets qui recherche les marques d'espace de stationnement trac√©es sur la route: <br><br><img src="https://habrastorage.org/webt/bo/vv/nu/bovvnu6rsl-zimlr1gtpp1a_egm.png" alt="image"><br><br>  Mais cette approche est moyenne.  Premi√®rement, dans ma ville, toutes ces marques sont tr√®s petites et difficiles √† voir √† distance, il sera donc difficile de les d√©tecter √† l'aide d'un ordinateur.  Deuxi√®mement, la rue est pleine de toutes sortes d'autres lignes et marques.  Il sera difficile de s√©parer les marques de stationnement des s√©parateurs de voies et des passages pour pi√©tons. <br><br>  Lorsque vous rencontrez un probl√®me qui semble difficile √† premi√®re vue, prenez quelques minutes pour trouver une autre approche pour r√©soudre le probl√®me, ce qui vous aidera √† contourner certains probl√®mes techniques.  Qu'y a-t-il une place de parking?  C'est juste un endroit o√π une voiture est gar√©e pendant longtemps.  Peut-√™tre n'avons-nous pas du tout besoin de reconna√Ætre les places de stationnement.  Pourquoi ne reconnaissons-nous pas simplement les voitures qui restent immobiles pendant longtemps et ne supposons-nous pas qu'elles se trouvent dans l'espace de stationnement? <br><br>  En d'autres termes, les places de stationnement sont situ√©es l√† o√π les voitures se trouvent pendant longtemps: <br><br><img src="https://habrastorage.org/webt/b8/tb/ua/b8tbuafyf4uci3jy61jnjlwanqa.png" alt="image"><br><br>  Ainsi, si nous pouvons reconna√Ætre les voitures et savoir lesquelles ne se d√©placent pas entre les cadres, nous pouvons deviner o√π se trouvent les places de stationnement.  Aussi simple que cela - passez √† la reconnaissance de la machine! <br><br><h3>  Reconna√Ætre les voitures </h3><br>  Reconna√Ætre des voitures sur une image vid√©o est une t√¢che classique de reconnaissance d'objets.  Il existe de nombreuses approches d'apprentissage automatique que nous pourrions utiliser pour la reconnaissance.  En voici quelques-unes dans l'ordre de la ¬´vieille √©cole¬ª √† la ¬´nouvelle √©cole¬ª: <br><br><ul><li>  Vous pouvez entra√Æner le d√©tecteur sur la base du HOG (histogramme des gradients orient√©s, histogrammes des gradients directionnels) et le parcourir toute l'image pour trouver toutes les voitures.  Cette ancienne approche, qui n'utilise pas le deep learning, fonctionne relativement rapidement, mais ne fonctionne pas tr√®s bien avec des machines situ√©es de diff√©rentes mani√®res. </li><li>  Vous pouvez entra√Æner le d√©tecteur bas√© sur CNN (Convolutional Neural Network, un r√©seau de neurones √† convolution) et le parcourir toute l'image jusqu'√† ce que nous trouvions toutes les machines.  Cette approche fonctionne exactement, mais pas aussi efficacement, car nous devons num√©riser l'image plusieurs fois √† l'aide de CNN pour trouver toutes les machines.  Et bien que nous puissions trouver des machines situ√©es de diff√©rentes mani√®res, nous avons besoin de beaucoup plus de donn√©es d'entra√Ænement que pour un d√©tecteur HOG. </li><li>  Vous pouvez utiliser une nouvelle approche avec un apprentissage en profondeur comme Mask R-CNN, Faster R-CNN ou YOLO, qui combine la pr√©cision de CNN et un ensemble de trucs techniques qui augmentent consid√©rablement la vitesse de reconnaissance.  De tels mod√®les fonctionneront relativement rapidement (sur le GPU) si nous avons beaucoup de donn√©es pour former le mod√®le. </li></ul><br>  Dans le cas g√©n√©ral, nous avons besoin de la solution la plus simple, qui fonctionnera comme elle le devrait et n√©cessitera le moins de donn√©es de formation.  Il n'est pas n√©cessaire que ce soit l'algorithme le plus r√©cent et le plus rapide.  Cependant, en particulier dans notre cas, le masque R-CNN est un choix raisonnable, malgr√© le fait qu'il soit assez nouveau et rapide. <br><br>  L'architecture Mask R-CNN est con√ßue de mani√®re √† reconna√Ætre les objets dans l'image enti√®re, √† d√©penser efficacement les ressources et √† ne pas utiliser l'approche √† fen√™tre coulissante.  En d'autres termes, cela fonctionne assez rapidement.  Avec un GPU moderne, nous pourrons reconna√Ætre des objets en vid√©o en haute r√©solution √† une vitesse de plusieurs images par seconde.  Pour notre projet, cela devrait suffire. <br><br>  De plus, Mask R-CNN fournit de nombreuses informations sur chaque objet reconnu.  La plupart des algorithmes de reconnaissance renvoient uniquement une bo√Æte englobante pour chaque objet.  Cependant, Mask R-CNN ne nous donnera pas seulement l'emplacement de chaque objet, mais aussi son contour (masque): <br><br><img src="https://habrastorage.org/webt/n2/b0/hp/n2b0hpwgwpkn6ahfhqetvbhq1rg.png" alt="image"><br><br>  Pour former Mask R-CNN, nous avons besoin de beaucoup d'images d'objets que nous voulons reconna√Ætre.  Nous pourrions sortir, prendre des photos de voitures et les marquer sur des photos, ce qui n√©cessiterait plusieurs jours de travail.  Heureusement, les voitures sont l'un de ces objets que les gens veulent souvent reconna√Ætre, il existe donc d√©j√† plusieurs jeux de donn√©es publics avec des images de voitures. <br><br>  L'un d'eux est le populaire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ensemble de donn√©es</a> SOCO (abr√©viation de Common Objects In Context), qui a des images annot√©es avec des masques d'objets.  Cet ensemble de donn√©es contient plus de 12 000 images avec des machines d√©j√† √©tiquet√©es.  Voici un exemple d'image de l'ensemble de donn√©es: <br><br><img src="https://habrastorage.org/webt/dv/lz/7l/dvlz7ltgwmudog9-b2f6i7tlmhe.jpeg" alt="image"><br><br>  Ces donn√©es sont excellentes pour la formation d'un mod√®le bas√© sur le masque R-CNN. <br><br>  Mais tenez les chevaux, il y a encore des nouvelles!  Nous ne sommes pas les premiers √† vouloir former leur mod√®le √† l'aide de l'ensemble de donn√©es COCO - de nombreuses personnes l'ont d√©j√† fait avant nous et ont partag√© leurs r√©sultats.  Par cons√©quent, au lieu de former notre mod√®le, nous pouvons prendre un mod√®le pr√™t √† l'emploi qui peut d√©j√† reconna√Ætre les voitures.  Pour notre projet, nous utiliserons le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®le open-source de Matterport.</a> <br><br>  Si nous donnons une image de la cam√©ra √† l'entr√©e de ce mod√®le, c'est ce que nous obtenons d√©j√† "hors de la bo√Æte": <br><br><img src="https://habrastorage.org/webt/vy/kq/50/vykq50pcxhyt_vkmfzmxk_fgl5g.png" alt="image"><br><br>  Le mod√®le a reconnu non seulement les voitures, mais aussi les objets tels que les feux de circulation et les personnes.  C'est dr√¥le qu'elle ait reconnu l'arbre comme plante d'int√©rieur. <br><br>  Pour chaque objet reconnu, le mod√®le Mask R-CNN renvoie 4 choses: <br><br><ul><li>  Type d'objet d√©tect√© (entier).  Le mod√®le COCO pr√©-form√© peut reconna√Ætre 80 objets communs diff√©rents comme les voitures et les camions.  Une liste compl√®te d'entre eux peut √™tre trouv√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici.</a> </li><li>  Le degr√© de confiance dans les r√©sultats de reconnaissance.  Plus le nombre est √©lev√©, plus le mod√®le est confiant dans la reconnaissance de l'objet. </li><li>  Un cadre de d√©limitation pour un objet sous la forme de coordonn√©es XY de pixels dans l'image. </li><li>  Un ¬´masque¬ª qui montre quels pixels dans le cadre de s√©lection font partie de l'objet.  En utilisant les donn√©es du masque, vous pouvez trouver le contour de l'objet. </li></ul><br>  Vous trouverez ci-dessous le code Python pour d√©tecter la bo√Æte englobante pour les machines utilisant les mod√®les Mask R-CNN et OpenCV pr√©-form√©s: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-comment"><span class="hljs-comment"># ,     Mask-RCNN. class MaskRCNNConfig(mrcnn.config.Config): NAME = "coco_pretrained_model_config" IMAGES_PER_GPU = 1 GPU_COUNT = 1 NUM_CLASSES = 1 + 80 #   COCO  80  + 1  . DETECTION_MIN_CONFIDENCE = 0.6 #    ,    . def get_car_boxes(boxes, class_ids): car_boxes = [] for i, box in enumerate(boxes): #     ,   . if class_ids[i] in [3, 8, 6]: car_boxes.append(box) return np.array(car_boxes) #   . ROOT_DIR = Path(".") #       . MODEL_DIR = ROOT_DIR / "logs" #       . COCO_MODEL_PATH = ROOT_DIR / "mask_rcnn_coco.h5" #   COCO  . if not COCO_MODEL_PATH.exists(): mrcnn.utils.download_trained_weights(COCO_MODEL_PATH) #     . IMAGE_DIR = ROOT_DIR / "images" #      ‚Äî   0,    ,   . VIDEO_SOURCE = "test_images/parking.mp4" #   Mask-RCNN   . model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig()) #   . model.load_weights(COCO_MODEL_PATH, by_name=True) #   . parked_car_boxes = None #  ,     . video_capture = cv2.VideoCapture(VIDEO_SOURCE) #      . while video_capture.isOpened(): success, frame = video_capture.read() if not success: break #      BGR ( OpenCV)  RGB. rgb_image = frame[:, :, ::-1] #    Mask R-CNN   . results = model.detect([rgb_image], verbose=0) # Mask R-CNN ,       . #     ,     . r = results[0] #  r    : # - r['rois'] ‚Äî      ; # - r['class_ids'] ‚Äî  () ; # - r['scores'] ‚Äî  ; # - r['masks'] ‚Äî   (    ). #      . car_boxes = get_car_boxes(r['rois'], r['class_ids']) print("Cars found in frame of video:") #     . for box in car_boxes: print("Car:", box) y1, x1, y2, x2 = box #  . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1) #    . cv2.imshow('Video', frame) #  'q',  . if cv2.waitKey(1) &amp; 0xFF == ord('q'): break #    . video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre> <br>  Apr√®s avoir ex√©cut√© ce script, une image avec un cadre autour de chaque machine d√©tect√©e appara√Ætra √† l'√©cran: <br><br><img src="https://habrastorage.org/webt/_p/il/0r/_pil0reoz3gj7dtqboav_rgerl8.jpeg" alt="image"><br><br>  De plus, les coordonn√©es de chaque machine seront affich√©es dans la console: <br><br><pre> <code class="python hljs">Cars found <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> frame of video: Car: [<span class="hljs-number"><span class="hljs-number">492</span></span> <span class="hljs-number"><span class="hljs-number">871</span></span> <span class="hljs-number"><span class="hljs-number">551</span></span> <span class="hljs-number"><span class="hljs-number">961</span></span>] Car: [<span class="hljs-number"><span class="hljs-number">450</span></span> <span class="hljs-number"><span class="hljs-number">819</span></span> <span class="hljs-number"><span class="hljs-number">509</span></span> <span class="hljs-number"><span class="hljs-number">913</span></span>] Car: [<span class="hljs-number"><span class="hljs-number">411</span></span> <span class="hljs-number"><span class="hljs-number">774</span></span> <span class="hljs-number"><span class="hljs-number">470</span></span> <span class="hljs-number"><span class="hljs-number">856</span></span>]</code> </pre><br>  Nous avons donc appris √† reconna√Ætre les voitures dans l'image. <br><br><h3>  Nous reconnaissons les espaces de stationnement vides </h3><br>  Nous connaissons les coordonn√©es en pixels de chaque machine.  En regardant √† travers plusieurs cadres cons√©cutifs, nous pouvons facilement d√©terminer laquelle des voitures n'a pas boug√© et supposer qu'il y a des places de parking.  Mais comment comprendre que la voiture a quitt√© le parking? <br><br>  Le probl√®me est que les ch√¢ssis des machines se chevauchent partiellement: <br><br><img src="https://habrastorage.org/webt/7t/vi/4q/7tvi4q1rgvkfkaljrsp8sjathr0.jpeg" alt="image"><br><br>  Par cons√©quent, si vous imaginez que chaque ch√¢ssis repr√©sente un espace de stationnement, il peut s'av√©rer qu'il est partiellement occup√© par la machine, alors qu'en fait il est vide.  Nous devons trouver un moyen de mesurer le degr√© d'intersection de deux objets afin de rechercher uniquement les cadres ¬´les plus vides¬ª. <br><br>  Nous utiliserons une mesure appel√©e Intersection Over Union (rapport de l'aire d'intersection √† l'aire totale) ou IoU.  IoU peut √™tre trouv√© en calculant le nombre de pixels o√π deux objets se croisent et en divisant par le nombre de pixels occup√©s par ces objets: <br><br><img src="https://habrastorage.org/webt/zs/c0/sz/zsc0szsct8xjwkx5eo-6ieynfuc.png" alt="image"><br><br>  Ainsi, nous pouvons comprendre comment le cadre tr√®s d√©limit√© de la voiture croise le cadre de l'espace de stationnement.  Cela vous permettra de d√©terminer facilement si le stationnement est gratuit.  Si la valeur IoU est faible, comme 0,15, alors la voiture occupe une petite partie de l'espace de stationnement.  Et si elle est √©lev√©e, comme 0,6, cela signifie que la voiture occupe la majeure partie de l'espace et que vous ne pouvez pas vous y garer. <br><br>  √âtant donn√© que l'IoU est utilis√© assez souvent en vision par ordinateur, il est tr√®s probable que les biblioth√®ques correspondantes mettent en ≈ìuvre cette mesure.  Dans notre biblioth√®que Mask R-CNN, il est impl√©ment√© comme une fonction mrcnn.utils.compute_overlaps (). <br><br>  Si nous avons une liste de bo√Ætes de d√©limitation pour les espaces de stationnement, vous pouvez ajouter un contr√¥le de la pr√©sence de voitures dans ce cadre en ajoutant une ligne enti√®re ou deux de code: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#      . car_boxes = get_car_boxes(r['rois'], r['class_ids']) # ,        . overlaps = mrcnn.utils.compute_overlaps(car_boxes, parking_areas) print(overlaps)</span></span></code> </pre><br>  Le r√©sultat devrait ressembler √† ceci: <br><br><pre> <code class="python hljs">[ [<span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-number"><span class="hljs-number">0.07040032</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] [<span class="hljs-number"><span class="hljs-number">0.07040032</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-number"><span class="hljs-number">0.07673165</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] [<span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.02332112</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] ]</code> </pre><br>  Dans ce tableau √† deux dimensions, chaque rang√©e refl√®te une image de l'espace de stationnement.  Et chaque colonne indique √† quel point chacun des endroits croise fortement avec l'une des machines d√©tect√©es.  Un r√©sultat de 1,0 signifie que toute la place est compl√®tement occup√©e par la voiture, et une valeur faible comme 0,02 indique que la voiture s'est un peu mise en place, mais vous pouvez toujours vous garer dessus. <br><br>  Pour trouver des endroits inoccup√©s, il vous suffit de v√©rifier chaque ligne de ce tableau.  Si tous les nombres sont proches de z√©ro, alors la place est probablement gratuite! <br><br>  Cependant, gardez √† l'esprit que la reconnaissance d'objets ne fonctionne pas toujours parfaitement avec la vid√©o en temps r√©el.  Bien que le mod√®le bas√© sur Mask R-CNN soit assez pr√©cis, il peut de temps en temps manquer une voiture ou deux dans une image de la vid√©o.  Par cons√©quent, avant d'affirmer que l'endroit est libre, vous devez vous assurer qu'il le reste pour les 5 √† 10 prochaines images de la vid√©o.  De cette fa√ßon, nous pouvons √©viter les situations o√π le syst√®me marque par erreur un endroit vide en raison d'un probl√®me dans une image de la vid√©o.  D√®s que nous nous assurons que le lieu reste libre pour plusieurs images, vous pouvez envoyer un message! <br><br><h3>  Envoyer un SMS </h3><br>  La derni√®re partie de notre convoyeur envoie des notifications par SMS lorsqu'une place de parking gratuite appara√Æt. <br><br>  L'envoi d'un message depuis Python est tr√®s facile si vous utilisez Twilio.  Twilio est une API populaire qui vous permet d'envoyer des SMS √† partir de presque n'importe quel langage de programmation avec seulement quelques lignes de code.  Bien s√ªr, si vous pr√©f√©rez un service diff√©rent, vous pouvez l'utiliser.  Je n'ai rien √† voir avec Twilio, c'est juste la premi√®re chose qui me vient √† l'esprit. <br><br>  Pour utiliser Twilio, inscrivez-vous pour un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">compte d'essai</a> , cr√©ez un num√©ro de t√©l√©phone Twilio et obtenez les informations d'authentification de votre compte.  Installez ensuite la biblioth√®que cliente: <br><br><pre> <code class="python hljs">$ pip3 install twilio</code> </pre><br>  Apr√®s cela, utilisez le code suivant pour envoyer le message: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> twilio.rest <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Client <span class="hljs-comment"><span class="hljs-comment">#   Twilio. twilio_account_sid = ' Twilio SID' twilio_auth_token = '   Twilio' twilio_source_phone_number = '   Twilio' #    Twilio. client = Client(twilio_account_sid, twilio_auth_token) #  SMS. message = client.messages.create( body=" ", from_=twilio_source_phone_number, to=" ,   " )</span></span></code> </pre><br>  Pour ajouter la possibilit√© d'envoyer des messages √† notre script, copiez simplement ce code l√†.  Cependant, vous devez vous assurer que le message n'est pas envoy√© sur chaque trame, o√π vous pouvez voir l'espace libre.  Par cons√©quent, nous aurons un indicateur qui, dans l'√©tat install√©, ne permettra pas d'envoyer des messages pendant un certain temps ou jusqu'√† ce qu'un autre endroit soit lib√©r√©. <br><br><h3>  Tout mettre ensemble </h3><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> twilio.rest <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Client <span class="hljs-comment"><span class="hljs-comment"># ,     Mask-RCNN. class MaskRCNNConfig(mrcnn.config.Config): NAME = "coco_pretrained_model_config" IMAGES_PER_GPU = 1 GPU_COUNT = 1 NUM_CLASSES = 1 + 80 #   COCO  80  + 1  . DETECTION_MIN_CONFIDENCE = 0.6 #    ,    . def get_car_boxes(boxes, class_ids): car_boxes = [] for i, box in enumerate(boxes): #     ,   . if class_ids[i] in [3, 8, 6]: car_boxes.append(box) return np.array(car_boxes) #  Twilio. twilio_account_sid = ' Twilio SID' twilio_auth_token = '   Twilio' twilio_phone_number = '   Twilio' destination_phone_number = ',   ' client = Client(twilio_account_sid, twilio_auth_token) #   . ROOT_DIR = Path(".") #       . MODEL_DIR = ROOT_DIR / "logs" #       . COCO_MODEL_PATH = ROOT_DIR / "mask_rcnn_coco.h5" #   COCO  . if not COCO_MODEL_PATH.exists(): mrcnn.utils.download_trained_weights(COCO_MODEL_PATH) #     . IMAGE_DIR = ROOT_DIR / "images" #      ‚Äî   0,   ,   . VIDEO_SOURCE = "test_images/parking.mp4" #   Mask-RCNN   . model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig()) #   . model.load_weights(COCO_MODEL_PATH, by_name=True) #   . parked_car_boxes = None #  ,     . video_capture = cv2.VideoCapture(VIDEO_SOURCE) #         . free_space_frames = 0 #    SMS? sms_sent = False #      . while video_capture.isOpened(): success, frame = video_capture.read() if not success: break #      BGR  RGB. rgb_image = frame[:, :, ::-1] #    Mask R-CNN   . results = model.detect([rgb_image], verbose=0) # Mask R-CNN ,       . #     ,     . r = results[0] #  r    : # - r['rois'] ‚Äî      ; # - r['class_ids'] ‚Äî  () ; # - r['scores'] ‚Äî  ; # - r['masks'] ‚Äî   (    ). if parked_car_boxes is None: #     ‚Äî ,       . #            . parked_car_boxes = get_car_boxes(r['rois'], r['class_ids']) else: #   ,  . ,   . #     . car_boxes = get_car_boxes(r['rois'], r['class_ids']) # ,         . overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes) # ,    ,      . free_space = False #        . for parking_area, overlap_areas in zip(parked_car_boxes, overlaps): #        #    (, ). max_IoU_overlap = np.max(overlap_areas) #         . y1, x1, y2, x2 = parking_area # ,   ,   IoU. if max_IoU_overlap &lt; 0.15: #  !     . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3) # ,        . free_space = True else: #     ‚Äî   . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1) #   IoU  . font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, f"{max_IoU_overlap:0.2}", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255)) #       ,   . #   ,  ,     #      . if free_space: free_space_frames += 1 else: #   ,  . free_space_frames = 0 #       ,  ,   . if free_space_frames &gt; 10: #   SPACE AVAILABLE!!  . font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, f"SPACE AVAILABLE!", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED) #  ,     . if not sms_sent: print("SENDING SMS!!!") message = client.messages.create( body="Parking space open - go go go!", from_=twilio_phone_number, to=destination_phone_number ) sms_sent = True #    . cv2.imshow('Video', frame) #  'q',  . if cv2.waitKey(1) &amp; 0xFF == ord('q'): break #  'q',  . video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre><br>  Pour ex√©cuter ce code, vous devez d'abord installer Python 3.6+, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Matterport Mask R-CNN</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenCV</a> . <br><br>  J'ai sp√©cifiquement √©crit le code aussi simple que possible.  Par exemple, s'il voit une voiture sur le premier cadre, il conclut qu'elles sont toutes gar√©es.  Essayez de l'exp√©rimenter et voyez si vous pouvez am√©liorer sa fiabilit√©. <br><br>  En changeant simplement les identifiants des objets que le mod√®le recherche, vous pouvez transformer le code en quelque chose de compl√®tement diff√©rent.  Par exemple, imaginez que vous travaillez dans une station de ski.  Apr√®s avoir apport√© quelques modifications, vous pouvez transformer ce script en un syst√®me qui reconna√Æt automatiquement les snowboarders sautant de la rampe et enregistre des vid√©os avec des sauts sympas.  Ou, si vous travaillez dans une r√©serve naturelle, vous pouvez cr√©er un syst√®me qui compte les z√®bres.  Vous n'√™tes limit√© que par votre imagination. <br><br>  D'autres articles de ce type peuvent √™tre lus dans la cha√Æne de t√©l√©gramme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Neuron</a> (@neurondata) <br><br>  Lien de traduction alternatif: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tproger.ru/translations/parking-searching/</a> <br><br>  Toutes les connaissances.  Exp√©rimentez! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451164/">https://habr.com/ru/post/fr451164/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451152/index.html">La r√©sistance dans le circuit de grille ou comment le faire correctement</a></li>
<li><a href="../fr451154/index.html">Syst√®me local autonome d'acquisition de donn√©es (suite)</a></li>
<li><a href="../fr451158/index.html">Circuits √©lectriques. Types de circuits</a></li>
<li><a href="../fr451160/index.html">Apache Kafka et le streaming avec Spark Streaming</a></li>
<li><a href="../fr451162/index.html">Correction d'erreurs - Constantes physiques dans les versions actuelles et nouvelles du syst√®me international d'unit√©s (SI)</a></li>
<li><a href="../fr451166/index.html">Qu'offriront les nouveaux r√©f√©rentiels pour les syst√®mes AI et MO?</a></li>
<li><a href="../fr451170/index.html">Jeff Bezos a annonc√© son intention de conqu√©rir la lune</a></li>
<li><a href="../fr451172/index.html">Julia: fonctions et structures en tant que fonctions</a></li>
<li><a href="../fr451174/index.html">Adaptation de programmes pour ZX Spectrum √† TR-DOS par des moyens modernes. Partie 1</a></li>
<li><a href="../fr451176/index.html">Nouvelles du monde d'OpenStreetMap n ¬∞ 458 (23/04/2019 - 09/09/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
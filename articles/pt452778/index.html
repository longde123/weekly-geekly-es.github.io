<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘© ğŸ˜“ ğŸ” Como acelerar o descarregamento do LZ4 no ClickHouse ğŸ¦• ğŸ˜© ğŸ“</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ao executar consultas no ClickHouse, vocÃª pode notar que, no criador de perfil, em um dos primeiros locais, a funÃ§Ã£o LZ_decompress_fast costuma estar ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como acelerar o descarregamento do LZ4 no ClickHouse</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/452778/"> Ao executar consultas no ClickHouse, vocÃª pode notar que, no criador de perfil, em um dos primeiros locais, a funÃ§Ã£o LZ_decompress_fast costuma estar visÃ­vel.  Por que isso estÃ¡ acontecendo?  Essa questÃ£o se tornou a razÃ£o de todo o estudo sobre a escolha do melhor algoritmo de descompressÃ£o.  Aqui publico o estudo inteiro, e a versÃ£o curta pode ser encontrada no meu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">relatÃ³rio</a> sobre o HighLoad ++ Siberia. <br><br>  Os dados do ClickHouse sÃ£o armazenados em formato compactado.  E durante a execuÃ§Ã£o de solicitaÃ§Ãµes, o ClickHouse tenta fazer quase nada - use um mÃ­nimo de recursos da CPU.  Acontece que todos os cÃ¡lculos que podem demorar um pouco jÃ¡ estÃ£o bem otimizados e a solicitaÃ§Ã£o Ã© bem escrita pelo usuÃ¡rio.  Resta entÃ£o executar o lanÃ§amento. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/302/aba/057302aba5041790af404c2c781c4dd3.png"><br><br>  A questÃ£o Ã©: por que o lanÃ§amento do LZ4 pode ser um gargalo?  Parece que o LZ4 Ã© um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">algoritmo muito leve</a> : a taxa de compactaÃ§Ã£o, dependendo dos dados, geralmente varia de 1 a 3 GB / s por nÃºcleo do processador.  Isso Ã© significativamente mais do que a velocidade do subsistema de disco.  AlÃ©m disso, usamos todos os kernels disponÃ­veis, e a expansÃ£o Ã© escalada linearmente em todos os kernels fÃ­sicos. <br><a name="habracut"></a><br>  Mas hÃ¡ dois pontos a serem lembrados.  Primeiro, os dados compactados sÃ£o lidos no disco e a taxa de compactaÃ§Ã£o Ã© fornecida na quantidade de dados nÃ£o compactados.  Se a taxa de compactaÃ§Ã£o for grande o suficiente, quase nada precisarÃ¡ ser lido nos discos.  Mas, ao mesmo tempo, muitos dados compactados sÃ£o gerados e, Ã© claro, isso afeta o consumo da CPU: a quantidade de trabalho de compactaÃ§Ã£o de dados no caso do LZ4 Ã© quase proporcional ao volume dos dados compactados. <br><br>  Em segundo lugar, a leitura de dados de discos pode nÃ£o ser necessÃ¡ria, se os dados estiverem no cache.  Para fazer isso, vocÃª pode confiar no cache da pÃ¡gina ou usar seu prÃ³prio cache.  Em um banco de dados de colunas, o uso do cache Ã© mais eficiente, pois nem todas as colunas caem nele, mas apenas as usadas com frequÃªncia.  Ã‰ por isso que o LZ4, em termos de carga da CPU, costuma ser um gargalo. <br><br>  DaÃ­ mais duas perguntas.  Se a compactaÃ§Ã£o de dados "diminuir", talvez eles nÃ£o devam ser compactados?  Mas, na prÃ¡tica, essa suposiÃ§Ã£o nÃ£o tem sentido.  Recentemente, no ClickHouse, foi possÃ­vel configurar apenas duas opÃ§Ãµes de compactaÃ§Ã£o de dados - LZ4 e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zstandard</a> .  O padrÃ£o Ã© LZ4.  Ao mudar para o Zstandard, vocÃª pode tornar a compactaÃ§Ã£o mais forte e mais lenta.  Mas era impossÃ­vel desativar completamente a compactaÃ§Ã£o atÃ© recentemente - o LZ4 Ã© considerado um mÃ­nimo razoÃ¡vel, que sempre pode ser usado.  Ã‰ por isso que eu realmente amo o LZ4.  :) <br><br>  Mas, recentemente, um estranho misterioso apareceu no chat do ClickHouse em inglÃªs, que disse ter um subsistema de disco muito rÃ¡pido (NVMe SSD) e tudo depende da compactaÃ§Ã£o - seria bom poder desativÃ¡-lo.  Respondi que nÃ£o existe essa possibilidade, mas Ã© fÃ¡cil acrescentar.  Alguns dias depois, recebemos uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">solicitaÃ§Ã£o de pool</a> , que implementa o mÃ©todo de compactaÃ§Ã£o <code>none</code> .  Eu pedi os resultados - quanto isso ajudou, com que rapidez os pedidos.  A pessoa disse que esse novo recurso acabou sendo inÃºtil na prÃ¡tica, pois os dados sem compactaÃ§Ã£o comeÃ§aram a ocupar muito espaÃ§o. <br><br>  A segunda pergunta que surge Ã©: se houver um cache, por que nÃ£o armazenar nele os dados nÃ£o compactados?  Isso Ã© permitido - em muitos casos, serÃ¡ possÃ­vel se livrar da necessidade de descompressÃ£o.  E no ClickHouse existe esse cache - um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cache de blocos expandidos</a> .  Mas Ã© uma pena gastar muita memÃ³ria RAM por causa de sua baixa eficiÃªncia.  Ele se justifica apenas em solicitaÃ§Ãµes pequenas e consecutivas que usam quase os mesmos dados. <br><br>  ConsideraÃ§Ã£o geral: os dados devem ser compactados, de preferÃªncia sempre.  Sempre grave-os em um disco compactado.  Transmitir pela rede tambÃ©m com compactaÃ§Ã£o.  Na minha opiniÃ£o, a compactaÃ§Ã£o padrÃ£o deve ser considerada justificada, mesmo ao transferir para uma rede de 10 gigabit sem excesso de inscriÃ§Ã£o no datacenter, e a transferÃªncia de dados sem compactaÃ§Ã£o entre datacenters Ã© geralmente inaceitÃ¡vel. <br><br><h3>  Por que LZ4? </h3><br>  Por que o LZ4 Ã© usado?  Ã‰ possÃ­vel escolher algo ainda mais fÃ¡cil?  Em princÃ­pio, Ã© possÃ­vel, e Ã© certo e Ãºtil.  Mas vamos primeiro examinar a que classe de algoritmos o LZ4 pertence. <br><br>  Em primeiro lugar, nÃ£o depende do tipo de dados.  Por exemplo, se vocÃª sabe com antecedÃªncia que terÃ¡ uma matriz de nÃºmeros inteiros, poderÃ¡ usar uma das muitas variantes do algoritmo VarInt - serÃ¡ mais eficiente na CPU.  Em segundo lugar, o LZ4 nÃ£o depende muito das suposiÃ§Ãµes necessÃ¡rias no modelo de dados.  Suponha que vocÃª tenha uma sÃ©rie temporal ordenada de leituras de sensores - uma matriz com nÃºmeros do tipo float.  EntÃ£o vocÃª pode calcular os deltas e depois comprimir ainda mais, e isso serÃ¡ mais eficiente em termos de taxa de compactaÃ§Ã£o. <br><br>  Ou seja, o LZ4 pode ser usado sem problemas para matrizes de bytes - para qualquer arquivo.  Obviamente, ele tem sua prÃ³pria especializaÃ§Ã£o (mais sobre isso abaixo) e, em alguns casos, seu uso nÃ£o faz sentido.  Mas se vocÃª o chamar de algoritmo de uso geral, este serÃ¡ um pequeno erro.  E observe que, graÃ§as ao dispositivo interno, o LZ4 implementa automaticamente o algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RLE</a> como um caso especial. <br><br>  Outra pergunta: o LZ4 Ã© o algoritmo mais ideal dessa classe para a combinaÃ§Ã£o de velocidade e forÃ§a de compressÃ£o?  Esses algoritmos sÃ£o chamados de fronteira de pareto - isso significa que nÃ£o hÃ¡ outro algoritmo que seja estritamente melhor em um indicador e que nÃ£o seja pior em outros (e mesmo em uma ampla variedade de conjuntos de dados).  Existem algoritmos que sÃ£o mais rÃ¡pidos, mas oferecem uma taxa de compactaÃ§Ã£o mais baixa, e hÃ¡ outros que compactam mais, mas ao mesmo tempo, compactam ou descomprimem mais lentamente. <br><br>  De fato, o LZ4 nÃ£o Ã© uma fronteira de pareto.  Existem opÃ§Ãµes um pouco melhores.  Por exemplo, este Ã© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LZTURBO</a> de um certo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">powturbo</a> .  NÃ£o hÃ¡ dÃºvida na confiabilidade dos resultados graÃ§as Ã  comunidade no encode.ru (o maior e aproximadamente o Ãºnico fÃ³rum de compactaÃ§Ã£o de dados).  Mas o desenvolvedor nÃ£o distribui o cÃ³digo-fonte ou os binÃ¡rios, mas apenas os entrega a um cÃ­rculo limitado de pessoas para testes ou por muito dinheiro (como ninguÃ©m pagou atÃ© agora).  TambÃ©m vale a pena prestar atenÃ§Ã£o ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lizard</a> (anteriormente LZ5) e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Density</a> .  Eles podem funcionar um pouco melhor que o LZ4 ao escolher algum nÃ­vel de compactaÃ§Ã£o.  TambÃ©m preste atenÃ§Ã£o ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LZSSE</a> - uma coisa extremamente interessante.  No entanto, Ã© melhor analisar depois de ler este artigo. <br><br><h3>  Como o LZ4 funciona? </h3><br>  Vamos ver como o LZ4 funciona em geral.  Esta Ã© uma das implementaÃ§Ãµes do algoritmo LZ77: L e Z indicam os nomes dos autores (Lempel e Ziv) e 77 - em 1977, quando o algoritmo foi publicado.  Possui muitas outras implementaÃ§Ãµes: QuickLZ, FastLZ, BriefLZ, LZF, LZO, bem como gzip e zip ao usar baixos nÃ­veis de compactaÃ§Ã£o. <br><br>  Um bloco de dados compactado usando LZ4 contÃ©m uma sequÃªncia de registros (comandos, instruÃ§Ãµes) de dois tipos: <br><br><ol><li>  Literal: "pegue os prÃ³ximos N bytes como estÃ£o e copie-os para o resultado." </li><li>  CorrespondÃªncia (correspondÃªncia): "pegue N bytes que jÃ¡ foram descompactados pelo deslocamento da posiÃ§Ã£o atual". </li></ol><br>  Um exemplo  Antes da compactaÃ§Ã£o: <br> <code>Hello world Hello</code> <br> <br>  ApÃ³s a compactaÃ§Ã£o: <br> <code>literals 12 "Hello world " match 5 12</code> <br> <br>  Se pegarmos um bloco compactado e o percorrermos com o cursor, executando esses comandos, obteremos os dados iniciais nÃ£o compactados como resultado. <br><br>  Analisamos aproximadamente como os dados sÃ£o descompactados.  O ponto tambÃ©m Ã© claro: para realizar a compactaÃ§Ã£o, o algoritmo codifica sequÃªncias de bytes repetidas usando correspondÃªncias. <br><br>  Claro e algumas propriedades.  Esse algoritmo Ã© orientado a bytes - nÃ£o disseca bytes individuais, mas apenas os copia por inteiro.  Aqui reside a diferenÃ§a, por exemplo, da codificaÃ§Ã£o da entropia.  Por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">zstd</a> Ã© uma composiÃ§Ã£o de LZ77 e codificaÃ§Ã£o de entropia. <br><br>  Observe que o tamanho do bloco compactado nÃ£o Ã© escolhido muito grande para nÃ£o gastar muita RAM durante o descarregamento;  para nÃ£o retardar o acesso aleatÃ³rio em um arquivo compactado (que consiste em muitos blocos compactados);  e Ã s vezes para que o bloco caiba em algum cache da CPU.  Por exemplo, vocÃª pode escolher 64 KB - portanto, os buffers para dados compactados e nÃ£o compactados caberÃ£o no cache L2 e metade permanecerÃ¡. <br><br>  Se precisarmos compactar um arquivo maior, simplesmente concatenamos os blocos compactados.  Ao mesmo tempo, ao lado de cada bloco compactado, Ã© conveniente colocar dados adicionais - tamanhos, soma de verificaÃ§Ã£o. <br><br>  O deslocamento mÃ¡ximo para a partida Ã© limitado, em LZ4 - 64 kilobytes.  Este valor Ã© chamado de janela deslizante.  De fato, isso significa que, Ã  medida que o cursor avanÃ§a, as correspondÃªncias podem estar em uma janela de tamanho de 64 kilobytes para o cursor, que se move com o cursor. <br><br>  Agora vamos ver como compactar dados - em outras palavras, como encontrar seqÃ¼Ãªncias correspondentes em um arquivo.  Obviamente, vocÃª pode usar o sufixo trie (Ã³timo se vocÃª jÃ¡ ouviu falar).  Existem opÃ§Ãµes nas quais a sequÃªncia de correspondÃªncia mais longa Ã© garantida entre os bytes anteriores no processo de compactaÃ§Ã£o.  Isso Ã© chamado de anÃ¡lise ideal e fornece uma taxa de compactaÃ§Ã£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">quase</a> melhor para um formato de bloco compactado fixo.  Mas existem opÃ§Ãµes mais eficazes - quando encontramos uma correspondÃªncia suficientemente boa nos dados, mas nÃ£o necessariamente a mais longa.  A maneira mais eficiente de encontrÃ¡-lo Ã© usar uma tabela de hash. <br><br>  Para fazer isso, percorremos o bloco de dados de origem com o cursor e pegamos alguns bytes apÃ³s o cursor.  Por exemplo, 4 bytes.  Hash-los e colocar na tabela de hash o deslocamento desde o inÃ­cio do bloco - onde esses 4 bytes se encontraram.  O valor 4 Ã© chamado min-match - com a ajuda de uma tabela de hash, podemos encontrar correspondÃªncias de pelo menos 4 bytes. <br><br>  Se observarmos a tabela de hash, e jÃ¡ houver um registro, e se o deslocamento nÃ£o exceder a janela deslizante, verificamos quantos bytes mais correspondem apÃ³s esses quatro bytes.  Talvez haja muito mais que coincida.  TambÃ©m Ã© possÃ­vel que tenha ocorrido uma colisÃ£o na tabela de hash e nada corresponda.  Isso Ã© normal - vocÃª pode simplesmente substituir o valor na tabela de hash por um novo.  As colisÃµes na tabela de hash simplesmente resultam em uma taxa de compactaÃ§Ã£o mais baixa, pois hÃ¡ menos correspondÃªncias.  A propÃ³sito, esse tipo de tabela de hash (de tamanho fixo e sem resoluÃ§Ã£o de colisÃ£o) Ã© chamada de tabela de cache, tabela de cache.  Isso tambÃ©m Ã© lÃ³gico - no caso de uma colisÃ£o, a tabela de cache apenas esquece o registro antigo. <br><blockquote>  A tarefa para o leitor atento.  Deixe os dados serem uma matriz de nÃºmeros como o UInt32 no formato little endian, que faz parte de uma sequÃªncia de nÃºmeros naturais: 0, 1, 2 ... Explique por que, ao usar o LZ4, esses dados nÃ£o sÃ£o compactados (a quantidade de dados compactados nÃ£o Ã© menor que a quantidade de dados nÃ£o compactados). </blockquote><h3>  Como acelerar as coisas </h3><br>  EntÃ£o, eu quero acelerar o descarregamento do LZ4.  Vamos ver como Ã© o ciclo de descarga.  Aqui estÃ¡ o loop no pseudocÃ³digo: <br><br><pre>  enquanto (...)
 {
     ler (input_pos, comprimento_ literal, comprimento_de_conjuntos);<font></font>
<font></font>
     cÃ³pia (output_pos, input_pos, literal_length);
     output_pos + = comprimento_ literal;<font></font>
<font></font>
     ler (input_pos, match_offset);<font></font>
<font></font>
     cÃ³pia (output_pos, output_pos - match_offset,
         match_length);
     output_pos + = match_length;
 } </pre><br>  O formato LZ4 Ã© projetado para que literais e correspondÃªncias se alternem em um arquivo compactado.  E, obviamente, o literal sempre vem em primeiro lugar (porque, desde o inÃ­cio, a partida nÃ£o tem para onde ir).  Portanto, seus comprimentos sÃ£o codificados juntos. <br><br>  De fato, tudo Ã© um pouco mais complicado.  Um byte Ã© lido no arquivo e dois nibles sÃ£o retirados, nos quais sÃ£o codificados nÃºmeros de 0 a 15. Se o nÃºmero correspondente nÃ£o for igual a 15, serÃ¡ considerado o comprimento do literal e da correspondÃªncia, respectivamente.  E se tiver 15 anos, o comprimento serÃ¡ maior e serÃ¡ codificado nos seguintes bytes.  Em seguida, o prÃ³ximo byte Ã© lido e seu valor Ã© adicionado ao comprimento.  AlÃ©m disso, se for 255, continuamos - lemos o prÃ³ximo byte da mesma maneira. <br><br>  Observe que a taxa mÃ¡xima de compactaÃ§Ã£o para o formato LZ4 nÃ£o atinge 255. E a segunda observaÃ§Ã£o (inÃºtil): se seus dados forem muito redundantes, o uso do LZ4 aumentarÃ¡ o dobro da taxa de compactaÃ§Ã£o. <br><br>  Quando lemos a duraÃ§Ã£o do literal (e tambÃ©m a duraÃ§Ã£o da correspondÃªncia e o deslocamento da correspondÃªncia), para desanuviar, basta copiar duas partes da memÃ³ria. <br><br><h3>  Como copiar um pedaÃ§o de memÃ³ria </h3><br>  Parece que vocÃª pode usar a funÃ§Ã£o <code>memcpy</code> , que foi projetada apenas para copiar pedaÃ§os de memÃ³ria.  Mas isso nÃ£o Ã© o ideal e ainda estÃ¡ incorreto. <br><br>  Por que o uso da funÃ§Ã£o memcpy estÃ¡ abaixo do ideal?  Porque ela: <br><br><ol><li>  geralmente localizado na biblioteca libc (e a biblioteca libc geralmente se vincula dinamicamente e a chamada memcpy serÃ¡ indiretamente, via PLT), </li><li>  nÃ£o estÃ¡ alinhado com o argumento de tamanho desconhecido no tempo de compilaÃ§Ã£o, </li><li>  faz muito esforÃ§o para processar corretamente as "caudas" de um fragmento de memÃ³ria que nÃ£o sÃ£o mÃºltiplos do tamanho de uma palavra ou registro de mÃ¡quina. </li></ol><br>  O Ãºltimo ponto Ã© o mais importante.  Suponha que pedimos Ã  funÃ§Ã£o memcpy para copiar exatamente 5 bytes.  Seria muito bom copiar 8 bytes de uma sÃ³ vez, usando duas instruÃ§Ãµes movq para isso. <br><br> <code>Hello world <font color="#0fc000">Hello</font> <font color="#ff0000">wo</font> ... <br> ^^^^^ <font color="#ff0000">^^^</font> - src <br> ^^^^^ <font color="#ff0000">^^^</font> - dst</code> <br> <br>  Mas entÃ£o copiaremos trÃªs bytes extras - isto Ã©, gravaremos no exterior o buffer transferido.  A funÃ§Ã£o <code>memcpy</code> nÃ£o tem o direito de fazer isso - de fato, porque sobrescreveremos alguns dados em nosso programa, haverÃ¡ uma "passagem" da memÃ³ria.  E se escrevermos em um endereÃ§o nÃ£o alinhado, esses bytes extras poderÃ£o ser localizados em uma pÃ¡gina de memÃ³ria virtual nÃ£o alocada ou em uma pÃ¡gina sem acesso de gravaÃ§Ã£o.  EntÃ£o temos segfault (isso Ã© bom). <br><br>  Mas, no nosso caso, quase sempre podemos escrever bytes extras.  Podemos ler bytes extras no buffer de entrada, desde que os bytes extras estejam totalmente nele.  Sob as mesmas condiÃ§Ãµes, podemos escrever bytes extras no buffer de saÃ­da - porque na prÃ³xima iteraÃ§Ã£o os substituiremos de qualquer maneira. <br><br>  Essa otimizaÃ§Ã£o jÃ¡ estÃ¡ na implementaÃ§Ã£o LZ4 original: <br><br><pre>  copy8 vazio inline (UInt8 * dst, const UInt8 * src)
 {
     memcpy (dst, src, 8);  /// Na verdade, memcpy nÃ£o Ã© chamado aqui.
 }<font></font>
<font></font>
 wildCopy8 vazio em linha (UInt8 * dst, const UInt8 * src, UInt8 * dst_end)
 {
     fazer
     {
         copy8 (dst, src);
         dst + = 8;
         src + = 8;
     } while (dst &lt;dst_end);
 } </pre><br>  Para tirar proveito dessa otimizaÃ§Ã£o, vocÃª sÃ³ precisa verificar se estamos longe o suficiente da borda do buffer.  Isso deve ser gratuito, porque jÃ¡ verificamos que os limites do buffer foram excedidos.  E o processamento dos Ãºltimos bytes - a "cauda" dos dados - pode ser feito apÃ³s o loop principal. <br><br>  No entanto, ainda existem algumas sutilezas.  Existem duas cÃ³pias no ciclo - literal e match.  PorÃ©m, ao usar a funÃ§Ã£o LZ4_decompress_fast (em vez de LZ4_decompress_safe), a verificaÃ§Ã£o Ã© realizada uma vez - quando precisamos copiar o literal.  Ao copiar uma partida, a verificaÃ§Ã£o nÃ£o Ã© realizada, mas na <a href="">especificaÃ§Ã£o do formato LZ4</a> existem condiÃ§Ãµes que permitem que ela seja evitada: <br><br><blockquote>  Os Ãºltimos 5 bytes sÃ£o sempre literais <br>  A Ãºltima correspondÃªncia deve iniciar pelo menos 12 bytes antes do final do bloco. <br>  ConseqÃ¼entemente, um bloco com menos de 13 bytes nÃ£o pode ser compactado. </blockquote><br>  Dados de entrada especialmente selecionados podem causar uma unidade de memÃ³ria.  Se vocÃª usar a funÃ§Ã£o LZ4_decompress_fast, precisarÃ¡ de proteÃ§Ã£o contra dados incorretos.  Os dados compactados devem ter pelo menos uma soma de verificaÃ§Ã£o.  E se vocÃª precisar de proteÃ§Ã£o contra um invasor, use a funÃ§Ã£o LZ4_decompress_safe.  Outras opÃ§Ãµes: use uma funÃ§Ã£o hash criptogrÃ¡fica como uma soma de verificaÃ§Ã£o, mas quase certamente matarÃ¡ todo o desempenho;  aloque mais memÃ³ria para buffers;  aloque memÃ³ria para buffers com uma chamada separada para o mmap e crie uma pÃ¡gina de proteÃ§Ã£o. <br><br>  Quando vejo um cÃ³digo que copia dados de 8 bytes, pergunto imediatamente - por que exatamente 8 bytes?  VocÃª pode copiar 16 bytes usando registros SSE: <br><br><pre>  cÃ³pia vazia em linha16 (UInt8 * dst, const UInt8 * src)
 {
 #if __SSE2__
     _mm_storeu_si128 (reinterpret_cast &lt;__ m128i *&gt; (dst),
         _mm_loadu_si128 (reinterpret_cast &lt;const __m128i *&gt; (src)));
 #else
     memcpy (dst, src, 16);
 #endif
 }<font></font>
<font></font>
 wildCopy16 vazio na linha (UInt8 * dst, const UInt8 * src, UInt8 * dst_end)
 {
     fazer
     {
         copy16 (dst, src);
         dst + = 16;
         src + = 16;
     } while (dst &lt;dst_end);
 } </pre><br>  Copiar 32 bytes para o AVX e 64 bytes para o AVX-512 funciona da mesma maneira.  AlÃ©m disso, vocÃª pode expandir o ciclo vÃ¡rias vezes.  Se vocÃª jÃ¡ viu como o <code>memcpy</code> implementado, essa Ã© exatamente a abordagem.  (A propÃ³sito, o compilador nesse caso nÃ£o expandirÃ¡ nem vetorizarÃ¡ o loop: isso exigirÃ¡ a inserÃ§Ã£o de verificaÃ§Ãµes complicadas.) <br><br>  Por que isso nÃ£o Ã© feito na implementaÃ§Ã£o original do LZ4?  Em primeiro lugar, nÃ£o Ã© Ã³bvio se isso Ã© melhor ou pior.  O resultado depende do tamanho dos fragmentos a serem copiados.  De repente, todos eles sÃ£o curtos e o trabalho extra serÃ¡ inÃºtil?  E, em segundo lugar, destrÃ³i as condiÃ§Ãµes no formato LZ4 que permitem evitar brunch desnecessÃ¡rio no loop interno. <br><br>  No entanto, manteremos essa opÃ§Ã£o em mente por enquanto. <br><br><h3>  CÃ³pia complicada </h3><br>  De volta Ã  pergunta - Ã© sempre possÃ­vel copiar dados dessa maneira?  Suponha que precisamos copiar uma correspondÃªncia - isto Ã©, copiar um pedaÃ§o de memÃ³ria do buffer de saÃ­da que estÃ¡ em algum deslocamento atrÃ¡s do cursor para a posiÃ§Ã£o desse cursor. <br><br>  Imagine um caso simples - vocÃª precisa copiar 5 bytes no deslocamento 12: <br><br> <code><font color="#0fc000">Hello</font> world ........... <br> ^^^^^ - src <br> ^^^^^ - dst <br> <br> Hello world <font color="#0fc000">Hello</font> <font color="#a8a8a8">wo</font> ... <br> ^^^^^ - src <br> ^^^^^ - dst</code> <br> <br>  Mas hÃ¡ um caso mais complicado - quando precisamos copiar um pedaÃ§o de memÃ³ria cujo tamanho Ã© maior que o deslocamento.  Ou seja, indica parcialmente os dados que ainda nÃ£o foram gravados no buffer de saÃ­da. <br><br>  Copie 10 bytes no deslocamento 3: <br><br> <code><font color="#0fc000">abc</font> ............. <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst <br> <br> abc <font color="#0fc000">abcabcabca</font> ... <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst</code> <br> <br>  No processo de compactaÃ§Ã£o, temos todos os dados, e essa correspondÃªncia pode ser encontrada.  A funÃ§Ã£o <code>memcpy</code> nÃ£o Ã© adequada para copiÃ¡-la: nÃ£o suporta o caso quando os intervalos de fragmentos de memÃ³ria se cruzam.  A propÃ³sito, a funÃ§Ã£o <code>memmove</code> tambÃ©m nÃ£o Ã© adequada, porque o fragmento de memÃ³ria de onde obter os dados ainda nÃ£o foi totalmente inicializado.  VocÃª precisa copiar como se estivÃ©ssemos copiando por byte. <br><br><pre>  op [0] = partida [0];
 op [1] = partida [1];
 op [2] = partida [2];
 op [3] = partida [3];
 ... </pre><br><br>  Veja como funciona: <br><br> <code><font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ............ <br> ^ - src <br> ^ - dst <br> <br> a <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........... <br> ^ - src <br> ^ - dst <br> <br> ab <font color="#0fc000">c</font> ab <font color="#0fc000">c</font> .......... <br> ^ - src <br> ^ - dst <br> <br> abc <font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ......... <br> ^ - src <br> ^ - dst <br> <br> abca <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........ <br> ^ - src <br> ^ - dst</code> <br> <br>  Ou seja, devemos criar uma sequÃªncia repetida.  Na implementaÃ§Ã£o original do LZ4, um cÃ³digo surpreendentemente incompreensÃ­vel foi escrito para isso: <br><br><pre>  const unsigned dec32table [] = {0, 1, 2, 1, 4, 4, 4, 4};
 const int dec64table [] = {0, 0, 0, -1, 0, 1, 2, 3};<font></font>
<font></font>
 const int dec64 = dec64table [deslocamento];
 op [0] = partida [0];
 op [1] = partida [1];
 op [2] = partida [2];
 op [3] = partida [3];
 match + = dec32table [deslocamento];
 memcpy (op + 4, partida, 4);
 correspondÃªncia - = dec64; </pre><br>  Copiamos os primeiros 4 bytes byte por bit, mudamos para algum nÃºmero mÃ¡gico, copiamos os prÃ³ximos 4 bytes como um todo, mudamos o ponteiro para corresponder a outro nÃºmero mÃ¡gico.  O autor do cÃ³digo ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Jan Collet</a> ), por algum motivo ridÃ­culo, esqueceu de deixar um comentÃ¡rio sobre o que isso significa.  AlÃ©m disso, nomes de variÃ¡veis â€‹â€‹sÃ£o confusos.  Ambos sÃ£o chamados dec ... table, mas adicionamos um deles e subtraÃ­mos o outro.  AlÃ©m disso, outro nÃ£o Ã© assinado e o outro Ã© int.  No entanto, vale a pena prestar homenagem: recentemente, o autor melhorou esse lugar no cÃ³digo. <br><br>  Aqui estÃ¡ como ele realmente funciona.  Copie o primeiro byte de 4 bytes: <br><br> <code>abc <font color="#0fc000">abca</font> ......... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Agora vocÃª pode copiar 4 bytes de uma vez: <br><br> <code>abcabca <font color="#0fc000">bcab</font> ..... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>    ,  8  : <br><br> <code>abcabcabcab <font color="#0fc000">cabcabca</font> ..... <br> ^^^^^^^^ - src <br> ^^^^^^^^ - dst</code> <br> <br>     ,      â€”   .   : <br><br><pre> inline void copyOverlap8(UInt8 * op, const UInt8 *&amp; match, const size_t offset)<font></font>
{<font></font>
    /// 4 % n.<font></font>
    /// Or if 4 % n is zero, we use n.<font></font>
    /// It gives equivalent result, but is better CPU friendly for unknown reason.<font></font>
    static constexpr int shift1[] = { 0, 1, 2, 1, 4, 4, 4, 4 };<font></font>
<font></font>
    /// 8 % n - 4 % n<font></font>
    static constexpr int shift2[] = { 0, 0, 0, 1, 0, -1, -2, -3 };<font></font>
<font></font>
    op[0] = match[0];<font></font>
    op[1] = match[1];<font></font>
    op[2] = match[2];<font></font>
    op[3] = match[3];<font></font>
<font></font>
    match += shift1[offset];<font></font>
    memcpy(op + 4, match, 4);<font></font>
    match += shift2[offset];<font></font>
} </pre><br> ,  ,   . ,     ,     â€”   16 . <br><br>    Â« Â»    ,     ( <code>offset &lt; 16</code>   ,  <code>offset &lt; 8</code> ).  ()     16-   : <br><br><pre> inline void copyOverlap16(UInt8 * op, const UInt8 *&amp; match, const size_t offset)<font></font>
{<font></font>
    /// 4 % n.<font></font>
    static constexpr int shift1[]<font></font>
        = { 0, 1, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4 };<font></font>
<font></font>
    /// 8 % n - 4 % n<font></font>
    static constexpr int shift2[]<font></font>
        = { 0, 0, 0, 1, 0, -1, -2, -3, -4, 4, 4, 4, 4, 4, 4, 4 };<font></font>
<font></font>
    /// 16 % n - 8 % n<font></font>
    static constexpr int shift3[]<font></font>
        = { 0, 0, 0, -1, 0, -2, 2, 1, 8, -1, -2, -3, -4, -5, -6, -7 };<font></font>
<font></font>
    op[0] = match[0];<font></font>
    op[1] = match[1];<font></font>
    op[2] = match[2];<font></font>
    op[3] = match[3];<font></font>
<font></font>
    match += shift1[offset];<font></font>
    memcpy(op + 4, match, 4);<font></font>
    match += shift2[offset];<font></font>
    memcpy(op + 8, match, 8);<font></font>
    match += shift3[offset];<font></font>
} </pre><br>       ?  ,        SIMD-,       16 ,         ( 1  15). ,   ,      . <br><br>    â€”   <code>pshufb</code> (  packed shuffle bytes)    SSSE3 (  S).    16- .      .   â€” Â«Â»:       0  15 â€”    ,       . ,      127 â€”     . <br><br>  Aqui estÃ¡ um exemplo: <br><br><pre> xmm0: abc.............<font></font>
xmm1: 0120120120120120<font></font>
<font></font>
pshufb %xmm1, %xmm0<font></font>
<font></font>
xmm0: abcabcabcabcabca </pre><br>           â€”      !      : <br><br><pre> inline void copyOverlap16Shuffle(UInt8 * op, const UInt8 *&amp; match, const size_t offset)<font></font>
{<font></font>
#ifdef __SSSE3__<font></font>
<font></font>
    static constexpr UInt8 __attribute__((__aligned__(16))) masks[] =<font></font>
    {<font></font>
        0, 1, 2, 1, 4, 1, 4, 2, 8, 7, 6, 5, 4, 3, 2, 1, /* offset = 0, not used as mask, but for shift amount instead */<font></font>
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, /* offset = 1 */<font></font>
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,<font></font>
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,<font></font>
        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,<font></font>
        0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0,<font></font>
        0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3,<font></font>
        0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 1, 2,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 1,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0,<font></font>
    };<font></font>
<font></font>
    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(op),<font></font>
        _mm_shuffle_epi8(<font></font>
            _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(match)),<font></font>
            _mm_load_si128(reinterpret_cast&lt;const __m128i *&gt;(masks) + offset)));<font></font>
<font></font>
    match += masks[offset];<font></font>
<font></font>
#else<font></font>
    copyOverlap16(op, match, offset);<font></font>
#endif<font></font>
} </pre><br>  <code>_mm_shuffle_epi8</code> â€”  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">intrinsic</a> ,    <code>pshufb</code> . <br><br>          ,    ?  SSSE3 â€”    ,   2006 .  AVX2  ,      32 ,      16- .     packed shuffle bytes,  vector permute bytes â€”  ,    .  AVX-512 VBMI    ,    64 ,        .      ARM NEON â€”   vtbl (vector table lookup),     8 . <br><br>  ,    <code>pshufb</code>  64- MMX-,   8 .         . ,        ,   16  (  ). <br><br>   Highload++ Siberia         ,    8          (  ) â€”       ! <br><br><h3>    if </h3><br> ,    ,   16 .         ? <br><br>  ,       .      ,           ,  ,         .    ,     . <br><br> ,    . , ,    ,      65 536 .        65 536    .           , ,  65 551 .  ,  ,       96   128  â€”     .     ,           Â«Â»      mmap    (     madvice).      - page faults.         ,    . <br><br><h3>   ? </h3><br> ,    ,     : <br><br><ol><li>   16   8. </li><li>  shuffle-   <code>offset &lt; 16</code> . </li><li>    if. </li></ol><br>              . <br><br>  Exemplo 1: <br> Xeon E2650v2,  .,  AppVersion. <br> reference: 1.67 GB/sec. <br> 16 bytes, shuffle: 2.94 GB/sec ( 76% ). <br><br>  Exemplo 2: <br> Xeon E2650v2,  .,  ShowsSumPosition. <br> reference: 2.30 GB/sec. <br> 16 bytes, shuffle: 1.91 GB/sec ( 20% ). <br><br>   ,         .     ,    .   - ,   .   ,      .     â€”       16 .  :    ,     ,   . <br><br>   ,     C++      :  8-  16-  ;     shuffle-. <br><br><pre> template &lt;size_t copy_amount, bool use_shuffle&gt;<font></font>
void NO_INLINE decompressImpl(<font></font>
     const char * const source,<font></font>
     char * const dest,<font></font>
     size_t dest_size) </pre><br>        ,         shuffle  .     ,   : <br><br><pre> sudo echo 'performance' | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor<font></font>
kill -STOP $(pidof firefox) $(pidof chromium) </pre><br>        Â«Â»  (c  Xeon E5645),           ,    . ,         ,    .    ,    shuffle-,   ,      16- . <br><br>         : <br><br><pre> sudo kill -STOP $(pidof python) $(pidof perl) $(pgrep -u skynet) $(pidof cqudp-client) </pre><br>    .    thermal throttling  power capping. <br><br><h3>     </h3><br> ,      ,        .         ,         ,    .       .       , ,     .   : ClickHouse      ,       ,         .       ,             (       â€”  ?).      . <br><br>      ,    ,      .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Â« Â»</a> .   ,      ,           ,    . <br><br>      ,   .        .       -        .             â€”   ClickHouse      64 . ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>   .) <br><br>  ,     Â« Â», ,    .      ,     ,   ,   -   .           .            ,          ,    .      . <br><br>         ,          ,       .    Â«Â»     ,    .     ,        .    Thompson Sampling. <br><br> ,   ,    .  â€”      :  ,  .          .     ,     .       ,           C++.     â€” ,     -   ,   ;     . <br><br>     ?      ,       .    . -,      ,         . -,  ,   ,   Â«Â» . <br><br> ,  ,           Thompson Sampling â€”   (   ,        ).   ,         ,         - ,     ,      .           ,     . <br><br>   ,   Â«Â» .   ,     ,        Â«Â»,     .      â€” <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> .    ,     ,       . <br><br>       ,   ,    ,    ,   Â«Â»: <br><br><pre> /// For better convergence, we don't use proper estimate of stddev.<font></font>
/// We want to eventually separate between two algorithms even in case<font></font>
/// when there is no statistical significant difference between them.<font></font>
double sigma() const<font></font>
{<font></font>
    return mean() / sqrt(adjustedCount());<font></font>
}<font></font>
<font></font>
double sample(pcg64 &amp; rng) const<font></font>
{<font></font>
     ...<font></font>
    return std::normal_distribution&lt;&gt;(mean(), sigma())(rng);<font></font>
} </pre><br>    ,       â€”    memory latencies. <br><br>   ,         ,       â€”    LZ4    . <br><br>  ,    : <br> â€” reference (baseline):  LZ4   ; <br> â€” variant 0:   8 ,   shuffle; <br> â€” variant 1:   8 ,  shuffle; <br> â€” variant 2:   16 ,   shuffle; <br> â€” variant 3:   16 ,  shuffle; <br> â€” Â«Â» ,            . <br><br><h3>    CPU </h3><br>       CPU,    ,  .  ,   CPU   ? <br><br>         ClickHouse   ,  256    100    ( 256  ).  ,  CPU  ,      .      CPU: <br> â€” IntelÂ® XeonÂ® CPU E5-2650 v2 @ 2.60GHz <br> â€” IntelÂ® XeonÂ® CPU E5-2660 v4 @ 2.00GHz <br> â€” IntelÂ® XeonÂ® CPU E5-2660 0 @ 2.20GHz <br> â€” IntelÂ® XeonÂ® CPU E5645 @ 2.40GHz <br> â€” Intel Xeon E312xx (Sandy Bridge) <br> â€” AMD Opteron(TM) Processor 6274 <br> â€” AMD Opteron(tm) Processor 6380 <br> â€” IntelÂ® XeonÂ® CPU E5-2683 v4 @ 2.10GHz <br> â€” IntelÂ® XeonÂ® CPU E5530 @ 2.40GHz <br> â€” IntelÂ® XeonÂ® CPU E5440 @ 2.83GHz <br> â€” IntelÂ® XeonÂ® CPU E5-2667 v2 @ 3.30GHz <br><br>    â€” ,   R&amp;D: <br> â€” AMD EPYC 7351 16-Core Processor â€”    AMD. <br> â€” Cavium ThunderX2 â€”     x86,  AArch64.    SIMD-   .    224   56  . <br><br>  13 ,        256   6  (reference, 0, 1, 2, 3, adaptive),    10 ,   .  199 680 ,    . <br><br> ,    CPU  .         :      LZ4    (   â€”  ).  ,  Cavium   .       ClickHouse,   Â«Â» Xeon E5-2650 v2         ,      ,   ClickHouse    x86. <br><br><pre> â”Œâ”€cpuâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€refâ”€â”¬â”€adaptâ”€â”¬â”€â”€maxâ”€â”¬â”€bestâ”€â”¬â”€adapt_boostâ”€â”¬â”€max_boostâ”€â”¬â”€adapt_over_maxâ”€â”<font></font>
â”‚ E5-2667 v2 @ 3.30GHz â”‚ 2.81 â”‚ 3.19 â”‚ 3.15 â”‚ 3 â”‚ 1.14 â”‚ 1.12 â”‚ 1.01 â”‚<font></font>
â”‚ E5-2650 v2 @ 2.60GHz â”‚ 2.5 â”‚ 2.84 â”‚ 2.81 â”‚ 3 â”‚ 1.14 â”‚ 1.12 â”‚ 1.01 â”‚<font></font>
â”‚ E5-2683 v4 @ 2.10GHz â”‚ 2.26 â”‚ 2.63 â”‚ 2.59 â”‚ 3 â”‚ 1.16 â”‚ 1.15 â”‚ 1.02 â”‚<font></font>
â”‚ E5-2660 v4 @ 2.00GHz â”‚ 2.15 â”‚ 2.49 â”‚ 2.46 â”‚ 3 â”‚ 1.16 â”‚ 1.14 â”‚ 1.01 â”‚<font></font>
â”‚ AMD EPYC 7351 â”‚ 2.03 â”‚ 2.44 â”‚ 2.35 â”‚ 3 â”‚ 1.20 â”‚ 1.16 â”‚ 1.04 â”‚<font></font>
â”‚ E5-2660 0 @ 2.20GHz â”‚ 2.13 â”‚ 2.39 â”‚ 2.37 â”‚ 3 â”‚ 1.12 â”‚ 1.11 â”‚ 1.01 â”‚<font></font>
â”‚ E312xx (Sandy Bridge) â”‚ 1.97 â”‚ 2.2 â”‚ 2.18 â”‚ 3 â”‚ 1.12 â”‚ 1.11 â”‚ 1.01 â”‚<font></font>
â”‚ E5530 @ 2.40GHz â”‚ 1.65 â”‚ 1.93 â”‚ 1.94 â”‚ 3 â”‚ 1.17 â”‚ 1.18 â”‚ 0.99 â”‚<font></font>
â”‚ E5645 @ 2.40GHz â”‚ 1.65 â”‚ 1.92 â”‚ 1.94 â”‚ 3 â”‚ 1.16 â”‚ 1.18 â”‚ 0.99 â”‚<font></font>
â”‚ AMD Opteron 6380 â”‚ 1.47 â”‚ 1.58 â”‚ 1.56 â”‚ 1 â”‚ 1.07 â”‚ 1.06 â”‚ 1.01 â”‚<font></font>
â”‚ AMD Opteron 6274 â”‚ 1.15 â”‚ 1.35 â”‚ 1.35 â”‚ 1 â”‚ 1.17 â”‚ 1.17 â”‚ 1 â”‚<font></font>
â”‚ E5440 @ 2.83GHz â”‚ 1.35 â”‚ 1.33 â”‚ 1.42 â”‚ 1 â”‚ 0.99 â”‚ 1.05 â”‚ 0.94 â”‚<font></font>
â”‚ Cavium ThunderX2 â”‚ 0.84 â”‚ 0.87 â”‚ 0.87 â”‚ 0 â”‚ 1.04 â”‚ 1.04 â”‚ 1 â”‚<font></font>
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ </pre><br> ref, adapt, max â€”       (,            ). best â€”      ,  0  3. adapt_boost â€”        baseline. max_boost â€”          baseline. adapt_over_max â€”         . <br><br>  ,    x86      12â€“20%.   ARM    4%,   ,         .  ,        Â«Â»              Intel. <br><br><h3>  ConclusÃµes </h3><br>       . ,   LZ4     12â€“20%,            .           .      ,         . <br><br>    ,     ,    Â«Â» ,    ZStandard level 1  LZ4:      IO    . <br><br>           â€” ,      .          ,       . <br><br>    :         . LZ4    ,   Lizard, Density  LZSSE  ,    . ,    LZ4      LZSSE  ClickHouse. <br><br>       LZ4 :         .          :      ,   .             . ,   inc-  dec-   <a href=""></a> .  ,           12â€“15%     32 ,    16,   .       32  â€”     ,     <a href=""> </a> . <br><br>       ,  ,          page cache  userspace (   mmap,    O_DIRECT  userspace page cache â€”     ),      - (  CityHash128  CRC32-C,    HighwayHash, FARSH  XXH3).         ,       . <br><br>   ,     master,            .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>  HighLoad++ Siberia,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt452778/">https://habr.com/ru/post/pt452778/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt452766/index.html">Tecnologia Progressive Streaming, ou como assistir a vÃ­deos em 4K na rede, sem frisos</a></li>
<li><a href="../pt452768/index.html">Como projetar um produto se vocÃª decidir entrar no mercado externo</a></li>
<li><a href="../pt452772/index.html">5 tÃ©cnicas avanÃ§adas de teste</a></li>
<li><a href="../pt452774/index.html">Dell XPS 13 9380: laptop confiÃ¡vel e muito compacto para negÃ³cios sÃ©rios</a></li>
<li><a href="../pt452776/index.html">N.M.D. (NÃ£o Ã© da minha conta)</a></li>
<li><a href="../pt452780/index.html">Mobius 2019 Piter: TransmissÃ£o ao vivo grÃ¡tis e tudo o resto</a></li>
<li><a href="../pt452788/index.html">A luta pela qualidade em aplicaÃ§Ãµes web, depressÃ£o, dragÃµes e Westeros</a></li>
<li><a href="../pt452790/index.html">OpenCV 4.0 e 4.1 - o que hÃ¡ de novo?</a></li>
<li><a href="../pt452792/index.html">AnÃ¡lise de SSD de estado sÃ³lido para usuÃ¡rios corporativos Kingston DC500R</a></li>
<li><a href="../pt452794/index.html">Sobre localizaÃ§Ã£o de produtos. Parte um: por onde comeÃ§ar?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
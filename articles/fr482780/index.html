<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ∞Ô∏è üåµ üìπ Exp√©riences avec des r√©seaux de neurones bas√©s sur des donn√©es sismiques üë®üèº‚Äç‚öïÔ∏è üéûÔ∏è ‚ô•Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La complexit√© de l'interpr√©tation des donn√©es sismiques est due au fait que pour chaque t√¢che, il est n√©cessaire de rechercher une approche individuel...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Exp√©riences avec des r√©seaux de neurones bas√©s sur des donn√©es sismiques</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/482780/">  La complexit√© de l'interpr√©tation des donn√©es sismiques est due au fait que pour chaque t√¢che, il est n√©cessaire de rechercher une approche individuelle, car chaque ensemble de ces donn√©es est unique.  Le traitement manuel n√©cessite des co√ªts de main-d'≈ìuvre importants et le r√©sultat contient souvent des erreurs li√©es au facteur humain.  L'utilisation de r√©seaux de neurones pour l'interpr√©tation peut r√©duire consid√©rablement le travail manuel, mais l'unicit√© des donn√©es impose des restrictions √† l'automatisation de ce travail. <br><br>  Cet article d√©crit une exp√©rience pour analyser l'applicabilit√© des r√©seaux de neurones pour automatiser l'allocation des couches g√©ologiques dans les images 2D en utilisant des donn√©es enti√®rement √©tiquet√©es de la mer du Nord comme exemple. <br><br><img src="https://habrastorage.org/webt/rs/vp/ky/rsvpky5vebdp4xtive1ywcvtvtk.png" alt="Lev√©s sismiques d'origine hydrique"><br>  Figure 1. Lev√©s sismiques aquatiques ( <a href="https://www.nationalgeographic.com/news/2010/4/100407-energy-undersea-sound/">source</a> ) <br><a name="habracut"></a><br><h2>  Un peu sur le sujet </h2><br>  L'exploration sismique est une m√©thode g√©ophysique pour √©tudier des objets g√©ologiques √† l'aide de vibrations √©lastiques - ondes sismiques.  Cette m√©thode est bas√©e sur le fait que la vitesse de propagation des ondes sismiques d√©pend des propri√©t√©s de l'environnement g√©ologique dans lequel elles se propagent (composition de la roche, porosit√©, fracture, saturation en humidit√©, etc.) En traversant des couches g√©ologiques aux propri√©t√©s diff√©rentes, les ondes sismiques sont r√©fl√©chies par diff√©rents objets et retourn√©s au r√©cepteur (voir figure 1).  Leur nature est enregistr√©e et, apr√®s traitement, vous permet de former une image bidimensionnelle - une section sismique ou un tableau de donn√©es tridimensionnel - un cube sismique. <br><br><img src="https://habrastorage.org/webt/xi/dn/4p/xidn4psxaiynjkoqtvw3ctogcqq.gif" alt="Exemple de cube sismique"><br>  Figure 2. Un exemple de cube sismique ( <a href="http://cge.rosgeo.com/en/services/glubinnaya-3d-migraciya-do-summirovaniya/">source</a> ) <br><br>  L'axe horizontal du cube sismique est situ√© le long de la surface de la terre et la verticale repr√©sente la profondeur ou le temps (voir la figure 2).  Dans certains cas, le cube est divis√© en sections verticales le long de l'axe des g√©ophones (les soi-disant inlines, inlines) ou √† travers (crosslines, crosslines, xlines).  Chaque cube vertical (et tranche) est une trace sismique distincte. <br><br>  Ainsi, les alignements et les croisements sont constitu√©s des m√™mes tra√Æn√©es sismiques, mais dans un ordre diff√©rent.  Les sentiers sismiques adjacents sont tr√®s similaires les uns aux autres.  Un changement plus spectaculaire se produit aux points de faille, mais il y aura toujours des similitudes.  Cela signifie que les tranches voisines sont tr√®s similaires les unes aux autres. <br><br>  Toutes ces connaissances nous seront utiles lors de la planification d'exp√©riences. <br><br><h2>  La t√¢che d'interpr√©tation et le r√¥le des r√©seaux de neurones dans sa solution </h2><br>  Les donn√©es obtenues sont trait√©es manuellement par des interpr√®tes qui identifient directement sur le cube ou √† chaque tranche ses couches g√©ologiques individuelles de roches et leurs limites (horizons, horizons), les d√©p√¥ts de sel, les failles et autres caract√©ristiques de la structure g√©ologique de la zone d'√©tude.  L'interpr√®te, travaillant avec un cube ou une tranche, commence son travail par une s√©lection manuelle minutieuse des couches g√©ologiques et des horizons.  Chaque horizon doit √™tre piqu√© manuellement (de la collection ¬´picking¬ª en anglais) en pointant le curseur et en cliquant avec la souris. <br><br><img src="https://habrastorage.org/webt/w6/j3/gn/w6j3gnflms5vqyxc3mbjdnzsaam.png" alt="Un exemple de coupe 2D (√† gauche) et le r√©sultat du marquage des couches g√©ologiques correspondantes (√† droite)"><br>  Figure 3. Exemple de coupe 2D (√† gauche) et r√©sultat du marquage des couches g√©ologiques correspondantes (√† droite) ( <a href="https://arxiv.org/pdf/1904.00770v1.pdf">source</a> ) <br><br>  Le principal probl√®me est li√© au volume croissant de donn√©es sismiques obtenues chaque ann√©e dans des conditions g√©ologiques de plus en plus complexes (par exemple, des sections sous-marines √† grande profondeur de mer) et √† l'ambigu√Øt√© de l'interpr√©tation de ces donn√©es.  De plus, dans des conditions de d√©lais serr√©s et / ou de gros volumes, l'interpr√®te fait in√©vitablement des erreurs, par exemple, passe √† c√¥t√© de diverses caract√©ristiques de la section g√©ologique. <br><br>  Ce probl√®me peut √™tre partiellement r√©solu √† l'aide de r√©seaux de neurones, r√©duisant consid√©rablement le travail manuel, acc√©l√©rant ainsi le processus d'interpr√©tation et r√©duisant le nombre d'erreurs.  Pour le fonctionnement du r√©seau de neurones, un certain nombre de sections pr√™tes √† l'emploi et √©tiquet√©es (sections du cube) sont n√©cessaires, et par cons√©quent un marquage complet de toutes les sections (ou du cube entier) sera obtenu, ce qui, id√©alement, ne n√©cessitera qu'un raffinement mineur par une personne pour ajuster certaines sections des horizons ou rep√©rer de petites zones qui le r√©seau n'a pas pu reconna√Ætre correctement. <br><br>  Il existe de nombreuses solutions aux probl√®mes d'interpr√©tation √† l'aide de r√©seaux de neurones, en voici quelques exemples: <a href="https://arxiv.org/abs/1903.11215">un</a> , <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">deux</a> , <a href="">trois</a> .  La difficult√© r√©side dans le fait que chaque ensemble de donn√©es est unique - en raison des particularit√©s des roches g√©ologiques de la r√©gion √©tudi√©e, en raison de divers moyens techniques et m√©thodes d'exploration sismique, en raison des diverses m√©thodes utilis√©es pour transformer les donn√©es brutes en donn√©es pr√™tes √† l'emploi.  M√™me √† cause des bruits ext√©rieurs (par exemple, un chien qui aboie et d'autres sons forts), qu'il n'est pas toujours possible de supprimer compl√®tement.  Par cons√©quent, chaque t√¢che doit √™tre r√©solue individuellement. <br><br>  Mais, malgr√© cela, de nombreux travaux permettent de chercher √† t√¢tons des approches g√©n√©rales distinctes pour r√©soudre divers probl√®mes d'interpr√©tation. <br><br>  Nous √† <a href="https://maritimeai.net/">MaritimeAI</a> (un projet d√©velopp√© √† partir de la <a href="http://ods.ai/">communaut√©</a> Machine Learning for Social Goods <a href="http://ods.ai/">ODS</a> , <a href="https://habr.com/ru/company/ods/blog/454964/">un article sur nous</a> ) pour chaque zone de notre domaine d'int√©r√™t (recherche en mer) √©tudions des travaux d√©j√† publi√©s et menons nos propres exp√©riences, nous permettant de clarifier les limites et les caract√©ristiques de l'application de certains solutions, et parfois trouver vos propres approches. <br><br>  Les r√©sultats d'une exp√©rience que nous d√©crivons dans cet article. <br><br><h2>  Objectifs de recherche commerciale </h2><br>  Il suffit qu'un sp√©cialiste de la science des donn√©es jette un coup d'≈ìil √† la figure 3 pour soupirer de soulagement - une t√¢che courante de la segmentation d'image s√©mantique, pour laquelle de nombreuses architectures de r√©seaux de neurones et m√©thodes d'enseignement ont √©t√© invent√©es.  Il vous suffit de choisir les bons et de former le r√©seau. <br><br>  Mais pas si simple. <br><br>  Pour obtenir un bon r√©sultat √† l'aide d'un r√©seau de neurones, vous avez besoin autant que possible de donn√©es d√©j√† balis√©es sur lesquelles il va apprendre.  Mais notre t√¢che est pr√©cis√©ment de r√©duire la quantit√© de travail manuel.  Et il est rarement possible d'utiliser des donn√©es balis√©es d'autres r√©gions en raison de leurs fortes diff√©rences dans la structure g√©ologique. <br><br>  Nous traduisons ce qui pr√©c√®de dans la langue des affaires. <br><br>  Pour que l'utilisation des r√©seaux de neurones soit √©conomiquement justifi√©e, il est n√©cessaire de minimiser la quantit√© d'interpr√©tation manuelle primaire et les raffinements des r√©sultats obtenus.  Mais la r√©duction des donn√©es pour la formation du r√©seau affectera n√©gativement la qualit√© de son r√©sultat.  Un r√©seau de neurones peut-il donc acc√©l√©rer et faciliter le travail des interpr√®tes et am√©liorer la qualit√© des images √©tiquet√©es?  Ou simplement compliquer le processus habituel? <br><br>  Le but de cette √©tude est de tenter de d√©terminer le volume minimum suffisant de donn√©es de cube sismique balis√© pour un r√©seau de neurones et d'√©valuer les r√©sultats obtenus.  Nous avons essay√© de trouver des r√©ponses aux questions suivantes, qui devraient aider les "propri√©taires" des r√©sultats de l'enqu√™te sismique √† d√©cider de l'interpr√©tation manuelle ou partiellement automatis√©e: <br><br><ol><li>  De combien de donn√©es les experts ont-ils besoin pour cr√©er un r√©seau de neurones?  Et quelles donn√©es choisir pour cela? </li><li>  Que se passe-t-il √† une telle sortie?  Un raffinement manuel des pr√©dictions du r√©seau neuronal sera-t-il n√©cessaire?  Si oui, dans quelle mesure est-il complexe et volumineux? </li></ol><br><h2>  Description g√©n√©rale de l'exp√©rience et des donn√©es utilis√©es </h2><br>  Pour l'exp√©rience, nous avons s√©lectionn√© l'un des probl√®mes d'interpr√©tation, √† savoir la t√¢che d'isoler les couches g√©ologiques sur les coupes 2D d'un cube sismique (voir figure 3).  Nous avons d√©j√† essay√© de r√©soudre ce probl√®me (voir <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">ici</a> ) et, selon les auteurs, nous avons obtenu un bon r√©sultat pour 1% des tranches s√©lectionn√©es au hasard.  Compte tenu du volume du cube, ce sont 16 images.  Cependant, l'article ne fournit pas de param√®tres de comparaison et il n'y a pas de description de la m√©thodologie de formation (fonction de perte, optimiseur, sch√©ma de changement de la vitesse d'apprentissage, etc.), ce qui rend l'exp√©rience irreproductible. <br><br>  De plus, les r√©sultats qui y sont pr√©sent√©s, √† notre avis, sont insuffisants pour obtenir des r√©ponses compl√®tes aux questions pos√©es.  Cette valeur est-elle optimale √† 1%?  Ou peut-√™tre que pour un autre √©chantillon de tranches, ce sera diff√©rent?  Puis-je s√©lectionner moins de donn√©es?  Vaut-il la peine d'en prendre plus?  Comment le r√©sultat va-t-il changer?  Etc. <br><br>  Pour l'exp√©rience, nous avons pris le m√™me ensemble de donn√©es enti√®rement √©tiquet√©es du secteur n√©erlandais de la mer du Nord.  Les donn√©es sismiques source sont disponibles sur le site Web Open Seismic Repository: <a href="https://terranubis.com/datainfo/Netherlands-Offshore-F3-Block-Complete">Project Netherlands Offshore F3 Block</a> .  Une br√®ve description peut √™tre trouv√©e dans <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Silva et al.</a>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">"Netherlands Dataset: A New Public Dataset for Machine Learning in Seismic Interpretation</a> . <a href="https://arxiv.org/pdf/1904.00770v1.pdf">"</a> <br><br>  Puisque dans notre cas, nous parlons de tranches 2D, nous n'avons pas utilis√© le cube 3D d'origine, mais le ¬´d√©coupage¬ª d√©j√† fait, disponible ici: <a href="https://zenodo.org/record/1471548">Netherlands F3 Interpretation Dataset</a> . <br><br>  Au cours de l'exp√©rience, nous avons r√©solu les t√¢ches suivantes: <br><br><ol><li>  Nous avons examin√© les donn√©es source et s√©lectionn√© les tranches, dont la qualit√© est la plus proche du marquage manuel. </li><li>  Nous avons enregistr√© l'architecture du r√©seau neuronal, la m√©thodologie et les param√®tres de la formation, et le principe de s√©lection des tranches pour la formation et la validation. </li><li>  Nous avons form√© 20 r√©seaux neuronaux identiques sur diff√©rents volumes de donn√©es du m√™me type de tranches pour comparer les r√©sultats. </li><li>  Nous avons form√© 20 autres r√©seaux de neurones sur une quantit√© diff√©rente de donn√©es de diff√©rents types de tranches pour comparer les r√©sultats. </li><li>  Estimation du degr√© de raffinement manuel n√©cessaire des r√©sultats pr√©vus. </li></ol><br>  Les r√©sultats de l'exp√©rience sous forme de m√©triques estim√©es et pr√©dits par les r√©seaux de masques de tranche sont pr√©sent√©s ci-dessous. <br><br><h2>  T√¢che 1. S√©lection des donn√©es </h2><br>  Ainsi, comme donn√©es initiales, nous avons utilis√© des lignes et des lignes transversales pr√™tes √† l'emploi du cube sismique du secteur n√©erlandais de la mer du Nord.  Une analyse d√©taill√©e a montr√© que tout ne se passe pas bien - il existe de nombreuses images et masques avec des artefacts et m√™me des d√©formations graves (voir les figures 4 et 5). <br><br><img src="https://habrastorage.org/webt/0d/d-/iv/0dd-iveosyikwl35e4uylytlnss.png" alt="Exemple de masque d'artefact"><br>  Figure 4. Exemple de masque avec des artefacts <br><br><img src="https://habrastorage.org/webt/iz/_k/3j/iz_k3jbbvf4adnpgbzmehevzegm.png" alt="Exemple de masque d√©form√©"><br>  Figure 5. Un exemple de masque d√©form√© <br><br>  Avec un marquage manuel, rien de tel ne sera observ√©.  Par cons√©quent, en simulant le travail de l'interpr√®te, pour la formation du r√©seau, nous n'avons choisi que des masques propres, apr√®s avoir regard√© toutes les tranches.  En cons√©quence, 700 crosslines et 400 inlines ont √©t√© s√©lectionn√©es. <br><br><h2>  T√¢che 2. Fixer les param√®tres de l'exp√©rience </h2><br>  Cette section est tout d'abord int√©ressante pour les sp√©cialistes de la science des donn√©es, par cons√©quent, une terminologie appropri√©e sera utilis√©e. <br><br>  Puisque les alignements et les croisements sont constitu√©s des m√™mes traces sismiques, deux hypoth√®ses mutuellement exclusives peuvent √™tre avanc√©es: <br><br><ol><li>  La formation ne peut √™tre effectu√©e que sur un type de tranches (par exemple, en ligne), en utilisant des images d'un autre type comme s√©lection retard√©e.  Cela donnera une √©valuation plus ad√©quate du r√©sultat, car  les tranches restantes du m√™me type que celles utilis√©es lors de la formation seront toujours similaires √† celles de la formation. </li><li>  Pour l'entra√Ænement, il est pr√©f√©rable d'utiliser un m√©lange de tranches de diff√©rents types, car il s'agit d'une augmentation pr√™te √† l'emploi. </li></ol><br>  V√©rifiez-le. <br><br>  De plus, la similitude des tranches voisines du m√™me type et le d√©sir d'obtenir un r√©sultat reproductible nous ont conduit √† une strat√©gie de s√©lection des tranches pour la formation et la validation, non pas par un principe arbitraire, mais uniform√©ment dans tout le cube, c'est-√†-dire  de sorte que les tranches soient aussi √©loign√©es que possible et couvrent donc la plus grande vari√©t√© de donn√©es. <br><br>  Pour la validation, 2 tranches ont √©t√© utilis√©es, √©galement r√©parties √©galement entre les images adjacentes de l'√©chantillon d'apprentissage.  Par exemple, dans le cas d'un √©chantillon d'apprentissage de 3 inlines, l'√©chantillon de validation √©tait compos√© de 4 inlines, pour 3 inlines et 3 crosslines, de 8 tranches, respectivement. <br><br>  En cons√©quence, nous avons men√© 2 s√©ries de formations: <br><br><ol><li>  Formation sur des √©chantillons de lignes de 3 √† 20 tranches uniform√©ment r√©parties sur le cube avec v√©rification du r√©sultat des pr√©dictions du r√©seau sur les lignes restantes et sur toutes les lignes crois√©es.  De plus, une formation a √©t√© dispens√©e sur 80 et 160 sections. </li><li>  Formation √† des √©chantillons combin√©s √† partir de lignes en ligne et de lignes transversales de 3 √† 10 sections de chaque type uniform√©ment r√©parties sur un cube avec v√©rification du r√©sultat des pr√©visions du r√©seau dans les images restantes.  De plus, une formation a √©t√© dispens√©e sur 40 + 40 et 80 + 80 sections. </li></ol><br>  Avec cette approche, il est n√©cessaire de tenir compte du fait que les tailles des √©chantillons de formation et de validation varient consid√©rablement, ce qui complique la comparaison, mais le volume des images restantes n'est pas tellement r√©duit qu'il peut √™tre utilis√© pour √©valuer correctement les changements dans le r√©sultat. <br><br>  Pour r√©duire le recyclage de l'√©chantillon d'apprentissage, l'augmentation a √©t√© utilis√©e avec une taille de recadrage arbitraire 448x64 et une image miroir le long de l'axe vertical avec une probabilit√© de 0,5. <br><br>  Comme nous ne nous int√©ressons √† la d√©pendance de la qualit√© du r√©sultat que sur le nombre de tranches dans l'√©chantillon d'apprentissage, le pr√©traitement des images peut √™tre n√©glig√©.  Nous avons utilis√© une seule couche d'images PNG sans aucun changement. <br><br>  Pour la m√™me raison, dans le cadre de cette exp√©rience, il n'est pas n√©cessaire de rechercher la meilleure architecture r√©seau - l'essentiel est qu'elle soit la m√™me √† chaque √©tape.  Nous avons choisi une UNet simple mais bien √©tablie pour ces t√¢ches: <br><br><img src="https://habrastorage.org/webt/i0/jg/fs/i0jgfsxjgo5nibyatbaokikg0tg.png" alt="Architecture de r√©seau"><br>  Figure 6. Architecture du r√©seau <br><br>  La fonction de perte consistait en une combinaison du coefficient de Jacquard et de l'entropie crois√©e binaire: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">jaccard_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smoothing = <span class="hljs-number"><span class="hljs-number">1.</span></span> intersection = tf.reduce_sum(y_true * y_pred, axis = (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) union = tf.reduce_sum(y_true + y_pred, axis = (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) jaccard = (intersection + smoothing) / (union - intersection + smoothing) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - tf.reduce_mean(jaccard) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0.75</span></span> * jaccard_loss(y_true, y_pred) + <span class="hljs-number"><span class="hljs-number">0.25</span></span> * keras.losses.binary_crossentropy(y_true, y_pred)</code> </pre> <br>  Autres options d'apprentissage: <br><br><pre> <code class="python hljs">keras.optimizers.SGD(lr = <span class="hljs-number"><span class="hljs-number">0.01</span></span>, momentum = <span class="hljs-number"><span class="hljs-number">0.9</span></span>, nesterov = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) keras.callbacks.EarlyStopping(monitor = <span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience = <span class="hljs-number"><span class="hljs-number">10</span></span>), keras.callbacks.ReduceLROnPlateau(monitor = <span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience = <span class="hljs-number"><span class="hljs-number">5</span></span>)</code> </pre> <br>  Pour r√©duire l'influence du caract√®re al√©atoire du choix des poids initiaux sur les r√©sultats, le r√©seau a √©t√© form√© sur 3 inlines pour 1 √®re.  Toutes les autres formations ont commenc√© avec ces poids re√ßus. <br><br>  Chaque r√©seau a √©t√© form√© sur la GeForce GTX 1060 6 Go pour 30 √† 60 √©poques.  La formation de chaque √©poque a pris 10 √† 30 secondes selon la taille de l'√©chantillon. <br><br><h2>  T√¢che 3. Formation sur un type de tranches (en ligne) </h2><br>  La premi√®re s√©rie comprenait 18 formations r√©seau ind√©pendantes sur 3 √† 20 lignes.  Et, bien que nous ne soyons int√©ress√©s que par l'estimation du coefficient de Jacquard sur des tranches non utilis√©es en formation et validation, il est int√©ressant de consid√©rer tous les graphiques. <br><br>  Rappelons que les r√©sultats d'interpr√©tation pour chaque tranche sont de 10 classes (couches g√©ologiques), qui sur les figures sont en outre marqu√©es par des nombres de 0 √† 9. <br><br><img src="https://habrastorage.org/webt/g0/1o/tm/g01otmt3jodludsk-puf_fv1kic.png" alt="Coefficient Jacquard pour l'ensemble d'entra√Ænement"><br>  Figure 7. Coefficient Jacquard pour l'ensemble d'entra√Ænement <br><br><img src="https://habrastorage.org/webt/e9/fs/g7/e9fsg7p5aemva9-k7g_jruodo6m.png" alt="Coefficient Jacquard pour l'√©chantillon de validation"><br>  Figure 8. Coefficient Jacquard pour l'√©chantillon de validation <br><br><img src="https://habrastorage.org/webt/qe/di/av/qediavhy6nbnjmci8-whfxyocuy.png" alt="Coefficient Jacquard pour les autres inlines"><br>  Figure 9. Coefficient Jacquard pour les autres lignes <br><br><img src="https://habrastorage.org/webt/h_/qm/2n/h_qm2n3v5fapcqprdjluppb1-cy.png" alt="Coefficient Jacquard pour les lignes crois√©es"><br>  Figure 10. Coefficient Jacquard pour les lignes crois√©es <br><br>  Un certain nombre de conclusions peuvent √™tre tir√©es des diagrammes ci-dessus. <br><br>  Premi√®rement, la qualit√© de la pr√©vision, mesur√©e par le coefficient Jacquard, d√©j√† √† 9 inlines atteint une valeur tr√®s √©lev√©e, apr√®s quoi elle continue de cro√Ætre, mais pas de mani√®re aussi intensive.  C'est-√†-dire  l'hypoth√®se de la suffisance d'un petit nombre d'images marqu√©es pour la formation d'un r√©seau neuronal est confirm√©e. <br><br>  Deuxi√®mement, un r√©sultat tr√®s √©lev√© a √©t√© obtenu pour les lignes crois√©es, malgr√© le fait que seules les lignes en ligne ont √©t√© utilis√©es pour la formation et la validation - l'hypoth√®se de la suffisance d'un seul type de tranches est √©galement confirm√©e.  Cependant, pour la conclusion finale, vous devez comparer les r√©sultats avec une formation sur un m√©lange de lignes et de lignes crois√©es. <br><br>  Troisi√®mement, les m√©triques pour diff√©rentes couches, c'est-√†-dire  La qualit√© de leur reconnaissance est tr√®s diff√©rente.  Cela conduit √† l'id√©e de choisir une strat√©gie d'apprentissage diff√©rente, par exemple, en utilisant des poids ou des r√©seaux suppl√©mentaires pour les classes faibles, ou un syst√®me √† part enti√®re ¬´un contre tous¬ª. <br><br>  Enfin, il convient de noter que le coefficient Jacquard ne peut pas donner une description compl√®te de la qualit√© du r√©sultat.  Afin d'√©valuer les pr√©dictions de r√©seau dans ce cas, il est pr√©f√©rable de regarder les masques eux-m√™mes pour √©valuer leur aptitude √† la r√©vision par l'interpr√©teur. <br><br>  Les figures suivantes montrent le balisage par un r√©seau form√© sur 10 inlines.  La deuxi√®me colonne, marqu√©e ¬´masque GT¬ª (masque de v√©rit√© au sol), repr√©sente l'interpr√©tation cible, la troisi√®me est la pr√©diction du r√©seau neuronal. <br><br><img src="https://habrastorage.org/webt/ub/pa/6t/ubpa6tj0p0gfe0ixdoysku8_bzw.png" alt="Exemples de pr√©visions de r√©seau pour les inlines"><br><img src="https://habrastorage.org/webt/me/fi/mu/mefimu03q9gzh_hcdomwrtagwm0.png" alt="Exemples de pr√©visions de r√©seau pour les inlines"><br>  Figure 11. Exemples de pr√©visions de r√©seau pour les inlines <br><br><img src="https://habrastorage.org/webt/7l/25/5_/7l255_ofscuyfhozqokfiw5ifjk.png" alt="Exemples de pr√©visions de r√©seau pour les lignes crois√©es"><br><img src="https://habrastorage.org/webt/eh/kd/hw/ehkdhwyuzl0j_sl5rhy-6m0613k.png" alt="Exemples de pr√©visions de r√©seau pour les lignes crois√©es"><br>  Figure 12. Exemples de pr√©visions de r√©seau pour les lignes crois√©es <br><br>  On peut voir sur les figures que, avec des masques assez propres, le r√©seau est difficile √† reconna√Ætre des cas complexes, m√™me sur les lignes elles-m√™mes.  Ainsi, malgr√© la m√©trique suffisamment √©lev√©e pour 10 tranches, une partie des r√©sultats n√©cessitera un raffinement important. <br><br>  La taille des √©chantillons que nous consid√©rons fluctue autour de 1% du volume total de donn√©es - et cela permet d√©j√† de bien d√©limiter une partie des tranches restantes.  Dois-je augmenter le nombre de sections initialement marqu√©es?  Cela donnera-t-il une augmentation comparable de la qualit√©? <br><br>  Consid√©rons la dynamique des changements dans les r√©sultats de pr√©vision par des r√©seaux form√©s sur 5, 10, 15, 20, 80 (5% du volume total du cube) et 160 (10%) en ligne en utilisant les m√™mes sections comme exemple. <br><br><img src="https://habrastorage.org/webt/4c/aw/ye/4cawye-bfzessxxllovzxb1-gne.png" alt="Exemples de pr√©visions de r√©seaux form√©s sur diff√©rents volumes de l'√©chantillon de formation"><br>  Figure 13. Exemples de pr√©visions de r√©seaux form√©s sur diff√©rents volumes de l'√©chantillon de formation <br><br>  La figure 13 montre qu'une augmentation du volume de l'√©chantillon d'apprentissage de 5 ou m√™me 10 fois ne conduit pas √† une am√©lioration significative.  Les tranches d√©j√† bien reconnues dans 10 images d'entra√Ænement ne s'aggravent pas. <br><br>  Ainsi, m√™me un simple r√©seau sans r√©glage et pr√©traitement d'images est capable d'interpr√©ter une partie des tranches avec une qualit√© suffisamment √©lev√©e avec un petit nombre d'images marqu√©es manuellement.  Nous examinerons la question de la part de ces interpr√©tations et de la complexit√© de la finalisation de tranches mal reconnues. <br><br>  Une s√©lection rigoureuse de l'architecture, des param√®tres r√©seau et de la formation, le pr√©traitement des images peuvent am√©liorer ces r√©sultats sur le m√™me volume de donn√©es balis√©es.  Mais cela d√©passe d√©j√† le cadre de l'exp√©rience actuelle. <br><br><h2>  T√¢che 4. Formation sur diff√©rents types de tranches (en ligne et en croix) </h2><br>  Comparons maintenant les r√©sultats de cette s√©rie avec les pr√©visions obtenues par la formation sur un m√©lange de lignes et de lignes crois√©es. <br><br>  Les diagrammes ci-dessous montrent des estimations du coefficient de Jacquard pour diff√©rents √©chantillons, y compris, en comparaison avec les r√©sultats de la s√©rie pr√©c√©dente.  Pour comparaison (voir les bons diagrammes sur les figures), seuls des √©chantillons du m√™me volume ont √©t√© pr√©lev√©s, c'est-√†-dire  10 inlines vs 5 inlines + 5 crosslines, etc. <br><br><img src="https://habrastorage.org/webt/4q/df/qr/4qdfqrbxrh9_blq0e-5rgoh_z14.png" alt="Coefficient Jacquard pour l'ensemble d'entra√Ænement"><br>  Figure 14. Coefficient Jacquard pour l'ensemble d'entra√Ænement <br><br><img src="https://habrastorage.org/webt/s6/uh/pr/s6uhprjziuoobasc5gl0wak7h9y.png" alt="Coefficient Jacquard pour l'√©chantillon de validation"><br>  Figure 15. Coefficient Jacquard pour l'√©chantillon de validation <br><br><img src="https://habrastorage.org/webt/hu/c5/dv/huc5dv9_k7dgwphwygzhypzwpxy.png" alt="Coefficient Jacquard pour les autres inlines"><br>  Figure 16. Coefficient Jacquard pour les autres lignes <br><br><img src="https://habrastorage.org/webt/rx/c3/tz/rxc3tzlw5synjdwoj1j97aj56xy.png" alt="Coefficient Jacquard pour le reste des lignes transversales"><br>  Figure 17. Coefficient Jacquard pour les lignes transversales restantes <br><br>  Les diagrammes illustrent clairement que l'ajout de tranches d'un type diff√©rent n'am√©liore pas les r√©sultats.  M√™me dans le contexte des classes (voir figure 18), l'influence des croisements n'est observ√©e pour aucune des tailles d'√©chantillon consid√©r√©es. <br><br><img src="https://habrastorage.org/webt/0z/yx/sh/0zyxshghib81lkvjqe6le4sgute.png" alt="Coefficient Jacquard pour diff√©rentes classes (le long de l'axe X) et diff√©rentes tailles et composition de l'√©chantillon d'apprentissage"><br>  Figure 18. Coefficient de jacquard pour diff√©rentes classes (le long de l'axe X) et diff√©rentes tailles et composition de l'√©chantillon d'apprentissage <br><br>  Pour compl√©ter le tableau, nous comparons les r√©sultats des pr√©visions du r√©seau sur les m√™mes tranches: <br><br><img src="https://habrastorage.org/webt/2q/qh/wn/2qqhwnj0_lemjeaog44lunjbw8g.png" alt="Comparaison des pr√©visions de r√©seau pour inline"><br>  Figure 19. Comparaison des pr√©visions de r√©seau pour en ligne <br><br><img src="https://habrastorage.org/webt/8f/gk/vm/8fgkvmw0860finev7nzkuuwsfmc.png" alt="Comparaison des pr√©visions de r√©seau pour les lignes crois√©es"><br>  Figure 20. Comparaison des pr√©visions de r√©seau pour les lignes crois√©es <br><br>  Une comparaison visuelle confirme l'hypoth√®se selon laquelle l'ajout de diff√©rents types de tranches √† la formation ne change pas fondamentalement la situation.  Certaines am√©liorations ne peuvent √™tre observ√©es que pour la ligne transversale gauche, mais sont-elles globales?  Nous essaierons de r√©pondre davantage √† cette question. <br><br><h2>  T√¢che 5. √âvaluation du volume de raffinement manuel </h2><br>  Pour une conclusion finale sur les r√©sultats, il est n√©cessaire d'estimer le degr√© de raffinement manuel des pr√©visions de r√©seau obtenues.  Pour ce faire, nous avons d√©termin√© le nombre de composants connect√©s (c'est-√†-dire des taches solides de la m√™me couleur) sur chaque pr√©vision obtenue.  Si cette valeur est 10, alors les couches sont s√©lectionn√©es correctement et nous parlons d'un maximum de correction d'horizon mineure.  S'il n'y en a pas beaucoup plus, il vous suffit de ¬´nettoyer¬ª les petites zones de l'image.  S'il y en a beaucoup plus, tout est mauvais et peut m√™me n√©cessiter une r√©organisation compl√®te. <br><br>  Pour les tests, nous avons s√©lectionn√© 110 lignes et 360 lignes crois√©es qui n'ont √©t√© utilis√©es dans la formation d'aucun des r√©seaux consid√©r√©s. <br><br>  Tableau 1. Statistiques moyennes sur les deux types de tranches <br><img src="https://habrastorage.org/webt/ov/b8/fs/ovb8fsaxxqbwea4jn4_pw_dsd_e.png" alt="Statistiques moyennes sur les deux types de tranches"><br><br>  Le tableau 1 confirme certains des r√©sultats pr√©c√©dents.  En particulier, lors de l'utilisation de tranches de 1% pour la formation, il n'y a pas de diff√©rence, utilisez un type de tranches ou les deux, et le r√©sultat peut √™tre caract√©ris√© comme suit: <br><br><ul><li>  environ 10% des pr√©visions sont proches de l'id√©al, c'est-√†-dire  ne n√©cessitent pas plus que des ajustements √† des sections individuelles des horizons; </li><li>  50% des pr√©visions ne contiennent pas plus de 15 spots, soit  pas plus de 5 suppl√©mentaires; </li><li>  75% des pr√©visions ne contiennent pas plus de 20 spots, soit  pas plus de 10 suppl√©mentaires; </li><li>  les 25% restants des pr√©visions n√©cessitent un raffinement plus substantiel, y compris, √©ventuellement, une refonte compl√®te des tranches individuelles. </li></ul><br>  Une augmentation de la taille de l'√©chantillon allant jusqu'√† 5% modifie la situation.  En particulier, les r√©seaux form√©s sur un m√©lange de sections affichent des indicateurs significativement plus √©lev√©s, bien que la valeur maximale des composants augmente √©galement, ce qui indique l'apparition d'interpr√©tations distinctes de tr√®s mauvaise qualit√©.  Cependant, si vous augmentez l'√©chantillon de 5 fois et utilisez un m√©lange de tranches: <br><br><ul><li>  environ 30% des pr√©visions sont proches de l'id√©al, c'est-√†-dire  ne n√©cessitent pas plus que des ajustements √† des sections individuelles des horizons; </li><li>  50% des pr√©visions ne contiennent pas plus de 12 spots, soit  pas plus de 2 suppl√©mentaires; </li><li>  75% des pr√©visions ne contiennent pas plus de 14 spots, soit  pas plus de 4 suppl√©mentaires; </li><li>  les 25% restants des pr√©visions n√©cessitent un raffinement plus substantiel, y compris, √©ventuellement, une refonte compl√®te des tranches individuelles. </li></ul><br>  Une nouvelle augmentation de la taille de l'√©chantillon n'am√©liore pas les r√©sultats. <br><br>  En g√©n√©ral, pour le cube de donn√©es que nous avons examin√©, nous pouvons tirer des conclusions sur la suffisance de 1 √† 5% du volume total de donn√©es pour obtenir un bon r√©sultat √† partir d'un r√©seau de neurones. <br><br>  Selon ces donn√©es, en conjonction avec les m√©triques et illustrations ci-dessus, il est d√©j√† possible de tirer des conclusions sur la pertinence d'utiliser des r√©seaux de neurones pour aider les interpr√®tes et sur les r√©sultats que les sp√©cialistes traiteront. <br><br><h2>  Conclusions </h2><br>  Ainsi, maintenant nous pouvons r√©pondre aux questions pos√©es au d√©but de l'article, en utilisant les r√©sultats obtenus sur l'exemple d'un cube sismique de la mer du Nord: <br><br>  <b>De combien de donn√©es les experts ont-ils besoin pour cr√©er un r√©seau de neurones?</b>  <b>Et quelles donn√©es dois-je choisir?</b> <br><br>  Pour avoir une bonne pr√©vision du r√©seau, il suffit vraiment de pr√©-marquer 1 √† 5% du nombre total de tranches.  Une nouvelle augmentation de volume n'entra√Æne pas une am√©lioration du r√©sultat, comparable √† l'augmentation du nombre de donn√©es pr√©c√©demment marqu√©es.  Pour obtenir un meilleur balisage sur un si petit volume √† l'aide d'un r√©seau de neurones, vous devez essayer d'autres approches, par exemple, affiner l'architecture et les strat√©gies d'apprentissage, le pr√©traitement des images, etc. <br><br>  Pour le marquage pr√©liminaire, il vaut la peine de choisir des tranches des deux types - en ligne et en croix. <br><br>  <b>Que se passe-t-il √† une telle sortie?</b>  <b>Un raffinement manuel des pr√©dictions du r√©seau neuronal sera-t-il n√©cessaire?</b>  <b>Si oui, dans quelle mesure est-il complexe et volumineux?</b> <b><br></b> <br>  En cons√©quence, une partie importante des images marqu√©es par un tel r√©seau neuronal ne n√©cessitera pas le raffinement le plus significatif, consistant en la correction de zones individuelles mal reconnues.  Parmi eux, de telles interpr√©tations ne n√©cessiteront aucune correction.  Et uniquement pour des images uniques, vous devrez peut-√™tre une nouvelle mise en page manuelle. <br><br>  Bien s√ªr, lors de l'optimisation de l'algorithme d'apprentissage et des param√®tres r√©seau, ses capacit√©s de pr√©diction peuvent √™tre am√©lior√©es.  Dans notre exp√©rience, la solution de ces probl√®mes n'a pas √©t√© incluse. <br><br>  De plus, les r√©sultats d'une √©tude sur un cube sismique ne devraient pas √™tre g√©n√©ralis√©s sans r√©fl√©chir - pr√©cis√©ment en raison de l'unicit√© de chaque ensemble de donn√©es.  Mais ces r√©sultats sont la confirmation d'une exp√©rience men√©e par d'autres auteurs, et la base de comparaison avec nos √©tudes ult√©rieures, dont nous parlerons √©galement sous peu. <br><br><h2>  Remerciements </h2><br>  Et √† la fin, je voudrais remercier mes coll√®gues de <a href="https://maritimeai.net/">MaritimeAI</a> (en particulier Andrey Kokhan) et <a href="http://ods.ai/">ODS</a> pour leurs pr√©cieux commentaires et leur aide! <br><br><h2>  Liste des sources utilis√©es: </h2><br><ol><li>  <a href="https://arxiv.org/abs/1903.11215">Bas Peters, Eldad Haber, Justin Granek.</a>  <a href="https://arxiv.org/abs/1903.11215">R√©seaux de neurones pour les g√©ophysiciens et leur application √† l'interpr√©tation des donn√©es sismiques</a> </li><li>  <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">Hao Wu, Bo Zhang.</a>  <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">Un r√©seau neuronal codeur-d√©codeur convolutionnel profond pour aider le suivi de l'horizon sismique</a> </li><li>  <a href="">Thilo Wrona, Indranil Pan, Robert L. Gawthorpe et Haakon Fossen.</a>  <a href="">Analyse des faci√®s sismiques √† l'aide de l'apprentissage automatique</a> </li><li>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Reinaldo Mozart Silva, Lais Baroni, Rodrigo S. Ferreira, Daniel Civitarese, Daniela Szwarcman, Emilio Vital Br√©sil.</a>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Pays-Bas: un nouveau jeu de donn√©es public pour l'apprentissage automatique en interpr√©tation sismique</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr482780/">https://habr.com/ru/post/fr482780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr482762/index.html">42 000 000 000 de visites. PornHub r√©sume 2019</a></li>
<li><a href="../fr482764/index.html">Rhasspy est une bo√Æte √† outils vocale open source et enti√®rement hors ligne. Reconnaissance de la langue russe. Aucune fuite vers le cloud</a></li>
<li><a href="../fr482766/index.html">√Ä propos de certains probl√®mes de microoptimisation</a></li>
<li><a href="../fr482768/index.html">Quand DeepRegistry appara√Ætra-t-il? De l'amour des r√©gulateurs mondiaux pour tout contr√¥ler</a></li>
<li><a href="../fr482778/index.html">Ventilation avec r√©cup√©ration dans l'appartement. Sans conduits et SMS</a></li>
<li><a href="../fr482784/index.html">La vie secr√®te d'un serveur Linux ou d'une attaque par force brute de fan sur le sous-syst√®me SSH</a></li>
<li><a href="../fr482786/index.html">√ânigme non r√©solue</a></li>
<li><a href="../fr482788/index.html">Contenu du TPU Google Coral Edge: tests de vitesse et d'analyse de l'appareil</a></li>
<li><a href="../fr482790/index.html">Oubliez le cryptage homomorphique: nous avons maintenant un cryptage fonctionnel</a></li>
<li><a href="../fr482794/index.html">R√©seaux de neurones. O√π est-ce que tout va</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
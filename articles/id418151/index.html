<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💳 🧑🏿‍🤝‍🧑🏾 🕺🏽 Pengantar tugas mengenali emosi 🤫 🧙 🖥️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pengenalan emosi adalah topik hangat di bidang kecerdasan buatan. Bidang aplikasi teknologi yang paling menarik meliputi: pengenalan pengemudi, riset ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengantar tugas mengenali emosi</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/speechpro/blog/418151/"><p>  Pengenalan emosi adalah topik hangat di bidang kecerdasan buatan.  Bidang aplikasi teknologi yang paling menarik meliputi: pengenalan pengemudi, riset pemasaran, sistem analisis video untuk kota pintar, interaksi manusia-mesin, pemantauan siswa yang mengambil kursus online, perangkat yang dapat dipakai, dll. </p><br><p>  Tahun ini, MDG mendedikasikan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sekolah pembelajaran mesin musim panasnya</a> untuk topik ini.  Dalam artikel ini saya akan mencoba memberikan perjalanan singkat ke masalah mengenali keadaan emosional seseorang dan menceritakan tentang pendekatan untuk solusinya. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/626/db4/5bb/626db45bb7b0aad7fdbc2970c0b4183f.jpg" alt="gambar"></div><a name="habracut"></a><br><h3 id="chto-takoe-emocii">  Apa itu emosi? </h3><br><p>  Emosi adalah jenis proses mental khusus yang mengungkapkan pengalaman seseorang tentang hubungannya dengan dunia dan dirinya sendiri.  Menurut salah satu teori, penulisnya adalah ahli fisiologi Rusia P.K.  Anokhin, kemampuan untuk mengalami emosi dikembangkan dalam proses evolusi sebagai cara adaptasi makhluk hidup yang lebih sukses dengan kondisi keberadaan.  Emosi bermanfaat untuk bertahan hidup dan memungkinkan makhluk hidup dengan cepat dan paling ekonomis merespons pengaruh eksternal. </p><br><p>  Emosi memainkan peran besar dalam kehidupan manusia dan komunikasi antarpribadi.  Mereka dapat diekspresikan dengan berbagai cara: ekspresi wajah, postur, reaksi motorik, suara dan reaksi otonom (denyut jantung, tekanan darah, laju pernapasan).  Namun, wajah orang tersebut paling ekspresif. </p><br><p>  Setiap orang mengekspresikan emosi dengan beberapa cara berbeda.  Psikolog Amerika terkenal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Paul Ekman</a> , yang mempelajari perilaku non-verbal dari suku-suku terasing di Papua Nugini pada tahun 70-an abad terakhir, menemukan bahwa sejumlah emosi, yaitu: kemarahan, ketakutan, kesedihan, jijik, jijik, kejutan, dan kegembiraan adalah universal dan dapat universal untuk dipahami oleh manusia, terlepas dari budayanya. </p><br><p>  Orang dapat mengekspresikan berbagai macam emosi.  Dipercayai bahwa keduanya dapat digambarkan sebagai kombinasi emosi-emosi dasar (misalnya, nostalgia adalah sesuatu antara kesedihan dan sukacita).  Tetapi pendekatan kategoris semacam itu tidak selalu nyaman, karena  tidak memungkinkan untuk mengukur kekuatan emosi.  Oleh karena itu, bersama dengan model emosi yang terpisah, sejumlah yang terus menerus dikembangkan.  Model J. Russell memiliki basis dua dimensi di mana setiap emosi ditandai oleh tanda (valensi) dan intensitas (gairah).  Karena kesederhanaannya, model Russell baru-baru ini menjadi semakin populer dalam konteks tugas mengklasifikasikan ekspresi wajah secara otomatis. </p><br><div style="text-align:center;"><img height="300" src="https://habrastorage.org/getpro/habr/post_images/f59/cd1/a24/f59cd1a24e77d64759641a076d86bef1.png" alt="gambar"></div><br><p>  Jadi, kami mengetahui bahwa jika Anda tidak berusaha menyembunyikan rangsangan emosional, maka keadaan Anda saat ini dapat diperkirakan dengan ekspresi wajah.  Selain itu, dengan menggunakan prestasi modern di bidang pembelajaran yang mendalam, bahkan dimungkinkan untuk membangun pendeteksi kebohongan berdasarkan seri “Lie to me”, dasar ilmiah yang secara langsung disediakan oleh Paul Ekman.  Namun, tugas ini jauh dari sederhana.  Seperti yang ditunjukkan oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">penelitian oleh</a> ahli saraf, Lisa Feldman Barrett, ketika mengenali emosi, seseorang secara aktif menggunakan informasi kontekstual: suara, tindakan, situasi.  Lihatlah foto-foto di bawah ini, sungguh.  Hanya menggunakan area wajah, tidak mungkin membuat prediksi yang benar.  Dalam hal ini, untuk mengatasi masalah ini, perlu menggunakan modalitas tambahan dan informasi tentang perubahan sinyal dari waktu ke waktu. </p><br><div style="text-align:center;"><img height="200" src="https://habrastorage.org/webt/el/a6/t7/ela6t7ig73rti-peenhb7_f0sgs.jpeg" alt="gambar"></div><br><p>  Di sini kita akan mempertimbangkan pendekatan untuk analisis hanya dua modalitas: audio dan video, karena sinyal-sinyal ini dapat diperoleh dengan cara non-kontak.  Untuk mendekati tugas, Anda harus terlebih dahulu mendapatkan data.  Berikut adalah daftar database emosi terbesar yang tersedia untuk umum yang saya tahu.  Gambar dan video dalam database ini ditandai secara manual, beberapa menggunakan Amazon Mechanical Turk. </p><br><table><thead><tr><th>  Judul </th><th>  Data </th><th>  Markup </th><th>  Tahun pembuatan </th></tr></thead><tbody><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">OMG-Emosi tantangan</a> </td><td>  audio / video </td><td>  7 kategori, valensi / gairah </td><td>  2018 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tantangan emotiw</a> </td><td>  audio / video </td><td>  6 kategori </td><td>  2018 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Affectnet</a> </td><td>  gambar </td><td>  7 kategori, valensi / gairah </td><td>  2017 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AFEW-VA</a> </td><td>  videonya </td><td>  valensi / gairah </td><td>  2017 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tantangan EmotioNet</a> </td><td>  gambar </td><td>  16 kategori </td><td>  2017 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Emoreact</a> </td><td>  audio / video </td><td>  17 kategori </td><td>  2016 </td></tr></tbody></table><br><h3 id="klassicheskiy-podhod-k-zadache-klassifikacii-emociy">  Pendekatan klasik untuk klasifikasi emosi </h3><br><p>  Cara termudah untuk menentukan emosi dari gambar wajah didasarkan pada klasifikasi titik-titik kunci (landmark wajah), koordinat yang dapat diperoleh dengan menggunakan berbagai algoritma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">PDM</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CML</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AAM</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DPM</a> atau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CNN</a> .  Biasanya menandai dari 5 hingga 68 poin, mengikatnya ke posisi alis, mata, bibir, hidung, rahang, yang memungkinkan Anda untuk menangkap sebagian ekspresi wajah.  Koordinat titik yang dinormalisasi dapat langsung diserahkan ke pengklasifikasi (misalnya, SVM atau Hutan Acak) dan mendapatkan solusi dasar.  Secara alami, posisi orang harus disejajarkan. </p><br><div style="text-align:center;"><img height="300" src="https://habrastorage.org/getpro/habr/post_images/c60/24a/dbe/c6024adbeaecca98404dcaae3361785e.jpg" alt="gambar"></div><br><p>  Penggunaan sederhana koordinat tanpa komponen visual menyebabkan hilangnya informasi bermanfaat yang signifikan, oleh karena itu, berbagai deskriptor dihitung pada titik-titik ini untuk meningkatkan sistem: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">LBP</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HOG</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SIFT</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">LATCH</a> , dll. Setelah deskriptor digabungkan dan dimensi dikurangi menggunakan PCK, vektor fitur yang dihasilkan dapat digunakan untuk klasifikasi emosi. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/u7/lh/oa/u7lhoatsm4vbqzb_zlksw9ekygy.jpeg" alt="gambar"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ke artikel</a> </p><br><p>  Namun, pendekatan ini sudah dianggap usang, karena diketahui bahwa jaringan konvolusi yang dalam adalah pilihan terbaik untuk analisis data visual. </p><br><h3 id="klassifikaciya-emociy-s-primeneniem-deep-learning">  Klasifikasi emosi menggunakan pembelajaran yang mendalam </h3><br><p>  Untuk membangun pengklasifikasi jaringan saraf, cukup untuk mengambil beberapa jaringan dengan arsitektur dasar, yang sebelumnya dilatih di ImageNet, dan melatih kembali beberapa lapisan terakhir.  Jadi Anda bisa mendapatkan solusi dasar yang baik untuk mengklasifikasikan berbagai data, tetapi dengan mempertimbangkan spesifikasi tugas, jaringan saraf yang digunakan untuk tugas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pengenalan wajah</a> skala besar akan lebih cocok. </p><br><p>  Jadi, cukup mudah untuk membangun penggolong emosi untuk gambar individual, tetapi seperti yang kami ketahui, foto tidak cukup akurat mencerminkan emosi sebenarnya yang dialami seseorang dalam situasi tertentu.  Oleh karena itu, untuk meningkatkan akurasi sistem, perlu menganalisis urutan frame.  Ada dua cara untuk melakukan ini.  Cara pertama adalah memberi makan fitur tingkat tinggi yang diterima dari CNN yang mengklasifikasikan setiap frame individu ke dalam jaringan berulang (mis., LSTM) untuk menangkap komponen waktu. </p><br><div style="text-align:center;"><img height="300" src="https://habrastorage.org/webt/ik/wi/zh/ikwizhwy65xydfoyu15ql3szjbi.jpeg" alt="gambar"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ke artikel</a> </p><br><p>  Cara kedua adalah secara langsung mengumpankan urutan frame yang diambil dari video dalam beberapa langkah ke input 3D-CNN.  CNN serupa menggunakan konvolusi dengan tiga derajat kebebasan yang mengubah input empat dimensi menjadi peta fitur tiga dimensi. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/iv/a2/kd/iva2kdloqzpghk8gfcymk6g5sc4.jpeg" alt="gambar"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ke artikel</a> </p><br><p>  Bahkan, dalam kasus umum, dua pendekatan ini dapat dikombinasikan dengan membangun monster seperti itu. </p><br><div style="text-align:center;"><img height="400" src="https://habrastorage.org/webt/oo/ir/yo/ooiryorm9sh8n0cht5oud1yqbd4.jpeg" alt="gambar"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ke artikel</a> </p><br><h3 id="klassifikaciya-emociy-po-rechi">  Klasifikasi emosi ujaran </h3><br><p>  Berdasarkan data visual, tanda emosi dapat diprediksi dengan akurasi tinggi, tetapi lebih baik menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sinyal ucapan</a> saat menentukan intensitas.  Menganalisis audio sedikit lebih sulit karena variabilitas durasi bicara dan suara speaker yang tinggi.  Biasanya, mereka tidak menggunakan gelombang suara asli, tetapi berbagai set <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">atribut</a> , misalnya: F0, MFCC, LPC, i-vektor, dll. Dalam masalah mengenali emosi melalui ucapan, perpustakaan terbuka <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">OpenSMILE</a> memiliki <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">reputasi yang baik</a> . Ini berisi serangkaian algoritma yang kaya untuk menganalisis pidato dan musikal sinyal.  Setelah ekstraksi, atribut dapat diserahkan ke SVM atau LSTM untuk klasifikasi. </p><br><p>  Baru-baru ini, bagaimanapun, jaringan saraf convolutional juga telah mulai menembus bidang analisis suara, menggeser pendekatan yang ditetapkan.  Untuk menerapkannya, suara direpresentasikan dalam bentuk spektogram dalam skala linier atau mel, setelah itu dioperasikan dengan spektogram yang diperoleh seperti halnya gambar dua dimensi biasa.  Dalam hal ini, masalah ukuran spektogram yang berubah-ubah sepanjang sumbu waktu diselesaikan secara elegan menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pengumpulan statistik</a> atau dengan memasukkan jaringan berulang dalam arsitektur. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/kq/4d/ts/kq4dtsbybmnn3nsq6cwq_wek19u.jpeg" alt="gambar"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ke artikel</a> </p><br><h3 id="audiovizualnoe-raspoznavanie-emociy">  Pengenalan emosi secara audiovisual </h3><br><p>  Jadi, kami memeriksa sejumlah pendekatan untuk analisis modalitas audio dan video, tahap terakhir tetap - kombinasi pengklasifikasi untuk menghasilkan solusi akhir.  Cara paling sederhana adalah menggabungkan peringkat mereka secara langsung.  Dalam hal ini, cukup untuk mengambil maksimum atau rata-rata.  Opsi yang lebih sulit adalah menggabungkan pada tingkat penanaman untuk setiap modalitas.  SVM sering digunakan untuk ini, tetapi ini tidak selalu benar, karena embeddings dapat memiliki tingkat yang berbeda.  Dalam hal ini, algoritma yang lebih maju dikembangkan, misalnya: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Multiple Kernel Learning</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ModDrop</a> . </p><br><p>  Dan tentu saja, ada baiknya menyebutkan kelas solusi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">end-to-end</a> yang dapat dilatih langsung pada data mentah dari beberapa sensor tanpa pemrosesan awal. </p><br><p>  Secara umum, tugas pengenalan emosi secara otomatis masih jauh dari diselesaikan.  Menilai dari hasil Pengakuan Emosi tahun lalu di kontes Wild, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">solusi terbaik</a> mencapai akurasi sekitar 60%.  Saya berharap bahwa informasi yang disajikan dalam artikel ini akan cukup untuk mencoba membangun sistem kita sendiri untuk mengenali emosi. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id418151/">https://habr.com/ru/post/id418151/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id418141/index.html">RE: Ghat / AFR Race Skipper Pemula</a></li>
<li><a href="../id418143/index.html">PVS-Studio sebagai solusi SAST</a></li>
<li><a href="../id418145/index.html">Gugatan pertama terhadap Roskomnadzor dari sebuah perusahaan yang menderita ketika Telegram diblokir</a></li>
<li><a href="../id418147/index.html">Silence of Ruby Executions: Transactional Rails / PostgreSQL Thriller</a></li>
<li><a href="../id418149/index.html">Phishing dengan tag judul</a></li>
<li><a href="../id418153/index.html">Kolesa Android Meetup Video: Tentang MVVM, Antipatterns, dan Pengembangan Modular</a></li>
<li><a href="../id418155/index.html">Diode LED Dioda zener</a></li>
<li><a href="../id418157/index.html">Buku "Benda elegan. Edisi Jawa »</a></li>
<li><a href="../id418159/index.html">Tempat mencari desainer: penghargaan bergengsi dari Rusia, Eropa Timur, dan negara-negara CIS</a></li>
<li><a href="../id418161/index.html">Di Stanford, baterai streaming suhu kamar dikembangkan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
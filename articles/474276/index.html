<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñïüèø ü§¥üèª üîñ ‚ÄúEntrenamiento de refuerzo profundo. AlphaGo y otras tecnolog√≠as ": el anuncio del libro üõ∂ üïµÔ∏è üë∞üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos! 

 Tenemos uno de los mejores libros sobre capacitaci√≥n en refuerzo disponible para pedidos por adelantado, originalmente llamado " Deep...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>‚ÄúEntrenamiento de refuerzo profundo. AlphaGo y otras tecnolog√≠as ": el anuncio del libro</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/474276/">  Hola a todos! <br><br>  Tenemos uno de los mejores libros sobre capacitaci√≥n en refuerzo disponible para pedidos por adelantado, originalmente llamado " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deep Reinforcement Learning Hands-on</a> " por Maxim Lapan.  Aqu√≠ est√° la portada de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">traducci√≥n</a> al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ruso</a> : <br><br><img src="https://habrastorage.org/webt/av/ig/n-/avign-oqnxjpgpptv7irkkwsope.jpeg"><br><br>  Para que pueda apreciar el resumen del libro, le ofrecemos una traducci√≥n de la revisi√≥n escrita por el autor al lanzamiento del original. <br><a name="habracut"></a><br><br>  Hola <br><br>  Soy un entusiasta autodidacta que est√° interesado en el aprendizaje profundo.  Por lo tanto, cuando los representantes de la editorial Packt se pusieron en contacto conmigo y me sugirieron que escribiera un libro pr√°ctico sobre el estado actual del aprendizaje profundo con refuerzo, me asust√© un poco, pero despu√©s de algunas dudas, estuve de acuerdo, asumiendo de manera optimista: "Oh, habr√° una experiencia interesante". <br>  No dir√© que este trabajo me fue dado como una caminata f√°cil, por supuesto que no.  No tiene d√≠as libres, no tiene tiempo libre, miedo constante a la "estupidez congelante" y la b√∫squeda de plazos para cada cap√≠tulo (dos semanas por cap√≠tulo y c√≥digo de ejemplo).  Sin embargo, en general, todo fue positivo y muy interesante. <br><br>  Antes de describir brevemente el contenido de cada cap√≠tulo, describamos la <i>idea de todo el libro</i> . <br>  Cuando comenc√© a experimentar en RL hace m√°s de cuatro a√±os, ten√≠a a mi disposici√≥n las siguientes fuentes de informaci√≥n: <br><br><ul><li>  Libro de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aprendizaje</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">refuerzo</a> de Sutton y Barto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">: una introducci√≥n</a> </li><li>  Art√≠culos cient√≠ficos en <a href="">arxiv.org</a> </li><li>  El curso de David Silver. </li></ul><br><br>  Quiz√°s hab√≠a algo m√°s, pero estas eran las fuentes de informaci√≥n m√°s importantes.  Todos ellos est√°n muy lejos de la pr√°ctica: <br><br><ul><li>  El libro de Sutton y Barto, tambi√©n conocido como "El libro RL", proporciona solo los fundamentos te√≥ricos de esta disciplina. </li><li>  Los art√≠culos relacionados con RL se publican casi a diario, pero rara vez contienen enlaces a c√≥digos espec√≠ficos.  Solo f√≥rmulas y algoritmos.  Si tiene suerte, se indicar√°n hiperpar√°metros. </li><li>  El curso de David Silver se imparti√≥ en el University College London (UCL) en 2015.  Proporciona una muy buena visi√≥n general de los m√©todos que exist√≠an en ese momento, permiti√©ndoles dominarlos intuitivamente, sin embargo, aqu√≠ la teor√≠a vuelve a prevalecer sobre la pr√°ctica. </li></ul><br><br>  Al mismo tiempo, estaba profundamente enganchado al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo DeepMind</a> ("¬°Una red neuronal puede aprender a jugar juegos de Atari en p√≠xeles! ¬°GUAU!"), Y sent√≠ que esta teor√≠a seca esconde un enorme valor pr√°ctico.  Entonces, pas√© mucho tiempo estudiando la teor√≠a, implementando varios m√©todos y depur√°ndolos.  Como probablemente haya adivinado, no fue f√°cil: puede pasar un par de semanas perfeccionando el m√©todo y luego descubrir que su implementaci√≥n es incorrecta (o, lo que es peor, no entendi√≥ la f√≥rmula).  No considero que dicho entrenamiento sea una p√©rdida de tiempo; por el contrario, creo que esta es la forma m√°s correcta de aprender algo.  Sin embargo, esto lleva mucho tiempo. <br><br>  Dos a√±os m√°s tarde, cuando comenc√© a trabajar en el texto, mi objetivo principal era: proporcionar informaci√≥n pr√°ctica exhaustiva sobre los m√©todos de RL a un lector que solo conoce esta fascinante disciplina, como lo hice una vez. <br><br>  Ahora un poco sobre el libro.  Se centra principalmente en la pr√°ctica, y trat√© de minimizar el volumen de la teor√≠a y las f√≥rmulas.  Contiene f√≥rmulas clave, pero no se proporciona evidencia.  B√°sicamente, trato de dar una comprensi√≥n intuitiva de lo que est√° sucediendo, sin buscar el m√°ximo rigor de presentaci√≥n. <br><br>  Al mismo tiempo, se supone que el lector tiene conocimientos b√°sicos de aprendizaje profundo y estad√≠sticas.  Hay un cap√≠tulo en el libro con una descripci√≥n general de la biblioteca PyTorch (ya que todos los ejemplos se dan usando PyTorch), pero este cap√≠tulo no puede considerarse una fuente de informaci√≥n autosuficiente en redes neuronales.  Si nunca antes ha o√≠do hablar de las funciones de p√©rdida y activaci√≥n, comience mirando otros libros, hoy hay muchos.  (Nota: por ejemplo, el libro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprendizaje profundo</a> "). <br><br>  En mi libro encontrar√° muchos ejemplos de complejidad variable, comenzando con los m√°s simples (el m√©todo <code>CrossEntropy</code> en el entorno <code>CartPole</code> contiene ~ 100 l√≠neas en python), y termina con proyectos bastante grandes, por ejemplo, estudiar AlphGo Zero o un agente RL para operar en el intercambio.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El c√≥digo de muestra est√° completamente cargado en GitHub</a> , hay m√°s de 14k l√≠neas de c√≥digo en Python. <br><br>  El libro consta de 18 cap√≠tulos que cubren los aspectos m√°s importantes del aprendizaje profundo moderno con refuerzo: <br><br><ul><li>  <b>El Cap√≠tulo 1</b> : proporciona informaci√≥n introductoria sobre el paradigma de aprendizaje reforzado, demuestra c√≥mo difiere del aprendizaje con y sin un maestro.  Aqu√≠ consideramos el modelo matem√°tico central relacionado con el aprendizaje por refuerzo: los procesos de toma de decisiones de Markov: (MPPR).  El conocimiento de MPNR se hizo paso a paso: hablo de las cadenas de Markov, que se transforman en procesos de refuerzo de Markov (con la adici√≥n de un componente de refuerzo) y, finalmente, en los procesos de toma de decisiones de Markov en toda regla, donde las acciones del agente tambi√©n se tienen en cuenta en la imagen general. </li><li>  <b>Cap√≠tulo 2</b> : habla sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenAI Gym</a> , una API generalizada para RL, dise√±ada para trabajar en una variedad de entornos, incluido Atari, para resolver problemas cl√°sicos, como CartPole, tareas de aprendizaje continuo, etc. </li><li>  <b>Cap√≠tulo 3</b> : ofrece una descripci√≥n general expresa de la API PyTorch.  Este cap√≠tulo no fue una gu√≠a completa de DL, sin embargo, sienta las bases para comprender otros cap√≠tulos.  Si utiliza otras herramientas para resolver problemas de aprendizaje profundo, deber√≠a servir como una buena introducci√≥n al hermoso modelo PyTorch, para que le resulte m√°s f√°cil comprender los ejemplos de los siguientes cap√≠tulos.  Al final de este cap√≠tulo, ense√±aremos una GAN simple que generar√° y distinguir√° capturas de pantalla de Atari de diferentes juegos. </li><li>  <b>Cap√≠tulo 4</b> : examina uno de los m√©todos m√°s simples y poderosos: CrossEntropy.  En este cap√≠tulo, le ense√±aremos la primera red que puede resolver problemas en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">entorno CartPole</a> . </li><li>  <b>Cap√≠tulo 5</b> : Este cap√≠tulo comienza la <b>segunda parte del libro</b> sobre el algoritmo de iteraci√≥n para valores.  El Cap√≠tulo 5 discute una forma simple de capacitaci√≥n en hojas de c√°lculo utilizando la ecuaci√≥n de Bellman para resolver problemas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en el entorno FrozenLake</a> . </li><li>  <b>Cap√≠tulo 6</b> : Este cap√≠tulo te presenta los DQN que juegan el juego Atari.  La arquitectura del agente es exactamente la misma que en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">famoso art√≠culo DeepMind</a> . </li><li>  <b>Cap√≠tulo 7</b> : presenta varias extensiones modernas de DQN para ayudar a mejorar la estabilidad y el rendimiento del DQN subyacente.  En este cap√≠tulo, los m√©todos del art√≠culo " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Rainbow: Combinar mejoras en Deep RL</a> ";  Todos estos m√©todos se implementan en el cap√≠tulo, y explico las ideas subyacentes.  Estos m√©todos son: DQN de N pasos, DQN dual, redes ruidosas, buffer de reproducci√≥n prioritario, redes de duelo y redes de categor√≠a.  Al final del cap√≠tulo, todos los m√©todos se combinan en un ejemplo de c√≥digo com√∫n, exactamente como se hizo en el "art√≠culo del arco iris". </li><li>  <b>Cap√≠tulo 8</b> : describe el primer proyecto de tama√±o mediano, ilustrando el lado pr√°ctico de RL en la resoluci√≥n de problemas del mundo real.  En este cap√≠tulo, utilizando el DQN, un agente est√° capacitado para realizar operaciones en el intercambio. </li><li>  <b>Cap√≠tulo 9</b> : Este cap√≠tulo comienza la <b>tercera parte del</b> libro sobre t√©cnicas de gradiente de pol√≠ticas.  En √©l nos familiarizamos con tales m√©todos, sus fortalezas y debilidades en comparaci√≥n con los m√©todos de enumeraci√≥n por valores ya considerados anteriormente.  El primer m√©todo en esta familia se llama REFORZAR. </li><li>  <b>Cap√≠tulo 10</b> : describe c√≥mo lidiar con uno de los problemas m√°s serios de RL: la variabilidad del gradiente de pol√≠ticas.  Despu√©s de experimentar con los niveles b√°sicos de PG, se familiarizar√° con el m√©todo actor-cr√≠tico. </li><li>  <b>Cap√≠tulo 11</b> : habla sobre c√≥mo paralelizar el m√©todo actor-cr√≠tico en el hardware moderno. </li><li>  <b>Cap√≠tulo 12</b> : un segundo ejemplo pr√°ctico que describe c√≥mo resolver problemas asociados con el procesamiento del lenguaje natural.  En este cap√≠tulo, ense√±amos un chatbot simple para usar m√©todos RL en el material del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cuadro de di√°logo de cine de Cornell</a> . </li><li>  <b>Cap√≠tulo 13</b> : otro ejemplo pr√°ctico sobre automatizaci√≥n web: MiniWoB se utiliza como plataforma.  Desafortunadamente, OpenAI se neg√≥ a usar MiniWoB, por lo que es dif√≠cil encontrar informaci√≥n al respecto ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hay</a> algunos granos).  Pero la idea de MiniWoB es brillante, por lo que en este cap√≠tulo muestro c√≥mo configurar y capacitar al agente para resolver algunos de los problemas asociados con √©l. </li><li>  <b>Cap√≠tulo 14</b> : la √∫ltima y <b>cuarta parte del</b> libro, dedicada a m√©todos y t√©cnicas m√°s avanzadas, comienza con √©l.  El Cap√≠tulo 14 se centra en las tareas de administraci√≥n continua y describe los m√©todos A3C, DDPG y D4PG para resolver problemas en algunos entornos PyBullet. </li><li>  <b>Cap√≠tulo 15</b> : habla m√°s sobre los problemas de gesti√≥n continua y le presenta el fen√≥meno de la Regi√≥n de confianza utilizando TRPO, PPO y ACKTR como ejemplos. </li><li>  <b>Cap√≠tulo 16</b> : dedicado a los m√©todos de ense√±anza con refuerzo sin gradientes (trabajando sobre el principio de "caja negra");  se posicionan como alternativas m√°s escalables para los m√©todos DQN y PG.  Las estrategias evolutivas y los algoritmos gen√©ticos se aplican aqu√≠ para resolver varios problemas de control continuo. </li><li>  <b>Cap√≠tulo 17</b> : examina los enfoques de RL basados ‚Äã‚Äãen modelos y describe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el intento de DeepMind para</a> llenar el vac√≠o entre los m√©todos basados ‚Äã‚Äãen modelos y no basados ‚Äã‚Äãen modelos.  Este cap√≠tulo implementa el agente I2A para Breakout. </li><li>  <b>Cap√≠tulo 18</b> : El cap√≠tulo final del libro discute el m√©todo AlphaGo Zero utilizado al jugar Connect4.  Luego, el agente terminado se usa como parte del bot de telegramas para verificar los resultados. </li></ul><br><br><br>  Eso es todo!  Espero que disfrutes el libro. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/474276/">https://habr.com/ru/post/474276/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../474252/index.html">Animaci√≥n realista de personajes en juegos usando IA</a></li>
<li><a href="../474254/index.html">Hacer un efecto pegajoso genial para un control deslizante en React</a></li>
<li><a href="../474256/index.html">La idea de encontrar gente en el bosque.</a></li>
<li><a href="../474268/index.html">Reconocimiento de circuitos digitales. Disparador de conteo asincr√≥nico</a></li>
<li><a href="../474274/index.html">Gr√°fico de conocimiento. Pluralidad, temporalidad, enfoque de actividad.</a></li>
<li><a href="../474278/index.html">Python v3.x: c√≥mo aumentar la velocidad del decorador sin registro y sms</a></li>
<li><a href="../474280/index.html">¬øQuieres un DBMS de primera mano? Una reuni√≥n abierta en Nizhny Novgorod - para ser</a></li>
<li><a href="../474282/index.html">Datacenter TCP explicado</a></li>
<li><a href="../474284/index.html">No solo futuros y opciones: qu√© otros instrumentos financieros secundarios existen en las bolsas y no solo</a></li>
<li><a href="../474286/index.html">An√°lisis detallado del m√©todo simplex</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò™ üöÄ üîà KI √ºbersetzte Gehirnaktivit√§t in Sprache ‚è∫Ô∏è ‚òîÔ∏è üë®‚Äç‚úàÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Viele gel√§hmte Menschen, die nicht sprechen k√∂nnen, haben Signale von dem, was sie sagen wollen, in ihrem Gehirn versteckt. Und niemand konnte diese S...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>KI √ºbersetzte Gehirnaktivit√§t in Sprache</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/435904/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2da/ae7/5ef/2daae75ef2ff8a8c4af731c7d5c8eeb3.jpg" alt="Bild"></div><br>  Viele gel√§hmte Menschen, die nicht sprechen k√∂nnen, haben Signale von dem, was sie sagen wollen, in ihrem Gehirn versteckt.  Und niemand konnte diese Signale entschl√ºsseln.  Vor kurzem haben drei Forscherteams Fortschritte bei der √úbersetzung von Daten von Elektroden, die auf chirurgische Weise am Gehirn platziert wurden, in computer-synthetisierte Sprache erzielt. <br><br>  Mithilfe von Modellen, die auf neuronalen Netzen basieren, rekonstruierten sie W√∂rter und sogar ganze S√§tze, die in einigen F√§llen f√ºr den durchschnittlichen menschlichen H√∂rer durchaus verst√§ndlich waren. <br><a name="habracut"></a><br>  Keiner der in den Vorabdrucken der Arbeit an bioRxiv beschriebenen Versuche, Sprache aus Gedanken wiederherzustellen, hat zum Erfolg gef√ºhrt.  Stattdessen beobachteten die Forscher die Aktivit√§t verschiedener Regionen des Gehirns des Patienten, w√§hrend sie laut vorlas, entweder vorlesen, aber immer noch ihre Lippen bewegen, den Text intern sprechen oder den Notizen zuh√∂ren. <br><br>  "Zu zeigen, dass rekonstruierte Sprache durchaus verst√§ndlich ist, ist wirklich aufregend."  Sagt Stephanie Martin, eine Neuroingenieurin an der Universit√§t Genf in der Schweiz, die an diesem Projekt beteiligt ist. <br><br>  Menschen, die nach einem Schlaganfall oder infolge einer Krankheit nicht mehr sprechen k√∂nnen, k√∂nnen mit ihren Augen oder anderen kleinen Bewegungen den Cursor steuern oder Buchstaben auf dem Bildschirm ausw√§hlen (der Kosmologe Stephen Hawking spannte seine Wange an, um den auf seiner Brille installierten Schalter zu aktivieren).  Wenn die Gehirn-Computer-Schnittstelle jedoch die Sprache von Patienten direkt reproduzieren kann, wird dies ihre F√§higkeiten erheblich erweitern: Sie gibt die Kontrolle √ºber die Tonalit√§t und erm√∂glicht es Ihnen, an schnell laufenden Gespr√§chen teilzunehmen. <br><br>  "Wir versuchen, ein Schema zu entwickeln ... von Neuronen, die zu verschiedenen Zeitpunkten aktiviert werden und eine Schlussfolgerung dar√ºber ziehen, wie die Sprache klingt", sagt Nima Mesgarani, Ingenieurin an der Columbia University.  "Eine in eine andere umzuwandeln ist nicht so einfach." <br><br>  Die Art und Weise, wie diese Signale von Neuronen in Sprache umgewandelt werden, variiert von Person zu Person. Daher m√ºssen Computermodelle f√ºr jede Person separat trainiert werden.  Und das Beste ist, dass es sich um Modelle handelt, die aus √§u√üerst genauen Daten lernen, deren Empfang das √ñffnen des Sch√§dels erfordert. <br><br>  Forscher k√∂nnen diese Gelegenheit in einem sehr seltenen Fall erhalten.  Eine davon ist, wenn ein Patient aus einem Gehirntumor entfernt wird.  Chirurgen verwenden die Messwerte von Sensoren, die elektrische Signale direkt vom Gehirn lesen, um Sprach- und Motorbereiche zu lokalisieren und zu vermeiden.  Ein anderes Beispiel ist, wenn einem Patienten mit Epilepsie mehrere Tage lang Elektroden implantiert werden, um die Quelle der Anf√§lle zu lokalisieren, bevor eine Operation durchgef√ºhrt wird. <br><br>  ‚ÄûWir haben maximal 20, manchmal 30 Minuten Zeit, um Daten zu sammeln‚Äú, sagt Stephanie Martin.  "Wir sind sehr, sehr zeitlich begrenzt." <br><br>  Die besten Ergebnisse erzielten die Teams, die die Daten aus der Aufzeichnung der Gehirnaktivit√§t in k√ºnstliche neuronale Netze ‚Äûeinspeisten‚Äú.  Als Ausgabe (Hrsg. Labels) erhielten die Netzwerke eine Rede, die der Patient entweder laut sagte oder h√∂rte. <br><br>  Das Nima Mesgarani-Team st√ºtzte sich auf Daten von f√ºnf verschiedenen Patienten mit Epilepsie.  Ihre neuronalen Netze wurden auf Aufzeichnungen aus dem auditorischen Kortex des Gehirns von Menschen trainiert (das sowohl w√§hrend der eigenen Sprache als auch beim H√∂ren anderer Personen aktiv ist), die zu dieser Zeit Aufzeichnungen verschiedener Geschichten spielten und eine Folge von Zahlen von 0 bis 9 √ºberspielten. Dann synthetisierte ein Computermodell Sprache Durch das Aussprechen derselben Zahlenfolge und einer Kontrollgruppe von Personen konnten 75% dieser Daten erkannt werden. <br><br><div class="spoiler">  <b class="spoiler_title">Computergenerierte Sprache, die aus Gehirnaktivit√§tsdaten eines Patienten beim H√∂ren von Zahlen erhalten wird</b> <div class="spoiler_text">  <a href="">www.sciencemag.org/sites/default/files/audio/Mesgarani-1.mp3</a> <br></div></div><br>  Ein anderes Team unter der Leitung von Tanja Schultz von der Universit√§t Bremen in Deutschland verwendete Daten von 6 Personen, die sich einer Operation unterzogen, um Hirntumoren zu entfernen.  Ihre Rede wurde auf einem Mikrofon aufgezeichnet, w√§hrend sie einsilbige W√∂rter laut vorlas.  Gleichzeitig erfassten Elektroden in ihrem Gehirn die Aktivit√§t der Planungsbereiche und Motorbereiche und sendeten Befehle an den Sprachpfad, um W√∂rter auszusprechen. <br><br>  Die Ingenieure Miguel Angrick und Christian Herff von der Universit√§t Maastricht trainierten ein neuronales Netzwerk, das die mit den Elektroden gelesenen Daten mit den resultierenden Audioaufzeichnungen abglichen, und rekonstruierten dann die W√∂rter und Phrasen f√ºr das zuvor nicht gezeigte Modell der gelesenen Datens√§tze.  Nach diesen Daten synthetisierte das Modell Sprache, von der etwa 40% f√ºr den Menschen verst√§ndlich waren. <br><br><div class="spoiler">  <b class="spoiler_title">Aufzeichnen von computergenerierter Sprache basierend auf Daten von Elektroden</b> <div class="spoiler_text">  <a href="">www.sciencemag.org/sites/default/files/audio/Herff-1.mp3</a> <br></div></div><br>  Und schlie√ülich rekonstruierten der Neurochirurg Edward Chang und sein Team von der University of California in San Francisco ganze S√§tze √ºber die Aktivit√§t des Sprachzentrums, die von Elektroden bei 6 Patienten mit Epilepsie gelesen wurden, als sie laut vorlas.  Die Forscher f√ºhrten einen Online-Test durch, bei dem 166 Personen einen der vom Computermodell generierten S√§tze h√∂rten und dann unter den 10 vorgeschlagenen Optionen die ausw√§hlen mussten, die ihrer Meinung nach gelesen wurde.  Einige S√§tze wurden in mehr als 80% der F√§lle korrekt identifiziert.  Aber die Forscher h√∂rten hier nicht auf und zwangen das Modell, die Sprache einer Person anhand von Daten zur Gehirnaktivit√§t nachzubilden, die sie beim Lesen von W√∂rtern f√ºr sich selbst erhalten hatte, aber er bewegte zu diesem Zeitpunkt seine Lippen, als w√ºrde er sie ‚Äûintern aussprechen‚Äú. <br><br>  "Dies ist ein sehr wichtiges Ergebnis", sagt Christian Herff, "wir sind der Sprachprothetik einen Schritt n√§her gekommen." <br><br>  "Was wir jedoch wirklich erwarten, ist, wie sich diese Methoden zeigen, wenn der Patient √ºberhaupt nicht sprechen kann."  - Antwortet Stephanie Ri√®s, Neurowissenschaftlerin an der Universit√§t von San Diego in Kalifornien.  ‚ÄûDie Signale des Gehirns, w√§hrend eine Person sich selbst vorliest oder anderen zuh√∂rt, unterscheiden sich von denen, die beim Vorlesen oder in der Live-Kommunikation auftreten.  Ohne einen externen Klang, mit dem man die Gehirnaktivit√§t vergleichen k√∂nnte, wird es f√ºr Computermodelle sehr schwierig sein, vorherzusagen, wo die interne Sprache beginnt und wo sie endet. ‚Äú <br><br>  "Die Entschl√ºsselung imagin√§rer Sprache wird einen gro√üen Sprung nach vorne machen", sagt Gerwin Schalk, Neurowissenschaftler am Nationalen Zentrum f√ºr adaptive Neurotechnologie des New York State Department of Health.  "Und jetzt ist v√∂llig unklar, wie dies erreicht werden kann." <br><br>  Eine der Methoden, so Herff, kann das Feedback sein, das der Patient an ein Computermodell gibt, das die Sprache in Echtzeit reproduziert, w√§hrend die Person die W√∂rter mental ausspricht.  Mit einer ausreichenden Menge an Training f√ºr den Patienten und die KI k√∂nnen sich Gehirn und Computer irgendwo in der Mitte treffen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de435904/">https://habr.com/ru/post/de435904/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de435894/index.html">Privatunterricht. Versteckt in PHP</a></li>
<li><a href="../de435896/index.html">Verwenden von DiagnosticSource in .NET Core: Theorie</a></li>
<li><a href="../de435898/index.html">Woran Sie bei einem NALSD-Interview denken sollten</a></li>
<li><a href="../de435900/index.html">Verkapseln Sie es</a></li>
<li><a href="../de435902/index.html">Sie k√∂nnen SELECT nicht einfach nehmen und schreiben, wenn der Anbieter dies nicht zul√§sst ... aber wir werden schreiben</a></li>
<li><a href="../de435906/index.html">Schrittmacher-Cluster-Speicher + DRBD (Dual Primary) + ctdb</a></li>
<li><a href="../de435908/index.html">Asketisches Netz: Prototyp-Flohm√§rkte f√ºr unterwegs und js</a></li>
<li><a href="../de435910/index.html">Warum hat BSD den Kampf mit GNU / Linux verloren?</a></li>
<li><a href="../de435912/index.html">Die Hauptprobleme bei der Entwicklung moderner Schnittstellen</a></li>
<li><a href="../de435914/index.html">Packen von ASP.NET Core-Anwendungen mit Docker</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
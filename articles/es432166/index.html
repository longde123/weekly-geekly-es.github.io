<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ú¥Ô∏è üë®üèΩ‚Äçüîß üëçüèΩ Apache NiFi: qu√© es y una breve descripci√≥n de las caracter√≠sticas üë©üèΩ‚Äçüîß ü§í üõ•Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoy en los sitios extranjeros tem√°ticos sobre Big Data puede encontrar una menci√≥n de una herramienta relativamente nueva para el ecosistema de Hadoop...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apache NiFi: qu√© es y una breve descripci√≥n de las caracter√≠sticas</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/432166/">  Hoy en los sitios extranjeros tem√°ticos sobre Big Data puede encontrar una menci√≥n de una herramienta relativamente nueva para el ecosistema de Hadoop como Apache NiFi.  Esta es una herramienta moderna de c√≥digo abierto ETL.  Arquitectura distribuida para una carga paralela r√°pida y procesamiento de datos, una gran cantidad de complementos para fuentes y transformaciones, el control de versiones de las configuraciones son solo una parte de sus ventajas.  Con toda su potencia, NiFi sigue siendo bastante f√°cil de usar. <br><br><img src="https://habrastorage.org/webt/9b/zs/ri/9bzsrib2emb_rcdq1cj-d8nubbe.png" alt="imagen"><br><br>  En Rostelecom nos esforzamos por desarrollar el trabajo con Hadoop, por lo que ya hemos probado y evaluado las ventajas de Apache NiFi en comparaci√≥n con otras soluciones.  En este art√≠culo te contar√© c√≥mo nos atrajo esta herramienta y c√≥mo la usamos. <br><a name="habracut"></a><br><h2>  Antecedentes </h2><br>  No hace mucho tiempo, nos enfrentamos con la elecci√≥n de una soluci√≥n para cargar datos de fuentes externas en un cl√∫ster de Hadoop.  Durante mucho tiempo, utilizamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Flume</a> para resolver tales problemas.  No hubo quejas sobre Flume en general, excepto por algunos puntos que no nos conven√≠an. <br><br>  <i>Lo primero</i> que a nosotros, como administradores, no nos gust√≥ fue que escribir la configuraci√≥n de Flume para realizar la pr√≥xima descarga trivial no pod√≠a confiarse a un desarrollador o analista que no estuviera inmerso en las complejidades de esta herramienta.  La conexi√≥n de cada nueva fuente requiri√≥ la intervenci√≥n obligatoria del equipo de administraci√≥n. <br>  <i>El segundo punto</i> fue la tolerancia a fallas y la escala.  Para descargas pesadas, por ejemplo, a trav√©s de syslog, fue necesario configurar varios agentes Flume y establecer un equilibrador frente a ellos.  Todo esto tuvo que ser monitoreado y restaurado de alguna manera en caso de falla. <br>  <i>En tercer lugar</i> , Flume no permiti√≥ descargar datos de varios DBMS y trabajar con algunos otros protocolos listos para usar.  Por supuesto, en las vastas extensiones de la red, podr√≠a encontrar formas de hacer que Flume funcione con Oracle o SFTP, pero apoyar esas bicicletas no es nada agradable.  Para cargar datos del mismo Oracle, tuvimos que usar otra herramienta: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Sqoop</a> . <br>  Francamente, por mi naturaleza, soy una persona perezosa, y no quer√≠a apoyar el zool√≥gico de soluciones en absoluto.  Y no me gust√≥ que todo este trabajo tuviera que hacerlo yo mismo. <br><br>  Existen, por supuesto, soluciones bastante potentes en el mercado de herramientas ETL que pueden funcionar con Hadoop.  Estos incluyen Informatica, IBM Datastage, SAS y Pentaho Data Integration.  Estos son los que con mayor frecuencia se escuchan de los colegas en el taller y de aquellos que primero vienen a la mente.  Por cierto, utilizamos IBM DataStage para ETL en soluciones de la clase Data Warehouse.  Pero hist√≥ricamente sucedi√≥ que nuestro equipo no pudo usar DataStage para descargas en Hadoop.  Nuevamente, no necesit√°bamos todo el poder de las soluciones de este nivel para realizar conversiones y descargas de datos bastante simples.  Lo que necesit√°bamos era una soluci√≥n con una buena din√°mica de desarrollo, capaz de trabajar con muchos protocolos y una interfaz conveniente e intuitiva que no solo un administrador que entend√≠a todas sus sutilezas pod√≠a hacer frente, sino tambi√©n un desarrollador con un analista, que a menudo son para nosotros. clientes de los datos en s√≠. <br><br>  Como puede ver en el t√≠tulo, resolvimos los problemas anteriores con Apache NiFi. <br><br><h2>  ¬øQu√© es Apache NiFi? </h2><br>  El nombre NiFi proviene de "Niagara Files".  El proyecto fue desarrollado por la Agencia de Seguridad Nacional de EE. UU. Durante ocho a√±os, y en noviembre de 2014 su c√≥digo fuente fue abierto y transferido a la Apache Software Foundation como parte del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Programa de Transferencia de Tecnolog√≠a</a> de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">NSA</a> . <br><br>  NiFi es una herramienta ETL / ELT de c√≥digo abierto que puede funcionar con muchos sistemas, y no solo con las clases Big Data y Data Warehouse.  Estos son algunos de ellos: HDFS, Hive, HBase, Solr, Cassandra, MongoDB, ElastcSearch, Kafka, RabbitMQ, Syslog, HTTPS, SFTP.  Puede ver la lista completa en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n</a> oficial. <br><br>  El trabajo con un DBMS espec√≠fico se implementa agregando el controlador JDBC apropiado.  Hay una API para escribir su m√≥dulo como receptor adicional o convertidor de datos.  Se pueden encontrar ejemplos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br><h2>  Caracter√≠sticas clave </h2><br>  NiFi utiliza una interfaz web para crear DataFlow.  Un analista que recientemente comenz√≥ a trabajar con Hadoop, un desarrollador y un administrador barbudo se encargar√°n de ello.  Los dos √∫ltimos pueden interactuar no solo con ‚Äúrect√°ngulos y flechas‚Äù, sino tambi√©n con la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API REST</a> para recopilar estad√≠sticas, monitorear y administrar los componentes de DataFlow. <br><br><img src="https://habrastorage.org/webt/zw/dx/iq/zwdxiqh9ovilvva4tak-stj5jpc.png" alt="imagen"><br>  <i>Gesti√≥n basada en web NiFi</i> <br><br>  A continuaci√≥n, mostrar√© algunos ejemplos de DataFlow para realizar algunas operaciones comunes. <br><br><img src="https://habrastorage.org/webt/jz/cw/v_/jzcwv_nu7infyyarte3skiwvayi.png" alt="imagen"><br>  <i>Ejemplo de descarga de archivos de un servidor SFTP a HDFS</i> <br><br>  En este ejemplo, el procesador ListSFTP hace una lista de archivos en el servidor remoto.  El resultado de este listado se utiliza para la carga de archivos paralelos por todos los nodos del cl√∫ster por el procesador FetchSFTP.  Despu√©s de eso, los atributos se agregan a cada archivo, obtenido al analizar su nombre, que luego son utilizados por el procesador PutHDFS al escribir el archivo en el directorio final. <br><br><img src="https://habrastorage.org/webt/v-/ei/op/v-eiopqny5-jao0kaqlyexduvx0.png" alt="imagen"><br>  <i>Un ejemplo de descarga de datos de syslog en Kafka y HDFS</i> <br><br>  Aqu√≠, usando el procesador ListenSyslog, obtenemos el flujo de mensajes de entrada.  Despu√©s de eso, los atributos sobre el momento de su llegada a NiFi y el nombre del esquema en el Registro de esquemas Avro se agregan a cada grupo de mensajes.  A continuaci√≥n, la primera rama se dirige a la entrada del procesador QueryRecord, que, seg√∫n el esquema especificado, lee los datos y los analiza mediante SQL, y luego los env√≠a a Kafka.  La segunda rama se env√≠a al procesador MergeContent, que agrega los datos durante 10 minutos, y luego los entrega al siguiente procesador para convertirlos al formato Parquet y grabarlos en HDFS. <br><br>  Aqu√≠ hay un ejemplo de c√≥mo puedes dise√±ar un DataFlow: <br><img src="https://habrastorage.org/webt/43/kd/2-/43kd2-43rovwudvvoi3sm8hdmuk.png" alt="imagen"><br>  <i>Descargue datos de syslog a Kafka y HDFS.</i>  <i>Borrar datos en Hive</i> <br><br>  Ahora sobre la conversi√≥n de datos.  NiFi le permite analizar datos con datos regulares, ejecutar SQL en ellos, filtrar y agregar campos y convertir un formato de datos a otro.  Tambi√©n tiene su propio lenguaje de expresi√≥n, rico en varios operadores y funciones integradas.  Con √©l, puede agregar variables y atributos a los datos, comparar y calcular valores, usarlos m√°s adelante en la formaci√≥n de varios par√°metros, como la ruta para escribir en HDFS o la consulta SQL en Hive.  Lee m√°s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br><img src="https://habrastorage.org/webt/a4/7m/b_/a47mb_i_f2mzkfezluoq6qrt6-0.png" alt="imagen"><br>  <i>Un ejemplo de uso de variables y funciones en el procesador UpdateAttribute</i> <br><br>  El usuario puede rastrear la ruta completa de los datos, observar el cambio en sus contenidos y atributos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a69/e09/44a/a69e0944abb4bb44f3863653994cd891.png"><br>  <i>Visualizaci√≥n de la cadena DataFlow</i> <br><br><img src="https://habrastorage.org/webt/sc/u3/ih/scu3ihzv1nwydvwfjc4ks9yvfoe.png" alt="imagen"><br>  <i>Ver contenido y atributos de datos</i> <br><br>  Para versionar DataFlow hay un servicio de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">registro de NiFi</a> separado.  Al configurarlo, puede administrar los cambios.  Puede ejecutar cambios locales, revertir o descargar cualquier versi√≥n anterior. <br><br><img src="https://habrastorage.org/webt/ci/uz/ge/ciuzgeuazknrhqm5peopzmekiuo.png" alt="imagen"><br>  <i>Men√∫ de control de versiones</i> <br><br>  En NiFi, puede controlar el acceso a la interfaz web y la separaci√≥n de los derechos del usuario.  Actualmente se admiten los siguientes mecanismos de autenticaci√≥n: <br><br><ul><li>  Certificado basado <br></li><li>  Basado en nombre de usuario y contrase√±a a trav√©s de LDAP y Kerberos <br></li><li>  Via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Knox</a> <br></li><li>  V√≠a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenID Connect</a> <br></li></ul><br>  No se admite el uso simult√°neo de varios mecanismos a la vez.  Para autorizar a los usuarios en el sistema, se utilizan FileUserGroupProvider y LdapUserGroupProvider.  Lea m√°s sobre esto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  Como dije, NiFi puede funcionar en modo de cl√∫ster.  Esto proporciona tolerancia a fallas y permite el escalamiento de carga horizontal.  No hay un nodo maestro est√°ticamente fijo.  En cambio, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Zookeeper</a> selecciona un nodo como coordinador y otro como primario.  El coordinador recibe informaci√≥n sobre su estado de otros nodos y es responsable de su conexi√≥n y desconexi√≥n del cl√∫ster. <br>  El nodo primario se usa para iniciar procesadores aislados, que no deber√≠an ejecutarse en todos los nodos simult√°neamente. <br><br><img src="https://habrastorage.org/webt/1w/io/mv/1wiomvdhjbh_ewwa73dgl-yjitg.png" alt="imagen"><br>  <i>Operaci√≥n de NiFi en un cl√∫ster</i> <br><br><img src="https://habrastorage.org/webt/du/ty/ea/dutyeaditjnc6bq_qgta6xcexrk.png" alt="imagen"><br>  <i>Distribuci√≥n de carga por nodos de cl√∫ster utilizando el procesador PutHDFS como ejemplo</i> <br><br><h2>  Una breve descripci√≥n de la arquitectura y componentes NiFi </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/d68/920/1de/d689201de4c392c562e807fc279cd2ab.png"><br>  <i>Arquitectura de instancia de NiFi</i> <br><br>  NiFi se basa en el concepto de "Programaci√≥n basada en flujo" ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FBP</a> ).  Estos son los conceptos y componentes b√°sicos que cada usuario encuentra: <br><br>  <b>FlowFile</b> : una entidad que representa un objeto con contenido de cero o m√°s bytes y sus atributos correspondientes.  Estos pueden ser los datos en s√≠ (por ejemplo, el flujo de mensajes de Kafka) o el resultado del procesador (PutSQL, por ejemplo), que no contiene datos como tales, sino solo los atributos generados como resultado de la consulta.  Los atributos son metadatos de FlowFile. <br><br>  <b>El procesador FlowFile</b> es exactamente la esencia que hace el trabajo b√°sico en NiFi.  Un procesador, por regla general, tiene una o varias funciones para trabajar con FlowFile: crear, leer / escribir y cambiar contenidos, leer / escribir / cambiar atributos, enrutamiento.  Por ejemplo, el procesador ListenSyslog recibe datos utilizando el protocolo syslog, creando FlowFiles con los atributos syslog.version, syslog.hostname, syslog.sender y otros.  El procesador RouteOnAttribute lee los atributos del FlowFile de entrada y decide redirigirlo a la conexi√≥n adecuada con otro procesador, seg√∫n los valores de los atributos. <br><br>  <b>Conexi√≥n</b> : proporciona conexi√≥n y transferencia de archivos de flujo entre varios procesadores y algunas otras entidades NiFi.  Connection pone el FlowFile en una cola y luego lo pasa por la cadena.  Puede configurar c√≥mo se seleccionan los FlowFiles de la cola, su duraci√≥n, n√∫mero m√°ximo y tama√±o m√°ximo de todos los objetos en la cola. <br><br>  <b>Grupo de procesos</b> : un conjunto de procesadores, sus conexiones y otros elementos de DataFlow.  Es un mecanismo para organizar muchos componentes en una estructura l√≥gica.  Ayuda a simplificar la comprensi√≥n de DataFlow.  Los puertos de entrada / salida se utilizan para recibir y enviar datos desde los grupos de procesos.  Lea m√°s sobre su uso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  <b>El repositorio de FlowFile</b> es donde NiFi almacena toda la informaci√≥n que conoce sobre cada FlowFile existente en el sistema. <br><br>  <b>Repositorio de contenido</b> : el repositorio en el que se encuentran los contenidos de todos los FlowFiles, es decir  los datos transmitidos en s√≠. <br><br>  <b>Repositorio de procedencia</b> : contiene una historia sobre cada FlowFile.  Cada vez que ocurre un evento con FlowFile (creaci√≥n, cambio, etc.), la informaci√≥n correspondiente se ingresa en este repositorio. <br><br>  <b>Servidor web</b> : proporciona una interfaz web y una API REST. <br><br><h2>  Conclusi√≥n </h2><br>  Con NiFi, Rostelecom pudo mejorar el mecanismo para entregar datos a Data Lake en Hadoop.  En general, todo el proceso se ha vuelto m√°s conveniente y confiable.  Hoy, puedo decir con seguridad que NiFi es excelente para descargar a Hadoop.  No tenemos problemas en su funcionamiento. <br><br>  Por cierto, NiFi es parte de la distribuci√≥n de flujo de datos de Hortonworks y es desarrollado activamente por Hortonworks.  Tambi√©n tiene un interesante subproyecto Apache MiNiFi, que le permite recopilar datos de varios dispositivos e integrarlos en DataFlow dentro de NiFi. <br><br><h2>  Informaci√≥n adicional sobre NiFi </h2><br><ul><li>  P√°gina oficial de documentaci√≥n del proyecto <br></li><li>  Una colecci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culos interesantes</a> sobre NiFi de uno de los participantes del proyecto. <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Blog sobre</a> uno de los desarrolladores de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">NiFi</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Art√≠culos de</a> Hortonworks <br></li></ul><br>  Quiz√°s eso es todo.  Gracias a todos por su atenci√≥n.  Escriba en los comentarios si tiene preguntas.  Les responder√© con gusto. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es432166/">https://habr.com/ru/post/es432166/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es432154/index.html">Acceso condicional como mecanismo de control de acceso</a></li>
<li><a href="../es432156/index.html">Nuevo 2GIS: con√©ctese a pruebas p√∫blicas</a></li>
<li><a href="../es432158/index.html">Usando JIRA y Confluence en un proyecto grande</a></li>
<li><a href="../es432160/index.html">Video de Android Kolesa Mobile: sobre desarrollo modular, interfaz de usuario basada en backend e integraci√≥n continua</a></li>
<li><a href="../es432162/index.html">"Tratamos de dar historias de la vida real": sobre el programa Heisenbug 2018 Mosc√∫</a></li>
<li><a href="../es432168/index.html">Las autoridades chinas recopilan informaci√≥n de veh√≠culos el√©ctricos de ciudadanos del pa√≠s.</a></li>
<li><a href="../es432170/index.html">Transporta un centro de datos en 14,400 segundos</a></li>
<li><a href="../es432172/index.html">Invitaci√≥n peligrosa, o c√≥mo funciona la carga de combate para un correo electr√≥nico de phishing</a></li>
<li><a href="../es432174/index.html">C√≥mo desarrollar de manera competente y efectiva un producto de software</a></li>
<li><a href="../es432176/index.html">C√≥mo duplicamos la velocidad de trabajo con Float en Mono</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
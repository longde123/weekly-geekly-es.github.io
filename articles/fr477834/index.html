<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ûø ‚õ∞Ô∏è üçã Principes de construction de syst√®mes d'analyse en streaming üëäüèΩ üí∂ üì∞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La conception de syst√®mes d'analyse en continu et de traitement de donn√©es en continu a ses propres nuances, ses propres probl√®mes et sa propre pile t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Principes de construction de syst√®mes d'analyse en streaming</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/477834/"><img src="https://habrastorage.org/webt/rk/pz/c5/rkpzc5nw7uyyv0vsp_00trtag44.jpeg" alt="image"><br><br>  La conception de syst√®mes d'analyse en continu et de traitement de donn√©es en continu a ses propres nuances, ses propres probl√®mes et sa propre pile technologique.  Nous en avons parl√© dans la prochaine <a href="https://www.youtube.com/watch%3Fv%3DNFjL8YQKuVg">le√ßon ouverte</a> , tenue √† la veille du lancement du cours <a href="https://otus.pw/IxY2/">Data Engineer</a> . <br><br>  Lors du webinaire discut√©: <br><br><ul><li>  lorsque le traitement en streaming est n√©cessaire; </li><li>  quels √©l√©ments sont dans SPOD, quels outils pouvons-nous utiliser pour impl√©menter ces √©l√©ments; </li><li>  comment construire votre propre syst√®me d'analyse clickstream. </li></ul><br>  Conf√©rencier - <a href="https://otus.ru/teacher/370/">Yegor Mateshuk</a> , ing√©nieur principal des donn√©es chez MaximaTelecom. <br><a name="habracut"></a><br><h3>  Quand le streaming est-il n√©cessaire?  Stream vs Batch </h3><br>  Tout d'abord, nous devons d√©terminer quand nous avons besoin de streaming et lors du traitement par lots.  Expliquons les forces et les faiblesses de ces approches. <br><br>  <b>Ainsi, les inconv√©nients du traitement par lots:</b> <br><br><ul><li>  les donn√©es sont livr√©es avec un retard.  Puisque nous avons une certaine p√©riode de calculs, alors pour cette p√©riode, nous sommes toujours en retard sur le temps r√©el.  Et plus il y a d'it√©rations, plus nous prenons de retard.  Ainsi, nous obtenons un d√©lai, qui dans certains cas est critique; </li><li>  une charge de pointe sur le fer est cr√©√©e.  Si nous calculons beaucoup en mode batch, √† la fin de la p√©riode (jour, semaine, mois) nous avons une charge de pointe, car vous devez calculer beaucoup de choses.  √Ä quoi cela m√®ne-t-il?  Premi√®rement, nous commen√ßons √† nous appuyer sur des limites qui, comme vous le savez, ne sont pas infinies.  Par cons√©quent, le syst√®me fonctionne r√©guli√®rement jusqu'√† la limite, ce qui entra√Æne souvent des √©checs.  Deuxi√®mement, comme tous ces emplois d√©marrent en m√™me temps, ils se font concurrence et sont calcul√©s assez lentement, c'est-√†-dire que vous ne pouvez pas compter sur un r√©sultat rapide. </li></ul><br>  <b>Mais le traitement par lots a ses avantages:</b> <br><br><ul><li>  haute efficacit√©.  Nous n'irons pas plus loin, car l'efficacit√© est associ√©e √† la compression, aux frameworks et √† l'utilisation de formats de colonnes, etc. Le fait est que le traitement par lots, si vous prenez le nombre d'enregistrements trait√©s par unit√© de temps, sera plus efficace; </li><li>  facilit√© de d√©veloppement et de support.  Vous pouvez traiter n'importe quelle partie des donn√©es en testant et en recomptant si n√©cessaire. </li></ul><br>  <b>Avantages du streaming de traitement de donn√©es (streaming):</b> <br><br><ul><li>  r√©sultat en temps r√©el.  Nous n'attendons la fin d'aucune p√©riode: d√®s que les donn√©es (m√™me tr√®s petites) nous parviennent, nous pouvons imm√©diatement les traiter et les transmettre.  C'est-√†-dire que le r√©sultat, par d√©finition, tend vers le temps r√©el; </li><li>  charge uniforme sur le fer.  Il est clair qu'il existe des cycles quotidiens, etc., cependant, la charge est toujours r√©partie tout au long de la journ√©e et elle s'av√®re plus uniforme et pr√©visible. </li></ul><br>  <b>Le principal inconv√©nient du traitement en streaming:</b> <br><ul><li>  complexit√© du d√©veloppement et du support.  Tout d'abord, les tests, la gestion et la r√©cup√©ration des donn√©es sont un peu plus difficiles par rapport au lot.  La deuxi√®me difficult√© (en fait, c'est le probl√®me le plus fondamental) est associ√©e aux annulations.  Si les emplois n'ont pas fonctionn√© et qu'il y a eu un √©chec, il est tr√®s difficile de saisir exactement le moment o√π tout s'est cass√©.  Et r√©soudre le probl√®me vous demandera plus d'efforts et de ressources que le traitement par lots. </li></ul><br>  Donc, si vous pensez <b>que vous avez besoin de flux</b> , r√©pondez vous-m√™me aux questions suivantes: <br><br><ol><li>  Avez-vous vraiment besoin de temps r√©el? </li><li>  Existe-t-il de nombreuses sources de streaming? </li><li>  La perte d'un enregistrement est-elle critique? </li></ol><br>  Regardons <b>deux exemples</b> : <br><br>  <i>Exemple 1. Analyse des stocks pour la vente au d√©tail:</i> <br><ul><li>  l'affichage des marchandises ne change pas en temps r√©el; </li><li>  les donn√©es sont le plus souvent livr√©es en mode batch; </li><li>  la perte d'informations est critique. </li></ul><br>  Dans cet exemple, il est pr√©f√©rable d'utiliser le lot. <br><br>  <i>Exemple 2. Analytique pour un portail Web:</i> <br><br><ul><li>  la vitesse d'analyse d√©termine le temps de r√©action √† un probl√®me; </li><li>  les donn√©es arrivent en temps r√©el; </li><li>  Les pertes d'une petite quantit√© d'informations sur les activit√©s des utilisateurs sont acceptables. </li></ul><br>  Imaginez que l'analyse refl√®te la fa√ßon dont les visiteurs d'un portail Web se sentent en utilisant votre produit.  Par exemple, vous avez d√©ploy√© une nouvelle version et vous devez comprendre dans un d√©lai de 10 √† 30 minutes si tout est en ordre, si des fonctionnalit√©s personnalis√©es se sont cass√©es.  Disons que le texte du bouton "Commander" a disparu - les analyses vous permettront de r√©agir rapidement √† une forte baisse du nombre de commandes, et vous comprendrez imm√©diatement que vous devez revenir en arri√®re. <br><br>  Ainsi, dans le deuxi√®me exemple, il est pr√©f√©rable d'utiliser des flux. <br><br><h3>  √âl√©ments SPOD </h3><br>  Les ing√©nieurs en traitement de donn√©es capturent, d√©placent, livrent, convertissent et stockent ces m√™mes donn√©es (oui, le stockage de donn√©es est √©galement un processus actif!). <br>  Par cons√©quent, afin de construire un syst√®me de traitement de donn√©es en continu (SPOD), nous aurons besoin des √©l√©ments suivants: <br><br><ol><li>  <b>chargeur de donn√©es</b> (moyen de livraison des donn√©es au stockage); </li><li>  <b>bus d'√©change de donn√©es</b> (ce n'est pas toujours n√©cessaire, mais il n'y a aucun moyen dans les flux sans lui, car vous avez besoin d'un syst√®me √† travers lequel vous √©changerez des donn√©es en temps r√©el); </li><li>  <b>stockage de donn√©es</b> (comme sans); </li><li>  <b>Moteur ETL</b> (n√©cessaire pour effectuer diverses op√©rations de filtrage, de tri et autres); </li><li>  <b>BI</b> (pour afficher les r√©sultats); </li><li>  <b>orchestrateur</b> (relie l'ensemble du processus, organise le traitement des donn√©es en plusieurs √©tapes). </li></ol><br>  Dans notre cas, nous consid√©rerons la situation la plus simple et nous concentrerons uniquement sur les trois premiers √©l√©ments. <br><br><h3>  Outils de traitement de flux de donn√©es </h3><br>  Nous avons plusieurs ¬´candidats¬ª pour le r√¥le de <b>chargeur</b> de <b>donn√©es</b> : <br><br><ul><li>  Canal Apache </li><li>  Apache nifi </li><li>  Streamset </li></ul><br><h4>  Canal Apache </h4><br>  Le premier dont nous parlerons est <b>Apache Flume</b> , un outil pour transporter des donn√©es entre diff√©rentes sources et r√©f√©rentiels. <br><br><img src="https://habrastorage.org/webt/dg/by/a3/dgbya30snrkaceq0y7bvtct59wc.png" alt="image"><br><br>  Avantages: <br><br><ul><li>  il y a presque partout </li><li>  longtemps utilis√© </li><li>  suffisamment flexible et extensible </li></ul><br>  Inconv√©nients: <br><br><ul><li>  configuration peu pratique </li><li>  difficile √† surveiller </li></ul><br>  Quant √† sa configuration, elle ressemble √† ceci: <br><br><img src="https://habrastorage.org/webt/hf/-i/bz/hf-ibz-bp5n8ydo3c1viwsxw9qe.png" alt="image"><br><br>  Ci-dessus, nous cr√©ons un canal simple qui se trouve sur le port, en prend les donn√©es et les enregistre simplement.  En principe, pour d√©crire un processus, c'est toujours normal, mais lorsque vous en avez des dizaines, le fichier de configuration se transforme en enfer.  Quelqu'un ajoute des configurateurs visuels, mais pourquoi s'emb√™ter s'il existe des outils qui le rendent pr√™t √† l'emploi?  Par exemple, les m√™mes NiFi et StreamSets. <br><br><h4>  Apache nifi </h4><br>  En fait, il joue le m√™me r√¥le que Flume, mais avec une interface visuelle, ce qui est un gros plus, surtout quand il y a beaucoup de processus. <br><br>  Quelques faits sur NiFi <br><br><ul><li>  d√©velopp√© √† l'origine √† la NSA; </li><li>  Hortonworks est maintenant pris en charge et d√©velopp√©; </li><li>  une partie de HDF de Hortonworks; </li><li>  dispose d'une version sp√©ciale de MiNiFi pour la collecte de donn√©es √† partir d'appareils. </li></ul><br>  Le syst√®me ressemble √† ceci: <br><br><img src="https://habrastorage.org/webt/jz/1k/l7/jz1kl7seqymd9rxx2tog4k88wni.png" alt="image"><br><br>  Nous avons un champ de cr√©ativit√© et d'√©tapes de traitement des donn√©es que nous y jetons.  Il existe de nombreux connecteurs pour tous les syst√®mes possibles, etc. <br><br><h4>  Streamset </h4><br>  C'est √©galement un syst√®me de contr√¥le de flux de donn√©es avec une interface visuelle.  Il a √©t√© d√©velopp√© par des gens de Cloudera, il est facilement install√© comme Parcel sur CDH, il a une version sp√©ciale de SDC Edge pour collecter des donn√©es √† partir d'appareils. <br><br>  Se compose de deux √©l√©ments: <br><br><ul><li>  SDC - un syst√®me qui effectue un traitement direct des donn√©es (gratuit); </li><li>  StreamSets Control Hub - un centre de contr√¥le pour plusieurs SDC avec des fonctionnalit√©s suppl√©mentaires pour le d√©veloppement de lignes de paiement (payantes). </li></ul><br>  Cela ressemble √† ceci: <br><br><img src="https://habrastorage.org/webt/kx/3z/jw/kx3zjwqx_ijbfxdlg7hvizllnt4.png" alt="image"><br><br>  Moment d√©sagr√©able - StreamSets ont des pi√®ces gratuites et payantes. <br><br><h4>  Bus de donn√©es </h4><br>  Voyons maintenant o√π nous allons t√©l√©charger ces donn√©es.  Candidats: <br><br><ul><li>  Apache kafka </li><li>  Rabbitmq </li><li>  NATS </li></ul><br>  Apache Kafka est la meilleure option, mais si vous avez RabbitMQ ou NATS dans votre entreprise et que vous devez ajouter un peu d'analyse, le d√©ploiement de Kafka √† partir de z√©ro ne sera pas tr√®s rentable. <br><br>  Dans tous les autres cas, Kafka est un excellent choix.  En fait, c'est un courtier de messages avec une mise √† l'√©chelle horizontale et une bande passante √©norme.  Il est parfaitement int√©gr√© √† l'ensemble de l'√©cosyst√®me d'outils pour travailler avec les donn√©es et peut supporter de lourdes charges.  Il a une interface universelle et est le syst√®me circulatoire de notre traitement des donn√©es. <br><br>  √Ä l'int√©rieur, Kafka est divis√© en sujet - un certain flux de donn√©es distinct des messages avec le m√™me sch√©ma ou, au moins, avec le m√™me objectif. <br><br>  Pour discuter de la nuance suivante, vous devez vous rappeler que les sources de donn√©es peuvent varier l√©g√®rement.  Le format des donn√©es est tr√®s important: <br><br><img src="https://habrastorage.org/webt/fq/kn/ci/fqkncilmsox7hmoye289ronvbyk.png" alt="image"><br><br>  Le format de s√©rialisation des donn√©es Apache Avro m√©rite une mention sp√©ciale.  Le syst√®me utilise JSON pour d√©terminer la structure de donn√©es (sch√©ma) qui est s√©rialis√©e en un <b>format binaire compact</b> .  Par cons√©quent, nous √©conomisons une √©norme quantit√© de donn√©es et la s√©rialisation / d√©s√©rialisation est moins ch√®re. <br><br>  Tout semble aller bien, mais la pr√©sence de fichiers s√©par√©s avec des circuits pose un probl√®me, car nous devons √©changer des fichiers entre diff√©rents syst√®mes.  Il semblerait que c'est simple, mais lorsque vous travaillez dans diff√©rents d√©partements, les gars de l'autre c√¥t√© peuvent changer quelque chose et se calmer, et tout va tomber en panne pour vous. <br><br>  Afin de ne pas transf√©rer tous ces fichiers sur des lecteurs flash, des disquettes et des peintures rupestres, il existe un service sp√©cial - Registre de sch√©ma.  Il s'agit d'un service de synchronisation d'avro-sch√©mas entre des services qui √©crivent et lisent √† partir de Kafka. <br><br><img src="https://habrastorage.org/webt/do/jf/qd/dojfqd1m6nf5wr53xmvmg5hee_a.png" alt="image"><br><br>  Pour Kafka, le producteur est celui qui √©crit, le consommateur est celui qui consomme (lit) les donn√©es. <br><br><h4>  Entrep√¥t de donn√©es </h4><br>  Challengers (en fait, il y a beaucoup plus d'options, mais n'en prenez que quelques-unes): <br><br><ul><li>  HDFS + Hive </li><li>  Kudu + Impala </li><li>  Clickhouse </li></ul><br>  Avant de choisir un r√©f√©rentiel, rappelez-vous ce qu'est l' <b>idempotence</b> .  Wikip√©dia dit que l'idempotence (idem latin - le m√™me + potens - capable) - la propri√©t√© d'un objet ou d'une op√©ration lors de la nouvelle application de l'op√©ration √† l'objet, donne le m√™me r√©sultat que le premier.  Dans notre cas, le processus de traitement en continu doit √™tre construit de sorte que lors du remplissage des donn√©es source, le r√©sultat reste correct. <br><br>  <b>Comment y parvenir</b> dans les syst√®mes de streaming: <br><br><ul><li>  identifier un identifiant unique (peut √™tre composite) </li><li>  utilisez cet identifiant pour d√©dupliquer les donn√©es </li></ul><br>  Le stockage HDFS + Hive <b>ne fournit pas l'idempotence</b> pour l'enregistrement en streaming ¬´pr√™t √† l'emploi¬ª, nous avons donc: <br><br><ul><li>  Kudu + Impala </li><li>  Clickhouse </li></ul><br>  <b>Kudu</b> est un r√©f√©rentiel adapt√© aux requ√™tes analytiques, mais avec une cl√© primaire, pour la d√©duplication.  <b>Impala</b> est l'interface SQL de ce r√©f√©rentiel (et de plusieurs autres). <br><br>  Quant √† ClickHouse, il s'agit d'une base de donn√©es analytique de Yandex.  Son objectif principal est l'analyse sur une table remplie d'un grand flux de donn√©es brutes.  Parmi les avantages - il existe un moteur ReplacingMergeTree pour la d√©duplication des cl√©s (la d√©duplication est con√ßue pour √©conomiser de l'espace et peut laisser des doublons dans certains cas, vous devez prendre en compte les <a href="https://clickhouse.yandex/docs/ru/operations/table_engines/replacingmergetree/">nuances</a> ). <br><br>  Reste √† ajouter quelques mots sur <b>Divolte</b> .  Si vous vous en souvenez, nous avons parl√© du fait que certaines donn√©es doivent √™tre saisies.  Si vous avez besoin d'organiser rapidement et facilement des analyses pour un portail, Divolte est un excellent service pour capturer les √©v√©nements des utilisateurs sur une page Web via JavaScript. <br><br><img src="https://habrastorage.org/webt/wo/7m/ol/wo7molaoelkzjjatvyzzaihkrmm.png" alt="image"><br><br><h3>  Exemple pratique </h3><br>  Qu'essayons-nous de faire?  <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4016">Essayons de construire un</a> pipeline pour collecter les donn√©es Clickstream en temps r√©el.  <b>Clickstream</b> est une empreinte virtuelle qu'un utilisateur laisse lorsqu'il est sur votre site.  Nous allons capturer des donn√©es √† l'aide de Divolte et les √©crire dans Kafka. <br><br><img src="https://habrastorage.org/webt/uj/mt/h-/ujmth-4jh9catnqqxt0ikp0w9xa.png" alt="image"><br><br>  Vous avez besoin de Docker pour fonctionner, et vous devez cloner le <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example">r√©f√©rentiel suivant</a> .  Tout ce qui se passera sera lanc√© dans des conteneurs.  Pour ex√©cuter r√©guli√®rement plusieurs conteneurs √† la fois, <a href="">docker-compose.yml</a> sera utilis√©.  De plus, il existe un <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/blob/master/Dockerfile">Dockerfile</a> compilant nos StreamSets avec certaines d√©pendances. <br><br>  Il existe √©galement trois dossiers: <br><br><ol><li>  <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/clickhouse-data">les donn√©es clickhouse</a> seront √©crites dans <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/clickhouse-data">clickhouse-data</a> </li><li>  exactement le m√™me papa ( <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/sdc-data">sdc-data</a> ) que nous aurons pour StreamSets, o√π le syst√®me peut stocker des configurations </li><li>  le troisi√®me dossier ( <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/examples">exemples</a> ) comprend un fichier de demande et un fichier de configuration de canal pour StreamSets </li></ol><br><br><img src="https://habrastorage.org/webt/-r/xt/2r/-rxt2rlhxzdqqeyz7qv3z3dugxw.png" alt="image"><br><br>  Pour commencer, entrez la commande suivante: <br><br><pre><code class="bash hljs">docker-compose up</code> </pre> <br>  Et nous appr√©cions la fa√ßon dont les conteneurs d√©marrent lentement mais s√ªrement.  Apr√®s le d√©marrage, nous pouvons aller √† l'adresse <a href="http://localhost:8290/">http: // localhost: 18630 ‚Äã‚Äã/</a> et toucher imm√©diatement Divolte: <br><br><img src="https://habrastorage.org/webt/cc/1m/im/cc1mimjszmzdoyiwb-elb2c_igu.png" alt="image"><br><br>  Nous avons donc Divolte, qui a d√©j√† re√ßu des √©v√©nements et les a enregistr√©s √† Kafka.  Essayons de les calculer en utilisant StreamSets: <a href="http://localhost:18630/">http: // localhost: 18630 ‚Äã‚Äã/</a> (mot de passe / login - admin / admin). <br><br><img src="https://habrastorage.org/webt/fc/hk/qz/fchkqzqe9pzpdws-xilz3ftdcb8.png" alt="image"><br><br>  Afin de ne pas souffrir, il est pr√©f√©rable d' <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4425">importer</a> <b>Pipeline</b> , en le nommant, par exemple, <b>clickstream_pipeline</b> .  Et √† partir du dossier d'exemples, nous importons <b>clickstream.json</b> .  Si tout va bien, <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4701">nous verrons l'image suivante</a> : <br><br><img src="https://habrastorage.org/webt/o8/z9/x5/o8z9x5eaacqkehcfcgxattekpba.png" alt="image"><br><br>  Nous avons donc cr√©√© une connexion √† Kafka, enregistr√© quel Kafka nous avons besoin, enregistr√© quel sujet nous int√©resse, puis s√©lectionn√© les champs qui nous int√©ressent, puis mis un drain dans Kafka, enregistrant quel Kafka et quel sujet.  Les diff√©rences sont que dans un cas, le format de donn√©es est Avro et dans le second, il s'agit simplement de JSON. <br><br>  Continuons.  Nous pouvons, par exemple, <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4768">faire un aper√ßu</a> qui capture certains enregistrements en temps r√©el √† partir de Kafka.  Ensuite, nous √©crivons tout. <br><br>  Apr√®s le lancement, nous verrons qu'un flux d'√©v√©nements vole vers Kafka, et cela se produit en temps r√©el: <br><br><img src="https://habrastorage.org/webt/kr/a7/0n/kra70nxdaplug8-oywal1wb23oi.png" alt="image"><br><br>  Vous pouvez maintenant cr√©er un r√©f√©rentiel pour ces donn√©es dans ClickHouse.  Pour travailler avec ClickHouse, vous pouvez utiliser un client natif simple en ex√©cutant la commande suivante: <br><br><pre> <code class="bash hljs">docker run -it --rm --network divolte-ss-ch_default yandex/clickhouse-client --host clickhouse</code> </pre> <br>  Veuillez noter que cette ligne indique le r√©seau auquel vous souhaitez vous connecter.  Et selon la fa√ßon dont vous nommez le dossier avec le r√©f√©rentiel, le nom de votre r√©seau peut diff√©rer.  En g√©n√©ral, la commande sera la suivante: <br><br><pre> <code class="bash hljs">docker run -it --rm --network {your_network_name} yandex/clickhouse-client --host clickhouse</code> </pre> <br>  La liste des r√©seaux peut √™tre consult√©e avec la commande: <br><br><pre> <code class="bash hljs">docker network ls</code> </pre> <br>  Eh bien, il ne reste plus rien: <br><br>  1. <b>Tout d'abord, ¬´signez¬ª notre ClickHouse √† Kafka</b> , ¬´lui expliquant¬ª le format des donn√©es dont nous avons besoin: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">IF</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXISTS</span></span> clickstream_topic ( firstInSession UInt8, <span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span> UInt64, location <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, partyId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, sessionId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, pageViewId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, eventType <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, userAgentString <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = Kafka <span class="hljs-keyword"><span class="hljs-keyword">SETTINGS</span></span> kafka_broker_list = <span class="hljs-string"><span class="hljs-string">'kafka:9092'</span></span>, kafka_topic_list = <span class="hljs-string"><span class="hljs-string">'clickstream'</span></span>, kafka_group_name = <span class="hljs-string"><span class="hljs-string">'clickhouse'</span></span>, kafka_format = <span class="hljs-string"><span class="hljs-string">'JSONEachRow'</span></span>;</code> </pre><br>  2. <b>Nous allons maintenant cr√©er un vrai tableau</b> o√π nous mettrons les donn√©es finales: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> clickstream ( firstInSession UInt8, <span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span> UInt64, location <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, partyId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, sessionId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, pageViewId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, eventType <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, userAgentString <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = ReplacingMergeTree() <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> (<span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span>, pageViewId);</code> </pre> <br>  3. <b>Et puis nous fournirons une relation entre ces deux tables</b> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">MATERIALIZED</span></span> <span class="hljs-keyword"><span class="hljs-keyword">VIEW</span></span> clickstream_consumer <span class="hljs-keyword"><span class="hljs-keyword">TO</span></span> clickstream <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> clickstream_topic;</code> </pre> <br>  4. <b>Et maintenant, nous allons s√©lectionner les champs n√©cessaires</b> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> clickstream;</code> </pre> <br>  Par cons√©quent, le choix dans la table cible nous donnera le r√©sultat dont nous avons besoin. <br><br><img src="https://habrastorage.org/webt/wn/sr/qe/wnsrqei2fo7iydrf41zattwbddy.png"><br><br>  C'est tout, c'√©tait le Clickstream le plus simple que vous puissiez cr√©er.  Si vous souhaitez effectuer vous-m√™me les √©tapes ci-dessus, <a href="https://www.youtube.com/watch%3Fv%3DNFjL8YQKuVg">regardez l'</a> int√©gralit√© de la <a href="https://www.youtube.com/watch%3Fv%3DNFjL8YQKuVg">vid√©o</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr477834/">https://habr.com/ru/post/fr477834/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr477820/index.html">VMware, Hyper-V, OpenStack, Kubernetes, Swarm - surveillance √† partir d'une seule interface dans Quest Foglight</a></li>
<li><a href="../fr477822/index.html">PHP 7.4 est sorti! Comment les mises √† niveau de Badoo</a></li>
<li><a href="../fr477824/index.html">Vivons jusqu'√† lundi ou comment survivre au vendredi noir</a></li>
<li><a href="../fr477826/index.html">Pr√©sentation et comparaison des technologies V2X</a></li>
<li><a href="../fr477832/index.html">Comment s'entendre avec la g√©n√©ration Z</a></li>
<li><a href="../fr477836/index.html">Comment nous avons test√© le WD ActiveScale P100 pour notre stockage S3</a></li>
<li><a href="../fr477840/index.html">Analyseur de code statique PVS-Studio comme protection contre les vuln√©rabilit√©s zero-day</a></li>
<li><a href="../fr477842/index.html">Histoires de Gennady Zelenko et Sergey Popov - vulgarisateurs de la technologie en URSS</a></li>
<li><a href="../fr477844/index.html">5 √©tapes de l'id√©e √† l'application pratique de l'apprentissage automatique avec SAP Data Intelligence</a></li>
<li><a href="../fr477846/index.html">Le condens√© des √©v√©nements pour les professionnels des RH en informatique pour d√©cembre 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
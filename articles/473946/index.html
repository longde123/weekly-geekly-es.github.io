<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äç‚öñÔ∏è üëáüèº üßúüèø Registro distribuido y rastreo para microservicios üßù üïî ü§πüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El registro es una parte importante de cualquier aplicaci√≥n. Cualquier sistema de registro pasa por tres pasos evolutivos principales. El primero se e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Registro distribuido y rastreo para microservicios</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/473946/">  El registro es una parte importante de cualquier aplicaci√≥n.  Cualquier sistema de registro pasa por tres pasos evolutivos principales.  El primero se env√≠a a la consola, el segundo es iniciar sesi√≥n en un archivo y la apariencia de un marco para el registro estructurado, y el tercero es el registro distribuido o la recopilaci√≥n de registros de varios servicios en un solo centro. <br><br>  Si el registro est√° bien organizado, le permite comprender qu√©, cu√°ndo y c√≥mo sale mal, y transmitir la informaci√≥n necesaria a las personas que tienen que corregir estos errores.  Para un sistema en el que se env√≠an 100 mil mensajes por segundo en 10 centros de datos en 190 pa√≠ses, y 350 ingenieros implementan algo todos los d√≠as, el sistema de registro es especialmente importante. <br><br><img src="https://habrastorage.org/webt/sy/7i/u_/sy7iu_dnjrrvar7krt8llrje1ga.jpeg"><br><br>  <b>Ivan Letenko</b> es l√≠der de equipo y desarrollador en Infobip.  Para resolver el problema del procesamiento centralizado y el seguimiento de registros en la arquitectura de microservicios bajo cargas tan enormes, la compa√±√≠a prob√≥ varias combinaciones de la pila ELK, Graylog, Neo4j y MongoDB.  Como resultado, despu√©s de mucho rastrillo, escribieron su servicio de registro en Elasticsearch, y PostgreSQL fue tomado como una base de datos para obtener informaci√≥n adicional. <br><br>  Debajo del gato en detalle, con ejemplos y gr√°ficos: la arquitectura y la evoluci√≥n del sistema, rastrillos, registro y rastreo, m√©tricas y monitoreo, la pr√°ctica de trabajar con clusters de Elasticsearch y administrarlos con recursos limitados. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Sr71xsI6X5I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Para presentarle el contexto, le contar√© un poco sobre la empresa.  Ayudamos a las organizaciones de clientes a enviar mensajes a sus clientes: mensajes de un servicio de taxi, SMS de un banco sobre la cancelaci√≥n o una contrase√±a de un solo uso al ingresar VC.  <b>350 millones de mensajes</b> pasan a trav√©s de nosotros todos los d√≠as para clientes en 190 pa√≠ses.  Cada uno de ellos aceptamos, procesamos, facturamos, enrutamos, adaptamos, enviamos a los operadores y, en la direcci√≥n opuesta, procesamos informes de entrega y generamos an√°lisis. <br><br>  Para que todo esto funcione en tales vol√∫menes, tenemos: <br><br><ul><li>  36 centros de datos en todo el mundo; <br></li><li>  M√°s de 5000 m√°quinas virtuales <br></li><li>  M√°s de 350 ingenieros; <br></li><li>  M√°s de 730 microservicios diferentes. <br></li></ul><br>  Este es un sistema complejo, y ni un solo gur√∫ puede comprender la escala completa sin ayuda.  Uno de los principales objetivos de nuestra empresa es la alta velocidad de entrega de nuevas funciones y lanzamientos para empresas.  En este caso, todo deber√≠a funcionar y no caerse.  Estamos trabajando en esto: 40,000 implementaciones en 2017, 80,000 en 2018, 300 implementaciones por d√≠a. <br><br>  Tenemos 350 ingenieros, resulta que <b>cada ingeniero implementa algo diariamente</b> .  Hace solo unos a√±os, solo una persona en una empresa ten√≠a esa productividad: Kreshimir, nuestro ingeniero principal.  Pero nos aseguramos de que cada ingeniero se sienta tan seguro como Kresimir cuando presiona el bot√≥n Implementar o ejecuta un script. <br><br>  ¬øQu√© se necesita para esto?  En primer lugar, la <b>confianza de que entendemos lo que est√° sucediendo en el sistema</b> y en qu√© estado se encuentra.  La confianza est√° dada por la capacidad de hacer una pregunta al sistema y descubrir la causa del problema durante el incidente y durante el desarrollo del c√≥digo. <br><br>  Para lograr esta confianza, invertimos en <b>observabilidad</b> .  Tradicionalmente, este t√©rmino combina tres componentes: <br><br><ul><li>  tala <br></li><li>  m√©tricas <br></li><li>  rastro <br></li></ul><br>  Hablaremos de esto.  En primer lugar, echemos un vistazo a nuestra soluci√≥n para el registro, pero tambi√©n abordaremos m√©tricas y rastreos. <br><br><h2>  Evoluci√≥n </h2><br>  Casi cualquier aplicaci√≥n o sistema de registro, incluido el nuestro, pasa por varias etapas de evoluci√≥n. <br><br>  El primer paso es dar <b>salida a la consola</b> . <br><br>  Segundo: comenzamos <b>a escribir registros en un archivo</b> , aparece un <b>marco</b> para la salida estructurada a un archivo.  Usualmente usamos Logback porque vivimos en la JVM.  En esta etapa, aparece el registro estructurado en el archivo, entendiendo que los diferentes registros deben tener diferentes niveles, advertencias y errores. <br><br>  Tan pronto <b>como haya varias</b> <b>instancias de nuestro servicio</b> o diferentes servicios, aparece la tarea de <b>acceso centralizado</b> a los registros para desarrolladores y soporte.  Pasamos al registro distribuido: combinamos varios servicios en un solo servicio de registro. <br><br><h2>  Registro distribuido </h2><br>  La opci√≥n m√°s famosa es la pila ELK: Elasticsearch, Logstash y Kibana, pero elegimos <b>Graylog</b> .  Tiene una interfaz genial que est√° orientada al registro.  Las alarmas ya vienen de la caja en la versi√≥n gratuita, que no est√° en Kibana, por ejemplo.  Para nosotros, esta es una excelente opci√≥n en t√©rminos de registros, y debajo del cap√≥ est√° el mismo Elasticsearch. <br><br><img src="https://habrastorage.org/webt/x1/en/7f/x1en7fmypsgbipabhmfhy6y7rts.jpeg"><br>  <i>En Graylog, puede crear alertas, gr√°ficos como Kibana e incluso registrar m√©tricas.</i> <br><br><h3>  Los problemas </h3><br>  Nuestra empresa estaba creciendo y, en alg√∫n momento, qued√≥ claro que algo estaba mal con Graylog. <br><br>  <b>Carga excesiva</b>  Hubo problemas de rendimiento.  Muchos desarrolladores comenzaron a usar las caracter√≠sticas interesantes de Graylog: crearon m√©tricas y paneles que realizan la agregaci√≥n de datos.  No es la mejor opci√≥n para crear an√°lisis complejos en el cl√∫ster Elasticsearch, que se encuentra bajo una gran carga de grabaci√≥n. <br><br>  <b>Colisiones</b>  Hay muchos equipos, no hay un esquema √∫nico.  Tradicionalmente, cuando una ID golpe√≥ Graylog por primera vez como larga, la asignaci√≥n se produjo autom√°ticamente.  Si otro equipo decide que debe escribirse el UUID como una cadena, esto romper√° el sistema. <br><br><h2>  Primera decisi√≥n </h2><br>  <b>Registros de aplicaciones y registros de comunicaci√≥n separados</b> .  Los diferentes registros tienen diferentes escenarios y m√©todos de aplicaci√≥n.  Hay, por ejemplo, registros de aplicaciones para los que diferentes equipos tienen diferentes requisitos para diferentes par√°metros: por el tiempo de almacenamiento en el sistema, por la velocidad de b√∫squeda. <br><br>  Por lo tanto, lo primero que hicimos fue separar los registros de aplicaciones y los registros de comunicaci√≥n.  El segundo tipo son los registros importantes que almacenan informaci√≥n sobre la interacci√≥n de nuestra plataforma con el mundo exterior y sobre la interacci√≥n dentro de la plataforma.  Hablaremos m√°s sobre esto. <br><br>  <b>Reemplaz√≥ una parte sustancial de los registros con m√©tricas</b> .  En nuestra empresa, la opci√≥n est√°ndar es Prometheus y Grafana.  Algunos equipos usan otras soluciones.  Pero es importante que eliminemos una gran cantidad de paneles con agregaciones dentro de Graylog, que transfiramos todo a Prometheus y Grafana.  Esto facilit√≥ enormemente la carga en los servidores. <br><br>  Veamos los escenarios para aplicar registros, m√©tricas y rastreos. <br><br><h3>  Registros </h3><br>  <b>Alta dimensionalidad, depuraci√≥n e investigaci√≥n</b> .  ¬øQu√© son buenos registros? <br><blockquote>  Los registros son los eventos que registramos. </blockquote>  Pueden tener una gran dimensi√≥n: puede registrar ID de solicitud, ID de usuario, atributos de solicitud y otros datos, cuya dimensi√≥n no est√° limitada.  Tambi√©n son buenos para la depuraci√≥n y la investigaci√≥n, para hacer preguntas al sistema sobre lo que sucedi√≥ y buscar causas y efectos. <br><br><h3>  M√©tricas </h3><br>  <b>Baja dimensionalidad, agregaci√≥n, monitoreo y alertas</b> .  Bajo el cap√≥ de todos los sistemas de recopilaci√≥n m√©trica se encuentran las bases de datos de series temporales.  Estas bases de datos hacen un excelente trabajo de agregaci√≥n, por lo que las m√©tricas son adecuadas para la agregaci√≥n, el monitoreo y la creaci√≥n de alertas. <br><blockquote>  Las m√©tricas son muy sensibles a la dimensi√≥n de datos. </blockquote>  Para las m√©tricas, la dimensi√≥n de los datos no debe exceder mil.  Si agregamos algunos ID de solicitud, en los cuales el tama√±o de los valores no est√° limitado, r√°pidamente encontraremos problemas serios.  Ya hemos pisado este rastrillo. <br><br><h3>  Correlaci√≥n y traza </h3><blockquote>  Los registros deben estar correlacionados. </blockquote>  Los registros estructurados no son suficientes para que podamos buscar convenientemente por datos.  Debe haber campos con ciertos valores: ID de solicitud, ID de usuario, otros datos de los servicios de los que provienen los registros. <br><br>  La soluci√≥n tradicional es asignar una identificaci√≥n √∫nica a la transacci√≥n (registro) en la entrada al sistema.  Luego, esta ID (contexto) se reenv√≠a a trav√©s de todo el sistema a trav√©s de una cadena de llamadas dentro de un servicio o entre servicios. <br><br><img src="https://habrastorage.org/webt/sk/ba/ht/skbahtrbo1zjpc7x8u8hy_odxg4.png"><br>  <i>Correlaci√≥n y rastreo.</i> <br><br>  Hay t√©rminos bien establecidos.  La traza se divide en tramos y demuestra la pila de llamadas de un servicio en relaci√≥n con otro, un m√©todo en relaci√≥n con otro en relaci√≥n con la l√≠nea de tiempo.  Puede rastrear claramente la ruta del mensaje, todos los tiempos. <br><br>  Primero usamos Zipkin.  Ya en 2015, ten√≠amos una Prueba de concepto (proyecto piloto) de estas soluciones. <br><br><img src="https://habrastorage.org/webt/iw/jg/f1/iwjgf1st5rm6ymwppx3g9scb_uw.jpeg"><br>  <i>Traza distribuida</i> <br><br>  Para obtener esa imagen, el <b>c√≥digo debe ser instrumentado</b> .  Si ya est√° trabajando con una base de c√≥digo que existe, debe revisarla; requiere cambios. <br><br>  Para obtener una imagen completa y beneficiarse de los rastros, debe <b>instrumentar todos los servicios de la cadena</b> , y no solo un servicio en el que est√© trabajando actualmente. <br><br>  Esta es una herramienta poderosa, pero requiere importantes costos de administraci√≥n y hardware, por lo que cambiamos de Zipkin a otra soluci√≥n, que es proporcionada por "como servicio". <br><br><h2>  Informes de entrega </h2><br>  Los registros deben estar correlacionados.  Las huellas tambi√©n deben estar correlacionadas.  Necesitamos una identificaci√≥n √∫nica, un contexto com√∫n que se pueda reenviar a trav√©s de la cadena de llamadas.  Pero a menudo esto no es posible: la <b>correlaci√≥n ocurre dentro del sistema como resultado de su funcionamiento</b> .  Cuando comenzamos una o m√°s transacciones, todav√≠a no sabemos si son parte de un solo todo grande. <br><br>  Considere el primer ejemplo. <br><br><img src="https://habrastorage.org/webt/05/lf/ds/05lfdssmlzvh6h41nzgl3w8cjwu.jpeg"><br>  <i>Informes de entrega.</i> <br><br><ul><li>  El cliente envi√≥ una solicitud de mensaje y nuestra plataforma interna lo proces√≥. <br></li><li>  El servicio, que interact√∫a con el operador, envi√≥ este mensaje al operador: apareci√≥ una entrada en el sistema de registro. <br></li><li>  M√°s tarde, el operador nos env√≠a un informe de entrega. <br></li><li>  El servicio de procesamiento no sabe a qu√© mensaje se refiere este informe de entrega.  Esta relaci√≥n se crea m√°s adelante en nuestra plataforma. <br></li></ul><br>  Dos transacciones relacionadas son partes de una sola transacci√≥n completa.  Esta informaci√≥n es muy importante para los ingenieros de soporte y los desarrolladores de integraci√≥n.  Pero esto es completamente imposible de ver en funci√≥n de un solo rastro o una sola identificaci√≥n. <br><br>  El segundo caso es similar: el cliente nos env√≠a un mensaje en un paquete grande, luego los desarmamos, tambi√©n regresan en lotes.  El n√∫mero de paquetes puede incluso variar, pero luego se combinan todos. <br><br><img src="https://habrastorage.org/webt/67/jg/w3/67jgw3eyg33a7bwjsx8savqmgxo.jpeg"><br><br>  Desde el punto de vista del cliente, envi√≥ un mensaje y recibi√≥ una respuesta.  Pero obtuvimos varias transacciones independientes que deben combinarse.  Resulta una relaci√≥n de uno a muchos, y con un informe de entrega, uno a uno.  Esto es esencialmente un gr√°fico. <br><br><img src="https://habrastorage.org/webt/h6/bm/ak/h6bmak77dcsvoqebnfriqxuiqcq.jpeg"><br>  <i>Estamos construyendo un gr√°fico.</i> <br><br>  Una vez que vemos un gr√°fico, una opci√≥n adecuada son las bases de datos de gr√°ficos, por ejemplo, Neo4j.  La elecci√≥n fue obvia porque Neo4j regala camisetas geniales y libros gratis en las conferencias. <br><br><h3>  Neo4j </h3><br>  Implementamos Prueba de concepto: un host de 16 n√∫cleos que podr√≠a procesar un gr√°fico de 100 millones de nodos y 150 millones de enlaces.  El gr√°fico ocupaba solo 15 GB de disco, entonces nos conven√≠a. <br><br><img src="https://habrastorage.org/webt/aa/5q/bk/aa5qbkmdwshpycitkyz3-lztkck.jpeg"><br>  <i>Nuestra decision.</i>  <i>Arquitectura de registro.</i> <br><br>  Adem√°s de Neo4j, ahora tenemos una interfaz simple para ver registros relacionados.  Con √©l, los ingenieros ven la imagen completa. <br><br>  Pero bastante r√°pido, nos decepcionamos en esta base de datos. <br><br><h3>  Problemas con Neo4j </h3><br>  <b>Rotaci√≥n de datos</b> .  Tenemos vol√∫menes potentes y los datos deben rotarse.  Pero cuando se elimina un nodo de Neo4j, los datos del disco no se borran.  Tuve que construir una soluci√≥n compleja y reconstruir completamente los gr√°ficos. <br><br>  <b>Rendimiento</b>  Todas las bases de datos de gr√°ficos son de solo lectura.  En la grabaci√≥n, el rendimiento es notablemente menor.  Nuestro caso es todo lo contrario: escribimos mucho y leemos relativamente raramente; estas son unidades de solicitudes por segundo o incluso por minuto. <br><br>  <b>Alta disponibilidad y an√°lisis de conglomerados por una tarifa</b> .  En nuestra escala, esto se traduce en costos decentes. <br><br>  Por lo tanto, fuimos por el otro lado. <br><br><h3>  Soluci√≥n con PostgreSQL </h3><br>  Decidimos que, dado que raramente leemos, el gr√°fico se puede construir sobre la marcha cuando se lee.  Por lo tanto, en la base de datos relacional PostgreSQL almacenamos la lista de adyacencia de nuestros ID en forma de una placa simple con dos columnas y un √≠ndice en ambas.  Cuando llega la solicitud, omitimos el gr√°fico de conectividad utilizando el algoritmo DFS familiar (recorrido de profundidad) y obtenemos todas las ID asociadas.  Pero esto es necesario. <br><br>  La rotaci√≥n de datos tambi√©n es f√°cil de resolver.  Para cada d√≠a comenzamos un nuevo plato y despu√©s de unos d√≠as cuando llegue el momento, lo eliminamos y publicamos los datos.  Una soluci√≥n simple <br><br>  Ahora tenemos 850 millones de conexiones en PostgreSQL, ocupan 100 GB de disco.  Escribimos all√≠ a una velocidad de 30 mil por segundo, y para esto en la base de datos solo hay dos m√°quinas virtuales con 2 CPU y 6 GB de RAM.  Seg√∫n sea necesario, PostgreSQL puede escribir largos r√°pidamente. <br><br>  Todav√≠a hay m√°quinas peque√±as para el servicio en s√≠, que giran y controlan. <br><br><img src="https://habrastorage.org/webt/yk/re/vq/ykrevqnk3xx8rpa3lkc9lkgiram.jpeg"><br>  <i>C√≥mo ha cambiado nuestra arquitectura.</i> <br><br><h2>  Desaf√≠os con Graylog </h2><br>  La compa√±√≠a creci√≥, aparecieron nuevos centros de datos, la carga aument√≥ notablemente, incluso con una soluci√≥n con registros de comunicaci√≥n.  Pensamos que Graylog ya no es perfecto. <br><br>  <b>Esquema unificado y centralizaci√≥n</b> .  Me gustar√≠a tener una √∫nica herramienta de administraci√≥n de cl√∫ster en 10 centros de datos.  Adem√°s, surgi√≥ la cuesti√≥n de un esquema unificado de mapeo de datos para que no hubiera colisiones. <br><br>  <b>API</b>  Utilizamos nuestra propia interfaz para mostrar las conexiones entre los registros y la API est√°ndar de Graylog no siempre fue conveniente de usar, por ejemplo, cuando necesita mostrar datos de diferentes centros de datos, ordenarlos y marcarlos correctamente.  Por lo tanto, quer√≠amos poder cambiar la API a nuestro gusto. <br><br>  <b>Rendimiento, es dif√≠cil evaluar la p√©rdida</b> .  Nuestro tr√°fico es de 3 TB de registros por d√≠a, lo cual es decente.  Por lo tanto, Graylog no siempre funcion√≥ de manera estable, fue necesario entrar en su interior para comprender las causas de los fallos.  Result√≥ que ya no lo us√°bamos como herramienta, ten√≠amos que hacer algo al respecto. <br><br>  <b>Retrasos en el procesamiento (colas)</b> .  No nos gust√≥ la implementaci√≥n est√°ndar de la cola en Graylog. <br><br>  <b>La necesidad de apoyar MongoDB</b> .  Graylog arrastra MongoDB, tambi√©n era necesario administrar este sistema. <br><br>  Nos dimos cuenta de que en esta etapa queremos nuestra propia soluci√≥n.  Quiz√°s haya menos funciones interesantes para alertas que no se hayan utilizado, para paneles, pero las suyas son mejores. <br><br><h3>  Nuestra decision </h3><br>  Hemos desarrollado nuestro propio servicio de registros. <br><br><img src="https://habrastorage.org/webt/2e/cl/zb/2eclzbtgkkzyjdy1u9amvwujcw8.jpeg"><br>  <i>Servicio de registro.</i> <br><br>  En ese momento, ya ten√≠amos experiencia en el servicio y mantenimiento de grandes grupos de Elasticsearch, por lo que tomamos a Elasticsearch como base.  La pila est√°ndar en la compa√±√≠a es JVM, pero para el backend tambi√©n usamos Kotlin de manera famosa, por lo que tomamos este idioma para el servicio. <br><br>  La primera pregunta es c√≥mo rotar los datos y qu√© hacer con el mapeo.  Usamos mapeo fijo.  En Elasticsearch, es mejor tener √≠ndices del mismo tama√±o.  Pero con tales √≠ndices, necesitamos mapear datos de alguna manera, especialmente para varios centros de datos, un sistema distribuido y un estado distribuido.  Hubo ideas para sujetar ZooKeeper, pero esto es nuevamente una complicaci√≥n de mantenimiento y c√≥digo. <br><blockquote>  Por lo tanto, decidimos simplemente: escribir a tiempo. </blockquote>  Un √≠ndice por una hora, en otros centros de datos 2 √≠ndices por una hora, en el tercer √≠ndice por 3 horas, pero todo a tiempo.  Los √≠ndices se obtienen en diferentes tama√±os, porque en la noche el tr√°fico es menor que durante el d√≠a, pero en general funciona.  La experiencia ha demostrado que no se necesitan complicaciones. <br><br>  Para facilitar la migraci√≥n y dada la gran cantidad de datos, elegimos el protocolo GELF, un protocolo Graylog simple basado en TCP.  Entonces obtuvimos un servidor GELF para Netty y un decodificador GELF. <br><br>  Luego, JSON se codifica para escribir en Elasticsearch.  Usamos la API oficial de Java de Elasticsearch y escribimos en Bulk. <br><blockquote>  Para una alta velocidad de grabaci√≥n necesitas escribir Bulk'ami. </blockquote>  Esta es una optimizaci√≥n importante.  La API proporciona un procesador masivo que acumula autom√°ticamente las solicitudes y luego las env√≠a para su grabaci√≥n en un paquete o con el tiempo. <br><br><h3>  Problema con el procesador masivo </h3><br>  Todo parece estar bien.  Pero comenzamos y nos dimos cuenta de que descans√°bamos en el procesador Bulk; fue inesperado.  No podemos alcanzar los valores con los que contamos: el problema surgi√≥ de la nada. <br><br><img src="https://habrastorage.org/webt/f8/eh/aq/f8ehaq7rjnpje-lcnrr3gtbk6ho.jpeg"><br><br>  En la implementaci√≥n est√°ndar, el procesador Bulk es de un solo subproceso, sincr√≥nico, a pesar del hecho de que hay una configuraci√≥n de paralelismo.  Ese fue el problema. <br><br>  Rebuscamos y result√≥ que este es un error conocido, pero no resuelto.  Cambiamos un poco el procesador Bulk, hicimos un bloqueo expl√≠cito a trav√©s de ReentrantLock.  Solo en mayo, se realizaron cambios similares en el repositorio oficial de Elasticsearch y estar√°n disponibles solo desde la versi√≥n 7.3.  El actual es 7.1, y estamos utilizando la versi√≥n 6.3. <br><br>  Si tambi√©n trabaja con un procesador masivo y desea overclockear una entrada en Elasticsearch, observe estos <a href="">cambios en GitHub</a> y vuelva a su puerto.  Los cambios afectan solo al procesador masivo.  No habr√° dificultades si necesita portar a la versi√≥n a continuaci√≥n. <br><br>  Todo est√° bien, el procesador Bulk se ha ido, la velocidad se ha acelerado. <br><br><img src="https://habrastorage.org/webt/al/kk/nz/alkknzzqgvbtqc-lx0alpunp27y.jpeg"><br><br>  El rendimiento de escritura de Elasticsearch es inestable con el tiempo, ya que varias operaciones tienen lugar all√≠: fusi√≥n de √≠ndices, vaciado.  Adem√°s, el rendimiento disminuye durante un tiempo durante el mantenimiento, cuando parte de los nodos se eliminan del cl√∫ster, por ejemplo. <br><br>  En este sentido, nos dimos cuenta de que necesitamos implementar no solo el b√∫fer en la memoria, sino tambi√©n la cola.  Decidimos que solo enviar√≠amos mensajes rechazados a la cola, solo aquellos que el procesador masivo no pod√≠a escribir en Elasticsearch. <br><br><h3>  Reintentar reserva </h3><br>  Esta es una implementaci√≥n simple. <br><br><ul><li><script type="text/javascript">function gtElInit() {var lib = new google.translate.TranslateService();lib.translatePage('ru', 'es', function () {});}</script><script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=gtElInit&amp;client=wt"></script> Guardamos los mensajes rechazados en el archivo - <code>RejectedExecutionHandler</code> . <br></li><li>  Vuelva a enviar en el intervalo especificado en un ejecutor separado. <br></li><li>  Sin embargo, no retrasamos el tr√°fico nuevo. <br></li></ul><br>  Para los ingenieros y desarrolladores de soporte, el nuevo tr√°fico en el sistema es notablemente m√°s importante que el que, por alguna raz√≥n, se retras√≥ durante el pico o la desaceleraci√≥n de Elasticsearch.  Se demor√≥, pero vendr√≠a m√°s tarde, no es gran cosa.  Se prioriza el nuevo tr√°fico. <br><br><img src="https://habrastorage.org/webt/_f/jf/xz/_fjfxzutbmmt88ibablan9les0i.jpeg"><br>  <i>Nuestro esquema comenz√≥ a verse as√≠.</i> <br><br>  Ahora hablemos sobre c√≥mo preparamos Elasticsearch, qu√© par√°metros usamos y c√≥mo lo configuramos. <br><br><h2>  Configuraci√≥n de Elasticsearch </h2><br>  El problema al que nos enfrentamos es la necesidad de overclockear Elasticsearch y optimizarlo para escribir, ya que la cantidad de lecturas es notablemente menor. <br><br>  Utilizamos varios par√°metros. <br><br>  <code>"ignore_malformed": true</code> : <b>descarta los campos con el tipo incorrecto y no todo el documento</b> .  Todav√≠a queremos almacenar los datos, incluso si por alguna raz√≥n los campos con una asignaci√≥n incorrecta se han filtrado all√≠.  Esta opci√≥n no est√° completamente relacionada con el rendimiento. <br><br>  Para el hierro, Elasticsearch tiene un matiz.  Cuando comenzamos a pedir grandes grupos, nos dijeron que las matrices RAID de las unidades SSD para sus vol√∫menes son terriblemente caras.  Pero las matrices no son necesarias porque la tolerancia a fallas y la partici√≥n ya est√°n integradas en Elasticsearch.  Incluso en el sitio web oficial hay una recomendaci√≥n para tomar m√°s hierro barato que menos costoso y bueno.  Esto se aplica tanto a los discos como a la cantidad de n√∫cleos de procesador, ya que Elasticsearch completo es muy similar. <br><br>  <code>"index.merge.scheduler.max_thread_count": 1</code> - <b>recomendado para HDD</b> . <br>  Si no obtuvo SSD, sino HDD normales, configure este par√°metro en uno.  Los √≠ndices se escriben en piezas, luego estas piezas se congelan.  Esto ahorra un poco de disco, pero, sobre todo, acelera la b√∫squeda.  Adem√°s, cuando deja de escribir en el √≠ndice, puede <code>force merge</code> .  Cuando la carga en el cl√∫ster es menor, se congela autom√°ticamente. <br><br>  <code>"index.unassigned.node_left.delayed_timeout": "5m"</code> : <b>retraso de la implementaci√≥n cuando desaparece un nodo</b> .  Este es el tiempo despu√©s del cual Elasticsearch comenzar√° a implementar √≠ndices y datos si un nodo se reinicia, implementa o retira para mantenimiento.  Pero si tiene una gran carga en el disco y la red, entonces la implementaci√≥n es una operaci√≥n dif√≠cil.  Para no sobrecargarlos, este tiempo de espera es mejor para controlar y comprender qu√© retrasos se necesitan. <br><br>  <code>"index.refresh_interval": -1</code> : <b>no actualice los √≠ndices si no hay consultas de b√∫squeda</b> .  Luego, el √≠ndice se actualizar√° cuando aparezca una consulta de b√∫squeda.  Este √≠ndice se puede establecer en segundos y minutos. <br><br>  <code>"index.translogDurability": "async"</code> - con qu√© frecuencia ejecutar fsync: con cada solicitud o por tiempo.  Da ganancias de rendimiento para unidades lentas. <br><br>  Tambi√©n tenemos una forma interesante de usarlo.  El soporte y los desarrolladores desean poder realizar b√∫squedas de texto completo y usar regexp'ov en todo el cuerpo del mensaje.  Pero en Elasticsearch esto no es posible: solo puede buscar por tokens que ya existen en su sistema.  Se pueden usar RegExp y comodines, pero el token no puede comenzar con algunos RegExp.  Por lo tanto, agregamos <code>word_delimiter</code> al filtro: <br><br><pre> <code class="plaintext hljs">"tokenizer": "standard" "filter" : [ "word_delimiter" ]</code> </pre> <br>  Divide autom√°ticamente las palabras en tokens: <br><br><ul><li>  "Wi-Fi" ‚Üí "Wi", "Fi"; <br></li><li>  ‚ÄúPowerShot‚Äù ‚Üí ‚ÄúPower‚Äù, ‚ÄúShot‚Äù; <br></li><li>  "SD500" ‚Üí "SD", "500". <br></li></ul><br>  De manera similar, se escribe el nombre de la clase, diversa informaci√≥n de depuraci√≥n.  Con √©l, cerramos algunos de los problemas con la b√∫squeda de texto completo.  Le aconsejo que agregue dicha configuraci√≥n cuando trabaje con el inicio de sesi√≥n. <br><br><h3>  Sobre el cluster </h3><br>  <b>El n√∫mero de fragmentos debe ser igual al n√∫mero de nodos de datos para el equilibrio de carga</b> .  El n√∫mero m√≠nimo de r√©plicas es 1, luego cada nodo tendr√° un fragmento principal y una r√©plica.  Pero si tiene datos valiosos, por ejemplo, transacciones financieras, es mejor 2 o m√°s. <br><br>  <b>El tama√±o del fragmento es de unos pocos GB a varias decenas de GB</b> .  El n√∫mero de fragmentos en un nodo no es m√°s de 20 por 1 GB de cadera Elasticsearch, por supuesto.  Adem√°s Elasticsearch se ralentiza, tambi√©n lo atacamos.  En aquellos centros de datos donde hay poco tr√°fico, los datos no giraron en volumen, aparecieron miles de √≠ndices y el sistema se bloque√≥. <br><br>  <b>Utilice el</b> <code>allocation awareness</code> , por ejemplo, por el nombre de un hipervisor en caso de servicio.  Ayuda a dispersar √≠ndices y fragmentos en diferentes hipervisores para que no se superpongan cuando un hipervisor se desconecta. <br><br>  <b>Crear √≠ndices de antemano</b> .  Buena pr√°ctica, especialmente cuando se escribe a tiempo.  El √≠ndice est√° inmediatamente caliente, listo y no hay retrasos. <br><br>  <b>Limite el n√∫mero de fragmentos de un √≠ndice por nodo</b> .  <code>"index.routing.allocation.total_shards_per_node": 4</code> es el n√∫mero m√°ximo de fragmentos de un √≠ndice por nodo.  En el caso ideal, hay 2 de ellos, ponemos 4 por si acaso, si todav√≠a tenemos menos autos. <br><br>  ¬øCu√°l es el problema aqu√≠?  Utilizamos el <code>allocation awareness</code> : Elasticsearch sabe c√≥mo distribuir correctamente los √≠ndices en los hipervisores.  Pero descubrimos que despu√©s de que el nodo se apag√≥ durante mucho tiempo, y luego vuelve al cl√∫ster, Elasticsearch ve que hay formalmente menos √≠ndices y se restauran.  Hasta que los datos est√©n sincronizados, formalmente hay pocos √≠ndices en el nodo.  Si es necesario, asigne un nuevo √≠ndice, Elasticsearch intenta martillar esta m√°quina lo m√°s densamente posible con nuevos √≠ndices.  Por lo tanto, un nodo recibe una carga no solo por el hecho de que los datos se replican, sino tambi√©n por el tr√°fico nuevo, los √≠ndices y los datos nuevos que caen en este nodo.  Controlarlo y limitarlo. <br><br><h3>  Recomendaciones de mantenimiento de Elasticsearch </h3><br>  Quienes trabajan con Elasticsearch est√°n familiarizados con estas recomendaciones. <br><blockquote>  Durante el mantenimiento programado, aplique las recomendaciones para la actualizaci√≥n continua: deshabilite la asignaci√≥n de fragmentos, el vaciado sincronizado. </blockquote>  <b>Deshabilitar la asignaci√≥n de fragmentos</b> .  Desactive la asignaci√≥n de fragmentos de r√©plicas, deje la capacidad de asignar solo primarios.  Esto ayuda notablemente a Elasticsearch: no reasignar√° datos que no necesita.  Por ejemplo, usted sabe que en media hora el nodo se elevar√°, ¬øpor qu√© transferir todos los fragmentos de un nodo a otro?  Nada terrible suceder√° si vives con el grupo amarillo durante media hora, cuando solo hay fragmentos primarios disponibles. <br><br>  <b>Rubor sincronizado</b> .  En este caso, el nodo se sincroniza mucho m√°s r√°pido cuando vuelve al cl√∫ster. <br><blockquote>  Con una gran carga al escribir en el √≠ndice o la recuperaci√≥n, puede reducir la cantidad de r√©plicas. </blockquote>  Si descarga una gran cantidad de datos, por ejemplo, carga m√°xima, puede desactivar fragmentos y luego dar un comando a Elasticsearch para crearlos cuando la carga ya es menor. <br><br>  Aqu√≠ hay algunos comandos que me gusta usar: <br><br><ul><li>  <code>GET _cat/thread_pool?v</code> : le permite ver <code>thread_pool</code> en cada nodo: lo que est√° de moda ahora, cu√°les son las colas de escritura y lectura. <br></li><li>  <code>GET _cat/recovery/?active_only=true</code> : qu√© √≠ndices se implementan en d√≥nde, d√≥nde tiene lugar la recuperaci√≥n. <br></li><li>  <code>GET _cluster/allocation/explain</code> - en una forma humana conveniente por qu√© y qu√© √≠ndices o r√©plicas no se asignaron. <br></li></ul><br>  Para el monitoreo usamos Grafana. <br><br><img src="https://habrastorage.org/webt/zg/wz/pm/zgwzpmdlzs580aaf88kv-l_rnh4.jpeg"><br><br>  Existe un excelente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">exportador</a> y miembro de equipo de Grafana de <b>Vincent van Hollebeke</b> , que le permite ver visualmente el estado del cl√∫ster y todos sus par√°metros principales.  Lo agregamos a nuestra imagen de Docker y todas las m√©tricas al implementar desde nuestra caja. <br><br><h2>  Conclusiones de registro </h2><br>  Los registros deben ser: <br><br><ul><li>  <b>centralizado</b> : un √∫nico punto de entrada para desarrolladores; <br></li><li>  <b>disponible</b> : la capacidad de buscar r√°pidamente; <br></li><li>  <b>estructurado</b> - para la extracci√≥n r√°pida y conveniente de informaci√≥n valiosa; <br></li><li>  <b>correlacionado</b> , no solo entre ellos, sino tambi√©n con otras m√©tricas y sistemas que utiliza. <br></li></ul><br>  El concurso sueco <b>Melodifestivalen</b> se ha celebrado recientemente.  Esta es una selecci√≥n de representantes de Suecia para Eurovisi√≥n.  Antes de la competencia, nuestro servicio de soporte nos contact√≥: ‚ÄúAhora en Suecia habr√° una gran carga.  El tr√°fico es bastante sensible y queremos correlacionar algunos datos.  Tiene datos en los registros que faltan en el panel de Grafana.  Tenemos m√©tricas que se pueden tomar de Prometheus, pero necesitamos datos sobre solicitudes de identificaci√≥n espec√≠ficas ". <br><br>  Agregaron Elasticsearch como la fuente de Grafana y pudieron correlacionar estos datos, cerrar el problema y obtener buenos resultados lo suficientemente r√°pido. <br><blockquote>  Explotar sus propias soluciones es mucho m√°s f√°cil. </blockquote>  Ahora, en lugar de los 10 cl√∫steres de Graylog que funcionaron para esta soluci√≥n, tenemos varios servicios.  Estos son 10 centros de datos, pero ni siquiera tenemos un equipo dedicado y personas que los atiendan.  Hay varias personas que trabajaron en ellos y cambian algo seg√∫n sea necesario.  Este peque√±o equipo est√° perfectamente integrado en nuestra infraestructura: la implementaci√≥n y el mantenimiento son m√°s f√°ciles y econ√≥micos. <br><blockquote>  Separe los casos y use las herramientas apropiadas. </blockquote>  Estas son herramientas separadas para el registro, rastreo y monitoreo.  No existe un "instrumento de oro" que cubra todas sus necesidades. <br><br>  Para comprender qu√© herramienta se necesita, qu√© monitorear, qu√© registros usar, qu√© requisitos de registro, definitivamente debe consultar <b>SLI / SLO</b> - Indicador de nivel de servicio / Objetivo de nivel de servicio.  Necesita saber qu√© es importante para sus clientes y su negocio, qu√© indicadores observan. <br><br><blockquote>  Una semana despu√©s, SKOLKOVO presentar√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HighLoad ++ 2019</a> .  En la noche del 7 de noviembre, Ivan Letenko <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">le contar√°</a> c√≥mo vive con Redis en la producci√≥n, y en total hay 150 informes en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">programa</a> sobre diversos temas. <br><br>  Si tiene problemas para visitar HighLoad ++ 2019 en vivo, tenemos buenas noticias.  Este a√±o, la conferencia se llevar√° a cabo en tres ciudades a la vez: en Mosc√∫, Novosibirsk y San Petersburgo.  Al mismo tiempo  C√≥mo ser√° y c√≥mo llegar all√≠: inf√≥rmese en una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">p√°gina de promoci√≥n</a> separada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">del</a> evento. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/473946/">https://habr.com/ru/post/473946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../473932/index.html">¬øC√≥mo funciona una IA de juegos h√≠bridos y cu√°les son sus ventajas?</a></li>
<li><a href="../473936/index.html">Rendimiento de audio interactivo: una nueva era de juegos de asistente de voz</a></li>
<li><a href="../473938/index.html">Almacene universalmente la configuraci√≥n de las aplicaciones a trav√©s de IConfiguration</a></li>
<li><a href="../473940/index.html">Prueba de resistencia: nanomec√°nica de n√°car c√°scara noble pinna</a></li>
<li><a href="../473944/index.html">Consejos del creador de RimWorld: distorsiones cognitivas al predecir un fan√°tico del juego</a></li>
<li><a href="../473948/index.html">Operon: Acelera el rendimiento de Ansible</a></li>
<li><a href="../473950/index.html">Implementar, escalar: la experiencia de usar autotests en VTB</a></li>
<li><a href="../473952/index.html">Mientras escrib√≠a AI para la estrategia por turnos</a></li>
<li><a href="../473956/index.html">Informaci√≥n secreta de una compa√±√≠a telef√≥nica de traficantes de drogas</a></li>
<li><a href="../473958/index.html">Japoneses de NICT introdujeron un cluster de fibra funcional con un ancho de banda de 1 Pbit / s</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
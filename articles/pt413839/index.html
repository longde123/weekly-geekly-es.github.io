<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👗 👋🏻 🙇🏻 AI, curso prático. Coleta e pesquisa de imagens 💟 🐅 🔞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este artigo discute os métodos usados ​​para coletar dados de imagem em um projeto de música com uma apresentação de slides. Houve limitações que nos ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso prático. Coleta e pesquisa de imagens</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/413839/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/_j/dr/q0/_jdrq0ffcxcf86rbei-wxierd5u.jpeg"></div><br>  Este artigo discute os métodos usados ​​para coletar dados de imagem em um projeto de música com uma apresentação de slides.  Houve limitações que nos forçaram a usar o banco de dados existente de imagens, em vez de imagens tiradas do Flickr.  No entanto, este artigo discute as duas abordagens para que o leitor possa aprender como extrair dados usando a API do Flickr. <br><br>  Além disso, como a qualidade de uma parte significativa das imagens coletadas com o Flickr era baixa, decidiu-se usar imagens de bancos de dados de imagens existentes.  Em particular, foram coletadas imagens de três bancos de dados para pesquisa psicológica. <br><a name="habracut"></a><br>  Lembre-se de que inicialmente os seguintes conjuntos de dados foram selecionados para este projeto: <br><br><ol><li>  Um conjunto de dados de treinamento contendo 7000 imagens emocionalmente coloridas do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Flickr</a> para um algoritmo de extração de emoções. </li><li>  Um conjunto de dados de treinamento contendo as obras de Bach para o algoritmo de conclusão da melodia. </li><li>  Um conjunto de músicas que servem como modelos para modular emoções. </li></ol><br>  Agora você precisa coletar os conjuntos de dados.  Como será mostrado no artigo, a quantidade de trabalho necessária para isso varia significativamente, dependendo do conjunto de dados selecionado. <br><br><h2>  <font color="#0071c5">Captura de imagem</font> </h2><br>  Esse projeto exigia um conjunto de imagens que evocavam sete emoções diferentes: felicidade, tristeza, medo, ansiedade, reverência, determinação, raiva.  Para a coleta de imagens, foi decidido usar o Flickr, um site popular de compartilhamento de fotos, devido ao seu tamanho e licenciamento pelo Creative Commons *. <br><br>  A pesquisa manual de 7000 imagens no Flickr é uma tarefa assustadora.  Felizmente, o Flickr possui uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">API</a> que fornece um conjunto de métodos que facilitam a troca de dados com o Flickr em uma linguagem de programação.  No entanto, antes de usar a API para coletar imagens, é importante saber o que procurar para evocar emoções relevantes.  Para determinar a lista de termos de pesquisa, uma tarefa foi usada na plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Amazon Mechanical Turk</a> *. <br><br><h3>  <font color="#0071c5">API do Flickr</font> </h3><br>  Para usar os métodos oferecidos pela API do Flickr, você precisará criar uma conta do Flickr e solicitar uma chave da API.  Para fazer isso, você deve ter uma conta no Flickr ou no Yahoo! *.  Em seguida, você precisa seguir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este link</a> e obter a chave. <br><br><img src="https://habrastorage.org/webt/uh/q3/0k/uhq30kznjns9goydmrjwufzdwl0.png"><br>  <i>Captura de tela de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.flickr.com/services/apps/create/apply</a></i> <br><br>  O processo de processamento de um aplicativo para uma chave não comercial é bastante simples.  Inclui uma descrição do uso pretendido e a aceitação dos termos de uso.  A chave da API é uma medida de segurança e é usada para evitar o uso indevido da API.  Nos métodos fornecidos pela API, é um parâmetro necessário. <br><br>  Depois de receber a chave da API, você pode baixar e instalar o kit de ferramentas da API para uma das linguagens de programação do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">App Garden</a> .  Este projeto usa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a API PythonI Flickr da Beej</a> , que pode ser usada com a linguagem Python 3. Você deve seguir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o guia de instalação da</a> API Flickr. <br><br>  O código usado para baixar as imagens é mostrado abaixo.  Basicamente, a função de passeio da API é usada aqui, que procura uma imagem por tag.  As tags são armazenadas em um arquivo .txt e são listadas uma por linha.  Se uma imagem for encontrada, seu URL será criado a partir do modelo no <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">farm</a> {id da fazenda} .staticflickr.com / {server-id} / {id} _ {secret} .jpg</i> , em que o conteúdo dos chavetas é substituído pelos atributos da imagem.  Em seguida, as 30 principais imagens de cada tag (classificadas por relevância) são extraídas e organizadas em pastas, dependendo da emoção e das condições de pesquisa. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> flickrapi <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> urllib.request <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os project_path = <span class="hljs-string"><span class="hljs-string">'/path/to/your/project'</span></span> photos_per_tag = <span class="hljs-number"><span class="hljs-number">30</span></span> filenames = [<span class="hljs-string"><span class="hljs-string">'Awe.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Happiness.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Fear.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Determination.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Anxiety.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Tranquility.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Sadness.txt'</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">download_files</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(flickr, t, category, num_photos)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Downloads the files of a specific tag os.mkdir(t) os.chdir(t) s = [] for photo in flickr.walk(tag_mode='all', sort='relevance', tags=t, license=4, per_page=50): url = 'https://farm{}.staticflickr.com/{}/{}_{}.jpg'.format(photo.get('farm'), photo.get('server'), photo.get('id'), photo.get('secret')) s.append(url) if len(s) == num_photos: break for i in range(len(s)): filename = '{}_{}_{}.jpg'.format(category, t, str(i)) urllib.request.urlretrieve(s[i], filename) os.chdir(os.path.join(project_path, category)) if __name__ == '__main__': # Creates flickr object # These keys should be requested from flickr api_key = u'xxxxxxxxxxxx' api_secret = u'xxxxxxxxxxx' flickr = flickrapi.FlickrAPI(api_key, api_secret) # Runs the program, cycles through the emotions and downloads the images for each tag. os.chdir(project_path) for fname in filenames: categ = fname[:-4] with open(fname, 'r') as f: tags = f.read().splitlines() os.mkdir(categ) os.chdir(categ) for t in tags: download_files(flickr, t, categ, photos_per_tag) os.chdir(project_path)</span></span></code> </pre> <br>  Para usar esse código, você precisa clonar o repositório usando o link do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GitHub</a> .  Depois disso, siga as instruções no arquivo LEIA-ME.  Você deve substituir os parâmetros api_key e api_secret pelas chaves de API recebidas no Flickr.  Como mencionado acima, esse script funciona apenas no Python 3. <br><br>  Após a execução do programa, a pasta fica assim: <br><br><img src="https://habrastorage.org/webt/d6/vg/4u/d6vg4uz-dqluh8gznempvdzwxrk.png"><br><br><img src="https://habrastorage.org/webt/db/n5/l_/dbn5l_zbd8-w-zjvkjyyelpumz8.jpeg"><br>  <i>Um conjunto de dados dos resultados da pesquisa no Flickr.</i> <br><br>  No total, foram coletadas cerca de 8800 imagens.  Foram recebidas mais imagens do que o necessário, pois planejávamos descartar algumas das imagens de baixa qualidade que não podem ser usadas.  O próximo passo foi procurar essas imagens. <br><br><h3>  <font color="#0071c5">Seleção de imagem</font> </h3><br>  A qualidade das imagens coletadas foi diferente.  Algumas condições de pesquisa, por exemplo, flores (mostradas na figura) forneceram imagens utilizáveis ​​de alta qualidade.  No entanto, condições de pesquisa menos específicas geralmente produzem imagens completamente inutilizáveis.  Por exemplo, uma imagem de um bolo com uma mulher maravilha * foi obtida a partir da etiqueta milagrosa (devido à emoção de reverência) e uma imagem de repolho da Ambitious Farms foi encontrada a partir da etiqueta ambiciosa (devido à emoção de determinação). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xk/ia/0k/xkia0kxzikvgjlowgyg8b6_bemo.jpeg"></div><br>  <i>Imagens inadequadas.</i> <br><br>  Qualquer pessoa que planeja usar a API do Flickr para pesquisar imagens é incentivada a usar substantivos específicos como termos de pesquisa.  As imagens encontradas a partir deles são muito melhores do que usar adjetivos ou substantivos abstratos.  Por exemplo, ao pesquisar imagens de admiração, você deve usar termos de pesquisa como o oceano ou o Grand Canyon, em vez de admiração ou milagre. <br><br>  Após visualizar as imagens, a equipe concluiu que mais de 40% das imagens eram inutilizáveis.  Como resultado, a abordagem para selecionar um conjunto de dados foi revisada.  Depois de discutir várias possibilidades, como limitar o conjunto de imagens a rostos com emoções relevantes, decidiu-se usar imagens de bancos de dados existentes que são comumente usados ​​em pesquisas psicológicas (Geneva Affective PicturE Database ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GAPED</a> ), Open Affective Standardized Image Set ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OASIS</a> ) e Image Estímulos para Elicitação das Emoções ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ISEE</a> )). <br><br>  Apesar de as imagens nos bancos de dados existentes serem menos diversas do que poderiam ser no novo conjunto de dados, a escolha foi feita em favor dos bancos de dados existentes devido à maior qualidade da imagem e à disponibilidade de informações sobre os parâmetros.  Ter informações sobre os parâmetros é uma enorme vantagem, pois elimina a necessidade de anotação usando o Amazon Mechanical Turk, o que reduz significativamente o custo. <br><br><h3>  <font color="#0071c5">Fonte de dados</font> </h3><br>  O processo de coleta de dados para o novo conjunto de dados foi muito mais simples.  Em particular, as etapas não eram mais necessárias com o Amazon Mechanical Turk e a API do Flickr.  Os conjuntos de dados GAPED e OASIS (incluindo marcação de parâmetro) estão disponíveis para download na Internet.  O conjunto de dados ISEE ficou disponível após um email para o autor solicitando acesso.  Se as instruções para o download dos conjuntos de dados não forem bem compreendidas, provavelmente uma pesquisa no Google * ajudará a encontrar contatos de autores que podem solicitar diretamente o acesso aos conjuntos de dados. <br><br>  Dois conjuntos de dados foram criados para este projeto.  O primeiro usou a API do Flickr para carregar imagens usando tags de emoção, o segundo foi uma compilação de bancos de dados existentes usados ​​em pesquisas psicológicas.  Cada um desses conjuntos de dados tem seus prós e contras;  no entanto, o segundo foi escolhido para o projeto - graças a vantagens como qualidade de imagem, presença de parâmetros e custo rotulados. <br><br>  O método usado para coletar dados diretamente depende de quais dados são necessários.  No entanto, os processos e métodos descritos neste artigo provavelmente serão úteis para muitos projetos. <br><br>  Agora que os conjuntos de dados foram criados, o projeto está pronto para executar as seguintes etapas - pesquisa e processamento preliminar de dados. <br><br><h2>  <font color="#0071c5">Exploração de dados de imagem</font> </h2><br>  Como a qualidade de uma parte significativa das imagens coletadas com o Flickr era baixa, decidiu-se usar imagens de bancos de dados de imagens existentes.  Em particular, foram coletadas imagens de três bancos de dados para pesquisa psicológica.  Cada imagem inclui informações de classificação para (des) agradabilidade e intensidade, coletadas de vários artistas.  1986 imagens dessas bases de dados foram divididas em 4 categorias.  Essas categorias cobriram 87% das imagens e incluíram 34% dos animais, 28% das pessoas, 13% das cenas e 12% dos objetos.  Os 13% restantes foram classificados como diversos. <br><br><h3>  <font color="#0071c5">Animais</font> </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_j/dr/q0/_jdrq0ffcxcf86rbei-wxierd5u.jpeg"></div><br>  <i>Exemplos de imagens da categoria "Animais"</i> <br><br>  Cerca de um terço das imagens contém animais - isolados ou em conjunto com outros animais, como mostrado acima.  Nesses exemplos, movendo-se da esquerda para a direita, a classificação de agradabilidade aumenta.  Imagens desagradáveis ​​de hienas comendo presas e baratas podem causar uma reação na forma de emoções como: medo, tristeza e nojo. <br><br>  As imagens à direita - um gato adormecido, um cachorro sorridente - pelo contrário, podem causar simpatia e felicidade. <br><br><h3>  <font color="#0071c5">Pessoas</font> </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z6/kd/vf/z6kdvfa0yknvuqh3_sdboqobqa8.jpeg"></div><br>  <i>Amostras de imagens da categoria Pessoas</i> <br><br>  A categoria Pessoas de imagens inclui imagens de indivíduos e grupos de pessoas, enquanto imagens de grupos de pessoas geralmente contêm mais informações contextuais.  Por exemplo, a imagem da banda parece ter sido filmada no cenário de um estádio cheio de fãs, sugerindo que a imagem seja filmada em uma performance durante esportes.  A imagem de uma mulher irritada, pelo contrário, é privada de contexto - o espectador não tem a oportunidade de descobrir ou adivinhar o motivo de sua raiva.  Note-se que nem todas as imagens com muitas pessoas ou grupos têm informações adicionais. <br><br>  Por exemplo, a imagem de homens deitados em uma linha no chão, com feridas visíveis e roupas ensangüentadas, não dá uma idéia do que está acontecendo.  No entanto, mesmo com essa falta de informação, imagens com pessoas causam várias reações emocionais. <br><br><h3>  <font color="#0071c5">Cenas</font> </h3><br>  A categoria “Cenas” de um conjunto de imagens inclui uma variedade de cenas - de estruturas e objetos feitos pelo homem a cenas da natureza e até de espaço. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ho/2v/tt/ho2vttl3iuauwnr94ce8uivrwdw.jpeg"></div><br>  <i>Imagens de exemplo da categoria Cenas</i> <br><br><h3>  <font color="#0071c5">Os objetos</font> </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vl/5_/bk/vl5_bkiof6y8puazjhku6d9yfuy.jpeg"></div><br>  <i>Amostras de imagens da categoria Objetos</i> <br><br>  A categoria "Objetos" do conjunto de imagens inclui imagens focadas em um objeto, como mostrado nos exemplos acima.  Não há contexto situacional nessas imagens, especialmente quando comparado com outras categorias no conjunto de imagens. <br><br><h3>  <font color="#0071c5">Diversos</font> </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/md/qf/1g/mdqf1gyo2nw5sdu4oo2vyhbyxfm.jpeg"></div><br>  <i>Exemplos de imagens da categoria Diversos</i> <br><br>  Finalmente, um subconjunto de imagens permaneceu no conjunto que não pôde ser atribuído a nenhuma das quatro categorias.  Freqüentemente, como mostrado nos exemplos, essas imagens eram cenas com vários objetos, mas sem o contexto típico para imagens da categoria Cenas.  Como regra, esse tipo de imagem continha uma classificação neutra - não eram agradáveis ​​nem desagradáveis. <br><br><h2>  <font color="#0071c5">Categorias de emoção para o banco de dados de imagens</font> </h2><br>  Para identificar as categorias de emoções do banco de dados de imagens, contamos com classificações normativas de significância subjetiva que acompanham cada imagem no Geneva Affective PicturE Database (GAPED) e no Open Affective Standardized Image Set (OASIS).  Como o GAPED usou a escala Likert de 0 a 100 e o OASIS usou a escala Likert de 1 a 7, foi aplicada uma transformação linear que levou todas as classificações a uma escala contínua de 0 a 100. Em seguida, foram investigadas duas regras em potencial para categorizar emoções. <br><br>  Primeiro, é intuitivamente desejável classificar as imagens de acordo com o nível de agradabilidade, seguido pela divisão em três partes de acordo com a escala de classificação, para que imagens com classificações de 0 a 33,33 representem a categoria negativa, com classificações de 33,33 a 66,67, neutras e com classificações 66,67–100 - uma categoria positiva.  Para implementar essa regra de dividir em três categorias, o código Python foi usado: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">organizeFolderGAPED</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(original, pos, neg, neut)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#      GAPED    #        dict = {} files = os.listdir(original) for file in files: if '.txt' in file: with open(os.path.join(original, file), 'r') as f: for l in f: l = l.split() dict[l[0][:-4]] = l[1] #        pos/neg/neut      for roots, dirs, files, in os.walk(original): for file in files: if '.bmp' in file: if float(dict[file[:-4]]) &lt; 100/3: shutil.copy(os.path.join(roots, file), neg) elif float(dict[file[:-4]]) &gt; 200/3: shutil.copy(os.path.join(roots, file), pos) else: shutil.copy(os.path.join(roots, file), neut) def organizeFolderOASIS(original, pos, neg, neut): #      GAPED    #        dict = {} with open('/Users/harrys/Desktop/OASIS.csv') as file: reader = csv.reader(file) for row in reader: dict[row[1]] = row[4] #        pos/neg/neut       for roots, dirs, files, in os.walk(original): for file in files: if '.jpg' in file: if (float(dict[file[:-4]])-1)*100/6 &lt; 100/3: shutil.copy(os.path.join(roots, file), neg) elif (float(dict[file[:-4]])-1)*100/6 &gt; 200/3: shutil.copy(os.path.join(roots, file), pos) else: shutil.copy(os.path.join(roots, file), neut) if __name__ == '__main__' : gaped = 'path/to/your/project/directory/GAPED' oasis = 'path/to/your/project/directory/Oasis' pos = 'path/to/your/project/directory/Positive' neg = 'path/to/your/project/directory/Negative' neut = 'path/to/your/project/directory/Neutral' organizeFolderOASIS(oasis, pos, neg, neut) organizeFolderGAPED(gaped, pos, neg, neut)</span></span></code> </pre><br>  Essa abordagem nos permitiu dividir o banco de dados em categorias: 417 imagens negativas, 774 neutras e 442 positivas.  Nessa abordagem, a divisão em três categorias em proporções iguais de imagens desagradáveis, cuja classificação não atingiu o valor limite, foi classificada como neutra;  por exemplo, imagens de um cadáver, uma criança chorando, cemitérios foram classificados como neutros.  Embora essas imagens fossem menos desagradáveis ​​do que outras na categoria negativa, surgiram dúvidas sobre sua neutralidade. <br><br>  Portanto, decidiu-se aplicar uma regra de categorização otimizada com base na distribuição normal dos dados, além de melhorar a separação de parâmetros em categorias emocionais.  Os valores de 0 a 39 foram atribuídos à categoria negativa, 40 a 60 à categoria neutra e 61 a 100 à categoria positiva.  Para implementar esta regra, o código Python foi usado: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">organizeFolderGAPED</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(original, pos, neg, neut)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#      GAPED    #        dict = {} files = os.listdir(original) for file in files: if '.txt' in file: with open(os.path.join(original, file), 'r') as f: for l in f: l = l.split() dict[l[0][:-4]] = l[1] #        pos/neg/neut      for roots, dirs, files, in os.walk(original): for file in files: if '.bmp' in file: if float(dict[file[:-4]]) &lt; 40: shutil.copy(os.path.join(roots, file), neg) elif float(dict[file[:-4]]) &gt; 60: shutil.copy(os.path.join(roots, file), pos) else: shutil.copy(os.path.join(roots, file), neut) def organizeFolderOASIS(original, pos, neg, neut): #      GAPED    #        dict = {} with open('path/to/your/project/directory/OASIS.csv') as file: reader = csv.reader(file) for row in reader: dict[row[1]] = row[4] #        pos/neg/neut       for roots, dirs, files, in os.walk(original): for file in files: if '.jpg' in file: if (float(dict[file[:-4]])-1)*100/6 &lt; 40: shutil.copy(os.path.join(roots, file), neg) elif (float(dict[file[:-4]])-1)*100/6 &gt; 60: shutil.copy(os.path.join(roots, file), pos) else: shutil.copy(os.path.join(roots, file), neut) if __name__ == '__main__' : gaped = 'path/to/your/project/directory/GAPED' oasis = 'path/to/your/project/directory/Oasis' pos = 'path/to/your/project/directory/Positive' neg = 'path/to/your/project/directory/Negative' neut = 'path/to/your/project/directory/Neutral' organizeFolderOASIS(oasis, pos, neg, neut) organizeFolderGAPED(gaped, pos, neg, neut)</span></span></code> </pre><br>  Com essa regra de categorização, 40-60–40 567 imagens positivas foram classificadas como mais agradáveis ​​que 502 neutras e 564 imagens negativas foram classificadas como menos agradáveis ​​que neutras.  Assim, o valor alvo das categorias emocionais foi mantido e a distribuição das imagens por categoria foi melhorada.  A figura abaixo ilustra o nível de prazer associado a cada uma das categorias.  Os diferentes comprimentos dos bigodes no diagrama de dispersão indicam em qual categoria emocional (positiva ou negativa) há uma faixa maior de classificações em comparação à categoria neutra. <br><br><img src="https://habrastorage.org/webt/yx/3f/sv/yx3fsvbh9cpl_jyfz4_1j9xf-io.jpeg"><br>  <i>Classificações médias de prazer para cada uma das categorias emocionais</i> <br><br>  Concluímos que essa regra de categorização é suficiente para classificar imagens com base em emoções.  Em relação às categorias de parâmetros do banco de dados de imagens, os tipos de imagens que representam cada uma das categorias emocionais são mostrados abaixo.  Note-se que cada categoria de parâmetros (animais, pessoas, cenas, objetos, diversos) é representada em cada uma das categorias emocionais. <br><br>  <i>Categoria emocional 1: Negativo</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wg/mo/xx/wgmoxxsmn1b8zp5sbsapzfpgsxi.jpeg"></div><br>  <i>Categoria emocional 2: Neutro</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/dv/8a/rzdv8a89hkcqc5gbrtqt8k_yc-q.jpeg"></div><br>  <i>Categoria Emocional 3: Positiva</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fx/u2/ot/fxu2otvmennaundgxobtgb-empq.jpeg"></div><br>  Para resumir.  Dividimos o banco de dados de imagens em categorias emocionais neutras, negativas e positivas, usando classificações de significância normativa no intervalo de 0 a 100, atribuindo 0-39 a negativo, 40-60 a neutro e 61 a 100 a positivo.  As imagens foram distribuídas adequadamente nessas categorias emocionais.  Finalmente, cada categoria emocional incluía imagens de animais, pessoas, cenas, objetos e muito mais. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt413839/">https://habr.com/ru/post/pt413839/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt413819/index.html">Honestamente sobre o mercado de TI na Rússia</a></li>
<li><a href="../pt413823/index.html">O boom do emprego sem sentido</a></li>
<li><a href="../pt413827/index.html">Projeto Kubernetes faz 4 anos</a></li>
<li><a href="../pt413831/index.html">A nova versão do Tesla Autopilot será lançada em agosto, pela primeira vez com "recursos de direção totalmente autônomos"</a></li>
<li><a href="../pt413837/index.html">Fazendo da Defesa da Torre um Jogo de Unidade - Parte 1</a></li>
<li><a href="../pt413841/index.html">Alternativas aos produtos do Google</a></li>
<li><a href="../pt413843/index.html">Waymo à frente do resto: os robomobiles da empresa rodaram 11 milhões de quilômetros</a></li>
<li><a href="../pt413847/index.html">Monumento de gatilho "vivo"</a></li>
<li><a href="../pt413849/index.html">História da marca Sennheiser: liberdade e visão</a></li>
<li><a href="../pt413851/index.html">Esteganografia em pacotes IP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
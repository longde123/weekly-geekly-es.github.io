<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöÆ üê£ üë©üèø‚Äçü§ù‚Äçüë©üèæ Mask-R CNN do iniciante ao profissional üëÅÔ∏è üïí ‚Ü™Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Uma vez que eu precisava analisar as informa√ß√µes da imagem e na sa√≠da para ter o tipo do objeto, seu tipo e tamb√©m analisar a totalidade dos quadros, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mask-R CNN do iniciante ao profissional</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483018/"><p><img src="https://lh6.googleusercontent.com/2ZHVaccuXIFgG1Z5qnHROW6cKyxjEe1RLo0SwRAaOxxyQI7Q_Ymbs7ZuZ6bOs56v7oMaCInsarFjOPZRDWL5hNdKpVhlVtHINo9u3gae4utQB-FARZPFxEV5UmkYY8LVJdTjZ0PK"></p><br><p> Uma vez que eu precisava analisar as informa√ß√µes da imagem e na sa√≠da para ter o tipo do objeto, seu tipo e tamb√©m analisar a totalidade dos quadros, precisava fornecer o identificador do objeto e o tempo gasto no quadro, era necess√°rio determinar como o objeto estava se movendo e quais c√¢meras foram exibidas.  Vamos come√ßar, talvez, com os dois primeiros, a an√°lise do pessoal no conjunto ser√° discutida na pr√≥xima parte. </p><a name="habracut"></a><br><p>  Bem, descreveremos com mais detalhes nossas tarefas: </p><br><ul><li>  Corrija pessoas e carros - selecione-os na imagem e gere as inst√¢ncias de classe correspondentes com os campos necess√°rios. </li><li>  Determine o n√∫mero do carro, se ele cair no quadro de uma c√¢mera espec√≠fica </li><li>  Compare o quadro atual com o anterior para igualdade de objetos, para que possamos descobrir </li></ul><br><p>  Ok, pensei, e peguei uma cobra grossa, python, isso significa.  Decidiu-se usar a rede neural <a href="https://github.com/matterport/Mask_RCNN">Mask R-Cnn</a> em conex√£o com sua simplicidade e <a href="https://habr.com/ru/post/421299/">recursos modernos</a> .  Al√©m disso, √© claro, usaremos o OpenCV para manipula√ß√£o de imagens. </p><br><h2 id="ustanovka-sredy">  Configura√ß√£o do ambiente </h2><br><p>  Usaremos o Windows 10, porque √© mais prov√°vel que voc√™ o use. <br>  Entende-se que voc√™ j√° possui Python de 64 bits.  Caso contr√°rio, voc√™ pode fazer o download do pacote, por exemplo, <a href="https://www.python.org/downloads/release/python-374/">aqui</a> </p><br><h3 id="ustanovka-paketov">  Instala√ß√£o do pacote </h3><br><pre><code class="plaintext hljs">git clone https://github.com/matterport/Mask_RCNN cd Mask_RCNN pip3 install -r requirements.txt python3 setup.py install</code> </pre> <br><p>  Se, por algum motivo, n√£o for poss√≠vel compilar a partir do c√≥digo-fonte, existe uma vers√£o do pip: </p><br><pre> <code class="plaintext hljs">pip3 install mrcnn --user</code> </pre> <br><p>  O pacote, √© claro, vem com todas as <a href="https://github.com/matterport/Mask_RCNN/blob/master/requirements.txt">depend√™ncias</a> . </p><br><h2 id="etap-1-sozdanie-prosteyshey-programmy-raspoznavatelya">  Etapa 1. Criando um reconhecedor simples. </h2><br><p>  Faremos as importa√ß√µes necess√°rias </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN</code> </pre> <br><p>  A rede neural requer a cria√ß√£o de uma configura√ß√£o com campos substitu√≠dos </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MaskRCNNConfig</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(mrcnn.config.Config)</span></span></span><span class="hljs-class">:</span></span> NAME = <span class="hljs-string"><span class="hljs-string">"coco_pretrained_model_config"</span></span> GPU_COUNT = <span class="hljs-number"><span class="hljs-number">1</span></span> IMAGES_PER_GPU = <span class="hljs-number"><span class="hljs-number">1</span></span> DETECTION_MIN_CONFIDENCE = <span class="hljs-number"><span class="hljs-number">0.8</span></span> <span class="hljs-comment"><span class="hljs-comment">#     NUM_CLASSES = 81</span></span></code> </pre> <br><p>  Indique a localiza√ß√£o do arquivo com as balan√ßas.  Deixe neste exemplo, ele estar√° na pasta com este arquivo.  Caso contr√°rio, ele ser√° baixado. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils DATASET_FILE = <span class="hljs-string"><span class="hljs-string">"mask_rcnn_coco.h5"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(DATASET_FILE): mrcnn.utils.download_trained_weights(DATASET_FILE)</code> </pre> <br><p>  Vamos criar nosso modelo com as configura√ß√µes acima </p><br><pre> <code class="python hljs">model = MaskRCNN(mode=<span class="hljs-string"><span class="hljs-string">"inference"</span></span>, model_dir=<span class="hljs-string"><span class="hljs-string">"logs"</span></span>, config=MaskRCNNConfig()) model.load_weights(DATASET_FILE, by_name=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  E talvez come√ßaremos a processar todas as imagens no diret√≥rio <code>images</code> no diret√≥rio atual. </p><br><pre> <code class="python hljs">IMAGE_DIR = os.path.join(os.getcwd(), <span class="hljs-string"><span class="hljs-string">"images"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.listdir(IMAGE_DIR): image = cv2.imread(os.path.join(IMAGE_DIR, filename)) rgb_image = image[:, :, ::<span class="hljs-number"><span class="hljs-number">-1</span></span>] detections = model.detect([rgb_image], verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  O que veremos nas detec√ß√µes? </p><br><pre> <code class="python hljs"> print(detections)</code> </pre> <br><p>  Por exemplo, algo semelhante: </p><br><pre> <code class="plaintext hljs">{'rois': array([[ 303, 649, 542, 1176],[ 405, 2, 701, 319]]), 'class_ids': array([3, 3]), 'scores': array([0.99896, 0.99770015], dtype=float32), 'masks': array()}</code> </pre> <br><p>  Nesse caso, 2 objetos foram encontrados. <br>  <code>rois</code> - matrizes de coordenadas do canto inferior esquerdo e superior direito <br>  <code>class_ids</code> s√£o os identificadores num√©ricos dos objetos encontrados, enquanto precisamos saber que 1 √© uma pessoa, 3 √© um carro, 8 √© um caminh√£o. <br>  <code>scores</code> - desde que o modelo esteja confiante na solu√ß√£o, esse par√¢metro pode ser <code>DETECTION_MIN_CONFIDENCE</code> atrav√©s de <code>DETECTION_MIN_CONFIDENCE</code> na configura√ß√£o, cortando todas as op√ß√µes inadequadas. <br>  <code>masks</code> - o contorno do objeto.  Os dados s√£o usados ‚Äã‚Äãpara desenhar uma m√°scara de objeto.  Porque  s√£o bastante volumosos e n√£o se destinam √† compreens√£o humana; n√£o os citarei no artigo. </p><br><p>  Ok, poder√≠amos parar por a√≠, mas queremos ver a imagem que orienta o uso de redes neurais com objetos lindamente selecionados, geralmente s√£o exibidos? </p><br><p>  Seria mais simples chamar a fun√ß√£o <code>mrcnn.visualize.display_instances</code> , mas n√£o faremos isso, escreveremos os nossos. </p><br><p>  A fun√ß√£o ir√° capturar uma imagem e os principais par√¢metros obtidos no dicion√°rio desde os primeiros passos. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">visualize_detections</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image, masks, boxes, class_ids, scores)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np bgr_image = image[:, :, ::<span class="hljs-number"><span class="hljs-number">-1</span></span>] CLASS_NAMES = [<span class="hljs-string"><span class="hljs-string">'BG'</span></span>,<span class="hljs-string"><span class="hljs-string">"person"</span></span>, <span class="hljs-string"><span class="hljs-string">"bicycle"</span></span>, <span class="hljs-string"><span class="hljs-string">"car"</span></span>, <span class="hljs-string"><span class="hljs-string">"motorcycle"</span></span>, <span class="hljs-string"><span class="hljs-string">"bus"</span></span>, <span class="hljs-string"><span class="hljs-string">"truck"</span></span>] COLORS = mrcnn.visualize.random_colors(len(CLASS_NAMES)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(boxes.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]): y1, x1, y2, x2 = boxes[i] classID = class_ids[i] label = CLASS_NAMES[classID] font = cv2.FONT_HERSHEY_DUPLEX color = [int(c) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> np.array(COLORS[classID]) * <span class="hljs-number"><span class="hljs-number">255</span></span>] text = <span class="hljs-string"><span class="hljs-string">"{}: {:.3f}"</span></span>.format(label, scores[i]) size = <span class="hljs-number"><span class="hljs-number">0.8</span></span> width = <span class="hljs-number"><span class="hljs-number">2</span></span> cv2.rectangle(bgr_image, (x1, y1), (x2, y2), color, width) cv2.putText(bgr_image, text, (x1, y1<span class="hljs-number"><span class="hljs-number">-20</span></span>), font, size, color, width)</code> </pre><br><p><img src="https://lh3.googleusercontent.com/dnSAiGZW32zMK92_T8yyk2nXCFCKECQ_eSdNiVv5Bzpz9TOsBZT6_jyAY-LfUT4c0jCzfdgFOCpy6_0HzT54CAPo3vvkZ6VgR1U5cdmSTb0zLLpAxJjX-_pTNUnpIExXsao_u29b"></p><br><div class="spoiler">  <b class="spoiler_title">Imagem de origem</b> <div class="spoiler_text"><p><img src="https://sun9-10.userapi.com/c854324/v854324789/e2f73/nJHcTGLnWI4.jpg"></p></div></div><br><p>  Embora uma das principais vantagens dessa rede neural seja a solu√ß√£o para os problemas de segmenta√ß√£o de inst√¢ncias - obtendo os contornos dos objetos, ainda n√£o a usamos, vamos analis√°-la. </p><br><p>  Para implementar m√°scaras, adicione algumas linhas antes de desenhar um ret√¢ngulo para cada objeto encontrado. </p><br><pre> <code class="python hljs">mask = masks[:, :, i] <span class="hljs-comment"><span class="hljs-comment">#   image = mrcnn.visualize.apply_mask(image, mask, color, alpha=0.6) #  </span></span></code> </pre> <br><p>  Resultado: <br><img src="https://lh6.googleusercontent.com/2ZHVaccuXIFgG1Z5qnHROW6cKyxjEe1RLo0SwRAaOxxyQI7Q_Ymbs7ZuZ6bOs56v7oMaCInsarFjOPZRDWL5hNdKpVhlVtHINo9u3gae4utQB-FARZPFxEV5UmkYY8LVJdTjZ0PK"></p><br><div class="spoiler">  <b class="spoiler_title">Vers√£o com m√°scaras brancas</b> <div class="spoiler_text"><p><img src="https://lh5.googleusercontent.com/JUUlUQfOCc9jeeuzMDiSc2Hd06P2aMVli2UPSRkUoxlNVwdlwEfi-BHmuyzOsx-nlvm19lPmYlyxFGYV9xGzpppXRORmDBLtLYH6UcYRh1zO47ROLb04HgUggDoz14Zk2AWZ3ta3"></p></div></div><br><h2 id="etap-ii-pervye-uspehi-raspoznavanie-nomerov-mashin">  Est√°gio II.  Primeiros sucessos.  Reconhecimento de n√∫meros de carros. </h2><br><p>  Para o reconhecimento, precisamos de um quadro claro do carro pr√≥ximo, por isso foi decidido tirar apenas os quadros do ponto de verifica√ß√£o e compar√°-los √† semelhan√ßa (mais sobre isso no pr√≥ximo cap√≠tulo).  Esse m√©todo, no entanto, gera muita imprecis√£o, porque  m√°quinas podem ser muito semelhantes visualmente e meu algoritmo ainda n√£o pode evitar tais situa√ß√µes. </p><br><p>  Foi decidido usar uma lib pronta do fabricante ucraniano <a href="https://github.com/ria-com/nomeroff-net">nomeroff-net</a> (sem publicidade).  Porque  quase todo o c√≥digo pode ser encontrado nos exemplos do modelo, ent√£o n√£o darei uma descri√ß√£o completa. </p><br><p>  S√≥ posso dizer que esta fun√ß√£o pode ser iniciada com a imagem original ou a m√°quina reconhecida pode ser cortada do quadro e passada para esta fun√ß√£o. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.image <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mpimg <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os sys.path.append(cfg.NOMEROFF_NET_DIR) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> NomeroffNet <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> filters, RectDetector, TextDetector, OptionsDetector, Detector, textPostprocessing nnet = Detector(cfg.MASK_RCNN_DIR, cfg.MASK_RCNN_LOG_DIR) nnet.loadModel(<span class="hljs-string"><span class="hljs-string">"latest"</span></span>) rectDetector = RectDetector() optionsDetector = OptionsDetector() optionsDetector.load(<span class="hljs-string"><span class="hljs-string">"latest"</span></span>) textDetector = TextDetector.get_static_module(<span class="hljs-string"><span class="hljs-string">"ru"</span></span>)() textDetector.load(<span class="hljs-string"><span class="hljs-string">"latest"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">detectCarNumber</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(imgPath: str)</span></span></span><span class="hljs-function"> -&gt; str:</span></span> img = mpimg.imread(imgPath) NP = nnet.detect([img]) cvImgMasks = filters.cv_img_mask(NP) arrPoints = rectDetector.detect(cvImgMasks) zones = rectDetector.get_cv_zonesBGR(img, arrPoints) regionIds, stateIds, _c = optionsDetector.predict(zones) regionNames = optionsDetector.getRegionLabels(regionIds) <span class="hljs-comment"><span class="hljs-comment"># find text with postprocessing by standart textArr = textDetector.predict(zones) textArr = textPostprocessing(textArr, regionNames) return textArr</span></span></code> </pre> <br><p>  o textArr de sa√≠da representar√° uma matriz de strings com o n√∫mero de m√°quinas encontradas no quadro, por exemplo: <br>  <code>["293163"]</code> ou <code>[""]</code> , <code>[]</code> - se nenhum n√∫mero correspondente for encontrado. </p><br><h2 id="etap-iii-opoznaem-obekty-na-shozhest">  Est√°gio III.  Identifique objetos por similaridade. </h2><br><p>  Agora precisamos entender como consertar um objeto uma vez, entender que √© ele no pr√≥ximo quadro.  Nesse est√°gio, assumiremos que temos apenas uma c√¢mera e apenas distinguiremos os quadros diferentes dela. </p><br><p>  Para fazer isso, voc√™ precisa descobrir como compararemos os dois objetos. </p><br><p>  Vou propor um algoritmo de <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">peneira√ß√£o</a> para esses prop√≥sitos.  Fazemos uma reserva de que n√£o faz parte da parte principal do OpenCV, portanto, precisamos fornecer m√≥dulos de contribui√ß√£o adicional.  Infelizmente, o algoritmo √© patenteado e seu uso em programas comerciais √© limitado.  Mas estamos focados em atividades de pesquisa, certo? </p><br><pre> <code class="plaintext hljs">pip3 install opencv-contrib-python --user</code> </pre> <br><p>  ~~ Sobrecarregar o operador == ~~ Escrevemos uma fun√ß√£o que recebe 2 objetos comparados na forma de matrizes.  Por exemplo, n√≥s os obtemos ap√≥s chamar a fun√ß√£o <code>cv2.open(path)</code> </p><br><p>  Escreveremos uma implementa√ß√£o do nosso algoritmo. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compareImages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img1, img2)</span></span></span><span class="hljs-function"> -&gt; bool:</span></span> sift = cv2.xfeatures2d.SIFT_create()</code> </pre> <br><p>  Encontre os principais pontos e descritores usando o SIFT.  Talvez eu n√£o forne√ßa uma ajuda para essas fun√ß√µes, porque voc√™ sempre pode cham√°-lo no shell interativo como <code>help(somefunc)</code> </p><br><pre> <code class="python hljs"> kp1, des1 = sift.detectAndCompute(img1, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) kp2, des2 = sift.detectAndCompute(img2, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)</code> </pre> <br><p>  Configure nosso algoritmo. </p><br><pre> <code class="python hljs"> FLANN_INDEX_KDTREE = <span class="hljs-number"><span class="hljs-number">0</span></span> indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=<span class="hljs-number"><span class="hljs-number">5</span></span>) searchParams = dict(checks=<span class="hljs-number"><span class="hljs-number">50</span></span>) flann = cv2.FlannBasedMatcher(indexParams, searchParams)</code> </pre> <br><p>  Agora corra. </p><br><pre> <code class="python hljs"> matches = flann.knnMatch(des1, des2, k=<span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre> <br><p>  Conte as semelhan√ßas entre as imagens. </p><br><pre> <code class="python hljs"> matchesCount = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> m, n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> matches: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> m.distance &lt; cfg.cencitivity*n.distance: matchesCount += <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> matchesCount &gt; cfg.MIN_MATCH_COUNT</code> </pre> <br><p>  Agora, tente us√°-lo <br>  Para fazer isso, depois de detectar objetos, precisamos cort√°-los da imagem original </p><br><p>  N√£o consegui escrever nada melhor do que salv√°-lo para mem√≥ria lenta e depois ler a partir da√≠. </p><br><pre> <code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">extractObjects</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(objects, binaryImage, outputImageDirectory, filename=None)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> objects: y1, x1, y2, x2 = item.coordinates <span class="hljs-comment"><span class="hljs-comment">#       cropped = binaryImage[y1:y2, x1:x2] beforePoint, afterPoint = filename.split(".") outputDirPath = os.path.join(os.path.split(outputImageDirectory)[0], "objectsOn" + beforePoint) if not os.path.exists(outputDirPath): os.mkdir(outputDirPath) coordinates = str(item).replace(" ", ",") pathToObjectImage = "{}{}.jpg".format(item.type, coordinates) cv2.imwrite(os.path.join(outputDirPath, str(pathToObjectImage)), cropped)</span></span></code> </pre> <br><p>  Agora temos os objetos no <code>&lt;outputImageDirectory&gt;/objectsOn&lt;imageFilename&gt;</code> </p><br><p>  Agora, se tivermos pelo menos 2 desses diret√≥rios, poderemos comparar os objetos neles.  Execute a fun√ß√£o escrita anteriormente </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> compareImages(previousObjects, currentObjects): print(‚Äú  !‚Äù)</code> </pre> <br><p>  Ou podemos executar outra a√ß√£o, como marcar esses objetos com o mesmo identificador. </p><br><p>  Obviamente, como todas as redes neurais, essa tende a dar resultados √†s vezes err√¥neos. </p><br><p>  Em geral, conclu√≠mos as 3 tarefas definidas no in√≠cio, portanto, concluiremos.  Duvido que este artigo tenha aberto os olhos de pessoas que escreveram pelo menos um programa que resolve os problemas de reconhecimento / segmenta√ß√£o de imagens, mas espero ter ajudado pelo menos um desenvolvedor iniciante. </p><br><p>  O c√≥digo fonte completo do projeto pode ser encontrado <a href="https://github.com/Sapfir0/premier-eye">aqui</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt483018/">https://habr.com/ru/post/pt483018/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt483004/index.html">Efeito Kuleshov no Disco Elysium: como o contexto cria significado</a></li>
<li><a href="../pt483008/index.html">Outro futuro - uma divis√£o da humanidade</a></li>
<li><a href="../pt483012/index.html">Antiguidades: Roland MT-32, um som alternativo para jogos DOS</a></li>
<li><a href="../pt483014/index.html">Filas de mensagens do PostgreSQL usando PgQ</a></li>
<li><a href="../pt483016/index.html">Uma Breve Hist√≥ria dos Microprocessadores Espaciais, Parte Dois</a></li>
<li><a href="../pt483024/index.html">‚ÄúO que as empresas fizeram com sua privacidade?‚Äù, Arthur Khachuyan (Tazeros Global)</a></li>
<li><a href="../pt483026/index.html">Java / Spring: Como gerar completamente uma API RUD CRUD usando Speedment</a></li>
<li><a href="../pt483030/index.html">API que faz voc√™ chorar</a></li>
<li><a href="../pt483032/index.html">Mudando da CEI para a Rep√∫blica Tcheca, experi√™ncia pr√≥pria (parte 2)</a></li>
<li><a href="../pt483036/index.html">Problema de conclus√£o do n-Queens - algoritmo de solu√ß√£o linear</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîÅ üîú üë©üèº‚Äçüè´ 50 (oder 60) Jahre Prozessorentwicklung ... daf√ºr? üë∂üèª üÜñ üé•</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content=""Dennards Skalierungsgesetz und Moores Gesetz sind tot, was nun?" - ein St√ºck in vier Akten von David Patterson 

 ‚ÄûWir verbrennen die Br√ºcken, die wi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>50 (oder 60) Jahre Prozessorentwicklung ... daf√ºr?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/411989/"><img src="https://habrastorage.org/webt/z7/70/_h/z770_h7dznpgykjg-tfjbqhrgza.jpeg" align="left">  <b>"Dennards Skalierungsgesetz und Moores Gesetz sind tot, was nun?"</b>  <b>- ein St√ºck in vier Akten von David Patterson</b> <br><br>  <i>‚ÄûWir verbrennen die Br√ºcken, die wir hier hetzen, und haben keine anderen Beweise f√ºr unsere Bewegung, au√üer den Erinnerungen an den Rauchgeruch und die Annahme, dass er Tr√§nen verursacht hat‚Äú - ‚ÄûRosencrantz und Guildenstern sind tot‚Äú, ein absurdes St√ºck von Tom Stoppard</i> <br><br>  Am 15. M√§rz sprach Dr. David Patterson vor rund 200 Pizza-Ingenieuren.  Der Arzt erz√§hlte ihnen w√§hrend eines IEEE-Vortrags mit dem Titel ‚Äû50 Jahre Computerarchitektur: Von zentralen Verarbeitungseinheiten zu DNN TPU und Open RISC-V‚Äú kurz die Geschichte des Bauens von Computern an den St√§nden im gro√üen Konferenzraum von Geb√§ude E auf dem Campus von Texas Instruments in Santa Clara.  Dies ist eine Geschichte von zuf√§lligen H√∂hen und Tiefen, Einbr√ºchen und schwarzen L√∂chern, die ganze Architekturen verschluckt haben. <br><br>  Patterson begann in den 1960er Jahren mit dem bahnbrechenden IBM System / 360-Projekt, das auf Maurice Wilks 'Mikroprogrammierungsarbeiten von Anfang 1951 basierte.  Nach IT-Ma√üst√§ben ist es lange her ... Gegen Ende der Rede zeigte Patterson ein erstaunliches Diagramm.  Es zeigt deutlich, wie genau der Tod von Dennards Skalierungsgesetz, gefolgt vom Tod von Moores Gesetz, die Entwurfsmethoden von Computersystemen vollst√§ndig ver√§ndert hat.  Am Ende erkl√§rte er die posthumen technologischen Folgen dieser Schocks. <br><a name="habracut"></a><br>  Es ist immer sch√∂n zu sehen, wie ein wahrer Meister mit seinem Lieblingshandwerk besch√§ftigt ist, und Patterson ist wirklich ein Experte f√ºr Computerarchitektur und die Kr√§fte, die sie regieren.  Er unterrichtete dieses Thema seit 1976 und war Co-Autor eines wahren Bestsellers <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, Computer Architecture.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quantitativer Ansatz ‚Äú</a> mit Dr. John Hennessy.  Das Buch hat k√ºrzlich die sechste Ausgabe √ºberlebt.  Patterson war also eine Gr√∂√üenordnung gr√∂√üer als der von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Malcolm Gladwell</a> formulierte Meilenstein von 10.000 Stunden, um in jedem Fach die Meisterschaft zu erlangen.  Und es ist sichtbar. <br><br>  Patterson erregte 75 Minuten lang die Aufmerksamkeit des Publikums und teilte die Auff√ºhrung in vier Akte auf.  Wie in Tom Stoppards absurdem St√ºck "Rosencrantz und der Guildenstern sind tot" scheint nichts in dieser Geschichte - √ºberhaupt nichts - wie geplant zu verlaufen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/9fe/217/ae8/9fe217ae8a9b5ab628c1918e30f3fd23.png"></div><br>  <i><font color="gray">Dr. David Patterson von der IEEE Santa Clara Valley Section am 15. M√§rz 2018, bevor er ihm den ACM Turing Award 2017 verlieh.</font></i>  <i><font color="gray">Quelle: Steve Leibson</font></i> <br><br><h3>  Erster Akt: IBM System / 360, DEC VAX und CISC Prelude </h3><br>  In den 1950er und 1960er Jahren wurden gro√üartige Experimente mit Befehlssatzarchitekturen (ISA) f√ºr Mainframes durchgef√ºhrt (zu dieser Zeit gab es praktisch keine Computer au√üer Mainframes).  Fast jeder Mainframe hatte eine "neue und verbesserte" ISA.  In den fr√ºhen 1960er Jahren hatte nur IBM vier Computerreihen herausgebracht: 650, 701, 702 und 1401, die f√ºr gesch√§ftliche, wissenschaftliche und Echtzeitanwendungen entwickelt wurden.  Alle von ihnen sind mit inkompatiblen Befehlssatzarchitekturen ausgestattet.  Vier inkompatible ISAs bedeuteten, dass IBM vier v√∂llig unabh√§ngige S√§tze von Peripherieger√§ten (Bandlaufwerke, Festplatten / Drum-Laufwerke und Drucker) sowie vier S√§tze von Softwareentwicklungstools (Assembler, Compiler, Betriebssysteme usw.) entwickelte und wartete. . <br><br>  Die Situation schien eindeutig nicht stabil zu sein.  Daher hat IBM gro√ü gespielt.  Sie beschloss, einen bin√§r kompatiblen Befehlssatz f√ºr alle ihre Maschinen zu entwickeln.  Ein ger√§teunabh√§ngiger Befehlssatz f√ºr alles.  Der Chefarchitekt Gene Amdahl und sein Team haben die System / 360-Architektur entwickelt, die im Bereich von kosteng√ºnstigen bis zu teuren Serien mit 8-, 16-, 32- und 64-Bit-Datenbussen implementiert werden kann. <br><br>  Um die Entwicklung des Prozessors f√ºr IBM System / 360 zu vereinfachen, entschied sich das Entwicklungsteam, Mikrocode f√ºr die schwer zu entwerfende Steuerlogik zu verwenden.  Maurice Wilkes erfand den Mikrocode 1951 und wurde 1958 erstmals f√ºr den EDSAC 2-Computer verwendet.  In gewisser Weise war der Mikrocode bereits zu Beginn des System / 360-Projekts eine bew√§hrte Technologie.  Und er hat sich erneut bew√§hrt. <br><br>  Der Prozessor-Mikrocode spiegelte sich sofort im Mainframe-Design wider, insbesondere als Halbleiterspeicherchips das Moore'sche Gesetz sattelten.  Das vielleicht beste Beispiel f√ºr die massive Verwendung von Mikrocode ist der 1977 eingef√ºhrte DEC VAX.  VAX 11/780, ein innovativer Minicomputer auf Basis von TTL und Speicherchips, wurde bis zum Ende des Jahrhunderts zum Leistungsma√üstab. <br><br>  Die DEC-Ingenieure haben ISA f√ºr VAX zu einer Zeit erstellt, als die Assembler-Programmierung vorherrschte, teils aufgrund der technischen Tr√§gheit (‚Äûdas haben wir immer gemacht‚Äú), teils weil rudiment√§re High-Level-Compiler zu dieser Zeit Maschinencode generierten, der durch handgeschriebene Pr√§gnanz verloren ging Baugruppencode.  Die VAX ISA-Anweisungen unterst√ºtzten eine Vielzahl programmiererfreundlicher Adressierungsmodi und enthielten separate Maschinenanweisungen, die komplexe Vorg√§nge ausf√ºhrten, z. B. das Einf√ºgen / L√∂schen einer Warteschlange und das Berechnen eines Polynoms.  Die Ingenieure von VAX waren begeistert von der Entwicklung von Hardware, die Programmierern das Leben leichter machte.  Der Mikrocode machte es einfach, der ISA neue Anweisungen hinzuzuf√ºgen - und die 99-Bit-VAX-Firmware-Steuerung wurde auf 4096 W√∂rter aufgeblasen. <br><br>  Dieser Fokus auf die st√§ndige Erweiterung der Anzahl von Anweisungen, um Assembler-Programmierern das Leben zu erleichtern, hat sich f√ºr VAX von DEC als echter Wettbewerbsvorteil erwiesen.  Programmierer mochten Computer, die ihre Arbeit erleichtern.  F√ºr viele Computerhistoriker ist der VAX 11/780 die Geburtsstunde der CISC-Prozessorarchitektur (mit einem vollst√§ndigen Satz von Anweisungen). <br><br><h3>  Zweiter Akt: Zuf√§lliger Erfolg und gro√üe Misserfolge </h3><br>  Der Minicomputer DEC VAX 11/780 erreichte seinen H√∂hepunkt, als der Mikroprozessorausleger begann.  Fast alle der ersten Mikroprozessoren waren CISC-Maschinen, da die Entlastung des Programmierger√§ts auch dann ein Wettbewerbsvorteil blieb, wenn der Computer auf einen einzigen Chip komprimiert wurde.  Gordon Moore von Intel, der das Gesetz von Moore bei Fairchild gepr√§gt hat, wurde beauftragt, die n√§chste ISA zu entwickeln, die die versehentlich beliebte ISA f√ºr den 8-Bit-Intel 8080/8085 (und Z80) ersetzen soll.  Gordon Moore nahm einen Teil des √§u√üerst erfolgreichen IBM System / 360-Projekts (ein ISA, um alles zu verwalten) und den anderen Teil der DEC-Reihe von CISC-Minicomputern von DEC und versuchte, eine universelle Befehlssatzarchitektur zu entwickeln - eine einzige Intel ISA, die bis zum Ende Bestand haben wird Jahrhunderte. <br><br>  Zu dieser Zeit liefen 8-Bit-Mikroprozessoren in einem 16-Bit-Adressraum, und die neue Intel ISA-Befehlssatzarchitektur verf√ºgte √ºber einen 32-Bit-Adressraum und einen integrierten Speicherschutz.  Sie unterst√ºtzte Anweisungen beliebiger L√§nge, die mit einem Bit beginnen.  Und es wurde in der neuesten und besten Hochsprache programmiert: Ada. <br><br>  Dieser ISA sollte Teil des Intel iAPX 432-Prozessors sein, und es war ein sehr gro√ües, sehr ehrgeiziges Projekt f√ºr Intel. <br><br>  Wenn Sie die Geschichte des ‚Äûrevolution√§ren‚Äú iAPX 432 studieren, werden Sie feststellen, dass er in einem schrecklichen Misserfolg endete.  Die f√ºr die IAPX 432-Architektur erforderliche Hardware ist √§u√üerst komplex.  Infolgedessen wurde der Chip mit gro√üer Verz√∂gerung freigegeben.  (Es erforderte einen 6-j√§hrigen Entwicklungszyklus und erschien erst 1981.) Und als der Mikroprozessor schlie√ülich erschien, stellte sich heraus, dass er au√üergew√∂hnlich langsam war. <br><br>  Zu Beginn des Projekts erkannte Moore, dass die Entwicklung eines iAPX 432 viel Zeit in Anspruch nehmen w√ºrde. 1976 startete er ein Parallelprojekt zur Entwicklung eines viel weniger ehrgeizigen 16-Bit-Mikroprozessors, der auf der Erweiterung des erfolgreichen 8-Bit-ISA von 8080 basiert und auf Quellenebene kompatibel ist Code.  Die Entwickler hatten nur ein Jahr Zeit, um den Chip freizugeben, sodass sie nur drei Wochen Zeit hatten, um ISA zu entwickeln.  Das Ergebnis war ein 8086-Prozessor und ein universeller ISA, zumindest f√ºr die n√§chsten Jahrzehnte. <br><br>  Es gab nur ein Problem: Laut der Beschreibung der Insider von Intel war der 8086-Mikroprozessor sehr schwach. <br><br>  Die Leistung des Intel 8086 blieb hinter der seiner engsten Konkurrenten zur√ºck: dem eleganten Motorola 68000 (32-Bit-Prozessor in 16-Bit-Bekleidung) und dem 16-Bit-Zilog Z8000.  Trotz der schlechten Leistung entschied sich IBM f√ºr Intel 8086 f√ºr sein IBM PC-Projekt, da Intel-Ingenieure in Israel die 8088-Variante entwickelten - es ist 8086 mit einem 8-Bit-Bus.  Der 8088-Mikroprozessor arbeitete etwas langsamer als der 8086, aber sein 8-Bit-Bus schien besser mit vorhandenen Peripherie-Chips kompatibel zu sein und reduzierte die Kosten f√ºr die Herstellung eines PC-Motherboards. <br><br>  Nach Prognosen von IBM war der Verkauf von rund 250.000 IBM PC-Computern geplant.  Stattdessen lag der Umsatz √ºber 100 Millionen, und der Intel 8088 war ein zuf√§lliger, aber absoluter Hit. <br><br><h3>  Der dritte Akt: die Geburt von RISC, VLIW und der Untergang von "Itanika" </h3><br>  Unmittelbar nach dem Erscheinen der ersten kommerziellen Mikroprozessoren versuchte IBM John Kok 1974, einen Steuerprozessor f√ºr eine elektronische Telefonzentrale zu entwickeln.  Er sch√§tzt, dass der Steuerprozessor ungef√§hr 10 Millionen Anweisungen pro Sekunde (MIPS) ausf√ºhren muss, um die Anwendungsanforderungen zu erf√ºllen.  Die Mikroprozessoren dieser Zeit waren um eine Gr√∂√üenordnung langsamer, und selbst der IBM System / 370-Mainframe war f√ºr diese Aufgabe nicht geeignet: Er erzeugte etwa 2 MIPS. <br><br>  Daher entwickelte das Kok-Team im Rahmen des Projekts 801 eine radikal modernisierte Prozessorarchitektur mit einem F√∂rderbus und einer schnellen Steuerschaltung ohne Mikrocode. Dies wurde erm√∂glicht, indem die Anzahl der Anweisungen auf ein Minimum reduziert wurde, um die Verwaltung zu vereinfachen.  (Die Maschine wurde IBM 801 genannt, weil sie im 801-Geb√§ude des Thomas J. Watson IBM Research Center entwickelt wurde.)  Zum ersten Mal implementierte IBM 801 die RISC-Architektur (reduzierter Befehlssatz). <br><br>  Der Prototyp des Computers 801 wurde auf kleinen Chips von Motorola MECL 10K gebaut, die zusammen eine beispiellose Leistung von 15 MIPS ergaben und problemlos in die technischen Anforderungen passen.  Da der verk√ºrzte Befehlssatz f√ºr den Programmierer weniger praktisch ist als der CISC-Befehlssatz, musste das Coca-Team optimierende Compiler entwickeln.  Sie √ºbernahmen die zus√§tzliche Last, effizienten Maschinencode aus komplexen Algorithmen zu erstellen, die in Hochsprachen geschrieben sind. <br><br>  Danach wurde Kok als "Vater von RISC" bekannt.  IBM hat nie einen Telefonschalter herausgebracht, aber der 801-Prozessor hat sich weiterentwickelt und wurde schlie√ülich zur Basis f√ºr die gro√üe Reihe von RISC-Prozessoren von IBM, die in seinen Mainframes und Servern weit verbreitet sind. <br><br>  Sp√§ter stellten mehrere Ingenieure bei DEC fest, dass etwa 20% der CISC-Anweisungen von VAX etwa 80% des Mikrocodes, aber nur 0,2% der gesamten Programmausf√ºhrungszeit belegen.  Solch eine Ausgabe!  Angesichts der Ergebnisse des IBM 801-Projekts und der Ergebnisse der DEC-Ingenieure kann davon ausgegangen werden, dass die CISC-Architektur nicht so gut ist. <br><br>  Die Annahme wurde best√§tigt. <br><br>  1984 ver√∂ffentlichte der Stanford-Professor John Hennessey einen wegweisenden Artikel im <i>IEEE Transactions on Computers-</i> Journal mit dem Titel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûVLSI-Prozessorarchitektur‚Äú</a> , in dem er die √úberlegenheit von Architekturen und ISA auf RISC f√ºr VLSI-Prozessorimplementierungen nachwies.  Patterson fasste Hennesseys Beweis in seinem Vortrag zusammen: RISC ist per Definition schneller, da CISC-Maschinen sechsmal mehr Befehlszyklen erfordern als RISC-Maschinen.  Obwohl die CISC-Maschine die H√§lfte der Anweisungen f√ºr dieselbe Aufgabe ausf√ºhren muss, ist der RISC-Computer im Wesentlichen dreimal schneller als der CISC. <br><br>  Daher f√ºhren x86-Prozessoren in modernen Computern scheinbar nur CISC-kompatible Softwareanweisungen aus. Sobald diese Anweisungen aus dem externen RAM in den Prozessor gelangen, werden sie sofort in einfachere "Mikrobefehle" (wie Intel RISC-Anweisungen nennt) zerlegt dann in die Warteschlange gestellt und in mehreren RISC-Pipelines ausgef√ºhrt.  Die heutigen x86-Prozessoren sind schneller geworden und werden zu RISC-Maschinen. <br><br>  Mehrere Entwickler von Prozessorarchitekturen haben beschlossen, ISA zu entwickeln, das viel besser als RISC oder CISC sein wird.  Mit Hilfe von sehr langen Maschinenanweisungen (VLIW) ist es m√∂glich geworden, viele parallele Operationen in eine gro√üe Maschinenanweisung zu packen.  Architekten nannten diese Version von ISA VLIW (Very Long Instruction Word).  VLIW-Maschinen leihen sich eines der Prinzipien des RISC-Betriebs aus und beauftragen den Compiler mit der Planung und Verpackung von Maschinencode-VLIW-Anweisungen, die aus Quellcode auf hoher Ebene generiert werden. <br><br>  Intel entschied, dass die VLIW-Architektur sehr attraktiv aussieht - und begann mit der Entwicklung des VLIW-Prozessors, der seine Anwendung f√ºr den Einstieg in die unvermeidliche Welt der 64-Bit-Prozessoren sein wird.  Intel nannte seinen VLIW ISA IA-64.  Wie √ºblich hat Intel eine eigene Nomenklatur und Namen f√ºr vertraute Begriffe entwickelt.  In Intel Jargon hat sich VLIW zu EPIC (Explicitly Parallel Instruction Computing) entwickelt.  Die EPIC-Architektur sollte nicht auf dem x86-Befehlssatz basieren, um zu verhindern, dass AMD kopiert. <br><br>  Sp√§ter entschieden die HP PA-RISC-Ingenieure auch, dass das Entwicklungspotential von RISC fast ausgesch√∂pft war - und sie wurden auch mit VLIW infiziert.  1994 entwickelte HP gemeinsam mit Intel eine gemeinsame 64-Bit-VLIW / EPIC-Architektur.  Das Ergebnis hei√üt Itanium.  Das Ziel wurde angek√ºndigt, 1998 den ersten Itanium-Prozessor auf den Markt zu bringen. <br><br>  Es wurde jedoch schnell klar, dass es schwierig sein w√ºrde, VLIW-Prozessoren und -Compiler zu entwickeln.  Intel gab den Namen Itanium erst 1999 bekannt (der Witz im Usenet nannte den Prozessor sofort ‚ÄûItanik‚Äú), und der erste funktionierende Prozessor wurde erst 2001 ver√∂ffentlicht.  Der Itanic ertrank 2017 sicher, als Intel den Abschluss der Arbeiten am IA-64 bekannt gab.  (Siehe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûIntel hat Itanium versenkt: das vielleicht teuerste Projekt f√ºr fehlerhafte Prozessoren der Welt.‚Äú</a> ) <br><br>  Die EPIC-Architektur ist ebenfalls zu einem epischen Fehler geworden - eine Mikroprozessorversion von JJ Jinx aus Star Wars.  Obwohl es zu einer Zeit eine gute Idee schien. <br><br>  Itanium-, EPIC- und VLIW-Prozessoren sind aus mehreren Gr√ºnden gestorben, sagt Patterson: <br><br><ul><li>  Unvorhersehbare Verzweigungen, die das Planen und Packen von Paralleloperationen in VLIW-Befehlsw√∂rter erschweren. </li><li>  Unvorhersehbare Cache-Fehler verlangsamten die Ausf√ºhrung und f√ºhrten zu variablen Ausf√ºhrungsverz√∂gerungen. </li><li>  VLIW-Befehlss√§tze haben die Codemenge aufgeblasen. </li><li>  Es stellte sich als zu schwierig heraus, gute Optimierungscompiler f√ºr VLIW-Maschinen zu erstellen. </li></ul><br>  Der vielleicht weltweit bekannteste Spezialist f√ºr Computeralgorithmen, Donald Knuth, bemerkte: "Der Itanium-Ansatz ... schien so gro√üartig - bis sich herausstellte, dass die gew√ºnschten Compiler im Wesentlichen unm√∂glich zu schreiben waren." <br><br>  Compiler scheinen mit einfachen Architekturen wie RISC besser abzuschneiden. <br><br>  VLIW-Architekturen stellten keine universellen Mikroprozessoren her.  Aber sp√§ter fanden sie immer noch ihre Berufung, die uns zum vierten Akt des St√ºcks f√ºhrt. <br><br><h3>  Vierter Akt: Dennards Skalierungsgesetz und Moores Gesetz sind tot, aber DSA, TPU und Open RISC-V leben </h3><br>  In Tom Stoppards St√ºck sind Rosencrantz und der Guildenstern tot. Zwei unbedeutende Charaktere aus Shakespeares Hamlet verstehen am Ende des letzten Aktes endlich, dass sie w√§hrend des gesamten St√ºcks tot waren.  Im letzten Akt der Prozessorgeschichte starb Patterson an Dennards Skalierungsgesetz und Moores Gesetz.  Hier ist eine Zeichnung aus der neuesten Ausgabe von Hennesseys und Pattersons Buch, die die ganze Geschichte grafisch zeigt: <br><br><img src="https://habrastorage.org/webt/2r/5b/ik/2r5biko9vehcn_w6juzpu3zohjq.png"><br>  <i><font color="gray">Quelle: John Hennessey und David Patterson, ‚ÄûComputer Architecture.</font></i>  <i><font color="gray">Der quantitative Ansatz ‚Äú, 6. Aufl.</font></i>  <i><font color="gray">2018</font></i> <br><br>  Die Grafik zeigt, dass RISC-Mikroprozessoren von 1986 bis 2004 ein fast zwanzigj√§hriges schnelles Produktivit√§tswachstum erm√∂glichten, da sie sich nach dem Moore-Gesetz (doppelt so viele Transistoren in jeder neuen Runde der Prozesstechnologie) und dem Dennard-Skalierungsgesetz (Verdoppelung der Geschwindigkeit durch Verdoppelung des Stromverbrauchs pro Transistor um) entwickelten jeder neue Zweig der Prozesstechnologie).  Dann starb Dennards Skalierungsgesetz - und einzelne Prozessoren h√∂rten auf zu beschleunigen.  Der Energieverbrauch des Transistors h√∂rte ebenfalls auf, sich in jeder Stufe zu halbieren. <br><br>  Die Industrie kompensierte dies, indem sie sich ausschlie√ülich auf das Gesetz von Moore st√ºtzte, um die Anzahl der Transistoren zu verdoppeln - und die Anzahl der Prozessoren auf einem Chip schnell zu erh√∂hen, was in eine Multi-Core-√Ñra eintrat.  Das Produktivit√§tsverdopplungsintervall stieg von 1,5 auf 3,5 Jahre in dieser Zeit, die weniger als zehn Jahre dauerte, bevor Amdahls Gesetz in Kraft trat (umformuliert als ‚ÄûParallelit√§t wird in jeder Anwendung nur begrenzt genutzt‚Äú).  Nur wenige Anwendungen k√∂nnen Dutzende von Prozessoren vollst√§ndig laden. <br><br>  Dann verstarb auch Moores Gesetz. <br><br>  Laut Patterson ist das Ergebnis so, dass das Wachstum der Prozessorleistung seit 2015 auf vernachl√§ssigbare 3% pro Jahr gesunken ist.  Moores Gesetzesverdopplung tritt nun in 1,5 und nicht einmal in 3,5 Jahren auf.  Jetzt ist es <u>zwanzig Jahre alt</u> . <br><br>  Ende des Spiels?  "Nein", sagt Patterson.  In der Prozessorarchitektur k√∂nnen Sie einige interessantere Dinge ausprobieren. <br><br>  Ein Beispiel: Domain Specific Architectures (DSAs) sind speziell entwickelte Prozessoren, die versuchen, die Ausf√ºhrung einer kleinen Anzahl von Aufgaben f√ºr bestimmte Anwendungen zu beschleunigen.  VLIW-Architekturen sind nicht f√ºr Universalprozessoren geeignet, aber f√ºr DSP-Anwendungen mit viel weniger Verzweigungen sinnvoll.  Ein weiteres Beispiel: Google TPU (Tensor Processing Unit), das die Ausf√ºhrung von DNN (Deep Neural Network) mithilfe eines Blocks von 65.536 Einheiten Multiplikationsaddition (MAC) auf einem einzelnen Chip beschleunigt. <br><br>  Es stellt sich heraus, dass Matrix-Computing mit reduzierter Genauigkeit der Schl√ºssel zur Realisierung wirklich schneller DNNs ist.  65.536 Acht-Bit-MAC-Bl√∂cke in Google TPUs arbeiten mit 700 MHz und bieten eine Leistung von 92 TOPS (Teraoperationen pro Sekunde).  Dies ist ungef√§hr 30 Mal schneller als die Server-CPU und 15 Mal schneller als die GPU.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Multiplizieren Sie den Stromverbrauch einer 28-Nanometer-TPU im Vergleich zu einer Server-CPU oder -GPU mit der H√§lfte - und erhalten Sie einen 60- bzw. 30-fachen Energie- / Leistungsvorteil. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Durch einen seltsamen Zufall trat Professor David Patterson k√ºrzlich von der University of California in Berkeley zur√ºck, nachdem er dort 40 Jahre lang unterrichtet und gearbeitet hatte. Derzeit ist er als "Emeritus Engineer" bei Google f√ºr das TPU-Entwicklungsprojekt t√§tig. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine weitere interessante Sache ist die Erstellung von Open-Source-ISA-Architekturen, sagt Patterson. Fr√ºhere derartige Versuche, einschlie√ülich </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenRISC</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenSPARC</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , liefen nicht an, aber Patterson sprach von einer v√∂llig neuen Open-Source-ISA - dies ist </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RISC-V</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">was er in Berkeley mitentwickelte. Schauen Sie sich den SoC an, sagt Patterson, und Sie werden viele Prozessoren mit unterschiedlichen ISAs sehen. "Warum?" Er stellt eine Frage. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum brauchen wir eine universelle ISA, eine weitere ISA f√ºr die Bildverarbeitung sowie eine ISA f√ºr die Videoverarbeitung, f√ºr die Audioverarbeitung und einen ISA-DSP auf einem einzigen Chip? Warum nicht einfach einen oder mehrere einfache ISAs (und einen Satz von Softwareentwicklungstools) erstellen, die f√ºr bestimmte Anwendungen wiederverwendet werden k√∂nnen? Warum nicht ISA Open Source machen, damit jeder diese Architektur kostenlos nutzen und verbessern kann? Pattersons einzige Antwort auf diese Fragen ist die RISC-V ISA. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">K√ºrzlich gegr√ºndete </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RISC-V Foundation</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√§hnlich im Konzept wie die erfolgreiche Linux Foundation. Es waren bereits mehr als 100 Unternehmen beteiligt, und er √ºbernahm die Standardisierung des RISC-V ISA. Die Aufgabe des Fonds besteht darin, zur Umsetzung von RISC-V ISA und seiner k√ºnftigen Entwicklung beizutragen. Zuf√§lligerweise ist Dr. David Patterson, ‚Äûim Ruhestand‚Äú, der stellvertretende Vorsitzende der RISC-V-Stiftung. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie Rosencrantz und Guildenstern enden Dennards Skalierungsgesetz und Moores Gesetz am Ende von Pattersons historischem Spiel, aber interessante Ereignisse in der Computerarchitektur stehen erst am Anfang. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Es gibt nichts √ºberzeugenderes als den nicht √ºberzeugenden Tod", hei√üt es in dem St√ºck.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Epilog: Am 21. M√§rz, nur eine Woche nach dem Vortrag bei IEEE, w√ºrdigte die Computing Technology Association (ACM) den Beitrag von Patterson und Hennessey zur Computerarchitektur, indem sie ihnen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">den ACM Turing Award 2017</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr einen innovativen, systematischen und rechnergest√ºtzten Ansatz zum Entwerfen und Bewerten von Computerarchitekturen </font><font style="vertical-align: inherit;">verlieh </font><font style="vertical-align: inherit;">dauerhafte Auswirkungen auf die Mikroprozessorindustrie. ‚Äú</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de411989/">https://habr.com/ru/post/de411989/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de411977/index.html">Geboren um zu kriechen</a></li>
<li><a href="../de411979/index.html">Hippokrates hat nie davon getr√§umt: additive Technologien in der Medizin und ihre Anwendung</a></li>
<li><a href="../de411981/index.html">Der k√ºrzlich ver√∂ffentlichte Exploit erm√∂glicht das Hacken jeder Nintendo Switch-Konsole</a></li>
<li><a href="../de411983/index.html">Audiofilkin Brief: ein paar Worte zur Verteidigung von HI-RES</a></li>
<li><a href="../de411985/index.html">Kopfh√∂rer bei der Arbeit: Was die Forschung sagt</a></li>
<li><a href="../de411991/index.html">Aktualisierte Projektoren der XEED-Serie: Eine Touchdown-Story mit herausragender Technologie</a></li>
<li><a href="../de411993/index.html">Einf√ºhrung in DJI Phantom 4 Pro V2.0</a></li>
<li><a href="../de411995/index.html">Grundlagen der √ñkonomie der Halbleiterfertigung</a></li>
<li><a href="../de411997/index.html">Internetradiomodul oder was im Mai zu tun ist</a></li>
<li><a href="../de411999/index.html">Software-Review zur topologischen Optimierung und zum bionischen Design</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
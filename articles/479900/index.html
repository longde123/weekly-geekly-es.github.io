<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïë ‚û∞ üë±üèø Data Lake orientado al cliente en una empresa de juegos ü§≤üèø ü§æüèæ ‚öõÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fuente 

 Hola Habr! Mi nombre es Maxim Pchelin, y lidero el desarrollo de BI-DWH en MyGames (divisi√≥n de juegos de Mail.ru Group). En este art√≠culo h...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Data Lake orientado al cliente en una empresa de juegos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/479900/"><img src="https://habrastorage.org/webt/ic/em/yw/icemywxszsrmzmrife7stz9ltpg.jpeg"><br>  <a href="https://www.filthymonkeymen.com/2016/06/16/neanderthal-hunting-strategy/">Fuente</a> <br><br>  Hola Habr!  Mi nombre es Maxim Pchelin, y lidero el desarrollo de BI-DWH en MyGames (divisi√≥n de juegos de Mail.ru Group).  En este art√≠culo hablar√© sobre c√≥mo y por qu√© creamos un almacenamiento DataLake orientado al cliente. <br><br>  El art√≠culo consta de tres partes.  Primero, explicar√© por qu√© decidimos implementar DataLake.  En la segunda parte, describir√© qu√© tecnolog√≠as y soluciones utilizamos para que el almacenamiento pueda funcionar y llenarse de datos.  Y en la tercera parte, describir√© lo que hacemos para mejorar la calidad de nuestros servicios. <br><a name="habracut"></a><br><h1>  Lo que nos trajo a DataLake </h1><br>  En <a href="https://my.games/">MyGames,</a> trabajamos en el departamento de BI-DWH y <a href="https://my.games/">brindamos</a> servicios de dos categor√≠as: un repositorio para analistas de datos y servicios de informes regulares para usuarios comerciales (gerentes, especialistas en marketing, desarrolladores de juegos y otros). <br><br><h3>  ¬øPor qu√© tal almacenamiento no est√°ndar? </h3><br>  Por lo general, BI-DWH no implica la implementaci√≥n del almacenamiento de DataLake; esto no se puede llamar una soluci√≥n t√≠pica.  ¬øY c√≥mo se construyen entonces estos servicios? <br><br>  Por lo general, una empresa tiene un proyecto; en nuestro caso, este es un juego.  El proyecto tiene un sistema de registro que con mayor frecuencia escribe datos en la base de datos.  Adem√°s de esta base, se crean escaparates para agregados, m√©tricas y otras entidades para an√°lisis futuros.  Los informes regulares se crean sobre la base de escaparates que utilizan cualquier herramienta de BI adecuada, as√≠ como sistemas de an√°lisis ad-hoc, comenzando con consultas SQL simples y tablas de Excel, y terminando con Jupyter Notebook para DS y ML.  Todo el sistema es compatible con un equipo de desarrollo. <br><br>  Supongamos que otra empresa nace en una empresa.  Tener otro equipo de desarrollo e infraestructura debajo es atractivo, pero costoso.  Por lo tanto, el proyecto debe estar "conectado".  Esto se puede hacer de diferentes maneras: en el nivel de la base de datos, en el nivel de la tienda, o al menos en el nivel de visualizaci√≥n: el problema est√° resuelto. <br><br>  ¬øY si la empresa tiene un tercer proyecto?  "Compartir" ya puede terminar mal: puede haber problemas con la asignaci√≥n de recursos o derechos de acceso.  Por ejemplo, uno de los proyectos lo realiza un equipo externo que no necesita saber nada sobre los dos primeros proyectos.  La situaci√≥n se est√° volviendo m√°s arriesgada. <br><br>  Ahora imagine que no hay tres proyectos, sino mucho m√°s.  Y sucedi√≥ que este es exactamente nuestro caso. <br><br>  MyGames es una de las divisiones m√°s grandes del Grupo Mail.ru, tenemos 150 proyectos en nuestra cartera.  Adem√°s, todos son muy diferentes: su propio desarrollo y la compra para operaciones en Rusia.  Funcionan en varias plataformas: PC, Xbox, Playstation, iOS y Android.  Estos proyectos se desarrollan en diez oficinas en todo el mundo con cientos de tomadores de decisiones. <br><br><img src="https://habrastorage.org/webt/6y/33/c5/6y33c5pfbswcdiqeikzuptzbs9k.jpeg"><br><br>  Para los negocios, esto es excelente, pero complica la tarea para el equipo de BI-DWH. <br><br>  En nuestros juegos, se registran muchas acciones de los jugadores: cu√°ndo ingres√≥ al juego, d√≥nde y c√≥mo alcanz√≥ los niveles, con qui√©n y con qu√© √©xito luch√≥, qu√© y para qu√© moneda compr√≥.  Necesitamos recopilar todos estos datos para cada uno de los juegos. <br><br>  Necesitamos esto para que la empresa pueda recibir respuestas a sus preguntas sobre los proyectos.  ¬øQu√© pas√≥ la semana pasada despu√©s del lanzamiento de la acci√≥n?  ¬øCu√°les son nuestras previsiones de ingresos o uso de las capacidades del servidor de juegos para el pr√≥ximo mes?  ¬øQu√© se puede hacer para influir en estos pron√≥sticos? <br><br>  Es importante que MyGames no imponga un paradigma de desarrollo en los proyectos.  Cada estudio de juegos registra datos ya que los considera m√°s eficientes.  Algunos proyectos generan registros en el lado del cliente, algunos en el lado del servidor.  Algunos proyectos usan RDBMS para recopilarlos, mientras que otros usan herramientas completamente diferentes: Kafka, Elasticsearch, Hadoop, Tarantool o Redis.  Y recurrimos a estas fuentes de datos para cargarlos en el repositorio. <br><br><h3>  ¬øQu√© quieres de nuestro BI-DWH? </h3><br>  En primer lugar, desde el departamento de BI-DWH quieren recibir datos de todos nuestros juegos para resolver tanto las tareas operativas diarias como las estrat√©gicas.  Comenzando por cu√°ntas vidas dar un monstruo terrible al final del nivel, y terminando con c√≥mo distribuir adecuadamente los recursos dentro de la empresa: qu√© proyectos deber√≠an dar m√°s desarrolladores o qui√©n deber√≠a asignar un presupuesto de marketing. <br><br>  La fiabilidad tambi√©n se espera de nosotros.  Trabajamos en una gran empresa y no podemos vivir seg√∫n el principio de "Ayer trabajamos, pero hoy el sistema est√° en su lugar, y solo aumentar√° en una semana si se nos ocurre algo". <br><br>  Quieren ahorros de nosotros.  Nos complacer√≠a resolver todos los problemas comprando hierro o contratando personas.  Pero somos una organizaci√≥n comercial y no podemos pagarla.  Tratamos de hacer que la empresa se beneficie. <br><br>  Es importante destacar que quieren que nos centremos en el cliente.  Los clientes en este caso son nuestros consumidores, clientes: gerentes, analistas, etc. Debemos adaptarnos a nuestros juegos y trabajar de tal manera que sea conveniente que los clientes cooperen con nosotros.  Por ejemplo, en algunos casos, cuando compramos proyectos en el mercado asi√°tico para operaciones, junto con el juego podemos obtener bases con nombres en chino.  Y la documentaci√≥n de estas bases en chino.  Podr√≠amos buscar un desarrollador de ETL con conocimientos de chino o negarnos a descargar datos en el juego, pero en cambio, el equipo y yo nos encerramos en la sala de reuniones, tomamos el reloj y comenzamos a jugar.  Entra y sal del juego, compra, dispara, muere.  Y miramos qu√© y cu√°ndo aparece en esta o aquella tabla.  Luego, escribimos la documentaci√≥n y, sobre esta base, construimos ETL. <br><br>  En este caso, es importante sentir la ventaja.  Profundizar en el registro √∫nico de un juego con una DAU de 50 personas, cuando necesitas ayudar a un proyecto con una DAU de 500,000 cerca, es un lujo inadmisible.  Por lo tanto, por supuesto, podemos dedicar mucho esfuerzo a crear una soluci√≥n personalizada, pero solo si las empresas realmente lo necesitan. <br><br>  Sin embargo, tan pronto como los desarrolladores, especialmente los principiantes, escuchan que tendr√°n que adaptarse de esta manera, desean no hacerlo nunca.  Cualquier desarrollador quiere hacer una arquitectura ideal, nunca cambiarla y escribir art√≠culos sobre ella en Habr. <br><br>  ¬øPero qu√© pasa si dejamos de adaptarnos a nuestros juegos?  ¬øSupongamos que comenzamos a exigirles que env√≠en datos a una √∫nica API de entrada?  El resultado ser√° uno: todos comenzar√°n a dispersarse. <br><br><ul><li>  Algunos proyectos comenzar√°n a reducir sus soluciones de BI-DWH, con preferencia y poetas.  Esto conducir√° a la duplicaci√≥n de recursos y dificultades en el intercambio de datos entre sistemas. <br></li><li>  Otros proyectos no lograr√°n la creaci√≥n de su BI-DWH, pero tampoco querr√°n adaptarse al nuestro.  Y a√∫n otros dejar√°n de usar datos, lo que es a√∫n peor. <br></li><li>  Bueno y lo m√°s importante, la administraci√≥n no tendr√° informaci√≥n sistem√°tica actualizada sobre lo que est√° sucediendo en los proyectos. <br></li></ul><br><h3>  ¬øPodr√≠amos implementar el almacenamiento de una manera simple? </h3><br>  150 proyectos es mucho.  Implementar la soluci√≥n de inmediato para todos es demasiado largo.  Las empresas no esperar√°n un a√±o para que aparezcan los primeros resultados.  Por lo tanto, tomamos 3 proyectos que generan los m√°ximos ingresos e implementamos el primer prototipo para ellos.  Quer√≠amos recopilar datos clave y crear paneles b√°sicos con las m√©tricas m√°s populares: DAU, MAU, Ingresos, registros, retenci√≥n, as√≠ como un poco de econom√≠a y pron√≥sticos. <br><br>  No pudimos usar las bases del juego de los proyectos para esto.  En primer lugar, esto dificultar√≠a el an√°lisis de dise√±o cruzado debido a la necesidad de agregar datos de varias bases de datos.  En segundo lugar, los juegos en s√≠ funcionan sobre estas bases de datos, lo cual es importante para que los maestros y las r√©plicas no se sobrecarguen.  Finalmente, todos los juegos en alg√∫n momento eliminan todo el historial de datos que no necesitan en sus bases de datos, lo cual es inaceptable para el an√°lisis. <br><br>  Por lo tanto, la √∫nica opci√≥n es recopilar todo lo que necesita para el an√°lisis en un solo lugar.  En este punto, cualquier base de datos relacional o repositorio de texto sin formato nos conviene.  Atornillar√≠amos BI y construir√≠amos tableros.  Hay muchas opciones para combinaciones de tales soluciones: <br><br><img src="https://habrastorage.org/webt/vx/1e/hm/vx1ehmdjxzv-nimt1x3_ivm3sd8.jpeg"><br><br>  Pero entendimos que m√°s tarde tendr√≠amos que cubrir los otros 150 juegos.  Quiz√°s alguna base de datos relacional de cl√∫ster pueda manejar la cantidad de datos generados.  Pero las fuentes no solo se encuentran en sistemas completamente diferentes, sino que tambi√©n tienen estructuras de datos muy diferentes.  Nos encontramos con estructuras relacionales, Data Vault y otros.  No funcionar√° poner todo esto en una base de datos sin trucos complejos y laboriosos. <br><br>  Todo esto nos llev√≥ a comprender que necesitamos construir un DataLake. <br><br><h1>  Implementaci√≥n de DataLake </h1><br>  En primer lugar, el almacenamiento de DataLake es adecuado para nuestras condiciones, ya que nos permite almacenar datos no estructurados.  DataLake puede convertirse en un √∫nico punto de entrada para todas las fuentes diversas, desde tablas desde RDBMS hasta JSON, que enviamos desde Kafka o Mongo.  Como resultado, DataLake puede convertirse en la base para el an√°lisis de dise√±o cruzado implementado en base a interfaces para varios consumidores: SQL, Python, R, Spark, etc. <br><br><h3>  Cambiar a Hadoop </h3><br>  Para DataLake, elegimos la soluci√≥n obvia: Hadoop.  Espec√≠ficamente, su montaje desde Cloudera.  Hadoop le permite trabajar con datos no estructurados y es f√°cilmente escalable al agregar nodos de datos.  Adem√°s, este producto ha sido bien estudiado, por lo que la respuesta a cualquier pregunta se puede encontrar en Stackoverflow y no gastar recursos en I + D. <br><br>  Despu√©s de implementar Hadoop, obtuvimos el siguiente diagrama de nuestro primer almacenamiento unificado: <br><br><img src="https://habrastorage.org/webt/95/fn/2u/95fn2uesgfvlgfqrxdohrfnltsa.jpeg"><br><br>  Los datos se recopilaron en Hadoop de un peque√±o n√∫mero de fuentes, y luego se enfrent√≥ a varias interfaces: herramientas y servicios de BI para an√°lisis ad-hoc. <br><br>  Otros eventos se desarrollaron inesperadamente: nuestro Hadoop comenz√≥ a la perfecci√≥n, y los consumidores para quienes los datos fluyeron a la tienda abandonaron los viejos sistemas anal√≠ticos y comenzaron a usar el nuevo producto a diario para su trabajo. <br><br>  Pero surgi√≥ un problema: cuanto m√°s haces, m√°s quieren de ti.  Muy r√°pidamente, los proyectos que ya estaban integrados en Hadoop comenzaron a solicitar m√°s datos.  Y aquellos proyectos que a√∫n no se han agregado, comenzaron a solicitarlo.  Los requisitos de estabilidad comenzaron a crecer bruscamente. <br><br>  Al mismo tiempo, no es razonable simplemente aumentar el equipo linealmente.  Si dos desarrolladores de DWH hacen frente a dos proyectos, entonces para cuatro proyectos no podemos contratar a dos desarrolladores m√°s.  Por lo tanto, primero fuimos por el otro lado. <br><br><h3>  Establecimiento de procesos </h3><br>  Con recursos limitados, la soluci√≥n m√°s barata es ajustar los procesos.  Adem√°s, en una gran empresa es imposible crear una arquitectura de almacenamiento e implementarla.  Tiene que negociar con una gran cantidad de personas. <br><br><ul><li>  En primer lugar, con representantes comerciales que asignan recursos para an√°lisis.  Deber√° demostrar que necesita implementar solo aquellas tareas de sus clientes que beneficiar√°n al negocio. <br></li><li>  Tambi√©n debe negociar con los analistas para que le den algo a cambio de los servicios que les brinda: an√°lisis de sistemas, an√°lisis de negocios, pruebas.  Por ejemplo, entregamos el an√°lisis del sistema de nuestras fuentes de datos a analistas.  Por supuesto, no est√°n contentos, pero de lo contrario simplemente no habr√° nadie para hacerlo. <br></li><li>  Por √∫ltimo, pero no menos importante, debe negociar con los desarrolladores de juegos: instalar SLA y acordar una estructura de datos.  Si los campos desaparecen, aparecen y cambian de nombre constantemente, no importa el tama√±o del equipo, siempre perder√° sus manos. <br></li><li>  Tambi√©n debe negociar con su propio equipo: busque un compromiso entre las soluciones ideales que todos los desarrolladores desean crear y las soluciones est√°ndar que no son tan interesantes, pero que pueden ser remachadas de manera econ√≥mica y r√°pida. <br></li><li>  Ser√° necesario acordar con los administradores el monitoreo de la infraestructura.  Aunque, tan pronto como tenga recursos adicionales, es mejor contratar a su propio especialista DevOps en el equipo de almacenamiento. <br></li></ul><br>  En este punto, podr√≠a terminar el art√≠culo si tal variante del repositorio cumplir√≠a todos los objetivos establecidos para √©l.  Pero esto no es as√≠.  Por qu√© <br><br>  Antes de Hadoop, pod√≠amos proporcionar datos y estad√≠sticas para cinco proyectos.  Con la implementaci√≥n de Hadoop y sin un aumento en el equipo, pudimos cubrir 10 proyectos.  Despu√©s de establecer los procesos, nuestro equipo ya ha atendido 15 proyectos.  Esto es genial, pero tenemos 150 proyectos. Necesit√°bamos algo nuevo. <br><br><h3>  Implementaci√≥n de flujo de aire </h3><br>  Inicialmente, recopilamos datos de fuentes usando Cron.  Dos proyectos es normal.  10 - duele, pero est√° bien.  Sin embargo, ahora se cargan diariamente alrededor de 12 mil procesos para cargar desde 150 proyectos en DataLake.  Cron ya no es adecuado.  Para hacer esto, necesitamos una herramienta poderosa para administrar flujos de descarga de datos. <br><br>  Elegimos el Administrador de tareas de flujo de aire de c√≥digo abierto.  Naci√≥ en las entra√±as de Airbnb, luego de lo cual fue transferido a Apache.  Esta es una herramienta para ETL basado en c√≥digo.  Es decir, usted escribe un script en Python, y se convierte en un DAG (gr√°fico ac√≠clico dirigido).  Los DAG son excelentes para mantener las dependencias entre tareas: no puede crear un escaparate utilizando datos que a√∫n no se han cargado. <br><br>  Airflow tiene un excelente controlador de errores.  Si un proceso falla o hay un problema con la red, el despachador reinicia el proceso la cantidad de veces que especifique.  Si hay muchas fallas, por ejemplo, la tabla en la fuente ha cambiado, entonces llega un mensaje de notificaci√≥n. <br><br>  Airflow tiene una excelente interfaz de usuario: muestra convenientemente qu√© procesos se est√°n ejecutando, cu√°les se han completado con √©xito o con un error.  Si las tareas cayeron con errores, puede reiniciarlas desde la interfaz y controlar el proceso a trav√©s de la supervisi√≥n sin entrar en el c√≥digo. <br><br>  Airflow es personalizable, est√° construido sobre operadores, estos son complementos para trabajar con fuentes espec√≠ficas.  Algunos operadores salen de la caja, muchos han escrito la comunidad Airflow.  Si lo desea, puede crear su propio operador, la interfaz para esto es muy simple. <br><br><h3>  ¬øC√≥mo usamos el flujo de aire? </h3><br>  Por ejemplo, necesitamos cargar una tabla de PostgreSQL en Hadoop.  La tarea <code>sql_sensor_battle_log</code> verifica si la fuente tiene los datos que necesitamos para ayer.  Si es as√≠, la tarea <code>load_stg_data_from_battle_log</code> datos de la PG y los agrega a Hadoop.  Finalmente, <code>load_oda_data_from_battle_log</code> realiza el procesamiento inicial: digamos, convirtiendo de Unix Time a tiempo legible para humanos. <br><br>  En dicha cadena de tareas, los datos se toman de una entidad en una fuente: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/347/38d/4af/34738d4afc911f105891070f97f90097.png"><br><br>  Y as√≠, de todas las entidades que necesitamos de una fuente: <br><br><img src="https://habrastorage.org/webt/bs/2i/ne/bs2ines-6me7a6f677u7rc4wgac.jpeg"><br><br>  Este conjunto de descargas es el DAG.  Y en este momento tenemos 250 DAG para cargar datos sin procesar, procesar, transformar y crear escaparates en √©l. <br><br>  El esquema de almacenamiento unificado actualizado es el siguiente: <br><br><img src="https://habrastorage.org/webt/a4/9m/ag/a49magbaiqyrtasd2awg6mqnjmk.jpeg"><br><br><ol><li>  Despu√©s de la introducci√≥n de Airflow, pudimos permitirnos un fuerte aumento en el n√∫mero de fuentes, hasta 400 piezas.  Las fuentes de datos son tanto internas (de nuestros juegos) como externas: sistemas de estad√≠sticas comprados, API heterog√©neas.  Es Airflow que nos permite ejecutar y controlar diariamente 12 mil procesos que procesan datos de nuestros 150 juegos. <br></li><li>  En m√°s detalle sobre nuestro flujo de aire, Dean Safina escribi√≥ en su art√≠culo ( <a href="https://habr.com/ru/company/mailru/blog/344398/">https://habr.com/ru/company/mailru/blog/344398/</a> ).  Y tambi√©n √∫nete a la comunidad Airflow en Telegram ( <a href="https://t.me/ruairflow">https://t.me/ruairflow</a> ).  Muchas preguntas sobre Airflow pueden resolverse con la ayuda de la documentaci√≥n, pero a veces aparecen m√°s solicitudes personalizadas: ¬øc√≥mo puedo empaquetar Airflow en la ventana acoplable, por qu√© no funciona el tercer d√≠a y todo eso?  Esto se puede responder en esta comunidad. <br></li></ol><br><h1>  Qu√© mejorar en DataLake </h1><br>  En este punto, los desarrolladores de DWH conf√≠an en que todo est√° listo y ahora puedes calmarte.  Desafortunadamente o afortunadamente, todav√≠a hay algo que ajustar en DataLake. <br><br><h3>  Calidad de los datos </h3><br>  Con una gran cantidad de tablas en DataLake, la calidad de los datos es la primera en sufrir.  Por ejemplo, tome una mesa con pagos.  Contiene user_id, cantidad, fecha y hora de pago: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/998/c18/2df/998c182df294a894a55c0c7822eead23.png" width="400"></div><br>  Alrededor de 10 mil pagos ocurren cada d√≠a: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b46/115/a01/b46115a0116d11be5373b93fc4d872e8.png" width="400"><br><br>  Una vez en la tabla del d√≠a llegaron solo 28 entradas.  S√≠, y user_id est√° todo vac√≠o: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/606/7c2/d84/6067c2d840a71002e83364d5c0aef2ae.png" width="200"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6b5/055/af6/6b5055af6affe4417834ee051947e57c.png" width="400"></div><br><br>  Si algo se rompe repentinamente en nuestra fuente, entonces, gracias a Airflow, lo sabremos de inmediato.  Pero si formalmente hay datos, e incluso en el formato correcto, entonces no aprendemos de inmediato sobre el desglose y de los consumidores de datos.  No es realista comprobar nuestras 5000 mesas con nuestras propias manos. <br><br>  Para evitar esto, hemos desarrollado nuestro propio sistema de control de calidad de datos (DQ).  Todos los d√≠as monitorea las descargas clave a nuestro repositorio: rastrea cambios repentinos en el n√∫mero de filas, busca campos vac√≠os y verifica la duplicaci√≥n de datos.  El sistema tambi√©n aplica controles personalizados de analistas.  En base a esto, ella env√≠a notificaciones por correo sobre lo que sali√≥ mal y d√≥nde.  Los analistas van a los proyectos y descubren por qu√©, por ejemplo, hay muy pocos datos, eliminan los motivos y volvemos a cargar los datos. <br><br><h3>  Priorizar descargas </h3><br>  Con el creciente n√∫mero de tareas para cargar datos en DataLake, r√°pidamente surge un conflicto de prioridad.  La situaci√≥n habitual: alg√∫n proyecto no tan importante tom√≥ todos los recursos con sus descargas por la noche, y las tablas que se necesitan para calcular las m√©tricas para la alta gerencia no tienen tiempo para cargar al comienzo del d√≠a laboral.  Nos ocupamos de esto de varias maneras. <br><br><ul><li>  Monitoreo de descargas clave.  Airflow tiene su propio sistema SLA, que le permite determinar si todas las claves llegaron a tiempo.  Si no se cargan algunos datos, lo descubriremos unas horas antes que los usuarios y tendremos tiempo para solucionarlo. <br></li><li>  Establecimiento de prioridades.  Para hacer esto, utilizamos la cola Airflow y el sistema de prioridad.  Nos permite determinar el orden de carga de los DAG y la cantidad de procesos paralelos en ellos.  No tiene sentido cargar registros que se analizan una vez por trimestre, antes de descargar datos para las m√©tricas de alta gerencia. <br></li></ul><br><h3>  Monitoreo de la duraci√≥n del lote nocturno </h3><br>  Tenemos un almacenamiento por lotes.  Por la noche, estamos en el proceso de construirlo, y es importante para nosotros asegurarnos de que haya suficiente noche para procesar el lote diario.  De lo contrario, durante las horas de trabajo, los analistas no tendr√°n suficientes recursos de almacenamiento para trabajar.  Regularmente resolvemos este problema de varias maneras: <br><br><ul><li>  Escala inversa.  No enviamos todos los datos, sino solo lo que necesitan los analistas.  Monitoreamos todas las tablas cargadas, y si una de ellas no se usa durante seis meses, entonces apagamos su carga. <br></li><li>  Desarrollo de capacidades.  Si entendemos que estamos limitados por las capacidades de la red, la cantidad de n√∫cleos o la capacidad del disco, entonces agregamos nodos de datos a Hadoop. <br></li><li>  Optimizaci√≥n del flujo de aire de los trabajadores.  Estamos haciendo todo lo posible para que cada parte de nuestro sistema se utilice al m√°ximo en cada momento del tiempo de construcci√≥n del almacenamiento. <br></li><li>  Refactorizaci√≥n de procesos no √≥ptimos.  Por ejemplo, consideramos la econom√≠a de un juego nuevo y nos lleva 5 minutos.  Pero despu√©s de un a√±o, los datos crecen y la misma solicitud se procesa durante 2 horas.  En alg√∫n momento, debemos reajustarnos al rec√°lculo incremental, aunque al principio esto puede parecer una complicaci√≥n innecesaria. <br></li></ul><br><h3>  Control de recursos </h3><br>  Es importante no solo tener tiempo para terminar de preparar el repositorio para el comienzo de la jornada laboral, sino tambi√©n monitorear la disponibilidad de sus recursos despu√©s de eso.  Con esto, pueden surgir dificultades con el tiempo.  En primer lugar, la raz√≥n es que los analistas escriben consultas sub√≥ptimas.  Una vez m√°s, los propios analistas se est√°n volviendo cada vez m√°s.  Lo m√°s simple en este caso: aumentar la capacidad del hardware.  Sin embargo, una solicitud no √≥ptima a√∫n ocupar√° todos los recursos disponibles.  Es decir, tarde o temprano comenzar√° a gastar dinero en hierro sin un beneficio significativo.  Por lo tanto, usamos varios otros enfoques. <br><br><ul><li>  Cita: dejamos a los usuarios al menos un poco de recursos.  S√≠, las solicitudes se ejecutar√°n lentamente, pero al menos lo har√°n. <br></li><li>  Monitoreo de los recursos consumidos: cu√°ntos n√∫cleos utilizan las solicitudes de los usuarios, quienes olvidaron usar particiones en Hadoop y tomaron toda la RAM, etc. Adem√°s, estos monitoreos son visibles para los propios analistas, y cuando algo no funciona para ellos, ellos mismos encuentran al culpable y tratan con ellos. el.  Si tuvi√©ramos pocos proyectos, rastrear√≠amos el consumo de recursos nosotros mismos.  Pero con tantos, tendr√≠amos que contratar un equipo de monitoreo separado y en constante expansi√≥n.  Y a la larga, esto no es razonable. <br></li><li>  Formaci√≥n voluntaria obligatoria del usuario.  El trabajo de los analistas no es escribir consultas de calidad en su repositorio.  Su trabajo es responder preguntas comerciales.  Y adem√°s de nosotros, el equipo del repositorio, a nadie le importa la calidad de las solicitudes de los analistas.  Por lo tanto, creamos preguntas frecuentes y presentaciones, realizamos conferencias para nuestros analistas, explicamos c√≥mo podemos trabajar con nuestro DataLake y c√≥mo no. <br></li></ul><br>  De hecho, dedicar tiempo a hacer que los datos est√©n disponibles es mucho m√°s importante que completarlos.  Si hay datos en el almacenamiento, pero no est√°n disponibles, entonces, desde el punto de vista empresarial, todav√≠a est√°n all√≠, y sus esfuerzos para descargar ya se han gastado. <br><br><h3>  Flexibilidad de la arquitectura </h3><br>  Es importante no olvidarse de la flexibilidad del DataLake construido y no tener miedo de cambiar la arquitectura al cambiar los factores de entrada: qu√© datos deben cargarse en el almacenamiento, qui√©n los usa y c√≥mo.  No creemos que nuestra arquitectura siempre permanecer√° sin cambios. <br><br>  Por ejemplo, lanzamos un nuevo juego m√≥vil.  Ella escribe JSON a Nginx desde los clientes, Nginx arroja datos a Kafka, los analizamos usando Spark y los ponemos en Hadoop.  Todo funciona, la tarea est√° cerrada. <br><br><img src="https://habrastorage.org/webt/mj/2i/cq/mj2icqljg45ckemxfjwjp1idafy.jpeg"><br><br>  Pasaron un par de meses y, en el almacenamiento, todos los procesos del lote nocturno comenzaron a durar m√°s.  Estamos empezando a descubrir cu√°l es el problema: resulta que el juego "dispar√≥", se generaron 50 veces m√°s datos y Spark no pudo hacer frente al an√°lisis JSON, arrastrando la mitad de los recursos de almacenamiento.  Inicialmente, todos los datos se enviaron a un tema de Kafka, y Spark los clasific√≥ en diferentes entidades.  Pedimos a los desarrolladores de juegos que compartan datos sobre clientes con diferentes entidades y los viertan en temas separados de Kafka.  Se hizo m√°s f√°cil, pero no por mucho tiempo.  Luego decidimos cambiar del an√°lisis JSON diario a cada hora.  Sin embargo, la instalaci√≥n de almacenamiento comenz√≥ a construirse no solo por la noche, sino durante todo el d√≠a, lo que no era deseable para nosotros.  Despu√©s de tales intentos, para resolver este problema, abandonamos Spark e implementamos ClickHouse. <br><br><img src="https://habrastorage.org/webt/wv/xw/bo/wvxwbo1pgsxynb8u3lif75uttfw.jpeg"><br><br>  Tiene un gran motor de an√°lisis JSON que descompone instant√°neamente los datos en tablas.  Primero enviamos informaci√≥n de Kafka a ClickHouse, y desde all√≠ la recogemos en Hadoop.  Esto resolvi√≥ completamente nuestro problema. <br><br>  Por supuesto, tratamos de no reproducir sistemas de zool√≥gicos en nuestro almacenamiento DataLake, pero intentamos seleccionar las tecnolog√≠as m√°s adecuadas para tareas espec√≠ficas. <br><br><h1>  ¬øVali√≥ la pena? </h1><br>  ¬øVali√≥ la pena implementar Hadoop, un sistema de control de calidad, lidiar con Airflow y establecer procesos comerciales?  Por supuesto que vali√≥ la pena: <br><br><ul><li>  La empresa tiene informaci√≥n actualizada sobre todos los proyectos, que est√° disponible en servicios individuales. <br></li><li>  Los usuarios de nuestro sistema, desde dise√±adores de juegos hasta gerentes, dejaron de tomar decisiones solo sobre la base de la intuici√≥n y cambiaron a enfoques basados ‚Äã‚Äãen datos. <br></li><li>  Les dimos a los analistas las herramientas para hacer su propia ciencia de cohetes.  Ahora responden consultas comerciales complejas, crean modelos de pron√≥stico, sistemas de recomendaci√≥n, mejoran los juegos.  En realidad, para esto trabajamos en BI-DWH. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/479900/">https://habr.com/ru/post/479900/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../479890/index.html">Problemas y tareas de implementaci√≥n del concepto de Internet de las cosas</a></li>
<li><a href="../479892/index.html">Acerca de los complementos de Gradle, subprocesos m√∫ltiples en sistemas distribuidos y automatizaci√≥n de monitoreo: video de Yandex. Metap de dinero</a></li>
<li><a href="../479894/index.html">De Hyper-V a VMware y viceversa: convertir discos virtuales</a></li>
<li><a href="../479896/index.html">S√°bado: Pensamientos de un programador sobre econom√≠a, Marx, Lenin y Capital</a></li>
<li><a href="../479898/index.html">Verdad desnuda</a></li>
<li><a href="../479902/index.html">IntelliJ IDEA 2019.3: optimizaci√≥n del rendimiento y mejora de la calidad</a></li>
<li><a href="../479904/index.html">Qu√© es NFC y c√≥mo funciona. ¬øActualizar lo b√°sico?</a></li>
<li><a href="../479906/index.html">Resumen de la industria FinTech: las tecnolog√≠as financieras m√°s prometedoras de finales de 2019</a></li>
<li><a href="../479908/index.html">C√≥mo AR / VR de Apple se enfrent√≥ a una realidad brutal</a></li>
<li><a href="../479910/index.html">C√≥mo abrir un t√∫nel en Kubernetes pod o contenedor con tcpserver y netcat</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
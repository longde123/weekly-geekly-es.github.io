<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📟 👧🏿 😑 Vision industrielle vs intuition humaine: algorithmes pour perturber le fonctionnement des programmes de reconnaissance d'objets 🏯 🧣 🧦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La logique des machines est impeccable, elles ne font pas d'erreurs si leur algorithme fonctionne correctement et les paramètres réglés correspondent ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vision industrielle vs intuition humaine: algorithmes pour perturber le fonctionnement des programmes de reconnaissance d'objets</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/445372/"><img src="https://habrastorage.org/webt/s9/kf/68/s9kf68iyyoikag7yeexxfaxrp1e.jpeg"><br><br>  La logique des machines est impeccable, elles ne font pas d'erreurs si leur algorithme fonctionne correctement et les paramètres réglés correspondent aux normes nécessaires.  Demandez à la voiture de choisir un itinéraire du point A au point B, et elle construira la plus optimale, en tenant compte de la distance, de la consommation de carburant, de la présence de stations-service, etc.  Ceci est un pur calcul.  La voiture ne dira pas: "Allons sur cette route, je ressens mieux cette route."  Peut-être que les voitures sont meilleures que nous dans la vitesse des calculs, mais l'intuition est toujours l'un de nos atouts.  L'humanité a passé des décennies à créer une machine semblable au cerveau humain.  Mais y a-t-il tant de points communs entre eux?  Aujourd'hui, nous examinerons une étude dans laquelle des scientifiques, doutant de la "vision" inégalée des machines sur la base de réseaux de neurones convolutifs, ont mené une expérience pour tromper un système de reconnaissance d'objets en utilisant un algorithme dont la tâche était de créer des images "fausses".  Dans quelle mesure l'activité de sabotage de l'algorithme a-t-elle réussi, les gens ont-ils mieux géré la reconnaissance que les voitures et qu'est-ce que cette étude apportera à l'avenir de cette technologie?  Nous trouverons des réponses dans le rapport des scientifiques.  Allons-y. <a name="habracut"></a><br><br><h3>  Base d'étude </h3><br>  Les technologies de reconnaissance d'objets utilisant des réseaux de neurones convolutifs (SNS) permettent à la machine, en gros, de distinguer un cygne du nombre 9 ou un chat d'un vélo.  Cette technologie se développe assez rapidement et est actuellement appliquée dans divers domaines, dont le plus évident est la production de véhicules sans pilote.  Beaucoup sont d'avis que le SCN du système de reconnaissance des objets peut être considéré comme un modèle de vision humaine.  Cependant, cette déclaration est trop forte, en raison du facteur humain.  Le truc, c'est que tromper une voiture s'est avéré plus facile que de tromper une personne (du moins en matière de reconnaissance d'objets).  Les systèmes SNA sont très vulnérables aux effets d'algorithmes malveillants (hostiles, si vous le souhaitez), ce qui les empêchera à tous égards d'exécuter correctement leur tâche, créant des images qui seront incorrectement classées par le système SNA. <br><br>  Les chercheurs divisent ces images en deux catégories: «tromper» (changer complètement la cible) et «embarrassant» (changer partiellement la cible).  Les premières sont des images dénuées de sens qui sont reconnues par le système comme quelque chose de familier.  Par exemple, un ensemble de lignes peut être classé comme un «baseball» et le bruit numérique multicolore comme un «tatou».  La deuxième catégorie d'images («embarrassantes») sont des images qui, dans des conditions normales, seraient classées correctement, mais l'algorithme malveillant les déforme légèrement, exagérant en disant, aux yeux du système SNA.  Par exemple, le numéro manuscrit 6 sera classé numéro 5 en raison d'un petit complément de plusieurs pixels. <br><br>  Imaginez ce que peuvent faire de tels algorithmes.  Il vaut la peine d'échanger la classification des panneaux routiers pour le transport autonome et les accidents seront inévitables. <br><br>  Voici les «fausses» images qui trompent le système SNA, entraînées à reconnaître les objets, et comment un système similaire les a classées. <br><br><img src="https://habrastorage.org/webt/bl/wf/ze/blwfzeyvqwjwhtqmk65ykrbulrc.jpeg"><br>  <i>Image n ° 1</i> <br><br>  Explication de la série: <br><br><ul><li>  <b>et</b> - images "frauduleuses" codées indirectement; </li><li>  <b>b</b> - images "frauduleuses" directement codées; </li><li>  <b>c</b> - images «embarrassantes», obligeant le système à classer un chiffre comme un autre; </li><li>  <b>d</b> - L'attaque LaVAN (bruit contradictoire / malveillant localisé et visible) peut conduire à une classification incorrecte, même lorsque le «bruit» n'est localisé qu'en un point (dans le coin inférieur droit). </li><li>  <b>e</b> - objets tridimensionnels mal classés sous différents angles. </li></ul><br>  La chose la plus curieuse à ce sujet est qu'une personne peut ne pas succomber à duper un algorithme malveillant et classer correctement les images, en fonction de l'intuition.  Auparavant, comme le disent les scientifiques, personne n'a fait de comparaison pratique des capacités d'une machine et d'une personne dans une expérience pour contrer des algorithmes malveillants de fausses images.  C'est ce que les chercheurs ont décidé de faire. <br><br>  Pour cela, plusieurs images réalisées par des algorithmes malveillants ont été préparées.  Les sujets ont été informés que la machine classait ces images (de face) comme des objets familiers, c'est-à-dire  la machine ne les a pas reconnus correctement.  La tâche des sujets était de déterminer exactement comment la machine classait ces images, c'est-à-dire  ce qu'ils pensent que la machine a vu dans les images, est-ce que cette classification est vraie, etc. <br><br>  Au total, 8 expériences ont été réalisées, dans lesquelles 5 types d'images malveillantes créées sans prise en compte de la vision humaine ont été utilisées.  En d'autres termes, ils sont créés par machine pour machine.  Les résultats de ces expériences se sont avérés très divertissants, mais nous ne les gâterons pas et ne considérerons pas tout dans l'ordre. <br><br><h3>  Résultats de l'expérience </h3><br><h2>  Expérience n ° 1: tromper les images avec des balises non valides </h2><br>  Dans la première expérience, 48 images trompées ont été utilisées, créées par l'algorithme pour contrer le système de reconnaissance basé sur le SNA appelé AlexNet.  Ce système a classé ces images comme «équipement» et «beignet» ( <b>2a</b> ). <br><br><img src="https://habrastorage.org/webt/fg/yt/0h/fgyt0hewtb9akm-4nlbb-movqxo.jpeg"><br>  <i>Image n ° 2</i> <br><br>  Au cours de chaque tentative, la personne testée, dont 200 personnes, a vu une image dupante et deux marques, soit  étiquettes de classification: étiquette SNS système et aléatoire parmi les 47 autres images.  Les sujets devaient choisir l'étiquette créée par la machine. <br><br>  En conséquence, la plupart des sujets ont choisi de choisir une étiquette créée par la machine, plutôt qu'une étiquette d'un algorithme malveillant.  Précision de classification, c.-à-d.  le degré de consentement du sujet avec la machine était de 74%.  Statistiquement, 98% des sujets ont choisi des étiquettes de machine à un niveau supérieur à l'aléatoire statistique ( <b>2d</b> , «% des sujets sont d'accord avec la machine»).  94% des images montraient un alignement homme-machine très élevé, c'est-à-dire que sur 48, seules 3 images étaient classées par des personnes différemment d'une machine. <br><br>  Ainsi, les sujets ont montré qu'une personne est capable de partager une image réelle et un imbécile, c'est-à-dire d'agir selon un programme basé sur le SCN. <br><br><h2>  Expérience n ° 2: premier choix contre deuxième </h2><br>  Les chercheurs ont posé la question - en raison de quels sujets ont-ils pu reconnaître si bien les images et les séparer des marques erronées et des images dupes?  Les sujets ont peut-être noté l'anneau orange-jaune comme un «beignet», car en réalité le beignet a exactement cette forme et à peu près la même couleur.  En reconnaissance, des associations et des choix intuitifs basés sur l'expérience et les connaissances pourraient aider une personne. <br><br>  Pour vérifier cela, l'étiquette aléatoire a été remplacée par celle qui a été sélectionnée par la machine comme deuxième option de classification possible.  Par exemple, AlexNet a classé l'anneau orange-jaune comme un «beignet», et la deuxième option pour ce programme était «bretzel». <br><br>  Les sujets ont été confrontés à la tâche de choisir la première marque de la machine ou celle qui occupait la deuxième place pour les 48 images ( <b>2</b> ). <br><br>  Le graphique au centre de l'image <b>2d</b> montre les résultats de ce test: 91% des sujets ont choisi la première version de l'étiquette, et le niveau de correspondance homme-machine était de 71%. <br><br><h2>  Expérience n ° 3: classification multi-thread </h2><br>  Les expériences décrites ci-dessus sont assez simples compte tenu du fait que les sujets ont le choix entre deux réponses possibles (balise machine et balise aléatoire).  En fait, la machine en cours de reconnaissance d'image parcourt des centaines voire des milliers d'options d'étiquettes avant de choisir la plus adaptée. <br><br>  Dans ce test, toutes les notes pour 48 images étaient immédiatement devant les sujets.  Ils devaient choisir parmi cet ensemble le plus adapté à chaque image. <br><br>  En conséquence, 88% des sujets ont choisi exactement les mêmes étiquettes que la machine, et le degré de coordination était de 79%.  Un fait intéressant est que même en choisissant la mauvaise étiquette que la machine a choisie, les sujets dans 63% de ces cas ont choisi l'une des 5 meilleures étiquettes.  Autrement dit, toutes les marques sur la voiture sont ordonnées dans une liste des plus appropriées aux plus inappropriées (exemple exagéré: «bagel», «bretzel», «anneau en caoutchouc», «pneu», etc. jusqu'à «faucon dans le ciel nocturne» ) <br><br><h2>  Expérience n ° 3b: "qu'est-ce que c'est?" </h2><br>  Dans ce test, les scientifiques ont légèrement modifié les règles.  Au lieu de leur demander de «deviner» quelle étiquette la machine choisira pour une image particulière, on a simplement demandé aux sujets ce qu'ils voyaient devant eux. <br><br>  Les systèmes de reconnaissance basés sur des réseaux de neurones convolutifs sélectionnent l'étiquette appropriée pour une image particulière.  Il s'agit d'un processus assez clair et logique.  Dans ce test, les sujets présentent une pensée intuitive. <br><br>  En conséquence, 90% des sujets ont choisi une étiquette, qui a également été choisie par la machine.  L'alignement homme-machine parmi les images était de 81%. <br><br><h2>  Expérience 4: Bruit statique de la télévision </h2><br>  Les scientifiques notent que dans les expériences précédentes, les images sont inhabituelles, mais elles ont des caractéristiques distinctes qui peuvent inciter les sujets à faire le bon (ou le mauvais) choix d'étiquette.  Par exemple, l'image «baseball» n'est pas une balle, mais il y a des lignes et des couleurs qui sont présentes sur une vraie balle de baseball.  Il s'agit d'une caractéristique distinctive frappante.  Mais si l'image n'a pas de telles caractéristiques, mais est essentiellement un bruit statique, une personne peut-elle reconnaître au moins quelque chose dessus?  C'est ce qu'il a été décidé de vérifier. <br><br><img src="https://habrastorage.org/webt/je/9o/sm/je9osmgxp99wmexrvqmzndviqpk.jpeg"><br>  <i>Image n ° 3a</i> <br><br>  Dans ce test, il y avait 8 images avec des statiques devant les sujets, que le système SNS reconnaît comme un objet spécifique (par exemple, un oiseau-zaryanka).  De plus, devant les sujets, il y avait une étiquette et des images normales associées (8 images de statiques, 1 étiquette «zaryanka» et 5 photos de cet oiseau).  Le sujet du test devait sélectionner 1 image sur 8 de l'électricité statique qui convenait le mieux à l'une ou l'autre étiquette. <br><br>  Vous pouvez vous tester.  Ci-dessus, vous voyez un exemple d'un tel test.  Laquelle des trois images convient le mieux au tag «zaryanka» et pourquoi? <br><br>  81% des sujets ont choisi l'étiquette choisie par la machine.  Dans le même temps, 75% des images ont été étiquetées par les sujets avec l'étiquette la plus appropriée de l'avis de la machine (à partir d'un certain nombre d'options, comme nous l'avons mentionné précédemment). <br><br>  Pour ce test particulier, vous pouvez avoir des questions, tout comme le mien.  Le fait est que dans la statique proposée (ci-dessus), je vois personnellement trois caractéristiques prononcées qui les distinguent les unes des autres.  Et seulement dans une image, cette fonctionnalité ressemble fortement à la même zaryanka (je pense que vous comprenez quelle image des trois).  Par conséquent, mon opinion personnelle et très subjective est qu'un tel test n'est pas particulièrement indicatif.  Bien que peut-être parmi d'autres options pour les images statiques étaient vraiment indiscernables et méconnaissables. <br><br><h2>  Expérience n ° 5: chiffres «douteux» </h2><br>  Les tests décrits ci-dessus étaient basés sur des images qui ne peuvent pas être immédiatement entièrement et sans aucun doute classées comme l'un ou l'autre objet.  Il y a toujours une fraction de doute.  Les images trompeuses sont assez simples dans leur travail - gâcher l'image au-delà de la reconnaissance.  Mais il existe un deuxième type d'algorithmes malveillants qui n'ajoutent (ou suppriment) qu'un petit détail dans l'image, ce qui peut complètement violer le système de reconnaissance par le système SNA.  Ajoutez quelques pixels et le chiffre 6 se transforme comme par magie en chiffre 5 ( <b>1s</b> ). <br><br>  Les scientifiques considèrent ces algorithmes comme l'un des plus dangereux.  Vous pouvez légèrement modifier l'étiquette d'image et le véhicule sans pilote considère incorrectement le panneau de limitation de vitesse (par exemple, 75 au lieu de 45), ce qui peut entraîner de tristes conséquences. <br><br><img src="https://habrastorage.org/webt/9k/wr/h9/9kwrh9bcsqbqyolfpdgc1crqcfg.jpeg"><br>  <i>Image # 3b</i> <br><br>  Dans ce test, les scientifiques ont suggéré que les sujets choisissent la mauvaise réponse, mais plutôt la mauvaise.  Dans le test, 100 images numériques modifiées par un algorithme malveillant ont été utilisées (le LeNet SNA a changé leur classification, c'est-à-dire que l'algorithme malveillant a fonctionné avec succès).  Les sujets devaient dire quel chiffre à leur avis la machine voyait.  Comme prévu, 89% des sujets ont réussi ce test. <br><br><h2>  Expérience 6: photos et "distorsion" localisée </h2><br>  Les scientifiques notent que non seulement des systèmes de reconnaissance d'objets se développent, mais également des algorithmes malveillants qui les empêchent de le faire.  Auparavant, pour que l'image soit classée incorrectement, il fallait déformer (changer, supprimer, endommager, etc.) 14% de tous les pixels de l'image cible.  Maintenant, ce chiffre est devenu beaucoup plus petit.  Il suffit d'ajouter une petite image à l'intérieur de la cible et le classement sera violé. <br><br><img src="https://habrastorage.org/webt/6i/sz/1p/6isz1pvm_j-zzxt1mkeq2krmlts.jpeg"><br>  <i>Image n ° 4</i> <br><br>  Dans ce test, un algorithme LaVAN malveillant assez récent a été utilisé, qui place une petite image localisée à un point sur la photo cible.  En conséquence, le système de reconnaissance d'objets peut reconnaître le métro comme une boîte de lait ( <b>4a</b> ).  Les caractéristiques les plus importantes de cet algorithme sont précisément la faible proportion de pixels endommagés (seulement 2%) de l'image cible et l'absence de la nécessité de la déformer dans son intégralité ou la partie principale (la plus importante) de celle-ci. <br><br>  Dans le test, 22 images endommagées par LaVAN ont été utilisées (le système de reconnaissance SNA Inception V3 a été piraté avec succès par cet algorithme).  Les sujets étaient censés classer l'encart malveillant sur la photo.  87% des sujets ont réussi à le faire. <br><br><h2>  Expérience 7: objets tridimensionnels </h2><br>  Les images que nous avons vues précédemment sont en deux dimensions, comme toute photo, photo ou coupure de journal.  La plupart des algorithmes malveillants manipulent avec succès de telles images.  Cependant, ces ravageurs ne peuvent fonctionner que sous certaines conditions, c'est-à-dire qu'ils ont un certain nombre de limitations: <br><br><ul><li>  complexité: uniquement des images en deux dimensions; </li><li>  application pratique: les modifications malveillantes ne sont possibles que sur les systèmes qui lisent les images numériques reçues, et non les images des capteurs et des capteurs; </li><li>  stabilité: une attaque malveillante perd de sa force si vous faites pivoter une image bidimensionnelle (redimensionner, recadrer, affiner, etc.); </li><li>  les gens: nous voyons le monde et les objets qui nous entourent en 3D sous différents angles, sous différents éclairages, et non sous la forme d'images numériques bidimensionnelles prises sous un seul angle. </li></ul><br><br>  Mais, comme nous le savons, les progrès n'ont pas épargné les algorithmes malveillants.  Parmi eux figurait celui qui est capable non seulement de déformer les images bidimensionnelles, mais aussi les images tridimensionnelles, ce qui conduit à une classification incorrecte par le système de reconnaissance d'objets.  Lors de l'utilisation d'un logiciel pour les graphiques en trois dimensions, un tel algorithme induit en erreur les classificateurs basés sur le SNA (dans ce cas, le programme Inception V3) à partir de différentes distances et angles de vue.  La chose la plus surprenante est que de telles images 3D trompeuses peuvent être imprimées sur une imprimante appropriée, c'est-à-dire  créer un véritable objet physique, et le système de reconnaissance d'objets ne le classera toujours pas correctement (par exemple, une orange comme perceuse électrique).  Et tout cela grâce à des changements mineurs dans la texture de l'image cible ( <b>4b</b> ). <br><br>  Pour un système de reconnaissance d'objets, un tel algorithme malveillant est un adversaire sérieux.  Mais l'homme n'est pas une machine, il voit et pense différemment.  Dans ce test, avant les sujets, il y avait des images d'objets tridimensionnels dans lesquels il y avait les changements de texture décrits ci-dessus sous trois angles.  Les sujets ont également reçu la note correcte et erronée.  Ils devaient déterminer quelles étiquettes sont correctes, lesquelles ne le sont pas et pourquoi, c'est-à-dire  si les sujets testés voient des changements de texture dans les images. <br><br>  En conséquence, 83% des sujets ont réussi la tâche. <br><br>  Pour une connaissance plus détaillée des nuances de l'étude, je vous recommande fortement de consulter le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport des scientifiques</a> . <br><br>  Et sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce lien,</a> vous trouverez les fichiers d'images, de données et de code qui ont été utilisés dans l'étude. <br><br><h3>  Épilogue </h3><br>  Les travaux menés ont permis aux scientifiques de tirer une conclusion simple et assez évidente: l'intuition humaine peut être une source de données très importantes et un outil pour prendre la bonne décision et / ou la perception de l'information.  Une personne est en mesure de comprendre intuitivement comment le système de reconnaissance d'objets se comportera, quelles étiquettes il choisira et pourquoi. <br><br>  Les raisons pour lesquelles il est plus facile pour une personne de voir une image réelle et de la reconnaître correctement plusieurs.  Le plus évident est la méthode d'obtention de l'information: la machine reçoit une image sous forme numérique, et une personne la voit de ses propres yeux.  Pour une machine, une image est un ensemble de données dont vous pouvez modifier la classification.  Pour nous, l'image d'une rame de métro sera toujours une rame de métro, pas une canette de lait, car nous la voyons. <br><br>  Les scientifiques soulignent également que ces tests sont difficiles à évaluer, car une personne n'est pas une machine et une machine n'est pas une personne.  Par exemple, les chercheurs parlent du test avec un «beignet» et une «roue».  Ces images sont similaires au «beignet» et à la «roue», car le système de reconnaissance les classe de cette façon.  Une personne voit qu'elle ressemble à un «beignet» et à une «roue», mais ce n'est pas le cas.  Il s'agit de la différence fondamentale dans la perception des informations visuelles entre une personne et un programme. <br><br>  Merci de votre attention, restez curieux et bonne semaine de travail, les gars. <br><br>  Merci de rester avec nous.  Aimez-vous nos articles?  Vous voulez voir des matériaux plus intéressants?  Soutenez-nous en passant une commande ou en le recommandant à vos amis, une <b>réduction de 30% pour les utilisateurs Habr sur un analogue unique de serveurs d'entrée de gamme que nous avons inventés pour vous:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Toute la vérité sur VPS (KVM) E5-2650 v4 (6 cœurs) 10 Go DDR4 240 Go SSD 1 Gbps à partir de 20 $ ou comment diviser le serveur?</a>  (les options sont disponibles avec RAID1 et RAID10, jusqu'à 24 cœurs et jusqu'à 40 Go de DDR4). <br><br>  <b>VPS (KVM) E5-2650 v4 (6 cœurs) 10 Go DDR4 240 Go SSD 1 Gbit / s jusqu'à l'été gratuitement</b> lorsque vous payez pour une période de six mois, vous pouvez commander <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  <b>Dell R730xd 2 fois moins cher?</b>  Nous avons seulement <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2 x Intel Dodeca-Core Xeon E5-2650v4 128 Go DDR4 6x480 Go SSD 1 Gbps 100 TV à partir de 249 $</a> aux Pays-Bas et aux États-Unis!</b>  Pour en savoir plus sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">création d'un bâtiment d'infrastructure.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">classe utilisant des serveurs Dell R730xd E5-2650 v4 coûtant 9 000 euros pour un sou?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr445372/">https://habr.com/ru/post/fr445372/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr445360/index.html">5 tâches typiques pour les interviews JavaScript: analyse et solutions</a></li>
<li><a href="../fr445362/index.html">Le livre "Distributed Systems. Modèles de conception</a></li>
<li><a href="../fr445366/index.html">Comment accélérer le cryptage selon GOST 28147-89 sur le processeur Baikal-T1 en raison du bloc SIMD</a></li>
<li><a href="../fr445368/index.html">Test de charge d'un jeu avec quelques centaines de milliers d'utilisateurs virtuels</a></li>
<li><a href="../fr445370/index.html">Analyse TSDB dans Prométhée 2</a></li>
<li><a href="../fr445378/index.html">Labyrinthes: classification, génération, recherche de solutions</a></li>
<li><a href="../fr445380/index.html">Le PHP moderne est beau et productif</a></li>
<li><a href="../fr445384/index.html">Mission Chang'e-4 - équipement scientifique sur le module d'atterrissage et le satellite répéteur</a></li>
<li><a href="../fr445390/index.html">IDE d'une personne normale ou pourquoi nous avons choisi Monaco</a></li>
<li><a href="../fr445392/index.html">Remarketing dynamique MyTarget: recommandations de produits non personnels</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ“Ÿ ğŸ‘§ğŸ¿ ğŸ˜‘ Vision industrielle vs intuition humaine: algorithmes pour perturber le fonctionnement des programmes de reconnaissance d'objets ğŸ¯ ğŸ§£ ğŸ§¦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La logique des machines est impeccable, elles ne font pas d'erreurs si leur algorithme fonctionne correctement et les paramÃ¨tres rÃ©glÃ©s correspondent ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vision industrielle vs intuition humaine: algorithmes pour perturber le fonctionnement des programmes de reconnaissance d'objets</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/445372/"><img src="https://habrastorage.org/webt/s9/kf/68/s9kf68iyyoikag7yeexxfaxrp1e.jpeg"><br><br>  La logique des machines est impeccable, elles ne font pas d'erreurs si leur algorithme fonctionne correctement et les paramÃ¨tres rÃ©glÃ©s correspondent aux normes nÃ©cessaires.  Demandez Ã  la voiture de choisir un itinÃ©raire du point A au point B, et elle construira la plus optimale, en tenant compte de la distance, de la consommation de carburant, de la prÃ©sence de stations-service, etc.  Ceci est un pur calcul.  La voiture ne dira pas: "Allons sur cette route, je ressens mieux cette route."  Peut-Ãªtre que les voitures sont meilleures que nous dans la vitesse des calculs, mais l'intuition est toujours l'un de nos atouts.  L'humanitÃ© a passÃ© des dÃ©cennies Ã  crÃ©er une machine semblable au cerveau humain.  Mais y a-t-il tant de points communs entre eux?  Aujourd'hui, nous examinerons une Ã©tude dans laquelle des scientifiques, doutant de la "vision" inÃ©galÃ©e des machines sur la base de rÃ©seaux de neurones convolutifs, ont menÃ© une expÃ©rience pour tromper un systÃ¨me de reconnaissance d'objets en utilisant un algorithme dont la tÃ¢che Ã©tait de crÃ©er des images "fausses".  Dans quelle mesure l'activitÃ© de sabotage de l'algorithme a-t-elle rÃ©ussi, les gens ont-ils mieux gÃ©rÃ© la reconnaissance que les voitures et qu'est-ce que cette Ã©tude apportera Ã  l'avenir de cette technologie?  Nous trouverons des rÃ©ponses dans le rapport des scientifiques.  Allons-y. <a name="habracut"></a><br><br><h3>  Base d'Ã©tude </h3><br>  Les technologies de reconnaissance d'objets utilisant des rÃ©seaux de neurones convolutifs (SNS) permettent Ã  la machine, en gros, de distinguer un cygne du nombre 9 ou un chat d'un vÃ©lo.  Cette technologie se dÃ©veloppe assez rapidement et est actuellement appliquÃ©e dans divers domaines, dont le plus Ã©vident est la production de vÃ©hicules sans pilote.  Beaucoup sont d'avis que le SCN du systÃ¨me de reconnaissance des objets peut Ãªtre considÃ©rÃ© comme un modÃ¨le de vision humaine.  Cependant, cette dÃ©claration est trop forte, en raison du facteur humain.  Le truc, c'est que tromper une voiture s'est avÃ©rÃ© plus facile que de tromper une personne (du moins en matiÃ¨re de reconnaissance d'objets).  Les systÃ¨mes SNA sont trÃ¨s vulnÃ©rables aux effets d'algorithmes malveillants (hostiles, si vous le souhaitez), ce qui les empÃªchera Ã  tous Ã©gards d'exÃ©cuter correctement leur tÃ¢che, crÃ©ant des images qui seront incorrectement classÃ©es par le systÃ¨me SNA. <br><br>  Les chercheurs divisent ces images en deux catÃ©gories: Â«tromperÂ» (changer complÃ¨tement la cible) et Â«embarrassantÂ» (changer partiellement la cible).  Les premiÃ¨res sont des images dÃ©nuÃ©es de sens qui sont reconnues par le systÃ¨me comme quelque chose de familier.  Par exemple, un ensemble de lignes peut Ãªtre classÃ© comme un Â«baseballÂ» et le bruit numÃ©rique multicolore comme un Â«tatouÂ».  La deuxiÃ¨me catÃ©gorie d'images (Â«embarrassantesÂ») sont des images qui, dans des conditions normales, seraient classÃ©es correctement, mais l'algorithme malveillant les dÃ©forme lÃ©gÃ¨rement, exagÃ©rant en disant, aux yeux du systÃ¨me SNA.  Par exemple, le numÃ©ro manuscrit 6 sera classÃ© numÃ©ro 5 en raison d'un petit complÃ©ment de plusieurs pixels. <br><br>  Imaginez ce que peuvent faire de tels algorithmes.  Il vaut la peine d'Ã©changer la classification des panneaux routiers pour le transport autonome et les accidents seront inÃ©vitables. <br><br>  Voici les Â«faussesÂ» images qui trompent le systÃ¨me SNA, entraÃ®nÃ©es Ã  reconnaÃ®tre les objets, et comment un systÃ¨me similaire les a classÃ©es. <br><br><img src="https://habrastorage.org/webt/bl/wf/ze/blwfzeyvqwjwhtqmk65ykrbulrc.jpeg"><br>  <i>Image n Â° 1</i> <br><br>  Explication de la sÃ©rie: <br><br><ul><li>  <b>et</b> - images "frauduleuses" codÃ©es indirectement; </li><li>  <b>b</b> - images "frauduleuses" directement codÃ©es; </li><li>  <b>c</b> - images Â«embarrassantesÂ», obligeant le systÃ¨me Ã  classer un chiffre comme un autre; </li><li>  <b>d</b> - L'attaque LaVAN (bruit contradictoire / malveillant localisÃ© et visible) peut conduire Ã  une classification incorrecte, mÃªme lorsque le Â«bruitÂ» n'est localisÃ© qu'en un point (dans le coin infÃ©rieur droit). </li><li>  <b>e</b> - objets tridimensionnels mal classÃ©s sous diffÃ©rents angles. </li></ul><br>  La chose la plus curieuse Ã  ce sujet est qu'une personne peut ne pas succomber Ã  duper un algorithme malveillant et classer correctement les images, en fonction de l'intuition.  Auparavant, comme le disent les scientifiques, personne n'a fait de comparaison pratique des capacitÃ©s d'une machine et d'une personne dans une expÃ©rience pour contrer des algorithmes malveillants de fausses images.  C'est ce que les chercheurs ont dÃ©cidÃ© de faire. <br><br>  Pour cela, plusieurs images rÃ©alisÃ©es par des algorithmes malveillants ont Ã©tÃ© prÃ©parÃ©es.  Les sujets ont Ã©tÃ© informÃ©s que la machine classait ces images (de face) comme des objets familiers, c'est-Ã -dire  la machine ne les a pas reconnus correctement.  La tÃ¢che des sujets Ã©tait de dÃ©terminer exactement comment la machine classait ces images, c'est-Ã -dire  ce qu'ils pensent que la machine a vu dans les images, est-ce que cette classification est vraie, etc. <br><br>  Au total, 8 expÃ©riences ont Ã©tÃ© rÃ©alisÃ©es, dans lesquelles 5 types d'images malveillantes crÃ©Ã©es sans prise en compte de la vision humaine ont Ã©tÃ© utilisÃ©es.  En d'autres termes, ils sont crÃ©Ã©s par machine pour machine.  Les rÃ©sultats de ces expÃ©riences se sont avÃ©rÃ©s trÃ¨s divertissants, mais nous ne les gÃ¢terons pas et ne considÃ©rerons pas tout dans l'ordre. <br><br><h3>  RÃ©sultats de l'expÃ©rience </h3><br><h2>  ExpÃ©rience n Â° 1: tromper les images avec des balises non valides </h2><br>  Dans la premiÃ¨re expÃ©rience, 48 images trompÃ©es ont Ã©tÃ© utilisÃ©es, crÃ©Ã©es par l'algorithme pour contrer le systÃ¨me de reconnaissance basÃ© sur le SNA appelÃ© AlexNet.  Ce systÃ¨me a classÃ© ces images comme Â«Ã©quipementÂ» et Â«beignetÂ» ( <b>2a</b> ). <br><br><img src="https://habrastorage.org/webt/fg/yt/0h/fgyt0hewtb9akm-4nlbb-movqxo.jpeg"><br>  <i>Image n Â° 2</i> <br><br>  Au cours de chaque tentative, la personne testÃ©e, dont 200 personnes, a vu une image dupante et deux marques, soit  Ã©tiquettes de classification: Ã©tiquette SNS systÃ¨me et alÃ©atoire parmi les 47 autres images.  Les sujets devaient choisir l'Ã©tiquette crÃ©Ã©e par la machine. <br><br>  En consÃ©quence, la plupart des sujets ont choisi de choisir une Ã©tiquette crÃ©Ã©e par la machine, plutÃ´t qu'une Ã©tiquette d'un algorithme malveillant.  PrÃ©cision de classification, c.-Ã -d.  le degrÃ© de consentement du sujet avec la machine Ã©tait de 74%.  Statistiquement, 98% des sujets ont choisi des Ã©tiquettes de machine Ã  un niveau supÃ©rieur Ã  l'alÃ©atoire statistique ( <b>2d</b> , Â«% des sujets sont d'accord avec la machineÂ»).  94% des images montraient un alignement homme-machine trÃ¨s Ã©levÃ©, c'est-Ã -dire que sur 48, seules 3 images Ã©taient classÃ©es par des personnes diffÃ©remment d'une machine. <br><br>  Ainsi, les sujets ont montrÃ© qu'une personne est capable de partager une image rÃ©elle et un imbÃ©cile, c'est-Ã -dire d'agir selon un programme basÃ© sur le SCN. <br><br><h2>  ExpÃ©rience n Â° 2: premier choix contre deuxiÃ¨me </h2><br>  Les chercheurs ont posÃ© la question - en raison de quels sujets ont-ils pu reconnaÃ®tre si bien les images et les sÃ©parer des marques erronÃ©es et des images dupes?  Les sujets ont peut-Ãªtre notÃ© l'anneau orange-jaune comme un Â«beignetÂ», car en rÃ©alitÃ© le beignet a exactement cette forme et Ã  peu prÃ¨s la mÃªme couleur.  En reconnaissance, des associations et des choix intuitifs basÃ©s sur l'expÃ©rience et les connaissances pourraient aider une personne. <br><br>  Pour vÃ©rifier cela, l'Ã©tiquette alÃ©atoire a Ã©tÃ© remplacÃ©e par celle qui a Ã©tÃ© sÃ©lectionnÃ©e par la machine comme deuxiÃ¨me option de classification possible.  Par exemple, AlexNet a classÃ© l'anneau orange-jaune comme un Â«beignetÂ», et la deuxiÃ¨me option pour ce programme Ã©tait Â«bretzelÂ». <br><br>  Les sujets ont Ã©tÃ© confrontÃ©s Ã  la tÃ¢che de choisir la premiÃ¨re marque de la machine ou celle qui occupait la deuxiÃ¨me place pour les 48 images ( <b>2</b> ). <br><br>  Le graphique au centre de l'image <b>2d</b> montre les rÃ©sultats de ce test: 91% des sujets ont choisi la premiÃ¨re version de l'Ã©tiquette, et le niveau de correspondance homme-machine Ã©tait de 71%. <br><br><h2>  ExpÃ©rience n Â° 3: classification multi-thread </h2><br>  Les expÃ©riences dÃ©crites ci-dessus sont assez simples compte tenu du fait que les sujets ont le choix entre deux rÃ©ponses possibles (balise machine et balise alÃ©atoire).  En fait, la machine en cours de reconnaissance d'image parcourt des centaines voire des milliers d'options d'Ã©tiquettes avant de choisir la plus adaptÃ©e. <br><br>  Dans ce test, toutes les notes pour 48 images Ã©taient immÃ©diatement devant les sujets.  Ils devaient choisir parmi cet ensemble le plus adaptÃ© Ã  chaque image. <br><br>  En consÃ©quence, 88% des sujets ont choisi exactement les mÃªmes Ã©tiquettes que la machine, et le degrÃ© de coordination Ã©tait de 79%.  Un fait intÃ©ressant est que mÃªme en choisissant la mauvaise Ã©tiquette que la machine a choisie, les sujets dans 63% de ces cas ont choisi l'une des 5 meilleures Ã©tiquettes.  Autrement dit, toutes les marques sur la voiture sont ordonnÃ©es dans une liste des plus appropriÃ©es aux plus inappropriÃ©es (exemple exagÃ©rÃ©: Â«bagelÂ», Â«bretzelÂ», Â«anneau en caoutchoucÂ», Â«pneuÂ», etc. jusqu'Ã  Â«faucon dans le ciel nocturneÂ» ) <br><br><h2>  ExpÃ©rience n Â° 3b: "qu'est-ce que c'est?" </h2><br>  Dans ce test, les scientifiques ont lÃ©gÃ¨rement modifiÃ© les rÃ¨gles.  Au lieu de leur demander de Â«devinerÂ» quelle Ã©tiquette la machine choisira pour une image particuliÃ¨re, on a simplement demandÃ© aux sujets ce qu'ils voyaient devant eux. <br><br>  Les systÃ¨mes de reconnaissance basÃ©s sur des rÃ©seaux de neurones convolutifs sÃ©lectionnent l'Ã©tiquette appropriÃ©e pour une image particuliÃ¨re.  Il s'agit d'un processus assez clair et logique.  Dans ce test, les sujets prÃ©sentent une pensÃ©e intuitive. <br><br>  En consÃ©quence, 90% des sujets ont choisi une Ã©tiquette, qui a Ã©galement Ã©tÃ© choisie par la machine.  L'alignement homme-machine parmi les images Ã©tait de 81%. <br><br><h2>  ExpÃ©rience 4: Bruit statique de la tÃ©lÃ©vision </h2><br>  Les scientifiques notent que dans les expÃ©riences prÃ©cÃ©dentes, les images sont inhabituelles, mais elles ont des caractÃ©ristiques distinctes qui peuvent inciter les sujets Ã  faire le bon (ou le mauvais) choix d'Ã©tiquette.  Par exemple, l'image Â«baseballÂ» n'est pas une balle, mais il y a des lignes et des couleurs qui sont prÃ©sentes sur une vraie balle de baseball.  Il s'agit d'une caractÃ©ristique distinctive frappante.  Mais si l'image n'a pas de telles caractÃ©ristiques, mais est essentiellement un bruit statique, une personne peut-elle reconnaÃ®tre au moins quelque chose dessus?  C'est ce qu'il a Ã©tÃ© dÃ©cidÃ© de vÃ©rifier. <br><br><img src="https://habrastorage.org/webt/je/9o/sm/je9osmgxp99wmexrvqmzndviqpk.jpeg"><br>  <i>Image n Â° 3a</i> <br><br>  Dans ce test, il y avait 8 images avec des statiques devant les sujets, que le systÃ¨me SNS reconnaÃ®t comme un objet spÃ©cifique (par exemple, un oiseau-zaryanka).  De plus, devant les sujets, il y avait une Ã©tiquette et des images normales associÃ©es (8 images de statiques, 1 Ã©tiquette Â«zaryankaÂ» et 5 photos de cet oiseau).  Le sujet du test devait sÃ©lectionner 1 image sur 8 de l'Ã©lectricitÃ© statique qui convenait le mieux Ã  l'une ou l'autre Ã©tiquette. <br><br>  Vous pouvez vous tester.  Ci-dessus, vous voyez un exemple d'un tel test.  Laquelle des trois images convient le mieux au tag Â«zaryankaÂ» et pourquoi? <br><br>  81% des sujets ont choisi l'Ã©tiquette choisie par la machine.  Dans le mÃªme temps, 75% des images ont Ã©tÃ© Ã©tiquetÃ©es par les sujets avec l'Ã©tiquette la plus appropriÃ©e de l'avis de la machine (Ã  partir d'un certain nombre d'options, comme nous l'avons mentionnÃ© prÃ©cÃ©demment). <br><br>  Pour ce test particulier, vous pouvez avoir des questions, tout comme le mien.  Le fait est que dans la statique proposÃ©e (ci-dessus), je vois personnellement trois caractÃ©ristiques prononcÃ©es qui les distinguent les unes des autres.  Et seulement dans une image, cette fonctionnalitÃ© ressemble fortement Ã  la mÃªme zaryanka (je pense que vous comprenez quelle image des trois).  Par consÃ©quent, mon opinion personnelle et trÃ¨s subjective est qu'un tel test n'est pas particuliÃ¨rement indicatif.  Bien que peut-Ãªtre parmi d'autres options pour les images statiques Ã©taient vraiment indiscernables et mÃ©connaissables. <br><br><h2>  ExpÃ©rience n Â° 5: chiffres Â«douteuxÂ» </h2><br>  Les tests dÃ©crits ci-dessus Ã©taient basÃ©s sur des images qui ne peuvent pas Ãªtre immÃ©diatement entiÃ¨rement et sans aucun doute classÃ©es comme l'un ou l'autre objet.  Il y a toujours une fraction de doute.  Les images trompeuses sont assez simples dans leur travail - gÃ¢cher l'image au-delÃ  de la reconnaissance.  Mais il existe un deuxiÃ¨me type d'algorithmes malveillants qui n'ajoutent (ou suppriment) qu'un petit dÃ©tail dans l'image, ce qui peut complÃ¨tement violer le systÃ¨me de reconnaissance par le systÃ¨me SNA.  Ajoutez quelques pixels et le chiffre 6 se transforme comme par magie en chiffre 5 ( <b>1s</b> ). <br><br>  Les scientifiques considÃ¨rent ces algorithmes comme l'un des plus dangereux.  Vous pouvez lÃ©gÃ¨rement modifier l'Ã©tiquette d'image et le vÃ©hicule sans pilote considÃ¨re incorrectement le panneau de limitation de vitesse (par exemple, 75 au lieu de 45), ce qui peut entraÃ®ner de tristes consÃ©quences. <br><br><img src="https://habrastorage.org/webt/9k/wr/h9/9kwrh9bcsqbqyolfpdgc1crqcfg.jpeg"><br>  <i>Image # 3b</i> <br><br>  Dans ce test, les scientifiques ont suggÃ©rÃ© que les sujets choisissent la mauvaise rÃ©ponse, mais plutÃ´t la mauvaise.  Dans le test, 100 images numÃ©riques modifiÃ©es par un algorithme malveillant ont Ã©tÃ© utilisÃ©es (le LeNet SNA a changÃ© leur classification, c'est-Ã -dire que l'algorithme malveillant a fonctionnÃ© avec succÃ¨s).  Les sujets devaient dire quel chiffre Ã  leur avis la machine voyait.  Comme prÃ©vu, 89% des sujets ont rÃ©ussi ce test. <br><br><h2>  ExpÃ©rience 6: photos et "distorsion" localisÃ©e </h2><br>  Les scientifiques notent que non seulement des systÃ¨mes de reconnaissance d'objets se dÃ©veloppent, mais Ã©galement des algorithmes malveillants qui les empÃªchent de le faire.  Auparavant, pour que l'image soit classÃ©e incorrectement, il fallait dÃ©former (changer, supprimer, endommager, etc.) 14% de tous les pixels de l'image cible.  Maintenant, ce chiffre est devenu beaucoup plus petit.  Il suffit d'ajouter une petite image Ã  l'intÃ©rieur de la cible et le classement sera violÃ©. <br><br><img src="https://habrastorage.org/webt/6i/sz/1p/6isz1pvm_j-zzxt1mkeq2krmlts.jpeg"><br>  <i>Image n Â° 4</i> <br><br>  Dans ce test, un algorithme LaVAN malveillant assez rÃ©cent a Ã©tÃ© utilisÃ©, qui place une petite image localisÃ©e Ã  un point sur la photo cible.  En consÃ©quence, le systÃ¨me de reconnaissance d'objets peut reconnaÃ®tre le mÃ©tro comme une boÃ®te de lait ( <b>4a</b> ).  Les caractÃ©ristiques les plus importantes de cet algorithme sont prÃ©cisÃ©ment la faible proportion de pixels endommagÃ©s (seulement 2%) de l'image cible et l'absence de la nÃ©cessitÃ© de la dÃ©former dans son intÃ©gralitÃ© ou la partie principale (la plus importante) de celle-ci. <br><br>  Dans le test, 22 images endommagÃ©es par LaVAN ont Ã©tÃ© utilisÃ©es (le systÃ¨me de reconnaissance SNA Inception V3 a Ã©tÃ© piratÃ© avec succÃ¨s par cet algorithme).  Les sujets Ã©taient censÃ©s classer l'encart malveillant sur la photo.  87% des sujets ont rÃ©ussi Ã  le faire. <br><br><h2>  ExpÃ©rience 7: objets tridimensionnels </h2><br>  Les images que nous avons vues prÃ©cÃ©demment sont en deux dimensions, comme toute photo, photo ou coupure de journal.  La plupart des algorithmes malveillants manipulent avec succÃ¨s de telles images.  Cependant, ces ravageurs ne peuvent fonctionner que sous certaines conditions, c'est-Ã -dire qu'ils ont un certain nombre de limitations: <br><br><ul><li>  complexitÃ©: uniquement des images en deux dimensions; </li><li>  application pratique: les modifications malveillantes ne sont possibles que sur les systÃ¨mes qui lisent les images numÃ©riques reÃ§ues, et non les images des capteurs et des capteurs; </li><li>  stabilitÃ©: une attaque malveillante perd de sa force si vous faites pivoter une image bidimensionnelle (redimensionner, recadrer, affiner, etc.); </li><li>  les gens: nous voyons le monde et les objets qui nous entourent en 3D sous diffÃ©rents angles, sous diffÃ©rents Ã©clairages, et non sous la forme d'images numÃ©riques bidimensionnelles prises sous un seul angle. </li></ul><br><br>  Mais, comme nous le savons, les progrÃ¨s n'ont pas Ã©pargnÃ© les algorithmes malveillants.  Parmi eux figurait celui qui est capable non seulement de dÃ©former les images bidimensionnelles, mais aussi les images tridimensionnelles, ce qui conduit Ã  une classification incorrecte par le systÃ¨me de reconnaissance d'objets.  Lors de l'utilisation d'un logiciel pour les graphiques en trois dimensions, un tel algorithme induit en erreur les classificateurs basÃ©s sur le SNA (dans ce cas, le programme Inception V3) Ã  partir de diffÃ©rentes distances et angles de vue.  La chose la plus surprenante est que de telles images 3D trompeuses peuvent Ãªtre imprimÃ©es sur une imprimante appropriÃ©e, c'est-Ã -dire  crÃ©er un vÃ©ritable objet physique, et le systÃ¨me de reconnaissance d'objets ne le classera toujours pas correctement (par exemple, une orange comme perceuse Ã©lectrique).  Et tout cela grÃ¢ce Ã  des changements mineurs dans la texture de l'image cible ( <b>4b</b> ). <br><br>  Pour un systÃ¨me de reconnaissance d'objets, un tel algorithme malveillant est un adversaire sÃ©rieux.  Mais l'homme n'est pas une machine, il voit et pense diffÃ©remment.  Dans ce test, avant les sujets, il y avait des images d'objets tridimensionnels dans lesquels il y avait les changements de texture dÃ©crits ci-dessus sous trois angles.  Les sujets ont Ã©galement reÃ§u la note correcte et erronÃ©e.  Ils devaient dÃ©terminer quelles Ã©tiquettes sont correctes, lesquelles ne le sont pas et pourquoi, c'est-Ã -dire  si les sujets testÃ©s voient des changements de texture dans les images. <br><br>  En consÃ©quence, 83% des sujets ont rÃ©ussi la tÃ¢che. <br><br>  Pour une connaissance plus dÃ©taillÃ©e des nuances de l'Ã©tude, je vous recommande fortement de consulter le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport des scientifiques</a> . <br><br>  Et sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce lien,</a> vous trouverez les fichiers d'images, de donnÃ©es et de code qui ont Ã©tÃ© utilisÃ©s dans l'Ã©tude. <br><br><h3>  Ã‰pilogue </h3><br>  Les travaux menÃ©s ont permis aux scientifiques de tirer une conclusion simple et assez Ã©vidente: l'intuition humaine peut Ãªtre une source de donnÃ©es trÃ¨s importantes et un outil pour prendre la bonne dÃ©cision et / ou la perception de l'information.  Une personne est en mesure de comprendre intuitivement comment le systÃ¨me de reconnaissance d'objets se comportera, quelles Ã©tiquettes il choisira et pourquoi. <br><br>  Les raisons pour lesquelles il est plus facile pour une personne de voir une image rÃ©elle et de la reconnaÃ®tre correctement plusieurs.  Le plus Ã©vident est la mÃ©thode d'obtention de l'information: la machine reÃ§oit une image sous forme numÃ©rique, et une personne la voit de ses propres yeux.  Pour une machine, une image est un ensemble de donnÃ©es dont vous pouvez modifier la classification.  Pour nous, l'image d'une rame de mÃ©tro sera toujours une rame de mÃ©tro, pas une canette de lait, car nous la voyons. <br><br>  Les scientifiques soulignent Ã©galement que ces tests sont difficiles Ã  Ã©valuer, car une personne n'est pas une machine et une machine n'est pas une personne.  Par exemple, les chercheurs parlent du test avec un Â«beignetÂ» et une Â«roueÂ».  Ces images sont similaires au Â«beignetÂ» et Ã  la Â«roueÂ», car le systÃ¨me de reconnaissance les classe de cette faÃ§on.  Une personne voit qu'elle ressemble Ã  un Â«beignetÂ» et Ã  une Â«roueÂ», mais ce n'est pas le cas.  Il s'agit de la diffÃ©rence fondamentale dans la perception des informations visuelles entre une personne et un programme. <br><br>  Merci de votre attention, restez curieux et bonne semaine de travail, les gars. <br><br>  Merci de rester avec nous.  Aimez-vous nos articles?  Vous voulez voir des matÃ©riaux plus intÃ©ressants?  Soutenez-nous en passant une commande ou en le recommandant Ã  vos amis, une <b>rÃ©duction de 30% pour les utilisateurs Habr sur un analogue unique de serveurs d'entrÃ©e de gamme que nous avons inventÃ©s pour vous:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Toute la vÃ©ritÃ© sur VPS (KVM) E5-2650 v4 (6 cÅ“urs) 10 Go DDR4 240 Go SSD 1 Gbps Ã  partir de 20 $ ou comment diviser le serveur?</a>  (les options sont disponibles avec RAID1 et RAID10, jusqu'Ã  24 cÅ“urs et jusqu'Ã  40 Go de DDR4). <br><br>  <b>VPS (KVM) E5-2650 v4 (6 cÅ“urs) 10 Go DDR4 240 Go SSD 1 Gbit / s jusqu'Ã  l'Ã©tÃ© gratuitement</b> lorsque vous payez pour une pÃ©riode de six mois, vous pouvez commander <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  <b>Dell R730xd 2 fois moins cher?</b>  Nous avons seulement <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2 x Intel Dodeca-Core Xeon E5-2650v4 128 Go DDR4 6x480 Go SSD 1 Gbps 100 TV Ã  partir de 249 $</a> aux Pays-Bas et aux Ã‰tats-Unis!</b>  Pour en savoir plus sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">crÃ©ation d'un bÃ¢timent d'infrastructure.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">classe utilisant des serveurs Dell R730xd E5-2650 v4 coÃ»tant 9 000 euros pour un sou?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr445372/">https://habr.com/ru/post/fr445372/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr445360/index.html">5 tÃ¢ches typiques pour les interviews JavaScript: analyse et solutions</a></li>
<li><a href="../fr445362/index.html">Le livre "Distributed Systems. ModÃ¨les de conception</a></li>
<li><a href="../fr445366/index.html">Comment accÃ©lÃ©rer le cryptage selon GOST 28147-89 sur le processeur Baikal-T1 en raison du bloc SIMD</a></li>
<li><a href="../fr445368/index.html">Test de charge d'un jeu avec quelques centaines de milliers d'utilisateurs virtuels</a></li>
<li><a href="../fr445370/index.html">Analyse TSDB dans PromÃ©thÃ©e 2</a></li>
<li><a href="../fr445378/index.html">Labyrinthes: classification, gÃ©nÃ©ration, recherche de solutions</a></li>
<li><a href="../fr445380/index.html">Le PHP moderne est beau et productif</a></li>
<li><a href="../fr445384/index.html">Mission Chang'e-4 - Ã©quipement scientifique sur le module d'atterrissage et le satellite rÃ©pÃ©teur</a></li>
<li><a href="../fr445390/index.html">IDE d'une personne normale ou pourquoi nous avons choisi Monaco</a></li>
<li><a href="../fr445392/index.html">Remarketing dynamique MyTarget: recommandations de produits non personnels</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëáüèº üë©üèª‚Äçüè≠ üßóüèª Grandes cambios en las principales arquitecturas de chips üëèüèø üë©üèª‚Äçüåæ üéÆ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La introducci√≥n de AI a nivel de chip le permite procesar m√°s datos localmente, porque un aumento en la cantidad de dispositivos ya no da el mismo efe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Grandes cambios en las principales arquitecturas de chips</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422787/"><h4>  <font color="gray">La introducci√≥n de AI a nivel de chip le permite procesar m√°s datos localmente, porque un aumento en la cantidad de dispositivos ya no da el mismo efecto.</font> </h4><br>  Los fabricantes de chips est√°n trabajando en nuevas arquitecturas que aumentan significativamente la cantidad de datos procesados ‚Äã‚Äãpor vatio y ciclo.  El terreno est√° listo para una de las mayores revoluciones en la arquitectura de chips en las √∫ltimas d√©cadas. <br><br>  Todos los principales fabricantes de chips y sistemas est√°n cambiando la direcci√≥n del desarrollo.  Entraron en la carrera de las arquitecturas, lo que proporciona un cambio de paradigma en todo: desde los m√©todos de lectura y escritura hasta la memoria, su procesamiento y, en √∫ltima instancia, el dise√±o de varios elementos en un chip.  Aunque la miniaturizaci√≥n contin√∫a, nadie est√° apostando por escalar para hacer frente al crecimiento explosivo de datos de los sensores y aumentar el volumen de tr√°fico entre m√°quinas. <br><a name="habracut"></a><br>  Entre los cambios en las nuevas arquitecturas: <br><br><ul><li>  Nuevos m√©todos para procesar una mayor cantidad de datos en 1 ciclo de reloj, a veces con menos precisi√≥n o por prioridad de ciertas operaciones, dependiendo de la aplicaci√≥n. </li><li>  Nuevas arquitecturas de memoria que cambian la forma en que almacenamos, leemos, escribimos y accedemos a los datos. </li><li>  M√≥dulos de procesamiento m√°s especializados ubicados en todo el sistema cerca de la memoria.  En lugar de un procesador central, los aceleradores se seleccionan seg√∫n el tipo de datos y la aplicaci√≥n. </li><li>  En el campo de la IA, se est√° trabajando para combinar varios tipos de datos en forma de plantillas, lo que aumenta efectivamente la densidad de datos y minimiza las discrepancias entre los diferentes tipos. </li><li>  Ahora, el dise√±o en el caso es el componente principal de la arquitectura, y se presta cada vez m√°s atenci√≥n a la facilidad de cambiar estos dise√±os. </li></ul><br>  "Hay varias tendencias que afectan los avances tecnol√≥gicos", dijo Stephen Wu, un distinguido ingeniero de Rambus.  - En los centros de datos, aprovecha al m√°ximo el hardware y el software.  Desde este √°ngulo, los propietarios de centros de datos est√°n mirando la econom√≠a.  Introducir algo nuevo es costoso.  Pero los cuellos de botella est√°n cambiando, por lo que se est√°n introduciendo chips especializados para una inform√°tica m√°s eficiente.  Y si reduce los flujos de datos de ida y vuelta a E / S y memoria, esto puede tener un gran impacto ". <br><br>  Los cambios son m√°s evidentes en el borde de la infraestructura inform√°tica, es decir, entre los sensores finales.  Los fabricantes de repente se dieron cuenta de que decenas de miles de millones de dispositivos generar√≠an demasiados datos: ese volumen no podr√≠a enviarse a la nube para su procesamiento.  Pero el procesamiento de todos estos datos en el borde presenta otros problemas: requiere mejoras de rendimiento importantes sin un aumento significativo en el consumo de energ√≠a. <br><br>  "Hay una nueva tendencia hacia una menor precisi√≥n", dijo Robert Ober, arquitecto principal de la plataforma de Tesla en Nvidia.  - Estos no son solo ciclos computacionales.  Este es un paquete de datos m√°s intensivo en la memoria, donde se utiliza el formato de instrucciones de 16 bits ". <br><br>  Aubert cree que gracias a una serie de optimizaciones arquitect√≥nicas en el futuro previsible, puede duplicar la velocidad de procesamiento cada dos a√±os.  "Veremos un aumento dram√°tico en la productividad", dijo.  - Para esto necesitas hacer tres cosas.  El primero es la inform√°tica.  El segundo es la memoria.  La tercera √°rea es el ancho de banda del host y el ancho de banda de E / S.  Se necesita mucho trabajo para optimizar el almacenamiento y la pila de red ". <br><br>  Ya se est√° implementando algo.  En una presentaci√≥n en la conferencia Hot Chips 2018, Jeff Rupley, arquitecto principal en el Centro de Investigaci√≥n Austin de Samsung, se√±al√≥ varios cambios arquitect√≥nicos importantes en el procesador M3.  Uno incluye m√°s instrucciones por latido: seis en lugar de cuatro en el √∫ltimo chip M2.  Adem√°s, se implement√≥ la predicci√≥n de ramificaci√≥n en redes neuronales y se duplic√≥ la cola de instrucciones. <br><br>  Tales cambios trasladan el punto de innovaci√≥n de la fabricaci√≥n directa de microcircuitos a la arquitectura y el dise√±o, por un lado, y al dise√±o de elementos en el otro lado de la cadena de producci√≥n.  Aunque las innovaciones continuar√°n en los procesos tecnol√≥gicos, es solo a expensas de esto que es incre√≠blemente dif√≠cil lograr un aumento del 15-20% en la productividad y la potencia en cada nuevo modelo de chip, y esto no es suficiente para hacer frente al r√°pido crecimiento en el volumen de datos. <br><br>  "Los cambios est√°n teniendo lugar a un ritmo exponencial", dijo Victor Pan, presidente y director ejecutivo de Xilinx, en un discurso en la conferencia Hot Chips, "se generar√°n 10 zettabytes [10 <sup>21</sup> bytes] de datos cada a√±o, y la mayor√≠a de ellos no est√°n estructurados". <br><br><h1>  Nuevos enfoques de la memoria. </h1><br>  Trabajar con tantos datos requiere un replanteamiento de cada componente del sistema, desde los m√©todos de procesamiento de datos hasta su almacenamiento. <br><br>  "Ha habido muchos intentos de crear nuevas arquitecturas de memoria", dijo Carlos Machin, director senior de innovaci√≥n de eSilicon EMEA.  - El problema es que necesita leer todas las l√≠neas y seleccionar un bit en cada una.  Una opci√≥n es crear una memoria que se pueda leer de izquierda a derecha, as√≠ como de arriba a abajo.  Puede ir a√∫n m√°s lejos y agregar computaci√≥n a la memoria ". <br><br>  Estos cambios incluyen cambiar los m√©todos para leer la memoria, la ubicaci√≥n y el tipo de elementos de procesamiento, as√≠ como la introducci√≥n de IA para priorizar el almacenamiento, el procesamiento y el movimiento de datos en todo el sistema. <br><br>  "¬øQu√© pasa si, en el caso de datos dispersos, solo podemos leer un byte de esta matriz a la vez, o tal vez ocho bytes consecutivos de la misma ruta de bytes sin desperdiciar energ√≠a en otros bytes o rutas de bytes que no nos interesan? ?  "Pregunta Mark Greenberg, director de marketing de productos de Cadence".  - En el futuro, esto es posible.  Si observa la arquitectura de HBM2, por ejemplo, la pila est√° organizada en 16 canales virtuales de 64 bits cada uno, y necesita obtener solo 4 palabras consecutivas de 64 bits para acceder a cualquier canal virtual.  Por lo tanto, es posible crear matrices de datos con un ancho de 1024 bits, escribir horizontalmente, pero leer verticalmente cuatro palabras de 64 bits a la vez ". <br><br>  La memoria es uno de los componentes principales de la arquitectura von Neumann, pero ahora tambi√©n se ha convertido en uno de los principales escenarios para los experimentos.  "El enemigo principal son los sistemas de memoria virtual, donde los datos se mueven de manera m√°s antinatural", dijo Dan Bouvier, arquitecto jefe de productos para clientes de AMD.  - Esta es una transmisi√≥n de difusi√≥n.  Estamos acostumbrados a esto en el campo de los gr√°ficos.  Pero si resolvemos los conflictos en el banco de memoria DRAM, obtenemos una transmisi√≥n mucho m√°s eficiente.  Luego, una GPU separada puede usar DRAM en el rango de eficiencia del 90%, lo cual es muy bueno.  Pero si configura la transmisi√≥n sin interrupciones, la CPU y la APU tambi√©n caer√°n en el rango de eficiencia del 80% al 85% ". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6af/814/e8c/6af814e8c5d0a2f4b9274d165aa8f622.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Arquitectura von Neumann.</font></i>  <i><font color="gray">Fuente: Ingenier√≠a de semiconductores</font></i> <br><br>  IBM est√° desarrollando un tipo diferente de arquitectura de memoria, que es esencialmente una versi√≥n actualizada de la agregaci√≥n de discos.  El objetivo es que, en lugar de usar una sola unidad, el sistema puede usar arbitrariamente cualquier memoria disponible a trav√©s de un conector, que Jeff Stucheli, un arquitecto de hardware de IBM, llama "Swiss Army Knife" para conectar elementos.  La ventaja del enfoque es que le permite mezclar y combinar diferentes tipos de datos. <br><br>  "El procesador se est√° convirtiendo en el centro de una interfaz de se√±alizaci√≥n de alto rendimiento", dice Stucelli.  "Si cambia la microarquitectura, el n√∫cleo realiza m√°s operaciones por ciclo a la misma frecuencia". <br><br>  La conectividad y el rendimiento deber√≠an garantizar el procesamiento de un volumen radicalmente mayor de datos generados.  "Los principales cuellos de botella est√°n ahora en las ubicaciones de movimiento de datos", dijo Wu desde Rambus.  "La industria ha hecho un gran trabajo aumentando la velocidad de la inform√°tica".  Pero si espera datos o plantillas de datos especializadas, entonces necesita ejecutar la memoria m√°s r√°pido.  Por lo tanto, si observa DRAM y NVM, el rendimiento depende del patr√≥n de tr√°fico.  Si los datos se transmiten, la memoria proporcionar√° un rendimiento muy bueno.  Pero si los datos vienen en forma aleatoria, es menos eficiente.  Y no importa lo que hagas, con un aumento en el volumen a√∫n tienes que hacerlo m√°s r√°pido ". <br><br><h1>  M√°s inform√°tica, menos tr√°fico. </h1><br>  El problema se agrava por el hecho de que hay varios tipos diferentes de datos generados a diferentes frecuencias y velocidades por los dispositivos en el borde.  Para que estos datos se muevan libremente entre diferentes m√≥dulos de procesamiento, la administraci√≥n debe ser mucho m√°s eficiente que en el pasado. <br><br>  "Hay cuatro configuraciones principales: muchos a muchos, subsistemas de memoria, E / S de baja potencia y topolog√≠as de cuadr√≠culas y anillos", dice Charlie Janak, presidente y CEO de Arteris IP.  - Puede colocar los cuatro en un chip, lo que sucede con los chips IoT clave.  O puede agregar subsistemas HBM de alto rendimiento.  Pero la complejidad es enorme, porque algunas de estas cargas de trabajo son muy espec√≠ficas, y el chip tiene varias tareas de trabajo diferentes.  Si observa algunos de estos microchips, obtienen grandes cantidades de datos.  Esto es en sistemas como los radares de autom√≥viles y los lidars.  No pueden existir sin algunas interconexiones avanzadas ". <br><br>  La tarea es c√≥mo minimizar el movimiento de datos, pero al mismo tiempo maximizar el flujo de datos cuando sea necesario, y de alguna manera encontrar un equilibrio entre el procesamiento local y centralizado sin un aumento innecesario del consumo de energ√≠a. <br><br>  "Por un lado, este es un problema de ancho de banda", dijo Rajesh Ramanujam, gerente de marketing de productos de NetSpeed ‚Äã‚ÄãSystems.  - Desea reducir el tr√°fico tanto como sea posible, de modo que transfiera los datos m√°s cerca del procesador.  Pero si a√∫n necesita mover los datos, es recomendable compactarlos tanto como sea posible.  Pero nada existe por s√≠ mismo.  Todo debe planificarse desde el nivel del sistema.  En cada paso, se deben considerar varios ejes interdependientes.  Determinan si usa la memoria en la forma tradicional de leer y escribir, o si usa nuevas tecnolog√≠as.  En algunos casos, es posible que deba cambiar la forma en que almacena los datos.  Si necesita un mayor rendimiento, esto generalmente significa un aumento en el √°rea del chip, lo que afecta la disipaci√≥n de calor.  Y ahora, teniendo en cuenta la seguridad funcional, no se puede permitir la sobrecarga de datos ". <br><br>  Es por eso que varios m√≥dulos de procesamiento de datos prestan tanta atenci√≥n al procesamiento de datos en el borde y al ancho de banda del canal.  Pero a medida que desarrolla diferentes arquitecturas, es muy diferente c√≥mo y d√≥nde se implementa este procesamiento de datos. <br><br>  Por ejemplo, Marvell introdujo un controlador SSD con inteligencia artificial integrada para manejar la pesada carga inform√°tica en el borde.  El motor de IA se puede usar para an√°lisis directamente dentro de la unidad SSD. <br><br>  "Puede cargar modelos directamente en el hardware y hacer el procesamiento del hardware en el controlador SSD", dijo Ned Varnitsa, ingeniero jefe de Marvell.  - Hoy hace el servidor en la nube (host).  Pero si cada disco env√≠a datos a la nube, esto crear√° una gran cantidad de tr√°fico de red.  Es mejor hacer el procesamiento en el borde, y el host solo emite un comando, que son solo metadatos.  Cuantas m√°s unidades tenga, m√°s potencia de procesamiento.  Este es un gran beneficio del tr√°fico reducido ". <br><br>  Este enfoque es particularmente interesante porque se adapta a diferentes datos seg√∫n la aplicaci√≥n.  Por lo tanto, el host puede generar una tarea y enviarla al dispositivo de almacenamiento para su procesamiento, despu√©s de lo cual solo se env√≠an los metadatos o resultados de c√°lculo.  En otro escenario, un dispositivo de almacenamiento puede almacenar datos, preprocesarlos y generar metadatos, etiquetas e √≠ndices, que luego el host recupera seg√∫n sea necesario para su posterior an√°lisis. <br><br>  Esta es una de las posibles opciones.  Hay otros  Rupli de Samsung enfatiz√≥ la importancia de procesar y fusionar modismos que pueden decodificar dos instrucciones y combinarlas en una sola operaci√≥n. <br><br><h1>  La IA se ocupa del control y la optimizaci√≥n </h1><br>  En todos los niveles de optimizaci√≥n, se utiliza la Inteligencia Artificial: este es uno de los elementos verdaderamente nuevos en la arquitectura de chips.  En lugar de permitir que el sistema operativo y el middleware administren funciones, esta funci√≥n de monitoreo se distribuye a trav√©s del chip, entre los chips y al nivel del sistema.  En algunos casos, se introducen redes neuronales de hardware. <br><br>  "El objetivo no es tanto agrupar m√°s elementos, sino cambiar la arquitectura tradicional", dice Mike Gianfanya, vicepresidente de marketing de eSilicon.  - Con la ayuda de la inteligencia artificial y el aprendizaje autom√°tico, puede distribuir elementos en todo el sistema, obteniendo un procesamiento m√°s eficiente con pron√≥sticos.  O puede usar chips separados que funcionan independientemente en el sistema o en el m√≥dulo ". <br><br>  ARM ha desarrollado su primer chip de aprendizaje autom√°tico, que planea lanzar a finales de este a√±o para varios mercados.  "Este es un nuevo tipo de procesador", dijo Ian Bratt, ingeniero de honor de ARM.  - Incluye un bloque fundamental: es un motor inform√°tico, as√≠ como un motor MAC, un motor DMA con un m√≥dulo de control y una red de difusi√≥n.  En total, hay 16 n√∫cleos inform√°ticos realizados con la tecnolog√≠a de proceso de 7 nm, que producen 4 TeraOps a una frecuencia de 1 GHz ". <br><br>  Dado que ARM trabaja con un ecosistema asociado, su chip es m√°s vers√°til y personalizable que otros chips AI / ML que se est√°n desarrollando.  En lugar de una estructura monol√≠tica, separa el procesamiento por funci√≥n, por lo que cada m√≥dulo inform√°tico funciona en un mapa de caracter√≠sticas separado.  Bratt identific√≥ cuatro ingredientes clave: planificaci√≥n est√°tica, plegado eficiente, mecanismos de estrechamiento y adaptaci√≥n programada a futuros cambios de dise√±o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbe/7e4/ab1/fbe7e4ab11731ad3dafebc992b9c7bf2.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. Arquitectura ARM del procesador ML.</font></i>  <i><font color="gray">Fuente: ARM / Hot Chips</font></i> <br><br>  Mientras tanto, Nvidia eligi√≥ una t√°ctica diferente: crear un motor de aprendizaje profundo dedicado junto a la GPU para optimizar el procesamiento de im√°genes y videos. <br><br><h1>  Conclusi√≥n </h1><br>  Utilizando algunos o todos estos enfoques, los fabricantes de chips esperan duplicar el rendimiento cada dos a√±os, manteni√©ndose al d√≠a con el crecimiento explosivo de datos, mientras permanecen dentro del marco ajustado de los presupuestos de energ√≠a.  Pero esto no es solo m√°s computaci√≥n.  Este es un cambio en la plataforma de dise√±o de chips y sistemas, cuando el creciente volumen de datos, en lugar de las limitaciones de hardware y software, se convierte en el factor principal. <br><br>  "Cuando aparecieron las computadoras en las empresas, a muchos les pareci√≥ que el mundo que nos rodea se hab√≠a acelerado", dijo Aart de Gues, presidente y director ejecutivo de Synopsys.  - Hicieron contabilidad en trozos de papel con pilas de libros.  El libro mayor se ha convertido en una pila de tarjetas perforadas para impresi√≥n y computaci√≥n.  Se ha producido un cambio tremendo y lo vemos de nuevo.  Con el advenimiento de las computadoras inform√°ticas simples mentalmente, el algoritmo de acciones no ha cambiado: puede rastrear cada paso.  Pero ahora est√° sucediendo algo m√°s que podr√≠a conducir a una nueva aceleraci√≥n.  Es como en un campo agr√≠cola incluir riego y aplicar un cierto tipo de fertilizante solo en un d√≠a determinado, cuando la temperatura alcanza el nivel deseado.  Este uso del aprendizaje autom√°tico es una optimizaci√≥n que no era obvia en el pasado ". <br><br>  No est√° solo en esta evaluaci√≥n.  "Se adoptar√°n las nuevas arquitecturas", dijo Wally Raines, presidente y CEO de Mentor, Siemens Business.  - Ser√°n dise√±ados.  El aprendizaje autom√°tico se utilizar√° en muchos o la mayor√≠a de los casos, porque su cerebro aprende de su propia experiencia.  Visit√© 20 o m√°s empresas que desarrollan procesadores de IA especializados de un tipo u otro, y cada una de ellas tiene su propio nicho peque√±o.  Pero ver√° cada vez m√°s su aplicaci√≥n en aplicaciones espec√≠ficas, y complementar√°n la arquitectura tradicional de von Neumann.  La computaci√≥n neurom√≥rfica se convertir√° en la corriente principal.  Este es un gran paso en la eficiencia inform√°tica y la reducci√≥n de costos.  Los dispositivos m√≥viles y los sensores comenzar√°n a hacer el trabajo que los servidores hacen hoy ". </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es422787/">https://habr.com/ru/post/es422787/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es422775/index.html">Conferencia DEFCON 22. Andrew "Zoz" Brooks. ¬°No lo arruines! Parte 1</a></li>
<li><a href="../es422777/index.html">Una introducci√≥n simple a ALU para redes neuronales: explicaci√≥n, significado f√≠sico e implementaci√≥n</a></li>
<li><a href="../es422781/index.html">Fintech digest: SWIFT continuar√° trabajando en la Federaci√≥n de Rusia, VISA le permitir√° transferir fondos por n√∫mero de tel√©fono, costosos datos biom√©tricos</a></li>
<li><a href="../es422783/index.html">Mejor, m√°s r√°pido, m√°s potente: componentes con estilo v4</a></li>
<li><a href="../es422785/index.html">Digitalizaci√≥n de f√°brica: una mirada al frente</a></li>
<li><a href="../es422789/index.html">@Pythonetc Aug 2018</a></li>
<li><a href="../es422791/index.html">C√≥mo NO aprender ingl√©s: errores comunes</a></li>
<li><a href="../es422793/index.html">Conferencia DEFCON 22. Andrew "Zoz" Brooks. ¬°No lo arruines! Parte 2</a></li>
<li><a href="../es422795/index.html">Tecnolog√≠a y negocios: un nuevo modelo de cooperaci√≥n con Zyxel en Rusia</a></li>
<li><a href="../es422797/index.html">C√≥mo hicimos una grabadora de video en la nube de tama√±o peque√±o a partir de una c√°mara IP normal</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
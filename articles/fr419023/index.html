<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😔 👗 👩🏼‍🚒 Comment nous avons fait évoluer Nginx et sauvons le monde 54 ans d'attente chaque jour 👸🏻 🔘 🏇🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="«L'équipe @Cloudflare vient d'apporter des modifications qui ont considérablement amélioré les performances de notre réseau, en particulier pour les d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment nous avons fait évoluer Nginx et sauvons le monde 54 ans d'attente chaque jour</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/419023/"> <i>«L'équipe @Cloudflare vient d'apporter des modifications qui ont considérablement amélioré les performances de notre réseau, en particulier pour les demandes les plus lentes.</i>  <i>Combien plus rapide?</i>  <i>Nous estimons que nous économisons sur Internet environ 54 ans de temps <b>par jour</b> qui auraient autrement été consacrés à attendre le chargement des sites</i> . <i>»</i>  - Matthew Prince <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tweet</a> , 28 juin 2018 <br><br>  10 millions de sites, applications et API utilisent Cloudflare pour accélérer les téléchargements de contenu pour les utilisateurs.  Au plus fort, nous traitons plus de 10 millions de demandes par seconde dans 151 centres de données.  Au fil des ans, nous avons apporté de nombreux changements à notre version de Nginx pour faire face à la croissance.  Cet article concerne l'un de ces changements. <br><a name="habracut"></a><br><h1>  Comment fonctionne Nginx </h1><br>  Nginx est l'un des programmes qui utilise des boucles de traitement d'événements pour résoudre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le problème C10K</a> .  Chaque fois qu'un événement réseau arrive (nouvelle connexion, demande ou notification pour envoyer une plus grande quantité de données, etc.), Nginx se réveille, traite l'événement, puis revient à un autre travail (il peut s'agir de traiter d'autres événements).  Lorsqu'un événement arrive, les données le concernant sont prêtes, ce qui vous permet de traiter efficacement de nombreuses demandes simultanées sans interruption. <br><br><pre><code class="hljs pgsql">num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/</code> </pre> <br>  Par exemple, voici à quoi pourrait ressembler un morceau de code pour lire les données d'un descripteur de fichier: <br><br><pre> <code class="hljs pgsql">// we got a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> fd <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (buf_len &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { ssize_t n = <span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (n &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EWOULDBLOCK || errno == EAGAIN) { // try later <span class="hljs-keyword"><span class="hljs-keyword">when</span></span> we <span class="hljs-keyword"><span class="hljs-keyword">get</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event again } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EINTR) { <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> total; } buf_len -= n; buf += n; total += n; }</code> </pre> <br>  Si fd est une socket réseau, les octets déjà reçus seront retournés.  Le dernier appel renverra <code>EWOULDBLOCK</code> .  Cela signifie que le tampon de lecture local est terminé et que vous ne devez plus lire à partir de ce socket jusqu'à ce que les données apparaissent. <br><br><h1>  Les E / S de disque sont différentes du réseau </h1><br>  Si fd est un fichier normal sous Linux, alors <code>EWOULDBLOCK</code> et <code>EAGAIN</code> n'apparaissent jamais, et l'opération de lecture attend toujours de lire la totalité du tampon, même si le fichier est ouvert à l'aide de <code>O_NONBLOCK</code> .  Comme écrit dans le manuel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">open (2)</a> : <br><br><blockquote>  Veuillez noter que cet indicateur n'est pas valide pour les fichiers normaux et les périphériques bloqués. </blockquote><br>  En d'autres termes, le code ci-dessus est essentiellement réduit à ceci: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> buf_len; }</code> </pre> <br>  Si le gestionnaire doit lire à partir du disque, il bloque la boucle d'événements jusqu'à la fin de la lecture et les gestionnaires d'événements suivants attendent. <br><br>  Ceci est normal pour la plupart des tâches, car la lecture à partir d'un disque est généralement assez rapide et beaucoup plus prévisible que l'attente d'un paquet du réseau.  Surtout maintenant que tout le monde a un SSD et que tous nos caches sont sur des SSD.  Dans les SSD modernes, un très petit retard, généralement en dizaines de microsecondes.  En outre, vous pouvez exécuter Nginx avec plusieurs flux de travail afin qu'un gestionnaire d'événements lent ne bloque pas les demandes dans d'autres processus.  La plupart du temps, vous pouvez compter sur Nginx pour traiter rapidement et efficacement les demandes. <br><br><h1>  Performances SSD: pas toujours comme promis </h1><br>  Comme vous l'avez peut-être deviné, ces hypothèses roses ne sont pas toujours vraies.  Si chaque lecture prend toujours 50 μs, la lecture de 0,19 Mo en blocs de 4 Ko (et nous lisons en blocs encore plus grands) ne prendra que 2 ms.  Mais les tests ont montré que le délai jusqu'au premier octet est parfois bien pire, en particulier dans les 99e et 999e centiles.  En d'autres termes, la lecture la plus lente sur 100 (ou 1000) lectures prend souvent beaucoup plus de temps. <br><br>  Les disques SSD sont très rapides, mais connus pour leur complexité.  Ils ont des ordinateurs à l'intérieur de cette file d'attente et réordonnent les E / S, et effectuent également diverses tâches d'arrière-plan, telles que la récupération de place et la défragmentation.  De temps en temps, les demandes ralentissent sensiblement.  Mon collègue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ivan Bobrov a</a> lancé plusieurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tests de performances d'</a> E / S et enregistré des retards de lecture pouvant aller jusqu'à 1 seconde.  De plus, certains de nos SSD ont plus de pics de performances que d'autres.  À l'avenir, nous allons tenir compte de cet indicateur lors de l'achat d'un SSD, mais nous devons maintenant développer une solution pour les équipements existants. <br><br><h1>  Répartition uniforme de la charge avec <code>SO_REUSEPORT</code> </h1><br>  Il est difficile d'éviter une réponse lente pour 1000 requêtes, mais ce que nous ne voulons vraiment pas, c'est bloquer les 1000 requêtes restantes pendant une seconde entière.  Conceptuellement, Nginx est capable de traiter de nombreuses demandes en parallèle, mais il ne démarre qu'un seul gestionnaire d'événements à la fois.  J'ai donc ajouté une métrique spéciale: <br><br><pre> <code class="hljs pgsql">gettimeofday(&amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ gettimeofday(&amp;event_start_handle, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/ timersub(&amp;event_start_handle, &amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, &amp;event_loop_blocked);</code> </pre> <br>  Le 99e centile (p99) <code>event_loop_blocked</code> dépassait 50% de notre TTFB.  En d'autres termes, la moitié du temps lors du traitement d'une demande est le résultat du blocage du cycle de traitement des événements par d'autres demandes.  <code>event_loop_blocked</code> ne mesure que la moitié du verrou (car les appels en attente à <code>epoll_wait()</code> ne <code>epoll_wait()</code> pas mesurés), donc le rapport réel du temps bloqué est beaucoup plus élevé. <br><br>  Chacune de nos machines exécute Nginx avec 15 workflows, c'est-à-dire qu'une E / S lente ne bloquera pas plus de 6% des demandes.  Mais les événements ne sont pas également répartis: le travailleur principal reçoit 11% des demandes. <br><br>  <code>SO_REUSEPORT</code> peut résoudre le problème de la distribution inégale.  Marek Maikovsky a écrit plus tôt sur l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">inconvénient de</a> cette approche dans le contexte d'autres instances de Nginx, mais ici vous pouvez principalement l'ignorer: les connexions en amont dans le cache sont durables, vous pouvez donc négliger une légère augmentation du délai lors de l'ouverture de la connexion.  Ce changement de configuration à lui seul avec l'activation de <code>SO_REUSEPORT</code> amélioré le pic p99 de 33%. <br><br><h1>  Déplacer read () vers un pool de threads: pas une solution miracle </h1><br>  La solution est de rendre read () non bloquant.  En fait, cette fonction est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">implémentée dans Nginx normal</a> !  En utilisant la configuration suivante, read () et write () sont exécutées dans le pool de threads et ne bloquent pas la boucle d'événements: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">aio</span></span> threads; <span class="hljs-attribute"><span class="hljs-attribute">aio_write</span></span> <span class="hljs-literal"><span class="hljs-literal">on</span></span>;</code> </pre> <br>  Mais nous avons testé cette configuration et au lieu d'améliorer le temps de réponse de 33 fois, nous n'avons remarqué qu'un petit changement dans p99, la différence est dans la marge d'erreur.  Le résultat a été très décourageant, nous avons donc temporairement reporté cette option. <br><br>  Il y a plusieurs raisons pour lesquelles nous n'avons pas apporté d'améliorations significatives, comme les développeurs Nginx.  Dans le test, ils ont utilisé 200 connexions simultanées pour demander des fichiers de 4 Mo sur le disque dur.  Les Winchesters ont beaucoup plus de latence d'E / S, donc l'optimisation a un effet plus important. <br><br>  De plus, nous sommes principalement préoccupés par les performances de p99 (et p999).  L'optimisation du retard moyen ne résout pas nécessairement le problème des pics d'émission. <br><br>  Enfin, dans notre environnement, les tailles de fichiers typiques sont beaucoup plus petites.  90% de nos hits de cache sont inférieurs à 60 Ko.  Plus les fichiers sont petits, moins il y a de cas de blocage (généralement nous lisons le fichier entier en deux lectures). <br><br>  Regardons les E / S disque lorsqu'elles sont touchées dans le cache: <br><br><pre> <code class="hljs ruby">/<span class="hljs-regexp"><span class="hljs-regexp">/     https:/</span></span><span class="hljs-regexp"><span class="hljs-regexp">/example.com    0xCAFEBEEF fd = open("/cache</span></span><span class="hljs-regexp"><span class="hljs-regexp">/prefix/dir</span></span><span class="hljs-regexp"><span class="hljs-regexp">/EF/</span></span>BE/CAFEBEEF<span class="hljs-string"><span class="hljs-string">", O_RDONLY); //    32    //    ,  "</span></span>aio threads<span class="hljs-string"><span class="hljs-string">"  read(fd, buf, 32*1024);</span></span></code> </pre> <br>  32K ne sont pas toujours lus.  Si les en-têtes sont petits, vous devez lire seulement 4 Ko (nous n'utilisons pas directement les E / S, donc le noyau arrondit à 4 Ko).  <code>open()</code> semble inoffensif, mais il prend en fait des ressources.  Au minimum, le noyau doit vérifier si le fichier existe et si le processus appelant a l'autorisation de l'ouvrir.  Il doit trouver l'inode pour <code>/cache/prefix/dir/EF/BE/CAFEBEEF</code> , et pour cela il devra chercher <code>CAFEBEEF</code> dans <code>/cache/prefix/dir/EF/BE/</code> .  En bref, dans le pire des cas, le noyau effectue cette recherche: <br><br><pre> <code class="hljs pgsql">/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE/CAFEBEEF</code> </pre> <br>  Ce sont 6 lectures distinctes que <code>open()</code> produit, contre 1 <code>read()</code> !  Heureusement, dans la plupart des cas, la recherche tombe dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cache de</a> la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dentisterie</a> et n'atteint pas le SSD.  Mais il est clair que le traitement de <code>read()</code> dans un pool de threads ne représente que la moitié de l'image. <br><br><h1>  Accord final: open () non bloquant dans les pools de threads </h1><br>  Par conséquent, nous avons apporté une modification à Nginx afin que <code>open()</code> soit principalement exécuté à l'intérieur du pool de threads et ne bloque pas la boucle d'événements.  Et voici le résultat de non-bloquant open () et read () en même temps: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d70/b1a/84b/d70b1a84b46934921ffd5a1fd7e7182a.png"><br><br>  Le 26 juin, nous avons apporté les modifications aux 5 centres de données les plus occupés et le lendemain, à tous les 146 autres centres de données du monde.  Le pic total p99 TTFB a diminué de 6 fois.  En fait, si nous résumons constamment le traitement de 8 millions de demandes par seconde, nous économisons à Internet 54 ans d'attente chaque jour. <br><br>  Notre série d'événements ne s'est pas encore complètement débarrassée des serrures.  En particulier, le blocage se produit toujours la première fois que le fichier est mis en cache (à la fois <code>open(O_CREAT)</code> et <code>rename()</code> ) ou lors de la mise à jour de la revalidation.  Mais de tels cas sont rares par rapport aux accès au cache.  À l'avenir, nous envisagerons la possibilité de déplacer ces éléments en dehors de la boucle de traitement d'événements pour améliorer encore le facteur de retard p99. <br><br><h1>  Conclusion </h1><br>  Nginx est une plate-forme puissante, mais la mise à l'échelle de charges d'E / S Linux extrêmement élevées peut être une tâche ardue.  Les décharges Nginx standard lisent dans des threads séparés, mais à notre échelle, nous devons souvent aller plus loin. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr419023/">https://habr.com/ru/post/fr419023/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr419011/index.html">Jinja2 dans le monde C ++, deuxième partie. Rendu</a></li>
<li><a href="../fr419013/index.html">Attribution basée sur l'entonnoir pour les entreprises SaaS B2B - car nous avons considéré la valeur de tous les efforts de marketing</a></li>
<li><a href="../fr419017/index.html">Nouveautés de ConstraintLayout 1.1</a></li>
<li><a href="../fr419019/index.html">AlterEgo: un appareil qui peut lire (certaines) pensées</a></li>
<li><a href="../fr419021/index.html">Les principaux types d'impression et leurs fonctionnalités</a></li>
<li><a href="../fr419025/index.html">@Pythonetc compilation, juillet 2018</a></li>
<li><a href="../fr419027/index.html">Sécurité de l'information des paiements bancaires sans espèces. Partie 6 - Analyse de la criminalité bancaire</a></li>
<li><a href="../fr419029/index.html">Fortnite est devenu un phénomène social. Les parents recrutent de plus en plus des entraîneurs pour leurs enfants et jouent avec eux</a></li>
<li><a href="../fr419033/index.html">Une petite note sur le sujet de l'exécution de vue.js dans le cluster kubernetes</a></li>
<li><a href="../fr419035/index.html">Livre «Head First Agile. Gestion de projet flexible ”</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
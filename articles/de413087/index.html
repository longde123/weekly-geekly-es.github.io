<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ñ™Ô∏è ü§Ω üõ∏ Mann Autoassistent üë®üèø‚Äçü§ù‚Äçüë®üèΩ üîÉ üèöÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Blog ist normalerweise der Kennzeichenerkennung gewidmet. Bei der Arbeit an dieser Aufgabe kamen wir jedoch zu einer interessanten L√∂sung, die ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mann Autoassistent</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/413087/">  Dieser Blog ist normalerweise der Kennzeichenerkennung gewidmet.  Bei der Arbeit an dieser Aufgabe kamen wir jedoch zu einer interessanten L√∂sung, die leicht auf eine Vielzahl von Computer-Vision-Aufgaben angewendet werden kann.  Wir werden jetzt dar√ºber sprechen: Wie man ein Erkennungssystem erstellt, das Sie nicht im Stich l√§sst.  Und wenn Sie versagen, k√∂nnen Sie ihr sagen, wo der Fehler liegt, sich weiterbilden und eine etwas zuverl√§ssigere L√∂sung als zuvor finden.  Willkommen bei Katze! <br><br><img width="800" src="https://habrastorage.org/webt/oa/jr/p5/oajrp5emopyf5wdieawfi47crdo.jpeg"><br><a name="habracut"></a><br><h3>  Was ist passiert? </h3><br>  Stellen Sie sich vor, Sie standen vor der Aufgabe, auf dem Foto Pizza zu finden und festzustellen, um welche Art von Pizza es sich handelt. <br><br>  Lassen Sie uns kurz den Standardweg durchgehen, den wir oft gegangen sind.  Warum?  Um zu verstehen, wie es geht ... keine Notwendigkeit. <br><br>  <b>Schritt 1:</b> Heben Sie die Basis auf <br><br><img src="https://habrastorage.org/webt/gf/rl/sx/gfrlsxreghr2shr-jazcddvedds.jpeg"><br><br>  <b>Schritt 2:</b> F√ºr die Zuverl√§ssigkeit der Erkennung kann festgestellt werden, dass es Pizza gibt und was der Hintergrund ist (daher werden wir ein neuronales Segmentierungsnetzwerk in das Erkennungsverfahren einbeziehen, aber es lohnt sich oft): <br><br><img src="https://habrastorage.org/webt/x6/r7/xz/x6r7xzm1vgo0_ifq3dvhrlduhdk.jpeg"><br><br>  <b>Schritt 3:</b> Wir bringen es in eine ‚Äûnormalisierte Form‚Äú und klassifizieren es unter Verwendung eines anderen neuronalen Faltungsnetzwerks: <br><br><img src="https://habrastorage.org/webt/al/xf/4v/alxf4vznbx2lstcpyzxpkyqceh4.jpeg"><br><br>  Gro√üartig!  Jetzt haben wir eine Trainingsbasis.  Im Durchschnitt kann die Gr√∂√üe der Trainingsbasis mehrere tausend Bilder betragen. <br><br>  Wir nehmen 2 Faltungsnetzwerke, zum Beispiel Unet und VGG.  Das erste wird an den Eingabebildern trainiert, dann normalisieren wir das Bild und trainieren die VGG f√ºr die Klassifizierung.  Es funktioniert gro√üartig, wir √ºbertragen es an den Kunden und betrachten ehrlich verdientes Geld. <br><br><h3>  So funktioniert das nicht! </h3><br>  Leider fast nie.  Bei der Implementierung treten mehrere schwerwiegende Probleme auf: <br><br><ol><li>  Variabilit√§t der Eingabedaten.  Wir haben an einem Beispiel studiert, in Wirklichkeit ist alles anders gelaufen.  Ja, gerade w√§hrend des Betriebs ist etwas schief gelaufen. </li><li>  Sehr oft bleibt die Erkennungsgenauigkeit unzureichend.  Ich m√∂chte 99,5%, aber an einem guten Tag geht es von 60% auf 90%.  Aber sie wollten in der Regel eine L√∂sung automatisieren, die selbst funktioniert und sogar besser als Menschen! <br></li><li>  Solche Aufgaben werden h√§ufig ausgelagert, was bedeutet, dass die Vertr√§ge bereits geschlossen sind, die Gesetze unterzeichnet sind und der Gesch√§ftsinhaber entscheiden muss, ob er in die √úberarbeitung investiert oder die Entscheidung ganz aufgibt. </li><li>  Ja, es beginnt sich mit der Zeit zu verschlechtern, wie in jedem komplexen System, wenn Sie keine Spezialisten einbeziehen, die an der Erstellung beteiligt waren, oder das gleiche Qualifikationsniveau. </li></ol><br>  Infolgedessen wird f√ºr viele, die all diese Mechanik mit den H√§nden ber√ºhrt haben, klar, dass alles auf eine v√∂llig andere Weise geschehen sollte.  Ungef√§hr so: <br><br><img src="https://habrastorage.org/webt/r7/d7/y6/r7d7y6j9ufu170_7qax9716mcne.png"><br><br>  Daten werden an unseren Server gesendet (√ºber http POST oder mithilfe der Python-API). Der GPU-Server erkennt sie "wie es k√∂nnte" und gibt das Ergebnis sofort zur√ºck.  Unterwegs wird das gleiche Erkennungsergebnis zusammen mit dem Bild zum Archiv hinzugef√ºgt.  Eine Person kontrolliert dann alle Daten oder einen zuf√§lligen Teil davon und korrigiert sie.  Das korrigierte Ergebnis wird in das zweite Archiv gestellt.  Und wenn dies zweckm√§√üig ist (z. B. nachts), werden alle zur Erkennung verwendeten neuronalen Faltungsnetzwerke unter Verwendung der von der Person korrigierten Daten umgeschult. <br><br>  Eine solche Erkennungsschaltung, menschliche √úberwachung und Weiterbildung l√∂sen viele der oben aufgef√ºhrten Probleme.  Dar√ºber hinaus kann in L√∂sungen, in denen eine hohe Genauigkeit erforderlich ist, eine vom Menschen verifizierte Ausgabe verwendet werden.  Es scheint, dass diese Verwendung von vom Menschen verifizierten Daten zu kostspielig ist, aber wir werden weiter zeigen, dass sie fast immer wirtschaftlich sinnvoll ist. <br><br><h3>  Echtes Beispiel </h3><br>  Wir haben das beschriebene Prinzip umgesetzt und erfolgreich auf mehrere reale Aufgaben angewendet.  Eine davon ist die Erkennung von Zahlen auf Bildern von Containern in Eisenbahnterminals, die von einem Tablet stammen.  Es ist sehr praktisch - richten Sie das Tablet auf den Beh√§lter, erhalten Sie die erkannte Nummer und arbeiten Sie damit im Tablet-Programm. <br><br>  Ein typisches Schnappschuss-Beispiel: <br><br><img src="https://habrastorage.org/webt/z-/am/06/z-am0654dzncgmhthgumqm_et7w.jpeg"><br><br>  Auf dem Bild ist die Zahl fast perfekt, nur viel visuelles Rauschen.  Bei Aufnahmen treten jedoch scharfe Schatten, Schnee, unerwartete Beschriftungslayouts, ernsthafte Neigungen oder Perspektiven auf. <br><br>  Und so sieht es aus wie eine Reihe von Webseiten, auf denen all die ‚ÄûMagie‚Äú geschieht: <br><br>  1) Hochladen der Datei auf den Server (dies kann nat√ºrlich nicht √ºber die HTML-Seite erfolgen, sondern mit Python oder einer anderen Programmiersprache): <br><br><img src="https://habrastorage.org/webt/px/oq/jb/pxoqjbj78lppmgsq3ohmxbdrepu.png"><br>  2) Der Server gibt das Erkennungsergebnis zur√ºck: <br><br><img src="https://habrastorage.org/webt/wx/iq/xo/wxiqxof-umbhtkwnp1thymupo98.png"><br>  3) Und dies ist eine Seite f√ºr den Bediener, der den Erfolg der Erkennung √ºberwacht und gegebenenfalls das Ergebnis korrigiert.  Es gibt zwei Stufen: die Suche nach Bereichen von Symbolgruppen, deren Erkennung.  Der Bediener kann dies alles korrigieren, wenn er einen Fehler sieht. <br><br><img src="https://habrastorage.org/webt/yt/le/cv/ytlecvmjlo-3mljkhirkpt0svdc.png"><br>  4) Hier ist eine einfache Seite, auf der Sie mit dem Training f√ºr jede der Erkennungsstufen beginnen und durch Ausf√ºhren den aktuellen Verlust anzeigen k√∂nnen. <br><br><img src="https://habrastorage.org/webt/0h/fb/vd/0hfbvdw7eof_rnu21myj-cuyihw.png"><br>  Harter Minimalismus, aber es funktioniert gro√üartig! <br><br>  Wie kann dies von der Seite eines Unternehmens aussehen, das plant, den beschriebenen Ansatz (oder unsere Erfahrung und Recognitor-Server) zu verwenden? <br><br><ol><li>  Es werden hochmoderne neuronale Netze ausgew√§hlt.  Wenn alles auf vorhandenen Debug-L√∂sungen basiert, k√∂nnen Sie den Server starten und das Markup in einer Woche konfigurieren. <br></li><li>  Auf dem Server ist ein Datenstrom (vorzugsweise endlos) organisiert, mehrere hundert Frames sind markiert. <br></li><li>  Das Training beginnt.  Wenn alles ‚Äûpasst‚Äú, ist das Ergebnis 60-70% der erfolgreichen Erkennung, was bei der weiteren Kennzeichnung sehr hilfreich ist. <br></li><li>  Dann beginnt die systematische Arbeit, alle m√∂glichen Situationen darzustellen, die Erkennungsergebnisse zu √ºberpr√ºfen, zu bearbeiten und umzuschulen.  Wie Sie lernen, wird die Einbettung des Systems in einen Gesch√§ftsprozess immer kosteng√ºnstiger. </li></ol><br><h3>  Wer macht das noch? </h3><br>  Das Closed-Loop-Thema ist nicht neu.  Viele Unternehmen bieten Datenverarbeitungssysteme der einen oder anderen Art an.  Das Arbeitsparadigma kann jedoch auf ganz andere Weise aufgebaut werden: <br><br><ul><li>  Nvidia Digits sind einige ziemlich gute und leistungsstarke Modelle, die in eine intuitive Benutzeroberfl√§che eingebunden sind, in der der Benutzer seine Bilder und JSON anh√§ngen muss.  Das Hauptplus - ein Minimum an Programmier- und Verwaltungskenntnissen bietet Ihnen eine gute L√∂sung.  Minus - diese L√∂sung kann bei weitem nicht optimal sein (zum Beispiel ist es nicht m√∂glich, √ºber SSD gut nach Autonummern zu suchen).  Und um zu verstehen, wie die L√∂sung optimiert werden kann, verf√ºgt der Benutzer nicht √ºber ausreichende Kenntnisse.  Wenn er genug Wissen hat, braucht er keine Ziffern.  Das zweite Minus: Sie ben√∂tigen Ihre eigene Ausr√ºstung, um alles zu konfigurieren und bereitzustellen. <br></li><li>  Markup-Services wie Mechanical Turk, Toloka, Supervise.ly.  Die ersten beiden bieten Ihnen Markup-Tools sowie Personen, die die Daten markieren k√∂nnen.  Letzteres bietet gro√üartige Werkzeuge, aber ohne Menschen.  Durch Services k√∂nnen Sie die menschliche Arbeit automatisieren, m√ºssen jedoch ein Experte f√ºr die Festlegung der Aufgabe sein. <br></li><li>  Unternehmen, die bereits geschult sind und eine feste L√∂sung anbieten (Microsoft, Google, Amazon).  Lesen Sie hier mehr dar√ºber (https://habr.com/post/312714/).  Ihre Entscheidungen sind nicht flexibel, nicht immer "unter der Haube" sind die besten Entscheidungen, die in Ihrem Fall notwendig sind.  Im Allgemeinen hilft es fast immer nicht. </li><li>  Unternehmen, die speziell mit Ihren Daten arbeiten, z. B. ScaleAPI (https://www.scaleapi.com/).  Sie haben eine gro√üartige API, f√ºr den Kunden wird es eine Black Box sein.  Eingabedaten - Ausgabeergebnis.  Es ist sehr wahrscheinlich, dass sich im Inneren die besten Automatisierungsl√∂sungen befinden, aber das spielt f√ºr Sie keine Rolle.  Ziemlich teure L√∂sungen in Bezug auf einen Frame, aber wenn Ihre Daten wirklich wertvoll sind - warum nicht? </li><li>  Unternehmen, die √ºber die Werkzeuge verf√ºgen, um einen fast vollst√§ndigen Zyklus mit ihren eigenen H√§nden durchzuf√ºhren.  Zum Beispiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PowerAI von IBM</a> .  Es ist fast wie bei DIGITS, aber Sie m√ºssen nur die Datens√§tze markieren.  Au√üerdem optimiert niemand neuronale Netze und L√∂sungen.  Aber viele F√§lle wurden ausgearbeitet.  Das resultierende neuronale Netzwerkmodell wird f√ºr Sie bereitgestellt und erh√§lt http-Zugriff.  Hier gibt es den gleichen Nachteil wie bei Digits - Sie m√ºssen verstehen, was zu tun ist.  Es ist Ihr Fall, der m√∂glicherweise ‚Äûnicht konvergiert‚Äú oder einfach einen ungew√∂hnlichen Ansatz zur Erkennung erfordert.  Im Allgemeinen ist die L√∂sung perfekt, wenn Sie eine ziemlich normale Aufgabe mit gut trennbaren Objekten haben, die klassifiziert werden m√ºssen. <br></li><li>  Unternehmen, die mit ihren Tools genau Ihr Problem l√∂sen.  Es gibt nicht viele solcher Unternehmen.  In Wirklichkeit w√ºrde ich nur CrowdFlower auf sie verweisen.  Hier werden sie f√ºr angemessenes Geld Scribbler einsetzen, einen Manager zuweisen und ihre Server bereitstellen, auf denen Ihre Modelle gestartet werden.  Und f√ºr mehr Geld k√∂nnen sie ihre Entscheidungen f√ºr Ihre Aufgabe √§ndern oder optimieren. <br>  Gro√üe Unternehmen arbeiten mit ihnen zusammen - ebay, oracle, tesco, adobe.  Gemessen an ihrer Offenheit interagieren sie erfolgreich mit kleinen Unternehmen. <br>  Wie unterscheidet sich dies von der benutzerdefinierten Entwicklung, die beispielsweise EPAM durchf√ºhrt?  Dass hier alles fertig ist.  99% der L√∂sung wird nicht geschrieben, sondern aus vorgefertigten Modulen zusammengesetzt: Datenmarkup, Netzwerkauswahl, Schulung, Entwicklung.  Unternehmen, die sich auf Bestellung entwickeln, verf√ºgen nicht √ºber eine solche Geschwindigkeit, die Dynamik der L√∂sungsentwicklung und die fertige Infrastruktur.  Wir glauben, dass der von CrowdFlower identifizierte Trend und Ansatz wahr ist. <br></li></ul><br><h3>  F√ºr welche Aufgaben funktioniert das? </h3><br>  M√∂glicherweise werden 70% der Aufgaben auf diese Weise automatisiert.  Die am besten geeigneten Aufgaben sind die vielf√§ltige Erkennung von Bereichen, die Text enthalten.  Zum Beispiel Autokennzeichen, √ºber die wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bereits gesprochen haben</a> , Zugnummern ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier ist unser Beispiel vor zwei Jahren</a> ), Inschriften auf Containern. <br><br><img src="https://habrastorage.org/webt/br/iq/gi/briqgiqlbmobcki2ghzdygb92yw.jpeg"><br><br>  In Fabriken werden viele symbolische technische Informationen erkannt, um Produkte und deren Qualit√§t zu ber√ºcksichtigen. <br><br>  Dieser Ansatz hilft sehr beim Erkennen von Produkten in Verkaufsregalen und Preisschildern, obwohl dort recht komplizierte Erkennungsl√∂sungen erstellt werden m√ºssen. <br><br><img src="https://habrastorage.org/webt/xw/s3/yz/xws3yzpdggdme-_d3sukvfisrr8.jpeg"><br><br>  Mit technischen Informationen k√∂nnen Sie sich jedoch den Aufgaben entziehen.  Jede Semantik, sei es Instanzsegmentierung, mit der Erkennung von Autos, Argali, Elchen und Pelzrobben wird ebenfalls perfekt auf diesen Ansatz fallen. <br><br><img src="https://habrastorage.org/webt/6l/kq/qn/6lkqqnugn0xz8okakq096e4xjk8.png"><br><br>  Eine vielversprechende Richtung ist die Aufrechterhaltung der Kommunikation mit Personen in Sprach- und Text-Chat-Bots.  Es wird eine eher ungew√∂hnliche Art der Kennzeichnung geben: Kontext, Art der Phrase, ihre ‚ÄûF√ºllung‚Äú.  Das Prinzip ist jedoch dasselbe: Wir arbeiten in einem automatischen Modus, eine Person kontrolliert die Richtigkeit des Verstehens und der Antworten.  Bei unzufriedenem oder irritiertem Ton des Kunden k√∂nnen Sie auf die Unterst√ºtzung des Bedieners zur√ºckgreifen.  Wenn sich Daten ansammeln, trainieren wir neu. <br><br><h3>  Wie arbeite ich mit Video? </h3><br>  Wenn Sie oder Ihr Unternehmen die erforderlichen Kompetenzen entwickelt haben (ein wenig Erfahrung im maschinellen Lernen, Arbeiten mit dem Zoo Framework, sowohl offline als auch online), gibt es keine Schwierigkeiten bei der L√∂sung einfacher Computer-Vision-Probleme: Segmentierung, Klassifizierung, Texterkennung und andere <br><br>  Aber f√ºr das Video ist nicht alles so glatt.  Wie markieren Sie diese endlosen Datenmengen?  Beispielsweise kann sich herausstellen, dass alle paar Sekunden ein Objekt (oder mehrere Objekte) in dem Rahmen angezeigt wird, der markiert werden muss.  Infolgedessen kann all dies zu einer Einzelbildanzeige werden und nimmt so viele Ressourcen in Anspruch, dass man nach dem Start einer L√∂sung nicht einmal √ºber zus√§tzliche Kontrolle durch eine Person sprechen muss.  Dies kann jedoch √ºberwunden werden, wenn Sie das Video richtig pr√§sentieren, um Bilder mit einem interessierenden Bereich hervorzuheben. <br><br>  Zum Beispiel stie√üen wir auf riesige Videoserien, in denen ein bestimmtes Objekt hervorgehoben werden musste - die Kopplung der Bahnsteige.  Und es war wirklich nicht einfach.  Es stellte sich heraus, dass nicht alles so be√§ngstigend ist. Wenn Sie den Monitor weiter nehmen, w√§hlen Sie eine Bildrate, z. B. 10 fps, und platzieren Sie 256 Bilder auf einem Bild, d. H.  25,6 s in einem Bild: <br><br><img src="https://habrastorage.org/webt/wl/rs/sj/wlrssj5ye7bbn_ufkd_zvlfm1pk.jpeg"><br><br>  Es sieht wahrscheinlich be√§ngstigend aus.  In der Realit√§t dauert es jedoch ungef√§hr 15 Sekunden, bis Sie zu einem einzelnen Rahmen durchgeklickt sind und die Mitte der Fahrzeugkupplung auf dem Rahmen ausgew√§hlt haben.  Und selbst eine Person an ein oder zwei Tagen kann mindestens 10 Stunden Video markieren.  Holen Sie sich mehr als 30.000 Beispiele f√ºr das Training.  Dar√ºber hinaus ist der Durchgang von Plattformen vor der Kamera in diesem Fall kein fortlaufender Prozess (aber eher selten, sollte angemerkt werden), es ist sogar in fast Echtzeit ziemlich realistisch, die Erkennungsmaschine zu korrigieren und die Trainingsbasis aufzuf√ºllen!  Und wenn die Erkennung in den meisten F√§llen korrekt erfolgt, kann eine Stunde Video in wenigen Minuten √ºberwunden werden.  Und dann ist es wirtschaftlich nicht rentabel, die totale Kontrolle durch die Person zu vernachl√§ssigen. <br><br>  Es ist immer noch einfacher, wenn das Video mit ‚ÄûJa / Nein‚Äú markiert werden muss, anstatt das Objekt zu lokalisieren.  Schlie√ülich bleiben Ereignisse oft ‚Äûzusammengeklebt‚Äú, und mit einem Mausklick k√∂nnen Sie bis zu 16 Bilder gleichzeitig markieren. <br><br>  Das einzige, was Sie in der Regel bei der Analyse des Videos in zwei Schritten tun m√ºssen: Suchen Sie nach ‚ÄûFrames oder Bereichen von Interesse‚Äú und arbeiten Sie dann mit jedem solchen Frame (oder jeder Frame-Sequenz) nach anderen Algorithmen. <br><br><h3>  Maschinen-Mensch-Wirtschaft </h3><br>  Wie viel k√∂nnen die Kosten f√ºr die Verarbeitung visueller Daten optimiert werden?  Auf die eine oder andere Weise ist es unbedingt erforderlich, eine Person zur Kontrolle der Datenerkennung zu haben.  Wenn diese Kontrolle selektiv ist, sind die Kosten vernachl√§ssigbar.  Aber wenn wir √ºber totale Kontrolle sprechen, wie viel kann es dann von Vorteil sein?  Es stellt sich heraus, dass dies fast immer Sinn macht, wenn zuvor eine Person dieselbe Aufgabe ohne die Hilfe einer Maschine ausgef√ºhrt hat. <br><br>  Nehmen wir ganz am Anfang das nicht beste Beispiel: Suche nach Pizza im Bild, Markup und Typauswahl (und in Wirklichkeit eine Reihe anderer Merkmale).  Obwohl die Aufgabe nicht so synthetisch ist, wie es scheinen mag.  Es gibt eine Kontrolle √ºber das Erscheinungsbild von Franchise-Netzwerkprodukten in der Realit√§t. <br><br>  Angenommen, die Erkennung mit einem GPU-Server erfordert 0,5 Sekunden Maschinenzeit, damit eine Person einen Rahmen f√ºr etwa 10 Sekunden vollst√§ndig markiert (w√§hlen Sie die Art der Pizza und ihre Qualit√§t anhand einer Reihe von Parametern) und um zu √ºberpr√ºfen, ob alles vom Computer korrekt erkannt wird, ben√∂tigen Sie 2 Sekunden.  Nat√ºrlich wird es eine Herausforderung sein, wie bequem es ist, diese Daten zu pr√§sentieren, aber solche Zeiten sind mit unserer Praxis durchaus vergleichbar. <br><br>  Wir ben√∂tigen mehr Input f√ºr die Kosten f√ºr das manuelle Layout und die Miete eines GPU-Servers.  In der Regel m√ºssen Sie sich nicht auf eine vollst√§ndige Serverlast verlassen.  Erm√∂glichen Sie das Laden von 100.000 Frames pro Tag (60% der Verarbeitungsleistung einer GPU) mit gesch√§tzten Kosten f√ºr eine monatliche Servermiete von 60.000 Rubel.  Es ergeben sich 2 Cent f√ºr die Analyse eines Frames auf der GPU.  Eine manuelle Analyse zu einem Preis von 30.000 R f√ºr 40 Stunden Arbeitszeit kostet 26 Kopeken pro Frame. <br><br><img src="https://habrastorage.org/webt/kt/j3/4-/ktj34-ojvq_duoxm6vrylckti_a.png"><br><br>  Wenn Sie anschlie√üend die Gesamtsteuerung entfernen, k√∂nnen Sie einen Preis von fast 20 Rubel pro 1000 Frames erzielen.  Wenn viele Eingabedaten vorhanden sind, ist es m√∂glich, Erkennungsalgorithmen zu optimieren, an der Daten√ºbertragung zu arbeiten und eine noch h√∂here Effizienz zu erzielen. <br><br>  In der Praxis hat das Entladen einer Person, w√§hrend das Erkennungssystem lernt, eine weitere wichtige Bedeutung: Es erleichtert die Skalierung Ihres Produkts erheblich.  Durch eine deutliche Erh√∂hung der Datenmenge k√∂nnen Sie den Erkennungsserver besser trainieren und die Genauigkeit erh√∂hen.  Und die Anzahl der am Datenverarbeitungsprozess beteiligten Mitarbeiter wird nicht proportional zum Datenvolumen zunehmen, was das Wachstum des Unternehmens aus organisatorischer Sicht erheblich vereinfachen wird. <br><br>  Je mehr Text und Umrisse Sie manuell eingeben m√ºssen, desto rentabler ist in der Regel die automatische Erkennung. <br><br><h3>  Und √§ndert sich alles? </h3><br>  Nat√ºrlich nicht alle.  Aber jetzt sind einige Bereiche des Gesch√§fts nicht mehr so ‚Äã‚Äãverr√ºckt wie zuvor. <br><br>  M√∂chten Sie einen Offline-Dienst ohne eine Person in der Einrichtung durchf√ºhren?  Pflanzen Sie einen Bediener aus der Ferne und √ºberwachen Sie ihn <br>  auf Kameras f√ºr jeden Kunden?  Es wird sich als etwas schlimmer herausstellen als eine lebende Person an Ort und Stelle.  Ja, und die Betreiber brauchen fast mehr.  Und wenn Sie den Bediener alle 5 Mal entladen?  Dies kann ein Sch√∂nheitssalon ohne Empfang und Kontrolle in der Fabrik sowie Sicherheitssysteme sein.  Eine 100% ige Genauigkeit ist nicht erforderlich - Sie k√∂nnen den Bediener vollst√§ndig von der Kette ausschlie√üen. <br><br>  Es ist m√∂glich, recht komplexe Buchhaltungssysteme f√ºr vorhandene Dienste zu organisieren, um deren Effizienz zu steigern: Kontrolle von Fahrg√§sten, Fahrzeugen, Dienstzeiten, bei denen die Gefahr besteht, dass das Ticketb√ºro umgangen wird usw. <br><br>  Wenn sich die Aufgabe auf dem aktuellen Entwicklungsstand von Computer Vision befindet und keine v√∂llig neuen L√∂sungen erfordert, sind keine ernsthaften Investitionen in die Entwicklung erforderlich. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de413087/">https://habr.com/ru/post/de413087/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de413071/index.html">DeepMind brachte AI bei, YouTube-Videospiele zu spielen</a></li>
<li><a href="../de413073/index.html">So arbeiten Sie mit der Cloud: 30 Materialien, praktische Anleitungen und Tipps zum Thema PD, IS und IaaS</a></li>
<li><a href="../de413075/index.html">Volltextsuche: Elasticsearch-spezifische Funktionen f√ºr komplexe Aufgaben</a></li>
<li><a href="../de413077/index.html">Die Zusammenfassung interessanter Materialien f√ºr den mobilen Entwickler # 255 (28. Mai - 3. Juni)</a></li>
<li><a href="../de413083/index.html">Entwickler vom MIT erstellen eine bionische Prothese mit pr√§ziser Bewegungskoordination</a></li>
<li><a href="../de413091/index.html">Bequeme Protokollierung in SpringBoot + Log4j2 + Maven</a></li>
<li><a href="../de413093/index.html">In Erwartung des Rennens der Weltraumh√§ndler in den USA und in China</a></li>
<li><a href="../de413095/index.html">Anwendung neuronaler Netzwerktechnologien: Softwareentwicklung</a></li>
<li><a href="../de413097/index.html">Basierend auf Software auf Unternehmensebene, millionenfach getestet: openSUSE Leap 15 ver√∂ffentlicht</a></li>
<li><a href="../de413099/index.html">Downclocking RAM auf MacBook</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
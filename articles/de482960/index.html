<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤽🏻 ♑️ 👨🏾‍🤝‍👨🏻 WCS 5.2 Übersicht - WebRTC Server für Webentwickler von Online-Broadcasts und Video-Chats 🙍🏾 👊🏽 👮</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Alice ist eine erfahrene Full-Stack-Entwicklerin und kann mit PHP in einer Woche ein SAAS-Projekt-Framework in ihrem Lieblings-Framework schreiben. Am...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>WCS 5.2 Übersicht - WebRTC Server für Webentwickler von Online-Broadcasts und Video-Chats</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flashphoner/blog/482960/"><img src="https://habrastorage.org/webt/za/go/wo/zagowolkguxr8_bdsbwjmkvyd0a.jpeg"><br><br><p>  Alice ist eine erfahrene Full-Stack-Entwicklerin und kann mit PHP in einer Woche ein SAAS-Projekt-Framework in ihrem Lieblings-Framework schreiben.  Am vorderen Ende bevorzugt er Vue.js. </p><br><p> Ein Kunde, der unbedingt eine Website entwickeln muss, die der Treffpunkt von Arbeitgeber und Arbeitnehmer für ein persönliches Gespräch ist, wird an einem Telegramm geklopft.  Vollzeit - bedeutet direkten Videokontakt in Echtzeit mit Video und Sprache auf Augenhöhe. <br>  "Warum nicht Skype?" Sie fragen.  Es ist einfach so gekommen, dass ernsthafte Projekte und jedes Startup, das sich zweifellos als solches versteht, aus einer Vielzahl von Gründen versuchen, einen internen Kommunikationsdienst anzubieten, darunter: <a name="habracut"></a></p><br><p>  1) Geben Sie Ihre Benutzer nicht an externe Kommunikatoren weiter (Skype, <br>  Treffpunkte usw.).  Lass sie im Dienst. </p><br><p>  2) Überwachen Sie die Kommunikation: Anrufverlauf, Interviewergebnisse. </p><br><p>  3) Anrufe aufzeichnen (natürlich beide Parteien über die Aufzeichnung benachrichtigen). </p><br><p>  4) Verlassen Sie sich nicht auf Richtlinien und Aktualisierungen von Diensten von Drittanbietern.  Jeder kennt diese Geschichte: Skype aktualisiert, und es begann ... </p><br><p>  Die Aufgabe sieht einfach aus.  WebRTC ist über das Thema gegoogelt und es sieht so aus, als könnten Sie eine Peer-to-Peer-Verbindung zwischen zwei Browsern einrichten. Es bleiben jedoch folgende Fragen offen: </p><br><p>  1) Woher bekommen Sie STUN / TURN Server? </p><br><p>  2) Ist es möglich, ohne sie auszukommen? </p><br><p>  3) Aufzeichnen eines Peer-to-Peer-WebRTC-Anrufs </p><br><p>  4) Was passiert, wenn Sie einen Dritten zum Anruf hinzufügen müssen, z. B. einen Personalleiter oder einen anderen Spezialisten des Arbeitgebers. </p><br><p>  Es stellt sich heraus, dass nur WebRTC und Peer-to-Peer nicht ausreichen, und es ist nicht klar, was damit zu tun ist, um die erforderlichen Videofunktionen des Dienstes zu starten. </p><br><h2>  Artikelinhalt </h2><br><div class="spoiler">  <b class="spoiler_title">Inhaltsverzeichnis</b> <div class="spoiler_text"><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Server und API</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Eingehende Streams</a> <br><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">WebRTC</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">RTMP</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Rtsp</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Vod</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">SIP / RTP</a> </li></ul><br></li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Ausgehende Streams</a> <br><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">WebRTC</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">RTMP</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Rtsp</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">MSE</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Hls</a> </li></ul><br></li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Posteingang und Postausgang</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Eingehende Stream-Manipulation</a> <br><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Aufnahme eingehender Streams</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Snapshot-Entfernung</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Stream zum Mixer hinzufügen</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Stream-Transcodierung</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Hinzufügen eines Wasserzeichens</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Hinzufügen eines FPS-Filters</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Drehen Sie das Bild um 90, 180, 270 Grad</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Wo ist die Kontrolle der eingehenden Streams</a> </li></ul><br></li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Stream-Relay</a> <br><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">WebRTC</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">RTMP</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">SIP / RTP</a> </li></ul><br></li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Verbinden von Servern mit einem CDN-Netzwerk zur Inhaltsverarbeitung</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Um es zusammenzufassen</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482960/">Referenzen</a> </li></ul><br></div></div><br><br><h2><a name="serverapi"></a>  Server und API </h2><br><p>  Um all diese White Spots zu schließen, werden Serverlösungen und eine Peer-Server-Peer-Architektur verwendet.  Web Call Server 5.2 WCS ist eine der Serverlösungen - eine Entwicklungsplattform, mit der Sie dem Projekt solche Videofunktionen hinzufügen können, ohne sich um die Stabilität von STUN / TURN- und Peer-to-Peer-Verbindungen sorgen zu müssen. </p><br><p>  Auf der höchsten Ebene ist WCS ein JavaScript-API + -Serverteil.  Die API wird verwendet, um auf der Browserseite normales JavaScript zu entwickeln, und der Server verarbeitet den Videoverkehr und fungiert als Stateful Proxy für den Medienverkehr. </p><br><p><img src="https://habrastorage.org/webt/7a/w0/qv/7aw0qvwyfc9tak6ij9ycdr1sju4.png"></p><br><p>  Neben der JavaScript-API gibt es auch das Android SDK und das iOS SDK, die für die Entwicklung nativer mobiler Anwendungen für iOS bzw. Android erforderlich sind. </p><br><p>  Das Veröffentlichen eines Streams auf einem Server (Streaming eines Streams von einer Webcam zum Server) sieht beispielsweise folgendermaßen aus: </p><br><p>  Web SDK </p><br><pre><code class="plaintext hljs">session.createStream({name:”stream123”}).publish();</code> </pre> <br><p>  Android SDK </p><br><pre> <code class="plaintext hljs">publishStream = session.createStream(streamOptions) publishStream.publish();</code> </pre> <br><p>  iOS SDK </p><br><pre> <code class="plaintext hljs">FPWCSApi2Stream *stream = [session createStream:options error:&amp;error]; if(![stream publish:&amp;error]) { //published without errors }</code> </pre> <br><p>  Auf diese Weise können Sie nicht nur eine Webanwendung implementieren, sondern auch umfassende Funktionen für Google Play und den App Store mit Unterstützung für Video-Streaming.  Fügen Sie dem Bild der obersten Ebene mobile SDKs hinzu.  Es wird sich wie folgt herausstellen: </p><br><p><img src="https://habrastorage.org/webt/tf/z-/ya/tfz-yax_izaf-eyitcvd57y82h0.png"><br><br></p><h2><a name="Incomingstreams"></a>  Eingehende Streams </h2><br><p>  Der Streaming-Server (WCS) beginnt mit eingehenden Streams.  Um etwas zu verschenken, muss man es haben.  Um Videostreams an Zuschauer zu verteilen, ist es erforderlich, dass diese Streams in den Server gelangen, dessen RAM durchlaufen und über die Netzwerkkarte beendet werden.  Daher ist die erste Frage, die Sie sich stellen sollten, wenn Sie sich mit einem Medienserver vertraut machen, folgende: Für welche Protokolle und Formate akzeptiert dieser Streams.  Im Fall von WCS sind dies die folgenden Technologien: WebRTC, RTMP, RTSP, VOD, SIP / RTP. </p><br><p><img src="https://habrastorage.org/webt/du/2r/pc/du2rpcr6ihdkicklwlyusrodjog.png"></p><br><p>  Jedes der Protokolle kann von verschiedenen Clients verwendet werden.  Beispielsweise kann über WebRTC nicht nur ein Stream von einem Browser eingegeben werden, sondern auch von einem anderen Server.  Wir zeigen die möglichen Quellen des eingehenden Verkehrs in der Tabelle an. </p><br><p></p><div class="scrollable-table"><table><tbody><tr><td>  <strong>WebRTC</strong> </td><td>  <strong>RTMP</strong> </td><td>  <strong>Rtsp</strong> </td><td>  <strong>Vod</strong> </td><td>  <strong>SIP / RTP</strong> </td></tr><tr><td><ul><li>  Web SDK <br><ul><li>  Kamera + Mikrofon </li><li>  Leinwand </li><li>  Bildschirmfreigabe </li></ul><br></li><li>  Android SDK </li><li>  iOS SDK </li><li>  WCS <br><ul><li>  schieben </li><li>  ziehen </li></ul><br></li><li>  Cdn </li></ul><br></td><td><ul><li>  RTMP-Encoder <br><ul><li>  ffmpeg </li><li>  Obs </li><li>  Wirecast </li></ul><br></li><li>  Adobe Encoder </li><li>  WCS <br><ul><li>  schieben </li><li>  ziehen </li></ul><br></li><li>  Flash Player </li></ul><br></td><td><ul><li>  IP-Kamera </li><li>  RTSP-Server </li></ul><br></td><td><ul><li>  Dateisystem </li><li>  AWS S3 </li></ul><br></td><td><ul><li>  SIP-Endpunkt </li><li>  SIP-Konferenzen </li></ul><br></td></tr></tbody></table></div><br><p>  Wenn Sie die Quellen des eingehenden Datenverkehrs durchgehen, können Sie Folgendes hinzufügen: </p><br><br><h3><a name="inWebRTC"></a>  <strong>Eingehendes WebRTC</strong> </h3><br><p>  Mit Web SDK können Sie nicht nur die Kamera und das Mikrofon erfassen, sondern auch die Funktionen der Browser-API für den Zugriff auf die Bildschirmfreigabe verwenden.  Darüber hinaus können Sie ein beliebiges Canvas-Element erfassen, auf das für die anschließende Übertragung nur Canvas-Streaming gezeichnet wird. </p><br><p>  Android SDK und iOS SDK können aufgrund mobiler Besonderheiten im Handumdrehen zwischen der vorderen und hinteren Kamera des Geräts wechseln.  Auf diese Weise können Sie die Quelle während des Streamings wechseln, ohne den Stream zu stoppen. </p><br><p>  Der eingehende WebRTC-Stream kann auch von einem anderen WCS-Server mit den Methoden Push, Pull und CDN abgerufen werden, auf die später noch eingegangen wird. </p><br><p><img src="https://habrastorage.org/webt/zn/rw/5i/znrw5ikkd8vcjuexwarfzeqkhg4.jpeg"><br></p><h3><a name="inRTMP"></a>  <strong>Inbound rtmp</strong> </h3><br><p>  Das RTMP-Protokoll wird häufig in den bevorzugten OBS-Streamern und in anderen Encodern verwendet: Wirecast, Adobe Media Ensourcer, ffmpeg usw.  Mit einem dieser Encoder können Sie den Stream erfassen und an den Server senden. </p><br><p>  Sie können einen RTMP-Stream auch von einem anderen Medienserver oder WCS-Server abrufen <br>  mit Push-and-Pull-Methoden.  Im Fall von Push ist der Initiator der Remote-Server.  Im Fall von pull wenden wir uns an den lokalen, um den Stream vom fernen zu ziehen. </p><br><p><img src="https://habrastorage.org/webt/3o/8x/f8/3o8xf84v5rx2apw_09n_lm2cjoe.jpeg"></p><br><br><h3><a name="inRTSP"></a>  <strong>Eingehendes RTSP</strong> </h3><br><p>  Die Quellen des RTSP-Verkehrs sind normalerweise IP-Kameras oder Medienserver von Drittanbietern, die das RTSP-Protokoll unterstützen.  Obwohl beim Herstellen einer RTSP-Verbindung WCS als Initiator fungiert, wird der Audio- und Videoverkehr von der IP-Kamera zum WCS-Server geleitet.  Daher betrachten wir den Stream von der Kamera als eingehend. </p><br><p><img src="https://habrastorage.org/webt/ch/pj/qi/chpjqiof2ipgoqzmwx0zzkewrgm.jpeg"></p><br><br><h3><a name="inVOD"></a>  <strong>Eingehende VOD</strong> </h3><br><p>  Auf den ersten Blick scheint die VOD-Funktion (Video On Demand) ausschließlich mit ausgehenden Streams und der Wiedergabe der Datei durch Browser verbunden zu sein.  In unserem Fall ist das ein bisschen falsch.  WCS übersetzt die mp4-Datei ehrlich vom Dateisystem in localhost. Dadurch wird ein eingehender Stream erstellt, als stamme er aus einer Quelle eines Drittanbieters.  Wenn wir einen Viewer auf eine mp4-Datei beschränken, erhalten wir den klassischen VOD, bei dem der Viewer den Stream aufnimmt und ihn von Anfang an wiedergibt.  Wenn nicht beschränkt, erhalten wir VOD LIVE - eine Variation von VOD, bei der die Zuschauer die gleiche Datei wie einen Stream abspielen können und eine Verbindung zu dem Wiedergabepunkt herstellen, an dem sich alle anderen gerade befinden (voraufgezeichneter Fernsehmodus). </p><br><p><img src="https://habrastorage.org/webt/cn/ot/tv/cnottvwwytktaxh9vnbjexlxlaq.jpeg"><br><br></p><h3><a name="inSIP-RTP"></a>  <strong>Eingehendes SIP / RTP</strong> </h3><br><p>  Um eingehenden RTP-Verkehr innerhalb einer SIP-Sitzung zu empfangen, müssen Sie einen Anruf mit einem SIP-Gateway eines Drittanbieters einrichten.  Nach erfolgreicher Verbindung wird Audio- und / oder Videodatenverkehr vom SIP-Gateway geleitet, der auf der WCS-Seite in einen eingehenden Datenstrom eingeschlossen wird. </p><br><p><img src="https://habrastorage.org/webt/-r/km/io/-rkmio-9lhqlfjioblwkanzuxiq.jpeg"></p><br><br><h2><a name="Outgoingstreams"></a>  Ausgehende Streams </h2><br><p>  Nach dem Empfang des Streams auf dem Server können Sie den empfangenen Stream auf Anfrage an einen oder mehrere Viewer replizieren.  Der Viewer fordert einen Stream vom Player oder einem anderen Gerät an.  Solche Streams werden als ausgehende Streams oder "Streams von Zuschauern" bezeichnet, da Sitzungen mit solchen Streams immer auf der Seite des Zuschauers / Players initiiert werden.  Die Wiedergabetechnologien umfassen die folgenden Protokolle / Formate: WebRTC, RTMP, RTSP, MSE, HLS </p><br><div class="scrollable-table"><table><thead><tr><th>  WebRTC </th><th>  RTMP </th><th>  Rtsp </th><th>  MSE </th><th>  Hls </th></tr></thead><tbody><tr><td><ul><li>  Web SDK </li><li>  Android SDK </li><li>  iOS SDK </li><li>  WCS <br><ul><li>  ziehen </li><li>  Cdn </li></ul><br></li></ul><br></td><td><ul><li>  Flash Player </li><li>  RTMP-Player </li></ul><br></td><td><ul><li>  RTSP-Player <br><ul><li>  VLC </li><li>  WCS </li><li>  usw </li></ul><br></li></ul><br></td><td><ul><li>  Web SDK </li></ul><br></td><td><ul><li>  HLS-Spieler <br><ul><li>  hls.js </li><li>  einheimische Safari </li></ul><br></li></ul><br></td></tr></tbody></table></div><br><br><br><h3><a name="outWebRTC"></a>  <strong>Ausgehendes WebRTC</strong> </h3><br><p>  In diesem Fall fungieren das Web SDK, Android SDK und iOS SDK als API für den Player.  Ein Beispiel für das Abspielen eines WebRTC-Streams sieht folgendermaßen aus: </p><br><p>  Web SDK </p><br><pre> <code class="plaintext hljs">session.createStream({name:”stream123”}).play();</code> </pre> <br><p>  Android SDK </p><br><pre> <code class="plaintext hljs">playStream = session.createStream(streamOptions); playStream.play();</code> </pre> <br><p>  iOS SDK </p><br><pre> <code class="plaintext hljs">FPWCSApi2Stream *stream = [session createStream:options error:nil]; if(![stream play:&amp;error]) { //published without errors }</code> </pre> <br><p>  Dies ist der Veröffentlichungs-API sehr ähnlich, mit dem einzigen Unterschied, dass stattdessen <br>  stream.publish (), stream.play () wird zur Wiedergabe aufgerufen. </p><br><p>  Ein Player kann auch ein WCS-Server eines Drittanbieters sein, der den Befehl erhält, mithilfe der Pull-Methode einen Stream über WebRTC von einem anderen Server abzurufen oder einen Stream innerhalb von CDN abzurufen. </p><br><br><h3> <strong><a name="outRTMP"></a></strong>  <strong>Ausgehende rtmp</strong> </h3><br><p><img src="https://habrastorage.org/webt/in/zq/nb/inzqnbejvsout_d4n5iiej4gozi.png"></p><br><p>  Hier wird es hauptsächlich RTMP-Player geben - sowohl den bekannten Flash Player als auch Desktop- und Mobilanwendungen, die das RTMP-Protokoll verwenden, empfangen und spielen einen RTMP-Stream.  Tatsache ist, dass trotz der Tatsache, dass Flash den Browser verlassen hat, das RTMP-Protokoll, das häufig für Video-Broadcasts verwendet wird, und die mangelnde native Unterstützung in Browsern die Verwendung dieses recht erfolgreichen Protokolls in anderen Client-Anwendungen nicht verhindern.  Es ist bekannt, dass RTMP in VR-Playern für mobile Anwendungen für Android und iOS weit verbreitet ist. </p><br><br><h3><a name="outRTSP"></a>  <strong>Ausgehender RTSP</strong> </h3><br><p><img src="https://habrastorage.org/webt/ly/xu/r9/lyxur9b3gfzwsubfmrb3afmkfh0.png"></p><br><p>  Der WCS-Server kann als RTSP-Server fungieren und den empfangenen Stream über RTSP als reguläre IP-Kamera verteilen.  In diesem Fall muss der Player eine RTSP-Verbindung zum Server herstellen und den Stream zur Wiedergabe abrufen, als wäre es eine IP-Kamera. </p><br><br><h3><a name="outMSE"></a>  <strong>Ausgehende MSE</strong> </h3><br><p><img src="https://habrastorage.org/webt/lt/wh/wz/ltwhwz7b8urhlg4m5ay-blpg-d8.jpeg"></p><br><p>  In diesem Fall fordert der Player mithilfe des Websocket-Protokolls einen Stream vom Server an.  Der Server stellt Audio- und Videodaten auf Web-Sockets bereit.  Die Daten erreichen den Browser und werden in Blöcke konvertiert, die der Browser dank der standardmäßig unterstützten nativen MSE-Erweiterung wiedergeben kann.  Der Player arbeitet letztendlich auf der Basis des HTML5-Videoelements. </p><br><br><h3><a name="outHLS"></a>  <strong>Ausgehendes HLS</strong> </h3><br><p><img src="https://habrastorage.org/webt/if/5l/5f/if5l5fdsrgbgaekle2edci9gyws.jpeg"></p><br><p>  Hier fungiert WCS als HLS-Server oder Webserver, der HLS (HTTP Live Streaming) unterstützt.  Nachdem der eingehende Stream auf dem Server angezeigt wurde, wird eine HLS-Wiedergabeliste im .m3u8-Format generiert, die dem Player als Antwort auf eine HTTP-Anforderung übergeben wird.  Die Wiedergabeliste beschreibt, welche Abschnitte des Videos der Player herunterladen und anzeigen soll.  Der Player lädt Videosegmente herunter und spielt sie auf einer Browserseite, auf einem mobilen Gerät, auf einem Desktop, in einer Apple TV-Set-Top-Box und überall dort ab, wo HLS-Unterstützung in Anspruch genommen wird. </p><br><br><h2><a name="IncomingOutgoing"></a>  Posteingang und Postausgang </h2><br><p>  Insgesamt haben wir 5 eingehende und die gleiche Anzahl ausgehender Stream-Typen.  Wir listen auf <br>  sie in der Tabelle: </p><br><p></p><div class="scrollable-table"><table><thead><tr><th>  <strong>Posteingang</strong> </th><th>  <strong>Ausgehend</strong> </th></tr></thead><tbody><tr><td>  WebRTC </td><td>  WebRTC </td></tr><tr><td>  RTMP </td><td>  RTMP </td></tr><tr><td>  Rtsp </td><td>  Rtsp </td></tr><tr><td>  Vod </td><td>  MSE </td></tr><tr><td>  SIP / RTP </td><td>  Hls </td></tr></tbody></table></div><br><br><p>  Das heißt  Wir können Streams zum Server leiten und eine Verbindung zu ihnen herstellen und für diese Angelegenheit geeignete Spieler spielen.  Verwenden Sie das Web SDK, um den WebRTC-Stream abzuspielen.  Verwenden Sie einen HLS-Player usw., um den WebRTC-Stream als HLS abzuspielen.  Ein Stream kann von vielen Zuschauern gespielt werden.  Eins-zu-viele-Sendungen funktionieren. </p><br><p>  Nun werden wir sagen, welche Aktionen mit Streams durchgeführt werden können. </p><br><br><h2><a name="manipulatingincoming"></a>  Eingehende Stream-Manipulation </h2><br><p>  Ausgehende Streams, auf denen Zuschauer sitzen, manipulieren nicht besonders.  Wenn der Viewer eine Sitzung mit dem Server eingerichtet hat und bereits eine Art Stream empfängt, können keine Änderungen daran vorgenommen werden, ohne die Sitzung zu unterbrechen.  Aus diesem Grund finden alle Manipulationen und Änderungen an eingehenden Streams zu dem Zeitpunkt statt, an dem die Replikation noch nicht erfolgt ist.  Der Stream, der sich geändert hat, wird dann an alle verbundenen Betrachter weitergeleitet. </p><br><p>  Operationen auf Streams umfassen: </p><br><ul><li>  aufzeichnen </li><li>  Schnappschussentfernung </li><li>  Stream zum Mixer hinzufügen </li><li>  Stream-Transcodierung </li><li>  Wasserzeichen hinzufügen </li><li>  FPS-Filter hinzufügen </li><li>  Bilddrehung um 90, 180, 270 Grad </li></ul><br><br><h3><a name="recording"></a>  <strong>Aufnahme eingehender Streams</strong> </h3><br><p><img src="https://habrastorage.org/webt/m_/je/j8/m_jej8-gdyvh2e2urt4s75ltsse.jpeg"></p><br><p>  Vielleicht die verständlichste und am häufigsten anzutreffende Funktion.  Streams müssen in vielen Fällen aufgezeichnet werden: Webinar, Englischunterricht, Beratung usw. </p><br><p><img src="https://habrastorage.org/webt/kz/t0/_r/kzt0_rj0y1mvgb4rnob5ix4_bnk.jpeg"></p><br><p>  Die Aufzeichnung kann entweder mit dem Web SDK oder der REST-API mit einer speziellen Anforderung gestartet werden: </p><br><pre> <code class="plaintext hljs">/stream/startRecording {}</code> </pre> <br><p>  Das Ergebnis wird als mp4-Datei im Dateisystem gespeichert. </p><br><br><h3><a name="snapshot"></a>  <strong>Snapshot-Entfernung</strong> </h3><br><p><img src="https://habrastorage.org/webt/cg/g6/yh/cgg6yhu_d8lj4tl6tecphzvgsce.jpeg"></p><br><p>  Ebenso häufig ist es, Bilder des aktuellen Streams aufzunehmen, um Symbole auf der Site anzuzeigen.  Sie haben beispielsweise 50 Streams in einem Videoüberwachungssystem, von denen jeder eine Quelle für eine IP-Kamera hat.  Das Anzeigen aller 50 Threads auf einer Seite ist nicht nur problematisch für Browser-Ressourcen, sondern auch sinnlos.  Bei 30 Bildern pro Sekunde beträgt die Gesamtgeschwindigkeit des sich ändernden Bildes 1500 Bilder pro Sekunde, und das menschliche Auge akzeptiert diese Frequenz einfach nicht.  Als Lösung können Sie das automatische Schneiden oder Aufnehmen von Snapshots nach Bedarf konfigurieren. In diesem Fall können Sie Bilder auf einer Site mit einer beliebigen Häufigkeit anzeigen, z. B. 1 Frame in 10 Sekunden.  Snapshots können über die REST-API aus dem SDK entfernt oder automatisch aufgeteilt werden. </p><br><p><img src="https://habrastorage.org/webt/b9/c5/hf/b9c5hfkspnmifm7wfw96aatldl8.jpeg"></p><br><p>  Der WCS-Server unterstützt die folgende REST-Methode zum Entfernen von Snapshots: </p><br><pre> <code class="plaintext hljs">/stream/snapshot</code> </pre> <br><p><img src="https://habrastorage.org/webt/5c/8z/v-/5c8zv-0i7uglnd6t5eyldejyzt0.jpeg"></p><br><br><h3><a name="mixer"></a>  <strong>Stream zum Mixer hinzufügen</strong> </h3><br><p><img src="https://habrastorage.org/webt/o3/mx/bj/o3mxbjmxo3evugpsr5td7wko1pc.jpeg"></p><br><p>  Ein Bild aus zwei oder mehr Quellen kann zu einem Bild kombiniert werden, um es den Betrachtern anzuzeigen.  Dieser Vorgang wird als Mischen bezeichnet.  Grundlegende Beispiele: 1) Videoüberwachung von mehreren Kameras auf dem Bildschirm in einem Bild.  2) Videokonferenz, bei der jeder Benutzer einen Stream erhält, um Ressourcen zu sparen, in die der Rest gemischt wird.  Der Mixer wird über die REST-API gesteuert und verfügt über einen MCU-Betriebsmodus zum Erstellen von Videokonferenzen. </p><br><p>  REST-Befehl zum Hinzufügen eines Streams zum Mixer: </p><br><pre> <code class="plaintext hljs">/mixer/startup</code> </pre> <br><br><h3><a name="transcoding"></a>  <strong>Stream-Transcodierung</strong> </h3><br><p><img src="https://habrastorage.org/webt/e8/dn/ml/e8dnmlrtcfd5dxvsnmfkrckeiqm.jpeg"></p><br><p>  Streams müssen manchmal komprimiert werden, um sich für bestimmte Gruppen von Clientgeräten nach Auflösung und Bitrate anzupassen.  Hierfür wird die Transcodierung verwendet.  Die Transkodierung kann auf der Web-SDK-Seite, über die REST-API oder automatisch über einen speziellen Transkodierungsknoten im CDN aktiviert werden.  Wenn Sie beispielsweise ein Video mit einer Auflösung von 1280 x 720 eingeben, kann es für die Verteilung an Kunden aus einer geografischen Region mit einer traditionell geringen Bandbreite auf 640 x 360 transcodiert werden.  Wo sind deine Gefährten, Elon Musk? </p><br><p><img src="https://habrastorage.org/webt/yn/t2/5g/ynt25g1_9phfzcqtptzb0e0u3gq.jpeg"></p><br><p>  Verwendete REST-Methode: </p><br><pre> <code class="plaintext hljs">/transcoder/startup</code> </pre> <br><br><br><h3><a name="watermark"></a>  <strong>Hinzufügen eines Wasserzeichens</strong> </h3><br><p><img src="https://habrastorage.org/webt/l_/7q/-t/l_7q-td_lifwkr5aw3mn-btem1o.png"></p><br><p>  Es ist bekannt, dass jeder Inhalt gestohlen und in WebRip umgewandelt werden kann, unabhängig davon, mit welchem ​​Schutz der Player ausgestattet ist.  Wenn Ihr Inhalt wirklich so wertvoll ist, können Sie ein Wasserzeichen oder Logo einbetten, das die weitere Verwendung und öffentliche Anzeige erheblich erschwert.  Um ein Wasserzeichen hinzuzufügen, laden Sie einfach ein PNG-Bild hoch und es wird durch Transcodierung in den Videostream eingefügt.  Daher müssen Sie auf der Serverseite einige CPU-Kerne vorbereiten, falls Sie sich noch entscheiden <br>  Füge dem Stream ein Wasserzeichen hinzu.  Um das Wasserzeichen auf dem Server nicht durch Umcodierung zu verdrehen, ist es besser, es direkt zum Encoder / Streamer hinzuzufügen, der <br>  bieten oft eine solche Gelegenheit. </p><br><br><h3><a name="fpsfilter"></a>  <strong>Hinzufügen eines FPS-Filters</strong> </h3><br><p><img src="https://habrastorage.org/webt/27/oi/bk/27oibkbef1jtrjulbcdcpomi_ts.png"></p><br><p>  In einigen Fällen ist es erforderlich, dass der Stream eine gerade FPS (Frames pro Sekunde) aufweist.  Dies kann nützlich sein, wenn wir den Stream an eine Drittanbieter-Ressource wie Youtube oder Facebook weiterleiten oder ihn mit einem empfindlichen HLS-Player abspielen.  Das erneute Filtern erfordert eine Umcodierung. Berechnen Sie daher die Stärke Ihres Servers und bereiten Sie die Konfiguration sowie 2 Cores pro Stream vor, wenn ein solcher Vorgang geplant ist. </p><br><br><h3><a name="rotate"></a>  <strong>Drehen Sie das Bild um 90, 180, 270 Grad</strong> </h3><br><p><img src="https://habrastorage.org/webt/ou/bh/2n/oubh2n__wt2uasdqfdgtj3rmves.png"></p><br><p>  Mobile Geräte können die Auflösung des veröffentlichten Streams in Abhängigkeit vom Drehwinkel ändern.  Zum Beispiel haben sie angefangen zu streamen, das iPhone horizontal gehalten und sich dann auf die Seite gedreht.  Gemäß der WebRTC-Spezifikation sollte der Streamer-Browser des Mobilgeräts und in diesem Fall iOS Safari eine Wende an den Server signalisieren.  Der Server muss dieses Ereignis wiederum an alle Abonnenten senden.  Sonst hätte es sich herausgestellt <br>  so dass der streamer das telefon auf die seite legt, seine kamera aber noch aufrecht sieht, während die zuschauer auf der seite gestapelt sind.  Um mit Umdrehungen auf der SDK-Seite zu arbeiten, ist die entsprechende cvoExtension-Erweiterung enthalten. </p><br><br><h3><a name="manage"></a>  <strong>Wo ist die Kontrolle der eingehenden Streams</strong> </h3><br><p>  Automatisch - Die Konfiguration wird normalerweise serverseitig in eingestellt <br>  Einstellungen. </p><br><div class="scrollable-table"><table><thead><tr><th>  Flow-Aktion </th><th>  Web, iOS, Android SDK </th><th>  REST-API </th><th>  Automatisch </th><th>  Cdn </th></tr></thead><tbody><tr><td>  Aufnehmen </td><td>  + </td><td>  + </td><td><br></td><td><br></td></tr><tr><td>  Snapshot-Entfernung </td><td>  + </td><td>  + </td><td>  + </td><td><br></td></tr><tr><td>  Zum Mixer hinzufügen </td><td>  + </td><td>  + </td><td><br></td><td><br></td></tr><tr><td>  Stream-Transcodierung </td><td>  + </td><td>  + </td><td><br></td><td>  + </td></tr><tr><td>  Wasser hinzufügen <br>  unterschreiben </td><td><br></td><td><br></td><td>  + </td><td><br></td></tr><tr><td>  Hinzufügen eines FPS-Filters </td><td><br></td><td><br></td><td>  + </td><td><br></td></tr><tr><td>  Drehe das Bild um 90, <br>  180, 270 Grad </td><td>  + </td><td><br></td><td><br></td><td><br></td></tr></tbody></table></div><br><br><h2><a name="Streamrelay"></a>  Stream-Relay </h2><br><p>  Relaying ist auch eine Option zum Bearbeiten von Streams, die auf den Server gelangen, und besteht darin, den Stream auf einen Server eines Drittanbieters zu zwingen.  Ein Synonym für Relaying sind solche Wörter wie: Replikation, Push, Injektion. </p><br><p>  Das Relais kann mit einem der folgenden Protokolle implementiert werden: WebRTC, RTMP, SIP / RTP.  Die Tabelle zeigt die Richtung, in die der Stream weitergeleitet werden kann. </p><br><br><div class="scrollable-table"><table><thead><tr><th>  WebRTC </th><th>  RTMP </th><th>  SIP / RTP </th></tr></thead><tbody><tr><td>  WCS </td><td>  RTMP-Server-WCS </td><td>  SIP-Server </td></tr></tbody></table></div><br><br><br><h3><a name="repubWebRTC"></a>  <strong>WebRTC-Relais</strong> </h3><br><p><img src="https://habrastorage.org/webt/d9/yf/cc/d9yfccsjz8zqvx3jo-3gas2nuu8.jpeg"></p><br><p>  Ein Stream kann an einen anderen WCS-Server weitergeleitet werden, wenn es aus irgendeinem Grund erforderlich ist, den Stream auf einem anderen Server verfügbar zu machen.  Die Weitergabe erfolgt über die REST-API mit der Methode / push.  Nach Erhalt einer solchen REST-Anforderung stellt WCS eine Verbindung zum angegebenen Server her und veröffentlicht einen Server-Server-Stream an diesen.  Danach steht der Stream für die Wiedergabe auf einem anderen Computer zur Verfügung. </p><br><pre> <code class="plaintext hljs">/pull/push</code> </pre> <br><p>  - die verwendete REST-Methode. </p><br><br><h3><a name="rebubRTMP"></a>  <strong>RTMP-Relais</strong> </h3><br><p><img src="https://habrastorage.org/webt/y-/hv/tn/y-hvtne9e-vtgry-2or6nhmqzte.jpeg"></p><br><p>  Wie bei der WebRTC-Weiterleitung ist auch eine RTMP-Weiterleitung an einen anderen Server möglich.  Der Unterschied besteht nur im Relaisprotokoll.  RTMP-Relaying wird auch über / push ausgeführt und ermöglicht die Übertragung des Streams an RTMP-Server von Drittanbietern sowie an Dienste, die RTMP-Ingest unterstützen: Youtube, Facebook-Streaming usw.  Somit kann der WebRTC-Stream an RTMP weitergeleitet werden.  Mit dem gleichen Erfolg in RTMP können Sie jeden anderen Stream weiterleiten, der auf den Server gelangt, z. B. RTSP oder VOD. </p><br><p>  Der Videostream wird mithilfe von REST-Aufrufen an einen anderen RTMP-Server weitergeleitet </p><br><pre> <code class="plaintext hljs">/push/startup</code> </pre> <br><p>  - REST-Aufruf verwendet. </p><br><br><h3><a name="repubSIP-RTP"></a>  <strong>SIP / RTP-Relais</strong> </h3><br><p><img src="https://habrastorage.org/webt/sl/tt/hj/sltthjlgwbvryka0vgpqel0hcx8.jpeg"></p><br><br><p>  Selten genutzte Funktion.  Meistens in Unternehmen.  Wenn Sie beispielsweise einen SIP-Anruf mit einem externen SIP-Konferenzserver einrichten und den Audio- oder Videostream auf diesen Anruf umleiten möchten, damit das Konferenzpublikum einige Videoinhalte sieht: "Bitte sehen Sie sich dieses Video an" oder "Kollegen", und schauen wir uns jetzt den Stream mit IP an Kameras von der Baustelle. “  Es versteht sich, dass die Konferenz selbst existiert und in diesem Fall auf einem externen VKS-Server mit SIP-Unterstützung verwaltet wird (kürzlich haben wir die Lösung von Polycom DMA getestet). Wir verbinden einfach den vorhandenen Stream und leiten ihn an diesen Server weiter.  Die REST-API-Funktion heißt / inject und dient nur für diesen Fall. </p><br><p>  REST-API-Befehl: </p><br><pre> <code class="plaintext hljs">/call/inject_stream/startup</code> </pre> <br><br><h2><a name="CDN"></a>  Verbinden von Servern mit einem CDN-Netzwerk zur Inhaltsverarbeitung </h2><br><p>  Ein Server verfügt normalerweise über eine begrenzte Menge an Ressourcen.  Daher ist für große Online-Sendungen, bei denen das Konto des Publikums Tausende und Zehntausende umfasst, eine Skalierung erforderlich.  Mehrere WCS-Server können zu einem CDN-Netzwerk für die Bereitstellung von Inhalten zusammengefasst werden.  Intern arbeitet CDN über WebRTC, um die Latenz während des Streamings gering zu halten. </p><br><p><img src="https://habrastorage.org/webt/99/sx/gd/99sxgd8frahbmd2trrxsfltfmeg.jpeg"></p><br><p>  Der Server kann in einer der folgenden Rollen konfiguriert werden: Origin, Edge, Transcoder.  Origin-Server - Empfangen Sie Datenverkehr und verteilen Sie ihn an die Edge-Knoten der Edge-Server, die für die Übermittlung des Streams an die Betrachter verantwortlich sind.  Wenn es erforderlich ist, einen Stream in mehreren Auflösungen vorzubereiten, werden Transcoder-Knoten in das Schema aufgenommen, die die ressourcenintensive Aufgabe des Transcodierens von Streams übernehmen. </p><br><br><h2><a name="summarize"></a>  Um es zusammenzufassen </h2><br><p>  WCS 5.2 ist ein Server für die Entwicklung von Anwendungen mit Audio- und Video-Echtzeitunterstützung für Browser und Mobilgeräte.  Für die Entwicklung stehen vier APIs zur Verfügung: Web-SDK, iOS-SDK, Android-SDK und REST-API.  Sie können Videostreams mithilfe von fünf Protokollen auf dem Server veröffentlichen (Feed): WebRTC, RTMP, RTSP, VOD, SIP / RTP.  Vom Server aus können Sie Streams mit Playern mit fünf Protokollen abspielen: WebRTC, RTMP, RTSP, MSE, HLS.  Streams können gesteuert und ausgeführt werden, z. B .: Aufzeichnen, Aufteilen von Schnappschüssen, Mischen, Transcodieren, Hinzufügen eines Wasserzeichens, Filtern von FPS, Senden von Videos auf Mobilgeräten.  Streams können über WebRTC- und RTMP-Protokolle an andere Server weitergeleitet und zu SIP-Konferenzen umgeleitet werden.  Server können in ein Content Delivery-Netzwerk integriert und für die Verarbeitung einer beliebigen Anzahl von Videostreams skaliert werden. </p><br><br><h3>  <strong>Was Alice wissen muss, um mit dem Server zu arbeiten</strong> </h3><br><p>  Der Entwickler muss Linux beherrschen.  Mannschaften dieser Art in <br>  Die Befehlszeile sollte keine Verwirrung stiften: </p><br><pre> <code class="plaintext hljs">tar -xvzf wcs5.2.tar.gz</code> </pre> <br><pre> <code class="plaintext hljs">cd wcs5.2</code> </pre> <br><pre> <code class="plaintext hljs">./install.sh</code> </pre> <br><pre> <code class="plaintext hljs">tail -f flashphoner.log</code> </pre> <br><pre> <code class="plaintext hljs">ps aux | grep WebCallServer</code> </pre> <br><pre> <code class="plaintext hljs">top</code> </pre> <br><p>  Vanilla JavaScript muss auch in der Lage sein, wenn es darum geht, für zu entwickeln <br>  Web </p><br><pre> <code class="plaintext hljs">//  session.createStream({name:'mystream'}).publish(); //  session.createStream({name:'mystream'}).play();</code> </pre><br><p>  Die Möglichkeit, mit dem Backend zu arbeiten, ist ebenfalls nützlich. </p><br><p><img src="https://habrastorage.org/webt/3l/0a/9s/3l0a9shqbhfy4yjheu30ocammzg.jpeg"></p><br><p>  WCS kann nicht nur Steuerbefehle über die REST-API empfangen, sondern auch Hooks senden - Benachrichtigungen über die darin auftretenden Ereignisse. <br>  Wenn Sie beispielsweise versuchen, eine Verbindung über einen Browser oder eine mobile Anwendung herzustellen, ruft WCS den / connect-Hook auf, und wenn Sie versuchen, einen Stream abzuspielen, wird der playStream-Hook aufgerufen.  Daher muss sich der Entwickler ein wenig mit dem Back-End auseinandersetzen, das sowohl einen einfachen REST-Client als auch einen kleinen REST-Server für die Verarbeitung von Hooks schreiben kann. </p><br><p>  REST-API-Beispiel </p><br><pre> <code class="plaintext hljs">/rest-api/stream/find_all</code> </pre> <br><p>  - Ein Beispiel für eine REST-API, in der die Liste der Streams auf einem Server aufgeführt ist </p><br><p>  Beispiel für einen REST-Hook </p><br><pre> <code class="plaintext hljs">https://myback-end.com/hook/connect</code> </pre> <br><p>  - REST Hook / Connect-Verarbeitung auf der Backend-Seite. </p><br><p>  Linux, JavaScript, REST-Client / Server sind die drei Elemente, die <br>  genug, um einen Produktionsdienst auf der WCS-Plattform zu entwickeln, der funktioniert <br>  mit Video-Streams. </p><br><p>  Für die Entwicklung mobiler Apps sind Kenntnisse in Java und Objective-C erforderlich <br>  für Android bzw. iOS. </p><br><br><h3>  <strong>Installation und Start</strong> </h3><br><p>  Es gibt drei Möglichkeiten, WCS heute schnell zu starten: </p><br><p>  1) Installieren Sie auf Ihrem Centos7 oder Ubuntu 16.x LTS oder Ubuntu 18.x LTS, und <br>  etc.  angeleitet von einem <a href="https://docs.flashphoner.com/pages/viewpage.action%3FpageId%3D9241019">Artikel aus der Dokumentation</a> . </p><br><p>  oder </p><br><p>  2) Nehmen Sie das <a href="https://flashphoner.com/podderzhka-oblachnyh-serverov-amazon-ec2-v-web-call-server/%3Flang%3Dru">fertige Bild in Amazon EC2 auf</a> . </p><br><p>  oder sonst </p><br><p>  3) Nehmen Sie das <a href="https://flashphoner.com/podderzhka-web-call-server-v-digital-ocean-marketplace/%3Flang%3Dru">fertige Server-Image auf DigitalOcean</a> . </p><br><p>  Starten Sie eine spannende Projektentwicklung mit Streaming-Videofunktionen. </p><br><p>  Der Übersichtsartikel erwies sich als recht umfangreich.  Danke dafür. <br>  Geduld lesen. </p><br><p>  Viel Spaß beim Streamen! </p><br><br><br><h2><a name="Links"></a>  Referenzen </h2><br><p>  <a href="https://flashphoner.com/">WCS 5.2</a> - WebRTC Server </p><br><h3>  Installation und Start </h3><br><p>  <a href="https://docs.flashphoner.com/pages/viewpage.action%3FpageId%3D9241019">Installieren Sie WCS und führen Sie es aus</a> </p><br><p>  <a href="https://flashphoner.com/podderzhka-oblachnyh-serverov-amazon-ec2-v-web-call-server/%3Flang%3Dru">Starten Sie ein vorgefertigtes Image in Amazon AWS</a> </p><br><p> <a href="https://flashphoner.com/podderzhka-web-call-server-v-digital-ocean-marketplace/%3Flang%3Dru">    DigitalOcean</a> </p><br><h3> SDK </h3><br><p> <a href="https://docs.flashphoner.com/display/WCS52RU/Web%2BSDK">  Web SDK</a> </p><br><p> <a href="https://docs.flashphoner.com/display/WCS52RU/Android%2BSDK">  Android SDK</a> </p><br><p> <a href="https://docs.flashphoner.com/display/WCS52RU/iOS%2BSDK">  iOS SDK</a> </p><br><h3>  </h3><br><p> <a href="https://docs.flashphoner.com/pages/viewpage.action%3FpageId%3D9241216"> </a> </p><br><p> <a href="https://docs.flashphoner.com/pages/viewpage.action%3FpageId%3D9241448"> </a> </p><br><p> <a href="https://docs.flashphoner.com/pages/viewpage.action%3FpageId%3D9241404"> </a> </p><br><p> <a href="https://docs.flashphoner.com/pages/viewpage.action%3FpageId%3D9241533"> </a> </p><br><p> <a href="">WebRTC CDN   </a> </p><br><h3>  Die Dokumentation </h3><br><p> <a href="https://docs.flashphoner.com/display/WCS52RU/Web%2BCall%2BServer%2B5.2%2B-%2BRU"> Web Call Server 5.2</a> </p><br><br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de482960/">https://habr.com/ru/post/de482960/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de482946/index.html">1С DSS und Schätzung der Projektlaufzeiten und -kosten nach der COCOMO II-Methode</a></li>
<li><a href="../de482948/index.html">"Eins, zwei, drei - verbrenne den Weihnachtsbaum!" Oder mein erster Blick auf den CANNY 3 winzigen Controller</a></li>
<li><a href="../de482950/index.html">Java: Dinge, die einem erfahrenen Entwickler neugierig erscheinen mögen</a></li>
<li><a href="../de482956/index.html">Überprüfung von WCS 5.2 - WebRTC Server für Webcast- und Webcam-Entwickler</a></li>
<li><a href="../de482958/index.html">"Wachstumsregeln: Vom Junior zum CTO", Auszug aus einem Webinar von Fedor Borshchev</a></li>
<li><a href="../de482968/index.html">Quarkus - Ein neuer Blick auf Cloud Native Java</a></li>
<li><a href="../de482970/index.html">Hack The Box - Walkthrough Craft. Wir stöbern in Git, nutzen Schwachstellen in der API aus, beschäftigen uns mit Vault</a></li>
<li><a href="../de482974/index.html">Psychologische Unterstützung mit Virtual Reality</a></li>
<li><a href="../de482976/index.html">Analyse anonymer Transaktionen im Aktienhandel</a></li>
<li><a href="../de482978/index.html">Blockchain-Parser mit 300 Zeilen in Python</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë≤ üë©‚Äçüë©‚Äçüëß‚Äçüë¶ üë∏üèø Technique de r√©duction du r√©seau de convolution Jedi - √©lagage üèæ üë∞üèΩ üèûÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Avant de nouveau, la t√¢che de d√©tecter des objets. Priorit√© - vitesse avec une pr√©cision acceptable. Vous prenez l'architecture de YOLOv3 et la formez...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Technique de r√©duction du r√©seau de convolution Jedi - √©lagage</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482050/"><p><img src="https://habrastorage.org/webt/tf/oa/br/tfoabr16w_dawnzb9hnjndyv_bg.png" alt="image"></p><br><p>  Avant de nouveau, la t√¢che de d√©tecter des objets.  Priorit√© - vitesse avec une pr√©cision acceptable.  Vous prenez l'architecture de YOLOv3 et la formez.  La pr√©cision (mAp75) est sup√©rieure √† 0,95.  Mais la vitesse de course est encore faible.  L'enfer </p><br><p>  Aujourd'hui, nous contournerons la quantification.  Et sous la coupe, pensez √† l' <strong>√©lagage du mod√®le</strong> - couper les parties de r√©seau redondantes pour acc√©l√©rer l'inf√©rence sans perdre en pr√©cision.  Visuellement - o√π, combien et comment couper.  Voyons comment le faire manuellement et o√π vous pouvez automatiser.  √Ä la fin se trouve un r√©f√©rentiel sur les keras. </p><a name="habracut"></a><br><h3 id="vvedenie">  Pr√©sentation </h3><br><p>  Au dernier lieu de travail, Perm Macroscop, j'ai eu une habitude - toujours de surveiller le temps d'ex√©cution des algorithmes.  Et la dur√©e d'ex√©cution du r√©seau doit toujours √™tre v√©rifi√©e via le filtre d'ad√©quation.  Habituellement, l'√©tat de l'art dans la prod ne passe pas ce filtre, ce qui m'a conduit √† l'√©lagage. </p><br><p>  L'√©lagage est un th√®me ancien qui a √©t√© abord√© dans les <a href="https://www.youtube.com/watch%3Fv%3DeZdOkDtYMoo" rel="nofollow">conf√©rences de Stanford</a> en 2017.  L'id√©e principale est de r√©duire la taille du r√©seau form√© sans perdre en pr√©cision en supprimant divers n≈ìuds.  √áa a l'air cool, mais j'entends rarement parler de son utilisation.  Probablement, il n'y a pas assez d'impl√©mentations, il n'y a pas d'articles en russe, ou tout le monde consid√®re que l'√©lagage du savoir-faire est silencieux. <br>  Mais va d√©monter </p><br><h3 id="vzglyad-v-biologiyu">  Un regard sur la biologie </h3><br><p>  J'aime quand dans le Deep Learning les id√©es viennent de la biologie.  On peut leur faire confiance, comme l'√©volution (saviez-vous que ReLU est tr√®s similaire √† la <a href="http://www.gatsby.ucl.ac.uk/~lmate/biblio/dayanabbott.pdf" rel="nofollow">fonction d'activation des neurones dans le cerveau</a> ?) </p><br><p>  Le processus d'√©lagage du mod√®le est √©galement proche de la biologie.  La r√©ponse du r√©seau ici peut √™tre compar√©e √† la plasticit√© du cerveau.  Quelques exemples int√©ressants se trouvent dans <a href="https://www.litres.ru/norman-doydzh/plastichnost-mozga/%3Futm_medium%3Dcpc%26utm_source%3Dgoogle%26utm_campaign%3DDSA%257C149839530%26utm_term%3D%26utm_content%3Dk50id%257Caud-499675211712%253Adsa-179513627318%257Ccid%257C149839530%257Caid%257C248455294996%257Cgid%257C6837176850%257Cpos%257C1t1%257Csrc%257Cg_%257Cdvc%257Cc%257Creg%257C1011993%257Crin%257C%257C%26k50id%3D6837176850%257Caud-499675211712%253Adsa-179513627318%26gclid%3DCj0KCQiA0ZHwBRCRARIsAK0Tr-oKPqkmL7_Oxg62JZO8Jlk9zO-9nYKIRFxHi_lgoCvsQQadvUGxUzkaApgpEALw_wcB" rel="nofollow">le</a> livre de <a href="https://www.litres.ru/norman-doydzh/plastichnost-mozga/%3Futm_medium%3Dcpc%26utm_source%3Dgoogle%26utm_campaign%3DDSA%257C149839530%26utm_term%3D%26utm_content%3Dk50id%257Caud-499675211712%253Adsa-179513627318%257Ccid%257C149839530%257Caid%257C248455294996%257Cgid%257C6837176850%257Cpos%257C1t1%257Csrc%257Cg_%257Cdvc%257Cc%257Creg%257C1011993%257Crin%257C%257C%26k50id%3D6837176850%257Caud-499675211712%253Adsa-179513627318%26gclid%3DCj0KCQiA0ZHwBRCRARIsAK0Tr-oKPqkmL7_Oxg62JZO8Jlk9zO-9nYKIRFxHi_lgoCvsQQadvUGxUzkaApgpEALw_wcB" rel="nofollow">Norman Dodge</a> : </p><br><ol><li>  Le cerveau d'une femme qui n'avait qu'une moiti√© de naissance s'est reprogramm√©e pour remplir les fonctions de la moiti√© manquante </li><li>  Le gars s'est tir√© une balle dans la partie du cerveau responsable de la vision.  Au fil du temps, d'autres parties du cerveau ont repris ces fonctions.  (ne r√©essayez pas) </li></ol><br><p>  Ainsi, √† partir de votre mod√®le, vous pouvez supprimer certains des paquets faibles.  Dans les cas extr√™mes, les faisceaux restants aideront √† remplacer ceux coup√©s. </p><br><h3 id="lyubish-transfer-learning-ili-uchish-s-nulya">  Aimez-vous le transfert d'apprentissage ou apprenez √† partir de z√©ro? </h3><br><p>  <strong>Option num√©ro un.</strong>  Vous utilisez Transfer Learning sur Yolov3.  Retina, Mask-RCNN ou U-Net.  Mais le plus souvent, nous n'avons pas besoin de reconna√Ætre 80 classes d'objets, comme dans COCO.  Dans ma pratique, tout est limit√© √† 1-2 classes.  On peut supposer que l'architecture pour 80 classes est redondante ici.  Cela laisse penser que l'architecture doit √™tre r√©duite.  De plus, je voudrais le faire sans perdre les poids pr√©-form√©s existants. </p><br><p>  <strong>Option num√©ro deux.</strong>  Peut-√™tre que vous avez beaucoup de donn√©es et de ressources informatiques, ou que vous avez juste besoin d'une architecture super-personnalis√©e.  Peu importe.  Mais vous apprenez le r√©seau √† partir de z√©ro.  L'ordre habituel consiste √† examiner la structure des donn√©es, √† s√©lectionner une architecture dont la puissance est R√âDUITE et √† emp√™cher les abandons de se recycler.  J'ai vu des d√©crocheurs 0,6, Carl. </p><br><p>  Dans les deux cas, le r√©seau peut √™tre r√©duit.  Promu.  Voyons maintenant quel genre de <del>  circoncision </del>  √©lagage </p><br><h3 id="obschiy-algoritm">  Algorithme g√©n√©ral </h3><br><p>  Nous avons d√©cid√© de supprimer la convolution.  Cela semble tr√®s simple: </p><br><p><img src="https://habrastorage.org/webt/ey/yt/-g/eyyt-g-b6pfzjrbnim_ssosyqqk.png"></p><br><p>  La suppression de toute convolution est une contrainte pour le r√©seau, ce qui entra√Æne g√©n√©ralement une augmentation des erreurs.  D'une part, cette croissance d'erreur est un indicateur de la fa√ßon dont nous supprimons correctement les convolutions (par exemple, une croissance importante indique que nous faisons quelque chose de mal).  Mais une petite croissance est tout √† fait acceptable et est souvent √©limin√©e par un entra√Ænement ult√©rieur facile et ult√©rieur avec un petit LR.  Nous ajoutons une √©tape de recyclage: </p><br><p><img src="https://habrastorage.org/webt/kb/ui/5d/kbui5dm1k8sgflm5xzu0wggbbhs.png"></p><br><p>  Maintenant, nous devons comprendre quand nous voulons arr√™ter notre cycle d'apprentissage &lt;-&gt; √âlagage.  Il peut y avoir des options exotiques lorsque nous devons r√©duire le r√©seau √† une certaine taille et vitesse d'ex√©cution (par exemple, pour les appareils mobiles).  Cependant, l'option la plus courante consiste √† poursuivre le cycle jusqu'√† ce que l'erreur devienne sup√©rieure √† celle autoris√©e.  Ajouter une condition: </p><br><p><img src="https://habrastorage.org/webt/1i/pi/52/1ipi52uqhkciw2ne-1zt2rbdmje.png"></p><br><p>  Ainsi, l'algorithme devient clair.  Reste √† savoir comment d√©terminer les circonvolutions supprim√©es. </p><br><h3 id="poisk-udalyaemyh-svertok">  Rechercher la convolution √† supprimer </h3><br><p>  Nous devons supprimer certaines circonvolutions.  Arracher et ¬´tirer¬ª sur n'importe quelle est une mauvaise id√©e, m√™me si cela fonctionnera.  Mais si vous avez une t√™te, vous pouvez penser et essayer de s√©lectionner des convolutions ¬´faibles¬ª pour l'enl√®vement.  Il existe plusieurs options: </p><br><ol><li>  <a href="https://openreview.net/pdf%3Fid%3DrJqFGTslg" rel="nofollow">La plus petite mesure L1 ou √©lagage √† faible amplitude</a> .  L'id√©e que les convolutions de petits poids contribuent peu √† la d√©cision finale </li><li>  La plus petite mesure L1 tenant compte de la moyenne et de l'√©cart-type.  Nous compl√©tons l'appr√©ciation de la nature de la distribution. </li><li>  <a href="https://arxiv.org/abs/1512.08571" rel="nofollow">Masquer les circonvolutions et √©liminer le moins possible la pr√©cision r√©sultante</a> .  Une d√©finition plus pr√©cise des convolutions insignifiantes, mais tr√®s chronophage et gourmande en ressources. </li><li>  Autre </li></ol><br><p>  Chacune des options a droit √† la vie et poss√®de ses propres fonctionnalit√©s de mise en ≈ìuvre.  Ici, nous consid√©rons la variante avec la plus petite mesure L1 </p><br><h3 id="ruchnoy-process-dlya-yolov3">  Processus manuel pour YOLOv3 </h3><br><p>  L'architecture d'origine contient des blocs r√©siduels.  Mais peu importe √† quel point ils sont cool pour les r√©seaux profonds, ils nous g√™neront quelque peu.  La difficult√© est que vous ne pouvez pas supprimer les rapprochements avec diff√©rents indices dans ces couches: </p><br><p><img src="https://habrastorage.org/webt/mh/p-/-k/mhp--ksk3ifgurz5jx6exgcrm5c.png"></p><br><p>  Par cons√©quent, nous s√©lectionnons les couches dont nous pouvons supprimer librement les rapprochements: </p><br><p><img src="https://habrastorage.org/webt/qy/ek/zo/qyekzofcur-q0auqurg3egxnato.png"></p><br><p>  Construisons maintenant un cycle de travail: </p><br><ol><li>  D√©charger l'activation </li><li>  On se demande combien couper </li><li>  D√©couper </li><li>  Apprenez 10 √©poques avec LR = 1e-4 </li><li>  Test </li></ol><br><p>  Le d√©chargement des convolutions est utile pour √©valuer quelle partie nous pouvons retirer √† une certaine √©tape.  Exemples de d√©chargement: </p><br><p><img src="https://habrastorage.org/webt/rp/jo/pk/rpjopk6dzfrl6psoucr8tgj0log.png"></p><br><p>  Nous voyons que presque partout 5% des circonvolutions ont une norme L1 tr√®s basse et nous pouvons les supprimer.  √Ä chaque √©tape, ce d√©chargement a √©t√© r√©p√©t√© et une √©valuation a √©t√© faite des couches et de la quantit√© pouvant √™tre coup√©e. </p><br><p>  L'ensemble du processus s'est d√©roul√© en 4 √©tapes (ici et partout les chiffres du RTX 2060 Super): </p><br><div class="scrollable-table"><table><thead><tr><th>  √âtape </th><th>  mAp75 </th><th>  Le nombre de param√®tres, millions </th><th>  Taille du r√©seau, mb </th><th>  De l'original,% </th><th>  Temps d'ex√©cution, ms </th><th>  Condition de circoncision </th></tr></thead><tbody><tr><td>  0 </td><td>  0,9656 </td><td>  60 </td><td>  241 </td><td>  100 </td><td>  180 </td><td>  - </td></tr><tr><td>  1 </td><td>  0,9622 </td><td>  55 </td><td>  218 </td><td>  91 </td><td>  175 </td><td>  5% de tous </td></tr><tr><td>  2 </td><td>  0,9625 </td><td>  50 </td><td>  197 </td><td>  83 </td><td>  168 </td><td>  5% de tous </td></tr><tr><td>  3 </td><td>  0,9633 </td><td>  39 </td><td>  155 </td><td>  64 </td><td>  155 </td><td>  15% pour les couches avec plus de 400 convolutions </td></tr><tr><td><del>  4 </del></td><td><del>  0,9555 </del></td><td><del>  31 </del></td><td><del>  124 </del></td><td><del>  51 </del></td><td><del>  146 </del></td><td><del>  10% pour les couches avec 100+ convolution </del></td></tr></tbody></table></div><br><p>  √Ä l'√©tape 2, un effet positif a √©t√© ajout√©: le patch de taille 4 est entr√© en m√©moire, ce qui a consid√©rablement acc√©l√©r√© le processus de recyclage. <br>  √Ä l'√©tape 4, le processus a √©t√© arr√™t√©, car  m√™me une formation continue prolong√©e n'a pas √©lev√© le mAp75 √† ses anciennes valeurs. <br>  En cons√©quence, nous avons r√©ussi √† acc√©l√©rer l'inf√©rence de <strong>15%</strong> , √† r√©duire la taille de <strong>35%</strong> et √† ne pas perdre en pr√©cision. </p><br><h3 id="avtomatizaciya-dlya-bolee-prostyh-arhitektur">  Automatisation pour des architectures plus simples </h3><br><p>  Pour les architectures de r√©seau plus simples (sans ajout conditionnel, concat√©nation et blocs r√©siduels), il est tout √† fait possible de se concentrer sur le traitement de toutes les couches convolutives et d'automatiser le processus de d√©coupe des convolutions. </p><br><p>  J'ai impl√©ment√© <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">cette</a> option <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">ici</a> . <br>  C'est simple: vous n'avez qu'une fonction de perte, un optimiseur et des g√©n√©rateurs batch: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pruning <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequence train_batch_generator = BatchGenerator... score_batch_generator = BatchGenerator... opt = Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>) pruner = pruning.Pruner(<span class="hljs-string"><span class="hljs-string">"config.json"</span></span>, <span class="hljs-string"><span class="hljs-string">"categorical_crossentropy"</span></span>, opt) pruner.prune(train_batch, valid_batch)</code> </pre> <br><p>  Si n√©cessaire, vous pouvez modifier les param√®tres de configuration: </p><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"input_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"output_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model_pruned.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"finetuning_epochs"</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, # the number of epochs for train between pruning steps <span class="hljs-attr"><span class="hljs-attr">"stop_loss"</span></span>: <span class="hljs-number"><span class="hljs-number">0.1</span></span>, # loss for stopping process <span class="hljs-attr"><span class="hljs-attr">"pruning_percent_step"</span></span>: <span class="hljs-number"><span class="hljs-number">0.05</span></span>, # part of convs for delete on every pruning step <span class="hljs-attr"><span class="hljs-attr">"pruning_standart_deviation_part"</span></span>: <span class="hljs-number"><span class="hljs-number">0.2</span></span> # shift for limit pruning part }</code> </pre> <br><p>  De plus, une restriction bas√©e sur l'√©cart-type est mise en ≈ìuvre.  L'objectif est de limiter une partie de celles supprim√©es, √† l'exclusion des convolutions avec des mesures L1 d√©j√† "suffisantes": </p><br><p><img src="https://habrastorage.org/webt/bh/_9/nq/bh_9nqasnp91xifixn7ilhco0mw.png"></p><br><p>  Ainsi, nous ne pouvons supprimer que des convolutions faibles de distributions similaires √† la droite et ne pas affecter la suppression de distributions comme la gauche: </p><br><p><img src="https://habrastorage.org/webt/pr/r5/zp/prr5zpjrdvh1wow6slejnn6axya.png"></p><br><p>  Lorsque la distribution s'approche de la normale, le coefficient pruning_standart_deviation_part peut √™tre s√©lectionn√© parmi: </p><br><p><img src="https://habrastorage.org/webt/dl/yl/7d/dlyl7dub216jsr67dcbnhez5fl8.png"><br>  Je recommande une hypoth√®se de 2 sigma.  Ou vous ne pouvez pas vous concentrer sur cette fonctionnalit√©, laissant la valeur &lt;1.0. </p><br><p>  La sortie est un graphique de la taille du r√©seau, de la perte et de la dur√©e d'ex√©cution du r√©seau pour l'ensemble du test, normalis√© √† 1,0.  Par exemple, ici, la taille du r√©seau a √©t√© r√©duite de pr√®s de 2 fois sans perte de qualit√© (un petit r√©seau de convolution pour des poids de 100k): </p><br><p><img src="https://habrastorage.org/webt/ig/hu/x_/ighux_gyoaptm71iu2hk_txga_g.png"></p><br><p>  La vitesse de course est sujette √† des fluctuations normales et n'a pas beaucoup chang√©.  Il y a une explication √† cela: </p><br><ol><li>  Le nombre de circonvolutions passe de pratique (32, 64, 128) √† pas le plus pratique pour les cartes vid√©o - 27, 51, etc.  Ici, je peux me tromper, mais cela affecte tr√®s probablement. </li><li>  L'architecture n'est pas large, mais coh√©rente.  En r√©duisant la largeur, on ne touche pas la profondeur.  Ainsi, nous r√©duisons la charge, mais ne modifions pas la vitesse. </li></ol><br><p>  Par cons√©quent, l'am√©lioration s'est traduite par une diminution de la charge de CUDA pendant l'analyse de 20 √† 30%, mais pas par une diminution de la dur√©e d'ex√©cution. </p><br><h3 id="itogi">  R√©sum√© </h3><br><p>  R√©fl√©chissez.  Nous avons envisag√© 2 options d'√©lagage - pour YOLOv3 (lorsque vous devez travailler avec vos mains) et pour les r√©seaux avec des architectures plus faciles.  On peut voir que dans les deux cas, il est possible d'obtenir une r√©duction de la taille et de l'acc√©l√©ration du r√©seau sans perte de pr√©cision.  R√©sultats: </p><br><ul><li>  R√©duction des effectifs </li><li>  Acc√©l√©ration de la course </li><li>  R√©duction de charge CUDA </li><li>  En cons√©quence, respect de l'environnement (Nous optimisons l'utilisation future des ressources informatiques. Quelque part <a href="https://meduza.io/feature/2019/12/12/kto-takaya-greta-tunberg-i-pochemu-ona-stala-chelovekom-goda-zhurnal-time" rel="nofollow">Greta Tunberg</a> se r√©jouit seule) </li></ul><br><h3 id="appendix">  Appendice </h3><br><ul><li>  Apr√®s l'√©tape d'√©lagage, vous pouvez √©galement tordre la quantification (par exemple, avec TensorRT) </li><li>  Tensorflow fournit des fonctionnalit√©s pour <a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras" rel="nofollow">low_magnitude_pruning</a> .  √áa marche. </li><li>  Je souhaite d√©velopper le <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">r√©f√©rentiel</a> et je serai heureux de vous aider </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr482050/">https://habr.com/ru/post/fr482050/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr482034/index.html">Yandex: il y a tout ... sur les utilisateurs</a></li>
<li><a href="../fr482038/index.html">Nous r√©sumons les r√©sultats de 2019 √† Haber Career</a></li>
<li><a href="../fr482040/index.html">Caract√©ristiques des programmes de profilage en C ++</a></li>
<li><a href="../fr482042/index.html">Travailler avec la biblioth√®que Newtonsoft.Json avec un exemple r√©el. 2e partie</a></li>
<li><a href="../fr482044/index.html">10 meilleures pratiques pour s√©curiser les images Docker. 2e partie</a></li>
<li><a href="../fr482052/index.html">Jeu de donn√©es du Nouvel An 2019: dictionnaire tonal ouvert de la langue russe</a></li>
<li><a href="../fr482054/index.html">3. Pile √©lastique: analyse du journal de s√©curit√©. Tableaux de bord</a></li>
<li><a href="../fr482058/index.html">Pr√©dateur ou proie? Qui prot√©gera les autorit√©s de certification</a></li>
<li><a href="../fr482060/index.html">Mod√®le de mandat de contr√¥le d'acc√®s (MAC): pr√©sentation et applications</a></li>
<li><a href="../fr482064/index.html">Facilit√© de d√©veloppement de sites multilingues sur CMS Umbraco 8</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ‚Äçüè´ üë©üèª‚Äçü§ù‚Äçüë®üèΩ üç≤ Impl√©mentation de mod√®les seq2seq dans Tensorflow üß§ üë®üèø‚Äçüåæ ‚ò¶Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La g√©n√©ration de donn√©es √† l'aide d'un r√©seau neuronal r√©current devient une m√©thode de plus en plus populaire et utilis√©e dans de nombreux domaines d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Impl√©mentation de mod√®les seq2seq dans Tensorflow</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440472/"><p>  La g√©n√©ration de donn√©es √† l'aide d'un r√©seau neuronal r√©current devient une m√©thode de plus en plus populaire et utilis√©e dans de nombreux domaines de l'informatique.  Depuis le d√©but de la naissance du concept seq2seq en 2014, seulement cinq ans se sont √©coul√©s, mais le monde a vu de nombreuses applications, √† commencer par les mod√®les classiques de traduction et de reconnaissance vocale, et se terminant par la g√©n√©ration de descriptions d'objets dans les photographies. </p><br><p> D'autre part, au fil du temps, la biblioth√®que Tensorflow, publi√©e par Google sp√©cifiquement pour le d√©veloppement de r√©seaux de neurones, a gagn√© en popularit√©.  Naturellement, les d√©veloppeurs de Google ne pouvaient pas ignorer un paradigme aussi populaire que seq2seq, de sorte que la biblioth√®que Tensorflow fournit des classes pour le d√©veloppement au sein de ce paradigme.  Cet article d√©crit ce syst√®me de classes. </p><a name="habracut"></a><br><h2 id="rekurentnye-seti">  R√©seaux r√©currents </h2><br><p>  √Ä l'heure actuelle, les r√©seaux r√©currents sont l'un des formalismes les plus connus et les plus pratiques pour construire des r√©seaux de neurones profonds.  Les r√©seaux r√©cursifs sont con√ßus pour traiter des donn√©es s√©rie.Par cons√©quent, contrairement √† une cellule normale (neurone), qui re√ßoit des donn√©es en entr√©e et g√©n√®re le r√©sultat des calculs, une cellule r√©cursive contient deux entr√©es et deux sorties. </p><br><p>  L'une des entr√©es repr√©sente les donn√©es de l'√©l√©ment actuel de la s√©quence, et la deuxi√®me entr√©e est appel√©e l' <i>√©tat</i> et est transmise √† la suite des calculs de cellule sur l'√©l√©ment pr√©c√©dent de la s√©quence. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/684/601/aa6/684601aa63886d86a1b4dafcf8ab079c.png" width="100" alt="image"><br><p>  La figure montre la cellule A, pour laquelle les donn√©es d'un √©l√©ment de s√©quence sont entr√©es <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-1"> x_t </script>  ainsi que la condition non indiqu√©e ici <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.017ex" height="1.937ex" viewBox="0 -520.7 1729.5 834" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-73" x="0" y="0"></use><g transform="translate(469,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMAIN-31" x="1140" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-2"> s_ {t-1} </script>  .  En sortie, la cellule A donne l'√©tat <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.916ex" height="1.817ex" viewBox="0 -520.7 825.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-73" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-74" x="663" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> s_t </script>  et le r√©sultat du calcul <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>h</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.165ex" height="2.419ex" viewBox="0 -780.1 932.1 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-74" x="815" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>h</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> h_t </script>  . </p><br><p>  En pratique, la s√©quence de donn√©es est g√©n√©ralement divis√©e en sous-s√©quences d'une certaine longueur fixe et transmise au calcul par sous-ensembles entiers (lots).  En d'autres termes, les sous-s√©quences sont des exemples d'apprentissage.  Les entr√©es, sorties et √©tats de cellule d'un r√©seau r√©cursif sont des s√©quences de nombres r√©els.  Pour le calcul d'entr√©e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mn>1</mn></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.384ex" height="1.696ex" viewBox="0 -520.7 1026.4 730.2" role="img" focusable="false" style="vertical-align: -0.487ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjnDJ9sq-ZAmXoV4v9Hl9Jy5YuMAw#MJMAIN-31" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mn>1</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> x_1 </script>  il est n√©cessaire d'utiliser un √©tat qui n'√©tait pas le r√©sultat d'un calcul sur une s√©quence donn√©e de donn√©es.  Ces √©tats sont appel√©s √©tats initiaux.  Si la s√©quence est suffisamment longue, il est logique de conserver le contexte des calculs sur chaque sous-s√©quence.  Dans ce cas, il est possible de transmettre le dernier √©tat calcul√© dans la s√©quence pr√©c√©dente en tant qu'√©tat initial.  Si la s√©quence n'est pas si longue ou si la sous-s√©quence est le premier segment, vous pouvez initialiser l'√©tat initial avec des z√©ros. </p><br><p>  √Ä l'heure actuelle, pour l'entra√Ænement des r√©seaux de neurones presque partout, l'algorithme de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©tro-propagation des erreurs est utilis√©</a> .  Le r√©sultat du calcul sur l'ensemble d'exemples transmis (dans notre cas, l'ensemble de sous-s√©quences) est v√©rifi√© par rapport au r√©sultat attendu (donn√©es balis√©es).  La diff√©rence entre les valeurs r√©elles et attendues est appel√©e une erreur et cette erreur est propag√©e aux poids du r√©seau dans le sens oppos√©.  Ainsi, le r√©seau s'adapte aux donn√©es √©tiquet√©es et, en r√®gle g√©n√©rale, le r√©sultat de cette adaptation fonctionne bien pour les donn√©es que le r√©seau n'a pas rencontr√©es dans les exemples de formation initiale (hypoth√®se de g√©n√©ralisation). </p><br><p>  Dans le cas d'un r√©seau r√©cursif, nous avons plusieurs options sur les sorties pour consid√©rer l'erreur.  Nous en d√©crirons ici deux principaux: </p><br><ol><li>  Vous pouvez consid√©rer l'erreur en comparant la sortie de la derni√®re cellule de la sous-s√©quence avec la sortie attendue.  Cela fonctionne bien pour la t√¢che de classification.  Par exemple, nous devons d√©terminer la coloration √©motionnelle d'un tweet.  Pour ce faire, nous s√©lectionnons les tweets et les marquons en trois cat√©gories: n√©gatif, positif et neutre.  La sortie de la cellule sera compos√©e de trois nombres - le poids des cat√©gories.  Le tweet sera √©galement marqu√© de trois chiffres - les probabilit√©s de tweet appartenant √† la cat√©gorie correspondante.  Apr√®s avoir calcul√© l'erreur sur un sous-ensemble des donn√©es, vous pouvez la propager √† travers la sortie ou l'√©tat comme vous le souhaitez. </li><li>  Vous pouvez lire l'erreur imm√©diatement aux sorties du calcul de cellule pour chaque √©l√©ment de la sous-s√©quence.  Ceci est bien adapt√© pour la t√¢che de pr√©dire l'√©l√©ment suivant d'une s√©quence √† partir des pr√©c√©dents.  Une telle approche peut √™tre utilis√©e, par exemple, dans le probl√®me de la d√©termination des anomalies dans les s√©ries temporelles de donn√©es ou dans la t√¢che de pr√©dire le caract√®re suivant dans un texte, afin de le g√©n√©rer plus tard.  La propagation des erreurs est √©galement possible via des √©tats ou des sorties. </li></ol><br><p>  Contrairement √† un r√©seau neuronal enti√®rement connect√© r√©gulier, un r√©seau r√©cursif est profond dans le sens o√π l'erreur se propage non seulement des sorties du r√©seau √† ses poids, mais aussi √† gauche, via des connexions entre les √©tats.  La profondeur du r√©seau est ainsi d√©termin√©e par la longueur de la sous-s√©quence.  Pour propager l'erreur √† travers l'√©tat du r√©seau r√©cursif, il existe un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">algorithme</a> sp√©cial.  Sa particularit√© est que les gradients des poids se multiplient entre eux, lorsque l'erreur se propage de droite √† gauche.  Si l'erreur initiale est sup√©rieure √† l'unit√©, en cons√©quence, l'erreur peut devenir tr√®s importante.  Inversement, si l'erreur initiale est inf√©rieure √† l'unit√©, quelque part au d√©but de la s√©quence, l'erreur peut s'estomper.  Cette situation dans la th√©orie des r√©seaux de neurones est appel√©e carrousel d'erreur standard.  Afin d'√©viter de telles situations pendant l'entra√Ænement, des cellules sp√©ciales ont √©t√© invent√©es qui ne pr√©sentent pas de tels inconv√©nients.  La premi√®re cellule de ce type √©tait le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LSTM</a> , il existe maintenant une large gamme d'alternatives, dont le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GRU</a> le plus populaire. </p><br><p>  Une bonne introduction aux r√©seaux de r√©currence peut √™tre trouv√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans cet article</a> .  Une autre source bien connue est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article</a> du blog d'Andrey Karpaty. </p><br><p>  La biblioth√®que Tensorflow poss√®de de nombreuses classes et fonctions pour impl√©menter des r√©seaux r√©cursifs.  Voici un exemple de cr√©ation d'un r√©seau r√©cursif dynamique bas√© sur une cellule de type GRU: </p><br><pre><code class="python hljs">cell = tf.contrib.rnn.GRUCell(dimension) outputs, state = tf.nn.dynamic_rnn(cell, input, sequence_length=input_length, dtype=tf.float32)</code> </pre> <br><p>  Dans cet exemple, une cellule GRU est cr√©√©e, qui est ensuite utilis√©e pour cr√©er un r√©seau r√©cursif dynamique.  Le tenseur de donn√©es d'entr√©e et les longueurs r√©elles des sous-s√©quences sont transmis au r√©seau.  Les donn√©es d'entr√©e sont toujours sp√©cifi√©es par un vecteur de nombres r√©els.  Pour une seule valeur, par exemple, un code de symbole ou un mot, le soi-disant  incorporation - mappage de ce code √† une s√©quence de nombres.  La fonction de cr√©ation d'un r√©seau r√©cursif dynamique renvoie une paire de valeurs: une liste de sorties r√©seau pour toutes les valeurs de la s√©quence et le dernier √©tat calcul√©.  En entr√©e, la fonction prend une cellule, des donn√©es d'entr√©e et un tenseur de longueur de sous-s√©quence. </p><br><p>  Un r√©seau r√©cursif dynamique diff√®re d'un r√©seau statique en ce qu'il ne cr√©e pas √† l'avance un r√©seau de cellules de r√©seau pour la sous-s√©quence (au stade de la d√©termination du graphe de calcul), mais lance dynamiquement les cellules des entr√©es lors du calcul du graphe sur les donn√©es d'entr√©e.  Par cons√©quent, cette fonction doit conna√Ætre les longueurs des sous-s√©quences des donn√©es d'entr√©e afin de s'arr√™ter au bon moment. </p><br><h2 id="porozhdayuschie-modeli-na-osnove-rekurentnyh-setey">  G√©n√©ration de mod√®les bas√©s sur des r√©seaux de r√©currence </h2><br><h3 id="porozhdayuschie-rekurentnye-seti">  G√©n√©ration de r√©seaux de r√©currence </h3><br><p>  Plus t√¥t, nous avons consid√©r√© deux m√©thodes de calcul des erreurs des r√©seaux r√©cursifs: √† la derni√®re sortie ou √† toutes les sorties pour une s√©quence donn√©e.  Nous consid√©rons ici le probl√®me de la g√©n√©ration de s√©quences.  La formation du r√©seau de g√©n√©rateurs est bas√©e sur la deuxi√®me m√©thode de ce qui pr√©c√®de. </p><br><p>  Plus en d√©tail, nous essayons de former un r√©seau r√©cursif pour pr√©dire le prochain √©l√©ment d'une s√©quence.  Comme mentionn√© ci-dessus, la sortie d'une cellule dans un r√©seau r√©cursif est simplement une s√©quence de nombres.  Ce vecteur n'est pas tr√®s pratique pour l'apprentissage, par cons√©quent, ils introduisent un autre niveau, qui re√ßoit ce vecteur en entr√©e et en sortie donne le poids des pr√©dictions.  Ce niveau est appel√© <em>niveau de projection</em> et vous permet de comparer la sortie de la cellule sur un √©l√©ment donn√© de la s√©quence avec la sortie attendue dans les donn√©es √©tiquet√©es. </p><br><p>  Pour illustrer, consid√©rez la t√¢che de g√©n√©rer du texte qui est repr√©sent√© comme une s√©quence de caract√®res.  La longueur du vecteur de sortie du niveau de projection est √©gale √† la taille de l'alphabet du texte source.  La taille de l'alphabet ne d√©passe g√©n√©ralement pas 150 caract√®res, si l'on compte les caract√®res des langues russe et anglaise, ainsi que les signes de ponctuation.  La sortie du niveau de projection est un vecteur avec la longueur de l'alphabet, o√π chaque symbole correspond √† une certaine position dans ce vecteur - l'indice de ce symbole.  Les donn√©es √©tiquet√©es sont √©galement un vecteur compos√© de z√©ros, o√π l'on se trouve √† la position du caract√®re suivant la s√©quence. </p><br><p>  Pour la formation, nous utilisons deux s√©quences de donn√©es: </p><br><ol><li>  Une s√©quence de caract√®res dans le texte source, au d√©but de laquelle est ajout√© un caract√®re sp√©cial qui ne fait pas partie du texte source.  Il est g√©n√©ralement appel√© <em>go</em> . </li><li>  La s√©quence de caract√®res du texte source tel quel, sans ajouts. </li></ol><br><p>  Exemple pour le texte "maman a lav√© le cadre": </p><br><pre> <code class="python hljs">[<span class="hljs-string"><span class="hljs-string">'&lt;go&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">'] ['</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>]</code> </pre> <br><p>  Pour la formation, des minibatches sont g√©n√©ralement form√©s, consistant en un petit nombre d'exemples.  Dans notre cas, ce sont des cha√Ænes qui peuvent √™tre de diff√©rentes longueurs.  Le code d√©crit ci-dessous utilise la m√©thode suivante pour r√©soudre le probl√®me des diff√©rentes longueurs.  Parmi les nombreuses lignes de ce mini-paquet, la longueur maximale est calcul√©e.  Toutes les autres lignes sont remplies d'un caract√®re sp√©cial (remplissage) afin que tous les exemples du mini-paquet aient la m√™me longueur.  Dans l'exemple de code ci-dessous, la cha√Æne de <em>pav√©</em> est utilis√©e comme un tel caract√®re.  De plus, pour une meilleure g√©n√©ration, √† la fin de l'exemple, ajoutez le symbole de fin de phrase - <em>eos</em> .  Ainsi, en r√©alit√©, les donn√©es de l'exemple seront un peu diff√©rentes: </p><br><pre> <code class="python hljs">[<span class="hljs-string"><span class="hljs-string">'&lt;go&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;eos&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">'] ['</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;eos&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>]</code> </pre> <br><p>  La premi√®re s√©quence est envoy√©e √† l'entr√©e du r√©seau et la seconde s√©quence est utilis√©e comme donn√©es √©tiquet√©es.  L'entra√Ænement √† la pr√©diction est bas√© sur le d√©calage de la s√©quence d'origine d'un caract√®re vers la gauche. </p><br><h3 id="obuchenie-i-porozhdenie">  Formation et frai </h3><br><h4 id="obuchenie">  La formation </h4><br><p>  L'algorithme d'apprentissage est assez simple.  Pour chaque √©l√©ment de la s√©quence d'entr√©e, nous calculons le vecteur de sortie de son niveau de projection et le comparons avec celui marqu√©.  La seule question est de savoir comment calculer l'erreur.  Vous pouvez utiliser l'erreur quadratique moyenne, mais pour calculer l'erreur dans cette situation, il est pr√©f√©rable d'utiliser l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">entropie crois√©e</a> .  La biblioth√®que Tensorflow fournit plusieurs fonctions pour son calcul, bien que rien n'arr√™te l'impl√©mentation de la formule de calcul directement dans le code. </p><br><p>  Pour plus de clart√©, nous introduisons une notation.  Par symbol_id nous d√©signerons l'identifiant du symbole (son num√©ro de s√©rie dans l'alphabet).  Le terme symbole ici est plut√¥t arbitraire et signifie simplement un √©l√©ment de l'alphabet.  L'alphabet peut ne pas contenir de symboles, mais des mots ou m√™me des ensembles d'attributs plus complexes.  Le terme symbol_embedding sera utilis√© pour d√©signer le vecteur de nombres correspondant √† un √©l√©ment donn√© de l'alphabet.  En r√®gle g√©n√©rale, ces ensembles de nombres sont stock√©s dans une table de taille qui correspond √† la taille de l'alphabet. </p><br><p>  Tensorflow fournit une fonctionnalit√© qui vous permet d'acc√©der √† la table d'int√©gration et de remplacer les indices de caract√®res par leurs vecteurs d'int√©gration.  Tout d'abord, nous d√©finissons une variable pour stocker la table: </p><br><pre> <code class="python hljs">embedding_table = tf.Variable(tf.random_uniform([alphabet_size, embedding_size]))</code> </pre> <br><p>  Apr√®s cela, vous pouvez convertir les tenseurs d'entr√©e en tenseurs d'int√©gration: </p><br><pre> <code class="python hljs">input_embeddings = tf.nn.embedding_lookup(embedding_table, input_ids)</code> </pre> <br><p>  Le r√©sultat de l'appel de fonction est un tenseur de la m√™me dimension qui a √©t√© transf√©r√© √† l'entr√©e, mais en cons√©quence, tous les indices de caract√®res sont remplac√©s par les s√©quences d'int√©gration correspondantes. </p><br><h4 id="porozhdenie">  Spawn </h4><br><p>  Pour calculer, une cellule d'un r√©seau r√©cursif a besoin d'un √©tat et du caract√®re courant.  Le r√©sultat du calcul est une sortie et un nouvel √©tat.  Si nous appliquons le niveau de projection √† la sortie, nous pouvons obtenir un vecteur de poids o√π le poids √† la position correspondante peut √™tre consid√©r√© (tr√®s conditionnellement) comme la probabilit√© que ce symbole apparaisse √† la position suivante dans la s√©quence. </p><br><p>  Diff√©rentes strat√©gies peuvent √™tre utilis√©es pour s√©lectionner le symbole suivant en fonction du vecteur de poids g√©n√©r√© par le niveau de projection: </p><br><ul><li>  Strat√©gie de recherche gourmande.  Chaque fois que nous s√©lectionnons le symbole avec le poids le plus √©lev√©, c'est-√†-dire  tr√®s probablement dans cette situation, mais pas n√©cessairement le plus appropri√© dans le contexte de la s√©quence enti√®re. </li><li>  Strat√©gie pour choisir la meilleure s√©quence (recherche de faisceau).  Nous ne s√©lectionnons pas un symbole √† la fois, mais nous nous souvenons de plusieurs variantes des symboles les plus probables.  Une fois toutes ces options calcul√©es pour tous les √©l√©ments de la s√©quence g√©n√©r√©e, nous s√©lectionnons la s√©quence de caract√®res la plus probable, en tenant compte du contexte de la s√©quence enti√®re.  Habituellement, cela est mis en ≈ìuvre au moyen d'une matrice dont la largeur est √©gale √† la longueur de la s√©quence et la hauteur au nombre de largeurs de g√©n√©ration de faisceau.  Une fois la g√©n√©ration des variantes de s√©quence termin√©e, l'une des variantes de l'algorithme de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Viterbi</a> est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">utilis√©e</a> pour s√©lectionner la s√©quence la plus probable. </li></ul><br><h2 id="sistema-tipov-seq2seq-v-biblioteke-tensorflow">  Biblioth√®que Tensorflow syst√®me de type seq2seq </h2><br><p>  Compte tenu de ce qui pr√©c√®de, il est clair que la mise en ≈ìuvre de mod√®les g√©n√©ratifs bas√©s sur des r√©seaux de r√©currence est une t√¢che assez difficile √† coder.  Par cons√©quent, naturellement, des syst√®mes de classes ont √©t√© propos√©s pour faciliter la solution de ce probl√®me.  L'un de ces syst√®mes est appel√© seq2seq, puis nous d√©crivons la fonctionnalit√© de ses principaux types. </p><br><p>  Mais, tout d'abord, quelques mots sur le nom de la biblioth√®que.  Le nom seq2seq est l'abr√©viation de s√©quence √† s√©quence (de s√©quence √† s√©quence).  L'id√©e originale de g√©n√©rer une s√©quence a √©t√© propos√©e pour la mise en ≈ìuvre d'un syst√®me de traduction.  La s√©quence d'entr√©e de mots a √©t√© transmise √† l'entr√©e d'un r√©seau r√©cursif, appel√© codeur dans ce syst√®me.  La sortie de ce r√©seau r√©cursif √©tait l'√©tat du calcul de cellule sur le dernier caract√®re de la s√©quence.  Cet √©tat a √©t√© pr√©sent√© comme l'√©tat initial du deuxi√®me r√©seau r√©cursif, le d√©codeur, qui a √©t√© form√© pour g√©n√©rer le mot suivant.  Les mots ont √©t√© utilis√©s comme symboles dans les deux r√©seaux.  Des erreurs sur le d√©corateur ont √©t√© propag√©es √† l'encodeur via l'√©tat transmis.  Le vecteur d'√©tat lui-m√™me dans cette terminologie √©tait appel√© le vecteur de pens√©e.  La pr√©sentation interm√©diaire a √©t√© utilis√©e dans les mod√®les de traduction traditionnels et, en r√®gle g√©n√©rale, √©tait un graphique repr√©sentant la structure du texte d'entr√©e pour la traduction.  Le syst√®me de traduction a g√©n√©r√© un texte de sortie bas√© sur cette structure interm√©diaire. </p><br><p>  En fait, l'impl√©mentation de seq2seq dans Tensorflow appartient √† la partie d√©codeur, sans affecter l'encodeur.  Par cons√©quent, il serait juste d'appeler la biblioth√®que 2seq, mais la force de la tradition et l'inertie de la pens√©e l'emportent √©videmment sur le bon sens. </p><br><p>  Les deux principaux m√©tatypes de la biblioth√®que seq2seq sont: </p><br><ol><li>  Classe d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">aide</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">D√©codeur de</a> classe. </li></ol><br><p>  Les d√©veloppeurs de biblioth√®que ont identifi√© ces types sur la base des consid√©rations suivantes.  Consid√©rons le processus d'apprentissage et le processus de g√©n√©ration, que nous avons d√©crits ci-dessus, sous un angle l√©g√®rement diff√©rent. </p><br><p>  Pour la formation dont vous avez besoin: </p><br><ol><li>  Pour chaque caract√®re, passez le calcul de l'√©tat courant et l'incorporation du caract√®re courant. </li><li>  N'oubliez pas l'√©tat de sortie et la projection calcul√©s pour la sortie. </li><li>  Obtenez le caract√®re suivant dans la s√©quence et passez √† l'√©tape 1. </li></ol><br><p>  Apr√®s cela, vous pouvez commencer √† compter les erreurs en comparant les r√©sultats des calculs avec les caract√®res suivants de la s√©quence. </p><br><p>  Pour le g√©n√©rer il faut: </p><br><ol><li>  Pour chaque caract√®re, passez le calcul de l'√©tat courant et l'incorporation du caract√®re courant. </li><li>  N'oubliez pas l'√©tat de sortie et la projection calcul√©s pour la sortie. </li><li>  Calculez le caract√®re suivant comme le maximum des indices de niveau de projection et passez √† l'√©tape 1. </li></ol><br><p>  Comme le montre la description, les algorithmes sont tr√®s similaires.  Par cons√©quent, les d√©veloppeurs de la biblioth√®que ont d√©cid√© d'encapsuler la proc√©dure d'obtention du caract√®re suivant dans la classe Helper.  Pour l'entra√Ænement, il s'agit simplement de lire le caract√®re suivant de la s√©quence, et pour le g√©n√©rer, s√©lectionner le caract√®re avec le poids maximum (bien s√ªr, pour une recherche gourmande). </p><br><p>  Par cons√©quent, la classe de base Helper impl√©mente la m√©thode next_inputs pour obtenir le caract√®re suivant du courant et de l'√©tat, ainsi que la m√©thode d'exemple pour obtenir les indices de caract√®re du niveau de projection.  La classe TrainingHelper est fournie pour la formation et la classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GreedyEmbeddingHelper</a> est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">disponible</a> pour la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">g√©n√©ration</a> gourmande.  Malheureusement, le mod√®le de recherche de faisceau ne rentre pas dans ce syst√®me de type, par cons√©quent, une classe sp√©ciale <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">BeamSearchDecoder est</a> impl√©ment√©e dans la biblioth√®que pour cela.  n'utilise pas Helper. </p><br><p>  La classe Decoder fournit une interface pour impl√©menter un d√©codeur.  En fait, la classe propose deux m√©thodes: </p><br><ol><li>  initialiser pour initialiser au d√©but du travail. </li><li>  √©tape pour mettre en ≈ìuvre une √©tape d'apprentissage ou une g√©n√©ration.  Le contenu de cette √©tape est d√©termin√© par l'assistant correspondant. </li></ol><br><p>  La biblioth√®que impl√©mente la classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">BasicDecoder</a> , qui peut √™tre utilis√©e √† la fois pour la formation et pour la reproduction avec les assistants TrainingHelper et GreedyEmbeddingHelper.  Ces trois classes sont g√©n√©ralement suffisantes pour impl√©menter des mod√®les de g√©n√©ration bas√©s sur des r√©seaux de r√©currence. </p><br><p>  Enfin, les fonctions <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dynamic_decode</a> sont utilis√©es pour organiser le passage √† travers une entr√©e ou une s√©quence g√©n√©r√©e. </p><br><p>  Ensuite, nous consid√©rerons un exemple illustratif, qui montre des m√©thodes pour construire des mod√®les de g√©n√©ration pour diff√©rents types de biblioth√®que seq2seq. </p><br><h2 id="illyustrativnyy-primer">  Exemple illustratif </h2><br><p>  Tout d'abord, il faut dire que tous les exemples sont impl√©ment√©s en Python 2.7.  Une liste de biblioth√®ques suppl√©mentaires se trouve dans le fichier requirements.txt. </p><br><p>  √Ä titre d'exemple illustratif, consid√©rons une partie des donn√©es du concours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">D√©fi de normalisation de texte - langue russe</a> organis√© par Kaggle by Google en 2017.  Le but de ce concours √©tait de convertir le texte russe en une forme adapt√©e √† la lecture.  Le texte du concours a √©t√© d√©compos√© en expressions dactylographi√©es.  Les donn√©es d'entra√Ænement ont √©t√© sp√©cifi√©es dans un fichier CSV de la forme suivante: </p><br><pre> <code class="plaintext hljs">"sentence_id","token_id","class","before","after" 0,0,"PLAIN","","" 0,1,"PLAIN","","" 0,2,"PLAIN","","" 0,3,"DATE","1862 ","    " 0,4,"PUNCT",".","." 1,0,"PLAIN","","" 1,1,"PLAIN","","" 1,2,"PLAIN","","" 1,3,"PLAIN","","" 1,4,"PLAIN","","" 1,5,"PLAIN","","" 1,6,"PLAIN","","" 1,7,"PLAIN","","" 1,8,"PLAIN","","" 1,9,"PUNCT",".","." ...</code> </pre> <br><p>  Dans l'exemple ci-dessus, une expression de type DATE est int√©ressante: "1862" se traduit par "mille huit cent soixante-deuxi√®me ann√©e".  Pour illustrer, nous consid√©rons les donn√©es de type DATE uniquement comme des paires de la forme (expression avant, expression apr√®s).  D√©but du fichier de donn√©es: </p><br><pre> <code class="plaintext hljs">before,after 1862 ,     1811 ,    12  2013,      15  2013,      1905 ,    17  2014,      7  2010 ,      1 ,  1843 ,     30  2007 ,      1846 ,     1996 ,     9 ,  ...</code> </pre> <br><p>  Nous allons construire le mod√®le g√©n√©rateur √† l'aide de la biblioth√®que seq2seq, dans laquelle l'encodeur sera impl√©ment√© au niveau du symbole (c'est-√†-dire que les √©l√©ments de l'alphabet sont des symboles), et le d√©codeur utilisera les mots comme alphabet.  Un exemple de code, comme les donn√©es, est disponible dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©f√©rentiel sur Github</a> . </p><br><p>  Les donn√©es de formation sont divis√©es en trois sous-ensembles: train.csv, test.csv et dev.csv, pour la v√©rification de la formation, des tests et du recyclage, respectivement.  Les donn√©es se trouvent dans le r√©pertoire de donn√©es.  Trois mod√®les sont impl√©ment√©s dans le r√©f√©rentiel: seq2seq_greedy.py, seq2seq_attention.py et seq2seq_beamsearch.py.  Ici, nous regardons le code du mod√®le de recherche gourmand de base. </p><br><p>  Tous les mod√®les utilisent la classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Estimator</a> pour impl√©menter.  L'utilisation de cette classe vous permet de simplifier le codage sans √™tre distrait par des pi√®ces non mod√®les.  Par exemple, il n'est pas n√©cessaire d'impl√©menter un cycle de transfert de donn√©es pour la formation, de cr√©er des sessions pour travailler avec Tensorflow, de penser √† transf√©rer des donn√©es vers Tensorboard, etc.  Estimator ne n√©cessite que deux fonctions pour sa mise en ≈ìuvre: pour le transfert de donn√©es et pour la construction d'un mod√®le.  Les exemples utilisent √©galement la classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dataset</a> pour transmettre des donn√©es pour le traitement.  Cette impl√©mentation moderne est beaucoup plus rapide que les dictionnaires traditionnels pour le transfert de donn√©es feed_dict. </p><br><h3 id="formirovanie-dannyh">  G√©n√©ration de donn√©es </h3><br><p>  Consid√©rez un code de g√©n√©ration de donn√©es pour la formation et la g√©n√©ration. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parse_fn</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(line_before, line_after)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Encode in Bytes for TF source = [c.encode('utf8') for c in line_before.decode('utf8').rstrip('\n')] t = [w.encode('utf8') for w in nltk.word_tokenize(line_after.decode('utf8').strip())] learn_target = t + ['&lt;eos&gt;'] + ['&lt;pad&gt;'] target = ['&lt;go&gt;'] + t + ['&lt;eos&gt;'] return (source, len(source)), (target, learn_target, len(target)) def generator_fn(data_file): with open(data_file, 'rb') as f: reader = csv.DictReader(f, delimiter=',', quotechar='"') for row in reader: yield parse_fn(row['before'], row['after']) def input_fn(data_file, params=None): params = params if params is not None else {} shapes = (([None], ()), ([None], [None], ())) types = ((tf.string, tf.int32), (tf.string, tf.string, tf.int32)) defaults = (('&lt;pad&gt;', 0), ('&lt;pad&gt;', '&lt;pad&gt;', 0)) dataset = tf.data.Dataset.from_generator(functools.partial(generator_fn, data_file), output_shapes=shapes, output_types=types) dataset = dataset.repeat(params['epochs']) return (dataset.padded_batch(params.get('batch_size', 50), shapes, defaults).prefetch(1))</span></span></code> </pre> <br><p>  La fonction input_fn est utilis√©e pour cr√©er une collection de donn√©es que Estimator transmet ensuite √† la formation et √† la g√©n√©ration.  Le type de donn√©es est d√©fini en premier.  Il s'agit d'une paire de la forme ((s√©quence codeur, longueur), (s√©quence d√©codeur, s√©quence d√©codeur avec un pr√©fixe, longueur)).  La cha√Æne "" est utilis√©e comme pr√©fixe, chaque s√©quence d'encodeur se termine par un mot sp√©cial "".  De plus, √©tant donn√© que les s√©quences (√† la fois en entr√©e et en sortie) ont une longueur in√©gale, le symbole de remplissage avec la valeur "" est utilis√©. <br></p><p>  Le code de pr√©paration des donn√©es lit le fichier de donn√©es, divise la cha√Æne d'encodeur en caract√®res et la cha√Æne de d√©codeur en mots, en utilisant la biblioth√®que nltk pour cela.  Une ligne ainsi trait√©e est un exemple de donn√©es d'apprentissage.  La collection g√©n√©r√©e est divis√©e en mini-packages et la quantit√© de donn√©es est clon√©e en fonction du nombre d'√©poques de formation (chaque √©poque correspond √† une passe de donn√©es). </p><br><h3 id="rabota-so-slovaryami">  Travailler avec des dictionnaires </h3><br><p>  Les dictionnaires sont stock√©s sous forme de liste dans des fichiers, une ligne pour un mot ou un caract√®re.  Pour cr√©er des dictionnaires, utilisez le script build_vocabs.py.  Les dictionnaires g√©n√©r√©s se trouvent dans le r√©pertoire de donn√©es sous forme de fichiers de la forme vocab. *. Txt. </p><br><p>  Code de lecture des dictionnaires: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Read vocabs and inputs dropout = params['dropout'] source, source_length = features training = (mode == tf.estimator.ModeKeys.TRAIN) vocab_source = tf.contrib.lookup.index_table_from_file(vocabulary_file=params['source_vocab_file'], num_oov_buckets=params['num_oov_buckets']) with open(params['source_vocab_file']) as f: num_sources = sum(1 for _ in f) + params['num_oov_buckets'] vocab_target = tf.contrib.lookup.index_table_from_file(vocabulary_file=params['target_vocab_file'], num_oov_buckets=params['num_oov_buckets']) with open(params['target_vocab_file']) as f: num_targets = sum(1 for _ in f) + params['num_oov_buckets']</span></span></code> </pre> <br><p>  Ici, probablement, la fonction index_table_from_file est int√©ressante, qui lit les √©l√©ments du dictionnaire d'un fichier, et son param√®tre num_oov_buckets est le nombre de paniers de vocabulaire.  Par d√©faut, ce nombre est √©gal √† un, c'est-√†-dire  tous les mots qui ne sont pas dans le dictionnaire ont le m√™me indice √©gal √† la taille du dictionnaire + 1. Nous avons trois mots inconnus: "", "" et "", pour lesquels nous voulons avoir des index diff√©rents.  Par cons√©quent, d√©finissez ce param√®tre sur le num√©ro trois.  Malheureusement, vous devez relire le fichier d'entr√©e pour obtenir le nombre de mots dans le dictionnaire comme constante de temps pour d√©finir le graphique du mod√®le. <br></p><p>  Nous devons encore cr√©er une table pour impl√©menter l'incorporation - _source_embedding, ainsi que la traduction des cha√Ænes de mots en cha√Ænes d'identification: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># source embeddings matrix _source_embedding = tf.Variable(tf.random_uniform([num_sources, params['embedding_size']])) source_ids = vocab_source.lookup(source) source_embedding = tf.nn.embedding_lookup(_source_embedding, source_ids)</span></span></code> </pre> <br><h3 id="realizaciya-kodirovschika">  Impl√©mentation de l'encodeur </h3><br><p>  Pour l'encodeur, nous utiliserons un r√©seau r√©cursif bidirectionnel √† plusieurs niveaux.     ,     ,      . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># add multilayer bidirectional RNN cell_fw = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) cell_bw = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, source_embedding, sequence_length=source_length, dtype=tf.float32) # prepare output output = tf.concat(outputs, axis=-1) encoder_output = tf.layers.dense(output, params['dim']) # prepare state state_fw, state_bw = states cells = [] for fw, bw in zip(state_fw, state_bw): state = tf.concat([fw, bw], axis=-1) cells += [tf.layers.dense(state, params['dim'])] encoder_state = tuple(cells)</span></span></code> </pre> <br><p>       GRU,    MultiRNNCell,   ,   rnn.Cell.    , <br> sequence_length ‚Äî     ,     ,    . </p><br><p> ,       ,       ,           .      ,      128,        256.     ,        ,      128.        . </p><br><p>     .  Parce que    , ,    bidirectional_dynamic_rnn,   ,     .           ,      .     , ..       . , ,  .            ,   ,       . </p><br><h3 id="realizaciya-dekodirovschika">   </h3><br><p>     ,    .           . </p><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># decoder RNN cell decoder_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) decoder_initial_state = encoder_state # projection layer projection_layer = tf.layers.Dense(num_targets, use_bias=False) # embedding table for targets target_embedding = tf.Variable(tf.random_uniform([num_targets, params['embedding_size']]))</span></span></code> </pre> <br><h4 id="obuchenie-1">  La formation </h4><br><p>    TrainingHelper + BasicDecoder. </p><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># target embeddings matrix target, learn_target, target_length = labels target_ids = vocab_target.lookup(target) target_learn_ids = vocab_target.lookup(learn_target) # train encoder _target_embedding = tf.nn.embedding_lookup(target_embedding, target_ids) train_helper = tf.contrib.seq2seq.TrainingHelper(_target_embedding, target_length) train_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, train_helper, decoder_initial_state, output_layer=projection_layer) train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(train_decoder) train_output = train_outputs.rnn_output train_sample_id = train_outputs.sample_id</span></span></code> </pre> <br><h4 id="porozhdenie-1">  </h4><br><p>        . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># prediction decoder prediction_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper( embedding=target_embedding, start_tokens=tf.fill([batch_size], tf.to_int32(vocab_target.lookup(tf.fill([], '&lt;go&gt;')))), end_token=tf.to_int32(vocab_target.lookup(tf.fill([], '&lt;eos&gt;')))) prediction_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, prediction_helper, decoder_initial_state, output_layer=projection_layer) prediction_output, _, _ = tf.contrib.seq2seq.dynamic_decode(prediction_decoder, maximum_iterations=params['max_iters']) # prepare prediction reverse_vocab_target = tf.contrib.lookup.index_to_string_table_from_file(params['target_vocab_file']) pred_strings = reverse_vocab_target.lookup(tf.to_int64(prediction_output.sample_id)) predictions = { 'ids': prediction_output.sample_id, 'text': pred_strings }</span></span></code> </pre> <br><p>     GreedyEmbeddingHelper       "",     "".        . , ,    dynamic_decode      .    ,    ,   . ,     ,        . <br><br></p><h4 id="funkciya-poter-i-optimizaciya">     </h4><br><p>     ,        seq2seq. </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># loss masks = tf.sequence_mask(lengths=target_length, dtype=tf.float32) loss = tf.contrib.seq2seq.sequence_loss(logits=train_output, targets=target_learn_ids, weights=masks)</span></span></code> </pre> <br><p>    ,     ,      sequence_mask. </p><br><p>     Adam   ,   . </p><br><pre> <code class="python hljs">optimizer = tf.train.AdamOptimizer(learning_rate=params.get(<span class="hljs-string"><span class="hljs-string">'lr'</span></span>, <span class="hljs-number"><span class="hljs-number">.001</span></span>)) grads, vs = zip(*optimizer.compute_gradients(loss)) grads, gnorm = tf.clip_by_global_norm(grads, params.get(<span class="hljs-string"><span class="hljs-string">'clip'</span></span>, <span class="hljs-number"><span class="hljs-number">.5</span></span>)) train_op = optimizer.apply_gradients(zip(grads, vs), global_step=tf.train.get_or_create_global_step())</code> </pre> <br><h4 id="rezultaty-obucheniya">   </h4><br><p>         .     0.9   . , ,     ,    .   ,    . </p><br><pre> <code class="plaintext hljs">24  1944                 1  2003              1992 .           11  1927               1969            1  2016             1047          1863            17      22  2014              </code> </pre> <br><p>        .   ‚Äî   ,   ‚Äî  ,   ‚Äî  . </p><br><p>  ,    ‚Äî   .             .    ,    ( ),       .       .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>        ,     . </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>            seq2seq.      ,          ,     .    ,  . </p><br><p>           .  Tensorflow   ,   ,     .   ,         ,   .        ,        . ,      ,   padding  ,   embedding     ?       , ,       .         ‚Äî     . ,    ,    . ,    ,    ,    . ,       . ,          , , ,        . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440472/">https://habr.com/ru/post/fr440472/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440462/index.html">Les 7 meilleures strat√©gies de marketing de contenu √† ne pas manquer en 2019</a></li>
<li><a href="../fr440464/index.html">Travailler avec le service Digital Ocean Managed Databases dans .NET Core</a></li>
<li><a href="../fr440466/index.html">T√©l√©commande Web UART</a></li>
<li><a href="../fr440468/index.html">2 fois plus, 10 fois plus vite, 24 heures sur 24 - pour le bien des gens</a></li>
<li><a href="../fr440470/index.html">Incorporer un interpr√©teur Python dans une application Java √† l'aide du projet Panama</a></li>
<li><a href="../fr440474/index.html">Effets de filtrage SVG. Partie 4. Images bicolores avec feComponentTransfer</a></li>
<li><a href="../fr440476/index.html">¬´Commencez par les mitaps¬ª ou avez-vous besoin de cours de programmation?</a></li>
<li><a href="../fr440478/index.html">Sortie de 3CX v16 Beta 1 avec prise en charge de Raspberry Pi</a></li>
<li><a href="../fr440486/index.html">Prix ‚Äã‚Äãde la qualit√©: 7 principes pour optimiser les co√ªts de test</a></li>
<li><a href="../fr440488/index.html">Cartes d'ombres r√©fl√©chissantes: Partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
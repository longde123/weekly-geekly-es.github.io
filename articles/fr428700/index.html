<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèΩ‚Äçü§ù‚ÄçüßëüèΩ üë©üèæ‚ÄçüöÄ ü•™ Comment l'apprentissage automatique chez YouDo se transforme en production. Conf√©rence √† Yandex üëéüèæ üë∂ ü¶í</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans les grands services, r√©soudre un probl√®me en utilisant le machine learning signifie ne faire qu'une partie du travail. L'incorporation de mod√®les...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment l'apprentissage automatique chez YouDo se transforme en production. Conf√©rence √† Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/428700/">  Dans les grands services, r√©soudre un probl√®me en utilisant le machine learning signifie ne faire qu'une partie du travail.  L'incorporation de mod√®les ML n'est pas si facile, et la construction de processus CI / CD autour d'eux est encore plus difficile.  Lors de la conf√©rence Yandex <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Data &amp; Science: the application program¬ª,</a> Adam Eldarov <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> responsable de la science des donn√©es chez YouDo, a expliqu√© comment g√©rer le cycle de vie des mod√®les, mettre en place des processus de recyclage et de recyclage, d√©velopper des microservices √©volutifs, et bien plus encore. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/k1Rp0A2NVdk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Commen√ßons par l'introduction.  Il y a un scientifique des donn√©es, il √©crit du code dans le cahier Jupyter, fait de l'ing√©nierie des fonctionnalit√©s, de la validation crois√©e, forme des mod√®les de mod√®les.  La vitesse augmente. <a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/fr/sg/9x/frsg9xiv8sslwj5gritig9jx4xc.jpeg"><br><br>  Mais √† un moment donn√©, il comprend: pour apporter une valeur commerciale √† l'entreprise, il doit attacher la solution quelque part dans la production, √† une production mythique, ce qui nous pose beaucoup de probl√®mes.  Dans la plupart des cas, l'ordinateur portable que nous avons vu en production ne peut pas √™tre envoy√©.  Et la question se pose: comment envoyer ce code √† l'int√©rieur de l'ordinateur portable √† un certain service.  Dans la plupart des cas, vous devez √©crire un service dot√© d'une API.  Ou ils communiquent via PubSub, via des files d'attente. <br><br><img src="https://habrastorage.org/webt/lj/al/h0/ljalh0b3jiosapstldusxdueenk.jpeg"><br><br>  Lorsque nous faisons des recommandations, nous devons souvent former des mod√®les et les recycler.  Ce processus doit √™tre surveill√©.  Dans ce cas, il faut toujours v√©rifier avec des tests √† la fois le code lui-m√™me et les mod√®les, afin qu'√† un moment notre mod√®le ne devienne pas fou et ne commence pas toujours √† pr√©dire z√©ro.  Il doit √©galement √™tre v√©rifi√© sur de vrais utilisateurs via des tests AB - ce que nous avons fait de mieux ou du moins pas de pire. <br><br>  Comment abordons-nous le code?  Nous avons GitLab.  Tout notre code est divis√© en plusieurs petites biblioth√®ques qui r√©solvent un probl√®me de domaine sp√©cifique.  En m√™me temps, il s'agit d'un projet GitLab distinct, d'un contr√¥le de version Git et du mod√®le de branchement GitFlow.  Nous utilisons des choses comme les hooks de pr√©-validation afin que vous ne puissiez pas valider du code qui ne satisfait pas nos v√©rifications de test de statistiques.  Et les tests eux-m√™mes, les tests unitaires.  Nous utilisons pour eux l'approche de test bas√©e sur les propri√©t√©s. <br><br><img src="https://habrastorage.org/webt/l8/bm/3y/l8bm3y6qju0gpmusipaz_1dvatk.jpeg"><br><br>  Habituellement, lorsque vous √©crivez des tests, vous voulez dire que vous avez une fonction de test et les arguments que vous cr√©ez avec vos mains, quelques exemples et quelles valeurs votre fonction de test renvoie.  C'est g√™nant.  Le code est gonfl√©, beaucoup en principe sont trop paresseux pour l'√©crire.  En cons√©quence, nous avons un tas de code d√©couvert par des tests.  Les tests bas√©s sur les propri√©t√©s impliquent que tous vos arguments ont une certaine distribution.  Faisons un phasage, et plusieurs fois √©chantillonnons tous nos arguments √† partir de ces distributions, appelons la fonction test√©e avec ces arguments, et v√©rifions pour certaines propri√©t√©s le r√©sultat de cette fonction.  En cons√©quence, nous avons beaucoup moins de code, et en m√™me temps, il y a beaucoup plus de tests. <br><br><img src="https://habrastorage.org/webt/6i/x6/pc/6ix6pclinddxyed-lumlmodfbdk.jpeg"><br><br>  Qu'est-ce que GitFlow?  Il s'agit d'un mod√®le de branchement, ce qui implique que vous avez deux branches principales - d√©velopper et ma√Ætriser, o√π se trouve le code pr√™t pour la production, et tout d√©veloppement est effectu√© dans la branche d√©velopper, o√π toutes les nouvelles fonctionnalit√©s proviennent de brunchs de fonctionnalit√©s.  Autrement dit, chaque fonctionnalit√© est un nouveau brunch de fonctionnalit√©s, tandis que le brunch de fonctionnalit√©s devrait √™tre de courte dur√©e, et pour de bon - √©galement couvert par le basculement des fonctionnalit√©s.  Nous faisons ensuite une version, √† partir du d√©veloppement, jetez les modifications sur master et mettez la balise de version de notre biblioth√®que ou service dessus. <br><br><img src="https://habrastorage.org/webt/ne/a7/5h/nea75hpkozbra0cmpe1q-iheh8q.jpeg"><br><br>  Nous faisons du d√©veloppement, scions une fonctionnalit√©, la poussons vers GitLab, cr√©ons une demande de fusion du brunch des fonctionnalit√©s aux jeunes filles.  Les d√©clencheurs fonctionnent, ex√©cutent des tests, si tout va bien, nous pouvons le geler.  Mais ce n'est pas nous qui le tenons, mais quelqu'un de l'√©quipe.  Il r√©vise le code et augmente ainsi le facteur de bus.  Cette section de code est d√©j√† connue de deux personnes.  Par cons√©quent, si quelqu'un se fait heurter par un bus, quelqu'un sait d√©j√† ce qu'il fait. <br><br><img src="https://habrastorage.org/webt/vg/fn/69/vgfn69mplj3hogej0adwyqe4cxe.jpeg"><br><br>  L'int√©gration continue pour les biblioth√®ques ressemble g√©n√©ralement √† des tests pour tout changement.  Et si nous le publions, il est √©galement publi√© sur le serveur PyPI priv√© de notre package. <br><br><img src="https://habrastorage.org/webt/b5/cy/fr/b5cyfrfqzlecbvb53clsbhklvp4.jpeg"><br><br>  De plus, nous pouvons le collecter dans des pipelines.  Pour cela, nous utilisons la biblioth√®que Luigi.  Il fonctionne avec une entit√© telle que la t√¢che, qui a une sortie, o√π l'artefact cr√©√© pendant l'ex√©cution de la t√¢che est enregistr√©.  Il existe un param√®tre de t√¢che qui param√®tre la logique m√©tier qu'il ex√©cute, identifie la t√¢che et sa sortie.  Dans le m√™me temps, les t√¢ches ont toujours des exigences que les autres t√¢ches posent.  Lorsque nous ex√©cutons une sorte de t√¢che, toutes ses d√©pendances sont v√©rifi√©es en v√©rifiant ses sorties.  Si la sortie existe, notre d√©pendance ne d√©marre pas.  Si l'artefact manque dans un espace de stockage, il d√©marre.  Cela forme un pipeline, un graphique cyclique dirig√©. <br><br><img src="https://habrastorage.org/webt/4k/xg/_j/4kxg_j0yykqghkej-ikbbo7y_oq.jpeg"><br><br>  Tous les param√®tres identifient la logique m√©tier.  Ce faisant, ils identifient l'artefact.  C'est toujours une date avec une certaine granularit√©, sensibilit√©, ou une semaine, jour, heure, trois heures.  Si nous formons un mod√®le, Luigi taska a toujours des hyperparam√®tres de cette t√¢che, ils fuient dans l'artefact que nous produisons, les hyperparam√®tres sont refl√©t√©s dans le nom de l'artefact.  Ainsi, nous mettons essentiellement √† jour tous les ensembles de donn√©es interm√©diaires et les artefacts finaux, et ils ne sont jamais √©cras√©s, toujours r√©serv√©s au stockage, et le stockage est priv√© HDFS et S3, qui voit les artefacts finaux de certains cornichons, mod√®les ou autre chose .  Et tout le code du pipeline r√©side dans le projet de service dans le r√©f√©rentiel auquel il se rapporte. <br><br><img src="https://habrastorage.org/webt/o6/a1/h_/o6a1h_rv7c9-vtggkki_vmbe7iq.jpeg"><br><br>  Il doit √™tre corrig√© d'une mani√®re ou d'une autre.  La pile HashiCorp vient √† la rescousse, nous utilisons Terraform pour d√©clarer l'infrastructure sous forme de code, Vault pour g√©rer les secrets, il y a tous les mots de passe, les apparences dans la base de donn√©es.  Consul est un service de d√©couverte distribu√© par stockage de valeurs cl√©s que vous pouvez utiliser pour configurer.  Et Consul v√©rifie √©galement la sant√© de vos n≈ìuds et de vos services, v√©rifiant leur disponibilit√©. <br><br>  Et - Nomade.  c'est un syst√®me d'orchestration, qui d√©livre vos services et une sorte de travaux par lots. <br><br><img src="https://habrastorage.org/webt/cy/zb/rd/cyzbrd9uibdyssgdczrckszrpwk.jpeg"><br><br>  Comment utilisons-nous cela?  Il y a un pipeline Luigi, nous allons l'emballer dans le conteneur Docker, d√©poser la batte ou le travail par lots p√©riodique dans Nomad.  Travail par lots - c'est quelque chose de termin√©, termin√©, et si tout r√©ussit - tout va bien, nous pouvons le red√©marrer manuellement.  Mais si quelque chose a mal tourn√©, Nomad le r√©essaye jusqu'√† ce qu'il √©puise la tentative, ou il ne se termine pas avec succ√®s. <br><br>  Travail par lots p√©riodique - c'est exactement la m√™me chose, ne fonctionne que sur un calendrier. <br><br>  Il y a un probl√®me.  Lorsque nous d√©ployons un conteneur sur n'importe quel syst√®me d'orchestration, nous devons indiquer la quantit√© de m√©moire dont ce conteneur, CPU ou m√©moire a besoin.  Si nous avons un pipeline qui fonctionne pendant trois heures, deux heures de cela consomment 10 Go de RAM, 1 heure - 70 Go.  Si nous d√©passons la limite que nous lui avons donn√©e, le d√©mon Docker arrive et tue Dockers et (nrzb.) [02:26:13] Nous ne voulons pas intercepter constamment de la m√©moire, nous devons donc sp√©cifier tous les 70 Go, la charge de m√©moire maximale.  Mais voici le probl√®me, tous les 70 Go pour trois heures seront allou√©s et inaccessibles √† tout autre travail. <br><br>  Par cons√©quent, nous sommes all√©s dans l'autre sens.  L'ensemble de notre pipeline Luigi ne d√©marre aucune sorte de logique m√©tier, il lance simplement un ensemble de d√©s dans Nomad, le travail dit param√©tr√©.  En fait, il s'agit d'un analogue des fonctions serveur (NRZB.) [02:26:39], AVS Lambda, qui sait.  Lorsque nous cr√©ons une biblioth√®que, nous d√©ployons via CI tout notre code sous forme de travaux param√©tr√©s, c'est-√†-dire un conteneur avec certains param√®tres.  Supposons, Lite JBM Classifier, qu'il ait un param√®tre pour le chemin d'acc√®s aux donn√©es d'entr√©e pour la formation, les hyperparam√®tres des mod√®les et le chemin d'acc√®s pour les artefacts de sortie.  Tout cela est enregistr√© dans Nomad, puis √† partir du pipeline Luigi, nous pouvons extraire tous ces travaux Nomad via l'API, tandis que Luigi s'assure de ne pas ex√©cuter la m√™me t√¢che plusieurs fois. <br><br>  Supposons que nous ayons le m√™me traitement de texte.  Il existe 10 mod√®les conditionnels et nous ne voulons pas red√©marrer le traitement de texte √† chaque fois.  Il ne d√©marrera qu'une seule fois, et en m√™me temps, il y aura un r√©sultat fini √† chaque r√©utilisation.  Et en m√™me temps, tout cela fonctionne de mani√®re distribu√©e, nous pouvons ex√©cuter une recherche de grille g√©ante sur un grand cluster, avoir seulement le temps de vider le fer. <br><br><img src="https://habrastorage.org/webt/ig/bg/fv/igbgfv9ciptp0thzljej2u1pa-a.jpeg"><br><br>  Nous avons un artefact, nous devons en quelque sorte organiser cela sous la forme d'un service.  Les services exposent une API HTTP ou communiquent via des files d'attente.  Dans cet exemple, il s'agit de l'API HTTP, l'exemple le plus simple.  Dans le m√™me temps, la communication avec le service, ou notre service communique avec d'autres services via l'API HTTP JSON, valide le sch√©ma JSON.  Le service lui-m√™me d√©crit toujours un objet JSON dans la documentation de son API et le sch√©ma de cet objet.  Mais tous les champs de l'objet JSON ne sont pas toujours n√©cessaires, donc les contrats ax√©s sur le consommateur sont valid√©s, ce sch√©ma est valid√©, la communication a lieu via un disjoncteur de mod√®le pour emp√™cher notre syst√®me distribu√© de tomber en panne en raison de d√©faillances en cascade. <br><br>  Dans le m√™me temps, le service doit d√©finir un contr√¥le d'int√©grit√© HTTP afin que Consul puisse venir v√©rifier la disponibilit√© de ce service.  Dans le m√™me temps, Nomad peut faire en sorte qu'il y ait un service pour trois v√©rifications de bonjour d'affil√©e, il peut red√©marrer le service pour l'aider.  Le service √©crit tous ses journaux au format JSON.  Nous utilisons le pilote de journalisation JSON et la pile Elastics, √† chaque point FileBit prend simplement tous les journaux JSON, les jette dans le cache de journaux, √† partir de l√†, ils arrivent √† Elastic, nous pouvons analyser KBan.  Dans le m√™me temps, nous n'utilisons pas de journaux pour la collecte de m√©triques et la cr√©ation de tableaux de bord, il est inefficace, nous utilisons le syst√®me d'entra√Ænement Prometheus pour cela, nous avons un processus pour cr√©er des mod√®les pour chaque service de tableau de bord et nous pouvons analyser les m√©triques techniques produites par le service. <br><br>  De plus, en cas de probl√®me, des alertes arrivent, mais dans la plupart des cas, cela ne suffit pas.  La sentinelle vient √† notre aide, c'est une chose pour l'analyse des incidents.  En fait, nous capturons tous les journaux de niveau d'erreur par le gestionnaire Sentry et les poussons dans Sentry.  Et puis il y a une trace d√©taill√©e, il y a toutes les informations sur l'environnement dans lequel le service √©tait, quelle version, quelles fonctions √©taient appel√©es par quels arguments et quelles variables dans cette √©tendue √©taient avec quelles valeurs.  Toutes les configurations, tout cela est visible, et cela aide beaucoup √† comprendre rapidement ce qui s'est pass√© et √† corriger l'erreur. <br><br><img src="https://habrastorage.org/webt/yx/oj/rl/yxojrltjutx_s1_tll0fa9xajrc.jpeg"><br><br>  Par cons√©quent, le service ressemble √† ceci.  Projet GitLab s√©par√©, code de pipeline, code de test, code de service lui-m√™me, un tas de configurations diff√©rentes, Nomad, configurations CI, documentation API, crochets de validation et plus encore. <br><br><img src="https://habrastorage.org/webt/_b/8q/f_/_b8qf_bf1ninu3_2gafa6qmm9by.jpeg"><br><br>  Lorsque nous faisons une version, nous effectuons le CI comme suit: construire un conteneur, ex√©cuter des tests, d√©poser un cluster sur une mise en sc√®ne, ex√©cuter un contrat de test pour notre service l√†-bas, effectuer des tests de r√©sistance pour nous assurer que notre pr√©diction n'est pas trop lente et garder la charge que nous pensons .  Si tout va bien, nous d√©ploierons ce service en production.  Et il y a deux fa√ßons: nous pouvons d√©ployer le pipeline, si le travail par lots p√©riodique, il fonctionne quelque part en arri√®re-plan et produit des artefacts, ou avec les stylos, nous d√©clenchons une sorte de pipeline, il forme un mod√®le, apr√®s cela, nous comprenons que tout va bien et d√©ployer le service. <br><br><img src="https://habrastorage.org/webt/ee/uo/uv/eeuouvuw2tpqohzhcwtz1x-qjje.jpeg"><br><br>  Que se passe-t-il d'autre dans ce cas?  J'ai dit que dans le d√©veloppement des brunchs de fonctionnalit√©s, il existe un paradigme tel que les basculements de fonctionnalit√©s.  Dans le bon sens, vous devez couvrir les fonctionnalit√©s avec quelques bascules, juste pour r√©duire une fonctionnalit√© au combat si quelque chose ne va pas.  Nous pouvons ensuite collecter toutes les fonctionnalit√©s dans les trains de versions, et m√™me si les fonctionnalit√©s ne sont pas termin√©es, nous pouvons les d√©ployer.  Le basculement des fonctionnalit√©s sera d√©sactiv√©.  Puisque nous sommes tous des Data Scientists, nous voulons √©galement faire des tests AV.  Disons que nous avons remplac√© LightGBM par CatBoost.  Nous voulons v√©rifier cela, mais en m√™me temps, le test AV est g√©r√© en r√©f√©rence √† un ID utilisateur.  Le basculement de fonction est li√© √† l'ID utilisateur et passe donc le test AV.  Nous devons v√©rifier ces mesures ici. <br><br>  Tous les services sont d√©ploy√©s sur Nomad.  Nous avons deux clusters de production Nomad - un pour le travail par lots et un pour les services. <br><br><img src="https://habrastorage.org/webt/xc/ku/mm/xckummfxsskmztnet3fnzklweny.jpeg"><br><br>  Ils poussent tous leurs √©v√©nements commerciaux √† Kafka.  De l√†, nous pouvons les r√©cup√©rer.  C'est essentiellement une architecture d'agneau.  Nous pouvons souscrire √† HDFS avec certains services, effectuer des analyses en temps r√©el et en m√™me temps, nous ratissons tous dans ClickHouse et cr√©ons des tableaux de bord pour analyser tous les √©v√©nements commerciaux de nos services.  Nous pouvons analyser les tests AV, peu importe. <br><br><img src="https://habrastorage.org/webt/e9/_z/g1/e9_zg1a4j-ycqi6c0ghuzmphd0c.jpeg"><br><br>  Et si nous n'avons pas chang√© le code, n'utilisez pas de bascule de fonction.  Nous venons de commencer √† travailler avec des stylos sur un pipeline, il nous a appris un nouveau mod√®le.  Nous avons une nouvelle voie vers cela.  Nous modifions simplement le chemin Nomad vers le mod√®le dans la configuration, faisons une nouvelle version de service, et ici le paradigme de d√©ploiement Canary vient √† notre aide, il est disponible dans Nomad de la bo√Æte. <br><br>  Nous avons la version actuelle du service dans trois cas.  Nous disons que nous voulons trois canaris - trois autres r√©pliques de nouvelles versions sont d√©ploy√©es sans abattre les anciennes.  En cons√©quence, le trafic commence √† se diviser en deux parties.  Une partie du trafic tombe sur de nouvelles versions de services.  Tous les services poussent tous leurs √©v√©nements professionnels √† Kafka.  En cons√©quence, nous pouvons analyser les m√©triques en temps r√©el. <br><br>  Si tout va bien, on peut dire que tout va bien.  D√©ployez, Nomad passera, d√©sactivez doucement toutes les anciennes versions et mettez √† l'√©chelle les nouvelles. <br><br>  Ce mod√®le est mauvais en ce sens que si nous devons lier le routage de version √† une entit√©, l'√©l√©ment utilisateur.  Un tel sch√©ma ne fonctionne pas, car le trafic est √©quilibr√© via un round-robin.  Par cons√©quent, nous avons suivi le chemin suivant et sci√© le service en deux parties. <br><br><img src="https://habrastorage.org/webt/mr/s4/hf/mrs4hf-bhaqlntomrhwjah_0qms.jpeg"><br><br>  Il s'agit de la couche Gateway et de la couche Workers.  Le client communique via HTTP avec la couche passerelle, toute la logique de s√©lection de version et d'√©quilibrage du trafic se trouve dans la passerelle.  Dans le m√™me temps, toutes les t√¢ches li√©es aux E / S qui sont n√©cessaires pour terminer le pr√©dicat se trouvent √©galement dans la passerelle.  Supposons que nous obtenions un ID utilisateur dans le pr√©dicat de la demande, que nous devons enrichir avec quelques informations.  Nous devons extraire d'autres microservices et r√©cup√©rer toutes les informations, fonctionnalit√©s ou bases.  En cons√©quence, tout cela se produit dans la passerelle.  Il communique avec des travailleurs qui ne sont que dans le mod√®le et fait une chose - une pr√©diction.  Entr√©e et sortie. <br><br>  Mais depuis que nous avons divis√© notre service en deux parties, des frais g√©n√©raux sont apparus en raison d'un appel r√©seau distant.  Comment le niveler?  Le framework JRPC de Google, le RPC de Google, qui fonctionne sur HTTP2 vient √† la rescousse.  Vous pouvez utiliser le multiplexage et la compression.  JPRC utilise protobuff.  Il s'agit d'un protocole binaire fortement typ√© qui a une s√©rialisation et une d√©s√©rialisation rapides. <br><br>  En cons√©quence, nous avons √©galement la possibilit√© de faire √©voluer ind√©pendamment Gateway et Worker.  Disons que nous ne pouvons pas conserver une certaine quantit√© de connexions HTTP ouvertes.  D'accord, la mise √† l'√©chelle de la passerelle.  Notre pr√©diction est trop lente, nous n'avons pas le temps de garder la charge - ok, nous faisons √©voluer les travailleurs.  Cette approche convient tr√®s bien aux bandits multi-arm√©s.  Dans Gateway, puisque toute la logique d'√©quilibrage du trafic est impl√©ment√©e, il peut acc√©der √† des microservices externes et prendre toutes les statistiques pour chaque version, ainsi que prendre des d√©cisions sur la fa√ßon d'√©quilibrer le trafic.  Disons en utilisant l'√©chantillonnage de Thompson. <br><br><img src="https://habrastorage.org/webt/wh/nf/3e/whnf3envxyd5biwjhjftw4yjlsu.jpeg"><br><br>  D'accord, les mod√®les ont √©t√© form√©s d'une mani√®re ou d'une autre, nous les avons enregistr√©s dans la configuration Nomade.  Mais que se passe-t-il s'il existe un mod√®le de recommandations qui a d√©j√† le temps de devenir obsol√®te lors de la formation et que nous devons constamment les recycler?  Tout se fait de la m√™me mani√®re: gr√¢ce √† des travaux par lots p√©riodiques, un artefact est produit, disons toutes les trois heures.  Dans le m√™me temps, √† la fin de ses travaux, le pipeline d√©finit le chemin du nouveau mod√®le dans Consul.  Il s'agit du stockage de valeurs cl√©s, utilis√© pour la configuration.  Nomad peut configurer des configurations.  Soit une variable d'environnement bas√©e sur les valeurs du consul de stockage des valeurs cl√©s.  Il surveille les changements et, d√®s qu'un nouveau chemin appara√Æt, d√©cide que deux chemins peuvent √™tre emprunt√©s.  Il t√©l√©charge l'artefact lui-m√™me via un nouveau lien, place le conteneur de services dans Docker √† l'aide du volume et le recharge - et fait tout pour qu'il n'y ait pas de temps d'arr√™t, c'est-√†-dire lentement, individuellement.  Ou il rend une nouvelle configuration et lui rapporte le service.  Ou le service lui-m√™me le d√©tecte - et √† l'int√©rieur de lui-m√™me peut, ind√©pendamment, mettre √† jour en direct son modelka.  C'est tout, merci. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428700/">https://habr.com/ru/post/fr428700/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428688/index.html">Configuration de l'environnement de travail dans Docker pour l'application yii-framework</a></li>
<li><a href="../fr428690/index.html">Comment enseigner √† votre petite amie comment programmer si vous n'√™tes pas professeur, mais elle croit en vous</a></li>
<li><a href="../fr428694/index.html">L'histoire d'un jeu unique ou d'une strat√©gie 4x qui a commenc√© il y a 20 ans et qui est toujours vivante</a></li>
<li><a href="../fr428696/index.html">Commentaires sur Telegram Channel</a></li>
<li><a href="../fr428698/index.html">The Insaisissable Space Pirate: cachez-vous dans le frigo des flics, battez la guerre des dro√Ødes et crachez dans les yeux de Sauron</a></li>
<li><a href="../fr428702/index.html">Des √©chos de magie au service des sciences exactes</a></li>
<li><a href="../fr428704/index.html">Entra√Ænements de prologue</a></li>
<li><a href="../fr428706/index.html">Crypt Bugs</a></li>
<li><a href="../fr428708/index.html">Natation facile avec Kubernetes (bande dessin√©e)</a></li>
<li><a href="../fr428710/index.html">Utilisation et restauration des batteries au plomb mon exp√©rience</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
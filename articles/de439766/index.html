<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍🤝‍👩🏼 🌇 😛 Erhöhen Sie es! Moderne Auflösung steigt 🙏🏻 💰 🤸🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich habe bereits aufgehört zu schaudern und mich zu fragen, wann das Telefon klingelt und eine harte, selbstbewusste Stimme im Empfänger zu hören ist:...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erhöhen Sie es! Moderne Auflösung steigt</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439766/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b88/1db/675/b881db675f3ef17c06a45cc67a8c1cb2.png"></div><br>  Ich habe bereits aufgehört zu schaudern und mich zu fragen, wann das Telefon klingelt und eine harte, selbstbewusste Stimme im Empfänger zu hören ist: "Sind Sie besorgt über den Kapitän so und so (Major so und so), können Sie ein paar Fragen beantworten?"  Warum nicht mit deiner eigenen Polizei sprechen ... <br><br>  Die Fragen sind immer gleich.  "Wir haben ein Video mit dem Verdächtigen, bitte helfen Sie, das Gesicht wiederherzustellen" ... "Helfen Sie, die Anzahl vom DVR zu erhöhen" ... "Es gibt hier keine menschlichen Hände, bitte helfen Sie zu erhöhen" ... und so weiter in der gleichen Richtung. <br><br>  Um zu verdeutlichen, worum es geht, hier ein reales Beispiel für ein stark komprimiertes Video, das gesendet wird, um ein unscharfes Gesicht wiederherzustellen (dessen Größe etwa 8 Pixel entspricht): <br><br><div style="text-align:center;"><img width="400" src="https://habrastorage.org/webt/k-/bw/5h/k-bw5hsws_7bijnrykr3vrvhk_i.png"></div><br>  Und okay, nur die russischen Onkel von Stepa würden stören, schreiben Western Pinkertones. <br><a name="habracut"></a>  Hier ist zum Beispiel ein Brief der englischen Polizei &lt;***** @ *****. Fsnet.co.uk&gt;: <br><blockquote>  Ich habe Ihre Filter einige Zeit privat verwendet, um meine schlechten Videos von Familienferien zu retten, aber ich möchte die kommerziellen Filter für meine Arbeit verwenden.  Ich bin derzeit Polizist bei einer kleinen Polizei und wir bekommen eine Menge CCTV-Videos, die manchmal von sehr schlechter Qualität sind und ich kann sehen, wie Ihre Filter einen echten Unterschied machen würden.  Kannst du mir die Kosten sagen und ob ich sie benutzen könnte? <br><br>  Danke <br><br><div class="spoiler">  <b class="spoiler_title">Übersetzung</b> <div class="spoiler_text">  Ich habe Ihre Filter bereits für persönliche Zwecke verwendet, um meine schlechten Videos aus dem Familienurlaub zu speichern.  Aber ich möchte in meiner Arbeit kommerzielle Filter verwenden.  Ich bin derzeit ein Polizist in einer kleinen Einheit.  Wir erhalten eine große Anzahl von Videos von CCTV-Kameras, manchmal von sehr schlechter Qualität, und Ihre Filter werden wirklich helfen.  Können Sie mir ihre Kosten mitteilen und kann ich sie verwenden? <br><br>  Vielen Dank </div></div></blockquote>  Oder ein australischer Polizist schreibt: <br><blockquote>  Hallo <br>  Ich arbeite für die Victoria Police in Australien in der Abteilung Video- und Audio-Forensik.  Gelegentlich erhalten wir Videos von Hand- oder Fahrzeugkameras.  Oft erfassen diese Interlaced-Aufnahmen von sich schnell bewegenden Ereignissen.  Insbesondere ist das Filmmaterial, das normalerweise das "Versprechen" hat, das Filmmaterial von Fahrzeugnummernschildern.  Wir stellen häufig fest, dass sich das betreffende Fahrzeug zwischen dem ersten und dem letzten erfassten Feld erheblich bewegt hat.  Infolgedessen versuchen wir, den gesamten Rahmen aus den beiden Feldern zu rekonstruieren, wobei der zweite übersetzt, manchmal gedreht wird und gelegentlich auch die Größe unterschiedlich ist (wenn das Fahrzeug weg oder in Richtung Kamera fährt). Diese beiden Felder heiraten , vorzugsweise bis zur Subpixel-Genauigkeit, und die Rekonstruktion des Rahmens, der das Nummernschild enthält, kann schwierig sein. <br>  Nach dem, was ich von Ihnen beim Deinterlacing von Filmmaterial gesehen habe, kann es sein, dass Ihr Filter einige, wenn nicht alle Aufgaben ausführen kann, die wir benötigen.  Um ehrlich zu sein, da unser Budget eher klein ist, ist es unwahrscheinlich, dass wir uns eine kommerzielle Lizenz leisten können.  Wir verkaufen das Produkt natürlich nicht, wir verwenden es als Beweismittel in Polizeifällen.  Auf jeden Fall dachte ich, ich würde eine E-Mail schreiben und trotzdem fragen.  Wie viel würde eine Lizenz kosten?  Ist es möglich, das Produkt anhand von Filmmaterial zu testen, um festzustellen, ob es angemessen ist?  Tut es etwas von dem, was wir brauchen?  Wurde der Algorithmus zuletzt veröffentlicht?  Die Arbeit mit unbekannten Algorithmen ist für ein Gericht eine gefährliche Praxis.  Wenn die Beweise dazu führen, dass ein Mann 20 Jahre lang ins Gefängnis geht, ist es eine gute Praxis zu wissen, warum! <br><br>  Alle Informationen, die Sie anbieten können, wären willkommen. <br><br>  Grüße, <br>  Fallbearbeiter <br>  Audiovisuelle Einheit <br>  Victoria Police Forensic Services Abteilung <br><br><div class="spoiler">  <b class="spoiler_title">Übersetzung</b> <div class="spoiler_text">  Hallo, <br>  Ich arbeite für die Victoria Police in Australien in der forensischen Video- und Audioabteilung.  Von Zeit zu Zeit erhalten wir Videos von Handkameras und DVRs.  Oft handelt es sich bei diesen Videos um Interlaced-Aufnahmen von sich schnell bewegenden Objekten.  Das wichtigste Material sind insbesondere Kfz-Kennzeichen.  Wir stellen häufig fest, dass sich das betreffende Fahrzeug stark zwischen dem ersten und dem letzten erfassten Feld bewegt.  Infolgedessen versuchen wir, ein ganzes Bild aus zwei Feldern wiederherzustellen, wobei das zweite verschoben, manchmal gedreht und manchmal unterschiedlich groß ist (wenn das Auto zur oder von der Kamera fährt).  Das Kombinieren dieser beiden Felder, vorzugsweise mit einer Genauigkeit von einem halben Pixel, und das Wiederherstellen eines gesamten Rahmens, der ein Nummernschild enthält, kann schwierig sein. <br><br>  Ich sehe, wie Sie Deinterlacing auf Frames anwenden, und vielleicht können Ihre Filter etwas bewirken, wenn nicht alles, was wir brauchen.  Ehrlich gesagt können wir uns möglicherweise keine kommerzielle Lizenz leisten, da unser Budget recht klein ist.  Wir verkaufen das Produkt natürlich nicht, wir verwenden es als Beweismittel in Polizeifällen.  Auf jeden Fall dachte ich, ich würde einen Brief schreiben und trotzdem fragen.  Wie viel kostet die Lizenz?  Ist es möglich, das Produkt am Material zu testen, um festzustellen, ob es geeignet ist?  Macht er einen Teil dessen, was wir brauchen?  Wurde der Algorithmus schließlich veröffentlicht? Die Arbeit mit unbekannten Algorithmen ist eine gefährliche Praxis vor Gericht.  Wenn die Beweise dazu führen, dass eine Person 20 Jahre lang ins Gefängnis muss, ist es hilfreich zu wissen, warum. <br><br>  Wir sind dankbar für alle Informationen, die Sie uns zur Verfügung stellen können. <br><br>  Mit freundlichen Grüßen, <br>  Ermittler <br>  Audio- und Videoabteilung <br>  Forensische Abteilung der Polizei von Victoria </div></div></blockquote>  Beachten Sie, dass der Brief sehr nachdenklich ist, eine Person besorgt über den veröffentlichten Algorithmus und über die Verantwortung für eine fehlerhafte Wiederherstellung ist. <br><br>  Manchmal geben sie nur im Korrespondenzprozess zu, dass sie von der Polizei sind.  Zum Beispiel möchten Italiens Carabinieri helfen: <br><blockquote>  Dr.  Vatolin <br>  Danke für die Antwort. <br>  Die Antwort ist auch für die Polizei wert (Carabinieri-Untersuchung <br>  wissenschaftlich für PARMA ITALIEN)? <br>  Mit welcher Software sie Ihre Algorithmen verknüpft haben. <br>  Wir wären viel. <br><br><div class="spoiler">  <b class="spoiler_title">Übersetzung</b> <div class="spoiler_text">  Dr.  Batolin <br>  Danke für die Antwort. <br>  Ist dies für die Polizei geeignet (Carabinieri Investigation Unit für PARMA ITALIEN)? <br>  Interessieren sie sich für die Software, die Ihre Algorithmen verwenden? <br>  Wir werden dankbar sein. </div></div></blockquote>  Und natürlich viele Appelle gewöhnlicher Menschen ... <br><br><h2>  Erhöhen Sie es!  Was, tut Ihnen leid, wenn Sie den richtigen Knopf drücken? </h2><br>  Es ist klar, dass dieser gesamte Anrufstrom nicht von Grund auf neu angezeigt wird. <br><br>  "Schuld" vor allem Filme und TV-Shows. <br><br>  Zum Beispiel wird hier in 3 Sekunden der Frame des komprimierten Videos um das 50-fache vergrößert und durch die Reflexion in der Brille sehen sie Beweise: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/I_8ZH1Ggjk0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Und es gibt viele solcher Momente in modernen Filmen und Serien.  In diesem Video haben wir beispielsweise solche Episoden aus einer Reihe von Fernsehsendungen absolut episch gesammelt. Nehmen Sie sich keine zwei Minuten Zeit, um sie anzusehen: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/LhF_56SxrGk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Und wenn Sie dies in jedem Film sehen, wird dem letzten Igel klar, dass alles, was Sie brauchen, ein kompetentes Computergenie ist, eine Kombination aus modernen Algorithmen, und es bleibt nur, um sofort <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">„STOP!“</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">und "Verbessere es!"</a>  .  Und voila!  Ein Wunder wird geschehen! <br><br>  Die Drehbuchautoren hören jedoch nicht bei dieser bereits abgedroschenen Rezeption auf, und ihre ungezügelte Vorstellungskraft geht noch weiter.  Hier ist ein sehr monströses Beispiel.  Galante Detektive, die sich in der Pupille des Opfers widerspiegeln sollten, erhielten ein Foto des Täters.  In der Tat war das Spiegelbild in der Brille bereits da.  Das ist alltäglich.  Lass uns weitermachen!  Es ist nur so, dass sich die Auflösung der CCTV-Kamera im Treppenhaus als ziemlich zufällig herausstellte, wie beim Hubble-Teleskop: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3uoM5kfZIQ0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Im "Propheten" (00:38:07): <div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e82/109/09e/e8210909e53e8966a6484d35b096bf0f.gif"></div><br>  In „Avatar“ (1: 41: 04–1: 41: 05) ist der Schärfungsalgorithmus im Vergleich zu anderen Filmen übrigens etwas ungewöhnlich: Er schärft zuerst an bestimmten Stellen und zieht nach Sekundenbruchteilen den Rest des Bildes auf, t .e.  zuerst die linke Mundhälfte und dann die rechte: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fff/54d/603/fff54d603344fb7b80c8a5c93aaca7ab.gif"></div><br>  In sehr beliebten Filmen, die von Hunderten von Millionen angesehen werden, erfolgt das Schärfen des Bildes im Allgemeinen mit einem Klick.  <b>Alle Leute (in den Filmen) machen es!</b>  Warum können Sie, so clevere Experten, das nicht? <br><br><hr>  "Ich weiß, das ist einfach!"  Und mir wurde definitiv gesagt, dass Sie dies tun!  Sind Sie zu faul, um diesen Knopf zu drücken? <br><br>  <i>// Oh je ... Verdammte Drehbuchautoren mit ihrer wilden Fantasie ...</i> <br><br>  - Ich verstehe, dass Sie beschäftigt sind, aber es geht um Ihre Hilfe für den Staat bei der Aufklärung eines wichtigen Verbrechens! <br><br>  <i>// Wir verstehen.</i> <br><br>  - Vielleicht geht es ums Geld?  Wie viel müssen Sie bezahlen? <br><br>  <i>// Nun, wie man kurz erklärt, dass wir kein Geld brauchen ... Und dann wieder und dann wieder ...</i> <hr><br>  Das Zusammentreffen der obigen Zitate mit echten Dialogen ist völlig zufällig. Insbesondere wird dieser Text jedoch so geschrieben, dass eine Person ihn zuerst sorgfältig liest und erst dann zurückruft. <br><blockquote>  <b>Fazit:</b> Aufgrund der Tatsache, dass die Szene mit der Vergrößerung von Bildern von CCTV-Kameras mit einem Klick zu einem Stempel des modernen Kinos geworden ist, sind viele Menschen aufrichtig davon überzeugt, dass es sehr einfach ist, ein Fragment eines Rahmens einer billigen Kamera oder eines billigen Videorecorders zu vergrößern.  Die Hauptsache ist, wie man fragt (nun, oder befiehlt, das ist wie viel Glück). </blockquote><h2>  Woher wachsen die Beine? </h2><br>  Es ist klar, dass dieser gesamte Anrufstrom nicht von Grund auf neu erstellt wird.  Wir beschäftigen uns seit ungefähr 20 Jahren wirklich mit der Verbesserung von Videos, einschließlich verschiedener Arten der Videowiederherstellung (und es gibt übrigens verschiedene Arten davon), und unsere Beispiele werden in diesem Abschnitt niedriger sein. <br><br>  Eine „intelligente“ Erhöhung der Auflösung in wissenschaftlichen Artikeln wird normalerweise als Super Resolution (kurz SR) bezeichnet.  Google Scholar auf Anfrage <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Super Resolution</a> findet 2,9 Millionen Artikel, d. H.  Das Thema war sozusagen ziemlich gut ausgegraben, und eine große Anzahl von Menschen beschäftigte sich damit.  Wenn Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem Link</a> folgen, gibt es ein Meer von Ergebnissen, eines schöner als das andere.  Es lohnt sich jedoch, tiefer zu graben, das Bild wird wie üblich nicht so pastoral.  Das SR-Thema hat zwei Richtungen: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Video Super Resolution</a> (0,4 Millionen Artikel) - die tatsächliche Wiederherstellung unter Verwendung vorheriger (und manchmal nachfolgender) Frames, <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bild-Superauflösung</a> (2,2 Millionen Artikel) - „intelligente“ Erhöhung der Auflösung mit nur einem Frame.  Da im Fall eines Bildes Informationen darüber aufgenommen werden sollen, was sich an dieser Stelle eigentlich nirgends befand, vervollständigen die Algorithmen das Bild auf die eine oder andere Weise (oder relativ gesehen „vervollständigen“) - was könnte dort sein.  Das Hauptkriterium dafür ist, dass das Ergebnis so natürlich wie möglich oder so nah wie möglich am Original aussehen sollte.  Und es ist klar, dass solche Methoden nicht geeignet sind, um das wiederherzustellen, was „wirklich“ war, obwohl das Bild vergrößert wird, damit es beispielsweise beim Drucken besser aussieht (wenn Sie ein eindeutiges Foto haben, aber keine Version in höherer Auflösung vorhanden ist) ) Solche Methoden sind sehr gut möglich. <br></li></ul><br>  Wie Sie sehen können, sind 0,4 Millionen gegenüber 2,2 Millionen - das heißt, fünfmal weniger Menschen sind an der tatsächlichen Genesung beteiligt.  Glücklicherweise ist das Thema „Mach es größer, nur schön“ sehr gefragt, auch in der Branche (der berüchtigte digitale Zoom von Smartphones und digitalen Seifenschalen).  Wenn Sie noch tiefer eintauchen, wird schnell klar, dass eine erhebliche Anzahl von Artikeln zur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Video-Superauflösung</a> auch eine Erhöhung der Videoauflösung ohne Wiederherstellung darstellt, da die Wiederherstellung schwierig ist.  Infolgedessen können wir sagen, dass diejenigen, die „schön“ sind, etwa zehnmal mehr sind als diejenigen, die wirklich versuchen, sie wiederherzustellen.  Übrigens eine ganz normale Lebenssituation. <br><br>  Wir gehen noch tiefer.  Sehr oft sind die Ergebnisse des Algorithmus sehr gut, aber er benötigt beispielsweise 20 Frames vorwärts und 20 Frames zurück, und die Verarbeitungsgeschwindigkeit eines Frames beträgt bei Verwendung der fortschrittlichsten GPU etwa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">15 Minuten</a> .  Das heißt,  Für 1 Minute benötigt das Video 450 Stunden (fast 19 Tage).  Ups-ss ... Stimmen Sie zu, dies ist überhaupt nicht wie der Moment "Zoom it!"  aus den Filmen.  Regelmäßig gibt es Algorithmen, die mehrere Tage pro Frame arbeiten.  Bei Artikeln ist ein besseres Ergebnis in der Regel wichtiger als die Arbeitszeit, da die Beschleunigung eine separate schwierige Aufgabe ist und es einfacher ist, einen großen Elefanten in Teilen zu essen.  Das ist der Unterschied zwischen Leben und Kino ... <br><br>  Die Anfrage nach Algorithmen, die auf Video mit einer angemessenen Geschwindigkeit ausgeführt werden, führte zu einer separaten Richtung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schnellen Video-Superauflösung</a> - 0,18 Millionen Artikel, einschließlich "langsamer" Artikel, die mit "schnellen" verglichen werden, d. H.  Die tatsächliche Anzahl der Artikel zu solchen Methoden ist überbewertet.  Es ist zu beachten, dass unter den "schnellen" Ansätzen der Prozentsatz der Spekulation, d.h.  ohne echte Erholung höher.  Dementsprechend ist der Prozentsatz der ehrlichen Genesung geringer. <br><br>  Sie sehen, das Bild wird klar.  Aber das ist natürlich weit von allem entfernt. <br><br>  Welche anderen Punkte beeinflussen das Erreichen eines guten Ergebnisses erheblich? <br><br>  Erstens ist Lärm sehr einflussreich.  Unten sehen Sie ein Beispiel für eine zweifache Wiederherstellung der Auflösung in einem sehr verrauschten Video: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/461/c9c/bd5/461c9cbd5b7b8d0a7b50f75471ebe941.png"></div><br>  <i>Quelle: Materialien des Autors</i> <br><br>  Das Hauptproblem in diesem Fragment ist nicht einmal die üblichen Geräusche, sondern das farbige <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Moiré</a> auf dem Hemd, das schwer zu verarbeiten ist.  Einige könnten sagen, dass große Geräusche heute kein Problem sind.  Es ist nicht so.  Sehen Sie sich die Daten von Auto-DVRs und CCTV-Kameras im Dunkeln an (genau dann, wenn sie stärker nachgefragt werden). <br><br>  Moiré kann jedoch auch bei relativ „sauberen“ Rauschvideos auftreten, z. B. in der folgenden Stadt (die folgenden Beispiele <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">basieren auf unserer Arbeit</a> ): <br><br> <a href=""><img src="https://habrastorage.org/webt/0a/-x/0z/0a-x0zj47mmkgsa79aiojqtrfco.gif"></a> <br>  <i>Quelle: Materialien des Autors</i> <br><br>  Zweitens ist für eine optimale Wiederherstellung eine nahezu ideale Vorhersage der Bewegung zwischen Bildern erforderlich.  Warum dies schwierig ist, ist ein separates großes Thema, aber dies erklärt, warum Szenen mit einer Panoramakamerabewegung oft sehr gut wiederhergestellt werden und Szenen mit einer relativ chaotischen Bewegung äußerst schwer wiederherzustellen sind, aber mit ihnen können Sie in einigen Situationen ein recht gutes Ergebnis erzielen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4bd/7bb/3da/4bd7bb3da22d2904311d2da762331b5e.gif"></div>  <i>Quelle: Materialien des Autors</i> <br><br>  Und zum Schluss noch ein Beispiel für die Wiederherstellung von Text: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a98/ad0/a00/a98ad0a0062a2fa1a7b4c602d26e2edd.png"></div><br>  <i>Quelle: Materialien des Autors</i> <br><br>  Hier bewegt sich der Hintergrund ziemlich reibungslos und der Algorithmus kann "durchstreifen": <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a5e/1a4/542/a5e1a4542ea2b0a441c6160e4c9eaba0.png"></div><br><br>  Insbesondere wenn wir eine sehr kleine Inschrift mit der rechten Hand vergleichen, einschließlich der Vergrößerung mit klassischer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bikubischer Interpolation</a> , ist der Unterschied sehr deutlich sichtbar: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9d4/d00/dfc/9d4d00dfc6a3364dfae37e8637708993.png"></div><br>  Es ist zu sehen, dass es für die bikubische Interpolation fast unmöglich ist, das Jahr zu lesen. Für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lanczos4</a> , das von jenen geliebt wird, die die Videoauflösung semiprofessionell auf Schärfe ändern, sind die Kanten natürlich klarer, aber es ist immer noch unmöglich, das Jahr zu lesen.  Wir kommentieren den kommerziellen Topas nicht, aber wir lesen die Inschrift deutlich und Sie können sehen, dass dies höchstwahrscheinlich 1809 ist. <br><blockquote>  <b>Schlussfolgerungen:</b> <br><br><ul><li>  Tausende von Forschern auf der Welt sind daran beteiligt, die Auflösung zu erhöhen, und Millionen von Artikeln wurden zu diesem Thema veröffentlicht.  Aus diesem Grund verfügt jedes Smartphone über einen „Digitalzoom“, der in der Regel objektiv besser ist als die Algorithmen zur Erhöhung herkömmlicher Programme, und jeder FullHD-Fernseher kann SD-Videos anzeigen, häufig auch ohne charakteristische Artefakte der Auflösungsänderung. <br></li><li>  Das Wiederherstellen eines realen Bildes aus einem Video macht weniger als 10% der an Super Resolution Beteiligten aus. Darüber hinaus sind die meisten Wiederherstellungsalgorithmen extrem langsam (bis zu mehreren Tagen Berechnungen pro Frame). <br></li><li>  In den meisten Fällen soll die Wiederherstellung sicherstellen, dass hohe Frequenzen im Video mehr oder weniger erhalten bleiben und daher bei Videos mit erheblichen Komprimierungsartefakten nicht funktionieren.  Und da in den Einstellungen von CCTV-Kameras das Komprimierungsverhältnis häufig aufgrund des Wunsches gewählt wird, mehr Stunden zu sparen (dh das Video wird stärker komprimiert und die hohen Frequenzen werden "getötet"), wird es fast unmöglich, ein solches Video wiederherzustellen. <br></li></ul></blockquote><br><h2>  Wie SR in der Branche aussieht </h2><br>  Fairerweise stellen wir fest, dass heute alle (oder zumindest gekauften) Auflösungsalgorithmen für alle TV-Hersteller (Sie müssen HD-Bilder aus SD-Bildern im laufenden Betrieb erstellen), für alle Smartphone-Hersteller (was in der Werbung als „digitaler Zoom“ bezeichnet wird) usw. verfügbar sind. .d.  Wir werden über die Ergebnisse von Google sprechen (und nicht nur).  Erstens, weil Google sehr nett und ohne viel Pathos ist und Marketing die Ergebnisse in seinem Blog beschreibt - und das ist sehr schön.  Zweitens, weil Smartphone-Hersteller (zum Beispiel ein sehr bekanntes koreanisches Unternehmen) nicht davor zurückschrecken, beispielsweise Photoshop für die Werbung für ihre Technologien zu verwenden (was ist der Unterschied - die Leute schlucken immer noch) - und dies ist unangenehm.  Lassen Sie uns im Allgemeinen über diejenigen sprechen, die ihre Technologie ziemlich ehrlich beschreiben. <br><br>  Bereits <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im Jahr 2016 veröffentlichte Google</a> interessante Ergebnisse des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RAISR-</a> Algorithmus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(Rapid and Accurate Image Super Resolution),</a> der im Pixel 2-Smartphone verwendet wird. Bei den erfolgreichsten Bildern sah das Ergebnis einfach großartig aus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/78c/785/e21/78c785e214d760cb58f8ea2e2d78b70a.png"></div><br>  <i>Quelle: <a href="">Google AI Blog</a></i> <br><br>  Der Algorithmus war eine Reihe von Filtern, die nach der ML-Klassifizierung verwendet wurden, und verglichen mit der bikubischen Interpolation (traditioneller Prügelknabe) war das Ergebnis erfreulich: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/67b/1f3/a53/67b1f3a5335bbced94d53be35ba3881d.png"></div><br>  <i>In der Reihenfolge: ursprüngliche, bikubische Interpolation, RAISR</i> <br><br>  Aber es war Single Frame Interpolation, und bei den „erfolglosen“ Beispielen wie dem folgenden Laub wurde das Bild sehr unangenehm verzerrt - nach der Vergrößerung wurde das Bild merklich „synthetisch“.  Es zeigte genau den Effekt, für den der Digitalzoom moderner Smartphones nicht beliebt ist: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/g0/y7/xw/g0y7xw8cipif-g-cw3yuljfmivg.png"></div><br>  Das Wunder geschah tatsächlich nicht, und Google veröffentlichte ehrlich und sofort ein Gegenbeispiel, d. H.  umriss sofort die Grenzen der Anwendbarkeit ihres Ansatzes und rettete die Menschen vor übermäßigen Erwartungen (typisch für konventionelles Marketing). <br><br>  Weniger als zwei Jahre später wurde jedoch die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fortsetzung der</a> in Google Pixel 3 verwendeten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit veröffentlicht,</a> die die Qualität der Aufnahme erheblich verbessert. Dies ist bereits eine ehrliche Superauflösung mit mehreren Bildern, d. H.  Wiederherstellungsalgorithmus für die Auflösung mehrerer Frames: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/83b/3ff/950/83b3ff950cf9959b2acb3d11a134ef50.gif"></div><br>  <i>Quelle: <a href="">Google AI Blog</a></i> <br><br>  Das obige Bild zeigt einen Vergleich der Ergebnisse von Pixel 2 und Pixel 3, und die Ergebnisse sehen sehr gut aus - das Bild ist wirklich viel klarer geworden und es ist deutlich zu sehen, dass dies nicht „ausdenken“, sondern wirklich Details wiederherstellen.  Darüber hinaus hat ein aufmerksamer professioneller Leser Fragen zu zwei vertikalen Doppelrohren auf der linken Seite.  Die Auflösung hat deutlich zugenommen, während der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aliasing-</a> Schritt (ein Zeichen für echte Auflösung) seltsam nahe kommt.  Was war das? <br><br>  Kurz gesagt, wir werden den Algorithmus analysieren.  Die Kollegen haben die Interpolation des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bayer-Musters geändert</a> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/355/0ba/e72/3550bae72349a1d9d9705e1e8c69cdd3.png"></div><br>  Tatsache ist, dass 2/3 der Informationen in einem realen Bild tatsächlich informationsinterpoliert sind.  Das heißt,  Ihr Bild ist BEREITS unscharf und „unscharf“, aber bei einem echten Rauschpegel ist dies nicht so wichtig.  Übrigens hat die Fähigkeit, komplexere Interpolationsalgorithmen zu verwenden, beliebte Programme mit RAW-Konvertierung von höchster Qualität für Fotos gemacht (der Unterschied zwischen dem in jede Kamera eingebauten einfachen Algorithmus und dem komplexen Algorithmus eines speziellen Programms ist normalerweise beim Vergrößern des Bildes mit dem Auge erkennbar). <br><br>  Kollegen von Google nutzen die Tatsache, dass die überwiegende Mehrheit der Smartphone-Fotos mit den Händen aufgenommen wird, d. H.  Die Kamera zittert leicht: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/864/59b/d05/86459bd058ec0edfdd5f3b1d0c9b287b.gif"></div><br>  <i>Quelle: <a href="">Google AI Blog</a> (Mehrfachbild auf Pixelebene ausgerichtet, um die Verschiebung von Subpixeln anzuzeigen)</i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn Sie ein paar Frames nehmen und die Verschiebung auswerten (und das Eisen, das eine Bewegungsschätzungskarte mit Viertelpixelgenauigkeit erstellen kann, befindet sich in jedem Smartphone mit H.264-Unterstützung), erhalten wir eine Verschiebungskarte. Getreu der obigen Animation ist deutlich zu erkennen, dass das Erstellen einer Verschiebungskarte mit Subpixel-Genauigkeit bei einem realen Rauschpegel eine nicht triviale Aufgabe ist, aber in den letzten 20 Jahren sind in diesem Bereich sehr gute Algorithmen aufgetaucht. Natürlich manchmal, und sie haben es schwer. Im obigen Beispiel blinkt beispielsweise etwas an einem Rahmen oben am Treppengeländer. Und dies ist immer noch eine statische Szene. Es gibt keine sich bewegenden Objekte, die sich manchmal nicht nur bewegen, sondern drehen, ihre Form ändern, sich schnell bewegen und große Öffnungsbereiche hinterlassen (deren Schleife nach der Verarbeitung nicht sichtbar sein sollte). Das folgende Beispiel zeigt deutlichWas passiert mit sich schnell bewegenden Objekten, wenn Sie die spezielle Verarbeitung solcher Fälle deaktivieren (links deaktiviert, rechts aktiviert, wenn Sie klicken, sind Verarbeitungsblöcke deutlich sichtbar):</font></font><br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/2e8/3d1/bb2/2e83d1bb215c546de4eb6d55524f865f.png"></a> <br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle: </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google AI Blog (empfohlen zum Klicken und Anzeigen in hoher Auflösung)</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Harte Beispiele sind Flammen, Wellen, Sonnenlicht auf dem Wasser usw. Im Allgemeinen gibt es selbst bei dem „einfachen“ Problem der Bestimmung der Verschiebung viele nicht triviale Momente, die die Lebensdauer des Algorithmus erheblich verkomplizieren. Jetzt geht es jedoch nicht darum. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interessanterweise können Sie den Sensor auch dann, wenn die Kamera vollständig stationär ist (z. B. auf einem Stativ montiert), durch die Steuerung des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">optischen Stabilisierungsmoduls</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (OIS - Optical Image Stabilization) </font><font style="vertical-align: inherit;">bewegen </font><font style="vertical-align: inherit;">. Als Ergebnis erhalten wir die gewünschten Subpixelverschiebungen. In Pixel 3 ist die OIS-Unterstützung implementiert, und Sie können das Telefon gegen das Glas drücken und mit Interesse beobachten, wie OIS </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">das Bild entlang einer Ellipse bewegt (ungefähr wie dieser Link).</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das heißt, selbst in diesem schwierigen Fall der Befestigung auf einem Stativ kann Super Resolution die Qualität verbessern. </font><font style="vertical-align: inherit;">Der Löwenanteil der Aufnahmen mit Smartphones entfällt jedoch auf Handaufnahmen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Als Ergebnis haben wir zusätzliche Informationen, um ein Foto mit größerer Auflösung zu erstellen:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/11d/67a/0a2/11d67a0a2127af61576cadffbfeba49b.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wie oben erwähnt, ist die direkte Folge von SR eine signifikante Abnahme des Geräuschpegels, in einigen Fällen ist dies sehr auffällig: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3e1/cd0/1b1/3e1cd01b1e996fc11a6309dca47b0e17.png"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle: </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google AI Blog</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Beachten Sie, dass Wiederherstellung auch Wiederherstellung durch die Anzahl der Bits pro Komponente bedeutet.</font></font> Das heißt,<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn das Problem der Erhöhung der Auflösung formal gelöst wird, kann dieselbe Engine unter bestimmten Bedingungen nicht nur Rauschen unterdrücken, sondern auch den Rahmen in HDR verwandeln. Es ist klar, dass HDR heutzutage selten verwendet wird, aber dies ist, wie Sie sehen, ein guter Bonus. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das folgende Beispiel zeigt einen Vergleich von Bildern, die beim Aufnehmen auf Pixel 2 und Pixel 3 nach SR mit vergleichbarer Sensorqualität erhalten wurden. Der Unterschied im Rauschen und der Unterschied in der Klarheit sind deutlich sichtbar:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/74c/17b/e38/74c17be383c81603e91124d9b4fd04c9.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Für diejenigen, die sich die Details ansehen möchten, gibt </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">es ein Album,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in dem Googles Super Resolution (Marketingname Super Res Zoom) in seiner ganzen Pracht im Spektrum der </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bildzoom-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Skala auf einem Smartphone ( </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">FoV-</font></a><font style="vertical-align: inherit;"> Änderung </font><font style="vertical-align: inherit;">) </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">geschätzt werden</font></a><font style="vertical-align: inherit;"> kann </font><font style="vertical-align: inherit;">: </font><font style="vertical-align: inherit;">Wie sie bescheiden schreiben - sie sind der Aufnahmequalität von Smartphones einen Schritt näher gekommen auf die Qualität professioneller Kameras. </font><font style="vertical-align: inherit;">Fairerweise stellen wir fest, dass professionelle Kameras auch nicht stillstehen. Eine andere Sache ist, dass bei kleineren Verkäufen dieselben Technologien für den Benutzer mehr kosten. SR erscheint jedoch bereits in professionellen Kameras. </font><b><font style="vertical-align: inherit;">UPD:</font></b><font style="vertical-align: inherit;"> Als Beispiel (letzter Link ist ein Vergleich):</font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/321/e5e/40d/321e5e40d89b28612139434735c76fe0.png"></a> <br><br><font style="vertical-align: inherit;"></font><br><br><font style="vertical-align: inherit;"></font><br><br> <b><font style="vertical-align: inherit;"></font></b> <br><font style="vertical-align: inherit;"></font><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Testing Sony's New Pixel Shift Feature in the a7R III</a> ,     2     ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>    ,               ), <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">   Olympus E-M5 Mark II</a>  16  40 , <br></li><li>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> Super Resolution   Pentax K-1</a> , <br></li><li>  : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pixel-Shift Shootout: Olympus vs. Pentax vs. Sony vs. Panasonic</a> —    <b>Pentax K-1, Sony a7R III, Olympus OM-D E-M1 Mark II  Panasonic Lumix DC-G9.</b> ,    ,         ,    Pentax K-1. <br></li></ul><br><blockquote> <b>:</b> <br><br><ul><li>  Super Resolution    ,        ,         . <br></li><li>  SR: Image Super Resolution —    ( ),     . <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Die Hauptprämien der Wiederherstellungsalgorithmen sind Rauschunterdrückung, Verfeinerung von Details, „ehrlicheres“ HDR und deutlich sichtbare höhere Bildqualität bei Großbildfernsehern. </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> All diese Pracht wurde durch einen Kardinal (ungefähr 3 Größenordnungen in der Anzahl der Operationen) ermöglicht, der die Komplexität von Fotoverarbeitungsalgorithmen erhöhte, genauer gesagt - ein Videobild. </font></font><br></li></ul></blockquote><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Yandex-Ergebnisse </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Da sie in den Kommentaren noch nachfragen werden, möchte ich ein paar Worte zu Yandex sagen, das letztes Jahr seine Version von Super Resolution veröffentlicht hat: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/02a/ec9/09f/02aec909f0cfd75bf9902a25ee85acc9.png"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://yandex.ru/blog/company/oldfilms</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Und hier einige Beispiele für Cartoons:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d6a/e9e/2cb/d6ae9e2cba814e1c02a4060ccb545280.png"></div><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://yandex.ru/blog/company/soyuzmultfilm</a></i> <br><br>  Was war das?  Yandex wiederholte die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Technologie von Google im Jahr 2016</a> ? <br><br>  Auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der</a> Technologiebeschreibungsseite von Yandex (Marketingname DeepHD) wird nur auf Image Super Resolution verwiesen.  Dies bedeutet, dass es offensichtlich Gegenbeispiele gibt, bei denen der Algorithmus das Bild verdirbt, und sie sind häufiger als bei ehrlichen Wiederherstellungsalgorithmen.  Aber ungefähr 80% der Artikel sind dem Thema gewidmet und der Algorithmus ist einfacher zu implementieren. <br><br>  Diese Technologie wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auch</a> in einem Hub beschrieben (es ist interessant, dass der Autor des Artikels ein Absolvent unseres Labors ist), aber wie Sie den Kommentaren entnehmen können, haben die Autoren keine meiner Fragen beantwortet, während sie die anderen beantworteten.  Und dies sind eher nicht die Autoren der Bösewichte, sondern die Politik des Unternehmens (in anderen Beiträgen gibt es, wenn Sie genau hinschauen, oft auch keine Antworten auf Fragen von Experten).  Für Technologieunternehmen zögern Blogs, tiefer in die Diskussion über Implementierungs- oder Technologiedetails einzusteigen.  Vor allem, wenn dies einen besseren Eindruck von der Technologie / dem Produkt vermittelt.  Oder Konkurrenten können das Gleiche schneller schneiden.  Auch hier ist das Marketing für die Beiträge verantwortlich, und dies ist ihre direkte Arbeit - sie schafft einen positiven Eindruck von den Produkten des Unternehmens, unabhängig von der Qualität der Produkte selbst.  Daher das häufige Misstrauen gegenüber den Informationen aus dem Marketing. <br><br>  Generell lohnt es sich, aus folgenden Gründen sehr skeptisch gegenüber den Bildern von Unternehmen aus der Serie „Wie wir alles gut gemacht haben“ zu sein: <br><br><ul><li>  Autoren von Verarbeitungsalgorithmen sind sich bewusst, dass es praktisch <b>keine Algorithmen gibt, die in einigen Fällen keine Artefakte erzeugen würden.</b>  Tatsächlich besteht eine der Hauptaufgaben des Entwicklers darin, den Prozentsatz solcher Fälle (oder die Sichtbarkeit von Artefakten in solchen Fällen) zu verringern und gleichzeitig die Qualität in anderen Fällen aufrechtzuerhalten.  Und sehr oft gelingt dies NICHT: <br><br><ul><li>  Oder die Artefakte sind so stark und schwer zu reparieren, dass der gesamte Ansatz abgelehnt wird.  Tatsächlich ist dies vielleicht der Fall (Überraschung-Überraschung!) Bei den meisten Artikeln.  In einigen Fällen göttliche Bilder (auf denen gemahlen wurde) und im Rest „es funktioniert überhaupt nicht“. <br></li><li>  Oder (und dies ist eine häufige Situation für praktische Technologieunternehmen) Sie müssen im Durchschnitt auf Qualität verzichten, damit Artefakte im schlimmsten Fall toleriert werden können. <br></li></ul><br></li></ul>  Wenn also schlechte Beispiele nicht veröffentlicht werden (Klassiker für Unternehmen) oder nur begrenzt und mit Standardeinstellungen (Klassiker für Artikel) veröffentlicht werden, ist dies der häufigste Fall, in dem Menschen über die Eigenschaften einer Technologie / eines Algorithmus irregeführt werden. <br><br><ul><li>  <b>Ein weiteres häufiges Missverständnis in Bezug auf Verarbeitungsalgorithmen ist die Verwendung von Parametern (einschließlich interner Parameter) des Algorithmus.</b>  Algorithmen haben Parameter, und Benutzer - und das ist auch die Norm - möchten höchstens eine Schaltfläche zum Aktivieren haben.  Und selbst wenn es Einstellungen gibt, verwendet der Massenbenutzer diese nicht.  Deshalb fragen sie beim Kauf von Technologie „hundertmal“ und fragen erneut: „Ist das sicher eine komplette Maschine?“  und fragen Sie nach vielen Beispielen. <br><br><ul><li>  Dementsprechend ist eine gemeinsame Geschichte die Veröffentlichung eines Ergebnisses, das mit bestimmten Parametern erhalten wurde.  Glücklicherweise kennt der Entwickler sie gut und selbst wenn es fünfzig sind (die reale Situation!), Nimmt er sie sehr schnell auf, so dass das Bild magisch ist.  Genau diese Bilder gehen oft in die Werbung. <br></li><li>  Darüber hinaus kann der Entwickler sogar dagegen sein.  Marketing sieht die neuen Beispiele gesendet und sagt: "Auf ihnen ist nichts sichtbar, in der letzten Präsentation hatten Sie normale Beispiele!"  Und dann können sie versuchen, ihnen zu erklären, dass neue Beispiele das sind, was die Leute wirklich sehen, und in der letzten Präsentation wurden potenzielle Ergebnisse gezeigt, die durch vorläufige Studien zum Start des Projekts erzielt werden können.  Das stört niemanden.  Die Leute bekommen das Bild "wo man sehen kann".  In einigen Fällen verwenden sogar große Unternehmen Photoshop.  Messing wird serviert, meine Herren!  ) <br></li></ul><br></li></ul><ul><li>  <b>Wenn es um Videos geht, eröffnet es der <s>Maschine</s> einfach riesige Freiflächen <s>...</s> gutes Marketing!</b>  Denn in der Regel werden Frames angelegt, und die Qualität des komprimierten Videos schwingt immer und hängt von der Masse der Parameter ab.  Wieder - mehrere Technologien können korrekt angewendet werden, die Verarbeitungszeit kann wiederum unterschiedlich sein.  Und das ist noch nicht alles, der Umfang ist großartig. <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laut</a> Yandex-Werbung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">funktioniert</a> die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DeepHD-</a> Technologie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in Echtzeit, sodass Sie heute damit Fernsehkanäle ansehen können</a> .  Es wurde oben erklärt, dass die Betriebsgeschwindigkeit die Achillesferse von Super Resolution ist.  Der Vorteil neuronaler Netze besteht natürlich darin, dass sie beim Lernen über einen längeren Zeitraum in einigen Fällen sehr schnell arbeiten können, aber ich würde trotzdem (mit großem beruflichen Interesse) prüfen, welche Auflösung und Qualität der Algorithmus in Echtzeit funktioniert.  Normalerweise werden mehrere Modifikationen des Algorithmus erstellt und bei hohen Auflösungen in Echtzeit müssen <b>viele</b> (qualitätskritische "Chips" deaktiviert werden.  <b>Zu viele.</b> <br></li><li>  In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schwarz-Weiß-Beispielen</a> zeigt ein genauerer Blick, dass sich die lokale Helligkeit ändert.  Da der richtige SR die Helligkeit nicht ändert, scheint es, dass ein anderer Algorithmus funktioniert hat, möglicherweise nicht einer (die Ergebnisse zeigen, dass dies keine Einzelbildverarbeitung ist oder vielmehr nicht nur so aussieht).  Wenn Sie ein größeres Stück (mindestens 100 Bilder) betrachten, wird das Bild klar.  Das Messen der Videoqualität ist jedoch ein separates, sehr großes Thema. <br></li></ul><br></li></ul><blockquote>  <b>Schlussfolgerungen:</b> <br><br><ul><li>  Sie müssen verstehen, dass Vermarkter ihre Tricks oft genau deshalb anwenden, weil es funktioniert (und wie!).  Die überwiegende Mehrheit der Menschen <s>liest nicht habr,</s> will das Thema nicht tief verstehen und sucht nicht einmal nach Expertenmeinungen, sie haben nur genug Werbung (manchmal Golimoy-Werbung).  Was regelmäßig zu allen Arten von Verzerrungen führt.  Ich wünsche mir, dass weniger Werbung gemacht wird, besonders wenn das Geschichtenerzählen am besten ist und wirklich an ein Wunder glauben möchte! <br></li><li>  Und natürlich ist es sehr gut, dass Yandex auch an dem Thema arbeitet und eine eigene SR erstellt (genauer gesagt eine eigene SR-Familie). <br></li></ul></blockquote><br><h2>  Perspektiven </h2><br>  Kommen wir zurück zu unserem Ausgangspunkt.  Was tun für diejenigen, die das komprimierte Video vergrößern möchten?  Ist das alles schlecht? <br><br>  Wie oben beschrieben, ist selbst eine geringfügige Änderung des Bildes in der Region, buchstäblich auf dem Rauschpegel, für die Algorithmen der "ehrlichen" Wiederherstellung entscheidend.  Das heißt, hohe Frequenzen im Bild und deren Wechsel zwischen Bildern sind kritisch. <br><br>  In diesem Fall ist die Hauptsache, aufgrund derer die Videokomprimierung durchgeführt wird, das Entfernen von Interframe-Rauschen.  Im folgenden Beispiel ist der Unterschied zwischen den Bildern eines verrauschten Videos vor der Bewegungskompensation, nach der Kompensation (mit schwacher Komprimierung) und nach der wahrnehmbaren Komprimierung zu spüren - spüren Sie den Unterschied (der Kontrast wird etwa sechsmal erhöht, damit die Details sichtbar werden): <br><img src="https://habrastorage.org/getpro/habr/post_images/4a0/867/c18/4a0867c1839ba6acea0aa16a7a5a408c.png"><br>  <i>Quelle: Autorenvorträge zu Komprimierungsalgorithmen</i> <br><br>  Es ist deutlich zu erkennen, dass aus Sicht des Codecs der ideale Bereich der Bereich ist, in dem die Bewegung vollständig kompensiert wurde und für den keine Bits mehr ausgegeben werden müssen.  Nun, ein bisschen kann ausgegeben werden, etwas minimal korrigiertes.  Und es kann einige solcher Bereiche geben.  Daher verliert Super Resolution sein „Hauptbrot“ - Informationen darüber, was sich an dieser Stelle in anderen Frames befindet, unter Berücksichtigung der Subpixelverschiebung. <br><br>  Wenn Sie sich die Artikel ansehen, dann enthält die JPEG- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wiederherstellung</a> selbst für ein relativ einfaches JPEG <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">26.000</a> Ergebnisse und für die JPEG- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wiederherstellung</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">52.000</a> , und dies zusammen mit der Wiederherstellung fehlerhafter Dateien usw.  Bei Videos ist die Situation schlimmer als bei der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MPEG-Wiederherstellung</a> - 22.000, d. H.  Die Arbeiten sind natürlich im Gange, aber der Umfang der Arbeiten zur Superauflösung ist nicht vergleichbar.  Es gibt ungefähr eine Größenordnung weniger Arbeit als das Wiederherstellen der Videoauflösung und zwei Größenordnungen weniger als die Bild-Superauflösung.  Zwei Bestellungen sind viel.  Wir haben auch einen Ansatz für das Projektil gewählt (da wir schon lange Komprimierung und Verarbeitung betreiben). Es gibt etwas, mit dem wir arbeiten können, insbesondere wenn die Qualität oszilliert oder etwas wie M-JPEG verwendet wird (in jüngerer Zeit ein allgemeines Bild in der Videoüberwachung).  Dies sind jedoch alles Sonderfälle. <br><br>  Die Ergebnisse der Artikel aus den obigen Links zeigen auch, dass die Ergebnisse manchmal sehr schön sind, aber für ganz besondere Fälle erhalten werden.  Das heißt,  Morgen wird diese Funktion auf jedem Smartphone leider nicht angezeigt.  Das sind schlechte Nachrichten.  Gut - übermorgen und auf einem Computer mit einer guten GPU - wird sicher erscheinen. <br><br>  Gründe: <br><br><ul><li>  Speichergeräte (SD-Karten für Registrare, Festplatten für CCTV-Kameras usw.) werden allmählich billiger und die durchschnittliche Bitrate zum Speichern von Videos steigt. <br></li><li>  Während der Komprimierung wechseln sie schrittweise zu den Standards der nächsten Generationen (z. B. bei HEVC), was eine spürbare Qualitätsverbesserung bei gleicher Bitrate bedeutet.  Die letzten 2 Punkte bedeuten, dass die Videoqualität allmählich höher wird und ab einem bestimmten Zeitpunkt gut entwickelte Video-Super-Resolution-Algorithmen funktionieren. <br></li><li>  Schließlich werden die Algorithmen verbessert.  Die Erfolge maschinell lernender Algorithmen in den letzten 4 Jahren sind besonders gut.  In dieser Hinsicht können wir mit hoher Wahrscheinlichkeit so etwas erwarten: <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/fce/82a/6a9/fce82a6a91aa6c5d654bd22c26bbf3d4.png"><br><br>  Das heißt,  Der Algorithmus verwendet explizit Bewegungsinformationen, die vom Codec empfangen wurden, und diese Daten werden dann einem neuronalen Netzwerk zugeführt, das darauf trainiert ist, für bestimmte Codecs spezifische Artefakte wiederherzustellen.  Ein solches Schema scheint derzeit durchaus erreichbar zu sein. <br><br>  In jedem Fall müssen Sie jedoch klar verstehen, dass die aktuelle Wiederherstellung in der Regel eine zweifache Erhöhung der Auflösung darstellt.  In einigen Fällen, in denen das Ausgangsmaterial nicht oder fast nicht komprimiert wurde, können wir seltener 3-4 Mal darüber sprechen.  Wie Sie sehen können, ist dies nicht annähernd das 100-1000-fache der Vergrößerung von Filmen, wenn 1,5 Pixel einer nächtlichen rauschunterdrückten Aufnahme zu einer Fahrzeugnummer von ausgezeichneter Qualität werden.  Dem Genre "Science Fiction" sollte eigentlich ein größerer Prozentsatz der Filme und Fernsehsendungen zugeordnet werden. <br><br>  Und natürlich wird es Versuche geben, im Rahmen des Modetrends „Das Wichtigste ist, mehr Schichten zu schneiden“ etwas Universelles zu tun.  Und hier lohnt es sich, vor "Cheers-Cheers" -Reaktionen auf Werbematerial zu diesem Thema zu warnen.  Denn neuronale Netze sind der bequemste Rahmen, um Wunder und alle Arten von Spekulationen zu demonstrieren.  Die Hauptsache ist, das Trainingsmuster und die endgültigen Beispiele richtig auszuwählen.  Und voila!  Sehen Sie das Wunder!  Übrigens sehr praktisch in Bezug auf das Hilling von Investoren.  Das heißt, es ist äußerst wichtig, dass die Effizienz von Technologien von jemandem bestätigt wird, der von einer großen Anzahl heterogener Beispiele unabhängig ist, was selten gezeigt wird.  Für Unternehmen ist es heute eine zivile Leistung, ein oder zwei Beispiele zu nennen, wenn die Technologie nicht funktioniert. <br><br>  Nun, damit das Leben nicht wie Honig aussieht, möchte ich Sie daran erinnern, dass die sogenannte Transcodierung heute beliebt ist, wenn Sie tatsächlich mit einem Video arbeiten müssen, das ursprünglich von einem Algorithmus verkleinert und dann von einem anderen verkleinert wurde, während andere Bewegungsvektoren verwendet werden, werden hohe wieder zerstört Frequenzen etc.  Und die Tatsache, dass eine Person dort alles gut sieht, bedeutet nicht, dass der Algorithmus, der ein solches Video verarbeitet, tatsächlich Wunder vollbringt.  Es wird nicht möglich sein, stark eingeklemmte Videos wiederherzustellen, obwohl sich Super Resolution in den nächsten 10 Jahren im Allgemeinen schnell entwickeln wird. <br><br><blockquote>  <b>Schlussfolgerungen:</b> <br><br><ul><li>  Denken Sie daran, dass das, was Sie in Filmen sehen und wie es im wirklichen Leben ist, sehr unterschiedlich ist.  Und das nicht nur in Bezug auf die Wiederherstellung hochkomprimierter Videos! <br></li><li>  Normalerweise erhöhen moderne Algorithmen die Auflösungen seltener um das Zweifache - etwas mehr, d. H.  Nein, 50 mal, aus dem Film bekannt, muss bald warten. <br></li><li>  Der Bereich Super Resolution boomt und Sie können in den kommenden Jahren mit einer aktiven Entwicklung der Videowiederherstellung rechnen, einschließlich der Wiederherstellung nach der Komprimierung. <br></li><li>  Aber das erste, was wir sehen werden, sind alle möglichen Spekulationen zu diesem Thema, wenn die demonstrierten Ergebnisse die tatsächlichen Fähigkeiten der Algorithmen stark übertreiben werden.  Sei vorsichtig! <br></li></ul></blockquote>  Ende letzten Jahres hielten wir einen Vortrag „Neuronale Netze in der Videoverarbeitung - Mythen und Realität“.  Vielleicht können wir sie hierher bringen. <br><br>  Bleib dran! <br><br><h2>  Danksagung </h2><br>  Ich möchte mich herzlich bedanken bei: <br><br><ul><li>  Labor für Computergrafik VMK Moscow State University  MV Lomonosov für Rechenleistung und nicht nur <br></li><li>  von unseren Kollegen aus der Videogruppe, dank derer die oben genannten Algorithmen erstellt wurden, und insbesondere von Karen Simonyan, der Autorin des Artikels, dessen Ergebnisse oben gezeigt wurden und die jetzt in Google DeepMind funktioniert. <br></li><li>  persönlich Konstantin Kozhemyakov, der viel getan hat, um diesen Artikel besser und visueller zu machen, <br></li><li>  Google für ein exzellentes Blog und relativ korrekte Beschreibungen der erstellten Technologien und Yandex für einen sehr guten Wettbewerb auf breiter Front - Google ist praktisch das einzige erfolgreiche Beispiel in einem Land, in dem Google-Dienste nicht verboten sind. <br></li><li>  Habrovchan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">denisshabr</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">JamboJet</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">iMADik</a> für den Tipp und Links zu professionellen Multi-Frame-SR-Kameras, <br></li><li>  und schließlich vielen Dank an Vyacheslav Napadovsky, Evgeny Kuptsov, Stanislav Grokholsky, Ivan Molodetsky, Alexei Soloviev, Evgeny Lyapustin, Jegor Sklyarov, Denis Kondranin, Alexandra Anzina, Roman Kazantsev und Gleb Ishelev für diese große Menge nützlicher Bemerkungen besser! <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439766/">https://habr.com/ru/post/de439766/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439756/index.html">Warum brauche ich einen thermoakustischen Generator?</a></li>
<li><a href="../de439758/index.html">Auf halbem Weg "Juno"</a></li>
<li><a href="../de439760/index.html">Ingenieure "verdrehten" das Licht in der Faser - eine neue Technologie beschleunigt die Datenübertragung um das Hundertfache</a></li>
<li><a href="../de439762/index.html">Über Hochschulbildung, Programmierer und Arbeiter</a></li>
<li><a href="../de439764/index.html">Unternehmensfrüchte</a></li>
<li><a href="../de439768/index.html">Wie funktioniert ein Barcode?</a></li>
<li><a href="../de439772/index.html">Unit-Tests in Swift schreiben, um asynchrone Aufgaben zu testen</a></li>
<li><a href="../de439774/index.html">Automatisieren Sie das Testen von Redux-Selektoren in der Anwendung</a></li>
<li><a href="../de439776/index.html">Frontend Weekly Digest (4. - 10. Februar 2019)</a></li>
<li><a href="../de439778/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends für die letzte Woche Nr. 351 (4. - 10. Februar 2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
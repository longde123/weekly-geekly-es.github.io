<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ðŸ’Ÿ ðŸ¦€ ðŸ”© Spark SQL. Sedikit tentang pengoptimal permintaan ðŸ”¹ ðŸ§” ðŸšœ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya. Sebagai pengantar, saya ingin memberi tahu Anda bagaimana saya sampai pada kehidupan seperti itu. 



 Sebelum bertemu dengan Big Data ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark SQL. Sedikit tentang pengoptimal permintaan</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neoflex/blog/417103/"><p>  Halo semuanya.  Sebagai pengantar, saya ingin memberi tahu Anda bagaimana saya sampai pada kehidupan seperti itu. <br></p><br><p>  Sebelum bertemu dengan Big Data dan Spark, khususnya, saya punya banyak dan sering untuk mengoptimalkan query SQL, pertama untuk MSSQL, kemudian untuk Oracle, dan sekarang saya menemukan SparkSQL. <br></p><br><p>  Dan jika sudah ada banyak buku bagus untuk DBMS yang menjelaskan metodologi dan "pena" yang dapat Anda putar untuk mendapatkan rencana kueri yang optimal, maka saya belum melihat buku seperti itu untuk Spark.  Saya menemukan lebih banyak artikel dan serangkaian praktik, lebih terkait dengan bekerja melalui RDD / Dataset API, daripada SQL murni.  Bagi saya, salah satu buku referensi tentang optimasi SQL adalah buku J. Lewis, Oracle.  Dasar-dasar optimasi biaya. "  Saya mencari sesuatu yang serupa dalam studi mendalam.  Mengapa subjek penelitian khusus SparkSQL, dan bukan API yang mendasarinya?  Kemudian ketertarikan itu disebabkan oleh fitur-fitur proyek yang sedang saya kerjakan. <br></p><br><img src="https://habrastorage.org/webt/po/1f/un/po1fun6vgbktou6lykepwmrncci.jpeg"><br><a name="habracut"></a><br><p>  Untuk salah satu pelanggan kami, perusahaan kami sedang mengembangkan data warehouse, lapisan terperinci di mana dan bagian dari jendela ada di cluster Hadoop, dan jendela terakhir di Oracle.  Proyek ini melibatkan lapisan konversi data yang luas, yang diimplementasikan pada Spark.  Untuk mempercepat pengembangan dan konektivitas pengembang ETL yang tidak terbiasa dengan seluk-beluk teknologi Big Data, tetapi akrab dengan alat SQL dan ETL, alat telah dikembangkan yang secara ideologis mengingatkan alat ETL lainnya, misalnya, Informatica, dan memungkinkan Anda merancang proses ETL secara visual dengan generasi berikutnya. kode untuk Spark.  Karena kompleksitas algoritma dan banyaknya transformasi, pengembang terutama menggunakan kueri SparkSQL. <br></p><br><p> Di sinilah cerita dimulai, karena saya harus menjawab sejumlah besar pertanyaan dari bentuk "Mengapa kueri tidak bekerja / bekerja lambat / tidak berfungsi seperti di Oracle?".  Yang ini ternyata menjadi bagian yang paling menarik bagi saya: "Mengapa itu bekerja lambat?".  Selain itu, tidak seperti DBMS yang pernah saya pakai sebelumnya, Anda dapat masuk ke kode sumber dan mendapatkan jawaban atas pertanyaan Anda. <br></p><cut text="    "></cut><br><h2>  Keterbatasan dan Asumsi </h2><br><p>  Spark 2.3.0 digunakan untuk menjalankan contoh dan menganalisis kode sumber. <br>  Diasumsikan bahwa pembaca sudah terbiasa dengan arsitektur Spark, dan prinsip umum pengoptimal kueri untuk salah satu DBMS.  Paling tidak, frasa "rencana kueri" tentu tidak mengherankan. <br></p><br><p>  Juga, artikel ini mencoba untuk tidak menjadi terjemahan kode optimizer Spark ke dalam bahasa Rusia, jadi untuk hal-hal yang sangat menarik dari sudut pandang optimizer, tetapi yang dapat dibaca dalam kode sumber, mereka hanya akan disebutkan secara singkat di sini dengan tautan ke kelas yang sesuai. <br></p><br><h2>  Lanjutkan untuk belajar </h2><br><p>  Mari kita mulai dengan kueri kecil untuk menjelajahi tahapan dasar yang digunakan mulai dari penguraian ke eksekusi. <br></p><br><pre><code class="scala hljs">scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/balance"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"bal"</span></span>) scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/customer"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"cust"</span></span>) scala&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> df = spark.sql(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">" | select bal.account_rk, cust.full_name | from bal | join cust | on bal.party_rk = cust.party_rk | and bal.actual_date = cust.actual_date | where bal.actual_date = cast('2017-12-31' as date) | "</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>) df: org.apache.spark.sql.<span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = [account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: string] scala&gt; df.explain(<span class="hljs-literal"><span class="hljs-literal">true</span></span>)</code> </pre> <br><p>  Modul utama yang bertanggung jawab untuk mem-parsing SQL dan mengoptimalkan rencana eksekusi permintaan adalah Spark Catalyst. <br></p><br><p>  Output yang diperluas dalam deskripsi rencana permintaan (df.explain (true)) memungkinkan Anda untuk melacak semua tahapan yang dilalui permintaan: <br></p><br><ul><li>  Parsed Logical Plan - dapatkan setelah parsing SQL.  Pada tahap ini, hanya kebenaran sintaksis dari permintaan yang diperiksa. </li></ul><br><pre> <code class="hljs rust">== Parsed Logical Plan == <span class="hljs-symbol"><span class="hljs-symbol">'Project</span></span> [<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.account_rk, <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.full_name] +- <span class="hljs-symbol"><span class="hljs-symbol">'Filter</span></span> (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- <span class="hljs-symbol"><span class="hljs-symbol">'Join</span></span> Inner, ((<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.party_rk = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.party_rk) &amp;&amp; (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.actual_date)) :- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `bal` +- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `cust`</code> </pre><br><ul><li>  Analisis Logical Plan - pada tahap ini, informasi tentang struktur entitas yang digunakan ditambahkan, korespondensi struktur dan atribut yang diminta diperiksa. </li></ul><br><pre> <code class="hljs delphi">== Analyzed Logical Plan == account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Filter (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- SubqueryAlias bal : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- SubqueryAlias cust +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Optimized Logical Plan adalah yang paling menarik bagi kami.  Pada tahap ini, pohon kueri yang dihasilkan dikonversi berdasarkan aturan optimasi yang tersedia. </li></ul><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Rencana Fisik - fitur akses ke data sumber mulai diperhitungkan, termasuk optimisasi untuk menyaring partisi dan data untuk meminimalkan set data yang dihasilkan.  Strategi eksekusi gabungan dipilih (untuk detail lebih lanjut tentang opsi yang tersedia, lihat di bawah). </li></ul><br><pre> <code class="hljs pgsql">== Physical Plan == *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [account_rk#<span class="hljs-number"><span class="hljs-number">1</span></span>, full_name#<span class="hljs-number"><span class="hljs-number">59</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) BroadcastHashJoin [party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">27</span></span>], [party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">88</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">Inner</span></span>, BuildRight :- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>, PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>) : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) FileScan orc [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>,PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/balance], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;ACCOUNT_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>)&gt; +- BroadcastExchange HashedRelationBroadcastMode(List(<span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>])) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) Project [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>, FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) FileScan orc [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>,FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/customer], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),FULL_NAME:string&gt;</code> </pre><br><p>  Tahapan optimasi dan eksekusi berikut (misalnya, WholeStageCodegen) berada di luar ruang lingkup artikel ini, tetapi dijelaskan secara sangat rinci (serta tahapan yang dijelaskan di atas) di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Menguasai Spark Sql</a> . <br></p><br><p>  Membaca rencana eksekusi permintaan biasanya terjadi "dari dalam" dan "dari bawah ke atas", yaitu, bagian yang paling bersarang dijalankan terlebih dahulu, dan secara bertahap maju ke proyeksi akhir yang terletak di bagian paling atas. <br></p><br><h2>  Jenis pengoptimal kueri </h2><br><p>  Dua jenis pengoptimal kueri dapat dibedakan: </p><br><ul><li>  Pengoptimal berbasis aturan (RBO). </li><li>  Pengoptimal berdasarkan pada perkiraan biaya eksekusi permintaan (Pengoptimal berbasis biaya, KSM). </li></ul><br><p>  Yang pertama difokuskan pada penggunaan seperangkat aturan tetap, misalnya, penerapan kondisi penyaringan dari mana pada tahap sebelumnya, jika mungkin, perhitungan konstanta, dll. <br></p><br><p>  Untuk mengevaluasi kualitas rencana yang dihasilkan, pengoptimal CBO menggunakan fungsi biaya, yang biasanya tergantung pada jumlah data yang diproses, jumlah baris yang termasuk dalam filter, dan biaya untuk melakukan operasi tertentu. <br></p><br><p>  Untuk mempelajari lebih lanjut tentang spesifikasi desain CBO untuk Apache Spark, silakan ikuti tautan: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">spesifikasi</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tugas utama JIRA untuk implementasi</a> . <br></p><br><p>  Titik awal untuk menjelajahi berbagai optimasi yang ada adalah kode Optimizer.scala. <br></p><br><p>  Berikut ini kutipan singkat dari daftar panjang optimisasi yang tersedia: <br></p><br><pre> <code class="hljs perl">def batches: Se<span class="hljs-string"><span class="hljs-string">q[Batch]</span></span> = { val operatorOptimizationRuleSet = Se<span class="hljs-string"><span class="hljs-string">q( // Operator push down PushProjectionThroughUnion, ReorderJoin, EliminateOuterJoin, PushPredicateThroughJoin, PushDownPredicate, LimitPushDown, ColumnPruning, InferFiltersFromConstraints, // Operator combine CollapseRepartition, CollapseProject, CollapseWindow, CombineFilters, CombineLimits, CombineUnions, // Constant folding and strength reduction NullPropagation, ConstantPropagation, ........</span></span></code> </pre><br><p>  Perlu dicatat bahwa daftar optimisasi ini mencakup optimisasi berbasis aturan dan optimisasi berdasarkan estimasi biaya kueri, yang akan dibahas di bawah ini. <br></p><br><p>  Fitur CBO adalah bahwa untuk operasi yang benar perlu mengetahui dan menyimpan informasi tentang statistik data yang digunakan dalam kueri - jumlah catatan, ukuran catatan, histogram distribusi data dalam kolom tabel. <br></p><br><p>  Untuk mengumpulkan statistik, seperangkat perintah SQL ANALYZE TABLE ... COMPUTE STATISTICS digunakan, di samping itu, satu set tabel diperlukan untuk menyimpan informasi, API disediakan melalui ExternalCatalog, lebih tepatnya melalui HiveExternalCatalog. <br></p><br><p>  Karena CBO saat ini dinonaktifkan secara default, penekanan utama akan ditempatkan pada penelitian optimasi dan nuansa RBO yang tersedia. <br></p><br><h2>  Jenis dan pilihan strategi bergabung </h2><br><p>  Pada tahap pembentukan rencana fisik untuk mengeksekusi permintaan, strategi bergabung dipilih.  Opsi berikut saat ini tersedia di Spark (Anda dapat mulai mempelajari kode dari kode di SparkStrategies.scala). <br></p><br><h3>  Siaran hash bergabung </h3><br><p>  Opsi terbaik adalah jika salah satu pihak bergabung cukup kecil (kriteria kecukupan diatur oleh parameter spark.sql.autoBroadcastJoinThreshold di SQLConf).  Dalam hal ini, sisi ini sepenuhnya disalin ke semua pelaksana, di mana ada hash bergabung dengan tabel utama.  Selain ukuran, harus dicatat bahwa dalam kasus sambungan luar, hanya sisi luar yang dapat disalin, oleh karena itu, jika mungkin, sebagai tabel utama dalam kasus sambungan luar, Anda harus menggunakan tabel dengan jumlah data terbesar. <br></p><br><pre> <code class="hljs pgsql">  ,    ,     <span class="hljs-keyword"><span class="hljs-keyword">SQL</span></span>      Oracle,   <span class="hljs-comment"><span class="hljs-comment">/*+ broadcast(t1, t2) */</span></span></code> </pre><br><h3>  Sortir gabungan bergabung </h3><br><p>  Dengan <em>spark.sql.join.preferSortMergeJoin</em> diaktifkan secara default, metode ini diterapkan secara default jika kunci untuk bergabung dapat diurutkan. <br>  Dari fitur-fiturnya, dapat dicatat bahwa, tidak seperti metode sebelumnya, optimisasi pembuatan kode untuk melakukan operasi hanya tersedia untuk gabungan internal. <br></p><br><h3>  Kocok hash bergabung </h3><br><p>  Jika kunci tidak dapat diurutkan, atau opsi pemilihan gabungan pilihan gabungan dinonaktifkan, Catalyst mencoba menerapkan gabungan hash acak.  Selain memeriksa pengaturan, juga diperiksa bahwa Spark memiliki cukup memori untuk membangun peta hash lokal untuk satu partisi (jumlah total partisi diatur dengan mengatur <em>spark.sql.shuffle.partitions</em> ) </p><br><h3>  BroadcastNestedLoopJoin dan CartesianProduct </h3><br><p>  Dalam kasus di mana tidak ada kemungkinan perbandingan langsung dengan kunci (misalnya, kondisi seperti) atau tidak ada kunci untuk bergabung dengan tabel, tergantung pada ukuran tabel, baik jenis ini atau Produk Cartesian dipilih. <br></p><br><h3>  Urutan menentukan tabel di join'ah </h3><br><p>  Bagaimanapun, bergabung membutuhkan tabel acak dengan kunci.  Oleh karena itu, saat ini, urutan tabel penentu, terutama dalam hal melakukan beberapa gabungan dalam satu baris, adalah penting (jika Anda membosankan, maka jika CBO tidak dihidupkan dan pengaturan JOIN_REORDER_ENABLED tidak diaktifkan). <br></p><br><p>  Jika memungkinkan, urutan tabel bergabung harus meminimalkan jumlah operasi acak untuk tabel besar, yang bergabung dengan kunci yang sama harus berurutan.  Juga, jangan lupa untuk meminimalkan data untuk bergabung, untuk mengaktifkan Broadcast Hash Join. <br></p><br><h2>  Aplikasi kondisi filter yang transitif </h2><br><p>  Pertimbangkan pertanyaan berikut: <br></p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> bal.account_rk, cust.full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> balance bal <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> customer cust <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> bal.party_rk = cust.party_rk <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> bal.actual_date = cust.actual_date <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> bal.actual_date = <span class="hljs-keyword"><span class="hljs-keyword">cast</span></span>(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-built_in"><span class="hljs-built_in">date</span></span>)</code> </pre><br><p>  Di sini kita menghubungkan dua tabel yang dipartisi dengan cara yang sama, sesuai dengan bidang actual_date dan menerapkan filter eksplisit hanya untuk partisi sesuai dengan tabel saldo. <br></p><br><p>  Seperti yang dapat dilihat dari rencana kueri yang dioptimalkan, filter berdasarkan tanggal juga berlaku untuk pelanggan, dan pada saat membaca data dari disk, ditentukan bahwa tepat satu partisi diperlukan. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter (((actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>) &amp;&amp; isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><p>  Tetapi Anda hanya perlu mengganti gabungan dalam dengan bagian luar kiri dalam kueri, karena predikat push untuk tabel pelanggan langsung jatuh, dan pemindaian penuh terjadi, yang merupakan efek yang tidak diinginkan. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join LeftOuter, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter (isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><h2>  Jenis konversi </h2><br><p>  Pertimbangkan contoh sederhana pemilihan dari tabel dengan pemfilteran menurut jenis klien, dalam skema, jenis bidang party_type adalah string. <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> party_rk, full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> cust <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> actual_date = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> party_type = <span class="hljs-number"><span class="hljs-number">101</span></span> <span class="hljs-comment"><span class="hljs-comment">--   -- and party_type = '101' --    </span></span></code> </pre><br><p>  Dan bandingkan dua rencana yang dihasilkan, yang pertama - ketika kita merujuk ke tipe yang salah (akan ada pemeran implisit ke int), yang kedua - ketika jenisnya sesuai dengan skema. <br></p><br><pre> <code class="hljs powershell">PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>)] //            . PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>), <span class="hljs-type"><span class="hljs-type">EqualTo</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>,<span class="hljs-number"><span class="hljs-number">101</span></span>)] //             .</code> </pre><br><p>  Masalah serupa diamati untuk kasus membandingkan tanggal dengan string, akan ada filter untuk membandingkan string.  Contoh: <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = <span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> (isnotnull(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span>) &amp;&amp; (cast(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> string) = <span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>) PushedFilters: [IsNotNull(OPER_DATE)] <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) PushedFilters: [IsNotNull(OPER_DATE), EqualTo(OPER_DATE,<span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>)]</code> </pre><br><p>  Untuk kasus ketika konversi tipe implisit dimungkinkan, misalnya, int -&gt; desimal, pengoptimal melakukannya sendiri. <br></p><br><h2>  Penelitian lebih lanjut </h2><br><p>  Banyak informasi menarik tentang "kenop" yang dapat digunakan untuk menyempurnakan Catalyst, serta tentang kemungkinan (sekarang dan masa depan) dari pengoptimal, dapat diperoleh dari SQLConf.scala. <br></p><br><p>  Secara khusus, seperti yang Anda lihat secara default, pengoptimal biaya masih dimatikan saat ini. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">CBO_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables CBO for estimation of plan statistics when set true."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  Serta optimalisasi dependen yang terkait dengan pemesanan ulang join'ov. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">JOIN_REORDER_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.joinReorder.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables join reorder in CBO."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  atau </p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">STARSCHEMA_DETECTION</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.starSchemaDetection"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"When true, it enables join reordering based on star schema detection. "</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><h2>  Ringkasan Singkat </h2><br><p>  Hanya sebagian kecil dari optimasi yang ada telah disentuh, eksperimen dengan optimasi biaya, yang dapat memberikan lebih banyak ruang untuk konversi kueri, ada di depan.  Juga, pertanyaan menarik yang terpisah adalah perbandingan dari serangkaian optimisasi ketika membaca file dari Parket dan Orc, dilihat dari jira proyek, ini tentang paritas, tetapi benarkah demikian? <br></p><br><p>  Selain itu: </p><br><ul><li>  Analisis dan optimalisasi permintaan menarik dan mengasyikkan, terutama mengingat ketersediaan kode sumber. </li><li>  Dimasukkannya CBO akan memberikan ruang untuk optimasi dan penelitian lebih lanjut. </li><li>  Penting untuk memantau penerapan aturan-aturan dasar yang memungkinkan Anda menyaring sebanyak mungkin data "ekstra" sedini mungkin. </li><li>  Bergabung adalah kejahatan yang perlu, tetapi jika memungkinkan, meminimalkan mereka dan melacak implementasi mana yang digunakan di bawah tenda. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id417103/">https://habr.com/ru/post/id417103/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id417091/index.html">Buat shader air kartun untuk web. Bagian 3</a></li>
<li><a href="../id417093/index.html">Sakelar sentuh dengan Modbus: mengapa diperlukan dan bagaimana menerapkannya di apartemen pintar</a></li>
<li><a href="../id417097/index.html">Pemrograman JavaScript</a></li>
<li><a href="../id417099/index.html">Bagaimana saya menulis library C ++ 11 standar atau mengapa boost sangat menakutkan. Bab 2</a></li>
<li><a href="../id417101/index.html">Definisi Ready - Yang Kami Lupa Memberitahu Tentang</a></li>
<li><a href="../id417105/index.html">Mencetak pada printer 3D. Pengalaman Rahasia 3Dtool</a></li>
<li><a href="../id417107/index.html">Pembuat game sementara True: learn () tentang pemrograman gamedev, masalah VR, dan simulasi ML</a></li>
<li><a href="../id417109/index.html">Richard Hamming: Bab 10. Teori Pengkodean - I</a></li>
<li><a href="../id417111/index.html">Konferensi online: streaming vs webinar</a></li>
<li><a href="../id417113/index.html">Printer Italia 3D di Rusia: Raise3D N1 Dual - modelling dan prototyping</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíì ‚öΩÔ∏è üíé La simplicidad y complejidad de las primitivas o c√≥mo determinar el preprocesamiento innecesario para una red neuronal üìâ üßëüèæ‚Äçü§ù‚Äçüßëüèæ üßëüèª‚Äçü§ù‚Äçüßëüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este es el tercer art√≠culo sobre el an√°lisis y estudio de elipses, tri√°ngulos y otras formas geom√©tricas. 
 Los art√≠culos anteriores plantearon alguna...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La simplicidad y complejidad de las primitivas o c√≥mo determinar el preprocesamiento innecesario para una red neuronal</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439122/">  Este es el tercer art√≠culo sobre el an√°lisis y estudio de elipses, tri√°ngulos y otras formas geom√©tricas. <br>  Los art√≠culos anteriores plantearon algunas preguntas muy interesantes entre los lectores, en particular, sobre la complejidad o simplicidad de ciertas secuencias de entrenamiento.  Las preguntas son realmente muy interesantes, por ejemplo, ¬øcu√°nto m√°s dif√≠cil es aprender un tri√°ngulo que un cuadr√°ngulo u otro pol√≠gono? <br><br><img src="https://habrastorage.org/webt/3p/l8/bo/3pl8bouhofjpesjyyzbmosjerxw.jpeg"><br><br>  Intentemos comparar, y para comparar tenemos una gran idea, probada por generaciones de estudiantes, la idea: cuanto m√°s corta es la hoja de trucos, m√°s f√°cil es el examen. <br><br>  Este art√≠culo tambi√©n es simplemente el resultado de la curiosidad y el inter√©s ocioso, nada de eso se encuentra en la pr√°ctica y para tareas pr√°cticas hay un par de grandes ideas, pero no hay casi nada para copiar y pegar.  Este es un peque√±o estudio de la complejidad de las secuencias de entrenamiento: se presentan el razonamiento y el c√≥digo del autor, puede verificar / complementar / cambiar todo usted mismo. <br><br>  Entonces, intentemos averiguar qu√© figura geom√©trica es m√°s complicada o m√°s simple para la segmentaci√≥n, qu√© curso de conferencias para IA es m√°s comprensible y mejor absorbido. <a name="habracut"></a><br><br>  Hay muchas formas geom√©tricas diferentes, pero solo compararemos tri√°ngulos, cuadr√°ngulos y estrellas de cinco puntas.  Utilizaremos un m√©todo simple para construir una secuencia de tren: dividiremos las im√°genes monocromas de 128x128 en cuatro partes y colocaremos al azar una elipse y, por ejemplo, un tri√°ngulo en estos cuartos.  Detectaremos un tri√°ngulo del mismo color que la elipse.  Es decir  la tarea es entrenar la red para distinguir, por ejemplo, un pol√≠gono cuadrangular de una elipse pintada del mismo color.  Aqu√≠ hay ejemplos de im√°genes que estudiaremos. <br><br><img src="https://habrastorage.org/webt/nu/qo/8i/nuqo8io482lnoa3ukyvjorfrlyo.png"><br><br><img src="https://habrastorage.org/webt/3h/rf/n6/3hrfn6wwnthkepnuqdrjezoyaas.png"><br><br><img src="https://habrastorage.org/webt/fi/_l/zw/fi_lzwaortnx2k4fbb-50l2_8rs.png"><br><br>  No detectaremos un tri√°ngulo y un cuadr√°ngulo en una imagen, los detectaremos por separado, en diferentes trenes, contra el fondo de interferencia en forma de elipse. <br><br>  Tomemos la cl√°sica red U y tres tipos de secuencias de entrenamiento con tri√°ngulos, cuadr√°ngulos y estrellas para la investigaci√≥n. <br><br>  Entonces, dado: <br><br><ul><li>  tres secuencias de entrenamiento de pares de im√°genes / m√°scaras; </li><li>  la red  Red U ordinaria, que se usa ampliamente para la segmentaci√≥n. </li></ul><br>  Idea para probar: <br><br><ul><li>  determinar cu√°l de las secuencias de entrenamiento es "m√°s dif√≠cil" de aprender; </li><li>  c√≥mo algunas t√©cnicas de preprocesamiento afectan el aprendizaje </li></ul><br>  Comencemos, seleccione 10,000 pares de im√°genes de cuadr√°ngulos con elipses y m√°scaras y consid√©relos cuidadosamente.  Estamos interesados ‚Äã‚Äãen lo corto que resultar√° la cuna y de qu√© longitud depende. <br><br><div class="spoiler">  <b class="spoiler_title">Cargamos bibliotecas, determinamos los tama√±os de una serie de im√°genes.</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.draw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ellipse, polygon <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization,Activation,Add,Dropout <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.losses <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> binary_crossentropy <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> keras w_size = <span class="hljs-number"><span class="hljs-number">128</span></span> train_num = <span class="hljs-number"><span class="hljs-number">10000</span></span> radius_min = <span class="hljs-number"><span class="hljs-number">10</span></span> radius_max = <span class="hljs-number"><span class="hljs-number">20</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">determinar las funciones de p√©rdida y precisi√≥n</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br>  Usaremos la m√©trica del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primer art√≠culo</a> .  Perm√≠tanme recordarles a los lectores que vamos a predecir la m√°scara del p√≠xel: este es el "fondo" o "cuadr√°ngulo" y evaluar la verdad o la falsedad de la predicci√≥n.  Es decir  Son posibles las siguientes cuatro opciones: predijimos correctamente que un p√≠xel es un fondo, predijimos correctamente que un p√≠xel es un cuadr√°ngulo o cometimos un error al predecir un "fondo" o "cuadr√°ngulo".  Entonces, para todas las im√°genes y todos los p√≠xeles, estimamos el n√∫mero de las cuatro opciones y calculamos el resultado; este ser√° el resultado de la red.  Y cuanto menos predicciones err√≥neas y m√°s verdaderas, cuanto m√°s preciso sea el resultado y mejor ser√° la red. <br><br>  Examinamos la red como un "recuadro negro", no veremos lo que est√° sucediendo con la red interna, c√≥mo cambian los pesos y c√≥mo se eligen los gradientes; m√°s adelante analizaremos las entra√±as de la red cuando comparemos las redes. <br><br><div class="spoiler">  <b class="spoiler_title">U-net simple</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_layer, start_neurons)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># 128 -&gt; 64 conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(input_layer) conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(conv1) pool1 = MaxPooling2D((2, 2))(conv1) pool1 = Dropout(0.25)(pool1) # 64 -&gt; 32 conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(conv2) pool2 = MaxPooling2D((2, 2))(conv2) pool2 = Dropout(0.5)(pool2) # 32 -&gt; 16 conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(conv3) pool3 = MaxPooling2D((2, 2))(conv3) pool3 = Dropout(0.5)(pool3) # 16 -&gt; 8 conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(conv4) pool4 = MaxPooling2D((2, 2))(conv4) pool4 = Dropout(0.5)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(pool4) convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(convm) # 8 -&gt; 16 deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) uconv4 = Dropout(0.5)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(uconv4) # 16 -&gt; 32 deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) uconv3 = Dropout(0.5)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(uconv3) # 32 -&gt; 64 deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) uconv2 = Dropout(0.5)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(uconv2) # 64 -&gt; 128 deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) uconv1 = Dropout(0.5)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(uconv1) uncov1 = Dropout(0.5)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer # model input_layer = Input((w_size, w_size, 1)) output_layer = build_model(input_layer, 26) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=1e-4), metrics=[my_iou_metric]) model.summary()</span></span></code> </pre><br></div></div><br>  La funci√≥n de generar pares de imagen / m√°scara.  En una imagen en blanco y negro de 128x128 llena de ruido aleatorio con una selecci√≥n aleatoria de dos rangos, o 0.0 ... 0.75 o 0.25..1.0.  Seleccione aleatoriamente un cuarto en la imagen y coloque una elipse orientada al azar y en el otro cuarto colocamos un cuadril√°tero e igualmente color con ruido aleatorio. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> img_l = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img_h = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span> + <span class="hljs-number"><span class="hljs-number">0.25</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">2</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) i0_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> i0_qua == i1_qua: i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) _qua = np.int(w_size/<span class="hljs-number"><span class="hljs-number">4</span></span>) qua = np.array([[_qua,_qua],[_qua,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua]]) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] c = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p0 = np.rint(np.random.sample()*(radius_max-radius_min) + radius_min) p1 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] - (radius_max-radius_min) p2 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] - (radius_max-radius_min) p3 = np.rint(np.random.sample()*radius_min) p4 = np.rint(np.random.sample()*radius_min) p5 = np.rint(np.random.sample()*radius_min) p6 = np.rint(np.random.sample()*radius_min) p7 = np.rint(np.random.sample()*radius_min) p8 = np.rint(np.random.sample()*radius_min) poly = np.array(( (p1, p2), (p1+p3, p2+p4+p0), (p1+p5+p0, p2+p6+p0), (p1+p7+p0, p2+p8), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr_p, cc_p,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br>  Creemos una secuencia de entrenamiento de pares, ver al azar 10. Perm√≠tanme recordarles que las im√°genes son monocromas, en escala de grises. <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] f_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) f_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) <span class="hljs-comment"><span class="hljs-comment">#    10   fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk]) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze())</span></span></code> </pre><br><img src="https://habrastorage.org/webt/nu/qo/8i/nuqo8io482lnoa3ukyvjorfrlyo.png"><br><br><h3>  Primer paso  Entrenamos en el set inicial m√≠nimo </h3><br>  El primer paso de nuestro experimento es simple, estamos tratando de entrenar a la red para predecir solo 11 primeras im√°genes. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br> <code>accuracy 0.8545 loss 0.0674 lenght 11 : : 793it [00:58, 14.79it/s]</code> <br> <br>  Seleccionamos los primeros 11 de la secuencia inicial y capacitamos a la red en ellos.  Ahora no importa si la red memoriza estas im√°genes espec√≠ficamente o resume, lo principal es que puede reconocer estas 11 im√°genes de la manera que necesitamos.  Dependiendo del conjunto de datos y la precisi√≥n seleccionados, la capacitaci√≥n en red puede durar mucho, mucho tiempo.  Pero solo tenemos unas pocas iteraciones.  Repito que ahora no es importante para nosotros c√≥mo y qu√© aprendi√≥ o aprendi√≥ la red, lo principal es que ha alcanzado la precisi√≥n establecida de predicci√≥n. <br><br><h3>  Ahora comienza el experimento principal </h3><br>  Construiremos la hoja de trucos, construiremos dichas hojas de trucos por separado para las tres secuencias de entrenamiento y compararemos su longitud.  Tomaremos nuevos pares de imagen / m√°scara de la secuencia construida e intentaremos predecirlos por la red entrenada en la secuencia ya seleccionada.  Al principio, son solo 11 pares de imagen / m√°scara y la red est√° entrenada, quiz√°s no muy correctamente.  Si en un nuevo par se predice la m√°scara de la imagen con una precisi√≥n aceptable, entonces descartamos este par, no tiene informaci√≥n nueva para la red, ya lo sabe y puede calcular la m√°scara a partir de esta imagen.  Si la precisi√≥n de la predicci√≥n es insuficiente, entonces agregamos esta imagen con una m√°scara a nuestra secuencia y comenzamos a entrenar la red hasta que se obtenga un resultado de precisi√≥n aceptable en la secuencia seleccionada.  Es decir  Esta imagen contiene informaci√≥n nueva y la agregamos a nuestra secuencia de entrenamiento y extraemos la informaci√≥n contenida en ella mediante entrenamiento. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f_imgs[m0_select&gt;0], f_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9338 loss 0.0266 selected img 1007 tested img 9985 : : 4291it [49:52, 1.73s/it]</code> </pre> <br>  Aqu√≠ la precisi√≥n se usa en el sentido de "precisi√≥n", y no como la m√©trica est√°ndar de keras, y la subrutina "my_iou_metric" se usa para calcular la precisi√≥n. <br><br>  Ahora compare el funcionamiento de la misma red con los mismos par√°metros en una secuencia diferente, en tri√°ngulos <br><br><img src="https://habrastorage.org/webt/3h/rf/n6/3hrfn6wwnthkepnuqdrjezoyaas.png"><br><br>  Y obtenemos un resultado completamente diferente <br><br><pre> <code class="bash hljs">Accuracy 0.9823 loss 0.0108 selected img 1913 tested img 9995 : : 6343it [2:11:36, 3.03s/it]</code> </pre> <br>  La red seleccion√≥ im√°genes de 1913 con informaci√≥n "nueva", es decir  ¬°El contenido de las im√°genes con tri√°ngulos es la mitad que con los cuadr√°ngulos! <br><br>  Verifiquemos lo mismo en las estrellas y ejecutemos la red en la tercera secuencia <br><br><img src="https://habrastorage.org/webt/fi/_l/zw/fi_lzwaortnx2k4fbb-50l2_8rs.png"><br><br>  tenemos <br><br><pre> <code class="bash hljs">Accuracy 0.8985 loss 0.0478 selected img 476 tested img 9985 : : 2188it [16:13, 1.16it/s]</code> </pre> <br>  Como puede ver, las estrellas resultaron ser las m√°s informativas, solo 476 im√°genes en una hoja de trucos. <br><br>  Ten√≠amos razones para juzgar la complejidad de las formas geom√©tricas para la percepci√≥n por su red neuronal.  La m√°s simple es la estrella, con solo 476 im√°genes en la hoja de trucos, luego el cuadr√°ngulo con su 1007 y el m√°s complejo result√≥ ser un tri√°ngulo: para el entrenamiento necesitas 1913 im√°genes. <br><br>  Tenga en cuenta que esto es para nosotros, para las personas es una imagen, pero para la red es un curso de lectura sobre reconocimiento y el curso sobre tri√°ngulos result√≥ ser el m√°s dif√≠cil. <br><br><h3>  Ahora sobre lo serio </h3><br>  A primera vista, todas estas elipses y tri√°ngulos parecen mimos, tortas de arena y lego.  Pero aqu√≠ hay una pregunta espec√≠fica y seria: si aplicamos alg√∫n tipo de preprocesamiento, filtro a la secuencia inicial, ¬øc√≥mo cambiar√° la complejidad de la secuencia?  Por ejemplo, tomamos las mismas elipses y cuadr√°ngulos y les aplicamos dicho preprocesamiento <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.ndimage <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gaussian_filter _tmp = [gaussian_filter(idx, sigma = <span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f_imgs] f1_imgs = np.array(_tmp)[:,:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_tmp) fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>): kk = np.random.randint(train_num) axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(f1_imgs[kk].squeeze(), cmap=<span class="hljs-string"><span class="hljs-string">"gray"</span></span>) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(f_msks[kk].squeeze(), cmap=<span class="hljs-string"><span class="hljs-string">"gray"</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/76/mb/0f/76mb0fpk1weknaahb8fyxn6cevk.png"><br><br>  A primera vista, todo es lo mismo, las mismas elipses, los mismos pol√≠gonos, pero la red comenz√≥ a funcionar de una manera completamente diferente: <br><br><pre> <code class="bash hljs">Accuracy 1.0575 loss 0.0011 selected img 7963 tested img 9999 : : 17765it [29:02:00, 12.40s/it]</code> </pre> <br>  Aqu√≠ se necesita una peque√±a explicaci√≥n, no utilizamos el aumento, porque  La forma del pol√≠gono y la forma de la elipse se seleccionan inicialmente al azar.  Por lo tanto, el aumento no dar√° nueva informaci√≥n y no tiene sentido en este caso. <br><br>  Pero, como se puede ver en el resultado del trabajo, un simple gaussian_filter cre√≥ muchos problemas para la red, gener√≥ mucha informaci√≥n nueva y probablemente superflua. <br><br>  Bueno, para los amantes de la simplicidad en su forma m√°s pura, tomamos las mismas elipses con pol√≠gonos, pero sin ninguna aleatoriedad en el color. <br><br><img src="https://habrastorage.org/webt/8x/7b/vd/8x7bvdqpavgkjuubnk-2ug-kjt4.png"><br><br>  El resultado sugiere que el color aleatorio no es una simple adici√≥n. <br><br><pre> <code class="bash hljs">Accuracy 0.9004 loss 0.0315 selected img 251 tested img 9832 : : 1000it [06:46, 1.33it/s]</code> </pre><br>  La red vali√≥ completamente la informaci√≥n extra√≠da de 251 im√°genes, casi cuatro veces menos que la de muchas im√°genes pintadas con ruido. <br><br>  El prop√≥sito del art√≠culo es mostrar algunas herramientas y ejemplos de su trabajo en ejemplos fr√≠volos, el lego en el sandbox.  Tenemos una herramienta para comparar dos secuencias de entrenamiento, podemos evaluar cu√°nto complica nuestro preprocesamiento o simplifica la secuencia de entrenamiento, c√≥mo esta o aquella primitiva en la secuencia de entrenamiento es f√°cil de detectar. <br><br>  La posibilidad de aplicar este ejemplo de Lego en casos reales es obvia, pero los entrenamientos reales y las redes de lectores dependen de los propios lectores. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439122/">https://habr.com/ru/post/439122/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439112/index.html">Creador de Kate Mobile arrestado por ped√≥filo usando su servicio</a></li>
<li><a href="../439114/index.html">Del caos al orden, o "crear una estructura de proyecto en Unity y no solo ..."</a></li>
<li><a href="../439116/index.html">Juego de Andrey: miedo a la crisis tecnol√≥gica</a></li>
<li><a href="../439118/index.html">Nuevo en los navegadores: Firefox 66 bloquea el video y el sonido de forma predeterminada, Chromium limita el presupuesto de la p√°gina</a></li>
<li><a href="../439120/index.html">Solicitudes de funciones y requisitos del producto</a></li>
<li><a href="../439124/index.html">Si el software se crea con dinero p√∫blico, el c√≥digo debe estar abierto</a></li>
<li><a href="../439126/index.html">Solicitudes de usuario y requisitos de producto</a></li>
<li><a href="../439128/index.html">C√≥mo organizar el trabajo de QA. Una forma pr√°ctica</a></li>
<li><a href="../439130/index.html">13 tendencias del mercado de ciberseguridad y seguridad de la informaci√≥n 2019-2020</a></li>
<li><a href="../439132/index.html">Vejez inolvidable</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
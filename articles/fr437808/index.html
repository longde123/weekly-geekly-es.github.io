<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚èπÔ∏è üë©‚Äçüíº üë©üèª‚Äçü§ù‚Äçüë®üèø Perf et graphes de flamme üîö üë®üèΩ‚Äç‚úàÔ∏è üôÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le sujet de l'am√©lioration des performances des syst√®mes d'exploitation et de la recherche de goulots d'√©tranglement gagne en popularit√©. Dans cet art...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Perf et graphes de flamme</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/437808/"><img src="https://habrastorage.org/webt/pa/ue/x8/pauex8un6--wep6-1ehqvmciieg.png"><br><br>  Le sujet de l'am√©lioration des performances des syst√®mes d'exploitation et de la recherche de goulots d'√©tranglement gagne en popularit√©.  Dans cet article, nous parlerons d'un outil pour trouver ces endroits m√™mes en utilisant l'exemple de la pile de blocs sous Linux et d'un cas de d√©pannage d'un h√¥te. <br><br><h2>  Exemple 1. Test </h2><br><h3>  Rien ne marche </h3><br>  Les tests dans notre d√©partement sont des synth√©tiques sur le mat√©riel du produit et des tests de logiciels d'application ult√©rieurs.  Nous avons re√ßu un lecteur Intel Optane pour les tests.  Nous avons d√©j√† √©crit sur le test des disques Optane <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans notre blog</a> . <br><br>  Le disque a √©t√© install√© sur un serveur standard construit pendant une p√©riode relativement longue sous l'un des projets cloud. <br><a name="habracut"></a><br>  Pendant le test, le disque ne s'est pas montr√© de la meilleure fa√ßon: pendant le test avec une profondeur de file d'attente de 1 requ√™te pour 1 flux, en blocs de 4 Ko environ ~ 70 Ko.  Et cela signifie que le temps de r√©ponse est √©norme: environ 13 microsecondes par requ√™te! <br><br>  C'est √©trange, car la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sp√©cification</a> promet "Latence - Lire 10 ¬µs", et nous avons obtenu 30% de plus, la diff√©rence est assez significative.  Le disque a √©t√© r√©organis√© sur une autre plate-forme, un assemblage plus ¬´frais¬ª utilis√© dans un autre projet. <br><br><h3>  Pourquoi √ßa marche? </h3><br>  C'est dr√¥le, mais le lecteur sur la nouvelle plate-forme a fonctionn√© comme il se doit.  Performances augment√©es, latence diminu√©e, CPU par √©tag√®re, 1 flux par requ√™te, blocs de 4 octets, ~ 106 Ko √† ~ 9 microsecondes par requ√™te. <br><br>  Et puis il est temps de <s>comparer les param√®tres</s> pour obtenir des <b>performances</b> de <b>jambes</b> larges.  Apr√®s tout, nous nous demandons pourquoi?  Avec <b>perf,</b> vous pouvez: <br><br><ul><li>  Prenez des relev√©s de compteur mat√©riel: le nombre d'appels d'instructions, de rat√©s de cache, de branches incorrectement pr√©dites, etc.  (√âv√©nements PMU) </li><li>  Supprimer les informations des points de vente statiques, le nombre d'occurrences </li><li>  Effectuer un tra√ßage dynamique </li></ul><br>  Pour la v√©rification, nous avons utilis√© l'√©chantillonnage du processeur. <br><br>  L'essentiel est que <b>perf</b> puisse compiler la trace de pile enti√®re d'un programme en cours d'ex√©cution.  Naturellement, l'ex√©cution de <b>perf</b> introduira un retard dans le fonctionnement de l'ensemble du syst√®me.  Mais nous avons le drapeau <i>-F #</i> , o√π <i>#</i> est la fr√©quence d'√©chantillonnage, mesur√©e en Hz. <br><br>  Il est important de comprendre que plus la fr√©quence d'√©chantillonnage est √©lev√©e, plus il est probable qu'il intercepte un appel √† une fonction particuli√®re, mais plus le profileur apporte de freins au syst√®me.  Plus la fr√©quence est basse, plus il est probable que nous ne verrons pas une partie de la pile. <br><br>  Lorsque vous choisissez une fr√©quence, vous devez √™tre guid√© par le bon sens et une astuce - essayez de ne pas d√©finir une fr√©quence paire, afin de ne pas vous retrouver dans une situation o√π un travail ex√©cut√© sur une minuterie avec cette fr√©quence p√©n√®tre dans les √©chantillons. <br><br>  Un autre point qui est trompeur au d√©part - le logiciel doit √™tre compil√© avec le drapeau <i>-fno-omit-frame-pointer</i> , si cela est bien s√ªr possible.  Sinon, dans la trace, au lieu des noms de fonction, nous verrons <i>des</i> valeurs <i>inconnues</i> solides.  Pour certains logiciels, les symboles de d√©bogage sont fournis dans un package s√©par√©, par exemple <i>someutil-dbg</i> .  Il est recommand√© de les installer avant d'ex√©cuter <b>perf</b> . <br><br>  Nous avons effectu√© les actions suivantes: <br><br><ul><li>  Extrait de fio de git: //git.kernel.dk/fio.git, tag fio-3.9 </li><li>  Ajout de l' <em>option -fno-omit-frame-pointer</em> √† CPPFLAGS dans Makefile </li><li>  Lancement de <em>make -j8</em> </li></ul><br><pre><code class="bash hljs">perf record -g ~/fio/fio --name=<span class="hljs-built_in"><span class="hljs-built_in">test</span></span> --rw=randread --bs=4k --ioengine=pvsync2 --filename=/dev/nvme0n1 --direct=1 --hipri --filesize=1G</code> </pre> <br>  L'option -g est n√©cessaire pour capturer la pile de traces. <br><br>  Vous pouvez voir le r√©sultat par la commande: <br><br><pre> <code class="bash hljs">perf report -g fractal</code> </pre> <br>  L'option <i>-g fractal</i> est n√©cessaire pour que les pourcentages refl√©tant le nombre d'√©chantillons avec cette fonction et montr√©s par <b>perf</b> soient relatifs √† la fonction appelante, dont le nombre d'appels est pris √† 100%. <br><br>  Vers la fin de la longue pile d'appels fio sur la plate-forme ¬´nouvelle construction¬ª, nous verrons: <br><br><img src="https://habrastorage.org/webt/_y/pn/jb/_ypnjb3xkf3urq140p0qssevtku.png"><br><br>  Et sur la plateforme ¬´old build¬ª: <br><br><img src="https://habrastorage.org/webt/gq/kx/ul/gqkxulpyxspbmfudoxhh7ysdv1e.png"><br><br>  Super!  Mais je veux de beaux flammes. <br><br><h3>  Construction de flammes </h3><br>  Pour √™tre belle, il existe deux outils: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Graphique de flamme</a> relativement plus statique </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Flamescope</a> , qui permet de s√©lectionner une p√©riode de temps sp√©cifique parmi les √©chantillons collect√©s.  Ceci est tr√®s utile lorsque le code de recherche charge le CPU avec de courtes rafales. </li></ul><br>  Ces utilitaires acceptent <b>perf script&gt; result</b> comme entr√©e. <br><br>  T√©l√©chargez le <i>r√©sultat</i> et envoyez-le via des tuyaux √† <i>svg</i> : <br><br><pre> <code class="bash hljs">FlameGraph/stackcollapse-perf.pl ./result | FlameGraph/flamegraph.pl &gt; ./result.svg</code> </pre> <br>  Ouvrez dans un navigateur et profitez d'une image cliquable. <br><br>  Vous pouvez utiliser une autre m√©thode: <br><br><ol><li>  Ajouter le <i>r√©sultat</i> au flamescope / exemple / </li><li>  Ex√©cutez python ./run.py </li><li>  On passe par le navigateur vers le port 5000 de l'h√¥te local </li></ol><br><h3>  Que voyons-nous finalement? </h3><br>  Un bon fio passe beaucoup de temps √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">voter</a> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o1/zg/wy/o1zgwy-l6idzwcxniq16ndbskvo.png"></div><br>  Un mauvais fio passe du temps n'importe o√π, mais pas dans les sondages: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3z/er/bz/3zerbzvtrpwznzewdteyf6bexfq.png"></div><br>  √Ä premi√®re vue, il semble que l'interrogation ne fonctionne pas sur l'ancien h√¥te, mais partout le noyau 4.15 est du m√™me assemblage et l'interrogation est activ√©e par d√©faut sur les disques NVMe.  V√©rifiez si l'interrogation est activ√©e dans <b>sysfs</b> : <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cat /sys/class/block/nvme0n1/queue/io_poll 1</span></span></code> </pre> <br>  Pendant les tests, des appels <i>preadv2</i> avec l'indicateur <i>RWF_HIPRI</i> sont <i>utilis√©s</i> - une condition n√©cessaire pour que l'interrogation fonctionne.  Et, si vous √©tudiez attentivement le graphique de la flamme (ou la capture d'√©cran pr√©c√©dente de la sortie du <b>rapport de</b> performance), vous pouvez le trouver, mais cela prend tr√®s peu de temps. <br><br>  La deuxi√®me chose visible est la pile d'appels diff√©rente pour la fonction submit_bio () et le manque d'appels √† io_schedule ().  Examinons de plus pr√®s la diff√©rence √† l'int√©rieur de submit_bio (). <br><br>  Plate-forme lente "ancienne construction": <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sd/ba/ew/sdbaewdxmxq2qqy7w6xwlkmpuia.png"></div><br>  Plateforme rapide "fra√Æche": <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_a/d2/_w/_ad2_wholhggbeewyuoxvqdpuas.png"></div><br>  Il semble que sur une plate-forme lente, la demande va un long chemin vers l'appareil, tout en entrant dans le <b>planificateur kyber</b> .  Vous pouvez en savoir plus sur les planificateurs d'E / S dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">notre article</a> . <br><br>  Une fois le <b>kyber</b> √©teint, le m√™me test fio a montr√© une latence moyenne d'environ 10 microsecondes, comme indiqu√© dans la sp√©cification.  Super! <br><br>  Mais d'o√π vient la diff√©rence dans une autre microseconde? <br><br><h3>  Et si un peu plus profond? </h3><br>  Comme d√©j√† mentionn√©, <b>perf</b> vous permet de collecter des statistiques √† partir de compteurs mat√©riels.  Essayons de voir le nombre d'√©checs de cache et d'instructions par cycle: <br><br><pre> <code class="bash hljs">perf <span class="hljs-built_in"><span class="hljs-built_in">stat</span></span> -e cycles,instructions,cache-references,cache-misses,bus-cycles /root/fio/fio --clocksource=cpu --name=<span class="hljs-built_in"><span class="hljs-built_in">test</span></span> --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=10</code> </pre> <br><img src="https://habrastorage.org/webt/ue/pc/fo/uepcfo8up5ehpvqb1ophotqjzb8.png"><br><br><img src="https://habrastorage.org/webt/p5/ln/al/p5lnalg0u05xtvc5792ghegtv34.png"><br><br>  Les r√©sultats montrent qu'une plate-forme rapide ex√©cute plus d'instructions pour le cycle du processeur et pr√©sente un pourcentage plus faible de rat√©s de cache pendant l'ex√©cution.  Bien entendu, nous n'entrerons pas dans les d√©tails du fonctionnement des diff√©rentes plateformes mat√©rielles dans le cadre de cet article. <br><br><h2>  Exemple 2. √âpicerie </h2><br><h3>  Quelque chose ne va pas </h3><br>  Dans le travail d'un syst√®me de stockage distribu√©, une augmentation de la charge sur le CPU sur l'un des h√¥tes a √©t√© observ√©e avec une augmentation du trafic entrant.  Les h√¥tes sont des pairs, des pairs et ont un mat√©riel et des logiciels identiques. <br><br>  Regardons la charge CPU: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># pidstat -p 1441734 1 Linux 3.13.0-96-generic (lol) 10/10/2018 _x86_64_ (24 CPU) 09:23:30 PM UID PID %usr %system %guest %CPU CPU Command 09:23:44 PM 0 1441734 23.00 1.00 0.00 24.00 4 ceph-osd 09:23:45 PM 0 1441734 85.00 34.00 0.00 119.00 4 ceph-osd 09:23:46 PM 0 1441734 0.00 130.00 0.00 130.00 4 ceph-osd 09:23:47 PM 0 1441734 121.00 0.00 0.00 121.00 4 ceph-osd 09:23:48 PM 0 1441734 28.00 82.00 0.00 110.00 4 ceph-osd 09:23:49 PM 0 1441734 4.00 13.00 0.00 17.00 4 ceph-osd 09:23:50 PM 0 1441734 1.00 6.00 0.00 7.00 4 ceph-osd</span></span></code> </pre> <br>  Le probl√®me est survenu √† 09:23:46 et nous voyons que le processus a fonctionn√© dans l'espace du noyau exclusivement pendant toute la seconde.  Voyons ce qui se passait √† l'int√©rieur. <br><br><h3>  Pourquoi si lent? </h3><br>  Dans ce cas, nous avons pr√©lev√© des √©chantillons de l'ensemble du syst√®me: <br><br><pre> <code class="bash hljs">perf record -a -g -- sleep 22 perf script &gt; perf.results</code> </pre> <br>  L'option <i>-a</i> est n√©cessaire ici pour que <b>perf</b> supprime les traces de tous les CPU. <br><br>  Ouvrez <b>perf.results</b> avec <b>flamescope</b> pour suivre le moment de l'augmentation de la charge du processeur. <br><br><div class="spoiler">  <b class="spoiler_title">Heatmap</b> <div class="spoiler_text"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ao/db/hq/aodbhqbwotkcwaq99bvmbznkbrg.png"></div><br></div></div><br>  Nous avons devant nous une "carte thermique" dont les deux axes (X et Y) repr√©sentent le temps. <br><br>  Sur l'axe X, l'espace est divis√© en secondes, et sur l'axe Y, en segments de 20 millisecondes en X secondes. Le temps passe de bas en haut et de gauche √† droite.  Les carr√©s les plus brillants ont le plus grand nombre d'√©chantillons.  Autrement dit, le processeur √† ce moment-l√† a fonctionn√© le plus activement. <br><br>  En fait, nous nous int√©ressons √† la tache rouge au milieu.  S√©lectionnez-le avec la souris, cliquez et voyez ce qu'il cache: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gv/kk/ko/gvkkkomg9vl7u1ylpwx7h8pceqc.png"></div><br>  En g√©n√©ral, il est d√©j√† √©vident que le probl√®me est le <i>fonctionnement</i> lent <i>tcp_recvmsg</i> et <i>skb_copy_datagram_iovec</i> . <br><br>  Pour plus de clart√©, comparez avec des exemples d'un autre h√¥te sur lequel la m√™me quantit√© de trafic entrant ne pose pas de probl√®me: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/v6/_j/72/v6_j72zqvscfolhkaipeoyx9lg8.png"></div><br>  Sur la base du fait que nous avons la m√™me quantit√© de trafic entrant, des plates-formes identiques qui fonctionnent depuis longtemps sans s'arr√™ter, nous pouvons supposer que les probl√®mes sont survenus du c√¥t√© du fer.  La fonction <i>skb_copy_datagram_iovec</i> copie les donn√©es de la structure du noyau vers la structure dans l'espace utilisateur pour les transmettre √† l'application.  Il y a probablement des probl√®mes de m√©moire h√¥te.  Dans le m√™me temps, il n'y a aucune erreur dans les journaux. <br><br>  Nous red√©marrons la plateforme.  Lors du chargement du BIOS, nous voyons un message concernant une barre de m√©moire cass√©e.  Remplacement, l'h√¥te d√©marre et le probl√®me avec un CPU surcharg√© n'est plus reproduit. <br><br><h2>  Postscript </h2><br><h3>  Performances du syst√®me avec perf </h3><br>  De mani√®re g√©n√©rale, sur un syst√®me occup√©, l'ex√©cution de <b>perf</b> peut <b>entra√Æner</b> un retard dans le traitement des demandes.  La taille de ces retards d√©pend √©galement de la charge sur le serveur. <br><br>  Essayons de trouver ce retard: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /root/fio/fio --clocksource=cpu --name=test --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=1 test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=pvsync2, iodepth=1 fio-3.9-dirty Starting 1 process Jobs: 1 (f=1): [r(1)][100.0%][r=413MiB/s][r=106k IOPS][eta 00m:00s] test: (groupid=0, jobs=1): err= 0: pid=109786: Wed Dec 12 17:25:56 2018 read: IOPS=106k, BW=414MiB/s (434MB/s)(4096MiB/9903msec) clat (nsec): min=8161, max=84768, avg=9092.68, stdev=1866.73 lat (nsec): min=8195, max=92651, avg=9127.03, stdev=1867.13 ‚Ä¶ ~# perf record /root/fio/fio --clocksource=cpu --name=test --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=1 test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=pvsync2, iodepth=1 fio-3.9-dirty Starting 1 process Jobs: 1 (f=1): [r(1)][100.0%][r=413MiB/s][r=106k IOPS][eta 00m:00s] test: (groupid=0, jobs=1): err= 0: pid=109839: Wed Dec 12 17:27:50 2018 read: IOPS=106k, BW=413MiB/s (433MB/s)(4096MiB/9916msec) clat (nsec): min=8259, max=55066, avg=9102.88, stdev=1903.37 lat (nsec): min=8293, max=55096, avg=9135.43, stdev=1904.01</span></span></code> </pre> <br>  La diff√©rence n'est pas tr√®s visible, seulement environ 8 nanosecondes. <br><br>  Voyons ce qui se passe si vous augmentez la charge: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /root/fio/fio --clocksource=cpu --name=test --numjobs=4 --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=1 test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=pvsync2, iodepth=1 ... fio-3.9-dirty Starting 4 processes Jobs: 4 (f=4): [r(4)][100.0%][r=1608MiB/s][r=412k IOPS][eta 00m:00s] ~# perf record /root/fio/fio --clocksource=cpu --name=test --numjobs=4 --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=1 test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=pvsync2, iodepth=1 ... fio-3.9-dirty Starting 4 processes Jobs: 4 (f=4): [r(4)][100.0%][r=1584MiB/s][r=405k IOPS][eta 00m:00s]</span></span></code> </pre> <br>  Ici, la diff√©rence devient d√©j√† perceptible.  On peut dire que le syst√®me a ralenti de moins de 1%, mais essentiellement perdre environ 7 kiops sur un syst√®me lourdement charg√© peut entra√Æner des probl√®mes. <br><br>  Il est clair que cet exemple est synth√©tique, n√©anmoins il est tr√®s r√©v√©lateur. <br><br>  Essayons d'ex√©cuter un autre test synth√©tique qui calcule les nombres premiers - <i>sysbench</i> : <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># sysbench --max-time=10 --test=cpu run --num-threads=10 --cpu-max-prime=100000 ... Test execution summary: total time: 10.0140s total number of events: 3540 total time taken by event execution: 100.1248 per-request statistics: min: 28.26ms avg: 28.28ms max: 28.53ms approx. 95 percentile: 28.31ms Threads fairness: events (avg/stddev): 354.0000/0.00 execution time (avg/stddev): 10.0125/0.00 ~# perf record sysbench --max-time=10 --test=cpu run --num-threads=10 --cpu-max-prime=100000 ‚Ä¶ Test execution summary: total time: 10.0284s total number of events: 3498 total time taken by event execution: 100.2164 per-request statistics: min: 28.53ms avg: 28.65ms max: 28.89ms approx. 95 percentile: 28.67ms Threads fairness: events (avg/stddev): 349.8000/0.40 execution time (avg/stddev): 10.0216/0.01</span></span></code> </pre> <br>  Ici, vous pouvez voir que m√™me le temps de traitement minimum a augment√© de 270 microsecondes. <br><br><h3>  Au lieu d'une conclusion </h3><br>  <b>Perf</b> est un outil tr√®s puissant pour analyser les performances du syst√®me et le d√©bogage.  Cependant, comme pour tout autre outil, vous devez garder le contr√¥le et vous rappeler que tout syst√®me charg√© sous surveillance √©troite fonctionne moins bien. <br><br>  Liens connexes: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Exemples d'une seule ligne avec perf</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Perf wiki</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr437808/">https://habr.com/ru/post/fr437808/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr437796/index.html">AlphaStar a-t-il impl√©ment√© la vitesse surhumaine en tant que patch pour l'erreur d'entra√Ænement √† la simulation?</a></li>
<li><a href="../fr437800/index.html">ScrumBut dans l'√©quipe d'analyse: avant le d√©collage</a></li>
<li><a href="../fr437802/index.html">Innovate Cloud Technology: Catastrophic Cloud</a></li>
<li><a href="../fr437804/index.html">Puis-je utiliser Redux sur un serveur?</a></li>
<li><a href="../fr437806/index.html">EcmaScript 10 - JavaScript de cette ann√©e (ES2019)</a></li>
<li><a href="../fr437810/index.html">R√©alit√© d'entreprise</a></li>
<li><a href="../fr437812/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 et autres b√™tas</a></li>
<li><a href="../fr437814/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 et autres versions b√™ta</a></li>
<li><a href="../fr437816/index.html">MPLS est partout. Comment est l'infrastructure r√©seau Yandex.Cloud</a></li>
<li><a href="../fr437818/index.html">Nous enseignons √† un ordinateur √† distinguer les sons: se familiariser avec le concours DCASE et assembler votre classificateur audio en 30 minutes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
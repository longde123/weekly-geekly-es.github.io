<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¤œ ğŸ’‡ ğŸ“ƒ Cadangan Bagian 7: Kesimpulan ğŸ‘¨ğŸ¼â€ğŸ¤â€ğŸ‘¨ğŸ» ğŸ›€ğŸ» ğŸ‘©ğŸ¾â€ğŸ”§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Catatan ini melengkapi siklus cadangan. Ini akan berbicara tentang organisasi logis dari server khusus (atau VPS), nyaman untuk cadangan, dan juga aka...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cadangan Bagian 7: Kesimpulan</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/472776/"><p><img src="https://habrastorage.org/webt/0j/nc/w0/0jncw0g7k55eoykgop-7y2vcdgi.jpeg"></p><br><p>  Catatan ini melengkapi siklus cadangan.  Ini akan berbicara tentang organisasi logis dari server khusus (atau VPS), nyaman untuk cadangan, dan juga akan menawarkan opsi untuk dengan cepat memulihkan server dari cadangan tanpa downtime jika terjadi kecelakaan. </p><a name="habracut"></a><br><h2 id="ishodnye-dannye">  Sumber data </h2><br><p>  Sebuah dedicated server paling sering memiliki setidaknya dua hard drive yang digunakan untuk mengatur array RAID tingkat pertama (mirror).  Ini diperlukan untuk dapat melanjutkan server jika satu drive gagal.  Jika ini adalah server khusus yang didedikasikan, mungkin ada pengontrol RAID perangkat keras terpisah dengan teknologi caching aktif pada SSD, sehingga selain hard drive biasa satu atau lebih SSD dapat dihubungkan.  Kadang-kadang server khusus ditawarkan, di mana hanya SATADOM yang hadir dari disk lokal (disk kecil, secara struktural - drive flash USB yang terhubung ke port SATA), atau bahkan drive flash USB kecil (8-16GB) biasa yang terhubung ke port internal khusus, dan data diambil dari sistem penyimpanan terhubung melalui jaringan penyimpanan khusus (Ethernet 10G, FC, dll.), dan ada server khusus yang dimuat langsung dari sistem penyimpanan.  Saya tidak akan mempertimbangkan opsi seperti itu, karena dalam kasus seperti itu, tugas mencadangkan server dengan lancar diteruskan ke spesialis yang melayani sistem penyimpanan, biasanya ada berbagai teknologi eksklusif untuk membuat snapshot keadaan, deduplikasi bawaan, dan kegembiraan lain dari administrator sistem yang dibahas dalam bagian sebelumnya dari seri ini.  Volume array disk dari server khusus dapat mencapai beberapa puluh terabyte, tergantung pada jumlah dan volume disk yang terhubung ke server.  Dalam kasus VPS, volumenya lebih sederhana: biasanya tidak lebih dari 100GB (tetapi ada lebih banyak), dan tarif untuk VPS seperti itu dapat dengan mudah lebih mahal daripada server khusus yang termurah dari hoster yang sama.  VPS paling sering memiliki satu drive, karena di bawahnya akan ada penyimpanan (atau sesuatu hyperconverged).  Terkadang VPS memiliki beberapa disk dengan karakteristik berbeda, untuk tujuan berbeda: </p><br><ul><li>  sistem kecil - untuk menginstal sistem operasi; </li><li>  besar - penyimpanan data pengguna. </li></ul><br><p>  Saat menginstal ulang sistem menggunakan panel kontrol, disk dengan data pengguna tidak ditimpa, tetapi sistem sepenuhnya dimuat ulang.  Juga, dalam kasus VPS, tuan rumah dapat menawarkan tombol yang mengambil snapshot dari status VPS (atau disk), namun, jika Anda menginstal sistem operasi Anda atau lupa untuk mengaktifkan layanan yang diinginkan di dalam VPS, beberapa data mungkin masih hilang.  Selain tombol, layanan penyimpanan data biasanya ditawarkan, paling sering sangat terbatas.  Biasanya ini adalah akun dengan akses FTP atau SFTP, kadang-kadang bersama-sama dengan SSH, dengan shell terpotong (misalnya rbash), atau pembatasan menjalankan perintah melalui otorisasi_keys (melalui ForcedCommand). </p><br><p>  Server khusus terhubung ke jaringan oleh dua port dengan kecepatan 1 Gbit / s, kadang-kadang dapat berupa kartu dengan kecepatan 10 Gbit / s.  VPS sering memiliki satu antarmuka jaringan.  Paling sering, pusat data tidak membatasi kecepatan jaringan di dalam pusat data, tetapi membatasi kecepatan akses Internet. </p><br><p>  Beban khas dari server khusus atau VPS adalah server web, database, server aplikasi.  Kadang-kadang berbagai layanan dukungan tambahan dapat diinstal, termasuk untuk server web atau database: mesin pencari, sistem surat, dll. </p><br><p>  Server yang disiapkan secara khusus bertindak sebagai ruang untuk menyimpan salinan cadangan, itu akan dijelaskan secara lebih rinci di bawah ini. </p><br>
<h2 id="logicheskaya-organizaciya-diskovoy-sistemy">  Organisasi Disk Logis </h2><br><p>  Jika ada pengontrol RAID, atau VPS dengan satu disk, dan juga tidak ada preferensi khusus untuk subsistem disk (misalnya, disk cepat terpisah untuk basis data) - semua ruang kosong dibagi sebagai berikut: satu partisi dibuat, sekelompok volume LVM dibuat di atasnya , ia menciptakan beberapa volume: 2 yang kecil dengan ukuran yang sama yang digunakan sebagai sistem file root (mereka diubah secara bergantian dengan pembaruan untuk mengaktifkan rollback cepat, ide itu dimata-matai dari distribusi Calculate Linux), yang lain adalah untuk partisi swap, sisanya gratis  ruang ini dibagi menjadi volume kecil yang digunakan sebagai sistem file root untuk kontainer penuh, disk untuk mesin virtual, sistem file untuk akun di / rumah (setiap akun memiliki sistem file sendiri), sistem file untuk kontainer aplikasi. </p><br><p>  Catatan penting: volume harus sepenuhnya swasembada, mis.  seharusnya tidak bergantung satu sama lain dan pada sistem file root.  Dalam kasus mesin atau wadah virtual, titik ini diamati secara otomatis.  Jika ini adalah wadah aplikasi atau direktori rumah, Anda harus mempertimbangkan untuk memisahkan file konfigurasi server web dan layanan lain sedemikian rupa untuk secara maksimal menghapus dependensi volume di antara mereka.  Misalnya, setiap situs berjalan pada penggunanya sendiri, file konfigurasi situs berada di direktori home pengguna, dalam pengaturan server web, file konfigurasi situs tidak disertakan melalui /etc/nginx/conf.d/ .conf <em>, tetapi, misalnya, / home /</em> /configs/nginx/*.conf </p><br><p>  Jika ada beberapa disk, Anda dapat membuat RAID perangkat lunak (dan mengkonfigurasi caching pada SSD, jika ada kebutuhan dan peluang), di atas yang mana untuk memasang LVM sesuai dengan aturan yang disarankan di atas.  Juga dalam hal ini, Anda dapat menggunakan ZFS atau BtrFS, tetapi di sini perlu dipertimbangkan beberapa kali: keduanya memerlukan pendekatan sumber daya yang jauh lebih serius, di samping itu, ZFS tidak datang dengan kernel Linux. </p><br><p>  Terlepas dari skema yang digunakan, selalu bermanfaat untuk memperkirakan perkiraan kecepatan penulisan perubahan pada disk sebelumnya, dan kemudian menghitung ukuran ruang kosong yang akan disediakan untuk membuat snapshot.  Misalnya, jika server kami menulis data pada kecepatan 10 megabyte per detik, dan ukuran seluruh array data adalah 10 terabyte - waktu sinkronisasi dapat mencapai satu hari (22 jam - jumlah ini akan ditransfer melalui jaringan 1 gbit / s) - layak untuk dicadangkan tentang 800 GB  Pada kenyataannya, jumlahnya akan lebih sedikit, Anda dapat dengan aman membaginya dengan jumlah volume logis. </p><br><h2 id="ustroystvo-servera-hraneniya-rezervnyh-kopiy">  Perangkat Server Penyimpanan Cadangan </h2><br><p>  Perbedaan utama antara server untuk menyimpan cadangan adalah disk besar, murah, dan relatif lambat.  Karena HDD modern telah melewati batas 10 TB dalam satu drive, perlu untuk menggunakan sistem file atau RAID dengan checksum, karena selama pembangunan kembali array atau pemulihan sistem file (beberapa hari!), Disk kedua mungkin gagal karena peningkatan beban.  Pada disk dengan kapasitas hingga 1TB, ini tidak terlalu sensitif.  Untuk kesederhanaan deskripsi, saya berasumsi bahwa ruang disk dibagi menjadi dua bagian dengan ukuran yang kira-kira sama (sekali lagi, misalnya, menggunakan LVM): </p><br><ul><li>  volume yang terkait dengan server yang digunakan untuk menyimpan data pengguna (cadangan terakhir yang dibuat untuk verifikasi akan digunakan untuk mereka); </li><li>  volume yang digunakan sebagai repositori BorgBackup (data untuk cadangan akan langsung sampai di sini). </li></ul><br><p>  Prinsip operasi adalah bahwa volume terpisah dibuat untuk setiap server di bawah repositori BorgBackup, di mana data dari server pertempuran akan pergi.  Repositori beroperasi dalam mode add-only, yang menghilangkan kemungkinan penghapusan data yang disengaja, dan karena deduplikasi dan pembersihan repositori berkala dari cadangan lama (ada salinan tahunan, bulanan untuk tahun lalu, mingguan untuk bulan lalu, setiap hari untuk minggu terakhir, mungkin dalam spesial kasing - jam untuk hari terakhir: total 24 + 7 + 4 + 12 + tahunan - sekitar 50 salinan untuk setiap server). <br>  Dalam repositori BorgBackup, hanya mode penambahan yang tidak diaktifkan, sebagai gantinya, ForcedCommand digunakan dalam .ssh / authorizedkey tentang kira-kira paket berikut: </p><br><pre><code class="plaintext hljs">from=" ",command="/usr/local/bin/borg serve --append-only --restrict-to-path /home/servername/borgbackup/",no-pty,no-agent-forwarding,no-port-forwarding,no-X11-forwarding,no-user-rc AAAAA.......</code> </pre> <br><p>  Pembungkus skrip ditempatkan di atas jalur yang ditentukan di atas borg, yang, selain meluncurkan biner dengan parameter, juga memulai proses memulihkan cadangan setelah data dihapus.  Untuk melakukan ini, skrip wrapper membuat file tag di sebelah repositori yang sesuai.  Cadangan terakhir yang dibuat setelah proses pengunggahan data secara otomatis dikembalikan ke volume logis yang sesuai. </p><br><p>  Desain ini memungkinkan Anda untuk membersihkan cadangan yang tidak perlu secara berkala, dan juga tidak memungkinkan server pertempuran untuk menghapus apa pun di server penyimpanan cadangan. </p><br><h2 id="process-rezervnogo-kopirovaniya">  Proses pencadangan </h2><br><p>  Pemrakarsa cadangan adalah server khusus itu sendiri atau VPS, karena skema semacam itu memberi lebih banyak kendali atas proses pencadangan dari server ini.  Pertama-tama, potret keadaan sistem file root aktif diambil, yang dipasang dan diunggah menggunakan BorgBackup ke server penyimpanan cadangan.  Setelah menyelesaikan pengambilan data, gambar dilepas dan dihapus. </p><br><p>  Jika ada database kecil (hingga 1 GB untuk setiap situs), dump database dibuat, yang disimpan dalam volume logis yang sesuai, di mana sisa data dari situs yang sama berada, tetapi agar dump tidak dapat diakses melalui server web.  Jika databasenya besar, Anda harus mengonfigurasi data mining "panas", misalnya menggunakan xtrabackup untuk MySQL, atau WAL dengan archive_command di PostgreSQL.  Dalam hal ini, basis data akan dipulihkan secara terpisah dari situs-situs ini. </p><br><p>  Jika wadah atau mesin virtual digunakan, Anda harus mengonfigurasi qemu-guest-agent, CRIU atau teknologi lain yang diperlukan.  Dalam kasus lain, pengaturan tambahan paling sering tidak diperlukan - buat saja snapshot dari volume logis, yang kemudian diproses sama dengan snapshot dari keadaan sistem file root.  Setelah mengambil data, gambar dihapus. </p><br><p>  Pekerjaan lebih lanjut dilakukan pada server penyimpanan cadangan: </p><br><ul><li>  Cadangan terakhir yang dibuat di setiap repositori diperiksa. </li><li>  memeriksa file tag yang menunjukkan bahwa proses pengambilan data selesai, </li><li>  data sedang diperluas ke volume lokal yang sesuai, </li><li>  file tag dihapus </li></ul><br><h2 id="process-vosstanovleniya-rabotosposobnosti-servera">  Proses pemulihan server </h2><br><p>  Jika server utama mati, server khusus serupa diluncurkan, yang diambil dari beberapa gambar standar.  Kemungkinan besar, pengunduhan akan dilakukan melalui jaringan, namun teknisi pusat data yang melakukan konfigurasi server dapat segera menyalin gambar standar ini ke salah satu disk.  Pengunduhan dilakukan dalam RAM, setelah itu proses pemulihan dimulai: </p><br><ul><li>  permintaan dibuat untuk melampirkan perangkat blok melalui iscsi \ nbd atau protokol serupa lainnya dari volume logis yang berisi sistem file root dari server yang mati;  karena sistem file root harus kecil - langkah ini harus diselesaikan dalam beberapa menit.  Pemulihan bootloader juga dilakukan; </li><li>  struktur volume logis lokal diciptakan kembali, volume logis dilampirkan dari server cadangan menggunakan modul kernel dm_clone: â€‹â€‹pemulihan data dimulai, dan perubahan ditulis segera ke disk lokal </li><li>  sebuah wadah diluncurkan dengan semua disk fisik yang tersedia - server sepenuhnya dipulihkan, tetapi dengan kinerja yang berkurang; </li><li>  setelah sinkronisasi data selesai, volume logis dari server cadangan terputus, wadah dimatikan, server reboot; </li></ul><br><p>  Setelah reboot, server akan memiliki semua data yang ada pada saat cadangan, dan juga termasuk semua perubahan yang dibuat selama proses pemulihan. </p><br><div class="spoiler">  <b class="spoiler_title">Artikel siklus lainnya</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cadangan, bagian 1: Mengapa Anda memerlukan cadangan, tinjauan umum metode, teknologi</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cadangan, Bagian 2: Tinjauan Umum dan Pengujian alat pencadangan berbasis rsync</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cadangan, Bagian 3: Gambaran Umum dan Pengujian duplikasi, dupati</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cadangan, Bagian 4: Tinjauan Umum dan Pengujian zbackup, restic, borgbackup</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cadangan, Bagian 5: Menguji Bacula dan Cadangan Veeam untuk Linux</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cadangan: bagian yang diminta oleh pembaca: ulasan AMANDA, UrBackup, BackupPC</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cadangan, Bagian 6: Membandingkan Alat Cadangan</a> <br>  Cadangan Bagian 7: Kesimpulan </p></div></div><br><p>  Saya mengundang Anda untuk membahas opsi yang diusulkan di komentar, terima kasih atas perhatian Anda! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id472776/">https://habr.com/ru/post/id472776/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id472762/index.html">Analisis teknis eksploitasi checkm8</a></li>
<li><a href="../id472766/index.html">Parameterisasi dari file di py.test</a></li>
<li><a href="../id472768/index.html">Cara merekrut, memecat, dan kembali dari manajemen ke pengembangan: video dari Badoo Techleads Meetup # 5</a></li>
<li><a href="../id472770/index.html">Organisasi antarmuka dalam Persatuan dengan Kanvas UI</a></li>
<li><a href="../id472772/index.html">Cari insiden dan klaim serupa. Metrik dan Optimasi</a></li>
<li><a href="../id472778/index.html">5 Cara Menggunakan Raspberry Pi</a></li>
<li><a href="../id472780/index.html">Mengapa menghindari teman, atau bagaimana saya kehilangan semua kelebihan saya</a></li>
<li><a href="../id472782/index.html">Mengapa 3D Headache / Bagian 8 Defocus dan masa depan 3D</a></li>
<li><a href="../id472790/index.html">Barang Antik: i-Mate Jasjar, seorang komunikator untuk bisnis</a></li>
<li><a href="../id472792/index.html">Komputer berdasarkan katup NOR: di dalam komputer kontrol on-board Apollo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😅 👷 👾 Mengapa Anda tidak harus menunggu manifestasi moral dari robomobiles 🧖🏻 🏀 🗝️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sejak perusahaan mulai mengembangkan kendaraan robot, orang-orang mulai bertanya tentang bagaimana perancang akan menyelesaikan masalah moral , sepert...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mengapa Anda tidak harus menunggu manifestasi moral dari robomobiles</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441704/"><img src="https://habrastorage.org/getpro/habr/post_images/773/dac/cf6/773daccf6483ad47c1e3169babe23727.jpg"><br><br>  Sejak perusahaan mulai mengembangkan kendaraan robot, orang-orang mulai bertanya tentang bagaimana perancang akan menyelesaikan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">masalah moral</a> , seperti siapa yang harus dibunuh robot jika terjadi kecelakaan yang tidak dapat dihindari.  Sebuah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">studi</a> baru-baru <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ini</a> menunjukkan bahwa pertanyaan ini mungkin lebih sulit untuk dijawab daripada yang diperkirakan sebelumnya, karena preferensi moral orang berbeda-beda di berbagai negara. <br><br>  Para peneliti di Universitas Harvard dan MIT telah mengembangkan game online yang mensimulasikan situasi di mana kecelakaan dengan para korban tidak dapat dihindari.  Mereka mewawancarai 40 juta orang dari 200 negara, menawarkan untuk memilih berbagai opsi tentang bagaimana insiden seperti itu harus berakhir, misalnya, apakah penumpang mobil atau pejalan kaki harus mati. <br><a name="habracut"></a><br>  Akibatnya, tiga kelompok budaya dengan preferensi etis yang berbeda ditemukan.  Misalnya, di kluster selatan (yang mencakup sebagian besar Amerika Latin dan bekas koloni Prancis), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">paling disukai</a> untuk membebaskan perempuan daripada merugikan laki-laki.  Di kluster timur (yang mencakup banyak negara Islam, Cina, Jepang, dan Korea), orang-orang cenderung memilih untuk menyelamatkan kaum muda agar merugikan para lansia. <br><br>  Para peneliti menyimpulkan bahwa informasi ini harus memengaruhi keputusan pengembang robomobiles.  Tetapi haruskah itu?  Karya ini, menyoroti penemuan menarik dari perbedaan global dalam preferensi moral, juga menunjukkan kesalahpahaman terus-menerus tentang AI dan kemampuannya.  Mengingat tingkat teknologi AI saat ini yang digunakan dalam kendaraan robot, jelas bahwa mesin tidak dapat membuat keputusan moral. <br><br><h2>  Fantasi "mesin moral" </h2><br>  Robomobiles dilatih untuk membuat keputusan tentang kapan harus mengarahkan dan kapan harus memperlambat, menggunakan jenis khusus AI, juga dikenal sebagai " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AI lemah (sempit),</a> " yang berfokus pada satu tugas yang sangat khusus.  Mereka dikembangkan menggunakan berbagai sensor, kamera, dan laser rangefinding (kapten) yang memberikan informasi ke komputer pusat.  Komputer menggunakan AI untuk menganalisis data input dan membuat keputusan. <br><br>  Dan meskipun saat ini teknologi ini relatif sederhana, sebagai akibatnya, mobil dapat melampaui seseorang dalam tugas paling sederhana yang terkait dengan mengendarai mobil.  Tetapi tidak realistis untuk percaya bahwa robomobiles harus dapat membuat keputusan yang etis, yang bahkan orang yang paling bermoral pun tidak akan punya waktu jika terjadi kecelakaan.  Jika kita menginginkan ini dari mobil, kita perlu memprogram kecerdasan buatan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tujuan umum</a> (IION). <br><br>  IION setara dengan menjadikan kita manusia.  Ini adalah kesempatan untuk berbicara, menikmati musik, menertawakan sesuatu atau menilai moralitas.  Sekarang tidak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mungkin</a> membuat IION karena kompleksitas pemikiran dan emosi manusia.  Jika kita menuntut penciptaan mobil otonom dengan moralitas, kita harus menunggu beberapa dekade, bahkan jika ini mungkin. <br><br>  Masalah lain dengan studi baru ini adalah sifat tidak realistis dari banyak situasi yang dinilai oleh para peserta.  Dalam satu skenario, " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">masalah troli</a> " yang terkenal dimainkan, dan peserta ditanyai siapa mobil yang harus bergerak ketika rem gagal: tiga penumpang (seorang pria, seorang wanita dan seorang anak) atau tiga pejalan kaki tua (dua pria tua dan satu wanita tua). <br><br>  Orang dapat dengan hati-hati merenungkan masalah seperti itu dengan mengisi kuesioner.  Tetapi dalam sebagian besar insiden kehidupan nyata, pengemudi tidak akan punya waktu untuk membuat keputusan seperti itu dalam sepersekian detik yang akan terjadi.  Jadi, perbandingannya salah.  Mengingat tingkat teknologi AI saat ini yang digunakan dalam kendaraan robot, kendaraan ini juga tidak akan dapat membuat keputusan seperti itu. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5b7/69d/ad1/5b769dad146a14e131d4e61694b2c442.jpg"><br>  <i>AI yang sempit memungkinkan robot mobil membuat penilaian sederhana tentang objek di sekitarnya</i> <br><br>  Robomobiles modern memiliki kemampuan persepsi dunia yang kompleks, dan mereka dapat membedakan pejalan kaki dari objek lain, seperti lampu jalan atau rambu lalu lintas.  Namun, penulis penelitian percaya bahwa robomobiles dapat, dan bahkan mungkin perlu membuat perbedaan yang lebih dalam.  Misalnya, mereka dapat menghargai tingkat kegunaan orang-orang tertentu bagi masyarakat, misalnya, dokter atau atlet, dan memutuskan untuk menyelamatkan mereka jika terjadi kecelakaan. <br><br>  Kenyataannya adalah bahwa untuk melakukan penalaran yang rumit seperti itu, Anda harus membuat IION, yang tidak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mungkin</a> hari ini.  Selain itu, tidak jelas apakah ini harus dilakukan sama sekali.  Sekalipun dimungkinkan untuk membuat program mesin kesempatan untuk memutuskan kehidupan siapa yang harus diselamatkan, saya percaya bahwa kita seharusnya tidak diizinkan untuk melakukan ini.  Kita tidak boleh membiarkan preferensi ditentukan oleh penelitian, tidak peduli seberapa besar pemilihannya, untuk menentukan nilai kehidupan manusia. <br><br>  Pada dasarnya, robomobiles dirancang untuk menghindari kecelakaan sebanyak mungkin atau untuk meminimalkan kecepatan tumbukan.  Meskipun, seperti halnya manusia, mereka tidak akan dapat membuat keputusan berdasarkan moralitas jika terjadi tabrakan yang akan terjadi.  Namun, robomobiles akan lebih <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">aman</a> daripada mobil yang digerakkan orang, lebih penuh perhatian, kecepatan reaksi mereka akan lebih tinggi, dan mereka akan dapat menggunakan potensi penuh dari sistem pengereman. <br><br>  Sejauh ini, masalah etika terbesar di bidang robomobiles adalah apakah cukup bukti telah dikumpulkan dalam simulasi perilaku aman mereka untuk dapat melepaskan robomobiles di jalanan.  Tetapi ini tidak berarti bahwa mereka akan "bermoral", atau akan menjadi seperti itu dalam waktu dekat.  Mengatakan sebaliknya adalah mengacaukan AI yang sempit, dengan IION, yang mungkin tidak akan muncul selama hidup kita. <br><br>  Pada akhirnya, robomobiles akan lebih aman daripada manusia.  Ini akan tercapai berkat desain mereka dan kemampuan untuk menghindari insiden dengan sekuat tenaga, atau untuk mengurangi kerusakan jika terjadi keniscayaan.  Namun, mesin tidak dapat membuat keputusan moral di mana bahkan kita tidak bisa.  Gagasan ini tetap merupakan fiksi, dan Anda tidak boleh berharap untuk itu.  Sebaliknya, kami fokus pada keamanan: iman di dalamnya akan dibenarkan. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id441704/">https://habr.com/ru/post/id441704/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id441694/index.html">Mengapa grafik lalu lintas "berbohong"</a></li>
<li><a href="../id441696/index.html">Sejarah Cyrillic LiveJournal: bagaimana manajemen Rusia menghancurkan kebangkitan blogging berbahasa Rusia</a></li>
<li><a href="../id441698/index.html">Disconnection: apa yang terjadi ketika Facebook ditinggalkan?</a></li>
<li><a href="../id441700/index.html">Bagaimana teka-teki anak-anak membantu mengungkap rahasia magnetisme</a></li>
<li><a href="../id441702/index.html">Pada penyimpanan data pribadi, Roskomnadzor dan situs kencan</a></li>
<li><a href="../id441706/index.html">Selusin perusahaan terkemuka sedang mencoba untuk membuat Lidar yang kuat dan murah</a></li>
<li><a href="../id441708/index.html">API Kontrak WG: kebun binatang layanan</a></li>
<li><a href="../id441710/index.html">Game seluler browser menantang Anda</a></li>
<li><a href="../id441712/index.html">Solusi matematika untuk masalah relativitas</a></li>
<li><a href="../id441714/index.html">Bagaimana lokomotif uap diatur?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêÜ ü¶ç ü§òüèø De nombreux personnages - de nombreux r√©seaux de neurones: comment construire un syst√®me de reconnaissance efficace pour un grand nombre de classes? ‚úåÔ∏è üï∫ ü§üüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans des articles pr√©c√©dents, ils ont d√©j√† √©crit sur le fonctionnement de notre technologie de reconnaissance de texte: 

 Navigateur de s√©rie 

- Rec...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>De nombreux personnages - de nombreux r√©seaux de neurones: comment construire un syst√®me de reconnaissance efficace pour un grand nombre de classes?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/438128/">  Dans des articles pr√©c√©dents, ils ont d√©j√† √©crit sur le fonctionnement de notre technologie de reconnaissance de texte: <br><br><div class="spoiler">  <b class="spoiler_title">Navigateur de s√©rie</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reconnaissance de texte dans ABBYY FineReader (1/2)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reconnaissance de texte dans ABBYY FineReader (2/2)</a> </li></ul><br></div></div><br>  Jusqu'en 2018, la reconnaissance des caract√®res japonais et chinois √©tait organis√©e de la m√™me mani√®re: tout d'abord, √† l'aide de classificateurs raster et d'entit√©s.  Mais avec la reconnaissance des hi√©roglyphes, il y a des difficult√©s: <br><br><ol><li>  Un grand nombre de classes √† distinguer. </li><li>  Caract√®re de l'appareil plus complexe dans son ensemble. </li></ol><br><img src="https://habrastorage.org/webt/fy/p7/yu/fyp7yudyxpraxbdsegon8y7w_xa.png" alt="image"><br><br>  Il est aussi difficile de dire sans √©quivoque combien de caract√®res l'alphabet chinois poss√®de par √©crit, car il est exact de compter le nombre de mots en russe.  Mais le plus souvent, en √©criture chinoise, environ 10 000 caract√®res sont utilis√©s.  Avec eux, nous avons limit√© le nombre de classes utilis√©es en reconnaissance. <br><br>  Les deux probl√®mes d√©crits ci-dessus conduisent √©galement au fait que pour atteindre une qualit√© √©lev√©e, vous devez utiliser un grand nombre de signes et ces signes eux-m√™mes sont calcul√©s sur les images des caract√®res plus longtemps. <br><br>  Pour que ces probl√®mes n'entra√Ænent pas de ralentissements s√©v√®res dans l'ensemble du syst√®me de reconnaissance, j'ai d√ª utiliser beaucoup d'heuristiques, visant principalement √† couper rapidement un nombre important de hi√©roglyphes, auxquels cette image ne ressemble d√©finitivement pas.  Cela n'a toujours pas aid√© √† la fin, mais nous voulions porter notre technologie √† un tout nouveau niveau. <br><br>  Nous avons commenc√© √† √©tudier l'applicabilit√© des r√©seaux de neurones convolutifs afin d'augmenter √† la fois la qualit√© et la vitesse de reconnaissance des hi√©roglyphes.  Je voulais remplacer l'unit√© enti√®re pour reconna√Ætre un seul caract√®re pour ces langues √† l'aide de r√©seaux de neurones.  Dans cet article, nous d√©crirons comment nous avons finalement r√©ussi. <br><a name="habracut"></a><br><h2>  Une approche simple: un r√©seau de convolution pour reconna√Ætre tous les hi√©roglyphes </h2><br>  En g√©n√©ral, l'utilisation de r√©seaux convolutifs pour la reconnaissance de caract√®res n'est pas du tout une id√©e nouvelle.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Historiquement, ils ont √©t√© utilis√©s</a> pour la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premi√®re fois</a> pr√©cis√©ment pour cette t√¢che en 1998.  Certes, il ne s'agissait pas de hi√©roglyphes imprim√©s, mais de lettres et de chiffres anglais manuscrits. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yg/fi/se/ygfisegze1bli8r9nyakftguapu.png"></div><br><br>  En 20 ans, la technologie dans le domaine du deep learning a bien s√ªr fait un bond en avant.  Incluant des architectures plus avanc√©es et de nouvelles approches d'apprentissage. <br><br>  L'architecture pr√©sent√©e dans le diagramme ci-dessus (LeNet), en fait, et est aujourd'hui tr√®s bien adapt√©e √† des t√¢ches aussi simples que la reconnaissance de texte imprim√©.  ¬´Simple¬ª, je l'appelle par rapport √† d'autres t√¢ches de vision par ordinateur telles que la recherche et la reconnaissance des visages. <br><br>  Il semblerait que la solution ne soit nulle part plus simple.  Nous prenons un r√©seau neuronal, un √©chantillon de hi√©roglyphes √©tiquet√©s et le formons pour le probl√®me de classification.  Malheureusement, il s'est av√©r√© que tout n'est pas si simple.  Toutes les modifications possibles de LeNet pour la t√¢che de classification de 10 000 hi√©roglyphes n'ont pas fourni une qualit√© suffisante (au moins comparable au syst√®me de reconnaissance que nous avons d√©j√†). <br><br>  Pour atteindre la qualit√© requise, nous avons d√ª envisager des architectures plus profondes et plus complexes: WideResNet, SqueezeNet, etc.  Avec leur aide, il a √©t√© possible d'atteindre le niveau de qualit√© requis, mais ils ont donn√© un fort ralentissement de la vitesse - 3-5 fois par rapport √† l'algorithme de base sur le CPU. <br><br>  Quelqu'un peut demander: "Quel est l'int√©r√™t de mesurer la vitesse du r√©seau sur le CPU, si cela fonctionne beaucoup plus vite sur le processeur graphique (GPU)"?  Ici, il convient de faire une remarque concernant le fait que la vitesse de l'algorithme sur le CPU est principalement importante pour nous.  Nous d√©veloppons une technologie pour la large gamme de produits de reconnaissance d'ABBYY.  Dans le plus grand nombre de sc√©narios, la reconnaissance se fait c√¥t√© client, et nous ne pouvons pas savoir qu'il dispose d'un GPU. <br><br>  Donc, √† la fin, nous sommes arriv√©s au probl√®me suivant: un r√©seau de neurones pour reconna√Ætre tous les caract√®res en fonction du choix de l'architecture fonctionne trop mal ou trop lentement. <br><br><h2>  Mod√®le de reconnaissance de hi√©roglyphes de r√©seau neuronal √† deux niveaux </h2><br>  J'ai d√ª chercher un autre moyen.  En m√™me temps, je ne voulais pas abandonner les r√©seaux de neurones.  Il semblait que le plus gros probl√®me √©tait un grand nombre de classes, √† cause de quoi il √©tait n√©cessaire de construire des r√©seaux d'architecture complexe.  Par cons√©quent, nous avons d√©cid√© que nous ne formerions pas un r√©seau pour un grand nombre de classes, c'est-√†-dire pour l'ensemble de l'alphabet, mais plut√¥t que nous formerions de nombreux r√©seaux pour un petit nombre de classes (sous-ensembles de l'alphabet). <br><br>  Dans les d√©tails g√©n√©raux, le syst√®me id√©al a √©t√© pr√©sent√© comme suit: l'alphabet est divis√© en groupes de caract√®res similaires.  Le r√©seau de premier niveau classe √† quel groupe de caract√®res appartient une image donn√©e.  Pour chaque groupe, √† son tour, un r√©seau de deuxi√®me niveau est form√©, qui produit la classification finale au sein de chaque groupe. <br><br>  <i>Image cliquable</i> <br> <a href=""><img src="https://habrastorage.org/webt/lg/r9/a1/lgr9a1ibz_vktq5xvkzqquawd7k.png"></a> <br><br>  Ainsi, nous faisons le classement final en lan√ßant deux r√©seaux: le premier d√©termine quel r√©seau de second niveau lancer, et le second fait d√©j√† le classement final. <br><br>  En fait, le point fondamental ici est de savoir comment diviser les personnages en groupes afin que le r√©seau de premier niveau puisse √™tre rendu pr√©cis et rapide. <br><br><h2>  Construire un classificateur de premier niveau </h2><br>  Pour comprendre quels symboles de r√©seau sont plus faciles √† distinguer et lesquels sont plus difficiles, il est plus facile de regarder quels signes se distinguent pour des symboles particuliers.  Pour ce faire, nous avons pris un r√©seau de classificateurs form√© pour distinguer tous les caract√®res de l'alphabet de bonne qualit√© et examin√© les statistiques d'activation de l'avant-derni√®re couche de ce r√©seau - nous avons commenc√© √† examiner les repr√©sentations des fonctionnalit√©s finales que le r√©seau re√ßoit pour tous les caract√®res. <br><br>  En m√™me temps, nous savions que la photo devait √™tre quelque chose comme ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sr/bw/el/srbwele_woukv5qioz-qr6vdq6g.png"></div><br><br>  Il s'agit d'un exemple simple dans le cas de la classification d'un √©chantillon de chiffres manuscrits (MNIST) en 10 classes.  Sur l'avant-derni√®re couche cach√©e, qui pr√©c√®de la classification, il n'y a que 2 neurones, ce qui facilite l'affichage de leurs statistiques d'activation dans l'avion.  Chaque point du graphique correspond √† un exemple de l'√©chantillon de test.  La couleur d'un point correspond √† une classe sp√©cifique. <br><br>  Dans notre cas, la dimension de l'espace caract√©ristique √©tait sup√©rieure √† 128 dans l'exemple. Nous avons ex√©cut√© un groupe d'images √† partir d'un √©chantillon de test et re√ßu un vecteur caract√©ristique pour chaque image.  Apr√®s cela, ils ont √©t√© normalis√©s (divis√©s par la longueur).  La photo ci-dessus montre clairement pourquoi cela vaut la peine.  Nous avons regroup√© les vecteurs normalis√©s par la m√©thode KMeans.  Nous avons obtenu une ventilation de l'√©chantillon en groupes d'images similaires (du point de vue du r√©seau). <br><br>  Mais √† la fin, nous devions obtenir une partition de l'alphabet en groupes, et non une partition de l'√©chantillon de test.  Mais la premi√®re de la seconde n'est pas difficile √† obtenir: il suffit d'attribuer chaque √©tiquette de classe au cluster qui contient le plus d'images de cette classe.  Dans la plupart des situations, bien s√ªr, toute la classe se retrouvera m√™me √† l'int√©rieur d'un cluster. <br><br>  Eh bien, c'est tout, nous avons obtenu une partition de l'alphabet entier en groupes de caract√®res similaires.  Reste alors √† choisir une architecture simple et √† former le classifieur pour distinguer ces groupes. <br><br>  Voici un exemple de 6 groupes al√©atoires qui sont obtenus en divisant l'alphabet source entier en 500 groupes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ge/14/zi/ge14ziruqvxamfjvh-zx6fchb3s.png"></div><br><h2>  Construction de classificateurs de deuxi√®me niveau </h2><br>  Ensuite, vous devez d√©cider des jeux de caract√®res cibles que les classificateurs de second niveau apprendront.  La r√©ponse semble √©vidente - il devrait s'agir de groupes de caract√®res obtenus √† l'√©tape pr√©c√©dente.  Cela fonctionnera, mais pas toujours avec une bonne qualit√©. <br><br>  Le fait est que le classificateur du premier niveau fait en tout cas des erreurs et elles peuvent √™tre partiellement compens√©es par la construction d'ensembles du deuxi√®me niveau comme suit: <br><br><ul><li>  Nous corrigeons un certain √©chantillon s√©par√© d'images de symboles (ne participant ni √† la formation ni aux tests); </li><li>  Nous ex√©cutons cet √©chantillon √† travers un classificateur de premier niveau form√©, marquant chaque image avec l'√©tiquette de ce classificateur (√©tiquette de groupe); </li><li>  Pour chaque symbole, nous consid√©rons tous les groupes possibles auxquels le classifieur du premier niveau appartient aux images de ce symbole; </li><li>  Ajoutez ce symbole √† tous les groupes jusqu'√† ce que le degr√© de couverture requis T_acc soit atteint; </li><li>  Nous consid√©rons les groupes finaux de symboles comme des ensembles cibles du deuxi√®me niveau, sur lesquels les classificateurs seront form√©s. </li></ul><br>  Par exemple, les images du symbole ¬´A¬ª ont √©t√© attribu√©es par le classificateur de premier niveau 980 fois au 5e groupe, 19 fois au 2e groupe et 1 fois au 6e groupe.  Au total, nous avons 1000 images de ce symbole. <br><br>  Ensuite, nous pouvons ajouter le symbole ¬´A¬ª au 5e groupe et obtenir une couverture de 98% de ce symbole.  Nous pouvons l'attribuer aux 5e et 2e groupes et obtenir une couverture de 99,9%.  Et nous pouvons imm√©diatement l'attribuer √† des groupes (5, 2, 6) et obtenir une couverture √† 100%. <br><br>  En substance, T_acc √©tablit un certain √©quilibre entre la vitesse et la qualit√©.  Plus elle est √©lev√©e, plus la qualit√© finale de la classification sera √©lev√©e, mais plus les ensembles cibles du deuxi√®me niveau seront grands et plus la classification au deuxi√®me niveau sera difficile. <br><br>  La pratique montre que m√™me avec T_acc = 1, l'augmentation de la taille des ensembles √† la suite de la proc√©dure de r√©approvisionnement d√©crite ci-dessus n'est pas si importante - en moyenne, environ 2 fois.  √âvidemment, cela d√©pendra directement de la qualit√© du classificateur de premier niveau form√©. <br><br>  Voici un exemple du fonctionnement de cette compl√©tion pour l'un des ensembles de la m√™me partition en 500 groupes, qui √©tait plus √©lev√©: <br><br><img src="https://habrastorage.org/webt/b6/kd/nh/b6kdnh829fmav36s41h2ygqzen0.png" alt="image"><br><br><h2>  R√©sultats d'int√©gration du mod√®le </h2><br>  Les mod√®les √† deux niveaux form√©s ont finalement fonctionn√© plus rapidement et mieux que les classificateurs pr√©c√©demment utilis√©s.  En fait, il n'√©tait pas si facile de ¬´se faire des amis¬ª avec le m√™me graphe de division lin√©aire (GLD).  Pour ce faire, j'ai d√ª enseigner s√©par√©ment le mod√®le pour distinguer les caract√®res des erreurs de segmentation des ordures et de segmentation a priori (pour retourner une faible confiance dans ces situations). <br><br>  R√©sultat final de l'int√©gration dans l'algorithme de reconnaissance de document complet ci-dessous (obtenu sur la collection de documents chinois et japonais), la vitesse est indiqu√©e pour l'algorithme complet: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7g/jq/oa/7gjqoavm4iu3xwanuakuhml4mhe.png"></div><br>  Nous avons am√©lior√© la qualit√© et acc√©l√©r√© √† la fois en mode normal et en mode rapide, tout en transf√©rant toute la reconnaissance des caract√®res aux r√©seaux de neurones. <br><br><h2>  Un peu sur la reconnaissance de bout en bout </h2><br>  Aujourd'hui, la plupart des syst√®mes OCR connus du public (le m√™me Tesseract de Google) utilisent l'architecture de bout en bout des r√©seaux de neurones pour reconna√Ætre les cha√Ænes ou leurs fragments dans son int√©gralit√©.  Mais ici, nous avons utilis√© les r√©seaux de neurones pr√©cis√©ment pour remplacer un module de reconnaissance de caract√®re unique.  Ce n'est pas un hasard. <br><br>  Le fait est que la segmentation d'une cha√Æne en caract√®res en chinois et en japonais imprim√©s n'est pas un gros probl√®me en raison de l'impression √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">espacement fixe</a> .  √Ä cet √©gard, l'utilisation de la reconnaissance de bout en bout pour ces langues n'am√©liore pas consid√©rablement la qualit√©, mais elle est beaucoup plus lente (au moins sur le processeur).  En g√©n√©ral, il n'est pas clair comment utiliser l'approche √† deux niveaux propos√©e dans le contexte de bout en bout. <br><br>  Au contraire, il existe des langues pour lesquelles la division lin√©aire en caract√®res est un probl√®me cl√©.  Des exemples explicites sont l'arabe, l'hindi.  Pour l'arabe, par exemple, les solutions de bout en bout sont d√©j√† activement √©tudi√©es avec nous.  Mais c'est une histoire compl√®tement diff√©rente. <br><br>  <i>Alexey Zhuravlev, responsable du groupe OCR New Technologies</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr438128/">https://habr.com/ru/post/fr438128/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr438118/index.html">Dex-Net 4.0 permet aux robots Ambidextro de choisir le meilleur</a></li>
<li><a href="../fr438120/index.html">Le condens√© des √©v√©nements pour les professionnels des RH dans le domaine des TI pour f√©vrier 2019</a></li>
<li><a href="../fr438122/index.html">Num√©rologie sur MS SQL - une exp√©rience amusante</a></li>
<li><a href="../fr438124/index.html">Piter GraphQL: vid√©os de mitap dans Wrike</a></li>
<li><a href="../fr438126/index.html">Dipl√¥m√©s de stages informatiques √† Raiffeisenbank - comment c'√©tait</a></li>
<li><a href="../fr438130/index.html">Neutralinojs - une alternative aux √©lectrons qui consomme moins de m√©moire</a></li>
<li><a href="../fr438132/index.html">GOSINT - une solution open source pour la gestion des indicateurs de compromis (IoC)</a></li>
<li><a href="../fr438134/index.html">Installation de syst√®mes de vid√©osurveillance: belles et malheureuses histoires avec des cam√©ras</a></li>
<li><a href="../fr438136/index.html">Consentement au traitement des donn√©es RGPD: analyse d√©taill√©e</a></li>
<li><a href="../fr438138/index.html">Anatomie du faucon</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
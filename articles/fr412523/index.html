<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëõ üë©üèø‚Äç‚úàÔ∏è üëÆ ConvNets. Prototype d'un projet √† l'aide du masque R-CNN üêç ü§¶üèª üë®üèª‚Äç‚úàÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! Enfin, nous avons attendu une autre partie de la s√©rie de documents du dipl√¥m√© de nos programmes de Big Data Specialist et Deep Learnin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ConvNets. Prototype d'un projet √† l'aide du masque R-CNN</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/newprolab/blog/412523/">  Bonjour, Habr!  Enfin, nous avons attendu une autre partie de la s√©rie de documents du dipl√¥m√© de nos programmes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Big Data Specialist</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deep Learning</a> , Cyril Danilyuk, sur l'utilisation de Mask R-CNN, les r√©seaux de neurones actuellement populaires, dans le cadre d'un syst√®me de classification des images, √† savoir √©valuer la qualit√© d'un plat pr√©par√© √† l'aide d'un ensemble de donn√©es provenant de capteurs. <br><br>  Apr√®s avoir examin√© l'ensemble de donn√©es sur les jouets consistant en des images de panneaux de signalisation dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article pr√©c√©dent</a> , nous pouvons maintenant r√©soudre le probl√®me que j'ai rencontr√© dans la vie r√©elle: <b>¬´Est-il possible de mettre en ≈ìuvre l'algorithme d'apprentissage profond, qui pourrait distinguer les plats de haute qualit√© des mauvais plats un par un des photos? "</b>  .  En bref, l'entreprise voulait cela: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fv/_o/vv/fv_ovvsls8uz-qdmfurmijy-qbk.png"></div>  <sub>Ce qu'une entreprise repr√©sente lorsqu'elle pense au machine learning:</sub> <br><a name="habracut"></a><br>  Ceci est un exemple d'un probl√®me mal pos√©: dans ce cas, il est impossible de d√©terminer si une solution existe, si elle est unique et stable.  De plus, l'√©nonc√© du probl√®me lui-m√™me est tr√®s vague, sans parler de la mise en ≈ìuvre de sa solution.  Bien s√ªr, cet article n'est pas consacr√© √† l'efficacit√© de la communication ou de la gestion de projet, mais il est important de le noter: <b>ne jamais prendre en charge des projets dont le r√©sultat final n'est pas d√©fini et enregistr√© dans les TdR.</b>  L'un des moyens les plus fiables pour faire face √† une telle incertitude est de construire d'abord un prototype, puis, en utilisant de nouvelles connaissances, de structurer le reste de la t√¢che.  C'est ce que nous avons fait. <br><br><h3>  √ânonc√© du probl√®me </h3><br>  Dans mon prototype, je me suis concentr√© sur un plat du menu - une omelette - et j'ai construit un pipeline √©volutif, qui d√©termine la "qualit√©" de l'omelette √† la sortie.  Cela peut √™tre d√©crit plus en d√©tail comme suit: <br><br><ul><li>  <b>Type de probl√®me:</b> classification multiclasse avec 6 classes de qualit√© discr√®tes: <i>bonne</i> (bonne), <i>jaune cass√©</i> (avec jaune d'≈ìuf √©tal√©), <i>grill√©</i> (trop cuit), deux ≈ìufs (deux ≈ìufs), quatre ≈ìufs (quatre ≈ìufs), morceaux <i>mal plac√©s</i> (avec des morceaux dispers√©s sur une plaque) . </li><li> <b>Ensemble de donn√©es:</b> 351 photographies collect√©es manuellement de diverses omelettes.  Echantillons de formation / validation / test: 139/32/180 photos mixtes. </li><li>  <b>Labels de classe:</b> chaque photo correspond √† un label de classe correspondant √† une √©valuation subjective de la qualit√© de l'omelette. </li><li>  <b>M√©trique:</b> entropie crois√©e cat√©gorique. </li><li>  <b>Connaissance minimale du domaine: une</b> omelette de ¬´qualit√©¬ª devrait ressembler √† ceci: elle se compose de trois ≈ìufs, d'une petite quantit√© de bacon, d'une feuille de persil au centre, n'a pas de jaunes √©tal√©s et de morceaux trop cuits.  De plus, la composition globale doit ¬´bien para√Ætre¬ª, c'est-√†-dire que les pi√®ces ne doivent pas √™tre dispers√©es sur toute la plaque. </li><li>  <b>Crit√®re d'ach√®vement: la</b> meilleure valeur de l'entropie crois√©e dans l'√©chantillon test parmi tous les possibles apr√®s deux semaines de d√©veloppement du prototype. </li><li>  <b>La m√©thode de visualisation finale:</b> t-SNE sur l'espace de donn√©es d'une plus petite dimension. </li></ul><br><img src="https://habrastorage.org/webt/yb/8i/uk/yb8iuk0ics242w3vpztsjefgucg.png"><br>  <sub>Images d'entr√©e</sub> <br><br>  Le principal objectif du pipeline est d'apprendre √† combiner plusieurs types de signaux (par exemple, des images sous diff√©rents angles, une carte thermique, etc.), apr√®s avoir re√ßu une repr√©sentation pr√©compress√©e de chacun d'eux et passer ces caract√©ristiques √† travers le classificateur de r√©seau neuronal pour la pr√©diction finale.  Ainsi, nous pouvons r√©aliser notre prototype et le rendre pratiquement applicable dans d'autres travaux.  Voici quelques-uns des signaux utilis√©s dans le prototype: <br><br><ul><li>  Masques d'ingr√©dients cl√©s (masque R-CNN): <i>signal n ¬∞ 1</i> . </li><li>  Le nombre d'ingr√©dients cl√©s sur le cadre., <i>Num√©ro de signal 2</i> . </li><li>  Recadrage RVB de plaques avec omelette sans fond.  Pour plus de simplicit√©, j'ai d√©cid√© de ne pas les ajouter au mod√®le pour le moment, bien qu'ils soient le signal le plus √©vident: √† l'avenir, vous pouvez entra√Æner le r√©seau neuronal convolutionnel pour la classification en utilisant une fonction de <i>perte de triplet</i> ad√©quate, calculer les plongements d'images et couper la <i>distance L2</i> du courant Des images √† perfectionner.  Malheureusement, je n'ai pas eu l'occasion de tester cette hypoth√®se, car l'√©chantillon de test ne comprenait que 139 objets. </li></ul><br><h3>  Vue g√©n√©rale du pipeline </h3><br>  Je note que je devrai ignorer quelques √©tapes importantes, telles que l'analyse exploratoire des donn√©es, la construction d'un classificateur de base et l'√©tiquetage actif (mon terme propos√©, qui signifie annotation semi-automatique d'objets, inspir√© de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vid√©o de d√©monstration Polygon-RNN</a> ) pour le masque R-CNN (en savoir plus sur ceci dans les prochains articles). <br><br>  Jetez un ≈ìil √† l'ensemble du pipeline en g√©n√©ral: <br><br><img src="https://habrastorage.org/webt/er/bd/m2/erbdm2blw4soc4vjtoabjlwbbrg.png"><br>  <sub>Dans cet article, nous nous int√©ressons aux √©tapes de Mask R-CNN et au classement au sein du pipeline.</sub> <br><br>  Ensuite, nous consid√©rerons trois √©tapes: 1) utiliser le masque R-CNN pour construire des masques d'ingr√©dients d'omelette;  2) classificateur ConvNet bas√© sur Keras;  3) visualisation des r√©sultats en utilisant t-SNE. <br><br><h3>  √âtape 1: Masque R-CNN et masques de construction </h3><br>  Le masque R-CNN (MRCNN) a r√©cemment connu un pic de popularit√©.  √Ä partir de l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article Facebook</a> original et se terminant par le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Data Science Bowl 2018</a> √† Kaggle, Mask R-CNN s'est impos√© comme une architecture puissante pour la segmentation par exemple (c'est-√†-dire non seulement la segmentation d'image pixel par pixel, mais aussi la s√©paration de plusieurs objets appartenant √† la m√™me classe )  De plus, c'est un plaisir de travailler avec la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mise en ≈ìuvre du MRCNN √† partir de Matterport</a> dans le Keras.  Le code est bien structur√©, a une bonne documentation et fonctionne d√®s la sortie de la bo√Æte, bien que plus lentement que pr√©vu. <br><br>  En pratique, en particulier lors du d√©veloppement d'un prototype, il est essentiel d'avoir un r√©seau neuronal convolutionnel pr√©-form√©.  Dans la plupart des cas, l'ensemble de donn√©es √©tiquet√©es du data scientist est tr√®s limit√© ou pas du tout, tandis que ConvNet n√©cessite beaucoup de donn√©es √©tiquet√©es pour atteindre la convergence (par exemple, l'ensemble de donn√©es ImageNet contient 1,2 million d'images √©tiquet√©es).  Ici, l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprentissage par transfert</a> vient √† la rescousse: nous pouvons fixer le poids des couches convolutives et recycler uniquement le classificateur.  La fixation des couches convolutives est importante pour les petits ensembles de donn√©es, car cette technique emp√™che le recyclage. <br><br>  Voici ce que j'ai obtenu apr√®s la premi√®re √®re de recyclage: <br><br><img src="https://habrastorage.org/webt/ru/g-/cv/rug-cvztg2vpv85obstkuvhl7-4.png"><br>  <sub>R√©sultat de la segmentation des objets: tous les ingr√©dients cl√©s reconnus</sub> <br><br>  √Ä l'√©tape suivante du pipeline ( <i>Process Inferenced Data for Classifier</i> ), il est n√©cessaire de d√©couper la partie de l'image qui contient la plaque et d'extraire le masque binaire bidimensionnel pour chaque ingr√©dient de cette plaque: <br><br><img src="https://habrastorage.org/webt/qg/62/5p/qg625pze9oobq1ttlp0ryp6beuk.png"><br>  <sub>Image recadr√©e avec des ingr√©dients cl√©s sous forme de masques binaires.</sub> <br><br>  Ces masques binaires sont ensuite combin√©s en une image √† 8 canaux (puisque j'ai d√©fini 8 classes de masques pour MRCNN), et nous obtenons le <i>signal n ¬∞ 1</i> : <br><br><img src="https://habrastorage.org/webt/l7/3w/8p/l73w8p1ztuu_udp5mmq7ro9knsk.png"><br>  <sub><i>Signal n ¬∞ 1</i> : image √† 8 canaux compos√©e de masques binaires.</sub>  <sub>En couleur pour une meilleure visualisation.</sub> <br><br>  Pour obtenir le <i>signal n ¬∞ 2</i> , j'ai compt√© le nombre de fois que chaque ingr√©dient est trouv√© sur la r√©colte de la plaque et j'ai obtenu un ensemble de vecteurs de caract√©ristiques, chacun correspondant √† sa r√©colte. <br><br><h3>  √âtape 2: ConvNet Classifier dans Keras </h3><br>  Le classificateur CNN a √©t√© impl√©ment√© √† partir de z√©ro √† l'aide de Keras.  Je voulais combiner plusieurs signaux ( <i>signal n ¬∞ 1</i> et <i>signal n ¬∞ 2</i> , ainsi que l'ajout √©ventuel de donn√©es √† l'avenir) et laisser les r√©seaux de neurones les utiliser pour faire des pr√©visions concernant la qualit√© de la parabole.  L'architecture pr√©sent√©e ci-dessous est d'essai et loin d'√™tre id√©ale: <br><br><img src="https://habrastorage.org/webt/zb/ow/y4/zbowy4ebvcigyosde3wv3ni-ziq.jpeg"><br><br>  Quelques mots sur l'architecture du classifieur: <br><br><ul><li>  <b>Module convolutionnel √† plusieurs √©chelles</b> : J'ai d'abord choisi un filtre 5x5 pour les couches convolutionnelles, mais cela n'a conduit qu'√† un r√©sultat satisfaisant.  Des am√©liorations ont √©t√© obtenues en appliquant <i>AveragePooling2D</i> √† plusieurs couches avec diff√©rents filtres: 3x3, 5x5, 7x7, 11x11.  Une couche convolutionnelle 1x1 suppl√©mentaire a √©t√© ajout√©e devant chacune des couches pour r√©duire la dimension.  Ce composant est un peu comme un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">module Inception</a> , m√™me si je n'avais pas pr√©vu de construire un r√©seau trop profond. </li><li>  <b>Filtres plus grands</b> : j'ai utilis√© des filtres plus grands, car ils aident √† extraire facilement des signes plus grands de l'image d'entr√©e (qui est elle-m√™me essentiellement une couche d'activation avec 8 filtres - le masque de chaque ingr√©dient peut √™tre consid√©r√© comme un filtre s√©par√©). </li><li>  <b>Combinaison de signaux</b> : dans mon impl√©mentation na√Øve, une seule couche a √©t√© utilis√©e pour connecter deux ensembles d'attributs: les masques binaires trait√©s ( <i>signal n ¬∞ 1</i> ) et les ingr√©dients compt√©s ( <i>signal n ¬∞ 2</i> ).  Cependant, malgr√© sa simplicit√©, l'ajout du <i>signal n ¬∞ 2</i> a permis de r√©duire la m√©trique d'entropie crois√©e de <i>0,8</i> √† <i>[0,7, 0,72]</i> . </li><li>  <b>Logits</b> : en termes de TensorFlow, logit est une couche sur laquelle <i>tf.nn.softmax_cross_entropy_with_logits</i> est appliqu√© pour calculer <i>la perte de lot</i> . </li></ul><br><h3>  √âtape 3: visualisation des r√©sultats √† l'aide de t-SNE </h3><br>  Pour visualiser les r√©sultats du classificateur sur les donn√©es de test, j'ai utilis√© t-SNE - un algorithme qui vous permet de transf√©rer les donn√©es source vers un espace de dimension inf√©rieure (pour comprendre le principe de l'algorithme, je recommande de lire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'article original</a> , il est extr√™mement informatif et bien √©crit). <br><br>  Avant la visualisation, j'ai pris des images de test, extrait la couche logite du classificateur et appliqu√© l'algorithme t-SNE √† cet ensemble de donn√©es.  Bien que je n'ai pas essay√© diff√©rentes valeurs du param√®tre de perplexit√©, le r√©sultat semble toujours assez bon: <br><br><img src="https://habrastorage.org/webt/er/yk/ic/erykictzlrzdvhchpvli86c8lwi.gif"><br>  <sub>Le r√©sultat du t-SNE sur les donn√©es de test avec les pr√©dictions du classificateur</sub> <br><br>  Bien s√ªr, cette approche est imparfaite, mais elle fonctionne.  Il peut y avoir plusieurs am√©liorations possibles: <br><br><ul><li>  <b>Plus de donn√©es.</b>  Les r√©seaux de convolution n√©cessitent beaucoup de donn√©es et je n'avais que 139 images pour la formation.  Des techniques telles que l'augmentation des donn√©es fonctionnent bien (j'ai utilis√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">D4 ou une augmentation sym√©trique des di√®dres</a> , ce qui donne plus de 2 000 images), mais il est toujours extr√™mement important d'avoir plus de donn√©es r√©elles. </li><li>  <b>Fonction de perte plus appropri√©e.</b>  Pour plus de simplicit√©, j'ai utilis√© une entropie crois√©e cat√©gorique, ce qui est bien car cela fonctionne d√®s la sortie de la bo√Æte.  La meilleure option serait d'utiliser la fonction de perte, qui prend en compte la variation au sein des classes, par exemple, la fonction de perte de triplet (voir l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article FaceNet</a> ). </li><li>  <b>Am√©lioration de l'architecture du classificateur.</b>  Le classificateur actuel est essentiellement un prototype, dont le seul but est de construire des masques binaires et de combiner plusieurs ensembles de fonctionnalit√©s pour former un seul pipeline. </li><li>  <b>Am√©lioration de la disposition des images.</b>  J'√©tais tr√®s b√¢cl√© lors du balisage manuel des images: le classificateur a fait ce travail mieux que moi sur une dizaine d'images de test. </li></ul><br>  <b>Conclusion</b>  Il faut enfin reconna√Ætre que l'entreprise n'a ni donn√©es, ni explications, ni m√™me une t√¢che plus clairement d√©finie √† r√©soudre.  Et c'est bien (sinon, pourquoi ont-ils besoin de vous?), Car votre travail consiste √† utiliser divers outils, des processeurs multic≈ìurs, des mod√®les pr√©-form√©s et un m√©lange d'expertise technique et commerciale pour cr√©er de la valeur ajout√©e dans l'entreprise. <br><br>  Commencez petit: un prototype fonctionnel peut √™tre cr√©√© √† partir de plusieurs blocs de code jouets, et il augmentera consid√©rablement la productivit√© des conversations ult√©rieures avec la direction de l'entreprise.  C'est le travail d'un scientifique des donn√©es - pour offrir aux entreprises de nouvelles approches et id√©es. <br><br><hr><br>  Le 20 septembre 2018, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Big Data Specialist 9.0¬ª</a> commence, o√π, entre autres, vous apprendrez √† visualiser les donn√©es et √† comprendre la logique m√©tier derri√®re telle ou telle t√¢che, ce qui vous aidera √† pr√©senter plus efficacement les r√©sultats de votre travail √† vos coll√®gues et √† la direction. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr412523/">https://habr.com/ru/post/fr412523/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr412513/index.html">Comment devenir chef de produit sans exp√©rience?</a></li>
<li><a href="../fr412515/index.html">DJI Ronin-S lance ses ventes</a></li>
<li><a href="../fr412517/index.html">AGPM - Comme Git pour la strat√©gie de groupe. Presque</a></li>
<li><a href="../fr412519/index.html">Cam√©scope HD sans batterie sans fil</a></li>
<li><a href="../fr412521/index.html">SOC is People: Cours de recyclage Jedi</a></li>
<li><a href="../fr412527/index.html">Crowdfunding pour l'astronautique sur l'exemple du projet 435nm</a></li>
<li><a href="../fr412529/index.html">O√π payer plus aux programmeurs. Comparez 22 pays</a></li>
<li><a href="../fr412531/index.html">Battle Space Laser "Skiff"</a></li>
<li><a href="../fr412533/index.html">Localisation des donn√©es personnelles des non-russes</a></li>
<li><a href="../fr412535/index.html">Entretien avec ¬´Alice's Chief Brain¬ª</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
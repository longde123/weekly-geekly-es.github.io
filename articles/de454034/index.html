<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§æüèº üìô üëäüèø Erstes Modell: Fashion MNIST Dataset üë®üèø‚Äçüöí üå°Ô∏è üëã</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Den vollst√§ndigen Kurs in Russisch finden Sie unter diesem Link . 
 Der urspr√ºngliche Englischkurs ist unter diesem Link verf√ºgbar. 

 Alle 2-3 Tage s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstes Modell: Fashion MNIST Dataset</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454034/">  Den vollst√§ndigen Kurs in Russisch finden Sie unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Link</a> . <br>  Der urspr√ºngliche Englischkurs ist unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Link</a> verf√ºgbar. <br><img src="https://habrastorage.org/webt/ry/3a/55/ry3a55ljajwq9gp5jwwhztrxyxo.png"><br>  <i>Alle 2-3 Tage sind neue Vortr√§ge geplant.</i> <br><a name="habracut"></a><br><h2>  Interview mit Sebastian Trun, CEO Udacity </h2><br>  "Also sind wir immer noch bei dir und bei uns, wie zuvor, Sebastian."  Wir wollen nur vollst√§ndig verbundene Schichten diskutieren, dieselben dichten Schichten.  Vorher m√∂chte ich eine Frage stellen.  Was sind die Grenzen und was sind die Haupthindernisse, die dem tiefen Lernen im Wege stehen und in den n√§chsten 10 Jahren den gr√∂√üten Einfluss darauf haben werden?  Alles √§ndert sich so schnell!  Was denkst du wird das n√§chste "gro√üe Ding" sein? <br>  - Ich w√ºrde zwei Dinge sagen.  Die erste ist die allgemeine KI f√ºr mehr als eine Aufgabe.  Das ist gro√üartig!  Menschen k√∂nnen mehr als ein Problem l√∂sen und sollten niemals dasselbe tun.  Die zweite ist die Markteinf√ºhrung von Technologie.  F√ºr mich ist die Besonderheit des maschinellen Lernens, dass es Computern die M√∂glichkeit bietet, Muster in Daten zu beobachten und zu finden, und Menschen dabei hilft, die besten auf dem Gebiet zu werden - auf Expertenebene!  Maschinelles Lernen kann in Recht, Medizin und autonomen Autos eingesetzt werden.  Entwickeln Sie solche Anwendungen, weil sie eine Menge Geld bringen k√∂nnen, aber vor allem haben Sie die M√∂glichkeit, die Welt zu einem viel besseren Ort zu machen. <br>  - Ich mag die Art und Weise, wie Sie alles in einem einzigen Bild des tiefen Lernens und seiner Anwendung zusammenfassen. Dies ist nur ein Werkzeug, mit dem Sie ein bestimmtes Problem l√∂sen k√∂nnen. <br>  - Ja genau!  Unglaubliches Werkzeug, richtig? <br>  - Ja, ja, ich stimme dir vollkommen zu! <br>  "Fast wie ein menschliches Gehirn!" <br>  - Sie haben in unserem ersten Interview im ersten Teil des Videokurses medizinische Anwendungen erw√§hnt.  In welchen Anwendungen sorgt Ihrer Meinung nach der Einsatz von Deep Learning f√ºr die gr√∂√üte Freude und √úberraschung? <br>  - Sehr viel!  Sehr!  Die Medizin steht auf der kurzen Liste der Bereiche, in denen Deep Learning aktiv eingesetzt wird.  Ich habe meine Schwester vor ein paar Monaten verloren, sie war an Krebs erkrankt, was sehr traurig ist.  Ich denke, es gibt viele Krankheiten, die fr√ºher erkannt werden k√∂nnten - in den fr√ºhen Stadien, die es erm√∂glichen, den Prozess ihrer Entwicklung zu heilen oder zu verlangsamen.  Die Idee ist in der Tat, einige Werkzeuge in das Haus (Smart Home) zu √ºbertragen, so dass es m√∂glich ist, solche Gesundheitsabweichungen lange vor dem Moment zu erkennen, in dem die Person sie selbst sieht.  Ich w√ºrde auch hinzuf√ºgen - alles wird wiederholt, jede B√ºroarbeit, bei der Sie immer wieder die gleichen Aktionen ausf√ºhren, zum Beispiel die Buchhaltung.  Sogar ich als CEO mache viele sich wiederholende Aktionen.  Es w√§re gro√üartig, sie zu automatisieren und sogar mit E-Mail-Korrespondenz zu arbeiten! <br>  - Ich kann dir nicht widersprechen!  In dieser Lektion werden wir den Sch√ºlern einen Kurs mit einer neuronalen Netzwerkschicht vorstellen, die als dichte Schicht bezeichnet wird.  K√∂nnen Sie uns genauer sagen, was Sie von vollst√§ndig verbundenen Schichten halten? <br>  - Beginnen wir also damit, dass jedes Netzwerk auf unterschiedliche Weise verbunden werden kann.  Einige von ihnen verf√ºgen m√∂glicherweise √ºber eine sehr enge Konnektivit√§t, wodurch Sie einige Vorteile bei der Skalierung erzielen und gegen gro√üe Netzwerke ‚Äûgewinnen‚Äú k√∂nnen.  Manchmal wissen Sie nicht, wie viele Verbindungen Sie ben√∂tigen, also verbinden Sie alles mit allem - dies wird als vollst√§ndig verbundene Schicht bezeichnet.  Ich f√ºge hinzu, dass dieser Ansatz viel mehr Kraft und Potenzial hat als etwas strukturierteres. <br>  - Ich stimme dir vollkommen zu!  Vielen Dank, dass Sie uns dabei helfen, mehr √ºber vollst√§ndig verbundene Ebenen zu erfahren.  Ich freue mich auf den Moment, in dem wir endlich beginnen, sie zu implementieren und Code zu schreiben. <br>  - Viel Spa√ü!  Es wird wirklich Spa√ü machen! <br><br><h2>  Einf√ºhrung </h2><br>  - Willkommen zur√ºck!  In der letzten Lektion haben Sie herausgefunden, wie Sie mit TensorFlow und Keras Ihr erstes neuronales Netzwerk aufbauen, wie neuronale Netzwerke funktionieren und wie der Trainingsprozess funktioniert.  Insbesondere haben wir gesehen, wie das Modell trainiert wird, um Grad Celsius in Grad Fahrenheit umzurechnen. <br><br><img src="https://habrastorage.org/webt/7h/jc/jq/7hjcjqzg5rz1qzpbncjes5ipor8.jpeg"><br><br>  - Wir haben auch das Konzept der vollst√§ndig verbundenen Schichten (dichten Schichten) kennengelernt, der wichtigsten Schicht in neuronalen Netzen.  Aber in dieser Lektion werden wir viel coolere Dinge tun!  In dieser Lektion werden wir ein neuronales Netzwerk entwickeln, das Kleidungselemente und Bilder erkennen kann.  Wie bereits erw√§hnt, verwendet das maschinelle Lernen Eingaben, die als "Features" bezeichnet werden, und Ausgaben, die als "Labels" bezeichnet werden, anhand derer das Modell einen Transformationsalgorithmus lernt und findet.  Daher werden wir zun√§chst viele Beispiele ben√∂tigen, um das neuronale Netzwerk zu trainieren, um verschiedene Elemente der Kleidung zu erkennen.  Ich m√∂chte Sie daran erinnern, dass ein Beispiel f√ºr das Training ein Wertepaar ist - eine Eingabefunktion und eine Ausgabebezeichnung, die der Eingabe eines neuronalen Netzwerks zugef√ºhrt werden.  In unserem neuen Beispiel wird das Bild als Eingabe verwendet, und das Ausgabeetikett sollte die Kleidungskategorie sein, zu der das auf dem Bild gezeigte Kleidungsst√ºck geh√∂rt.  Gl√ºcklicherweise existiert ein solcher Datensatz bereits.  Es hei√üt Fashion MNIST.  Wir werden uns diesen Datensatz im n√§chsten Teil genauer ansehen. <br><br><h2>  Mode MNIST Datensatz </h2><br>  Willkommen in der Welt des MNIST-Datensatzes!  Unser Set besteht also aus 28 x 28 Bildern, von denen jedes Pixel einen Grauton darstellt. <br><br><img src="https://habrastorage.org/webt/ua/mr/f6/uamrf6n8gci7qi2c1t_ganxtai8.jpeg"><br><br>  Der Datensatz enth√§lt Bilder von T-Shirts, Tops, Sandalen und sogar Stiefeln.  Hier ist eine vollst√§ndige Liste unserer MNIST-Datens√§tze: <br><br><img src="https://habrastorage.org/webt/3i/ce/7n/3ice7nwlkok2g_n-trodker5s7e.jpeg"><br><br>  Jedes Eingabebild entspricht einer der obigen Beschriftungen.  Der Fashion MNIST-Datensatz enth√§lt 70.000 Bilder, sodass wir einen Ort haben, an dem wir beginnen und arbeiten k√∂nnen.  Von diesen 70.000 werden wir 60.000 verwenden, um das neuronale Netzwerk zu trainieren. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Und wir werden die verbleibenden 10.000 Elemente verwenden, um zu √ºberpr√ºfen, wie gut unser neuronales Netzwerk gelernt hat, Kleidungselemente zu erkennen.  Sp√§ter werden wir erkl√§ren, warum wir den Datensatz in einen Trainingssatz und einen Testsatz unterteilt haben. <br><br>  Hier ist also unser Fashion MNIST-Datensatz. <br><br><img src="https://habrastorage.org/webt/mx/lw/dz/mxlwdzjrfhviwmgsliwdcy6tbwq.png"><br><br>  Denken Sie daran, dass jedes Bild im Datensatz ein Bild der Gr√∂√üe 28 x 28 in Graustufen ist. Dies bedeutet, dass jedes Bild eine Gr√∂√üe von 784 Byte hat.  Unsere Aufgabe ist es, ein neuronales Netzwerk zu erstellen, das diese 784 Bytes am Eingang empf√§ngt und am Ausgang zur√ºckgibt, zu welcher von 10 verf√ºgbaren Kleidungskategorien das am Eingang angewendete Element geh√∂rt. <br><br><h2>  Neuronales Netz </h2><br>  In dieser Lektion verwenden wir ein tiefes neuronales Netzwerk, das lernt, Bilder aus dem Fashion MNIST-Datensatz zu klassifizieren. <br><br><img src="https://habrastorage.org/webt/xg/cr/h_/xgcrh_cowdhfz-owx34wp-kqzi0.png"><br><br>  Das Bild oben zeigt, wie unser neuronales Netzwerk aussehen wird.  Schauen wir uns das genauer an. <br><br>  Der Eingabewert unseres neuronalen Netzwerks ist ein eindimensionales Array mit einer L√§nge von 784, ein Array mit genau dieser L√§nge, da jedes Bild 28 x 28 Pixel (= insgesamt 784 Pixel im Bild) betr√§gt, das wir in ein eindimensionales Array konvertieren.  Das Konvertieren eines 2D-Bildes in einen Vektor wird als Abflachung bezeichnet und durch eine Gl√§ttungsschicht - eine Abflachungsebene - implementiert. <br><br><img src="https://habrastorage.org/webt/7d/wu/d_/7dwud_tt2qctnaigzc8my3pz1j0.png"><br><br>  Sie k√∂nnen eine Gl√§ttung durchf√ºhren, indem Sie die entsprechende Ebene erstellen: <br><br><pre><code class="python hljs">tf.keras.layers.Flatten(input_shape=[<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Diese Ebene konvertiert ein 2D-Bild mit 28 x 28 Pixeln (1 Byte f√ºr Graustufen f√ºr jedes Pixel) in ein 1D-Array mit 784 Pixeln. <br><br>  Die Eingabewerte werden vollst√§ndig mit unserer ersten <code>dense</code> Netzwerkschicht verkn√ºpft, deren Gr√∂√üe wir gleich 128 Neuronen gew√§hlt haben. <br><br><img src="https://habrastorage.org/webt/mk/n_/3w/mkn_3wrocxruhbwhil0fmh5wh_8.png"><br><br>  So sieht die Erstellung dieser Ebene im Code aus: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu)</code> </pre><br>  H√∂r auf!  Was ist <code>tf.nn.relu</code> ?  Wir haben dies in unserem vorherigen Beispiel f√ºr ein neuronales Netzwerk nicht verwendet, als wir Grad Celsius in Grad Fahrenheit umgerechnet haben!  Das Fazit ist, dass die aktuelle Aufgabe viel komplizierter ist als die, die als Beispiel f√ºr die Ermittlung von Fakten verwendet wurde - die Umrechnung von Grad Celsius in Grad Fahrenheit. <br><br>  <code>ReLU</code> ist eine mathematische Funktion, die wir unserer vollst√§ndig verbundenen Schicht hinzuf√ºgen und die unserem Netzwerk mehr Leistung verleiht.  Tats√§chlich ist dies eine kleine Erweiterung f√ºr unsere vollst√§ndig verbundene Schicht, die es unserem neuronalen Netzwerk erm√∂glicht, komplexere Probleme zu l√∂sen.  Wir werden nicht auf Details eingehen, aber ein wenig detailliertere Informationen finden Sie unten. <br><br>  Schlie√ülich besteht unsere letzte Schicht, auch als Ausgangsschicht bekannt, aus 10 Neuronen.  Es besteht aus 10 Neuronen, da unser Fashion MNIST-Datensatz 10 Kleidungskategorien enth√§lt.  Jeder dieser 10 Ausgabewerte repr√§sentiert die Wahrscheinlichkeit, dass sich das Eingabebild in dieser Kleidungskategorie befindet.  Mit anderen Worten, diese Werte spiegeln das ‚ÄûVertrauen‚Äú des Modells in die Richtigkeit der Vorhersage und Korrelation des abgelegten Bildes mit einer bestimmten von 10 Kleidungskategorien am Ausgang wider.  Wie hoch ist beispielsweise die Wahrscheinlichkeit, dass das Bild ein Kleid, Turnschuhe, Schuhe usw. zeigt? <br><br><img src="https://habrastorage.org/webt/fo/2b/3v/fo2b3vakws6ubmiwtj9rrctltla.png"><br><br>  Wenn beispielsweise ein Hemdbild an die Eingabe unseres neuronalen Netzwerks gesendet wird, kann das Modell Ergebnisse liefern, wie Sie sie im obigen Bild sehen - die Wahrscheinlichkeit, dass das Eingabebild mit dem Ausgabeetikett √ºbereinstimmt. <br><br>  Wenn Sie darauf achten, werden Sie feststellen, dass sich die gr√∂√üte Wahrscheinlichkeit - 0,85 - auf Tag 6 bezieht, das dem Shirt entspricht.  Das Modell ist zu 85% sicher, dass das Bild auf dem Shirt.  Normalerweise haben Dinge, die wie Hemden aussehen, auch eine hohe Wahrscheinlichkeitsbewertung, und Dinge, die am wenigsten √§hnlich sind, haben eine niedrigere Wahrscheinlichkeitsbewertung. <br><br>  Da alle 10 Ausgabewerte Wahrscheinlichkeiten entsprechen, erhalten wir beim Summieren aller dieser Werte 1. Diese 10 Werte werden auch als Wahrscheinlichkeitsverteilung bezeichnet. <br><br>  Jetzt ben√∂tigen wir eine Ausgabeebene, um die Wahrscheinlichkeiten f√ºr jedes Etikett zu berechnen. <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br>  Und wir werden dies mit dem folgenden Befehl tun: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax)</code> </pre><br>  Tats√§chlich verwenden wir immer dann, wenn wir neuronale Netze erstellen, die Klassifizierungsprobleme l√∂sen, eine vollst√§ndig verbundene Schicht als letzte Schicht eines neuronalen Netzes.  Die letzte Schicht des neuronalen Netzwerks sollte die Anzahl der Neuronen enthalten, die der Anzahl der Klassen entspricht, zu denen wir die <code>softmax</code> bestimmen und die Softmax-Aktivierungsfunktion verwenden. <br><br><h3>  <code>ReLU</code> - Neuronenaktivierungsfunktion </h3><br>  In dieser Lektion haben wir √ºber <code>ReLU</code> als etwas gesprochen, das die F√§higkeiten unseres neuronalen Netzwerks erweitert und ihm zus√§tzliche Leistung verleiht. <br><br>  <code>ReLU</code> ist eine mathematische Funktion, die folgenderma√üen aussieht: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/691/c04/e7b/691c04e7b270706458daf61c4b38cf22.png" alt="Bild"><br><br>  Die <code>ReLU</code> Funktion gibt 0 zur√ºck, wenn der Eingabewert ein negativer Wert oder Null war. In allen anderen F√§llen gibt die Funktion den urspr√ºnglichen Eingabewert zur√ºck. <br><br>  <code>ReLU</code> erm√∂glicht die L√∂sung nichtlinearer Probleme. <br><br>  Die Umrechnung von Grad Celsius in Grad Fahrenheit ist eine lineare Aufgabe, da der Ausdruck <code>f = 1.8*c + 32</code> die Gleichung der Linie ist - <code>y = m*x + b</code> .  Die meisten Aufgaben, die wir l√∂sen m√∂chten, sind jedoch nicht linear.  In solchen F√§llen kann das Hinzuf√ºgen der ReLU-Aktivierungsfunktion zu unserer vollst√§ndig verbundenen Schicht bei dieser Art von Aufgabe hilfreich sein. <br><br>  <code>ReLU</code> ist nur eine Art von Aktivierungsfunktion.  Es gibt Aktivierungsfunktionen wie Sigmoid, ReLU, ELU, <code>ReLU</code> Am h√§ufigsten wird jedoch <code>ReLU</code> als Standardaktivierungsfunktion verwendet.  Um Modelle mit ReLU zu erstellen und zu verwenden, m√ºssen Sie nicht verstehen, wie es intern funktioniert.  Wenn Sie noch besser verstehen wollen, empfehlen wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesen Artikel</a> . <br><br>  Lassen Sie uns die neuen Begriffe in dieser Lektion durchgehen: <br><br><ul><li>  <b>Gl√§tten</b> - der Prozess des Konvertierens eines 2D-Bildes in einen 1D-Vektor; </li><li>  <b>ReLU</b> ist eine Aktivierungsfunktion, mit der das Modell nichtlineare Probleme l√∂sen kann. </li><li>  <b>Softmax</b> - eine Funktion, die die Wahrscheinlichkeiten f√ºr jede m√∂gliche Ausgabeklasse berechnet; </li><li>  <b>Klassifizierung</b> - Eine Klasse von maschinellen Lernaufgaben, mit denen die Unterschiede zwischen zwei oder mehr Kategorien (Klassen) ermittelt werden. </li></ul><br><h2>  Schulung und Pr√ºfung </h2><br>  Beim Training eines Modells, eines Modells f√ºr maschinelles Lernen, ist es immer erforderlich, den Datensatz in mindestens zwei verschiedene S√§tze zu unterteilen - den f√ºr das Training verwendeten Datensatz und den zum Testen verwendeten Datensatz.  In diesem Teil werden wir verstehen, warum es sich lohnt, dies zu tun. <br><br>  Erinnern wir uns, wie wir unseren Datensatz von Fashion MNIST mit 70.000 Exemplaren verteilt haben. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Wir haben vorgeschlagen, 70.000 in zwei Teile zu teilen - im ersten Teil 60.000 f√ºr das Training und im zweiten Teil 10.000 f√ºr Tests.  Die Notwendigkeit eines solchen Ansatzes wird durch die folgende Tatsache verursacht: Nachdem das Modell auf 60.000 Kopien trainiert wurde, m√ºssen die Ergebnisse und die Wirksamkeit seiner Arbeit an Beispielen √ºberpr√ºft werden, die noch nicht in dem Datensatz enthalten waren, auf dem das Modell trainiert wurde. <br><br>  Auf seine Weise √§hnelt es dem Bestehen einer Pr√ºfung in der Schule.  Bevor Sie die Pr√ºfung bestehen, sind Sie flei√üig damit besch√§ftigt, Probleme einer bestimmten Klasse zu l√∂sen.  In der Pr√ºfung sto√üen Sie dann auf dieselbe Problemklasse, jedoch mit unterschiedlichen Eingabedaten.  Es ist nicht sinnvoll, dieselben Daten wie w√§hrend des Trainings zu √ºbermitteln. Andernfalls wird die Aufgabe darauf reduziert, sich an Entscheidungen zu erinnern und nicht nach einem L√∂sungsmodell zu suchen.  Deshalb stehen Sie bei Pr√ºfungen vor Aufgaben, die zuvor nicht im Lehrplan enthalten waren.  Nur so k√∂nnen wir √ºberpr√ºfen, ob das Modell die allgemeine L√∂sung gelernt hat oder nicht. <br><br>  Das gleiche passiert beim maschinellen Lernen.  Sie zeigen einige Daten an, die eine bestimmte Klasse von Aufgaben darstellen, deren L√∂sung Sie lernen m√∂chten.  In unserem Fall m√∂chten wir, dass das neuronale Netzwerk mit einem Datensatz von Fashion MNIST die Kategorie bestimmen kann, zu der das Kleidungselement im Bild geh√∂rt.  Deshalb trainieren wir unser Modell an 60.000 Beispielen, die alle Kategorien von Kleidungsst√ºcken enthalten.  Nach dem Training m√∂chten wir die Wirksamkeit des Modells √ºberpr√ºfen, damit wir die verbleibenden 10.000 Kleidungsst√ºcke f√ºttern, die das Modell noch nicht ‚Äûgesehen‚Äú hat.  Wenn wir uns entscheiden w√ºrden, dies nicht zu tun und nicht mit 10.000 Beispielen zu testen, k√∂nnten wir nicht mit Sicherheit sagen, ob unser Modell tats√§chlich darauf trainiert wurde, die Klasse des Kleidungsst√ºcks zu bestimmen, oder ob sie sich an alle Paare von Eingabe- / Ausgabewerten erinnerte. <br><br>  Deshalb haben wir beim maschinellen Lernen immer einen Datensatz f√ºr das Training und einen Datensatz zum Testen. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow</a> ist eine Sammlung gebrauchsfertiger Trainingsdaten. <br><br>  Datens√§tze werden normalerweise in mehrere Bl√∂cke unterteilt, von denen jeder in einer bestimmten Phase des Trainings und Testens der Wirksamkeit des neuronalen Netzwerks verwendet wird.  In diesem Teil sprechen wir √ºber: <br><br><ul><li>  <b>Trainingsdatensatz</b> : ein Datensatz zum Trainieren eines neuronalen Netzwerks; </li><li>  <b>Testdatensatz</b> : Ein Datensatz zur √úberpr√ºfung der Effizienz eines neuronalen Netzwerks. </li></ul><br>  Stellen Sie sich einen anderen Datensatz vor, den ich als Validierungsdatensatz bezeichne.  Dieser Datensatz wird nicht <b>zum</b> Trainieren des Modells verwendet, sondern nur <b>w√§hrend des</b> Trainings.  Nachdem unser Modell mehrere Trainingszyklen durchlaufen hat, geben wir ihm unseren Testdatensatz und sehen uns die Ergebnisse an.  Wenn beispielsweise w√§hrend des Trainings der Wert der Verlustfunktion abnimmt und sich die Genauigkeit des Testdatensatzes verschlechtert, bedeutet dies, dass sich unser Modell einfach nur Paare von Eingabe-Ausgabe-Werten merkt. <br><br>  Der Verifizierungsdatensatz wird am Ende des Trainings wiederverwendet, um die endg√ºltige Genauigkeit der Modellvorhersagen zu messen. <br><br>  Weitere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Informationen zu Trainings- und Testdatens√§tzen finden Sie im Google Crash-Kurs</a> . <br><br><h2>  Praktischer Teil in CoLab </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link zum originalen CoLab in Englisch</a> und ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link zum russischen CoLab</a> . <br><br><h2>  Klassifizierung von Bildern von Kleidungsst√ºcken </h2><br>  In diesem Teil der Lektion werden wir ein neuronales Netzwerk aufbauen und trainieren, um Bilder von Kleidungselementen wie Kleidern, Turnschuhen, Hemden, T-Shirts usw. zu klassifizieren. <br><br>  Es ist in Ordnung, wenn einige Momente nicht klar sind.  Der Zweck dieses Kurses ist es, Sie mit TensorFlow vertraut zu machen und gleichzeitig die Algorithmen seiner Arbeit zu erkl√§ren und ein gemeinsames Verst√§ndnis f√ºr Projekte mit TensorFlow zu entwickeln, anstatt sich mit den Details der Implementierung zu befassen. <br><br>  In diesem Teil verwenden wir <code>tf.keras</code> , eine <code>tf.keras</code> API zum <code>tf.keras</code> und Trainieren von Modellen in TensorFlow. <br><br><h3>  Abh√§ngigkeiten installieren und importieren </h3><br>  Wir ben√∂tigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein TensorFlow-Dataset</a> , eine API, die das Laden und Zugreifen auf Datasets vereinfacht, die von mehreren Diensten bereitgestellt werden.  Wir werden auch einige Hilfsbibliotheken brauchen. <br><br><pre> <code class="python hljs">!pip install -U tensorflow_datasets</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-comment"><span class="hljs-comment">#  TensorFlow    TensorFlow import tensorflow as tf import tensorflow_datasets as tfds tf.logging.set_verbosity(tf.logging.ERROR) #   import math import numpy as np import matplotlib.pyplot as plt #    import tqdm import tqdm.auto tqdm.tqdm = tqdm.auto.tqdm print(tf.__version__) tf.enable_eager_execution()</span></span></code> </pre><br><h3>  Importieren Sie den Fashion MNIST-Datensatz </h3><br>  In diesem Beispiel wird der Fashion MNIST-Datensatz verwendet, der 70.000 Bilder von Kleidungsst√ºcken in 10 Kategorien in Graustufen enth√§lt.  Die Bilder enthalten Kleidungsst√ºcke in niedriger Aufl√∂sung (28 x 28 Pixel), wie unten gezeigt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/2c1/da3/18d2c1da3b5c7dbff14ea81077d9ed24.png" alt="Bild"><br><br>  Fashion MNIST wird als Ersatz f√ºr den klassischen MNIST-Datensatz verwendet - am h√§ufigsten als "Hallo Welt!"  in maschinellem Lernen und Computer Vision.  Der MNIST-Datensatz enth√§lt Bilder von handgeschriebenen Zahlen (0, 1, 2 usw.) im gleichen Format wie die Kleidungsst√ºcke in unserem Beispiel. <br><br>  In unserem Beispiel verwenden wir Fashion MNIST aufgrund der Vielfalt und weil diese Aufgabe unter dem Gesichtspunkt der Implementierung interessanter ist als die L√∂sung eines typischen Problems im MNIST-Datensatz.  Beide Datens√§tze sind klein genug, daher werden sie verwendet, um die korrekte Funktionsf√§higkeit des Algorithmus zu √ºberpr√ºfen.  Hervorragende Datens√§tze zum Erlernen des maschinellen Lernens, Testens und Debuggens von Code. <br><br>  Wir werden 60.000 Bilder verwenden, um das Netzwerk zu trainieren, und 10.000 Bilder, um die Genauigkeit des Trainings und der Bildklassifizierung zu testen.  Sie k√∂nnen √ºber TensorFlow √ºber die API direkt auf den Fashion MNIST-Datensatz zugreifen: <br><br><pre> <code class="python hljs">dataset, metadata = tfds.load(<span class="hljs-string"><span class="hljs-string">'fashion_mnist'</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_dataset, test_dataset = dataset[<span class="hljs-string"><span class="hljs-string">'train'</span></span>], dataset[<span class="hljs-string"><span class="hljs-string">'test'</span></span>]</code> </pre><br>  Durch Laden eines Datensatzes erhalten wir Metadaten, einen Trainingsdatensatz und einen Testdatensatz. <br><br><ul><li>  Das Modell wird an einem Datensatz aus "train_dataset" trainiert </li><li>  Das Modell wird an einem Datensatz aus `test_dataset` getestet </li></ul><br>  Bilder sind zweidimensionale <code>2828</code> Arrays, bei denen die Werte in jeder Zelle im Intervall <code>[0, 255]</code> .  Beschriftungen - ein Array von Ganzzahlen, wobei jeder Wert im Intervall <code>[0, 9]</code> .  Diese Beschriftungen entsprechen der Ausgabebildklasse wie folgt: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Etikett </th><th>  Klasse </th></tr><tr><td>  0 </td><td>  T-Shirt / Top </td></tr><tr><td>  1 </td><td>  Shorts </td></tr><tr><td>  2 </td><td>  Pullover </td></tr><tr><td>  3 </td><td>  Kleid </td></tr><tr><td>  4 </td><td>  Umhang </td></tr><tr><td>  5 </td><td>  Sandalen </td></tr><tr><td>  6 </td><td>  Hemd </td></tr><tr><td>  7 </td><td>  Sneaker </td></tr><tr><td>  8 </td><td>  Tasche </td></tr><tr><td>  9 </td><td>  Booten </td></tr></tbody></table></div><br><br>  Jedes Bild geh√∂rt zu einem Tag.  Da die Klassennamen nicht im Originaldatensatz enthalten sind, speichern wir sie f√ºr die zuk√ºnftige Verwendung, wenn wir die Bilder zeichnen: <br><br><pre> <code class="python hljs">class_names = [<span class="hljs-string"><span class="hljs-string">' / '</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>]</code> </pre><br><h4>  Wir recherchieren Daten </h4><br>  Lassen Sie uns das Format und die Struktur der im Trainingssatz dargestellten Daten untersuchen, bevor Sie das Modell trainieren.  Der folgende Code zeigt, dass sich 60.000 Bilder im Trainingsdatensatz und 10.000 Bilder im Testdatensatz befinden: <br><br><pre> <code class="python hljs">num_train_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'train'</span></span>].num_examples num_test_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'test'</span></span>].num_examples print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_train_examples)) print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_test_examples))</code> </pre><br><h3>  Datenvorverarbeitung </h3><br>  Der Wert jedes Pixels im Bild liegt im Bereich <code>[0,255]</code> .  Damit das Modell korrekt funktioniert, m√ºssen diese Werte normalisiert und auf Werte im Intervall <code>[0,1]</code> reduziert werden.  Etwas niedriger deklarieren und implementieren wir daher die Normalisierungsfunktion und wenden sie dann auf jedes Bild in den Trainings- und Testdatens√§tzen an. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normalize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images, labels)</span></span></span><span class="hljs-function">:</span></span> images = tf.cast(images, tf.float32) images /= <span class="hljs-number"><span class="hljs-number">255</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> images, labels <span class="hljs-comment"><span class="hljs-comment">#  map         #      train_dataset = train_dataset.map(normalize) test_dataset = test_dataset.map(normalize)</span></span></code> </pre><br><h4>  Wir untersuchen die verarbeiteten Daten </h4><br>  Zeichnen wir ein Bild, um es uns anzusehen: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          #   reshape() for image, label in test_dataset.take(1): break; image = image.numpy().reshape((28, 28)) #   plt.figure() plt.imshow(image, cmap=plt.cm.binary) plt.colorbar() plt.grid(False) plt.show()</span></span></code> </pre><br><img src="https://habrastorage.org/webt/ce/se/hw/cesehwjbca_ol0s1dcpxnaxyu2i.png"><br><br>  Wir zeigen die ersten 25 Bilder aus dem Trainingsdatensatz an und geben unter jedem Bild an, zu welcher Klasse es geh√∂rt. <br><br>  Stellen Sie sicher, dass die Daten im richtigen Format vorliegen und wir mit der Erstellung und Schulung des Netzwerks beginnen k√∂nnen. <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) i = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (image, label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">25</span></span>): image = image.numpy().reshape((<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,i+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.xticks([]) plt.yticks([]) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.imshow(image, cmap=plt.cm.binary) plt.xlabel(class_names[label]) i += <span class="hljs-number"><span class="hljs-number">1</span></span> plt.show()</code> </pre><br><img src="https://habrastorage.org/webt/4h/_v/s7/4h_vs7mj97mmqknia5mpnzaqfis.png"><br><br><h4>  Ein Modell bauen </h4><br>  Um ein neuronales Netzwerk aufzubauen, m√ºssen Ebenen abgestimmt und anschlie√üend ein Modell mit Optimierungs- und Verlustfunktionen zusammengestellt werden. <br><br><h4>  Passen Sie Ebenen an </h4><br>  Das Grundelement beim Aufbau eines neuronalen Netzwerks ist die Schicht.  Die Ebene extrahiert die Ansicht aus den Daten, die in ihre Eingabe eingegangen sind.  Als Ergebnis der Arbeit mehrerer miteinander verbundener Schichten erhalten wir eine Ansicht, die zur L√∂sung des Problems sinnvoll ist. <br><br>  Die meiste Zeit, in der Sie tief lernen, werden Sie Verkn√ºpfungen zwischen einfachen Ebenen herstellen.  Die meisten Ebenen, z. B. tf.keras.layers.Dense, verf√ºgen √ºber eine Reihe von Parametern, die w√§hrend des Lernprozesses ‚Äûangepasst‚Äú werden k√∂nnen. <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br>  Das Netzwerk besteht aus drei Schichten: <br><br><ul><li>  <b>input</b> <code>tf.keras.layers.Flatten</code> - Diese Ebene konvertiert Bilder mit einer Gr√∂√üe von 28 x 28 Pixel in ein 1D-Array mit einer Gr√∂√üe von 784 (28 * 28).  Auf dieser Ebene haben wir keine Parameter f√ºr das Training, da diese Ebene nur die Konvertierung von Eingabedaten behandelt. </li><li>  <b>versteckte Schicht</b> <code>tf.keras.layers.Dense</code> - eine eng verbundene Schicht von 128 Neuronen.  Jedes Neuron (Knoten) nimmt alle 784 Werte aus der vorherigen Schicht als Eingabe, √§ndert die Eingabewerte entsprechend den internen Gewichten und Verschiebungen w√§hrend des Trainings und gibt einen einzelnen Wert an die n√§chste Schicht zur√ºck. </li><li>  <b>Ausgabeschicht</b> <code>ts.keras.layers.Dense</code> - <code>softmax</code> besteht aus 10 Neuronen, von denen jede eine bestimmte Klasse von Kleidungselementen darstellt.  Wie in der vorherigen Schicht empf√§ngt jedes Neuron die Eingabewerte aller 128 Neuronen der vorherigen Schicht.  Die Gewichte und Verschiebungen jedes Neurons auf dieser Schicht √§ndern sich w√§hrend des Trainings, so dass der resultierende Wert im Intervall <code>[0,1]</code> und die Wahrscheinlichkeit darstellt, dass das Bild zu dieser Klasse geh√∂rt.  Die Summe aller Ausgangswerte von 10 Neuronen ist 1. </li></ul><br><h4>  Kompilieren Sie das Modell </h4><br>  Bevor wir mit dem Training des Modells beginnen, sollten noch einige Einstellungen vorgenommen werden.  Diese Einstellungen werden w√§hrend der Modellzusammenstellung vorgenommen, wenn die Kompilierungsmethode aufgerufen wird: <br><br><ul><li>  <b>Verlustfunktion</b> - Ein Algorithmus zum Messen, wie weit der gew√ºnschte Wert vom vorhergesagten Wert entfernt ist. </li><li>  <b>Optimierungsfunktion</b> - ein Algorithmus zum ‚ÄûAnpassen‚Äú der internen Parameter (Gewichte und Offsets) des Modells, um die Verlustfunktion zu minimieren; </li><li>  <b>Metriken</b> - werden verwendet, um den Trainingsprozess und die Tests zu √ºberwachen.  Im folgenden Beispiel werden Metriken wie <code></code> und der Prozentsatz der Bilder verwendet, die korrekt klassifiziert wurden. </li></ul><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><h3>  Wir trainieren das Modell </h3><br>  Zun√§chst bestimmen wir die Reihenfolge der Aktionen w√§hrend des Trainings anhand eines Trainingsdatensatzes: <br><br><ol><li>  Wiederholen Sie den Satz von Eingabedaten mit der Methode <code>dataset.repeat()</code> unendlich <code>dataset.repeat()</code> der unten beschriebene Parameter <code>epochs</code> bestimmt die Anzahl aller durchzuf√ºhrenden Trainingsiterationen). </li><li>  Die Methode <code>dataset.shuffle(60000)</code> alle Bilder, sodass das Training unseres Modells nicht durch die Reihenfolge der Eingabedaten beeinflusst wird. </li><li>  Die Methode <code>dataset.batch(32)</code> weist die Trainingsmethode <code>model.fit</code> , bei <code>model.fit</code> Aktualisierung der internen Variablen des Modells Bl√∂cke mit 32 Bildern und Beschriftungen <code>model.fit</code> verwenden. </li></ol><br>  Das Training erfolgt durch Aufrufen der <code>model.fit</code> Methode: <br><br><ul><li>  Sendet <code>train_dataset</code> an die Modelleingabe. </li><li>  Das Modell lernt, das Eingabebild mit dem Etikett abzugleichen. </li><li>  Der Parameter <code>epochs=5</code> begrenzt die Anzahl der Trainingseinheiten auf 5 vollst√§ndige Trainingsiterationen in einem Datensatz, wodurch wir letztendlich an 5 * 60.000 = 300.000 Beispielen trainieren k√∂nnen. </li></ul><br>  (Sie k√∂nnen den Parameter <code>steps_per_epoch</code> ignorieren, bald wird dieser Parameter von der Methode ausgeschlossen.) <br><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE) test_dataset = test_dataset.batch(BATCH_SIZE)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))</code> </pre><br>  Und hier ist die Schlussfolgerung: <br><br> <code>Epoch 1/5 <br> 1875/1875 [==============================] - 26s 14ms/step - loss: 0.4921 - acc: 0.8267 <br> Epoch 2/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3652 - acc: 0.8686 <br> Epoch 3/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3341 - acc: 0.8782 <br> Epoch 4/5 <br> 1875/1875 [==============================] - 19s 10ms/step - loss: 0.3111 - acc: 0.8858 <br> Epoch 5/5 <br> 1875/1875 [==============================] - 16s 8ms/step - loss: 0.2911 - acc: 0.8922 <br></code> <br>  W√§hrend des Modelltrainings werden f√ºr jede Trainingsiteration der Wert der Verlustfunktion und die Genauigkeitsmetrik angezeigt.  Dieses Modell erreicht eine Genauigkeit von ca. 0,88 (88%) bei Trainingsdaten. <br><br><h4>  √úberpr√ºfen Sie die Genauigkeit </h4><br>  Lassen Sie uns √ºberpr√ºfen, welche Genauigkeit das Modell mit Testdaten erzeugt.  Wir werden alle Beispiele, die wir im Testdatensatz haben, zur √úberpr√ºfung der Genauigkeit verwenden. <br><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE)) print(<span class="hljs-string"><span class="hljs-string">"    : "</span></span>, test_accuracy)</code> </pre><br>  Fazit: <br><br> <code>313/313 [==============================] - 1s 5ms/step - loss: 0.3440 - acc: 0.8793 <br>     : 0.8793 <br></code> <br><br>  Wie Sie sehen k√∂nnen, war die Genauigkeit des Testdatensatzes geringer als die Genauigkeit des Trainingsdatensatzes.  Dies ist ganz normal, da das Modell auf train_dataset-Daten trainiert wurde.  Wenn ein Modell Bilder entdeckt, die es noch nie zuvor gesehen hat (aus dem Dataset train_dataset), ist es offensichtlich, dass die Klassifizierungseffizienz abnimmt. <br><br><h3>  Vorhersagen und erforschen </h3><br>  Wir k√∂nnen das trainierte Modell verwenden, um Vorhersagen f√ºr einige Bilder zu erhalten. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> test_images, test_labels <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): test_images = test_images.numpy() test_labels = test_labels.numpy() predictions = model.predict(test_images)</code> </pre><br><pre> <code class="python hljs">predictions.shape</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schlussfolgerung: </font><font style="vertical-align: inherit;">Im obigen Beispiel hat das Modell Beschriftungen f√ºr jedes Testeingabebild vorhergesagt. </font><font style="vertical-align: inherit;">Schauen wir uns die erste Vorhersage an:</font></font><br><br> <code>(32, 10) <br></code> <br><br><font style="vertical-align: inherit;"></font><br><br><pre> <code class="python hljs">predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fazit: </font></font><br><br><pre> <code class="python hljs">array([<span class="hljs-number"><span class="hljs-number">3.1365351e-05</span></span>, <span class="hljs-number"><span class="hljs-number">9.0029374e-08</span></span>, <span class="hljs-number"><span class="hljs-number">5.0016739e-03</span></span>, <span class="hljs-number"><span class="hljs-number">6.3597057e-05</span></span>, <span class="hljs-number"><span class="hljs-number">6.8342477e-02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span>, <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span>, <span class="hljs-number"><span class="hljs-number">1.8982398e-09</span></span>, <span class="hljs-number"><span class="hljs-number">8.4999456e-06</span></span>, <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>], dtype=float32)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Denken Sie daran, dass Modellvorhersagen ein Array von 10 Werten sind. </font><font style="vertical-align: inherit;">Diese Werte beschreiben das ‚ÄûVertrauen‚Äú des Modells, dass das Eingabebild zu einer bestimmten Klasse (Kleidungsst√ºck) geh√∂rt. </font><font style="vertical-align: inherit;">Wir k√∂nnen den Maximalwert wie folgt sehen:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fazit: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies bedeutet, dass das Modell am sichersten war, dass dieses Bild zur Klasse mit der Bezeichnung 6 (class_names [6]) geh√∂rt. </font><font style="vertical-align: inherit;">Wir k√∂nnen √ºberpr√ºfen und sicherstellen, dass das Ergebnis wahr und korrekt ist:</font></font><br><br><pre> <code class="python hljs">test_labels[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wir k√∂nnen alle Eingabebilder und die entsprechenden Modellvorhersagen f√ºr 10 Klassen anzeigen: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_labels, images)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label, img = predictions_array[i], true_label[i], images[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) plt.imshow(img[...,<span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=plt.cm.binary) predicted_label = np.argmax(predictions_array) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_label == true_label: color = <span class="hljs-string"><span class="hljs-string">'blue'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: color = <span class="hljs-string"><span class="hljs-string">'red'</span></span> plt.xlabel(<span class="hljs-string"><span class="hljs-string">"{} {:2.0f}% ({})"</span></span>.format(class_names[predicted_label], <span class="hljs-number"><span class="hljs-number">100</span></span> * np.max(predictions_array), class_names[true_label]), color=color) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_value_array</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_label)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label = predictions_array[i], true_label[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) thisplot = plt.bar(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), predictions_array, color=<span class="hljs-string"><span class="hljs-string">"#777777"</span></span>) plt.ylim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) predicted_label = np.argmax(predictions_array) thisplot[predicted_label].set_color(<span class="hljs-string"><span class="hljs-string">'red'</span></span>) thisplot[true_label].set_color(<span class="hljs-string"><span class="hljs-string">'blue'</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Schauen wir uns das 0. Bild an, das Ergebnis der Vorhersage des Modells und das Array von Vorhersagen. </font></font><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">0</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/fc/7i/ef/fc7iefucuvtopx4_avluy-rq1ei.png"><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">12</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/n0/2y/tj/n02ytjjdkeubvkqvjdusbkwoemy.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lassen Sie uns nun einige Bilder mit ihren jeweiligen Vorhersagen anzeigen. </font><font style="vertical-align: inherit;">Richtige Vorhersagen sind blau, falsche Vorhersagen sind rot. </font><font style="vertical-align: inherit;">Der Wert unter dem Bild gibt den Prozentsatz der Sicherheit an, dass das Eingabebild dieser Klasse entspricht. </font><font style="vertical-align: inherit;">Bitte beachten Sie, dass das Ergebnis m√∂glicherweise falsch ist, auch wenn der Wert f√ºr ‚ÄûVertrauen‚Äú hoch ist.</font></font><br><br><pre> <code class="python hljs">num_rows = <span class="hljs-number"><span class="hljs-number">5</span></span> num_cols = <span class="hljs-number"><span class="hljs-number">3</span></span> num_images = num_rows * num_cols plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_rows)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_images): plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/m1/11/je/m111jevw7ptxblu2ccmlwmtonva.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Verwenden Sie das trainierte Modell, um die Beschriftung f√ºr ein einzelnes Bild vorherzusagen: </font></font><br><br><pre> <code class="python hljs">img = test_images[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fazit: </font></font><br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modelle in sind </font></font><code>tf.keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f√ºr Vorhersagen durch Bl√∂cke (Sammlungen) optimiert. </font><font style="vertical-align: inherit;">Trotz der Tatsache, dass wir ein einzelnes Element verwenden, m√ºssen Sie es der Liste hinzuf√ºgen:</font></font><br><br><pre> <code class="python hljs">img = np.array([img]) print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fazit: </font></font><br><br> <code>(1, 28, 28, 1)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetzt werden wir das Ergebnis vorhersagen:</font></font><br><br><pre> <code class="python hljs">predictions_single = model.predict(img) print(predictions_single)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fazit: </font></font><br><br><pre> <code class="python hljs">[[<span class="hljs-number"><span class="hljs-number">3.1365438e-05</span></span> <span class="hljs-number"><span class="hljs-number">9.0029722e-08</span></span> <span class="hljs-number"><span class="hljs-number">5.0016833e-03</span></span> <span class="hljs-number"><span class="hljs-number">6.3597123e-05</span></span> <span class="hljs-number"><span class="hljs-number">6.8342514e-02</span></span> <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span> <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.8982469e-09</span></span> <span class="hljs-number"><span class="hljs-number">8.4999692e-06</span></span> <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>]]</code> </pre><br><pre> <code class="python hljs">plot_value_array(<span class="hljs-number"><span class="hljs-number">0</span></span>, predictions_single, test_labels) _ = plt.xticks(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), class_names, rotation=<span class="hljs-number"><span class="hljs-number">45</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/eo/vw/sl/eovwslxcn_ldtj2abz870ninw4g.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die model.predict-Methode gibt eine Liste von Listen (ein Array von Arrays) zur√ºck, jeweils f√ºr ein Bild aus einem Eingabeblock. </font><font style="vertical-align: inherit;">Wir erhalten das einzige Ergebnis f√ºr unser einzelnes Eingabebild:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions_single[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fazit: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wie zuvor sagte das Modell das Etikett 6 (Hemd) voraus. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √úbungen </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Experimentieren Sie mit verschiedenen Modellen und sehen Sie, wie sich die Genauigkeit √§ndert. </font><font style="vertical-align: inherit;">Versuchen Sie insbesondere, die folgenden Einstellungen zu √§ndern:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Setzen Sie den Parameter epochs auf 1; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √Ñndern Sie beispielsweise die Anzahl der Neuronen in der verborgenen Schicht von einem niedrigen Wert von 10 auf 512 und sehen Sie, wie sich die Genauigkeit des Prognosemodells √§ndert. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> F√ºgen Sie zus√§tzliche Schichten zwischen der Abflachungsschicht (Gl√§ttungsschicht) und der letzten dichten Schicht hinzu. Experimentieren Sie mit der Anzahl der Neuronen auf dieser Schicht. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Normalisieren Sie die Pixelwerte nicht und sehen Sie, was passiert. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Denken Sie daran, die GPU zu aktivieren, damit alle Berechnungen schneller sind ( </font></font><code>Runtime -&gt; Change runtime type -&gt; Hardware accelertor -&gt; GPU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">). </font><font style="vertical-align: inherit;">Wenn Sie w√§hrend des Vorgangs auf Probleme sto√üen, versuchen Sie, die globalen Umgebungseinstellungen zur√ºckzusetzen:</font></font><br><br><ul><li> <code>Edit -&gt; Clear all outputs</code> </li> <li> <code>Runtime -&gt; Reset all runtimes</code> </li> </ul><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Grad Celsius VS MNIST </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Zu diesem Zeitpunkt sind wir bereits auf zwei Arten von neuronalen Netzen gesto√üen. Unser erstes neuronales Netzwerk hat gelernt, wie man Grad Celsius in Grad Frenheit umwandelt, wobei ein einzelner Wert zur√ºckgegeben wird, der in einem weiten Bereich numerischer Werte liegen kann. </font></font><br><br><img src="https://habrastorage.org/webt/o8/ag/_t/o8ag_trkedahoa0ftg3pstkirt4.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unser zweites neuronales Netzwerk gibt 10 Wahrscheinlichkeitswerte zur√ºck, die das Vertrauen des Netzwerks widerspiegeln, dass das Eingabebild einer bestimmten Klasse entspricht. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neuronale Netze k√∂nnen verwendet werden, um verschiedene Probleme zu l√∂sen. </font></font><br><br><img src="https://habrastorage.org/webt/no/0v/jo/no0vjoulnrva_-bky0uauc3tesi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die erste Klasse von Problemen, die wir mit der Vorhersage eines einzelnen Wertes gel√∂st haben, hei√üt </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Regression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Die Umrechnung von Grad Celsius in Grad Fahrenheit ist ein Beispiel f√ºr die Aufgabe dieser Klasse. Ein weiteres Beispiel f√ºr diese Aufgabenklasse kann die Aufgabe sein, den Wert eines Hauses anhand der Anzahl der R√§ume, der Gesamtfl√§che, des Standorts und anderer Merkmale zu bestimmen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die zweite Klasse von Aufgaben, die wir in dieser Lektion untersucht haben, um Bilder in verf√ºgbare Kategorien zu </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">klassifizieren,</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wird als </font><b><font style="vertical-align: inherit;">Klassifizierung bezeichnet</font></b><font style="vertical-align: inherit;"> . Gem√§√ü den Eingabedaten gibt das Modell die Wahrscheinlichkeitsverteilung zur√ºck (das ‚ÄûVertrauen‚Äú des Modells, dass der Eingabewert zu dieser Klasse geh√∂rt). In dieser Lektion haben wir ein neuronales Netzwerk entwickelt, das Kleidungselemente in 10 Kategorien klassifiziert. In der n√§chsten Lektion lernen wir zu bestimmen, wer auf dem Foto gezeigt wird - ein Hund oder eine Katze. Diese Aufgabe geh√∂rt auch zur Klassifizierungsaufgabe.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lassen Sie uns den Unterschied zwischen diesen beiden Problemklassen - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Regression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Klassifizierung</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - zusammenfassen und feststellen </font><font style="vertical-align: inherit;">. </font></font><br><br><img src="https://habrastorage.org/webt/_c/wj/qu/_cwjquy9ivk-s3zma34qamyakoq.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Herzlichen Gl√ºckwunsch, Sie haben zwei Arten von neuronalen Netzen untersucht! Machen Sie sich bereit f√ºr die n√§chste Vorlesung. Dort werden wir einen neuen Typ neuronaler Netze untersuchen - Convolutional Neural Networks (CNN).</font></font><br><br><h3>  Zusammenfassung </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In dieser Lektion haben wir das neuronale Netzwerk trainiert, um Bilder mit Kleidungselementen zu klassifizieren. Zu diesem Zweck haben wir den Fashion MNIST-Datensatz verwendet, der 70.000 Bilder von Kleidungsst√ºcken enth√§lt. 60.000 davon haben wir verwendet, um das neuronale Netzwerk zu trainieren, und die restlichen 10.000, um die Wirksamkeit seiner Arbeit zu testen. Um diese Bilder an die Eingabe unseres neuronalen Netzwerks zu senden, mussten wir sie von einem 28x28 2D-Format in ein 1D-Format mit 784 Elementen konvertieren (gl√§tten). Unser Netzwerk bestand aus einer vollst√§ndig verbundenen Schicht von 128 Neuronen und einer Ausgangsschicht von 10 Neuronen, entsprechend der Anzahl der Etiketten (Klassen, Kategorien von Kleidungsst√ºcken). Diese 10 Ausgabewerte repr√§sentierten die Wahrscheinlichkeitsverteilung f√ºr jede Klasse. </font><i><font style="vertical-align: inherit;">Softmax-</font></i><font style="vertical-align: inherit;"> Aktivierungsfunktion</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">z√§hlte die Wahrscheinlichkeitsverteilung. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben auch die Unterschiede zwischen </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Regression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Klassifikation kennengelernt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Regression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Ein Modell, das einen einzelnen Wert zur√ºckgibt, z. B. den Wert eines Hauses.</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Klassifizierung</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Ein Modell, das die Wahrscheinlichkeitsverteilung zwischen mehreren Kategorien zur√ºckgibt. </font><font style="vertical-align: inherit;">In unserer Aufgabe mit Fashion MNIST waren die Ausgabewerte beispielsweise 10 Wahrscheinlichkeitswerte, von denen jeder einer bestimmten Klasse (Kategorie von Kleidungsst√ºcken) zugeordnet war. </font><font style="vertical-align: inherit;">Ich erinnere Sie daran, dass wir die </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Softmax-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aktivierungsfunktion verwendet haben </font><font style="vertical-align: inherit;">, um eine Wahrscheinlichkeitsverteilung auf der letzten Ebene zu erhalten.</font></font></li></ul><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Videoversion des Artikels</font></font></b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das Video erscheint einige Tage nach Ver√∂ffentlichung und wird dem Artikel hinzugef√ºgt. </font></font><br></div></div><br>  ... und Standard-Handlungsaufforderung - anmelden, ein Plus setzen und teilen :) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Telegramm</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de454034/">https://habr.com/ru/post/de454034/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de454018/index.html">iOS Digest Nr. 6 (17. - 30. Mai)</a></li>
<li><a href="../de454024/index.html">MPPT-Laderegler am STM32F334C8T6</a></li>
<li><a href="../de454028/index.html">Skizzen mit PHP Russia 2019: sauberer Code, dunkle Magie</a></li>
<li><a href="../de454030/index.html">Odigest: interessant f√ºr Designer der Woche</a></li>
<li><a href="../de454032/index.html">Saubere schnelle Architektur f√ºr Router und Daten√ºbergabe</a></li>
<li><a href="../de454036/index.html">6 Wege, um zur H√∂lle der vorgefertigten L√∂sungen zu gelangen und ein oder zwei Millionen zu senken</a></li>
<li><a href="../de454038/index.html">Ilya Zverev: Im Laufe der Jahre hat OpenStreetMap eine so ernsthafte Infrastruktur aufgebaut, dass Sie eine Karte zeichnen k√∂nnen, ohne Ihr Zuhause zu verlassen</a></li>
<li><a href="../de454040/index.html">React Russia 2019 Konferenz ist bereits der 1. Juni</a></li>
<li><a href="../de454042/index.html">Zahlen Sie, was Sie wollen: wie sich dieses Modell in der Musik gezeigt hat und wer versucht hat, so Geld zu verdienen</a></li>
<li><a href="../de454044/index.html">Kreativit√§t auf iPad und iPhone</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
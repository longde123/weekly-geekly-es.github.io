<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏽‍🔬 ☮️ 👃 NVIDIA Jetson Nano: tests et premières impressions - Partie 2, tests d'intelligence artificielle 🎎 🧓🏻 👩🏽‍🤝‍👨🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut, Habr. 

 Dans la première partie , NVIDIA Jetson Nano a été envisagée - une carte au format Raspberry Pi, axée sur le calcul des performances à...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NVIDIA Jetson Nano: tests et premières impressions - Partie 2, tests d'intelligence artificielle</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460971/">  Salut, Habr. <br><br>  Dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">première partie</a> , NVIDIA Jetson Nano a été envisagée - une carte au format Raspberry Pi, axée sur le calcul des performances à l'aide du GPU.  Il est temps de tester la carte dans laquelle elle a été créée - pour des calculs orientés IA. <br><br><img src="https://habrastorage.org/webt/91/1a/7i/911a7i0fv9k20_edm9oftroelpq.png"><br><br>  Réfléchissez à la façon dont les différentes tâches se déroulent sur le tableau, comme classer des images ou reconnaître des piétons ou des phoques (où sans eux).  Pour tous les tests, les codes sources pouvant être exécutés sur le bureau, Jetson Nano ou Raspberry Pi sont donnés.  Pour ceux qui sont intéressés, continue sous la coupe. <br><a name="habracut"></a><br>  Il existe deux façons d'utiliser cette carte.  La première consiste à exécuter des cadres standard comme Keras et Tensorflow.  Cela fonctionnera en principe, ce sera le cas, mais comme déjà vu dans la première partie, Jetson Nano, bien sûr, est inférieur à une carte vidéo de bureau ou d'ordinateur portable à part entière.  L'utilisateur devra se charger d'optimiser le modèle.  La deuxième façon consiste à suivre des cours prêts à l'emploi fournis avec la planche.  C'est plus simple et fonctionne «prêt à l'emploi», le moins est que tous les détails de l'implémentation sont beaucoup plus cachés, en plus, vous devrez étudier et utiliser custom-sdk, qui, en plus de ces cartes, ne sera utile nulle part ailleurs.  Cependant, nous examinerons les deux façons, en commençant par la première. <br><br><h2>  Classification d'image </h2><br>  Considérez le problème de la reconnaissance d'image.  Pour ce faire, nous utiliserons le modèle ResNet50 fourni avec Keras (ce modèle a été lauréat du Défi ImageNet en 2015).  Pour l'utiliser, quelques lignes de code suffisent. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time IMAGE_SIZE = <span class="hljs-number"><span class="hljs-number">224</span></span> IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>) resnet = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE) img = tf.contrib.keras.preprocessing.image.load_img(<span class="hljs-string"><span class="hljs-string">'cat.png'</span></span>, target_size=(IMAGE_SIZE, IMAGE_SIZE)) t_start = time.time() img_data = tf.contrib.keras.preprocessing.image.img_to_array(img) x = tf.contrib.keras.applications.resnet50.preprocess_input(np.expand_dims(img_data, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)) probabilities = resnet.predict(x) print(tf.contrib.keras.applications.resnet50.decode_predictions(probabilities, top=<span class="hljs-number"><span class="hljs-number">5</span></span>)) print(<span class="hljs-string"><span class="hljs-string">"dT"</span></span>, time.time() - t_start)</code> </pre> <br>  Je n'ai même pas commencé à supprimer le code sous le spoiler, car  il est très petit.  Comme vous pouvez le voir, l'image est d'abord redimensionnée à 224x224 (c'est le format réseau d'entrée), à ​​la fin, la fonction de prédiction fait tout le travail. <br><br>  Nous prenons une photo du chat et exécutons le programme. <br><br><img src="https://habrastorage.org/webt/_q/e8/ln/_qe8ln2w3hsmbw4dqcy7kdnuft0.png"><br><br>  Résultats: <br><br><pre> <code class="python hljs">[[(<span class="hljs-string"><span class="hljs-string">'n02123045'</span></span>, <span class="hljs-string"><span class="hljs-string">'tabby'</span></span>, <span class="hljs-number"><span class="hljs-number">0.765179</span></span>), (<span class="hljs-string"><span class="hljs-string">'n02123159'</span></span>, <span class="hljs-string"><span class="hljs-string">'tiger_cat'</span></span>, <span class="hljs-number"><span class="hljs-number">0.19059166</span></span>), (<span class="hljs-string"><span class="hljs-string">'n02124075'</span></span>, <span class="hljs-string"><span class="hljs-string">'Egyptian_cat'</span></span>, <span class="hljs-number"><span class="hljs-number">0.013605555</span></span>), (<span class="hljs-string"><span class="hljs-string">'n04493381'</span></span>, <span class="hljs-string"><span class="hljs-string">'tub'</span></span>, <span class="hljs-number"><span class="hljs-number">0.0025916891</span></span>), (<span class="hljs-string"><span class="hljs-string">'n04553703'</span></span>, <span class="hljs-string"><span class="hljs-string">'washbasin'</span></span>, <span class="hljs-number"><span class="hljs-number">0.0021566998</span></span>)]]</code> </pre> <br>  Encore une fois, bouleversé par sa connaissance de l'anglais (je me demande combien de non-natifs savent ce qu'est un «tabby»?), J'ai vérifié la sortie avec le dictionnaire, oui, tout fonctionne. <br><br>  Le temps d'exécution du code PC était de <b>0,5 s</b> pour les calculs sur le CPU et de 2 s (!) Pour les calculs sur le GPU.  À en juger par le journal, le problème se situe dans le modèle ou dans Tensorflow, mais lorsqu'il démarre, le code essaie d'allouer beaucoup de mémoire, obtenant plusieurs avertissements du formulaire «Allocator (GPU_0_bfc) a manqué de mémoire en essayant d'allouer 2.13GiB avec freed_by_count = 0.» .  Il s'agit d'un avertissement et non d'une erreur, le code fonctionne, mais beaucoup plus lentement qu'il ne devrait. <br><br>  Sur Jetson Nano, il est toujours plus lent: <b>2,8 c</b> sur le CPU et <b>18,8 c</b> sur le GPU, la sortie ressemble à ceci: <br><br><img src="https://habrastorage.org/webt/t6/ok/ja/t6okja2fzqx_tjvmd6evens5dn8.png"><br><br>  En général, même 3s par image, ce n'est pas encore le temps réel.  La définition de l'option gpu_options.allow_growth recommandée en cas de débordement de pile n'aide pas, si quelqu'un connaît une autre manière, écrivez dans les commentaires. <br><br>  <b>Modifier</b> : comme demandé dans les commentaires, le premier démarrage de tensorflow prend toujours beaucoup de temps et il est incorrect de mesurer le temps d'utilisation.  En effet, lors du traitement du deuxième fichier et des fichiers suivants, les résultats sont bien meilleurs - 0,6s sans GPU et 0,2s avec GPU.  Sur le bureau, la vitesse est cependant de 2,0 s et 0,05 s, respectivement. <br><br>  Une caractéristique pratique de ResNet50 est qu'au premier démarrage, il pompe tout le modèle sur le disque (environ 100 Mo), puis le code fonctionne de manière complètement autonome, sans inscription ni SMS.  Ce qui est particulièrement agréable, étant donné que la plupart des services d'IA modernes ne fonctionnent que sur le serveur, et sans Internet, l'appareil se transforme en "citrouille". <br><br><h2>  Chats vs chiens </h2><br>  Considérez le problème suivant.  En utilisant Keras, nous allons créer un réseau de neurones qui peut distinguer les chats des chiens.  Ce sera un réseau neuronal convolutionnel (CNN - Convolutional Neural Network), nous prendrons la conception du réseau de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette</a> publication.  Un ensemble d'images d'entraînement de chats et de chiens est déjà inclus dans le package tensorflow_datasets, vous n'aurez donc pas à les photographier vous-même. <br><br>  Nous chargeons un ensemble d'images et le divisons en trois blocs - formation, vérification et test.  Nous «normalisons» chaque image, ce qui porte les couleurs à la plage 0..1. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow_datasets <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tfds <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time IMAGE_SIZE = <span class="hljs-number"><span class="hljs-number">64</span></span> IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>) splits = tfds.Split.TRAIN.subsplit(weighted=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) (cat_train, cat_valid, cat_test), info = tfds.load(<span class="hljs-string"><span class="hljs-string">'cats_vs_dogs'</span></span>, split=list(splits), with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) label_names = info.features[<span class="hljs-string"><span class="hljs-string">'label'</span></span>].int2str <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pre_process_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image, label)</span></span></span><span class="hljs-function">:</span></span> image = tf.cast(image, tf.float32) image = image / <span class="hljs-number"><span class="hljs-number">255.0</span></span> <span class="hljs-comment"><span class="hljs-comment"># Normalize image: 0..255 -&gt; 0..1 image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE)) return image, label BATCH_SIZE = 32 SHUFFLE_BUFFER_SIZE = 1000 train_batch = cat_train.map(pre_process_image).shuffle(SHUFFLE_BUFFER_SIZE).repeat().batch(BATCH_SIZE) validation_batch = cat_valid.map(pre_process_image).repeat().batch(BATCH_SIZE)</span></span></code> </pre><br>  Nous écrivons la fonction de génération d'un réseau neuronal convolutionnel. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">custom_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Source: https://medium.com/@ferhat00/deep-learning-with-keras-classifying-cats-and-dogs-part-1-982067594856 classifier = tf.keras.Sequential() # Step 1 — Convolution classifier.add(layers.Conv2D(32, (3, 3), input_shape=IMG_SHAPE, activation='relu')) # Step 2 — Pooling classifier.add(layers.MaxPooling2D(pool_size=(2, 2))) # Adding a second convolutional layer classifier.add(layers.Conv2D(32, (3, 3), activation='relu')) classifier.add(layers.MaxPooling2D(pool_size=(2, 2))) # Step 3 — Flattening classifier.add(layers.Flatten()) # Step 4 — Full connection classifier.add(layers.Dense(units=128, activation='relu')) classifier.add(layers.Dense(units=1, activation='sigmoid')) # Compiling the CNN we shall use the Adam stochastic optimisation method, binary cross entropy loss function classifier.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy']) return classifier</span></span></code> </pre><br>  Nous pouvons maintenant organiser une formation en réseau sur notre kit «chat-chien».  La formation prend beaucoup de temps (20 minutes sur le GPU et 1-2 heures sur le CPU), donc à la fin nous enregistrons le modèle dans un fichier. <br><br><pre> <code class="python hljs">tl_model = custom_model() t_start = time.time() tl_model.fit(train_batch, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">8000</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">2</span></span>, validation_data=validation_batch, validation_steps=<span class="hljs-number"><span class="hljs-number">10</span></span>, callbacks=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) print(<span class="hljs-string"><span class="hljs-string">"Training done, dT:"</span></span>, time.time() - t_start) print(tl_model.summary()) validation_steps = <span class="hljs-number"><span class="hljs-number">20</span></span> loss0, accuracy0 = tl_model.evaluate(validation_batch, steps=validation_steps) print(<span class="hljs-string"><span class="hljs-string">"Loss: {:.2f}"</span></span>.format(loss0)) print(<span class="hljs-string"><span class="hljs-string">"Accuracy: {:.2f}"</span></span>.format(accuracy0)) tl_model.save(<span class="hljs-string"><span class="hljs-string">"dog_cat_model.h5"</span></span>)</code> </pre><br>  Soit dit en passant, la tentative de lancement de la formation directement sur le Jetson Nano a échoué - après 5 minutes, la planche a surchauffé et a suspendu.  Pour les calculs gourmands en ressources, un refroidisseur est requis pour la carte, bien que dans l'ensemble, cela n'a aucun sens de faire de telles tâches directement sur Jetson Nano - vous pouvez entraîner le modèle sur un PC et utiliser le fichier enregistré fini sur Nano. <br><br>  Un autre écueil est apparu ici - la bibliothèque tensowflow version 14 a été installée sur le PC, et la dernière version pour Jetson Nano est jusqu'à présent 13. Et le modèle enregistré dans la 14e version n'a pas été lu dans le 13e, j'ai dû installer les mêmes versions en utilisant pip. <br><br>  Enfin, nous pouvons charger le modèle à partir d'un fichier et l'utiliser pour reconnaître des images. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, image_file)</span></span></span><span class="hljs-function">:</span></span> img = image.load_img(image_file, target_size=(IMAGE_SIZE, IMAGE_SIZE)) t_start = time.time() img_arr = np.expand_dims(img, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) result = model.predict_classes(img_arr) print(<span class="hljs-string"><span class="hljs-string">"Result: {}, dT: {}"</span></span>.format(label_names(result[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]), time.time() - t_start)) model = tf.keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'dog_cat_model.h5'</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"cat.png"</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"dog1.png"</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"dog2.png"</span></span>)</code> </pre><br>  La photo du chat a été utilisée de la même façon, mais pour le test "chien" 2 photos ont été utilisées: <br><br><img src="https://habrastorage.org/webt/2m/0m/6f/2m0m6fvejlzvcdfuewdq2m9b5ug.png"><br><br>  Le premier a deviné correctement, et le second a d'abord eu des erreurs et le réseau neuronal pensait que c'était un chat, j'ai dû augmenter le nombre d'itérations d'entraînement.  Cependant, j'aurais probablement fait une erreur la première fois;) <br><br>  Le temps d'exécution sur Jetson Nano s'est avéré être assez petit - la toute première photo a été traitée en 0,3 s, mais toutes les suivantes ont été beaucoup plus rapides, apparemment les données sont mises en cache en mémoire. <br><br><img src="https://habrastorage.org/webt/hx/w1/vg/hxw1vgfb217p1usxaftimpmkybo.png"><br><br>  En général, nous pouvons supposer que sur de tels réseaux neuronaux simples, la vitesse de la carte est assez suffisante même sans optimisation, 100fps est une valeur suffisante même pour la vidéo en temps réel. <br><br><h2>  Conclusion </h2><br>  Comme vous pouvez le voir, même les modèles standard de Keras et Tensorflow peuvent être utilisés sur Nano, bien qu'avec un succès variable - quelque chose fonctionne, quelque chose ne fonctionne pas.  Cependant, les résultats peuvent être améliorés, des instructions sur l'optimisation du modèle et la réduction de la taille de la mémoire peuvent être lues <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Mais heureusement pour nous, les fabricants l'ont déjà fait pour nous.  Si les lecteurs sont toujours intéressés, la dernière partie sera consacrée aux <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bibliothèques prêtes</a> à l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">emploi</a> optimisées pour travailler avec Jetson Nano. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr460971/">https://habr.com/ru/post/fr460971/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr460959/index.html">La nouvelle technologie de Microsoft permet aux copies 3D d'une personne réelle de parler n'importe quelle langue</a></li>
<li><a href="../fr460961/index.html">Configuration de tests unitaires dans des projets mixtes Swift + Objective-C</a></li>
<li><a href="../fr460965/index.html">Split Controller sans ces storyboards</a></li>
<li><a href="../fr460967/index.html">Troy Hunt: 10 leçons financières personnelles pour les professionnels des technologies de l'information</a></li>
<li><a href="../fr460969/index.html">Margaret Hamilton: «Ils craignaient que les hommes ne se rebellent; mais ce n'est pas arrivé "</a></li>
<li><a href="../fr460973/index.html">Soudage par contact pour les batteries 18650</a></li>
<li><a href="../fr460979/index.html">Les biotechnologies de rajeunissement sont réelles et inévitables</a></li>
<li><a href="../fr460981/index.html">Implémentation MVVM de la configuration de l'application WPF basée sur le framework Catel</a></li>
<li><a href="../fr460983/index.html">Je ne suis pas réel</a></li>
<li><a href="../fr460985/index.html">14 meilleurs outils Kanban en 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
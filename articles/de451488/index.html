<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçÜ üî¶ üö∫ Berechnung der Kannibalisierung basierend auf dem klassischen A / B-Test und der Bootstrap-Methode üîò üë®üèø‚Äçü§ù‚Äçüë®üèº üö∑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel beschreibt eine Methode zur Berechnung der Kannibalisierung f√ºr eine mobile Anwendung basierend auf dem klassischen A / B-Test. In dies...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Berechnung der Kannibalisierung basierend auf dem klassischen A / B-Test und der Bootstrap-Methode</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451488/">  Dieser Artikel beschreibt eine Methode zur Berechnung der Kannibalisierung f√ºr eine mobile Anwendung basierend auf dem klassischen A / B-Test.  In diesem Fall werden Zielaktionen als Teil des Prozesses der Neuzuweisung von einer Werbequelle (Direct, Criteo, AdWords UAC und andere) im Vergleich zu Zielaktionen in der Gruppe, f√ºr die die Werbung deaktiviert wurde, ber√ºcksichtigt und bewertet. <br><br>  Der Artikel gibt einen √úberblick √ºber klassische Methoden zum Vergleich unabh√§ngiger Stichproben mit einer kurzen theoretischen Grundlage und eine Beschreibung der verwendeten Bibliotheken, einschlie√ülich  Beschreibt kurz das Wesentliche der Bootstrap-Methode und ihre Implementierung in der FaceBook Bootstrapped-Bibliothek sowie die Probleme, die in der Praxis bei der Anwendung dieser Techniken auftreten, und wie sie gel√∂st werden k√∂nnen. <br><a name="habracut"></a><br>  Der Nachweis wird entweder verschleiert oder nicht erbracht, um eine Geheimhaltungsvereinbarung aufrechtzuerhalten. <br><br>  In Zukunft plane ich, diesen Artikel zu erg√§nzen und geringf√ºgig zu √§ndern, sobald neue Fakten erscheinen, sodass diese Version als erste Version betrachtet werden kann.  Ich w√§re dankbar f√ºr die Kommentare und Bewertungen. <br><br><h3>  Einf√ºhrung </h3> <br>  Kannibalisierung ist der Prozess des vollst√§ndigen und gezielten Verkehrsflusses von einem Kanal zum anderen. <br><br>  Vermarkter verwenden diesen Indikator normalerweise als zus√§tzlichen K-Koeffizienten bei der Berechnung des CPA: Der berechnete CPA wird mit 1 + K multipliziert.  In diesem Fall bedeutet CPA die Gesamtkosten f√ºr die Gewinnung von Traffic / die Anzahl der gezielten Aktionen, die direkt monetarisiert werden, dh die den tats√§chlichen Gewinn gebracht haben - beispielsweise einen gezielten Anruf und / oder indirekt monetarisiert -, z. B. das Volumen der Anzeigendatenbank erh√∂hen, die Zielgruppe erh√∂hen und so weiter. <br><br>  Wenn kostenlose Kan√§le (z. B. Besuche von organischen SERPs, Klicks auf Links auf Websites, die f√ºr uns kostenlos sind) gegen Bezahlung ausschlachten (Direkt, AdWords anstelle von organischen Inhalten, Werbung in Feeds von sozialen Netzwerken anstelle von Klicks auf Anzeigen), ist dies kostenlos In Gruppen eingeteilt usw.) birgt dies das Risiko eines finanziellen Verlusts. Daher ist es wichtig, die Kannibalisierungsrate zu kennen. <br><br>  In unserem Fall bestand die Aufgabe darin, die Kannibalisierung von "organischen" √úberg√§ngen zur Anwendung durch √úberg√§nge aus dem Criteo-Werbenetzwerk zu berechnen.  Die √úberwachung ist ein Ger√§t oder eine Benutzer-UID (GAID / ADVID und IDFA). <br><br><h3>  Versuchsvorbereitung </h3><br>  Sie k√∂nnen die Zielgruppe auf das Experiment vorbereiten, indem Sie die Benutzer in der Benutzeroberfl√§che des AdJust-Analysesystems in Gruppen unterteilen, um diejenigen zu isolieren, die Anzeigen aus einem bestimmten Werbenetzwerk sehen (Kontrollbeispiel), und diejenigen, denen keine Anzeigen mit GAID oder ADVID bzw. IDFA angezeigt werden (AdJust stellt die Audience Builder-API bereit.)  Anschlie√üend k√∂nnen Sie im Kontrollbeispiel eine Werbekampagne in das im Experiment untersuchte Werbenetzwerk aufnehmen. <br><br>  Ich stelle von mir selbst fest, dass, wie es intuitiv erscheint, die folgende Durchf√ºhrung des Experiments in diesem Fall kompetenter w√§re: vier Gruppen auszuw√§hlen - diejenigen, bei denen das Retargeting aus allen Kan√§len deaktiviert war (1), als Versuchsgruppe und diejenigen, die dies getan haben nur Retargeting mit Criteo (2) aktiviert;  diejenigen, bei denen das Retargeting nur mit Criteo (3) deaktiviert war, diejenigen, bei denen das Retargeting (4) aktiviert war.  Dann w√§re es m√∂glich, (1) / (2) zu berechnen, nachdem der tats√§chliche Wert der Kannibalisierung von Werbekampagnen des Criteo-Netzwerks f√ºr ‚Äûorganische‚Äú √úberg√§nge zur Anwendung erhalten wurde, und (3) / (4), wenn Kannitalisierung von Criteo in der ‚Äûnat√ºrlichen‚Äú Umgebung erhalten wurde (schlie√ülich nat√ºrlich Criteo) kann auch andere kostenpflichtige Kan√§le ausschlachten).  Das gleiche Experiment sollte f√ºr andere Werbenetzwerke wiederholt werden, um die Auswirkungen der einzelnen Netzwerke herauszufinden.  In einer idealen Welt w√§re es sch√∂n, die Kannibalisierung zwischen allen wichtigen bezahlten Quellen zu untersuchen, die den gr√∂√üten Anteil am Gesamtverkehr ausmachen, aber es w√ºrde so viel Zeit in Anspruch nehmen (sowohl f√ºr die Vorbereitung von Experimenten aus Sicht der Entwicklung als auch f√ºr die Bewertung der Ergebnisse), was dazu f√ºhren w√ºrde Kritik an unvern√ºnftiger Sorgfalt. <br><br>  Tats√§chlich wurde unser Experiment unter den Bedingungen (3) und (4) durchgef√ºhrt, die Proben wurden im Verh√§ltnis von 10% zu 90% aufgeteilt, das Experiment wurde 2 Wochen lang durchgef√ºhrt. <br><br><h3>  Datenaufbereitung und -verifizierung </h3><br>  Ein wichtiger Schritt vor Beginn einer Studie ist die kompetente Vorschulung und Datenbereinigung. <br><br>  Es sollte beachtet werden, dass tats√§chlich die aktiven Vorrichtungen f√ºr den Versuchszeitraum zweimal geringer waren (42,5% bzw. 50% der Kontroll- und Versuchsgruppen) als die Vorrichtungen in den vollst√§ndigen Anfangsproben, was durch die Art der Daten erkl√§rt wird: <br><br><ol><li>  Erstens (und dies ist der Hauptgrund) enth√§lt die Auswahl f√ºr das Retargeting unter Anpassen die Kennungen aller Ger√§te, die die Anwendung jemals installiert haben, dh der Ger√§te, die nicht mehr verwendet werden, und der Ger√§te, mit denen die Anwendung bereits verwendet wurde gel√∂scht </li><li>  Zweitens ist es nicht erforderlich, dass sich alle Ger√§te w√§hrend des Experiments bei der Anwendung angemeldet haben. </li></ol><br>  Wir haben jedoch die Kannibalisierung anhand von Daten aus einer vollst√§ndigen Stichprobe berechnet.  F√ºr mich pers√∂nlich scheint die Richtigkeit einer solchen Berechnung immer noch ein strittiger Punkt zu sein - meiner Meinung nach ist es im Allgemeinen korrekter, alle diejenigen zu bereinigen, die die Anwendung deinstalliert und nicht √ºber die entsprechenden Tags installiert haben, sowie diejenigen, die sich seit mehr als einem Jahr nicht mehr bei der Anwendung angemeldet haben. In diesem Zeitraum kann der Benutzer das Ger√§t wechseln.  Minus - Auf diese Weise k√∂nnen f√ºr das Experiment diejenigen Benutzer aus der Auswahl entfernt werden, die nicht zur Anwendung gewechselt sind, dies aber konnten, wenn wir ihnen Anzeigen im Criteo-Netzwerk zeigen.  Ich m√∂chte darauf hinweisen, dass in einer guten Welt all diese erzwungenen Vernachl√§ssigungen und Annahmen separat untersucht und verifiziert werden sollten, aber wir leben in einer Welt, in der es schnell und pelzig geht. <br><br>  In unserem Fall ist es wichtig, die folgenden Punkte zu √ºberpr√ºfen: <br><br><ol><li>  Wir √ºberpr√ºfen den Schnittpunkt in unseren ersten Proben - experimentell und kontrolliert.  In einem korrekt durchgef√ºhrten Experiment sollten solche Schnittpunkte nicht vorhanden sein. In unserem Fall befanden sich jedoch mehrere Duplikate aus der experimentellen Probe in der Kontrolle.  In unserem Fall war der Anteil dieser Duplikate am Gesamtvolumen der an dem Experiment beteiligten Ger√§te gering, daher haben wir diese Bedingung vernachl√§ssigt.  Wenn es&gt; 1% Duplikate gab, sollte das Experiment als falsch angesehen werden und ein zweites Experiment sollte durchgef√ºhrt werden, nachdem zuvor die Duplikate gereinigt wurden. </li><li>  Wir stellen sicher, dass die Daten im Experiment wirklich betroffen waren - das Retargeting sollte in der experimentellen Probe (zumindest mit Criteo im korrekt eingestellten Experiment - von allen Kan√§len aus) deaktiviert werden. Daher muss beim Retargeting mit Criteo √ºberpr√ºft werden, ob DeviceID aus dem Experiment fehlt.  In unserem Fall fiel DeviceID aus der Versuchsgruppe dennoch in das Retargeting, aber es gab weniger als 1%, was vernachl√§ssigbar ist. </li></ol><br><h3>  Direkte Auswertung des Experiments </h3><br>  Wir werden die √Ñnderung in den folgenden Zielmetriken ber√ºcksichtigen: absolut - die Anzahl der Anrufe und relativ - die Anzahl der Anrufe pro Benutzer in der Kontrollgruppe (S√§genanzeigen im Criteo-Netzwerk) und in der experimentellen Gruppe (Anzeigen wurden deaktiviert).  Im folgenden Code beziehen sich die variablen Daten auf die pandas.DataFrame-Struktur, die aus den Ergebnissen einer Versuchs- oder Kontrollprobe gebildet wird. <br><br>  Es gibt parametrische und nichtparametrische Methoden zur Bewertung der statistischen Signifikanz der Wertdifferenz in nicht verwandten Proben.  Parametrische Bewertungskriterien bieten eine gr√∂√üere Genauigkeit, haben jedoch Einschr√§nkungen in ihrer Anwendung - insbesondere ist eine der Hauptbedingungen, dass die gemessenen Werte f√ºr die Beobachtungen in der Probe normal verteilt werden sollten. <br><br><h4>  1. Die Untersuchung der Verteilung der Werte in den Proben auf Normalit√§t </h4><br>  Der erste Schritt besteht darin, die vorhandenen Stichproben anhand von Standardtests auf die Art der Werteverteilung und die Gleichheit der Varianzen der Stichproben zu untersuchen - die Kriterien von Kolmogorov-Smirnov und Shapiro-Wilks sowie den in der Bibliothek sklearn.stats implementierten Bartlett-Test mit einem p-Wert von = 0,05: <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : def norm_test(df, pvalue = 0.05, test_name = 'kstest'): if test_name == 'kstest': st = stats.kstest(df, 'norm') if test_name == 'shapiro': st = stats.shapiro(df) sys.stdout.write('According to {} {} is {}normal\n'.format(test_name, df.name, {True:'NOT ', False:''}[st[1] &lt; pvalue])) #    : def barlett_test(df1, df2, pvalue = 0.05): st = stats.bartlett(df1, df2) sys.stdout.write('Variances of {} and {} is {}equals\n'.format(df1.name, df2.name, {True:'NOT ', False:''}[st[1] &lt; pvalue]))</span></span></code> </pre> <br>  Zus√§tzlich k√∂nnen Sie zur visuellen Beurteilung der Ergebnisse die Histogrammfunktion verwenden. <br><br><pre> <code class="python hljs">data_agg = data.groupby([<span class="hljs-string"><span class="hljs-string">'bucket'</span></span>]).aggregate({<span class="hljs-string"><span class="hljs-string">'device_id'</span></span>: <span class="hljs-string"><span class="hljs-string">'nunique'</span></span>, <span class="hljs-string"><span class="hljs-string">'calls'</span></span>: <span class="hljs-string"><span class="hljs-string">'sum'</span></span>}).fillna(<span class="hljs-number"><span class="hljs-number">0</span></span>) data_conv = data_agg[<span class="hljs-string"><span class="hljs-string">'calls_auto'</span></span>]/data_agg[<span class="hljs-string"><span class="hljs-string">'device_id'</span></span>] data_conv.hist(bins=<span class="hljs-number"><span class="hljs-number">20</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/8m/zc/u4/8mzcu4-emautrimdpvczuttfkf8.png" alt="Bild"><br><br>  Sie k√∂nnen das Histogramm folgenderma√üen lesen: 10 Mal in der Stichprobe gab es eine Umrechnung von 0,08, 1 - 0,14.  Dies sagt nichts √ºber die Anzahl der Ger√§te als Beobachtungen f√ºr einen der Umrechnungsindikatoren aus. <br><br>  In unserem Fall ist die Verteilung des Parameterwerts sowohl in absoluten Werten als auch in relativen Werten (Anzahl der Aufrufe an das Ger√§t) in den Stichproben nicht normal. <br>  In diesem Fall k√∂nnen Sie entweder den nichtparametrischen Wilcoxon-Test verwenden, der in der Standardbibliothek sklearn.stats implementiert ist, oder versuchen, die Verteilung der Werte in den Stichproben auf die normale Form zu bringen und eines der parametrischen Kriterien anzuwenden - Student's aka t-test oder Shapiro-Wilks-Test. <br><br><h4>  2. Methoden zur Reduzierung der Werteverteilung in Proben auf die Normalform </h4><br>  <b>2.1.</b>  <b>Untereimer</b> <br><br>  Ein Ansatz, um die Verteilung zu normalisieren, ist die Sub-Bucket-Methode.  Sein Wesen ist einfach, und die folgende mathematische These ist die theoretische Grundlage: Nach dem klassischen zentralen Grenzwertsatz tendiert die Verteilung der Mittel zur Normalit√§t - die Summe von n unabh√§ngigen identisch verteilten Zufallsvariablen hat eine Verteilung nahe der Normalen und √§quivalent die Verteilung der Stichprobenmittel des ersten n unabh√§ngigen identisch verteilten Zufalls Mengen tendieren zu normal.  Daher k√∂nnen wir die vorhandenen Bucket'es in Sub-Bucket'y aufteilen und dementsprechend, wenn wir die Durchschnittswerte von Sub-Bucket'y f√ºr jeden der Bucket'ov nehmen, eine Verteilung erhalten, die nahezu normal ist: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   subbucket' data['subbucket'] = data['device_id'].apply(lambda x: randint(0,1000)) # Variant 1 data['subbucket'] = data['device_id'].apply(lambda x: hash(x)%1000) # Variant 2</span></span></code> </pre> <br>  Es gibt viele Optionen f√ºr die Aufteilung, alles h√§ngt von der Vorstellungskraft und den moralischen Prinzipien des Entwicklers ab. Sie k√∂nnen ehrliche Zufallszahlen verwenden oder Hash aus dem urspr√ºnglichen Bucket verwenden und dabei den Mechanismus f√ºr die Ausgabe im Schema ber√ºcksichtigen. <br><br>  In der Praxis haben wir jedoch nach mehreren Dutzend Codestarts die Normalverteilung nur einmal erhalten, dh diese Methode ist weder garantiert noch stabil. <br><br>  Dar√ºber hinaus stimmt das Verh√§ltnis von Zielaktionen und Benutzern zur Gesamtzahl der Aktionen und Benutzer im Unterbereich m√∂glicherweise nicht mit den anf√§nglichen Backets √ºberein. Sie m√ºssen daher zun√§chst √ºberpr√ºfen, ob das Verh√§ltnis beibehalten wird. <br><br><pre> <code class="python hljs">data[data[<span class="hljs-string"><span class="hljs-string">'calls'</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>].device_id.nunique()/data.device_id.nunique() <span class="hljs-comment"><span class="hljs-comment"># Total buckets = data.groupby(['bucket']).aggregate({'device_id': 'nunique', 'calls': 'sum'}) buckets[buckets['calls'] &gt; 0].device_id.nunique()/buckets.device_id.nunique() # Buckets subbuckets = data.groupby(['subbucket']).aggregate({'device_id': 'nunique', 'calls': 'sum'}) subbuckets[subbuckets['calls'] &gt; 0].device_id.nunique()/subbuckets.device_id.nunique() # Subbuckets</span></span></code> </pre> <br>  Bei dieser √úberpr√ºfung haben wir festgestellt, dass die Umrechnungsverh√§ltnisse f√ºr Subbuckets relativ zur urspr√ºnglichen Auswahl nicht erhalten bleiben.  Da wir zus√§tzlich die Konsistenz des Verh√§ltnisses des Anteils der Aufrufe in den Ausgabe- und Quellstichproben gew√§hrleisten m√ºssen, verwenden wir den Klassenausgleich und f√ºgen die Gewichtung hinzu, sodass die Daten getrennt nach Untergruppen ausgew√§hlt werden: getrennt von Beobachtungen mit Zielaktionen und getrennt von Beobachtungen ohne Zielaktionen im richtigen Verh√§ltnis.  Au√üerdem waren in unserem Fall die Proben ungleich verteilt;  intuitiv scheint sich der Durchschnitt nicht zu √§ndern, aber wie sich die Ungleichm√§√üigkeit der Proben auf die Varianz auswirkt, ist aus der Dispersionsformel nicht ersichtlich.  Um zu kl√§ren, ob der Unterschied in der Gr√∂√üe der Stichproben das Ergebnis beeinflusst, wird das Xi-Quadrat-Kriterium verwendet. Wenn ein statistisch signifikanter Unterschied festgestellt wird, wird ein gr√∂√üerer Datenrahmen mit einer kleineren Gr√∂√üe abgetastet: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">class_arrays_balancer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df1, df2, target = </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'calls'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, pvalue=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.05</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> df1_target_size = len(df1[df1[target] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>]) print(df1.columns.to_list()) df2_target_size = len(df2[df2[target] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>]) total_target_size = df1_target_size + df2_target_size chi2_target, pvalue_target, dof_target, expected_target = chi2_contingency([[df1_target_size, total_target_size], [df2_target_size, total_target_size]]) df1_other_size = len(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>]) df2_other_size = len(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>]) total_other_size = df1_other_size + df2_other_size chi2_other, pvalue_other, dof_other, expected_other = chi2_contingency([[df1_other_size, total_other_size], [df2_other_size, total_other_size]]) df1_target, df2_target, df1_other, df2_other = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> pvalue_target &lt; pvalue: sample_size = min([df1_target_size, df2_target_size]) df1_rnd_indx = np.random.choice(df1_target_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df2_rnd_indx = np.random.choice(df2_target_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df1_target = pd.DataFrame((np.asarray(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">1</span></span>])[df1_rnd_indx]).tolist(), columns = df1.columns.tolist()) df2_target = pd.DataFrame((np.asarray(df2[df2[target] == <span class="hljs-number"><span class="hljs-number">1</span></span>])[df2_rnd_indx]).tolist(), columns = df2.columns.tolist()) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p_value_other &lt; pvalue: sample_size = min([df1_other_size, df2_other_size]) df1_rnd_indx = np.random.choice(df1_other_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df2_rnd_indx = np.random.choice(df2_other_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df1_other = pd.DataFrame((np.asarray(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>])[df1_rnd_indx]).tolist(), columns = df1.columns.tolist()) df2_other = pd.DataFrame((np.asarray(df2[df2[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>])[df2_rnd_indx]).tolist(), columns = df2.columns.tolist()) df1 = pd.concat([df1_target, df1_other]) df2 = pd.concat([df2_target, df2_other]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df1, df2 exp_classes, control_classes = class_arrays_balancer(data_exp, data_control)</code> </pre> <br>  Am Ausgang erhalten wir Daten, deren Gr√∂√üe ausgewogen ist und die mit den anf√§nglichen Umrechnungsverh√§ltnissen √ºbereinstimmen, den untersuchten Metriken (berechnet f√ºr Durchschnittswerte f√ºr den Unterbereich), in denen sie bereits normal verteilt sind, was sowohl visuell als auch anhand der Ergebnisse der Anwendung der uns bereits bekannten Testkriterien ersichtlich ist Normalit√§t (mit p-Wert&gt; = 0,05).  Zum Beispiel f√ºr relative Indikatoren: <br><br><pre> <code class="python hljs">data_conv = (data[data[<span class="hljs-string"><span class="hljs-string">'calls'</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>].groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.sum()*<span class="hljs-number"><span class="hljs-number">1.0</span></span>/data.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).device_id.nunique()) data_conv.hist(bins = <span class="hljs-number"><span class="hljs-number">50</span></span>)</code> </pre> <br>  Jetzt kann der T-Test auf den Durchschnitt √ºber Sub-Bucket'es angewendet werden (daher ist es nicht device_id, kein Ger√§t, sondern Sub-Bucket, das als Beobachtung dient). <br><br>  Nachdem wir sichergestellt haben, dass die √Ñnderungen statistisch signifikant sind, k√∂nnen wir mit gutem Gewissen das tun, wof√ºr wir alle begonnen haben - die Kannibalisierung berechnen: <br><br><pre> <code class="python hljs">(data_exp.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg() - data_cntrl.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg() )/ data_exp.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg()</code> </pre> <br>  Der Nenner sollte Verkehr ohne Werbung sein, dh experimentell. <br><br><h4>  3. Bootstrap-Methode </h4><br>  Die Bootstrap-Methode ist eine Erweiterung der Sub-Bucket-Methode und stellt die erweiterte und verbesserte Version dar.  Eine Software-Implementierung dieser Methode in Python finden Sie in der Facebook Bootstrapped-Bibliothek. <br>  Kurz gesagt, die Idee des Bootstraps kann wie folgt beschrieben werden: Eine Methode ist nichts anderes als ein Konstruktor von Samples, die auf √§hnliche Weise wie Sub-Bucket-Methoden zuf√§llig generiert wurden, jedoch mit m√∂glichen Wiederholungen.  Wir k√∂nnen die Platzierung aus der Allgemeinbev√∂lkerung (wenn man die Originalstichprobe nennen kann) mit der R√ºckgabe sagen.  Am Ausgang werden Mittelwerte (oder Mediane, Betr√§ge usw.) aus den Durchschnittswerten f√ºr jede der erzeugten Unterproben gebildet. <br><br>  <i>Die wichtigsten Methoden der FaceBook Bootstrap-Bibliothek</i> : <br><pre> <code class="python hljs">bootstrap()</code> </pre>  - implementiert einen Mechanismus zur Bildung von Teilproben;  Gibt standardm√§√üig die Untergrenze (5 Perzentil) und die Obergrenze (95 Perzentil) zur√ºck.  <i>Um</i> eine diskrete Verteilung in diesem Bereich zur√ºckzugeben, muss der Parameter <i>return_distribution = True gesetzt werden</i> (er wird von der <i>Hilfsfunktion</i> <i>generate_distributions () generiert</i> ). <br><br>  Sie k√∂nnen die Anzahl der Iterationen mithilfe des Parameters <i>num_iterations angeben</i> , in dem <i>Unterproben</i> generiert werden, und die Anzahl der <i>Unterproben</i> <i>iteration_batch_size</i> f√ºr jede Iteration.  Bei der Ausgabe von <i>generate_distributions ()</i> wird eine Stichprobe mit einer Gr√∂√üe generiert, die der Anzahl der Iterationen <i>num_iterations entspricht</i> , deren Elemente der Durchschnitt der Werte der bei jeder Iteration berechneten Stichproben von iteration_batch_size sind.  Bei gro√üen Stichprobenmengen passen die Daten m√∂glicherweise nicht mehr in den Speicher. In solchen F√§llen ist es daher ratsam, den Wert von <i>iteration_batch_size</i> zu verringern. <br><br>  <i>Beispiel</i> : Die urspr√ºngliche Stichprobe sei 2.000.000;  <i>num_iterations</i> = 10.000, <i>iteration_batch_size</i> = 300. Bei jeder der 10.000 Iterationen werden 300 Listen mit 2.000.000 Elementen im Speicher gespeichert. <br><br>  Die Funktion erm√∂glicht auch die parallele Berechnung auf mehreren Prozessorkernen und auf mehreren Threads, wobei die erforderliche Anzahl mithilfe des Parameters <i>num_threads festgelegt</i> wird. <br><br><pre> <code class="python hljs">bootstrap_ab()</code> </pre> <br>  f√ºhrt dieselben Aktionen aus wie die oben beschriebene Funktion <i>bootstrap ().</i> Zus√§tzlich wird die Aggregation von Durchschnittswerten jedoch auch mit der in <i>stat_func</i> angegebenen Methode <i>durchgef√ºhrt</i> - aus den Werten von <i>num_iterations</i> .  Als n√§chstes wird die im Parameter compare_func angegebene Metrik berechnet und die statistische Signifikanz gesch√§tzt. <br><br><pre> <code class="python hljs">compare_functions</code> </pre> <br>  - eine Klasse von Funktionen, die Werkzeuge zur Bildung von Metriken f√ºr die Bewertung bereitstellt: <br><pre> <code class="python hljs">compare_functions.difference() compare_functions.percent_change() compare_functions.ratio() compare_functions.percent_difference() <span class="hljs-comment"><span class="hljs-comment"># difference = (test_stat - ctrl_stat) # percent_change = (test_stat - ctrl_stat) * 100.0 / ctrl_stat # ratio = test_stat / ctrl_stat # percent_difference = (test_stat - ctrl_stat) / ((test_stat + ctrl_stat) / 2.0) * 100.0</span></span></code> </pre> <br><pre> <code class="python hljs">stats_functions</code> </pre>  - eine Klasse von Funktionen, aus denen die Aggregationsmethode der untersuchten Metrik ausgew√§hlt wird: <br><pre> <code class="python hljs">stats_functions.mean stats_functions.sum stats_functions.median stats_functions.std</code> </pre> <br>  Als <i>stat_func k√∂nnen</i> Sie auch eine benutzerdefinierte benutzerdefinierte Funktion verwenden, zum Beispiel: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(test_stat, ctrl_stat)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (test_stat - ctrl_stat)/test_stat bs.bootstrap_ab(test.values, control.values, stats_functions.mean, test_func, num_iterations=<span class="hljs-number"><span class="hljs-number">5000</span></span>, alpha=<span class="hljs-number"><span class="hljs-number">0.05</span></span>, iteration_batch_size=<span class="hljs-number"><span class="hljs-number">100</span></span>, scale_test_by=<span class="hljs-number"><span class="hljs-number">1</span></span>, num_threads=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br>  Tats√§chlich ist <i>(test_stat - ctrl_stat) / test_stat</i> die Formel zur Berechnung unserer Kannibalisierung. <br><br>  Alternativ oder zum Zweck eines praktischen Experiments k√∂nnen Sie zun√§chst Verteilungen mit <i>bootstrap ()</i> abrufen, die statistische Signifikanz von Unterschieden in Zielmetriken mithilfe von t-test √ºberpr√ºfen und dann die erforderlichen Manipulationen auf diese anwenden. <br>  Ein Beispiel daf√ºr, wie mit dieser Methode eine Normalverteilung ‚ÄûQualit√§t‚Äú erzielt werden kann: <br><br><img src="https://habrastorage.org/webt/pc/is/ws/pciswsulv_wuinbcqkn-hgmluwe.png"><br><br>  Eine ausf√ºhrlichere Dokumentation finden Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Repository-Seite</a> . <br><br>  Im Moment ist dies alles, wor√ºber ich sprechen wollte (oder konnte).  Ich habe versucht, die verwendeten Methoden und den Prozess ihrer Implementierung kurz, aber klar zu beschreiben.  Es ist m√∂glich, dass die Methoden angepasst werden m√ºssen, daher bin ich f√ºr Feedback und Bewertungen dankbar. <br><br>  Ich m√∂chte auch meinen Kollegen f√ºr ihre Hilfe bei der Vorbereitung dieser Arbeit danken.  Wenn der Artikel √ºberwiegend positives Feedback erh√§lt, werde ich hier deren Namen oder Spitznamen angeben (nach vorheriger Absprache). <br><br>  Beste W√ºnsche an alle!  :) :) <br><br>  PS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sehr geehrter Championship Channel</a> , die Aufgabe, die Ergebnisse von A / B-Tests auszuwerten, ist eine der wichtigsten in Data Science, da kein einziger Start eines neuen ML-Modells in der Produktion ohne A / B abgeschlossen ist.  Vielleicht ist es an der Zeit, einen Wettbewerb zu organisieren, um ein System zur Bewertung der Ergebnisse von A / B-Tests zu entwickeln?  :) :) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de451488/">https://habr.com/ru/post/de451488/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de451468/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 364 (6. - 12. Mai 2019)</a></li>
<li><a href="../de451476/index.html">LLVM in Bezug auf Go</a></li>
<li><a href="../de451478/index.html">Beschleunigung der Datenexploration mithilfe der Pandas-Profiling-Bibliothek</a></li>
<li><a href="../de451480/index.html">Warum verbietet das Ministerium f√ºr Industrie und Handel die Speicherung von Daten √ºber ausl√§ndische Ger√§te?</a></li>
<li><a href="../de451482/index.html">Kompetenzen eines modernen Programmierers aus einem anderen Blickwinkel</a></li>
<li><a href="../de451492/index.html">Sieben unerwartete Bash-Variablen</a></li>
<li><a href="../de451496/index.html">Mitap Netologii ‚ÄûKarriere in der Datenwissenschaft f√ºr Anf√§nger‚Äú</a></li>
<li><a href="../de451498/index.html">Food Design Digest, April 2019</a></li>
<li><a href="../de451502/index.html">Digitale Veranstaltungen in Moskau vom 13. bis 19. Mai</a></li>
<li><a href="../de451504/index.html">Bilder im Web 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
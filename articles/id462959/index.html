<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ¿â€ğŸ¤â€ğŸ‘¨ğŸ¼ ğŸ‘¨â€ğŸ¨ ğŸ¤²ğŸ¼ Pemrosesan Bahasa Alami untuk cek online: kursus pelajaran sihir untuk kucing biasa dan masalah lainnya ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ ğŸ‘¦ğŸ¾ â™¦ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="CleverDATA sedang mengembangkan platform untuk bekerja dengan data besar. Secara khusus, pada platform kami dimungkinkan untuk bekerja dengan informas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pemrosesan Bahasa Alami untuk cek online: kursus pelajaran sihir untuk kucing biasa dan masalah lainnya</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/462959/">  CleverDATA sedang mengembangkan platform untuk bekerja dengan data besar.  Secara khusus, pada platform kami dimungkinkan untuk bekerja dengan informasi dari cek belanja online.  Tugas kami adalah mempelajari cara memproses data teks cek dan membuat kesimpulan tentang konsumen untuk menciptakan karakteristik yang sesuai pada pertukaran data.  Itu wajar untuk mengatasi pembelajaran mesin untuk memecahkan masalah ini.  Pada artikel ini kami ingin berbicara tentang masalah yang kami temui dalam klasifikasi teks cek online. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cde/371/4f5/cde3714f55f236e3ea5ea8a4b8fc12f7.jpg"></div> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Sumber</a> <br><a name="habracut"></a><br>  Perusahaan kami mengembangkan solusi untuk monetisasi data.  Salah satu produk kami adalah pertukaran data 1DMC, yang memungkinkan Anda untuk memperkaya data dari sumber eksternal (lebih dari 9000 sumber, pemirsa hariannya sekitar 100 juta profil).  Tugas-tugas yang 1DMC bantu selesaikan diketahui oleh para pemasar: membangun segmen yang mirip, perusahaan media berbasis luas, kampanye iklan tertarget untuk khalayak yang sangat terspesialisasi, dll.  Jika perilaku Anda dekat dengan perilaku audiens target toko, maka Anda cenderung masuk ke segmen yang mirip.  Jika informasi tentang kecanduan Anda pada bidang minat apa pun dicatat, maka Anda dapat masuk ke kampanye iklan tertarget yang sangat terspesialisasi.  Pada saat yang sama, semua undang-undang tentang data pribadi diterapkan, Anda menerima iklan yang lebih relevan dengan minat Anda, dan perusahaan secara efektif menggunakan anggaran mereka untuk menarik pelanggan. <br><br>  Informasi tentang profil disimpan di bursa dalam bentuk berbagai atribut yang diartikan manusia: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c0b/dce/356/c0bdce356303c98084a640f38bf670a9.jpg"></div><br>  Ini mungkin informasi bahwa seseorang memiliki peralatan motor, misalnya, helikopter sepeda motor.  Atau bahwa seseorang memiliki minat pada makanan dari jenis tertentu, misalnya, dia adalah seorang vegetarian. <br><br><h2>  Pernyataan masalah dan cara untuk menyelesaikannya </h2><br>  Baru-baru ini, 1DMC menerima data dari salah satu operator data fiskal.  Untuk menyajikannya dalam bentuk atribut profil pertukaran, menjadi perlu untuk bekerja dengan memeriksa teks dalam bentuk mentah.  Berikut ini adalah teks cek khas untuk salah satu pelanggan: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/13e/da5/6b1/13eda56b1d67e7ef6c54278f164ed9b6.jpg"></div><br>  Dengan demikian, tugasnya adalah mencocokkan cek dengan atribut.  Menarik pembelajaran mesin untuk memecahkan masalah yang dijelaskan, pertama-tama, ada keinginan untuk mencoba metode <i>pengajaran tanpa guru</i> (Pembelajaran <i>Tanpa</i> Pengawasan).  Guru adalah informasi tentang jawaban yang benar, dan karena kita tidak memiliki informasi ini, metode pengajaran tanpa guru bisa cocok dengan kasus yang diselesaikan.  Metode pengajaran yang khas tanpa guru adalah pengelompokan, berkat sampel pelatihan ini dibagi menjadi kelompok atau kelompok yang stabil.  Dalam kasus kami, setelah mengelompokkan teks sesuai dengan kata-kata, kami harus membandingkan cluster yang dihasilkan dengan atribut.  Jumlah atribut unik cukup besar, sehingga diinginkan untuk menghindari markup manual.  Pendekatan lain untuk mengajar tanpa guru untuk teks disebut pemodelan topik, yang memungkinkan Anda untuk mengidentifikasi topik utama dalam teks yang tidak ditempatkan.  Setelah menggunakan pemodelan tematik, perlu membandingkan topik yang diperoleh dengan atribut, yang juga ingin saya hindari.  Selain itu, dimungkinkan untuk menggunakan kedekatan semantik antara teks cek dan deskripsi teks atribut berdasarkan model bahasa apa pun.  Namun, percobaan menunjukkan bahwa kualitas model berdasarkan kedekatan semantik tidak cocok untuk tugas kita.  Dari sudut pandang bisnis, Anda harus yakin bahwa seseorang menyukai jujitsu dan itulah sebabnya ia membeli barang olahraga.  Akan lebih menguntungkan jika tidak menggunakan kesimpulan menengah, kontroversial, dan diragukan.  Dengan demikian, sayangnya, metode pembelajaran tanpa pengawasan tidak cocok untuk tugas tersebut. <br><br>  Jika kita meninggalkan metode pembelajaran yang tidak diawasi, masuk akal untuk beralih ke metode pembelajaran yang diawasi dan, khususnya, ke klasifikasi.  Guru adalah informasi tentang kelas yang benar, dan pendekatan tipikal adalah melakukan klasifikasi multi-kelas, tetapi dalam kasus ini tugas menjadi rumit oleh kenyataan bahwa kita mendapatkan terlalu banyak kelas (dengan jumlah atribut unik).  Ada fitur lain: atribut dapat bekerja pada teks yang sama dalam beberapa grup, yaitu  klasifikasi harus multilabel.  Misalnya, informasi bahwa seseorang membeli kasing untuk telepon pintar dapat berisi atribut seperti: orang yang memiliki perangkat seperti Samsung dengan telepon Galaxy, membeli atribut Kasing Kasus Deppa, dan umumnya membeli aksesoris untuk telepon.  Artinya, beberapa atribut orang tertentu harus dicatat dalam profil sekaligus. <br><br>  Untuk menerjemahkan tugas ke dalam kategori "pelatihan dengan guru" Anda perlu mendapat markup.  Ketika orang-orang menghadapi masalah seperti itu, mereka mempekerjakan penilai dan, dengan imbalan uang dan waktu, mendapatkan markup yang baik dan membangun model prediksi dari markup.  Kemudian sering ternyata markupnya salah, dan penilai perlu terhubung untuk bekerja secara teratur, karena  atribut baru dan penyedia data baru muncul.  Cara alternatif adalah menggunakan Yandex.  Toloki. "  Ini memungkinkan Anda mengurangi biaya untuk penilai, tetapi tidak menjamin kualitas. <br><br>  Selalu ada opsi untuk menemukan pendekatan baru, dan diputuskan untuk pergi dengan cara ini.  Jika ada satu set teks untuk satu atribut, maka akan mungkin untuk membangun model klasifikasi biner.  Teks untuk setiap atribut dapat diperoleh dari permintaan pencarian, dan untuk pencarian Anda dapat menggunakan deskripsi teks dari atribut, yang ada di taksonomi.  Pada tahap ini, kami menemukan fitur berikut: teks output tidak begitu beragam untuk membangun model yang kuat dari mereka, dan untuk mendapatkan berbagai teks masuk akal untuk menggunakan augmentasi teks. <br><br><h2>  Augmentasi Teks </h2><br>  Untuk augmentasi teks, logis untuk menggunakan model bahasa.  Hasil karya model bahasa adalah embeddings - ini adalah pemetaan dari ruang kata ke ruang vektor dengan panjang tetap tertentu, dan vektor yang sesuai dengan kata-kata yang memiliki arti yang sama akan terletak bersebelahan di ruang baru, dan jauh dalam maknanya.  Untuk tugas augmentasi teks, properti ini adalah kuncinya, karena dalam hal ini perlu mencari sinonim.  Untuk sekumpulan kata acak atas nama atribut taksonomi, kami mengambil sampel subset acak elemen serupa dari ruang representasi teks. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9c9/f35/f30/9c9f35f30591478533dcd5c04116b539.jpg"></div><br>  Mari kita lihat augmentasi dengan sebuah contoh.  Seseorang memiliki ketertarikan pada genre mistis sinema.  Kami mengambil sampel, kami mendapatkan beragam teks yang dapat dikirim ke perayap dan mengumpulkan hasil pencarian.  Ini akan menjadi sampel positif untuk pelatihan pengklasifikasi. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6k/ja/si/6kjasijucptt4fute8dbcqjgolu.jpeg"></div><br>  Dan kami memilih sampel negatif dengan lebih mudah, kami mencicipi jumlah atribut yang sama yang tidak terkait dengan tema film: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lm/7i/si/lm7isiam3hbeokxsf8nl-gpk2ri.jpeg"></div><br><h2>  Pelatihan model </h2><br>  Saat menggunakan pendekatan TF-IDF (misalnya, di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> ) dengan filter berdasarkan frekuensi dan regresi logistik, Anda sudah bisa mendapatkan hasil yang sangat baik: teks yang awalnya sangat berbeda dikirim ke crawler, dan model tersebut berupaya dengan baik.  Tentu saja, perlu untuk memverifikasi operasi model pada data nyata, di bawah ini kami menyajikan hasil operasi model sesuai dengan atribut "minat membeli peralatan AEG". <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bx/t3/aa/bxt3aaszx7tj3ewyxoh0e5tvdtc.jpeg"></div><br>  Setiap baris berisi kata-kata AEG, model yang diatasi tanpa positif palsu.  Namun, jika kami mengambil kasus yang lebih rumit, misalnya, mobil GAZ, kami akan menghadapi masalah: model ini berfokus pada kata kunci dan tidak menggunakan konteks. <br><br><h2>  Menangani kesalahan </h2><br>  Kami akan membangun model yang menarik dalam melanjutkan pendidikan - kursus pelatihan kejuruan. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/iq/h2/r-/iqh2r-ultuusd2rkcos9xwqgp7e.jpeg"></div><br>  <i>Kursus pelajaran sihir untuk kucing biasa</i> juga merupakan kasus yang sulit, yang dapat menyesatkan seseorang. <br><br>  Untuk memfilter positif palsu, kami menggunakan embeddings: kami menghitung pusat sampel positif di ruang embedding dan mengukur jarak ke sana untuk setiap baris. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/je/sw/-5/jesw-5ara7karrwfnowtnoc2eay.jpeg"></div><br>  Perbedaan jarak untuk kursus pelajaran sihir dan perolehan abstrak terlihat dengan mata telanjang. <br><br>  Contoh lain: pemilik merek Audi.  Jarak dalam ruang embeddings dalam hal ini juga menyelamatkan dari positif palsu. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b4d/7dc/c79/b4d7dcc79d690f39080947f9bf89fa78.jpg"></div><br><br><h2>  Masalah skalabilitas </h2><br>  Hingga saat ini, pertukaran data beroperasi sekitar 30 ribu atribut, dan yang baru muncul secara teratur.  Kebutuhan untuk otomatisasi melatih model-model baru dan menandai dengan atribut-atribut baru cukup jelas.  Urutan langkah-langkah untuk membangun model atribut baru adalah sebagai berikut: <br><br><ol><li>  ambil nama atribut dari taksonomi; </li><li>  buat daftar permintaan ke mesin pencari menggunakan augmentasi teks; </li><li>  pemilihan teks kraulim; </li><li>  kami melatih model klasifikasi pada sampel yang diperoleh; </li><li>  katakanlah model pembelian data mentah yang terlatih; </li><li>  filter hasilnya dengan word2vec ke pusat kelas positif. </li></ol><br>  Ada sejumlah titik lemah dalam algoritma yang dijelaskan di atas: <br><br><ol><li>  sulit untuk mengendalikan kumpulan teks yang berjongkok; </li><li>  sulit untuk mengontrol kualitas sampel pelatihan; </li><li>  tidak ada cara untuk menentukan apakah model yang terlatih baik melakukan tugasnya. </li></ol><br>  Penting untuk dipahami bahwa metrik klasik tidak cocok untuk kontrol kualitas model yang terlatih, karena  informasi yang hilang pada kelas benar dalam teks cek.  Pembelajaran dan prediksi terjadi pada data yang berbeda, kualitas model dapat diukur pada sampel pelatihan, dan tidak ada markup pada tubuh teks utama, yang berarti Anda tidak dapat menggunakan metode biasa untuk mengevaluasi kualitas. <br><br><h2>  Penilaian kualitas model </h2><br>  Untuk menilai kualitas model yang dilatih, kami mengambil dua populasi: satu merujuk pada objek di bawah ambang batas respon model, yang kedua mengacu pada objek di mana model dievaluasi di atas ambang batas. <br><br>  Untuk setiap populasi, kami menghitung jarak word2vec ke pusat sampel pelatihan positif.  Kami mendapatkan dua distribusi jarak yang terlihat seperti ini. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wx/y9/od/wxy9odzkbwh1hpcdrs512uodvs4.png"></div><br>  Warna merah menunjukkan distribusi jarak untuk objek yang telah melewati ambang, dan biru menunjukkan objek di bawah ambang batas sesuai dengan penilaian model.  Distribusi dapat dibagi, dan untuk memperkirakan jarak antara distribusi, pertama-tama logis untuk merujuk pada Kullback-Leibler Divergence (DKL).  DCL adalah fungsional asimetris, ketimpangan segitiga tidak puas.  Pembatasan ini mempersulit penggunaan DCL sebagai metrik, tetapi dapat digunakan jika mencerminkan ketergantungan yang diperlukan.  Dalam kasus kami, DCL mengasumsikan nilai konstan pada semua model terlepas dari nilai ambang, sehingga menjadi perlu untuk mencari metode lain. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ug/td/js/ugtdjs3kl2t8pu4ng-w_tqz-jho.png"></div><br>  Untuk memperkirakan jarak antara distribusi, kami menghitung selisih antara nilai rata-rata distribusi.  Perbedaan yang dihasilkan dapat diukur dalam standar deviasi distribusi awal jarak.  Nyatakan nilai yang diperoleh dengan metrik-Z dengan analogi dengan nilai-Z, dan nilai metrik-Z akan menjadi fungsi dari nilai ambang batas dari model prediksi.  Untuk setiap ambang batas tetap dari model, fungsi Z-metrik mengembalikan perbedaan antara distribusi dalam sigma dari distribusi jarak awal. <br><br>  Dari banyak pendekatan yang diuji, Z-metriklah yang memberikan ketergantungan yang diperlukan untuk menentukan kualitas model yang dibangun. <br><br>  Pertimbangkan perilaku metrik-Z: semakin besar metrik-Z, semakin baik model yang diatasi, karena semakin besar jarak antara distribusi mencirikan klasifikasi kualitatif.  Namun, aturan keputusan yang didefinisikan dengan jelas untuk menentukan klasifikasi kualitatif tidak dapat diturunkan.  Misalnya, model dengan Z-metrik di sudut kiri bawah gambar mendapat nilai konstan sama dengan 10. Model ini menentukan minat bepergian ke Thailand.  Sampel pelatihan sebagian besar diiklankan oleh berbagai spa, dan model dilatih pada teks yang tidak terkait langsung dengan perjalanan ke Thailand.  Artinya, model ini bekerja dengan baik, tetapi tidak mencerminkan minat dalam perjalanan ke Thailand. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/49e/b66/ca9/49eb66ca99544712498283d2be31ee65.jpg"></div>  <i>Z-metic untuk sejumlah model prediksi.</i>  <i>Model di bagian kanan gambar bagus, dan lima model di bagian kiri jelek.</i> <br><br>  Selama pencarian dan percobaan, 160 model dengan markup sesuai dengan kriteria "baik / buruk" telah terkumpul.  Berdasarkan tanda-tanda z-metrik, sebuah meta-model yang didasarkan pada peningkatan gradien dibangun yang menentukan kualitas model yang dibangun.  Dengan demikian, dimungkinkan untuk mengkonfigurasi pemantauan kualitas model yang dibangun dalam mode otomatis. <br><br><h2>  Ringkasan </h2><br>  Saat ini, urutan tindakan adalah sebagai berikut: <br><br><ol><li>  ambil nama atribut dari taksonomi; </li><li>  buat daftar permintaan ke mesin pencari menggunakan augmentasi teks; </li><li>  pemilihan teks kraulim; </li><li>  kami melatih model klasifikasi pada sampel yang diperoleh; </li><li>  katakanlah model pembelian data mentah yang terlatih; </li><li>  kami memfilter hasilnya dengan word2vec jarak ke pusat kelas positif; </li><li>  kami menghitung Z-metrik dan membuat tanda untuk meta-model; </li><li>  kami menggunakan meta-model dan mengevaluasi kualitas model yang dihasilkan; </li><li>  jika model memiliki kualitas yang dapat diterima, maka ditambahkan ke set model yang digunakan.  Jika tidak, model kembali untuk revisi. </li></ol><br>  Menurut penilaian meta-model dalam mode otomatis, keputusan dibuat untuk memperkenalkannya ke dalam produksi atau untuk dikembalikan untuk revisi.  Penyempurnaan dimungkinkan dengan berbagai cara yang telah diturunkan untuk analis. <br><br><ul><li>  Seringkali model menghalangi kata-kata tertentu yang memiliki beberapa makna.  Daftar hitam kata-kata menipu membuat model lebih mudah untuk dikerjakan. </li><li>  Pendekatan lain adalah membuat aturan untuk mengecualikan objek dari set pelatihan.  Pendekatan ini membantu jika metode pertama tidak berhasil. </li><li>  Untuk teks kompleks dan atribut multi-nilai, kamus khusus ditransfer ke model, yang membatasi model, tetapi memungkinkan Anda untuk mengontrol kesalahan. </li></ul><br><h2>  Tapi bagaimana dengan jaringan saraf? </h2><br>  Pertama-tama, ada keinginan untuk menggunakan jaringan saraf untuk tugas yang dijelaskan.  Misalnya, seseorang dapat melatih Transformer pada kumpulan teks yang besar, dan kemudian membuat Transfer Pembelajaran pada set sampel pelatihan kecil dari setiap atribut.  Sayangnya, penggunaan jaringan saraf seperti itu harus ditinggalkan karena alasan berikut. <br><br><ul><li>  Jika model untuk satu atribut berhenti berfungsi dengan benar, maka perlu untuk dapat menonaktifkannya tanpa kehilangan atribut yang tersisa. </li><li>  Jika model tidak berfungsi dengan baik untuk satu atribut, maka perlu menyetel dan menyetel model secara terpisah, tanpa risiko merusak hasilnya untuk atribut lainnya. </li><li>  Ketika atribut baru muncul, Anda perlu mendapatkan model untuk itu sesegera mungkin, tanpa pelatihan jangka panjang semua model (atau satu model besar). </li><li>  Memecahkan masalah kontrol kualitas untuk satu atribut lebih cepat dan lebih mudah daripada menyelesaikan masalah kontrol kualitas untuk semua atribut sekaligus.  Jika model besar tidak mengatasi salah satu atribut, Anda harus menyesuaikan dan menyesuaikan seluruh model besar, yang membutuhkan lebih banyak waktu dan perhatian spesialis. </li></ul><br>  Dengan demikian, ansambel model kecil independen untuk menyelesaikan masalah ternyata lebih praktis daripada model besar dan kompleks.  Selain itu, model bahasa dan embedding masih digunakan untuk kontrol kualitas dan augmentasi teks, sehingga tidak mungkin untuk sepenuhnya menggunakan jaringan saraf, dan tidak ada tujuan seperti itu.  Penggunaan jaringan saraf terbatas pada tugas-tugas di mana mereka diperlukan. <br><br><h2>  Untuk dilanjutkan </h2><br>  Pekerjaan pada proyek berlanjut: perlu untuk mengatur pemantauan, memperbarui model, bekerja dengan anomali, dll.  Salah satu bidang prioritas untuk pengembangan lebih lanjut adalah tugas mengumpulkan dan menganalisis kasus-kasus yang belum diklasifikasikan oleh model apa pun dari ansambel.  Namun demikian, sudah sekarang kita melihat hasil pekerjaan kami: sekitar 60% dari cek setelah menerapkan model menerima atribut mereka.  Jelas, ada proporsi yang signifikan dari cek yang tidak membawa informasi tentang kepentingan pemilik, sehingga tingkat yang sepenuhnya dimiliki tidak dapat dicapai.  Namun demikian, sangat menggembirakan bahwa hasil yang diperoleh sejauh ini sudah melebihi harapan kami dan kami terus bekerja ke arah ini. <br><br>  Artikel ini ditulis bersama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">samy1010</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Dan pekerjaan tradisional!</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Insinyur perangkat lunak</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Analis</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Analis Data Senior</a> </li></ul></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id462959/">https://habr.com/ru/post/id462959/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id462947/index.html">Kisah bagaimana PVS-Studio menemukan kesalahan di perpustakaan yang digunakan di ... PVS-Studio</a></li>
<li><a href="../id462949/index.html">Kisah bagaimana PVS-Studio menemukan kesalahan di perpustakaan yang digunakan di ... PVS-Studio</a></li>
<li><a href="../id462951/index.html">Di mana seseorang melihat bentuk, AI melihat tekstur</a></li>
<li><a href="../id462955/index.html">Transformasi digital pelatihan dan sertifikasi staf lapangan</a></li>
<li><a href="../id462957/index.html">Pro dan kontra: ambang harga untuk .org masih dibatalkan</a></li>
<li><a href="../id462961/index.html">Intisari Ilmu Data (Agustus 2019)</a></li>
<li><a href="../id462963/index.html">Menggunakan API Konteks dalam Bereaksi untuk membuat tema aplikasi global</a></li>
<li><a href="../id462965/index.html">Naikkan server 1c dengan publikasi database dan layanan web di Linux</a></li>
<li><a href="../id462967/index.html">Hacks ketika bekerja dengan sejumlah besar file kecil</a></li>
<li><a href="../id462969/index.html">Bagaimana pihak berwenang Kazakhstani berusaha menutupi kegagalan mereka dengan diperkenalkannya sertifikat</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
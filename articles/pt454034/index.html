<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëçüèΩ üîê üëè Primeiro Modelo: Conjunto de Dados Fashion MNIST üë®üèº‚Äçüè´ üè¢ üåü</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O curso completo em russo pode ser encontrado neste link . 
 O curso de ingl√™s original est√° dispon√≠vel neste link . 

 Novas palestras s√£o agendadas ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Primeiro Modelo: Conjunto de Dados Fashion MNIST</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454034/">  O curso completo em russo pode ser encontrado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste link</a> . <br>  O curso de ingl√™s original est√° dispon√≠vel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste link</a> . <br><img src="https://habrastorage.org/webt/ry/3a/55/ry3a55ljajwq9gp5jwwhztrxyxo.png"><br>  <i>Novas palestras s√£o agendadas a cada 2-3 dias.</i> <br><a name="habracut"></a><br><h2>  Entrevista com Sebastian Trun, CEO da Udacity </h2><br>  "Ent√£o, ainda estamos com voc√™ e conosco, como antes, Sebastian."  N√≥s apenas queremos discutir camadas totalmente conectadas, essas mesmas camadas densas.  Antes disso, eu gostaria de fazer uma pergunta.  Quais s√£o os limites e quais s√£o os principais obst√°culos que atrapalhar√£o o aprendizado profundo e ter√£o maior impacto nos pr√≥ximos 10 anos?  Tudo muda t√£o r√°pido!  O que voc√™ acha que ser√° a pr√≥xima "grande coisa"? <br>  Eu diria duas coisas.  A primeira √© a IA geral para mais de uma tarefa.  Isso √© √≥timo!  As pessoas podem resolver mais de um problema e nunca devem fazer a mesma coisa.  O segundo √© trazer a tecnologia ao mercado.  Para mim, a peculiaridade do aprendizado de m√°quina √© que ele fornece aos computadores a capacidade de observar e encontrar padr√µes nos dados, ajudando as pessoas a se tornarem melhores no campo - no n√≠vel de especialista!  O aprendizado de m√°quina pode ser usado em leis, medicina e carros aut√¥nomos.  Desenvolva esses aplicativos porque eles podem gerar uma enorme quantia de dinheiro, mas o mais importante √© que voc√™ tem a oportunidade de tornar o mundo um lugar muito melhor. <br>  ‚ÄúGosto muito da maneira como voc√™ diz tudo em uma √∫nica imagem do aprendizado profundo e de sua aplica√ß√£o - essa √© apenas uma ferramenta que pode ajud√°-lo a resolver um problema espec√≠fico. <br>  Sim, exatamente!  Ferramenta incr√≠vel, certo? <br>  - Sim, sim, concordo plenamente com voc√™! <br>  "Quase como um c√©rebro humano!" <br>  - Voc√™ mencionou aplica√ß√µes m√©dicas em nossa primeira entrevista, na primeira parte do curso em v√≠deo.  Em quais aplica√ß√µes, na sua opini√£o, o uso da aprendizagem profunda causa o maior prazer e surpresa? <br>  Muito!  Muito!  A medicina est√° na pequena lista de √°reas que usam ativamente o aprendizado profundo.  Perdi minha irm√£ h√° alguns meses, ela estava com c√¢ncer, o que √© muito triste.  Eu acho que existem muitas doen√ßas que podem ser detectadas mais cedo - nos est√°gios iniciais, tornando poss√≠vel cur√°-las ou retardar o processo de seu desenvolvimento.  A id√©ia, de fato, √© transferir algumas ferramentas para a casa (casa inteligente), para que seja poss√≠vel detectar tais desvios na sa√∫de muito antes do momento em que a pr√≥pria pessoa os v√™.  Eu tamb√©m acrescentaria - tudo √© repetido, qualquer trabalho de escrit√≥rio, no qual voc√™ executa o mesmo tipo de a√ß√µes repetidamente, por exemplo, contabilidade.  At√© eu, como CEO, fa√ßo muitas a√ß√µes repetitivas.  Seria √≥timo automatiz√°-los, at√© trabalhar com correspond√™ncia por email! <br>  - Eu n√£o posso discordar de voc√™!  Nesta li√ß√£o, apresentaremos aos alunos um curso com uma camada de rede neural chamada camada densa.  Voc√™ poderia nos dizer com mais detalhes o que pensa sobre as camadas totalmente conectadas? <br>  - Ent√£o, vamos come√ßar com o fato de que cada rede pode ser conectada de maneiras diferentes.  Alguns deles podem ter conectividade muito estreita, o que permite obter alguns benef√≠cios no dimensionamento e na "vit√≥ria" contra grandes redes.  √Äs vezes, voc√™ n√£o sabe quantas conex√µes precisa e conecta tudo com tudo - isso √© chamado de camada totalmente conectada.  Acrescento que essa abordagem tem muito mais poder e potencial do que algo mais estruturado. <br>  - Concordo plenamente com voc√™!  Obrigado por nos ajudar a aprender um pouco mais sobre as camadas totalmente conectadas.  Estou ansioso pelo momento em que finalmente come√ßamos a implement√°-los e escrever c√≥digo. <br>  - Divirta-se!  Vai ser muito divertido! <br><br><h2>  1. Introdu√ß√£o </h2><br>  - Bem vindo de volta!  Na √∫ltima li√ß√£o, voc√™ descobriu como construir sua primeira rede neural usando o TensorFlow e Keras, como as redes neurais funcionam e como o processo de treinamento (treinamento) funciona.  Em particular, vimos como treinar o modelo para converter graus Celsius em graus Fahrenheit. <br><br><img src="https://habrastorage.org/webt/7h/jc/jq/7hjcjqzg5rz1qzpbncjes5ipor8.jpeg"><br><br>  - Tamb√©m nos familiarizamos com o conceito de camadas totalmente conectadas (camadas densas), a camada mais importante nas redes neurais.  Mas nesta li√ß√£o, faremos coisas muito mais legais!  Nesta li√ß√£o, desenvolveremos uma rede neural capaz de reconhecer elementos e imagens de roupas.  Como mencionamos anteriormente, o aprendizado de m√°quina usa entradas chamadas "recursos" e sa√≠das chamadas "r√≥tulos", pelas quais o modelo aprende e encontra um algoritmo de transforma√ß√£o.  Portanto, em primeiro lugar, precisaremos de muitos exemplos para treinar a rede neural para reconhecer v√°rios elementos da roupa.  Deixe-me lembr√°-lo de que um exemplo de treinamento √© um par de valores - um recurso de entrada e um r√≥tulo de sa√≠da, que s√£o alimentados na entrada de uma rede neural.  Em nosso novo exemplo, a entrada ser√° uma imagem e a etiqueta de sa√≠da deve ser a categoria de roupa √† qual o item de roupa mostrado na imagem pertence.  Felizmente, esse conjunto de dados j√° existe.  Chama-se Moda MNIST.  Examinaremos mais de perto esse conjunto de dados na pr√≥xima parte. <br><br><h2>  Conjunto de dados MNIST de moda </h2><br>  Bem-vindo ao mundo do conjunto de dados MNIST!  Portanto, nosso conjunto consiste em imagens de 28x28, cada pixel representando um tom de cinza. <br><br><img src="https://habrastorage.org/webt/ua/mr/f6/uamrf6n8gci7qi2c1t_ganxtai8.jpeg"><br><br>  O conjunto de dados cont√©m imagens de camisetas, blusas, sand√°lias e at√© botas.  Aqui est√° uma lista completa do que o nosso conjunto de dados MNIST cont√©m: <br><br><img src="https://habrastorage.org/webt/3i/ce/7n/3ice7nwlkok2g_n-trodker5s7e.jpeg"><br><br>  Cada imagem de entrada corresponde a um dos r√≥tulos acima.  O conjunto de dados Fashion MNIST cont√©m 70.000 imagens, portanto, temos um local para come√ßar e trabalhar.  Desses 70.000, usaremos 60.000 para treinar a rede neural. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  E usaremos os 10.000 elementos restantes para verificar at√© que ponto nossa rede neural aprendeu a reconhecer elementos da roupa.  Mais tarde, explicaremos por que dividimos o conjunto de dados em um conjunto de treinamento e um conjunto de testes. <br><br>  Ent√£o, aqui est√° o nosso conjunto de dados do Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/mx/lw/dz/mxlwdzjrfhviwmgsliwdcy6tbwq.png"><br><br>  Lembre-se de que cada imagem no conjunto de dados √© uma imagem de tamanho 28x28 em tons de cinza, o que significa que cada imagem tem 784 bytes de tamanho.  Nossa tarefa √© criar uma rede neural, que receba esses 784 bytes na entrada e na sa√≠da retorne a qual categoria de roupas dentre 10 dispon√≠veis, o elemento aplicado na entrada pertence. <br><br><h2>  Rede neural </h2><br>  Nesta li√ß√£o, usaremos uma rede neural profunda que aprende a classificar imagens do conjunto de dados Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/xg/cr/h_/xgcrh_cowdhfz-owx34wp-kqzi0.png"><br><br>  A imagem acima mostra como ser√° nossa rede neural.  Vamos dar uma olhada em mais detalhes. <br><br>  O valor de entrada da nossa rede neural √© uma matriz unidimensional com um comprimento de 784, uma matriz exatamente desse comprimento pelo motivo de cada imagem ter 28x28 pixels (= 784 pixels no total na imagem), que converteremos em uma matriz unidimensional.  O processo de convers√£o de uma imagem 2D em um vetor √© chamado nivelamento e √© implementado atrav√©s de uma camada de nivelamento - uma camada de nivelamento. <br><br><img src="https://habrastorage.org/webt/7d/wu/d_/7dwud_tt2qctnaigzc8my3pz1j0.png"><br><br>  Voc√™ pode executar a suaviza√ß√£o criando a camada apropriada: <br><br><pre><code class="python hljs">tf.keras.layers.Flatten(input_shape=[<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Essa camada converte uma imagem 2D de 28x28 pixels (1 byte para tons de cinza para cada pixel) em uma matriz 1D de 784 pixels. <br><br>  Os valores de entrada ser√£o totalmente associados √† nossa primeira camada de rede <code>dense</code> , cujo tamanho escolhemos igual a 128 neur√¥nios. <br><br><img src="https://habrastorage.org/webt/mk/n_/3w/mkn_3wrocxruhbwhil0fmh5wh_8.png"><br><br>  Aqui est√° como ser√° a cria√ß√£o dessa camada no c√≥digo: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu)</code> </pre><br>  Pare com isso!  O que √© um <code>tf.nn.relu</code> ?  N√£o usamos isso em nosso exemplo anterior de rede neural ao converter graus Celsius em graus Fahrenheit!  O ponto principal √© que a tarefa atual √© muito mais complicada do que a que foi usada como exemplo de descoberta de fatos - a convers√£o de graus Celsius em graus Fahrenheit. <br><br>  <code>ReLU</code> √© uma fun√ß√£o matem√°tica que adicionamos √† nossa camada totalmente conectada e que d√° mais poder √† nossa rede.  De fato, essa √© uma pequena extens√£o para nossa camada totalmente conectada, o que permite que nossa rede neural resolva problemas mais complexos.  N√£o entraremos em detalhes, mas informa√ß√µes um pouco mais detalhadas podem ser encontradas abaixo. <br><br>  Finalmente, nossa √∫ltima camada, tamb√©m conhecida como camada de sa√≠da, consiste em 10 neur√¥nios.  Consiste em 10 neur√¥nios porque nosso conjunto de dados Fashion MNIST cont√©m 10 categorias de roupas.  Cada um desses 10 valores de sa√≠da representar√° a probabilidade de a imagem de entrada estar nessa categoria de roupas.  Em outras palavras, esses valores refletem a ‚Äúconfian√ßa‚Äù do modelo na corre√ß√£o da previs√£o e correla√ß√£o da imagem arquivada com uma de 10 categorias de roupas espec√≠ficas na sa√≠da.  Por exemplo, qual √© a probabilidade de a imagem mostrar um vestido, t√™nis, sapatos etc. <br><br><img src="https://habrastorage.org/webt/fo/2b/3v/fo2b3vakws6ubmiwtj9rrctltla.png"><br><br>  Por exemplo, se uma imagem de camisa √© enviada para a entrada da nossa rede neural, o modelo pode nos fornecer resultados como os que voc√™ v√™ na imagem acima - a probabilidade da imagem de entrada corresponder ao r√≥tulo de sa√≠da. <br><br>  Se voc√™ prestar aten√ß√£o, notar√° que a maior probabilidade - 0,85 refere-se √† etiqueta 6, que corresponde √† camisa.  O modelo tem 85% de certeza de que a imagem na camiseta.  Normalmente, coisas que parecem camisas tamb√©m ter√£o uma alta probabilidade e coisas menos semelhantes ter√£o uma menor probabilidade. <br><br>  Como todos os 10 valores de sa√≠da correspondem a probabilidades, ao somar todos esses valores, obtemos 1. Esses 10 valores tamb√©m s√£o chamados de distribui√ß√£o de probabilidade. <br><br>  Agora precisamos de uma camada de sa√≠da para calcular as pr√≥prias probabilidades para cada etiqueta. <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br>  E faremos isso com o seguinte comando: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax)</code> </pre><br>  De fato, sempre que criamos redes neurais que resolvem problemas de classifica√ß√£o, sempre usamos uma camada totalmente conectada como a √∫ltima camada de uma rede neural.  A √∫ltima camada da rede neural deve conter o n√∫mero de neur√¥nios igual ao n√∫mero de classes, √†s quais determinamos a <code>softmax</code> e usamos a fun√ß√£o de ativa√ß√£o do softmax. <br><br><h3>  <code>ReLU</code> - fun√ß√£o de ativa√ß√£o de neur√¥nios </h3><br>  Nesta li√ß√£o, falamos sobre a <code>ReLU</code> como algo que amplia os recursos de nossa rede neural e lhe fornece energia adicional. <br><br>  <code>ReLU</code> √© uma fun√ß√£o matem√°tica que se parece com isso: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/691/c04/e7b/691c04e7b270706458daf61c4b38cf22.png" alt="imagem"><br><br>  A fun√ß√£o <code>ReLU</code> retorna 0 se o valor de entrada for um valor negativo ou zero; em todos os outros casos, a fun√ß√£o retornar√° o valor de entrada original. <br><br>  <code>ReLU</code> torna poss√≠vel resolver problemas n√£o lineares. <br><br>  Converter graus Celsius em graus Fahrenheit √© uma tarefa linear, porque a express√£o <code>f = 1.8*c + 32</code> √© a equa√ß√£o da reta - <code>y = m*x + b</code> .  Mas a maioria das tarefas que queremos resolver √© n√£o linear.  Nesses casos, adicionar a fun√ß√£o de ativa√ß√£o ReLU √† nossa camada totalmente conectada pode ajudar nesse tipo de tarefa. <br><br>  <code>ReLU</code> √© apenas um tipo de fun√ß√£o de ativa√ß√£o.  Existem fun√ß√µes de ativa√ß√£o, como sigmoid, ReLU, ELU, tanh, no entanto, √© o <code>ReLU</code> que <code>ReLU</code> mais frequentemente usado como a fun√ß√£o de ativa√ß√£o padr√£o.  Para criar e usar modelos que incluem ReLU, voc√™ n√£o precisa entender como ele funciona internamente.  Se voc√™ ainda deseja entender melhor, recomendamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este artigo</a> . <br><br>  Vamos revisar os novos termos introduzidos nesta li√ß√£o: <br><br><ul><li>  <b>Suaviza√ß√£o</b> - o processo de convers√£o de uma imagem 2D em um vetor 1D; </li><li>  <b>ReLU</b> √© uma fun√ß√£o de ativa√ß√£o que permite ao modelo resolver problemas n√£o lineares; </li><li>  <b>Softmax</b> - uma fun√ß√£o que calcula as probabilidades para cada classe de sa√≠da poss√≠vel; </li><li>  <b>Classifica√ß√£o</b> - uma classe de tarefas de aprendizado de m√°quina usadas para determinar as diferen√ßas entre duas ou mais categorias (classes). </li></ul><br><h2>  Treinamento e teste </h2><br>  Ao treinar um modelo, qualquer modelo no aprendizado de m√°quina, √© sempre necess√°rio dividir o conjunto de dados em pelo menos dois conjuntos diferentes - o conjunto de dados usado para treinamento e o conjunto de dados usado para teste.  Nesta parte, entenderemos por que vale a pena fazer isso. <br><br>  Vamos lembrar como distribu√≠mos nosso conjunto de dados do Fashion MNIST, composto por 70.000 c√≥pias. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Propusemos dividir 70.000 em duas partes - na primeira parte, deixamos 60.000 para treinamento e na segunda parte 10.000 para testes.  A necessidade dessa abordagem √© causada pelo seguinte fato: ap√≥s o modelo ter sido treinado em 60.000 c√≥pias, √© necess√°rio verificar os resultados e a efic√°cia de seu trabalho em exemplos que ainda n√£o estavam no conjunto de dados em que o modelo foi treinado. <br><br>  √Ä sua maneira, assemelha-se a passar em um exame na escola.  Antes de passar no exame, voc√™ est√° empenhado em resolver problemas de uma classe espec√≠fica.  Em seguida, no exame, voc√™ encontra a mesma classe de problemas, mas com dados de entrada diferentes.  N√£o faz sentido enviar os mesmos dados que estavam durante o treinamento; caso contr√°rio, a tarefa ser√° reduzida a lembrar decis√µes e n√£o procurar um modelo de solu√ß√£o.  √â por isso que nos exames voc√™ se depara com tarefas que n√£o estavam anteriormente no curr√≠culo.  Somente dessa maneira podemos verificar se o modelo aprendeu a solu√ß√£o geral ou n√£o. <br><br>  O mesmo acontece com o aprendizado de m√°quina.  Voc√™ mostra alguns dados que representam uma determinada classe de tarefas que voc√™ deseja aprender a resolver.  No nosso caso, com um conjunto de dados do Fashion MNIST, queremos que a rede neural seja capaz de determinar a categoria √† qual o elemento vestu√°rio na imagem pertence.  √â por isso que treinamos nosso modelo em 60.000 exemplos que cont√™m todas as categorias de itens de vestu√°rio.  Ap√≥s o treinamento, queremos verificar a efic√°cia do modelo, para alimentar os 10.000 itens restantes de roupas que o modelo ainda n√£o ‚Äúviu‚Äù.  Se decid√≠ssemos n√£o fazer isso, n√£o testar com 10.000 exemplos, n√£o poder√≠amos dizer com certeza se nosso modelo foi realmente treinado para determinar a classe do item de vestu√°rio ou se ela se lembrava de todos os pares de valores de entrada + sa√≠da. <br><br>  √â por isso que no aprendizado de m√°quina sempre temos um conjunto de dados para treinamento e um conjunto de dados para teste. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O TensorFlow</a> √© uma cole√ß√£o de dados de treinamento prontos para uso. <br><br>  Os conjuntos de dados geralmente s√£o divididos em v√°rios blocos, cada um dos quais √© usado em um determinado est√°gio do treinamento e teste da efic√°cia da rede neural.  Nesta parte, falamos sobre: <br><br><ul><li>  <b>conjunto de dados de treinamento</b> : um conjunto de dados destinado ao treinamento de uma rede neural; </li><li>  <b>conjunto de dados de teste</b> : um conjunto de dados projetado para verificar a efici√™ncia de uma rede neural; </li></ul><br>  Considere outro conjunto de dados, que eu chamo de conjunto de dados de valida√ß√£o.  Este conjunto de dados n√£o √© usado <b>para</b> treinar o modelo, apenas <b>durante o</b> treinamento.  Assim, depois que nosso modelo passou por v√°rios ciclos de treinamento, alimentamos nosso conjunto de dados de teste e analisamos os resultados.  Por exemplo, se durante o treinamento o valor da fun√ß√£o de perda diminuir e a precis√£o se deteriorar no conjunto de dados de teste, isso significa que nosso modelo simplesmente se lembra dos pares de valores de entrada e sa√≠da. <br><br>  O conjunto de dados de verifica√ß√£o √© reutilizado no final do treinamento para medir a precis√£o final das previs√µes do modelo. <br><br>  Para obter mais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">informa√ß√µes sobre conjuntos de dados de treinamento e teste, consulte o curso de falha do Google</a> . <br><br><h2>  Parte pr√°tica no CoLab </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link para o CoLab original em ingl√™s</a> e um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">link para o Russian CoLab</a> . <br><br><h2>  Classifica√ß√£o de imagens de itens de vestu√°rio </h2><br>  Nesta parte da li√ß√£o, construiremos e treinaremos uma rede neural para classificar imagens de elementos de vestu√°rio, como vestidos, t√™nis, camisas, camisetas, etc. <br><br>  Tudo bem se alguns momentos n√£o estiverem claros.  O objetivo deste curso √© apresentar o TensorFlow e ao mesmo tempo explicar os algoritmos de seu trabalho e desenvolver um entendimento comum de projetos usando o TensorFlow, em vez de investigar os detalhes da implementa√ß√£o. <br><br>  Nesta parte, usamos o <code>tf.keras</code> , uma API de alto n√≠vel para criar e treinar modelos no TensorFlow. <br><br><h3>  Instalando e Importando Depend√™ncias </h3><br>  Vamos precisar de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um conjunto de dados TensorFlow</a> , uma API que simplifique o carregamento e o acesso a conjuntos de dados fornecidos por v√°rios servi√ßos.  Tamb√©m precisaremos de algumas bibliotecas auxiliares. <br><br><pre> <code class="python hljs">!pip install -U tensorflow_datasets</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-comment"><span class="hljs-comment">#  TensorFlow    TensorFlow import tensorflow as tf import tensorflow_datasets as tfds tf.logging.set_verbosity(tf.logging.ERROR) #   import math import numpy as np import matplotlib.pyplot as plt #    import tqdm import tqdm.auto tqdm.tqdm = tqdm.auto.tqdm print(tf.__version__) tf.enable_eager_execution()</span></span></code> </pre><br><h3>  Importar o conjunto de dados Fashion MNIST </h3><br>  Este exemplo usa o conjunto de dados Fashion MNIST, que cont√©m 70.000 imagens de itens de vestu√°rio em 10 categorias em escala de cinza.  As imagens cont√™m itens de vestu√°rio em baixa resolu√ß√£o (28x28 pixels), conforme mostrado abaixo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/2c1/da3/18d2c1da3b5c7dbff14ea81077d9ed24.png" alt="imagem"><br><br>  O Fashion MNIST √© usado como um substituto para o conjunto de dados cl√°ssico do MNIST - geralmente usado como "Ol√°, Mundo!"  em aprendizado de m√°quina e vis√£o computacional.  O conjunto de dados MNIST cont√©m imagens de n√∫meros escritos √† m√£o (0, 1, 2 etc.) no mesmo formato que os itens de vestu√°rio em nosso exemplo. <br><br>  Em nosso exemplo, usamos o Fashion MNIST por causa da variedade e porque esta tarefa √© mais interessante do ponto de vista da implementa√ß√£o do que resolver um problema t√≠pico no conjunto de dados MNIST.  Ambos os conjuntos de dados s√£o pequenos o suficiente, portanto, s√£o usados ‚Äã‚Äãpara verificar a operacionalidade correta do algoritmo.  √ìtimos conjuntos de dados para iniciar o aprendizado de m√°quina, teste e c√≥digo de depura√ß√£o. <br><br>  Usaremos 60.000 imagens para treinar a rede e 10.000 imagens para testar a precis√£o do treinamento e da classifica√ß√£o de imagens.  Voc√™ pode acessar diretamente o conjunto de dados Fashion MNIST atrav√©s do TensorFlow usando a API: <br><br><pre> <code class="python hljs">dataset, metadata = tfds.load(<span class="hljs-string"><span class="hljs-string">'fashion_mnist'</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_dataset, test_dataset = dataset[<span class="hljs-string"><span class="hljs-string">'train'</span></span>], dataset[<span class="hljs-string"><span class="hljs-string">'test'</span></span>]</code> </pre><br>  Ao carregar um conjunto de dados, obtemos metadados, um conjunto de dados de treinamento e um conjunto de dados de teste. <br><br><ul><li>  O modelo √© treinado em um conjunto de dados de `train_dataset` </li><li>  O modelo √© testado em um conjunto de dados de `test_dataset` </li></ul><br>  As imagens s√£o matrizes bidimensionais de <code>2828</code> , onde os valores em cada c√©lula podem estar no intervalo <code>[0, 255]</code> .  Etiquetas - uma matriz de n√∫meros inteiros, onde cada valor est√° no intervalo <code>[0, 9]</code> .  Esses r√≥tulos correspondem √† classe de imagem de sa√≠da da seguinte maneira: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Etiqueta </th><th>  Class </th></tr><tr><td>  0 0 </td><td>  Camiseta / top </td></tr><tr><td>  1 </td><td>  Cal√ß√µes </td></tr><tr><td>  2 </td><td>  Camisola </td></tr><tr><td>  3 </td><td>  Vestido </td></tr><tr><td>  4 </td><td>  Manto </td></tr><tr><td>  5 </td><td>  Sand√°lias </td></tr><tr><td>  6 </td><td>  Camisa </td></tr><tr><td>  7 </td><td>  Sapatilha </td></tr><tr><td>  8 </td><td>  Bag </td></tr><tr><td>  9 </td><td>  Boot </td></tr></tbody></table></div><br><br>  Cada imagem pertence a uma tag.  Como os nomes das classes n√£o est√£o contidos no conjunto de dados original, vamos salv√°-los para uso futuro quando desenharmos as imagens: <br><br><pre> <code class="python hljs">class_names = [<span class="hljs-string"><span class="hljs-string">' / '</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>]</code> </pre><br><h4>  Pesquisamos dados </h4><br>  Vamos estudar o formato e a estrutura dos dados apresentados no conjunto de treinamento antes de treinar o modelo.  O c√≥digo a seguir mostrar√° que 60.000 imagens est√£o no conjunto de dados de treinamento e 10.000 imagens no conjunto de dados de teste: <br><br><pre> <code class="python hljs">num_train_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'train'</span></span>].num_examples num_test_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'test'</span></span>].num_examples print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_train_examples)) print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_test_examples))</code> </pre><br><h3>  Pr√©-processamento de dados </h3><br>  O valor de cada pixel na imagem est√° no intervalo <code>[0,255]</code> .  Para que o modelo funcione corretamente, esses valores devem ser normalizados - reduzidos a valores no intervalo <code>[0,1]</code> .  Portanto, um pouco menor, declaramos e implementamos a fun√ß√£o de normaliza√ß√£o e, em seguida, aplicamos a cada imagem nos conjuntos de dados de treinamento e teste. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normalize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images, labels)</span></span></span><span class="hljs-function">:</span></span> images = tf.cast(images, tf.float32) images /= <span class="hljs-number"><span class="hljs-number">255</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> images, labels <span class="hljs-comment"><span class="hljs-comment">#  map         #      train_dataset = train_dataset.map(normalize) test_dataset = test_dataset.map(normalize)</span></span></code> </pre><br><h4>  Estudamos os dados processados </h4><br>  Vamos desenhar uma imagem para dar uma olhada nela: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          #   reshape() for image, label in test_dataset.take(1): break; image = image.numpy().reshape((28, 28)) #   plt.figure() plt.imshow(image, cmap=plt.cm.binary) plt.colorbar() plt.grid(False) plt.show()</span></span></code> </pre><br><img src="https://habrastorage.org/webt/ce/se/hw/cesehwjbca_ol0s1dcpxnaxyu2i.png"><br><br>  Exibimos as 25 primeiras imagens do conjunto de dados de treinamento e, em cada imagem, indicamos a qual classe pertence. <br><br>  Verifique se os dados est√£o no formato correto e se estamos prontos para come√ßar a criar e treinar a rede. <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) i = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (image, label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">25</span></span>): image = image.numpy().reshape((<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,i+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.xticks([]) plt.yticks([]) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.imshow(image, cmap=plt.cm.binary) plt.xlabel(class_names[label]) i += <span class="hljs-number"><span class="hljs-number">1</span></span> plt.show()</code> </pre><br><img src="https://habrastorage.org/webt/4h/_v/s7/4h_vs7mj97mmqknia5mpnzaqfis.png"><br><br><h4>  Construindo um modelo </h4><br>  Construir uma rede neural requer camadas de ajuste e, em seguida, montar um modelo com fun√ß√µes de otimiza√ß√£o e perda. <br><br><h4>  Personalizar camadas </h4><br>  O elemento b√°sico na constru√ß√£o de uma rede neural √© a camada.  A camada extrai a visualiza√ß√£o dos dados que entraram em sua entrada.  O resultado do trabalho de v√°rias camadas conectadas, temos uma vis√£o que faz sentido para resolver o problema. <br><br>  Na maioria das vezes, aprendendo profundamente, voc√™ criar√° links entre camadas simples.  A maioria das camadas, por exemplo, como tf.keras.layers.Dense, possui um conjunto de par√¢metros que podem ser "ajustados" durante o processo de aprendizado. <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br>  A rede consiste em tr√™s camadas: <br><br><ul><li>  <b>entrada</b> <code>tf.keras.layers.Flatten</code> - essa camada converte imagens de 28 x 28 pixels em um array 1D com o tamanho 784 (28 * 28).  Nesta camada, n√£o temos par√¢metros para treinamento, pois essa camada lida apenas com a convers√£o de dados de entrada. </li><li>  <b>camada oculta</b> <code>tf.keras.layers.Dense</code> - uma camada firmemente conectada de 128 neur√¥nios.  Cada neur√¥nio (n√≥) pega todos os 784 valores da camada anterior como entrada, altera os valores de entrada de acordo com os pesos e deslocamentos internos durante o treinamento e retorna um √∫nico valor para a pr√≥xima camada. </li><li>  <b>camada de sa√≠da</b> <code>ts.keras.layers.Dense</code> - <code>ts.keras.layers.Dense</code> - <code>softmax</code> consiste em 10 neur√¥nios, cada um dos quais representa uma classe espec√≠fica de elemento de vestu√°rio.  Como na camada anterior, cada neur√¥nio recebe os valores de entrada de todos os 128 neur√¥nios da camada anterior.  Os pesos e deslocamentos de cada neur√¥nio nesta camada mudam durante o treinamento, de modo que o valor resultante esteja no intervalo <code>[0,1]</code> e represente a probabilidade de a imagem pertencer a essa classe.  A soma de todos os valores de sa√≠da de 10 neur√¥nios √© 1. </li></ul><br><h4>  Compilar o modelo </h4><br>  Antes de come√ßarmos a treinar o modelo, vale mais algumas configura√ß√µes.  Essas configura√ß√µes s√£o feitas durante a montagem do modelo quando o m√©todo de compila√ß√£o √© chamado: <br><br><ul><li>  <b>fun√ß√£o de perda</b> - um algoritmo para medir a dist√¢ncia entre o valor desejado e o previsto. </li><li>  <b>fun√ß√£o de otimiza√ß√£o</b> - um algoritmo para ‚Äúajustar‚Äù os par√¢metros internos (pesos e compensa√ß√µes) do modelo para minimizar a fun√ß√£o de perda; </li><li>  <b>m√©tricas</b> - usadas para monitorar o processo de treinamento e testes.  O exemplo abaixo usa m√©tricas como <code></code> , a porcentagem de imagens que foram classificadas corretamente. </li></ul><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><h3>  Treinamos o modelo </h3><br>  Primeiramente, determinamos a sequ√™ncia de a√ß√µes durante o treinamento em um conjunto de dados de treinamento: <br><br><ol><li>  Repita o conjunto de dados de entrada um n√∫mero infinito de vezes usando o m√©todo <code>dataset.repeat()</code> (o par√¢metro <code>epochs</code> , descrito abaixo, determina o n√∫mero de todas as itera√ß√µes de treinamento a serem executadas) </li><li>  O m√©todo <code>dataset.shuffle(60000)</code> todas as imagens para que o treinamento do nosso modelo n√£o seja afetado pela ordem de entrada dos dados de entrada. </li><li>  O m√©todo <code>dataset.batch(32)</code> informa ao <code>model.fit</code> treinamento <code>model.fit</code> usar blocos de 32 imagens e r√≥tulos sempre que as vari√°veis ‚Äã‚Äãinternas do modelo s√£o atualizadas. </li></ol><br>  O treinamento ocorre chamando o m√©todo <code>model.fit</code> : <br><br><ul><li>  Envia <code>train_dataset</code> para a entrada do modelo. </li><li>  O modelo aprende a combinar a imagem de entrada com a etiqueta. </li><li>  O par√¢metro <code>epochs=5</code> limita o n√∫mero de sess√µes de treinamento a 5 itera√ß√µes completas de treinamento em um conjunto de dados, o que nos d√° treinamento em 5 * 60.000 = 300.000 exemplos. </li></ul><br>  (voc√™ pode ignorar o par√¢metro <code>steps_per_epoch</code> , em breve esse par√¢metro ser√° exclu√≠do do m√©todo). <br><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE) test_dataset = test_dataset.batch(BATCH_SIZE)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))</code> </pre><br>  E aqui est√° a conclus√£o: <br><br> <code>Epoch 1/5 <br> 1875/1875 [==============================] - 26s 14ms/step - loss: 0.4921 - acc: 0.8267 <br> Epoch 2/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3652 - acc: 0.8686 <br> Epoch 3/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3341 - acc: 0.8782 <br> Epoch 4/5 <br> 1875/1875 [==============================] - 19s 10ms/step - loss: 0.3111 - acc: 0.8858 <br> Epoch 5/5 <br> 1875/1875 [==============================] - 16s 8ms/step - loss: 0.2911 - acc: 0.8922 <br></code> <br>  Durante o treinamento do modelo, o valor da fun√ß√£o de perda e a m√©trica de precis√£o s√£o exibidos para cada itera√ß√£o de treinamento.  Este modelo atinge uma precis√£o de cerca de 0,88 (88%) nos dados de treinamento. <br><br><h4>  Verifique a precis√£o </h4><br>  Vamos verificar a precis√£o que o modelo produz nos dados de teste.  Usaremos todos os exemplos que temos no conjunto de dados de teste para verificar a precis√£o. <br><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE)) print(<span class="hljs-string"><span class="hljs-string">"    : "</span></span>, test_accuracy)</code> </pre><br>  Conclus√£o: <br><br> <code>313/313 [==============================] - 1s 5ms/step - loss: 0.3440 - acc: 0.8793 <br>     : 0.8793 <br></code> <br><br>  Como voc√™ pode ver, a precis√£o no conjunto de dados de teste acabou sendo menor que a precis√£o no conjunto de dados de treinamento.  Isso √© normal, pois o modelo foi treinado em dados train_dataset.  Quando um modelo descobre imagens que nunca viu antes (do conjunto de dados train_dataset), √© √≥bvio que a efici√™ncia da classifica√ß√£o diminuir√°. <br><br><h3>  Preveja e explore </h3><br>  Podemos usar o modelo treinado para obter previs√µes para algumas imagens. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> test_images, test_labels <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): test_images = test_images.numpy() test_labels = test_labels.numpy() predictions = model.predict(test_images)</code> </pre><br><pre> <code class="python hljs">predictions.shape</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclus√£o: </font><font style="vertical-align: inherit;">No exemplo acima, o modelo previu r√≥tulos para cada imagem de entrada de teste. </font><font style="vertical-align: inherit;">Vejamos a primeira previs√£o:</font></font><br><br> <code>(32, 10) <br></code> <br><br><font style="vertical-align: inherit;"></font><br><br><pre> <code class="python hljs">predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclus√£o: </font></font><br><br><pre> <code class="python hljs">array([<span class="hljs-number"><span class="hljs-number">3.1365351e-05</span></span>, <span class="hljs-number"><span class="hljs-number">9.0029374e-08</span></span>, <span class="hljs-number"><span class="hljs-number">5.0016739e-03</span></span>, <span class="hljs-number"><span class="hljs-number">6.3597057e-05</span></span>, <span class="hljs-number"><span class="hljs-number">6.8342477e-02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span>, <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span>, <span class="hljs-number"><span class="hljs-number">1.8982398e-09</span></span>, <span class="hljs-number"><span class="hljs-number">8.4999456e-06</span></span>, <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>], dtype=float32)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lembre-se de que as previs√µes do modelo s√£o uma matriz de 10 valores. </font><font style="vertical-align: inherit;">Esses valores descrevem a ‚Äúconfian√ßa‚Äù do modelo de que a imagem de entrada pertence a uma determinada classe (item de vestu√°rio). </font><font style="vertical-align: inherit;">Podemos ver o valor m√°ximo da seguinte maneira:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclus√£o: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Isso significa que o modelo estava mais confiante de que esta imagem pertence √† classe rotulada 6 (class_names [6]). </font><font style="vertical-align: inherit;">Podemos verificar e garantir que o resultado seja verdadeiro e correto:</font></font><br><br><pre> <code class="python hljs">test_labels[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Podemos exibir todas as imagens de entrada e as previs√µes de modelo correspondentes para 10 classes: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_labels, images)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label, img = predictions_array[i], true_label[i], images[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) plt.imshow(img[...,<span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=plt.cm.binary) predicted_label = np.argmax(predictions_array) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_label == true_label: color = <span class="hljs-string"><span class="hljs-string">'blue'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: color = <span class="hljs-string"><span class="hljs-string">'red'</span></span> plt.xlabel(<span class="hljs-string"><span class="hljs-string">"{} {:2.0f}% ({})"</span></span>.format(class_names[predicted_label], <span class="hljs-number"><span class="hljs-number">100</span></span> * np.max(predictions_array), class_names[true_label]), color=color) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_value_array</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_label)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label = predictions_array[i], true_label[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) thisplot = plt.bar(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), predictions_array, color=<span class="hljs-string"><span class="hljs-string">"#777777"</span></span>) plt.ylim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) predicted_label = np.argmax(predictions_array) thisplot[predicted_label].set_color(<span class="hljs-string"><span class="hljs-string">'red'</span></span>) thisplot[true_label].set_color(<span class="hljs-string"><span class="hljs-string">'blue'</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Vamos dar uma olhada na 0¬™ imagem, o resultado da previs√£o do modelo e a matriz de previs√µes. </font></font><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">0</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/fc/7i/ef/fc7iefucuvtopx4_avluy-rq1ei.png"><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">12</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/n0/2y/tj/n02ytjjdkeubvkqvjdusbkwoemy.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vamos agora exibir algumas imagens com suas respectivas previs√µes. </font><font style="vertical-align: inherit;">As previs√µes corretas s√£o azuis, as previs√µes incorretas s√£o vermelhas. </font><font style="vertical-align: inherit;">O valor abaixo da imagem reflete a porcentagem de confian√ßa de que a imagem de entrada corresponde a esta classe. </font><font style="vertical-align: inherit;">Observe que o resultado pode estar incorreto mesmo se o valor de "confian√ßa" for alto.</font></font><br><br><pre> <code class="python hljs">num_rows = <span class="hljs-number"><span class="hljs-number">5</span></span> num_cols = <span class="hljs-number"><span class="hljs-number">3</span></span> num_images = num_rows * num_cols plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_rows)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_images): plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/m1/11/je/m111jevw7ptxblu2ccmlwmtonva.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Use o modelo treinado para prever o r√≥tulo para uma √∫nica imagem: </font></font><br><br><pre> <code class="python hljs">img = test_images[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclus√£o: </font></font><br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Os modelos s√£o </font></font><code>tf.keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">otimizados para previs√µes por blocos (cole√ß√µes). </font><font style="vertical-align: inherit;">Portanto, apesar de usarmos um √∫nico elemento, voc√™ precisa adicion√°-lo √† lista:</font></font><br><br><pre> <code class="python hljs">img = np.array([img]) print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclus√£o: </font></font><br><br> <code>(1, 28, 28, 1)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora vamos prever o resultado:</font></font><br><br><pre> <code class="python hljs">predictions_single = model.predict(img) print(predictions_single)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclus√£o: </font></font><br><br><pre> <code class="python hljs">[[<span class="hljs-number"><span class="hljs-number">3.1365438e-05</span></span> <span class="hljs-number"><span class="hljs-number">9.0029722e-08</span></span> <span class="hljs-number"><span class="hljs-number">5.0016833e-03</span></span> <span class="hljs-number"><span class="hljs-number">6.3597123e-05</span></span> <span class="hljs-number"><span class="hljs-number">6.8342514e-02</span></span> <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span> <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.8982469e-09</span></span> <span class="hljs-number"><span class="hljs-number">8.4999692e-06</span></span> <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>]]</code> </pre><br><pre> <code class="python hljs">plot_value_array(<span class="hljs-number"><span class="hljs-number">0</span></span>, predictions_single, test_labels) _ = plt.xticks(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), class_names, rotation=<span class="hljs-number"><span class="hljs-number">45</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/eo/vw/sl/eovwslxcn_ldtj2abz870ninw4g.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O m√©todo model.predict retorna uma lista de listas (uma matriz de matrizes), cada uma para uma imagem de um bloco de entrada. </font><font style="vertical-align: inherit;">Obtemos o √∫nico resultado para nossa imagem de entrada √∫nica:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions_single[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclus√£o: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Como anteriormente, o modelo previu a etiqueta 6 (camisa). </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exerc√≠cios </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Experimente modelos diferentes e veja como a precis√£o mudar√°. </font><font style="vertical-align: inherit;">Em particular, tente alterar as seguintes configura√ß√µes:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> defina o par√¢metro epochs como 1; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> altere o n√∫mero de neur√¥nios na camada oculta, por exemplo, de um valor baixo de 10 a 512 e veja como a precis√£o do modelo de previs√£o mudar√°; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> adicione camadas adicionais entre a camada achatada (camada de suaviza√ß√£o) e a camada densa final; experimente o n√∫mero de neur√¥nios nessa camada; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> n√£o normalize os valores de pixel e veja o que acontece. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lembre-se de ativar a GPU para que todos os c√°lculos sejam mais r√°pidos ( </font></font><code>Runtime -&gt; Change runtime type -&gt; Hardware accelertor -&gt; GPU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">). </font><font style="vertical-align: inherit;">Al√©m disso, se voc√™ encontrar problemas durante a opera√ß√£o, tente redefinir as configura√ß√µes do ambiente global:</font></font><br><br><ul><li> <code>Edit -&gt; Clear all outputs</code> </li> <li> <code>Runtime -&gt; Reset all runtimes</code> </li> </ul><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Graus Celsius VS MNIST </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Nesta fase, j√° encontramos dois tipos de redes neurais. Nossa primeira rede neural aprendeu a converter graus Celsius em graus Frenheit, retornando um valor √∫nico que pode estar em uma ampla gama de valores num√©ricos. </font></font><br><br><img src="https://habrastorage.org/webt/o8/ag/_t/o8ag_trkedahoa0ftg3pstkirt4.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nossa segunda rede neural retorna 10 valores de probabilidade que refletem a confian√ßa da rede de que a imagem de entrada corresponde a uma determinada classe. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Redes neurais podem ser usadas para resolver v√°rios problemas. </font></font><br><br><img src="https://habrastorage.org/webt/no/0v/jo/no0vjoulnrva_-bky0uauc3tesi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A primeira classe de problemas que resolvemos com a previs√£o de um √∫nico valor √© chamada de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regress√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Converter graus Celsius em graus Fahrenheit √© um exemplo da tarefa desta classe. Outro exemplo dessa classe de tarefas pode ser a tarefa de determinar o valor de uma casa pelo n√∫mero de c√¥modos, √°rea total, localiza√ß√£o e outras caracter√≠sticas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A segunda classe de tarefas que examinamos nesta li√ß√£o, classificando imagens em categorias dispon√≠veis, √© chamada de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classifica√ß√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . De acordo com os dados de entrada, o modelo retornar√° a distribui√ß√£o de probabilidade (a ‚Äúconfian√ßa‚Äù do modelo de que o valor de entrada pertence a essa classe). Nesta li√ß√£o, desenvolvemos uma rede neural que classificou os elementos de vestu√°rio em 10 categorias e, na pr√≥xima li√ß√£o, aprenderemos a determinar quem √© mostrado na fotografia - um cachorro ou um gato, essa tarefa tamb√©m pertence √† tarefa de classifica√ß√£o.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vamos resumir e observar a diferen√ßa entre essas duas classes de problemas - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regress√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classifica√ß√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/webt/_c/wj/qu/_cwjquy9ivk-s3zma34qamyakoq.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parab√©ns, voc√™ estudou dois tipos de redes neurais! Prepare-se para a pr√≥xima palestra, onde estudaremos um novo tipo de redes neurais - redes neurais convolucionais (CNN).</font></font><br><br><h3>  Sum√°rio </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nesta li√ß√£o, treinamos a rede neural para classificar imagens com elementos de vestu√°rio. Para fazer isso, usamos o conjunto de dados Fashion MNIST, que cont√©m 70.000 imagens de itens de vestu√°rio. 60.000 dos quais costum√°vamos treinar a rede neural e os 10.000 restantes para testar a efic√°cia de seu trabalho. Para enviar essas imagens para a entrada de nossa rede neural, precis√°vamos convert√™-las (suavizadas) de um formato 2D de 28x28 para um formato 1D de 784 elementos. Nossa rede consistia em uma camada totalmente conectada de 128 neur√¥nios e uma camada de sa√≠da de 10 neur√¥nios, correspondendo ao n√∫mero de etiquetas (classes, categorias de itens de vestu√°rio). Esses 10 valores de sa√≠da representaram a distribui√ß√£o de probabilidade para cada classe. </font><i><font style="vertical-align: inherit;">Fun√ß√£o de</font></i><font style="vertical-align: inherit;"> ativa√ß√£o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">contou a distribui√ß√£o de probabilidade. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tamb√©m aprendemos sobre as diferen√ßas entre </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regress√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classifica√ß√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Regress√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : um modelo que retorna um √∫nico valor, como o valor de uma casa.</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classifica√ß√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : um modelo que retorna a distribui√ß√£o de probabilidade entre v√°rias categorias. </font><font style="vertical-align: inherit;">Por exemplo, em nossa tarefa com o Fashion MNIST, os valores de sa√≠da eram 10 valores de probabilidade, cada um dos quais associado a uma classe espec√≠fica (categoria de item de vestu√°rio). </font><font style="vertical-align: inherit;">Lembro que usamos a fun√ß√£o de ativa√ß√£o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> apenas para obter uma distribui√ß√£o de probabilidade na √∫ltima camada.</font></font></li></ul><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vers√£o em v√≠deo do artigo</font></font></b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O v√≠deo sai alguns dias ap√≥s a publica√ß√£o e √© adicionado ao artigo. </font></font><br></div></div><br>  ... e call to action padr√£o - inscreva-se, coloque um plus e compartilhe :) <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">YouTube</font></font></a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Telegram</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt454034/">https://habr.com/ru/post/pt454034/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt454018/index.html">iOS Digest No. 6 (17 a 30 de maio)</a></li>
<li><a href="../pt454024/index.html">Controlador de carga MPPT em STM32F334C8T6</a></li>
<li><a href="../pt454028/index.html">Esbo√ßos com PHP R√∫ssia 2019: c√≥digo limpo, magia negra</a></li>
<li><a href="../pt454030/index.html">Odigest: interessante para designers da semana</a></li>
<li><a href="../pt454032/index.html">Roteador e dados passando a arquitetura Clean Swift</a></li>
<li><a href="../pt454036/index.html">6 maneiras de ir para o inferno de solu√ß√µes prontas e diminuir um milh√£o ou dois</a></li>
<li><a href="../pt454038/index.html">Ilya Zverev: Ao longo dos anos, o OpenStreetMap ganhou uma infraestrutura t√£o s√©ria que voc√™ pode desenhar um mapa sem sair de casa</a></li>
<li><a href="../pt454042/index.html">Pague o que quiser: como esse modelo se mostrou na m√∫sica e quem tentou ganhar dinheiro assim</a></li>
<li><a href="../pt454044/index.html">Criatividade no iPad e iPhone</a></li>
<li><a href="../pt454046/index.html">Motiva√ß√£o Fa√ßa voc√™ mesmo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
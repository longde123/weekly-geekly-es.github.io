<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöß üïé üë©üèº‚Äçüè≠ Konvergenz mit Kubernetes ü§õüèº ‚õ©Ô∏è üñêüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vollst√§ndige Standardisierung 


 Ich bereitete dieses Material f√ºr meine Rede auf der Konferenz vor und fragte unseren technischen Direktor, was das ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Konvergenz mit Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/427441/"><h3 id="totalnaya-standartizaciya">  Vollst√§ndige Standardisierung </h3><br><p>  Ich bereitete dieses Material f√ºr meine Rede auf der Konferenz vor und fragte unseren technischen Direktor, was das Hauptmerkmal von Kubernetes f√ºr unsere Organisation sei.  Er antwortete: </p><br><blockquote>  Die Entwickler selbst verstehen nicht, wie viel zus√§tzliche Arbeit sie geleistet haben. </blockquote><p>  Anscheinend war er von dem k√ºrzlich gelesenen Buch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûFactfulness‚Äú</a> inspiriert - es ist schwierig, geringf√ºgige und kontinuierliche Ver√§nderungen zum Besseren zu bemerken, und wir verlieren st√§ndig unsere Fortschritte aus den Augen. </p><br><p>  Der Wechsel zu Kubernetes ist aber definitiv nicht unerheblich. </p><br><p><img src="https://habrastorage.org/webt/72/vu/bn/72vubnen7dnspn7tp9wmy2if9cu.png"></p><a name="habracut"></a><br><p> Fast 30 unserer Teams f√ºhren alle oder einige Workloads in den Clustern aus.  Etwa 70% unseres HTTP-Datenverkehrs wird von Anwendungen in Kubernetes-Clustern generiert.  Dies ist wahrscheinlich die gr√∂√üte Technologiekonvergenz seit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">meinem Eintritt</a> in das Unternehmen, nachdem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Forward 2010 uSwitch gekauft hat</a> , als wir von .NET und physischen Servern auf AWS und von einem monolithischen System auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Microservices umgestiegen sind</a> . </p><br><p>  Und alles ging sehr schnell.  Ende 2017 nutzten alle Teams ihre AWS-Infrastruktur.  Sie richten Load Balancer, EC2-Instanzen, ECS-Cluster-Updates und √§hnliches ein.  Etwas mehr als ein Jahr verging und alles √§nderte sich. </p><br><p>  Wir haben ein Minimum an Zeit f√ºr die Konvergenz aufgewendet. Infolgedessen hat Kubernetes uns bei der L√∂sung dringender Probleme geholfen - unsere Cloud wuchs, die Organisation wurde komplizierter und wir hatten Probleme, neue Mitarbeiter in Teams zu integrieren.  Wir haben die Organisation nicht ge√§ndert, um Kubernetes zu verwenden.  Im Gegenteil - wir haben Kubernetes verwendet, um die Organisation zu √§ndern. </p><br><p>  Die Entwickler haben vielleicht keine gro√üen √Ñnderungen bemerkt, aber die Daten sprechen f√ºr sich.  Dazu sp√§ter mehr. </p><br><hr><br><p>  Vor vielen Jahren war ich auf einer Clojure-Konferenz und h√∂rte einen Vortrag von Michael Nygard <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√ºber Architektur, der nicht in seinen endg√ºltigen Zustand gebracht werden kann</a> .  Er √∂ffnete meine Augen.  Ein ordentliches und ordentliches System sieht karikiert aus, wenn es Fernsehgesch√§fte mit K√ºchenartikeln und der gro√ü angelegten Softwarearchitektur vergleicht - das vorhandene System sieht aus wie ein dummes Messer, und anstelle von geraden Scheiben kommt eine Art Brei heraus.  Ohne ein neues Messer gibt es nichts, woran man denken k√∂nnte. </p><br><p>  Hier geht es darum, wie Organisationen dreij√§hrige Projekte lieben: Das erste Jahr ist die Entwicklung und Vorbereitung, das zweite Jahr ist die Implementierung, das dritte ist die R√ºckkehr.  In einem Vortrag sagt er, dass solche Projekte normalerweise kontinuierlich durchgef√ºhrt werden und selten das Ende des zweiten Jahres erreichen (oft aufgrund der √úbernahme durch ein anderes Unternehmen und einer √Ñnderung der Richtung und Strategie), so dass die √ºbliche Architektur ist </p><br><blockquote>  Schichtung des Wandels in einem gewissen Anschein von Stabilit√§t. </blockquote><p>  Und uSwitch ist ein gutes Beispiel. </p><br><p>  Wir sind aus vielen Gr√ºnden zu AWS gewechselt - unser System konnte Spitzenlasten nicht bew√§ltigen, und die Organisation wurde durch ein zu starres System und eng verwandte Teams behindert, die f√ºr bestimmte Projekte gebildet und durch Spezialisierung unterteilt wurden. </p><br><p>  Wir wollten nicht alles beenden, alle Systeme √ºbertragen und neu beginnen.  Wir haben neue Dienste mit Proxy √ºber den vorhandenen Load Balancer erstellt und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die alte</a> Anwendung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schrittweise gedrosselt</a> .  Wir wollten sofort die R√ºckkehr zeigen und f√ºhrten in der ersten Woche A / B-Tests der ersten Version des neuen Service in der Produktion durch.  Infolgedessen nahmen wir langfristige Produkte und begannen, aus Entwicklern, Designern, Analysten usw. Teams f√ºr sie zu bilden. Und wir sahen sofort das Ergebnis.  Im Jahr 2010 schien dies eine echte Revolution zu sein. </p><br><p>  Jahr f√ºr Jahr haben wir neue Teams, Dienste und Anwendungen hinzugef√ºgt und das monolithische System schrittweise ‚Äûerw√ºrgt‚Äú.  Die Teams entwickelten sich schnell - jetzt arbeiteten sie unabh√§ngig voneinander und bestanden aus Spezialisten in allen notwendigen Bereichen.  Wir haben die Teaminteraktionen f√ºr Produktversionen minimiert.  Wir haben nur f√ºr die Konfiguration des Load Balancers mehrere Befehle zugewiesen. </p><br><p>  Die Teams selbst w√§hlten Entwicklungsmethoden, Tools und Sprachen.  Wir haben ihnen eine Aufgabe gestellt, und sie haben selbst eine L√∂sung gefunden, weil sie sich in dieser Angelegenheit am besten auskennen.  Mit AWS sind diese √Ñnderungen einfacher geworden. </p><br><p>  Wir haben uns intuitiv an die Prinzipien der Programmierung gehalten - Teams, die lose miteinander verbunden sind, werden weniger wahrscheinlich kommunizieren und wir m√ºssen keine wertvollen Ressourcen f√ºr die Koordination ihrer Arbeit aufwenden.  All dies wird in dem k√ºrzlich ver√∂ffentlichten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Buch Accelerate</a> gro√üartig beschrieben. </p><br><p>  Als Ergebnis haben wir, wie Michael Nygard beschrieben hat, ein System mit vielen Ebenen von √Ñnderungen erhalten - einige Systeme wurden mit Puppet automatisiert, andere mit Terraform, irgendwo haben wir ECS verwendet, irgendwo EC2. </p><br><p>  2012 waren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wir stolz auf unsere Architektur, die leicht ge√§ndert werden konnte</a> , um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu experimentieren</a> , erfolgreiche L√∂sungen zu finden und diese zu entwickeln. </p><br><p>  Aber 2017 haben wir festgestellt, dass sich viel ge√§ndert hat. </p><br><hr><br><p>  AWS ist jetzt viel komplexer als im Jahr 2010. Es bietet eine Vielzahl von Optionen und Funktionen - aber nicht ohne Konsequenzen.  Heute muss jedes Team, das mit EC2 arbeitet, eine VPC, eine Netzwerkkonfiguration und vieles mehr ausw√§hlen. </p><br><p>  Wir haben dies selbst erlebt - Teams begannen sich zu beschweren, dass sie immer mehr Zeit f√ºr die Wartung der Infrastruktur aufwenden, z. B. f√ºr die Aktualisierung von Instanzen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in AWS ECS-Clustern</a> , EC2-Maschinen, den Wechsel von ELB-Balancern zu ALB usw. </p><br><p>  Mitte 2017 forderte ich bei einer Firmenveranstaltung alle auf, ihre Arbeit zu standardisieren, um die Gesamtqualit√§t der Systeme zu verbessern.  Ich habe die abgedroschene Eisberg-Metapher verwendet, um zu zeigen, wie wir Software erstellen und warten: </p><br><p><img src="https://habrastorage.org/webt/sn/ci/pt/sncipt6axzuuqa2pcqxrpbcwzh0.png"></p><br><p>  Ich sagte, dass die meisten Teams in unserem Unternehmen Services oder Produkte erstellen und sich auf Probleml√∂sung, Anwendungscode, Plattformen und Bibliotheken usw. konzentrieren sollten. In dieser Reihenfolge.  Unter Wasser bleibt noch viel Arbeit - Integration von Protokollen, Verbesserung der Beobachtbarkeit, Verwaltung von Geheimnissen usw. </p><br><p>  Zu dieser Zeit befasste sich jedes Team von Anwendungsentwicklern mit fast dem gesamten Eisberg und traf alle Entscheidungen selbst - Auswahl der Sprache, der Entwicklungsumgebung, des Bibliotheks- und Metriktools, des Betriebssystems, des Instanztyps und des Speichers. </p><br><p>  Am Fu√üe der Pyramide hatten wir eine Amazon Web Services-Infrastruktur.  Es sind jedoch nicht alle AWS-Services gleich.  Sie verf√ºgen √ºber ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Backend-as-a-Service (BaaS)</a> , beispielsweise zur Authentifizierung und Datenspeicherung.  Und es gibt andere, relativ niedrige Dienste wie EC2.  Ich wollte die Daten studieren und verstehen, dass die Teams Grund zur Beschwerde haben und wirklich mehr Zeit damit verbringen, mit Low-Level-Diensten zu arbeiten und viele nicht die wichtigsten Entscheidungen zu treffen. </p><br><p>  Ich habe die Dienste in Kategorien unterteilt, mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CloudTrail</a> alle verf√ºgbaren Statistiken gesammelt und dann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mithilfe von BigQuery</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Athena</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ggplot2 festgestellt</a> , wie sich die Situation f√ºr Entwickler in letzter Zeit ge√§ndert hat.  Das Wachstum f√ºr Dienste wie RDS, Redshift usw. halten wir f√ºr w√ºnschenswert (und erwartet) und das Wachstum f√ºr EC2, CloudFormation usw. - umgekehrt. </p><br><p><img src="https://habrastorage.org/webt/dd/bd/-f/ddbd-fy5t4wzicbekukgyx_lji0.png"></p><br><p>  Jeder Punkt im Diagramm zeigt das 90. (rot), 80. (gr√ºn) und 50. (blau) Perzentil f√ºr die Anzahl der <strong>Dienste auf niedriger Ebene</strong> , die unsere Mitarbeiter f√ºr einen bestimmten Zeitraum jede Woche in Anspruch genommen haben.  Ich habe Gl√§ttungslinien hinzugef√ºgt, um den Trend zu zeigen. </p><br><p>  Obwohl wir bei der Bereitstellung von Software, beispielsweise mithilfe von Containern und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Amazon ECS</a> , Abstraktionen auf h√∂herer Ebene anstrebten, verwendeten unsere Entwickler regelm√§√üig immer mehr AWS-Services und abstrahierten nicht ausreichend von den Schwierigkeiten bei der Verwaltung von Systemen.  In zwei Jahren hat sich die Anzahl der Dienstleistungen f√ºr 50% der Besch√§ftigten verdoppelt und f√ºr 20% fast verdreifacht. </p><br><p>  Dies begrenzte das Wachstum unseres Unternehmens.  Die Teams suchten Autonomie, aber wie kann man neue Leute einstellen?  Wir brauchten starke Anwendungs- und Produktentwickler und Kenntnisse √ºber das immer ausgefeilter werdende AWS-System. </p><br><hr><br><p>  Wir wollten unsere Teams erweitern und gleichzeitig die Prinzipien bewahren, mit denen wir erfolgreich waren: Autonomie, minimale Koordination und Self-Service-Infrastruktur. </p><br><p>  Mit Kubernetes haben wir dies mit anwendungsorientierten Abstraktionen und der F√§higkeit erreicht, Cluster mit minimaler Teamkoordination zu verwalten und zu konfigurieren. </p><br><h3 id="abstrakcii-s-fokusom-na-prilozheniya">  Anwendungsorientierte Abstraktionen </h3><br><p>  Kubernetes-Konzepte lassen sich leicht mit der Sprache des Anwendungsentwicklers abgleichen.  Angenommen, Sie verwalten Anwendungsversionen als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bereitstellung</a> .  Sie k√∂nnen mehrere Replikate hinter dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dienst</a> ausf√ºhren und sie √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ingress</a> HTTP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zuordnen</a> .  √úber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Benutzerressourcen k√∂nnen</a> Sie diese Sprache je nach Bedarf erweitern und spezialisieren. </p><br><p>  Teams arbeiten effizienter mit diesen Abstraktionen.  Grunds√§tzlich enth√§lt dieses Beispiel alles, was Sie zum Bereitstellen und Ausf√ºhren einer Webanwendung ben√∂tigen.  Der Rest ist Kubernetes. </p><br><p>  Im Bild mit dem Eisberg befinden sich diese Konzepte auf Wasserspiegel und kombinieren die Aufgaben des Entwicklers von oben mit der Plattform unten.  Das Cluster-Management-Team kann einfache und unbedeutende Entscheidungen treffen (√ºber die Verwaltung von Metriken, die Protokollierung usw.) und gleichzeitig mit den Entwicklern √ºber Wasser dieselbe Sprache sprechen. </p><br><p>  Im Jahr 2010 hatte uSwitch traditionelle Teams f√ºr die Wartung eines monolithischen Systems, und zuletzt hatten wir eine IT-Abteilung, die unser AWS-Konto teilweise verwaltete.  Es scheint mir, dass das Fehlen gemeinsamer Konzepte die Arbeit dieses Teams ernsthaft behinderte. </p><br><p>  Versuchen Sie, etwas N√ºtzliches zu sagen, wenn Ihr Vokabular, Ihre Load Balancer und Ihre Subnetze nur EC2-Instanzen enthalten.  Es war schwierig oder sogar unm√∂glich, das Wesentliche der Anwendung zu beschreiben.  Es k√∂nnte sich um ein Debian-Paket, die Bereitstellung √ºber Capistrano usw. handeln.  Wir konnten die Anwendung nicht in einer allen gemeinsamen Sprache beschreiben. </p><br><p>  Anfang der 2000er Jahre arbeitete ich bei ThoughtWorks in London.  Beim Interview wurde mir geraten, Eric Evans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">'Problemorientiertes Entwerfen</a> zu lesen.  Auf dem Heimweg kaufte ich ein Buch und begann im Zug zu lesen.  Seitdem erinnere ich mich in fast jedem Projekt und System an sie. </p><br><p>  Eines der Hauptkonzepte des Buches ist eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einzige Sprache,</a> in der verschiedene Teams kommunizieren.  Kubernetes bietet Entwicklern und Infrastrukturwartungsteams eine einheitliche Sprache, und dies ist einer der Hauptvorteile.  Dar√ºber hinaus kann es um weitere Themenbereiche und Gesch√§ftsbereiche erweitert und erg√§nzt werden. </p><br><p>  Die Kommunikation in einer gemeinsamen Sprache ist produktiver, aber wir m√ºssen die Interaktion zwischen den Teams so weit wie m√∂glich einschr√§nken. </p><br><h3 id="neobhodimyy-minimum-vzaimodeystviya">  Notwendiges Minimum an Interaktion </h3><br><p>  Die Autoren von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Accelerate</a> heben die Merkmale einer lose gekoppelten Architektur hervor, mit der IT-Teams effizienter arbeiten: </p><br><blockquote>  Im Jahr 2017 hing der Erfolg der kontinuierlichen Lieferung davon ab, ob das Team: <br>  √Ñndern Sie die Struktur Ihres Systems ernsthaft ohne die Erlaubnis der Verwaltung. <br>  √Ñndern Sie ernsthaft die Struktur Ihres Systems, ohne darauf zu warten, dass andere Teams ihre √§ndern, und ohne unn√∂tige Arbeit f√ºr andere Teams zu verursachen. <br>  F√ºhren Sie ihre Aufgaben aus, ohne ihre Arbeit mit anderen Teams zu kommunizieren oder zu koordinieren. <br>  Bereitstellen und Freigeben eines Produkts oder einer Dienstleistung bei Bedarf, unabh√§ngig von anderen damit verbundenen Diensten. <br>  F√ºhren Sie die meisten Tests bei Bedarf ohne integrierte Testumgebung durch. </blockquote><p>  Wir brauchten zentralisierte Software-Multi-Tenant-Cluster f√ºr alle Teams, wollten aber gleichzeitig diese Eigenschaften beibehalten.  Wir haben das Ideal noch nicht erreicht, aber wir versuchen so gut wir k√∂nnen: </p><br><ul><li>  Wir haben mehrere Arbeitscluster, und die Teams selbst entscheiden, wo die Anwendung ausgef√ºhrt werden soll.  Wir verwenden noch keinen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verbund</a> (wir warten auf AWS-Unterst√ºtzung), aber wir haben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Envoy</a> f√ºr den Lastausgleich auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ingress-</a> Balancern in verschiedenen Clustern.  Wir automatisieren die meisten dieser Aufgaben mithilfe der Pipeline f√ºr die kontinuierliche Bereitstellung (wir haben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drone</a> ) und anderer AWS-Services. </li><li>  Alle Cluster haben den gleichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Namespace</a> .  Etwa eine f√ºr jedes Team. </li><li>  Wir steuern den Zugriff auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Namespaces</a> √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RBAC</a> (rollenbasierte Zugriffskontrolle).  Zur Authentifizierung und Autorisierung verwenden wir die Corporate Identity in Active Directory. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cluster werden automatisch skaliert</a> und wir bem√ºhen uns, die Startzeit des Knotens zu optimieren.  Es dauert immer noch ein paar Minuten, aber im Allgemeinen verzichten wir auch bei gro√üen Arbeitslasten auf Koordination. </li><li>  Anwendungen werden automatisch basierend auf Metriken auf Anwendungsebene von Prometheus skaliert.  Entwicklungsteams steuern die automatische Skalierung ihrer Anwendung anhand von Abfragemetriken pro Sekunde, Vorg√§ngen pro Sekunde usw. Dank der automatischen Skalierung des Clusters bereitet das System Knoten vor, wenn die Nachfrage die Funktionen des aktuellen Clusters √ºberschreitet. </li><li>  Wir haben Go mit einem Befehlszeilentool namens <strong>u geschrieben</strong> , das die Befehlsauthentifizierung in Kubernetes standardisiert, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vault verwendet</a> , Anforderungen f√ºr tempor√§re AWS-Anmeldeinformationen anfordert und so weiter. </li></ul><br><p><img src="https://habrastorage.org/webt/oy/qv/bm/oyqvbm7x1orfe2kpjxubpis6r60.png"></p><br><p>  Ich bin mir nicht sicher, ob wir mit Kubernetes mehr Autonomie haben, aber es blieb definitiv auf einem hohen Niveau, und gleichzeitig haben wir einige Probleme beseitigt. </p><br><hr><br><p>  Der Wechsel zu Kubernetes war schnell.  Das Diagramm zeigt die Gesamtzahl <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Namespaces</a> (ungef√§hr gleich der Anzahl der Befehle) in unseren Arbeitsclustern.  Der erste erschien im Februar 2017. </p><br><p><img src="https://habrastorage.org/webt/ux/y_/q_/uxy_q_hravmwkjhead1bgzkspz4.png"></p><br><p>  Wir hatten Gr√ºnde, uns zu beeilen - wir wollten die kleinen Teams, die sich auf ihr Produkt konzentrieren, vor Sorgen um die Infrastruktur bewahren. </p><br><p>  Das erste Team erkl√§rte sich bereit, zu Kubernetes zu wechseln, wenn der Anwendungsserver aufgrund falscher Logrotate-Einstellungen keinen Speicherplatz mehr hatte.  Der √úbergang dauerte nur wenige Tage, und sie machten sich wieder an die Arbeit. </p><br><p>  Vor kurzem haben Teams auf Kubetnetes umgestellt, um die Tools zu verbessern.  Kubernetes-Cluster vereinfachen die Integration mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hashicorp Vault</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Cloud Trace</a> und √§hnlichen Tools.  <em>Alle</em> unsere Teams erhalten noch effektivere Funktionen. </p><br><hr><br><p>  Ich habe bereits ein Diagramm mit Perzentilen der Anzahl der Dienste gezeigt, die unsere Mitarbeiter von Ende 2014 bis 2017 jede Woche in Anspruch genommen haben.  Und hier ist eine Fortsetzung dieses Diagramms bis heute. </p><br><p><img src="https://habrastorage.org/webt/o7/fa/mu/o7famum8vaa0uuuw5e2ynah0-ay.png"></p><br><p>  Wir haben Fortschritte bei der Verwaltung des komplexen AWS-Frameworks erzielt.  Ich bin froh, dass jetzt die H√§lfte der Mitarbeiter das Gleiche tut wie Anfang 2015.  Wir haben 4-6 Mitarbeiter im Cloud-Computing-Team, etwa 10% der Gesamtzahl - es ist nicht verwunderlich, dass sich das 90. Perzentil fast nicht bewegt hat.  Aber ich hoffe auch hier auf Fortschritte. </p><br><p>  Abschlie√üend werde ich dar√ºber sprechen, wie sich unser Entwicklungszyklus ver√§ndert hat, und noch einmal an das k√ºrzlich gelesene Accelerate-Buch erinnern. </p><br><p>  Das Buch erw√§hnt zwei Lean-Entwicklungsmetriken: Vorlaufzeit und Paketgr√∂√üe.  Die Vorlaufzeit wird von der Anfrage bis zur Lieferung der fertigen L√∂sung ber√ºcksichtigt.  Die Paketgr√∂√üe ist der Arbeitsaufwand.  Je kleiner die Packungsgr√∂√üe, desto effizienter die Arbeit: </p><br><blockquote>  Je kleiner das Paket, desto k√ºrzer der Produktionszyklus, weniger Prozessvariabilit√§t, weniger Risiken, Kosten und Kosten, wir erhalten schneller Feedback, arbeiten effizienter, wir haben mehr Motivation, wir versuchen schneller fertig zu werden und verschieben die Lieferung seltener. </blockquote><p>  Das Buch schl√§gt vor, die Gr√∂√üe von Paketen anhand der Bereitstellungsh√§ufigkeit zu messen. Je h√§ufiger die Bereitstellung erfolgt, desto kleiner sind die Pakete. </p><br><p>  Wir haben Daten f√ºr <em>einige</em> Bereitstellungen.  Die Daten sind nicht ganz korrekt - einige Teams senden Releases direkt an den Hauptzweig des Repositorys, andere verwenden andere Mechanismen.  Dies schlie√üt nicht alle Antr√§ge ein, aber Daten f√ºr 12 Monate k√∂nnen als Richtwerte angesehen werden. </p><br><p><img src="https://habrastorage.org/webt/dt/vt/53/dtvt53s-2o7-w9rs-7qx6dhnydc.png"></p><br><p>  Das Scheitern in der drei√üigsten Woche ist Weihnachten.  Im √úbrigen nimmt die Bereitstellungsh√§ufigkeit zu, was bedeutet, dass die Paketgr√∂√üe abnimmt.  Von M√§rz bis Mai 2018 hat sich die H√§ufigkeit der Ver√∂ffentlichungen fast verdoppelt, und in letzter Zeit stellen wir manchmal mehr als hundert Ausgaben pro Tag her. </p><br><p>  Der Wechsel zu Kubernetes ist nur ein Teil unserer Strategie zur Standardisierung, Automatisierung und Verbesserung von Tools.  H√∂chstwahrscheinlich haben all diese Faktoren die H√§ufigkeit der Freisetzungen beeinflusst. </p><br><p>  Accelerate spricht auch √ºber die Beziehung zwischen der Bereitstellungsh√§ufigkeit und der Anzahl der Mitarbeiter und dar√ºber, wie schnell ein Unternehmen arbeiten kann, wenn mehr Mitarbeiter eingestellt werden.  Die Autoren betonen die Grenzen verwandter Architekturen und Teams: </p><br><blockquote>  Es wird traditionell angenommen, dass die Erweiterung eines Teams die Gesamtproduktivit√§t erh√∂ht, aber die Produktivit√§t einzelner Entwickler verringert. </blockquote><p>  Wenn wir dieselben Daten zur H√§ufigkeit von Bereitstellungen verwenden und ein Diagramm der Abh√§ngigkeit von der Anzahl der Benutzer erstellen, k√∂nnen wir sehen, dass wir die H√§ufigkeit von Releases erh√∂hen k√∂nnen, selbst wenn wir mehr Mitarbeiter haben. </p><br><p><img src="https://habrastorage.org/webt/xc/ti/xf/xctixfjqbqgkbdooamerhtg3d_e.png"></p><br><p>  Am Anfang des Artikels erw√§hnte ich das Buch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Factfulness</a> (das unseren CTO inspirierte).  Der √úbergang zu Kubernetes ist f√ºr unsere Entwickler zur bedeutendsten und schnellsten Konvergenz der Technologie geworden.  Wir bewegen uns in kleinen Schritten, und es ist leicht zu bemerken, wie sehr sich alles zum Besseren ver√§ndert hat.  Es ist gut, dass wir Daten haben, und sie zeigen, dass wir erreicht haben, was wir wollen - unsere Mitarbeiter sind an ihrem Produkt beteiligt und treffen wichtige Entscheidungen auf ihrem Gebiet. </p><br><p>  Fr√ºher war es gut f√ºr uns.  Wir hatten Microservices, AWS, gut etablierte Teams f√ºr Produkte, Entwickler, die f√ºr ihre Dienstleistungen in der Produktion verantwortlich waren, lose gekoppelte Teams und Architektur.  Ich habe 2012 in dem Bericht <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûUnser Zeitalter der Aufkl√§rung‚Äú</a> (‚ÄûUnser Zeitalter der Aufkl√§rung‚Äú) auf einer Konferenz dar√ºber gesprochen.  Der Perfektion sind jedoch keine Grenzen gesetzt. </p><br><p>  Am Ende m√∂chte ich ein anderes Buch zitieren - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scale</a> .  Ich habe k√ºrzlich damit begonnen und es gibt ein interessantes Fragment zum Energieverbrauch in komplexen Systemen: </p><br><blockquote>  Um Ordnung und Struktur in einem sich entwickelnden System aufrechtzuerhalten, ist ein st√§ndiger Energiezufluss erforderlich, der zu St√∂rungen f√ºhrt.  Um das Leben zu erhalten, m√ºssen wir daher die ganze Zeit essen, um die unvermeidliche Entropie zu besiegen. <br>  Wir bek√§mpfen die Entropie, indem wir mehr Energie f√ºr Wachstum, Innovation, Wartung und Reparatur bereitstellen, was mit zunehmendem Alter des Systems schwieriger wird. Dieser Kampf ist die Grundlage f√ºr ernsthafte Diskussionen √ºber Alterung, Sterblichkeit, Nachhaltigkeit und Selbstversorgung eines Systems, sei es eines lebenden Organismus , Unternehmen oder Gesellschaft. </blockquote><p>  Ich denke, Sie k√∂nnen hier IT-Systeme hinzuf√ºgen.  Ich hoffe, dass unsere letzten Bem√ºhungen die Entropie auch f√ºr eine Weile aufrechterhalten werden. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de427441/">https://habr.com/ru/post/de427441/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de427431/index.html">Wie Android funktioniert, Teil 4</a></li>
<li><a href="../de427433/index.html">Verkehrsausgleich in den IP-Netzen des Betreibers</a></li>
<li><a href="../de427435/index.html">STM32H7 - Uhreinstellung ohne HAL</a></li>
<li><a href="../de427437/index.html">Verbindungsserver konfigurieren: MS SQL Server und Teradata</a></li>
<li><a href="../de427439/index.html">Die ganze Wahrheit √ºber RTOS. Artikel 16. Signale</a></li>
<li><a href="../de427443/index.html">Vivisektion des Erfolgs</a></li>
<li><a href="../de427447/index.html">PVS-Studio unterst√ºtzt die GNU Arm Embedded Toolchain</a></li>
<li><a href="../de427449/index.html">Wie man Tensorflow versteht und nicht stirbt und sogar etwas √ºber ein Auto lehrt</a></li>
<li><a href="../de427451/index.html">Verbinden Sie phpStorm-Tasks mit Bitrix24</a></li>
<li><a href="../de427453/index.html">Wie ich die Ton√ºbertragung auf dem Raspberry Pi gemacht habe</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
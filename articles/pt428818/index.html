<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìì üôáüèº üöñ DeOldify: um programa para colorir imagens em preto e branco üë≤üèæ üë©üèΩ‚Äçü§ù‚Äçüë©üèº üßóüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Em suma, a tarefa deste projeto √© colorir e restaurar fotografias antigas. Vou me aprofundar um pouco mais nos detalhes, mas primeiro, vamos ver as fo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>DeOldify: um programa para colorir imagens em preto e branco</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428818/">  Em suma, a tarefa deste projeto √© colorir e restaurar fotografias antigas.  Vou me aprofundar um pouco mais nos detalhes, mas primeiro, vamos ver as fotos!  A prop√≥sito, a maioria das imagens de origem √© tirada do subreddit r / TheWayWeWere, agrade√ßo a todos por fotos grandes e de alta qualidade. <br><br>  <b>Estes s√£o apenas alguns exemplos e s√£o bastante t√≠picos!</b> <br><br>  <i>Maria Anderson como a pequena fada e sua p√°gina Lyubov Ryabtsova no bal√© Bela Adormecida no Teatro Imperial, S√£o Petersburgo, R√∫ssia, 1890</i> <i><br></i> <br><img src="https://habrastorage.org/webt/s0/vh/vl/s0vhvlbdvsrvx09bxdugq6n6vaq.jpeg"><br><a name="habracut"></a><br>  <i>Uma mulher relaxa em sua sala de estar (1920, Su√©cia)</i> <br><br><img src="https://habrastorage.org/webt/qt/fe/7f/qtfe7f0alc4foxo_f6vija5p1ey.jpeg"><br><br>  <i>Estudantes de medicina se passando perto de um cad√°ver, por volta de 1890</i> <br><br><img src="https://habrastorage.org/webt/z7/bp/xl/z7bpxlwrvbib_tzqgaaw8ihadqy.jpeg"><br><br>  <i>Surfista no Hava√≠, 1890</i> <br><br><img src="https://habrastorage.org/webt/pr/7f/do/pr7fdopo8pdjs-yoxa-v-4bbwmi.jpeg"><br><br>  <i>Cavalo de giro, 1898</i> <br><br><img src="https://habrastorage.org/webt/yj/pk/iw/yjpkiwkgzbscgirnzjtp3sny8po.jpeg"><br><br>  <i>O interior do bar Miller e Shoemaker, 1899</i> <br><br><img src="https://habrastorage.org/webt/x6/d8/mo/x6d8modnwsdzhquyhiqnpwf4t2c.jpeg"><br><br>  <i>Paris na d√©cada de 1880</i> <br><br><img src="https://habrastorage.org/webt/kl/ct/pj/klctpjrr-czaqpsejgpgzbwyuqw.jpeg"><br><br>  <i>Vista a√©rea de Edimburgo na d√©cada de 1920</i> <br><br><img src="https://habrastorage.org/webt/fo/st/3w/fost3w3afdg26wwg_6dfjri-dw8.jpeg"><br><br>  <i>Mulher do Texas em 1938</i> <br><br><img src="https://habrastorage.org/webt/cm/47/lp/cm47lpwsw1hpb5kcnkicahf-iga.jpeg"><br><br>  <i>As pessoas na esta√ß√£o Waterloo assistem TV pela primeira vez, Londres, 1936</i> <br><br><img src="https://habrastorage.org/webt/in/nk/x9/innkx9gt0mixwjvdhk8ridbrqpy.jpeg"><br><br>  <i>Li√ß√£o de Geografia em 1850</i> <br><br><img src="https://habrastorage.org/webt/j_/ju/6l/j_ju6l3-7cea5_cuyjbucbsk8sq.jpeg"><br><br>  <i>Fumantes chineses de √≥pio em 1880</i> <br><br><img src="https://habrastorage.org/webt/i_/_j/tr/i__jtry3w4divci7u7b2hcaagim.jpeg"><br><br>  <b>Observe que mesmo fotos muito antigas e / ou de baixa qualidade ainda s√£o muito legais:</b> <br><br>  <i>Deadwood, Dakota do Sul, 1877</i> <br><br><img src="https://habrastorage.org/webt/lm/bj/vl/lmbjvladhdfyfygu0mal1rbqtry.jpeg"><br><br>  <i>Irm√£os e irm√£s em 1877 (Deadwood)</i> <br><br><img src="https://habrastorage.org/webt/mz/br/wq/mzbrwqmqehigiyahfj_obgmlflc.jpeg"><br><br>  <i>Pra√ßa Portsmouth em S√£o Francisco, 1851</i> <br><br><img src="https://habrastorage.org/webt/l3/qk/w-/l3qkw-yf0byhfmc8e6ysjl-bo7o.jpeg"><br><br>  <i>Samurai, por volta dos anos 1860</i> <br><br><img src="https://habrastorage.org/webt/l_/ug/wa/l_ugwar3td8vea4rhep9gfg7r4s.jpeg"><br><br>  Obviamente, o modelo n√£o √© perfeito.  Essa m√£o vermelha me deixa louco, mas, caso contr√°rio, funciona de maneira fant√°stica: <br><br>  <i>Menina de Seneca Iroquois, 1908</i> <br><br><img src="https://habrastorage.org/webt/js/ft/be/jsftbe0bjiodlhidemhvjj5fdf0.jpeg"><br><br>  <b>Ela tamb√©m pode colorir desenhos em preto e branco:</b> <br><br><img src="https://habrastorage.org/webt/hf/gf/zu/hfgfzugkkblhev4-ke5f55dabn8.jpeg"><br><br><h1>  Detalhes t√©cnicos </h1><br>  Este √© um modelo de aprendizado profundo.  Em particular, combinei as seguintes abordagens: <br><br><ul><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Auto-aten√ß√£o GAN</a></b> .  A √∫nica coisa √© que o <b>Unet pr√©-treinado √©</b> usado como gerador e eu apenas o troquei para normaliza√ß√£o espectral e, de fato, o mecanismo de Auto-Aten√ß√£o.  Esta √© uma modifica√ß√£o bastante simples.  Vou lhe dizer que a diferen√ßa √© impressionante em compara√ß√£o com a vers√£o anterior do Wasserstein GAN, que tentei fazer funcionar.  Gostei da teoria de Wasserstein GAN, mas na pr√°tica ela n√£o funciona.  Mas me apaixonei pela rede GAN de auto-aten√ß√£o. </li><li>  Uma estrutura de aprendizado como o <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">crescimento progressivo de um GAN</a></b> (mas n√£o exatamente o mesmo).  A diferen√ßa √© que o n√∫mero de camadas permanece constante: alterei o tamanho dos dados de entrada e ajustei a velocidade de aprendizado para que as transi√ß√µes entre os tamanhos fossem bem-sucedidas.  Parece que produz o mesmo resultado final, mas aprende mais r√°pido, √© mais est√°vel e executa melhor a generaliza√ß√£o. </li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Regra TTUR</a></b> ( <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Regra</a></b> de atualiza√ß√£o em duas <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">escalas de</a></b> tempo).  Aqui est√° bem claro: apenas uma itera√ß√£o individual do gerador / discriminador (cr√≠tica) e uma maior velocidade de treinamento de discriminador. </li><li>  <b>A fun√ß√£o de perda do gerador</b> consiste em duas partes: uma delas √© a principal fun√ß√£o da Perda Perceptual (ou Perda de Recurso) baseada no VGG16 - simplesmente pressiona o modelo do gerador para replicar a imagem de entrada.  A segunda parte √© a estimativa de perdas do discriminador (cr√≠tica).  Para os curiosos: somente a fun√ß√£o Perda Perceptual n√£o √© suficiente para um bom resultado.  Isso tende a simplesmente incentivar um monte de marrom / verde / azul - voc√™ sabe, enganando o teste, em que redes neurais s√£o realmente boas!  O ponto principal √© que os pr√≥prios GANs aprendem essencialmente a fun√ß√£o de perda para voc√™, o que √© realmente um grande passo em dire√ß√£o ao ideal que estamos buscando no aprendizado de m√°quina.  E, √© claro, os resultados melhorar√£o significativamente quando a pr√≥pria m√°quina aprender o que voc√™ codificou anteriormente manualmente.  Claro, este √© o caso aqui. </li></ul><br>  A beleza deste modelo √© que ele √© muito bom em uma variedade de modifica√ß√µes de imagem.  O que voc√™ v√™ acima s√£o os resultados do modelo de colora√ß√£o, mas esse √© apenas um componente do pipeline que eu quero desenvolver com o mesmo modelo. <br><br>  Em seguida, tentarei aperfei√ßoar as imagens antigas, e o pr√≥ximo item da agenda √© um modelo para melhorar a satura√ß√£o e a riqueza (desvanecimento).  Agora ela est√° nos est√°gios iniciais do treinamento.  Este √© basicamente o mesmo modelo, mas com algumas configura√ß√µes de contraste / brilho como uma simula√ß√£o de fotos desbotadas e fotos tiradas com equipamento antigo / ruim.  J√° recebi alguns resultados encorajadores: <br><br><img src="https://habrastorage.org/webt/jh/bs/qg/jhbsqg6a-unrsvzhxtva3z0ee7u.jpeg"><br><br><h1>  Detalhes do Projeto </h1><br>  Qual √© a ess√™ncia deste projeto?  Eu s√≥ quero aplicar o GAN para que as fotos antigas pare√ßam muito, muito boas.  E mais importante, tornar√° o projeto <i>√∫til</i> .  E sim, definitivamente estou interessado em trabalhar com o v√≠deo, mas primeiro preciso descobrir como controlar esse modelo sob o controle do consumo de mem√≥ria (este √© um verdadeiro animal).  Seria bom se os modelos n√£o aprendessem de dois a tr√™s dias no 1080Ti (infelizmente, t√≠pico da GAN).  Embora este seja meu filho, atualizarei e melhorarei ativamente o c√≥digo no futuro pr√≥ximo, mas tentarei tornar o programa o mais amig√°vel poss√≠vel, embora provavelmente haja algumas dificuldades com ele. <br><br>  E juro que documentarei o c√≥digo corretamente ... algum dia.  √â certo que sou uma daquelas pessoas que acredita em "c√≥digo de auto-documenta√ß√£o" (LOL). <br><br><h1>  Modelo de auto-lan√ßamento </h1><br>  O projeto √© constru√≠do na maravilhosa biblioteca Fast.AI.  Infelizmente, esta √© uma vers√£o antiga e ainda precisa ser atualizada para uma nova (definitivamente esta na ordem do dia).  Portanto, os pr√©-requisitos, em resumo: <br><br><ul><li>  <b>Biblioteca <i>antiga</i> Fast.AI.</b>  Tendo me enterrado no projeto por dois meses, perdi um pouco o que aconteceu com ele, porque o que agora est√° marcado como ‚Äúantigo‚Äù n√£o se parece realmente com o que tenho.  Tudo mudou nos √∫ltimos dois meses ou mais.  Portanto, se nada funcionar com outras vers√µes, eu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bifurquei aqui</a> .  Mais uma vez, a atualiza√ß√£o para a vers√£o mais recente est√° na agenda, pe√ßo desculpas antecipadamente. </li><li>  <b>Todas as depend√™ncias do Fast.AI</b> : existem arquivos requirements.txt e environment.yml convenientes. </li><li>  <b>Pytorch 0.4.1</b> (spectral_norm √© necess√°rio, portanto, voc√™ precisa da vers√£o est√°vel mais recente). </li><li>  <b>JupyterLab</b> . </li><li>  <b>Tensorboard</b> (ou seja, instala√ß√£o do Tensorflow) e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><b>TensorboardX</b></a> .  Eu acho que isso n√£o √© <i>estritamente</i> necess√°rio, mas √© muito mais f√°cil.  Para sua conveni√™ncia, j√° forneci todos os ganchos / retornos de chamada necess√°rios no Tensorboard!  Existem exemplos de seu uso.  Vale ressaltar que, por padr√£o, as imagens durante o processamento s√£o gravadas no Tensorboard a cada 200 itera√ß√µes, para que voc√™ tenha uma vis√£o constante e conveniente do que o modelo faz. </li><li>  <b>ImageNet</b> : Um excelente conjunto de dados para treinamento. </li><li>  <b>Placa gr√°fica poderosa</b> .  Eu realmente gostaria de ter mais mem√≥ria do que 11 GB na minha GeForce 1080Ti.  Se voc√™ tem algo mais fraco, ser√° dif√≠cil.  Unet e Critic s√£o absurdamente grandes, mas quanto maiores, melhores os resultados. </li></ul><br>  <b>Se voc√™ deseja iniciar o processamento de imagens agora mesmo</b> sem treinar o modelo, pode fazer o download de pesos prontos <a href="">aqui</a> .  Em seguida, abra ColorizationVisualization.ipynb no JupyterLab.  Verifique se h√° uma linha com um link para os pesos: <br><br><pre><code class="python hljs">colorizer_path = Path(<span class="hljs-string"><span class="hljs-string">'/path/to/colorizer_gen_192.h5'</span></span>)</code> </pre> <br>  Depois, voc√™ precisa carregar o modelo do colorizador ap√≥s a inicializa√ß√£o do netG: <br><br><pre> <code class="python hljs">load_model(netG, colorizer_path)</code> </pre> <br>  Em seguida, basta colocar as imagens na pasta / test_images /, de onde voc√™ inicia o programa.  Voc√™ pode visualizar os resultados no Notebook Jupyter com as seguintes linhas: <br><br><pre> <code class="python hljs">vis.plot_transformed_image(<span class="hljs-string"><span class="hljs-string">"test_images/derp.jpg"</span></span>, netG, md.val_ds, tfms=x_tfms, sz=<span class="hljs-number"><span class="hljs-number">500</span></span>)</code> </pre> <br>  Eu salvaria um tamanho de cerca de 500 px, mais ou menos, se voc√™ executar o programa em uma GPU com muita mem√≥ria (por exemplo, GeForce 1080Ti 11 GB).  Se houver menos mem√≥ria, voc√™ dever√° reduzir o tamanho das imagens ou tentar executar na CPU.  Na verdade, tentei fazer o √∫ltimo, mas por alguma raz√£o o modelo funcionou muito, absurdamente devagar, e n√£o encontrei tempo para investigar o problema.  Os especialistas recomendaram a constru√ß√£o de Pytorch a partir das fontes, resultando em um grande aumento de desempenho.  Hmm ... Naquele momento n√£o foi antes disso. <br><br><h1>  Informa√ß√µes Adicionais </h1><br>  A visualiza√ß√£o das imagens geradas conforme voc√™ aprende <i>tamb√©m pode ser</i> feita no Jupyter: voc√™ s√≥ precisa configur√°-la como <i>verdadeira</i> ao criar uma inst√¢ncia deste gancho de visualiza√ß√£o: <br><br> <code>GANVisualizationHook(TENSORBOARD_PATH, trainer, 'trainer', jupyter=True, visual_iters=100</code> <br> <br>  Eu prefiro deixar <i>false</i> e apenas usar o Tensorboard.  Acredite, voc√™ tamb√©m quer fazer exatamente isso.  Al√©m disso, se voc√™ deixar que ele funcione por muito tempo, o Jupyter consumir√° muita mem√≥ria com essas imagens. <br><br>  Os pesos dos modelos tamb√©m s√£o salvos automaticamente durante as execu√ß√µes de treinamento do GANTrainer.  Por padr√£o, eles s√£o salvos a cada 1000 itera√ß√µes (esta √© uma opera√ß√£o cara).  Eles s√£o armazenados na pasta raiz que voc√™ especificou para treinamento e o nome corresponde a save_base_name especificado na programa√ß√£o de treinamento.  Os pesos s√£o armazenados separadamente para cada tamanho de treino. <br><br>  Eu recomendaria navegar pelo c√≥digo de cima para baixo, come√ßando com o Jupyter Notebook.  Tomo essas anota√ß√µes simplesmente como uma interface conveniente para prototipagem e visualiza√ß√£o; todo o resto ir√° para os arquivos .py assim que eu encontrar um local para eles.  J√° tenho exemplos de visualiza√ß√£o que voc√™ pode ativar e ver com facilidade: basta abrir o xVisualization no Notebook, ele mostra as imagens de teste inclu√≠das no projeto (elas est√£o em test_images). <br><br>  Se voc√™ vir os Agendamentos da GAN, essa √© a coisa mais feia do projeto, apenas a minha vers√£o da implementa√ß√£o da GAN de aprendizado progressivo, adequada para o gerador Unet. <br><br>  Os pesos pr√©-treinados para o gerador de colora√ß√£o tamb√©m est√£o <a href="">aqui</a> .  O projeto DeFade ainda est√° em andamento, tentarei colocar bons pesos em alguns dias. <br><br>  Geralmente, durante o treinamento, voc√™ ver√° os primeiros bons resultados na metade, ou seja, com um tamanho de 192px (se voc√™ usar os exemplos de treinamento fornecidos). <br><br>  Tenho certeza de que estraguei tudo em algum lugar, ent√£o, por favor, deixe-me saber se √© assim. <br><br><h1>  Problemas conhecidos </h1><br><ul><li>  Voc√™ precisa <b>brincar um</b> pouco <b>com o tamanho da imagem</b> para obter o melhor resultado.  O modelo sofre claramente de algumas propor√ß√µes e propor√ß√µes ao gerar imagens.  Costumava ser muito pior, mas a situa√ß√£o melhorou significativamente com o aumento da ilumina√ß√£o / contraste e a introdu√ß√£o da aprendizagem progressiva.  Eu quero eliminar completamente esse problema e focar nele, mas at√© agora n√£o se desespere se a imagem parecer muito saturada ou com falhas estranhas.  Provavelmente, tudo ficar√° normal ap√≥s um pequeno redimensionamento.  Como regra, para imagens super saturadas voc√™ precisa aumentar o tamanho. </li><li>  Al√©m do acima: obter as melhores imagens realmente se resume √† <b>arte de escolher os par√¢metros ideais</b> .  Sim, os resultados s√£o selecionados manualmente.  Estou muito satisfeito com a qualidade e o modelo funciona de maneira bastante confi√°vel, mas n√£o perfeitamente.  O projeto ainda est√° em andamento!  Eu acho que a ferramenta pode ser usada como um "artista de IA", mas ainda n√£o est√° pronta para o p√∫blico em geral.  Apenas n√£o √© o tempo. </li><li>  Para complicar a situa√ß√£o: no momento, o modelo est√° <b>brutalmente consumindo mem√≥ria</b> ; portanto, no meu cart√£o 1080Ti, ele processa fotos com um m√°ximo de 500-600px.  Aposto que existem muitas op√ß√µes de otimiza√ß√£o aqui, mas ainda n√£o o fiz. </li><li>  Adicionei zero padding ao gerador Unet para qualquer coisa que n√£o caiba nos tamanhos esperados (√© assim que eu posso carregar uma imagem de tamanho arbitr√°rio).  Foi um hack muito r√°pido e leva a est√∫pidas bordas direita e inferior na sa√≠da de imagens de teste de tamanho arbitr√°rio.  Estou certo de que existe uma maneira melhor, mas ainda n√£o a encontrei. </li><li>  Modelo <i>adora</i> roupas azuis.  N√£o sei por que, a solu√ß√£o est√° na pesquisa! </li></ul><br><h1>  Quer mais? </h1><br>  Vou postar novos resultados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no Twitter</a> . <br><br>  <i>Adi√ß√£o do tradutor.</i> <br>  Deste √∫ltimo no Twitter: <br><br>  <i>Representantes da nacionalidade em seu esconderijo, 1880</i> <br><br><img src="https://habrastorage.org/webt/pc/qb/sq/pcqbsqbpnwcxf2htl6sd4s8p1ki.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">original</a> ) <br><br>  <i>A constru√ß√£o do metr√¥ de Londres, 1860</i> <br><br><img src="https://habrastorage.org/webt/k9/ag/td/k9agtdyfo6ugvfs0fencnkf4nge.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">original</a> ) <br><br>  <i>As favelas de Baltimore, 1938</i> <br><br><img src="https://habrastorage.org/webt/4i/2s/kt/4i2sktdre4ehitbtuybqzwocaia.jpeg"><br><br>  <i>Gin√°sio no Titanic, 1912</i> <br><br><img src="https://habrastorage.org/webt/ud/_v/vn/ud_vvn-6x0v3lcbx-khx_tvtey0.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">original</a> ) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt428818/">https://habr.com/ru/post/pt428818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt428808/index.html">Pouca conveni√™ncia na vida estudantil</a></li>
<li><a href="../pt428810/index.html">18 materiais sobre tecnologia digital em √°udio</a></li>
<li><a href="../pt428812/index.html">TypeScript: Desserializando JSON em classes com valida√ß√£o de tipo em propriedades</a></li>
<li><a href="../pt428814/index.html">Correspond√™ncia de produtos usando o Elasticsearch para o servi√ßo de monitoramento de pre√ßos dos concorrentes</a></li>
<li><a href="../pt428816/index.html">Material Design: Shape - dicas para melhorar a GUI de um aplicativo Android (e n√£o apenas) alterando a forma dos elementos</a></li>
<li><a href="../pt428820/index.html">Voc√™ est√° no 3D da terceira pessoa: Oculus Go + Raspberry Pi</a></li>
<li><a href="../pt428822/index.html">A hist√≥ria de um pequeno hack ou um bug adequado Bounty de um provedor de Internet local</a></li>
<li><a href="../pt428824/index.html">Telesc√≥pio al√©m do razo√°vel</a></li>
<li><a href="../pt428826/index.html">Ecaterimburgo pelos olhos de um rec√©m-chegado ou cinco anos ap√≥s a primeira reuni√£o</a></li>
<li><a href="../pt428828/index.html">Controle Remoto para Smartphone</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
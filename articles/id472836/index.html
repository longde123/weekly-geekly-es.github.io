<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚽 🆕 🐼 Open Data Hub Project - Platform Pembelajaran Mesin Terbuka Berbasis Red Hat OpenShift ☝️ 🌦️ 🧘🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Masa depan telah tiba, kecerdasan buatan dan teknologi pembelajaran mesin sudah berhasil digunakan oleh toko-toko favorit Anda, perusahaan transportas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Open Data Hub Project - Platform Pembelajaran Mesin Terbuka Berbasis Red Hat OpenShift</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redhatrussia/blog/472836/">  Masa depan telah tiba, kecerdasan buatan dan teknologi pembelajaran mesin sudah berhasil digunakan oleh toko-toko favorit Anda, perusahaan transportasi dan bahkan peternakan yang menumbuhkan kalkun. <br><br><img src="https://habrastorage.org/webt/po/5a/pz/po5apz39w7i01k1j6z_k3nlbxjk.jpeg" width="100%"><br><br>  Dan jika ada sesuatu, maka di Internet tentang hal itu sudah ada ... proyek terbuka!  Lihat bagaimana Open Data Hub membantu meningkatkan teknologi baru dan menghindari kesulitan dalam mengimplementasikannya. <br><a name="habracut"></a><br>  Dengan semua manfaat kecerdasan buatan (AI) dan pembelajaran mesin (ML), organisasi sering mengalami kesulitan meningkatkan teknologi ini.  Masalah utama dengan ini, sebagai suatu peraturan, adalah sebagai berikut: <br><br><ul><li>  <b>Pertukaran informasi dan kerja sama</b> - hampir mustahil untuk bertukar informasi tanpa upaya yang tidak perlu dan bekerja sama dalam mode iterasi cepat. </li><li>  <b>Akses ke data</b> - untuk setiap tugas perlu dibangun kembali dan secara manual, yang memakan waktu. </li><li>  Akses atas permintaan - tidak ada cara untuk mendapatkan akses atas permintaan ke alat dan platform pembelajaran mesin, serta infrastruktur komputasi. </li><li>  <b>Produksi</b> - model tetap pada tahap prototipe dan tidak dibawa ke eksploitasi industri. </li><li>  <b>Melacak dan menjelaskan hasil AI</b> - reproduksibilitas, pelacakan, dan menjelaskan hasil AI / ML sulit. </li></ul><br>  Dibiarkan tidak terselesaikan, masalah-masalah ini mempengaruhi kecepatan, efisiensi dan produktivitas spesialis pengolahan dan analisis data yang berharga.  Hal ini menyebabkan frustrasi, kekecewaan mereka dalam pekerjaan, dan sebagai hasilnya, harapan bisnis tentang AI / ML menjadi sia-sia. <br><br>  Tanggung jawab untuk menyelesaikan masalah ini terletak pada profesional TI yang perlu menyediakan analis data - benar, seperti cloud.  Jika lebih berkembang, maka kita membutuhkan platform yang memberikan kebebasan memilih dan memiliki akses yang nyaman dan mudah.  Pada saat yang sama, ia cepat, mudah dikonfigurasi ulang, dapat disesuaikan sesuai permintaan dan tahan terhadap kegagalan.  Membangun platform semacam itu berdasarkan teknologi open source membantu untuk tidak menjadi tergantung pada vendor dan mempertahankan keunggulan strategis jangka panjang dalam hal pengendalian biaya. <br><br>  Beberapa tahun yang lalu, sesuatu yang serupa terjadi dalam pengembangan aplikasi dan menyebabkan munculnya layanan-layanan microser, lingkungan cloud hybrid, otomatisasi IT dan proses-proses yang gesit.  Untuk mengatasi semua ini, para profesional TI mulai menggunakan wadah, Kubernetes, dan cloud hybrid terbuka. <br><br>  Sekarang pengalaman ini diterapkan untuk menjawab tantangan Al.  Oleh karena itu, profesional TI membuat platform yang didasarkan pada wadah, memungkinkan Anda untuk membuat layanan AI / ML sebagai bagian dari proses lincah, mempercepat inovasi dan dibangun dengan mata pada cloud hybrid. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vl/gs/kt/vlgsktsdfenliiynd552uvd_eb0.png"></div><br><br>  Kami akan mulai membangun platform seperti itu dengan Red Hat OpenShift, platform Kubernetes kontainer kami untuk cloud hybrid yang memiliki ekosistem solusi perangkat lunak dan perangkat keras ML yang berkembang cepat (NVIDIA, H2O.ai, Starburst, PerceptiLabs, dll.).  Beberapa pelanggan Red Hat, seperti BMW Group, ExxonMobil, dan lain-lain, telah mengerahkan rantai alat-alat ML dan proses DevOps kemas berdasarkan platform ini dan ekosistemnya untuk membawa arsitektur ML-nya ke operasi komersial dan mempercepat pekerjaan analis data. <br><br>  Alasan lain mengapa kami meluncurkan proyek Open Data Hub adalah untuk mendemonstrasikan arsitektur contoh berdasarkan beberapa proyek sumber terbuka dan menunjukkan bagaimana menerapkan seluruh siklus hidup solusi ML berdasarkan pada platform OpenShift. <br><br><h3>  Buka Proyek Hub Data </h3><br>  Ini adalah proyek sumber terbuka yang berkembang dalam kerangka komunitas pengembangan yang sesuai dan menerapkan siklus operasi penuh - mulai dari memuat dan mengonversi data awal hingga pembentukan, pelatihan, dan pemeliharaan model - saat menyelesaikan tugas AI / ML menggunakan wadah dan Kubernet pada platform OpenShift.  Proyek ini dapat dianggap sebagai implementasi referensi, contoh bagaimana membangun AI / ML terbuka sebagai solusi Layanan berdasarkan OpenShift dan alat sumber terbuka terkait seperti Tensorflow, JupyterHub, Spark dan lainnya.  Penting untuk dicatat bahwa Red Hat sendiri menggunakan proyek ini untuk menyediakan layanan AI / ML-nya.  Selain itu, OpenShift terintegrasi dengan perangkat lunak utama dan solusi ML perangkat keras dari NVIDIA, Seldon, Starbust dan vendor lainnya, yang memfasilitasi pembangunan dan peluncuran sistem pembelajaran mesin mereka sendiri. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ii/lx/er/iilxervidxlqx7qsyfej1ibhnuc.png"></div><br><br>  Proyek Open Data Hub berfokus pada kategori pengguna dan kasus penggunaan berikut: <br><br><ul><li>  Seorang analis data yang membutuhkan solusi untuk mengimplementasikan proyek-proyek ML, yang diselenggarakan oleh jenis cloud dengan fungsi swalayan. </li><li>  Seorang analis data yang membutuhkan seleksi maksimum dari berbagai alat dan platform AI / ML open source terbaru. </li><li>  Seorang analis data yang membutuhkan akses ke sumber data saat melatih model. </li><li>  Analis data yang membutuhkan akses ke sumber daya komputasi (CPU, GPU, memori). </li><li>  Date adalah seorang analis yang membutuhkan kesempatan untuk berkolaborasi dan berbagi hasil kerja dengan kolega, menerima umpan balik dan memperkenalkan peningkatan menggunakan metode iterasi cepat. </li><li>  Seorang analis data yang ingin berinteraksi dengan pengembang (dan tim devops) sehingga model ML dan hasil kerjanya masuk ke produksi. </li><li>  Seorang insinyur data yang perlu menyediakan analitik data dengan akses ke berbagai sumber data sesuai dengan standar dan persyaratan keselamatan. </li><li>  Seorang administrator / operator sistem TI yang membutuhkan kemampuan untuk dengan mudah mengontrol siklus hidup (instalasi, konfigurasi, pembaruan) komponen dan teknologi open source.  Kami juga membutuhkan alat manajemen dan kuota yang tepat. </li></ul><br>  Proyek Open Data Hub menggabungkan sejumlah alat sumber terbuka untuk mengimplementasikan operasi AI / ML yang lengkap.  Notebook Jupyter digunakan di sini sebagai alat kerja utama untuk analisis data.  Toolkit ini sekarang populer di kalangan profesional pengolah data dan analisis, dan Open Data Hub memungkinkan mereka untuk dengan mudah membuat dan mengelola ruang kerja Notebook Jupyter menggunakan JupyterHub bawaan.  Selain membuat dan mengimpor notebook Jupyter, proyek Open Data Hub juga berisi sejumlah notebook yang sudah jadi dalam bentuk AI Library. <br><br>  Perpustakaan ini adalah kumpulan komponen pembelajaran mesin sumber terbuka dan solusi skrip sampel yang menyederhanakan prototipe cepat.  JupyterHub terintegrasi dengan model akses OpenShift RBAC, yang memungkinkan Anda untuk menggunakan akun OpenShift yang ada dan menerapkan sistem masuk tunggal.  Selain itu, JupyterHub menawarkan antarmuka pengguna yang nyaman yang disebut spawner, yang dengannya pengguna dapat dengan mudah mengkonfigurasi jumlah sumber daya komputasi (inti prosesor, memori, GPU) untuk Jupyter Notebook yang dipilih. <br><br>  Setelah analis data membuat dan mengatur laptop, penjadwal Kubernetes, yang merupakan bagian dari OpenShift, menangani sisanya.  Pengguna hanya dapat melakukan eksperimen, menyimpan, dan membagikan hasil pekerjaan mereka.  Selain itu, pengguna tingkat lanjut dapat secara langsung mengakses shell OpenShift CLI langsung dari notebook Jupyter untuk mengaktifkan primitif Kubernetes, seperti Pekerjaan, atau fungsionalitas OpenShift, seperti Tekton atau Knative.  Atau Anda dapat menggunakan OpenShift GUI yang nyaman yang disebut "OpenShift Web Console" untuk ini. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gh/j_/2v/ghj_2vrrngca4d0gp0218_rcv2s.png"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3w/zn/_a/3wzn_ap-tzpzvuzeb5xcgvuwhse.png"></div><br><br>  Beralih ke langkah berikutnya, Open Data Hub menyediakan kemampuan untuk mengelola jalur pipa data.  Untuk ini, objek Ceph digunakan, yang disediakan sebagai gudang data objek S3-kompatibel.  Apache Spark mengalirkan data dari sumber eksternal atau penyimpanan internal Ceph S3, dan juga memungkinkan Anda untuk melakukan konversi data awal.  Apache Kafka menyediakan manajemen jaringan pipa data tingkat lanjut (di mana Anda dapat melakukan banyak unduhan, serta operasi transformasi, analisis, dan penyimpanan data). <br><br>  Jadi, analis data mendapat akses ke data dan membangun model.  Sekarang ia memiliki keinginan untuk membagikan hasilnya dengan kolega atau pengembang aplikasi, dan untuk memberi mereka model prinsip layanannya.  Untuk melakukan ini, Anda memerlukan server output, dan Open Data Hub memiliki server seperti itu, disebut Seldon dan memungkinkan Anda untuk menerbitkan model sebagai layanan yang tenang. <br><br>  Pada beberapa titik, ada beberapa model seperti itu di server Seldon, dan ada kebutuhan untuk memantau bagaimana mereka digunakan.  Untuk melakukan ini, Open Data Hub menawarkan koleksi metrik yang relevan dan mesin laporan berdasarkan pada alat pemantauan sumber terbuka yang banyak digunakan Prometheus dan Grafana.  Sebagai hasilnya, kami mendapatkan umpan balik untuk memantau penggunaan model AI, khususnya di lingkungan produksi. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ka/wx/pq/kawxpqusyybvhp52lblnjqov2xy.png"></div><br><br>  Dengan demikian, Open Data Hub menyediakan pendekatan seperti awan di seluruh siklus operasi AI / ML, dari akses dan persiapan data hingga pelatihan dan operasi industri dari model. <br><br><h3>  Menyatukan semuanya </h3><br>  Sekarang pertanyaannya adalah bagaimana mengatur ini untuk administrator OpenShift.  Dan inilah operator Kubernetes khusus untuk proyek Open Data Hub. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gj/qh/io/gjqhiogbxzrwqu7f7n5eqkian9q.png"></div><br><br>  Operator ini mengelola instalasi, konfigurasi, dan siklus hidup proyek Open Data Hub, termasuk penyebaran alat-alat seperti JupyterHub, Ceph, Spark, Kafka, Seldon, Prometheus, dan Grafana.  Proyek Open Data Hub dapat ditemukan di konsol web OpenShift, di bagian komunitas-operator.  Dengan demikian, administrator OpenShift dapat menentukan bahwa proyek OpenShift yang sesuai dikategorikan sebagai "Open Data Hub Project".  Ini dilakukan sekali.  Setelah itu, analis data melalui konsol web OpenShift memasuki ruang proyeknya dan melihat bahwa operator Kubernet yang sesuai telah diinstal dan tersedia untuk proyek-proyeknya.  Dia kemudian membuat sebuah instance dari proyek Open Data Hub dengan satu klik dan segera mengakses alat yang dijelaskan di atas.  Dan semua ini dapat dikonfigurasi dalam mode ketersediaan tinggi dan toleransi kesalahan. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_n/vn/g5/_nvng5tdobehanormqndfv-tnms.png"></div><br><br>  Jika Anda ingin mencoba proyek Open Data Hub dengan tangan Anda sendiri, mulailah dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">instruksi instalasi dan tutorial pengantar</a> .  Rincian teknis arsitektur Open Data Hub dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> , rencana pengembangan proyek ada di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> .  Di masa depan, direncanakan untuk mengimplementasikan integrasi tambahan dengan Kubeflow, menyelesaikan sejumlah masalah dengan regulasi dan keamanan data, dan mengatur integrasi dengan sistem berdasarkan aturan Drools dan Optaplanner.  Anda dapat mengekspresikan pendapat Anda dan menjadi anggota proyek <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Open Data Hub</a> di halaman <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">komunitas</a> . <br><br>  Kami meringkas: masalah serius dengan penskalaan mencegah organisasi dari sepenuhnya menyadari potensi kecerdasan buatan dan pembelajaran mesin.  Red Hat OpenShift telah lama berhasil digunakan untuk memecahkan masalah serupa di industri perangkat lunak.  Proyek Open Data Hub, yang diimplementasikan dalam komunitas pengembangan sumber terbuka, menawarkan arsitektur referensi untuk mengatur siklus operasi AI / ML penuh berdasarkan pada cloud hybrid OpenShift.  Kami memiliki rencana pengembangan yang jelas dan bijaksana untuk proyek ini, dan kami serius menciptakan komunitas yang aktif dan bermanfaat untuk mengembangkan solusi AI terbuka pada platform OpenShift di sekitarnya. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id472836/">https://habr.com/ru/post/id472836/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id472818/index.html">Gerakan Kolektif: Bagaimana Para Ilmuwan Semut Gabus Belajar</a></li>
<li><a href="../id472822/index.html">Ketika Akademi Ilmu Pengetahuan Rusia tidak berdaya</a></li>
<li><a href="../id472826/index.html">Interaksi mikro dan penggunaannya dalam antarmuka pengguna</a></li>
<li><a href="../id472830/index.html">Cara menulis kode yang mudah dijelaskan</a></li>
<li><a href="../id472832/index.html">Lokalisasi atau Adaptasi Kreatif? Studi Kasus Game Streets of Rogue</a></li>
<li><a href="../id472838/index.html">Dalam praktiknya, dalam 80-90% kasus, aplikasi web lambat karena front-end: wawancara dengan Ivan Akulov</a></li>
<li><a href="../id472840/index.html">Penyimpanan yang Ditentukan Perangkat Lunak, atau Apa yang Membunuh Dinosaurus?</a></li>
<li><a href="../id472848/index.html">Refleksi tentang karier di bidang TI</a></li>
<li><a href="../id472850/index.html">Profesi atau Kehidupan: Menangkan Kursus Netologi Jika Anda Tidak Takut</a></li>
<li><a href="../id472852/index.html">GitLab membuat perubahan untuk pengguna produk cloud dan komersial</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåâ üë¥üèª üôçüèº Analyse des param√®tres ELK 7.5 pour l'analyse des journaux Mikrotik üçó üêº ü•É</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il a longtemps √©t√© une id√©e de voir ce que vous pouvez faire avec ELK et des sources improvis√©es de journaux et de statistiques. Sur les pages du Habr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analyse des param√®tres ELK 7.5 pour l'analyse des journaux Mikrotik</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/481596/">  Il a longtemps √©t√© une id√©e de voir ce que vous pouvez faire avec ELK et des sources improvis√©es de journaux et de statistiques.  Sur les pages du Habr, je pr√©vois de montrer un exemple pratique de la fa√ßon dont, en utilisant un mini-serveur domestique, vous pouvez faire, par exemple, un pot de miel avec un syst√®me d'analyse de journal bas√© sur la pile ELK.  Dans cet article, je vais vous parler de l'exemple le plus simple d'analyse des journaux de pare-feu √† l'aide de la pile ELK.  √Ä l'avenir, je voudrais d√©crire les param√®tres d'environnement pour analyser le trafic Netflow et les vidages PCAP par Zeek. <br><br><img src="https://habrastorage.org/webt/ze/cb/qx/zecbqxrubn4v0mutaoewxzsp1zm.png"><br><br>  Si vous avez une adresse IP publique et un appareil plus ou moins intelligent comme passerelle / pare-feu, vous pouvez organiser un pot de miel passif en configurant des demandes entrantes pour des ports TCP et UDP ¬´d√©licieux¬ª.  Il existe un exemple de configuration d'un routeur Mikrotik sous un chat, mais si vous avez un routeur de fournisseur diff√©rent (ou un autre syst√®me de s√©curit√©) √† port√©e de main, il vous suffit de comprendre un peu de formats de donn√©es et de param√®tres sp√©cifiques au fournisseur, et vous obtiendrez le m√™me r√©sultat. <br><br><h3>  Clause de non-responsabilit√© </h3><br>  L'article ne pr√©tend pas √™tre original, il ne traite pas des questions de tol√©rance aux pannes des services, de s√©curit√©, de bonnes pratiques, etc.  Il est n√©cessaire de consid√©rer ce mat√©riel comme acad√©mique, il convient √† la connaissance des fonctionnalit√©s de base de la pile ELK et du m√©canisme d'analyse des journaux du p√©riph√©rique r√©seau.  Cependant, cela pourrait aussi √™tre int√©ressant pour un novice. <br><br>  Le projet est lanc√© √† partir du fichier docker-compose, et il est tr√®s facile de d√©ployer votre environnement similaire, m√™me si vous avez un routeur de fournisseur diff√©rent sous la main, il vous suffit de comprendre un peu les formats de donn√©es et les param√®tres sp√©cifiques au fournisseur.  Pour le reste, j'ai essay√© de d√©crire autant que possible toutes les nuances associ√©es √† la configuration des pipelines Logstash et des mappages Elasticsearch dans la version actuelle d'ELK.  Tous les composants de ce syst√®me sont h√©berg√©s sur <a href="https://github.com/mekhanme/elk-mikrot" rel="nofollow">github</a> , y compris les configurations de service.  √Ä la fin de l'article, je ferai la section D√©pannage, qui d√©crira les √©tapes pour diagnostiquer les probl√®mes courants des nouveaux arrivants dans cette entreprise. <br><a name="habracut"></a><br><h3>  Pr√©sentation </h3><br>  Sur le serveur lui-m√™me, j'ai install√© le syst√®me de virtualisation Proxmox, sur celui-ci dans les conteneurs Docker de la machine KVM sont lanc√©s.  On suppose que vous savez comment fonctionnent Docker et Docker-compose, l'avantage de d√©finir des exemples d'utilisation sur Internet est suffisant.  Je n'aborderai pas les probl√®mes d'installation de Docker, j'√©crirai un peu sur docker-compose. <br><br>  L'id√©e de lancer Honeypot est n√©e lors de l'√©tude d'Elasticsearch, Logstash et Kibana.  Dans ma carri√®re professionnelle, je n'ai jamais √©t√© impliqu√© dans l'administration et l'utilisation g√©n√©rale de cette pile, mais j'ai des projets de loisirs, gr√¢ce auxquels j'ai d√©velopp√© un grand int√©r√™t √† explorer les possibilit√©s offertes par le moteur de recherche Elasticsearch et Kibana, avec lesquelles vous pouvez analyser et visualiser des donn√©es. <br><br>  Mon pas le plus r√©cent mini-serveur NUC avec 8 Go de RAM est juste suffisant pour d√©marrer la pile ELK avec un n≈ìud Elastic.  Dans les environnements de production, cela, bien s√ªr, n'est pas recommand√©, mais juste pour la formation.  Concernant la question de la s√©curit√©, il y a une remarque √† la fin de l'article. <br><br>  Internet regorge d'instructions pour installer et configurer la pile ELK pour des t√¢ches similaires (par exemple, <a href="https://habr.com/ru/post/324760/">analyser les attaques par force brute sur ssh √† l'aide de Logstash version 2</a> , <a href="https://habr.com/ru/post/431600/">analyser les journaux Suricata √† l'aide de Filebeat version 6</a> ), mais dans la plupart des cas, l'attention n'est pas accord√©e aux d√©tails, √† cela 90 pour cent du mat√©riel sera pour les versions 1 √† 6 (au moment de la r√©daction, la version actuelle d'ELK est 7.5.0).  Ceci est important, car √† partir de la version 6, Elasticsearch a <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html" rel="nofollow">d√©cid√© de supprimer l'</a> entit√© de type de mappage, modifiant ainsi la syntaxe de la requ√™te et la structure de la carte.  Le mod√®le de mappage dans Elastic est g√©n√©ralement un objet tr√®s important, et pour que plus tard il n'y ait plus de probl√®mes avec l'√©chantillonnage et la visualisation des donn√©es, je vous conseille de ne pas vous impliquer dans le copier-coller et d'essayer de comprendre ce que vous faites.  De plus, je vais essayer d'expliquer clairement ce que signifient les op√©rations et les configurations d√©crites. <br><br><h2>  Configuration du routeur </h2><br>  Pour le r√©seau domestique, j'utilise Mikrotik comme routeur, donc un exemple sera pour lui.  Mais presque n'importe quel syst√®me peut √™tre configur√© pour envoyer syslog √† un serveur distant, que ce soit un routeur, un serveur ou un autre syst√®me de s√©curit√© pouvant se connecter. <br><br><h3>  Envoi de messages Syslog √† un serveur distant </h3><br>  Dans Mikrotik, pour configurer la journalisation sur un serveur distant via la CLI, entrez simplement quelques commandes: <br><br><pre><code class="plaintext hljs">/system logging action add remote=192.168.88.130 remote-port=5145 src-address=192.168.88.1 name=logstash target=remote /system logging add action=logstash topics=info</code> </pre> <br><h3>  Configuration des r√®gles de pare-feu avec journalisation </h3><br>  Nous ne sommes int√©ress√©s que par certaines donn√©es (nom d'h√¥te, adresse IP, nom d'utilisateur, URL, etc.), √† partir desquelles vous pouvez obtenir une belle visualisation ou s√©lection.  Dans le cas le plus simple, pour obtenir des informations sur les analyses de port et les tentatives d'acc√®s, vous devez configurer le composant pare-feu pour consigner les d√©clencheurs de r√®gles.  Sur Mikrotik, j'ai mis en place les r√®gles dans la table NAT, pas Filter, car √† l'avenir je vais mettre des chanipots qui imiteront le travail des services, cela me permettra d'enqu√™ter plus d'informations sur le comportement des botnets, mais c'est un sc√©nario plus avanc√© et pas √† cette √©poque. <br><br>  Attention!  Dans la configuration ci-dessous, le port TCP standard du service SSH (22) est boucl√© dans le r√©seau local.  Si vous utilisez SSH pour acc√©der au routeur de l'ext√©rieur et que les param√®tres disposent du port 22 ( <i>impression du service ip</i> dans la CLI et des <i>services ip&gt;</i> dans Winbox), vous devez r√©affecter le port pour la gestion SSH, ou n'entrez pas la derni√®re r√®gle dans le tableau. <br>  En outre, selon le nom de l'interface WAN (si le pont WAN n'est pas utilis√©), vous devez modifier le param√®tre dans l' <i>interface</i> en celui appropri√©. <br><br><pre> <code class="plaintext hljs">/ip firewall nat add action=netmap chain=dstnat comment="HONEYPOT RDP" dst-port=3389 in-interface=bridge-wan log=yes log-prefix=honeypot_rdp protocol=tcp to-addresses=192.168.88.201 to-ports=3389 add action=netmap chain=dstnat comment="HONEYPOT ELASTIC" dst-port=9200 in-interface=bridge-wan log=yes log-prefix=honeypot_elastic protocol=tcp to-addresses=192.168.88.201 to-ports=9211 add action=netmap chain=dstnat comment=" HONEYPOT TELNET" dst-port=23 in-interface=bridge-wan log=yes log-prefix=honeypot_telnet protocol=tcp to-addresses=192.168.88.201 to-ports=2325 add action=netmap chain=dstnat comment="HONEYPOT DNS" dst-port=53 in-interface=bridge-wan log=yes log-prefix=honeypot_dns protocol=udp to-addresses=192.168.88.201 to-ports=9953 add action=netmap chain=dstnat comment="HONEYPOT FTP" dst-port=21 in-interface=bridge-wan log=yes log-prefix=honeypot_ftp protocol=tcp to-addresses=192.168.88.201 to-ports=9921 add action=netmap chain=dstnat comment="HONEYPOT SMTP" dst-port=25 in-interface=bridge-wan log=yes log-prefix=honeypot_smtp protocol=tcp to-addresses=192.168.88.201 to-ports=9925 add action=netmap chain=dstnat comment="HONEYPOT SMB" dst-port=445 in-interface=bridge-wan log=yes log-prefix=honeypot_smb protocol=tcp to-addresses=192.168.88.201 to-ports=9445 add action=netmap chain=dstnat comment="HONEYPOT MQTT" dst-port=1883 in-interface=bridge-wan log=yes log-prefix=honeypot_mqtt protocol=tcp to-addresses=192.168.88.201 to-ports=9883 add action=netmap chain=dstnat comment="HONEYPOT SIP" dst-port=5060 in-interface=bridge-wan log=yes log-prefix=honeypot_sip protocol=tcp to-addresses=192.168.88.201 to-ports=9060 add action=dst-nat chain=dstnat comment="HONEYPOT SSH" dst-port=22 in-interface=bridge-wan log=yes log-prefix=honeypot_ssh protocol=tcp to-addresses=192.168.88.201 to-ports=9922</code> </pre> <br><img src="https://habrastorage.org/webt/of/dm/jo/ofdmjo5n3f8fi54udyvbixhaifm.png"><br><br>  Dans Winbox, le m√™me est configur√© dans l' <i>onglet IP&gt; Pare-feu&gt; NAT</i> . <br><br>  Maintenant, le routeur redirige les paquets re√ßus vers l'adresse locale 192.168.88.201 et le port personnalis√©.  √Ä l'heure actuelle, personne n'√©coute sur ces ports, donc les connexions seront interrompues.  √Ä l'avenir, dans Docker, vous pouvez ex√©cuter Honeypot, dont il existe de nombreux pour chaque service.  Si cela n'est pas pr√©vu, au lieu de r√®gles NAT, vous devez √©crire une r√®gle avec l'action de suppression dans la cha√Æne de filtrage. <br><br><h3>  D√©marrage d'ELK avec docker-compose </h3><br>  Ensuite, vous pouvez commencer √† configurer le composant qui traitera les journaux.  Je vous conseille de vous entra√Æner imm√©diatement et de cloner le r√©f√©rentiel pour voir compl√®tement les fichiers de configuration.  Toutes les configurations d√©crites peuvent √™tre vues ici, dans le texte de l'article, je ne copierai qu'une partie des configurations. <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ git clone https://github.com/mekhanme/elk-mikrot.git</code> </pre> <br><img src="https://habrastorage.org/webt/95/_b/9g/95_b9gu4scfg99nwtyfph-0pf7o.png"><br><br>  Dans un environnement de test ou de d√©veloppement, il est plus pratique d'ex√©cuter des conteneurs Docker √† l'aide de Docker-compose.  Dans ce projet, j'utilise le fichier docker-compose de la derni√®re <a href="https://docs.docker.com/compose/compose-file/" rel="nofollow">version 3.7</a> pour le moment, il n√©cessite la version 18.06.0+ du moteur docker, donc cela vaut la peine de mettre √† jour le <a href="https://docs.docker.com/install/linux/docker-ce/centos/" rel="nofollow">docker</a> , ainsi que <a href="https://docs.docker.com/compose/install/" rel="nofollow">docker-compose</a> . <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl -L "https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose ‚ùØ‚ùØ chmod +x /usr/local/bin/docker-compose</code> </pre> <br>  √âtant donn√© que dans les versions r√©centes de docker-compose, le param√®tre mem_limit a √©t√© <i>supprim√©</i> et <i>d√©ploy√© a √©t√©</i> ajout√©, qui ne s'ex√©cute qu'en mode <i>swarm</i> ( <i>docker stack deploy</i> ), le lancement de la configuration <i>docker-compose up</i> avec des limites entra√Æne une erreur.  Comme je n'utilise pas swarm et que je veux avoir des limites de ressources, je dois le d√©marrer avec l'option <i>--compatibility</i> , qui convertit les limites des nouvelles versions compos√©es par docker en √©quivalent non-weld. <br><br>  Test de tous les conteneurs (en arri√®re-plan -d): <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker-compose --compatibility up -d</code> </pre> <br>  Vous devrez attendre que toutes les images soient t√©l√©charg√©es, et une fois le lancement termin√©, vous pouvez v√©rifier l'√©tat des conteneurs avec la commande: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker-compose --compatibility ps</code> </pre> <br>  En raison du fait que tous les conteneurs seront sur le m√™me r√©seau (si vous ne sp√©cifiez pas explicitement le r√©seau, un nouveau pont est cr√©√©, ce qui convient dans ce sc√©nario) et docker-compose.yml contient le param√®tre container_name pour tous les <i>conteneurs</i> , les conteneurs auront d√©j√† une connectivit√© via le DNS int√©gr√© docker.  Par cons√©quent, il n'est pas n√©cessaire d'enregistrer les adresses IP dans les configurations de conteneurs.  Dans la configuration Logstash, le sous-r√©seau 192.168.88.0/24 est enregistr√© comme local, plus loin dans la configuration, il y aura des explications plus d√©taill√©es, selon lesquelles vous pouvez d√©vier l'exemple de la configuration avant de commencer. <br><br><h2>  Configurer les services ELK </h2><br>  De plus, il y aura des explications sur la fa√ßon de configurer la fonctionnalit√© des composants ELK, ainsi que d'autres actions qui devront √™tre effectu√©es sur Elasticsearch. <br><br>  Pour d√©terminer les coordonn√©es g√©ographiques par adresse IP, vous devrez t√©l√©charger la base de donn√©es <a href="https://dev.maxmind.com/geoip/geoip2/geolite2/" rel="nofollow">GeoLite2</a> gratuite de MaxMind: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ cd elk-mikrot &amp;&amp; mkdir logstash/geoip_db ‚ùØ‚ùØ curl -O https://geolite.maxmind.com/download/geoip/database/GeoLite2-City-CSV.zip &amp;&amp; unzip GeoLite2-City-CSV.zip -d logstash/geoip_db &amp;&amp; rm -f GeoLite2-City-CSV.zip ‚ùØ‚ùØ curl -O https://geolite.maxmind.com/download/geoip/database/GeoLite2-ASN-CSV.zip &amp;&amp; unzip GeoLite2-ASN-CSV.zip -d logstash/geoip_db &amp;&amp; rm -f GeoLite2-ASN-CSV.zip</code> </pre> <br><h3>  Configuration de Logstash </h3><br>  Le fichier de configuration principal est <i>logstash.yml</i> , o√π j'ai enregistr√© l'option pour recharger automatiquement la configuration, les autres param√®tres de l'environnement de test ne sont pas significatifs.  La configuration du traitement des donn√©es (journaux) dans Logstash est d√©crite dans des fichiers de <i>configuration</i> s√©par√©s, g√©n√©ralement stock√©s dans le r√©pertoire du <i>pipeline</i> .  Dans le sch√©ma, lorsque <a href="https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html" rel="nofollow">plusieurs pipelines</a> sont utilis√©s, le fichier <a href="https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html" rel="nofollow">pipelines.yml</a> d√©crit les <i>pipelines</i> activ√©s.  Un pipeline est une cha√Æne d'actions sur des donn√©es non structur√©es afin de recevoir des donn√©es avec une structure sp√©cifique en sortie.  Un sch√©ma avec <i>pipelines.yml</i> configur√© s√©par√©ment est facultatif, vous pouvez vous en passer en t√©l√©chargeant toutes les configurations √† partir du r√©pertoire de <i>pipeline</i> mont√©.Cependant, avec un fichier <i>pipelines.yml</i> sp√©cifique, la configuration est plus flexible, car vous pouvez activer et d√©sactiver les fichiers de <i>configuration</i> √† partir du r√©pertoire de <i>pipeline</i> configs n√©cessaires.  De plus, le rechargement des configurations ne fonctionne que dans le sch√©ma de pipelines multiples. <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ cat logstash/config/pipelines.yml - pipeline.id: logstash-mikrot path.config: "pipeline/logstash-mikrot.conf"</code> </pre> <br>  Vient ensuite la partie la plus importante de la configuration Logstash.  La description du pipeline se compose de plusieurs sections - au d√©but, les plugins sont indiqu√©s dans la section <i>Input</i> √† l'aide de laquelle Logstash re√ßoit des donn√©es.  Le moyen le plus simple de collecter syslog √† partir d'un p√©riph√©rique r√©seau est d'utiliser les plugins d'entr√©e <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-tcp.html" rel="nofollow">tcp</a> / <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-udp.html" rel="nofollow">udp</a> .  Le seul param√®tre requis pour ces plugins est le <i>port</i> , il doit √™tre sp√©cifi√© de la m√™me mani√®re que dans les param√®tres du routeur. <br><br>  La deuxi√®me section est <i>Filtre</i> , qui prescrit d'autres actions avec des donn√©es qui n'ont pas encore √©t√© structur√©es.  Dans mon exemple, les messages syslog inutiles d'un routeur avec un certain texte sont supprim√©s.  Cela se fait √† l'aide de la condition et de l'action de <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-drop.html" rel="nofollow"><i>suppression</i></a> standard, qui supprime l'int√©gralit√© du message si la condition est remplie.  Dans la <a href="https://www.elastic.co/guide/en/logstash/7.5/event-dependent-configuration.html" rel="nofollow">condition</a> , le champ de <i>message</i> est v√©rifi√© pour la pr√©sence de certains textes. <br><br><img src="https://habrastorage.org/webt/iq/j0/ut/iqj0utufb6itcsrwspxi9qw4e2c.png"><br><br>  Si le message ne tombe pas, il descend plus bas dans la cha√Æne et entre dans le filtre <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-grok.html" rel="nofollow"><i>grok</i></a> .  Comme le dit la documentation, <i>grok est un excellent moyen d'analyser les donn√©es de journal non structur√©es en quelque chose de structur√© et interrogeable</i> .  Ce filtre est utilis√© pour traiter les journaux de diff√©rents syst√®mes (linux syslog, serveur Web, base de donn√©es, p√©riph√©riques r√©seau, etc.).  Sur la <a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns" rel="nofollow">base de mod√®les pr√™ts</a> √† l' <a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns" rel="nofollow">emploi,</a> vous pouvez, sans passer beaucoup de temps, cr√©er un analyseur pour une s√©quence plus ou moins r√©p√©titive.  Il est pratique d'utiliser un <a href="http://grokdebug.herokuapp.com/" rel="nofollow">analyseur en ligne</a> pour la validation (dans la derni√®re version de Kibana, des fonctionnalit√©s similaires se trouvent dans la section <i>Dev Tools</i> ). <br><br><img src="https://habrastorage.org/webt/_g/9q/ky/_g9qkyst3-na7a2i8mhxwf8avw0.gif"><br><br>  Le volume <i>"./logstash/patterns:/usr/share/logstash/patterns" est</i> enregistr√© dans <i>docker-compose.yml</i> <i>,</i> dans le r√©pertoire <i>patterns</i> il y a un fichier avec des mod√®les de communaut√© standard (juste pour plus de commodit√©, voir si j'ai oubli√©), ainsi qu'un fichier avec mod√®les de plusieurs types de messages Mikrotik (modules <i>Firewall</i> et <i>Auth)</i> , par analogie, vous pouvez ajouter vos propres mod√®les pour les messages d'une structure diff√©rente. <br><br>  Les options standard <i>add_field</i> et <i>remove_field</i> vous permettent d'ajouter ou de supprimer des champs du message en cours de traitement dans n'importe quel filtre.  Dans ce cas, le champ <i>h√¥te</i> est supprim√©, qui contient le nom d'h√¥te √† partir duquel le message a √©t√© re√ßu.  Dans mon exemple, il n'y a qu'un seul h√¥te, il n'y a donc aucun int√©r√™t dans ce domaine. <br><br>  De plus, dans la m√™me section <i>Filtre</i> , j'ai enregistr√© le filtre <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-cidr.html" rel="nofollow"><i>cidr</i></a> , qui v√©rifie le champ avec l'adresse IP pour la conformit√© avec la condition d'entr√©e dans le sous-r√©seau donn√© et place la balise.  Sur la base de la balise de la cha√Æne suivante, des actions seront ex√©cut√©es ou non (si cela est sp√©cifique, afin de ne pas faire de recherche de geoip pour les adresses locales √† l'avenir). <br><br>  Il peut y avoir un certain nombre de sections de <i>filtre</i> , de sorte qu'il y ait moins de conditions dans une section, dans la nouvelle section j'ai d√©fini des actions pour les messages sans la balise <i>src_local</i> , c'est-√†-dire que les √©v√©nements de pare-feu sont trait√©s ici dans lesquels nous sommes int√©ress√©s par l'adresse source. <br><br>  Maintenant, nous devons parler un peu plus d'o√π Logstash obtient les informations GeoIP.  Logstash prend en charge les bases de donn√©es GeoLite2.  Il existe plusieurs options de base de donn√©es, j'utilise deux bases de donn√©es: GeoLite2 City (qui contient des informations sur le pays, la ville, le fuseau horaire) et GeoLite2 ASN (informations sur le syst√®me autonome auquel appartient l'adresse IP). <br><br><img src="https://habrastorage.org/webt/gf/ps/a1/gfpsa18cwgwa-7bcadoca7qyhtk.png"><br><br>  Le plugin <a href="https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-geoip.html" rel="nofollow"><i>geoip</i></a> est √©galement impliqu√© dans l'ajout d'informations GeoIP au message.  √Ä partir des param√®tres, vous devez sp√©cifier le champ qui contient l'adresse IP, la base utilis√©e et le nom du nouveau champ dans lequel les informations seront √©crites.  Dans mon exemple, la m√™me chose se fait pour l'adresse IP de destination, mais jusqu'√† pr√©sent dans ce sc√©nario simple, ces informations ne seront pas int√©ressantes, car l'adresse de destination sera toujours l'adresse du routeur.  Cependant, √† l'avenir, il sera possible d'ajouter des journaux √† ce pipeline non seulement √† partir du pare-feu, mais √©galement √† partir d'autres syst√®mes o√π il sera pertinent d'examiner les deux adresses. <br><br>  Le filtre <a href="https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-mutate.html" rel="nofollow"><i>mutate</i></a> vous permet de changer les champs de message et de modifier le texte dans les champs lui-m√™me; la documentation d√©crit en d√©tail de nombreux exemples de ce que vous pouvez faire.  Dans ce cas, il est utilis√© pour ajouter une balise, renommer des champs (pour une visualisation plus approfondie des journaux dans Kibana, un certain format de l'objet <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.3/geo-point.html" rel="nofollow"><i>g√©o-point</i></a> est requis, je reviendrai sur ce sujet) et supprimer les champs inutiles. <br><br><img src="https://habrastorage.org/webt/kn/9l/qf/kn9lqfj3uwaqh0fhh-tir-f7zr4.png"><br><br>  Cela met fin √† la section de traitement des donn√©es et ne peut qu'indiquer o√π envoyer un message structur√©.  Dans ce cas, Elasticsearch collectera des donn√©es, il vous suffit de saisir l'adresse IP, le port et le nom d'index.  Il est recommand√© de saisir l'index avec un champ de date variable afin qu'un nouvel index soit cr√©√© chaque jour. <br><br><img src="https://habrastorage.org/webt/ve/sk/ec/veskecc3kqsidcymnbkafoa3spo.png"><br><br><h3>  Configuration d'Elasticsearch </h3><br>  Retour √† Elasticsearch.  Vous devez d'abord vous assurer que le serveur est op√©rationnel.  Elastic est le plus efficacement interagi avec l'API Rest dans la CLI.  En utilisant curl, vous pouvez voir l'√©tat du n≈ìud (remplacez localhost par l'adresse IP du docker h√¥te): <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl localhost:9200</code> </pre> <br>  Ensuite, vous pouvez essayer d'ouvrir Kibana √† <a href="http://localhost:5601/" rel="nofollow"></a>  <a href="http://localhost/" rel="nofollow"><i>localhost</i></a> : 5601.  Il n'est pas n√©cessaire de configurer quoi que ce soit dans l'interface Web de Kibana (√† moins de changer le th√®me en sombre).  Nous souhaitons savoir si un index a √©t√© cr√©√©. Pour ce faire, ouvrez la section <i>Gestion</i> et s√©lectionnez <i>Elasticsearch Index Management</i> en haut √† gauche.  Ici, vous pouvez voir combien de documents sont index√©s, combien cela prend d'espace disque, vous pouvez √©galement consulter des informations sur le mappage d'index √† partir d'informations utiles. <br><br><img src="https://habrastorage.org/webt/kl/yp/vv/klypvvi1aa2zlueq98960wdut90.png"><br><br>  √Ä ce moment, vous devez enregistrer le mod√®le de mappage correct.  Ces informations sont n√©cessaires pour Elastic afin qu'il comprenne √† quels types de donn√©es quels champs appartiennent.  Par exemple, pour effectuer des s√©lections sp√©ciales en fonction des adresses IP, pour le champ <i>src_ip</i> , <i>vous</i> devez sp√©cifier explicitement le type de donn√©es <i>ip</i> et pour d√©terminer l'emplacement g√©ographique, vous devez d√©finir le champ <i>geoip.location</i> dans un format sp√©cifique et enregistrer le type <i>geo_point</i> .  Tous les champs possibles n'ont pas besoin d'√™tre d√©crits, car pour les nouveaux champs, le type de donn√©es est d√©termin√© automatiquement en fonction de mod√®les dynamiques ( <i>long</i> pour les nombres et <i>mot</i> - <i>cl√©</i> pour les cha√Ænes). <br><br>  Vous pouvez √©crire un nouveau mod√®le soit en utilisant curl, soit directement depuis la console Kibana (section <i>Dev Tools</i> ). <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl -X POST -H "Content-Type: application/json" -d @elasticsearch/logstash_mikrot-template.json http://192.168.88.130:9200/_template/logstash-mikrot</code> </pre> <br>  Apr√®s avoir modifi√© le mappage, vous devez supprimer l'index: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl -X DELETE http://192.168.88.130:9200/logstash-mikrot-2019.12.16</code> </pre> <br>  Lorsqu'au moins un message arrive dans l'index, v√©rifiez le mappage: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl http://192.168.88.130:9200/logstash-mikrot-2019.12.16/_mapping</code> </pre> <br>  Pour une utilisation ult√©rieure des donn√©es dans Kibana, vous devez cr√©er un <i>mod√®le</i> dans <i>Gestion&gt; Mod√®le d'index Kibana</i> .  Saisissez le <i>nom de</i> l' <i>index</i> avec le symbole * ( <i>logstash-mikrot *)</i> pour que tous les indices correspondent, s√©lectionnez le champ d' <i>horodatage</i> comme champ avec la date et l'heure.  Dans le champ <i>ID de mod√®le d'index personnalis√©</i> , vous pouvez entrer l'ID de mod√®le (par exemple, <i>logstash-mikrot</i> ), √† l'avenir, cela peut simplifier l'acc√®s √† l'objet. <br><br><h2>  Analyse et visualisation des donn√©es dans Kibana </h2><br>  Une fois que vous avez cr√©√© le <i>mod√®le d'index</i> , vous pouvez passer √† la partie la plus int√©ressante - l'analyse et la visualisation des donn√©es.  Kibana a beaucoup de fonctionnalit√©s et de sections, mais jusqu'√† pr√©sent, nous ne serons int√©ress√©s que par deux. <br><br><h3>  D√©couvrir </h3><br>  Ici, vous pouvez afficher des documents dans des index, filtrer, rechercher et afficher les informations re√ßues.  Il est important de ne pas oublier la chronologie, qui d√©finit le d√©lai dans les conditions de recherche. <br><br><img src="https://habrastorage.org/webt/vk/wn/ta/vkwntasygmykelzligkpf3flsxu.gif"><br><br><h3>  Visualisez </h3><br>  Dans cette section, vous pouvez cr√©er une visualisation bas√©e sur les donn√©es collect√©es.  Le plus simple est d'afficher les sources de balayage des r√©seaux de zombies sur une carte g√©ographique, soit en pointill√©s, soit sous forme de carte thermique.  Il existe √©galement de nombreuses fa√ßons de cr√©er des graphiques, d'effectuer des s√©lections, etc. <br><br><img src="https://habrastorage.org/webt/f_/rx/p2/f_rxp2xbq4necn0dcsyw2mxkfuy.gif"><br><br>  √Ä l'avenir, je pr√©vois de parler plus en d√©tail du traitement des donn√©es, √©ventuellement de la visualisation, peut-√™tre d'autre chose d'int√©ressant.  En cours d'√©tude, je vais essayer de compl√©ter le tutoriel. <br><br><h2>  D√©pannage </h2><br>  Si l'index n'appara√Æt pas dans Elasticsearch, vous devez d'abord consulter les journaux Logstash: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker logs logstash --tail 100 -f</code> </pre> <br>  Logstash ne fonctionnera pas s'il n'y a pas de connectivit√© avec Elasticsearch, ou une erreur dans la configuration du pipeline est la principale raison et cela devient clair apr√®s une √©tude minutieuse des journaux √©crits par d√©faut dans json docker. <br><br>  S'il n'y a aucune erreur dans le journal, vous devez vous assurer que Logstash intercepte les messages sur son socket configur√©.  √Ä des fins de d√©bogage, vous pouvez utiliser <i>stdout</i> en <i>sortie</i> : <br><br><pre> <code class="plaintext hljs">stdout { codec =&gt; rubydebug }</code> </pre> <br>  Apr√®s cela, Logstash √©crira des informations de d√©bogage lorsque le message sera re√ßu directement dans le journal. <br><br>  La v√©rification d'Elasticsearch est tr√®s simple - il suffit de faire une boucle de demande GET sur l'adresse IP et le port du serveur, ou sur un point de terminaison API sp√©cifique.  Par exemple, regardez l'√©tat des index dans une table lisible par l'homme: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ curl -s 'http://192.168.88.130:9200/_cat/indices?v'</code> </pre> <br><img src="https://habrastorage.org/webt/of/ke/v_/ofkev_rfp6uo9x5rf4tcey0egbm.gif"><br><br>  Kibana ne d√©marre pas non plus s'il n'y a pas de connexion √† Elasticsearch, il est facile de voir cela dans les journaux. <br><br>  Si l'interface Web ne s'ouvre pas, vous devez vous assurer que le pare-feu est correctement configur√© ou d√©sactiv√© sous Linux (dans Centos, il y avait des probl√®mes avec <i>iptables</i> et <i>docker</i> , ils ont √©t√© r√©solus sur les conseils de la <a href="https://stackoverflow.com/questions/31667160/running-docker-container-iptables-no-chain-target-match-by-that-name" rel="nofollow">rubrique</a> ).  Il convient √©galement de consid√©rer que sur des √©quipements peu productifs, tous les composants peuvent se charger pendant plusieurs minutes.  Avec un manque de m√©moire, les services peuvent ne pas se charger du tout.  Afficher l'utilisation des ressources de conteneur: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker stats</code> </pre> <br>  Si soudainement quelqu'un ne sait pas comment modifier correctement la configuration des conteneurs dans le <i>fichier docker-compose.yml</i> et red√©marrer les conteneurs, cela se fait en modifiant <i>docker-compose.yml</i> et en utilisant la m√™me commande avec les m√™mes param√®tres, red√©marre: <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker-compose --compatibility up -d</code> </pre> <br>  Dans le m√™me temps, dans les sections modifi√©es, les anciens objets (conteneurs, r√©seaux, volumes) sont effac√©s et de nouveaux sont recr√©√©s selon la configuration.  Les donn√©es des services ne sont pas perdues en m√™me temps, car des <i>volumes nomm√©s sont utilis√©s</i> , qui ne sont pas supprim√©s avec le conteneur, et les configurations sont mont√©es √† partir du syst√®me h√¥te, Logstash peut m√™me surveiller les fichiers de configuration et red√©marrer la configuration du pipeline lorsque le fichier est modifi√©. <br><br>  Vous pouvez red√©marrer le service s√©par√©ment avec la <i>commande docker restart</i> (il n'est pas n√©cessaire d'√™tre dans le r√©pertoire avec <i>docker-compose.yml)</i> : <br><br><pre> <code class="plaintext hljs">‚ùØ‚ùØ docker restart logstash</code> </pre> <br>  Vous pouvez voir la configuration de l'objet <i>docker</i> avec la <i>commande docker inspect</i> , il est plus pratique de l'utiliser avec <i><a href="https://stedolan.github.io/jq/tutorial/" rel="nofollow">jq</a></i> . <br><br><img src="https://habrastorage.org/webt/vw/l0/-v/vwl0-vgzu8snbp16vgzet9lsa64.gif"><br><br><h2>  Conclusion </h2><br>  Je tiens √† noter que la s√©curit√© de ce projet n'a pas √©t√© signal√©e car il s'agit d'un environnement de test (dev) et il n'est pas pr√©vu de le sortir en dehors du routeur.  Si vous le d√©ployez pour une utilisation plus s√©rieuse, vous devez suivre les meilleures pratiques, installer des certificats pour HTTPS, effectuer des sauvegardes, une surveillance normale (qui ne d√©marre pas √† c√¥t√© du syst√®me principal).  Soit dit en passant, Traefik s'ex√©cute dans mon docker sur mon serveur, qui est un proxy inverse pour certains services, et met √©galement fin √† TLS sur lui-m√™me et effectue l'authentification.  Autrement dit, gr√¢ce au DNS configur√© et au proxy inverse, il devient possible d'acc√©der √† l'interface Web de Kibana √† partir d'Internet avec HTTPS non configur√© et un mot de passe (si je comprends bien, dans la version communautaire, Kibana ne prend pas en charge la protection par mot de passe pour l'interface Web).  Je pr√©vois de d√©crire plus en d√©tail mon exp√©rience dans la configuration de Traefik pour une utilisation sur un r√©seau domestique avec Docker. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr481596/">https://habr.com/ru/post/fr481596/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr481584/index.html">Lorsque vous g√©rez une √©quipe, brisez toutes les r√®gles</a></li>
<li><a href="../fr481586/index.html">Tendances Tech Ecommerce 2020: l'√®re des technologies immersives</a></li>
<li><a href="../fr481588/index.html">Les exercices pour isoler Runet ont commenc√©. Allons-nous surveiller?</a></li>
<li><a href="../fr481592/index.html">Six options de cadeaux du Nouvel An pour un automobiliste avec une bonne remise</a></li>
<li><a href="../fr481594/index.html">D√©veloppement d'un ¬´g√©n√©rateur de tension simple¬ª selon GOST R IEC 61508 (IEC 61508)</a></li>
<li><a href="../fr481598/index.html">Une petite contribution √† la lutte contre les plateformes de zoo Avalonia UI</a></li>
<li><a href="../fr481600/index.html">Moteur Wiki Bonsai Family: R√©sultats 2019</a></li>
<li><a href="../fr481604/index.html">Comment les d√©veloppeurs de Chelyabinsk durs cr√©ent des jeux pour Google Play et les r√©seaux sociaux</a></li>
<li><a href="../fr481606/index.html">Abonnement statique √† l'aide du mod√®le Observer √† l'aide de C ++ et du microcontr√¥leur Cortex M4</a></li>
<li><a href="../fr481610/index.html">PostgreSQL Antipatterns: mise √† jour d'une grande table en charge</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
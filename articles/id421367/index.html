<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👻 ⬇️ 🐲 AI, tentu saja praktis. Menyiapkan model dan hiperparameter untuk mengenali emosi dalam gambar 🙏🏽 👎🏼 👎🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam artikel sebelumnya dari seri tutorial ini, opsi yang mungkin untuk mempersiapkan data dijelaskan. Pra-pemrosesan dan penambahan data dengan gamb...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, tentu saja praktis. Menyiapkan model dan hiperparameter untuk mengenali emosi dalam gambar</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/421367/"><img src="https://habrastorage.org/webt/zq/7s/el/zq7selxswjsrmplg_pxw2xilqi4.jpeg"><br><br>  Dalam artikel sebelumnya dari seri tutorial ini, opsi yang mungkin untuk mempersiapkan data dijelaskan. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pra-pemrosesan dan penambahan data dengan gambar</a> , dalam artikel ini, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model Base untuk mengenali emosi</a> berdasarkan gambar dari jaringan saraf convolutional juga dibangun. <br>  Dalam artikel ini, kita akan membangun model jaringan saraf convolutional yang lebih baik untuk mengenali emosi dalam gambar menggunakan teknik yang disebut <i>pembelajaran induktif</i> . <br><a name="habracut"></a><br>  Pertama, Anda perlu membiasakan diri dengan artikel tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Model Dasar untuk Mengenali Emosi dalam Gambar</a> , dan Anda juga dapat merujuknya saat membaca, karena beberapa bagian, termasuk mempelajari sumber data dan menggambarkan indikator jaringan, tidak akan diberikan secara rinci di sini. <br><br><h2>  <font color="#0071c5">Data</font> </h2><br>  Kumpulan data berisi 1630 gambar dengan emosi dua kelas: <i>Negatif</i> (kelas 0) dan <i>Positif</i> (kelas 1).  Beberapa contoh gambar tersebut diberikan di bawah ini. <br><br>  <b>Negatif</b> <br><img src="https://habrastorage.org/webt/zr/pf/ki/zrpfkiqvgcxw6kpsv777v9d1t6w.jpeg"><br><br><img src="https://habrastorage.org/webt/52/8x/s6/528xs6k7jnimfgvhagwolru8mi4.jpeg"><br><br><img src="https://habrastorage.org/webt/no/p0/vb/nop0vbapr4ep7o5dps1wvpkncoa.jpeg"><br><br>  <b>Positif</b> <br><img src="https://habrastorage.org/webt/uc/ua/oh/ucuaohklcwcgotqf4uryopnt_qg.jpeg"><br><br><img src="https://habrastorage.org/webt/u5/hp/rb/u5hprb1cjig28b4xk8urdljb8lm.jpeg"><br><br><img src="https://habrastorage.org/webt/ru/_a/xo/ru_axoahw4h4xytx_-yphxk56ii.jpeg"><br><br>  Beberapa contoh mengandung emosi positif atau negatif yang jelas, sementara yang lain mungkin tidak dikategorikan - bahkan dengan keterlibatan manusia.  Berdasarkan inspeksi visual dari kasus-kasus tersebut, kami memperkirakan bahwa keakuratan maksimum yang mungkin harus sekitar 80 persen.  Perhatikan bahwa classifier acak memberikan akurasi sekitar 53 persen karena ketidakseimbangan kecil di kelas. <br><br>  Untuk melatih model, kami menggunakan teknik <i>mempertahankan bagian sampel</i> dan membagi set data awal menjadi dua bagian, yang salah satunya (20 persen dari set awal) akan digunakan oleh kami untuk verifikasi.  Partisi dilakukan dengan menggunakan <i>stratifikasi</i> : ini berarti keseimbangan antar kelas dipertahankan dalam set pelatihan dan tes. <br><br><h2>  <font color="#0071c5">Mengatasi Ketidakcukupan Data</font> </h2><br>  Model dasar menunjukkan hasil, hanya sedikit lebih baik daripada prediksi acak dari kelas gambar.  Mungkin ada banyak alasan yang memungkinkan untuk perilaku ini.  Kami percaya bahwa alasan utama adalah bahwa jumlah data yang tersedia jelas tidak cukup untuk pelatihan seperti bagian konvolusional dari jaringan yang akan memungkinkan memperoleh fitur karakteristik berdasarkan gambar input. <br>  Ada banyak cara berbeda untuk menyelesaikan masalah kekurangan data.  Berikut ini beberapa di antaranya: <br><br><ul><li>  <b>Ambil kembali</b> .  Gagasan metode ini adalah untuk mengevaluasi distribusi data dan memilih <i>contoh-contoh baru</i> dari distribusi ini. </li><li>  <b>Belajar tanpa guru</b> .  Setiap orang dapat menemukan sejumlah besar data dengan sifat yang sama seperti contoh yang ditandai dalam dataset yang diberikan.  Misalnya, bisa berupa film untuk pengenalan video atau buku audio untuk pengenalan suara.  Langkah selanjutnya adalah menggunakan data ini untuk pra-pelatihan model (misalnya, menggunakan auto-encoders). </li><li>  <b>Augmentasi Data</b> .  Selama proses ini, data sampel dimodifikasi secara acak menggunakan serangkaian transformasi yang diberikan. </li><li>  <b>Pembelajaran Induktif</b> .  Topik ini sangat menarik bagi kami, jadi mari kita kenali lebih detail. </li></ul><br><h2>  <font color="#0071c5">Pembelajaran Induktif</font> </h2><br>  Istilah <i>pelatihan induktif</i> mengacu pada serangkaian teknik yang menggunakan model (seringkali sangat besar) yang dilatih tentang kumpulan data yang berbeda yang sifatnya hampir sama. <br><br><img src="https://habrastorage.org/webt/wl/jb/qi/wljbqidbfmpj1yfddtvjlkqt9ma.png"><br><br><img src="https://habrastorage.org/webt/bq/ji/ah/bqjiahabshkakrv2jcilp5pa1y8.png"><br><br>  Perbandingan pembelajaran mesin tradisional dan metode pembelajaran induktif.  Gambar diambil dari entri blog S. Ruder <i>"Apa itu pembelajaran induktif?"</i>  . <br>  Ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tiga</a> skenario utama untuk menggunakan pembelajaran induktif: <br><br><ul><li>  <b>Model pra-terlatih</b> .  Setiap pengguna dapat dengan mudah mengambil model yang dilatih oleh orang lain dan menggunakannya untuk tugas mereka.  Skenario seperti itu dimungkinkan jika tugasnya sangat mirip. </li><li>  <b>Memblokir pemilihan tanda</b> .  Pada titik ini, kita tahu bahwa arsitektur model dapat dibagi menjadi dua bagian utama: <i>unit ekstraksi fitur</i> , yang bertanggung jawab untuk mengekstraksi fitur dari data input, dan <i>modul klasifikasi</i> , yang mengklasifikasikan contoh berdasarkan fitur yang diterima.  Biasanya, blok ekstraksi fitur adalah bagian utama dari model.  Gagasan metode ini adalah untuk mengambil blok untuk membedakan fitur dari model yang dilatih dalam masalah lain, memperbaiki koefisien bobotnya (membuat mereka tidak terlatih), dan kemudian membangun berdasarkan modul klasifikasi baru untuk masalah yang sedang dipertimbangkan.  Modul klasifikasi biasanya tidak terlalu dalam dan terdiri dari beberapa lapisan yang terhubung sepenuhnya, sehingga model ini lebih mudah untuk dilatih. </li><li>  <b>Penyesuaian yang tepat dan dalam</b> .  Metode ini seperti skenario menggunakan blok ekstraksi fitur.  Tindakan yang sama dilakukan dengan pengecualian "membekukan" blok ekstraksi fitur.  Misalnya, Anda dapat menggunakan jaringan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VGG</a> sebagai blok ekstraksi fitur dan "membekukan" di dalamnya hanya tiga (dari empat) blok konvolusional pertama.  Dalam hal ini, unit ekstraksi fitur dapat lebih beradaptasi dengan tugas saat ini.  Untuk informasi lebih lanjut, lihat posting blog F. Chollet.Buat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model klasifikasi gambar yang kuat menggunakan data yang sangat sedikit</a> . </li></ul><br>  Penjelasan terperinci dari skenario untuk menggunakan pembelajaran induktif dapat ditemukan dalam kursus Stanford University <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CS231n jaringan saraf konvolusional untuk pengakuan visual</a> oleh Fei-Fei Li dan entri blog oleh S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pembelajaran induktif adalah batas berikutnya dalam pengembangan pembelajaran mesin</a> (topik dibahas lebih komprehensif). <br><br>  Anda mungkin memiliki pertanyaan: mengapa semua metode ini diperlukan dan mengapa mereka bisa bekerja?  Kami akan mencoba menjawabnya. <br><br><ul><li>  Manfaat menggunakan dataset besar.  Misalnya, kita dapat mengambil blok ekstraksi fitur dari model yang dilatih pada 14 juta gambar yang terkandung dalam dataset kontes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ImageNet</a> .  Model-model ini cukup kompleks untuk memungkinkan <i>ekstraksi fitur berkualitas sangat tinggi</i> dari data input. </li><li>  Pertimbangan terkait waktu.  Pelatihan model besar dapat memakan waktu berminggu-minggu atau bahkan berbulan-bulan.  Dalam hal ini, setiap orang dapat <i>menghemat banyak waktu dan sumber daya komputasi</i> . </li><li>  Asumsi berbobot yang mendasari mengapa semua ini bisa bekerja adalah sebagai berikut: Atribut yang diperoleh dari pelatihan dalam satu tugas dapat berguna dan cocok untuk tugas lain.  Dengan kata lain, fitur memiliki properti invarian sehubungan dengan masalah tersebut.  Perhatikan bahwa <i>domain</i> tugas baru harus serupa dengan domain tugas asli.  Jika tidak, unit ekstraksi fitur bahkan dapat memperburuk hasilnya. </li></ul><br><h2>  <font color="#0071c5">Arsitektur Model yang Ditingkatkan</font> </h2><br>  Sekarang kita akrab dengan konsep pembelajaran induktif.  Kita juga tahu bahwa ImageNet adalah peristiwa besar, di mana hampir semua arsitektur jaringan saraf convolutional canggih modern diuji.  Mari kita coba untuk mengambil blok ekstraksi fitur dari salah satu jaringan ini. <br><br>  Untungnya, perpustakaan Keras memberi kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">beberapa</a> model pra-terlatih (melalui ImageNet) yang dibuat di dalam platform ini.  Kami mengimpor dan menggunakan salah satu model ini. <br><br><img src="https://habrastorage.org/webt/jz/3t/ry/jz3trysk11d88hbmbxvlnoungxy.png"><br><br>  Dalam hal ini, kami akan menggunakan jaringan dengan arsitektur VGG.  Untuk memilih hanya unit ekstraksi fitur, kami menghapus modul klasifikasi (tiga lapisan teratas yang sepenuhnya terhubung) dari jaringan dengan mengatur parameter <i>include_top</i> ke <i>False</i> .  Kami juga ingin menginisialisasi jaringan kami menggunakan bobot jaringan yang dilatih di ImageNet.  Parameter terakhir adalah ukuran input. <br><br>  Harap perhatikan bahwa ukuran gambar asli dalam kontes ImageNet adalah (224, 224, 3), sedangkan gambar kami berukuran (400, 500, 3).  Namun, kami menggunakan lapisan konvolusional - ini berarti bahwa bobot jaringan adalah bobot dari kernel yang bergerak dalam operasi konvolusi.  Bersama-sama dengan properti pemisahan parameter (diskusi tentang ini ditemukan dalam artikel teoritis kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tinjauan umum jaringan saraf convolutional untuk mengklasifikasikan gambar</a> ), ini mengarah pada fakta bahwa ukuran data input dapat hampir sewenang-wenang, karena konvolusi dilakukan dengan menggunakan jendela geser, dan jendela ini dapat meluncur bersama gambar dari berbagai ukuran.  Satu-satunya batasan adalah bahwa ukuran data input harus cukup besar sehingga tidak runtuh ke satu titik (pengukuran spasial) di beberapa lapisan menengah, karena jika tidak maka tidak mungkin untuk membuat perhitungan lebih lanjut. <br><br>  Trik lain yang kami gunakan adalah <i>caching</i> .  VGG adalah jaringan yang sangat besar.  Satu operan langsung untuk semua gambar (1630 contoh) melalui unit ekstraksi fitur membutuhkan waktu sekitar 50 detik.  Namun, harus diingat bahwa bobot unit ekstraksi fitur adalah tetap, dan umpan langsung selalu memberikan hasil yang sama untuk gambar yang sama.  Kita dapat menggunakan fakta ini untuk melakukan operan langsung melalui unit ekstraksi fitur hanya <i>sekali</i> dan kemudian men-cache hasil dalam array perantara.  Untuk menerapkan skenario ini, pertama-tama kita membuat instance kelas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ImageDataGenerator</a> untuk memuat file dari hard drive secara langsung (untuk informasi lebih lanjut, lihat artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dasar Model dasar untuk mengenali emosi dalam gambar</a> ). <br><br><img src="https://habrastorage.org/webt/o-/wo/7h/o-wo7hel-_kgurcvwcs2v2smecc.png"><br><br>  Pada tahap berikutnya, kami menggunakan dalam mode prediksi blok ekstraksi fitur yang dibuat sebelumnya sebagai bagian dari model untuk mendapatkan fitur gambar. <br><br><img src="https://habrastorage.org/webt/gl/no/p7/glnop717aagtytzitgpdtbl_11c.png"><br><br>  Dibutuhkan sekitar 50 detik.  Sekarang kita dapat menggunakan hasilnya untuk pelatihan yang sangat cepat dari bagian klasifikasi model - satu era berlangsung sekitar 1 detik untuk kita.  Bayangkan sekarang bahwa setiap era berlangsung 50 detik lebih lama.  Dengan demikian, teknik caching sederhana ini memungkinkan kami untuk mempercepat proses pelatihan jaringan sebanyak 50 kali!  Dalam skenario ini, kami menyimpan semua tanda untuk semua contoh dalam RAM, karena volumenya cukup untuk ini.  Saat menggunakan kumpulan data yang lebih besar, Anda dapat menghitung properti, menulisnya ke hard drive, dan kemudian membacanya menggunakan pendekatan yang sama yang terkait dengan kelas generator. <br><br>  Akhirnya, pertimbangkan arsitektur bagian klasifikasi model: <br><br><img src="https://habrastorage.org/webt/6x/hq/qb/6xhqqbgjol6dfxyn47rufbuc_ag.png"><br><br><img src="https://habrastorage.org/webt/ss/4v/3t/ss4v3to-rinafik2lthu5ecszt8.png"><br><br>  Ingat bahwa pada output blok ekstraksi fitur jaringan saraf convolutional, tensor empat dimensi (contoh, tinggi, lebar dan saluran) dikeluarkan, dan lapisan yang terhubung penuh untuk klasifikasi memerlukan tensor dua dimensi (contoh, fitur).  Salah satu cara untuk mengubah tensor empat dimensi dengan fitur adalah dengan menyelaraskannya di sekitar tiga sumbu terakhir (kami menggunakan teknik serupa dalam model dasar).  Dalam skenario ini, kami menggunakan pendekatan yang berbeda, yang disebut <i>global mean value sub</i> - <i>sampling</i> (GAP).  Alih-alih menyelaraskan vektor empat dimensi, kita akan mengambil nilai rata-rata berdasarkan dua dimensi spasial.  Faktanya, kami mengambil peta atribut dan rata-rata semua nilai di dalamnya.  Metode GAP pertama kali diperkenalkan dalam karya luar biasa dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Jaringan</a> Min Lin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di Internet</a> (buku ini benar-benar layak untuk dikenali karena membahas beberapa konsep penting - misalnya, konvolusi 1 × 1).  Satu keuntungan nyata dari pendekatan GAP adalah pengurangan signifikan dalam jumlah parameter.  Dengan menggunakan GAP, kami hanya mendapatkan 512 fitur untuk setiap contoh, sementara menyelaraskan data mentah, jumlah fitur akan menjadi 15 × 12 × 512 = 92 160. Ini dapat menyebabkan overhead yang serius, karena dalam kasus ini bagian klasifikasi model akan memiliki sekitar 50 juta parameter!  Elemen lain dari bagian klasifikasi model, seperti lapisan dan lapisan yang terhubung penuh yang menerapkan metode pengecualian, dibahas secara rinci dalam artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Model dasar untuk mengenali emosi dalam gambar</a> . <br><br><h2>  <font color="#0071c5">Opsi pengaturan dan pelatihan</font> </h2><br>  Setelah kami menyiapkan arsitektur model kami menggunakan Keras, Anda perlu mengonfigurasi seluruh model untuk pelatihan menggunakan metode kompilasi. <br><br><img src="https://habrastorage.org/webt/dl/x5/by/dlx5byabpmih_ocdviw_8ngvatw.png"><br><br>  Dalam hal ini, kami menggunakan pengaturan yang hampir mirip dengan pengaturan model dasar, dengan pengecualian pilihan pengoptimal.  Untuk mengoptimalkan pembelajaran, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">binary cross-entropy</a> akan digunakan sebagai fungsi kerugian, dan metrik akurasi akan dilacak tambahan.  Kami menggunakan metode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Adam</a> sebagai pengoptimal.  Adam adalah jenis algoritma penurunan gradien stokastik dengan momen dan <i>kecepatan belajar</i> adaptif (untuk informasi lebih lanjut lihat entri blog oleh S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Gambaran umum algoritma optimasi penurunan gradien</a> ). <br><br>  Kecepatan belajar adalah hyperparameter pengoptimal yang harus dikonfigurasi untuk memastikan model operasional.  Ingat bagaimana rumus untuk penurunan gradien "vanilla" tidak mengandung fungsionalitas tambahan: <br><br><img src="https://habrastorage.org/webt/qy/iu/ny/qyiunyjwn2bjmvzkkd_jg5050ay.png"><br><br>  Θ adalah vektor parameter model (dalam kasus kami, ini adalah koefisien bobot dari jaringan saraf), - adalah fungsi objektif, ∇ adalah operator gradien (dihitung menggunakan algoritma propagasi kesalahan kembali), dan α adalah kecepatan belajar.  Dengan demikian, gradien fungsi objektif mewakili arah langkah optimasi dalam ruang parameter, dan kecepatan belajar adalah ukurannya.  Ketika menggunakan kecepatan belajar yang terlalu tinggi, ada kemungkinan tergelincirnya titik optimal secara konstan karena ukuran langkah yang terlalu besar.  Di sisi lain, jika kecepatan belajar terlalu rendah, maka optimasi akan memakan waktu terlalu banyak dan dapat memastikan konvergensi hanya untuk minimum lokal berkualitas rendah daripada ekstrem global.  Oleh karena itu, dalam setiap situasi tertentu, perlu untuk mencari kompromi yang sesuai.  Menggunakan pengaturan default untuk algoritma Adam adalah titik awal yang baik untuk memulai. <br><br>  Namun, dalam tugas ini, pengaturan Adam default menunjukkan hasil yang buruk.  Kita perlu mengurangi tingkat pembelajaran awal menjadi 0,0001.  Kalau tidak, pelatihan tidak akan bisa memastikan konvergensi. <br><br>  Pada akhirnya, kita dapat mulai belajar lebih dari 100 era dan kemudian menyimpan model itu sendiri dan sejarah pembelajaran.  Perintah <i>% time</i> adalah perintah sihir Ipython * yang memungkinkan Anda untuk mengukur waktu eksekusi kode. <br><br><img src="https://habrastorage.org/webt/tp/qr/h3/tpqrh3zk0u7oxnxg77cbsmigxc8.png"><br><br><h2>  <font color="#0071c5">Peringkat</font> </h2><br><br><img src="https://habrastorage.org/webt/ij/w6/a-/ijw6a-rdyl9fd5rhlsuybmu24vm.png"><br><br>  Mari kita evaluasi keefektifan model selama pelatihan.  Dalam kasus kami, akurasi verifikasi adalah 73 persen (dibandingkan dengan 55 persen menggunakan model dasar).  Hasil ini jauh lebih baik daripada hasil model dasar. <br><br>  Mari kita juga melihat distribusi kesalahan menggunakan matriks ketidakakuratan.  Kesalahan didistribusikan hampir merata antara kelas-kelas dengan sedikit bias terhadap contoh negatif yang salah diklasifikasikan (sel kiri atas matriks ketidakakuratan).  Hal ini dapat dijelaskan dengan <i>ketidakseimbangan kecil dalam kumpulan data</i> menuju kelas positif. <br><br>  Metrik lain yang kami lacak adalah kurva kinerja penerima (kurva ROC) dan area di bawah kurva ini (AUC).  Untuk deskripsi terperinci tentang metrik ini, lihat artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Model dasar untuk mengenali emosi dalam gambar</a> . <br><br><img src="https://habrastorage.org/webt/if/lx/cf/iflxcf-2pxzdcuicg8im4us-9yg.png"><br><br>  Semakin dekat kurva ROC ke titik kiri atas grafik dan semakin besar area di bawahnya (metrik AUC), semakin baik classifier bekerja.  Gambar ini jelas menunjukkan bahwa model yang ditingkatkan dan pra-pelatihan menunjukkan hasil yang lebih baik dibandingkan dengan model dasar yang dibuat dari awal.  Nilai AUC untuk model pra-terlatih adalah 0,82, yang merupakan hasil yang baik. <br><br><img src="https://habrastorage.org/webt/7o/dy/hu/7odyhuvi5j09ajzquknecv_ch2s.png"><br><br><h2>  <font color="#0071c5">Kesimpulan</font> </h2><br>  Pada artikel ini, kami bertemu dengan teknik yang kuat - pembelajaran induktif.  Kami juga membangun sebuah pengklasifikasi jaringan saraf convolutional menggunakan unit ekstraksi fitur pra-dilatih berdasarkan arsitektur VGG.  Klasifikasi ini melampaui karakteristik kinerjanya model konvolusional dasar, dilatih dari awal.  Peningkatan akurasi adalah 18 persen, dan peningkatan metrik AUC adalah 0,25, yang menunjukkan peningkatan kualitas sistem yang sangat signifikan. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id421367/">https://habr.com/ru/post/id421367/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id421355/index.html">Go 1.11 Diluncurkan - Modul WebAssembly dan Asli</a></li>
<li><a href="../id421357/index.html">Untuk pertanyaan yang tidak mungkin. Bagian 3</a></li>
<li><a href="../id421359/index.html">Festival itu seperti permainan. Taksonomi orang TI</a></li>
<li><a href="../id421361/index.html">AMD telah membuka kode sumber untuk V-EZ, sebuah lintas-platform, shell Vulkan level rendah</a></li>
<li><a href="../id421365/index.html">Evolusi satu startup. Agile dari Yaytselov ke Chiken Invaders</a></li>
<li><a href="../id421369/index.html">Apa yang sebenarnya dilakukan oleh trainee di ABBYY</a></li>
<li><a href="../id421371/index.html">Jarum tak terlihat: para ilmuwan telah mengembangkan cara untuk menutupi nanosensor untuk optik dan biomedis</a></li>
<li><a href="../id421373/index.html">Python membuat pemrograman tersedia untuk khalayak luas</a></li>
<li><a href="../id421375/index.html">Bagaimana ketidakpastian membunuh perdagangan</a></li>
<li><a href="../id421377/index.html">7 kesalahpahaman tentang manajer proyek pemula di gamedev</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
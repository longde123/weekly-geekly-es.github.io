<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐒 👈🏿 ⏱️ Programación diferenciable 👩🏻‍🔬 ✋🏼 🌉</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Con cuatro parámetros, puedo preguntarle a un elefante, y con cinco puedo hacer que mueva su trompa. 
 - John Von Neumann 

 La idea de " programación...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Programación diferenciable</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/459562/"><p><img src="https://habrastorage.org/webt/fv/8k/s8/fv8ks8cvj64dyqlstu1vi9znbv8.jpeg"></p><br><blockquote>  Con cuatro parámetros, puedo preguntarle a un elefante, y con cinco puedo hacer que mueva su trompa. <br>  - John Von Neumann </blockquote><p>  La idea de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">programación diferenciable</a> " es muy popular en el mundo del aprendizaje automático.  Para muchos, no está claro si este término refleja un cambio real en la forma en que los investigadores entienden el aprendizaje automático, o es simplemente (otro) cambio de marca del "aprendizaje profundo".  Esta publicación explica qué hay de nuevo en la programación diferenciada (o ∂P) en la tabla de aprendizaje automático. </p><br><p>  Lo más importante, la programación diferenciada es el cambio opuesto a la dirección del aprendizaje profundo;  desde modelos cada vez más parametrizados hasta modelos más simples que utilizan la estructura del problema en mayor medida. </p><br><p>  A continuación, hojeamos un lienzo de texto poco interesante, queremos descubrir qué es la auto diferenciación e incluso poblarla desde una catapulta. </p><a name="habracut"></a><br><h2 id="brute-force-with-benefits">  Fuerza bruta con beneficios </h2><br><p>  La diferenciabilidad es una idea básica que hace que el aprendizaje profundo sea tan exitoso.  Cuando las búsquedas de fuerza bruta, incluso para unos pocos cientos de parámetros del modelo, serían demasiado caras, los gradientes permiten un recorrido pseudoaleatorio de partes interesantes del espacio de parámetros y encuentran un buen conjunto.  Realizando un algoritmo aparentemente tan ingenuo, obtenemos una buena generalidad, pero está lejos de ser obvio que necesitamos diferenciar, por ejemplo, trabajar con secuencias en la traducción de idiomas, pero todo resulta ser simple, mostramos un poco de ingenio. </p><br><p>  ¿Qué pasa con las neuronas biológicas y <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>y</mi><mo>=</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x3C3;</mo></mrow><mo stretchy=&quot;false&quot;>(</mo><mi>W</mi><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>e</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>x</mi><mo>+</mo><mi>b</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="20.966ex" height="2.66ex" viewBox="0 -832 9027 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-79" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-3D" x="775" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-3C3" x="1831" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-28" x="2403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-57" x="2792" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-76" x="4091" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-65" x="4576" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-63" x="5043" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-65" x="5476" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-73" x="5943" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="6412" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-2B" x="7207" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-62" x="8208" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-29" x="8637" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mo>σ</mo></mrow><mo stretchy="false">(</mo><mi>W</mi><mtext>&nbsp;</mtext><mi>v</mi><mi>e</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>x</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> y = σ (W \ veces x + b) </script>  ?  No hay nada especial en esta fórmula;  Este es un ejemplo simple y flexible de una función no lineal altamente paramétrica.  De hecho, esta es probablemente la peor característica en la mayoría de los casos.  Una capa de la red neuronal, en principio, puede clasificar imágenes de gatos, pero solo usando un truco relativamente poco interesante.  <strong>¡Funciona perfectamente!</strong>  - pero la letra pequeña advierte que puede necesitar más parámetros que átomos en el universo.  Para que este trabajo funcione, debe codificar la estructura problemática en el modelo; aquí es donde comienza a parecerse más a la programación tradicional. </p><br><p>  Por ejemplo, las <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">ConvNets</a></em> tienen una gran ventaja sobre el perceptrón, porque funcionan con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">núcleos de imágenes</a> , que se sabe que usan invariancia traslacional.  Cara: es la cara, independientemente de si se muestra en la esquina superior izquierda de la imagen o en el centro, pero donde el perceptrón debe estudiar este caso en cada caso, el núcleo puede responder de inmediato a cualquier parte de la imagen.  Es difícil analizar las redes convolucionales en términos estadísticos, pero es mucho más fácil considerarlas como una versión automática de lo que los expertos en procesamiento de imágenes escribieron a mano.  El núcleo de la imagen es el primer y más fácil programa diferenciable. </p><br><h2 id="encoding-structure-redux">  Estructura de codificación, Redux </h2><br><p>  Los kits de herramientas de ML son cada vez más compatibles con la diferenciación algorítmica (AD), lo que nos permite diferenciar modelos utilizando bucles, ramas y recursividad, o cualquier programa construido sobre un conjunto de primitivas matemáticas diferenciables.  Esto condujo a una arquitectura más compleja: los modelos de PNL se parecen cada vez más a los analizadores de gramática clásicos con modelos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">aumentados de pila</a> , e incluso puede diferenciar un análogo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">de una máquina Turing</a> o un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">intérprete de lenguaje de programación</a> . </p><br><p>  El último paso dado por la programación diferenciada es no considerar más la multiplicación matricial, la convolución y el <em>RNN</em> como elementos fundamentales del aprendizaje profundo, sino solo como casos especiales.  Podemos aplicar métodos de aprendizaje profundo a cualquier función diferenciable parametrizada <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.418ex" height="2.66ex" viewBox="0 -832 1902 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-28" x="550" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="940" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-29" x="1512" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-2"> f (x) </script>  .  Funciones tan complejas como simuladores físicos o trazadores de rayos también se pueden diferenciar y optimizar.  Incluso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">la computación cuántica</a> puede encajar en esta estructura. </p><br><p><img src="https://habrastorage.org/webt/8i/pk/fa/8ipkfaovyvmrkrgev-dnc85atm8.png"></p><br><p>  Los científicos han utilizado durante mucho tiempo modelos mecanicistas que se encuentran entre la programación explícita y el aprendizaje automático.  Las ecuaciones diferenciales con parámetros libres utilizados en física, epidemiología o farmacodinámica son equivalentes a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">las redes neuronales</a> en todo, excepto en la terminología.  Simplemente tienen como objetivo proporcionar una funcionalidad mucho más estrecha, porque es más simple. </p><br><p>  El progreso realmente poderoso es este: la diferenciabilidad generalizada significa que todos estos métodos se conectan entre sí como ladrillos de <em>lego</em> . <br>  En lugar de escribir siempre nuevos programas para ML, podemos reutilizar los programas existentes utilizando motores físicos dentro de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">modelos robóticos</a> basados ​​en el aprendizaje profundo.  Donde los algoritmos modernos de aprendizaje de refuerzo necesitan construir un modelo detallado del mundo exterior basado solo en lo que serán recompensados ​​(suena como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">fuerza bruta</a> ), en su lugar, simplemente podemos aplicar un conocimiento detallado y preciso de los sistemas físicos antes de que el aprendizaje comience. </p><br><p>  Incluso las áreas más maduras de aprendizaje profundo no se hacen a un lado;  después del núcleo de convolución, el siguiente paso natural para los modelos de imagen es un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">rastreador de rayos diferenciable</a> .  La representación 3D contiene una gran cantidad de conocimiento estructural sobre cómo se muestran las escenas en píxeles, que seguirán desempeñando un papel en nuestra cocina.  Digamos que un modelo toma decisiones en un entorno simulado que se muestra como píxeles, que el modelo utiliza como entrada.  En principio, ahora podemos hacer que todo el ciclo sea diferenciable, lo que nos permitirá ver directamente la influencia del entorno en las decisiones del modelo y viceversa.  Esto puede aumentar significativamente la potencia de un entorno simulado realista para modelos de entrenamiento, como los automóviles con conducción automática. </p><br><p>  Como en la ciencia, los modelos híbridos pueden ser más eficientes y resolver algunos de los inconvenientes entre el aprendizaje profundo y la programación explícita.  Por ejemplo, un planificador de ruta de vuelo de drones puede tener un componente de red neuronal que solo puede realizar cambios ligeramente correctivos en un programa explícito confiable, haciendo que se analice su comportamiento general, mientras se adapta a los datos empíricos.  Esto también es bueno para la interpretabilidad: los parámetros de los modelos mecanicistas y las simulaciones generalmente tienen interpretaciones físicas claras, por lo que si el modelo evalúa los parámetros internos, hace una declaración clara sobre lo que, en su opinión, sucede afuera. </p><br><p>  Si todo esto es tan maravilloso, ¿por qué no todos se dieron por vencidos y se apresuraron a aprender a diferenciar?  Desafortunadamente, las limitaciones de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">los marcos existentes</a> dificultan la construcción de modelos de tal complejidad, y es imposible reutilizar la gran cantidad de conocimiento incrustado en el código científico existente.  La necesidad de volver a implementar motores físicos desde cero en un lenguaje de modelado muy limitado convierte un guión de diez líneas en un proyecto de investigación de varios años.  Pero los avances en el lenguaje y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">tecnología de compilación</a> , especialmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">la diferenciación automática</a> , nos acercan al Santo Grial: "solo diferencia mi motor de juego, por favor". </p><br><h2 id="itak-chto-takoe-differenciruemoe-programmirovanie">  Entonces, ¿qué es la programación diferenciada? </h2><br><p>  La programación diferenciada le permite aplicar métodos de aprendizaje profundo a programas existentes complejos, reutilizando con ellos una gran cantidad de conocimiento incrustado en ellos.  Aprendizaje profundo, estadísticas, programación y ciencia, todo lo que trata de decir su palabra al modelar el mundo que nos rodea, es hora de combinarlo todo, uniéndolo como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">partículas en un colisionador de hadrones</a> .  Esto mejorará los modelos actuales y permitirá que ML se aplique en áreas donde sus limitaciones actuales, ya sea la interpretabilidad o los requisitos computacionales y de datos, los hacen individualmente inaplicables. </p><br><h2 id="differenciruemye-problemy-upravleniya">  Problemas de gestión diferenciables </h2><br><p>  A continuación, mostramos que la diferenciabilidad puede traer algunas tareas de administración simples pero clásicas, en las que usualmente utilizamos el aprendizaje de refuerzo (RL) como un cuadro negro.  Los modelos diferenciables (modelos ∂P) no solo revelan estrategias de control mucho más efectivas, sino que también aprenden varios órdenes de magnitud más rápido.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">El código está disponible</a> para su estudio; en la mayoría de los casos, se aprende en unos segundos en cualquier computadora portátil. </p><br><h2 id="sleduyte-za-gradientom">  Sigue el gradiente </h2><br><p>  La diferenciación es la fuerza impulsora en casi todos los pasos del aprendizaje profundo;  para esta función <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.672ex" height="2.66ex" viewBox="0 -832 3733.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-79" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-3D" x="775" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="1831" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-28" x="2382" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="2771" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-29" x="3344" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-3"> y = f (x) </script>  usamos el gradiente <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>x</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.061ex" height="2.419ex" viewBox="0 -780.1 4332 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-72" x="800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-61" x="1252" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-63" x="1781" y="0"></use><g transform="translate(2215,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-79" x="523" y="0"></use></g><g transform="translate(3236,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="523" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>x</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-4"> \ frac {dy} {dx} </script> para descubrir cómo un cambio en <code>x</code> afectará a <code>y</code> .  A pesar de la naturaleza matemática, los gradientes son en realidad un concepto muy general e intuitivo.  Olvídate de las fórmulas que tenías que mirar en la escuela;  hagamos algo más divertido, como arrojar algo por un camino parabólico. </p><br><p><img src="https://habrastorage.org/webt/hy/uu/qr/hyuuqrkomuhvvl8h_wxnqlzkfas.gif"></p><br><p>  Cuando lanzamos proyectiles con la ayuda de un tiro tres, nuestra <code>x</code> (entrada) representa la configuración (por ejemplo, el tamaño del contrapeso o el ángulo de expulsión), e <code>y</code> es la distancia que recorre el proyectil antes de aterrizar.  Si está tratando de apuntar, el gradiente le dice algo muy útil: aumentar o disminuir un determinado parámetro.  Para maximizar la distancia, solo sigue el gradiente. </p><br><p>  OK, pero ¿cómo obtenemos el parámetro correcto?  Pero con la ayuda de algo complicado llamado <a href="" rel="nofollow">diferenciación algorítmica</a> , que le permite diferenciar no solo fórmulas simples que aprendió en la escuela, sino también programas de cualquier complejidad, por ejemplo, nuestro <a href="" rel="nofollow">simulador Trebuchet</a> .  Como resultado, podemos tomar un simulador simple escrito en Julia y un paquete diff <a href="" rel="nofollow">diff DiffEq</a> sin un estudio profundo, y obtener gradientes para él en una llamada de función. </p><br><pre> <code class="julia hljs"><span class="hljs-comment"><span class="hljs-comment"># what you did in school gradient(x -&gt; 3x^2 + 2x + 1, 5) # (32,) # something a little more advanced gradient((wind, angle, weight) -&gt; Trebuchet.shoot(wind, angle, weight), -2, 45, 200) # (4.02, -0.99, 0.051)</span></span></code> </pre> <br><h2 id="throwing-stuff">  Tirando cosas </h2><br><p>  Necesitamos apuntar el trebuchet en el objetivo, usando gradientes para ajustar el ángulo de eyección;  Esto se llama estimación de parámetros, y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">ya hemos visto ejemplos similares</a> .  Podemos hacer la tarea más interesante moviéndonos al meta-método: en lugar de apuntar el trebuchet a un objetivo, optimizamos la red neuronal, que puede apuntar a cualquier objetivo.  Así es como funciona: una red neuronal acepta dos entradas, una distancia objetivo en metros y una velocidad actual del viento.  En la red, se establecen los ajustes para el trebuchet (la masa del contrapeso y el ángulo de disparo), que se envían a un simulador que calcula la distancia recorrida.  Luego comparamos con nuestro objetivo y nos movemos a lo largo de toda la cadena para ajustar el peso de la red.  Nuestro "conjunto de datos" es un conjunto de objetivos y velocidades del viento seleccionados al azar. </p><br><p><img src="https://habrastorage.org/webt/nc/gz/7w/ncgz7wwykokoutzvfgyrm4xbspm.png"></p><br><p>  Una buena característica de este modelo simple es que el aprendizaje es rápido porque expresamos exactamente lo que queremos del modelo de una manera completamente diferenciable.  Inicialmente, se ve así: </p><br><p><img src="https://habrastorage.org/webt/au/8a/-d/au8a-dfq1ud9_fhdcrbvzapfedi.gif"></p><br><p>  Después de unos cinco minutos de entrenamiento (en el mismo núcleo del procesador de mi computadora portátil) se ve así: </p><br><p><img src="https://habrastorage.org/webt/ta/wu/lr/tawulrzggnp09s7qwcyykbhqeqs.gif"></p><br><p>  Si desea influir en la trayectoria, aumente la velocidad del viento: </p><br><p><img src="https://habrastorage.org/webt/qq/9m/dg/qq9mdgrns5hqcpzedeoh1-htrua.gif"></p><br><p>  Desviado por 16 cm, o aproximadamente 0.3%.  ¿Qué hay de apuntar al trebuchet directamente?  Esto es fácil de hacer con el descenso de gradiente, dado que tenemos gradientes.  Sin embargo, este es un proceso iterativo lento que tarda unos 100 ms cada vez.  Por el contrario, el funcionamiento de una red neuronal tarda 5 μs (veinte mil veces más rápido) con una ligera pérdida de precisión.  Este truco, llamado "inversión de función aproximada a través de gradientes", es muy común y puede usarse no solo con sistemas dinámicos, sino también con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">un algoritmo de transferencia de estilo rápido</a> . </p><br><p>  Este es el problema de gestión más simple posible que utilizamos principalmente con fines ilustrativos.  Pero podemos aplicar los mismos métodos de formas más avanzadas a los problemas clásicos de RL. </p><br><h2 id="cart-meet-pole">  Carrito, conoce el poste </h2><br><p>  Un desafío de gestión más reconocible es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">CartPole</a> , el "Hola mundo" para el aprendizaje por refuerzo.  El desafío es aprender a equilibrar el pilar vertical empujando su base hacia la izquierda o hacia la derecha.  Nuestra configuración es generalmente similar al caso de Trebuchet: la <a href="" rel="nofollow">implementación de Julia</a> nos permite considerar directamente las recompensas recibidas por el medio ambiente como pérdidas.  ∂P nos permite cambiar sin problemas de un modelo simple a un modelo RL. </p><br><p><img src="https://habrastorage.org/webt/ik/wp/0y/ikwp0y4qhogsybm3rakwiyxwfuc.png"></p><br><p>  Un lector astuto puede notar un inconveniente.  El área de acción para el piso, un desplazamiento hacia la izquierda o hacia la derecha, es discreta y, por lo tanto, no es diferenciable.  Resolvemos este problema introduciendo discretización diferenciable, definida de la <a href="" rel="nofollow">siguiente manera</a> : </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><merror><mtext>f&amp;#xA0;(x)&amp;#xA0;=&amp;#xA0;\&amp;#xA0;left&amp;#xA0;\&amp;#xA0;{\&amp;#xA0;begin&amp;#xA0;{matrix}&amp;#xA0;\,&amp;#xA0;1,&amp;#xA0;\,&amp;#xA0;x&amp;#xA0;\&amp;#xA0;geqslant0&amp;#xA0;\\&amp;#xA0;-1,&amp;#xA0;\,&amp;#xA0;x&amp;#xA0;&amp;lt;0&amp;#xA0;\&amp;#xA0;end&amp;#xA0;{matrix}&amp;#xA0;\&amp;#xA0;right.&amp;#xA0;$</mtext></merror></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><span class="noError" aria-hidden="true" style="display: inline-block;">f&nbsp;(x)&nbsp;=&nbsp;\&nbsp;left&nbsp;\&nbsp;{\&nbsp;begin&nbsp;{matrix}&nbsp;\,&nbsp;1,&nbsp;\,&nbsp;x&nbsp;\&nbsp;geqslant0&nbsp;\\&nbsp;-1,&nbsp;\,&nbsp;x&nbsp;&lt;0&nbsp;\&nbsp;end&nbsp;{matrix}&nbsp;\&nbsp;right.&nbsp;$</span><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><merror><mtext>f&nbsp;(x)&nbsp;=&nbsp;\&nbsp;left&nbsp;\&nbsp;{\&nbsp;begin&nbsp;{matrix}&nbsp;\,&nbsp;1,&nbsp;\,&nbsp;x&nbsp;\&nbsp;geqslant0&nbsp;\\&nbsp;-1,&nbsp;\,&nbsp;x&nbsp;&lt;0&nbsp;\&nbsp;end&nbsp;{matrix}&nbsp;\&nbsp;right.&nbsp;$</mtext></merror></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-5"> f (x) = \ left \ {\ begin {matrix} \, 1, \, x \ geqslant0 \\ -1, \, x <0 \ end {matrix} \ right. $ </script></p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>f</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>x</mi></mrow><mo>=</mo><mn>1</mn></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="14.445ex" height="2.419ex" viewBox="0 -780.1 6219.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-72" x="800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-61" x="1252" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-63" x="1781" y="0"></use><g transform="translate(2215,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="523" y="0"></use></g><g transform="translate(3289,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="523" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-3D" x="4662" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-31" x="5719" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>f</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>x</mi></mrow><mo>=</mo><mn>1</mn></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-6"> \ frac {df} {dx} = 1 </script></p><br><p>  En otras palabras, hacemos que el gradiente se comporte como si <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.279ex" height="2.419ex" viewBox="0 -780.1 550.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-7"> f </script>  Era una función idéntica.  Dado lo mucho que la idea matemática de diferenciabilidad ya se usa en ML, quizás no sea sorprendente que simplemente podamos engañar aquí;  Para el entrenamiento, todo lo que necesitamos es una señal para informar nuestra caminata pseudoaleatoria alrededor del espacio de parámetros, y el resto son los detalles.  Los resultados hablan por sí mismos.  En los casos en que los métodos RL necesitan ser entrenados en cientos de episodios antes de resolver el problema, los modelos ∂P solo necesitan alrededor de 5 episodios para finalmente ganar. </p><br><p><img src="https://habrastorage.org/webt/7t/eq/hj/7teqhjn1f4rdicydv4iiqjasirm.gif"></p><br><h2 id="the-pendulum--backprop-through-time">  El péndulo y el backprop a través del tiempo </h2><br><p>  Un objetivo importante para RL <em>(aprendizaje de refuerzo)</em> es manejar la remuneración diferida cuando una acción no nos ayuda a mejorar los resultados de varios pasos seguidos.  Cuando el entorno es diferenciable, ∂P le permite entrenar al agente en la propagación hacia atrás en el tiempo, ¡como en una red recursiva!  En este caso, el estado del entorno se convierte en un "estado oculto" que cambia entre los pasos de tiempo. </p><br><p><img src="https://habrastorage.org/webt/uy/od/mb/uyodmbo3grxrwkyawrgfol0nujo.png"></p><br><p>  Para demostrar esta técnica, consideramos un modelo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">péndulo</a> , donde la tarea es balancear el péndulo hasta que esté en posición vertical y mantenerlo en equilibrio inestable.  Esto es difícil para los modelos RL;  Después de aproximadamente 20 episodios de entrenamiento, el problema está resuelto, pero a menudo el camino hacia la solución claramente no es óptimo.  En contraste, BPTT puede superar la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">clasificación de los líderes de</a> RL en un episodio de entrenamiento.  Es instructivo observar cómo se desarrolla este episodio;  Al comienzo de la grabación, la estrategia es aleatoria y el modelo mejora con el tiempo.  El ritmo de aprendizaje es casi alarmante. </p><br><p><img src="https://habrastorage.org/webt/jm/wm/nh/jmwmnhr9nts4ki257ywtittvgck.gif"></p><br><p>  El modelo es muy adecuado para mecanizar cualquier ángulo inicial y tiene algo cercano a la estrategia óptima.  Al reiniciar, el modelo se ve más o menos así. </p><br><p><img src="https://habrastorage.org/webt/bu/7f/t3/bu7ft3bzofjrdumbfqvvwqr0nz8.gif"></p><br><p>  Esto es solo el comienzo;  lograremos un verdadero éxito aplicando <em>DP</em> a entornos con los cuales RL es generalmente demasiado difícil de trabajar, donde ya existen simulaciones y modelos ricos (como en la mayoría de las ciencias de ingeniería y naturales), y donde la interpretabilidad es un factor importante (como en la medicina). </p><br><h2 id="the-map-is-not-the-territory">  El mapa no es el territorio </h2><br><p>  Una limitación de estos modelos de juguetes es que equiparan el entorno de aprendizaje simulado con el entorno de prueba;  Por supuesto, el mundo real no es diferenciable.  En un modelo más realista, la simulación nos proporciona un patrón de comportamiento aproximado, que los datos refinan.  Estos datos informan, por ejemplo, de los efectos simulados del viento, que, a su vez, mejora la calidad de los gradientes que el simulador pasa al controlador.  Los modelos incluso pueden formar parte del pase directo del controlador, lo que le permite refinar sus pronósticos sin tener que estudiar la dinámica del sistema desde cero.  Aprender estas nuevas arquitecturas hará que el trabajo futuro sea emocionante. </p><br><h2 id="coda">  Coda </h2><br><p>  La idea básica es que la programación diferenciable, en la que simplemente escribimos un programa numérico arbitrario y lo optimizamos utilizando gradientes, es una forma poderosa de crear mejores modelos y arquitecturas similares al aprendizaje profundo, especialmente cuando tenemos una gran biblioteca de programas diferenciables a la mano .  Los modelos descritos son solo vistas previas, pero esperamos que den una idea de cómo estas ideas pueden implementarse de una manera más realista. </p><br><p>  Así como la programación funcional implica razonar y expresar algoritmos utilizando patrones funcionales, la programación diferenciable implica expresar algoritmos utilizando patrones diferenciables.  La comunidad de aprendizaje profundo ya ha desarrollado muchos de estos patrones de diseño, por ejemplo, para manejar problemas de gestión o una estructura de datos consistente y en forma de árbol.  A medida que crezca el área, se inventará mucho más y, como resultado de estos programas, probablemente incluso las arquitecturas de aprendizaje profundo más avanzadas se verán groseras y hacia atrás. </p><br><h3 id="ssylki">  Referencias </h3><br><ul><li>  Fuentes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Primero</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Segundo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Wikipedia</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Auto diferenciación;</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículo sobre habr</a> </li><li>  <a href="" rel="nofollow">Auto diferenciación;</a>  <a href="" rel="nofollow">paquete terminado</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Auto diferenciación;</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">hazlo tu mismo</a> </li></ul><br><p><img src="https://habrastorage.org/webt/f2/4o/pr/f24oprfnnrnguwwb03xcyo__xx4.gif"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/459562/">https://habr.com/ru/post/459562/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../459550/index.html">Backup, Parte 5: Prueba de Bacula y Veeam Backup para Linux</a></li>
<li><a href="../459552/index.html">Cómo perder el acceso al sistema en vivo simplemente buscando el código fuente</a></li>
<li><a href="../459554/index.html">Realice un seguimiento de los cambios de archivos con Alerting OpenDistro for Elasticsearch</a></li>
<li><a href="../459558/index.html">Cómo comenzar a usar el modo de usuario en Linux</a></li>
<li><a href="../459560/index.html">Capacidades de los centros de datos de contenedores: centro de conmutación listo para usar en Myanmar en 50 días</a></li>
<li><a href="../459564/index.html">Lo que los desarrolladores necesitan saber sobre negocios</a></li>
<li><a href="../459568/index.html">Letra vertical en TI moderna</a></li>
<li><a href="../459570/index.html">Beeline muestra anuncios al robot de Google. Bot infeliz</a></li>
<li><a href="../459574/index.html">Profundice en los espacios de nombres de Linux, parte 2</a></li>
<li><a href="../459576/index.html">Extensiones útiles de Google Chrome para el programador</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêí üëàüèø ‚è±Ô∏è Programaci√≥n diferenciable üë©üèª‚Äçüî¨ ‚úãüèº üåâ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Con cuatro par√°metros, puedo preguntarle a un elefante, y con cinco puedo hacer que mueva su trompa. 
 - John Von Neumann 

 La idea de " programaci√≥n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Programaci√≥n diferenciable</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/459562/"><p><img src="https://habrastorage.org/webt/fv/8k/s8/fv8ks8cvj64dyqlstu1vi9znbv8.jpeg"></p><br><blockquote>  Con cuatro par√°metros, puedo preguntarle a un elefante, y con cinco puedo hacer que mueva su trompa. <br>  - John Von Neumann </blockquote><p>  La idea de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">programaci√≥n diferenciable</a> " es muy popular en el mundo del aprendizaje autom√°tico.  Para muchos, no est√° claro si este t√©rmino refleja un cambio real en la forma en que los investigadores entienden el aprendizaje autom√°tico, o es simplemente (otro) cambio de marca del "aprendizaje profundo".  Esta publicaci√≥n explica qu√© hay de nuevo en la programaci√≥n diferenciada (o ‚àÇP) en la tabla de aprendizaje autom√°tico. </p><br><p>  Lo m√°s importante, la programaci√≥n diferenciada es el cambio opuesto a la direcci√≥n del aprendizaje profundo;  desde modelos cada vez m√°s parametrizados hasta modelos m√°s simples que utilizan la estructura del problema en mayor medida. </p><br><p>  A continuaci√≥n, hojeamos un lienzo de texto poco interesante, queremos descubrir qu√© es la auto diferenciaci√≥n e incluso poblarla desde una catapulta. </p><a name="habracut"></a><br><h2 id="brute-force-with-benefits">  Fuerza bruta con beneficios </h2><br><p>  La diferenciabilidad es una idea b√°sica que hace que el aprendizaje profundo sea tan exitoso.  Cuando las b√∫squedas de fuerza bruta, incluso para unos pocos cientos de par√°metros del modelo, ser√≠an demasiado caras, los gradientes permiten un recorrido pseudoaleatorio de partes interesantes del espacio de par√°metros y encuentran un buen conjunto.  Realizando un algoritmo aparentemente tan ingenuo, obtenemos una buena generalidad, pero est√° lejos de ser obvio que necesitamos diferenciar, por ejemplo, trabajar con secuencias en la traducci√≥n de idiomas, pero todo resulta ser simple, mostramos un poco de ingenio. </p><br><p>  ¬øQu√© pasa con las neuronas biol√≥gicas y <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>y</mi><mo>=</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x3C3;</mo></mrow><mo stretchy=&quot;false&quot;>(</mo><mi>W</mi><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>e</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>x</mi><mo>+</mo><mi>b</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="20.966ex" height="2.66ex" viewBox="0 -832 9027 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-79" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-3D" x="775" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-3C3" x="1831" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-28" x="2403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-57" x="2792" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-76" x="4091" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-65" x="4576" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-63" x="5043" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-65" x="5476" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-73" x="5943" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="6412" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-2B" x="7207" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-62" x="8208" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-29" x="8637" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mo>œÉ</mo></mrow><mo stretchy="false">(</mo><mi>W</mi><mtext>&nbsp;</mtext><mi>v</mi><mi>e</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>x</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> y = œÉ (W \ veces x + b) </script>  ?  No hay nada especial en esta f√≥rmula;  Este es un ejemplo simple y flexible de una funci√≥n no lineal altamente param√©trica.  De hecho, esta es probablemente la peor caracter√≠stica en la mayor√≠a de los casos.  Una capa de la red neuronal, en principio, puede clasificar im√°genes de gatos, pero solo usando un truco relativamente poco interesante.  <strong>¬°Funciona perfectamente!</strong>  - pero la letra peque√±a advierte que puede necesitar m√°s par√°metros que √°tomos en el universo.  Para que este trabajo funcione, debe codificar la estructura problem√°tica en el modelo; aqu√≠ es donde comienza a parecerse m√°s a la programaci√≥n tradicional. </p><br><p>  Por ejemplo, las <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">ConvNets</a></em> tienen una gran ventaja sobre el perceptr√≥n, porque funcionan con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">n√∫cleos de im√°genes</a> , que se sabe que usan invariancia traslacional.  Cara: es la cara, independientemente de si se muestra en la esquina superior izquierda de la imagen o en el centro, pero donde el perceptr√≥n debe estudiar este caso en cada caso, el n√∫cleo puede responder de inmediato a cualquier parte de la imagen.  Es dif√≠cil analizar las redes convolucionales en t√©rminos estad√≠sticos, pero es mucho m√°s f√°cil considerarlas como una versi√≥n autom√°tica de lo que los expertos en procesamiento de im√°genes escribieron a mano.  El n√∫cleo de la imagen es el primer y m√°s f√°cil programa diferenciable. </p><br><h2 id="encoding-structure-redux">  Estructura de codificaci√≥n, Redux </h2><br><p>  Los kits de herramientas de ML son cada vez m√°s compatibles con la diferenciaci√≥n algor√≠tmica (AD), lo que nos permite diferenciar modelos utilizando bucles, ramas y recursividad, o cualquier programa construido sobre un conjunto de primitivas matem√°ticas diferenciables.  Esto condujo a una arquitectura m√°s compleja: los modelos de PNL se parecen cada vez m√°s a los analizadores de gram√°tica cl√°sicos con modelos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">aumentados de pila</a> , e incluso puede diferenciar un an√°logo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">de una m√°quina Turing</a> o un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">int√©rprete de lenguaje de programaci√≥n</a> . </p><br><p>  El √∫ltimo paso dado por la programaci√≥n diferenciada es no considerar m√°s la multiplicaci√≥n matricial, la convoluci√≥n y el <em>RNN</em> como elementos fundamentales del aprendizaje profundo, sino solo como casos especiales.  Podemos aplicar m√©todos de aprendizaje profundo a cualquier funci√≥n diferenciable parametrizada <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.418ex" height="2.66ex" viewBox="0 -832 1902 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-28" x="550" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="940" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-29" x="1512" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-2"> f (x) </script>  .  Funciones tan complejas como simuladores f√≠sicos o trazadores de rayos tambi√©n se pueden diferenciar y optimizar.  Incluso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">la computaci√≥n cu√°ntica</a> puede encajar en esta estructura. </p><br><p><img src="https://habrastorage.org/webt/8i/pk/fa/8ipkfaovyvmrkrgev-dnc85atm8.png"></p><br><p>  Los cient√≠ficos han utilizado durante mucho tiempo modelos mecanicistas que se encuentran entre la programaci√≥n expl√≠cita y el aprendizaje autom√°tico.  Las ecuaciones diferenciales con par√°metros libres utilizados en f√≠sica, epidemiolog√≠a o farmacodin√°mica son equivalentes a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">las redes neuronales</a> en todo, excepto en la terminolog√≠a.  Simplemente tienen como objetivo proporcionar una funcionalidad mucho m√°s estrecha, porque es m√°s simple. </p><br><p>  El progreso realmente poderoso es este: la diferenciabilidad generalizada significa que todos estos m√©todos se conectan entre s√≠ como ladrillos de <em>lego</em> . <br>  En lugar de escribir siempre nuevos programas para ML, podemos reutilizar los programas existentes utilizando motores f√≠sicos dentro de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">modelos rob√≥ticos</a> basados ‚Äã‚Äãen el aprendizaje profundo.  Donde los algoritmos modernos de aprendizaje de refuerzo necesitan construir un modelo detallado del mundo exterior basado solo en lo que ser√°n recompensados ‚Äã‚Äã(suena como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">fuerza bruta</a> ), en su lugar, simplemente podemos aplicar un conocimiento detallado y preciso de los sistemas f√≠sicos antes de que el aprendizaje comience. </p><br><p>  Incluso las √°reas m√°s maduras de aprendizaje profundo no se hacen a un lado;  despu√©s del n√∫cleo de convoluci√≥n, el siguiente paso natural para los modelos de imagen es un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">rastreador de rayos diferenciable</a> .  La representaci√≥n 3D contiene una gran cantidad de conocimiento estructural sobre c√≥mo se muestran las escenas en p√≠xeles, que seguir√°n desempe√±ando un papel en nuestra cocina.  Digamos que un modelo toma decisiones en un entorno simulado que se muestra como p√≠xeles, que el modelo utiliza como entrada.  En principio, ahora podemos hacer que todo el ciclo sea diferenciable, lo que nos permitir√° ver directamente la influencia del entorno en las decisiones del modelo y viceversa.  Esto puede aumentar significativamente la potencia de un entorno simulado realista para modelos de entrenamiento, como los autom√≥viles con conducci√≥n autom√°tica. </p><br><p>  Como en la ciencia, los modelos h√≠bridos pueden ser m√°s eficientes y resolver algunos de los inconvenientes entre el aprendizaje profundo y la programaci√≥n expl√≠cita.  Por ejemplo, un planificador de ruta de vuelo de drones puede tener un componente de red neuronal que solo puede realizar cambios ligeramente correctivos en un programa expl√≠cito confiable, haciendo que se analice su comportamiento general, mientras se adapta a los datos emp√≠ricos.  Esto tambi√©n es bueno para la interpretabilidad: los par√°metros de los modelos mecanicistas y las simulaciones generalmente tienen interpretaciones f√≠sicas claras, por lo que si el modelo eval√∫a los par√°metros internos, hace una declaraci√≥n clara sobre lo que, en su opini√≥n, sucede afuera. </p><br><p>  Si todo esto es tan maravilloso, ¬øpor qu√© no todos se dieron por vencidos y se apresuraron a aprender a diferenciar?  Desafortunadamente, las limitaciones de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">los marcos existentes</a> dificultan la construcci√≥n de modelos de tal complejidad, y es imposible reutilizar la gran cantidad de conocimiento incrustado en el c√≥digo cient√≠fico existente.  La necesidad de volver a implementar motores f√≠sicos desde cero en un lenguaje de modelado muy limitado convierte un gui√≥n de diez l√≠neas en un proyecto de investigaci√≥n de varios a√±os.  Pero los avances en el lenguaje y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">tecnolog√≠a de compilaci√≥n</a> , especialmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">la diferenciaci√≥n autom√°tica</a> , nos acercan al Santo Grial: "solo diferencia mi motor de juego, por favor". </p><br><h2 id="itak-chto-takoe-differenciruemoe-programmirovanie">  Entonces, ¬øqu√© es la programaci√≥n diferenciada? </h2><br><p>  La programaci√≥n diferenciada le permite aplicar m√©todos de aprendizaje profundo a programas existentes complejos, reutilizando con ellos una gran cantidad de conocimiento incrustado en ellos.  Aprendizaje profundo, estad√≠sticas, programaci√≥n y ciencia, todo lo que trata de decir su palabra al modelar el mundo que nos rodea, es hora de combinarlo todo, uni√©ndolo como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">part√≠culas en un colisionador de hadrones</a> .  Esto mejorar√° los modelos actuales y permitir√° que ML se aplique en √°reas donde sus limitaciones actuales, ya sea la interpretabilidad o los requisitos computacionales y de datos, los hacen individualmente inaplicables. </p><br><h2 id="differenciruemye-problemy-upravleniya">  Problemas de gesti√≥n diferenciables </h2><br><p>  A continuaci√≥n, mostramos que la diferenciabilidad puede traer algunas tareas de administraci√≥n simples pero cl√°sicas, en las que usualmente utilizamos el aprendizaje de refuerzo (RL) como un cuadro negro.  Los modelos diferenciables (modelos ‚àÇP) no solo revelan estrategias de control mucho m√°s efectivas, sino que tambi√©n aprenden varios √≥rdenes de magnitud m√°s r√°pido.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">El c√≥digo est√° disponible</a> para su estudio; en la mayor√≠a de los casos, se aprende en unos segundos en cualquier computadora port√°til. </p><br><h2 id="sleduyte-za-gradientom">  Sigue el gradiente </h2><br><p>  La diferenciaci√≥n es la fuerza impulsora en casi todos los pasos del aprendizaje profundo;  para esta funci√≥n <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.672ex" height="2.66ex" viewBox="0 -832 3733.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-79" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-3D" x="775" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="1831" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-28" x="2382" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="2771" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-29" x="3344" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-3"> y = f (x) </script>  usamos el gradiente <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>x</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.061ex" height="2.419ex" viewBox="0 -780.1 4332 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-72" x="800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-61" x="1252" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-63" x="1781" y="0"></use><g transform="translate(2215,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-79" x="523" y="0"></use></g><g transform="translate(3236,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="523" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>x</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-4"> \ frac {dy} {dx} </script> para descubrir c√≥mo un cambio en <code>x</code> afectar√° a <code>y</code> .  A pesar de la naturaleza matem√°tica, los gradientes son en realidad un concepto muy general e intuitivo.  Olv√≠date de las f√≥rmulas que ten√≠as que mirar en la escuela;  hagamos algo m√°s divertido, como arrojar algo por un camino parab√≥lico. </p><br><p><img src="https://habrastorage.org/webt/hy/uu/qr/hyuuqrkomuhvvl8h_wxnqlzkfas.gif"></p><br><p>  Cuando lanzamos proyectiles con la ayuda de un tiro tres, nuestra <code>x</code> (entrada) representa la configuraci√≥n (por ejemplo, el tama√±o del contrapeso o el √°ngulo de expulsi√≥n), e <code>y</code> es la distancia que recorre el proyectil antes de aterrizar.  Si est√° tratando de apuntar, el gradiente le dice algo muy √∫til: aumentar o disminuir un determinado par√°metro.  Para maximizar la distancia, solo sigue el gradiente. </p><br><p>  OK, pero ¬øc√≥mo obtenemos el par√°metro correcto?  Pero con la ayuda de algo complicado llamado <a href="" rel="nofollow">diferenciaci√≥n algor√≠tmica</a> , que le permite diferenciar no solo f√≥rmulas simples que aprendi√≥ en la escuela, sino tambi√©n programas de cualquier complejidad, por ejemplo, nuestro <a href="" rel="nofollow">simulador Trebuchet</a> .  Como resultado, podemos tomar un simulador simple escrito en Julia y un paquete diff <a href="" rel="nofollow">diff DiffEq</a> sin un estudio profundo, y obtener gradientes para √©l en una llamada de funci√≥n. </p><br><pre> <code class="julia hljs"><span class="hljs-comment"><span class="hljs-comment"># what you did in school gradient(x -&gt; 3x^2 + 2x + 1, 5) # (32,) # something a little more advanced gradient((wind, angle, weight) -&gt; Trebuchet.shoot(wind, angle, weight), -2, 45, 200) # (4.02, -0.99, 0.051)</span></span></code> </pre> <br><h2 id="throwing-stuff">  Tirando cosas </h2><br><p>  Necesitamos apuntar el trebuchet en el objetivo, usando gradientes para ajustar el √°ngulo de eyecci√≥n;  Esto se llama estimaci√≥n de par√°metros, y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">ya hemos visto ejemplos similares</a> .  Podemos hacer la tarea m√°s interesante movi√©ndonos al meta-m√©todo: en lugar de apuntar el trebuchet a un objetivo, optimizamos la red neuronal, que puede apuntar a cualquier objetivo.  As√≠ es como funciona: una red neuronal acepta dos entradas, una distancia objetivo en metros y una velocidad actual del viento.  En la red, se establecen los ajustes para el trebuchet (la masa del contrapeso y el √°ngulo de disparo), que se env√≠an a un simulador que calcula la distancia recorrida.  Luego comparamos con nuestro objetivo y nos movemos a lo largo de toda la cadena para ajustar el peso de la red.  Nuestro "conjunto de datos" es un conjunto de objetivos y velocidades del viento seleccionados al azar. </p><br><p><img src="https://habrastorage.org/webt/nc/gz/7w/ncgz7wwykokoutzvfgyrm4xbspm.png"></p><br><p>  Una buena caracter√≠stica de este modelo simple es que el aprendizaje es r√°pido porque expresamos exactamente lo que queremos del modelo de una manera completamente diferenciable.  Inicialmente, se ve as√≠: </p><br><p><img src="https://habrastorage.org/webt/au/8a/-d/au8a-dfq1ud9_fhdcrbvzapfedi.gif"></p><br><p>  Despu√©s de unos cinco minutos de entrenamiento (en el mismo n√∫cleo del procesador de mi computadora port√°til) se ve as√≠: </p><br><p><img src="https://habrastorage.org/webt/ta/wu/lr/tawulrzggnp09s7qwcyykbhqeqs.gif"></p><br><p>  Si desea influir en la trayectoria, aumente la velocidad del viento: </p><br><p><img src="https://habrastorage.org/webt/qq/9m/dg/qq9mdgrns5hqcpzedeoh1-htrua.gif"></p><br><p>  Desviado por 16 cm, o aproximadamente 0.3%.  ¬øQu√© hay de apuntar al trebuchet directamente?  Esto es f√°cil de hacer con el descenso de gradiente, dado que tenemos gradientes.  Sin embargo, este es un proceso iterativo lento que tarda unos 100 ms cada vez.  Por el contrario, el funcionamiento de una red neuronal tarda 5 Œºs (veinte mil veces m√°s r√°pido) con una ligera p√©rdida de precisi√≥n.  Este truco, llamado "inversi√≥n de funci√≥n aproximada a trav√©s de gradientes", es muy com√∫n y puede usarse no solo con sistemas din√°micos, sino tambi√©n con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">un algoritmo de transferencia de estilo r√°pido</a> . </p><br><p>  Este es el problema de gesti√≥n m√°s simple posible que utilizamos principalmente con fines ilustrativos.  Pero podemos aplicar los mismos m√©todos de formas m√°s avanzadas a los problemas cl√°sicos de RL. </p><br><h2 id="cart-meet-pole">  Carrito, conoce el poste </h2><br><p>  Un desaf√≠o de gesti√≥n m√°s reconocible es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">CartPole</a> , el "Hola mundo" para el aprendizaje por refuerzo.  El desaf√≠o es aprender a equilibrar el pilar vertical empujando su base hacia la izquierda o hacia la derecha.  Nuestra configuraci√≥n es generalmente similar al caso de Trebuchet: la <a href="" rel="nofollow">implementaci√≥n de Julia</a> nos permite considerar directamente las recompensas recibidas por el medio ambiente como p√©rdidas.  ‚àÇP nos permite cambiar sin problemas de un modelo simple a un modelo RL. </p><br><p><img src="https://habrastorage.org/webt/ik/wp/0y/ikwp0y4qhogsybm3rakwiyxwfuc.png"></p><br><p>  Un lector astuto puede notar un inconveniente.  El √°rea de acci√≥n para el piso, un desplazamiento hacia la izquierda o hacia la derecha, es discreta y, por lo tanto, no es diferenciable.  Resolvemos este problema introduciendo discretizaci√≥n diferenciable, definida de la <a href="" rel="nofollow">siguiente manera</a> : </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><merror><mtext>f&amp;#xA0;(x)&amp;#xA0;=&amp;#xA0;\&amp;#xA0;left&amp;#xA0;\&amp;#xA0;{\&amp;#xA0;begin&amp;#xA0;{matrix}&amp;#xA0;\,&amp;#xA0;1,&amp;#xA0;\,&amp;#xA0;x&amp;#xA0;\&amp;#xA0;geqslant0&amp;#xA0;\\&amp;#xA0;-1,&amp;#xA0;\,&amp;#xA0;x&amp;#xA0;&amp;lt;0&amp;#xA0;\&amp;#xA0;end&amp;#xA0;{matrix}&amp;#xA0;\&amp;#xA0;right.&amp;#xA0;$</mtext></merror></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><span class="noError" aria-hidden="true" style="display: inline-block;">f&nbsp;(x)&nbsp;=&nbsp;\&nbsp;left&nbsp;\&nbsp;{\&nbsp;begin&nbsp;{matrix}&nbsp;\,&nbsp;1,&nbsp;\,&nbsp;x&nbsp;\&nbsp;geqslant0&nbsp;\\&nbsp;-1,&nbsp;\,&nbsp;x&nbsp;&lt;0&nbsp;\&nbsp;end&nbsp;{matrix}&nbsp;\&nbsp;right.&nbsp;$</span><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><merror><mtext>f&nbsp;(x)&nbsp;=&nbsp;\&nbsp;left&nbsp;\&nbsp;{\&nbsp;begin&nbsp;{matrix}&nbsp;\,&nbsp;1,&nbsp;\,&nbsp;x&nbsp;\&nbsp;geqslant0&nbsp;\\&nbsp;-1,&nbsp;\,&nbsp;x&nbsp;&lt;0&nbsp;\&nbsp;end&nbsp;{matrix}&nbsp;\&nbsp;right.&nbsp;$</mtext></merror></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-5"> f (x) = \ left \ {\ begin {matrix} \, 1, \, x \ geqslant0 \\ -1, \, x <0 \ end {matrix} \ right. $ </script></p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>f</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>x</mi></mrow><mo>=</mo><mn>1</mn></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="14.445ex" height="2.419ex" viewBox="0 -780.1 6219.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-72" x="800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-61" x="1252" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-63" x="1781" y="0"></use><g transform="translate(2215,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="523" y="0"></use></g><g transform="translate(3289,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-78" x="523" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-3D" x="4662" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMAIN-31" x="5719" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>f</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>x</mi></mrow><mo>=</mo><mn>1</mn></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-6"> \ frac {df} {dx} = 1 </script></p><br><p>  En otras palabras, hacemos que el gradiente se comporte como si <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.279ex" height="2.419ex" viewBox="0 -780.1 550.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/459562/&amp;usg=ALkJrhh3lfvfRRDk7c6f6gJgaUfw9slPwA#MJMATHI-66" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-7"> f </script>  Era una funci√≥n id√©ntica.  Dado lo mucho que la idea matem√°tica de diferenciabilidad ya se usa en ML, quiz√°s no sea sorprendente que simplemente podamos enga√±ar aqu√≠;  Para el entrenamiento, todo lo que necesitamos es una se√±al para informar nuestra caminata pseudoaleatoria alrededor del espacio de par√°metros, y el resto son los detalles.  Los resultados hablan por s√≠ mismos.  En los casos en que los m√©todos RL necesitan ser entrenados en cientos de episodios antes de resolver el problema, los modelos ‚àÇP solo necesitan alrededor de 5 episodios para finalmente ganar. </p><br><p><img src="https://habrastorage.org/webt/7t/eq/hj/7teqhjn1f4rdicydv4iiqjasirm.gif"></p><br><h2 id="the-pendulum--backprop-through-time">  El p√©ndulo y el backprop a trav√©s del tiempo </h2><br><p>  Un objetivo importante para RL <em>(aprendizaje de refuerzo)</em> es manejar la remuneraci√≥n diferida cuando una acci√≥n no nos ayuda a mejorar los resultados de varios pasos seguidos.  Cuando el entorno es diferenciable, ‚àÇP le permite entrenar al agente en la propagaci√≥n hacia atr√°s en el tiempo, ¬°como en una red recursiva!  En este caso, el estado del entorno se convierte en un "estado oculto" que cambia entre los pasos de tiempo. </p><br><p><img src="https://habrastorage.org/webt/uy/od/mb/uyodmbo3grxrwkyawrgfol0nujo.png"></p><br><p>  Para demostrar esta t√©cnica, consideramos un modelo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">p√©ndulo</a> , donde la tarea es balancear el p√©ndulo hasta que est√© en posici√≥n vertical y mantenerlo en equilibrio inestable.  Esto es dif√≠cil para los modelos RL;  Despu√©s de aproximadamente 20 episodios de entrenamiento, el problema est√° resuelto, pero a menudo el camino hacia la soluci√≥n claramente no es √≥ptimo.  En contraste, BPTT puede superar la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">clasificaci√≥n de los l√≠deres de</a> RL en un episodio de entrenamiento.  Es instructivo observar c√≥mo se desarrolla este episodio;  Al comienzo de la grabaci√≥n, la estrategia es aleatoria y el modelo mejora con el tiempo.  El ritmo de aprendizaje es casi alarmante. </p><br><p><img src="https://habrastorage.org/webt/jm/wm/nh/jmwmnhr9nts4ki257ywtittvgck.gif"></p><br><p>  El modelo es muy adecuado para mecanizar cualquier √°ngulo inicial y tiene algo cercano a la estrategia √≥ptima.  Al reiniciar, el modelo se ve m√°s o menos as√≠. </p><br><p><img src="https://habrastorage.org/webt/bu/7f/t3/bu7ft3bzofjrdumbfqvvwqr0nz8.gif"></p><br><p>  Esto es solo el comienzo;  lograremos un verdadero √©xito aplicando <em>DP</em> a entornos con los cuales RL es generalmente demasiado dif√≠cil de trabajar, donde ya existen simulaciones y modelos ricos (como en la mayor√≠a de las ciencias de ingenier√≠a y naturales), y donde la interpretabilidad es un factor importante (como en la medicina). </p><br><h2 id="the-map-is-not-the-territory">  El mapa no es el territorio </h2><br><p>  Una limitaci√≥n de estos modelos de juguetes es que equiparan el entorno de aprendizaje simulado con el entorno de prueba;  Por supuesto, el mundo real no es diferenciable.  En un modelo m√°s realista, la simulaci√≥n nos proporciona un patr√≥n de comportamiento aproximado, que los datos refinan.  Estos datos informan, por ejemplo, de los efectos simulados del viento, que, a su vez, mejora la calidad de los gradientes que el simulador pasa al controlador.  Los modelos incluso pueden formar parte del pase directo del controlador, lo que le permite refinar sus pron√≥sticos sin tener que estudiar la din√°mica del sistema desde cero.  Aprender estas nuevas arquitecturas har√° que el trabajo futuro sea emocionante. </p><br><h2 id="coda">  Coda </h2><br><p>  La idea b√°sica es que la programaci√≥n diferenciable, en la que simplemente escribimos un programa num√©rico arbitrario y lo optimizamos utilizando gradientes, es una forma poderosa de crear mejores modelos y arquitecturas similares al aprendizaje profundo, especialmente cuando tenemos una gran biblioteca de programas diferenciables a la mano .  Los modelos descritos son solo vistas previas, pero esperamos que den una idea de c√≥mo estas ideas pueden implementarse de una manera m√°s realista. </p><br><p>  As√≠ como la programaci√≥n funcional implica razonar y expresar algoritmos utilizando patrones funcionales, la programaci√≥n diferenciable implica expresar algoritmos utilizando patrones diferenciables.  La comunidad de aprendizaje profundo ya ha desarrollado muchos de estos patrones de dise√±o, por ejemplo, para manejar problemas de gesti√≥n o una estructura de datos consistente y en forma de √°rbol.  A medida que crezca el √°rea, se inventar√° mucho m√°s y, como resultado de estos programas, probablemente incluso las arquitecturas de aprendizaje profundo m√°s avanzadas se ver√°n groseras y hacia atr√°s. </p><br><h3 id="ssylki">  Referencias </h3><br><ul><li>  Fuentes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Primero</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Segundo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Wikipedia</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Auto diferenciaci√≥n;</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo sobre habr</a> </li><li>  <a href="" rel="nofollow">Auto diferenciaci√≥n;</a>  <a href="" rel="nofollow">paquete terminado</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Auto diferenciaci√≥n;</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">hazlo tu mismo</a> </li></ul><br><p><img src="https://habrastorage.org/webt/f2/4o/pr/f24oprfnnrnguwwb03xcyo__xx4.gif"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/459562/">https://habr.com/ru/post/459562/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../459550/index.html">Backup, Parte 5: Prueba de Bacula y Veeam Backup para Linux</a></li>
<li><a href="../459552/index.html">C√≥mo perder el acceso al sistema en vivo simplemente buscando el c√≥digo fuente</a></li>
<li><a href="../459554/index.html">Realice un seguimiento de los cambios de archivos con Alerting OpenDistro for Elasticsearch</a></li>
<li><a href="../459558/index.html">C√≥mo comenzar a usar el modo de usuario en Linux</a></li>
<li><a href="../459560/index.html">Capacidades de los centros de datos de contenedores: centro de conmutaci√≥n listo para usar en Myanmar en 50 d√≠as</a></li>
<li><a href="../459564/index.html">Lo que los desarrolladores necesitan saber sobre negocios</a></li>
<li><a href="../459568/index.html">Letra vertical en TI moderna</a></li>
<li><a href="../459570/index.html">Beeline muestra anuncios al robot de Google. Bot infeliz</a></li>
<li><a href="../459574/index.html">Profundice en los espacios de nombres de Linux, parte 2</a></li>
<li><a href="../459576/index.html">Extensiones √∫tiles de Google Chrome para el programador</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🉑 🍼 💆🏾 Adaptation de la vidéo à un écran avec une fréquence de 1000 images / s 🧚 🧗🏿 📄</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La vidéo est projetée sur une feuille de papier en mouvement (à gauche) et sur le tissu déformant du T-shirt.
 
 Tout le monde a vu un projecteur numé...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Adaptation de la vidéo à un écran avec une fréquence de 1000 images / s</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/398539/"><img src="https://habrastorage.org/files/7bb/da5/1b8/7bbda51b819a477289b61b2a6a904233.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La vidéo est projetée sur une feuille de papier en mouvement (à gauche) et sur le tissu déformant du T-shirt.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Tout le monde a vu un projecteur numérique régulier qui projette la vidéo sur une surface plate et blanche - sur l'écran. De préférence dans l'obscurité. Les exigences pour l'écran sont très strictes: la beauté de l'image dépend en grande partie de sa qualité. Mais imaginez que le projecteur puisse projeter de la vidéo non seulement sur une surface plane, mais sur un tissu de toute forme, et même en </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mouvement</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ! Cette technologie incroyable a été développée par le personnel </font><font style="vertical-align: inherit;">du </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">laboratoire Ishikawa Watanabe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de l'Université de Tokyo.</font></font><br>
<a name="habracut"></a><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-bh1MHuA5jU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selon des ingénieurs japonais, l'amélioration technologique des projecteurs s'est figée sur place. Mais c'est une technologie importante qui s'étend, complète le monde réel. Théoriquement, les images et vidéos projetées peuvent être très utiles dans divers domaines de la réalité augmentée: de l'industrie du divertissement aux assistants numériques d'information qui affichent des informations contextuelles dans un endroit pratique, sur le verre de lunettes, un casque ou simplement sur un rideau dans la pièce. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La plupart des technologies modernes de projection d'images sont limitées aux surfaces statiques. Cela réduit considérablement leur portée.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les ingénieurs du laboratoire d'Isikawa Watanabe ont décidé de supprimer cette limitation en rendant les projecteurs plus adaptés au monde environnant dynamique, dans lequel la réalité change constamment de forme et de transformation. Dans la réalité augmentée du futur, les objets virtuels et le monde réel vont fusionner en une seule forme organique, parfaitement adaptée à la vision humaine. Idéalement, nous ne devrions pas faire de distinction entre les étiquettes de peinture et les projections numériques. Dans un avenir plus lointain, les objets «vivants» dynamiques tridimensionnels ne devraient pas différer beaucoup des objets réels du monde physique réel.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De quoi a-t-on besoin pour donner vie à cette idée? Tout d'abord, un projecteur haute vitesse avec une fréquence d'images par seconde exceptionnellement élevée et une faible latence est requis. C'est avec ces exigences </font><font style="vertical-align: inherit;">que le </font><font style="vertical-align: inherit;">projecteur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DynaFlash a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> été conçu </font><font style="vertical-align: inherit;">, qui projette des images 8 bits avec une fréquence d'images de 1000 images / s et un retard de seulement 3 millisecondes. </font></font><br>
<br>
<img src="https://habrastorage.org/files/e82/a0f/be3/e82a0fbe3e864dac9d1ac907f15fe9f4.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Projecteur numérique DynaFlash</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Les Japonais ne recherchent pas des moyens simples. Ils ne se sont pas arrêtés à la création d'un projecteur haute vitesse, mais sont allés plus loin - et ont compris comment le faire déformer l'image en fonction des déformations du tissu souple en temps quasi réel. Pourquoi? Par exemple, pour que le projecteur puisse projeter des vidéos sans distorsion sur des objets en mouvement. Par exemple, sur un T-shirt d'une personne en mouvement.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme vous pouvez le deviner, la projection à grande vitesse est effectuée via un suivi spécial, c'est-à-dire un suivi de surface. Il s'agit également d'une tâche extraordinaire dans le domaine de la vision par ordinateur. La tâche de suivre les surfaces froissées est compliquée par le fait que la surface peut se couvrir partiellement, sans parler de la fermeture partielle par des corps étrangers. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bien sûr, le suivi de la surface doit avoir lieu à la même vitesse élevée que celle du projecteur. La </font><font style="vertical-align: inherit;">technologie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deformable Dot Cluster Marker</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> a donc les mêmes caractéristiques techniques: 1000 images / s et un retard de 3 millisecondes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comment suivre la forme de la surface avec une telle précision et une telle vitesse? En principe, il existe également peu d'options. Les Japonais l'ont fait à travers une grille de marqueurs, qui est appliquée à l'objet. La conception de la grille des marqueurs est représentée dans des graphiques animés. </font></font><br>
<br>
<img src="https://habrastorage.org/files/1d7/2b1/248/1d72b12480a640d08247d7629cb3a5d6.gif"> <img src="https://habrastorage.org/files/a2c/c71/1b2/a2cc711b226f48789f54956e76a8ef6b.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le suivi à grande vitesse se produit sur une tâche hautement parallélisée dans de nombreux threads indépendants. Cependant, même sur le CPU, une performance de 1000 images par seconde est atteinte. </font></font><br>
<br>
<img src="https://habrastorage.org/files/8e1/ca5/0d7/8e1ca50d71224422baacc420af2a399e.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Convoyeur de reconnaissance de grille de marqueur</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Après </font><i><font style="vertical-align: inherit;">la</font></i><font style="vertical-align: inherit;"> reconnaissance de </font><i><font style="vertical-align: inherit;">grille de marqueur</font></i><font style="vertical-align: inherit;"> , le programme calcule rapidement les vecteurs de déformation de trame nécessaires dans la vidéo et projette le résultat en temps réel à l'aide du projecteur DynaFlash. </font></font><br>
<br>
<img src="https://habrastorage.org/files/289/10b/fa5/28910bfa571745bca4268acb72a7adbb.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Calcul des vecteurs dans le programme</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En général, selon la description, le système fonctionne de manière assez logique et simple. La question est la mise en œuvre technique - comment ont-ils réussi à optimiser cette tâche de vision industrielle pour des performances aussi élevées? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La réponse à cette question se trouve dans l'article " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dynamic Projection Mapping on Deforming Non-rigid Surface using Deformable Dot Cluster Marker</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ", que les auteurs ont publié dans </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IEEE Transactions on Visualization and Computer Graphics</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (doi: 10.1109 / TVCG.2016.2592910, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pdf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Il décrit en détail les algorithmes de calcul des vecteurs pour une grille de marqueurs, de mise à jour des positions des clusters de points suivis, de détection des faux positifs, d'interpolation des clusters perdus, etc. Les auteurs écrivent qu'ils ont utilisé le package OpenMP pour paralléliser les calculs. La reconnaissance par le programme du réseau de marqueurs et le suivi trame par trame ont nécessité respectivement moins de 2 ms et 1 ms, selon la forme de la distorsion. Le tableau compare le résultat avec un autre système DRDM que des collègues ont présenté au Symposium IEEE en 2011. </font></font><br>
<br>
<img src="https://habrastorage.org/files/822/8a0/5bc/8228a05bcbf14f4cb5b05c013d5d9cdd.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les auteurs sont convaincus que la nature organique de la réalité augmentée sur des objets du monde réel est une condition importante pour l'intégrité des impressions de ce type de réalité synthétique. Il ne devrait pas y avoir de retard important dans la projection de vidéo et de distorsion géométrique.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les gars du laboratoire d'Ishikawa Watanabe sont connus depuis longtemps pour leurs inventions inhabituelles et intéressantes. </font><font style="vertical-align: inherit;">Par exemple, en 2013, ils ont inventé le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">projecteur</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> haute vitesse </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">Lumipen</font></a><font style="vertical-align: inherit;"> , qui projette la vidéo sur des objets en mouvement.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ZuSUHuSceYc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une telle technologie peut trouver une application dans les jeux de réalité augmentée, où une personne interagit en réalité avec des objets virtuels, que ce soit un pokeball ou un ballon de football. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La projection de la réalité virtuelle sur des objets du monde réel est largement utilisée dans les parcs d'attractions du monde entier. </font><font style="vertical-align: inherit;">Il peut être utilisé dans les interfaces informatiques, le prototypage, l'enseignement avec un enseignant (par exemple, l'enseignement de la conduite d'une voiture) et de nombreux autres domaines.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr398539/">https://habr.com/ru/post/fr398539/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr398529/index.html">Batteries au lithium-soufre pour les futurs programmes spatiaux</a></li>
<li><a href="../fr398531/index.html">La tempête hexagonale sur Saturne a changé de couleur - et personne ne sait pourquoi</a></li>
<li><a href="../fr398533/index.html">Maison intelligente ou jouet pour homme: contrôle de l'électricité</a></li>
<li><a href="../fr398535/index.html">Il fait froid, il n'y a pas d'atmosphère, mais il y a un rayonnement dur? Super, il pourrait y avoir de la vie</a></li>
<li><a href="../fr398537/index.html">Les scientifiques ont découvert comment le cerveau humain s'adapte aux mensonges</a></li>
<li><a href="../fr398541/index.html">LinkedIn sera bloqué en Fédération de Russie</a></li>
<li><a href="../fr398543/index.html">Nouveau dans la gamme de projecteurs à domicile d'Epson: découvrez l'Epson EH-TW6700 / 6800/7300/9300 et le laser Epson LS10500</a></li>
<li><a href="../fr398545/index.html">Нажатия клавиатуры можно подслушать по Skype</a></li>
<li><a href="../fr398547/index.html">Génération d'images d'art dans un réseau neuronal formé pour reconnaître le porno</a></li>
<li><a href="../fr398549/index.html">Le sang de l'entrepôt n'est pas pire que du sang frais, et le sang des jeunes sera testé sur des vieux</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
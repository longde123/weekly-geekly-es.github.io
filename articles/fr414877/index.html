<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏾‍💼 🧗🏾 🗡️ Un objectif inhabituel pour un appareil photo ordinaire ou comment arrêter de penser à la mise au point 🍳 👲🏽 🕺🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Près de deux siècles d'existence de la caméra n'auraient pas dû laisser aux ingénieurs la possibilité d'ajouter «autre chose». Les caméras modernes to...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Un objectif inhabituel pour un appareil photo ordinaire ou comment arrêter de penser à la mise au point</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414877/">  Près de deux siècles d'existence de la caméra n'auraient pas dû laisser aux ingénieurs la possibilité d'ajouter «autre chose».  Les caméras modernes tournent des vidéos de haute qualité, téléchargent des photos dans le cloud et prennent des géo-tags.  Nous pouvons prendre des panoramas et 360 °, regarder les étoiles et ralentir le temps.  Mais les progrès ne s'arrêtent pas, mais se précipitent vers l'avenir, alimentés par des esprits curieux. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cb/co/ue/cbcoueypd1fnm9blmcb3ohpqyeu.png" alt="test d'image"></div><br>  La technologie dont il sera question aujourd'hui n'est pas nouvelle par nature.  Mais la façon dont il est mis en œuvre mérite certainement d'être examinée.  Ce sera un objectif à champ lumineux intéressant qui peut être utilisé avec n'importe quel appareil photo reflex numérique. <br><a name="habracut"></a><br><h2>  Qu'est-ce qu'un champ de Ligh et avec quoi mange-t-il? </h2><br>  Le terme <i>champ de lumière lui-</i> même a été proposé par le physicien soviétique Gershun en 1936 dans ses travaux sur les propriétés radiométriques de la lumière. <br><br>  Un champ lumineux est une fonction vectorielle qui décrit la lumière passant dans n'importe quelle direction à travers un point dans l'espace. <img src="https://habrastorage.org/webt/av/tv/ns/avtvnsfa4n-252jrwzy2cntdf5k.png" alt="image" align="right">  Un rayon de lumière (ou plutôt sa direction) pour un point donné de l’espace peut être décrit par cinq paramètres (la fonction dite de plénoptique 5D): <i>coordonnées x</i> , <i>y</i> , <i>z</i> et deux angles <i>θ</i> et <i>ϕ</i> .  En intégrant les vecteurs de champ obtenus à partir de différents points de vue, nous obtenons la valeur d'éclairage totale.  Et ayant une description complète des rayons lumineux dans l'espace, nous pouvons déterminer avec précision, par exemple, à quoi ressemble un objet de n'importe quel point de vue. <br><br>  Quelle est l'application pratique de la théorie du champ lumineux?  L'un des domaines les plus intéressants est celui des caméras à champ lumineux.  Contrairement aux caméras classiques, enregistrant l'intensité de la lumière aux points d'un objet, la caméra du champ lumineux prend également en compte la direction des rayons, sortants et ces points.  En d'autres termes, nous capturons les rayons de lumière «individuels» émanant de l'objet.  Et cela, à son tour, vous permet d'obtenir les coordonnées physiques des objets dans l'espace et une carte de profondeur. <br><br><h2>  Comment les caméras de champ lumineux sont-elles disposées? </h2><br>  Nous savons déjà qu'une caméra de ce type devrait enregistrer non seulement l'intensité, mais également la direction des rayons lumineux émanant de l'objet.  Une façon de mettre en œuvre cela consiste à utiliser un réseau de lentilles devant le capteur optique.  Ces lentilles collectent les rayons de lumière d'un objet situé dans une partie spécifique de la scène et les concentrent sur le capteur. <br><br>  Il est important de comprendre que dans ce cas, l'objectif principal de l'objectif ne focalise plus l'image sur le capteur.  Au lieu de cela, les rayons sont projetés sur le plan du réseau de lentilles (dans les caméras classiques, le capteur est situé exactement dans ce plan), le réseau de lentilles passe et ne tombe ensuite que sur le capteur, formant une image en mosaïque de différentes parties de la scène. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qf/gl/5i/qfgl5i2miblhvrhz_ge49lqfrnq.png" alt="image"></div><br>  La figure montre un schéma simplifié du fonctionnement d'un tel objectif.  Grâce à l'organisation astucieuse du système optique, nous obtenons finalement non pas une, mais de nombreuses images de l'objet, et chacune de ces images crée une représentation unique de l'objet sous son angle de vue unique. <br><br>  Cependant, ce schéma présente un certain nombre d'inconvénients, tels que le coût élevé de fabrication, la complexité de l'étalonnage, le contrôle de l'ouverture et d'autres paramètres du système.  L'un des exemples les plus célèbres de ces caméras est le produit de Lytro - la caméra Lytro Illum (le projet semble être gelé) <br><br><h2>  Pouvez-vous rendre cela plus facile? </h2><br>  Tu peux.  La lentille dont je veux parler dans cet article ne contient pas une gamme de micro-lentilles.  Au lieu de cela, un système est utilisé, qui est un «canal» de miroir à section rectangulaire (boîte à miroir), où, grâce à la réflexion multiple, une image dite kaléidoscopique est formée, qui est enregistrée par le capteur de la caméra de la manière habituelle. <br><br><img src="https://habrastorage.org/webt/jp/gt/dh/jpgtdhotrubcdjqctkx1ypxtxv8.png" alt="image"><br><br>  Une petite entreprise allemande se développe.  L'objectif est au stade d'un prototype pleinement fonctionnel, et le principe de son fonctionnement est assez simple. <br><br>  Les images obtenues par le système ressemblent à ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bc/0z/u9/bc0zu9ojlfgakmjvfyu2ed6j6og.png" alt="image"></div><br>  Les éléments ici sont reflétés.  Une telle image kaléidoscopique inhabituelle est une conséquence de la réflexion des rayons dans le «canal miroir». <br><br>  Et voici à quoi ressemble la différence absolue de la paire d'éléments récupérés (les pixels lumineux signifient une plus grande différence de valeurs): <br><br><img src="https://habrastorage.org/webt/e1/t5/po/e1t5poethhxhqe9f2i8xmplliys.png" alt="image"><br><br>  En d'autres termes, nous n'avons rien d'autre qu'une paire stéréo.  Ou plutôt, stéréo neuf (éléments 3x3).  En changeant les paramètres géométriques du canal, nous pouvons obtenir 5x5 et même de grandes dimensions, ce qui, cependant, n'a aucun sens dans la vie réelle et même nuit. <br><br>  Nous avons donc un ensemble d'images formant une image kaléidoscopique.  Et ensuite? <br><br>  C'est là que le matériel optique analogique chaud se termine et que le soft numérique froid commence. <br><br><h2>  Calibration </h2><br>  Quelle que soit l'application, les images doivent être restaurées (vous devez calibrer l'ensemble du système optique et appliquer les données d'étalonnage obtenues aux images).  Le processus est assez fastidieux, mais important, car les différents éléments de l'image kaléidoscopique doivent nécessairement être «coordonnés» entre eux (même insignifiants / plusieurs pixels / écarts des éléments peuvent gâcher considérablement le résultat et l'impression).  Il existe de nombreux travaux sur le thème de l'étalonnage, il est donc inutile de révéler des détails.  Vous devez juste vous rappeler que l'étalonnage est très important pour toute application stéréo. <br><br><h2>  Carte de profondeur </h2><br>  Après avoir reçu des images «paires», nous pouvons construire une carte de profondeur. <br>  C'est peut-être la partie la plus importante et la plus difficile du pipeline.  La qualité de l'application finale dépend de la qualité de la carte de profondeur.  Et la qualité de la carte de profondeur, à son tour, dépend de la qualité de l'étalonnage, de l'algorithme sélectionné et de la "complexité" de la scène. <br><br>  Mais quel que soit l'algorithme, la tâche est toujours la même: trouver les points correspondants des images gauche et droite (et dans notre cas + 7 images supplémentaires) et calculer la distance (disparité) entre elles.  La valeur de distance sera l'inverse de la valeur de profondeur pour un pixel donné. <br><br>  Pourquoi utiliser 9 images si vous vous entendez avec deux?  Évidemment, en utilisant plus d'images, nous avons plus d'informations sur la scène et pouvons résoudre partiellement certains problèmes des algorithmes existants pour estimer la carte de profondeur. <br><br>  Parmi les problèmes classiques de tels algorithmes: <br><br><ul><li>  Surfaces monotones monochromes sans texture - l'algorithme n'a tout simplement rien à «attraper» dans le processus de recherche de correspondances </li><li>  Objets superposés (visibles d'un coin et invisibles d'un autre) </li><li>  Ombres et reflets sur des surfaces réfléchissantes ou brillantes </li><li>  Les structures régulières telles que les cellules et les rayures posent des problèmes, car il n'est pas toujours clair quelle cellule de l'image A correspond à la cellule de l'image B. </li><li>  Bordures d'images - un problème similaire au problème des objets qui se chevauchent.  Aux frontières des images, les informations sont inévitablement perdues sous tous les angles. </li></ul><br>  Il existe de nombreux algorithmes de qualité et peu nombreux pour construire une carte de profondeur.  Les développements les plus prometteurs se situent désormais dans le domaine des approches hybrides utilisant des méthodes classiques et diverses techniques d'apprentissage automatique (CNN, DNN).  Comme toujours, le choix de l'algorithme est un compromis entre vitesse et qualité.  Heureusement, en photographie, nous pouvons nous permettre de prendre du recul en temps réel et d'obtenir une meilleure carte de profondeur. <br><br>  Pour notre exemple, la carte de profondeur ressemble à ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lk/a5/p2/lka5p2k7vkqazvlzads_pqai9y4.png" alt="image"></div><br><br><h2>  Post focus </h2><br>  Nous avons une carte des profondeurs, que faire maintenant?  Les informations sur l'éloignement des objets sont souvent utiles.  Une application populaire est le post focus. <br><br>  La mise au point est l'un des problèmes des photographes.  Avez-vous remarqué que dans l'image d'origine, toute la scène était nette?  Voici à quoi ressemble la post-focalisation basée sur une carte de profondeur: <br><br><img src="https://habrastorage.org/webt/5q/qy/dp/5qqydpw85mv-p_b0hzock0cqi20.png" alt="image"><br><br>  Il convient de noter qu'avec cette approche, nous nous débarrassons en fait des propriétés physiques du système optique.  Cela permet, par exemple, de créer une image algorithmique avec plusieurs astuces.  Ou modifiez par programme la profondeur d'un espace clairement représenté (Profondeur de champ). <br><br><h2>  Autres applications </h2><br>  La post-mise au point est la principale mais pas toujours la seule application.  En général, cet objectif peut être considéré comme un ensemble de caméras virtuelles (9 pièces).  En conséquence, il est applicable à toutes les applications que vous pouvez imaginer pour un ensemble de caméras, par exemple: <br><br><ul><li>  Filtres de polarisation - chacun des 9 éléments d'image a son propre filtre de polarisation avec une direction donnée.  Cela vous permet d'obtenir 9 images avec différentes polarisations en une seule fois et même de créer une série vidéo d'un changement en douceur de la direction de la polarisation </li><li>  HDR (High-Dynamic-Range) - le même principe: 9 filtres différents + algorithme pour la "combinaison" optimale de luminosité </li><li>  Changement de perspective </li><li>  Édition basée sur la profondeur - vous permet d'appliquer divers filtres à différentes profondeurs.  Par exemple, créez l'arrière-plan en noir et blanc, en mettant en évidence le premier plan. </li><li>  Segmentation - sélection d'objets situés à une certaine distance </li><li>  Mesure de distance - une règle pour les images.  Cela fonctionne particulièrement bien pour les scènes «superficielles» pour lesquelles la disparité est plus facile à calculer. </li><li>  Applications pour l'industrie - différentes façons d'évaluer la qualité et le suivi de la production </li></ul><br><h2>  Conclusion </h2><br>  La question du coût final de cet objectif est toujours ouverte, mais certains paramètres physiques ont déjà été déterminés.  Il est connu que la longueur ne doit pas dépasser 20 cm et la masse - 800 g.  Il est précisé que cet appareil sera principalement compatible avec les appareils photo Sony, Canon et Nikon. <br><br>  En dehors de l'article, il restait des sujets importants tels que l'utilisation pratique de caméras standard avec viseurs, la restauration de la résolution (super-résolution), les algorithmes de traitement et l'intégration avec des éditeurs graphiques.  Je vais en parler la prochaine fois. <br><br>  Merci de votre attention! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr414877/">https://habr.com/ru/post/fr414877/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr414867/index.html">ThinkingHome.Migrator - migration versionnée du schéma de base de données sur la plate-forme .NET Core</a></li>
<li><a href="../fr414869/index.html">Cadres en voie de disparition</a></li>
<li><a href="../fr414871/index.html">La tempête de poussière sur Mars a atteint l'échelle planétaire, même la curiosité est affectée</a></li>
<li><a href="../fr414873/index.html">IDisposable - que votre maman n'a pas parlé de libérer des ressources. Partie 1</a></li>
<li><a href="../fr414875/index.html">L'intégration Kubernetes Container remplace Docker prêt pour la production</a></li>
<li><a href="../fr414879/index.html">Pourquoi 2 extrudeuses dans une imprimante 3D?</a></li>
<li><a href="../fr414881/index.html">Un peu de VK dans les coulisses</a></li>
<li><a href="../fr414883/index.html">Les souvenirs résonnaient d'une manière nouvelle: la BBC a mis à jour les archives sonores du projet RemArc</a></li>
<li><a href="../fr414885/index.html">Nous traitons les erreurs et les «béquilles» dans le Registre d'État unifié des entités juridiques - le registre d'État des entités juridiques</a></li>
<li><a href="../fr414887/index.html">Création d'un crochet pour chat dans Unity. Partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
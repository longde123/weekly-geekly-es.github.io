<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎏 🕤 🧝🏼 Registro de eventos con Kafka 🙇🏼 🧑🏼 📂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! 

 Descubrimos las últimas reservas del libro " Apache Kafka. Procesamiento de flujo y análisis de datos " y lo enviamos a la preimpresión....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Registro de eventos con Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/424739/"> Hola Habr! <br><br>  Descubrimos las últimas reservas del libro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Kafka. Procesamiento de flujo y análisis de datos</a> " y lo enviamos a la preimpresión.  Además, hemos recibido un contrato para el libro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kafka Streams in Action</a> " y comenzamos a traducirlo literalmente la próxima semana. <br><br><img src="https://habrastorage.org/webt/re/29/51/re2951jsut-yre1r79xmmt4ibdy.jpeg"><br><br>  Para mostrar el interesante caso de usar la biblioteca Kafka Streams, decidimos traducir el artículo sobre el paradigma de Abastecimiento de eventos en Kafka del mismo Adam Worski, cuyo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículo</a> sobre el lenguaje Scala se publicó hace dos semanas.  Es aún más interesante que la opinión de Adam Worski no sea innegable: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> , por ejemplo, se argumenta que este paradigma definitivamente no es adecuado para Kafka.  Aún más memorable, esperamos, tenemos la impresión del artículo. <br><br>  El término "Abastecimiento de eventos" se traduce como "Registro de eventos" tanto en nuestra publicación de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Clean Architecture por</a> Robert Martin como en este artículo.  Si alguien está impresionado por la traducción de "eventos de bombeo", hágamelo saber. <br><a name="habracut"></a><br>  Al crear un sistema que proporciona registro de eventos (fuente de eventos), tarde o temprano nos enfrentamos al problema de la persistencia (persistencia), y aquí tenemos un par de opciones.  En primer lugar, está <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">EventStore</a> , una implementación madura reforzada en la batalla.  Alternativamente, puede usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">akka-persistence</a> para aprovechar al máximo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la</a> escalabilidad de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cassandra</a> , así como confiar en el rendimiento del modelo de actor.  Otra opción es la buena y antigua <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">base de datos relacional</a> , donde el enfoque <code>CRUD</code> se combina con el uso de eventos y el máximo beneficio se exprime de las transacciones. <br><br>  Además de estas (y, quizás, muchas otras) oportunidades que han surgido gracias a varias cosas implementadas recientemente, hoy se ha vuelto bastante simple organizar el registro de eventos sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kafka</a> .  Veamos cómo. <br><br>  <b>¿Qué es el registro de eventos?</b> <br><br>  Hay una serie de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">excelentes</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículos</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">introductorios</a> sobre este tema, por lo que me limitaré a la introducción más concisa.  Al registrar eventos, no guardamos el estado "actual" de las entidades utilizadas en nuestro sistema, sino el flujo de eventos relacionados con estas entidades.  Cada <i>evento</i> es un <b>hecho</b> que describe un cambio de estado (¡ya!) Que ha <b>ocurrido</b> con el objeto.  Como saben, los hechos no se discuten ni se <b>modifican</b> . <br><br>  Cuando tenemos una secuencia de tales eventos, el estado actual de una entidad puede aclararse minimizando todos los eventos relacionados con ella;  sin embargo, tenga en cuenta que lo contrario no es posible: preservando solo el estado "actual", descartamos mucha información cronológica valiosa. <br><br>  El registro de eventos puede <b>coexistir</b> pacíficamente con formas más tradicionales de almacenar el estado.  Como regla, el sistema procesa varios tipos de entidades (por ejemplo: usuarios, pedidos, bienes, ...) y es muy posible que el registro de eventos sea útil solo para algunas de estas categorías.  Es importante tener en cuenta que aquí no nos enfrentamos a la elección de "todo o nada";  se trata solo de la función de administración de estado adicional en nuestra aplicación. <br><br>  <b>Almacenamiento de eventos en Kafka</b> <br><br>  El primer problema a resolver: ¿cómo almacenar eventos en Kafka?  Hay tres estrategias posibles: <br><br><ul><li>  Almacene todos los eventos para todo tipo de entidades en un <b>solo tema</b> (con muchos segmentos) </li><li>  Por tema por tipo de entidad, es decir, eliminamos todos los eventos relacionados con el usuario en un tema separado, en un tema separado, todos relacionados con el producto, etc. </li><li>  Por tema por esencia, es decir, por un tema separado para cada usuario específico y cada nombre de producto </li></ul><br>  La tercera estrategia (tema por esencia) es prácticamente impracticable.  Si, cuando cada nuevo usuario apareciera en el sistema, tuviera que comenzar un tema separado, pronto el número de temas sería ilimitado.  Cualquier agregación en este caso sería muy difícil, por ejemplo, sería difícil indexar a todos los usuarios en un motor de búsqueda;  no solo tendría que consumir una gran cantidad de temas, sino que no todos se conocían de antemano. <br><br>  Por lo tanto, queda elegir entre 1 y 2. Ambas opciones tienen sus ventajas y desventajas.  Tener un solo tema hace que sea más fácil obtener una <b>visión global</b> de todos los eventos.  Por otro lado, al resaltar el tema para cada tipo de entidad, puede escalar y segmentar el flujo de cada entidad individualmente.  La elección de una de dos estrategias depende del caso de uso específico. <br><br>  Además, puede implementar ambas estrategias a la vez, si tiene espacio de almacenamiento adicional: produzca temas por tipo de entidad a partir de un tema completo. <br><br><img src="https://habrastorage.org/webt/1i/lg/v4/1ilgv4fs1_uoaw6uximo7fy9e7k.png"><br><br>  En el resto del artículo, trabajaremos con un solo tipo de entidad y con un solo tema, aunque el material presentado puede extrapolarse fácilmente y aplicarse para trabajar con muchos temas o tipos de entidad. <br><br>  (EDITAR: como señaló <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Chris Hunt</a> , hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un excelente artículo de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Martin Kleppman</a> , que examinó en detalle cómo distribuir eventos por tema y segmento). <br><br>  <b>Las operaciones de almacenamiento más simples en el paradigma de registro de eventos.</b> <br><br>  La operación más simple, que es lógico esperar de una tienda que admite el registro de eventos, es leer el estado "actual" (minimizado) de una entidad particular.  Como regla general, cada entidad tiene una u otra <code>id</code> .  En consecuencia, conociendo esta <code>id</code> , nuestro sistema de almacenamiento debería devolver el estado actual del objeto. <br><br>  La verdad en el último recurso será el registro de eventos: el estado actual siempre se puede deducir de la secuencia de eventos asociados con una entidad en particular.  Para esto, el motor de la base de datos necesitará una función pura (sin efectos secundarios) que acepte el evento y el estado inicial, y devuelva el estado modificado: <code>Event = &amp;gt State =&amp;gt State</code> .  En presencia de dicha función y el <b>valor del estado inicial, el</b> estado actual es una <b>convolución del</b> flujo de eventos (la función de cambio de estado debe estar <b>limpia</b> para que pueda aplicarse libremente repetidamente a los mismos eventos). <br><br>  Una implementación simplificada de la operación "leer el estado actual" en Kafka recopila una secuencia de <b>todos los</b> eventos del tema, los filtra, dejando solo eventos con la <code>id</code> dada y colapsa usando la función especificada.  Si hay muchos eventos (y con el tiempo el número de eventos solo aumenta), esta operación puede ser lenta y consumir muchos recursos.  Incluso si su resultado se almacenará en la memoria caché y se almacenará en el nodo de servicio, esta información deberá volver a crearse periódicamente, por ejemplo, debido a fallas en los nodos o debido a la exclusión de los datos de la memoria caché. <br><br><img src="https://habrastorage.org/webt/r5/te/aa/r5teaa64otzjedcvs0g1snt9lj8.png"><br><br>  Por lo tanto, se necesita una forma más racional.  Aquí es donde los flujos de kafka y los repositorios de estado son útiles.  Las aplicaciones Kafka-streams se ejecutan en un grupo completo de nodos que consumen ciertos temas juntos.  A cada nodo se le asigna una serie de segmentos de temas consumidos, al igual que con el consumidor habitual de Kafka.  Sin embargo, kafka-streams proporciona operaciones de datos de nivel superior que hacen que sea mucho más fácil crear flujos derivados. <br><br>  Una de esas operaciones en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">kafka-streams</a> es la convolución de un flujo en el almacenamiento local.  Cada almacenamiento local contiene datos de solo aquellos segmentos que son consumidos por un nodo dado.  Fuera de la caja, hay dos implementaciones de almacenamiento local disponibles: <i>en RAM</i> y basadas en <i>RocksDB</i> . <br><br>  Volviendo al tema del registro de eventos, observamos que es posible contraer la secuencia de eventos en <b>la tienda de estado</b> manteniendo en el nodo local el "estado actual" de cada entidad de los segmentos asignados al nodo.  Si utilizamos la implementación del almacén de estado basado en RocksDB, entonces cuántas entidades podemos rastrear en un solo nodo solo depende de la cantidad de espacio en disco. <br><br>  Así es como se ve la convolución de eventos en el almacenamiento local cuando se usa la API de Java (serde significa "serializador / deserializador"): <br><br><pre> <code class="java hljs">KStreamBuilder builder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KStreamBuilder(); builder.stream(keySerde, valueSerde, <span class="hljs-string"><span class="hljs-string">"my_entity_events"</span></span>) .groupByKey(keySerde, valueSerde) <span class="hljs-comment"><span class="hljs-comment">//  :     .reduce((currentState, event) -&gt; ..., "my_entity_store"); .toStream(); //     return builder;</span></span></code> </pre> <br>  Un ejemplo completo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de procesamiento de pedidos basado en microservicios</a> está disponible en el sitio web de Confluent. <br><br>  (EDITAR: como señalaron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Sergei Egorov</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nikita Salnikov</a> en Twitter, para un sistema con registro de eventos, probablemente deba cambiar la configuración predeterminada de almacenamiento de datos en Kafka para que no funcionen los límites de tiempo o tamaño, y también, opcionalmente , habilite la compresión de datos). <br><br>  <b>Ver estado actual</b> <br><br>  Hemos creado un repositorio de estados donde se encuentran los estados actuales de todas las entidades que provienen de los segmentos asignados al nodo, pero ¿cómo solicitar este repositorio ahora?  Si la solicitud es local (es decir, proviene del mismo nodo donde se encuentra el repositorio), entonces todo es bastante simple: <br><br><pre> <code class="java hljs">streams .store(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, QueryableStoreTypes.keyValueStore()); .get(entityId);</code> </pre> <br>  Pero, ¿qué pasa si queremos solicitar datos ubicados en otro nodo?  ¿Y cómo averiguar qué es este nodo?  Aquí, otra característica recientemente introducida en Kafka es útil: <b>consultas interactivas</b> .  Con su ayuda, puede acceder a los metadatos de Kafka y descubrir qué nodo procesa el segmento del tema con la <code>id</code> dada (en este caso, la herramienta para la segmentación del tema se usa implícitamente): <br><br><pre> <code class="java hljs">metadataService .streamsMetadataForStoreAndKey(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, entityId, keySerde)</code> </pre> <br>  A continuación, debe redirigir de alguna manera la solicitud al nodo correcto.  Tenga en cuenta: la forma específica en que se implementa y maneja la comunicación entre sitios, ya sea REST, akka-remote o cualquier otro, no pertenece al área de responsabilidad de kafka-streams.  Kafka simplemente proporciona acceso a la tienda de estado y proporciona información sobre el nodo en el que se encuentra la tienda de estado para la <code>id</code> dada. <br><br>  <b>Recuperación ante desastres</b> <br><br>  Las tiendas estatales se ven bien, pero ¿qué sucede cuando falla un nodo?  Reconstruir una tienda estatal local para un segmento dado también puede ser una operación costosa.  Puede provocar mayores demoras o pérdida de solicitudes durante mucho tiempo, ya que será necesario reequilibrar los flujos de kafka (después de agregar o eliminar un nodo). <br><br>  Es por eso que, de forma predeterminada, los almacenes de estado a largo plazo se registran: es decir, todos los cambios realizados en la tienda se escriben adicionalmente en el tema changelog-topic.  Este tema está comprimido (porque para cada <code>id</code> solo nos interesa el último registro, sin un historial de cambios, ya que el historial se almacena en los eventos mismos), por lo tanto, es lo más pequeño posible.  Es por eso que la recreación del almacenamiento en otro nodo puede ocurrir mucho más rápido. <br><br>  Sin embargo, con el reequilibrio en este caso, las demoras aún son posibles.  Para reducirlos aún más, kafka-streams brinda la capacidad de contener múltiples <b>réplicas de respaldo</b> ( <code>num.standby.replicas</code> ) para cada repositorio.  Estas réplicas aplican todas las actualizaciones recuperadas de los temas con registros de cambios a medida que están disponibles, y están listas para cambiar al modo de almacén de estado principal para un segmento determinado tan pronto como falle el almacén principal actual. <br><br>  <b>Coherencia</b> <br><br>  Con la configuración predeterminada, Kafka proporciona al menos una entrega única.  Es decir, en caso de falla de un nodo, algunos mensajes pueden entregarse varias veces.  Por ejemplo, es posible que un evento en particular se aplique dos veces al almacén de estado si el sistema se bloquea después de que el almacén de estado cambie al registro, pero antes de que se realice el desplazamiento para este evento en particular.  Quizás esto no cause ninguna dificultad: nuestra función de actualización de estado ( <code>Event = &amp;gt State =&amp;gt State</code> ) normalmente puede hacer frente a tales situaciones.  Sin embargo, es posible que no pueda hacer frente: en tal caso, se pueden utilizar las garantías de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">entrega estrictamente única</a> proporcionadas por Kafka.  Dichas garantías solo se aplican al leer y escribir temas de Kafka, pero esto es lo que estamos haciendo aquí: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en el fondo, todas las entradas en los temas de Kafka se reducen a actualizar el registro de cambios para la tienda estatal</a> y realizar compensaciones.  Todo esto se puede hacer <b>en forma de transacciones</b> . <br><br>  Por lo tanto, si nuestra función de actualizar el estado lo requiere, podemos habilitar la semántica del procesamiento de flujos "estrictamente de una sola vez" utilizando una única opción de configuración: <code>processing.guarantee</code> .  Debido a esto, el rendimiento cae, pero nada es en vano. <br><br>  <b>Escucha del evento</b> <br><br>  Ahora que hemos cubierto los conceptos básicos: consultar el "estado actual" y actualizarlo para cada entidad, ¿qué pasa con la activación de <b>los efectos secundarios</b> ?  En algún momento, esto será necesario, por ejemplo, para: <br><br><ul><li>  Enviar correos electrónicos de notificación </li><li>  Indexación de entidades del motor de búsqueda </li><li>  Llamar a servicios externos a través de REST (o SOAP, CORBA, etc.) </li></ul><br>  Todas estas tareas son, en un grado u otro, bloqueantes y relacionadas con las operaciones de E / S (esto es natural para los efectos secundarios), por lo que probablemente no sea una buena idea ejecutarlas dentro del marco de la lógica de actualización de estado: como resultado, la frecuencia de fallas en el bucle principal puede aumentar eventos, y en términos de rendimiento habrá un cuello de botella. <br><br>  Además, una función con lógica de actualización de estado (E <code>Event = &amp;gt State =&amp;gt State</code> ) se puede ejecutar varias veces (en caso de fallas o reinicios), y la mayoría de las veces queremos minimizar el número de casos en los que los efectos secundarios para un evento en particular se ejecutan varias veces. <br><br>  Afortunadamente, dado que trabajamos con temas de Kafka, tenemos bastante flexibilidad.  En la etapa de flujos, donde se actualiza el almacén de estado, los eventos se pueden emitir sin cambios (o, si es necesario, también en una forma modificada), y la secuencia / tema resultante (en Kafka, estos conceptos son equivalentes) se pueden consumir a su gusto.  Además, se puede consumir antes o después de la etapa de actualización de estado.  Finalmente, podemos controlar cómo lanzamos los efectos secundarios: al menos una vez o máximo una vez.  La primera opción se proporciona si realiza el desplazamiento del tema-evento consumido solo después de que todos los efectos secundarios se hayan completado con éxito.  Por el contrario, con un máximo de una carrera, realizamos turnos hasta que comiencen los efectos secundarios. <br><br>  Hay varias opciones para desencadenar efectos secundarios, que dependen de la situación práctica específica.  En primer lugar, puede definir la etapa Kafka-streams donde se activan los efectos secundarios para cada evento como parte de la función de procesamiento de stream. <br>  Configurar dicho mecanismo es bastante simple, pero esta solución no es flexible cuando tiene que lidiar con reintentos, controlar compensaciones y competir con compensaciones para muchos eventos a la vez.  En estos casos más complejos, puede ser más apropiado determinar el procesamiento utilizando, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">reactivo-kafka</a> u otro mecanismo que consume los temas de Kafka "directamente". <br><br>  También es posible que un evento <b>desencadene otros eventos</b> ; por ejemplo, el evento "pedido" puede desencadenar los eventos de "preparación para el envío" y "notificación al cliente".  Esto también se puede implementar en la etapa kafka-streams. <br><br>  Finalmente, si quisiéramos almacenar eventos o algunos datos extraídos de eventos en una base de datos o motor de búsqueda, por ejemplo, en ElasticSearch o PostgreSQL, podríamos usar el conector <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kafka Connect</a> , que procesará para nosotros todos los detalles relacionados con el consumo de temas. <br><br>  <b>Crear vistas y proyecciones</b> <br><br>  Por lo general, los requisitos del sistema no se limitan a consultar y procesar solo flujos de entidades individuales.  Agregación, combinación de múltiples secuencias de eventos también debe ser compatible.  Tales flujos combinados a menudo se denominan <b>proyecciones</b> y, cuando se colapsan, se pueden usar para crear <b>representaciones de datos</b> .  ¿Es posible implementarlos con Kafka? <br><br><img src="https://habrastorage.org/webt/yc/r2/jt/ycr2jtvibrdg7wy0lhin1ehwu1y.png"><br><br>  De nuevo, si!  Recuerde que, en principio, estamos tratando simplemente con el tema de Kafka, donde se almacenan nuestros eventos;  por lo tanto, tenemos todo el poder de los Consumidores / Productores de Kafka sin procesar, el combinador de flujos de kafka e incluso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">KSQL</a> ; todo esto será útil para que definamos las proyecciones.  Por ejemplo, usando kafka-streams puede filtrar un flujo, mostrar, agrupar por clave, agregar en ventanas temporales o de sesión, etc.  ya sea a nivel de código o usando KSQL similar a SQL. <br><br>  Dichos flujos pueden almacenarse y proporcionarse para consultas durante mucho tiempo utilizando almacenes de estado y consultas interactivas, tal como lo hicimos con los flujos de entidades individuales. <br><br>  <b>Que sigue</b> <br><br>  Para evitar el flujo infinito de eventos a medida que se desarrolla el sistema, puede ser útil una opción de compresión como guardar <b>instantáneas del</b> "estado actual".  Por lo tanto, podemos limitarnos a almacenar solo unas pocas instantáneas recientes y aquellos eventos que ocurrieron después de su creación. <br><br>  Aunque Kafka no tiene soporte directo para instantáneas (y en algunos otros sistemas que operan según el principio de grabación de eventos, sí lo es), definitivamente puede agregar este tipo de funcionalidad usted mismo, utilizando algunos de los mecanismos anteriores, como transmisiones, consumidores, tiendas estatales, etc. d. <br><br>  <b>Resumen</b> <br><br>  Aunque, inicialmente, Kafka no se diseñó teniendo en cuenta el paradigma de registro de eventos, de hecho es un motor de transmisión de datos con soporte para <b>replicación de temas</b> , segmentación, <b>repositorios de estado</b> y <b>API de transmisión</b> , y es muy flexible al mismo tiempo.  Por lo tanto, además de Kafka, puede implementar fácilmente un sistema de registro de eventos.  Además, dado que en el contexto de todo lo que sucede, siempre tendremos un tema de Kafka, obtendremos flexibilidad adicional, ya que podemos trabajar con API de transmisión de alto nivel o consumidores de bajo nivel. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es424739/">https://habr.com/ru/post/es424739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es424729/index.html">¿Por qué el compilador convirtió mi bucle condicional en un infinito?</a></li>
<li><a href="../es424731/index.html">Historial de soporte técnico, o ¿Por qué AutoCAD elimina objetos proxy?</a></li>
<li><a href="../es424733/index.html">Pastilla azul STM32F103 como PLC</a></li>
<li><a href="../es424735/index.html">¿Cómo funciona? ¿Funciona la psicoterapia conversacional?</a></li>
<li><a href="../es424737/index.html">42º protocolo de vida, el universo y todo eso: "discurso de despedida"</a></li>
<li><a href="../es424741/index.html">Chicos, vivamos en paz o sobre el campo Contraseña al registrarse</a></li>
<li><a href="../es424745/index.html">La actividad de GosSOPKI ha aumentado</a></li>
<li><a href="../es424747/index.html">El lugar donde vive el sonido.</a></li>
<li><a href="../es424751/index.html">Cómo funciona el sistema biométrico unificado</a></li>
<li><a href="../es424753/index.html">Novedades de YouTrack 2018.3</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
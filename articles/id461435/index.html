<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüé® #‚É£ ü¶î Pengenalan emosi menggunakan jaringan saraf convolutional üö¶ üë¥üèø üé∏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mengenali emosi selalu menjadi tantangan yang menarik bagi para ilmuwan. Baru-baru ini, saya telah mengerjakan proyek SER eksperimental (Pengenalan Em...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengenalan emosi menggunakan jaringan saraf convolutional</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/461435/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/4f/gh/qr/4fghqrzh79wxguvk28uxvxg1ice.png"></div><br>  Mengenali emosi selalu menjadi tantangan yang menarik bagi para ilmuwan.  Baru-baru ini, saya telah mengerjakan proyek SER eksperimental (Pengenalan Emosi Pidato) untuk memahami potensi teknologi ini - untuk ini saya memilih repositori paling populer di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Github</a> dan menjadikannya dasar proyek saya. <br><br>  Sebelum kita mulai memahami proyek ini, alangkah baiknya mengingat jenis kemacetan yang dimiliki SER. <br><a name="habracut"></a><br><h2>  Hambatan utama </h2><br><ul><li>  emosi bersifat subjektif, bahkan orang menafsirkannya secara berbeda.  Sulit untuk mendefinisikan konsep "emosi"; </li><li>  mengomentari audio sulit.  Haruskah kita menandai setiap kata, kalimat, atau keseluruhan komunikasi secara keseluruhan sebagai satu kesatuan?  Seperangkat emosi seperti apa yang digunakan dalam pengakuan? </li><li>  mengumpulkan data juga tidak mudah.  Banyak data audio dapat dikumpulkan dari film dan berita.  Namun, kedua sumber itu ‚Äúbias‚Äù karena berita harus netral, dan emosi para aktor dimainkan.  Sulit untuk menemukan sumber data audio yang ‚Äúobyektif‚Äù. </li><li>  data markup membutuhkan sumber daya manusia dan waktu yang besar.  Tidak seperti menggambar bingkai pada gambar, itu membutuhkan personel terlatih khusus untuk mendengarkan seluruh rekaman audio, menganalisisnya dan memberikan komentar.  Dan kemudian komentar ini harus dihargai oleh <b>banyak</b> orang lain, karena peringkatnya subjektif. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6a/kn/wc/6aknwc9ko-dj-nzw2dmlvfb31ry.png"></div><br><h2>  Deskripsi Proyek </h2><br>  Menggunakan jaringan saraf convolutional untuk mengenali emosi dalam rekaman audio.  Dan ya, pemilik repositori tidak merujuk ke sumber apa pun. <br><br><h2>  Deskripsi Data </h2><br>  Ada dua set data yang digunakan dalam repositori RAVDESS dan SAVEE, saya baru saja mengadaptasi RAVDESS dalam model saya.  Ada dua jenis data dalam konteks RAVDESS: pidato dan lagu. <br><br>  Dataset <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">RAVDESS (The Ryerson Audio-Visual Database of Emotional Speech and Song)</a> : <br><br><ul><li>  12 aktor dan 12 aktris merekam pidato dan lagu mereka dalam penampilan mereka; </li><li>  aktor # 18 tidak memiliki lagu yang direkam; </li><li>  Emosi Jijik (jijik), Netral (netral) dan Kejutan (terkejut) tidak ada dalam data "lagu". </li></ul><br>  Rincian Emosi: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ed/c1/zk/edc1zkhvwub39whbvy-v61kt9vk.png"></div><br>  Bagan Distribusi Emosi: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gq/un/1a/gqun1a1oud8gnesmrvkt6jtnwmu.png"></div><br><h3>  Ekstraksi fitur </h3><br>  Ketika kami bekerja dengan tugas-tugas pengenalan ucapan, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Koefisien Cepstral (MFCCs)</a> adalah teknologi canggih, terlepas dari kenyataan bahwa itu muncul di tahun 80-an. <br><br>  Kutipan dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tutorial MFCC</a> : <br><blockquote>  Bentuk ini menentukan apa suara output.  Jika kita dapat menentukan bentuk, itu akan memberi kita representasi akurat dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">fonem yang</a> dibunyikan.  Bentuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">saluran suara</a> memanifestasikan dirinya dalam amplop spektrum pendek, dan tugas MFCC adalah menampilkan amplop ini secara akurat. </blockquote><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nv/id/_7/nvid_7_cvd_qg9puppfec9riswk.png"></div><br>  <font color="grey">Bentuk gelombang</font> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wz/5d/rl/wz5drlsibxxjtuu4azisa7grico.png"></div><br>  <font color="grey">Spektrogram</font> <br><br>  Kami menggunakan MFCC sebagai fitur input.  Jika Anda tertarik untuk mempelajari lebih lanjut tentang apa itu MFCC, maka <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tutorial</a> ini cocok untuk Anda.  Mengunduh data dan mengonversinya ke format MFCC dapat dengan mudah dilakukan dengan menggunakan paket librosa Python. <br><br><h3>  Arsitektur Model Default </h3><br>  Penulis mengembangkan model CNN menggunakan paket Keras, membuat 7 lapisan - enam lapisan Con1D dan satu lapisan kepadatan (Padat). <br><br><pre><code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>,padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">216</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>))) <span class="hljs-comment"><span class="hljs-comment">#1 model.add(Activation('relu')) model.add(Conv1D(128, 5,padding='same')) #2 model.add(Activation('relu')) model.add(Dropout(0.1)) model.add(MaxPooling1D(pool_size=(8))) model.add(Conv1D(128, 5,padding='same')) #3 model.add(Activation('relu')) #model.add(Conv1D(128, 5,padding='same')) #4 #model.add(Activation('relu')) #model.add(Conv1D(128, 5,padding='same')) #5 #model.add(Activation('relu')) #model.add(Dropout(0.2)) model.add(Conv1D(128, 5,padding='same')) #6 model.add(Activation('relu')) model.add(Flatten()) model.add(Dense(10)) #7 model.add(Activation('softmax')) opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)</span></span></code> </pre> <br><blockquote>  Penulis berkomentar pada layer 4 dan 5 dalam rilis terbaru (18 September 2018) dan ukuran file akhir dari model ini tidak sesuai dengan jaringan yang disediakan, jadi saya tidak dapat mencapai hasil yang sama dalam akurasi - 72%. </blockquote><br>  Model ini hanya dilatih dengan parameter <code>batch_size=16</code> dan <code>epochs=700</code> , tanpa jadwal pelatihan, dll. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Compile Model model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy']) # Fit Model cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))</span></span></code> </pre> <br>  Di sini <code>categorical_crossentropy</code> adalah fungsi dari kerugian, dan ukuran evaluasi adalah akurasi. <br><br><h2>  Eksperimen saya </h2><br><h3>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Analisis data eksplorasi</a> </h3><br>  Dalam dataset RAVDESS, setiap aktor menunjukkan 8 emosi, mengucapkan dan menyanyikan 2 kalimat, masing-masing 2 kali.  Hasilnya, 4 contoh dari setiap emosi diperoleh dari masing-masing aktor, dengan pengecualian dari emosi netral yang disebutkan di atas, jijik, dan kejutan.  Setiap audio berlangsung sekitar 4 detik, pada detik pertama dan terakhir paling sering diam. <br><br>  <b>Penawaran khas</b> : <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/es/87/u_/es87u_qdtsjmiv-slst1vzmzyay.png"></div><br><h3>  Pengamatan </h3><br>  Setelah saya memilih dataset dari 1 aktor dan 1 aktris, dan kemudian mendengarkan semua catatan mereka, saya menyadari bahwa pria dan wanita mengekspresikan emosi mereka secara berbeda.  Sebagai contoh: <br><br><ul><li>  kemarahan laki-laki (Marah) lebih keras; </li><li>  kegembiraan pria (Bahagia) dan frustrasi (Sedih) - sebuah fitur dalam nada tertawa dan menangis selama "keheningan"; </li><li>  sukacita perempuan (Bahagia), kemarahan (Marah) dan frustrasi (Sedih) lebih keras; </li><li>  female disgust (Disgust) berisi suara muntah. </li></ul><br><h3>  Pengulangan percobaan </h3><br>  Penulis menghapus kelas netral, jijik, dan terkejut untuk membuat pengakuan kelas RAVDESS 10-set data.  Mencoba mengulangi pengalaman penulis, saya mendapatkan hasil ini: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-l/yz/vm/-lyzvmb6xx5vwqtkmjrdsawgjtc.png"></div><br><br>  Namun, saya menemukan bahwa ada kebocoran data ketika dataset untuk validasi identik dengan dataset pengujian.  Oleh karena itu, saya mengulangi pemisahan data, mengisolasi kumpulan data dari dua aktor dan dua aktris sehingga mereka tidak terlihat selama tes: <br><br><ul><li>  aktor 1 hingga 20 digunakan untuk set Train / Valid dalam rasio 8: 2; </li><li>  aktor 21 hingga 24 diisolasi dari pengujian; </li><li>  Parameter Set Kereta: (1248, 216, 1); </li><li>  Parameter Set Valid: (312, 216, 1); </li><li>  Parameter Set Tes: (320, 216, 1) - (terisolasi). </li></ul><br>  Saya melatih ulang modelnya dan inilah hasilnya: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/57/gj/jh/57gjjho-dwtlz1p7j4zv-eawhu0.png"></div><br><h3>  Tes kinerja </h3><br>  Dari grafik Train Valid Gross jelas bahwa tidak ada konvergensi untuk 10 kelas yang dipilih.  Karena itu, saya memutuskan untuk mengurangi kompleksitas model dan hanya menyisakan emosi pria.  Saya mengisolasi dua aktor di set tes, dan meletakkan sisanya di kereta / set valid, rasio 8: 2.  Ini memastikan bahwa tidak ada ketidakseimbangan dalam dataset.  Kemudian saya melatih data pria dan wanita secara terpisah untuk melakukan tes. <br><br>  <b>Dataset jantan</b> <br><br><ul><li>  Train Set - 640 sampel dari aktor 1-10; </li><li>  Set Berlaku - 160 sampel dari aktor 1-10; </li><li>  Set Tes - 160 sampel dari aktor 11-12. </li></ul><br>  <b>Baris referensi: laki-laki</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/we/xy/hd/wexyhdyxjn9_i_wph4caesawaua.png"></div><br>  <b>Dataset wanita</b> <br><br><ul><li>  Train Set - 608 sampel dari aktris 1-10; </li><li>  Set Berlaku - 152 sampel dari aktris 1-10; </li><li>  Set Tes - 160 sampel dari aktris 11-12. </li></ul><br>  <b>Baris referensi: wanita</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ja/jc/np/jajcnp6xzp7oncqgl4-2zkshigm.png"></div><br>  Seperti yang Anda lihat, matriks kesalahan berbeda. <br><br>  Pria: Angry dan Happy adalah kelas prediksi utama dalam model, tetapi mereka tidak sama. <br><br>  Wanita: gangguan (Sedih) dan sukacita (Bahagia) - pada dasarnya prediksi kelas dalam model;  kemarahan dan sukacita mudah dikacaukan. <br><br>  Mengingat pengamatan dari <b>Analisis Data Intelijen</b> , saya curiga bahwa Angry dan Happy wanita mirip dengan titik kebingungan, karena cara mereka berekspresi hanya untuk mengangkat suara mereka. <br><br>  Selain itu, saya ingin tahu bahwa jika saya menyederhanakan model lebih jauh, hanya menyisakan kelas Positif, Netral, dan Negatif.  Atau hanya Positif dan Negatif.  Singkatnya, saya mengelompokkan emosi menjadi 2 dan 3 kelas, masing-masing. <br><br>  <b>2 kelas:</b> <br><br><ul><li>  Positif: sukacita (Bahagia), tenang (Tenang); </li><li>  Negatif: marah, takut (takut), frustrasi (sedih). </li></ul><br>  <b>3 kelas:</b> <br><br><ul><li>  Positif: sukacita (Happy); </li><li>  Netral: tenang (Tenang), netral (Netral); </li><li>  Negatif: marah, takut (takut), frustrasi (sedih). </li></ul><br>  Sebelum memulai percobaan, saya mengatur arsitektur model menggunakan data pria, membuat pengenalan 5 kelas. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   -  target_class = 5 #  model = Sequential() model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1))) #1 model.add(Activation('relu')) model.add(Conv1D(256, 8, padding='same')) #2 model.add(BatchNormalization()) model.add(Activation('relu')) model.add(Dropout(0.25)) model.add(MaxPooling1D(pool_size=(8))) model.add(Conv1D(128, 8, padding='same')) #3 model.add(Activation('relu')) model.add(Conv1D(128, 8, padding='same')) #4 model.add(Activation('relu')) model.add(Conv1D(128, 8, padding='same')) #5 model.add(Activation('relu')) model.add(Conv1D(128, 8, padding='same')) #6 model.add(BatchNormalization()) model.add(Activation('relu')) model.add(Dropout(0.25)) model.add(MaxPooling1D(pool_size=(8))) model.add(Conv1D(64, 8, padding='same')) #7 model.add(Activation('relu')) model.add(Conv1D(64, 8, padding='same')) #8 model.add(Activation('relu')) model.add(Flatten()) model.add(Dense(target_class)) #9 model.add(Activation('softmax')) opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)</span></span></code> </pre> <br>  Saya menambahkan 2 lapisan Conv1D, satu lapisan MaxPooling1D dan 2 lapisan BarchNormalisasi;  Saya juga mengubah nilai putus sekolah menjadi 0,25.  Akhirnya, saya mengubah pengoptimal menjadi SGD dengan kecepatan belajar 0,0001. <br><br><pre> <code class="python hljs">lr_reduce = ReduceLROnPlateau(monitor=<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, factor=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, patience=<span class="hljs-number"><span class="hljs-number">20</span></span>, min_lr=<span class="hljs-number"><span class="hljs-number">0.000001</span></span>) mcp_save = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">'model/baseline_2class_np.h5'</span></span>, save_best_only=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, monitor=<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'min'</span></span>) cnnhistory=model.fit(x_traincnn, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">700</span></span>, validation_data=(x_testcnn, y_test), callbacks=[mcp_save, lr_reduce])</code> </pre> <br>  Untuk melatih model, saya menerapkan pengurangan dalam "dataran tinggi pembelajaran" dan hanya menyimpan model terbaik dengan nilai <code>val_loss</code> minimum.  Dan inilah hasil untuk kelas target yang berbeda. <br><br><h2>  Performa model baru </h2><br>  <b>Pria, 5 kelas</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tw/jm/ay/twjmaytexfauezocygymudu6m_8.png"></div><br><br>  <b>Wanita, Kelas 5</b> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uz/mc/7t/uzmc7t4mtmwlf_mfohv3qzzc4hq.png"></div><br>  <b>Pria, Kelas 2</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dw/y5/rf/dwy5rf0osgtrxfhb6kb-kitxyu8.png"></div><br>  <b>Pria, 3 kelas</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/15/sy/2w/15sy2wzciyl66tapqxfwpguhzze.png"></div><br><h2>  Menambah (augmentasi) </h2><br>  Ketika saya memperkuat arsitektur model, optimizer dan kecepatan pelatihan, ternyata model tersebut masih tidak menyatu dalam mode pelatihan.  Saya menyarankan bahwa ini adalah masalah kuantitas data, karena kami hanya memiliki 800 sampel.  Ini mengarahkan saya ke metode peningkatan audio, pada akhirnya saya menggandakan dataset.  Mari kita lihat metode-metode ini. <br><br><h3>  Pria, 5 kelas </h3><br>  <b>Peningkatan Dinamis</b> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dyn_change</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    """</span></span> dyn_change = np.random.uniform(low=<span class="hljs-number"><span class="hljs-number">1.5</span></span>,high=<span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (data * dyn_change)</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/kc/-l/iz/kc-lizrw-sintgd-ko0cdd3htlc.png"></div><br><br>  <b>Penyesuaian Pitch</b> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pitch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, sample_rate)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    """</span></span> bins_per_octave = <span class="hljs-number"><span class="hljs-number">12</span></span> pitch_pm = <span class="hljs-number"><span class="hljs-number">2</span></span> pitch_change = pitch_pm * <span class="hljs-number"><span class="hljs-number">2</span></span>*(np.random.uniform()) data = librosa.effects.pitch_shift(data.astype(<span class="hljs-string"><span class="hljs-string">'float64'</span></span>), sample_rate, n_steps=pitch_change, bins_per_octave=bins_per_octave)</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pk/rq/2x/pkrq2xfcdfsyph3eipzuwpvtu8a.png"></div><br>  <b>Offset</b> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">shift</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""   """</span></span> s_range = int(np.random.uniform(low=<span class="hljs-number"><span class="hljs-number">-5</span></span>, high = <span class="hljs-number"><span class="hljs-number">5</span></span>)*<span class="hljs-number"><span class="hljs-number">500</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.roll(data, s_range)</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wc/3_/ik/wc3_ikjjnyejxxbmw23pcuanr9c.png"></div><br>  <b>Menambahkan White Noise</b> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">noise</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    """</span></span> <span class="hljs-comment"><span class="hljs-comment">#     : https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html noise_amp = 0.005*np.random.uniform()*np.amax(data) data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0]) return data</span></span></code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uh/qh/aw/uhqhawd_gpp5sampbam9yez3lre.png"></div><br>  Terlihat bahwa augmentasi sangat meningkatkan akurasi, hingga 70+% dalam kasus umum.  Terutama dalam kasus penambahan putih, yang meningkatkan akurasi hingga 87,19% - namun, akurasi tes dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ukuran F1</a> turun lebih dari 5%.  Dan kemudian saya mendapat ide untuk menggabungkan beberapa metode augmentasi untuk hasil yang lebih baik. <br><br><h3>  Menggabungkan beberapa metode </h3><br>  <b>Kebisingan putih + bias</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qv/fn/tg/qvfntgup-tjnrytyxoj2egxy1ys.png"></div><br><h2>  Menguji augmentasi pada pria </h2><br><h3>  Pria, Kelas 2 </h3><br>  <b>Kebisingan putih + bias</b> <br><br>  Untuk semua sampel <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lm/8v/h8/lm8vh88-i4moor2edj9j2rtksoi.png"></div><br>  <b>Kebisingan putih + bias</b> <br><br>  Hanya untuk sampel positif, karena set 2-kelas tidak seimbang (terhadap sampel negatif). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1c/0u/us/1c0uus8vlv-reh0hpd-jnoherm8.png"></div><br>  <b>Pitch + White Noise</b> <br>  Untuk semua sampel <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gb/qb/oz/gbqbozph3uampaicmgzewiitacy.png"></div><br>  <b>Pitch + White Noise</b> <br><br>  Hanya untuk sampel positif <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ip/jk/4p/ipjk4phb0cqc56qfbudr-_vwuww.png"></div><br><h2>  Kesimpulan </h2><br>  Pada akhirnya, saya hanya bisa bereksperimen dengan dataset pria.  Saya membagi ulang data untuk menghindari ketidakseimbangan dan, sebagai akibatnya, kebocoran data.  Saya menyiapkan model untuk bereksperimen dengan suara laki-laki, karena saya ingin menyederhanakan model sebanyak mungkin untuk memulai.  Saya juga melakukan tes menggunakan berbagai metode augmentasi;  penambahan white noise dan bias telah bekerja dengan baik pada data yang tidak seimbang. <br><br><h2>  Kesimpulan </h2><br><ul><li>  emosi bersifat subjektif dan sulit untuk diperbaiki; </li><li>  perlu untuk menentukan terlebih dahulu emosi mana yang cocok untuk proyek; </li><li>  Jangan selalu mempercayai konten dengan Github, meskipun memiliki banyak bintang; </li><li>  berbagi data - ingatlah; </li><li>  analisis data eksplorasi selalu memberikan ide yang bagus, tetapi Anda harus bersabar ketika harus bekerja dengan data audio; </li><li>  Tentukan apa yang akan Anda berikan pada input model Anda: sebuah kalimat, seluruh catatan, atau tanda seru? </li><li>  kurangnya data merupakan faktor keberhasilan penting dalam SER, namun, membuat dataset yang baik dengan emosi adalah tugas yang kompleks dan mahal; </li><li>  sederhanakan model Anda jika tidak ada data. </li></ul><br><h2>  Perbaikan lebih lanjut </h2><br><ul><li>  Saya hanya menggunakan 3 detik pertama sebagai input untuk mengurangi ukuran data keseluruhan - proyek asli digunakan 2,5 detik.  Saya ingin bereksperimen dengan rekaman ukuran penuh; </li><li>  Anda dapat melakukan pra-proses data: memangkas keheningan, menormalkan panjang dengan mengisi dengan nol, dll; </li><li>  coba jaringan saraf berulang untuk tugas ini. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id461435/">https://habr.com/ru/post/id461435/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id461421/index.html">Cara mengasuransikan diri Anda dari kemungkinan kerugian saat berinvestasi di bursa: produk struktural</a></li>
<li><a href="../id461423/index.html">11 tips: cara mempresentasikan UI / UX berfungsi untuk "non-desainer"</a></li>
<li><a href="../id461425/index.html">Bagaimana menjadi manajer produk dan berkembang lebih jauh</a></li>
<li><a href="../id461431/index.html">"Suka dan tidak suka": DNS over HTTPS</a></li>
<li><a href="../id461433/index.html">Menggunakan Identity Server 4 di Net Core 3.0</a></li>
<li><a href="../id461437/index.html">370 bola lampu</a></li>
<li><a href="../id461439/index.html">Memulai perpustakaan komponen React dan TypeScript</a></li>
<li><a href="../id461441/index.html">Laporan tentang kondisi penyimpanan menggunakan R. Komputasi paralel, grafik, xlsx, email dan semua ini</a></li>
<li><a href="../id461443/index.html">Pasca-analisis: apa yang diketahui tentang serangan terbaru pada jaringan server kunci SKS Keyserver crypto</a></li>
<li><a href="../id461447/index.html">Epik tentang administrator sistem sebagai spesies yang terancam punah</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äçüî¨ ‚ÑπÔ∏è ü§û 3D-Rekonstruktion von Gesichtern aus Fotografien und deren Animation mittels Video. Vortrag in Yandex üßùüèø üòÄ üë±</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In dem Film Mission Impossible 3 wurde der Prozess der Erstellung der ber√ºhmten Spionagemasken gezeigt, durch den einige Charaktere nicht mehr von and...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>3D-Rekonstruktion von Gesichtern aus Fotografien und deren Animation mittels Video. Vortrag in Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/421353/"> In dem Film Mission Impossible 3 wurde der Prozess der Erstellung der ber√ºhmten Spionagemasken gezeigt, durch den einige Charaktere nicht mehr von anderen zu unterscheiden sind.  Der Handlung zufolge musste zun√§chst die Person, in die sich der Held verwandeln wollte, aus verschiedenen Blickwinkeln fotografiert werden.  Im Jahr 2018 wird ein einfaches 3D-Gesichtsmodell m√∂glicherweise nicht einmal gedruckt, sondern zumindest in digitaler Form erstellt - und basiert auf nur einem Foto.  Ein VisionLabs-Forscher beschrieb den Prozess auf der Yandex-Veranstaltung ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Welt mit den Augen von Robotern</a> ‚Äú aus der Data &amp; Science-Reihe ausf√ºhrlich mit Einzelheiten zu bestimmten Methoden und Formeln. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/zy9fxYDgUQw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Guten Tag.  Mein Name ist Nikolai, ich arbeite f√ºr VisionLabs, ein Computer Vision Unternehmen.  Unser Hauptprofil ist die Gesichtserkennung, aber wir haben auch Technologien, die in der erweiterten und virtuellen Realit√§t anwendbar sind.  Insbesondere haben wir eine Technologie zum Erstellen eines 3D-Gesichts aus einem Foto, und heute werde ich dar√ºber sprechen. <br><br><a name="habracut"></a><img src="https://habrastorage.org/webt/hi/ks/fu/hiksfukx8cknqrbhf5kv-c9xwbs.jpeg"><br><br>  Beginnen wir mit einer Geschichte dar√ºber, was es ist.  Auf der Folie sehen Sie das Originalfoto von Jack Ma und ein 3D-Modell, das aus diesem Foto in zwei Variationen erstellt wurde: mit und ohne Textur, nur Geometrie.  Dies ist die Aufgabe, die wir l√∂sen. <br><br><img src="https://habrastorage.org/webt/qo/sy/10/qosy10ijsqqmfgyqiemsloakdqg.jpeg"><br><br>  Wir m√∂chten auch in der Lage sein, dieses Modell zu animieren, die Blickrichtung, den Gesichtsausdruck zu √§ndern, Gesichtsausdr√ºcke hinzuzuf√ºgen usw. <br><br>  Die Anwendung ist in verschiedenen Bereichen.  Am offensichtlichsten sind Spiele, einschlie√ülich VR.  Sie k√∂nnen auch virtuelle Umkleidekabinen einrichten - probieren Sie Brillen, B√§rte und Frisuren an.  Sie k√∂nnen 3D-Druck betreiben, da einige Leute an personalisierten Accessoires f√ºr ihr Gesicht interessiert sind.  Und Sie k√∂nnen Gesichter f√ºr Roboter erstellen: Drucken und Anzeigen auf einem Display des Roboters. <br><br><img src="https://habrastorage.org/webt/uh/d4/1b/uhd41bqzarsfib5oao3zven7gxk.jpeg"><br><br>  Ich werde Ihnen zun√§chst erkl√§ren, wie Sie 3D-Gesichter im Allgemeinen generieren, und dann werden wir zur Aufgabe der 3D-Rekonstruktion als inverse Generierungsaufgabe √ºbergehen.  Danach konzentrieren wir uns auf die Animation und gehen auf die Herausforderungen ein, die sich in diesem Bereich ergeben. <br><br><img src="https://habrastorage.org/webt/bk/yb/sj/bkybsja0tr11pleorczx4okgk3g.jpeg"><br><br>  Was ist die Aufgabe, Gesichter zu erzeugen?  Wir m√∂chten eine M√∂glichkeit haben, dreidimensionale Gesichter zu erzeugen, die sich in Form und Ausdruck unterscheiden.  Hier sind zwei Zeilen mit Beispielen.  Die erste Reihe zeigt Gesichter unterschiedlicher Form, die wie zu verschiedenen Personen geh√∂ren.  Und unten ist das gleiche Gesicht mit einem anderen Ausdruck. <br><br><img src="https://habrastorage.org/webt/_s/md/94/_smd94kpe-kgilpu8c2ncguhgve.jpeg"><br><br>  Eine M√∂glichkeit, das Generierungsproblem zu l√∂sen, sind deformierbare Modelle.  Die Fl√§che ganz links auf der Folie ist eine Art gemitteltes Modell, auf das wir durch Anpassen der Schieberegler Verformungen anwenden k√∂nnen.  Hier sind drei Schieberegler.  In der oberen Reihe befinden sich Fl√§chen in Richtung der Erh√∂hung der Intensit√§t des Schiebereglers, in der unteren Reihe in Richtung der Verringerung.  Daher haben wir mehrere anpassbare Parameter.  Durch die Installation k√∂nnen Sie Menschen verschiedene Formen geben. <br><br><img src="https://habrastorage.org/webt/rs/gj/bd/rsgjbdm2ekfclog-l9r24yj05zq.jpeg"><br><br>  Ein Beispiel f√ºr ein deformierbares Modell ist das ber√ºhmte Basler Gesichtsmodell, das aus Gesichts-Scans erstellt wurde.  Um ein deformierbares Modell zu erstellen, m√ºssen Sie zuerst einige Personen mitnehmen, sie in ein spezielles Labor bringen und ihre Gesichter mit spezieller Ausr√ºstung fotografieren und in 3D √ºbersetzen.  Auf dieser Grundlage k√∂nnen Sie dann neue Gesichter erstellen. <br><br><img src="https://habrastorage.org/webt/da/lm/zi/dalmziafwox1_wosdsp25pjphiu.jpeg"><br><br>  Wie ist es mathematisch angeordnet?  Wir k√∂nnen uns ein dreidimensionales Modell eines Gesichts als Vektor im dreidimensionalen Raum vorstellen.  Hier ist n die Anzahl der Eckpunkte im Modell, jeder Eckpunkt entspricht drei Koordinaten in 3D, und somit erhalten wir 3n Koordinaten. <br><br><img src="https://habrastorage.org/webt/fr/h2/ek/frh2ekb0ts7xoeymvoxdthm7_ak.jpeg"><br><br>  Wenn wir einen Satz von Scans haben, wird jeder Scan durch einen solchen Vektor dargestellt, und wir haben einen Satz von n solchen Vektoren. <br><br>  Au√üerdem k√∂nnen wir neue Fl√§chen als lineare Kombinationen von Vektoren aus unserer Datenbank erstellen.  Gleichzeitig m√∂chten wir, dass die Koeffizienten aussagekr√§ftig sind.  Offensichtlich k√∂nnen sie nicht v√∂llig willk√ºrlich sein, und ich werde bald zeigen, warum.  Eine der Einschr√§nkungen kann so eingestellt werden, dass alle Koeffizienten im Bereich von 0 bis 1 liegen. Dies muss erfolgen, denn wenn die Koeffizienten v√∂llig willk√ºrlich sind, erweisen sich die Fl√§chen als unplausibel. <br><br><img src="https://habrastorage.org/webt/43/x3/m_/43x3m_fwzwj8xcsvywqjusbijmm.jpeg"><br><br>  Hier m√∂chte ich den Parametern eine probabilistische Bedeutung geben.  Das hei√üt, wir m√∂chten eine Reihe von Parametern betrachten und verstehen, ob es wahrscheinlich ist, dass sich eine Person herausstellt oder nicht.  Damit wollen wir, dass geringe Verzerrungen verzerrten Gesichtern entsprechen. <br><br><img src="https://habrastorage.org/webt/ge/m4/yb/gem4ybi9ha0puz8tcjv3nomiwiy.jpeg"><br><br>  Hier erfahren Sie, wie es geht.  Wir k√∂nnen die Hauptkomponentenmethode auf eine Reihe von Scans anwenden.  Am Ausgang erhalten wir die durchschnittliche Fl√§che S0, erhalten die Matrix V, einen Satz von Hauptkomponenten, und erhalten auch Datenvariationen entlang der Hauptkomponenten.  Dann k√∂nnen wir einen neuen Blick auf die Erzeugung von Gesichtern werfen. Wir werden die Gesichter als ein durchschnittliches Gesicht plus die Matrix der Hauptkomponenten, multipliziert mit dem Vektor der Parameter, darstellen. <br><br>  Der Wert der Parameter ist die Intensit√§t der Schieberegler, √ºber die ich in einer der fr√ºheren Folien gesprochen habe.  Au√üerdem k√∂nnen wir dem Parametervektor einen probabilistischen Wert zuweisen.  Insbesondere k√∂nnen wir uns darauf einigen, dass dieser Vektor Gau√üsch ist. <br><br><img src="https://habrastorage.org/webt/pv/bk/qq/pvbkqqdess7l175ginfuz9vkzmw.jpeg"><br><br>  Auf diese Weise erhalten wir eine Methode, mit der Sie 3D-Gesichter generieren k√∂nnen. Diese Generierung wird durch die folgenden Parameter gesteuert.  Wie auf der vorherigen Folie haben wir zwei Parameters√§tze, zwei Vektoren Œ± id und Œ± exp. Sie sind dieselben wie auf der vorherigen Folie, aber Œ± id ist f√ºr die Form des Gesichts verantwortlich und Œ± exp ist f√ºr die Emotion verantwortlich. <br><br>  Ein neuer Vektor T erscheint ebenfalls - ein Texturvektor.  Es hat dieselbe Dimension wie der Formvektor, und jeder Scheitelpunkt in diesem Vektor hat drei RGB-Werte.  In √§hnlicher Weise wird ein Texturvektor unter Verwendung des Parametervektors Œ≤ erzeugt.  Hier werden nicht die Parameter formalisiert, die f√ºr die Beleuchtung des Gesichts und f√ºr seine Position verantwortlich sind, sondern sie existieren auch. <br><br><img src="https://habrastorage.org/webt/ab/bx/23/abbx2327nyov76ewuzl_s_fa9qo.jpeg"><br><br>  Hier sind Beispiele f√ºr Fl√§chen, die mit einem deformierten Modell erzeugt werden k√∂nnen.  Bitte beachten Sie, dass sie sich in Form und Hautfarbe unterscheiden und auch bei unterschiedlichen Lichtverh√§ltnissen gezeichnet werden. <br><br><img src="https://habrastorage.org/webt/-n/ht/eu/-nhteuzhzcomppfvup80sevyhhc.jpeg"><br><br>  Jetzt k√∂nnen wir mit der 3D-Rekonstruktion fortfahren.  Dies wird als inverses Problem bezeichnet, da wir solche Parameter f√ºr das verformbare Modell ausw√§hlen m√∂chten, damit die Fl√§che, die wir daraus zeichnen, dem Original so √§hnlich wie m√∂glich ist.  Diese Folie unterscheidet sich von der ersten darin, dass hier rechts das Gesicht vollst√§ndig synthetisch ist.  Wenn auf der ersten Folie unsere Textur von einem Foto stammt, dann wurde hier die Textur von einem deformierbaren Modell √ºbernommen. <br><br>  Am Ausgang haben wir alle Parameter, auf der Folie werden Œ± id und Œ± exp dargestellt, und wir haben auch Beleuchtung, Texturparameter usw. <br><br><img src="https://habrastorage.org/webt/qa/ci/ql/qaciqlkbflxmqo1a1pzzn01g4d8.jpeg"><br><br>  Wir wollten sicherstellen, dass das generierte Modell wie ein Foto aussieht.  Diese √Ñhnlichkeit wird anhand der Energiefunktion ermittelt.  Hier nehmen wir nur den pixelweisen Unterschied der Bilder in den Pixeln, in denen wir glauben, dass das Gesicht sichtbar ist.  Wenn beispielsweise das Gesicht gedreht wird, tritt eine √úberlappung auf.  Zum Beispiel wird ein Teil des Wangenknochens von der Nase bedeckt.  Und die Sichtbarkeitsmatrix M sollte eine solche √úberlappung anzeigen. <br><br>  Im Wesentlichen soll die 3D-Rekonstruktion diese Energiefunktion minimieren.  Um dieses Minimierungsproblem zu l√∂sen, w√§re eine Initialisierung und Regularisierung w√ºnschenswert.  Eine Regularisierung ist aus einem offensichtlichen Grund erforderlich, da wir sagten, dass wir verzerrte Gesichter bekommen k√∂nnen, wenn wir die Parameter nicht regulieren und sie v√∂llig willk√ºrlich machen.  Die Initialisierung ist erforderlich, da die Aufgabe insgesamt komplex ist, lokale Minima aufweist und Sie sich nicht mit ihnen befassen m√∂chten. <br><br><img src="https://habrastorage.org/webt/jq/i-/ns/jqi-nskft-v7pvl8tadsmrldaco.jpeg"><br><br>  Wie kann die Initialisierung erfolgen?  Hierf√ºr k√∂nnen Sie 68 Schl√ºsselpunkte des Gesichts verwenden.  Seit 2013-2014 sind viele Algorithmen erschienen, mit denen 68 Punkte mit ziemlich guter Genauigkeit erkannt werden k√∂nnen, und jetzt n√§hern sie sich einer S√§ttigung ihrer Genauigkeit.  Daher haben wir eine M√∂glichkeit, 68 Gesichtspunkte zuverl√§ssig zu erkennen. <br><br>  Wir k√∂nnen unserer Energiefunktion einen neuen Begriff hinzuf√ºgen, der besagt, dass die Projektionen derselben 68 Punkte des Modells mit den Schl√ºsselpunkten des Gesichts √ºbereinstimmen sollen.  Wir markieren diese Punkte auf dem Modell, verformen dann das Modell irgendwie, drehen es, projizieren die Punkte und stellen sicher, dass die Positionen der Punkte √ºbereinstimmen.  Auf dem linken Foto befinden sich zweifarbige Punkte, Violett und Gelb.  Einige Punkte wurden vom Algorithmus erkannt, w√§hrend andere aus dem Modell projiziert wurden.  Markierungspunkte auf dem Modell rechts, aber f√ºr Punkte entlang der Gesichtskante wird nicht ein Punkt markiert, sondern eine ganze Linie.  Dies geschieht, weil sich beim Drehen der Fl√§che die Markierungen dieser Punkte √§ndern m√ºssen und der Punkt mit einer Linie ausgew√§hlt wird. <br><br><img src="https://habrastorage.org/webt/sb/kg/n0/sbkgn0oajeqf_z-bleo0qfhzguy.jpeg"><br><br>  Hier ist der Begriff, √ºber den ich gesprochen habe. Es ist die koordinatenweise Differenz zweier Vektoren, die die Schl√ºsselpunkte des Gesichts und die vom Modell projizierten Schl√ºsselpunkte beschreiben. <br><br><img src="https://habrastorage.org/webt/wj/ku/eq/wjkueqaneclilvcxhbdsimu-gik.jpeg"><br><br>  Kehren wir zur Regularisierung zur√ºck und betrachten das gesamte Problem aus der Perspektive der Bayes'schen Schlussfolgerung.  Die Wahrscheinlichkeit, dass der Vektor Œ± gleich etwas ist, das in einem bekannten Bild gegeben ist, ist proportional zum Produkt der Wahrscheinlichkeit, das Bild f√ºr ein gegebenes Œ± zu beobachten, multipliziert mit der Wahrscheinlichkeit Œ±.  Wenn wir den negativen Logarithmus dieses Ausdrucks nehmen, den wir minimieren m√ºssen, werden wir sehen, dass der f√ºr die Regularisierung verantwortliche Begriff hier eine konkrete Form hat.  Dies ist insbesondere der zweite Begriff.  Wenn wir uns daran erinnern, dass wir zuvor angenommen haben, dass der Vektor Œ± Gau√üsch ist, sehen wir, dass der f√ºr die Regularisierung verantwortliche Term die Summe der Quadrate der Parameter ist, die auf Variationen entlang der Hauptkomponenten reduziert sind. <br><br><img src="https://habrastorage.org/webt/9t/hj/y2/9thjy2x8qmvgcqxayk7rrddusra.jpeg"><br><br>  Wir k√∂nnen also die volle Energiefunktion ausschreiben, die drei Begriffe enth√§lt.  Der erste Term ist verantwortlich f√ºr die Textur, f√ºr die Pixeldifferenz zwischen dem erzeugten Bild und dem Zielbild.  Der zweite Begriff ist f√ºr wichtige Punkte verantwortlich, der dritte f√ºr die Regularisierung. <br><br>  Die Koeffizienten der Terme im Minimierungsprozess werden nicht optimiert, sondern einfach eingestellt. <br>  Hier wird die Energiefunktion als Funktion aller Parameter dargestellt.  Œ± id - Gesichtsformparameter, Œ± exp - Ausdrucksparameter, Œ≤ - Texturparameter, p - andere Parameter, √ºber die wir gesprochen, aber nicht formalisiert haben, dies sind Positions- und Beleuchtungsparameter. <br><br><img src="https://habrastorage.org/webt/tn/ki/np/tnkinpazftdmbqj3cyiij4vxn8s.jpeg"><br><br>  Lassen Sie uns auf diese Bemerkung eingehen.  Diese Energiefunktion kann vereinfacht werden.  Daraus k√∂nnen Sie den Begriff entfernen, der f√ºr die Textur verantwortlich ist, und nur die Informationen verwenden, die von 68 Punkten √ºbertragen wurden.  Auf diese Weise k√∂nnen Sie eine Art 3D-Modell erstellen.  Beachten Sie jedoch das Modellprofil.  Auf der linken Seite befindet sich ein Modell, das nur an wichtigen Punkten erstellt wurde.  Auf der rechten Seite befindet sich ein Modell, das beim Erstellen eine Textur verwendet.  Beachten Sie, dass das Profil rechts besser mit dem zentralen Foto √ºbereinstimmt, das die Vorderansicht des Gesichts darstellt. <br><br><img src="https://habrastorage.org/webt/r2/kp/p9/r2kpp94wnxg7vhfz1nha-ewl4xg.jpeg"><br><br>  Die Animation mit dem vorhandenen Algorithmus zum Erstellen eines 3D-Modells des Gesichts funktioniert ganz einfach.  Denken Sie daran, dass wir beim Erstellen eines 3D-Modells zwei Parametervektoren erhalten, von denen einer f√ºr die Form und der andere f√ºr den Ausdruck verantwortlich ist.  Diese Vektoren von Parametern f√ºr den Benutzer und den Avatar haben immer ihre eigenen.  Der Benutzer hat einen Vektor von Formularparametern, der Avatar hat einen anderen.  Wir k√∂nnen jedoch die f√ºr den Ausdruck verantwortlichen Vektoren f√ºr sie gleich machen.  Wir nehmen die Parameter, die f√ºr den Gesichtsausdruck des Benutzers verantwortlich sind, und ersetzen sie einfach durch das Avatar-Modell.  So √ºbertragen wir den Gesichtsausdruck des Benutzers auf den Avatar. <br><br>  Lassen Sie uns √ºber zwei Herausforderungen in diesem Bereich sprechen: die Arbeitsgeschwindigkeit und das begrenzte verformbare Modell. <br><br><img src="https://habrastorage.org/webt/d8/s6/q8/d8s6q8yjlm76pcdoa2p4pavf-vw.jpeg"><br><br>  Geschwindigkeit ist wirklich ein Problem.  Das Minimieren der Gesamtenergiefunktion ist eine sehr rechenintensive Aufgabe.  Insbesondere kann es 20 bis 40 dauern, durchschnittlich 30 Sekunden.  Das ist lang genug.  Wenn wir ein dreidimensionales Modell nur an Schl√ºsselpunkten erstellen, wird es viel schneller ausfallen, aber die Qualit√§t wird darunter leiden. <br><br><img src="https://habrastorage.org/webt/wk/se/zq/wksezqkjmdzs3v25feuanneaf84.jpeg"><br><br>  Wie gehe ich mit diesem Problem um?  Sie k√∂nnen mehr Ressourcen verwenden, einige Leute l√∂sen dieses Problem auf der GPU.  Es k√∂nnen nur wichtige Punkte verwendet werden, aber die Qualit√§t wird darunter leiden.  Und Sie k√∂nnen Methoden des maschinellen Lernens verwenden. <br><br><img src="https://habrastorage.org/webt/p2/8m/fa/p28mfavfwitizfwss5fhreauviq.jpeg"><br><br>  Mal sehen in der Reihenfolge.  Hier ist die Arbeit von 2016, in der der Gesichtsausdruck des Benutzers auf ein bestimmtes Video √ºbertragen wird. Sie k√∂nnen das Video mit Ihrem Gesicht steuern.  Hier erfolgt die Erstellung des 3D-Modells in Echtzeit mit der GPU. <br><br><img src="https://habrastorage.org/webt/dn/qx/yj/dnqxyjywcjbx5yus2v7pvcyq8vm.jpeg"><br><br>  Hier sind die Methoden, die maschinelles Lernen verwenden.  Die Idee ist, dass wir zuerst eine gro√üe Basis von Gesichtern f√ºr jedes Gesicht verwenden k√∂nnen, indem wir einen langen, aber genauen Algorithmus verwenden, um 3D-Modelle zu erstellen, jedes Modell als einen Satz von Parametern darzustellen und dann das Gitter zu trainieren, um diese Parameter vorherzusagen.  Insbesondere wird in dieser Arbeit von 2016 ResNet verwendet, das ein Bild zur Eingabe nimmt und die Modellparameter zur Ausgabe gibt. <br><br><img src="https://habrastorage.org/webt/p6/ng/t6/p6ngt6gzn-4mps27709zhmeuzwk.jpeg"><br><br>  Das dreidimensionale Modell kann auf andere Weise dargestellt werden.  In dieser Arbeit von 2017 wird das 3D-Modell nicht als eine Reihe von Parametern dargestellt, sondern als eine Reihe von Voxeln.  Das Netzwerk sagt Voxel voraus und verwandelt das Bild in eine dreidimensionale Darstellung.  Es ist erw√§hnenswert, dass Netzwerk-Trainingsoptionen m√∂glich sind, f√ºr die 3D-Modelle √ºberhaupt nicht erforderlich sind. <br><br><img src="https://habrastorage.org/webt/yw/__/ot/yw__otysknuehp7kdjgikvziijc.jpeg"><br><br>  Dies funktioniert wie folgt.  Hier ist der wichtigste Teil die Ebene, die die Parameter des verformbaren Modells als Eingabe verwenden und das Bild rendern kann.  Es hat eine so wunderbare Eigenschaft, dass Sie dadurch die R√ºckausbreitung des Fehlers durchf√ºhren k√∂nnen.  Das Netzwerk akzeptiert ein Bild als Eingabe, sagt die Parameter voraus, f√ºhrt diese Parameter einer Ebene zu, die das Bild rendert, vergleicht dieses Bild mit der Eingabe, empf√§ngt einen Fehler, gibt den Fehler zur√ºck und lernt weiter.  Somit lernt das Netzwerk, die Parameter des dreidimensionalen Modells vorherzusagen, wobei nur Bilder als Trainingsdaten verwendet werden.  Und es ist sehr interessant. <br><br><img src="https://habrastorage.org/webt/m_/kx/vc/m_kxvcoekvrrgp41k410ikd_viu.jpeg"><br><br>  Wir haben viel √ºber Genauigkeit gesprochen - insbesondere dar√ºber, dass es leidet, wenn wir einige Begriffe aus der Funktion der Energie herauswerfen.  Lassen Sie uns formalisieren, was dies bedeutet und wie Sie die Genauigkeit der 3D-Gesichtsrekonstruktion bewerten k√∂nnen.  Um dies zu erreichen, ben√∂tigen wir eine Basis von Wahrheits-Wahrheits-Scans, die mit speziellen Ger√§ten durchgef√ºhrt werden und Methoden verwenden, f√ºr die es einige Garantien f√ºr die Genauigkeit gibt.  Wenn eine solche Basis existiert, k√∂nnen wir unsere rekonstruierten Modelle mit der Grundwahrheit vergleichen.  Dies geschieht einfach: Wir berechnen den durchschnittlichen Abstand von den Eckpunkten unseres Modells, das wir erstellt haben, zu den Eckpunkten in der Grundwahrheit und normalisieren auf die Gr√∂√üe des Scans.  Dies muss erfolgen, weil die Gesichter unterschiedlich sind, einige gr√∂√üer, andere kleiner und der Fehler auf dem kleinen Gesicht kleiner w√§re, einfach weil das Gesicht selbst kleiner ist.  Daher ist eine Normalisierung erforderlich. <br><br><img src="https://habrastorage.org/webt/a0/us/rq/a0usrqlogscnks2yygnrestgf9o.jpeg"><br><br>  Ich m√∂chte √ºber unsere Arbeit sprechen, es wird in Workshops sein, es gibt ECCV.  Wir machen √§hnliche Dinge und bringen MobileNet bei, die Parameter eines deformierbaren Modells vorherzusagen.  Als Trainingsdaten verwenden wir 3D-Modelle, die f√ºr Fotos aus dem 300-W-Datensatz erstellt wurden.  Bewerten Sie die Genauigkeit anhand von BU4DFE-Scans. <br><br><img src="https://habrastorage.org/webt/oa/db/ha/oadbhaivdnukffi7vcdwye8vsmu.jpeg"><br><br>  Hier ist das Ergebnis.  Wir vergleichen unsere beiden Algorithmen mit dem Stand der Technik.  Die gelbe Kurve in diesem Diagramm ist ein Algorithmus, der 30 Sekunden dauert und darin besteht, die Gesamtenergiefunktion zu minimieren.  Hier entlang der X-Achse ist der Fehler, √ºber den wir gerade gesprochen haben, der durchschnittliche Abstand zwischen den Eckpunkten.  Die Y-Achse ist der Anteil der Bilder, bei denen dieser Fehler kleiner als der auf der X-Achse ist. In diesem Diagramm ist es umso besser, je h√∂her die Kurve ist.  Die n√§chste Kurve ist unser MobileNet-basiertes Netzwerk.  Als n√§chstes die drei Werke, √ºber die wir gesprochen haben.  Parameter Predictive Network und Voxel Predictive Network. <br><br><img src="https://habrastorage.org/webt/p3/ku/82/p3ku82pa5bgvee5_k7mj2w5bfne.jpeg"><br><br>  Wir haben unser Netzwerk auch hinsichtlich Modellgr√∂√üe und Geschwindigkeit mit Kollegen verglichen.  Dies ist ein Gewinn, da wir MobileNet verwenden, was recht einfach ist. <br><br>  Die zweite Herausforderung ist die Begrenztheit des verformbaren Modells. <br><br><img src="https://habrastorage.org/webt/u1/6a/9j/u16a9jeq3vc6lvwvc0hu82ymqd8.jpeg"><br><br>  Achten Sie auf das linke Gesicht, schauen Sie auf die Fl√ºgel der Nase.  Es gibt Schatten auf den Fl√ºgeln der Nase.  Die R√§nder der Schatten stimmen nicht mit den R√§ndern der Nase auf dem Foto √ºberein, so dass ein Defekt erhalten wird.  Der Grund daf√ºr kann sein, dass das verformbare Modell im Prinzip nicht in der Lage ist, die Nase mit der erforderlichen Form aufzubauen, da dieses verformbare Modell aus Scans von nur 200 Fl√§chen erhalten wurde.  Wir m√∂chten, dass die Nase korrekt ist, wie auf dem rechten Foto.  Wir m√ºssen also irgendwie √ºber den Rahmen des deformierbaren Modells hinausgehen. <br><br><img src="https://habrastorage.org/webt/eh/83/a5/eh83a5w3ovjb0t3v0d3slmazsgc.jpeg"><br><br>  Dies kann unter Verwendung einer nichtparametrischen Verformung des Netzes erfolgen.  Hier sind drei Aufgaben, die wir l√∂sen m√∂chten: √Ñndern Sie den lokalen Teil des Gesichts, z. B. die Nase, und binden Sie ihn dann in das urspr√ºngliche Modell des Gesichts ein, damit alles andere unver√§ndert bleibt. <br><br><img src="https://habrastorage.org/webt/kr/dt/j5/krdtj5freppwfivlapbiqtlyz-y.jpeg"><br><br>  Dies kann wie folgt erfolgen.  Kehren wir zur Bezeichnung des Netzes als Vektor im dreidimensionalen Raum zur√ºck und betrachten den Mittelungsoperator.  Dies ist ein Operator, der in S mit einem Header jeden Scheitelpunkt durch den Durchschnitt seiner Nachbarn ersetzt.  Die Nachbarn des Gipfels sind diejenigen, die durch eine Kante mit ihm verbunden sind. <br><br>  Wir werden eine bestimmte Energiefunktion definieren, die die Position des Scheitelpunkts relativ zu seinen Nachbarn beschreibt.  Wir wollen, dass die Position des Peaks relativ zu seinen Nachbarn unver√§ndert bleibt oder sich zumindest nicht wesentlich √§ndert.  Gleichzeitig werden wir S irgendwie modifizieren. Diese Energiefunktion wird als intern bezeichnet, da es auch einen externen Begriff geben wird, der besagt, dass beispielsweise die Nase eine bestimmte Form annehmen sollte. <br><br><img src="https://habrastorage.org/webt/9r/0g/-o/9r0g-o4tyxpzkzgfl_3bx7_xjue.jpeg"><br><br>  Solche Techniken wurden beispielsweise in der Arbeit von 2015 verwendet.  Sie haben aus mehreren Fotos eine 3D-Gesichtsrekonstruktion durchgef√ºhrt.  Wir haben mehrere Fotos vom Telefon aufgenommen, eine Punktwolke erhalten und dann das Gesichtsmodell mit nicht parametrischen √Ñnderungen an diese Wolke angepasst. <br><br><img src="https://habrastorage.org/webt/1q/9c/yh/1q9cyhw6dspqkz57ese7dwbezyc.jpeg"><br><br>  Sie k√∂nnen auf andere Weise √ºber das verformbare Modell hinausgehen.  Lassen Sie uns auf die Aktion des Gl√§ttungsoperators eingehen.  Hier wird der Einfachheit halber ein zweidimensionales Netz dargestellt, auf das dieser Operator angewendet wurde.  Es gibt viele Details zum Modell auf der linken Seite, beim Modell auf der rechten Seite wurden diese Details gegl√§ttet.  Aber k√∂nnen wir etwas tun, um Details hinzuzuf√ºgen, anstatt sie zu entfernen? <br><br><img src="https://habrastorage.org/webt/5k/je/ir/5kjeirpdi5wtjeapi2v6h7tsxm8.jpeg"><br><br>          .          . <br><br>      ?    -:     -  .                   .      ,     2016 .     ,  . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421353/">https://habr.com/ru/post/de421353/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421343/index.html">Schutz von Microsoft Office 365 Cloud-Daten mit Veeam</a></li>
<li><a href="../de421345/index.html">Winkel: Nicht offensichtliche Merkmale von Direktivenselektoren</a></li>
<li><a href="../de421347/index.html">CORS, CSP, HTTPS, HSTS: Informationen zu Web Security-Technologien</a></li>
<li><a href="../de421349/index.html">Entwickeln einer Nothing Progressive-Webanwendung in 15 Minuten</a></li>
<li><a href="../de421351/index.html">Theorie des Gl√ºcks. Fluch des Direktors und verfluchte Drucker</a></li>
<li><a href="../de421355/index.html">Go 1.11 gestartet - WebAssembly und native Module</a></li>
<li><a href="../de421357/index.html">Auf die Frage nach dem Unm√∂glichen. Teil 3</a></li>
<li><a href="../de421359/index.html">Das Festival ist wie ein Spiel. Taxonomie von IT-Mitarbeitern</a></li>
<li><a href="../de421361/index.html">AMD hat den Quellcode f√ºr V-EZ ge√∂ffnet, eine plattform√ºbergreifende Vulkan-API auf niedriger Ebene</a></li>
<li><a href="../de421365/index.html">Die Entwicklung eines Startups. Agil von Yaytselov bis Chiken Invaders</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
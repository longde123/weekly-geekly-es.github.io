<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôÜüèø üëµ üí± Visualisation de la traduction automatique neuronale (mod√®les seq2seq avec m√©canisme d'attention) ü¶î üñ®Ô∏è üöï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! Je vous pr√©sente la traduction de l'article "Visualiser un mod√®le de traduction automatique neuronal (M√©canique des mod√®les Seq2seq ave...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Visualisation de la traduction automatique neuronale (mod√®les seq2seq avec m√©canisme d'attention)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/486158/"><p>  Bonjour, Habr!  Je vous pr√©sente la traduction de l'article <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="nofollow">"Visualiser un mod√®le de traduction automatique neuronal (M√©canique des mod√®les Seq2seq avec attention)"</a> de Jay Alammar. </p><br><p>  Les mod√®les de s√©quence √† s√©quence (seq2seq) sont des mod√®les d'apprentissage en profondeur qui ont connu un grand succ√®s dans des t√¢ches telles que la traduction automatique, le r√©sum√© de texte, l'annotation d'images, etc.Par exemple, fin 2016, un mod√®le similaire a <a href="https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/" rel="nofollow">√©t√© int√©gr√©</a> √† Google Translate.  Les fondements des mod√®les seq2seq ont √©t√© jet√©s en 2014 avec la publication de deux articles - <a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" rel="nofollow">Sutskever et al., 2014</a> , <a href="http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf" rel="nofollow">Cho et al., 2014</a> . </p><br><p> Afin de comprendre et d'utiliser suffisamment ces mod√®les, certains concepts doivent d'abord √™tre clarifi√©s.  Les visualisations propos√©es dans cet article seront un bon compl√©ment aux articles mentionn√©s ci-dessus. </p><br><p>  Le mod√®le s√©quence √† s√©quence est un mod√®le qui accepte une s√©quence d'√©l√©ments en entr√©e (mots, lettres, attributs d'image, etc.) et renvoie une autre s√©quence d'√©l√©ments.  Le mod√®le form√© fonctionne comme suit: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/seq2seq_1.mp4" type="video/mp4"></video></div></div></div><a name="habracut"></a><br><p>  En traduction automatique neuronale, une s√©quence d'√©l√©ments est un ensemble de mots qui sont trait√©s √† leur tour.  La conclusion est √©galement un ensemble de mots: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/seq2seq_2.mp4" type="video/mp4"></video></div></div></div><br><h1 id="zaglyanem-pod-kapot">  Jetez un ≈ìil sous le capot </h1><br><p>  Sous le capot, le mod√®le dispose d'un encodeur et d'un d√©codeur. </p><br><p>  Le codeur traite chaque √©l√©ment de la s√©quence d'entr√©e, traduit les informations re√ßues en un vecteur appel√© contexte.  Apr√®s avoir trait√© toute la s√©quence d'entr√©e, le codeur envoie le contexte au d√©codeur, qui commence alors √† g√©n√©rer la s√©quence de sortie √©l√©ment par √©l√©ment. </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/seq2seq_3.mp4" type="video/mp4"></video></div></div></div><br><p>  La m√™me chose se produit avec la traduction automatique. </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/seq2seq_4.mp4" type="video/mp4"></video></div></div></div><br><p>  Pour la traduction automatique, le contexte est un vecteur (un tableau de nombres), et l'encodeur et le d√©codeur, √† leur tour, sont le plus souvent des r√©seaux de neurones r√©currents (voir l'introduction de RNN - <a href="https://www.youtube.com/watch%3Fv%3DUNmqTiOnRfg" rel="nofollow">Une introduction conviviale aux r√©seaux de neurones r√©currents</a> ). </p><br><p><img src="https://habrastorage.org/webt/yr/ir/92/yrir92d8paf_xdm29bovaw109gu.png" alt="contexte"></p><br><p>  <em>Le contexte est un vecteur de nombres √† virgule flottante.</em>  <em>Plus loin dans l'article, les vecteurs seront visualis√©s en couleur de sorte que la couleur plus claire correspond aux cellules avec de grandes valeurs.</em> </p><br><p>  Lors de la formation du mod√®le, vous pouvez d√©finir la taille du vecteur de contexte - le nombre de neurones cach√©s (unit√©s cach√©es) dans l'encodeur RNN.  Les donn√©es de visualisation montrent un vecteur √† 4 dimensions, mais dans des applications r√©elles, le vecteur de contexte aura une dimension de l'ordre de 256, 512 ou 1024. </p><br><p>  Par d√©faut, √† chaque intervalle de temps, RNN re√ßoit deux √©l√©ments en entr√©e: l'√©l√©ment d'entr√©e lui-m√™me (dans le cas d'un codeur, un mot de la phrase d'origine) et l'√©tat cach√©.  Le mot, cependant, doit √™tre repr√©sent√© par un vecteur.  Pour convertir un mot en vecteur, ils ont recours √† une s√©rie d'algorithmes appel√©s plongements de mots.  Les int√©grations traduisent les mots en espaces vectoriels contenant des informations s√©mantiques et s√©mantiques √† leur sujet (par exemple, <a href="http://p.migdal.pl/2017/01/06/king-man-woman-queen-why.html" rel="nofollow">¬´roi¬ª - ¬´homme¬ª + ¬´femme¬ª = ¬´reine¬ª</a> ). </p><br><p><img src="https://habrastorage.org/webt/87/pp/s9/87pps99ndmgvp6gqxskkodf4zl4.png" alt="encastrement"></p><br><p>  <em>Avant de traiter des mots, vous devez les convertir en vecteurs.</em>  <em>Cette transformation est effectu√©e √† l'aide de l'algorithme d'int√©gration de mots.</em>  <em>Vous pouvez utiliser √† la fois des int√©grations pr√©-form√©es et des int√©grations de train sur votre ensemble de donn√©es.</em>  <em>200-300 - dimension typique du vecteur d'int√©gration;</em>  <em>cet article utilise la dimension 4 pour plus de simplicit√©.</em> </p><br><p>  Maintenant que nous avons pris connaissance de nos principaux vecteurs / tenseurs, rappelons le m√©canisme de RNN et cr√©ons des visualisations pour le d√©crire: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/RNN_1.mp4" type="video/mp4"></video></div></div></div><br><p>  Dans l'√©tape suivante, RNN prend le deuxi√®me vecteur d'entr√©e et l'√©tat latent # 1 pour former la sortie √† cet intervalle de temps.  Plus loin dans l'article, une animation similaire est utilis√©e pour d√©crire les vecteurs √† l'int√©rieur d'un mod√®le de traduction automatique neuronale. </p><br><p>  Dans la visualisation suivante, chaque trame d√©crit le traitement des entr√©es par un codeur et la g√©n√©ration des sorties par un d√©codeur dans un intervalle de temps.  √âtant donn√© que le codeur et le d√©codeur sont tous deux RNN, √† chaque intervalle de temps, le r√©seau neuronal est occup√© √† traiter et √† mettre √† jour ses √©tats cach√©s sur la base des entr√©es actuelles et pr√©c√©dentes.  Dans ce cas, le dernier des √©tats cach√©s du codeur est le contexte m√™me qui est transmis au d√©codeur. </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/seq2seq_5.mp4" type="video/mp4"></video></div></div></div><br><p>  Le d√©codeur contient √©galement des √©tats cach√©s qu'il transf√®re d'un intervalle de temps √† un autre.  (Ce n'est pas dans la visualisation, repr√©sentant uniquement les principales parties du mod√®le.) </p><br><p>  Nous nous tournons maintenant vers un autre type de visualisation de mod√®les de s√©quence √† s√©quence.  Cette animation aidera √† comprendre les graphiques statiques qui d√©crivent ces mod√®les - les soi-disant  une vue d√©roul√©e, o√π au lieu d'afficher un d√©codeur, nous en montrons une copie pour chaque intervalle de temps.  Nous pouvons donc regarder les √©l√©ments d'entr√©e et de sortie √† chaque intervalle de temps. </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/seq2seq_6.mp4" type="video/mp4"></video></div></div></div><br><h1 id="obratite-vnimanie">  Faites attention! </h1><br><p>  Le vecteur de contexte est un goulot d'√©tranglement pour ce type de mod√®le, ce qui rend difficile pour eux de faire face √† de longues phrases.  La solution a √©t√© propos√©e dans des articles de <a href="" rel="nofollow">Bahdanau et al., 2014</a> et <a href="https://arxiv.org/abs/1508.04025" rel="nofollow">Luong et al., 2015</a> , qui pr√©sentaient une technique appel√©e m√©canisme d'attention.  Ce m√©canisme am√©liore consid√©rablement la qualit√© des syst√®mes de traduction automatique, permettant aux mod√®les de se concentrer sur les parties pertinentes des s√©quences d'entr√©e. </p><br><p><img src="https://habrastorage.org/webt/b1/ru/kj/b1rukj6w-dgtyfncd3a62635zb0.png" alt="attention"></p><br><p>  <em>Dans le 7√®me laps de temps, le m√©canisme d'attention permet au d√©codeur de se concentrer sur le mot √©tudiant (√©tudiant en fran√ßais) avant de g√©n√©rer une traduction en anglais.</em>  <em>Cette capacit√© √† amplifier le signal de la partie pertinente de la s√©quence d'entr√©e permet aux mod√®les bas√©s sur le m√©canisme d'attention d'obtenir un meilleur r√©sultat par rapport aux autres mod√®les.</em> </p><br><p>  Lorsque l'on consid√®re un mod√®le avec un m√©canisme d'attention √† un niveau d'abstraction √©lev√©, on peut distinguer deux diff√©rences principales par rapport au mod√®le classique de s√©quence √† s√©quence. </p><br><p>  Premi√®rement, le codeur transf√®re beaucoup plus de donn√©es au d√©codeur: au lieu de transmettre uniquement le dernier √©tat cach√© apr√®s la phase de codage, le codeur lui envoie tous ses √©tats cach√©s: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/seq2seq_7.mp4" type="video/mp4"></video></div></div></div><br><p>  Deuxi√®mement, le d√©codeur passe par une √©tape suppl√©mentaire avant de g√©n√©rer la sortie.  Afin de se concentrer sur les parties de la s√©quence d'entr√©e qui sont pertinentes pour la p√©riode de temps correspondante, le d√©codeur effectue les op√©rations suivantes: </p><br><ol><li>  Examine un ensemble d'√©tats latents re√ßus d'un codeur - chacun des √©tats latents correspond le mieux √† l'un des mots de la s√©quence d'entr√©e; </li><li>  Attribue une certaine √©valuation √† chaque √©tat latent (omettons pour l'instant comment se d√©roule la proc√©dure d'estimation); </li><li>  Multiplie chaque √©tat cach√© par une estimation convertie par la fonction softmax, mettant ainsi en surbrillance les √©tats cach√©s avec une note √©lev√©e et rel√©guant les √©tats cach√©s avec une petite note. </li></ol><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/attention_process.mp4" type="video/mp4"></video></div></div></div><br><p>  Cet ¬´exercice de gradation¬ª est effectu√© au niveau du d√©codeur √† chaque intervalle de temps. </p><br><p>  Donc, r√©sumant tout ce qui pr√©c√®de, nous consid√©rons le processus du mod√®le avec le m√©canisme d'attention: </p><br><ol><li>  Au niveau du d√©codeur, le RNN re√ßoit l'incorporation &lt;END&gt; du jeton et l'√©tat cach√© initial. </li><li>  Le RNN traite l'√©l√©ment d'entr√©e, g√©n√®re la sortie et un nouveau vecteur d'√©tat cach√© (h4).  La sortie est ignor√©e. </li><li>  Le m√©canisme d'attention utilise les √©tats cach√©s du codeur et le vecteur h4 pour calculer le vecteur de contexte (C4) √† un intervalle de temps donn√©. </li><li>  Les vecteurs h4 et C4 sont concat√©n√©s en un seul vecteur. </li><li>  Ce vecteur passe √† travers un r√©seau neuronal √† action directe (FFN), form√© avec le mod√®le. </li><li>  La sortie du r√©seau FFN indique le mot de sortie √† un intervalle de temps donn√©. </li><li>  L'algorithme est r√©p√©t√© pour l'intervalle de temps suivant. </li></ol><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/attention_tensor_dance.mp4" type="video/mp4"></video></div></div></div><br><p>  Une autre fa√ßon de voir quelle partie de la phrase originale le mod√®le se concentre √† chaque √©tape du d√©codeur: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Votre navigateur ne prend pas en charge la vid√©o HTML5. <source src="https://jalammar.github.io/images/seq2seq_9.mp4" type="video/mp4"></video></div></div></div><br><p>  Notez que le mod√®le ne connecte pas simplement sans r√©fl√©chir le premier mot de l'entr√©e avec le premier mot de la sortie.  Elle a en fait compris au cours du processus de formation comment faire correspondre les mots de cette paire de langues consid√©r√©e (dans notre cas, le fran√ßais et l'anglais).  Un exemple de la pr√©cision avec laquelle ce m√©canisme peut fonctionner peut √™tre trouv√© dans les articles sur le m√©canisme d'attention mentionn√©s ci-dessus. </p><br><p><img src="https://habrastorage.org/webt/cl/dv/9f/cldv9f7zdegsobuszn10hyy1nde.png" alt="attention_sentence"></p><br><p>  Si vous sentez que vous √™tes pr√™t √† apprendre comment appliquer ce mod√®le, reportez-vous au manuel <a href="https://github.com/tensorflow/nmt" rel="nofollow">Neural Machine Translation (seq2seq)</a> sur TensorFlow. </p><br><h1 id="avtory">  Les auteurs </h1><br><ul><li>  <strong>Original</strong> par <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="nofollow">Jay Alammar</a> </li><li>  <strong>Traduction</strong> - <a href="https://habr.com/ru/users/smekur/">Ekaterina Smirnova</a> </li><li>  <strong>√âdition et mise en page</strong> - <a href="https://habr.com/ru/users/kouki_rus/">Shkarin Sergey</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr486158/">https://habr.com/ru/post/fr486158/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr486120/index.html">Normalisation de la d√©viance. Comment les mauvaises pratiques deviennent la norme dans notre industrie</a></li>
<li><a href="../fr486122/index.html">Child ReactJS avec 135 lignes de code</a></li>
<li><a href="../fr486128/index.html">Architecte de solution de test: qui est-ce et quand est-il n√©cessaire</a></li>
<li><a href="../fr486150/index.html">D√©veloppement de la sph√®re informatique en Slovaquie. Prestations de travail pour les jeunes professionnels</a></li>
<li><a href="../fr486156/index.html">Comme j'ai enseign√©, puis √©crit un manuel de formation en Python</a></li>
<li><a href="../fr486164/index.html">Coronavirus 2019-nCoV. FAQ sur la protection respiratoire et la d√©sinfection</a></li>
<li><a href="../fr486174/index.html">J'ai un chiffre d'affaires nul</a></li>
<li><a href="../hi429422/index.html">UHCI, ‡§Ø‡§æ ‡§¨‡§π‡•Å‡§§ ‡§™‡§π‡§≤‡•á USB</a></li>
<li><a href="../hi429424/index.html">‡§°‡•á‡§Æ‡§≤‡§∞ ‡§î‡§∞ ‡§¨‡•â‡§∂ ‡§ï‡•á ‡§∞‡•ã‡§¨‡•ã‡§ü‡•à‡§ï‡•ç‡§∏‡§ø ‡§ï‡•à‡§≤‡§ø‡§´‡•ã‡§∞‡•ç‡§®‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§Ç‡§ó‡•á</a></li>
<li><a href="../hi429426/index.html">QGIS ‡§î‡§∞ ‡§ü‡§æ‡§á‡§≤ ‡§®‡§ø‡§∞‡•ç‡§Ø‡§æ‡§§</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïú ü§æüèø üñáÔ∏è Cassandra pour le stockage des m√©tadonn√©es: succ√®s et √©checs üëí ‚õµÔ∏è üí´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√Ä quelles exigences le stockage de m√©tadonn√©es pour un service cloud doit-il r√©pondre? Oui, pas le plus ordinaire, mais pour les entreprises prenant e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cassandra pour le stockage des m√©tadonn√©es: succ√®s et √©checs</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/417617/"> √Ä quelles exigences le stockage de m√©tadonn√©es pour un service cloud doit-il r√©pondre?  Oui, pas le plus ordinaire, mais pour les entreprises prenant en charge les centres de donn√©es g√©ographiquement distribu√©s et Active-Active.  De toute √©vidence, le syst√®me doit √©voluer correctement, √™tre <strong>tol√©rant aux pannes et souhaiter pouvoir impl√©menter une coh√©rence des op√©rations personnalisable.</strong> <br><br>  Seule Cassandra convient √† toutes ces exigences, et rien d'autre ne convient.  Il convient de noter que Cassandra est vraiment cool, mais travailler avec elle ressemble √† des montagnes russes. <br><img src="https://habrastorage.org/webt/zs/tw/jb/zstwjb6bvwlg43rmuphw91_jtrm.jpeg"><br><br>  Dans un rapport √† Highload ++ 2017, <strong>Andrei Smirnov</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">smira</a> ) a d√©cid√© qu'il n'√©tait pas int√©ressant de parler de bien, mais il a parl√© en d√©tail de chaque probl√®me qui devait √™tre rencontr√©: de la perte de donn√©es et de la corruption, des zombies et de la perte de performances.  Ces histoires rappellent vraiment les montagnes russes, mais pour tous les probl√®mes, il existe une solution, pour laquelle vous √™tes les bienvenus au chat. <br><br>  <strong><em>√Ä propos du conf√©rencier:</em></strong> Andrey Smirnov travaille pour Virtustream, une entreprise qui impl√©mente le stockage cloud pour les entreprises.  L'id√©e est qu'Amazon conditionnellement fait le cloud pour tout le monde, et Virtustream fait les choses sp√©cifiques dont une grande entreprise a besoin. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SAyClLjN6Sk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  Quelques mots sur Virtustream </h1><br>  Nous travaillons dans une petite √©quipe compl√®tement √©loign√©e et nous sommes engag√©s dans l'une des solutions cloud Virtustream.  Il s'agit d'un nuage de stockage de donn√©es. <br><img src="https://habrastorage.org/webt/bo/rc/jh/borcjhczgtiycqzx8dz0bnh9zim.jpeg"><br><br>  En termes tr√®s simples, il s'agit d'une API compatible S3 dans laquelle vous pouvez stocker des objets.  Pour ceux qui ne savent pas ce qu'est S3, c'est juste une API HTTP avec laquelle vous pouvez t√©l√©charger des objets dans le cloud quelque part, les r√©cup√©rer, les supprimer, obtenir une liste d'objets, etc.  En outre - des fonctionnalit√©s plus complexes bas√©es sur ces op√©rations simples. <br><br>  Nous avons certaines caract√©ristiques distinctives qu'Amazon n'a pas.  L'un d'eux est ce qu'on appelle les g√©or√©gions.  Dans la situation habituelle, lorsque vous cr√©ez un r√©f√©rentiel et dites que vous stockerez des objets dans le cloud, vous devez s√©lectionner une r√©gion.  Une r√©gion est essentiellement un centre de donn√©es et vos objets ne quitteront jamais ce centre de donn√©es.  Si quelque chose lui arrive, vos objets ne seront plus disponibles. <br><br>  Nous proposons des g√©or√©gions dans lesquelles les donn√©es sont localis√©es simultan√©ment dans plusieurs centres de donn√©es (DC), au moins dans deux, comme sur la photo.  Le client peut contacter n'importe quel centre de donn√©es, pour lui c'est transparent.  Les donn√©es entre eux sont r√©pliqu√©es, c'est-√†-dire que nous travaillons en mode actif-actif et en permanence.  Cela fournit au client des fonctionnalit√©s suppl√©mentaires, notamment: <br><br><ol><li>  une plus grande fiabilit√© du stockage, de la lecture et de l'√©criture en cas de panne DC ou de perte de connectivit√©; <br></li><li>  la disponibilit√© des donn√©es m√™me si l'un des contr√¥leurs de domaine tombe en panne; <br></li><li>  rediriger les op√©rations vers le contr√¥leur de domaine ¬´le plus proche¬ª. <br></li></ol><br>  Il s'agit d'une opportunit√© int√©ressante - m√™me si ces contr√¥leurs de domaine sont g√©ographiquement √©loign√©s, certains d'entre eux peuvent √™tre plus proches du client √† diff√©rents moments.  Et l'acc√®s aux donn√©es au contr√¥leur de domaine le plus proche est tout simplement plus rapide. <br><img src="https://habrastorage.org/webt/k-/ry/dl/k-rydl_mt74-eybwakpv1dpqjum.jpeg"><br><br>  Afin de diviser la construction dont nous parlerons en parties, je pr√©senterai ces objets qui sont stock√©s dans le nuage en deux gros morceaux: <br><br>  1. La premi√®re pi√®ce simple d'un objet est une <strong>donn√©e</strong> .  Ils sont inchang√©s, ils ont √©t√© t√©l√©charg√©s une fois et c'est tout.  La seule chose qui peut leur arriver par la suite, c'est que nous pouvons les retirer s'ils ne sont plus n√©cessaires. <br><br>  Notre projet pr√©c√©dent √©tait li√© au stockage d'exaoctets de donn√©es, nous n'avons donc eu aucun probl√®me avec le stockage de donn√©es.  C'√©tait d√©j√† une t√¢che r√©solue pour nous. <br><br>  2. <strong>M√©tadonn√©es</strong> .  Toute logique m√©tier, la plus int√©ressante, li√©e √† la concurrence: acc√®s, enregistrements, r√©√©critures - dans le domaine des m√©tadonn√©es. <br><br>  Les m√©tadonn√©es sur l'objet prennent en elles-m√™mes la plus grande complexit√© du projet, les m√©tadonn√©es stockent un pointeur sur le bloc de donn√©es stock√©es de l'objet. <br><br>  Du point de vue de l'utilisateur, il s'agit d'un objet unique, mais nous pouvons le diviser en deux parties.  Aujourd'hui, je ne parlerai <strong>que des m√©tadonn√©es</strong> . <br><br><h2>  Les chiffres <br></h2><br><ul><li>  <strong>Donn√©es</strong> : 4 octets. </li><li>  <strong>Clusters de m√©tadonn√©es</strong> : 3. </li><li>  <strong>Objets</strong> : 40 milliards. </li><li>  <strong>Taille des m√©tadonn√©es</strong> : 160 To (y compris la r√©plication). </li><li>  <strong>Taux de changement (m√©tadonn√©es):</strong> 3000 objets / s. </li></ul><br>  Si vous regardez attentivement ces indicateurs, la premi√®re chose qui attire votre attention est la tr√®s petite taille moyenne de l'objet stock√©.  Nous avons beaucoup de m√©tadonn√©es par volume unitaire de donn√©es de base.  Pour nous, ce n'√©tait pas moins une surprise que peut-√™tre pour vous maintenant. <br><br>  Nous avions pr√©vu d'avoir au moins un ordre de donn√©es, sinon 2, de plus que des m√©tadonn√©es.  Autrement dit, chaque objet sera consid√©rablement plus grand et la quantit√© de m√©tadonn√©es sera moindre.  Parce que les donn√©es sont moins ch√®res √† stocker, moins d'op√©rations avec elles et les m√©tadonn√©es sont beaucoup plus ch√®res √† la fois dans le sens du mat√©riel, et dans le sens de l'entretien et de l'ex√©cution de diverses op√©rations sur elles. <br><br>  De plus, ces donn√©es changent √† une vitesse assez √©lev√©e.  J'ai donn√© la valeur de cr√™te ici, la valeur non cr√™te n'est pas beaucoup moins, mais, n√©anmoins, une charge assez importante peut √™tre obtenue √† des moments sp√©cifiques. <br><br>  Ces chiffres ont d√©j√† √©t√© obtenus √† partir d'un syst√®me fonctionnel, mais revenons un peu en arri√®re, √† l'√©poque de la conception du stockage cloud. <br><br><h1>  Choix d'un r√©f√©rentiel pour les m√©tadonn√©es </h1><br>  Lorsque nous avons √©t√© confront√©s au d√©fi que nous voulons avoir des g√©or√©gions, Active-Active, et que nous devons stocker des m√©tadonn√©es quelque part, nous pensions que cela pourrait √™tre? <br><br>  De toute √©vidence, le r√©f√©rentiel (base de donn√©es) doit avoir les propri√©t√©s suivantes: <br><br><ul><li>  <strong>Support actif-actif</strong> ; </li><li>  <strong>√âvolutivit√©.</strong> </li></ul><br>  Nous aimerions vraiment que notre produit soit extr√™mement populaire, et nous ne savons pas comment il √©voluera en m√™me temps, donc le syst√®me devrait √©voluer. <br><br><ul><li>  <strong>L'√©quilibre entre la tol√©rance aux pannes et la fiabilit√© du stockage.</strong> </li></ul><br>  Les m√©tadonn√©es doivent √™tre stock√©es en toute s√©curit√©, car si nous les perdons et qu'il y avait un lien vers les donn√©es qu'elles contiennent, alors nous perdrons tout l'objet. <br><br><ul><li>  <strong>Coh√©rence des op√©rations personnalisable.</strong> </li></ul><br>  √âtant donn√© que nous travaillons dans plusieurs contr√¥leurs de domaine et permettons la possibilit√© que les contr√¥leurs de domaine soient indisponibles, en outre, les contr√¥leurs de domaine sont √©loign√©s les uns des autres, nous ne pouvons pas, pendant la plupart des op√©rations API, exiger que cette op√©ration soit effectu√©e simultan√©ment deux DC.  Ce sera trop lent et impossible si le deuxi√®me DC n'est pas disponible.  Par cons√©quent, une partie des op√©rations devrait fonctionner localement dans un seul contr√¥leur de domaine. <br><br>  Mais, √©videmment, une sorte de convergence devrait se produire √† un moment donn√© et apr√®s avoir r√©solu tous les conflits, les donn√©es devraient √™tre visibles dans les deux centres de donn√©es.  Par cons√©quent, la coh√©rence des op√©rations doit √™tre ajust√©e. <br><br>  De mon point de vue, Cassandra convient √† ces exigences. <br><br><h1>  Cassandra </h1><br>  Je serais tr√®s heureux si nous n'avions pas √† utiliser Cassandra, car pour nous, c'√©tait une sorte de nouvelle exp√©rience.  Mais rien d'autre ne convient.  Il me semble que c'est la situation la plus triste sur le march√© pour de tels syst√®mes de stockage - pas d' <strong>alternative</strong> . <br><br><img src="https://habrastorage.org/webt/ge/l-/xo/gel-xoykdx5yx1-sb36hjinlsas.jpeg"><br><br><h3>  Qu'est-ce que Cassandra? <br></h3><br>  Il s'agit d'une base de donn√©es de valeurs-cl√©s distribu√©e.  Du point de vue de l'architecture et des id√©es qui y sont ancr√©es, il me semble que tout est cool.  Si je le faisais, je ferais de m√™me.  Lorsque nous avons commenc√©, nous avons pens√© √† √©crire notre propre syst√®me de stockage de m√©tadonn√©es.  Mais plus nous nous rendons compte de plus en plus que nous devrons faire quelque chose de tr√®s similaire √† Cassandra, et les efforts que nous y consacrerons n'en valent pas la peine.  Pour l'ensemble du d√©veloppement <strong>, nous n'avions qu'un mois et demi</strong> .  Il serait √©trange de les d√©penser pour √©crire votre base de donn√©es. <br><br>  Si Cassandra √©tait en couches comme un g√¢teau de couches, je s√©lectionnerais 3 couches: <br><br>  1. <strong>Stockage KV local sur chaque n≈ìud.</strong> <br>  Il s'agit d'un cluster de n≈ìuds, chacun pouvant stocker localement des donn√©es de valeur-cl√©. <br><br>  2. <strong>Partage des donn√©es sur les n≈ìuds (hachage coh√©rent).</strong> <br>  Cassandra peut distribuer des donn√©es entre les n≈ìuds du cluster, y compris la r√©plication, et il le fait de telle sorte que le cluster peut augmenter ou diminuer en taille, et les donn√©es seront redistribu√©es. <br><br>  3. Un <strong>coordinateur pour rediriger les demandes vers d'autres n≈ìuds.</strong> <br>  Lorsque nous acc√©dons aux donn√©es de certaines requ√™tes de notre application, Cassandra peut distribuer notre requ√™te en n≈ìuds afin que nous obtenions les donn√©es que nous voulons et avec le niveau de coh√©rence dont nous avons besoin - nous voulons simplement les lire quorum, ou souhaitez un quorum avec deux DC, etc. <br><img src="https://habrastorage.org/webt/zs/tw/jb/zstwjb6bvwlg43rmuphw91_jtrm.jpeg"><br><br>  Pour nous, deux ans avec Cassandra - c'est un roller coaster ou un roller coaster - tout ce que vous voulez.  Tout a commenc√© en profondeur, nous n'avions aucune exp√©rience avec Cassandra.  Nous avions peur.  Nous avons commenc√© et tout allait bien.  Mais des chutes et des d√©collages constants commencent: le probl√®me, tout est mauvais, nous ne savons pas quoi faire, nous obtenons des erreurs, puis nous r√©solvons le probl√®me, etc. <br><br>  Ces montagnes russes, en principe, ne se terminent pas √† ce jour. <br><br><h1>  Bon </h1><br>  Le premier et dernier chapitre, o√π je dis que Cassandra est cool.  C'est vraiment cool, un excellent syst√®me, mais si je continue √† dire √† quel point c'est bon, je pense que vous ne serez pas int√©ress√©.  Par cons√©quent, nous ferons plus attention aux mauvais, mais plus tard. <br><br>  Cassandra est vraiment bonne. <br><br><ul><li>  C'est l'un des syst√®mes qui nous permet d'avoir <strong>un temps de r√©ponse en millisecondes</strong> , c'est-√†-dire √©videmment inf√©rieur √† 10 ms.  C'est bon pour nous, car le temps de r√©ponse en g√©n√©ral est important pour nous.  L'op√©ration avec des m√©tadonn√©es pour nous n'est qu'une partie de toute op√©ration li√©e au stockage d'un objet, qu'il soit en r√©ception ou en enregistrement. </li><li>  D'un point de vue d'enregistrement, <strong>une √©volutivit√© √©lev√©e est</strong> obtenue.  Vous pouvez √©crire dans Cassandra √† une vitesse folle, et dans certaines situations, cela est n√©cessaire, par exemple, lorsque nous d√©pla√ßons de grandes quantit√©s de donn√©es entre les enregistrements. </li><li>  Cassandra est vraiment <strong>tol√©rante aux pannes</strong> .  La chute d'un n≈ìud ne conduit pas imm√©diatement √† des probl√®mes, mais t√¥t ou tard, ils commenceront.  Cassandra d√©clare qu'elle n'a pas un seul point d'√©chec, mais, en fait, il y a des points d'√©chec partout.  En fait, celui qui a travaill√© avec la base de donn√©es sait que m√™me un crash de n≈ìud n'est pas quelque chose qui souffre g√©n√©ralement jusqu'au matin.  Habituellement, cette situation doit √™tre corrig√©e plus rapidement. </li><li>  <strong>Simplicit√©.</strong>  Pourtant, par rapport aux autres bases de donn√©es relationnelles Cassandra standard, il est plus facile de comprendre ce qui se passe.  Tr√®s souvent, quelque chose ne va pas et nous devons comprendre ce qui se passe.  Cassandra a plus de chances de le comprendre, d'obtenir la plus petite vis, probablement, qu'avec une autre base de donn√©es. </li></ul><br><h1>  Cinq mauvaises histoires </h1><br>  Je le r√©p√®te, Cassandra est bonne, cela fonctionne pour nous, mais je vais raconter cinq histoires de mauvais.  Je pense que c'est pour cela que vous l'avez lu.  Je vais donner les histoires par ordre chronologique, bien qu'elles ne soient pas tr√®s li√©es les unes aux autres. <br><img src="https://habrastorage.org/webt/ao/15/oa/ao15oaiwdhwvl4w4u5pvcgwolrq.jpeg"><br><br>  Cette histoire a √©t√© la plus triste pour nous.  Puisque nous stockons des donn√©es utilisateur, la pire chose possible est de les perdre, et de les <strong>perdre pour toujours</strong> , comme cela s'est produit dans cette situation.  Nous avons fourni des moyens de r√©cup√©rer des donn√©es si nous les perdons dans Cassandra, mais nous les avons perdues de sorte que nous ne pouvions vraiment pas r√©cup√©rer. <br><br>  Afin d'expliquer comment cela se produit, je vais devoir parler un peu de la fa√ßon dont tout est organis√© en nous. <br><img src="https://habrastorage.org/webt/6i/vf/gk/6ivfgkdspndo3kzyy153iveq4xq.jpeg"><br><br>  Du point de vue S3, il y a quelques √©l√©ments de base: <br><br><ul><li>  Bucket - il peut √™tre imagin√© comme un √©norme catalogue dans lequel l'utilisateur t√©l√©charge un objet (ci-apr√®s d√©nomm√© le bucket). </li><li>  Chaque objet a un nom (cl√©) et des m√©tadonn√©es qui lui sont associ√©es: taille, type de contenu et un pointeur vers les donn√©es de l'objet.  Dans le m√™me temps, la taille du seau n'est limit√©e par rien.  Autrement dit, il peut s'agir de 10 cl√©s, peut-√™tre de 100 milliards de cl√©s - il n'y a pas de diff√©rence. </li><li>  Toutes les op√©rations concurrentielles sont possibles, c'est-√†-dire qu'il peut y avoir plusieurs remplissages comp√©titifs dans la m√™me cl√©, il peut y avoir une suppression concurrentielle, etc. </li></ul><br>  Dans notre situation, des op√©rations actives-actives peuvent se produire, y compris de mani√®re comp√©titive dans diff√©rents DC, pas seulement dans un.  Par cons√©quent, nous avons besoin d'une sorte de sch√©ma de conservation qui nous permettra de mettre en ≈ìuvre une telle logique.  Au final, nous avons choisi une politique simple: la derni√®re version enregistr√©e l'emporte.  Parfois, plusieurs op√©rations concurrentielles ont lieu, mais il n'est pas n√©cessaire que nos clients le fassent expr√®s.  Il peut s'agir simplement d'une demande qui a commenc√©, mais le client n'a pas attendu de r√©ponse, quelque chose d'autre s'est produit, a r√©essay√©, etc. <br><br>  Par cons√©quent, nous avons deux tables de base: <br><br><ol><li>  <strong>Table d'objets</strong> .  Dans ce document, une paire - le nom du compartiment et le nom de la cl√© - est associ√©e √† sa version actuelle.  Si l'objet est supprim√©, il n'y a rien dans cette version.  Si l'objet existe, il existe sa version actuelle.  En fait, dans ce tableau, nous modifions uniquement le champ de la version actuelle. <br></li><li>  <strong>Table de version des objets</strong> .  Nous n'ins√©rons que de nouvelles versions dans ce tableau.  Chaque fois qu'un nouvel objet est t√©l√©charg√©, nous ins√©rons une nouvelle version dans le tableau des versions, lui donnons un num√©ro unique, enregistrons toutes les informations le concernant et, √† la fin, mettons √† jour le lien vers celui-ci dans le tableau des objets. <br></li></ol><br>  La figure montre un exemple de la fa√ßon dont les tables d'objets et les versions d'objets sont li√©es. <br><img src="https://habrastorage.org/webt/rv/jm/3y/rvjm3y1ohf-9yiehp1ajlm4zjik.jpeg"><br><br>  Voici un objet qui a deux versions - une actuelle et une ancienne, il y a un objet qui a d√©j√† √©t√© supprim√© et sa version est toujours l√†.  Nous devons nettoyer de temps en temps les versions inutiles, c'est-√†-dire supprimer quelque chose auquel personne d'autre ne fait r√©f√©rence.  De plus, nous n'avons pas besoin de le supprimer tout de suite, nous pouvons le faire en mode diff√©r√©.  Il s'agit de notre nettoyage interne, nous supprimons simplement ce qui n'est plus n√©cessaire. <br><br>  Il y avait un probl√®me. <br><img src="https://habrastorage.org/webt/md/rc/xy/mdrcxyc9ojwdjuwchg7gsgkspio.jpeg"><br><br>  Le probl√®me √©tait le suivant: nous avons actif-actif, deux DC.  Dans chaque DC, les m√©tadonn√©es sont stock√©es en trois copies, c'est-√†-dire que nous avons 3 + 3 - seulement 6 r√©pliques.  Lorsque les clients nous contactent, nous effectuons des op√©rations avec coh√©rence (du point de vue de Cassandra cela s'appelle LOCAL_QUORUM).  Autrement dit, il est garanti que l'enregistrement (ou la lecture) s'est produit dans 2 r√©pliques dans le contr√¥leur de domaine local.  Ceci est une garantie - sinon l'op√©ration √©chouera. <br><br>  Cassandra essaiera toujours d'√©crire dans les 6 lignes - 99% du temps tout ira bien.  En fait, les 6 r√©pliques seront les m√™mes, mais garanties pour nous 2. <br><br>  Nous avons eu une situation difficile, m√™me si ce n'√©tait m√™me pas une g√©or√©gion.  M√™me pour les r√©gions ordinaires qui se trouvent dans un DC, nous avons toujours stock√© la deuxi√®me copie des m√©tadonn√©es dans un autre DC.  C'est une longue histoire, je ne donnerai pas tous les d√©tails.  Mais √† la fin, nous avons eu un processus de nettoyage qui a supprim√© les versions inutiles. <br><br>  Et puis le m√™me probl√®me s'est pos√©.  Le processus de nettoyage a √©galement fonctionn√© avec la coh√©rence du quorum local dans un centre de donn√©es, car cela n'a aucun sens de le faire fonctionner en deux - ils se battront. <br><br>  Tout allait bien jusqu'√† ce qu'il s'av√®re que nos utilisateurs √©crivent encore parfois dans un autre centre de donn√©es, ce que nous ne soup√ßonnions pas.  Tout a √©t√© mis en place juste au cas o√π le feylover, mais il s'est av√©r√© qu'ils l'utilisaient d√©j√†. <br><img src="https://habrastorage.org/webt/sa/cs/6q/sacs6qjj7og_ay7jbmkhfkjh9ei.jpeg"><br><br>  La plupart du temps, tout allait bien jusqu'au jour o√π une situation s'est produite lorsqu'un enregistrement dans la table des versions a √©t√© r√©pliqu√© dans les deux contr√¥leurs de domaine, mais l'enregistrement dans la table des objets s'est av√©r√© ne se trouver que dans un seul contr√¥leur de domaine, mais n'est pas entr√© dans le second.  En cons√©quence, la proc√©dure de nettoyage, lanc√©e dans le premier DC (sup√©rieur), a vu qu'il y avait une version √† laquelle personne ne faisait r√©f√©rence et l'a supprim√©e.  Et j'ai supprim√© non seulement la version, mais aussi, bien s√ªr, les donn√©es - tout est compl√®tement, car ce n'est qu'un objet inutile.  Et cette suppression est irr√©vocable. <br><br>  Bien s√ªr, il y a un ¬´boom¬ª suppl√©mentaire, car nous avons encore un enregistrement dans la table des objets qui fait r√©f√©rence √† une version qui n'existe plus. <br><br>  Donc, la premi√®re fois que nous avons perdu des donn√©es, nous les avons perdues de mani√®re irr√©vocable - bien, un peu. <br><br><h3>  Solution </h3><br>  Que faire  Dans notre situation, tout est simple. <br><br>  Comme nous avons des donn√©es stock√©es dans deux centres de donn√©es, le processus de nettoyage est un processus de convergence et de synchronisation.  Nous devons lire les donn√©es des deux DC.  Ce processus ne fonctionnera que lorsque les deux contr√¥leurs de domaine seront disponibles.  Puisque j'ai dit que c'est un processus retard√© qui ne se produit pas pendant le traitement de l'API, ce n'est pas effrayant. <br><br>  <strong>La coh√©rence TOUT</strong> est une caract√©ristique de Cassandra 2. Dans Cassandra 3, tout va un peu mieux - il y a un niveau de coh√©rence, qui est appel√© quorum dans chaque DC.  Mais en tout cas, il y a le probl√®me qu'il est <strong>lent</strong> , car, tout d'abord, nous devons nous tourner vers le DC distant.  Deuxi√®mement, dans le cas de la coh√©rence des 6 n≈ìuds, cela signifie que cela fonctionne √† la vitesse du pire de ces 6 n≈ìuds. <br><br>  Mais en m√™me temps, le processus dit de <strong>r√©paration en lecture</strong> se produit, lorsque toutes les r√©pliques ne sont pas synchrones.  Autrement dit, lorsque l'enregistrement a √©chou√© quelque part, ce processus les r√©pare simultan√©ment.  C‚Äôest ainsi que Cassandra fonctionne. <br><br>  Lorsque cela s'est produit, nous avons re√ßu une plainte du client selon laquelle l'objet n'√©tait pas disponible.  Nous l'avons compris, compris pourquoi, et la premi√®re chose que nous voulions faire √©tait de d√©couvrir combien d'autres objets de ce type nous avions.  Nous avons ex√©cut√© un script qui tentait de trouver une construction similaire √† celle-ci lorsqu'il y avait une entr√©e dans une table, mais aucune entr√©e dans une autre. <br><br>  Soudain, nous avons constat√© que nous poss√©dions <strong>10% de ces enregistrements</strong> .  Rien de pire, probablement, n'aurait pas pu se produire si nous n'avions pas devin√© que ce n'√©tait pas le cas.  Le probl√®me √©tait diff√©rent. <br><br><img src="https://habrastorage.org/webt/kc/jt/_d/kcjt_dh03wmb-6szvtrgxqz-hme.jpeg"><br><br>  Des zombies se sont gliss√©s dans notre base de donn√©es.  Il s'agit du nom semi-officiel de ce probl√®me.  Pour comprendre de quoi il s'agit, vous devez parler du fonctionnement de la suppression √† Cassandra. <br><img src="https://habrastorage.org/webt/k2/sd/2j/k2sd2jvngn9ouhiv6b3yre0s8vs.jpeg"><br><br>  Par exemple, nous avons des donn√©es <strong><em>x</em></strong> qui sont enregistr√©es et parfaitement r√©pliqu√©es sur les 6 r√©pliques.  Si nous voulons le supprimer, la suppression, comme toute op√©ration dans Cassandra, peut ne pas √™tre effectu√©e sur tous les n≈ìuds. <br><br>  Par exemple, nous voulions garantir la coh√©rence de 2 sur 3 dans un DC.  Laissez l'op√©ration de suppression √™tre effectu√©e sur cinq n≈ìuds, mais restez sur un enregistrement, par exemple, car le n≈ìud n'√©tait pas disponible √† ce moment. <br><img src="https://habrastorage.org/webt/lu/d5/ot/lud5otv1dguftzwinkrb2wpeaaq.jpeg"><br><br>  Si nous supprimons cela et essayons ensuite de lire ¬´Je veux 2 sur 3¬ª avec la m√™me coh√©rence, alors Cassandra, voyant la valeur et son absence, interpr√®te cela comme la pr√©sence de donn√©es.  Autrement dit, en relisant, elle dira: "Oh, il y a des donn√©es!", Bien que nous les ayons supprim√©es.  Par cons√©quent, vous ne pouvez pas supprimer de cette mani√®re. <br><img src="https://habrastorage.org/webt/m6/li/ol/m6liolpvsglhmd_9wjg1gvkascw.jpeg"><br><br>  Cassandra enl√®ve diff√©remment.  <strong>La suppression est en fait un record</strong> .  Lorsque nous supprimons des donn√©es, Cassandra √©crit un petit marqueur appel√© <strong>Tombstone</strong> (tombstone).  Il marque que les donn√©es sont supprim√©es.  Ainsi, si nous lisons le jeton de suppression et les donn√©es en m√™me temps, Cassandra pr√©f√®re toujours le jeton de suppression dans cette situation et dit qu'il n'y a en fait aucune donn√©e.  Voil√† ce dont vous avez besoin. <br><br>  <strong>Tombstone ‚Äî   </strong> , , ,      , -     ,     .   Tombstone     .   <strong>Tombstone   gc_grace_period </strong> .   ,   ,   . <br><br>   ? <br><br><h2> Repair <br></h2><br>  Cassandra  ,   Repair ().   ‚Äî  ,     .       ,  ,      ,     , / ,  , -  - ,    ..     . Repair  ,    . <br><img src="https://habrastorage.org/webt/hj/td/x0/hjtdx0thzgak5uhzjd_ejn09s1m.jpeg"><br><br>   , -   , -   .  Repair    ,    ,    .  - ,     ‚Äî     .     ,    . <br><img src="https://habrastorage.org/webt/qe/ee/kj/qeeekjf-dzxokqp6c4zi1aylljm.jpeg"><br><br>     Repair,       ,  ,      ,    ‚Äî ,   .   6     .     ‚Äî ,   ,     . <br><img src="https://habrastorage.org/webt/c7/qo/o2/c7qoo2bykcraic_gbj8fxbxrmoo.jpeg"><br><br>     ,      ‚Äî ,  -  .      ,    .        ,  - ,    ,       ,    . <br><br><h3>  Solution <br></h3><br>   ,   : <br><br><ul><li> <strong>Repair       </strong> . </li></ul><br>    ,      repair.    ,          ,       . <br><br><ul><li> <strong>    ,    Tombstones,   ,   repair.</strong> </li></ul><br>  repair ‚Äî   ,     repair. ,  ,          10-20 , , 3 .    Tombstone     ,     .      ,  ,      -. <br><img src="https://habrastorage.org/webt/18/yp/cc/18ypccovl1xcoxairec6nf3ssx0.jpeg"><br><br>      Cassandra,     .       . <br><br>  S3  .   ,      ‚Äî 10 , 100  .   API,     ‚Äî      .     , ,  , ,   ,         .  ,    ,  ,    ‚Äî     ,    .      . <br><br>    API? <br><img src="https://habrastorage.org/webt/1l/tl/hd/1ltlhdhdtgnwgxezzz8jsnavvky.jpeg"><br><br>   ,     ‚Äî , ,   ‚Äî    ,    ,    .    .              ‚Äî .   ,     ,   .   ,   ,      Cassandra.    ,         ‚Äî  ,  ,    ,      . <br><br>        ,          ,      ,  ,  .          ,      . ,   ,             . ,   - ,           . <br><br> Cassandra ,       .           ,       ,  ,   ,       ,     . <br><img src="https://habrastorage.org/webt/fk/os/a3/fkosa3zozy2gk_dzpgjvxdwm4k8.jpeg"><br><br>    ,   Cassandra  <strong>composite key</strong> .       ,    ‚Äî    ,   - ,      ‚Äî  .    ,   .   ? ,   ,    ! <br><br>      ,    ,  , ,      ‚Äî  ,          . <br><br>     .  Cassandra   ,   <strong>  Cassandra      </strong> .  ,     ,    Cassandra,        :  ,  ,   SQL  ..    ! <br><img src="https://habrastorage.org/webt/8o/_s/ka/8o_ska-swgmzixxiztlblopuze0.jpeg"><br><br>      .     Cassandra  ?    ,     ,   API.  ,   ,     ,   ,     (     )   . <strong>   ,   </strong>   . <br><br>    ,           .        ,   , ,    .   ,     ‚Äî   ‚Äî       . , ,  ,          . <br><br>   Cassandra   ,       .    : ¬´  100 ¬ª,    ,    ,  ,      ,        ,   100,    . <br><br> ,         (   ),    ‚Äî          ,    ,         .         ,   ,   ,   ,     ,   - .     100 ,   - ,     ,  .      ,         SQL    . <br><br> Cassandra       ,     ,     Java,    .  ,  <strong>Large Partition</strong> ,  .    ‚Äî , , ,  ,     ‚Äî  .         ,   , garbage collection    ..     . <br><br>   ,   ,  <strong>    ,   </strong> ,        . <br><br> ,        ,   -  . <br><img src="https://habrastorage.org/webt/qg/o9/oo/qgo9ooa3pgv_zqkv8iyby4ppq9g.jpeg"><br><br>   ,     ,           .      .     ,      Large Partition. <br><br>     : <br><br><ol><li>        ( ,  - ); <br></li><li>   ,    ,       .     ,     . <br></li></ol><br>   ,     ,   ,     key_hash   0.   , <strong>    ,         </strong> .       ,    .       ,      ,      . <br><br>  ,     . <br><img src="https://habrastorage.org/webt/zr/aw/xn/zrawxn-n6hr1huoqkenbqcgpeoo.jpeg"><br><br>    ‚Äî ,    ,    ,      - -      . <br><br>   ‚Äî      ,   N ?    ,  Large Partition,   ‚Äî     .  ,        .   :   .  ,    ,  ,    ,       -  .    ,           .    , ,     . <br><img src="https://habrastorage.org/webt/og/um/4y/ogum4yxqpvbvrdadna7r8adomwm.jpeg"><br><br>     ‚Äî   ,    ,   -  .    -  ,       ,       .    ,    ,    .   ,    ,        .. <br><br>         ‚Äî  ,    ?    ,   .    ? -     md5- ‚Äî      ,   -  30  ‚Äî     ,  - .    .     ,     ,   . <br><img src="https://habrastorage.org/webt/yp/ik/vy/ypikvyolprsxdju5hawmlm6_epq.jpeg"><br><br>      ,    , , ,   .       ‚Äî   ,    .    ,       .   ,    -  -   - ,  -  - ‚Äî  .     ,     .      . <br><br><h2>   </h2><br>    ,    ,     ,    . <br><br><ul><li>   . </li><li>         . </li><li>     Cassandra. </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Redistribution en ligne (sans arr√™t des op√©rations ni perte de coh√©rence). </font></font></li></ul><br>  Nous avons maintenant un √©tat du compartiment, il est en quelque sorte divis√© en partitions.  On comprend alors que certaines partitions sont trop grandes ou trop petites.  Nous devons trouver une nouvelle partition, qui, d'une part, sera optimale, c'est-√†-dire que la taille de chaque partition sera inf√©rieure √† certaines de nos limites, et elles seront plus ou moins uniformes.  Dans ce cas, la transition de l'√©tat actuel √† un nouvel √©tat doit n√©cessiter un nombre minimum d'actions.  Il est clair que toute transition n√©cessite de d√©placer des cl√©s entre les partitions, mais moins nous les d√©pla√ßons, mieux c'est. <br><br>  Nous l'avons fait.  Probablement, la partie qui traite de la s√©lection de la distribution est l'√©l√©ment le plus difficile de l'ensemble du service, si nous parlons de travailler avec les m√©tadonn√©es en g√©n√©ral.  Nous l'avons r√©√©crit, retravaill√© et le faisons toujours, car certains clients ou certains mod√®les de cr√©ation de cl√©s sont toujours trouv√©s qui ont atteint un point faible de ce sch√©ma. <br><br>  Par exemple, nous avons suppos√© que le seau se d√©velopperait plus ou moins uniform√©ment.  Autrement dit, nous avons choisi une sorte de distribution et nous esp√©rions que toutes les partitions se d√©velopperaient conform√©ment √† cette distribution.  Mais nous avons trouv√© un client qui √©crit toujours √† la fin, dans le sens o√π ses cl√©s sont toujours tri√©es.  Il bat tout le temps dans la toute derni√®re partition, qui cro√Æt √† une vitesse telle qu'en une minute, elle peut atteindre 100 000 touches.  Et 100 000 est approximativement la valeur qui tient dans une partition. <br><br>  Nous n'aurions tout simplement pas le temps de traiter un tel ajout de cl√©s avec notre algorithme, et nous avons d√ª introduire une distribution pr√©liminaire sp√©ciale pour ce client.  Puisque nous savons √† quoi ressemblent ses cl√©s, si nous voyons que c'est lui, nous commen√ßons juste √† cr√©er des partitions vides √† l'avance √† la fin, afin qu'il puisse y √©crire calmement, et jusqu'√† pr√©sent, nous aurions un peu de repos jusqu'√† la prochaine it√©ration, quand nous devrons √† nouveau tout redistribuer. <br><br>  Tout cela se passe en ligne dans le sens o√π nous n'arr√™tons pas l'op√©ration.  Il peut y avoir des op√©rations de lecture, d'√©criture, √† tout moment vous pouvez demander une liste de cl√©s.  Il sera toujours coh√©rent, m√™me si nous sommes en train de repartitionner. <br><br>  C'est assez int√©ressant, et √ßa s'av√®re avec Cassandra.  Ici, vous pouvez jouer avec des astuces li√©es au fait que Cassandra est capable de r√©soudre les conflits.  Si nous avons √©crit deux valeurs diff√©rentes sur la m√™me ligne, alors la valeur qui a un horodatage plus grand l'emporte. <br><br>  L'horodatage est g√©n√©ralement l'horodatage actuel, mais il peut √™tre transmis manuellement.  Par exemple, nous voulons √©crire une valeur dans une cha√Æne, qui dans tous les cas doit √™tre effac√©e si le client √©crit lui-m√™me quelque chose.  Autrement dit, nous copions certaines donn√©es, mais nous voulons que le client, s'il √©crit soudainement avec nous en m√™me temps, puisse les √©craser.  Ensuite, nous pouvons simplement copier nos donn√©es avec un horodatage un peu du pass√©.  Ensuite, tout enregistrement en cours sera d√©lib√©r√©ment effiloch√©, quel que soit l'ordre dans lequel l'enregistrement a √©t√© effectu√©. <br><br>  Ces astuces vous permettent de le faire en ligne. <br><br><h2>  Solution </h2><br><ul><li>  Ne <strong>laissez</strong> jamais, jamais <strong>l'apparence d'une grande partition</strong> . </li><li>  <strong>R√©partissez les donn√©es par cl√© primaire en</strong> fonction de la t√¢che. </li></ul><br>  Si quelque chose de similaire √† une grande partition est pr√©vu dans le sch√©ma de donn√©es, vous devez imm√©diatement essayer de faire quelque chose - comprendre comment le casser et comment s'en √©loigner.  T√¥t ou tard, cela se produit, car tout index invers√© se produit t√¥t ou tard dans presque toutes les t√¢ches.  Je vous ai d√©j√† racont√© une telle histoire - nous avons une cl√© de compartiment dans l'objet, et nous devons obtenir une liste de cl√©s du compartiment - en fait, c'est un index. <br><br>  De plus, la partition peut √™tre volumineuse non seulement √† partir des donn√©es, mais √©galement √† partir de pierres tombales (marqueurs de suppression).  Du point de vue des internes de Cassandra (nous ne les voyons jamais de l'ext√©rieur), les marqueurs de suppression sont √©galement des donn√©es, et une partition peut √™tre grande si beaucoup de choses y sont supprim√©es, car la suppression est un enregistrement.  N'oubliez pas non plus. <br><img src="https://habrastorage.org/webt/-s/tw/la/-stwlarb11mcy5nlqaqrpxfc-ky.jpeg"><br><br>  Une autre histoire qui est en fait constante est que quelque chose ne va pas du d√©but √† la fin.  Par exemple, vous voyez que le temps de r√©ponse de Cassandra a augment√©, il r√©pond lentement.  Comment comprendre et comprendre quel est le probl√®me?  Il n'y a jamais de signal externe indiquant que le probl√®me existe. <br><img src="https://habrastorage.org/webt/c0/lr/5r/c0lr5rwf9w5zi-nx1ddd5k5blgk.jpeg"><br><br>  Par exemple, je vais donner un graphique - c'est le temps de r√©ponse moyen du cluster dans son ensemble.  Cela montre que nous avons un probl√®me - le temps de r√©ponse maximum est de 12 secondes - c'est le timeout interne de Cassandra.  Cela signifie qu'elle va s'arr√™ter elle-m√™me.  Si le d√©lai est sup√©rieur √† 12 s, cela signifie tr√®s probablement que le ramasse-miettes fonctionne et que Cassandra n'a m√™me pas le temps de r√©pondre au bon moment.  Elle se r√©pond par timeout, mais le temps de r√©ponse √† la plupart des demandes, comme je l'ai dit, devrait √™tre en moyenne de 10 ms. <br><br>  Sur le graphique, la moyenne a d√©j√† d√©pass√© des centaines de millisecondes - quelque chose s'est mal pass√©.  Mais en regardant cette photo, il est impossible de comprendre quelle est la raison. <br><br><img src="https://habrastorage.org/webt/e6/t6/qk/e6t6qkz3yw6k80sjw7smsycclrc.jpeg"><br><br>  Mais si vous d√©veloppez les m√™mes statistiques sur les n≈ìuds Cassandra, vous pouvez voir qu'en principe, tous les n≈ìuds ne sont plus ou moins rien, mais le temps de r√©ponse pour un n≈ìud diff√®re par ordre de grandeur.  Il y a tr√®s probablement un probl√®me avec lui. <br><br>  Les statistiques sur les n≈ìuds changent compl√®tement l'image.  Ces statistiques sont du c√¥t√© de l'application.  Mais ici, il est en fait tr√®s souvent difficile de comprendre quel est le probl√®me.  Lorsqu'une application acc√®de √† Cassandra, elle acc√®de √† un n≈ìud, l'utilisant comme coordinateur.  En d'autres termes, l'application envoie une demande et le coordinateur la redirige vers les r√©pliques contenant les donn√©es.  Ceux-l√† r√©pondent d√©j√†, et le coordinateur forme la r√©ponse finale. <br><br>  Mais pourquoi le coordinateur r√©pond-il lentement?  Peut-√™tre que le probl√®me est avec lui, en tant que tel, c'est-√†-dire qu'il ralentit et r√©pond lentement?  Ou peut-√™tre qu'il ralentit, parce que les r√©pliques lui r√©pondent lentement?  Si les r√©pliques r√©pondent lentement, du point de vue de l'application, cela ressemblera √† une r√©ponse lente du coordinateur, m√™me si cela n'a rien √† voir avec cela. <br><br>  Voici une situation heureuse - il est clair qu'un seul n≈ìud r√©pond lentement, et tr√®s probablement le probl√®me est l√†-dedans. <br><br><h3>  Complexit√© de l'interpr√©tation </h3><br><br><ul><li>  Temps de r√©ponse du coordinateur (n≈ìud vs r√©plique lui-m√™me). </li><li>  Une table sp√©cifique ou le n≈ìud entier? </li><li>  GC Pause?  Pool de threads inad√©quat? </li><li>  Trop de SSTables non compact√©s? </li></ul><br>  Il est toujours difficile de comprendre ce qui ne va pas.  Il a juste <strong>besoin de beaucoup de statistiques et de surveillance</strong> , √† la fois du c√¥t√© des applications et de Cassandra lui-m√™me, car si c'est vraiment mauvais, rien n'est visible de Cassandra.  Vous pouvez regarder le niveau des requ√™tes individuelles, au niveau de chaque table sp√©cifique, √† chaque n≈ìud sp√©cifique. <br><br>  Il peut y avoir, par exemple, une situation o√π une table de ce qui est appel√© dans Cassandra SSTables (fichiers s√©par√©s) en a trop.  Pour la lecture, Cassandra doit, grosso modo, trier toutes les SSTables.  S'il y en a trop, alors simplement le processus de ce tri prend trop de temps et la lecture commence √† s'affaisser. <br><br>  La solution est le compactage, ce qui r√©duit le nombre de ces SSTables, mais il convient de noter qu'il ne peut √™tre que sur un n≈ìud pour une table sp√©cifique.  √âtant donn√© que Cassandra, malheureusement, est √©crit en Java et s'ex√©cute sur la JVM, peut-√™tre que le garbage collector est entr√© dans une telle pause qu'il n'a tout simplement pas le temps de r√©pondre.  Lorsque le garbage collector entre en pause, non seulement vos demandes ralentissent, mais l' <strong>interaction au sein du cluster Cassandra entre les n≈ìuds commence √† ralentir</strong> .  Les n≈ìuds l'un de l'autre commencent √† √™tre consid√©r√©s comme √©tant tomb√©s, c'est-√†-dire tomb√©s, morts. <br><br>  Une situation encore plus amusante commence, car lorsqu'un n≈ìud pense qu'un autre n≈ìud est en panne, il ne lui envoie pas de demandes, et deuxi√®mement, il commence √† essayer d'enregistrer les donn√©es dont il aurait besoin pour se r√©pliquer sur un autre n≈ìud √† lui-m√™me localement, alors il commence √† se tuer lentement, etc. <br><br>  Il existe des situations o√π ce probl√®me peut √™tre r√©solu simplement en utilisant les param√®tres corrects.  Par exemple, il peut y avoir suffisamment de ressources, tout va bien et merveilleux, mais juste un pool de threads, dont le nombre est de taille fixe, doit √™tre augment√©. <br><br>  Enfin, nous devons peut-√™tre limiter la comp√©titivit√© du c√¥t√© conducteur.  Parfois, il arrive que trop de demandes concurrentielles ont √©t√© envoy√©es, et comme toute base de donn√©es, Cassandra ne peut pas les traiter et va au corps √† corps lorsque le temps de r√©ponse augmente de fa√ßon exponentielle, et nous essayons de donner de plus en plus de travail. <br><br><h3>  Compr√©hension du contexte </h3><br>  Il y a toujours un certain contexte pour le probl√®me - ce qui se passe dans le cluster, si Repair fonctionne maintenant, sur quel n≈ìud, dans quels espaces cl√©s, dans quelle table. <br><br>  Par exemple, nous avons eu des probl√®mes assez ridicules avec le fer.  Nous avons vu qu'une partie des n≈ìuds est lente.  Il a √©t√© d√©couvert plus tard que la raison en √©tait que dans le BIOS, leurs processeurs √©taient en mode d'√©conomie d'√©nergie.  Pour une raison quelconque, lors de l'installation initiale de fer, cela s'est produit et environ 50% des ressources du processeur ont √©t√© utilis√©es par rapport aux autres n≈ìuds. <br><br>  En fait, comprendre un tel probl√®me peut √™tre difficile.  Le sympt√¥me est le suivant: il semble que le n≈ìud effectue le compactage, mais il le fait lentement.  Parfois, il est li√© au fer, parfois non, mais ce n'est qu'un autre bug de Cassandra. <br><br>  Par cons√©quent, la surveillance est obligatoire et n√©cessite beaucoup.  Plus la fonctionnalit√© de Cassandra est complexe, plus elle est √©loign√©e de l'√©criture et de la lecture simples, plus il y a de probl√®mes et plus vite elle peut tuer une base de donn√©es avec un nombre suffisant de requ√™tes.  Par cons√©quent, si possible, ne regardez pas des chips "savoureuses" et essayez de les utiliser, il vaut mieux les √©viter autant que possible.  Pas toujours possible - bien s√ªr, t√¥t ou tard, c'est n√©cessaire. <br><img src="https://habrastorage.org/webt/mx/m8/lx/mxm8lxirhudrxrdlcq26jpstvle.jpeg"><br><br>  La derni√®re histoire concerne la fa√ßon dont Cassandra a g√¢ch√© les donn√©es.  Dans cette situation, cela s'est produit √† l'int√©rieur de Cassandra.  C'√©tait int√©ressant. <br><br>  Nous avons vu qu'environ une fois par semaine dans notre base de donn√©es plusieurs dizaines de lignes endommag√©es apparaissent - elles sont litt√©ralement obstru√©es par des ordures.  De plus, Cassandra valide les donn√©es qui vont √† son entr√©e.  Par exemple, s'il s'agit d'une cha√Æne, elle doit √™tre dans utf8.  Mais dans ces lignes, il y avait des ordures, pas utf8, et Cassandra n'a m√™me rien donn√© √† voir avec cela.  Lorsque j'essaie de supprimer (ou de faire autre chose), je ne peux pas supprimer une valeur qui n'est pas utf8, car, en particulier, je ne peux pas la saisir dans OERE, car la cl√© doit √™tre utf8. <br><br>  Des lignes g√¢t√©es apparaissent, comme un flash, √† un moment donn√©, puis elles disparaissent √† nouveau pendant plusieurs jours ou semaines. <br><br>  Nous avons commenc√© √† chercher un probl√®me.  Nous avons pens√© qu'il y avait peut-√™tre un probl√®me dans un n≈ìud particulier avec lequel nous jouions, en faisant quelque chose avec les donn√©es, en copiant SSTables.  Peut-√™tre, tout de m√™me, vous pouvez voir des r√©pliques de ces donn√©es?  Peut-√™tre que ces r√©pliques ont un n≈ìud commun, le plus petit facteur commun?  Peut-√™tre que certains n≈ìuds se bloquent?  Non, rien de tel. <br><br>  Peut-√™tre quelque chose avec un disque?  Les donn√©es sont-elles corrompues sur le disque?  Non encore. <br><br>  Peut-√™tre un souvenir?  Non!  Dispers√© sur un cluster. <br><br>  C'est peut-√™tre une sorte de probl√®me de r√©plication?  Un n≈ìud a tout g√¢ch√© et reproduit une mauvaise valeur?  - Non. <br><br>  Enfin, c'est peut-√™tre un probl√®me d'application? <br><br>  De plus, √† un moment donn√©, les lignes endommag√©es ont commenc√© √† appara√Ætre dans deux grappes de Cassandra.  L'un a travaill√© sur la version 2.1, le second sur le troisi√®me.  Il semble que Cassandra soit diff√©rente, mais le probl√®me est le m√™me.  Peut-√™tre que notre service envoie de mauvaises donn√©es?  Mais c'√©tait difficile √† croire.  Cassandra valide les donn√©es d'entr√©e; elle n'a pas pu √©crire d'ordures.  Mais tout d'un coup? <br><br>  Rien ne va. <br><br><h3>  Une aiguille a √©t√© trouv√©e! </h3><br>  Nous nous sommes battus longtemps et durement jusqu'√† ce que nous d√©couvrions un petit probl√®me: pourquoi avons-nous une sorte de vidage sur incident de la JVM sur les n≈ìuds auquel nous n'avons pas pr√™t√© beaucoup d'attention?  Et d'une mani√®re ou d'une autre, cela semble suspect dans le collecteur de d√©chets de trace de pile ... Et pour une raison quelconque, certaines traces de pile sont √©galement obstru√©es par des d√©chets. <br><br>  En fin de compte, nous avons r√©alis√© - oh, <strong>pour une raison quelconque, nous utilisons la JVM de l'ancienne version de 2015</strong> .  C'√©tait la seule chose courante qui unissait les clusters Cassandra sur diff√©rentes versions de Cassandra. <br><br>  Je ne sais toujours pas quel √©tait le probl√®me, car rien n‚Äô√©tait √©crit √† ce sujet dans les notes de version officielles de la JVM.  Mais apr√®s la mise √† jour, tout a disparu, le probl√®me ne s'est plus pos√©.  De plus, cela ne s'est pas produit dans le cluster d√®s le premier jour, mais √† un moment donn√©, bien qu'il ait longtemps fonctionn√© sur la m√™me machine virtuelle Java. <br><br><h3>  R√©cup√©ration de donn√©es </h3><br>  Quelle le√ßon en avons-nous tir√©e: <br><br>  ‚óè La sauvegarde est inutile. <br>  Comme nous l'avons d√©couvert, les donn√©es ont √©t√© corrompues d√®s la seconde o√π elles ont √©t√© enregistr√©es.  Au moment o√π les donn√©es sont entr√©es dans le coordinateur, elles √©taient d√©j√† corrompues. <br><br>  ‚óè Une restauration partielle des colonnes intactes est possible. <br>  Certaines colonnes n'ont pas √©t√© endommag√©es, nous avons pu lire ces donn√©es, les restaurer partiellement. <br><br>  ‚óè En fin de compte, nous avons d√ª effectuer une r√©cup√©ration √† partir de diverses sources. <br>  Nous avions des m√©tadonn√©es de sauvegarde dans l'objet, mais dans les donn√©es elles-m√™mes.  Pour renouer avec l'objet, nous avons utilis√© des journaux, etc. <br><br>  ‚óè Les journaux sont inestimables! <br>  Nous avons pu r√©cup√©rer toutes les donn√©es corrompues, mais au final, il est tr√®s difficile de faire confiance √† la base de donn√©es si elle perd vos donn√©es m√™me sans aucune action de votre part. <br><br><h3>  Solution </h3><br><ul><li>  Mettez √† jour la JVM apr√®s des tests approfondis. </li><li>  Surveillance des plantages JVM. </li><li>  Ayez une copie ind√©pendante de Cassandra des donn√©es. </li></ul><br><blockquote>  <strong>Un conseil:</strong> essayez d'avoir une sorte de copie ind√©pendante de Cassandra des donn√©es √† partir de laquelle vous pouvez r√©cup√©rer si n√©cessaire.  Cela peut √™tre la solution de dernier niveau.  Laissez cela prendre beaucoup de temps, de ressources, mais il devrait y avoir une option qui vous permettra de renvoyer des donn√©es. </blockquote><br><h1>  Bugs </h1><br>  ‚óè <strong>Mauvaise qualit√© des tests de version</strong> <br>  Lorsque vous commencez √† travailler avec Cassandra, il y a un sentiment constant (surtout si vous vous d√©placez, relativement parlant, de ¬´bonnes¬ª bases de donn√©es, par exemple, PostgreSQL) que si vous avez corrig√© un bogue dans la version de la pr√©c√©dente, vous en ajouterez certainement un nouveau.  Et le bug n'est pas un non-sens, il s'agit g√©n√©ralement de donn√©es corrompues ou d'un autre comportement incorrect. <br><br>  ‚óè <strong>Probl√®mes persistants avec des fonctionnalit√©s complexes</strong> <br>  Plus la fonctionnalit√© est complexe, plus elle pose de probl√®mes, de bugs, etc. <br><br>  ‚óè <strong>N'utilisez pas de r√©paration incr√©mentielle en 2.1</strong> <br>  La fameuse r√©paration, dont j'ai parl√©, qui corrige la coh√©rence des donn√©es, en mode standard, quand elle interroge tous les n≈ìuds, fonctionne bien.  Mais pas dans le mode dit incr√©mentiel (lorsque la r√©paration ignore les donn√©es qui n'ont pas chang√© depuis la r√©paration pr√©c√©dente, ce qui est assez logique).  Il a √©t√© annonc√© il y a longtemps, officiellement, car une fonctionnalit√© existe, mais tout le monde dit: ¬´Non, dans la version 2.1, ne l'utilisez jamais!  Il va certainement manquer quelque chose.  En 3, nous le r√©parons. ¬ª <br><br>  ‚óè <strong>Mais n'utilisez pas la r√©paration incr√©mentielle dans 3.x</strong> <br>  Lorsque la troisi√®me version est sortie, quelques jours plus tard, ils ont dit: ¬´Non, vous ne pouvez pas l'utiliser dans la 3e.  Il y a une liste de 15 bugs, donc en aucun cas n'utilisez pas de r√©paration incr√©mentielle.  En 4e, nous ferons mieux! ¬ª <br><br>  Je ne les crois pas.  Et c'est un gros probl√®me, surtout avec l'augmentation de la taille du cluster.  Par cons√©quent, vous devez surveiller constamment leur bugtracker et voir ce qui se passe.  Malheureusement, il est impossible de vivre avec eux sans lui. <br><br>  ‚óè <strong>Besoin de garder une trace de JIRA</strong> <br><img src="https://habrastorage.org/webt/g0/1k/el/g01kela-ibcrrsorr1pjxo-pmdc.jpeg"><br><br><blockquote>  Si vous dispersez toutes les bases de donn√©es sur le spectre de pr√©visibilit√©, pour moi, Cassandra est √† gauche dans la zone rouge.  Cela ne veut pas dire que c'est mauvais, il suffit de se pr√©parer au fait que Cassandra est impr√©visible dans tous les sens du terme: √† la fois dans la fa√ßon dont cela fonctionne et dans le fait que quelque chose peut arriver. </blockquote><br><img src="https://habrastorage.org/webt/je/_1/w0/je_1w0808rlhzxo1bakk0zjj9ee.jpeg"><br><br>  Je vous souhaite de trouver d'autres r√¢teaux et de marcher dessus, car, de mon point de vue, quoi qu'il arrive, Cassandra est bonne et certainement pas ennuyeuse.  N'oubliez pas les bosses sur la route! <br><br><blockquote>  <strong>R√©union ouverte des militants de HighLoad ++</strong> <br><br>  Le 31 juillet √† Moscou, √† 19h00, une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©union des</a> orateurs, du Comit√© du programme et des militants de la conf√©rence des d√©veloppeurs de syst√®mes √† haute charge HighLoad ++ 2018 aura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lieu</a> . Nous organiserons un petit brainstorming sur le programme de cette ann√©e afin de ne rien manquer de nouveau et d'important.  La r√©union est ouverte, mais vous devez vous <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">inscrire</a> . <br><br>  <strong>Appel √† communications</strong> <br><br>  Accepter activement les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">demandes</a> de rapports √† Highload ++ 2018. Le Comit√© du programme attend votre r√©sum√© jusqu'√† la fin de l'√©t√©. <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417617/">https://habr.com/ru/post/fr417617/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417601/index.html">Choisissez un serveur. Que chercher? Liste de contr√¥le</a></li>
<li><a href="../fr417603/index.html">Annonce d'un mitap mobile: que faire lorsque l'application est devenue volumineuse?</a></li>
<li><a href="../fr417605/index.html">Bases de la mod√©lisation 3D pour l'impression 3D</a></li>
<li><a href="../fr417607/index.html">Les tests A / B ne fonctionnent pas. V√©rifiez ce que vous faites mal</a></li>
<li><a href="../fr417609/index.html">Sp√©cialisation en programmation sportive sur le curseur</a></li>
<li><a href="../fr417619/index.html">Win32 / Glupteba n'est plus associ√© √† l'op√©ration Windigo</a></li>
<li><a href="../fr417621/index.html">Que s'est-il pass√© lorsque nous avons craqu√© l'exposition?</a></li>
<li><a href="../fr417627/index.html">Hyper CRM ou Mini ERP? Les affaires ont g√¢ch√©</a></li>
<li><a href="../fr417629/index.html">Delphi et C ++ Builder Community Edition</a></li>
<li><a href="../fr417631/index.html">Tutoriel vid√©o CSS Grid</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
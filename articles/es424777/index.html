<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèæ‚Äçü§ù‚Äçüßëüèº ‚è≥ üê¶ Uso del c√≥nsul para escalar servicios con estado üè™ üßìüèæ üßíüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El 22 de septiembre, celebramos nuestro primer mitap no est√°ndar para desarrolladores de sistemas altamente cargados. Fue genial, recibi√≥ muchos comen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Uso del c√≥nsul para escalar servicios con estado</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/424777/">  <i>El 22 de septiembre, celebramos nuestro primer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mitap no est√°ndar</a> para desarrolladores de sistemas altamente cargados.</i>  <i>Fue genial, recibi√≥ muchos comentarios positivos sobre los informes y, por lo tanto, decidi√≥ no solo subirlos, sino tambi√©n descifrarlos para Habr.</i>  <i>Hoy publicamos un discurso de Ivan Bubnov, DevOps de BIT.GAMES.</i>  <i>Habl√≥ sobre la implementaci√≥n del servicio de descubrimiento de C√≥nsul en un proyecto de alta carga que ya funciona para la posibilidad de escalar r√°pidamente y conmutar por error los servicios con estado.</i>  <i>Y tambi√©n sobre la organizaci√≥n de un espacio de nombres flexible para aplicaciones de backend y dificultades.</i>  <i>Ahora una palabra para Ivan.</i> <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/X4VYCrOCD3A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Administro la infraestructura de producci√≥n en el estudio BIT.GAMES y cuento la historia de la implementaci√≥n del c√≥nsul de Hashicorp en nuestro proyecto "Guild of Heroes" - RPG de fantas√≠a con pvp as√≠ncrono para dispositivos m√≥viles.  Disponible en Google Play, App Store, Samsung, Amazon.  DAU alrededor de 100,000, en l√≠nea de 10 a 13 mil.  Creamos el juego en Unity, por lo que escribimos el cliente en C # y usamos nuestro propio lenguaje de secuencias de comandos BHL para la l√≥gica del juego.  Escribimos la parte del servidor en Golang (cambiado desde PHP).  Lo siguiente es la arquitectura esquem√°tica de nuestro proyecto. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/dd/-v/gu/dd-vgufl1o4g4sjqu8luww4f56k.png"><br>  <i>De hecho, hay muchos m√°s servicios, solo hay lo b√°sico de la l√≥gica del juego.</i> <br><br>  Entonces lo que tenemos.  De los servicios ap√°tridas, estos son: <br><br><ul><li>  nginx, que usamos como frontend y balanceadores de carga y distribuimos clientes a nuestros backends por coeficientes de peso; </li><li>  gamed: backends, aplicaciones compiladas de Go.  Este es el eje central de nuestra arquitectura, realizan la mayor parte del trabajo y se comunican con todos los dem√°s servicios de back-end. </li></ul><br>  De los servicios de Stateful, los principales que tenemos son: <br><br><ul><li>  Redis, que utilizamos para almacenar en cach√© la informaci√≥n activa (tambi√©n la utilizamos para organizar chat en el juego y almacenar notificaciones para nuestros jugadores); </li><li>  Percona Server para Mysql es un repositorio de informaci√≥n persistente (probablemente la m√°s grande y lenta de cualquier arquitectura).  Usamos la bifurcaci√≥n de MySQL y aqu√≠ hablaremos de ello con m√°s detalle hoy. </li></ul><br>  Durante el proceso de dise√±o, nosotros (como todos los dem√°s) esperamos que el proyecto tenga √©xito y proporcione un mecanismo de fragmentaci√≥n.  Se compone de dos entidades de base de datos MAINDB y los propios fragmentos. <br><br><img src="https://habrastorage.org/webt/y2/sj/h-/y2sjh-qfoxlosksflpkvxuq3cxk.png"><br><br>  MAINDB es un tipo de tabla de contenido: almacena informaci√≥n sobre qu√© datos de fragmentos particulares sobre el progreso del jugador se almacenan.  Por lo tanto, la cadena completa de recuperaci√≥n de informaci√≥n se ve m√°s o menos as√≠: el cliente accede a la interfaz, que a su vez la redistribuye por peso a uno de los backends, el backend va a MAINDB, localiza el fragmento del jugador y luego selecciona los datos directamente del fragmento en s√≠. <br><br>  Pero cuando dise√±amos, no √©ramos un gran proyecto, por lo que decidimos hacer fragmentos de fragmentos solo nominalmente.  Todos estaban ubicados en el mismo servidor f√≠sico y muy probablemente particionando la base de datos dentro del mismo servidor. <br><br>  Para la copia de seguridad, utilizamos la r√©plica cl√°sica de esclavo maestro.  No fue una muy buena soluci√≥n (dir√© por qu√© un poco m√°s tarde), pero el principal inconveniente de esa arquitectura fue que todos nuestros backends sab√≠an sobre otros servicios de backend exclusivamente por direcciones IP.  Y en el caso de otro accidente rid√≠culo en el centro de datos del tipo "lo <i>siento, nuestro ingeniero golpe√≥ el cable de su servidor mientras reparaba otro y nos tom√≥ mucho tiempo descubrir por qu√© su servidor no se pone en contacto</i> ".  En primer lugar, esta es la reconstrucci√≥n y preinstalaci√≥n de backends desde el servidor de respaldo IP para el lugar del que fall√≥.  En segundo lugar, despu√©s del incidente, es necesario restaurar a nuestro maestro del respaldo de la reserva, porque estaba en un estado inconsistente y llevarlo a un estado coordinado utilizando la misma replicaci√≥n.  Luego volvimos a montar backends y volvimos a cargar.  Todo esto, por supuesto, caus√≥ tiempo de inactividad. <br><br>  Lleg√≥ un momento en que nuestro director t√©cnico (por lo que le agradezco mucho) dijo: "Chicos, dejen de sufrir, tenemos que cambiar algo, busquemos salidas".  En primer lugar, quer√≠amos lograr un proceso de escalado y migraci√≥n simple, comprensible y, lo que es m√°s importante, f√°cil de administrar, de un lugar a otro de nuestras bases de datos si es necesario.  Adem√°s, quer√≠amos lograr una alta disponibilidad mediante la automatizaci√≥n de la conmutaci√≥n por error. <br><br><img src="https://habrastorage.org/webt/lb/96/ys/lb96yszgjsbjtriury8zxqr0loa.png"><br><br>  El eje central de nuestra investigaci√≥n se ha convertido en C√≥nsul de Hashicorp.  En primer lugar, nos aconsejaron, y en segundo lugar, nos atrajo su simplicidad, amabilidad y excelente tecnolog√≠a en una caja: servicio de descubrimiento con verificaci√≥n de salud, almacenamiento de valor clave y lo m√°s importante que quer√≠amos usar era DNS que nos resuelve direcciones del dominio service.consul. <br><br>  Consul tambi√©n proporciona excelentes interfaces de usuario web y API REST para administrar todo esto. <br><br>  En cuanto a la alta disponibilidad, elegimos dos utilidades para la conmutaci√≥n por error autom√°tica: <br><br><ul><li>  MHA para MySQL </li><li>  Redis-centinela </li></ul><br><img src="https://habrastorage.org/webt/bc/e5/dg/bce5dg_dxoi0irv9gic5e4d1jki.png"><br><br>  En el caso de MHA para MySQL, vertimos agentes en nodos con bases de datos, y esos monitorearon su estado.  Hubo un cierto tiempo de espera con la falla del maestro, despu√©s de lo cual se hizo una detenci√≥n de esclavo para mantener la coherencia y nuestro maestro de respaldo del maestro aparecido en un estado inconsistente no tom√≥ los datos.  Y agregamos un enlace web a estos agentes, que registraron all√≠ la nueva IP del maestro de respaldo en el propio C√≥nsul, luego de lo cual se introdujo la emisi√≥n de DNS. <br><br>  Con Redis-sentinel, todo es a√∫n m√°s simple.  Como √©l mismo lleva a cabo la mayor parte del trabajo, todo lo que nos quedaba por hacer era tener en cuenta en el chequeo de salud que Redis-centinela deber√≠a tener lugar exclusivamente en el nodo maestro. <br><br>  Al principio todo funcion√≥ perfectamente, como un reloj.  No tuvimos problemas en el banco de pruebas.  Pero vali√≥ la pena pasar al entorno natural de transferencia de datos de un centro de datos cargado, recordando algunas muertes de OOM (esto est√° fuera de la memoria, en el que el n√∫cleo del sistema mata el proceso) y restaurando el servicio o cosas m√°s sofisticadas que afectan la disponibilidad del servicio. ¬øC√≥mo obtuvimos inmediatamente un riesgo grave de falsos positivos o ninguna respuesta garantizada (si intenta torcer algunas comprobaciones en un intento de escapar de los falsos positivos)? <br><br><img src="https://habrastorage.org/webt/a9/8t/7i/a98t7i3cvbb18duz7mkcr8f4vqg.png"><br><br>  En primer lugar, todo depende de la dificultad de escribir el chequeo de salud correcto.  Parece que la tarea es bastante trivial: compruebe que el servicio se est√© ejecutando en su servidor y puerto pingani.  Pero, como lo ha demostrado la pr√°ctica posterior, escribir un chequeo de salud al implementar Consul es un proceso extremadamente complejo y lento.  Debido a que no se pueden prever tantos factores que afectan la disponibilidad de su servicio en el centro de datos, se detectan solo despu√©s de un cierto tiempo. <br><br>  Adem√°s, el centro de datos no es una estructura est√°tica con la que est√° inundado y funciona seg√∫n lo previsto.  Pero nosotros, desafortunadamente (o afortunadamente), descubrimos esto solo m√°s tarde, pero por ahora est√°bamos inspirados y llenos de confianza de que implementar√≠amos todo en la producci√≥n. <br><br><img src="https://habrastorage.org/webt/c3/kt/uz/c3ktuzba_fzzjqodfbfsdv6sj6k.png"><br><br>  En cuanto a la escala, dir√© brevemente: tratamos de encontrar una bicicleta terminada, pero todas est√°n dise√±adas para arquitecturas espec√≠ficas.  Y, como en el caso de Jetpants, no pudimos cumplir con las condiciones que impuso a la arquitectura de un almacenamiento persistente de informaci√≥n. <br><br>  Por lo tanto, pensamos en nuestro propio gui√≥n vinculante y pospusimos esta pregunta.  Decidimos actuar consistentemente y comenzar con la implementaci√≥n de Consul. <br><br><img src="https://habrastorage.org/webt/99/em/bk/99embkj_f7vdi-kta4rdme6ga6k.png"><br><br>  Consul es un cl√∫ster descentralizado y distribuido que funciona seg√∫n el protocolo de chismes y el algoritmo de consenso Raft. <br><br>  Tenemos un equorum independiente de cinco servidores (cinco para evitar la situaci√≥n de cerebro dividido).  Para cada nodo, derramamos el agente C√≥nsul en modo agente y derramamos todas las comprobaciones de estado (es decir, no hubo tal forma de cargar una comprobaci√≥n de estado a un servidor espec√≠fico y otras a servidores espec√≠ficos).  Healthcheck se escribi√≥ para que pasen solo donde hay un servicio. <br><br>  Tambi√©n utilizamos otra utilidad para no tener que aprender nuestro backend para resolver direcciones de un dominio espec√≠fico en un puerto no est√°ndar.  Utilizamos Dnsmasq: proporciona la capacidad de resolver de forma completamente transparente las direcciones en los nodos del cl√∫ster que necesitamos (que en el mundo real, por as√≠ decirlo, no existen, sino que existen exclusivamente dentro del cl√∫ster).  Preparamos un script autom√°tico para llenar Ansible, lo subimos todo a producci√≥n, ajustamos el espacio de nombres y nos aseguramos de que todo estuviera completo.  Y, cruzando los dedos, volvimos a cargar nuestros backends, a los que se accedi√≥ no por direcciones IP, sino por estos nombres del dominio server.consul. <br><br>  Todo comenz√≥ la primera vez, nuestra alegr√≠a no conoc√≠a l√≠mites.  Pero era demasiado temprano para alegrarnos, porque en una hora notamos que en todos los nodos donde se encuentran nuestros backends, el indicador de carga promedio aument√≥ de 0.7 a 1.0, que es un indicador bastante gordo. <br><br><img src="https://habrastorage.org/webt/em/ua/v_/emuav_oozpbvjdoa7yg1ldfeag0.png"><br><br>  Me sub√≠ al servidor para ver qu√© estaba pasando y se hizo evidente que la CPU se estaba comiendo Consul.  Aqu√≠ comenzamos a resolverlo, comenzamos a chamanizar con strace (una utilidad para sistemas unix que le permite rastrear qu√© syscall se est√° ejecutando el proceso), volcando las estad√≠sticas de Dnsmasq para comprender lo que est√° sucediendo en este nodo, y result√≥ que perdimos un punto muy importante.  Al planear la integraci√≥n, nos perdimos el almacenamiento en cach√© de los registros DNS y result√≥ que nuestro backend sac√≥ Dnsmasq para cada uno de sus movimientos, y que, a su vez, recurri√≥ al C√≥nsul y todo esto result√≥ en 940 consultas DNS por segundo. <br><br>  La salida parec√≠a obvia: solo gire ttl y todo mejorar√°.  Pero aqu√≠ era imposible ser fan√°tico, porque quer√≠amos implementar esta estructura con el fin de obtener un espacio de nombres din√°mico, f√°cil de controlar y que cambiara r√°pidamente (por lo tanto, no pudimos establecer, por ejemplo, 20 minutos).  Cambiamos ttl a los valores √≥ptimos m√°ximos para nosotros, logramos reducir la tasa de consulta por segundo a 540, pero esto no afect√≥ el indicador de consumo de CPU. <br><br>  Luego decidimos salir de una manera complicada, usando un archivo de host personalizado. <br><br><img src="https://habrastorage.org/webt/0p/li/01/0pli01ivofxzndxm9pa9xrtvu6m.png"><br><br>  Es bueno que tengamos todo para esto: un excelente sistema de plantillas de Consul, que, seg√∫n el estado del cl√∫ster y el script de plantilla, genera un archivo de cualquier tipo, cualquier configuraci√≥n es todo lo que desea.  Adem√°s, Dnsmasq tiene un par√°metro de configuraci√≥n addn-hosts que le permite utilizar un archivo de host que no sea del sistema como el mismo archivo de host adicional. <br><br>  Lo que hicimos, nuevamente prepar√≥ el gui√≥n en Ansible, lo subi√≥ a producci√≥n y comenz√≥ a parecerse a esto: <br><br><img src="https://habrastorage.org/webt/p6/qe/3i/p6qe3iaqlloehk1ld7ptisb_0dg.png"><br><br>  Hab√≠a un elemento adicional y un archivo est√°tico en el disco, que se regenera con bastante rapidez.  Ahora la cadena parec√≠a bastante simple: Gamed se volvi√≥ hacia Dnsmasq, y eso a su vez (en lugar de tirar del agente Consula, que preguntar√≠a a los servidores d√≥nde ten√≠amos este o aquel nodo) solo mir√≥ el archivo.  Esto resolvi√≥ el problema con el consumo de CPU por parte de Consul. <br><br>  Ahora todo comenz√≥ a verse como lo planeamos, absolutamente transparente para nuestra producci√≥n, pr√°cticamente sin consumir recursos. <br><br>  Est√°bamos bastante atormentados ese d√≠a y con gran aprensi√≥n nos fuimos a casa.  No tuvieron miedo en vano, porque por la noche una alerta del monitoreo me despert√≥ y me inform√≥ que ten√≠amos una explosi√≥n de errores a gran escala (aunque a corto plazo). <br><br><img src="https://habrastorage.org/webt/yg/yj/z_/ygyjz_upz8khxqgriqbsye0_xma.png"><br><br>  Al tratar con los registros en la ma√±ana, vi que todos los errores eran del mismo tipo de host desconocido.  No estaba claro por qu√© Dnsmasq no pod√≠a usar uno u otro servicio de un archivo; parec√≠a que no exist√≠a en absoluto.  Para tratar de comprender lo que estaba sucediendo, agregu√© una m√©trica personalizada para volver a generar el archivo; ahora sab√≠a exactamente el momento en que se regenerar√≠a.  Adem√°s, la propia plantilla de C√≥nsul tiene una excelente opci√≥n de respaldo, es decir  Puede ver el estado anterior del archivo regenerado. <br><br>  Durante el d√≠a, el incidente se repiti√≥ varias veces y qued√≥ claro que en alg√∫n momento (aunque era espor√°dico, de naturaleza no sistem√°tica), el archivo de hosts sin ning√∫n servicio espec√≠fico se volver√≠a a procesar.  Result√≥ que en un centro de datos en particular (no har√© antipublicidad) hay redes bastante inestables: debido al fracaso de las redes, dejamos de pasar imprevisiblemente, o incluso los nodos se cayeron del cl√∫ster.  Se parec√≠a a esto: <br><br><img src="https://habrastorage.org/webt/3v/_q/ve/3v_qvengzywl6bqdchzxs2fshl4.png"><br><br>  El nodo se cay√≥ del cl√∫ster, el agente del C√≥nsul fue notificado de inmediato sobre esto, y la plantilla del C√≥nsul regener√≥ inmediatamente el archivo de hosts sin el servicio que necesit√°bamos.  En general, esto era inaceptable, porque el problema es rid√≠culo: si el servicio no est√° disponible durante unos segundos, configure tiempos de espera y retransmisiones (no se conectaron una vez, pero la segunda vez result√≥).  Pero provocamos una nueva estructura en el vendedor cuando el servicio simplemente desaparece de la vista y no hay forma de conectarse a √©l. <br><br>  Comenzamos a pensar qu√© hacer y torcer el par√°metro de tiempo de espera en Consul, despu√©s de lo cual se identifica despu√©s de cu√°nto se cae el nodo.  Logramos resolver este problema con un indicador bastante peque√±o, los nodos dejaron de caerse, pero esto no ayud√≥ con el chequeo de salud. <br><br>  Comenzamos a pensar en elegir diferentes par√°metros para el chequeo de salud, tratando de entender de alguna manera cu√°ndo y c√≥mo sucede esto.  Pero debido al hecho de que todo sucedi√≥ de forma espor√°dica e impredecible, no pudimos hacerlo. <br><br>  Luego fuimos a la plantilla de C√≥nsul y decidimos hacer un tiempo de espera para ello, despu√©s de lo cual reacciona a un cambio en el estado del cl√∫ster.  Nuevamente, era imposible ser fan√°tico, porque pod√≠amos llegar a una situaci√≥n en la que el resultado no ser√≠a mejor que el DNS cl√°sico, cuando apuntamos a uno completamente diferente. <br><br>  Y una vez m√°s, nuestro director t√©cnico vino al rescate y dijo: "Chicos, intentemos renunciar a toda esta interactividad, tenemos todo en producci√≥n y no tenemos tiempo para investigar, necesitamos resolver este problema.  Aprovechemos las cosas simples y comprensibles ".  Entonces llegamos al concepto de usar el almacenamiento de valores clave como fuente para generar un archivo de hosts. <br><br><img src="https://habrastorage.org/webt/ar/qm/kx/arqmkxvbfzahdo6qrlom1htydq4.png"><br><br>  C√≥mo se ve: rechazamos todas las comprobaciones de estado din√°micas, reescribimos nuestro script de plantilla para que genere un archivo basado en los datos registrados en el almacenamiento de valores-clave.  En el almacenamiento de valores clave, describimos toda nuestra infraestructura en forma de nombre clave (este es el nombre del servicio que necesitamos) y el valor clave (este es el nombre del nodo en el cl√∫ster).  Es decir  si el nodo est√° presente en el cl√∫ster, entonces obtenemos f√°cilmente su direcci√≥n IP y la escribimos en el archivo de hosts. <br><br>  Probamos todo, lo llenamos en producci√≥n y se convirti√≥ en una bala de plata en una situaci√≥n espec√≠fica.  Una vez m√°s, nos atormentamos durante todo el d√≠a, volvimos a casa, pero regresamos descansados, entusiasmados, porque estos problemas ya no se repitieron y no se repitieron en la presentaci√≥n durante un a√±o.  De lo cual personalmente concluyo que esta fue la decisi√≥n correcta (espec√≠ficamente para nosotros). <br><br>  Entonces  Finalmente obtuvimos lo que quer√≠amos y organizamos un espacio de nombres din√°mico para nuestros backends.  Adem√°s, nos dirigimos a garantizar una alta disponibilidad. <br><br><img src="https://habrastorage.org/webt/m9/k0/nu/m9k0nueo_w_79ywwhcco0tgnq5u.png"><br><br>  Pero el hecho es que est√° bastante asustado de la integraci√≥n del c√≥nsul y, debido a los problemas que encontramos, pensamos y decidimos que introducir la conmutaci√≥n por error autom√°tica no es una buena soluci√≥n, porque de nuevo corremos el riesgo de falsos positivos o fallas  Este proceso es opaco e incontrolable. <br><br>  Por lo tanto, seguimos un camino m√°s simple (o complejo): decidimos dejar la conmutaci√≥n por error en la conciencia del administrador de turno, pero le dimos otra herramienta adicional.  Hemos reemplazado la replicaci√≥n maestra esclava por la replicaci√≥n maestra maestra en modo de solo lectura.  Esto elimina una gran cantidad de dolor de cabeza en el proceso de failover'ov: cuando obtienes un asistente, todo lo que necesitas hacer es cambiar el valor en k / v-storage usando la interfaz de usuario web o un comando en la API y antes de eso, modo de solo lectura maestro de respaldo. <br><br>  Una vez que termina el incidente, el maestro contacta y autom√°ticamente llega a un estado coordinado sin acciones innecesarias.  Nos detuvimos en esta opci√≥n y la usamos como antes: para nosotros es lo m√°s conveniente posible y, lo m√°s importante, lo m√°s simple, claro y controlado posible. <br><br><img src="https://habrastorage.org/webt/mr/fn/tc/mrfntctgtpanvrkqhlqmbm9liue.png"><br>  <i>Interfaz web c√≥nsul</i> <br><br>  A la derecha est√° el almacenamiento de k / v y nuestros servicios son visibles, que utilizamos en gamed;  valor es el nombre del nodo. <br><br>  En cuanto al escalado, comenzamos a implementarlo cuando los fragmentos ya estaban abarrotados en un servidor, las bases crecieron, se volvieron lentas, el n√∫mero de jugadores aument√≥, intercambiamos y tuvimos la tarea de distribuir todos los fragmentos a nuestros diferentes servidores separados. <br><br><img src="https://habrastorage.org/webt/0b/yc/zg/0byczgl-2ugpi8z_dgwzytcmrw4.png"><br><br>  C√≥mo se ve√≠a: usando la utilidad XtraBackup, restauramos nuestra copia de seguridad en un nuevo par de servidores, despu√©s de lo cual el nuevo maestro fue colgado con un esclavo en el anterior.  Lleg√≥ a un estado consistente, cambiamos el valor clave en k / v-storage del nombre del nodo del maestro antiguo al nombre del nodo del nuevo maestro.  Luego (cuando cre√≠amos que todo iba correctamente y todo se jugaba con sus selecciones, actualizaciones, inserciones para el nuevo maestro), solo ten√≠amos que eliminar la replicaci√≥n y crear la codiciada base de datos de ca√≠da en producci√≥n, ya que a todos nos encanta hacer con bases de datos innecesarias. <br><br><img src="https://habrastorage.org/webt/1x/6k/pw/1x6kpwybgw6-wsgscd6r1kylk-u.png"><br><br>  As√≠ que destrozamos los fragmentos.  Todo el proceso de movimiento dur√≥ de 40 minutos a una hora y no caus√≥ el tiempo de inactividad de nadie, fue completamente transparente para nuestros backends y por s√≠ solo fue completamente transparente para los jugadores (excepto que tan pronto como se movieron, se volvi√≥ m√°s f√°cil y m√°s agradable para ellos jugar). <br><br><img src="https://habrastorage.org/webt/gm/du/bj/gmdubjovhtlet9n2-bljkeqz7oq.png"><br><br>  En cuanto a los procesos de conmutaci√≥n por error, aqu√≠ el tiempo de conmutaci√≥n es de 20 a 40 segundos, m√°s el tiempo de reacci√≥n del administrador del sistema en servicio.  As√≠ es como se ve todo con nosotros ahora. <br><br>  Lo que me gustar√≠a decir como conclusi√≥n: desafortunadamente, nuestras esperanzas de una automatizaci√≥n absoluta e integral se han estrellado contra la dura realidad del medio de transmisi√≥n de datos en un centro de datos cargado y factores aleatorios que no pod√≠amos prever. <br><br>  En segundo lugar, nos ense√±√≥ una vez m√°s que una teta simple y probada en manos del administrador de su sistema es mejor que una gr√∫a nueva, auto-reaccionante y autoescalada en alg√∫n lugar m√°s all√° de las nubes, que ni siquiera comprende si se est√° cayendo a pedazos o si realmente comenz√≥ a escalar. <br><br>  La introducci√≥n de cualquier infraestructura, la automatizaci√≥n en su producci√≥n no deber√≠a causar un dolor de cabeza innecesario para el personal que lo atiende;  no deber√≠a aumentar significativamente el costo de mantener la producci√≥n de infraestructura: la soluci√≥n debe ser simple, clara, transparente para sus clientes, conveniente y controlada. <br><br><h3>  Preguntas de la audiencia </h3><br>  <b>¬øC√≥mo se escribe k / v con servidores? ¬øUn script o simplemente lo parcheas?</b> <br><br> K/v-     Consul-   -  ,     http- RESTful API  Web UI. <br><br>     ,   -             ,     ,   . <br><br> <b>       ,     Redis?</b> <br><br>        ,    - . <br><br> -,          backend. -,      backend',       ‚Äî    .  Es decir       ,     MAINDB        ,   .        .                  -  ,       . <br><br>      - ,       inmemory key-value    -. <br><br> <b>   ?</b> <br><br>    MySQL ‚Äî Percona server. <br><br> <b>            ?      Maria,     MHA for MySQL,    Galera.</b> <br><br>      Galera.    -   ¬´ ¬ª       Galera       ,     .       ,       . <br><br>    ,     ‚Äî         ,         ,     -  ,    ,         ,   . <br><br><h3>    Pixonic DevGAMM Talks </h3><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CICD:        </a> ( ,   Pixonic); </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">     -  Quake Champions</a> ( , backend- Saber Interactive); </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> -  - Tacticool</a> ( , Lead Software Engineer  PanzerDog); </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> ECS, C# Job System  SRP    </a> ( , Field Engineer  Unity); </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Principio de KISS en desarrollo</a> (Konstantin Gladyshev, Programador principal de juegos en 1C Game Studios); </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">      </a> ( , Deputy Technical Officer  Pixonic). </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cucumber  :  BDD-    </a> ( , Technical Product Manager  ALICE Platform). </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es424777/">https://habr.com/ru/post/es424777/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es424763/index.html">Un editor de texto no es su mejor matem√°tica, aqu√≠ debe pensar</a></li>
<li><a href="../es424765/index.html">Gesti√≥n del estado en aplicaciones Flutter</a></li>
<li><a href="../es424767/index.html">Hacemos un pastel de Habr. De nuevo</a></li>
<li><a href="../es424771/index.html">Experiencia personal: de una idea y una hoja en blanco a una versi√≥n borrador de un sitio</a></li>
<li><a href="../es424773/index.html">Biofarma y modelaci√≥n num√©rica: experiencia y pr√°ctica de Amgen</a></li>
<li><a href="../es424779/index.html">SPA de varias p√°ginas en Python</a></li>
<li><a href="../es424781/index.html">Ense√±ar y probar redes neuronales en PyTorch usando Ignite</a></li>
<li><a href="../es424787/index.html">Entrevista con Aaron Patterson, presidente de la Conferencia RubyRussia 2018</a></li>
<li><a href="../es424789/index.html">C√≥mo implementar una aplicaci√≥n Ruby on Rails con HAProxy Ingress, unicornio / puma y sockets web</a></li>
<li><a href="../es424791/index.html">Expandir las capacidades de red de un rel√© programable usando WI-FI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
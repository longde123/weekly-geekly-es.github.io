<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï≥Ô∏è üì≥ üôãüèæ Python 3.5 Impl√©mentation de la concurrence √† l'aide de asyncio üôÜ üòΩ üî∞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Traduction du chapitre 13 Concurrence 
 du livre 'Expert Python Programming', 
 Deuxi√®me √©dition 
 Micha≈Ç Jaworski et Tarek Ziad√©, 2016 
 
 Programmat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python 3.5 Impl√©mentation de la concurrence √† l'aide de asyncio</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/484446/">  <i>Traduction du chapitre 13 Concurrence</i> <i><br></i>  <i>du livre 'Expert Python Programming',</i> <i><br></i>  <i>Deuxi√®me √©dition</i> <i><br></i>  <i>Micha≈Ç Jaworski et Tarek Ziad√©, 2016</i> <i><br></i> <br><h4>  Programmation asynchrone </h4><br>  Ces derni√®res ann√©es, la programmation asynchrone a gagn√© en popularit√©.  Python 3.5 a enfin obtenu quelques fonctions de syntaxe qui renforcent les concepts de solutions asynchrones.  Mais cela ne signifie pas que la programmation asynchrone n'est devenue possible que depuis Python 3.5.  De nombreuses biblioth√®ques et frameworks ont √©t√© fournis beaucoup plus t√¥t, et la plupart d'entre eux provenaient d'anciennes versions de Python 2. Il existe m√™me une impl√©mentation alternative de Python appel√©e Stackless (voir le chapitre 1, ¬´Le statut actuel de Python¬ª), qui se concentre sur cette approche de programmation unique.  Pour certaines solutions, telles que <b>Twisted, Tornado</b> ou <b>Eventlet</b> , des communaut√©s actives existent toujours et valent vraiment la peine d'√™tre connues.  Dans tous les cas, √† partir de Python 3.5, la programmation asynchrone est devenue plus facile que jamais.  Ainsi, il est pr√©vu que ses fonctions asynchrones int√©gr√©es remplaceront la plupart des anciens outils, ou que les projets externes se transformeront progressivement en une sorte de cadres de haut niveau bas√©s sur Python int√©gr√©. <br><a name="habracut"></a><br>  Lorsque vous essayez d'expliquer ce qu'est la programmation asynchrone, il est plus facile de consid√©rer cette approche comme quelque chose de similaire aux threads, mais sans planificateur syst√®me.  Cela signifie qu'un programme asynchrone peut traiter des t√¢ches en m√™me temps, mais son contexte est chang√© en interne et non par le planificateur syst√®me. <br><br>  Mais, bien s√ªr, nous n'utilisons pas de threads pour le traitement parall√®le des t√¢ches dans un programme asynchrone.  La plupart des solutions utilisent des concepts diff√©rents et, selon l'impl√©mentation, sont appel√©es diff√©remment.  Voici quelques exemples de noms utilis√©s pour d√©crire ces objets de programme parall√®les: <br><br><ul><li>  Fils verts - Fils verts (projets greenlet, gevent ou eventlet) </li><li>  <b>Coroutines</b> - coroutines (programmation asynchrone pure en Python 3.5) </li><li>  <b>Tasklets (Stackless Python)</b> Ce sont essentiellement les m√™mes concepts, mais souvent impl√©ment√©s de mani√®res l√©g√®rement diff√©rentes. </li></ul><br>  Pour des raisons √©videntes, dans cette section, nous nous concentrerons uniquement sur les coroutines initialement prises en charge par Python, √† partir de la version 3.5. <br><br><h4>  Multit√¢che collaboratif et E / S asynchrones </h4><br>  Le multit√¢che collaboratif est au c≈ìur de la programmation asynchrone.  En ce sens, le multit√¢che dans le syst√®me d'exploitation n'est pas requis pour initier un changement de contexte (vers un autre processus ou thread), mais √† la place, chaque processus lib√®re volontairement le contr√¥le lorsqu'il est en mode veille pour assurer l'ex√©cution simultan√©e de plusieurs programmes.  C'est pourquoi il est appel√© collaboratif.  Tous les processus doivent travailler ensemble pour garantir le succ√®s du multit√¢che. <br><br>  Le mod√®le multit√¢che √©tait parfois utilis√© dans les syst√®mes d'exploitation, mais il ne peut d√©sormais plus √™tre trouv√© comme une solution au niveau du syst√®me.  En effet, il existe un risque qu'un service mal con√ßu puisse facilement perturber la stabilit√© de l'ensemble du syst√®me.  La planification des threads et des processus √† l'aide de commutateurs de contexte contr√¥l√©s directement par le syst√®me d'exploitation est actuellement l'approche dominante pour la concurrence au niveau du syst√®me.  Mais le multit√¢che collaboratif est toujours un excellent outil de concurrence au niveau de l'application. <br><br>  En parlant de multit√¢che conjoint au niveau de l'application, nous ne traitons pas de threads ou de processus qui doivent lib√©rer le contr√¥le, car toute l'ex√©cution est contenue dans un processus et un thread.  Au lieu de cela, nous avons plusieurs t√¢ches (coroutines, tasklets et fils verts) qui transf√®rent le contr√¥le √† une seule fonction qui contr√¥le la coordination des t√¢ches.  Cette fonction est g√©n√©ralement une sorte de boucle d'√©v√©nement. <br><br>  Pour √©viter toute confusion (en raison de la terminologie Python), nous allons maintenant appeler ces t√¢ches parall√®les coroutines.  Le probl√®me le plus important dans le multit√¢che collaboratif est de savoir quand transf√©rer le contr√¥le.  Dans la plupart des applications asynchrones, le contr√¥le est transmis au planificateur ou √† la boucle d'√©v√©nements pendant les op√©rations d'E / S.  Que le programme lise les donn√©es du syst√®me de fichiers ou communique via un socket, une telle op√©ration d'E / S est toujours associ√©e √† un certain temps d'attente lorsque le processus devient inactif.  La latence d√©pend d'une ressource externe, c'est donc une bonne occasion de lib√©rer le contr√¥le afin que d'autres coroutines puissent faire leur travail, jusqu'√† ce qu'elles doivent √©galement attendre que cette approche soit quelque peu similaire dans son comportement √† la fa√ßon dont le multithreading est impl√©ment√© en Python.  Nous savons que le GIL s√©rialise les threads Python, mais il est √©galement lib√©r√© √† chaque op√©ration d'E / S.  La principale diff√©rence est que les threads en Python sont impl√©ment√©s en tant que threads au niveau du syst√®me, de sorte que le syst√®me d'exploitation peut d√©charger le thread en cours d'ex√©cution √† tout moment et transf√©rer le contr√¥le √† un autre. <br><br>  En programmation asynchrone, les t√¢ches ne sont jamais interrompues par la boucle d'√©v√©nement principale.  C'est pourquoi ce style multit√¢che est √©galement appel√© multit√¢che non prioritaire. <br><br>  Bien s√ªr, chaque application Python s'ex√©cute sur un syst√®me d'exploitation o√π d'autres processus se disputent les ressources.  Cela signifie que le syst√®me d'exploitation a toujours le droit de d√©charger l'ensemble du processus et de transf√©rer le contr√¥le √† un autre.  Mais lorsque notre application asynchrone red√©marre, elle reprend l√† o√π elle a √©t√© interrompue lorsque le planificateur syst√®me est intervenu.  C'est pourquoi les coroutines dans ce contexte sont consid√©r√©es comme non encombrantes. <br><br><h4>  Python asynchrone et attend les mots cl√©s </h4><br>  Les mots cl√©s <i>asynchrones</i> et <i>attendent</i> sont les principaux √©l√©ments constitutifs de la programmation Python asynchrone. <br><br>  Le <i>mot-cl√© async</i> utilis√© avant l'instruction <i>def</i> d√©finit une nouvelle coroutine.  Une fonction coroutine peut √™tre suspendue et reprise dans des circonstances strictement d√©finies.  Sa syntaxe et son comportement sont tr√®s similaires √† ceux des g√©n√©rateurs (voir Chapitre 2, ¬´Recommandations de syntaxe¬ª, sous le niveau de la classe).  En fait, les g√©n√©rateurs devraient √™tre utilis√©s dans les anciennes versions de Python pour impl√©menter les coroutines.  Voici un exemple de d√©claration d'une fonction qui utilise le <i>mot cl√© async</i> : <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">async_hello</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> print(<span class="hljs-string"><span class="hljs-string">"hello, world!"</span></span>)</code> </pre> <br>  Les fonctions d√©finies √† l'aide du <i>mot</i> - <i>cl√© async</i> sont sp√©ciales.  Lorsqu'ils sont appel√©s, ils n'ex√©cutent pas de code √† l'int√©rieur, mais renvoient √† la place un objet coroutine: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt;&gt; async def async_hello(): ... print("hello, world!") ... &gt;&gt;&gt; async_hello() &lt;coroutine object async_hello at 0x1014129e8&gt;</code></b> </pre><br>  L'objet coroutine ne fait rien tant que son ex√©cution n'est pas planifi√©e dans la boucle d'√©v√©nement.  Le module asyncio est disponible pour fournir une impl√©mentation de base de la boucle d'√©v√©nements, ainsi que de nombreux autres utilitaires asynchrones: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt; import asyncio &gt;&gt;&gt; async def async_hello(): ... print("hello, world!") ... &gt;&gt;&gt; loop = asyncio.get_event_loop() &gt;&gt;&gt; loop.run_until_complete(async_hello()) hello, world! &gt;&gt;&gt; loop.close()</code></b> </pre><br>  Naturellement, en ne cr√©ant qu'une seule coroutine simple, dans notre programme nous n'impl√©mentons pas le parall√©lisme.  Pour voir quelque chose de vraiment parall√®le, nous devons cr√©er plus de t√¢ches qui seront effectu√©es par une boucle d'√©v√©nement. <br><br>  De nouvelles t√¢ches peuvent √™tre ajout√©es √† la boucle en appelant la m√©thode <i>loop.create_task ()</i> ou en fournissant un autre objet pour attendre l'utilisation de la fonction <i>asyncio.wait ()</i> .  Nous allons utiliser cette derni√®re approche et essayer d'imprimer de mani√®re asynchrone une s√©quence de nombres g√©n√©r√©e √† l'aide de la fonction <i>range ()</i> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_number</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(number)</span></span></span><span class="hljs-function">:</span></span> print(number) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: loop = asyncio.get_event_loop() loop.run_until_complete( asyncio.wait([ print_number(number) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> number <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>) ]) ) loop.close()</code> </pre><br>  La fonction <i>asyncio.wait ()</i> accepte une liste d'objets coroutine et retourne imm√©diatement.  Le r√©sultat est un g√©n√©rateur qui produit des objets repr√©sentant des r√©sultats futurs (futurs).  Comme son nom l'indique, il est utilis√© pour attendre que toutes les coroutines fournies soient termin√©es.  La raison pour laquelle il retourne un g√©n√©rateur au lieu d'un objet coroutine est qu'il est r√©trocompatible avec les versions pr√©c√©dentes de Python, ce qui sera expliqu√© plus loin.  Le r√©sultat de l'ex√©cution de ce script peut √™tre le suivant: <br><br><pre> <b><code class="plaintext hljs">$ python asyncprint.py 0 7 8 3 9 4 1 5 2 6</code></b> </pre><br>  Comme nous pouvons le voir, les chiffres ne sont pas imprim√©s dans l'ordre dans lequel nous avons cr√©√© nos coroutines.  Mais c'est exactement ce que nous voulions r√©aliser. <br><br>  Le deuxi√®me mot cl√© important ajout√© dans Python 3.5 est en <i>attente</i> .  Il est utilis√© pour attendre les r√©sultats d'une coroutine ou d'un √©v√©nement futur (expliqu√© plus loin) et lib√©rer le contr√¥le de l'ex√©cution dans la boucle d'√©v√©nement.  Pour mieux comprendre comment cela fonctionne, nous devons consid√©rer un exemple de code plus complexe. <br><br>  Supposons que nous voulons cr√©er deux coroutines qui effectueront des t√¢ches simples en boucle: <br><br><ul><li>  Attendez un nombre al√©atoire de secondes </li><li>  Imprimez le texte fourni comme argument et le temps d'attente.  Commen√ßons par une impl√©mentation simple qui a quelques probl√®mes de concurrence que nous essaierons d'am√©liorer plus tard avec l'utilisation suppl√©mentaire de wait: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">waiter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): time_to_sleep = random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) / <span class="hljs-number"><span class="hljs-number">4</span></span> time.sleep(time_to_sleep) print( <span class="hljs-string"><span class="hljs-string">"{} waited {} seconds"</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span>.format(name, time_to_sleep) ) <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.wait([waiter(<span class="hljs-string"><span class="hljs-string">"foo"</span></span>), waiter(<span class="hljs-string"><span class="hljs-string">"bar"</span></span>)]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: loop = asyncio.get_event_loop() loop.run_until_complete(main()) loop.close()</code> </pre></li></ul><br>  Lorsqu'il est ex√©cut√© dans le terminal (en utilisant la commande time pour mesurer le temps), vous pouvez voir: <br><br><pre> <b><code class="plaintext hljs">$ time python corowait.py bar waited 0.25 seconds bar waited 0.25 seconds bar waited 0.5 seconds bar waited 0.5 seconds foo waited 0.75 seconds foo waited 0.75 seconds foo waited 0.25 seconds foo waited 0.25 seconds real 0m3.734s user 0m0.153s sys 0m0.028s</code></b> </pre><br><br>  Comme nous pouvons le voir, les deux coroutines ont termin√© leur ex√©cution, mais pas de mani√®re asynchrone.  La raison en est qu'ils utilisent tous les deux la fonction <i>time.sleep ()</i> , qui verrouille mais ne lib√®re pas le contr√¥le dans la boucle d'√©v√©nement.  Cela fonctionnera mieux dans une installation multi-thread, mais nous ne voulons pas utiliser de flux pour le moment.  Alors, comment pouvons-nous r√©soudre ce probl√®me? <br><br>  La r√©ponse consiste √† utiliser <i>asyncio.sleep ()</i> , qui est une version asynchrone de time.sleep (), et √† attendre le r√©sultat √† l'aide du mot cl√© wait.  Nous avons d√©j√† utilis√© cette instruction dans la premi√®re version de <i>main ()</i> , mais c'√©tait uniquement pour am√©liorer la clart√© du code.  Cela n'a clairement pas rendu notre mise en ≈ìuvre plus parall√®le.  Regardons une version am√©lior√©e de la coroutine waiter () qui utilise attendent asyncio.sleep (): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">waiter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): time_to_sleep = random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) / <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(time_to_sleep) print( <span class="hljs-string"><span class="hljs-string">"{} waited {} seconds"</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span>.format(name, time_to_sleep) )</code> </pre><br><br>  En ex√©cutant le script mis √† jour, nous verrons comment la sortie de deux fonctions alternent entre elles: <br><br><pre> <b><code class="plaintext hljs">$ time python corowait_improved.py bar waited 0.25 seconds foo waited 0.25 seconds bar waited 0.25 seconds foo waited 0.5 seconds foo waited 0.25 seconds bar waited 0.75 seconds foo waited 0.25 seconds bar waited 0.5 seconds real 0m1.953s user 0m0.149s sys 0m0.026s</code></b> </pre><br><br>  Un avantage suppl√©mentaire de cette simple am√©lioration est que le code s'ex√©cute plus rapidement.  Le temps d'ex√©cution total √©tait inf√©rieur √† la somme de tous les temps de sommeil, car les coroutines ont pris le contr√¥le un par un. <br><br><h4>  Asyncio dans les versions pr√©c√©dentes de Python </h4><br>  Le module asyncio est apparu en Python 3.4.  C'est donc la seule version de Python qui prend en charge s√©rieusement la programmation asynchrone avant Python 3.5.  Malheureusement, il semble que ces deux versions ult√©rieures soient suffisantes pour pr√©senter des probl√®mes de compatibilit√©. <br><br>  Quoi qu'il en soit, le noyau de programmation asynchrone en Python a √©t√© introduit plus t√¥t que les √©l√©ments de syntaxe qui prennent en charge ce mod√®le.  Mieux vaut tard que jamais, mais cela a cr√©√© une situation o√π il existe deux syntaxes pour travailler avec des coroutines. <br><br>  √Ä partir de Python 3.5, vous pouvez utiliser <i>async</i> et <i>attendre</i> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre><br><br>  Cependant, dans Python 3.4, vous devrez en plus appliquer le d√©corateur asyncio.coroutine et donner le texte dans le texte coroutine: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@asyncio.couroutine def main(): yield from asyncio.sleep(0)</span></span></code> </pre><br><br>  Un autre fait utile est que le <i>rendement de l'instruction a</i> √©t√© introduit dans Python 3.3, et PyPI a un backport asynchrone.  Cela signifie que vous pouvez √©galement utiliser cette impl√©mentation du multit√¢che collaboratif avec Python 3.3. <br><br><h4>  Un exemple pratique de programmation asynchrone </h4><br>  Comme mentionn√© √† plusieurs reprises dans ce chapitre, la programmation asynchrone est un excellent outil pour g√©rer les E / S.  Il est temps de cr√©er quelque chose de plus pratique que d'imprimer des s√©quences ou une attente asynchrone. <br><br>  Afin d'assurer la coh√©rence, nous essaierons de r√©soudre le m√™me probl√®me que nous avons r√©solu √† l'aide du multithreading et du multiprocessing.  Par cons√©quent, nous essaierons d'extraire de mani√®re asynchrone certaines donn√©es de ressources externes via une connexion r√©seau.  Ce serait formidable si nous pouvions utiliser le m√™me paquet <i>python-gmaps</i> que dans les sections pr√©c√©dentes.  Malheureusement, nous ne pouvons pas. <br><br>  Le cr√©ateur de <i>python-gmaps</i> √©tait un peu paresseux et ne prenait que le nom.  Pour simplifier le d√©veloppement, il a choisi le package de requ√™te comme biblioth√®que client HTTP.  Malheureusement, les demandes ne prennent pas en charge les E / S <i>asynchrones</i> avec <i>async</i> et <i>attendent</i> .  Il existe d'autres projets qui visent √† fournir un certain parall√©lisme pour le projet de requ√™te, mais ils s'appuient sur <i>Gevent</i> ( <i>grequests</i> , voir <i>https://github.com/ kennethreitz / grequests</i> ) ou ex√©cutent un pool de threads / processus (query-futures voir <i><a href="https://github.com/ross/requests-futures" rel="nofollow">github.com/ross/requests-futures</a></i> ).  Aucun d'eux ne r√©sout notre probl√®me. <br><br><blockquote>  <i>Avant de me reprocher d'avoir r√©primand√© un d√©veloppeur open source innocent, calmez-vous.</i>  <i>La personne derri√®re le paquet <i>python-gmaps</i> est moi.</i>  <i>Un mauvais choix de d√©pendances est l'un des probl√®mes de ce projet.</i>  <i>J'aime juste me critiquer publiquement de temps en temps.</i>  <i>Ce sera une le√ßon am√®re pour moi, car <i>python-gmaps</i> dans sa derni√®re version (0.3.1 au moment de la r√©daction de ce livre) ne peut pas √™tre facilement int√©gr√© avec les E / S asynchrones de Python.</i>  <i>Dans tous les cas, cela peut changer √† l'avenir, donc rien n'est perdu.</i> <br></blockquote>  Connaissant les limites de la biblioth√®que, qui √©tait si facile √† utiliser dans les exemples pr√©c√©dents, nous devons cr√©er quelque chose qui comble cette lacune.  Google MapsAPI est vraiment facile √† utiliser, nous allons donc cr√©er un utilitaire asynchrone √† titre d'illustration.  Il manque toujours √† la biblioth√®que standard de Python 3.5 une biblioth√®que qui puisse ex√©cuter des requ√™tes HTTP asynchrones aussi facilement que d'appeler <i>urllib.urlopen ()</i> .  Nous ne voulons certainement pas cr√©er un support de protocole complet √† partir de z√©ro, nous allons donc utiliser un peu d'aide du package <i>aiohttp</i> disponible dans PyPI.  Il s'agit d'une biblioth√®que tr√®s prometteuse qui ajoute des impl√©mentations client et serveur pour HTTP asynchrone.  Voici un petit module int√©gr√© √† <i>aiohttp</i> qui cr√©e une fonction d'assistance <i>geocode</i> <i>()</i> qui ex√©cute des demandes de g√©ocodage au service API Google Maps: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> aiohttp session = aiohttp.ClientSession() <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">geocode</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(place)</span></span></span><span class="hljs-function">:</span></span> params = { <span class="hljs-string"><span class="hljs-string">'sensor'</span></span>: <span class="hljs-string"><span class="hljs-string">'false'</span></span>, <span class="hljs-string"><span class="hljs-string">'address'</span></span>: place } <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> session.get( <span class="hljs-string"><span class="hljs-string">'https://maps.googleapis.com/maps/api/geocode/json'</span></span>, params=params ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> response: result = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> response.json() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result[<span class="hljs-string"><span class="hljs-string">'results'</span></span>]</code> </pre><br><br>  Supposons que ce code soit stock√© dans un module nomm√© <i>asyncgmaps</i> , que nous utiliserons plus tard.  Nous sommes maintenant pr√™ts √† r√©√©crire l'exemple utilis√© dans la discussion sur le multithreading et le multiprocessing.  Auparavant, nous avions l'habitude de s√©parer l'ensemble de l'op√©ration en deux √©tapes distinctes: <br><br><ol><li>  R√©pondez √† toutes les demandes au service externe en parall√®le √† l'aide de la fonction <i>fetch_place ()</i> . </li><li>  Affichez tous les r√©sultats dans une boucle en utilisant la fonction <i>present_result ()</i> . </li></ol><br>  Mais comme le multit√¢che collaboratif est compl√®tement diff√©rent de l'utilisation de plusieurs processus ou threads, nous pouvons l√©g√®rement changer notre approche.  La plupart des probl√®mes soulev√©s dans Utilisation d'un seul thread par article ne nous concernent plus. <br>  Les coroutines ne sont pas pr√©emptives, nous pouvons donc facilement afficher les r√©sultats imm√©diatement apr√®s avoir re√ßu des r√©ponses HTTP.  Cela simplifiera notre code et le rendra plus compr√©hensible: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-comment"><span class="hljs-comment"># note: local module introduced earlier from asyncgmaps import geocode, session PLACES = ( 'Reykjavik', 'Vien', 'Zadar', 'Venice', 'Wroc≈Çaw', 'Bolognia', 'Berlin', 'S≈Çubice', 'New York', 'Dehli', ) async def fetch_place(place): return (await geocode(place))[0] async def present_result(result): geocoded = await result print("{:&gt;25s}, {:6.2f}, {:6.2f}".format( geocoded['formatted_address'], geocoded['geometry']['location']['lat'], geocoded['geometry']['location']['lng'], )) async def main(): await asyncio.wait([ present_result(fetch_place(place)) for place in PLACES ]) if __name__ == "__main__": loop = asyncio.get_event_loop() loop.run_until_complete(main()) # aiohttp will raise issue about unclosed # ClientSession so we perform cleanup manually loop.run_until_complete(session.close()) loop.close()</span></span></code> </pre><br><br>  La programmation asynchrone est id√©ale pour les d√©veloppeurs d'arri√®re-plan int√©ress√©s par la cr√©ation d'applications √©volutives.  En pratique, c'est l'un des outils les plus importants pour cr√©er des serveurs hautement comp√©titifs. <br><br>  Mais la r√©alit√© est triste.  De nombreux packages courants traitant des probl√®mes d'E / S ne sont pas destin√©s √† √™tre utilis√©s avec du code asynchrone.  Les principales raisons en sont: <br><br><ul><li>  Impl√©mentation encore faible de Python 3 et de certaines de ses fonctionnalit√©s avanc√©es </li><li>  Faible compr√©hension des diff√©rents concepts de concurrence chez les d√©butants pour apprendre Python </li></ul><br>  Cela signifie que tr√®s souvent, la migration des applications et packages multithreads synchrones existants est soit impossible (en raison de restrictions architecturales), soit trop co√ªteuse.  De nombreux projets pourraient grandement b√©n√©ficier de la mise en ≈ìuvre du style multit√¢che asynchrone, mais seuls quelques-uns finiront par le faire.  Cela signifie qu'en ce moment, vous aurez beaucoup de difficult√©s √† cr√©er des applications asynchrones d√®s le d√©but.  Dans la plupart des cas, cela ressemblera au probl√®me mentionn√© dans la section ¬´Exemple pratique de programmation asynchrone¬ª - interfaces incompatibles et blocage non synchrone des op√©rations d'E / S.  Bien s√ªr, vous pouvez parfois renoncer √† attendre lorsque vous rencontrez une telle incompatibilit√© et obtenir simplement les ressources n√©cessaires de mani√®re synchrone.  Mais cela emp√™chera l'autre coroutine d'ex√©cuter son code pendant que vous attendez les r√©sultats.  Techniquement, cela fonctionne, mais d√©truit √©galement tous les avantages de la programmation asynchrone.  Ainsi, au final, la combinaison d'E / S asynchrones avec des E / S synchrones n'est pas une option.  C'est un jeu tout ou rien. <br><br>  Un autre probl√®me est la longueur des op√©rations li√©es au processeur.  Lorsque vous effectuez une op√©ration d'E / S, il n'y a aucun probl√®me √† lib√©rer le contr√¥le d'une coroutine.  Lors de l'√©criture / lecture √† partir d'un syst√®me de fichiers ou d'un socket, vous finirez par attendre, donc un appel utilisant wait est le meilleur que vous puissiez faire.  Mais que faire si vous avez besoin de calculer quelque chose et que vous savez que cela prendra un certain temps?  Bien s√ªr, vous pouvez diviser le probl√®me en parties et annuler le contr√¥le chaque fois que vous avancez un peu le travail.  Mais bient√¥t vous constaterez que ce n'est pas un tr√®s bon mod√®le.  Une telle chose peut rendre le code d√©sordonn√© et ne garantit pas non plus de bons r√©sultats. <br><br>  La liaison temporelle devrait √™tre la responsabilit√© de l'interpr√®te ou du syst√®me d'exploitation. <br><br><h4>  Combinaison de code asynchrone avec des contrats √† terme asynchrones </h4><br>  Que faire si vous avez du code qui ex√©cute de longues E / S synchrones que vous ne pouvez pas ou ne voulez pas r√©√©crire.  Ou que faire lorsque vous devez effectuer des op√©rations de processeur lourdes dans une application con√ßue principalement pour les E / S asynchrones?  Eh bien ... vous devez trouver une solution de contournement.  Et j'entends par l√† le multithreading ou le multiprocessing. <br><br>  Cela peut ne pas sembler tr√®s bon, mais parfois la meilleure solution peut √™tre ce dont nous avons essay√© de nous √©loigner.  Le traitement parall√®le des t√¢ches gourmandes en ressources en Python est toujours mieux ex√©cut√© gr√¢ce au multitraitement.  Et le multithreading peut g√©rer les op√©rations d'E / S tout aussi bien (rapidement et sans beaucoup de ressources), comme asynchrone et en attente s'il est correctement configur√© et g√©r√© avec soin. <br><br>  Donc, parfois, lorsque vous ne savez pas quoi faire lorsque quelque chose ne correspond tout simplement pas √† votre application asynchrone, utilisez un morceau de code qui le place sur un thread ou un processus distinct.  Vous pouvez pr√©tendre qu'il s'agit d'une coroutine, lib√©rer le contr√¥le de la boucle d'√©v√©nements et finalement traiter les r√©sultats lorsqu'ils sont pr√™ts. <br><br>  Heureusement pour nous, la biblioth√®que standard Python fournit le module <i>concurrent.futures</i> , qui est √©galement int√©gr√© au module <i>asyncio</i> .  Ensemble, ces deux modules vous permettent de planifier des fonctions de blocage qui sont ex√©cut√©es dans des threads ou des processus suppl√©mentaires, comme s'il s'agissait de coroutines asynchrones non bloquantes. <br><br><h4>  Ex√©cuteurs testamentaires et contrats √† terme </h4><br>  Avant de voir comment incorporer des threads ou des processus dans une boucle d'√©v√©nement asynchrone, nous examinons de plus pr√®s le module <i>concurrent.futures</i> , qui deviendra plus tard le composant principal de notre soi-disant solution de contournement. <br><br>  Les classes les plus importantes du module <i>concurrent.futures</i> sont <i>Executor</i> et <i>Future</i> . <br><br>  <i>Executor</i> est un pool de ressources qui peut traiter des √©l√©ments de travail en parall√®le.  Il peut sembler tr√®s similaire dans son objectif aux classes du module multiprocesseur - <i>Pool</i> et <i>dummy.Pool</i> - mais il a une interface et une s√©mantique compl√®tement diff√©rentes.  Il s'agit d'une classe de base qui n'est pas destin√©e √† √™tre impl√©ment√©e et poss√®de deux impl√©mentations sp√©cifiques: <br><br><ul><li>  <i>ThreadPoolExecutor</i> : qui repr√©sente un pool de threads </li><li>  <i>ProcessPoolExecutor</i> : qui repr√©sente un pool de processus </li></ul><br>  Chaque <i>ex√©cuteur testamentaire</i> pr√©sente trois m√©thodes: <br><br><ul><li>  <i>submit (fn, * args, ** kwargs)</i> : planifie l'ex√©cution de la fonction fn dans le pool de ressources et retourne un objet Future repr√©sentant l'ex√©cution de l'objet appel√© </li><li>  <i>map (func, * iterables, timeout = None, chunksize = 1)</i> : la fonction <i>func</i> est ex√©cut√©e sur l'it√©ration de mani√®re similaire au multiprocessing.  <i>M√©thode Pool.map ()</i> </li><li>  <i>shutdown (wait = True)</i> : cela arr√™te l' <i>Executor</i> et lib√®re toutes ses ressources. </li></ul><br>  La m√©thode la plus int√©ressante est <i>submit () en</i> raison de l'objet Future qu'elle renvoie.  Il repr√©sente l'ex√©cution asynchrone de l'appel√© et ne repr√©sente qu'indirectement son r√©sultat.  Pour obtenir la valeur de retour r√©elle de l'objet appel√© distribu√©, vous devez appeler la m√©thode <i>Future.result ()</i> .  Et si l'objet appel√© est d√©j√† termin√©, la m√©thode <i>result ()</i> ne le bloquera pas et retournera simplement la sortie de la fonction.  Si ce n'est pas le cas, il le bloquera jusqu'√† ce que le r√©sultat soit pr√™t.  Consid√©rez-le comme une promesse de r√©sultat (c'est en fait le m√™me concept qu'une promesse en JavaScript).  Vous n'avez pas besoin de le d√©compresser imm√©diatement apr√®s l'avoir re√ßu (en utilisant la m√©thode <i>result ()</i> ), mais si vous essayez de le faire, il est garanti de retourner √©ventuellement quelque chose: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt; def loudy_return(): ... print("processing") ... return 42 ... &gt;&gt;&gt; from concurrent.futures import ThreadPoolExecutor &gt;&gt;&gt; with ThreadPoolExecutor(1) as executor: ... future = executor.submit(loudy_return) ... processing &gt;&gt;&gt; future &lt;Future at 0x33cbf98 state=finished returned int&gt; &gt;&gt;&gt; future.result() 42</code></b> </pre><br><br>  Si vous souhaitez utiliser la m√©thode <i>Executor.map ()</i> , son utilisation n'est pas diff√©rente de la m√©thode <i>Pool.map ()</i> de la classe <i>Pool</i> du module multiprocesseur: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> ThreadPoolExecutor(POOL_SIZE) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pool: results = pool.map(fetch_place, PLACES) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> result <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> results: present_result(result)</code> </pre><br><br><h4>  Utilisation de l' <i>ex√©cuteur</i> dans une <i>boucle d'</i> √©v√©nement </h4><br>  Les instances de la classe Future renvoy√©es par la m√©thode <i>Executor.submit ()</i> sont conceptuellement tr√®s proches des coroutines utilis√©es dans la programmation asynchrone.  C'est pourquoi nous pouvons utiliser des artistes pour cr√©er un hybride entre le multit√¢che collaboratif et le multitraitement ou le multithreading. <br><br>  Le c≈ìur de cette solution de contournement est la <i>m√©thode BaseEventLoop.run_in_executor (executor, func, * args)</i> de la classe de boucle d' <i>√©v√©nements</i> .  Cela vous permet de planifier l'ex√©cution de la fonction func dans un processus ou un pool de threads repr√©sent√© par l'argument ex√©cuteur.  La chose la plus importante √† propos de cette m√©thode est qu'elle renvoie le nouvel objet attendu (l'objet auquel on peut s'attendre √† l'aide de l'op√©rateur wait).  Ainsi, gr√¢ce √† cela, vous pouvez effectuer une fonction de blocage qui n'est pas une coroutine exactement comme une coroutine, et elle ne se bloquera pas, quel que soit le temps n√©cessaire pour terminer.  Il arr√™tera uniquement la fonction qui attend les r√©sultats d'un tel appel, mais tout le cycle d'√©v√©nements se poursuivra. <br><br>  Et un fait utile est que vous n'avez m√™me pas besoin de cr√©er votre propre instance d'ex√©cuteur testamentaire.  Si vous passez <i>None</i> comme argument √† <i>executor</i> , la classe <i>ThreadPoolExecutor</i> sera utilis√©e avec le nombre de threads par d√©faut (pour Python 3.5, c'est le nombre de processeurs multipli√© par 5). <br><br>  Supposons donc que nous ne voulions pas r√©√©crire la partie probl√©matique du paquet python-gmaps qui causait nos maux de t√™te.  Nous pouvons facilement reporter un appel de blocage √† un thread s√©par√© en appelant <i>loop.run_in_executor ()</i> , tout en laissant la fonction fetch_place () comme coroutine attendue: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fetch_place</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(place)</span></span></span><span class="hljs-function">:</span></span> coro = loop.run_in_executor(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, api.geocode, place) result = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> coro <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une telle solution est pire que d'avoir une biblioth√®que enti√®rement asynchrone pour faire le travail, mais vous savez qu'au moins quelque chose vaut mieux que rien. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apr√®s avoir expliqu√© ce qu'est r√©ellement la concurrence, nous avons pris des mesures et analys√© l'un des probl√®mes parall√®les typiques en utilisant le multithreading. Apr√®s avoir identifi√© les principales lacunes de notre code et les avoir corrig√©es, nous nous sommes tourn√©s vers le multitraitement pour voir comment cela fonctionnerait dans notre cas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apr√®s cela, nous avons constat√© qu'avec un module multiprocesseur, l'utilisation de plusieurs processus est beaucoup plus facile que les threads de base avec le multithreading. Mais seulement apr√®s cela, nous avons r√©alis√© que nous pouvons utiliser la m√™me API avec des threads, gr√¢ce √† </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">multiprocessing.dummy</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ainsi, le choix entre le multitraitement et le multithread d√©pend d√©sormais uniquement de la solution la mieux adapt√©e au probl√®me et non de la solution qui a la meilleure interface. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En parlant d'adapter le probl√®me, nous avons finalement essay√© la programmation asynchrone, qui devrait √™tre la meilleure solution pour les applications li√©es aux E / S, seulement pour comprendre que nous ne pouvons pas compl√®tement oublier les threads et les processus. Nous avons donc fait un cercle, l√† o√π nous avons commenc√©!</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et cela nous am√®ne √† la conclusion finale de ce chapitre. </font><font style="vertical-align: inherit;">Il n'y a pas de solution qui convienne √† tout le monde. </font><font style="vertical-align: inherit;">Il existe plusieurs approches que vous pouvez pr√©f√©rer ou aimer davantage. </font><font style="vertical-align: inherit;">Certaines approches conviennent mieux √† cet ensemble de probl√®mes, mais vous devez toutes les conna√Ætre pour r√©ussir. </font><font style="vertical-align: inherit;">Dans des sc√©narios r√©alistes, vous pouvez utiliser tout l'arsenal d'outils et de styles de parall√©lisme dans une seule application, ce qui n'est pas rare. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La conclusion pr√©c√©dente est une excellente introduction au sujet du chapitre suivant, Chapitre 14 ¬´Mod√®les de conception utiles¬ª. </font><font style="vertical-align: inherit;">Puisqu'il n'y a pas de mod√®le unique qui r√©soudra tous vos probl√®mes. </font><font style="vertical-align: inherit;">Vous devez en savoir autant que possible, car en fin de compte, vous les utiliserez tous les jours.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr484446/">https://habr.com/ru/post/fr484446/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr484436/index.html">Open Source ingrat: le d√©veloppeur du serveur web le plus rapide a supprim√© son r√©f√©rentiel - Mise √† jour importante</a></li>
<li><a href="../fr484438/index.html">Des √©quations de fluides c√©l√®bres ont fui</a></li>
<li><a href="../fr484440/index.html">Sauvegarde compl√®te avec des outils Windows standard</a></li>
<li><a href="../fr484442/index.html">Exemple SNMPv3</a></li>
<li><a href="../fr484444/index.html">Comment les conditions de fonctionnement affectent la batterie ou l'histoire d'une r√©surrection miraculeuse</a></li>
<li><a href="../fr484448/index.html">Conf√©rence DEFCON 27. Pirater la police. Partie 1</a></li>
<li><a href="../fr484454/index.html">D√©tective Habra: votre photo est perdue</a></li>
<li><a href="../fr484456/index.html">ReactJS, rendu c√¥t√© serveur et quelques subtilit√©s du traitement des balises META de la page</a></li>
<li><a href="../fr484458/index.html">Ce pigiste est cass√© - donnez-moi le prochain</a></li>
<li><a href="../fr484462/index.html">Scraping Github: recherche de "secrets" √† d√©velopper</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
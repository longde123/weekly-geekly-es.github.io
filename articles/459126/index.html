<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙋 🚶🏾 🤣 Tanque de robot Raspberry Pi con Intel Neural Computer Stick 2 📩 🐯 🛵</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Así que ha llegado una nueva etapa en el desarrollo del tanque Raspberry . 

 En la serie anterior, resultó que la segmentación semántica fuera de la ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tanque de robot Raspberry Pi con Intel Neural Computer Stick 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/459126/">  Así que ha llegado una nueva etapa en el desarrollo del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tanque Raspberry</a> . <br><br>  En la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">serie anterior,</a> resultó que la segmentación semántica fuera de la caja era demasiado difícil para Raspberry. <br><br>  La lluvia de ideas y los comentarios nos permitieron identificar las siguientes áreas de desarrollo: <br><br><ul><li>  entrene su propia red E-net para el tamaño de imagen deseado </li><li>  transfiera el lanzamiento de una red neuronal desde la propia Raspberry a una pieza especial de hardware, de la cual se mencionó con mayor frecuencia Intel Movidius (también conocido como Neural Compute Stick, también conocido como NCS). </li></ul><br>  Adjuntar una nueva pieza de hierro al robot es lo más interesante en robótica, por lo que el trabajo minucioso de entrenar la red neuronal se ha pospuesto hasta tiempos mejores. <br><br>  Unos días, y la milagrosa pieza de hierro de Intel en mis manos. <br><br>  Es bastante grande y no se puede pegar en el conector USB inferior de la frambuesa.  Dado que los puertos USB derechos estaban ocultos por el trípode de la cámara y la parte superior izquierda estaba ocupada por el módulo GPS, no había tantas opciones. <br><br>  Como resultado, el GPS se colocó en un cable, se rechazó, y el cable se envolvió alrededor de un trípode, y el NCS se colocó en su lugar. <br><br>  En esta parte del hardware se completó. <br><br><img src="https://habrastorage.org/webt/rr/an/a1/rrana1u2e0uwupybfu4txj6hmmk.jpeg"><br><a name="habracut"></a><br><h2>  Intel NCS </h2><br>  Intel lanzó recientemente la segunda versión de NCS, y la API era completamente incompatible con la versión anterior, que los usuarios vertieron mucho dolor en Internet. <br><br>  Como resultado, toda la base de conocimiento sobre la versión anterior es solo basura informativa. <br><br>  La nueva edición ofrece el marco OpenVino, que incluye OpenCV y mucho más, incluidas varias herramientas para trabajar con redes neuronales. <br><br>  Aquí hay algunos artículos introductorios sobre NCS2 y OpenVino: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">De Intel mismo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Hacia la ciencia de datos I</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Hacia la ciencia de datos II</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PyImageSearch</a> </li></ul><br>  Comenzar con NCS resultó ser bastante sencillo. <br><br>  Intel inicialmente apoyó a Raspbian, por lo que no había necesidad de bailar con una pandereta. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El documento introductorio</a> también fue muy claro y la instalación del marco OpenVino no causó ningún problema. <br><br>  Resultó ser una buena ventaja que OpenVino incluye OpenCV 4.1, lo que ahorra tiempo, ya que tuve que construir versiones anteriores de OpenCV en Raspberry. <br><br>  Así es como se ve NCS2 por sí solo: <br><br><img src="https://habrastorage.org/webt/ww/dc/by/wwdcbyyaogekp33qbtehz6zp3mo.jpeg"><br><br>  Además resultó ser más interesante. <br><br>  NCS solo admite su propio formato de red neuronal, mientras que Intel proporciona la herramienta Model Optimizer como parte de OpenVino para convertir gráficos de los marcos más populares: Tensorflow, Caffe, Torch.  Más sobre esto será el próximo. <br><br>  Además, Intel también ofrece <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelos zoológicos</a> , un conjunto de modelos listos para usar en muchas ocasiones. <br><br>  Entre ellos había dos modelos para la segmentación de carreteras: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Uno mas simple</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Otro engañado</a> </li></ul><br><h2>  Redes neuronales en NCS </h2><br>  Para ejecutar una red neuronal en un dispositivo, debe seguir varios pasos. <br><br><h4>  Inicializar dispositivo </h4><br>  El nombre MYRIAD, la idea del complemento y la carga dinámica del mismo, la ruta a la que debe especificarse en el programa, se extienden claramente desde el pasado oscuro. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> openvino.inference_engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IENetwork, IEPlugin ncs_plugin = IEPlugin(device=<span class="hljs-string"><span class="hljs-string">"MYRIAD"</span></span>, plugin_dirs=<span class="hljs-string"><span class="hljs-string">"/opt/intel/openvino/inference_engine/lib/armv7l"</span></span>)</code> </pre> <br><h4>  Descargar modelo </h4><br>  A continuación, debe cargar el modelo en el dispositivo. <br><br>  Esta es una operación difícil.  Ese pequeño modelo que utilicé para la segmentación tarda unos 15 segundos en cargarse. <br><br>  La buena noticia es que solo necesita descargar el modelo una vez y puede descargar varios modelos. <br><br><pre> <code class="python hljs"> model = IENetwork(model=xml_path, weights=bin_path) net = ncs_plugin.load(network=model)</code> </pre><br><h4>  Ejecutar cálculo </h4><br>  Ahora se puede usar el modelo. <br><br><pre> <code class="python hljs"> input_blob = next(iter(model.inputs)) out_blob = next(iter(model.outputs)) n, c, h, w = model.inputs[input_blob].shape images = np.ndarray(shape=(n, c, h, w)) images[<span class="hljs-number"><span class="hljs-number">0</span></span>] = image res = net.infer(inputs={input_blob: images}) res = res[out_blob]</code> </pre><br><h4>  Proceso único </h4><br>  De repente resultó que no puedes usar NCS de dos procesos diferentes al mismo tiempo. <br>  Cualquier persona que llegue tarde no puede cargar el modelo: <br><br><pre> <code class="bash hljs">E: [ncAPI] [ 684447] resetAll:348 Failed to connect to stalled device, rc: X_LINK_ERROR E: [ncAPI] [ 691700] ncDeviceOpen:672 Failed to find suitable device, rc: X_LINK_DEVICE_NOT_FOUND Traceback (most recent call last): net = ncs_plugin.load(network=model) File <span class="hljs-string"><span class="hljs-string">"ie_api.pyx"</span></span>, line 395, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> openvino.inference_engine.ie_api.IEPlugin.load File <span class="hljs-string"><span class="hljs-string">"ie_api.pyx"</span></span>, line 406, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> openvino.inference_engine.ie_api.IEPlugin.load RuntimeError: Can not init USB device: NC_ERROR</code> </pre><br>  Ni Google ni el foro de asistencia de Intel hicieron posible entender qué era el problema: el dispositivo es realmente exclusivo o simplemente no sé cómo cocinarlo. <br><br><h2>  Segmentación OpenVino </h2><br>  Como ya se mencionó, fuera de la caja, OpenVino proporciona un modelo de segmentación de carreteras y ejemplos. <br><br>  Los resultados de la prueba son algo contradictorios.  A veces se reconoce torcidamente, pero en la mayoría es normal. <br><br>  Enet funcionó mejor, pero todavía tenemos que probar Enet en NCS, así que intentemos con lo que tenemos. <br><br><img src="https://habrastorage.org/webt/gk/ll/sm/gkllsmwznf3smcft_gyxk_gdaos.jpeg"><br><br>  Curiosamente, aprender más sobre el modelo de OpenVino y volver a entrenarlo no es tan simple. <br><br>  Los usuarios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">están interesados</a> , pero la persona de Intel dijo estrictamente que el código y los datos del modelo están cerrados, y aquellos que lo deseen pueden tomar una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">red neuronal similar en PyTorch</a> , entrenarla, convertirla y usarla. <br><br>  La ventaja de la velocidad es muy significativa: <br>  Si la segmentación de Enet tardó 6 segundos, entonces este modelo tardó 0,8 segundos en procesar una imagen (mientras que tardó 14 segundos en cargar el modelo en el dispositivo, pero esto se hace al mismo tiempo). <br><br><h3>  Clasificación de direcciones </h3><br>  Para tomar decisiones sobre la dirección del movimiento, el tanque utiliza una red neuronal simple, como se describe en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículo correspondiente</a> . <br><br>  La red neuronal está entrenada en Keras y se ejecuta en Raspberry a través de Tensorflow, que tiene un adaptador incorporado para este formato. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El modelo es</a> muy simple e incluso en Raspberry muestra resultados de velocidad aceptables. <br>  (0,35 segundos por imagen). <br><br>  Sin embargo, al tener la glándula Intel, puede esperar lograr mejores resultados. <br>  Entre los formatos que acepta el Optimizador de modelos de Intel para la conversión, hay Tensorflow, pero no Keras. <br><br>  Convertir Keras a TF es algo bastante popular, hay suficiente material sobre este tema, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este artículo</a> me guió. <br><br>  El mismo autor tiene un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículo más extenso</a> , solo sobre el tema de cómo ejecutar el modelo Keras en OpenVino. <br><br>  También puede usar la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">guía de Intel</a> . <br><br>  En general, compilando las fuentes, obtuve un script para convertir el modelo de Keras a TF: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.framework.graph_util <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> convert_variables_to_constants <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> model_from_json <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_keras_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(json_file, model_file)</span></span></span><span class="hljs-function">:</span></span> jf = open(json_file, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) loaded_model_json = jf.read() jf.close() loaded_model = model_from_json(loaded_model_json) loaded_model.load_weights(model_file) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> loaded_model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">freeze_session</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(session, keep_var_names=None, output_names=None, clear_devices=True)</span></span></span><span class="hljs-function">:</span></span> graph = session.graph <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> graph.as_default(): freeze_var_names = list(set(v.op.name <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tf.global_variables()).difference(keep_var_names <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> [])) output_names = output_names <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> [] output_names += [v.op.name <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tf.global_variables()] <span class="hljs-comment"><span class="hljs-comment"># Graph -&gt; GraphDef ProtoBuf input_graph_def = graph.as_graph_def() if clear_devices: for node in input_graph_def.node: node.device = "" frozen_graph = convert_variables_to_constants(session, input_graph_def, output_names, freeze_var_names) return frozen_graph model = load_keras_model('./model.json', './model.h5') frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs]) tf.train.write_graph(frozen_graph, ".", "ktf_model.pb", as_text=False)</span></span></code> </pre><br>  El mismo código se encuentra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en el github</a> . <br><br>  El modelo TF resultante se destila aún más en el formato OpenVino: <br><br><pre> <code class="bash hljs">python mo_tf.py --input_model <span class="hljs-string"><span class="hljs-string">"model/ktf_model.pb"</span></span> --log_level=DEBUG -b1 --data_type FP16</code> </pre> <br>  Las pruebas mostraron que la clasificación de la imagen toma 0.007 segundos. <br>  Este resultado es muy agradable. <br><br>  Todos los modelos entrenados (Keras, TF, OpenVino) también se cargan <a href="">en el github</a> . <br><br><h2>  Reconocimiento de objetos </h2><br>  La tarea de segmentación no es la única que un robot tiene que resolver en su difícil vida. <br><br>  Al principio había un detector de gatos, que luego se convirtió en un detector universal basado en MobileSSD y OpenCV-DNN. <br><br>  Ahora es el momento de activar la misma tarea en el NCS. <br><br>  En <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">model_zoo</a> de Intel, los detectores de una especificidad más estrecha basados ​​en MobileSSD son suficientes, pero no hay un análogo exacto. <br><br>  Sin embargo, esta red figura como compatible en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lista de modelos TF compatibles</a> . <br><br>  Curiosamente, al momento de escribir, la versión de MobileSSD 2018_01_28 se indica aquí. <br><br>  Sin embargo, OpenCV se niega a leer este modelo: <br><br><pre> <code class="bash hljs">cv2.error: OpenCV(4.1.0-openvino) /home/jenkins/workspace/OpenCV/OpenVINO/build/opencv/modules/dnn/src/tensorflow/tf_importer.cpp:530: error: (-2:Unspecified error) Const input blob <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> weights not found <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-string"><span class="hljs-string">'getConstBlob'</span></span></code> </pre><br>  (Pero descubrimos que usan Jenkins). <br><br>  Al mismo tiempo, la conversión a OpenVino es exitosa. <br><br>  Si intentamos convertir la versión de Mobile SSD compatible con OpenCV-DNN (11_06_2017), obtenemos esto: <br><br><pre> <code class="bash hljs">[E0919 main.py:317] Unexpected exception happened during extracting attributes <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/Relu6. Original exception message: operands could not be broadcast together with remapped shapes [original-&gt;remapped]: (0,) and requested shape (1,0,10,256)</code> </pre><br>  Algo así, técnicamente OpenVino y OpenCV-DNN están en el mismo paquete, pero son incompatibles con las versiones de las redes neuronales utilizadas. <br><br>  Es decir, si desea utilizar ambos enfoques simultáneamente, debe arrastrar dos versiones de MobileSSD. <br><br>  En términos de velocidad, la comparación está ciertamente a favor del NCS: 0.1 segundos versus 1.7. <br><br>  En términos de calidad ... (Aunque esto no es una cuestión de la NCS, sino de la evolución de la SSD móvil). <br><br><img src="https://habrastorage.org/webt/rz/58/zz/rz58zzzllyd5i3gubv99nz5-b6m.jpeg"><br><br><h2>  Clasificación de la imagen </h2><br>  El tanque puede clasificar imágenes a través de Tensorflow, usando Inception en Imagenet. <br>  Y usé Inception 2015-12-05, cuando era otro. <br><br>  Resultó que estaba muy por detrás de la vida, porque los chicos de Google no están comiendo su pan por nada y ¡ya han producido 4 versiones! <br><br>  Pero los chicos de Intel no están detrás de ellos y las 4 versiones fueron compatibles con OpenVino. <br><br>  Aquí hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un artículo que</a> describe varias versiones de Inception. <br>  Pero no vamos a jugar, descargamos inmediatamente el último, cuarto. <br><br>  Clasificamos la imagen con el gato y la computadora portátil sobre la mesa. <br><br>  Recordamos los resultados de la versión actual: <br><br><ul><li>  computadora portátil, computadora portátil 62% </li><li>  cuaderno, computadora portátil 11% </li><li>  13 segundos </li><li>  donde esta el gato </li></ul><br>  Ahora leemos las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">instrucciones</a> para convertir Inception a OpenVino. <br><br>  La conversión es exitosa, comenzamos el clasificador en NCS: <br><br><ul><li>  computadora portátil, computadora portátil 85% </li><li>  cuaderno, computadora portátil 8% </li><li>  0.2 segundos </li><li>  no hay gato otra vez </li></ul><br><h2>  Conclusión </h2><br>  Por lo tanto, todos los escenarios que requerían Tensorflow se reprodujeron usando NCS, y esto significa que puede optar por no usar Tensorflow. <br><br>  De todos modos, este marco es pesado para Raspberry. <br><br>  La velocidad con la que el NCS digiere la red neuronal le permite expandir sus horizontes. <br><br>  Hay tareas que el robot ya realiza, por ejemplo, segmentación semántica y clasificación, pero hay otras como la segmentación de objetos o la transmisión de video con objetos detectados en tiempo real.  (que no podría haberse pensado en la frambuesa desnuda). <br><br>  Los problemas con el multiprocesamiento son algo confusos, pero incluso si no se pueden resolver, siempre hay una opción en forma de envolver el NCS como un servicio separado. <br><br><h2>  Referencias </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Introducción a Intel OpenVino</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Guía de instalación de Raspbian</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenVino Model Zoo: una lista de modelos preparados con descripciones</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Recurso donde puede descargar modelos OpenVino</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Depósito de firmware de repositorio para OpenVino en github</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/459126/">https://habr.com/ru/post/459126/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../459114/index.html">14 mejores plugins de WordPress SEO en 2019</a></li>
<li><a href="../459116/index.html">Un paso más cerca de la reparación del timo</a></li>
<li><a href="../459118/index.html">Cómo diseñamos e implementamos la nueva red en Huawei en la oficina de Moscú, parte 2</a></li>
<li><a href="../459120/index.html">Computadoras modulares integradas de la serie UNO-1000/2000</a></li>
<li><a href="../459122/index.html">Aleksey Savvateev: Premio Nobel de Jean Tyrol por analizar mercados imperfectos (2014) y reputación colectiva</a></li>
<li><a href="../459128/index.html">Interfaces japonesas en el mundo real</a></li>
<li><a href="../459130/index.html">Manejo suave de errores en microservicios</a></li>
<li><a href="../459134/index.html">Experiencia usando BDD</a></li>
<li><a href="../459136/index.html">Píldora azul falsa</a></li>
<li><a href="../459138/index.html">Cómo la clave secreta de Huawei entró en el firmware de los enrutadores Cisco</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>   VotingClassifier en sikit-learn: construyendo y optimizando un conjunto de modelos de clasificaci贸n  そ </title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Como parte de la implementaci贸n de la gran tarea del An谩lisis de Sentimientos (an谩lisis de revisiones), decid铆 dedicar algo de tiempo al estudio adici...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>VotingClassifier en sikit-learn: construyendo y optimizando un conjunto de modelos de clasificaci贸n</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/430280/"> Como parte de la implementaci贸n de la gran tarea del An谩lisis de Sentimientos (an谩lisis de revisiones), decid铆 dedicar algo de tiempo al estudio adicional de su elemento separado, utilizando el VotingClassifier del m贸dulo sklearn.ensemble como una herramienta para construir un conjunto de modelos de clasificaci贸n y mejorar la calidad final de las predicciones.  驴Por qu茅 es esto importante y cu谩les son los matices? <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/pu/ka/uy/pukauyhbdf34xacms3hlnnm4jok.jpeg"><br><br>  A menudo sucede que, en el curso de la resoluci贸n del problema aplicado del an谩lisis de datos, no es inmediatamente obvio (o nada obvio) qu茅 modelo de capacitaci贸n es el m谩s adecuado.  Una soluci贸n puede ser seleccionar el modelo m谩s popular y / o intuitivamente apropiado en funci贸n de la naturaleza de los datos disponibles.  En este caso, los par谩metros del modelo seleccionado se optimizan (por ejemplo, a trav茅s de GridSearchCV) y se utilizan en el trabajo.  Otro enfoque puede ser utilizar un conjunto de modelos cuando los resultados de varios de ellos est谩n involucrados simult谩neamente en la formaci贸n del resultado final.  Dir茅 de inmediato que el prop贸sito del art铆culo no es describir las ventajas de usar un conjunto de modelos o los principios de su construcci贸n (esto se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu铆</a> ), sino m谩s bien en un enfoque aplicado por separado para resolver el problema usando un ejemplo espec铆fico y analizando los matices que surgen durante tal soluci贸n. <br><br>  <u>El enunciado del problema global es el siguiente</u> : solo se dieron <u>100</u> revisiones en tel茅fonos m贸viles como muestra de prueba, y necesitamos un modelo previamente entrenado que muestre el mejor resultado en estas 100 revisiones, es decir, determinar谩 si la revisi贸n es positiva o negativa.  Una dificultad adicional, como se deduce de las condiciones del problema, es la falta de una muestra de entrenamiento.  Para superar esta dificultad con la ayuda de la biblioteca Beautiful Soup, se analizaron con 茅xito 10,000 rese帽as sobre tel茅fonos m贸viles y calificaciones para ellos de uno de los sitios rusos. <br><br>  <i>Saltando los pasos de an谩lisis, preprocesamiento de datos y estudio de su estructura inicial</i> , pasamos al momento en que hay: <br><br><ul><li>  muestra de capacitaci贸n, que consta de 10,000 revisiones telef贸nicas, cada revisi贸n est谩 marcada como binaria (positiva o negativa).  Marcado para la definici贸n de revisiones con calificaciones 1-3 como negativas y calificaciones 4-5 como positivas. </li><li>  usando Count Vectorizer, los datos se presentan en una forma adecuada para entrenar modelos clasificadores </li></ul><br>  <u>驴C贸mo decidir qu茅 modelo es mejor para ti?</u>  No tenemos la capacidad de enumerar modelos manualmente, porque  una muestra de prueba de solo 100 revisiones plantea un gran riesgo de que alg煤n modelo simplemente se adapte mejor a esta muestra de prueba, pero si lo usa en una muestra adicional oculta a nosotros o en una "batalla", el resultado ser谩 inferior al promedio. <br><br>  Para resolver este problema <b>, la biblioteca Scikit-learn tiene un m贸dulo VotingClassifier</b> , que es una herramienta excelente para usar varios modelos de aprendizaje autom谩tico diferentes y combinarlos en un solo clasificador.  Esto reduce el riesgo de reentrenamiento, as铆 como la interpretaci贸n incorrecta de los resultados de cualquier modelo en particular.  <u>El m贸dulo VotingClassifier se importa con el siguiente comando</u> : <br> <code>from sklearn.ensemble import VotingClassifier</code> <br> <br>  Detalles pr谩cticos al trabajar con este m贸dulo: <br><br>  1) Lo primero y m谩s importante es c贸mo obtener una sola predicci贸n tomada del clasificador combinado despu茅s de recibir predicciones de cada uno de los modelos incluidos en 茅l.  Entre los par谩metros de VotingClassifier hay un par谩metro de <i>votaci贸n</i> con dos valores posibles: 'hard' y 'soft'. <br><br>  1.1) En el primer caso, la respuesta final del clasificador conjunto corresponder谩 a la "opini贸n" de la mayor铆a de sus miembros.  Por ejemplo, su clasificador combinado usa datos de tres modelos diferentes.  Dos de ellos en una observaci贸n espec铆fica predicen la respuesta "retroalimentaci贸n positiva", el tercero - "retroalimentaci贸n negativa".  Por lo tanto, para esta observaci贸n, la predicci贸n final ser谩 "retroalimentaci贸n positiva", ya que tenemos 2 - "a favor" y 1 "en contra". <br><br>  1.2) En el segundo caso, es decir  cuando se usa el valor "suave" del par谩metro de <i>votaci贸n</i> , hay una "votaci贸n" completa y una ponderaci贸n de las predicciones del modelo para <u>cada</u> clase, por lo que la respuesta final del clasificador combinado es la argmax de la suma de las probabilidades predichas.  <b>隆IMPORTANTE!</b>  Para poder utilizar dicho m茅todo de "votaci贸n", <b>cada</b> clasificador de los incluidos en su conjunto debe admitir el m茅todo <b>predict_proba ()</b> para obtener una estimaci贸n cuantitativa de la probabilidad de ocurrencia en cada una de las clases.  Tenga en cuenta que no todos los modelos de clasificadores admiten este m茅todo y, en consecuencia, se pueden usar dentro del marco de VotingClassifier cuando se usa el m茅todo de probabilidades ponderadas (votaci贸n suave). <br><br>  <u>Veamos un ejemplo</u> : hay tres clasificadores y dos clases de revisiones: positivas y negativas.  Cada clasificador, a trav茅s del m茅todo predict_proba, dar谩 un cierto valor de probabilidad (p), con el que asigna una observaci贸n particular a la clase 1 y, en consecuencia, con probabilidad (1-p) a la clase dos.  El clasificador combinado, despu茅s de recibir una respuesta de cada uno de los modelos, lleva a cabo la ponderaci贸n de las estimaciones obtenidas y da el resultado final obtenido como <p><math> </math> $$ display $$ max (w1 * p1 + w2 * p1 + w3 * p1, w1 * p2 + w2 * p2 + w3 * p3) $$ display $$ </p>  , donde w1, w2, w3 son los pesos de sus clasificadores incluidos en el conjunto, por defecto tienen pesos iguales, y p1, p2 es la evaluaci贸n de pertenecer a la clase 1 o clase 2 de cada uno de ellos.  Tenga en cuenta tambi茅n que los pesos de los clasificadores cuando se usa Soft Vote se pueden cambiar usando el par谩metro de pesos, por lo que la llamada al m贸dulo deber铆a verse as铆: <br>  <code>... = VotingClassifier(estimators=[('..', clf1), ('..', clf2), ('...', clf3)], voting='soft', weights=[*,*,*])</code> , donde los asteriscos pueden indicar los pesos requeridos para cada modelo. <br><br>  2) La capacidad de usar <u>simult谩neamente</u> el m贸dulo VotingClassifier y GridSearch para optimizar los hiperpar谩metros de cada uno de los clasificadores incluidos en el conjunto. <br><br>  Cuando planea usar un conjunto y desea que los modelos incluidos en 茅l sean optimizados, puede usar GridSearch ya en el clasificador unificado.  Y el siguiente c贸digo muestra c贸mo puede trabajar con los modelos incluidos en 茅l (regresi贸n log铆stica, ingenuo Bayes, descenso de gradiente estoc谩stico) mientras permanece dentro del marco del clasificador unificado (VotingClassifier): <br><br><pre> <code class="plaintext hljs">clf1 = LogisticRegression() clf2 = MultinomialNB() clf3 = SGDClassifier(max_iter=1000, loss='log') eclf = VotingClassifier(estimators=[ ('lr', clf1), ('nb', clf2),('sgd', clf3)], voting='hard') #      (hard voting), . . 1.1 &lt;b&gt;params = {'lr__C' : [0.5,1,1.5], 'lr__class_weight': [None,'balanced'], 'nb__alpha' : [0.1,1,2], 'sgd__penalty' : ['l2', 'l1'], 'sgd__alpha': [0.0001,0.001,0.01]} &lt;/b&gt; #       ,  ,     grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1) grid = grid.fit(data_messages_vectorized, df_texts['Binary_Rate']) #    ,      5     </code> </pre><br>  Por lo tanto, el diccionario de par谩metros debe establecerse de modo que, al acceder a 茅l a trav茅s de GridSearch, pueda determinar qu茅 par谩metro del conjunto de modelos se refiere a un par谩metro cuyo valor desea optimizar. <br><br>  Eso es todo lo que necesita saber para usar completamente la herramienta VotingClassifier como una forma de construir un conjunto de modelos y optimizarlo.  Veamos los resultados: <br><br><pre> <code class="plaintext hljs"> print grid.best_params_ {'lr__class_weight': 'balanced', 'sgd__penalty': 'l1', 'nb__alpha': 1, 'lr__C': 1, 'sgd__alpha': 0.001}</code> </pre><br>  Se encuentran los valores 贸ptimos de los par谩metros, queda por comparar los resultados del trabajo para el conjunto de clasificadores (VotingClassifier) con los par谩metros 贸ptimos, realizaremos una validaci贸n cruzada en la muestra de entrenamiento y compararemos los modelos con los par谩metros 贸ptimos y el conjunto que consiste en ellos: <br><br><pre> <code class="plaintext hljs">for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Naive Bayes', 'SGD', 'Ensemble_HardVoting']): scores = cross_val_score(clf, data_messages_vectorized, df_texts['Binary_Rate'], cv=3, scoring='accuracy') print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))</code> </pre><br>  El resultado final: <br><br>  Precisi贸n: 0,75 (卤 0,02) [Regresi贸n log铆stica] <br>  Precisi贸n: 0,79 (卤 0,02) [Naive Bayes] <br>  Precisi贸n: 0,79 (卤 0,02) [SGD] <br>  Precisi贸n: 0,79 (卤 0,02) [Ensemble_HardVoting] <br><br>  Como puede ver, los modelos se mostraron algo diferentes en la muestra de entrenamiento (con par谩metros est谩ndar, esta diferencia fue m谩s notable).  Adem谩s, el valor total (seg煤n la m茅trica de precisi贸n) del conjunto no tiene que exceder el mejor valor de los modelos incluidos en 茅l, porque  el conjunto es m谩s bien un modelo m谩s estable, capaz de mostrar un resultado similar en el conjunto de prueba y en la "batalla", lo que significa reducir el riesgo de reentrenamiento, ajuste al conjunto de entrenamiento y otros clasificadores de problemas relacionados con el entrenamiento.  隆Buena suerte en la resoluci贸n de problemas aplicados y gracias por su atenci贸n! <br><br>  PD Dadas las especificaciones y reglas de publicaci贸n en el sandbox, no puedo proporcionar un enlace a github y el c贸digo fuente para el an谩lisis dado en este art铆culo, as铆 como enlaces a Kaggle, en el marco de la competencia InClass que proporcion贸 un conjunto de pruebas y herramientas para verificar modelos en 茅l.  Solo puedo decir que este conjunto super贸 significativamente la l铆nea de base y ocup贸 el lugar que le corresponde en la tabla de clasificaci贸n despu茅s de verificar un conjunto de prueba.  Espero en las siguientes publicaciones que pueda compartir. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es430280/">https://habr.com/ru/post/es430280/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es430270/index.html">Pruebe esto: c贸mo determinamos qu茅 pruebas ejecutar en las comprobaciones de solicitud de extracci贸n</a></li>
<li><a href="../es430272/index.html">"Monstruos en juegos o 15 cm son suficientes para atacar"</a></li>
<li><a href="../es430274/index.html">7 juegos m谩s geniales para PC para aprender ingl茅s</a></li>
<li><a href="../es430276/index.html">El error devastador de los principiantes en gamedev</a></li>
<li><a href="../es430278/index.html">Conferencia de Budapest (29-31 de octubre) An谩lisis de datos</a></li>
<li><a href="../es430282/index.html">9 de cada 10 personas aceptan ganar menos en trabajos m谩s significativos</a></li>
<li><a href="../es430284/index.html">El resumen de materiales interesantes para el desarrollador m贸vil # 275 (12-18 de noviembre)</a></li>
<li><a href="../es430286/index.html">Detalles del lado desordenado y oscuro de los juegos piratas para Nintendo Switch</a></li>
<li><a href="../es430290/index.html">Un intento de predecir la cuarta iteraci贸n del proyecto SpaceX BFR</a></li>
<li><a href="../es430292/index.html">Electronic Frontier Foundation: el rendimiento de la red de matr铆culas de la polic铆a de los EE. UU. Es del 0,5%</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§Ωüèº üôâ üíÇüèº Nachrichtenbroker verstehen. Erlernen der Mechanismen des Messaging √ºber ActiveMQ und Kafka. Kapitel 3. Kafka üë©üèº‚Äçüç≥ üå´Ô∏è üë®üèø‚Äçüíº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fortsetzung der √úbersetzung eines kleinen Buches: 
 "Message Brokers verstehen", 
 Autor: Jakub Korab, Herausgeber: O'Reilly Media, Inc., Erscheinungs...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nachrichtenbroker verstehen. Erlernen der Mechanismen des Messaging √ºber ActiveMQ und Kafka. Kapitel 3. Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466585/">  Fortsetzung der √úbersetzung eines kleinen Buches: <br>  "Message Brokers verstehen", <br>  Autor: Jakub Korab, Herausgeber: O'Reilly Media, Inc., Erscheinungsdatum: Juni 2017, ISBN: 9781492049296. <br><br>  <b>√úbersetzung abgeschlossen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tele.gg/middle_java</a></b> <br><br>  Vorheriger Teil: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grundlegendes zu Message Brokern.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erlernen der Mechanismen des Messaging √ºber ActiveMQ und Kafka.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kapitel 2. ActiveMQ</a> <br><a name="habracut"></a><br><h2>  KAPITEL 3 </h2><br><h2>  Kafka </h2><br>  Kafka wurde auf LinkedIn entwickelt, um einige der Einschr√§nkungen herk√∂mmlicher Nachrichtenbroker zu umgehen und die Notwendigkeit zu vermeiden, mehrere Nachrichtenbroker f√ºr unterschiedliche Punkt-zu-Punkt-Interaktionen zu konfigurieren. Dies wird im Abschnitt ‚ÄûVertikale und horizontale Skalierung‚Äú auf Seite 28 in diesem Buch beschrieben. LinkedIn st√ºtzte sich stark auf die unidirektionale Absorption sehr gro√üer Datenmengen wie Seitenklicks und Zugriffsprotokolle, w√§hrend mehrere Systeme diese Daten verwenden konnten.  Uhr, ohne die Leistung anderer Hersteller oder konsyumerov zu beeinflussen.  Der Grund, warum Kafka existiert, besteht darin, die von der Universal Data Pipeline beschriebene Messaging-Architektur abzurufen. <br><br>  Angesichts dieses Endziels ergaben sich nat√ºrlich andere Anforderungen.  Kafka muss: <br><br><ul><li>  Sei extrem schnell </li><li>  Bieten Sie einen h√∂heren Messaging-Durchsatz </li><li>  Unterst√ºtzt Publisher-Subscriber- und Point-to-Point-Modelle </li><li>  Verlangsamen Sie nicht mit dem Hinzuf√ºgen von Verbrauchern.  Beispielsweise verschlechtert sich die Leistung von Warteschlangen und Themen in ActiveMQ mit zunehmender Anzahl von Verbrauchern am Ziel. </li><li>  Horizontal skalierbar sein;  Wenn eine einzelne persistierende Nachricht dies nur mit maximaler Festplattengeschwindigkeit tun kann, ist es zur Leistungssteigerung sinnvoll, die Grenzen einer Brokerinstanz zu √ºberschreiten </li><li>  Beschreiben Sie den Zugriff auf das Speichern und Abrufen von Nachrichten </li></ul><br>  Um all dies zu erreichen, hat Kafka eine Architektur eingef√ºhrt, die die Rollen und Verantwortlichkeiten von Kunden und Messaging-Brokern neu definiert.  Das JMS-Modell konzentriert sich sehr auf den Broker, bei dem er f√ºr die Verteilung von Nachrichten verantwortlich ist, und Kunden m√ºssen sich nur um das Senden und Empfangen von Nachrichten k√ºmmern.  Kafka hingegen ist kundenorientiert, wobei der Kunde viele Funktionen eines traditionellen Brokers √ºbernimmt, beispielsweise die gerechte Verteilung relevanter Nachrichten unter den Verbrauchern, und im Gegenzug einen extrem schnellen und skalierbaren Broker erh√§lt.  F√ºr Menschen, die mit traditionellen Nachrichtensystemen arbeiten, erfordert die Arbeit mit Kafka eine grundlegende √Ñnderung der Einstellung. <br>  Diese technische Ausrichtung hat zur Schaffung einer Messaging-Infrastruktur gef√ºhrt, die den Durchsatz im Vergleich zu einem herk√∂mmlichen Broker um viele Gr√∂√üenordnungen steigern kann.  Wie wir sehen werden, ist dieser Ansatz mit Kompromissen behaftet, was bedeutet, dass Kafka f√ºr bestimmte Arten von Lasten und installierter Software nicht geeignet ist. <br><br><h3>  Einheitliches Zielmodell </h3><br>  Um die oben beschriebenen Anforderungen zu erf√ºllen, kombinierte Kafka das Publikationsabonnement und das Punkt-zu-Punkt-Messaging in einem Adressatentyp - <i>Thema</i> .  Dies ist verwirrend f√ºr Personen, die mit Nachrichtensystemen arbeiten, bei denen sich das Wort "Thema" auf den √úbertragungsmechanismus bezieht, von dem (vom Thema) das Lesen nicht zuverl√§ssig ist (nicht haltbar ist).  Kafka-Themen sollten als hybrider Zieltyp betrachtet werden, wie in der Einleitung zu diesem Buch definiert. <br><blockquote>  Im Rest dieses Kapitels bezieht sich der Begriff Thema, sofern nicht ausdr√ºcklich anders angegeben, auf das Kafka-Thema. </blockquote><br>  Um zu verstehen, wie sich Themen verhalten und welche Garantien sie bieten, m√ºssen wir zun√§chst √ºberlegen, wie sie in Kafka implementiert werden. <br>  <i>Jedes Thema in Kafka hat ein eigenes Tagebuch.</i> <br>  Produzenten, die Nachrichten an Kafka senden, f√ºgen diese Zeitschrift hinzu, und Verbraucher lesen aus der Zeitschrift mit Zeigern, die sich st√§ndig weiterentwickeln.  Kafka l√∂scht regelm√§√üig die √§ltesten Teile des Journals, unabh√§ngig davon, ob Nachrichten in diesen Teilen gelesen wurden oder nicht.  Ein zentraler Bestandteil von Kafkas Design ist, dass es dem Broker egal ist, ob Nachrichten gelesen werden oder nicht - dies liegt in der Verantwortung des Kunden. <br><blockquote>  Die Begriffe "Journal" und "Index" sind in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kafka-Dokumentation nicht enthalten</a> .  Diese bekannten Begriffe werden hier zum besseren Verst√§ndnis verwendet. </blockquote><br>  Dieses Modell unterscheidet sich grundlegend von ActiveMQ, bei dem Nachrichten aus allen Warteschlangen in einem Journal gespeichert werden und der Broker Nachrichten nach dem Lesen als gel√∂scht markiert. <br>  Gehen wir jetzt etwas tiefer und schauen uns das Themenmagazin genauer an. <br>  Das Kafka Magazine besteht aus mehreren Partitionen ( <a href="">Abbildung 3-1</a> ).  Kafka garantiert eine strikte Reihenfolge in jeder Partition.  Dies bedeutet, dass Nachrichten, die in einer bestimmten Reihenfolge auf die Partition geschrieben wurden, in derselben Reihenfolge gelesen werden.  Jede Partition wird als fortlaufende (Protokoll-) Protokolldatei implementiert, die eine <i>Teilmenge</i> aller Nachrichten enth√§lt, die von ihren Produzenten an das Thema gesendet wurden.  Das erstellte Thema enth√§lt standardm√§√üig eine Partition.  Partitionierung ist Kafkas zentrale Idee f√ºr die horizontale Skalierung. <br><br><img src="https://habrastorage.org/webt/tm/w2/yf/tmw2yf3lanppqtrumxoidotplhi.png"><br>  <i>Abbildung 3-1.</i>  <i>Trennw√§nde Kafka</i> <br><br>  Wenn der Produzent eine Nachricht an das Kafka-Thema sendet, entscheidet er, an welche Partition die Nachricht gesendet werden soll.  Wir werden dies sp√§ter genauer betrachten. <br><br><h2>  Nachrichten lesen </h2><br>  Ein Client, der Nachrichten lesen m√∂chte, steuert einen benannten Zeiger, der als <i>Verbrauchergruppe</i> bezeichnet wird und den <i>Versatz einer</i> Nachricht in einer Partition angibt.  Ein Offset ist eine Position mit zunehmender Zahl, die am Anfang der Partition bei 0 beginnt.  Diese Gruppe von Verbrauchern, auf die in der API √ºber eine benutzerdefinierte Kennung group_id verwiesen wird, entspricht einem <i>einzelnen logischen Verbraucher oder System</i> . <br><br>  Die meisten Nachrichtensysteme lesen Daten vom Empf√§nger √ºber mehrere Instanzen und Threads, um Nachrichten parallel zu verarbeiten.  Daher wird es normalerweise viele F√§lle von Verbrauchern geben, die dieselbe Verbrauchergruppe teilen. <br><br>  Das Leseproblem kann wie folgt dargestellt werden: <br><br><ul><li>  Das Thema hat mehrere Partitionen </li><li>  Mehrere Verbrauchergruppen k√∂nnen das Thema gleichzeitig verwenden. </li><li>  Eine Gruppe von Verbrauchern kann mehrere separate Instanzen haben. </li></ul><br>  Dies ist ein nicht triviales Viele-zu-Viele-Problem.  Um zu verstehen, wie Kafka mit den Beziehungen zwischen Verbrauchergruppen, Instanzen von Verbrauchern und Partitionen umgeht, werfen wir einen Blick auf eine Reihe immer komplexer werdender Leseskripte. <br><br><h3>  Verbraucher und Verbrauchergruppen </h3><br>  Nehmen wir ein Thema mit einer einzelnen Partition als Ausgangspunkt ( <a href="">Abbildung 3-2</a> ). <br><br><img src="https://habrastorage.org/webt/6z/tz/dh/6ztzdhqmjweck-z15htxb2xbe28.png"><br>  <i>Abbildung 3-2.</i>  <i>Der Verbraucher liest von der Partition</i> <br><br>  Wenn eine Consumer-Instanz mit ihrer eigenen group_id zu diesem Thema verbunden ist, wird ihr eine zu lesende Partition und ein Offset in dieser Partition zugewiesen.  Die Position dieses Versatzes wird im Client als Zeiger auf die letzte Position (die neueste Nachricht) oder die fr√ºheste Position (die √§lteste Nachricht) konfiguriert.  Der Verbraucher fordert (Abfragen) Nachrichten zum Thema an, was zu deren sequentiellem Lesen aus dem Journal f√ºhrt. <br>  Die Versatzposition wird regelm√§√üig an Kafka zur√ºckgeschrieben und als Nachrichten im internen Thema <i>_consumer_offsets gespeichert</i> .  Gelesene Nachrichten werden im Gegensatz zu einem normalen Broker immer noch nicht gel√∂scht, und der Client kann den Offset zur√ºckspulen, um bereits angezeigte Nachrichten erneut zu verarbeiten. <br><br>  Wenn ein zweiter logischer Consumer √ºber eine andere group_id verbunden ist, steuert er einen zweiten Zeiger, der vom ersten unabh√§ngig ist ( <a href="">Abbildung 3-3</a> ).  Somit fungiert das Kafka-Thema als Warteschlange, in der sich ein Verbraucher befindet, und als regul√§res Thema als Herausgeber-Abonnent (Pub-Sub), bei dem mehrere Verbraucher abonniert sind, mit dem zus√§tzlichen Vorteil, dass alle Nachrichten gespeichert werden und mehrmals verarbeitet werden k√∂nnen. <br><br><img src="https://habrastorage.org/webt/qe/v1/yk/qev1yktga3s-g1gqlynylbe3n9w.png"><br>  <i>Abbildung 3-3.</i>  <i>Zwei Verbraucher in verschiedenen Verbrauchergruppen lesen von derselben Partition</i> <br><br><h3>  Verbraucher in der Verbrauchergruppe </h3><br>  Wenn eine Instanz des Verbrauchers Daten von der Partition liest, steuert sie den Zeiger vollst√§ndig und verarbeitet die Nachrichten, wie im vorherigen Abschnitt beschrieben. <br>  Wenn mehrere Instanzen der Konsumenten mit derselben Gruppe_ID mit einer Partition mit dem Thema verbunden waren, erh√§lt die zuletzt verbundene Instanz die Kontrolle √ºber den Zeiger und erh√§lt von da an alle Nachrichten ( <a href="">Abbildung 3-4</a> ). <br><br><img src="https://habrastorage.org/webt/0j/ao/f2/0jaof2mdwg3cqvmwemhtxkrltuq.png"><br>  <i>Abbildung 3-4.</i>  <i>Zwei Verbraucher in derselben Gruppe von Verbrauchern lesen von derselben Partition</i> <br><br>  Dieser Verarbeitungsmodus, bei dem die Anzahl der Verbraucherinstanzen die Anzahl der Partitionen √ºberschreitet, kann als eine Art Monopolverbraucher betrachtet werden.  Dies kann n√ºtzlich sein, wenn Sie ein "Aktiv-Passiv" - (oder "Hei√ü-Warm") - Clustering Ihrer Instanzen von Verbrauchern ben√∂tigen, obwohl der parallele Betrieb mehrerer Verbraucher ("Aktiv-Aktiv" oder "Hei√ü-Hei√ü") viel typischer ist als Verbraucher im Standby-Modus. <br><blockquote>  Dieses oben beschriebene Nachrichtenverteilungsverhalten kann im Vergleich zum Verhalten einer regul√§ren JMS-Warteschlange √ºberraschend sein.  In diesem Modell werden an die Warteschlange gesendete Nachrichten gleichm√§√üig zwischen den beiden Verbrauchern verteilt. </blockquote><br>  Wenn wir mehrere Instanzen von Compilern erstellen, tun wir dies meistens entweder zur parallelen Verarbeitung von Nachrichten oder um die Lesegeschwindigkeit zu erh√∂hen oder um die Stabilit√§t des Leseprozesses zu erh√∂hen.  Wie wird dies in Kafka erreicht, da nur eine Instanz eines Verbrauchers Daten von einer Partition lesen kann? <br><br>  Eine M√∂glichkeit, dies zu tun, besteht darin, eine Instanz des Verbrauchers zu verwenden, um alle Nachrichten zu lesen und sie an den Thread-Pool zu senden.  Obwohl dieser Ansatz den Verarbeitungsdurchsatz erh√∂ht, erh√∂ht er die Komplexit√§t der Logik der Verbraucher und tr√§gt nicht zur Erh√∂hung der Stabilit√§t des Lesesystems bei.  Wenn eine Instanz des Verbrauchers aufgrund eines Stromausfalls oder eines √§hnlichen Ereignisses ausgeschaltet wird, wird das Korrekturlesen gestoppt. <br><br>  Der kanonische Weg, um dieses Problem in Kafka zu l√∂sen, besteht darin, mehr Partitionen zu verwenden. <br><br><h3>  Partitionierung </h3><br>  Partitionen sind der Hauptmechanismus f√ºr die Parallelisierung des Lesens und Skalierens des Themas √ºber die Bandbreite einer Instanz des Brokers hinaus.  Um dies besser zu verstehen, betrachten wir eine Situation, in der es ein Thema mit zwei Partitionen gibt und ein Verbraucher dieses Thema abonniert ( <a href="">Abbildung 3-5</a> ). <br><br><img src="https://habrastorage.org/webt/en/9g/ct/en9gct0o017cqp8buawguwlscty.png"><br>  <i>Abbildung 3-5.</i>  <i>Ein Verbraucher liest von mehreren Partitionen</i> <br><br>  In diesem Szenario erh√§lt der Berater die Kontrolle √ºber die Zeiger, die seiner group_id in beiden Partitionen entsprechen, und das Lesen von Nachrichten von beiden Partitionen beginnt. <br>  Wenn diesem Thema ein zus√§tzlicher Compurator f√ºr dieselbe group_id hinzugef√ºgt wird, weist Kafka eine der Partitionen von der ersten zur zweiten neu zu (ordnet sie neu zu).  Danach wird jede Instanz des Verbrauchers von einer Partition des Themas abgezogen ( <a href="">Abbildung 3-6</a> ). <br><br>  Um sicherzustellen, dass Nachrichten in 20 Threads parallel verarbeitet werden, ben√∂tigen Sie mindestens 20 Partitionen.  Wenn weniger Partitionen vorhanden sind, haben Sie immer noch Konsumenten, an denen Sie nicht arbeiten m√ºssen, wie bereits in der Diskussion √ºber exklusive Monitore beschrieben. <br><br><img src="https://habrastorage.org/webt/8b/a0/um/8ba0umn2yzr9yy3vztonhdfiub0.png"><br>  <i>Abbildung 3-6.</i>  <i>Zwei Verbraucher in derselben Verbrauchergruppe lesen von verschiedenen Partitionen</i> <br><br>  Dieses Schema reduziert die Komplexit√§t des Kafka-Brokers im Vergleich zur Nachrichtenverteilung, die zur Unterst√ºtzung der JMS-Warteschlange erforderlich ist, erheblich.  Folgende Punkte m√ºssen nicht beachtet werden: <br><br><ul><li>  Welcher Verbraucher die n√§chste Nachricht basierend auf der Round-Robin-Verteilung, der aktuellen Prefetch-Pufferkapazit√§t oder fr√ºheren Nachrichten (wie bei JMS-Nachrichtengruppen) erhalten soll? </li><li>  Welche Nachrichten wurden an welche Verbraucher gesendet und sollten sie im Falle eines Fehlers erneut gesendet werden? </li></ul><br>  Der Kafka-Broker sollte lediglich konsistent Nachrichten an den Berater senden, wenn dieser diese anfordert. <br><br>  Die Anforderungen f√ºr die Parallelisierung des Korrekturlesens und das erneute Senden nicht erfolgreicher Nachrichten verschwinden jedoch nicht - die Verantwortung daf√ºr geht einfach vom Broker auf den Client √ºber.  Dies bedeutet, dass sie in Ihren Code einbezogen werden m√ºssen. <br><br><h2>  Nachrichten senden </h2><br>  Die Verantwortung f√ºr die Entscheidung, an welche Partition die Nachricht gesendet werden soll, liegt beim Hersteller der Nachricht.  Um den Mechanismus zu verstehen, mit dem dies geschieht, m√ºssen Sie zun√§chst √ºberlegen, was genau wir tats√§chlich senden. <br><br>  W√§hrend wir in JMS eine Nachrichtenstruktur mit Metadaten (Headern und Eigenschaften) und einem Text verwenden, der Nutzdaten enth√§lt, ist die Nachricht in Kafka <i>ein Schl√ºssel-Wert-Paar</i> .  Die Nachrichtennutzdaten werden als Wert gesendet.  Ein Schl√ºssel wird dagegen haupts√§chlich f√ºr die Partitionierung verwendet und muss einen <i>gesch√§ftslogikspezifischen Schl√ºssel enthalten</i> , um verwandte Nachrichten in dieselbe Partition zu stellen. <br><br>  In Kapitel 2 haben wir das Online-Wett-Szenario er√∂rtert, bei dem verwandte Ereignisse in der Reihenfolge von einem einzelnen Verbraucher verarbeitet werden sollten: <br><br><ol><li>  Das Benutzerkonto ist konfiguriert. </li><li>  Geld wird dem Konto gutgeschrieben. </li><li>  Es wird eine Wette abgeschlossen, die Geld vom Konto abhebt. </li></ol><br>  Wenn jedes Ereignis eine Nachricht ist, die an das Thema gesendet wird, ist in diesem Fall die Kontokennung der nat√ºrliche Schl√ºssel. <br>  Wenn eine Nachricht mit der Kafka Producer-API gesendet wird, wird sie an die Partitionsfunktion √ºbergeben, die angesichts der Nachricht und des aktuellen Status des Kafka-Clusters die Kennung der Partition zur√ºckgibt, an die die Nachricht gesendet werden soll.  Diese Funktion wird in Java √ºber die Partitioner-Oberfl√§che implementiert. <br><br>  Diese Schnittstelle ist wie folgt: <br><br><pre><code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Partitioner</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">partition</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String topic, Object key, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] keyBytes, Object value, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] valueBytes, Cluster cluster)</span></span></span></span>; }</code> </pre> <br>  Die Partitioner-Implementierung verwendet den Standard-Allzweck-Hashing-Algorithmus f√ºr den Schl√ºssel oder das Round-Robin, wenn der Schl√ºssel nicht zur Bestimmung der Partition angegeben ist.  Dieser Standardwert funktioniert in den meisten F√§llen gut.  In Zukunft m√∂chten Sie jedoch Ihre eigenen schreiben. <br><br><h3>  Schreiben Sie Ihre eigene Partitionierungsstrategie </h3><br>  Schauen wir uns ein Beispiel an, in dem Sie Metadaten zusammen mit der Nachrichtennutzlast senden m√∂chten.  Die Nutzlast in unserem Beispiel ist eine Anweisung zum Einzahlen auf ein Spielkonto.  Eine Anweisung m√∂chten wir garantieren, dass sie w√§hrend der √úbertragung nicht ge√§ndert wird, und wir m√∂chten sicherstellen, dass nur ein vertrauensw√ºrdiges √ºbergeordnetes System diese Anweisung initiieren kann.  In diesem Fall vereinbaren die sendenden und empfangenden Systeme die Verwendung der Signatur zur Authentifizierung der Nachricht. <br>  In einem regul√§ren JMS definieren wir einfach die Nachrichtensignatur-Eigenschaft und f√ºgen sie der Nachricht hinzu.  Kafka bietet uns jedoch keinen Mechanismus zur √úbertragung von Metadaten - nur den Schl√ºssel und den Wert. <br><br>  Da der Wert die Nutzlast einer Bank√ºberweisung (Bank√ºberweisungsnutzlast) ist, deren Integrit√§t wir beibehalten m√∂chten, haben wir keine andere Wahl, als die Datenstruktur f√ºr die Verwendung im Schl√ºssel zu bestimmen.  Angenommen, wir ben√∂tigen eine Kontokennung f√ºr die Partitionierung, da alle Nachrichten, die sich auf das Konto beziehen, der Reihe nach verarbeitet werden m√ºssen, werden wir die folgende JSON-Struktur erstellen: <br><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"signature"</span></span>: <span class="hljs-string"><span class="hljs-string">"541661622185851c248b41bf0cea7ad0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"accountId"</span></span>: <span class="hljs-string"><span class="hljs-string">"10007865234"</span></span> }</code> </pre> <br>  Da der Signaturwert abh√§ngig von der Nutzlast variiert, gruppiert die Standard-Hash-Strategie der Partitioner-Schnittstelle verwandte Nachrichten nicht zuverl√§ssig.  Daher m√ºssen wir unsere eigene Strategie schreiben, die diesen Schl√ºssel analysiert und den Wert von accountId teilt. <br><blockquote>  Kafka enth√§lt Pr√ºfsummen zum Erkennen von Nachrichtenbesch√§digungen im Repository und verf√ºgt √ºber einen vollst√§ndigen Satz von Sicherheitsfunktionen.  Selbst dann treten manchmal branchenspezifische Anforderungen auf, wie die oben genannten. </blockquote><br>  Die Benutzerpartitionierungsstrategie sollte sicherstellen, dass alle zugeh√∂rigen Nachrichten auf derselben Partition landen.  Obwohl dies einfach erscheint, kann die Anforderung kompliziert sein, da wichtige Nachrichten bestellt werden m√ºssen und die Anzahl der Partitionen im Thema festgelegt ist. <br><br>  Die Anzahl der Partitionen im Thema kann sich im Laufe der Zeit √§ndern, da sie hinzugef√ºgt werden k√∂nnen, wenn der Datenverkehr die urspr√ºnglichen Erwartungen √ºbertrifft.  Somit k√∂nnen Nachrichtenschl√ºssel der Partition zugeordnet werden, an die sie urspr√ºnglich gesendet wurden, was einen Teil des Status impliziert, der zwischen Produzenteninstanzen verteilt werden muss. <br><br>  Ein weiterer zu ber√ºcksichtigender Faktor ist die gleichm√§√üige Verteilung von Nachrichten zwischen Partitionen.  In der Regel sind Schl√ºssel nicht gleichm√§√üig auf Nachrichten verteilt, und Hash-Funktionen garantieren keine faire Verteilung von Nachrichten f√ºr einen kleinen Schl√ºsselsatz. <br>  Es ist wichtig zu beachten, dass das Trennzeichen selbst m√∂glicherweise wiederverwendet werden muss, unabh√§ngig davon, wie Sie die Nachrichten aufteilen. <br><br>  Ber√ºcksichtigen Sie die Anforderung f√ºr die Datenreplikation zwischen Kafka-Clustern an verschiedenen geografischen Standorten.  Zu diesem Zweck wird Kafka mit einem Befehlszeilentool namens MirrorMaker geliefert, mit dem Nachrichten von einem Cluster gelesen und an einen anderen √ºbertragen werden k√∂nnen. <br><br>  MirrorMaker muss die Schl√ºssel des replizierten Themas verstehen, um die relative Reihenfolge zwischen Nachrichten w√§hrend der Replikation zwischen Clustern beizubehalten, da die Anzahl der Partitionen f√ºr dieses Thema in zwei Clustern m√∂glicherweise nicht √ºbereinstimmt. <br><br>  Benutzerdefinierte Partitionierungsstrategien sind relativ selten, da Standard-Hashes oder Round-Robin in den meisten Szenarien erfolgreich funktionieren.  Wenn Sie jedoch strenge Bestellgarantien ben√∂tigen oder Metadaten aus den Nutzdaten extrahieren m√ºssen, sollten Sie sich die Partitionierung genauer ansehen. <br><br>  Die Skalierbarkeits- und Leistungsvorteile von Kafka ergeben sich aus der √úbertragung einiger Verantwortlichkeiten eines traditionellen Brokers auf einen Kunden.  In diesem Fall wird eine Entscheidung √ºber die Verteilung potenziell verwandter Nachrichten an mehrere parallel arbeitende Verbraucher getroffen. <br><blockquote>  JMS-Broker m√ºssen sich ebenfalls mit solchen Anforderungen befassen.  Interessanterweise erfordert der Mechanismus zum Senden verwandter Nachrichten an dasselbe Konto, der √ºber die JMS-Nachrichtengruppen implementiert wurde (eine Art SLB-Ausgleichsstrategie (Sticky Load Balancing)), dass der Absender auch Nachrichten als verwandt markiert.  Im Fall von JMS ist der Broker daf√ºr verantwortlich, diese Gruppe verwandter Nachrichten an einen der vielen Kunden zu senden und das Eigentum an der Gruppe zu √ºbertragen, wenn der Kunde abgefallen ist. </blockquote><br><h2>  Herstellervereinbarung </h2><br>  Partitionierung ist nicht das einzige, was beim Senden von Nachrichten ber√ºcksichtigt werden muss.  Schauen wir uns die send () -Methoden der Producer-Klasse in der Java-API an: <br><br><pre> <code class="java hljs">Future &lt; RecordMetadata &gt; send(ProducerRecord &lt; K, V &gt; record); Future &lt; RecordMetadata &gt; send(ProducerRecord &lt; K, V &gt; record, Callback callback);</code> </pre> <br>  Es ist sofort zu beachten, dass beide Methoden Future zur√ºckgeben, was darauf hinweist, dass der Sendevorgang nicht sofort ausgef√ºhrt wird.  Als Ergebnis stellt sich heraus, dass die Nachricht (ProducerRecord) f√ºr jede aktive Partition in den Sendepuffer geschrieben und im Hintergrundstrom in der Kafka-Clientbibliothek an den Broker √ºbertragen wird.  Dies macht die Arbeit zwar unglaublich schnell, bedeutet jedoch, dass eine unerfahrene Anwendung Nachrichten verlieren kann, wenn ihr Prozess gestoppt wird. <br><br>  Wie immer gibt es eine M√∂glichkeit, den Sendevorgang aufgrund der Leistung zuverl√§ssiger zu gestalten.  Die Gr√∂√üe dieses Puffers kann auf 0 gesetzt werden, und der Thread der sendenden Anwendung muss wie folgt warten, bis die Nachricht an den Broker gesendet wird: <br><br><pre> <code class="java hljs">RecordMetadata metadata = producer.send(record).get();</code> </pre> <br><h2>  Noch einmal √ºber das Lesen von Nachrichten </h2><br>  Das Lesen von Nachrichten hat zus√§tzliche Schwierigkeiten, die ber√ºcksichtigt werden m√ºssen.  Im Gegensatz zur JMS-API, mit der ein Nachrichtenlistener als Antwort auf eine Nachricht gestartet werden kann, werden von der <i>Consumer</i> Kafka-Schnittstelle nur Abfragen durchgef√ºhrt.  Schauen wir uns die zu diesem Zweck verwendete <i>poll ()</i> -Methode genauer an: <br><br><pre> <code class="java hljs">ConsumerRecords &lt; K, V &gt; poll(<span class="hljs-keyword"><span class="hljs-keyword">long</span></span> timeout);</code> </pre> <br>  Der R√ºckgabewert der Methode ist eine Container-Struktur, die mehrere <i>ConsumerRecord-</i> Objekte von m√∂glicherweise mehreren Partitionen enth√§lt.  <i>Ein ConsumerRecord</i> selbst ist ein Inhaberobjekt f√ºr ein Schl√ºssel-Wert-Paar mit zugeh√∂rigen Metadaten, z. B. der Partition, von der es abgeleitet ist. <br><br>  Wie in Kapitel 2 erl√§utert, m√ºssen wir uns st√§ndig daran erinnern, was mit Nachrichten geschieht, nachdem sie erfolgreich oder erfolglos verarbeitet wurden, z. B. wenn der Client die Nachricht nicht verarbeiten kann oder die Arbeit unterbricht.  In JMS wurde dies im Best√§tigungsmodus behandelt.  Der Broker l√∂scht entweder die erfolgreich verarbeitete Nachricht oder √ºbermittelt die unformatierte oder gespiegelte Nachricht erneut (sofern Transaktionen verwendet wurden). <br>  Kafka arbeitet ganz anders.  Nachrichten werden nach dem Korrekturlesen nicht im Broker gel√∂scht, und die Verantwortung f√ºr das, was bei einem Fehler passiert, liegt beim Code selbst. <br><br>  Wie bereits erw√§hnt, ist eine Gruppe von Verbrauchern mit einem Offset in der Zeitschrift verbunden.  Die dieser Verzerrung zugeordnete Protokollposition entspricht der n√§chsten Nachricht, die als Antwort auf <i>poll ()</i> ausgegeben wird.  Entscheidend beim Lesen ist der Zeitpunkt, zu dem dieser Versatz zunimmt. <br><br>  Zur√ºck zum zuvor diskutierten Lesemodell besteht die Nachrichtenverarbeitung aus drei Schritten: <br><br><ol><li>  Rufen Sie eine Nachricht zum Lesen ab. </li><li>  Verarbeiten Sie die Nachricht. </li><li>  Nachricht best√§tigen. </li></ol><br>  Der Kafka Consumer Advisor wird mit der Konfigurationsoption <i>enable.auto.commit geliefert</i> .  Dies ist eine h√§ufig verwendete Standardeinstellung, wie dies normalerweise bei Einstellungen der Fall ist, die das Wort ‚Äûauto‚Äú enthalten. <br><br>  Vor Kafka 0.10 hat der Client, der diesen Parameter verwendet, den Offset der zuletzt gelesenen Nachricht beim n√§chsten Aufruf von <i>poll ()</i> nach der Verarbeitung gesendet.  Dies bedeutete, dass alle Nachrichten, die bereits abgerufen wurden, erneut verarbeitet werden konnten, wenn der Client sie bereits verarbeitet hatte, aber vor dem Aufruf von <i>poll ()</i> unerwartet zerst√∂rt wurden.  Da der Broker keinen Status dar√ºber beh√§lt, wie oft die Nachricht gelesen wurde, wei√ü der n√§chste Verbraucher, der diese Nachricht abruft, nicht, dass etwas Schlimmes passiert ist.  Dieses Verhalten war pseudotransaktional.  Der Offset wurde nur bei erfolgreicher Verarbeitung der Nachricht festgeschrieben. Wenn der Client jedoch unterbrochen wurde, hat der Broker dieselbe Nachricht erneut an einen anderen Client gesendet.  Dieses Verhalten stimmte mit der Garantie f√ºr die Zustellung von Nachrichten " <i>mindestens einmal</i> " √ºberein. <br><br>  In Kafka 0.10 wurde der Clientcode so ge√§ndert, dass das Commit gem√§√ü der Einstellung <i>auto.commit.interval.ms</i> regelm√§√üig von der <i>Clientbibliothek gestartet wurde</i> .  Dieses Verhalten liegt irgendwo zwischen den Modi JMS AUTO_ACKNOWLEDGE und DUPS_OK_ACKNOWLEDGE.  Bei Verwendung der automatischen Festschreibung k√∂nnen Nachrichten best√§tigt werden, unabh√§ngig davon, ob sie tats√§chlich verarbeitet wurden. Dies kann bei einem langsamen Verbraucher der Fall sein.  Wenn der Compurator unterbrochen wurde, wurden Nachrichten vom n√§chsten Compurator ab einer gesicherten Position abgerufen, was zum √úberspringen von Nachrichten f√ºhren konnte.  In diesem Fall hat Kafka keine Nachrichten verloren, der Lesecode hat sie einfach nicht verarbeitet. <br><br>  Dieser Modus hat die gleichen Aussichten wie in Version 0.9: Nachrichten k√∂nnen verarbeitet werden, aber im Falle eines Fehlers wird der Offset m√∂glicherweise nicht geschlossen, was m√∂glicherweise zu einer doppelten Zustellung f√ºhren kann.  Je mehr Nachrichten Sie bei <i>poll ()</i> abrufen, desto gr√∂√üer ist dieses Problem. <br><br>  Wie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Abschnitt</a> ‚ÄûSubtrahieren von Nachrichten von der Warteschlange‚Äú in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kapitel 2</a> erl√§utert, gibt es im Nachrichtensystem angesichts der Fehlermodi keine einmalige Nachrichten√ºbermittlung. <br><br>  In Kafka gibt es zwei M√∂glichkeiten, einen Offset (Offset) zu korrigieren (festzuschreiben): automatisch und manuell.  In beiden F√§llen k√∂nnen Nachrichten mehrmals verarbeitet werden, falls die Nachricht verarbeitet wurde, aber vor dem Festschreiben fehlgeschlagen ist.  Sie k√∂nnen die Nachricht auch √ºberhaupt nicht verarbeiten, wenn das Festschreiben im Hintergrund erfolgt ist und Ihr Code vor Beginn der Verarbeitung abgeschlossen wurde (m√∂glicherweise in Kafka 0.9 und fr√ºheren Versionen). <br><br>  Sie k√∂nnen den Prozess des manuellen <i>Festschreibens</i> von Offsets in der Kafka <i>Consumer-</i> API <i>steuern</i> , indem Sie <i>enable.auto.commit</i> auf false setzen und eine der folgenden Methoden explizit aufrufen: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">commitSync</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">commitAsync</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>;</code> </pre> <br>  Wenn Sie die Nachricht "mindestens einmal" verarbeiten m√∂chten, m√ºssen Sie den Offset manuell mit <i>commitSync () festschreiben,</i> indem Sie diesen Befehl unmittelbar nach der Verarbeitung der Nachrichten ausf√ºhren. <br><br>  Mit diesen Methoden k√∂nnen best√§tigte Nachrichten nicht verarbeitet werden, bevor sie verarbeitet werden. Sie tragen jedoch nicht dazu bei, potenzielle Verarbeitungsduplikationen zu beseitigen und gleichzeitig den Anschein von Transaktionsf√§higkeit zu erwecken.  Kafka hat keine Transaktionen.  Der Kunde hat nicht die M√∂glichkeit, Folgendes zu tun: <br><br><ul><li>  Rollback einer Rollback-Nachricht automatisch.  Verbraucher selbst m√ºssen Ausnahmen behandeln, die sich aus problematischen Nutzdaten und Backend-Trennungen ergeben, da sie sich nicht darauf verlassen k√∂nnen, dass der Broker Nachrichten erneut √ºbermittelt. </li><li>  Senden Sie Nachrichten an mehrere Themen innerhalb einer atomaren Operation.  Wie wir gleich sehen werden, kann die Kontrolle √ºber verschiedene Themen und Partitionen auf verschiedenen Computern im Kafka-Cluster erfolgen, die beim Senden keine Transaktionen koordinieren.  Zum Zeitpunkt dieses Schreibens wurden einige Arbeiten durchgef√ºhrt, um dies mit dem KIP-98 zu erm√∂glichen. </li><li>  Verkn√ºpfen Sie das Lesen einer Nachricht aus einem Thema mit dem Senden einer anderen Nachricht an ein anderes Thema.  Auch hier h√§ngt die Architektur von Kafka von vielen unabh√§ngigen Maschinen ab, die als ein Bus arbeiten, und es wird kein Versuch unternommen, ihn zu verbergen.  Beispielsweise gibt es keine API-Komponenten, mit denen der <i>Verbraucher</i> und der <i>Produzent</i> in einer Transaktion verkn√ºpft werden k√∂nnen.  In JMS wird dies durch das <i>Sitzungsobjekt</i> bereitgestellt, aus dem <i>MessageProducers</i> und <i>MessageConsumers</i> erstellt werden. </li></ul><br>  Wenn wir uns nicht auf Transaktionen verlassen k√∂nnen, wie k√∂nnen wir eine Semantik bereitstellen, die der von herk√∂mmlichen Messagingsystemen n√§her kommt? <br><br>  Wenn die M√∂glichkeit besteht, dass sich der Offset des Verbrauchers erh√∂ht, bevor die Nachricht verarbeitet wurde, z. B. w√§hrend des Ausfalls des Kunden, kann der Kunde nicht herausfinden, ob die Kundengruppe die Nachricht √ºbergeben hat, als ihr eine Partition zugewiesen wurde.  Daher besteht eine Strategie darin, den Versatz auf die vorherige Position zur√ºckzuspulen.  Die Kafka Consumer Advisor-API bietet hierf√ºr folgende Methoden: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">seek</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(TopicPartition partition, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">long</span></span></span></span><span class="hljs-function"><span class="hljs-params"> offset)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">seekToBeginning</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Collection &lt; TopicPartition &gt; partitions)</span></span></span></span>;</code> </pre> <br>  Die Methode <i>seek ()</i> kann mit der Methode verwendet werden <br>  <i>offsetsForTimes (Map &lt;TopicPartition, Long&gt; timestampsToSearch)</i> , um zu einem bestimmten Zeitpunkt in der Vergangenheit in einen Zustand zur√ºckzuspulen. <br><br>  Die Verwendung dieses Ansatzes bedeutet implizit, dass es sehr wahrscheinlich ist, dass einige Nachrichten, die zuvor verarbeitet wurden, gelesen und erneut verarbeitet werden.  Um dies zu vermeiden, k√∂nnen wir, wie in Kapitel 4 beschrieben, idempotentes Lesen verwenden, um zuvor angezeigte Nachrichten zu verfolgen und Duplikate zu beseitigen. <br><br>  Alternativ kann der Code Ihres Verbrauchers einfach sein, wenn der Verlust oder die Vervielf√§ltigung von Nachrichten zul√§ssig ist.  Wenn wir uns Nutzungsszenarien ansehen, f√ºr die Kafka normalerweise verwendet wird, z. B. die Verarbeitung von Protokollereignissen, Metriken, Klickverfolgung usw., verstehen wir, dass der Verlust einzelner Nachrichten wahrscheinlich keine wesentlichen Auswirkungen auf die umgebenden Anwendungen hat.  In solchen F√§llen sind die Standardwerte akzeptabel.  Wenn Ihre Anwendung jedoch Zahlungen √ºberweisen muss, m√ºssen Sie sich sorgf√§ltig um jede einzelne Nachricht k√ºmmern.  Es kommt alles auf den Kontext an. <br><br>  Pers√∂nliche Beobachtungen zeigen, dass mit zunehmender Nachrichtenintensit√§t der Wert jeder einzelnen Nachricht abnimmt.  Nachrichten mit hohem Volumen werden in der Regel wertvoll, wenn sie in aggregierter Form angezeigt werden. <br><br><h2>  Hochverf√ºgbarkeit </h2><br>  Der Hochverf√ºgbarkeitsansatz von Kafka unterscheidet sich stark von ActiveMQ.  Kafka basiert auf horizontal skalierbaren Clustern, in denen alle Instanzen des Brokers gleichzeitig Nachrichten empfangen und verteilen. <br><br>  Der Kafka-Cluster besteht aus mehreren Brokerinstanzen, die auf verschiedenen Servern ausgef√ºhrt werden.  Kafka wurde f√ºr die Arbeit mit einer herk√∂mmlichen eigenst√§ndigen Hardware entwickelt, bei der jeder Knoten √ºber einen eigenen dedizierten Speicher verf√ºgt.  Die Verwendung von Network Attached Storage (SAN) wird nicht empfohlen, da mehrere Rechenknoten um Speicherzeitschlitze konkurrieren und Konflikte verursachen k√∂nnen. <br><br>  Kafka ist ein <i>st√§ndig laufendes</i> System.  Viele gro√üe Kafka-Benutzer l√∂schen ihre Cluster nie und die Software bietet Updates immer durch einen konsistenten Neustart.  Dies wird erreicht, indem die Kompatibilit√§t mit der vorherigen Version f√ºr Nachrichten und Interaktionen zwischen Brokern gew√§hrleistet wird. <br><br>  Broker sind mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ZooKeeper</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Servercluster verbunden</a> , der als vorgegebene Konfigurationsregistrierung fungiert und zur Koordinierung der Rollen der einzelnen Broker verwendet wird.  ZooKeeper selbst ist ein verteiltes System, das durch Informationsreplikation durch Einrichtung eines <i>Quorums</i> eine hohe Verf√ºgbarkeit bietet. <br><br>  Im Basisfall wird das Thema im Kafka-Cluster mit den folgenden Eigenschaften erstellt: <br><br><ul><li>  Die Anzahl der Partitionen.  Wie bereits erw√§hnt, h√§ngt der hier verwendete genaue Wert von der gew√ºnschten Stufe des gleichzeitigen Lesens ab. </li><li>  Der Replikationskoeffizient (Faktor) bestimmt, wie viele Brokerinstanzen im Cluster die Protokolle f√ºr diese Partition enthalten sollen. </li></ul><br>  Mit ZooKeepers zur Koordination versucht Kafka, neue Partitionen fair zwischen den Brokern im Cluster zu verteilen.  Dies erfolgt durch eine Instanz, die als Controller fungiert. <br><br>  Zur Laufzeit <i>f√ºr jede Partition des Themas weist der</i> <i>Controller</i> dem Broker die Rollen von <i>Leader</i> (Leader, Master, Leader) und <i>Followern</i> (Follower, Slaves, Subordinates) zu.  Der Broker, der als Leiter dieser Partition fungiert, ist daf√ºr verantwortlich, alle von den Herstellern an ihn gesendeten Nachrichten zu empfangen und Nachrichten an die Verbraucher zu verteilen.  Wenn Sie Nachrichten an eine Themenpartition senden, werden diese auf alle Brokerknoten repliziert, die als Follower f√ºr diese Partition fungieren.  Jeder Knoten, der die Protokolle f√ºr die Partition enth√§lt, wird als <i>Replikat bezeichnet</i> .  Ein Broker kann f√ºr einige Partitionen als Leader und f√ºr andere als Follower fungieren. <br><br>  Ein Follower, der alle vom Leader gespeicherten Nachrichten enth√§lt, wird als <i>synchronisiertes Replikat bezeichnet</i> (ein Replikat in einem synchronisierten Zustand, synchrones Replikat).  Wenn der Broker, der als Leader f√ºr die Partition fungiert, nicht verbunden ist, kann jeder Broker, der sich f√ºr diese Partition im aktualisierten oder synchronisierten Zustand befindet, die Rolle des Leader √ºbernehmen.  Dies ist ein unglaublich nachhaltiges Design. <br><br>  Teil der Konfiguration des Herstellers ist der Parameter <i>acks</i> , der bestimmt, wie viele Replikate den Empfang einer Nachricht best√§tigen sollen, bevor der Anwendungsstrom weiter sendet: 0, 1 oder alle.  Wenn der Wert auf <i>all</i> gesetzt ist, sendet der Leiter beim Empfang der Nachricht eine Best√§tigung an den Produzenten zur√ºck, sobald er eine Best√§tigung von den verschiedenen Replikaten (einschlie√ülich sich selbst) erh√§lt, die in der <i>Themeneinstellung min.insync.replicas</i> (standardm√§√üig 1) definiert sind.  Wenn die Nachricht nicht erfolgreich repliziert werden kann, <i>l√∂st</i> der Hersteller eine Ausnahme f√ºr die Anwendung aus ( <i>NotEnoughReplicas</i> oder <i>NotEnoughReplicasAfterAppend</i> ). <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In einer typischen Konfiguration wird ein Thema mit einem Replikationskoeffizienten von 3 (1 Leader, 2 Follower f√ºr jede Partition) erstellt und der Parameter </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">min.insync.replicas</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auf 2 gesetzt. In diesem Fall kann einer der Broker, die die Partition verwalten, vom Cluster getrennt werden ohne Auswirkungen auf Client-Anwendungen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies bringt uns zur√ºck zu dem bereits bekannten Kompromiss zwischen Leistung und Zuverl√§ssigkeit. Die Replikation erfolgt aufgrund der zus√§tzlichen Wartezeit f√ºr Best√§tigungen (Best√§tigungen) von Followern. Da die Replikation von mindestens drei Knoten parallel ausgef√ºhrt wird, hat sie dieselbe Leistung wie zwei (ohne Ber√ºcksichtigung der Zunahme der Netzwerkbandbreitennutzung).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit diesem Replikationsschema vermeidet Kafka geschickt die Notwendigkeit, jede Nachricht mithilfe der Operation </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sync ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> physisch auf die Festplatte zu schreiben </font><font style="vertical-align: inherit;">. Jede vom Produzenten gesendete Nachricht wird in das Partitionsprotokoll geschrieben. Wie in Kapitel 2 erl√§utert, wird das Schreiben in die Datei zun√§chst im Betriebssystempuffer ausgef√ºhrt. Wenn diese Nachricht auf eine andere Instanz von Kafka repliziert wird und sich in seinem Speicher befindet, bedeutet der Verlust eines Anf√ºhrers nicht, dass die Nachricht selbst verloren gegangen ist - eine synchronisierte Replik kann sie auf sich nehmen. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deaktivieren Sie den Betrieb von </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sync ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bedeutet, dass Kafka Nachrichten mit der Geschwindigkeit empfangen kann, mit der sie in den Speicher geschrieben werden k√∂nnen. Umgekehrt ist es umso besser, je l√§nger Sie vermeiden k√∂nnen, Speicher auf die Festplatte zu leeren. Aus diesem Grund ist es f√ºr Kafka-Broker nicht ungew√∂hnlich, 64 GB oder mehr Speicher zuzuweisen. Diese Speichernutzung bedeutet, dass eine Instanz von Kafka problemlos mit einer Geschwindigkeit arbeiten kann, die viele tausend Mal schneller ist als ein herk√∂mmlicher Nachrichtenbroker. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka kann auch f√ºr die Verwendung von </font><i><font style="vertical-align: inherit;">sync ()</font></i><font style="vertical-align: inherit;"> konfiguriert werden.</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zu Nachrichtenpaketen. Da alles bei Kafka paketorientiert ist, funktioniert es f√ºr viele Anwendungsf√§lle ziemlich gut und ist ein n√ºtzliches Werkzeug f√ºr Benutzer, die sehr starke Garantien ben√∂tigen. Der gr√∂√üte Teil der reinen Leistung von Kafka bezieht sich auf Nachrichten, die in Form von Paketen an den Broker gesendet werden, und auf die Tatsache, dass diese Nachrichten in aufeinanderfolgenden Bl√∂cken mithilfe von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nullkopiervorg√§ngen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vom Broker gelesen </font><font style="vertical-align: inherit;">werden (Vorg√§nge, bei denen keine Daten aus einem Speicherbereich kopiert werden) ein anderer). Letzteres ist ein gro√üer Gewinn in Bezug auf Leistung und Ressourcen und nur durch die Verwendung der zugrunde liegenden Protokolldatenstruktur m√∂glich, die das Partitionsschema definiert.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In einem Kafka-Cluster ist eine viel h√∂here Leistung m√∂glich als bei Verwendung eines einzelnen Kafka-Brokers, da die Themenpartitionen auf vielen separaten Computern horizontal skaliert werden k√∂nnen.</font></font><br><br><h2>  Zusammenfassung </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In diesem Kapitel haben wir untersucht, wie die Kafka-Architektur die Beziehung zwischen Clients und Brokern neu interpretiert, um eine unglaublich robuste Messaging-Pipeline bereitzustellen, deren Bandbreite um ein Vielfaches h√∂her ist als bei einem normalen Nachrichtenbroker. Wir haben die Funktionen er√∂rtert, mit denen dieses Ziel erreicht wird, und kurz die Architektur der Anwendungen √ºberpr√ºft, die diese Funktionen bereitstellen. Im n√§chsten Kapitel werden wir allgemeine Probleme diskutieren, die Messaging-Anwendungen l√∂sen m√ºssen, und Strategien zu ihrer L√∂sung diskutieren. Wir schlie√üen das Kapitel mit einer Beschreibung der allgemeinen Beschreibung von Messaging-Technologien ab, damit Sie deren Eignung f√ºr Ihre Anwendungsf√§lle bewerten k√∂nnen. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√úbersetzung abgeschlossen: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tele.gg/middle_java</font></font></a></b> <br><br>  <i>Fortsetzung folgt...</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de466585/">https://habr.com/ru/post/de466585/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de466575/index.html">√úbergabe zweidimensionaler Listen von Python an DLL</a></li>
<li><a href="../de466577/index.html">Wie zwei Sch√ºler das Spiel unter iOS gemacht haben und wie viel sie damit verdient haben</a></li>
<li><a href="../de466579/index.html">Die Geschichte der Tetris-Randomisierungsalgorithmen</a></li>
<li><a href="../de466581/index.html">Quantendarwinismus: Eine Idee, die die objektive Realit√§t erkl√§rt, besteht den ersten Test</a></li>
<li><a href="../de466583/index.html">Eine kurze Geschichte des L√ºgendetektors</a></li>
<li><a href="../de466589/index.html">So empfangen Sie Daten von Google Analytics mit R in Microsoft SQL Server</a></li>
<li><a href="../de466591/index.html">MVC ohne C: Was √§ndert SwiftUI in der Anwendungsarchitektur?</a></li>
<li><a href="../de466593/index.html">Situation: Hybrid Cloud- und IaaS-Perspektiven</a></li>
<li><a href="../de466597/index.html">Zweiter Platz in der Mini AI Cup 4: Paper IO</a></li>
<li><a href="../de466599/index.html">So umgehen Sie Captcha mithilfe der Tonerkennung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñêüèΩ üõµ ü•â Experi√™ncia de modelagem da equipe Computer Vision Mail.ru üë®üèæ‚Äç‚úàÔ∏è üï∫üèø üßíüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Meu nome √© Eduard Tyantov, lidero a equipe da Computer Vision no Mail.ru Group. Ao longo dos v√°rios anos de exist√™ncia, nossa equipe resolveu dezenas ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Experi√™ncia de modelagem da equipe Computer Vision Mail.ru</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/460307/"><img src="https://habrastorage.org/webt/zz/gc/py/zzgcpycxxdaz-0a657wzkvjlvos.jpeg"><br><br>  Meu nome √© Eduard Tyantov, lidero a equipe da Computer Vision no Mail.ru Group.  Ao longo dos v√°rios anos de exist√™ncia, nossa equipe resolveu dezenas de problemas de vis√£o computacional, e hoje vou falar sobre os m√©todos que usamos para criar modelos de aprendizado de m√°quina que funcionam em uma ampla variedade de tarefas.  Compartilharei truques que podem acelerar o modelo em todas as etapas: defini√ß√£o de uma tarefa, prepara√ß√£o de dados, treinamento e implanta√ß√£o na produ√ß√£o. <br><a name="habracut"></a><br><h2>  Computer Vision em Mail.ru </h2><br>  Para come√ßar, o que √© o Computer Vision no Mail.ru e quais projetos fazemos.  Fornecemos solu√ß√µes em nossos produtos, como Mail, Mail.ru Cloud (um aplicativo para armazenar fotos e v√≠deos), Vision (solu√ß√µes B2B baseadas na vis√£o computacional) e outros.  Vou dar alguns exemplos. <br><br>  O Cloud (este √© o nosso primeiro e principal cliente) possui 60 bilh√µes de fotos.  Desenvolvemos v√°rios recursos baseados no aprendizado de m√°quina para o processamento inteligente, por exemplo, reconhecimento de rosto e passeios tur√≠sticos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">h√° um post separado sobre isso</a> ).  Todas as fotos do usu√°rio s√£o executadas em modelos de reconhecimento, o que permite organizar uma pesquisa e um agrupamento por pessoas, tags, cidades e pa√≠ses visitados e assim por diante. <br><br><img src="https://habrastorage.org/webt/dc/ls/ug/dclsugao8xumevprode0ift5dxq.jpeg"><img src="https://habrastorage.org/webt/zr/bo/rd/zrbordgq4zygrzpzvmsg5x0nt6i.jpeg"><br><br>  Para o Mail, fizemos OCR - reconhecimento de texto de uma imagem.  Hoje vou falar um pouco mais sobre ele. <br><br>  Para produtos B2B, reconhecemos e contamos pessoas em filas.  Por exemplo, h√° uma fila para o telef√©rico e voc√™ precisa calcular quantas pessoas est√£o nele.  Para come√ßar, para testar a tecnologia e jogar, implantamos um prot√≥tipo na sala de jantar do escrit√≥rio.  Existem v√°rias mesas de caixa e, consequentemente, v√°rias filas, e n√≥s, usando v√°rias c√¢meras (uma para cada uma das filas), usando o modelo, calculamos quantas pessoas est√£o nas filas e quantos minutos restantes restam em cada uma delas.  Dessa forma, podemos equilibrar melhor as linhas na sala de jantar. <br><br><img src="https://habrastorage.org/webt/yr/yq/hb/yryqhbu5zqhxm_fozg-4ygkz6i4.jpeg"><br><br><h2>  Declara√ß√£o do problema </h2><br>  Vamos come√ßar com a parte cr√≠tica de qualquer tarefa - sua formula√ß√£o.  Quase todo desenvolvimento de ML leva pelo menos um m√™s (isso √© o melhor quando voc√™ sabe o que fazer) e, na maioria dos casos, v√°rios meses.  Se a tarefa estiver incorreta ou imprecisa, h√° uma grande chance no final do trabalho de ouvir do gerente de produto algo no esp√≠rito: ‚ÄúEst√° tudo errado.  Isso n√£o √© bom.  Eu queria outra coisa.  Para impedir que isso aconte√ßa, voc√™ precisa executar algumas etapas.  O que h√° de especial nos produtos baseados em ML?  Diferentemente da tarefa de desenvolver um site, a tarefa de aprendizado de m√°quina n√£o pode ser formalizada apenas com texto.  Al√©m disso, como regra geral, parece para uma pessoa despreparada que tudo j√° √© √≥bvio, e √© simplesmente necess√°rio fazer tudo "lindamente".  Mas que pequenos detalhes existem, o gerente de tarefas pode nem saber, nunca pensou neles e n√£o pensar√° at√© ver o produto final e dizer: "O que voc√™ fez?" <br><br><h2>  Os problemas </h2><br>  Vamos entender por exemplo quais problemas podem ser.  Suponha que voc√™ tenha uma tarefa de reconhecimento de rosto.  Voc√™ o recebe, se alegra e chama sua m√£e: "Viva, uma tarefa interessante!"  Mas √© poss√≠vel quebrar diretamente e come√ßar a fazer?  Se voc√™ fizer isso, no final, poder√° esperar surpresas: <br><br><ul><li>  Existem diferentes nacionalidades.  Por exemplo, n√£o havia asi√°ticos ou mais ningu√©m no conjunto de dados.  Seu modelo, portanto, n√£o sabe como reconhec√™-los, e o produto precisa dele.  Ou vice-versa, voc√™ gastou mais tr√™s meses em revis√£o, e o produto ter√° apenas caucasianos, e isso n√£o foi necess√°rio. <br></li><li>  Tem filhos  Para pais sem filhos como eu, todos os filhos est√£o em um rosto.  Estou absolutamente de acordo com o modelo, quando ela envia todos os filhos para um cluster - n√£o est√° realmente claro como a maioria das crian√ßas difere!  ;) Mas as pessoas que t√™m filhos t√™m uma opini√£o completamente diferente.  Geralmente eles tamb√©m s√£o seus l√≠deres.  Ou ainda h√° erros de reconhecimento engra√ßados quando a cabe√ßa da crian√ßa √© comparada com sucesso com o cotovelo ou a cabe√ßa de um homem careca (hist√≥ria verdadeira). <br></li><li>  O que fazer com caracteres pintados geralmente n√£o √© claro.  Preciso reconhec√™-los ou n√£o? <br></li></ul><br>  Tais aspectos da tarefa s√£o muito importantes para serem identificados no in√≠cio.  Portanto, voc√™ precisa trabalhar e se comunicar com o gerente desde o in√≠cio "nos dados".  Explica√ß√µes orais n√£o podem ser aceitas.  √â necess√°rio olhar para os dados.  √â desej√°vel a partir da mesma distribui√ß√£o na qual o modelo funcionar√°. <br><br>  Idealmente, no processo desta discuss√£o, ser√° obtido algum conjunto de dados de teste no qual voc√™ pode finalmente executar o modelo e verificar se ele funciona como o gerente queria.  √â aconselh√°vel fornecer parte do conjunto de dados de teste ao pr√≥prio gerente, para que voc√™ n√£o tenha acesso a ele.  Como voc√™ pode treinar facilmente neste conjunto de testes, voc√™ √© um desenvolvedor de ML! <br><br>  Definir uma tarefa no ML √© um trabalho constante entre um gerente de produto e um especialista no ML.  Mesmo que, a princ√≠pio, voc√™ defina bem a tarefa, √† medida que o modelo se desenvolver, mais e mais novos problemas aparecer√£o, novos recursos que voc√™ aprender√° sobre seus dados.  Tudo isso precisa ser discutido constantemente com o gerente.  Bons gerentes sempre transmitem para suas equipes de ML que eles precisam assumir responsabilidade e ajudar o gerente a definir tarefas. <br><br>  Porque  O aprendizado de m√°quina √© uma √°rea relativamente nova.  Os gerentes n√£o t√™m (ou t√™m pouca) experi√™ncia no gerenciamento de tais tarefas.  Com que frequ√™ncia as pessoas aprendem a resolver novos problemas?  Sobre os erros.  Se voc√™ n√£o deseja que seu projeto favorito se torne um erro, voc√™ precisa se envolver e assumir a responsabilidade, ensinar o gerente de produto a definir corretamente a tarefa, desenvolver listas de verifica√ß√£o e pol√≠ticas;  tudo isso ajuda muito.  Cada vez que me retiro (ou algu√©m dos meus colegas me puxa) quando uma nova tarefa interessante chega, e corremos para faz√™-la.  Tudo o que acabei de lhe contar, eu mesmo esque√ßo.  Portanto, √© importante ter algum tipo de lista de verifica√ß√£o para verificar a si mesmo. <br><br><h2>  Dados </h2><br>  Os dados s√£o super importantes no ML.  Para aprendizado profundo, quanto mais dados voc√™ alimentar modelos, melhor.  O gr√°fico azul mostra que geralmente os modelos de aprendizado profundo melhoram bastante quando os dados s√£o adicionados. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1x/wf/bb/1xwfbbc7-os0p9wjc8y_2iiyn10.jpeg"></div><br>  E os algoritmos "antigos" (cl√°ssicos) de algum ponto n√£o podem mais melhorar. <br><br>  Geralmente nos conjuntos de dados ML est√£o sujos.  Eles foram marcados por pessoas que sempre mentem.  Os avaliadores geralmente n√£o prestam aten√ß√£o e cometem muitos erros.  Usamos esta t√©cnica: pegamos os dados que temos, treinamos o modelo neles e, com a ajuda desse modelo, limpamos os dados e repetimos o ciclo novamente. <br><br>  Vamos dar uma olhada no exemplo do mesmo reconhecimento facial.  Digamos que baixamos os avatares de usu√°rios do VKontakte.  Por exemplo, temos um perfil de usu√°rio com 4 avatares.  Detectamos rostos que est√£o nas 4 imagens e percorremos o modelo de reconhecimento de rostos.  Portanto, temos casamentos de pessoas, com a ajuda das quais elas podem "colar" pessoas semelhantes em grupos (grupos).  Em seguida, selecionamos o maior cluster, assumindo que os avatares do usu√°rio contenham principalmente sua face.  Dessa forma, podemos limpar todos os outros rostos (que s√£o ru√≠dos) dessa maneira.  Depois disso, podemos repetir o ciclo novamente: nos dados limpos, treine o modelo e use-o para limpar os dados.  Voc√™ pode repetir v√°rias vezes. <br><br>  Quase sempre para esse agrupamento, usamos os algoritmos CLink.  Esse √© um algoritmo de cluster hier√°rquico no qual √© muito conveniente definir um valor limite para "colar" objetos semelhantes (√© exatamente isso que √© necess√°rio para a limpeza).  O CLink gera clusters esf√©ricos.  Isso √© importante, pois geralmente aprendemos o espa√ßo m√©trico dessas incorpora√ß√µes.  O algoritmo tem uma complexidade de O (n <sup>2</sup> ), que, em princ√≠pio, √© de aprox. <br><br>  √Äs vezes, os dados s√£o t√£o dif√≠ceis de obter ou marcar que n√£o h√° mais nada a fazer assim que voc√™ come√ßa a ger√°-los.  A abordagem generativa permite produzir uma enorme quantidade de dados.  Mas para isso voc√™ precisa programar alguma coisa.  O exemplo mais simples √© OCR, reconhecimento de texto em imagens.  A marca√ß√£o do texto para esta tarefa √© extremamente cara e barulhenta: voc√™ precisa destacar cada linha e cada palavra, assinar o texto e assim por diante.  Os avaliadores (marcadores) ocupar√£o cem p√°ginas de texto por um per√≠odo extremamente longo e √© necess√°rio muito mais para o treinamento.  Obviamente, voc√™ pode de alguma forma gerar o texto e, de alguma forma, "mov√™-lo" para que o modelo aprenda com ele. <br><br>  Descobrimos por n√≥s mesmos que o melhor e mais conveniente kit de ferramentas para essa tarefa √© uma combina√ß√£o de PIL, OpenCV e Numpy.  Eles t√™m tudo para trabalhar com texto.  Voc√™ pode complicar a imagem com o texto de qualquer maneira, para que a rede n√£o seja treinada novamente para obter exemplos simples. <br><br><img src="https://habrastorage.org/webt/cv/zd/ib/cvzdibgjrtt_qnyro4u8-zcgdgw.png"><br><br>  √Äs vezes precisamos de alguns objetos do mundo real.  Por exemplo, mercadorias nas prateleiras das lojas.  Uma dessas imagens √© gerada automaticamente.  Voc√™ acha que esquerda ou direita? <br><br><img src="https://habrastorage.org/webt/os/py/gi/ospygi-cu95vtgblk8ekol86qak.jpeg"><br><br>  De fato, ambos s√£o gerados.  Se voc√™ n√£o olhar para os pequenos detalhes, n√£o perceber√° diferen√ßas da realidade.  Fazemos isso usando o Blender (anal√≥gico do 3dmax). <br><br><img src="https://habrastorage.org/webt/wq/7i/hd/wq7ihd3zrqp0fevkbdylp96hm0m.jpeg"><br><br>  A principal vantagem importante √© que √© de c√≥digo aberto.  Possui uma excelente API Python, que permite colocar diretamente objetos no c√≥digo, configurar e randomizar o processo e, finalmente, obter um conjunto de dados diversificado. <br><br>  Para renderiza√ß√£o, o tra√ßado de raios √© usado.  Este √© um procedimento bastante caro, mas produz um resultado com excelente qualidade.  A quest√£o mais importante: onde conseguir modelos para objetos?  Como regra, eles devem ser comprados.  Mas se voc√™ √© um estudante pobre e quer experimentar algo, sempre h√° torrents.  √â claro que, para a produ√ß√£o, voc√™ precisa comprar ou pedir modelos renderizados de algu√©m. <br><br>  Isso √© tudo sobre os dados.  Vamos para o aprendizado. <br><br><h2>  Aprendizado m√©trico </h2><br>  O objetivo do aprendizado do Metric √© treinar a rede para converter objetos semelhantes em regi√µes semelhantes no espa√ßo m√©trico de incorpora√ß√£o.  Darei novamente um exemplo com as vistas, o que √© incomum, pois √© essencialmente uma tarefa de classifica√ß√£o, mas para dezenas de milhares de classes.  Parece, por que aqui a aprendizagem m√©trica, que, por regra, √© apropriada em tarefas como reconhecimento facial?  Vamos tentar descobrir. <br><br>  Se voc√™ usar perdas padr√£o ao treinar um problema de classifica√ß√£o, por exemplo, Softmax, as classes no espa√ßo m√©trico estar√£o bem separadas, mas no espa√ßo de incorpora√ß√£o, pontos de classes diferentes poder√£o estar pr√≥ximos um do outro ... <br><br><img src="https://habrastorage.org/webt/od/fl/aq/odflaq4hgygf8vvrnftdrdeinh8.jpeg"><br><br>  Isso cria poss√≠veis erros durante a generaliza√ß√£o, como  uma pequena diferen√ßa nos dados de origem pode alterar o resultado da classifica√ß√£o.  Gostar√≠amos realmente que os pontos fossem mais compactos.  Para isso, s√£o utilizadas v√°rias t√©cnicas de aprendizado m√©trico.  Por exemplo, perda de centro, cuja ideia √© extremamente simples: simplesmente juntamos pontos ao centro de aprendizagem de cada classe, que eventualmente se torna mais compacto. <br><br><img src="https://habrastorage.org/webt/am/pf/nw/ampfnwjhkn4idpxob_tjpvg3sey.jpeg"><br><br>  A perda de centro √© programada literalmente em 10 linhas em Python, funciona muito rapidamente e, o mais importante, melhora a qualidade da classifica√ß√£o, porque  compacidade leva a uma melhor capacidade de generaliza√ß√£o. <br><br><h2>  Softmax angular </h2><br>  Tentamos muitos m√©todos diferentes de aprendizado de m√©tricas e chegamos √† conclus√£o de que o Angular Softmax produz os melhores resultados.  Entre a comunidade de pesquisa, ele tamb√©m √© considerado o estado da arte. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ks/gx/ap/ksgxapfkweb9invhas0g2dz2w2s.jpeg"></div><br>  Vejamos um exemplo de reconhecimento de rosto.  Aqui temos duas pessoas.  Se voc√™ usar o Softmax padr√£o, um plano de divis√£o ser√° desenhado entre eles - com base em dois vetores de peso.  Se fizermos a norma de incorpora√ß√£o 1, os pontos estar√£o no c√≠rculo, ou seja,  na esfera no caso n-dimensional (figura √† direita). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/by/zf/a9/byzfa9okk0cry7vcx6vg4n3dsd8.jpeg"></div><br>  Ent√£o voc√™ pode ver que o √¢ngulo entre eles j√° √© respons√°vel pela separa√ß√£o de classes e pode ser otimizado.  Mas isso n√£o basta.  Se continuarmos a otimizar o √¢ngulo, a tarefa n√£o mudar√° de fato, porque  n√≥s simplesmente a reformulamos em outros termos.  Nosso objetivo, lembro-me, √© tornar os clusters mais compactos. <br><br>  √â necess√°rio, de alguma maneira, exigir um √¢ngulo maior entre as classes - para complicar a tarefa da rede neural.  Por exemplo, de tal maneira que ela acha que o √¢ngulo entre os pontos de uma classe √© maior do que na realidade, de modo que ela tenta comprimi-los cada vez mais.  Isto √© conseguido atrav√©s da introdu√ß√£o do par√¢metro m, que controla a diferen√ßa nos cossenos dos √¢ngulos. <br><br><img src="https://habrastorage.org/webt/lx/fk/xc/lxfkxcrdodlg-wpoasqxcws3gao.jpeg"><br><br>  Existem v√°rias op√ß√µes para o Angular Softmax.  Todos eles brincam com o fato de multiplicar por m esse √¢ngulo ou somar, ou multiplicar e somar.  Estado-da-arte - ArcFace. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/_i/zw/ye_izwbkvqmr0-fxpxahc2uty6e.gif"></div><br>  De fato, √© f√°cil integrar este na classifica√ß√£o de pipeline. <br><br><img src="https://habrastorage.org/webt/05/gi/vt/05givtsihtduioo9co9f0jzj5hk.jpeg"><br><br>  Vejamos o exemplo de Jack Nicholson.  Corremos a foto dele pela grade no processo de aprendizado.  Obtemos incorpora√ß√£o, percorremos a camada linear para classifica√ß√£o e obtemos pontua√ß√µes na sa√≠da, que refletem o grau de pertencimento √† classe.  Nesse caso, a fotografia de Nicholson tem uma velocidade de 20, a maior.  Al√©m disso, de acordo com a f√≥rmula do ArcFace, reduzimos a velocidade de 20 para 13 (feita apenas para a classe groundtruth), complicando a tarefa da rede neural.  Em seguida, fazemos tudo como de costume: Softmax + Cross Entropy. <br><br>  No total, a camada linear usual √© substitu√≠da pela camada ArcFace, que √© escrita n√£o em 10, mas em 20 linhas, mas oferece excelentes resultados e um m√≠nimo de sobrecarga para implementa√ß√£o.  Como resultado, o ArcFace √© melhor que a maioria dos outros m√©todos para a maioria das tarefas.  Ele se integra perfeitamente √†s tarefas de classifica√ß√£o e melhora a qualidade. <br><br><h2>  Transfer√™ncia de aprendizado </h2><br>  A segunda coisa que eu queria falar √© sobre o aprendizado de transfer√™ncia - usando uma rede pr√©-treinada em uma tarefa semelhante para reciclagem de uma nova tarefa.  Assim, o conhecimento √© transferido de uma tarefa para outra. <br><br>  Fizemos nossa busca por imagens.  A ess√™ncia da tarefa √© produzir semanticamente semelhantes a partir do banco de dados na imagem (consulta). <br><br><img src="https://habrastorage.org/webt/hp/m-/x2/hpm-x27etg2zdagi9wupvgjdqtm.jpeg"><br><br>  √â l√≥gico pegar uma rede que j√° estudou um grande n√∫mero de imagens - nos conjuntos de dados ImageNet ou OpenImages, nos quais existem milh√µes de fotos, e treinar nossos dados. <br><br><img src="https://habrastorage.org/webt/fn/hq/c-/fnhqc-efmzfkuqmwocx_zy4wp1a.jpeg"><br><br>  Coletamos dados para esta tarefa com base na semelhan√ßa de imagens e cliques do usu√°rio e obtivemos 200 mil aulas.  Ap√≥s o treinamento com o ArFace, obtivemos o seguinte resultado. <br><br><img src="https://habrastorage.org/webt/da/gu/dd/daguddqmsfbsvj9rdrix-slta4u.jpeg"><br><br>  Na foto acima, vemos que, para o pelicano solicitado, os pardais tamb√©m entraram na quest√£o.  I.e.  a incorpora√ß√£o acabou semanticamente verdadeira - √© um p√°ssaro, mas racialmente infiel.  O mais irritante √© que o modelo original com o qual treinamos novamente conhecia essas classes e as distinguia perfeitamente.  Aqui vemos o efeito comum a todas as redes neurais, chamado esquecimento catastr√≥fico.  Ou seja, durante a reciclagem, a rede esquece a tarefa anterior, √†s vezes at√© completamente.  √â exatamente isso que impede nesta tarefa de obter melhor qualidade. <br><br><h2>  Destila√ß√£o de conhecimento </h2><br>  Isso √© tratado usando uma t√©cnica chamada destila√ß√£o de conhecimento, quando uma rede ensina a outra e ‚Äútransfere seu conhecimento para ela‚Äù.  Como est√° (pipeline de treinamento completo na figura abaixo). <br><br><img src="https://habrastorage.org/webt/-j/bx/kc/-jbxkco1joxnxva7ec8luts-hii.jpeg"><br><br>  J√° temos um pipeline de classifica√ß√£o familiar com o Arcface.  Lembre-se de que temos uma rede com a qual somos fingidos.  Congelamos e simplesmente calculamos seus embeddings em todas as fotos em que aprendemos nossa rede e obtemos as classes das classes OpenImages: pelicanos, pardais, carros, pessoas, etc. OpenImages, que produz pontua√ß√µes semelhantes.  Com o BCE, fazemos com que a rede produza uma distribui√ß√£o semelhante dessas pontua√ß√µes.  Assim, por um lado, estamos aprendendo uma nova tarefa (na parte superior da imagem), mas tamb√©m fazemos com que a rede n√£o esque√ßa suas ra√≠zes (na parte inferior) - lembre-se das aulas que costumava conhecer.  Se voc√™ equilibrar corretamente os gradientes em uma propor√ß√£o condicional de 50/50, isso deixar√° todos os pelicanos no topo e jogar√° fora todos os pardais de l√°. <br><br><img src="https://habrastorage.org/webt/vx/kf/ha/vxkfhatx6n6heozx_xpbhgg_zuq.jpeg"><br><br>  Quando aplicamos isso, obtivemos uma porcentagem completa no mAP.  Isso √© bastante. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modelo </th><th>  MAP </th></tr><tr><td>  Arcface </td><td>  92,8 </td></tr><tr><td>  + Conhecimento destilado </td><td>  93,8 (+ 1%) </td></tr></tbody></table></div><br>  Portanto, se sua rede esquecer a tarefa anterior, trate-a usando a destila√ß√£o de conhecimento - isso funciona bem. <br><br><h2>  Cabe√ßas extras </h2><br>  A ideia b√°sica √© muito simples.  Novamente no exemplo de reconhecimento de rosto.  Temos um conjunto de pessoas no conjunto de dados.  Mas tamb√©m frequentemente nos conjuntos de dados existem outras caracter√≠sticas da face.  Por exemplo, quantos anos, que cor dos olhos etc.  Tudo isso pode ser adicionado como mais uma adi√ß√£o.  sinal: ensine chefes individuais a prever esses dados.  Assim, nossa rede recebe um sinal mais diversificado e, como resultado, pode ser melhor aprender a tarefa principal. <br><br><img src="https://habrastorage.org/webt/43/to/rp/43torpgdsj-cce3akz2pfe3me9a.jpeg"><br><br>  Outro exemplo: detec√ß√£o de fila. <br><br><img src="https://habrastorage.org/webt/im/cj/tk/imcjtk4jdpqwcphgrzjldnckfgq.jpeg"><br><br>  Muitas vezes, em conjuntos de dados com pessoas, al√©m do corpo, h√° uma marca√ß√£o separada da posi√ß√£o da cabe√ßa, que, obviamente, pode ser usada.  Portanto, adicionamos √† rede a previs√£o da caixa delimitadora da pessoa e a previs√£o da caixa delimitadora da cabe√ßa e obtivemos um aumento de 0,5% na precis√£o (mAP), o que √© decente.  E o mais importante - gratuito em termos de desempenho, porque  na produ√ß√£o, a cabe√ßa extra √© "desconectada". <br><br><img src="https://habrastorage.org/webt/gl/4y/5l/gl4y5lhjiikvdewhfntr7bdhkwu.jpeg"><br><br><h2>  OCR </h2><script type="text/javascript">function gtElInit() {var lib = new google.translate.TranslateService();lib.translatePage('ru', 'pt', function () {});}</script><script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=gtElInit&amp;client=wt"></script><br>  Um caso mais complexo e interessante √© o OCR, j√° mencionado acima.  O pipeline padr√£o √© assim. <br><br><img src="https://habrastorage.org/webt/i8/nj/dd/i8njddzf7z3ux8wcawjqmjvkyri.jpeg"><br><br>  Que haja um p√¥ster com um pinguim, o texto est√° escrito nele.  Usando o modelo de detec√ß√£o, destacamos este texto.  Al√©m disso, alimentamos esse texto com a entrada do modelo de reconhecimento, que produz o texto reconhecido.  Digamos que nossa rede esteja errada e, em vez de "i", a palavra pinguins prediz "l".  Na verdade, esse √© um problema muito comum no OCR quando a rede confunde caracteres semelhantes.  A quest√£o √© como evitar isso - traduzir pengulns em pinguins?  Quando uma pessoa olha para este exemplo, √© √≥bvio para ele que isso √© um erro, porque  ele tem conhecimento da estrutura da linguagem.  Portanto, o conhecimento sobre a distribui√ß√£o de caracteres e palavras no idioma deve ser incorporado no modelo. <br><br>  Usamos uma coisa chamada BPE (codifica√ß√£o de pares de bytes) para isso.  Esse √© um algoritmo de compacta√ß√£o que foi geralmente inventado nos anos 90, n√£o para aprendizado de m√°quina, mas agora √© muito popular e √© usado no aprendizado profundo.  O significado do algoritmo √© que as subsequ√™ncias frequentes no texto s√£o substitu√≠das por novos caracteres.  Suponha que tenhamos a string "aaabdaaabac" e desejemos obter um BPE para ela.  Conclu√≠mos que o par de caracteres ‚Äúaa‚Äù √© o mais frequente em nossa palavra.  N√≥s o substitu√≠mos por um novo caractere "Z", obtemos a string "ZabdZabac".  Repetimos a itera√ß√£o: vemos que ab √© a subsequ√™ncia mais frequente, substitua-a por "Y", obtemos a string "ZYdZYac".  Agora ‚ÄúZY‚Äù √© a subsequ√™ncia mais frequente, substitu√≠mos por ‚ÄúX‚Äù, obtemos ‚ÄúXdXac‚Äù.  Assim, codificamos algumas depend√™ncias estat√≠sticas na distribui√ß√£o do texto.  Se encontrarmos uma palavra na qual existem subsequ√™ncias muito "estranhas" (raras para o corpo docente), ent√£o essa palavra √© suspeita. <br><br> <code>aaabdaaabac <br> ZabdZabac Z=aa <br> <font color="#fa7566">ZY</font> d <font color="#fa7566">ZY</font> ac Y=ab <br> <font color="#fa7566">X</font> d <font color="#fa7566">X</font> ac X=ZY</code> <br> <br>  Como tudo se encaixa no reconhecimento. <br><br><img src="https://habrastorage.org/webt/zq/fm/1v/zqfm1vzn2szxicl-txouuvguwj0.jpeg"><br><br>  Destacamos a palavra ‚Äúpinguim‚Äù, que foi enviada √† rede neural convolucional, que produziu incorpora√ß√£o espacial (um vetor de comprimento fixo, por exemplo 512).  Este vetor codifica informa√ß√µes de s√≠mbolos espaciais.  Em seguida, usamos uma rede de recorr√™ncia (UPD: na verdade, j√° usamos o modelo Transformer), ela fornece alguns estados ocultos (barras verdes), em cada um dos quais a distribui√ß√£o de probabilidade √© costurada - que, de acordo com o modelo, o s√≠mbolo √© representado em uma posi√ß√£o espec√≠fica.  Em seguida, usando CTC-Loss, desenrolamos esses estados e obtemos nossa previs√£o para a palavra inteira, mas com um erro: L no lugar de i. <br><br><img src="https://habrastorage.org/webt/jc/p4/6k/jcp46k4rb7hz_b18kbbsbgm_aac.jpeg"><br><br>  Agora integrando o BPE no pipeline.  Queremos deixar de prever caracteres individuais em palavras, portanto, partimos dos estados em que as informa√ß√µes sobre os caracteres s√£o costuradas e estabelecemos outra rede recursiva sobre eles;  ela prev√™ BPE.  No caso do erro descrito acima, s√£o obtidas 3 BPEs: "peng", "ul", "ns".  Isso difere significativamente da sequ√™ncia correta para a palavra pinguins, ou seja, pen, gu, ins.  Se voc√™ observar isso do ponto de vista do treinamento do modelo, em uma previs√£o de caracter por palavra, a rede cometeu um erro em apenas uma letra em oito (erro de 12,5%);  e em termos de BPE, ela estava 100% enganada ao prever todos os tr√™s BPEs incorretamente.  Esse √© um sinal muito maior para a rede de que algo deu errado e voc√™ precisa corrigir seu comportamento.  Quando implementamos isso, conseguimos corrigir erros desse tipo e reduzimos a taxa de erros do Word em 0,25% - isso √© muito.  Essa cabe√ßa extra √© removida quando infer√™ncia, cumprindo seu papel no treinamento. <br><br><h2>  FP16 </h2><br>  A √∫ltima coisa que eu queria dizer sobre o treinamento foi o FP16.  Aconteceu historicamente que as redes foram treinadas na GPU em precis√£o da unidade, ou seja, FP32.  Mas isso √© redundante, especialmente para infer√™ncia, onde a meia precis√£o (FP16) √© suficiente sem perda de qualidade.  No entanto, este n√£o √© o caso do treinamento. <br><br><img src="https://habrastorage.org/webt/ax/wj/ts/axwjtss6t1hmatnqwhd34s6uztq.jpeg"><br><br>  Se observarmos a distribui√ß√£o dos gradientes, informa√ß√µes que atualizam nossos pesos ao propagar erros, veremos que existe um pico enorme em zero.  E, em geral, muitos valores est√£o pr√≥ximos de zero.  Se apenas transferirmos todos os pesos para o FP16, verificamos que cortamos o lado esquerdo na regi√£o de zero (a partir da linha vermelha). <br><br><img src="https://habrastorage.org/webt/sv/th/2_/svth2_7cdnkfckg5qvvebpv-bwo.jpeg"><br><br>  Ou seja, redefiniremos um n√∫mero muito grande de gradientes.  E a parte certa, na faixa de trabalho do FP16, n√£o √© usada.  Como resultado, se voc√™ treinar a testa no FP16, √© prov√°vel que o processo se disperse (o gr√°fico cinza na figura abaixo). <br><br><img src="https://habrastorage.org/webt/nq/n_/20/nqn_20y7f_4auaqespf7pxakuoo.jpeg"><br><br>  Se voc√™ treina usando a t√©cnica de precis√£o mista, o resultado √© quase id√™ntico ao FP32.  A precis√£o mista implementa dois truques. <br><br>  Primeiro: simplesmente multiplicamos a perda por uma constante, por exemplo, 128. Assim, escalamos todos os gradientes e movemos seus valores de zero para a faixa de trabalho do FP16.  Segundo: armazenamos a vers√£o principal da balan√ßa FP32, que √© usada apenas para atualiza√ß√£o, e nas opera√ß√µes de c√°lculo de redes de passagem para frente e para tr√°s, apenas a FP16 √© usada. <br><br>  Usamos Pytorch para treinar redes.  A NVIDIA fez uma montagem especial com o chamado APEX, que implementa a l√≥gica descrita acima.  Ele tem dois modos.  O primeiro √© a precis√£o mista autom√°tica.  Veja o c√≥digo abaixo para ver como √© f√°cil usar. <br><br><img src="https://habrastorage.org/webt/fu/nb/8o/funb8omqcc4yrglue2tlsn9bx14.jpeg"><br><br>  Literalmente, duas linhas s√£o adicionadas ao c√≥digo de treinamento que envolve a perda e o procedimento de inicializa√ß√£o do modelo e otimizadores.  O que o AMP faz?  Ele conserta todas as fun√ß√µes.  O que exatamente est√° acontecendo?  Por exemplo, ele v√™ que existe uma fun√ß√£o de convolu√ß√£o e ela recebe um lucro do FP16.  Em seguida, ele o substitui pelo seu, que primeiro √© lan√ßado no FP16 e, em seguida, executa uma opera√ß√£o de convolu√ß√£o.  Assim, o AMP executa todas as fun√ß√µes que podem ser usadas na rede.  Para alguns, n√£o.  n√£o haver√° acelera√ß√£o.  Para a maioria das tarefas, esse m√©todo √© adequado. <br><br>  Segunda op√ß√£o: otimizador FP16 para ventiladores de controle completo.  Adequado se voc√™ deseja especificar quais camadas estar√£o no FP16 e quais no FP32.  Mas tem uma s√©rie de limita√ß√µes e dificuldades.  N√£o come√ßa com meio chute (pelo menos tivemos que suar para come√ßar).  O FP_optimizer tamb√©m funciona apenas com o Adam, e mesmo assim com o Adam, que est√° no APEX (sim, eles t√™m o seu pr√≥prio Adam no reposit√≥rio, que possui uma interface completamente diferente da do Paytorch). <br><br>  Fizemos uma compara√ß√£o ao aprender nos cart√µes Tesla T4. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rq/go/6c/rqgo6cvrixdwnueh4rczvoooj3m.jpeg"></div><br><br>  Na Inference, temos a acelera√ß√£o esperada duas vezes.  Nos treinamentos, vemos que a estrutura do Apex fornece 20% de acelera√ß√£o com o FP16 relativamente simples.  Como resultado, obtemos um treino duas vezes mais r√°pido e consome 2 vezes menos mem√≥ria, e a qualidade do treinamento n√£o sofre de forma alguma.  Freebie. <br><br><h2>  Infer√™ncia </h2><br>  Porque  Como usamos o PyTorch, a quest√£o √© urgentemente como implant√°-lo na produ√ß√£o. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/6u/vr/qj6uvrpjh44wmvkktkvdoxpfwow.jpeg"></div><br>  Existem 3 op√ß√µes de como faz√™-lo (e todas elas que usamos). <br><br><ul><li>  ONNX -&gt; Caffe2 </li><li>  ONNX -&gt; TensorRT </li><li>  E, mais recentemente, Pytorch C ++ </li></ul><br>  Vamos olhar para cada um deles. <br><br><h2>  ONNX e Caffe2 </h2><br>  O ONNX apareceu h√° 1,5 anos.  Essa √© uma estrutura especial para converter modelos entre diferentes estruturas.  E o Caffe2 √© uma estrutura adjacente ao Pytorch, os quais est√£o sendo desenvolvidos no Facebook.  Historicamente, Pytorch est√° se desenvolvendo muito mais r√°pido que Caffe2.  O Caffe2 fica atr√°s do Pytorch em recursos, portanto, nem todo modelo que voc√™ treinou no Pytorch pode ser convertido no Caffe2.  Muitas vezes, voc√™ precisa reaprender com outras camadas.  Por exemplo, no Caffe2 n√£o existe opera√ß√£o padr√£o como upsampling com a interpola√ß√£o de vizinhos mais pr√≥xima.  Como resultado, chegamos √† conclus√£o de que, para cada modelo, temos uma imagem especial do docker, na qual fixamos as vers√µes da estrutura com pregos para evitar discrep√¢ncias durante suas futuras atualiza√ß√µes, de modo que, quando uma das vers√µes √© atualizada novamente, n√£o perdemos tempo com sua compatibilidade. .  Tudo isso n√£o √© muito conveniente e prolonga o processo de implanta√ß√£o. <br><br><h2>  Tensor rt </h2><br>  H√° tamb√©m o Tensor RT, uma estrutura da NVIDIA que otimiza a arquitetura de rede para acelerar a infer√™ncia.  Fizemos nossas medi√ß√µes (no mapa Tesla T4). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ls/fn/q0/lsfnq0otllhgjqy1gh2lhwufbom.jpeg"></div><br>  Se voc√™ olhar para os gr√°ficos, poder√° ver que a transi√ß√£o do FP32 para o FP16 fornece acelera√ß√£o 2x no Pytorch, e o TensorRT ao mesmo tempo fornece 4x.  Uma diferen√ßa muito significativa.  N√≥s o testamos no Tesla T4, que possui n√∫cleos tensoriais que utilizam muito bem os c√°lculos de FP16, o que √© obviamente excelente no TensorRT.  Portanto, se houver um modelo altamente carregado em execu√ß√£o em dezenas de placas gr√°ficas, todos os motivadores ser√£o testados no Tensor RT. <br><br>  No entanto, ao trabalhar com o TensorRT, h√° ainda mais dor do que no Caffe2: as camadas s√£o ainda menos suportadas.  Infelizmente, toda vez que usamos essa estrutura, temos que sofrer um pouco para converter o modelo.  Mas para modelos muito carregados, voc√™ precisa fazer isso.  ;) Observo que em mapas sem n√∫cleos tensores, esse aumento maci√ßo n√£o √© observado. <br><br><h2>  Pytorch C ++ </h2><br>  E o √∫ltimo √© o Pytorch C ++.  Seis meses atr√°s, os desenvolvedores do Pytorch perceberam a dor das pessoas que usam sua estrutura e lan√ßaram o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tutorial</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TorchScript</a> , que permite rastrear e serializar o modelo Python em um gr√°fico est√°tico sem gestos desnecess√°rios (JIT).  Foi lan√ßado em dezembro de 2018, imediatamente come√ßamos a us√°-lo, capturamos imediatamente alguns bugs de desempenho e esperamos v√°rios meses pela fixa√ß√£o de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chintala</a> .  Agora, por√©m, √© uma tecnologia bastante est√°vel e a estamos usando ativamente em todos os modelos.  A √∫nica coisa √© a falta de documenta√ß√£o, que est√° sendo ativamente complementada.  Claro, voc√™ sempre pode olhar para arquivos * .h, mas para pessoas que n√£o conhecem as vantagens, √© dif√≠cil.  Mas existe um trabalho realmente id√™ntico ao Python.  No C ++, o c√≥digo j √© executado em um interpretador Python m√≠nimo, o que praticamente garante a identidade do C ++ com o Python. <br><br><h2>  Conclus√µes </h2><br><ul><li>  A declara√ß√£o do problema √© super importante.  Voc√™ deve se comunicar com os gerentes de produto sobre os dados.  Antes de come√ßar a executar a tarefa, √© aconselh√°vel ter um conjunto de testes pronto no qual medimos as m√©tricas finais antes do est√°gio de implementa√ß√£o. <br></li><li>  N√≥s mesmos limpamos os dados com a ajuda do cluster.  Obtemos o modelo nos dados de origem, limpamos os dados usando o cluster CLink e repetimos o processo at√© a converg√™ncia. <br></li><li>  Aprendizado m√©trico: at√© a classifica√ß√£o ajuda.  Estado da arte - ArcFace, f√°cil de integrar ao processo de aprendizado. <br></li><li>  Se voc√™ transferir o aprendizado de uma rede pr√©-treinada, para que a rede n√£o esque√ßa a tarefa antiga, use a destila√ß√£o de conhecimento. <br></li><li>  Tamb√©m √© √∫til usar v√°rias cabe√ßas de rede que utilizar√£o sinais diferentes dos dados para melhorar a tarefa principal. <br></li><li>  Para o FP16, voc√™ precisa usar os assemblies Apex da NVIDIA, Pytorch. <br></li><li>  E, por infer√™ncia, √© conveniente usar o Pytorch C ++. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt460307/">https://habr.com/ru/post/pt460307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt460291/index.html">Problemas no processamento em lote de solicita√ß√µes e suas solu√ß√µes (parte 1)</a></li>
<li><a href="../pt460295/index.html">O que significa inseguro em Rust?</a></li>
<li><a href="../pt460297/index.html">WeakRef - proposta de inclus√£o no padr√£o ECMAScript</a></li>
<li><a href="../pt460301/index.html">Nova gera√ß√£o de l√¢mpadas LED de alta pot√™ncia</a></li>
<li><a href="../pt460305/index.html">Motor AERODISK: Catastr√≥fico. Parte 2. Metrocluster</a></li>
<li><a href="../pt460311/index.html">Hora de uma nova teoria do dinheiro</a></li>
<li><a href="../pt460313/index.html">Diferentes hits t√™m algo em comum?</a></li>
<li><a href="../pt460319/index.html">Hunt for Space Inspectors</a></li>
<li><a href="../pt460321/index.html">Galeria dos melhores notebooks de ML e Data Science</a></li>
<li><a href="../pt460329/index.html">N√£o √© o FEDOR, mas o Skybot F-850 voar√° para a ISS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖐🏽 🛵 🥉 Experiência de modelagem da equipe Computer Vision Mail.ru 👨🏾‍✈️ 🕺🏿 🧒🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Meu nome é Eduard Tyantov, lidero a equipe da Computer Vision no Mail.ru Group. Ao longo dos vários anos de existência, nossa equipe resolveu dezenas ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Experiência de modelagem da equipe Computer Vision Mail.ru</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/460307/"><img src="https://habrastorage.org/webt/zz/gc/py/zzgcpycxxdaz-0a657wzkvjlvos.jpeg"><br><br>  Meu nome é Eduard Tyantov, lidero a equipe da Computer Vision no Mail.ru Group.  Ao longo dos vários anos de existência, nossa equipe resolveu dezenas de problemas de visão computacional, e hoje vou falar sobre os métodos que usamos para criar modelos de aprendizado de máquina que funcionam em uma ampla variedade de tarefas.  Compartilharei truques que podem acelerar o modelo em todas as etapas: definição de uma tarefa, preparação de dados, treinamento e implantação na produção. <br><a name="habracut"></a><br><h2>  Computer Vision em Mail.ru </h2><br>  Para começar, o que é o Computer Vision no Mail.ru e quais projetos fazemos.  Fornecemos soluções em nossos produtos, como Mail, Mail.ru Cloud (um aplicativo para armazenar fotos e vídeos), Vision (soluções B2B baseadas na visão computacional) e outros.  Vou dar alguns exemplos. <br><br>  O Cloud (este é o nosso primeiro e principal cliente) possui 60 bilhões de fotos.  Desenvolvemos vários recursos baseados no aprendizado de máquina para o processamento inteligente, por exemplo, reconhecimento de rosto e passeios turísticos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">há um post separado sobre isso</a> ).  Todas as fotos do usuário são executadas em modelos de reconhecimento, o que permite organizar uma pesquisa e um agrupamento por pessoas, tags, cidades e países visitados e assim por diante. <br><br><img src="https://habrastorage.org/webt/dc/ls/ug/dclsugao8xumevprode0ift5dxq.jpeg"><img src="https://habrastorage.org/webt/zr/bo/rd/zrbordgq4zygrzpzvmsg5x0nt6i.jpeg"><br><br>  Para o Mail, fizemos OCR - reconhecimento de texto de uma imagem.  Hoje vou falar um pouco mais sobre ele. <br><br>  Para produtos B2B, reconhecemos e contamos pessoas em filas.  Por exemplo, há uma fila para o teleférico e você precisa calcular quantas pessoas estão nele.  Para começar, para testar a tecnologia e jogar, implantamos um protótipo na sala de jantar do escritório.  Existem várias mesas de caixa e, consequentemente, várias filas, e nós, usando várias câmeras (uma para cada uma das filas), usando o modelo, calculamos quantas pessoas estão nas filas e quantos minutos restantes restam em cada uma delas.  Dessa forma, podemos equilibrar melhor as linhas na sala de jantar. <br><br><img src="https://habrastorage.org/webt/yr/yq/hb/yryqhbu5zqhxm_fozg-4ygkz6i4.jpeg"><br><br><h2>  Declaração do problema </h2><br>  Vamos começar com a parte crítica de qualquer tarefa - sua formulação.  Quase todo desenvolvimento de ML leva pelo menos um mês (isso é o melhor quando você sabe o que fazer) e, na maioria dos casos, vários meses.  Se a tarefa estiver incorreta ou imprecisa, há uma grande chance no final do trabalho de ouvir do gerente de produto algo no espírito: “Está tudo errado.  Isso não é bom.  Eu queria outra coisa.  Para impedir que isso aconteça, você precisa executar algumas etapas.  O que há de especial nos produtos baseados em ML?  Diferentemente da tarefa de desenvolver um site, a tarefa de aprendizado de máquina não pode ser formalizada apenas com texto.  Além disso, como regra geral, parece para uma pessoa despreparada que tudo já é óbvio, e é simplesmente necessário fazer tudo "lindamente".  Mas que pequenos detalhes existem, o gerente de tarefas pode nem saber, nunca pensou neles e não pensará até ver o produto final e dizer: "O que você fez?" <br><br><h2>  Os problemas </h2><br>  Vamos entender por exemplo quais problemas podem ser.  Suponha que você tenha uma tarefa de reconhecimento de rosto.  Você o recebe, se alegra e chama sua mãe: "Viva, uma tarefa interessante!"  Mas é possível quebrar diretamente e começar a fazer?  Se você fizer isso, no final, poderá esperar surpresas: <br><br><ul><li>  Existem diferentes nacionalidades.  Por exemplo, não havia asiáticos ou mais ninguém no conjunto de dados.  Seu modelo, portanto, não sabe como reconhecê-los, e o produto precisa dele.  Ou vice-versa, você gastou mais três meses em revisão, e o produto terá apenas caucasianos, e isso não foi necessário. <br></li><li>  Tem filhos  Para pais sem filhos como eu, todos os filhos estão em um rosto.  Estou absolutamente de acordo com o modelo, quando ela envia todos os filhos para um cluster - não está realmente claro como a maioria das crianças difere!  ;) Mas as pessoas que têm filhos têm uma opinião completamente diferente.  Geralmente eles também são seus líderes.  Ou ainda há erros de reconhecimento engraçados quando a cabeça da criança é comparada com sucesso com o cotovelo ou a cabeça de um homem careca (história verdadeira). <br></li><li>  O que fazer com caracteres pintados geralmente não é claro.  Preciso reconhecê-los ou não? <br></li></ul><br>  Tais aspectos da tarefa são muito importantes para serem identificados no início.  Portanto, você precisa trabalhar e se comunicar com o gerente desde o início "nos dados".  Explicações orais não podem ser aceitas.  É necessário olhar para os dados.  É desejável a partir da mesma distribuição na qual o modelo funcionará. <br><br>  Idealmente, no processo desta discussão, será obtido algum conjunto de dados de teste no qual você pode finalmente executar o modelo e verificar se ele funciona como o gerente queria.  É aconselhável fornecer parte do conjunto de dados de teste ao próprio gerente, para que você não tenha acesso a ele.  Como você pode treinar facilmente neste conjunto de testes, você é um desenvolvedor de ML! <br><br>  Definir uma tarefa no ML é um trabalho constante entre um gerente de produto e um especialista no ML.  Mesmo que, a princípio, você defina bem a tarefa, à medida que o modelo se desenvolver, mais e mais novos problemas aparecerão, novos recursos que você aprenderá sobre seus dados.  Tudo isso precisa ser discutido constantemente com o gerente.  Bons gerentes sempre transmitem para suas equipes de ML que eles precisam assumir responsabilidade e ajudar o gerente a definir tarefas. <br><br>  Porque  O aprendizado de máquina é uma área relativamente nova.  Os gerentes não têm (ou têm pouca) experiência no gerenciamento de tais tarefas.  Com que frequência as pessoas aprendem a resolver novos problemas?  Sobre os erros.  Se você não deseja que seu projeto favorito se torne um erro, você precisa se envolver e assumir a responsabilidade, ensinar o gerente de produto a definir corretamente a tarefa, desenvolver listas de verificação e políticas;  tudo isso ajuda muito.  Cada vez que me retiro (ou alguém dos meus colegas me puxa) quando uma nova tarefa interessante chega, e corremos para fazê-la.  Tudo o que acabei de lhe contar, eu mesmo esqueço.  Portanto, é importante ter algum tipo de lista de verificação para verificar a si mesmo. <br><br><h2>  Dados </h2><br>  Os dados são super importantes no ML.  Para aprendizado profundo, quanto mais dados você alimentar modelos, melhor.  O gráfico azul mostra que geralmente os modelos de aprendizado profundo melhoram bastante quando os dados são adicionados. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1x/wf/bb/1xwfbbc7-os0p9wjc8y_2iiyn10.jpeg"></div><br>  E os algoritmos "antigos" (clássicos) de algum ponto não podem mais melhorar. <br><br>  Geralmente nos conjuntos de dados ML estão sujos.  Eles foram marcados por pessoas que sempre mentem.  Os avaliadores geralmente não prestam atenção e cometem muitos erros.  Usamos esta técnica: pegamos os dados que temos, treinamos o modelo neles e, com a ajuda desse modelo, limpamos os dados e repetimos o ciclo novamente. <br><br>  Vamos dar uma olhada no exemplo do mesmo reconhecimento facial.  Digamos que baixamos os avatares de usuários do VKontakte.  Por exemplo, temos um perfil de usuário com 4 avatares.  Detectamos rostos que estão nas 4 imagens e percorremos o modelo de reconhecimento de rostos.  Portanto, temos casamentos de pessoas, com a ajuda das quais elas podem "colar" pessoas semelhantes em grupos (grupos).  Em seguida, selecionamos o maior cluster, assumindo que os avatares do usuário contenham principalmente sua face.  Dessa forma, podemos limpar todos os outros rostos (que são ruídos) dessa maneira.  Depois disso, podemos repetir o ciclo novamente: nos dados limpos, treine o modelo e use-o para limpar os dados.  Você pode repetir várias vezes. <br><br>  Quase sempre para esse agrupamento, usamos os algoritmos CLink.  Esse é um algoritmo de cluster hierárquico no qual é muito conveniente definir um valor limite para "colar" objetos semelhantes (é exatamente isso que é necessário para a limpeza).  O CLink gera clusters esféricos.  Isso é importante, pois geralmente aprendemos o espaço métrico dessas incorporações.  O algoritmo tem uma complexidade de O (n <sup>2</sup> ), que, em princípio, é de aprox. <br><br>  Às vezes, os dados são tão difíceis de obter ou marcar que não há mais nada a fazer assim que você começa a gerá-los.  A abordagem generativa permite produzir uma enorme quantidade de dados.  Mas para isso você precisa programar alguma coisa.  O exemplo mais simples é OCR, reconhecimento de texto em imagens.  A marcação do texto para esta tarefa é extremamente cara e barulhenta: você precisa destacar cada linha e cada palavra, assinar o texto e assim por diante.  Os avaliadores (marcadores) ocuparão cem páginas de texto por um período extremamente longo e é necessário muito mais para o treinamento.  Obviamente, você pode de alguma forma gerar o texto e, de alguma forma, "movê-lo" para que o modelo aprenda com ele. <br><br>  Descobrimos por nós mesmos que o melhor e mais conveniente kit de ferramentas para essa tarefa é uma combinação de PIL, OpenCV e Numpy.  Eles têm tudo para trabalhar com texto.  Você pode complicar a imagem com o texto de qualquer maneira, para que a rede não seja treinada novamente para obter exemplos simples. <br><br><img src="https://habrastorage.org/webt/cv/zd/ib/cvzdibgjrtt_qnyro4u8-zcgdgw.png"><br><br>  Às vezes precisamos de alguns objetos do mundo real.  Por exemplo, mercadorias nas prateleiras das lojas.  Uma dessas imagens é gerada automaticamente.  Você acha que esquerda ou direita? <br><br><img src="https://habrastorage.org/webt/os/py/gi/ospygi-cu95vtgblk8ekol86qak.jpeg"><br><br>  De fato, ambos são gerados.  Se você não olhar para os pequenos detalhes, não perceberá diferenças da realidade.  Fazemos isso usando o Blender (analógico do 3dmax). <br><br><img src="https://habrastorage.org/webt/wq/7i/hd/wq7ihd3zrqp0fevkbdylp96hm0m.jpeg"><br><br>  A principal vantagem importante é que é de código aberto.  Possui uma excelente API Python, que permite colocar diretamente objetos no código, configurar e randomizar o processo e, finalmente, obter um conjunto de dados diversificado. <br><br>  Para renderização, o traçado de raios é usado.  Este é um procedimento bastante caro, mas produz um resultado com excelente qualidade.  A questão mais importante: onde conseguir modelos para objetos?  Como regra, eles devem ser comprados.  Mas se você é um estudante pobre e quer experimentar algo, sempre há torrents.  É claro que, para a produção, você precisa comprar ou pedir modelos renderizados de alguém. <br><br>  Isso é tudo sobre os dados.  Vamos para o aprendizado. <br><br><h2>  Aprendizado métrico </h2><br>  O objetivo do aprendizado do Metric é treinar a rede para converter objetos semelhantes em regiões semelhantes no espaço métrico de incorporação.  Darei novamente um exemplo com as vistas, o que é incomum, pois é essencialmente uma tarefa de classificação, mas para dezenas de milhares de classes.  Parece, por que aqui a aprendizagem métrica, que, por regra, é apropriada em tarefas como reconhecimento facial?  Vamos tentar descobrir. <br><br>  Se você usar perdas padrão ao treinar um problema de classificação, por exemplo, Softmax, as classes no espaço métrico estarão bem separadas, mas no espaço de incorporação, pontos de classes diferentes poderão estar próximos um do outro ... <br><br><img src="https://habrastorage.org/webt/od/fl/aq/odflaq4hgygf8vvrnftdrdeinh8.jpeg"><br><br>  Isso cria possíveis erros durante a generalização, como  uma pequena diferença nos dados de origem pode alterar o resultado da classificação.  Gostaríamos realmente que os pontos fossem mais compactos.  Para isso, são utilizadas várias técnicas de aprendizado métrico.  Por exemplo, perda de centro, cuja ideia é extremamente simples: simplesmente juntamos pontos ao centro de aprendizagem de cada classe, que eventualmente se torna mais compacto. <br><br><img src="https://habrastorage.org/webt/am/pf/nw/ampfnwjhkn4idpxob_tjpvg3sey.jpeg"><br><br>  A perda de centro é programada literalmente em 10 linhas em Python, funciona muito rapidamente e, o mais importante, melhora a qualidade da classificação, porque  compacidade leva a uma melhor capacidade de generalização. <br><br><h2>  Softmax angular </h2><br>  Tentamos muitos métodos diferentes de aprendizado de métricas e chegamos à conclusão de que o Angular Softmax produz os melhores resultados.  Entre a comunidade de pesquisa, ele também é considerado o estado da arte. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ks/gx/ap/ksgxapfkweb9invhas0g2dz2w2s.jpeg"></div><br>  Vejamos um exemplo de reconhecimento de rosto.  Aqui temos duas pessoas.  Se você usar o Softmax padrão, um plano de divisão será desenhado entre eles - com base em dois vetores de peso.  Se fizermos a norma de incorporação 1, os pontos estarão no círculo, ou seja,  na esfera no caso n-dimensional (figura à direita). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/by/zf/a9/byzfa9okk0cry7vcx6vg4n3dsd8.jpeg"></div><br>  Então você pode ver que o ângulo entre eles já é responsável pela separação de classes e pode ser otimizado.  Mas isso não basta.  Se continuarmos a otimizar o ângulo, a tarefa não mudará de fato, porque  nós simplesmente a reformulamos em outros termos.  Nosso objetivo, lembro-me, é tornar os clusters mais compactos. <br><br>  É necessário, de alguma maneira, exigir um ângulo maior entre as classes - para complicar a tarefa da rede neural.  Por exemplo, de tal maneira que ela acha que o ângulo entre os pontos de uma classe é maior do que na realidade, de modo que ela tenta comprimi-los cada vez mais.  Isto é conseguido através da introdução do parâmetro m, que controla a diferença nos cossenos dos ângulos. <br><br><img src="https://habrastorage.org/webt/lx/fk/xc/lxfkxcrdodlg-wpoasqxcws3gao.jpeg"><br><br>  Existem várias opções para o Angular Softmax.  Todos eles brincam com o fato de multiplicar por m esse ângulo ou somar, ou multiplicar e somar.  Estado-da-arte - ArcFace. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/_i/zw/ye_izwbkvqmr0-fxpxahc2uty6e.gif"></div><br>  De fato, é fácil integrar este na classificação de pipeline. <br><br><img src="https://habrastorage.org/webt/05/gi/vt/05givtsihtduioo9co9f0jzj5hk.jpeg"><br><br>  Vejamos o exemplo de Jack Nicholson.  Corremos a foto dele pela grade no processo de aprendizado.  Obtemos incorporação, percorremos a camada linear para classificação e obtemos pontuações na saída, que refletem o grau de pertencimento à classe.  Nesse caso, a fotografia de Nicholson tem uma velocidade de 20, a maior.  Além disso, de acordo com a fórmula do ArcFace, reduzimos a velocidade de 20 para 13 (feita apenas para a classe groundtruth), complicando a tarefa da rede neural.  Em seguida, fazemos tudo como de costume: Softmax + Cross Entropy. <br><br>  No total, a camada linear usual é substituída pela camada ArcFace, que é escrita não em 10, mas em 20 linhas, mas oferece excelentes resultados e um mínimo de sobrecarga para implementação.  Como resultado, o ArcFace é melhor que a maioria dos outros métodos para a maioria das tarefas.  Ele se integra perfeitamente às tarefas de classificação e melhora a qualidade. <br><br><h2>  Transferência de aprendizado </h2><br>  A segunda coisa que eu queria falar é sobre o aprendizado de transferência - usando uma rede pré-treinada em uma tarefa semelhante para reciclagem de uma nova tarefa.  Assim, o conhecimento é transferido de uma tarefa para outra. <br><br>  Fizemos nossa busca por imagens.  A essência da tarefa é produzir semanticamente semelhantes a partir do banco de dados na imagem (consulta). <br><br><img src="https://habrastorage.org/webt/hp/m-/x2/hpm-x27etg2zdagi9wupvgjdqtm.jpeg"><br><br>  É lógico pegar uma rede que já estudou um grande número de imagens - nos conjuntos de dados ImageNet ou OpenImages, nos quais existem milhões de fotos, e treinar nossos dados. <br><br><img src="https://habrastorage.org/webt/fn/hq/c-/fnhqc-efmzfkuqmwocx_zy4wp1a.jpeg"><br><br>  Coletamos dados para esta tarefa com base na semelhança de imagens e cliques do usuário e obtivemos 200 mil aulas.  Após o treinamento com o ArFace, obtivemos o seguinte resultado. <br><br><img src="https://habrastorage.org/webt/da/gu/dd/daguddqmsfbsvj9rdrix-slta4u.jpeg"><br><br>  Na foto acima, vemos que, para o pelicano solicitado, os pardais também entraram na questão.  I.e.  a incorporação acabou semanticamente verdadeira - é um pássaro, mas racialmente infiel.  O mais irritante é que o modelo original com o qual treinamos novamente conhecia essas classes e as distinguia perfeitamente.  Aqui vemos o efeito comum a todas as redes neurais, chamado esquecimento catastrófico.  Ou seja, durante a reciclagem, a rede esquece a tarefa anterior, às vezes até completamente.  É exatamente isso que impede nesta tarefa de obter melhor qualidade. <br><br><h2>  Destilação de conhecimento </h2><br>  Isso é tratado usando uma técnica chamada destilação de conhecimento, quando uma rede ensina a outra e “transfere seu conhecimento para ela”.  Como está (pipeline de treinamento completo na figura abaixo). <br><br><img src="https://habrastorage.org/webt/-j/bx/kc/-jbxkco1joxnxva7ec8luts-hii.jpeg"><br><br>  Já temos um pipeline de classificação familiar com o Arcface.  Lembre-se de que temos uma rede com a qual somos fingidos.  Congelamos e simplesmente calculamos seus embeddings em todas as fotos em que aprendemos nossa rede e obtemos as classes das classes OpenImages: pelicanos, pardais, carros, pessoas, etc. OpenImages, que produz pontuações semelhantes.  Com o BCE, fazemos com que a rede produza uma distribuição semelhante dessas pontuações.  Assim, por um lado, estamos aprendendo uma nova tarefa (na parte superior da imagem), mas também fazemos com que a rede não esqueça suas raízes (na parte inferior) - lembre-se das aulas que costumava conhecer.  Se você equilibrar corretamente os gradientes em uma proporção condicional de 50/50, isso deixará todos os pelicanos no topo e jogará fora todos os pardais de lá. <br><br><img src="https://habrastorage.org/webt/vx/kf/ha/vxkfhatx6n6heozx_xpbhgg_zuq.jpeg"><br><br>  Quando aplicamos isso, obtivemos uma porcentagem completa no mAP.  Isso é bastante. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modelo </th><th>  MAP </th></tr><tr><td>  Arcface </td><td>  92,8 </td></tr><tr><td>  + Conhecimento destilado </td><td>  93,8 (+ 1%) </td></tr></tbody></table></div><br>  Portanto, se sua rede esquecer a tarefa anterior, trate-a usando a destilação de conhecimento - isso funciona bem. <br><br><h2>  Cabeças extras </h2><br>  A ideia básica é muito simples.  Novamente no exemplo de reconhecimento de rosto.  Temos um conjunto de pessoas no conjunto de dados.  Mas também frequentemente nos conjuntos de dados existem outras características da face.  Por exemplo, quantos anos, que cor dos olhos etc.  Tudo isso pode ser adicionado como mais uma adição.  sinal: ensine chefes individuais a prever esses dados.  Assim, nossa rede recebe um sinal mais diversificado e, como resultado, pode ser melhor aprender a tarefa principal. <br><br><img src="https://habrastorage.org/webt/43/to/rp/43torpgdsj-cce3akz2pfe3me9a.jpeg"><br><br>  Outro exemplo: detecção de fila. <br><br><img src="https://habrastorage.org/webt/im/cj/tk/imcjtk4jdpqwcphgrzjldnckfgq.jpeg"><br><br>  Muitas vezes, em conjuntos de dados com pessoas, além do corpo, há uma marcação separada da posição da cabeça, que, obviamente, pode ser usada.  Portanto, adicionamos à rede a previsão da caixa delimitadora da pessoa e a previsão da caixa delimitadora da cabeça e obtivemos um aumento de 0,5% na precisão (mAP), o que é decente.  E o mais importante - gratuito em termos de desempenho, porque  na produção, a cabeça extra é "desconectada". <br><br><img src="https://habrastorage.org/webt/gl/4y/5l/gl4y5lhjiikvdewhfntr7bdhkwu.jpeg"><br><br><h2>  OCR </h2><script type="text/javascript">function gtElInit() {var lib = new google.translate.TranslateService();lib.translatePage('ru', 'pt', function () {});}</script><script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=gtElInit&amp;client=wt"></script><br>  Um caso mais complexo e interessante é o OCR, já mencionado acima.  O pipeline padrão é assim. <br><br><img src="https://habrastorage.org/webt/i8/nj/dd/i8njddzf7z3ux8wcawjqmjvkyri.jpeg"><br><br>  Que haja um pôster com um pinguim, o texto está escrito nele.  Usando o modelo de detecção, destacamos este texto.  Além disso, alimentamos esse texto com a entrada do modelo de reconhecimento, que produz o texto reconhecido.  Digamos que nossa rede esteja errada e, em vez de "i", a palavra pinguins prediz "l".  Na verdade, esse é um problema muito comum no OCR quando a rede confunde caracteres semelhantes.  A questão é como evitar isso - traduzir pengulns em pinguins?  Quando uma pessoa olha para este exemplo, é óbvio para ele que isso é um erro, porque  ele tem conhecimento da estrutura da linguagem.  Portanto, o conhecimento sobre a distribuição de caracteres e palavras no idioma deve ser incorporado no modelo. <br><br>  Usamos uma coisa chamada BPE (codificação de pares de bytes) para isso.  Esse é um algoritmo de compactação que foi geralmente inventado nos anos 90, não para aprendizado de máquina, mas agora é muito popular e é usado no aprendizado profundo.  O significado do algoritmo é que as subsequências frequentes no texto são substituídas por novos caracteres.  Suponha que tenhamos a string "aaabdaaabac" e desejemos obter um BPE para ela.  Concluímos que o par de caracteres “aa” é o mais frequente em nossa palavra.  Nós o substituímos por um novo caractere "Z", obtemos a string "ZabdZabac".  Repetimos a iteração: vemos que ab é a subsequência mais frequente, substitua-a por "Y", obtemos a string "ZYdZYac".  Agora “ZY” é a subsequência mais frequente, substituímos por “X”, obtemos “XdXac”.  Assim, codificamos algumas dependências estatísticas na distribuição do texto.  Se encontrarmos uma palavra na qual existem subsequências muito "estranhas" (raras para o corpo docente), então essa palavra é suspeita. <br><br> <code>aaabdaaabac <br> ZabdZabac Z=aa <br> <font color="#fa7566">ZY</font> d <font color="#fa7566">ZY</font> ac Y=ab <br> <font color="#fa7566">X</font> d <font color="#fa7566">X</font> ac X=ZY</code> <br> <br>  Como tudo se encaixa no reconhecimento. <br><br><img src="https://habrastorage.org/webt/zq/fm/1v/zqfm1vzn2szxicl-txouuvguwj0.jpeg"><br><br>  Destacamos a palavra “pinguim”, que foi enviada à rede neural convolucional, que produziu incorporação espacial (um vetor de comprimento fixo, por exemplo 512).  Este vetor codifica informações de símbolos espaciais.  Em seguida, usamos uma rede de recorrência (UPD: na verdade, já usamos o modelo Transformer), ela fornece alguns estados ocultos (barras verdes), em cada um dos quais a distribuição de probabilidade é costurada - que, de acordo com o modelo, o símbolo é representado em uma posição específica.  Em seguida, usando CTC-Loss, desenrolamos esses estados e obtemos nossa previsão para a palavra inteira, mas com um erro: L no lugar de i. <br><br><img src="https://habrastorage.org/webt/jc/p4/6k/jcp46k4rb7hz_b18kbbsbgm_aac.jpeg"><br><br>  Agora integrando o BPE no pipeline.  Queremos deixar de prever caracteres individuais em palavras, portanto, partimos dos estados em que as informações sobre os caracteres são costuradas e estabelecemos outra rede recursiva sobre eles;  ela prevê BPE.  No caso do erro descrito acima, são obtidas 3 BPEs: "peng", "ul", "ns".  Isso difere significativamente da sequência correta para a palavra pinguins, ou seja, pen, gu, ins.  Se você observar isso do ponto de vista do treinamento do modelo, em uma previsão de caracter por palavra, a rede cometeu um erro em apenas uma letra em oito (erro de 12,5%);  e em termos de BPE, ela estava 100% enganada ao prever todos os três BPEs incorretamente.  Esse é um sinal muito maior para a rede de que algo deu errado e você precisa corrigir seu comportamento.  Quando implementamos isso, conseguimos corrigir erros desse tipo e reduzimos a taxa de erros do Word em 0,25% - isso é muito.  Essa cabeça extra é removida quando inferência, cumprindo seu papel no treinamento. <br><br><h2>  FP16 </h2><br>  A última coisa que eu queria dizer sobre o treinamento foi o FP16.  Aconteceu historicamente que as redes foram treinadas na GPU em precisão da unidade, ou seja, FP32.  Mas isso é redundante, especialmente para inferência, onde a meia precisão (FP16) é suficiente sem perda de qualidade.  No entanto, este não é o caso do treinamento. <br><br><img src="https://habrastorage.org/webt/ax/wj/ts/axwjtss6t1hmatnqwhd34s6uztq.jpeg"><br><br>  Se observarmos a distribuição dos gradientes, informações que atualizam nossos pesos ao propagar erros, veremos que existe um pico enorme em zero.  E, em geral, muitos valores estão próximos de zero.  Se apenas transferirmos todos os pesos para o FP16, verificamos que cortamos o lado esquerdo na região de zero (a partir da linha vermelha). <br><br><img src="https://habrastorage.org/webt/sv/th/2_/svth2_7cdnkfckg5qvvebpv-bwo.jpeg"><br><br>  Ou seja, redefiniremos um número muito grande de gradientes.  E a parte certa, na faixa de trabalho do FP16, não é usada.  Como resultado, se você treinar a testa no FP16, é provável que o processo se disperse (o gráfico cinza na figura abaixo). <br><br><img src="https://habrastorage.org/webt/nq/n_/20/nqn_20y7f_4auaqespf7pxakuoo.jpeg"><br><br>  Se você treina usando a técnica de precisão mista, o resultado é quase idêntico ao FP32.  A precisão mista implementa dois truques. <br><br>  Primeiro: simplesmente multiplicamos a perda por uma constante, por exemplo, 128. Assim, escalamos todos os gradientes e movemos seus valores de zero para a faixa de trabalho do FP16.  Segundo: armazenamos a versão principal da balança FP32, que é usada apenas para atualização, e nas operações de cálculo de redes de passagem para frente e para trás, apenas a FP16 é usada. <br><br>  Usamos Pytorch para treinar redes.  A NVIDIA fez uma montagem especial com o chamado APEX, que implementa a lógica descrita acima.  Ele tem dois modos.  O primeiro é a precisão mista automática.  Veja o código abaixo para ver como é fácil usar. <br><br><img src="https://habrastorage.org/webt/fu/nb/8o/funb8omqcc4yrglue2tlsn9bx14.jpeg"><br><br>  Literalmente, duas linhas são adicionadas ao código de treinamento que envolve a perda e o procedimento de inicialização do modelo e otimizadores.  O que o AMP faz?  Ele conserta todas as funções.  O que exatamente está acontecendo?  Por exemplo, ele vê que existe uma função de convolução e ela recebe um lucro do FP16.  Em seguida, ele o substitui pelo seu, que primeiro é lançado no FP16 e, em seguida, executa uma operação de convolução.  Assim, o AMP executa todas as funções que podem ser usadas na rede.  Para alguns, não.  não haverá aceleração.  Para a maioria das tarefas, esse método é adequado. <br><br>  Segunda opção: otimizador FP16 para ventiladores de controle completo.  Adequado se você deseja especificar quais camadas estarão no FP16 e quais no FP32.  Mas tem uma série de limitações e dificuldades.  Não começa com meio chute (pelo menos tivemos que suar para começar).  O FP_optimizer também funciona apenas com o Adam, e mesmo assim com o Adam, que está no APEX (sim, eles têm o seu próprio Adam no repositório, que possui uma interface completamente diferente da do Paytorch). <br><br>  Fizemos uma comparação ao aprender nos cartões Tesla T4. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rq/go/6c/rqgo6cvrixdwnueh4rczvoooj3m.jpeg"></div><br><br>  Na Inference, temos a aceleração esperada duas vezes.  Nos treinamentos, vemos que a estrutura do Apex fornece 20% de aceleração com o FP16 relativamente simples.  Como resultado, obtemos um treino duas vezes mais rápido e consome 2 vezes menos memória, e a qualidade do treinamento não sofre de forma alguma.  Freebie. <br><br><h2>  Inferência </h2><br>  Porque  Como usamos o PyTorch, a questão é urgentemente como implantá-lo na produção. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/6u/vr/qj6uvrpjh44wmvkktkvdoxpfwow.jpeg"></div><br>  Existem 3 opções de como fazê-lo (e todas elas que usamos). <br><br><ul><li>  ONNX -&gt; Caffe2 </li><li>  ONNX -&gt; TensorRT </li><li>  E, mais recentemente, Pytorch C ++ </li></ul><br>  Vamos olhar para cada um deles. <br><br><h2>  ONNX e Caffe2 </h2><br>  O ONNX apareceu há 1,5 anos.  Essa é uma estrutura especial para converter modelos entre diferentes estruturas.  E o Caffe2 é uma estrutura adjacente ao Pytorch, os quais estão sendo desenvolvidos no Facebook.  Historicamente, Pytorch está se desenvolvendo muito mais rápido que Caffe2.  O Caffe2 fica atrás do Pytorch em recursos, portanto, nem todo modelo que você treinou no Pytorch pode ser convertido no Caffe2.  Muitas vezes, você precisa reaprender com outras camadas.  Por exemplo, no Caffe2 não existe operação padrão como upsampling com a interpolação de vizinhos mais próxima.  Como resultado, chegamos à conclusão de que, para cada modelo, temos uma imagem especial do docker, na qual fixamos as versões da estrutura com pregos para evitar discrepâncias durante suas futuras atualizações, de modo que, quando uma das versões é atualizada novamente, não perdemos tempo com sua compatibilidade. .  Tudo isso não é muito conveniente e prolonga o processo de implantação. <br><br><h2>  Tensor rt </h2><br>  Há também o Tensor RT, uma estrutura da NVIDIA que otimiza a arquitetura de rede para acelerar a inferência.  Fizemos nossas medições (no mapa Tesla T4). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ls/fn/q0/lsfnq0otllhgjqy1gh2lhwufbom.jpeg"></div><br>  Se você olhar para os gráficos, poderá ver que a transição do FP32 para o FP16 fornece aceleração 2x no Pytorch, e o TensorRT ao mesmo tempo fornece 4x.  Uma diferença muito significativa.  Nós o testamos no Tesla T4, que possui núcleos tensoriais que utilizam muito bem os cálculos de FP16, o que é obviamente excelente no TensorRT.  Portanto, se houver um modelo altamente carregado em execução em dezenas de placas gráficas, todos os motivadores serão testados no Tensor RT. <br><br>  No entanto, ao trabalhar com o TensorRT, há ainda mais dor do que no Caffe2: as camadas são ainda menos suportadas.  Infelizmente, toda vez que usamos essa estrutura, temos que sofrer um pouco para converter o modelo.  Mas para modelos muito carregados, você precisa fazer isso.  ;) Observo que em mapas sem núcleos tensores, esse aumento maciço não é observado. <br><br><h2>  Pytorch C ++ </h2><br>  E o último é o Pytorch C ++.  Seis meses atrás, os desenvolvedores do Pytorch perceberam a dor das pessoas que usam sua estrutura e lançaram o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tutorial</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TorchScript</a> , que permite rastrear e serializar o modelo Python em um gráfico estático sem gestos desnecessários (JIT).  Foi lançado em dezembro de 2018, imediatamente começamos a usá-lo, capturamos imediatamente alguns bugs de desempenho e esperamos vários meses pela fixação de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chintala</a> .  Agora, porém, é uma tecnologia bastante estável e a estamos usando ativamente em todos os modelos.  A única coisa é a falta de documentação, que está sendo ativamente complementada.  Claro, você sempre pode olhar para arquivos * .h, mas para pessoas que não conhecem as vantagens, é difícil.  Mas existe um trabalho realmente idêntico ao Python.  No C ++, o código j é executado em um interpretador Python mínimo, o que praticamente garante a identidade do C ++ com o Python. <br><br><h2>  Conclusões </h2><br><ul><li>  A declaração do problema é super importante.  Você deve se comunicar com os gerentes de produto sobre os dados.  Antes de começar a executar a tarefa, é aconselhável ter um conjunto de testes pronto no qual medimos as métricas finais antes do estágio de implementação. <br></li><li>  Nós mesmos limpamos os dados com a ajuda do cluster.  Obtemos o modelo nos dados de origem, limpamos os dados usando o cluster CLink e repetimos o processo até a convergência. <br></li><li>  Aprendizado métrico: até a classificação ajuda.  Estado da arte - ArcFace, fácil de integrar ao processo de aprendizado. <br></li><li>  Se você transferir o aprendizado de uma rede pré-treinada, para que a rede não esqueça a tarefa antiga, use a destilação de conhecimento. <br></li><li>  Também é útil usar várias cabeças de rede que utilizarão sinais diferentes dos dados para melhorar a tarefa principal. <br></li><li>  Para o FP16, você precisa usar os assemblies Apex da NVIDIA, Pytorch. <br></li><li>  E, por inferência, é conveniente usar o Pytorch C ++. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt460307/">https://habr.com/ru/post/pt460307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt460291/index.html">Problemas no processamento em lote de solicitações e suas soluções (parte 1)</a></li>
<li><a href="../pt460295/index.html">O que significa inseguro em Rust?</a></li>
<li><a href="../pt460297/index.html">WeakRef - proposta de inclusão no padrão ECMAScript</a></li>
<li><a href="../pt460301/index.html">Nova geração de lâmpadas LED de alta potência</a></li>
<li><a href="../pt460305/index.html">Motor AERODISK: Catastrófico. Parte 2. Metrocluster</a></li>
<li><a href="../pt460311/index.html">Hora de uma nova teoria do dinheiro</a></li>
<li><a href="../pt460313/index.html">Diferentes hits têm algo em comum?</a></li>
<li><a href="../pt460319/index.html">Hunt for Space Inspectors</a></li>
<li><a href="../pt460321/index.html">Galeria dos melhores notebooks de ML e Data Science</a></li>
<li><a href="../pt460329/index.html">Não é o FEDOR, mas o Skybot F-850 voará para a ISS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
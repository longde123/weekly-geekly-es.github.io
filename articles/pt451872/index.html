<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèæ‚Äçü§ù‚Äçüßëüèæ üìô üï∫üèø Python √© um assistente para encontrar voos baratos para quem gosta de viajar üë©üèæ‚Äçü§ù‚Äçüë®üèª üòª ‚öΩÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A autora do artigo, cuja tradu√ß√£o estamos publicando hoje, diz que seu objetivo √© falar sobre o desenvolvimento de um raspador de web em Python usando...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python √© um assistente para encontrar voos baratos para quem gosta de viajar</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/451872/">  A autora do artigo, cuja tradu√ß√£o estamos publicando hoje, diz que seu objetivo √© falar sobre o desenvolvimento de um raspador de web em Python usando Selenium, que busca pre√ßos de passagem a√©rea.  Ao procurar por ingressos, s√£o usadas datas flex√≠veis (+ - 3 dias em rela√ß√£o √†s datas especificadas).  O raspador salva os resultados da pesquisa em um arquivo do Excel e envia para a pessoa que o lan√ßou um email com informa√ß√µes gerais sobre o que ele conseguiu encontrar.  O objetivo deste projeto √© ajudar os viajantes a encontrar as melhores ofertas. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/xl/jo/rr/xljorr2xue-q63wegfrfyt5uxu4.jpeg"></a> <br><br>  Se voc√™, ao lidar com o material, sentir que est√° perdido - d√™ uma olhada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste</a> artigo. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">O que estamos procurando?</font> </h2><br>  Voc√™ √© livre para usar o sistema descrito aqui da maneira que desejar.  Por exemplo, usei-o para procurar passeios e ingressos de fim de semana para minha cidade natal.  Se voc√™ √© s√©rio em encontrar tickets lucrativos, pode executar o script no servidor (um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">servidor</a> simples, por 130 rublos por m√™s, √© bastante adequado para isso) e execut√°-lo uma ou duas vezes por dia.  Os resultados da pesquisa ser√£o enviados por e-mail para voc√™.  Al√©m disso, recomendo que voc√™ configure tudo para que o script salve o arquivo do Excel com os resultados da pesquisa na pasta Dropbox, que permite exibir esses arquivos de qualquer lugar e a qualquer momento. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d39/b7b/f3b/d39b7bf3b4f8c11fa9617ae308f01247.png"></div><br>  <i><font color="#999999">Ainda n√£o encontrei tarifas com erros, mas acredito que isso seja poss√≠vel</font></i> <br><br>  Ao pesquisar, como j√° foi dito, uma "data flex√≠vel" √© usada, o script encontra ofertas dentro de tr√™s dias a partir das datas especificadas.  Embora, ao iniciar o script, ele procure ofertas em apenas uma dire√ß√£o, √© f√°cil refin√°-lo para que ele possa coletar dados em v√°rias dire√ß√µes dos voos.  Com sua ajuda, voc√™ pode at√© procurar tarifas erradas, tais achados podem ser muito interessantes. <br><br><h2>  <font color="#3AC1EF">Por que preciso de outro raspador da web?</font> </h2><br>  Quando comecei a raspagem na web, para ser sincero, n√£o era particularmente interessante.  Eu queria fazer mais projetos no campo da modelagem preditiva, an√°lise financeira e, possivelmente, no campo de an√°lise da colora√ß√£o emocional dos textos.  Mas acabou sendo muito interessante - descobrir como criar um programa que coleta dados de sites.  Ao me aprofundar neste t√≥pico, percebi que a raspagem da Web √© o "mecanismo" da Internet. <br><br>  Voc√™ pode decidir que esta √© uma declara√ß√£o muito ousada.  Mas pense em como o Google come√ßou com um raspador da Web criado por Larry Page usando Java e Python.  O Googlebots est√° pesquisando e explorando a Internet, tentando fornecer a seus usu√°rios as melhores respostas poss√≠veis para suas perguntas.  A raspagem da Web possui um n√∫mero infinito de aplicativos e, mesmo se voc√™, no campo da Ci√™ncia de Dados, estiver interessado em outra coisa, para obter dados para an√°lise, voc√™ precisar√° de algumas habilidades de raspagem. <br><br>  Alguns dos truques usados ‚Äã‚Äãaqui foram encontrados em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">livro</a> maravilhoso sobre raspagem na web, que adquiri recentemente.  Nele voc√™ pode encontrar muitos exemplos e id√©ias simples sobre a aplica√ß√£o pr√°tica dos estudados.  Al√©m disso, h√° um cap√≠tulo muito interessante sobre o desvio de teste do reCaptcha.  Para mim, isso era novidade, pois eu n√£o sabia que havia ferramentas especiais e servi√ßos completos para resolver esses problemas. <br><br><h2>  <font color="#3AC1EF">Voc√™ gosta de viajar ?!</font> </h2><br>  √Ä pergunta simples e bastante inofensiva colocada no cabe√ßalho desta se√ß√£o, muitas vezes √© poss√≠vel ouvir uma resposta positiva, fornecida com algumas hist√≥rias de viagem da pessoa a quem ela foi solicitada.  Muitos de n√≥s concordam que viajar √© uma √≥tima maneira de mergulhar em novos ambientes culturais e expandir nossos horizontes.  No entanto, se voc√™ perguntar a algu√©m se ele gosta de procurar passagens a√©reas, tenho certeza de que a resposta estar√° longe de ser t√£o positiva.  De fato, aqui o Python vem em socorro. <br><br>  A primeira tarefa que precisamos resolver no caminho de criar um sistema de busca de informa√ß√µes sobre passagens a√©reas √© selecionar uma plataforma adequada com a qual obteremos informa√ß√µes.  A solu√ß√£o para esse problema n√£o foi f√°cil para mim, mas, no final, escolhi o servi√ßo Kayak.  Tentei os servi√ßos de Momondo, Skyscanner, Expedia e um pouco mais, mas os mecanismos de prote√ß√£o contra rob√¥s nesses recursos eram impenetr√°veis.  Depois de v√°rias tentativas, durante as quais, ao tentar convencer os sistemas de que eu era humano, tive que lidar com sem√°foros, passagens para pedestres e bicicletas, decidi que o caiaque me convinha melhor, mesmo aqui tamb√©m, se carregar muitas p√°ginas em pouco tempo, as verifica√ß√µes tamb√©m come√ßam.  Consegui fazer o bot enviar solicita√ß√µes para o site em intervalos de 4 a 6 horas, e tudo funcionou bem.  As dificuldades tamb√©m surgem periodicamente ao trabalhar com o Kayak, mas se voc√™ come√ßar a ser incomodado por verifica√ß√µes, precisar√° lidar com elas manualmente, iniciar o bot ou esperar algumas horas, e as verifica√ß√µes devem parar.  Se necess√°rio, voc√™ pode adaptar o c√≥digo para outra plataforma e, se fizer isso, poder√° denunci√°-lo nos coment√°rios. <br><br>  Se voc√™ est√° come√ßando o scraping na Web e n√£o sabe por que alguns sites est√£o tendo problemas, antes de iniciar seu primeiro projeto nessa √°rea, fa√ßa um favor a si mesmo e pesquise no Google por palavras "Etiqueta de raspagem na web".  Seus experimentos podem terminar mais cedo do que voc√™ imagina se estiver envolvido de maneira irracional na raspagem da Web. <br><br><h2>  <font color="#3AC1EF">Introdu√ß√£o</font> </h2><br>  Aqui est√° uma vis√£o geral do que acontecer√° no c√≥digo do nosso raspador da Web: <br><br><ul><li>  Importe as bibliotecas necess√°rias. </li><li>  Abra a guia Google Chrome. </li><li>  Chamando a fun√ß√£o que lan√ßa o bot, passando a cidade e a data, que ser√£o usadas na procura de ingressos. </li><li>  Esta fun√ß√£o recebe os primeiros resultados da pesquisa, classificados pelos crit√©rios dos mais atraentes (melhores), e pressiona o bot√£o para carregar resultados adicionais. </li><li>  Outra fun√ß√£o coleta dados da p√°gina inteira e retorna um quadro de dados. </li><li>  As duas etapas anteriores s√£o executadas usando tipos de classifica√ß√£o pelo pre√ßo do bilhete (barato) e pela velocidade do v√¥o (mais r√°pida). </li><li>  Um email √© enviado ao usu√°rio do script contendo um breve resumo dos pre√ßos dos ingressos (os mais baratos e o pre√ßo m√©dio), e o quadro de dados com informa√ß√µes classificadas pelos tr√™s indicadores mencionados acima √© salvo como um arquivo do Excel. </li><li>  Todas as a√ß√µes acima s√£o executadas em um ciclo ap√≥s um per√≠odo especificado. </li></ul><br>  Note-se que todo projeto Selenium come√ßa com um driver da web.  Uso o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chromedriver</a> , trabalho com o Google Chrome, mas existem outras op√ß√µes.  Tamb√©m populares s√£o o PhantomJS e o Firefox.  Depois de carregar o driver, voc√™ precisa coloc√°-lo na pasta apropriada, isso completa a prepara√ß√£o para o seu uso.  As primeiras linhas do nosso script abrem uma nova guia Chrome. <br><br>  Lembre-se de que, na minha hist√≥ria, n√£o estou tentando abrir novos horizontes para encontrar ofertas lucrativas em passagens a√©reas.  Existem t√©cnicas muito mais avan√ßadas para encontrar essas ofertas.  Eu s√≥ quero oferecer aos leitores deste material uma maneira simples, mas pr√°tica, de resolver esse problema. <br><br>  Aqui est√° o c√≥digo que falamos acima. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sleep, strftime <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> randint <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> selenium <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> webdriver <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> selenium.webdriver.common.keys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Keys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> smtplib <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> email.mime.multipart <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MIMEMultipart <span class="hljs-comment"><span class="hljs-comment">#      chromedriver! chromedriver_path = 'C:/{YOUR PATH HERE}/chromedriver_win32/chromedriver.exe' driver = webdriver.Chrome(executable_path=chromedriver_path) #     Chrome sleep(2)</span></span></code> </pre> <br>  No in√≠cio do c√≥digo, voc√™ pode ver os comandos de importa√ß√£o de pacotes usados ‚Äã‚Äãem todo o nosso projeto.  Portanto, o <code>randint</code> √© usado para que o bot "adorme√ßa" por um n√∫mero aleat√≥rio de segundos antes de iniciar uma nova opera√ß√£o de pesquisa.  Normalmente, nenhum bot pode ficar sem ele.  Se voc√™ executar o c√≥digo acima, uma janela do Chrome ser√° aberta, a qual o bot usar√° para trabalhar com sites. <br><br>  Vamos fazer um pequeno experimento e abrir o site kayak.com em uma janela separada.  Escolha a cidade a partir da qual vamos voar, a cidade para a qual queremos chegar e as datas dos voos.  Ao escolher as datas, verificaremos se o intervalo √© de + -3 dias.  Eu escrevi o c√≥digo levando em considera√ß√£o o que o site produz em resposta a esses pedidos.  Se, por exemplo, voc√™ precisar procurar tickets apenas para determinadas datas, √© altamente prov√°vel que voc√™ precise modificar o c√≥digo bot.  Falando sobre o c√≥digo, fa√ßo explica√ß√µes apropriadas, mas se voc√™ sentir que est√° confuso, me avise. <br><br>  Agora clique no bot√£o iniciar da pesquisa e veja o link na barra de endere√ßo.  Ele deve se parecer com o link que eu uso no exemplo abaixo, onde a vari√°vel <code>kayak</code> que armazena a URL √© declarada e o m√©todo <code>get</code> do driver da web √© usado.  Depois de clicar no bot√£o de pesquisa, os resultados devem aparecer na p√°gina. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ae6/ac7/1f7/ae6ac71f71c92c6ff76d5dd6a8fcfa25.png"></div><br>  Quando usei o comando <code>get</code> mais de duas a tr√™s vezes em alguns minutos, fui solicitado a passar em um teste usando o reCaptcha.  Voc√™ pode passar por essa verifica√ß√£o manualmente e continuar as experi√™ncias at√© que o sistema decida organizar uma nova verifica√ß√£o.  Quando testei o script, tive a sensa√ß√£o de que a primeira sess√£o de pesquisa sempre fica sem problemas; portanto, se voc√™ quiser experimentar o c√≥digo, basta chec√°-lo manualmente periodicamente e deixar que o c√≥digo seja executado usando longos intervalos entre as sess√µes de pesquisa.  Sim, e se voc√™ pensar bem, √© improv√°vel que uma pessoa precise de informa√ß√µes sobre os pre√ßos dos ingressos recebidos em intervalos de 10 minutos entre as opera√ß√µes de pesquisa. <br><br><h2>  <font color="#3AC1EF">Trabalhando com uma P√°gina Usando XPath</font> </h2><br>  Ent√£o, abrimos a janela e carregamos o site.  Para obter pre√ßos e outras informa√ß√µes, precisamos usar a tecnologia XPath ou seletores CSS.  Eu decidi me debru√ßar sobre o XPath e n√£o senti a necessidade de usar seletores CSS, mas √© bem poss√≠vel trabalhar assim.  Mover uma p√°gina usando o XPath pode ser uma tarefa assustadora e, mesmo que voc√™ use os m√©todos que descrevi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste</a> artigo, que usavam a c√≥pia dos identificadores correspondentes do c√≥digo da p√°gina, percebi que essa n√£o √© a melhor maneira de acessar elementos necess√°rios.  A prop√≥sito, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste</a> livro, voc√™ pode encontrar uma excelente descri√ß√£o dos conceitos b√°sicos sobre como trabalhar com p√°ginas usando os seletores XPath e CSS.  Aqui est√° a apar√™ncia do m√©todo correspondente do driver da web. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fa6/5c0/5c0/fa65c05c0385c658a4eee0c08a6274ff.png"></div><br>  Ent√£o, continuamos a trabalhar no bot.  Aproveite o programa para selecionar os bilhetes mais baratos.  Na imagem a seguir, o c√≥digo do seletor XPath √© destacado em vermelho.  Para visualizar o c√≥digo, voc√™ precisa clicar com o bot√£o direito do mouse no elemento da p√°gina em que est√° interessado e selecionar o comando Inspecionar no menu exibido.  Este comando pode ser chamado para diferentes elementos da p√°gina, cujo c√≥digo ser√° exibido e destacado na janela de visualiza√ß√£o de c√≥digo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2c4/eee/9dc/2c4eee9dc28a8ef0ff540e1c01d3eda5.png"></div><br>  <i><font color="#999999">Exibir c√≥digo da p√°gina</font></i> <br><br>  Para encontrar confirma√ß√£o do meu racioc√≠nio sobre as desvantagens de copiar seletores do c√≥digo, preste aten√ß√£o aos seguintes recursos. <br><br>  Aqui est√° o que voc√™ obt√©m ao copiar c√≥digo: <br><br><pre> <code class="python hljs">//*[@id=<span class="hljs-string"><span class="hljs-string">"wtKI-price_aTab"</span></span>]/div[<span class="hljs-number"><span class="hljs-number">1</span></span>]/div/div/div[<span class="hljs-number"><span class="hljs-number">1</span></span>]/div/span/span</code> </pre> <br>  Para copiar algo semelhante, √© necess√°rio clicar com o bot√£o direito do mouse na parte do c√≥digo que lhe interessa e selecionar Copiar&gt; Copiar XPath no menu exibido. <br><br>  Aqui est√° o que eu usei para definir o bot√£o Mais Barato: <br><br><pre> <code class="python hljs">cheap_results = <span class="hljs-string"><span class="hljs-string">'//a[@data-code = "price"]'</span></span></code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9c9/4e3/8a4/9c94e38a436fa588ade8a2f92d97aa2d.png"></div><br>  <i><font color="#999999">Copiar&gt; Copiar Comando XPath</font></i> <br><br>  √â bastante √≥bvio que a segunda op√ß√£o parece muito mais simples.  Ao us√°-lo, ele procura o elemento a, que possui o atributo de <code>data-code</code> igual ao <code>price</code> .  Utilizando a primeira op√ß√£o, √© pesquisado um elemento <code>id</code> que √© <code>wtKI-price_aTab</code> , e o caminho XPath para o elemento se parece com <code>/div[1]/div/div/div[1]/div/span/span</code> .  Uma solicita√ß√£o XPath semelhante a uma p√°gina far√° o truque, mas apenas uma vez.  Posso dizer agora que o <code>id</code> ser√° alterado na pr√≥xima vez que a p√°gina for carregada.  A <code>wtKI</code> caracteres <code>wtKI</code> muda dinamicamente toda vez que a p√°gina √© carregada; como resultado, o c√≥digo no qual ela √© usada ser√° in√∫til ap√≥s a pr√≥xima p√°gina ser recarregada.  Portanto, dedique algum tempo para descobrir o XPath.  Este conhecimento ir√° atend√™-lo bem. <br><br>  No entanto, deve-se observar que a c√≥pia de seletores XPath pode ser √∫til ao trabalhar com sites bastante simples e, se isso lhe conv√©m, n√£o h√° nada de errado nisso. <br><br>  Agora, vamos pensar no que fazer se precisar obter todos os resultados da pesquisa em v√°rias linhas, dentro da lista.  Muito simples  Cada resultado est√° dentro de um objeto com a classe <code>resultWrapper</code> .  O download de todos os resultados pode ser feito em um loop semelhante ao mostrado abaixo. <br><br>  Deve-se notar que, se voc√™ entende o que foi dito acima, deve entender facilmente a maior parte do c√≥digo que analisaremos.  No decorrer do trabalho desse c√≥digo, nos voltamos para o que precisamos (de fato, este √© o elemento no qual o resultado √© agrupado) usando algum mecanismo para indicar o caminho (XPath).  Isso √© feito para obter o texto do elemento e coloc√°-lo em um objeto a partir do qual os dados podem ser lidos (primeiro use <code>flight_containers</code> , em seguida, <code>flights_list</code> ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0b2/3fc/b7f/0b23fcb7f32738fd6012541c40f68b97.png"></div><br>  As tr√™s primeiras linhas s√£o exibidas e podemos ver claramente tudo o que precisamos.  No entanto, temos maneiras mais interessantes de obter informa√ß√µes.  Precisamos coletar dados de cada elemento separadamente. <br><br><h2>  <font color="#3AC1EF">Trabalhar!</font> </h2><br>  √â mais f√°cil escrever uma fun√ß√£o para carregar resultados adicionais, ent√£o vamos come√ßar com ela.  Gostaria de maximizar o n√∫mero de v√¥os sobre os quais o programa recebe informa√ß√µes e, ao mesmo tempo, n√£o causar suspeitas no servi√ßo que levam √† verifica√ß√£o, por isso clico no bot√£o Carregar mais resultados uma vez toda vez que a p√°gina √© exibida.  Neste c√≥digo, voc√™ deve prestar aten√ß√£o ao bloco <code>try</code> , que eu adicionei devido ao fato de que √†s vezes o bot√£o n√£o carrega normalmente.  Se voc√™ tamb√©m encontrar isso, comente as chamadas para essa fun√ß√£o no c√≥digo da fun√ß√£o <code>start_kayak</code> , que discutiremos abaixo. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      ,      def load_more():   try:       more_results = '//a[@class = "moreButton"]'       driver.find_element_by_xpath(more_results).click()       #            ,          print('sleeping.....')       sleep(randint(45,60))   except:       pass</span></span></code> </pre> <br>  Agora, depois de uma longa an√°lise dessa fun√ß√£o (√†s vezes eu posso me deixar levar), estamos prontos para declarar uma fun√ß√£o que lidar√° com a raspagem de p√°gina. <br><br>  Eu j√° coletei a maior parte do necess√°rio na pr√≥xima fun√ß√£o chamada <code>page_scrape</code> .  √Äs vezes, os dados retornados sobre os est√°gios do caminho acabam sendo combinados; para a separa√ß√£o deles, uso um m√©todo simples.  Por exemplo, na primeira vez que utilizo as vari√°veis <code>section_a_list</code> e <code>section_b_list</code> .  Nossa fun√ß√£o retorna o quadro de dados <code>flights_df</code> , isso nos permite separar os resultados obtidos usando diferentes m√©todos de classifica√ß√£o de dados e depois combin√°-los. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">page_scrape</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-string"><span class="hljs-string">"""This function takes care of the scraping part"""</span></span>     xp_sections = <span class="hljs-string"><span class="hljs-string">'//*[@class="section duration"]'</span></span>   sections = driver.find_elements_by_xpath(xp_sections)   sections_list = [value.text <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> value <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sections]   section_a_list = sections_list[::<span class="hljs-number"><span class="hljs-number">2</span></span>] <span class="hljs-comment"><span class="hljs-comment">#          section_b_list = sections_list[1::2]     #     reCaptcha,    - .   #  ,  -   ,     ,       #   if        -   #    ,           #    SystemExit           if section_a_list == []:       raise SystemExit     #     A     B     a_duration = []   a_section_names = []   for n in section_a_list:       #         a_section_names.append(''.join(n.split()[2:5]))       a_duration.append(''.join(n.split()[0:2]))   b_duration = []   b_section_names = []   for n in section_b_list:       #         b_section_names.append(''.join(n.split()[2:5]))       b_duration.append(''.join(n.split()[0:2]))   xp_dates = '//div[@class="section date"]'   dates = driver.find_elements_by_xpath(xp_dates)   dates_list = [value.text for value in dates]   a_date_list = dates_list[::2]   b_date_list = dates_list[1::2]   #      a_day = [value.split()[0] for value in a_date_list]   a_weekday = [value.split()[1] for value in a_date_list]   b_day = [value.split()[0] for value in b_date_list]   b_weekday = [value.split()[1] for value in b_date_list]     #     xp_prices = '//a[@class="booking-link"]/span[@class="price option-text"]'   prices = driver.find_elements_by_xpath(xp_prices)   prices_list = [price.text.replace('$','') for price in prices if price.text != '']   prices_list = list(map(int, prices_list))   # stops -   ,         ,   -     xp_stops = '//div[@class="section stops"]/div[1]'   stops = driver.find_elements_by_xpath(xp_stops)   stops_list = [stop.text[0].replace('n','0') for stop in stops]   a_stop_list = stops_list[::2]   b_stop_list = stops_list[1::2]   xp_stops_cities = '//div[@class="section stops"]/div[2]'   stops_cities = driver.find_elements_by_xpath(xp_stops_cities)   stops_cities_list = [stop.text for stop in stops_cities]   a_stop_name_list = stops_cities_list[::2]   b_stop_name_list = stops_cities_list[1::2]     #   -,          xp_schedule = '//div[@class="section times"]'   schedules = driver.find_elements_by_xpath(xp_schedule)   hours_list = []   carrier_list = []   for schedule in schedules:       hours_list.append(schedule.text.split('\n')[0])       carrier_list.append(schedule.text.split('\n')[1])   #          a  b   a_hours = hours_list[::2]   a_carrier = carrier_list[1::2]   b_hours = hours_list[::2]   b_carrier = carrier_list[1::2]     cols = (['Out Day', 'Out Time', 'Out Weekday', 'Out Airline', 'Out Cities', 'Out Duration', 'Out Stops', 'Out Stop Cities',           'Return Day', 'Return Time', 'Return Weekday', 'Return Airline', 'Return Cities', 'Return Duration', 'Return Stops', 'Return Stop Cities',           'Price'])   flights_df = pd.DataFrame({'Out Day': a_day,                              'Out Weekday': a_weekday,                              'Out Duration': a_duration,                              'Out Cities': a_section_names,                              'Return Day': b_day,                              'Return Weekday': b_weekday,                              'Return Duration': b_duration,                              'Return Cities': b_section_names,                              'Out Stops': a_stop_list,                              'Out Stop Cities': a_stop_name_list,                              'Return Stops': b_stop_list,                              'Return Stop Cities': b_stop_name_list,                              'Out Time': a_hours,                              'Out Airline': a_carrier,                              'Return Time': b_hours,                              'Return Airline': b_carrier,                                                     'Price': prices_list})[cols]     flights_df['timestamp'] = strftime("%Y%m%d-%H%M") #      return flights_df</span></span></code> </pre> <br>  Tentei nomear as vari√°veis ‚Äã‚Äãpara que o c√≥digo ficasse claro.  Lembre-se de que as vari√°veis ‚Äã‚Äãque come√ßam com <code>a</code> referem-se ao primeiro passo do caminho <code>b</code> ao segundo.  V√° para a pr√≥xima fun√ß√£o. <br><br><h2>  <font color="#3AC1EF">Mecanismos auxiliares</font> </h2><br>  Agora, temos uma fun√ß√£o que permite carregar resultados de pesquisa adicionais e uma fun√ß√£o para processar esses resultados.  Este artigo pode ser conclu√≠do, pois essas duas fun√ß√µes fornecem tudo o necess√°rio para raspar p√°ginas que podem ser abertas independentemente.  Mas ainda n√£o consideramos alguns dos mecanismos auxiliares discutidos acima.  Por exemplo, este √© um c√≥digo para enviar e-mails e outras coisas.  Tudo isso pode ser encontrado na fun√ß√£o <code>start_kayak</code> , que agora consideramos. <br><br>  Para usar esta fun√ß√£o, voc√™ precisa de informa√ß√µes sobre cidades e datas.  Usando essas informa√ß√µes, ela forma um link na vari√°vel <code>kayak</code> , que √© usada para ir para uma p√°gina que conter√° os resultados da pesquisa classificados pela melhor correspond√™ncia.  Ap√≥s a primeira sess√£o de raspagem, trabalharemos com os pre√ßos na tabela na parte superior da p√°gina.  Ou seja, encontramos o pre√ßo m√≠nimo do ingresso e o pre√ßo m√©dio.  Tudo isso, juntamente com a previs√£o emitida pelo site, ser√£o enviados por e-mail.  Na p√°gina, a tabela correspondente deve estar no canto superior esquerdo.  Trabalhar com esta tabela, a prop√≥sito, pode causar um erro ao pesquisar usando datas exatas, pois nesse caso a tabela n√£o √© exibida na p√°gina. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">start_kayak</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(city_from, city_to, date_start, date_end)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-string"><span class="hljs-string">"""City codes - it's the IATA codes!   Date format -  YYYY-MM-DD"""</span></span>     kayak = (<span class="hljs-string"><span class="hljs-string">'https://www.kayak.com/flights/'</span></span> + city_from + <span class="hljs-string"><span class="hljs-string">'-'</span></span> + city_to +            <span class="hljs-string"><span class="hljs-string">'/'</span></span> + date_start + <span class="hljs-string"><span class="hljs-string">'-flexible/'</span></span> + date_end + <span class="hljs-string"><span class="hljs-string">'-flexible?sort=bestflight_a'</span></span>)   driver.get(kayak)   sleep(randint(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>))     <span class="hljs-comment"><span class="hljs-comment">#    ,           try   try:       xp_popup_close = '//button[contains(@id,"dialog-close") and contains(@class,"Button-No-Standard-Style close ")]'       driver.find_elements_by_xpath(xp_popup_close)[5].click()   except Exception as e:       pass   sleep(randint(60,95))   print('loading more.....')  #     load_more()     print('starting first scrape.....')   df_flights_best = page_scrape()   df_flights_best['sort'] = 'best'   sleep(randint(60,80))     #      ,        matrix = driver.find_elements_by_xpath('//*[contains(@id,"FlexMatrixCell")]')   matrix_prices = [price.text.replace('$','') for price in matrix]   matrix_prices = list(map(int, matrix_prices))   matrix_min = min(matrix_prices)   matrix_avg = sum(matrix_prices)/len(matrix_prices)     print('switching to cheapest results.....')   cheap_results = '//a[@data-code = "price"]'   driver.find_element_by_xpath(cheap_results).click()   sleep(randint(60,90))   print('loading more.....')  #     load_more()     print('starting second scrape.....')   df_flights_cheap = page_scrape()   df_flights_cheap['sort'] = 'cheap'   sleep(randint(60,80))     print('switching to quickest results.....')   quick_results = '//a[@data-code = "duration"]'   driver.find_element_by_xpath(quick_results).click()    sleep(randint(60,90))   print('loading more.....')  #     load_more()     print('starting third scrape.....')   df_flights_fast = page_scrape()   df_flights_fast['sort'] = 'fast'   sleep(randint(60,80))     #     Excel-,         final_df = df_flights_cheap.append(df_flights_best).append(df_flights_fast)   final_df.to_excel('search_backups//{}_flights_{}-{}_from_{}_to_{}.xlsx'.format(strftime("%Y%m%d-%H%M"),                                                                                  city_from, city_to,                                                                                  date_start, date_end), index=False)   print('saved df.....')     #    ,  ,  ,      xp_loading = '//div[contains(@id,"advice")]'   loading = driver.find_element_by_xpath(xp_loading).text   xp_prediction = '//span[@class="info-text"]'   prediction = driver.find_element_by_xpath(xp_prediction).text   print(loading+'\n'+prediction)     #    loading   , , ,        #    -    "Not Sure"   weird = '¬Ø\\_(„ÉÑ)_/¬Ø'   if loading == weird:       loading = 'Not sure'     username = 'YOUREMAIL@hotmail.com'   password = 'YOUR PASSWORD'   server = smtplib.SMTP('smtp.outlook.com', 587)   server.ehlo()   server.starttls()   server.login(username, password)   msg = ('Subject: Flight Scraper\n\n\ Cheapest Flight: {}\nAverage Price: {}\n\nRecommendation: {}\n\nEnd of message'.format(matrix_min, matrix_avg, (loading+'\n'+prediction)))   message = MIMEMultipart()   message['From'] = 'YOUREMAIL@hotmail.com'   message['to'] = 'YOUROTHEREMAIL@domain.com'   server.sendmail('YOUREMAIL@hotmail.com', 'YOUROTHEREMAIL@domain.com', msg)   print('sent email.....')</span></span></code> </pre> <br>  Testei esse script usando uma conta do Outlook (hotmail.com).  N√£o verifiquei o funcionamento correto da conta do Gmail, esse sistema de e-mail √© muito popular, mas existem muitas op√ß√µes poss√≠veis.  Se voc√™ usa uma conta do Hotmail, para que tudo funcione, basta inserir seus dados no c√≥digo. <br><br>  Se voc√™ deseja entender exatamente o que √© executado em se√ß√µes separadas do c√≥digo dessa fun√ß√£o, voc√™ pode copi√°-las e experimentar com elas.  As experi√™ncias com c√≥digo s√£o a √∫nica maneira de entend√™-lo. <br><br><h2>  <font color="#3AC1EF">Sistema pronto</font> </h2><br>  Agora que tudo o que falamos est√° pronto, podemos criar um loop simples no qual nossas fun√ß√µes s√£o chamadas.  O script solicita ao usu√°rio dados sobre cidades e datas.  Ao testar com uma reinicializa√ß√£o constante do script, √© improv√°vel que voc√™ insira esses dados manualmente a cada vez, para que as linhas correspondentes, durante a dura√ß√£o do teste, possam ser comentadas descomentando aquelas abaixo delas nas quais os dados necess√°rios para o script s√£o codificados. <br><br><pre> <code class="python hljs">city_from = input(<span class="hljs-string"><span class="hljs-string">'From which city? '</span></span>) city_to = input(<span class="hljs-string"><span class="hljs-string">'Where to? '</span></span>) date_start = input(<span class="hljs-string"><span class="hljs-string">'Search around which departure date? Please use YYYY-MM-DD format only '</span></span>) date_end = input(<span class="hljs-string"><span class="hljs-string">'Return when? Please use YYYY-MM-DD format only '</span></span>) <span class="hljs-comment"><span class="hljs-comment"># city_from = 'LIS' # city_to = 'SIN' # date_start = '2019-08-21' # date_end = '2019-09-07' for n in range(0,5):   start_kayak(city_from, city_to, date_start, date_end)   print('iteration {} was complete @ {}'.format(n, strftime("%Y%m%d-%H%M")))     #  4    sleep(60*60*4)   print('sleep finished.....')</span></span></code> </pre> <br>  Aqui est√° a execu√ß√£o de teste do script. <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/44c/305/023/44c305023996a98a3dec745493dce7a7.png"></div><br>  <i><font color="#999999">Script de execu√ß√£o de teste</font></i> <br><br><h2>  <font color="#3AC1EF">Sum√°rio</font> </h2><br>  Se voc√™ chegar a esse ponto - parab√©ns!  Agora voc√™ tem um raspador de web em funcionamento, embora eu j√° veja muitas maneiras de melhor√°-lo.  Por exemplo, ele pode ser integrado ao Twilio para que, em vez de emails, envie mensagens de texto.  Voc√™ pode usar uma VPN ou outra coisa para receber simultaneamente resultados de v√°rios servidores.  H√° tamb√©m um problema recorrente ao verificar se o usu√°rio do site √© uma pessoa, mas esse problema tamb√©m pode ser resolvido.  De qualquer forma, agora voc√™ tem uma base que pode ser expandida, se desejar.  Por exemplo, para garantir que o arquivo do Excel seja enviado ao usu√°rio como um anexo de um email. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt451872/">https://habr.com/ru/post/pt451872/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt451860/index.html">Matem√°ticos descobriram a maneira perfeita de multiplicar n√∫meros</a></li>
<li><a href="../pt451862/index.html">Musical Lightning, de Joe Diprim: um engenheiro autodidata faz bobinas de Tesla para entretenimento e ganhos</a></li>
<li><a href="../pt451864/index.html">Vulnerabilidade cr√≠tica ao n√≠vel de EternalBlue no RCE detectada no sistema operacional Windows</a></li>
<li><a href="../pt451866/index.html">Escolha os n√≥s mais pr√≥ximos na rede</a></li>
<li><a href="../pt451870/index.html">Recursos modernos em C ++ que todos os programadores precisam conhecer</a></li>
<li><a href="../pt451874/index.html">Principais tend√™ncias de SEO no Google</a></li>
<li><a href="../pt451876/index.html">Data center de Frankfurt: data center de Telehouse</a></li>
<li><a href="../pt451878/index.html">Transmiss√£o ao vivo de v√≠deo est√©reo para √≥culos VR (Oculus Go)</a></li>
<li><a href="../pt451880/index.html">DevPRO'19: vista do estande da Wrike</a></li>
<li><a href="../pt451884/index.html">Sete anos trabalhando como desenvolvedor: que li√ß√µes aprendi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>